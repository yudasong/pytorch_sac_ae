{"episode_reward": 0.0, "episode": 1.0, "duration": 18.10740637779236, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.508040189743042, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.2482080787281149, "critic_loss": 0.017607976366660522, "actor_loss": -24.024613438792027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 68.44543147087097, "step": 3000}
{"episode_reward": 5.977581655482409, "episode": 4.0, "batch_reward": 0.15542580066621303, "critic_loss": 0.009989749793428928, "actor_loss": -20.790985971450805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.293835639953613, "step": 4000}
{"episode_reward": 7.4570145876339105, "episode": 5.0, "batch_reward": 0.1229660843089223, "critic_loss": 0.013121801006607712, "actor_loss": -20.958934911727905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.487685680389404, "step": 5000}
{"episode_reward": 11.147986926944029, "episode": 6.0, "batch_reward": 0.10225877122208477, "critic_loss": 0.01366557301278226, "actor_loss": -19.288419724464415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.575700044631958, "step": 6000}
{"episode_reward": 9.323491432812856, "episode": 7.0, "batch_reward": 0.08804035357013344, "critic_loss": 0.012306214409414679, "actor_loss": -18.85723865032196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.366562843322754, "step": 7000}
{"episode_reward": 7.170052653928828, "episode": 8.0, "batch_reward": 0.07694147111847997, "critic_loss": 0.01248003357835114, "actor_loss": -19.22281179523468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.845683336257935, "step": 8000}
{"episode_reward": 8.429162351806706, "episode": 9.0, "batch_reward": 0.06832260422594845, "critic_loss": 0.008356576329329983, "actor_loss": -18.420626846313475, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.390541315078735, "step": 9000}
{"episode_reward": 10.029625348353004, "episode": 10.0, "batch_reward": 0.06267840024642646, "critic_loss": 0.011936111012008041, "actor_loss": -18.40512212085724, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.94986605644226, "step": 10000}
{"episode_reward": 7.233914073092059, "episode": 11.0, "batch_reward": 0.05699569246545434, "critic_loss": 0.0111332222847268, "actor_loss": -17.135356469631194, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.902374267578125, "step": 11000}
{"episode_reward": 7.531856885826691, "episode": 12.0, "batch_reward": 0.053622232470661405, "critic_loss": 0.010297119951574132, "actor_loss": -17.713844769001007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.17784094810486, "step": 12000}
{"episode_reward": 9.509122693622317, "episode": 13.0, "batch_reward": 0.049702401800081134, "critic_loss": 0.009074992093723267, "actor_loss": -16.49076998233795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.936995029449463, "step": 13000}
{"episode_reward": 8.066404544311826, "episode": 14.0, "batch_reward": 0.04577573534939438, "critic_loss": 0.009526424091891385, "actor_loss": -16.915636035442354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34327507019043, "step": 14000}
{"episode_reward": 7.752669362920739, "episode": 15.0, "batch_reward": 0.04385563518479466, "critic_loss": 0.011466967333923094, "actor_loss": -15.236012357234955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.144461393356323, "step": 15000}
{"episode_reward": 7.964675070192192, "episode": 16.0, "batch_reward": 0.04085257287230343, "critic_loss": 0.00900954317569267, "actor_loss": -17.582880834579466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.67682147026062, "step": 16000}
{"episode_reward": 9.011635979621708, "episode": 17.0, "batch_reward": 0.039340125755406914, "critic_loss": 0.010057684875559062, "actor_loss": -16.837899310112, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.14694094657898, "step": 17000}
{"episode_reward": 10.297700499204945, "episode": 18.0, "batch_reward": 0.03737340576853603, "critic_loss": 0.005890685577644036, "actor_loss": -17.345713347434998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.75339651107788, "step": 18000}
{"episode_reward": 7.610320006945052, "episode": 19.0, "batch_reward": 0.03663464087387547, "critic_loss": 0.011202228613197803, "actor_loss": -16.97401166391373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.974170684814453, "step": 19000}
{"episode_reward": 13.28554008980593, "episode": 20.0, "batch_reward": 0.0352792390557006, "critic_loss": 0.006136359917058144, "actor_loss": -15.177390038490296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.822455406188965, "step": 20000}
{"episode_reward": 8.228257885599936, "episode": 21.0, "batch_reward": 0.03310779125802219, "critic_loss": 0.009778855448355899, "actor_loss": -16.211309455871582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.58687400817871, "step": 21000}
{"episode_reward": 10.406124952107284, "episode": 22.0, "batch_reward": 0.03229903947608546, "critic_loss": 0.011545094105298631, "actor_loss": -15.736505534648895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.262216567993164, "step": 22000}
{"episode_reward": 11.002951297063783, "episode": 23.0, "batch_reward": 0.03134806588664651, "critic_loss": 0.005685034279245884, "actor_loss": -15.307567796230316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.469730615615845, "step": 23000}
{"episode_reward": 6.549979631375147, "episode": 24.0, "batch_reward": 0.030619853352196514, "critic_loss": 0.0073721374655142426, "actor_loss": -15.347910524845123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.926125526428223, "step": 24000}
{"episode_reward": 7.409283713920729, "episode": 25.0, "batch_reward": 0.029621238447725774, "critic_loss": 0.008647009789186996, "actor_loss": -15.159891034603119, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.832003831863403, "step": 25000}
{"episode_reward": 8.329841997611455, "episode": 26.0, "batch_reward": 0.029167220955714585, "critic_loss": 0.00668310240394203, "actor_loss": -15.846413942575454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.7044939994812, "step": 26000}
{"episode_reward": 10.771140608821606, "episode": 27.0, "batch_reward": 0.028474664177745582, "critic_loss": 0.006266047020850238, "actor_loss": -14.588184935092926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.912158489227295, "step": 27000}
{"episode_reward": 9.086047072270322, "episode": 28.0, "batch_reward": 0.02677393130492419, "critic_loss": 0.009127133441215846, "actor_loss": -15.883521932840347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.83152151107788, "step": 28000}
{"episode_reward": 8.631232795553046, "episode": 29.0, "batch_reward": 0.026308117403648794, "critic_loss": 0.0039513450065278444, "actor_loss": -14.356894783973694, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.451621532440186, "step": 29000}
{"episode_reward": 10.060721955225132, "episode": 30.0, "batch_reward": 0.026516594010405244, "critic_loss": 0.006738307251071092, "actor_loss": -14.524068396091462, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.83346462249756, "step": 30000}
{"episode_reward": 8.636054697767088, "episode": 31.0, "batch_reward": 0.02548322481755167, "critic_loss": 0.005761512693890836, "actor_loss": -15.462170649528504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.45375156402588, "step": 31000}
{"episode_reward": 7.254894514756208, "episode": 32.0, "batch_reward": 0.024861905882135035, "critic_loss": 0.006967892804881558, "actor_loss": -15.447047972917558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.914109468460083, "step": 32000}
{"episode_reward": 5.385065679588657, "episode": 33.0, "batch_reward": 0.024862075719982387, "critic_loss": 0.00854464567269315, "actor_loss": -13.83441796207428, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.39800214767456, "step": 33000}
{"episode_reward": 10.360251723060923, "episode": 34.0, "batch_reward": 0.02386918044416234, "critic_loss": 0.004834734467614908, "actor_loss": -15.045530379652977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.118024587631226, "step": 34000}
{"episode_reward": 9.850284405468633, "episode": 35.0, "batch_reward": 0.023430799143854528, "critic_loss": 0.005537395007559098, "actor_loss": -15.34576459145546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.83365797996521, "step": 35000}
{"episode_reward": 7.383917874667553, "episode": 36.0, "batch_reward": 0.023128113466780634, "critic_loss": 0.004741608572367113, "actor_loss": -15.860955503106117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.973613023757935, "step": 36000}
{"episode_reward": 9.725811761871004, "episode": 37.0, "batch_reward": 0.022644624557811768, "critic_loss": 0.006377204582211561, "actor_loss": -15.226512469768524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.458004474639893, "step": 37000}
{"episode_reward": 7.339681117719171, "episode": 38.0, "batch_reward": 0.022351640969514846, "critic_loss": 0.006345199732517358, "actor_loss": -13.826096030116082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.578791618347168, "step": 38000}
{"episode_reward": 6.25741806389674, "episode": 39.0, "batch_reward": 0.022215693430043756, "critic_loss": 0.0040011009659210684, "actor_loss": -14.653387160539626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.69276475906372, "step": 39000}
{"episode_reward": 5.862841704092831, "episode": 40.0, "batch_reward": 0.021217282094061374, "critic_loss": 0.004850401310570305, "actor_loss": -15.317797600746156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.320245265960693, "step": 40000}
{"episode_reward": 6.082704622187762, "episode": 41.0, "batch_reward": 0.021165097611490637, "critic_loss": 0.006372809793276247, "actor_loss": -15.90930898451805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.442126512527466, "step": 41000}
{"episode_reward": 7.516683483686725, "episode": 42.0, "batch_reward": 0.020665340131148697, "critic_loss": 0.00460460790747311, "actor_loss": -14.42987021100521, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.89441156387329, "step": 42000}
{"episode_reward": 6.513644796407618, "episode": 43.0, "batch_reward": 0.020269818679895253, "critic_loss": 0.0070131477712420745, "actor_loss": -14.994525262951852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.974581718444824, "step": 43000}
{"episode_reward": 8.311255406936416, "episode": 44.0, "batch_reward": 0.01992710312921554, "critic_loss": 0.004234830989938928, "actor_loss": -14.157267951965332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.361810207366943, "step": 44000}
{"episode_reward": 7.3179086145575685, "episode": 45.0, "batch_reward": 0.019765009140595792, "critic_loss": 0.004021573423495284, "actor_loss": -13.533132968306541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.125751733779907, "step": 45000}
{"episode_reward": 7.365682225891497, "episode": 46.0, "batch_reward": 0.019707804766483605, "critic_loss": 0.004706943052588031, "actor_loss": -14.985601528882981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.16584801673889, "step": 46000}
{"episode_reward": 10.169289515807465, "episode": 47.0, "batch_reward": 0.019400705511681736, "critic_loss": 0.005346167055598925, "actor_loss": -15.402902765274048, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97657346725464, "step": 47000}
{"episode_reward": 6.236715388690514, "episode": 48.0, "batch_reward": 0.019000670250505208, "critic_loss": 0.004500112776644528, "actor_loss": -14.485890356659889, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90449857711792, "step": 48000}
{"episode_reward": 6.795570312443422, "episode": 49.0, "batch_reward": 0.019295082371216268, "critic_loss": 0.004265113902685698, "actor_loss": -14.989304322957993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.4923996925354, "step": 49000}
{"episode_reward": 7.453120451116436, "episode": 50.0, "batch_reward": 0.018919342040549965, "critic_loss": 0.0034137906706600916, "actor_loss": -14.079074702441693, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.628418445587158, "step": 50000}
{"episode_reward": 11.137368627050229, "episode": 51.0, "batch_reward": 0.018534884220454843, "critic_loss": 0.006277038071362768, "actor_loss": -12.90547908526659, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.07572317123413, "step": 51000}
{"episode_reward": 10.098283745712283, "episode": 52.0, "batch_reward": 0.018537782285828145, "critic_loss": 0.003528263704996789, "actor_loss": -15.47428874129057, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.199920892715454, "step": 52000}
{"episode_reward": 7.4759919341001275, "episode": 53.0, "batch_reward": 0.018284641849342732, "critic_loss": 0.00516720880655339, "actor_loss": -12.887096637010574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.755246877670288, "step": 53000}
{"episode_reward": 6.478290178800252, "episode": 54.0, "batch_reward": 0.018357230506371707, "critic_loss": 0.003403105624107411, "actor_loss": -15.608562731027604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.963242292404175, "step": 54000}
{"episode_reward": 7.375388459121393, "episode": 55.0, "batch_reward": 0.017684783482458444, "critic_loss": 0.003828773868706776, "actor_loss": -14.81593288975954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.788005590438843, "step": 55000}
{"episode_reward": 6.522187074839669, "episode": 56.0, "batch_reward": 0.017354354550596328, "critic_loss": 0.006411863356013782, "actor_loss": -13.470818661510945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.125186920166016, "step": 56000}
{"episode_reward": 7.989354537104922, "episode": 57.0, "batch_reward": 0.017506898764520884, "critic_loss": 0.0032543986150121783, "actor_loss": -13.943980694234371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.37332320213318, "step": 57000}
{"episode_reward": 7.345188563130117, "episode": 58.0, "batch_reward": 0.01722889005811885, "critic_loss": 0.005431957539127325, "actor_loss": -13.234763107776642, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.23728084564209, "step": 58000}
{"episode_reward": 8.696758507669415, "episode": 59.0, "batch_reward": 0.016911098608281463, "critic_loss": 0.003133982090483187, "actor_loss": -14.23696998566389, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.486509084701538, "step": 59000}
{"episode_reward": 12.11325568960305, "episode": 60.0, "batch_reward": 0.017023938050027936, "critic_loss": 0.0042321159692073704, "actor_loss": -15.172061421751977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.766054391860962, "step": 60000}
{"episode_reward": 14.384131954125081, "episode": 61.0, "batch_reward": 0.016740053557325156, "critic_loss": 0.004168679451744537, "actor_loss": -14.660762937009334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.23565721511841, "step": 61000}
{"episode_reward": 7.280974816717407, "episode": 62.0, "batch_reward": 0.016446102927904577, "critic_loss": 0.003377158280403819, "actor_loss": -12.993350650787354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.058043241500854, "step": 62000}
{"episode_reward": 10.863346175402675, "episode": 63.0, "batch_reward": 0.01653221560968086, "critic_loss": 0.004241642501030583, "actor_loss": -13.194299197137356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.28234076499939, "step": 63000}
{"episode_reward": 10.193163913078257, "episode": 64.0, "batch_reward": 0.016453327413182707, "critic_loss": 0.00392614616866922, "actor_loss": -13.754623243153095, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.707550525665283, "step": 64000}
{"episode_reward": 12.208791303674577, "episode": 65.0, "batch_reward": 0.016548133657779546, "critic_loss": 0.003964469439699314, "actor_loss": -13.45764558762312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.58584976196289, "step": 65000}
{"episode_reward": 8.390569773294894, "episode": 66.0, "batch_reward": 0.01610699556907639, "critic_loss": 0.0033177808176260443, "actor_loss": -13.611033840060234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.076265811920166, "step": 66000}
{"episode_reward": 7.335885122692943, "episode": 67.0, "batch_reward": 0.01606193795381114, "critic_loss": 0.0032659941611636895, "actor_loss": -12.708215927779674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.161837339401245, "step": 67000}
{"episode_reward": 7.0260550834979645, "episode": 68.0, "batch_reward": 0.016173750292975457, "critic_loss": 0.004008834536827635, "actor_loss": -13.81581245368719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.290512084960938, "step": 68000}
{"episode_reward": 6.314271813190291, "episode": 69.0, "batch_reward": 0.016092536597047, "critic_loss": 0.0030922840135754084, "actor_loss": -13.876357921421528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.694435596466064, "step": 69000}
{"episode_reward": 12.591858339167471, "episode": 70.0, "batch_reward": 0.01577134483214468, "critic_loss": 0.003867605542647652, "actor_loss": -14.456668345510959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.17697811126709, "step": 70000}
{"episode_reward": 8.026937815187583, "episode": 71.0, "batch_reward": 0.015732038609217854, "critic_loss": 0.00345307246997254, "actor_loss": -14.392130253314972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.61625051498413, "step": 71000}
{"episode_reward": 7.729969067588801, "episode": 72.0, "batch_reward": 0.015558530343696475, "critic_loss": 0.0035239204417448493, "actor_loss": -14.05396673744917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.63374137878418, "step": 72000}
{"episode_reward": 6.380904891392683, "episode": 73.0, "batch_reward": 0.015612491545267403, "critic_loss": 0.003700778177852044, "actor_loss": -13.831960993766785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.45587944984436, "step": 73000}
{"episode_reward": 8.496936459894329, "episode": 74.0, "batch_reward": 0.015393976652994752, "critic_loss": 0.0037805588757328225, "actor_loss": -14.189271132737398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.68851399421692, "step": 74000}
{"episode_reward": 8.272578658659116, "episode": 75.0, "batch_reward": 0.015658727656118573, "critic_loss": 0.004167330392956501, "actor_loss": -14.249612229377032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.537992238998413, "step": 75000}
{"episode_reward": 8.029110575812316, "episode": 76.0, "batch_reward": 0.015089999805670232, "critic_loss": 0.0037806455201498464, "actor_loss": -14.605831357389688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.51523780822754, "step": 76000}
{"episode_reward": 7.315584291133417, "episode": 77.0, "batch_reward": 0.014896965078543871, "critic_loss": 0.0027264525690843585, "actor_loss": -13.99233765888214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.111060857772827, "step": 77000}
{"episode_reward": 11.472288660591534, "episode": 78.0, "batch_reward": 0.015215550555847585, "critic_loss": 0.004106307927679154, "actor_loss": -13.961105094790458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.952232360839844, "step": 78000}
{"episode_reward": 7.2703262674011055, "episode": 79.0, "batch_reward": 0.014880998393055051, "critic_loss": 0.0030847907938587014, "actor_loss": -13.812990214020013, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.290629625320435, "step": 79000}
{"episode_reward": 8.169870996134856, "episode": 80.0, "batch_reward": 0.014988897413481026, "critic_loss": 0.0037393008598010057, "actor_loss": -14.151422421365977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.653438091278076, "step": 80000}
{"episode_reward": 7.807819561101117, "episode": 81.0, "batch_reward": 0.014892483317293226, "critic_loss": 0.0027117007635824846, "actor_loss": -13.769152963608503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.63945031166077, "step": 81000}
{"episode_reward": 7.208766982904125, "episode": 82.0, "batch_reward": 0.014635915397666394, "critic_loss": 0.0032236778224178126, "actor_loss": -13.37441265204549, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.83393669128418, "step": 82000}
{"episode_reward": 7.008551750421733, "episode": 83.0, "batch_reward": 0.014522425043862313, "critic_loss": 0.0037384250561299267, "actor_loss": -14.724960599839687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.045640468597412, "step": 83000}
{"episode_reward": 7.1927523411433905, "episode": 84.0, "batch_reward": 0.014203614644240588, "critic_loss": 0.0036876069220888896, "actor_loss": -14.888593416512013, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.321447134017944, "step": 84000}
{"episode_reward": 6.496106836010518, "episode": 85.0, "batch_reward": 0.014729898756369948, "critic_loss": 0.0038226389427145476, "actor_loss": -13.367585737049579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.06437921524048, "step": 85000}
{"episode_reward": 4.985995054053279, "episode": 86.0, "batch_reward": 0.01437228206731379, "critic_loss": 0.0030947968670807314, "actor_loss": -14.114221324056388, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.606304168701172, "step": 86000}
{"episode_reward": 9.504204922727386, "episode": 87.0, "batch_reward": 0.014629574820399284, "critic_loss": 0.00308666100690607, "actor_loss": -14.833509163290262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.048001527786255, "step": 87000}
{"episode_reward": 8.243483959299102, "episode": 88.0, "batch_reward": 0.01438909219391644, "critic_loss": 0.0029543133006955033, "actor_loss": -14.829382051438094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.09009575843811, "step": 88000}
{"episode_reward": 6.691062944019721, "episode": 89.0, "batch_reward": 0.01412909999070689, "critic_loss": 0.003249104779708432, "actor_loss": -13.663334695577621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.98767852783203, "step": 89000}
{"episode_reward": 11.79156885512522, "episode": 90.0, "batch_reward": 0.013990900543984025, "critic_loss": 0.0035761800845793912, "actor_loss": -13.921632510140538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.328869581222534, "step": 90000}
{"episode_reward": 8.943101414626728, "episode": 91.0, "batch_reward": 0.014095618060790002, "critic_loss": 0.002942388323834166, "actor_loss": -13.64039683547616, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.50238800048828, "step": 91000}
{"episode_reward": 10.216232982759418, "episode": 92.0, "batch_reward": 0.014083573522977531, "critic_loss": 0.002796674555953359, "actor_loss": -13.860784168690444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.69441533088684, "step": 92000}
{"episode_reward": 9.285002029306746, "episode": 93.0, "batch_reward": 0.014097385250963271, "critic_loss": 0.004359796000091592, "actor_loss": -13.954737602993847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.254678964614868, "step": 93000}
{"episode_reward": 9.731142149269333, "episode": 94.0, "batch_reward": 0.013762618836015462, "critic_loss": 0.0022272918583184946, "actor_loss": -13.954160862177611, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.222765684127808, "step": 94000}
{"episode_reward": 8.690499983360272, "episode": 95.0, "batch_reward": 0.013748960192315281, "critic_loss": 0.00417295089084655, "actor_loss": -14.33780752515793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.300296306610107, "step": 95000}
{"episode_reward": 9.839284830507452, "episode": 96.0, "batch_reward": 0.013827117024920881, "critic_loss": 0.002749804533435963, "actor_loss": -14.339642541378737, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.19255042076111, "step": 96000}
{"episode_reward": 6.362512091346924, "episode": 97.0, "batch_reward": 0.013649108970537782, "critic_loss": 0.0029544924175861523, "actor_loss": -14.110718796342612, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.517479419708252, "step": 97000}
{"episode_reward": 5.0454071931298605, "episode": 98.0, "batch_reward": 0.013541275196243078, "critic_loss": 0.0033289274454145926, "actor_loss": -13.334920342579483, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.357789039611816, "step": 98000}
{"episode_reward": 9.162818840187098, "episode": 99.0, "batch_reward": 0.01372464302368462, "critic_loss": 0.003399413436447503, "actor_loss": -14.874796110197902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.06844973564148, "step": 99000}
{"episode_reward": 7.427601924535486, "episode": 100.0, "batch_reward": 0.0134378632446751, "critic_loss": 0.0035212698233081027, "actor_loss": -14.434527161926031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.99908757209778, "step": 100000}
{"episode_reward": 8.48318975057316, "episode": 101.0, "batch_reward": 0.01338457149034366, "critic_loss": 0.0023458863651612772, "actor_loss": -14.423987109959125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.923933267593384, "step": 101000}
{"episode_reward": 9.463680265433165, "episode": 102.0, "batch_reward": 0.01327325347205624, "critic_loss": 0.00405345671629766, "actor_loss": -14.517857934355735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.179274082183838, "step": 102000}
{"episode_reward": 6.180297755571498, "episode": 103.0, "batch_reward": 0.013468411268200725, "critic_loss": 0.002576847681106301, "actor_loss": -14.212479687452316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.907740116119385, "step": 103000}
{"episode_reward": 6.0487873044465, "episode": 104.0, "batch_reward": 0.013590108324773609, "critic_loss": 0.003098773444799008, "actor_loss": -15.033200396135449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.28637719154358, "step": 104000}
{"episode_reward": 6.982166448373932, "episode": 105.0, "batch_reward": 0.013184043830726296, "critic_loss": 0.0033627949786314273, "actor_loss": -14.240247495219112, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.821640253067017, "step": 105000}
{"episode_reward": 7.744034640517447, "episode": 106.0, "batch_reward": 0.013319813240785152, "critic_loss": 0.003011597836099099, "actor_loss": -14.915382983297109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.271240949630737, "step": 106000}
{"episode_reward": 10.911019276014876, "episode": 107.0, "batch_reward": 0.01316798412008211, "critic_loss": 0.0026556555679417217, "actor_loss": -14.61450816206634, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.11284565925598, "step": 107000}
{"episode_reward": 10.183724119517759, "episode": 108.0, "batch_reward": 0.012914336453191936, "critic_loss": 0.002654276024812134, "actor_loss": -13.118124059438706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.06511354446411, "step": 108000}
{"episode_reward": 9.829953607207022, "episode": 109.0, "batch_reward": 0.013134943791665138, "critic_loss": 0.0034504263728740627, "actor_loss": -15.341230967909098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.60111713409424, "step": 109000}
{"episode_reward": 8.295169085842451, "episode": 110.0, "batch_reward": 0.012913164727855473, "critic_loss": 0.0031606689824257047, "actor_loss": -15.325550911411643, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.46682357788086, "step": 110000}
{"episode_reward": 10.217697827071573, "episode": 111.0, "batch_reward": 0.01302575411228463, "critic_loss": 0.002172680873074569, "actor_loss": -13.40297521544993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.60293745994568, "step": 111000}
{"episode_reward": 7.491469105737339, "episode": 112.0, "batch_reward": 0.013143800858873874, "critic_loss": 0.003227109288884094, "actor_loss": -15.707677943065763, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.722200870513916, "step": 112000}
{"episode_reward": 7.855147328172014, "episode": 113.0, "batch_reward": 0.012999239626340569, "critic_loss": 0.0035886242376582233, "actor_loss": -14.503021250963211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.889352560043335, "step": 113000}
{"episode_reward": 7.508317957291304, "episode": 114.0, "batch_reward": 0.013057144068181514, "critic_loss": 0.002716361073195003, "actor_loss": -14.665087728187443, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.85268521308899, "step": 114000}
{"episode_reward": 7.426813212091537, "episode": 115.0, "batch_reward": 0.012611258407123387, "critic_loss": 0.0031431407966883854, "actor_loss": -14.591159953773023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.334033727645874, "step": 115000}
{"episode_reward": 9.764629521292386, "episode": 116.0, "batch_reward": 0.012741666139103472, "critic_loss": 0.0034248501625552307, "actor_loss": -14.697108179941774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.025213718414307, "step": 116000}
{"episode_reward": 10.770075010885904, "episode": 117.0, "batch_reward": 0.013166283542755992, "critic_loss": 0.002191572482333868, "actor_loss": -12.685408355802297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108901262283325, "step": 117000}
{"episode_reward": 7.390392166578284, "episode": 118.0, "batch_reward": 0.012673820746596903, "critic_loss": 0.002538000827174983, "actor_loss": -13.761883592069148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.008524656295776, "step": 118000}
{"episode_reward": 8.871339913814117, "episode": 119.0, "batch_reward": 0.012677420843392611, "critic_loss": 0.002846498552200501, "actor_loss": -14.25428915926814, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.96140742301941, "step": 119000}
{"episode_reward": 7.2925546518167605, "episode": 120.0, "batch_reward": 0.01267315325839445, "critic_loss": 0.0025965493796393274, "actor_loss": -13.31922120821476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.367228507995605, "step": 120000}
{"episode_reward": 10.3156812111789, "episode": 121.0, "batch_reward": 0.012672709526028484, "critic_loss": 0.0022633706064661965, "actor_loss": -13.334946379780769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.15208053588867, "step": 121000}
{"episode_reward": 6.135593988081927, "episode": 122.0, "batch_reward": 0.012744459514506161, "critic_loss": 0.0037064149965153775, "actor_loss": -13.827747474506497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.485108613967896, "step": 122000}
{"episode_reward": 7.9861447871632505, "episode": 123.0, "batch_reward": 0.012343289095908403, "critic_loss": 0.0018943982909695478, "actor_loss": -14.357238671481609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90140151977539, "step": 123000}
{"episode_reward": 8.212998747569833, "episode": 124.0, "batch_reward": 0.01253929058695212, "critic_loss": 0.002257587728308863, "actor_loss": -14.29640359532833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.507726192474365, "step": 124000}
{"episode_reward": 10.593786058772709, "episode": 125.0, "batch_reward": 0.01258926935121417, "critic_loss": 0.002897245743937674, "actor_loss": -14.30312876215577, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.218456506729126, "step": 125000}
{"episode_reward": 8.574229230278654, "episode": 126.0, "batch_reward": 0.012595338885206728, "critic_loss": 0.0024673965903784846, "actor_loss": -13.598068577796221, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.012948036193848, "step": 126000}
{"episode_reward": 8.073290364731854, "episode": 127.0, "batch_reward": 0.01242087529040873, "critic_loss": 0.0018577018631767714, "actor_loss": -14.896110293626785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.159396648406982, "step": 127000}
{"episode_reward": 7.411251103789497, "episode": 128.0, "batch_reward": 0.01202326743490994, "critic_loss": 0.0022534649959416128, "actor_loss": -14.11865736657381, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97237253189087, "step": 128000}
{"episode_reward": 10.847059919665876, "episode": 129.0, "batch_reward": 0.012623234392143787, "critic_loss": 0.0026266432233242086, "actor_loss": -13.532121260866523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.575388193130493, "step": 129000}
{"episode_reward": 6.08449686530827, "episode": 130.0, "batch_reward": 0.012130324974656105, "critic_loss": 0.00183926950886962, "actor_loss": -13.508510835662484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.49420404434204, "step": 130000}
{"episode_reward": 10.373384022464709, "episode": 131.0, "batch_reward": 0.0123002750845626, "critic_loss": 0.0021293557620228965, "actor_loss": -14.421739176943898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.77049374580383, "step": 131000}
{"episode_reward": 8.360590570989443, "episode": 132.0, "batch_reward": 0.01228506869217381, "critic_loss": 0.0023446624648640864, "actor_loss": -14.617364725917577, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.377665281295776, "step": 132000}
{"episode_reward": 6.563056197446195, "episode": 133.0, "batch_reward": 0.012087141164112835, "critic_loss": 0.0023963567686732857, "actor_loss": -13.449996905446053, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.345383882522583, "step": 133000}
{"episode_reward": 7.380478336617393, "episode": 134.0, "batch_reward": 0.01234741433756426, "critic_loss": 0.001738806654830114, "actor_loss": -12.871444755122065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.443257808685303, "step": 134000}
{"episode_reward": 8.93646773766219, "episode": 135.0, "batch_reward": 0.012176873940974473, "critic_loss": 0.0023056265309569428, "actor_loss": -14.825125818803906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.1090190410614, "step": 135000}
{"episode_reward": 10.648556847464588, "episode": 136.0, "batch_reward": 0.01210466180788353, "critic_loss": 0.0016098440907080659, "actor_loss": -11.744190706461668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.182090044021606, "step": 136000}
{"episode_reward": 8.532095150025121, "episode": 137.0, "batch_reward": 0.012106931791175156, "critic_loss": 0.0024581472434510943, "actor_loss": -14.057912151858211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097610235214233, "step": 137000}
{"episode_reward": 7.124560111742188, "episode": 138.0, "batch_reward": 0.012101609881035983, "critic_loss": 0.0022457838945119874, "actor_loss": -13.889631024047732, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.279109477996826, "step": 138000}
{"episode_reward": 8.225802663400152, "episode": 139.0, "batch_reward": 0.012001532778143883, "critic_loss": 0.0022965605744102503, "actor_loss": -13.888939908966423, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.674285411834717, "step": 139000}
{"episode_reward": 7.21924873814938, "episode": 140.0, "batch_reward": 0.011974421427119523, "critic_loss": 0.0021947394055023325, "actor_loss": -14.112086748957633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.112043142318726, "step": 140000}
{"episode_reward": 8.137667266309338, "episode": 141.0, "batch_reward": 0.012211513351183385, "critic_loss": 0.002250300134488498, "actor_loss": -14.337089214503765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.06627607345581, "step": 141000}
{"episode_reward": 9.300726694315108, "episode": 142.0, "batch_reward": 0.012042693221010268, "critic_loss": 0.0020784160974435507, "actor_loss": -12.794192403122782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.416841745376587, "step": 142000}
{"episode_reward": 7.20536548409746, "episode": 143.0, "batch_reward": 0.012200943259056657, "critic_loss": 0.002164269340370083, "actor_loss": -12.638498114079237, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.031314849853516, "step": 143000}
{"episode_reward": 10.446832332873754, "episode": 144.0, "batch_reward": 0.011772991811390967, "critic_loss": 0.002536004224253702, "actor_loss": -14.5498458057791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.58240056037903, "step": 144000}
{"episode_reward": 11.728162127040301, "episode": 145.0, "batch_reward": 0.011872174884192645, "critic_loss": 0.0020376753023592757, "actor_loss": -14.210049027010799, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.205694675445557, "step": 145000}
{"episode_reward": 11.970965939415166, "episode": 146.0, "batch_reward": 0.012014300370588898, "critic_loss": 0.0016875863024033606, "actor_loss": -14.277523586958647, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.13640809059143, "step": 146000}
{"episode_reward": 7.083708350989681, "episode": 147.0, "batch_reward": 0.011842828754801303, "critic_loss": 0.0029482857531838817, "actor_loss": -14.330252873554826, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.589354991912842, "step": 147000}
{"episode_reward": 9.988054337741543, "episode": 148.0, "batch_reward": 0.011930333873257041, "critic_loss": 0.0020282709678867833, "actor_loss": -13.884945593997836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.505308866500854, "step": 148000}
{"episode_reward": 7.654654850098393, "episode": 149.0, "batch_reward": 0.011891831800807268, "critic_loss": 0.001904433769363095, "actor_loss": -13.98738810838759, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.259618997573853, "step": 149000}
{"episode_reward": 7.430729134444327, "episode": 150.0, "batch_reward": 0.012268827018793673, "critic_loss": 0.002260085385336424, "actor_loss": -14.389680615350604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
