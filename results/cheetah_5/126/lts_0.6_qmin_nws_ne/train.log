{"episode_reward": 0.0, "episode": 1.0, "duration": 19.435064554214478, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.530646800994873, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.24820807890698846, "critic_loss": 0.01742481426731039, "actor_loss": -28.03714975897892, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 68.99373245239258, "step": 3000}
{"episode_reward": 5.9775834584625605, "episode": 4.0, "batch_reward": 0.155425801679492, "critic_loss": 0.012439223233843222, "actor_loss": -24.325618773460388, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.322210788726807, "step": 4000}
{"episode_reward": 7.457016176637782, "episode": 5.0, "batch_reward": 0.12301313235983252, "critic_loss": 0.011871533467900009, "actor_loss": -23.572633374214174, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.676129817962646, "step": 5000}
{"episode_reward": 11.178034737148531, "episode": 6.0, "batch_reward": 0.10228038350492716, "critic_loss": 0.013281888002064078, "actor_loss": -21.812297220230104, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.321296453475952, "step": 6000}
{"episode_reward": 9.323491113439559, "episode": 7.0, "batch_reward": 0.08804487747326493, "critic_loss": 0.01215184838976711, "actor_loss": -21.156264795303343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.517317533493042, "step": 7000}
{"episode_reward": 7.170051940853325, "episode": 8.0, "batch_reward": 0.07695523962937295, "critic_loss": 0.012417605191236362, "actor_loss": -21.87382874107361, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.12518811225891, "step": 8000}
{"episode_reward": 8.429162190852901, "episode": 9.0, "batch_reward": 0.06833274912834167, "critic_loss": 0.009324051861651242, "actor_loss": -20.493926728248596, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.385785579681396, "step": 9000}
{"episode_reward": 10.029624415498901, "episode": 10.0, "batch_reward": 0.06268345462530851, "critic_loss": 0.01262964250938967, "actor_loss": -20.82129697227478, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.67322325706482, "step": 10000}
{"episode_reward": 7.2339140708656435, "episode": 11.0, "batch_reward": 0.05700861199013889, "critic_loss": 0.01027950217272155, "actor_loss": -20.119898151397706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.79339003562927, "step": 11000}
{"episode_reward": 7.531856585524175, "episode": 12.0, "batch_reward": 0.05362020912393928, "critic_loss": 0.012255652114283293, "actor_loss": -20.339219407081604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.348471879959106, "step": 12000}
{"episode_reward": 9.509122594270126, "episode": 13.0, "batch_reward": 0.049706575375050306, "critic_loss": 0.010917995240539312, "actor_loss": -19.524643152713775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.693222284317017, "step": 13000}
{"episode_reward": 8.066403735058897, "episode": 14.0, "batch_reward": 0.04577691012434661, "critic_loss": 0.008011416621739044, "actor_loss": -19.836072006225585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.62977623939514, "step": 14000}
{"episode_reward": 7.752668771527953, "episode": 15.0, "batch_reward": 0.043860285080969334, "critic_loss": 0.010880648791790008, "actor_loss": -18.311616501808167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.816927671432495, "step": 15000}
{"episode_reward": 7.96467471620774, "episode": 16.0, "batch_reward": 0.040853967607021334, "critic_loss": 0.010915770763414911, "actor_loss": -20.171005374908447, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.066604614257812, "step": 16000}
{"episode_reward": 9.011635275866153, "episode": 17.0, "batch_reward": 0.03934189414558932, "critic_loss": 0.010121972516877577, "actor_loss": -19.648690352439882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.211754322052002, "step": 17000}
{"episode_reward": 10.297699551674134, "episode": 18.0, "batch_reward": 0.037389073847793046, "critic_loss": 0.0062057674097595735, "actor_loss": -19.63349062395096, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.49088740348816, "step": 18000}
{"episode_reward": 7.610319842399724, "episode": 19.0, "batch_reward": 0.036621284746564925, "critic_loss": 0.01040439088724088, "actor_loss": -20.002522983551025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03251624107361, "step": 19000}
{"episode_reward": 13.28553998013573, "episode": 20.0, "batch_reward": 0.035270215082913635, "critic_loss": 0.007062574553885497, "actor_loss": -17.851543831825257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.118633031845093, "step": 20000}
{"episode_reward": 8.228257762139764, "episode": 21.0, "batch_reward": 0.033100029298570005, "critic_loss": 0.01097152162308339, "actor_loss": -19.026296805381776, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.390740633010864, "step": 21000}
{"episode_reward": 10.406124998284833, "episode": 22.0, "batch_reward": 0.032299832288175824, "critic_loss": 0.006686361748492345, "actor_loss": -18.086144197225572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.026947736740112, "step": 22000}
{"episode_reward": 11.002950938019621, "episode": 23.0, "batch_reward": 0.031353646952658895, "critic_loss": 0.007756658659025561, "actor_loss": -18.40017596077919, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.549145936965942, "step": 23000}
{"episode_reward": 6.549979083915225, "episode": 24.0, "batch_reward": 0.03061590672750026, "critic_loss": 0.006921801783610135, "actor_loss": -18.387999421834945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.828665733337402, "step": 24000}
{"episode_reward": 7.409283484612525, "episode": 25.0, "batch_reward": 0.029622472702525555, "critic_loss": 0.008597652251424734, "actor_loss": -18.20341595172882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.591020107269287, "step": 25000}
{"episode_reward": 8.329841396232432, "episode": 26.0, "batch_reward": 0.029171276808716357, "critic_loss": 0.007700561314530205, "actor_loss": -18.783682919740677, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.365782737731934, "step": 26000}
{"episode_reward": 10.771137896557587, "episode": 27.0, "batch_reward": 0.028468957122415303, "critic_loss": 0.006573050090693869, "actor_loss": -17.853112071752548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.879327535629272, "step": 27000}
{"episode_reward": 9.086076213741157, "episode": 28.0, "batch_reward": 0.026788689678069202, "critic_loss": 0.007506353047851007, "actor_loss": -18.0858922085762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.754992961883545, "step": 28000}
{"episode_reward": 8.969841358938197, "episode": 29.0, "batch_reward": 0.02633053459133953, "critic_loss": 0.005910926807089709, "actor_loss": -17.309864250659942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.678404808044434, "step": 29000}
{"episode_reward": 12.020845468220092, "episode": 30.0, "batch_reward": 0.026597271921113132, "critic_loss": 0.010101822016877123, "actor_loss": -16.89673471069336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.306163787841797, "step": 30000}
{"episode_reward": 8.243620522937597, "episode": 31.0, "batch_reward": 0.02547666765190661, "critic_loss": 0.006213684120622929, "actor_loss": -17.565194287776947, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.473549127578735, "step": 31000}
{"episode_reward": 4.874417476663439, "episode": 32.0, "batch_reward": 0.02484515483863652, "critic_loss": 0.0061934493314474825, "actor_loss": -17.460362778663637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.637253999710083, "step": 32000}
{"episode_reward": 5.142373683201671, "episode": 33.0, "batch_reward": 0.024814499703701587, "critic_loss": 0.00993696603924036, "actor_loss": -17.139528440237044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.110779523849487, "step": 33000}
{"episode_reward": 9.193744580660926, "episode": 34.0, "batch_reward": 0.02379687103908509, "critic_loss": 0.00650996600597864, "actor_loss": -17.85163159918785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.464520692825317, "step": 34000}
{"episode_reward": 9.263460894218342, "episode": 35.0, "batch_reward": 0.023339634247589856, "critic_loss": 0.008424749993777368, "actor_loss": -17.10726575064659, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.937236070632935, "step": 35000}
{"episode_reward": 6.359130433180004, "episode": 36.0, "batch_reward": 0.022998519930057228, "critic_loss": 0.0071663129900116475, "actor_loss": -18.532634619832038, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.126904249191284, "step": 36000}
{"episode_reward": 8.48706785884271, "episode": 37.0, "batch_reward": 0.022478116451296954, "critic_loss": 0.0068828215500107036, "actor_loss": -17.465316421985627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.41755223274231, "step": 37000}
{"episode_reward": 5.997169241907551, "episode": 38.0, "batch_reward": 0.02220098354574293, "critic_loss": 0.007576928021764615, "actor_loss": -16.33890355360508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.883899688720703, "step": 38000}
{"episode_reward": 6.153429011819919, "episode": 39.0, "batch_reward": 0.022091326881665735, "critic_loss": 0.006076291841978673, "actor_loss": -17.547563424229622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.902971029281616, "step": 39000}
{"episode_reward": 6.897967222142852, "episode": 40.0, "batch_reward": 0.021088469676673414, "critic_loss": 0.005538455219299067, "actor_loss": -18.062820828676223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.411968231201172, "step": 40000}
{"episode_reward": 6.493853197309152, "episode": 41.0, "batch_reward": 0.021052355408202855, "critic_loss": 0.008419010831392371, "actor_loss": -18.26638266134262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.086254358291626, "step": 41000}
{"episode_reward": 7.466244208853509, "episode": 42.0, "batch_reward": 0.020523197540082038, "critic_loss": 0.006694861306983512, "actor_loss": -17.059912806510926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.337737560272217, "step": 42000}
{"episode_reward": 5.938595845798575, "episode": 43.0, "batch_reward": 0.02011836832109839, "critic_loss": 0.008570313086092938, "actor_loss": -18.053992168664934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.55217146873474, "step": 43000}
{"episode_reward": 6.960514494047376, "episode": 44.0, "batch_reward": 0.019755029228515922, "critic_loss": 0.006552262260287534, "actor_loss": -16.73750160717964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.119960069656372, "step": 44000}
{"episode_reward": 7.230377796066425, "episode": 45.0, "batch_reward": 0.01958437992678955, "critic_loss": 0.008178297955833842, "actor_loss": -16.282747026801108, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.953876495361328, "step": 45000}
{"episode_reward": 5.764936652450371, "episode": 46.0, "batch_reward": 0.01949948282074183, "critic_loss": 0.008435491992626339, "actor_loss": -17.62654255461693, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.189921140670776, "step": 46000}
{"episode_reward": 8.945897910823463, "episode": 47.0, "batch_reward": 0.019186930479016154, "critic_loss": 0.009055891108815559, "actor_loss": -17.774402276158334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.482017278671265, "step": 47000}
{"episode_reward": 6.146293990563331, "episode": 48.0, "batch_reward": 0.01878231703210622, "critic_loss": 0.0066280042152502576, "actor_loss": -17.946623972296713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.98647713661194, "step": 48000}
{"episode_reward": 6.186755371841832, "episode": 49.0, "batch_reward": 0.019068329417146743, "critic_loss": 0.006774718623899389, "actor_loss": -17.903744187176226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.848106861114502, "step": 49000}
{"episode_reward": 7.036752956437163, "episode": 50.0, "batch_reward": 0.018675804054830224, "critic_loss": 0.007609281923505478, "actor_loss": -17.102846342623234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.141258478164673, "step": 50000}
{"episode_reward": 10.236240370238383, "episode": 51.0, "batch_reward": 0.018280676007736474, "critic_loss": 0.006576115812436911, "actor_loss": -16.570715231955052, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.887657165527344, "step": 51000}
{"episode_reward": 9.461131194700283, "episode": 52.0, "batch_reward": 0.018296288650017232, "critic_loss": 0.007884241501393262, "actor_loss": -17.756405722737313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.77175784111023, "step": 52000}
{"episode_reward": 8.733173923885632, "episode": 53.0, "batch_reward": 0.018075603317003697, "critic_loss": 0.00782767428155057, "actor_loss": -15.566960134267807, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.727919816970825, "step": 53000}
{"episode_reward": 6.318167964964261, "episode": 54.0, "batch_reward": 0.01815377972042188, "critic_loss": 0.00541132251865929, "actor_loss": -18.04418500459194, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.48056149482727, "step": 54000}
{"episode_reward": 7.124455552855658, "episode": 55.0, "batch_reward": 0.017463589700870218, "critic_loss": 0.00611687153019011, "actor_loss": -17.467235084474087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.08756995201111, "step": 55000}
{"episode_reward": 6.231617256312796, "episode": 56.0, "batch_reward": 0.017148643584456294, "critic_loss": 0.010767347549641272, "actor_loss": -16.242243009924888, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.131645679473877, "step": 56000}
{"episode_reward": 6.79233250104399, "episode": 57.0, "batch_reward": 0.01726939548458904, "critic_loss": 0.006926898416859331, "actor_loss": -16.875231447815896, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.704006910324097, "step": 57000}
{"episode_reward": 6.296180102294678, "episode": 58.0, "batch_reward": 0.01699937822856009, "critic_loss": 0.009041401180787943, "actor_loss": -17.10721328830719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.33623480796814, "step": 58000}
{"episode_reward": 9.204819550145148, "episode": 59.0, "batch_reward": 0.01666808971716091, "critic_loss": 0.00632102285505971, "actor_loss": -16.904119358479978, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.690593004226685, "step": 59000}
{"episode_reward": 11.278816387712194, "episode": 60.0, "batch_reward": 0.016793072411324828, "critic_loss": 0.009576896930055227, "actor_loss": -17.12973226004839, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.965785264968872, "step": 60000}
{"episode_reward": 13.358720795789022, "episode": 61.0, "batch_reward": 0.016501623326446863, "critic_loss": 0.008724299192923354, "actor_loss": -17.60459663963318, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.819315671920776, "step": 61000}
{"episode_reward": 8.04248454145799, "episode": 62.0, "batch_reward": 0.01616804578062147, "critic_loss": 0.007021932288975222, "actor_loss": -16.056606553554534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.193105459213257, "step": 62000}
{"episode_reward": 9.33466326676267, "episode": 63.0, "batch_reward": 0.01625050750700757, "critic_loss": 0.011102643230347894, "actor_loss": -15.8740032107234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.42165517807007, "step": 63000}
{"episode_reward": 8.700573903137416, "episode": 64.0, "batch_reward": 0.016115691506303848, "critic_loss": 0.005210280864936067, "actor_loss": -16.708033876478673, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.28626799583435, "step": 64000}
{"episode_reward": 9.971742807733815, "episode": 65.0, "batch_reward": 0.01621923886379227, "critic_loss": 0.010851008531550178, "actor_loss": -15.97445396119356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.803988456726074, "step": 65000}
{"episode_reward": 6.234670034779971, "episode": 66.0, "batch_reward": 0.015784560514148324, "critic_loss": 0.005886338149284711, "actor_loss": -16.565931713581087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.485069274902344, "step": 66000}
{"episode_reward": 7.71285091658813, "episode": 67.0, "batch_reward": 0.015734890854917468, "critic_loss": 0.009200584635837004, "actor_loss": -15.933356786489487, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.916004419326782, "step": 67000}
{"episode_reward": 6.047795995153397, "episode": 68.0, "batch_reward": 0.015845796858426183, "critic_loss": 0.007829844988707918, "actor_loss": -16.90636910197139, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.749326944351196, "step": 68000}
{"episode_reward": 5.424753943156745, "episode": 69.0, "batch_reward": 0.0157535455818288, "critic_loss": 0.007045664442499401, "actor_loss": -16.661537666112185, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.442517042160034, "step": 69000}
{"episode_reward": 10.49830222230046, "episode": 70.0, "batch_reward": 0.015378999717067927, "critic_loss": 0.007015307204186683, "actor_loss": -17.705046420037746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.55955457687378, "step": 70000}
{"episode_reward": 7.109960649135626, "episode": 71.0, "batch_reward": 0.01534687752975151, "critic_loss": 0.006675218868156662, "actor_loss": -15.85439603242278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.50264883041382, "step": 71000}
{"episode_reward": 5.870228332389708, "episode": 72.0, "batch_reward": 0.015172460442408919, "critic_loss": 0.008761901803867659, "actor_loss": -17.03501313573122, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.796223878860474, "step": 72000}
{"episode_reward": 5.785584446047295, "episode": 73.0, "batch_reward": 0.01520908121438697, "critic_loss": 0.0060491581991955175, "actor_loss": -16.655941138893365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.52906608581543, "step": 73000}
{"episode_reward": 7.923049541949465, "episode": 74.0, "batch_reward": 0.014969953746069223, "critic_loss": 0.007533230164466658, "actor_loss": -16.674005567491054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.483843326568604, "step": 74000}
{"episode_reward": 5.924832488692254, "episode": 75.0, "batch_reward": 0.015210790469776839, "critic_loss": 0.007946028177102563, "actor_loss": -16.897155533492565, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.1758873462677, "step": 75000}
{"episode_reward": 7.729222548338379, "episode": 76.0, "batch_reward": 0.014648357763886451, "critic_loss": 0.005916874226299115, "actor_loss": -17.122002957880497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.396361112594604, "step": 76000}
{"episode_reward": 5.474425887706932, "episode": 77.0, "batch_reward": 0.014418446646537632, "critic_loss": 0.00944575534175965, "actor_loss": -16.939339836269617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.05102849006653, "step": 77000}
{"episode_reward": 9.750950731854926, "episode": 78.0, "batch_reward": 0.014782679335214198, "critic_loss": 0.010494098241702885, "actor_loss": -16.368747951328753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.75136423110962, "step": 78000}
{"episode_reward": 7.686338613295806, "episode": 79.0, "batch_reward": 0.014415032272227108, "critic_loss": 0.006439867621666053, "actor_loss": -16.65136991584301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.970313787460327, "step": 79000}
{"episode_reward": 6.3870641572522535, "episode": 80.0, "batch_reward": 0.014516523108817637, "critic_loss": 0.008990988279634621, "actor_loss": -16.71281420174241, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.516079664230347, "step": 80000}
{"episode_reward": 6.9671326143782215, "episode": 81.0, "batch_reward": 0.0144226566539146, "critic_loss": 0.006960922651021974, "actor_loss": -16.335116596221923, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.06417536735535, "step": 81000}
{"episode_reward": 6.313075414444637, "episode": 82.0, "batch_reward": 0.014175914934836328, "critic_loss": 0.007521163630735827, "actor_loss": -16.376506303578616, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.396255016326904, "step": 82000}
{"episode_reward": 6.429514450552735, "episode": 83.0, "batch_reward": 0.014053051488939672, "critic_loss": 0.007989891814038856, "actor_loss": -17.426522594988345, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077173233032227, "step": 83000}
{"episode_reward": 8.154210367353057, "episode": 84.0, "batch_reward": 0.013728116359561681, "critic_loss": 0.006505292682501022, "actor_loss": -17.96994850420952, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.377151250839233, "step": 84000}
{"episode_reward": 6.604062527907228, "episode": 85.0, "batch_reward": 0.014277860310394318, "critic_loss": 0.010088371025689411, "actor_loss": -16.64055617287755, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.59589910507202, "step": 85000}
{"episode_reward": 4.298193313758309, "episode": 86.0, "batch_reward": 0.013926524726673961, "critic_loss": 0.007686823005467886, "actor_loss": -16.559578197062017, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.053332328796387, "step": 86000}
{"episode_reward": 9.084577202059505, "episode": 87.0, "batch_reward": 0.014195794798899443, "critic_loss": 0.008589184082869907, "actor_loss": -17.055390053495763, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.12014627456665, "step": 87000}
{"episode_reward": 7.913249995908397, "episode": 88.0, "batch_reward": 0.013925037987995893, "critic_loss": 0.007402218166680541, "actor_loss": -17.644518741071224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.143800497055054, "step": 88000}
{"episode_reward": 5.329003718302413, "episode": 89.0, "batch_reward": 0.013646913293283432, "critic_loss": 0.005729073432506993, "actor_loss": -16.436011823922396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.287678003311157, "step": 89000}
{"episode_reward": 9.211418503574667, "episode": 90.0, "batch_reward": 0.01350311951385811, "critic_loss": 0.008107604783202988, "actor_loss": -17.1853502047956, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.013736248016357, "step": 90000}
{"episode_reward": 8.606046425425225, "episode": 91.0, "batch_reward": 0.013558769402559847, "critic_loss": 0.01041101237674593, "actor_loss": -16.791132963091137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.03956127166748, "step": 91000}
{"episode_reward": 7.09078559699641, "episode": 92.0, "batch_reward": 0.013584990730509162, "critic_loss": 0.008587533098994755, "actor_loss": -16.415093572705985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.58094811439514, "step": 92000}
{"episode_reward": 8.823113332223082, "episode": 93.0, "batch_reward": 0.013567100974265486, "critic_loss": 0.0066194894147629385, "actor_loss": -16.449240267276764, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.517502307891846, "step": 93000}
{"episode_reward": 10.676539992887859, "episode": 94.0, "batch_reward": 0.01322295670537278, "critic_loss": 0.007443737044814043, "actor_loss": -16.97451832523942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.7488694190979, "step": 94000}
{"episode_reward": 6.92754443768349, "episode": 95.0, "batch_reward": 0.013263863709755241, "critic_loss": 0.009310243678453844, "actor_loss": -17.187836377620698, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.19206666946411, "step": 95000}
{"episode_reward": 6.959698388723251, "episode": 96.0, "batch_reward": 0.013242313301190734, "critic_loss": 0.006267824251583079, "actor_loss": -16.86505691741407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.99042296409607, "step": 96000}
{"episode_reward": 6.1952327511859195, "episode": 97.0, "batch_reward": 0.0131193378707394, "critic_loss": 0.007080563170951791, "actor_loss": -17.234108671858905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.67359685897827, "step": 97000}
{"episode_reward": 4.172265289372742, "episode": 98.0, "batch_reward": 0.013014215915463865, "critic_loss": 0.008207041701127309, "actor_loss": -16.360390558123587, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.449354648590088, "step": 98000}
{"episode_reward": 6.240615144635425, "episode": 99.0, "batch_reward": 0.013162709626834839, "critic_loss": 0.006083444434276317, "actor_loss": -17.16762154853344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.42619752883911, "step": 99000}
{"episode_reward": 5.228975316999259, "episode": 100.0, "batch_reward": 0.012869622870814055, "critic_loss": 0.007024354647321161, "actor_loss": -16.83469367174804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.084741830825806, "step": 100000}
{"episode_reward": 7.630426270887996, "episode": 101.0, "batch_reward": 0.012840454418212176, "critic_loss": 0.005214365367835853, "actor_loss": -17.401275529369713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.807321071624756, "step": 101000}
{"episode_reward": 8.115376091517309, "episode": 102.0, "batch_reward": 0.012696483531035483, "critic_loss": 0.00862278764336952, "actor_loss": -17.334157335713506, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.758111238479614, "step": 102000}
{"episode_reward": 6.564701407453917, "episode": 103.0, "batch_reward": 0.01290139318164438, "critic_loss": 0.0065458526075526605, "actor_loss": -16.762082230448723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.082666158676147, "step": 103000}
{"episode_reward": 5.178873105435431, "episode": 104.0, "batch_reward": 0.013001002798322588, "critic_loss": 0.007748807302938076, "actor_loss": -17.463172017797827, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.43467926979065, "step": 104000}
{"episode_reward": 9.125974503449457, "episode": 105.0, "batch_reward": 0.01262758308602497, "critic_loss": 0.006032236431346974, "actor_loss": -16.564437754258513, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.33522605895996, "step": 105000}
{"episode_reward": 7.127934736381873, "episode": 106.0, "batch_reward": 0.01275089449621737, "critic_loss": 0.006122309324593516, "actor_loss": -17.396653337702155, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.218446254730225, "step": 106000}
{"episode_reward": 10.820979603100366, "episode": 107.0, "batch_reward": 0.012630491864867508, "critic_loss": 0.0063820625254011245, "actor_loss": -16.941958263874053, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.569045543670654, "step": 107000}
{"episode_reward": 10.924581538871314, "episode": 108.0, "batch_reward": 0.012384387337602675, "critic_loss": 0.00585573659875081, "actor_loss": -16.118294958263636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.060259103775024, "step": 108000}
{"episode_reward": 9.526481522139157, "episode": 109.0, "batch_reward": 0.012582948720548302, "critic_loss": 0.008299571261275559, "actor_loss": -17.500984923660756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.65894317626953, "step": 109000}
{"episode_reward": 6.731190826339879, "episode": 110.0, "batch_reward": 0.01239351480687037, "critic_loss": 0.007520831134665059, "actor_loss": -17.63924284505844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.26475191116333, "step": 110000}
{"episode_reward": 9.247404043484021, "episode": 111.0, "batch_reward": 0.01247158961649984, "critic_loss": 0.007120483905309811, "actor_loss": -16.079476768374445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.01022911071777, "step": 111000}
{"episode_reward": 6.245464127947766, "episode": 112.0, "batch_reward": 0.012548267488367855, "critic_loss": 0.006284710535837803, "actor_loss": -17.750256680041552, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.70542049407959, "step": 112000}
{"episode_reward": 5.586729094980494, "episode": 113.0, "batch_reward": 0.01244861560408026, "critic_loss": 0.006668503696215339, "actor_loss": -16.89011492924392, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.9404776096344, "step": 113000}
{"episode_reward": 6.313794438568061, "episode": 114.0, "batch_reward": 0.012459257829934359, "critic_loss": 0.006836474460316822, "actor_loss": -17.636751244992016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.9228618144989, "step": 114000}
{"episode_reward": 6.957386628787119, "episode": 115.0, "batch_reward": 0.012075904172845184, "critic_loss": 0.005982443225831958, "actor_loss": -16.972992178916932, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.532500743865967, "step": 115000}
{"episode_reward": 9.441284634868381, "episode": 116.0, "batch_reward": 0.012122553794644773, "critic_loss": 0.007719599828938954, "actor_loss": -17.39679588392377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.389442205429077, "step": 116000}
{"episode_reward": 10.214083341271564, "episode": 117.0, "batch_reward": 0.012599344199057668, "critic_loss": 0.006183846629632171, "actor_loss": -16.082718574255704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.71434760093689, "step": 117000}
{"episode_reward": 8.858522713724685, "episode": 118.0, "batch_reward": 0.012119696813169867, "critic_loss": 0.008675268300808966, "actor_loss": -16.811314004704357, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.516380548477173, "step": 118000}
{"episode_reward": 7.495849057320583, "episode": 119.0, "batch_reward": 0.012115600171498955, "critic_loss": 0.006408060373243643, "actor_loss": -17.01527955301106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.859054803848267, "step": 119000}
{"episode_reward": 8.387873472719507, "episode": 120.0, "batch_reward": 0.0121193649857305, "critic_loss": 0.005389583112992114, "actor_loss": -16.43164931026101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.974196434020996, "step": 120000}
{"episode_reward": 10.566892164507063, "episode": 121.0, "batch_reward": 0.01211894783191383, "critic_loss": 0.006558785648987396, "actor_loss": -16.273854179516434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.450037240982056, "step": 121000}
{"episode_reward": 5.839331221310276, "episode": 122.0, "batch_reward": 0.012210367451421917, "critic_loss": 0.007378266631189036, "actor_loss": -16.21760725173354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.80758833885193, "step": 122000}
{"episode_reward": 9.108184564889587, "episode": 123.0, "batch_reward": 0.011823474952485412, "critic_loss": 0.006472942204010906, "actor_loss": -17.60288246501982, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.984848976135254, "step": 123000}
{"episode_reward": 8.347641754099548, "episode": 124.0, "batch_reward": 0.012001771890092642, "critic_loss": 0.005505235327495029, "actor_loss": -16.74296130633354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07574987411499, "step": 124000}
{"episode_reward": 8.784109537868783, "episode": 125.0, "batch_reward": 0.01205437732161954, "critic_loss": 0.007727545564761385, "actor_loss": -16.950399114668368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.963664293289185, "step": 125000}
{"episode_reward": 8.24481964445928, "episode": 126.0, "batch_reward": 0.012124801247846335, "critic_loss": 0.008040933387499536, "actor_loss": -16.113129342451693, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.89785146713257, "step": 126000}
{"episode_reward": 8.714740390707814, "episode": 127.0, "batch_reward": 0.011899813073221594, "critic_loss": 0.004635364219953772, "actor_loss": -16.787797562539577, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.5433566570282, "step": 127000}
{"episode_reward": 8.595047144450207, "episode": 128.0, "batch_reward": 0.011545920277014374, "critic_loss": 0.006048284858319676, "actor_loss": -16.724855873793363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077687978744507, "step": 128000}
{"episode_reward": 13.660839158477224, "episode": 129.0, "batch_reward": 0.012152157357893885, "critic_loss": 0.005664253526978427, "actor_loss": -16.04691831086576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.370722770690918, "step": 129000}
{"episode_reward": 6.495803672544045, "episode": 130.0, "batch_reward": 0.011627347697969526, "critic_loss": 0.005017340519931167, "actor_loss": -16.226151274099944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.696337938308716, "step": 130000}
{"episode_reward": 7.9489703113666526, "episode": 131.0, "batch_reward": 0.011815396638587118, "critic_loss": 0.007666836517310003, "actor_loss": -16.657800339981915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.44191646575928, "step": 131000}
{"episode_reward": 7.1818307538682316, "episode": 132.0, "batch_reward": 0.011784599563572556, "critic_loss": 0.005904803479090333, "actor_loss": -17.702925632432102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.708373069763184, "step": 132000}
{"episode_reward": 6.329022473308661, "episode": 133.0, "batch_reward": 0.011559176797047257, "critic_loss": 0.007254158150259172, "actor_loss": -16.600287354454398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.52530312538147, "step": 133000}
{"episode_reward": 7.143705056685651, "episode": 134.0, "batch_reward": 0.011892053723335266, "critic_loss": 0.007111160380765796, "actor_loss": -15.602145160511135, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.240483283996582, "step": 134000}
{"episode_reward": 7.551043724875894, "episode": 135.0, "batch_reward": 0.011676601871848106, "critic_loss": 0.0063487040773034095, "actor_loss": -17.39471344459057, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.965322256088257, "step": 135000}
{"episode_reward": 8.505515043145422, "episode": 136.0, "batch_reward": 0.01158998982515186, "critic_loss": 0.004894699978554854, "actor_loss": -14.478533602327108, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.92704439163208, "step": 136000}
{"episode_reward": 8.875226127135239, "episode": 137.0, "batch_reward": 0.011594904165249317, "critic_loss": 0.006890679106261814, "actor_loss": -16.53687277124822, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.15310835838318, "step": 137000}
{"episode_reward": 7.383638880802541, "episode": 138.0, "batch_reward": 0.011622361853253096, "critic_loss": 0.005405780515109654, "actor_loss": -16.360424702733756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.835367918014526, "step": 138000}
{"episode_reward": 8.143005578795062, "episode": 139.0, "batch_reward": 0.011511638817377389, "critic_loss": 0.006337391007022234, "actor_loss": -16.31151292027533, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.65659260749817, "step": 139000}
{"episode_reward": 5.685900836336836, "episode": 140.0, "batch_reward": 0.01147565298806876, "critic_loss": 0.007794300144159934, "actor_loss": -16.36977051201463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.87727379798889, "step": 140000}
{"episode_reward": 8.903299664354568, "episode": 141.0, "batch_reward": 0.011685952564235777, "critic_loss": 0.006999764588690596, "actor_loss": -16.755273894250394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.27573013305664, "step": 141000}
{"episode_reward": 8.404905434232145, "episode": 142.0, "batch_reward": 0.01154054047446698, "critic_loss": 0.005878501927858451, "actor_loss": -15.455106337741018, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.097442150115967, "step": 142000}
{"episode_reward": 7.760960249452604, "episode": 143.0, "batch_reward": 0.01169222502829507, "critic_loss": 0.005160486275301082, "actor_loss": -15.522238835975529, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.93071937561035, "step": 143000}
{"episode_reward": 8.557881393913679, "episode": 144.0, "batch_reward": 0.011263592455536127, "critic_loss": 0.008624673075275495, "actor_loss": -16.575013066902756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.870062828063965, "step": 144000}
{"episode_reward": 10.63304673490517, "episode": 145.0, "batch_reward": 0.011375387285370379, "critic_loss": 0.006488558267476037, "actor_loss": -16.7820814794451, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.193079471588135, "step": 145000}
{"episode_reward": 9.917843597700456, "episode": 146.0, "batch_reward": 0.011509887031279505, "critic_loss": 0.0074474697388650386, "actor_loss": -17.01313050159812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.802701473236084, "step": 146000}
{"episode_reward": 6.838804950740238, "episode": 147.0, "batch_reward": 0.011274015134200453, "critic_loss": 0.008326946183166001, "actor_loss": -16.51934869965911, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.00199055671692, "step": 147000}
{"episode_reward": 8.087498853951976, "episode": 148.0, "batch_reward": 0.011418717244639992, "critic_loss": 0.008560498823499074, "actor_loss": -16.620366744145752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.916786432266235, "step": 148000}
{"episode_reward": 5.81279774778565, "episode": 149.0, "batch_reward": 0.011353856535162776, "critic_loss": 0.006371633269096491, "actor_loss": -16.23853312623501, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05799174308777, "step": 149000}
{"episode_reward": 6.290783272196778, "episode": 150.0, "batch_reward": 0.011697284558787942, "critic_loss": 0.009947613656142494, "actor_loss": -16.957349643200637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
