{"episode_reward": 0.0, "episode": 1.0, "duration": 19.527746200561523, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.6516993045806885, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.24820807989079302, "critic_loss": 0.0173745941340137, "actor_loss": -35.51040655728124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 67.03206515312195, "step": 3000}
{"episode_reward": 5.977590661378246, "episode": 4.0, "batch_reward": 0.15563872677087784, "critic_loss": 0.012893591042840854, "actor_loss": -30.677955551147463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.273052215576172, "step": 4000}
{"episode_reward": 9.828660557546167, "episode": 5.0, "batch_reward": 0.12341699112951755, "critic_loss": 0.014360959514509887, "actor_loss": -28.7771718416214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.483381509780884, "step": 5000}
{"episode_reward": 10.543905507765128, "episode": 6.0, "batch_reward": 0.10256936351209879, "critic_loss": 0.01230368878459558, "actor_loss": -27.463498840332033, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006794929504395, "step": 6000}
{"episode_reward": 9.323491328164854, "episode": 7.0, "batch_reward": 0.08831330015137792, "critic_loss": 0.010584726174129174, "actor_loss": -27.000839166641235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.22553586959839, "step": 7000}
{"episode_reward": 7.170052468986994, "episode": 8.0, "batch_reward": 0.07717869293317199, "critic_loss": 0.010438049750169738, "actor_loss": -27.257589727401733, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.96759581565857, "step": 8000}
{"episode_reward": 8.429162235136708, "episode": 9.0, "batch_reward": 0.06854424962028861, "critic_loss": 0.009467657015658914, "actor_loss": -26.01273587322235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.35736632347107, "step": 9000}
{"episode_reward": 10.029625278425264, "episode": 10.0, "batch_reward": 0.0628982104063034, "critic_loss": 0.010590921706985681, "actor_loss": -26.011710412979127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.825752019882202, "step": 10000}
{"episode_reward": 7.2339140708656435, "episode": 11.0, "batch_reward": 0.05716362332180142, "critic_loss": 0.010786273302743211, "actor_loss": -25.581178301811217, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.42836833000183, "step": 11000}
{"episode_reward": 7.531856735684748, "episode": 12.0, "batch_reward": 0.05374599441699684, "critic_loss": 0.01127378004102502, "actor_loss": -25.48591924858093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00153160095215, "step": 12000}
{"episode_reward": 9.509122594270126, "episode": 13.0, "batch_reward": 0.049838217539712786, "critic_loss": 0.010388364913989789, "actor_loss": -25.157395305156708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.202821731567383, "step": 13000}
{"episode_reward": 8.066404763258305, "episode": 14.0, "batch_reward": 0.045906323876231905, "critic_loss": 0.008323851818451657, "actor_loss": -25.137724470615385, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.154000997543335, "step": 14000}
{"episode_reward": 7.752669669932636, "episode": 15.0, "batch_reward": 0.04397531027998775, "critic_loss": 0.011538364566862584, "actor_loss": -23.586334205150603, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.658088445663452, "step": 15000}
{"episode_reward": 7.964675278361208, "episode": 16.0, "batch_reward": 0.04097161442227661, "critic_loss": 0.010410808514920064, "actor_loss": -24.872304291248323, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.74721121788025, "step": 16000}
{"episode_reward": 9.011830654836999, "episode": 17.0, "batch_reward": 0.03946453385846689, "critic_loss": 0.011406084328424186, "actor_loss": -24.30784225702286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.563817262649536, "step": 17000}
{"episode_reward": 10.29769978455592, "episode": 18.0, "batch_reward": 0.03748868614714593, "critic_loss": 0.0066792076035635545, "actor_loss": -24.410730763912202, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.25314235687256, "step": 18000}
{"episode_reward": 7.61031989601155, "episode": 19.0, "batch_reward": 0.03672040934488177, "critic_loss": 0.010403633099631406, "actor_loss": -24.58174256658554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.76795792579651, "step": 19000}
{"episode_reward": 13.285540015895894, "episode": 20.0, "batch_reward": 0.035373025584965946, "critic_loss": 0.007330977333127521, "actor_loss": -23.444840243339538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.177424907684326, "step": 20000}
{"episode_reward": 8.228257824416687, "episode": 21.0, "batch_reward": 0.03319321727007628, "critic_loss": 0.011299414221313782, "actor_loss": -23.593238015651703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.25289702415466, "step": 21000}
{"episode_reward": 10.406125233615834, "episode": 22.0, "batch_reward": 0.032389637410640715, "critic_loss": 0.006858457024325616, "actor_loss": -23.198866740942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.577613592147827, "step": 22000}
{"episode_reward": 11.002950812489873, "episode": 23.0, "batch_reward": 0.03142620366998017, "critic_loss": 0.008212222711183131, "actor_loss": -23.63209597611427, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.211206436157227, "step": 23000}
{"episode_reward": 6.549979072531292, "episode": 24.0, "batch_reward": 0.030701425081118942, "critic_loss": 0.00838719752675388, "actor_loss": -23.304993749856948, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.453888177871704, "step": 24000}
{"episode_reward": 7.409283478057073, "episode": 25.0, "batch_reward": 0.029683738889172674, "critic_loss": 0.00921290100394981, "actor_loss": -24.09295474600792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.815966844558716, "step": 25000}
{"episode_reward": 8.329841357868688, "episode": 26.0, "batch_reward": 0.029251072966028004, "critic_loss": 0.006390263675944879, "actor_loss": -23.20024144387245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.87893056869507, "step": 26000}
{"episode_reward": 10.771137456862672, "episode": 27.0, "batch_reward": 0.02852980661438778, "critic_loss": 0.007737883630441502, "actor_loss": -23.241485308885576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.149017095565796, "step": 27000}
{"episode_reward": 9.08604609520926, "episode": 28.0, "batch_reward": 0.02683832064596936, "critic_loss": 0.010937640385091072, "actor_loss": -23.47330372285843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.653374433517456, "step": 28000}
{"episode_reward": 8.631232778667385, "episode": 29.0, "batch_reward": 0.026376294125802814, "critic_loss": 0.004453702487691771, "actor_loss": -22.444087678194045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.17785668373108, "step": 29000}
{"episode_reward": 10.060721898376109, "episode": 30.0, "batch_reward": 0.026567439992912115, "critic_loss": 0.007434958121331874, "actor_loss": -22.41439542245865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.83117938041687, "step": 30000}
{"episode_reward": 8.63605465101312, "episode": 31.0, "batch_reward": 0.02553512930124998, "critic_loss": 0.006588741990621202, "actor_loss": -23.56795918607712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.87656593322754, "step": 31000}
{"episode_reward": 7.254894394622768, "episode": 32.0, "batch_reward": 0.024924798424821346, "critic_loss": 0.006590027974802069, "actor_loss": -23.136554084300993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.09749674797058, "step": 32000}
{"episode_reward": 5.3850656504102945, "episode": 33.0, "batch_reward": 0.024922625803854317, "critic_loss": 0.00801504432677757, "actor_loss": -23.16434524011612, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.783116579055786, "step": 33000}
{"episode_reward": 10.360251193774104, "episode": 34.0, "batch_reward": 0.023917996537871657, "critic_loss": 0.004849852020328399, "actor_loss": -23.14332346868515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.03956627845764, "step": 34000}
{"episode_reward": 9.85028437442974, "episode": 35.0, "batch_reward": 0.023480357696767897, "critic_loss": 0.00607626231276663, "actor_loss": -22.528235327363014, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.09527325630188, "step": 35000}
{"episode_reward": 7.383917803911761, "episode": 36.0, "batch_reward": 0.023186118405777962, "critic_loss": 0.0054678090109373445, "actor_loss": -24.021862428903578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.116610527038574, "step": 36000}
{"episode_reward": 9.72581178209056, "episode": 37.0, "batch_reward": 0.02267773927981034, "critic_loss": 0.006432681462320034, "actor_loss": -23.184624423265458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.76369881629944, "step": 37000}
{"episode_reward": 7.339681098011888, "episode": 38.0, "batch_reward": 0.022394691119436174, "critic_loss": 0.0066014818061958065, "actor_loss": -22.324562644839286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.673158645629883, "step": 38000}
{"episode_reward": 6.257417904274686, "episode": 39.0, "batch_reward": 0.02226471239887178, "critic_loss": 0.0055052244920516386, "actor_loss": -23.42643345308304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.846263647079468, "step": 39000}
{"episode_reward": 5.862841596026081, "episode": 40.0, "batch_reward": 0.021260793527588247, "critic_loss": 0.005705904875707347, "actor_loss": -23.34323991727829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.859043836593628, "step": 40000}
{"episode_reward": 6.082704490352353, "episode": 41.0, "batch_reward": 0.021212094728369265, "critic_loss": 0.005884025344392285, "actor_loss": -23.983255512833594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.63254761695862, "step": 41000}
{"episode_reward": 7.516683383103081, "episode": 42.0, "batch_reward": 0.020715369986370205, "critic_loss": 0.0060219670700025745, "actor_loss": -22.14351191055775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.173232555389404, "step": 42000}
{"episode_reward": 6.513644740015418, "episode": 43.0, "batch_reward": 0.02031135204760358, "critic_loss": 0.006817374813690549, "actor_loss": -23.30980771458149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.907880783081055, "step": 43000}
{"episode_reward": 8.31125538960214, "episode": 44.0, "batch_reward": 0.01996964627271518, "critic_loss": 0.004506500012153992, "actor_loss": -23.177161494851113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.15281367301941, "step": 44000}
{"episode_reward": 7.317908537791677, "episode": 45.0, "batch_reward": 0.019798304396215827, "critic_loss": 0.004990479586442234, "actor_loss": -22.833924916028977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.80670142173767, "step": 45000}
{"episode_reward": 7.365682208918293, "episode": 46.0, "batch_reward": 0.019746124668512492, "critic_loss": 0.007048032165970653, "actor_loss": -22.606096172332762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.31812357902527, "step": 46000}
{"episode_reward": 10.169289515807465, "episode": 47.0, "batch_reward": 0.01944179774262011, "critic_loss": 0.00456131247288431, "actor_loss": -23.20039369392395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.748841762542725, "step": 47000}
{"episode_reward": 6.2367153222005145, "episode": 48.0, "batch_reward": 0.019054267610423267, "critic_loss": 0.00449867953840294, "actor_loss": -23.056100510954856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.416175603866577, "step": 48000}
{"episode_reward": 6.795570287527462, "episode": 49.0, "batch_reward": 0.019329321711789818, "critic_loss": 0.005465367777505889, "actor_loss": -23.294520587563515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.59498429298401, "step": 49000}
{"episode_reward": 7.453120432295246, "episode": 50.0, "batch_reward": 0.01894790468364954, "critic_loss": 0.004708655847003683, "actor_loss": -22.44406785595417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.490648984909058, "step": 50000}
{"episode_reward": 11.137368613235378, "episode": 51.0, "batch_reward": 0.01857188145071268, "critic_loss": 0.007229393402027199, "actor_loss": -22.468800054609776, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.29899621009827, "step": 51000}
{"episode_reward": 10.098283737380712, "episode": 52.0, "batch_reward": 0.018565606210846453, "critic_loss": 0.004159152260748669, "actor_loss": -23.292181897461415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.784376621246338, "step": 52000}
{"episode_reward": 7.475991930478656, "episode": 53.0, "batch_reward": 0.018319975305814296, "critic_loss": 0.0053176705433288585, "actor_loss": -21.80030545139313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.913087844848633, "step": 53000}
{"episode_reward": 6.478290178800252, "episode": 54.0, "batch_reward": 0.018388648878317326, "critic_loss": 0.004180916860845173, "actor_loss": -23.532526137411594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.412096738815308, "step": 54000}
{"episode_reward": 7.375388459121393, "episode": 55.0, "batch_reward": 0.017716798153705894, "critic_loss": 0.004672746221156558, "actor_loss": -22.908112200081348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.775291681289673, "step": 55000}
{"episode_reward": 6.522187074839669, "episode": 56.0, "batch_reward": 0.01738851565262303, "critic_loss": 0.005310556906159036, "actor_loss": -21.730399600863457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.681637048721313, "step": 56000}
{"episode_reward": 7.989354537104922, "episode": 57.0, "batch_reward": 0.01753605389036238, "critic_loss": 0.004033918656728929, "actor_loss": -23.02891815239191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.9876127243042, "step": 57000}
{"episode_reward": 7.345188563130117, "episode": 58.0, "batch_reward": 0.017267830126918852, "critic_loss": 0.0057578436958719975, "actor_loss": -22.324109577476978, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.897373914718628, "step": 58000}
{"episode_reward": 8.696758507669415, "episode": 59.0, "batch_reward": 0.01694346177019179, "critic_loss": 0.0028387222920719067, "actor_loss": -22.40121499764919, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.620818376541138, "step": 59000}
{"episode_reward": 12.11325568960305, "episode": 60.0, "batch_reward": 0.017051995971240103, "critic_loss": 0.0062746050959976854, "actor_loss": -22.345915185809137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.34741187095642, "step": 60000}
{"episode_reward": 14.384131954125081, "episode": 61.0, "batch_reward": 0.01677269874792546, "critic_loss": 0.004568756979948375, "actor_loss": -22.933469146609305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.892600774765015, "step": 61000}
{"episode_reward": 7.280974816717407, "episode": 62.0, "batch_reward": 0.016471900215838105, "critic_loss": 0.004957012041384587, "actor_loss": -21.931051945626734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.458069801330566, "step": 62000}
{"episode_reward": 10.863346175402675, "episode": 63.0, "batch_reward": 0.016553813653532416, "critic_loss": 0.0037005375091102907, "actor_loss": -22.239738445580006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.011380434036255, "step": 63000}
{"episode_reward": 10.193163913078257, "episode": 64.0, "batch_reward": 0.016471098786219954, "critic_loss": 0.005744185815565288, "actor_loss": -22.3096457644701, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.548877239227295, "step": 64000}
{"episode_reward": 12.208791303674577, "episode": 65.0, "batch_reward": 0.016572126267012207, "critic_loss": 0.0048987401795748155, "actor_loss": -21.95947607266903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.395047187805176, "step": 65000}
{"episode_reward": 8.390569773294894, "episode": 66.0, "batch_reward": 0.01613455707859248, "critic_loss": 0.00329751491965726, "actor_loss": -22.062416296482088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.53986954689026, "step": 66000}
{"episode_reward": 7.335885122692943, "episode": 67.0, "batch_reward": 0.016085794010665268, "critic_loss": 0.004022264660598011, "actor_loss": -21.550851491332054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.30930995941162, "step": 67000}
{"episode_reward": 7.0260550834979645, "episode": 68.0, "batch_reward": 0.016204365825280547, "critic_loss": 0.0048148682491737415, "actor_loss": -22.489715306282044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.920994520187378, "step": 68000}
{"episode_reward": 6.314271813190291, "episode": 69.0, "batch_reward": 0.01612201808253303, "critic_loss": 0.0038955723657854834, "actor_loss": -22.55460136818886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10880184173584, "step": 69000}
{"episode_reward": 12.591858339167471, "episode": 70.0, "batch_reward": 0.01580331900343299, "critic_loss": 0.0038753966319491156, "actor_loss": -22.528316520154476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.212963342666626, "step": 70000}
{"episode_reward": 8.026937815187583, "episode": 71.0, "batch_reward": 0.01575706605287269, "critic_loss": 0.0036997471245995258, "actor_loss": -21.64375867176056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.60541224479675, "step": 71000}
{"episode_reward": 7.729969067588801, "episode": 72.0, "batch_reward": 0.015585794501472265, "critic_loss": 0.003956440783920698, "actor_loss": -22.737952171415092, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.818247079849243, "step": 72000}
{"episode_reward": 6.380904891392683, "episode": 73.0, "batch_reward": 0.015629239395726472, "critic_loss": 0.0043685497487313115, "actor_loss": -22.51326374387741, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.81921887397766, "step": 73000}
{"episode_reward": 8.496936459894329, "episode": 74.0, "batch_reward": 0.015425039204768837, "critic_loss": 0.004007740386965452, "actor_loss": -21.935521726757287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.421786785125732, "step": 74000}
{"episode_reward": 8.272578658659116, "episode": 75.0, "batch_reward": 0.015670963013079017, "critic_loss": 0.0040238756628532425, "actor_loss": -22.656209201186897, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.982486963272095, "step": 75000}
{"episode_reward": 8.029110575812316, "episode": 76.0, "batch_reward": 0.01511287435144186, "critic_loss": 0.0043848313281487205, "actor_loss": -22.13449240016937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.359353065490723, "step": 76000}
{"episode_reward": 7.315584291133417, "episode": 77.0, "batch_reward": 0.014914810850750655, "critic_loss": 0.0035318175850843547, "actor_loss": -21.910109920352696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.288913011550903, "step": 77000}
{"episode_reward": 11.472288660591534, "episode": 78.0, "batch_reward": 0.015225815248675644, "critic_loss": 0.004784278840234037, "actor_loss": -21.493783386588095, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.344438314437866, "step": 78000}
{"episode_reward": 7.2703262674011055, "episode": 79.0, "batch_reward": 0.01490197736490518, "critic_loss": 0.00397873142894241, "actor_loss": -22.1704702706933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.735451459884644, "step": 79000}
{"episode_reward": 8.169870996134856, "episode": 80.0, "batch_reward": 0.015005006069783122, "critic_loss": 0.004180123128084233, "actor_loss": -22.23456967034936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.81853938102722, "step": 80000}
{"episode_reward": 7.807819561101117, "episode": 81.0, "batch_reward": 0.01491093448922038, "critic_loss": 0.004208393978071399, "actor_loss": -22.18365158033371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.782267808914185, "step": 81000}
{"episode_reward": 7.208766982904125, "episode": 82.0, "batch_reward": 0.014656402003485709, "critic_loss": 0.0032321291138068774, "actor_loss": -21.953666694581507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.112488746643066, "step": 82000}
{"episode_reward": 7.008551750421733, "episode": 83.0, "batch_reward": 0.014537668123375624, "critic_loss": 0.00348361286688305, "actor_loss": -22.0383753618598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.897969484329224, "step": 83000}
{"episode_reward": 7.1927523411433905, "episode": 84.0, "batch_reward": 0.01422214230429381, "critic_loss": 0.003976101860665949, "actor_loss": -22.976053929418324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.397336959838867, "step": 84000}
{"episode_reward": 6.496106836010518, "episode": 85.0, "batch_reward": 0.014762650412973017, "critic_loss": 0.004875308273622068, "actor_loss": -22.227625702410936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.819311141967773, "step": 85000}
{"episode_reward": 4.985995054053279, "episode": 86.0, "batch_reward": 0.014387640250846743, "critic_loss": 0.003396050417140941, "actor_loss": -22.63756653010845, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.42081880569458, "step": 86000}
{"episode_reward": 9.504204922727386, "episode": 87.0, "batch_reward": 0.01465221066121012, "critic_loss": 0.003517850580858067, "actor_loss": -22.591178181290626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.50340175628662, "step": 87000}
{"episode_reward": 8.243483959299102, "episode": 88.0, "batch_reward": 0.014403109991457313, "critic_loss": 0.003880190085503273, "actor_loss": -22.750317388564348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.369645833969116, "step": 88000}
{"episode_reward": 6.691062944019721, "episode": 89.0, "batch_reward": 0.014154039734508843, "critic_loss": 0.0032949708410451423, "actor_loss": -22.027269899070262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.153198957443237, "step": 89000}
{"episode_reward": 11.79156885512522, "episode": 90.0, "batch_reward": 0.014004246183205397, "critic_loss": 0.003801269704621518, "actor_loss": -22.185338904261588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.7519748210907, "step": 90000}
{"episode_reward": 8.943101414626728, "episode": 91.0, "batch_reward": 0.014115028648171574, "critic_loss": 0.003656193452668958, "actor_loss": -21.793520469993354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.87399220466614, "step": 91000}
{"episode_reward": 10.216232982759418, "episode": 92.0, "batch_reward": 0.014104521663859487, "critic_loss": 0.00344009707083751, "actor_loss": -21.94905583113432, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.0203378200531, "step": 92000}
{"episode_reward": 9.285002029306746, "episode": 93.0, "batch_reward": 0.014117570905014873, "critic_loss": 0.0037152212485380004, "actor_loss": -22.76576407510042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.653372049331665, "step": 93000}
{"episode_reward": 9.731142149269333, "episode": 94.0, "batch_reward": 0.01377756514120847, "critic_loss": 0.003760013232298661, "actor_loss": -22.707588720455767, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.31748127937317, "step": 94000}
{"episode_reward": 8.690499983360272, "episode": 95.0, "batch_reward": 0.013772572285961359, "critic_loss": 0.0044075653833278924, "actor_loss": -22.707617193579672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.032901525497437, "step": 95000}
{"episode_reward": 9.839284830507452, "episode": 96.0, "batch_reward": 0.013844227162655444, "critic_loss": 0.0031888862375053575, "actor_loss": -22.220354475915432, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.262383937835693, "step": 96000}
{"episode_reward": 6.362512091346924, "episode": 97.0, "batch_reward": 0.01367591901961714, "critic_loss": 0.003270783446962014, "actor_loss": -22.643000021338462, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.929737329483032, "step": 97000}
{"episode_reward": 5.0454071931298605, "episode": 98.0, "batch_reward": 0.013562988452147692, "critic_loss": 0.003503653424762888, "actor_loss": -22.699902901783584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.882564783096313, "step": 98000}
{"episode_reward": 9.162818840187098, "episode": 99.0, "batch_reward": 0.013742634727619588, "critic_loss": 0.004585408933926374, "actor_loss": -22.30888801366091, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.6422221660614, "step": 99000}
{"episode_reward": 7.427601924535486, "episode": 100.0, "batch_reward": 0.013455325230490416, "critic_loss": 0.004065605140902335, "actor_loss": -23.02337670388818, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.139512538909912, "step": 100000}
{"episode_reward": 8.48318975057316, "episode": 101.0, "batch_reward": 0.01340678881853819, "critic_loss": 0.003747665040573338, "actor_loss": -22.789368404358626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.897770166397095, "step": 101000}
{"episode_reward": 9.463680265433165, "episode": 102.0, "batch_reward": 0.013299642800353468, "critic_loss": 0.0036679618284106257, "actor_loss": -23.326937681987882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.34409189224243, "step": 102000}
{"episode_reward": 6.180297755571498, "episode": 103.0, "batch_reward": 0.013482905649114401, "critic_loss": 0.003710480225941865, "actor_loss": -21.7605647149384, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.573317766189575, "step": 103000}
{"episode_reward": 6.0487873044465, "episode": 104.0, "batch_reward": 0.013607124862261117, "critic_loss": 0.00427401086910686, "actor_loss": -22.520863302245736, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.773054122924805, "step": 104000}
{"episode_reward": 6.982166448373932, "episode": 105.0, "batch_reward": 0.013201420260593295, "critic_loss": 0.0031101869971753332, "actor_loss": -22.006354970648886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.995169401168823, "step": 105000}
{"episode_reward": 7.744034640517447, "episode": 106.0, "batch_reward": 0.013333241695072502, "critic_loss": 0.0035207437854114687, "actor_loss": -23.226232310950756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.057873010635376, "step": 106000}
{"episode_reward": 10.911019276014876, "episode": 107.0, "batch_reward": 0.013181698558852076, "critic_loss": 0.003138031424023211, "actor_loss": -23.146915889263152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14126491546631, "step": 107000}
{"episode_reward": 10.183724119517759, "episode": 108.0, "batch_reward": 0.012935961384791882, "critic_loss": 0.002510210206528427, "actor_loss": -22.037205584838986, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.78317427635193, "step": 108000}
{"episode_reward": 9.829953607207022, "episode": 109.0, "batch_reward": 0.013153385284822435, "critic_loss": 0.004417551368998829, "actor_loss": -22.830156330034136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.716085195541382, "step": 109000}
{"episode_reward": 8.295169085842451, "episode": 110.0, "batch_reward": 0.012928572992794216, "critic_loss": 0.003454389000471565, "actor_loss": -22.479847664237024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.99775218963623, "step": 110000}
{"episode_reward": 10.217697827071573, "episode": 111.0, "batch_reward": 0.0130457679387182, "critic_loss": 0.002416499467246467, "actor_loss": -22.101935159415007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.27746224403381, "step": 111000}
{"episode_reward": 7.491469105737339, "episode": 112.0, "batch_reward": 0.013155706008896232, "critic_loss": 0.0034794098064303398, "actor_loss": -22.758399013489484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.595402240753174, "step": 112000}
{"episode_reward": 7.855147328172014, "episode": 113.0, "batch_reward": 0.013011793951038271, "critic_loss": 0.003016310301842168, "actor_loss": -22.984511296495796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.329642295837402, "step": 113000}
{"episode_reward": 7.508317957291304, "episode": 114.0, "batch_reward": 0.013073668768629431, "critic_loss": 0.003341306752641685, "actor_loss": -23.09082047240436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.802786111831665, "step": 114000}
{"episode_reward": 7.426813212091537, "episode": 115.0, "batch_reward": 0.012633719534613192, "critic_loss": 0.002091037693535327, "actor_loss": -22.249851053476334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.79067897796631, "step": 115000}
{"episode_reward": 9.764629521292386, "episode": 116.0, "batch_reward": 0.012759957673028111, "critic_loss": 0.004240207318405737, "actor_loss": -22.572454679951072, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.34754252433777, "step": 116000}
{"episode_reward": 10.770075010885904, "episode": 117.0, "batch_reward": 0.01317870442243293, "critic_loss": 0.0021074807638215135, "actor_loss": -21.442613695800304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.65746235847473, "step": 117000}
{"episode_reward": 7.390392166578284, "episode": 118.0, "batch_reward": 0.012690383929293603, "critic_loss": 0.0033828105780849002, "actor_loss": -22.023206992954016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.225118398666382, "step": 118000}
{"episode_reward": 8.871339913814117, "episode": 119.0, "batch_reward": 0.012687052832916379, "critic_loss": 0.002080903037422104, "actor_loss": -22.071787653043867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.888850927352905, "step": 119000}
{"episode_reward": 7.2925546518167605, "episode": 120.0, "batch_reward": 0.01268703454080969, "critic_loss": 0.0028150803264434215, "actor_loss": -22.021538126751782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.58173370361328, "step": 120000}
{"episode_reward": 10.3156812111789, "episode": 121.0, "batch_reward": 0.012694247592706234, "critic_loss": 0.002211368133430369, "actor_loss": -22.03197501318157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.7237823009491, "step": 121000}
{"episode_reward": 6.135593988081927, "episode": 122.0, "batch_reward": 0.012753467598930002, "critic_loss": 0.0023841368879948277, "actor_loss": -22.748468076348306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.50639820098877, "step": 122000}
{"episode_reward": 7.9861447871632505, "episode": 123.0, "batch_reward": 0.012363802179228514, "critic_loss": 0.0021963150771771326, "actor_loss": -23.162714853674174, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.558834552764893, "step": 123000}
{"episode_reward": 8.212998747569833, "episode": 124.0, "batch_reward": 0.012553292777389287, "critic_loss": 0.0022459891965554563, "actor_loss": -22.9392922603786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.326154470443726, "step": 124000}
{"episode_reward": 10.593786105456118, "episode": 125.0, "batch_reward": 0.012603684425819665, "critic_loss": 0.004026128322613658, "actor_loss": -22.723367032393814, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.530874729156494, "step": 125000}
{"episode_reward": 8.574229230278654, "episode": 126.0, "batch_reward": 0.012610826668329536, "critic_loss": 0.003112424475955777, "actor_loss": -22.133517991647125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.584723472595215, "step": 126000}
{"episode_reward": 8.073290364731854, "episode": 127.0, "batch_reward": 0.012433261346537619, "critic_loss": 0.002247281686824863, "actor_loss": -21.78477501308918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.378106117248535, "step": 127000}
{"episode_reward": 7.411251103789497, "episode": 128.0, "batch_reward": 0.012044044815935195, "critic_loss": 0.002851412805946893, "actor_loss": -21.98916812449694, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.346447706222534, "step": 128000}
{"episode_reward": 10.847059919665876, "episode": 129.0, "batch_reward": 0.012638598053716123, "critic_loss": 0.002467410355064203, "actor_loss": -22.39696863745153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.869121074676514, "step": 129000}
{"episode_reward": 6.08449686530827, "episode": 130.0, "batch_reward": 0.012145995557773858, "critic_loss": 0.00238524475468148, "actor_loss": -21.87573861014843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.7271671295166, "step": 130000}
{"episode_reward": 10.373384022464709, "episode": 131.0, "batch_reward": 0.012312226364389061, "critic_loss": 0.0024590437720762564, "actor_loss": -22.626450517967342, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.599876165390015, "step": 131000}
{"episode_reward": 8.360590570989443, "episode": 132.0, "batch_reward": 0.012297446010168642, "critic_loss": 0.002893113160826033, "actor_loss": -23.14775963793695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.829737901687622, "step": 132000}
{"episode_reward": 6.563056197446195, "episode": 133.0, "batch_reward": 0.01209471985232085, "critic_loss": 0.0024662838432268474, "actor_loss": -22.636653250157835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.230525255203247, "step": 133000}
{"episode_reward": 7.380478336617393, "episode": 134.0, "batch_reward": 0.012359995611943304, "critic_loss": 0.0024670916449540527, "actor_loss": -22.174940303504467, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.147665977478027, "step": 134000}
{"episode_reward": 8.93646773766219, "episode": 135.0, "batch_reward": 0.01218984314193949, "critic_loss": 0.002268180784973083, "actor_loss": -21.86798420764506, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.49798560142517, "step": 135000}
{"episode_reward": 10.648556847464588, "episode": 136.0, "batch_reward": 0.01211879496416077, "critic_loss": 0.002499276380462106, "actor_loss": -21.37256788878143, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.023252964019775, "step": 136000}
{"episode_reward": 8.532095150025121, "episode": 137.0, "batch_reward": 0.012122483850456774, "critic_loss": 0.0027602907162799966, "actor_loss": -22.970255296334624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.074079990386963, "step": 137000}
{"episode_reward": 7.124560111742188, "episode": 138.0, "batch_reward": 0.012112016353290529, "critic_loss": 0.002009871474641841, "actor_loss": -22.468748334378002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.280959606170654, "step": 138000}
{"episode_reward": 8.225802663400152, "episode": 139.0, "batch_reward": 0.012011610410176218, "critic_loss": 0.0027543844417959916, "actor_loss": -22.13514992132783, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.884909868240356, "step": 139000}
{"episode_reward": 7.21924873814938, "episode": 140.0, "batch_reward": 0.011985215701162816, "critic_loss": 0.0025868000902992206, "actor_loss": -22.08607104982436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.601214170455933, "step": 140000}
{"episode_reward": 8.137667266309338, "episode": 141.0, "batch_reward": 0.012229836895130575, "critic_loss": 0.0029166161676257617, "actor_loss": -22.69181709498167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.68525409698486, "step": 141000}
{"episode_reward": 9.300726694315108, "episode": 142.0, "batch_reward": 0.012056386285461485, "critic_loss": 0.0019301463875599438, "actor_loss": -21.040663216233252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.037843704223633, "step": 142000}
{"episode_reward": 7.20536548409746, "episode": 143.0, "batch_reward": 0.01221030728239566, "critic_loss": 0.0022073392531456195, "actor_loss": -21.493401305809616, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.048185348510742, "step": 143000}
{"episode_reward": 10.446832332873754, "episode": 144.0, "batch_reward": 0.011787665502168239, "critic_loss": 0.003174464435665868, "actor_loss": -22.19373422397673, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.551679611206055, "step": 144000}
{"episode_reward": 11.728162127040301, "episode": 145.0, "batch_reward": 0.011881772636901588, "critic_loss": 0.0029254483269760385, "actor_loss": -22.953417846024035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.248404264450073, "step": 145000}
{"episode_reward": 11.970965939415166, "episode": 146.0, "batch_reward": 0.012034857916645705, "critic_loss": 0.002907322059327271, "actor_loss": -22.687029737591743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.928657054901123, "step": 146000}
{"episode_reward": 7.083708350989681, "episode": 147.0, "batch_reward": 0.011854518122039736, "critic_loss": 0.002448407913558185, "actor_loss": -21.920172055721284, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.77496314048767, "step": 147000}
{"episode_reward": 9.988054337741543, "episode": 148.0, "batch_reward": 0.011940523222088814, "critic_loss": 0.002559609301693854, "actor_loss": -22.902798348158598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22091054916382, "step": 148000}
{"episode_reward": 7.654654850098393, "episode": 149.0, "batch_reward": 0.011902281842194497, "critic_loss": 0.002663902121814317, "actor_loss": -21.68672441250086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.2208993434906, "step": 149000}
{"episode_reward": 7.430729134444327, "episode": 150.0, "batch_reward": 0.012286719739902764, "critic_loss": 0.0021235222876857733, "actor_loss": -22.80741491034627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
