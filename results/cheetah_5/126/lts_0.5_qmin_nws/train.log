{"episode_reward": 0.0, "episode": 1.0, "duration": 19.7624089717865, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.9104716777801514, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.2523504842337309, "critic_loss": 0.039354990415024174, "actor_loss": -21.970011398855114, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 67.76521897315979, "step": 3000}
{"episode_reward": 42.68003202702859, "episode": 4.0, "batch_reward": 0.16533122400939465, "critic_loss": 0.04103131297230721, "actor_loss": -9.775878338187933, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.363564252853394, "step": 4000}
{"episode_reward": 5.602844761891494, "episode": 5.0, "batch_reward": 0.12988111179322004, "critic_loss": 0.03133415425941348, "actor_loss": -9.024197784923016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.17072319984436, "step": 5000}
{"episode_reward": 3.3719561838789054, "episode": 6.0, "batch_reward": 0.10685766822099686, "critic_loss": 0.02840598779078573, "actor_loss": -9.401425157234073, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.733411073684692, "step": 6000}
{"episode_reward": 3.87800394632608, "episode": 7.0, "batch_reward": 0.09118585543707013, "critic_loss": 0.030535990878008307, "actor_loss": -10.444114687100052, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.65685749053955, "step": 7000}
{"episode_reward": 3.9576552042186877, "episode": 8.0, "batch_reward": 0.07955332782678307, "critic_loss": 0.02739838926680386, "actor_loss": -11.862117574378848, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.390101432800293, "step": 8000}
{"episode_reward": 6.599552777696772, "episode": 9.0, "batch_reward": 0.07082224190048873, "critic_loss": 0.034311948800459506, "actor_loss": -12.034852268472314, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.661965370178223, "step": 9000}
{"episode_reward": 37.01341321893398, "episode": 10.0, "batch_reward": 0.06859666237980128, "critic_loss": 0.05050336939375848, "actor_loss": -12.672479705929756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.319049835205078, "step": 10000}
{"episode_reward": 37.79508398491641, "episode": 11.0, "batch_reward": 0.06593142509460449, "critic_loss": 0.0355511601306498, "actor_loss": -12.052060052335262, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.73855137825012, "step": 11000}
{"episode_reward": 74.37878118041633, "episode": 12.0, "batch_reward": 0.06611076846346259, "critic_loss": 0.05868933927640319, "actor_loss": -12.882534408912063, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.939460515975952, "step": 12000}
{"episode_reward": 15.15427180346187, "episode": 13.0, "batch_reward": 0.06726810783334077, "critic_loss": 0.08521124961785972, "actor_loss": -11.802332689747214, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.718820333480835, "step": 13000}
{"episode_reward": 137.35198076584993, "episode": 14.0, "batch_reward": 0.07091039802134037, "critic_loss": 0.09702845742367208, "actor_loss": -12.135940016642213, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.79637050628662, "step": 14000}
{"episode_reward": 142.942397760549, "episode": 15.0, "batch_reward": 0.07712215468287469, "critic_loss": 0.09754556940495968, "actor_loss": -11.441494176574052, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.703587293624878, "step": 15000}
{"episode_reward": 113.3013514120614, "episode": 16.0, "batch_reward": 0.07694709120318294, "critic_loss": 0.10530080252885818, "actor_loss": -13.1700312795192, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.07413363456726, "step": 16000}
{"episode_reward": 58.51405433189097, "episode": 17.0, "batch_reward": 0.07649436445534229, "critic_loss": 0.11456426585838199, "actor_loss": -12.223624456122518, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.64044690132141, "step": 17000}
{"episode_reward": 106.46095819148454, "episode": 18.0, "batch_reward": 0.07887697023898363, "critic_loss": 0.1450331676416099, "actor_loss": -13.527739008188247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.36550498008728, "step": 18000}
{"episode_reward": 144.4485651839534, "episode": 19.0, "batch_reward": 0.08300613234937192, "critic_loss": 0.16980611326545478, "actor_loss": -13.652966988921165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.461474180221558, "step": 19000}
{"episode_reward": 88.21318890521341, "episode": 20.0, "batch_reward": 0.0847287152633071, "critic_loss": 0.16631782737374307, "actor_loss": -12.58576366865635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.615986585617065, "step": 20000}
{"episode_reward": 190.37158243950074, "episode": 21.0, "batch_reward": 0.08718114694580435, "critic_loss": 0.19597344733029604, "actor_loss": -14.380798198699951, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.12216258049011, "step": 21000}
{"episode_reward": 110.18936114470885, "episode": 22.0, "batch_reward": 0.08859587554261088, "critic_loss": 0.20926170767843724, "actor_loss": -14.59263062286377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.26000142097473, "step": 22000}
{"episode_reward": 114.28296395135132, "episode": 23.0, "batch_reward": 0.09060730427876115, "critic_loss": 0.2194017404317856, "actor_loss": -14.979551562309265, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.388929843902588, "step": 23000}
{"episode_reward": 142.7306191529219, "episode": 24.0, "batch_reward": 0.09271211976185441, "critic_loss": 0.2430028013586998, "actor_loss": -15.58353031206131, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.99187684059143, "step": 24000}
{"episode_reward": 169.27859517067026, "episode": 25.0, "batch_reward": 0.09762726803123951, "critic_loss": 0.27045712907612324, "actor_loss": -16.0957001581192, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.794334650039673, "step": 25000}
{"episode_reward": 239.0830906765361, "episode": 26.0, "batch_reward": 0.10279006461054087, "critic_loss": 0.28584098659455776, "actor_loss": -17.106680000305175, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.440030097961426, "step": 26000}
{"episode_reward": 133.4629873286317, "episode": 27.0, "batch_reward": 0.10305878568440675, "critic_loss": 0.25637137741595506, "actor_loss": -16.447094332695006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.81979537010193, "step": 27000}
{"episode_reward": 97.03083928884277, "episode": 28.0, "batch_reward": 0.10253777957707644, "critic_loss": 0.25921170119941234, "actor_loss": -17.357722532272337, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.19655132293701, "step": 28000}
{"episode_reward": 180.50718400259598, "episode": 29.0, "batch_reward": 0.10512082145363093, "critic_loss": 0.2668513601794839, "actor_loss": -16.734143726348876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.24215054512024, "step": 29000}
{"episode_reward": 195.53815224352115, "episode": 30.0, "batch_reward": 0.10874242147058248, "critic_loss": 0.2908027112185955, "actor_loss": -17.461253064155578, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.892611742019653, "step": 30000}
{"episode_reward": 195.7564106015626, "episode": 31.0, "batch_reward": 0.11341597454994917, "critic_loss": 0.3217121527642012, "actor_loss": -18.631323744773866, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.54376745223999, "step": 31000}
{"episode_reward": 326.51347358786285, "episode": 32.0, "batch_reward": 0.11942668025940657, "critic_loss": 0.32679491797089577, "actor_loss": -19.21311667060852, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.497443437576294, "step": 32000}
{"episode_reward": 194.407972196089, "episode": 33.0, "batch_reward": 0.11944891411811114, "critic_loss": 0.2816149977296591, "actor_loss": -18.157913639068603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.436625003814697, "step": 33000}
{"episode_reward": 57.81206800365408, "episode": 34.0, "batch_reward": 0.1190853824019432, "critic_loss": 0.2988756508529186, "actor_loss": -18.763201890945435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.23351263999939, "step": 34000}
{"episode_reward": 144.257938774924, "episode": 35.0, "batch_reward": 0.12010197857022285, "critic_loss": 0.29950318111479285, "actor_loss": -19.204225019454956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.070746183395386, "step": 35000}
{"episode_reward": 213.4036487957591, "episode": 36.0, "batch_reward": 0.1212219241708517, "critic_loss": 0.30736283339560033, "actor_loss": -19.640123466491698, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.29738688468933, "step": 36000}
{"episode_reward": 58.4485655471992, "episode": 37.0, "batch_reward": 0.12138408600538969, "critic_loss": 0.3052778624594212, "actor_loss": -19.20728565979004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.6182382106781, "step": 37000}
{"episode_reward": 233.1725897125452, "episode": 38.0, "batch_reward": 0.1240093676224351, "critic_loss": 0.29466010481119154, "actor_loss": -18.736362657546998, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.246414184570312, "step": 38000}
{"episode_reward": 157.11959532706578, "episode": 39.0, "batch_reward": 0.1256781047284603, "critic_loss": 0.30596084652841093, "actor_loss": -19.324616048812867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.299952745437622, "step": 39000}
{"episode_reward": 265.55355924426544, "episode": 40.0, "batch_reward": 0.12807499335706235, "critic_loss": 0.32117663231492044, "actor_loss": -20.113201026916503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.388410568237305, "step": 40000}
{"episode_reward": 240.80033042367987, "episode": 41.0, "batch_reward": 0.13147332543879747, "critic_loss": 0.3106409453302622, "actor_loss": -20.791012741088867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.61660838127136, "step": 41000}
{"episode_reward": 224.57844690138793, "episode": 42.0, "batch_reward": 0.13236335703730584, "critic_loss": 0.32290824042260646, "actor_loss": -19.878485456466674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.07494354248047, "step": 42000}
{"episode_reward": 87.70247515780669, "episode": 43.0, "batch_reward": 0.1328566217198968, "critic_loss": 0.3158431394249201, "actor_loss": -20.261975618362428, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.046415328979492, "step": 43000}
{"episode_reward": 260.04521162015754, "episode": 44.0, "batch_reward": 0.13578320936113597, "critic_loss": 0.32492657117545604, "actor_loss": -19.960935930252074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.482739210128784, "step": 44000}
{"episode_reward": 169.4892012798941, "episode": 45.0, "batch_reward": 0.13610959225147962, "critic_loss": 0.33204378361999987, "actor_loss": -19.669703577041627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.788386344909668, "step": 45000}
{"episode_reward": 138.90423101944748, "episode": 46.0, "batch_reward": 0.13526898211240768, "critic_loss": 0.3232565906792879, "actor_loss": -20.345283611297607, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.07262945175171, "step": 46000}
{"episode_reward": 117.56494158696276, "episode": 47.0, "batch_reward": 0.13685447537899018, "critic_loss": 0.3526078471392393, "actor_loss": -20.625616682052613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.8029682636261, "step": 47000}
{"episode_reward": 260.39163699678113, "episode": 48.0, "batch_reward": 0.13908474331349135, "critic_loss": 0.3379860704690218, "actor_loss": -20.210943284988403, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.820103645324707, "step": 48000}
{"episode_reward": 175.3855030210092, "episode": 49.0, "batch_reward": 0.1396994856968522, "critic_loss": 0.32049891652166845, "actor_loss": -20.616478052139282, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.216667413711548, "step": 49000}
{"episode_reward": 177.65025559495473, "episode": 50.0, "batch_reward": 0.14044185230135917, "critic_loss": 0.3539146663993597, "actor_loss": -20.15396837234497, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.447723627090454, "step": 50000}
{"episode_reward": 270.8066681532815, "episode": 51.0, "batch_reward": 0.1429023722037673, "critic_loss": 0.34115417508780954, "actor_loss": -19.72005344581604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.2748076915741, "step": 51000}
{"episode_reward": 188.49714694543948, "episode": 52.0, "batch_reward": 0.14434791799634694, "critic_loss": 0.33930577601492407, "actor_loss": -21.241285963058473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.01440954208374, "step": 52000}
{"episode_reward": 321.8418485712146, "episode": 53.0, "batch_reward": 0.1460140331760049, "critic_loss": 0.32168498188257216, "actor_loss": -20.03632707977295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.887882709503174, "step": 53000}
{"episode_reward": 70.28407945121724, "episode": 54.0, "batch_reward": 0.14673266917467118, "critic_loss": 0.3392049165219069, "actor_loss": -21.427014375686646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.081734895706177, "step": 54000}
{"episode_reward": 357.2783364036552, "episode": 55.0, "batch_reward": 0.14945559563487767, "critic_loss": 0.3468336911201477, "actor_loss": -21.45179400253296, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.912161588668823, "step": 55000}
{"episode_reward": 279.52855778835203, "episode": 56.0, "batch_reward": 0.15179082004725933, "critic_loss": 0.3453963918089867, "actor_loss": -20.805115810394287, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.414234399795532, "step": 56000}
{"episode_reward": 225.38995368477882, "episode": 57.0, "batch_reward": 0.15243336354196071, "critic_loss": 0.34811442479491234, "actor_loss": -21.041517971038818, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.410771131515503, "step": 57000}
{"episode_reward": 135.43020884810835, "episode": 58.0, "batch_reward": 0.15340150764584543, "critic_loss": 0.37053106786310674, "actor_loss": -20.81215178489685, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.435293912887573, "step": 58000}
{"episode_reward": 210.0100329106627, "episode": 59.0, "batch_reward": 0.15299984784424306, "critic_loss": 0.36754644006490705, "actor_loss": -21.34106534576416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.415666103363037, "step": 59000}
{"episode_reward": 96.54262148043955, "episode": 60.0, "batch_reward": 0.15346124432235955, "critic_loss": 0.38124251236021517, "actor_loss": -21.875288814544678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.502281188964844, "step": 60000}
{"episode_reward": 274.49929874498577, "episode": 61.0, "batch_reward": 0.15535135680437087, "critic_loss": 0.37948462621867657, "actor_loss": -21.66042463684082, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.46685552597046, "step": 61000}
{"episode_reward": 288.9400193783764, "episode": 62.0, "batch_reward": 0.15717032105475665, "critic_loss": 0.38201893854141233, "actor_loss": -21.13610234069824, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.20159077644348, "step": 62000}
{"episode_reward": 388.55047554840183, "episode": 63.0, "batch_reward": 0.1592100507989526, "critic_loss": 0.42704128140211106, "actor_loss": -21.492442710876464, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.285306930541992, "step": 63000}
{"episode_reward": 118.19794357103598, "episode": 64.0, "batch_reward": 0.1614532989114523, "critic_loss": 0.4526926726102829, "actor_loss": -21.930574077606202, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.180313110351562, "step": 64000}
{"episode_reward": 418.1507108412586, "episode": 65.0, "batch_reward": 0.16540598495304584, "critic_loss": 0.5216338390111923, "actor_loss": -22.08617189216614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.764671564102173, "step": 65000}
{"episode_reward": 287.7784862906413, "episode": 66.0, "batch_reward": 0.16598644982278346, "critic_loss": 0.45968914444744585, "actor_loss": -22.20596538925171, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.327601671218872, "step": 66000}
{"episode_reward": 172.0065289453455, "episode": 67.0, "batch_reward": 0.167063209310174, "critic_loss": 0.473612550675869, "actor_loss": -22.06734879875183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.211014986038208, "step": 67000}
{"episode_reward": 400.0622447857199, "episode": 68.0, "batch_reward": 0.1700087792649865, "critic_loss": 0.5087040777653455, "actor_loss": -22.852410194396974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.720792531967163, "step": 68000}
{"episode_reward": 182.46227844559473, "episode": 69.0, "batch_reward": 0.17131973128020764, "critic_loss": 0.4738567703217268, "actor_loss": -22.9536620388031, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.964617013931274, "step": 69000}
{"episode_reward": 408.61290162959745, "episode": 70.0, "batch_reward": 0.17299093821644784, "critic_loss": 0.46248089891672134, "actor_loss": -23.308174074172975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.91246795654297, "step": 70000}
{"episode_reward": 194.65829199478753, "episode": 71.0, "batch_reward": 0.17178345732390882, "critic_loss": 0.4711461945474148, "actor_loss": -23.263463430404663, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.978474617004395, "step": 71000}
{"episode_reward": 97.64722567833988, "episode": 72.0, "batch_reward": 0.17355508954823018, "critic_loss": 0.46456632907688616, "actor_loss": -23.2013500957489, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.550103664398193, "step": 72000}
{"episode_reward": 349.7134270482859, "episode": 73.0, "batch_reward": 0.17491717204451562, "critic_loss": 0.4583340828716755, "actor_loss": -23.321448343276977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.930786848068237, "step": 73000}
{"episode_reward": 207.396916900526, "episode": 74.0, "batch_reward": 0.1754488355219364, "critic_loss": 0.5291635954231024, "actor_loss": -23.426614545822144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.60905408859253, "step": 74000}
{"episode_reward": 143.7853411969996, "episode": 75.0, "batch_reward": 0.17545169742405414, "critic_loss": 0.44502560010552406, "actor_loss": -23.48324997138977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.806204795837402, "step": 75000}
{"episode_reward": 159.8296175900361, "episode": 76.0, "batch_reward": 0.1762971183359623, "critic_loss": 0.4814968716800213, "actor_loss": -23.548478881835937, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.75473403930664, "step": 76000}
{"episode_reward": 417.8630150634959, "episode": 77.0, "batch_reward": 0.1787256439626217, "critic_loss": 0.4717645096927881, "actor_loss": -23.575951433181764, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.68770933151245, "step": 77000}
{"episode_reward": 413.2220999508122, "episode": 78.0, "batch_reward": 0.18074517340958118, "critic_loss": 0.46225893484055997, "actor_loss": -23.712187602996828, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.647616863250732, "step": 78000}
{"episode_reward": 163.30474830237142, "episode": 79.0, "batch_reward": 0.18087431575357915, "critic_loss": 0.47805024978518484, "actor_loss": -23.556654809951784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.269580602645874, "step": 79000}
{"episode_reward": 249.76959903684286, "episode": 80.0, "batch_reward": 0.18189293219149114, "critic_loss": 0.4556113570034504, "actor_loss": -23.81530533027649, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.104100704193115, "step": 80000}
{"episode_reward": 187.52141868983904, "episode": 81.0, "batch_reward": 0.18311060772836207, "critic_loss": 0.48777222238481044, "actor_loss": -23.77779796600342, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.549349308013916, "step": 81000}
{"episode_reward": 318.54687795159646, "episode": 82.0, "batch_reward": 0.1833412733376026, "critic_loss": 0.4695025520175695, "actor_loss": -23.633299478530883, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.00525665283203, "step": 82000}
{"episode_reward": 267.70255772517527, "episode": 83.0, "batch_reward": 0.18475644558668136, "critic_loss": 0.43972290059924124, "actor_loss": -24.254995691299438, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.745281219482422, "step": 83000}
{"episode_reward": 299.7860237522366, "episode": 84.0, "batch_reward": 0.18658847892284394, "critic_loss": 0.4587264416217804, "actor_loss": -24.25814914703369, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.653205156326294, "step": 84000}
{"episode_reward": 479.4295617132457, "episode": 85.0, "batch_reward": 0.1900102041810751, "critic_loss": 0.47961548826098443, "actor_loss": -24.17944231414795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.408043384552002, "step": 85000}
{"episode_reward": 261.77549821903165, "episode": 86.0, "batch_reward": 0.18908065456151962, "critic_loss": 0.46731172600388526, "actor_loss": -24.20238624572754, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.509990215301514, "step": 86000}
{"episode_reward": 22.45467673826609, "episode": 87.0, "batch_reward": 0.1888556488752365, "critic_loss": 0.4756582841426134, "actor_loss": -24.576677282333375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.915082693099976, "step": 87000}
{"episode_reward": 336.4685920818219, "episode": 88.0, "batch_reward": 0.1899508031308651, "critic_loss": 0.4742559750378132, "actor_loss": -24.540830169677733, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.420372486114502, "step": 88000}
{"episode_reward": 163.61947806419536, "episode": 89.0, "batch_reward": 0.19022469495236874, "critic_loss": 0.48260382148623465, "actor_loss": -24.10936692428589, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.211835145950317, "step": 89000}
{"episode_reward": 315.5656466556879, "episode": 90.0, "batch_reward": 0.19101937825977802, "critic_loss": 0.4765498732477427, "actor_loss": -24.144312311172484, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.702495574951172, "step": 90000}
{"episode_reward": 294.80938926033, "episode": 91.0, "batch_reward": 0.1931933086514473, "critic_loss": 0.4713562154918909, "actor_loss": -24.15644989967346, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.41262435913086, "step": 91000}
{"episode_reward": 420.8460295714509, "episode": 92.0, "batch_reward": 0.1954355676919222, "critic_loss": 0.4936966721266508, "actor_loss": -24.45004684829712, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.689559936523438, "step": 92000}
{"episode_reward": 260.64201894231013, "episode": 93.0, "batch_reward": 0.1962972006946802, "critic_loss": 0.46732014475762845, "actor_loss": -24.5349898147583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.65019917488098, "step": 93000}
{"episode_reward": 503.71094581172076, "episode": 94.0, "batch_reward": 0.20038929617404938, "critic_loss": 0.4974833316206932, "actor_loss": -24.81803630447388, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.630921125411987, "step": 94000}
{"episode_reward": 475.4477745513711, "episode": 95.0, "batch_reward": 0.20211897230148315, "critic_loss": 0.47069694255292416, "actor_loss": -25.13166223144531, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.935629844665527, "step": 95000}
{"episode_reward": 341.8887249603929, "episode": 96.0, "batch_reward": 0.20343343915045262, "critic_loss": 0.48992723298072816, "actor_loss": -25.230023067474367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.959117650985718, "step": 96000}
{"episode_reward": 326.79975523215575, "episode": 97.0, "batch_reward": 0.2052139308154583, "critic_loss": 0.45337027937173846, "actor_loss": -25.259706089019776, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.225088596343994, "step": 97000}
{"episode_reward": 469.9539502331674, "episode": 98.0, "batch_reward": 0.20754175263643265, "critic_loss": 0.4382838810533285, "actor_loss": -25.175794410705567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.665085077285767, "step": 98000}
{"episode_reward": 475.03151946432274, "episode": 99.0, "batch_reward": 0.21119362293183805, "critic_loss": 0.4178189242631197, "actor_loss": -26.050648735046387, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.854702472686768, "step": 99000}
{"episode_reward": 461.0169874591841, "episode": 100.0, "batch_reward": 0.21331328628957272, "critic_loss": 0.4333878725171089, "actor_loss": -26.152650089263915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.98978066444397, "step": 100000}
{"episode_reward": 339.8826267976997, "episode": 101.0, "batch_reward": 0.21501899534463884, "critic_loss": 0.4099970673471689, "actor_loss": -26.052003574371337, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.633740186691284, "step": 101000}
{"episode_reward": 496.2814916159075, "episode": 102.0, "batch_reward": 0.21696273128688334, "critic_loss": 0.4096224120557308, "actor_loss": -26.20938372039795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.576403856277466, "step": 102000}
{"episode_reward": 439.29140642250275, "episode": 103.0, "batch_reward": 0.21917305791378022, "critic_loss": 0.4268991053551435, "actor_loss": -26.32077672958374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.69045114517212, "step": 103000}
{"episode_reward": 261.94659761611484, "episode": 104.0, "batch_reward": 0.21785478752851486, "critic_loss": 0.41439787817001345, "actor_loss": -26.372411804199217, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.918867349624634, "step": 104000}
{"episode_reward": 111.96522312585877, "episode": 105.0, "batch_reward": 0.21830177283287047, "critic_loss": 0.434514908567071, "actor_loss": -26.12485040283203, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.602431297302246, "step": 105000}
{"episode_reward": 164.3909841574462, "episode": 106.0, "batch_reward": 0.21792807464301586, "critic_loss": 0.4231645219624042, "actor_loss": -26.258299976348876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.323843002319336, "step": 106000}
{"episode_reward": 374.8722122000774, "episode": 107.0, "batch_reward": 0.2195630642771721, "critic_loss": 0.45072299034893515, "actor_loss": -26.224359146118164, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.42865753173828, "step": 107000}
{"episode_reward": 355.3498146651785, "episode": 108.0, "batch_reward": 0.2199609425663948, "critic_loss": 0.4410968481451273, "actor_loss": -25.65778563308716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.546945571899414, "step": 108000}
{"episode_reward": 476.5079323208417, "episode": 109.0, "batch_reward": 0.22233162853121757, "critic_loss": 0.4435207953006029, "actor_loss": -26.60968953704834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.835657596588135, "step": 109000}
{"episode_reward": 272.5329552951743, "episode": 110.0, "batch_reward": 0.22397227320075036, "critic_loss": 0.4283476007729769, "actor_loss": -26.710520149230955, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.29363775253296, "step": 110000}
{"episode_reward": 496.0311360129384, "episode": 111.0, "batch_reward": 0.22533966188132762, "critic_loss": 0.4363861545622349, "actor_loss": -26.080477390289307, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.36755847930908, "step": 111000}
{"episode_reward": 457.48000048809917, "episode": 112.0, "batch_reward": 0.2289366238564253, "critic_loss": 0.4953290192037821, "actor_loss": -27.200058559417723, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.08545732498169, "step": 112000}
{"episode_reward": 529.830093253749, "episode": 113.0, "batch_reward": 0.23183583085238935, "critic_loss": 0.4324690764844418, "actor_loss": -27.147418113708497, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.80784797668457, "step": 113000}
{"episode_reward": 579.4989078765108, "episode": 114.0, "batch_reward": 0.23485523967444896, "critic_loss": 0.4398539383560419, "actor_loss": -27.41171097946167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.622429132461548, "step": 114000}
{"episode_reward": 562.2041630625033, "episode": 115.0, "batch_reward": 0.23625757317245005, "critic_loss": 0.45137353223562243, "actor_loss": -27.35700940322876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.758882522583008, "step": 115000}
{"episode_reward": 414.1951840876067, "episode": 116.0, "batch_reward": 0.2391828666329384, "critic_loss": 0.4858906111717224, "actor_loss": -27.57484062194824, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.634609699249268, "step": 116000}
{"episode_reward": 479.7145542298833, "episode": 117.0, "batch_reward": 0.2405626450330019, "critic_loss": 0.46259861591458323, "actor_loss": -27.157205795288085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.314997911453247, "step": 117000}
{"episode_reward": 449.8543742982783, "episode": 118.0, "batch_reward": 0.2426416134983301, "critic_loss": 0.4707303606569767, "actor_loss": -27.68891487121582, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.036505460739136, "step": 118000}
{"episode_reward": 393.5431486961342, "episode": 119.0, "batch_reward": 0.24243257859349251, "critic_loss": 0.46569284749031065, "actor_loss": -27.704174266815187, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.517472982406616, "step": 119000}
{"episode_reward": 182.06265960649364, "episode": 120.0, "batch_reward": 0.24222147420048715, "critic_loss": 0.4817413817048073, "actor_loss": -27.407452396392824, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.158794164657593, "step": 120000}
{"episode_reward": 521.779251412958, "episode": 121.0, "batch_reward": 0.2451163093149662, "critic_loss": 0.4648190647661686, "actor_loss": -27.54901135253906, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.63452363014221, "step": 121000}
{"episode_reward": 594.9631699644259, "episode": 122.0, "batch_reward": 0.24850844910740852, "critic_loss": 0.4662261451035738, "actor_loss": -28.00303554916382, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.846603393554688, "step": 122000}
{"episode_reward": 536.0590830642343, "episode": 123.0, "batch_reward": 0.25047803823649883, "critic_loss": 0.46776149518787863, "actor_loss": -28.44975421142578, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.391652584075928, "step": 123000}
{"episode_reward": 526.2909326850382, "episode": 124.0, "batch_reward": 0.25217204402387144, "critic_loss": 0.45652448970079423, "actor_loss": -28.51508535385132, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.338446378707886, "step": 124000}
{"episode_reward": 485.5308410914597, "episode": 125.0, "batch_reward": 0.2548999056220055, "critic_loss": 0.4698657072931528, "actor_loss": -28.824740158081056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.679380893707275, "step": 125000}
{"episode_reward": 516.0142903499941, "episode": 126.0, "batch_reward": 0.2575318901389837, "critic_loss": 0.4597803945094347, "actor_loss": -28.703054588317872, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.083247184753418, "step": 126000}
{"episode_reward": 574.2861951340064, "episode": 127.0, "batch_reward": 0.2590298729389906, "critic_loss": 0.4283930741101503, "actor_loss": -29.3433602142334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.136486530303955, "step": 127000}
{"episode_reward": 509.3744723927414, "episode": 128.0, "batch_reward": 0.2613771257400513, "critic_loss": 0.4572893620431423, "actor_loss": -29.266931636810302, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.429694175720215, "step": 128000}
{"episode_reward": 582.0108894827129, "episode": 129.0, "batch_reward": 0.2635033480376005, "critic_loss": 0.45577218940854075, "actor_loss": -29.204942451477052, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.76112961769104, "step": 129000}
{"episode_reward": 314.4385136059973, "episode": 130.0, "batch_reward": 0.26467366655170915, "critic_loss": 0.4446159492433071, "actor_loss": -29.26880850601196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.562418222427368, "step": 130000}
{"episode_reward": 553.1586302628607, "episode": 131.0, "batch_reward": 0.2662556481361389, "critic_loss": 0.4238355969041586, "actor_loss": -29.846851379394533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.40942621231079, "step": 131000}
{"episode_reward": 549.7539720457232, "episode": 132.0, "batch_reward": 0.2680439733713865, "critic_loss": 0.45247106938064097, "actor_loss": -30.00411771774292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.16276526451111, "step": 132000}
{"episode_reward": 569.0852518743885, "episode": 133.0, "batch_reward": 0.27137005725502966, "critic_loss": 0.4747529260665178, "actor_loss": -29.708194686889648, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.36811089515686, "step": 133000}
{"episode_reward": 583.4793841693706, "episode": 134.0, "batch_reward": 0.2724333577752113, "critic_loss": 0.4365455007404089, "actor_loss": -29.533924011230468, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.81885004043579, "step": 134000}
{"episode_reward": 555.7104850293957, "episode": 135.0, "batch_reward": 0.27540005995333194, "critic_loss": 0.45583035598695276, "actor_loss": -30.61957072067261, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.15171718597412, "step": 135000}
{"episode_reward": 576.8470338354944, "episode": 136.0, "batch_reward": 0.2777638880908489, "critic_loss": 0.43707155944406983, "actor_loss": -29.816007217407225, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.246343851089478, "step": 136000}
{"episode_reward": 572.8855134369974, "episode": 137.0, "batch_reward": 0.27861584568023684, "critic_loss": 0.4743113085627556, "actor_loss": -30.756858055114748, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.23507022857666, "step": 137000}
{"episode_reward": 225.65383597149864, "episode": 138.0, "batch_reward": 0.2801816286742687, "critic_loss": 0.43818615007400513, "actor_loss": -30.61211432647705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.59550142288208, "step": 138000}
{"episode_reward": 617.5110676646517, "episode": 139.0, "batch_reward": 0.28314112712442874, "critic_loss": 0.44767957292497157, "actor_loss": -30.992217811584474, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.65203595161438, "step": 139000}
{"episode_reward": 292.3737080946977, "episode": 140.0, "batch_reward": 0.28309878638386726, "critic_loss": 0.4672861530482769, "actor_loss": -31.042765491485596, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.52033805847168, "step": 140000}
{"episode_reward": 570.5861521522005, "episode": 141.0, "batch_reward": 0.2839835048168898, "critic_loss": 0.4256620659977198, "actor_loss": -31.207624439239503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.58042311668396, "step": 141000}
{"episode_reward": 579.0210829180464, "episode": 142.0, "batch_reward": 0.2845252970457077, "critic_loss": 0.46547449815273284, "actor_loss": -30.811206924438476, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.631436824798584, "step": 142000}
{"episode_reward": 527.2084758199221, "episode": 143.0, "batch_reward": 0.28701443776488306, "critic_loss": 0.42602914991974833, "actor_loss": -30.88018185043335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.659034252166748, "step": 143000}
{"episode_reward": 551.3999527023566, "episode": 144.0, "batch_reward": 0.28841863030195236, "critic_loss": 0.43811444610357286, "actor_loss": -31.658283840179443, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.155422687530518, "step": 144000}
{"episode_reward": 112.07781528789921, "episode": 145.0, "batch_reward": 0.28843391509354116, "critic_loss": 0.4296929195672274, "actor_loss": -31.412344814300535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.51573920249939, "step": 145000}
{"episode_reward": 392.8411890438418, "episode": 146.0, "batch_reward": 0.2890553512126207, "critic_loss": 0.43742837914824484, "actor_loss": -31.5745227394104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.887569904327393, "step": 146000}
{"episode_reward": 612.217806881403, "episode": 147.0, "batch_reward": 0.2907641868442297, "critic_loss": 0.44981406517326833, "actor_loss": -31.69329705429077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.777534246444702, "step": 147000}
{"episode_reward": 608.0780258966505, "episode": 148.0, "batch_reward": 0.2942746694236994, "critic_loss": 0.4368602239489555, "actor_loss": -31.916111988067627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.58219814300537, "step": 148000}
{"episode_reward": 582.946136230325, "episode": 149.0, "batch_reward": 0.29479499562084677, "critic_loss": 0.47124419450759886, "actor_loss": -31.962915622711183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.607505798339844, "step": 149000}
{"episode_reward": 529.9445538309957, "episode": 150.0, "batch_reward": 0.29691761028766633, "critic_loss": 0.47534649129211903, "actor_loss": -32.2693754234314, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
