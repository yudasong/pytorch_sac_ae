{"episode": 1.0, "duration": 15.906695127487183, "episode_reward": 7.300100444933085, "step": 1000}
{"episode": 2.0, "duration": 1.6123640537261963, "episode_reward": 521.6090064697321, "step": 2000}
{"episode": 3.0, "batch_reward": 0.2533507805669177, "actor_loss": -43.82821954770678, "actor_target_entropy": -6.0, "alpha_value": 0.010699999250839183, "duration": 64.84186124801636, "episode_reward": 132.65330905529885, "step": 3000}
{"episode": 4.0, "batch_reward": 0.22342750343680381, "actor_loss": -41.54712961578369, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.79177737236023, "episode_reward": 254.52817072808156, "step": 4000}
{"episode": 5.0, "batch_reward": 0.23165775619447232, "actor_loss": -40.96497238922119, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.61226511001587, "episode_reward": 178.76865597109023, "step": 5000}
{"episode": 6.0, "batch_reward": 0.2181905706524849, "actor_loss": -38.276209815979, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.294737815856934, "episode_reward": 200.48260791494712, "step": 6000}
{"episode": 7.0, "batch_reward": 0.21867887902259828, "actor_loss": -37.39900340270996, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.11604356765747, "episode_reward": 277.1179363318645, "step": 7000}
{"episode": 8.0, "batch_reward": 0.22347423474490644, "actor_loss": -37.92681847381592, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.967008352279663, "episode_reward": 279.4931836690015, "step": 8000}
{"episode": 9.0, "batch_reward": 0.2308921489417553, "actor_loss": -37.885044380187985, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.773827075958252, "episode_reward": 163.1615192444915, "step": 9000}
{"episode": 10.0, "batch_reward": 0.2196755516976118, "actor_loss": -35.487649600982664, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.959025144577026, "episode_reward": 88.150875092815, "step": 10000}
{"episode": 11.0, "batch_reward": 0.2050763421356678, "actor_loss": -33.35843939208984, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.594879150390625, "episode_reward": 63.16756460490481, "step": 11000}
{"episode": 12.0, "batch_reward": 0.20288813909888267, "actor_loss": -32.83522004699707, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.25279188156128, "episode_reward": 363.2567425145189, "step": 12000}
{"episode": 13.0, "batch_reward": 0.2109244524538517, "actor_loss": -33.30089525985718, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.725709199905396, "episode_reward": 153.8440904548483, "step": 13000}
{"episode": 14.0, "batch_reward": 0.19949772107601166, "actor_loss": -31.57931970214844, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.5736985206604, "episode_reward": 20.695350022830276, "step": 14000}
{"episode": 15.0, "batch_reward": 0.198487052410841, "actor_loss": -31.39521452331543, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.56368398666382, "episode_reward": 360.6476888171721, "step": 15000}
{"episode": 16.0, "batch_reward": 0.20345487236976623, "actor_loss": -31.913934131622316, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.526371479034424, "episode_reward": 141.06746293856756, "step": 16000}
{"episode": 17.0, "batch_reward": 0.19766670885682106, "actor_loss": -31.0734779548645, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.78264546394348, "episode_reward": 67.60218631319889, "step": 17000}
{"episode": 18.0, "batch_reward": 0.19665232127904891, "actor_loss": -30.843177352905272, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.062299013137817, "episode_reward": 335.7182640470269, "step": 18000}
{"episode": 19.0, "batch_reward": 0.2025669603049755, "actor_loss": -31.62569432449341, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.930782794952393, "episode_reward": 316.64655650819867, "step": 19000}
{"episode": 20.0, "batch_reward": 0.2045299836397171, "actor_loss": -31.72930551147461, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.008158683776855, "episode_reward": 94.10533530030018, "step": 20000}
{"episode": 21.0, "batch_reward": 0.2026778431981802, "actor_loss": -31.4850634765625, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 37.50752282142639, "episode_reward": 276.08117850116827, "step": 21000}
{"episode": 22.0, "batch_reward": 0.20749659246206284, "actor_loss": -31.96107197189331, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.44201922416687, "episode_reward": 328.2873014078865, "step": 22000}
{"episode": 23.0, "batch_reward": 0.21296474850177766, "actor_loss": -32.428893451690676, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.54722833633423, "episode_reward": 353.22100171406834, "step": 23000}
{"episode": 24.0, "batch_reward": 0.21918242132663726, "actor_loss": -33.03202467727661, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.91741704940796, "episode_reward": 387.8842170726611, "step": 24000}
{"episode": 25.0, "batch_reward": 0.22497644011676313, "actor_loss": -33.522800685882565, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.514010667800903, "episode_reward": 291.5334254517047, "step": 25000}
{"episode": 26.0, "batch_reward": 0.2284439822882414, "actor_loss": -33.79579933166504, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.613526105880737, "episode_reward": 381.0599942243203, "step": 26000}
{"episode": 27.0, "batch_reward": 0.23192326076328754, "actor_loss": -33.88712133026123, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.665578365325928, "episode_reward": 130.7991268971989, "step": 27000}
{"episode": 28.0, "batch_reward": 0.2289106272608042, "actor_loss": -33.465481758117676, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.08501362800598, "episode_reward": 294.127313090528, "step": 28000}
{"episode": 29.0, "batch_reward": 0.23240261293947698, "actor_loss": -33.96390129852295, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.87230682373047, "episode_reward": 360.1775603233566, "step": 29000}
{"episode": 30.0, "batch_reward": 0.2357931242287159, "actor_loss": -34.142041328430174, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.227354526519775, "episode_reward": 244.53841004095042, "step": 30000}
{"episode": 31.0, "batch_reward": 0.23701143723726273, "actor_loss": -34.24769413757324, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 39.655139207839966, "episode_reward": 409.73541253870155, "step": 31000}
{"episode": 32.0, "batch_reward": 0.24225256602466105, "actor_loss": -34.5911981086731, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.22015070915222, "episode_reward": 276.35367585872007, "step": 32000}
{"episode": 33.0, "batch_reward": 0.2435773420780897, "actor_loss": -34.73565310287476, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.735482454299927, "episode_reward": 368.8361198800014, "step": 33000}
{"episode": 34.0, "batch_reward": 0.24770769676566123, "actor_loss": -35.04099398422241, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.447317600250244, "episode_reward": 390.89654840130567, "step": 34000}
{"episode": 35.0, "batch_reward": 0.25062214466929433, "actor_loss": -35.32948393630981, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.692705631256104, "episode_reward": 243.3908479756683, "step": 35000}
{"episode": 36.0, "batch_reward": 0.25263413704931736, "actor_loss": -35.24000966644287, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.981993436813354, "episode_reward": 444.90332587121844, "step": 36000}
{"episode": 37.0, "batch_reward": 0.256434554412961, "actor_loss": -35.6305722618103, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.634116888046265, "episode_reward": 337.40695996837536, "step": 37000}
{"episode": 38.0, "batch_reward": 0.25902277263998985, "actor_loss": -35.73654286956787, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.622312307357788, "episode_reward": 413.6679517607163, "step": 38000}
{"episode": 39.0, "batch_reward": 0.2616869374960661, "actor_loss": -35.91832886505127, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.67310333251953, "episode_reward": 142.4170024767256, "step": 39000}
{"episode": 40.0, "batch_reward": 0.2586900491863489, "actor_loss": -35.352148216247556, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.028353929519653, "episode_reward": 220.99780459538368, "step": 40000}
{"episode": 41.0, "batch_reward": 0.2591216425001621, "actor_loss": -35.3453925857544, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 39.535128593444824, "episode_reward": 485.1894821321819, "step": 41000}
{"episode": 42.0, "batch_reward": 0.2640950858592987, "actor_loss": -35.734436107635496, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.482000589370728, "episode_reward": 234.76995490763238, "step": 42000}
{"episode": 43.0, "batch_reward": 0.2645174589902163, "actor_loss": -35.534314067840576, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.671876668930054, "episode_reward": 390.3018419472829, "step": 43000}
{"episode": 44.0, "batch_reward": 0.2669771973490715, "actor_loss": -35.85629983520508, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.090468406677246, "episode_reward": 267.11584454102405, "step": 44000}
{"episode": 45.0, "batch_reward": 0.2662807016223669, "actor_loss": -35.63448338317871, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.790405988693237, "episode_reward": 261.53252941968987, "step": 45000}
{"episode": 46.0, "batch_reward": 0.26742409461736677, "actor_loss": -35.723910987854005, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.965821504592896, "episode_reward": 416.6910536765798, "step": 46000}
{"episode": 47.0, "batch_reward": 0.26980642922222614, "actor_loss": -36.008209270477295, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.56560182571411, "episode_reward": 378.06918184370363, "step": 47000}
{"episode": 48.0, "batch_reward": 0.2730631274729967, "actor_loss": -36.296341613769535, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.42753505706787, "episode_reward": 444.50667706116116, "step": 48000}
{"episode": 49.0, "batch_reward": 0.27577573582530024, "actor_loss": -36.51207286834717, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.25752830505371, "episode_reward": 332.0422143597853, "step": 49000}
{"episode": 50.0, "batch_reward": 0.27744881346821787, "actor_loss": -36.51221630477905, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.591460704803467, "episode_reward": 291.8062917257149, "step": 50000}
{"episode": 51.0, "batch_reward": 0.2774415114969015, "actor_loss": -36.618330474853515, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 38.47959852218628, "episode_reward": 403.9829404061532, "step": 51000}
{"episode": 52.0, "batch_reward": 0.2805807711035013, "actor_loss": -36.84010362243652, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.347160577774048, "episode_reward": 410.39432687354525, "step": 52000}
{"episode": 53.0, "batch_reward": 0.2813289108723402, "actor_loss": -36.76458899307251, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.08499050140381, "episode_reward": 418.2211830718041, "step": 53000}
{"episode": 54.0, "batch_reward": 0.2866548940241337, "actor_loss": -37.36473342895508, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.949727535247803, "episode_reward": 442.332053167483, "step": 54000}
{"episode": 55.0, "batch_reward": 0.28691429303586485, "actor_loss": -37.4195922241211, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.18604850769043, "episode_reward": 390.939871257947, "step": 55000}
{"episode": 56.0, "batch_reward": 0.2874616401344538, "actor_loss": -37.294983959198, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.54071807861328, "episode_reward": 66.44705651898126, "step": 56000}
{"episode": 57.0, "batch_reward": 0.28562406420707703, "actor_loss": -37.1390164642334, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.742754459381104, "episode_reward": 438.5482216002876, "step": 57000}
{"episode": 58.0, "batch_reward": 0.2886139751523733, "actor_loss": -37.3797161026001, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.961448907852173, "episode_reward": 472.5853556234571, "step": 58000}
{"episode": 59.0, "batch_reward": 0.2925851891040802, "actor_loss": -37.79590802764893, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.6608567237854, "episode_reward": 498.1312867336123, "step": 59000}
{"episode": 60.0, "batch_reward": 0.2951182980984449, "actor_loss": -37.98684061813354, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.88556146621704, "episode_reward": 504.6766138974755, "step": 60000}
{"episode": 61.0, "batch_reward": 0.29844448933005335, "actor_loss": -38.445817657470705, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 38.25602674484253, "episode_reward": 414.12671094288817, "step": 61000}
{"episode": 62.0, "batch_reward": 0.2971047794222832, "actor_loss": -38.224548721313475, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.861676692962646, "episode_reward": 63.30683507617663, "step": 62000}
{"episode": 63.0, "batch_reward": 0.2958259870707989, "actor_loss": -37.89027592468262, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.35501527786255, "episode_reward": 356.16544674870505, "step": 63000}
{"episode": 64.0, "batch_reward": 0.2986015758216381, "actor_loss": -38.30089212799072, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.851765632629395, "episode_reward": 533.4615419703802, "step": 64000}
{"episode": 65.0, "batch_reward": 0.30102083274722097, "actor_loss": -38.51404845428467, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.059049367904663, "episode_reward": 436.57906102958196, "step": 65000}
{"episode": 66.0, "batch_reward": 0.3032434168457985, "actor_loss": -38.70647214508057, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.83272886276245, "episode_reward": 487.48547550549983, "step": 66000}
{"episode": 67.0, "batch_reward": 0.30531016194820404, "actor_loss": -38.79373829650879, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.50053071975708, "episode_reward": 424.88212882774314, "step": 67000}
{"episode": 68.0, "batch_reward": 0.3082896576523781, "actor_loss": -39.22630461883545, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.5551118850708, "episode_reward": 425.30980762657583, "step": 68000}
{"episode": 69.0, "batch_reward": 0.30925666564702986, "actor_loss": -39.16638405609131, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.129522562026978, "episode_reward": 528.7271672764502, "step": 69000}
{"episode": 70.0, "batch_reward": 0.31183749535679817, "actor_loss": -39.44688972473145, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.59782099723816, "episode_reward": 306.4420933798774, "step": 70000}
{"episode": 71.0, "batch_reward": 0.31324456855654714, "actor_loss": -39.49842119598389, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 38.3623411655426, "episode_reward": 493.88207581972136, "step": 71000}
{"episode": 72.0, "batch_reward": 0.314103937625885, "actor_loss": -39.602920860290524, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.444660186767578, "episode_reward": 314.8675804559504, "step": 72000}
{"episode": 73.0, "batch_reward": 0.31425502303242686, "actor_loss": -39.646471138000486, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.852871656417847, "episode_reward": 458.23357567810785, "step": 73000}
{"episode": 74.0, "batch_reward": 0.3173957488834858, "actor_loss": -39.910239921569826, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.923842191696167, "episode_reward": 477.65656790975663, "step": 74000}
{"episode": 75.0, "batch_reward": 0.31890146535634994, "actor_loss": -40.0213164138794, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.86414623260498, "episode_reward": 456.6572968426705, "step": 75000}
{"episode": 76.0, "batch_reward": 0.3196411646604538, "actor_loss": -40.19980060577392, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.664469242095947, "episode_reward": 148.57222432693098, "step": 76000}
{"episode": 77.0, "batch_reward": 0.31920207846164705, "actor_loss": -40.08707349395752, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.752500772476196, "episode_reward": 444.82666573067945, "step": 77000}
{"episode": 78.0, "batch_reward": 0.32112500062584876, "actor_loss": -40.243717544555665, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.72784996032715, "episode_reward": 521.8958934737498, "step": 78000}
{"episode": 79.0, "batch_reward": 0.32301977586746217, "actor_loss": -40.459602493286134, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.789228200912476, "episode_reward": 442.4698061028739, "step": 79000}
{"episode": 80.0, "batch_reward": 0.3245884334743023, "actor_loss": -40.431798065185546, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.839747190475464, "episode_reward": 402.14060746550587, "step": 80000}
{"episode": 81.0, "batch_reward": 0.32378234922885896, "actor_loss": -40.499328086853026, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 39.67543077468872, "episode_reward": 174.2749839557717, "step": 81000}
{"episode": 82.0, "batch_reward": 0.3245089382827282, "actor_loss": -40.60154196929932, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.71952486038208, "episode_reward": 482.86563455905326, "step": 82000}
{"episode": 83.0, "batch_reward": 0.32457531115412713, "actor_loss": -40.673573402404784, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.238938570022583, "episode_reward": 446.062345737387, "step": 83000}
{"episode": 84.0, "batch_reward": 0.3271930785179138, "actor_loss": -40.721829933166504, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.83683967590332, "episode_reward": 472.050505346869, "step": 84000}
{"episode": 85.0, "batch_reward": 0.3287215610742569, "actor_loss": -40.987753074645994, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.106030225753784, "episode_reward": 508.9172451377312, "step": 85000}
{"episode": 86.0, "batch_reward": 0.3293012557923794, "actor_loss": -41.07487615203858, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.907548427581787, "episode_reward": 420.1676578887428, "step": 86000}
{"episode": 87.0, "batch_reward": 0.3320921815931797, "actor_loss": -41.284401763916016, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.616772651672363, "episode_reward": 229.97817524371035, "step": 87000}
{"episode": 88.0, "batch_reward": 0.33193071907758714, "actor_loss": -41.13261197662354, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.872619152069092, "episode_reward": 402.1336033039625, "step": 88000}
{"episode": 89.0, "batch_reward": 0.331605645686388, "actor_loss": -41.07883475494385, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.848702669143677, "episode_reward": 505.16438419785516, "step": 89000}
{"episode": 90.0, "batch_reward": 0.33027673491835596, "actor_loss": -40.71833553314209, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.8622944355011, "episode_reward": 58.365811562506416, "step": 90000}
{"episode": 91.0, "batch_reward": 0.3303113924860954, "actor_loss": -40.813808166503904, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 40.94533610343933, "episode_reward": 476.6423130208692, "step": 91000}
{"episode": 92.0, "batch_reward": 0.3303014692664146, "actor_loss": -40.83757695770264, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.64133334159851, "episode_reward": 81.97585066067788, "step": 92000}
{"episode": 93.0, "batch_reward": 0.32981672456860545, "actor_loss": -40.92475946807861, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.827231884002686, "episode_reward": 487.7813240990271, "step": 93000}
{"episode": 94.0, "batch_reward": 0.330657976090908, "actor_loss": -40.871082710266116, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.841736316680908, "episode_reward": 147.44897318067186, "step": 94000}
{"episode": 95.0, "batch_reward": 0.329252032071352, "actor_loss": -40.73173067474365, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.647422075271606, "episode_reward": 480.7981378258522, "step": 95000}
{"episode": 96.0, "batch_reward": 0.33074374467134476, "actor_loss": -40.95561096954346, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.56302809715271, "episode_reward": 100.12078908448187, "step": 96000}
{"episode": 97.0, "batch_reward": 0.3281187527179718, "actor_loss": -40.64214520263672, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.976719856262207, "episode_reward": 372.881170160306, "step": 97000}
{"episode": 98.0, "batch_reward": 0.3278421564996242, "actor_loss": -40.46613497161865, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.757054567337036, "episode_reward": 411.55387299647253, "step": 98000}
{"episode": 99.0, "batch_reward": 0.32926671704649924, "actor_loss": -40.690961471557614, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.695332288742065, "episode_reward": 445.9088623547524, "step": 99000}
{"episode": 100.0, "batch_reward": 0.3303686189651489, "actor_loss": -40.8120150756836, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.796509742736816, "episode_reward": 532.00635132247, "step": 100000}
{"episode": 101.0, "batch_reward": 0.3310982776880264, "actor_loss": -40.81881951141357, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 41.09301781654358, "episode_reward": 103.0492043119244, "step": 101000}
{"episode": 102.0, "batch_reward": 0.33136005598306656, "actor_loss": -40.77182474517822, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.114450216293335, "episode_reward": 494.2949016954829, "step": 102000}
{"episode": 103.0, "batch_reward": 0.3322407149374485, "actor_loss": -40.91827651977539, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.341426372528076, "episode_reward": 252.1839424128661, "step": 103000}
{"episode": 104.0, "batch_reward": 0.3310528225004673, "actor_loss": -40.69216333770752, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.22838068008423, "episode_reward": 525.9997044711624, "step": 104000}
{"episode": 105.0, "batch_reward": 0.332988826662302, "actor_loss": -40.846565979003906, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.511929988861084, "episode_reward": 504.18551950752095, "step": 105000}
{"episode": 106.0, "batch_reward": 0.3350747791230679, "actor_loss": -41.05092181396484, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.820979356765747, "episode_reward": 508.51731853911537, "step": 106000}
{"episode": 107.0, "batch_reward": 0.33681928119063376, "actor_loss": -41.27966171264649, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.653684854507446, "episode_reward": 478.6822582461391, "step": 107000}
{"episode": 108.0, "batch_reward": 0.33774786069989204, "actor_loss": -41.28912831115723, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.08231830596924, "episode_reward": 497.2585810466619, "step": 108000}
{"episode": 109.0, "batch_reward": 0.33853946751356123, "actor_loss": -41.46388136291504, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.194371223449707, "episode_reward": 235.13649959754864, "step": 109000}
{"episode": 110.0, "batch_reward": 0.33784710538387297, "actor_loss": -41.27572760009765, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.87190890312195, "episode_reward": 520.6485310679215, "step": 110000}
{"episode": 111.0, "batch_reward": 0.3390260213315487, "actor_loss": -41.28771530914307, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 41.004820585250854, "episode_reward": 118.20685242902411, "step": 111000}
{"episode": 112.0, "batch_reward": 0.33772267630696295, "actor_loss": -41.18550161743164, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.11368680000305, "episode_reward": 490.12300728336004, "step": 112000}
{"episode": 113.0, "batch_reward": 0.3394048210680485, "actor_loss": -41.304820297241214, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.56174087524414, "episode_reward": 323.35555935572387, "step": 113000}
{"episode": 114.0, "batch_reward": 0.3394562621116638, "actor_loss": -41.373944145202636, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.633862257003784, "episode_reward": 431.35759968134823, "step": 114000}
{"episode": 115.0, "batch_reward": 0.3406446367502213, "actor_loss": -41.58654622650146, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.889772653579712, "episode_reward": 500.26919488221665, "step": 115000}
{"episode": 116.0, "batch_reward": 0.3416234886944294, "actor_loss": -41.53640370178223, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.194308042526245, "episode_reward": 529.853454915632, "step": 116000}
{"episode": 117.0, "batch_reward": 0.3431399396061897, "actor_loss": -41.60346022796631, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.03350305557251, "episode_reward": 120.47827453403598, "step": 117000}
{"episode": 118.0, "batch_reward": 0.34122584173083303, "actor_loss": -41.589798484802245, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.071960926055908, "episode_reward": 390.74131306190327, "step": 118000}
{"episode": 119.0, "batch_reward": 0.3411008175909519, "actor_loss": -41.39423031616211, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.809346437454224, "episode_reward": 522.5448414507018, "step": 119000}
{"episode": 120.0, "batch_reward": 0.34358829897642135, "actor_loss": -41.72128327178955, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.50195813179016, "episode_reward": 476.65759393860475, "step": 120000}
{"episode": 121.0, "batch_reward": 0.3439682618379593, "actor_loss": -41.78751372528076, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 40.932793855667114, "episode_reward": 470.20534576203363, "step": 121000}
{"episode": 122.0, "batch_reward": 0.3454400654435158, "actor_loss": -41.85953993988037, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.691899061203003, "episode_reward": 500.9125222905817, "step": 122000}
{"episode": 123.0, "batch_reward": 0.3457440581321716, "actor_loss": -41.90809051513672, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.05051612854004, "episode_reward": 453.7200604991167, "step": 123000}
{"episode": 124.0, "batch_reward": 0.34701335421204565, "actor_loss": -42.05595025634766, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.503084421157837, "episode_reward": 487.4861152063614, "step": 124000}
{"episode": 125.0, "batch_reward": 0.34782703018188477, "actor_loss": -41.99751530456543, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.540383338928223, "episode_reward": 434.7230113660825, "step": 125000}
{"episode": 126.0, "batch_reward": 0.3497578756213188, "actor_loss": -42.2646554107666, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.33059549331665, "episode_reward": 479.66371732595024, "step": 126000}
{"episode": 127.0, "batch_reward": 0.35171742364764214, "actor_loss": -42.50416870117188, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.877025365829468, "episode_reward": 507.8155045473221, "step": 127000}
{"episode": 128.0, "batch_reward": 0.3515729530751705, "actor_loss": -42.40984261322021, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.588122844696045, "episode_reward": 525.7926720487063, "step": 128000}
{"episode": 129.0, "batch_reward": 0.3513887568414211, "actor_loss": -42.36938256072998, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.864120483398438, "episode_reward": 513.7254579244963, "step": 129000}
{"episode": 130.0, "batch_reward": 0.3538291037082672, "actor_loss": -42.70356450653076, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.83631181716919, "episode_reward": 443.443598241984, "step": 130000}
{"episode": 131.0, "batch_reward": 0.3553085639476776, "actor_loss": -42.609371673583986, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 41.29187345504761, "episode_reward": 504.29048545931636, "step": 131000}
{"episode": 132.0, "batch_reward": 0.35643081679940225, "actor_loss": -42.86522312927246, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.001096487045288, "episode_reward": 554.1719967180238, "step": 132000}
{"episode": 133.0, "batch_reward": 0.3569041915237904, "actor_loss": -42.90494388580322, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.30419111251831, "episode_reward": 560.3447395397013, "step": 133000}
{"episode": 134.0, "batch_reward": 0.3587135655283928, "actor_loss": -43.09647358703613, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.51876950263977, "episode_reward": 504.2471416961464, "step": 134000}
{"episode": 135.0, "batch_reward": 0.3605863883495331, "actor_loss": -43.323329299926755, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.481080770492554, "episode_reward": 425.57888087325904, "step": 135000}
{"episode": 136.0, "batch_reward": 0.3606188359260559, "actor_loss": -43.25409627532959, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.113645553588867, "episode_reward": 367.8244013789433, "step": 136000}
{"episode": 137.0, "batch_reward": 0.36013915690779685, "actor_loss": -43.21225463867187, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.92269515991211, "episode_reward": 551.9905896426202, "step": 137000}
{"episode": 138.0, "batch_reward": 0.36275093123316765, "actor_loss": -43.404657875061034, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.69922137260437, "episode_reward": 552.4181041436243, "step": 138000}
{"episode": 139.0, "batch_reward": 0.3642446739375591, "actor_loss": -43.49585785675049, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.692811250686646, "episode_reward": 441.39227449113827, "step": 139000}
{"episode": 140.0, "batch_reward": 0.3649536987245083, "actor_loss": -43.60930643463135, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.748904705047607, "episode_reward": 523.5932551006547, "step": 140000}
{"episode": 141.0, "batch_reward": 0.3655933735072613, "actor_loss": -43.72948830413819, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 41.041797399520874, "episode_reward": 431.4263247375353, "step": 141000}
{"episode": 142.0, "batch_reward": 0.3651800240278244, "actor_loss": -43.56837727355957, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.814421892166138, "episode_reward": 544.0405016095908, "step": 142000}
{"episode": 143.0, "batch_reward": 0.3661321536004543, "actor_loss": -43.817016860961914, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.69400405883789, "episode_reward": 530.5067007102645, "step": 143000}
{"episode": 144.0, "batch_reward": 0.3679216081798077, "actor_loss": -43.815818168640135, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.082380771636963, "episode_reward": 523.3634558182737, "step": 144000}
{"episode": 145.0, "batch_reward": 0.36936211946606634, "actor_loss": -43.87663452911377, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.550299406051636, "episode_reward": 539.0013684789886, "step": 145000}
{"episode": 146.0, "batch_reward": 0.3697723810374737, "actor_loss": -44.0536919708252, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.248011350631714, "episode_reward": 473.75159962543216, "step": 146000}
{"episode": 147.0, "batch_reward": 0.37088328450918195, "actor_loss": -44.153129295349125, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.412447214126587, "episode_reward": 555.2606337090276, "step": 147000}
{"episode": 148.0, "batch_reward": 0.37192518097162247, "actor_loss": -44.1887320022583, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.78663182258606, "episode_reward": 538.242441721678, "step": 148000}
{"episode": 149.0, "batch_reward": 0.3733141502737999, "actor_loss": -44.40924125671387, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.670351028442383, "episode_reward": 452.657994489296, "step": 149000}
{"episode": 150.0, "batch_reward": 0.37368260768055916, "actor_loss": -44.24582388305664, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "step": 150000}
