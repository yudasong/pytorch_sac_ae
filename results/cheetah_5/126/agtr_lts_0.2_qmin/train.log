{"episode_reward": 0.0, "episode": 1.0, "duration": 17.27589440345764, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.4907395839691162, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.2480681461492313, "critic_loss": 0.16950795040895994, "actor_loss": -46.88591991209326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.18702244758606, "step": 3000}
{"episode_reward": 7.45209552241362, "episode": 4.0, "batch_reward": 0.15503997421264648, "critic_loss": 0.3094250688999891, "actor_loss": -48.98345556640625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16552734375, "step": 4000}
{"episode_reward": 2.4828472487716975, "episode": 5.0, "batch_reward": 0.12173106795176863, "critic_loss": 0.6405167291760445, "actor_loss": -56.99560375595093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.149866104125977, "step": 5000}
{"episode_reward": 7.1109999106399115, "episode": 6.0, "batch_reward": 0.1110112913660705, "critic_loss": 0.7479019316136837, "actor_loss": -56.79417213821411, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.191229343414307, "step": 6000}
{"episode_reward": 96.09510193940717, "episode": 7.0, "batch_reward": 0.10003683026134967, "critic_loss": 0.9536096543073654, "actor_loss": -57.66824258041382, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.198283195495605, "step": 7000}
{"episode_reward": 5.68624501214297, "episode": 8.0, "batch_reward": 0.08735133131593466, "critic_loss": 1.1833625351190566, "actor_loss": -56.92282418441773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1909921169281, "step": 8000}
{"episode_reward": 11.842048896155944, "episode": 9.0, "batch_reward": 0.07742116826400161, "critic_loss": 0.9072330349385739, "actor_loss": -57.266578060150145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16659641265869, "step": 9000}
{"episode_reward": 0.8769153319534743, "episode": 10.0, "batch_reward": 0.07015342888608575, "critic_loss": 0.8820929879844188, "actor_loss": -57.83942792510987, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.165998220443726, "step": 10000}
{"episode_reward": 14.073209035120922, "episode": 11.0, "batch_reward": 0.06449814803525805, "critic_loss": 0.8174491259157658, "actor_loss": -60.47825130462647, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.56367254257202, "step": 11000}
{"episode_reward": 8.699206018066189, "episode": 12.0, "batch_reward": 0.06070006502605975, "critic_loss": 0.8909439004063606, "actor_loss": -58.20470656204223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.167327642440796, "step": 12000}
{"episode_reward": 10.543646227002764, "episode": 13.0, "batch_reward": 0.056030995713546874, "critic_loss": 0.8279275015890598, "actor_loss": -59.404547233581546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19717311859131, "step": 13000}
{"episode_reward": 1.0326262397520638, "episode": 14.0, "batch_reward": 0.05144742614030838, "critic_loss": 0.7971712104380131, "actor_loss": -60.91288108444214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20487356185913, "step": 14000}
{"episode_reward": 5.978867057859056, "episode": 15.0, "batch_reward": 0.04875941086001694, "critic_loss": 0.7467745615541935, "actor_loss": -61.36694376373291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.198195934295654, "step": 15000}
{"episode_reward": 8.829398787690032, "episode": 16.0, "batch_reward": 0.045345632893033325, "critic_loss": 0.5046475660800934, "actor_loss": -58.46281934356689, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.201347827911377, "step": 16000}
{"episode_reward": 5.014219066139375, "episode": 17.0, "batch_reward": 0.04358182972483337, "critic_loss": 0.419583062261343, "actor_loss": -56.424795623779296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.160372972488403, "step": 17000}
{"episode_reward": 6.8450223457736925, "episode": 18.0, "batch_reward": 0.04110418427921832, "critic_loss": 0.4054120373129845, "actor_loss": -55.953121307373046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17690372467041, "step": 18000}
{"episode_reward": 7.78316285695589, "episode": 19.0, "batch_reward": 0.04009864273667336, "critic_loss": 0.42016757720708847, "actor_loss": -54.50554753112793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15362787246704, "step": 19000}
{"episode_reward": 6.768732434990994, "episode": 20.0, "batch_reward": 0.039211228067986666, "critic_loss": 0.64901655626297, "actor_loss": -54.325464042663576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.166276931762695, "step": 20000}
{"episode_reward": 47.89638971985706, "episode": 21.0, "batch_reward": 0.04039534721709788, "critic_loss": 0.9453166016042233, "actor_loss": -53.53974598693848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.48661804199219, "step": 21000}
{"episode_reward": 81.01434048177939, "episode": 22.0, "batch_reward": 0.04013312550447881, "critic_loss": 1.0811551465988158, "actor_loss": -56.34311678314209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.156092166900635, "step": 22000}
{"episode_reward": 5.934401713141317, "episode": 23.0, "batch_reward": 0.039055102537386116, "critic_loss": 1.0445555472373962, "actor_loss": -60.35771510314942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18109941482544, "step": 23000}
{"episode_reward": 6.55393493811725, "episode": 24.0, "batch_reward": 0.0372966475840658, "critic_loss": 0.9638087090849876, "actor_loss": -62.48102090835571, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.177481651306152, "step": 24000}
{"episode_reward": 1.6615001608337854, "episode": 25.0, "batch_reward": 0.03601617388799787, "critic_loss": 0.9038133383393288, "actor_loss": -61.23754895401001, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1690194606781, "step": 25000}
{"episode_reward": 5.2257254472474, "episode": 26.0, "batch_reward": 0.03562267727311701, "critic_loss": 1.0047226156890392, "actor_loss": -60.52634494781494, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.204599142074585, "step": 26000}
{"episode_reward": 14.600240912249744, "episode": 27.0, "batch_reward": 0.03571823771577329, "critic_loss": 1.0707319113612175, "actor_loss": -62.0238394203186, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.500840425491333, "step": 27000}
{"episode_reward": 54.66762996944532, "episode": 28.0, "batch_reward": 0.03412816012930125, "critic_loss": 1.033108164936304, "actor_loss": -58.81384447860718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.186753749847412, "step": 28000}
{"episode_reward": 11.65062940333711, "episode": 29.0, "batch_reward": 0.03367263977508992, "critic_loss": 1.0164104685783386, "actor_loss": -61.41776764297485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.173725843429565, "step": 29000}
{"episode_reward": 10.837796918371685, "episode": 30.0, "batch_reward": 0.03363673546910286, "critic_loss": 1.0592587904036046, "actor_loss": -60.88548302078247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.179020166397095, "step": 30000}
{"episode_reward": 6.182372984642073, "episode": 31.0, "batch_reward": 0.03260031113401055, "critic_loss": 1.1408326673209668, "actor_loss": -60.60591374206543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.663764238357544, "step": 31000}
{"episode_reward": 16.83394936832593, "episode": 32.0, "batch_reward": 0.03208906706608832, "critic_loss": 1.0778064143657684, "actor_loss": -61.838855836868284, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.204238176345825, "step": 32000}
{"episode_reward": 20.45491594814331, "episode": 33.0, "batch_reward": 0.031844777540303765, "critic_loss": 0.9277203337848187, "actor_loss": -60.59739759254455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.213361501693726, "step": 33000}
{"episode_reward": 5.482017165585137, "episode": 34.0, "batch_reward": 0.030468356577679514, "critic_loss": 0.9491052840054035, "actor_loss": -59.27841792297363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16228151321411, "step": 34000}
{"episode_reward": 6.267115024829564, "episode": 35.0, "batch_reward": 0.030336390926502647, "critic_loss": 0.9744520790874958, "actor_loss": -58.82167906188965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.193995714187622, "step": 35000}
{"episode_reward": 29.475147883170003, "episode": 36.0, "batch_reward": 0.03029252141620964, "critic_loss": 0.9856220310926438, "actor_loss": -58.15932385826111, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18870210647583, "step": 36000}
{"episode_reward": 27.348923735700705, "episode": 37.0, "batch_reward": 0.030388646990060806, "critic_loss": 0.8796844043433666, "actor_loss": -56.871021723747255, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.190733194351196, "step": 37000}
{"episode_reward": 27.597589472990308, "episode": 38.0, "batch_reward": 0.03015452173165977, "critic_loss": 0.825069460004568, "actor_loss": -58.17941051387787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19088125228882, "step": 38000}
{"episode_reward": 20.708628901786913, "episode": 39.0, "batch_reward": 0.03071743901539594, "critic_loss": 0.7180480675101281, "actor_loss": -54.76052888584137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.501258611679077, "step": 39000}
{"episode_reward": 51.62735373427912, "episode": 40.0, "batch_reward": 0.029468085849657655, "critic_loss": 0.7587231272757053, "actor_loss": -52.63899558353424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.218979358673096, "step": 40000}
{"episode_reward": 4.617575839952911, "episode": 41.0, "batch_reward": 0.03230040207877755, "critic_loss": 0.8040030760765076, "actor_loss": -50.59127431344986, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.514376401901245, "step": 41000}
{"episode_reward": 202.5755037136982, "episode": 42.0, "batch_reward": 0.03388798192050308, "critic_loss": 0.7333295520842076, "actor_loss": -49.22026216030121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.180628776550293, "step": 42000}
{"episode_reward": 32.63365659523044, "episode": 43.0, "batch_reward": 0.03384282700996846, "critic_loss": 0.6693529403209686, "actor_loss": -49.10188965344429, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.220987796783447, "step": 43000}
{"episode_reward": 23.69079910791781, "episode": 44.0, "batch_reward": 0.03427669157274067, "critic_loss": 0.6245520071685314, "actor_loss": -47.365623366117475, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15247082710266, "step": 44000}
{"episode_reward": 77.73550577712577, "episode": 45.0, "batch_reward": 0.03460467685945332, "critic_loss": 0.532273362994194, "actor_loss": -47.730629711151124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.196962594985962, "step": 45000}
{"episode_reward": 8.915843672887577, "episode": 46.0, "batch_reward": 0.033955550863407555, "critic_loss": 0.45853261977434157, "actor_loss": -44.85857486200332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1902117729187, "step": 46000}
{"episode_reward": 6.539365082187801, "episode": 47.0, "batch_reward": 0.03333754809945822, "critic_loss": 0.37458177092671396, "actor_loss": -42.571828121185305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1664297580719, "step": 47000}
{"episode_reward": 12.59852937964977, "episode": 48.0, "batch_reward": 0.032659670548513535, "critic_loss": 0.3312540172785521, "actor_loss": -43.05154919242859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17059063911438, "step": 48000}
{"episode_reward": 8.048209204853775, "episode": 49.0, "batch_reward": 0.03279027747362852, "critic_loss": 0.28934098361432553, "actor_loss": -41.03603178024292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17141103744507, "step": 49000}
{"episode_reward": 12.565831876632641, "episode": 50.0, "batch_reward": 0.032086289326660335, "critic_loss": 0.2531322876289487, "actor_loss": -38.49546325492859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.173131942749023, "step": 50000}
{"episode_reward": 3.8187674506853413, "episode": 51.0, "batch_reward": 0.03162259630393237, "critic_loss": 0.23924178376048805, "actor_loss": -37.83134317588806, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.67650890350342, "step": 51000}
{"episode_reward": 2.8888922618846022, "episode": 52.0, "batch_reward": 0.030908891591243447, "critic_loss": 0.23261088854074477, "actor_loss": -35.71999134635925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16653037071228, "step": 52000}
{"episode_reward": 2.6310374152956, "episode": 53.0, "batch_reward": 0.030493267936632037, "critic_loss": 0.21651017493754626, "actor_loss": -35.266590523719785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.191129684448242, "step": 53000}
{"episode_reward": 3.2596953629949974, "episode": 54.0, "batch_reward": 0.030148521201685072, "critic_loss": 0.21273357716947794, "actor_loss": -33.465363755226136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18323540687561, "step": 54000}
{"episode_reward": 2.9841226449000384, "episode": 55.0, "batch_reward": 0.0295324883190915, "critic_loss": 0.201656568787992, "actor_loss": -31.777422436714172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.178176879882812, "step": 55000}
{"episode_reward": 3.978355196522782, "episode": 56.0, "batch_reward": 0.02863882885593921, "critic_loss": 0.2094801883623004, "actor_loss": -31.471815934181212, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19397282600403, "step": 56000}
{"episode_reward": 6.396673675892402, "episode": 57.0, "batch_reward": 0.028641926100477576, "critic_loss": 0.20064120579510927, "actor_loss": -29.967291011810303, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.192640781402588, "step": 57000}
{"episode_reward": 17.063779851800305, "episode": 58.0, "batch_reward": 0.028381378153339028, "critic_loss": 0.19967902498692275, "actor_loss": -29.2393197183609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21351194381714, "step": 58000}
{"episode_reward": 83.99065468322782, "episode": 59.0, "batch_reward": 0.02975849104486406, "critic_loss": 0.24575852762907743, "actor_loss": -27.838130962371824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.188548803329468, "step": 59000}
{"episode_reward": 104.89824258324175, "episode": 60.0, "batch_reward": 0.030987729689106343, "critic_loss": 0.23458637811988592, "actor_loss": -26.60231449985504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.151432275772095, "step": 60000}
{"episode_reward": 78.44136073855371, "episode": 61.0, "batch_reward": 0.03185439489036798, "critic_loss": 0.26731733801215884, "actor_loss": -26.24022463417053, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.51389694213867, "step": 61000}
{"episode_reward": 115.12204269598843, "episode": 62.0, "batch_reward": 0.03310747291985899, "critic_loss": 0.24846396094560624, "actor_loss": -26.26250692176819, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17958426475525, "step": 62000}
{"episode_reward": 107.43157216226875, "episode": 63.0, "batch_reward": 0.035099074779078365, "critic_loss": 0.2634598959311843, "actor_loss": -25.535910272598265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.175439834594727, "step": 63000}
{"episode_reward": 192.9243006921468, "episode": 64.0, "batch_reward": 0.03801737998053432, "critic_loss": 0.2751227149888873, "actor_loss": -24.72241028213501, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.168367624282837, "step": 64000}
{"episode_reward": 194.94978074572643, "episode": 65.0, "batch_reward": 0.039019155452027915, "critic_loss": 0.2318706617280841, "actor_loss": -24.15523450088501, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.169193506240845, "step": 65000}
{"episode_reward": 32.14131923354143, "episode": 66.0, "batch_reward": 0.03915077546797693, "critic_loss": 0.2056543252170086, "actor_loss": -22.78059564113617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.163636922836304, "step": 66000}
{"episode_reward": 63.62592419064228, "episode": 67.0, "batch_reward": 0.03925082954764366, "critic_loss": 0.1824877557903528, "actor_loss": -21.983693313598632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.179258346557617, "step": 67000}
{"episode_reward": 24.630591799397862, "episode": 68.0, "batch_reward": 0.041647584278136494, "critic_loss": 0.23354674546420573, "actor_loss": -21.229570103168488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19661784172058, "step": 68000}
{"episode_reward": 295.9465041951606, "episode": 69.0, "batch_reward": 0.04362651711329818, "critic_loss": 0.22223349405825138, "actor_loss": -20.65899528312683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16764497756958, "step": 69000}
{"episode_reward": 48.655733181895634, "episode": 70.0, "batch_reward": 0.04344484973885119, "critic_loss": 0.2087204734236002, "actor_loss": -20.27885753440857, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17928457260132, "step": 70000}
{"episode_reward": 62.21094655825669, "episode": 71.0, "batch_reward": 0.04514889994449914, "critic_loss": 0.21700362133979798, "actor_loss": -19.982713503837587, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.581226110458374, "step": 71000}
{"episode_reward": 221.6532356083239, "episode": 72.0, "batch_reward": 0.0463946579080075, "critic_loss": 0.21708777315169572, "actor_loss": -19.564698373794556, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16085648536682, "step": 72000}
{"episode_reward": 106.40237528890026, "episode": 73.0, "batch_reward": 0.04735238866508007, "critic_loss": 0.19856908605992793, "actor_loss": -18.896322011947632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1831796169281, "step": 73000}
{"episode_reward": 133.94888005235512, "episode": 74.0, "batch_reward": 0.04812958481907845, "critic_loss": 0.1895008201599121, "actor_loss": -18.382741738319396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.188289403915405, "step": 74000}
{"episode_reward": 105.32236033112837, "episode": 75.0, "batch_reward": 0.049546924024820325, "critic_loss": 0.1941694738343358, "actor_loss": -17.978105745315553, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.197267293930054, "step": 75000}
{"episode_reward": 118.3179484106946, "episode": 76.0, "batch_reward": 0.05048386790044606, "critic_loss": 0.20105959458649159, "actor_loss": -17.774626605033873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.198021411895752, "step": 76000}
{"episode_reward": 92.6944306492539, "episode": 77.0, "batch_reward": 0.050712876638397575, "critic_loss": 0.20642375934123994, "actor_loss": -17.72078409194946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.192389011383057, "step": 77000}
{"episode_reward": 181.57197031373136, "episode": 78.0, "batch_reward": 0.05318118005432188, "critic_loss": 0.21121213471144437, "actor_loss": -17.670109288215638, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.185065984725952, "step": 78000}
{"episode_reward": 288.5597231626959, "episode": 79.0, "batch_reward": 0.055281992582604286, "critic_loss": 0.2242665824815631, "actor_loss": -17.389263723373414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.165578365325928, "step": 79000}
{"episode_reward": 52.63882438503772, "episode": 80.0, "batch_reward": 0.05596546577848494, "critic_loss": 0.2232547429651022, "actor_loss": -16.849680491447447, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.164525270462036, "step": 80000}
{"episode_reward": 222.3527909722753, "episode": 81.0, "batch_reward": 0.05738486892357469, "critic_loss": 0.2068567832559347, "actor_loss": -16.829568610191345, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.58614206314087, "step": 81000}
{"episode_reward": 74.91030228953181, "episode": 82.0, "batch_reward": 0.05839705460704863, "critic_loss": 0.22910525140911342, "actor_loss": -16.532458557128905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18944764137268, "step": 82000}
{"episode_reward": 381.28405255367585, "episode": 83.0, "batch_reward": 0.06158079781383276, "critic_loss": 0.2361915688216686, "actor_loss": -16.53883010864258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.173818826675415, "step": 83000}
{"episode_reward": 192.58617616909947, "episode": 84.0, "batch_reward": 0.0632297563329339, "critic_loss": 0.23709636497497558, "actor_loss": -16.511275360107422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.168248891830444, "step": 84000}
{"episode_reward": 175.42155425399233, "episode": 85.0, "batch_reward": 0.06614764117822051, "critic_loss": 0.23876008722186087, "actor_loss": -16.596406576156618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.177342176437378, "step": 85000}
{"episode_reward": 379.5144290119269, "episode": 86.0, "batch_reward": 0.06965242571383715, "critic_loss": 0.23521772226691245, "actor_loss": -16.83272173881531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19280743598938, "step": 86000}
{"episode_reward": 297.51783307265924, "episode": 87.0, "batch_reward": 0.07233167416602374, "critic_loss": 0.2552134581059217, "actor_loss": -16.79033574295044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18805694580078, "step": 87000}
{"episode_reward": 156.5478216950627, "episode": 88.0, "batch_reward": 0.07250992108881474, "critic_loss": 0.2727502186372876, "actor_loss": -16.547111330032347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.197014570236206, "step": 88000}
{"episode_reward": 155.47176667567575, "episode": 89.0, "batch_reward": 0.07275618304312229, "critic_loss": 0.25902752712368965, "actor_loss": -16.359595458984376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17923069000244, "step": 89000}
{"episode_reward": 114.0162902218332, "episode": 90.0, "batch_reward": 0.07372863265499473, "critic_loss": 0.2883063454627991, "actor_loss": -16.262388105392457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.181032419204712, "step": 90000}
{"episode_reward": 372.1701913969672, "episode": 91.0, "batch_reward": 0.07705505149438978, "critic_loss": 0.2892415410876274, "actor_loss": -16.199839057922365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.550950050354004, "step": 91000}
{"episode_reward": 159.66546041877402, "episode": 92.0, "batch_reward": 0.0785860179439187, "critic_loss": 0.2950233175009489, "actor_loss": -16.1103503074646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.178634643554688, "step": 92000}
{"episode_reward": 314.59148944019427, "episode": 93.0, "batch_reward": 0.08104752473160624, "critic_loss": 0.29116314903646706, "actor_loss": -16.05719271659851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.185142755508423, "step": 93000}
{"episode_reward": 458.61947957033965, "episode": 94.0, "batch_reward": 0.08527742077037692, "critic_loss": 0.3068738145530224, "actor_loss": -16.32368286514282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15166473388672, "step": 94000}
{"episode_reward": 199.2568409782454, "episode": 95.0, "batch_reward": 0.0862144210152328, "critic_loss": 0.2861844586879015, "actor_loss": -16.304919397354126, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14993953704834, "step": 95000}
{"episode_reward": 395.758591465112, "episode": 96.0, "batch_reward": 0.08922962290793657, "critic_loss": 0.30991939413547515, "actor_loss": -16.383846071243287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.133198261260986, "step": 96000}
{"episode_reward": 153.99969711906752, "episode": 97.0, "batch_reward": 0.0892456569224596, "critic_loss": 0.29962121003866193, "actor_loss": -16.24438655090332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.161145210266113, "step": 97000}
{"episode_reward": 111.14420841986035, "episode": 98.0, "batch_reward": 0.09058514015004039, "critic_loss": 0.3057040736600757, "actor_loss": -16.21285237121582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.192572355270386, "step": 98000}
{"episode_reward": 303.74021078315513, "episode": 99.0, "batch_reward": 0.0922114166431129, "critic_loss": 0.30519757261872293, "actor_loss": -16.23649666404724, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.159138441085815, "step": 99000}
{"episode_reward": 258.19297558416093, "episode": 100.0, "batch_reward": 0.09281793607398868, "critic_loss": 0.28770108258724214, "actor_loss": -16.13143840789795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16887879371643, "step": 100000}
{"episode_reward": 147.3523863928742, "episode": 101.0, "batch_reward": 0.09482560051232576, "critic_loss": 0.28129383010417225, "actor_loss": -15.964899221420287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.532649993896484, "step": 101000}
{"episode_reward": 396.87180337644236, "episode": 102.0, "batch_reward": 0.09771316871792078, "critic_loss": 0.2976890124157071, "actor_loss": -16.029583923339842, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.163291931152344, "step": 102000}
{"episode_reward": 453.252418079432, "episode": 103.0, "batch_reward": 0.10160645980387926, "critic_loss": 0.27592859306931494, "actor_loss": -16.293955276489257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.188496112823486, "step": 103000}
{"episode_reward": 413.8131419092087, "episode": 104.0, "batch_reward": 0.10419599188119173, "critic_loss": 0.3001992352157831, "actor_loss": -16.425867111206056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.164243698120117, "step": 104000}
{"episode_reward": 196.26907945422136, "episode": 105.0, "batch_reward": 0.1047017480172217, "critic_loss": 0.28364335700124504, "actor_loss": -16.488892791748047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.128470420837402, "step": 105000}
{"episode_reward": 359.10240092375693, "episode": 106.0, "batch_reward": 0.10682035030052066, "critic_loss": 0.30586293487250804, "actor_loss": -16.49365136909485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.13738250732422, "step": 106000}
{"episode_reward": 254.2600691953331, "episode": 107.0, "batch_reward": 0.10698038342595101, "critic_loss": 0.3051287234649062, "actor_loss": -16.170297134399416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16512656211853, "step": 107000}
{"episode_reward": 44.87058575069007, "episode": 108.0, "batch_reward": 0.10669671037048102, "critic_loss": 0.29514821763336657, "actor_loss": -16.013735187530518, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.140474319458008, "step": 108000}
{"episode_reward": 203.65034979614342, "episode": 109.0, "batch_reward": 0.10934408082440496, "critic_loss": 0.29152981267124417, "actor_loss": -16.1675254573822, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.151020288467407, "step": 109000}
{"episode_reward": 417.48413214667994, "episode": 110.0, "batch_reward": 0.11229162911325694, "critic_loss": 0.319658196747303, "actor_loss": -16.34841968536377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15415596961975, "step": 110000}
{"episode_reward": 471.3654201038377, "episode": 111.0, "batch_reward": 0.11395680153369904, "critic_loss": 0.2985485462769866, "actor_loss": -16.264263942718507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.55280661582947, "step": 111000}
{"episode_reward": 109.57501223689512, "episode": 112.0, "batch_reward": 0.11547212679684161, "critic_loss": 0.3090113211274147, "actor_loss": -16.50769840812683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.172755002975464, "step": 112000}
{"episode_reward": 445.88750026322, "episode": 113.0, "batch_reward": 0.11849499138444662, "critic_loss": 0.32731074481457473, "actor_loss": -16.59561973762512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17799735069275, "step": 113000}
{"episode_reward": 445.0299036259938, "episode": 114.0, "batch_reward": 0.12122698853164911, "critic_loss": 0.2930056009665132, "actor_loss": -16.97581651878357, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.171927213668823, "step": 114000}
{"episode_reward": 534.177098926877, "episode": 115.0, "batch_reward": 0.12455470541864634, "critic_loss": 0.28569777577370403, "actor_loss": -17.17673494529724, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.178568601608276, "step": 115000}
{"episode_reward": 198.2944304573998, "episode": 116.0, "batch_reward": 0.12628014213591815, "critic_loss": 0.2849271185398102, "actor_loss": -17.17965069961548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.157400846481323, "step": 116000}
{"episode_reward": 508.4559156841187, "episode": 117.0, "batch_reward": 0.1282396025210619, "critic_loss": 0.2813749241232872, "actor_loss": -17.265348741531373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.156600952148438, "step": 117000}
{"episode_reward": 179.58694064198676, "episode": 118.0, "batch_reward": 0.12912176275253295, "critic_loss": 0.28674442443996667, "actor_loss": -17.424739511489868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.155315160751343, "step": 118000}
{"episode_reward": 529.4117422243002, "episode": 119.0, "batch_reward": 0.13191243869811298, "critic_loss": 0.30290467528253795, "actor_loss": -17.638946146011353, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1781587600708, "step": 119000}
{"episode_reward": 431.1038534051084, "episode": 120.0, "batch_reward": 0.1338472760692239, "critic_loss": 0.314470980450511, "actor_loss": -17.64240962409973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18500280380249, "step": 120000}
{"episode_reward": 355.4297978157886, "episode": 121.0, "batch_reward": 0.13644861299544572, "critic_loss": 0.32247248266637324, "actor_loss": -18.145839754104614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.60949683189392, "step": 121000}
{"episode_reward": 441.43074592461005, "episode": 122.0, "batch_reward": 0.13926116365939378, "critic_loss": 0.32737092424929143, "actor_loss": -18.146202592849733, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.159680128097534, "step": 122000}
{"episode_reward": 516.7848926919643, "episode": 123.0, "batch_reward": 0.14225872794538735, "critic_loss": 0.3256470602080226, "actor_loss": -18.492947780609132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.163237810134888, "step": 123000}
{"episode_reward": 374.9754728237049, "episode": 124.0, "batch_reward": 0.14324405663460493, "critic_loss": 0.33475213520228864, "actor_loss": -18.72234320259094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.150728702545166, "step": 124000}
{"episode_reward": 276.8272410865431, "episode": 125.0, "batch_reward": 0.14536427035927774, "critic_loss": 0.31340116968005893, "actor_loss": -18.74193751716614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.163576126098633, "step": 125000}
{"episode_reward": 382.3763383174914, "episode": 126.0, "batch_reward": 0.14762729875743388, "critic_loss": 0.32023331068456173, "actor_loss": -18.812236909866332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17686676979065, "step": 126000}
{"episode_reward": 288.26597912584793, "episode": 127.0, "batch_reward": 0.14781284335255623, "critic_loss": 0.3253418824672699, "actor_loss": -19.09096487045288, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.185641527175903, "step": 127000}
{"episode_reward": 449.987750620088, "episode": 128.0, "batch_reward": 0.15079182439297437, "critic_loss": 0.36669699296355246, "actor_loss": -19.289796913146972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.184051752090454, "step": 128000}
{"episode_reward": 540.7132526756766, "episode": 129.0, "batch_reward": 0.1533699478805065, "critic_loss": 0.38324876387417317, "actor_loss": -19.50785936164856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.197922229766846, "step": 129000}
{"episode_reward": 91.13317726261823, "episode": 130.0, "batch_reward": 0.15248169081658125, "critic_loss": 0.3584717380031943, "actor_loss": -19.474938077926637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20568346977234, "step": 130000}
{"episode_reward": 111.50818860184191, "episode": 131.0, "batch_reward": 0.1535296523347497, "critic_loss": 0.3537710209339857, "actor_loss": -19.618712251663208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.554277420043945, "step": 131000}
{"episode_reward": 521.6510243630744, "episode": 132.0, "batch_reward": 0.15509395011514426, "critic_loss": 0.3702792390584946, "actor_loss": -19.795502998352053, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.190691232681274, "step": 132000}
{"episode_reward": 556.9643183752855, "episode": 133.0, "batch_reward": 0.15866514930129053, "critic_loss": 0.3729882052689791, "actor_loss": -19.86472542953491, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18320894241333, "step": 133000}
{"episode_reward": 382.6663662348853, "episode": 134.0, "batch_reward": 0.16055515439808368, "critic_loss": 0.36178695936501026, "actor_loss": -20.02897002029419, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.183470010757446, "step": 134000}
{"episode_reward": 527.1565010172682, "episode": 135.0, "batch_reward": 0.16453001050651073, "critic_loss": 0.362301583096385, "actor_loss": -20.403380325317382, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.166622161865234, "step": 135000}
{"episode_reward": 414.3136325841412, "episode": 136.0, "batch_reward": 0.16469813311100007, "critic_loss": 0.3797733177095652, "actor_loss": -20.135407680511474, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.171579360961914, "step": 136000}
{"episode_reward": 628.5835365837336, "episode": 137.0, "batch_reward": 0.16925269800424575, "critic_loss": 0.3660547606125474, "actor_loss": -20.702239459991453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.177229404449463, "step": 137000}
{"episode_reward": 451.9438961708147, "episode": 138.0, "batch_reward": 0.17165080622583628, "critic_loss": 0.37168669918179514, "actor_loss": -20.989038650512697, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.176804542541504, "step": 138000}
{"episode_reward": 505.1818498942218, "episode": 139.0, "batch_reward": 0.17440456476807595, "critic_loss": 0.3541055908054113, "actor_loss": -21.006215808868408, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.199414253234863, "step": 139000}
{"episode_reward": 546.8063744176483, "episode": 140.0, "batch_reward": 0.1771119668930769, "critic_loss": 0.3832271523326635, "actor_loss": -21.290398166656495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.159828424453735, "step": 140000}
{"episode_reward": 471.6274641322953, "episode": 141.0, "batch_reward": 0.17812868100404738, "critic_loss": 0.34346834985911845, "actor_loss": -21.601706398010254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.78388690948486, "step": 141000}
{"episode_reward": 551.4281725490059, "episode": 142.0, "batch_reward": 0.17926856632530688, "critic_loss": 0.3525928168743849, "actor_loss": -21.581128505706786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16079354286194, "step": 142000}
{"episode_reward": 575.3473288872717, "episode": 143.0, "batch_reward": 0.18357366618514062, "critic_loss": 0.3282735479772091, "actor_loss": -21.88740059661865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1384379863739, "step": 143000}
{"episode_reward": 529.9947767299029, "episode": 144.0, "batch_reward": 0.18659729586541654, "critic_loss": 0.3740706866979599, "actor_loss": -22.198866802215576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16273260116577, "step": 144000}
{"episode_reward": 562.8012755155478, "episode": 145.0, "batch_reward": 0.18904379530251025, "critic_loss": 0.3380698687136173, "actor_loss": -22.547952018737792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.161407232284546, "step": 145000}
{"episode_reward": 609.5592556639688, "episode": 146.0, "batch_reward": 0.1915082904100418, "critic_loss": 0.3151494998112321, "actor_loss": -22.83152187347412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.142823696136475, "step": 146000}
{"episode_reward": 534.2013593288417, "episode": 147.0, "batch_reward": 0.19396107490360737, "critic_loss": 0.33153213530778886, "actor_loss": -23.036924949645996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.195988416671753, "step": 147000}
{"episode_reward": 529.0436344377841, "episode": 148.0, "batch_reward": 0.19496419870853424, "critic_loss": 0.3150326999425888, "actor_loss": -23.254486095428465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.189452409744263, "step": 148000}
{"episode_reward": 161.82039097033365, "episode": 149.0, "batch_reward": 0.19587853515148163, "critic_loss": 0.32307671231031415, "actor_loss": -23.224845138549803, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19204831123352, "step": 149000}
{"episode_reward": 548.3886410633659, "episode": 150.0, "batch_reward": 0.1994371957182884, "critic_loss": 0.3342357944697142, "actor_loss": -23.542870429992675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
