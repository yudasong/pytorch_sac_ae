{"episode_reward": 0.0, "episode": 1.0, "duration": 14.009730100631714, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.249756097793579, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.2515551546894737, "critic_loss": 0.03313368165455001, "actor_loss": -26.385481693630233, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 74.34680581092834, "step": 3000}
{"episode_reward": 35.903207317545416, "episode": 4.0, "batch_reward": 0.1686190265342593, "critic_loss": 0.04043645088560879, "actor_loss": -19.531108024269344, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.69470524787903, "step": 4000}
{"episode_reward": 58.140544371732865, "episode": 5.0, "batch_reward": 0.14009739630669354, "critic_loss": 0.0372902626991272, "actor_loss": -18.579159226059915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.17022705078125, "step": 5000}
{"episode_reward": 4.256012399352548, "episode": 6.0, "batch_reward": 0.11555199006944895, "critic_loss": 0.031115151564590632, "actor_loss": -19.400868805199863, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.46098494529724, "step": 6000}
{"episode_reward": 8.446043872493368, "episode": 7.0, "batch_reward": 0.10102490007132292, "critic_loss": 0.0383537185639143, "actor_loss": -18.82743106240034, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.88288378715515, "step": 7000}
{"episode_reward": 37.90930841281816, "episode": 8.0, "batch_reward": 0.10003981827571988, "critic_loss": 0.057853128565475344, "actor_loss": -17.431840439289807, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.6879723072052, "step": 8000}
{"episode_reward": 118.19628275078988, "episode": 9.0, "batch_reward": 0.09970533181726933, "critic_loss": 0.06623263446986676, "actor_loss": -16.61609455089271, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.926414251327515, "step": 9000}
{"episode_reward": 147.74011071539834, "episode": 10.0, "batch_reward": 0.10781719989329576, "critic_loss": 0.08198462895303965, "actor_loss": -16.16297604483366, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.489864110946655, "step": 10000}
{"episode_reward": 171.11287642744622, "episode": 11.0, "batch_reward": 0.11011786372959614, "critic_loss": 0.08150629745796323, "actor_loss": -17.588147850349547, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.48384475708008, "step": 11000}
{"episode_reward": 58.08265534230305, "episode": 12.0, "batch_reward": 0.10647736141085624, "critic_loss": 0.07933558871224522, "actor_loss": -15.419704321101309, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.47507619857788, "step": 12000}
{"episode_reward": 75.05295696463423, "episode": 13.0, "batch_reward": 0.10487823617458343, "critic_loss": 0.08568745758756995, "actor_loss": -15.787469426736235, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34129023551941, "step": 13000}
{"episode_reward": 142.27389997359307, "episode": 14.0, "batch_reward": 0.10614091286063194, "critic_loss": 0.099640051510185, "actor_loss": -15.796981862336397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.290949821472168, "step": 14000}
{"episode_reward": 75.38842878381796, "episode": 15.0, "batch_reward": 0.10833850003033876, "critic_loss": 0.11043402025103569, "actor_loss": -17.078986907824873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.0933780670166, "step": 15000}
{"episode_reward": 201.80486966110752, "episode": 16.0, "batch_reward": 0.11778605455905199, "critic_loss": 0.1387319182343781, "actor_loss": -15.064187343955039, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.356414556503296, "step": 16000}
{"episode_reward": 263.5501721899098, "episode": 17.0, "batch_reward": 0.12303142386674881, "critic_loss": 0.1727228477038443, "actor_loss": -15.68021321606636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.593668937683105, "step": 17000}
{"episode_reward": 153.92551439006766, "episode": 18.0, "batch_reward": 0.12384109318256378, "critic_loss": 0.1753836633451283, "actor_loss": -15.252794026374817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.045037984848022, "step": 18000}
{"episode_reward": 154.73534612431084, "episode": 19.0, "batch_reward": 0.12593824261426925, "critic_loss": 0.20972712071985006, "actor_loss": -15.718089191913604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.740296840667725, "step": 19000}
{"episode_reward": 130.47394228286257, "episode": 20.0, "batch_reward": 0.12710608603060244, "critic_loss": 0.20001362285763025, "actor_loss": -16.314404704093935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.98042869567871, "step": 20000}
{"episode_reward": 163.22083990226042, "episode": 21.0, "batch_reward": 0.1270948492512107, "critic_loss": 0.21460522051900624, "actor_loss": -15.479661628723145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.10303568840027, "step": 21000}
{"episode_reward": 136.36334971983158, "episode": 22.0, "batch_reward": 0.12764224568754434, "critic_loss": 0.2088583420366049, "actor_loss": -15.961023422718048, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.468559980392456, "step": 22000}
{"episode_reward": 96.1240679821414, "episode": 23.0, "batch_reward": 0.12733768670260906, "critic_loss": 0.18938896225392818, "actor_loss": -16.16005645084381, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.103511095046997, "step": 23000}
{"episode_reward": 224.2891666705309, "episode": 24.0, "batch_reward": 0.13134022457152605, "critic_loss": 0.2648633328005672, "actor_loss": -16.58866353225708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.314254760742188, "step": 24000}
{"episode_reward": 187.7182317922257, "episode": 25.0, "batch_reward": 0.13431152686476708, "critic_loss": 0.21907000270485877, "actor_loss": -16.932096091270445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.299221992492676, "step": 25000}
{"episode_reward": 217.96210217031876, "episode": 26.0, "batch_reward": 0.13814333243668078, "critic_loss": 0.24124826772511004, "actor_loss": -16.81730920982361, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.072806358337402, "step": 26000}
{"episode_reward": 218.69679332614965, "episode": 27.0, "batch_reward": 0.14197585637867452, "critic_loss": 0.26822225980460646, "actor_loss": -17.647510204315186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.06112813949585, "step": 27000}
{"episode_reward": 280.62168652190553, "episode": 28.0, "batch_reward": 0.14303486490249634, "critic_loss": 0.2406675162985921, "actor_loss": -17.009029109954835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.61951780319214, "step": 28000}
{"episode_reward": 149.53120720758182, "episode": 29.0, "batch_reward": 0.142862370043993, "critic_loss": 0.25803693775832653, "actor_loss": -17.89589402294159, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.56476140022278, "step": 29000}
{"episode_reward": 47.82704407224626, "episode": 30.0, "batch_reward": 0.14486060552299024, "critic_loss": 0.24552968659251928, "actor_loss": -17.719570629119872, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.49906897544861, "step": 30000}
{"episode_reward": 265.5357106037087, "episode": 31.0, "batch_reward": 0.14460250149667264, "critic_loss": 0.27201641917228697, "actor_loss": -17.06053842639923, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.21177387237549, "step": 31000}
{"episode_reward": 71.8423089984557, "episode": 32.0, "batch_reward": 0.14366226670891047, "critic_loss": 0.2495680852457881, "actor_loss": -17.101632160186767, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.401201725006104, "step": 32000}
{"episode_reward": 225.8519351542005, "episode": 33.0, "batch_reward": 0.14684971302747726, "critic_loss": 0.26829972536861896, "actor_loss": -18.49953040599823, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.297365188598633, "step": 33000}
{"episode_reward": 241.57973963540505, "episode": 34.0, "batch_reward": 0.1475587746873498, "critic_loss": 0.3230223881304264, "actor_loss": -17.8906463098526, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.19348406791687, "step": 34000}
{"episode_reward": 184.5465703902178, "episode": 35.0, "batch_reward": 0.15120054192095994, "critic_loss": 0.29062798964232206, "actor_loss": -18.442668437957764, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.20570468902588, "step": 35000}
{"episode_reward": 200.04329620007903, "episode": 36.0, "batch_reward": 0.15261742343753576, "critic_loss": 0.2987534979581833, "actor_loss": -17.65896834754944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.615804433822632, "step": 36000}
{"episode_reward": 260.49070196104924, "episode": 37.0, "batch_reward": 0.15432471210509538, "critic_loss": 0.3096419496461749, "actor_loss": -18.64705797767639, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.153709650039673, "step": 37000}
{"episode_reward": 236.7861247516787, "episode": 38.0, "batch_reward": 0.1568193420097232, "critic_loss": 0.3012049564346671, "actor_loss": -19.49831873703003, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.588160753250122, "step": 38000}
{"episode_reward": 208.46932394744326, "episode": 39.0, "batch_reward": 0.15825402081757783, "critic_loss": 0.3330236968845129, "actor_loss": -19.207576709747315, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.93035650253296, "step": 39000}
{"episode_reward": 120.85778641647998, "episode": 40.0, "batch_reward": 0.15803344545513393, "critic_loss": 0.3192884129434824, "actor_loss": -18.58426163673401, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.57548451423645, "step": 40000}
{"episode_reward": 323.19774344708645, "episode": 41.0, "batch_reward": 0.1609081202968955, "critic_loss": 0.3122752020061016, "actor_loss": -18.804963256835936, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.72559428215027, "step": 41000}
{"episode_reward": 132.09731117014158, "episode": 42.0, "batch_reward": 0.1617473497018218, "critic_loss": 0.2985012583434582, "actor_loss": -19.65185817337036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.175804138183594, "step": 42000}
{"episode_reward": 346.58662378806685, "episode": 43.0, "batch_reward": 0.16680196003615858, "critic_loss": 0.3086478080153465, "actor_loss": -19.72417151069641, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.654137134552002, "step": 43000}
{"episode_reward": 314.9120300481792, "episode": 44.0, "batch_reward": 0.16841960361599922, "critic_loss": 0.3283063369691372, "actor_loss": -20.389751737594604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.752203226089478, "step": 44000}
{"episode_reward": 216.14605832090203, "episode": 45.0, "batch_reward": 0.16929748667776584, "critic_loss": 0.300341051697731, "actor_loss": -20.768785011291502, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.51004409790039, "step": 45000}
{"episode_reward": 208.95286026085327, "episode": 46.0, "batch_reward": 0.17080157023668288, "critic_loss": 0.3130846573710442, "actor_loss": -20.054450700759887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.51693606376648, "step": 46000}
{"episode_reward": 133.27350581568922, "episode": 47.0, "batch_reward": 0.16939577633142472, "critic_loss": 0.32779817228019237, "actor_loss": -20.000455278396608, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.736039400100708, "step": 47000}
{"episode_reward": 152.1516145108156, "episode": 48.0, "batch_reward": 0.17025224781036377, "critic_loss": 0.30089435140788556, "actor_loss": -19.969383964538576, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.370069980621338, "step": 48000}
{"episode_reward": 185.67492012530928, "episode": 49.0, "batch_reward": 0.17068955306708813, "critic_loss": 0.30999522809684277, "actor_loss": -20.112907356262205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.99052858352661, "step": 49000}
{"episode_reward": 266.6625013753783, "episode": 50.0, "batch_reward": 0.1725326244533062, "critic_loss": 0.28786122138798237, "actor_loss": -20.702565616607664, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.063504695892334, "step": 50000}
{"episode_reward": 299.2711115257847, "episode": 51.0, "batch_reward": 0.17362402465939522, "critic_loss": 0.2786312309205532, "actor_loss": -20.93784977722168, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.388137340545654, "step": 51000}
{"episode_reward": 77.99763585415558, "episode": 52.0, "batch_reward": 0.1739034122824669, "critic_loss": 0.28321781305968763, "actor_loss": -20.515185874938965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.759162664413452, "step": 52000}
{"episode_reward": 358.2181999823079, "episode": 53.0, "batch_reward": 0.17511864939332009, "critic_loss": 0.2910846114680171, "actor_loss": -21.624932046890258, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.655445098876953, "step": 53000}
{"episode_reward": 126.72586236834312, "episode": 54.0, "batch_reward": 0.17635635341703892, "critic_loss": 0.29012848395109175, "actor_loss": -20.64852374458313, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.279407262802124, "step": 54000}
{"episode_reward": 350.0078293963798, "episode": 55.0, "batch_reward": 0.17779500143229962, "critic_loss": 0.2875512001812458, "actor_loss": -21.063217079162598, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.150064706802368, "step": 55000}
{"episode_reward": 126.82814039135339, "episode": 56.0, "batch_reward": 0.17861805365979672, "critic_loss": 0.2863653906881809, "actor_loss": -21.68387488746643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.48669981956482, "step": 56000}
{"episode_reward": 346.24702256703966, "episode": 57.0, "batch_reward": 0.18000218085944653, "critic_loss": 0.29199599724262953, "actor_loss": -21.486874977111817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.425028085708618, "step": 57000}
{"episode_reward": 148.43995334162685, "episode": 58.0, "batch_reward": 0.18078579354286195, "critic_loss": 0.3124645101428032, "actor_loss": -21.500616861343385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.251561164855957, "step": 58000}
{"episode_reward": 318.5511504644698, "episode": 59.0, "batch_reward": 0.18129114539921284, "critic_loss": 0.2981108389943838, "actor_loss": -21.642425830841063, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.876683235168457, "step": 59000}
{"episode_reward": 88.69516793071926, "episode": 60.0, "batch_reward": 0.1801883931607008, "critic_loss": 0.30148560175299643, "actor_loss": -21.553576971054078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.43421483039856, "step": 60000}
{"episode_reward": 140.7302231069185, "episode": 61.0, "batch_reward": 0.18059286859631538, "critic_loss": 0.3102739327251911, "actor_loss": -21.397936084747315, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.579570293426514, "step": 61000}
{"episode_reward": 185.519072508769, "episode": 62.0, "batch_reward": 0.1810232878178358, "critic_loss": 0.3164141209125519, "actor_loss": -22.035718702316284, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.50526785850525, "step": 62000}
{"episode_reward": 385.5652574850146, "episode": 63.0, "batch_reward": 0.18356510047614574, "critic_loss": 0.31280880139768125, "actor_loss": -22.325585584640503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41924500465393, "step": 63000}
{"episode_reward": 421.09081011154404, "episode": 64.0, "batch_reward": 0.18663672621548175, "critic_loss": 0.3182275382727385, "actor_loss": -22.31603338241577, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.590269327163696, "step": 64000}
{"episode_reward": 191.8858099277187, "episode": 65.0, "batch_reward": 0.1882668869495392, "critic_loss": 0.29086252386868, "actor_loss": -22.711847314834596, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.255027770996094, "step": 65000}
{"episode_reward": 379.4460731109762, "episode": 66.0, "batch_reward": 0.19148684829473495, "critic_loss": 0.30338144619762897, "actor_loss": -22.688389417648317, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.762722969055176, "step": 66000}
{"episode_reward": 340.44742306510494, "episode": 67.0, "batch_reward": 0.19321283681690693, "critic_loss": 0.3019294362068176, "actor_loss": -22.964188907623292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.936885833740234, "step": 67000}
{"episode_reward": 393.09235296833776, "episode": 68.0, "batch_reward": 0.19635731615126134, "critic_loss": 0.3198720016181469, "actor_loss": -23.009108137130738, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.480351448059082, "step": 68000}
{"episode_reward": 365.3036321860953, "episode": 69.0, "batch_reward": 0.19778695271909236, "critic_loss": 0.3223689487427473, "actor_loss": -23.27396635055542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.66940951347351, "step": 69000}
{"episode_reward": 127.6158785645936, "episode": 70.0, "batch_reward": 0.1960680839717388, "critic_loss": 0.33483434256911276, "actor_loss": -22.605464775085448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.364092111587524, "step": 70000}
{"episode_reward": 81.83837245824118, "episode": 71.0, "batch_reward": 0.19541957089304923, "critic_loss": 0.3274659290164709, "actor_loss": -23.353546548843383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.92196321487427, "step": 71000}
{"episode_reward": 398.0031801987341, "episode": 72.0, "batch_reward": 0.19815293253958224, "critic_loss": 0.35144263617694377, "actor_loss": -23.145427463531494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.53148126602173, "step": 72000}
{"episode_reward": 353.76317505865876, "episode": 73.0, "batch_reward": 0.20107321688532828, "critic_loss": 0.3281030298024416, "actor_loss": -23.670691299438477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.665481328964233, "step": 73000}
{"episode_reward": 247.99389151661575, "episode": 74.0, "batch_reward": 0.20089741012454032, "critic_loss": 0.334117050409317, "actor_loss": -23.593926277160644, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.511728048324585, "step": 74000}
{"episode_reward": 128.3828692216066, "episode": 75.0, "batch_reward": 0.2000300569087267, "critic_loss": 0.32815818122029305, "actor_loss": -23.52705125427246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.135338306427002, "step": 75000}
{"episode_reward": 233.5881401795849, "episode": 76.0, "batch_reward": 0.1995976710021496, "critic_loss": 0.3177811727672815, "actor_loss": -23.294133134841918, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.188116788864136, "step": 76000}
{"episode_reward": 120.17356690657728, "episode": 77.0, "batch_reward": 0.19958625434339047, "critic_loss": 0.35024132680892944, "actor_loss": -23.364009826660155, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.263039588928223, "step": 77000}
{"episode_reward": 343.839507979869, "episode": 78.0, "batch_reward": 0.20044042687118052, "critic_loss": 0.34344688481092456, "actor_loss": -23.626072574615478, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.541738510131836, "step": 78000}
{"episode_reward": 90.08289191969116, "episode": 79.0, "batch_reward": 0.20056726349890233, "critic_loss": 0.33074659088253977, "actor_loss": -23.481452186584473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54483723640442, "step": 79000}
{"episode_reward": 361.5528393175905, "episode": 80.0, "batch_reward": 0.20165318210422992, "critic_loss": 0.3275296796783805, "actor_loss": -23.420461128234862, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.692320346832275, "step": 80000}
{"episode_reward": 206.8756465961757, "episode": 81.0, "batch_reward": 0.20194983647763728, "critic_loss": 0.3589672090411186, "actor_loss": -23.64440175628662, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.85104012489319, "step": 81000}
{"episode_reward": 171.22734760472784, "episode": 82.0, "batch_reward": 0.20088084957003594, "critic_loss": 0.33233206361532214, "actor_loss": -23.439753818511964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.388508796691895, "step": 82000}
{"episode_reward": 153.401741490906, "episode": 83.0, "batch_reward": 0.20201065085828304, "critic_loss": 0.339669053286314, "actor_loss": -23.126012130737305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.520885229110718, "step": 83000}
{"episode_reward": 423.8044639032312, "episode": 84.0, "batch_reward": 0.2045022045224905, "critic_loss": 0.3472494968175888, "actor_loss": -23.201115825653076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.447840452194214, "step": 84000}
{"episode_reward": 300.9712932490063, "episode": 85.0, "batch_reward": 0.2064440222978592, "critic_loss": 0.3535560903698206, "actor_loss": -23.86169514846802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.473955154418945, "step": 85000}
{"episode_reward": 485.57757021040595, "episode": 86.0, "batch_reward": 0.20851690128445624, "critic_loss": 0.35753347285091874, "actor_loss": -23.943965679168702, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23742651939392, "step": 86000}
{"episode_reward": 457.34347170361514, "episode": 87.0, "batch_reward": 0.21194041180610657, "critic_loss": 0.3276985054463148, "actor_loss": -24.140361045837402, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.212711334228516, "step": 87000}
{"episode_reward": 438.78137464159715, "episode": 88.0, "batch_reward": 0.21460598587989807, "critic_loss": 0.3399987128227949, "actor_loss": -24.104555004119874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.471785068511963, "step": 88000}
{"episode_reward": 445.120375157623, "episode": 89.0, "batch_reward": 0.21615446777641772, "critic_loss": 0.3221362210214138, "actor_loss": -24.61064275741577, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.008243083953857, "step": 89000}
{"episode_reward": 166.25801681849347, "episode": 90.0, "batch_reward": 0.21630381411314012, "critic_loss": 0.33623173063993456, "actor_loss": -24.382237869262696, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.563743352890015, "step": 90000}
{"episode_reward": 472.9741123817176, "episode": 91.0, "batch_reward": 0.21917694076895713, "critic_loss": 0.33192485256493093, "actor_loss": -24.83201641845703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.807313203811646, "step": 91000}
{"episode_reward": 450.5802794498941, "episode": 92.0, "batch_reward": 0.22208612275123596, "critic_loss": 0.36118694037199023, "actor_loss": -25.090696266174316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.1361985206604, "step": 92000}
{"episode_reward": 517.519116144667, "episode": 93.0, "batch_reward": 0.2250477507710457, "critic_loss": 0.3543542566597462, "actor_loss": -25.320876865386964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.76833748817444, "step": 93000}
{"episode_reward": 442.20154968631596, "episode": 94.0, "batch_reward": 0.22710703298449517, "critic_loss": 0.349880812600255, "actor_loss": -25.347525104522706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.355947256088257, "step": 94000}
{"episode_reward": 241.25868193149395, "episode": 95.0, "batch_reward": 0.22781236484646797, "critic_loss": 0.36355731637775895, "actor_loss": -25.290188201904297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.74342131614685, "step": 95000}
{"episode_reward": 543.6773416945251, "episode": 96.0, "batch_reward": 0.23064020454883574, "critic_loss": 0.3856420958042145, "actor_loss": -25.637278800964356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.397674083709717, "step": 96000}
{"episode_reward": 482.89200512161653, "episode": 97.0, "batch_reward": 0.23289699836075306, "critic_loss": 0.36276421922445296, "actor_loss": -25.66548846054077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.28513193130493, "step": 97000}
{"episode_reward": 426.8378060002622, "episode": 98.0, "batch_reward": 0.23469216312468053, "critic_loss": 0.3835838837325573, "actor_loss": -26.2273625831604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.637762308120728, "step": 98000}
{"episode_reward": 280.99137325926824, "episode": 99.0, "batch_reward": 0.23596630251407624, "critic_loss": 0.397386355176568, "actor_loss": -26.041416801452637, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.89587426185608, "step": 99000}
{"episode_reward": 462.20975869334995, "episode": 100.0, "batch_reward": 0.2378361503481865, "critic_loss": 0.3698867295086384, "actor_loss": -26.34882735824585, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.227842807769775, "step": 100000}
{"episode_reward": 464.5122611207977, "episode": 101.0, "batch_reward": 0.24049344649910928, "critic_loss": 0.37351343388855457, "actor_loss": -26.384441104888914, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.787062644958496, "step": 101000}
{"episode_reward": 516.1097803626377, "episode": 102.0, "batch_reward": 0.24371411037445068, "critic_loss": 0.35181168262660506, "actor_loss": -26.660902004241944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.68240761756897, "step": 102000}
{"episode_reward": 473.1673922496411, "episode": 103.0, "batch_reward": 0.24521464468538762, "critic_loss": 0.38023891738057136, "actor_loss": -26.974915393829345, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.73476004600525, "step": 103000}
{"episode_reward": 456.1012155706809, "episode": 104.0, "batch_reward": 0.2475225668847561, "critic_loss": 0.3813924937695265, "actor_loss": -26.978117290496826, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.11482262611389, "step": 104000}
{"episode_reward": 439.24056340496236, "episode": 105.0, "batch_reward": 0.24916054029762744, "critic_loss": 0.37814704109728337, "actor_loss": -27.25103458404541, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.741806030273438, "step": 105000}
{"episode_reward": 307.9065358442665, "episode": 106.0, "batch_reward": 0.2500274018496275, "critic_loss": 0.38631520384550094, "actor_loss": -27.220575561523436, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.77656054496765, "step": 106000}
{"episode_reward": 496.7592245049996, "episode": 107.0, "batch_reward": 0.2522632424682379, "critic_loss": 0.3915606368482113, "actor_loss": -27.46811738204956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.508082628250122, "step": 107000}
{"episode_reward": 449.03177607603936, "episode": 108.0, "batch_reward": 0.25342265439033507, "critic_loss": 0.3618936394006014, "actor_loss": -27.788259078979493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.750136613845825, "step": 108000}
{"episode_reward": 524.8562045407202, "episode": 109.0, "batch_reward": 0.25626389403641225, "critic_loss": 0.37651410134136676, "actor_loss": -27.612009365081786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.64301109313965, "step": 109000}
{"episode_reward": 510.019520639363, "episode": 110.0, "batch_reward": 0.2585703807324171, "critic_loss": 0.3957463199645281, "actor_loss": -27.710229709625246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.383089780807495, "step": 110000}
{"episode_reward": 445.5241425331715, "episode": 111.0, "batch_reward": 0.2604032513797283, "critic_loss": 0.36506278955936433, "actor_loss": -28.408282978057862, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.45255160331726, "step": 111000}
{"episode_reward": 517.0352430614752, "episode": 112.0, "batch_reward": 0.2625262141674757, "critic_loss": 0.35650028333067896, "actor_loss": -28.07277104949951, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.498772859573364, "step": 112000}
{"episode_reward": 383.81681905471714, "episode": 113.0, "batch_reward": 0.2646642114371061, "critic_loss": 0.35243662625551225, "actor_loss": -28.425816387176514, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.891641855239868, "step": 113000}
{"episode_reward": 578.5657497640381, "episode": 114.0, "batch_reward": 0.26504325240850446, "critic_loss": 0.35854893518984315, "actor_loss": -28.189634517669678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.607385396957397, "step": 114000}
{"episode_reward": 299.42327762552657, "episode": 115.0, "batch_reward": 0.26617879785597326, "critic_loss": 0.3682400839179754, "actor_loss": -28.506707599639892, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.66034245491028, "step": 115000}
{"episode_reward": 350.473313962315, "episode": 116.0, "batch_reward": 0.26852518643438816, "critic_loss": 0.3903346356004477, "actor_loss": -28.51366855621338, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.869035482406616, "step": 116000}
{"episode_reward": 536.6382882251985, "episode": 117.0, "batch_reward": 0.2699994417577982, "critic_loss": 0.37549692411720753, "actor_loss": -29.18214743041992, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.5524959564209, "step": 117000}
{"episode_reward": 594.3221835123454, "episode": 118.0, "batch_reward": 0.27327174066007137, "critic_loss": 0.38718808875977995, "actor_loss": -29.24540807723999, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.69409465789795, "step": 118000}
{"episode_reward": 543.0746135038358, "episode": 119.0, "batch_reward": 0.27544725900888445, "critic_loss": 0.40148144955933096, "actor_loss": -29.199236064910888, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.445115327835083, "step": 119000}
{"episode_reward": 533.2168764966757, "episode": 120.0, "batch_reward": 0.2763350370079279, "critic_loss": 0.36580282808840275, "actor_loss": -29.597687339782716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.94208264350891, "step": 120000}
{"episode_reward": 536.0842136940691, "episode": 121.0, "batch_reward": 0.2785856758803129, "critic_loss": 0.3810947457849979, "actor_loss": -29.81230698776245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.65533113479614, "step": 121000}
{"episode_reward": 539.6653847907755, "episode": 122.0, "batch_reward": 0.28199869735538957, "critic_loss": 0.37846455435454845, "actor_loss": -30.052536430358888, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.59799551963806, "step": 122000}
{"episode_reward": 525.646274143293, "episode": 123.0, "batch_reward": 0.283417051538825, "critic_loss": 0.3710604516118765, "actor_loss": -29.735092235565187, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.519047260284424, "step": 123000}
{"episode_reward": 524.8858305751243, "episode": 124.0, "batch_reward": 0.2838606609404087, "critic_loss": 0.3710833775997162, "actor_loss": -30.18653267288208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.274245500564575, "step": 124000}
{"episode_reward": 128.85607731240324, "episode": 125.0, "batch_reward": 0.2845683881938457, "critic_loss": 0.36242168088257315, "actor_loss": -29.97735329055786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.047813892364502, "step": 125000}
{"episode_reward": 558.0038842497363, "episode": 126.0, "batch_reward": 0.2870183742046356, "critic_loss": 0.37351281332969666, "actor_loss": -30.585704380035402, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.62069582939148, "step": 126000}
{"episode_reward": 500.37786738765374, "episode": 127.0, "batch_reward": 0.2880011694729328, "critic_loss": 0.3905296614468098, "actor_loss": -30.488967781066894, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.591878175735474, "step": 127000}
{"episode_reward": 521.494014398048, "episode": 128.0, "batch_reward": 0.28959974883496764, "critic_loss": 0.3665967751741409, "actor_loss": -30.568155536651613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.74100399017334, "step": 128000}
{"episode_reward": 464.1617660737974, "episode": 129.0, "batch_reward": 0.29175713163614275, "critic_loss": 0.3755079957097769, "actor_loss": -31.0161469039917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.60615849494934, "step": 129000}
{"episode_reward": 556.8884960932756, "episode": 130.0, "batch_reward": 0.29393063056468965, "critic_loss": 0.3713755739927292, "actor_loss": -31.13368996810913, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.412802934646606, "step": 130000}
{"episode_reward": 341.2052980796261, "episode": 131.0, "batch_reward": 0.29473070771992205, "critic_loss": 0.36721996049582956, "actor_loss": -31.094841171264648, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.43046545982361, "step": 131000}
{"episode_reward": 475.097420887223, "episode": 132.0, "batch_reward": 0.29413714675605296, "critic_loss": 0.3729875822514296, "actor_loss": -30.8071823425293, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.60339641571045, "step": 132000}
{"episode_reward": 539.4325671185691, "episode": 133.0, "batch_reward": 0.2974614815860987, "critic_loss": 0.37510814996063707, "actor_loss": -31.375155506134032, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.42194700241089, "step": 133000}
{"episode_reward": 567.4390502900209, "episode": 134.0, "batch_reward": 0.2983642897903919, "critic_loss": 0.39442346401512623, "actor_loss": -31.748457374572755, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.764521598815918, "step": 134000}
{"episode_reward": 179.44536250064942, "episode": 135.0, "batch_reward": 0.29811409533023836, "critic_loss": 0.42473155120015144, "actor_loss": -31.16600039291382, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.228550672531128, "step": 135000}
{"episode_reward": 560.7376681190661, "episode": 136.0, "batch_reward": 0.29960434909164907, "critic_loss": 0.3936938170045614, "actor_loss": -32.132089836120606, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.90520477294922, "step": 136000}
{"episode_reward": 173.6914311998559, "episode": 137.0, "batch_reward": 0.2989475019723177, "critic_loss": 0.36116057619452474, "actor_loss": -31.528080814361573, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.311738967895508, "step": 137000}
{"episode_reward": 128.1522918168533, "episode": 138.0, "batch_reward": 0.29923863999545575, "critic_loss": 0.38882017254829404, "actor_loss": -31.486830406188965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.651028156280518, "step": 138000}
{"episode_reward": 511.0394007347779, "episode": 139.0, "batch_reward": 0.3000618433952332, "critic_loss": 0.3966163585036993, "actor_loss": -31.67304480743408, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27996277809143, "step": 139000}
{"episode_reward": 547.5158096841936, "episode": 140.0, "batch_reward": 0.30180612502992155, "critic_loss": 0.36363486871123313, "actor_loss": -31.840919624328613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.598992347717285, "step": 140000}
{"episode_reward": 595.1186278663496, "episode": 141.0, "batch_reward": 0.3034875660091639, "critic_loss": 0.3953196524977684, "actor_loss": -31.89746642303467, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.326770544052124, "step": 141000}
{"episode_reward": 206.86002979627608, "episode": 142.0, "batch_reward": 0.3016222910732031, "critic_loss": 0.3790881377905607, "actor_loss": -32.031265480041505, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.422716856002808, "step": 142000}
{"episode_reward": 300.1394948307817, "episode": 143.0, "batch_reward": 0.30287642060220243, "critic_loss": 0.37696616449952125, "actor_loss": -32.18839682388305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.512203454971313, "step": 143000}
{"episode_reward": 518.3981847419324, "episode": 144.0, "batch_reward": 0.30384155325591566, "critic_loss": 0.3808377613127232, "actor_loss": -31.891522804260255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.593145608901978, "step": 144000}
{"episode_reward": 583.2372393284336, "episode": 145.0, "batch_reward": 0.30641161191463473, "critic_loss": 0.4048375268876553, "actor_loss": -32.08443032836914, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.752785682678223, "step": 145000}
{"episode_reward": 572.5470632047532, "episode": 146.0, "batch_reward": 0.308239121645689, "critic_loss": 0.40917649191617966, "actor_loss": -32.17389125823975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.27491593360901, "step": 146000}
{"episode_reward": 578.2877174611933, "episode": 147.0, "batch_reward": 0.3092469371110201, "critic_loss": 0.3934590001702309, "actor_loss": -32.473123683929444, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.076195001602173, "step": 147000}
{"episode_reward": 583.6441897204397, "episode": 148.0, "batch_reward": 0.3115518644452095, "critic_loss": 0.38257485151290893, "actor_loss": -32.69541081619263, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.149527549743652, "step": 148000}
{"episode_reward": 525.1242544415816, "episode": 149.0, "batch_reward": 0.31264683121442793, "critic_loss": 0.4069857123196125, "actor_loss": -32.82427967453003, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.556915998458862, "step": 149000}
{"episode_reward": 538.6398833691227, "episode": 150.0, "batch_reward": 0.31531150203943253, "critic_loss": 0.4189854558110237, "actor_loss": -32.807670722961426, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
