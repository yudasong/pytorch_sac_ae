{"episode": 1.0, "duration": 19.670186042785645, "episode_reward": 7.300100444933085, "step": 1000}
{"episode": 2.0, "duration": 1.7817447185516357, "episode_reward": 521.6090064697321, "step": 2000}
{"episode": 3.0, "batch_reward": 0.25771126505850794, "actor_loss": -45.470282167613675, "actor_target_entropy": -6.0, "alpha_value": 0.010699999250839183, "duration": 54.12624955177307, "episode_reward": 230.73587179111306, "step": 3000}
{"episode": 4.0, "batch_reward": 0.22749229285120964, "actor_loss": -41.715903038024905, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 23.664320468902588, "episode_reward": 90.26732614341577, "step": 4000}
{"episode": 5.0, "batch_reward": 0.20037311297655105, "actor_loss": -38.63082157897949, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.114738941192627, "episode_reward": 90.30113230780772, "step": 5000}
{"episode": 6.0, "batch_reward": 0.17260059470683337, "actor_loss": -36.301073783874514, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.94839859008789, "episode_reward": 17.006361369776616, "step": 6000}
{"episode": 7.0, "batch_reward": 0.1567922954708338, "actor_loss": -35.795796699523926, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.677520275115967, "episode_reward": 121.17936405452895, "step": 7000}
{"episode": 8.0, "batch_reward": 0.14920614928007125, "actor_loss": -35.63940872192383, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.503151416778564, "episode_reward": 99.51983799470608, "step": 8000}
{"episode": 9.0, "batch_reward": 0.14415076688677073, "actor_loss": -35.514242889404294, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.203749656677246, "episode_reward": 96.35490402500906, "step": 9000}
{"episode": 10.0, "batch_reward": 0.13900107157975436, "actor_loss": -30.920415657043456, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 5108.430350065231, "episode_reward": 123.28895381528756, "step": 10000}
{"episode": 11.0, "batch_reward": 0.14150505028665067, "actor_loss": -31.15049115753174, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 29.863385915756226, "episode_reward": 166.10688918825937, "step": 11000}
{"episode": 12.0, "batch_reward": 0.1402347309589386, "actor_loss": -28.23065605545044, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 560.7481405735016, "episode_reward": 120.20407975862055, "step": 12000}
{"episode": 13.0, "batch_reward": 0.14038741888850928, "actor_loss": -28.14612502670288, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.348188638687134, "episode_reward": 119.54704169026263, "step": 13000}
{"episode": 14.0, "batch_reward": 0.14099763936549425, "actor_loss": -25.47309195327759, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 556.3573093414307, "episode_reward": 217.80860995961876, "step": 14000}
{"episode": 15.0, "batch_reward": 0.14986683353036642, "actor_loss": -25.95334532928467, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 23.678540229797363, "episode_reward": 339.4203317878264, "step": 15000}
{"episode": 16.0, "batch_reward": 0.1586785633713007, "actor_loss": -24.586880851745605, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 557.7587168216705, "episode_reward": 196.7697788935542, "step": 16000}
{"episode": 17.0, "batch_reward": 0.16179308443516494, "actor_loss": -24.80659383773804, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.681463479995728, "episode_reward": 153.49493348719625, "step": 17000}
{"episode": 18.0, "batch_reward": 0.1597130987048149, "actor_loss": -23.546859085083007, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 553.5390355587006, "episode_reward": 182.07663165304933, "step": 18000}
{"episode": 19.0, "batch_reward": 0.15976201467216014, "actor_loss": -23.449995246887205, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.08873224258423, "episode_reward": 81.28631543362309, "step": 19000}
{"episode": 20.0, "batch_reward": 0.1573698238953948, "actor_loss": -21.812965660095216, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 558.4542856216431, "episode_reward": 192.04313231672384, "step": 20000}
{"episode": 21.0, "batch_reward": 0.1599788660556078, "actor_loss": -22.14427795410156, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 29.0919349193573, "episode_reward": 215.7298881507871, "step": 21000}
{"episode": 22.0, "batch_reward": 0.16102706337720155, "actor_loss": -21.4053021774292, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 553.0209736824036, "episode_reward": 112.65570499409719, "step": 22000}
{"episode": 23.0, "batch_reward": 0.16158882489800452, "actor_loss": -21.22981748199463, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.126951694488525, "episode_reward": 257.8347261861542, "step": 23000}
{"episode": 24.0, "batch_reward": 0.16441909950971603, "actor_loss": -20.286145881652832, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 554.6834380626678, "episode_reward": 225.66467387201567, "step": 24000}
{"episode": 25.0, "batch_reward": 0.16713073752820493, "actor_loss": -20.577664840698244, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.421735286712646, "episode_reward": 222.75755921559343, "step": 25000}
{"episode": 26.0, "batch_reward": 0.16568299232423306, "actor_loss": -19.798295501708985, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 557.863986492157, "episode_reward": 31.885002546381237, "step": 26000}
{"episode": 27.0, "batch_reward": 0.16527865850925447, "actor_loss": -19.628180389404296, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.94421100616455, "episode_reward": 299.93069989124524, "step": 27000}
{"episode": 28.0, "batch_reward": 0.16613253688812255, "actor_loss": -19.10559927368164, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 559.7818377017975, "episode_reward": 45.29343767577134, "step": 28000}
{"episode": 29.0, "batch_reward": 0.16486373174190522, "actor_loss": -18.818024950027464, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.186136722564697, "episode_reward": 233.54467689012117, "step": 29000}
{"episode": 30.0, "batch_reward": 0.16530726988613606, "actor_loss": -18.48714905166626, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 556.2171316146851, "episode_reward": 78.57813641381462, "step": 30000}
{"episode": 31.0, "batch_reward": 0.1650828124731779, "actor_loss": -18.22469401359558, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.435792207717896, "episode_reward": 283.5400863681754, "step": 31000}
{"episode": 32.0, "batch_reward": 0.16677001084387302, "actor_loss": -18.166132263183595, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 559.0552639961243, "episode_reward": 113.04306780108095, "step": 32000}
{"episode": 33.0, "batch_reward": 0.1629721987247467, "actor_loss": -17.641186141967772, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 24.626516103744507, "episode_reward": 32.360999629159636, "step": 33000}
{"episode": 34.0, "batch_reward": 0.16270555590093136, "actor_loss": -17.331794713974, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 555.6506471633911, "episode_reward": 263.5266617663283, "step": 34000}
{"episode": 35.0, "batch_reward": 0.1659631322324276, "actor_loss": -17.85391279411316, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.707477331161499, "episode_reward": 293.1844654193075, "step": 35000}
{"episode": 36.0, "batch_reward": 0.16891509352624418, "actor_loss": -18.008614072799684, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 555.0005686283112, "episode_reward": 240.41140540021735, "step": 36000}
{"episode": 37.0, "batch_reward": 0.1703964591175318, "actor_loss": -18.024495788574217, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.397053718566895, "episode_reward": 251.37259006714675, "step": 37000}
{"episode": 38.0, "batch_reward": 0.17323250548541547, "actor_loss": -18.39789104270935, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 557.6775171756744, "episode_reward": 301.62797605466204, "step": 38000}
{"episode": 39.0, "batch_reward": 0.17636872529983522, "actor_loss": -18.75644317817688, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.041948795318604, "episode_reward": 287.98269395892635, "step": 39000}
{"episode": 40.0, "batch_reward": 0.17947994662821293, "actor_loss": -19.139569025039673, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 554.2988715171814, "episode_reward": 227.0763076563401, "step": 40000}
{"episode": 41.0, "batch_reward": 0.17989739707112312, "actor_loss": -19.038429565429688, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 41.76365780830383, "episode_reward": 112.28969582118212, "step": 41000}
{"episode": 42.0, "batch_reward": 0.17866279032826424, "actor_loss": -18.94890185546875, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 547.6593945026398, "episode_reward": 270.2147675997588, "step": 42000}
{"episode": 43.0, "batch_reward": 0.18106380324065685, "actor_loss": -19.19584666442871, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.011373043060303, "episode_reward": 328.45190197634037, "step": 43000}
{"episode": 44.0, "batch_reward": 0.18270623487234117, "actor_loss": -19.300200710296632, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 557.2650780677795, "episode_reward": 76.95699114138401, "step": 44000}
{"episode": 45.0, "batch_reward": 0.18257835420966148, "actor_loss": -19.18974139213562, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.96561884880066, "episode_reward": 197.16494026094412, "step": 45000}
{"episode": 46.0, "batch_reward": 0.18315413090586663, "actor_loss": -19.333798364639282, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 554.1309502124786, "episode_reward": 292.00224665219815, "step": 46000}
{"episode": 47.0, "batch_reward": 0.18561653995513916, "actor_loss": -19.429993162155153, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.37490177154541, "episode_reward": 245.9996673352687, "step": 47000}
{"episode": 48.0, "batch_reward": 0.18580562014877797, "actor_loss": -19.14382513999939, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 549.4262609481812, "episode_reward": 199.13017271885917, "step": 48000}
{"episode": 49.0, "batch_reward": 0.18483140583336352, "actor_loss": -19.069033143997192, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.42730164527893, "episode_reward": 63.57077477134283, "step": 49000}
{"episode": 50.0, "batch_reward": 0.18414055024087428, "actor_loss": -18.96862209701538, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 554.3715846538544, "episode_reward": 348.70562368802547, "step": 50000}
{"episode": 51.0, "batch_reward": 0.1866935047507286, "actor_loss": -19.197000326156616, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 36.76160788536072, "episode_reward": 212.3579045357501, "step": 51000}
{"episode": 52.0, "batch_reward": 0.18814577174186706, "actor_loss": -18.91476606941223, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 554.0614483356476, "episode_reward": 279.24966906476635, "step": 52000}
{"episode": 53.0, "batch_reward": 0.18963198852539062, "actor_loss": -19.06731458091736, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.410123825073242, "episode_reward": 316.7733137149765, "step": 53000}
{"episode": 54.0, "batch_reward": 0.19315439356863498, "actor_loss": -19.13292368507385, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 552.467169046402, "episode_reward": 419.72388121460693, "step": 54000}
{"episode": 55.0, "batch_reward": 0.19681843158602713, "actor_loss": -19.54475819015503, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.047107696533203, "episode_reward": 434.0415114438596, "step": 55000}
{"episode": 56.0, "batch_reward": 0.20103272366523742, "actor_loss": -19.805304431915282, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 555.920820236206, "episode_reward": 395.4793792469884, "step": 56000}
{"episode": 57.0, "batch_reward": 0.20522840017080307, "actor_loss": -20.113845708847045, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.862359762191772, "episode_reward": 358.17379617748855, "step": 57000}
{"episode": 58.0, "batch_reward": 0.2071026195883751, "actor_loss": -20.112829751968384, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 552.5378787517548, "episode_reward": 284.75157298989, "step": 58000}
{"episode": 59.0, "batch_reward": 0.20812423525750637, "actor_loss": -20.056774467468262, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.1673002243042, "episode_reward": 354.31648282212603, "step": 59000}
{"episode": 60.0, "batch_reward": 0.2104746823310852, "actor_loss": -20.381633615493776, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 553.7223255634308, "episode_reward": 392.75143015208454, "step": 60000}
{"episode": 61.0, "batch_reward": 0.21303673920035363, "actor_loss": -20.516122158050536, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 28.484519720077515, "episode_reward": 154.8813649458431, "step": 61000}
{"episode": 62.0, "batch_reward": 0.2113281383216381, "actor_loss": -20.03877979850769, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 548.6347694396973, "episode_reward": 81.5810176992276, "step": 62000}
{"episode": 63.0, "batch_reward": 0.21058992677927016, "actor_loss": -19.92103173828125, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.003437042236328, "episode_reward": 345.1959028181325, "step": 63000}
{"episode": 64.0, "batch_reward": 0.21111637653410434, "actor_loss": -20.171802715301514, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 544.7494444847107, "episode_reward": 96.51455627735285, "step": 64000}
{"episode": 65.0, "batch_reward": 0.2115759090036154, "actor_loss": -19.998860092163085, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.692753553390503, "episode_reward": 257.68846749096485, "step": 65000}
{"episode": 66.0, "batch_reward": 0.21159708912670613, "actor_loss": -19.64280927276611, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 554.0170319080353, "episode_reward": 229.75651942716016, "step": 66000}
{"episode": 67.0, "batch_reward": 0.2123962160050869, "actor_loss": -19.680397638320922, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.026407957077026, "episode_reward": 419.13505117091375, "step": 67000}
{"episode": 68.0, "batch_reward": 0.21536774209141732, "actor_loss": -20.34047264289856, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 550.0034177303314, "episode_reward": 313.24621106517213, "step": 68000}
{"episode": 69.0, "batch_reward": 0.2172168957591057, "actor_loss": -20.4531121635437, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.591055393218994, "episode_reward": 459.8858229673046, "step": 69000}
{"episode": 70.0, "batch_reward": 0.22068112125992775, "actor_loss": -20.524991746902465, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 552.4955155849457, "episode_reward": 467.06252770405945, "step": 70000}
{"episode": 71.0, "batch_reward": 0.2237065435051918, "actor_loss": -20.834451219558716, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 37.8816442489624, "episode_reward": 452.19885018672613, "step": 71000}
{"episode": 72.0, "batch_reward": 0.22740116798877716, "actor_loss": -21.48672116088867, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 554.2242641448975, "episode_reward": 459.54244161525406, "step": 72000}
{"episode": 73.0, "batch_reward": 0.2289980184584856, "actor_loss": -21.63927243423462, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.19082760810852, "episode_reward": 192.37780673372137, "step": 73000}
{"episode": 74.0, "batch_reward": 0.22932453228533267, "actor_loss": -21.558120613098144, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 561.7234561443329, "episode_reward": 420.1292134591588, "step": 74000}
{"episode": 75.0, "batch_reward": 0.23282139311730862, "actor_loss": -21.90528472137451, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.48663306236267, "episode_reward": 445.4821304887698, "step": 75000}
{"episode": 76.0, "batch_reward": 0.23497663037478925, "actor_loss": -22.570880043029785, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 565.3994529247284, "episode_reward": 455.8696387409575, "step": 76000}
{"episode": 77.0, "batch_reward": 0.2383116099983454, "actor_loss": -23.043811672210694, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.60032367706299, "episode_reward": 443.64088166589056, "step": 77000}
{"episode": 78.0, "batch_reward": 0.2409947919100523, "actor_loss": -23.434173538208007, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 560.9046025276184, "episode_reward": 484.5014986277656, "step": 78000}
{"episode": 79.0, "batch_reward": 0.24250363200902939, "actor_loss": -23.57911666870117, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.35194683074951, "episode_reward": 377.419784564517, "step": 79000}
{"episode": 80.0, "batch_reward": 0.24561295282840728, "actor_loss": -24.174958602905274, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 567.595915555954, "episode_reward": 329.219588803331, "step": 80000}
{"episode": 81.0, "batch_reward": 0.24642640282213688, "actor_loss": -24.323823638916014, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 28.950740098953247, "episode_reward": 486.62856234067914, "step": 81000}
{"episode": 82.0, "batch_reward": 0.2494216558635235, "actor_loss": -25.090155143737793, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 555.2041232585907, "episode_reward": 441.5111648767279, "step": 82000}
{"episode": 83.0, "batch_reward": 0.25161972689628603, "actor_loss": -25.28506827926636, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.759235620498657, "episode_reward": 397.0671247904457, "step": 83000}
{"episode": 84.0, "batch_reward": 0.2531046873629093, "actor_loss": -25.56873448562622, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 554.6136376857758, "episode_reward": 468.83813295872113, "step": 84000}
{"episode": 85.0, "batch_reward": 0.25739439807832243, "actor_loss": -25.956798038482667, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 24.301956176757812, "episode_reward": 495.92645518833086, "step": 85000}
{"episode": 86.0, "batch_reward": 0.25926521879434583, "actor_loss": -26.251953426361084, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 555.9669997692108, "episode_reward": 492.1963521626434, "step": 86000}
{"episode": 87.0, "batch_reward": 0.2608719262331724, "actor_loss": -26.505903408050536, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 23.48295259475708, "episode_reward": 400.14718542885845, "step": 87000}
{"episode": 88.0, "batch_reward": 0.2643664570748806, "actor_loss": -26.902164710998534, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 554.83682513237, "episode_reward": 494.9457856569847, "step": 88000}
{"episode": 89.0, "batch_reward": 0.2658722355365753, "actor_loss": -27.138722480773925, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.60900354385376, "episode_reward": 463.827654534682, "step": 89000}
{"episode": 90.0, "batch_reward": 0.2679781034886837, "actor_loss": -27.195777725219727, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 555.7893016338348, "episode_reward": 459.0895770766402, "step": 90000}
{"episode": 91.0, "batch_reward": 0.2709605770409107, "actor_loss": -27.46890422439575, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 39.94711971282959, "episode_reward": 451.5471024404957, "step": 91000}
{"episode": 92.0, "batch_reward": 0.2715102087408304, "actor_loss": -27.643029304504395, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 539.7266862392426, "episode_reward": 425.57176357490374, "step": 92000}
{"episode": 93.0, "batch_reward": 0.2733333325684071, "actor_loss": -27.715624584197997, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.543527841567993, "episode_reward": 469.618393142976, "step": 93000}
{"episode": 94.0, "batch_reward": 0.2760297850072384, "actor_loss": -28.00115969467163, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 554.223637342453, "episode_reward": 462.476760210787, "step": 94000}
{"episode": 95.0, "batch_reward": 0.27797471433877946, "actor_loss": -28.173920722961427, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.318504810333252, "episode_reward": 468.93232721666783, "step": 95000}
{"episode": 96.0, "batch_reward": 0.2802481958270073, "actor_loss": -28.449328742980956, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 555.018857717514, "episode_reward": 497.17943523408684, "step": 96000}
{"episode": 97.0, "batch_reward": 0.2822199249565601, "actor_loss": -28.64593078994751, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 23.8674738407135, "episode_reward": 448.0351908445554, "step": 97000}
{"episode": 98.0, "batch_reward": 0.2837738818526268, "actor_loss": -28.6550380859375, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 553.5268232822418, "episode_reward": 417.09581544271066, "step": 98000}
{"episode": 99.0, "batch_reward": 0.2847410975247622, "actor_loss": -28.979845489501955, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.68034839630127, "episode_reward": 456.4316716080783, "step": 99000}
{"episode": 100.0, "batch_reward": 0.2857428335994482, "actor_loss": -29.17854920578003, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 555.6035857200623, "episode_reward": 462.7089946838479, "step": 100000}
{"episode": 101.0, "batch_reward": 0.2891714709401131, "actor_loss": -29.457835994720458, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 29.086092233657837, "episode_reward": 467.5352487791927, "step": 101000}
{"episode": 102.0, "batch_reward": 0.28928670582175253, "actor_loss": -29.544260440826417, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 554.3174078464508, "episode_reward": 443.8591621080816, "step": 102000}
{"episode": 103.0, "batch_reward": 0.2912054882645607, "actor_loss": -29.698309803009032, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 23.658494472503662, "episode_reward": 478.90200528466715, "step": 103000}
{"episode": 104.0, "batch_reward": 0.29367268158495424, "actor_loss": -29.67134118270874, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 556.9214420318604, "episode_reward": 417.5080043300729, "step": 104000}
{"episode": 105.0, "batch_reward": 0.295497613042593, "actor_loss": -29.821313484191894, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.801847457885742, "episode_reward": 436.69090260928476, "step": 105000}
{"episode": 106.0, "batch_reward": 0.2961046701967716, "actor_loss": -29.800249702453613, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 558.7138669490814, "episode_reward": 472.89193331612057, "step": 106000}
{"episode": 107.0, "batch_reward": 0.29863996474444865, "actor_loss": -29.888878158569337, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.725745677947998, "episode_reward": 495.7922036705441, "step": 107000}
{"episode": 108.0, "batch_reward": 0.2996397124528885, "actor_loss": -29.720555618286134, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 560.6408016681671, "episode_reward": 447.17796955425973, "step": 108000}
{"episode": 109.0, "batch_reward": 0.30130878038704395, "actor_loss": -29.947606857299803, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.96119999885559, "episode_reward": 501.067528850065, "step": 109000}
{"episode": 110.0, "batch_reward": 0.30084177426993847, "actor_loss": -29.61516876602173, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 552.6103625297546, "episode_reward": 452.4722383131764, "step": 110000}
{"episode": 111.0, "batch_reward": 0.3042334841936827, "actor_loss": -30.147167503356933, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 36.82640218734741, "episode_reward": 507.92368675406203, "step": 111000}
{"episode": 112.0, "batch_reward": 0.30601248602569103, "actor_loss": -29.93868013763428, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 553.4887118339539, "episode_reward": 469.9674158621991, "step": 112000}
{"episode": 113.0, "batch_reward": 0.3074622131288052, "actor_loss": -30.09807127380371, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.145980834960938, "episode_reward": 504.091656516453, "step": 113000}
{"episode": 114.0, "batch_reward": 0.3094857638180256, "actor_loss": -29.468839157104494, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 557.7627167701721, "episode_reward": 477.57134521622805, "step": 114000}
{"episode": 115.0, "batch_reward": 0.3111881805509329, "actor_loss": -29.544006507873537, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.895354509353638, "episode_reward": 515.8445539247964, "step": 115000}
{"episode": 116.0, "batch_reward": 0.31243816873431207, "actor_loss": -28.79681660079956, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 556.9977493286133, "episode_reward": 473.02855079616825, "step": 116000}
{"episode": 117.0, "batch_reward": 0.3140568060874939, "actor_loss": -28.99579142379761, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.205037117004395, "episode_reward": 509.1347017278633, "step": 117000}
{"episode": 118.0, "batch_reward": 0.31641599953174593, "actor_loss": -28.600379917144775, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 555.6767673492432, "episode_reward": 458.0786943973551, "step": 118000}
{"episode": 119.0, "batch_reward": 0.3167362544238567, "actor_loss": -28.57884294128418, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.991209030151367, "episode_reward": 490.7941153166775, "step": 119000}
{"episode": 120.0, "batch_reward": 0.3184681136608124, "actor_loss": -28.566635055541994, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 558.536863565445, "episode_reward": 521.6525129032499, "step": 120000}
{"episode": 121.0, "batch_reward": 0.32010030829906466, "actor_loss": -28.735708686828612, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 38.81735968589783, "episode_reward": 518.7224921529132, "step": 121000}
{"episode": 122.0, "batch_reward": 0.32167154106497764, "actor_loss": -28.360965438842772, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 561.7013273239136, "episode_reward": 532.7342663614193, "step": 122000}
{"episode": 123.0, "batch_reward": 0.32335429242253305, "actor_loss": -28.671060260772705, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.854843616485596, "episode_reward": 490.9661819280936, "step": 123000}
{"episode": 124.0, "batch_reward": 0.3244218077659607, "actor_loss": -29.16571961212158, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 560.5343308448792, "episode_reward": 442.57711643107564, "step": 124000}
{"episode": 125.0, "batch_reward": 0.325307397544384, "actor_loss": -29.363355136871338, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.1676082611084, "episode_reward": 458.5803576375992, "step": 125000}
{"episode": 126.0, "batch_reward": 0.32699573594331743, "actor_loss": -29.36221566390991, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 560.2927057743073, "episode_reward": 448.1071918646478, "step": 126000}
{"episode": 127.0, "batch_reward": 0.32699639996886254, "actor_loss": -29.254809471130372, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.190284252166748, "episode_reward": 458.3793725941157, "step": 127000}
{"episode": 128.0, "batch_reward": 0.32843096539378164, "actor_loss": -29.553175788879393, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 556.53173995018, "episode_reward": 446.54689639141736, "step": 128000}
{"episode": 129.0, "batch_reward": 0.3290499589145184, "actor_loss": -29.65050686645508, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.133253812789917, "episode_reward": 468.79676465290174, "step": 129000}
{"episode": 130.0, "batch_reward": 0.3309328111708164, "actor_loss": -29.441181983947754, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 563.6589045524597, "episode_reward": 474.80170316507787, "step": 130000}
{"episode": 131.0, "batch_reward": 0.3313119295835495, "actor_loss": -29.503537532806398, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 38.52512168884277, "episode_reward": 235.09606024677296, "step": 131000}
{"episode": 132.0, "batch_reward": 0.33096531772613524, "actor_loss": -29.924192707061767, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 559.161315202713, "episode_reward": 537.0725945726596, "step": 132000}
{"episode": 133.0, "batch_reward": 0.332781132042408, "actor_loss": -29.948314987182616, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.27956461906433, "episode_reward": 494.23970593006584, "step": 133000}
{"episode": 134.0, "batch_reward": 0.333773414760828, "actor_loss": -30.493720932006838, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 562.2412538528442, "episode_reward": 420.4534759854339, "step": 134000}
{"episode": 135.0, "batch_reward": 0.33451314535737037, "actor_loss": -30.583586738586426, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.092803239822388, "episode_reward": 253.56523945900145, "step": 135000}
{"episode": 136.0, "batch_reward": 0.33301650816202166, "actor_loss": -30.404995124816896, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 560.6563279628754, "episode_reward": 478.4307800308544, "step": 136000}
{"episode": 137.0, "batch_reward": 0.3354257087409496, "actor_loss": -30.68052853012085, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.268648386001587, "episode_reward": 458.90788369547283, "step": 137000}
{"episode": 138.0, "batch_reward": 0.33599508079886437, "actor_loss": -30.930513847351076, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 552.2851877212524, "episode_reward": 495.7256368518142, "step": 138000}
{"episode": 139.0, "batch_reward": 0.33667289140820505, "actor_loss": -31.097842502593995, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.995139360427856, "episode_reward": 527.6429364751136, "step": 139000}
{"episode": 140.0, "batch_reward": 0.3383409214615822, "actor_loss": -31.5018018951416, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 557.3370354175568, "episode_reward": 455.67939074395423, "step": 140000}
{"episode": 141.0, "batch_reward": 0.3390689442455769, "actor_loss": -31.71616373825073, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 38.08921408653259, "episode_reward": 442.9513872717102, "step": 141000}
{"episode": 142.0, "batch_reward": 0.3409833624660969, "actor_loss": -31.920648609161375, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 542.5547747612, "episode_reward": 496.44695124733056, "step": 142000}
{"episode": 143.0, "batch_reward": 0.3411099275946617, "actor_loss": -32.04086499404907, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.56473445892334, "episode_reward": 468.41528105659285, "step": 143000}
{"episode": 144.0, "batch_reward": 0.3414306881427765, "actor_loss": -32.32069888687134, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 559.1853008270264, "episode_reward": 407.77187846425994, "step": 144000}
{"episode": 145.0, "batch_reward": 0.3424861455857754, "actor_loss": -32.39673734283447, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.10112476348877, "episode_reward": 442.1285404795351, "step": 145000}
{"episode": 146.0, "batch_reward": 0.3431330625712872, "actor_loss": -32.005318092346194, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 557.1609916687012, "episode_reward": 484.3171884745004, "step": 146000}
{"episode": 147.0, "batch_reward": 0.3441374405622482, "actor_loss": -32.109270320892335, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.942734479904175, "episode_reward": 460.55816987133534, "step": 147000}
{"episode": 148.0, "batch_reward": 0.34463174909353256, "actor_loss": -31.83311722946167, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 531.6169493198395, "episode_reward": 425.3675126870165, "step": 148000}
{"episode": 149.0, "batch_reward": 0.3453521181643009, "actor_loss": -31.99508915710449, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.604864835739136, "episode_reward": 465.92543016811936, "step": 149000}
{"episode": 150.0, "batch_reward": 0.3459354285001755, "actor_loss": -31.966644744873047, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "step": 150000}
