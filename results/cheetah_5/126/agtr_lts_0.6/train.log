{"episode_reward": 0.0, "episode": 1.0, "duration": 16.913100481033325, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.4653410911560059, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.25106949397686046, "critic_loss": 0.20029007612282573, "actor_loss": -44.81163078634774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.9428334236145, "step": 3000}
{"episode_reward": 143.2675215039938, "episode": 4.0, "batch_reward": 0.2230342215001583, "critic_loss": 0.41548124347627163, "actor_loss": -44.39685981750488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.56840682029724, "step": 4000}
{"episode_reward": 156.30426897660027, "episode": 5.0, "batch_reward": 0.184650279738009, "critic_loss": 0.5526490628570319, "actor_loss": -42.635540843963625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52948546409607, "step": 5000}
{"episode_reward": 1.1942018263735825, "episode": 6.0, "batch_reward": 0.1790945306196809, "critic_loss": 1.0064656900763511, "actor_loss": -45.744654777526854, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.530781745910645, "step": 6000}
{"episode_reward": 424.86157196398943, "episode": 7.0, "batch_reward": 0.22310553301870822, "critic_loss": 0.8739819675683975, "actor_loss": -48.09469286346435, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.549087285995483, "step": 7000}
{"episode_reward": 484.40488030487364, "episode": 8.0, "batch_reward": 0.2377659828066826, "critic_loss": 1.106012022137642, "actor_loss": -47.94112804412842, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.553695917129517, "step": 8000}
{"episode_reward": 201.2746207598609, "episode": 9.0, "batch_reward": 0.22847259795665742, "critic_loss": 0.9110953174829483, "actor_loss": -48.584017875671385, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.553674936294556, "step": 9000}
{"episode_reward": 4.812734267684942, "episode": 10.0, "batch_reward": 0.20649976037442686, "critic_loss": 0.7206063273251057, "actor_loss": -47.68157044219971, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.5556960105896, "step": 10000}
{"episode_reward": 2.493292191523646, "episode": 11.0, "batch_reward": 0.19165643187612294, "critic_loss": 0.6617149933576584, "actor_loss": -47.71389720153809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.6067430973053, "step": 11000}
{"episode_reward": 241.93121233721837, "episode": 12.0, "batch_reward": 0.19869293715059758, "critic_loss": 0.6750560121536255, "actor_loss": -47.37853536987305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.566901445388794, "step": 12000}
{"episode_reward": 330.119151650274, "episode": 13.0, "batch_reward": 0.21309501057863237, "critic_loss": 0.5762642046511173, "actor_loss": -47.47308741760254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.57632875442505, "step": 13000}
{"episode_reward": 312.9001448137589, "episode": 14.0, "batch_reward": 0.20942578688263894, "critic_loss": 0.4416239052116871, "actor_loss": -45.71802136230469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.592259168624878, "step": 14000}
{"episode_reward": 3.703148361936955, "episode": 15.0, "batch_reward": 0.1956761927008629, "critic_loss": 0.3738338179439306, "actor_loss": -46.299342765808106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.56623673439026, "step": 15000}
{"episode_reward": 4.6149420063604785, "episode": 16.0, "batch_reward": 0.18299178510904313, "critic_loss": 0.335258863016963, "actor_loss": -44.212411384582516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.568711757659912, "step": 16000}
{"episode_reward": 3.558756149638156, "episode": 17.0, "batch_reward": 0.17233598399162292, "critic_loss": 0.2792255149334669, "actor_loss": -43.807851425170895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.57008981704712, "step": 17000}
{"episode_reward": 3.6271677950839605, "episode": 18.0, "batch_reward": 0.16311141317337752, "critic_loss": 0.236542815849185, "actor_loss": -43.01480712890625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.59192728996277, "step": 18000}
{"episode_reward": 4.090680535082199, "episode": 19.0, "batch_reward": 0.1550467809662223, "critic_loss": 0.23028248700499535, "actor_loss": -41.903267456054685, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.57849621772766, "step": 19000}
{"episode_reward": 7.393336941106734, "episode": 20.0, "batch_reward": 0.1521368062272668, "critic_loss": 0.23199114261567594, "actor_loss": -42.196966567993165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.552371501922607, "step": 20000}
{"episode_reward": 379.6165670597601, "episode": 21.0, "batch_reward": 0.1574067792147398, "critic_loss": 0.27590329524874685, "actor_loss": -41.754276359558105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.674357414245605, "step": 21000}
{"episode_reward": 5.579601053436878, "episode": 22.0, "batch_reward": 0.15029699287563564, "critic_loss": 0.27412683828175066, "actor_loss": -42.470207817077636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.557322025299072, "step": 22000}
{"episode_reward": 3.6698800742966045, "episode": 23.0, "batch_reward": 0.1443989523500204, "critic_loss": 0.22825671933591365, "actor_loss": -41.69332530975342, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.564630031585693, "step": 23000}
{"episode_reward": 5.248622108337264, "episode": 24.0, "batch_reward": 0.13857002102583646, "critic_loss": 0.22488221514225007, "actor_loss": -41.15974646759033, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.571774005889893, "step": 24000}
{"episode_reward": 6.831885280824763, "episode": 25.0, "batch_reward": 0.13273871839791537, "critic_loss": 0.18923168789595365, "actor_loss": -40.67640672302246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.560367584228516, "step": 25000}
{"episode_reward": 5.152458637117792, "episode": 26.0, "batch_reward": 0.128304138623178, "critic_loss": 0.16178033851832152, "actor_loss": -39.83774397277832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.56471586227417, "step": 26000}
{"episode_reward": 5.741537739092945, "episode": 27.0, "batch_reward": 0.12409482803195715, "critic_loss": 0.13640471626073122, "actor_loss": -39.59882162475586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.571030378341675, "step": 27000}
{"episode_reward": 6.6633687609309185, "episode": 28.0, "batch_reward": 0.11963263972848653, "critic_loss": 0.12683311047777535, "actor_loss": -38.763218841552735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.581448793411255, "step": 28000}
{"episode_reward": 116.92275287831136, "episode": 29.0, "batch_reward": 0.11883085180819035, "critic_loss": 0.12498497952893377, "actor_loss": -38.391061721801755, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.57384443283081, "step": 29000}
{"episode_reward": 12.224370850727405, "episode": 30.0, "batch_reward": 0.11816142483055592, "critic_loss": 0.11564154420420528, "actor_loss": -37.81272701263428, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.551443338394165, "step": 30000}
{"episode_reward": 281.1911730616191, "episode": 31.0, "batch_reward": 0.12160582282394171, "critic_loss": 0.12294672375917434, "actor_loss": -37.14033905792236, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.55076885223389, "step": 31000}
{"episode_reward": 68.87769335158727, "episode": 32.0, "batch_reward": 0.12357477348297835, "critic_loss": 0.1408595764376223, "actor_loss": -36.71851667785644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.548497438430786, "step": 32000}
{"episode_reward": 430.40170393681285, "episode": 33.0, "batch_reward": 0.13604890172928572, "critic_loss": 0.18109490857273342, "actor_loss": -36.73909984588623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.541183710098267, "step": 33000}
{"episode_reward": 520.6249162607895, "episode": 34.0, "batch_reward": 0.14695877126604318, "critic_loss": 0.20864096970856189, "actor_loss": -36.5742419052124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.547258138656616, "step": 34000}
{"episode_reward": 517.992182687324, "episode": 35.0, "batch_reward": 0.15764966879040002, "critic_loss": 0.21376061790436507, "actor_loss": -36.74745381164551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.542794227600098, "step": 35000}
{"episode_reward": 498.2359434724845, "episode": 36.0, "batch_reward": 0.16858218820393087, "critic_loss": 0.23048559164255858, "actor_loss": -36.957332077026365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.532678604125977, "step": 36000}
{"episode_reward": 612.7873607921832, "episode": 37.0, "batch_reward": 0.17866267225891352, "critic_loss": 0.31437788423895835, "actor_loss": -36.88109177398682, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.5482497215271, "step": 37000}
{"episode_reward": 284.253526476877, "episode": 38.0, "batch_reward": 0.18398298798501492, "critic_loss": 0.3578776289820671, "actor_loss": -36.37784205245972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.55440855026245, "step": 38000}
{"episode_reward": 541.1187454916702, "episode": 39.0, "batch_reward": 0.19179854317754508, "critic_loss": 0.45425732009112835, "actor_loss": -36.59885962677002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.561230182647705, "step": 39000}
{"episode_reward": 540.9648078982995, "episode": 40.0, "batch_reward": 0.19991396284103394, "critic_loss": 0.5606261056661606, "actor_loss": -36.873408203125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.56933879852295, "step": 40000}
{"episode_reward": 518.6821889405275, "episode": 41.0, "batch_reward": 0.20806665584445, "critic_loss": 0.5238919174522162, "actor_loss": -37.227815982818605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.54046416282654, "step": 41000}
{"episode_reward": 556.040092716188, "episode": 42.0, "batch_reward": 0.21551611751317978, "critic_loss": 0.46922934222221374, "actor_loss": -37.24040057373047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.553574085235596, "step": 42000}
{"episode_reward": 463.9897743331798, "episode": 43.0, "batch_reward": 0.22246163402497768, "critic_loss": 0.5042433298081159, "actor_loss": -37.58418077087402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.537779569625854, "step": 43000}
{"episode_reward": 474.983312567422, "episode": 44.0, "batch_reward": 0.22890221199393274, "critic_loss": 0.5654243369102478, "actor_loss": -37.58956154632568, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.547041654586792, "step": 44000}
{"episode_reward": 332.78054056042674, "episode": 45.0, "batch_reward": 0.23093284748494625, "critic_loss": 0.6471739092171193, "actor_loss": -37.49130867004394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.546854972839355, "step": 45000}
{"episode_reward": 504.29975959294114, "episode": 46.0, "batch_reward": 0.23616988638043404, "critic_loss": 0.5819008396118879, "actor_loss": -37.924410163879394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.557629108428955, "step": 46000}
{"episode_reward": 515.1339793147803, "episode": 47.0, "batch_reward": 0.24329210612177848, "critic_loss": 0.610757597193122, "actor_loss": -38.26311532211304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.549097776412964, "step": 47000}
{"episode_reward": 551.9042223596643, "episode": 48.0, "batch_reward": 0.25140712840855123, "critic_loss": 0.5602403962612152, "actor_loss": -38.662350357055665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.53627848625183, "step": 48000}
{"episode_reward": 567.6735077372454, "episode": 49.0, "batch_reward": 0.25788221886754037, "critic_loss": 0.5457524726390839, "actor_loss": -38.99210051727295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.554697036743164, "step": 49000}
{"episode_reward": 566.3795554386049, "episode": 50.0, "batch_reward": 0.26181704112887383, "critic_loss": 0.5983163801431656, "actor_loss": -38.89471252441406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.532105684280396, "step": 50000}
{"episode_reward": 409.9775057400029, "episode": 51.0, "batch_reward": 0.2663597480207682, "critic_loss": 0.6463094909191132, "actor_loss": -38.634534187316895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.49198627471924, "step": 51000}
{"episode_reward": 459.0130141840097, "episode": 52.0, "batch_reward": 0.26997253181040287, "critic_loss": 0.5948169337809086, "actor_loss": -38.952651477813724, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.54627513885498, "step": 52000}
{"episode_reward": 486.87105001868673, "episode": 53.0, "batch_reward": 0.27245127560198307, "critic_loss": 0.6792417809665203, "actor_loss": -38.199215614318845, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.560131549835205, "step": 53000}
{"episode_reward": 273.46132666711213, "episode": 54.0, "batch_reward": 0.2747321263998747, "critic_loss": 0.5766767183989286, "actor_loss": -38.77925112915039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.555358409881592, "step": 54000}
{"episode_reward": 641.7060649764983, "episode": 55.0, "batch_reward": 0.27892885680496693, "critic_loss": 0.5828690989613533, "actor_loss": -38.83473385238648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.55245327949524, "step": 55000}
{"episode_reward": 303.0410028657683, "episode": 56.0, "batch_reward": 0.2807819260954857, "critic_loss": 0.5585957443267107, "actor_loss": -38.47219519042969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.541739225387573, "step": 56000}
{"episode_reward": 581.9835887891894, "episode": 57.0, "batch_reward": 0.286532932266593, "critic_loss": 0.5817383551597595, "actor_loss": -38.681840896606445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.550904989242554, "step": 57000}
{"episode_reward": 423.14605710879164, "episode": 58.0, "batch_reward": 0.28881278659403326, "critic_loss": 0.5895751594603061, "actor_loss": -38.660324062347414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.544483423233032, "step": 58000}
{"episode_reward": 559.944463601489, "episode": 59.0, "batch_reward": 0.2937611869424582, "critic_loss": 0.5709510117173194, "actor_loss": -38.81525703048706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.53795051574707, "step": 59000}
{"episode_reward": 617.9281167736775, "episode": 60.0, "batch_reward": 0.2976495863199234, "critic_loss": 0.5422610381543637, "actor_loss": -39.06278032684326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.55137825012207, "step": 60000}
{"episode_reward": 570.4811614014067, "episode": 61.0, "batch_reward": 0.3029158686995506, "critic_loss": 0.5131580323129893, "actor_loss": -39.41232062149048, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.567803144454956, "step": 61000}
{"episode_reward": 520.0935376674346, "episode": 62.0, "batch_reward": 0.30598661087453366, "critic_loss": 0.519084073394537, "actor_loss": -39.13837089538574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.56256604194641, "step": 62000}
{"episode_reward": 413.0109723714223, "episode": 63.0, "batch_reward": 0.3073646914660931, "critic_loss": 0.47205641780793667, "actor_loss": -38.981145637512206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.555155992507935, "step": 63000}
{"episode_reward": 613.7124308598006, "episode": 64.0, "batch_reward": 0.31351870694756506, "critic_loss": 0.4442677283287048, "actor_loss": -39.608234718322755, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.54436945915222, "step": 64000}
{"episode_reward": 646.4171476883965, "episode": 65.0, "batch_reward": 0.3178217605948448, "critic_loss": 0.4496036836057901, "actor_loss": -39.660885822296144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.5476655960083, "step": 65000}
{"episode_reward": 524.1412383310274, "episode": 66.0, "batch_reward": 0.32037368752062323, "critic_loss": 0.43312816542387006, "actor_loss": -39.97963354873657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.55240225791931, "step": 66000}
{"episode_reward": 312.6181501668387, "episode": 67.0, "batch_reward": 0.3202200963050127, "critic_loss": 0.43558759102225303, "actor_loss": -39.61159732437134, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.57388710975647, "step": 67000}
{"episode_reward": 241.15212085056922, "episode": 68.0, "batch_reward": 0.32077702608704567, "critic_loss": 0.43751381477713586, "actor_loss": -39.71673010253906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.568342447280884, "step": 68000}
{"episode_reward": 629.056484388179, "episode": 69.0, "batch_reward": 0.3252994817495346, "critic_loss": 0.4304194682687521, "actor_loss": -39.8910475769043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.56780219078064, "step": 69000}
{"episode_reward": 606.454069808928, "episode": 70.0, "batch_reward": 0.3292664984166622, "critic_loss": 0.4301069983690977, "actor_loss": -40.46674153137207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.644930124282837, "step": 70000}
{"episode_reward": 593.2751591640202, "episode": 71.0, "batch_reward": 0.3302770307064056, "critic_loss": 0.42577986045181754, "actor_loss": -40.0369700050354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.56989097595215, "step": 71000}
{"episode_reward": 624.0828409771497, "episode": 72.0, "batch_reward": 0.33624675816297533, "critic_loss": 0.4017516275793314, "actor_loss": -40.69914860534668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.5308575630188, "step": 72000}
{"episode_reward": 662.0447353162599, "episode": 73.0, "batch_reward": 0.33938906729221346, "critic_loss": 0.3944835506975651, "actor_loss": -40.84238069152832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.536733388900757, "step": 73000}
{"episode_reward": 587.6160346438887, "episode": 74.0, "batch_reward": 0.344081573754549, "critic_loss": 0.3963169500529766, "actor_loss": -41.12351517486572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.543734073638916, "step": 74000}
{"episode_reward": 553.6490117281352, "episode": 75.0, "batch_reward": 0.34910150489211084, "critic_loss": 0.38592874954640866, "actor_loss": -41.45967361450195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.548399448394775, "step": 75000}
{"episode_reward": 647.3540203340998, "episode": 76.0, "batch_reward": 0.3500355086922646, "critic_loss": 0.3981380427032709, "actor_loss": -41.62234684753418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.552515745162964, "step": 76000}
{"episode_reward": 197.32351011478485, "episode": 77.0, "batch_reward": 0.34922408959269524, "critic_loss": 0.38445792701840403, "actor_loss": -41.28442953491211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.54720187187195, "step": 77000}
{"episode_reward": 597.8434938846214, "episode": 78.0, "batch_reward": 0.35214336681365965, "critic_loss": 0.3670961312800646, "actor_loss": -41.324773818969724, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.552531003952026, "step": 78000}
{"episode_reward": 652.3461471977464, "episode": 79.0, "batch_reward": 0.35534391245245933, "critic_loss": 0.3680893121063709, "actor_loss": -41.67733771514892, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.55185604095459, "step": 79000}
{"episode_reward": 669.5234636370932, "episode": 80.0, "batch_reward": 0.36034576877951624, "critic_loss": 0.40797591860592364, "actor_loss": -42.091295051574704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.558238744735718, "step": 80000}
{"episode_reward": 623.806066447609, "episode": 81.0, "batch_reward": 0.3648806751668453, "critic_loss": 0.3900920983552933, "actor_loss": -42.36349279022217, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.55532932281494, "step": 81000}
{"episode_reward": 672.1734977295622, "episode": 82.0, "batch_reward": 0.36713013127446176, "critic_loss": 0.37604934856295585, "actor_loss": -42.466058990478516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.562690019607544, "step": 82000}
{"episode_reward": 667.4190382534732, "episode": 83.0, "batch_reward": 0.37003888672590257, "critic_loss": 0.40366770935058593, "actor_loss": -42.86157564544678, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.538126707077026, "step": 83000}
{"episode_reward": 628.9439072576625, "episode": 84.0, "batch_reward": 0.373583476960659, "critic_loss": 0.41156581670045855, "actor_loss": -43.40727484130859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.549856901168823, "step": 84000}
{"episode_reward": 574.2590912992299, "episode": 85.0, "batch_reward": 0.3751835387349129, "critic_loss": 0.3985020729005337, "actor_loss": -43.229944007873534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.546689987182617, "step": 85000}
{"episode_reward": 616.9617271139857, "episode": 86.0, "batch_reward": 0.38057039099931717, "critic_loss": 0.38938134151697157, "actor_loss": -43.558746925354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.616101503372192, "step": 86000}
{"episode_reward": 633.441660793391, "episode": 87.0, "batch_reward": 0.38192663061618803, "critic_loss": 0.38569780722260477, "actor_loss": -43.79629496765137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.808539390563965, "step": 87000}
{"episode_reward": 642.4640805585587, "episode": 88.0, "batch_reward": 0.3853122065365314, "critic_loss": 0.4009728795588017, "actor_loss": -44.203528884887696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.5140860080719, "step": 88000}
{"episode_reward": 620.5143354810094, "episode": 89.0, "batch_reward": 0.3884560042619705, "critic_loss": 0.40419553802907465, "actor_loss": -44.08974582672119, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51008701324463, "step": 89000}
{"episode_reward": 715.5870579175499, "episode": 90.0, "batch_reward": 0.39078861445188523, "critic_loss": 0.4136033882200718, "actor_loss": -44.47845491027832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51102900505066, "step": 90000}
{"episode_reward": 639.1521718421758, "episode": 91.0, "batch_reward": 0.39423799800872805, "critic_loss": 0.410818737834692, "actor_loss": -44.698031219482424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.512598514556885, "step": 91000}
{"episode_reward": 619.3041243647876, "episode": 92.0, "batch_reward": 0.3959587782025337, "critic_loss": 0.39671130062639715, "actor_loss": -44.71330614471436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.530184030532837, "step": 92000}
{"episode_reward": 620.3311479628272, "episode": 93.0, "batch_reward": 0.39953721258044245, "critic_loss": 0.4149478231817484, "actor_loss": -44.998480773925785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.526366472244263, "step": 93000}
{"episode_reward": 649.0173177625413, "episode": 94.0, "batch_reward": 0.4023837489485741, "critic_loss": 0.4351671215891838, "actor_loss": -45.367596900939944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.527761697769165, "step": 94000}
{"episode_reward": 611.0109464166459, "episode": 95.0, "batch_reward": 0.4035887650549412, "critic_loss": 0.42499918410181997, "actor_loss": -45.56279189300537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.531811475753784, "step": 95000}
{"episode_reward": 634.9060337706322, "episode": 96.0, "batch_reward": 0.4066636748611927, "critic_loss": 0.423773763358593, "actor_loss": -45.72034762573242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.559168815612793, "step": 96000}
{"episode_reward": 618.6240882630223, "episode": 97.0, "batch_reward": 0.40873185876011847, "critic_loss": 0.4398975228816271, "actor_loss": -45.87098976135254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.534736156463623, "step": 97000}
{"episode_reward": 676.3951912335641, "episode": 98.0, "batch_reward": 0.4105569462776184, "critic_loss": 0.4427542849481106, "actor_loss": -45.95085861968994, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.535906314849854, "step": 98000}
{"episode_reward": 640.7532835934134, "episode": 99.0, "batch_reward": 0.41420551878213885, "critic_loss": 0.44155945178866385, "actor_loss": -46.377423149108886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.522831201553345, "step": 99000}
{"episode_reward": 658.0067328084415, "episode": 100.0, "batch_reward": 0.4145710102021694, "critic_loss": 0.441167117074132, "actor_loss": -46.42222859954834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.553830862045288, "step": 100000}
{"episode_reward": 602.3602779739308, "episode": 101.0, "batch_reward": 0.41803731936216354, "critic_loss": 0.4722650624513626, "actor_loss": -46.843566390991214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.50825548171997, "step": 101000}
{"episode_reward": 699.0687617854624, "episode": 102.0, "batch_reward": 0.4210909956395626, "critic_loss": 0.4634382947683334, "actor_loss": -46.934887077331545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.555981636047363, "step": 102000}
{"episode_reward": 672.8339414831034, "episode": 103.0, "batch_reward": 0.42316521486639974, "critic_loss": 0.443772579357028, "actor_loss": -47.006670921325686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.539876699447632, "step": 103000}
{"episode_reward": 662.8168424292785, "episode": 104.0, "batch_reward": 0.4246118922829628, "critic_loss": 0.4204338431507349, "actor_loss": -47.41553875732422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.533557653427124, "step": 104000}
{"episode_reward": 664.3747797066768, "episode": 105.0, "batch_reward": 0.42854035329818724, "critic_loss": 0.4392007447630167, "actor_loss": -47.52598868560791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.524937868118286, "step": 105000}
{"episode_reward": 408.3615131239251, "episode": 106.0, "batch_reward": 0.4265299263894558, "critic_loss": 0.445000083103776, "actor_loss": -47.50144535827637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52642583847046, "step": 106000}
{"episode_reward": 659.113822863576, "episode": 107.0, "batch_reward": 0.4307638320624828, "critic_loss": 0.4317561156451702, "actor_loss": -47.65949591064453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52739143371582, "step": 107000}
{"episode_reward": 608.4182221349838, "episode": 108.0, "batch_reward": 0.4306635093986988, "critic_loss": 0.44704527865350246, "actor_loss": -47.55209536743164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.54766297340393, "step": 108000}
{"episode_reward": 631.9951901445424, "episode": 109.0, "batch_reward": 0.4333031984269619, "critic_loss": 0.44371656781435015, "actor_loss": -48.00518006134033, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.55292510986328, "step": 109000}
{"episode_reward": 685.9985029558729, "episode": 110.0, "batch_reward": 0.4361436691582203, "critic_loss": 0.4488271352797747, "actor_loss": -48.23794631195069, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52511978149414, "step": 110000}
{"episode_reward": 655.1492955311506, "episode": 111.0, "batch_reward": 0.4370066170990467, "critic_loss": 0.43816906355321406, "actor_loss": -48.13020136260986, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.4857120513916, "step": 111000}
{"episode_reward": 630.9557648367991, "episode": 112.0, "batch_reward": 0.43955403977632523, "critic_loss": 0.44451978589594365, "actor_loss": -48.46262223815918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.540307760238647, "step": 112000}
{"episode_reward": 646.0483853190096, "episode": 113.0, "batch_reward": 0.4417311365008354, "critic_loss": 0.45568873374164104, "actor_loss": -48.582355628967285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.537809371948242, "step": 113000}
{"episode_reward": 633.9956534066681, "episode": 114.0, "batch_reward": 0.44089808639883993, "critic_loss": 0.46087516197562217, "actor_loss": -48.5739005279541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52927803993225, "step": 114000}
{"episode_reward": 664.6789392922813, "episode": 115.0, "batch_reward": 0.4441965355575085, "critic_loss": 0.43067785660922525, "actor_loss": -48.855183624267575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.531172513961792, "step": 115000}
{"episode_reward": 644.1440960700344, "episode": 116.0, "batch_reward": 0.44796195966005325, "critic_loss": 0.4386089156121016, "actor_loss": -49.17589012145996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.521372079849243, "step": 116000}
{"episode_reward": 610.0857439095258, "episode": 117.0, "batch_reward": 0.4471310841739178, "critic_loss": 0.4176170339435339, "actor_loss": -48.907816497802735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.536492586135864, "step": 117000}
{"episode_reward": 727.0737559654917, "episode": 118.0, "batch_reward": 0.4513648157119751, "critic_loss": 0.43291054363548753, "actor_loss": -49.35085256958008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.540859937667847, "step": 118000}
{"episode_reward": 627.8926648784135, "episode": 119.0, "batch_reward": 0.45223140394687655, "critic_loss": 0.45435033659636975, "actor_loss": -49.39290296936035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.531978845596313, "step": 119000}
{"episode_reward": 605.5178235148753, "episode": 120.0, "batch_reward": 0.45231876704096796, "critic_loss": 0.4528790067732334, "actor_loss": -49.43009069824219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.53605580329895, "step": 120000}
{"episode_reward": 656.6984208954935, "episode": 121.0, "batch_reward": 0.4538804556131363, "critic_loss": 0.4660649788528681, "actor_loss": -49.56350970458984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.53118824958801, "step": 121000}
{"episode_reward": 698.0702193146708, "episode": 122.0, "batch_reward": 0.4575444866120815, "critic_loss": 0.4669305472075939, "actor_loss": -49.7062621383667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.556117057800293, "step": 122000}
{"episode_reward": 628.656400678421, "episode": 123.0, "batch_reward": 0.45748712810873987, "critic_loss": 0.4595369071364403, "actor_loss": -49.956468101501464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.545685529708862, "step": 123000}
{"episode_reward": 672.1903304399693, "episode": 124.0, "batch_reward": 0.46072188344597814, "critic_loss": 0.4751254221498966, "actor_loss": -49.98297550964355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.525922298431396, "step": 124000}
{"episode_reward": 651.5884862907739, "episode": 125.0, "batch_reward": 0.46282840219140053, "critic_loss": 0.45931186293065546, "actor_loss": -50.22593560028076, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.522905588150024, "step": 125000}
{"episode_reward": 640.6655329482561, "episode": 126.0, "batch_reward": 0.4625031379163265, "critic_loss": 0.4737156396359205, "actor_loss": -50.04596208190918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.534639358520508, "step": 126000}
{"episode_reward": 635.247251695462, "episode": 127.0, "batch_reward": 0.4626121484041214, "critic_loss": 0.4678913455158472, "actor_loss": -50.112936546325685, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52899146080017, "step": 127000}
{"episode_reward": 704.7285099213058, "episode": 128.0, "batch_reward": 0.4656215798854828, "critic_loss": 0.505681694611907, "actor_loss": -50.43611898803711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.528283834457397, "step": 128000}
{"episode_reward": 701.3771273173921, "episode": 129.0, "batch_reward": 0.46648023211956025, "critic_loss": 0.47444315247237684, "actor_loss": -50.30207538604736, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.545909881591797, "step": 129000}
{"episode_reward": 540.7381421451631, "episode": 130.0, "batch_reward": 0.4696277664601803, "critic_loss": 0.5586441283375024, "actor_loss": -50.51473734283447, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.534374237060547, "step": 130000}
{"episode_reward": 655.2909230589482, "episode": 131.0, "batch_reward": 0.4702486801445484, "critic_loss": 0.486115442737937, "actor_loss": -50.6150399017334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.499549865722656, "step": 131000}
{"episode_reward": 676.1727603163524, "episode": 132.0, "batch_reward": 0.4703896107673645, "critic_loss": 0.5071258433461189, "actor_loss": -50.825422492980955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.530976057052612, "step": 132000}
{"episode_reward": 606.207468105139, "episode": 133.0, "batch_reward": 0.4736671387553215, "critic_loss": 0.5147921982854605, "actor_loss": -50.82315367126465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.54930806159973, "step": 133000}
{"episode_reward": 667.0694964765576, "episode": 134.0, "batch_reward": 0.4747229107320309, "critic_loss": 0.5053634047210217, "actor_loss": -50.76271548461914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.549599170684814, "step": 134000}
{"episode_reward": 642.1223098076508, "episode": 135.0, "batch_reward": 0.4756408336162567, "critic_loss": 0.5116255229711533, "actor_loss": -51.139077308654784, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.559094190597534, "step": 135000}
{"episode_reward": 659.3552970023171, "episode": 136.0, "batch_reward": 0.4761596058011055, "critic_loss": 0.483654562830925, "actor_loss": -50.7754375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.552230834960938, "step": 136000}
{"episode_reward": 720.5822414813717, "episode": 137.0, "batch_reward": 0.47866636237502097, "critic_loss": 0.4674082660377026, "actor_loss": -51.21646299743652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.548771142959595, "step": 137000}
{"episode_reward": 708.6929266188047, "episode": 138.0, "batch_reward": 0.4809343875348568, "critic_loss": 0.47888516740500925, "actor_loss": -51.34876893615723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.539530038833618, "step": 138000}
{"episode_reward": 681.8791833687092, "episode": 139.0, "batch_reward": 0.4823480668067932, "critic_loss": 0.4597580824047327, "actor_loss": -51.53679623413086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.537337064743042, "step": 139000}
{"episode_reward": 664.3621683979445, "episode": 140.0, "batch_reward": 0.48371450132131577, "critic_loss": 0.4389082540422678, "actor_loss": -51.64885188293457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.5405011177063, "step": 140000}
{"episode_reward": 641.8329243094224, "episode": 141.0, "batch_reward": 0.4839026364088058, "critic_loss": 0.4306717318892479, "actor_loss": -51.639821327209475, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.50665307044983, "step": 141000}
{"episode_reward": 642.2254458778805, "episode": 142.0, "batch_reward": 0.4829064137041569, "critic_loss": 0.4309254381209612, "actor_loss": -51.45573777008057, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.55213236808777, "step": 142000}
{"episode_reward": 695.774104506107, "episode": 143.0, "batch_reward": 0.4859104820787907, "critic_loss": 0.41700220088660717, "actor_loss": -51.71911981201172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.546270847320557, "step": 143000}
{"episode_reward": 705.0676235921829, "episode": 144.0, "batch_reward": 0.4896911726891994, "critic_loss": 0.43152986706793306, "actor_loss": -52.133891166687015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.53916358947754, "step": 144000}
{"episode_reward": 507.2902155589668, "episode": 145.0, "batch_reward": 0.48807217231392863, "critic_loss": 0.44117219825088977, "actor_loss": -51.98871185302735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.530247926712036, "step": 145000}
{"episode_reward": 662.1464590072935, "episode": 146.0, "batch_reward": 0.48831030434370043, "critic_loss": 0.41811599442362785, "actor_loss": -52.059025924682615, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.533904552459717, "step": 146000}
{"episode_reward": 659.4406716369251, "episode": 147.0, "batch_reward": 0.4897170282304287, "critic_loss": 0.4212257419973612, "actor_loss": -52.12002161407471, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.53543972969055, "step": 147000}
{"episode_reward": 682.5961331609527, "episode": 148.0, "batch_reward": 0.49180385956168177, "critic_loss": 0.4304023029953241, "actor_loss": -52.290129791259766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.547923803329468, "step": 148000}
{"episode_reward": 603.4478320976273, "episode": 149.0, "batch_reward": 0.4929071427285671, "critic_loss": 0.4281795310676098, "actor_loss": -52.31491754150391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.562167406082153, "step": 149000}
{"episode_reward": 699.7520994301602, "episode": 150.0, "batch_reward": 0.49402825701236724, "critic_loss": 0.4244454100728035, "actor_loss": -52.51101315307617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
