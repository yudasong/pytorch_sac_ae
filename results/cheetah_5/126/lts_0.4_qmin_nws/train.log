{"episode_reward": 0.0, "episode": 1.0, "duration": 20.640404224395752, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.8516960144042969, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.2522333722316889, "critic_loss": 0.03903984033715982, "actor_loss": -17.593048305295053, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 67.43024682998657, "step": 3000}
{"episode_reward": 43.285928853018234, "episode": 4.0, "batch_reward": 0.16691351594030857, "critic_loss": 0.02757886849157512, "actor_loss": -9.765857281133533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.297336101531982, "step": 4000}
{"episode_reward": 14.435915695484649, "episode": 5.0, "batch_reward": 0.1322707198113203, "critic_loss": 0.0270155035443604, "actor_loss": -11.040224882245063, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.59847378730774, "step": 5000}
{"episode_reward": 7.306470527464292, "episode": 6.0, "batch_reward": 0.11002885069325566, "critic_loss": 0.022016861024778338, "actor_loss": -11.000246628403664, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.541439056396484, "step": 6000}
{"episode_reward": 14.6644850348705, "episode": 7.0, "batch_reward": 0.09542041329294443, "critic_loss": 0.02363725158944726, "actor_loss": -11.648561984479427, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.55887746810913, "step": 7000}
{"episode_reward": 11.142081270928026, "episode": 8.0, "batch_reward": 0.08364120807871223, "critic_loss": 0.031535598095040765, "actor_loss": -12.250687971889972, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.2881019115448, "step": 8000}
{"episode_reward": 8.139081234507136, "episode": 9.0, "batch_reward": 0.07815870450809598, "critic_loss": 0.045414392377249896, "actor_loss": -13.206476390585303, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.562752723693848, "step": 9000}
{"episode_reward": 82.2301091531898, "episode": 10.0, "batch_reward": 0.0776511475481093, "critic_loss": 0.057986709091812375, "actor_loss": -13.35602746540308, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.983035802841187, "step": 10000}
{"episode_reward": 37.88223958981767, "episode": 11.0, "batch_reward": 0.07826172503083945, "critic_loss": 0.10518462272547185, "actor_loss": -12.094545540213584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.217825174331665, "step": 11000}
{"episode_reward": 115.27697481690356, "episode": 12.0, "batch_reward": 0.07837337591126561, "critic_loss": 0.0850972526408732, "actor_loss": -12.736486357450485, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.068243503570557, "step": 12000}
{"episode_reward": 47.42662242545461, "episode": 13.0, "batch_reward": 0.07786250840127468, "critic_loss": 0.07763584892824292, "actor_loss": -11.067820975542068, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.403809547424316, "step": 13000}
{"episode_reward": 84.78805922787375, "episode": 14.0, "batch_reward": 0.07821760694682599, "critic_loss": 0.10798557420819997, "actor_loss": -10.784881130218507, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.60937762260437, "step": 14000}
{"episode_reward": 96.43082011778762, "episode": 15.0, "batch_reward": 0.07833853943645955, "critic_loss": 0.11755062238499522, "actor_loss": -9.838143175601958, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.78665566444397, "step": 15000}
{"episode_reward": 51.89737360602265, "episode": 16.0, "batch_reward": 0.07633847618475556, "critic_loss": 0.11790058265626431, "actor_loss": -11.821439687728882, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.313864707946777, "step": 16000}
{"episode_reward": 69.27544831586661, "episode": 17.0, "batch_reward": 0.07854689090698957, "critic_loss": 0.1303012796714902, "actor_loss": -11.588018049240112, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.450939655303955, "step": 17000}
{"episode_reward": 127.58150286236561, "episode": 18.0, "batch_reward": 0.07912479564920068, "critic_loss": 0.15015081725269555, "actor_loss": -11.99137242794037, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23885154724121, "step": 18000}
{"episode_reward": 60.47180432424552, "episode": 19.0, "batch_reward": 0.0792623484916985, "critic_loss": 0.15131593395024537, "actor_loss": -12.128607690811156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.768710374832153, "step": 19000}
{"episode_reward": 78.13831845992766, "episode": 20.0, "batch_reward": 0.0817949403077364, "critic_loss": 0.14977360631152986, "actor_loss": -11.870454049110412, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.308042764663696, "step": 20000}
{"episode_reward": 190.70849742909868, "episode": 21.0, "batch_reward": 0.08269126391038299, "critic_loss": 0.15133860423415899, "actor_loss": -12.507711820602417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.83608317375183, "step": 21000}
{"episode_reward": 55.38435283568227, "episode": 22.0, "batch_reward": 0.08532013166695833, "critic_loss": 0.16590036606788636, "actor_loss": -12.043578720092773, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.597407817840576, "step": 22000}
{"episode_reward": 263.1147275676617, "episode": 23.0, "batch_reward": 0.09437911133095622, "critic_loss": 0.1739681818932295, "actor_loss": -13.373161527633666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.036874532699585, "step": 23000}
{"episode_reward": 277.9531978263756, "episode": 24.0, "batch_reward": 0.09825936768949031, "critic_loss": 0.1929458548426628, "actor_loss": -13.497128632545472, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.519319534301758, "step": 24000}
{"episode_reward": 62.1413899518355, "episode": 25.0, "batch_reward": 0.10181049726903439, "critic_loss": 0.19847363481670618, "actor_loss": -14.000496574401856, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.7873592376709, "step": 25000}
{"episode_reward": 320.8918724081708, "episode": 26.0, "batch_reward": 0.10852076836675406, "critic_loss": 0.23540059404820204, "actor_loss": -14.91535841369629, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.065696001052856, "step": 26000}
{"episode_reward": 170.3510687876918, "episode": 27.0, "batch_reward": 0.11090137424319982, "critic_loss": 0.2406691314652562, "actor_loss": -14.701003240585328, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.7476487159729, "step": 27000}
{"episode_reward": 234.86496097389087, "episode": 28.0, "batch_reward": 0.11153708331286907, "critic_loss": 0.2351101196631789, "actor_loss": -15.39366551399231, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.070948362350464, "step": 28000}
{"episode_reward": 53.116260381866184, "episode": 29.0, "batch_reward": 0.11109797763824462, "critic_loss": 0.23821955001354217, "actor_loss": -15.017479927062988, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.706700086593628, "step": 29000}
{"episode_reward": 92.86108421428824, "episode": 30.0, "batch_reward": 0.11281665832549334, "critic_loss": 0.2366727266088128, "actor_loss": -15.40004214668274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.812913417816162, "step": 30000}
{"episode_reward": 223.11244330022728, "episode": 31.0, "batch_reward": 0.11397237748652697, "critic_loss": 0.2349581127539277, "actor_loss": -15.906078186035156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.83350586891174, "step": 31000}
{"episode_reward": 79.2671996352174, "episode": 32.0, "batch_reward": 0.11613452606648207, "critic_loss": 0.252330411978066, "actor_loss": -15.782487674713135, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.002485513687134, "step": 32000}
{"episode_reward": 322.62957042664016, "episode": 33.0, "batch_reward": 0.1206676485016942, "critic_loss": 0.25325218997895715, "actor_loss": -15.745341293334961, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.852965354919434, "step": 33000}
{"episode_reward": 101.93539348166885, "episode": 34.0, "batch_reward": 0.11944005884230137, "critic_loss": 0.26076666636765006, "actor_loss": -15.997262315750122, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.203686952590942, "step": 34000}
{"episode_reward": 104.76593288727376, "episode": 35.0, "batch_reward": 0.1192477437183261, "critic_loss": 0.2929403634443879, "actor_loss": -16.020264436721803, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.974400997161865, "step": 35000}
{"episode_reward": 104.89321063902786, "episode": 36.0, "batch_reward": 0.11966889116168022, "critic_loss": 0.2771920616850257, "actor_loss": -15.977993644714356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.21471118927002, "step": 36000}
{"episode_reward": 233.1975339991114, "episode": 37.0, "batch_reward": 0.12247959915548563, "critic_loss": 0.310115772664547, "actor_loss": -16.14655597305298, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41187620162964, "step": 37000}
{"episode_reward": 127.5930411419681, "episode": 38.0, "batch_reward": 0.12308357215672731, "critic_loss": 0.3066836289688945, "actor_loss": -15.876275491714477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.299620866775513, "step": 38000}
{"episode_reward": 265.1977212695168, "episode": 39.0, "batch_reward": 0.12860872650891542, "critic_loss": 0.35201561646163465, "actor_loss": -16.55231785774231, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.94663906097412, "step": 39000}
{"episode_reward": 337.38860386242254, "episode": 40.0, "batch_reward": 0.1319301229044795, "critic_loss": 0.3209177268892527, "actor_loss": -17.16714619255066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.754353284835815, "step": 40000}
{"episode_reward": 186.93219956149792, "episode": 41.0, "batch_reward": 0.13193928974866867, "critic_loss": 0.32650075034052134, "actor_loss": -17.50176305389404, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.94921255111694, "step": 41000}
{"episode_reward": 85.9065754766918, "episode": 42.0, "batch_reward": 0.13175281762331725, "critic_loss": 0.3465499310195446, "actor_loss": -17.06414734840393, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.74929666519165, "step": 42000}
{"episode_reward": 188.20088832271446, "episode": 43.0, "batch_reward": 0.13426253592222928, "critic_loss": 0.3410692375600338, "actor_loss": -17.22147047996521, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.454670906066895, "step": 43000}
{"episode_reward": 233.1764998231257, "episode": 44.0, "batch_reward": 0.13414774906635285, "critic_loss": 0.352886611238122, "actor_loss": -17.02657603263855, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.021449089050293, "step": 44000}
{"episode_reward": 37.16195193529366, "episode": 45.0, "batch_reward": 0.13189735247939824, "critic_loss": 0.3436096348464489, "actor_loss": -16.51947937011719, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.55970335006714, "step": 45000}
{"episode_reward": 52.4164480012498, "episode": 46.0, "batch_reward": 0.1310311981961131, "critic_loss": 0.34648264589905736, "actor_loss": -16.755061922073363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.686745166778564, "step": 46000}
{"episode_reward": 193.3728506129731, "episode": 47.0, "batch_reward": 0.13387448608875274, "critic_loss": 0.36966703630983827, "actor_loss": -17.271797636032105, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.52846360206604, "step": 47000}
{"episode_reward": 326.0250354591322, "episode": 48.0, "batch_reward": 0.13839973330497743, "critic_loss": 0.3664930882304907, "actor_loss": -17.22126865005493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.01146674156189, "step": 48000}
{"episode_reward": 327.0517756182329, "episode": 49.0, "batch_reward": 0.14239837025105953, "critic_loss": 0.38195011791586875, "actor_loss": -17.76941524887085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.780722618103027, "step": 49000}
{"episode_reward": 236.51211091477833, "episode": 50.0, "batch_reward": 0.1433557337448001, "critic_loss": 0.38550638930499553, "actor_loss": -18.28496969985962, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.34090280532837, "step": 50000}
{"episode_reward": 309.87264065715874, "episode": 51.0, "batch_reward": 0.144936233446002, "critic_loss": 0.4130266900360584, "actor_loss": -17.684265089035033, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 44.037259578704834, "step": 51000}
{"episode_reward": 37.00341500276004, "episode": 52.0, "batch_reward": 0.14657118763774635, "critic_loss": 0.39669074492156503, "actor_loss": -18.734436780929567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.602638006210327, "step": 52000}
{"episode_reward": 399.9861244666661, "episode": 53.0, "batch_reward": 0.14951563674211502, "critic_loss": 0.4427144708931446, "actor_loss": -18.307566940307616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.105931997299194, "step": 53000}
{"episode_reward": 246.79519195573533, "episode": 54.0, "batch_reward": 0.15267824651300907, "critic_loss": 0.4266124907582998, "actor_loss": -19.179838169097902, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.079859495162964, "step": 54000}
{"episode_reward": 402.0429785600116, "episode": 55.0, "batch_reward": 0.15530231554061175, "critic_loss": 0.4012231895178556, "actor_loss": -19.415839855194093, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.117899179458618, "step": 55000}
{"episode_reward": 154.62076938943906, "episode": 56.0, "batch_reward": 0.1553924024179578, "critic_loss": 0.4208427388817072, "actor_loss": -18.90850255012512, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.939449548721313, "step": 56000}
{"episode_reward": 214.72644700134845, "episode": 57.0, "batch_reward": 0.15682667630910874, "critic_loss": 0.4164698356539011, "actor_loss": -19.21330351257324, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.542134523391724, "step": 57000}
{"episode_reward": 202.42990605457157, "episode": 58.0, "batch_reward": 0.15724132730066775, "critic_loss": 0.4082523437291384, "actor_loss": -19.028990367889403, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.042717933654785, "step": 58000}
{"episode_reward": 345.4345797351242, "episode": 59.0, "batch_reward": 0.15904891286045314, "critic_loss": 0.4192560088336468, "actor_loss": -19.680710454940797, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.717830657958984, "step": 59000}
{"episode_reward": 66.39373410231953, "episode": 60.0, "batch_reward": 0.15859374738484622, "critic_loss": 0.42440980660915373, "actor_loss": -19.9427027053833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.186951160430908, "step": 60000}
{"episode_reward": 71.77915657617653, "episode": 61.0, "batch_reward": 0.15722878815978766, "critic_loss": 0.4292054288685322, "actor_loss": -19.51832150268555, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.69394636154175, "step": 61000}
{"episode_reward": 331.6495938981888, "episode": 62.0, "batch_reward": 0.15961218972504138, "critic_loss": 0.4093612260967493, "actor_loss": -19.2756795463562, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.25299835205078, "step": 62000}
{"episode_reward": 151.07365057456934, "episode": 63.0, "batch_reward": 0.1597562085837126, "critic_loss": 0.42339548729360105, "actor_loss": -19.385016523361205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.133238077163696, "step": 63000}
{"episode_reward": 157.16744444656234, "episode": 64.0, "batch_reward": 0.16103080785274507, "critic_loss": 0.42857073198258877, "actor_loss": -19.816015544891357, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.198718309402466, "step": 64000}
{"episode_reward": 183.24146133013932, "episode": 65.0, "batch_reward": 0.16098589918762446, "critic_loss": 0.4291162329018116, "actor_loss": -19.737737632751465, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.076983213424683, "step": 65000}
{"episode_reward": 216.54151429369747, "episode": 66.0, "batch_reward": 0.16125835017859935, "critic_loss": 0.4410762249529362, "actor_loss": -19.601862915039064, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.54550814628601, "step": 66000}
{"episode_reward": 199.86352591581138, "episode": 67.0, "batch_reward": 0.16299917753785848, "critic_loss": 0.4475664317756891, "actor_loss": -19.878355922698976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.918451070785522, "step": 67000}
{"episode_reward": 327.1658940542638, "episode": 68.0, "batch_reward": 0.1649014058560133, "critic_loss": 0.47650168550014493, "actor_loss": -20.239560235977173, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.002888679504395, "step": 68000}
{"episode_reward": 174.6396404008108, "episode": 69.0, "batch_reward": 0.1646899230480194, "critic_loss": 0.43985254503786564, "actor_loss": -20.012481023788453, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.76600217819214, "step": 69000}
{"episode_reward": 158.84770545915083, "episode": 70.0, "batch_reward": 0.16542596016824246, "critic_loss": 0.4432441093623638, "actor_loss": -20.402096145629883, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.206546306610107, "step": 70000}
{"episode_reward": 420.64397511315724, "episode": 71.0, "batch_reward": 0.16759197118133307, "critic_loss": 0.46304528559744357, "actor_loss": -20.40432618904114, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.95279335975647, "step": 71000}
{"episode_reward": 201.37218058708189, "episode": 72.0, "batch_reward": 0.16902285160124303, "critic_loss": 0.43858738718926904, "actor_loss": -20.2671787109375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22442889213562, "step": 72000}
{"episode_reward": 188.91777846715675, "episode": 73.0, "batch_reward": 0.16959888618439437, "critic_loss": 0.44347601526975633, "actor_loss": -20.38525008392334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.050583839416504, "step": 73000}
{"episode_reward": 291.31978879070954, "episode": 74.0, "batch_reward": 0.17079730814695357, "critic_loss": 0.4256945635527372, "actor_loss": -20.77751083755493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.765204668045044, "step": 74000}
{"episode_reward": 150.19731908589446, "episode": 75.0, "batch_reward": 0.17080640223622323, "critic_loss": 0.43587752121686935, "actor_loss": -20.645349952697753, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.548655033111572, "step": 75000}
{"episode_reward": 181.22800842428262, "episode": 76.0, "batch_reward": 0.1699340945109725, "critic_loss": 0.4347567477822304, "actor_loss": -20.713308687210084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.06378483772278, "step": 76000}
{"episode_reward": 91.03847874778246, "episode": 77.0, "batch_reward": 0.17004885462671518, "critic_loss": 0.38325579586625097, "actor_loss": -20.13799434661865, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.26110053062439, "step": 77000}
{"episode_reward": 333.2719544478508, "episode": 78.0, "batch_reward": 0.1716663178279996, "critic_loss": 0.4129323537796736, "actor_loss": -20.351133707046507, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.94476008415222, "step": 78000}
{"episode_reward": 182.21545333927804, "episode": 79.0, "batch_reward": 0.17273962639272214, "critic_loss": 0.3982163672447205, "actor_loss": -20.312475534439088, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.951279878616333, "step": 79000}
{"episode_reward": 382.39117096304454, "episode": 80.0, "batch_reward": 0.17383878555893897, "critic_loss": 0.38962891276180744, "actor_loss": -20.58771660232544, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32551097869873, "step": 80000}
{"episode_reward": 113.17759831862261, "episode": 81.0, "batch_reward": 0.17464042589068413, "critic_loss": 0.41075388742983343, "actor_loss": -20.435635679244996, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.87729477882385, "step": 81000}
{"episode_reward": 330.1366370404672, "episode": 82.0, "batch_reward": 0.1755668023377657, "critic_loss": 0.41871001733839514, "actor_loss": -20.560690055847168, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.315168619155884, "step": 82000}
{"episode_reward": 379.624914570607, "episode": 83.0, "batch_reward": 0.17862864382565022, "critic_loss": 0.3848759590685368, "actor_loss": -21.093238843917845, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.133588075637817, "step": 83000}
{"episode_reward": 307.48584470928387, "episode": 84.0, "batch_reward": 0.1799881157130003, "critic_loss": 0.4201635161191225, "actor_loss": -21.15209779548645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.291264057159424, "step": 84000}
{"episode_reward": 499.6484359063027, "episode": 85.0, "batch_reward": 0.1841766484826803, "critic_loss": 0.39787603233754637, "actor_loss": -21.164882719039916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.366338968276978, "step": 85000}
{"episode_reward": 237.61361072120746, "episode": 86.0, "batch_reward": 0.18564130374789237, "critic_loss": 0.4009021033197641, "actor_loss": -21.36167979812622, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.10417342185974, "step": 86000}
{"episode_reward": 389.05071982304685, "episode": 87.0, "batch_reward": 0.18680732087790966, "critic_loss": 0.40689986988902094, "actor_loss": -21.416531940460207, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.192923069000244, "step": 87000}
{"episode_reward": 151.81998188576287, "episode": 88.0, "batch_reward": 0.1859052682965994, "critic_loss": 0.4043211050182581, "actor_loss": -21.38605778121948, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.293062925338745, "step": 88000}
{"episode_reward": 81.4038927294474, "episode": 89.0, "batch_reward": 0.18525118742883206, "critic_loss": 0.4325015459060669, "actor_loss": -21.151897815704345, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.614267826080322, "step": 89000}
{"episode_reward": 216.73246321203857, "episode": 90.0, "batch_reward": 0.1850951368957758, "critic_loss": 0.3895145954936743, "actor_loss": -21.048228010177613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.718700647354126, "step": 90000}
{"episode_reward": 459.4471786913205, "episode": 91.0, "batch_reward": 0.18942331886291505, "critic_loss": 0.41444110180437566, "actor_loss": -21.34456968307495, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.36700701713562, "step": 91000}
{"episode_reward": 484.56707847452617, "episode": 92.0, "batch_reward": 0.19168102911114693, "critic_loss": 0.44614354413747787, "actor_loss": -21.507927854537964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.68769383430481, "step": 92000}
{"episode_reward": 140.75690921127293, "episode": 93.0, "batch_reward": 0.19182896338403224, "critic_loss": 0.41445235048234463, "actor_loss": -21.531573667526246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.423668146133423, "step": 93000}
{"episode_reward": 459.0261866620624, "episode": 94.0, "batch_reward": 0.19481896068155766, "critic_loss": 0.45798502257466317, "actor_loss": -21.8555218334198, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.425592184066772, "step": 94000}
{"episode_reward": 372.46728226760445, "episode": 95.0, "batch_reward": 0.19528298008441924, "critic_loss": 0.42563930264115335, "actor_loss": -21.744249614715578, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.38033962249756, "step": 95000}
{"episode_reward": 102.37026354479582, "episode": 96.0, "batch_reward": 0.1961830204576254, "critic_loss": 0.44307463778555395, "actor_loss": -22.196550548553468, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.976202487945557, "step": 96000}
{"episode_reward": 440.48135723176597, "episode": 97.0, "batch_reward": 0.1967670007944107, "critic_loss": 0.4564525059461594, "actor_loss": -21.836231113433836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.595219135284424, "step": 97000}
{"episode_reward": 69.63281426002814, "episode": 98.0, "batch_reward": 0.19674311217665671, "critic_loss": 0.4359360550194979, "actor_loss": -21.79791166305542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.416284561157227, "step": 98000}
{"episode_reward": 461.45050148507084, "episode": 99.0, "batch_reward": 0.20032164849340917, "critic_loss": 0.4474678798019886, "actor_loss": -22.571904706954957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.020284414291382, "step": 99000}
{"episode_reward": 566.1939665506897, "episode": 100.0, "batch_reward": 0.20310925257205964, "critic_loss": 0.4321315821558237, "actor_loss": -22.599614000320436, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.080828189849854, "step": 100000}
{"episode_reward": 485.51178524431594, "episode": 101.0, "batch_reward": 0.20668379193544387, "critic_loss": 0.4483695660531521, "actor_loss": -22.939449087142943, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.5066020488739, "step": 101000}
{"episode_reward": 500.3911102114378, "episode": 102.0, "batch_reward": 0.20922639755904673, "critic_loss": 0.44546315021812916, "actor_loss": -22.78960852432251, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.081581354141235, "step": 102000}
{"episode_reward": 314.1965339144615, "episode": 103.0, "batch_reward": 0.20843229934573174, "critic_loss": 0.43278072510659693, "actor_loss": -22.71698319244385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.291866302490234, "step": 103000}
{"episode_reward": 75.2389206661253, "episode": 104.0, "batch_reward": 0.20799903850257398, "critic_loss": 0.4437743941396475, "actor_loss": -23.002691579818727, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.088650226593018, "step": 104000}
{"episode_reward": 412.75769871466196, "episode": 105.0, "batch_reward": 0.21024991858005523, "critic_loss": 0.453451167345047, "actor_loss": -23.0796911239624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.75628399848938, "step": 105000}
{"episode_reward": 422.660707922936, "episode": 106.0, "batch_reward": 0.2127055465579033, "critic_loss": 0.4770880882292986, "actor_loss": -23.23320840072632, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.352670907974243, "step": 106000}
{"episode_reward": 491.70184535668227, "episode": 107.0, "batch_reward": 0.21564058509469033, "critic_loss": 0.46668467500805855, "actor_loss": -23.5619859085083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.917359113693237, "step": 107000}
{"episode_reward": 508.69468886836034, "episode": 108.0, "batch_reward": 0.2165158584713936, "critic_loss": 0.45779038055241106, "actor_loss": -23.096556316375732, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.798016786575317, "step": 108000}
{"episode_reward": 309.3765794317028, "episode": 109.0, "batch_reward": 0.21864227728545665, "critic_loss": 0.4602579019665718, "actor_loss": -23.906615333557127, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.616111755371094, "step": 109000}
{"episode_reward": 477.890642455528, "episode": 110.0, "batch_reward": 0.21998685352504255, "critic_loss": 0.48540127629041674, "actor_loss": -23.962179098129273, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.69521737098694, "step": 110000}
{"episode_reward": 60.96326659675546, "episode": 111.0, "batch_reward": 0.2192723546922207, "critic_loss": 0.4873793966472149, "actor_loss": -23.28055613708496, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.70250868797302, "step": 111000}
{"episode_reward": 541.9670963871899, "episode": 112.0, "batch_reward": 0.2216851659268141, "critic_loss": 0.4784276486337185, "actor_loss": -24.345542755126953, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.40864610671997, "step": 112000}
{"episode_reward": 474.2147956384622, "episode": 113.0, "batch_reward": 0.22457352946698667, "critic_loss": 0.48929229643940925, "actor_loss": -24.068457580566406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.12983751296997, "step": 113000}
{"episode_reward": 515.7052384892957, "episode": 114.0, "batch_reward": 0.22727029351890088, "critic_loss": 0.5080072624981403, "actor_loss": -24.41068346786499, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.785340785980225, "step": 114000}
{"episode_reward": 461.2139590650828, "episode": 115.0, "batch_reward": 0.22901330898702144, "critic_loss": 0.4942175527662039, "actor_loss": -24.435113372802736, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.18408703804016, "step": 115000}
{"episode_reward": 490.1733237686814, "episode": 116.0, "batch_reward": 0.23265182328224182, "critic_loss": 0.4801995086073875, "actor_loss": -24.605006519317627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.341158866882324, "step": 116000}
{"episode_reward": 476.80318215245757, "episode": 117.0, "batch_reward": 0.23365332955121995, "critic_loss": 0.49397921380400656, "actor_loss": -24.395764331817627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.91641139984131, "step": 117000}
{"episode_reward": 352.73411147143344, "episode": 118.0, "batch_reward": 0.2339455577582121, "critic_loss": 0.4929466458708048, "actor_loss": -24.751271881103516, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.665794610977173, "step": 118000}
{"episode_reward": 85.0104890818896, "episode": 119.0, "batch_reward": 0.23356801019608975, "critic_loss": 0.4642008820772171, "actor_loss": -24.61330979156494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.98608660697937, "step": 119000}
{"episode_reward": 537.7384005613507, "episode": 120.0, "batch_reward": 0.23492508690059186, "critic_loss": 0.5108928631395101, "actor_loss": -24.63555364227295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.994972229003906, "step": 120000}
{"episode_reward": 383.5125723346782, "episode": 121.0, "batch_reward": 0.23574177481234074, "critic_loss": 0.51086724434793, "actor_loss": -24.891519496917724, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.583431005477905, "step": 121000}
{"episode_reward": 530.7714370089626, "episode": 122.0, "batch_reward": 0.23986531527340413, "critic_loss": 0.47513311587274076, "actor_loss": -25.16659116744995, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.712385177612305, "step": 122000}
{"episode_reward": 484.3809793397895, "episode": 123.0, "batch_reward": 0.24207721039652824, "critic_loss": 0.4939207365214825, "actor_loss": -25.668684703826905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.272217750549316, "step": 123000}
{"episode_reward": 181.82368639145014, "episode": 124.0, "batch_reward": 0.24062956465780735, "critic_loss": 0.5116267880350351, "actor_loss": -25.60233936691284, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.833795309066772, "step": 124000}
{"episode_reward": 494.595299786838, "episode": 125.0, "batch_reward": 0.24359353686869145, "critic_loss": 0.4732338212877512, "actor_loss": -25.669147193908692, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.529739141464233, "step": 125000}
{"episode_reward": 501.31123251949737, "episode": 126.0, "batch_reward": 0.24615812672674656, "critic_loss": 0.45719816444814204, "actor_loss": -25.59832649612427, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.76017189025879, "step": 126000}
{"episode_reward": 538.3254358474619, "episode": 127.0, "batch_reward": 0.24642595593631267, "critic_loss": 0.45280819649994375, "actor_loss": -26.228560981750487, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.91294264793396, "step": 127000}
{"episode_reward": 292.91282282966114, "episode": 128.0, "batch_reward": 0.2479182157665491, "critic_loss": 0.45550434033572673, "actor_loss": -25.94004006576538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.272297143936157, "step": 128000}
{"episode_reward": 253.87541845117104, "episode": 129.0, "batch_reward": 0.24844804319739341, "critic_loss": 0.4401047967970371, "actor_loss": -25.7345782623291, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.671416759490967, "step": 129000}
{"episode_reward": 531.4624012673727, "episode": 130.0, "batch_reward": 0.25036085419356824, "critic_loss": 0.448549069494009, "actor_loss": -26.003233154296876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.554280757904053, "step": 130000}
{"episode_reward": 507.5091223260859, "episode": 131.0, "batch_reward": 0.2528493006080389, "critic_loss": 0.44293663001060485, "actor_loss": -26.42914768600464, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.0287766456604, "step": 131000}
{"episode_reward": 517.5052604695755, "episode": 132.0, "batch_reward": 0.25224246735870837, "critic_loss": 0.4737888872772455, "actor_loss": -26.478044864654542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.696174144744873, "step": 132000}
{"episode_reward": 126.33683852885504, "episode": 133.0, "batch_reward": 0.2535719481855631, "critic_loss": 0.482414459630847, "actor_loss": -26.25713553237915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.859559774398804, "step": 133000}
{"episode_reward": 279.48503004589645, "episode": 134.0, "batch_reward": 0.2531575991213322, "critic_loss": 0.4756985154598951, "actor_loss": -25.9632914390564, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.96249294281006, "step": 134000}
{"episode_reward": 278.01530086743395, "episode": 135.0, "batch_reward": 0.2538666401654482, "critic_loss": 0.48819646187126636, "actor_loss": -26.65416132736206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.80406427383423, "step": 135000}
{"episode_reward": 340.11167422188703, "episode": 136.0, "batch_reward": 0.25399116417765616, "critic_loss": 0.4646098975092173, "actor_loss": -25.84283436203003, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27728247642517, "step": 136000}
{"episode_reward": 599.0214577833364, "episode": 137.0, "batch_reward": 0.2563655806481838, "critic_loss": 0.49670758804678916, "actor_loss": -26.638479164123535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.133989572525024, "step": 137000}
{"episode_reward": 148.789656094319, "episode": 138.0, "batch_reward": 0.256934791252017, "critic_loss": 0.490731871008873, "actor_loss": -26.62245344543457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.894652366638184, "step": 138000}
{"episode_reward": 513.4606488703752, "episode": 139.0, "batch_reward": 0.25898237830400467, "critic_loss": 0.5037345033437014, "actor_loss": -26.663966117858887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.655994415283203, "step": 139000}
{"episode_reward": 503.81034128487323, "episode": 140.0, "batch_reward": 0.2606699474900961, "critic_loss": 0.47840041953325274, "actor_loss": -26.969517108917238, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.18147349357605, "step": 140000}
{"episode_reward": 544.3950134805667, "episode": 141.0, "batch_reward": 0.2623377778232098, "critic_loss": 0.49405028426647185, "actor_loss": -27.221865673065185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.77302026748657, "step": 141000}
{"episode_reward": 563.3082387301289, "episode": 142.0, "batch_reward": 0.2633901286125183, "critic_loss": 0.5300343245118856, "actor_loss": -27.04096394729614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.56256079673767, "step": 142000}
{"episode_reward": 566.3514887833317, "episode": 143.0, "batch_reward": 0.2656496833115816, "critic_loss": 0.5008192690610885, "actor_loss": -27.00748977279663, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.886589527130127, "step": 143000}
{"episode_reward": 335.08888811157647, "episode": 144.0, "batch_reward": 0.2663476197719574, "critic_loss": 0.5143989282697439, "actor_loss": -27.372549476623536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.86449956893921, "step": 144000}
{"episode_reward": 570.5686030161959, "episode": 145.0, "batch_reward": 0.26948668985068797, "critic_loss": 0.4811849723011255, "actor_loss": -27.769743499755858, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.653454780578613, "step": 145000}
{"episode_reward": 519.4086611434303, "episode": 146.0, "batch_reward": 0.2690352572202683, "critic_loss": 0.5033201965689659, "actor_loss": -27.64495983505249, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.89193606376648, "step": 146000}
{"episode_reward": 152.4299542715232, "episode": 147.0, "batch_reward": 0.2691961506009102, "critic_loss": 0.5118615417033434, "actor_loss": -27.53274659729004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.7456955909729, "step": 147000}
{"episode_reward": 522.0768793494402, "episode": 148.0, "batch_reward": 0.2709792771488428, "critic_loss": 0.42438627664744855, "actor_loss": -27.896253101348876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.980635404586792, "step": 148000}
{"episode_reward": 518.2480637940974, "episode": 149.0, "batch_reward": 0.2721127099990845, "critic_loss": 0.46338740760087965, "actor_loss": -27.896990783691408, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.831644773483276, "step": 149000}
{"episode_reward": 154.85550369554943, "episode": 150.0, "batch_reward": 0.2721289121508598, "critic_loss": 0.46950698395073415, "actor_loss": -28.036807220458986, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
