{"episode": 1.0, "duration": 17.79587411880493, "episode_reward": 7.300100444933085, "step": 1000}
{"episode": 2.0, "duration": 1.7087767124176025, "episode_reward": 521.6090064697321, "step": 2000}
{"episode": 3.0, "batch_reward": 0.2514266615193778, "actor_loss": -43.79012059535729, "actor_target_entropy": -6.0, "alpha_value": 0.010699999250839183, "duration": 54.06156659126282, "episode_reward": 89.33820392444491, "step": 3000}
{"episode": 4.0, "batch_reward": 0.19261315861344339, "actor_loss": -40.194591941833494, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.021868467330933, "episode_reward": 130.7972364755763, "step": 4000}
{"episode": 5.0, "batch_reward": 0.18733535048365593, "actor_loss": -39.24422876739502, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.5932936668396, "episode_reward": 153.11642787998963, "step": 5000}
{"episode": 6.0, "batch_reward": 0.18133244781196117, "actor_loss": -37.313387802124026, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.817301273345947, "episode_reward": 195.1933312870267, "step": 6000}
{"episode": 7.0, "batch_reward": 0.18789403840899468, "actor_loss": -37.74315258789063, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.215044260025024, "episode_reward": 227.2136300270428, "step": 7000}
{"episode": 8.0, "batch_reward": 0.18989790686964989, "actor_loss": -37.191153686523435, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.3184072971344, "episode_reward": 208.56167805634368, "step": 8000}
{"episode": 9.0, "batch_reward": 0.19048477378487588, "actor_loss": -36.91428314971924, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.003689765930176, "episode_reward": 129.23238223361906, "step": 9000}
{"episode": 10.0, "batch_reward": 0.18841353236138822, "actor_loss": -31.349607398986816, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 3959.458114385605, "episode_reward": 278.629445137557, "step": 10000}
{"episode": 11.0, "batch_reward": 0.1924117244631052, "actor_loss": -31.21037342453003, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 35.225177526474, "episode_reward": 102.12540585122991, "step": 11000}
{"episode": 12.0, "batch_reward": 0.18277276939153672, "actor_loss": -27.224483131408693, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 437.05982542037964, "episode_reward": 77.31709243969733, "step": 12000}
{"episode": 13.0, "batch_reward": 0.18190725363045931, "actor_loss": -26.802590000152588, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.49176287651062, "episode_reward": 300.9800020028849, "step": 13000}
{"episode": 14.0, "batch_reward": 0.18809961296617986, "actor_loss": -24.95741167831421, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 434.6386420726776, "episode_reward": 260.35001329976666, "step": 14000}
{"episode": 15.0, "batch_reward": 0.19293508307635784, "actor_loss": -25.53850732421875, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.416932582855225, "episode_reward": 267.72572596798193, "step": 15000}
{"episode": 16.0, "batch_reward": 0.19960047942399978, "actor_loss": -24.133149124145508, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 440.65916681289673, "episode_reward": 285.0283101223729, "step": 16000}
{"episode": 17.0, "batch_reward": 0.1995317504554987, "actor_loss": -24.20508017349243, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.28774333000183, "episode_reward": 201.30852547254023, "step": 17000}
{"episode": 18.0, "batch_reward": 0.20518384422361852, "actor_loss": -23.12835185241699, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 429.1992995738983, "episode_reward": 328.8013943519558, "step": 18000}
{"episode": 19.0, "batch_reward": 0.20631631052494048, "actor_loss": -23.03129333496094, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.188844680786133, "episode_reward": 78.41863534387278, "step": 19000}
{"episode": 20.0, "batch_reward": 0.20564250133931636, "actor_loss": -21.984870937347413, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 439.1859519481659, "episode_reward": 366.2067087166055, "step": 20000}
{"episode": 21.0, "batch_reward": 0.2072058521360159, "actor_loss": -21.464655418395996, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.41946339607239, "episode_reward": 45.13402458307884, "step": 21000}
{"episode": 22.0, "batch_reward": 0.20384035621583463, "actor_loss": -18.739358606338502, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 423.5300691127777, "episode_reward": 151.64662122186357, "step": 22000}
{"episode": 23.0, "batch_reward": 0.2017200486212969, "actor_loss": -18.443647274017334, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.934880256652832, "episode_reward": 225.2367948392669, "step": 23000}
{"episode": 24.0, "batch_reward": 0.20419536893069745, "actor_loss": -17.59891879081726, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 428.45103669166565, "episode_reward": 339.675116752251, "step": 24000}
{"episode": 25.0, "batch_reward": 0.2051205428391695, "actor_loss": -17.559408124923706, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.640777826309204, "episode_reward": 59.73617236977273, "step": 25000}
{"episode": 26.0, "batch_reward": 0.2049027473926544, "actor_loss": -16.886891763687135, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 432.2319779396057, "episode_reward": 424.6749065557252, "step": 26000}
{"episode": 27.0, "batch_reward": 0.21202609990537166, "actor_loss": -17.707601850509644, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.36933183670044, "episode_reward": 414.66550020188015, "step": 27000}
{"episode": 28.0, "batch_reward": 0.219095447614789, "actor_loss": -18.146406637191774, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 436.6201899051666, "episode_reward": 394.26963838324934, "step": 28000}
{"episode": 29.0, "batch_reward": 0.2255634761303663, "actor_loss": -18.924387826919556, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.563037157058716, "episode_reward": 418.0297645005904, "step": 29000}
{"episode": 30.0, "batch_reward": 0.23176011601090432, "actor_loss": -19.745299835205078, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 437.30128049850464, "episode_reward": 274.94457698363817, "step": 30000}
{"episode": 31.0, "batch_reward": 0.23394639399647713, "actor_loss": -19.896857192993163, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 39.03102922439575, "episode_reward": 413.24548135229713, "step": 31000}
{"episode": 32.0, "batch_reward": 0.23952665668725967, "actor_loss": -19.940556175231933, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 434.9987885951996, "episode_reward": 405.83479232581004, "step": 32000}
{"episode": 33.0, "batch_reward": 0.24502149048447608, "actor_loss": -20.702986455917358, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.025567293167114, "episode_reward": 457.71947783390954, "step": 33000}
{"episode": 34.0, "batch_reward": 0.25073913560807704, "actor_loss": -21.256619733810425, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 434.32874584198, "episode_reward": 373.80193469353287, "step": 34000}
{"episode": 35.0, "batch_reward": 0.2555034282356501, "actor_loss": -21.723638723373412, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.18147087097168, "episode_reward": 385.63496196191215, "step": 35000}
{"episode": 36.0, "batch_reward": 0.2578146039843559, "actor_loss": -22.407936382293702, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 435.1716504096985, "episode_reward": 414.75360187028207, "step": 36000}
{"episode": 37.0, "batch_reward": 0.2626469634473324, "actor_loss": -22.97085696029663, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.689762592315674, "episode_reward": 440.7248376475657, "step": 37000}
{"episode": 38.0, "batch_reward": 0.267923765078187, "actor_loss": -23.188643856048586, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 437.50758504867554, "episode_reward": 400.55941964259296, "step": 38000}
{"episode": 39.0, "batch_reward": 0.27108651484549046, "actor_loss": -23.534076637268065, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.331985235214233, "episode_reward": 417.20698130234837, "step": 39000}
{"episode": 40.0, "batch_reward": 0.27522124914824964, "actor_loss": -23.42046277618408, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 436.5175447463989, "episode_reward": 439.304507877357, "step": 40000}
{"episode": 41.0, "batch_reward": 0.2798116590678692, "actor_loss": -23.938662216186522, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.695128202438354, "episode_reward": 452.6872784002349, "step": 41000}
{"episode": 42.0, "batch_reward": 0.28256351816654207, "actor_loss": -24.279770446777345, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 428.5458459854126, "episode_reward": 383.6478129815238, "step": 42000}
{"episode": 43.0, "batch_reward": 0.28636446385085584, "actor_loss": -24.754959915161134, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.031087160110474, "episode_reward": 472.84227344394026, "step": 43000}
{"episode": 44.0, "batch_reward": 0.28650989089906215, "actor_loss": -24.24084617996216, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 415.01632165908813, "episode_reward": 95.39145559411719, "step": 44000}
{"episode": 45.0, "batch_reward": 0.28633666497468946, "actor_loss": -24.192734619140627, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.179821729660034, "episode_reward": 476.79574733504427, "step": 45000}
{"episode": 46.0, "batch_reward": 0.289762387573719, "actor_loss": -24.41462147140503, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 419.2873511314392, "episode_reward": 426.39428685790705, "step": 46000}
{"episode": 47.0, "batch_reward": 0.2930096549093723, "actor_loss": -24.90207177352905, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.95985245704651, "episode_reward": 434.8990835464446, "step": 47000}
{"episode": 48.0, "batch_reward": 0.2951497831046581, "actor_loss": -25.00154814910889, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 428.4375104904175, "episode_reward": 420.8354471727108, "step": 48000}
{"episode": 49.0, "batch_reward": 0.2990848155617714, "actor_loss": -25.434452220916747, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.21501660346985, "episode_reward": 476.0103506178213, "step": 49000}
{"episode": 50.0, "batch_reward": 0.3029868598282337, "actor_loss": -25.553682441711427, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 429.54080748558044, "episode_reward": 491.24655243880954, "step": 50000}
{"episode": 51.0, "batch_reward": 0.3063976040184498, "actor_loss": -25.807937416076662, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.79650163650513, "episode_reward": 469.077298126506, "step": 51000}
{"episode": 52.0, "batch_reward": 0.3089935898780823, "actor_loss": -25.49318699645996, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 434.73992109298706, "episode_reward": 489.8172082194475, "step": 52000}
{"episode": 53.0, "batch_reward": 0.31298085939884185, "actor_loss": -25.816374198913575, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.872210025787354, "episode_reward": 479.33346011885845, "step": 53000}
{"episode": 54.0, "batch_reward": 0.31588072288036345, "actor_loss": -25.94270634841919, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 431.57849407196045, "episode_reward": 417.05675663665204, "step": 54000}
{"episode": 55.0, "batch_reward": 0.3171939428150654, "actor_loss": -26.12815364074707, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.49883794784546, "episode_reward": 450.4960957675633, "step": 55000}
{"episode": 56.0, "batch_reward": 0.3188906668126583, "actor_loss": -26.54240189743042, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 438.83033180236816, "episode_reward": 450.70079593245293, "step": 56000}
{"episode": 57.0, "batch_reward": 0.32249917858839033, "actor_loss": -27.02201454925537, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.79677391052246, "episode_reward": 451.39668892054635, "step": 57000}
{"episode": 58.0, "batch_reward": 0.32380040046572683, "actor_loss": -26.94026028060913, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 440.4002068042755, "episode_reward": 424.2239624281632, "step": 58000}
{"episode": 59.0, "batch_reward": 0.32596734595298765, "actor_loss": -27.184868297576905, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.479368209838867, "episode_reward": 492.4940628106764, "step": 59000}
{"episode": 60.0, "batch_reward": 0.3279275020956993, "actor_loss": -27.348839294433592, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 433.7137098312378, "episode_reward": 457.5634324197178, "step": 60000}
{"episode": 61.0, "batch_reward": 0.3318751701116562, "actor_loss": -27.635074298858644, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.65921497344971, "episode_reward": 457.5207836731188, "step": 61000}
{"episode": 62.0, "batch_reward": 0.33206367990374563, "actor_loss": -27.989741374969483, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 444.0653009414673, "episode_reward": 417.413128714814, "step": 62000}
{"episode": 63.0, "batch_reward": 0.3342917366027832, "actor_loss": -28.224310562133788, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.577020168304443, "episode_reward": 423.270692699262, "step": 63000}
{"episode": 64.0, "batch_reward": 0.3361460130214691, "actor_loss": -28.512115882873534, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 435.74909472465515, "episode_reward": 448.0897740711023, "step": 64000}
{"episode": 65.0, "batch_reward": 0.33754855731129646, "actor_loss": -28.758257228851317, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.855650663375854, "episode_reward": 493.4500153643056, "step": 65000}
{"episode": 66.0, "batch_reward": 0.3399087650477886, "actor_loss": -27.902329208374024, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 439.9498815536499, "episode_reward": 435.9389104871915, "step": 66000}
{"episode": 67.0, "batch_reward": 0.3418696751594543, "actor_loss": -28.219668365478515, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.33876395225525, "episode_reward": 431.7375378098014, "step": 67000}
{"episode": 68.0, "batch_reward": 0.3422280432879925, "actor_loss": -27.966426628112792, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 434.86327862739563, "episode_reward": 461.51440670210326, "step": 68000}
{"episode": 69.0, "batch_reward": 0.3437478930354118, "actor_loss": -28.180911781311035, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.628339290618896, "episode_reward": 473.2896796891445, "step": 69000}
{"episode": 70.0, "batch_reward": 0.3457225652039051, "actor_loss": -28.248063419342042, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 439.0343568325043, "episode_reward": 399.2114043015918, "step": 70000}
{"episode": 71.0, "batch_reward": 0.3466220143735409, "actor_loss": -28.54169398498535, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 37.70576620101929, "episode_reward": 424.0284681352971, "step": 71000}
{"episode": 72.0, "batch_reward": 0.34862693068385125, "actor_loss": -28.597335983276366, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 438.0629346370697, "episode_reward": 467.6116089859014, "step": 72000}
{"episode": 73.0, "batch_reward": 0.34907800909876824, "actor_loss": -28.51045275878906, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.58922243118286, "episode_reward": 449.26170361896436, "step": 73000}
{"episode": 74.0, "batch_reward": 0.3507503916621208, "actor_loss": -28.326562412261964, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 437.7092490196228, "episode_reward": 388.46032307655673, "step": 74000}
{"episode": 75.0, "batch_reward": 0.3511419129371643, "actor_loss": -28.336822044372557, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.733383655548096, "episode_reward": 396.6281553665146, "step": 75000}
{"episode": 76.0, "batch_reward": 0.3517869637012482, "actor_loss": -28.24825870895386, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 434.2459454536438, "episode_reward": 368.751422861323, "step": 76000}
{"episode": 77.0, "batch_reward": 0.35194295743107795, "actor_loss": -28.494200736999513, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.450957536697388, "episode_reward": 423.99642918073755, "step": 77000}
{"episode": 78.0, "batch_reward": 0.3538380662202835, "actor_loss": -28.299329860687255, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 443.81242203712463, "episode_reward": 476.14489146562795, "step": 78000}
{"episode": 79.0, "batch_reward": 0.35490213003754617, "actor_loss": -28.49389366912842, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.81509804725647, "episode_reward": 490.0944622752187, "step": 79000}
{"episode": 80.0, "batch_reward": 0.3566465899348259, "actor_loss": -27.956623264312743, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 437.16603088378906, "episode_reward": 445.19296806474364, "step": 80000}
{"episode": 81.0, "batch_reward": 0.3583128805458546, "actor_loss": -28.19469221496582, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 35.84718894958496, "episode_reward": 459.30243416540196, "step": 81000}
{"episode": 82.0, "batch_reward": 0.3591332720220089, "actor_loss": -28.19507978439331, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 420.24602007865906, "episode_reward": 465.444011414428, "step": 82000}
{"episode": 83.0, "batch_reward": 0.36014605033397673, "actor_loss": -28.170194904327392, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.600873708724976, "episode_reward": 453.4439930294034, "step": 83000}
{"episode": 84.0, "batch_reward": 0.3603407437205315, "actor_loss": -27.820517044067383, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 421.67582726478577, "episode_reward": 436.3295620846722, "step": 84000}
{"episode": 85.0, "batch_reward": 0.36219812035560606, "actor_loss": -28.067423900604247, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.742831468582153, "episode_reward": 402.94868282539846, "step": 85000}
{"episode": 86.0, "batch_reward": 0.362096400141716, "actor_loss": -27.920606884002687, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 415.04486060142517, "episode_reward": 470.3795416686889, "step": 86000}
{"episode": 87.0, "batch_reward": 0.36383547440171243, "actor_loss": -28.17362544631958, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.79259443283081, "episode_reward": 444.3326966754141, "step": 87000}
{"episode": 88.0, "batch_reward": 0.3649529827237129, "actor_loss": -28.61576445388794, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 419.1029369831085, "episode_reward": 409.36233470146806, "step": 88000}
{"episode": 89.0, "batch_reward": 0.3650789564847946, "actor_loss": -28.54398614883423, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.673035383224487, "episode_reward": 434.0349231012955, "step": 89000}
{"episode": 90.0, "batch_reward": 0.3662075873017311, "actor_loss": -28.413773250579833, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 425.18510913848877, "episode_reward": 387.77888439949254, "step": 90000}
{"episode": 91.0, "batch_reward": 0.3668907703757286, "actor_loss": -28.375769412994384, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 31.80600666999817, "episode_reward": 421.452047661534, "step": 91000}
{"episode": 92.0, "batch_reward": 0.36635250779986384, "actor_loss": -28.231970169067385, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 416.10133266448975, "episode_reward": 386.6825958562835, "step": 92000}
{"episode": 93.0, "batch_reward": 0.3670567336380482, "actor_loss": -28.372690357208253, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.257451057434082, "episode_reward": 446.6513626591537, "step": 93000}
{"episode": 94.0, "batch_reward": 0.3685341482162476, "actor_loss": -28.403056079864502, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 432.2704393863678, "episode_reward": 366.8523739073019, "step": 94000}
{"episode": 95.0, "batch_reward": 0.36833041086792945, "actor_loss": -28.49360627746582, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.91370701789856, "episode_reward": 388.4293654400941, "step": 95000}
{"episode": 96.0, "batch_reward": 0.36735695973038673, "actor_loss": -28.538476871490477, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 442.03735852241516, "episode_reward": 424.4066333336579, "step": 96000}
{"episode": 97.0, "batch_reward": 0.36909169787168505, "actor_loss": -28.812778839111328, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.10090970993042, "episode_reward": 399.6587520489868, "step": 97000}
{"episode": 98.0, "batch_reward": 0.3685842483043671, "actor_loss": -28.885395015716554, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 433.7270510196686, "episode_reward": 403.1872800175991, "step": 98000}
{"episode": 99.0, "batch_reward": 0.3687521682679653, "actor_loss": -29.03920463180542, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.515239238739014, "episode_reward": 434.85292382393783, "step": 99000}
{"episode": 100.0, "batch_reward": 0.3693900179862976, "actor_loss": -28.974093479156494, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 433.89522218704224, "episode_reward": 425.37186687090315, "step": 100000}
{"episode": 101.0, "batch_reward": 0.3711292661130428, "actor_loss": -29.13581600189209, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 35.31947422027588, "episode_reward": 464.57954011566267, "step": 101000}
{"episode": 102.0, "batch_reward": 0.3707611221075058, "actor_loss": -29.338568141937255, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 436.7936089038849, "episode_reward": 413.373393923857, "step": 102000}
{"episode": 103.0, "batch_reward": 0.3716344163417816, "actor_loss": -29.549620624542236, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.617116928100586, "episode_reward": 462.205372212628, "step": 103000}
{"episode": 104.0, "batch_reward": 0.3729347270429134, "actor_loss": -29.28770402145386, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 435.72372460365295, "episode_reward": 441.606196233477, "step": 104000}
{"episode": 105.0, "batch_reward": 0.37388604012131693, "actor_loss": -29.6242177772522, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.07583975791931, "episode_reward": 411.4882755595719, "step": 105000}
{"episode": 106.0, "batch_reward": 0.3749068405628204, "actor_loss": -29.501155925750734, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 437.9348735809326, "episode_reward": 409.8875650636745, "step": 106000}
{"episode": 107.0, "batch_reward": 0.3749125273823738, "actor_loss": -29.61192692565918, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.24946355819702, "episode_reward": 475.97635977547753, "step": 107000}
{"episode": 108.0, "batch_reward": 0.37488053417205813, "actor_loss": -29.592271572113038, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 444.06309390068054, "episode_reward": 421.4770301544169, "step": 108000}
{"episode": 109.0, "batch_reward": 0.3753141274750233, "actor_loss": -29.713692348480226, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.51692843437195, "episode_reward": 440.0493464761693, "step": 109000}
{"episode": 110.0, "batch_reward": 0.37533729580044745, "actor_loss": -29.462912506103514, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 421.92176938056946, "episode_reward": 462.5221812425288, "step": 110000}
{"episode": 111.0, "batch_reward": 0.376206022053957, "actor_loss": -29.566995239257814, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.67424535751343, "episode_reward": 455.0254622756915, "step": 111000}
{"episode": 112.0, "batch_reward": 0.37804796782135963, "actor_loss": -29.715329116821287, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 418.6684777736664, "episode_reward": 461.851672339297, "step": 112000}
{"episode": 113.0, "batch_reward": 0.3789749175608158, "actor_loss": -29.905009983062744, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.91251230239868, "episode_reward": 474.3128822281148, "step": 113000}
{"episode": 114.0, "batch_reward": 0.37882156774401665, "actor_loss": -29.796615169525147, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 422.225768327713, "episode_reward": 454.74938949572436, "step": 114000}
{"episode": 115.0, "batch_reward": 0.3800355800390244, "actor_loss": -29.891314712524412, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.727203845977783, "episode_reward": 443.81772949421344, "step": 115000}
{"episode": 116.0, "batch_reward": 0.3806733312904835, "actor_loss": -29.787119705200194, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 421.2805190086365, "episode_reward": 473.4475926394194, "step": 116000}
{"episode": 117.0, "batch_reward": 0.38022458311915397, "actor_loss": -29.554735355377197, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.40406823158264, "episode_reward": 447.1124829275309, "step": 117000}
{"episode": 118.0, "batch_reward": 0.38223170179128646, "actor_loss": -30.19466940689087, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 441.6942319869995, "episode_reward": 482.3396255249154, "step": 118000}
{"episode": 119.0, "batch_reward": 0.38261330977082253, "actor_loss": -30.420484485626222, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.188417434692383, "episode_reward": 464.43874956747237, "step": 119000}
{"episode": 120.0, "batch_reward": 0.3830564562082291, "actor_loss": -30.381191593170165, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 437.6540310382843, "episode_reward": 443.7074844807014, "step": 120000}
{"episode": 121.0, "batch_reward": 0.3839999164044857, "actor_loss": -30.455261013031006, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 36.00290131568909, "episode_reward": 485.7710829215792, "step": 121000}
{"episode": 122.0, "batch_reward": 0.3838444653749466, "actor_loss": -30.493327041625978, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 434.4988877773285, "episode_reward": 482.43323184609017, "step": 122000}
{"episode": 123.0, "batch_reward": 0.3854129875898361, "actor_loss": -30.793076251983642, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.43307900428772, "episode_reward": 482.4511078304738, "step": 123000}
{"episode": 124.0, "batch_reward": 0.38611501213908195, "actor_loss": -31.420352630615234, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 436.6238024234772, "episode_reward": 432.7611417362297, "step": 124000}
{"episode": 125.0, "batch_reward": 0.3875402080118656, "actor_loss": -31.492564342498778, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.859723329544067, "episode_reward": 469.415692382439, "step": 125000}
{"episode": 126.0, "batch_reward": 0.3872658813595772, "actor_loss": -31.62916549682617, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 427.53663325309753, "episode_reward": 445.68706654403115, "step": 126000}
{"episode": 127.0, "batch_reward": 0.38839105746150016, "actor_loss": -31.85543172454834, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.659517288208008, "episode_reward": 443.709792738779, "step": 127000}
{"episode": 128.0, "batch_reward": 0.388614177942276, "actor_loss": -31.927462455749513, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 440.1563563346863, "episode_reward": 440.99518036088534, "step": 128000}
{"episode": 129.0, "batch_reward": 0.38788452982902527, "actor_loss": -31.886721672058105, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.82781481742859, "episode_reward": 409.1533364738887, "step": 129000}
{"episode": 130.0, "batch_reward": 0.38894142919778824, "actor_loss": -31.84229494857788, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 441.1622974872589, "episode_reward": 461.40049857108545, "step": 130000}
{"episode": 131.0, "batch_reward": 0.3892429660856724, "actor_loss": -31.897168148040773, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 36.616369009017944, "episode_reward": 486.8699192288684, "step": 131000}
{"episode": 132.0, "batch_reward": 0.3908460013568401, "actor_loss": -32.21348154067993, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 437.5111005306244, "episode_reward": 467.31439178954815, "step": 132000}
{"episode": 133.0, "batch_reward": 0.3906951423883438, "actor_loss": -32.376181007385256, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.025413751602173, "episode_reward": 474.1378994772161, "step": 133000}
{"episode": 134.0, "batch_reward": 0.39136043000221254, "actor_loss": -32.503502613067624, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 443.7313024997711, "episode_reward": 474.7004387278223, "step": 134000}
{"episode": 135.0, "batch_reward": 0.39233196368813517, "actor_loss": -32.744279571533205, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.084676504135132, "episode_reward": 521.9393101414491, "step": 135000}
{"episode": 136.0, "batch_reward": 0.3931181070804596, "actor_loss": -32.944750312805176, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 441.9162368774414, "episode_reward": 443.20383406061615, "step": 136000}
{"episode": 137.0, "batch_reward": 0.3940339846909046, "actor_loss": -32.97001445770264, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.683215618133545, "episode_reward": 478.48831891644795, "step": 137000}
{"episode": 138.0, "batch_reward": 0.3940500810146332, "actor_loss": -32.976595237731935, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 434.82007241249084, "episode_reward": 422.89857790778336, "step": 138000}
{"episode": 139.0, "batch_reward": 0.3939844007194042, "actor_loss": -32.9787487411499, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.09532594680786, "episode_reward": 456.17132556636875, "step": 139000}
{"episode": 140.0, "batch_reward": 0.3944022409319878, "actor_loss": -33.481509014129635, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 444.11367416381836, "episode_reward": 428.7236744835572, "step": 140000}
{"episode": 141.0, "batch_reward": 0.39408790773153307, "actor_loss": -33.40065571975708, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 36.017752170562744, "episode_reward": 408.7548410654161, "step": 141000}
{"episode": 142.0, "batch_reward": 0.39501554375886916, "actor_loss": -33.462701644897464, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 430.78808307647705, "episode_reward": 481.340842979527, "step": 142000}
{"episode": 143.0, "batch_reward": 0.3952577605545521, "actor_loss": -33.43878329849243, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.21056365966797, "episode_reward": 460.7662607882764, "step": 143000}
{"episode": 144.0, "batch_reward": 0.39632885113358496, "actor_loss": -33.66689000701904, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 438.16125893592834, "episode_reward": 488.58847392726483, "step": 144000}
{"episode": 145.0, "batch_reward": 0.396904730618, "actor_loss": -33.66805726242065, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.489325523376465, "episode_reward": 439.02700493855855, "step": 145000}
{"episode": 146.0, "batch_reward": 0.3968276332616806, "actor_loss": -33.84047525405884, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 453.18965196609497, "episode_reward": 492.1816794492904, "step": 146000}
{"episode": 147.0, "batch_reward": 0.3973106794059277, "actor_loss": -33.755959789276126, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.826310873031616, "episode_reward": 474.3210419699211, "step": 147000}
{"episode": 148.0, "batch_reward": 0.39837028270959857, "actor_loss": -34.5195354347229, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 439.0720839500427, "episode_reward": 344.25595552024384, "step": 148000}
{"episode": 149.0, "batch_reward": 0.39757592007517817, "actor_loss": -34.55350301361084, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.947493076324463, "episode_reward": 502.8088860275131, "step": 149000}
{"episode": 150.0, "batch_reward": 0.39788696444034577, "actor_loss": -34.310865394592284, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "step": 150000}
