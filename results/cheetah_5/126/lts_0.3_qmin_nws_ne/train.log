{"episode_reward": 0.0, "episode": 1.0, "duration": 18.311553955078125, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.5182673931121826, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.24820807909083073, "critic_loss": 0.01740635140034581, "actor_loss": -15.791401010333132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 70.5039930343628, "step": 3000}
{"episode_reward": 5.977584292818091, "episode": 4.0, "batch_reward": 0.1554258012548089, "critic_loss": 0.009264315574197098, "actor_loss": -15.113248310089112, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087186336517334, "step": 4000}
{"episode_reward": 7.457013530638449, "episode": 5.0, "batch_reward": 0.12282188403978944, "critic_loss": 0.010869854914024472, "actor_loss": -15.436543138504028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.102226972579956, "step": 5000}
{"episode_reward": 10.22371103895188, "episode": 6.0, "batch_reward": 0.10207370792329311, "critic_loss": 0.013938014031155035, "actor_loss": -14.016773348808288, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.846408128738403, "step": 6000}
{"episode_reward": 9.323491246114804, "episode": 7.0, "batch_reward": 0.08789235805720091, "critic_loss": 0.012364554446423426, "actor_loss": -13.449466923713684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.232872009277344, "step": 7000}
{"episode_reward": 7.170052067272287, "episode": 8.0, "batch_reward": 0.07682535216584802, "critic_loss": 0.010725013973424211, "actor_loss": -13.760683678627014, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.29194664955139, "step": 8000}
{"episode_reward": 8.429162209366028, "episode": 9.0, "batch_reward": 0.06821634760499, "critic_loss": 0.009081692012026906, "actor_loss": -12.860838248252868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.54924702644348, "step": 9000}
{"episode_reward": 10.029624718831869, "episode": 10.0, "batch_reward": 0.06258127360418439, "critic_loss": 0.010223790267133154, "actor_loss": -13.137829583644868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.360105752944946, "step": 10000}
{"episode_reward": 7.2339140708656435, "episode": 11.0, "batch_reward": 0.05692384355701506, "critic_loss": 0.012570413768058643, "actor_loss": -11.72469687795639, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.77748680114746, "step": 11000}
{"episode_reward": 7.53185679877057, "episode": 12.0, "batch_reward": 0.05353080236166716, "critic_loss": 0.010694837890565396, "actor_loss": -12.883474800109862, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.67111587524414, "step": 12000}
{"episode_reward": 9.509122594270126, "episode": 13.0, "batch_reward": 0.049629832703620196, "critic_loss": 0.010188621946843342, "actor_loss": -11.32511006116867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.005500078201294, "step": 13000}
{"episode_reward": 8.066403853408127, "episode": 14.0, "batch_reward": 0.04571048646420241, "critic_loss": 0.00956015892792493, "actor_loss": -11.389053892612457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.299268007278442, "step": 14000}
{"episode_reward": 7.752668964476671, "episode": 15.0, "batch_reward": 0.04379228909499943, "critic_loss": 0.010878046003170312, "actor_loss": -9.804577964305878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.4351749420166, "step": 15000}
{"episode_reward": 7.964674874515064, "episode": 16.0, "batch_reward": 0.04077619059942663, "critic_loss": 0.009201980966259725, "actor_loss": -12.618423989772797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.174375534057617, "step": 16000}
{"episode_reward": 9.011635364266668, "episode": 17.0, "batch_reward": 0.03928137687034905, "critic_loss": 0.010585023597581312, "actor_loss": -12.591464894294738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.804685354232788, "step": 17000}
{"episode_reward": 10.297699695566179, "episode": 18.0, "batch_reward": 0.03733367909118533, "critic_loss": 0.007367090225568972, "actor_loss": -11.83626137304306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.731285572052002, "step": 18000}
{"episode_reward": 7.610319863660167, "episode": 19.0, "batch_reward": 0.03656585379317403, "critic_loss": 0.011310306136030703, "actor_loss": -11.865341637611388, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.940051078796387, "step": 19000}
{"episode_reward": 13.285539995333167, "episode": 20.0, "batch_reward": 0.035235239122062924, "critic_loss": 0.007013225238886662, "actor_loss": -10.592152295589447, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.29118800163269, "step": 20000}
{"episode_reward": 8.228257798009789, "episode": 21.0, "batch_reward": 0.033053853888530285, "critic_loss": 0.010935423098038882, "actor_loss": -11.1374010181427, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.368611097335815, "step": 21000}
{"episode_reward": 10.406125171010318, "episode": 22.0, "batch_reward": 0.03226204110914841, "critic_loss": 0.00862582374754129, "actor_loss": -9.965778655290604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.206733226776123, "step": 22000}
{"episode_reward": 11.002950812537366, "episode": 23.0, "batch_reward": 0.031316343198530376, "critic_loss": 0.007253203084343113, "actor_loss": -10.533195033550262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.380432605743408, "step": 23000}
{"episode_reward": 6.549979049952126, "episode": 24.0, "batch_reward": 0.03058528701076284, "critic_loss": 0.00795453822100535, "actor_loss": -9.801135870695115, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.912954807281494, "step": 24000}
{"episode_reward": 7.409283472599026, "episode": 25.0, "batch_reward": 0.029587595202028753, "critic_loss": 0.00851953151676571, "actor_loss": -10.145230632066726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.285053253173828, "step": 25000}
{"episode_reward": 8.329841347419825, "episode": 26.0, "batch_reward": 0.029124324972741304, "critic_loss": 0.007224328919546679, "actor_loss": -10.168025849342346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.25239634513855, "step": 26000}
{"episode_reward": 10.771137406904973, "episode": 27.0, "batch_reward": 0.028444042273797095, "critic_loss": 0.007140529884665739, "actor_loss": -9.758927621603013, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.178426504135132, "step": 27000}
{"episode_reward": 9.086046092104635, "episode": 28.0, "batch_reward": 0.02674445566581562, "critic_loss": 0.006592853357025888, "actor_loss": -10.136878124713897, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.046895742416382, "step": 28000}
{"episode_reward": 8.631232786699703, "episode": 29.0, "batch_reward": 0.026278088827617466, "critic_loss": 0.00667114188708365, "actor_loss": -8.544955733537673, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.37475299835205, "step": 29000}
{"episode_reward": 10.060721897637174, "episode": 30.0, "batch_reward": 0.02647998602129519, "critic_loss": 0.006701356877805665, "actor_loss": -10.152996044158936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.043448448181152, "step": 30000}
{"episode_reward": 8.636054691555852, "episode": 31.0, "batch_reward": 0.02545342125557363, "critic_loss": 0.005148386635468342, "actor_loss": -10.344311551332474, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.64606046676636, "step": 31000}
{"episode_reward": 7.254894600961444, "episode": 32.0, "batch_reward": 0.02483621372561902, "critic_loss": 0.007744443235278595, "actor_loss": -9.671693287611008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.101378917694092, "step": 32000}
{"episode_reward": 5.385065716897253, "episode": 33.0, "batch_reward": 0.024838068959768863, "critic_loss": 0.012092655489803292, "actor_loss": -9.072736130475999, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.484843254089355, "step": 33000}
{"episode_reward": 10.360251291734595, "episode": 34.0, "batch_reward": 0.023842838199809195, "critic_loss": 0.004765423771517817, "actor_loss": -10.23325142812729, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.53824734687805, "step": 34000}
{"episode_reward": 9.850284399402533, "episode": 35.0, "batch_reward": 0.023412592876702547, "critic_loss": 0.006329210529569537, "actor_loss": -9.222439098715782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.09018111228943, "step": 35000}
{"episode_reward": 7.383917818425612, "episode": 36.0, "batch_reward": 0.02310460558347404, "critic_loss": 0.005007128511497285, "actor_loss": -9.727741525411606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.485125303268433, "step": 36000}
{"episode_reward": 9.725811761871004, "episode": 37.0, "batch_reward": 0.022605610522441567, "critic_loss": 0.006610864480840974, "actor_loss": -9.958705831050873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.557502031326294, "step": 37000}
{"episode_reward": 7.339681103420485, "episode": 38.0, "batch_reward": 0.02232690226379782, "critic_loss": 0.006039981019770494, "actor_loss": -8.545971875905991, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.971039056777954, "step": 38000}
{"episode_reward": 6.257417984163409, "episode": 39.0, "batch_reward": 0.0221915538511239, "critic_loss": 0.005885925389069598, "actor_loss": -9.211096341490746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.199469327926636, "step": 39000}
{"episode_reward": 5.862841688063804, "episode": 40.0, "batch_reward": 0.021188364542555065, "critic_loss": 0.005211931661644485, "actor_loss": -9.707681747555732, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.543213844299316, "step": 40000}
{"episode_reward": 6.082704543086562, "episode": 41.0, "batch_reward": 0.02114678137144074, "critic_loss": 0.0064517768429941495, "actor_loss": -10.075581530213356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.5905499458313, "step": 41000}
{"episode_reward": 7.5166834171665435, "episode": 42.0, "batch_reward": 0.02064816712308675, "critic_loss": 0.005542853744962485, "actor_loss": -9.574406152606011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.531132221221924, "step": 42000}
{"episode_reward": 6.513644777610211, "episode": 43.0, "batch_reward": 0.020249663988128306, "critic_loss": 0.007552522079757182, "actor_loss": -9.75278753221035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.827479362487793, "step": 43000}
{"episode_reward": 8.311255395380227, "episode": 44.0, "batch_reward": 0.019909786337055264, "critic_loss": 0.004849362363122054, "actor_loss": -9.555661573410035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.17371654510498, "step": 44000}
{"episode_reward": 7.31790855698324, "episode": 45.0, "batch_reward": 0.019735318610444665, "critic_loss": 0.004698903370648623, "actor_loss": -8.825485800266266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.636951684951782, "step": 45000}
{"episode_reward": 7.365682217404895, "episode": 46.0, "batch_reward": 0.0196891419775784, "critic_loss": 0.005592761946318205, "actor_loss": -9.346370563983918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.50972890853882, "step": 46000}
{"episode_reward": 10.169289515807465, "episode": 47.0, "batch_reward": 0.019378294624853878, "critic_loss": 0.0058824725230806505, "actor_loss": -10.145989994525909, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.20055365562439, "step": 47000}
{"episode_reward": 6.236715344363838, "episode": 48.0, "batch_reward": 0.018992605382576584, "critic_loss": 0.0050484015689289665, "actor_loss": -8.471081171035767, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.38301706314087, "step": 48000}
{"episode_reward": 6.795570287527462, "episode": 49.0, "batch_reward": 0.019266085618641227, "critic_loss": 0.00407867723016534, "actor_loss": -8.97297833287716, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.687264442443848, "step": 49000}
{"episode_reward": 7.453120432295246, "episode": 50.0, "batch_reward": 0.018902598631102593, "critic_loss": 0.0050750475739187095, "actor_loss": -9.428218674659728, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.86212730407715, "step": 50000}
{"episode_reward": 11.137368613235378, "episode": 51.0, "batch_reward": 0.018515579649712892, "critic_loss": 0.007695653244998539, "actor_loss": -7.709961829543114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.39970302581787, "step": 51000}
{"episode_reward": 10.098283737380712, "episode": 52.0, "batch_reward": 0.018520399015862495, "critic_loss": 0.005431089955178322, "actor_loss": -9.449977771937847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.56755542755127, "step": 52000}
{"episode_reward": 7.475991930478656, "episode": 53.0, "batch_reward": 0.018266749346163125, "critic_loss": 0.00590874202788109, "actor_loss": -7.9578535605072975, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09588360786438, "step": 53000}
{"episode_reward": 6.478290178800252, "episode": 54.0, "batch_reward": 0.018333513881079854, "critic_loss": 0.0047695858831284564, "actor_loss": -9.086411555767059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.60154414176941, "step": 54000}
{"episode_reward": 7.375388459121393, "episode": 55.0, "batch_reward": 0.017668887566775083, "critic_loss": 0.00468636765217525, "actor_loss": -9.268734966754913, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.068264722824097, "step": 55000}
{"episode_reward": 6.522187074839669, "episode": 56.0, "batch_reward": 0.017336968116927892, "critic_loss": 0.007760539034119575, "actor_loss": -8.415910388410092, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.059795141220093, "step": 56000}
{"episode_reward": 7.989354537104922, "episode": 57.0, "batch_reward": 0.01748787351185456, "critic_loss": 0.003463106346229324, "actor_loss": -8.88587028092146, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.66431736946106, "step": 57000}
{"episode_reward": 7.345188563130117, "episode": 58.0, "batch_reward": 0.017212793805636464, "critic_loss": 0.0061603148188733034, "actor_loss": -8.065260265052318, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.19888710975647, "step": 58000}
{"episode_reward": 8.696758507669415, "episode": 59.0, "batch_reward": 0.016891488266177476, "critic_loss": 0.003380989581084577, "actor_loss": -8.577834372162819, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.462750673294067, "step": 59000}
{"episode_reward": 12.11325568960305, "episode": 60.0, "batch_reward": 0.017006124959327282, "critic_loss": 0.005896770459105028, "actor_loss": -9.295509494364262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09539294242859, "step": 60000}
{"episode_reward": 14.384131954125081, "episode": 61.0, "batch_reward": 0.016724996672943235, "critic_loss": 0.004458275053446414, "actor_loss": -8.891140613496303, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.75343656539917, "step": 61000}
{"episode_reward": 7.280974816717407, "episode": 62.0, "batch_reward": 0.01642471090098843, "critic_loss": 0.004414513403607998, "actor_loss": -7.776985359966755, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.661750078201294, "step": 62000}
{"episode_reward": 10.863346175402675, "episode": 63.0, "batch_reward": 0.016511899972800167, "critic_loss": 0.006151897060743068, "actor_loss": -7.589831405878067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.64891290664673, "step": 63000}
{"episode_reward": 10.193163913078257, "episode": 64.0, "batch_reward": 0.016435142317321152, "critic_loss": 0.0032812655373709275, "actor_loss": -8.752171628296376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.796802043914795, "step": 64000}
{"episode_reward": 12.208791303674577, "episode": 65.0, "batch_reward": 0.01653260883735493, "critic_loss": 0.005149050863808952, "actor_loss": -8.338261516928673, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.65721821784973, "step": 65000}
{"episode_reward": 8.390569773294894, "episode": 66.0, "batch_reward": 0.01609227936435491, "critic_loss": 0.00413810622546589, "actor_loss": -8.713226916730404, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.712833642959595, "step": 66000}
{"episode_reward": 7.335885122692943, "episode": 67.0, "batch_reward": 0.01605545717012137, "critic_loss": 0.0046509507710288745, "actor_loss": -8.195190525054931, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.043282747268677, "step": 67000}
{"episode_reward": 7.0260550834979645, "episode": 68.0, "batch_reward": 0.016166255910880865, "critic_loss": 0.004268360539019341, "actor_loss": -8.640894366681575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.4191837310791, "step": 68000}
{"episode_reward": 6.314271813190291, "episode": 69.0, "batch_reward": 0.01608405039506033, "critic_loss": 0.004075391835547635, "actor_loss": -8.319404884517192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.040484189987183, "step": 69000}
{"episode_reward": 12.591858339167471, "episode": 70.0, "batch_reward": 0.015758097573649137, "critic_loss": 0.003406891208171146, "actor_loss": -9.287664691209793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.244730472564697, "step": 70000}
{"episode_reward": 8.026937815187583, "episode": 71.0, "batch_reward": 0.015721609193366022, "critic_loss": 0.003993493343732553, "actor_loss": -8.1803702455163, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.09755277633667, "step": 71000}
{"episode_reward": 7.729969067588801, "episode": 72.0, "batch_reward": 0.015547637888230383, "critic_loss": 0.0045386413214728236, "actor_loss": -8.661779686182737, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.672650814056396, "step": 72000}
{"episode_reward": 6.380904891392683, "episode": 73.0, "batch_reward": 0.015596352896653115, "critic_loss": 0.005310065753321396, "actor_loss": -8.715647788107395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.66285276412964, "step": 73000}
{"episode_reward": 8.496936459894329, "episode": 74.0, "batch_reward": 0.015380975674837828, "critic_loss": 0.0033000378793512936, "actor_loss": -9.239532704800368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.63967514038086, "step": 74000}
{"episode_reward": 8.272578658659116, "episode": 75.0, "batch_reward": 0.015646653609815986, "critic_loss": 0.0047812397840316405, "actor_loss": -9.03286424779892, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.31913733482361, "step": 75000}
{"episode_reward": 8.029110575812316, "episode": 76.0, "batch_reward": 0.015076133200898767, "critic_loss": 0.004112725880433573, "actor_loss": -9.44105488371849, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.68238878250122, "step": 76000}
{"episode_reward": 7.315584291133417, "episode": 77.0, "batch_reward": 0.014880157193168998, "critic_loss": 0.005426466241799062, "actor_loss": -7.9459769166708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.50313973426819, "step": 77000}
{"episode_reward": 11.472288660591534, "episode": 78.0, "batch_reward": 0.015198962676804513, "critic_loss": 0.004611417688836809, "actor_loss": -8.072178618609906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.386884450912476, "step": 78000}
{"episode_reward": 7.2703262674011055, "episode": 79.0, "batch_reward": 0.014875990406610072, "critic_loss": 0.003280235896847444, "actor_loss": -7.927925887465477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.070767402648926, "step": 79000}
{"episode_reward": 8.169870996134856, "episode": 80.0, "batch_reward": 0.014976023773662746, "critic_loss": 0.0044825479010178245, "actor_loss": -8.980287188977004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.581861972808838, "step": 80000}
{"episode_reward": 7.807819561101117, "episode": 81.0, "batch_reward": 0.014880844903178514, "critic_loss": 0.0032535169741895516, "actor_loss": -8.321184826999902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.58688998222351, "step": 81000}
{"episode_reward": 7.208766982904125, "episode": 82.0, "batch_reward": 0.014627452467102557, "critic_loss": 0.0032921858331537808, "actor_loss": -8.471883440077304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.199782133102417, "step": 82000}
{"episode_reward": 7.008551750421733, "episode": 83.0, "batch_reward": 0.014511147988028824, "critic_loss": 0.0037320200626854783, "actor_loss": -8.99153967192769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.538724184036255, "step": 83000}
{"episode_reward": 7.1927523411433905, "episode": 84.0, "batch_reward": 0.014190919786691666, "critic_loss": 0.003458156373060774, "actor_loss": -8.992681397169829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.194617748260498, "step": 84000}
{"episode_reward": 6.496106836010518, "episode": 85.0, "batch_reward": 0.014720908613409847, "critic_loss": 0.004207012711485731, "actor_loss": -7.855935348391533, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093381881713867, "step": 85000}
{"episode_reward": 4.985995054053279, "episode": 86.0, "batch_reward": 0.014358047031331807, "critic_loss": 0.0038412840552628042, "actor_loss": -9.208734778761864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.84536051750183, "step": 86000}
{"episode_reward": 9.504204922727386, "episode": 87.0, "batch_reward": 0.014619865782093257, "critic_loss": 0.003797438920766581, "actor_loss": -8.877960102796555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.406715393066406, "step": 87000}
{"episode_reward": 8.243483959299102, "episode": 88.0, "batch_reward": 0.014379270715638996, "critic_loss": 0.003455666738314903, "actor_loss": -8.872261113405228, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.029173135757446, "step": 88000}
{"episode_reward": 6.691062944019721, "episode": 89.0, "batch_reward": 0.014113353835884482, "critic_loss": 0.0034461079629545567, "actor_loss": -8.532712287843227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.752763986587524, "step": 89000}
{"episode_reward": 11.79156885512522, "episode": 90.0, "batch_reward": 0.013978366362396627, "critic_loss": 0.0034195696034876166, "actor_loss": -7.972366322219372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.547969341278076, "step": 90000}
{"episode_reward": 8.943101414626728, "episode": 91.0, "batch_reward": 0.014087110539898277, "critic_loss": 0.0040585863958112894, "actor_loss": -8.022237685650587, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.98819851875305, "step": 91000}
{"episode_reward": 10.216232982759418, "episode": 92.0, "batch_reward": 0.014072649492882193, "critic_loss": 0.0038194543239369523, "actor_loss": -8.679769501388073, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.0706889629364, "step": 92000}
{"episode_reward": 9.285002029306746, "episode": 93.0, "batch_reward": 0.014092466313391923, "critic_loss": 0.003988219035454677, "actor_loss": -8.55280372413993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.645918369293213, "step": 93000}
{"episode_reward": 9.731142149269333, "episode": 94.0, "batch_reward": 0.013750222348142415, "critic_loss": 0.0027915234050014987, "actor_loss": -8.660364659667016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.512080430984497, "step": 94000}
{"episode_reward": 8.690499983360272, "episode": 95.0, "batch_reward": 0.013736193182878196, "critic_loss": 0.0036115209314157254, "actor_loss": -7.176101691603661, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.89420771598816, "step": 95000}
{"episode_reward": 9.839284830507452, "episode": 96.0, "batch_reward": 0.013812599397730082, "critic_loss": 0.0025367414956563154, "actor_loss": -9.922426553457976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.80939793586731, "step": 96000}
{"episode_reward": 6.362512091346924, "episode": 97.0, "batch_reward": 0.013636033702641725, "critic_loss": 0.00396463504107669, "actor_loss": -8.928042714059353, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.06358551979065, "step": 97000}
{"episode_reward": 5.0454071931298605, "episode": 98.0, "batch_reward": 0.013531675052363426, "critic_loss": 0.003669111952680396, "actor_loss": -7.6584242836833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.726781368255615, "step": 98000}
{"episode_reward": 9.162818840187098, "episode": 99.0, "batch_reward": 0.013714502830989659, "critic_loss": 0.0038384877185162623, "actor_loss": -9.851670885518192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.17323112487793, "step": 99000}
{"episode_reward": 7.427601924535486, "episode": 100.0, "batch_reward": 0.01342771394457668, "critic_loss": 0.003838980579734198, "actor_loss": -9.024546626746654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.687053203582764, "step": 100000}
{"episode_reward": 8.48318975057316, "episode": 101.0, "batch_reward": 0.013376789272762835, "critic_loss": 0.0027799151075305418, "actor_loss": -9.560320973336697, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.72551465034485, "step": 101000}
{"episode_reward": 9.463680265433165, "episode": 102.0, "batch_reward": 0.013263053691014647, "critic_loss": 0.003179109226242872, "actor_loss": -8.93728700582683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.796403646469116, "step": 102000}
{"episode_reward": 6.180297755571498, "episode": 103.0, "batch_reward": 0.013459344638511539, "critic_loss": 0.0030589704570302273, "actor_loss": -8.739332508787513, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.711897373199463, "step": 103000}
{"episode_reward": 6.0487873044465, "episode": 104.0, "batch_reward": 0.013583690350409598, "critic_loss": 0.004166519297898049, "actor_loss": -9.068001059815288, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.91691565513611, "step": 104000}
{"episode_reward": 6.982166448373932, "episode": 105.0, "batch_reward": 0.013174003360792995, "critic_loss": 0.0035760247200378216, "actor_loss": -9.04466801609099, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.940332651138306, "step": 105000}
{"episode_reward": 7.744034640517447, "episode": 106.0, "batch_reward": 0.013314423178788275, "critic_loss": 0.0031227952848857966, "actor_loss": -9.720495469495654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.733778715133667, "step": 106000}
{"episode_reward": 10.911019276014876, "episode": 107.0, "batch_reward": 0.013160619782283903, "critic_loss": 0.002842781549290521, "actor_loss": -9.582366299971937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.982744455337524, "step": 107000}
{"episode_reward": 10.183724119517759, "episode": 108.0, "batch_reward": 0.0129072945388034, "critic_loss": 0.0027526935802015943, "actor_loss": -8.036198229402304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.994997262954712, "step": 108000}
{"episode_reward": 9.829953607207022, "episode": 109.0, "batch_reward": 0.013125189089216291, "critic_loss": 0.003924263532418991, "actor_loss": -9.099276069000364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.62426209449768, "step": 109000}
{"episode_reward": 8.295169085842451, "episode": 110.0, "batch_reward": 0.012907836915925145, "critic_loss": 0.004052683299945784, "actor_loss": -9.353374997630715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.378221035003662, "step": 110000}
{"episode_reward": 10.217697827071573, "episode": 111.0, "batch_reward": 0.01302129092020914, "critic_loss": 0.0024340305449586596, "actor_loss": -7.768236061051488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.93099045753479, "step": 111000}
{"episode_reward": 7.491469105737339, "episode": 112.0, "batch_reward": 0.013133430691435933, "critic_loss": 0.00281703547698271, "actor_loss": -9.792932394638658, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.043904066085815, "step": 112000}
{"episode_reward": 7.855147328172014, "episode": 113.0, "batch_reward": 0.012993924814742059, "critic_loss": 0.003035241255769506, "actor_loss": -8.972903480604291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.523663759231567, "step": 113000}
{"episode_reward": 7.508317957291304, "episode": 114.0, "batch_reward": 0.0130435012858361, "critic_loss": 0.0027976341738394695, "actor_loss": -9.129163763210178, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.51328730583191, "step": 114000}
{"episode_reward": 7.426813212091537, "episode": 115.0, "batch_reward": 0.01260640242230147, "critic_loss": 0.0023874386680399766, "actor_loss": -8.671471309408545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.651034355163574, "step": 115000}
{"episode_reward": 9.764629521292386, "episode": 116.0, "batch_reward": 0.012731719232629985, "critic_loss": 0.00374416383895732, "actor_loss": -8.280315724179149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.643646001815796, "step": 116000}
{"episode_reward": 10.770075010885904, "episode": 117.0, "batch_reward": 0.013160778179764748, "critic_loss": 0.0022303169131773757, "actor_loss": -7.479830936387181, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.531394958496094, "step": 117000}
{"episode_reward": 7.390392166578284, "episode": 118.0, "batch_reward": 0.012664035823196173, "critic_loss": 0.002701536007109098, "actor_loss": -8.113421383157373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.053982257843018, "step": 118000}
{"episode_reward": 8.871339913814117, "episode": 119.0, "batch_reward": 0.012670047416817397, "critic_loss": 0.002125187773926882, "actor_loss": -8.330282653808593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.32670283317566, "step": 119000}
{"episode_reward": 7.2925546518167605, "episode": 120.0, "batch_reward": 0.012665246623102576, "critic_loss": 0.0025763206521514804, "actor_loss": -7.449225888982415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.102240085601807, "step": 120000}
{"episode_reward": 10.3156812111789, "episode": 121.0, "batch_reward": 0.012661683981306852, "critic_loss": 0.002325309743726393, "actor_loss": -8.783424378484488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.3248336315155, "step": 121000}
{"episode_reward": 6.135593988081927, "episode": 122.0, "batch_reward": 0.012741021238733084, "critic_loss": 0.0025520567843923345, "actor_loss": -8.452457684591412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.265048503875732, "step": 122000}
{"episode_reward": 7.9861447871632505, "episode": 123.0, "batch_reward": 0.012336899109650403, "critic_loss": 0.002350207886454882, "actor_loss": -8.761914439976215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.58757781982422, "step": 123000}
{"episode_reward": 8.212998747569833, "episode": 124.0, "batch_reward": 0.012531205618288369, "critic_loss": 0.002406169873473118, "actor_loss": -9.08676358319819, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.885944843292236, "step": 124000}
{"episode_reward": 10.593786105456118, "episode": 125.0, "batch_reward": 0.01258139334572479, "critic_loss": 0.003205022279697005, "actor_loss": -8.598112904056906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.432467699050903, "step": 125000}
{"episode_reward": 8.574229230278654, "episode": 126.0, "batch_reward": 0.01259278186177835, "critic_loss": 0.0024174993677152086, "actor_loss": -7.948734300374984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.46548819541931, "step": 126000}
{"episode_reward": 8.073290364731854, "episode": 127.0, "batch_reward": 0.012412362136412412, "critic_loss": 0.0018916824160842224, "actor_loss": -9.246302918374539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.05133867263794, "step": 127000}
{"episode_reward": 7.411251103789497, "episode": 128.0, "batch_reward": 0.012013802086934448, "critic_loss": 0.0026498479730216787, "actor_loss": -9.292956316813827, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.867231130599976, "step": 128000}
{"episode_reward": 10.847059919665876, "episode": 129.0, "batch_reward": 0.012620049950666725, "critic_loss": 0.0028585738092951943, "actor_loss": -8.538313164755703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.249717235565186, "step": 129000}
{"episode_reward": 6.08449686530827, "episode": 130.0, "batch_reward": 0.01212079085316509, "critic_loss": 0.002015039694553707, "actor_loss": -8.514721321955323, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.233213186264038, "step": 130000}
{"episode_reward": 10.373384022464709, "episode": 131.0, "batch_reward": 0.012292019846849144, "critic_loss": 0.002653288109548157, "actor_loss": -8.162287367448211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.84320402145386, "step": 131000}
{"episode_reward": 8.360590570989443, "episode": 132.0, "batch_reward": 0.012275720768142491, "critic_loss": 0.002468334279139526, "actor_loss": -8.635517762228847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.349448442459106, "step": 132000}
{"episode_reward": 6.563056197446195, "episode": 133.0, "batch_reward": 0.012079593654721976, "critic_loss": 0.0023296718154742846, "actor_loss": -7.414217504605651, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.584354639053345, "step": 133000}
{"episode_reward": 7.380478336617393, "episode": 134.0, "batch_reward": 0.012337507380638272, "critic_loss": 0.0022244630231143675, "actor_loss": -7.822831738144159, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.28391194343567, "step": 134000}
{"episode_reward": 8.93646773766219, "episode": 135.0, "batch_reward": 0.012171023920178414, "critic_loss": 0.00217900503531564, "actor_loss": -9.006138166844845, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082285404205322, "step": 135000}
{"episode_reward": 10.648556847464588, "episode": 136.0, "batch_reward": 0.012097522458527236, "critic_loss": 0.0017443691231164848, "actor_loss": -7.189152227073908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.266860723495483, "step": 136000}
{"episode_reward": 8.532095150025121, "episode": 137.0, "batch_reward": 0.012100742307025939, "critic_loss": 0.003332390257593943, "actor_loss": -8.677025466561318, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.6553738117218, "step": 137000}
{"episode_reward": 7.124560111742188, "episode": 138.0, "batch_reward": 0.012095975083764643, "critic_loss": 0.0018614436855423264, "actor_loss": -9.167075637489557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20794701576233, "step": 138000}
{"episode_reward": 8.225802663400152, "episode": 139.0, "batch_reward": 0.01199286054354161, "critic_loss": 0.0019004901323933154, "actor_loss": -7.954617352917791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.282330751419067, "step": 139000}
{"episode_reward": 7.21924873814938, "episode": 140.0, "batch_reward": 0.011970656594727189, "critic_loss": 0.002711981300759362, "actor_loss": -8.562269193962216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.401127815246582, "step": 140000}
{"episode_reward": 8.137667266309338, "episode": 141.0, "batch_reward": 0.012204284838866443, "critic_loss": 0.001945960103359539, "actor_loss": -9.004850486338139, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.388835191726685, "step": 141000}
{"episode_reward": 9.300726694315108, "episode": 142.0, "batch_reward": 0.012034416464157403, "critic_loss": 0.0024186348055372947, "actor_loss": -7.902556446656584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.47956132888794, "step": 142000}
{"episode_reward": 7.20536548409746, "episode": 143.0, "batch_reward": 0.01219597354438156, "critic_loss": 0.001848927887083846, "actor_loss": -7.635753765791654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.67426371574402, "step": 143000}
{"episode_reward": 10.446832332873754, "episode": 144.0, "batch_reward": 0.011770268606022, "critic_loss": 0.002985770011873683, "actor_loss": -8.446446449369192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.758883476257324, "step": 144000}
{"episode_reward": 11.728162127040301, "episode": 145.0, "batch_reward": 0.011865367795806377, "critic_loss": 0.0019473924825870199, "actor_loss": -8.822076815709472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.497146368026733, "step": 145000}
{"episode_reward": 11.970965939415166, "episode": 146.0, "batch_reward": 0.0120100582735613, "critic_loss": 0.0017264347633026774, "actor_loss": -9.276241130694746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.937454223632812, "step": 146000}
{"episode_reward": 7.083708350989681, "episode": 147.0, "batch_reward": 0.011838216323871166, "critic_loss": 0.0028199343896558276, "actor_loss": -8.38914872057736, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.034379243850708, "step": 147000}
{"episode_reward": 9.988054337741543, "episode": 148.0, "batch_reward": 0.011923474991694093, "critic_loss": 0.0021953245926706584, "actor_loss": -8.552640874877572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.32769536972046, "step": 148000}
{"episode_reward": 7.654654850098393, "episode": 149.0, "batch_reward": 0.011883898766245692, "critic_loss": 0.002156603557858034, "actor_loss": -8.324851264238358, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.821470022201538, "step": 149000}
{"episode_reward": 7.430729134444327, "episode": 150.0, "batch_reward": 0.012267046056222171, "critic_loss": 0.0020112213543470718, "actor_loss": -8.396426181718708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
