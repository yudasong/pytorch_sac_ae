{"episode_reward": 0.0, "episode": 1.0, "duration": 19.178236722946167, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.537231206893921, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.24983862343034016, "critic_loss": 0.035237702718529405, "actor_loss": -13.737962865304215, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 67.5644154548645, "step": 3000}
{"episode_reward": 22.383802833393197, "episode": 4.0, "batch_reward": 0.1693618539571762, "critic_loss": 0.026403588274493815, "actor_loss": -10.462856291294099, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.83149003982544, "step": 4000}
{"episode_reward": 49.82353352386273, "episode": 5.0, "batch_reward": 0.14120122069120408, "critic_loss": 0.031493010248988866, "actor_loss": -11.019785987615585, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.720913410186768, "step": 5000}
{"episode_reward": 68.70100284568117, "episode": 6.0, "batch_reward": 0.12551562988758086, "critic_loss": 0.031834663073532284, "actor_loss": -9.577637983322143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.036816596984863, "step": 6000}
{"episode_reward": 23.95573730152776, "episode": 7.0, "batch_reward": 0.1151025716252625, "critic_loss": 0.033444141522981224, "actor_loss": -9.190313561439513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.146106719970703, "step": 7000}
{"episode_reward": 63.220269388406855, "episode": 8.0, "batch_reward": 0.10888535162061452, "critic_loss": 0.05326534139085561, "actor_loss": -9.778811912775039, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.63960289955139, "step": 8000}
{"episode_reward": 90.02423436773496, "episode": 9.0, "batch_reward": 0.10529697381705046, "critic_loss": 0.05747996039874852, "actor_loss": -9.53135435962677, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.480401277542114, "step": 9000}
{"episode_reward": 107.63736205744085, "episode": 10.0, "batch_reward": 0.1065493450500071, "critic_loss": 0.07301131628267467, "actor_loss": -10.469965034484863, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.488998413085938, "step": 10000}
{"episode_reward": 87.33449472349905, "episode": 11.0, "batch_reward": 0.10689441549777985, "critic_loss": 0.11452903153747321, "actor_loss": -9.82637984418869, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.81894588470459, "step": 11000}
{"episode_reward": 136.26092217253213, "episode": 12.0, "batch_reward": 0.10705972775071859, "critic_loss": 0.10488353556022048, "actor_loss": -11.100727082252503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.515904903411865, "step": 12000}
{"episode_reward": 66.5749316849693, "episode": 13.0, "batch_reward": 0.102952692091465, "critic_loss": 0.10264443101361394, "actor_loss": -10.2288550157547, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.566869497299194, "step": 13000}
{"episode_reward": 54.568179269836016, "episode": 14.0, "batch_reward": 0.09689403331652284, "critic_loss": 0.09770451636239887, "actor_loss": -10.312652866363525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.600056886672974, "step": 14000}
{"episode_reward": 18.930505902894087, "episode": 15.0, "batch_reward": 0.09277149270102382, "critic_loss": 0.09938816949352622, "actor_loss": -9.720874318122863, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.441195487976074, "step": 15000}
{"episode_reward": 27.630198043317154, "episode": 16.0, "batch_reward": 0.089920907497406, "critic_loss": 0.10488550658151508, "actor_loss": -10.532229307174683, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.030943155288696, "step": 16000}
{"episode_reward": 73.19774657743608, "episode": 17.0, "batch_reward": 0.0904747351333499, "critic_loss": 0.10512864238023759, "actor_loss": -10.62486696624756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.690927028656006, "step": 17000}
{"episode_reward": 109.47083965035489, "episode": 18.0, "batch_reward": 0.09356842393428087, "critic_loss": 0.11465216329693795, "actor_loss": -10.744693260192872, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.92198395729065, "step": 18000}
{"episode_reward": 232.07552887252328, "episode": 19.0, "batch_reward": 0.10137828453630209, "critic_loss": 0.13259125846251846, "actor_loss": -11.48889568901062, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.622867107391357, "step": 19000}
{"episode_reward": 191.4477904687435, "episode": 20.0, "batch_reward": 0.10467612974345684, "critic_loss": 0.13878648941591382, "actor_loss": -11.28990504360199, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.191198587417603, "step": 20000}
{"episode_reward": 114.4161581272081, "episode": 21.0, "batch_reward": 0.1030782501026988, "critic_loss": 0.15626693131029606, "actor_loss": -11.48580854034424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.68469214439392, "step": 21000}
{"episode_reward": 88.60122983065233, "episode": 22.0, "batch_reward": 0.105078105263412, "critic_loss": 0.19715005002915859, "actor_loss": -11.41417208480835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.009945154190063, "step": 22000}
{"episode_reward": 137.3118729486165, "episode": 23.0, "batch_reward": 0.10715932165831328, "critic_loss": 0.18835925878584384, "actor_loss": -11.958861313819884, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.727162837982178, "step": 23000}
{"episode_reward": 247.5795700918881, "episode": 24.0, "batch_reward": 0.11472389374673367, "critic_loss": 0.22581568329781293, "actor_loss": -12.478895254135132, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.963483810424805, "step": 24000}
{"episode_reward": 333.74623847379513, "episode": 25.0, "batch_reward": 0.11836620627343655, "critic_loss": 0.20761631248146295, "actor_loss": -13.012191381454468, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.077252864837646, "step": 25000}
{"episode_reward": 49.02132176693753, "episode": 26.0, "batch_reward": 0.12149258970469236, "critic_loss": 0.21394060243666171, "actor_loss": -13.228166822433472, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.91208004951477, "step": 26000}
{"episode_reward": 364.56768653895955, "episode": 27.0, "batch_reward": 0.12776761361956596, "critic_loss": 0.20203258980065583, "actor_loss": -13.770396339416504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.819125413894653, "step": 27000}
{"episode_reward": 216.1988663600263, "episode": 28.0, "batch_reward": 0.1281048387810588, "critic_loss": 0.2213084125444293, "actor_loss": -14.167860349655152, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.07138967514038, "step": 28000}
{"episode_reward": 57.66858289805412, "episode": 29.0, "batch_reward": 0.12655051036924123, "critic_loss": 0.21316090369969606, "actor_loss": -13.719909952163697, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.895753145217896, "step": 29000}
{"episode_reward": 74.12512401559098, "episode": 30.0, "batch_reward": 0.12756299044191838, "critic_loss": 0.23800910384207963, "actor_loss": -14.299130683898925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.226905345916748, "step": 30000}
{"episode_reward": 260.74183563746254, "episode": 31.0, "batch_reward": 0.13070408163964747, "critic_loss": 0.2529562283605337, "actor_loss": -14.639266174316406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.19842982292175, "step": 31000}
{"episode_reward": 137.97139020371432, "episode": 32.0, "batch_reward": 0.13158339320868254, "critic_loss": 0.2633697511255741, "actor_loss": -14.513912693023682, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.036468267440796, "step": 32000}
{"episode_reward": 160.89103180017162, "episode": 33.0, "batch_reward": 0.13069305094331504, "critic_loss": 0.26774567022174595, "actor_loss": -14.368578689575195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.121052503585815, "step": 33000}
{"episode_reward": 50.94606979229318, "episode": 34.0, "batch_reward": 0.13034542541205882, "critic_loss": 0.3011837781071663, "actor_loss": -14.545835111618041, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.68660855293274, "step": 34000}
{"episode_reward": 296.28601666843304, "episode": 35.0, "batch_reward": 0.13522543511539697, "critic_loss": 0.30799532936513424, "actor_loss": -14.902516101837158, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.003382444381714, "step": 35000}
{"episode_reward": 166.58456254076395, "episode": 36.0, "batch_reward": 0.13524315466731787, "critic_loss": 0.3036328881457448, "actor_loss": -15.080009437561035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.744990587234497, "step": 36000}
{"episode_reward": 132.27041650730237, "episode": 37.0, "batch_reward": 0.13612436012923718, "critic_loss": 0.31568405275046824, "actor_loss": -15.390480968475341, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.628943920135498, "step": 37000}
{"episode_reward": 241.37150203424468, "episode": 38.0, "batch_reward": 0.14033035112172365, "critic_loss": 0.32457708674669267, "actor_loss": -15.599431518554688, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.131062269210815, "step": 38000}
{"episode_reward": 241.36149889555918, "episode": 39.0, "batch_reward": 0.142176607593894, "critic_loss": 0.329474472746253, "actor_loss": -16.02706463432312, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.619920015335083, "step": 39000}
{"episode_reward": 285.70416104719396, "episode": 40.0, "batch_reward": 0.14277524542808534, "critic_loss": 0.3524941177815199, "actor_loss": -16.408782955169677, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.961198568344116, "step": 40000}
{"episode_reward": 94.45770629670339, "episode": 41.0, "batch_reward": 0.14408048848062754, "critic_loss": 0.3640848808288574, "actor_loss": -16.670031185150147, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.110339641571045, "step": 41000}
{"episode_reward": 274.89092835954824, "episode": 42.0, "batch_reward": 0.14640553564578296, "critic_loss": 0.36427134403586386, "actor_loss": -16.904646074295044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.517682552337646, "step": 42000}
{"episode_reward": 225.2411287945118, "episode": 43.0, "batch_reward": 0.14996258582919836, "critic_loss": 0.4025860290825367, "actor_loss": -17.31745657157898, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.187485694885254, "step": 43000}
{"episode_reward": 338.8709818391944, "episode": 44.0, "batch_reward": 0.15489307007193565, "critic_loss": 0.4099345761835575, "actor_loss": -17.774209476470947, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.64345359802246, "step": 44000}
{"episode_reward": 402.50345426784304, "episode": 45.0, "batch_reward": 0.15941215574741363, "critic_loss": 0.46355564932525156, "actor_loss": -18.059698921203612, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.828539848327637, "step": 45000}
{"episode_reward": 222.20467941678217, "episode": 46.0, "batch_reward": 0.16057008614391088, "critic_loss": 0.44373132711648944, "actor_loss": -18.27375975036621, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.860090494155884, "step": 46000}
{"episode_reward": 280.1048840919267, "episode": 47.0, "batch_reward": 0.1629983339458704, "critic_loss": 0.45282181972265245, "actor_loss": -18.751877182006837, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.708653688430786, "step": 47000}
{"episode_reward": 226.11225010807, "episode": 48.0, "batch_reward": 0.16543321867287158, "critic_loss": 0.4309941067844629, "actor_loss": -18.87127516555786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.631523609161377, "step": 48000}
{"episode_reward": 361.89128716576084, "episode": 49.0, "batch_reward": 0.1699435377046466, "critic_loss": 0.455052635088563, "actor_loss": -19.41145282173157, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.118487119674683, "step": 49000}
{"episode_reward": 311.0527653287094, "episode": 50.0, "batch_reward": 0.17190472944080828, "critic_loss": 0.44092499777674676, "actor_loss": -19.941028587341307, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.010850191116333, "step": 50000}
{"episode_reward": 239.88600309384182, "episode": 51.0, "batch_reward": 0.17418655810505151, "critic_loss": 0.46011083959043025, "actor_loss": -19.968976167678832, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.285505294799805, "step": 51000}
{"episode_reward": 271.1259959371993, "episode": 52.0, "batch_reward": 0.1743077429831028, "critic_loss": 0.454172997713089, "actor_loss": -20.371744287490845, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.73677659034729, "step": 52000}
{"episode_reward": 162.88585280769777, "episode": 53.0, "batch_reward": 0.17367144738137721, "critic_loss": 0.4553268928080797, "actor_loss": -20.197029300689696, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.767776012420654, "step": 53000}
{"episode_reward": 100.3155094111969, "episode": 54.0, "batch_reward": 0.17352672815322875, "critic_loss": 0.44043056707084177, "actor_loss": -20.252412015914917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.399181842803955, "step": 54000}
{"episode_reward": 173.99884556205984, "episode": 55.0, "batch_reward": 0.17280087152123452, "critic_loss": 0.4372553918659687, "actor_loss": -20.33878771209717, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.486979246139526, "step": 55000}
{"episode_reward": 169.89115145086956, "episode": 56.0, "batch_reward": 0.17354353238642214, "critic_loss": 0.40387975999712944, "actor_loss": -20.413885276794435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.744422912597656, "step": 56000}
{"episode_reward": 351.9601872678758, "episode": 57.0, "batch_reward": 0.17615739496052266, "critic_loss": 0.41126182033121583, "actor_loss": -20.685388860702513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.023144006729126, "step": 57000}
{"episode_reward": 125.11157560012221, "episode": 58.0, "batch_reward": 0.17542723467946053, "critic_loss": 0.40035493597388266, "actor_loss": -20.65618752670288, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.812242031097412, "step": 58000}
{"episode_reward": 366.77481577694016, "episode": 59.0, "batch_reward": 0.17885398972034455, "critic_loss": 0.3783850182890892, "actor_loss": -21.01338219833374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.05555510520935, "step": 59000}
{"episode_reward": 322.1855650142934, "episode": 60.0, "batch_reward": 0.1813963203728199, "critic_loss": 0.4018714531213045, "actor_loss": -21.44691891860962, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.156389951705933, "step": 60000}
{"episode_reward": 345.6108937837345, "episode": 61.0, "batch_reward": 0.18396193322539328, "critic_loss": 0.3809086060672998, "actor_loss": -21.63085515975952, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.02790570259094, "step": 61000}
{"episode_reward": 330.02333133929267, "episode": 62.0, "batch_reward": 0.18570112562179567, "critic_loss": 0.39504829204082487, "actor_loss": -21.505174034118653, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.034751653671265, "step": 62000}
{"episode_reward": 232.63609590794988, "episode": 63.0, "batch_reward": 0.1874875092357397, "critic_loss": 0.376238728120923, "actor_loss": -21.690543491363524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.933796167373657, "step": 63000}
{"episode_reward": 459.74374928924044, "episode": 64.0, "batch_reward": 0.19211830808222294, "critic_loss": 0.3642966827303171, "actor_loss": -22.186804290771484, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.943607091903687, "step": 64000}
{"episode_reward": 160.8575848337736, "episode": 65.0, "batch_reward": 0.1911223607957363, "critic_loss": 0.3706965956091881, "actor_loss": -21.893571964263916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.760973930358887, "step": 65000}
{"episode_reward": 383.63531580195547, "episode": 66.0, "batch_reward": 0.19309265446662902, "critic_loss": 0.3758697270005941, "actor_loss": -22.124956230163573, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.21339750289917, "step": 66000}
{"episode_reward": 195.96814092883906, "episode": 67.0, "batch_reward": 0.19360107484459876, "critic_loss": 0.3889029082506895, "actor_loss": -21.997239974975585, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.15336322784424, "step": 67000}
{"episode_reward": 215.52075890399658, "episode": 68.0, "batch_reward": 0.1953763151317835, "critic_loss": 0.37007221138477325, "actor_loss": -22.202252170562744, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.395673990249634, "step": 68000}
{"episode_reward": 427.9272142520732, "episode": 69.0, "batch_reward": 0.1989035015553236, "critic_loss": 0.3925504926890135, "actor_loss": -22.434474979400633, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.650996685028076, "step": 69000}
{"episode_reward": 456.73952564295223, "episode": 70.0, "batch_reward": 0.2021166658550501, "critic_loss": 0.4035515159368515, "actor_loss": -22.735288238525392, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.048607349395752, "step": 70000}
{"episode_reward": 356.67591906642826, "episode": 71.0, "batch_reward": 0.20356446032226086, "critic_loss": 0.3852413880378008, "actor_loss": -22.77175164794922, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.08968710899353, "step": 71000}
{"episode_reward": 425.47536105598573, "episode": 72.0, "batch_reward": 0.20677237536013127, "critic_loss": 0.3901496623456478, "actor_loss": -23.054744674682617, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.410672664642334, "step": 72000}
{"episode_reward": 366.07603067725313, "episode": 73.0, "batch_reward": 0.20928179541230202, "critic_loss": 0.3947475140690804, "actor_loss": -23.271426013946535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.589160203933716, "step": 73000}
{"episode_reward": 290.7536541861717, "episode": 74.0, "batch_reward": 0.21115344807505607, "critic_loss": 0.37352092742919923, "actor_loss": -23.40696876525879, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.199023008346558, "step": 74000}
{"episode_reward": 478.30491045020347, "episode": 75.0, "batch_reward": 0.2136729176491499, "critic_loss": 0.40299593648314475, "actor_loss": -23.475703399658205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.708658695220947, "step": 75000}
{"episode_reward": 292.64441461689785, "episode": 76.0, "batch_reward": 0.21425129245221614, "critic_loss": 0.3678094892650843, "actor_loss": -23.594783462524415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.12525725364685, "step": 76000}
{"episode_reward": 258.0181412047238, "episode": 77.0, "batch_reward": 0.21500949989259244, "critic_loss": 0.396115643799305, "actor_loss": -23.484546844482423, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.608604907989502, "step": 77000}
{"episode_reward": 156.383189769777, "episode": 78.0, "batch_reward": 0.2152377034276724, "critic_loss": 0.4050104345977306, "actor_loss": -23.47295337677002, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.460921049118042, "step": 78000}
{"episode_reward": 449.2826206378774, "episode": 79.0, "batch_reward": 0.21644896283745765, "critic_loss": 0.38269337491691113, "actor_loss": -23.616616481781005, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.665543794631958, "step": 79000}
{"episode_reward": 92.12270394396262, "episode": 80.0, "batch_reward": 0.21649962508678436, "critic_loss": 0.394026319116354, "actor_loss": -23.758678619384767, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.915462732315063, "step": 80000}
{"episode_reward": 367.09899393524154, "episode": 81.0, "batch_reward": 0.21872673735022544, "critic_loss": 0.3842188875377178, "actor_loss": -23.943986808776856, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.76578092575073, "step": 81000}
{"episode_reward": 485.0940935345771, "episode": 82.0, "batch_reward": 0.2216841841340065, "critic_loss": 0.3965096798092127, "actor_loss": -24.159630542755128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.716336727142334, "step": 82000}
{"episode_reward": 489.18259248649366, "episode": 83.0, "batch_reward": 0.2235775814950466, "critic_loss": 0.38820943573117256, "actor_loss": -24.36215858078003, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.856520891189575, "step": 83000}
{"episode_reward": 203.28014211242782, "episode": 84.0, "batch_reward": 0.2238869047164917, "critic_loss": 0.39486508414149285, "actor_loss": -24.293435997009276, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.519674062728882, "step": 84000}
{"episode_reward": 332.8110976650049, "episode": 85.0, "batch_reward": 0.22588355730473994, "critic_loss": 0.38697625462710855, "actor_loss": -24.401558498382567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.535999298095703, "step": 85000}
{"episode_reward": 523.2704646186737, "episode": 86.0, "batch_reward": 0.23027618899941443, "critic_loss": 0.40263940177857876, "actor_loss": -24.916999229431152, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.210347652435303, "step": 86000}
{"episode_reward": 481.2626246697476, "episode": 87.0, "batch_reward": 0.23262986782193185, "critic_loss": 0.4071532476842403, "actor_loss": -25.12643254852295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.254161834716797, "step": 87000}
{"episode_reward": 393.1471791101583, "episode": 88.0, "batch_reward": 0.23533046713471412, "critic_loss": 0.4260852705091238, "actor_loss": -25.30563666152954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.067413330078125, "step": 88000}
{"episode_reward": 418.1448332315436, "episode": 89.0, "batch_reward": 0.23521680927276611, "critic_loss": 0.40639102503657343, "actor_loss": -25.279011783599852, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.227144956588745, "step": 89000}
{"episode_reward": 199.46226027173472, "episode": 90.0, "batch_reward": 0.23412942883372306, "critic_loss": 0.40651343017816544, "actor_loss": -24.856361827850343, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.327523708343506, "step": 90000}
{"episode_reward": 128.03483538495828, "episode": 91.0, "batch_reward": 0.23386310210824013, "critic_loss": 0.4186164700686932, "actor_loss": -24.770390811920166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.07136678695679, "step": 91000}
{"episode_reward": 375.39554834943897, "episode": 92.0, "batch_reward": 0.23674279002845286, "critic_loss": 0.40072267089784147, "actor_loss": -25.26152416610718, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.11278247833252, "step": 92000}
{"episode_reward": 385.02232186274915, "episode": 93.0, "batch_reward": 0.2374631703197956, "critic_loss": 0.4171794048398733, "actor_loss": -25.285193592071533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.881972551345825, "step": 93000}
{"episode_reward": 340.9778229052561, "episode": 94.0, "batch_reward": 0.23870733027160168, "critic_loss": 0.43439253966510294, "actor_loss": -25.377172142028808, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.562129497528076, "step": 94000}
{"episode_reward": 226.53291417635194, "episode": 95.0, "batch_reward": 0.23894771093130113, "critic_loss": 0.394468813598156, "actor_loss": -25.050994735717772, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.603440046310425, "step": 95000}
{"episode_reward": 473.35837619159395, "episode": 96.0, "batch_reward": 0.24228901939094066, "critic_loss": 0.44531597684323787, "actor_loss": -25.76050456237793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.65737009048462, "step": 96000}
{"episode_reward": 533.9587678301867, "episode": 97.0, "batch_reward": 0.24402038855850697, "critic_loss": 0.4217041987776756, "actor_loss": -25.679333408355713, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.0834002494812, "step": 97000}
{"episode_reward": 518.2852921718352, "episode": 98.0, "batch_reward": 0.24656482444703579, "critic_loss": 0.421405472099781, "actor_loss": -25.778863048553468, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.268895387649536, "step": 98000}
{"episode_reward": 443.24228449034797, "episode": 99.0, "batch_reward": 0.2488321418464184, "critic_loss": 0.4255119915902615, "actor_loss": -26.280422523498537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27610182762146, "step": 99000}
{"episode_reward": 435.5846695971163, "episode": 100.0, "batch_reward": 0.2484357232451439, "critic_loss": 0.43282183979451655, "actor_loss": -26.110059516906738, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.18382239341736, "step": 100000}
{"episode_reward": 82.88816743401449, "episode": 101.0, "batch_reward": 0.2489696672707796, "critic_loss": 0.43124745415151117, "actor_loss": -26.197829929351805, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.79483509063721, "step": 101000}
{"episode_reward": 483.09844903155357, "episode": 102.0, "batch_reward": 0.25291555777192115, "critic_loss": 0.4167712205499411, "actor_loss": -26.476041160583495, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.823065996170044, "step": 102000}
{"episode_reward": 571.6372944214996, "episode": 103.0, "batch_reward": 0.2545924635976553, "critic_loss": 0.4130171019285917, "actor_loss": -26.473872047424315, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.86797523498535, "step": 103000}
{"episode_reward": 483.7259087110455, "episode": 104.0, "batch_reward": 0.25628943437337875, "critic_loss": 0.4215371875315905, "actor_loss": -26.699779861450196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.95703887939453, "step": 104000}
{"episode_reward": 247.99920559682542, "episode": 105.0, "batch_reward": 0.2570581488311291, "critic_loss": 0.42733807949721814, "actor_loss": -26.80567190170288, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.212812900543213, "step": 105000}
{"episode_reward": 317.8288991619551, "episode": 106.0, "batch_reward": 0.2568701079338789, "critic_loss": 0.43919648715853693, "actor_loss": -26.931425052642822, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.57596731185913, "step": 106000}
{"episode_reward": 502.5340784941646, "episode": 107.0, "batch_reward": 0.25965233641862867, "critic_loss": 0.4199145346879959, "actor_loss": -27.016228847503662, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.977720260620117, "step": 107000}
{"episode_reward": 422.5021700512469, "episode": 108.0, "batch_reward": 0.2581982349455357, "critic_loss": 0.44633323304355144, "actor_loss": -26.66705849838257, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.804547548294067, "step": 108000}
{"episode_reward": 57.28199004075665, "episode": 109.0, "batch_reward": 0.25882462538778783, "critic_loss": 0.46502512773871424, "actor_loss": -26.933565742492675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.853524446487427, "step": 109000}
{"episode_reward": 405.75308854111086, "episode": 110.0, "batch_reward": 0.26041060923039916, "critic_loss": 0.4445517545640469, "actor_loss": -27.107200603485108, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.038216590881348, "step": 110000}
{"episode_reward": 461.1177946985193, "episode": 111.0, "batch_reward": 0.2618038121163845, "critic_loss": 0.4562309187054634, "actor_loss": -26.91473611831665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.08793544769287, "step": 111000}
{"episode_reward": 434.16638361694413, "episode": 112.0, "batch_reward": 0.2640750116556883, "critic_loss": 0.45949041083455083, "actor_loss": -27.374085151672364, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.523210525512695, "step": 112000}
{"episode_reward": 553.748660057627, "episode": 113.0, "batch_reward": 0.2675827656835318, "critic_loss": 0.47441557462513445, "actor_loss": -27.469143795013427, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.41816473007202, "step": 113000}
{"episode_reward": 557.4773568664506, "episode": 114.0, "batch_reward": 0.268860132932663, "critic_loss": 0.44709119230508804, "actor_loss": -27.764775314331054, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.028021574020386, "step": 114000}
{"episode_reward": 513.5813615845873, "episode": 115.0, "batch_reward": 0.2710276489108801, "critic_loss": 0.48714992313086986, "actor_loss": -27.891981418609618, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.45470690727234, "step": 115000}
{"episode_reward": 491.6840455787256, "episode": 116.0, "batch_reward": 0.2742925786525011, "critic_loss": 0.5427865379452705, "actor_loss": -28.02646115875244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.697838068008423, "step": 116000}
{"episode_reward": 573.8624813980679, "episode": 117.0, "batch_reward": 0.27498077358305456, "critic_loss": 0.5294982163608074, "actor_loss": -28.060128845214845, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.73724937438965, "step": 117000}
{"episode_reward": 264.801386729678, "episode": 118.0, "batch_reward": 0.27615494452416894, "critic_loss": 0.4954461002498865, "actor_loss": -28.401078556060792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.150618314743042, "step": 118000}
{"episode_reward": 548.2112792753833, "episode": 119.0, "batch_reward": 0.2776851768642664, "critic_loss": 0.5162786886245012, "actor_loss": -28.472142032623292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.103452920913696, "step": 119000}
{"episode_reward": 227.28420638148978, "episode": 120.0, "batch_reward": 0.27739924654364584, "critic_loss": 0.5381127647310495, "actor_loss": -28.395219749450682, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.366235494613647, "step": 120000}
{"episode_reward": 579.770701126072, "episode": 121.0, "batch_reward": 0.27996090023219583, "critic_loss": 0.5348364125043154, "actor_loss": -28.692037910461426, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.14517068862915, "step": 121000}
{"episode_reward": 461.8360841809484, "episode": 122.0, "batch_reward": 0.28252303165197373, "critic_loss": 0.5301139621138573, "actor_loss": -28.938967842102052, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.405282020568848, "step": 122000}
{"episode_reward": 555.3616171235684, "episode": 123.0, "batch_reward": 0.28332794313132764, "critic_loss": 0.5283803919404745, "actor_loss": -29.07357234954834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.485464096069336, "step": 123000}
{"episode_reward": 513.1017823823365, "episode": 124.0, "batch_reward": 0.2847535775005817, "critic_loss": 0.5324594381451607, "actor_loss": -29.269452270507813, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.291849851608276, "step": 124000}
{"episode_reward": 533.5580871676744, "episode": 125.0, "batch_reward": 0.28846492002904417, "critic_loss": 0.5153907573819161, "actor_loss": -29.514153350830078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.544947147369385, "step": 125000}
{"episode_reward": 608.8558456140387, "episode": 126.0, "batch_reward": 0.2899099219292402, "critic_loss": 0.5560108074247837, "actor_loss": -29.640735481262208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.580894231796265, "step": 126000}
{"episode_reward": 475.2181147235739, "episode": 127.0, "batch_reward": 0.2903931593745947, "critic_loss": 0.5448874617218972, "actor_loss": -29.93625873184204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.063530921936035, "step": 127000}
{"episode_reward": 557.0861946981947, "episode": 128.0, "batch_reward": 0.2939333612024784, "critic_loss": 0.5142149665951729, "actor_loss": -30.310398860931397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.85038709640503, "step": 128000}
{"episode_reward": 551.2481506487335, "episode": 129.0, "batch_reward": 0.2955465769022703, "critic_loss": 0.5185744175314904, "actor_loss": -30.377426498413087, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.39911985397339, "step": 129000}
{"episode_reward": 586.253547134804, "episode": 130.0, "batch_reward": 0.2989243262708187, "critic_loss": 0.5480778126418591, "actor_loss": -30.512889450073242, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.62235689163208, "step": 130000}
{"episode_reward": 555.5268712612872, "episode": 131.0, "batch_reward": 0.3004494964033365, "critic_loss": 0.5229600367695093, "actor_loss": -30.551855083465576, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.20709276199341, "step": 131000}
{"episode_reward": 353.08520755562324, "episode": 132.0, "batch_reward": 0.29973712345957754, "critic_loss": 0.5651536922454834, "actor_loss": -30.640514392852783, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.295669078826904, "step": 132000}
{"episode_reward": 535.9336782576206, "episode": 133.0, "batch_reward": 0.3012819191068411, "critic_loss": 0.5389874362498521, "actor_loss": -30.480411735534666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.68760108947754, "step": 133000}
{"episode_reward": 217.4826705474963, "episode": 134.0, "batch_reward": 0.3019202659726143, "critic_loss": 0.5522466250061989, "actor_loss": -30.62113137435913, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.90249228477478, "step": 134000}
{"episode_reward": 524.9923146668682, "episode": 135.0, "batch_reward": 0.30340091496706006, "critic_loss": 0.4943481304049492, "actor_loss": -31.00406883239746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.794883966445923, "step": 135000}
{"episode_reward": 605.8455969546364, "episode": 136.0, "batch_reward": 0.30578049780428407, "critic_loss": 0.5244199597984552, "actor_loss": -30.817843605041503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.81290102005005, "step": 136000}
{"episode_reward": 664.4447702215023, "episode": 137.0, "batch_reward": 0.3076261455863714, "critic_loss": 0.5673594739437103, "actor_loss": -31.411810520172118, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.89970827102661, "step": 137000}
{"episode_reward": 580.0604370101279, "episode": 138.0, "batch_reward": 0.3112984044551849, "critic_loss": 0.5244039016962051, "actor_loss": -31.72684382247925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.820402145385742, "step": 138000}
{"episode_reward": 619.4550857739767, "episode": 139.0, "batch_reward": 0.3131080984771252, "critic_loss": 0.5273990144878626, "actor_loss": -31.604449745178222, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.119177103042603, "step": 139000}
{"episode_reward": 641.5809508507919, "episode": 140.0, "batch_reward": 0.3160894216895103, "critic_loss": 0.5550098505467177, "actor_loss": -32.017350658416746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.613778114318848, "step": 140000}
{"episode_reward": 604.2116799681688, "episode": 141.0, "batch_reward": 0.3168535161316395, "critic_loss": 0.5190752435475587, "actor_loss": -32.2322721748352, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.182846784591675, "step": 141000}
{"episode_reward": 597.6090807063487, "episode": 142.0, "batch_reward": 0.31710854402184485, "critic_loss": 0.5345384040176868, "actor_loss": -32.0931364364624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.826592206954956, "step": 142000}
{"episode_reward": 569.8941519802221, "episode": 143.0, "batch_reward": 0.3198559680879116, "critic_loss": 0.5348498689085245, "actor_loss": -32.3564977645874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.20270013809204, "step": 143000}
{"episode_reward": 196.0242391885763, "episode": 144.0, "batch_reward": 0.3202643555104733, "critic_loss": 0.531714610606432, "actor_loss": -32.38737485504151, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.06007480621338, "step": 144000}
{"episode_reward": 588.5842220273022, "episode": 145.0, "batch_reward": 0.3236163708269596, "critic_loss": 0.5723358425050974, "actor_loss": -32.834192218780515, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.24013113975525, "step": 145000}
{"episode_reward": 647.5679304443718, "episode": 146.0, "batch_reward": 0.3234379066228867, "critic_loss": 0.5255326521843672, "actor_loss": -32.85602936553955, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.607661724090576, "step": 146000}
{"episode_reward": 616.2579964668222, "episode": 147.0, "batch_reward": 0.32548910000920295, "critic_loss": 0.5788253380358219, "actor_loss": -32.946244888305664, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.93595266342163, "step": 147000}
{"episode_reward": 552.481570820449, "episode": 148.0, "batch_reward": 0.3276700050532818, "critic_loss": 0.5738578468561173, "actor_loss": -33.12729955291748, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.273747444152832, "step": 148000}
{"episode_reward": 591.7810192456185, "episode": 149.0, "batch_reward": 0.32958542203903196, "critic_loss": 0.5285507398992777, "actor_loss": -33.2645267829895, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.729920625686646, "step": 149000}
{"episode_reward": 598.834807795447, "episode": 150.0, "batch_reward": 0.33152871334552764, "critic_loss": 0.5966833533942699, "actor_loss": -33.43069027328491, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
