{"episode_reward": 0.0, "episode": 1.0, "duration": 19.433467626571655, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.5521221160888672, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.2493648640500899, "critic_loss": 0.03106540048907338, "actor_loss": -26.80721389893748, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 69.65777111053467, "step": 3000}
{"episode_reward": 14.682373496658922, "episode": 4.0, "batch_reward": 0.1620728237479925, "critic_loss": 0.030895965908654035, "actor_loss": -18.024268226385118, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.677663326263428, "step": 4000}
{"episode_reward": 64.49425198007357, "episode": 5.0, "batch_reward": 0.1396620689406991, "critic_loss": 0.03670005915127695, "actor_loss": -18.749024551659822, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.379780292510986, "step": 5000}
{"episode_reward": 32.977019701604696, "episode": 6.0, "batch_reward": 0.12518252004683017, "critic_loss": 0.04725776123441756, "actor_loss": -17.586144904702902, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.668079376220703, "step": 6000}
{"episode_reward": 116.6918678840373, "episode": 7.0, "batch_reward": 0.1221541777998209, "critic_loss": 0.06279219560697674, "actor_loss": -17.734583242625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.38826322555542, "step": 7000}
{"episode_reward": 103.61995696721235, "episode": 8.0, "batch_reward": 0.1236245874017477, "critic_loss": 0.07948844842240214, "actor_loss": -19.30308568813652, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.007831573486328, "step": 8000}
{"episode_reward": 92.823060845504, "episode": 9.0, "batch_reward": 0.11855991700291633, "critic_loss": 0.07397005728259683, "actor_loss": -16.80845777980983, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.52131152153015, "step": 9000}
{"episode_reward": 84.38652097204402, "episode": 10.0, "batch_reward": 0.11670294085890055, "critic_loss": 0.07965988189354539, "actor_loss": -17.132155320554972, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.313658237457275, "step": 10000}
{"episode_reward": 125.1981934880693, "episode": 11.0, "batch_reward": 0.11792028061300516, "critic_loss": 0.08832626539841294, "actor_loss": -16.643371839880942, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.93378186225891, "step": 11000}
{"episode_reward": 163.64048593991214, "episode": 12.0, "batch_reward": 0.12202562165260315, "critic_loss": 0.10092454018071294, "actor_loss": -17.504188678950072, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.808106660842896, "step": 12000}
{"episode_reward": 104.0575967946661, "episode": 13.0, "batch_reward": 0.11917925910651683, "critic_loss": 0.08918903097137809, "actor_loss": -16.412931404396893, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.119742155075073, "step": 13000}
{"episode_reward": 68.29843506255696, "episode": 14.0, "batch_reward": 0.11726248418539763, "critic_loss": 0.09749722894281149, "actor_loss": -16.637868238180875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.997899770736694, "step": 14000}
{"episode_reward": 197.12804812496677, "episode": 15.0, "batch_reward": 0.1230947313606739, "critic_loss": 0.10876396529749036, "actor_loss": -16.033017483472825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.815692901611328, "step": 15000}
{"episode_reward": 128.28433383436007, "episode": 16.0, "batch_reward": 0.12243961872905493, "critic_loss": 0.10210955640301109, "actor_loss": -17.86870191144943, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.09805154800415, "step": 16000}
{"episode_reward": 111.58389382572115, "episode": 17.0, "batch_reward": 0.12291260718554259, "critic_loss": 0.11531438366696238, "actor_loss": -17.576278848052024, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.28183937072754, "step": 17000}
{"episode_reward": 194.39888050691815, "episode": 18.0, "batch_reward": 0.12765446657687426, "critic_loss": 0.14925809486955405, "actor_loss": -18.578704243659974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.311264276504517, "step": 18000}
{"episode_reward": 224.099025362308, "episode": 19.0, "batch_reward": 0.13287864923477172, "critic_loss": 0.16546654507517813, "actor_loss": -19.50754960823059, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.516721487045288, "step": 19000}
{"episode_reward": 192.1002703682678, "episode": 20.0, "batch_reward": 0.13546584741026163, "critic_loss": 0.16279050765186548, "actor_loss": -17.994112708091738, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.461158990859985, "step": 20000}
{"episode_reward": 127.68249875160096, "episode": 21.0, "batch_reward": 0.13278758092969656, "critic_loss": 0.15554212633520365, "actor_loss": -18.836861393928526, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.2988383769989, "step": 21000}
{"episode_reward": 80.15381546414194, "episode": 22.0, "batch_reward": 0.1326971246600151, "critic_loss": 0.1486260915324092, "actor_loss": -18.168191357135772, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.61978507041931, "step": 22000}
{"episode_reward": 206.2494188571216, "episode": 23.0, "batch_reward": 0.13380149313807488, "critic_loss": 0.1788469113484025, "actor_loss": -18.72827673768997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.762670755386353, "step": 23000}
{"episode_reward": 63.88941908275465, "episode": 24.0, "batch_reward": 0.1304655091241002, "critic_loss": 0.1695618975907564, "actor_loss": -18.50536635494232, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.07778024673462, "step": 24000}
{"episode_reward": 61.80857385942227, "episode": 25.0, "batch_reward": 0.12704883205145598, "critic_loss": 0.17263056503981353, "actor_loss": -18.0818016371727, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.180094242095947, "step": 25000}
{"episode_reward": 33.134475084723505, "episode": 26.0, "batch_reward": 0.1285523199737072, "critic_loss": 0.2170523424819112, "actor_loss": -18.582078566551207, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.82468581199646, "step": 26000}
{"episode_reward": 251.52143299663726, "episode": 27.0, "batch_reward": 0.13324014636129142, "critic_loss": 0.2709810903072357, "actor_loss": -18.112290150642394, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.083970069885254, "step": 27000}
{"episode_reward": 200.7013646082085, "episode": 28.0, "batch_reward": 0.1331178846657276, "critic_loss": 0.24710213389247657, "actor_loss": -18.368856802940368, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.94547724723816, "step": 28000}
{"episode_reward": 244.5367087370006, "episode": 29.0, "batch_reward": 0.13748594404011966, "critic_loss": 0.2326794567257166, "actor_loss": -18.39091134262085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.761932134628296, "step": 29000}
{"episode_reward": 262.971248100166, "episode": 30.0, "batch_reward": 0.14272266228497027, "critic_loss": 0.25893785908818245, "actor_loss": -18.784087428092956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.977248668670654, "step": 30000}
{"episode_reward": 273.77633438190065, "episode": 31.0, "batch_reward": 0.1454475981593132, "critic_loss": 0.24962764944136143, "actor_loss": -19.634620129585265, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.53363537788391, "step": 31000}
{"episode_reward": 124.25427533718623, "episode": 32.0, "batch_reward": 0.14675209511071444, "critic_loss": 0.25612374626100065, "actor_loss": -19.720381440162658, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.993181467056274, "step": 32000}
{"episode_reward": 204.72963386771835, "episode": 33.0, "batch_reward": 0.14751933567225933, "critic_loss": 0.2541934903934598, "actor_loss": -19.59602725791931, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.39742875099182, "step": 33000}
{"episode_reward": 172.75051166569435, "episode": 34.0, "batch_reward": 0.1477414263933897, "critic_loss": 0.27501039718836545, "actor_loss": -20.039470816612244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.479737043380737, "step": 34000}
{"episode_reward": 111.08557416079216, "episode": 35.0, "batch_reward": 0.14720968834310771, "critic_loss": 0.24122707476466895, "actor_loss": -19.547098615646362, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.00319814682007, "step": 35000}
{"episode_reward": 153.93552361199806, "episode": 36.0, "batch_reward": 0.14718034843355418, "critic_loss": 0.22552062227576972, "actor_loss": -20.379980728149413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.71503448486328, "step": 36000}
{"episode_reward": 131.31384360234307, "episode": 37.0, "batch_reward": 0.1473299874588847, "critic_loss": 0.24801982518285512, "actor_loss": -19.547844480514527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.08702826499939, "step": 37000}
{"episode_reward": 206.23602018963848, "episode": 38.0, "batch_reward": 0.14935508196800948, "critic_loss": 0.2620963237285614, "actor_loss": -19.168650747299193, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.337724685668945, "step": 38000}
{"episode_reward": 219.06727938987788, "episode": 39.0, "batch_reward": 0.15181734266877175, "critic_loss": 0.27491663256287574, "actor_loss": -20.17649676990509, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.191455602645874, "step": 39000}
{"episode_reward": 320.7274679264869, "episode": 40.0, "batch_reward": 0.154371003203094, "critic_loss": 0.2591012730821967, "actor_loss": -20.779346536636353, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.35535454750061, "step": 40000}
{"episode_reward": 318.3645364369297, "episode": 41.0, "batch_reward": 0.15913477223366498, "critic_loss": 0.2799009162783623, "actor_loss": -21.30264126777649, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.503013610839844, "step": 41000}
{"episode_reward": 274.63271290999063, "episode": 42.0, "batch_reward": 0.16175715640187263, "critic_loss": 0.28824485340714456, "actor_loss": -20.93502997016907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.731972455978394, "step": 42000}
{"episode_reward": 239.0927483615952, "episode": 43.0, "batch_reward": 0.16443850542604924, "critic_loss": 0.30910102353990077, "actor_loss": -21.74458847427368, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.069749116897583, "step": 43000}
{"episode_reward": 319.3889552158406, "episode": 44.0, "batch_reward": 0.16615650717914104, "critic_loss": 0.3038418312519789, "actor_loss": -21.12764730453491, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.59950613975525, "step": 44000}
{"episode_reward": 103.06012390898209, "episode": 45.0, "batch_reward": 0.16371454192698, "critic_loss": 0.3081489507630467, "actor_loss": -20.64301237487793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.680187225341797, "step": 45000}
{"episode_reward": 65.66384505427824, "episode": 46.0, "batch_reward": 0.16347776381671428, "critic_loss": 0.29586514285206794, "actor_loss": -21.434271890640257, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.677075624465942, "step": 46000}
{"episode_reward": 257.7722397257723, "episode": 47.0, "batch_reward": 0.16536291640996933, "critic_loss": 0.32328868892788887, "actor_loss": -21.63684274291992, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.341469049453735, "step": 47000}
{"episode_reward": 159.5159555990619, "episode": 48.0, "batch_reward": 0.1658640256971121, "critic_loss": 0.3390682436823845, "actor_loss": -21.858115058898925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.38590931892395, "step": 48000}
{"episode_reward": 332.6022623835006, "episode": 49.0, "batch_reward": 0.16997441640496255, "critic_loss": 0.3426210491359234, "actor_loss": -22.092451881408692, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.58116340637207, "step": 49000}
{"episode_reward": 377.2193018285593, "episode": 50.0, "batch_reward": 0.17309851318597794, "critic_loss": 0.34366317553818226, "actor_loss": -22.095486446380615, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.606573820114136, "step": 50000}
{"episode_reward": 295.42206379418195, "episode": 51.0, "batch_reward": 0.1769596471339464, "critic_loss": 0.3476961377710104, "actor_loss": -22.22227024269104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.8598735332489, "step": 51000}
{"episode_reward": 306.35976943627634, "episode": 52.0, "batch_reward": 0.1790595999211073, "critic_loss": 0.33106631579995155, "actor_loss": -23.065301748275758, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.645125150680542, "step": 52000}
{"episode_reward": 352.14901585251886, "episode": 53.0, "batch_reward": 0.1808598281443119, "critic_loss": 0.3286137874275446, "actor_loss": -22.158646883010864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.06797981262207, "step": 53000}
{"episode_reward": 89.14275625961605, "episode": 54.0, "batch_reward": 0.179520992025733, "critic_loss": 0.34434563337266444, "actor_loss": -23.320290603637694, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.2563157081604, "step": 54000}
{"episode_reward": 108.24086146943789, "episode": 55.0, "batch_reward": 0.17828848744928838, "critic_loss": 0.34741324359178544, "actor_loss": -23.041484308242797, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.173359155654907, "step": 55000}
{"episode_reward": 314.51408042254144, "episode": 56.0, "batch_reward": 0.18039226198196412, "critic_loss": 0.33348535788059236, "actor_loss": -22.61521855735779, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.346110105514526, "step": 56000}
{"episode_reward": 216.3204611404557, "episode": 57.0, "batch_reward": 0.18194866734743118, "critic_loss": 0.34336474834382535, "actor_loss": -22.975490398406983, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.364567279815674, "step": 57000}
{"episode_reward": 294.1332020262647, "episode": 58.0, "batch_reward": 0.18248715175688265, "critic_loss": 0.3842546434700489, "actor_loss": -23.268458707809447, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.28931999206543, "step": 58000}
{"episode_reward": 152.09195544525446, "episode": 59.0, "batch_reward": 0.18353535576164723, "critic_loss": 0.3883089342713356, "actor_loss": -23.142726593017578, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.410821199417114, "step": 59000}
{"episode_reward": 368.54517567957384, "episode": 60.0, "batch_reward": 0.18689671330153942, "critic_loss": 0.37981589637696744, "actor_loss": -23.642217687606813, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.530490159988403, "step": 60000}
{"episode_reward": 385.7490327456128, "episode": 61.0, "batch_reward": 0.19036927025020123, "critic_loss": 0.3600786515921354, "actor_loss": -24.230482831954955, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.62835931777954, "step": 61000}
{"episode_reward": 410.21481945160207, "episode": 62.0, "batch_reward": 0.1925741258263588, "critic_loss": 0.3745686899274588, "actor_loss": -23.571049615859984, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.885359525680542, "step": 62000}
{"episode_reward": 234.44643000889664, "episode": 63.0, "batch_reward": 0.1932958706319332, "critic_loss": 0.36790685668587686, "actor_loss": -23.50447117614746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.168339014053345, "step": 63000}
{"episode_reward": 279.5520315092284, "episode": 64.0, "batch_reward": 0.19607546934485434, "critic_loss": 0.37908118794858453, "actor_loss": -24.262920669555665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.970354557037354, "step": 64000}
{"episode_reward": 358.8247966982531, "episode": 65.0, "batch_reward": 0.19736658291518688, "critic_loss": 0.3849102100431919, "actor_loss": -24.070910730361938, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.52731990814209, "step": 65000}
{"episode_reward": 161.15621650230278, "episode": 66.0, "batch_reward": 0.19619233471155167, "critic_loss": 0.3960417354851961, "actor_loss": -24.324034189224243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.519865036010742, "step": 66000}
{"episode_reward": 123.07371241398693, "episode": 67.0, "batch_reward": 0.19659610183537007, "critic_loss": 0.38371268565952776, "actor_loss": -23.921603595733643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.240262508392334, "step": 67000}
{"episode_reward": 370.2908989786272, "episode": 68.0, "batch_reward": 0.19965810054540634, "critic_loss": 0.4028963997811079, "actor_loss": -24.76871074104309, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.60243034362793, "step": 68000}
{"episode_reward": 294.68841059419697, "episode": 69.0, "batch_reward": 0.1988233374208212, "critic_loss": 0.4055450223684311, "actor_loss": -24.52944926071167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.068875312805176, "step": 69000}
{"episode_reward": 53.79273545102695, "episode": 70.0, "batch_reward": 0.19860777378082276, "critic_loss": 0.393414940148592, "actor_loss": -24.867055231094362, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.524916887283325, "step": 70000}
{"episode_reward": 352.5088253508166, "episode": 71.0, "batch_reward": 0.20001983445882798, "critic_loss": 0.42343114463984965, "actor_loss": -24.327920820236205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.63678860664368, "step": 71000}
{"episode_reward": 438.1115653374318, "episode": 72.0, "batch_reward": 0.20423682369291782, "critic_loss": 0.4290291954427958, "actor_loss": -25.16780761528015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.75701642036438, "step": 72000}
{"episode_reward": 327.82823291070576, "episode": 73.0, "batch_reward": 0.2053659364283085, "critic_loss": 0.42315963973104953, "actor_loss": -25.05180454826355, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.86523199081421, "step": 73000}
{"episode_reward": 305.0824661137011, "episode": 74.0, "batch_reward": 0.20760026079416274, "critic_loss": 0.44636763390898704, "actor_loss": -25.225095233917237, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.514034748077393, "step": 74000}
{"episode_reward": 345.470847359194, "episode": 75.0, "batch_reward": 0.2093629532456398, "critic_loss": 0.4757435035705566, "actor_loss": -25.43750344657898, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.252666234970093, "step": 75000}
{"episode_reward": 383.16708504223885, "episode": 76.0, "batch_reward": 0.2103568147867918, "critic_loss": 0.49861244463920595, "actor_loss": -25.651576238632202, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.987207412719727, "step": 76000}
{"episode_reward": 103.55008155196896, "episode": 77.0, "batch_reward": 0.20949998885393142, "critic_loss": 0.5240213318169117, "actor_loss": -25.510776260375977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.546169757843018, "step": 77000}
{"episode_reward": 298.87506439844526, "episode": 78.0, "batch_reward": 0.21041797749698163, "critic_loss": 0.5175770902782678, "actor_loss": -25.337896743774415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.632464170455933, "step": 78000}
{"episode_reward": 340.7550470669338, "episode": 79.0, "batch_reward": 0.21199403558671476, "critic_loss": 0.5462591740339995, "actor_loss": -25.626457412719727, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.43827986717224, "step": 79000}
{"episode_reward": 245.70740970846094, "episode": 80.0, "batch_reward": 0.21194327476620675, "critic_loss": 0.5491073779314757, "actor_loss": -25.564536796569826, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.948355197906494, "step": 80000}
{"episode_reward": 338.6933085499614, "episode": 81.0, "batch_reward": 0.21444170202314855, "critic_loss": 0.5609866797477007, "actor_loss": -25.720803527832032, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.71642255783081, "step": 81000}
{"episode_reward": 302.00524037505176, "episode": 82.0, "batch_reward": 0.21420342180132865, "critic_loss": 0.599093261897564, "actor_loss": -25.634622940063476, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.8122878074646, "step": 82000}
{"episode_reward": 134.76467144301557, "episode": 83.0, "batch_reward": 0.21334498770534993, "critic_loss": 0.6346014796048403, "actor_loss": -26.049550201416015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.523355722427368, "step": 83000}
{"episode_reward": 340.39185032127193, "episode": 84.0, "batch_reward": 0.21539829431474208, "critic_loss": 0.6093896759599448, "actor_loss": -26.425953140258787, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.943719625473022, "step": 84000}
{"episode_reward": 221.2690622986338, "episode": 85.0, "batch_reward": 0.21564574445784093, "critic_loss": 0.5617729471474886, "actor_loss": -25.947575433731078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.881452560424805, "step": 85000}
{"episode_reward": 148.06571795087925, "episode": 86.0, "batch_reward": 0.21527474154531956, "critic_loss": 0.5461419711411, "actor_loss": -25.81307540512085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.796865701675415, "step": 86000}
{"episode_reward": 191.05435262365722, "episode": 87.0, "batch_reward": 0.21505221743881703, "critic_loss": 0.5484916182011366, "actor_loss": -25.951194869995117, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.196108102798462, "step": 87000}
{"episode_reward": 291.66300729122185, "episode": 88.0, "batch_reward": 0.2167797991335392, "critic_loss": 0.49432706120610237, "actor_loss": -26.32281122016907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.23016047477722, "step": 88000}
{"episode_reward": 427.5584857828972, "episode": 89.0, "batch_reward": 0.21840661969780922, "critic_loss": 0.5235020997524261, "actor_loss": -26.0564013671875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.17949938774109, "step": 89000}
{"episode_reward": 484.689924042094, "episode": 90.0, "batch_reward": 0.2204041922390461, "critic_loss": 0.5292787282466889, "actor_loss": -26.49360298538208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.709538221359253, "step": 90000}
{"episode_reward": 430.738235078747, "episode": 91.0, "batch_reward": 0.22424537101387979, "critic_loss": 0.48580195331573484, "actor_loss": -26.48543850708008, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.35523295402527, "step": 91000}
{"episode_reward": 487.44756438266194, "episode": 92.0, "batch_reward": 0.22717982256412506, "critic_loss": 0.49422780188918114, "actor_loss": -26.5311506729126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.617311000823975, "step": 92000}
{"episode_reward": 473.77980942425444, "episode": 93.0, "batch_reward": 0.22927187666296958, "critic_loss": 0.48321594175696375, "actor_loss": -26.742904754638673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.092507362365723, "step": 93000}
{"episode_reward": 405.0043455858985, "episode": 94.0, "batch_reward": 0.2320736431032419, "critic_loss": 0.5127568399012089, "actor_loss": -27.341128269195558, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.83342742919922, "step": 94000}
{"episode_reward": 462.8523744003889, "episode": 95.0, "batch_reward": 0.23337509573996068, "critic_loss": 0.475062479659915, "actor_loss": -27.416302974700926, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.272844552993774, "step": 95000}
{"episode_reward": 365.0826468054537, "episode": 96.0, "batch_reward": 0.23432345530390739, "critic_loss": 0.4347472875714302, "actor_loss": -27.461952648162843, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.437271118164062, "step": 96000}
{"episode_reward": 447.02101039387185, "episode": 97.0, "batch_reward": 0.23707774576544763, "critic_loss": 0.43784397964179517, "actor_loss": -27.810820148468018, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.6169171333313, "step": 97000}
{"episode_reward": 132.26300588981448, "episode": 98.0, "batch_reward": 0.23528483833372593, "critic_loss": 0.4545759458094835, "actor_loss": -27.277745155334472, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.683804512023926, "step": 98000}
{"episode_reward": 169.91484920747067, "episode": 99.0, "batch_reward": 0.2351366260945797, "critic_loss": 0.4512977512031794, "actor_loss": -27.57061078643799, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.255680084228516, "step": 99000}
{"episode_reward": 306.953955783291, "episode": 100.0, "batch_reward": 0.2352355210930109, "critic_loss": 0.4189861758351326, "actor_loss": -27.385104377746583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.118467092514038, "step": 100000}
{"episode_reward": 289.59321739590985, "episode": 101.0, "batch_reward": 0.23743514743447303, "critic_loss": 0.42075975821912287, "actor_loss": -27.790689861297608, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.86568474769592, "step": 101000}
{"episode_reward": 353.82091041810287, "episode": 102.0, "batch_reward": 0.23746585364639758, "critic_loss": 0.4190705027878284, "actor_loss": -27.656572345733643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.830844163894653, "step": 102000}
{"episode_reward": 151.97214106866235, "episode": 103.0, "batch_reward": 0.23678689308464526, "critic_loss": 0.41598989816009996, "actor_loss": -27.338161643981934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.70688772201538, "step": 103000}
{"episode_reward": 318.22668726734224, "episode": 104.0, "batch_reward": 0.23754111008346082, "critic_loss": 0.47422785075008866, "actor_loss": -27.758005668640138, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.22248125076294, "step": 104000}
{"episode_reward": 402.83600327175645, "episode": 105.0, "batch_reward": 0.24023435866832732, "critic_loss": 0.4034751851707697, "actor_loss": -27.549979431152344, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.606563091278076, "step": 105000}
{"episode_reward": 445.47068232117044, "episode": 106.0, "batch_reward": 0.2420805391818285, "critic_loss": 0.41352818012237547, "actor_loss": -28.09985194396973, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.470314979553223, "step": 106000}
{"episode_reward": 471.58566902737414, "episode": 107.0, "batch_reward": 0.24348455587029458, "critic_loss": 0.41393913623690604, "actor_loss": -27.918510646820067, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.694114446640015, "step": 107000}
{"episode_reward": 435.9518982998075, "episode": 108.0, "batch_reward": 0.24510763536393643, "critic_loss": 0.4297204634845257, "actor_loss": -27.731807193756104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.99194049835205, "step": 108000}
{"episode_reward": 545.9511355252836, "episode": 109.0, "batch_reward": 0.24822065238654614, "critic_loss": 0.4395407037734985, "actor_loss": -28.563914070129396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.78123688697815, "step": 109000}
{"episode_reward": 487.15760738636516, "episode": 110.0, "batch_reward": 0.2506322370916605, "critic_loss": 0.4201307749301195, "actor_loss": -28.855423671722413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.836364269256592, "step": 110000}
{"episode_reward": 516.856928151773, "episode": 111.0, "batch_reward": 0.2518989719450474, "critic_loss": 0.41083519515395167, "actor_loss": -28.213321353912352, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.902294397354126, "step": 111000}
{"episode_reward": 486.83854197665977, "episode": 112.0, "batch_reward": 0.25433142654597757, "critic_loss": 0.4334742380231619, "actor_loss": -29.222400699615477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.012166500091553, "step": 112000}
{"episode_reward": 464.7112406555712, "episode": 113.0, "batch_reward": 0.2572243282049894, "critic_loss": 0.4169978175908327, "actor_loss": -28.98976992416382, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.20690107345581, "step": 113000}
{"episode_reward": 456.4781640480538, "episode": 114.0, "batch_reward": 0.2582491041868925, "critic_loss": 0.4073674253374338, "actor_loss": -29.458144348144533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.959625482559204, "step": 114000}
{"episode_reward": 507.7407742069288, "episode": 115.0, "batch_reward": 0.26003913167119025, "critic_loss": 0.4216534459143877, "actor_loss": -29.275061573028566, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.372493028640747, "step": 115000}
{"episode_reward": 458.6939256026179, "episode": 116.0, "batch_reward": 0.2636500394195318, "critic_loss": 0.41940869721770285, "actor_loss": -29.73993714904785, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.327723503112793, "step": 116000}
{"episode_reward": 476.6065270676492, "episode": 117.0, "batch_reward": 0.2635657713860273, "critic_loss": 0.4355605525672436, "actor_loss": -29.26120552444458, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.94584059715271, "step": 117000}
{"episode_reward": 238.5107953444352, "episode": 118.0, "batch_reward": 0.2650976266860962, "critic_loss": 0.406716522321105, "actor_loss": -29.697376899719238, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.11700963973999, "step": 118000}
{"episode_reward": 449.7395885209377, "episode": 119.0, "batch_reward": 0.26559400007128714, "critic_loss": 0.4249790836125612, "actor_loss": -29.777137996673584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.454041719436646, "step": 119000}
{"episode_reward": 513.1714078831212, "episode": 120.0, "batch_reward": 0.2667811085432768, "critic_loss": 0.4089696374833584, "actor_loss": -29.559309391021728, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.479387998580933, "step": 120000}
{"episode_reward": 475.5147063879414, "episode": 121.0, "batch_reward": 0.2684868552982807, "critic_loss": 0.38518958316743374, "actor_loss": -29.6744285697937, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.334693908691406, "step": 121000}
{"episode_reward": 501.682606650019, "episode": 122.0, "batch_reward": 0.27175929978489877, "critic_loss": 0.3789607778638601, "actor_loss": -29.828124813079835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.07941460609436, "step": 122000}
{"episode_reward": 440.85874530154655, "episode": 123.0, "batch_reward": 0.27258852498233316, "critic_loss": 0.38850447711348535, "actor_loss": -30.65176937866211, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.65641736984253, "step": 123000}
{"episode_reward": 373.59384406547485, "episode": 124.0, "batch_reward": 0.27304599407315255, "critic_loss": 0.397831370189786, "actor_loss": -30.320661231994627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.60014843940735, "step": 124000}
{"episode_reward": 240.6053574263231, "episode": 125.0, "batch_reward": 0.2738619619011879, "critic_loss": 0.3719048558920622, "actor_loss": -30.413910400390623, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.83455491065979, "step": 125000}
{"episode_reward": 536.4626718244984, "episode": 126.0, "batch_reward": 0.2744029579162598, "critic_loss": 0.35492736542224884, "actor_loss": -30.091208576202394, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.064043521881104, "step": 126000}
{"episode_reward": 161.82020668840448, "episode": 127.0, "batch_reward": 0.2744466491937637, "critic_loss": 0.3834798800498247, "actor_loss": -30.426161846160888, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.15621519088745, "step": 127000}
{"episode_reward": 302.6196590577329, "episode": 128.0, "batch_reward": 0.2748194862157106, "critic_loss": 0.3797566055059433, "actor_loss": -30.282061443328857, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.51694345474243, "step": 128000}
{"episode_reward": 535.648397639917, "episode": 129.0, "batch_reward": 0.2768343300074339, "critic_loss": 0.39400641894340516, "actor_loss": -30.19079387283325, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.690934419631958, "step": 129000}
{"episode_reward": 442.4210196715722, "episode": 130.0, "batch_reward": 0.2781612665951252, "critic_loss": 0.40581935103237626, "actor_loss": -30.421098613739012, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.597888708114624, "step": 130000}
{"episode_reward": 517.5479773232403, "episode": 131.0, "batch_reward": 0.28107175540924073, "critic_loss": 0.4070737654566765, "actor_loss": -30.788884037017823, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.63353157043457, "step": 131000}
{"episode_reward": 497.7225449667958, "episode": 132.0, "batch_reward": 0.2809640809595585, "critic_loss": 0.4129075466692448, "actor_loss": -31.30177911376953, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.13880181312561, "step": 132000}
{"episode_reward": 492.60261422409883, "episode": 133.0, "batch_reward": 0.2836065294444561, "critic_loss": 0.43097129541635515, "actor_loss": -31.071239112854006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.46082854270935, "step": 133000}
{"episode_reward": 517.5871932535213, "episode": 134.0, "batch_reward": 0.28443865716457367, "critic_loss": 0.39732496957480906, "actor_loss": -30.543648540496825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.9945547580719, "step": 134000}
{"episode_reward": 497.47251001852794, "episode": 135.0, "batch_reward": 0.2872364078164101, "critic_loss": 0.38683139243721965, "actor_loss": -31.73975592803955, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.325020790100098, "step": 135000}
{"episode_reward": 512.3163273227475, "episode": 136.0, "batch_reward": 0.2871741496026516, "critic_loss": 0.4205722369402647, "actor_loss": -30.482972957611086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.07662320137024, "step": 136000}
{"episode_reward": 550.3473456373123, "episode": 137.0, "batch_reward": 0.2899456789493561, "critic_loss": 0.4116007083505392, "actor_loss": -31.58550003051758, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.645229816436768, "step": 137000}
{"episode_reward": 512.9112475743108, "episode": 138.0, "batch_reward": 0.29215315398573877, "critic_loss": 0.41966762201488017, "actor_loss": -31.63616130065918, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.823097229003906, "step": 138000}
{"episode_reward": 484.06495419160757, "episode": 139.0, "batch_reward": 0.29457917566597464, "critic_loss": 0.4372512172013521, "actor_loss": -31.959328548431397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.15157151222229, "step": 139000}
{"episode_reward": 537.427556281216, "episode": 140.0, "batch_reward": 0.29594092440605163, "critic_loss": 0.42697331066429617, "actor_loss": -32.05210150527954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.335976123809814, "step": 140000}
{"episode_reward": 503.69718479028046, "episode": 141.0, "batch_reward": 0.2959586345106363, "critic_loss": 0.4594490327090025, "actor_loss": -32.250793243408204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.543495178222656, "step": 141000}
{"episode_reward": 567.1865160067381, "episode": 142.0, "batch_reward": 0.2978463283032179, "critic_loss": 0.4458982235342264, "actor_loss": -31.853806983947752, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.195086002349854, "step": 142000}
{"episode_reward": 507.71689004229967, "episode": 143.0, "batch_reward": 0.2998794927150011, "critic_loss": 0.4232300603836775, "actor_loss": -32.12817539215088, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.197160959243774, "step": 143000}
{"episode_reward": 510.67829002498803, "episode": 144.0, "batch_reward": 0.30172758232057095, "critic_loss": 0.41933525548875333, "actor_loss": -32.72998191070557, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.46682834625244, "step": 144000}
{"episode_reward": 536.1158599401775, "episode": 145.0, "batch_reward": 0.30329144962131976, "critic_loss": 0.4231613073647022, "actor_loss": -32.93175129699707, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.237209796905518, "step": 145000}
{"episode_reward": 511.22106376054154, "episode": 146.0, "batch_reward": 0.30477174173295496, "critic_loss": 0.3846953869313002, "actor_loss": -33.28534128570556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.961825132369995, "step": 146000}
{"episode_reward": 575.8125028780565, "episode": 147.0, "batch_reward": 0.3054493745714426, "critic_loss": 0.3977268847376108, "actor_loss": -33.08809348678589, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.68750238418579, "step": 147000}
{"episode_reward": 548.6117605286076, "episode": 148.0, "batch_reward": 0.3078009702861309, "critic_loss": 0.3982392950952053, "actor_loss": -33.36723919296265, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.88344979286194, "step": 148000}
{"episode_reward": 584.0280110904438, "episode": 149.0, "batch_reward": 0.31027955293655396, "critic_loss": 0.41003820012509823, "actor_loss": -33.31156951904297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.731006145477295, "step": 149000}
{"episode_reward": 528.4802675264849, "episode": 150.0, "batch_reward": 0.3114978885650635, "critic_loss": 0.40246338869631293, "actor_loss": -33.716141605377196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
