{"episode_reward": 0.0, "episode": 1.0, "duration": 19.346590042114258, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.6551642417907715, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.2486818139504973, "critic_loss": 0.03582724848704393, "actor_loss": -35.3332393518677, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 66.9891209602356, "step": 3000}
{"episode_reward": 9.412899970481302, "episode": 4.0, "batch_reward": 0.1700792076587677, "critic_loss": 0.05272940087504685, "actor_loss": -25.5848988802433, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.904337167739868, "step": 4000}
{"episode_reward": 95.54282538157494, "episode": 5.0, "batch_reward": 0.14258030664920807, "critic_loss": 0.03700810932926834, "actor_loss": -23.70670974469185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.399431228637695, "step": 5000}
{"episode_reward": 3.6546834459903446, "episode": 6.0, "batch_reward": 0.11812151828408242, "critic_loss": 0.038721577774733305, "actor_loss": -23.628459719657897, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.3538875579834, "step": 6000}
{"episode_reward": 10.07551688537124, "episode": 7.0, "batch_reward": 0.10195308170095087, "critic_loss": 0.03809842986613512, "actor_loss": -24.091920374155045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.757984161376953, "step": 7000}
{"episode_reward": 16.45489888748491, "episode": 8.0, "batch_reward": 0.09001604842767119, "critic_loss": 0.03451109094079584, "actor_loss": -25.107441391944885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.340036869049072, "step": 8000}
{"episode_reward": 12.965694840263083, "episode": 9.0, "batch_reward": 0.08023903669416904, "critic_loss": 0.033934472670778634, "actor_loss": -23.9951177649498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.71736168861389, "step": 9000}
{"episode_reward": 13.844570532907046, "episode": 10.0, "batch_reward": 0.07343842266499996, "critic_loss": 0.03278020332753658, "actor_loss": -24.348832592487334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.72679829597473, "step": 10000}
{"episode_reward": 8.755755612635557, "episode": 11.0, "batch_reward": 0.06733465421572328, "critic_loss": 0.032026566693559286, "actor_loss": -24.060790281772615, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.47622513771057, "step": 11000}
{"episode_reward": 22.594356406252675, "episode": 12.0, "batch_reward": 0.06522090385481716, "critic_loss": 0.03586478442326188, "actor_loss": -24.251766794919966, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.021090030670166, "step": 12000}
{"episode_reward": 38.9204303557753, "episode": 13.0, "batch_reward": 0.06739912383258342, "critic_loss": 0.06416193586029112, "actor_loss": -24.293235661029815, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.952437162399292, "step": 13000}
{"episode_reward": 182.33473491096547, "episode": 14.0, "batch_reward": 0.07372712246328593, "critic_loss": 0.07708784117735923, "actor_loss": -24.890726342201233, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.094860553741455, "step": 14000}
{"episode_reward": 107.12790585073694, "episode": 15.0, "batch_reward": 0.07577561860904097, "critic_loss": 0.06919669983163476, "actor_loss": -23.32020886516571, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.209530115127563, "step": 15000}
{"episode_reward": 73.37560967036394, "episode": 16.0, "batch_reward": 0.07369194103777409, "critic_loss": 0.06901694443449378, "actor_loss": -25.28599233675003, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.01901364326477, "step": 16000}
{"episode_reward": 56.521591814310035, "episode": 17.0, "batch_reward": 0.0749473697207868, "critic_loss": 0.07514958585426211, "actor_loss": -24.78628003060818, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.587653636932373, "step": 17000}
{"episode_reward": 157.71642611081245, "episode": 18.0, "batch_reward": 0.07977082547917962, "critic_loss": 0.09406533012539148, "actor_loss": -25.385064539670942, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.190247058868408, "step": 18000}
{"episode_reward": 144.07737550648017, "episode": 19.0, "batch_reward": 0.08552632265537977, "critic_loss": 0.12008044825866819, "actor_loss": -26.04878405162692, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.572091817855835, "step": 19000}
{"episode_reward": 210.84218825514867, "episode": 20.0, "batch_reward": 0.09310302971303464, "critic_loss": 0.14060517915338278, "actor_loss": -25.219952459782363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.44830894470215, "step": 20000}
{"episode_reward": 215.97829521680708, "episode": 21.0, "batch_reward": 0.09803673028200864, "critic_loss": 0.15896415615081788, "actor_loss": -25.675739705324172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.44801378250122, "step": 21000}
{"episode_reward": 180.93604864034305, "episode": 22.0, "batch_reward": 0.10036856555938721, "critic_loss": 0.15534529683738946, "actor_loss": -25.316505551278592, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.36745595932007, "step": 22000}
{"episode_reward": 101.53304793858506, "episode": 23.0, "batch_reward": 0.10073510754853487, "critic_loss": 0.16415865113586187, "actor_loss": -25.8690864200294, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.664371490478516, "step": 23000}
{"episode_reward": 190.10001378380204, "episode": 24.0, "batch_reward": 0.10458902156352996, "critic_loss": 0.17605013851076365, "actor_loss": -25.778207977354526, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.68907141685486, "step": 24000}
{"episode_reward": 115.32414287698356, "episode": 25.0, "batch_reward": 0.10669975399971009, "critic_loss": 0.20971193255484105, "actor_loss": -26.593008805811404, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.845943927764893, "step": 25000}
{"episode_reward": 217.267713906456, "episode": 26.0, "batch_reward": 0.11204062481969596, "critic_loss": 0.22102957122772932, "actor_loss": -25.820859899878503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.194007635116577, "step": 26000}
{"episode_reward": 255.559603213808, "episode": 27.0, "batch_reward": 0.11376026085019111, "critic_loss": 0.23762733622640372, "actor_loss": -26.08384634423256, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.83188271522522, "step": 27000}
{"episode_reward": 111.45226566037417, "episode": 28.0, "batch_reward": 0.11400508543103934, "critic_loss": 0.2775403747111559, "actor_loss": -26.32504888176918, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.44625997543335, "step": 28000}
{"episode_reward": 104.25957775671723, "episode": 29.0, "batch_reward": 0.11602652080357075, "critic_loss": 0.2581705402135849, "actor_loss": -25.074821598529816, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.462833881378174, "step": 29000}
{"episode_reward": 192.19078505463645, "episode": 30.0, "batch_reward": 0.11927455822378397, "critic_loss": 0.30238231994211673, "actor_loss": -25.173627718925477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.04283618927002, "step": 30000}
{"episode_reward": 283.80183028696183, "episode": 31.0, "batch_reward": 0.12457834455370903, "critic_loss": 0.34279994197189806, "actor_loss": -26.79762097930908, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.326308250427246, "step": 31000}
{"episode_reward": 284.21182038020805, "episode": 32.0, "batch_reward": 0.12639824622869492, "critic_loss": 0.30610983504354955, "actor_loss": -26.376116401433944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.339866161346436, "step": 32000}
{"episode_reward": 42.329383248278134, "episode": 33.0, "batch_reward": 0.12809192894399166, "critic_loss": 0.3170251082181931, "actor_loss": -26.35261631298065, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.088685750961304, "step": 33000}
{"episode_reward": 337.31870941046924, "episode": 34.0, "batch_reward": 0.13059494415670633, "critic_loss": 0.3082818964123726, "actor_loss": -26.349826521873474, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.83502459526062, "step": 34000}
{"episode_reward": 73.46902764271766, "episode": 35.0, "batch_reward": 0.13019993074983358, "critic_loss": 0.311605517283082, "actor_loss": -25.589537667274474, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.32095217704773, "step": 35000}
{"episode_reward": 137.7275149703014, "episode": 36.0, "batch_reward": 0.12883817931264638, "critic_loss": 0.3059999964982271, "actor_loss": -26.677976773262024, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30896544456482, "step": 36000}
{"episode_reward": 52.69201994205086, "episode": 37.0, "batch_reward": 0.12861167549341918, "critic_loss": 0.34486020960658786, "actor_loss": -25.91890679168701, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.801822900772095, "step": 37000}
{"episode_reward": 163.82800475201063, "episode": 38.0, "batch_reward": 0.13014785749465227, "critic_loss": 0.33031726486980917, "actor_loss": -25.277995666503905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.207242012023926, "step": 38000}
{"episode_reward": 243.34114935930114, "episode": 39.0, "batch_reward": 0.13367218932509423, "critic_loss": 0.32603595952689646, "actor_loss": -26.573295370101928, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.359697103500366, "step": 39000}
{"episode_reward": 281.0210087984262, "episode": 40.0, "batch_reward": 0.13493625758588315, "critic_loss": 0.3206200075745583, "actor_loss": -26.57347235584259, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.65564489364624, "step": 40000}
{"episode_reward": 107.86307846576567, "episode": 41.0, "batch_reward": 0.13681076854467392, "critic_loss": 0.2969727124720812, "actor_loss": -27.11726857662201, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.918396949768066, "step": 41000}
{"episode_reward": 344.38498003788567, "episode": 42.0, "batch_reward": 0.14134119752794505, "critic_loss": 0.3529418638944626, "actor_loss": -25.90101128387451, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.505924463272095, "step": 42000}
{"episode_reward": 307.1394943468867, "episode": 43.0, "batch_reward": 0.14538586515188218, "critic_loss": 0.32335517622530463, "actor_loss": -27.252910853385924, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.249017000198364, "step": 43000}
{"episode_reward": 330.61003828709704, "episode": 44.0, "batch_reward": 0.14736891435086727, "critic_loss": 0.34273398225009444, "actor_loss": -27.19565640449524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.747104167938232, "step": 44000}
{"episode_reward": 68.03510046130044, "episode": 45.0, "batch_reward": 0.1468302875086665, "critic_loss": 0.343317811280489, "actor_loss": -26.790632840156555, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.312522411346436, "step": 45000}
{"episode_reward": 173.00317010843335, "episode": 46.0, "batch_reward": 0.14778276067972182, "critic_loss": 0.33691892206668855, "actor_loss": -26.44178091430664, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.068763256072998, "step": 46000}
{"episode_reward": 160.13194483396887, "episode": 47.0, "batch_reward": 0.14886720859259367, "critic_loss": 0.3585323113054037, "actor_loss": -26.76887846279144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.026909589767456, "step": 47000}
{"episode_reward": 209.8687968364978, "episode": 48.0, "batch_reward": 0.1498708195760846, "critic_loss": 0.32698910814523696, "actor_loss": -26.707665238380432, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.522261142730713, "step": 48000}
{"episode_reward": 319.21018443875585, "episode": 49.0, "batch_reward": 0.15395578476041555, "critic_loss": 0.32506676533818246, "actor_loss": -27.224425256729127, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.587148666381836, "step": 49000}
{"episode_reward": 193.14969514246525, "episode": 50.0, "batch_reward": 0.15466014781594276, "critic_loss": 0.3244314886629581, "actor_loss": -26.581919114112853, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.451526641845703, "step": 50000}
{"episode_reward": 336.33043360552296, "episode": 51.0, "batch_reward": 0.15880498158186673, "critic_loss": 0.3129580033272505, "actor_loss": -26.867946520805358, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.95173931121826, "step": 51000}
{"episode_reward": 333.04128058586167, "episode": 52.0, "batch_reward": 0.16226350778341295, "critic_loss": 0.3432175210863352, "actor_loss": -27.839232564926146, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.53205919265747, "step": 52000}
{"episode_reward": 334.43124124805854, "episode": 53.0, "batch_reward": 0.16490397354960443, "critic_loss": 0.3377283401042223, "actor_loss": -26.711642011642457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.014535188674927, "step": 53000}
{"episode_reward": 246.60088071990543, "episode": 54.0, "batch_reward": 0.1643399993777275, "critic_loss": 0.3429190933406353, "actor_loss": -28.015244824409486, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.416961193084717, "step": 54000}
{"episode_reward": 60.62306008362013, "episode": 55.0, "batch_reward": 0.16250714502483607, "critic_loss": 0.3456317561417818, "actor_loss": -27.325389803886413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.420286178588867, "step": 55000}
{"episode_reward": 79.50107492785818, "episode": 56.0, "batch_reward": 0.16038292261213064, "critic_loss": 0.3543210901319981, "actor_loss": -25.984038959503174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.037219047546387, "step": 56000}
{"episode_reward": 74.669731269078, "episode": 57.0, "batch_reward": 0.16183799181878566, "critic_loss": 0.35198387944698334, "actor_loss": -26.98411159706116, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.246291637420654, "step": 57000}
{"episode_reward": 386.7046580438095, "episode": 58.0, "batch_reward": 0.1650554588586092, "critic_loss": 0.33499922758340833, "actor_loss": -26.804126277923583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.85457158088684, "step": 58000}
{"episode_reward": 290.41960241386363, "episode": 59.0, "batch_reward": 0.16573031924664974, "critic_loss": 0.34942445436120034, "actor_loss": -26.82988694190979, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.77493190765381, "step": 59000}
{"episode_reward": 91.10326018557369, "episode": 60.0, "batch_reward": 0.16619805341213942, "critic_loss": 0.3449376111030579, "actor_loss": -26.83511948776245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.08752965927124, "step": 60000}
{"episode_reward": 319.56728652623224, "episode": 61.0, "batch_reward": 0.16882730661332607, "critic_loss": 0.35469756032526495, "actor_loss": -27.49272901916504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.945093870162964, "step": 61000}
{"episode_reward": 378.06004728785035, "episode": 62.0, "batch_reward": 0.17166837410628796, "critic_loss": 0.3632839183360338, "actor_loss": -26.990903112411498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.9324688911438, "step": 62000}
{"episode_reward": 280.4139459304063, "episode": 63.0, "batch_reward": 0.17357358372211457, "critic_loss": 0.37166762638092044, "actor_loss": -27.451875625610352, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.140538215637207, "step": 63000}
{"episode_reward": 406.38175350337417, "episode": 64.0, "batch_reward": 0.1770291531085968, "critic_loss": 0.36995311911404133, "actor_loss": -27.874730554580687, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.72867751121521, "step": 64000}
{"episode_reward": 410.1895844137695, "episode": 65.0, "batch_reward": 0.18080205297470092, "critic_loss": 0.34186622440814973, "actor_loss": -27.83536703681946, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.85109281539917, "step": 65000}
{"episode_reward": 362.82796283402087, "episode": 66.0, "batch_reward": 0.18378756032884122, "critic_loss": 0.3341186962127686, "actor_loss": -28.229149864196778, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.405741214752197, "step": 66000}
{"episode_reward": 412.52571205080835, "episode": 67.0, "batch_reward": 0.18719849959015847, "critic_loss": 0.341056276217103, "actor_loss": -28.046978109359742, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.90150237083435, "step": 67000}
{"episode_reward": 199.53996728193616, "episode": 68.0, "batch_reward": 0.18775437372922898, "critic_loss": 0.37261369425058366, "actor_loss": -28.685935625076294, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.820525884628296, "step": 68000}
{"episode_reward": 265.41811381766246, "episode": 69.0, "batch_reward": 0.1892465652525425, "critic_loss": 0.3480768009126186, "actor_loss": -28.721882175445558, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.33090329170227, "step": 69000}
{"episode_reward": 389.36385274755554, "episode": 70.0, "batch_reward": 0.19273420517146586, "critic_loss": 0.3731148059219122, "actor_loss": -28.9886537361145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.169067859649658, "step": 70000}
{"episode_reward": 423.905335293173, "episode": 71.0, "batch_reward": 0.19415719930827618, "critic_loss": 0.37429754075407984, "actor_loss": -28.615202339172363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.66382646560669, "step": 71000}
{"episode_reward": 390.1248184937419, "episode": 72.0, "batch_reward": 0.19789205887913705, "critic_loss": 0.32964466685056687, "actor_loss": -29.5831547870636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.633733987808228, "step": 72000}
{"episode_reward": 393.5012849317229, "episode": 73.0, "batch_reward": 0.19944597388803958, "critic_loss": 0.3745647641271353, "actor_loss": -29.597174867630006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.475781679153442, "step": 73000}
{"episode_reward": 209.9674881571381, "episode": 74.0, "batch_reward": 0.200412519544363, "critic_loss": 0.3932293450683355, "actor_loss": -29.05277750968933, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.500182390213013, "step": 74000}
{"episode_reward": 377.2852569638849, "episode": 75.0, "batch_reward": 0.2033287893384695, "critic_loss": 0.42656622526049615, "actor_loss": -29.85528336906433, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.119571208953857, "step": 75000}
{"episode_reward": 294.84959734400405, "episode": 76.0, "batch_reward": 0.20388792437314987, "critic_loss": 0.4014034861326218, "actor_loss": -29.391784488677978, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.806859970092773, "step": 76000}
{"episode_reward": 321.87904879560324, "episode": 77.0, "batch_reward": 0.20596736317873002, "critic_loss": 0.44968901155889035, "actor_loss": -29.617660512924193, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.943909168243408, "step": 77000}
{"episode_reward": 446.88639120380003, "episode": 78.0, "batch_reward": 0.20901655840873717, "critic_loss": 0.4437825313210487, "actor_loss": -29.46329207229614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.05600905418396, "step": 78000}
{"episode_reward": 421.5149767151448, "episode": 79.0, "batch_reward": 0.2102393620312214, "critic_loss": 0.431439245313406, "actor_loss": -30.016851943969726, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.668513536453247, "step": 79000}
{"episode_reward": 151.50398767394177, "episode": 80.0, "batch_reward": 0.2108162302225828, "critic_loss": 0.43197235284745694, "actor_loss": -30.022936304092408, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.647990942001343, "step": 80000}
{"episode_reward": 389.01870727137606, "episode": 81.0, "batch_reward": 0.21391080366075038, "critic_loss": 0.453389166995883, "actor_loss": -30.153844120025635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.99859428405762, "step": 81000}
{"episode_reward": 424.5430634262786, "episode": 82.0, "batch_reward": 0.21595405793190003, "critic_loss": 0.4649219025373459, "actor_loss": -30.2746390914917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.72318196296692, "step": 82000}
{"episode_reward": 383.4596200559304, "episode": 83.0, "batch_reward": 0.2150907613784075, "critic_loss": 0.42954174165427683, "actor_loss": -30.101491731643677, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.72003173828125, "step": 83000}
{"episode_reward": 26.554317593459203, "episode": 84.0, "batch_reward": 0.21506555196642876, "critic_loss": 0.41048789635300637, "actor_loss": -30.73657747077942, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.47138810157776, "step": 84000}
{"episode_reward": 451.5653859614239, "episode": 85.0, "batch_reward": 0.21765999515354634, "critic_loss": 0.41259864696860316, "actor_loss": -30.453850198745727, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.148621559143066, "step": 85000}
{"episode_reward": 201.4980761374961, "episode": 86.0, "batch_reward": 0.21846897219121456, "critic_loss": 0.4277364799231291, "actor_loss": -30.767211849212647, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.813410997390747, "step": 86000}
{"episode_reward": 326.79134675522357, "episode": 87.0, "batch_reward": 0.21858194707334042, "critic_loss": 0.43199768532812594, "actor_loss": -30.61021875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41483974456787, "step": 87000}
{"episode_reward": 119.65887003876195, "episode": 88.0, "batch_reward": 0.21898101183772087, "critic_loss": 0.4192329053580761, "actor_loss": -30.70526082611084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.944719076156616, "step": 88000}
{"episode_reward": 461.8062808831978, "episode": 89.0, "batch_reward": 0.22091141982376575, "critic_loss": 0.42886260424554346, "actor_loss": -30.30604977798462, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.88545513153076, "step": 89000}
{"episode_reward": 306.2777682088046, "episode": 90.0, "batch_reward": 0.22184863211214542, "critic_loss": 0.4023577895462513, "actor_loss": -30.467874757766722, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.419922590255737, "step": 90000}
{"episode_reward": 405.0900747597928, "episode": 91.0, "batch_reward": 0.22333311754465104, "critic_loss": 0.4041094563603401, "actor_loss": -30.250220386505127, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.102307081222534, "step": 91000}
{"episode_reward": 249.99430082024722, "episode": 92.0, "batch_reward": 0.22441308462619783, "critic_loss": 0.402615377292037, "actor_loss": -30.457563581466676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.823137760162354, "step": 92000}
{"episode_reward": 416.95970639991765, "episode": 93.0, "batch_reward": 0.22690105944871902, "critic_loss": 0.41671330530941486, "actor_loss": -31.171031209945678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.461345195770264, "step": 93000}
{"episode_reward": 311.75289218057407, "episode": 94.0, "batch_reward": 0.2275281331092119, "critic_loss": 0.43601769430935383, "actor_loss": -31.252472150802614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.443506956100464, "step": 94000}
{"episode_reward": 442.33222021297763, "episode": 95.0, "batch_reward": 0.22919196811318399, "critic_loss": 0.4326683382540941, "actor_loss": -31.238109451293944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.739521026611328, "step": 95000}
{"episode_reward": 337.79069344217464, "episode": 96.0, "batch_reward": 0.23068866242468358, "critic_loss": 0.43260192294418814, "actor_loss": -31.039311470031738, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.6763916015625, "step": 96000}
{"episode_reward": 411.3764717796656, "episode": 97.0, "batch_reward": 0.23231169851124286, "critic_loss": 0.42621448515355587, "actor_loss": -31.43012237930298, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.498806476593018, "step": 97000}
{"episode_reward": 496.37725327762445, "episode": 98.0, "batch_reward": 0.23471138252317905, "critic_loss": 0.43425415582954885, "actor_loss": -31.700655153274536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.195199728012085, "step": 98000}
{"episode_reward": 419.9872327106717, "episode": 99.0, "batch_reward": 0.23688070946931838, "critic_loss": 0.44595758068561553, "actor_loss": -31.59631125640869, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.190739631652832, "step": 99000}
{"episode_reward": 237.9416647839909, "episode": 100.0, "batch_reward": 0.23490456752479077, "critic_loss": 0.4275054135769606, "actor_loss": -31.896819623947145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30522918701172, "step": 100000}
{"episode_reward": 98.25195391321837, "episode": 101.0, "batch_reward": 0.2359880973249674, "critic_loss": 0.4464368702620268, "actor_loss": -31.73966250991821, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.75241804122925, "step": 101000}
{"episode_reward": 443.3104839183386, "episode": 102.0, "batch_reward": 0.2379052247852087, "critic_loss": 0.4601490772664547, "actor_loss": -32.17776577949524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.635589361190796, "step": 102000}
{"episode_reward": 454.8399218868964, "episode": 103.0, "batch_reward": 0.23991992220282554, "critic_loss": 0.4391117369681597, "actor_loss": -31.417111022949218, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.21793270111084, "step": 103000}
{"episode_reward": 391.6759537839603, "episode": 104.0, "batch_reward": 0.2412145135998726, "critic_loss": 0.4550125365257263, "actor_loss": -31.914788091659545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.809067726135254, "step": 104000}
{"episode_reward": 237.07296968414298, "episode": 105.0, "batch_reward": 0.24262387523055076, "critic_loss": 0.45538458740711213, "actor_loss": -31.536255094528197, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.146504402160645, "step": 105000}
{"episode_reward": 488.85483651144216, "episode": 106.0, "batch_reward": 0.2434638270586729, "critic_loss": 0.4348503887653351, "actor_loss": -32.5228600063324, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.340781450271606, "step": 106000}
{"episode_reward": 439.99072239859635, "episode": 107.0, "batch_reward": 0.24575318445265293, "critic_loss": 0.4465945679396391, "actor_loss": -32.505689586639406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.59946036338806, "step": 107000}
{"episode_reward": 493.650687099575, "episode": 108.0, "batch_reward": 0.24721850794553757, "critic_loss": 0.4518321336060762, "actor_loss": -31.99215481185913, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.830617904663086, "step": 108000}
{"episode_reward": 483.9640475340023, "episode": 109.0, "batch_reward": 0.24871530418097973, "critic_loss": 0.46848691056668756, "actor_loss": -32.56275384902954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.5795681476593, "step": 109000}
{"episode_reward": 57.35105588437, "episode": 110.0, "batch_reward": 0.24808650314807892, "critic_loss": 0.42384423381090164, "actor_loss": -32.335070220947266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.15887141227722, "step": 110000}
{"episode_reward": 420.7986644337639, "episode": 111.0, "batch_reward": 0.24931343472003936, "critic_loss": 0.41180173015594485, "actor_loss": -32.16503587913513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.625107526779175, "step": 111000}
{"episode_reward": 243.6065509943084, "episode": 112.0, "batch_reward": 0.24839165662229062, "critic_loss": 0.43018834218382834, "actor_loss": -32.386862884521484, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.535488605499268, "step": 112000}
{"episode_reward": 106.30144937324243, "episode": 113.0, "batch_reward": 0.2481543728262186, "critic_loss": 0.42589080150425435, "actor_loss": -32.40486604499817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14642858505249, "step": 113000}
{"episode_reward": 148.67908357725003, "episode": 114.0, "batch_reward": 0.24795192836225033, "critic_loss": 0.41942612965404985, "actor_loss": -32.52286435890198, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.973625659942627, "step": 114000}
{"episode_reward": 508.06538206272717, "episode": 115.0, "batch_reward": 0.2499683425575495, "critic_loss": 0.447468249335885, "actor_loss": -32.11588394165039, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.313470602035522, "step": 115000}
{"episode_reward": 338.70824199237774, "episode": 116.0, "batch_reward": 0.2511260981857777, "critic_loss": 0.417264934360981, "actor_loss": -32.41206174850464, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.311664819717407, "step": 116000}
{"episode_reward": 283.14224720433646, "episode": 117.0, "batch_reward": 0.24918877916038037, "critic_loss": 0.4134436351656914, "actor_loss": -31.437031742095947, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.48885416984558, "step": 117000}
{"episode_reward": 397.06338440049245, "episode": 118.0, "batch_reward": 0.25236422403156755, "critic_loss": 0.4238169991970062, "actor_loss": -31.960970321655275, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.37769842147827, "step": 118000}
{"episode_reward": 247.19742377019728, "episode": 119.0, "batch_reward": 0.251217841565609, "critic_loss": 0.42401129913330077, "actor_loss": -31.932586399078367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.445616960525513, "step": 119000}
{"episode_reward": 128.07443512640737, "episode": 120.0, "batch_reward": 0.2511558411717415, "critic_loss": 0.4227331277877092, "actor_loss": -31.962550258636476, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.61312961578369, "step": 120000}
{"episode_reward": 397.60981272915365, "episode": 121.0, "batch_reward": 0.25279269632697104, "critic_loss": 0.44877510897815226, "actor_loss": -32.02106270217895, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.15511870384216, "step": 121000}
{"episode_reward": 536.7640626865185, "episode": 122.0, "batch_reward": 0.2548500058054924, "critic_loss": 0.4342494917064905, "actor_loss": -32.482846500396725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.69015622138977, "step": 122000}
{"episode_reward": 376.1184127369832, "episode": 123.0, "batch_reward": 0.25501890197396276, "critic_loss": 0.4736875944584608, "actor_loss": -32.824654409408566, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.63977313041687, "step": 123000}
{"episode_reward": 263.61767474793277, "episode": 124.0, "batch_reward": 0.2548912180662155, "critic_loss": 0.45885747806727883, "actor_loss": -32.63821075057984, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.125577926635742, "step": 124000}
{"episode_reward": 443.49695302853553, "episode": 125.0, "batch_reward": 0.25689196653664115, "critic_loss": 0.45028662513196466, "actor_loss": -32.71961060714722, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.10180115699768, "step": 125000}
{"episode_reward": 408.86178591165685, "episode": 126.0, "batch_reward": 0.25864128048717977, "critic_loss": 0.4858859285414219, "actor_loss": -32.417933292388916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.72310709953308, "step": 126000}
{"episode_reward": 476.18512228177525, "episode": 127.0, "batch_reward": 0.25882025237381456, "critic_loss": 0.4518807116299868, "actor_loss": -32.40462166595459, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.160277605056763, "step": 127000}
{"episode_reward": 356.95199582492495, "episode": 128.0, "batch_reward": 0.26045674560964105, "critic_loss": 0.48156748339533806, "actor_loss": -32.646060695648195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.065649271011353, "step": 128000}
{"episode_reward": 487.91402917801344, "episode": 129.0, "batch_reward": 0.26322385695576667, "critic_loss": 0.4978291573822498, "actor_loss": -33.098419910430906, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.003939151763916, "step": 129000}
{"episode_reward": 542.6164557272608, "episode": 130.0, "batch_reward": 0.26566411586105826, "critic_loss": 0.4780229745358229, "actor_loss": -32.866429889678955, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.37071442604065, "step": 130000}
{"episode_reward": 311.8769922047658, "episode": 131.0, "batch_reward": 0.26559100292623045, "critic_loss": 0.47431948453187944, "actor_loss": -33.26568899536133, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.79824495315552, "step": 131000}
{"episode_reward": 339.833085431875, "episode": 132.0, "batch_reward": 0.2649487746059895, "critic_loss": 0.4681811033785343, "actor_loss": -33.62501049423218, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.79798936843872, "step": 132000}
{"episode_reward": 463.84221834758876, "episode": 133.0, "batch_reward": 0.2675539103150368, "critic_loss": 0.48605259726941585, "actor_loss": -33.332293119430545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.523465633392334, "step": 133000}
{"episode_reward": 471.2440618996767, "episode": 134.0, "batch_reward": 0.268104074254632, "critic_loss": 0.47642116390168665, "actor_loss": -33.079405490875246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.76149082183838, "step": 134000}
{"episode_reward": 477.58903303882187, "episode": 135.0, "batch_reward": 0.2704188005775213, "critic_loss": 0.46320642611384394, "actor_loss": -33.17788460922241, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.757922649383545, "step": 135000}
{"episode_reward": 530.9886152021762, "episode": 136.0, "batch_reward": 0.2726618547737598, "critic_loss": 0.47628501914441584, "actor_loss": -33.203693088531494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.568060398101807, "step": 136000}
{"episode_reward": 549.763746219694, "episode": 137.0, "batch_reward": 0.27402268835902216, "critic_loss": 0.46523244957625864, "actor_loss": -34.330275356292724, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.269770622253418, "step": 137000}
{"episode_reward": 456.1168159346291, "episode": 138.0, "batch_reward": 0.27669126451015474, "critic_loss": 0.4648107652813196, "actor_loss": -34.150285205841065, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.539475679397583, "step": 138000}
{"episode_reward": 522.4004942531683, "episode": 139.0, "batch_reward": 0.27840307013690474, "critic_loss": 0.4752475107908249, "actor_loss": -34.183475681304934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.84508204460144, "step": 139000}
{"episode_reward": 544.2576347230791, "episode": 140.0, "batch_reward": 0.28024773436784745, "critic_loss": 0.4812031233608723, "actor_loss": -34.11512232589722, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.44741201400757, "step": 140000}
{"episode_reward": 432.3281687721698, "episode": 141.0, "batch_reward": 0.28003584246337415, "critic_loss": 0.4561626352220774, "actor_loss": -34.680569316864016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.32929062843323, "step": 141000}
{"episode_reward": 507.92727952426844, "episode": 142.0, "batch_reward": 0.28147285360097885, "critic_loss": 0.48433532494306564, "actor_loss": -33.727314247131346, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.261922359466553, "step": 142000}
{"episode_reward": 489.54374102752905, "episode": 143.0, "batch_reward": 0.28317909280955794, "critic_loss": 0.46798927034437654, "actor_loss": -34.17257526397705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.720017194747925, "step": 143000}
{"episode_reward": 488.3942639309288, "episode": 144.0, "batch_reward": 0.2853068668991327, "critic_loss": 0.4955195184201002, "actor_loss": -34.77452294921875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.386544227600098, "step": 144000}
{"episode_reward": 446.3497291732971, "episode": 145.0, "batch_reward": 0.2870540743917227, "critic_loss": 0.4849090160280466, "actor_loss": -35.259394874572756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.068373918533325, "step": 145000}
{"episode_reward": 341.76671474325474, "episode": 146.0, "batch_reward": 0.2865055765658617, "critic_loss": 0.5079929189532996, "actor_loss": -35.00354578781128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.858248233795166, "step": 146000}
{"episode_reward": 488.44715809250283, "episode": 147.0, "batch_reward": 0.2876154780089855, "critic_loss": 0.48412253510951997, "actor_loss": -34.71698695755005, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.94598126411438, "step": 147000}
{"episode_reward": 491.245331222819, "episode": 148.0, "batch_reward": 0.28953707419335845, "critic_loss": 0.5607811073660851, "actor_loss": -35.486964015960694, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.01234197616577, "step": 148000}
{"episode_reward": 487.84131129821617, "episode": 149.0, "batch_reward": 0.29071974828839303, "critic_loss": 0.5476199585050344, "actor_loss": -34.797072677612306, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54062581062317, "step": 149000}
{"episode_reward": 510.2811987373166, "episode": 150.0, "batch_reward": 0.29215668053925037, "critic_loss": 0.4841280502676964, "actor_loss": -35.58213187789917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
