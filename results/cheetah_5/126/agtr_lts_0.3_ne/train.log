{"episode_reward": 0.0, "episode": 1.0, "duration": 17.246519088745117, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.4842660427093506, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.2526572412125227, "critic_loss": 0.25683580373114806, "actor_loss": -47.71509294483174, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.03040194511414, "step": 3000}
{"episode_reward": 99.56951727104375, "episode": 4.0, "batch_reward": 0.18191578786075116, "critic_loss": 0.5278723850250244, "actor_loss": -52.502846954345706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93366289138794, "step": 4000}
{"episode_reward": 4.341835183467565, "episode": 5.0, "batch_reward": 0.14416761268675327, "critic_loss": 1.2797197400331497, "actor_loss": -56.93958640289306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97797679901123, "step": 5000}
{"episode_reward": 16.189174633346937, "episode": 6.0, "batch_reward": 0.12526366018131374, "critic_loss": 1.4274759322404862, "actor_loss": -60.81823165130615, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.953505754470825, "step": 6000}
{"episode_reward": 84.25345598925738, "episode": 7.0, "batch_reward": 0.11537322803586722, "critic_loss": 2.1227245718240737, "actor_loss": -62.10003518676758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96885633468628, "step": 7000}
{"episode_reward": 16.120200462218502, "episode": 8.0, "batch_reward": 0.10051169657334685, "critic_loss": 2.867869197130203, "actor_loss": -66.95230600357056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97839593887329, "step": 8000}
{"episode_reward": 0.7674630846989746, "episode": 9.0, "batch_reward": 0.08802075818181038, "critic_loss": 4.209702615499497, "actor_loss": -72.29925486373901, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97756838798523, "step": 9000}
{"episode_reward": 1.4010569636540287, "episode": 10.0, "batch_reward": 0.07970336656272412, "critic_loss": 3.6494323292970656, "actor_loss": -73.90546573257447, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.970669984817505, "step": 10000}
{"episode_reward": 5.699478835606993, "episode": 11.0, "batch_reward": 0.07250054610148073, "critic_loss": 2.1781984493732454, "actor_loss": -78.59646599197387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.38719320297241, "step": 11000}
{"episode_reward": 6.27443162050976, "episode": 12.0, "batch_reward": 0.0672614779509604, "critic_loss": 1.6622692062854767, "actor_loss": -75.9853865890503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.960024118423462, "step": 12000}
{"episode_reward": 8.627350921793159, "episode": 13.0, "batch_reward": 0.06261290013976395, "critic_loss": 1.277365412592888, "actor_loss": -78.36930317306519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9798264503479, "step": 13000}
{"episode_reward": 7.566689418433351, "episode": 14.0, "batch_reward": 0.05745598683692515, "critic_loss": 1.210249549150467, "actor_loss": -76.64438320922852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.966201782226562, "step": 14000}
{"episode_reward": 0.6272155890876872, "episode": 15.0, "batch_reward": 0.053877536609768864, "critic_loss": 1.1191183156371116, "actor_loss": -78.65598017501831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.938897609710693, "step": 15000}
{"episode_reward": 0.0, "episode": 16.0, "batch_reward": 0.049661937687546016, "critic_loss": 0.9743371217250824, "actor_loss": -69.56592258071899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.940247774124146, "step": 16000}
{"episode_reward": 0.0, "episode": 17.0, "batch_reward": 0.0473159289304167, "critic_loss": 0.8471713212132453, "actor_loss": -67.76685287475586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.963327169418335, "step": 17000}
{"episode_reward": 0.006755483289306419, "episode": 18.0, "batch_reward": 0.044410529188811776, "critic_loss": 0.7275319686830044, "actor_loss": -67.4233899345398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.976699829101562, "step": 18000}
{"episode_reward": 8.970202803953597, "episode": 19.0, "batch_reward": 0.04377307273447514, "critic_loss": 0.7247723813354969, "actor_loss": -65.43842557525635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.980948209762573, "step": 19000}
{"episode_reward": 46.55639647233053, "episode": 20.0, "batch_reward": 0.04337608686182648, "critic_loss": 0.7178800295293332, "actor_loss": -65.87258382034302, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.966782808303833, "step": 20000}
{"episode_reward": 9.29724995197702, "episode": 21.0, "batch_reward": 0.04106400124076754, "critic_loss": 0.6555396151840687, "actor_loss": -62.99480365753174, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.286779165267944, "step": 21000}
{"episode_reward": 46.34116292755423, "episode": 22.0, "batch_reward": 0.04421315997093916, "critic_loss": 0.8198575703799724, "actor_loss": -63.13332328796387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.961495399475098, "step": 22000}
{"episode_reward": 174.1236034877078, "episode": 23.0, "batch_reward": 0.050376443788409234, "critic_loss": 1.112759868234396, "actor_loss": -60.01821161651611, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.965593576431274, "step": 23000}
{"episode_reward": 208.338564306556, "episode": 24.0, "batch_reward": 0.059008885258808735, "critic_loss": 1.2259110158383846, "actor_loss": -59.80206366729736, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.968197107315063, "step": 24000}
{"episode_reward": 342.1571158016998, "episode": 25.0, "batch_reward": 0.07028757968358695, "critic_loss": 1.324348639369011, "actor_loss": -59.486814453125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.260255336761475, "step": 25000}
{"episode_reward": 336.54297373054106, "episode": 26.0, "batch_reward": 0.07824027078971267, "critic_loss": 1.4040075953006745, "actor_loss": -59.544588710784915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.953396320343018, "step": 26000}
{"episode_reward": 46.69521931668754, "episode": 27.0, "batch_reward": 0.0822100706025958, "critic_loss": 1.3008021138906478, "actor_loss": -59.491972248077396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.932809114456177, "step": 27000}
{"episode_reward": 340.6981249503105, "episode": 28.0, "batch_reward": 0.09078723245486617, "critic_loss": 1.3211880727410317, "actor_loss": -57.77691911697388, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.231252670288086, "step": 28000}
{"episode_reward": 341.0004549624154, "episode": 29.0, "batch_reward": 0.09923499737679958, "critic_loss": 1.3095425361990929, "actor_loss": -59.60067865753174, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.932023525238037, "step": 29000}
{"episode_reward": 261.56574782760566, "episode": 30.0, "batch_reward": 0.10377891168370842, "critic_loss": 1.2757425793409347, "actor_loss": -56.9299548072815, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.900498151779175, "step": 30000}
{"episode_reward": 346.19668439461583, "episode": 31.0, "batch_reward": 0.11396753761544824, "critic_loss": 1.2092596758008003, "actor_loss": -56.37840483856201, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.22280168533325, "step": 31000}
{"episode_reward": 313.00293346726426, "episode": 32.0, "batch_reward": 0.11838534902781248, "critic_loss": 1.110217210650444, "actor_loss": -56.55246347045898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96260094642639, "step": 32000}
{"episode_reward": 285.9993574298874, "episode": 33.0, "batch_reward": 0.1253267604112625, "critic_loss": 1.0029788794517518, "actor_loss": -56.56657629776001, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.945162057876587, "step": 33000}
{"episode_reward": 397.13427918146454, "episode": 34.0, "batch_reward": 0.13322730711847544, "critic_loss": 0.9305393847227097, "actor_loss": -53.94073943710327, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.935314416885376, "step": 34000}
{"episode_reward": 409.6428793773706, "episode": 35.0, "batch_reward": 0.13848952781409024, "critic_loss": 0.8439876042604446, "actor_loss": -53.806979263305664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.935174703598022, "step": 35000}
{"episode_reward": 194.97152606837196, "episode": 36.0, "batch_reward": 0.1428482168763876, "critic_loss": 0.7678877093195915, "actor_loss": -52.03129527664185, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92948317527771, "step": 36000}
{"episode_reward": 333.452642507558, "episode": 37.0, "batch_reward": 0.14751227195560931, "critic_loss": 0.7202256508171558, "actor_loss": -50.84361351013184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.952613353729248, "step": 37000}
{"episode_reward": 340.8137474605855, "episode": 38.0, "batch_reward": 0.15231131445616483, "critic_loss": 0.693282354325056, "actor_loss": -51.1273032875061, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.963534116744995, "step": 38000}
{"episode_reward": 268.4578792787863, "episode": 39.0, "batch_reward": 0.15617864733189343, "critic_loss": 0.6572363608181476, "actor_loss": -49.27108590316772, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.975203037261963, "step": 39000}
{"episode_reward": 324.57099858527306, "episode": 40.0, "batch_reward": 0.15867426890879868, "critic_loss": 0.6065026854276657, "actor_loss": -47.80354537582397, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.963934421539307, "step": 40000}
{"episode_reward": 268.92675272624757, "episode": 41.0, "batch_reward": 0.16132894495129585, "critic_loss": 0.5817498185634613, "actor_loss": -46.618081562042235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.28977012634277, "step": 41000}
{"episode_reward": 281.887695707291, "episode": 42.0, "batch_reward": 0.16355670370161535, "critic_loss": 0.5518562212586403, "actor_loss": -45.789558361053466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.971293449401855, "step": 42000}
{"episode_reward": 144.9804012202993, "episode": 43.0, "batch_reward": 0.16521875084191562, "critic_loss": 0.5166533544361591, "actor_loss": -44.53739556121826, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9579598903656, "step": 43000}
{"episode_reward": 388.2600914326337, "episode": 44.0, "batch_reward": 0.17178659225255252, "critic_loss": 0.5016127499341965, "actor_loss": -43.88615472793579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.971778392791748, "step": 44000}
{"episode_reward": 447.32096505648036, "episode": 45.0, "batch_reward": 0.1780175684094429, "critic_loss": 0.5149840696752072, "actor_loss": -43.58354712677002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9545419216156, "step": 45000}
{"episode_reward": 474.36114586930563, "episode": 46.0, "batch_reward": 0.1842363414913416, "critic_loss": 0.4946514944434166, "actor_loss": -42.664599605560305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95257306098938, "step": 46000}
{"episode_reward": 475.6424009443483, "episode": 47.0, "batch_reward": 0.1889324867874384, "critic_loss": 0.47722894716262815, "actor_loss": -41.708426921844485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94061827659607, "step": 47000}
{"episode_reward": 241.67015890056297, "episode": 48.0, "batch_reward": 0.18992274188995362, "critic_loss": 0.4419494604617357, "actor_loss": -41.48013590621948, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9471275806427, "step": 48000}
{"episode_reward": 310.757546939878, "episode": 49.0, "batch_reward": 0.19238534219563008, "critic_loss": 0.44847041530907156, "actor_loss": -40.50312441253662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.972632884979248, "step": 49000}
{"episode_reward": 128.12744032967328, "episode": 50.0, "batch_reward": 0.1923440187871456, "critic_loss": 0.4383067897260189, "actor_loss": -39.22767611694336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.948612689971924, "step": 50000}
{"episode_reward": 482.29514669582306, "episode": 51.0, "batch_reward": 0.19810711880028248, "critic_loss": 0.4311641593873501, "actor_loss": -39.41607495498657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.18202757835388, "step": 51000}
{"episode_reward": 438.54908695398456, "episode": 52.0, "batch_reward": 0.20076857408881188, "critic_loss": 0.4205887544155121, "actor_loss": -38.30171923828125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.966697931289673, "step": 52000}
{"episode_reward": 212.62798989199686, "episode": 53.0, "batch_reward": 0.20204314506053925, "critic_loss": 0.4219156593382359, "actor_loss": -37.67217479324341, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.938970804214478, "step": 53000}
{"episode_reward": 243.42875017026296, "episode": 54.0, "batch_reward": 0.20396771344542503, "critic_loss": 0.4325187315791845, "actor_loss": -36.88973399734497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.960899829864502, "step": 54000}
{"episode_reward": 519.945695502716, "episode": 55.0, "batch_reward": 0.20736630848050117, "critic_loss": 0.4410397285223007, "actor_loss": -36.45968608093262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94357132911682, "step": 55000}
{"episode_reward": 154.89074820947118, "episode": 56.0, "batch_reward": 0.20668278965353964, "critic_loss": 0.4233132611811161, "actor_loss": -35.95171088027954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.916792631149292, "step": 56000}
{"episode_reward": 347.5290367578052, "episode": 57.0, "batch_reward": 0.21241042341291905, "critic_loss": 0.4146379672139883, "actor_loss": -35.52696628189087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.934455394744873, "step": 57000}
{"episode_reward": 548.6878341722244, "episode": 58.0, "batch_reward": 0.2165619853436947, "critic_loss": 0.42131672230362893, "actor_loss": -35.43631777191162, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92768907546997, "step": 58000}
{"episode_reward": 269.0268625657735, "episode": 59.0, "batch_reward": 0.2180633212774992, "critic_loss": 0.40643447364866736, "actor_loss": -34.827270027160644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92985725402832, "step": 59000}
{"episode_reward": 458.8139447704776, "episode": 60.0, "batch_reward": 0.2211792723685503, "critic_loss": 0.4116222605109215, "actor_loss": -34.67677529144287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94286799430847, "step": 60000}
{"episode_reward": 471.3001385895126, "episode": 61.0, "batch_reward": 0.22637761779129506, "critic_loss": 0.42673000586032866, "actor_loss": -34.529964157104494, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.17952513694763, "step": 61000}
{"episode_reward": 500.9823076433943, "episode": 62.0, "batch_reward": 0.2305303938537836, "critic_loss": 0.44838833925127985, "actor_loss": -34.67894631195068, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94017481803894, "step": 62000}
{"episode_reward": 584.7528697763759, "episode": 63.0, "batch_reward": 0.23525588573515416, "critic_loss": 0.44728934940695764, "actor_loss": -34.768956615448, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.957489490509033, "step": 63000}
{"episode_reward": 370.3064340468605, "episode": 64.0, "batch_reward": 0.23630709286034107, "critic_loss": 0.4406015261411667, "actor_loss": -34.594487865447995, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95666217803955, "step": 64000}
{"episode_reward": 116.41878272583882, "episode": 65.0, "batch_reward": 0.2366501004844904, "critic_loss": 0.46040875312685964, "actor_loss": -34.378978324890134, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.952122926712036, "step": 65000}
{"episode_reward": 549.6610741051871, "episode": 66.0, "batch_reward": 0.24254029811918734, "critic_loss": 0.4613749389499426, "actor_loss": -34.40945464324951, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.961026430130005, "step": 66000}
{"episode_reward": 606.249832310894, "episode": 67.0, "batch_reward": 0.24685694339871406, "critic_loss": 0.4799907484203577, "actor_loss": -34.38163862991333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98277997970581, "step": 67000}
{"episode_reward": 410.32936570852524, "episode": 68.0, "batch_reward": 0.2466780534237623, "critic_loss": 0.49245108568668366, "actor_loss": -34.220884738922116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96074390411377, "step": 68000}
{"episode_reward": 48.03470485829146, "episode": 69.0, "batch_reward": 0.24823944893479347, "critic_loss": 0.4812457595020533, "actor_loss": -33.98880300521851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93110966682434, "step": 69000}
{"episode_reward": 587.5828707451332, "episode": 70.0, "batch_reward": 0.25185135240852835, "critic_loss": 0.46428233897686005, "actor_loss": -34.15653197860718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.960291624069214, "step": 70000}
{"episode_reward": 467.2109549268653, "episode": 71.0, "batch_reward": 0.2535684241503477, "critic_loss": 0.46287758652865885, "actor_loss": -34.056757377624514, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.24890398979187, "step": 71000}
{"episode_reward": 564.7739903856595, "episode": 72.0, "batch_reward": 0.2596673611402512, "critic_loss": 0.4592524677813053, "actor_loss": -34.48742625808716, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.958996534347534, "step": 72000}
{"episode_reward": 605.3951569136997, "episode": 73.0, "batch_reward": 0.26232429018616676, "critic_loss": 0.4576560153216124, "actor_loss": -34.63250522613525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95655131340027, "step": 73000}
{"episode_reward": 539.0897370542594, "episode": 74.0, "batch_reward": 0.26554277043044566, "critic_loss": 0.44870105470716953, "actor_loss": -34.799469242095945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94866371154785, "step": 74000}
{"episode_reward": 123.40918634890495, "episode": 75.0, "batch_reward": 0.26687006805837155, "critic_loss": 0.47415596958994866, "actor_loss": -34.78898788452148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.940958261489868, "step": 75000}
{"episode_reward": 553.2264081441218, "episode": 76.0, "batch_reward": 0.2700304355174303, "critic_loss": 0.4739496412873268, "actor_loss": -34.988153900146486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.935572624206543, "step": 76000}
{"episode_reward": 633.0419804570396, "episode": 77.0, "batch_reward": 0.274404794678092, "critic_loss": 0.46358172845840456, "actor_loss": -35.012901237487796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.936151027679443, "step": 77000}
{"episode_reward": 564.3502140182393, "episode": 78.0, "batch_reward": 0.27822197273373606, "critic_loss": 0.4389957258552313, "actor_loss": -35.06523392486572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.971020221710205, "step": 78000}
{"episode_reward": 594.2382681976047, "episode": 79.0, "batch_reward": 0.2823680172115564, "critic_loss": 0.42534747226536274, "actor_loss": -35.27409425735473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.949780225753784, "step": 79000}
{"episode_reward": 675.0347950958956, "episode": 80.0, "batch_reward": 0.2872180836200714, "critic_loss": 0.42702956491708755, "actor_loss": -35.468641639709475, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.974884510040283, "step": 80000}
{"episode_reward": 527.4569102290444, "episode": 81.0, "batch_reward": 0.2903213067352772, "critic_loss": 0.41973921813070775, "actor_loss": -35.634905437469484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.21716237068176, "step": 81000}
{"episode_reward": 604.4783742160539, "episode": 82.0, "batch_reward": 0.292934741795063, "critic_loss": 0.40945430189371107, "actor_loss": -35.66492848587036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.950622081756592, "step": 82000}
{"episode_reward": 581.0111802685667, "episode": 83.0, "batch_reward": 0.2962756992727518, "critic_loss": 0.42043691672384736, "actor_loss": -35.75593166351318, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.973016023635864, "step": 83000}
{"episode_reward": 591.3510603332835, "episode": 84.0, "batch_reward": 0.3002230647802353, "critic_loss": 0.39864135427773, "actor_loss": -35.97331873703003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95477056503296, "step": 84000}
{"episode_reward": 574.979610972044, "episode": 85.0, "batch_reward": 0.3026660191267729, "critic_loss": 0.39583019572496414, "actor_loss": -35.96339961624145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.935405492782593, "step": 85000}
{"episode_reward": 632.8138778191725, "episode": 86.0, "batch_reward": 0.3083924734443426, "critic_loss": 0.39408865904808044, "actor_loss": -36.466940162658695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.965232133865356, "step": 86000}
{"episode_reward": 635.9435100192061, "episode": 87.0, "batch_reward": 0.31152991938591, "critic_loss": 0.40061308425664904, "actor_loss": -36.67354776763916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.958049058914185, "step": 87000}
{"episode_reward": 600.442040544711, "episode": 88.0, "batch_reward": 0.31598558524250986, "critic_loss": 0.41214565926790236, "actor_loss": -36.91790980529785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.953072547912598, "step": 88000}
{"episode_reward": 616.6419056294351, "episode": 89.0, "batch_reward": 0.31789321726560593, "critic_loss": 0.4101989523023367, "actor_loss": -37.067615421295166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95073676109314, "step": 89000}
{"episode_reward": 260.73302708895466, "episode": 90.0, "batch_reward": 0.3165921241641045, "critic_loss": 0.42775901494920254, "actor_loss": -36.97241206359863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98070001602173, "step": 90000}
{"episode_reward": 139.65275002451884, "episode": 91.0, "batch_reward": 0.31621155408024787, "critic_loss": 0.4496837565600872, "actor_loss": -36.84362311553955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.25604462623596, "step": 91000}
{"episode_reward": 601.6611158786054, "episode": 92.0, "batch_reward": 0.31914517405629156, "critic_loss": 0.45598694729804995, "actor_loss": -37.15610068893432, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95592975616455, "step": 92000}
{"episode_reward": 635.0946260455844, "episode": 93.0, "batch_reward": 0.3227354005873203, "critic_loss": 0.43985650457441805, "actor_loss": -37.450689834594726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.971862316131592, "step": 93000}
{"episode_reward": 652.3686813879227, "episode": 94.0, "batch_reward": 0.3266805016696453, "critic_loss": 0.41504376831650736, "actor_loss": -37.652635627746584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95171308517456, "step": 94000}
{"episode_reward": 607.5880354713105, "episode": 95.0, "batch_reward": 0.3293545013666153, "critic_loss": 0.4164541150331497, "actor_loss": -37.652249870300295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93713092803955, "step": 95000}
{"episode_reward": 639.150610454516, "episode": 96.0, "batch_reward": 0.33263466623425486, "critic_loss": 0.4259764323681593, "actor_loss": -38.118607421875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.970065116882324, "step": 96000}
{"episode_reward": 617.683694653826, "episode": 97.0, "batch_reward": 0.3347613070309162, "critic_loss": 0.40060814687609675, "actor_loss": -38.19203134918213, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.963773012161255, "step": 97000}
{"episode_reward": 645.606695316784, "episode": 98.0, "batch_reward": 0.33736006113886835, "critic_loss": 0.395032035946846, "actor_loss": -38.23355593109131, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.969629287719727, "step": 98000}
{"episode_reward": 554.9306212608801, "episode": 99.0, "batch_reward": 0.3406960899233818, "critic_loss": 0.3854151435643435, "actor_loss": -38.705831619262696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96202802658081, "step": 99000}
{"episode_reward": 588.3173251609616, "episode": 100.0, "batch_reward": 0.34134477260708807, "critic_loss": 0.3950091380774975, "actor_loss": -38.592130676269534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.957817792892456, "step": 100000}
{"episode_reward": 652.3142406831531, "episode": 101.0, "batch_reward": 0.347477768778801, "critic_loss": 0.38772634004056455, "actor_loss": -38.98687851715088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.24840521812439, "step": 101000}
{"episode_reward": 647.0570298824919, "episode": 102.0, "batch_reward": 0.3489429545104504, "critic_loss": 0.38902722506225107, "actor_loss": -39.02186794281006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95527696609497, "step": 102000}
{"episode_reward": 579.7038512699526, "episode": 103.0, "batch_reward": 0.35178087663650515, "critic_loss": 0.38966743329167364, "actor_loss": -39.17524931335449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95559525489807, "step": 103000}
{"episode_reward": 616.2053483539399, "episode": 104.0, "batch_reward": 0.3530402658581734, "critic_loss": 0.3833709768205881, "actor_loss": -39.32149043273926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.956642389297485, "step": 104000}
{"episode_reward": 636.0758532974068, "episode": 105.0, "batch_reward": 0.357500303119421, "critic_loss": 0.38210191409289834, "actor_loss": -39.64935818481445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.959468841552734, "step": 105000}
{"episode_reward": 604.4722717108117, "episode": 106.0, "batch_reward": 0.3576476962864399, "critic_loss": 0.38983910901844504, "actor_loss": -39.733719734191894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.955865383148193, "step": 106000}
{"episode_reward": 594.0376149677987, "episode": 107.0, "batch_reward": 0.3617043226659298, "critic_loss": 0.3998122304975987, "actor_loss": -39.93952761077881, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.933680534362793, "step": 107000}
{"episode_reward": 662.0616842266604, "episode": 108.0, "batch_reward": 0.3625447291135788, "critic_loss": 0.40880273462831973, "actor_loss": -39.774010833740235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.956546783447266, "step": 108000}
{"episode_reward": 369.6338031149347, "episode": 109.0, "batch_reward": 0.36335988050699236, "critic_loss": 0.4059085415452719, "actor_loss": -39.94343958282471, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96159839630127, "step": 109000}
{"episode_reward": 642.6227777759647, "episode": 110.0, "batch_reward": 0.3675679233968258, "critic_loss": 0.4210568032860756, "actor_loss": -40.28407566070557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95693349838257, "step": 110000}
{"episode_reward": 646.4591571723261, "episode": 111.0, "batch_reward": 0.36827044624090194, "critic_loss": 0.41750725696980956, "actor_loss": -40.174652839660645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.25078797340393, "step": 111000}
{"episode_reward": 586.8137971605275, "episode": 112.0, "batch_reward": 0.37094306644797326, "critic_loss": 0.4141234279423952, "actor_loss": -40.538909378051756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.963991403579712, "step": 112000}
{"episode_reward": 607.6728722426983, "episode": 113.0, "batch_reward": 0.3730854221284389, "critic_loss": 0.4141149453371763, "actor_loss": -40.61285234069824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.955135345458984, "step": 113000}
{"episode_reward": 681.6516396619601, "episode": 114.0, "batch_reward": 0.37468166860938074, "critic_loss": 0.4049544893354177, "actor_loss": -40.79716355895996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.945190906524658, "step": 114000}
{"episode_reward": 557.7494917259942, "episode": 115.0, "batch_reward": 0.37550382408499716, "critic_loss": 0.4220597697198391, "actor_loss": -40.750798301696776, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95480179786682, "step": 115000}
{"episode_reward": 505.98509928006547, "episode": 116.0, "batch_reward": 0.3799700976908207, "critic_loss": 0.43848684169352053, "actor_loss": -40.991499542236326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.956190586090088, "step": 116000}
{"episode_reward": 610.3244093918381, "episode": 117.0, "batch_reward": 0.37867385026812556, "critic_loss": 0.46625545562803744, "actor_loss": -40.91426188659668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9560546875, "step": 117000}
{"episode_reward": 531.2059763627964, "episode": 118.0, "batch_reward": 0.3825485519170761, "critic_loss": 0.45416304165124893, "actor_loss": -41.3792483291626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9685161113739, "step": 118000}
{"episode_reward": 649.0169351791782, "episode": 119.0, "batch_reward": 0.38427677911520003, "critic_loss": 0.43855775609612463, "actor_loss": -41.595058158874515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96180558204651, "step": 119000}
{"episode_reward": 668.5801999695851, "episode": 120.0, "batch_reward": 0.38583706539869306, "critic_loss": 0.4149165739119053, "actor_loss": -41.44812900543213, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.956112384796143, "step": 120000}
{"episode_reward": 517.5621198882426, "episode": 121.0, "batch_reward": 0.3862567286193371, "critic_loss": 0.41900351355969906, "actor_loss": -41.73198644256592, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.27641272544861, "step": 121000}
{"episode_reward": 672.9658152598427, "episode": 122.0, "batch_reward": 0.3904422576725483, "critic_loss": 0.42225237891077994, "actor_loss": -41.87141715240479, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.968824863433838, "step": 122000}
{"episode_reward": 665.8208431535892, "episode": 123.0, "batch_reward": 0.39110979440808297, "critic_loss": 0.42991839212179184, "actor_loss": -42.04476941680908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94469666481018, "step": 123000}
{"episode_reward": 390.40989228333655, "episode": 124.0, "batch_reward": 0.3917898968160152, "critic_loss": 0.43288826690614224, "actor_loss": -41.98578220367432, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.939714670181274, "step": 124000}
{"episode_reward": 655.2919320861307, "episode": 125.0, "batch_reward": 0.39469963786005974, "critic_loss": 0.4159893614947796, "actor_loss": -42.24961750030518, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.948904752731323, "step": 125000}
{"episode_reward": 657.8794529019813, "episode": 126.0, "batch_reward": 0.3961909901201725, "critic_loss": 0.4339455276578665, "actor_loss": -42.187066635131835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.939664602279663, "step": 126000}
{"episode_reward": 697.4346389923181, "episode": 127.0, "batch_reward": 0.3974563479721546, "critic_loss": 0.41720904245972634, "actor_loss": -42.55411987304687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.943952560424805, "step": 127000}
{"episode_reward": 662.818828617927, "episode": 128.0, "batch_reward": 0.39991536757349966, "critic_loss": 0.41555548544228077, "actor_loss": -42.85981966400146, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96666693687439, "step": 128000}
{"episode_reward": 671.3737509708428, "episode": 129.0, "batch_reward": 0.40231078732013703, "critic_loss": 0.4230967654287815, "actor_loss": -42.92307517242432, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.962382555007935, "step": 129000}
{"episode_reward": 679.7928310907121, "episode": 130.0, "batch_reward": 0.4048353110551834, "critic_loss": 0.4225640699863434, "actor_loss": -43.078324798583985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.973315238952637, "step": 130000}
{"episode_reward": 162.12324805702042, "episode": 131.0, "batch_reward": 0.40278659561276436, "critic_loss": 0.43094846430420874, "actor_loss": -42.84711938476563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.268662452697754, "step": 131000}
{"episode_reward": 620.4815153865936, "episode": 132.0, "batch_reward": 0.40337699350714684, "critic_loss": 0.4247594043761492, "actor_loss": -43.054491569519044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.967347145080566, "step": 132000}
{"episode_reward": 666.5536294885277, "episode": 133.0, "batch_reward": 0.4077853660285473, "critic_loss": 0.43394539842009544, "actor_loss": -43.17019596862793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.963857173919678, "step": 133000}
{"episode_reward": 662.9220307691357, "episode": 134.0, "batch_reward": 0.4082318267822266, "critic_loss": 0.4159460602104664, "actor_loss": -43.39262786865234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.967025756835938, "step": 134000}
{"episode_reward": 605.8822391321139, "episode": 135.0, "batch_reward": 0.41114635986089704, "critic_loss": 0.42630476292967795, "actor_loss": -43.75630039215088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.964125394821167, "step": 135000}
{"episode_reward": 663.5899583192203, "episode": 136.0, "batch_reward": 0.4127901585102081, "critic_loss": 0.4380893207937479, "actor_loss": -43.737615531921385, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.956870555877686, "step": 136000}
{"episode_reward": 695.5249001620289, "episode": 137.0, "batch_reward": 0.4142985624372959, "critic_loss": 0.4203330490887165, "actor_loss": -44.20035990905762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.961769580841064, "step": 137000}
{"episode_reward": 682.742572882488, "episode": 138.0, "batch_reward": 0.418080850481987, "critic_loss": 0.42426067277789115, "actor_loss": -44.434772888183595, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.953269243240356, "step": 138000}
{"episode_reward": 681.8035646073391, "episode": 139.0, "batch_reward": 0.4189210366010666, "critic_loss": 0.4150049723684788, "actor_loss": -44.40976088714599, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96214461326599, "step": 139000}
{"episode_reward": 697.0246561063278, "episode": 140.0, "batch_reward": 0.4203905356824398, "critic_loss": 0.4189481621980667, "actor_loss": -44.6137677154541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.962592840194702, "step": 140000}
{"episode_reward": 584.1294558122646, "episode": 141.0, "batch_reward": 0.42110452657938, "critic_loss": 0.41392088705301283, "actor_loss": -44.63265991973877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.26724433898926, "step": 141000}
{"episode_reward": 666.2730459381165, "episode": 142.0, "batch_reward": 0.422229568451643, "critic_loss": 0.4118241581320763, "actor_loss": -44.61052882385254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96878147125244, "step": 142000}
{"episode_reward": 700.6865784981326, "episode": 143.0, "batch_reward": 0.42489808559417724, "critic_loss": 0.4121139409840107, "actor_loss": -44.9785873413086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.949598789215088, "step": 143000}
{"episode_reward": 677.1552860998138, "episode": 144.0, "batch_reward": 0.4282108251154423, "critic_loss": 0.39831676188111304, "actor_loss": -45.26271057891846, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.927196502685547, "step": 144000}
{"episode_reward": 631.408791121781, "episode": 145.0, "batch_reward": 0.4289456054568291, "critic_loss": 0.4038798454552889, "actor_loss": -45.38434007263184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.935603380203247, "step": 145000}
{"episode_reward": 640.633293577806, "episode": 146.0, "batch_reward": 0.42935455006361006, "critic_loss": 0.40575315864384176, "actor_loss": -45.43385424041748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.952855587005615, "step": 146000}
{"episode_reward": 695.6326318738189, "episode": 147.0, "batch_reward": 0.43103337025642396, "critic_loss": 0.3979075794667006, "actor_loss": -45.648155227661135, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.935147762298584, "step": 147000}
{"episode_reward": 656.0610619371323, "episode": 148.0, "batch_reward": 0.4329731796383858, "critic_loss": 0.3997105498760939, "actor_loss": -45.80806309509278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.956496238708496, "step": 148000}
{"episode_reward": 579.4541820535676, "episode": 149.0, "batch_reward": 0.4335866328477859, "critic_loss": 0.40386679175496104, "actor_loss": -45.841111038208005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.953055381774902, "step": 149000}
{"episode_reward": 675.3511165634751, "episode": 150.0, "batch_reward": 0.43584310659766196, "critic_loss": 0.401287009999156, "actor_loss": -46.070502182006834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
