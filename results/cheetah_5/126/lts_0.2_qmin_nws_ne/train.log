{"episode_reward": 0.0, "episode": 1.0, "duration": 17.882264852523804, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.5315494537353516, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.24820807677044318, "critic_loss": 0.01753343624188917, "actor_loss": -12.083419900050625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 68.70385360717773, "step": 3000}
{"episode_reward": 5.9775658368233175, "episode": 4.0, "batch_reward": 0.15542580055445432, "critic_loss": 0.010104278936050832, "actor_loss": -12.508408270835876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.882137298583984, "step": 4000}
{"episode_reward": 7.457028564878788, "episode": 5.0, "batch_reward": 0.12276086444407701, "critic_loss": 0.008104822027264163, "actor_loss": -12.290194108963012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.005980491638184, "step": 5000}
{"episode_reward": 9.41367547612169, "episode": 6.0, "batch_reward": 0.1023011833615601, "critic_loss": 0.01590820631501265, "actor_loss": -11.485025769233703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.023740530014038, "step": 6000}
{"episode_reward": 11.761285998529143, "episode": 7.0, "batch_reward": 0.08809650924056768, "critic_loss": 0.011064554270589725, "actor_loss": -10.6144022397995, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.26800847053528, "step": 7000}
{"episode_reward": 7.1700520963695915, "episode": 8.0, "batch_reward": 0.0770550285987556, "critic_loss": 0.012095424986211583, "actor_loss": -12.20569368171692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.333332777023315, "step": 8000}
{"episode_reward": 8.429162227646522, "episode": 9.0, "batch_reward": 0.06842251810431481, "critic_loss": 0.010580931494478136, "actor_loss": -11.268917419433594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.353724241256714, "step": 9000}
{"episode_reward": 10.029624796579089, "episode": 10.0, "batch_reward": 0.06274268035963178, "critic_loss": 0.00919297866569832, "actor_loss": -10.83511808204651, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.125962257385254, "step": 10000}
{"episode_reward": 7.2339140708656435, "episode": 11.0, "batch_reward": 0.057085524344816806, "critic_loss": 0.0138136906970758, "actor_loss": -9.484464710235596, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.86010789871216, "step": 11000}
{"episode_reward": 7.5318568321422745, "episode": 12.0, "batch_reward": 0.053679200932383535, "critic_loss": 0.011982176259392872, "actor_loss": -10.75683378124237, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.98142695426941, "step": 12000}
{"episode_reward": 9.509122594270126, "episode": 13.0, "batch_reward": 0.04974478261917829, "critic_loss": 0.011011871145572514, "actor_loss": -9.529389712333678, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.216869115829468, "step": 13000}
{"episode_reward": 8.066403817774203, "episode": 14.0, "batch_reward": 0.04585068829357624, "critic_loss": 0.01196158125041984, "actor_loss": -8.942097970962525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.534961223602295, "step": 14000}
{"episode_reward": 7.752669015167594, "episode": 15.0, "batch_reward": 0.04392784617375582, "critic_loss": 0.010215715978178195, "actor_loss": -7.995272554397583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.660696744918823, "step": 15000}
{"episode_reward": 7.964674863770539, "episode": 16.0, "batch_reward": 0.040872570685110986, "critic_loss": 0.012183923450065777, "actor_loss": -9.541543807983398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.575437307357788, "step": 16000}
{"episode_reward": 9.01163541679333, "episode": 17.0, "batch_reward": 0.03938668147474527, "critic_loss": 0.010861128304619341, "actor_loss": -10.13845321750641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.756893396377563, "step": 17000}
{"episode_reward": 10.29769978455592, "episode": 18.0, "batch_reward": 0.03742042252328247, "critic_loss": 0.00847443676716648, "actor_loss": -9.125714600086212, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.137831211090088, "step": 18000}
{"episode_reward": 7.61031989601155, "episode": 19.0, "batch_reward": 0.03666049192007631, "critic_loss": 0.010753479179227724, "actor_loss": -9.15196851491928, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.11565613746643, "step": 19000}
{"episode_reward": 13.285540015895894, "episode": 20.0, "batch_reward": 0.03534207616373897, "critic_loss": 0.007392454394255765, "actor_loss": -8.479543709754944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.71144461631775, "step": 20000}
{"episode_reward": 8.228257824416687, "episode": 21.0, "batch_reward": 0.03314741550758481, "critic_loss": 0.011676281263935379, "actor_loss": -9.273417663574218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.08892059326172, "step": 21000}
{"episode_reward": 10.406125233615834, "episode": 22.0, "batch_reward": 0.03233801204478368, "critic_loss": 0.010146059360937215, "actor_loss": -8.111885055065155, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.631285190582275, "step": 22000}
{"episode_reward": 11.002950812489873, "episode": 23.0, "batch_reward": 0.03138312203809619, "critic_loss": 0.008146653680945746, "actor_loss": -7.972410353183746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.494929552078247, "step": 23000}
{"episode_reward": 6.549979072531292, "episode": 24.0, "batch_reward": 0.030646326381713152, "critic_loss": 0.008392930704867468, "actor_loss": -7.80036621594429, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.343700647354126, "step": 24000}
{"episode_reward": 7.409283478057073, "episode": 25.0, "batch_reward": 0.029646236399188636, "critic_loss": 0.010300632790662349, "actor_loss": -7.5934062972068785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.612643718719482, "step": 25000}
{"episode_reward": 8.329841357868688, "episode": 26.0, "batch_reward": 0.029217288561165334, "critic_loss": 0.007675489396904595, "actor_loss": -7.810906316280365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.59954285621643, "step": 26000}
{"episode_reward": 10.771137456862672, "episode": 27.0, "batch_reward": 0.028490950871258976, "critic_loss": 0.008555478856200352, "actor_loss": -6.804406094551086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.899674892425537, "step": 27000}
{"episode_reward": 9.08604609520926, "episode": 28.0, "batch_reward": 0.026810079420451074, "critic_loss": 0.010776089310704265, "actor_loss": -7.871116121768951, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.89845895767212, "step": 28000}
{"episode_reward": 8.631232778667385, "episode": 29.0, "batch_reward": 0.026322105787694453, "critic_loss": 0.004379263896378689, "actor_loss": -6.494841453075409, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.421472311019897, "step": 29000}
{"episode_reward": 10.060721898376109, "episode": 30.0, "batch_reward": 0.026545828637667, "critic_loss": 0.008698506869724952, "actor_loss": -7.186007553339005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.281367778778076, "step": 30000}
{"episode_reward": 8.63605465101312, "episode": 31.0, "batch_reward": 0.025496516035869717, "critic_loss": 0.006093399018689524, "actor_loss": -7.522297422170639, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.77633547782898, "step": 31000}
{"episode_reward": 7.254894394622768, "episode": 32.0, "batch_reward": 0.02488324777316302, "critic_loss": 0.008557003656867892, "actor_loss": -6.897594778776169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.861295700073242, "step": 32000}
{"episode_reward": 5.3850656504102945, "episode": 33.0, "batch_reward": 0.024897726176772265, "critic_loss": 0.00882298672851175, "actor_loss": -7.160808985710144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.028876066207886, "step": 33000}
{"episode_reward": 10.360251193774104, "episode": 34.0, "batch_reward": 0.02388959368830547, "critic_loss": 0.005181982139940373, "actor_loss": -7.244180750370026, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.260525941848755, "step": 34000}
{"episode_reward": 9.85028437442974, "episode": 35.0, "batch_reward": 0.023450123807881026, "critic_loss": 0.008828581522102467, "actor_loss": -7.03776282787323, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.197420120239258, "step": 35000}
{"episode_reward": 7.383917803911761, "episode": 36.0, "batch_reward": 0.023149850732646884, "critic_loss": 0.005341996792179998, "actor_loss": -7.376632982850075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.898102283477783, "step": 36000}
{"episode_reward": 9.72581178209056, "episode": 37.0, "batch_reward": 0.022656121286563576, "critic_loss": 0.008929461325227749, "actor_loss": -7.8177572940588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.05005669593811, "step": 37000}
{"episode_reward": 7.339681098011888, "episode": 38.0, "batch_reward": 0.02237019716296345, "critic_loss": 0.007583612196263858, "actor_loss": -6.288968301057816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.479013919830322, "step": 38000}
{"episode_reward": 6.257417904274686, "episode": 39.0, "batch_reward": 0.022240957789123057, "critic_loss": 0.00559857747668866, "actor_loss": -6.99884503185749, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.589415550231934, "step": 39000}
{"episode_reward": 5.862841596026081, "episode": 40.0, "batch_reward": 0.021235627010464667, "critic_loss": 0.006466223601106321, "actor_loss": -7.060073507547378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.060460805892944, "step": 40000}
{"episode_reward": 6.082704490352353, "episode": 41.0, "batch_reward": 0.021175921838264913, "critic_loss": 0.00800964877702063, "actor_loss": -7.473179573535919, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.72811961174011, "step": 41000}
{"episode_reward": 7.516683383103081, "episode": 42.0, "batch_reward": 0.020694043800234794, "critic_loss": 0.004624057677399832, "actor_loss": -7.407399088144302, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.425581693649292, "step": 42000}
{"episode_reward": 6.513644740015418, "episode": 43.0, "batch_reward": 0.020285883320029827, "critic_loss": 0.008292720331053716, "actor_loss": -6.605591866612435, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.839761972427368, "step": 43000}
{"episode_reward": 8.31125538960214, "episode": 44.0, "batch_reward": 0.01995500632515177, "critic_loss": 0.005348530537390616, "actor_loss": -7.106300380468369, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.104211807250977, "step": 44000}
{"episode_reward": 7.317908537791677, "episode": 45.0, "batch_reward": 0.019765523893292992, "critic_loss": 0.005492278811405413, "actor_loss": -6.477989071726799, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.265485525131226, "step": 45000}
{"episode_reward": 7.365682208918293, "episode": 46.0, "batch_reward": 0.019722356154117732, "critic_loss": 0.006550626559241209, "actor_loss": -7.1625136811733245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.06181240081787, "step": 46000}
{"episode_reward": 10.169289515807465, "episode": 47.0, "batch_reward": 0.019423516806215048, "critic_loss": 0.005423276822373736, "actor_loss": -7.519453450679779, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.76838445663452, "step": 47000}
{"episode_reward": 6.2367153222005145, "episode": 48.0, "batch_reward": 0.019022538600023835, "critic_loss": 0.004958357731666183, "actor_loss": -5.945483196735382, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.85051131248474, "step": 48000}
{"episode_reward": 6.795570287527462, "episode": 49.0, "batch_reward": 0.019301246320828795, "critic_loss": 0.0055024342427495865, "actor_loss": -6.1720318392515185, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.94924759864807, "step": 49000}
{"episode_reward": 7.453120432295246, "episode": 50.0, "batch_reward": 0.01893487036181614, "critic_loss": 0.004868401872372487, "actor_loss": -6.727835510849952, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.41355323791504, "step": 50000}
{"episode_reward": 11.137368613235378, "episode": 51.0, "batch_reward": 0.01854633619869128, "critic_loss": 0.006251217441749759, "actor_loss": -5.767170853435993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.090524673461914, "step": 51000}
{"episode_reward": 10.098283737380712, "episode": 52.0, "batch_reward": 0.01855193316238001, "critic_loss": 0.007512519813666586, "actor_loss": -6.4597486585378645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.506809949874878, "step": 52000}
{"episode_reward": 7.475991930478656, "episode": 53.0, "batch_reward": 0.018299205658957363, "critic_loss": 0.005608842915244168, "actor_loss": -5.667804719865322, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.320695638656616, "step": 53000}
{"episode_reward": 6.478290178800252, "episode": 54.0, "batch_reward": 0.01837279980489984, "critic_loss": 0.004026192593330051, "actor_loss": -6.1996313406229016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002120971679688, "step": 54000}
{"episode_reward": 7.375388459121393, "episode": 55.0, "batch_reward": 0.017701216110493988, "critic_loss": 0.005892298847495113, "actor_loss": -6.434574882686138, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.460688829421997, "step": 55000}
{"episode_reward": 6.522187074839669, "episode": 56.0, "batch_reward": 0.017363068548496813, "critic_loss": 0.007039844077662565, "actor_loss": -5.467994024872779, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.788512468338013, "step": 56000}
{"episode_reward": 7.989354537104922, "episode": 57.0, "batch_reward": 0.017506998429540545, "critic_loss": 0.005748956507217372, "actor_loss": -5.928125893890858, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.460920095443726, "step": 57000}
{"episode_reward": 7.345188563130117, "episode": 58.0, "batch_reward": 0.017243829029146583, "critic_loss": 0.005618518877890892, "actor_loss": -5.317635169148445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.284717082977295, "step": 58000}
{"episode_reward": 8.696758507669415, "episode": 59.0, "batch_reward": 0.016919515083543956, "critic_loss": 0.010016934771410888, "actor_loss": -5.7717984411120415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.120631456375122, "step": 59000}
{"episode_reward": 12.11325568960305, "episode": 60.0, "batch_reward": 0.01704178794287145, "critic_loss": 0.008206191966310143, "actor_loss": -5.98538357681036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.628719568252563, "step": 60000}
{"episode_reward": 14.384131954125081, "episode": 61.0, "batch_reward": 0.016742805841844528, "critic_loss": 0.00807739853579551, "actor_loss": -5.8481187191009525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.2756073474884, "step": 61000}
{"episode_reward": 7.280974816717407, "episode": 62.0, "batch_reward": 0.016448959665372968, "critic_loss": 0.006587753802828956, "actor_loss": -5.384785832524299, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.437572956085205, "step": 62000}
{"episode_reward": 10.863346175402675, "episode": 63.0, "batch_reward": 0.016539767500478773, "critic_loss": 0.0045897220778279004, "actor_loss": -5.639070608615875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006551265716553, "step": 63000}
{"episode_reward": 10.193163913078257, "episode": 64.0, "batch_reward": 0.016459949521813542, "critic_loss": 0.005079394960048376, "actor_loss": -6.145209165871143, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.822383642196655, "step": 64000}
{"episode_reward": 12.208791303674577, "episode": 65.0, "batch_reward": 0.016560305775608866, "critic_loss": 0.003770375738531584, "actor_loss": -5.355443792879582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.01486825942993, "step": 65000}
{"episode_reward": 8.390569773294894, "episode": 66.0, "batch_reward": 0.016116342121735214, "critic_loss": 0.004181810050708009, "actor_loss": -6.224033712983132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.823318243026733, "step": 66000}
{"episode_reward": 7.335885122692943, "episode": 67.0, "batch_reward": 0.016082099952735008, "critic_loss": 0.004227602072904119, "actor_loss": -5.81879996201396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.936325073242188, "step": 67000}
{"episode_reward": 7.0260550834979645, "episode": 68.0, "batch_reward": 0.016196378566790372, "critic_loss": 0.004478711959760403, "actor_loss": -5.877246400505304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.651643991470337, "step": 68000}
{"episode_reward": 6.314271813190291, "episode": 69.0, "batch_reward": 0.01610349386744201, "critic_loss": 0.004019872097182088, "actor_loss": -6.156019254207611, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.81881332397461, "step": 69000}
{"episode_reward": 12.591858339167471, "episode": 70.0, "batch_reward": 0.015787156164646148, "critic_loss": 0.003565150232549058, "actor_loss": -5.639830742686987, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.721028327941895, "step": 70000}
{"episode_reward": 8.026937815187583, "episode": 71.0, "batch_reward": 0.015746491017285733, "critic_loss": 0.0035198735422163735, "actor_loss": -5.686679486066103, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.3859338760376, "step": 71000}
{"episode_reward": 7.729969067588801, "episode": 72.0, "batch_reward": 0.015565774469170719, "critic_loss": 0.003833747929427773, "actor_loss": -5.730633234113455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.95641326904297, "step": 72000}
{"episode_reward": 6.380904891392683, "episode": 73.0, "batch_reward": 0.015614769104868174, "critic_loss": 0.0042001569560088685, "actor_loss": -6.217935493886471, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.161174774169922, "step": 73000}
{"episode_reward": 8.496936459894329, "episode": 74.0, "batch_reward": 0.015402808900456876, "critic_loss": 0.004043674404383637, "actor_loss": -5.641721449106932, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.963900566101074, "step": 74000}
{"episode_reward": 8.272578658659116, "episode": 75.0, "batch_reward": 0.015660835362039507, "critic_loss": 0.0037808860937657302, "actor_loss": -5.979392249256373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.787262201309204, "step": 75000}
{"episode_reward": 8.029110575812316, "episode": 76.0, "batch_reward": 0.015102711388841271, "critic_loss": 0.003474458025331842, "actor_loss": -6.44350039190054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.148255825042725, "step": 76000}
{"episode_reward": 7.315584291133417, "episode": 77.0, "batch_reward": 0.014901261975523085, "critic_loss": 0.0042300370189477686, "actor_loss": -5.8877567363083365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.450148582458496, "step": 77000}
{"episode_reward": 11.472288660591534, "episode": 78.0, "batch_reward": 0.0152196138468571, "critic_loss": 0.00443057966188644, "actor_loss": -5.022199208378792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.601009368896484, "step": 78000}
{"episode_reward": 7.2703262674011055, "episode": 79.0, "batch_reward": 0.01488960474357009, "critic_loss": 0.0036419121497892775, "actor_loss": -5.153299727618695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.85276746749878, "step": 79000}
{"episode_reward": 8.169870996134856, "episode": 80.0, "batch_reward": 0.014988921568263322, "critic_loss": 0.0038304059290676378, "actor_loss": -6.150130333095789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.175122022628784, "step": 80000}
{"episode_reward": 7.807819561101117, "episode": 81.0, "batch_reward": 0.01490623869933188, "critic_loss": 0.0035534584469278344, "actor_loss": -5.875113571405411, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.39215564727783, "step": 81000}
{"episode_reward": 7.208766982904125, "episode": 82.0, "batch_reward": 0.01464605010766536, "critic_loss": 0.002843250010788324, "actor_loss": -5.63816551810503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.44356369972229, "step": 82000}
{"episode_reward": 7.008551750421733, "episode": 83.0, "batch_reward": 0.014527198798023165, "critic_loss": 0.004190528581180843, "actor_loss": -6.714837361752987, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.753632307052612, "step": 83000}
{"episode_reward": 7.1927523411433905, "episode": 84.0, "batch_reward": 0.014206600629258902, "critic_loss": 0.002555734458466759, "actor_loss": -6.056654578477144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.448688745498657, "step": 84000}
{"episode_reward": 6.496106836010518, "episode": 85.0, "batch_reward": 0.01474762863572687, "critic_loss": 0.0038875458608090413, "actor_loss": -5.905023533463478, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.146600484848022, "step": 85000}
{"episode_reward": 4.985995054053279, "episode": 86.0, "batch_reward": 0.014378140128217637, "critic_loss": 0.004002490669139661, "actor_loss": -6.768414543032646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95024609565735, "step": 86000}
{"episode_reward": 9.504204922727386, "episode": 87.0, "batch_reward": 0.0146345523474738, "critic_loss": 0.0033826578991429414, "actor_loss": -6.056083719551563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.77369999885559, "step": 87000}
{"episode_reward": 8.243483959299102, "episode": 88.0, "batch_reward": 0.01439800782361999, "critic_loss": 0.0037451087290246506, "actor_loss": -6.603498389422893, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.38546657562256, "step": 88000}
{"episode_reward": 6.691062944019721, "episode": 89.0, "batch_reward": 0.014130005013663322, "critic_loss": 0.0032992454727354924, "actor_loss": -5.550977674126625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109225749969482, "step": 89000}
{"episode_reward": 11.79156885512522, "episode": 90.0, "batch_reward": 0.014001192231662572, "critic_loss": 0.003744771407044027, "actor_loss": -4.824677088737488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.027247428894043, "step": 90000}
{"episode_reward": 8.943101414626728, "episode": 91.0, "batch_reward": 0.014100267344620079, "critic_loss": 0.00499582960177213, "actor_loss": -5.8110848633050916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.677085876464844, "step": 91000}
{"episode_reward": 10.216232982759418, "episode": 92.0, "batch_reward": 0.014085767584852874, "critic_loss": 0.003397768361726776, "actor_loss": -6.084308949381113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.74749517440796, "step": 92000}
{"episode_reward": 9.285002029306746, "episode": 93.0, "batch_reward": 0.014103108756244183, "critic_loss": 0.006077379139751429, "actor_loss": -5.625801560074091, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.308536529541016, "step": 93000}
{"episode_reward": 9.731142149269333, "episode": 94.0, "batch_reward": 0.013774190355557948, "critic_loss": 0.002599446519234334, "actor_loss": -6.004840014010668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.867959022521973, "step": 94000}
{"episode_reward": 8.690499983360272, "episode": 95.0, "batch_reward": 0.013755452076438815, "critic_loss": 0.0043885824928293, "actor_loss": -4.9555790298879145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006742477416992, "step": 95000}
{"episode_reward": 9.839284830507452, "episode": 96.0, "batch_reward": 0.01384024022752419, "critic_loss": 0.002822580661799293, "actor_loss": -7.212209221899509, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.432889938354492, "step": 96000}
{"episode_reward": 6.362512091346924, "episode": 97.0, "batch_reward": 0.013658418278675526, "critic_loss": 0.004038758990122005, "actor_loss": -6.325393592596054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.563660383224487, "step": 97000}
{"episode_reward": 5.0454071931298605, "episode": 98.0, "batch_reward": 0.013554306843318046, "critic_loss": 0.003981505572097376, "actor_loss": -5.05085209313035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.09933567047119, "step": 98000}
{"episode_reward": 9.162818840187098, "episode": 99.0, "batch_reward": 0.013725112083833665, "critic_loss": 0.003067926870950032, "actor_loss": -7.029021650478244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.576013803482056, "step": 99000}
{"episode_reward": 7.427601924535486, "episode": 100.0, "batch_reward": 0.013441195467021317, "critic_loss": 0.004148753877263516, "actor_loss": -6.421019760161638, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.703368425369263, "step": 100000}
{"episode_reward": 8.48318975057316, "episode": 101.0, "batch_reward": 0.013391012398526072, "critic_loss": 0.0026572944477229613, "actor_loss": -7.451926179930568, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.40011024475098, "step": 101000}
{"episode_reward": 9.463680265433165, "episode": 102.0, "batch_reward": 0.013278575693722814, "critic_loss": 0.003382666559497011, "actor_loss": -6.170970070838928, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.34957981109619, "step": 102000}
{"episode_reward": 6.180297755571498, "episode": 103.0, "batch_reward": 0.013468172491062433, "critic_loss": 0.002684791897845571, "actor_loss": -5.473099642470479, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.2499098777771, "step": 103000}
{"episode_reward": 6.0487873044465, "episode": 104.0, "batch_reward": 0.013585141639690846, "critic_loss": 0.003648509115446359, "actor_loss": -6.238633248776197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.225801944732666, "step": 104000}
{"episode_reward": 6.982166448373932, "episode": 105.0, "batch_reward": 0.013187749261502176, "critic_loss": 0.0025584946422022767, "actor_loss": -6.384137706562877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.69309711456299, "step": 105000}
{"episode_reward": 7.744034640517447, "episode": 106.0, "batch_reward": 0.013326072146184743, "critic_loss": 0.003489962619059952, "actor_loss": -6.506218263417482, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.3808913230896, "step": 106000}
{"episode_reward": 10.911019276014876, "episode": 107.0, "batch_reward": 0.01317895025247708, "critic_loss": 0.0026348592708818615, "actor_loss": -6.424732375711202, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.31702709197998, "step": 107000}
{"episode_reward": 10.183724119517759, "episode": 108.0, "batch_reward": 0.01292190829711035, "critic_loss": 0.0023241550907550845, "actor_loss": -5.204184610560536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.452632904052734, "step": 108000}
{"episode_reward": 9.829953607207022, "episode": 109.0, "batch_reward": 0.013152068871539087, "critic_loss": 0.0036288848643307573, "actor_loss": -5.556433311939239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.655638456344604, "step": 109000}
{"episode_reward": 8.295169085842451, "episode": 110.0, "batch_reward": 0.012921907184179873, "critic_loss": 0.0037378657105728054, "actor_loss": -5.869212925493717, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.92589282989502, "step": 110000}
{"episode_reward": 10.217697827071573, "episode": 111.0, "batch_reward": 0.013037205984815956, "critic_loss": 0.0023604773154656867, "actor_loss": -4.999898679420352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.92763805389404, "step": 111000}
{"episode_reward": 7.491469105737339, "episode": 112.0, "batch_reward": 0.013149510180111974, "critic_loss": 0.004121033627190627, "actor_loss": -6.702792715556919, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.08090376853943, "step": 112000}
{"episode_reward": 7.855147328172014, "episode": 113.0, "batch_reward": 0.013005579255986959, "critic_loss": 0.00325261267813039, "actor_loss": -5.877868377536536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.448958158493042, "step": 113000}
{"episode_reward": 7.508317957291304, "episode": 114.0, "batch_reward": 0.013060758927837014, "critic_loss": 0.0042214275618025566, "actor_loss": -6.417244153559208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.746870756149292, "step": 114000}
{"episode_reward": 7.426813212091537, "episode": 115.0, "batch_reward": 0.01261996399704367, "critic_loss": 0.0037472214194567643, "actor_loss": -6.230287383377552, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.255035400390625, "step": 115000}
{"episode_reward": 9.764629521292386, "episode": 116.0, "batch_reward": 0.012746448257006705, "critic_loss": 0.004453479025047272, "actor_loss": -5.892123477190733, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.939152240753174, "step": 116000}
{"episode_reward": 10.770075010885904, "episode": 117.0, "batch_reward": 0.01317847878811881, "critic_loss": 0.0029735679921286647, "actor_loss": -5.586570069842041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.144886255264282, "step": 117000}
{"episode_reward": 7.390392166578284, "episode": 118.0, "batch_reward": 0.012677498833741993, "critic_loss": 0.0023171601990179622, "actor_loss": -6.003826673462987, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.197736501693726, "step": 118000}
{"episode_reward": 8.871339913814117, "episode": 119.0, "batch_reward": 0.012678176702465863, "critic_loss": 0.0028582890549732837, "actor_loss": -5.673501466691494, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.68593716621399, "step": 119000}
{"episode_reward": 7.2925546518167605, "episode": 120.0, "batch_reward": 0.012679461087100208, "critic_loss": 0.0026775175310467603, "actor_loss": -5.122803108677268, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.254623651504517, "step": 120000}
{"episode_reward": 10.3156812111789, "episode": 121.0, "batch_reward": 0.012671378187369554, "critic_loss": 0.0024956723985087594, "actor_loss": -5.966473088443279, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.820261001586914, "step": 121000}
{"episode_reward": 6.135593988081927, "episode": 122.0, "batch_reward": 0.012750284530222415, "critic_loss": 0.002914814924792154, "actor_loss": -5.4699464850574735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.685269117355347, "step": 122000}
{"episode_reward": 7.9861447871632505, "episode": 123.0, "batch_reward": 0.012343176598660648, "critic_loss": 0.002500956764444709, "actor_loss": -5.833059196129441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.24512004852295, "step": 123000}
{"episode_reward": 8.212998747569833, "episode": 124.0, "batch_reward": 0.012539537511300295, "critic_loss": 0.0025180432708875743, "actor_loss": -6.547437470853328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.847883939743042, "step": 124000}
{"episode_reward": 10.593786105456118, "episode": 125.0, "batch_reward": 0.012593529263976961, "critic_loss": 0.003342340535018593, "actor_loss": -6.2792507671862845, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.174909591674805, "step": 125000}
{"episode_reward": 8.574229230278654, "episode": 126.0, "batch_reward": 0.012612658626399934, "critic_loss": 0.0025127808024699334, "actor_loss": -5.354089426085353, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.697845697402954, "step": 126000}
{"episode_reward": 8.073290364731854, "episode": 127.0, "batch_reward": 0.012423787114210426, "critic_loss": 0.0019479365355946356, "actor_loss": -6.49019138379395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.94122290611267, "step": 127000}
{"episode_reward": 7.411251103789497, "episode": 128.0, "batch_reward": 0.01202634988585487, "critic_loss": 0.002507959323149407, "actor_loss": -6.152247970238328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.87969732284546, "step": 128000}
{"episode_reward": 10.847059919665876, "episode": 129.0, "batch_reward": 0.012634234668686985, "critic_loss": 0.0019429297188471536, "actor_loss": -5.564781202763319, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.279331922531128, "step": 129000}
{"episode_reward": 6.08449686530827, "episode": 130.0, "batch_reward": 0.012135914837010205, "critic_loss": 0.0025178428629151314, "actor_loss": -5.543389864459634, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.057100296020508, "step": 130000}
{"episode_reward": 10.373384022464709, "episode": 131.0, "batch_reward": 0.01230544358305633, "critic_loss": 0.0025570840831496753, "actor_loss": -5.797994849190116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.90767216682434, "step": 131000}
{"episode_reward": 8.360590570989443, "episode": 132.0, "batch_reward": 0.01229222886543721, "critic_loss": 0.002524870357941836, "actor_loss": -5.613023208767176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.190301656723022, "step": 132000}
{"episode_reward": 6.563056197446195, "episode": 133.0, "batch_reward": 0.012095342474989593, "critic_loss": 0.0020205717901844765, "actor_loss": -4.885196341559291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.780704259872437, "step": 133000}
{"episode_reward": 7.380478336617393, "episode": 134.0, "batch_reward": 0.012349640450440347, "critic_loss": 0.0027026572825125184, "actor_loss": -5.458088092535734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06227993965149, "step": 134000}
{"episode_reward": 8.93646773766219, "episode": 135.0, "batch_reward": 0.012177428239490837, "critic_loss": 0.0019207060194021324, "actor_loss": -6.311771835178137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.42276120185852, "step": 135000}
{"episode_reward": 10.648556847464588, "episode": 136.0, "batch_reward": 0.012103888671845198, "critic_loss": 0.0022735401376121444, "actor_loss": -5.046351093903184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.637717723846436, "step": 136000}
{"episode_reward": 8.532095150025121, "episode": 137.0, "batch_reward": 0.012105979511979968, "critic_loss": 0.002411204569594702, "actor_loss": -5.818400927364826, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.138725996017456, "step": 137000}
{"episode_reward": 7.124560111742188, "episode": 138.0, "batch_reward": 0.01211025117477402, "critic_loss": 0.0016974312794045545, "actor_loss": -6.4208777333498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.987332820892334, "step": 138000}
{"episode_reward": 8.225802663400152, "episode": 139.0, "batch_reward": 0.012003520344849677, "critic_loss": 0.0020270529148256173, "actor_loss": -4.494421009108424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.42369794845581, "step": 139000}
{"episode_reward": 7.21924873814938, "episode": 140.0, "batch_reward": 0.011986943188589066, "critic_loss": 0.0025998064585000973, "actor_loss": -5.870561191722751, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.144432306289673, "step": 140000}
{"episode_reward": 8.137667266309338, "episode": 141.0, "batch_reward": 0.012210125560406595, "critic_loss": 0.002143445423949743, "actor_loss": -6.5318298112601045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.09287405014038, "step": 141000}
{"episode_reward": 9.300726694315108, "episode": 142.0, "batch_reward": 0.012044306129217149, "critic_loss": 0.0020380239778314715, "actor_loss": -5.212001138582826, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.3298077583313, "step": 142000}
{"episode_reward": 7.20536548409746, "episode": 143.0, "batch_reward": 0.012203512773383409, "critic_loss": 0.001951885786038474, "actor_loss": -5.108891516461968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.873377323150635, "step": 143000}
{"episode_reward": 10.446832332873754, "episode": 144.0, "batch_reward": 0.011778620994649828, "critic_loss": 0.0027002336968289455, "actor_loss": -5.428677089437842, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.49537968635559, "step": 144000}
{"episode_reward": 11.728162127040301, "episode": 145.0, "batch_reward": 0.01187601012084633, "critic_loss": 0.002108284328496666, "actor_loss": -6.137466932937503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.316434860229492, "step": 145000}
{"episode_reward": 11.970965939415166, "episode": 146.0, "batch_reward": 0.012015969190746547, "critic_loss": 0.0019666882968012943, "actor_loss": -6.4226170854866504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.597604990005493, "step": 146000}
{"episode_reward": 7.083708350989681, "episode": 147.0, "batch_reward": 0.011851311471778899, "critic_loss": 0.002780051275592996, "actor_loss": -5.814029902026057, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.957879781723022, "step": 147000}
{"episode_reward": 9.988054337741543, "episode": 148.0, "batch_reward": 0.011944365362636745, "critic_loss": 0.0020726801959244767, "actor_loss": -5.816913594424725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.724714756011963, "step": 148000}
{"episode_reward": 7.654654850098393, "episode": 149.0, "batch_reward": 0.01189767981460318, "critic_loss": 0.001930442767450586, "actor_loss": -5.591683854326606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.830382823944092, "step": 149000}
{"episode_reward": 7.430729134444327, "episode": 150.0, "batch_reward": 0.012277896328363567, "critic_loss": 0.0025003027105121875, "actor_loss": -6.265148213371634, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
