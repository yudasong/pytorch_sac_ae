{"episode_reward": 0.0, "episode": 1.0, "duration": 13.961947202682495, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.238499402999878, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.2528204077400737, "critic_loss": 0.03926651250253015, "actor_loss": -34.18808970541335, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 73.45030498504639, "step": 3000}
{"episode_reward": 49.142560293401864, "episode": 4.0, "batch_reward": 0.18134838578104973, "critic_loss": 0.04921937541849911, "actor_loss": -20.948720123559237, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.00853943824768, "step": 4000}
{"episode_reward": 141.07446356005218, "episode": 5.0, "batch_reward": 0.16159762854129076, "critic_loss": 0.03823131826892495, "actor_loss": -20.837424323871733, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.361887454986572, "step": 5000}
{"episode_reward": 5.075307688316769, "episode": 6.0, "batch_reward": 0.13332707446068526, "critic_loss": 0.03503516987431794, "actor_loss": -22.012894458293914, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.945136308670044, "step": 6000}
{"episode_reward": 4.5383900878568, "episode": 7.0, "batch_reward": 0.11361089761555195, "critic_loss": 0.03343515627272427, "actor_loss": -21.98916159635782, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.148969888687134, "step": 7000}
{"episode_reward": 6.05249357338616, "episode": 8.0, "batch_reward": 0.09970590829476714, "critic_loss": 0.03235770171601325, "actor_loss": -20.530085432171823, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.080158710479736, "step": 8000}
{"episode_reward": 13.884193261613596, "episode": 9.0, "batch_reward": 0.08821144617721438, "critic_loss": 0.02875292035099119, "actor_loss": -20.56583337676525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.421259880065918, "step": 9000}
{"episode_reward": 7.237325846403267, "episode": 10.0, "batch_reward": 0.08007753610238433, "critic_loss": 0.026125135773792864, "actor_loss": -19.354948281526564, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.066030740737915, "step": 10000}
{"episode_reward": 8.219501437584917, "episode": 11.0, "batch_reward": 0.0788674550037831, "critic_loss": 0.0489092420777306, "actor_loss": -20.081519531846048, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.128782987594604, "step": 11000}
{"episode_reward": 174.103216940722, "episode": 12.0, "batch_reward": 0.08611552554741501, "critic_loss": 0.08195503347739577, "actor_loss": -18.50603725206852, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.70844340324402, "step": 12000}
{"episode_reward": 57.72896465668984, "episode": 13.0, "batch_reward": 0.08863299036771059, "critic_loss": 0.09089018394052982, "actor_loss": -19.154510208308697, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.05417823791504, "step": 13000}
{"episode_reward": 184.56650418801573, "episode": 14.0, "batch_reward": 0.09280181421339512, "critic_loss": 0.10689567280188203, "actor_loss": -19.057333801418544, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.45556402206421, "step": 14000}
{"episode_reward": 171.6297616713066, "episode": 15.0, "batch_reward": 0.09620881148427725, "critic_loss": 0.14645505511760712, "actor_loss": -19.68534109029174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.584767818450928, "step": 15000}
{"episode_reward": 54.72349048934106, "episode": 16.0, "batch_reward": 0.09683252568170428, "critic_loss": 0.13762990954890847, "actor_loss": -15.861483876109123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.581130981445312, "step": 16000}
{"episode_reward": 217.0765926553553, "episode": 17.0, "batch_reward": 0.10283132401853799, "critic_loss": 0.14081717513874173, "actor_loss": -16.673873903423548, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.009381532669067, "step": 17000}
{"episode_reward": 109.53939919496601, "episode": 18.0, "batch_reward": 0.10496761366724967, "critic_loss": 0.13673896073177458, "actor_loss": -16.405624712616206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.16141104698181, "step": 18000}
{"episode_reward": 229.02155985383325, "episode": 19.0, "batch_reward": 0.11526392707228661, "critic_loss": 0.17546673484146594, "actor_loss": -17.015412552654745, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.08075714111328, "step": 19000}
{"episode_reward": 296.45484492309964, "episode": 20.0, "batch_reward": 0.1198434509858489, "critic_loss": 0.18321843529492618, "actor_loss": -17.75915648198128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.192360877990723, "step": 20000}
{"episode_reward": 105.87556739041301, "episode": 21.0, "batch_reward": 0.11790500227361918, "critic_loss": 0.17622756838798523, "actor_loss": -16.731882964372634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.77189517021179, "step": 21000}
{"episode_reward": 90.56895919070486, "episode": 22.0, "batch_reward": 0.1176978291273117, "critic_loss": 0.15830498769134282, "actor_loss": -17.205633071899413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.91029405593872, "step": 22000}
{"episode_reward": 91.05714290615506, "episode": 23.0, "batch_reward": 0.11716478696465492, "critic_loss": 0.1714829469025135, "actor_loss": -16.465063091754914, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.699076175689697, "step": 23000}
{"episode_reward": 222.11961916331654, "episode": 24.0, "batch_reward": 0.12237060046195984, "critic_loss": 0.18634973045438527, "actor_loss": -17.207128788471223, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.994568347930908, "step": 24000}
{"episode_reward": 241.06527973838158, "episode": 25.0, "batch_reward": 0.12557509960234164, "critic_loss": 0.18663163067400457, "actor_loss": -17.206472084522247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.324033737182617, "step": 25000}
{"episode_reward": 209.449071593045, "episode": 26.0, "batch_reward": 0.13018590500950813, "critic_loss": 0.19194818871468305, "actor_loss": -16.860466769218444, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.449004411697388, "step": 26000}
{"episode_reward": 142.66150977967283, "episode": 27.0, "batch_reward": 0.13037196086347103, "critic_loss": 0.19198003026098012, "actor_loss": -17.419830892562867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.091426372528076, "step": 27000}
{"episode_reward": 118.91449647002183, "episode": 28.0, "batch_reward": 0.13139227817952634, "critic_loss": 0.1821817350462079, "actor_loss": -16.56865997314453, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.076056241989136, "step": 28000}
{"episode_reward": 335.12802356410765, "episode": 29.0, "batch_reward": 0.13462005351483822, "critic_loss": 0.20964588817954063, "actor_loss": -17.792386717796326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.477492332458496, "step": 29000}
{"episode_reward": 32.54109117093264, "episode": 30.0, "batch_reward": 0.13379673497378827, "critic_loss": 0.20585255926847457, "actor_loss": -17.351693139076232, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.1688392162323, "step": 30000}
{"episode_reward": 154.2170830817606, "episode": 31.0, "batch_reward": 0.1323267858326435, "critic_loss": 0.20477079149335622, "actor_loss": -16.755139266967774, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.26649570465088, "step": 31000}
{"episode_reward": 52.6219470612964, "episode": 32.0, "batch_reward": 0.1297326860949397, "critic_loss": 0.19947516210377217, "actor_loss": -16.498679280281067, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22813582420349, "step": 32000}
{"episode_reward": 42.20224619432093, "episode": 33.0, "batch_reward": 0.12983609064668417, "critic_loss": 0.2204634214118123, "actor_loss": -16.787494071006776, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.67139983177185, "step": 33000}
{"episode_reward": 142.40051387103938, "episode": 34.0, "batch_reward": 0.13049935638904572, "critic_loss": 0.21024248894304037, "actor_loss": -16.172646039009095, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.410347938537598, "step": 34000}
{"episode_reward": 284.97119405946955, "episode": 35.0, "batch_reward": 0.13578761633485556, "critic_loss": 0.26685252448171376, "actor_loss": -16.911483815193176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.43257164955139, "step": 35000}
{"episode_reward": 330.7526101332293, "episode": 36.0, "batch_reward": 0.13975664719194175, "critic_loss": 0.259947549469769, "actor_loss": -16.521440276145935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.643320322036743, "step": 36000}
{"episode_reward": 151.6822602011846, "episode": 37.0, "batch_reward": 0.13843717908114195, "critic_loss": 0.25563849467784167, "actor_loss": -16.74705467414856, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.647361993789673, "step": 37000}
{"episode_reward": 160.74476206185835, "episode": 38.0, "batch_reward": 0.14076624228060244, "critic_loss": 0.2746459523886442, "actor_loss": -17.801374853134156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32004427909851, "step": 38000}
{"episode_reward": 151.51683917403992, "episode": 39.0, "batch_reward": 0.14209455162286758, "critic_loss": 0.27378387887775896, "actor_loss": -16.94282482147217, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.526196002960205, "step": 39000}
{"episode_reward": 194.28821020906813, "episode": 40.0, "batch_reward": 0.141858491204679, "critic_loss": 0.29214113067090514, "actor_loss": -17.184574686050414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.305436849594116, "step": 40000}
{"episode_reward": 152.2457973345292, "episode": 41.0, "batch_reward": 0.14041444323211907, "critic_loss": 0.29161978177726267, "actor_loss": -16.77302122116089, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.049169301986694, "step": 41000}
{"episode_reward": 53.79505509278255, "episode": 42.0, "batch_reward": 0.14070989152044058, "critic_loss": 0.28407112033665183, "actor_loss": -17.2392465839386, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.07463049888611, "step": 42000}
{"episode_reward": 229.0779594477772, "episode": 43.0, "batch_reward": 0.14420076987147332, "critic_loss": 0.3089429839849472, "actor_loss": -17.316182765960694, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.56260633468628, "step": 43000}
{"episode_reward": 258.1079676718923, "episode": 44.0, "batch_reward": 0.14632441374659538, "critic_loss": 0.30220306131243707, "actor_loss": -17.47283112716675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.450450897216797, "step": 44000}
{"episode_reward": 300.1700695475803, "episode": 45.0, "batch_reward": 0.14837916728854178, "critic_loss": 0.3271509198397398, "actor_loss": -17.907596160888673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.680301189422607, "step": 45000}
{"episode_reward": 144.23934700388872, "episode": 46.0, "batch_reward": 0.14872649569809437, "critic_loss": 0.32354312109947203, "actor_loss": -17.81206014060974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.841614723205566, "step": 46000}
{"episode_reward": 333.442903076145, "episode": 47.0, "batch_reward": 0.15166771683841943, "critic_loss": 0.3531938404738903, "actor_loss": -18.000441333770752, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.506048679351807, "step": 47000}
{"episode_reward": 77.45891918463394, "episode": 48.0, "batch_reward": 0.1519837516620755, "critic_loss": 0.33933903811872007, "actor_loss": -18.05087435722351, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.577658891677856, "step": 48000}
{"episode_reward": 201.8797224107533, "episode": 49.0, "batch_reward": 0.1525359531491995, "critic_loss": 0.3483486982434988, "actor_loss": -18.038993421554565, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.01639676094055, "step": 49000}
{"episode_reward": 113.47304628119012, "episode": 50.0, "batch_reward": 0.15182090354710817, "critic_loss": 0.35310796156525615, "actor_loss": -18.31135831260681, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.412719249725342, "step": 50000}
{"episode_reward": 199.56087257635014, "episode": 51.0, "batch_reward": 0.15174478045105935, "critic_loss": 0.36026957488059996, "actor_loss": -18.373622016906737, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.86867809295654, "step": 51000}
{"episode_reward": 77.6285338080336, "episode": 52.0, "batch_reward": 0.15176730680465697, "critic_loss": 0.3531458792090416, "actor_loss": -18.262061410903932, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.474244117736816, "step": 52000}
{"episode_reward": 198.48770103161092, "episode": 53.0, "batch_reward": 0.15169915060698985, "critic_loss": 0.3827276048064232, "actor_loss": -18.991177442550658, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.82565975189209, "step": 53000}
{"episode_reward": 205.33712197854632, "episode": 54.0, "batch_reward": 0.15229519569128752, "critic_loss": 0.36031581051647665, "actor_loss": -18.615318365097046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.454895496368408, "step": 54000}
{"episode_reward": 49.8491632787828, "episode": 55.0, "batch_reward": 0.15101276060193777, "critic_loss": 0.35601333341002467, "actor_loss": -18.9897972240448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.43021249771118, "step": 55000}
{"episode_reward": 251.04563683135112, "episode": 56.0, "batch_reward": 0.15172164376825095, "critic_loss": 0.350145150847733, "actor_loss": -19.493359186172487, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.97414994239807, "step": 56000}
{"episode_reward": 70.14695516328216, "episode": 57.0, "batch_reward": 0.15047359643131494, "critic_loss": 0.34218000181019304, "actor_loss": -18.978311462402345, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.75503635406494, "step": 57000}
{"episode_reward": 73.21411274725487, "episode": 58.0, "batch_reward": 0.14939701922982931, "critic_loss": 0.3754732666313648, "actor_loss": -19.212548555374145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.033218145370483, "step": 58000}
{"episode_reward": 175.76570810683873, "episode": 59.0, "batch_reward": 0.14998120123147965, "critic_loss": 0.35278190813958643, "actor_loss": -19.33422044944763, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.177129983901978, "step": 59000}
{"episode_reward": 121.47197882673053, "episode": 60.0, "batch_reward": 0.15099236960709095, "critic_loss": 0.3283057134672999, "actor_loss": -19.539901746749877, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.424148559570312, "step": 60000}
{"episode_reward": 375.4907322799767, "episode": 61.0, "batch_reward": 0.1536459626480937, "critic_loss": 0.36001517513394354, "actor_loss": -19.707102945327758, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.42609763145447, "step": 61000}
{"episode_reward": 235.19108276511125, "episode": 62.0, "batch_reward": 0.1548303931877017, "critic_loss": 0.3479475567638874, "actor_loss": -20.0702255859375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.12069296836853, "step": 62000}
{"episode_reward": 284.5886243295772, "episode": 63.0, "batch_reward": 0.1555848077237606, "critic_loss": 0.331617830991745, "actor_loss": -20.044052225112914, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.25370764732361, "step": 63000}
{"episode_reward": 66.54351589442291, "episode": 64.0, "batch_reward": 0.1554051462635398, "critic_loss": 0.34355111949145795, "actor_loss": -20.05387181854248, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.562817811965942, "step": 64000}
{"episode_reward": 96.02611130804566, "episode": 65.0, "batch_reward": 0.15479333167523146, "critic_loss": 0.3269043559283018, "actor_loss": -20.09507022476196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.611658096313477, "step": 65000}
{"episode_reward": 118.68932702368666, "episode": 66.0, "batch_reward": 0.1520425889045, "critic_loss": 0.3297308768555522, "actor_loss": -20.22314747428894, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.398194789886475, "step": 66000}
{"episode_reward": 52.51930526907607, "episode": 67.0, "batch_reward": 0.1524368371143937, "critic_loss": 0.3505979586839676, "actor_loss": -20.283300546646117, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.313395261764526, "step": 67000}
{"episode_reward": 209.7964974839193, "episode": 68.0, "batch_reward": 0.1523645102083683, "critic_loss": 0.3569043963998556, "actor_loss": -20.003643459320067, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.944427490234375, "step": 68000}
{"episode_reward": 88.11470570954272, "episode": 69.0, "batch_reward": 0.15340971568226813, "critic_loss": 0.3649074896872044, "actor_loss": -20.114009578704835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.617825508117676, "step": 69000}
{"episode_reward": 166.42636790250026, "episode": 70.0, "batch_reward": 0.151549674667418, "critic_loss": 0.39152934519946575, "actor_loss": -19.787308282852173, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.4030818939209, "step": 70000}
{"episode_reward": 281.44197819839303, "episode": 71.0, "batch_reward": 0.15340984877943992, "critic_loss": 0.35785049806535246, "actor_loss": -20.217327520370482, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.3209228515625, "step": 71000}
{"episode_reward": 182.1989313419777, "episode": 72.0, "batch_reward": 0.1552898469939828, "critic_loss": 0.36025447531044485, "actor_loss": -20.040433753967285, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.66988205909729, "step": 72000}
{"episode_reward": 214.77570208658844, "episode": 73.0, "batch_reward": 0.15517692111432552, "critic_loss": 0.3457877147346735, "actor_loss": -20.205903049468994, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.68463706970215, "step": 73000}
{"episode_reward": 89.83144941004545, "episode": 74.0, "batch_reward": 0.15557841035723685, "critic_loss": 0.3463767040669918, "actor_loss": -20.2574820022583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.588762760162354, "step": 74000}
{"episode_reward": 215.00930294253197, "episode": 75.0, "batch_reward": 0.1559510347545147, "critic_loss": 0.37922535437345506, "actor_loss": -19.99679891586304, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.525530099868774, "step": 75000}
{"episode_reward": 246.20532965862196, "episode": 76.0, "batch_reward": 0.15728257843852042, "critic_loss": 0.3316250320225954, "actor_loss": -20.257348188400268, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.655817985534668, "step": 76000}
{"episode_reward": 306.87389629805295, "episode": 77.0, "batch_reward": 0.15974443203955888, "critic_loss": 0.38169370840489864, "actor_loss": -20.39397390937805, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.611735105514526, "step": 77000}
{"episode_reward": 449.0746718240543, "episode": 78.0, "batch_reward": 0.1618186699822545, "critic_loss": 0.3678144799619913, "actor_loss": -20.674060009002684, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.726044416427612, "step": 78000}
{"episode_reward": 206.40468966517358, "episode": 79.0, "batch_reward": 0.16433269657194616, "critic_loss": 0.3459289181381464, "actor_loss": -20.59331340789795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.128637313842773, "step": 79000}
{"episode_reward": 376.2518520908269, "episode": 80.0, "batch_reward": 0.16605074089765548, "critic_loss": 0.36171180513501167, "actor_loss": -20.74743308067322, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.4510178565979, "step": 80000}
{"episode_reward": 223.47885055596495, "episode": 81.0, "batch_reward": 0.16788079688698054, "critic_loss": 0.33709015968441963, "actor_loss": -20.868306865692137, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.70290780067444, "step": 81000}
{"episode_reward": 375.6616436573798, "episode": 82.0, "batch_reward": 0.16877807612717152, "critic_loss": 0.35898284675180914, "actor_loss": -20.87926286697388, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.83864665031433, "step": 82000}
{"episode_reward": 212.49878338174992, "episode": 83.0, "batch_reward": 0.1698185790106654, "critic_loss": 0.3882314636111259, "actor_loss": -20.939002391815187, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.17566752433777, "step": 83000}
{"episode_reward": 408.5183145113332, "episode": 84.0, "batch_reward": 0.17278404952585696, "critic_loss": 0.3572183948606253, "actor_loss": -21.092422328948974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.276432514190674, "step": 84000}
{"episode_reward": 399.57781392182864, "episode": 85.0, "batch_reward": 0.17575616274774075, "critic_loss": 0.3987386256605387, "actor_loss": -21.523719825744628, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.0266375541687, "step": 85000}
{"episode_reward": 181.95727661972495, "episode": 86.0, "batch_reward": 0.17636394773423672, "critic_loss": 0.3799503466039896, "actor_loss": -21.377385082244874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.009443998336792, "step": 86000}
{"episode_reward": 278.11076429756497, "episode": 87.0, "batch_reward": 0.1760721491277218, "critic_loss": 0.38012381783127785, "actor_loss": -21.367315254211427, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.351155996322632, "step": 87000}
{"episode_reward": 85.25728103957846, "episode": 88.0, "batch_reward": 0.17537947253882885, "critic_loss": 0.38545050486922267, "actor_loss": -21.16124781036377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.928762912750244, "step": 88000}
{"episode_reward": 151.96632734791564, "episode": 89.0, "batch_reward": 0.1743500082939863, "critic_loss": 0.3433551692664623, "actor_loss": -21.25274047088623, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.21064305305481, "step": 89000}
{"episode_reward": 110.27120929090195, "episode": 90.0, "batch_reward": 0.1750197123736143, "critic_loss": 0.361136133313179, "actor_loss": -21.256406425476076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34463906288147, "step": 90000}
{"episode_reward": 288.35867634785535, "episode": 91.0, "batch_reward": 0.17615643210709095, "critic_loss": 0.4057462601661682, "actor_loss": -21.383236095428465, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.26054000854492, "step": 91000}
{"episode_reward": 389.85029005824805, "episode": 92.0, "batch_reward": 0.1789674900919199, "critic_loss": 0.4042583670169115, "actor_loss": -21.495249382019043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.05562162399292, "step": 92000}
{"episode_reward": 315.3354389649202, "episode": 93.0, "batch_reward": 0.17853403612971305, "critic_loss": 0.39353358756005763, "actor_loss": -21.32645579147339, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.475362539291382, "step": 93000}
{"episode_reward": 66.5238221000293, "episode": 94.0, "batch_reward": 0.1785124338120222, "critic_loss": 0.38669028028845787, "actor_loss": -21.231015056610108, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.872129917144775, "step": 94000}
{"episode_reward": 190.82782180318338, "episode": 95.0, "batch_reward": 0.17980365961790085, "critic_loss": 0.397610437259078, "actor_loss": -21.364327114105226, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.715102434158325, "step": 95000}
{"episode_reward": 290.21103704876043, "episode": 96.0, "batch_reward": 0.17958976177871228, "critic_loss": 0.4028514110893011, "actor_loss": -21.306978080749513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.358189344406128, "step": 96000}
{"episode_reward": 251.0748139781244, "episode": 97.0, "batch_reward": 0.18060135835409163, "critic_loss": 0.3310090027451515, "actor_loss": -21.384760135650634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.528022050857544, "step": 97000}
{"episode_reward": 387.6862677377142, "episode": 98.0, "batch_reward": 0.18316385716199876, "critic_loss": 0.3653987779766321, "actor_loss": -21.59187138366699, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.650879859924316, "step": 98000}
{"episode_reward": 446.09377790996945, "episode": 99.0, "batch_reward": 0.1869154012799263, "critic_loss": 0.3640892251729965, "actor_loss": -21.986182231903076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.562142848968506, "step": 99000}
{"episode_reward": 445.26655325646965, "episode": 100.0, "batch_reward": 0.18805500356853008, "critic_loss": 0.3698884827196598, "actor_loss": -21.941487785339355, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.70681142807007, "step": 100000}
{"episode_reward": 313.4668333678086, "episode": 101.0, "batch_reward": 0.19065701845288277, "critic_loss": 0.36174536642432215, "actor_loss": -22.083042125701905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.55930852890015, "step": 101000}
{"episode_reward": 402.85863009279717, "episode": 102.0, "batch_reward": 0.19190722586214543, "critic_loss": 0.3620998581647873, "actor_loss": -22.116398567199706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.777480602264404, "step": 102000}
{"episode_reward": 462.24088955619374, "episode": 103.0, "batch_reward": 0.19478326119482517, "critic_loss": 0.37105750501155854, "actor_loss": -22.68967358779907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41467571258545, "step": 103000}
{"episode_reward": 478.40973360787154, "episode": 104.0, "batch_reward": 0.1975112020522356, "critic_loss": 0.3690113666206598, "actor_loss": -22.825412784576415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.83227276802063, "step": 104000}
{"episode_reward": 372.89301865785075, "episode": 105.0, "batch_reward": 0.19940819157660009, "critic_loss": 0.38578721199929716, "actor_loss": -22.98536138534546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.83233141899109, "step": 105000}
{"episode_reward": 530.5345325753551, "episode": 106.0, "batch_reward": 0.20212558333575725, "critic_loss": 0.3794860875457525, "actor_loss": -23.06717195892334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.02924346923828, "step": 106000}
{"episode_reward": 391.27844661996653, "episode": 107.0, "batch_reward": 0.20461300165951252, "critic_loss": 0.3816919765174389, "actor_loss": -23.1778635635376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.449896097183228, "step": 107000}
{"episode_reward": 384.9242776698988, "episode": 108.0, "batch_reward": 0.2050009081363678, "critic_loss": 0.38907773277163504, "actor_loss": -23.36427613067627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.75972056388855, "step": 108000}
{"episode_reward": 340.492889420811, "episode": 109.0, "batch_reward": 0.2069592826962471, "critic_loss": 0.36907430508732797, "actor_loss": -23.510407821655274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3710880279541, "step": 109000}
{"episode_reward": 534.2003080246174, "episode": 110.0, "batch_reward": 0.2091089711934328, "critic_loss": 0.3533934228122234, "actor_loss": -23.863677047729492, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.8327898979187, "step": 110000}
{"episode_reward": 169.9065065112999, "episode": 111.0, "batch_reward": 0.2094332804530859, "critic_loss": 0.365631946824491, "actor_loss": -23.805959789276123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.44923281669617, "step": 111000}
{"episode_reward": 454.81813356361783, "episode": 112.0, "batch_reward": 0.21158646775782108, "critic_loss": 0.35522644010186194, "actor_loss": -23.83250762939453, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.970722436904907, "step": 112000}
{"episode_reward": 416.6365016726476, "episode": 113.0, "batch_reward": 0.21389621905982495, "critic_loss": 0.37558849146962164, "actor_loss": -24.096718383789064, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.420472860336304, "step": 113000}
{"episode_reward": 487.7367636058473, "episode": 114.0, "batch_reward": 0.21562477396428584, "critic_loss": 0.3660071487277746, "actor_loss": -24.310314323425292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.90587568283081, "step": 114000}
{"episode_reward": 512.981507459145, "episode": 115.0, "batch_reward": 0.2187283506691456, "critic_loss": 0.32976971912384034, "actor_loss": -24.796915992736817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.37765645980835, "step": 115000}
{"episode_reward": 524.3401173193656, "episode": 116.0, "batch_reward": 0.22144300793111324, "critic_loss": 0.3533464707136154, "actor_loss": -24.784241901397706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.9250385761261, "step": 116000}
{"episode_reward": 506.8779790188068, "episode": 117.0, "batch_reward": 0.22278810641169547, "critic_loss": 0.3484279650002718, "actor_loss": -25.229011348724367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.455411672592163, "step": 117000}
{"episode_reward": 75.53616837596535, "episode": 118.0, "batch_reward": 0.22160989555716515, "critic_loss": 0.3479963565915823, "actor_loss": -25.048960235595704, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.60781216621399, "step": 118000}
{"episode_reward": 509.06494543256565, "episode": 119.0, "batch_reward": 0.22425976152718066, "critic_loss": 0.3387467509359121, "actor_loss": -25.26044761657715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.043493270874023, "step": 119000}
{"episode_reward": 308.1900535066055, "episode": 120.0, "batch_reward": 0.2242722838819027, "critic_loss": 0.33420573449134827, "actor_loss": -25.243195903778076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.79892921447754, "step": 120000}
{"episode_reward": 278.27294074835896, "episode": 121.0, "batch_reward": 0.22533524172008038, "critic_loss": 0.32156792882084845, "actor_loss": -25.407907527923584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.91249132156372, "step": 121000}
{"episode_reward": 528.1361512658779, "episode": 122.0, "batch_reward": 0.22883062139153482, "critic_loss": 0.3540927347093821, "actor_loss": -25.53534295272827, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.929927110671997, "step": 122000}
{"episode_reward": 490.88387203763995, "episode": 123.0, "batch_reward": 0.23062366278469562, "critic_loss": 0.3265863414555788, "actor_loss": -25.55410891342163, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.083219289779663, "step": 123000}
{"episode_reward": 209.11700012179696, "episode": 124.0, "batch_reward": 0.2289132886081934, "critic_loss": 0.3110202577114105, "actor_loss": -25.56701717376709, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.663557052612305, "step": 124000}
{"episode_reward": 524.542455280313, "episode": 125.0, "batch_reward": 0.23246792356669904, "critic_loss": 0.3503513249307871, "actor_loss": -25.836328830718994, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.357714653015137, "step": 125000}
{"episode_reward": 264.60242233891574, "episode": 126.0, "batch_reward": 0.23288715836405754, "critic_loss": 0.3249735235571861, "actor_loss": -26.000607681274413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.971238613128662, "step": 126000}
{"episode_reward": 472.3881890956857, "episode": 127.0, "batch_reward": 0.23416826039552688, "critic_loss": 0.3245698329657316, "actor_loss": -26.174490615844725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.885240077972412, "step": 127000}
{"episode_reward": 505.9457614945802, "episode": 128.0, "batch_reward": 0.2368013741672039, "critic_loss": 0.32101122629642487, "actor_loss": -26.335535621643068, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.99906277656555, "step": 128000}
{"episode_reward": 504.15207651489436, "episode": 129.0, "batch_reward": 0.2395225350856781, "critic_loss": 0.32317433500289916, "actor_loss": -26.462250869750978, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.479480028152466, "step": 129000}
{"episode_reward": 574.1557855554697, "episode": 130.0, "batch_reward": 0.24203705328702926, "critic_loss": 0.3293119083493948, "actor_loss": -26.718378086090087, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.428945541381836, "step": 130000}
{"episode_reward": 474.7666430342159, "episode": 131.0, "batch_reward": 0.2436148272305727, "critic_loss": 0.3184416496306658, "actor_loss": -26.77550005722046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.772271156311035, "step": 131000}
{"episode_reward": 564.9318217421214, "episode": 132.0, "batch_reward": 0.24563872615993024, "critic_loss": 0.3099969173818827, "actor_loss": -26.793353591918944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34641408920288, "step": 132000}
{"episode_reward": 519.7653425531281, "episode": 133.0, "batch_reward": 0.24791382078826427, "critic_loss": 0.30420200107991696, "actor_loss": -27.07994931793213, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.945367574691772, "step": 133000}
{"episode_reward": 425.16213978005493, "episode": 134.0, "batch_reward": 0.24853488761186598, "critic_loss": 0.3092905644774437, "actor_loss": -27.148491760253908, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.677300691604614, "step": 134000}
{"episode_reward": 175.79853903088483, "episode": 135.0, "batch_reward": 0.2491251709163189, "critic_loss": 0.3106856759935617, "actor_loss": -27.243904510498048, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.044398546218872, "step": 135000}
{"episode_reward": 577.7140791845774, "episode": 136.0, "batch_reward": 0.251014034986496, "critic_loss": 0.3353760516494513, "actor_loss": -27.497947566986085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34513211250305, "step": 136000}
{"episode_reward": 399.47136110531534, "episode": 137.0, "batch_reward": 0.2524552322477102, "critic_loss": 0.32527181777358055, "actor_loss": -27.377573612213133, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.77295994758606, "step": 137000}
{"episode_reward": 535.3583417618547, "episode": 138.0, "batch_reward": 0.2553171046823263, "critic_loss": 0.35544806019961833, "actor_loss": -27.560697784423827, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.422675371170044, "step": 138000}
{"episode_reward": 555.7177522908204, "episode": 139.0, "batch_reward": 0.256665211379528, "critic_loss": 0.32400275141000745, "actor_loss": -27.917379890441893, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.37315344810486, "step": 139000}
{"episode_reward": 558.6148352402735, "episode": 140.0, "batch_reward": 0.2595256682783365, "critic_loss": 0.322472151607275, "actor_loss": -28.070105224609375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.126124143600464, "step": 140000}
{"episode_reward": 337.15840307309645, "episode": 141.0, "batch_reward": 0.25903248827159403, "critic_loss": 0.3527651779949665, "actor_loss": -27.993622871398927, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.07213020324707, "step": 141000}
{"episode_reward": 346.9792336459974, "episode": 142.0, "batch_reward": 0.25940898855030536, "critic_loss": 0.3149315382689238, "actor_loss": -28.263473178863524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.384331941604614, "step": 142000}
{"episode_reward": 569.5715873917086, "episode": 143.0, "batch_reward": 0.26228196373581886, "critic_loss": 0.35589493456482885, "actor_loss": -28.34319764328003, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23007869720459, "step": 143000}
{"episode_reward": 481.8536912218105, "episode": 144.0, "batch_reward": 0.2642493132799864, "critic_loss": 0.3487447336167097, "actor_loss": -28.444150817871094, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.10601806640625, "step": 144000}
{"episode_reward": 603.8790926197642, "episode": 145.0, "batch_reward": 0.26669770665466785, "critic_loss": 0.3848316497057676, "actor_loss": -28.432422042846678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.5138156414032, "step": 145000}
{"episode_reward": 337.93011360829865, "episode": 146.0, "batch_reward": 0.26605001632869246, "critic_loss": 0.3433812527656555, "actor_loss": -28.550421195983887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.259900331497192, "step": 146000}
{"episode_reward": 417.9203992558668, "episode": 147.0, "batch_reward": 0.26777512224018574, "critic_loss": 0.3697231514006853, "actor_loss": -28.80854034805298, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.757591247558594, "step": 147000}
{"episode_reward": 531.287063813402, "episode": 148.0, "batch_reward": 0.26871810330450535, "critic_loss": 0.38773267832398417, "actor_loss": -28.733646125793456, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.51535940170288, "step": 148000}
{"episode_reward": 384.83386153523094, "episode": 149.0, "batch_reward": 0.2707435686737299, "critic_loss": 0.3706450545042753, "actor_loss": -29.09046926498413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.498865127563477, "step": 149000}
{"episode_reward": 613.3085176928377, "episode": 150.0, "batch_reward": 0.271916381329298, "critic_loss": 0.3903538397997618, "actor_loss": -29.128563362121582, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
