{"episode_reward": 0.0, "episode": 1.0, "duration": 18.202855348587036, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.6191835403442383, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.24820807779399742, "critic_loss": 0.01762097372536657, "actor_loss": -19.863177132776745, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 69.33906674385071, "step": 3000}
{"episode_reward": 5.977575233737333, "episode": 4.0, "batch_reward": 0.15542579958587885, "critic_loss": 0.00905587647925131, "actor_loss": -18.03128996181488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.64446187019348, "step": 4000}
{"episode_reward": 7.4570167966971574, "episode": 5.0, "batch_reward": 0.12285609260946512, "critic_loss": 0.01464117328217253, "actor_loss": -17.941588971138, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.02100443840027, "step": 5000}
{"episode_reward": 10.369678993491027, "episode": 6.0, "batch_reward": 0.10211054147034883, "critic_loss": 0.01344907234981656, "actor_loss": -16.77043460559845, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.36647605895996, "step": 6000}
{"episode_reward": 9.322789394190949, "episode": 7.0, "batch_reward": 0.08792597432434558, "critic_loss": 0.012925109073985369, "actor_loss": -16.34309545993805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.92507839202881, "step": 7000}
{"episode_reward": 7.177031624460631, "episode": 8.0, "batch_reward": 0.07684236374869943, "critic_loss": 0.010778266560053453, "actor_loss": -16.203184844017027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.410370111465454, "step": 8000}
{"episode_reward": 8.429162127231951, "episode": 9.0, "batch_reward": 0.06823466712236405, "critic_loss": 0.009766797984717414, "actor_loss": -16.276141446113588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.20841932296753, "step": 9000}
{"episode_reward": 10.029624723263506, "episode": 10.0, "batch_reward": 0.06259150821529329, "critic_loss": 0.013200466725043953, "actor_loss": -15.935603533267974, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.770145893096924, "step": 10000}
{"episode_reward": 7.2339140708656435, "episode": 11.0, "batch_reward": 0.05692908666282892, "critic_loss": 0.012379558510379866, "actor_loss": -14.518098407268525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.32055640220642, "step": 11000}
{"episode_reward": 7.53185683448234, "episode": 12.0, "batch_reward": 0.05353511108085513, "critic_loss": 0.009532664599595592, "actor_loss": -15.296649874687194, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.26587176322937, "step": 12000}
{"episode_reward": 9.509122594270126, "episode": 13.0, "batch_reward": 0.04964363458007574, "critic_loss": 0.011475192750338465, "actor_loss": -13.968321372985839, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.451961994171143, "step": 13000}
{"episode_reward": 8.066403817774203, "episode": 14.0, "batch_reward": 0.04571816453058273, "critic_loss": 0.007922021974576638, "actor_loss": -14.067620168209077, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.34712266921997, "step": 14000}
{"episode_reward": 7.752669015167594, "episode": 15.0, "batch_reward": 0.04380677078291774, "critic_loss": 0.01408214824728202, "actor_loss": -12.327330220699311, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.892011404037476, "step": 15000}
{"episode_reward": 7.964674863770539, "episode": 16.0, "batch_reward": 0.04079603850189596, "critic_loss": 0.009318475992069579, "actor_loss": -15.252142031669617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.575523614883423, "step": 16000}
{"episode_reward": 9.01163541679333, "episode": 17.0, "batch_reward": 0.039301239839289334, "critic_loss": 0.008826114443014376, "actor_loss": -14.70884702205658, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.86601495742798, "step": 17000}
{"episode_reward": 10.29769978455592, "episode": 18.0, "batch_reward": 0.03733947864733636, "critic_loss": 0.006557118112454191, "actor_loss": -14.41986025762558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.430676698684692, "step": 18000}
{"episode_reward": 7.61031989601155, "episode": 19.0, "batch_reward": 0.036580163722857835, "critic_loss": 0.011363627689890564, "actor_loss": -14.408007605552672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.47671604156494, "step": 19000}
{"episode_reward": 13.285540015895894, "episode": 20.0, "batch_reward": 0.03523243165761232, "critic_loss": 0.007145871598972007, "actor_loss": -13.184476497173309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.004714965820312, "step": 20000}
{"episode_reward": 8.228257824416687, "episode": 21.0, "batch_reward": 0.03306245542317629, "critic_loss": 0.00737294028326869, "actor_loss": -13.902487897396087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.794031620025635, "step": 21000}
{"episode_reward": 10.406125233615834, "episode": 22.0, "batch_reward": 0.03226936340285465, "critic_loss": 0.008301447993260809, "actor_loss": -12.253565450191498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.474670886993408, "step": 22000}
{"episode_reward": 11.002950812489873, "episode": 23.0, "batch_reward": 0.031309602411463855, "critic_loss": 0.006978504165541381, "actor_loss": -13.16387825679779, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.07759690284729, "step": 23000}
{"episode_reward": 6.549979072531292, "episode": 24.0, "batch_reward": 0.0305942643545568, "critic_loss": 0.008416349728649948, "actor_loss": -12.569369623661041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.117827653884888, "step": 24000}
{"episode_reward": 7.409283478057073, "episode": 25.0, "batch_reward": 0.02959373169951141, "critic_loss": 0.008538800351670943, "actor_loss": -12.801255562543869, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.433603048324585, "step": 25000}
{"episode_reward": 8.329841357868688, "episode": 26.0, "batch_reward": 0.029132934188470246, "critic_loss": 0.0068438275945954955, "actor_loss": -13.316049335479736, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.604719638824463, "step": 26000}
{"episode_reward": 10.771137456862672, "episode": 27.0, "batch_reward": 0.028443486683536322, "critic_loss": 0.00791974503378151, "actor_loss": -11.784496223449707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.917372703552246, "step": 27000}
{"episode_reward": 9.08604609520926, "episode": 28.0, "batch_reward": 0.02674309992371127, "critic_loss": 0.009128255365183576, "actor_loss": -13.117528788089752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.03377604484558, "step": 28000}
{"episode_reward": 8.631232778667385, "episode": 29.0, "batch_reward": 0.026284477699548007, "critic_loss": 0.005710294490330853, "actor_loss": -11.73985260462761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.058335542678833, "step": 29000}
{"episode_reward": 10.060721898376109, "episode": 30.0, "batch_reward": 0.026488263678736985, "critic_loss": 0.00795752628275659, "actor_loss": -12.241892230987549, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18846344947815, "step": 30000}
{"episode_reward": 8.63605465101312, "episode": 31.0, "batch_reward": 0.02545879201637581, "critic_loss": 0.005462413504428696, "actor_loss": -13.174841040611268, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.96993136405945, "step": 31000}
{"episode_reward": 7.254894394622768, "episode": 32.0, "batch_reward": 0.024840595818590373, "critic_loss": 0.007438320056651719, "actor_loss": -12.33583429145813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31461787223816, "step": 32000}
{"episode_reward": 5.3850656504102945, "episode": 33.0, "batch_reward": 0.024838467323221265, "critic_loss": 0.00848926774377469, "actor_loss": -11.114613043785095, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.61822199821472, "step": 33000}
{"episode_reward": 10.360251193774104, "episode": 34.0, "batch_reward": 0.023837114427238702, "critic_loss": 0.004793450517870951, "actor_loss": -12.669197704553604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.942105293273926, "step": 34000}
{"episode_reward": 9.85028437442974, "episode": 35.0, "batch_reward": 0.023407555867917835, "critic_loss": 0.007582689300761558, "actor_loss": -12.799813564062118, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.158867597579956, "step": 35000}
{"episode_reward": 7.383917803911761, "episode": 36.0, "batch_reward": 0.023114101687446237, "critic_loss": 0.005876695088925772, "actor_loss": -12.551806288123132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.212573289871216, "step": 36000}
{"episode_reward": 9.72581178209056, "episode": 37.0, "batch_reward": 0.022617381944786758, "critic_loss": 0.007367148577352055, "actor_loss": -12.515799862384796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.016143321990967, "step": 37000}
{"episode_reward": 7.339681098011888, "episode": 38.0, "batch_reward": 0.022329301760997622, "critic_loss": 0.008243034298502608, "actor_loss": -11.330793750047684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.831264972686768, "step": 38000}
{"episode_reward": 6.257417904274686, "episode": 39.0, "batch_reward": 0.022201046576257794, "critic_loss": 0.005871432883432135, "actor_loss": -11.814737840652466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.38583731651306, "step": 39000}
{"episode_reward": 5.862841596026081, "episode": 40.0, "batch_reward": 0.02119304096419364, "critic_loss": 0.005587006554706022, "actor_loss": -12.45642397904396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.722705841064453, "step": 40000}
{"episode_reward": 6.082704490352353, "episode": 41.0, "batch_reward": 0.02114800314232707, "critic_loss": 0.007157207108393777, "actor_loss": -13.135567624568939, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.41647124290466, "step": 41000}
{"episode_reward": 7.516683383103081, "episode": 42.0, "batch_reward": 0.020650841532740744, "critic_loss": 0.006530123064934742, "actor_loss": -12.106563669204712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97505259513855, "step": 42000}
{"episode_reward": 6.513644740015418, "episode": 43.0, "batch_reward": 0.0202504929471761, "critic_loss": 0.0069567382455861665, "actor_loss": -12.026304280042648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.77735733985901, "step": 43000}
{"episode_reward": 8.31125538960214, "episode": 44.0, "batch_reward": 0.01991050008777529, "critic_loss": 0.004998512285470497, "actor_loss": -11.685919378519058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.78106665611267, "step": 44000}
{"episode_reward": 7.317908537791677, "episode": 45.0, "batch_reward": 0.019742091632448135, "critic_loss": 0.005412566655257251, "actor_loss": -10.906354815244674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.391984939575195, "step": 45000}
{"episode_reward": 7.365682208918293, "episode": 46.0, "batch_reward": 0.019691719443537294, "critic_loss": 0.0055155475510691755, "actor_loss": -11.701687510251999, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.627365589141846, "step": 46000}
{"episode_reward": 10.169289515807465, "episode": 47.0, "batch_reward": 0.019387364176567643, "critic_loss": 0.0057064170469238885, "actor_loss": -12.659058343052864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.452661275863647, "step": 47000}
{"episode_reward": 6.2367153222005145, "episode": 48.0, "batch_reward": 0.018997786834836005, "critic_loss": 0.0055146623233449646, "actor_loss": -11.414636890530586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.09641456604004, "step": 48000}
{"episode_reward": 6.795570287527462, "episode": 49.0, "batch_reward": 0.019274532917886972, "critic_loss": 0.006170913556066807, "actor_loss": -11.539167035341263, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.912315845489502, "step": 49000}
{"episode_reward": 7.453120432295246, "episode": 50.0, "batch_reward": 0.018904828496742992, "critic_loss": 0.004760570922924671, "actor_loss": -12.21223184454441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.975972652435303, "step": 50000}
{"episode_reward": 11.137368613235378, "episode": 51.0, "batch_reward": 0.018522047818172724, "critic_loss": 0.006738574819552014, "actor_loss": -10.164753049731255, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.51578187942505, "step": 51000}
{"episode_reward": 10.098283737380712, "episode": 52.0, "batch_reward": 0.018522120723035187, "critic_loss": 0.006718131607020041, "actor_loss": -12.726875293791293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.702393770217896, "step": 52000}
{"episode_reward": 7.475991930478656, "episode": 53.0, "batch_reward": 0.018265463655814527, "critic_loss": 0.005503372192935786, "actor_loss": -10.519368735432625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.086317777633667, "step": 53000}
{"episode_reward": 6.478290178800252, "episode": 54.0, "batch_reward": 0.018337173712439835, "critic_loss": 0.00705217688769335, "actor_loss": -12.350322861611843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.530197381973267, "step": 54000}
{"episode_reward": 7.375388459121393, "episode": 55.0, "batch_reward": 0.017668389530852438, "critic_loss": 0.004148462235432817, "actor_loss": -11.990853829324246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.677818775177002, "step": 55000}
{"episode_reward": 6.522187074839669, "episode": 56.0, "batch_reward": 0.01734231045655906, "critic_loss": 0.006217223501211265, "actor_loss": -10.59455730009079, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.020945072174072, "step": 56000}
{"episode_reward": 7.989354537104922, "episode": 57.0, "batch_reward": 0.017493264434393495, "critic_loss": 0.005545358718838543, "actor_loss": -11.170597771048547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.488579034805298, "step": 57000}
{"episode_reward": 7.345188563130117, "episode": 58.0, "batch_reward": 0.017219329877756536, "critic_loss": 0.006202231179369846, "actor_loss": -10.515811347961426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.743738412857056, "step": 58000}
{"episode_reward": 8.696758507669415, "episode": 59.0, "batch_reward": 0.016898115313146264, "critic_loss": 0.0036693146500911098, "actor_loss": -11.790099424719811, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.740654468536377, "step": 59000}
{"episode_reward": 12.11325568960305, "episode": 60.0, "batch_reward": 0.017011044487822802, "critic_loss": 0.005558045886718901, "actor_loss": -12.498029838383198, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.731731176376343, "step": 60000}
{"episode_reward": 14.384131954125081, "episode": 61.0, "batch_reward": 0.016725414532702418, "critic_loss": 0.004833780451066559, "actor_loss": -11.497053664803506, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.88700985908508, "step": 61000}
{"episode_reward": 7.280974816717407, "episode": 62.0, "batch_reward": 0.01642515875957906, "critic_loss": 0.004428774759668158, "actor_loss": -10.163555502474308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.012128591537476, "step": 62000}
{"episode_reward": 10.863346175402675, "episode": 63.0, "batch_reward": 0.01651157205272466, "critic_loss": 0.005260519428324187, "actor_loss": -10.036084838032723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.88267970085144, "step": 63000}
{"episode_reward": 10.193163913078257, "episode": 64.0, "batch_reward": 0.016439122166484594, "critic_loss": 0.004012624192080694, "actor_loss": -11.312589610040188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.661722421646118, "step": 64000}
{"episode_reward": 12.208791303674577, "episode": 65.0, "batch_reward": 0.016532454305328428, "critic_loss": 0.005246905829408206, "actor_loss": -11.118475944459439, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.880518674850464, "step": 65000}
{"episode_reward": 8.390569773294894, "episode": 66.0, "batch_reward": 0.016099676660262047, "critic_loss": 0.0038178253804217093, "actor_loss": -10.559455233991146, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.561217784881592, "step": 66000}
{"episode_reward": 7.335885122692943, "episode": 67.0, "batch_reward": 0.01605704972241074, "critic_loss": 0.005316758761822712, "actor_loss": -10.919697589099407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.803848028182983, "step": 67000}
{"episode_reward": 7.0260550834979645, "episode": 68.0, "batch_reward": 0.01616571501083672, "critic_loss": 0.005089105372404447, "actor_loss": -11.592033363819123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16245436668396, "step": 68000}
{"episode_reward": 6.314271813190291, "episode": 69.0, "batch_reward": 0.0160877882335335, "critic_loss": 0.004338731485564494, "actor_loss": -11.106723596394062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.306652069091797, "step": 69000}
{"episode_reward": 12.591858339167471, "episode": 70.0, "batch_reward": 0.015761553797870875, "critic_loss": 0.004533257981878706, "actor_loss": -12.011700534969568, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.385806798934937, "step": 70000}
{"episode_reward": 8.026937815187583, "episode": 71.0, "batch_reward": 0.015723939132876695, "critic_loss": 0.004596026846178575, "actor_loss": -11.673143150150777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.73885536193848, "step": 71000}
{"episode_reward": 7.729969067588801, "episode": 72.0, "batch_reward": 0.015547682740725577, "critic_loss": 0.004002362357423408, "actor_loss": -11.171246816188097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.99516248703003, "step": 72000}
{"episode_reward": 6.380904891392683, "episode": 73.0, "batch_reward": 0.015602980297058821, "critic_loss": 0.004985945682332385, "actor_loss": -11.16951190713048, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.222999334335327, "step": 73000}
{"episode_reward": 8.496936459894329, "episode": 74.0, "batch_reward": 0.015382659934926778, "critic_loss": 0.004263522921013646, "actor_loss": -12.125610947489738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.861104249954224, "step": 74000}
{"episode_reward": 8.272578658659116, "episode": 75.0, "batch_reward": 0.01564573895651847, "critic_loss": 0.005387239624571521, "actor_loss": -11.752144027322531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.61196804046631, "step": 75000}
{"episode_reward": 8.029110575812316, "episode": 76.0, "batch_reward": 0.015084677649661898, "critic_loss": 0.0034845366114750506, "actor_loss": -12.541634856462478, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.189087629318237, "step": 76000}
{"episode_reward": 7.315584291133417, "episode": 77.0, "batch_reward": 0.014886570853646844, "critic_loss": 0.005010621361143421, "actor_loss": -10.883703015565873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.993404388427734, "step": 77000}
{"episode_reward": 11.472288660591534, "episode": 78.0, "batch_reward": 0.01520004882151261, "critic_loss": 0.005159329221496592, "actor_loss": -11.121905720949172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.739110708236694, "step": 78000}
{"episode_reward": 7.2703262674011055, "episode": 79.0, "batch_reward": 0.014874445490073412, "critic_loss": 0.0034671193896065235, "actor_loss": -10.754451419889927, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.77063012123108, "step": 79000}
{"episode_reward": 8.169870996134856, "episode": 80.0, "batch_reward": 0.014978072591125964, "critic_loss": 0.004738607455103193, "actor_loss": -11.696978238493204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.295673608779907, "step": 80000}
{"episode_reward": 7.807819561101117, "episode": 81.0, "batch_reward": 0.014880214906297625, "critic_loss": 0.003514492918140604, "actor_loss": -10.988658290416002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.666242599487305, "step": 81000}
{"episode_reward": 7.208766982904125, "episode": 82.0, "batch_reward": 0.014624856199137866, "critic_loss": 0.0033599529179628006, "actor_loss": -10.97459862947464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.92195987701416, "step": 82000}
{"episode_reward": 7.008551750421733, "episode": 83.0, "batch_reward": 0.014509192163124681, "critic_loss": 0.005763524417590816, "actor_loss": -11.938641002833844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.73036289215088, "step": 83000}
{"episode_reward": 7.1927523411433905, "episode": 84.0, "batch_reward": 0.014195316642988473, "critic_loss": 0.0025817327147233298, "actor_loss": -12.107255471765995, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.900920867919922, "step": 84000}
{"episode_reward": 6.496106836010518, "episode": 85.0, "batch_reward": 0.014725198254454881, "critic_loss": 0.004727956560323946, "actor_loss": -10.58472217786312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.532800436019897, "step": 85000}
{"episode_reward": 4.985995054053279, "episode": 86.0, "batch_reward": 0.014364728729706257, "critic_loss": 0.003674290306749754, "actor_loss": -11.442575472056866, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.64861536026001, "step": 86000}
{"episode_reward": 9.504204922727386, "episode": 87.0, "batch_reward": 0.014620138267055154, "critic_loss": 0.003581827173329657, "actor_loss": -11.556136078596115, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.75976324081421, "step": 87000}
{"episode_reward": 8.243483959299102, "episode": 88.0, "batch_reward": 0.014378990409430116, "critic_loss": 0.00403378582856385, "actor_loss": -11.711677895873786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.911158084869385, "step": 88000}
{"episode_reward": 6.691062944019721, "episode": 89.0, "batch_reward": 0.014119855829980224, "critic_loss": 0.002533605081785936, "actor_loss": -11.040758156210185, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.294673919677734, "step": 89000}
{"episode_reward": 11.79156885512522, "episode": 90.0, "batch_reward": 0.013978894155472517, "critic_loss": 0.004271237479610136, "actor_loss": -11.138473402142525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.179199934005737, "step": 90000}
{"episode_reward": 8.943101414626728, "episode": 91.0, "batch_reward": 0.014086528210435063, "critic_loss": 0.004537100358051248, "actor_loss": -11.026341313272715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.32497000694275, "step": 91000}
{"episode_reward": 10.216232982759418, "episode": 92.0, "batch_reward": 0.01407501313695684, "critic_loss": 0.0037242110202059847, "actor_loss": -11.29828471404314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.00223422050476, "step": 92000}
{"episode_reward": 9.285002029306746, "episode": 93.0, "batch_reward": 0.014088353518396615, "critic_loss": 0.0041329829485912345, "actor_loss": -11.171561689257622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.368839025497437, "step": 93000}
{"episode_reward": 9.731142149269333, "episode": 94.0, "batch_reward": 0.013750687585212291, "critic_loss": 0.0035445221090485575, "actor_loss": -11.498810823112727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.389246940612793, "step": 94000}
{"episode_reward": 8.690499983360272, "episode": 95.0, "batch_reward": 0.013742836117744446, "critic_loss": 0.004685888227424584, "actor_loss": -10.946028706863522, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.962977170944214, "step": 95000}
{"episode_reward": 9.839284830507452, "episode": 96.0, "batch_reward": 0.013814550606068223, "critic_loss": 0.0031806616085232236, "actor_loss": -12.267533464863897, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.785724878311157, "step": 96000}
{"episode_reward": 6.362512091346924, "episode": 97.0, "batch_reward": 0.013642200756818056, "critic_loss": 0.003649086520279525, "actor_loss": -11.156519684240221, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.988706350326538, "step": 97000}
{"episode_reward": 5.0454071931298605, "episode": 98.0, "batch_reward": 0.013533149250783026, "critic_loss": 0.004089723007724388, "actor_loss": -10.600777628391981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.345713138580322, "step": 98000}
{"episode_reward": 9.162818840187098, "episode": 99.0, "batch_reward": 0.013720177537761629, "critic_loss": 0.003432341341715073, "actor_loss": -12.358013685688377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.45552110671997, "step": 99000}
{"episode_reward": 7.427601924535486, "episode": 100.0, "batch_reward": 0.013433269553352147, "critic_loss": 0.0032621221553417856, "actor_loss": -11.4788457762748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1175057888031, "step": 100000}
{"episode_reward": 8.48318975057316, "episode": 101.0, "batch_reward": 0.013379434624686838, "critic_loss": 0.0032325194750446825, "actor_loss": -11.685537635669112, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.146066665649414, "step": 101000}
{"episode_reward": 9.463680265433165, "episode": 102.0, "batch_reward": 0.013269892363809049, "critic_loss": 0.004412473930016859, "actor_loss": -11.228778669849039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.673741102218628, "step": 102000}
{"episode_reward": 6.180297755571498, "episode": 103.0, "batch_reward": 0.01346084696194157, "critic_loss": 0.0035543668090831488, "actor_loss": -11.092298995360732, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.395883083343506, "step": 103000}
{"episode_reward": 6.0487873044465, "episode": 104.0, "batch_reward": 0.013582931926008315, "critic_loss": 0.0043783949795761145, "actor_loss": -11.916793962210416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.464411735534668, "step": 104000}
{"episode_reward": 6.982166448373932, "episode": 105.0, "batch_reward": 0.01317554640956223, "critic_loss": 0.003938742610276677, "actor_loss": -11.946330261677504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.04030704498291, "step": 105000}
{"episode_reward": 7.744034640517447, "episode": 106.0, "batch_reward": 0.013312440661713481, "critic_loss": 0.0037267191022692715, "actor_loss": -12.018452186614274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.45552682876587, "step": 106000}
{"episode_reward": 10.911019276014876, "episode": 107.0, "batch_reward": 0.013160962857306004, "critic_loss": 0.00313371432578424, "actor_loss": -12.154676706671715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.176970958709717, "step": 107000}
{"episode_reward": 10.183724119517759, "episode": 108.0, "batch_reward": 0.012906215709168464, "critic_loss": 0.0027540282859408764, "actor_loss": -10.551109089434147, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.4814350605011, "step": 108000}
{"episode_reward": 9.829953607207022, "episode": 109.0, "batch_reward": 0.013128946306649595, "critic_loss": 0.004448142637498677, "actor_loss": -12.386960118666291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.497341632843018, "step": 109000}
{"episode_reward": 8.295169085842451, "episode": 110.0, "batch_reward": 0.012909261639695614, "critic_loss": 0.0034738382542273028, "actor_loss": -12.367013182386756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.135510444641113, "step": 110000}
{"episode_reward": 10.217697827071573, "episode": 111.0, "batch_reward": 0.013018781382124872, "critic_loss": 0.002179514353221748, "actor_loss": -10.503276767164468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.297560691833496, "step": 111000}
{"episode_reward": 7.491469105737339, "episode": 112.0, "batch_reward": 0.013134454473853112, "critic_loss": 0.005045175928171375, "actor_loss": -13.081381260722875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.503897190093994, "step": 112000}
{"episode_reward": 7.855147328172014, "episode": 113.0, "batch_reward": 0.012993770204950125, "critic_loss": 0.003065900238463655, "actor_loss": -11.660615531742573, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.437721014022827, "step": 113000}
{"episode_reward": 7.508317957291304, "episode": 114.0, "batch_reward": 0.01304555941047147, "critic_loss": 0.0029691198860236907, "actor_loss": -11.927825093254446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.863044023513794, "step": 114000}
{"episode_reward": 7.426813212091537, "episode": 115.0, "batch_reward": 0.012608616952318697, "critic_loss": 0.0029325420744280564, "actor_loss": -11.684696324571966, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.786945343017578, "step": 115000}
{"episode_reward": 9.764629521292386, "episode": 116.0, "batch_reward": 0.012736156244762242, "critic_loss": 0.0038075232172268443, "actor_loss": -11.29482633818686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.2497456073761, "step": 116000}
{"episode_reward": 10.770075010885904, "episode": 117.0, "batch_reward": 0.01315870992746204, "critic_loss": 0.0026809019090578657, "actor_loss": -10.05774683137238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.547098636627197, "step": 117000}
{"episode_reward": 7.390392166578284, "episode": 118.0, "batch_reward": 0.01267016217391938, "critic_loss": 0.0027722750095126687, "actor_loss": -10.909348543420434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.10298776626587, "step": 118000}
{"episode_reward": 8.871339913814117, "episode": 119.0, "batch_reward": 0.01266802861681208, "critic_loss": 0.00268324651781586, "actor_loss": -10.907493298180402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.307672023773193, "step": 119000}
{"episode_reward": 7.2925546518167605, "episode": 120.0, "batch_reward": 0.012666267734020948, "critic_loss": 0.0027773059992614434, "actor_loss": -10.0820279122293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.145458459854126, "step": 120000}
{"episode_reward": 10.3156812111789, "episode": 121.0, "batch_reward": 0.012668193692341448, "critic_loss": 0.0024494287897250614, "actor_loss": -10.976092788286508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.24289846420288, "step": 121000}
{"episode_reward": 6.135593988081927, "episode": 122.0, "batch_reward": 0.012735801060218365, "critic_loss": 0.003831698395908461, "actor_loss": -10.921005953751504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1889226436615, "step": 122000}
{"episode_reward": 7.9861447871632505, "episode": 123.0, "batch_reward": 0.01233917434886098, "critic_loss": 0.002710959994292352, "actor_loss": -11.557717018306255, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.11592197418213, "step": 123000}
{"episode_reward": 8.212998747569833, "episode": 124.0, "batch_reward": 0.012531179356388748, "critic_loss": 0.0023909179476468124, "actor_loss": -11.662702179640531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.599955558776855, "step": 124000}
{"episode_reward": 10.593786105456118, "episode": 125.0, "batch_reward": 0.012584024759009481, "critic_loss": 0.004888373984416831, "actor_loss": -11.448894335471094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.06088900566101, "step": 125000}
{"episode_reward": 8.574229230278654, "episode": 126.0, "batch_reward": 0.012592002059798688, "critic_loss": 0.0022203536609740693, "actor_loss": -10.636030921779573, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.678914546966553, "step": 126000}
{"episode_reward": 8.073290364731854, "episode": 127.0, "batch_reward": 0.012413412586320192, "critic_loss": 0.0019567155079421353, "actor_loss": -12.540369133874774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.133786916732788, "step": 127000}
{"episode_reward": 7.411251103789497, "episode": 128.0, "batch_reward": 0.012019713561050594, "critic_loss": 0.003927419399915379, "actor_loss": -11.263936210744083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.531160593032837, "step": 128000}
{"episode_reward": 10.847059919665876, "episode": 129.0, "batch_reward": 0.012622365759219975, "critic_loss": 0.0027304651261947583, "actor_loss": -10.622915357835591, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.569902181625366, "step": 129000}
{"episode_reward": 6.08449686530827, "episode": 130.0, "batch_reward": 0.012124377522151918, "critic_loss": 0.0022648686299216935, "actor_loss": -10.926877399280666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.73943591117859, "step": 130000}
{"episode_reward": 10.373384022464709, "episode": 131.0, "batch_reward": 0.012294937090948223, "critic_loss": 0.0028866066994378344, "actor_loss": -11.457837260752916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.64900517463684, "step": 131000}
{"episode_reward": 8.360590570989443, "episode": 132.0, "batch_reward": 0.012277436150703579, "critic_loss": 0.0031100704896089154, "actor_loss": -11.92714158384502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.714661359786987, "step": 132000}
{"episode_reward": 6.563056197446195, "episode": 133.0, "batch_reward": 0.012081807720009238, "critic_loss": 0.0026462607950670644, "actor_loss": -10.64770684773475, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.220245599746704, "step": 133000}
{"episode_reward": 7.380478336617393, "episode": 134.0, "batch_reward": 0.01233997729094699, "critic_loss": 0.002501437619954231, "actor_loss": -10.234834649965167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.856662034988403, "step": 134000}
{"episode_reward": 8.93646773766219, "episode": 135.0, "batch_reward": 0.012173575706779956, "critic_loss": 0.0027708395037188893, "actor_loss": -11.912228981524706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.267383098602295, "step": 135000}
{"episode_reward": 10.648556847464588, "episode": 136.0, "batch_reward": 0.012100181424058973, "critic_loss": 0.002263001718354644, "actor_loss": -9.325291579954326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.698598861694336, "step": 136000}
{"episode_reward": 8.532095150025121, "episode": 137.0, "batch_reward": 0.012101788632571697, "critic_loss": 0.002891390491844504, "actor_loss": -11.251569915212691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.445159435272217, "step": 137000}
{"episode_reward": 7.124560111742188, "episode": 138.0, "batch_reward": 0.012096848706714809, "critic_loss": 0.0023870137411286124, "actor_loss": -11.358426474742592, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.364081859588623, "step": 138000}
{"episode_reward": 8.225802663400152, "episode": 139.0, "batch_reward": 0.011995741583406926, "critic_loss": 0.0026440095589350676, "actor_loss": -10.808742623649538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.28400158882141, "step": 139000}
{"episode_reward": 7.21924873814938, "episode": 140.0, "batch_reward": 0.01196664805803448, "critic_loss": 0.002663146234306623, "actor_loss": -11.527600148752331, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.618806838989258, "step": 140000}
{"episode_reward": 8.137667266309338, "episode": 141.0, "batch_reward": 0.012205908020492644, "critic_loss": 0.002883014873455977, "actor_loss": -11.638017410002648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.869348764419556, "step": 141000}
{"episode_reward": 9.300726694315108, "episode": 142.0, "batch_reward": 0.012036361396312714, "critic_loss": 0.002597827727528056, "actor_loss": -10.754968006424606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34294295310974, "step": 142000}
{"episode_reward": 7.20536548409746, "episode": 143.0, "batch_reward": 0.012195116938091815, "critic_loss": 0.0027057717570132807, "actor_loss": -10.492308451637626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.338877201080322, "step": 143000}
{"episode_reward": 10.446832332873754, "episode": 144.0, "batch_reward": 0.011771268106997013, "critic_loss": 0.0031822215443826282, "actor_loss": -11.140850625604392, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.44924020767212, "step": 144000}
{"episode_reward": 11.728162127040301, "episode": 145.0, "batch_reward": 0.011866131355986, "critic_loss": 0.00248652676497295, "actor_loss": -11.408710220173, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.559929847717285, "step": 145000}
{"episode_reward": 11.970965939415166, "episode": 146.0, "batch_reward": 0.012009039900265634, "critic_loss": 0.0025254149383690675, "actor_loss": -11.586631629392505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.217522621154785, "step": 146000}
{"episode_reward": 7.083708350989681, "episode": 147.0, "batch_reward": 0.011838966825511306, "critic_loss": 0.003463386631716276, "actor_loss": -11.031863898321987, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.416111946105957, "step": 147000}
{"episode_reward": 9.988054337741543, "episode": 148.0, "batch_reward": 0.011925495756324381, "critic_loss": 0.0025753288262640125, "actor_loss": -11.302050393380224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.951807260513306, "step": 148000}
{"episode_reward": 7.654654850098393, "episode": 149.0, "batch_reward": 0.011883893624413758, "critic_loss": 0.0023499075797008117, "actor_loss": -11.40447424968332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.864436388015747, "step": 149000}
{"episode_reward": 7.430729134444327, "episode": 150.0, "batch_reward": 0.012268379588611425, "critic_loss": 0.002717582150318776, "actor_loss": -11.866287263922393, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
