{"episode_reward": 0.0, "episode": 1.0, "duration": 18.69429898262024, "step": 1000}
{"episode_reward": 7.300100444933085, "episode": 2.0, "duration": 1.5147039890289307, "step": 2000}
{"episode_reward": 521.6090064697321, "episode": 3.0, "batch_reward": 0.2487206698139734, "critic_loss": 0.02233730450725334, "actor_loss": -9.899179759559084, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 68.76496195793152, "step": 3000}
{"episode_reward": 10.96039269172631, "episode": 4.0, "batch_reward": 0.16050076466053725, "critic_loss": 0.015477816843893379, "actor_loss": -7.6982141371965405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.563669204711914, "step": 4000}
{"episode_reward": 42.249460739563155, "episode": 5.0, "batch_reward": 0.14259524221718312, "critic_loss": 0.02576019206829369, "actor_loss": -8.639329638004304, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.910418272018433, "step": 5000}
{"episode_reward": 86.97864789494446, "episode": 6.0, "batch_reward": 0.13359529127925635, "critic_loss": 0.04705890742503106, "actor_loss": -7.8893471672534945, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.884077072143555, "step": 6000}
{"episode_reward": 139.18232736082706, "episode": 7.0, "batch_reward": 0.13888841211795808, "critic_loss": 0.05796759514138103, "actor_loss": -8.132126727104186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.6816885471344, "step": 7000}
{"episode_reward": 219.30249916109318, "episode": 8.0, "batch_reward": 0.14437668768316508, "critic_loss": 0.0684028425682336, "actor_loss": -11.101148230075836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.30347442626953, "step": 8000}
{"episode_reward": 92.92605199204297, "episode": 9.0, "batch_reward": 0.1421675118803978, "critic_loss": 0.07965898096933961, "actor_loss": -10.750384085655213, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.59140658378601, "step": 9000}
{"episode_reward": 124.89315437125472, "episode": 10.0, "batch_reward": 0.13820810513943435, "critic_loss": 0.08415770680457353, "actor_loss": -10.807072845458984, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.669365406036377, "step": 10000}
{"episode_reward": 76.57561442464721, "episode": 11.0, "batch_reward": 0.1317756364643574, "critic_loss": 0.07882246974483133, "actor_loss": -9.991123854637147, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.3010790348053, "step": 11000}
{"episode_reward": 80.28049890774066, "episode": 12.0, "batch_reward": 0.1283940048366785, "critic_loss": 0.08465802158415317, "actor_loss": -11.164124628067016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.803940534591675, "step": 12000}
{"episode_reward": 93.87745400393761, "episode": 13.0, "batch_reward": 0.12300549533963204, "critic_loss": 0.09783519491180778, "actor_loss": -10.779601027488708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.637969255447388, "step": 13000}
{"episode_reward": 48.46706572764643, "episode": 14.0, "batch_reward": 0.12188594720512629, "critic_loss": 0.1071205891445279, "actor_loss": -10.912056135177613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.727346897125244, "step": 14000}
{"episode_reward": 167.297375504554, "episode": 15.0, "batch_reward": 0.1194856843277812, "critic_loss": 0.10577155619114638, "actor_loss": -10.66310398864746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.82330632209778, "step": 15000}
{"episode_reward": 20.692296856361487, "episode": 16.0, "batch_reward": 0.11445688103884459, "critic_loss": 0.11048247953876852, "actor_loss": -11.066977542877197, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.692479133605957, "step": 16000}
{"episode_reward": 60.72142226453513, "episode": 17.0, "batch_reward": 0.11288322935998439, "critic_loss": 0.11464792244136333, "actor_loss": -11.397530028343201, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.77277708053589, "step": 17000}
{"episode_reward": 100.3494001789504, "episode": 18.0, "batch_reward": 0.11175478164851665, "critic_loss": 0.13093818141520022, "actor_loss": -11.394613315582275, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.188618898391724, "step": 18000}
{"episode_reward": 98.91394736913601, "episode": 19.0, "batch_reward": 0.11469637767970561, "critic_loss": 0.1230496998615563, "actor_loss": -11.769489046096801, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.402506828308105, "step": 19000}
{"episode_reward": 174.49530416611532, "episode": 20.0, "batch_reward": 0.11479668650776148, "critic_loss": 0.13130310831964015, "actor_loss": -11.856273719787598, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.12785005569458, "step": 20000}
{"episode_reward": 92.02011045024578, "episode": 21.0, "batch_reward": 0.11461059115827084, "critic_loss": 0.14067870463430882, "actor_loss": -12.268603076934815, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.09548783302307, "step": 21000}
{"episode_reward": 202.39552155740398, "episode": 22.0, "batch_reward": 0.11857869114726782, "critic_loss": 0.15423950618505478, "actor_loss": -12.417714288711547, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.8948655128479, "step": 22000}
{"episode_reward": 149.97677943529135, "episode": 23.0, "batch_reward": 0.12069541749358177, "critic_loss": 0.16377244789898396, "actor_loss": -12.667089685440063, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.409812211990356, "step": 23000}
{"episode_reward": 198.997686519748, "episode": 24.0, "batch_reward": 0.12227449189871549, "critic_loss": 0.16316711861640215, "actor_loss": -12.784981353759765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.350967407226562, "step": 24000}
{"episode_reward": 90.46645246351174, "episode": 25.0, "batch_reward": 0.12434880305081605, "critic_loss": 0.17029197677969932, "actor_loss": -13.026712902069091, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.913944721221924, "step": 25000}
{"episode_reward": 217.9410991569253, "episode": 26.0, "batch_reward": 0.12530799590051175, "critic_loss": 0.19263754115998746, "actor_loss": -13.32683417892456, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.975759506225586, "step": 26000}
{"episode_reward": 197.8402619631194, "episode": 27.0, "batch_reward": 0.1301822836101055, "critic_loss": 0.21610272821784018, "actor_loss": -13.888859254837037, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.684866428375244, "step": 27000}
{"episode_reward": 298.84424833616725, "episode": 28.0, "batch_reward": 0.13584465193748474, "critic_loss": 0.24634315137565135, "actor_loss": -14.72730237197876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.954669713974, "step": 28000}
{"episode_reward": 216.0247114916773, "episode": 29.0, "batch_reward": 0.13973724870383739, "critic_loss": 0.26111891451478003, "actor_loss": -15.08031628036499, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.049647331237793, "step": 29000}
{"episode_reward": 348.56978626961325, "episode": 30.0, "batch_reward": 0.14599099246412517, "critic_loss": 0.26671821146458385, "actor_loss": -15.998157819747926, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.52212119102478, "step": 30000}
{"episode_reward": 270.10383874238033, "episode": 31.0, "batch_reward": 0.14734288991242647, "critic_loss": 0.30520982655882833, "actor_loss": -16.42728065299988, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.48959136009216, "step": 31000}
{"episode_reward": 70.27966246381361, "episode": 32.0, "batch_reward": 0.14819084718078374, "critic_loss": 0.3165751600712538, "actor_loss": -16.740927976608276, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.691690921783447, "step": 32000}
{"episode_reward": 294.47512436203834, "episode": 33.0, "batch_reward": 0.1526442288607359, "critic_loss": 0.32539685209095476, "actor_loss": -17.499939153671264, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.311004400253296, "step": 33000}
{"episode_reward": 242.9585874118452, "episode": 34.0, "batch_reward": 0.15533816335350276, "critic_loss": 0.3359866258651018, "actor_loss": -17.975187799453735, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.898772954940796, "step": 34000}
{"episode_reward": 283.71821663697347, "episode": 35.0, "batch_reward": 0.15583687718957662, "critic_loss": 0.3529357698559761, "actor_loss": -18.2090913772583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.678266763687134, "step": 35000}
{"episode_reward": 42.65057690590502, "episode": 36.0, "batch_reward": 0.15455082950741053, "critic_loss": 0.3489416742324829, "actor_loss": -18.391951734542847, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.357727766036987, "step": 36000}
{"episode_reward": 236.5846102007581, "episode": 37.0, "batch_reward": 0.15749563930928706, "critic_loss": 0.3625876146256924, "actor_loss": -18.84765229034424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.795097827911377, "step": 37000}
{"episode_reward": 271.8403277527232, "episode": 38.0, "batch_reward": 0.16302173472195863, "critic_loss": 0.3869754731208086, "actor_loss": -19.264885580062867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.545413494110107, "step": 38000}
{"episode_reward": 373.6080262570465, "episode": 39.0, "batch_reward": 0.16530878637731075, "critic_loss": 0.4046657668799162, "actor_loss": -19.695659088134764, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.478948831558228, "step": 39000}
{"episode_reward": 109.77518868154364, "episode": 40.0, "batch_reward": 0.1624319675117731, "critic_loss": 0.40527617056667803, "actor_loss": -19.6747485370636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.28404974937439, "step": 40000}
{"episode_reward": 113.46820735840262, "episode": 41.0, "batch_reward": 0.16413959497958422, "critic_loss": 0.4414410171359777, "actor_loss": -20.006782859802247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.07449293136597, "step": 41000}
{"episode_reward": 365.8675002752796, "episode": 42.0, "batch_reward": 0.16674527248740195, "critic_loss": 0.5200460364222527, "actor_loss": -20.49933044433594, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.71273946762085, "step": 42000}
{"episode_reward": 107.75556765229742, "episode": 43.0, "batch_reward": 0.16816232374310494, "critic_loss": 0.5085743424743414, "actor_loss": -20.868994842529297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.355286121368408, "step": 43000}
{"episode_reward": 337.9321872383212, "episode": 44.0, "batch_reward": 0.17082215447723864, "critic_loss": 0.49642827512323856, "actor_loss": -21.35573461151123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.246296882629395, "step": 44000}
{"episode_reward": 252.6170077232706, "episode": 45.0, "batch_reward": 0.1719009866565466, "critic_loss": 0.4888501947671175, "actor_loss": -21.562780017852784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.179722785949707, "step": 45000}
{"episode_reward": 110.41223596979238, "episode": 46.0, "batch_reward": 0.17107029562443496, "critic_loss": 0.49607164491713046, "actor_loss": -21.684004390716552, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.031607151031494, "step": 46000}
{"episode_reward": 125.56533962072199, "episode": 47.0, "batch_reward": 0.17116920921206474, "critic_loss": 0.5207253360152244, "actor_loss": -21.863107040405275, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.365020036697388, "step": 47000}
{"episode_reward": 319.3221448584281, "episode": 48.0, "batch_reward": 0.17509634243696928, "critic_loss": 0.5255798632949591, "actor_loss": -22.27347176361084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.77813172340393, "step": 48000}
{"episode_reward": 352.5771546762626, "episode": 49.0, "batch_reward": 0.17690026676654816, "critic_loss": 0.5109542484730482, "actor_loss": -22.591741111755372, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.97963237762451, "step": 49000}
{"episode_reward": 119.1568665310209, "episode": 50.0, "batch_reward": 0.1745015681385994, "critic_loss": 0.5045031615793705, "actor_loss": -22.600861259460448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.237378358840942, "step": 50000}
{"episode_reward": 130.54263909907775, "episode": 51.0, "batch_reward": 0.1756295636445284, "critic_loss": 0.5206368723362684, "actor_loss": -22.966126319885255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.60885763168335, "step": 51000}
{"episode_reward": 347.2730436646513, "episode": 52.0, "batch_reward": 0.17990731170773505, "critic_loss": 0.4938020647317171, "actor_loss": -23.33086640548706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.492432117462158, "step": 52000}
{"episode_reward": 249.09971155175995, "episode": 53.0, "batch_reward": 0.17947534000873566, "critic_loss": 0.47632259625196455, "actor_loss": -23.32033223724365, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.29603362083435, "step": 53000}
{"episode_reward": 142.92504566176032, "episode": 54.0, "batch_reward": 0.18061063615977765, "critic_loss": 0.4793448405712843, "actor_loss": -23.439149410247804, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.198700666427612, "step": 54000}
{"episode_reward": 237.10739897811675, "episode": 55.0, "batch_reward": 0.1807597455829382, "critic_loss": 0.48220627929270266, "actor_loss": -23.586465518951417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.312504768371582, "step": 55000}
{"episode_reward": 284.0051572216292, "episode": 56.0, "batch_reward": 0.1815557948499918, "critic_loss": 0.5175189510285855, "actor_loss": -23.64124571609497, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.791495084762573, "step": 56000}
{"episode_reward": 227.4897841094329, "episode": 57.0, "batch_reward": 0.18298232892155647, "critic_loss": 0.4969486114084721, "actor_loss": -23.75720401763916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.86051630973816, "step": 57000}
{"episode_reward": 176.56783479029835, "episode": 58.0, "batch_reward": 0.18399484819173814, "critic_loss": 0.49996734170615675, "actor_loss": -23.97485385131836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.303587198257446, "step": 58000}
{"episode_reward": 352.36766640039315, "episode": 59.0, "batch_reward": 0.18503886008262635, "critic_loss": 0.5194358131140471, "actor_loss": -24.041338363647462, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.701092004776, "step": 59000}
{"episode_reward": 154.70843561739014, "episode": 60.0, "batch_reward": 0.18521593545377255, "critic_loss": 0.49440076321363446, "actor_loss": -24.176165405273437, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.166033506393433, "step": 60000}
{"episode_reward": 154.42416364032752, "episode": 61.0, "batch_reward": 0.18444886431097984, "critic_loss": 0.47089534099400043, "actor_loss": -24.154461051940917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.048959493637085, "step": 61000}
{"episode_reward": 170.83533319583378, "episode": 62.0, "batch_reward": 0.18540417909622192, "critic_loss": 0.45460782034695146, "actor_loss": -24.228102993011476, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.49000573158264, "step": 62000}
{"episode_reward": 383.5528663629018, "episode": 63.0, "batch_reward": 0.1858511834591627, "critic_loss": 0.45560651871562, "actor_loss": -24.243194522857667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.127076148986816, "step": 63000}
{"episode_reward": 122.4845815443687, "episode": 64.0, "batch_reward": 0.18669350591301917, "critic_loss": 0.4227003143429756, "actor_loss": -24.364227851867675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.666218757629395, "step": 64000}
{"episode_reward": 293.47013860180294, "episode": 65.0, "batch_reward": 0.1897674322873354, "critic_loss": 0.43692992436885836, "actor_loss": -24.456850940704346, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.18514084815979, "step": 65000}
{"episode_reward": 390.72205286492095, "episode": 66.0, "batch_reward": 0.19193887726962566, "critic_loss": 0.4386616433262825, "actor_loss": -24.610854053497313, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.160172700881958, "step": 66000}
{"episode_reward": 428.84152320115965, "episode": 67.0, "batch_reward": 0.1952973735630512, "critic_loss": 0.4348910770714283, "actor_loss": -24.73405746459961, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.793426752090454, "step": 67000}
{"episode_reward": 343.21455567242646, "episode": 68.0, "batch_reward": 0.1973541677892208, "critic_loss": 0.4245983152538538, "actor_loss": -24.88997729873657, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.32012701034546, "step": 68000}
{"episode_reward": 367.0267815621622, "episode": 69.0, "batch_reward": 0.2011801637262106, "critic_loss": 0.4508238141536713, "actor_loss": -25.0424953956604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.577182054519653, "step": 69000}
{"episode_reward": 418.87901008977735, "episode": 70.0, "batch_reward": 0.20307039226591586, "critic_loss": 0.4292673089504242, "actor_loss": -25.247041900634766, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.861773014068604, "step": 70000}
{"episode_reward": 322.6370106238202, "episode": 71.0, "batch_reward": 0.20342757543921472, "critic_loss": 0.43811705270409584, "actor_loss": -25.33403824996948, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.89860701560974, "step": 71000}
{"episode_reward": 141.64160708640662, "episode": 72.0, "batch_reward": 0.20451822182536125, "critic_loss": 0.43995183481276035, "actor_loss": -25.24219826889038, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.310988426208496, "step": 72000}
{"episode_reward": 412.12447142689564, "episode": 73.0, "batch_reward": 0.20537150664627551, "critic_loss": 0.4302449482828379, "actor_loss": -25.400023010253907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.256012678146362, "step": 73000}
{"episode_reward": 117.34648613011957, "episode": 74.0, "batch_reward": 0.20554815389215947, "critic_loss": 0.4226141110360622, "actor_loss": -25.342122493743897, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.07206964492798, "step": 74000}
{"episode_reward": 265.50511589537723, "episode": 75.0, "batch_reward": 0.2069359281808138, "critic_loss": 0.4337541031092405, "actor_loss": -25.33552512741089, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.204776525497437, "step": 75000}
{"episode_reward": 428.897507093892, "episode": 76.0, "batch_reward": 0.2094956992864609, "critic_loss": 0.410292445987463, "actor_loss": -25.482007431030272, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.93496060371399, "step": 76000}
{"episode_reward": 199.3446257035016, "episode": 77.0, "batch_reward": 0.20809613175690175, "critic_loss": 0.41382879522442817, "actor_loss": -25.341486362457275, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.75623321533203, "step": 77000}
{"episode_reward": 197.64162974052076, "episode": 78.0, "batch_reward": 0.2091498118042946, "critic_loss": 0.4021883928477764, "actor_loss": -25.43394225692749, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.678277730941772, "step": 78000}
{"episode_reward": 341.5542078065223, "episode": 79.0, "batch_reward": 0.2106138185709715, "critic_loss": 0.42508017998933795, "actor_loss": -25.489920845031737, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.241708278656006, "step": 79000}
{"episode_reward": 288.8264700594687, "episode": 80.0, "batch_reward": 0.2105352270156145, "critic_loss": 0.40946117797493936, "actor_loss": -25.35347548675537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.26084852218628, "step": 80000}
{"episode_reward": 104.10659053618444, "episode": 81.0, "batch_reward": 0.21099140112102033, "critic_loss": 0.397119122967124, "actor_loss": -25.319359130859375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.1943302154541, "step": 81000}
{"episode_reward": 407.1523272941719, "episode": 82.0, "batch_reward": 0.21222888951003552, "critic_loss": 0.405189631909132, "actor_loss": -25.466854419708252, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.66801929473877, "step": 82000}
{"episode_reward": 194.40931924657306, "episode": 83.0, "batch_reward": 0.2132075912505388, "critic_loss": 0.40921083313226697, "actor_loss": -25.532105545043944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.205625295639038, "step": 83000}
{"episode_reward": 254.36651212915368, "episode": 84.0, "batch_reward": 0.21030562447011472, "critic_loss": 0.3969372976869345, "actor_loss": -25.044458984375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.88042116165161, "step": 84000}
{"episode_reward": 56.77649197997452, "episode": 85.0, "batch_reward": 0.21248897552490234, "critic_loss": 0.3808959480524063, "actor_loss": -25.24084003829956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.207367181777954, "step": 85000}
{"episode_reward": 462.86150740073674, "episode": 86.0, "batch_reward": 0.21290037159621716, "critic_loss": 0.3848376931399107, "actor_loss": -25.167858875274657, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.93619203567505, "step": 86000}
{"episode_reward": 37.913422081492904, "episode": 87.0, "batch_reward": 0.21155644442141056, "critic_loss": 0.351119726896286, "actor_loss": -24.913403175354002, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.17233109474182, "step": 87000}
{"episode_reward": 267.15679192961466, "episode": 88.0, "batch_reward": 0.21324702908098697, "critic_loss": 0.35248315665125846, "actor_loss": -24.974470134735107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.827765226364136, "step": 88000}
{"episode_reward": 335.4798263809346, "episode": 89.0, "batch_reward": 0.21502820312976836, "critic_loss": 0.3741326105296612, "actor_loss": -25.01737536239624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.35346221923828, "step": 89000}
{"episode_reward": 377.7551352644364, "episode": 90.0, "batch_reward": 0.215221735984087, "critic_loss": 0.34322824577987193, "actor_loss": -24.97378620147705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.66600203514099, "step": 90000}
{"episode_reward": 407.99892692089315, "episode": 91.0, "batch_reward": 0.21837185820937158, "critic_loss": 0.3415536688119173, "actor_loss": -25.161535133361816, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.97185206413269, "step": 91000}
{"episode_reward": 326.7752906955004, "episode": 92.0, "batch_reward": 0.21848021782934665, "critic_loss": 0.33014881794154644, "actor_loss": -25.041520153045653, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.914005279541016, "step": 92000}
{"episode_reward": 115.93817263678679, "episode": 93.0, "batch_reward": 0.21761418733000756, "critic_loss": 0.3136798341423273, "actor_loss": -24.78786449813843, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.72497248649597, "step": 93000}
{"episode_reward": 170.08301002261817, "episode": 94.0, "batch_reward": 0.2166545209288597, "critic_loss": 0.32189165837317707, "actor_loss": -24.658869552612305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.86033844947815, "step": 94000}
{"episode_reward": 220.17975731520139, "episode": 95.0, "batch_reward": 0.2179566343575716, "critic_loss": 0.3042730710655451, "actor_loss": -24.65895918273926, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.189328908920288, "step": 95000}
{"episode_reward": 417.046473256159, "episode": 96.0, "batch_reward": 0.21871527548134326, "critic_loss": 0.3146905936002731, "actor_loss": -24.763260494232178, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.87295937538147, "step": 96000}
{"episode_reward": 111.44401090313941, "episode": 97.0, "batch_reward": 0.21894155342876911, "critic_loss": 0.3236280024945736, "actor_loss": -24.60755013656616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.68897008895874, "step": 97000}
{"episode_reward": 547.0823595156356, "episode": 98.0, "batch_reward": 0.22234741884469986, "critic_loss": 0.3106934690773487, "actor_loss": -24.794159801483154, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.15394902229309, "step": 98000}
{"episode_reward": 266.4431511126592, "episode": 99.0, "batch_reward": 0.2225033420473337, "critic_loss": 0.3134239656627178, "actor_loss": -24.93857643890381, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.720834255218506, "step": 99000}
{"episode_reward": 300.68367624317113, "episode": 100.0, "batch_reward": 0.22357839758694173, "critic_loss": 0.2996739934682846, "actor_loss": -24.84099656677246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.247857093811035, "step": 100000}
{"episode_reward": 419.8337784407216, "episode": 101.0, "batch_reward": 0.22512493565678596, "critic_loss": 0.31603244645893575, "actor_loss": -24.970755336761474, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.9486243724823, "step": 101000}
{"episode_reward": 289.277950039573, "episode": 102.0, "batch_reward": 0.22707216715812684, "critic_loss": 0.3126754754632711, "actor_loss": -24.900554538726805, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.252952575683594, "step": 102000}
{"episode_reward": 279.9610604640763, "episode": 103.0, "batch_reward": 0.22757479579746723, "critic_loss": 0.3057725075632334, "actor_loss": -24.83264094543457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.80137610435486, "step": 103000}
{"episode_reward": 537.1831781626391, "episode": 104.0, "batch_reward": 0.22996353371441364, "critic_loss": 0.31190241838991645, "actor_loss": -25.06449102783203, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.08580470085144, "step": 104000}
{"episode_reward": 260.59763400687376, "episode": 105.0, "batch_reward": 0.23023388010263443, "critic_loss": 0.3148465608507395, "actor_loss": -25.047446144104004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.66102409362793, "step": 105000}
{"episode_reward": 357.3087720481247, "episode": 106.0, "batch_reward": 0.23181597426533698, "critic_loss": 0.3119038332700729, "actor_loss": -25.10172254180908, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.372007131576538, "step": 106000}
{"episode_reward": 531.3746064512518, "episode": 107.0, "batch_reward": 0.23484862618148328, "critic_loss": 0.3226903066039085, "actor_loss": -25.277122798919677, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.409663677215576, "step": 107000}
{"episode_reward": 518.8876818032701, "episode": 108.0, "batch_reward": 0.23599434891343116, "critic_loss": 0.3332086275666952, "actor_loss": -25.190638450622558, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.630552291870117, "step": 108000}
{"episode_reward": 549.2131850421197, "episode": 109.0, "batch_reward": 0.23851257926225664, "critic_loss": 0.337660892739892, "actor_loss": -25.405442836761473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.11095643043518, "step": 109000}
{"episode_reward": 122.32245929529554, "episode": 110.0, "batch_reward": 0.23876512213051318, "critic_loss": 0.31193599659204485, "actor_loss": -25.435006107330324, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.41492199897766, "step": 110000}
{"episode_reward": 557.5810851612819, "episode": 111.0, "batch_reward": 0.23947371610999107, "critic_loss": 0.33049641923606393, "actor_loss": -25.274882125854493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.315509557724, "step": 111000}
{"episode_reward": 96.84864559385775, "episode": 112.0, "batch_reward": 0.24017425301671028, "critic_loss": 0.3239750269502401, "actor_loss": -25.54544546508789, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.530910968780518, "step": 112000}
{"episode_reward": 402.0899903983339, "episode": 113.0, "batch_reward": 0.2428214528411627, "critic_loss": 0.35612812905013563, "actor_loss": -25.68930270385742, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.862430095672607, "step": 113000}
{"episode_reward": 579.510011468458, "episode": 114.0, "batch_reward": 0.24438217663764952, "critic_loss": 0.3316964695900679, "actor_loss": -25.853884757995605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.607255220413208, "step": 114000}
{"episode_reward": 355.2416535082817, "episode": 115.0, "batch_reward": 0.2449510013461113, "critic_loss": 0.3529519033133984, "actor_loss": -25.857266109466554, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.61487054824829, "step": 115000}
{"episode_reward": 467.21217826960446, "episode": 116.0, "batch_reward": 0.2494717632830143, "critic_loss": 0.3567786330729723, "actor_loss": -26.08068815612793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.004472732543945, "step": 116000}
{"episode_reward": 551.8781171431488, "episode": 117.0, "batch_reward": 0.25035256235301495, "critic_loss": 0.3576747409403324, "actor_loss": -26.279156211853028, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.085362672805786, "step": 117000}
{"episode_reward": 540.0803774740735, "episode": 118.0, "batch_reward": 0.2527156316787004, "critic_loss": 0.37552891024947166, "actor_loss": -26.492986125946047, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.580108404159546, "step": 118000}
{"episode_reward": 408.45897274302337, "episode": 119.0, "batch_reward": 0.25282148736715315, "critic_loss": 0.36509745559096335, "actor_loss": -26.322603519439696, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.208938598632812, "step": 119000}
{"episode_reward": 369.7105724326612, "episode": 120.0, "batch_reward": 0.25443725772202014, "critic_loss": 0.36641303953528404, "actor_loss": -26.553366092681884, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.880695819854736, "step": 120000}
{"episode_reward": 484.95063464879547, "episode": 121.0, "batch_reward": 0.2569082849174738, "critic_loss": 0.3771279844790697, "actor_loss": -26.816200622558593, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.028287172317505, "step": 121000}
{"episode_reward": 576.836580638067, "episode": 122.0, "batch_reward": 0.2597036058008671, "critic_loss": 0.3896786956936121, "actor_loss": -26.889276008605957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.04006576538086, "step": 122000}
{"episode_reward": 577.0855190342668, "episode": 123.0, "batch_reward": 0.2622874288111925, "critic_loss": 0.39550290279090405, "actor_loss": -27.076260299682616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.885029315948486, "step": 123000}
{"episode_reward": 526.9784585946582, "episode": 124.0, "batch_reward": 0.26224933786690235, "critic_loss": 0.3781091310530901, "actor_loss": -27.286738681793214, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.187511444091797, "step": 124000}
{"episode_reward": 158.0641090234824, "episode": 125.0, "batch_reward": 0.2633836375325918, "critic_loss": 0.3866650393605232, "actor_loss": -27.364000762939455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.065448760986328, "step": 125000}
{"episode_reward": 596.4476052042482, "episode": 126.0, "batch_reward": 0.26698293870687484, "critic_loss": 0.39132686200737954, "actor_loss": -27.527715263366698, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.352665185928345, "step": 126000}
{"episode_reward": 597.7108583208284, "episode": 127.0, "batch_reward": 0.26846116803586484, "critic_loss": 0.3958626382946968, "actor_loss": -27.79617105102539, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.69599461555481, "step": 127000}
{"episode_reward": 585.5246754967536, "episode": 128.0, "batch_reward": 0.2715050198584795, "critic_loss": 0.39503763042390344, "actor_loss": -28.042433746337892, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.35889482498169, "step": 128000}
{"episode_reward": 576.1516152791576, "episode": 129.0, "batch_reward": 0.27306076158583165, "critic_loss": 0.39012398186326025, "actor_loss": -28.06094960784912, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.937186002731323, "step": 129000}
{"episode_reward": 565.7093476712798, "episode": 130.0, "batch_reward": 0.2766815709471703, "critic_loss": 0.38677214083075523, "actor_loss": -28.439138069152833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.825746059417725, "step": 130000}
{"episode_reward": 608.6538065509568, "episode": 131.0, "batch_reward": 0.27806742149591446, "critic_loss": 0.4341946466714144, "actor_loss": -28.54206848907471, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.0103120803833, "step": 131000}
{"episode_reward": 223.66957798246543, "episode": 132.0, "batch_reward": 0.2782863076478243, "critic_loss": 0.3993114188760519, "actor_loss": -28.490938003540037, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.12273383140564, "step": 132000}
{"episode_reward": 621.1312582984498, "episode": 133.0, "batch_reward": 0.28037559290230274, "critic_loss": 0.41329936090111735, "actor_loss": -28.589480842590334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.724727153778076, "step": 133000}
{"episode_reward": 465.7025244917161, "episode": 134.0, "batch_reward": 0.2812039549946785, "critic_loss": 0.4001813719421625, "actor_loss": -28.74431625366211, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.986881971359253, "step": 134000}
{"episode_reward": 518.0982900965082, "episode": 135.0, "batch_reward": 0.28343416076898575, "critic_loss": 0.4232430458366871, "actor_loss": -29.0261995010376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.865403652191162, "step": 135000}
{"episode_reward": 398.1359866187764, "episode": 136.0, "batch_reward": 0.2851038314849138, "critic_loss": 0.40472900988161564, "actor_loss": -29.037837673187255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.54919743537903, "step": 136000}
{"episode_reward": 352.893473761562, "episode": 137.0, "batch_reward": 0.2848272206634283, "critic_loss": 0.42251531498134137, "actor_loss": -29.23471085357666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.677464485168457, "step": 137000}
{"episode_reward": 275.2555090641965, "episode": 138.0, "batch_reward": 0.28550262899696827, "critic_loss": 0.43770112916827203, "actor_loss": -29.227947212219238, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.56083655357361, "step": 138000}
{"episode_reward": 252.7410939692733, "episode": 139.0, "batch_reward": 0.28616089491546154, "critic_loss": 0.47701344023644926, "actor_loss": -29.138092079162597, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.242064714431763, "step": 139000}
{"episode_reward": 395.9582625304543, "episode": 140.0, "batch_reward": 0.28670920050144194, "critic_loss": 0.4709730924516916, "actor_loss": -29.20030867767334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.749881505966187, "step": 140000}
{"episode_reward": 604.3377259907062, "episode": 141.0, "batch_reward": 0.2881691111624241, "critic_loss": 0.48543261556327344, "actor_loss": -29.562145111083986, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.5110399723053, "step": 141000}
{"episode_reward": 519.8457423444343, "episode": 142.0, "batch_reward": 0.2888858125805855, "critic_loss": 0.47936670781672003, "actor_loss": -29.511463943481445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.662574291229248, "step": 142000}
{"episode_reward": 616.5403549564552, "episode": 143.0, "batch_reward": 0.2919114075005054, "critic_loss": 0.48098989483714105, "actor_loss": -29.60855651855469, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.840946197509766, "step": 143000}
{"episode_reward": 607.1765711759297, "episode": 144.0, "batch_reward": 0.2938129957169294, "critic_loss": 0.45260064156353474, "actor_loss": -29.875426136016845, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.87732219696045, "step": 144000}
{"episode_reward": 601.0852091061104, "episode": 145.0, "batch_reward": 0.29609920680522916, "critic_loss": 0.4717173819690943, "actor_loss": -30.223041152954103, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.487589836120605, "step": 145000}
{"episode_reward": 607.9460759418575, "episode": 146.0, "batch_reward": 0.2987526500672102, "critic_loss": 0.48326290845870973, "actor_loss": -30.417755348205567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.58604669570923, "step": 146000}
{"episode_reward": 563.7801010909859, "episode": 147.0, "batch_reward": 0.29939087998867037, "critic_loss": 0.45996627473831175, "actor_loss": -30.454518417358397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.00197672843933, "step": 147000}
{"episode_reward": 533.1961366227456, "episode": 148.0, "batch_reward": 0.30168398360908033, "critic_loss": 0.4594342510998249, "actor_loss": -30.745139892578123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.010838270187378, "step": 148000}
{"episode_reward": 580.4529828655311, "episode": 149.0, "batch_reward": 0.304430938154459, "critic_loss": 0.48399523603916167, "actor_loss": -30.86661194610596, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.763975858688354, "step": 149000}
{"episode_reward": 593.2486048663233, "episode": 150.0, "batch_reward": 0.3057235618233681, "critic_loss": 0.45385828948020934, "actor_loss": -31.068403476715087, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
