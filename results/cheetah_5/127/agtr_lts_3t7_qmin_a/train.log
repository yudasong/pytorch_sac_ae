{"episode_reward": 0.0, "episode": 1.0, "duration": 14.838327407836914, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.345017671585083, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.2653130312667922, "critic_loss": 0.04630090732334872, "actor_loss": -27.871133143121764, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 67.52523732185364, "step": 3000}
{"episode_reward": 74.57424897286842, "episode": 4.0, "batch_reward": 0.20327625681459904, "critic_loss": 0.0643534115049988, "actor_loss": -21.526764039508997, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.633501052856445, "step": 4000}
{"episode_reward": 146.81007046502015, "episode": 5.0, "batch_reward": 0.185566082470119, "critic_loss": 0.06847494712471962, "actor_loss": -20.041234515197576, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.541237115859985, "step": 5000}
{"episode_reward": 108.65187572287144, "episode": 6.0, "batch_reward": 0.16995753510296344, "critic_loss": 0.06349833784252405, "actor_loss": -17.659507418118416, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.22669792175293, "step": 6000}
{"episode_reward": 67.48685635381761, "episode": 7.0, "batch_reward": 0.1575094735994935, "critic_loss": 0.07888522870466114, "actor_loss": -17.324309301074596, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.49811053276062, "step": 7000}
{"episode_reward": 125.53411604678584, "episode": 8.0, "batch_reward": 0.1518780350536108, "critic_loss": 0.06912577736563981, "actor_loss": -15.887917605765164, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.058263540267944, "step": 8000}
{"episode_reward": 91.10140221941622, "episode": 9.0, "batch_reward": 0.14717876549810172, "critic_loss": 0.07154247834533453, "actor_loss": -15.470495062291622, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.7413432598114, "step": 9000}
{"episode_reward": 164.18916224638204, "episode": 10.0, "batch_reward": 0.14862222965806723, "critic_loss": 0.07658473466709256, "actor_loss": -15.51870197917521, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.800819873809814, "step": 10000}
{"episode_reward": 148.88560619191622, "episode": 11.0, "batch_reward": 0.14987438232451678, "critic_loss": 0.09131685236468912, "actor_loss": -15.16938990047574, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.661275148391724, "step": 11000}
{"episode_reward": 132.95610844988187, "episode": 12.0, "batch_reward": 0.14742140763252973, "critic_loss": 0.08891073264926672, "actor_loss": -15.243534853890539, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.308241367340088, "step": 12000}
{"episode_reward": 165.532407494668, "episode": 13.0, "batch_reward": 0.14485995802283286, "critic_loss": 0.10478932300209999, "actor_loss": -16.232066214084625, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.881194353103638, "step": 13000}
{"episode_reward": 75.74720366521706, "episode": 14.0, "batch_reward": 0.14529943354427816, "critic_loss": 0.1055170845016837, "actor_loss": -15.755824632167815, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.236257791519165, "step": 14000}
{"episode_reward": 204.87717392669222, "episode": 15.0, "batch_reward": 0.14794451721012591, "critic_loss": 0.11719886588677764, "actor_loss": -15.486920238018035, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.651459455490112, "step": 15000}
{"episode_reward": 193.1157183443739, "episode": 16.0, "batch_reward": 0.1497849593088031, "critic_loss": 0.12780334778502583, "actor_loss": -16.50502442884445, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.73171305656433, "step": 16000}
{"episode_reward": 103.6916819553502, "episode": 17.0, "batch_reward": 0.14843752432614565, "critic_loss": 0.13298029358312488, "actor_loss": -16.077232384204866, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.31233549118042, "step": 17000}
{"episode_reward": 195.0670624296038, "episode": 18.0, "batch_reward": 0.15190122525393962, "critic_loss": 0.13490729489922523, "actor_loss": -16.455218809127807, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.858394622802734, "step": 18000}
{"episode_reward": 126.21621456418968, "episode": 19.0, "batch_reward": 0.14867871717363595, "critic_loss": 0.1470334944203496, "actor_loss": -16.08298754262924, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.522765636444092, "step": 19000}
{"episode_reward": 87.75771164648873, "episode": 20.0, "batch_reward": 0.1464575153440237, "critic_loss": 0.1477610787525773, "actor_loss": -15.04812451171875, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.947630882263184, "step": 20000}
{"episode_reward": 121.61774682620003, "episode": 21.0, "batch_reward": 0.1456544226706028, "critic_loss": 0.1601801588833332, "actor_loss": -16.491240619659425, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.810543060302734, "step": 21000}
{"episode_reward": 136.91255950294672, "episode": 22.0, "batch_reward": 0.1444801570698619, "critic_loss": 0.14953914749622346, "actor_loss": -14.765547081947327, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.660717010498047, "step": 22000}
{"episode_reward": 122.66864414925242, "episode": 23.0, "batch_reward": 0.142581184707582, "critic_loss": 0.1426338815316558, "actor_loss": -15.276811631202698, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.726096630096436, "step": 23000}
{"episode_reward": 81.31484167704701, "episode": 24.0, "batch_reward": 0.14095688506960868, "critic_loss": 0.15342132914066314, "actor_loss": -15.284723660469055, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.01163959503174, "step": 24000}
{"episode_reward": 113.49426262177177, "episode": 25.0, "batch_reward": 0.14172671634703873, "critic_loss": 0.1796915568113327, "actor_loss": -15.098909843444824, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.10884690284729, "step": 25000}
{"episode_reward": 158.53123609055578, "episode": 26.0, "batch_reward": 0.1430094967111945, "critic_loss": 0.1707930901274085, "actor_loss": -15.312008903503418, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.86878514289856, "step": 26000}
{"episode_reward": 311.1427062919452, "episode": 27.0, "batch_reward": 0.14641780757904052, "critic_loss": 0.1913356280401349, "actor_loss": -15.837323070526123, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.130444765090942, "step": 27000}
{"episode_reward": 88.31544486113908, "episode": 28.0, "batch_reward": 0.1475368812456727, "critic_loss": 0.20810992255806923, "actor_loss": -15.551184832572938, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.492721557617188, "step": 28000}
{"episode_reward": 328.9313127654623, "episode": 29.0, "batch_reward": 0.14940970330685377, "critic_loss": 0.20797956176102161, "actor_loss": -16.2411630897522, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.596676111221313, "step": 29000}
{"episode_reward": 51.45156382013193, "episode": 30.0, "batch_reward": 0.15007298261672258, "critic_loss": 0.21482060743123294, "actor_loss": -16.743125328063964, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.7996985912323, "step": 30000}
{"episode_reward": 186.46922903786597, "episode": 31.0, "batch_reward": 0.15107854578644037, "critic_loss": 0.20003230515122414, "actor_loss": -16.301745420455934, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.37548112869263, "step": 31000}
{"episode_reward": 204.83762096065195, "episode": 32.0, "batch_reward": 0.15252870918810368, "critic_loss": 0.21571598046272994, "actor_loss": -16.157511665344238, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.945921421051025, "step": 32000}
{"episode_reward": 257.3175056200175, "episode": 33.0, "batch_reward": 0.15355019698292016, "critic_loss": 0.21973601299524306, "actor_loss": -16.51068334388733, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.57902693748474, "step": 33000}
{"episode_reward": 79.38672568771764, "episode": 34.0, "batch_reward": 0.15382127268612386, "critic_loss": 0.22176003001630307, "actor_loss": -16.696986877441407, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.291943550109863, "step": 34000}
{"episode_reward": 244.9722807099282, "episode": 35.0, "batch_reward": 0.154476634927094, "critic_loss": 0.22602041358500718, "actor_loss": -16.402035556793212, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.144451141357422, "step": 35000}
{"episode_reward": 123.97762843292799, "episode": 36.0, "batch_reward": 0.1554245750978589, "critic_loss": 0.23069457010179759, "actor_loss": -16.07530634498596, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.188543796539307, "step": 36000}
{"episode_reward": 190.93538799450485, "episode": 37.0, "batch_reward": 0.1568240728378296, "critic_loss": 0.2549623670503497, "actor_loss": -16.66786813354492, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.685089826583862, "step": 37000}
{"episode_reward": 344.96905925053886, "episode": 38.0, "batch_reward": 0.15966312953084708, "critic_loss": 0.25123785975575447, "actor_loss": -16.86359563064575, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.04105496406555, "step": 38000}
{"episode_reward": 94.06411313053023, "episode": 39.0, "batch_reward": 0.15840931146591902, "critic_loss": 0.25839190830290315, "actor_loss": -16.9109990234375, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.563455820083618, "step": 39000}
{"episode_reward": 126.00911999350485, "episode": 40.0, "batch_reward": 0.15836472494155168, "critic_loss": 0.251778135612607, "actor_loss": -16.7450389213562, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.91804313659668, "step": 40000}
{"episode_reward": 147.49528660993127, "episode": 41.0, "batch_reward": 0.1583611800968647, "critic_loss": 0.2548890963345766, "actor_loss": -17.222777534484862, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.17787790298462, "step": 41000}
{"episode_reward": 331.20336900430664, "episode": 42.0, "batch_reward": 0.1641622392311692, "critic_loss": 0.27546848329901696, "actor_loss": -17.363944650650023, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.994971752166748, "step": 42000}
{"episode_reward": 365.3787182414725, "episode": 43.0, "batch_reward": 0.16667415647208692, "critic_loss": 0.27598805782943964, "actor_loss": -17.583267181396483, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.713412284851074, "step": 43000}
{"episode_reward": 200.7111866977626, "episode": 44.0, "batch_reward": 0.16783159375190734, "critic_loss": 0.2294324031546712, "actor_loss": -17.129978437423706, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.159461736679077, "step": 44000}
{"episode_reward": 164.62198307146127, "episode": 45.0, "batch_reward": 0.16616777865588664, "critic_loss": 0.2441080456599593, "actor_loss": -17.596196306228638, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.21837854385376, "step": 45000}
{"episode_reward": 87.89574484553032, "episode": 46.0, "batch_reward": 0.16665348953008652, "critic_loss": 0.22331994580477477, "actor_loss": -17.880526247024537, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.37821888923645, "step": 46000}
{"episode_reward": 340.0312230731749, "episode": 47.0, "batch_reward": 0.17066252164542675, "critic_loss": 0.27040689980238675, "actor_loss": -18.088996814727782, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.587580919265747, "step": 47000}
{"episode_reward": 362.30846453628726, "episode": 48.0, "batch_reward": 0.1732951576113701, "critic_loss": 0.24864173671603204, "actor_loss": -18.38070269203186, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.091038703918457, "step": 48000}
{"episode_reward": 98.0657063627289, "episode": 49.0, "batch_reward": 0.171142584040761, "critic_loss": 0.2331140904352069, "actor_loss": -17.90399944496155, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.033169984817505, "step": 49000}
{"episode_reward": 117.41142458763755, "episode": 50.0, "batch_reward": 0.1717170193493366, "critic_loss": 0.25737122778594496, "actor_loss": -18.313484924316406, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.264097690582275, "step": 50000}
{"episode_reward": 335.0377842781231, "episode": 51.0, "batch_reward": 0.17418479377031326, "critic_loss": 0.2868199825063348, "actor_loss": -18.544708442687988, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.69798731803894, "step": 51000}
{"episode_reward": 157.65937846473744, "episode": 52.0, "batch_reward": 0.17317126207053662, "critic_loss": 0.2485619553923607, "actor_loss": -18.649772218704225, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.446741104125977, "step": 52000}
{"episode_reward": 181.1457112218632, "episode": 53.0, "batch_reward": 0.17543391145020723, "critic_loss": 0.2699497057944536, "actor_loss": -18.642283111572265, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.55772089958191, "step": 53000}
{"episode_reward": 265.16879347095426, "episode": 54.0, "batch_reward": 0.17684731224179268, "critic_loss": 0.25608600390702485, "actor_loss": -18.769954326629637, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.6407949924469, "step": 54000}
{"episode_reward": 348.4142100333058, "episode": 55.0, "batch_reward": 0.17867669175565243, "critic_loss": 0.2585494471043348, "actor_loss": -19.088367370605468, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.177918672561646, "step": 55000}
{"episode_reward": 161.31081472905404, "episode": 56.0, "batch_reward": 0.1775101047307253, "critic_loss": 0.26407235630601644, "actor_loss": -19.010791440963747, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.416210412979126, "step": 56000}
{"episode_reward": 97.02527881136697, "episode": 57.0, "batch_reward": 0.17663460893929003, "critic_loss": 0.2742156623750925, "actor_loss": -19.033567443847655, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.739378213882446, "step": 57000}
{"episode_reward": 128.57094518135136, "episode": 58.0, "batch_reward": 0.17549429367482663, "critic_loss": 0.30275385885685685, "actor_loss": -18.992077041625976, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.734827041625977, "step": 58000}
{"episode_reward": 106.42376194452362, "episode": 59.0, "batch_reward": 0.17534886641800404, "critic_loss": 0.26454201178997755, "actor_loss": -19.050556810379028, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.602061986923218, "step": 59000}
{"episode_reward": 234.82311069342768, "episode": 60.0, "batch_reward": 0.17697691304981708, "critic_loss": 0.29686521700024604, "actor_loss": -19.080309085845947, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.98833394050598, "step": 60000}
{"episode_reward": 229.76065062582893, "episode": 61.0, "batch_reward": 0.17817690268158912, "critic_loss": 0.3099428476318717, "actor_loss": -19.330073637008667, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.471579790115356, "step": 61000}
{"episode_reward": 434.6248125582647, "episode": 62.0, "batch_reward": 0.18232554274797438, "critic_loss": 0.28670095002651214, "actor_loss": -19.5942582988739, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.379974603652954, "step": 62000}
{"episode_reward": 276.69520344706405, "episode": 63.0, "batch_reward": 0.1841756713092327, "critic_loss": 0.3109464695677161, "actor_loss": -19.789188163757323, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.19569754600525, "step": 63000}
{"episode_reward": 431.8157249692041, "episode": 64.0, "batch_reward": 0.18690753339231014, "critic_loss": 0.31490302861481906, "actor_loss": -19.94211996269226, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.332890510559082, "step": 64000}
{"episode_reward": 276.4775593416142, "episode": 65.0, "batch_reward": 0.18856870657205582, "critic_loss": 0.2852575477063656, "actor_loss": -20.163822217941284, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.834624767303467, "step": 65000}
{"episode_reward": 285.783643746881, "episode": 66.0, "batch_reward": 0.19111602289974688, "critic_loss": 0.31721108021587135, "actor_loss": -20.271551567077637, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.91037082672119, "step": 66000}
{"episode_reward": 390.71013533652086, "episode": 67.0, "batch_reward": 0.1940925665050745, "critic_loss": 0.3231922059953213, "actor_loss": -20.460187324523925, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.676964044570923, "step": 67000}
{"episode_reward": 313.3416200322234, "episode": 68.0, "batch_reward": 0.19506813237071038, "critic_loss": 0.34069671771675347, "actor_loss": -20.400786220550536, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.85468888282776, "step": 68000}
{"episode_reward": 394.7373314307243, "episode": 69.0, "batch_reward": 0.19760739222168922, "critic_loss": 0.3096323503404856, "actor_loss": -20.9420095539093, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.928359746932983, "step": 69000}
{"episode_reward": 248.23836481549213, "episode": 70.0, "batch_reward": 0.19822205580770969, "critic_loss": 0.3603942766040564, "actor_loss": -20.881597106933594, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.604203939437866, "step": 70000}
{"episode_reward": 410.0489211494066, "episode": 71.0, "batch_reward": 0.20212710720300675, "critic_loss": 0.337790974214673, "actor_loss": -21.30201538467407, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.846779108047485, "step": 71000}
{"episode_reward": 342.3146974178147, "episode": 72.0, "batch_reward": 0.2037254680991173, "critic_loss": 0.3348516475111246, "actor_loss": -21.338387634277343, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.36250400543213, "step": 72000}
{"episode_reward": 266.5128798809014, "episode": 73.0, "batch_reward": 0.2049203412681818, "critic_loss": 0.341181363388896, "actor_loss": -21.363290740966796, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.81829261779785, "step": 73000}
{"episode_reward": 321.32191053865273, "episode": 74.0, "batch_reward": 0.20535604894161225, "critic_loss": 0.30307309415191414, "actor_loss": -21.51190853881836, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.124494075775146, "step": 74000}
{"episode_reward": 211.29807690726818, "episode": 75.0, "batch_reward": 0.20617549006640912, "critic_loss": 0.30821864914149044, "actor_loss": -21.511259872436522, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.564687252044678, "step": 75000}
{"episode_reward": 395.28597703577105, "episode": 76.0, "batch_reward": 0.20935693162679672, "critic_loss": 0.33548738165199754, "actor_loss": -21.82547573852539, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.89523410797119, "step": 76000}
{"episode_reward": 327.8172803820918, "episode": 77.0, "batch_reward": 0.21042029950022698, "critic_loss": 0.3165481777340174, "actor_loss": -21.85691547012329, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.32246708869934, "step": 77000}
{"episode_reward": 248.94096349763814, "episode": 78.0, "batch_reward": 0.2114986528903246, "critic_loss": 0.3160477689355612, "actor_loss": -21.888509925842285, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.815969944000244, "step": 78000}
{"episode_reward": 351.6944243145834, "episode": 79.0, "batch_reward": 0.2131569439023733, "critic_loss": 0.32518454629182814, "actor_loss": -21.996029567718505, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.41412115097046, "step": 79000}
{"episode_reward": 361.1633413090484, "episode": 80.0, "batch_reward": 0.21465709473192693, "critic_loss": 0.33333245931565764, "actor_loss": -22.17846759033203, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.73388385772705, "step": 80000}
{"episode_reward": 389.778992599122, "episode": 81.0, "batch_reward": 0.21687042939662934, "critic_loss": 0.30844143122434614, "actor_loss": -22.38374678039551, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.97635531425476, "step": 81000}
{"episode_reward": 424.91464253829054, "episode": 82.0, "batch_reward": 0.21900528539717198, "critic_loss": 0.31044243222475054, "actor_loss": -22.67895037460327, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.66225004196167, "step": 82000}
{"episode_reward": 452.0196736114223, "episode": 83.0, "batch_reward": 0.2228830658197403, "critic_loss": 0.2877807450890541, "actor_loss": -22.80737914657593, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.400832653045654, "step": 83000}
{"episode_reward": 286.3178643732437, "episode": 84.0, "batch_reward": 0.22261269381642343, "critic_loss": 0.2950522700101137, "actor_loss": -22.625214946746826, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.686822414398193, "step": 84000}
{"episode_reward": 243.9228899574891, "episode": 85.0, "batch_reward": 0.22249617491662502, "critic_loss": 0.2915548488497734, "actor_loss": -22.737422191619874, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.07359552383423, "step": 85000}
{"episode_reward": 322.3157894886047, "episode": 86.0, "batch_reward": 0.22339233176410198, "critic_loss": 0.3052992704957724, "actor_loss": -22.93929606628418, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.094404935836792, "step": 86000}
{"episode_reward": 153.73798870111702, "episode": 87.0, "batch_reward": 0.22474057926237584, "critic_loss": 0.3044053108692169, "actor_loss": -22.64717283630371, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.000295400619507, "step": 87000}
{"episode_reward": 289.6040971693136, "episode": 88.0, "batch_reward": 0.22248974949121475, "critic_loss": 0.29832927833497525, "actor_loss": -22.69163391494751, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.054657220840454, "step": 88000}
{"episode_reward": 103.8594860865663, "episode": 89.0, "batch_reward": 0.22305318379402161, "critic_loss": 0.30985220996290447, "actor_loss": -22.763586597442625, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.756301879882812, "step": 89000}
{"episode_reward": 472.55582091635233, "episode": 90.0, "batch_reward": 0.22741811759769917, "critic_loss": 0.31812425383925436, "actor_loss": -23.01768578338623, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.236364126205444, "step": 90000}
{"episode_reward": 485.38051857015387, "episode": 91.0, "batch_reward": 0.2284332311153412, "critic_loss": 0.3362895313948393, "actor_loss": -23.19551403427124, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.67250347137451, "step": 91000}
{"episode_reward": 303.9871621695989, "episode": 92.0, "batch_reward": 0.23011873611807823, "critic_loss": 0.29953607915341857, "actor_loss": -23.237730735778808, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.8486270904541, "step": 92000}
{"episode_reward": 434.1656311983408, "episode": 93.0, "batch_reward": 0.23167831820249557, "critic_loss": 0.3171321753561497, "actor_loss": -23.533835811614992, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.38922667503357, "step": 93000}
{"episode_reward": 371.16348062133585, "episode": 94.0, "batch_reward": 0.2331640268713236, "critic_loss": 0.3333339505791664, "actor_loss": -23.39533190536499, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.056893587112427, "step": 94000}
{"episode_reward": 477.14109023537196, "episode": 95.0, "batch_reward": 0.23492808935046197, "critic_loss": 0.32227653267234563, "actor_loss": -23.463847938537597, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.158419847488403, "step": 95000}
{"episode_reward": 336.0581533142633, "episode": 96.0, "batch_reward": 0.23794138239324092, "critic_loss": 0.30425189876556397, "actor_loss": -23.686829181671143, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.576621055603027, "step": 96000}
{"episode_reward": 527.9079349107259, "episode": 97.0, "batch_reward": 0.24061854834854604, "critic_loss": 0.32260556034743787, "actor_loss": -24.19198578262329, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.271966457366943, "step": 97000}
{"episode_reward": 444.9374207868953, "episode": 98.0, "batch_reward": 0.2413243571817875, "critic_loss": 0.3188491447865963, "actor_loss": -23.805525955200196, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.694146871566772, "step": 98000}
{"episode_reward": 440.5242619003559, "episode": 99.0, "batch_reward": 0.24459961433708668, "critic_loss": 0.3286772879064083, "actor_loss": -24.448358947753906, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.766314029693604, "step": 99000}
{"episode_reward": 500.00134314784674, "episode": 100.0, "batch_reward": 0.2463901842236519, "critic_loss": 0.3345473198890686, "actor_loss": -24.652415775299072, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.119842052459717, "step": 100000}
{"episode_reward": 343.61201164229993, "episode": 101.0, "batch_reward": 0.2481766777187586, "critic_loss": 0.33716717952489855, "actor_loss": -24.89580331039429, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.99134802818298, "step": 101000}
{"episode_reward": 430.7952783766315, "episode": 102.0, "batch_reward": 0.24967669881880283, "critic_loss": 0.3448201608359814, "actor_loss": -24.77463753128052, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.03115224838257, "step": 102000}
{"episode_reward": 276.07149382852754, "episode": 103.0, "batch_reward": 0.2505235665142536, "critic_loss": 0.33598831516504285, "actor_loss": -25.025696678161623, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.770602226257324, "step": 103000}
{"episode_reward": 482.7200369824946, "episode": 104.0, "batch_reward": 0.2512348171174526, "critic_loss": 0.35115247374773023, "actor_loss": -25.002295490264892, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.19619393348694, "step": 104000}
{"episode_reward": 93.49000028903843, "episode": 105.0, "batch_reward": 0.2511668008118868, "critic_loss": 0.3348044813126326, "actor_loss": -25.017619262695312, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.7264986038208, "step": 105000}
{"episode_reward": 483.3491068428284, "episode": 106.0, "batch_reward": 0.25304595318436623, "critic_loss": 0.3430308195799589, "actor_loss": -25.124857280731202, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.598735809326172, "step": 106000}
{"episode_reward": 488.5310655103137, "episode": 107.0, "batch_reward": 0.25563543918728826, "critic_loss": 0.3579018834978342, "actor_loss": -25.450872436523436, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.057661533355713, "step": 107000}
{"episode_reward": 537.2945699508141, "episode": 108.0, "batch_reward": 0.2571844539642334, "critic_loss": 0.33042350509762763, "actor_loss": -25.294040584564208, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.88028597831726, "step": 108000}
{"episode_reward": 349.0310907735563, "episode": 109.0, "batch_reward": 0.2585586194097996, "critic_loss": 0.36377540780603884, "actor_loss": -25.582448627471923, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.783379793167114, "step": 109000}
{"episode_reward": 385.21394824533417, "episode": 110.0, "batch_reward": 0.25920405182242395, "critic_loss": 0.3535415716618299, "actor_loss": -25.557535110473633, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.612403631210327, "step": 110000}
{"episode_reward": 416.5861156159365, "episode": 111.0, "batch_reward": 0.26048622047901154, "critic_loss": 0.3504602765887976, "actor_loss": -25.837362174987792, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.40096640586853, "step": 111000}
{"episode_reward": 360.20383091687324, "episode": 112.0, "batch_reward": 0.26163849410414697, "critic_loss": 0.354299894079566, "actor_loss": -25.64023779296875, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.19583010673523, "step": 112000}
{"episode_reward": 409.6712227688038, "episode": 113.0, "batch_reward": 0.26303504800796507, "critic_loss": 0.3900686476826668, "actor_loss": -25.901941421508788, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.759437084197998, "step": 113000}
{"episode_reward": 139.4119592934119, "episode": 114.0, "batch_reward": 0.2622578837275505, "critic_loss": 0.3854298953413963, "actor_loss": -25.747049282073974, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.46063542366028, "step": 114000}
{"episode_reward": 464.57655235208045, "episode": 115.0, "batch_reward": 0.264857892036438, "critic_loss": 0.3775320761054754, "actor_loss": -26.027078662872313, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.56346869468689, "step": 115000}
{"episode_reward": 488.1250895873795, "episode": 116.0, "batch_reward": 0.2657612067013979, "critic_loss": 0.3975201387256384, "actor_loss": -26.012261627197265, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.020118474960327, "step": 116000}
{"episode_reward": 174.44718693593734, "episode": 117.0, "batch_reward": 0.265286289319396, "critic_loss": 0.41808709716796877, "actor_loss": -26.1157960357666, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.226187229156494, "step": 117000}
{"episode_reward": 186.62391284904817, "episode": 118.0, "batch_reward": 0.2641869382858276, "critic_loss": 0.41103649494051936, "actor_loss": -26.112450172424317, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.629088640213013, "step": 118000}
{"episode_reward": 242.4487670200049, "episode": 119.0, "batch_reward": 0.2635862818658352, "critic_loss": 0.40963802275061606, "actor_loss": -26.013684352874755, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.110584497451782, "step": 119000}
{"episode_reward": 444.74281975597995, "episode": 120.0, "batch_reward": 0.2660109916329384, "critic_loss": 0.42719694735109803, "actor_loss": -26.23149240875244, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.667608499526978, "step": 120000}
{"episode_reward": 508.9659479971243, "episode": 121.0, "batch_reward": 0.26776799933612344, "critic_loss": 0.4003818196058273, "actor_loss": -26.33632175064087, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.49104690551758, "step": 121000}
{"episode_reward": 258.99509085506895, "episode": 122.0, "batch_reward": 0.2662041080594063, "critic_loss": 0.4193793578594923, "actor_loss": -26.193107608795167, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.845735788345337, "step": 122000}
{"episode_reward": 96.29050782752881, "episode": 123.0, "batch_reward": 0.266836365967989, "critic_loss": 0.4093567778021097, "actor_loss": -26.20892841720581, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.762929916381836, "step": 123000}
{"episode_reward": 469.835526471788, "episode": 124.0, "batch_reward": 0.2680193005055189, "critic_loss": 0.39970607282221315, "actor_loss": -26.327400115966796, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.842963933944702, "step": 124000}
{"episode_reward": 521.9999918121661, "episode": 125.0, "batch_reward": 0.26901257593929767, "critic_loss": 0.42538127446174623, "actor_loss": -26.478695579528807, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.094646453857422, "step": 125000}
{"episode_reward": 492.98431711590405, "episode": 126.0, "batch_reward": 0.27195676766335963, "critic_loss": 0.41954610212147236, "actor_loss": -26.63314436721802, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.13916540145874, "step": 126000}
{"episode_reward": 499.26714622978994, "episode": 127.0, "batch_reward": 0.2726858666539192, "critic_loss": 0.40931528858840466, "actor_loss": -26.567087383270263, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.217706441879272, "step": 127000}
{"episode_reward": 101.14569404938482, "episode": 128.0, "batch_reward": 0.27305271130800246, "critic_loss": 0.3918331825584173, "actor_loss": -26.86608777618408, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.13615131378174, "step": 128000}
{"episode_reward": 548.6539109727837, "episode": 129.0, "batch_reward": 0.2740462321639061, "critic_loss": 0.3950779728889465, "actor_loss": -26.8913853263855, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.303391933441162, "step": 129000}
{"episode_reward": 99.6430116472271, "episode": 130.0, "batch_reward": 0.27260035181045533, "critic_loss": 0.383463165551424, "actor_loss": -26.730210411071777, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.98084020614624, "step": 130000}
{"episode_reward": 560.264262468184, "episode": 131.0, "batch_reward": 0.27555402037501336, "critic_loss": 0.37605497346818445, "actor_loss": -27.19391774368286, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.246957540512085, "step": 131000}
{"episode_reward": 477.5240733084771, "episode": 132.0, "batch_reward": 0.2770228666216135, "critic_loss": 0.3878198744058609, "actor_loss": -27.17300355529785, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.76049256324768, "step": 132000}
{"episode_reward": 519.6267482203742, "episode": 133.0, "batch_reward": 0.2785218498557806, "critic_loss": 0.36212405714392665, "actor_loss": -27.366946071624756, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.853036165237427, "step": 133000}
{"episode_reward": 524.7570731993854, "episode": 134.0, "batch_reward": 0.2809805041104555, "critic_loss": 0.36668658575415614, "actor_loss": -27.425817718505858, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.74224615097046, "step": 134000}
{"episode_reward": 531.2743293114842, "episode": 135.0, "batch_reward": 0.2826424585878849, "critic_loss": 0.35338952714204785, "actor_loss": -27.44425301361084, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.795144081115723, "step": 135000}
{"episode_reward": 573.0038263941885, "episode": 136.0, "batch_reward": 0.28541031789779664, "critic_loss": 0.3952599937468767, "actor_loss": -27.904913005828856, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.76878046989441, "step": 136000}
{"episode_reward": 549.8728662659697, "episode": 137.0, "batch_reward": 0.286908390134573, "critic_loss": 0.3764777384251356, "actor_loss": -28.007437187194824, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.98641610145569, "step": 137000}
{"episode_reward": 555.0344651176121, "episode": 138.0, "batch_reward": 0.2882544324696064, "critic_loss": 0.3655985147058964, "actor_loss": -28.095134601593017, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.164714813232422, "step": 138000}
{"episode_reward": 564.3380670321442, "episode": 139.0, "batch_reward": 0.29029207238554955, "critic_loss": 0.35651230457425115, "actor_loss": -28.351224658966064, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.67665982246399, "step": 139000}
{"episode_reward": 451.1178448483168, "episode": 140.0, "batch_reward": 0.29124530574679375, "critic_loss": 0.3652624266222119, "actor_loss": -28.21319115447998, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.014051914215088, "step": 140000}
{"episode_reward": 568.1128314580814, "episode": 141.0, "batch_reward": 0.29472343914210797, "critic_loss": 0.35580783116817477, "actor_loss": -28.56227184677124, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.18258881568909, "step": 141000}
{"episode_reward": 478.50645136233936, "episode": 142.0, "batch_reward": 0.2953197544813156, "critic_loss": 0.38188455794751647, "actor_loss": -28.706074001312256, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.092747688293457, "step": 142000}
{"episode_reward": 544.134204592418, "episode": 143.0, "batch_reward": 0.29662502697110177, "critic_loss": 0.36301794850826263, "actor_loss": -28.808504459381105, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.735341787338257, "step": 143000}
{"episode_reward": 365.58357063749673, "episode": 144.0, "batch_reward": 0.29659559988975526, "critic_loss": 0.41313493782281874, "actor_loss": -28.591611274719238, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.718778610229492, "step": 144000}
{"episode_reward": 177.9153336597324, "episode": 145.0, "batch_reward": 0.2952689852416515, "critic_loss": 0.3969083066731691, "actor_loss": -28.632071949005127, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.66048288345337, "step": 145000}
{"episode_reward": 571.5582043731065, "episode": 146.0, "batch_reward": 0.2978377716690302, "critic_loss": 0.4102139935642481, "actor_loss": -29.13197673034668, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.30024790763855, "step": 146000}
{"episode_reward": 526.9540479735948, "episode": 147.0, "batch_reward": 0.2992701339423656, "critic_loss": 0.4084929360449314, "actor_loss": -29.08293927001953, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.986890077590942, "step": 147000}
{"episode_reward": 520.2088394210348, "episode": 148.0, "batch_reward": 0.302230519220233, "critic_loss": 0.3929152511656284, "actor_loss": -29.245049224853517, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.32703924179077, "step": 148000}
{"episode_reward": 527.7286291182639, "episode": 149.0, "batch_reward": 0.30248098835349085, "critic_loss": 0.398612304225564, "actor_loss": -29.353937065124512, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.275752067565918, "step": 149000}
{"episode_reward": 211.94643788674935, "episode": 150.0, "batch_reward": 0.3019788408130407, "critic_loss": 0.4015984148085117, "actor_loss": -29.26457483291626, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
