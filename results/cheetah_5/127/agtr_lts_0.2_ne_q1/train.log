{"episode_reward": 0.0, "episode": 1.0, "duration": 21.64136576652527, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 2.170579195022583, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.2620658721177329, "critic_loss": 1.4373111972941204, "actor_loss": -42.10005890784048, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 91.86270451545715, "step": 3000}
{"episode_reward": 72.2098166076003, "episode": 4.0, "batch_reward": 0.18378598176687955, "critic_loss": 1.3319118513464927, "actor_loss": -45.08083489227295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.74170231819153, "step": 4000}
{"episode_reward": 17.705979941956954, "episode": 5.0, "batch_reward": 0.1449175641015172, "critic_loss": 0.8192878922224045, "actor_loss": -46.5418565788269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.557034015655518, "step": 5000}
{"episode_reward": 5.040956061391595, "episode": 6.0, "batch_reward": 0.11823018353059887, "critic_loss": 0.9512987059354782, "actor_loss": -48.158499687194826, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.50800848007202, "step": 6000}
{"episode_reward": 6.226329977911332, "episode": 7.0, "batch_reward": 0.1016555883474648, "critic_loss": 0.9962358996272087, "actor_loss": -49.295906120300295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.198938131332397, "step": 7000}
{"episode_reward": 5.830074149921003, "episode": 8.0, "batch_reward": 0.08869786586612463, "critic_loss": 0.9967684971094132, "actor_loss": -50.63518608856201, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.11453127861023, "step": 8000}
{"episode_reward": 2.3817120419755415, "episode": 9.0, "batch_reward": 0.07832648587599397, "critic_loss": 1.041114335358143, "actor_loss": -49.98744595336914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.22394323348999, "step": 9000}
{"episode_reward": 6.272491477591603, "episode": 10.0, "batch_reward": 0.0711139499116689, "critic_loss": 0.8266564249396324, "actor_loss": -48.36689847946167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.352834939956665, "step": 10000}
{"episode_reward": 6.105846644967477, "episode": 11.0, "batch_reward": 0.06564632890745997, "critic_loss": 0.5324473101198673, "actor_loss": -47.66919581604004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 51.45394849777222, "step": 11000}
{"episode_reward": 3.080562776523134, "episode": 12.0, "batch_reward": 0.059434085132554174, "critic_loss": 0.4046491622924805, "actor_loss": -45.64102239227295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.446156978607178, "step": 12000}
{"episode_reward": 22.503818820563783, "episode": 13.0, "batch_reward": 0.056164875123649836, "critic_loss": 0.3334739959537983, "actor_loss": -44.69604700469971, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.333923816680908, "step": 13000}
{"episode_reward": 3.126264141119881, "episode": 14.0, "batch_reward": 0.052582616010680795, "critic_loss": 0.2688298877775669, "actor_loss": -42.55550029754639, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.849528789520264, "step": 14000}
{"episode_reward": 3.1287440294932183, "episode": 15.0, "batch_reward": 0.04874579964764416, "critic_loss": 0.25032821683585643, "actor_loss": -41.20383376693726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.754762649536133, "step": 15000}
{"episode_reward": 6.985847294153062, "episode": 16.0, "batch_reward": 0.0460123977875337, "critic_loss": 0.21979978639632464, "actor_loss": -39.82772166061402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.52207088470459, "step": 16000}
{"episode_reward": 3.6295430019606014, "episode": 17.0, "batch_reward": 0.04342047824896872, "critic_loss": 0.17801649513840676, "actor_loss": -38.201176677703856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.218782663345337, "step": 17000}
{"episode_reward": 2.5163367860084582, "episode": 18.0, "batch_reward": 0.04205282496009022, "critic_loss": 0.15568467964977026, "actor_loss": -37.04605519104004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.785175323486328, "step": 18000}
{"episode_reward": 2.2096553123674454, "episode": 19.0, "batch_reward": 0.03937771800812334, "critic_loss": 0.14513759586960076, "actor_loss": -35.6165393333435, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.06521987915039, "step": 19000}
{"episode_reward": 5.080431121503862, "episode": 20.0, "batch_reward": 0.0382337842322886, "critic_loss": 0.14065128787979483, "actor_loss": -34.47803754425049, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.35902237892151, "step": 20000}
{"episode_reward": 58.51766328092733, "episode": 21.0, "batch_reward": 0.03776046357955783, "critic_loss": 0.13880203457921744, "actor_loss": -33.21928642654419, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 51.59592032432556, "step": 21000}
{"episode_reward": 5.631061545279, "episode": 22.0, "batch_reward": 0.03749468909576535, "critic_loss": 0.11316215659305454, "actor_loss": -31.811769454956053, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.318397760391235, "step": 22000}
{"episode_reward": 56.71685184321587, "episode": 23.0, "batch_reward": 0.039616973240859804, "critic_loss": 0.13336012072116138, "actor_loss": -31.106613426208497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.33077573776245, "step": 23000}
{"episode_reward": 166.79105034382397, "episode": 24.0, "batch_reward": 0.05024557739496231, "critic_loss": 0.186477011539042, "actor_loss": -30.50814391326904, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.655357122421265, "step": 24000}
{"episode_reward": 329.6120049362497, "episode": 25.0, "batch_reward": 0.057757089126855135, "critic_loss": 0.20972149787098168, "actor_loss": -29.721908180236817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.534382104873657, "step": 25000}
{"episode_reward": 200.7946889577856, "episode": 26.0, "batch_reward": 0.06345718753524125, "critic_loss": 0.21014709759503603, "actor_loss": -28.634601566314696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.566007375717163, "step": 26000}
{"episode_reward": 88.72806748989964, "episode": 27.0, "batch_reward": 0.06562356870621443, "critic_loss": 0.22010000943392516, "actor_loss": -27.424126022338868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.218445301055908, "step": 27000}
{"episode_reward": 181.97253413182858, "episode": 28.0, "batch_reward": 0.07137932185456157, "critic_loss": 0.24002322504669427, "actor_loss": -26.59125691986084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.087918043136597, "step": 28000}
{"episode_reward": 290.8175416040548, "episode": 29.0, "batch_reward": 0.07885230980440974, "critic_loss": 0.2673106158450246, "actor_loss": -26.174461563110352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.533265352249146, "step": 29000}
{"episode_reward": 359.3430604005265, "episode": 30.0, "batch_reward": 0.08594808366149664, "critic_loss": 0.273255526907742, "actor_loss": -25.590441200256347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.527166843414307, "step": 30000}
{"episode_reward": 63.44597825463704, "episode": 31.0, "batch_reward": 0.08902315772324801, "critic_loss": 0.277877927929163, "actor_loss": -25.13195867538452, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 52.21721029281616, "step": 31000}
{"episode_reward": 337.78909487459396, "episode": 32.0, "batch_reward": 0.09567477729916572, "critic_loss": 0.3254568070322275, "actor_loss": -24.992202758789062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.5256450176239, "step": 32000}
{"episode_reward": 180.90045089547047, "episode": 33.0, "batch_reward": 0.09873271235078573, "critic_loss": 0.3770516342371702, "actor_loss": -24.477513916015624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.45022964477539, "step": 33000}
{"episode_reward": 262.6867458439496, "episode": 34.0, "batch_reward": 0.10101893845573068, "critic_loss": 0.3694122436195612, "actor_loss": -24.168290042877196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.93170142173767, "step": 34000}
{"episode_reward": 100.23219516628082, "episode": 35.0, "batch_reward": 0.10284530495852232, "critic_loss": 0.41949823251366614, "actor_loss": -24.17469701385498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.419877290725708, "step": 35000}
{"episode_reward": 276.1937274903645, "episode": 36.0, "batch_reward": 0.10615844034403563, "critic_loss": 0.5025512128174305, "actor_loss": -23.64090140914917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.532893896102905, "step": 36000}
{"episode_reward": 146.6063556610623, "episode": 37.0, "batch_reward": 0.10783112605661153, "critic_loss": 0.4327462014406919, "actor_loss": -23.09483562850952, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.17002820968628, "step": 37000}
{"episode_reward": 177.91588389450337, "episode": 38.0, "batch_reward": 0.1125554144307971, "critic_loss": 0.4598880293518305, "actor_loss": -22.862956897735597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.264299869537354, "step": 38000}
{"episode_reward": 447.49730459743205, "episode": 39.0, "batch_reward": 0.11727977664023638, "critic_loss": 0.48962063126266003, "actor_loss": -22.982090492248535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.16479206085205, "step": 39000}
{"episode_reward": 162.41092772563914, "episode": 40.0, "batch_reward": 0.12062531439214945, "critic_loss": 0.49232257370650767, "actor_loss": -22.962332168579103, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.890899658203125, "step": 40000}
{"episode_reward": 309.6293030888139, "episode": 41.0, "batch_reward": 0.12505347442626952, "critic_loss": 0.5034014420360327, "actor_loss": -23.167131034851074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 50.77402591705322, "step": 41000}
{"episode_reward": 385.1902676631012, "episode": 42.0, "batch_reward": 0.1311415601596236, "critic_loss": 0.4422411499172449, "actor_loss": -23.496173458099364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.11469864845276, "step": 42000}
{"episode_reward": 140.20820588454947, "episode": 43.0, "batch_reward": 0.13195860694348813, "critic_loss": 0.4336372086107731, "actor_loss": -23.251562839508058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.426757097244263, "step": 43000}
{"episode_reward": 383.05264688627267, "episode": 44.0, "batch_reward": 0.13844733355939387, "critic_loss": 0.4272329047322273, "actor_loss": -23.37607205581665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.196268558502197, "step": 44000}
{"episode_reward": 457.3886742949764, "episode": 45.0, "batch_reward": 0.14332926532626153, "critic_loss": 0.45071183881163596, "actor_loss": -23.443430484771728, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.60237979888916, "step": 45000}
{"episode_reward": 70.79358038601157, "episode": 46.0, "batch_reward": 0.1433736622184515, "critic_loss": 0.4584324510097504, "actor_loss": -23.214584732055663, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.273105144500732, "step": 46000}
{"episode_reward": 362.2729868960304, "episode": 47.0, "batch_reward": 0.147307484716177, "critic_loss": 0.4428836542516947, "actor_loss": -23.1777360534668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.717523336410522, "step": 47000}
{"episode_reward": 207.28698452695167, "episode": 48.0, "batch_reward": 0.15026609122008086, "critic_loss": 0.468037989795208, "actor_loss": -23.002872200012206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.901390075683594, "step": 48000}
{"episode_reward": 427.7026729157944, "episode": 49.0, "batch_reward": 0.15645938434451817, "critic_loss": 0.4515783191025257, "actor_loss": -24.013464149475098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.07136058807373, "step": 49000}
{"episode_reward": 489.7190435567605, "episode": 50.0, "batch_reward": 0.1630131463780999, "critic_loss": 0.47045650389790533, "actor_loss": -24.9117677154541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.613458156585693, "step": 50000}
{"episode_reward": 441.7508177897393, "episode": 51.0, "batch_reward": 0.1683324510678649, "critic_loss": 0.4505514728575945, "actor_loss": -25.205109027862548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 49.924474239349365, "step": 51000}
{"episode_reward": 472.3439737096785, "episode": 52.0, "batch_reward": 0.17387182334810494, "critic_loss": 0.3918929016888142, "actor_loss": -25.15963190841675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.604352235794067, "step": 52000}
{"episode_reward": 234.3347134164375, "episode": 53.0, "batch_reward": 0.1708174881786108, "critic_loss": 0.3597510290443897, "actor_loss": -25.010857494354248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.15008544921875, "step": 53000}
{"episode_reward": 3.7928173250651627, "episode": 54.0, "batch_reward": 0.17195874996483326, "critic_loss": 0.36518023435771463, "actor_loss": -24.66512596511841, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.636398553848267, "step": 54000}
{"episode_reward": 435.80455389838363, "episode": 55.0, "batch_reward": 0.1735744434222579, "critic_loss": 0.3626898568421602, "actor_loss": -24.632996864318848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.364187717437744, "step": 55000}
{"episode_reward": 33.812521072496295, "episode": 56.0, "batch_reward": 0.1743220126479864, "critic_loss": 0.35855021157860756, "actor_loss": -24.536110359191895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.30043077468872, "step": 56000}
{"episode_reward": 451.30526612926764, "episode": 57.0, "batch_reward": 0.18069530732929706, "critic_loss": 0.35755139370262623, "actor_loss": -24.6261015663147, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.82516884803772, "step": 57000}
{"episode_reward": 530.9905130588817, "episode": 58.0, "batch_reward": 0.18485500373691321, "critic_loss": 0.3499368432015181, "actor_loss": -24.62856287384033, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.10029649734497, "step": 58000}
{"episode_reward": 441.4766384107944, "episode": 59.0, "batch_reward": 0.19033918252587317, "critic_loss": 0.3682382104992867, "actor_loss": -24.543632320404054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.814571380615234, "step": 59000}
{"episode_reward": 493.02297738253225, "episode": 60.0, "batch_reward": 0.19497869557142258, "critic_loss": 0.37014667911827565, "actor_loss": -24.56832378768921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.849428415298462, "step": 60000}
{"episode_reward": 484.33996322495483, "episode": 61.0, "batch_reward": 0.19990482506155968, "critic_loss": 0.38483074547350404, "actor_loss": -24.67851652908325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 50.80995488166809, "step": 61000}
{"episode_reward": 347.5966936044418, "episode": 62.0, "batch_reward": 0.20319134134054184, "critic_loss": 0.4173329322040081, "actor_loss": -24.77896736907959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.225544691085815, "step": 62000}
{"episode_reward": 456.60595842115936, "episode": 63.0, "batch_reward": 0.2070552732348442, "critic_loss": 0.4277047437876463, "actor_loss": -24.51144569015503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.354676485061646, "step": 63000}
{"episode_reward": 581.3798319405532, "episode": 64.0, "batch_reward": 0.21402589374780656, "critic_loss": 0.4133479249328375, "actor_loss": -25.088765747070312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.575448751449585, "step": 64000}
{"episode_reward": 647.4998480211356, "episode": 65.0, "batch_reward": 0.22009480985999108, "critic_loss": 0.4339423989206552, "actor_loss": -25.518030246734618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.479782342910767, "step": 65000}
{"episode_reward": 474.3727843123816, "episode": 66.0, "batch_reward": 0.22328163788467645, "critic_loss": 0.44112844607234003, "actor_loss": -25.854134735107422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.644219398498535, "step": 66000}
{"episode_reward": 568.2881919299049, "episode": 67.0, "batch_reward": 0.2293817418962717, "critic_loss": 0.43875675086677074, "actor_loss": -26.192982460021973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.465898036956787, "step": 67000}
{"episode_reward": 611.4597246625267, "episode": 68.0, "batch_reward": 0.23484925040602683, "critic_loss": 0.44456813877820966, "actor_loss": -26.572903343200682, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.252563953399658, "step": 68000}
{"episode_reward": 634.5527720897813, "episode": 69.0, "batch_reward": 0.23967243063449858, "critic_loss": 0.4478508908599615, "actor_loss": -26.581204681396486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.2887122631073, "step": 69000}
{"episode_reward": 555.4336505656986, "episode": 70.0, "batch_reward": 0.2449622460156679, "critic_loss": 0.42793603031337263, "actor_loss": -27.10891466522217, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.137308835983276, "step": 70000}
{"episode_reward": 446.326435422125, "episode": 71.0, "batch_reward": 0.24794660367071628, "critic_loss": 0.44348190891742706, "actor_loss": -27.255185623168945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 51.35569167137146, "step": 71000}
{"episode_reward": 495.608715777037, "episode": 72.0, "batch_reward": 0.2518823466747999, "critic_loss": 0.42447838066518306, "actor_loss": -27.494997943878175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.85128378868103, "step": 72000}
{"episode_reward": 620.6414804464266, "episode": 73.0, "batch_reward": 0.25557586865127085, "critic_loss": 0.47664547930657863, "actor_loss": -27.78495348739624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.80368161201477, "step": 73000}
{"episode_reward": 247.18991130963798, "episode": 74.0, "batch_reward": 0.2544756357073784, "critic_loss": 0.47588535070419313, "actor_loss": -27.363764350891113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.043739318847656, "step": 74000}
{"episode_reward": 311.1168852915203, "episode": 75.0, "batch_reward": 0.25375236493349074, "critic_loss": 0.49043498523533346, "actor_loss": -27.08730837249756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.393277168273926, "step": 75000}
{"episode_reward": 52.608935620412765, "episode": 76.0, "batch_reward": 0.2535176469385624, "critic_loss": 0.47647033743560313, "actor_loss": -27.106123706817627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.36409854888916, "step": 76000}
{"episode_reward": 528.348470350806, "episode": 77.0, "batch_reward": 0.25864534091949465, "critic_loss": 0.49027440175414083, "actor_loss": -27.365152477264406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.873929500579834, "step": 77000}
{"episode_reward": 624.3820206413864, "episode": 78.0, "batch_reward": 0.26319626289606096, "critic_loss": 0.4709248426556587, "actor_loss": -27.719850059509277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.398471355438232, "step": 78000}
{"episode_reward": 598.382815953339, "episode": 79.0, "batch_reward": 0.26590427102148534, "critic_loss": 0.4678274800926447, "actor_loss": -28.020544090270995, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.7710862159729, "step": 79000}
{"episode_reward": 301.94876703398097, "episode": 80.0, "batch_reward": 0.26654382449388503, "critic_loss": 0.4867124843746424, "actor_loss": -28.107160221099853, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.48161745071411, "step": 80000}
{"episode_reward": 608.8068622175933, "episode": 81.0, "batch_reward": 0.26992542839050293, "critic_loss": 0.47309888161718844, "actor_loss": -28.2225633354187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 51.71582388877869, "step": 81000}
{"episode_reward": 197.9347036368283, "episode": 82.0, "batch_reward": 0.27069209271669387, "critic_loss": 0.47579240991175176, "actor_loss": -28.037520034790038, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.134077072143555, "step": 82000}
{"episode_reward": 629.8375535262413, "episode": 83.0, "batch_reward": 0.276246611148119, "critic_loss": 0.48231702630221845, "actor_loss": -28.536547660827637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.644734621047974, "step": 83000}
{"episode_reward": 644.628540912378, "episode": 84.0, "batch_reward": 0.2794367648512125, "critic_loss": 0.4847113265991211, "actor_loss": -28.699005718231202, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.31060028076172, "step": 84000}
{"episode_reward": 592.0073610964844, "episode": 85.0, "batch_reward": 0.2831765129715204, "critic_loss": 0.47890538251399994, "actor_loss": -28.954491905212404, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.26987338066101, "step": 85000}
{"episode_reward": 685.1876920668165, "episode": 86.0, "batch_reward": 0.2880254984349012, "critic_loss": 0.4788683528751135, "actor_loss": -29.43461235809326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.404361248016357, "step": 86000}
{"episode_reward": 634.2188693869073, "episode": 87.0, "batch_reward": 0.29107512420415876, "critic_loss": 0.4651496353149414, "actor_loss": -29.81687398147583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.202783823013306, "step": 87000}
{"episode_reward": 602.9339191778103, "episode": 88.0, "batch_reward": 0.2940910044461489, "critic_loss": 0.5076101155281066, "actor_loss": -29.745589851379396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.77080798149109, "step": 88000}
{"episode_reward": 482.6597644176001, "episode": 89.0, "batch_reward": 0.29655327305197715, "critic_loss": 0.49821190668642523, "actor_loss": -30.115443851470946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.505858659744263, "step": 89000}
{"episode_reward": 521.9241202654297, "episode": 90.0, "batch_reward": 0.30055623112618923, "critic_loss": 0.512591660618782, "actor_loss": -30.37449950027466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.215718746185303, "step": 90000}
{"episode_reward": 584.0868022614213, "episode": 91.0, "batch_reward": 0.3031698425114155, "critic_loss": 0.5002472685873508, "actor_loss": -30.50601202392578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 52.63414788246155, "step": 91000}
{"episode_reward": 631.8985220731456, "episode": 92.0, "batch_reward": 0.3070635313540697, "critic_loss": 0.498223679125309, "actor_loss": -31.02482448196411, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.559151887893677, "step": 92000}
{"episode_reward": 640.5439009293093, "episode": 93.0, "batch_reward": 0.30984670533239844, "critic_loss": 0.4911011408418417, "actor_loss": -31.27491386795044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.48791217803955, "step": 93000}
{"episode_reward": 687.6739867766036, "episode": 94.0, "batch_reward": 0.31456971694529057, "critic_loss": 0.48536210300028326, "actor_loss": -31.55583268356323, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.3785080909729, "step": 94000}
{"episode_reward": 664.1028066549729, "episode": 95.0, "batch_reward": 0.3181918065100908, "critic_loss": 0.47227070650458336, "actor_loss": -32.11781209564209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.457367181777954, "step": 95000}
{"episode_reward": 626.778302541393, "episode": 96.0, "batch_reward": 0.3219237611591816, "critic_loss": 0.48867204478383064, "actor_loss": -32.24257099533081, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.47638463973999, "step": 96000}
{"episode_reward": 641.5914498443086, "episode": 97.0, "batch_reward": 0.32379935203492644, "critic_loss": 0.49198993979394434, "actor_loss": -32.70751482391358, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.309756994247437, "step": 97000}
{"episode_reward": 616.1663277196583, "episode": 98.0, "batch_reward": 0.3271117035895586, "critic_loss": 0.4814238142520189, "actor_loss": -33.317598148345944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.26463747024536, "step": 98000}
{"episode_reward": 638.7225464006223, "episode": 99.0, "batch_reward": 0.33048586708307265, "critic_loss": 0.4804156385958195, "actor_loss": -33.12931156539917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.127036333084106, "step": 99000}
{"episode_reward": 565.4596572740107, "episode": 100.0, "batch_reward": 0.33406855329871177, "critic_loss": 0.4673804315328598, "actor_loss": -33.58113419342041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.403910875320435, "step": 100000}
{"episode_reward": 664.0323806306277, "episode": 101.0, "batch_reward": 0.3364112375378609, "critic_loss": 0.4912391313016415, "actor_loss": -33.85288360595703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 52.9193480014801, "step": 101000}
{"episode_reward": 690.9068555823136, "episode": 102.0, "batch_reward": 0.33878870561718943, "critic_loss": 0.48649026700854303, "actor_loss": -34.01659310150146, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.489490509033203, "step": 102000}
{"episode_reward": 158.96356566059885, "episode": 103.0, "batch_reward": 0.33658696135878563, "critic_loss": 0.4921482557058334, "actor_loss": -33.922934951782224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.606756448745728, "step": 103000}
{"episode_reward": 221.81629444338625, "episode": 104.0, "batch_reward": 0.3373544578999281, "critic_loss": 0.4936159745156765, "actor_loss": -33.77183050918579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.45039391517639, "step": 104000}
{"episode_reward": 654.897497758217, "episode": 105.0, "batch_reward": 0.34063689661026003, "critic_loss": 0.4940774264335632, "actor_loss": -34.22385439300537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.136398792266846, "step": 105000}
{"episode_reward": 686.715271376682, "episode": 106.0, "batch_reward": 0.3422606950700283, "critic_loss": 0.5203159972727299, "actor_loss": -34.48576770782471, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.50119709968567, "step": 106000}
{"episode_reward": 604.392440564513, "episode": 107.0, "batch_reward": 0.3459528978765011, "critic_loss": 0.5171150422096252, "actor_loss": -34.752805671691895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.466147661209106, "step": 107000}
{"episode_reward": 579.2335418025189, "episode": 108.0, "batch_reward": 0.34812379160523416, "critic_loss": 0.5278846748024225, "actor_loss": -35.14925189590454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.21160387992859, "step": 108000}
{"episode_reward": 650.0793575334221, "episode": 109.0, "batch_reward": 0.35139600867033005, "critic_loss": 0.5225365068912506, "actor_loss": -35.34425147247315, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.629634141921997, "step": 109000}
{"episode_reward": 282.46029648583436, "episode": 110.0, "batch_reward": 0.3505607678294182, "critic_loss": 0.5446349860429763, "actor_loss": -35.34104223251343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.392784595489502, "step": 110000}
{"episode_reward": 650.763985200937, "episode": 111.0, "batch_reward": 0.35232947012782095, "critic_loss": 0.5167967675328254, "actor_loss": -35.407325454711916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.38584327697754, "step": 111000}
{"episode_reward": 679.0976364446198, "episode": 112.0, "batch_reward": 0.3564127219617367, "critic_loss": 0.5222836749255657, "actor_loss": -35.773143463134765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.255536556243896, "step": 112000}
{"episode_reward": 691.9941897409016, "episode": 113.0, "batch_reward": 0.35879804569482804, "critic_loss": 0.5403082444369793, "actor_loss": -35.86837146377564, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.648884057998657, "step": 113000}
{"episode_reward": 652.6631010696285, "episode": 114.0, "batch_reward": 0.36095089262723923, "critic_loss": 0.518614831417799, "actor_loss": -36.40194934082031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.325656414031982, "step": 114000}
{"episode_reward": 667.4571862063201, "episode": 115.0, "batch_reward": 0.3641930686235428, "critic_loss": 0.538959857583046, "actor_loss": -36.454268714904785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.314025163650513, "step": 115000}
{"episode_reward": 628.9113146864443, "episode": 116.0, "batch_reward": 0.3678844462931156, "critic_loss": 0.4950271256566048, "actor_loss": -36.746220333099366, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.50409507751465, "step": 116000}
{"episode_reward": 701.5835165934205, "episode": 117.0, "batch_reward": 0.37071672242879866, "critic_loss": 0.5064549753963947, "actor_loss": -36.946574169158936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.590400218963623, "step": 117000}
{"episode_reward": 679.8743577256827, "episode": 118.0, "batch_reward": 0.3726055640280247, "critic_loss": 0.5045992394685745, "actor_loss": -37.214334106445314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.506564378738403, "step": 118000}
{"episode_reward": 657.5960123560469, "episode": 119.0, "batch_reward": 0.37485305735468866, "critic_loss": 0.5216872398257255, "actor_loss": -37.24040615081787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.578529834747314, "step": 119000}
{"episode_reward": 682.3285974295894, "episode": 120.0, "batch_reward": 0.3775221292972565, "critic_loss": 0.5014480693936348, "actor_loss": -37.52367395019531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.104673862457275, "step": 120000}
{"episode_reward": 682.6579335054631, "episode": 121.0, "batch_reward": 0.3786878722012043, "critic_loss": 0.5346327140331268, "actor_loss": -37.79465414047241, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.143327951431274, "step": 121000}
{"episode_reward": 394.88430743199063, "episode": 122.0, "batch_reward": 0.3777325727045536, "critic_loss": 0.5339766507744789, "actor_loss": -37.58820207214355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.81502890586853, "step": 122000}
{"episode_reward": 92.94265126175716, "episode": 123.0, "batch_reward": 0.3772582816779613, "critic_loss": 0.5443184360414743, "actor_loss": -37.53320630645752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.045046091079712, "step": 123000}
{"episode_reward": 646.4237231146175, "episode": 124.0, "batch_reward": 0.3792161523103714, "critic_loss": 0.5451950121819973, "actor_loss": -37.78821816253662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.77375841140747, "step": 124000}
{"episode_reward": 592.7895643479342, "episode": 125.0, "batch_reward": 0.3799399466216564, "critic_loss": 0.5540440019667149, "actor_loss": -37.84937697982788, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.29834747314453, "step": 125000}
{"episode_reward": 691.9104442277353, "episode": 126.0, "batch_reward": 0.38318242621421816, "critic_loss": 0.558810578584671, "actor_loss": -38.189032676696776, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.372960567474365, "step": 126000}
{"episode_reward": 645.8969521451115, "episode": 127.0, "batch_reward": 0.38560440361499787, "critic_loss": 0.5688547391295433, "actor_loss": -38.1298027267456, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.258384704589844, "step": 127000}
{"episode_reward": 652.1341073977459, "episode": 128.0, "batch_reward": 0.3876310449242592, "critic_loss": 0.558655902594328, "actor_loss": -38.58560826873779, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.946104288101196, "step": 128000}
{"episode_reward": 704.2597494879252, "episode": 129.0, "batch_reward": 0.38955951458215715, "critic_loss": 0.5822806797921658, "actor_loss": -38.516398246765135, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.876259565353394, "step": 129000}
{"episode_reward": 708.8704201971925, "episode": 130.0, "batch_reward": 0.3924762088060379, "critic_loss": 0.5749785307049752, "actor_loss": -38.893725440979004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.20694088935852, "step": 130000}
{"episode_reward": 639.5293075422659, "episode": 131.0, "batch_reward": 0.39624076360464094, "critic_loss": 0.6037551693320274, "actor_loss": -39.10455503463745, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 53.80151176452637, "step": 131000}
{"episode_reward": 678.016707015283, "episode": 132.0, "batch_reward": 0.3972633236348629, "critic_loss": 0.5996236735284328, "actor_loss": -39.21305758285523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.721830368041992, "step": 132000}
{"episode_reward": 675.5056342946233, "episode": 133.0, "batch_reward": 0.39923640194535254, "critic_loss": 0.611795412003994, "actor_loss": -39.519446998596194, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.063792943954468, "step": 133000}
{"episode_reward": 658.4455363303542, "episode": 134.0, "batch_reward": 0.39994910529255867, "critic_loss": 0.5833823789060116, "actor_loss": -39.591310272216795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.610490798950195, "step": 134000}
{"episode_reward": 715.0782970367184, "episode": 135.0, "batch_reward": 0.4020609554350376, "critic_loss": 0.5737545868456364, "actor_loss": -39.727739700317386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.30894684791565, "step": 135000}
{"episode_reward": 693.1369305011693, "episode": 136.0, "batch_reward": 0.40630360195040705, "critic_loss": 0.6081506730020046, "actor_loss": -40.15897792816162, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.482577800750732, "step": 136000}
{"episode_reward": 731.8452460370646, "episode": 137.0, "batch_reward": 0.4081189639568329, "critic_loss": 0.6081044695079326, "actor_loss": -40.29667609405517, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.339541912078857, "step": 137000}
{"episode_reward": 613.4713753752719, "episode": 138.0, "batch_reward": 0.410212512999773, "critic_loss": 0.582832890689373, "actor_loss": -40.380383964538574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.852335214614868, "step": 138000}
{"episode_reward": 633.0688902653353, "episode": 139.0, "batch_reward": 0.4116319251656532, "critic_loss": 0.5506687760651111, "actor_loss": -40.70498672485351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.49427628517151, "step": 139000}
{"episode_reward": 744.0968695270747, "episode": 140.0, "batch_reward": 0.4116380226612091, "critic_loss": 0.545797848969698, "actor_loss": -40.668338241577146, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.14342737197876, "step": 140000}
{"episode_reward": 714.8222296635375, "episode": 141.0, "batch_reward": 0.41700619673728945, "critic_loss": 0.5686024591326714, "actor_loss": -41.010746147155764, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.25527596473694, "step": 141000}
{"episode_reward": 743.2138181546775, "episode": 142.0, "batch_reward": 0.4176658402681351, "critic_loss": 0.5693622084259987, "actor_loss": -41.11402319335937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.99132776260376, "step": 142000}
{"episode_reward": 230.16020201572488, "episode": 143.0, "batch_reward": 0.4171181835234165, "critic_loss": 0.5555692361593246, "actor_loss": -41.25088961029053, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.632393836975098, "step": 143000}
{"episode_reward": 699.6576991469561, "episode": 144.0, "batch_reward": 0.4185245558321476, "critic_loss": 0.567747784242034, "actor_loss": -41.29625420379639, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.534196376800537, "step": 144000}
{"episode_reward": 717.0945531005239, "episode": 145.0, "batch_reward": 0.4215912667810917, "critic_loss": 0.5619473796486855, "actor_loss": -41.609567909240724, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.00265884399414, "step": 145000}
{"episode_reward": 664.9687179829566, "episode": 146.0, "batch_reward": 0.42175208669900893, "critic_loss": 0.5539758520126343, "actor_loss": -41.56896744537354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.415602922439575, "step": 146000}
{"episode_reward": 712.8242924589556, "episode": 147.0, "batch_reward": 0.42174369165301323, "critic_loss": 0.5579832889437676, "actor_loss": -41.81076661682129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.523393154144287, "step": 147000}
{"episode_reward": 687.3427686206167, "episode": 148.0, "batch_reward": 0.42541038143634796, "critic_loss": 0.5547816723883152, "actor_loss": -41.99408196258545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.777113676071167, "step": 148000}
{"episode_reward": 547.9832273693503, "episode": 149.0, "batch_reward": 0.42695785665512087, "critic_loss": 0.5907634143531323, "actor_loss": -42.09484748077393, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.264023780822754, "step": 149000}
{"episode_reward": 639.585584060428, "episode": 150.0, "batch_reward": 0.42848631119728087, "critic_loss": 0.5778590268492698, "actor_loss": -42.22106965637207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
