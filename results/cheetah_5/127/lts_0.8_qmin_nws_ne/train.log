{"episode_reward": 0.0, "episode": 1.0, "duration": 18.294259548187256, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.5181753635406494, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.26089934298160594, "critic_loss": 0.0226049331333128, "actor_loss": -33.16665816758456, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.73549580574036, "step": 3000}
{"episode_reward": 15.48126563539911, "episode": 4.0, "batch_reward": 0.1656659992337227, "critic_loss": 0.021721608151681723, "actor_loss": -27.379575370788576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11001205444336, "step": 4000}
{"episode_reward": 7.574328835962831, "episode": 5.0, "batch_reward": 0.12918874602392316, "critic_loss": 0.019937096138484777, "actor_loss": -24.94915595626831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.776572704315186, "step": 5000}
{"episode_reward": 1.2808842004553338, "episode": 6.0, "batch_reward": 0.10498334949836136, "critic_loss": 0.021647320855408908, "actor_loss": -25.311299169540405, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.72382378578186, "step": 6000}
{"episode_reward": 2.1192953064755207, "episode": 7.0, "batch_reward": 0.08958454174920917, "critic_loss": 0.023457278755027802, "actor_loss": -24.448108930587768, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.2181556224823, "step": 7000}
{"episode_reward": 2.4680894848983526, "episode": 8.0, "batch_reward": 0.07810574214905501, "critic_loss": 0.024898949809838086, "actor_loss": -23.868589178562164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.86676859855652, "step": 8000}
{"episode_reward": 2.1742243109545916, "episode": 9.0, "batch_reward": 0.0688075599540025, "critic_loss": 0.022692210994660855, "actor_loss": -23.955758605480195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.781468391418457, "step": 9000}
{"episode_reward": 0.7022704116640125, "episode": 10.0, "batch_reward": 0.062236962627619505, "critic_loss": 0.02573191805789247, "actor_loss": -23.959214678287506, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.08051300048828, "step": 10000}
{"episode_reward": 3.425451575579099, "episode": 11.0, "batch_reward": 0.057376189855858684, "critic_loss": 0.02077796607464552, "actor_loss": -23.632448014736177, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.27709984779358, "step": 11000}
{"episode_reward": 3.768532174832426, "episode": 12.0, "batch_reward": 0.051433740113861856, "critic_loss": 0.023466117058414965, "actor_loss": -23.35128926849365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.788514852523804, "step": 12000}
{"episode_reward": 8.4266879951168, "episode": 13.0, "batch_reward": 0.04844685458578169, "critic_loss": 0.029052164962282405, "actor_loss": -23.329471463918686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.93500518798828, "step": 13000}
{"episode_reward": 9.089280967754704, "episode": 14.0, "batch_reward": 0.04614099484682083, "critic_loss": 0.02148645322956145, "actor_loss": -22.985647243738175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.370707988739014, "step": 14000}
{"episode_reward": 13.244396522847786, "episode": 15.0, "batch_reward": 0.04301351535972208, "critic_loss": 0.027330162348225714, "actor_loss": -23.63810290837288, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.73792815208435, "step": 15000}
{"episode_reward": 5.05855164635855, "episode": 16.0, "batch_reward": 0.040893501193262634, "critic_loss": 0.032379336363635956, "actor_loss": -23.310355907678606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.492320775985718, "step": 16000}
{"episode_reward": 7.56276228890678, "episode": 17.0, "batch_reward": 0.03887599920388311, "critic_loss": 0.01908390067704022, "actor_loss": -22.716063354730608, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.414687156677246, "step": 17000}
{"episode_reward": 9.68276496383478, "episode": 18.0, "batch_reward": 0.03806695915572345, "critic_loss": 0.031066138736205177, "actor_loss": -23.042126433610918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.77838969230652, "step": 18000}
{"episode_reward": 10.155070921154513, "episode": 19.0, "batch_reward": 0.035840869844891134, "critic_loss": 0.01802969568129629, "actor_loss": -23.254584027290345, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.7484028339386, "step": 19000}
{"episode_reward": 4.215554977875613, "episode": 20.0, "batch_reward": 0.03422890827432275, "critic_loss": 0.03037297773407772, "actor_loss": -23.937966233968734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.78288245201111, "step": 20000}
{"episode_reward": 5.013543131601414, "episode": 21.0, "batch_reward": 0.032083308665081856, "critic_loss": 0.0198198770780582, "actor_loss": -22.26905890583992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.73709988594055, "step": 21000}
{"episode_reward": 7.603334858023083, "episode": 22.0, "batch_reward": 0.03174551824992523, "critic_loss": 0.02726602399768308, "actor_loss": -23.154584597349167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.304643154144287, "step": 22000}
{"episode_reward": 7.671366208982671, "episode": 23.0, "batch_reward": 0.030538001930341126, "critic_loss": 0.02080135923670605, "actor_loss": -22.56018994832039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.798536777496338, "step": 23000}
{"episode_reward": 8.210568432451684, "episode": 24.0, "batch_reward": 0.02951455419836566, "critic_loss": 0.02579225080087781, "actor_loss": -23.087129722118377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96483826637268, "step": 24000}
{"episode_reward": 9.247406988438632, "episode": 25.0, "batch_reward": 0.029209947228897363, "critic_loss": 0.020927846905309706, "actor_loss": -23.462745153665544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.76041579246521, "step": 25000}
{"episode_reward": 8.281510807803416, "episode": 26.0, "batch_reward": 0.028161509199533613, "critic_loss": 0.02742733670445159, "actor_loss": -22.619080164074898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.79313087463379, "step": 26000}
{"episode_reward": 11.681343122894997, "episode": 27.0, "batch_reward": 0.02785266830585897, "critic_loss": 0.019889621055917815, "actor_loss": -22.972063384771346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.205772876739502, "step": 27000}
{"episode_reward": 4.996038028110942, "episode": 28.0, "batch_reward": 0.026797654913272708, "critic_loss": 0.0233538746740669, "actor_loss": -22.529449299812317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.74436068534851, "step": 28000}
{"episode_reward": 2.456617770121067, "episode": 29.0, "batch_reward": 0.02534303541108966, "critic_loss": 0.0234255823912099, "actor_loss": -22.761987863183023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.786349296569824, "step": 29000}
{"episode_reward": 3.5926332175834323, "episode": 30.0, "batch_reward": 0.02512145948735997, "critic_loss": 0.012535226461710408, "actor_loss": -21.868312690377234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.834699153900146, "step": 30000}
{"episode_reward": 10.265175807313007, "episode": 31.0, "batch_reward": 0.024286484338343142, "critic_loss": 0.022168552945135162, "actor_loss": -22.46347390949726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.12556552886963, "step": 31000}
{"episode_reward": 4.512974201117151, "episode": 32.0, "batch_reward": 0.023845302035100758, "critic_loss": 0.017674355001887306, "actor_loss": -22.367692652106285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.78959631919861, "step": 32000}
{"episode_reward": 5.185119311971338, "episode": 33.0, "batch_reward": 0.0232958744331263, "critic_loss": 0.02282871666480787, "actor_loss": -22.415915170311926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.063101530075073, "step": 33000}
{"episode_reward": 4.482601419109623, "episode": 34.0, "batch_reward": 0.022832011109218002, "critic_loss": 0.021363813682459296, "actor_loss": -22.353369417905807, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.61861777305603, "step": 34000}
{"episode_reward": 3.0464837824002995, "episode": 35.0, "batch_reward": 0.02152618864038959, "critic_loss": 0.021701363335712813, "actor_loss": -22.21907201886177, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.80639934539795, "step": 35000}
{"episode_reward": 8.75111235423234, "episode": 36.0, "batch_reward": 0.021358935287222266, "critic_loss": 0.017587146677309647, "actor_loss": -22.61358445107937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.522393226623535, "step": 36000}
{"episode_reward": 7.072198056519267, "episode": 37.0, "batch_reward": 0.021403408411191777, "critic_loss": 0.01908883238211274, "actor_loss": -21.822059957504273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.72510552406311, "step": 37000}
{"episode_reward": 8.278292310486998, "episode": 38.0, "batch_reward": 0.020903941966127604, "critic_loss": 0.012257081069401465, "actor_loss": -21.444885894298555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9969482421875, "step": 38000}
{"episode_reward": 11.326872235064059, "episode": 39.0, "batch_reward": 0.02092223102878779, "critic_loss": 0.026629307239083574, "actor_loss": -21.396253148198127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.800577402114868, "step": 39000}
{"episode_reward": 12.133924830541686, "episode": 40.0, "batch_reward": 0.02041751095931977, "critic_loss": 0.014222577701089903, "actor_loss": -22.03310275232792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.032500505447388, "step": 40000}
{"episode_reward": 3.9810092246235183, "episode": 41.0, "batch_reward": 0.019863274942152204, "critic_loss": 0.018480914716026746, "actor_loss": -21.740354317188263, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.31181883811951, "step": 41000}
{"episode_reward": 2.8542771730468592, "episode": 42.0, "batch_reward": 0.01968091616802849, "critic_loss": 0.015065113720600494, "actor_loss": -21.758023378133775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.74692964553833, "step": 42000}
{"episode_reward": 3.401302725428903, "episode": 43.0, "batch_reward": 0.019045705150580034, "critic_loss": 0.02026268618053291, "actor_loss": -21.830394535541533, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.824168920516968, "step": 43000}
{"episode_reward": 2.1115585745636896, "episode": 44.0, "batch_reward": 0.019038548284675928, "critic_loss": 0.013296603852999397, "actor_loss": -23.361453081965447, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.32124161720276, "step": 44000}
{"episode_reward": 6.44078165470599, "episode": 45.0, "batch_reward": 0.01836225273180753, "critic_loss": 0.014189653908950276, "actor_loss": -22.232452846348284, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.81068229675293, "step": 45000}
{"episode_reward": 2.4626358004239854, "episode": 46.0, "batch_reward": 0.017836028147256003, "critic_loss": 0.015680535427178257, "actor_loss": -21.169736110448838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.467989444732666, "step": 46000}
{"episode_reward": 2.373081398633564, "episode": 47.0, "batch_reward": 0.017573837323114277, "critic_loss": 0.01723624554241542, "actor_loss": -21.76974589884281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.505056142807007, "step": 47000}
{"episode_reward": 3.4482170301121213, "episode": 48.0, "batch_reward": 0.017453650194453076, "critic_loss": 0.014245341050787829, "actor_loss": -21.44479354542494, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.798604488372803, "step": 48000}
{"episode_reward": 3.027919554718156, "episode": 49.0, "batch_reward": 0.017333824921166523, "critic_loss": 0.010701646921865177, "actor_loss": -22.641340940117836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.740909099578857, "step": 49000}
{"episode_reward": 2.973689437435576, "episode": 50.0, "batch_reward": 0.016922441178932785, "critic_loss": 0.01842246640322264, "actor_loss": -22.05042384403944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.49616312980652, "step": 50000}
{"episode_reward": 5.787330566070176, "episode": 51.0, "batch_reward": 0.01680000563012436, "critic_loss": 0.00966960391891189, "actor_loss": -21.84762445896864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.99001955986023, "step": 51000}
{"episode_reward": 7.608651833345311, "episode": 52.0, "batch_reward": 0.016522100050468, "critic_loss": 0.014685344313038513, "actor_loss": -21.407266176044942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.810129404067993, "step": 52000}
{"episode_reward": 3.2078878773530892, "episode": 53.0, "batch_reward": 0.01634612682228908, "critic_loss": 0.017527549372112844, "actor_loss": -22.246676485776902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.761892080307007, "step": 53000}
{"episode_reward": 2.8003113710434997, "episode": 54.0, "batch_reward": 0.01605138561874628, "critic_loss": 0.012766823988524266, "actor_loss": -22.584748141109944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.635695219039917, "step": 54000}
{"episode_reward": 4.231523073518471, "episode": 55.0, "batch_reward": 0.016068189633544533, "critic_loss": 0.011035996994993184, "actor_loss": -22.286790483653544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.711028814315796, "step": 55000}
{"episode_reward": 2.993753174235059, "episode": 56.0, "batch_reward": 0.015451919564045966, "critic_loss": 0.011492480059852823, "actor_loss": -22.15639772939682, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988244771957397, "step": 56000}
{"episode_reward": 3.9079525980072956, "episode": 57.0, "batch_reward": 0.01539326692558825, "critic_loss": 0.012316339282959233, "actor_loss": -22.17288355076313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.790372848510742, "step": 57000}
{"episode_reward": 4.52359002510936, "episode": 58.0, "batch_reward": 0.015070782442577183, "critic_loss": 0.008619011735077948, "actor_loss": -22.288288252949716, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.112766981124878, "step": 58000}
{"episode_reward": 2.7611865044970445, "episode": 59.0, "batch_reward": 0.014852050662273542, "critic_loss": 0.013706590244430118, "actor_loss": -22.11390038526058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.774399042129517, "step": 59000}
{"episode_reward": 2.4625171754271444, "episode": 60.0, "batch_reward": 0.014908332663588226, "critic_loss": 0.009135186544735916, "actor_loss": -22.038803639650347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.593664169311523, "step": 60000}
{"episode_reward": 2.4059579051719773, "episode": 61.0, "batch_reward": 0.014802240772405639, "critic_loss": 0.01455170010839356, "actor_loss": -21.931438721060754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.676942586898804, "step": 61000}
{"episode_reward": 3.4271725892695564, "episode": 62.0, "batch_reward": 0.01473433133866638, "critic_loss": 0.009829248224385082, "actor_loss": -21.987161121606828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.79517102241516, "step": 62000}
{"episode_reward": 3.330908054582222, "episode": 63.0, "batch_reward": 0.014139099715976045, "critic_loss": 0.0084750567949377, "actor_loss": -22.07635774511099, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.865931510925293, "step": 63000}
{"episode_reward": 2.2754845600570306, "episode": 64.0, "batch_reward": 0.013939433339750394, "critic_loss": 0.009371649029839318, "actor_loss": -22.504134872674943, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.360652208328247, "step": 64000}
{"episode_reward": 7.6916771405096975, "episode": 65.0, "batch_reward": 0.013854166684672237, "critic_loss": 0.008478171715396457, "actor_loss": -21.942849342286586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.773211240768433, "step": 65000}
{"episode_reward": 6.32920511906442, "episode": 66.0, "batch_reward": 0.013748813150683417, "critic_loss": 0.012910179298080039, "actor_loss": -21.819888166606425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.819318532943726, "step": 66000}
{"episode_reward": 5.261987895962421, "episode": 67.0, "batch_reward": 0.013810908752027898, "critic_loss": 0.007516504150757101, "actor_loss": -22.54330666935444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.622776746749878, "step": 67000}
{"episode_reward": 3.491647419102474, "episode": 68.0, "batch_reward": 0.013448907893383875, "critic_loss": 0.010303555067745038, "actor_loss": -23.149188285470007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.736452341079712, "step": 68000}
{"episode_reward": 9.019362698745294, "episode": 69.0, "batch_reward": 0.01356908718473278, "critic_loss": 0.009791059037786909, "actor_loss": -21.469417569100855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.79344940185547, "step": 69000}
{"episode_reward": 3.425739095622724, "episode": 70.0, "batch_reward": 0.013449983196798711, "critic_loss": 0.00913802524690982, "actor_loss": -21.778212592840195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99387288093567, "step": 70000}
{"episode_reward": 7.545609481411439, "episode": 71.0, "batch_reward": 0.013340951063204556, "critic_loss": 0.012839153822511435, "actor_loss": -21.33989480483532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.37043261528015, "step": 71000}
{"episode_reward": 2.327056377934605, "episode": 72.0, "batch_reward": 0.013317539792042225, "critic_loss": 0.008571124908223282, "actor_loss": -22.290704939842225, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.841715574264526, "step": 72000}
{"episode_reward": 2.664827441771827, "episode": 73.0, "batch_reward": 0.01305049361474812, "critic_loss": 0.008927459595550318, "actor_loss": -22.471081154584883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.156337022781372, "step": 73000}
{"episode_reward": 3.668834948366557, "episode": 74.0, "batch_reward": 0.012649232611292973, "critic_loss": 0.008312957723683212, "actor_loss": -21.58905135577917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.965519189834595, "step": 74000}
{"episode_reward": 4.342021128037297, "episode": 75.0, "batch_reward": 0.012489763411227614, "critic_loss": 0.008893171229574363, "actor_loss": -21.57559382468462, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.440173387527466, "step": 75000}
{"episode_reward": 2.45377107585921, "episode": 76.0, "batch_reward": 0.012770443896297366, "critic_loss": 0.008371437552152201, "actor_loss": -22.142694740891457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.742838382720947, "step": 76000}
{"episode_reward": 5.021043961085824, "episode": 77.0, "batch_reward": 0.012828542160801589, "critic_loss": 0.010634520833089483, "actor_loss": -21.686488253235815, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1016366481781, "step": 77000}
{"episode_reward": 4.068487566745859, "episode": 78.0, "batch_reward": 0.012795238130958751, "critic_loss": 0.007442392926255707, "actor_loss": -22.031087131381035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.85873007774353, "step": 78000}
{"episode_reward": 4.000687154048308, "episode": 79.0, "batch_reward": 0.012182086496381089, "critic_loss": 0.009494868255860638, "actor_loss": -22.89951666122675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17590832710266, "step": 79000}
{"episode_reward": 4.023571136147084, "episode": 80.0, "batch_reward": 0.01227246272051707, "critic_loss": 0.008467330597690307, "actor_loss": -22.29190203553438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.045304775238037, "step": 80000}
{"episode_reward": 2.5200536916456557, "episode": 81.0, "batch_reward": 0.011698748441878706, "critic_loss": 0.009332208833890035, "actor_loss": -21.40392982327938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.67397975921631, "step": 81000}
{"episode_reward": 3.0385427782145564, "episode": 82.0, "batch_reward": 0.01185012234491296, "critic_loss": 0.008907329854962882, "actor_loss": -21.51780283522606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.829875469207764, "step": 82000}
{"episode_reward": 10.029434781183717, "episode": 83.0, "batch_reward": 0.011964270495576784, "critic_loss": 0.007631856680731289, "actor_loss": -22.068052754998206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.803968906402588, "step": 83000}
{"episode_reward": 10.380711764479438, "episode": 84.0, "batch_reward": 0.011921815184876323, "critic_loss": 0.011529078429448418, "actor_loss": -22.448635343253613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.107476234436035, "step": 84000}
{"episode_reward": 13.590780800677768, "episode": 85.0, "batch_reward": 0.011884193326812238, "critic_loss": 0.008014101112203208, "actor_loss": -22.10137966990471, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.35675621032715, "step": 85000}
{"episode_reward": 6.156699703594575, "episode": 86.0, "batch_reward": 0.011998760482063517, "critic_loss": 0.008234496892255265, "actor_loss": -21.94131533485651, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97982120513916, "step": 86000}
{"episode_reward": 6.97915687780242, "episode": 87.0, "batch_reward": 0.011854554142104462, "critic_loss": 0.00936018069559941, "actor_loss": -22.278093724370002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.809252500534058, "step": 87000}
{"episode_reward": 7.004786035112687, "episode": 88.0, "batch_reward": 0.011480480741942302, "critic_loss": 0.00680687818856677, "actor_loss": -21.49223421150446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.88973116874695, "step": 88000}
{"episode_reward": 12.481336019196958, "episode": 89.0, "batch_reward": 0.011880084145115688, "critic_loss": 0.012752694320108275, "actor_loss": -22.023933269500734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.239482402801514, "step": 89000}
{"episode_reward": 7.982428915599602, "episode": 90.0, "batch_reward": 0.011888778532855212, "critic_loss": 0.009060487721289973, "actor_loss": -21.65073669064045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.929130792617798, "step": 90000}
{"episode_reward": 6.371262257286534, "episode": 91.0, "batch_reward": 0.01168038644758053, "critic_loss": 0.00698392286960734, "actor_loss": -21.79430150079727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.35544753074646, "step": 91000}
{"episode_reward": 8.05016628684499, "episode": 92.0, "batch_reward": 0.01158329065470025, "critic_loss": 0.009303907781722956, "actor_loss": -22.639481526851654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.63174033164978, "step": 92000}
{"episode_reward": 6.841579447569632, "episode": 93.0, "batch_reward": 0.011534108837135137, "critic_loss": 0.00802287312305998, "actor_loss": -21.461998288810253, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.836398601531982, "step": 93000}
{"episode_reward": 13.175554302722562, "episode": 94.0, "batch_reward": 0.011460167978191748, "critic_loss": 0.007321364277653629, "actor_loss": -22.15992204836011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.785342693328857, "step": 94000}
{"episode_reward": 6.355387185009855, "episode": 95.0, "batch_reward": 0.011380978612462058, "critic_loss": 0.006828062254586257, "actor_loss": -22.718804633677006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.274814128875732, "step": 95000}
{"episode_reward": 9.858923132814887, "episode": 96.0, "batch_reward": 0.011767217169981449, "critic_loss": 0.008546021689777262, "actor_loss": -22.705257635772227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.95543885231018, "step": 96000}
{"episode_reward": 11.472700353430149, "episode": 97.0, "batch_reward": 0.011533881823299452, "critic_loss": 0.007626373059407342, "actor_loss": -22.07883086785674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.783540725708008, "step": 97000}
{"episode_reward": 2.2990596740203797, "episode": 98.0, "batch_reward": 0.01116342990566045, "critic_loss": 0.007153922915400472, "actor_loss": -22.797420731902122, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.784550189971924, "step": 98000}
{"episode_reward": 3.5910555288053567, "episode": 99.0, "batch_reward": 0.011240480119362474, "critic_loss": 0.007524537484685425, "actor_loss": -21.82648565867543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.890905141830444, "step": 99000}
{"episode_reward": 11.07588376984408, "episode": 100.0, "batch_reward": 0.011418899089796469, "critic_loss": 0.0094073971817852, "actor_loss": -22.520000789970158, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.333559036254883, "step": 100000}
{"episode_reward": 10.947228452377319, "episode": 101.0, "batch_reward": 0.011528302914230152, "critic_loss": 0.007550680503365583, "actor_loss": -21.403730158627035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.68370699882507, "step": 101000}
{"episode_reward": 6.217556199286427, "episode": 102.0, "batch_reward": 0.011553717559436336, "critic_loss": 0.010222059582767543, "actor_loss": -22.313963256031276, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.796465396881104, "step": 102000}
{"episode_reward": 11.1000807004836, "episode": 103.0, "batch_reward": 0.011551402788143605, "critic_loss": 0.007577294816321228, "actor_loss": -21.423776828855274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.888604879379272, "step": 103000}
{"episode_reward": 5.700892459824145, "episode": 104.0, "batch_reward": 0.011430099005810917, "critic_loss": 0.010068426880752667, "actor_loss": -21.425313842624426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.767110586166382, "step": 104000}
{"episode_reward": 8.022850661530539, "episode": 105.0, "batch_reward": 0.011273344575427472, "critic_loss": 0.009050389430776705, "actor_loss": -21.845189385652542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.478121995925903, "step": 105000}
{"episode_reward": 5.232623978765095, "episode": 106.0, "batch_reward": 0.010881108880741522, "critic_loss": 0.0084177425079979, "actor_loss": -21.71561549729109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.568691968917847, "step": 106000}
{"episode_reward": 8.517310818589452, "episode": 107.0, "batch_reward": 0.011179977039340884, "critic_loss": 0.010299951152177527, "actor_loss": -21.032822820156813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.778768301010132, "step": 107000}
{"episode_reward": 3.3819795091368547, "episode": 108.0, "batch_reward": 0.011381245783297345, "critic_loss": 0.007946811961417551, "actor_loss": -22.308775012254713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.059534311294556, "step": 108000}
{"episode_reward": 7.228167739736612, "episode": 109.0, "batch_reward": 0.010784572317963466, "critic_loss": 0.008719650527986232, "actor_loss": -21.753683643937112, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.787678003311157, "step": 109000}
{"episode_reward": 3.6057718610836655, "episode": 110.0, "batch_reward": 0.011237753483699636, "critic_loss": 0.00834087367815664, "actor_loss": -22.826143487036227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098724365234375, "step": 110000}
{"episode_reward": 4.2851385026611, "episode": 111.0, "batch_reward": 0.010893567291088401, "critic_loss": 0.009238837053242605, "actor_loss": -21.796900358617307, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.023927211761475, "step": 111000}
{"episode_reward": 7.548913910340346, "episode": 112.0, "batch_reward": 0.01091963733616285, "critic_loss": 0.010864196754409932, "actor_loss": -21.948269975692035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.976118803024292, "step": 112000}
{"episode_reward": 5.270037511313504, "episode": 113.0, "batch_reward": 0.010881918869679794, "critic_loss": 0.00829173009179067, "actor_loss": -21.74512850996852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.388885259628296, "step": 113000}
{"episode_reward": 7.566910443599415, "episode": 114.0, "batch_reward": 0.010937122567789628, "critic_loss": 0.008366402118350378, "actor_loss": -22.214107574641705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.79362392425537, "step": 114000}
{"episode_reward": 8.606995702970394, "episode": 115.0, "batch_reward": 0.010441768816905096, "critic_loss": 0.009403116361238062, "actor_loss": -22.078717340797187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.45783543586731, "step": 115000}
{"episode_reward": 5.212849581287655, "episode": 116.0, "batch_reward": 0.010756982693448663, "critic_loss": 0.009081527614733204, "actor_loss": -22.173197126626967, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.486685514450073, "step": 116000}
{"episode_reward": 6.436172891114224, "episode": 117.0, "batch_reward": 0.010605613525258377, "critic_loss": 0.007388679224430234, "actor_loss": -21.3100687443316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.75780177116394, "step": 117000}
{"episode_reward": 6.536172746178323, "episode": 118.0, "batch_reward": 0.010486752716125921, "critic_loss": 0.007039246372471098, "actor_loss": -21.72522073099017, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.815934419631958, "step": 118000}
{"episode_reward": 7.410246474845294, "episode": 119.0, "batch_reward": 0.010880656325025485, "critic_loss": 0.008685635053523584, "actor_loss": -22.149648198872804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.310601234436035, "step": 119000}
{"episode_reward": 8.0455881638571, "episode": 120.0, "batch_reward": 0.01076155805028975, "critic_loss": 0.008330342585919425, "actor_loss": -20.888339555442332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.156667470932007, "step": 120000}
{"episode_reward": 6.496079030482971, "episode": 121.0, "batch_reward": 0.010434468355728314, "critic_loss": 0.007396664116356987, "actor_loss": -21.67858459186554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.75529956817627, "step": 121000}
{"episode_reward": 9.209445276498151, "episode": 122.0, "batch_reward": 0.010444692673860117, "critic_loss": 0.006272238574107178, "actor_loss": -22.23919383636117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.73398232460022, "step": 122000}
{"episode_reward": 7.530113732643366, "episode": 123.0, "batch_reward": 0.01053680952754803, "critic_loss": 0.0076785724749206564, "actor_loss": -22.497093003898858, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.801804304122925, "step": 123000}
{"episode_reward": 6.19723478853237, "episode": 124.0, "batch_reward": 0.010818753530271352, "critic_loss": 0.008680164332385176, "actor_loss": -22.190568897873163, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.782806396484375, "step": 124000}
{"episode_reward": 4.098603997781916, "episode": 125.0, "batch_reward": 0.010273125275969505, "critic_loss": 0.005883848934405251, "actor_loss": -21.76396955573559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.777719736099243, "step": 125000}
{"episode_reward": 7.770984179686434, "episode": 126.0, "batch_reward": 0.010569334709784016, "critic_loss": 0.007175078567379387, "actor_loss": -22.50627892419696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.79361891746521, "step": 126000}
{"episode_reward": 7.577618403267548, "episode": 127.0, "batch_reward": 0.010381437357980758, "critic_loss": 0.008060310444328934, "actor_loss": -22.006724534600973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.98538851737976, "step": 127000}
{"episode_reward": 4.378221196429733, "episode": 128.0, "batch_reward": 0.010383950938936322, "critic_loss": 0.005456739587069023, "actor_loss": -21.22615782573819, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.68505549430847, "step": 128000}
{"episode_reward": 6.8316312752400234, "episode": 129.0, "batch_reward": 0.010553400649689139, "critic_loss": 0.0069224938310217116, "actor_loss": -21.969236611664297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.745312452316284, "step": 129000}
{"episode_reward": 14.283018705136449, "episode": 130.0, "batch_reward": 0.010346868389751762, "critic_loss": 0.006306551183224656, "actor_loss": -22.259384971559047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.939494132995605, "step": 130000}
{"episode_reward": 12.73529475174779, "episode": 131.0, "batch_reward": 0.010310562289319933, "critic_loss": 0.009801527856383472, "actor_loss": -20.622872912690042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.67646670341492, "step": 131000}
{"episode_reward": 9.588162237458432, "episode": 132.0, "batch_reward": 0.010327188393101096, "critic_loss": 0.006722926055896096, "actor_loss": -22.560781705647706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.801580905914307, "step": 132000}
{"episode_reward": 2.883878753347554, "episode": 133.0, "batch_reward": 0.01027224973309785, "critic_loss": 0.005697490502439905, "actor_loss": -21.151008194118738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89942169189453, "step": 133000}
{"episode_reward": 7.838046686210393, "episode": 134.0, "batch_reward": 0.01060561973042786, "critic_loss": 0.007070560543856118, "actor_loss": -21.760784171253444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.931224822998047, "step": 134000}
{"episode_reward": 13.135980712338359, "episode": 135.0, "batch_reward": 0.010101822639117018, "critic_loss": 0.00716231638591853, "actor_loss": -22.230170898407696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.271151781082153, "step": 135000}
{"episode_reward": 3.6806633562817037, "episode": 136.0, "batch_reward": 0.010460418625734746, "critic_loss": 0.009513372317218454, "actor_loss": -21.527566673249005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.818525314331055, "step": 136000}
{"episode_reward": 8.364568695013403, "episode": 137.0, "batch_reward": 0.010165332020493224, "critic_loss": 0.008217901303694816, "actor_loss": -22.211648661613463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.569854497909546, "step": 137000}
{"episode_reward": 4.62444419827415, "episode": 138.0, "batch_reward": 0.010214236790314317, "critic_loss": 0.009938147175649647, "actor_loss": -22.99351836398244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.689394235610962, "step": 138000}
{"episode_reward": 7.273698750326939, "episode": 139.0, "batch_reward": 0.010141265999525785, "critic_loss": 0.006343853254045825, "actor_loss": -21.01915199917555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999036073684692, "step": 139000}
{"episode_reward": 7.974477722248508, "episode": 140.0, "batch_reward": 0.01037544522457756, "critic_loss": 0.008905082850251347, "actor_loss": -22.645374971747398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.81585693359375, "step": 140000}
{"episode_reward": 7.413196067775177, "episode": 141.0, "batch_reward": 0.010124405422946438, "critic_loss": 0.00739370779087767, "actor_loss": -21.885877834886312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.68385577201843, "step": 141000}
{"episode_reward": 7.4530877577097465, "episode": 142.0, "batch_reward": 0.01011030426970683, "critic_loss": 0.007912494935619178, "actor_loss": -21.724501742854713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.76971411705017, "step": 142000}
{"episode_reward": 6.031798623583651, "episode": 143.0, "batch_reward": 0.010242944541154429, "critic_loss": 0.008926868248381651, "actor_loss": -21.879823461413384, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.83760356903076, "step": 143000}
{"episode_reward": 9.242510458667478, "episode": 144.0, "batch_reward": 0.010168271887814627, "critic_loss": 0.0063474066972848955, "actor_loss": -22.299557570904494, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.536799430847168, "step": 144000}
{"episode_reward": 8.487280630123271, "episode": 145.0, "batch_reward": 0.009877567539457231, "critic_loss": 0.010598162944545037, "actor_loss": -22.248778491556646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.69540309906006, "step": 145000}
{"episode_reward": 6.448282661659357, "episode": 146.0, "batch_reward": 0.009927939289715141, "critic_loss": 0.010082576648041141, "actor_loss": -21.095735659748314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.823200225830078, "step": 146000}
{"episode_reward": 5.07528617263159, "episode": 147.0, "batch_reward": 0.010175779624842108, "critic_loss": 0.007805863113666419, "actor_loss": -21.72000780925155, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.790515422821045, "step": 147000}
{"episode_reward": 6.737502600594625, "episode": 148.0, "batch_reward": 0.009988329341402277, "critic_loss": 0.007371116457623429, "actor_loss": -21.459720564343034, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97261691093445, "step": 148000}
{"episode_reward": 10.67656686158324, "episode": 149.0, "batch_reward": 0.010079219749663025, "critic_loss": 0.007798744035186246, "actor_loss": -22.031774942189454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.7358341217041, "step": 149000}
{"episode_reward": 12.405657672152051, "episode": 150.0, "batch_reward": 0.009796354965306819, "critic_loss": 0.007882143828901463, "actor_loss": -22.495489220798017, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
