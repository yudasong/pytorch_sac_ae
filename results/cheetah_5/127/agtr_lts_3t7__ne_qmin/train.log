{"episode_reward": 0.0, "episode": 1.0, "duration": 14.851142644882202, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.3294241428375244, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.26301187206284526, "critic_loss": 0.4090084869212093, "actor_loss": -43.12738978495451, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 73.3754653930664, "step": 3000}
{"episode_reward": 39.14403655847653, "episode": 4.0, "batch_reward": 0.17216526722162961, "critic_loss": 0.7218535308986902, "actor_loss": -48.62505010604858, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.12725853919983, "step": 4000}
{"episode_reward": 3.3048190477508514, "episode": 5.0, "batch_reward": 0.13493980166316033, "critic_loss": 0.6701277585327625, "actor_loss": -49.819561180114746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.43341898918152, "step": 5000}
{"episode_reward": 12.499780622957221, "episode": 6.0, "batch_reward": 0.11075882012769579, "critic_loss": 0.49027551245689394, "actor_loss": -53.81628957748413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.418241500854492, "step": 6000}
{"episode_reward": 4.521437073048322, "episode": 7.0, "batch_reward": 0.09488490042090415, "critic_loss": 0.41073173689842224, "actor_loss": -53.95154472732544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.247408390045166, "step": 7000}
{"episode_reward": 2.2735775280518182, "episode": 8.0, "batch_reward": 0.0825005896128714, "critic_loss": 0.37746418137848375, "actor_loss": -55.91692220306396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.82995367050171, "step": 8000}
{"episode_reward": 1.469818035826453, "episode": 9.0, "batch_reward": 0.07259259935840964, "critic_loss": 0.385074498206377, "actor_loss": -55.31116648483276, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.811857223510742, "step": 9000}
{"episode_reward": 1.74078331416302, "episode": 10.0, "batch_reward": 0.06565749238058925, "critic_loss": 0.3965145666897297, "actor_loss": -54.89929467010498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.67579746246338, "step": 10000}
{"episode_reward": 1.6037001096575136, "episode": 11.0, "batch_reward": 0.06093969535455108, "critic_loss": 0.7017704879939556, "actor_loss": -53.084736000061035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.097270488739014, "step": 11000}
{"episode_reward": 14.767898228373719, "episode": 12.0, "batch_reward": 0.05841869913600385, "critic_loss": 0.8597159271836281, "actor_loss": -52.57779880142212, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.294456005096436, "step": 12000}
{"episode_reward": 123.64056134299898, "episode": 13.0, "batch_reward": 0.06168984428234398, "critic_loss": 0.6070239096581936, "actor_loss": -50.73750650024414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.131294012069702, "step": 13000}
{"episode_reward": 68.65159140255757, "episode": 14.0, "batch_reward": 0.06327650025486946, "critic_loss": 0.5184261612445116, "actor_loss": -49.1836210861206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.481509685516357, "step": 14000}
{"episode_reward": 27.109963296647408, "episode": 15.0, "batch_reward": 0.0591291880402714, "critic_loss": 0.40422552347183227, "actor_loss": -49.23877121734619, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.629480600357056, "step": 15000}
{"episode_reward": 4.708024809647347, "episode": 16.0, "batch_reward": 0.05810407605022192, "critic_loss": 0.47265021803975105, "actor_loss": -47.21677822113037, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.079371690750122, "step": 16000}
{"episode_reward": 175.7728329488879, "episode": 17.0, "batch_reward": 0.06526584832929075, "critic_loss": 0.5330186620950699, "actor_loss": -45.601719959259036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.109983921051025, "step": 17000}
{"episode_reward": 58.82739256493002, "episode": 18.0, "batch_reward": 0.06362932819128037, "critic_loss": 0.4759880509823561, "actor_loss": -42.575180961608886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.483619451522827, "step": 18000}
{"episode_reward": 9.83669351825479, "episode": 19.0, "batch_reward": 0.06489039436541498, "critic_loss": 0.6592762912213802, "actor_loss": -41.34422280883789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.106358528137207, "step": 19000}
{"episode_reward": 174.52300011114787, "episode": 20.0, "batch_reward": 0.07141927444562315, "critic_loss": 0.8044310097694397, "actor_loss": -40.8463747177124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.45432138442993, "step": 20000}
{"episode_reward": 181.38729634610743, "episode": 21.0, "batch_reward": 0.07191747813671827, "critic_loss": 1.057035591006279, "actor_loss": -38.607980884552, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.23733901977539, "step": 21000}
{"episode_reward": 32.301637379331254, "episode": 22.0, "batch_reward": 0.07215079495683313, "critic_loss": 1.1583932922482492, "actor_loss": -41.106955249786374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.307405471801758, "step": 22000}
{"episode_reward": 101.32435339165282, "episode": 23.0, "batch_reward": 0.07692787026241421, "critic_loss": 1.2178757395744324, "actor_loss": -40.79372952270508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.469576358795166, "step": 23000}
{"episode_reward": 227.76900297831378, "episode": 24.0, "batch_reward": 0.08321073254942894, "critic_loss": 1.1123051680326461, "actor_loss": -40.86652868270874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.539324283599854, "step": 24000}
{"episode_reward": 300.3048736143175, "episode": 25.0, "batch_reward": 0.08761363494768738, "critic_loss": 0.9288489454984665, "actor_loss": -40.66107036209107, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.407867431640625, "step": 25000}
{"episode_reward": 52.09099335113835, "episode": 26.0, "batch_reward": 0.08913136703148485, "critic_loss": 0.8147830270826817, "actor_loss": -39.39991483306885, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.305847644805908, "step": 26000}
{"episode_reward": 143.04023835535727, "episode": 27.0, "batch_reward": 0.09345863375812768, "critic_loss": 0.841103767067194, "actor_loss": -37.5684181060791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.425729513168335, "step": 27000}
{"episode_reward": 290.9171617556108, "episode": 28.0, "batch_reward": 0.09734099832177162, "critic_loss": 0.8319577914178371, "actor_loss": -37.11962650680542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.780003547668457, "step": 28000}
{"episode_reward": 65.34673543077824, "episode": 29.0, "batch_reward": 0.09787779875472188, "critic_loss": 0.8746083586812019, "actor_loss": -35.879585983276364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.87234091758728, "step": 29000}
{"episode_reward": 316.5809778535638, "episode": 30.0, "batch_reward": 0.10276907644420862, "critic_loss": 0.9275426831543445, "actor_loss": -33.745055381774904, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.271949529647827, "step": 30000}
{"episode_reward": 33.51867993930427, "episode": 31.0, "batch_reward": 0.10314962495863438, "critic_loss": 0.9175357340574265, "actor_loss": -33.56852104949951, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.25884294509888, "step": 31000}
{"episode_reward": 284.39922726259374, "episode": 32.0, "batch_reward": 0.10693686469644308, "critic_loss": 0.7775674540996551, "actor_loss": -33.020258808135985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.288180351257324, "step": 32000}
{"episode_reward": 61.961402199020306, "episode": 33.0, "batch_reward": 0.10769735890626907, "critic_loss": 0.6869053881764412, "actor_loss": -32.080773902893064, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.949798583984375, "step": 33000}
{"episode_reward": 273.6644292264375, "episode": 34.0, "batch_reward": 0.1123663201034069, "critic_loss": 0.6193863449096679, "actor_loss": -30.744668087005614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22722840309143, "step": 34000}
{"episode_reward": 275.09089917195865, "episode": 35.0, "batch_reward": 0.11550399394333363, "critic_loss": 0.594322542116046, "actor_loss": -30.74952222061157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5441792011261, "step": 35000}
{"episode_reward": 129.3925374333439, "episode": 36.0, "batch_reward": 0.11685994438827038, "critic_loss": 0.5239220007359982, "actor_loss": -30.170165130615235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.075494527816772, "step": 36000}
{"episode_reward": 310.6311070088831, "episode": 37.0, "batch_reward": 0.12318893087655305, "critic_loss": 0.5033337450921536, "actor_loss": -29.416368194580077, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.975404977798462, "step": 37000}
{"episode_reward": 395.3659104951405, "episode": 38.0, "batch_reward": 0.12888825063407422, "critic_loss": 0.47417824935913083, "actor_loss": -29.430182529449464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.46109104156494, "step": 38000}
{"episode_reward": 310.6621774358613, "episode": 39.0, "batch_reward": 0.13672666043043136, "critic_loss": 0.479339370906353, "actor_loss": -29.183359867095948, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.98448920249939, "step": 39000}
{"episode_reward": 454.61172161825033, "episode": 40.0, "batch_reward": 0.1430818919762969, "critic_loss": 0.4488525604456663, "actor_loss": -28.815040252685545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.975910425186157, "step": 40000}
{"episode_reward": 393.3568993345453, "episode": 41.0, "batch_reward": 0.1504845240712166, "critic_loss": 0.4240909865647554, "actor_loss": -28.09901657485962, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.28991746902466, "step": 41000}
{"episode_reward": 264.3655396928896, "episode": 42.0, "batch_reward": 0.15368913480639457, "critic_loss": 0.44384351222217083, "actor_loss": -28.267435722351074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.297765493392944, "step": 42000}
{"episode_reward": 518.9855267511884, "episode": 43.0, "batch_reward": 0.16130466847866773, "critic_loss": 0.4159501864016056, "actor_loss": -28.433335163116457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.429514169692993, "step": 43000}
{"episode_reward": 420.1342931631074, "episode": 44.0, "batch_reward": 0.16573423059284687, "critic_loss": 0.3986097982674837, "actor_loss": -28.335989170074463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.713923931121826, "step": 44000}
{"episode_reward": 296.0692973941694, "episode": 45.0, "batch_reward": 0.16967641789466142, "critic_loss": 0.40915583741664885, "actor_loss": -27.958040878295897, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10948657989502, "step": 45000}
{"episode_reward": 352.6858240265904, "episode": 46.0, "batch_reward": 0.17359721413999796, "critic_loss": 0.4483130623847246, "actor_loss": -27.870608417510986, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.668832063674927, "step": 46000}
{"episode_reward": 433.30111363828456, "episode": 47.0, "batch_reward": 0.18086564202606678, "critic_loss": 0.44703308971226213, "actor_loss": -27.905839797973634, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.232429027557373, "step": 47000}
{"episode_reward": 498.8978394830799, "episode": 48.0, "batch_reward": 0.18745338141918183, "critic_loss": 0.45788447469472887, "actor_loss": -28.087698040008544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.259069204330444, "step": 48000}
{"episode_reward": 471.88487094911386, "episode": 49.0, "batch_reward": 0.19131152707338334, "critic_loss": 0.4637050121873617, "actor_loss": -27.97232230758667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.174986124038696, "step": 49000}
{"episode_reward": 205.92639290926027, "episode": 50.0, "batch_reward": 0.19441628690063953, "critic_loss": 0.4517329247742891, "actor_loss": -28.016486183166503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.200987339019775, "step": 50000}
{"episode_reward": 549.3442251222845, "episode": 51.0, "batch_reward": 0.19837813560664655, "critic_loss": 0.49048319889605047, "actor_loss": -27.900263916015625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.995190382003784, "step": 51000}
{"episode_reward": 190.1960300554342, "episode": 52.0, "batch_reward": 0.20009584566950797, "critic_loss": 0.4887702359855175, "actor_loss": -27.861040367126463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.23760676383972, "step": 52000}
{"episode_reward": 423.750411901018, "episode": 53.0, "batch_reward": 0.20345674678683281, "critic_loss": 0.48694962984323503, "actor_loss": -27.70047585296631, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.989732027053833, "step": 53000}
{"episode_reward": 512.3267743441669, "episode": 54.0, "batch_reward": 0.21051794840395452, "critic_loss": 0.5018447836041451, "actor_loss": -28.055178707122803, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.08685564994812, "step": 54000}
{"episode_reward": 442.61001734261055, "episode": 55.0, "batch_reward": 0.21457895740866662, "critic_loss": 0.49233210986852644, "actor_loss": -28.01160414505005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.216528177261353, "step": 55000}
{"episode_reward": 328.50420630903596, "episode": 56.0, "batch_reward": 0.21516560335457324, "critic_loss": 0.5254060719907284, "actor_loss": -27.910940338134765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.976512670516968, "step": 56000}
{"episode_reward": 425.47300800896784, "episode": 57.0, "batch_reward": 0.22084224212169648, "critic_loss": 0.5268991178274155, "actor_loss": -27.975016578674317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.78278088569641, "step": 57000}
{"episode_reward": 486.6617085154658, "episode": 58.0, "batch_reward": 0.224345100030303, "critic_loss": 0.5546303811520338, "actor_loss": -28.01716848373413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.284740209579468, "step": 58000}
{"episode_reward": 244.92310064503226, "episode": 59.0, "batch_reward": 0.22609378680586814, "critic_loss": 0.5843071651756764, "actor_loss": -28.27469992828369, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.194518089294434, "step": 59000}
{"episode_reward": 504.62937584936446, "episode": 60.0, "batch_reward": 0.2299205935895443, "critic_loss": 0.5785826119184494, "actor_loss": -28.09294686126709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.052982807159424, "step": 60000}
{"episode_reward": 538.4905961404241, "episode": 61.0, "batch_reward": 0.23711686736345292, "critic_loss": 0.5800927732884884, "actor_loss": -28.730312881469725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.06847929954529, "step": 61000}
{"episode_reward": 523.2301470947722, "episode": 62.0, "batch_reward": 0.24109737779200077, "critic_loss": 0.6109623294472695, "actor_loss": -28.47335219192505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.25849175453186, "step": 62000}
{"episode_reward": 556.0146100578179, "episode": 63.0, "batch_reward": 0.24565496276319027, "critic_loss": 0.6298916756212711, "actor_loss": -29.231319816589355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.26770281791687, "step": 63000}
{"episode_reward": 567.1798402095455, "episode": 64.0, "batch_reward": 0.2518671938478947, "critic_loss": 0.6413337927758693, "actor_loss": -29.15431030654907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.30036425590515, "step": 64000}
{"episode_reward": 531.1548893177321, "episode": 65.0, "batch_reward": 0.25490950368344784, "critic_loss": 0.6342814834713936, "actor_loss": -29.251660179138185, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.36730670928955, "step": 65000}
{"episode_reward": 515.0820360384489, "episode": 66.0, "batch_reward": 0.2582681982964277, "critic_loss": 0.6443431084156036, "actor_loss": -29.403549842834472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.15086579322815, "step": 66000}
{"episode_reward": 525.0038106053121, "episode": 67.0, "batch_reward": 0.26306319393217564, "critic_loss": 0.6494391983151436, "actor_loss": -29.164271377563477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.450369119644165, "step": 67000}
{"episode_reward": 467.0569341862175, "episode": 68.0, "batch_reward": 0.2661559325903654, "critic_loss": 0.6813563748598098, "actor_loss": -29.827518798828127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.269482374191284, "step": 68000}
{"episode_reward": 576.412554530594, "episode": 69.0, "batch_reward": 0.2697818624675274, "critic_loss": 0.7309884476959705, "actor_loss": -30.404874031066896, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.08724546432495, "step": 69000}
{"episode_reward": 581.4749456320537, "episode": 70.0, "batch_reward": 0.2751021044850349, "critic_loss": 0.7656245226860047, "actor_loss": -30.190721809387206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.12304449081421, "step": 70000}
{"episode_reward": 510.7313477278926, "episode": 71.0, "batch_reward": 0.2782261097729206, "critic_loss": 0.7516408290565014, "actor_loss": -30.374433250427245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.421252965927124, "step": 71000}
{"episode_reward": 564.7847120589392, "episode": 72.0, "batch_reward": 0.2824357537776232, "critic_loss": 0.7590787678658962, "actor_loss": -30.935752552032472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.111407995224, "step": 72000}
{"episode_reward": 437.60322454662565, "episode": 73.0, "batch_reward": 0.28512433721125124, "critic_loss": 0.7498111414313317, "actor_loss": -30.80416801452637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.39239263534546, "step": 73000}
{"episode_reward": 467.8046055290529, "episode": 74.0, "batch_reward": 0.28584971505403517, "critic_loss": 0.7077741974592209, "actor_loss": -30.861718715667724, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.187492609024048, "step": 74000}
{"episode_reward": 553.2891783191003, "episode": 75.0, "batch_reward": 0.28925227768719197, "critic_loss": 0.6753184615969657, "actor_loss": -31.411606872558593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.96679711341858, "step": 75000}
{"episode_reward": 571.4874563356884, "episode": 76.0, "batch_reward": 0.29458449681103227, "critic_loss": 0.6710046276450157, "actor_loss": -31.526937049865722, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.572243213653564, "step": 76000}
{"episode_reward": 579.813835365664, "episode": 77.0, "batch_reward": 0.29776309382915495, "critic_loss": 0.6520279132127762, "actor_loss": -31.343150329589843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.33164143562317, "step": 77000}
{"episode_reward": 560.307866917112, "episode": 78.0, "batch_reward": 0.3009123874157667, "critic_loss": 0.6356632281839848, "actor_loss": -31.601886936187743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.055634021759033, "step": 78000}
{"episode_reward": 564.7225537324973, "episode": 79.0, "batch_reward": 0.3049107660651207, "critic_loss": 0.6089964931607247, "actor_loss": -31.664226791381836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.449130535125732, "step": 79000}
{"episode_reward": 569.4793092991139, "episode": 80.0, "batch_reward": 0.30722581292688844, "critic_loss": 0.596208521515131, "actor_loss": -31.719070465087892, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.902772665023804, "step": 80000}
{"episode_reward": 538.6876006662862, "episode": 81.0, "batch_reward": 0.3105347976386547, "critic_loss": 0.6192371759712696, "actor_loss": -31.934334518432618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.1863739490509, "step": 81000}
{"episode_reward": 518.8823197886882, "episode": 82.0, "batch_reward": 0.31272862961888315, "critic_loss": 0.602201760455966, "actor_loss": -32.73719641494751, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.30202579498291, "step": 82000}
{"episode_reward": 583.6143453516233, "episode": 83.0, "batch_reward": 0.3169179558455944, "critic_loss": 0.598749531686306, "actor_loss": -32.15255039215088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.407624006271362, "step": 83000}
{"episode_reward": 652.1288460125928, "episode": 84.0, "batch_reward": 0.3209043973982334, "critic_loss": 0.5814485029578209, "actor_loss": -33.0395915107727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.067314386367798, "step": 84000}
{"episode_reward": 587.4168944097501, "episode": 85.0, "batch_reward": 0.32361139392852784, "critic_loss": 0.6136128206253052, "actor_loss": -33.12613816833496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.836271286010742, "step": 85000}
{"episode_reward": 578.5747844072142, "episode": 86.0, "batch_reward": 0.3274062354564667, "critic_loss": 0.6008294368684292, "actor_loss": -33.362867588043216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.978253602981567, "step": 86000}
{"episode_reward": 438.16473455614073, "episode": 87.0, "batch_reward": 0.32821642589569094, "critic_loss": 0.6103280745744705, "actor_loss": -32.96980629730225, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.17675542831421, "step": 87000}
{"episode_reward": 550.760942685522, "episode": 88.0, "batch_reward": 0.32972153905034063, "critic_loss": 0.6316537584960461, "actor_loss": -33.6698316078186, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21602463722229, "step": 88000}
{"episode_reward": 479.4391291326643, "episode": 89.0, "batch_reward": 0.33304844734072686, "critic_loss": 0.6507582560479641, "actor_loss": -33.912814819335935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.129475355148315, "step": 89000}
{"episode_reward": 363.58909318327227, "episode": 90.0, "batch_reward": 0.3332344394624233, "critic_loss": 0.6799999090433121, "actor_loss": -33.72248817062378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.002500295639038, "step": 90000}
{"episode_reward": 538.1943242973764, "episode": 91.0, "batch_reward": 0.3352396229505539, "critic_loss": 0.6792472974061966, "actor_loss": -34.05765323257446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.430975914001465, "step": 91000}
{"episode_reward": 589.1647946516849, "episode": 92.0, "batch_reward": 0.33856952461600304, "critic_loss": 0.7185565272569656, "actor_loss": -34.00741512680054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.35150456428528, "step": 92000}
{"episode_reward": 630.7084026749264, "episode": 93.0, "batch_reward": 0.34041691464185714, "critic_loss": 0.7343703685700893, "actor_loss": -34.30600620269775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.939531087875366, "step": 93000}
{"episode_reward": 560.8688944987413, "episode": 94.0, "batch_reward": 0.34413464653491976, "critic_loss": 0.7126237083673477, "actor_loss": -34.68996876525879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.064181089401245, "step": 94000}
{"episode_reward": 617.5058502133335, "episode": 95.0, "batch_reward": 0.34672590127587316, "critic_loss": 0.7335391052663326, "actor_loss": -34.19967746734619, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.468979597091675, "step": 95000}
{"episode_reward": 601.9871680857375, "episode": 96.0, "batch_reward": 0.35004530793428423, "critic_loss": 0.7297098744809628, "actor_loss": -35.032606296539306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.141090393066406, "step": 96000}
{"episode_reward": 593.3426944751441, "episode": 97.0, "batch_reward": 0.3503912070989609, "critic_loss": 0.6827738876342774, "actor_loss": -34.85163726043701, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.31465721130371, "step": 97000}
{"episode_reward": 529.7323007553806, "episode": 98.0, "batch_reward": 0.35276479053497317, "critic_loss": 0.7179324718415737, "actor_loss": -34.296311309814456, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.245078325271606, "step": 98000}
{"episode_reward": 573.4519979744256, "episode": 99.0, "batch_reward": 0.35592464593052864, "critic_loss": 0.6970938681662082, "actor_loss": -35.18775740432739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.94749426841736, "step": 99000}
{"episode_reward": 579.0619509062691, "episode": 100.0, "batch_reward": 0.3583755097985268, "critic_loss": 0.7110053430199623, "actor_loss": -35.256498043060304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.13308596611023, "step": 100000}
{"episode_reward": 629.3243170920354, "episode": 101.0, "batch_reward": 0.36027244809269904, "critic_loss": 0.7401342852413655, "actor_loss": -35.853242572784424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.833019733428955, "step": 101000}
{"episode_reward": 401.4112938278088, "episode": 102.0, "batch_reward": 0.361479553937912, "critic_loss": 0.783108244150877, "actor_loss": -35.107780570983884, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.326607704162598, "step": 102000}
{"episode_reward": 608.2370317998115, "episode": 103.0, "batch_reward": 0.3618327210843563, "critic_loss": 0.7498128761947155, "actor_loss": -35.25624056243897, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.237685441970825, "step": 103000}
{"episode_reward": 599.6274957861208, "episode": 104.0, "batch_reward": 0.36573511618375776, "critic_loss": 0.7583928154408932, "actor_loss": -35.7752776222229, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.918857097625732, "step": 104000}
{"episode_reward": 614.9620033455105, "episode": 105.0, "batch_reward": 0.36863176479935644, "critic_loss": 0.767809124827385, "actor_loss": -36.10900007247925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.390485286712646, "step": 105000}
{"episode_reward": 654.3062739245731, "episode": 106.0, "batch_reward": 0.37006749418377877, "critic_loss": 0.7144046413600444, "actor_loss": -36.1735671043396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.544711112976074, "step": 106000}
{"episode_reward": 528.3457562552876, "episode": 107.0, "batch_reward": 0.3725373423099518, "critic_loss": 0.6736927407979966, "actor_loss": -36.56603223800659, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.835981130599976, "step": 107000}
{"episode_reward": 586.0495159190554, "episode": 108.0, "batch_reward": 0.37340986958146094, "critic_loss": 0.6592777802348136, "actor_loss": -36.037770774841306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16603994369507, "step": 108000}
{"episode_reward": 611.1013754888503, "episode": 109.0, "batch_reward": 0.37706889897584916, "critic_loss": 0.6556427054703236, "actor_loss": -36.826370807647706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.02202081680298, "step": 109000}
{"episode_reward": 675.4367585640114, "episode": 110.0, "batch_reward": 0.3793370515406132, "critic_loss": 0.6409209082424641, "actor_loss": -36.42199570846557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.770686149597168, "step": 110000}
{"episode_reward": 397.9181957320268, "episode": 111.0, "batch_reward": 0.37907473772764205, "critic_loss": 0.6355829780995845, "actor_loss": -36.78135439300537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.94522500038147, "step": 111000}
{"episode_reward": 555.5544507370133, "episode": 112.0, "batch_reward": 0.38009358847141267, "critic_loss": 0.6450144671499729, "actor_loss": -36.51901372909546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.57858395576477, "step": 112000}
{"episode_reward": 584.7456908798596, "episode": 113.0, "batch_reward": 0.3807158313691616, "critic_loss": 0.6515944356918335, "actor_loss": -36.96815489578247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.023564338684082, "step": 113000}
{"episode_reward": 52.78763313117062, "episode": 114.0, "batch_reward": 0.38075978475809097, "critic_loss": 0.6747295793890953, "actor_loss": -36.613430854797365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.159139394760132, "step": 114000}
{"episode_reward": 649.8659920769965, "episode": 115.0, "batch_reward": 0.3821490662693977, "critic_loss": 0.6703432447314263, "actor_loss": -36.67666859436035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.905110359191895, "step": 115000}
{"episode_reward": 639.7088957823855, "episode": 116.0, "batch_reward": 0.3850803954601288, "critic_loss": 0.6522062404453755, "actor_loss": -37.10852806854248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.47539782524109, "step": 116000}
{"episode_reward": 602.11514582544, "episode": 117.0, "batch_reward": 0.38604491779208183, "critic_loss": 0.670888922572136, "actor_loss": -37.3451720123291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.27780795097351, "step": 117000}
{"episode_reward": 181.5262287199466, "episode": 118.0, "batch_reward": 0.3846961563825607, "critic_loss": 0.6798765866458416, "actor_loss": -37.29030251693725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.37264394760132, "step": 118000}
{"episode_reward": 529.78952898247, "episode": 119.0, "batch_reward": 0.3855265453159809, "critic_loss": 0.6986491255164147, "actor_loss": -37.460129570007325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.6997230052948, "step": 119000}
{"episode_reward": 521.3862631411702, "episode": 120.0, "batch_reward": 0.3864935774207115, "critic_loss": 0.7307658481895923, "actor_loss": -37.439437004089356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.248359203338623, "step": 120000}
{"episode_reward": 561.3351277589408, "episode": 121.0, "batch_reward": 0.38864417612552643, "critic_loss": 0.7330922320783139, "actor_loss": -37.664001041412355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.61433720588684, "step": 121000}
{"episode_reward": 623.0537433345208, "episode": 122.0, "batch_reward": 0.38961227384209635, "critic_loss": 0.7281368908584118, "actor_loss": -37.42345176696777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.630903720855713, "step": 122000}
{"episode_reward": 614.6139517991362, "episode": 123.0, "batch_reward": 0.3926625447273254, "critic_loss": 0.7351698778867721, "actor_loss": -37.6738180885315, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.51458239555359, "step": 123000}
{"episode_reward": 654.7747891715031, "episode": 124.0, "batch_reward": 0.39460898339748385, "critic_loss": 0.7112225834429264, "actor_loss": -37.86293589401245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.979427337646484, "step": 124000}
{"episode_reward": 568.1180525081799, "episode": 125.0, "batch_reward": 0.3950457107424736, "critic_loss": 0.7092514472901821, "actor_loss": -37.79104876327515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.428377389907837, "step": 125000}
{"episode_reward": 632.5494674648628, "episode": 126.0, "batch_reward": 0.3973608124256134, "critic_loss": 0.7063924762904644, "actor_loss": -38.02428010177612, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.779696702957153, "step": 126000}
{"episode_reward": 601.5277679855521, "episode": 127.0, "batch_reward": 0.3989097546339035, "critic_loss": 0.6798326908349991, "actor_loss": -37.706792079925535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.09674310684204, "step": 127000}
{"episode_reward": 625.7327899541723, "episode": 128.0, "batch_reward": 0.40203325977921484, "critic_loss": 0.6959109714329242, "actor_loss": -38.49805029296875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.839412689208984, "step": 128000}
{"episode_reward": 650.8612358415405, "episode": 129.0, "batch_reward": 0.40321800467371943, "critic_loss": 0.6893593199253082, "actor_loss": -38.567381465911865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.91167187690735, "step": 129000}
{"episode_reward": 604.2637207198671, "episode": 130.0, "batch_reward": 0.4047219087481499, "critic_loss": 0.6970580865740776, "actor_loss": -38.685707195281985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21804118156433, "step": 130000}
{"episode_reward": 585.3372065279051, "episode": 131.0, "batch_reward": 0.4062907451689243, "critic_loss": 0.7177342768907548, "actor_loss": -39.099536235809325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.45255136489868, "step": 131000}
{"episode_reward": 574.7298776124688, "episode": 132.0, "batch_reward": 0.40670953929424286, "critic_loss": 0.7397451379597187, "actor_loss": -38.971148178100584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.07588481903076, "step": 132000}
{"episode_reward": 585.7157772628, "episode": 133.0, "batch_reward": 0.40918159556388856, "critic_loss": 0.7385470044910908, "actor_loss": -39.413643966674805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.340372562408447, "step": 133000}
{"episode_reward": 641.148990608467, "episode": 134.0, "batch_reward": 0.4088509539067745, "critic_loss": 0.7471678225696087, "actor_loss": -39.035421257019046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.123804807662964, "step": 134000}
{"episode_reward": 561.2784157654264, "episode": 135.0, "batch_reward": 0.40999051281809806, "critic_loss": 0.7510955394208432, "actor_loss": -38.826408290863036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.361035585403442, "step": 135000}
{"episode_reward": 219.2840117311506, "episode": 136.0, "batch_reward": 0.4101517457664013, "critic_loss": 0.7396788814067841, "actor_loss": -39.20143278884888, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.164787769317627, "step": 136000}
{"episode_reward": 490.4641860427369, "episode": 137.0, "batch_reward": 0.41146460074186325, "critic_loss": 0.7594952763319015, "actor_loss": -38.909494647979734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16104817390442, "step": 137000}
{"episode_reward": 550.0852503403243, "episode": 138.0, "batch_reward": 0.4121328100860119, "critic_loss": 0.7796663729250431, "actor_loss": -39.012320880889895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.20111083984375, "step": 138000}
{"episode_reward": 610.7579828906843, "episode": 139.0, "batch_reward": 0.4136339931488037, "critic_loss": 0.7389717716574669, "actor_loss": -39.51864793395996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.324932098388672, "step": 139000}
{"episode_reward": 633.0561110382259, "episode": 140.0, "batch_reward": 0.41377644324302676, "critic_loss": 0.747596645116806, "actor_loss": -39.44193323135376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.099367141723633, "step": 140000}
{"episode_reward": 612.6968399797302, "episode": 141.0, "batch_reward": 0.41715537106990813, "critic_loss": 0.7766411364078522, "actor_loss": -39.56011169052124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.36199402809143, "step": 141000}
{"episode_reward": 633.2061752913891, "episode": 142.0, "batch_reward": 0.418023674428463, "critic_loss": 0.7624665921032429, "actor_loss": -39.69040263748169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.1267192363739, "step": 142000}
{"episode_reward": 631.9543080193229, "episode": 143.0, "batch_reward": 0.41957677122950554, "critic_loss": 0.7701079280376434, "actor_loss": -39.90822175979614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.296666145324707, "step": 143000}
{"episode_reward": 618.4640159400004, "episode": 144.0, "batch_reward": 0.4209520364403725, "critic_loss": 0.8092930230796337, "actor_loss": -39.845704883575436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.198381185531616, "step": 144000}
{"episode_reward": 673.1221410188836, "episode": 145.0, "batch_reward": 0.4222863742113113, "critic_loss": 0.800225586682558, "actor_loss": -39.94640154647827, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.81035542488098, "step": 145000}
{"episode_reward": 620.3176435851137, "episode": 146.0, "batch_reward": 0.4220269027650356, "critic_loss": 0.8145075190961361, "actor_loss": -40.16765684890747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.77739381790161, "step": 146000}
{"episode_reward": 78.48928259198307, "episode": 147.0, "batch_reward": 0.42031964483857154, "critic_loss": 0.7886661892533302, "actor_loss": -40.14032358551025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.744052410125732, "step": 147000}
{"episode_reward": 607.4036440022302, "episode": 148.0, "batch_reward": 0.42343684417009353, "critic_loss": 0.8163190167248249, "actor_loss": -40.199925075531006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.101006031036377, "step": 148000}
{"episode_reward": 686.0815765698018, "episode": 149.0, "batch_reward": 0.4244561296701431, "critic_loss": 0.8118251205980778, "actor_loss": -40.45253131484986, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.119187593460083, "step": 149000}
{"episode_reward": 633.012212014492, "episode": 150.0, "batch_reward": 0.42579766097664834, "critic_loss": 0.8108620758652687, "actor_loss": -40.03793882369995, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
