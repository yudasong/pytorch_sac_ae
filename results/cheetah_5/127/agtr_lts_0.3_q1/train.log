{"episode_reward": 0.0, "episode": 1.0, "duration": 18.72674584388733, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.5024428367614746, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.27002688570096517, "critic_loss": 0.5885527366278529, "actor_loss": -40.52872446586056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.66584587097168, "step": 3000}
{"episode_reward": 187.48593357461365, "episode": 4.0, "batch_reward": 0.22334842087328435, "critic_loss": 0.7755444361269475, "actor_loss": -36.18933714294434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.99426293373108, "step": 4000}
{"episode_reward": 37.33278202148678, "episode": 5.0, "batch_reward": 0.17490809112787248, "critic_loss": 0.6937693364918232, "actor_loss": -33.616495960235596, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.84496521949768, "step": 5000}
{"episode_reward": 5.1999763339970615, "episode": 6.0, "batch_reward": 0.1423678490743041, "critic_loss": 0.5865879183709621, "actor_loss": -33.444280342102054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.885897874832153, "step": 6000}
{"episode_reward": 4.427563176732573, "episode": 7.0, "batch_reward": 0.12202509465813637, "critic_loss": 0.5790785339474678, "actor_loss": -33.739391635894776, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.173065662384033, "step": 7000}
{"episode_reward": 3.1079121259409597, "episode": 8.0, "batch_reward": 0.10623190779611469, "critic_loss": 0.43656721456348896, "actor_loss": -33.059273723602296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.638134479522705, "step": 8000}
{"episode_reward": 2.8335297513154467, "episode": 9.0, "batch_reward": 0.09360048596933485, "critic_loss": 0.35702937276661395, "actor_loss": -32.381306442260744, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.719786643981934, "step": 9000}
{"episode_reward": 3.864304506532629, "episode": 10.0, "batch_reward": 0.08465655950829387, "critic_loss": 0.31983960354328156, "actor_loss": -31.794788822174073, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.063955783843994, "step": 10000}
{"episode_reward": 1.6763067687546325, "episode": 11.0, "batch_reward": 0.07770417120307684, "critic_loss": 0.26982016502320766, "actor_loss": -30.87490732574463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.63034248352051, "step": 11000}
{"episode_reward": 10.097664071877862, "episode": 12.0, "batch_reward": 0.07033754703961313, "critic_loss": 0.23464229223877192, "actor_loss": -29.973334194183348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.454907417297363, "step": 12000}
{"episode_reward": 6.513505668964049, "episode": 13.0, "batch_reward": 0.06561965130642057, "critic_loss": 0.2165241080969572, "actor_loss": -29.44372137069702, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.54520082473755, "step": 13000}
{"episode_reward": 6.69017773455454, "episode": 14.0, "batch_reward": 0.07310193102806807, "critic_loss": 0.3555687199756503, "actor_loss": -29.181707271575927, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.45383358001709, "step": 14000}
{"episode_reward": 347.99029118934834, "episode": 15.0, "batch_reward": 0.08674558309838176, "critic_loss": 0.41393860502541063, "actor_loss": -29.225913410186767, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.932122468948364, "step": 15000}
{"episode_reward": 130.53859775690574, "episode": 16.0, "batch_reward": 0.08357496993988753, "critic_loss": 0.302182783678174, "actor_loss": -28.176567558288575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.793312549591064, "step": 16000}
{"episode_reward": 8.064033701701126, "episode": 17.0, "batch_reward": 0.07964963255450129, "critic_loss": 0.2412914466112852, "actor_loss": -27.982592014312743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.744203090667725, "step": 17000}
{"episode_reward": 6.354066286114002, "episode": 18.0, "batch_reward": 0.07587679427489638, "critic_loss": 0.2028762666657567, "actor_loss": -27.606714805603026, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.34182572364807, "step": 18000}
{"episode_reward": 5.82294766018125, "episode": 19.0, "batch_reward": 0.07193275910243392, "critic_loss": 0.18035760819911956, "actor_loss": -27.024176239013673, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.035974740982056, "step": 19000}
{"episode_reward": 6.589550083495984, "episode": 20.0, "batch_reward": 0.06877596407011151, "critic_loss": 0.17485649731382727, "actor_loss": -26.404127254486085, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.818978786468506, "step": 20000}
{"episode_reward": 15.194530030911634, "episode": 21.0, "batch_reward": 0.06889059430360794, "critic_loss": 0.2325385710373521, "actor_loss": -25.728724662780763, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.81147861480713, "step": 21000}
{"episode_reward": 231.0572134999662, "episode": 22.0, "batch_reward": 0.07344119211658835, "critic_loss": 0.2419480702802539, "actor_loss": -25.389207176208497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.376317262649536, "step": 22000}
{"episode_reward": 6.183898121000184, "episode": 23.0, "batch_reward": 0.07293702030926943, "critic_loss": 0.30435630317032336, "actor_loss": -24.45720299911499, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.34459662437439, "step": 23000}
{"episode_reward": 72.05374660918095, "episode": 24.0, "batch_reward": 0.07084701810032129, "critic_loss": 0.34784578284621237, "actor_loss": -23.548452304840087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.487276077270508, "step": 24000}
{"episode_reward": 39.28135805862546, "episode": 25.0, "batch_reward": 0.07182839930430054, "critic_loss": 0.4920460594892502, "actor_loss": -23.053495235443116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.453991651535034, "step": 25000}
{"episode_reward": 68.83807926941991, "episode": 26.0, "batch_reward": 0.07059974800422787, "critic_loss": 0.4298552732765675, "actor_loss": -22.753657981872557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988320350646973, "step": 26000}
{"episode_reward": 47.01134690905258, "episode": 27.0, "batch_reward": 0.0688009699061513, "critic_loss": 0.35404530525207517, "actor_loss": -22.030365592956542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.888506174087524, "step": 27000}
{"episode_reward": 23.193415333652318, "episode": 28.0, "batch_reward": 0.06989928955584765, "critic_loss": 0.33055358749628067, "actor_loss": -21.449887077331542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.635565519332886, "step": 28000}
{"episode_reward": 130.38560719509334, "episode": 29.0, "batch_reward": 0.0716308065392077, "critic_loss": 0.32160173887014387, "actor_loss": -20.866395572662352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51712703704834, "step": 29000}
{"episode_reward": 111.29761254741192, "episode": 30.0, "batch_reward": 0.07657191578298807, "critic_loss": 0.3245530728250742, "actor_loss": -20.413897304534913, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.948212146759033, "step": 30000}
{"episode_reward": 375.9972369507055, "episode": 31.0, "batch_reward": 0.08437705252692103, "critic_loss": 0.37071231013536454, "actor_loss": -20.560438957214355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.36428380012512, "step": 31000}
{"episode_reward": 241.37821951286543, "episode": 32.0, "batch_reward": 0.0884181365892291, "critic_loss": 0.411633367985487, "actor_loss": -20.368530637741088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.143975734710693, "step": 32000}
{"episode_reward": 103.26748935736792, "episode": 33.0, "batch_reward": 0.08910621533170343, "critic_loss": 0.4006059910207987, "actor_loss": -20.109127265930177, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.94508934020996, "step": 33000}
{"episode_reward": 140.93218002120992, "episode": 34.0, "batch_reward": 0.09239169790223241, "critic_loss": 0.3703730913996697, "actor_loss": -19.795137998580934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.94794774055481, "step": 34000}
{"episode_reward": 364.5983908754153, "episode": 35.0, "batch_reward": 0.09972417408227921, "critic_loss": 0.43640790313482286, "actor_loss": -20.23464253616333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.576586723327637, "step": 35000}
{"episode_reward": 213.51741480398456, "episode": 36.0, "batch_reward": 0.10382757820934058, "critic_loss": 0.3861200536042452, "actor_loss": -20.118711872100832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.39643955230713, "step": 36000}
{"episode_reward": 357.4901791361849, "episode": 37.0, "batch_reward": 0.1096617892831564, "critic_loss": 0.3695162636041641, "actor_loss": -20.151020193099974, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.80816960334778, "step": 37000}
{"episode_reward": 165.30696929342804, "episode": 38.0, "batch_reward": 0.11229322707653046, "critic_loss": 0.36711288039386275, "actor_loss": -19.927551429748537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.28355121612549, "step": 38000}
{"episode_reward": 269.59694622983494, "episode": 39.0, "batch_reward": 0.11688775843381882, "critic_loss": 0.39075410048663617, "actor_loss": -20.046412244796752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.642711639404297, "step": 39000}
{"episode_reward": 415.55567901618923, "episode": 40.0, "batch_reward": 0.12277229772508144, "critic_loss": 0.41785320292413236, "actor_loss": -19.884186170578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.637423753738403, "step": 40000}
{"episode_reward": 156.3066955937922, "episode": 41.0, "batch_reward": 0.12384964489936828, "critic_loss": 0.37585735994577407, "actor_loss": -19.595621824264526, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.539462089538574, "step": 41000}
{"episode_reward": 286.29752785979065, "episode": 42.0, "batch_reward": 0.12690323600918055, "critic_loss": 0.42119704404473307, "actor_loss": -19.76295018005371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.733705282211304, "step": 42000}
{"episode_reward": 119.78781733020844, "episode": 43.0, "batch_reward": 0.12865215396136045, "critic_loss": 0.43778417144715787, "actor_loss": -19.64318389129639, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.070335388183594, "step": 43000}
{"episode_reward": 395.4641926923019, "episode": 44.0, "batch_reward": 0.13486926981806754, "critic_loss": 0.4456845411360264, "actor_loss": -20.10727243232727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.96414017677307, "step": 44000}
{"episode_reward": 460.05393006377767, "episode": 45.0, "batch_reward": 0.1422861474081874, "critic_loss": 0.444468999132514, "actor_loss": -20.298833864212035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.232832431793213, "step": 45000}
{"episode_reward": 388.09736800862845, "episode": 46.0, "batch_reward": 0.14851212033629418, "critic_loss": 0.38864643016457556, "actor_loss": -20.39174595069885, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.840190410614014, "step": 46000}
{"episode_reward": 561.8002775726407, "episode": 47.0, "batch_reward": 0.1559278304502368, "critic_loss": 0.4197275266945362, "actor_loss": -20.592442644119263, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.48949408531189, "step": 47000}
{"episode_reward": 265.88528318206704, "episode": 48.0, "batch_reward": 0.15930523413419723, "critic_loss": 0.4343085847198963, "actor_loss": -20.58630366897583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.612869262695312, "step": 48000}
{"episode_reward": 439.15814299262337, "episode": 49.0, "batch_reward": 0.16557746678590773, "critic_loss": 0.3957211448699236, "actor_loss": -21.220961868286132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.962785720825195, "step": 49000}
{"episode_reward": 446.694430369497, "episode": 50.0, "batch_reward": 0.17074273223429917, "critic_loss": 0.41603221970796583, "actor_loss": -21.222218643188477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.814240217208862, "step": 50000}
{"episode_reward": 443.5680414581027, "episode": 51.0, "batch_reward": 0.17547491713613272, "critic_loss": 0.41027369660139085, "actor_loss": -21.563366539001464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.141860246658325, "step": 51000}
{"episode_reward": 458.699141606154, "episode": 52.0, "batch_reward": 0.18253284173458814, "critic_loss": 0.41480433847010134, "actor_loss": -21.885599800109862, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.477229118347168, "step": 52000}
{"episode_reward": 428.837944667318, "episode": 53.0, "batch_reward": 0.18366783300042153, "critic_loss": 0.43880431063473224, "actor_loss": -22.39463511276245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.479502201080322, "step": 53000}
{"episode_reward": 314.91276339149636, "episode": 54.0, "batch_reward": 0.18927810415625573, "critic_loss": 0.4263022982478142, "actor_loss": -22.723153247833253, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.526206970214844, "step": 54000}
{"episode_reward": 527.9455431338924, "episode": 55.0, "batch_reward": 0.19609028658270836, "critic_loss": 0.41737686744332314, "actor_loss": -23.244288436889647, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.186767578125, "step": 55000}
{"episode_reward": 510.33589264289003, "episode": 56.0, "batch_reward": 0.2008531181514263, "critic_loss": 0.3989679414182901, "actor_loss": -23.322565929412843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.5165536403656, "step": 56000}
{"episode_reward": 326.52259425533884, "episode": 57.0, "batch_reward": 0.20354746659100056, "critic_loss": 0.41160950730741025, "actor_loss": -23.517124008178712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.490678071975708, "step": 57000}
{"episode_reward": 533.989448763109, "episode": 58.0, "batch_reward": 0.21048273615539073, "critic_loss": 0.42926381893455984, "actor_loss": -24.079363399505617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.29915738105774, "step": 58000}
{"episode_reward": 635.9818297064571, "episode": 59.0, "batch_reward": 0.21664000369608402, "critic_loss": 0.43510560724139213, "actor_loss": -24.16264956665039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.573633909225464, "step": 59000}
{"episode_reward": 633.4874036407327, "episode": 60.0, "batch_reward": 0.2224655461013317, "critic_loss": 0.4499426535665989, "actor_loss": -24.80947053527832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.547792434692383, "step": 60000}
{"episode_reward": 428.3964584952278, "episode": 61.0, "batch_reward": 0.22610330326855183, "critic_loss": 0.4405382294803858, "actor_loss": -24.89056916809082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.815391063690186, "step": 61000}
{"episode_reward": 532.7507549806738, "episode": 62.0, "batch_reward": 0.23361188073456288, "critic_loss": 0.46174848851561545, "actor_loss": -25.560179485321044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.7077579498291, "step": 62000}
{"episode_reward": 519.6673922695221, "episode": 63.0, "batch_reward": 0.23681733597815036, "critic_loss": 0.45980990782380105, "actor_loss": -25.45004098510742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02389645576477, "step": 63000}
{"episode_reward": 582.1444437270122, "episode": 64.0, "batch_reward": 0.24345720501244067, "critic_loss": 0.43572728626430035, "actor_loss": -26.075982089996337, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.807750940322876, "step": 64000}
{"episode_reward": 660.5044602802395, "episode": 65.0, "batch_reward": 0.24838023729622363, "critic_loss": 0.44874215631186964, "actor_loss": -26.404204914093018, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.746865272521973, "step": 65000}
{"episode_reward": 406.663438356641, "episode": 66.0, "batch_reward": 0.2511390752196312, "critic_loss": 0.4546157293617725, "actor_loss": -26.51716775894165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.595528602600098, "step": 66000}
{"episode_reward": 600.3222888656329, "episode": 67.0, "batch_reward": 0.2574461203962565, "critic_loss": 0.45436566419899466, "actor_loss": -27.312629299163817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.300119638442993, "step": 67000}
{"episode_reward": 658.7445898649486, "episode": 68.0, "batch_reward": 0.2625227001309395, "critic_loss": 0.45012940126657486, "actor_loss": -27.26654842376709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.308444261550903, "step": 68000}
{"episode_reward": 546.8350296753359, "episode": 69.0, "batch_reward": 0.26519970533251763, "critic_loss": 0.4819113592505455, "actor_loss": -27.27342109680176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.54011368751526, "step": 69000}
{"episode_reward": 361.23741713757056, "episode": 70.0, "batch_reward": 0.2683463924229145, "critic_loss": 0.48784811656177046, "actor_loss": -27.71120400238037, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.38906717300415, "step": 70000}
{"episode_reward": 673.7514661022147, "episode": 71.0, "batch_reward": 0.27220614832639695, "critic_loss": 0.5067136498838664, "actor_loss": -27.862710521698, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.22513270378113, "step": 71000}
{"episode_reward": 298.8549453995774, "episode": 72.0, "batch_reward": 0.273445441365242, "critic_loss": 0.5390567395687104, "actor_loss": -27.788145431518554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.649215698242188, "step": 72000}
{"episode_reward": 626.0595841793901, "episode": 73.0, "batch_reward": 0.2796330400109291, "critic_loss": 0.5817811601161956, "actor_loss": -28.39661614227295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.334641933441162, "step": 73000}
{"episode_reward": 624.0738345577627, "episode": 74.0, "batch_reward": 0.2810207888782024, "critic_loss": 0.5875384041965008, "actor_loss": -28.468446300506592, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.695460557937622, "step": 74000}
{"episode_reward": 353.65997505468795, "episode": 75.0, "batch_reward": 0.28440263789892195, "critic_loss": 0.5555090496838093, "actor_loss": -28.55627158355713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.815863609313965, "step": 75000}
{"episode_reward": 656.0821816425668, "episode": 76.0, "batch_reward": 0.28941648931801317, "critic_loss": 0.5597645214796066, "actor_loss": -29.049103507995607, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.717915058135986, "step": 76000}
{"episode_reward": 566.9229239299754, "episode": 77.0, "batch_reward": 0.2934267109036446, "critic_loss": 0.5701298362612724, "actor_loss": -29.517735805511474, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.455509424209595, "step": 77000}
{"episode_reward": 577.9353311366273, "episode": 78.0, "batch_reward": 0.2973672771006823, "critic_loss": 0.5171292015165091, "actor_loss": -29.905396823883056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13739800453186, "step": 78000}
{"episode_reward": 641.6734053749487, "episode": 79.0, "batch_reward": 0.3017305437922478, "critic_loss": 0.5447615161836147, "actor_loss": -30.23899683380127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.267866134643555, "step": 79000}
{"episode_reward": 608.8489017835109, "episode": 80.0, "batch_reward": 0.30503254720568657, "critic_loss": 0.5358482146561145, "actor_loss": -30.599276847839356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.04871368408203, "step": 80000}
{"episode_reward": 612.3037878007548, "episode": 81.0, "batch_reward": 0.3090541715323925, "critic_loss": 0.5553362724930048, "actor_loss": -30.769511959075928, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.87156963348389, "step": 81000}
{"episode_reward": 695.1886077420048, "episode": 82.0, "batch_reward": 0.31286892519891263, "critic_loss": 0.5579227523207665, "actor_loss": -30.802927875518797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.29731822013855, "step": 82000}
{"episode_reward": 683.4804868938688, "episode": 83.0, "batch_reward": 0.31824010469019415, "critic_loss": 0.5262570199072361, "actor_loss": -31.603213920593262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.922932624816895, "step": 83000}
{"episode_reward": 661.9782019926178, "episode": 84.0, "batch_reward": 0.32241343703866004, "critic_loss": 0.5381006330847741, "actor_loss": -31.710422203063963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.87137770652771, "step": 84000}
{"episode_reward": 670.2060500542557, "episode": 85.0, "batch_reward": 0.3269666385948658, "critic_loss": 0.5383197178393603, "actor_loss": -32.16068577194214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.563756704330444, "step": 85000}
{"episode_reward": 689.1197135400303, "episode": 86.0, "batch_reward": 0.3311241022050381, "critic_loss": 0.5209934447705745, "actor_loss": -32.58872117614746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.33454394340515, "step": 86000}
{"episode_reward": 671.5100266880074, "episode": 87.0, "batch_reward": 0.3351884099543095, "critic_loss": 0.5158166953921318, "actor_loss": -32.92524279022217, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.708455562591553, "step": 87000}
{"episode_reward": 651.6668809975437, "episode": 88.0, "batch_reward": 0.3371342344284058, "critic_loss": 0.49794082617759705, "actor_loss": -32.65090929412842, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.564541339874268, "step": 88000}
{"episode_reward": 668.5900436937955, "episode": 89.0, "batch_reward": 0.34163233599066734, "critic_loss": 0.4915352308154106, "actor_loss": -33.105759391784666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.303258657455444, "step": 89000}
{"episode_reward": 690.4214757094323, "episode": 90.0, "batch_reward": 0.3468354139626026, "critic_loss": 0.47225213143229483, "actor_loss": -33.46980783843994, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88983178138733, "step": 90000}
{"episode_reward": 435.3214993599714, "episode": 91.0, "batch_reward": 0.3447663048505783, "critic_loss": 0.49783823782205583, "actor_loss": -33.25371500015259, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.12306046485901, "step": 91000}
{"episode_reward": 85.05867115674967, "episode": 92.0, "batch_reward": 0.3443658960163593, "critic_loss": 0.4977948239147663, "actor_loss": -33.48423643875122, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.46753978729248, "step": 92000}
{"episode_reward": 625.2274710925459, "episode": 93.0, "batch_reward": 0.34660953268408773, "critic_loss": 0.514594947397709, "actor_loss": -33.60292198181153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14012336730957, "step": 93000}
{"episode_reward": 631.3991982965186, "episode": 94.0, "batch_reward": 0.3510616811513901, "critic_loss": 0.5227116569578648, "actor_loss": -33.9707229347229, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.865187644958496, "step": 94000}
{"episode_reward": 638.0705619397608, "episode": 95.0, "batch_reward": 0.353702893525362, "critic_loss": 0.5383384528458118, "actor_loss": -34.444002605438236, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.25118899345398, "step": 95000}
{"episode_reward": 605.7253575675277, "episode": 96.0, "batch_reward": 0.3558611353337765, "critic_loss": 0.5702916965186596, "actor_loss": -34.238349765777585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.294073581695557, "step": 96000}
{"episode_reward": 572.2170076984135, "episode": 97.0, "batch_reward": 0.3575597051680088, "critic_loss": 0.5775942170023918, "actor_loss": -34.66309757614136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.016109943389893, "step": 97000}
{"episode_reward": 628.2947631264451, "episode": 98.0, "batch_reward": 0.35931964391469956, "critic_loss": 0.6189733865261078, "actor_loss": -34.941060707092284, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.402345180511475, "step": 98000}
{"episode_reward": 633.6808944920958, "episode": 99.0, "batch_reward": 0.3615738130807877, "critic_loss": 0.6221950432062149, "actor_loss": -34.96525957489013, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.507877826690674, "step": 99000}
{"episode_reward": 92.51152625421918, "episode": 100.0, "batch_reward": 0.3622878793478012, "critic_loss": 0.630907855540514, "actor_loss": -35.022037631988525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.281378507614136, "step": 100000}
{"episode_reward": 702.6528579275015, "episode": 101.0, "batch_reward": 0.3639960884153843, "critic_loss": 0.5875818869769573, "actor_loss": -35.19989574813843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.64592957496643, "step": 101000}
{"episode_reward": 698.6911383123374, "episode": 102.0, "batch_reward": 0.368384855479002, "critic_loss": 0.5947874756753445, "actor_loss": -35.680610069274906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.751821517944336, "step": 102000}
{"episode_reward": 671.4625361104729, "episode": 103.0, "batch_reward": 0.36966070035099985, "critic_loss": 0.558639252960682, "actor_loss": -35.77427857589721, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.52257466316223, "step": 103000}
{"episode_reward": 627.6381203918145, "episode": 104.0, "batch_reward": 0.3734777335822582, "critic_loss": 0.5470619887709618, "actor_loss": -35.75404345321655, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.407092094421387, "step": 104000}
{"episode_reward": 621.7718992192243, "episode": 105.0, "batch_reward": 0.37617525732517243, "critic_loss": 0.6123901279568672, "actor_loss": -36.24025997543335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.827826976776123, "step": 105000}
{"episode_reward": 699.0566709344988, "episode": 106.0, "batch_reward": 0.37909158995747566, "critic_loss": 0.5770727436840534, "actor_loss": -36.58964122390747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.367239713668823, "step": 106000}
{"episode_reward": 672.6743504030239, "episode": 107.0, "batch_reward": 0.38130263766646383, "critic_loss": 0.5766996833086013, "actor_loss": -36.82448557662964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.69347381591797, "step": 107000}
{"episode_reward": 715.3225429564875, "episode": 108.0, "batch_reward": 0.3838994047343731, "critic_loss": 0.6096691997349262, "actor_loss": -37.03230606460571, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.07466173171997, "step": 108000}
{"episode_reward": 731.5601297351928, "episode": 109.0, "batch_reward": 0.38792669892311094, "critic_loss": 0.6067024764120579, "actor_loss": -37.286319919586184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.334900856018066, "step": 109000}
{"episode_reward": 309.0907905065255, "episode": 110.0, "batch_reward": 0.38730431658029557, "critic_loss": 0.6236391074061394, "actor_loss": -37.429557209014895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.831509351730347, "step": 110000}
{"episode_reward": 564.6942419280435, "episode": 111.0, "batch_reward": 0.3875972368717194, "critic_loss": 0.5957758678495884, "actor_loss": -37.289986282348636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.629345655441284, "step": 111000}
{"episode_reward": 634.8668761639863, "episode": 112.0, "batch_reward": 0.38999944457411767, "critic_loss": 0.6276050254106521, "actor_loss": -37.4180920715332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.170095205307007, "step": 112000}
{"episode_reward": 683.5681100175332, "episode": 113.0, "batch_reward": 0.39259693256020545, "critic_loss": 0.6401244105696678, "actor_loss": -37.6002370223999, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.180257081985474, "step": 113000}
{"episode_reward": 714.7739974642659, "episode": 114.0, "batch_reward": 0.39661057442426684, "critic_loss": 0.6425641080141068, "actor_loss": -38.08610409164429, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.483431816101074, "step": 114000}
{"episode_reward": 701.1282463865397, "episode": 115.0, "batch_reward": 0.398833281993866, "critic_loss": 0.6458494847416878, "actor_loss": -38.28497320556641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.752689361572266, "step": 115000}
{"episode_reward": 668.93776824214, "episode": 116.0, "batch_reward": 0.4024284877181053, "critic_loss": 0.6439922426939011, "actor_loss": -38.42856951522827, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.784438371658325, "step": 116000}
{"episode_reward": 684.790366537457, "episode": 117.0, "batch_reward": 0.4049082746207714, "critic_loss": 0.6414126602113247, "actor_loss": -38.685928756713864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.90229558944702, "step": 117000}
{"episode_reward": 663.9367562745326, "episode": 118.0, "batch_reward": 0.4061595389246941, "critic_loss": 0.6569997282922267, "actor_loss": -38.77539450836181, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.482995748519897, "step": 118000}
{"episode_reward": 636.8788507752201, "episode": 119.0, "batch_reward": 0.40845375588536265, "critic_loss": 0.6248405876457691, "actor_loss": -38.88941453552246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.39042019844055, "step": 119000}
{"episode_reward": 700.5809086463383, "episode": 120.0, "batch_reward": 0.4100499898195267, "critic_loss": 0.643402589738369, "actor_loss": -39.14986805725098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.808582305908203, "step": 120000}
{"episode_reward": 648.2626377402364, "episode": 121.0, "batch_reward": 0.410848451256752, "critic_loss": 0.5868148563206196, "actor_loss": -39.505561248779294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.55857443809509, "step": 121000}
{"episode_reward": 665.8716153026585, "episode": 122.0, "batch_reward": 0.41485021957755086, "critic_loss": 0.5958425439894199, "actor_loss": -39.88164360046387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.083045959472656, "step": 122000}
{"episode_reward": 650.4122058507936, "episode": 123.0, "batch_reward": 0.41620068088173867, "critic_loss": 0.5997018543481827, "actor_loss": -40.0414670791626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10992693901062, "step": 123000}
{"episode_reward": 403.571066771007, "episode": 124.0, "batch_reward": 0.41634115201234817, "critic_loss": 0.5924424514770508, "actor_loss": -39.97472646331787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.01748275756836, "step": 124000}
{"episode_reward": 630.8358055631936, "episode": 125.0, "batch_reward": 0.41583694505691526, "critic_loss": 0.6305996795594693, "actor_loss": -39.929489612579346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.691041946411133, "step": 125000}
{"episode_reward": 411.9807956055105, "episode": 126.0, "batch_reward": 0.41808153411746024, "critic_loss": 0.6531509900689125, "actor_loss": -40.20639209747314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.381173372268677, "step": 126000}
{"episode_reward": 670.7563495885881, "episode": 127.0, "batch_reward": 0.4206962278187275, "critic_loss": 0.675236327946186, "actor_loss": -40.289732208251955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.202333211898804, "step": 127000}
{"episode_reward": 622.251076123517, "episode": 128.0, "batch_reward": 0.42154233920574186, "critic_loss": 0.7430229286253452, "actor_loss": -40.492430191040036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.665914297103882, "step": 128000}
{"episode_reward": 711.8646645703053, "episode": 129.0, "batch_reward": 0.42404253014922144, "critic_loss": 0.7575401164889336, "actor_loss": -40.690682518005374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.61173725128174, "step": 129000}
{"episode_reward": 379.45650887880197, "episode": 130.0, "batch_reward": 0.4229458667337894, "critic_loss": 0.7360562880635262, "actor_loss": -40.58821748733521, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.433147192001343, "step": 130000}
{"episode_reward": 723.5752740089441, "episode": 131.0, "batch_reward": 0.4274004929959774, "critic_loss": 0.71685092446208, "actor_loss": -40.812729667663575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.499714374542236, "step": 131000}
{"episode_reward": 711.7677941237152, "episode": 132.0, "batch_reward": 0.427761209666729, "critic_loss": 0.7506253235638142, "actor_loss": -40.98769313812256, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.64558434486389, "step": 132000}
{"episode_reward": 639.1575814805562, "episode": 133.0, "batch_reward": 0.4304408365488052, "critic_loss": 0.7910971587002278, "actor_loss": -41.11257093811035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.78643488883972, "step": 133000}
{"episode_reward": 730.0122102558711, "episode": 134.0, "batch_reward": 0.4310401159226894, "critic_loss": 0.7287127743661403, "actor_loss": -41.264143630981444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.639013290405273, "step": 134000}
{"episode_reward": 722.422451626748, "episode": 135.0, "batch_reward": 0.43272723454236983, "critic_loss": 0.7887511294782161, "actor_loss": -41.5204176940918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.49719262123108, "step": 135000}
{"episode_reward": 601.7757895460089, "episode": 136.0, "batch_reward": 0.4357189621925354, "critic_loss": 0.762881443709135, "actor_loss": -41.72715641784668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.40005660057068, "step": 136000}
{"episode_reward": 698.8587900388345, "episode": 137.0, "batch_reward": 0.43743487244844437, "critic_loss": 0.8134062163233757, "actor_loss": -41.77828828430176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.217491149902344, "step": 137000}
{"episode_reward": 651.2925913132445, "episode": 138.0, "batch_reward": 0.4381356503665447, "critic_loss": 0.7719939588308334, "actor_loss": -41.85358232116699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.536314487457275, "step": 138000}
{"episode_reward": 699.0284029522473, "episode": 139.0, "batch_reward": 0.4411236498653889, "critic_loss": 0.7698023445606231, "actor_loss": -42.32694731140137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.7470383644104, "step": 139000}
{"episode_reward": 698.1024341827326, "episode": 140.0, "batch_reward": 0.44010449820756914, "critic_loss": 0.7682008583545685, "actor_loss": -42.22042403411865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.933255434036255, "step": 140000}
{"episode_reward": 713.8405865793845, "episode": 141.0, "batch_reward": 0.4459403286576271, "critic_loss": 0.7393101136684418, "actor_loss": -42.55116949462891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.19731664657593, "step": 141000}
{"episode_reward": 683.6593461473046, "episode": 142.0, "batch_reward": 0.44722878232598307, "critic_loss": 0.7757147435843944, "actor_loss": -42.700674285888674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.238089323043823, "step": 142000}
{"episode_reward": 665.2577956118512, "episode": 143.0, "batch_reward": 0.4463038609623909, "critic_loss": 0.7588695848286152, "actor_loss": -42.68545872497559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.056254863739014, "step": 143000}
{"episode_reward": 651.1511880444804, "episode": 144.0, "batch_reward": 0.44959013414382937, "critic_loss": 0.7089992210566998, "actor_loss": -42.94334265136719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.344030141830444, "step": 144000}
{"episode_reward": 602.669165367212, "episode": 145.0, "batch_reward": 0.450527478992939, "critic_loss": 0.7854420400857925, "actor_loss": -42.932390396118166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.642182111740112, "step": 145000}
{"episode_reward": 662.3599950273803, "episode": 146.0, "batch_reward": 0.4507314423918724, "critic_loss": 0.7896884595453739, "actor_loss": -42.929501136779784, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.674939393997192, "step": 146000}
{"episode_reward": 731.6748917878992, "episode": 147.0, "batch_reward": 0.452177148938179, "critic_loss": 0.8205830201506614, "actor_loss": -43.2629083404541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.367635488510132, "step": 147000}
{"episode_reward": 694.4026433034745, "episode": 148.0, "batch_reward": 0.45628614962100983, "critic_loss": 0.7963310646414756, "actor_loss": -43.52725021362305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.748143672943115, "step": 148000}
{"episode_reward": 448.3504389378436, "episode": 149.0, "batch_reward": 0.4552806835770607, "critic_loss": 0.7539318054318428, "actor_loss": -43.49719955444336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.528866052627563, "step": 149000}
{"episode_reward": 734.579777996213, "episode": 150.0, "batch_reward": 0.45592203801870346, "critic_loss": 0.7978093002736568, "actor_loss": -43.33999021911621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
