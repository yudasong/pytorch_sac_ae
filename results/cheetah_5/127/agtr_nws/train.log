{"episode": 1.0, "duration": 12.273416996002197, "episode_reward": 4.859792814687425, "step": 1000}
{"episode": 2.0, "duration": 1.1572504043579102, "episode_reward": 550.1572824113056, "step": 2000}
{"episode": 3.0, "batch_reward": 0.2622202640575105, "actor_loss": -40.86210426477109, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 50.272784948349, "episode_reward": 34.609600199739596, "step": 3000}
{"episode": 4.0, "batch_reward": 0.17944657666236163, "actor_loss": -29.099846103668213, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.14169979095459, "episode_reward": 64.3955295401169, "step": 4000}
{"episode": 5.0, "batch_reward": 0.1537676481306553, "actor_loss": -28.708655487060547, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.541138172149658, "episode_reward": 80.81561745923631, "step": 5000}
{"episode": 6.0, "batch_reward": 0.1457450580522418, "actor_loss": -27.035284896850587, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.84997010231018, "episode_reward": 111.63788524010873, "step": 6000}
{"episode": 7.0, "batch_reward": 0.14045475702732801, "actor_loss": -26.094281753540038, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.269492626190186, "episode_reward": 132.0042428789279, "step": 7000}
{"episode": 8.0, "batch_reward": 0.13413916783034802, "actor_loss": -26.486207355499268, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.541895627975464, "episode_reward": 67.37411663598867, "step": 8000}
{"episode": 9.0, "batch_reward": 0.12597079587727786, "actor_loss": -26.378323055267334, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.633656024932861, "episode_reward": 61.36712512725409, "step": 9000}
{"episode": 10.0, "batch_reward": 0.12009166521579027, "actor_loss": -22.121249309539795, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 5015.919335365295, "episode_reward": 63.833127092057495, "step": 10000}
{"episode": 11.0, "batch_reward": 0.11671108015626669, "actor_loss": -21.84877187347412, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 28.77685260772705, "episode_reward": 121.39686278922763, "step": 11000}
{"episode": 12.0, "batch_reward": 0.11861413159966469, "actor_loss": -19.214523933410643, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 549.6881296634674, "episode_reward": 113.02892256434242, "step": 12000}
{"episode": 13.0, "batch_reward": 0.11737384521216154, "actor_loss": -18.92081233406067, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.78737735748291, "episode_reward": 124.18434819100486, "step": 13000}
{"episode": 14.0, "batch_reward": 0.11950535226613283, "actor_loss": -16.66814541053772, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 546.9128851890564, "episode_reward": 199.0640458567507, "step": 14000}
{"episode": 15.0, "batch_reward": 0.11993909326195717, "actor_loss": -16.958231773376465, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.02120542526245, "episode_reward": 9.103340502736117, "step": 15000}
{"episode": 16.0, "batch_reward": 0.11217279463261366, "actor_loss": -14.924646881103516, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 545.9316585063934, "episode_reward": 7.7041555446432195, "step": 16000}
{"episode": 17.0, "batch_reward": 0.10935386427491903, "actor_loss": -15.116798414230347, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.424914121627808, "episode_reward": 150.79389834492798, "step": 17000}
{"episode": 18.0, "batch_reward": 0.11320441129058599, "actor_loss": -13.698631103515625, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 545.9054205417633, "episode_reward": 238.1677084228201, "step": 18000}
{"episode": 19.0, "batch_reward": 0.1202673020735383, "actor_loss": -14.069656963348388, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.354655027389526, "episode_reward": 147.44775718226137, "step": 19000}
{"episode": 20.0, "batch_reward": 0.12408182637393475, "actor_loss": -13.078015718460083, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 544.5587024688721, "episode_reward": 276.5243067673962, "step": 20000}
{"episode": 21.0, "batch_reward": 0.13072907989472152, "actor_loss": -13.252950510025025, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 28.1167151927948, "episode_reward": 224.25683851580635, "step": 21000}
{"episode": 22.0, "batch_reward": 0.13456626743078232, "actor_loss": -12.519486808776856, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 541.3010995388031, "episode_reward": 177.67652036043563, "step": 22000}
{"episode": 23.0, "batch_reward": 0.13680645824223756, "actor_loss": -12.52317253112793, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.214444875717163, "episode_reward": 269.19020410409405, "step": 23000}
{"episode": 24.0, "batch_reward": 0.14090704232454299, "actor_loss": -11.858225820541382, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 576.4919266700745, "episode_reward": 90.00258657726184, "step": 24000}
{"episode": 25.0, "batch_reward": 0.13855328979343176, "actor_loss": -11.725572626113891, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.83882164955139, "episode_reward": 184.61460172610992, "step": 25000}
{"episode": 26.0, "batch_reward": 0.1406772969663143, "actor_loss": -11.477413150787353, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 575.1096384525299, "episode_reward": 236.5427722867657, "step": 26000}
{"episode": 27.0, "batch_reward": 0.14366574745625257, "actor_loss": -11.729181060791015, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 25.208457946777344, "episode_reward": 98.61953264603936, "step": 27000}
{"episode": 28.0, "batch_reward": 0.14011398250609636, "actor_loss": -11.276575798034669, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 573.8013060092926, "episode_reward": 25.74571412050137, "step": 28000}
{"episode": 29.0, "batch_reward": 0.14085279598832132, "actor_loss": -11.45875304031372, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.747414350509644, "episode_reward": 335.7198405676914, "step": 29000}
{"episode": 30.0, "batch_reward": 0.1474848380535841, "actor_loss": -11.750784496307373, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 582.8859610557556, "episode_reward": 260.2787072234626, "step": 30000}
{"episode": 31.0, "batch_reward": 0.14972865509986877, "actor_loss": -11.869944020271301, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 34.92383313179016, "episode_reward": 203.5350744643505, "step": 31000}
{"episode": 32.0, "batch_reward": 0.15151367216557265, "actor_loss": -12.259789057731629, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 583.7760510444641, "episode_reward": 295.63583171293135, "step": 32000}
{"episode": 33.0, "batch_reward": 0.1545467606112361, "actor_loss": -12.409807914733888, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.44175934791565, "episode_reward": 120.12471433359818, "step": 33000}
{"episode": 34.0, "batch_reward": 0.15469117291271686, "actor_loss": -12.65528831100464, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 579.9906809329987, "episode_reward": 196.72254545645455, "step": 34000}
{"episode": 35.0, "batch_reward": 0.15618582424521446, "actor_loss": -12.842851593017578, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.774646043777466, "episode_reward": 238.94860846398745, "step": 35000}
{"episode": 36.0, "batch_reward": 0.1585057934001088, "actor_loss": -13.139595378875732, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 580.8307483196259, "episode_reward": 260.4964061189729, "step": 36000}
{"episode": 37.0, "batch_reward": 0.16000245627760887, "actor_loss": -13.269971529006957, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.962655067443848, "episode_reward": 103.85708929105613, "step": 37000}
{"episode": 38.0, "batch_reward": 0.1600193518549204, "actor_loss": -13.370487180709839, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 587.2793159484863, "episode_reward": 252.01169831926268, "step": 38000}
{"episode": 39.0, "batch_reward": 0.16314449562132358, "actor_loss": -13.72807900238037, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.67626118659973, "episode_reward": 265.7281580440955, "step": 39000}
{"episode": 40.0, "batch_reward": 0.16518349192291498, "actor_loss": -14.133767356872559, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 589.3571968078613, "episode_reward": 303.98384158698275, "step": 40000}
{"episode": 41.0, "batch_reward": 0.16873530009388923, "actor_loss": -14.448641920089722, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 34.758187770843506, "episode_reward": 241.41960024678716, "step": 41000}
{"episode": 42.0, "batch_reward": 0.17062644179165362, "actor_loss": -14.491284576416016, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 562.5000960826874, "episode_reward": 308.3857680528201, "step": 42000}
{"episode": 43.0, "batch_reward": 0.17397528906166554, "actor_loss": -14.858004343032837, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.044361114501953, "episode_reward": 320.70388777563943, "step": 43000}
{"episode": 44.0, "batch_reward": 0.17797211077809333, "actor_loss": -15.488070787429809, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 580.6193418502808, "episode_reward": 297.04645929919855, "step": 44000}
{"episode": 45.0, "batch_reward": 0.1799855023473501, "actor_loss": -15.633458770751954, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.080179452896118, "episode_reward": 331.17781628666006, "step": 45000}
{"episode": 46.0, "batch_reward": 0.18287287974357605, "actor_loss": -16.063170112609864, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 584.00501537323, "episode_reward": 176.10021149390232, "step": 46000}
{"episode": 47.0, "batch_reward": 0.18180781222879885, "actor_loss": -15.708976055145264, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.681245803833008, "episode_reward": 178.58062034682607, "step": 47000}
{"episode": 48.0, "batch_reward": 0.18391781876981259, "actor_loss": -15.60183596420288, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 580.8676314353943, "episode_reward": 415.56206269563484, "step": 48000}
{"episode": 49.0, "batch_reward": 0.18766640420258046, "actor_loss": -15.995810455322266, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.903836965560913, "episode_reward": 236.50724060210698, "step": 49000}
{"episode": 50.0, "batch_reward": 0.1894327318817377, "actor_loss": -15.65320233154297, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 575.7987730503082, "episode_reward": 267.819645485113, "step": 50000}
{"episode": 51.0, "batch_reward": 0.19116229583323002, "actor_loss": -15.69712314414978, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 40.7828643321991, "episode_reward": 411.42602592244776, "step": 51000}
{"episode": 52.0, "batch_reward": 0.19558248320221902, "actor_loss": -16.122187120437623, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 580.9362418651581, "episode_reward": 402.7357803823903, "step": 52000}
{"episode": 53.0, "batch_reward": 0.20012743853032589, "actor_loss": -16.510565727233885, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.674410581588745, "episode_reward": 461.8246303231247, "step": 53000}
{"episode": 54.0, "batch_reward": 0.2026241816431284, "actor_loss": -16.559078548431398, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 581.9008693695068, "episode_reward": 309.39923827183907, "step": 54000}
{"episode": 55.0, "batch_reward": 0.2037836354970932, "actor_loss": -16.62054524612427, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.829935789108276, "episode_reward": 76.70870863536815, "step": 55000}
{"episode": 56.0, "batch_reward": 0.20320407079160213, "actor_loss": -15.893456941604613, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 582.9823670387268, "episode_reward": 389.7377123883166, "step": 56000}
{"episode": 57.0, "batch_reward": 0.20682375456392765, "actor_loss": -16.14878080368042, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.006349325180054, "episode_reward": 285.86681543663735, "step": 57000}
{"episode": 58.0, "batch_reward": 0.2084284678697586, "actor_loss": -16.037726673126222, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 581.7590818405151, "episode_reward": 366.3337471332511, "step": 58000}
{"episode": 59.0, "batch_reward": 0.21125069169700145, "actor_loss": -16.17848818206787, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.826566219329834, "episode_reward": 410.1371030700851, "step": 59000}
{"episode": 60.0, "batch_reward": 0.2136684447824955, "actor_loss": -16.37231146812439, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 586.5246765613556, "episode_reward": 350.5217986305269, "step": 60000}
{"episode": 61.0, "batch_reward": 0.21763136775791644, "actor_loss": -16.864704175949097, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.04033613204956, "episode_reward": 427.9831298088843, "step": 61000}
{"episode": 62.0, "batch_reward": 0.22022456838190554, "actor_loss": -16.681356355667113, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 588.894327878952, "episode_reward": 444.3433602295442, "step": 62000}
{"episode": 63.0, "batch_reward": 0.2219507551640272, "actor_loss": -16.89985027694702, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.139453649520874, "episode_reward": 193.32265924121523, "step": 63000}
{"episode": 64.0, "batch_reward": 0.22397855918109416, "actor_loss": -16.80643660736084, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 584.762421131134, "episode_reward": 388.6398180782966, "step": 64000}
{"episode": 65.0, "batch_reward": 0.22541582320630552, "actor_loss": -16.876150608062744, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.735944747924805, "episode_reward": 397.4244083528674, "step": 65000}
{"episode": 66.0, "batch_reward": 0.22882880882918835, "actor_loss": -16.823899911880492, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 590.1519474983215, "episode_reward": 368.9841778065362, "step": 66000}
{"episode": 67.0, "batch_reward": 0.23067566807568074, "actor_loss": -16.953368848800658, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.85829448699951, "episode_reward": 388.3383868267252, "step": 67000}
{"episode": 68.0, "batch_reward": 0.2314315138757229, "actor_loss": -16.71063724708557, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 589.9560198783875, "episode_reward": 158.64963569291584, "step": 68000}
{"episode": 69.0, "batch_reward": 0.23239221368730067, "actor_loss": -16.84828989982605, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.59036922454834, "episode_reward": 442.83416881004626, "step": 69000}
{"episode": 70.0, "batch_reward": 0.234844632640481, "actor_loss": -16.345629655838014, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 586.8745861053467, "episode_reward": 413.22903125161406, "step": 70000}
{"episode": 71.0, "batch_reward": 0.23765877051651477, "actor_loss": -16.580254514694214, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.145955085754395, "episode_reward": 407.6382898698227, "step": 71000}
{"episode": 72.0, "batch_reward": 0.241007241204381, "actor_loss": -16.500442794799806, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 591.852053642273, "episode_reward": 462.5629018782625, "step": 72000}
{"episode": 73.0, "batch_reward": 0.24344326642155648, "actor_loss": -16.778952180862426, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.80799388885498, "episode_reward": 471.51419940784524, "step": 73000}
{"episode": 74.0, "batch_reward": 0.24492053982615472, "actor_loss": -16.948587242126465, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 580.6840717792511, "episode_reward": 256.5538848721191, "step": 74000}
{"episode": 75.0, "batch_reward": 0.24733054268360138, "actor_loss": -17.305543031692505, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 25.393986701965332, "episode_reward": 507.0465536251561, "step": 75000}
{"episode": 76.0, "batch_reward": 0.24731468291580677, "actor_loss": -17.318701740264892, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 580.8576173782349, "episode_reward": 43.77028647266352, "step": 76000}
{"episode": 77.0, "batch_reward": 0.24812644097208977, "actor_loss": -17.32322754859924, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 28.3226535320282, "episode_reward": 325.9835788191721, "step": 77000}
{"episode": 78.0, "batch_reward": 0.24866477833688258, "actor_loss": -17.32690548324585, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 580.7459712028503, "episode_reward": 493.48017866665856, "step": 78000}
{"episode": 79.0, "batch_reward": 0.25146577832102773, "actor_loss": -17.58470756340027, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.552600622177124, "episode_reward": 461.57630053653446, "step": 79000}
{"episode": 80.0, "batch_reward": 0.25397361344099045, "actor_loss": -17.750172403335572, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 584.2910716533661, "episode_reward": 482.8982482895178, "step": 80000}
{"episode": 81.0, "batch_reward": 0.25486674965918066, "actor_loss": -17.919951053619386, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 44.34360671043396, "episode_reward": 323.4352640945982, "step": 81000}
{"episode": 82.0, "batch_reward": 0.2579395085573196, "actor_loss": -18.13939243888855, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 581.9304203987122, "episode_reward": 395.3113242790391, "step": 82000}
{"episode": 83.0, "batch_reward": 0.2587818692177534, "actor_loss": -18.232782093048094, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.921566247940063, "episode_reward": 453.65662826334295, "step": 83000}
{"episode": 84.0, "batch_reward": 0.2596418711990118, "actor_loss": -18.033604330062865, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 585.6105816364288, "episode_reward": 43.83748091049251, "step": 84000}
{"episode": 85.0, "batch_reward": 0.259119669303298, "actor_loss": -17.845318897247314, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.891713857650757, "episode_reward": 236.03417475835346, "step": 85000}
{"episode": 86.0, "batch_reward": 0.25847601793706415, "actor_loss": -17.69414140701294, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 587.7890627384186, "episode_reward": 425.1089800941289, "step": 86000}
{"episode": 87.0, "batch_reward": 0.2602914429306984, "actor_loss": -17.81574328804016, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.94726800918579, "episode_reward": 443.384151554641, "step": 87000}
{"episode": 88.0, "batch_reward": 0.26431553660333157, "actor_loss": -18.63907166481018, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 588.6808006763458, "episode_reward": 495.10531743084033, "step": 88000}
{"episode": 89.0, "batch_reward": 0.264679542735219, "actor_loss": -18.707636186599732, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.429162740707397, "episode_reward": 257.2925036356989, "step": 89000}
{"episode": 90.0, "batch_reward": 0.26596190343797205, "actor_loss": -18.112390237808228, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 590.008841753006, "episode_reward": 446.6669569816038, "step": 90000}
{"episode": 91.0, "batch_reward": 0.2667437566369772, "actor_loss": -18.101628149032592, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.13089609146118, "episode_reward": 308.8828136300341, "step": 91000}
{"episode": 92.0, "batch_reward": 0.2672476326674223, "actor_loss": -17.940425786972046, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 579.5327825546265, "episode_reward": 237.8610039202356, "step": 92000}
{"episode": 93.0, "batch_reward": 0.2657609366476536, "actor_loss": -17.775232124328614, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.768221855163574, "episode_reward": 157.80993071058646, "step": 93000}
{"episode": 94.0, "batch_reward": 0.2666863882392645, "actor_loss": -17.885436059951783, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 590.9570906162262, "episode_reward": 211.8198787641834, "step": 94000}
{"episode": 95.0, "batch_reward": 0.26458478179574013, "actor_loss": -17.786866580963135, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.378276824951172, "episode_reward": 176.46283685589157, "step": 95000}
{"episode": 96.0, "batch_reward": 0.2650505384504795, "actor_loss": -17.46842130279541, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 588.2792148590088, "episode_reward": 421.5529052820567, "step": 96000}
{"episode": 97.0, "batch_reward": 0.266748913243413, "actor_loss": -17.62024832725525, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.338478803634644, "episode_reward": 485.2563784795307, "step": 97000}
{"episode": 98.0, "batch_reward": 0.26721633759140967, "actor_loss": -17.527088485717773, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 586.3530757427216, "episode_reward": 45.4403576901527, "step": 98000}
{"episode": 99.0, "batch_reward": 0.2662057315558195, "actor_loss": -17.4851058883667, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.517598867416382, "episode_reward": 446.4269360173982, "step": 99000}
{"episode": 100.0, "batch_reward": 0.26761132407188415, "actor_loss": -18.029812143325806, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 590.293021440506, "episode_reward": 317.0505710451655, "step": 100000}
{"episode": 101.0, "batch_reward": 0.26944578367471694, "actor_loss": -18.12067185974121, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.597596883773804, "episode_reward": 460.0695175578078, "step": 101000}
{"episode": 102.0, "batch_reward": 0.2699443275630474, "actor_loss": -18.037508226394653, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 591.5145637989044, "episode_reward": 456.74070049908613, "step": 102000}
{"episode": 103.0, "batch_reward": 0.2725757287740707, "actor_loss": -18.2817570438385, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.754379987716675, "episode_reward": 516.4308554462989, "step": 103000}
{"episode": 104.0, "batch_reward": 0.2743211435824633, "actor_loss": -18.492352764129638, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 589.4627678394318, "episode_reward": 302.6190991772919, "step": 104000}
{"episode": 105.0, "batch_reward": 0.27450785064697264, "actor_loss": -18.480082719802855, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.862683057785034, "episode_reward": 249.7156793579147, "step": 105000}
{"episode": 106.0, "batch_reward": 0.27383583799004557, "actor_loss": -18.464763885498048, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 588.0408849716187, "episode_reward": 400.1039253665254, "step": 106000}
{"episode": 107.0, "batch_reward": 0.27652527938783167, "actor_loss": -18.704160736083985, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.493653059005737, "episode_reward": 424.73998332801824, "step": 107000}
{"episode": 108.0, "batch_reward": 0.27772628219425677, "actor_loss": -18.757088869094847, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 589.1414189338684, "episode_reward": 552.9108629345992, "step": 108000}
{"episode": 109.0, "batch_reward": 0.2799285250753164, "actor_loss": -19.00638245201111, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.704772233963013, "episode_reward": 191.16664430865526, "step": 109000}
{"episode": 110.0, "batch_reward": 0.2793463774621487, "actor_loss": -18.756264627456666, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 586.5216159820557, "episode_reward": 560.3614687578328, "step": 110000}
{"episode": 111.0, "batch_reward": 0.2812760607600212, "actor_loss": -18.937434568405152, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 32.6551239490509, "episode_reward": 447.2317687179859, "step": 111000}
{"episode": 112.0, "batch_reward": 0.28280631186068056, "actor_loss": -19.508736989974974, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 589.0852146148682, "episode_reward": 477.03430679179223, "step": 112000}
{"episode": 113.0, "batch_reward": 0.28437867161631586, "actor_loss": -19.52736428642273, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.295512914657593, "episode_reward": 210.28308791767688, "step": 113000}
{"episode": 114.0, "batch_reward": 0.28397872000932695, "actor_loss": -19.208878885269165, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 585.1969039440155, "episode_reward": 544.9067807515357, "step": 114000}
{"episode": 115.0, "batch_reward": 0.28680350618064404, "actor_loss": -19.516007928848268, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.319288730621338, "episode_reward": 417.13480000267225, "step": 115000}
{"episode": 116.0, "batch_reward": 0.28758226084709165, "actor_loss": -19.526861398696898, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 581.8037421703339, "episode_reward": 475.2296874398454, "step": 116000}
{"episode": 117.0, "batch_reward": 0.289255277082324, "actor_loss": -19.538817407608033, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 26.105456352233887, "episode_reward": 494.2698960483262, "step": 117000}
{"episode": 118.0, "batch_reward": 0.29132211434841154, "actor_loss": -19.93531467819214, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 578.8248455524445, "episode_reward": 445.3353740350481, "step": 118000}
{"episode": 119.0, "batch_reward": 0.2910665472745895, "actor_loss": -19.817854122161865, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 25.292177200317383, "episode_reward": 520.3519088213895, "step": 119000}
{"episode": 120.0, "batch_reward": 0.2943764346092939, "actor_loss": -20.20959534072876, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 585.6485998630524, "episode_reward": 509.2716441134679, "step": 120000}
{"episode": 121.0, "batch_reward": 0.29662722849845885, "actor_loss": -20.53217703437805, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 44.472904920578, "episode_reward": 473.66244315543247, "step": 121000}
{"episode": 122.0, "batch_reward": 0.2978523618578911, "actor_loss": -20.04557837677002, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 582.5949199199677, "episode_reward": 530.1388578583116, "step": 122000}
{"episode": 123.0, "batch_reward": 0.2989779798090458, "actor_loss": -20.226649906158446, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 25.615790367126465, "episode_reward": 487.8235735963642, "step": 123000}
{"episode": 124.0, "batch_reward": 0.30022758300602437, "actor_loss": -20.28496829223633, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 582.3940932750702, "episode_reward": 378.9428515683659, "step": 124000}
{"episode": 125.0, "batch_reward": 0.3020474620461464, "actor_loss": -20.443549036026003, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.876532793045044, "episode_reward": 492.0730077079295, "step": 125000}
{"episode": 126.0, "batch_reward": 0.3023737729638815, "actor_loss": -20.694750558853148, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 586.5825946331024, "episode_reward": 417.70549760590285, "step": 126000}
{"episode": 127.0, "batch_reward": 0.30333029755949975, "actor_loss": -20.75515667152405, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.557077646255493, "episode_reward": 482.6797795259364, "step": 127000}
{"episode": 128.0, "batch_reward": 0.3054022814035416, "actor_loss": -21.294219165802, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 581.0324101448059, "episode_reward": 519.7832095292403, "step": 128000}
{"episode": 129.0, "batch_reward": 0.3069276662170887, "actor_loss": -21.378902210235594, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.799431085586548, "episode_reward": 489.86945376986466, "step": 129000}
{"episode": 130.0, "batch_reward": 0.3078138275742531, "actor_loss": -21.638170349121093, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 581.6329934597015, "episode_reward": 483.71437529653815, "step": 130000}
{"episode": 131.0, "batch_reward": 0.3099015903174877, "actor_loss": -21.758884815216064, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 41.495935916900635, "episode_reward": 531.7661653420164, "step": 131000}
{"episode": 132.0, "batch_reward": 0.31094124461710454, "actor_loss": -21.83861190032959, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 589.426323890686, "episode_reward": 538.4028993774051, "step": 132000}
{"episode": 133.0, "batch_reward": 0.31395443254709243, "actor_loss": -22.227966205596925, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.2119460105896, "episode_reward": 507.74870380102493, "step": 133000}
{"episode": 134.0, "batch_reward": 0.31497648522257804, "actor_loss": -22.39336893081665, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 584.3541634082794, "episode_reward": 297.58472342514335, "step": 134000}
{"episode": 135.0, "batch_reward": 0.3136555895507336, "actor_loss": -22.327381072998048, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.789121866226196, "episode_reward": 400.0629577459162, "step": 135000}
{"episode": 136.0, "batch_reward": 0.31573396557569505, "actor_loss": -22.683797492980958, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 582.8337244987488, "episode_reward": 518.0911341954514, "step": 136000}
{"episode": 137.0, "batch_reward": 0.317333362698555, "actor_loss": -22.938820446014404, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.296502351760864, "episode_reward": 554.1926738585951, "step": 137000}
{"episode": 138.0, "batch_reward": 0.31870482394099237, "actor_loss": -22.95413829040527, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 582.4716546535492, "episode_reward": 544.4276881863949, "step": 138000}
{"episode": 139.0, "batch_reward": 0.3203667809665203, "actor_loss": -22.906845176696777, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.518462896347046, "episode_reward": 488.64325920828156, "step": 139000}
{"episode": 140.0, "batch_reward": 0.3216864124238491, "actor_loss": -23.172949981689452, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 581.330977678299, "episode_reward": 514.8767783618714, "step": 140000}
{"episode": 141.0, "batch_reward": 0.32247350573539735, "actor_loss": -23.338029434204103, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.2306706905365, "episode_reward": 409.14244935866384, "step": 141000}
{"episode": 142.0, "batch_reward": 0.3231163789629936, "actor_loss": -22.933337020874024, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 576.4621412754059, "episode_reward": 469.4011225369135, "step": 142000}
{"episode": 143.0, "batch_reward": 0.32409991458058357, "actor_loss": -23.019757301330568, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.44614887237549, "episode_reward": 511.1422388806874, "step": 143000}
{"episode": 144.0, "batch_reward": 0.32562824460864065, "actor_loss": -22.92842643356323, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 586.0883009433746, "episode_reward": 600.9037645569564, "step": 144000}
{"episode": 145.0, "batch_reward": 0.32774703136086464, "actor_loss": -23.187842590332032, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.623969078063965, "episode_reward": 569.138548784402, "step": 145000}
{"episode": 146.0, "batch_reward": 0.32981122320890427, "actor_loss": -22.870425628662108, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 582.0215005874634, "episode_reward": 513.8516153011338, "step": 146000}
{"episode": 147.0, "batch_reward": 0.3304573464393616, "actor_loss": -22.92173320007324, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.857273817062378, "episode_reward": 576.6716556346573, "step": 147000}
{"episode": 148.0, "batch_reward": 0.33252380388975145, "actor_loss": -22.92649532699585, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 577.0221536159515, "episode_reward": 489.5617343696975, "step": 148000}
{"episode": 149.0, "batch_reward": 0.33253532364964483, "actor_loss": -22.931753246307373, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.8553786277771, "episode_reward": 141.29482163367524, "step": 149000}
{"episode": 150.0, "batch_reward": 0.33131224873661996, "actor_loss": -22.572640686035157, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
