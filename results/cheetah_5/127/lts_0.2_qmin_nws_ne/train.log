{"episode_reward": 0.0, "episode": 1.0, "duration": 21.81042194366455, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.675628900527954, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.260182796194578, "critic_loss": 0.021856207051353233, "actor_loss": -10.839911682123528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 67.21379065513611, "step": 3000}
{"episode_reward": 1.6458431185253957, "episode": 4.0, "batch_reward": 0.16144260048121215, "critic_loss": 0.009745789436623454, "actor_loss": -10.686110181808472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.71291470527649, "step": 4000}
{"episode_reward": 3.2533740257351287, "episode": 5.0, "batch_reward": 0.12521368419378995, "critic_loss": 0.01503352198889479, "actor_loss": -8.964168930530548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.2043559551239, "step": 5000}
{"episode_reward": 2.629619352261008, "episode": 6.0, "batch_reward": 0.10172628271207214, "critic_loss": 0.01451814739848487, "actor_loss": -9.79753671169281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.16513705253601, "step": 6000}
{"episode_reward": 0.7314572739599059, "episode": 7.0, "batch_reward": 0.08679148546606302, "critic_loss": 0.015607571636326612, "actor_loss": -8.530666394233704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.937971115112305, "step": 7000}
{"episode_reward": 1.543542248637121, "episode": 8.0, "batch_reward": 0.07556251928210259, "critic_loss": 0.016601273426320402, "actor_loss": -8.399109785079956, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.40497612953186, "step": 8000}
{"episode_reward": 2.159994942613925, "episode": 9.0, "batch_reward": 0.06669928767345845, "critic_loss": 0.01569037584448233, "actor_loss": -8.540087560892106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.140401601791382, "step": 9000}
{"episode_reward": 2.6134440621131216, "episode": 10.0, "batch_reward": 0.06042231667786837, "critic_loss": 0.017756403025472538, "actor_loss": -9.003624955654145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.41281819343567, "step": 10000}
{"episode_reward": 3.1586770267477444, "episode": 11.0, "batch_reward": 0.05569881949853152, "critic_loss": 0.015727473350940272, "actor_loss": -8.679782195329667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.19489145278931, "step": 11000}
{"episode_reward": 3.3000168985990714, "episode": 12.0, "batch_reward": 0.049464964340440926, "critic_loss": 0.01605616862815805, "actor_loss": -8.944543376684189, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.131420850753784, "step": 12000}
{"episode_reward": 2.8010637842330928, "episode": 13.0, "batch_reward": 0.04611569945141673, "critic_loss": 0.02237175655574538, "actor_loss": -7.801678866386413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.791653871536255, "step": 13000}
{"episode_reward": 2.8034503083011857, "episode": 14.0, "batch_reward": 0.043417345837689934, "critic_loss": 0.014094177464023232, "actor_loss": -8.452805769443511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.502254009246826, "step": 14000}
{"episode_reward": 3.974397520006179, "episode": 15.0, "batch_reward": 0.040139149216003714, "critic_loss": 0.015623089347500355, "actor_loss": -8.070196467399597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098814964294434, "step": 15000}
{"episode_reward": 2.823127661468729, "episode": 16.0, "batch_reward": 0.03796275723958388, "critic_loss": 0.018052908243844284, "actor_loss": -7.893342762947083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.604206562042236, "step": 16000}
{"episode_reward": 3.4499092589833404, "episode": 17.0, "batch_reward": 0.035719382448587564, "critic_loss": 0.011715059194830246, "actor_loss": -8.17944879770279, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.593425750732422, "step": 17000}
{"episode_reward": 2.070965512046859, "episode": 18.0, "batch_reward": 0.034724329656455666, "critic_loss": 0.0176780665575061, "actor_loss": -7.675093024969101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.9259192943573, "step": 18000}
{"episode_reward": 4.859334239008819, "episode": 19.0, "batch_reward": 0.03257802540343255, "critic_loss": 0.010197705573751591, "actor_loss": -7.662912710189819, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07451605796814, "step": 19000}
{"episode_reward": 2.5365916787853173, "episode": 20.0, "batch_reward": 0.03102208217070438, "critic_loss": 0.016998551482392942, "actor_loss": -7.1531638007164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.882648229599, "step": 20000}
{"episode_reward": 2.741264357433856, "episode": 21.0, "batch_reward": 0.02883952007931657, "critic_loss": 0.015222221148433164, "actor_loss": -7.118351359844207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.13416814804077, "step": 21000}
{"episode_reward": 2.9919769559428038, "episode": 22.0, "batch_reward": 0.02849213743582368, "critic_loss": 0.013321954802318943, "actor_loss": -8.679886512517928, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1134192943573, "step": 22000}
{"episode_reward": 4.139913081418456, "episode": 23.0, "batch_reward": 0.02714160571852699, "critic_loss": 0.012972112930670847, "actor_loss": -7.185452512741088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.864054441452026, "step": 23000}
{"episode_reward": 3.364661015531094, "episode": 24.0, "batch_reward": 0.026043569539207966, "critic_loss": 0.013893098408123479, "actor_loss": -7.862229163050651, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.47014856338501, "step": 24000}
{"episode_reward": 2.7261609815564523, "episode": 25.0, "batch_reward": 0.025679991799406707, "critic_loss": 0.014960310821887106, "actor_loss": -6.986953986644745, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.022428512573242, "step": 25000}
{"episode_reward": 3.697179327386781, "episode": 26.0, "batch_reward": 0.02440073478082195, "critic_loss": 0.013160327470395715, "actor_loss": -6.49540992128849, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.167945861816406, "step": 26000}
{"episode_reward": 2.700609002063491, "episode": 27.0, "batch_reward": 0.024161738155642525, "critic_loss": 0.012249820198630914, "actor_loss": -6.587199873208999, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.167667627334595, "step": 27000}
{"episode_reward": 2.8742479487775516, "episode": 28.0, "batch_reward": 0.023244239027611913, "critic_loss": 0.010015698605799116, "actor_loss": -7.1915439404249195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.395264863967896, "step": 28000}
{"episode_reward": 3.2690484473635015, "episode": 29.0, "batch_reward": 0.021912427622359246, "critic_loss": 0.014428829310811124, "actor_loss": -7.0831350471973415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.110468864440918, "step": 29000}
{"episode_reward": 2.363300315900984, "episode": 30.0, "batch_reward": 0.021636210915166886, "critic_loss": 0.013529030126490397, "actor_loss": -5.787404435396194, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.802420377731323, "step": 30000}
{"episode_reward": 3.1090971735660498, "episode": 31.0, "batch_reward": 0.020744760310044512, "critic_loss": 0.00834086323887459, "actor_loss": -6.939625401735306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.45251274108887, "step": 31000}
{"episode_reward": 2.4391450184284196, "episode": 32.0, "batch_reward": 0.020347560480237007, "critic_loss": 0.013595082286512478, "actor_loss": -7.985838280200959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.79970359802246, "step": 32000}
{"episode_reward": 2.4430807079079493, "episode": 33.0, "batch_reward": 0.019804175577824934, "critic_loss": 0.0084590302768338, "actor_loss": -7.5001774133443835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.058492183685303, "step": 33000}
{"episode_reward": 2.677467761168603, "episode": 34.0, "batch_reward": 0.019424004753585904, "critic_loss": 0.011102914650196909, "actor_loss": -6.126613745212555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.181390523910522, "step": 34000}
{"episode_reward": 1.1958474546094005, "episode": 35.0, "batch_reward": 0.01805654677725397, "critic_loss": 0.01225950689119054, "actor_loss": -8.344639975070953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.01903772354126, "step": 35000}
{"episode_reward": 1.8970280384585234, "episode": 36.0, "batch_reward": 0.017856406543403865, "critic_loss": 0.011467318298848114, "actor_loss": -7.366688478350639, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.48531699180603, "step": 36000}
{"episode_reward": 3.920298854377476, "episode": 37.0, "batch_reward": 0.017895856075221674, "critic_loss": 0.012471045105048689, "actor_loss": -6.746252354502678, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.78485870361328, "step": 37000}
{"episode_reward": 3.1512368162805364, "episode": 38.0, "batch_reward": 0.017243812114116734, "critic_loss": 0.007338402574852808, "actor_loss": -6.422265083312988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.794840335845947, "step": 38000}
{"episode_reward": 2.40434981970337, "episode": 39.0, "batch_reward": 0.017131849892088213, "critic_loss": 0.012256600188295124, "actor_loss": -7.136357430696488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.187019109725952, "step": 39000}
{"episode_reward": 2.4453269536029625, "episode": 40.0, "batch_reward": 0.01667906995001249, "critic_loss": 0.007052576036337996, "actor_loss": -6.151232740104199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.23546051979065, "step": 40000}
{"episode_reward": 2.693988667461147, "episode": 41.0, "batch_reward": 0.01622829867666587, "critic_loss": 0.010830245348610334, "actor_loss": -6.455686457812786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.365644693374634, "step": 41000}
{"episode_reward": 2.6966841065084206, "episode": 42.0, "batch_reward": 0.016045816069236024, "critic_loss": 0.007379761690754094, "actor_loss": -6.791832327246666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.586965322494507, "step": 42000}
{"episode_reward": 3.0459728003422057, "episode": 43.0, "batch_reward": 0.015482403093832545, "critic_loss": 0.011843881203210912, "actor_loss": -6.806971953213215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.423168897628784, "step": 43000}
{"episode_reward": 1.4096670937169344, "episode": 44.0, "batch_reward": 0.015487508056219667, "critic_loss": 0.006705806181547814, "actor_loss": -6.491716111123562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.98443293571472, "step": 44000}
{"episode_reward": 3.432594004895557, "episode": 45.0, "batch_reward": 0.014902251012972555, "critic_loss": 0.0073195819461543575, "actor_loss": -6.990101581335067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.89119267463684, "step": 45000}
{"episode_reward": 4.1242077112777435, "episode": 46.0, "batch_reward": 0.014491227102582343, "critic_loss": 0.006739397253593779, "actor_loss": -6.392374789953232, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06132197380066, "step": 46000}
{"episode_reward": 3.110948212127012, "episode": 47.0, "batch_reward": 0.014360195436282083, "critic_loss": 0.009151530184579315, "actor_loss": -6.675190011382103, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.376157999038696, "step": 47000}
{"episode_reward": 3.784636758480511, "episode": 48.0, "batch_reward": 0.014309021465014666, "critic_loss": 0.00868452465828159, "actor_loss": -6.595484443485737, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.637248277664185, "step": 48000}
{"episode_reward": 2.43764187162073, "episode": 49.0, "batch_reward": 0.0142568704362493, "critic_loss": 0.007371970486114151, "actor_loss": -6.838253475606441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.976189374923706, "step": 49000}
{"episode_reward": 3.5749350677831093, "episode": 50.0, "batch_reward": 0.013906508265295997, "critic_loss": 0.011333441500741174, "actor_loss": -6.368975579619407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13815689086914, "step": 50000}
{"episode_reward": 5.072016092590318, "episode": 51.0, "batch_reward": 0.013724046215647831, "critic_loss": 0.006829461459812592, "actor_loss": -5.835786678671837, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.226741552352905, "step": 51000}
{"episode_reward": 1.8411024046951323, "episode": 52.0, "batch_reward": 0.013581625344930216, "critic_loss": 0.007798877505760174, "actor_loss": -5.475880446434021, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.60809564590454, "step": 52000}
{"episode_reward": 1.898161320861968, "episode": 53.0, "batch_reward": 0.013349526525009424, "critic_loss": 0.006644195187269361, "actor_loss": -7.127361959934235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.928788661956787, "step": 53000}
{"episode_reward": 2.785301163510398, "episode": 54.0, "batch_reward": 0.013106439756578766, "critic_loss": 0.010107609221886377, "actor_loss": -5.999657259821892, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.588826179504395, "step": 54000}
{"episode_reward": 2.9334999388415035, "episode": 55.0, "batch_reward": 0.013187117202091031, "critic_loss": 0.006076032140801544, "actor_loss": -6.61479523819685, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.194733142852783, "step": 55000}
{"episode_reward": 4.624738164957595, "episode": 56.0, "batch_reward": 0.012609916662797331, "critic_loss": 0.009407532005818212, "actor_loss": -6.746583692610264, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.135075330734253, "step": 56000}
{"episode_reward": 2.1184952494258704, "episode": 57.0, "batch_reward": 0.012554368218989111, "critic_loss": 0.008660930663521867, "actor_loss": -6.978998965799809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.965416431427002, "step": 57000}
{"episode_reward": 3.4384362458462476, "episode": 58.0, "batch_reward": 0.012300276447087526, "critic_loss": 0.005274167203766411, "actor_loss": -6.8713497902154925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.87529754638672, "step": 58000}
{"episode_reward": 4.447625409634622, "episode": 59.0, "batch_reward": 0.012170795558486134, "critic_loss": 0.009048117115307832, "actor_loss": -6.338077897071838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.89725685119629, "step": 59000}
{"episode_reward": 3.6144262527530424, "episode": 60.0, "batch_reward": 0.01225017331307754, "critic_loss": 0.005026222400570986, "actor_loss": -6.449088124871254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.633530855178833, "step": 60000}
{"episode_reward": 3.0849720235446783, "episode": 61.0, "batch_reward": 0.0122424232828198, "critic_loss": 0.006562641106385854, "actor_loss": -6.14827112364769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.97045850753784, "step": 61000}
{"episode_reward": 2.3716323743284846, "episode": 62.0, "batch_reward": 0.01217198636464309, "critic_loss": 0.006437492827550159, "actor_loss": -6.816169336676597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.333542823791504, "step": 62000}
{"episode_reward": 3.3014231627780877, "episode": 63.0, "batch_reward": 0.011666134152095765, "critic_loss": 0.008231996324335342, "actor_loss": -5.432985978186131, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.336925983428955, "step": 63000}
{"episode_reward": 3.5378773268324197, "episode": 64.0, "batch_reward": 0.011450963872019201, "critic_loss": 0.004657880210404983, "actor_loss": -6.214246024727822, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.02998948097229, "step": 64000}
{"episode_reward": 1.5034164689862604, "episode": 65.0, "batch_reward": 0.011272608327562921, "critic_loss": 0.009608629094960634, "actor_loss": -6.323125931799412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.982283115386963, "step": 65000}
{"episode_reward": 3.2976132436718197, "episode": 66.0, "batch_reward": 0.011132609096122906, "critic_loss": 0.004216455028596101, "actor_loss": -6.877396389842033, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.78653907775879, "step": 66000}
{"episode_reward": 3.1476141416504837, "episode": 67.0, "batch_reward": 0.011256170294480398, "critic_loss": 0.005002736161841313, "actor_loss": -6.768680135309697, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.697765350341797, "step": 67000}
{"episode_reward": 2.846106922750395, "episode": 68.0, "batch_reward": 0.010957148996298202, "critic_loss": 0.006932601000138675, "actor_loss": -7.136440272152424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.68229651451111, "step": 68000}
{"episode_reward": 2.47801564144941, "episode": 69.0, "batch_reward": 0.010935916338465176, "critic_loss": 0.0046959520574455385, "actor_loss": -5.650106281280517, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.46476936340332, "step": 69000}
{"episode_reward": 3.001739642980226, "episode": 70.0, "batch_reward": 0.01084671428380534, "critic_loss": 0.00484436057905259, "actor_loss": -6.220511986136437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.195963621139526, "step": 70000}
{"episode_reward": 3.0839527326782816, "episode": 71.0, "batch_reward": 0.010782809543190525, "critic_loss": 0.007479762848641258, "actor_loss": -6.66664078220725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.22436881065369, "step": 71000}
{"episode_reward": 2.036438801293318, "episode": 72.0, "batch_reward": 0.010713576201233081, "critic_loss": 0.0036268170189869124, "actor_loss": -6.1543180397748944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.837028980255127, "step": 72000}
{"episode_reward": 2.322302009618586, "episode": 73.0, "batch_reward": 0.010595689758425578, "critic_loss": 0.00631679707604053, "actor_loss": -6.490462536126375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.05789065361023, "step": 73000}
{"episode_reward": 2.7796595118588687, "episode": 74.0, "batch_reward": 0.010173159435857088, "critic_loss": 0.006405178973480361, "actor_loss": -5.802589231878519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.440505504608154, "step": 74000}
{"episode_reward": 2.9760340740200966, "episode": 75.0, "batch_reward": 0.00997808687586803, "critic_loss": 0.003949167595696053, "actor_loss": -5.088401337653399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.79300308227539, "step": 75000}
{"episode_reward": 2.4385018978345903, "episode": 76.0, "batch_reward": 0.010319113953621126, "critic_loss": 0.005302285444777226, "actor_loss": -5.96280077162385, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.743569135665894, "step": 76000}
{"episode_reward": 4.666205580458279, "episode": 77.0, "batch_reward": 0.010356815039762296, "critic_loss": 0.008713979876920347, "actor_loss": -5.79311793422699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.166618824005127, "step": 77000}
{"episode_reward": 2.0050088601996516, "episode": 78.0, "batch_reward": 0.010443444207543508, "critic_loss": 0.0036654095765625244, "actor_loss": -5.945566185742616, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.36623787879944, "step": 78000}
{"episode_reward": 3.9128384296601935, "episode": 79.0, "batch_reward": 0.009813172704540194, "critic_loss": 0.005853853491644258, "actor_loss": -6.5134997550547125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.205074310302734, "step": 79000}
{"episode_reward": 3.530847261840266, "episode": 80.0, "batch_reward": 0.00989003086509183, "critic_loss": 0.004103238631723798, "actor_loss": -6.891328944921494, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.287899255752563, "step": 80000}
{"episode_reward": 2.4572305087210946, "episode": 81.0, "batch_reward": 0.009458084936253726, "critic_loss": 0.006183154229162028, "actor_loss": -6.884130540728569, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.15954041481018, "step": 81000}
{"episode_reward": 2.6932019914569856, "episode": 82.0, "batch_reward": 0.009472792612272315, "critic_loss": 0.005504897270759102, "actor_loss": -6.0938933554887775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.894271850585938, "step": 82000}
{"episode_reward": 2.8550798997610967, "episode": 83.0, "batch_reward": 0.009562066787737421, "critic_loss": 0.004040391631744569, "actor_loss": -6.703672960072756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.030486583709717, "step": 83000}
{"episode_reward": 2.884067629279092, "episode": 84.0, "batch_reward": 0.009377685350133107, "critic_loss": 0.005523439326323569, "actor_loss": -6.113390181541443, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11904501914978, "step": 84000}
{"episode_reward": 4.069466563538237, "episode": 85.0, "batch_reward": 0.00933155199198518, "critic_loss": 0.0049709505749342495, "actor_loss": -6.01554929664731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.504892587661743, "step": 85000}
{"episode_reward": 2.4792694977156158, "episode": 86.0, "batch_reward": 0.009485412105335853, "critic_loss": 0.004357302837932366, "actor_loss": -6.4680578650534155, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.639458417892456, "step": 86000}
{"episode_reward": 3.9823658096400463, "episode": 87.0, "batch_reward": 0.009279093621647918, "critic_loss": 0.004637589701873367, "actor_loss": -6.804795076221228, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.859175205230713, "step": 87000}
{"episode_reward": 3.14484201226379, "episode": 88.0, "batch_reward": 0.008854071063688025, "critic_loss": 0.004997601945942734, "actor_loss": -5.695795840382576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.062967777252197, "step": 88000}
{"episode_reward": 3.146347915533005, "episode": 89.0, "batch_reward": 0.009193893196992577, "critic_loss": 0.0038422100535826756, "actor_loss": -5.9339901559054855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.981615781784058, "step": 89000}
{"episode_reward": 2.2706683155501817, "episode": 90.0, "batch_reward": 0.009213453044067137, "critic_loss": 0.006771389598652604, "actor_loss": -6.22616765794158, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.63161063194275, "step": 90000}
{"episode_reward": 2.7212837835950086, "episode": 91.0, "batch_reward": 0.008973889142158442, "critic_loss": 0.0031314507930437687, "actor_loss": -5.7588893117010596, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.095449447631836, "step": 91000}
{"episode_reward": 2.093261488188081, "episode": 92.0, "batch_reward": 0.008811820338014514, "critic_loss": 0.005269842915069603, "actor_loss": -5.929359639495611, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.624471187591553, "step": 92000}
{"episode_reward": 2.740003981847028, "episode": 93.0, "batch_reward": 0.008721173554775304, "critic_loss": 0.0038795734035229545, "actor_loss": -5.633307632952929, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.48512578010559, "step": 93000}
{"episode_reward": 2.741983014174724, "episode": 94.0, "batch_reward": 0.008674663921352476, "critic_loss": 0.005407675459093298, "actor_loss": -5.175604474544525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23128032684326, "step": 94000}
{"episode_reward": 3.998952609863566, "episode": 95.0, "batch_reward": 0.008527216269518249, "critic_loss": 0.003896970720270474, "actor_loss": -6.423084679126739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09541940689087, "step": 95000}
{"episode_reward": 3.555817535231781, "episode": 96.0, "batch_reward": 0.008902955884346739, "critic_loss": 0.004666769435061724, "actor_loss": -5.403194052398205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.533156633377075, "step": 96000}
{"episode_reward": 2.8711778754650954, "episode": 97.0, "batch_reward": 0.00869559089152608, "critic_loss": 0.0065187792067154075, "actor_loss": -5.957291205435991, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.110525608062744, "step": 97000}
{"episode_reward": 2.3409104743478206, "episode": 98.0, "batch_reward": 0.008366785113466904, "critic_loss": 0.003916130758429063, "actor_loss": -7.946863811612129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04461169242859, "step": 98000}
{"episode_reward": 3.383098922060076, "episode": 99.0, "batch_reward": 0.008376463939552195, "critic_loss": 0.004331512395408936, "actor_loss": -5.321135728001595, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.873651027679443, "step": 99000}
{"episode_reward": 3.0407347060411984, "episode": 100.0, "batch_reward": 0.00845075168123003, "critic_loss": 0.005527552050509257, "actor_loss": -6.058260114818811, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.90767192840576, "step": 100000}
{"episode_reward": 2.9839535099388255, "episode": 101.0, "batch_reward": 0.008527076143887825, "critic_loss": 0.0041424504285823786, "actor_loss": -5.7367156719565395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.59313201904297, "step": 101000}
{"episode_reward": 2.728649182576043, "episode": 102.0, "batch_reward": 0.008577290733461269, "critic_loss": 0.004971537488330796, "actor_loss": -5.848140378266573, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.73937153816223, "step": 102000}
{"episode_reward": 2.637073256521335, "episode": 103.0, "batch_reward": 0.008552274011541157, "critic_loss": 0.0040580577559812805, "actor_loss": -6.12907314285636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.888044118881226, "step": 103000}
{"episode_reward": 3.4879804768017664, "episode": 104.0, "batch_reward": 0.008433693269849754, "critic_loss": 0.004717002756449802, "actor_loss": -5.897505582362413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.58827805519104, "step": 104000}
{"episode_reward": 3.359848467431686, "episode": 105.0, "batch_reward": 0.008293541767401621, "critic_loss": 0.0041091553998048765, "actor_loss": -5.8378127883374695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.758124828338623, "step": 105000}
{"episode_reward": 2.6626865724513005, "episode": 106.0, "batch_reward": 0.007788851366727613, "critic_loss": 0.004816847746697022, "actor_loss": -5.527359656363726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.532961130142212, "step": 106000}
{"episode_reward": 3.5499168527808456, "episode": 107.0, "batch_reward": 0.008140559822088108, "critic_loss": 0.005057062224026595, "actor_loss": -6.176338044673204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.619463205337524, "step": 107000}
{"episode_reward": 3.1215088926527534, "episode": 108.0, "batch_reward": 0.008371450283098965, "critic_loss": 0.0036217239267498373, "actor_loss": -6.804225762963295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.13968515396118, "step": 108000}
{"episode_reward": 2.6517456982855165, "episode": 109.0, "batch_reward": 0.007814566179411486, "critic_loss": 0.004133797124821285, "actor_loss": -6.023199417680502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.49362301826477, "step": 109000}
{"episode_reward": 3.058625549205494, "episode": 110.0, "batch_reward": 0.00818686477432493, "critic_loss": 0.004237675114571175, "actor_loss": -6.90268992242217, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.51950216293335, "step": 110000}
{"episode_reward": 1.866944394579505, "episode": 111.0, "batch_reward": 0.00783336145139765, "critic_loss": 0.0031442165473126804, "actor_loss": -5.981629114031792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.76207399368286, "step": 111000}
{"episode_reward": 2.722433908063959, "episode": 112.0, "batch_reward": 0.00792162521230057, "critic_loss": 0.005303582369080686, "actor_loss": -6.767299380749464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.753009796142578, "step": 112000}
{"episode_reward": 4.433721100308667, "episode": 113.0, "batch_reward": 0.00790186533727683, "critic_loss": 0.002861965772419353, "actor_loss": -5.930324861526489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.073198556900024, "step": 113000}
{"episode_reward": 4.292877332936635, "episode": 114.0, "batch_reward": 0.007944175746641122, "critic_loss": 0.003254520943337411, "actor_loss": -6.544140184432268, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.887760400772095, "step": 114000}
{"episode_reward": 3.247964863696354, "episode": 115.0, "batch_reward": 0.007486400740104727, "critic_loss": 0.003997875894143362, "actor_loss": -6.2284007131159305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.191309213638306, "step": 115000}
{"episode_reward": 3.0581423849433373, "episode": 116.0, "batch_reward": 0.007752467500860803, "critic_loss": 0.0035407946165069005, "actor_loss": -6.137013672083616, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.77812361717224, "step": 116000}
{"episode_reward": 1.8377351725117732, "episode": 117.0, "batch_reward": 0.007568259449442848, "critic_loss": 0.004195142671924259, "actor_loss": -5.402446693241596, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.107938289642334, "step": 117000}
{"episode_reward": 1.2136054926308324, "episode": 118.0, "batch_reward": 0.0074640055452473465, "critic_loss": 0.002441411458901712, "actor_loss": -6.4111949402391915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.378753900527954, "step": 118000}
{"episode_reward": 1.836998493726725, "episode": 119.0, "batch_reward": 0.007800339507986791, "critic_loss": 0.004702808764457586, "actor_loss": -5.741776124566793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.484527349472046, "step": 119000}
{"episode_reward": 2.94601939655713, "episode": 120.0, "batch_reward": 0.0077201758055016395, "critic_loss": 0.003408667820287519, "actor_loss": -5.2857319419085975, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.93558692932129, "step": 120000}
{"episode_reward": 2.418735868299291, "episode": 121.0, "batch_reward": 0.007342986667761579, "critic_loss": 0.003625595499011979, "actor_loss": -5.491915172845125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.675394773483276, "step": 121000}
{"episode_reward": 2.865196813185519, "episode": 122.0, "batch_reward": 0.0073335902203107255, "critic_loss": 0.003070964976279356, "actor_loss": -5.838942607074976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.598029136657715, "step": 122000}
{"episode_reward": 3.9531138494874627, "episode": 123.0, "batch_reward": 0.007424822293571196, "critic_loss": 0.0036920652956177946, "actor_loss": -6.237980184197426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.51847791671753, "step": 123000}
{"episode_reward": 3.0281149697525187, "episode": 124.0, "batch_reward": 0.007613190493080765, "critic_loss": 0.0038154599723784484, "actor_loss": -6.07188979524374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.833391904830933, "step": 124000}
{"episode_reward": 3.5908170258077896, "episode": 125.0, "batch_reward": 0.007139088470721617, "critic_loss": 0.0023659159582166468, "actor_loss": -5.921788157790899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.848061561584473, "step": 125000}
{"episode_reward": 1.4900353162907956, "episode": 126.0, "batch_reward": 0.007414751569158397, "critic_loss": 0.004229862690292066, "actor_loss": -6.061005596578121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13723611831665, "step": 126000}
{"episode_reward": 4.739438750645413, "episode": 127.0, "batch_reward": 0.007270700776600279, "critic_loss": 0.0030748502836286207, "actor_loss": -6.400968686938286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.965543746948242, "step": 127000}
{"episode_reward": 3.694417452925209, "episode": 128.0, "batch_reward": 0.007285789112676866, "critic_loss": 0.002717548845917918, "actor_loss": -6.456666354000569, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.35816264152527, "step": 128000}
{"episode_reward": 1.827238297937766, "episode": 129.0, "batch_reward": 0.007370750568923541, "critic_loss": 0.003901064209996548, "actor_loss": -6.58726307618618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.907947063446045, "step": 129000}
{"episode_reward": 3.503120430518248, "episode": 130.0, "batch_reward": 0.007055348930531181, "critic_loss": 0.0030610893324628705, "actor_loss": -6.788146325260401, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.53267812728882, "step": 130000}
{"episode_reward": 1.8138358819107607, "episode": 131.0, "batch_reward": 0.00711511295766104, "critic_loss": 0.0035221115739477683, "actor_loss": -5.875819739371538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.805795669555664, "step": 131000}
{"episode_reward": 1.8895004941390752, "episode": 132.0, "batch_reward": 0.007030153173487633, "critic_loss": 0.003309075645942357, "actor_loss": -5.639757414281369, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.944278717041016, "step": 132000}
{"episode_reward": 1.729959332465373, "episode": 133.0, "batch_reward": 0.007002544926363044, "critic_loss": 0.0026954033507208806, "actor_loss": -5.702440516859293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.930552005767822, "step": 133000}
{"episode_reward": 3.022026530032379, "episode": 134.0, "batch_reward": 0.007298870747210458, "critic_loss": 0.0037350622516678414, "actor_loss": -6.781893859386444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.546351432800293, "step": 134000}
{"episode_reward": 5.92755788740706, "episode": 135.0, "batch_reward": 0.006806532439426519, "critic_loss": 0.002731409600834013, "actor_loss": -7.055253236919642, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.099234104156494, "step": 135000}
{"episode_reward": 2.720286803065296, "episode": 136.0, "batch_reward": 0.0070911647847387935, "critic_loss": 0.0045139648991971626, "actor_loss": -6.2124822473526, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.06867551803589, "step": 136000}
{"episode_reward": 2.8712609570881895, "episode": 137.0, "batch_reward": 0.0069145892421947795, "critic_loss": 0.0027236751062446273, "actor_loss": -6.753809913277626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.347667932510376, "step": 137000}
{"episode_reward": 3.3394993754648796, "episode": 138.0, "batch_reward": 0.00692645424650982, "critic_loss": 0.004468721884513797, "actor_loss": -6.542056820183992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.783148765563965, "step": 138000}
{"episode_reward": 1.8250164133692555, "episode": 139.0, "batch_reward": 0.00679223930707667, "critic_loss": 0.002522289674503554, "actor_loss": -5.455403819650412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.81291675567627, "step": 139000}
{"episode_reward": 4.806290523754123, "episode": 140.0, "batch_reward": 0.007092486347537488, "critic_loss": 0.0032227767760123244, "actor_loss": -5.684119552999735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.53022027015686, "step": 140000}
{"episode_reward": 3.3528567379683967, "episode": 141.0, "batch_reward": 0.006828515885747038, "critic_loss": 0.002326893691533769, "actor_loss": -6.526538902506232, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.25050377845764, "step": 141000}
{"episode_reward": 3.2423417690947365, "episode": 142.0, "batch_reward": 0.006809453159221448, "critic_loss": 0.003099109188071452, "actor_loss": -5.907303453952074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.819022178649902, "step": 142000}
{"episode_reward": 2.553179905082318, "episode": 143.0, "batch_reward": 0.006964326262357645, "critic_loss": 0.003165938197511423, "actor_loss": -6.194536429941654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.995179176330566, "step": 143000}
{"episode_reward": 5.010312472322433, "episode": 144.0, "batch_reward": 0.006770205709501169, "critic_loss": 0.0018194284757919376, "actor_loss": -6.646079170197249, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.44394874572754, "step": 144000}
{"episode_reward": 2.7169928163136348, "episode": 145.0, "batch_reward": 0.006588948564021848, "critic_loss": 0.00314411983716127, "actor_loss": -6.579683324635029, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.692356824874878, "step": 145000}
{"episode_reward": 4.123612152439403, "episode": 146.0, "batch_reward": 0.006587925222236663, "critic_loss": 0.0031748214785766323, "actor_loss": -6.584123091131449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.463651418685913, "step": 146000}
{"episode_reward": 2.3149714632715455, "episode": 147.0, "batch_reward": 0.006797677179449238, "critic_loss": 0.002989565898446017, "actor_loss": -5.960453464120627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04609227180481, "step": 147000}
{"episode_reward": 3.021913232628564, "episode": 148.0, "batch_reward": 0.006581001530168578, "critic_loss": 0.0023272987686505076, "actor_loss": -6.923208026230335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.70121455192566, "step": 148000}
{"episode_reward": 2.8484464823579008, "episode": 149.0, "batch_reward": 0.006662100948742591, "critic_loss": 0.002689510977899772, "actor_loss": -5.782671644985676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.992158889770508, "step": 149000}
{"episode_reward": 3.242796222426932, "episode": 150.0, "batch_reward": 0.006366832951549441, "critic_loss": 0.0024955209646432197, "actor_loss": -6.746339387565851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
