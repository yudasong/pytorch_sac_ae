{"episode_reward": 0.0, "episode": 1.0, "duration": 17.07516312599182, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.470508098602295, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.26923210528362745, "critic_loss": 0.2709843855389717, "actor_loss": -38.556802957236364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.03604245185852, "step": 3000}
{"episode_reward": 94.16643780198312, "episode": 4.0, "batch_reward": 0.23396674896776676, "critic_loss": 0.3087643248438835, "actor_loss": -31.205925884246827, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993206024169922, "step": 4000}
{"episode_reward": 295.0199426636001, "episode": 5.0, "batch_reward": 0.26240626847743986, "critic_loss": 0.41922354358434677, "actor_loss": -31.876291538238526, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.982125282287598, "step": 5000}
{"episode_reward": 504.9165375227251, "episode": 6.0, "batch_reward": 0.2939670250862837, "critic_loss": 0.6218813360482455, "actor_loss": -32.878698246002195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.30648946762085, "step": 6000}
{"episode_reward": 439.9350621637207, "episode": 7.0, "batch_reward": 0.3186280311048031, "critic_loss": 0.6525802145600319, "actor_loss": -34.59986091613769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.968270301818848, "step": 7000}
{"episode_reward": 355.78673571096635, "episode": 8.0, "batch_reward": 0.3236558024287224, "critic_loss": 1.060994865477085, "actor_loss": -33.96538076400757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.944591283798218, "step": 8000}
{"episode_reward": 401.906824229695, "episode": 9.0, "batch_reward": 0.3188498774766922, "critic_loss": 0.7650880948603154, "actor_loss": -34.398468898773196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.982104063034058, "step": 9000}
{"episode_reward": 248.98317243436307, "episode": 10.0, "batch_reward": 0.32228973039984704, "critic_loss": 0.6788035651445389, "actor_loss": -35.35593276977539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.967926025390625, "step": 10000}
{"episode_reward": 419.5044978138268, "episode": 11.0, "batch_reward": 0.32908286473155024, "critic_loss": 0.7043687684237957, "actor_loss": -35.39845486068726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.126670360565186, "step": 11000}
{"episode_reward": 170.04982707626462, "episode": 12.0, "batch_reward": 0.3208863972723484, "critic_loss": 0.6997172368466854, "actor_loss": -34.23083278274536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.967375993728638, "step": 12000}
{"episode_reward": 476.58003533626857, "episode": 13.0, "batch_reward": 0.3268586273491383, "critic_loss": 0.7714273808002472, "actor_loss": -34.50450146102905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00011706352234, "step": 13000}
{"episode_reward": 163.01949612172922, "episode": 14.0, "batch_reward": 0.32334029221534727, "critic_loss": 0.7514169744253159, "actor_loss": -33.96072808074951, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97598171234131, "step": 14000}
{"episode_reward": 559.431318672232, "episode": 15.0, "batch_reward": 0.339882983982563, "critic_loss": 0.7856189610660076, "actor_loss": -35.22100305175781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.987046241760254, "step": 15000}
{"episode_reward": 579.3333214825701, "episode": 16.0, "batch_reward": 0.34477826464176176, "critic_loss": 0.8534762369692326, "actor_loss": -35.16572571563721, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.975659132003784, "step": 16000}
{"episode_reward": 122.55601868159998, "episode": 17.0, "batch_reward": 0.3408061245083809, "critic_loss": 0.8353994617462158, "actor_loss": -34.77795878601074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98944330215454, "step": 17000}
{"episode_reward": 533.0637958399208, "episode": 18.0, "batch_reward": 0.349718285292387, "critic_loss": 0.9155190232396125, "actor_loss": -35.38702534103393, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98180317878723, "step": 18000}
{"episode_reward": 462.911764372938, "episode": 19.0, "batch_reward": 0.35547478854656217, "critic_loss": 0.9615273795127869, "actor_loss": -35.70672061538696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990519523620605, "step": 19000}
{"episode_reward": 335.3278094077888, "episode": 20.0, "batch_reward": 0.3567251428067684, "critic_loss": 0.9322654268145562, "actor_loss": -35.64850298690796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9796199798584, "step": 20000}
{"episode_reward": 525.1653982256945, "episode": 21.0, "batch_reward": 0.36526189315319063, "critic_loss": 0.9016224273443222, "actor_loss": -36.005597122192384, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.14317321777344, "step": 21000}
{"episode_reward": 524.7360966858976, "episode": 22.0, "batch_reward": 0.3716921721100807, "critic_loss": 0.8266841593980789, "actor_loss": -36.70218480682373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981867790222168, "step": 22000}
{"episode_reward": 569.4980120523526, "episode": 23.0, "batch_reward": 0.3792011199593544, "critic_loss": 0.8108184391558171, "actor_loss": -37.08399803161621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9949369430542, "step": 23000}
{"episode_reward": 474.4476837414452, "episode": 24.0, "batch_reward": 0.381720679551363, "critic_loss": 0.7687276600301266, "actor_loss": -37.2372502784729, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98829698562622, "step": 24000}
{"episode_reward": 257.56359639693665, "episode": 25.0, "batch_reward": 0.37799833771586416, "critic_loss": 0.7166476965248585, "actor_loss": -36.64556092071533, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.994306325912476, "step": 25000}
{"episode_reward": 276.044176604215, "episode": 26.0, "batch_reward": 0.37314100658893584, "critic_loss": 0.6628139133751393, "actor_loss": -36.01002165603638, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99482488632202, "step": 26000}
{"episode_reward": 353.55454380304064, "episode": 27.0, "batch_reward": 0.3743944410383701, "critic_loss": 0.6646975543498993, "actor_loss": -35.99227474975586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98075842857361, "step": 27000}
{"episode_reward": 565.1822514945358, "episode": 28.0, "batch_reward": 0.3818562252521515, "critic_loss": 0.6659096282422543, "actor_loss": -36.456229984283446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.987329483032227, "step": 28000}
{"episode_reward": 541.8163275617334, "episode": 29.0, "batch_reward": 0.38682188403606416, "critic_loss": 0.6473037846982479, "actor_loss": -36.836780441284176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.984566926956177, "step": 29000}
{"episode_reward": 490.3927603677158, "episode": 30.0, "batch_reward": 0.3915116005539894, "critic_loss": 0.6394180972278118, "actor_loss": -37.01323691558838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97482132911682, "step": 30000}
{"episode_reward": 579.5783759662474, "episode": 31.0, "batch_reward": 0.39817882972955704, "critic_loss": 0.6268814410865307, "actor_loss": -37.721179504394534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.10132908821106, "step": 31000}
{"episode_reward": 600.4690757689478, "episode": 32.0, "batch_reward": 0.4046921000182629, "critic_loss": 0.6526124006211758, "actor_loss": -38.17961075210571, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97559428215027, "step": 32000}
{"episode_reward": 610.911873965052, "episode": 33.0, "batch_reward": 0.4111077459156513, "critic_loss": 0.6385176489651203, "actor_loss": -38.59799722290039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986753225326538, "step": 33000}
{"episode_reward": 658.2842187672308, "episode": 34.0, "batch_reward": 0.41782263267040254, "critic_loss": 0.6238191016316413, "actor_loss": -39.1655544090271, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98167371749878, "step": 34000}
{"episode_reward": 627.4190989874137, "episode": 35.0, "batch_reward": 0.42376394939422607, "critic_loss": 0.6275381967723369, "actor_loss": -39.509301666259766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98126220703125, "step": 35000}
{"episode_reward": 558.2684128205985, "episode": 36.0, "batch_reward": 0.42753970915079115, "critic_loss": 0.6378714272379875, "actor_loss": -39.973086738586424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.978402376174927, "step": 36000}
{"episode_reward": 533.194713873445, "episode": 37.0, "batch_reward": 0.42922365710139276, "critic_loss": 0.6414935983419419, "actor_loss": -40.11423285675049, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.989296197891235, "step": 37000}
{"episode_reward": 565.6029815040356, "episode": 38.0, "batch_reward": 0.43512605494260786, "critic_loss": 0.6633478837907314, "actor_loss": -40.31980700683594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.979967832565308, "step": 38000}
{"episode_reward": 619.3015306122663, "episode": 39.0, "batch_reward": 0.43946456649899485, "critic_loss": 0.6657736341357231, "actor_loss": -40.606770599365234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.982265949249268, "step": 39000}
{"episode_reward": 611.823459542278, "episode": 40.0, "batch_reward": 0.4423041435480118, "critic_loss": 0.6756159198582172, "actor_loss": -41.0574284324646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981236696243286, "step": 40000}
{"episode_reward": 566.2488755288521, "episode": 41.0, "batch_reward": 0.44642835840582845, "critic_loss": 0.6728477196693421, "actor_loss": -41.35243264770508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.110233545303345, "step": 41000}
{"episode_reward": 600.4968383429667, "episode": 42.0, "batch_reward": 0.4479150748550892, "critic_loss": 0.6940856272280216, "actor_loss": -41.428441688537596, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.976118087768555, "step": 42000}
{"episode_reward": 179.7864202452228, "episode": 43.0, "batch_reward": 0.4434307160079479, "critic_loss": 0.6919086669683456, "actor_loss": -41.06259944152832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993162393569946, "step": 43000}
{"episode_reward": 551.8163732945812, "episode": 44.0, "batch_reward": 0.4456629604101181, "critic_loss": 0.6909408926367759, "actor_loss": -41.53437395858764, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.970413208007812, "step": 44000}
{"episode_reward": 590.649901698814, "episode": 45.0, "batch_reward": 0.4497268103957176, "critic_loss": 0.7158202531933785, "actor_loss": -41.66507138061523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97800326347351, "step": 45000}
{"episode_reward": 589.0935060103207, "episode": 46.0, "batch_reward": 0.4521857431232929, "critic_loss": 0.7514643579721451, "actor_loss": -41.488687911987306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.977191925048828, "step": 46000}
{"episode_reward": 564.1019009001238, "episode": 47.0, "batch_reward": 0.45641127586364744, "critic_loss": 0.723833210349083, "actor_loss": -41.92996408081055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.987056970596313, "step": 47000}
{"episode_reward": 661.6356832877352, "episode": 48.0, "batch_reward": 0.4578968647420406, "critic_loss": 0.7169623411595821, "actor_loss": -42.126900657653806, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981306552886963, "step": 48000}
{"episode_reward": 443.35527841202145, "episode": 49.0, "batch_reward": 0.45731503969430926, "critic_loss": 0.7429030569493771, "actor_loss": -42.326650024414064, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97542119026184, "step": 49000}
{"episode_reward": 466.2849855783757, "episode": 50.0, "batch_reward": 0.46024966448545457, "critic_loss": 0.770461244314909, "actor_loss": -42.40063050842285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.978532075881958, "step": 50000}
{"episode_reward": 609.5791181711082, "episode": 51.0, "batch_reward": 0.4612388293743134, "critic_loss": 0.7803487007319927, "actor_loss": -42.461111686706545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.101433753967285, "step": 51000}
{"episode_reward": 639.4062659454262, "episode": 52.0, "batch_reward": 0.4672533721327782, "critic_loss": 0.7452069938778877, "actor_loss": -42.728795013427735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98449969291687, "step": 52000}
{"episode_reward": 678.8445506639804, "episode": 53.0, "batch_reward": 0.47046878063678743, "critic_loss": 0.7763236765861511, "actor_loss": -43.21636459350586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.980554342269897, "step": 53000}
{"episode_reward": 653.935894464066, "episode": 54.0, "batch_reward": 0.4737308835089207, "critic_loss": 0.7967331963479519, "actor_loss": -43.49739202880859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986789226531982, "step": 54000}
{"episode_reward": 658.5235537250169, "episode": 55.0, "batch_reward": 0.475080190628767, "critic_loss": 0.8043939976692199, "actor_loss": -43.574861534118654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.984923839569092, "step": 55000}
{"episode_reward": 320.9555600479828, "episode": 56.0, "batch_reward": 0.4737156499028206, "critic_loss": 0.7971043710112572, "actor_loss": -43.29041455078125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.978923797607422, "step": 56000}
{"episode_reward": 635.5175588498647, "episode": 57.0, "batch_reward": 0.4771559209823608, "critic_loss": 0.8132280205488205, "actor_loss": -43.71620604705811, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9925537109375, "step": 57000}
{"episode_reward": 634.0682687049049, "episode": 58.0, "batch_reward": 0.4788128571510315, "critic_loss": 0.7986059013903141, "actor_loss": -43.89317544555664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.983200311660767, "step": 58000}
{"episode_reward": 610.7956082838592, "episode": 59.0, "batch_reward": 0.4824069628119469, "critic_loss": 0.8121467458307743, "actor_loss": -44.01722954559326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.984194040298462, "step": 59000}
{"episode_reward": 668.4654941422132, "episode": 60.0, "batch_reward": 0.4852179149389267, "critic_loss": 0.8283265864253044, "actor_loss": -44.379896705627445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.979422092437744, "step": 60000}
{"episode_reward": 628.022860180869, "episode": 61.0, "batch_reward": 0.48750532710552213, "critic_loss": 0.8312607048749924, "actor_loss": -44.43425461578369, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.125159740448, "step": 61000}
{"episode_reward": 630.6859050834818, "episode": 62.0, "batch_reward": 0.4893981566429138, "critic_loss": 0.8283425638079643, "actor_loss": -44.63613466644287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99320888519287, "step": 62000}
{"episode_reward": 622.137423477512, "episode": 63.0, "batch_reward": 0.49129801681637764, "critic_loss": 0.8398883438408374, "actor_loss": -44.81993845367432, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99075174331665, "step": 63000}
{"episode_reward": 287.1625649586471, "episode": 64.0, "batch_reward": 0.49022627022862436, "critic_loss": 0.8580705164968967, "actor_loss": -44.73841599273682, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98517942428589, "step": 64000}
{"episode_reward": 638.0077766448911, "episode": 65.0, "batch_reward": 0.4898617478609085, "critic_loss": 0.9070386256873607, "actor_loss": -44.5671354675293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990821361541748, "step": 65000}
{"episode_reward": 603.8587725319745, "episode": 66.0, "batch_reward": 0.49276539945602416, "critic_loss": 0.912065648317337, "actor_loss": -44.703162467956545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.994212865829468, "step": 66000}
{"episode_reward": 667.4975782361257, "episode": 67.0, "batch_reward": 0.49548025071620944, "critic_loss": 0.8989512028992176, "actor_loss": -45.24341184997559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990538835525513, "step": 67000}
{"episode_reward": 612.2999865522027, "episode": 68.0, "batch_reward": 0.49668711426854134, "critic_loss": 0.8910675536096097, "actor_loss": -45.54445344543457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.991171836853027, "step": 68000}
{"episode_reward": 629.1317955872412, "episode": 69.0, "batch_reward": 0.4979152392446995, "critic_loss": 0.9120909120440484, "actor_loss": -45.22825296783447, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99636220932007, "step": 69000}
{"episode_reward": 569.4403909683208, "episode": 70.0, "batch_reward": 0.5006137553155422, "critic_loss": 0.9662462213635444, "actor_loss": -45.40953539276123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99135684967041, "step": 70000}
{"episode_reward": 632.6836338451682, "episode": 71.0, "batch_reward": 0.5022401171624661, "critic_loss": 0.9387685979604721, "actor_loss": -45.38116905975342, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.14044260978699, "step": 71000}
{"episode_reward": 597.6106949210747, "episode": 72.0, "batch_reward": 0.5022056287229061, "critic_loss": 0.922004238665104, "actor_loss": -45.856173225402834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988105535507202, "step": 72000}
{"episode_reward": 660.9366520699175, "episode": 73.0, "batch_reward": 0.506874496102333, "critic_loss": 0.9687223543524742, "actor_loss": -46.120446464538574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9842746257782, "step": 73000}
{"episode_reward": 602.9737308636163, "episode": 74.0, "batch_reward": 0.5067382603287697, "critic_loss": 1.0020979826450347, "actor_loss": -45.812653388977054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999959230422974, "step": 74000}
{"episode_reward": 710.9748500109858, "episode": 75.0, "batch_reward": 0.5095661469995976, "critic_loss": 0.9633718796670437, "actor_loss": -46.16834023284912, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.998819589614868, "step": 75000}
{"episode_reward": 644.7928755019096, "episode": 76.0, "batch_reward": 0.5111529085636138, "critic_loss": 1.043432576149702, "actor_loss": -46.40722908782959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.000808715820312, "step": 76000}
{"episode_reward": 644.0574594587074, "episode": 77.0, "batch_reward": 0.5131857469379902, "critic_loss": 1.0797301607131957, "actor_loss": -46.43038144683838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00074601173401, "step": 77000}
{"episode_reward": 662.2495551214322, "episode": 78.0, "batch_reward": 0.5156619703173637, "critic_loss": 1.0155335341691971, "actor_loss": -46.789777694702146, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006126165390015, "step": 78000}
{"episode_reward": 643.1232156466941, "episode": 79.0, "batch_reward": 0.5166328218877315, "critic_loss": 1.0326574578881265, "actor_loss": -47.15835076141357, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.010207891464233, "step": 79000}
{"episode_reward": 436.9293042030266, "episode": 80.0, "batch_reward": 0.5140896611809731, "critic_loss": 1.024297718435526, "actor_loss": -46.6911517791748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003921031951904, "step": 80000}
{"episode_reward": 621.8359412492882, "episode": 81.0, "batch_reward": 0.5170558308064938, "critic_loss": 1.001117417782545, "actor_loss": -46.64988582611084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.15102553367615, "step": 81000}
{"episode_reward": 664.7019632352374, "episode": 82.0, "batch_reward": 0.5187663734257221, "critic_loss": 0.992294305562973, "actor_loss": -46.98630146789551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007731914520264, "step": 82000}
{"episode_reward": 655.2520027098356, "episode": 83.0, "batch_reward": 0.5214768023490906, "critic_loss": 0.9464664186835289, "actor_loss": -47.20732627868652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.995048999786377, "step": 83000}
{"episode_reward": 662.8068002736156, "episode": 84.0, "batch_reward": 0.5206930578947068, "critic_loss": 0.9922253115773201, "actor_loss": -47.28840592956543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.995323181152344, "step": 84000}
{"episode_reward": 290.2869712054911, "episode": 85.0, "batch_reward": 0.5190648494958877, "critic_loss": 1.0158477553725243, "actor_loss": -47.14369683074951, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9920916557312, "step": 85000}
{"episode_reward": 565.3377871691047, "episode": 86.0, "batch_reward": 0.5196429587602616, "critic_loss": 0.9758450216054917, "actor_loss": -47.14609267425537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986769914627075, "step": 86000}
{"episode_reward": 669.477392057659, "episode": 87.0, "batch_reward": 0.5209128242433071, "critic_loss": 0.9776525130271911, "actor_loss": -47.31240096282959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99248957633972, "step": 87000}
{"episode_reward": 654.9420086801422, "episode": 88.0, "batch_reward": 0.5221343107819557, "critic_loss": 0.9287850826978683, "actor_loss": -47.24872109222412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.985409021377563, "step": 88000}
{"episode_reward": 656.5020972039613, "episode": 89.0, "batch_reward": 0.5233364761173726, "critic_loss": 0.9250744526982307, "actor_loss": -47.44562730407715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006818532943726, "step": 89000}
{"episode_reward": 380.28828601517887, "episode": 90.0, "batch_reward": 0.5234349978268147, "critic_loss": 0.9407901413440705, "actor_loss": -47.33959356689453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986414909362793, "step": 90000}
{"episode_reward": 664.9618486931947, "episode": 91.0, "batch_reward": 0.5229210932850837, "critic_loss": 0.9464965530633926, "actor_loss": -47.40664427185059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.145140409469604, "step": 91000}
{"episode_reward": 266.3912136496356, "episode": 92.0, "batch_reward": 0.5224314703941345, "critic_loss": 0.9361783934533596, "actor_loss": -47.6006947631836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.976690530776978, "step": 92000}
{"episode_reward": 642.6341015802448, "episode": 93.0, "batch_reward": 0.5230653277039528, "critic_loss": 0.9044004926383495, "actor_loss": -47.28769397735596, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.989641189575195, "step": 93000}
{"episode_reward": 684.3233308907122, "episode": 94.0, "batch_reward": 0.524597017377615, "critic_loss": 0.976019959449768, "actor_loss": -47.61187289428711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99473214149475, "step": 94000}
{"episode_reward": 593.0621913627509, "episode": 95.0, "batch_reward": 0.5259366158246994, "critic_loss": 0.9519442521929741, "actor_loss": -47.93880704498291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.995995044708252, "step": 95000}
{"episode_reward": 627.5652861853496, "episode": 96.0, "batch_reward": 0.5270921835303306, "critic_loss": 1.0266505741178988, "actor_loss": -47.91626136779785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99092197418213, "step": 96000}
{"episode_reward": 610.7636932514044, "episode": 97.0, "batch_reward": 0.5272745113670826, "critic_loss": 0.9906592601537705, "actor_loss": -47.91425911712646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.992241144180298, "step": 97000}
{"episode_reward": 673.1699269408625, "episode": 98.0, "batch_reward": 0.5293614940941334, "critic_loss": 0.9932284647524356, "actor_loss": -48.192040351867675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98318862915039, "step": 98000}
{"episode_reward": 556.4430473376759, "episode": 99.0, "batch_reward": 0.5295938789248467, "critic_loss": 1.0001721027195454, "actor_loss": -47.954940452575684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981250047683716, "step": 99000}
{"episode_reward": 686.551295470051, "episode": 100.0, "batch_reward": 0.5319841498434543, "critic_loss": 1.0192599158883096, "actor_loss": -48.52846710968018, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99973154067993, "step": 100000}
{"episode_reward": 698.431397964881, "episode": 101.0, "batch_reward": 0.5333680560290813, "critic_loss": 0.9999470913410187, "actor_loss": -48.29330590820312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.147984981536865, "step": 101000}
{"episode_reward": 636.1776267594656, "episode": 102.0, "batch_reward": 0.5346689969301224, "critic_loss": 0.9947355028688908, "actor_loss": -48.54058204650879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.992141485214233, "step": 102000}
{"episode_reward": 671.6158295244314, "episode": 103.0, "batch_reward": 0.534045362919569, "critic_loss": 0.9909822015166283, "actor_loss": -48.44260781860351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.987207889556885, "step": 103000}
{"episode_reward": 681.2259402279051, "episode": 104.0, "batch_reward": 0.5366339559555053, "critic_loss": 0.9778843937218189, "actor_loss": -48.53144314575195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.996989011764526, "step": 104000}
{"episode_reward": 646.5879510690258, "episode": 105.0, "batch_reward": 0.5373584000468254, "critic_loss": 0.9986832707524299, "actor_loss": -48.80692806243896, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004133939743042, "step": 105000}
{"episode_reward": 671.9717613152264, "episode": 106.0, "batch_reward": 0.5366208700835705, "critic_loss": 1.0182437494397163, "actor_loss": -48.71030641937256, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003045558929443, "step": 106000}
{"episode_reward": 299.49260345047634, "episode": 107.0, "batch_reward": 0.5364027491211891, "critic_loss": 1.0050967420339585, "actor_loss": -48.613192100524905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.998513221740723, "step": 107000}
{"episode_reward": 623.3930618046061, "episode": 108.0, "batch_reward": 0.5367137688398361, "critic_loss": 1.0360129210948945, "actor_loss": -48.76899174499512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00112819671631, "step": 108000}
{"episode_reward": 633.5063820823676, "episode": 109.0, "batch_reward": 0.5388625187575817, "critic_loss": 1.0189659549593926, "actor_loss": -48.886657997131344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99340581893921, "step": 109000}
{"episode_reward": 631.9240393870314, "episode": 110.0, "batch_reward": 0.5383622404038906, "critic_loss": 1.0347344500422477, "actor_loss": -49.16085117340088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98704242706299, "step": 110000}
{"episode_reward": 639.825279815261, "episode": 111.0, "batch_reward": 0.5388102090656758, "critic_loss": 1.0722093113660813, "actor_loss": -48.95841744995117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.14638304710388, "step": 111000}
{"episode_reward": 609.1378607208984, "episode": 112.0, "batch_reward": 0.5393292315304279, "critic_loss": 1.0632111791968346, "actor_loss": -48.97450459289551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005977153778076, "step": 112000}
{"episode_reward": 228.30605006419034, "episode": 113.0, "batch_reward": 0.5377645871639252, "critic_loss": 1.0537831653356553, "actor_loss": -48.933393852233884, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99876046180725, "step": 113000}
{"episode_reward": 684.0939709532549, "episode": 114.0, "batch_reward": 0.5397810609638691, "critic_loss": 1.1010828443169594, "actor_loss": -49.067480514526366, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.991191387176514, "step": 114000}
{"episode_reward": 662.781817760452, "episode": 115.0, "batch_reward": 0.5404877476394176, "critic_loss": 1.078779082596302, "actor_loss": -49.21837530517578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006250619888306, "step": 115000}
{"episode_reward": 676.4444292751168, "episode": 116.0, "batch_reward": 0.5418188195228577, "critic_loss": 1.0358072087168693, "actor_loss": -49.32918344116211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.992374897003174, "step": 116000}
{"episode_reward": 680.6071179992614, "episode": 117.0, "batch_reward": 0.5430287730693817, "critic_loss": 1.0831850474476814, "actor_loss": -49.287623794555664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004541635513306, "step": 117000}
{"episode_reward": 690.2234104118323, "episode": 118.0, "batch_reward": 0.5443334611356259, "critic_loss": 1.0694000269770623, "actor_loss": -49.44403043365479, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99532198905945, "step": 118000}
{"episode_reward": 677.6790433895086, "episode": 119.0, "batch_reward": 0.5442696527242661, "critic_loss": 1.051339598953724, "actor_loss": -49.56860757446289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990406036376953, "step": 119000}
{"episode_reward": 630.416339842955, "episode": 120.0, "batch_reward": 0.5457474776208401, "critic_loss": 1.087279540926218, "actor_loss": -49.47069971466065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997750520706177, "step": 120000}
{"episode_reward": 670.2728629973811, "episode": 121.0, "batch_reward": 0.5474264280200004, "critic_loss": 1.0275313264727592, "actor_loss": -49.78771082305908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.46476650238037, "step": 121000}
{"episode_reward": 643.7209918324944, "episode": 122.0, "batch_reward": 0.5483529766201973, "critic_loss": 1.0523393000364303, "actor_loss": -49.98727325439453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002434968948364, "step": 122000}
{"episode_reward": 707.0289960253574, "episode": 123.0, "batch_reward": 0.5490692602992058, "critic_loss": 1.025048726439476, "actor_loss": -50.044433624267576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.973706483840942, "step": 123000}
{"episode_reward": 594.6772251908715, "episode": 124.0, "batch_reward": 0.5485752769708634, "critic_loss": 1.0804694086313247, "actor_loss": -49.86808334350586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.971647024154663, "step": 124000}
{"episode_reward": 634.7751294938917, "episode": 125.0, "batch_reward": 0.5492374833524227, "critic_loss": 1.1283585642278195, "actor_loss": -50.01611534118652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.309399604797363, "step": 125000}
{"episode_reward": 703.116947011896, "episode": 126.0, "batch_reward": 0.5500799926817417, "critic_loss": 1.0660667754411697, "actor_loss": -50.23910120391846, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00740623474121, "step": 126000}
{"episode_reward": 654.6879646252273, "episode": 127.0, "batch_reward": 0.55236188185215, "critic_loss": 1.0608139550387858, "actor_loss": -50.26910143280029, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.975718021392822, "step": 127000}
{"episode_reward": 692.8738014824719, "episode": 128.0, "batch_reward": 0.5523214429616928, "critic_loss": 1.119207859992981, "actor_loss": -50.14440874481201, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97684597969055, "step": 128000}
{"episode_reward": 564.0471975809317, "episode": 129.0, "batch_reward": 0.5529740514755249, "critic_loss": 1.1936828892230988, "actor_loss": -50.308250732421875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004664659500122, "step": 129000}
{"episode_reward": 708.6733603405446, "episode": 130.0, "batch_reward": 0.5536980912387371, "critic_loss": 1.103987768292427, "actor_loss": -50.336713111877444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.001198053359985, "step": 130000}
{"episode_reward": 662.2224206691699, "episode": 131.0, "batch_reward": 0.5552798620462418, "critic_loss": 1.1233502115607261, "actor_loss": -50.315007736206056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.14694166183472, "step": 131000}
{"episode_reward": 677.3219000209518, "episode": 132.0, "batch_reward": 0.5558199698626995, "critic_loss": 1.1036187582910062, "actor_loss": -50.702781364440916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997857093811035, "step": 132000}
{"episode_reward": 660.9899644431222, "episode": 133.0, "batch_reward": 0.5576934891045093, "critic_loss": 1.1154716073274613, "actor_loss": -50.65504331970215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99816584587097, "step": 133000}
{"episode_reward": 688.4489329282078, "episode": 134.0, "batch_reward": 0.557492045968771, "critic_loss": 1.1044440907239914, "actor_loss": -50.837576942443846, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005106449127197, "step": 134000}
{"episode_reward": 678.8745237241324, "episode": 135.0, "batch_reward": 0.5580412841439247, "critic_loss": 1.090407911837101, "actor_loss": -50.90846483612061, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004873514175415, "step": 135000}
{"episode_reward": 680.839544363547, "episode": 136.0, "batch_reward": 0.5599871927499771, "critic_loss": 1.1519085120558739, "actor_loss": -50.99950145721436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00443387031555, "step": 136000}
{"episode_reward": 719.1532512967588, "episode": 137.0, "batch_reward": 0.5611313998401165, "critic_loss": 1.134882196187973, "actor_loss": -51.14079750823974, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00075602531433, "step": 137000}
{"episode_reward": 676.8785213284633, "episode": 138.0, "batch_reward": 0.561486052185297, "critic_loss": 1.16009548163414, "actor_loss": -51.166861694335935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99537491798401, "step": 138000}
{"episode_reward": 581.4928931160488, "episode": 139.0, "batch_reward": 0.5619931947588921, "critic_loss": 1.1584598311185836, "actor_loss": -51.06671755218506, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.011685132980347, "step": 139000}
{"episode_reward": 607.0285654122381, "episode": 140.0, "batch_reward": 0.5613936279118061, "critic_loss": 1.1732357795238495, "actor_loss": -51.15705014038086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99242329597473, "step": 140000}
{"episode_reward": 668.2757943442854, "episode": 141.0, "batch_reward": 0.5634097467660903, "critic_loss": 1.1608770736455918, "actor_loss": -51.264667617797855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.15582489967346, "step": 141000}
{"episode_reward": 710.3399481428268, "episode": 142.0, "batch_reward": 0.5640944365561008, "critic_loss": 1.2469560485482216, "actor_loss": -51.243018615722654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.994430780410767, "step": 142000}
{"episode_reward": 637.8175285538049, "episode": 143.0, "batch_reward": 0.5651056366860867, "critic_loss": 1.2559252008795738, "actor_loss": -51.358265518188475, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.012287378311157, "step": 143000}
{"episode_reward": 611.7696212875152, "episode": 144.0, "batch_reward": 0.565027514398098, "critic_loss": 1.247419153392315, "actor_loss": -51.41279490661621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0095272064209, "step": 144000}
{"episode_reward": 708.4118129952054, "episode": 145.0, "batch_reward": 0.5667141524553299, "critic_loss": 1.2175995749831199, "actor_loss": -51.51748261260986, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004382848739624, "step": 145000}
{"episode_reward": 628.9785971401847, "episode": 146.0, "batch_reward": 0.5666062076985836, "critic_loss": 1.4347325415611267, "actor_loss": -51.34880736541748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00638484954834, "step": 146000}
{"episode_reward": 618.626255965698, "episode": 147.0, "batch_reward": 0.5650938776135445, "critic_loss": 1.360253575503826, "actor_loss": -51.514978576660155, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004831075668335, "step": 147000}
{"episode_reward": 668.4021298493184, "episode": 148.0, "batch_reward": 0.567328744828701, "critic_loss": 1.393555080652237, "actor_loss": -51.5283376083374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.011178255081177, "step": 148000}
{"episode_reward": 335.7784760717285, "episode": 149.0, "batch_reward": 0.5661635047197342, "critic_loss": 1.3545807181000709, "actor_loss": -51.50482272338867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99687933921814, "step": 149000}
{"episode_reward": 724.136338840757, "episode": 150.0, "batch_reward": 0.5650619308054448, "critic_loss": 1.4156793060302735, "actor_loss": -51.29033003997803, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
