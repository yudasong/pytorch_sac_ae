{"episode_reward": 0.0, "episode": 1.0, "duration": 17.53283667564392, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.4969079494476318, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.2643564894929573, "critic_loss": 0.04006533070600015, "actor_loss": -21.830218672333118, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 61.44754147529602, "step": 3000}
{"episode_reward": 140.3267291972524, "episode": 4.0, "batch_reward": 0.23256077519059182, "critic_loss": 0.07793731319531798, "actor_loss": -18.928748787850143, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.851312398910522, "step": 4000}
{"episode_reward": 194.84302984326922, "episode": 5.0, "batch_reward": 0.2136130518913269, "critic_loss": 0.06353620035015047, "actor_loss": -17.509916519343854, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.16381025314331, "step": 5000}
{"episode_reward": 178.4148430742624, "episode": 6.0, "batch_reward": 0.20089467361569405, "critic_loss": 0.06710092351585627, "actor_loss": -17.46342925310135, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.732476234436035, "step": 6000}
{"episode_reward": 48.444888272852786, "episode": 7.0, "batch_reward": 0.17422678942233324, "critic_loss": 0.05709615052491426, "actor_loss": -15.13311929117143, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.706364393234253, "step": 7000}
{"episode_reward": 32.69560343771909, "episode": 8.0, "batch_reward": 0.15613062208890915, "critic_loss": 0.06608466936089098, "actor_loss": -13.901863627314567, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.998981714248657, "step": 8000}
{"episode_reward": 27.203201092420578, "episode": 9.0, "batch_reward": 0.14663908361643552, "critic_loss": 0.08639124724641442, "actor_loss": -14.259464893162251, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.18618893623352, "step": 9000}
{"episode_reward": 149.63573502262554, "episode": 10.0, "batch_reward": 0.14907766605168582, "critic_loss": 0.10135220951586962, "actor_loss": -14.671087659940124, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.70015001296997, "step": 10000}
{"episode_reward": 199.42978394734416, "episode": 11.0, "batch_reward": 0.15418452777713537, "critic_loss": 0.12443707595765591, "actor_loss": -14.779284991681576, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.79808473587036, "step": 11000}
{"episode_reward": 122.94277844021445, "episode": 12.0, "batch_reward": 0.15200785864144564, "critic_loss": 0.12344102207198739, "actor_loss": -14.51574812066555, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.9882493019104, "step": 12000}
{"episode_reward": 198.58211822485197, "episode": 13.0, "batch_reward": 0.15696498443931342, "critic_loss": 0.143322618432343, "actor_loss": -14.629487992525101, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.355862617492676, "step": 13000}
{"episode_reward": 235.2211615386755, "episode": 14.0, "batch_reward": 0.1663034000173211, "critic_loss": 0.1519588074311614, "actor_loss": -15.41860573720932, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.88162636756897, "step": 14000}
{"episode_reward": 287.6452879451483, "episode": 15.0, "batch_reward": 0.17112064576148986, "critic_loss": 0.15553047389537095, "actor_loss": -16.410672261714936, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.69407320022583, "step": 15000}
{"episode_reward": 182.04460932098894, "episode": 16.0, "batch_reward": 0.16816364412009716, "critic_loss": 0.14393730572611094, "actor_loss": -15.927634339332581, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.74066424369812, "step": 16000}
{"episode_reward": 84.74705134821288, "episode": 17.0, "batch_reward": 0.16547878703475, "critic_loss": 0.1475658060759306, "actor_loss": -15.69973400402069, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.346462965011597, "step": 17000}
{"episode_reward": 148.01712093818625, "episode": 18.0, "batch_reward": 0.1644877756536007, "critic_loss": 0.15425980516523122, "actor_loss": -15.724318670749664, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.678969144821167, "step": 18000}
{"episode_reward": 118.02837385439817, "episode": 19.0, "batch_reward": 0.1626969497129321, "critic_loss": 0.16962184388190507, "actor_loss": -15.592805475234986, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.066684246063232, "step": 19000}
{"episode_reward": 172.26623583915125, "episode": 20.0, "batch_reward": 0.1631990336701274, "critic_loss": 0.16909946271777154, "actor_loss": -16.603341268539427, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.424768686294556, "step": 20000}
{"episode_reward": 244.63575807266835, "episode": 21.0, "batch_reward": 0.16607311983406545, "critic_loss": 0.1877067245617509, "actor_loss": -15.625418077468872, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.4112491607666, "step": 21000}
{"episode_reward": 115.57461205175909, "episode": 22.0, "batch_reward": 0.16208584398776293, "critic_loss": 0.17625877276062965, "actor_loss": -16.725956007957457, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.48956036567688, "step": 22000}
{"episode_reward": 72.50703992384011, "episode": 23.0, "batch_reward": 0.16171867569535972, "critic_loss": 0.19223655105382204, "actor_loss": -16.375270703315735, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.700857877731323, "step": 23000}
{"episode_reward": 265.0862194706968, "episode": 24.0, "batch_reward": 0.16534974766522645, "critic_loss": 0.24348552166670562, "actor_loss": -16.756448256492614, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.622886657714844, "step": 24000}
{"episode_reward": 235.82949708136442, "episode": 25.0, "batch_reward": 0.16900439676642418, "critic_loss": 0.25179432234168053, "actor_loss": -17.274775593757628, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.74022340774536, "step": 25000}
{"episode_reward": 146.6282638610985, "episode": 26.0, "batch_reward": 0.16541266773641108, "critic_loss": 0.25874020179361107, "actor_loss": -16.731723218917846, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.924992322921753, "step": 26000}
{"episode_reward": 87.81255577298263, "episode": 27.0, "batch_reward": 0.16238118555396797, "critic_loss": 0.24965461219847201, "actor_loss": -16.5014942111969, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.855719566345215, "step": 27000}
{"episode_reward": 86.0673895957978, "episode": 28.0, "batch_reward": 0.16077358382940293, "critic_loss": 0.2851270071566105, "actor_loss": -16.82874590587616, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.109699487686157, "step": 28000}
{"episode_reward": 97.89273569977034, "episode": 29.0, "batch_reward": 0.1585284713432193, "critic_loss": 0.2907266715168953, "actor_loss": -16.736568698883058, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.611359119415283, "step": 29000}
{"episode_reward": 239.68754572660066, "episode": 30.0, "batch_reward": 0.16109913032501935, "critic_loss": 0.26764348942786453, "actor_loss": -16.529236999511717, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.691201210021973, "step": 30000}
{"episode_reward": 115.70978675863537, "episode": 31.0, "batch_reward": 0.1578980535119772, "critic_loss": 0.26053761930018665, "actor_loss": -16.729341482162475, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.11104869842529, "step": 31000}
{"episode_reward": 30.456401223521347, "episode": 32.0, "batch_reward": 0.15673808797448874, "critic_loss": 0.2547172936871648, "actor_loss": -17.047979808807373, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.685615301132202, "step": 32000}
{"episode_reward": 292.7467699531882, "episode": 33.0, "batch_reward": 0.16131173419207334, "critic_loss": 0.2768609558045864, "actor_loss": -17.37139228439331, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.183867931365967, "step": 33000}
{"episode_reward": 216.74188713133987, "episode": 34.0, "batch_reward": 0.16392756751179696, "critic_loss": 0.29030721670389176, "actor_loss": -17.2073344745636, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.05569577217102, "step": 34000}
{"episode_reward": 253.95253400317705, "episode": 35.0, "batch_reward": 0.16442653139680624, "critic_loss": 0.2935237499177456, "actor_loss": -17.580070459365846, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.043373823165894, "step": 35000}
{"episode_reward": 168.598812408214, "episode": 36.0, "batch_reward": 0.16518275133520366, "critic_loss": 0.30977989825606345, "actor_loss": -17.769108282089235, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.663588523864746, "step": 36000}
{"episode_reward": 228.98906573936802, "episode": 37.0, "batch_reward": 0.16840484806895256, "critic_loss": 0.3309724297821522, "actor_loss": -17.697691776275636, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.981260061264038, "step": 37000}
{"episode_reward": 352.15114349135933, "episode": 38.0, "batch_reward": 0.1729334236085415, "critic_loss": 0.315976840749383, "actor_loss": -18.34790630722046, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.05533003807068, "step": 38000}
{"episode_reward": 376.8919801327096, "episode": 39.0, "batch_reward": 0.1768692142367363, "critic_loss": 0.40033990244567397, "actor_loss": -18.641680067062378, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.947914600372314, "step": 39000}
{"episode_reward": 240.7673156003866, "episode": 40.0, "batch_reward": 0.17984528996050358, "critic_loss": 0.39520858469605447, "actor_loss": -19.01930750465393, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.01197862625122, "step": 40000}
{"episode_reward": 256.1617711905806, "episode": 41.0, "batch_reward": 0.18114056578278542, "critic_loss": 0.39048885709047315, "actor_loss": -18.885847412109374, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.175493478775024, "step": 41000}
{"episode_reward": 232.9139606347497, "episode": 42.0, "batch_reward": 0.18283149084448813, "critic_loss": 0.38899728608131406, "actor_loss": -19.155006879806518, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.984927654266357, "step": 42000}
{"episode_reward": 264.38450557947397, "episode": 43.0, "batch_reward": 0.1838491563871503, "critic_loss": 0.396655619814992, "actor_loss": -19.57412829208374, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.736966609954834, "step": 43000}
{"episode_reward": 214.18813391294998, "episode": 44.0, "batch_reward": 0.18395915865898133, "critic_loss": 0.39488845360279085, "actor_loss": -19.95010220527649, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.68909764289856, "step": 44000}
{"episode_reward": 299.4691446304835, "episode": 45.0, "batch_reward": 0.18821331265568733, "critic_loss": 0.3970121230483055, "actor_loss": -19.933693557739257, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.504476308822632, "step": 45000}
{"episode_reward": 242.11222614774908, "episode": 46.0, "batch_reward": 0.18777763025462627, "critic_loss": 0.3839247636646032, "actor_loss": -19.722019468307494, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.6250638961792, "step": 46000}
{"episode_reward": 104.39100987356589, "episode": 47.0, "batch_reward": 0.18562627765536308, "critic_loss": 0.3766934240013361, "actor_loss": -19.691563110351563, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.67136549949646, "step": 47000}
{"episode_reward": 123.22679198632085, "episode": 48.0, "batch_reward": 0.18420715540647506, "critic_loss": 0.34543483798205854, "actor_loss": -19.5378318939209, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.069432497024536, "step": 48000}
{"episode_reward": 85.9437114928261, "episode": 49.0, "batch_reward": 0.18299554681777955, "critic_loss": 0.37547729995846746, "actor_loss": -19.918051263809204, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.997310400009155, "step": 49000}
{"episode_reward": 129.31974241651827, "episode": 50.0, "batch_reward": 0.18145988415181638, "critic_loss": 0.36632430289685725, "actor_loss": -19.46121471786499, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.397286653518677, "step": 50000}
{"episode_reward": 110.90625054009129, "episode": 51.0, "batch_reward": 0.18282505038380623, "critic_loss": 0.37843129847943785, "actor_loss": -19.382678060531617, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.09125804901123, "step": 51000}
{"episode_reward": 377.7434206485635, "episode": 52.0, "batch_reward": 0.18638666495680808, "critic_loss": 0.39745225238800047, "actor_loss": -19.798487998962404, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.756128549575806, "step": 52000}
{"episode_reward": 405.59172477912773, "episode": 53.0, "batch_reward": 0.18961930361390114, "critic_loss": 0.4046661873757839, "actor_loss": -20.51029599761963, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.71433973312378, "step": 53000}
{"episode_reward": 305.83599879501963, "episode": 54.0, "batch_reward": 0.1911426827311516, "critic_loss": 0.45305303497612476, "actor_loss": -20.758112480163575, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.121337890625, "step": 54000}
{"episode_reward": 155.44940016369713, "episode": 55.0, "batch_reward": 0.18917733070254325, "critic_loss": 0.4145848383903503, "actor_loss": -19.990411031723024, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.13753628730774, "step": 55000}
{"episode_reward": 71.36670745363702, "episode": 56.0, "batch_reward": 0.1869788566082716, "critic_loss": 0.3837496559172869, "actor_loss": -19.869793127059936, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.81257462501526, "step": 56000}
{"episode_reward": 86.44162988288507, "episode": 57.0, "batch_reward": 0.18647272978723048, "critic_loss": 0.37934032671153545, "actor_loss": -19.704173149108886, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.908103466033936, "step": 57000}
{"episode_reward": 153.9640849729037, "episode": 58.0, "batch_reward": 0.18729721470177174, "critic_loss": 0.3767747829258442, "actor_loss": -20.24430364227295, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.068325757980347, "step": 58000}
{"episode_reward": 430.41357076987254, "episode": 59.0, "batch_reward": 0.19005240516364574, "critic_loss": 0.3770103102773428, "actor_loss": -20.119894563674926, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.190068006515503, "step": 59000}
{"episode_reward": 346.87092686622714, "episode": 60.0, "batch_reward": 0.1931347960829735, "critic_loss": 0.40516964718699455, "actor_loss": -20.71275143623352, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.742659091949463, "step": 60000}
{"episode_reward": 359.80085554976347, "episode": 61.0, "batch_reward": 0.1975058549642563, "critic_loss": 0.37902530489861963, "actor_loss": -20.819344594955446, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.91877841949463, "step": 61000}
{"episode_reward": 409.94025907018266, "episode": 62.0, "batch_reward": 0.20057222385704518, "critic_loss": 0.39556024691462516, "actor_loss": -21.424620014190673, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.68145775794983, "step": 62000}
{"episode_reward": 352.5410208222449, "episode": 63.0, "batch_reward": 0.20130110651254654, "critic_loss": 0.3939147865176201, "actor_loss": -20.966256387710573, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.787878274917603, "step": 63000}
{"episode_reward": 152.12925364954975, "episode": 64.0, "batch_reward": 0.20201275025308132, "critic_loss": 0.40087807051837443, "actor_loss": -21.42441639328003, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.454128980636597, "step": 64000}
{"episode_reward": 370.92153054798274, "episode": 65.0, "batch_reward": 0.20383638083934785, "critic_loss": 0.38389581374824044, "actor_loss": -21.4877776222229, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.694459676742554, "step": 65000}
{"episode_reward": 219.78679274030097, "episode": 66.0, "batch_reward": 0.20491242541372776, "critic_loss": 0.36468446999788284, "actor_loss": -21.651859449386595, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.551007986068726, "step": 66000}
{"episode_reward": 440.6395813723108, "episode": 67.0, "batch_reward": 0.20749793513119222, "critic_loss": 0.3817738448083401, "actor_loss": -21.99093163871765, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.87301278114319, "step": 67000}
{"episode_reward": 195.73932925172824, "episode": 68.0, "batch_reward": 0.20616320185363293, "critic_loss": 0.40417102974653246, "actor_loss": -21.961592443466188, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.670165538787842, "step": 68000}
{"episode_reward": 92.12977277625379, "episode": 69.0, "batch_reward": 0.20426244680583477, "critic_loss": 0.3606948586553335, "actor_loss": -21.386569452285766, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.003187656402588, "step": 69000}
{"episode_reward": 140.38932304386623, "episode": 70.0, "batch_reward": 0.2048496317565441, "critic_loss": 0.37547634775936606, "actor_loss": -21.487251766204835, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.093962907791138, "step": 70000}
{"episode_reward": 301.03720700043704, "episode": 71.0, "batch_reward": 0.2067825672775507, "critic_loss": 0.4019535694718361, "actor_loss": -21.465032371520998, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.16274333000183, "step": 71000}
{"episode_reward": 355.7842656489745, "episode": 72.0, "batch_reward": 0.20784050107002258, "critic_loss": 0.40460239474475385, "actor_loss": -21.631205375671385, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.945385217666626, "step": 72000}
{"episode_reward": 427.52587374832694, "episode": 73.0, "batch_reward": 0.2118429732620716, "critic_loss": 0.3865980594605207, "actor_loss": -22.004510162353515, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.826371431350708, "step": 73000}
{"episode_reward": 256.47056515675786, "episode": 74.0, "batch_reward": 0.21235532063245774, "critic_loss": 0.36308574011921885, "actor_loss": -22.053000263214113, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.72388505935669, "step": 74000}
{"episode_reward": 465.58193781521055, "episode": 75.0, "batch_reward": 0.21528568084537983, "critic_loss": 0.413124039888382, "actor_loss": -22.333209239959718, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.790110111236572, "step": 75000}
{"episode_reward": 352.80753692499275, "episode": 76.0, "batch_reward": 0.21665946166217326, "critic_loss": 0.40842116586863997, "actor_loss": -22.252454416275025, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.507742643356323, "step": 76000}
{"episode_reward": 400.2886989496614, "episode": 77.0, "batch_reward": 0.21941567978262902, "critic_loss": 0.43176376758515833, "actor_loss": -22.692397514343263, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.681975603103638, "step": 77000}
{"episode_reward": 238.8939736049982, "episode": 78.0, "batch_reward": 0.2184821941703558, "critic_loss": 0.38767434532940387, "actor_loss": -22.379953050613402, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.591896772384644, "step": 78000}
{"episode_reward": 84.68165378183552, "episode": 79.0, "batch_reward": 0.21981859317421912, "critic_loss": 0.4231114848703146, "actor_loss": -22.873122840881347, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.605059385299683, "step": 79000}
{"episode_reward": 510.51005117136526, "episode": 80.0, "batch_reward": 0.22032052679359912, "critic_loss": 0.4101490461975336, "actor_loss": -22.90062180328369, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.677852630615234, "step": 80000}
{"episode_reward": 98.85243671069553, "episode": 81.0, "batch_reward": 0.22167081435024738, "critic_loss": 0.40755029052495956, "actor_loss": -22.879536392211914, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.43184781074524, "step": 81000}
{"episode_reward": 544.5721515807896, "episode": 82.0, "batch_reward": 0.22292538841068746, "critic_loss": 0.41707610386610033, "actor_loss": -22.788737480163576, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.8247287273407, "step": 82000}
{"episode_reward": 151.25419764012528, "episode": 83.0, "batch_reward": 0.22341571718454362, "critic_loss": 0.4160390224903822, "actor_loss": -23.018828956604004, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.094040393829346, "step": 83000}
{"episode_reward": 153.3883143916022, "episode": 84.0, "batch_reward": 0.22277858726680277, "critic_loss": 0.4072117969840765, "actor_loss": -23.005263317108156, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.092854499816895, "step": 84000}
{"episode_reward": 309.37361467243113, "episode": 85.0, "batch_reward": 0.22364779892563819, "critic_loss": 0.41275207430124283, "actor_loss": -22.806947898864745, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.802500009536743, "step": 85000}
{"episode_reward": 309.11905897980324, "episode": 86.0, "batch_reward": 0.2249112348407507, "critic_loss": 0.4731309956908226, "actor_loss": -23.002682384490967, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.113203287124634, "step": 86000}
{"episode_reward": 417.4933559252553, "episode": 87.0, "batch_reward": 0.22646102301776408, "critic_loss": 0.4220757928341627, "actor_loss": -23.197383319854737, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.94063901901245, "step": 87000}
{"episode_reward": 322.31390076496507, "episode": 88.0, "batch_reward": 0.2278840081244707, "critic_loss": 0.41172322024405, "actor_loss": -23.27589991760254, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.908829927444458, "step": 88000}
{"episode_reward": 474.439114969405, "episode": 89.0, "batch_reward": 0.23126162157952784, "critic_loss": 0.40531110963225364, "actor_loss": -23.156123584747313, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.252780199050903, "step": 89000}
{"episode_reward": 471.25117069571365, "episode": 90.0, "batch_reward": 0.23461160358786584, "critic_loss": 0.40401584149897096, "actor_loss": -23.47070291519165, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.833942651748657, "step": 90000}
{"episode_reward": 432.7626222694214, "episode": 91.0, "batch_reward": 0.23713111117482186, "critic_loss": 0.43082549101114276, "actor_loss": -23.606815547943114, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.239779472351074, "step": 91000}
{"episode_reward": 480.5282103077021, "episode": 92.0, "batch_reward": 0.23862638713419437, "critic_loss": 0.41127956576645375, "actor_loss": -24.049827136993407, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.971408367156982, "step": 92000}
{"episode_reward": 506.519869140638, "episode": 93.0, "batch_reward": 0.2421736551374197, "critic_loss": 0.4191008248180151, "actor_loss": -24.000951877593995, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.161647081375122, "step": 93000}
{"episode_reward": 536.5942704287781, "episode": 94.0, "batch_reward": 0.24360174052417277, "critic_loss": 0.4314065470248461, "actor_loss": -24.3242378616333, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.836639642715454, "step": 94000}
{"episode_reward": 156.76546435527243, "episode": 95.0, "batch_reward": 0.24137333507835865, "critic_loss": 0.4193396893292666, "actor_loss": -24.374242095947267, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.091966152191162, "step": 95000}
{"episode_reward": 130.68176119042158, "episode": 96.0, "batch_reward": 0.24286197051405906, "critic_loss": 0.4460271345078945, "actor_loss": -23.99176431274414, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.986999988555908, "step": 96000}
{"episode_reward": 520.2795153899333, "episode": 97.0, "batch_reward": 0.24474767614901066, "critic_loss": 0.44352486415207387, "actor_loss": -24.074498340606688, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.844705820083618, "step": 97000}
{"episode_reward": 135.5966370142891, "episode": 98.0, "batch_reward": 0.24393575803935527, "critic_loss": 0.4379672444164753, "actor_loss": -24.51086487197876, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.703386783599854, "step": 98000}
{"episode_reward": 448.9694633161121, "episode": 99.0, "batch_reward": 0.2464717354476452, "critic_loss": 0.44480213513970374, "actor_loss": -24.539701957702636, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.479674339294434, "step": 99000}
{"episode_reward": 533.9742384360832, "episode": 100.0, "batch_reward": 0.24966264453530312, "critic_loss": 0.4233560899198055, "actor_loss": -24.705687210083006, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.70764684677124, "step": 100000}
{"episode_reward": 477.100770138408, "episode": 101.0, "batch_reward": 0.2513050821274519, "critic_loss": 0.4146384302377701, "actor_loss": -24.79415996170044, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.46338772773743, "step": 101000}
{"episode_reward": 457.8004262027741, "episode": 102.0, "batch_reward": 0.2529874332547188, "critic_loss": 0.4314736558943987, "actor_loss": -25.15689775085449, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.706502676010132, "step": 102000}
{"episode_reward": 156.88702737330934, "episode": 103.0, "batch_reward": 0.2533170976936817, "critic_loss": 0.4321411868929863, "actor_loss": -25.082956645965577, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.73501205444336, "step": 103000}
{"episode_reward": 488.5743757970824, "episode": 104.0, "batch_reward": 0.2549428691416979, "critic_loss": 0.43910443134605887, "actor_loss": -24.92923461151123, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.137267589569092, "step": 104000}
{"episode_reward": 476.43167594430753, "episode": 105.0, "batch_reward": 0.25642325076460837, "critic_loss": 0.4309061033278704, "actor_loss": -25.22878849029541, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.097006797790527, "step": 105000}
{"episode_reward": 281.08648804027, "episode": 106.0, "batch_reward": 0.2568795426040888, "critic_loss": 0.4500763169378042, "actor_loss": -25.107667850494384, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.319724321365356, "step": 106000}
{"episode_reward": 308.39665104817453, "episode": 107.0, "batch_reward": 0.25728410068154334, "critic_loss": 0.4665624284446239, "actor_loss": -25.197331447601318, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.14598512649536, "step": 107000}
{"episode_reward": 274.24283355081246, "episode": 108.0, "batch_reward": 0.25847828735411166, "critic_loss": 0.4925158231556416, "actor_loss": -25.660154582977295, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.741121768951416, "step": 108000}
{"episode_reward": 561.0423620205373, "episode": 109.0, "batch_reward": 0.2614942538142204, "critic_loss": 0.4572066918462515, "actor_loss": -25.579805313110352, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.44050145149231, "step": 109000}
{"episode_reward": 445.2399155733877, "episode": 110.0, "batch_reward": 0.26275251515209674, "critic_loss": 0.4695719810575247, "actor_loss": -25.915490325927735, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.915103435516357, "step": 110000}
{"episode_reward": 452.8227356276412, "episode": 111.0, "batch_reward": 0.2643575664907694, "critic_loss": 0.4490845643132925, "actor_loss": -25.901358901977538, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.23382568359375, "step": 111000}
{"episode_reward": 478.0613966420412, "episode": 112.0, "batch_reward": 0.2664769578129053, "critic_loss": 0.44742611461877824, "actor_loss": -26.37114142227173, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.037250518798828, "step": 112000}
{"episode_reward": 564.5753455890351, "episode": 113.0, "batch_reward": 0.26962234699726106, "critic_loss": 0.4444552371203899, "actor_loss": -26.1515224571228, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.670289278030396, "step": 113000}
{"episode_reward": 461.7517877242132, "episode": 114.0, "batch_reward": 0.2711216967403889, "critic_loss": 0.4481436764448881, "actor_loss": -26.589241939544678, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.627851963043213, "step": 114000}
{"episode_reward": 468.4026772260271, "episode": 115.0, "batch_reward": 0.273159187078476, "critic_loss": 0.445391936480999, "actor_loss": -26.6776388092041, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.434457778930664, "step": 115000}
{"episode_reward": 582.219764220457, "episode": 116.0, "batch_reward": 0.2748034542500973, "critic_loss": 0.44899261443316935, "actor_loss": -26.943359123229982, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.477346658706665, "step": 116000}
{"episode_reward": 444.48210199374296, "episode": 117.0, "batch_reward": 0.27651587645709513, "critic_loss": 0.47191752947866916, "actor_loss": -26.84181567764282, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.658029317855835, "step": 117000}
{"episode_reward": 517.9675100845948, "episode": 118.0, "batch_reward": 0.2783170863389969, "critic_loss": 0.4601921559125185, "actor_loss": -27.05050022125244, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.977076292037964, "step": 118000}
{"episode_reward": 387.9830372365067, "episode": 119.0, "batch_reward": 0.2797149339914322, "critic_loss": 0.4404308432340622, "actor_loss": -27.13424615097046, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.79630708694458, "step": 119000}
{"episode_reward": 554.6627829581129, "episode": 120.0, "batch_reward": 0.2806484318226576, "critic_loss": 0.4770141553580761, "actor_loss": -27.18808518218994, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.657336235046387, "step": 120000}
{"episode_reward": 343.7628243466765, "episode": 121.0, "batch_reward": 0.28246193356812, "critic_loss": 0.48800424142181875, "actor_loss": -27.339883869171143, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.601319313049316, "step": 121000}
{"episode_reward": 555.6469822672868, "episode": 122.0, "batch_reward": 0.28528095366060735, "critic_loss": 0.4617059274613857, "actor_loss": -27.811312839508055, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.99687385559082, "step": 122000}
{"episode_reward": 594.011787676393, "episode": 123.0, "batch_reward": 0.28643485155701637, "critic_loss": 0.5015935237109661, "actor_loss": -27.930184494018555, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.046454191207886, "step": 123000}
{"episode_reward": 351.40475317961676, "episode": 124.0, "batch_reward": 0.28762708592414854, "critic_loss": 0.48179433473944666, "actor_loss": -28.14409073638916, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.152701377868652, "step": 124000}
{"episode_reward": 526.3745177298231, "episode": 125.0, "batch_reward": 0.2885055301487446, "critic_loss": 0.4923524225056171, "actor_loss": -28.027602550506593, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.12714719772339, "step": 125000}
{"episode_reward": 467.8953019043727, "episode": 126.0, "batch_reward": 0.29197986476123333, "critic_loss": 0.5040903874337673, "actor_loss": -28.451191165924072, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.71376347541809, "step": 126000}
{"episode_reward": 564.9736671158839, "episode": 127.0, "batch_reward": 0.2936816467344761, "critic_loss": 0.5138875546455384, "actor_loss": -28.665415348052978, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.632904291152954, "step": 127000}
{"episode_reward": 541.1005748051723, "episode": 128.0, "batch_reward": 0.29578284738957883, "critic_loss": 0.47862971436977386, "actor_loss": -28.829976543426515, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.80052900314331, "step": 128000}
{"episode_reward": 557.8069209102424, "episode": 129.0, "batch_reward": 0.2971608162224293, "critic_loss": 0.4849416227191687, "actor_loss": -28.81872445678711, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.28684663772583, "step": 129000}
{"episode_reward": 540.195708686975, "episode": 130.0, "batch_reward": 0.29931758795678615, "critic_loss": 0.485047038435936, "actor_loss": -29.005691913604736, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.152236461639404, "step": 130000}
{"episode_reward": 563.2825826866724, "episode": 131.0, "batch_reward": 0.3009700858145952, "critic_loss": 0.5104384030103684, "actor_loss": -28.951943870544433, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.5152587890625, "step": 131000}
{"episode_reward": 134.02330600822097, "episode": 132.0, "batch_reward": 0.3004053805470467, "critic_loss": 0.5186335479319095, "actor_loss": -29.011532360076906, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.69802498817444, "step": 132000}
{"episode_reward": 509.4206192710833, "episode": 133.0, "batch_reward": 0.3024862783998251, "critic_loss": 0.4966164024323225, "actor_loss": -29.08036526107788, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.97345495223999, "step": 133000}
{"episode_reward": 623.2837374586654, "episode": 134.0, "batch_reward": 0.30381547871232034, "critic_loss": 0.4649968892931938, "actor_loss": -29.37465508270264, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.69746708869934, "step": 134000}
{"episode_reward": 622.889638354763, "episode": 135.0, "batch_reward": 0.305762728407979, "critic_loss": 0.46721422831714154, "actor_loss": -29.741450496673583, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.716167449951172, "step": 135000}
{"episode_reward": 546.1998876049861, "episode": 136.0, "batch_reward": 0.3081063590347767, "critic_loss": 0.444232455521822, "actor_loss": -29.913792251586916, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.29461979866028, "step": 136000}
{"episode_reward": 595.598118390063, "episode": 137.0, "batch_reward": 0.31031760239601136, "critic_loss": 0.47973665671050547, "actor_loss": -29.914645156860352, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.08685302734375, "step": 137000}
{"episode_reward": 557.9169731661367, "episode": 138.0, "batch_reward": 0.3119852566719055, "critic_loss": 0.49811558540165424, "actor_loss": -30.122172710418702, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.836339950561523, "step": 138000}
{"episode_reward": 598.2755550537586, "episode": 139.0, "batch_reward": 0.3142709641456604, "critic_loss": 0.4830240559577942, "actor_loss": -30.213082313537598, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.74423360824585, "step": 139000}
{"episode_reward": 393.6162661161284, "episode": 140.0, "batch_reward": 0.3135602233707905, "critic_loss": 0.4679276528507471, "actor_loss": -30.33883907699585, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.508853673934937, "step": 140000}
{"episode_reward": 611.0345926209245, "episode": 141.0, "batch_reward": 0.31763149723410605, "critic_loss": 0.45337065663933757, "actor_loss": -30.651689807891845, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.503466844558716, "step": 141000}
{"episode_reward": 602.8952523495983, "episode": 142.0, "batch_reward": 0.3188650943338871, "critic_loss": 0.5130668966025114, "actor_loss": -30.740991436004638, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.03421950340271, "step": 142000}
{"episode_reward": 591.146380508042, "episode": 143.0, "batch_reward": 0.3201192515194416, "critic_loss": 0.48709040017426014, "actor_loss": -30.982265560150147, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.997190713882446, "step": 143000}
{"episode_reward": 611.8221076338463, "episode": 144.0, "batch_reward": 0.3226504486203194, "critic_loss": 0.46743535409867765, "actor_loss": -31.148392417907715, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.271753072738647, "step": 144000}
{"episode_reward": 589.6523829599163, "episode": 145.0, "batch_reward": 0.324028933852911, "critic_loss": 0.46846971049904823, "actor_loss": -31.46011710357666, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.99712371826172, "step": 145000}
{"episode_reward": 580.683942936348, "episode": 146.0, "batch_reward": 0.325463650226593, "critic_loss": 0.4822314955592156, "actor_loss": -31.29094041824341, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.90001916885376, "step": 146000}
{"episode_reward": 636.1895385932863, "episode": 147.0, "batch_reward": 0.32789171373844145, "critic_loss": 0.4922476350963116, "actor_loss": -31.75110292816162, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.313419342041016, "step": 147000}
{"episode_reward": 574.4942151065482, "episode": 148.0, "batch_reward": 0.33143676540255546, "critic_loss": 0.476839063346386, "actor_loss": -31.896766185760498, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.90682053565979, "step": 148000}
{"episode_reward": 613.0790186688628, "episode": 149.0, "batch_reward": 0.33309337857365606, "critic_loss": 0.48815715335309506, "actor_loss": -32.196177597045896, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.41718554496765, "step": 149000}
{"episode_reward": 551.5700185270862, "episode": 150.0, "batch_reward": 0.3328102915585041, "critic_loss": 0.5060991802066565, "actor_loss": -32.16083767318725, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
