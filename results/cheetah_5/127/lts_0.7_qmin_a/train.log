{"episode_reward": 0.0, "episode": 1.0, "duration": 17.253456592559814, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.537909984588623, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.2655610109158618, "critic_loss": 0.04922867524144142, "actor_loss": -29.266583081276693, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 61.88082551956177, "step": 3000}
{"episode_reward": 77.16848847483399, "episode": 4.0, "batch_reward": 0.2038955257833004, "critic_loss": 0.07725537889823318, "actor_loss": -22.067500452637674, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.570767164230347, "step": 4000}
{"episode_reward": 117.87516304076208, "episode": 5.0, "batch_reward": 0.1855817464441061, "critic_loss": 0.07963944093883038, "actor_loss": -19.67935144928843, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.2626531124115, "step": 5000}
{"episode_reward": 171.27946260056362, "episode": 6.0, "batch_reward": 0.18522548711299897, "critic_loss": 0.09026769502460956, "actor_loss": -20.383682897135614, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.820967435836792, "step": 6000}
{"episode_reward": 165.36572786757785, "episode": 7.0, "batch_reward": 0.18072090250998735, "critic_loss": 0.11484111983701586, "actor_loss": -19.419238011568783, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.99669647216797, "step": 7000}
{"episode_reward": 198.64141460771955, "episode": 8.0, "batch_reward": 0.18921722815930844, "critic_loss": 0.12872110279276966, "actor_loss": -20.435513400286435, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.617069244384766, "step": 8000}
{"episode_reward": 306.97016411430707, "episode": 9.0, "batch_reward": 0.19026278749108314, "critic_loss": 0.12106444802880287, "actor_loss": -20.28628819385171, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.95530867576599, "step": 9000}
{"episode_reward": 32.87425889723902, "episode": 10.0, "batch_reward": 0.18325231878459453, "critic_loss": 0.12891361802071333, "actor_loss": -20.519552211523056, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.22818160057068, "step": 10000}
{"episode_reward": 228.7487956097923, "episode": 11.0, "batch_reward": 0.18794812339544295, "critic_loss": 0.14489522071927785, "actor_loss": -20.114004185914993, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.2926824092865, "step": 11000}
{"episode_reward": 145.86341850264762, "episode": 12.0, "batch_reward": 0.18356216587126256, "critic_loss": 0.1439692745655775, "actor_loss": -19.988832151889802, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.99182653427124, "step": 12000}
{"episode_reward": 202.04240094949859, "episode": 13.0, "batch_reward": 0.1835944268256426, "critic_loss": 0.14263974514603614, "actor_loss": -19.49358840060234, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.091007232666016, "step": 13000}
{"episode_reward": 136.66728753078854, "episode": 14.0, "batch_reward": 0.18099820785224438, "critic_loss": 0.14203908424824477, "actor_loss": -19.17077703475952, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.00199055671692, "step": 14000}
{"episode_reward": 230.44871604300943, "episode": 15.0, "batch_reward": 0.18508299140632153, "critic_loss": 0.15358290255069731, "actor_loss": -19.766689579486847, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.92876648902893, "step": 15000}
{"episode_reward": 153.61760196568773, "episode": 16.0, "batch_reward": 0.1852969446927309, "critic_loss": 0.14863016699254514, "actor_loss": -20.26934482240677, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.595772743225098, "step": 16000}
{"episode_reward": 266.71197468594255, "episode": 17.0, "batch_reward": 0.18638418547809124, "critic_loss": 0.1462552686110139, "actor_loss": -19.42662552642822, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.86563491821289, "step": 17000}
{"episode_reward": 133.67980098184955, "episode": 18.0, "batch_reward": 0.18504267619550227, "critic_loss": 0.1490080051496625, "actor_loss": -19.64016295146942, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.939741134643555, "step": 18000}
{"episode_reward": 208.2722616318861, "episode": 19.0, "batch_reward": 0.18542030027508735, "critic_loss": 0.1561508930772543, "actor_loss": -19.8299260225296, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.716288805007935, "step": 19000}
{"episode_reward": 138.0914723869427, "episode": 20.0, "batch_reward": 0.18260514160990715, "critic_loss": 0.17187306368350982, "actor_loss": -20.41509133720398, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.851004362106323, "step": 20000}
{"episode_reward": 126.06459324296102, "episode": 21.0, "batch_reward": 0.17895509630441667, "critic_loss": 0.19933380433171988, "actor_loss": -18.83360223484039, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.88467741012573, "step": 21000}
{"episode_reward": 92.96034632743489, "episode": 22.0, "batch_reward": 0.17880500835180282, "critic_loss": 0.19521978244185448, "actor_loss": -19.25740686893463, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.023422241210938, "step": 22000}
{"episode_reward": 305.0162078133822, "episode": 23.0, "batch_reward": 0.18105408525466918, "critic_loss": 0.18832657489180565, "actor_loss": -19.01024563217163, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.792791604995728, "step": 23000}
{"episode_reward": 102.31092795166519, "episode": 24.0, "batch_reward": 0.1774165318161249, "critic_loss": 0.1986326917335391, "actor_loss": -19.363230216026306, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.011094570159912, "step": 24000}
{"episode_reward": 136.22077717529584, "episode": 25.0, "batch_reward": 0.1771602714806795, "critic_loss": 0.2217560494914651, "actor_loss": -19.661354037284852, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.848922967910767, "step": 25000}
{"episode_reward": 149.36074411525468, "episode": 26.0, "batch_reward": 0.1782182469367981, "critic_loss": 0.20898157196491957, "actor_loss": -19.168387447357176, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.621429920196533, "step": 26000}
{"episode_reward": 358.2920551532548, "episode": 27.0, "batch_reward": 0.18431778258085252, "critic_loss": 0.25534562493115665, "actor_loss": -19.83399858856201, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.808003187179565, "step": 27000}
{"episode_reward": 282.22040940457265, "episode": 28.0, "batch_reward": 0.18697246700525283, "critic_loss": 0.27238208793103696, "actor_loss": -19.98500957584381, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.83281373977661, "step": 28000}
{"episode_reward": 157.6630600781883, "episode": 29.0, "batch_reward": 0.18642585101723672, "critic_loss": 0.2827540475279093, "actor_loss": -20.14021455669403, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.803831100463867, "step": 29000}
{"episode_reward": 208.04271442219942, "episode": 30.0, "batch_reward": 0.18721383181214332, "critic_loss": 0.3000100305527449, "actor_loss": -19.781542680740355, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.700165271759033, "step": 30000}
{"episode_reward": 177.15414129078977, "episode": 31.0, "batch_reward": 0.18830460284650324, "critic_loss": 0.32218925066292287, "actor_loss": -19.760384815216064, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.55776524543762, "step": 31000}
{"episode_reward": 368.6582203198363, "episode": 32.0, "batch_reward": 0.19381719720363616, "critic_loss": 0.33425090116262435, "actor_loss": -20.291114065170287, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.219438076019287, "step": 32000}
{"episode_reward": 247.00055341505848, "episode": 33.0, "batch_reward": 0.19368426702916622, "critic_loss": 0.33121866147220136, "actor_loss": -20.519878797531128, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.193897485733032, "step": 33000}
{"episode_reward": 182.08455389040694, "episode": 34.0, "batch_reward": 0.1938207156062126, "critic_loss": 0.3449844242185354, "actor_loss": -20.404698095321656, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.235982418060303, "step": 34000}
{"episode_reward": 188.01353737500958, "episode": 35.0, "batch_reward": 0.1923772723376751, "critic_loss": 0.37499797166883947, "actor_loss": -20.35458669471741, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.175039529800415, "step": 35000}
{"episode_reward": 119.10190311369726, "episode": 36.0, "batch_reward": 0.19071894659101962, "critic_loss": 0.36243064123392105, "actor_loss": -20.691360399246214, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.968533754348755, "step": 36000}
{"episode_reward": 245.56489292651574, "episode": 37.0, "batch_reward": 0.19270426587760447, "critic_loss": 0.35525755760073663, "actor_loss": -20.205445766448975, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.02857542037964, "step": 37000}
{"episode_reward": 206.61792246144262, "episode": 38.0, "batch_reward": 0.19339004778861998, "critic_loss": 0.35400452868640425, "actor_loss": -19.967511381149293, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.25856852531433, "step": 38000}
{"episode_reward": 201.80417328164938, "episode": 39.0, "batch_reward": 0.1912145107537508, "critic_loss": 0.3630056198835373, "actor_loss": -20.202096822738646, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.19269108772278, "step": 39000}
{"episode_reward": 89.62867829421347, "episode": 40.0, "batch_reward": 0.19192483867704868, "critic_loss": 0.38423968529701236, "actor_loss": -20.38973969268799, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.11117649078369, "step": 40000}
{"episode_reward": 278.7712725637385, "episode": 41.0, "batch_reward": 0.19301117466390133, "critic_loss": 0.39738517040014265, "actor_loss": -20.3130426197052, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.36155462265015, "step": 41000}
{"episode_reward": 191.2416061823314, "episode": 42.0, "batch_reward": 0.19487464646995067, "critic_loss": 0.3994141171723604, "actor_loss": -20.473221681594847, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.933119297027588, "step": 42000}
{"episode_reward": 359.0798747274305, "episode": 43.0, "batch_reward": 0.19653439868986605, "critic_loss": 0.401720046594739, "actor_loss": -20.666378313064577, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.280648469924927, "step": 43000}
{"episode_reward": 226.34842780180497, "episode": 44.0, "batch_reward": 0.19785315361618996, "critic_loss": 0.3656296003907919, "actor_loss": -21.58551776313782, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.204643726348877, "step": 44000}
{"episode_reward": 336.85875843718793, "episode": 45.0, "batch_reward": 0.20091024006903171, "critic_loss": 0.3693190664499998, "actor_loss": -21.49216081047058, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.95189666748047, "step": 45000}
{"episode_reward": 272.56541928268, "episode": 46.0, "batch_reward": 0.20050855340063573, "critic_loss": 0.3672647712826729, "actor_loss": -20.88931948852539, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.40842604637146, "step": 46000}
{"episode_reward": 67.33437728090469, "episode": 47.0, "batch_reward": 0.2010113173276186, "critic_loss": 0.3628846917897463, "actor_loss": -21.245519086837767, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.380738496780396, "step": 47000}
{"episode_reward": 390.39007438050544, "episode": 48.0, "batch_reward": 0.20199399462342263, "critic_loss": 0.36978110329806807, "actor_loss": -21.195983182907103, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.90959358215332, "step": 48000}
{"episode_reward": 99.91774207822273, "episode": 49.0, "batch_reward": 0.20248699130117892, "critic_loss": 0.3705814463496208, "actor_loss": -21.960640256881714, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.063267946243286, "step": 49000}
{"episode_reward": 359.8197622852739, "episode": 50.0, "batch_reward": 0.20268657565116882, "critic_loss": 0.3541513751000166, "actor_loss": -21.5495697555542, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.60004758834839, "step": 50000}
{"episode_reward": 75.54174832137963, "episode": 51.0, "batch_reward": 0.20242345386743546, "critic_loss": 0.3811783102601767, "actor_loss": -21.321910785675048, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.34143853187561, "step": 51000}
{"episode_reward": 246.25050521416318, "episode": 52.0, "batch_reward": 0.2042885501086712, "critic_loss": 0.4075454370975494, "actor_loss": -21.598344772338866, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.18459677696228, "step": 52000}
{"episode_reward": 253.67951156083106, "episode": 53.0, "batch_reward": 0.20500351160764693, "critic_loss": 0.39242518877983096, "actor_loss": -21.935938760757445, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.938366651535034, "step": 53000}
{"episode_reward": 349.1599617590998, "episode": 54.0, "batch_reward": 0.20479683609306812, "critic_loss": 0.4118290793299675, "actor_loss": -22.02245185661316, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.385692358016968, "step": 54000}
{"episode_reward": 61.66752839300115, "episode": 55.0, "batch_reward": 0.20234919157624245, "critic_loss": 0.43459766237437725, "actor_loss": -21.59393636894226, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.6824631690979, "step": 55000}
{"episode_reward": 39.953784360956995, "episode": 56.0, "batch_reward": 0.20175062742829322, "critic_loss": 0.4395566246658564, "actor_loss": -21.413072832107545, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.886213779449463, "step": 56000}
{"episode_reward": 273.32177790971235, "episode": 57.0, "batch_reward": 0.20250839883089067, "critic_loss": 0.42343165892362594, "actor_loss": -21.483085289001465, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.21566152572632, "step": 57000}
{"episode_reward": 335.38500515297295, "episode": 58.0, "batch_reward": 0.20388001328706742, "critic_loss": 0.4339319416433573, "actor_loss": -21.669523763656617, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.00745940208435, "step": 58000}
{"episode_reward": 192.39090398187645, "episode": 59.0, "batch_reward": 0.20248558208346368, "critic_loss": 0.47289263892173766, "actor_loss": -21.29281781578064, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.83937954902649, "step": 59000}
{"episode_reward": 49.46830818139208, "episode": 60.0, "batch_reward": 0.20163839738070966, "critic_loss": 0.44706895492970944, "actor_loss": -21.40738218688965, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.88427972793579, "step": 60000}
{"episode_reward": 263.5769113266924, "episode": 61.0, "batch_reward": 0.20370953300595285, "critic_loss": 0.519006790086627, "actor_loss": -21.42478997039795, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.6024386882782, "step": 61000}
{"episode_reward": 440.7375327002863, "episode": 62.0, "batch_reward": 0.20721192294359206, "critic_loss": 0.4736823276728392, "actor_loss": -21.876128547668458, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.489935159683228, "step": 62000}
{"episode_reward": 362.49864631174546, "episode": 63.0, "batch_reward": 0.20754527889192104, "critic_loss": 0.49136304676532744, "actor_loss": -21.94473217391968, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.025599718093872, "step": 63000}
{"episode_reward": 73.78394084476591, "episode": 64.0, "batch_reward": 0.20782625161111354, "critic_loss": 0.4736556952744722, "actor_loss": -21.846002798080445, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.895046710968018, "step": 64000}
{"episode_reward": 367.9803938449088, "episode": 65.0, "batch_reward": 0.2102179632037878, "critic_loss": 0.45286385582387445, "actor_loss": -21.97175982475281, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.768784046173096, "step": 65000}
{"episode_reward": 113.48590154713494, "episode": 66.0, "batch_reward": 0.20785591401159764, "critic_loss": 0.4478422793149948, "actor_loss": -21.812547241210936, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.22946834564209, "step": 66000}
{"episode_reward": 371.8524652211877, "episode": 67.0, "batch_reward": 0.20875652991235255, "critic_loss": 0.4298583953529596, "actor_loss": -22.18590295600891, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.142388820648193, "step": 67000}
{"episode_reward": 51.557722788736676, "episode": 68.0, "batch_reward": 0.2075854739099741, "critic_loss": 0.4361230145394802, "actor_loss": -22.680861824035645, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.547992944717407, "step": 68000}
{"episode_reward": 137.75055898878054, "episode": 69.0, "batch_reward": 0.2071786100268364, "critic_loss": 0.43673792712390425, "actor_loss": -21.675561155319215, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.10456347465515, "step": 69000}
{"episode_reward": 397.26536143659126, "episode": 70.0, "batch_reward": 0.21080068208277225, "critic_loss": 0.45381553840637207, "actor_loss": -22.163931924819945, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.874288082122803, "step": 70000}
{"episode_reward": 398.9668388293039, "episode": 71.0, "batch_reward": 0.21260838641226293, "critic_loss": 0.449267642095685, "actor_loss": -22.004493967056273, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.587079763412476, "step": 71000}
{"episode_reward": 295.37597612723016, "episode": 72.0, "batch_reward": 0.21468444387614727, "critic_loss": 0.46388843993842604, "actor_loss": -22.467701208114622, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.014564752578735, "step": 72000}
{"episode_reward": 450.0299089379058, "episode": 73.0, "batch_reward": 0.2169728997349739, "critic_loss": 0.446616042971611, "actor_loss": -22.732253629684447, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.35401940345764, "step": 73000}
{"episode_reward": 201.54235571237228, "episode": 74.0, "batch_reward": 0.21682361912727355, "critic_loss": 0.45649438914656637, "actor_loss": -22.46604531478882, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.092609643936157, "step": 74000}
{"episode_reward": 414.5293897364352, "episode": 75.0, "batch_reward": 0.2201211352646351, "critic_loss": 0.4435381788611412, "actor_loss": -23.002336668014525, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.83696460723877, "step": 75000}
{"episode_reward": 388.12017306130065, "episode": 76.0, "batch_reward": 0.22076939433813095, "critic_loss": 0.4343658308237791, "actor_loss": -22.8637778301239, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.24857473373413, "step": 76000}
{"episode_reward": 163.60059669039396, "episode": 77.0, "batch_reward": 0.22230245611071586, "critic_loss": 0.46181166684627534, "actor_loss": -23.0412549495697, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.105724334716797, "step": 77000}
{"episode_reward": 271.6598233880343, "episode": 78.0, "batch_reward": 0.22268218043446542, "critic_loss": 0.4749827784150839, "actor_loss": -23.30811862182617, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.02177667617798, "step": 78000}
{"episode_reward": 469.29665866004063, "episode": 79.0, "batch_reward": 0.22562397085130215, "critic_loss": 0.4293235384821892, "actor_loss": -23.590413251876832, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.079514265060425, "step": 79000}
{"episode_reward": 333.98787038961143, "episode": 80.0, "batch_reward": 0.22632174617052078, "critic_loss": 0.452387789323926, "actor_loss": -23.602598196029664, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.320738554000854, "step": 80000}
{"episode_reward": 369.32014057297334, "episode": 81.0, "batch_reward": 0.22912428401410578, "critic_loss": 0.43051639357209204, "actor_loss": -23.50059030151367, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.28331732749939, "step": 81000}
{"episode_reward": 432.94224767533666, "episode": 82.0, "batch_reward": 0.23100291918218135, "critic_loss": 0.45217215003073213, "actor_loss": -23.61000022506714, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.084145069122314, "step": 82000}
{"episode_reward": 406.3402286029775, "episode": 83.0, "batch_reward": 0.23322414119541646, "critic_loss": 0.47416401153802873, "actor_loss": -23.921086679458618, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.946958303451538, "step": 83000}
{"episode_reward": 367.78703904040833, "episode": 84.0, "batch_reward": 0.2339286366701126, "critic_loss": 0.47365100651979447, "actor_loss": -24.36518957901001, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.932695150375366, "step": 84000}
{"episode_reward": 159.2147699670802, "episode": 85.0, "batch_reward": 0.23257365952432155, "critic_loss": 0.45310074247419835, "actor_loss": -24.136873903274537, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.248839855194092, "step": 85000}
{"episode_reward": 420.44590548836277, "episode": 86.0, "batch_reward": 0.23685593558847903, "critic_loss": 0.4465930689424276, "actor_loss": -24.03261587715149, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.21267032623291, "step": 86000}
{"episode_reward": 484.18572252113046, "episode": 87.0, "batch_reward": 0.23872445032000542, "critic_loss": 0.47920384190976617, "actor_loss": -24.944520055770873, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.864331245422363, "step": 87000}
{"episode_reward": 318.9819361763723, "episode": 88.0, "batch_reward": 0.238497812718153, "critic_loss": 0.4638342629224062, "actor_loss": -24.154895030975343, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.319761991500854, "step": 88000}
{"episode_reward": 422.1348463806139, "episode": 89.0, "batch_reward": 0.24148644210398199, "critic_loss": 0.49030701880156996, "actor_loss": -24.358307792663574, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.889527082443237, "step": 89000}
{"episode_reward": 191.0303740493841, "episode": 90.0, "batch_reward": 0.24199094662070275, "critic_loss": 0.4652407954186201, "actor_loss": -24.503684648513794, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.838908672332764, "step": 90000}
{"episode_reward": 462.40112068049825, "episode": 91.0, "batch_reward": 0.24377476300299167, "critic_loss": 0.47685447347164156, "actor_loss": -24.610002964019774, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.93785095214844, "step": 91000}
{"episode_reward": 398.7251735243826, "episode": 92.0, "batch_reward": 0.24495651477575303, "critic_loss": 0.48355506621301175, "actor_loss": -24.956418056488037, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.064486503601074, "step": 92000}
{"episode_reward": 189.862260964196, "episode": 93.0, "batch_reward": 0.24503404431045056, "critic_loss": 0.4752496009171009, "actor_loss": -24.57970880317688, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.28554606437683, "step": 93000}
{"episode_reward": 465.80651658012505, "episode": 94.0, "batch_reward": 0.2478031210452318, "critic_loss": 0.4875766675025225, "actor_loss": -25.177945238113402, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.01791262626648, "step": 94000}
{"episode_reward": 478.1409715330391, "episode": 95.0, "batch_reward": 0.24909851767122745, "critic_loss": 0.5078223722875118, "actor_loss": -25.55547148513794, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.937025785446167, "step": 95000}
{"episode_reward": 412.1530330445585, "episode": 96.0, "batch_reward": 0.2518820776641369, "critic_loss": 0.48880843353271486, "actor_loss": -25.428772462844847, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.500083208084106, "step": 96000}
{"episode_reward": 464.6988203001999, "episode": 97.0, "batch_reward": 0.2537001898735762, "critic_loss": 0.4967301630973816, "actor_loss": -25.27725992393494, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.108923196792603, "step": 97000}
{"episode_reward": 477.2715323939529, "episode": 98.0, "batch_reward": 0.25651998914778235, "critic_loss": 0.4846474327147007, "actor_loss": -26.390114793777467, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.02746558189392, "step": 98000}
{"episode_reward": 513.3371683231893, "episode": 99.0, "batch_reward": 0.25795050950348375, "critic_loss": 0.4756307640373707, "actor_loss": -25.699052263259887, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.7940411567688, "step": 99000}
{"episode_reward": 457.31306041045053, "episode": 100.0, "batch_reward": 0.26076696050167086, "critic_loss": 0.48094048745930196, "actor_loss": -25.924266857147217, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.086661338806152, "step": 100000}
{"episode_reward": 144.115191025609, "episode": 101.0, "batch_reward": 0.2588396568596363, "critic_loss": 0.4971244316548109, "actor_loss": -25.762933349609376, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.64703178405762, "step": 101000}
{"episode_reward": 352.74346812292185, "episode": 102.0, "batch_reward": 0.26015635479986665, "critic_loss": 0.4987376975417137, "actor_loss": -26.25936961555481, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.940687656402588, "step": 102000}
{"episode_reward": 173.40795238766327, "episode": 103.0, "batch_reward": 0.25960665276646616, "critic_loss": 0.48990305517613886, "actor_loss": -25.783046026229858, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.250192165374756, "step": 103000}
{"episode_reward": 510.45826115525125, "episode": 104.0, "batch_reward": 0.261459683150053, "critic_loss": 0.5094788238108158, "actor_loss": -25.825148221969606, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.53653120994568, "step": 104000}
{"episode_reward": 497.8938016442937, "episode": 105.0, "batch_reward": 0.2636777745336294, "critic_loss": 0.4718064131885767, "actor_loss": -26.359681240081787, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.952616453170776, "step": 105000}
{"episode_reward": 503.4429992684044, "episode": 106.0, "batch_reward": 0.26623913237452507, "critic_loss": 0.4400447350740433, "actor_loss": -26.42524235153198, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.850877285003662, "step": 106000}
{"episode_reward": 434.40178502337386, "episode": 107.0, "batch_reward": 0.26864512473344804, "critic_loss": 0.47231369760632513, "actor_loss": -26.203797111511232, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.026957035064697, "step": 107000}
{"episode_reward": 494.5666534579684, "episode": 108.0, "batch_reward": 0.27074668535590174, "critic_loss": 0.470296155795455, "actor_loss": -27.165170026779176, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.717873334884644, "step": 108000}
{"episode_reward": 499.0416508990921, "episode": 109.0, "batch_reward": 0.27138448488712313, "critic_loss": 0.45796462562680246, "actor_loss": -26.83231470108032, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.95474600791931, "step": 109000}
{"episode_reward": 117.52715925908495, "episode": 110.0, "batch_reward": 0.2713986662775278, "critic_loss": 0.44909597651660443, "actor_loss": -27.2771587600708, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.286076545715332, "step": 110000}
{"episode_reward": 496.97845981409216, "episode": 111.0, "batch_reward": 0.27340760023891925, "critic_loss": 0.44816312186419965, "actor_loss": -26.885844812393188, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.34586143493652, "step": 111000}
{"episode_reward": 529.3943978341404, "episode": 112.0, "batch_reward": 0.27605628898739815, "critic_loss": 0.4589283969551325, "actor_loss": -27.64793011856079, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.858966827392578, "step": 112000}
{"episode_reward": 545.3907564669455, "episode": 113.0, "batch_reward": 0.27848234301805497, "critic_loss": 0.4781657130420208, "actor_loss": -27.384664123535156, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.773577451705933, "step": 113000}
{"episode_reward": 529.0421086570166, "episode": 114.0, "batch_reward": 0.28026999431848526, "critic_loss": 0.4793820599466562, "actor_loss": -27.804596656799315, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.833266019821167, "step": 114000}
{"episode_reward": 530.4750853668701, "episode": 115.0, "batch_reward": 0.28287226434051993, "critic_loss": 0.45490488490462305, "actor_loss": -27.823023544311525, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.672906398773193, "step": 115000}
{"episode_reward": 451.3289446552677, "episode": 116.0, "batch_reward": 0.2835512052476406, "critic_loss": 0.4768131964802742, "actor_loss": -27.991108112335205, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.763944625854492, "step": 116000}
{"episode_reward": 507.2880467553181, "episode": 117.0, "batch_reward": 0.2864379668980837, "critic_loss": 0.4769357113242149, "actor_loss": -27.90849521636963, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.7971453666687, "step": 117000}
{"episode_reward": 538.7763451361963, "episode": 118.0, "batch_reward": 0.28750465512275697, "critic_loss": 0.45117570386826994, "actor_loss": -28.105367019653322, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.73776626586914, "step": 118000}
{"episode_reward": 524.686505180873, "episode": 119.0, "batch_reward": 0.29055207584798337, "critic_loss": 0.47490423268079757, "actor_loss": -28.47130561065674, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.768615007400513, "step": 119000}
{"episode_reward": 527.4995993136872, "episode": 120.0, "batch_reward": 0.291873689353466, "critic_loss": 0.4642355763912201, "actor_loss": -28.461328552246094, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.846400260925293, "step": 120000}
{"episode_reward": 529.5457481672624, "episode": 121.0, "batch_reward": 0.29333633284270766, "critic_loss": 0.45428924363851547, "actor_loss": -28.70119203186035, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.87028169631958, "step": 121000}
{"episode_reward": 404.08008923590234, "episode": 122.0, "batch_reward": 0.2936861993968487, "critic_loss": 0.5143552157133817, "actor_loss": -29.011867923736574, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.985901594161987, "step": 122000}
{"episode_reward": 186.8144868608479, "episode": 123.0, "batch_reward": 0.29299215650558474, "critic_loss": 0.4549779391735792, "actor_loss": -28.93823949432373, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.7521550655365, "step": 123000}
{"episode_reward": 478.33593452300056, "episode": 124.0, "batch_reward": 0.29446636183559893, "critic_loss": 0.47647791796922684, "actor_loss": -29.25064582443237, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.171839952468872, "step": 124000}
{"episode_reward": 161.79449195127313, "episode": 125.0, "batch_reward": 0.29405967849493025, "critic_loss": 0.4916701528728008, "actor_loss": -28.774217365264892, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.05993366241455, "step": 125000}
{"episode_reward": 522.7165322906704, "episode": 126.0, "batch_reward": 0.29547198390960694, "critic_loss": 0.47645192983746526, "actor_loss": -29.25222326660156, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.79889440536499, "step": 126000}
{"episode_reward": 292.987145170334, "episode": 127.0, "batch_reward": 0.29599693897366525, "critic_loss": 0.4758226896822453, "actor_loss": -29.205906173706055, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.976765632629395, "step": 127000}
{"episode_reward": 472.18910660251413, "episode": 128.0, "batch_reward": 0.2975425098389387, "critic_loss": 0.49021558575332164, "actor_loss": -29.412171997070313, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.807224988937378, "step": 128000}
{"episode_reward": 504.46767930244016, "episode": 129.0, "batch_reward": 0.29824973583221437, "critic_loss": 0.4820587681978941, "actor_loss": -29.21830680847168, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.048325538635254, "step": 129000}
{"episode_reward": 522.0466980853736, "episode": 130.0, "batch_reward": 0.2999951574653387, "critic_loss": 0.48836026975512503, "actor_loss": -29.678843605041504, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.954198598861694, "step": 130000}
{"episode_reward": 343.42277566457466, "episode": 131.0, "batch_reward": 0.3018369800448418, "critic_loss": 0.46040459637343883, "actor_loss": -29.149750679016112, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.669411420822144, "step": 131000}
{"episode_reward": 466.26143507967737, "episode": 132.0, "batch_reward": 0.3029047945588827, "critic_loss": 0.480908566609025, "actor_loss": -30.00459928512573, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.384090423583984, "step": 132000}
{"episode_reward": 489.82242581223704, "episode": 133.0, "batch_reward": 0.3044152671843767, "critic_loss": 0.4981285825073719, "actor_loss": -29.712272468566894, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.714236974716187, "step": 133000}
{"episode_reward": 524.647382447385, "episode": 134.0, "batch_reward": 0.3051757197082043, "critic_loss": 0.4879829947054386, "actor_loss": -30.066853355407716, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.970104217529297, "step": 134000}
{"episode_reward": 562.9784475462478, "episode": 135.0, "batch_reward": 0.30788255751132965, "critic_loss": 0.4666719328761101, "actor_loss": -30.474210426330565, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.23327922821045, "step": 135000}
{"episode_reward": 516.0210019579074, "episode": 136.0, "batch_reward": 0.30849947345256806, "critic_loss": 0.46816905073821546, "actor_loss": -30.142861316680907, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.19915270805359, "step": 136000}
{"episode_reward": 237.14671827636047, "episode": 137.0, "batch_reward": 0.3084710966944694, "critic_loss": 0.5277894441783428, "actor_loss": -30.298625595092773, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.085914850234985, "step": 137000}
{"episode_reward": 529.9671869191421, "episode": 138.0, "batch_reward": 0.3107177304327488, "critic_loss": 0.48750677074491977, "actor_loss": -30.357889514923095, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.95520806312561, "step": 138000}
{"episode_reward": 438.17713180919293, "episode": 139.0, "batch_reward": 0.31189262610673907, "critic_loss": 0.5099772062003612, "actor_loss": -30.415378433227538, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.837671518325806, "step": 139000}
{"episode_reward": 546.9687698105922, "episode": 140.0, "batch_reward": 0.3115876796543598, "critic_loss": 0.5228133234083653, "actor_loss": -30.92893684387207, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.456612586975098, "step": 140000}
{"episode_reward": 530.9470555083923, "episode": 141.0, "batch_reward": 0.31454404854774476, "critic_loss": 0.5245955449193717, "actor_loss": -30.756672389984132, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.8937714099884, "step": 141000}
{"episode_reward": 280.92728183100456, "episode": 142.0, "batch_reward": 0.31361719128489496, "critic_loss": 0.5234145585596561, "actor_loss": -30.684162063598635, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.23358988761902, "step": 142000}
{"episode_reward": 548.4940638151226, "episode": 143.0, "batch_reward": 0.3152376611232758, "critic_loss": 0.5058839106559754, "actor_loss": -30.949131019592286, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.1284601688385, "step": 143000}
{"episode_reward": 508.5971519306902, "episode": 144.0, "batch_reward": 0.31705637548863885, "critic_loss": 0.49986583325266837, "actor_loss": -31.485094013214113, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.41872215270996, "step": 144000}
{"episode_reward": 542.97417070183, "episode": 145.0, "batch_reward": 0.3184226256906986, "critic_loss": 0.5326246091127396, "actor_loss": -31.20340621185303, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.30641484260559, "step": 145000}
{"episode_reward": 549.4049003511752, "episode": 146.0, "batch_reward": 0.31939148262143136, "critic_loss": 0.5065955264568329, "actor_loss": -30.726538414001464, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.16982889175415, "step": 146000}
{"episode_reward": 469.19534987136655, "episode": 147.0, "batch_reward": 0.32108109244704247, "critic_loss": 0.5297726367563009, "actor_loss": -31.538912796020508, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.12243366241455, "step": 147000}
{"episode_reward": 481.56428619101183, "episode": 148.0, "batch_reward": 0.3227307966053486, "critic_loss": 0.5249714483171701, "actor_loss": -31.69524391555786, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.480461359024048, "step": 148000}
{"episode_reward": 578.65537312297, "episode": 149.0, "batch_reward": 0.3230107345581055, "critic_loss": 0.5187718005478382, "actor_loss": -31.741108238220214, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.798147439956665, "step": 149000}
{"episode_reward": 462.7905625877373, "episode": 150.0, "batch_reward": 0.3247906756103039, "critic_loss": 0.5397491412758827, "actor_loss": -31.81935232925415, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
