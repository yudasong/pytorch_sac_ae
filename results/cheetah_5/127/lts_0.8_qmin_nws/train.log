{"episode_reward": 0.0, "episode": 1.0, "duration": 17.58557152748108, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.5216290950775146, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.2628815775763873, "critic_loss": 0.07003268667612574, "actor_loss": -32.90766533486554, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 64.0538878440857, "step": 3000}
{"episode_reward": 31.025353396903032, "episode": 4.0, "batch_reward": 0.17623020090907812, "critic_loss": 0.051713582903146746, "actor_loss": -23.992969683647157, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.381881952285767, "step": 4000}
{"episode_reward": 58.09261916542823, "episode": 5.0, "batch_reward": 0.14610882456600666, "critic_loss": 0.05083873920142651, "actor_loss": -22.23711407136917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.279006004333496, "step": 5000}
{"episode_reward": 16.796776285706308, "episode": 6.0, "batch_reward": 0.12265375179797411, "critic_loss": 0.04218058930896223, "actor_loss": -23.24743915748596, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.492185354232788, "step": 6000}
{"episode_reward": 40.42835101959899, "episode": 7.0, "batch_reward": 0.11092389155179262, "critic_loss": 0.04782758928276599, "actor_loss": -22.5641291308403, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.41814923286438, "step": 7000}
{"episode_reward": 53.946565514101785, "episode": 8.0, "batch_reward": 0.11565817393362522, "critic_loss": 0.08831254091113806, "actor_loss": -22.5763838596344, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.223318576812744, "step": 8000}
{"episode_reward": 273.45314887649255, "episode": 9.0, "batch_reward": 0.12795370605587958, "critic_loss": 0.08515759366750718, "actor_loss": -23.045286887407304, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.241778135299683, "step": 9000}
{"episode_reward": 106.020281445095, "episode": 10.0, "batch_reward": 0.12430081656575202, "critic_loss": 0.08353714314475656, "actor_loss": -22.988209018468858, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.993895530700684, "step": 10000}
{"episode_reward": 102.71422614826193, "episode": 11.0, "batch_reward": 0.12430850365012884, "critic_loss": 0.07888324511423707, "actor_loss": -22.96174528336525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.409323930740356, "step": 11000}
{"episode_reward": 118.88548756499773, "episode": 12.0, "batch_reward": 0.12265980044007302, "critic_loss": 0.09978645889833569, "actor_loss": -22.487351415634155, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.256476640701294, "step": 12000}
{"episode_reward": 88.4325236645801, "episode": 13.0, "batch_reward": 0.12161844223737717, "critic_loss": 0.10296054249256849, "actor_loss": -21.67113222062588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.19444704055786, "step": 13000}
{"episode_reward": 123.58674075236667, "episode": 14.0, "batch_reward": 0.12125479520112276, "critic_loss": 0.12111847971752286, "actor_loss": -20.672718688726427, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.812371969223022, "step": 14000}
{"episode_reward": 95.90021992655714, "episode": 15.0, "batch_reward": 0.11848935468494892, "critic_loss": 0.11170684168115258, "actor_loss": -21.12470979759097, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.15003204345703, "step": 15000}
{"episode_reward": 118.5550029186864, "episode": 16.0, "batch_reward": 0.12059660924226046, "critic_loss": 0.1354300496056676, "actor_loss": -20.753707306146623, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.72462821006775, "step": 16000}
{"episode_reward": 200.38166130920806, "episode": 17.0, "batch_reward": 0.12569661412388086, "critic_loss": 0.13909545846655966, "actor_loss": -20.68525003899634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.963608980178833, "step": 17000}
{"episode_reward": 206.68962144361907, "episode": 18.0, "batch_reward": 0.12992470233887435, "critic_loss": 0.16411363699287176, "actor_loss": -21.268310796663165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.271166801452637, "step": 18000}
{"episode_reward": 99.99120091254734, "episode": 19.0, "batch_reward": 0.12899064707756042, "critic_loss": 0.17053674666583538, "actor_loss": -21.36553384041786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.23989725112915, "step": 19000}
{"episode_reward": 212.97048642876882, "episode": 20.0, "batch_reward": 0.13354265996068715, "critic_loss": 0.19930702971667053, "actor_loss": -22.38974637567997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.521313190460205, "step": 20000}
{"episode_reward": 154.14420343794984, "episode": 21.0, "batch_reward": 0.13557340863347053, "critic_loss": 0.20803886064887048, "actor_loss": -20.76481385833025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.508599519729614, "step": 21000}
{"episode_reward": 242.4737358097502, "episode": 22.0, "batch_reward": 0.1391214614585042, "critic_loss": 0.2031674800813198, "actor_loss": -22.051555518716572, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.235660076141357, "step": 22000}
{"episode_reward": 194.45008190665308, "episode": 23.0, "batch_reward": 0.14222665617614985, "critic_loss": 0.21778992530703545, "actor_loss": -21.817681257486342, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.63010549545288, "step": 23000}
{"episode_reward": 205.94692191954056, "episode": 24.0, "batch_reward": 0.14500880667567254, "critic_loss": 0.24340220723301173, "actor_loss": -22.64518873858452, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.308396339416504, "step": 24000}
{"episode_reward": 257.1607955413606, "episode": 25.0, "batch_reward": 0.14963524866104125, "critic_loss": 0.23285950303822756, "actor_loss": -23.19369130539894, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.485145092010498, "step": 25000}
{"episode_reward": 122.04310615462676, "episode": 26.0, "batch_reward": 0.14577967574447392, "critic_loss": 0.20679397930204868, "actor_loss": -21.944284267902376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.19875955581665, "step": 26000}
{"episode_reward": 65.44077217957523, "episode": 27.0, "batch_reward": 0.14591812036931515, "critic_loss": 0.20544769140332939, "actor_loss": -22.157659481048583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.9717059135437, "step": 27000}
{"episode_reward": 220.1316129294658, "episode": 28.0, "batch_reward": 0.1487630748823285, "critic_loss": 0.23396685185283422, "actor_loss": -22.16736599969864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.378088235855103, "step": 28000}
{"episode_reward": 256.3158119203517, "episode": 29.0, "batch_reward": 0.15264610229432582, "critic_loss": 0.2420530265495181, "actor_loss": -22.72200502061844, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.681869745254517, "step": 29000}
{"episode_reward": 266.02023605436125, "episode": 30.0, "batch_reward": 0.15593718911707402, "critic_loss": 0.24929114639014005, "actor_loss": -22.141664612293244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.175850868225098, "step": 30000}
{"episode_reward": 141.51264776392642, "episode": 31.0, "batch_reward": 0.15685035268217326, "critic_loss": 0.2562339601591229, "actor_loss": -23.04785849571228, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.00772476196289, "step": 31000}
{"episode_reward": 323.71362924144296, "episode": 32.0, "batch_reward": 0.15962692199647427, "critic_loss": 0.26158341578394173, "actor_loss": -23.531754507064818, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.84318971633911, "step": 32000}
{"episode_reward": 96.18845154084255, "episode": 33.0, "batch_reward": 0.15609362513571978, "critic_loss": 0.24778142762184144, "actor_loss": -23.196174492835997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.210808753967285, "step": 33000}
{"episode_reward": 47.847015080397846, "episode": 34.0, "batch_reward": 0.15444542668014766, "critic_loss": 0.254712801143527, "actor_loss": -22.88656372642517, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.37053108215332, "step": 34000}
{"episode_reward": 105.24056022955419, "episode": 35.0, "batch_reward": 0.15478896751254798, "critic_loss": 0.24364344675838948, "actor_loss": -22.775625224113465, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.200319290161133, "step": 35000}
{"episode_reward": 366.31590775597266, "episode": 36.0, "batch_reward": 0.1587364628314972, "critic_loss": 0.2522872331291437, "actor_loss": -23.350963199615478, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.739662408828735, "step": 36000}
{"episode_reward": 165.6781725089483, "episode": 37.0, "batch_reward": 0.15970149161666633, "critic_loss": 0.26199247635155914, "actor_loss": -22.87911757659912, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.241222858428955, "step": 37000}
{"episode_reward": 233.57931944721983, "episode": 38.0, "batch_reward": 0.16249903777241706, "critic_loss": 0.2673550922051072, "actor_loss": -22.806856442451476, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.61911964416504, "step": 38000}
{"episode_reward": 299.8804962040673, "episode": 39.0, "batch_reward": 0.1657764321565628, "critic_loss": 0.2698461867570877, "actor_loss": -23.001228940963745, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.157002687454224, "step": 39000}
{"episode_reward": 256.6983230554574, "episode": 40.0, "batch_reward": 0.16828682494163513, "critic_loss": 0.2799153795540333, "actor_loss": -23.815500604629516, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.866628646850586, "step": 40000}
{"episode_reward": 281.0884825998193, "episode": 41.0, "batch_reward": 0.17132672134041788, "critic_loss": 0.29539628358185294, "actor_loss": -23.812000513076782, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.76171088218689, "step": 41000}
{"episode_reward": 296.91695795275666, "episode": 42.0, "batch_reward": 0.17487950234115124, "critic_loss": 0.3170546482354403, "actor_loss": -24.181099992752074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.77271318435669, "step": 42000}
{"episode_reward": 250.46954527164826, "episode": 43.0, "batch_reward": 0.17689164559543133, "critic_loss": 0.3102220729738474, "actor_loss": -24.290753479003907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.413888454437256, "step": 43000}
{"episode_reward": 324.4878303101379, "episode": 44.0, "batch_reward": 0.17903265979886054, "critic_loss": 0.3267038912028074, "actor_loss": -25.671739528656005, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.172553539276123, "step": 44000}
{"episode_reward": 164.71597427049917, "episode": 45.0, "batch_reward": 0.1774834197461605, "critic_loss": 0.31453857496380805, "actor_loss": -24.515153733253477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.222368001937866, "step": 45000}
{"episode_reward": 76.10915303207418, "episode": 46.0, "batch_reward": 0.1761711588203907, "critic_loss": 0.3065538439154625, "actor_loss": -23.504690895080568, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.404367208480835, "step": 46000}
{"episode_reward": 276.63579926260564, "episode": 47.0, "batch_reward": 0.17834589989483357, "critic_loss": 0.3179232683032751, "actor_loss": -24.174063378334047, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.587538719177246, "step": 47000}
{"episode_reward": 277.8645909691132, "episode": 48.0, "batch_reward": 0.18089841869473458, "critic_loss": 0.32968179155886174, "actor_loss": -24.176110348701478, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.225342988967896, "step": 48000}
{"episode_reward": 306.5321305384755, "episode": 49.0, "batch_reward": 0.18411603729426862, "critic_loss": 0.348086793705821, "actor_loss": -25.37880393409729, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.895443201065063, "step": 49000}
{"episode_reward": 349.03658529982556, "episode": 50.0, "batch_reward": 0.18758736212551594, "critic_loss": 0.3842402499914169, "actor_loss": -25.245328496932984, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.82989501953125, "step": 50000}
{"episode_reward": 209.19803220924115, "episode": 51.0, "batch_reward": 0.18795983223617077, "critic_loss": 0.3657985931932926, "actor_loss": -24.970158912658693, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.91182851791382, "step": 51000}
{"episode_reward": 287.3227505003037, "episode": 52.0, "batch_reward": 0.1902932899594307, "critic_loss": 0.3736940120905638, "actor_loss": -24.77421947479248, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.05024790763855, "step": 52000}
{"episode_reward": 359.3475013901785, "episode": 53.0, "batch_reward": 0.19240237098932267, "critic_loss": 0.37097654363512994, "actor_loss": -25.606394828796386, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.72594976425171, "step": 53000}
{"episode_reward": 161.62793266853947, "episode": 54.0, "batch_reward": 0.1923967219591141, "critic_loss": 0.37470212948322296, "actor_loss": -25.73675534057617, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.39667296409607, "step": 54000}
{"episode_reward": 208.11161239764576, "episode": 55.0, "batch_reward": 0.19082192979753018, "critic_loss": 0.3813329636603594, "actor_loss": -25.22717200088501, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.175114631652832, "step": 55000}
{"episode_reward": 94.54123795697453, "episode": 56.0, "batch_reward": 0.18914987428486346, "critic_loss": 0.3742456791251898, "actor_loss": -24.84082356452942, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.302324056625366, "step": 56000}
{"episode_reward": 92.53260638599563, "episode": 57.0, "batch_reward": 0.19017662565410137, "critic_loss": 0.37517841574549676, "actor_loss": -24.8186702709198, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.53497338294983, "step": 57000}
{"episode_reward": 403.8114434656208, "episode": 58.0, "batch_reward": 0.19248824463784694, "critic_loss": 0.3831158849000931, "actor_loss": -25.155934183120728, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.23639988899231, "step": 58000}
{"episode_reward": 369.35042897853094, "episode": 59.0, "batch_reward": 0.19674579544365406, "critic_loss": 0.3608679591119289, "actor_loss": -25.33857543563843, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.256136417388916, "step": 59000}
{"episode_reward": 341.3921018266827, "episode": 60.0, "batch_reward": 0.19849870178103446, "critic_loss": 0.3777657513469458, "actor_loss": -25.425150674819946, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.279237031936646, "step": 60000}
{"episode_reward": 276.687914184764, "episode": 61.0, "batch_reward": 0.19928801277279853, "critic_loss": 0.36877155508100984, "actor_loss": -25.354280157089235, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.13161063194275, "step": 61000}
{"episode_reward": 149.5874032621004, "episode": 62.0, "batch_reward": 0.19965235610306262, "critic_loss": 0.38215229620039465, "actor_loss": -25.383319622039796, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.29919123649597, "step": 62000}
{"episode_reward": 374.3135201147576, "episode": 63.0, "batch_reward": 0.20149046432971954, "critic_loss": 0.3828988489359617, "actor_loss": -25.638739624023437, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.277524948120117, "step": 63000}
{"episode_reward": 336.6523100182501, "episode": 64.0, "batch_reward": 0.2047822512537241, "critic_loss": 0.3901135817170143, "actor_loss": -26.194156673431397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.412164211273193, "step": 64000}
{"episode_reward": 359.1251491304313, "episode": 65.0, "batch_reward": 0.20627169962227346, "critic_loss": 0.3918649873584509, "actor_loss": -25.894551113128664, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.23704695701599, "step": 65000}
{"episode_reward": 346.2298507566482, "episode": 66.0, "batch_reward": 0.20651577381789685, "critic_loss": 0.373720336958766, "actor_loss": -25.895450241088867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.29007577896118, "step": 66000}
{"episode_reward": 50.82013783358111, "episode": 67.0, "batch_reward": 0.20691400396823884, "critic_loss": 0.3491017067283392, "actor_loss": -26.312676496505738, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.62010407447815, "step": 67000}
{"episode_reward": 409.5374252029639, "episode": 68.0, "batch_reward": 0.2077302858531475, "critic_loss": 0.37551493574678896, "actor_loss": -26.689665313720702, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.228353261947632, "step": 68000}
{"episode_reward": 125.63380962175758, "episode": 69.0, "batch_reward": 0.20694268929958343, "critic_loss": 0.37288722229003907, "actor_loss": -25.429181661605835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.272428035736084, "step": 69000}
{"episode_reward": 148.28230627245912, "episode": 70.0, "batch_reward": 0.2079293533563614, "critic_loss": 0.3822393751442432, "actor_loss": -25.669012901306154, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.061399459838867, "step": 70000}
{"episode_reward": 361.77405607344826, "episode": 71.0, "batch_reward": 0.20862067829072475, "critic_loss": 0.41265996374189856, "actor_loss": -25.401687211990357, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.431456327438354, "step": 71000}
{"episode_reward": 138.61510646258444, "episode": 72.0, "batch_reward": 0.20715553526580333, "critic_loss": 0.43218482862412927, "actor_loss": -25.97093504714966, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.176393508911133, "step": 72000}
{"episode_reward": 109.77934703849957, "episode": 73.0, "batch_reward": 0.20721128216385842, "critic_loss": 0.4163761308342218, "actor_loss": -25.91235050010681, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.984650373458862, "step": 73000}
{"episode_reward": 357.4808557721557, "episode": 74.0, "batch_reward": 0.20789290802180768, "critic_loss": 0.435630281701684, "actor_loss": -25.262800399780275, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.863417625427246, "step": 74000}
{"episode_reward": 154.23568076025376, "episode": 75.0, "batch_reward": 0.20667848217487336, "critic_loss": 0.41449625697731973, "actor_loss": -25.095736431121825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.227367401123047, "step": 75000}
{"episode_reward": 96.89587810243664, "episode": 76.0, "batch_reward": 0.2062090872079134, "critic_loss": 0.41562166860699656, "actor_loss": -25.195669689178466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.58872413635254, "step": 76000}
{"episode_reward": 159.3881691683169, "episode": 77.0, "batch_reward": 0.20632228623330592, "critic_loss": 0.414036553144455, "actor_loss": -25.002984525680542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.263651132583618, "step": 77000}
{"episode_reward": 349.4366829885261, "episode": 78.0, "batch_reward": 0.2080447641760111, "critic_loss": 0.41428920313715933, "actor_loss": -25.3200769405365, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.043402433395386, "step": 78000}
{"episode_reward": 399.84456159675096, "episode": 79.0, "batch_reward": 0.21119924975931645, "critic_loss": 0.4345960524827242, "actor_loss": -26.082695011138917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.200419664382935, "step": 79000}
{"episode_reward": 263.260197734046, "episode": 80.0, "batch_reward": 0.2113288647532463, "critic_loss": 0.450419185757637, "actor_loss": -25.67785517692566, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.30729389190674, "step": 80000}
{"episode_reward": 401.57781871026253, "episode": 81.0, "batch_reward": 0.21345474138855935, "critic_loss": 0.450883279889822, "actor_loss": -25.31737812423706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.36777305603027, "step": 81000}
{"episode_reward": 291.20265320346226, "episode": 82.0, "batch_reward": 0.2143975856602192, "critic_loss": 0.43520517165958883, "actor_loss": -25.36524604034424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.294065952301025, "step": 82000}
{"episode_reward": 245.92964585744417, "episode": 83.0, "batch_reward": 0.21584683234989643, "critic_loss": 0.4369566075056791, "actor_loss": -25.672655378341673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.185508012771606, "step": 83000}
{"episode_reward": 272.9153227542343, "episode": 84.0, "batch_reward": 0.21465489894151688, "critic_loss": 0.4388647562563419, "actor_loss": -25.791096292495727, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.010109186172485, "step": 84000}
{"episode_reward": 167.29961545475504, "episode": 85.0, "batch_reward": 0.2150332430899143, "critic_loss": 0.431557173833251, "actor_loss": -25.541229467391968, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.36139965057373, "step": 85000}
{"episode_reward": 388.4366855899577, "episode": 86.0, "batch_reward": 0.21716669921576975, "critic_loss": 0.47552768170833587, "actor_loss": -25.598023736953735, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.24250292778015, "step": 86000}
{"episode_reward": 449.2924070387652, "episode": 87.0, "batch_reward": 0.218939707249403, "critic_loss": 0.49159749707579614, "actor_loss": -25.874707530975343, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.462077617645264, "step": 87000}
{"episode_reward": 429.96735502057743, "episode": 88.0, "batch_reward": 0.22229146863520147, "critic_loss": 0.48606829944252966, "actor_loss": -25.75788250350952, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.370465993881226, "step": 88000}
{"episode_reward": 324.96691724036333, "episode": 89.0, "batch_reward": 0.22344178815186025, "critic_loss": 0.4866734518259764, "actor_loss": -26.07021392440796, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.252546072006226, "step": 89000}
{"episode_reward": 445.1159361506714, "episode": 90.0, "batch_reward": 0.2274156161993742, "critic_loss": 0.501120039343834, "actor_loss": -26.132582012176513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.329267024993896, "step": 90000}
{"episode_reward": 523.6880099853136, "episode": 91.0, "batch_reward": 0.22961703208088874, "critic_loss": 0.4837345367968082, "actor_loss": -26.294531925201415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.666526794433594, "step": 91000}
{"episode_reward": 506.21559337926243, "episode": 92.0, "batch_reward": 0.23228516079485417, "critic_loss": 0.4823607992529869, "actor_loss": -27.099994144439698, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.203617572784424, "step": 92000}
{"episode_reward": 456.32219424265514, "episode": 93.0, "batch_reward": 0.2346924955099821, "critic_loss": 0.4728462287783623, "actor_loss": -26.595246376037597, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.592612266540527, "step": 93000}
{"episode_reward": 243.86637030267147, "episode": 94.0, "batch_reward": 0.23511195623874664, "critic_loss": 0.47489020888507366, "actor_loss": -27.00455861854553, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.139280319213867, "step": 94000}
{"episode_reward": 483.03286972613387, "episode": 95.0, "batch_reward": 0.23722866998612882, "critic_loss": 0.4974005507230759, "actor_loss": -27.51079459953308, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.434094429016113, "step": 95000}
{"episode_reward": 353.29323479322494, "episode": 96.0, "batch_reward": 0.23902406501770018, "critic_loss": 0.4996451693475246, "actor_loss": -27.694969665527342, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.181796312332153, "step": 96000}
{"episode_reward": 462.91045408126433, "episode": 97.0, "batch_reward": 0.23992799572646617, "critic_loss": 0.5120485991388559, "actor_loss": -27.44867514419556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.33189630508423, "step": 97000}
{"episode_reward": 155.22963122312046, "episode": 98.0, "batch_reward": 0.23965886780619622, "critic_loss": 0.5044189431965351, "actor_loss": -27.721897998809816, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.653297662734985, "step": 98000}
{"episode_reward": 451.03449534743726, "episode": 99.0, "batch_reward": 0.24191601575911045, "critic_loss": 0.5261483707427979, "actor_loss": -27.330626449584962, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.205724716186523, "step": 99000}
{"episode_reward": 206.19494559655124, "episode": 100.0, "batch_reward": 0.2419993256777525, "critic_loss": 0.563376800686121, "actor_loss": -27.67089147758484, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.27435874938965, "step": 100000}
{"episode_reward": 409.1537649916552, "episode": 101.0, "batch_reward": 0.24388127033412457, "critic_loss": 0.5695777863860131, "actor_loss": -27.135561014175416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.205973386764526, "step": 101000}
{"episode_reward": 449.54824899663276, "episode": 102.0, "batch_reward": 0.2466932357251644, "critic_loss": 0.576908537954092, "actor_loss": -27.825910358428956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.285306453704834, "step": 102000}
{"episode_reward": 429.1140628031026, "episode": 103.0, "batch_reward": 0.24816206276416777, "critic_loss": 0.5641735264658928, "actor_loss": -27.508102466583253, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.235419988632202, "step": 103000}
{"episode_reward": 334.3421679268265, "episode": 104.0, "batch_reward": 0.24774618372321128, "critic_loss": 0.5527668209522962, "actor_loss": -27.340081016540527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.455832719802856, "step": 104000}
{"episode_reward": 419.6442751473938, "episode": 105.0, "batch_reward": 0.2504474420696497, "critic_loss": 0.567660522967577, "actor_loss": -27.8496692237854, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.497794151306152, "step": 105000}
{"episode_reward": 471.18004743969294, "episode": 106.0, "batch_reward": 0.2510153934210539, "critic_loss": 0.5774740282595158, "actor_loss": -27.83868948173523, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.20304775238037, "step": 106000}
{"episode_reward": 230.42052870664068, "episode": 107.0, "batch_reward": 0.25173325183987616, "critic_loss": 0.5939268184900284, "actor_loss": -27.379999645233156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.243699312210083, "step": 107000}
{"episode_reward": 259.78115871685003, "episode": 108.0, "batch_reward": 0.2528215510994196, "critic_loss": 0.6318463400602341, "actor_loss": -28.211587785720827, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.857993364334106, "step": 108000}
{"episode_reward": 409.34676546204355, "episode": 109.0, "batch_reward": 0.2529258785545826, "critic_loss": 0.5911990518271923, "actor_loss": -27.816186038970947, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.114233255386353, "step": 109000}
{"episode_reward": 132.5767089437447, "episode": 110.0, "batch_reward": 0.25335414661467076, "critic_loss": 0.5929091115295887, "actor_loss": -28.51636541748047, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.221277952194214, "step": 110000}
{"episode_reward": 321.69157325666, "episode": 111.0, "batch_reward": 0.25162256379425524, "critic_loss": 0.5912131837010384, "actor_loss": -27.685459621429445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.48305082321167, "step": 111000}
{"episode_reward": 249.38561512418826, "episode": 112.0, "batch_reward": 0.2524232304692268, "critic_loss": 0.6178762657642365, "actor_loss": -27.739055780410766, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.177245378494263, "step": 112000}
{"episode_reward": 255.97866308503725, "episode": 113.0, "batch_reward": 0.2536304048597813, "critic_loss": 0.6055146341025829, "actor_loss": -27.760179914474488, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.190043210983276, "step": 113000}
{"episode_reward": 460.68424979604407, "episode": 114.0, "batch_reward": 0.25479396113753316, "critic_loss": 0.693759830981493, "actor_loss": -28.15362861251831, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.5362765789032, "step": 114000}
{"episode_reward": 456.6514255009156, "episode": 115.0, "batch_reward": 0.25558213108778, "critic_loss": 0.60748303642869, "actor_loss": -28.099600358963013, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.3263201713562, "step": 115000}
{"episode_reward": 292.37100817277525, "episode": 116.0, "batch_reward": 0.25744883435964583, "critic_loss": 0.6963106034398079, "actor_loss": -28.268420423507692, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.67414140701294, "step": 116000}
{"episode_reward": 239.32900771189728, "episode": 117.0, "batch_reward": 0.2579462213218212, "critic_loss": 0.6621810081005096, "actor_loss": -27.792886829376222, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.267354726791382, "step": 117000}
{"episode_reward": 494.9038532128447, "episode": 118.0, "batch_reward": 0.2585479016751051, "critic_loss": 0.6989613848626614, "actor_loss": -28.11018518447876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.74076795578003, "step": 118000}
{"episode_reward": 438.5782750037451, "episode": 119.0, "batch_reward": 0.25974285934865476, "critic_loss": 0.7202742467224598, "actor_loss": -28.28705284500122, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.152206659317017, "step": 119000}
{"episode_reward": 62.431053120843856, "episode": 120.0, "batch_reward": 0.25705506740510464, "critic_loss": 0.7242289528548718, "actor_loss": -27.452110538482668, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.45474672317505, "step": 120000}
{"episode_reward": 60.59011338528558, "episode": 121.0, "batch_reward": 0.25642527163028717, "critic_loss": 0.6635201151371002, "actor_loss": -27.996902488708496, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.371511459350586, "step": 121000}
{"episode_reward": 196.1754464302348, "episode": 122.0, "batch_reward": 0.256732583373785, "critic_loss": 0.7009039898812771, "actor_loss": -28.190285705566406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.29149055480957, "step": 122000}
{"episode_reward": 359.92228245430516, "episode": 123.0, "batch_reward": 0.25585367216169835, "critic_loss": 0.6857571394145489, "actor_loss": -28.24764525604248, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.751331090927124, "step": 123000}
{"episode_reward": 89.22807873761614, "episode": 124.0, "batch_reward": 0.256005292147398, "critic_loss": 0.6705740116238594, "actor_loss": -28.017723461151125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.214142560958862, "step": 124000}
{"episode_reward": 303.31543517906607, "episode": 125.0, "batch_reward": 0.25598561157286165, "critic_loss": 0.7595417329370976, "actor_loss": -27.729827487945556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.500737190246582, "step": 125000}
{"episode_reward": 239.68585069206128, "episode": 126.0, "batch_reward": 0.2562152231633663, "critic_loss": 0.7246715004742146, "actor_loss": -28.12587537574768, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.260810136795044, "step": 126000}
{"episode_reward": 144.87652873509748, "episode": 127.0, "batch_reward": 0.25449750776588914, "critic_loss": 0.6881611044704914, "actor_loss": -27.688929559707642, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.694244384765625, "step": 127000}
{"episode_reward": 168.770167415163, "episode": 128.0, "batch_reward": 0.25458881859481336, "critic_loss": 0.6705386061072349, "actor_loss": -27.244178644180298, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.502990245819092, "step": 128000}
{"episode_reward": 216.59922693380335, "episode": 129.0, "batch_reward": 0.2551044888496399, "critic_loss": 0.6532577774524688, "actor_loss": -27.576621196746824, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.706902265548706, "step": 129000}
{"episode_reward": 519.7077975841967, "episode": 130.0, "batch_reward": 0.25643744972348215, "critic_loss": 0.7430659336447716, "actor_loss": -27.840116773605345, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.06422996520996, "step": 130000}
{"episode_reward": 375.3390554112788, "episode": 131.0, "batch_reward": 0.25621338522434234, "critic_loss": 0.706843365073204, "actor_loss": -26.96395532798767, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.80802941322327, "step": 131000}
{"episode_reward": 148.29615602037643, "episode": 132.0, "batch_reward": 0.25613051195442676, "critic_loss": 0.6857697918117046, "actor_loss": -28.07408994102478, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.132392168045044, "step": 132000}
{"episode_reward": 439.5381503830317, "episode": 133.0, "batch_reward": 0.25763521890342234, "critic_loss": 0.6805885886549949, "actor_loss": -27.353616731643676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.970693588256836, "step": 133000}
{"episode_reward": 507.8237298046309, "episode": 134.0, "batch_reward": 0.2593553099632263, "critic_loss": 0.6817789044380188, "actor_loss": -27.824434253692626, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.680349349975586, "step": 134000}
{"episode_reward": 244.40488634016836, "episode": 135.0, "batch_reward": 0.258219285517931, "critic_loss": 0.6631534570753574, "actor_loss": -27.91301624107361, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.241700172424316, "step": 135000}
{"episode_reward": 93.78800741141859, "episode": 136.0, "batch_reward": 0.25938801547884943, "critic_loss": 0.6336876021027565, "actor_loss": -27.64061853790283, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.531494617462158, "step": 136000}
{"episode_reward": 333.4066859652144, "episode": 137.0, "batch_reward": 0.2598983716070652, "critic_loss": 0.6544049899876118, "actor_loss": -28.05514235115051, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.244465827941895, "step": 137000}
{"episode_reward": 410.5719306769782, "episode": 138.0, "batch_reward": 0.26065830972790716, "critic_loss": 0.6468732984960079, "actor_loss": -28.42720988845825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.606361865997314, "step": 138000}
{"episode_reward": 532.5445520659998, "episode": 139.0, "batch_reward": 0.2617033595144749, "critic_loss": 0.6726716312766076, "actor_loss": -27.584129215240477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.304072618484497, "step": 139000}
{"episode_reward": 495.8670877468503, "episode": 140.0, "batch_reward": 0.2636526533216238, "critic_loss": 0.6336920434236526, "actor_loss": -28.478295387268066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.548460245132446, "step": 140000}
{"episode_reward": 421.4145114444003, "episode": 141.0, "batch_reward": 0.26577830269932745, "critic_loss": 0.6028960636854171, "actor_loss": -28.076565080642702, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.64111042022705, "step": 141000}
{"episode_reward": 162.0892371453893, "episode": 142.0, "batch_reward": 0.263464552283287, "critic_loss": 0.6666293746829033, "actor_loss": -28.044746154785155, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.2419273853302, "step": 142000}
{"episode_reward": 368.76738431168195, "episode": 143.0, "batch_reward": 0.26450398766994476, "critic_loss": 0.666391458839178, "actor_loss": -28.151795526504518, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.6133975982666, "step": 143000}
{"episode_reward": 395.4346741460197, "episode": 144.0, "batch_reward": 0.265704976439476, "critic_loss": 0.6834867215752601, "actor_loss": -28.486398649215698, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.22595977783203, "step": 144000}
{"episode_reward": 353.99712280781273, "episode": 145.0, "batch_reward": 0.26636130872368813, "critic_loss": 0.6555539657473564, "actor_loss": -28.414888731002808, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.469313383102417, "step": 145000}
{"episode_reward": 452.82041931574093, "episode": 146.0, "batch_reward": 0.2675719359219074, "critic_loss": 0.6132305868566036, "actor_loss": -28.022342275619508, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.260412216186523, "step": 146000}
{"episode_reward": 257.9645998949344, "episode": 147.0, "batch_reward": 0.2674244679063559, "critic_loss": 0.6598637321293354, "actor_loss": -28.273097915649416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.991662979125977, "step": 147000}
{"episode_reward": 456.57860195291823, "episode": 148.0, "batch_reward": 0.26943832051753996, "critic_loss": 0.6265534525513649, "actor_loss": -28.249884525299073, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.967215061187744, "step": 148000}
{"episode_reward": 403.35813152714604, "episode": 149.0, "batch_reward": 0.27030895110964775, "critic_loss": 0.6141135516166687, "actor_loss": -28.54127985572815, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.291136980056763, "step": 149000}
{"episode_reward": 497.0593264525745, "episode": 150.0, "batch_reward": 0.2709385742843151, "critic_loss": 0.6217475365102291, "actor_loss": -28.877034282684328, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
