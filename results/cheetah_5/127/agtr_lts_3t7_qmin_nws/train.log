{"episode_reward": 0.0, "episode": 1.0, "duration": 12.267204761505127, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 0.9882717132568359, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.262739622069224, "critic_loss": 0.06658124617447193, "actor_loss": -35.761769905119905, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 67.34599351882935, "step": 3000}
{"episode_reward": 31.300730840659227, "episode": 4.0, "batch_reward": 0.17722549334913493, "critic_loss": 0.04171923515573144, "actor_loss": -29.168830798625947, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.310159921646118, "step": 4000}
{"episode_reward": 58.40899761875844, "episode": 5.0, "batch_reward": 0.15068235543370248, "critic_loss": 0.0629322906639427, "actor_loss": -28.28823932313919, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.283709049224854, "step": 5000}
{"episode_reward": 76.11474836798986, "episode": 6.0, "batch_reward": 0.1381296529173851, "critic_loss": 0.06907642133161426, "actor_loss": -25.0651175365448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.687296867370605, "step": 6000}
{"episode_reward": 98.443839311229, "episode": 7.0, "batch_reward": 0.1343133634775877, "critic_loss": 0.06787812604755163, "actor_loss": -24.995247846603394, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.605380296707153, "step": 7000}
{"episode_reward": 89.92838514443591, "episode": 8.0, "batch_reward": 0.12384764011949301, "critic_loss": 0.0703046724870801, "actor_loss": -22.617806087493896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.754462003707886, "step": 8000}
{"episode_reward": 37.353448132160175, "episode": 9.0, "batch_reward": 0.11439926316589118, "critic_loss": 0.07361683393642306, "actor_loss": -21.78417501926422, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.472288370132446, "step": 9000}
{"episode_reward": 67.37303073640513, "episode": 10.0, "batch_reward": 0.1131291336864233, "critic_loss": 0.07967544654011727, "actor_loss": -21.13316180181503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.657079219818115, "step": 10000}
{"episode_reward": 125.6397791563795, "episode": 11.0, "batch_reward": 0.117778964035213, "critic_loss": 0.09525761880353092, "actor_loss": -20.409603751897812, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 32.780033111572266, "step": 11000}
{"episode_reward": 137.95437611300167, "episode": 12.0, "batch_reward": 0.11763743158429861, "critic_loss": 0.10011575920507312, "actor_loss": -18.24317678976059, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.53317642211914, "step": 12000}
{"episode_reward": 114.06245945439, "episode": 13.0, "batch_reward": 0.12080576169490814, "critic_loss": 0.13206673612445594, "actor_loss": -18.975625844955445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.509811401367188, "step": 13000}
{"episode_reward": 193.41422133128088, "episode": 14.0, "batch_reward": 0.12009280184656382, "critic_loss": 0.13312292576208712, "actor_loss": -16.664910871863366, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.66014814376831, "step": 14000}
{"episode_reward": 40.41764811503009, "episode": 15.0, "batch_reward": 0.11949804218113422, "critic_loss": 0.1471826679855585, "actor_loss": -16.252387126743795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.26826548576355, "step": 15000}
{"episode_reward": 230.2918264722894, "episode": 16.0, "batch_reward": 0.1262861117348075, "critic_loss": 0.16138051702082157, "actor_loss": -16.681364588722587, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.961439609527588, "step": 16000}
{"episode_reward": 191.34497794376065, "episode": 17.0, "batch_reward": 0.12497819693386555, "critic_loss": 0.1588143671602011, "actor_loss": -15.684975938498974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.746407985687256, "step": 17000}
{"episode_reward": 19.201197049625225, "episode": 18.0, "batch_reward": 0.12751485370844604, "critic_loss": 0.2216358977332711, "actor_loss": -15.418137839615344, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.57023525238037, "step": 18000}
{"episode_reward": 310.73188586196994, "episode": 19.0, "batch_reward": 0.13118534898757936, "critic_loss": 0.24130379612743855, "actor_loss": -15.59724566307664, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.245903491973877, "step": 19000}
{"episode_reward": 59.58134188450037, "episode": 20.0, "batch_reward": 0.1289993754401803, "critic_loss": 0.2668819790557027, "actor_loss": -14.740510983109473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.58313298225403, "step": 20000}
{"episode_reward": 113.91357741860777, "episode": 21.0, "batch_reward": 0.1288588817343116, "critic_loss": 0.2297405367717147, "actor_loss": -15.73999761080742, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.15908694267273, "step": 21000}
{"episode_reward": 188.64821704152106, "episode": 22.0, "batch_reward": 0.13259456069022418, "critic_loss": 0.22571999426186085, "actor_loss": -13.797457041978836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.344989776611328, "step": 22000}
{"episode_reward": 157.99470596804716, "episode": 23.0, "batch_reward": 0.13243274614214898, "critic_loss": 0.22056875247508287, "actor_loss": -14.52854512834549, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.99955153465271, "step": 23000}
{"episode_reward": 121.48333735268665, "episode": 24.0, "batch_reward": 0.1303676505088806, "critic_loss": 0.23467152440547942, "actor_loss": -14.569658678531647, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.30987310409546, "step": 24000}
{"episode_reward": 121.2811402945314, "episode": 25.0, "batch_reward": 0.13247410175949334, "critic_loss": 0.23506297928094863, "actor_loss": -14.415582805156708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.169996738433838, "step": 25000}
{"episode_reward": 109.45861990357515, "episode": 26.0, "batch_reward": 0.12960106320679188, "critic_loss": 0.22332330818474294, "actor_loss": -14.343629788398742, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.373424291610718, "step": 26000}
{"episode_reward": 77.68986630477855, "episode": 27.0, "batch_reward": 0.12724589048326015, "critic_loss": 0.2239388658851385, "actor_loss": -14.278476683616638, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.80868625640869, "step": 27000}
{"episode_reward": 48.37659630181194, "episode": 28.0, "batch_reward": 0.12627623788267375, "critic_loss": 0.24149169791489838, "actor_loss": -13.791299014091491, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.817017078399658, "step": 28000}
{"episode_reward": 140.79925715343552, "episode": 29.0, "batch_reward": 0.12834259326756, "critic_loss": 0.27128770772367716, "actor_loss": -14.013170309066773, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.74932050704956, "step": 29000}
{"episode_reward": 223.72449362914392, "episode": 30.0, "batch_reward": 0.13208974167704582, "critic_loss": 0.23607701015472413, "actor_loss": -14.547205976486206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.33782434463501, "step": 30000}
{"episode_reward": 270.5604188590502, "episode": 31.0, "batch_reward": 0.13425125200301408, "critic_loss": 0.23689626402407885, "actor_loss": -14.458763203620911, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 33.39330458641052, "step": 31000}
{"episode_reward": 88.89388627790638, "episode": 32.0, "batch_reward": 0.1337734201774001, "critic_loss": 0.2253882052898407, "actor_loss": -14.425393795967102, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.57487964630127, "step": 32000}
{"episode_reward": 277.8275774247339, "episode": 33.0, "batch_reward": 0.13863196753710508, "critic_loss": 0.24514506003260614, "actor_loss": -14.670353123664857, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.900660514831543, "step": 33000}
{"episode_reward": 196.02798680733113, "episode": 34.0, "batch_reward": 0.14049948700517417, "critic_loss": 0.24294477363675832, "actor_loss": -14.717089688301087, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.233731269836426, "step": 34000}
{"episode_reward": 236.73291541411993, "episode": 35.0, "batch_reward": 0.1424042172729969, "critic_loss": 0.25084595069289206, "actor_loss": -14.758069150924683, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.657496452331543, "step": 35000}
{"episode_reward": 176.06271761141878, "episode": 36.0, "batch_reward": 0.14332742459326983, "critic_loss": 0.23626184025406838, "actor_loss": -14.46533012008667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.181066751480103, "step": 36000}
{"episode_reward": 157.30313489864415, "episode": 37.0, "batch_reward": 0.14296055170893668, "critic_loss": 0.2306723219230771, "actor_loss": -15.103259338378907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.202511310577393, "step": 37000}
{"episode_reward": 80.13021485554094, "episode": 38.0, "batch_reward": 0.14076889619231225, "critic_loss": 0.2532627567574382, "actor_loss": -15.23684875869751, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.56586241722107, "step": 38000}
{"episode_reward": 94.80709559861573, "episode": 39.0, "batch_reward": 0.1424273201301694, "critic_loss": 0.24848632921278477, "actor_loss": -14.913950540542602, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.079131841659546, "step": 39000}
{"episode_reward": 306.846161488342, "episode": 40.0, "batch_reward": 0.14520743556320667, "critic_loss": 0.25284723115712404, "actor_loss": -14.952896451950073, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.776187896728516, "step": 40000}
{"episode_reward": 200.32429585107997, "episode": 41.0, "batch_reward": 0.1464561096355319, "critic_loss": 0.25178290614485743, "actor_loss": -15.33264514350891, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 33.24898838996887, "step": 41000}
{"episode_reward": 203.76440865174303, "episode": 42.0, "batch_reward": 0.14991431581228973, "critic_loss": 0.2374177707657218, "actor_loss": -15.49760850906372, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.16342520713806, "step": 42000}
{"episode_reward": 272.7107027806505, "episode": 43.0, "batch_reward": 0.15164000125974417, "critic_loss": 0.26432224621623757, "actor_loss": -15.580010324478149, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.39448118209839, "step": 43000}
{"episode_reward": 253.151288095621, "episode": 44.0, "batch_reward": 0.15177745798975228, "critic_loss": 0.25109823456406594, "actor_loss": -15.182617664337158, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.905216693878174, "step": 44000}
{"episode_reward": 55.68717969300365, "episode": 45.0, "batch_reward": 0.15001621000468732, "critic_loss": 0.27465197747200726, "actor_loss": -15.58546078491211, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.385629653930664, "step": 45000}
{"episode_reward": 103.16976580108722, "episode": 46.0, "batch_reward": 0.15025889207422732, "critic_loss": 0.2721086225807667, "actor_loss": -15.845975574493409, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.617228507995605, "step": 46000}
{"episode_reward": 331.2187076121033, "episode": 47.0, "batch_reward": 0.15460111025720835, "critic_loss": 0.3068522534072399, "actor_loss": -16.203731695175172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.60819387435913, "step": 47000}
{"episode_reward": 275.4344944416521, "episode": 48.0, "batch_reward": 0.1561791941821575, "critic_loss": 0.3077167619615793, "actor_loss": -16.417018480300904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.707407474517822, "step": 48000}
{"episode_reward": 151.79064528822545, "episode": 49.0, "batch_reward": 0.15676502023637295, "critic_loss": 0.35114055333286526, "actor_loss": -16.517571825027467, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.272075653076172, "step": 49000}
{"episode_reward": 215.33326329343745, "episode": 50.0, "batch_reward": 0.15679409646242856, "critic_loss": 0.32166257815063, "actor_loss": -16.660323862075806, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.619300365447998, "step": 50000}
{"episode_reward": 99.1424858726397, "episode": 51.0, "batch_reward": 0.1571930089518428, "critic_loss": 0.37130963787436483, "actor_loss": -16.98962504386902, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.19931602478027, "step": 51000}
{"episode_reward": 266.660388527458, "episode": 52.0, "batch_reward": 0.1597915941849351, "critic_loss": 0.3703371603935957, "actor_loss": -17.65136216545105, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.592742204666138, "step": 52000}
{"episode_reward": 354.64621868134844, "episode": 53.0, "batch_reward": 0.16391372227668763, "critic_loss": 0.3639428620785475, "actor_loss": -18.065649560928346, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.385848999023438, "step": 53000}
{"episode_reward": 380.30554853547756, "episode": 54.0, "batch_reward": 0.1674170282483101, "critic_loss": 0.35551530385017394, "actor_loss": -18.730708869934084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.90887713432312, "step": 54000}
{"episode_reward": 277.037411198236, "episode": 55.0, "batch_reward": 0.16927657255530357, "critic_loss": 0.39042935371398924, "actor_loss": -19.249440538406372, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.244041442871094, "step": 55000}
{"episode_reward": 270.36251512096976, "episode": 56.0, "batch_reward": 0.17061991311609745, "critic_loss": 0.3937784940302372, "actor_loss": -19.587517318725585, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.155557870864868, "step": 56000}
{"episode_reward": 136.45076038427044, "episode": 57.0, "batch_reward": 0.170909416295588, "critic_loss": 0.4148876266479492, "actor_loss": -19.70405097961426, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.689992904663086, "step": 57000}
{"episode_reward": 291.6402938244514, "episode": 58.0, "batch_reward": 0.17103734941780568, "critic_loss": 0.3933166243582964, "actor_loss": -19.95024737739563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.248913764953613, "step": 58000}
{"episode_reward": 88.58731463959045, "episode": 59.0, "batch_reward": 0.17124791297316552, "critic_loss": 0.3985874294638634, "actor_loss": -20.037026447296142, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.679577350616455, "step": 59000}
{"episode_reward": 317.49413066090614, "episode": 60.0, "batch_reward": 0.17376103611290455, "critic_loss": 0.42572152145206926, "actor_loss": -20.498084548950196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.672919988632202, "step": 60000}
{"episode_reward": 152.91373921402965, "episode": 61.0, "batch_reward": 0.17340638065338135, "critic_loss": 0.43737403482198717, "actor_loss": -20.545456878662108, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 33.4851291179657, "step": 61000}
{"episode_reward": 348.8112923281662, "episode": 62.0, "batch_reward": 0.17656227814406156, "critic_loss": 0.42706071799993517, "actor_loss": -20.80098811721802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.72097086906433, "step": 62000}
{"episode_reward": 261.6372972833658, "episode": 63.0, "batch_reward": 0.17570018118619918, "critic_loss": 0.4277746083289385, "actor_loss": -20.93984189605713, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.142244815826416, "step": 63000}
{"episode_reward": 109.95779581347618, "episode": 64.0, "batch_reward": 0.17377775210142135, "critic_loss": 0.41928007189929484, "actor_loss": -20.83131251525879, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.673766613006592, "step": 64000}
{"episode_reward": 36.63594082708844, "episode": 65.0, "batch_reward": 0.1734594955816865, "critic_loss": 0.4191151873022318, "actor_loss": -20.936261386871337, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.627137422561646, "step": 65000}
{"episode_reward": 133.16157535997132, "episode": 66.0, "batch_reward": 0.17358066087961196, "critic_loss": 0.4215036485046148, "actor_loss": -20.991408603668212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.5002703666687, "step": 66000}
{"episode_reward": 322.4618784902577, "episode": 67.0, "batch_reward": 0.17598118534684182, "critic_loss": 0.4386741537898779, "actor_loss": -21.236061656951904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.95726442337036, "step": 67000}
{"episode_reward": 241.07716593341158, "episode": 68.0, "batch_reward": 0.17585253895819186, "critic_loss": 0.428842779353261, "actor_loss": -21.305797119140625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.587549686431885, "step": 68000}
{"episode_reward": 183.2900002656848, "episode": 69.0, "batch_reward": 0.17457681795954705, "critic_loss": 0.42784126071631906, "actor_loss": -21.297680377960205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.442516565322876, "step": 69000}
{"episode_reward": 37.61103050217456, "episode": 70.0, "batch_reward": 0.17569088964164256, "critic_loss": 0.39829117408394815, "actor_loss": -21.464843700408935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.717007637023926, "step": 70000}
{"episode_reward": 303.71685246439296, "episode": 71.0, "batch_reward": 0.1747544840723276, "critic_loss": 0.40708892834186555, "actor_loss": -21.492238914489747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 32.95402240753174, "step": 71000}
{"episode_reward": 50.91678332369599, "episode": 72.0, "batch_reward": 0.1746847424954176, "critic_loss": 0.41179272066056727, "actor_loss": -21.639876235961914, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.029142141342163, "step": 72000}
{"episode_reward": 322.0309832103962, "episode": 73.0, "batch_reward": 0.17676136676967144, "critic_loss": 0.42534862498939036, "actor_loss": -21.841157176971436, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.889450311660767, "step": 73000}
{"episode_reward": 209.17008368130666, "episode": 74.0, "batch_reward": 0.17620294734835626, "critic_loss": 0.4112140083909035, "actor_loss": -21.79256755065918, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.33073925971985, "step": 74000}
{"episode_reward": 92.10962258375007, "episode": 75.0, "batch_reward": 0.17501013514399527, "critic_loss": 0.4261277757883072, "actor_loss": -21.75184700012207, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.68760395050049, "step": 75000}
{"episode_reward": 90.13752491376935, "episode": 76.0, "batch_reward": 0.17449699694663287, "critic_loss": 0.408434221804142, "actor_loss": -21.565246528625487, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.82108998298645, "step": 76000}
{"episode_reward": 104.76485478203958, "episode": 77.0, "batch_reward": 0.17514112401008605, "critic_loss": 0.39646166445314884, "actor_loss": -21.79261766052246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.890082597732544, "step": 77000}
{"episode_reward": 420.3558003869083, "episode": 78.0, "batch_reward": 0.1773114604651928, "critic_loss": 0.43040748572349546, "actor_loss": -21.92507905578613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.705010652542114, "step": 78000}
{"episode_reward": 216.2132433755175, "episode": 79.0, "batch_reward": 0.17818195751309396, "critic_loss": 0.4025610389113426, "actor_loss": -22.03869057846069, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.98887538909912, "step": 79000}
{"episode_reward": 179.76058388393355, "episode": 80.0, "batch_reward": 0.17790174806118011, "critic_loss": 0.43647377780079843, "actor_loss": -22.04595993423462, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.973846912384033, "step": 80000}
{"episode_reward": 328.91928744334126, "episode": 81.0, "batch_reward": 0.1799498816728592, "critic_loss": 0.393266277462244, "actor_loss": -22.14607593536377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 33.18284034729004, "step": 81000}
{"episode_reward": 362.18484840744526, "episode": 82.0, "batch_reward": 0.18163562962412835, "critic_loss": 0.40398649038374423, "actor_loss": -22.34428005981445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.305971384048462, "step": 82000}
{"episode_reward": 363.3376270784994, "episode": 83.0, "batch_reward": 0.18502798621356487, "critic_loss": 0.3915691200196743, "actor_loss": -22.498558361053465, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.678133964538574, "step": 83000}
{"episode_reward": 254.157367062487, "episode": 84.0, "batch_reward": 0.18514159809052944, "critic_loss": 0.3784264112859964, "actor_loss": -22.56120597076416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.49412751197815, "step": 84000}
{"episode_reward": 255.81688299129817, "episode": 85.0, "batch_reward": 0.18581294758617878, "critic_loss": 0.40578442803025244, "actor_loss": -22.58148859024048, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.134760856628418, "step": 85000}
{"episode_reward": 350.4330781099521, "episode": 86.0, "batch_reward": 0.18817312052845955, "critic_loss": 0.3600647345036268, "actor_loss": -22.79072708892822, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.868171215057373, "step": 86000}
{"episode_reward": 405.38778322662864, "episode": 87.0, "batch_reward": 0.19150468064844609, "critic_loss": 0.39863107973337175, "actor_loss": -23.027637493133543, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.605794429779053, "step": 87000}
{"episode_reward": 502.3960827542356, "episode": 88.0, "batch_reward": 0.19425279188156128, "critic_loss": 0.37545732206106186, "actor_loss": -23.27406826019287, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.880738019943237, "step": 88000}
{"episode_reward": 388.86946162642494, "episode": 89.0, "batch_reward": 0.1966722115278244, "critic_loss": 0.3943213143348694, "actor_loss": -23.3792165184021, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.81196165084839, "step": 89000}
{"episode_reward": 441.60036058188, "episode": 90.0, "batch_reward": 0.200162994235754, "critic_loss": 0.383386473223567, "actor_loss": -23.61096257019043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.943316221237183, "step": 90000}
{"episode_reward": 459.7999447978208, "episode": 91.0, "batch_reward": 0.2020384973138571, "critic_loss": 0.3694718054533005, "actor_loss": -23.764897647857666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 33.279125928878784, "step": 91000}
{"episode_reward": 455.97372382431223, "episode": 92.0, "batch_reward": 0.20500727431476115, "critic_loss": 0.3927188453674316, "actor_loss": -24.00503899002075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.064131021499634, "step": 92000}
{"episode_reward": 242.2304989748448, "episode": 93.0, "batch_reward": 0.20509695196151734, "critic_loss": 0.35795101268589496, "actor_loss": -23.951310848236083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.009851694107056, "step": 93000}
{"episode_reward": 459.65988349398185, "episode": 94.0, "batch_reward": 0.20755767637491226, "critic_loss": 0.3884287796765566, "actor_loss": -24.081587768554687, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.011225938796997, "step": 94000}
{"episode_reward": 148.651354563001, "episode": 95.0, "batch_reward": 0.20695866265892982, "critic_loss": 0.37285958501696587, "actor_loss": -24.059863655090332, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.97353458404541, "step": 95000}
{"episode_reward": 322.42278032334355, "episode": 96.0, "batch_reward": 0.20882561981678008, "critic_loss": 0.3515924449712038, "actor_loss": -24.11916915512085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.987194776535034, "step": 96000}
{"episode_reward": 191.9883595742407, "episode": 97.0, "batch_reward": 0.20828717225790025, "critic_loss": 0.3446700141578913, "actor_loss": -24.149072612762453, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.75848889350891, "step": 97000}
{"episode_reward": 223.8551656592604, "episode": 98.0, "batch_reward": 0.20765217071771622, "critic_loss": 0.3492939930707216, "actor_loss": -24.018494606018066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.247562646865845, "step": 98000}
{"episode_reward": 507.0862390455735, "episode": 99.0, "batch_reward": 0.2126448905169964, "critic_loss": 0.3458846446722746, "actor_loss": -24.45629914474487, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.492436170578003, "step": 99000}
{"episode_reward": 515.1737131889944, "episode": 100.0, "batch_reward": 0.21572234420478345, "critic_loss": 0.36519533199071885, "actor_loss": -24.6576950340271, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.833269596099854, "step": 100000}
{"episode_reward": 492.66316451321626, "episode": 101.0, "batch_reward": 0.21840123075246812, "critic_loss": 0.3859202973395586, "actor_loss": -24.92938812637329, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 33.347771406173706, "step": 101000}
{"episode_reward": 534.6503181390428, "episode": 102.0, "batch_reward": 0.22100040636956692, "critic_loss": 0.3668065613955259, "actor_loss": -25.092339420318602, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.868637561798096, "step": 102000}
{"episode_reward": 459.83804330605875, "episode": 103.0, "batch_reward": 0.22329957333207132, "critic_loss": 0.35877388748526573, "actor_loss": -25.34889350128174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.354546308517456, "step": 103000}
{"episode_reward": 476.7676275518122, "episode": 104.0, "batch_reward": 0.2259223030656576, "critic_loss": 0.35333703996241095, "actor_loss": -25.510536849975587, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.796874523162842, "step": 104000}
{"episode_reward": 498.56221512421905, "episode": 105.0, "batch_reward": 0.22853501431643963, "critic_loss": 0.3801158898770809, "actor_loss": -25.730705963134767, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.57499861717224, "step": 105000}
{"episode_reward": 234.21934899220096, "episode": 106.0, "batch_reward": 0.22848108625411986, "critic_loss": 0.34270201495289804, "actor_loss": -25.70471124267578, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.22965693473816, "step": 106000}
{"episode_reward": 462.9055127830972, "episode": 107.0, "batch_reward": 0.23083513294160365, "critic_loss": 0.35478922732174395, "actor_loss": -25.803961833953856, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.603187799453735, "step": 107000}
{"episode_reward": 566.928633900491, "episode": 108.0, "batch_reward": 0.23496300706267356, "critic_loss": 0.368957255885005, "actor_loss": -26.075879634857177, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.382210969924927, "step": 108000}
{"episode_reward": 474.4278774932317, "episode": 109.0, "batch_reward": 0.2354308276027441, "critic_loss": 0.3731610685437918, "actor_loss": -26.071866577148437, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.141143560409546, "step": 109000}
{"episode_reward": 183.06837716066707, "episode": 110.0, "batch_reward": 0.23525223830342293, "critic_loss": 0.3620594794005156, "actor_loss": -26.00910083770752, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.01146411895752, "step": 110000}
{"episode_reward": 149.8081989682672, "episode": 111.0, "batch_reward": 0.2343527570217848, "critic_loss": 0.37824000816047193, "actor_loss": -26.044651592254638, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.19046449661255, "step": 111000}
{"episode_reward": 456.01379710342565, "episode": 112.0, "batch_reward": 0.23695368811488152, "critic_loss": 0.3487456047385931, "actor_loss": -26.25028396987915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.784857749938965, "step": 112000}
{"episode_reward": 587.9638242453676, "episode": 113.0, "batch_reward": 0.23923625008761884, "critic_loss": 0.37512412640452386, "actor_loss": -26.41660914993286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.53136706352234, "step": 113000}
{"episode_reward": 97.16524039039118, "episode": 114.0, "batch_reward": 0.23958125995099544, "critic_loss": 0.331841841802001, "actor_loss": -26.443444442749023, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.928685188293457, "step": 114000}
{"episode_reward": 506.7546083711213, "episode": 115.0, "batch_reward": 0.24027372325956822, "critic_loss": 0.3645692000091076, "actor_loss": -26.47154775238037, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.777082443237305, "step": 115000}
{"episode_reward": 500.7168123897844, "episode": 116.0, "batch_reward": 0.24098128370940686, "critic_loss": 0.3558438873887062, "actor_loss": -26.618782718658448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.845186948776245, "step": 116000}
{"episode_reward": 47.27003068672311, "episode": 117.0, "batch_reward": 0.24265626794099807, "critic_loss": 0.3461297787427902, "actor_loss": -26.641741275787354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.713071823120117, "step": 117000}
{"episode_reward": 598.761422678314, "episode": 118.0, "batch_reward": 0.24482110537588597, "critic_loss": 0.33949500299990176, "actor_loss": -26.889226432800292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.785431623458862, "step": 118000}
{"episode_reward": 541.5007139760827, "episode": 119.0, "batch_reward": 0.24675681100785732, "critic_loss": 0.33449811382591726, "actor_loss": -26.88742264175415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.48122787475586, "step": 119000}
{"episode_reward": 506.7480581537935, "episode": 120.0, "batch_reward": 0.24936323750019074, "critic_loss": 0.3396858791708946, "actor_loss": -27.162482292175294, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.856844663619995, "step": 120000}
{"episode_reward": 602.2185540513436, "episode": 121.0, "batch_reward": 0.25191840405762195, "critic_loss": 0.35252386531233787, "actor_loss": -27.365071418762206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 33.85823941230774, "step": 121000}
{"episode_reward": 559.7514084091782, "episode": 122.0, "batch_reward": 0.255389824911952, "critic_loss": 0.34435740230977535, "actor_loss": -27.68590060043335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.326379537582397, "step": 122000}
{"episode_reward": 424.3417985193463, "episode": 123.0, "batch_reward": 0.25699911476671694, "critic_loss": 0.36049952717125416, "actor_loss": -27.7996330909729, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.78183889389038, "step": 123000}
{"episode_reward": 655.5004651983971, "episode": 124.0, "batch_reward": 0.2598809849768877, "critic_loss": 0.3481583180576563, "actor_loss": -28.11879083251953, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.011401176452637, "step": 124000}
{"episode_reward": 557.282256125088, "episode": 125.0, "batch_reward": 0.26138190065324307, "critic_loss": 0.35647503611445425, "actor_loss": -28.120131355285643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.745539665222168, "step": 125000}
{"episode_reward": 530.671211283099, "episode": 126.0, "batch_reward": 0.26412887436151505, "critic_loss": 0.36259793320298195, "actor_loss": -28.421838737487793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.70928406715393, "step": 126000}
{"episode_reward": 377.2171353862099, "episode": 127.0, "batch_reward": 0.2637936917096376, "critic_loss": 0.3584270345419645, "actor_loss": -28.268515407562255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.173892736434937, "step": 127000}
{"episode_reward": 121.89259192263003, "episode": 128.0, "batch_reward": 0.26445447155833246, "critic_loss": 0.3622504820972681, "actor_loss": -28.4282114982605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.669224977493286, "step": 128000}
{"episode_reward": 621.5853844609172, "episode": 129.0, "batch_reward": 0.2665641493946314, "critic_loss": 0.36110731856524947, "actor_loss": -28.571876636505127, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.47365164756775, "step": 129000}
{"episode_reward": 630.3846238645799, "episode": 130.0, "batch_reward": 0.26941901063919066, "critic_loss": 0.3850975521206856, "actor_loss": -28.746563961029054, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.05649209022522, "step": 130000}
{"episode_reward": 556.0574349311252, "episode": 131.0, "batch_reward": 0.2717637315094471, "critic_loss": 0.3828661107867956, "actor_loss": -28.94335855102539, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 33.117324113845825, "step": 131000}
{"episode_reward": 559.5331094552054, "episode": 132.0, "batch_reward": 0.27404188287258147, "critic_loss": 0.3486889426708221, "actor_loss": -29.227170974731447, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.38621425628662, "step": 132000}
{"episode_reward": 643.7437636257882, "episode": 133.0, "batch_reward": 0.27653945872187613, "critic_loss": 0.38723528778553007, "actor_loss": -29.3562096824646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.007147312164307, "step": 133000}
{"episode_reward": 535.3514490983661, "episode": 134.0, "batch_reward": 0.2779528876543045, "critic_loss": 0.38630894385278225, "actor_loss": -29.610317890167238, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.75222134590149, "step": 134000}
{"episode_reward": 645.6720422638098, "episode": 135.0, "batch_reward": 0.2813749188929796, "critic_loss": 0.36768165706098077, "actor_loss": -29.801022270202637, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.112781047821045, "step": 135000}
{"episode_reward": 629.2386252077213, "episode": 136.0, "batch_reward": 0.2837789459377527, "critic_loss": 0.4094559709429741, "actor_loss": -30.075295631408693, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.555043935775757, "step": 136000}
{"episode_reward": 335.4400696736574, "episode": 137.0, "batch_reward": 0.28364108200371263, "critic_loss": 0.3689969562143087, "actor_loss": -30.154529289245605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.44397234916687, "step": 137000}
{"episode_reward": 361.13653939122514, "episode": 138.0, "batch_reward": 0.284250189602375, "critic_loss": 0.3674871337115765, "actor_loss": -30.185914501190187, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.665727376937866, "step": 138000}
{"episode_reward": 508.08287221215056, "episode": 139.0, "batch_reward": 0.28621422411501407, "critic_loss": 0.3749597806185484, "actor_loss": -30.270643013000488, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.889607906341553, "step": 139000}
{"episode_reward": 390.24390804578974, "episode": 140.0, "batch_reward": 0.2854075456261635, "critic_loss": 0.362954637542367, "actor_loss": -30.4194340133667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.571165084838867, "step": 140000}
{"episode_reward": 634.4923072427437, "episode": 141.0, "batch_reward": 0.2900082496553659, "critic_loss": 0.38415534363687037, "actor_loss": -30.65046090698242, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 32.77139687538147, "step": 141000}
{"episode_reward": 531.6547898258412, "episode": 142.0, "batch_reward": 0.29163202157616613, "critic_loss": 0.35556296387314795, "actor_loss": -30.888374759674072, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.88222861289978, "step": 142000}
{"episode_reward": 603.6898225095728, "episode": 143.0, "batch_reward": 0.2925445784777403, "critic_loss": 0.38665364845097067, "actor_loss": -30.95832734680176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.878180980682373, "step": 143000}
{"episode_reward": 584.513574953531, "episode": 144.0, "batch_reward": 0.29615707747638226, "critic_loss": 0.40590192142128945, "actor_loss": -31.36425929260254, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.65827751159668, "step": 144000}
{"episode_reward": 530.8362783386019, "episode": 145.0, "batch_reward": 0.29530151255428794, "critic_loss": 0.4029877256155014, "actor_loss": -31.298076904296874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.224623918533325, "step": 145000}
{"episode_reward": 442.2296591987301, "episode": 146.0, "batch_reward": 0.2969760067760944, "critic_loss": 0.4071491787135601, "actor_loss": -31.50235144042969, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.26731514930725, "step": 146000}
{"episode_reward": 613.1117585893431, "episode": 147.0, "batch_reward": 0.29895703691244124, "critic_loss": 0.3960525539815426, "actor_loss": -31.680615547180174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.035348653793335, "step": 147000}
{"episode_reward": 398.10064901853, "episode": 148.0, "batch_reward": 0.30099173025786874, "critic_loss": 0.44041097223758696, "actor_loss": -31.614622817993165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.05174946784973, "step": 148000}
{"episode_reward": 561.645242533092, "episode": 149.0, "batch_reward": 0.30339837373793127, "critic_loss": 0.42199240930378434, "actor_loss": -32.02987740325928, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.49796962738037, "step": 149000}
{"episode_reward": 622.2353370171835, "episode": 150.0, "batch_reward": 0.30445268912613394, "critic_loss": 0.42457692575454714, "actor_loss": -31.972373378753662, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
