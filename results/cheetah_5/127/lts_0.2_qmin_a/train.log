{"episode_reward": 0.0, "episode": 1.0, "duration": 17.773871898651123, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.5192747116088867, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.2673880326803544, "critic_loss": 0.0335892401461742, "actor_loss": -9.7001422187265, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 62.682636976242065, "step": 3000}
{"episode_reward": 179.8054900947094, "episode": 4.0, "batch_reward": 0.22632504819333554, "critic_loss": 0.045417536900378766, "actor_loss": -10.553282014846802, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.947274684906006, "step": 4000}
{"episode_reward": 114.27095881795732, "episode": 5.0, "batch_reward": 0.2182522828280926, "critic_loss": 0.051050133461132643, "actor_loss": -9.985803350925446, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.12530493736267, "step": 5000}
{"episode_reward": 214.58032592401233, "episode": 6.0, "batch_reward": 0.21304499641060828, "critic_loss": 0.0557396008297801, "actor_loss": -11.396034313201904, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.27802038192749, "step": 6000}
{"episode_reward": 274.18357516020166, "episode": 7.0, "batch_reward": 0.21996188253164292, "critic_loss": 0.07481420641019941, "actor_loss": -11.204993944168091, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.037532567977905, "step": 7000}
{"episode_reward": 152.01067898846497, "episode": 8.0, "batch_reward": 0.21484521239995957, "critic_loss": 0.10902064056694508, "actor_loss": -11.712069502830506, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.272759199142456, "step": 8000}
{"episode_reward": 182.09113482807552, "episode": 9.0, "batch_reward": 0.199637192055583, "critic_loss": 0.09951613431796431, "actor_loss": -11.84420622253418, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.331884145736694, "step": 9000}
{"episode_reward": 32.363511421912655, "episode": 10.0, "batch_reward": 0.18363513626158237, "critic_loss": 0.1078871164135635, "actor_loss": -11.939977328300476, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.213007926940918, "step": 10000}
{"episode_reward": 54.96210452590699, "episode": 11.0, "batch_reward": 0.17289298178255558, "critic_loss": 0.12315689843147994, "actor_loss": -11.771497873306274, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.729406118392944, "step": 11000}
{"episode_reward": 50.902221481595234, "episode": 12.0, "batch_reward": 0.16383068387955427, "critic_loss": 0.11656258843839168, "actor_loss": -12.031270428657532, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.305880069732666, "step": 12000}
{"episode_reward": 103.89988273011481, "episode": 13.0, "batch_reward": 0.15752060213685035, "critic_loss": 0.11569757376983762, "actor_loss": -11.661741773605346, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.408345937728882, "step": 13000}
{"episode_reward": 75.02820586133274, "episode": 14.0, "batch_reward": 0.14981892914324998, "critic_loss": 0.14261584898084403, "actor_loss": -11.988601257324218, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.050389766693115, "step": 14000}
{"episode_reward": 41.48809437393548, "episode": 15.0, "batch_reward": 0.14584676084667444, "critic_loss": 0.1403567962795496, "actor_loss": -12.18412899017334, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.790936946868896, "step": 15000}
{"episode_reward": 120.04908789529166, "episode": 16.0, "batch_reward": 0.14918455138802528, "critic_loss": 0.15605163600295782, "actor_loss": -12.772646669387818, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.039865016937256, "step": 16000}
{"episode_reward": 384.86058910674797, "episode": 17.0, "batch_reward": 0.1580906989276409, "critic_loss": 0.1931632207110524, "actor_loss": -13.890863674163818, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.263442516326904, "step": 17000}
{"episode_reward": 181.8567953855634, "episode": 18.0, "batch_reward": 0.1615229040235281, "critic_loss": 0.2240530721619725, "actor_loss": -14.604488403320312, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.8392231464386, "step": 18000}
{"episode_reward": 184.44687340158316, "episode": 19.0, "batch_reward": 0.15787908848375082, "critic_loss": 0.18878355535119773, "actor_loss": -14.679667734146118, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.82178521156311, "step": 19000}
{"episode_reward": 38.725569740280214, "episode": 20.0, "batch_reward": 0.1516519809216261, "critic_loss": 0.19624853363633155, "actor_loss": -14.522664541244508, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.234672784805298, "step": 20000}
{"episode_reward": 40.25848604301225, "episode": 21.0, "batch_reward": 0.14893273151665926, "critic_loss": 0.20254891870170832, "actor_loss": -14.559146507263183, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.94610929489136, "step": 21000}
{"episode_reward": 204.8464121975891, "episode": 22.0, "batch_reward": 0.15540663594007492, "critic_loss": 0.2174698473587632, "actor_loss": -15.344179927825929, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.46375608444214, "step": 22000}
{"episode_reward": 257.25110775452816, "episode": 23.0, "batch_reward": 0.15786715625971556, "critic_loss": 0.24585803711414336, "actor_loss": -15.580059539794922, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.159116983413696, "step": 23000}
{"episode_reward": 167.3630472181311, "episode": 24.0, "batch_reward": 0.1552677152082324, "critic_loss": 0.22008496277034284, "actor_loss": -15.686120826721192, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.674975395202637, "step": 24000}
{"episode_reward": 52.566125207478045, "episode": 25.0, "batch_reward": 0.15813627034425737, "critic_loss": 0.2311828622967005, "actor_loss": -16.044778533935546, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.79473567008972, "step": 25000}
{"episode_reward": 442.3685385665637, "episode": 26.0, "batch_reward": 0.16293616081029177, "critic_loss": 0.262809286378324, "actor_loss": -16.53201943397522, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.745249032974243, "step": 26000}
{"episode_reward": 77.22959292295872, "episode": 27.0, "batch_reward": 0.15875875921547414, "critic_loss": 0.2684714488834143, "actor_loss": -16.512276351928712, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.297375917434692, "step": 27000}
{"episode_reward": 22.38945520014386, "episode": 28.0, "batch_reward": 0.15698246443271638, "critic_loss": 0.30107441198080775, "actor_loss": -16.522548494338988, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.045658349990845, "step": 28000}
{"episode_reward": 195.83931584013715, "episode": 29.0, "batch_reward": 0.15840681312978266, "critic_loss": 0.2550430558025837, "actor_loss": -16.904179954528807, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.13992404937744, "step": 29000}
{"episode_reward": 285.3560124987474, "episode": 30.0, "batch_reward": 0.16152136519551277, "critic_loss": 0.269010254599154, "actor_loss": -17.285161205291747, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.32052230834961, "step": 30000}
{"episode_reward": 96.12134130011428, "episode": 31.0, "batch_reward": 0.16159218867123126, "critic_loss": 0.26405204950273037, "actor_loss": -17.437032205581666, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.54745268821716, "step": 31000}
{"episode_reward": 238.45336692688625, "episode": 32.0, "batch_reward": 0.16447887975722553, "critic_loss": 0.29235323441028593, "actor_loss": -17.706653955459593, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.565996408462524, "step": 32000}
{"episode_reward": 220.40675553343183, "episode": 33.0, "batch_reward": 0.16465506649017334, "critic_loss": 0.31193680068850516, "actor_loss": -17.898786897659303, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.838186502456665, "step": 33000}
{"episode_reward": 129.37744106784888, "episode": 34.0, "batch_reward": 0.16428812117874622, "critic_loss": 0.2804475528746843, "actor_loss": -17.858746786117553, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.29075050354004, "step": 34000}
{"episode_reward": 155.8302216683737, "episode": 35.0, "batch_reward": 0.16385288709402085, "critic_loss": 0.2785116729140282, "actor_loss": -17.94920837211609, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.36008596420288, "step": 35000}
{"episode_reward": 330.7396318162637, "episode": 36.0, "batch_reward": 0.16869337795674802, "critic_loss": 0.29496165637671945, "actor_loss": -18.268952472686767, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.15319514274597, "step": 36000}
{"episode_reward": 221.20235182384567, "episode": 37.0, "batch_reward": 0.17030595157295467, "critic_loss": 0.27719356113672255, "actor_loss": -18.17337237548828, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.179734468460083, "step": 37000}
{"episode_reward": 166.42653563552514, "episode": 38.0, "batch_reward": 0.17037573375552892, "critic_loss": 0.3183428449034691, "actor_loss": -18.280222677230835, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.17446756362915, "step": 38000}
{"episode_reward": 295.7086660931334, "episode": 39.0, "batch_reward": 0.1723305121809244, "critic_loss": 0.3054918512851, "actor_loss": -18.542737785339355, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.68950319290161, "step": 39000}
{"episode_reward": 161.96347243469938, "episode": 40.0, "batch_reward": 0.17251180336624383, "critic_loss": 0.31966669514775276, "actor_loss": -18.584746959686278, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.331237077713013, "step": 40000}
{"episode_reward": 164.22654214943694, "episode": 41.0, "batch_reward": 0.17128985241800546, "critic_loss": 0.3290320823341608, "actor_loss": -18.496411766052248, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.709309816360474, "step": 41000}
{"episode_reward": 85.20649160644008, "episode": 42.0, "batch_reward": 0.17079090762138366, "critic_loss": 0.35387523917108776, "actor_loss": -18.566691625595094, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.326584577560425, "step": 42000}
{"episode_reward": 159.31047839300007, "episode": 43.0, "batch_reward": 0.16969046802818774, "critic_loss": 0.33920945663750174, "actor_loss": -18.48824608230591, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.462064266204834, "step": 43000}
{"episode_reward": 119.0669591417108, "episode": 44.0, "batch_reward": 0.16930288837105037, "critic_loss": 0.3129319968223572, "actor_loss": -18.63826107597351, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.265635013580322, "step": 44000}
{"episode_reward": 201.7372543709553, "episode": 45.0, "batch_reward": 0.16961324071884154, "critic_loss": 0.33846263925731185, "actor_loss": -18.63285067176819, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.13075041770935, "step": 45000}
{"episode_reward": 369.6871628799179, "episode": 46.0, "batch_reward": 0.17522332386672496, "critic_loss": 0.33581063443422315, "actor_loss": -19.052141700744627, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.27313494682312, "step": 46000}
{"episode_reward": 345.8943369997209, "episode": 47.0, "batch_reward": 0.17617251086980104, "critic_loss": 0.3486347142904997, "actor_loss": -19.164491868972778, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.830591440200806, "step": 47000}
{"episode_reward": 54.908836314823155, "episode": 48.0, "batch_reward": 0.17490134447813033, "critic_loss": 0.3456001066714525, "actor_loss": -19.033343067169188, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.11797571182251, "step": 48000}
{"episode_reward": 123.57603681268932, "episode": 49.0, "batch_reward": 0.17360285434126854, "critic_loss": 0.3386105369031429, "actor_loss": -18.9458948135376, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.492765426635742, "step": 49000}
{"episode_reward": 122.22565300067436, "episode": 50.0, "batch_reward": 0.17420697082579137, "critic_loss": 0.33717085371911526, "actor_loss": -19.03437349128723, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.27721333503723, "step": 50000}
{"episode_reward": 368.5725205085465, "episode": 51.0, "batch_reward": 0.17612240962684156, "critic_loss": 0.34244843116402623, "actor_loss": -19.214636302947998, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.618865728378296, "step": 51000}
{"episode_reward": 102.06169798226496, "episode": 52.0, "batch_reward": 0.17678967371582985, "critic_loss": 0.31395679572224616, "actor_loss": -19.227986614227294, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.028611183166504, "step": 52000}
{"episode_reward": 435.55945805918526, "episode": 53.0, "batch_reward": 0.18118560601770878, "critic_loss": 0.3257281982153654, "actor_loss": -19.573975395202638, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.32654905319214, "step": 53000}
{"episode_reward": 234.96602165083166, "episode": 54.0, "batch_reward": 0.18300603480637073, "critic_loss": 0.3749978706985712, "actor_loss": -19.826664587020876, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.14927101135254, "step": 54000}
{"episode_reward": 250.09393539481846, "episode": 55.0, "batch_reward": 0.1829724628329277, "critic_loss": 0.37840746182203294, "actor_loss": -19.788398143768312, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.871109008789062, "step": 55000}
{"episode_reward": 287.6613267517099, "episode": 56.0, "batch_reward": 0.18518985165655613, "critic_loss": 0.3726218134313822, "actor_loss": -19.9364977645874, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.48841953277588, "step": 56000}
{"episode_reward": 143.8544858625942, "episode": 57.0, "batch_reward": 0.18181609653681516, "critic_loss": 0.39031871291995046, "actor_loss": -19.62400902938843, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.98747968673706, "step": 57000}
{"episode_reward": 27.22081065393378, "episode": 58.0, "batch_reward": 0.18185289092361928, "critic_loss": 0.40668580192327497, "actor_loss": -19.810703956604005, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.84406304359436, "step": 58000}
{"episode_reward": 281.70976034759946, "episode": 59.0, "batch_reward": 0.18212131698429584, "critic_loss": 0.41384355738759043, "actor_loss": -19.757912982940674, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.215989351272583, "step": 59000}
{"episode_reward": 143.84408404412304, "episode": 60.0, "batch_reward": 0.1821929731965065, "critic_loss": 0.3981569355428219, "actor_loss": -19.778714193344115, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.24449396133423, "step": 60000}
{"episode_reward": 190.71392700711655, "episode": 61.0, "batch_reward": 0.18149636620283127, "critic_loss": 0.3704587661027908, "actor_loss": -19.695491203308105, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.37907648086548, "step": 61000}
{"episode_reward": 135.56923804888663, "episode": 62.0, "batch_reward": 0.1814988447278738, "critic_loss": 0.3825925910025835, "actor_loss": -19.60415026473999, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.006025552749634, "step": 62000}
{"episode_reward": 80.81283681363287, "episode": 63.0, "batch_reward": 0.18106683258712292, "critic_loss": 0.36712262892723085, "actor_loss": -19.619515590667724, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.587902784347534, "step": 63000}
{"episode_reward": 258.45222352396917, "episode": 64.0, "batch_reward": 0.1815187435746193, "critic_loss": 0.38342497961223126, "actor_loss": -19.623086080551147, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.802140474319458, "step": 64000}
{"episode_reward": 333.98668840952314, "episode": 65.0, "batch_reward": 0.18305101973563434, "critic_loss": 0.40425939360260965, "actor_loss": -19.6616603679657, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.64548945426941, "step": 65000}
{"episode_reward": 161.60363870764834, "episode": 66.0, "batch_reward": 0.184627564817667, "critic_loss": 0.4260020416229963, "actor_loss": -19.75768544769287, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.232977628707886, "step": 66000}
{"episode_reward": 341.01060815223735, "episode": 67.0, "batch_reward": 0.1854567328542471, "critic_loss": 0.4029980112910271, "actor_loss": -19.792993129730224, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.83772850036621, "step": 67000}
{"episode_reward": 109.29985999483897, "episode": 68.0, "batch_reward": 0.1848007167726755, "critic_loss": 0.397112617790699, "actor_loss": -19.710758169174195, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.43503165245056, "step": 68000}
{"episode_reward": 146.18720713857337, "episode": 69.0, "batch_reward": 0.18419763818383217, "critic_loss": 0.44770939061045645, "actor_loss": -19.59929564857483, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.244811296463013, "step": 69000}
{"episode_reward": 231.37395879936145, "episode": 70.0, "batch_reward": 0.1835323520153761, "critic_loss": 0.42650115403532984, "actor_loss": -19.551988636016844, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.54328751564026, "step": 70000}
{"episode_reward": 56.29216441637487, "episode": 71.0, "batch_reward": 0.183232019379735, "critic_loss": 0.4066241904199123, "actor_loss": -19.4737711353302, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.52188324928284, "step": 71000}
{"episode_reward": 260.4559806695392, "episode": 72.0, "batch_reward": 0.18254084876179696, "critic_loss": 0.4076071510016918, "actor_loss": -19.439419471740724, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.30698847770691, "step": 72000}
{"episode_reward": 38.487414667258165, "episode": 73.0, "batch_reward": 0.18046204379200936, "critic_loss": 0.4047853741198778, "actor_loss": -19.266243614196778, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.956168174743652, "step": 73000}
{"episode_reward": 69.79879844890053, "episode": 74.0, "batch_reward": 0.18164221431314945, "critic_loss": 0.4468413325846195, "actor_loss": -19.372166292190553, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.007274866104126, "step": 74000}
{"episode_reward": 310.8240489054533, "episode": 75.0, "batch_reward": 0.183512407630682, "critic_loss": 0.44661274625360964, "actor_loss": -19.524160537719727, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.022512197494507, "step": 75000}
{"episode_reward": 413.9896362760433, "episode": 76.0, "batch_reward": 0.18502671383321284, "critic_loss": 0.45189200463891027, "actor_loss": -19.5906062335968, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.860252141952515, "step": 76000}
{"episode_reward": 117.69154156071208, "episode": 77.0, "batch_reward": 0.18368893422186375, "critic_loss": 0.43709582403302194, "actor_loss": -19.49612155532837, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.276284217834473, "step": 77000}
{"episode_reward": 141.5509759339208, "episode": 78.0, "batch_reward": 0.18417189034819603, "critic_loss": 0.4274100813418627, "actor_loss": -19.51138279914856, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.428972244262695, "step": 78000}
{"episode_reward": 336.12628130630065, "episode": 79.0, "batch_reward": 0.18595110104978085, "critic_loss": 0.4348808036148548, "actor_loss": -19.628655742645265, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.837706565856934, "step": 79000}
{"episode_reward": 106.02411618225209, "episode": 80.0, "batch_reward": 0.1855860750824213, "critic_loss": 0.4524404572993517, "actor_loss": -19.56199556350708, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.18867254257202, "step": 80000}
{"episode_reward": 283.13420323143, "episode": 81.0, "batch_reward": 0.18503214336931706, "critic_loss": 0.4499022619873285, "actor_loss": -19.421962421417238, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.140074014663696, "step": 81000}
{"episode_reward": 73.78923703132823, "episode": 82.0, "batch_reward": 0.1834319865256548, "critic_loss": 0.4518934458941221, "actor_loss": -19.37507931518555, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.370291471481323, "step": 82000}
{"episode_reward": 84.03645481657257, "episode": 83.0, "batch_reward": 0.18369507318735123, "critic_loss": 0.4354243479073048, "actor_loss": -19.312975231170654, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.913676738739014, "step": 83000}
{"episode_reward": 169.52316371918113, "episode": 84.0, "batch_reward": 0.1826945112645626, "critic_loss": 0.46937156043946743, "actor_loss": -19.232192470550537, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.832945585250854, "step": 84000}
{"episode_reward": 226.53352353928548, "episode": 85.0, "batch_reward": 0.1839426071792841, "critic_loss": 0.42959561002254487, "actor_loss": -19.307347412109376, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.88855218887329, "step": 85000}
{"episode_reward": 197.9030044215377, "episode": 86.0, "batch_reward": 0.1844966480731964, "critic_loss": 0.4834193496108055, "actor_loss": -19.35362034225464, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.477641820907593, "step": 86000}
{"episode_reward": 423.8736382782705, "episode": 87.0, "batch_reward": 0.18866455997526646, "critic_loss": 0.5075918067842722, "actor_loss": -19.62511204147339, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.824016571044922, "step": 87000}
{"episode_reward": 488.34170290402653, "episode": 88.0, "batch_reward": 0.1900506531894207, "critic_loss": 0.4837978060990572, "actor_loss": -19.759090896606445, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.897088766098022, "step": 88000}
{"episode_reward": 154.77961058973688, "episode": 89.0, "batch_reward": 0.18895741651952266, "critic_loss": 0.5086410007625818, "actor_loss": -19.565908910751343, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.048049688339233, "step": 89000}
{"episode_reward": 105.71925691493834, "episode": 90.0, "batch_reward": 0.19040073311328887, "critic_loss": 0.5160312979817391, "actor_loss": -19.639577739715577, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.829567670822144, "step": 90000}
{"episode_reward": 204.95050160299908, "episode": 91.0, "batch_reward": 0.19081129080057144, "critic_loss": 0.482815079331398, "actor_loss": -19.671327146530153, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 38.03594517707825, "step": 91000}
{"episode_reward": 526.3509026738047, "episode": 92.0, "batch_reward": 0.19356438080966473, "critic_loss": 0.49612089309096336, "actor_loss": -19.951206693649294, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.27502965927124, "step": 92000}
{"episode_reward": 398.2376366126056, "episode": 93.0, "batch_reward": 0.19548476187884808, "critic_loss": 0.4804247426241636, "actor_loss": -20.079847980499267, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.04357600212097, "step": 93000}
{"episode_reward": 332.2989508681322, "episode": 94.0, "batch_reward": 0.19641447786986826, "critic_loss": 0.4779439285695553, "actor_loss": -20.01234886932373, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.671427488327026, "step": 94000}
{"episode_reward": 176.93236580152748, "episode": 95.0, "batch_reward": 0.1956318759918213, "critic_loss": 0.47816383627057074, "actor_loss": -19.93968960380554, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.786245107650757, "step": 95000}
{"episode_reward": 84.14643071159063, "episode": 96.0, "batch_reward": 0.1960847412496805, "critic_loss": 0.47072297930717466, "actor_loss": -20.042439176559448, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.942902326583862, "step": 96000}
{"episode_reward": 196.1748059337115, "episode": 97.0, "batch_reward": 0.19587293311953544, "critic_loss": 0.4735153063982725, "actor_loss": -20.0313894405365, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.784767389297485, "step": 97000}
{"episode_reward": 476.3052796523674, "episode": 98.0, "batch_reward": 0.1967819048911333, "critic_loss": 0.46264551578462126, "actor_loss": -20.059204357147216, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.071871280670166, "step": 98000}
{"episode_reward": 46.975612259804706, "episode": 99.0, "batch_reward": 0.19748920720815658, "critic_loss": 0.4434592190980911, "actor_loss": -20.16640688896179, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.023460865020752, "step": 99000}
{"episode_reward": 423.55077031103764, "episode": 100.0, "batch_reward": 0.19795952288806437, "critic_loss": 0.4624867535233498, "actor_loss": -20.15839976501465, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.454167127609253, "step": 100000}
{"episode_reward": 163.52413173329674, "episode": 101.0, "batch_reward": 0.19929213689267636, "critic_loss": 0.49403009425103667, "actor_loss": -20.31071607208252, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.441354513168335, "step": 101000}
{"episode_reward": 397.7010462363987, "episode": 102.0, "batch_reward": 0.20121323493123056, "critic_loss": 0.4805155767351389, "actor_loss": -20.446083908081054, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.618181705474854, "step": 102000}
{"episode_reward": 335.4646138351202, "episode": 103.0, "batch_reward": 0.20245722667872906, "critic_loss": 0.5176768444925547, "actor_loss": -20.458744869232177, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.407268285751343, "step": 103000}
{"episode_reward": 271.51407200089614, "episode": 104.0, "batch_reward": 0.2026889221072197, "critic_loss": 0.5245506747066975, "actor_loss": -20.487603939056395, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.32684898376465, "step": 104000}
{"episode_reward": 298.1274966888152, "episode": 105.0, "batch_reward": 0.20275456719100476, "critic_loss": 0.48753192435204984, "actor_loss": -20.358236064910887, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.171019077301025, "step": 105000}
{"episode_reward": 47.902890994286565, "episode": 106.0, "batch_reward": 0.20147154431045056, "critic_loss": 0.4800242658108473, "actor_loss": -20.454118061065675, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.459395170211792, "step": 106000}
{"episode_reward": 98.95796277845182, "episode": 107.0, "batch_reward": 0.19998217076063157, "critic_loss": 0.44928504595160484, "actor_loss": -20.270784820556642, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.28399968147278, "step": 107000}
{"episode_reward": 128.24653995169098, "episode": 108.0, "batch_reward": 0.19996792221069337, "critic_loss": 0.49742201139032843, "actor_loss": -20.169435375213624, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.984782695770264, "step": 108000}
{"episode_reward": 98.39855530453843, "episode": 109.0, "batch_reward": 0.19865121518075465, "critic_loss": 0.44469658224284647, "actor_loss": -20.16534599494934, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.834347248077393, "step": 109000}
{"episode_reward": 177.09061918460523, "episode": 110.0, "batch_reward": 0.19860785959661006, "critic_loss": 0.44948842480778695, "actor_loss": -20.105875995635987, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.104695796966553, "step": 110000}
{"episode_reward": 56.54529762959171, "episode": 111.0, "batch_reward": 0.19773696249723435, "critic_loss": 0.4693755966871977, "actor_loss": -19.951297409057617, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.88427400588989, "step": 111000}
{"episode_reward": 203.85391554090384, "episode": 112.0, "batch_reward": 0.19853148019313813, "critic_loss": 0.46722422225773336, "actor_loss": -20.079771797180175, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.249189376831055, "step": 112000}
{"episode_reward": 432.6824193124564, "episode": 113.0, "batch_reward": 0.2008979773968458, "critic_loss": 0.48772925497591496, "actor_loss": -20.1459122467041, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.835992097854614, "step": 113000}
{"episode_reward": 361.0640522566527, "episode": 114.0, "batch_reward": 0.20132609874010085, "critic_loss": 0.4773027593642473, "actor_loss": -20.12971277809143, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.557859182357788, "step": 114000}
{"episode_reward": 141.57708436108624, "episode": 115.0, "batch_reward": 0.2006160834133625, "critic_loss": 0.4933163974583149, "actor_loss": -20.078670558929442, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.861555099487305, "step": 115000}
{"episode_reward": 312.74381398872254, "episode": 116.0, "batch_reward": 0.20132385866343974, "critic_loss": 0.48367937828600405, "actor_loss": -20.079806371688843, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.82938575744629, "step": 116000}
{"episode_reward": 122.04540743527838, "episode": 117.0, "batch_reward": 0.2021250784099102, "critic_loss": 0.4555388181209564, "actor_loss": -20.18869520187378, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.289155960083008, "step": 117000}
{"episode_reward": 490.94089830947337, "episode": 118.0, "batch_reward": 0.20379062584042548, "critic_loss": 0.46169473481178286, "actor_loss": -20.290109512329103, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.904003143310547, "step": 118000}
{"episode_reward": 373.055229133317, "episode": 119.0, "batch_reward": 0.20499542248249053, "critic_loss": 0.482348655089736, "actor_loss": -20.272322067260742, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.895079851150513, "step": 119000}
{"episode_reward": 264.9137418765215, "episode": 120.0, "batch_reward": 0.20563194411993027, "critic_loss": 0.4647860640585422, "actor_loss": -20.274713317871093, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.515942096710205, "step": 120000}
{"episode_reward": 178.53851765143742, "episode": 121.0, "batch_reward": 0.2057399253845215, "critic_loss": 0.44823589593172075, "actor_loss": -20.26183283615112, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.067771196365356, "step": 121000}
{"episode_reward": 265.3754216733547, "episode": 122.0, "batch_reward": 0.20572698663175107, "critic_loss": 0.4501353317052126, "actor_loss": -20.299873443603516, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.003856420516968, "step": 122000}
{"episode_reward": 401.40180223635224, "episode": 123.0, "batch_reward": 0.2081306087821722, "critic_loss": 0.48614263607561586, "actor_loss": -20.532441673278807, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.233548879623413, "step": 123000}
{"episode_reward": 467.0026899296052, "episode": 124.0, "batch_reward": 0.2107748613357544, "critic_loss": 0.4613192089945078, "actor_loss": -20.711385326385496, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.062567234039307, "step": 124000}
{"episode_reward": 368.8992769643901, "episode": 125.0, "batch_reward": 0.210298176497221, "critic_loss": 0.4953118508309126, "actor_loss": -20.592299255371096, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.561172008514404, "step": 125000}
{"episode_reward": 327.93221894152964, "episode": 126.0, "batch_reward": 0.2124969123005867, "critic_loss": 0.48942466801404955, "actor_loss": -20.813564544677735, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.158279418945312, "step": 126000}
{"episode_reward": 458.54303611724004, "episode": 127.0, "batch_reward": 0.21310201129317283, "critic_loss": 0.46436193968355655, "actor_loss": -20.832826625823973, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.800193786621094, "step": 127000}
{"episode_reward": 415.98683742474935, "episode": 128.0, "batch_reward": 0.21486083407700063, "critic_loss": 0.44320499858260154, "actor_loss": -20.941397232055664, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.085057258605957, "step": 128000}
{"episode_reward": 231.21216435016558, "episode": 129.0, "batch_reward": 0.21637713864445687, "critic_loss": 0.4541401275843382, "actor_loss": -21.095156352996828, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.252094984054565, "step": 129000}
{"episode_reward": 388.6821258412795, "episode": 130.0, "batch_reward": 0.21716040141880513, "critic_loss": 0.42494387294352054, "actor_loss": -21.085184398651123, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.718218088150024, "step": 130000}
{"episode_reward": 350.1388346312024, "episode": 131.0, "batch_reward": 0.21882247698307036, "critic_loss": 0.49503726688027383, "actor_loss": -21.018999797821046, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.34659194946289, "step": 131000}
{"episode_reward": 462.18399177352194, "episode": 132.0, "batch_reward": 0.22090064276754856, "critic_loss": 0.508823166206479, "actor_loss": -21.227664684295654, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.967364072799683, "step": 132000}
{"episode_reward": 501.26373635622537, "episode": 133.0, "batch_reward": 0.22152068726718427, "critic_loss": 0.44695926298201083, "actor_loss": -21.245809589385985, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.839558839797974, "step": 133000}
{"episode_reward": 273.3722654912968, "episode": 134.0, "batch_reward": 0.22141654162108898, "critic_loss": 0.4871619110405445, "actor_loss": -21.263526481628418, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.060069799423218, "step": 134000}
{"episode_reward": 163.85375657293835, "episode": 135.0, "batch_reward": 0.2219580077677965, "critic_loss": 0.4807886043488979, "actor_loss": -21.353630584716797, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.48889660835266, "step": 135000}
{"episode_reward": 479.20153091693163, "episode": 136.0, "batch_reward": 0.2242392113059759, "critic_loss": 0.5382630867213011, "actor_loss": -21.429009044647216, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.827699899673462, "step": 136000}
{"episode_reward": 164.6650700576591, "episode": 137.0, "batch_reward": 0.22316297186911105, "critic_loss": 0.49232063435018064, "actor_loss": -21.352108863830566, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.030317306518555, "step": 137000}
{"episode_reward": 239.0126884125752, "episode": 138.0, "batch_reward": 0.2232004527747631, "critic_loss": 0.5051665451228619, "actor_loss": -21.234527423858644, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.601438522338867, "step": 138000}
{"episode_reward": 181.1871138489862, "episode": 139.0, "batch_reward": 0.22344116194546224, "critic_loss": 0.47402498561143874, "actor_loss": -21.266986740112305, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.862902402877808, "step": 139000}
{"episode_reward": 170.0065412248783, "episode": 140.0, "batch_reward": 0.2223353725671768, "critic_loss": 0.46954165303707124, "actor_loss": -21.20310357475281, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.710819244384766, "step": 140000}
{"episode_reward": 209.82587114461677, "episode": 141.0, "batch_reward": 0.22364754800498485, "critic_loss": 0.5230210321694613, "actor_loss": -21.10603470993042, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.589951038360596, "step": 141000}
{"episode_reward": 157.79199511430443, "episode": 142.0, "batch_reward": 0.2225746369212866, "critic_loss": 0.5299366451501847, "actor_loss": -21.135027091979982, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.861347436904907, "step": 142000}
{"episode_reward": 298.5807149265317, "episode": 143.0, "batch_reward": 0.22254472206532955, "critic_loss": 0.46912810918688774, "actor_loss": -21.150037223815918, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.335144758224487, "step": 143000}
{"episode_reward": 508.4377291394157, "episode": 144.0, "batch_reward": 0.22533344201743602, "critic_loss": 0.4751202300786972, "actor_loss": -21.223871379852294, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.83391499519348, "step": 144000}
{"episode_reward": 256.3094286832499, "episode": 145.0, "batch_reward": 0.2241996830403805, "critic_loss": 0.48450332729518414, "actor_loss": -21.11368752670288, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.030635356903076, "step": 145000}
{"episode_reward": 555.6392941435005, "episode": 146.0, "batch_reward": 0.22682220739126205, "critic_loss": 0.4686383983641863, "actor_loss": -21.340915313720703, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.984400987625122, "step": 146000}
{"episode_reward": 185.18483244039288, "episode": 147.0, "batch_reward": 0.2266189838349819, "critic_loss": 0.4647336845248938, "actor_loss": -21.386794593811036, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.82032036781311, "step": 147000}
{"episode_reward": 356.2485693505672, "episode": 148.0, "batch_reward": 0.22660161001980306, "critic_loss": 0.45864273731410504, "actor_loss": -21.196460006713867, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.749082326889038, "step": 148000}
{"episode_reward": 126.04909869460269, "episode": 149.0, "batch_reward": 0.2280956391096115, "critic_loss": 0.45316044956445695, "actor_loss": -21.32056491470337, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.578920364379883, "step": 149000}
{"episode_reward": 309.8346791225914, "episode": 150.0, "batch_reward": 0.227526486068964, "critic_loss": 0.4730364895015955, "actor_loss": -21.330065773010254, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
