{"episode_reward": 0.0, "episode": 1.0, "duration": 17.784138917922974, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.611156940460205, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.26362100005567213, "critic_loss": 0.05761487891468387, "actor_loss": -29.07491281363262, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 63.51981711387634, "step": 3000}
{"episode_reward": 45.104077786738394, "episode": 4.0, "batch_reward": 0.17888139310479165, "critic_loss": 0.056414873348549006, "actor_loss": -21.726171810626983, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.46355390548706, "step": 4000}
{"episode_reward": 45.08205399630324, "episode": 5.0, "batch_reward": 0.1456744656190276, "critic_loss": 0.04082970089279115, "actor_loss": -20.456000528335572, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.802643060684204, "step": 5000}
{"episode_reward": 11.46782586105896, "episode": 6.0, "batch_reward": 0.1264627688974142, "critic_loss": 0.04532602524571121, "actor_loss": -20.97888071513176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.455923080444336, "step": 6000}
{"episode_reward": 96.85508052230121, "episode": 7.0, "batch_reward": 0.12112377755343914, "critic_loss": 0.05216944354400039, "actor_loss": -19.82890816473961, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.411425352096558, "step": 7000}
{"episode_reward": 50.84175760309471, "episode": 8.0, "batch_reward": 0.11236162636429071, "critic_loss": 0.05217275519110262, "actor_loss": -18.955008105278015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.290037393569946, "step": 8000}
{"episode_reward": 105.48397282158493, "episode": 9.0, "batch_reward": 0.11831205888837576, "critic_loss": 0.07274763768911362, "actor_loss": -19.221328300356866, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.980737686157227, "step": 9000}
{"episode_reward": 229.34270014607313, "episode": 10.0, "batch_reward": 0.12700123209506273, "critic_loss": 0.08391959370858967, "actor_loss": -20.70074489879608, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.39472985267639, "step": 10000}
{"episode_reward": 168.6933925389017, "episode": 11.0, "batch_reward": 0.1373592829629779, "critic_loss": 0.09121050155162812, "actor_loss": -20.074597749382256, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.29415965080261, "step": 11000}
{"episode_reward": 179.6466323641581, "episode": 12.0, "batch_reward": 0.1332521666660905, "critic_loss": 0.08551075748726726, "actor_loss": -19.78395821455121, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.112164735794067, "step": 12000}
{"episode_reward": 107.98973623079871, "episode": 13.0, "batch_reward": 0.13617303490638732, "critic_loss": 0.0980547192916274, "actor_loss": -19.499005687475204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.377300024032593, "step": 13000}
{"episode_reward": 152.79376255327904, "episode": 14.0, "batch_reward": 0.1358040526136756, "critic_loss": 0.10033614902943373, "actor_loss": -19.056782616361975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.810441732406616, "step": 14000}
{"episode_reward": 197.7178436298216, "episode": 15.0, "batch_reward": 0.13822156836092472, "critic_loss": 0.1120616971552372, "actor_loss": -19.76677371494472, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.113808155059814, "step": 15000}
{"episode_reward": 114.37014957674053, "episode": 16.0, "batch_reward": 0.13618645316362382, "critic_loss": 0.13378770683705807, "actor_loss": -20.185621376767756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.469562530517578, "step": 16000}
{"episode_reward": 68.0303271929981, "episode": 17.0, "batch_reward": 0.13387308674305679, "critic_loss": 0.14036957685276866, "actor_loss": -18.522620339751242, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.444643020629883, "step": 17000}
{"episode_reward": 95.59086763577504, "episode": 18.0, "batch_reward": 0.13516365976631642, "critic_loss": 0.1493995318263769, "actor_loss": -18.79213296702504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.894879817962646, "step": 18000}
{"episode_reward": 268.2911391260306, "episode": 19.0, "batch_reward": 0.14020224099606277, "critic_loss": 0.16203292233496905, "actor_loss": -19.055058926701545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.502315998077393, "step": 19000}
{"episode_reward": 150.6057474851833, "episode": 20.0, "batch_reward": 0.13930153609067203, "critic_loss": 0.15589485169947148, "actor_loss": -19.998717570066454, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.37994647026062, "step": 20000}
{"episode_reward": 92.1068030364987, "episode": 21.0, "batch_reward": 0.1387089398279786, "critic_loss": 0.13835348381847143, "actor_loss": -18.467602553725243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.030235052108765, "step": 21000}
{"episode_reward": 245.81418607790005, "episode": 22.0, "batch_reward": 0.145339908644557, "critic_loss": 0.15097445095330478, "actor_loss": -19.97568998336792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.300063371658325, "step": 22000}
{"episode_reward": 292.82269056251516, "episode": 23.0, "batch_reward": 0.1504376913458109, "critic_loss": 0.15874224032461642, "actor_loss": -19.713682345867156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.711415767669678, "step": 23000}
{"episode_reward": 161.014996299756, "episode": 24.0, "batch_reward": 0.15107857418805362, "critic_loss": 0.16331868736445904, "actor_loss": -20.418939289569856, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.628973722457886, "step": 24000}
{"episode_reward": 300.7495398875222, "episode": 25.0, "batch_reward": 0.15713011623173953, "critic_loss": 0.19033905535191298, "actor_loss": -21.2811735663414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.222779512405396, "step": 25000}
{"episode_reward": 152.1641044807668, "episode": 26.0, "batch_reward": 0.15676617082953453, "critic_loss": 0.17893986859172584, "actor_loss": -20.441250997066497, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.125207662582397, "step": 26000}
{"episode_reward": 277.8643575079831, "episode": 27.0, "batch_reward": 0.16227443566918373, "critic_loss": 0.2115700304657221, "actor_loss": -20.962970280647276, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.43429470062256, "step": 27000}
{"episode_reward": 295.83651984311956, "episode": 28.0, "batch_reward": 0.165332919575274, "critic_loss": 0.20976609804481267, "actor_loss": -21.046999793052674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.7027804851532, "step": 28000}
{"episode_reward": 81.92926749545362, "episode": 29.0, "batch_reward": 0.16371280268579722, "critic_loss": 0.19865771742910146, "actor_loss": -21.148655755996703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.360241413116455, "step": 29000}
{"episode_reward": 282.8700696122831, "episode": 30.0, "batch_reward": 0.1658222233876586, "critic_loss": 0.21827036766707897, "actor_loss": -20.847474768638612, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.084478855133057, "step": 30000}
{"episode_reward": 86.01858981735123, "episode": 31.0, "batch_reward": 0.1622818880081177, "critic_loss": 0.23632226921617985, "actor_loss": -20.561588254928587, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.19009280204773, "step": 31000}
{"episode_reward": 103.09252858120881, "episode": 32.0, "batch_reward": 0.16270201142132282, "critic_loss": 0.23793074341863393, "actor_loss": -21.011010725975037, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.4707190990448, "step": 32000}
{"episode_reward": 170.9231644879721, "episode": 33.0, "batch_reward": 0.16148374775797128, "critic_loss": 0.22442887504398823, "actor_loss": -21.03820933532715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.114341497421265, "step": 33000}
{"episode_reward": 65.84996143938098, "episode": 34.0, "batch_reward": 0.15903839205205442, "critic_loss": 0.23330504067242144, "actor_loss": -20.663827176094056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.42024803161621, "step": 34000}
{"episode_reward": 106.24568740386265, "episode": 35.0, "batch_reward": 0.15912939347326754, "critic_loss": 0.23793809691816567, "actor_loss": -20.772055079460145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.623860120773315, "step": 35000}
{"episode_reward": 180.97987143940318, "episode": 36.0, "batch_reward": 0.1595472700148821, "critic_loss": 0.244924530364573, "actor_loss": -21.240686418533326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.521398305892944, "step": 36000}
{"episode_reward": 299.0152567005747, "episode": 37.0, "batch_reward": 0.16283892852813006, "critic_loss": 0.2393954418450594, "actor_loss": -20.543782629966735, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.95271062850952, "step": 37000}
{"episode_reward": 161.4972653163502, "episode": 38.0, "batch_reward": 0.16291268937289716, "critic_loss": 0.2507105134576559, "actor_loss": -20.213137800216675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.4689199924469, "step": 38000}
{"episode_reward": 153.93030610348623, "episode": 39.0, "batch_reward": 0.16223267711699008, "critic_loss": 0.23261683378368617, "actor_loss": -20.559196953773498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.14775586128235, "step": 39000}
{"episode_reward": 108.43733676784979, "episode": 40.0, "batch_reward": 0.16223193338513375, "critic_loss": 0.2362028878107667, "actor_loss": -20.687683685302733, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.937769412994385, "step": 40000}
{"episode_reward": 175.14388376586805, "episode": 41.0, "batch_reward": 0.1625440236851573, "critic_loss": 0.2327515427917242, "actor_loss": -20.531966821670533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.09443712234497, "step": 41000}
{"episode_reward": 283.9258123847621, "episode": 42.0, "batch_reward": 0.16457776521891357, "critic_loss": 0.24732649490982295, "actor_loss": -20.63531046295166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.914145708084106, "step": 42000}
{"episode_reward": 118.34627262509524, "episode": 43.0, "batch_reward": 0.16160887780040503, "critic_loss": 0.23264834325760603, "actor_loss": -20.398396406173706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.334044933319092, "step": 43000}
{"episode_reward": 37.089152500390064, "episode": 44.0, "batch_reward": 0.16023195737600326, "critic_loss": 0.24912565598636865, "actor_loss": -21.41339497756958, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.795802354812622, "step": 44000}
{"episode_reward": 178.53273042277797, "episode": 45.0, "batch_reward": 0.1604954287186265, "critic_loss": 0.24944540021568537, "actor_loss": -20.791003736495973, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.63395929336548, "step": 45000}
{"episode_reward": 138.91427050789358, "episode": 46.0, "batch_reward": 0.1594126059859991, "critic_loss": 0.23782732574641705, "actor_loss": -19.875015924453734, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.279882431030273, "step": 46000}
{"episode_reward": 87.38634500202193, "episode": 47.0, "batch_reward": 0.15814760506898165, "critic_loss": 0.24409340143948793, "actor_loss": -20.11538479614258, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.435096979141235, "step": 47000}
{"episode_reward": 115.95533402980912, "episode": 48.0, "batch_reward": 0.1592058560550213, "critic_loss": 0.24572211263328791, "actor_loss": -19.918434425354004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.426329374313354, "step": 48000}
{"episode_reward": 270.5084363915728, "episode": 49.0, "batch_reward": 0.16126247856765985, "critic_loss": 0.2476104131117463, "actor_loss": -20.86414200782776, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.018930196762085, "step": 49000}
{"episode_reward": 236.1399919306353, "episode": 50.0, "batch_reward": 0.160082432590425, "critic_loss": 0.2914946309104562, "actor_loss": -20.153099279403687, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.440219402313232, "step": 50000}
{"episode_reward": 72.85683438023051, "episode": 51.0, "batch_reward": 0.16110748919099568, "critic_loss": 0.26277804926782844, "actor_loss": -19.876599034309386, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.34067749977112, "step": 51000}
{"episode_reward": 301.38644884552485, "episode": 52.0, "batch_reward": 0.16240302120149136, "critic_loss": 0.2532440709769726, "actor_loss": -20.015078758239746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.609569787979126, "step": 52000}
{"episode_reward": 95.2811257820094, "episode": 53.0, "batch_reward": 0.16259747006744146, "critic_loss": 0.2565850577428937, "actor_loss": -20.49443514251709, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.866732120513916, "step": 53000}
{"episode_reward": 228.4762171293371, "episode": 54.0, "batch_reward": 0.16379421769082547, "critic_loss": 0.24685662087053062, "actor_loss": -20.752019790649413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.522289037704468, "step": 54000}
{"episode_reward": 342.68565522643814, "episode": 55.0, "batch_reward": 0.1658855682015419, "critic_loss": 0.26086986996978523, "actor_loss": -20.578521028518676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.24894070625305, "step": 55000}
{"episode_reward": 95.089368410391, "episode": 56.0, "batch_reward": 0.1648264475017786, "critic_loss": 0.25302470721304415, "actor_loss": -20.36125789451599, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.22762680053711, "step": 56000}
{"episode_reward": 157.1836728756854, "episode": 57.0, "batch_reward": 0.16479500045627354, "critic_loss": 0.27528363685309887, "actor_loss": -20.342126848220826, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.468292474746704, "step": 57000}
{"episode_reward": 243.50691478648739, "episode": 58.0, "batch_reward": 0.16464351848512887, "critic_loss": 0.25790494284033777, "actor_loss": -20.468833269119262, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.410731077194214, "step": 58000}
{"episode_reward": 28.41819733756168, "episode": 59.0, "batch_reward": 0.16413177113234997, "critic_loss": 0.2516744784861803, "actor_loss": -20.188506719589235, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.020612239837646, "step": 59000}
{"episode_reward": 244.874850041031, "episode": 60.0, "batch_reward": 0.16442270750552415, "critic_loss": 0.24543886611610652, "actor_loss": -20.342260988235473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.29991316795349, "step": 60000}
{"episode_reward": 133.94884767813426, "episode": 61.0, "batch_reward": 0.16459767413884402, "critic_loss": 0.2571884908825159, "actor_loss": -20.179855392456055, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.12948513031006, "step": 61000}
{"episode_reward": 353.18604422635696, "episode": 62.0, "batch_reward": 0.16833325552940367, "critic_loss": 0.25386531959474085, "actor_loss": -20.715264678955077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.43109941482544, "step": 62000}
{"episode_reward": 249.24185632345998, "episode": 63.0, "batch_reward": 0.16834827063977717, "critic_loss": 0.2640050296857953, "actor_loss": -20.660030883789062, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.949432611465454, "step": 63000}
{"episode_reward": 136.41529162692143, "episode": 64.0, "batch_reward": 0.16859915070980788, "critic_loss": 0.27975248609483244, "actor_loss": -20.548059965133668, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.43320918083191, "step": 64000}
{"episode_reward": 296.8364878707849, "episode": 65.0, "batch_reward": 0.1703348845243454, "critic_loss": 0.26979885176569224, "actor_loss": -20.520669204711915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.112168312072754, "step": 65000}
{"episode_reward": 99.29472760891068, "episode": 66.0, "batch_reward": 0.16856305335462093, "critic_loss": 0.29105746310949326, "actor_loss": -20.33632188606262, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.264856338500977, "step": 66000}
{"episode_reward": 72.49084139699644, "episode": 67.0, "batch_reward": 0.1685766558945179, "critic_loss": 0.2786140471100807, "actor_loss": -20.752123924255372, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.439170837402344, "step": 67000}
{"episode_reward": 240.9077226598316, "episode": 68.0, "batch_reward": 0.16937543749809264, "critic_loss": 0.28941389241814613, "actor_loss": -21.29032356643677, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.422964811325073, "step": 68000}
{"episode_reward": 247.47710465468435, "episode": 69.0, "batch_reward": 0.16867297047376634, "critic_loss": 0.28441702654957773, "actor_loss": -20.11742573738098, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.077175855636597, "step": 69000}
{"episode_reward": 62.24516496951656, "episode": 70.0, "batch_reward": 0.16904161252081396, "critic_loss": 0.2763681356012821, "actor_loss": -20.350104892730712, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.11649179458618, "step": 70000}
{"episode_reward": 201.54495216342926, "episode": 71.0, "batch_reward": 0.1681570161283016, "critic_loss": 0.28342120318859815, "actor_loss": -19.861488431930542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.17644953727722, "step": 71000}
{"episode_reward": 73.49517254035314, "episode": 72.0, "batch_reward": 0.16829065743088722, "critic_loss": 0.2887718822956085, "actor_loss": -20.2025518283844, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.166014194488525, "step": 72000}
{"episode_reward": 166.90395930577833, "episode": 73.0, "batch_reward": 0.16868756066262722, "critic_loss": 0.2649738437831402, "actor_loss": -20.22905527496338, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.636396884918213, "step": 73000}
{"episode_reward": 216.13980398740043, "episode": 74.0, "batch_reward": 0.16891605964303016, "critic_loss": 0.2703433797955513, "actor_loss": -20.071503227233887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.465980291366577, "step": 74000}
{"episode_reward": 407.90892209668397, "episode": 75.0, "batch_reward": 0.1720151097252965, "critic_loss": 0.2794048007428646, "actor_loss": -20.501403371810913, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.630317449569702, "step": 75000}
{"episode_reward": 180.08577449365262, "episode": 76.0, "batch_reward": 0.17167082038521767, "critic_loss": 0.28324953919649126, "actor_loss": -20.275010425567626, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.66805934906006, "step": 76000}
{"episode_reward": 326.73882047660777, "episode": 77.0, "batch_reward": 0.1742631851583719, "critic_loss": 0.299922951862216, "actor_loss": -20.60347646903992, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.550436973571777, "step": 77000}
{"episode_reward": 203.21182579031282, "episode": 78.0, "batch_reward": 0.17402738805115223, "critic_loss": 0.32168753392994404, "actor_loss": -20.753014055252073, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.442644119262695, "step": 78000}
{"episode_reward": 164.43801496612267, "episode": 79.0, "batch_reward": 0.17442869146168233, "critic_loss": 0.34103373466432096, "actor_loss": -20.926832946777346, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.646504878997803, "step": 79000}
{"episode_reward": 169.76365942002698, "episode": 80.0, "batch_reward": 0.17421640081703663, "critic_loss": 0.34253331792354585, "actor_loss": -20.663399044036865, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.56167960166931, "step": 80000}
{"episode_reward": 229.9208484271569, "episode": 81.0, "batch_reward": 0.17411901733279228, "critic_loss": 0.36411601650714875, "actor_loss": -20.27239039039612, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.06484365463257, "step": 81000}
{"episode_reward": 69.64271123827747, "episode": 82.0, "batch_reward": 0.17367733006179334, "critic_loss": 0.36715126399695874, "actor_loss": -20.143664714813234, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.21188998222351, "step": 82000}
{"episode_reward": 220.69009625577706, "episode": 83.0, "batch_reward": 0.17541406884789468, "critic_loss": 0.3519980656653643, "actor_loss": -20.422656688690186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.175805807113647, "step": 83000}
{"episode_reward": 408.72495652506404, "episode": 84.0, "batch_reward": 0.17815402765572072, "critic_loss": 0.318057953953743, "actor_loss": -20.928686798095704, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.408069610595703, "step": 84000}
{"episode_reward": 404.5834870671466, "episode": 85.0, "batch_reward": 0.18007281623780727, "critic_loss": 0.34743117114901545, "actor_loss": -20.974592723846435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.70412588119507, "step": 85000}
{"episode_reward": 401.2088378379539, "episode": 86.0, "batch_reward": 0.18302672344446183, "critic_loss": 0.35837099063396455, "actor_loss": -20.698553150177002, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.591405153274536, "step": 86000}
{"episode_reward": 434.1376262307341, "episode": 87.0, "batch_reward": 0.1843606670498848, "critic_loss": 0.33619117754697797, "actor_loss": -21.685422313690186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.521920204162598, "step": 87000}
{"episode_reward": 257.7036451769864, "episode": 88.0, "batch_reward": 0.1864150617867708, "critic_loss": 0.3331051179766655, "actor_loss": -21.094449111938477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.4152569770813, "step": 88000}
{"episode_reward": 393.90461281378043, "episode": 89.0, "batch_reward": 0.18775761306285857, "critic_loss": 0.32497284965217116, "actor_loss": -21.135082624435423, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.871673822402954, "step": 89000}
{"episode_reward": 90.63206930066303, "episode": 90.0, "batch_reward": 0.187570763155818, "critic_loss": 0.32456455171108245, "actor_loss": -21.231443939208983, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.781307697296143, "step": 90000}
{"episode_reward": 362.38777928349793, "episode": 91.0, "batch_reward": 0.19000880581140517, "critic_loss": 0.33630057932436463, "actor_loss": -21.26379406929016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.06922459602356, "step": 91000}
{"episode_reward": 250.68921727727403, "episode": 92.0, "batch_reward": 0.19055028647184372, "critic_loss": 0.34831287041306497, "actor_loss": -21.639401971817016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.13001012802124, "step": 92000}
{"episode_reward": 350.5474273038277, "episode": 93.0, "batch_reward": 0.1913277223110199, "critic_loss": 0.3385639241114259, "actor_loss": -21.19913183784485, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.760865926742554, "step": 93000}
{"episode_reward": 105.17797172821035, "episode": 94.0, "batch_reward": 0.19199300964176655, "critic_loss": 0.3346264119446278, "actor_loss": -21.64077399635315, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.53607177734375, "step": 94000}
{"episode_reward": 405.180651204926, "episode": 95.0, "batch_reward": 0.19246009935438632, "critic_loss": 0.3390509554594755, "actor_loss": -22.00120269393921, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.47528886795044, "step": 95000}
{"episode_reward": 205.87109122422694, "episode": 96.0, "batch_reward": 0.193874626070261, "critic_loss": 0.34548936592042445, "actor_loss": -21.648207681655883, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.786412477493286, "step": 96000}
{"episode_reward": 219.5601631716614, "episode": 97.0, "batch_reward": 0.1926499452739954, "critic_loss": 0.35488690675795076, "actor_loss": -21.18905221748352, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.245196104049683, "step": 97000}
{"episode_reward": 90.65074093045567, "episode": 98.0, "batch_reward": 0.19302918374538422, "critic_loss": 0.37403153552114965, "actor_loss": -22.16621302604675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.42598056793213, "step": 98000}
{"episode_reward": 380.42653034848695, "episode": 99.0, "batch_reward": 0.1947427333444357, "critic_loss": 0.35784779946506023, "actor_loss": -21.42125779533386, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.752718210220337, "step": 99000}
{"episode_reward": 402.46168736969037, "episode": 100.0, "batch_reward": 0.19634891226887702, "critic_loss": 0.34453244461119176, "actor_loss": -21.59026630973816, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.3886456489563, "step": 100000}
{"episode_reward": 78.96215344326392, "episode": 101.0, "batch_reward": 0.19630104187130928, "critic_loss": 0.35157723248004913, "actor_loss": -21.61005644416809, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.303728103637695, "step": 101000}
{"episode_reward": 484.2520514054875, "episode": 102.0, "batch_reward": 0.19937799598276615, "critic_loss": 0.3484300877302885, "actor_loss": -22.132018281936645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.387789726257324, "step": 102000}
{"episode_reward": 351.91648337301274, "episode": 103.0, "batch_reward": 0.19986883701384067, "critic_loss": 0.38333358776569365, "actor_loss": -21.85361126899719, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.578121185302734, "step": 103000}
{"episode_reward": 404.1778407762897, "episode": 104.0, "batch_reward": 0.20203132410347463, "critic_loss": 0.3869228849112987, "actor_loss": -21.95917769050598, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.063751935958862, "step": 104000}
{"episode_reward": 394.7552950699693, "episode": 105.0, "batch_reward": 0.20387403616309166, "critic_loss": 0.3955486505627632, "actor_loss": -22.315415651321413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.413034200668335, "step": 105000}
{"episode_reward": 360.5547985683903, "episode": 106.0, "batch_reward": 0.2046459153443575, "critic_loss": 0.43819752950966356, "actor_loss": -22.156543251037597, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.995170831680298, "step": 106000}
{"episode_reward": 195.62805436319348, "episode": 107.0, "batch_reward": 0.20653836975991727, "critic_loss": 0.4179091660678387, "actor_loss": -21.94819797706604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.5143404006958, "step": 107000}
{"episode_reward": 364.42097085032066, "episode": 108.0, "batch_reward": 0.2070570040643215, "critic_loss": 0.3998630926460028, "actor_loss": -22.743337205886842, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.556729793548584, "step": 108000}
{"episode_reward": 212.18576463856428, "episode": 109.0, "batch_reward": 0.20794621732831, "critic_loss": 0.4316733708977699, "actor_loss": -22.335442121505736, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.410927772521973, "step": 109000}
{"episode_reward": 514.4553736481902, "episode": 110.0, "batch_reward": 0.20985788825154306, "critic_loss": 0.4274192007780075, "actor_loss": -23.017329811096193, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.89949631690979, "step": 110000}
{"episode_reward": 300.5590323665104, "episode": 111.0, "batch_reward": 0.20899317736923695, "critic_loss": 0.393206030100584, "actor_loss": -22.29828667640686, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.673824310302734, "step": 111000}
{"episode_reward": 203.10270604861654, "episode": 112.0, "batch_reward": 0.20957627291977404, "critic_loss": 0.4326067495495081, "actor_loss": -22.893385984420778, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.45166325569153, "step": 112000}
{"episode_reward": 142.11886905238492, "episode": 113.0, "batch_reward": 0.20997558751702308, "critic_loss": 0.4667510531693697, "actor_loss": -22.48972727203369, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.09195566177368, "step": 113000}
{"episode_reward": 499.6710425578173, "episode": 114.0, "batch_reward": 0.21197674424946308, "critic_loss": 0.5003697904348373, "actor_loss": -22.912090209960937, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.937560081481934, "step": 114000}
{"episode_reward": 542.7140137187648, "episode": 115.0, "batch_reward": 0.215917600274086, "critic_loss": 0.45841610641777514, "actor_loss": -22.944258991241455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.52109670639038, "step": 115000}
{"episode_reward": 495.6505765336801, "episode": 116.0, "batch_reward": 0.21783689875900744, "critic_loss": 0.4481092530936003, "actor_loss": -23.302180738449096, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.766981840133667, "step": 116000}
{"episode_reward": 544.015567622057, "episode": 117.0, "batch_reward": 0.21991185665130616, "critic_loss": 0.44127128897607326, "actor_loss": -23.07528910636902, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.85077691078186, "step": 117000}
{"episode_reward": 84.13606542871639, "episode": 118.0, "batch_reward": 0.21879167595505714, "critic_loss": 0.40386219291388986, "actor_loss": -23.10584436035156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.651564121246338, "step": 118000}
{"episode_reward": 194.3939928512093, "episode": 119.0, "batch_reward": 0.2184928309172392, "critic_loss": 0.42013137257099153, "actor_loss": -23.23749140739441, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.497320652008057, "step": 119000}
{"episode_reward": 428.60881926958666, "episode": 120.0, "batch_reward": 0.22095585599541664, "critic_loss": 0.4702403759807348, "actor_loss": -23.116162496566773, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.7118182182312, "step": 120000}
{"episode_reward": 484.4753759394655, "episode": 121.0, "batch_reward": 0.2232782552242279, "critic_loss": 0.4280744280964136, "actor_loss": -23.424226766586305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.603283405303955, "step": 121000}
{"episode_reward": 422.8298613820144, "episode": 122.0, "batch_reward": 0.22445291961729527, "critic_loss": 0.4421731043756008, "actor_loss": -23.901199914932253, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.475645542144775, "step": 122000}
{"episode_reward": 443.78156693405685, "episode": 123.0, "batch_reward": 0.2257875874042511, "critic_loss": 0.4310427717715502, "actor_loss": -23.77709264945984, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.00432014465332, "step": 123000}
{"episode_reward": 138.51060895606565, "episode": 124.0, "batch_reward": 0.22554438062012194, "critic_loss": 0.4410900948792696, "actor_loss": -24.091378490447998, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.139629364013672, "step": 124000}
{"episode_reward": 164.78522603369242, "episode": 125.0, "batch_reward": 0.2248950917571783, "critic_loss": 0.43303889890015124, "actor_loss": -23.713845993041993, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.53703284263611, "step": 125000}
{"episode_reward": 213.96512149674007, "episode": 126.0, "batch_reward": 0.22564344789087773, "critic_loss": 0.4571721606850624, "actor_loss": -23.954321969985962, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.21661639213562, "step": 126000}
{"episode_reward": 398.39193047693936, "episode": 127.0, "batch_reward": 0.22654644939303398, "critic_loss": 0.42732164050638677, "actor_loss": -24.008186849594118, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.599435806274414, "step": 127000}
{"episode_reward": 480.6162721421772, "episode": 128.0, "batch_reward": 0.22888953633606435, "critic_loss": 0.45772627674043176, "actor_loss": -24.20976897621155, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.585089921951294, "step": 128000}
{"episode_reward": 420.7515910276911, "episode": 129.0, "batch_reward": 0.23094644144177437, "critic_loss": 0.47901842308044434, "actor_loss": -24.26531583595276, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.425504684448242, "step": 129000}
{"episode_reward": 510.7037634404881, "episode": 130.0, "batch_reward": 0.23180810086429118, "critic_loss": 0.48719767068326475, "actor_loss": -24.55438451194763, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.105827569961548, "step": 130000}
{"episode_reward": 492.9065860504965, "episode": 131.0, "batch_reward": 0.23441672110557557, "critic_loss": 0.4346755041182041, "actor_loss": -24.18652758026123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.26925611495972, "step": 131000}
{"episode_reward": 510.44128832233463, "episode": 132.0, "batch_reward": 0.23666355589032173, "critic_loss": 0.47103667522966863, "actor_loss": -25.044202003479004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.524190664291382, "step": 132000}
{"episode_reward": 565.9717809655727, "episode": 133.0, "batch_reward": 0.23955602756142616, "critic_loss": 0.43125073610246184, "actor_loss": -24.771474199295042, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.47841787338257, "step": 133000}
{"episode_reward": 472.6868140758694, "episode": 134.0, "batch_reward": 0.2409080304503441, "critic_loss": 0.4542067500203848, "actor_loss": -25.144939533233643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.140719652175903, "step": 134000}
{"episode_reward": 527.5483995758575, "episode": 135.0, "batch_reward": 0.24308366276323795, "critic_loss": 0.4483593712002039, "actor_loss": -25.660236885070802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.39444637298584, "step": 135000}
{"episode_reward": 531.4221266896724, "episode": 136.0, "batch_reward": 0.24464066343009472, "critic_loss": 0.44784373615682127, "actor_loss": -25.384010663986206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.098687887191772, "step": 136000}
{"episode_reward": 508.7225804536557, "episode": 137.0, "batch_reward": 0.2470966374874115, "critic_loss": 0.43698709101974964, "actor_loss": -25.71902981185913, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.380454301834106, "step": 137000}
{"episode_reward": 544.9352140102288, "episode": 138.0, "batch_reward": 0.2481475305557251, "critic_loss": 0.4669814316034317, "actor_loss": -25.692204904556274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.527687549591064, "step": 138000}
{"episode_reward": 213.5940600775734, "episode": 139.0, "batch_reward": 0.24935818094015122, "critic_loss": 0.4394093776792288, "actor_loss": -25.70538372993469, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.489881992340088, "step": 139000}
{"episode_reward": 472.54194328734155, "episode": 140.0, "batch_reward": 0.2502254046499729, "critic_loss": 0.45296010576188567, "actor_loss": -26.230237146377565, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.710681200027466, "step": 140000}
{"episode_reward": 450.6080368295237, "episode": 141.0, "batch_reward": 0.2520481389015913, "critic_loss": 0.45435369965434075, "actor_loss": -26.031470838546753, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.02526879310608, "step": 141000}
{"episode_reward": 339.4060849805251, "episode": 142.0, "batch_reward": 0.25164059570431707, "critic_loss": 0.4614878301918507, "actor_loss": -25.93144482803345, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.440338134765625, "step": 142000}
{"episode_reward": 401.615363890181, "episode": 143.0, "batch_reward": 0.2530058707892895, "critic_loss": 0.4560758752524853, "actor_loss": -26.20602011489868, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.36356019973755, "step": 143000}
{"episode_reward": 487.0069158997584, "episode": 144.0, "batch_reward": 0.255495114788413, "critic_loss": 0.4680552766919136, "actor_loss": -26.73213974761963, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.336886405944824, "step": 144000}
{"episode_reward": 515.7121712844921, "episode": 145.0, "batch_reward": 0.25677954782545565, "critic_loss": 0.4731407426893711, "actor_loss": -26.542419918060304, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.434569597244263, "step": 145000}
{"episode_reward": 536.552123491707, "episode": 146.0, "batch_reward": 0.25880605198442935, "critic_loss": 0.43215502774715425, "actor_loss": -26.212110893249513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.471370220184326, "step": 146000}
{"episode_reward": 571.54187854244, "episode": 147.0, "batch_reward": 0.26099942126870157, "critic_loss": 0.4486960376650095, "actor_loss": -26.844557136535645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.8241229057312, "step": 147000}
{"episode_reward": 506.7244415811105, "episode": 148.0, "batch_reward": 0.2632076119184494, "critic_loss": 0.4638331800699234, "actor_loss": -27.14606876373291, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.915966033935547, "step": 148000}
{"episode_reward": 479.0487365620103, "episode": 149.0, "batch_reward": 0.26475525057315824, "critic_loss": 0.4545566840618849, "actor_loss": -27.240228244781495, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.501488208770752, "step": 149000}
{"episode_reward": 569.1207863671118, "episode": 150.0, "batch_reward": 0.2656197927594185, "critic_loss": 0.48388073398172854, "actor_loss": -27.25353946685791, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
