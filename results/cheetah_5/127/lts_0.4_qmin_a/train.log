{"episode_reward": 0.0, "episode": 1.0, "duration": 17.242961883544922, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.4921040534973145, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.2634038126450771, "critic_loss": 0.04033506694447005, "actor_loss": -17.54195026291602, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 62.709999084472656, "step": 3000}
{"episode_reward": 59.49506626761303, "episode": 4.0, "batch_reward": 0.20216438898444175, "critic_loss": 0.053389594117179515, "actor_loss": -14.502691503286362, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.425658464431763, "step": 4000}
{"episode_reward": 157.1527866008498, "episode": 5.0, "batch_reward": 0.18906665693223476, "critic_loss": 0.045947190104052425, "actor_loss": -14.260670509040356, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.19995141029358, "step": 5000}
{"episode_reward": 163.24159544503877, "episode": 6.0, "batch_reward": 0.1776108580380678, "critic_loss": 0.054731358133256434, "actor_loss": -14.268815705299378, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.835187196731567, "step": 6000}
{"episode_reward": 64.14100299549378, "episode": 7.0, "batch_reward": 0.15490053111314775, "critic_loss": 0.047915068101137874, "actor_loss": -12.197983015179634, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.996181964874268, "step": 7000}
{"episode_reward": 54.39705154149973, "episode": 8.0, "batch_reward": 0.14641904940456152, "critic_loss": 0.06486113522388041, "actor_loss": -13.008505595684051, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.995099544525146, "step": 8000}
{"episode_reward": 144.69943927251532, "episode": 9.0, "batch_reward": 0.14573577020317316, "critic_loss": 0.08131876339018344, "actor_loss": -13.545965527534484, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.88282084465027, "step": 9000}
{"episode_reward": 54.205509369732894, "episode": 10.0, "batch_reward": 0.13479756999015807, "critic_loss": 0.08492822625488043, "actor_loss": -12.956492098093033, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.630913972854614, "step": 10000}
{"episode_reward": 54.42931899391291, "episode": 11.0, "batch_reward": 0.12770988422632218, "critic_loss": 0.08463623554632067, "actor_loss": -13.148838892698288, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.52534627914429, "step": 11000}
{"episode_reward": 28.443508229961477, "episode": 12.0, "batch_reward": 0.11988300887495279, "critic_loss": 0.09371158023923636, "actor_loss": -12.705052726030349, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.87853217124939, "step": 12000}
{"episode_reward": 77.233798163935, "episode": 13.0, "batch_reward": 0.11883930646628141, "critic_loss": 0.10918271427974105, "actor_loss": -11.73731185722351, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.01958131790161, "step": 13000}
{"episode_reward": 99.00824204187548, "episode": 14.0, "batch_reward": 0.11376219613850116, "critic_loss": 0.10747147057205439, "actor_loss": -12.20721668291092, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.244487285614014, "step": 14000}
{"episode_reward": 32.09006985743691, "episode": 15.0, "batch_reward": 0.112304777123034, "critic_loss": 0.1347557945214212, "actor_loss": -12.605778560638427, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.6741943359375, "step": 15000}
{"episode_reward": 168.20234800909788, "episode": 16.0, "batch_reward": 0.11634630416333676, "critic_loss": 0.16379576434195042, "actor_loss": -12.279897922039032, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.97168731689453, "step": 16000}
{"episode_reward": 244.45818493586853, "episode": 17.0, "batch_reward": 0.11999821522831917, "critic_loss": 0.1870241357833147, "actor_loss": -12.999879714012145, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.019479990005493, "step": 17000}
{"episode_reward": 36.92213630975437, "episode": 18.0, "batch_reward": 0.11907163001596928, "critic_loss": 0.18315246410667896, "actor_loss": -13.206791491508485, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.04071807861328, "step": 18000}
{"episode_reward": 197.09265765030844, "episode": 19.0, "batch_reward": 0.12399249287694693, "critic_loss": 0.18856417143344878, "actor_loss": -13.873429306983947, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.984769821166992, "step": 19000}
{"episode_reward": 271.20903413764756, "episode": 20.0, "batch_reward": 0.13181996027380227, "critic_loss": 0.23130825532227756, "actor_loss": -14.759749839782716, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.188125133514404, "step": 20000}
{"episode_reward": 179.65364140109898, "episode": 21.0, "batch_reward": 0.13340259408205749, "critic_loss": 0.22544958778470756, "actor_loss": -14.43370151424408, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.74143648147583, "step": 21000}
{"episode_reward": 141.56484053681302, "episode": 22.0, "batch_reward": 0.13643775433301925, "critic_loss": 0.24625301814824344, "actor_loss": -16.07004201889038, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.298943758010864, "step": 22000}
{"episode_reward": 311.73954143971594, "episode": 23.0, "batch_reward": 0.14110866881906986, "critic_loss": 0.3088544937223196, "actor_loss": -16.141830476760866, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.271573305130005, "step": 23000}
{"episode_reward": 104.17095514482571, "episode": 24.0, "batch_reward": 0.1396441112011671, "critic_loss": 0.2869463589042425, "actor_loss": -16.235884819030762, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.085641860961914, "step": 24000}
{"episode_reward": 103.70866522525537, "episode": 25.0, "batch_reward": 0.14143307740986347, "critic_loss": 0.2811992593407631, "actor_loss": -16.627725269317626, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.36684250831604, "step": 25000}
{"episode_reward": 330.79555961550744, "episode": 26.0, "batch_reward": 0.1464153591915965, "critic_loss": 0.30098134715855124, "actor_loss": -16.825650983810426, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.406872034072876, "step": 26000}
{"episode_reward": 128.5164196021854, "episode": 27.0, "batch_reward": 0.14733182244002818, "critic_loss": 0.29756700903177263, "actor_loss": -16.867183599472046, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.222182989120483, "step": 27000}
{"episode_reward": 205.52335428052103, "episode": 28.0, "batch_reward": 0.15089883026480674, "critic_loss": 0.31872114093601706, "actor_loss": -17.841123323440552, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.519706964492798, "step": 28000}
{"episode_reward": 372.5755127974527, "episode": 29.0, "batch_reward": 0.1544851692467928, "critic_loss": 0.31445957547426223, "actor_loss": -17.99793392562866, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.181129455566406, "step": 29000}
{"episode_reward": 112.04345568783503, "episode": 30.0, "batch_reward": 0.15806979716569186, "critic_loss": 0.3211599405705929, "actor_loss": -17.94937546157837, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.992267370224, "step": 30000}
{"episode_reward": 331.2854446834248, "episode": 31.0, "batch_reward": 0.15832787866145373, "critic_loss": 0.33146417573094367, "actor_loss": -18.50547755432129, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.914289712905884, "step": 31000}
{"episode_reward": 72.94367907614496, "episode": 32.0, "batch_reward": 0.15630680011957884, "critic_loss": 0.3077020674198866, "actor_loss": -18.39085570526123, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.05478262901306, "step": 32000}
{"episode_reward": 81.84380031648493, "episode": 33.0, "batch_reward": 0.1554366249218583, "critic_loss": 0.3034814123660326, "actor_loss": -18.406345781326294, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.035364627838135, "step": 33000}
{"episode_reward": 146.01676679543462, "episode": 34.0, "batch_reward": 0.1551649876385927, "critic_loss": 0.3023753891289234, "actor_loss": -18.020838930130004, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.998307943344116, "step": 34000}
{"episode_reward": 171.56606599276856, "episode": 35.0, "batch_reward": 0.15676016753166913, "critic_loss": 0.28376380521059036, "actor_loss": -18.42321757698059, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.98775005340576, "step": 35000}
{"episode_reward": 271.3057248243655, "episode": 36.0, "batch_reward": 0.15874705965816974, "critic_loss": 0.2733764434456825, "actor_loss": -18.57909450340271, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.97013783454895, "step": 36000}
{"episode_reward": 155.25454466299678, "episode": 37.0, "batch_reward": 0.156259435929358, "critic_loss": 0.2791245749592781, "actor_loss": -18.232939414978027, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.062628984451294, "step": 37000}
{"episode_reward": 11.809859294911659, "episode": 38.0, "batch_reward": 0.15317676738649608, "critic_loss": 0.29266424821317194, "actor_loss": -18.197051990509035, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.26937961578369, "step": 38000}
{"episode_reward": 142.6545707297558, "episode": 39.0, "batch_reward": 0.15298267237097024, "critic_loss": 0.3073322187066078, "actor_loss": -18.127967021942137, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.460687160491943, "step": 39000}
{"episode_reward": 87.91121706208057, "episode": 40.0, "batch_reward": 0.1534723221734166, "critic_loss": 0.29180269719660284, "actor_loss": -17.85049596786499, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.110666751861572, "step": 40000}
{"episode_reward": 190.64175569788904, "episode": 41.0, "batch_reward": 0.15565600387752057, "critic_loss": 0.28300907492637634, "actor_loss": -17.556647481918336, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.59966969490051, "step": 41000}
{"episode_reward": 343.5826777209922, "episode": 42.0, "batch_reward": 0.15967035568505525, "critic_loss": 0.2899752295017242, "actor_loss": -18.190812280654907, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.043773651123047, "step": 42000}
{"episode_reward": 279.5490054800484, "episode": 43.0, "batch_reward": 0.16265042071044444, "critic_loss": 0.28915529942512513, "actor_loss": -18.53188130569458, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.9838387966156, "step": 43000}
{"episode_reward": 384.1759396140212, "episode": 44.0, "batch_reward": 0.16842346678674222, "critic_loss": 0.305505658864975, "actor_loss": -19.090035202026368, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.236984491348267, "step": 44000}
{"episode_reward": 410.4368315640833, "episode": 45.0, "batch_reward": 0.17111144414544105, "critic_loss": 0.32713312122225763, "actor_loss": -19.208204135894775, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.787803173065186, "step": 45000}
{"episode_reward": 104.32155048992388, "episode": 46.0, "batch_reward": 0.1714473993331194, "critic_loss": 0.31727539996802806, "actor_loss": -18.779152425765993, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.00561499595642, "step": 46000}
{"episode_reward": 323.8232200239067, "episode": 47.0, "batch_reward": 0.17522361098229886, "critic_loss": 0.31673175138235093, "actor_loss": -19.109898139953614, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.448076725006104, "step": 47000}
{"episode_reward": 400.47092846797835, "episode": 48.0, "batch_reward": 0.1794092133194208, "critic_loss": 0.3591146627962589, "actor_loss": -19.674171379089355, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.496331691741943, "step": 48000}
{"episode_reward": 458.7505892395005, "episode": 49.0, "batch_reward": 0.18471877916157245, "critic_loss": 0.3333150780647993, "actor_loss": -20.143957807540893, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.024304151535034, "step": 49000}
{"episode_reward": 241.40724744904495, "episode": 50.0, "batch_reward": 0.18665843184292316, "critic_loss": 0.32965367278456686, "actor_loss": -19.881957723617553, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.43005895614624, "step": 50000}
{"episode_reward": 354.46718264491017, "episode": 51.0, "batch_reward": 0.18881621146202088, "critic_loss": 0.33890646043419836, "actor_loss": -19.906253217697145, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.697510957717896, "step": 51000}
{"episode_reward": 294.80556637460376, "episode": 52.0, "batch_reward": 0.19326127533614634, "critic_loss": 0.344197894141078, "actor_loss": -20.28019639778137, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.50456404685974, "step": 52000}
{"episode_reward": 396.90936964737375, "episode": 53.0, "batch_reward": 0.19481920723617077, "critic_loss": 0.3570994419902563, "actor_loss": -20.69888158416748, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.206866979599, "step": 53000}
{"episode_reward": 117.74249603883797, "episode": 54.0, "batch_reward": 0.1922178326100111, "critic_loss": 0.3820924956947565, "actor_loss": -20.412197839736937, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.237041234970093, "step": 54000}
{"episode_reward": 75.20189237345133, "episode": 55.0, "batch_reward": 0.19222185169160366, "critic_loss": 0.35402666974067687, "actor_loss": -20.38295794868469, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.401964902877808, "step": 55000}
{"episode_reward": 381.56114325719494, "episode": 56.0, "batch_reward": 0.19381499506533145, "critic_loss": 0.36635107080638407, "actor_loss": -20.417989458084108, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.836202144622803, "step": 56000}
{"episode_reward": 76.91461411415303, "episode": 57.0, "batch_reward": 0.19347670231759548, "critic_loss": 0.37085028567910194, "actor_loss": -20.484471946716308, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.0414400100708, "step": 57000}
{"episode_reward": 202.2187696934477, "episode": 58.0, "batch_reward": 0.19195624014735221, "critic_loss": 0.4043877448439598, "actor_loss": -20.61034114074707, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.44825792312622, "step": 58000}
{"episode_reward": 202.00980517951285, "episode": 59.0, "batch_reward": 0.19193877670168877, "critic_loss": 0.4239741592258215, "actor_loss": -20.50443625831604, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.820857763290405, "step": 59000}
{"episode_reward": 93.34325294713004, "episode": 60.0, "batch_reward": 0.1931798979192972, "critic_loss": 0.4200298921763897, "actor_loss": -20.676682025909425, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.32692003250122, "step": 60000}
{"episode_reward": 435.34397310603066, "episode": 61.0, "batch_reward": 0.1947919484972954, "critic_loss": 0.4091074369698763, "actor_loss": -20.630342433929442, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.63856482505798, "step": 61000}
{"episode_reward": 91.24720702945369, "episode": 62.0, "batch_reward": 0.19535483737289905, "critic_loss": 0.4329073140770197, "actor_loss": -21.00866711807251, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.970109939575195, "step": 62000}
{"episode_reward": 412.77050273291945, "episode": 63.0, "batch_reward": 0.19824164035916328, "critic_loss": 0.39586010831594465, "actor_loss": -20.987911556243898, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.64329242706299, "step": 63000}
{"episode_reward": 449.8340649840614, "episode": 64.0, "batch_reward": 0.20190976604819297, "critic_loss": 0.41927413320541385, "actor_loss": -21.478111320495607, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.31679940223694, "step": 64000}
{"episode_reward": 406.58127631762875, "episode": 65.0, "batch_reward": 0.2046027854979038, "critic_loss": 0.3850650672316551, "actor_loss": -21.672500652313232, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.985152006149292, "step": 65000}
{"episode_reward": 104.20747727565764, "episode": 66.0, "batch_reward": 0.20283199134469032, "critic_loss": 0.39946236535906793, "actor_loss": -21.598744338989256, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.299871683120728, "step": 66000}
{"episode_reward": 213.0476856639091, "episode": 67.0, "batch_reward": 0.201230942517519, "critic_loss": 0.38410949240624903, "actor_loss": -21.736903507232665, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.4199161529541, "step": 67000}
{"episode_reward": 65.72522991092119, "episode": 68.0, "batch_reward": 0.20056735411286353, "critic_loss": 0.3732849430888891, "actor_loss": -21.586840869903565, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.470638513565063, "step": 68000}
{"episode_reward": 178.15465457795713, "episode": 69.0, "batch_reward": 0.20120416025817395, "critic_loss": 0.3780065861195326, "actor_loss": -21.33777075576782, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.44273567199707, "step": 69000}
{"episode_reward": 339.1022998181944, "episode": 70.0, "batch_reward": 0.20406460210680963, "critic_loss": 0.3666600325405598, "actor_loss": -21.69905014038086, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.37250256538391, "step": 70000}
{"episode_reward": 377.2461840606549, "episode": 71.0, "batch_reward": 0.20679796808958054, "critic_loss": 0.3584493921548128, "actor_loss": -21.72191056060791, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.66233420372009, "step": 71000}
{"episode_reward": 302.6240811188496, "episode": 72.0, "batch_reward": 0.20703838257491589, "critic_loss": 0.37808048194646837, "actor_loss": -21.809412647247314, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.569098472595215, "step": 72000}
{"episode_reward": 438.096374370911, "episode": 73.0, "batch_reward": 0.21065926469862462, "critic_loss": 0.3590526174008846, "actor_loss": -22.111040130615233, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.82673931121826, "step": 73000}
{"episode_reward": 455.87610830641796, "episode": 74.0, "batch_reward": 0.21249218885600568, "critic_loss": 0.36040336768329145, "actor_loss": -22.245793117523192, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.045963525772095, "step": 74000}
{"episode_reward": 143.95394034947196, "episode": 75.0, "batch_reward": 0.21171612386405467, "critic_loss": 0.35308594559133055, "actor_loss": -22.118922649383546, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.491563081741333, "step": 75000}
{"episode_reward": 179.52339200305698, "episode": 76.0, "batch_reward": 0.2109559821039438, "critic_loss": 0.3731008274108171, "actor_loss": -21.989276454925538, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.160550355911255, "step": 76000}
{"episode_reward": 104.28728942173333, "episode": 77.0, "batch_reward": 0.21215781074762344, "critic_loss": 0.37194696260988713, "actor_loss": -22.249102268218994, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.219672679901123, "step": 77000}
{"episode_reward": 545.5918164733414, "episode": 78.0, "batch_reward": 0.2160772007405758, "critic_loss": 0.3810542249232531, "actor_loss": -22.366117973327636, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.844895124435425, "step": 78000}
{"episode_reward": 498.62937908861636, "episode": 79.0, "batch_reward": 0.21852765175700187, "critic_loss": 0.3540949791967869, "actor_loss": -22.703156665802002, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.183597087860107, "step": 79000}
{"episode_reward": 184.30756104151223, "episode": 80.0, "batch_reward": 0.2184304399639368, "critic_loss": 0.360480114787817, "actor_loss": -22.79740326309204, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.077888250350952, "step": 80000}
{"episode_reward": 467.36741779570247, "episode": 81.0, "batch_reward": 0.22228141078352928, "critic_loss": 0.3762771497964859, "actor_loss": -23.05916163253784, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.88001847267151, "step": 81000}
{"episode_reward": 420.475526047514, "episode": 82.0, "batch_reward": 0.2234346014559269, "critic_loss": 0.38093126471340655, "actor_loss": -22.962002471923828, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.15330672264099, "step": 82000}
{"episode_reward": 443.2081037005155, "episode": 83.0, "batch_reward": 0.22713599275052548, "critic_loss": 0.40267562979459764, "actor_loss": -23.392852252960203, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.566184997558594, "step": 83000}
{"episode_reward": 485.20963069558087, "episode": 84.0, "batch_reward": 0.2303408787548542, "critic_loss": 0.39422968208789827, "actor_loss": -23.76626350402832, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.32400631904602, "step": 84000}
{"episode_reward": 438.4337536041042, "episode": 85.0, "batch_reward": 0.23175299493968488, "critic_loss": 0.39648073111474513, "actor_loss": -23.693863132476807, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.36769199371338, "step": 85000}
{"episode_reward": 354.6711377931219, "episode": 86.0, "batch_reward": 0.2337492619305849, "critic_loss": 0.4199332496970892, "actor_loss": -23.86293245315552, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.33323049545288, "step": 86000}
{"episode_reward": 236.64559313881824, "episode": 87.0, "batch_reward": 0.23485244078934192, "critic_loss": 0.4165978365689516, "actor_loss": -23.96797729873657, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.154269695281982, "step": 87000}
{"episode_reward": 309.23553960381264, "episode": 88.0, "batch_reward": 0.2355036821514368, "critic_loss": 0.4098304662257433, "actor_loss": -23.92817056274414, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.13224148750305, "step": 88000}
{"episode_reward": 560.5912338308411, "episode": 89.0, "batch_reward": 0.23949173042178154, "critic_loss": 0.4308936942964792, "actor_loss": -24.057083278656005, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.854437828063965, "step": 89000}
{"episode_reward": 486.0296980734579, "episode": 90.0, "batch_reward": 0.2420319982767105, "critic_loss": 0.4524321985244751, "actor_loss": -24.14170409011841, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.267799139022827, "step": 90000}
{"episode_reward": 306.6998154719505, "episode": 91.0, "batch_reward": 0.2419707731306553, "critic_loss": 0.4351562878638506, "actor_loss": -24.056332439422608, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.243547439575195, "step": 91000}
{"episode_reward": 477.1884327309968, "episode": 92.0, "batch_reward": 0.24435182124376298, "critic_loss": 0.4420942676514387, "actor_loss": -24.49778707122803, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.348819255828857, "step": 92000}
{"episode_reward": 242.4125090526484, "episode": 93.0, "batch_reward": 0.24422210776805878, "critic_loss": 0.43861817502975464, "actor_loss": -24.376569904327393, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.317022562026978, "step": 93000}
{"episode_reward": 451.1787827521043, "episode": 94.0, "batch_reward": 0.24620046737790108, "critic_loss": 0.4527612495869398, "actor_loss": -24.524541885375978, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.341966152191162, "step": 94000}
{"episode_reward": 156.5362115536309, "episode": 95.0, "batch_reward": 0.24544895368814468, "critic_loss": 0.4614936145097017, "actor_loss": -24.61002113342285, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.474785566329956, "step": 95000}
{"episode_reward": 453.08648949194276, "episode": 96.0, "batch_reward": 0.24919518601894378, "critic_loss": 0.48586017242074014, "actor_loss": -24.598444972991942, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.792667865753174, "step": 96000}
{"episode_reward": 419.2872969829327, "episode": 97.0, "batch_reward": 0.24973146697878837, "critic_loss": 0.44988096456229687, "actor_loss": -24.742403400421143, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.59267020225525, "step": 97000}
{"episode_reward": 517.3912689256556, "episode": 98.0, "batch_reward": 0.2510996343642473, "critic_loss": 0.44967671570181844, "actor_loss": -25.00591396331787, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.50365972518921, "step": 98000}
{"episode_reward": 261.94667271814546, "episode": 99.0, "batch_reward": 0.25260660944879054, "critic_loss": 0.4361106706559658, "actor_loss": -24.97217908859253, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.322453260421753, "step": 99000}
{"episode_reward": 403.1659727676715, "episode": 100.0, "batch_reward": 0.25471180778741837, "critic_loss": 0.46545088742673396, "actor_loss": -25.03859602737427, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.01428747177124, "step": 100000}
{"episode_reward": 461.1552356985146, "episode": 101.0, "batch_reward": 0.2567024524956942, "critic_loss": 0.4902767772227526, "actor_loss": -25.053663146972657, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.85743808746338, "step": 101000}
{"episode_reward": 522.50491387902, "episode": 102.0, "batch_reward": 0.25896421778202056, "critic_loss": 0.44870512194931506, "actor_loss": -25.355129688262938, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.98647379875183, "step": 102000}
{"episode_reward": 426.74028694858066, "episode": 103.0, "batch_reward": 0.2605204214900732, "critic_loss": 0.45422962081432344, "actor_loss": -25.452798053741454, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.43287754058838, "step": 103000}
{"episode_reward": 234.68311183316933, "episode": 104.0, "batch_reward": 0.26005300275981424, "critic_loss": 0.4758664550483227, "actor_loss": -25.13508039855957, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.52568006515503, "step": 104000}
{"episode_reward": 217.63281826266908, "episode": 105.0, "batch_reward": 0.2601328131258488, "critic_loss": 0.48229720824956895, "actor_loss": -25.248053909301756, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.55226445198059, "step": 105000}
{"episode_reward": 268.101900829123, "episode": 106.0, "batch_reward": 0.2594432566314936, "critic_loss": 0.4570450945198536, "actor_loss": -25.264432765960695, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.36607050895691, "step": 106000}
{"episode_reward": 260.898292268189, "episode": 107.0, "batch_reward": 0.2592478420287371, "critic_loss": 0.4352792771011591, "actor_loss": -25.075736839294432, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.137969255447388, "step": 107000}
{"episode_reward": 265.7489828380238, "episode": 108.0, "batch_reward": 0.26014938133955, "critic_loss": 0.4760656628012657, "actor_loss": -25.351862895965578, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.98979139328003, "step": 108000}
{"episode_reward": 534.0050118634681, "episode": 109.0, "batch_reward": 0.2633885407298803, "critic_loss": 0.4782971765100956, "actor_loss": -25.393589324951172, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.195888996124268, "step": 109000}
{"episode_reward": 543.5893308829067, "episode": 110.0, "batch_reward": 0.2661530618518591, "critic_loss": 0.4683428107351065, "actor_loss": -25.861547546386717, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.959846258163452, "step": 110000}
{"episode_reward": 490.9185526683282, "episode": 111.0, "batch_reward": 0.2663124171495438, "critic_loss": 0.505014970883727, "actor_loss": -25.752095134735107, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.97321629524231, "step": 111000}
{"episode_reward": 393.7166872987309, "episode": 112.0, "batch_reward": 0.26698756478726865, "critic_loss": 0.4893134513199329, "actor_loss": -25.89148631286621, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.058760166168213, "step": 112000}
{"episode_reward": 164.8374666267555, "episode": 113.0, "batch_reward": 0.26846924871206285, "critic_loss": 0.48067240582406523, "actor_loss": -25.80080823135376, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.033419370651245, "step": 113000}
{"episode_reward": 468.0688843439717, "episode": 114.0, "batch_reward": 0.2691035464555025, "critic_loss": 0.4751961523294449, "actor_loss": -25.98110200881958, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.061501026153564, "step": 114000}
{"episode_reward": 405.9659090249012, "episode": 115.0, "batch_reward": 0.27014434279501437, "critic_loss": 0.4528626089394093, "actor_loss": -25.939711421966553, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.514516353607178, "step": 115000}
{"episode_reward": 466.7290557412973, "episode": 116.0, "batch_reward": 0.27256449054181575, "critic_loss": 0.5017241992801428, "actor_loss": -26.063959323883058, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.991674661636353, "step": 116000}
{"episode_reward": 299.41864088949643, "episode": 117.0, "batch_reward": 0.27407069589197636, "critic_loss": 0.48229759189486504, "actor_loss": -25.969130996704102, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.266956090927124, "step": 117000}
{"episode_reward": 503.5191605336865, "episode": 118.0, "batch_reward": 0.27341455464065073, "critic_loss": 0.4834947720319033, "actor_loss": -25.962270946502684, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.970789432525635, "step": 118000}
{"episode_reward": 253.90885643029938, "episode": 119.0, "batch_reward": 0.27498914483189585, "critic_loss": 0.47378662556409834, "actor_loss": -26.053224948883056, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.03927779197693, "step": 119000}
{"episode_reward": 515.9059262695191, "episode": 120.0, "batch_reward": 0.27613655002415183, "critic_loss": 0.49086234417557717, "actor_loss": -26.151599906921387, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.195766925811768, "step": 120000}
{"episode_reward": 561.5531586444948, "episode": 121.0, "batch_reward": 0.2784716618657112, "critic_loss": 0.4515762722343206, "actor_loss": -26.238351219177247, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.72946619987488, "step": 121000}
{"episode_reward": 446.13601586499385, "episode": 122.0, "batch_reward": 0.27892243410646916, "critic_loss": 0.4920915351510048, "actor_loss": -26.54545037460327, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.300252199172974, "step": 122000}
{"episode_reward": 577.522267920178, "episode": 123.0, "batch_reward": 0.2827935698330402, "critic_loss": 0.5322721620798111, "actor_loss": -26.702369491577148, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.23151135444641, "step": 123000}
{"episode_reward": 552.3278396530102, "episode": 124.0, "batch_reward": 0.2846209550052881, "critic_loss": 0.5134866081029177, "actor_loss": -26.943059715270998, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.013027906417847, "step": 124000}
{"episode_reward": 400.77514231580193, "episode": 125.0, "batch_reward": 0.2853963575065136, "critic_loss": 0.4866572477221489, "actor_loss": -26.810266811370848, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.384151697158813, "step": 125000}
{"episode_reward": 371.73152750650917, "episode": 126.0, "batch_reward": 0.2862154276818037, "critic_loss": 0.5073227009475231, "actor_loss": -27.007550495147704, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.866602420806885, "step": 126000}
{"episode_reward": 592.5479960152605, "episode": 127.0, "batch_reward": 0.2877824303507805, "critic_loss": 0.5218096325695515, "actor_loss": -27.161757957458494, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.12312412261963, "step": 127000}
{"episode_reward": 224.71112880751838, "episode": 128.0, "batch_reward": 0.287684630125761, "critic_loss": 0.5001272534281015, "actor_loss": -27.068357433319093, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.323429346084595, "step": 128000}
{"episode_reward": 308.934951678156, "episode": 129.0, "batch_reward": 0.288406375259161, "critic_loss": 0.5084084623605013, "actor_loss": -27.047814071655274, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.334755659103394, "step": 129000}
{"episode_reward": 521.3367028097923, "episode": 130.0, "batch_reward": 0.2888371729999781, "critic_loss": 0.5153728293031454, "actor_loss": -27.13233291244507, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.017956733703613, "step": 130000}
{"episode_reward": 244.2356819611938, "episode": 131.0, "batch_reward": 0.2902253315448761, "critic_loss": 0.5215771125853061, "actor_loss": -27.132218421936035, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.840031147003174, "step": 131000}
{"episode_reward": 559.0693838695039, "episode": 132.0, "batch_reward": 0.29155087639391425, "critic_loss": 0.4850836131721735, "actor_loss": -27.196675956726075, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.1844322681427, "step": 132000}
{"episode_reward": 297.43610012479957, "episode": 133.0, "batch_reward": 0.2919692877829075, "critic_loss": 0.5453167659193278, "actor_loss": -27.062306541442872, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.855066061019897, "step": 133000}
{"episode_reward": 539.9127447933176, "episode": 134.0, "batch_reward": 0.2938534275144339, "critic_loss": 0.4819432245194912, "actor_loss": -27.449429153442384, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.96972370147705, "step": 134000}
{"episode_reward": 552.5688122968337, "episode": 135.0, "batch_reward": 0.2938066565841436, "critic_loss": 0.5123176128715277, "actor_loss": -27.439020725250245, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.006715059280396, "step": 135000}
{"episode_reward": 147.8437742538675, "episode": 136.0, "batch_reward": 0.29533831115067005, "critic_loss": 0.5288250602036715, "actor_loss": -27.547165908813476, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.089931964874268, "step": 136000}
{"episode_reward": 570.2379200107509, "episode": 137.0, "batch_reward": 0.2972169623374939, "critic_loss": 0.48056735955178737, "actor_loss": -27.763964393615723, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.068403959274292, "step": 137000}
{"episode_reward": 538.235570354787, "episode": 138.0, "batch_reward": 0.29758102184534074, "critic_loss": 0.5300524358302355, "actor_loss": -27.626324508666993, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.0327570438385, "step": 138000}
{"episode_reward": 281.15192902702796, "episode": 139.0, "batch_reward": 0.29864222590625283, "critic_loss": 0.5136623468101025, "actor_loss": -27.835050411224366, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.96157717704773, "step": 139000}
{"episode_reward": 563.0015820589618, "episode": 140.0, "batch_reward": 0.2987769110649824, "critic_loss": 0.5139140967726707, "actor_loss": -27.87428736114502, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.26509666442871, "step": 140000}
{"episode_reward": 549.2749590782612, "episode": 141.0, "batch_reward": 0.3031206157207489, "critic_loss": 0.46111880615353584, "actor_loss": -28.28569597244263, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.19391703605652, "step": 141000}
{"episode_reward": 538.7261626515668, "episode": 142.0, "batch_reward": 0.303687579035759, "critic_loss": 0.5311367663294077, "actor_loss": -28.320044532775878, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.338181495666504, "step": 142000}
{"episode_reward": 582.9929357801744, "episode": 143.0, "batch_reward": 0.3048401605933905, "critic_loss": 0.4836060647517443, "actor_loss": -28.378458042144775, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.057557344436646, "step": 143000}
{"episode_reward": 483.6182731728007, "episode": 144.0, "batch_reward": 0.307700489282608, "critic_loss": 0.45500394052267074, "actor_loss": -28.652645393371582, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.81861186027527, "step": 144000}
{"episode_reward": 621.7207971180616, "episode": 145.0, "batch_reward": 0.30849660490453246, "critic_loss": 0.4828570053130388, "actor_loss": -28.763000358581543, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.51024341583252, "step": 145000}
{"episode_reward": 608.7870034321788, "episode": 146.0, "batch_reward": 0.310115336060524, "critic_loss": 0.46919583079218863, "actor_loss": -28.793495105743407, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.111154556274414, "step": 146000}
{"episode_reward": 596.7867912029301, "episode": 147.0, "batch_reward": 0.3123579445034266, "critic_loss": 0.4770936433672905, "actor_loss": -29.00340531921387, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.042753219604492, "step": 147000}
{"episode_reward": 536.1222551294308, "episode": 148.0, "batch_reward": 0.31424523432552814, "critic_loss": 0.48540809166431426, "actor_loss": -29.08630833053589, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.182657480239868, "step": 148000}
{"episode_reward": 559.7601760424005, "episode": 149.0, "batch_reward": 0.317113212287426, "critic_loss": 0.4728755606412888, "actor_loss": -29.54818168258667, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.79563283920288, "step": 149000}
{"episode_reward": 572.9209444237559, "episode": 150.0, "batch_reward": 0.31767249438166617, "critic_loss": 0.4837505654990673, "actor_loss": -29.631411472320558, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
