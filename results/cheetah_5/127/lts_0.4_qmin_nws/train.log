{"episode_reward": 0.0, "episode": 1.0, "duration": 18.366017818450928, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.6172716617584229, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.2646278236191763, "critic_loss": 0.04569516325569468, "actor_loss": -17.341177661310272, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 67.81497502326965, "step": 3000}
{"episode_reward": 44.072128343581504, "episode": 4.0, "batch_reward": 0.18433223790675402, "critic_loss": 0.03037465009279549, "actor_loss": -12.32774535548687, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.752789735794067, "step": 4000}
{"episode_reward": 70.90754888297229, "episode": 5.0, "batch_reward": 0.1590417396724224, "critic_loss": 0.04169127821549773, "actor_loss": -11.343213281393052, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.955352306365967, "step": 5000}
{"episode_reward": 59.39473928780727, "episode": 6.0, "batch_reward": 0.14541258327662945, "critic_loss": 0.045027334513142704, "actor_loss": -10.880709602952004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.12834334373474, "step": 6000}
{"episode_reward": 112.67230431251902, "episode": 7.0, "batch_reward": 0.13724052149802446, "critic_loss": 0.05171951436623931, "actor_loss": -9.372518253803253, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.600829601287842, "step": 7000}
{"episode_reward": 68.01848064039754, "episode": 8.0, "batch_reward": 0.12714391469955444, "critic_loss": 0.06140732357464731, "actor_loss": -9.623259114980698, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.958131790161133, "step": 8000}
{"episode_reward": 97.34410484048249, "episode": 9.0, "batch_reward": 0.12528621380031107, "critic_loss": 0.07768437234312296, "actor_loss": -10.242998653888703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.08945393562317, "step": 9000}
{"episode_reward": 74.65051651917845, "episode": 10.0, "batch_reward": 0.12068028657883406, "critic_loss": 0.08553480964899063, "actor_loss": -9.713300576448441, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.67156434059143, "step": 10000}
{"episode_reward": 96.1708108098998, "episode": 11.0, "batch_reward": 0.11966900028288364, "critic_loss": 0.09463908584043383, "actor_loss": -10.020761668682098, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.299455881118774, "step": 11000}
{"episode_reward": 171.58576610692526, "episode": 12.0, "batch_reward": 0.12014191151410342, "critic_loss": 0.10231032553687691, "actor_loss": -10.50388207578659, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.297986268997192, "step": 12000}
{"episode_reward": 103.76146075445831, "episode": 13.0, "batch_reward": 0.12400237441062928, "critic_loss": 0.11968605514988304, "actor_loss": -10.632140142917633, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.881072759628296, "step": 13000}
{"episode_reward": 221.90994139999597, "episode": 14.0, "batch_reward": 0.13397178581357003, "critic_loss": 0.15603743464499711, "actor_loss": -12.020698903560639, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.431594848632812, "step": 14000}
{"episode_reward": 209.16657701511255, "episode": 15.0, "batch_reward": 0.13989012533426284, "critic_loss": 0.1614581945836544, "actor_loss": -12.846060293197631, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.122196435928345, "step": 15000}
{"episode_reward": 291.75671926826567, "episode": 16.0, "batch_reward": 0.14800736683607102, "critic_loss": 0.17572159054875375, "actor_loss": -13.124269885063171, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3645122051239, "step": 16000}
{"episode_reward": 328.21988625664585, "episode": 17.0, "batch_reward": 0.15595464454591274, "critic_loss": 0.19705060743540526, "actor_loss": -14.09599113368988, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.425976514816284, "step": 17000}
{"episode_reward": 108.39946820113926, "episode": 18.0, "batch_reward": 0.15239011819660664, "critic_loss": 0.19162050964683294, "actor_loss": -14.155619396209717, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.418816566467285, "step": 18000}
{"episode_reward": 63.828204907977906, "episode": 19.0, "batch_reward": 0.14885079733282328, "critic_loss": 0.20337944858521223, "actor_loss": -14.178628023147583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.947794914245605, "step": 19000}
{"episode_reward": 109.91661903102798, "episode": 20.0, "batch_reward": 0.1479561522603035, "critic_loss": 0.2364683467820287, "actor_loss": -14.51142338180542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.3616361618042, "step": 20000}
{"episode_reward": 154.88425040601825, "episode": 21.0, "batch_reward": 0.14669070369750262, "critic_loss": 0.24008291523903608, "actor_loss": -14.19398953151703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.19551730155945, "step": 21000}
{"episode_reward": 102.75665978215764, "episode": 22.0, "batch_reward": 0.14747082199156283, "critic_loss": 0.23728041552007198, "actor_loss": -15.384254662513733, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.8513240814209, "step": 22000}
{"episode_reward": 221.78530437729893, "episode": 23.0, "batch_reward": 0.148347387611866, "critic_loss": 0.2723184543848038, "actor_loss": -15.214564237594605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.0994656085968, "step": 23000}
{"episode_reward": 88.11540765835827, "episode": 24.0, "batch_reward": 0.14635580824315547, "critic_loss": 0.27262692792713644, "actor_loss": -15.231956974029542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.09313726425171, "step": 24000}
{"episode_reward": 229.1069158495285, "episode": 25.0, "batch_reward": 0.15005351243168116, "critic_loss": 0.2796695335507393, "actor_loss": -15.650536140441895, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.816408395767212, "step": 25000}
{"episode_reward": 112.41383870427323, "episode": 26.0, "batch_reward": 0.14841579230874777, "critic_loss": 0.27161156985163687, "actor_loss": -15.475153549194335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.260420083999634, "step": 26000}
{"episode_reward": 120.93367527101726, "episode": 27.0, "batch_reward": 0.14726153901964426, "critic_loss": 0.2776809810847044, "actor_loss": -15.402572156906128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.546716451644897, "step": 27000}
{"episode_reward": 107.78579749953632, "episode": 28.0, "batch_reward": 0.1485803180783987, "critic_loss": 0.29931307254731654, "actor_loss": -16.121476207733153, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.759974479675293, "step": 28000}
{"episode_reward": 227.1356724638301, "episode": 29.0, "batch_reward": 0.14961154904216528, "critic_loss": 0.30976211485266686, "actor_loss": -16.22578153038025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.81815218925476, "step": 29000}
{"episode_reward": 177.85430718895074, "episode": 30.0, "batch_reward": 0.15077273413538933, "critic_loss": 0.32631621572375297, "actor_loss": -16.19648470687866, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.341854095458984, "step": 30000}
{"episode_reward": 182.71413805819407, "episode": 31.0, "batch_reward": 0.14905500400811433, "critic_loss": 0.3269157216846943, "actor_loss": -16.59094844055176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.21431350708008, "step": 31000}
{"episode_reward": 27.41926258877539, "episode": 32.0, "batch_reward": 0.14956586553901435, "critic_loss": 0.3738094407916069, "actor_loss": -16.757314964294434, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.550851345062256, "step": 32000}
{"episode_reward": 228.1987065142139, "episode": 33.0, "batch_reward": 0.15131281331926585, "critic_loss": 0.36838961064815523, "actor_loss": -17.1819617729187, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.13345217704773, "step": 33000}
{"episode_reward": 198.0574387371085, "episode": 34.0, "batch_reward": 0.15282338920980693, "critic_loss": 0.38759381015598776, "actor_loss": -17.130508638381958, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.11995029449463, "step": 34000}
{"episode_reward": 266.7752610089079, "episode": 35.0, "batch_reward": 0.15583117096126078, "critic_loss": 0.4063221837133169, "actor_loss": -17.62151675796509, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.801297187805176, "step": 35000}
{"episode_reward": 353.10592642398694, "episode": 36.0, "batch_reward": 0.15802108215540647, "critic_loss": 0.3784848208129406, "actor_loss": -17.887477960586548, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.5955867767334, "step": 36000}
{"episode_reward": 28.43886483907166, "episode": 37.0, "batch_reward": 0.15671312177181243, "critic_loss": 0.38291611830890177, "actor_loss": -17.685031219482422, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.002603769302368, "step": 37000}
{"episode_reward": 142.59088255203903, "episode": 38.0, "batch_reward": 0.15594188069552184, "critic_loss": 0.38524231062829495, "actor_loss": -17.878745697021483, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.08014154434204, "step": 38000}
{"episode_reward": 126.19126766024219, "episode": 39.0, "batch_reward": 0.1556195069178939, "critic_loss": 0.3802369920313358, "actor_loss": -17.902684255599976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.747061014175415, "step": 39000}
{"episode_reward": 183.15914125384418, "episode": 40.0, "batch_reward": 0.15800708955526352, "critic_loss": 0.38319060449302195, "actor_loss": -17.97363539123535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.55880904197693, "step": 40000}
{"episode_reward": 290.17402527569845, "episode": 41.0, "batch_reward": 0.1593603453487158, "critic_loss": 0.358253533244133, "actor_loss": -17.931347169876098, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.66968059539795, "step": 41000}
{"episode_reward": 135.86387744076916, "episode": 42.0, "batch_reward": 0.16086399495601655, "critic_loss": 0.3638372046351433, "actor_loss": -18.368463451385498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.017414331436157, "step": 42000}
{"episode_reward": 354.04740533738084, "episode": 43.0, "batch_reward": 0.16132650996744632, "critic_loss": 0.3486781945973635, "actor_loss": -18.44578276824951, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.56913924217224, "step": 43000}
{"episode_reward": 25.56034267269889, "episode": 44.0, "batch_reward": 0.1620559440627694, "critic_loss": 0.3394575705081224, "actor_loss": -18.391319030761718, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.480958461761475, "step": 44000}
{"episode_reward": 370.5673319017022, "episode": 45.0, "batch_reward": 0.16417860148102045, "critic_loss": 0.3652639003098011, "actor_loss": -18.565057228088378, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.022437810897827, "step": 45000}
{"episode_reward": 124.67202580314058, "episode": 46.0, "batch_reward": 0.16396975836157798, "critic_loss": 0.35542940670251844, "actor_loss": -18.40436198616028, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.08467435836792, "step": 46000}
{"episode_reward": 150.27359721224087, "episode": 47.0, "batch_reward": 0.16303593119233847, "critic_loss": 0.3687595121711493, "actor_loss": -18.43466180038452, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.48258876800537, "step": 47000}
{"episode_reward": 73.07462353474229, "episode": 48.0, "batch_reward": 0.16244948308169843, "critic_loss": 0.3790723580121994, "actor_loss": -18.498716876983643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.061952352523804, "step": 48000}
{"episode_reward": 219.5376342237865, "episode": 49.0, "batch_reward": 0.16428002552688123, "critic_loss": 0.3554236509501934, "actor_loss": -18.648229570388793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.996336698532104, "step": 49000}
{"episode_reward": 175.02026721156818, "episode": 50.0, "batch_reward": 0.1637702522650361, "critic_loss": 0.3576210754066706, "actor_loss": -18.5526023311615, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.688451766967773, "step": 50000}
{"episode_reward": 177.00258163014942, "episode": 51.0, "batch_reward": 0.1654301444888115, "critic_loss": 0.3740034349113703, "actor_loss": -18.596544271469117, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.46544909477234, "step": 51000}
{"episode_reward": 318.48340191412007, "episode": 52.0, "batch_reward": 0.16733109360933304, "critic_loss": 0.3989904443621635, "actor_loss": -18.679728094100952, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.975694179534912, "step": 52000}
{"episode_reward": 121.47554681914302, "episode": 53.0, "batch_reward": 0.1672646561935544, "critic_loss": 0.4081067764014006, "actor_loss": -18.828979793548584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.130935668945312, "step": 53000}
{"episode_reward": 296.7662070069853, "episode": 54.0, "batch_reward": 0.1698545131981373, "critic_loss": 0.40183476923406125, "actor_loss": -19.051628362655638, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.5865797996521, "step": 54000}
{"episode_reward": 353.68116143432894, "episode": 55.0, "batch_reward": 0.17270237557590007, "critic_loss": 0.3979188532233238, "actor_loss": -19.175826011657715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.01581883430481, "step": 55000}
{"episode_reward": 385.8052850955756, "episode": 56.0, "batch_reward": 0.17695383466780185, "critic_loss": 0.37983466805517674, "actor_loss": -19.491948848724366, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.565399646759033, "step": 56000}
{"episode_reward": 225.98090841395435, "episode": 57.0, "batch_reward": 0.17669062035530805, "critic_loss": 0.373194052875042, "actor_loss": -19.407787200927736, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.49282217025757, "step": 57000}
{"episode_reward": 192.2031844073861, "episode": 58.0, "batch_reward": 0.17472874046862125, "critic_loss": 0.3703762002885342, "actor_loss": -19.35228768348694, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.039372444152832, "step": 58000}
{"episode_reward": 71.45147144075362, "episode": 59.0, "batch_reward": 0.1762859294116497, "critic_loss": 0.3410582596361637, "actor_loss": -19.348769605636598, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.579246282577515, "step": 59000}
{"episode_reward": 380.5471737729947, "episode": 60.0, "batch_reward": 0.17781235671043397, "critic_loss": 0.3531777291893959, "actor_loss": -19.430130268096924, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.026724338531494, "step": 60000}
{"episode_reward": 116.03758346764732, "episode": 61.0, "batch_reward": 0.17711977742612361, "critic_loss": 0.35523668976128103, "actor_loss": -19.20374066925049, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.703351736068726, "step": 61000}
{"episode_reward": 140.73808985912504, "episode": 62.0, "batch_reward": 0.17663084837794304, "critic_loss": 0.34857233092188833, "actor_loss": -19.16941711425781, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.599573850631714, "step": 62000}
{"episode_reward": 137.58175405513103, "episode": 63.0, "batch_reward": 0.17602720272541045, "critic_loss": 0.3540133658200502, "actor_loss": -18.97507588195801, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.516188383102417, "step": 63000}
{"episode_reward": 178.27297569684538, "episode": 64.0, "batch_reward": 0.17566299426555634, "critic_loss": 0.35074247808754444, "actor_loss": -18.971800231933592, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.122035264968872, "step": 64000}
{"episode_reward": 138.42357800657487, "episode": 65.0, "batch_reward": 0.1760239240527153, "critic_loss": 0.3438396351784468, "actor_loss": -18.998461769104004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.50605320930481, "step": 65000}
{"episode_reward": 300.9315170105476, "episode": 66.0, "batch_reward": 0.17770801985263823, "critic_loss": 0.3709957558810711, "actor_loss": -19.17795572471619, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.85789942741394, "step": 66000}
{"episode_reward": 210.6665087695023, "episode": 67.0, "batch_reward": 0.1793537175655365, "critic_loss": 0.3698171379119158, "actor_loss": -19.243653745651244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.488384008407593, "step": 67000}
{"episode_reward": 395.8213751141066, "episode": 68.0, "batch_reward": 0.18110415801405907, "critic_loss": 0.3972860605120659, "actor_loss": -19.334411865234376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.19543719291687, "step": 68000}
{"episode_reward": 233.92135898949292, "episode": 69.0, "batch_reward": 0.1813984846919775, "critic_loss": 0.3742061347365379, "actor_loss": -19.170393426895142, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.551581382751465, "step": 69000}
{"episode_reward": 111.26271011182536, "episode": 70.0, "batch_reward": 0.18106234681606292, "critic_loss": 0.3768604263365269, "actor_loss": -19.174724866867066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.451258897781372, "step": 70000}
{"episode_reward": 74.50497976061142, "episode": 71.0, "batch_reward": 0.17886557610332965, "critic_loss": 0.3491668211072683, "actor_loss": -18.90821913719177, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.56007170677185, "step": 71000}
{"episode_reward": 140.9830804828622, "episode": 72.0, "batch_reward": 0.1809361394941807, "critic_loss": 0.35429423601925375, "actor_loss": -19.043001462936402, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.31238055229187, "step": 72000}
{"episode_reward": 417.6351573985864, "episode": 73.0, "batch_reward": 0.18150644607841968, "critic_loss": 0.3756347228437662, "actor_loss": -19.07870260810852, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.99962329864502, "step": 73000}
{"episode_reward": 91.25335358863504, "episode": 74.0, "batch_reward": 0.18059756509959699, "critic_loss": 0.3501866650432348, "actor_loss": -19.013618682861328, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.204544067382812, "step": 74000}
{"episode_reward": 146.8071975813579, "episode": 75.0, "batch_reward": 0.18147911931574345, "critic_loss": 0.3680597600489855, "actor_loss": -18.96952865409851, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.239805459976196, "step": 75000}
{"episode_reward": 393.86007675248885, "episode": 76.0, "batch_reward": 0.18399873562157154, "critic_loss": 0.3533095996826887, "actor_loss": -19.08333178329468, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.899222135543823, "step": 76000}
{"episode_reward": 406.73429369598864, "episode": 77.0, "batch_reward": 0.18613709472119808, "critic_loss": 0.3427897989451885, "actor_loss": -19.33592022895813, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.33806538581848, "step": 77000}
{"episode_reward": 109.86722113792834, "episode": 78.0, "batch_reward": 0.1856845595985651, "critic_loss": 0.33925174932181834, "actor_loss": -19.189621517181397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34893488883972, "step": 78000}
{"episode_reward": 339.0506304401737, "episode": 79.0, "batch_reward": 0.18839091688394546, "critic_loss": 0.32974025143682956, "actor_loss": -19.48426268196106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.96443462371826, "step": 79000}
{"episode_reward": 321.2698969968037, "episode": 80.0, "batch_reward": 0.1901177026927471, "critic_loss": 0.3666317995339632, "actor_loss": -19.64742205429077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.623780727386475, "step": 80000}
{"episode_reward": 412.10212245834487, "episode": 81.0, "batch_reward": 0.19249331320822238, "critic_loss": 0.3462925033867359, "actor_loss": -19.793705656051635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.36636018753052, "step": 81000}
{"episode_reward": 379.8928349722953, "episode": 82.0, "batch_reward": 0.19419427275657652, "critic_loss": 0.3501806310266256, "actor_loss": -19.89106125831604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.677684545516968, "step": 82000}
{"episode_reward": 331.88519104748235, "episode": 83.0, "batch_reward": 0.1968781881183386, "critic_loss": 0.3556257267892361, "actor_loss": -20.205832008361817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.667852640151978, "step": 83000}
{"episode_reward": 302.0294125641175, "episode": 84.0, "batch_reward": 0.19803653220832348, "critic_loss": 0.36317341612279413, "actor_loss": -20.302060665130615, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.579668045043945, "step": 84000}
{"episode_reward": 453.8753454284793, "episode": 85.0, "batch_reward": 0.20075297577679158, "critic_loss": 0.33039615862071514, "actor_loss": -20.41083310699463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.26468324661255, "step": 85000}
{"episode_reward": 392.7405635016873, "episode": 86.0, "batch_reward": 0.20382736811041832, "critic_loss": 0.36402849923074243, "actor_loss": -20.791013076782228, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.66005516052246, "step": 86000}
{"episode_reward": 446.11357688702, "episode": 87.0, "batch_reward": 0.20600046440958977, "critic_loss": 0.37332223561406136, "actor_loss": -21.002498447418212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.586070775985718, "step": 87000}
{"episode_reward": 385.03658879325536, "episode": 88.0, "batch_reward": 0.20738960099220277, "critic_loss": 0.3612138101607561, "actor_loss": -20.98027409362793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.162681341171265, "step": 88000}
{"episode_reward": 425.55986679703045, "episode": 89.0, "batch_reward": 0.2101330880522728, "critic_loss": 0.3671219460964203, "actor_loss": -21.083724658966066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.17780613899231, "step": 89000}
{"episode_reward": 403.5969324293184, "episode": 90.0, "batch_reward": 0.21222257791459562, "critic_loss": 0.37966284380853177, "actor_loss": -21.225935707092287, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.03120732307434, "step": 90000}
{"episode_reward": 134.39794347919255, "episode": 91.0, "batch_reward": 0.21211063800752164, "critic_loss": 0.3688745747506619, "actor_loss": -21.240769744873045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.915114641189575, "step": 91000}
{"episode_reward": 314.729937724229, "episode": 92.0, "batch_reward": 0.2131052119731903, "critic_loss": 0.3803590711206198, "actor_loss": -21.410859649658203, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.059073448181152, "step": 92000}
{"episode_reward": 450.6323140879152, "episode": 93.0, "batch_reward": 0.21521954722702502, "critic_loss": 0.3763420989066362, "actor_loss": -21.419323474884035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.252251386642456, "step": 93000}
{"episode_reward": 405.44116052489164, "episode": 94.0, "batch_reward": 0.21664721408486368, "critic_loss": 0.37350637464225295, "actor_loss": -21.551414764404296, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.556297540664673, "step": 94000}
{"episode_reward": 113.92314305253974, "episode": 95.0, "batch_reward": 0.21538147611916064, "critic_loss": 0.4060041813403368, "actor_loss": -21.556187034606932, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.46081566810608, "step": 95000}
{"episode_reward": 104.2479609848562, "episode": 96.0, "batch_reward": 0.21533854581415654, "critic_loss": 0.3894452804774046, "actor_loss": -21.42030269241333, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.804203748703003, "step": 96000}
{"episode_reward": 309.1634682221118, "episode": 97.0, "batch_reward": 0.21584368290007114, "critic_loss": 0.3961756636798382, "actor_loss": -21.426765209198, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.914109468460083, "step": 97000}
{"episode_reward": 212.09128135609538, "episode": 98.0, "batch_reward": 0.21558006431162358, "critic_loss": 0.4033618166446686, "actor_loss": -21.640899379730225, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.53619647026062, "step": 98000}
{"episode_reward": 275.50451184582715, "episode": 99.0, "batch_reward": 0.21610989095270633, "critic_loss": 0.4062384329885244, "actor_loss": -21.544467029571532, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.18316388130188, "step": 99000}
{"episode_reward": 125.90287100636375, "episode": 100.0, "batch_reward": 0.21477535623311997, "critic_loss": 0.4193894497603178, "actor_loss": -21.38332439804077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.975085258483887, "step": 100000}
{"episode_reward": 208.91406273144418, "episode": 101.0, "batch_reward": 0.21526614640653133, "critic_loss": 0.4178239058405161, "actor_loss": -21.248317489624025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.77109432220459, "step": 101000}
{"episode_reward": 258.2861044060247, "episode": 102.0, "batch_reward": 0.21636775033175945, "critic_loss": 0.45124992717802526, "actor_loss": -21.3756711769104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.518855571746826, "step": 102000}
{"episode_reward": 245.06873354456783, "episode": 103.0, "batch_reward": 0.21685560868680478, "critic_loss": 0.41667187049984933, "actor_loss": -21.406129356384277, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.53202724456787, "step": 103000}
{"episode_reward": 386.0379885306413, "episode": 104.0, "batch_reward": 0.21901921927928925, "critic_loss": 0.45547040477395057, "actor_loss": -21.403470642089843, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.380435943603516, "step": 104000}
{"episode_reward": 478.8356576251103, "episode": 105.0, "batch_reward": 0.22107812514901162, "critic_loss": 0.4298726780563593, "actor_loss": -21.72795859146118, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.597439765930176, "step": 105000}
{"episode_reward": 234.16747471952417, "episode": 106.0, "batch_reward": 0.22124990017712115, "critic_loss": 0.47785448004305364, "actor_loss": -21.7389262008667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.192745208740234, "step": 106000}
{"episode_reward": 407.010517525496, "episode": 107.0, "batch_reward": 0.22282540240883827, "critic_loss": 0.42931632040441037, "actor_loss": -21.69944365310669, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.205398082733154, "step": 107000}
{"episode_reward": 256.0469170850368, "episode": 108.0, "batch_reward": 0.2238701969832182, "critic_loss": 0.45026691161096094, "actor_loss": -21.897397766113283, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.073522329330444, "step": 108000}
{"episode_reward": 457.15201146813394, "episode": 109.0, "batch_reward": 0.22454832142591477, "critic_loss": 0.4353543127179146, "actor_loss": -21.76595820617676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.735247373580933, "step": 109000}
{"episode_reward": 430.64821516463866, "episode": 110.0, "batch_reward": 0.2265164149403572, "critic_loss": 0.469051747366786, "actor_loss": -22.178780792236328, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.510927200317383, "step": 110000}
{"episode_reward": 302.356107634046, "episode": 111.0, "batch_reward": 0.22742767716944218, "critic_loss": 0.41474343042075634, "actor_loss": -22.087188213348387, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.92915201187134, "step": 111000}
{"episode_reward": 485.1205620027219, "episode": 112.0, "batch_reward": 0.22962204994261265, "critic_loss": 0.4723715929090977, "actor_loss": -22.364940685272217, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.02659273147583, "step": 112000}
{"episode_reward": 367.79141634898644, "episode": 113.0, "batch_reward": 0.23247753097116947, "critic_loss": 0.4651633246243, "actor_loss": -22.472827945709227, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.15900206565857, "step": 113000}
{"episode_reward": 485.26623878504876, "episode": 114.0, "batch_reward": 0.2326141233742237, "critic_loss": 0.5228416960835457, "actor_loss": -22.599006603240966, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41272234916687, "step": 114000}
{"episode_reward": 402.92180515559494, "episode": 115.0, "batch_reward": 0.23409430143237114, "critic_loss": 0.49495915111899375, "actor_loss": -22.674859004974365, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.272228956222534, "step": 115000}
{"episode_reward": 207.4802928416406, "episode": 116.0, "batch_reward": 0.23320458370447159, "critic_loss": 0.5086348886340857, "actor_loss": -22.49412672805786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.00118327140808, "step": 116000}
{"episode_reward": 106.43040630540217, "episode": 117.0, "batch_reward": 0.23357913184165954, "critic_loss": 0.4650487564653158, "actor_loss": -22.445953468322752, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.170104026794434, "step": 117000}
{"episode_reward": 400.7204462589313, "episode": 118.0, "batch_reward": 0.23516398976743222, "critic_loss": 0.48608551144599915, "actor_loss": -22.61687089920044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.61253070831299, "step": 118000}
{"episode_reward": 457.30306319073156, "episode": 119.0, "batch_reward": 0.2370930065959692, "critic_loss": 0.5038143228888512, "actor_loss": -22.722785385131836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.858243465423584, "step": 119000}
{"episode_reward": 425.5535101157908, "episode": 120.0, "batch_reward": 0.2381403401196003, "critic_loss": 0.47380452856421473, "actor_loss": -22.729259830474852, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.57310652732849, "step": 120000}
{"episode_reward": 274.56176930830316, "episode": 121.0, "batch_reward": 0.2377055474370718, "critic_loss": 0.484633249849081, "actor_loss": -22.652851837158202, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.84864521026611, "step": 121000}
{"episode_reward": 367.9737595357938, "episode": 122.0, "batch_reward": 0.2394897553920746, "critic_loss": 0.48922958301007746, "actor_loss": -23.112094509124756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.888092279434204, "step": 122000}
{"episode_reward": 217.9130693782755, "episode": 123.0, "batch_reward": 0.23996596911549567, "critic_loss": 0.4982558527737856, "actor_loss": -22.972631816864013, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.551108598709106, "step": 123000}
{"episode_reward": 446.7904472955661, "episode": 124.0, "batch_reward": 0.24045354329049587, "critic_loss": 0.5284413789510727, "actor_loss": -23.080034175872804, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.404363870620728, "step": 124000}
{"episode_reward": 205.33742758010095, "episode": 125.0, "batch_reward": 0.24101490397751332, "critic_loss": 0.5294340191930532, "actor_loss": -23.084302181243896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.982155323028564, "step": 125000}
{"episode_reward": 527.7915982654367, "episode": 126.0, "batch_reward": 0.24454169143736362, "critic_loss": 0.4632892831861973, "actor_loss": -23.42105611038208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.80782151222229, "step": 126000}
{"episode_reward": 420.437334027785, "episode": 127.0, "batch_reward": 0.2447462382763624, "critic_loss": 0.5232704402506352, "actor_loss": -23.39189558792114, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.139586687088013, "step": 127000}
{"episode_reward": 402.4313687291153, "episode": 128.0, "batch_reward": 0.24645943158864975, "critic_loss": 0.4816726214438677, "actor_loss": -23.56346339416504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.179100513458252, "step": 128000}
{"episode_reward": 369.37466242897284, "episode": 129.0, "batch_reward": 0.24682603737711906, "critic_loss": 0.5136469369232655, "actor_loss": -23.485018783569338, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.809255838394165, "step": 129000}
{"episode_reward": 489.94126615941815, "episode": 130.0, "batch_reward": 0.24782078509032726, "critic_loss": 0.5218650830239058, "actor_loss": -23.551261447906494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.61951518058777, "step": 130000}
{"episode_reward": 249.01882661061367, "episode": 131.0, "batch_reward": 0.2498392408490181, "critic_loss": 0.5246712263673544, "actor_loss": -23.716890266418456, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.444748878479004, "step": 131000}
{"episode_reward": 378.06841669943077, "episode": 132.0, "batch_reward": 0.24984751379489897, "critic_loss": 0.516401164740324, "actor_loss": -23.650740631103517, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.610980987548828, "step": 132000}
{"episode_reward": 456.8223141839806, "episode": 133.0, "batch_reward": 0.25112873320281504, "critic_loss": 0.5137657850533723, "actor_loss": -23.527974193572998, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.539355516433716, "step": 133000}
{"episode_reward": 245.957507189255, "episode": 134.0, "batch_reward": 0.2511249489784241, "critic_loss": 0.5017155420631171, "actor_loss": -23.770700016021728, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.84774422645569, "step": 134000}
{"episode_reward": 386.76450395167967, "episode": 135.0, "batch_reward": 0.25248621244728564, "critic_loss": 0.527675226315856, "actor_loss": -24.034432636260988, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.502317667007446, "step": 135000}
{"episode_reward": 480.29658365459386, "episode": 136.0, "batch_reward": 0.2552327502220869, "critic_loss": 0.5209607013761998, "actor_loss": -24.09734645462036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.43775773048401, "step": 136000}
{"episode_reward": 488.3585350080509, "episode": 137.0, "batch_reward": 0.25566037721931933, "critic_loss": 0.5410023918598891, "actor_loss": -24.201810939788817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.683446884155273, "step": 137000}
{"episode_reward": 394.54483438875906, "episode": 138.0, "batch_reward": 0.25646150195598605, "critic_loss": 0.5565309138298035, "actor_loss": -24.139199005126954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.673552751541138, "step": 138000}
{"episode_reward": 475.1208367267673, "episode": 139.0, "batch_reward": 0.2596487115621567, "critic_loss": 0.5566505967825651, "actor_loss": -24.33925994491577, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.329358100891113, "step": 139000}
{"episode_reward": 342.47816664449465, "episode": 140.0, "batch_reward": 0.2584968512803316, "critic_loss": 0.5452700234800577, "actor_loss": -24.285061042785646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.15515947341919, "step": 140000}
{"episode_reward": 473.3955822590462, "episode": 141.0, "batch_reward": 0.26216412548720835, "critic_loss": 0.6059611486792564, "actor_loss": -24.616951820373536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.18119263648987, "step": 141000}
{"episode_reward": 321.29478745719985, "episode": 142.0, "batch_reward": 0.2606391402184963, "critic_loss": 0.5516009162962436, "actor_loss": -24.440113605499267, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.15524196624756, "step": 142000}
{"episode_reward": 195.93934746620906, "episode": 143.0, "batch_reward": 0.259815574452281, "critic_loss": 0.5400264285504818, "actor_loss": -24.39477592086792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.096436977386475, "step": 143000}
{"episode_reward": 490.5634777528876, "episode": 144.0, "batch_reward": 0.26297015564143655, "critic_loss": 0.5211921139806509, "actor_loss": -24.595477069854738, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.223158597946167, "step": 144000}
{"episode_reward": 541.0824167811262, "episode": 145.0, "batch_reward": 0.2628696615099907, "critic_loss": 0.5651217785179615, "actor_loss": -24.636138847351074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.671634197235107, "step": 145000}
{"episode_reward": 405.99908578546797, "episode": 146.0, "batch_reward": 0.2643569005131722, "critic_loss": 0.546144969701767, "actor_loss": -24.6305617980957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.25255560874939, "step": 146000}
{"episode_reward": 304.0442036162304, "episode": 147.0, "batch_reward": 0.26571904303133487, "critic_loss": 0.5481703244149685, "actor_loss": -24.88519244003296, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.87144136428833, "step": 147000}
{"episode_reward": 593.6127150756197, "episode": 148.0, "batch_reward": 0.2669414247572422, "critic_loss": 0.5434837297052145, "actor_loss": -24.889373069763185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.014599561691284, "step": 148000}
{"episode_reward": 377.61892051520664, "episode": 149.0, "batch_reward": 0.2686605519503355, "critic_loss": 0.5282772429436445, "actor_loss": -25.143268093109132, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32043433189392, "step": 149000}
{"episode_reward": 585.5839768357948, "episode": 150.0, "batch_reward": 0.27057319159805776, "critic_loss": 0.5461227959096432, "actor_loss": -25.427061908721925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
