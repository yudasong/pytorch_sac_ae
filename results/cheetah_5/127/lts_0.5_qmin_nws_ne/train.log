{"episode_reward": 0.0, "episode": 1.0, "duration": 19.775596380233765, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.5301728248596191, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.2602174862021802, "critic_loss": 0.019876245390617598, "actor_loss": -22.63341246866116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 69.85005450248718, "step": 3000}
{"episode_reward": 1.9619449786469452, "episode": 4.0, "batch_reward": 0.16146199429780245, "critic_loss": 0.012495218587457202, "actor_loss": -19.528753409385683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.07016897201538, "step": 4000}
{"episode_reward": 2.9045590368319005, "episode": 5.0, "batch_reward": 0.12537541777268052, "critic_loss": 0.01247012955066748, "actor_loss": -18.796383598804475, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.992606163024902, "step": 5000}
{"episode_reward": 4.416769044564814, "episode": 6.0, "batch_reward": 0.10230260490998626, "critic_loss": 0.009507200644584372, "actor_loss": -19.07384686231613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.557135581970215, "step": 6000}
{"episode_reward": 3.8419937621802664, "episode": 7.0, "batch_reward": 0.08767204674333334, "critic_loss": 0.012481705610873178, "actor_loss": -17.346680848121643, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.333165884017944, "step": 7000}
{"episode_reward": 4.01458108742439, "episode": 8.0, "batch_reward": 0.07668586604855955, "critic_loss": 0.012065051912446506, "actor_loss": -16.802918095588684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.456876516342163, "step": 8000}
{"episode_reward": 4.934449884119947, "episode": 9.0, "batch_reward": 0.06787719737552106, "critic_loss": 0.01066853155347053, "actor_loss": -17.563533794879913, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.37541127204895, "step": 9000}
{"episode_reward": 3.0487198222046468, "episode": 10.0, "batch_reward": 0.06143836071901023, "critic_loss": 0.012653712661005557, "actor_loss": -17.283460973262788, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.997394323349, "step": 10000}
{"episode_reward": 3.805367541008713, "episode": 11.0, "batch_reward": 0.05685612668003887, "critic_loss": 0.011275911332457327, "actor_loss": -16.774507267713545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.08534479141235, "step": 11000}
{"episode_reward": 3.8025163567303113, "episode": 12.0, "batch_reward": 0.05060425958503038, "critic_loss": 0.010225124137359671, "actor_loss": -16.476338978290556, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.036059617996216, "step": 12000}
{"episode_reward": 5.253941651879306, "episode": 13.0, "batch_reward": 0.04733488843031228, "critic_loss": 0.01769185921282042, "actor_loss": -16.07148319530487, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.58694553375244, "step": 13000}
{"episode_reward": 3.4851692077801415, "episode": 14.0, "batch_reward": 0.044603208963759244, "critic_loss": 0.008726525889651384, "actor_loss": -15.990660606622695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.83038854598999, "step": 14000}
{"episode_reward": 6.198832751263242, "episode": 15.0, "batch_reward": 0.04137189240101725, "critic_loss": 0.012999375936342403, "actor_loss": -16.612151698350907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.135104179382324, "step": 15000}
{"episode_reward": 3.663166315125494, "episode": 16.0, "batch_reward": 0.03914240723755211, "critic_loss": 0.008605677929823287, "actor_loss": -16.205717543840407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.401641368865967, "step": 16000}
{"episode_reward": 4.239188097897094, "episode": 17.0, "batch_reward": 0.0368940658099018, "critic_loss": 0.011329850818612612, "actor_loss": -15.824382080554962, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.49384093284607, "step": 17000}
{"episode_reward": 3.3343004541271255, "episode": 18.0, "batch_reward": 0.03590717742498964, "critic_loss": 0.010668655631830917, "actor_loss": -15.68389612030983, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19683265686035, "step": 18000}
{"episode_reward": 4.950079421925961, "episode": 19.0, "batch_reward": 0.03372513238387182, "critic_loss": 0.00812602258886909, "actor_loss": -15.394055164575576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08616876602173, "step": 19000}
{"episode_reward": 4.520256533372396, "episode": 20.0, "batch_reward": 0.032169529089238494, "critic_loss": 0.0110141293501365, "actor_loss": -16.422367748975752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.120766401290894, "step": 20000}
{"episode_reward": 3.81205374536835, "episode": 21.0, "batch_reward": 0.030029926884453745, "critic_loss": 0.008415738143521595, "actor_loss": -14.132948217391968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.27246856689453, "step": 21000}
{"episode_reward": 5.523852210880644, "episode": 22.0, "batch_reward": 0.029739638693165035, "critic_loss": 0.011939789769414347, "actor_loss": -16.2193253865242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.928613424301147, "step": 22000}
{"episode_reward": 5.10995523096537, "episode": 23.0, "batch_reward": 0.02836688543856144, "critic_loss": 0.005585010126844281, "actor_loss": -15.441340845108032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.01384425163269, "step": 23000}
{"episode_reward": 3.864658660604653, "episode": 24.0, "batch_reward": 0.02719704899052158, "critic_loss": 0.00838401489291573, "actor_loss": -15.246276020884514, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.061537742614746, "step": 24000}
{"episode_reward": 4.223883979731007, "episode": 25.0, "batch_reward": 0.02683178589027375, "critic_loss": 0.008162109274882824, "actor_loss": -15.69485750067234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.61624765396118, "step": 25000}
{"episode_reward": 3.860510619348792, "episode": 26.0, "batch_reward": 0.025585586914094165, "critic_loss": 0.007261549905961146, "actor_loss": -15.164287138342857, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.720365524291992, "step": 26000}
{"episode_reward": 4.5848701553975655, "episode": 27.0, "batch_reward": 0.02538776208483614, "critic_loss": 0.006490481934626586, "actor_loss": -14.582547737240791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.34413242340088, "step": 27000}
{"episode_reward": 3.8852989231865824, "episode": 28.0, "batch_reward": 0.02436095946189016, "critic_loss": 0.00703223154193256, "actor_loss": -15.23532228088379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.34436535835266, "step": 28000}
{"episode_reward": 4.773140762294765, "episode": 29.0, "batch_reward": 0.023061025565024464, "critic_loss": 0.007659104420861695, "actor_loss": -14.858123675227166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.363694429397583, "step": 29000}
{"episode_reward": 3.4353093911411947, "episode": 30.0, "batch_reward": 0.022796612066216766, "critic_loss": 0.0060001488941488785, "actor_loss": -13.687622075080872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.133775234222412, "step": 30000}
{"episode_reward": 5.545369412542512, "episode": 31.0, "batch_reward": 0.02201653430238366, "critic_loss": 0.005243414269411005, "actor_loss": -14.50672718179226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.638052225112915, "step": 31000}
{"episode_reward": 3.344413640383054, "episode": 32.0, "batch_reward": 0.021536377805052326, "critic_loss": 0.008653839153674198, "actor_loss": -15.529237516403198, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.38262391090393, "step": 32000}
{"episode_reward": 3.516293133148403, "episode": 33.0, "batch_reward": 0.020997495429590344, "critic_loss": 0.00368452205361973, "actor_loss": -15.154552041530609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.118568658828735, "step": 33000}
{"episode_reward": 4.707104838214965, "episode": 34.0, "batch_reward": 0.020682316213380545, "critic_loss": 0.007252777079382213, "actor_loss": -14.130879021286965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.283672094345093, "step": 34000}
{"episode_reward": 4.260646029041274, "episode": 35.0, "batch_reward": 0.019343416874995457, "critic_loss": 0.00580288803219446, "actor_loss": -15.017177331089973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.362730264663696, "step": 35000}
{"episode_reward": 2.7883878113202174, "episode": 36.0, "batch_reward": 0.01914465610566549, "critic_loss": 0.006756745181861334, "actor_loss": -15.106583497166634, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.2687087059021, "step": 36000}
{"episode_reward": 5.746937133119172, "episode": 37.0, "batch_reward": 0.01919594373460859, "critic_loss": 0.0068774911608779805, "actor_loss": -14.22288030475378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098698139190674, "step": 37000}
{"episode_reward": 5.087038244142341, "episode": 38.0, "batch_reward": 0.0185712827432435, "critic_loss": 0.004706034602655564, "actor_loss": -14.526640864253045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.179741144180298, "step": 38000}
{"episode_reward": 2.9257783589916846, "episode": 39.0, "batch_reward": 0.018434505266370253, "critic_loss": 0.00601256561325863, "actor_loss": -14.236201629459858, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.008940935134888, "step": 39000}
{"episode_reward": 4.277932633726903, "episode": 40.0, "batch_reward": 0.017956564895808696, "critic_loss": 0.006367239182000048, "actor_loss": -14.204487034082412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3292453289032, "step": 40000}
{"episode_reward": 4.596574215188224, "episode": 41.0, "batch_reward": 0.017580787853337825, "critic_loss": 0.0051880601328593914, "actor_loss": -13.739399109601974, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.912527084350586, "step": 41000}
{"episode_reward": 5.9640002025398315, "episode": 42.0, "batch_reward": 0.01738771112426184, "critic_loss": 0.004631128323773737, "actor_loss": -14.009653208196163, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.15193247795105, "step": 42000}
{"episode_reward": 4.4170314993161215, "episode": 43.0, "batch_reward": 0.016842658541863783, "critic_loss": 0.005090215443720808, "actor_loss": -14.806036617219448, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.25574517250061, "step": 43000}
{"episode_reward": 4.154109019194902, "episode": 44.0, "batch_reward": 0.016911811280064283, "critic_loss": 0.004343578381507541, "actor_loss": -15.723107859373092, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.125205516815186, "step": 44000}
{"episode_reward": 5.8667668517350355, "episode": 45.0, "batch_reward": 0.01634026946942322, "critic_loss": 0.004634150004349067, "actor_loss": -14.502701938569546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.184366941452026, "step": 45000}
{"episode_reward": 4.047344348259729, "episode": 46.0, "batch_reward": 0.0158981264217291, "critic_loss": 0.004383853340172209, "actor_loss": -13.860480422079563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.507428646087646, "step": 46000}
{"episode_reward": 5.130470975251111, "episode": 47.0, "batch_reward": 0.015759609021479264, "critic_loss": 0.005599492659923272, "actor_loss": -14.524981737315654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17683982849121, "step": 47000}
{"episode_reward": 3.011265603129461, "episode": 48.0, "batch_reward": 0.015672862000064923, "critic_loss": 0.005728749754576711, "actor_loss": -14.335455284059048, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.63299798965454, "step": 48000}
{"episode_reward": 5.635358011278154, "episode": 49.0, "batch_reward": 0.015700981195783243, "critic_loss": 0.00501244283230335, "actor_loss": -15.559565080702304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.120439767837524, "step": 49000}
{"episode_reward": 4.004956772923032, "episode": 50.0, "batch_reward": 0.015254696783842519, "critic_loss": 0.006126549972381327, "actor_loss": -14.435216808140279, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.724663496017456, "step": 50000}
{"episode_reward": 3.3193733689373865, "episode": 51.0, "batch_reward": 0.015036851642886177, "critic_loss": 0.005200977401400451, "actor_loss": -13.635863587915898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.33994436264038, "step": 51000}
{"episode_reward": 3.7573677954150853, "episode": 52.0, "batch_reward": 0.01488336736126803, "critic_loss": 0.005140364401027909, "actor_loss": -13.904653595358134, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.500441789627075, "step": 52000}
{"episode_reward": 3.341376426377792, "episode": 53.0, "batch_reward": 0.014655514232581482, "critic_loss": 0.0035963981694658287, "actor_loss": -15.250830576360226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.092403173446655, "step": 53000}
{"episode_reward": 2.353127352087199, "episode": 54.0, "batch_reward": 0.014398488810984418, "critic_loss": 0.006126667983247899, "actor_loss": -15.482853313088418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.046770572662354, "step": 54000}
{"episode_reward": 3.65006187404909, "episode": 55.0, "batch_reward": 0.014471878081094474, "critic_loss": 0.0038088208948029206, "actor_loss": -13.761380993902684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.26810908317566, "step": 55000}
{"episode_reward": 4.225129453319552, "episode": 56.0, "batch_reward": 0.013878430523211137, "critic_loss": 0.003890705353260273, "actor_loss": -14.109304800897837, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.09828495979309, "step": 56000}
{"episode_reward": 5.181497638016356, "episode": 57.0, "batch_reward": 0.013815648639341817, "critic_loss": 0.004555631101757171, "actor_loss": -13.604104997456075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.24850296974182, "step": 57000}
{"episode_reward": 4.173057266702768, "episode": 58.0, "batch_reward": 0.013558146425290032, "critic_loss": 0.0035384729036304634, "actor_loss": -14.887929471850395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.588780879974365, "step": 58000}
{"episode_reward": 6.971928400135193, "episode": 59.0, "batch_reward": 0.013482647240627556, "critic_loss": 0.004599854109022999, "actor_loss": -14.149356798171997, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.98797845840454, "step": 59000}
{"episode_reward": 4.029606462688581, "episode": 60.0, "batch_reward": 0.013539090632926673, "critic_loss": 0.0027060511794989, "actor_loss": -14.866567423701285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.92678189277649, "step": 60000}
{"episode_reward": 3.4352683227506438, "episode": 61.0, "batch_reward": 0.0134749694543425, "critic_loss": 0.003840513979565003, "actor_loss": -13.638714099228382, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.65894961357117, "step": 61000}
{"episode_reward": 1.975542817505775, "episode": 62.0, "batch_reward": 0.013409413092536852, "critic_loss": 0.004306495483702747, "actor_loss": -15.401404979586601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.55505084991455, "step": 62000}
{"episode_reward": 6.126895361753995, "episode": 63.0, "batch_reward": 0.01292524088663049, "critic_loss": 0.0043515653890572135, "actor_loss": -13.323543964773416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.06793212890625, "step": 63000}
{"episode_reward": 5.569539596534192, "episode": 64.0, "batch_reward": 0.01272425193944946, "critic_loss": 0.0025691572428186192, "actor_loss": -14.701851767927408, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.531580924987793, "step": 64000}
{"episode_reward": 3.7147410253198716, "episode": 65.0, "batch_reward": 0.012514791323104874, "critic_loss": 0.004554347127326764, "actor_loss": -14.14719353941083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.290405988693237, "step": 65000}
{"episode_reward": 3.8366383272502995, "episode": 66.0, "batch_reward": 0.012370451977476478, "critic_loss": 0.0033903732778853735, "actor_loss": -14.528741922676563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.968192100524902, "step": 66000}
{"episode_reward": 2.871745736882295, "episode": 67.0, "batch_reward": 0.012491553727537394, "critic_loss": 0.002967260169883957, "actor_loss": -15.410461240887642, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.449409246444702, "step": 67000}
{"episode_reward": 3.1772818527310474, "episode": 68.0, "batch_reward": 0.012173418584512546, "critic_loss": 0.0038472038207692095, "actor_loss": -15.502685535252095, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.868977546691895, "step": 68000}
{"episode_reward": 3.5864266099102324, "episode": 69.0, "batch_reward": 0.012192274870816618, "critic_loss": 0.0037223082038690338, "actor_loss": -14.049756241440774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.625054597854614, "step": 69000}
{"episode_reward": 2.9392189304706076, "episode": 70.0, "batch_reward": 0.012112223922507838, "critic_loss": 0.002637688926406554, "actor_loss": -14.222945604801177, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.9014573097229, "step": 70000}
{"episode_reward": 5.447036367177238, "episode": 71.0, "batch_reward": 0.012032295542303473, "critic_loss": 0.005403125251774327, "actor_loss": -13.765891649246216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.62545871734619, "step": 71000}
{"episode_reward": 4.181014960474769, "episode": 72.0, "batch_reward": 0.011958689744351431, "critic_loss": 0.003198294041765621, "actor_loss": -13.819986879050731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.319833755493164, "step": 72000}
{"episode_reward": 3.0881104054841497, "episode": 73.0, "batch_reward": 0.011829555122181774, "critic_loss": 0.003631092943549447, "actor_loss": -13.980750110387802, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.743110418319702, "step": 73000}
{"episode_reward": 4.268845322537447, "episode": 74.0, "batch_reward": 0.011421817397233098, "critic_loss": 0.0028488071127576405, "actor_loss": -14.194342043876649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.081587314605713, "step": 74000}
{"episode_reward": 4.550295077023512, "episode": 75.0, "batch_reward": 0.01122813596506603, "critic_loss": 0.002636359572126821, "actor_loss": -14.110333834648133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.62741780281067, "step": 75000}
{"episode_reward": 3.5659402060754593, "episode": 76.0, "batch_reward": 0.011570531313307583, "critic_loss": 0.003350605291569082, "actor_loss": -13.733398003980517, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.298290252685547, "step": 76000}
{"episode_reward": 5.239924534686216, "episode": 77.0, "batch_reward": 0.01158779190084897, "critic_loss": 0.004723612855363171, "actor_loss": -14.354704985827208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.567883253097534, "step": 77000}
{"episode_reward": 3.197738653447304, "episode": 78.0, "batch_reward": 0.011653085440397263, "critic_loss": 0.0017494557738828007, "actor_loss": -13.620744317933918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.00326156616211, "step": 78000}
{"episode_reward": 5.4948925343831405, "episode": 79.0, "batch_reward": 0.011072668113978579, "critic_loss": 0.0032979323093168204, "actor_loss": -15.175061397239565, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.354848861694336, "step": 79000}
{"episode_reward": 3.9216956224530244, "episode": 80.0, "batch_reward": 0.011137703774031251, "critic_loss": 0.00304247496980679, "actor_loss": -14.942979964450002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.980844497680664, "step": 80000}
{"episode_reward": 3.4073452152996744, "episode": 81.0, "batch_reward": 0.010722375167533755, "critic_loss": 0.0030545315127747017, "actor_loss": -15.099960420757531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.30035400390625, "step": 81000}
{"episode_reward": 4.5582736144366445, "episode": 82.0, "batch_reward": 0.010709121351130307, "critic_loss": 0.002952992143771553, "actor_loss": -13.884669701173902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19401502609253, "step": 82000}
{"episode_reward": 3.904937373414058, "episode": 83.0, "batch_reward": 0.010822103475220501, "critic_loss": 0.002715836867733742, "actor_loss": -15.098492746055125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.082858324050903, "step": 83000}
{"episode_reward": 5.382799801689303, "episode": 84.0, "batch_reward": 0.010619481527479366, "critic_loss": 0.003413584728972637, "actor_loss": -15.237755595162511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.57831072807312, "step": 84000}
{"episode_reward": 4.981630636356826, "episode": 85.0, "batch_reward": 0.010599487615283579, "critic_loss": 0.003664911443280289, "actor_loss": -14.036221213549375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.304935216903687, "step": 85000}
{"episode_reward": 5.565319818216777, "episode": 86.0, "batch_reward": 0.010728928839555011, "critic_loss": 0.0031781613072671463, "actor_loss": -14.08632336884737, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.181791067123413, "step": 86000}
{"episode_reward": 4.808157381130683, "episode": 87.0, "batch_reward": 0.010522753732744604, "critic_loss": 0.002740408581070369, "actor_loss": -14.799154122695327, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.710716247558594, "step": 87000}
{"episode_reward": 2.9659153579474586, "episode": 88.0, "batch_reward": 0.010137307570083067, "critic_loss": 0.0027969892921100837, "actor_loss": -14.504013154298066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.752477169036865, "step": 88000}
{"episode_reward": 7.440490046366782, "episode": 89.0, "batch_reward": 0.01046494029648602, "critic_loss": 0.002688321146641101, "actor_loss": -13.350862039133906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.52291965484619, "step": 89000}
{"episode_reward": 5.645690296579629, "episode": 90.0, "batch_reward": 0.010507279404904693, "critic_loss": 0.003801542542030802, "actor_loss": -13.46764298388362, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12751293182373, "step": 90000}
{"episode_reward": 4.586318439602139, "episode": 91.0, "batch_reward": 0.010292436530580745, "critic_loss": 0.0019775297084706836, "actor_loss": -12.892844516560436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.206480503082275, "step": 91000}
{"episode_reward": 4.45050644478249, "episode": 92.0, "batch_reward": 0.010133989654714242, "critic_loss": 0.0028701444439575424, "actor_loss": -14.457792434468866, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.261964797973633, "step": 92000}
{"episode_reward": 4.465191014647597, "episode": 93.0, "batch_reward": 0.010055522253504022, "critic_loss": 0.002401874697956373, "actor_loss": -12.941770796328782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.191707134246826, "step": 93000}
{"episode_reward": 2.9283800907730906, "episode": 94.0, "batch_reward": 0.009972254603402689, "critic_loss": 0.0024373189423495204, "actor_loss": -14.38801916974783, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.741589784622192, "step": 94000}
{"episode_reward": 4.847989983845506, "episode": 95.0, "batch_reward": 0.009824544313596561, "critic_loss": 0.0022797227951377864, "actor_loss": -15.3830025267303, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.062142610549927, "step": 95000}
{"episode_reward": 5.6600334478524825, "episode": 96.0, "batch_reward": 0.010160172550473362, "critic_loss": 0.002951370477763703, "actor_loss": -13.604476734369992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.55832004547119, "step": 96000}
{"episode_reward": 2.212523573208918, "episode": 97.0, "batch_reward": 0.009924162158276885, "critic_loss": 0.003353590919963608, "actor_loss": -12.926727576225996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20122480392456, "step": 97000}
{"episode_reward": 2.9001686051617415, "episode": 98.0, "batch_reward": 0.00965336615871638, "critic_loss": 0.0021353802554804134, "actor_loss": -14.980002924129368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.47825026512146, "step": 98000}
{"episode_reward": 3.68992636394739, "episode": 99.0, "batch_reward": 0.009674672910012306, "critic_loss": 0.0022990878502241684, "actor_loss": -14.527263788491487, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.112679719924927, "step": 99000}
{"episode_reward": 4.0498566979745325, "episode": 100.0, "batch_reward": 0.009773425125749781, "critic_loss": 0.002342251565634797, "actor_loss": -14.135708795264364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.40803074836731, "step": 100000}
{"episode_reward": 4.294441173268472, "episode": 101.0, "batch_reward": 0.009786085574189201, "critic_loss": 0.002732445505869691, "actor_loss": -13.53778670847416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.62698817253113, "step": 101000}
{"episode_reward": 3.917906451943685, "episode": 102.0, "batch_reward": 0.00979418351314962, "critic_loss": 0.0038253584260382924, "actor_loss": -14.650005136892199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.103249311447144, "step": 102000}
{"episode_reward": 3.7783922303039486, "episode": 103.0, "batch_reward": 0.00977045544772409, "critic_loss": 0.0017489769583844464, "actor_loss": -14.597689573198556, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.4177508354187, "step": 103000}
{"episode_reward": 2.1100136462373014, "episode": 104.0, "batch_reward": 0.009675249507650733, "critic_loss": 0.001971940022413037, "actor_loss": -13.188275978952646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.554278135299683, "step": 104000}
{"episode_reward": 4.236168808830173, "episode": 105.0, "batch_reward": 0.009498654470779001, "critic_loss": 0.002370295203079877, "actor_loss": -13.916039106607437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.409905195236206, "step": 105000}
{"episode_reward": 2.571408693900442, "episode": 106.0, "batch_reward": 0.009023400988429785, "critic_loss": 0.0019159139839539422, "actor_loss": -13.112232370838523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.665127277374268, "step": 106000}
{"episode_reward": 5.1298489895963355, "episode": 107.0, "batch_reward": 0.009374100860906764, "critic_loss": 0.002225987948731927, "actor_loss": -13.354995863720776, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.534912586212158, "step": 107000}
{"episode_reward": 4.347090845003966, "episode": 108.0, "batch_reward": 0.00961936872638762, "critic_loss": 0.0022388103943376337, "actor_loss": -15.303048183858394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.343870162963867, "step": 108000}
{"episode_reward": 3.7259118324124287, "episode": 109.0, "batch_reward": 0.009083540722960606, "critic_loss": 0.002549212633042771, "actor_loss": -13.945036160930991, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.542394876480103, "step": 109000}
{"episode_reward": 7.080146813132324, "episode": 110.0, "batch_reward": 0.009503219585632905, "critic_loss": 0.002006836293192464, "actor_loss": -14.629205181583762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.631524801254272, "step": 110000}
{"episode_reward": 3.330290620656508, "episode": 111.0, "batch_reward": 0.009122168329311535, "critic_loss": 0.002519104213286482, "actor_loss": -13.733549621075392, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.090983152389526, "step": 111000}
{"episode_reward": 3.651623917102535, "episode": 112.0, "batch_reward": 0.009163427744526416, "critic_loss": 0.002455820853152545, "actor_loss": -15.225474942713976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.02066993713379, "step": 112000}
{"episode_reward": 3.514280817800852, "episode": 113.0, "batch_reward": 0.009137541820993647, "critic_loss": 0.0016417535873042653, "actor_loss": -13.183187759861351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.56159234046936, "step": 113000}
{"episode_reward": 3.809937482046423, "episode": 114.0, "batch_reward": 0.009143028498860076, "critic_loss": 0.0027776744086804683, "actor_loss": -14.561023598149418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.191022634506226, "step": 114000}
{"episode_reward": 4.54028118430708, "episode": 115.0, "batch_reward": 0.008712462682742625, "critic_loss": 0.002031004822085379, "actor_loss": -14.20403375902772, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20114493370056, "step": 115000}
{"episode_reward": 5.398232854201418, "episode": 116.0, "batch_reward": 0.009007525088498369, "critic_loss": 0.0018590084520037635, "actor_loss": -14.118751816496253, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.48292303085327, "step": 116000}
{"episode_reward": 2.577177673323514, "episode": 117.0, "batch_reward": 0.008810825744876637, "critic_loss": 0.0024066666887301836, "actor_loss": -13.166219933263957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.930150985717773, "step": 117000}
{"episode_reward": 1.7121262552277072, "episode": 118.0, "batch_reward": 0.008689852518960834, "critic_loss": 0.0019057176292262739, "actor_loss": -13.319346576012672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.685026168823242, "step": 118000}
{"episode_reward": 3.8869590713300144, "episode": 119.0, "batch_reward": 0.008994256797712296, "critic_loss": 0.0020731634496405603, "actor_loss": -13.43775068190694, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.124401092529297, "step": 119000}
{"episode_reward": 2.4272750778258247, "episode": 120.0, "batch_reward": 0.008897432473022491, "critic_loss": 0.0015439017430544481, "actor_loss": -13.38796591500193, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.7267906665802, "step": 120000}
{"episode_reward": 4.781802895180967, "episode": 121.0, "batch_reward": 0.00857212198409252, "critic_loss": 0.002058522737734165, "actor_loss": -12.978735661245883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.444854497909546, "step": 121000}
{"episode_reward": 3.205247842398741, "episode": 122.0, "batch_reward": 0.00855825262470171, "critic_loss": 0.0015587828806164906, "actor_loss": -14.32661078670621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.168621063232422, "step": 122000}
{"episode_reward": 2.9539081763359567, "episode": 123.0, "batch_reward": 0.00862742162309587, "critic_loss": 0.0026523067935340806, "actor_loss": -14.041735801577568, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.337074995040894, "step": 123000}
{"episode_reward": 3.661778358765015, "episode": 124.0, "batch_reward": 0.008813274726737291, "critic_loss": 0.001893394622449705, "actor_loss": -14.723610285192729, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.674760103225708, "step": 124000}
{"episode_reward": 4.359876130222724, "episode": 125.0, "batch_reward": 0.008338250063592569, "critic_loss": 0.0014734353105086485, "actor_loss": -13.907848086103797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34786057472229, "step": 125000}
{"episode_reward": 3.6602272966154037, "episode": 126.0, "batch_reward": 0.008594432939775288, "critic_loss": 0.0021022390583893867, "actor_loss": -14.537161876007914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.14429235458374, "step": 126000}
{"episode_reward": 5.166930352380015, "episode": 127.0, "batch_reward": 0.0084776532582473, "critic_loss": 0.001806191031828348, "actor_loss": -15.149274683199822, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.62665820121765, "step": 127000}
{"episode_reward": 4.131205406970718, "episode": 128.0, "batch_reward": 0.008475408079801128, "critic_loss": 0.0017625541796223842, "actor_loss": -14.703390247568489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.34516954421997, "step": 128000}
{"episode_reward": 4.850758101310383, "episode": 129.0, "batch_reward": 0.008574804023839533, "critic_loss": 0.00184071339359798, "actor_loss": -14.441674576669932, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.197327613830566, "step": 129000}
{"episode_reward": 4.566493719984415, "episode": 130.0, "batch_reward": 0.008255420945584775, "critic_loss": 0.00163529300497612, "actor_loss": -14.035789807461201, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.781482934951782, "step": 130000}
{"episode_reward": 2.0459248704617794, "episode": 131.0, "batch_reward": 0.008263699647737667, "critic_loss": 0.0028791197330356225, "actor_loss": -13.694616447195411, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.71816921234131, "step": 131000}
{"episode_reward": 4.305314953281349, "episode": 132.0, "batch_reward": 0.008254016385180876, "critic_loss": 0.0012427870874671498, "actor_loss": -13.97083753797412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.410329818725586, "step": 132000}
{"episode_reward": 5.872107532995179, "episode": 133.0, "batch_reward": 0.008203083149623126, "critic_loss": 0.0019016501482619788, "actor_loss": -12.915598151758314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.87213134765625, "step": 133000}
{"episode_reward": 3.8331082273784163, "episode": 134.0, "batch_reward": 0.008476036823587493, "critic_loss": 0.0019092293236535624, "actor_loss": -13.802734695859254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.020676136016846, "step": 134000}
{"episode_reward": 3.5083451617205608, "episode": 135.0, "batch_reward": 0.008009503449313343, "critic_loss": 0.0017306784010434058, "actor_loss": -14.62949517748505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.160675525665283, "step": 135000}
{"episode_reward": 5.775753195825411, "episode": 136.0, "batch_reward": 0.008304773206589743, "critic_loss": 0.0019410897066045435, "actor_loss": -14.530731022544206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.258399724960327, "step": 136000}
{"episode_reward": 3.5239637509585013, "episode": 137.0, "batch_reward": 0.008119464967399835, "critic_loss": 0.0016768177501580795, "actor_loss": -14.120793283574283, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.202152252197266, "step": 137000}
{"episode_reward": 5.496098165876973, "episode": 138.0, "batch_reward": 0.008131849265890195, "critic_loss": 0.0023610765145131154, "actor_loss": -14.240736604101956, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.895127773284912, "step": 138000}
{"episode_reward": 4.001865919621732, "episode": 139.0, "batch_reward": 0.00797021141462028, "critic_loss": 0.0017671532750755431, "actor_loss": -13.463657088853418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.733426570892334, "step": 139000}
{"episode_reward": 4.9252605732742065, "episode": 140.0, "batch_reward": 0.008312405900564045, "critic_loss": 0.0018147666531003778, "actor_loss": -13.858015041604638, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.090702295303345, "step": 140000}
{"episode_reward": 5.463816694225775, "episode": 141.0, "batch_reward": 0.008026668617036194, "critic_loss": 0.0013373446191981202, "actor_loss": -14.01527411286533, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.56321167945862, "step": 141000}
{"episode_reward": 3.4836597001146057, "episode": 142.0, "batch_reward": 0.008062921731034295, "critic_loss": 0.0019118109884220759, "actor_loss": -13.907134351581336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.236286163330078, "step": 142000}
{"episode_reward": 4.531530136819427, "episode": 143.0, "batch_reward": 0.008148593463236466, "critic_loss": 0.0015427844682199066, "actor_loss": -14.016507358081638, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.839654445648193, "step": 143000}
{"episode_reward": 4.798135512007089, "episode": 144.0, "batch_reward": 0.00797093168203719, "critic_loss": 0.001316030502661306, "actor_loss": -14.174760102905333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.92961835861206, "step": 144000}
{"episode_reward": 3.034611178544817, "episode": 145.0, "batch_reward": 0.007805470806546509, "critic_loss": 0.001803894683056569, "actor_loss": -15.060474850438535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.942533016204834, "step": 145000}
{"episode_reward": 4.240849616133941, "episode": 146.0, "batch_reward": 0.0078047338870819655, "critic_loss": 0.0015493946958449669, "actor_loss": -13.34412741933763, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.271230459213257, "step": 146000}
{"episode_reward": 3.7331427580778356, "episode": 147.0, "batch_reward": 0.008006177257047966, "critic_loss": 0.001408520019351272, "actor_loss": -13.897796562157572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.69123148918152, "step": 147000}
{"episode_reward": 4.875554673705837, "episode": 148.0, "batch_reward": 0.007777634508907795, "critic_loss": 0.0018024746185037657, "actor_loss": -14.116029712751509, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.53791356086731, "step": 148000}
{"episode_reward": 5.437068355948561, "episode": 149.0, "batch_reward": 0.007874308340251445, "critic_loss": 0.0017439295556032448, "actor_loss": -14.061397526144981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.992009162902832, "step": 149000}
{"episode_reward": 6.356835375428662, "episode": 150.0, "batch_reward": 0.007637751099187881, "critic_loss": 0.002235567462797917, "actor_loss": -14.71752458103001, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
