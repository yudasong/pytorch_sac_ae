{"episode_reward": 0.0, "episode": 1.0, "duration": 21.548192501068115, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.6206092834472656, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.2602473873174282, "critic_loss": 0.02142205291735732, "actor_loss": -14.678293780263077, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 68.15049815177917, "step": 3000}
{"episode_reward": 2.4051441603779136, "episode": 4.0, "batch_reward": 0.16229609092324973, "critic_loss": 0.013743146530585363, "actor_loss": -13.83498967075348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.7095844745636, "step": 4000}
{"episode_reward": 9.785766808565517, "episode": 5.0, "batch_reward": 0.126823377545923, "critic_loss": 0.014051387453917414, "actor_loss": -12.478603240013122, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.343597173690796, "step": 5000}
{"episode_reward": 2.9298638887131014, "episode": 6.0, "batch_reward": 0.1032974046766758, "critic_loss": 0.013818102137651294, "actor_loss": -12.838101029396057, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.470866441726685, "step": 6000}
{"episode_reward": 1.9918502724105573, "episode": 7.0, "batch_reward": 0.08816999284178019, "critic_loss": 0.01426317125861533, "actor_loss": -11.507953046798706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.93147301673889, "step": 7000}
{"episode_reward": 1.532710771227096, "episode": 8.0, "batch_reward": 0.0767651914935559, "critic_loss": 0.016894855195423587, "actor_loss": -11.810073770999908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16438579559326, "step": 8000}
{"episode_reward": 2.244549500206891, "episode": 9.0, "batch_reward": 0.06775456407479942, "critic_loss": 0.018549119684495963, "actor_loss": -11.665465224266052, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.677978038787842, "step": 9000}
{"episode_reward": 2.5192368613722227, "episode": 10.0, "batch_reward": 0.06134823894686997, "critic_loss": 0.017614934491459282, "actor_loss": -11.461646439552307, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.01416850090027, "step": 10000}
{"episode_reward": 3.1586770267477444, "episode": 11.0, "batch_reward": 0.05654585903603584, "critic_loss": 0.016127761357231065, "actor_loss": -12.352517360210419, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.44863724708557, "step": 11000}
{"episode_reward": 3.3000168985990714, "episode": 12.0, "batch_reward": 0.05024938443582505, "critic_loss": 0.01797752011718694, "actor_loss": -12.137101798534394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.11430597305298, "step": 12000}
{"episode_reward": 2.8010637842330928, "episode": 13.0, "batch_reward": 0.04687732707057148, "critic_loss": 0.027713368965429253, "actor_loss": -10.859729270935059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.2424418926239, "step": 13000}
{"episode_reward": 4.085477762237983, "episode": 14.0, "batch_reward": 0.04419520700071007, "critic_loss": 0.01919366052886471, "actor_loss": -11.73319732284546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.694929361343384, "step": 14000}
{"episode_reward": 3.934720896142044, "episode": 15.0, "batch_reward": 0.0408559119971469, "critic_loss": 0.018188886562478728, "actor_loss": -11.3003819937706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.267069578170776, "step": 15000}
{"episode_reward": 2.986931157432581, "episode": 16.0, "batch_reward": 0.038655094657558946, "critic_loss": 0.016563000835012644, "actor_loss": -11.346114032268524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.185680389404297, "step": 16000}
{"episode_reward": 2.97341014064245, "episode": 17.0, "batch_reward": 0.036322097967145965, "critic_loss": 0.01855648348131217, "actor_loss": -10.899516545057297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.428490161895752, "step": 17000}
{"episode_reward": 1.9253143286814907, "episode": 18.0, "batch_reward": 0.03522883078549057, "critic_loss": 0.01938039598183241, "actor_loss": -10.472697626113892, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.856276988983154, "step": 18000}
{"episode_reward": 2.255463224153251, "episode": 19.0, "batch_reward": 0.032969709685072304, "critic_loss": 0.012566512448014691, "actor_loss": -10.06738880944252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.43243956565857, "step": 19000}
{"episode_reward": 2.0776009848991706, "episode": 20.0, "batch_reward": 0.03132887785159983, "critic_loss": 0.01733462282427354, "actor_loss": -10.679420623064042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.203773975372314, "step": 20000}
{"episode_reward": 1.5615282861925044, "episode": 21.0, "batch_reward": 0.029066030649002643, "critic_loss": 0.015016425651381723, "actor_loss": -9.587385379433632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.746254444122314, "step": 21000}
{"episode_reward": 1.663678939199747, "episode": 22.0, "batch_reward": 0.028658994094468652, "critic_loss": 0.015542893197387457, "actor_loss": -11.480449002623558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.63124966621399, "step": 22000}
{"episode_reward": 2.2377782286120493, "episode": 23.0, "batch_reward": 0.027194408485433086, "critic_loss": 0.012397560625162441, "actor_loss": -9.77588658261299, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.296141862869263, "step": 23000}
{"episode_reward": 1.717999179610076, "episode": 24.0, "batch_reward": 0.026056588870240375, "critic_loss": 0.01563128786010202, "actor_loss": -10.343672356009483, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.824739933013916, "step": 24000}
{"episode_reward": 1.6304754419686978, "episode": 25.0, "batch_reward": 0.025636945088161157, "critic_loss": 0.013822719245508779, "actor_loss": -9.608454924821853, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.5315523147583, "step": 25000}
{"episode_reward": 2.7970275705589698, "episode": 26.0, "batch_reward": 0.024370019180700184, "critic_loss": 0.012561519122216851, "actor_loss": -9.04803012895584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.3447003364563, "step": 26000}
{"episode_reward": 2.7618451051251958, "episode": 27.0, "batch_reward": 0.024121386738261207, "critic_loss": 0.012306124588591047, "actor_loss": -9.064076028227806, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.611217737197876, "step": 27000}
{"episode_reward": 2.663810430535242, "episode": 28.0, "batch_reward": 0.023128072045044974, "critic_loss": 0.015232500064186753, "actor_loss": -10.993977068305016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.985889673233032, "step": 28000}
{"episode_reward": 2.302427692102027, "episode": 29.0, "batch_reward": 0.0218190266485326, "critic_loss": 0.012774744564492721, "actor_loss": -9.41555732703209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.042888164520264, "step": 29000}
{"episode_reward": 1.7797210321916819, "episode": 30.0, "batch_reward": 0.02150141467899084, "critic_loss": 0.011526450738529093, "actor_loss": -8.67783168411255, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.207671642303467, "step": 30000}
{"episode_reward": 3.0849502531072117, "episode": 31.0, "batch_reward": 0.02067153626587242, "critic_loss": 0.006469149197393563, "actor_loss": -9.165495817303658, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.8539514541626, "step": 31000}
{"episode_reward": 2.3867603429091857, "episode": 32.0, "batch_reward": 0.020240248523885385, "critic_loss": 0.012532436641282401, "actor_loss": -10.218383579611778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.06760597229004, "step": 32000}
{"episode_reward": 2.393352146286391, "episode": 33.0, "batch_reward": 0.019709258876740934, "critic_loss": 0.009890863014850766, "actor_loss": -10.622025631666183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.230401515960693, "step": 33000}
{"episode_reward": 2.488901094169142, "episode": 34.0, "batch_reward": 0.019333299545105546, "critic_loss": 0.009391832037828863, "actor_loss": -8.50933651661873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.226765155792236, "step": 34000}
{"episode_reward": 2.593074846093825, "episode": 35.0, "batch_reward": 0.01801520644710399, "critic_loss": 0.008541121603979263, "actor_loss": -10.412794423818589, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.26848077774048, "step": 35000}
{"episode_reward": 1.5847222433118895, "episode": 36.0, "batch_reward": 0.017768634654232302, "critic_loss": 0.011537335152679589, "actor_loss": -10.48491540569067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.748591661453247, "step": 36000}
{"episode_reward": 2.7304908794559974, "episode": 37.0, "batch_reward": 0.017820838776649906, "critic_loss": 0.007882188503979705, "actor_loss": -9.649857006549835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.315901517868042, "step": 37000}
{"episode_reward": 3.165399331843801, "episode": 38.0, "batch_reward": 0.01713473937381059, "critic_loss": 0.006847682839332265, "actor_loss": -9.73099983471632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.489343881607056, "step": 38000}
{"episode_reward": 2.3907689721909056, "episode": 39.0, "batch_reward": 0.017042404741514475, "critic_loss": 0.009164481747255196, "actor_loss": -10.056751259565353, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.240426540374756, "step": 39000}
{"episode_reward": 1.8624085571663267, "episode": 40.0, "batch_reward": 0.016554998747538775, "critic_loss": 0.006464477450426784, "actor_loss": -8.566149541676044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.541239261627197, "step": 40000}
{"episode_reward": 2.3689231189864266, "episode": 41.0, "batch_reward": 0.016138154146145098, "critic_loss": 0.008918002242804505, "actor_loss": -8.14450657981634, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.5322265625, "step": 41000}
{"episode_reward": 2.3749634845228327, "episode": 42.0, "batch_reward": 0.015893830632208845, "critic_loss": 0.005809474071502336, "actor_loss": -9.673123530328274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.266188621520996, "step": 42000}
{"episode_reward": 2.515674914271889, "episode": 43.0, "batch_reward": 0.015385515482863411, "critic_loss": 0.00981707041435584, "actor_loss": -9.475488740742206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.224821090698242, "step": 43000}
{"episode_reward": 1.5997617679256702, "episode": 44.0, "batch_reward": 0.015364347030757926, "critic_loss": 0.007382973788451637, "actor_loss": -10.340918607115746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.541264057159424, "step": 44000}
{"episode_reward": 2.4605917139207962, "episode": 45.0, "batch_reward": 0.014740157584077679, "critic_loss": 0.006318225285227527, "actor_loss": -9.947240103900432, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.209688425064087, "step": 45000}
{"episode_reward": 3.5869865728880024, "episode": 46.0, "batch_reward": 0.0143484305460006, "critic_loss": 0.005882815118398867, "actor_loss": -9.129201766312123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.70447063446045, "step": 46000}
{"episode_reward": 2.6250653440844123, "episode": 47.0, "batch_reward": 0.014218607754213736, "critic_loss": 0.007828042340828689, "actor_loss": -9.183060814738274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.38411855697632, "step": 47000}
{"episode_reward": 3.0351745340276106, "episode": 48.0, "batch_reward": 0.014155710536986589, "critic_loss": 0.008155185230672941, "actor_loss": -8.993454011499882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.56184959411621, "step": 48000}
{"episode_reward": 2.7736577450826467, "episode": 49.0, "batch_reward": 0.014119106708909385, "critic_loss": 0.0067150076023535805, "actor_loss": -9.961419389128684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15176033973694, "step": 49000}
{"episode_reward": 2.6658061998713776, "episode": 50.0, "batch_reward": 0.013711548109189607, "critic_loss": 0.009891031989449402, "actor_loss": -8.990690989673137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.234530210494995, "step": 50000}
{"episode_reward": 3.394613936902147, "episode": 51.0, "batch_reward": 0.013532835205085575, "critic_loss": 0.00654588466376299, "actor_loss": -8.681861179530621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.308069467544556, "step": 51000}
{"episode_reward": 2.3410946962729806, "episode": 52.0, "batch_reward": 0.013376819092896767, "critic_loss": 0.0075830268040590456, "actor_loss": -7.879263358950615, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.346982717514038, "step": 52000}
{"episode_reward": 1.6663126263731523, "episode": 53.0, "batch_reward": 0.013137247831909917, "critic_loss": 0.00465434124643798, "actor_loss": -9.426026652932167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.0966694355011, "step": 53000}
{"episode_reward": 1.844062524732494, "episode": 54.0, "batch_reward": 0.012867456343490631, "critic_loss": 0.0064719131379679315, "actor_loss": -9.107766549646854, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.10063862800598, "step": 54000}
{"episode_reward": 2.2855462947276557, "episode": 55.0, "batch_reward": 0.012948640730464832, "critic_loss": 0.0076996212347148684, "actor_loss": -9.54354672086239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.280340909957886, "step": 55000}
{"episode_reward": 2.4631106306734303, "episode": 56.0, "batch_reward": 0.01236628703342285, "critic_loss": 0.004195717144844821, "actor_loss": -8.950607221722603, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.23227596282959, "step": 56000}
{"episode_reward": 2.0904714428623357, "episode": 57.0, "batch_reward": 0.012331173621001654, "critic_loss": 0.006082877436245326, "actor_loss": -9.628061446785926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.533536911010742, "step": 57000}
{"episode_reward": 3.5671936600134595, "episode": 58.0, "batch_reward": 0.012061050793272443, "critic_loss": 0.006874554499678197, "actor_loss": -9.803481746912002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.057952642440796, "step": 58000}
{"episode_reward": 3.294186173997044, "episode": 59.0, "batch_reward": 0.011898499887320214, "critic_loss": 0.006186872015052359, "actor_loss": -8.537720610380173, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.809439182281494, "step": 59000}
{"episode_reward": 2.215038377599265, "episode": 60.0, "batch_reward": 0.01196866209397558, "critic_loss": 0.005294418312594644, "actor_loss": -9.38010005223751, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.039259672164917, "step": 60000}
{"episode_reward": 2.009482365318049, "episode": 61.0, "batch_reward": 0.011909360878285952, "critic_loss": 0.007259457111547817, "actor_loss": -8.462204617202282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.70172882080078, "step": 61000}
{"episode_reward": 1.7610680121046958, "episode": 62.0, "batch_reward": 0.011862025945680216, "critic_loss": 0.004809319108549971, "actor_loss": -9.456582242399454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.49666142463684, "step": 62000}
{"episode_reward": 2.7423812649249357, "episode": 63.0, "batch_reward": 0.011337053932365962, "critic_loss": 0.006632994048355613, "actor_loss": -7.735344177424908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.572438716888428, "step": 63000}
{"episode_reward": 1.7076120590332344, "episode": 64.0, "batch_reward": 0.011162986430455931, "critic_loss": 0.004970653207157738, "actor_loss": -9.028347763180733, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.016805171966553, "step": 64000}
{"episode_reward": 1.5152382231310617, "episode": 65.0, "batch_reward": 0.010976311759091913, "critic_loss": 0.0056891131560405485, "actor_loss": -9.038024206668139, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.84438419342041, "step": 65000}
{"episode_reward": 2.7798539805260827, "episode": 66.0, "batch_reward": 0.010809735313174315, "critic_loss": 0.006329006979372934, "actor_loss": -9.092046121001244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.153861045837402, "step": 66000}
{"episode_reward": 1.5763300814699532, "episode": 67.0, "batch_reward": 0.010905145053518936, "critic_loss": 0.004425074168088031, "actor_loss": -10.556163514465094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.964733600616455, "step": 67000}
{"episode_reward": 1.755743774388054, "episode": 68.0, "batch_reward": 0.010578997310716659, "critic_loss": 0.007054199942358536, "actor_loss": -9.298360045611858, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.245001316070557, "step": 68000}
{"episode_reward": 2.743321689597447, "episode": 69.0, "batch_reward": 0.01061800328514073, "critic_loss": 0.005114643198539852, "actor_loss": -7.883669687360525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.118359565734863, "step": 69000}
{"episode_reward": 1.6129322967673119, "episode": 70.0, "batch_reward": 0.010502295606653207, "critic_loss": 0.004927569297127775, "actor_loss": -9.305881604641677, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.978724241256714, "step": 70000}
{"episode_reward": 2.6862600880618785, "episode": 71.0, "batch_reward": 0.010455079702893272, "critic_loss": 0.006867047275329241, "actor_loss": -9.298690814495087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.28874063491821, "step": 71000}
{"episode_reward": 1.6756408115276675, "episode": 72.0, "batch_reward": 0.010348529140697792, "critic_loss": 0.005671659377097967, "actor_loss": -8.286108462363481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.907264709472656, "step": 72000}
{"episode_reward": 2.129893779081516, "episode": 73.0, "batch_reward": 0.01022239914315287, "critic_loss": 0.0069522656020708385, "actor_loss": -8.734590186744928, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.705456733703613, "step": 73000}
{"episode_reward": 2.2525266046482457, "episode": 74.0, "batch_reward": 0.009783971676486545, "critic_loss": 0.004608917882622336, "actor_loss": -8.833921524584293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.010680198669434, "step": 74000}
{"episode_reward": 2.3650220816219742, "episode": 75.0, "batch_reward": 0.00961552071943879, "critic_loss": 0.005149583287318819, "actor_loss": -7.673071192324161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.373054027557373, "step": 75000}
{"episode_reward": 1.827796932191343, "episode": 76.0, "batch_reward": 0.009951261943904683, "critic_loss": 0.0052170780468441084, "actor_loss": -8.42764961719513, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.041314601898193, "step": 76000}
{"episode_reward": 3.217967435668663, "episode": 77.0, "batch_reward": 0.009978569007129408, "critic_loss": 0.007288956854172284, "actor_loss": -9.152645045161247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.38305425643921, "step": 77000}
{"episode_reward": 2.2736484529196455, "episode": 78.0, "batch_reward": 0.01005225169833284, "critic_loss": 0.004747585273275036, "actor_loss": -9.080604651600122, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.02808690071106, "step": 78000}
{"episode_reward": 2.9542280982772784, "episode": 79.0, "batch_reward": 0.009425855265231804, "critic_loss": 0.004161301523126894, "actor_loss": -9.687848437786103, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.398528337478638, "step": 79000}
{"episode_reward": 3.010025407139674, "episode": 80.0, "batch_reward": 0.00950554581754841, "critic_loss": 0.00425761239946587, "actor_loss": -9.784266566574573, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.198843479156494, "step": 80000}
{"episode_reward": 2.2497836644484956, "episode": 81.0, "batch_reward": 0.009074023364111781, "critic_loss": 0.004970339663937921, "actor_loss": -9.709026946306228, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.779611587524414, "step": 81000}
{"episode_reward": 3.615439613090566, "episode": 82.0, "batch_reward": 0.009093410534784198, "critic_loss": 0.0032744481525442096, "actor_loss": -8.070034944117069, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.520495891571045, "step": 82000}
{"episode_reward": 1.6468452360027874, "episode": 83.0, "batch_reward": 0.009184903114335612, "critic_loss": 0.0027675424070403094, "actor_loss": -9.925909403264523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.36860680580139, "step": 83000}
{"episode_reward": 2.220008859359167, "episode": 84.0, "batch_reward": 0.008974875676212832, "critic_loss": 0.003841812691112864, "actor_loss": -8.668015775293112, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.436153411865234, "step": 84000}
{"episode_reward": 3.6689072491886923, "episode": 85.0, "batch_reward": 0.008987563537317328, "critic_loss": 0.004729794703991501, "actor_loss": -8.906124749690294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.392443656921387, "step": 85000}
{"episode_reward": 2.4372050273433348, "episode": 86.0, "batch_reward": 0.009093186023528687, "critic_loss": 0.003762591446888109, "actor_loss": -8.949130228340625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.221462726593018, "step": 86000}
{"episode_reward": 2.8899881041979376, "episode": 87.0, "batch_reward": 0.008914330078288913, "critic_loss": 0.003552965774018958, "actor_loss": -9.966015442460776, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.044185876846313, "step": 87000}
{"episode_reward": 3.070703547295585, "episode": 88.0, "batch_reward": 0.008473309877794237, "critic_loss": 0.002252114844195603, "actor_loss": -8.080197440892459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.256624937057495, "step": 88000}
{"episode_reward": 2.8634871708906258, "episode": 89.0, "batch_reward": 0.008837632342474535, "critic_loss": 0.004537417952080432, "actor_loss": -8.154080515235663, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.667123317718506, "step": 89000}
{"episode_reward": 2.465085735011378, "episode": 90.0, "batch_reward": 0.008851555430912412, "critic_loss": 0.003967415222206909, "actor_loss": -8.610672728449106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.339943885803223, "step": 90000}
{"episode_reward": 2.829090807141103, "episode": 91.0, "batch_reward": 0.008616840650560334, "critic_loss": 0.0024397208590235097, "actor_loss": -7.858498403936625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.78725051879883, "step": 91000}
{"episode_reward": 2.105009607724238, "episode": 92.0, "batch_reward": 0.008451123100239783, "critic_loss": 0.0037998331327107737, "actor_loss": -8.705957630485296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.262875080108643, "step": 92000}
{"episode_reward": 3.0270383580451616, "episode": 93.0, "batch_reward": 0.008383604968897998, "critic_loss": 0.003696333401123411, "actor_loss": -8.129316883534193, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.06569480895996, "step": 93000}
{"episode_reward": 2.895905620705203, "episode": 94.0, "batch_reward": 0.00832306542887818, "critic_loss": 0.0052004737544193635, "actor_loss": -7.900814356178045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.742589712142944, "step": 94000}
{"episode_reward": 3.245687108704315, "episode": 95.0, "batch_reward": 0.0081655880715698, "critic_loss": 0.002159452768995834, "actor_loss": -9.655217420727014, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.85166573524475, "step": 95000}
{"episode_reward": 3.1397792656567454, "episode": 96.0, "batch_reward": 0.008521972374175676, "critic_loss": 0.005376231246133102, "actor_loss": -8.01542289045453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.904330015182495, "step": 96000}
{"episode_reward": 2.4247312250068016, "episode": 97.0, "batch_reward": 0.008325710919336416, "critic_loss": 0.003563693420102936, "actor_loss": -8.729921409487725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.93573307991028, "step": 97000}
{"episode_reward": 2.5966742054693235, "episode": 98.0, "batch_reward": 0.008001965623698197, "critic_loss": 0.003442938296371722, "actor_loss": -10.261510851234197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.8741238117218, "step": 98000}
{"episode_reward": 2.84896748190522, "episode": 99.0, "batch_reward": 0.00803769250086043, "critic_loss": 0.0030935705942611094, "actor_loss": -8.791541614234447, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.0120792388916, "step": 99000}
{"episode_reward": 2.098542892774148, "episode": 100.0, "batch_reward": 0.00811398477340117, "critic_loss": 0.004350650603133545, "actor_loss": -9.01259460774064, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.925562620162964, "step": 100000}
{"episode_reward": 2.841048104993347, "episode": 101.0, "batch_reward": 0.008194069216842763, "critic_loss": 0.004500211332124309, "actor_loss": -7.852989885985851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.47004294395447, "step": 101000}
{"episode_reward": 2.7132014724829756, "episode": 102.0, "batch_reward": 0.008213349033729174, "critic_loss": 0.005518051876046229, "actor_loss": -9.373845181167125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.78502917289734, "step": 102000}
{"episode_reward": 2.6868142697959296, "episode": 103.0, "batch_reward": 0.008225250204326585, "critic_loss": 0.0029706532054260605, "actor_loss": -9.154816759467124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.653355598449707, "step": 103000}
{"episode_reward": 2.1322860151969802, "episode": 104.0, "batch_reward": 0.008040170362452045, "critic_loss": 0.005341921295890643, "actor_loss": -8.2433999774158, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.9889919757843, "step": 104000}
{"episode_reward": 2.770099578654669, "episode": 105.0, "batch_reward": 0.007911124516045675, "critic_loss": 0.004049477746702905, "actor_loss": -8.239491908669471, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.493128299713135, "step": 105000}
{"episode_reward": 1.92326423536411, "episode": 106.0, "batch_reward": 0.0074657264153938745, "critic_loss": 0.0032903419705689885, "actor_loss": -8.490983539372683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.53844952583313, "step": 106000}
{"episode_reward": 3.3636189358332462, "episode": 107.0, "batch_reward": 0.007768803915590979, "critic_loss": 0.006090727907758264, "actor_loss": -8.227322150081395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.15286636352539, "step": 107000}
{"episode_reward": 2.6750173307547542, "episode": 108.0, "batch_reward": 0.00801546887285076, "critic_loss": 0.003123429911916901, "actor_loss": -9.645365431904793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.79298448562622, "step": 108000}
{"episode_reward": 2.5940011582444336, "episode": 109.0, "batch_reward": 0.007438725705724209, "critic_loss": 0.004597454163085785, "actor_loss": -8.19847025358677, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.322455406188965, "step": 109000}
{"episode_reward": 2.7638048092918543, "episode": 110.0, "batch_reward": 0.007854802827117965, "critic_loss": 0.00378683363613527, "actor_loss": -9.974300471186638, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.610382556915283, "step": 110000}
{"episode_reward": 1.9414992038654235, "episode": 111.0, "batch_reward": 0.007482132970355451, "critic_loss": 0.003742218511077226, "actor_loss": -8.670345660090446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.59454798698425, "step": 111000}
{"episode_reward": 2.027755851779607, "episode": 112.0, "batch_reward": 0.00757556103344541, "critic_loss": 0.004865834590891609, "actor_loss": -9.344887840300798, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.49570941925049, "step": 112000}
{"episode_reward": 3.03173795307808, "episode": 113.0, "batch_reward": 0.007510718493838795, "critic_loss": 0.0035097539673442954, "actor_loss": -8.347444158732891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.09239912033081, "step": 113000}
{"episode_reward": 2.7375582724660372, "episode": 114.0, "batch_reward": 0.007566424917778931, "critic_loss": 0.003582668870250927, "actor_loss": -9.240313397943973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.643017530441284, "step": 114000}
{"episode_reward": 3.5487230081196746, "episode": 115.0, "batch_reward": 0.007127825563075021, "critic_loss": 0.004179803005456052, "actor_loss": -9.37944103690982, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.564926147460938, "step": 115000}
{"episode_reward": 2.5082525390308845, "episode": 116.0, "batch_reward": 0.007394871126161888, "critic_loss": 0.0033203173129368224, "actor_loss": -8.834356622457504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.552797317504883, "step": 116000}
{"episode_reward": 1.5920872155181718, "episode": 117.0, "batch_reward": 0.0072186292842961845, "critic_loss": 0.00511241222260287, "actor_loss": -8.437661580681802, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.441037893295288, "step": 117000}
{"episode_reward": 1.9232284176087486, "episode": 118.0, "batch_reward": 0.007111041610944085, "critic_loss": 0.0028181103736133082, "actor_loss": -8.306246857464313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.694780826568604, "step": 118000}
{"episode_reward": 2.258420425482927, "episode": 119.0, "batch_reward": 0.007426819349406287, "critic_loss": 0.004173969314841088, "actor_loss": -7.8049049195647235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.957310914993286, "step": 119000}
{"episode_reward": 2.3430740302986433, "episode": 120.0, "batch_reward": 0.007358869721298106, "critic_loss": 0.005181808500630723, "actor_loss": -8.144236063212157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.840402126312256, "step": 120000}
{"episode_reward": 2.2915486547039583, "episode": 121.0, "batch_reward": 0.006972365919617004, "critic_loss": 0.002646008328694734, "actor_loss": -8.123444266438485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.07203197479248, "step": 121000}
{"episode_reward": 2.583034390061222, "episode": 122.0, "batch_reward": 0.006983453956781887, "critic_loss": 0.0024401568925750327, "actor_loss": -8.915541528880595, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.110215663909912, "step": 122000}
{"episode_reward": 3.680651354525131, "episode": 123.0, "batch_reward": 0.0070699283290887255, "critic_loss": 0.0031724178235745058, "actor_loss": -8.855940114736557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.537067890167236, "step": 123000}
{"episode_reward": 2.3716052297316397, "episode": 124.0, "batch_reward": 0.007271976966178045, "critic_loss": 0.002944215388954035, "actor_loss": -8.6967724070251, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.11115288734436, "step": 124000}
{"episode_reward": 2.439892927971412, "episode": 125.0, "batch_reward": 0.006826293824706227, "critic_loss": 0.0024088190304100863, "actor_loss": -8.99992429637909, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.985870599746704, "step": 125000}
{"episode_reward": 2.026425332682636, "episode": 126.0, "batch_reward": 0.007074706846149638, "critic_loss": 0.004299453762665507, "actor_loss": -9.082305506825447, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.308701992034912, "step": 126000}
{"episode_reward": 4.540883077812731, "episode": 127.0, "batch_reward": 0.006926996811875142, "critic_loss": 0.0027349671175397818, "actor_loss": -10.033666030108929, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.89097785949707, "step": 127000}
{"episode_reward": 2.367186799864333, "episode": 128.0, "batch_reward": 0.006911376809235662, "critic_loss": 0.003264862310999888, "actor_loss": -8.956714985489846, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.54974865913391, "step": 128000}
{"episode_reward": 2.027814242438683, "episode": 129.0, "batch_reward": 0.007010111134964973, "critic_loss": 0.0025134088963095565, "actor_loss": -8.85639420351386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.178167819976807, "step": 129000}
{"episode_reward": 2.72927550651451, "episode": 130.0, "batch_reward": 0.006706816512043588, "critic_loss": 0.0028682751758315134, "actor_loss": -9.065231398135424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.283247709274292, "step": 130000}
{"episode_reward": 2.301600504217248, "episode": 131.0, "batch_reward": 0.0067376112098572775, "critic_loss": 0.002667026551476738, "actor_loss": -8.272763153225183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.29786014556885, "step": 131000}
{"episode_reward": 2.4238297629091736, "episode": 132.0, "batch_reward": 0.006724864818505012, "critic_loss": 0.003287109317818249, "actor_loss": -8.660788024574519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.7920982837677, "step": 132000}
{"episode_reward": 2.8114306756341847, "episode": 133.0, "batch_reward": 0.00669086495123338, "critic_loss": 0.002729086790983274, "actor_loss": -7.810396534979343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.020639657974243, "step": 133000}
{"episode_reward": 2.2892987588005944, "episode": 134.0, "batch_reward": 0.006947729903855361, "critic_loss": 0.002821832176952739, "actor_loss": -8.87834614238143, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.075061559677124, "step": 134000}
{"episode_reward": 3.319788596102393, "episode": 135.0, "batch_reward": 0.006467526097665541, "critic_loss": 0.0018604786674695788, "actor_loss": -9.889623697400094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.034401178359985, "step": 135000}
{"episode_reward": 2.585834708198968, "episode": 136.0, "batch_reward": 0.006741176567855291, "critic_loss": 0.004588141002597695, "actor_loss": -9.118378884643317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.600220918655396, "step": 136000}
{"episode_reward": 2.689123925860555, "episode": 137.0, "batch_reward": 0.006551132851745934, "critic_loss": 0.002176593497642898, "actor_loss": -9.714989235788584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.696003198623657, "step": 137000}
{"episode_reward": 2.7281703068185603, "episode": 138.0, "batch_reward": 0.006575650894665159, "critic_loss": 0.0027617926899838495, "actor_loss": -9.27525514677167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.343377590179443, "step": 138000}
{"episode_reward": 1.5982007077543745, "episode": 139.0, "batch_reward": 0.0064355846497928726, "critic_loss": 0.0028826806302240586, "actor_loss": -8.76638377469778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.213629961013794, "step": 139000}
{"episode_reward": 4.1398759192609536, "episode": 140.0, "batch_reward": 0.00673403103009332, "critic_loss": 0.00317268406265066, "actor_loss": -8.488004061967134, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.857901573181152, "step": 140000}
{"episode_reward": 3.787351714631254, "episode": 141.0, "batch_reward": 0.006450981472968124, "critic_loss": 0.0018452904234218296, "actor_loss": -9.209623118877412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.13557958602905, "step": 141000}
{"episode_reward": 2.7637852292813303, "episode": 142.0, "batch_reward": 0.006470938700134866, "critic_loss": 0.0031873717279013365, "actor_loss": -8.990231927156449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.162405490875244, "step": 142000}
{"episode_reward": 2.161819824505964, "episode": 143.0, "batch_reward": 0.006626125790528022, "critic_loss": 0.00287727184958203, "actor_loss": -8.87991546022892, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.812302589416504, "step": 143000}
{"episode_reward": 5.173785048056823, "episode": 144.0, "batch_reward": 0.006438522612908855, "critic_loss": 0.002051157647765649, "actor_loss": -9.316768437266349, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.404632091522217, "step": 144000}
{"episode_reward": 1.7806213910937394, "episode": 145.0, "batch_reward": 0.006239990840083919, "critic_loss": 0.0025246398832387057, "actor_loss": -9.198233512222767, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.752511978149414, "step": 145000}
{"episode_reward": 3.3689081557354212, "episode": 146.0, "batch_reward": 0.006259398681926541, "critic_loss": 0.0029268470667884686, "actor_loss": -8.463650348961353, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.051924228668213, "step": 146000}
{"episode_reward": 2.0767341273733644, "episode": 147.0, "batch_reward": 0.00644389448966831, "critic_loss": 0.0024021748779632615, "actor_loss": -8.8017595102489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.388695001602173, "step": 147000}
{"episode_reward": 2.0472739962819704, "episode": 148.0, "batch_reward": 0.006222335058148019, "critic_loss": 0.0028174268398943243, "actor_loss": -9.0747161462605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.609081029891968, "step": 148000}
{"episode_reward": 2.0017147208913992, "episode": 149.0, "batch_reward": 0.006288981368299574, "critic_loss": 0.0018276011430571088, "actor_loss": -8.28738046067953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.75182056427002, "step": 149000}
{"episode_reward": 3.6648403476599607, "episode": 150.0, "batch_reward": 0.00604307719564531, "critic_loss": 0.0024987483654986134, "actor_loss": -9.975224258095025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
