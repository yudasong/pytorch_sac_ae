{"episode_reward": 0.0, "episode": 1.0, "duration": 15.227656602859497, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.3707494735717773, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.2658662596278367, "critic_loss": 0.05488994697754176, "actor_loss": -35.752775864080846, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 68.56926250457764, "step": 3000}
{"episode_reward": 73.85708969893213, "episode": 4.0, "batch_reward": 0.19062933099269866, "critic_loss": 0.07400818638131022, "actor_loss": -25.74973052382469, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.69758653640747, "step": 4000}
{"episode_reward": 41.44508187342303, "episode": 5.0, "batch_reward": 0.15562775998562575, "critic_loss": 0.09024241767078638, "actor_loss": -21.663596421718598, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.813695192337036, "step": 5000}
{"episode_reward": 38.76346130917043, "episode": 6.0, "batch_reward": 0.1341404254436493, "critic_loss": 0.08779877158254384, "actor_loss": -17.80652853012085, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.444719791412354, "step": 6000}
{"episode_reward": 44.9797173551428, "episode": 7.0, "batch_reward": 0.12060728044062853, "critic_loss": 0.09599793411418796, "actor_loss": -17.736811952114106, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.417750120162964, "step": 7000}
{"episode_reward": 45.02838287047357, "episode": 8.0, "batch_reward": 0.11269850741326809, "critic_loss": 0.09285485356673598, "actor_loss": -15.860351850986481, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.89138960838318, "step": 8000}
{"episode_reward": 76.72697477463798, "episode": 9.0, "batch_reward": 0.10732625644654036, "critic_loss": 0.10301488713547588, "actor_loss": -14.880067224025726, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.02329683303833, "step": 9000}
{"episode_reward": 49.294655776446525, "episode": 10.0, "batch_reward": 0.10122776708379388, "critic_loss": 0.11480861714854837, "actor_loss": -13.388074268341065, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.10955786705017, "step": 10000}
{"episode_reward": 53.88699175708834, "episode": 11.0, "batch_reward": 0.0997899659872055, "critic_loss": 0.11254030202701688, "actor_loss": -12.709562408447265, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.45977020263672, "step": 11000}
{"episode_reward": 94.81261851345333, "episode": 12.0, "batch_reward": 0.09765322743356228, "critic_loss": 0.11030036352947355, "actor_loss": -11.448206768035888, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.825605630874634, "step": 12000}
{"episode_reward": 98.15119742238112, "episode": 13.0, "batch_reward": 0.09376890159398317, "critic_loss": 0.10163827691972256, "actor_loss": -12.525078244686126, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.585533142089844, "step": 13000}
{"episode_reward": 2.8222016737977533, "episode": 14.0, "batch_reward": 0.08990971904620529, "critic_loss": 0.11341355680301786, "actor_loss": -11.862853571891785, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.909900903701782, "step": 14000}
{"episode_reward": 115.58983723769819, "episode": 15.0, "batch_reward": 0.09027737671509385, "critic_loss": 0.142272771243006, "actor_loss": -12.094067399024963, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.855875968933105, "step": 15000}
{"episode_reward": 84.14547221178896, "episode": 16.0, "batch_reward": 0.09093104446306825, "critic_loss": 0.15571396560966969, "actor_loss": -12.533703713178635, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.70053243637085, "step": 16000}
{"episode_reward": 76.23118107270379, "episode": 17.0, "batch_reward": 0.09050627972185611, "critic_loss": 0.16169130294024944, "actor_loss": -12.177793089985848, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.25874090194702, "step": 17000}
{"episode_reward": 83.6900829522449, "episode": 18.0, "batch_reward": 0.0921101467050612, "critic_loss": 0.15030953300744296, "actor_loss": -11.748768270730972, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.19086217880249, "step": 18000}
{"episode_reward": 78.43839362310682, "episode": 19.0, "batch_reward": 0.08985036494210362, "critic_loss": 0.15145905603468418, "actor_loss": -11.510721741825343, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.864481449127197, "step": 19000}
{"episode_reward": 65.45777125397085, "episode": 20.0, "batch_reward": 0.08697000857442617, "critic_loss": 0.14463654712587595, "actor_loss": -10.774573670074343, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.072365045547485, "step": 20000}
{"episode_reward": 28.84729802696158, "episode": 21.0, "batch_reward": 0.08606698113679886, "critic_loss": 0.1665827391669154, "actor_loss": -11.723538276106119, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.44442319869995, "step": 21000}
{"episode_reward": 113.08806115537695, "episode": 22.0, "batch_reward": 0.08638723339140415, "critic_loss": 0.17696126470714807, "actor_loss": -9.964139473296703, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.94781255722046, "step": 22000}
{"episode_reward": 88.13007468813159, "episode": 23.0, "batch_reward": 0.08990014816820621, "critic_loss": 0.23398665796220303, "actor_loss": -10.974532268300653, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.614603519439697, "step": 23000}
{"episode_reward": 211.51055106784102, "episode": 24.0, "batch_reward": 0.09305339401960373, "critic_loss": 0.19747288344800473, "actor_loss": -11.168966658234597, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.853774309158325, "step": 24000}
{"episode_reward": 93.09008960716291, "episode": 25.0, "batch_reward": 0.09277824553102255, "critic_loss": 0.19527222687005996, "actor_loss": -10.878704679131507, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.90303611755371, "step": 25000}
{"episode_reward": 57.337329903154895, "episode": 26.0, "batch_reward": 0.09146135184168816, "critic_loss": 0.18787066262215377, "actor_loss": -10.90888228726387, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.04493522644043, "step": 26000}
{"episode_reward": 78.88201939570116, "episode": 27.0, "batch_reward": 0.0907893575541675, "critic_loss": 0.2174223484992981, "actor_loss": -10.994917860269547, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.892882347106934, "step": 27000}
{"episode_reward": 60.51314330066063, "episode": 28.0, "batch_reward": 0.09191835487633944, "critic_loss": 0.21818847692012786, "actor_loss": -10.587339032173157, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.5695641040802, "step": 28000}
{"episode_reward": 183.1182284674527, "episode": 29.0, "batch_reward": 0.09237171716615558, "critic_loss": 0.22841823565214872, "actor_loss": -10.974725713729859, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.205363988876343, "step": 29000}
{"episode_reward": 63.313294466114, "episode": 30.0, "batch_reward": 0.09511122691631317, "critic_loss": 0.2196855342015624, "actor_loss": -11.510049581050874, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.178377151489258, "step": 30000}
{"episode_reward": 227.744743054461, "episode": 31.0, "batch_reward": 0.09879341589286923, "critic_loss": 0.24519243223965168, "actor_loss": -11.613642680168152, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.36630177497864, "step": 31000}
{"episode_reward": 202.43721945670075, "episode": 32.0, "batch_reward": 0.09851466132700443, "critic_loss": 0.21592747996002434, "actor_loss": -11.522769865989686, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.787387371063232, "step": 32000}
{"episode_reward": 14.164041741887573, "episode": 33.0, "batch_reward": 0.09679952942952513, "critic_loss": 0.207592746026814, "actor_loss": -11.471871444702149, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.62419366836548, "step": 33000}
{"episode_reward": 53.81678037874926, "episode": 34.0, "batch_reward": 0.09755877285823226, "critic_loss": 0.2389074059948325, "actor_loss": -11.568183784484864, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.61877465248108, "step": 34000}
{"episode_reward": 134.62494016671707, "episode": 35.0, "batch_reward": 0.09699161882698536, "critic_loss": 0.21764435912668706, "actor_loss": -11.569040742874146, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.077797412872314, "step": 35000}
{"episode_reward": 109.58240553538865, "episode": 36.0, "batch_reward": 0.09902718634530902, "critic_loss": 0.20624279437959195, "actor_loss": -11.5591666431427, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.158551692962646, "step": 36000}
{"episode_reward": 246.34894815422876, "episode": 37.0, "batch_reward": 0.1029736655317247, "critic_loss": 0.20793950513750314, "actor_loss": -12.479684643745422, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.063031911849976, "step": 37000}
{"episode_reward": 155.1546253178698, "episode": 38.0, "batch_reward": 0.10409125991910696, "critic_loss": 0.20370794327557087, "actor_loss": -12.86015394973755, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.71603798866272, "step": 38000}
{"episode_reward": 156.7943550521195, "episode": 39.0, "batch_reward": 0.10533306657150387, "critic_loss": 0.1993081629499793, "actor_loss": -12.698684883117675, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.194865942001343, "step": 39000}
{"episode_reward": 146.10176483884902, "episode": 40.0, "batch_reward": 0.10568159176409245, "critic_loss": 0.19832890468090772, "actor_loss": -12.583959722518921, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.226893663406372, "step": 40000}
{"episode_reward": 114.18968674049, "episode": 41.0, "batch_reward": 0.10542984377592803, "critic_loss": 0.185252511523664, "actor_loss": -12.674399173736573, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.767592906951904, "step": 41000}
{"episode_reward": 143.90207712523946, "episode": 42.0, "batch_reward": 0.10726426297426224, "critic_loss": 0.18333739279210567, "actor_loss": -12.666616521835326, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.582332611083984, "step": 42000}
{"episode_reward": 92.18958681025119, "episode": 43.0, "batch_reward": 0.10653319930285216, "critic_loss": 0.18869115284830332, "actor_loss": -12.422163108825684, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.05424165725708, "step": 43000}
{"episode_reward": 100.52566892858057, "episode": 44.0, "batch_reward": 0.10758805187046527, "critic_loss": 0.21173295149952173, "actor_loss": -12.064761587142945, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.19537591934204, "step": 44000}
{"episode_reward": 191.72717438749098, "episode": 45.0, "batch_reward": 0.10850934536755084, "critic_loss": 0.2330883638560772, "actor_loss": -12.433504732131958, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.558470249176025, "step": 45000}
{"episode_reward": 121.37824361886939, "episode": 46.0, "batch_reward": 0.10931778075546027, "critic_loss": 0.22461305425316094, "actor_loss": -12.740391237258912, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.718278408050537, "step": 46000}
{"episode_reward": 193.78851075351704, "episode": 47.0, "batch_reward": 0.11018309238553047, "critic_loss": 0.21136266799271106, "actor_loss": -12.63683878326416, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.761330127716064, "step": 47000}
{"episode_reward": 68.54727574629428, "episode": 48.0, "batch_reward": 0.1094326987490058, "critic_loss": 0.22827693842351438, "actor_loss": -12.72239048576355, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.204472064971924, "step": 48000}
{"episode_reward": 119.38135924862763, "episode": 49.0, "batch_reward": 0.10915043392777443, "critic_loss": 0.24013791371881962, "actor_loss": -12.798978036880493, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.30772352218628, "step": 49000}
{"episode_reward": 41.05291405447708, "episode": 50.0, "batch_reward": 0.10805855366587638, "critic_loss": 0.25269455313682554, "actor_loss": -12.765534847259522, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.09840202331543, "step": 50000}
{"episode_reward": 82.27889549487927, "episode": 51.0, "batch_reward": 0.10900456331670284, "critic_loss": 0.2564288449808955, "actor_loss": -13.04391668510437, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.67117714881897, "step": 51000}
{"episode_reward": 210.82503743757812, "episode": 52.0, "batch_reward": 0.10932495444267988, "critic_loss": 0.2595471390709281, "actor_loss": -13.23697301864624, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.835993766784668, "step": 52000}
{"episode_reward": 52.537348897982184, "episode": 53.0, "batch_reward": 0.1087216767668724, "critic_loss": 0.29303654248267413, "actor_loss": -13.080468402862548, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.291409492492676, "step": 53000}
{"episode_reward": 81.81659847409244, "episode": 54.0, "batch_reward": 0.10957530874758958, "critic_loss": 0.30858494678884746, "actor_loss": -13.403646398544312, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.130353212356567, "step": 54000}
{"episode_reward": 292.45961053057374, "episode": 55.0, "batch_reward": 0.11133540827035904, "critic_loss": 0.3326298053115606, "actor_loss": -13.76893186187744, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.96066975593567, "step": 55000}
{"episode_reward": 68.66938146754845, "episode": 56.0, "batch_reward": 0.11001721011847257, "critic_loss": 0.3414501280412078, "actor_loss": -13.838136283874512, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.689383506774902, "step": 56000}
{"episode_reward": 74.59228538581938, "episode": 57.0, "batch_reward": 0.1102021222859621, "critic_loss": 0.3769427629262209, "actor_loss": -13.923530836105346, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.21223783493042, "step": 57000}
{"episode_reward": 85.22058314205694, "episode": 58.0, "batch_reward": 0.11051816336810588, "critic_loss": 0.3801189265549183, "actor_loss": -14.166683708190918, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.344815015792847, "step": 58000}
{"episode_reward": 218.60361331321147, "episode": 59.0, "batch_reward": 0.11140985560417176, "critic_loss": 0.38074848702549935, "actor_loss": -14.437329067230225, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.51484775543213, "step": 59000}
{"episode_reward": 115.86199005865046, "episode": 60.0, "batch_reward": 0.11300285856425762, "critic_loss": 0.3805757886171341, "actor_loss": -14.619966033935548, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.2404305934906, "step": 60000}
{"episode_reward": 251.93596726146185, "episode": 61.0, "batch_reward": 0.11396206104755402, "critic_loss": 0.4236012487113476, "actor_loss": -14.80581415939331, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.705097913742065, "step": 61000}
{"episode_reward": 78.94127734620466, "episode": 62.0, "batch_reward": 0.11448003742843867, "critic_loss": 0.4404744174107909, "actor_loss": -14.92494832801819, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.989441633224487, "step": 62000}
{"episode_reward": 180.7570765286353, "episode": 63.0, "batch_reward": 0.11390443550050258, "critic_loss": 0.41121344050765035, "actor_loss": -15.049768077850342, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.90611958503723, "step": 63000}
{"episode_reward": 62.47055634052391, "episode": 64.0, "batch_reward": 0.11489188316464424, "critic_loss": 0.4795155975520611, "actor_loss": -15.243017997741699, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.32041096687317, "step": 64000}
{"episode_reward": 304.14019745499667, "episode": 65.0, "batch_reward": 0.11731534367799759, "critic_loss": 0.48613367706537247, "actor_loss": -15.522776430130005, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.45458960533142, "step": 65000}
{"episode_reward": 264.7482800547143, "episode": 66.0, "batch_reward": 0.11977878246456385, "critic_loss": 0.4504026095867157, "actor_loss": -15.943966981887817, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.442748308181763, "step": 66000}
{"episode_reward": 196.66373376845897, "episode": 67.0, "batch_reward": 0.11994591756910086, "critic_loss": 0.4306671356409788, "actor_loss": -15.922328733444214, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.407491445541382, "step": 67000}
{"episode_reward": 60.73729099145363, "episode": 68.0, "batch_reward": 0.12028559259325265, "critic_loss": 0.4277065151631832, "actor_loss": -16.098879920959472, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.41159749031067, "step": 68000}
{"episode_reward": 342.0845734219164, "episode": 69.0, "batch_reward": 0.12373655612766743, "critic_loss": 0.5095779219120741, "actor_loss": -16.495332481384278, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.715993642807007, "step": 69000}
{"episode_reward": 287.727634516874, "episode": 70.0, "batch_reward": 0.12666686506569386, "critic_loss": 0.5256641878783703, "actor_loss": -16.75020785140991, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.30086588859558, "step": 70000}
{"episode_reward": 384.7374280194007, "episode": 71.0, "batch_reward": 0.12913459894806148, "critic_loss": 0.47737940569221976, "actor_loss": -16.92187992286682, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.13429236412048, "step": 71000}
{"episode_reward": 317.3936743644556, "episode": 72.0, "batch_reward": 0.131162479005754, "critic_loss": 0.4744709850102663, "actor_loss": -17.12192670059204, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.918872594833374, "step": 72000}
{"episode_reward": 197.1214242844351, "episode": 73.0, "batch_reward": 0.13287839096784593, "critic_loss": 0.46957216487824915, "actor_loss": -17.268353942871094, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.980353593826294, "step": 73000}
{"episode_reward": 186.52565827725772, "episode": 74.0, "batch_reward": 0.13321625308692456, "critic_loss": 0.4112733409702778, "actor_loss": -17.252316513061523, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.584824562072754, "step": 74000}
{"episode_reward": 116.83970940267926, "episode": 75.0, "batch_reward": 0.1331423981934786, "critic_loss": 0.44391858315467836, "actor_loss": -17.29517052078247, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.65551495552063, "step": 75000}
{"episode_reward": 223.05984302904037, "episode": 76.0, "batch_reward": 0.13547375728935004, "critic_loss": 0.45432065434753893, "actor_loss": -17.455608263015748, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.152782201766968, "step": 76000}
{"episode_reward": 296.07077468899365, "episode": 77.0, "batch_reward": 0.137687216155231, "critic_loss": 0.47217998138070105, "actor_loss": -17.711100465774535, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.889955282211304, "step": 77000}
{"episode_reward": 386.69795846084565, "episode": 78.0, "batch_reward": 0.1395995290800929, "critic_loss": 0.4714770753234625, "actor_loss": -17.83841303253174, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.49220895767212, "step": 78000}
{"episode_reward": 124.26542801922142, "episode": 79.0, "batch_reward": 0.14050280674546958, "critic_loss": 0.4188563373535871, "actor_loss": -17.924930692672728, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.143356800079346, "step": 79000}
{"episode_reward": 197.36938965301198, "episode": 80.0, "batch_reward": 0.14037580661475657, "critic_loss": 0.4128875605612993, "actor_loss": -17.93450231361389, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.504022359848022, "step": 80000}
{"episode_reward": 249.13923558627704, "episode": 81.0, "batch_reward": 0.1411043618619442, "critic_loss": 0.45784244281053543, "actor_loss": -17.964929502487184, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.38659906387329, "step": 81000}
{"episode_reward": 99.54996152550956, "episode": 82.0, "batch_reward": 0.14135789903253318, "critic_loss": 0.41447801285982133, "actor_loss": -18.01080616760254, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.754901885986328, "step": 82000}
{"episode_reward": 349.112837562684, "episode": 83.0, "batch_reward": 0.14343723256886004, "critic_loss": 0.46244830203056336, "actor_loss": -18.126869930267333, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.58977961540222, "step": 83000}
{"episode_reward": 37.59031421538984, "episode": 84.0, "batch_reward": 0.14276761704683305, "critic_loss": 0.40795398645102976, "actor_loss": -18.07400683403015, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.251214504241943, "step": 84000}
{"episode_reward": 193.7121126365546, "episode": 85.0, "batch_reward": 0.14369966384768487, "critic_loss": 0.3949245114028454, "actor_loss": -18.126118780136107, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.338847160339355, "step": 85000}
{"episode_reward": 439.91965392350096, "episode": 86.0, "batch_reward": 0.14651568191498518, "critic_loss": 0.4097027839571238, "actor_loss": -18.417177448272707, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.31508159637451, "step": 86000}
{"episode_reward": 191.72770064572833, "episode": 87.0, "batch_reward": 0.14679846731573343, "critic_loss": 0.4050991542339325, "actor_loss": -18.386302097320556, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.1819007396698, "step": 87000}
{"episode_reward": 100.36909115121098, "episode": 88.0, "batch_reward": 0.14698986028134822, "critic_loss": 0.4156170558556914, "actor_loss": -18.29888208770752, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.7536141872406, "step": 88000}
{"episode_reward": 352.032942756787, "episode": 89.0, "batch_reward": 0.1478981576859951, "critic_loss": 0.3451352573484182, "actor_loss": -18.306582164764404, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.54424738883972, "step": 89000}
{"episode_reward": 50.762882119735195, "episode": 90.0, "batch_reward": 0.14866885608434677, "critic_loss": 0.37778417678177356, "actor_loss": -18.30352642440796, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.822049379348755, "step": 90000}
{"episode_reward": 244.1642336072835, "episode": 91.0, "batch_reward": 0.14922086918354036, "critic_loss": 0.4044016718119383, "actor_loss": -18.31466053390503, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.47942233085632, "step": 91000}
{"episode_reward": 143.40574522083645, "episode": 92.0, "batch_reward": 0.14846377918124198, "critic_loss": 0.3613631348311901, "actor_loss": -18.16717183303833, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.10787796974182, "step": 92000}
{"episode_reward": 106.22153490857303, "episode": 93.0, "batch_reward": 0.1493502269759774, "critic_loss": 0.3819908628463745, "actor_loss": -18.204503335952758, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.25774598121643, "step": 93000}
{"episode_reward": 441.7114284650633, "episode": 94.0, "batch_reward": 0.15196858881413935, "critic_loss": 0.39725862072408197, "actor_loss": -18.51670484352112, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.275489568710327, "step": 94000}
{"episode_reward": 452.3338609430198, "episode": 95.0, "batch_reward": 0.15441713504493237, "critic_loss": 0.41371500773727893, "actor_loss": -18.6166095161438, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.291298151016235, "step": 95000}
{"episode_reward": 232.34527099948036, "episode": 96.0, "batch_reward": 0.15599859857559203, "critic_loss": 0.40890381126105785, "actor_loss": -18.58552431297302, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.423771142959595, "step": 96000}
{"episode_reward": 261.6493639741858, "episode": 97.0, "batch_reward": 0.15745420791953801, "critic_loss": 0.4006463762074709, "actor_loss": -18.677618242263794, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.292863607406616, "step": 97000}
{"episode_reward": 274.1400730436771, "episode": 98.0, "batch_reward": 0.15772595217078925, "critic_loss": 0.3772170988693833, "actor_loss": -18.67606250190735, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.05845832824707, "step": 98000}
{"episode_reward": 474.4934699665244, "episode": 99.0, "batch_reward": 0.1615706692636013, "critic_loss": 0.3656291860193014, "actor_loss": -18.987626319885255, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.11958885192871, "step": 99000}
{"episode_reward": 350.3395246073194, "episode": 100.0, "batch_reward": 0.16209349849820137, "critic_loss": 0.39012517175078393, "actor_loss": -19.07393959236145, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.202885389328003, "step": 100000}
{"episode_reward": 76.39224188162008, "episode": 101.0, "batch_reward": 0.16282965926080942, "critic_loss": 0.3660550662577152, "actor_loss": -19.108675092697144, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.792704820632935, "step": 101000}
{"episode_reward": 343.00147777262646, "episode": 102.0, "batch_reward": 0.1648627444282174, "critic_loss": 0.39972383305430415, "actor_loss": -19.22806499862671, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.16740369796753, "step": 102000}
{"episode_reward": 313.41191660405883, "episode": 103.0, "batch_reward": 0.1648842127993703, "critic_loss": 0.3467672021687031, "actor_loss": -19.251348384857177, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.65192174911499, "step": 103000}
{"episode_reward": 91.0525887347718, "episode": 104.0, "batch_reward": 0.16580793329328297, "critic_loss": 0.38994704115390777, "actor_loss": -19.26476738166809, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.321810483932495, "step": 104000}
{"episode_reward": 333.51429233271114, "episode": 105.0, "batch_reward": 0.16696802451461554, "critic_loss": 0.39290278097987175, "actor_loss": -19.314729156494142, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.425416231155396, "step": 105000}
{"episode_reward": 423.5909137686072, "episode": 106.0, "batch_reward": 0.16804525857418776, "critic_loss": 0.36629360483586787, "actor_loss": -19.352378133773804, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.117836475372314, "step": 106000}
{"episode_reward": 196.40322385040537, "episode": 107.0, "batch_reward": 0.1694416132196784, "critic_loss": 0.37746463502943517, "actor_loss": -19.4606907081604, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.11152148246765, "step": 107000}
{"episode_reward": 353.46628226580134, "episode": 108.0, "batch_reward": 0.17098838541656733, "critic_loss": 0.3601315162628889, "actor_loss": -19.50335136795044, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.311691761016846, "step": 108000}
{"episode_reward": 183.52010087908164, "episode": 109.0, "batch_reward": 0.1720097366720438, "critic_loss": 0.352241486415267, "actor_loss": -19.590679878234862, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.26488971710205, "step": 109000}
{"episode_reward": 420.7513489971759, "episode": 110.0, "batch_reward": 0.1740248178988695, "critic_loss": 0.35471780405938624, "actor_loss": -19.676878692626953, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.936975240707397, "step": 110000}
{"episode_reward": 447.15160775088174, "episode": 111.0, "batch_reward": 0.1748740748167038, "critic_loss": 0.348204040363431, "actor_loss": -19.77889891433716, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.42515444755554, "step": 111000}
{"episode_reward": 177.56159301162876, "episode": 112.0, "batch_reward": 0.17564019306004047, "critic_loss": 0.3518206001222134, "actor_loss": -19.69996852684021, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.144967079162598, "step": 112000}
{"episode_reward": 381.6149707896462, "episode": 113.0, "batch_reward": 0.17884857822954656, "critic_loss": 0.3585905150398612, "actor_loss": -19.95888921546936, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.321701765060425, "step": 113000}
{"episode_reward": 370.4788648492889, "episode": 114.0, "batch_reward": 0.17964104089140892, "critic_loss": 0.3643900700956583, "actor_loss": -19.978229293823244, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.75307273864746, "step": 114000}
{"episode_reward": 368.39580829014824, "episode": 115.0, "batch_reward": 0.18150740049034358, "critic_loss": 0.35050236704945564, "actor_loss": -19.985385091781616, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.020970106124878, "step": 115000}
{"episode_reward": 301.91920282220946, "episode": 116.0, "batch_reward": 0.1825878409817815, "critic_loss": 0.3479696109741926, "actor_loss": -19.984071767807006, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.957123517990112, "step": 116000}
{"episode_reward": 234.8207470929826, "episode": 117.0, "batch_reward": 0.18286448416113854, "critic_loss": 0.3725645973831415, "actor_loss": -20.030382484436036, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.841269493103027, "step": 117000}
{"episode_reward": 382.6303907879934, "episode": 118.0, "batch_reward": 0.18451477597653865, "critic_loss": 0.3695591653734446, "actor_loss": -20.19974062728882, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.287267923355103, "step": 118000}
{"episode_reward": 296.0019889660242, "episode": 119.0, "batch_reward": 0.186027140468359, "critic_loss": 0.37726849879324437, "actor_loss": -20.28766750717163, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.04807758331299, "step": 119000}
{"episode_reward": 508.98405092213426, "episode": 120.0, "batch_reward": 0.18740785002708435, "critic_loss": 0.3442170113027096, "actor_loss": -20.367904541015626, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.078672409057617, "step": 120000}
{"episode_reward": 391.0742417637887, "episode": 121.0, "batch_reward": 0.1896095883846283, "critic_loss": 0.3392328713387251, "actor_loss": -20.40397661972046, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.78264284133911, "step": 121000}
{"episode_reward": 405.96755342299497, "episode": 122.0, "batch_reward": 0.1918967211097479, "critic_loss": 0.3372260951548815, "actor_loss": -20.54363090133667, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.086119651794434, "step": 122000}
{"episode_reward": 491.7797454165079, "episode": 123.0, "batch_reward": 0.19449923698604107, "critic_loss": 0.3524485727548599, "actor_loss": -20.78098526763916, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.544681310653687, "step": 123000}
{"episode_reward": 418.19645155530145, "episode": 124.0, "batch_reward": 0.19655832193791867, "critic_loss": 0.3637788372784853, "actor_loss": -21.067689807891846, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.849134922027588, "step": 124000}
{"episode_reward": 499.7643394629045, "episode": 125.0, "batch_reward": 0.19831046926975252, "critic_loss": 0.3807373514175415, "actor_loss": -21.342447498321533, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.37941026687622, "step": 125000}
{"episode_reward": 472.3616456858157, "episode": 126.0, "batch_reward": 0.20069246485829353, "critic_loss": 0.36375767205655574, "actor_loss": -21.58953638458252, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.55800175666809, "step": 126000}
{"episode_reward": 383.25913429207924, "episode": 127.0, "batch_reward": 0.20191532036662102, "critic_loss": 0.37029277998209, "actor_loss": -21.553107189178466, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.25791573524475, "step": 127000}
{"episode_reward": 550.428773688516, "episode": 128.0, "batch_reward": 0.20400783856213092, "critic_loss": 0.3469208841025829, "actor_loss": -21.76548997116089, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.016241550445557, "step": 128000}
{"episode_reward": 173.9839938242616, "episode": 129.0, "batch_reward": 0.20395621266961098, "critic_loss": 0.3332098076790571, "actor_loss": -21.769757480621337, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.02706241607666, "step": 129000}
{"episode_reward": 422.38858469333263, "episode": 130.0, "batch_reward": 0.2048435508310795, "critic_loss": 0.3291327072381973, "actor_loss": -21.73555157852173, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.903696298599243, "step": 130000}
{"episode_reward": 126.7977267275658, "episode": 131.0, "batch_reward": 0.20521749663352967, "critic_loss": 0.3428074423745274, "actor_loss": -21.703432937622072, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.612337589263916, "step": 131000}
{"episode_reward": 171.69164462530034, "episode": 132.0, "batch_reward": 0.20525218264758588, "critic_loss": 0.3551907816976309, "actor_loss": -21.683824954986573, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.992743492126465, "step": 132000}
{"episode_reward": 448.4639287911585, "episode": 133.0, "batch_reward": 0.2065742027312517, "critic_loss": 0.3641946525126696, "actor_loss": -21.812001472473145, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.091678619384766, "step": 133000}
{"episode_reward": 156.94078746272174, "episode": 134.0, "batch_reward": 0.20625798252224922, "critic_loss": 0.35195866049826147, "actor_loss": -21.68246488571167, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.957271099090576, "step": 134000}
{"episode_reward": 469.42911609713786, "episode": 135.0, "batch_reward": 0.20762521366775036, "critic_loss": 0.3306433584839106, "actor_loss": -21.799853649139404, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.554094552993774, "step": 135000}
{"episode_reward": 404.1546068870863, "episode": 136.0, "batch_reward": 0.20962451787292957, "critic_loss": 0.33448458978533746, "actor_loss": -22.025570377349855, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.150799036026, "step": 136000}
{"episode_reward": 85.2314938479719, "episode": 137.0, "batch_reward": 0.2097410446703434, "critic_loss": 0.33944099509716036, "actor_loss": -21.967423637390137, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.2167649269104, "step": 137000}
{"episode_reward": 477.0722974066425, "episode": 138.0, "batch_reward": 0.21117336510121823, "critic_loss": 0.37006978956609965, "actor_loss": -22.023091957092284, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.22236680984497, "step": 138000}
{"episode_reward": 496.4290304272022, "episode": 139.0, "batch_reward": 0.21449222569167614, "critic_loss": 0.3396760759055614, "actor_loss": -22.42875244140625, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.451133251190186, "step": 139000}
{"episode_reward": 519.023373948349, "episode": 140.0, "batch_reward": 0.21532458405196667, "critic_loss": 0.3448688104748726, "actor_loss": -22.43132001876831, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.274982213974, "step": 140000}
{"episode_reward": 492.4743076580134, "episode": 141.0, "batch_reward": 0.2184098944067955, "critic_loss": 0.34981547905504706, "actor_loss": -22.651070266723632, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.0105619430542, "step": 141000}
{"episode_reward": 536.164979407311, "episode": 142.0, "batch_reward": 0.21940884967148305, "critic_loss": 0.34491349586844444, "actor_loss": -22.71304919052124, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.357622146606445, "step": 142000}
{"episode_reward": 471.24493575154327, "episode": 143.0, "batch_reward": 0.22182227799296378, "critic_loss": 0.33207280561327934, "actor_loss": -23.05079301071167, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.938939094543457, "step": 143000}
{"episode_reward": 408.98477426122076, "episode": 144.0, "batch_reward": 0.22293712551891803, "critic_loss": 0.3545435259193182, "actor_loss": -22.90124426651001, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.227519750595093, "step": 144000}
{"episode_reward": 271.1953823273593, "episode": 145.0, "batch_reward": 0.2215394141972065, "critic_loss": 0.3481784521341324, "actor_loss": -22.982245540618898, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.696765899658203, "step": 145000}
{"episode_reward": 468.90353417378446, "episode": 146.0, "batch_reward": 0.2243808491230011, "critic_loss": 0.3390423120856285, "actor_loss": -23.14569649887085, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.363205194473267, "step": 146000}
{"episode_reward": 502.2289142939885, "episode": 147.0, "batch_reward": 0.22626189053058623, "critic_loss": 0.34701109351217746, "actor_loss": -23.288131172180176, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.515933990478516, "step": 147000}
{"episode_reward": 410.97657323915763, "episode": 148.0, "batch_reward": 0.22876336877048015, "critic_loss": 0.35333078584074973, "actor_loss": -23.46467677307129, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.356762409210205, "step": 148000}
{"episode_reward": 442.39643900428524, "episode": 149.0, "batch_reward": 0.23018658268451692, "critic_loss": 0.3449608974158764, "actor_loss": -23.54517977142334, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.936328887939453, "step": 149000}
{"episode_reward": 451.1372321162864, "episode": 150.0, "batch_reward": 0.23046974425017833, "critic_loss": 0.3467607074528933, "actor_loss": -23.55957534790039, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
