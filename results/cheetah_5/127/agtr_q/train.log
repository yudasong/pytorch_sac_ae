{"episode": 1.0, "duration": 23.104137182235718, "episode_reward": 4.859792814687425, "step": 1000}
{"episode": 2.0, "duration": 1.7474098205566406, "episode_reward": 550.1572824113056, "step": 2000}
{"episode": 3.0, "batch_reward": 0.26181504094588753, "actor_loss": -38.805010502125654, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 54.877561807632446, "episode_reward": 28.150404251304106, "step": 3000}
{"episode": 4.0, "batch_reward": 0.1754285626411438, "actor_loss": -34.81634437561035, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.658175706863403, "episode_reward": 62.512230809583386, "step": 4000}
{"episode": 5.0, "batch_reward": 0.15177871921658517, "actor_loss": -33.72678749084473, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.439985513687134, "episode_reward": 102.7179498383738, "step": 5000}
{"episode": 6.0, "batch_reward": 0.14782117771357298, "actor_loss": -33.367855484008786, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.624552488327026, "episode_reward": 150.1818191676862, "step": 6000}
{"episode": 7.0, "batch_reward": 0.14516732413321734, "actor_loss": -32.08425067520142, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.550519943237305, "episode_reward": 57.10599592935954, "step": 7000}
{"episode": 8.0, "batch_reward": 0.13620460294932127, "actor_loss": -29.98613037490845, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.56903886795044, "episode_reward": 97.74118812199978, "step": 8000}
{"episode": 9.0, "batch_reward": 0.13363764966279268, "actor_loss": -29.161907398223878, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.90291166305542, "episode_reward": 183.75079158250145, "step": 9000}
{"episode": 10.0, "batch_reward": 0.13568332473188638, "actor_loss": -24.723148334503176, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 3949.5052103996277, "episode_reward": 63.81751514466634, "step": 10000}
{"episode": 11.0, "batch_reward": 0.1381594065949321, "actor_loss": -24.23817181777954, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 34.470404624938965, "episode_reward": 240.12384588299128, "step": 11000}
{"episode": 12.0, "batch_reward": 0.1416711197644472, "actor_loss": -20.61688423538208, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 430.42394757270813, "episode_reward": 120.43751053210549, "step": 12000}
{"episode": 13.0, "batch_reward": 0.14080530912429096, "actor_loss": -20.01396933746338, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.93922758102417, "episode_reward": 145.43070831307506, "step": 13000}
{"episode": 14.0, "batch_reward": 0.14499580957740546, "actor_loss": -17.584501327514648, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 432.7370800971985, "episode_reward": 244.1130237991222, "step": 14000}
{"episode": 15.0, "batch_reward": 0.1514613126143813, "actor_loss": -17.605542543411254, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.767428874969482, "episode_reward": 249.15894481498253, "step": 15000}
{"episode": 16.0, "batch_reward": 0.15841650180518627, "actor_loss": -15.895819089889526, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 428.34021162986755, "episode_reward": 346.7929504888233, "step": 16000}
{"episode": 17.0, "batch_reward": 0.1628444150313735, "actor_loss": -16.238828536987306, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.039621829986572, "episode_reward": 74.05492117976385, "step": 17000}
{"episode": 18.0, "batch_reward": 0.1602108896970749, "actor_loss": -14.152877649307252, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 425.5534269809723, "episode_reward": 115.10538346296376, "step": 18000}
{"episode": 19.0, "batch_reward": 0.15767635320872067, "actor_loss": -13.850943937301636, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.890950202941895, "episode_reward": 94.46474419811932, "step": 19000}
{"episode": 20.0, "batch_reward": 0.15751849818974734, "actor_loss": -12.830310537338256, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 433.12748551368713, "episode_reward": 275.3423445524334, "step": 20000}
{"episode": 21.0, "batch_reward": 0.16277856820821762, "actor_loss": -13.074205617904664, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.79791069030762, "episode_reward": 217.30510508209989, "step": 21000}
{"episode": 22.0, "batch_reward": 0.1635953812599182, "actor_loss": -12.191156885147095, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 438.0566258430481, "episode_reward": 115.37121022497008, "step": 22000}
{"episode": 23.0, "batch_reward": 0.1650399245917797, "actor_loss": -12.263966356277466, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.959664344787598, "episode_reward": 303.6747194446934, "step": 23000}
{"episode": 24.0, "batch_reward": 0.16867620690912008, "actor_loss": -11.637125816345215, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 447.4487826824188, "episode_reward": 207.91220908009385, "step": 24000}
{"episode": 25.0, "batch_reward": 0.172801366917789, "actor_loss": -11.923575839996339, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.223018407821655, "episode_reward": 390.2394728069495, "step": 25000}
{"episode": 26.0, "batch_reward": 0.1791332238316536, "actor_loss": -11.42583723640442, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 429.2121093273163, "episode_reward": 176.35785146073695, "step": 26000}
{"episode": 27.0, "batch_reward": 0.17763095103204252, "actor_loss": -11.373782474517823, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.251653909683228, "episode_reward": 135.26761845198882, "step": 27000}
{"episode": 28.0, "batch_reward": 0.1782694875895977, "actor_loss": -11.484853402137757, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 421.4759602546692, "episode_reward": 377.1890458129098, "step": 28000}
{"episode": 29.0, "batch_reward": 0.18525248803198338, "actor_loss": -11.987368364334106, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.3836886882782, "episode_reward": 343.63828267860794, "step": 29000}
{"episode": 30.0, "batch_reward": 0.1899907676577568, "actor_loss": -11.534989820480346, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 411.18585181236267, "episode_reward": 336.7568604658573, "step": 30000}
{"episode": 31.0, "batch_reward": 0.19542369665205478, "actor_loss": -11.967845769882203, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.06572890281677, "episode_reward": 213.62638519591323, "step": 31000}
{"episode": 32.0, "batch_reward": 0.19677572365105153, "actor_loss": -12.230875709533692, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 420.24843287467957, "episode_reward": 411.2719670845132, "step": 32000}
{"episode": 33.0, "batch_reward": 0.20409833544492723, "actor_loss": -12.808599365234375, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.440839052200317, "episode_reward": 423.3220697715024, "step": 33000}
{"episode": 34.0, "batch_reward": 0.21028118996322154, "actor_loss": -13.558394504547119, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 429.45456647872925, "episode_reward": 444.1349479998067, "step": 34000}
{"episode": 35.0, "batch_reward": 0.2175312394350767, "actor_loss": -14.148365156173707, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.820757627487183, "episode_reward": 449.480792347267, "step": 35000}
{"episode": 36.0, "batch_reward": 0.22417423179745674, "actor_loss": -15.156575929641724, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 415.29089188575745, "episode_reward": 490.4056290825033, "step": 36000}
{"episode": 37.0, "batch_reward": 0.23029358449578285, "actor_loss": -15.563417793273926, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.46759295463562, "episode_reward": 304.4111891664616, "step": 37000}
{"episode": 38.0, "batch_reward": 0.23227119246125222, "actor_loss": -15.661174057006836, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 429.6885120868683, "episode_reward": 414.71230067411, "step": 38000}
{"episode": 39.0, "batch_reward": 0.2371418612450361, "actor_loss": -15.841960287094116, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.717358827590942, "episode_reward": 237.01738495380775, "step": 39000}
{"episode": 40.0, "batch_reward": 0.23939404660463334, "actor_loss": -15.79044303894043, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 413.14369559288025, "episode_reward": 517.2933819523425, "step": 40000}
{"episode": 41.0, "batch_reward": 0.24465981771051884, "actor_loss": -16.214697662353515, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.16724419593811, "episode_reward": 294.2769943496143, "step": 41000}
{"episode": 42.0, "batch_reward": 0.2457826291769743, "actor_loss": -16.278075325012207, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 408.93420696258545, "episode_reward": 488.6833453163634, "step": 42000}
{"episode": 43.0, "batch_reward": 0.24946192871034145, "actor_loss": -16.60689800643921, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.651681661605835, "episode_reward": 173.5469010296158, "step": 43000}
{"episode": 44.0, "batch_reward": 0.25070236638188365, "actor_loss": -16.816956830978395, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 415.15922498703003, "episode_reward": 422.1655095734286, "step": 44000}
{"episode": 45.0, "batch_reward": 0.2546817260831594, "actor_loss": -17.061693794250488, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.09568166732788, "episode_reward": 388.7509643608483, "step": 45000}
{"episode": 46.0, "batch_reward": 0.25579874344170095, "actor_loss": -17.24694298171997, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 412.6463849544525, "episode_reward": 359.0953494788312, "step": 46000}
{"episode": 47.0, "batch_reward": 0.25564901550114155, "actor_loss": -17.149592864990236, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.44723391532898, "episode_reward": 61.98185522208132, "step": 47000}
{"episode": 48.0, "batch_reward": 0.25412770080566405, "actor_loss": -16.983491428375245, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 410.2007405757904, "episode_reward": 442.6507581384193, "step": 48000}
{"episode": 49.0, "batch_reward": 0.25895346404612063, "actor_loss": -17.41626630592346, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.647263050079346, "episode_reward": 528.7272179567282, "step": 49000}
{"episode": 50.0, "batch_reward": 0.2653221748620272, "actor_loss": -17.578684125900267, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 427.80958557128906, "episode_reward": 522.9907195048524, "step": 50000}
{"episode": 51.0, "batch_reward": 0.26978107529878614, "actor_loss": -17.869461874008177, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 31.980048894882202, "episode_reward": 475.53452135441546, "step": 51000}
{"episode": 52.0, "batch_reward": 0.2734002460837364, "actor_loss": -18.25470860671997, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 432.8494508266449, "episode_reward": 473.5231010083891, "step": 52000}
{"episode": 53.0, "batch_reward": 0.2762266034781933, "actor_loss": -18.57226268577576, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.801541090011597, "episode_reward": 456.4059357379, "step": 53000}
{"episode": 54.0, "batch_reward": 0.28019266040623186, "actor_loss": -19.247202325820922, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 420.5954945087433, "episode_reward": 480.7155996986808, "step": 54000}
{"episode": 55.0, "batch_reward": 0.2835327958166599, "actor_loss": -19.514784845352175, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.10813808441162, "episode_reward": 461.99800714581926, "step": 55000}
{"episode": 56.0, "batch_reward": 0.2859609910845757, "actor_loss": -19.495158138275148, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 434.5164167881012, "episode_reward": 245.06685734571542, "step": 56000}
{"episode": 57.0, "batch_reward": 0.2866171796917915, "actor_loss": -19.358057439804078, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.127557039260864, "episode_reward": 468.38372876675135, "step": 57000}
{"episode": 58.0, "batch_reward": 0.2894419020414352, "actor_loss": -19.17271786689758, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 428.1416082382202, "episode_reward": 438.0931537989697, "step": 58000}
{"episode": 59.0, "batch_reward": 0.29204454271495345, "actor_loss": -19.420525430679323, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.751795530319214, "episode_reward": 485.04008285016334, "step": 59000}
{"episode": 60.0, "batch_reward": 0.29465763963758945, "actor_loss": -19.440061233520506, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 430.57424235343933, "episode_reward": 188.17043687152693, "step": 60000}
{"episode": 61.0, "batch_reward": 0.2936891601383686, "actor_loss": -19.39258437538147, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 33.5531861782074, "episode_reward": 480.87092529577694, "step": 61000}
{"episode": 62.0, "batch_reward": 0.29302960334718225, "actor_loss": -19.136852081298827, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 427.19530177116394, "episode_reward": 27.421811801058315, "step": 62000}
{"episode": 63.0, "batch_reward": 0.2921952082067728, "actor_loss": -19.203759771347045, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.817192554473877, "episode_reward": 519.9748368723458, "step": 63000}
{"episode": 64.0, "batch_reward": 0.295471151933074, "actor_loss": -19.34353200531006, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 427.7314803600311, "episode_reward": 262.94090487063477, "step": 64000}
{"episode": 65.0, "batch_reward": 0.29551381775736807, "actor_loss": -19.42902982711792, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.066067695617676, "episode_reward": 452.56733464397956, "step": 65000}
{"episode": 66.0, "batch_reward": 0.29816336899995804, "actor_loss": -19.437967931747437, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 429.2808623313904, "episode_reward": 490.26740071736094, "step": 66000}
{"episode": 67.0, "batch_reward": 0.29992453460395335, "actor_loss": -19.740787712097166, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.96667194366455, "episode_reward": 363.38058732681503, "step": 67000}
{"episode": 68.0, "batch_reward": 0.3026891822218895, "actor_loss": -20.091158296585082, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 428.07252311706543, "episode_reward": 510.0081482848144, "step": 68000}
{"episode": 69.0, "batch_reward": 0.3046623862981796, "actor_loss": -20.09133703994751, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.82335901260376, "episode_reward": 243.99618446569457, "step": 69000}
{"episode": 70.0, "batch_reward": 0.303395023137331, "actor_loss": -20.047002977371214, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 428.53080439567566, "episode_reward": 449.2411086247245, "step": 70000}
{"episode": 71.0, "batch_reward": 0.3033935503512621, "actor_loss": -19.939413875579834, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.68483352661133, "episode_reward": 41.47578448558979, "step": 71000}
{"episode": 72.0, "batch_reward": 0.3002166328728199, "actor_loss": -19.61965898132324, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 423.8363811969757, "episode_reward": 58.041837842181295, "step": 72000}
{"episode": 73.0, "batch_reward": 0.29582525144517424, "actor_loss": -19.32632476043701, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.182212829589844, "episode_reward": 77.72976213187313, "step": 73000}
{"episode": 74.0, "batch_reward": 0.2956880185306072, "actor_loss": -19.28127984046936, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 431.09590768814087, "episode_reward": 494.61281511493416, "step": 74000}
{"episode": 75.0, "batch_reward": 0.2971654680520296, "actor_loss": -19.515884075164795, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.362956523895264, "episode_reward": 66.1384575900867, "step": 75000}
{"episode": 76.0, "batch_reward": 0.29624954803287984, "actor_loss": -19.497600347518922, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 424.6203362941742, "episode_reward": 441.6299421509973, "step": 76000}
{"episode": 77.0, "batch_reward": 0.29789999248087407, "actor_loss": -19.684381471633912, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.380593061447144, "episode_reward": 532.1117112358722, "step": 77000}
{"episode": 78.0, "batch_reward": 0.29958838154375556, "actor_loss": -19.45945354270935, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 432.69566822052, "episode_reward": 481.772462295503, "step": 78000}
{"episode": 79.0, "batch_reward": 0.3006965861618519, "actor_loss": -19.59088263511658, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.654062986373901, "episode_reward": 73.583941199345, "step": 79000}
{"episode": 80.0, "batch_reward": 0.30000183951854703, "actor_loss": -19.72403525352478, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 429.20822262763977, "episode_reward": 480.91435824527275, "step": 80000}
{"episode": 81.0, "batch_reward": 0.30258183741569517, "actor_loss": -20.018121419906617, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 38.04416871070862, "episode_reward": 561.8245547245472, "step": 81000}
{"episode": 82.0, "batch_reward": 0.3063788305222988, "actor_loss": -20.297122245788575, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 421.7917597293854, "episode_reward": 376.8919284210162, "step": 82000}
{"episode": 83.0, "batch_reward": 0.3044112008959055, "actor_loss": -20.156085157394408, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.68952441215515, "episode_reward": 416.2389672102009, "step": 83000}
{"episode": 84.0, "batch_reward": 0.3066812883466482, "actor_loss": -20.400811542510986, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 433.55430912971497, "episode_reward": 124.99821821378225, "step": 84000}
{"episode": 85.0, "batch_reward": 0.3052992016971111, "actor_loss": -20.270302307128905, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.70992946624756, "episode_reward": 428.8230781114917, "step": 85000}
{"episode": 86.0, "batch_reward": 0.3072288423776627, "actor_loss": -20.865474201202392, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 427.79892683029175, "episode_reward": 535.4210961124126, "step": 86000}
{"episode": 87.0, "batch_reward": 0.3091168987452984, "actor_loss": -20.963228801727293, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.257564544677734, "episode_reward": 348.80680580992083, "step": 87000}
{"episode": 88.0, "batch_reward": 0.31091457802057265, "actor_loss": -21.598952590942382, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 430.04141497612, "episode_reward": 489.9094095563936, "step": 88000}
{"episode": 89.0, "batch_reward": 0.31066746260225775, "actor_loss": -21.47690001678467, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.780130624771118, "episode_reward": 115.61131616263884, "step": 89000}
{"episode": 90.0, "batch_reward": 0.30948661249876025, "actor_loss": -21.775172576904296, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 429.99362230300903, "episode_reward": 495.7966480814741, "step": 90000}
{"episode": 91.0, "batch_reward": 0.31216152396798136, "actor_loss": -22.05084469985962, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 33.01251292228699, "episode_reward": 327.02424513244085, "step": 91000}
{"episode": 92.0, "batch_reward": 0.3115398551374674, "actor_loss": -21.56687956237793, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 410.3403823375702, "episode_reward": 315.82062302157294, "step": 92000}
{"episode": 93.0, "batch_reward": 0.3113567560762167, "actor_loss": -21.628237976074217, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.451645135879517, "episode_reward": 515.3961792105565, "step": 93000}
{"episode": 94.0, "batch_reward": 0.31430187770724294, "actor_loss": -22.115950294494628, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 438.6266918182373, "episode_reward": 475.33268338119075, "step": 94000}
{"episode": 95.0, "batch_reward": 0.3158632948696613, "actor_loss": -22.25784428024292, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.26783800125122, "episode_reward": 537.457365070325, "step": 95000}
{"episode": 96.0, "batch_reward": 0.3186821214556694, "actor_loss": -22.007835762023927, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 427.5672800540924, "episode_reward": 465.1054304590463, "step": 96000}
{"episode": 97.0, "batch_reward": 0.32029014331102373, "actor_loss": -22.16469203567505, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.148667812347412, "episode_reward": 545.229046814859, "step": 97000}
{"episode": 98.0, "batch_reward": 0.32200563269853594, "actor_loss": -22.184167644500732, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 430.9952783584595, "episode_reward": 520.3950904845776, "step": 98000}
{"episode": 99.0, "batch_reward": 0.32307642510533335, "actor_loss": -22.20288423538208, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.253787517547607, "episode_reward": 474.280889684287, "step": 99000}
{"episode": 100.0, "batch_reward": 0.32636322170495985, "actor_loss": -22.66602349472046, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 429.3338406085968, "episode_reward": 493.67282724571993, "step": 100000}
{"episode": 101.0, "batch_reward": 0.3275716022849083, "actor_loss": -22.70572057723999, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 34.74330496788025, "episode_reward": 481.96032763710974, "step": 101000}
{"episode": 102.0, "batch_reward": 0.32853956109285354, "actor_loss": -22.494519973754883, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 425.302885055542, "episode_reward": 511.12955768074784, "step": 102000}
{"episode": 103.0, "batch_reward": 0.3295289784669876, "actor_loss": -22.745906356811524, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.681965351104736, "episode_reward": 568.0340147206023, "step": 103000}
{"episode": 104.0, "batch_reward": 0.33294430565834043, "actor_loss": -23.531498424530028, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 432.43835043907166, "episode_reward": 508.0548785431625, "step": 104000}
{"episode": 105.0, "batch_reward": 0.3340287608206272, "actor_loss": -23.611534385681153, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.63811206817627, "episode_reward": 525.4193863059475, "step": 105000}
{"episode": 106.0, "batch_reward": 0.33531534919142725, "actor_loss": -23.76344327545166, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 429.75903367996216, "episode_reward": 230.95337811956077, "step": 106000}
{"episode": 107.0, "batch_reward": 0.33639879018068314, "actor_loss": -23.77131642150879, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.20158052444458, "episode_reward": 483.2728860348677, "step": 107000}
{"episode": 108.0, "batch_reward": 0.3370133056342602, "actor_loss": -23.97180810546875, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 424.57150530815125, "episode_reward": 436.44261348425243, "step": 108000}
{"episode": 109.0, "batch_reward": 0.3371551967561245, "actor_loss": -24.24484931945801, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.70273733139038, "episode_reward": 419.9976418381953, "step": 109000}
{"episode": 110.0, "batch_reward": 0.3386895977258682, "actor_loss": -23.94003567504883, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 414.4650137424469, "episode_reward": 523.4705775102562, "step": 110000}
{"episode": 111.0, "batch_reward": 0.3398159072697163, "actor_loss": -23.8554009475708, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 33.74333214759827, "episode_reward": 472.41012357282597, "step": 111000}
{"episode": 112.0, "batch_reward": 0.3411495341360569, "actor_loss": -24.182973308563234, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 414.5160105228424, "episode_reward": 533.3524527653179, "step": 112000}
{"episode": 113.0, "batch_reward": 0.3424607988297939, "actor_loss": -24.36105696487427, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.475045204162598, "episode_reward": 467.67480546222777, "step": 113000}
{"episode": 114.0, "batch_reward": 0.3446571777760983, "actor_loss": -24.826965068817138, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 427.82619738578796, "episode_reward": 536.2055864235627, "step": 114000}
{"episode": 115.0, "batch_reward": 0.34598526856303213, "actor_loss": -24.946818531036378, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.59418272972107, "episode_reward": 574.7188973823862, "step": 115000}
{"episode": 116.0, "batch_reward": 0.34833381563425064, "actor_loss": -25.270718925476075, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 428.09657096862793, "episode_reward": 471.66798804076876, "step": 116000}
{"episode": 117.0, "batch_reward": 0.3487551169395447, "actor_loss": -25.359279182434083, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.107322216033936, "episode_reward": 469.21674308718707, "step": 117000}
{"episode": 118.0, "batch_reward": 0.3503834834694862, "actor_loss": -26.214237182617186, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 427.96521639823914, "episode_reward": 485.9067216232282, "step": 118000}
{"episode": 119.0, "batch_reward": 0.3512396360337734, "actor_loss": -26.233440071105957, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.13711380958557, "episode_reward": 538.2522813735528, "step": 119000}
{"episode": 120.0, "batch_reward": 0.35205018958449363, "actor_loss": -26.536588943481444, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 426.6653950214386, "episode_reward": 490.4274216344425, "step": 120000}
{"episode": 121.0, "batch_reward": 0.35283980032801626, "actor_loss": -26.583046783447266, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.52225470542908, "episode_reward": 465.6015048375332, "step": 121000}
{"episode": 122.0, "batch_reward": 0.354319653570652, "actor_loss": -26.433126457214357, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 429.4140214920044, "episode_reward": 500.0300963425, "step": 122000}
{"episode": 123.0, "batch_reward": 0.3548935717344284, "actor_loss": -26.54486259841919, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.19130539894104, "episode_reward": 432.10089385916456, "step": 123000}
{"episode": 124.0, "batch_reward": 0.3572774164378643, "actor_loss": -26.941897300720214, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 431.9654664993286, "episode_reward": 527.1729257431956, "step": 124000}
{"episode": 125.0, "batch_reward": 0.35757389521598815, "actor_loss": -26.9077024269104, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.03022289276123, "episode_reward": 500.69875881597096, "step": 125000}
{"episode": 126.0, "batch_reward": 0.35929705867171285, "actor_loss": -27.495213371276854, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 419.72441816329956, "episode_reward": 507.3119077793709, "step": 126000}
{"episode": 127.0, "batch_reward": 0.35961233380436897, "actor_loss": -27.541806968688967, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.885995626449585, "episode_reward": 490.2040570441785, "step": 127000}
{"episode": 128.0, "batch_reward": 0.36078385016322134, "actor_loss": -27.43134809875488, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 415.62039399147034, "episode_reward": 491.8834530516562, "step": 128000}
{"episode": 129.0, "batch_reward": 0.36249692499637604, "actor_loss": -27.583073585510252, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.49972939491272, "episode_reward": 482.73655535560465, "step": 129000}
{"episode": 130.0, "batch_reward": 0.3621711615025997, "actor_loss": -27.61448684310913, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 413.96755385398865, "episode_reward": 453.2775753708048, "step": 130000}
{"episode": 131.0, "batch_reward": 0.3636067570745945, "actor_loss": -27.790205520629883, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 32.72799849510193, "episode_reward": 516.8285597345143, "step": 131000}
{"episode": 132.0, "batch_reward": 0.36492700585722926, "actor_loss": -28.331507247924804, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 417.25686502456665, "episode_reward": 534.7238920631827, "step": 132000}
{"episode": 133.0, "batch_reward": 0.36716739988327024, "actor_loss": -28.632604251861572, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.531009435653687, "episode_reward": 527.0783964217114, "step": 133000}
{"episode": 134.0, "batch_reward": 0.3679254656434059, "actor_loss": -28.439417449951172, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 412.828754901886, "episode_reward": 466.5154836861712, "step": 134000}
{"episode": 135.0, "batch_reward": 0.367260302901268, "actor_loss": -28.290443031311035, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.466169595718384, "episode_reward": 361.5302714861248, "step": 135000}
{"episode": 136.0, "batch_reward": 0.36869853737950326, "actor_loss": -28.598997444152833, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 418.2008852958679, "episode_reward": 523.1273806336213, "step": 136000}
{"episode": 137.0, "batch_reward": 0.37041624373197557, "actor_loss": -28.73885363006592, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.84805464744568, "episode_reward": 513.5155433622482, "step": 137000}
{"episode": 138.0, "batch_reward": 0.3712362477481365, "actor_loss": -28.78004201889038, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 423.9196581840515, "episode_reward": 541.7623213911447, "step": 138000}
{"episode": 139.0, "batch_reward": 0.37243947902321817, "actor_loss": -28.958182430267335, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.598729848861694, "episode_reward": 522.4083364917425, "step": 139000}
{"episode": 140.0, "batch_reward": 0.3727640494406223, "actor_loss": -28.908388008117676, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 417.2119402885437, "episode_reward": 522.9295887767163, "step": 140000}
{"episode": 141.0, "batch_reward": 0.37316501465439794, "actor_loss": -28.967346660614012, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 32.80821895599365, "episode_reward": 469.65585025537496, "step": 141000}
{"episode": 142.0, "batch_reward": 0.3741233236193657, "actor_loss": -28.740029705047608, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 400.6486339569092, "episode_reward": 441.06596429810025, "step": 142000}
{"episode": 143.0, "batch_reward": 0.37418950629234315, "actor_loss": -28.63427320098877, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.778952836990356, "episode_reward": 241.7716998673102, "step": 143000}
{"episode": 144.0, "batch_reward": 0.37354362827539445, "actor_loss": -28.460222591400147, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 415.5485579967499, "episode_reward": 489.76468125116395, "step": 144000}
{"episode": 145.0, "batch_reward": 0.3749268008172512, "actor_loss": -28.524865325927735, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.664344787597656, "episode_reward": 561.3998341548903, "step": 145000}
{"episode": 146.0, "batch_reward": 0.3757050954699516, "actor_loss": -28.209678131103516, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 414.0124001502991, "episode_reward": 497.26764147070475, "step": 146000}
{"episode": 147.0, "batch_reward": 0.376947448939085, "actor_loss": -28.312750255584717, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.949612855911255, "episode_reward": 521.806845423146, "step": 147000}
{"episode": 148.0, "batch_reward": 0.3782193487584591, "actor_loss": -27.919351356506347, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 412.859671831131, "episode_reward": 472.68828209709204, "step": 148000}
{"episode": 149.0, "batch_reward": 0.377910346865654, "actor_loss": -27.903388538360595, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.820024251937866, "episode_reward": 543.8576136927624, "step": 149000}
{"episode": 150.0, "batch_reward": 0.3800499632358551, "actor_loss": -28.106655376434325, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
