{"episode_reward": 0.0, "episode": 1.0, "duration": 15.548201560974121, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.3768999576568604, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.26581315803066735, "critic_loss": 0.05088814394719335, "actor_loss": -31.844996768171015, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 67.97968411445618, "step": 3000}
{"episode_reward": 126.83721134504468, "episode": 4.0, "batch_reward": 0.21771914705634118, "critic_loss": 0.06969627319276332, "actor_loss": -26.78720667923242, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.852292776107788, "step": 4000}
{"episode_reward": 120.33028891582896, "episode": 5.0, "batch_reward": 0.18580579491704702, "critic_loss": 0.05366393700614572, "actor_loss": -24.56193895179033, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.475282907485962, "step": 5000}
{"episode_reward": 91.2616356075659, "episode": 6.0, "batch_reward": 0.16828627935796975, "critic_loss": 0.05944726175069809, "actor_loss": -21.63451862105727, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.22837996482849, "step": 6000}
{"episode_reward": 50.197683883151605, "episode": 7.0, "batch_reward": 0.14675045944005252, "critic_loss": 0.053604408161714676, "actor_loss": -21.043141621604562, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.70701766014099, "step": 7000}
{"episode_reward": 19.876673477292965, "episode": 8.0, "batch_reward": 0.13047345869988203, "critic_loss": 0.05181066810712218, "actor_loss": -20.117023332238197, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.34306311607361, "step": 8000}
{"episode_reward": 21.93653661950286, "episode": 9.0, "batch_reward": 0.11665173406898975, "critic_loss": 0.05677191400900483, "actor_loss": -19.488423045277596, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.343547582626343, "step": 9000}
{"episode_reward": 14.439708731404227, "episode": 10.0, "batch_reward": 0.10700232565402984, "critic_loss": 0.054805653847754, "actor_loss": -19.28325940722227, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.39966058731079, "step": 10000}
{"episode_reward": 31.1870022755455, "episode": 11.0, "batch_reward": 0.10213428650051355, "critic_loss": 0.06145576310530305, "actor_loss": -17.602252826035024, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.665138959884644, "step": 11000}
{"episode_reward": 74.19601110115416, "episode": 12.0, "batch_reward": 0.0996558146327734, "critic_loss": 0.07065543960407376, "actor_loss": -17.304044925004245, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.50906014442444, "step": 12000}
{"episode_reward": 90.5853018740995, "episode": 13.0, "batch_reward": 0.10337860042601824, "critic_loss": 0.09190089709311723, "actor_loss": -18.15545723386109, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.66732668876648, "step": 13000}
{"episode_reward": 182.07973708958326, "episode": 14.0, "batch_reward": 0.10390494160354137, "critic_loss": 0.08578982127085329, "actor_loss": -16.729624136582018, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.017372131347656, "step": 14000}
{"episode_reward": 59.970713571883756, "episode": 15.0, "batch_reward": 0.10230191629379988, "critic_loss": 0.08643192050606012, "actor_loss": -16.77456829059124, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.33301043510437, "step": 15000}
{"episode_reward": 142.62946332241734, "episode": 16.0, "batch_reward": 0.10610284280031919, "critic_loss": 0.09654881405085325, "actor_loss": -17.751415191546084, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.94696879386902, "step": 16000}
{"episode_reward": 199.4841416782663, "episode": 17.0, "batch_reward": 0.1116176973208785, "critic_loss": 0.11147573985904455, "actor_loss": -17.159399810776115, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.27363419532776, "step": 17000}
{"episode_reward": 95.64562834569054, "episode": 18.0, "batch_reward": 0.11371302003413439, "critic_loss": 0.13446887809038163, "actor_loss": -17.01201136109233, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.317901611328125, "step": 18000}
{"episode_reward": 174.39195480218171, "episode": 19.0, "batch_reward": 0.1142511189058423, "critic_loss": 0.13720925829559566, "actor_loss": -16.392938897788525, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.715876579284668, "step": 19000}
{"episode_reward": 78.28937026240514, "episode": 20.0, "batch_reward": 0.11471924176812172, "critic_loss": 0.15491733166575433, "actor_loss": -15.276719947218895, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.825806379318237, "step": 20000}
{"episode_reward": 267.7072248999676, "episode": 21.0, "batch_reward": 0.12268601343780756, "critic_loss": 0.16212002393603325, "actor_loss": -17.321318839550017, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.23475790023804, "step": 21000}
{"episode_reward": 185.05170476870833, "episode": 22.0, "batch_reward": 0.12266373623162508, "critic_loss": 0.13606575376167893, "actor_loss": -15.023553663730622, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.088390350341797, "step": 22000}
{"episode_reward": 64.63527267415866, "episode": 23.0, "batch_reward": 0.12351721265912056, "critic_loss": 0.15138744380325078, "actor_loss": -15.70323524427414, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.18195366859436, "step": 23000}
{"episode_reward": 214.03544490361986, "episode": 24.0, "batch_reward": 0.12814260209351777, "critic_loss": 0.1622421775236726, "actor_loss": -16.057047735214233, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.88060760498047, "step": 24000}
{"episode_reward": 320.6378145251535, "episode": 25.0, "batch_reward": 0.13451244512200355, "critic_loss": 0.16680540284514428, "actor_loss": -15.964532259941102, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.34883141517639, "step": 25000}
{"episode_reward": 129.92143090222118, "episode": 26.0, "batch_reward": 0.13190507636964321, "critic_loss": 0.1603116492703557, "actor_loss": -15.81342646598816, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.16679835319519, "step": 26000}
{"episode_reward": 59.07098437263164, "episode": 27.0, "batch_reward": 0.13339399407058955, "critic_loss": 0.16513637132197617, "actor_loss": -16.071540711402893, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.11362338066101, "step": 27000}
{"episode_reward": 328.7039507176598, "episode": 28.0, "batch_reward": 0.1403688893467188, "critic_loss": 0.17909376677125693, "actor_loss": -16.12049297809601, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.863687992095947, "step": 28000}
{"episode_reward": 256.5082817664909, "episode": 29.0, "batch_reward": 0.14320250676572324, "critic_loss": 0.16824246599525214, "actor_loss": -16.325203642845153, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.454044580459595, "step": 29000}
{"episode_reward": 204.82616306415687, "episode": 30.0, "batch_reward": 0.1462730552777648, "critic_loss": 0.1925696473568678, "actor_loss": -17.009690170288085, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.068435192108154, "step": 30000}
{"episode_reward": 160.41623109789427, "episode": 31.0, "batch_reward": 0.14716912745684385, "critic_loss": 0.21110644666850567, "actor_loss": -16.672966053962707, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.729576110839844, "step": 31000}
{"episode_reward": 219.32488254756012, "episode": 32.0, "batch_reward": 0.1463004809692502, "critic_loss": 0.2117788156196475, "actor_loss": -16.201144552230836, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.739290714263916, "step": 32000}
{"episode_reward": 87.75441272867616, "episode": 33.0, "batch_reward": 0.1448102375715971, "critic_loss": 0.19552920490503312, "actor_loss": -16.310916442871093, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.878991842269897, "step": 33000}
{"episode_reward": 101.59337783142442, "episode": 34.0, "batch_reward": 0.14310548374801874, "critic_loss": 0.1884483890235424, "actor_loss": -16.248769063949585, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.827994108200073, "step": 34000}
{"episode_reward": 102.29491452675809, "episode": 35.0, "batch_reward": 0.1437303277105093, "critic_loss": 0.18814147280156612, "actor_loss": -16.092418743133546, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.160106420516968, "step": 35000}
{"episode_reward": 268.21331545573486, "episode": 36.0, "batch_reward": 0.14810929454863073, "critic_loss": 0.2086828507706523, "actor_loss": -15.987430233001708, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.64331841468811, "step": 36000}
{"episode_reward": 221.7278614634338, "episode": 37.0, "batch_reward": 0.15019454623758793, "critic_loss": 0.19920096874982118, "actor_loss": -16.817505409240724, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.481217861175537, "step": 37000}
{"episode_reward": 266.6799487840681, "episode": 38.0, "batch_reward": 0.14992686335742472, "critic_loss": 0.19682049272954463, "actor_loss": -16.89174842453003, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.99206852912903, "step": 38000}
{"episode_reward": 53.8572918750921, "episode": 39.0, "batch_reward": 0.15110446356981994, "critic_loss": 0.1892986565232277, "actor_loss": -16.76901857948303, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.50534462928772, "step": 39000}
{"episode_reward": 322.6956846260253, "episode": 40.0, "batch_reward": 0.15538278672099112, "critic_loss": 0.1988333662673831, "actor_loss": -16.99260734176636, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.660911083221436, "step": 40000}
{"episode_reward": 260.9341207568168, "episode": 41.0, "batch_reward": 0.15685292080789803, "critic_loss": 0.19087352693080903, "actor_loss": -17.382840036392214, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.89063310623169, "step": 41000}
{"episode_reward": 272.39902198594314, "episode": 42.0, "batch_reward": 0.16015640114992857, "critic_loss": 0.2019238512814045, "actor_loss": -17.498521083831786, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.93160367012024, "step": 42000}
{"episode_reward": 202.66311884625554, "episode": 43.0, "batch_reward": 0.16052048487216233, "critic_loss": 0.2070931782871485, "actor_loss": -17.408173078536986, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.495102167129517, "step": 43000}
{"episode_reward": 224.48778074866797, "episode": 44.0, "batch_reward": 0.16107498733699321, "critic_loss": 0.20113952460885048, "actor_loss": -16.724171667099, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.504364252090454, "step": 44000}
{"episode_reward": 131.81123364169156, "episode": 45.0, "batch_reward": 0.1597624876126647, "critic_loss": 0.19928657300770283, "actor_loss": -17.115617677688597, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.00775980949402, "step": 45000}
{"episode_reward": 50.36724010308692, "episode": 46.0, "batch_reward": 0.157891593426466, "critic_loss": 0.2093269499540329, "actor_loss": -17.563156726837157, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.346892595291138, "step": 46000}
{"episode_reward": 217.02674401995637, "episode": 47.0, "batch_reward": 0.1602710647433996, "critic_loss": 0.20322082969546318, "actor_loss": -17.43691795158386, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.444558143615723, "step": 47000}
{"episode_reward": 218.3508045143254, "episode": 48.0, "batch_reward": 0.16177098537236453, "critic_loss": 0.20263776075094939, "actor_loss": -17.741652732849122, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.523363828659058, "step": 48000}
{"episode_reward": 344.72180931278547, "episode": 49.0, "batch_reward": 0.16601940414309502, "critic_loss": 0.23313494385778905, "actor_loss": -17.77450712776184, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.615501165390015, "step": 49000}
{"episode_reward": 311.332251116822, "episode": 50.0, "batch_reward": 0.16891175416111945, "critic_loss": 0.21848110046237706, "actor_loss": -18.175235651016234, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.579973936080933, "step": 50000}
{"episode_reward": 275.27820470760906, "episode": 51.0, "batch_reward": 0.1705374606847763, "critic_loss": 0.2401113933548331, "actor_loss": -18.466335634231566, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.437259912490845, "step": 51000}
{"episode_reward": 272.562451864047, "episode": 52.0, "batch_reward": 0.17325391481816768, "critic_loss": 0.2510300492569804, "actor_loss": -18.958451292037964, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.811556100845337, "step": 52000}
{"episode_reward": 405.253186381235, "episode": 53.0, "batch_reward": 0.175520099401474, "critic_loss": 0.25756603402644396, "actor_loss": -19.12899570655823, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.08168125152588, "step": 53000}
{"episode_reward": 150.44626817001472, "episode": 54.0, "batch_reward": 0.17657728704065084, "critic_loss": 0.27210486100614073, "actor_loss": -19.212994743347167, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.713711738586426, "step": 54000}
{"episode_reward": 216.13321915852075, "episode": 55.0, "batch_reward": 0.17692580176889897, "critic_loss": 0.27659749422222374, "actor_loss": -19.24770009613037, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.372053861618042, "step": 55000}
{"episode_reward": 166.21031954756418, "episode": 56.0, "batch_reward": 0.1771132580637932, "critic_loss": 0.2745027209743857, "actor_loss": -19.362321437835693, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.249762535095215, "step": 56000}
{"episode_reward": 376.25809722481586, "episode": 57.0, "batch_reward": 0.1810843991190195, "critic_loss": 0.26131142853200434, "actor_loss": -19.718752143859863, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.835620641708374, "step": 57000}
{"episode_reward": 237.04030444027228, "episode": 58.0, "batch_reward": 0.18143856132030486, "critic_loss": 0.27110207712650297, "actor_loss": -19.82889846420288, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.78440237045288, "step": 58000}
{"episode_reward": 190.0485743131235, "episode": 59.0, "batch_reward": 0.18130025358498097, "critic_loss": 0.2622849367856979, "actor_loss": -19.852661630630493, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.792320251464844, "step": 59000}
{"episode_reward": 212.1838929194129, "episode": 60.0, "batch_reward": 0.1811682319790125, "critic_loss": 0.29467299830913546, "actor_loss": -19.85768552017212, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.35553765296936, "step": 60000}
{"episode_reward": 148.96289915017255, "episode": 61.0, "batch_reward": 0.18260424169898032, "critic_loss": 0.27479786168038844, "actor_loss": -20.05661796569824, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.20046305656433, "step": 61000}
{"episode_reward": 330.39105747264455, "episode": 62.0, "batch_reward": 0.18410873125493527, "critic_loss": 0.27475732257217167, "actor_loss": -20.1666491355896, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.80355215072632, "step": 62000}
{"episode_reward": 159.36108359641315, "episode": 63.0, "batch_reward": 0.18492073564231395, "critic_loss": 0.31099072107672693, "actor_loss": -20.278125005722046, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.49793243408203, "step": 63000}
{"episode_reward": 298.31428091954746, "episode": 64.0, "batch_reward": 0.18601485303044318, "critic_loss": 0.29446085188537835, "actor_loss": -20.28867436981201, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.001837730407715, "step": 64000}
{"episode_reward": 209.57547344887675, "episode": 65.0, "batch_reward": 0.18602810394763947, "critic_loss": 0.3182046815752983, "actor_loss": -20.484687728881838, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.52646565437317, "step": 65000}
{"episode_reward": 193.98404785145718, "episode": 66.0, "batch_reward": 0.18633817119896412, "critic_loss": 0.3290447941049933, "actor_loss": -20.5146986618042, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.980979204177856, "step": 66000}
{"episode_reward": 247.7654024457456, "episode": 67.0, "batch_reward": 0.18778505939245224, "critic_loss": 0.3252878884524107, "actor_loss": -20.608220983505248, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.756526231765747, "step": 67000}
{"episode_reward": 444.9855109685473, "episode": 68.0, "batch_reward": 0.1897638364583254, "critic_loss": 0.316554317638278, "actor_loss": -20.7447041053772, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.346930265426636, "step": 68000}
{"episode_reward": 126.37240995398244, "episode": 69.0, "batch_reward": 0.18998792694509029, "critic_loss": 0.30931593215465547, "actor_loss": -21.03208108520508, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.715248823165894, "step": 69000}
{"episode_reward": 429.7733601172366, "episode": 70.0, "batch_reward": 0.19254430571198464, "critic_loss": 0.32935962567478416, "actor_loss": -21.220706283569335, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.888346672058105, "step": 70000}
{"episode_reward": 91.37647484273243, "episode": 71.0, "batch_reward": 0.19220252223312856, "critic_loss": 0.3246947033032775, "actor_loss": -21.36385657119751, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.9457266330719, "step": 71000}
{"episode_reward": 384.8478560529811, "episode": 72.0, "batch_reward": 0.1952539644986391, "critic_loss": 0.3218889097571373, "actor_loss": -21.551099502563478, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.640578269958496, "step": 72000}
{"episode_reward": 207.89341180497652, "episode": 73.0, "batch_reward": 0.193804783731699, "critic_loss": 0.35236938996613026, "actor_loss": -21.42585089111328, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.689051628112793, "step": 73000}
{"episode_reward": 64.43831731904179, "episode": 74.0, "batch_reward": 0.1925645420253277, "critic_loss": 0.3253264800384641, "actor_loss": -21.472540264129638, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.968998432159424, "step": 74000}
{"episode_reward": 239.3988926808632, "episode": 75.0, "batch_reward": 0.19264377044141293, "critic_loss": 0.3067707181721926, "actor_loss": -21.532772869110108, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.072168588638306, "step": 75000}
{"episode_reward": 247.7230148152543, "episode": 76.0, "batch_reward": 0.194855918943882, "critic_loss": 0.3189585903286934, "actor_loss": -21.606407886505128, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.521169424057007, "step": 76000}
{"episode_reward": 483.5837325463005, "episode": 77.0, "batch_reward": 0.1996507108360529, "critic_loss": 0.3108045854344964, "actor_loss": -22.09112722015381, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.994853496551514, "step": 77000}
{"episode_reward": 511.6225409524561, "episode": 78.0, "batch_reward": 0.20232613655924797, "critic_loss": 0.331484353788197, "actor_loss": -22.262389060974122, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.84606170654297, "step": 78000}
{"episode_reward": 359.75567229368164, "episode": 79.0, "batch_reward": 0.20558061614632606, "critic_loss": 0.31264854648709295, "actor_loss": -22.43932416152954, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.25694251060486, "step": 79000}
{"episode_reward": 338.1540863323936, "episode": 80.0, "batch_reward": 0.20587122823297976, "critic_loss": 0.3123228854984045, "actor_loss": -22.640921993255617, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.7653546333313, "step": 80000}
{"episode_reward": 177.4342474783532, "episode": 81.0, "batch_reward": 0.20547272254526616, "critic_loss": 0.31202870508283376, "actor_loss": -22.635371017456055, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.514968156814575, "step": 81000}
{"episode_reward": 200.3325982892385, "episode": 82.0, "batch_reward": 0.20580099818110467, "critic_loss": 0.3217889786958694, "actor_loss": -22.736924869537354, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.40171718597412, "step": 82000}
{"episode_reward": 397.79020199586455, "episode": 83.0, "batch_reward": 0.2084012756049633, "critic_loss": 0.34515359595417977, "actor_loss": -22.82277007675171, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.499104738235474, "step": 83000}
{"episode_reward": 462.42148452913324, "episode": 84.0, "batch_reward": 0.21173271714150907, "critic_loss": 0.3426569823026657, "actor_loss": -23.216702419281006, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.992061614990234, "step": 84000}
{"episode_reward": 418.17168334520284, "episode": 85.0, "batch_reward": 0.21207460050284863, "critic_loss": 0.339388088054955, "actor_loss": -23.246893825531007, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.604012727737427, "step": 85000}
{"episode_reward": 206.83623505091765, "episode": 86.0, "batch_reward": 0.2133903612047434, "critic_loss": 0.30577607364952564, "actor_loss": -23.339091415405274, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.725658655166626, "step": 86000}
{"episode_reward": 217.85996046380242, "episode": 87.0, "batch_reward": 0.2142791982591152, "critic_loss": 0.3417990438044071, "actor_loss": -23.46212791442871, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.044649362564087, "step": 87000}
{"episode_reward": 386.12986674629616, "episode": 88.0, "batch_reward": 0.2153527685701847, "critic_loss": 0.32710891760885713, "actor_loss": -23.57968012237549, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.28260827064514, "step": 88000}
{"episode_reward": 281.2563432362117, "episode": 89.0, "batch_reward": 0.215170754596591, "critic_loss": 0.3436305529624224, "actor_loss": -23.40480707168579, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.522255659103394, "step": 89000}
{"episode_reward": 155.4731811010989, "episode": 90.0, "batch_reward": 0.216315789103508, "critic_loss": 0.390955037727952, "actor_loss": -23.5407897644043, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.66443943977356, "step": 90000}
{"episode_reward": 359.50000021753544, "episode": 91.0, "batch_reward": 0.21696022914350033, "critic_loss": 0.35482687518000605, "actor_loss": -23.529236721038817, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.20106506347656, "step": 91000}
{"episode_reward": 512.7989643693891, "episode": 92.0, "batch_reward": 0.22027187341451646, "critic_loss": 0.39629428446292875, "actor_loss": -23.774687194824217, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.49217987060547, "step": 92000}
{"episode_reward": 271.81713142317915, "episode": 93.0, "batch_reward": 0.2207973794043064, "critic_loss": 0.41121161517500876, "actor_loss": -23.81691707611084, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.954840660095215, "step": 93000}
{"episode_reward": 570.5182072829518, "episode": 94.0, "batch_reward": 0.22448266063630581, "critic_loss": 0.40183145028352735, "actor_loss": -24.00790376663208, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.68365240097046, "step": 94000}
{"episode_reward": 249.69656674813584, "episode": 95.0, "batch_reward": 0.22475093637406826, "critic_loss": 0.43945656903088093, "actor_loss": -24.043678043365478, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.53702688217163, "step": 95000}
{"episode_reward": 310.9534954746173, "episode": 96.0, "batch_reward": 0.22763932114839555, "critic_loss": 0.390919206276536, "actor_loss": -24.285710292816162, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.928576946258545, "step": 96000}
{"episode_reward": 483.29436226593424, "episode": 97.0, "batch_reward": 0.22863275377452374, "critic_loss": 0.41151610943675043, "actor_loss": -24.52087798309326, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.93345880508423, "step": 97000}
{"episode_reward": 415.07549571947123, "episode": 98.0, "batch_reward": 0.23054875449836254, "critic_loss": 0.4146389444470406, "actor_loss": -24.63849422454834, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.577946662902832, "step": 98000}
{"episode_reward": 440.9913489595946, "episode": 99.0, "batch_reward": 0.23350798204541207, "critic_loss": 0.4383910534977913, "actor_loss": -24.88404909133911, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.633987188339233, "step": 99000}
{"episode_reward": 431.53603078456155, "episode": 100.0, "batch_reward": 0.2344176889806986, "critic_loss": 0.3952716194391251, "actor_loss": -24.964612297058107, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.613234281539917, "step": 100000}
{"episode_reward": 110.58786273617562, "episode": 101.0, "batch_reward": 0.23250496503710746, "critic_loss": 0.41084944212436675, "actor_loss": -24.846970245361327, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.681193351745605, "step": 101000}
{"episode_reward": 106.58689574712496, "episode": 102.0, "batch_reward": 0.23335271200537683, "critic_loss": 0.39656718909740446, "actor_loss": -24.789071491241454, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.750789642333984, "step": 102000}
{"episode_reward": 494.10701553702285, "episode": 103.0, "batch_reward": 0.23392980653047563, "critic_loss": 0.4123492692410946, "actor_loss": -24.92575170135498, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.670287609100342, "step": 103000}
{"episode_reward": 197.21858052712432, "episode": 104.0, "batch_reward": 0.235173236399889, "critic_loss": 0.403024884223938, "actor_loss": -25.028784687042236, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.486542463302612, "step": 104000}
{"episode_reward": 470.16774344438346, "episode": 105.0, "batch_reward": 0.23733735460042954, "critic_loss": 0.39942794615030286, "actor_loss": -25.204947380065917, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.735512495040894, "step": 105000}
{"episode_reward": 502.4476433727005, "episode": 106.0, "batch_reward": 0.24005887721478938, "critic_loss": 0.41593158078193665, "actor_loss": -25.40803995132446, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.27980661392212, "step": 106000}
{"episode_reward": 463.68222197270586, "episode": 107.0, "batch_reward": 0.24104016849398613, "critic_loss": 0.42308586828410627, "actor_loss": -25.482578048706056, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.017278909683228, "step": 107000}
{"episode_reward": 467.0894560310767, "episode": 108.0, "batch_reward": 0.24487173394858838, "critic_loss": 0.44437099373340605, "actor_loss": -25.780676551818846, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.69436550140381, "step": 108000}
{"episode_reward": 529.1654832386549, "episode": 109.0, "batch_reward": 0.24792610377073288, "critic_loss": 0.4130159536451101, "actor_loss": -26.013285793304444, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.955328702926636, "step": 109000}
{"episode_reward": 549.7030215464646, "episode": 110.0, "batch_reward": 0.24941436386108398, "critic_loss": 0.44619776026904584, "actor_loss": -26.078819301605225, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.94535994529724, "step": 110000}
{"episode_reward": 384.21297758956314, "episode": 111.0, "batch_reward": 0.2484408922493458, "critic_loss": 0.47002941627800465, "actor_loss": -26.04166926574707, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.43075203895569, "step": 111000}
{"episode_reward": 128.27660789507456, "episode": 112.0, "batch_reward": 0.24989647667109965, "critic_loss": 0.46389781720936296, "actor_loss": -26.178854900360108, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.726388454437256, "step": 112000}
{"episode_reward": 506.32636577948625, "episode": 113.0, "batch_reward": 0.2508247191756964, "critic_loss": 0.4430654911249876, "actor_loss": -26.184762203216554, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.8838632106781, "step": 113000}
{"episode_reward": 454.14470473444453, "episode": 114.0, "batch_reward": 0.25383191411197187, "critic_loss": 0.4531823798418045, "actor_loss": -26.450370887756346, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.790881156921387, "step": 114000}
{"episode_reward": 560.3839687211414, "episode": 115.0, "batch_reward": 0.2561652878522873, "critic_loss": 0.4446822476387024, "actor_loss": -26.72604404449463, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.47100853919983, "step": 115000}
{"episode_reward": 292.2157687395452, "episode": 116.0, "batch_reward": 0.25601397979259494, "critic_loss": 0.462866186529398, "actor_loss": -26.538051189422607, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.817671060562134, "step": 116000}
{"episode_reward": 341.26725920793075, "episode": 117.0, "batch_reward": 0.2574613349288702, "critic_loss": 0.4339357980340719, "actor_loss": -26.633126747131346, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.71388554573059, "step": 117000}
{"episode_reward": 540.50237543202, "episode": 118.0, "batch_reward": 0.25845211872458457, "critic_loss": 0.4560216602683067, "actor_loss": -26.770385334014893, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.384031772613525, "step": 118000}
{"episode_reward": 196.16153362988786, "episode": 119.0, "batch_reward": 0.25978523257374764, "critic_loss": 0.49317890845239165, "actor_loss": -26.793063003540038, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.305875778198242, "step": 119000}
{"episode_reward": 320.19239976248275, "episode": 120.0, "batch_reward": 0.259274831533432, "critic_loss": 0.4678113345205784, "actor_loss": -26.74524112701416, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.01484966278076, "step": 120000}
{"episode_reward": 491.8524916088194, "episode": 121.0, "batch_reward": 0.2612518733292818, "critic_loss": 0.4573860092461109, "actor_loss": -26.841311630249024, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.26362228393555, "step": 121000}
{"episode_reward": 296.7592736381516, "episode": 122.0, "batch_reward": 0.2614265467822552, "critic_loss": 0.4231401382386684, "actor_loss": -26.91545852279663, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.578330278396606, "step": 122000}
{"episode_reward": 559.5116331882731, "episode": 123.0, "batch_reward": 0.26527824287116525, "critic_loss": 0.4939739702343941, "actor_loss": -27.27396870803833, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.658979654312134, "step": 123000}
{"episode_reward": 613.2617323272377, "episode": 124.0, "batch_reward": 0.2672358335405588, "critic_loss": 0.4685850052833557, "actor_loss": -27.459844104766844, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.66214942932129, "step": 124000}
{"episode_reward": 319.9665765078261, "episode": 125.0, "batch_reward": 0.2663565868139267, "critic_loss": 0.4561259545236826, "actor_loss": -27.366924266815186, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.7717182636261, "step": 125000}
{"episode_reward": 250.45355326214047, "episode": 126.0, "batch_reward": 0.2677976818829775, "critic_loss": 0.4812981917560101, "actor_loss": -27.473998298645018, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.766990661621094, "step": 126000}
{"episode_reward": 552.9299403923973, "episode": 127.0, "batch_reward": 0.26866404645144937, "critic_loss": 0.4854648235887289, "actor_loss": -27.467117614746094, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.67711114883423, "step": 127000}
{"episode_reward": 281.41623332137283, "episode": 128.0, "batch_reward": 0.2700058343410492, "critic_loss": 0.48727748841047286, "actor_loss": -27.70860954284668, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.20663285255432, "step": 128000}
{"episode_reward": 518.3855695702757, "episode": 129.0, "batch_reward": 0.2712173932492733, "critic_loss": 0.46476525719463824, "actor_loss": -27.797130519866943, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.81573462486267, "step": 129000}
{"episode_reward": 523.1103311886169, "episode": 130.0, "batch_reward": 0.27279737509787083, "critic_loss": 0.4529773128181696, "actor_loss": -27.965497718811037, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.928179025650024, "step": 130000}
{"episode_reward": 166.87084623628772, "episode": 131.0, "batch_reward": 0.2729093768298626, "critic_loss": 0.467839587777853, "actor_loss": -27.935288871765138, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.48416471481323, "step": 131000}
{"episode_reward": 291.6867213752828, "episode": 132.0, "batch_reward": 0.27237183405458926, "critic_loss": 0.4775742799937725, "actor_loss": -27.853650318145753, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.556300163269043, "step": 132000}
{"episode_reward": 160.2376589305872, "episode": 133.0, "batch_reward": 0.2722601742297411, "critic_loss": 0.49446863925457, "actor_loss": -27.879849899291994, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.754236459732056, "step": 133000}
{"episode_reward": 546.9904662256603, "episode": 134.0, "batch_reward": 0.2740916610658169, "critic_loss": 0.4664113309085369, "actor_loss": -28.04034478378296, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.463537454605103, "step": 134000}
{"episode_reward": 416.6730877587453, "episode": 135.0, "batch_reward": 0.2743796396553516, "critic_loss": 0.45588628396391867, "actor_loss": -27.896622131347655, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.114914894104004, "step": 135000}
{"episode_reward": 482.5912838826979, "episode": 136.0, "batch_reward": 0.2777500410825014, "critic_loss": 0.49072310477495196, "actor_loss": -28.182409999847412, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.995511531829834, "step": 136000}
{"episode_reward": 621.0042215547406, "episode": 137.0, "batch_reward": 0.2788547842651606, "critic_loss": 0.45537925797700884, "actor_loss": -28.37420266342163, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.379621982574463, "step": 137000}
{"episode_reward": 585.8508098920507, "episode": 138.0, "batch_reward": 0.2812929491847754, "critic_loss": 0.479480863198638, "actor_loss": -28.426604022979735, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.608585596084595, "step": 138000}
{"episode_reward": 566.395460228093, "episode": 139.0, "batch_reward": 0.28384419982135295, "critic_loss": 0.4628753226995468, "actor_loss": -28.784485412597657, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.089914560317993, "step": 139000}
{"episode_reward": 582.8296043575192, "episode": 140.0, "batch_reward": 0.28514252799749373, "critic_loss": 0.4580875620990992, "actor_loss": -28.880276668548586, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.053694248199463, "step": 140000}
{"episode_reward": 580.646072938607, "episode": 141.0, "batch_reward": 0.2891087956279516, "critic_loss": 0.4705785698890686, "actor_loss": -29.151439331054686, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.96476221084595, "step": 141000}
{"episode_reward": 597.3045495098501, "episode": 142.0, "batch_reward": 0.2905445497334003, "critic_loss": 0.4650529838502407, "actor_loss": -29.286616962432863, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.844305276870728, "step": 142000}
{"episode_reward": 320.7851577642504, "episode": 143.0, "batch_reward": 0.2883044330626726, "critic_loss": 0.452381939381361, "actor_loss": -29.157350437164308, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.195544719696045, "step": 143000}
{"episode_reward": 57.57556819794483, "episode": 144.0, "batch_reward": 0.28840516562759877, "critic_loss": 0.4568674370199442, "actor_loss": -29.110457321166994, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.92014193534851, "step": 144000}
{"episode_reward": 367.53271573447614, "episode": 145.0, "batch_reward": 0.2887456198036671, "critic_loss": 0.4574810644984245, "actor_loss": -29.0989715385437, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.119407176971436, "step": 145000}
{"episode_reward": 397.78283798693064, "episode": 146.0, "batch_reward": 0.28827362282574176, "critic_loss": 0.47023997841775417, "actor_loss": -29.178476654052734, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.933619499206543, "step": 146000}
{"episode_reward": 130.75626859324066, "episode": 147.0, "batch_reward": 0.2887259495854378, "critic_loss": 0.4561119481474161, "actor_loss": -29.222373287200927, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.913350105285645, "step": 147000}
{"episode_reward": 598.751625240734, "episode": 148.0, "batch_reward": 0.29075842978060246, "critic_loss": 0.45294819910824297, "actor_loss": -29.233088439941405, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.805313110351562, "step": 148000}
{"episode_reward": 529.4785707028118, "episode": 149.0, "batch_reward": 0.2930745522379875, "critic_loss": 0.5068390365242958, "actor_loss": -29.499665340423583, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.602973699569702, "step": 149000}
{"episode_reward": 555.1117794780881, "episode": 150.0, "batch_reward": 0.29361459031701087, "critic_loss": 0.5209232343435287, "actor_loss": -29.457746780395507, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
