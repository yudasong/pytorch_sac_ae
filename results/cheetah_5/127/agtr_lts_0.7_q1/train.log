{"episode_reward": 0.0, "episode": 1.0, "duration": 18.758068561553955, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.6430842876434326, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.26308913180612653, "critic_loss": 0.6378480131952474, "actor_loss": -38.96225423381633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 68.26069188117981, "step": 3000}
{"episode_reward": 29.607553982151178, "episode": 4.0, "batch_reward": 0.20089616799354554, "critic_loss": 1.251681933760643, "actor_loss": -35.21200371551514, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.772672414779663, "step": 4000}
{"episode_reward": 305.9140330004267, "episode": 5.0, "batch_reward": 0.23854240441322327, "critic_loss": 1.0120900265574455, "actor_loss": -37.11295048522949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.937766790390015, "step": 5000}
{"episode_reward": 485.8318561549817, "episode": 6.0, "batch_reward": 0.26869789773225783, "critic_loss": 0.9234135679602623, "actor_loss": -38.37282007598877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.262396812438965, "step": 6000}
{"episode_reward": 292.1939124652196, "episode": 7.0, "batch_reward": 0.25822948238253596, "critic_loss": 0.7540205047428608, "actor_loss": -37.001849250793455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.56291437149048, "step": 7000}
{"episode_reward": 21.89518620953244, "episode": 8.0, "batch_reward": 0.22950055626034738, "critic_loss": 0.5880606979131698, "actor_loss": -35.50623821258545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.590140342712402, "step": 8000}
{"episode_reward": 64.64792732742292, "episode": 9.0, "batch_reward": 0.2275333388596773, "critic_loss": 0.6616196610033512, "actor_loss": -34.55387020492554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.5500271320343, "step": 9000}
{"episode_reward": 414.4664314946418, "episode": 10.0, "batch_reward": 0.2332840464115143, "critic_loss": 0.6300539644062519, "actor_loss": -34.81923029708862, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.469427585601807, "step": 10000}
{"episode_reward": 219.06320498625882, "episode": 11.0, "batch_reward": 0.2356400101482868, "critic_loss": 0.606610720217228, "actor_loss": -34.628078941345215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.638051986694336, "step": 11000}
{"episode_reward": 289.01728341975104, "episode": 12.0, "batch_reward": 0.2524570897966623, "critic_loss": 0.6805179760158062, "actor_loss": -35.36253144836426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.528691291809082, "step": 12000}
{"episode_reward": 503.75106244007617, "episode": 13.0, "batch_reward": 0.2718834803402424, "critic_loss": 0.7514488086104393, "actor_loss": -36.092413513183594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.070342540740967, "step": 13000}
{"episode_reward": 453.1475649463405, "episode": 14.0, "batch_reward": 0.28811047884821894, "critic_loss": 0.7349442960619926, "actor_loss": -36.25446825408935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.3079776763916, "step": 14000}
{"episode_reward": 544.6548787772263, "episode": 15.0, "batch_reward": 0.30345260301232335, "critic_loss": 0.7356753027737141, "actor_loss": -37.063022422790525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.85015344619751, "step": 15000}
{"episode_reward": 537.3337754129426, "episode": 16.0, "batch_reward": 0.31995038568973544, "critic_loss": 0.770191960990429, "actor_loss": -37.94769747924805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.98993468284607, "step": 16000}
{"episode_reward": 581.7736758176633, "episode": 17.0, "batch_reward": 0.33159630128741263, "critic_loss": 0.825650850057602, "actor_loss": -38.25270381546021, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.030802249908447, "step": 17000}
{"episode_reward": 366.96521796995256, "episode": 18.0, "batch_reward": 0.32753567898273467, "critic_loss": 0.9453058298826218, "actor_loss": -37.54051021194458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.19745397567749, "step": 18000}
{"episode_reward": 67.03148719309493, "episode": 19.0, "batch_reward": 0.319623219743371, "critic_loss": 0.9511270204782486, "actor_loss": -36.62777601623535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.798223972320557, "step": 19000}
{"episode_reward": 398.41940500301837, "episode": 20.0, "batch_reward": 0.32424760465323926, "critic_loss": 1.0366926485300063, "actor_loss": -37.13604549789429, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.79235076904297, "step": 20000}
{"episode_reward": 366.0509837855957, "episode": 21.0, "batch_reward": 0.3279911068677902, "critic_loss": 0.9926192356348038, "actor_loss": -36.29034024810791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.559165477752686, "step": 21000}
{"episode_reward": 491.16256089885326, "episode": 22.0, "batch_reward": 0.3360765345990658, "critic_loss": 0.9375564845800399, "actor_loss": -37.14376837539673, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.952128648757935, "step": 22000}
{"episode_reward": 567.3583728196595, "episode": 23.0, "batch_reward": 0.3471107095479965, "critic_loss": 0.9618053723573685, "actor_loss": -37.46970434570313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.362735271453857, "step": 23000}
{"episode_reward": 491.5125097991255, "episode": 24.0, "batch_reward": 0.352204701602459, "critic_loss": 0.9072907482385635, "actor_loss": -37.733356929779056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.76583957672119, "step": 24000}
{"episode_reward": 527.4351888307103, "episode": 25.0, "batch_reward": 0.36123877969384194, "critic_loss": 0.875118328332901, "actor_loss": -38.34915775680542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.13870120048523, "step": 25000}
{"episode_reward": 597.194854248919, "episode": 26.0, "batch_reward": 0.3680710248947144, "critic_loss": 0.8899528654813766, "actor_loss": -38.23808098983765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.981449842453003, "step": 26000}
{"episode_reward": 569.6052391443128, "episode": 27.0, "batch_reward": 0.3764444078505039, "critic_loss": 0.8468042004406452, "actor_loss": -38.60269509124756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.7325336933136, "step": 27000}
{"episode_reward": 562.7034483361762, "episode": 28.0, "batch_reward": 0.38462802866101264, "critic_loss": 0.8078861002624035, "actor_loss": -38.91481870269775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.305262327194214, "step": 28000}
{"episode_reward": 600.3591459423347, "episode": 29.0, "batch_reward": 0.3901632129251957, "critic_loss": 0.7897428752183914, "actor_loss": -39.397511882781984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.50545024871826, "step": 29000}
{"episode_reward": 554.0441386505362, "episode": 30.0, "batch_reward": 0.3970484746694565, "critic_loss": 0.7850854808986187, "actor_loss": -39.44715642929077, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.597516536712646, "step": 30000}
{"episode_reward": 400.9501044911933, "episode": 31.0, "batch_reward": 0.39699067422747614, "critic_loss": 0.7562996742427349, "actor_loss": -39.181695045471194, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.78512191772461, "step": 31000}
{"episode_reward": 438.2722411607624, "episode": 32.0, "batch_reward": 0.3967050932943821, "critic_loss": 0.7905761653780937, "actor_loss": -38.94829468536377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.44806408882141, "step": 32000}
{"episode_reward": 277.21217014926594, "episode": 33.0, "batch_reward": 0.3950305635035038, "critic_loss": 0.8256841277778149, "actor_loss": -38.558807346344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.621772289276123, "step": 33000}
{"episode_reward": 390.4577604230204, "episode": 34.0, "batch_reward": 0.3948578631579876, "critic_loss": 0.8510439069569111, "actor_loss": -38.35467445373535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.107389450073242, "step": 34000}
{"episode_reward": 504.1352929426716, "episode": 35.0, "batch_reward": 0.3986429364681244, "critic_loss": 0.9063214811682702, "actor_loss": -38.59362585449219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.557860612869263, "step": 35000}
{"episode_reward": 576.1284273522651, "episode": 36.0, "batch_reward": 0.4028330633044243, "critic_loss": 0.9682976494729519, "actor_loss": -39.03017551422119, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.202690362930298, "step": 36000}
{"episode_reward": 584.6317527750413, "episode": 37.0, "batch_reward": 0.4065979978144169, "critic_loss": 0.967126325070858, "actor_loss": -38.52747265625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18134379386902, "step": 37000}
{"episode_reward": 504.63209281754837, "episode": 38.0, "batch_reward": 0.4066735304296017, "critic_loss": 0.966481458902359, "actor_loss": -38.15809187316894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.879923820495605, "step": 38000}
{"episode_reward": 102.44322389358204, "episode": 39.0, "batch_reward": 0.4027128891944885, "critic_loss": 0.8790689556002617, "actor_loss": -38.09235231781006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.298481702804565, "step": 39000}
{"episode_reward": 551.2091993562226, "episode": 40.0, "batch_reward": 0.40496833512187, "critic_loss": 0.9453253801167011, "actor_loss": -38.39977370452881, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.43157172203064, "step": 40000}
{"episode_reward": 405.2529616429079, "episode": 41.0, "batch_reward": 0.40594931921362876, "critic_loss": 0.8924155921936036, "actor_loss": -38.11628221511841, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.26983070373535, "step": 41000}
{"episode_reward": 535.2435786449821, "episode": 42.0, "batch_reward": 0.40924748024344443, "critic_loss": 0.8458409787416458, "actor_loss": -38.42365690612793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.33155870437622, "step": 42000}
{"episode_reward": 533.2277444327443, "episode": 43.0, "batch_reward": 0.4125196417868137, "critic_loss": 0.8553990724980831, "actor_loss": -38.759877910614016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.321839570999146, "step": 43000}
{"episode_reward": 574.2545766855746, "episode": 44.0, "batch_reward": 0.41527005302906034, "critic_loss": 0.8278380638957024, "actor_loss": -39.885770111083986, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.254053354263306, "step": 44000}
{"episode_reward": 520.8620937475849, "episode": 45.0, "batch_reward": 0.4181201005876064, "critic_loss": 0.8087393237054348, "actor_loss": -39.610272682189944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.437441110610962, "step": 45000}
{"episode_reward": 597.0307823495864, "episode": 46.0, "batch_reward": 0.4194557209312916, "critic_loss": 0.8358900578618049, "actor_loss": -39.15283655166626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.87723135948181, "step": 46000}
{"episode_reward": 310.6589226803166, "episode": 47.0, "batch_reward": 0.4187269871532917, "critic_loss": 0.8139886607527733, "actor_loss": -39.1860775680542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.605571508407593, "step": 47000}
{"episode_reward": 451.02675904349906, "episode": 48.0, "batch_reward": 0.4207757625877857, "critic_loss": 0.8854133533239364, "actor_loss": -39.14176652526856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.00300097465515, "step": 48000}
{"episode_reward": 592.2015676675364, "episode": 49.0, "batch_reward": 0.42401064291596413, "critic_loss": 0.9400249462425708, "actor_loss": -40.09242837905884, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.917884588241577, "step": 49000}
{"episode_reward": 556.9493754297754, "episode": 50.0, "batch_reward": 0.42627201312780383, "critic_loss": 0.9319590220451355, "actor_loss": -39.78360634613037, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.71218514442444, "step": 50000}
{"episode_reward": 365.8286657059503, "episode": 51.0, "batch_reward": 0.4242692598700523, "critic_loss": 1.0018315308690071, "actor_loss": -39.42108419036865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.40146780014038, "step": 51000}
{"episode_reward": 520.3008472037093, "episode": 52.0, "batch_reward": 0.42880407920479774, "critic_loss": 1.026799067378044, "actor_loss": -39.726900108337404, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.015307903289795, "step": 52000}
{"episode_reward": 646.353060621675, "episode": 53.0, "batch_reward": 0.4312391871213913, "critic_loss": 1.0441176709532738, "actor_loss": -40.31611995697021, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.49250864982605, "step": 53000}
{"episode_reward": 561.436347840734, "episode": 54.0, "batch_reward": 0.4346815719306469, "critic_loss": 1.0606042211651803, "actor_loss": -40.75188430786133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03630781173706, "step": 54000}
{"episode_reward": 594.1552664013441, "episode": 55.0, "batch_reward": 0.4357696919441223, "critic_loss": 1.008305387854576, "actor_loss": -40.558092948913576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.53973412513733, "step": 55000}
{"episode_reward": 520.306134191187, "episode": 56.0, "batch_reward": 0.4383171136677265, "critic_loss": 1.04937979054451, "actor_loss": -40.62769054031372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.846368074417114, "step": 56000}
{"episode_reward": 591.1599718525255, "episode": 57.0, "batch_reward": 0.4419189760088921, "critic_loss": 1.0666403262615203, "actor_loss": -40.753168964385985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.17142605781555, "step": 57000}
{"episode_reward": 647.4789932483523, "episode": 58.0, "batch_reward": 0.44397887992858887, "critic_loss": 1.0753965416550637, "actor_loss": -41.00929487991333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.82862091064453, "step": 58000}
{"episode_reward": 583.4082074081887, "episode": 59.0, "batch_reward": 0.446758068561554, "critic_loss": 1.012514200538397, "actor_loss": -41.05786320114136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.037571668624878, "step": 59000}
{"episode_reward": 564.0577666727553, "episode": 60.0, "batch_reward": 0.448010008841753, "critic_loss": 1.1080254644155503, "actor_loss": -41.426094722747806, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.06381893157959, "step": 60000}
{"episode_reward": 529.631849582129, "episode": 61.0, "batch_reward": 0.45073922100663183, "critic_loss": 1.1081761311292648, "actor_loss": -41.405396278381346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.91540765762329, "step": 61000}
{"episode_reward": 648.5265586854523, "episode": 62.0, "batch_reward": 0.4519987428188324, "critic_loss": 1.065086307168007, "actor_loss": -41.683137138366696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.355103969573975, "step": 62000}
{"episode_reward": 439.6301501545482, "episode": 63.0, "batch_reward": 0.4535903396010399, "critic_loss": 1.1137528821825982, "actor_loss": -41.83104316329956, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.268004417419434, "step": 63000}
{"episode_reward": 574.5680200834067, "episode": 64.0, "batch_reward": 0.4560790376663208, "critic_loss": 1.1978377597332002, "actor_loss": -41.8831708908081, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.18148136138916, "step": 64000}
{"episode_reward": 605.0971457959591, "episode": 65.0, "batch_reward": 0.458585198700428, "critic_loss": 1.1697367901802063, "actor_loss": -41.93634758758545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.66058349609375, "step": 65000}
{"episode_reward": 631.1250157973899, "episode": 66.0, "batch_reward": 0.4571756092309952, "critic_loss": 1.1433625266551972, "actor_loss": -41.84953859329224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.778051614761353, "step": 66000}
{"episode_reward": 110.96694052867825, "episode": 67.0, "batch_reward": 0.4538467176556587, "critic_loss": 1.1779414326548576, "actor_loss": -41.95551208114624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.77848482131958, "step": 67000}
{"episode_reward": 604.2655726866326, "episode": 68.0, "batch_reward": 0.45645604765415193, "critic_loss": 1.139522361576557, "actor_loss": -42.57490180587769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.921998500823975, "step": 68000}
{"episode_reward": 459.1373104432772, "episode": 69.0, "batch_reward": 0.4571378881037235, "critic_loss": 1.1430567929148674, "actor_loss": -41.605197093963625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.268351554870605, "step": 69000}
{"episode_reward": 628.4251305245207, "episode": 70.0, "batch_reward": 0.4599850276708603, "critic_loss": 1.1339458093047141, "actor_loss": -42.015795547485354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.60760188102722, "step": 70000}
{"episode_reward": 534.0318135187852, "episode": 71.0, "batch_reward": 0.4607467613816261, "critic_loss": 1.1164427390694618, "actor_loss": -41.74160109710694, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.40322947502136, "step": 71000}
{"episode_reward": 585.7690039552471, "episode": 72.0, "batch_reward": 0.46207164481282237, "critic_loss": 1.0727427616119385, "actor_loss": -42.371064586639406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.448935985565186, "step": 72000}
{"episode_reward": 513.8808187374797, "episode": 73.0, "batch_reward": 0.46337519827485085, "critic_loss": 1.0574906378388405, "actor_loss": -42.51795750427246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.953048944473267, "step": 73000}
{"episode_reward": 561.4042677388238, "episode": 74.0, "batch_reward": 0.46433762207627294, "critic_loss": 1.0537804688215255, "actor_loss": -42.268754428863524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8100905418396, "step": 74000}
{"episode_reward": 664.3571840527026, "episode": 75.0, "batch_reward": 0.46600003346800806, "critic_loss": 0.9961677580177783, "actor_loss": -42.73707850646973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.118247747421265, "step": 75000}
{"episode_reward": 604.6111482568858, "episode": 76.0, "batch_reward": 0.4691397658586502, "critic_loss": 1.01278738245368, "actor_loss": -42.82518787002564, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.90698266029358, "step": 76000}
{"episode_reward": 512.8914245393012, "episode": 77.0, "batch_reward": 0.470182676255703, "critic_loss": 1.0582655413746833, "actor_loss": -42.98362406921387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.417418241500854, "step": 77000}
{"episode_reward": 602.1638760335819, "episode": 78.0, "batch_reward": 0.47143746015429494, "critic_loss": 1.060283164203167, "actor_loss": -43.2539267539978, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.967405319213867, "step": 78000}
{"episode_reward": 610.9243092248348, "episode": 79.0, "batch_reward": 0.47417089983820915, "critic_loss": 1.0659081177115441, "actor_loss": -43.59342234802246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.55589985847473, "step": 79000}
{"episode_reward": 588.8693788379701, "episode": 80.0, "batch_reward": 0.47468641415238383, "critic_loss": 1.121207390010357, "actor_loss": -43.64129319763184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.794161081314087, "step": 80000}
{"episode_reward": 639.0663846210749, "episode": 81.0, "batch_reward": 0.47651432478427885, "critic_loss": 1.1123069427609444, "actor_loss": -43.53725762939453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.13890528678894, "step": 81000}
{"episode_reward": 542.6820258513417, "episode": 82.0, "batch_reward": 0.47748179388046263, "critic_loss": 1.0553596390485764, "actor_loss": -43.41349843597412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.057912826538086, "step": 82000}
{"episode_reward": 654.2464203217737, "episode": 83.0, "batch_reward": 0.480428345233202, "critic_loss": 1.0687378515601158, "actor_loss": -43.87153798675537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.35982036590576, "step": 83000}
{"episode_reward": 576.7288643912009, "episode": 84.0, "batch_reward": 0.4806517426073551, "critic_loss": 1.0466867217421532, "actor_loss": -44.298520122528075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.365593194961548, "step": 84000}
{"episode_reward": 594.1812235218713, "episode": 85.0, "batch_reward": 0.48137651759386063, "critic_loss": 1.0681153568029405, "actor_loss": -44.16742059326172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.76867151260376, "step": 85000}
{"episode_reward": 598.1998632146369, "episode": 86.0, "batch_reward": 0.48374822390079497, "critic_loss": 1.0822980242967606, "actor_loss": -43.89775629425049, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.36288619041443, "step": 86000}
{"episode_reward": 627.0833807191829, "episode": 87.0, "batch_reward": 0.48526041287183763, "critic_loss": 1.10031835603714, "actor_loss": -44.866361156463626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.232221603393555, "step": 87000}
{"episode_reward": 645.9694362559317, "episode": 88.0, "batch_reward": 0.487218301653862, "critic_loss": 1.0830425419211387, "actor_loss": -44.39119622039795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16470432281494, "step": 88000}
{"episode_reward": 636.2267629864789, "episode": 89.0, "batch_reward": 0.489376094698906, "critic_loss": 1.085395601451397, "actor_loss": -44.57057071685791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.964887380599976, "step": 89000}
{"episode_reward": 546.7664264156202, "episode": 90.0, "batch_reward": 0.48899343648552895, "critic_loss": 1.1223876999616622, "actor_loss": -44.56116831970215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.263224840164185, "step": 90000}
{"episode_reward": 573.3739351899143, "episode": 91.0, "batch_reward": 0.4900895039737225, "critic_loss": 1.1684920404553414, "actor_loss": -44.61640436553955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.59288573265076, "step": 91000}
{"episode_reward": 585.7209224735589, "episode": 92.0, "batch_reward": 0.4910981840789318, "critic_loss": 1.1393482939600945, "actor_loss": -45.02217756652832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.571941375732422, "step": 92000}
{"episode_reward": 622.5880935837707, "episode": 93.0, "batch_reward": 0.4928287642598152, "critic_loss": 1.110689470589161, "actor_loss": -44.895527404785156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.29686737060547, "step": 93000}
{"episode_reward": 635.1953643961797, "episode": 94.0, "batch_reward": 0.49456272467970847, "critic_loss": 1.125678281545639, "actor_loss": -45.35626587677002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.58307433128357, "step": 94000}
{"episode_reward": 547.8278722386176, "episode": 95.0, "batch_reward": 0.4966500913500786, "critic_loss": 1.1443501436114312, "actor_loss": -45.760432022094726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.689191579818726, "step": 95000}
{"episode_reward": 670.3878387144396, "episode": 96.0, "batch_reward": 0.49766998302936555, "critic_loss": 1.1716181059479713, "actor_loss": -45.721734497070315, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.102097749710083, "step": 96000}
{"episode_reward": 581.330866668761, "episode": 97.0, "batch_reward": 0.49711352682113646, "critic_loss": 1.1505820697546005, "actor_loss": -45.24963226318359, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.61300563812256, "step": 97000}
{"episode_reward": 653.7160183852012, "episode": 98.0, "batch_reward": 0.49874663025140764, "critic_loss": 1.1219046201705933, "actor_loss": -46.28347756195068, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.926798582077026, "step": 98000}
{"episode_reward": 646.0050942289054, "episode": 99.0, "batch_reward": 0.5002988770008087, "critic_loss": 1.1236062903404236, "actor_loss": -45.67877653503418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.85917854309082, "step": 99000}
{"episode_reward": 611.2035726370507, "episode": 100.0, "batch_reward": 0.5024529202580452, "critic_loss": 1.121094494819641, "actor_loss": -45.994965400695804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.879766702651978, "step": 100000}
{"episode_reward": 679.025411797369, "episode": 101.0, "batch_reward": 0.5033838500380516, "critic_loss": 1.1214978259801864, "actor_loss": -45.92164786529541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.37326455116272, "step": 101000}
{"episode_reward": 653.1232381678514, "episode": 102.0, "batch_reward": 0.5056598947644234, "critic_loss": 1.1726372538805008, "actor_loss": -46.575467338562014, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.865623235702515, "step": 102000}
{"episode_reward": 612.8929099171528, "episode": 103.0, "batch_reward": 0.5052395431101322, "critic_loss": 1.1853853738903999, "actor_loss": -46.2005553894043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.293601751327515, "step": 103000}
{"episode_reward": 530.6807554658473, "episode": 104.0, "batch_reward": 0.5055160282552242, "critic_loss": 1.1392070274353028, "actor_loss": -46.14043522644043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.809929132461548, "step": 104000}
{"episode_reward": 672.7526714825653, "episode": 105.0, "batch_reward": 0.5080088742077351, "critic_loss": 1.1389705813527107, "actor_loss": -46.5632943649292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.777920484542847, "step": 105000}
{"episode_reward": 660.4577896322497, "episode": 106.0, "batch_reward": 0.5097524825036526, "critic_loss": 1.1151651549935342, "actor_loss": -46.691961318969724, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.632691144943237, "step": 106000}
{"episode_reward": 628.5382177463779, "episode": 107.0, "batch_reward": 0.5104721505641937, "critic_loss": 1.1503994103074073, "actor_loss": -46.29004042816162, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.330108404159546, "step": 107000}
{"episode_reward": 671.9159532643578, "episode": 108.0, "batch_reward": 0.5099541096389294, "critic_loss": 1.1576517471075058, "actor_loss": -46.94781552124024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.557788372039795, "step": 108000}
{"episode_reward": 109.85475701629643, "episode": 109.0, "batch_reward": 0.5086000162959099, "critic_loss": 1.1339740048050881, "actor_loss": -46.52235382843018, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.0066339969635, "step": 109000}
{"episode_reward": 630.4385690369094, "episode": 110.0, "batch_reward": 0.5096524563133716, "critic_loss": 1.1838614909648895, "actor_loss": -47.04279901123047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.438748598098755, "step": 110000}
{"episode_reward": 604.1370121795647, "episode": 111.0, "batch_reward": 0.5100440531671048, "critic_loss": 1.160369665324688, "actor_loss": -46.44719699859619, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.907227516174316, "step": 111000}
{"episode_reward": 604.6403883249894, "episode": 112.0, "batch_reward": 0.5108641091883183, "critic_loss": 1.2310606169104577, "actor_loss": -47.03037059783936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.560194730758667, "step": 112000}
{"episode_reward": 590.8773297946802, "episode": 113.0, "batch_reward": 0.5119979557693004, "critic_loss": 1.1818154475688933, "actor_loss": -46.81710794067383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.325538158416748, "step": 113000}
{"episode_reward": 645.2129221638232, "episode": 114.0, "batch_reward": 0.5133453640937805, "critic_loss": 1.247935463488102, "actor_loss": -47.092119506835935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.23220157623291, "step": 114000}
{"episode_reward": 658.8614207255041, "episode": 115.0, "batch_reward": 0.5153402694761753, "critic_loss": 1.2105014156103133, "actor_loss": -47.241268699646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.602524518966675, "step": 115000}
{"episode_reward": 670.4970909397507, "episode": 116.0, "batch_reward": 0.5158217167258262, "critic_loss": 1.2295484862327575, "actor_loss": -47.244040946960446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.930926084518433, "step": 116000}
{"episode_reward": 657.2707594946695, "episode": 117.0, "batch_reward": 0.5168541168570518, "critic_loss": 1.2191030342578888, "actor_loss": -47.232118461608884, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.368387937545776, "step": 117000}
{"episode_reward": 659.1183844656456, "episode": 118.0, "batch_reward": 0.5181980023980141, "critic_loss": 1.2772383682131767, "actor_loss": -47.26256511688232, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.28367829322815, "step": 118000}
{"episode_reward": 615.2325669305801, "episode": 119.0, "batch_reward": 0.5196260290443897, "critic_loss": 1.2927420483827592, "actor_loss": -47.52057997894287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.50631093978882, "step": 119000}
{"episode_reward": 671.1787438693991, "episode": 120.0, "batch_reward": 0.5198882279992103, "critic_loss": 1.2594423598647118, "actor_loss": -47.464116233825685, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.62535309791565, "step": 120000}
{"episode_reward": 654.6476434517721, "episode": 121.0, "batch_reward": 0.5212248082756996, "critic_loss": 1.2785921465158463, "actor_loss": -47.681863609313965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.806578159332275, "step": 121000}
{"episode_reward": 652.5898135316319, "episode": 122.0, "batch_reward": 0.5227055508196354, "critic_loss": 1.244980637729168, "actor_loss": -48.060804008483885, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.32430410385132, "step": 122000}
{"episode_reward": 668.6758031011192, "episode": 123.0, "batch_reward": 0.5233163207173347, "critic_loss": 1.2849306408762933, "actor_loss": -48.08062451934814, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.913893222808838, "step": 123000}
{"episode_reward": 630.0258873577267, "episode": 124.0, "batch_reward": 0.5242511016726494, "critic_loss": 1.2795311255455017, "actor_loss": -48.16120339202881, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.612457275390625, "step": 124000}
{"episode_reward": 655.2133200617304, "episode": 125.0, "batch_reward": 0.5250679710805416, "critic_loss": 1.330734330713749, "actor_loss": -48.09896168518066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.724679231643677, "step": 125000}
{"episode_reward": 411.4488291931118, "episode": 126.0, "batch_reward": 0.5242987674772739, "critic_loss": 1.4078617424368858, "actor_loss": -48.069132804870605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.48008632659912, "step": 126000}
{"episode_reward": 647.3048336017946, "episode": 127.0, "batch_reward": 0.5245927158892155, "critic_loss": 1.4959761523008346, "actor_loss": -48.14608528137207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.742791414260864, "step": 127000}
{"episode_reward": 599.7826449106059, "episode": 128.0, "batch_reward": 0.5257098665237426, "critic_loss": 1.4401615983843803, "actor_loss": -48.2360897064209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.131843090057373, "step": 128000}
{"episode_reward": 661.7955301507006, "episode": 129.0, "batch_reward": 0.5269734864234924, "critic_loss": 1.3804749853610991, "actor_loss": -48.17977773284912, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.849032402038574, "step": 129000}
{"episode_reward": 654.7089958520963, "episode": 130.0, "batch_reward": 0.5272814397811889, "critic_loss": 1.4400175634622574, "actor_loss": -48.33929902648926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.779923915863037, "step": 130000}
{"episode_reward": 205.07456570638584, "episode": 131.0, "batch_reward": 0.5265509069561959, "critic_loss": 1.5068623349666594, "actor_loss": -47.836503921508786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.113327741622925, "step": 131000}
{"episode_reward": 673.0383900037955, "episode": 132.0, "batch_reward": 0.5266498260200023, "critic_loss": 1.4493080325722694, "actor_loss": -48.40553887176514, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.073640823364258, "step": 132000}
{"episode_reward": 608.8561973427704, "episode": 133.0, "batch_reward": 0.5283755284249783, "critic_loss": 1.4923666107058524, "actor_loss": -48.27073185729981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.716192483901978, "step": 133000}
{"episode_reward": 623.2782180577212, "episode": 134.0, "batch_reward": 0.5277909260690212, "critic_loss": 1.5518427614569663, "actor_loss": -48.28800999450684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.850109338760376, "step": 134000}
{"episode_reward": 663.061730408059, "episode": 135.0, "batch_reward": 0.5287874193489551, "critic_loss": 1.4978373478055, "actor_loss": -48.70223084259033, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.774152040481567, "step": 135000}
{"episode_reward": 651.2131531862498, "episode": 136.0, "batch_reward": 0.529748123973608, "critic_loss": 1.6028856340050697, "actor_loss": -48.43877217102051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.374555826187134, "step": 136000}
{"episode_reward": 489.89318929792483, "episode": 137.0, "batch_reward": 0.5297998397648335, "critic_loss": 1.7119807562828064, "actor_loss": -48.390540046691896, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.143075466156006, "step": 137000}
{"episode_reward": 665.4594341146727, "episode": 138.0, "batch_reward": 0.5310524770915508, "critic_loss": 1.7158245067000388, "actor_loss": -48.48025943756104, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.846120357513428, "step": 138000}
{"episode_reward": 639.8057562986319, "episode": 139.0, "batch_reward": 0.5308770287334919, "critic_loss": 1.7329708020091057, "actor_loss": -48.3969769744873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.847776412963867, "step": 139000}
{"episode_reward": 411.4229786421202, "episode": 140.0, "batch_reward": 0.5301671184599399, "critic_loss": 1.7494979739189147, "actor_loss": -48.553232604980465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.22196078300476, "step": 140000}
{"episode_reward": 653.181392250706, "episode": 141.0, "batch_reward": 0.5320810996592045, "critic_loss": 1.6856647003889085, "actor_loss": -48.58658317565918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.14895844459534, "step": 141000}
{"episode_reward": 668.7170593887223, "episode": 142.0, "batch_reward": 0.5333248643875123, "critic_loss": 1.7195442329645156, "actor_loss": -48.53219173431396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.098017692565918, "step": 142000}
{"episode_reward": 637.1233671327797, "episode": 143.0, "batch_reward": 0.534006877630949, "critic_loss": 1.7620654720067979, "actor_loss": -48.63553063964844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.925124883651733, "step": 143000}
{"episode_reward": 665.0457139507279, "episode": 144.0, "batch_reward": 0.5346948715746402, "critic_loss": 1.6832986583709717, "actor_loss": -49.148206245422365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.620187044143677, "step": 144000}
{"episode_reward": 651.2192497425369, "episode": 145.0, "batch_reward": 0.5357652993798256, "critic_loss": 1.602617505788803, "actor_loss": -48.70369731140137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.768083572387695, "step": 145000}
{"episode_reward": 657.4948694060249, "episode": 146.0, "batch_reward": 0.5355893022716045, "critic_loss": 1.640038745343685, "actor_loss": -48.35086688232422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.819911003112793, "step": 146000}
{"episode_reward": 663.4458045535979, "episode": 147.0, "batch_reward": 0.5356821438074112, "critic_loss": 1.5991150190234185, "actor_loss": -48.72739475250244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.745877981185913, "step": 147000}
{"episode_reward": 586.5845648053177, "episode": 148.0, "batch_reward": 0.5372740654349327, "critic_loss": 1.603623875439167, "actor_loss": -49.00422142791748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.633436918258667, "step": 148000}
{"episode_reward": 612.1160891074155, "episode": 149.0, "batch_reward": 0.5371662431359291, "critic_loss": 1.5979309087395668, "actor_loss": -48.91961754608154, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60892605781555, "step": 149000}
