{"episode_reward": 0.0, "episode": 1.0, "duration": 17.385470390319824, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.4960999488830566, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.26206992814027297, "critic_loss": 0.05073316070950202, "actor_loss": -33.383152344125826, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 61.44797921180725, "step": 3000}
{"episode_reward": 20.171433174604573, "episode": 4.0, "batch_reward": 0.17240003520250322, "critic_loss": 0.07580322841927409, "actor_loss": -25.82348621082306, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.79878568649292, "step": 4000}
{"episode_reward": 30.87512255606163, "episode": 5.0, "batch_reward": 0.14995672370493413, "critic_loss": 0.07587931042164564, "actor_loss": -20.831241728544235, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.963472604751587, "step": 5000}
{"episode_reward": 107.85930570824165, "episode": 6.0, "batch_reward": 0.13765700787305832, "critic_loss": 0.07968821160122752, "actor_loss": -21.706943291664125, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.37977433204651, "step": 6000}
{"episode_reward": 116.86692114037918, "episode": 7.0, "batch_reward": 0.1379375262632966, "critic_loss": 0.09814877478033304, "actor_loss": -21.08857552242279, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.703330516815186, "step": 7000}
{"episode_reward": 110.310165866835, "episode": 8.0, "batch_reward": 0.13957385360449553, "critic_loss": 0.10274478790909052, "actor_loss": -20.390808637142182, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.904441118240356, "step": 8000}
{"episode_reward": 244.03636691764598, "episode": 9.0, "batch_reward": 0.15315138816833496, "critic_loss": 0.1179398462548852, "actor_loss": -21.21594558709115, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.286933422088623, "step": 9000}
{"episode_reward": 169.69392548773834, "episode": 10.0, "batch_reward": 0.1513746564015746, "critic_loss": 0.12889070197194816, "actor_loss": -20.509555539131163, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.684362411499023, "step": 10000}
{"episode_reward": 122.4145660443863, "episode": 11.0, "batch_reward": 0.14775259762257337, "critic_loss": 0.11885791661962866, "actor_loss": -19.430160075157882, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.320629358291626, "step": 11000}
{"episode_reward": 79.87257505901053, "episode": 12.0, "batch_reward": 0.1413296222984791, "critic_loss": 0.1367401022426784, "actor_loss": -18.638936603069304, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.864428520202637, "step": 12000}
{"episode_reward": 182.4145052378306, "episode": 13.0, "batch_reward": 0.14431614550948144, "critic_loss": 0.1632488364726305, "actor_loss": -18.83143302810192, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.956038236618042, "step": 13000}
{"episode_reward": 79.31686858575887, "episode": 14.0, "batch_reward": 0.13983595924079417, "critic_loss": 0.18016543325781822, "actor_loss": -17.887282881498336, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.108519315719604, "step": 14000}
{"episode_reward": 92.15985033797062, "episode": 15.0, "batch_reward": 0.1366751848831773, "critic_loss": 0.16988332714140414, "actor_loss": -18.255581505775453, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.844083070755005, "step": 15000}
{"episode_reward": 110.47554746114794, "episode": 16.0, "batch_reward": 0.13634769112616776, "critic_loss": 0.17633714743703605, "actor_loss": -17.792195976138114, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.686530828475952, "step": 16000}
{"episode_reward": 199.7170027223601, "episode": 17.0, "batch_reward": 0.13579778994619846, "critic_loss": 0.19329819333553314, "actor_loss": -17.22384841179848, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.594998121261597, "step": 17000}
{"episode_reward": 33.90251258873387, "episode": 18.0, "batch_reward": 0.1324635246694088, "critic_loss": 0.17246239016205073, "actor_loss": -17.11858679819107, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.581799507141113, "step": 18000}
{"episode_reward": 86.54250308045152, "episode": 19.0, "batch_reward": 0.13063811614364385, "critic_loss": 0.1667585923448205, "actor_loss": -16.92999027737975, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.70496702194214, "step": 19000}
{"episode_reward": 102.61702661710905, "episode": 20.0, "batch_reward": 0.12769628781080247, "critic_loss": 0.1555448395460844, "actor_loss": -17.095716766119004, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.54804754257202, "step": 20000}
{"episode_reward": 52.17124699885461, "episode": 21.0, "batch_reward": 0.12654693246632814, "critic_loss": 0.16520636492222548, "actor_loss": -15.534592795312404, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.539391040802, "step": 21000}
{"episode_reward": 192.45597742533968, "episode": 22.0, "batch_reward": 0.12750318519771098, "critic_loss": 0.1824401417300105, "actor_loss": -16.457911261320113, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.20605206489563, "step": 22000}
{"episode_reward": 62.854733056824124, "episode": 23.0, "batch_reward": 0.12720402082800866, "critic_loss": 0.2043113498389721, "actor_loss": -15.883348819613456, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.012876510620117, "step": 23000}
{"episode_reward": 151.8808705363343, "episode": 24.0, "batch_reward": 0.1265156255438924, "critic_loss": 0.2014233376532793, "actor_loss": -16.257957487523555, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.842310667037964, "step": 24000}
{"episode_reward": 93.17459873199898, "episode": 25.0, "batch_reward": 0.12684745182842017, "critic_loss": 0.19297953464835882, "actor_loss": -16.537825360804796, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.393435955047607, "step": 25000}
{"episode_reward": 147.01645914919948, "episode": 26.0, "batch_reward": 0.1277732902020216, "critic_loss": 0.19951448356360196, "actor_loss": -16.131507992520927, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.998921632766724, "step": 26000}
{"episode_reward": 170.9600098014378, "episode": 27.0, "batch_reward": 0.12744417157769203, "critic_loss": 0.19678443694859743, "actor_loss": -16.422760257601738, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.707340955734253, "step": 27000}
{"episode_reward": 75.10634023615506, "episode": 28.0, "batch_reward": 0.12470459137111903, "critic_loss": 0.19965818887203932, "actor_loss": -15.859005883768202, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.764626502990723, "step": 28000}
{"episode_reward": 59.865106019100935, "episode": 29.0, "batch_reward": 0.12450791895389557, "critic_loss": 0.20887484151870012, "actor_loss": -16.144413251936435, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.868476629257202, "step": 29000}
{"episode_reward": 174.20922716322298, "episode": 30.0, "batch_reward": 0.12439149410277606, "critic_loss": 0.20802278679609298, "actor_loss": -15.448899392127991, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.72213649749756, "step": 30000}
{"episode_reward": 36.299500193968704, "episode": 31.0, "batch_reward": 0.12299800912290812, "critic_loss": 0.23070851372927428, "actor_loss": -16.1013806399703, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.76576519012451, "step": 31000}
{"episode_reward": 142.16244963040197, "episode": 32.0, "batch_reward": 0.12488318689167499, "critic_loss": 0.23041552280634642, "actor_loss": -16.41441458618641, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.21674108505249, "step": 32000}
{"episode_reward": 173.28081972279543, "episode": 33.0, "batch_reward": 0.1258551073372364, "critic_loss": 0.24651853033155202, "actor_loss": -16.596151831388475, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.16819739341736, "step": 33000}
{"episode_reward": 226.29092623265416, "episode": 34.0, "batch_reward": 0.12848938650637864, "critic_loss": 0.26252148451656104, "actor_loss": -16.859293211340905, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.231961250305176, "step": 34000}
{"episode_reward": 124.34680473142237, "episode": 35.0, "batch_reward": 0.127977023139596, "critic_loss": 0.2590959982872009, "actor_loss": -16.671793588161467, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.595334768295288, "step": 35000}
{"episode_reward": 172.88623450781756, "episode": 36.0, "batch_reward": 0.1279076797813177, "critic_loss": 0.25662990285456183, "actor_loss": -16.82602658700943, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.72995400428772, "step": 36000}
{"episode_reward": 46.55391431665553, "episode": 37.0, "batch_reward": 0.12857777278870344, "critic_loss": 0.2751557580679655, "actor_loss": -16.379649478912352, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.007860898971558, "step": 37000}
{"episode_reward": 301.8836695500993, "episode": 38.0, "batch_reward": 0.13122311630100011, "critic_loss": 0.2914216156601906, "actor_loss": -16.335743577718734, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.906280994415283, "step": 38000}
{"episode_reward": 119.92665600129261, "episode": 39.0, "batch_reward": 0.13297745294868946, "critic_loss": 0.3109586306810379, "actor_loss": -16.434252899646758, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.74670958518982, "step": 39000}
{"episode_reward": 202.3084339870084, "episode": 40.0, "batch_reward": 0.1330865136384964, "critic_loss": 0.3108469727188349, "actor_loss": -16.644629190921783, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.909807205200195, "step": 40000}
{"episode_reward": 164.31359320038752, "episode": 41.0, "batch_reward": 0.13383800807595253, "critic_loss": 0.35262212285399436, "actor_loss": -16.564755158901214, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.4875602722168, "step": 41000}
{"episode_reward": 151.57141702273069, "episode": 42.0, "batch_reward": 0.13336827901750803, "critic_loss": 0.3509942537844181, "actor_loss": -16.629787545204163, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.770357847213745, "step": 42000}
{"episode_reward": 90.21386178043367, "episode": 43.0, "batch_reward": 0.13330546386539935, "critic_loss": 0.34076302690804006, "actor_loss": -16.69881996393204, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.87158751487732, "step": 43000}
{"episode_reward": 162.53789255294177, "episode": 44.0, "batch_reward": 0.1338422257527709, "critic_loss": 0.35428521391749385, "actor_loss": -17.740342772960663, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.096962451934814, "step": 44000}
{"episode_reward": 244.12738275412545, "episode": 45.0, "batch_reward": 0.1372053880020976, "critic_loss": 0.3631952351629734, "actor_loss": -17.27648160982132, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.20639133453369, "step": 45000}
{"episode_reward": 205.46102115292595, "episode": 46.0, "batch_reward": 0.13778417779505253, "critic_loss": 0.4001597454100847, "actor_loss": -16.795953149318695, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.80817747116089, "step": 46000}
{"episode_reward": 217.76361494966454, "episode": 47.0, "batch_reward": 0.13903479209542274, "critic_loss": 0.4098104527294636, "actor_loss": -17.366446473121645, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.76651167869568, "step": 47000}
{"episode_reward": 114.51481613947527, "episode": 48.0, "batch_reward": 0.13764191245287657, "critic_loss": 0.3908658500760794, "actor_loss": -16.893327561855315, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.26620388031006, "step": 48000}
{"episode_reward": 46.139635684617886, "episode": 49.0, "batch_reward": 0.13715771057456733, "critic_loss": 0.3774563214927912, "actor_loss": -17.624077514648437, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.760716199874878, "step": 49000}
{"episode_reward": 237.09881332884774, "episode": 50.0, "batch_reward": 0.13929385823011398, "critic_loss": 0.4386147758066654, "actor_loss": -17.614223545074463, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.63194990158081, "step": 50000}
{"episode_reward": 225.43079475548265, "episode": 51.0, "batch_reward": 0.14248999333381654, "critic_loss": 0.43964750991761686, "actor_loss": -17.729134293556214, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.47012257575989, "step": 51000}
{"episode_reward": 191.5597925861162, "episode": 52.0, "batch_reward": 0.14256709191203118, "critic_loss": 0.45082673032581805, "actor_loss": -17.54044331073761, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.54216766357422, "step": 52000}
{"episode_reward": 238.05558295187515, "episode": 53.0, "batch_reward": 0.1440640595406294, "critic_loss": 0.4241704219132662, "actor_loss": -18.224337903022764, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.775030374526978, "step": 53000}
{"episode_reward": 196.9981792017818, "episode": 54.0, "batch_reward": 0.14583641589432955, "critic_loss": 0.40549539555609226, "actor_loss": -18.589030272483825, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.22605538368225, "step": 54000}
{"episode_reward": 300.342906012436, "episode": 55.0, "batch_reward": 0.14875612001121044, "critic_loss": 0.40983951757848264, "actor_loss": -18.54735530757904, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.378390789031982, "step": 55000}
{"episode_reward": 264.14094950385834, "episode": 56.0, "batch_reward": 0.14922385849058628, "critic_loss": 0.40462344340980055, "actor_loss": -18.59289328479767, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.740726470947266, "step": 56000}
{"episode_reward": 114.14921660176687, "episode": 57.0, "batch_reward": 0.1494611385911703, "critic_loss": 0.4016246803402901, "actor_loss": -18.53539650630951, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.823782205581665, "step": 57000}
{"episode_reward": 195.783962345799, "episode": 58.0, "batch_reward": 0.15076835525780916, "critic_loss": 0.40625506176054477, "actor_loss": -18.894331048965455, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.30223250389099, "step": 58000}
{"episode_reward": 340.93560344007443, "episode": 59.0, "batch_reward": 0.1538744643703103, "critic_loss": 0.4062676268965006, "actor_loss": -19.02599209499359, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.688596487045288, "step": 59000}
{"episode_reward": 307.38429896227785, "episode": 60.0, "batch_reward": 0.15571022912859916, "critic_loss": 0.4410314947515726, "actor_loss": -18.94775692272186, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.61837935447693, "step": 60000}
{"episode_reward": 212.01396250073506, "episode": 61.0, "batch_reward": 0.1572693520411849, "critic_loss": 0.38951722952723505, "actor_loss": -19.048000930786134, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.74078297615051, "step": 61000}
{"episode_reward": 145.42564379464213, "episode": 62.0, "batch_reward": 0.15665517176687718, "critic_loss": 0.36865233778953554, "actor_loss": -19.031866200447084, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.30103039741516, "step": 62000}
{"episode_reward": 153.293516654808, "episode": 63.0, "batch_reward": 0.15800103683024644, "critic_loss": 0.36708913181722164, "actor_loss": -19.076151648521424, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.05316185951233, "step": 63000}
{"episode_reward": 406.14963029460546, "episode": 64.0, "batch_reward": 0.16103248743712903, "critic_loss": 0.3856498287022114, "actor_loss": -19.54502285194397, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.27759075164795, "step": 64000}
{"episode_reward": 315.16566593317, "episode": 65.0, "batch_reward": 0.16311705760657788, "critic_loss": 0.4061863605231047, "actor_loss": -19.456738195419312, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.89036798477173, "step": 65000}
{"episode_reward": 211.7089958234403, "episode": 66.0, "batch_reward": 0.16344014283269645, "critic_loss": 0.39443436108529567, "actor_loss": -19.49878440284729, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.27284288406372, "step": 66000}
{"episode_reward": 79.92045664349402, "episode": 67.0, "batch_reward": 0.16253032655268906, "critic_loss": 0.36221133629977703, "actor_loss": -19.759284329414367, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.26495361328125, "step": 67000}
{"episode_reward": 87.18012520391999, "episode": 68.0, "batch_reward": 0.16043431001901626, "critic_loss": 0.40024379861354825, "actor_loss": -20.018677131652833, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.94029474258423, "step": 68000}
{"episode_reward": 70.82919040816407, "episode": 69.0, "batch_reward": 0.1601046435907483, "critic_loss": 0.35776806516945364, "actor_loss": -18.99448924636841, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.896369457244873, "step": 69000}
{"episode_reward": 164.96579853263202, "episode": 70.0, "batch_reward": 0.15961708924919366, "critic_loss": 0.3607475223839283, "actor_loss": -19.05535578250885, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.759138107299805, "step": 70000}
{"episode_reward": 91.84901153299143, "episode": 71.0, "batch_reward": 0.15959230678528546, "critic_loss": 0.3778907723873854, "actor_loss": -18.761758266448975, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.026280879974365, "step": 71000}
{"episode_reward": 170.2220486593509, "episode": 72.0, "batch_reward": 0.1599869830533862, "critic_loss": 0.4066962423324585, "actor_loss": -19.39107628059387, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.556610822677612, "step": 72000}
{"episode_reward": 261.87956845956074, "episode": 73.0, "batch_reward": 0.16178855703026057, "critic_loss": 0.3912388719022274, "actor_loss": -19.606645482063293, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.673855781555176, "step": 73000}
{"episode_reward": 298.0713704995236, "episode": 74.0, "batch_reward": 0.16299251140654086, "critic_loss": 0.3773369449675083, "actor_loss": -19.198575600624086, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.40649962425232, "step": 74000}
{"episode_reward": 308.86672429297164, "episode": 75.0, "batch_reward": 0.16451523424685002, "critic_loss": 0.3908622466772795, "actor_loss": -19.29442931175232, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.91021752357483, "step": 75000}
{"episode_reward": 160.8507621064792, "episode": 76.0, "batch_reward": 0.16532451362907888, "critic_loss": 0.3932628693729639, "actor_loss": -19.550773043632507, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.115779399871826, "step": 76000}
{"episode_reward": 365.456814727841, "episode": 77.0, "batch_reward": 0.16783023077994585, "critic_loss": 0.429066384896636, "actor_loss": -19.647660573005677, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.868634700775146, "step": 77000}
{"episode_reward": 326.1314898727388, "episode": 78.0, "batch_reward": 0.16837087988853455, "critic_loss": 0.4007097378820181, "actor_loss": -19.865868176460268, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.03604793548584, "step": 78000}
{"episode_reward": 59.09236142772332, "episode": 79.0, "batch_reward": 0.16867160593718292, "critic_loss": 0.38048658649623396, "actor_loss": -20.326497266769408, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.243019342422485, "step": 79000}
{"episode_reward": 265.690553281176, "episode": 80.0, "batch_reward": 0.17091017961502075, "critic_loss": 0.41314750760793684, "actor_loss": -20.186597654342652, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.695935249328613, "step": 80000}
{"episode_reward": 403.59223245775945, "episode": 81.0, "batch_reward": 0.17248055347800254, "critic_loss": 0.4063164699077606, "actor_loss": -19.773146671295166, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.53417229652405, "step": 81000}
{"episode_reward": 451.31877958431863, "episode": 82.0, "batch_reward": 0.17632185187935828, "critic_loss": 0.4106629995405674, "actor_loss": -20.307709671020508, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.683186292648315, "step": 82000}
{"episode_reward": 368.35253541197625, "episode": 83.0, "batch_reward": 0.17921243664622308, "critic_loss": 0.427494810000062, "actor_loss": -20.802167932510375, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.35929536819458, "step": 83000}
{"episode_reward": 377.5693560346789, "episode": 84.0, "batch_reward": 0.18116733019053935, "critic_loss": 0.42334408101439475, "actor_loss": -21.24097478103638, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.959266662597656, "step": 84000}
{"episode_reward": 459.3103909843697, "episode": 85.0, "batch_reward": 0.18269785352051257, "critic_loss": 0.38472548854351046, "actor_loss": -21.078933314323425, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.257690906524658, "step": 85000}
{"episode_reward": 67.9364488974535, "episode": 86.0, "batch_reward": 0.18238689316809178, "critic_loss": 0.40831795093417167, "actor_loss": -21.059222832679747, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.0739164352417, "step": 86000}
{"episode_reward": 378.4205865540658, "episode": 87.0, "batch_reward": 0.1851468262374401, "critic_loss": 0.4164212233275175, "actor_loss": -21.507174293518066, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.129950284957886, "step": 87000}
{"episode_reward": 367.7728662742669, "episode": 88.0, "batch_reward": 0.18512679205834864, "critic_loss": 0.3954213318526745, "actor_loss": -21.07181871509552, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.03091788291931, "step": 88000}
{"episode_reward": 120.023089058335, "episode": 89.0, "batch_reward": 0.18593789233267308, "critic_loss": 0.3869023367911577, "actor_loss": -21.38211612033844, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.70753812789917, "step": 89000}
{"episode_reward": 297.3406936774423, "episode": 90.0, "batch_reward": 0.18738265988230704, "critic_loss": 0.3515735312253237, "actor_loss": -21.205342678070068, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.99136209487915, "step": 90000}
{"episode_reward": 77.78495024691178, "episode": 91.0, "batch_reward": 0.18694432684779166, "critic_loss": 0.3689967489093542, "actor_loss": -21.232633190155028, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.439218521118164, "step": 91000}
{"episode_reward": 236.0369848435513, "episode": 92.0, "batch_reward": 0.18721216988563538, "critic_loss": 0.3684786946922541, "actor_loss": -21.83503563117981, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.844342947006226, "step": 92000}
{"episode_reward": 150.4787594566746, "episode": 93.0, "batch_reward": 0.18602820889651775, "critic_loss": 0.3736399408131838, "actor_loss": -21.035711187362672, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.458314180374146, "step": 93000}
{"episode_reward": 214.59508712151825, "episode": 94.0, "batch_reward": 0.18683266825973988, "critic_loss": 0.3772713627815247, "actor_loss": -21.479226090431215, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.701783895492554, "step": 94000}
{"episode_reward": 406.64424877535544, "episode": 95.0, "batch_reward": 0.18882767724990845, "critic_loss": 0.38961932715773584, "actor_loss": -22.004331159591676, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.36442255973816, "step": 95000}
{"episode_reward": 222.35964033277364, "episode": 96.0, "batch_reward": 0.19023524928092955, "critic_loss": 0.4020445749759674, "actor_loss": -22.05590340423584, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.829138040542603, "step": 96000}
{"episode_reward": 440.9354044920019, "episode": 97.0, "batch_reward": 0.1925038573294878, "critic_loss": 0.4139020067602396, "actor_loss": -21.852880168914794, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.713240385055542, "step": 97000}
{"episode_reward": 395.73699812136454, "episode": 98.0, "batch_reward": 0.19373652045428752, "critic_loss": 0.43933599495887754, "actor_loss": -22.42884127807617, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.222814798355103, "step": 98000}
{"episode_reward": 325.4429760732712, "episode": 99.0, "batch_reward": 0.19478242425620557, "critic_loss": 0.42642554084956646, "actor_loss": -21.993401174545287, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.008214235305786, "step": 99000}
{"episode_reward": 366.2377552715666, "episode": 100.0, "batch_reward": 0.19756697070598603, "critic_loss": 0.42827519510686396, "actor_loss": -22.5959672832489, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.684982299804688, "step": 100000}
{"episode_reward": 405.1589695606907, "episode": 101.0, "batch_reward": 0.19956576581299304, "critic_loss": 0.42486682650446894, "actor_loss": -22.229446195602417, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.41738772392273, "step": 101000}
{"episode_reward": 328.2868180963838, "episode": 102.0, "batch_reward": 0.20098352733254432, "critic_loss": 0.4369946365952492, "actor_loss": -22.83136777114868, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.423095226287842, "step": 102000}
{"episode_reward": 314.91603489429184, "episode": 103.0, "batch_reward": 0.2006450513601303, "critic_loss": 0.467380726352334, "actor_loss": -22.272047748565672, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.700815439224243, "step": 103000}
{"episode_reward": 29.67338552615493, "episode": 104.0, "batch_reward": 0.20061879788339138, "critic_loss": 0.47622975362837316, "actor_loss": -22.21814336490631, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.991111278533936, "step": 104000}
{"episode_reward": 413.0122758968341, "episode": 105.0, "batch_reward": 0.2017650522738695, "critic_loss": 0.48487891581654546, "actor_loss": -22.553375619888307, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.559695959091187, "step": 105000}
{"episode_reward": 343.23535072679203, "episode": 106.0, "batch_reward": 0.20314819003641604, "critic_loss": 0.4898954509943724, "actor_loss": -22.593462047576903, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.67176866531372, "step": 106000}
{"episode_reward": 353.2354962307102, "episode": 107.0, "batch_reward": 0.20470230254530908, "critic_loss": 0.5343308931589127, "actor_loss": -22.299095775604247, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.062837839126587, "step": 107000}
{"episode_reward": 219.9040786090117, "episode": 108.0, "batch_reward": 0.2058711176365614, "critic_loss": 0.5414365109801292, "actor_loss": -22.981635610580444, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.16751265525818, "step": 108000}
{"episode_reward": 417.3038260471684, "episode": 109.0, "batch_reward": 0.2060777348279953, "critic_loss": 0.5741593209505081, "actor_loss": -22.802546875, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.780926942825317, "step": 109000}
{"episode_reward": 185.10485818267125, "episode": 110.0, "batch_reward": 0.20752568390965462, "critic_loss": 0.5738875198662281, "actor_loss": -23.460009815216065, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.046259880065918, "step": 110000}
{"episode_reward": 377.5250847012386, "episode": 111.0, "batch_reward": 0.2087862771600485, "critic_loss": 0.584573969990015, "actor_loss": -23.080530557632446, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.246745109558105, "step": 111000}
{"episode_reward": 421.50981993204067, "episode": 112.0, "batch_reward": 0.21074433729052544, "critic_loss": 0.5709102870821953, "actor_loss": -23.324626871109007, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.648252725601196, "step": 112000}
{"episode_reward": 469.2739212018576, "episode": 113.0, "batch_reward": 0.21347367694973945, "critic_loss": 0.5947687816917896, "actor_loss": -23.403116693496703, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.362143516540527, "step": 113000}
{"episode_reward": 497.11917954597845, "episode": 114.0, "batch_reward": 0.21433683909475804, "critic_loss": 0.6090033209621907, "actor_loss": -23.75070055580139, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.71890139579773, "step": 114000}
{"episode_reward": 180.37327781539236, "episode": 115.0, "batch_reward": 0.2149016973376274, "critic_loss": 0.6479930708408356, "actor_loss": -23.707204133987428, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.855796575546265, "step": 115000}
{"episode_reward": 352.97941226392095, "episode": 116.0, "batch_reward": 0.21652661080658436, "critic_loss": 0.6599442075192928, "actor_loss": -23.722108880996704, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.97122073173523, "step": 116000}
{"episode_reward": 375.8507651018726, "episode": 117.0, "batch_reward": 0.21758734615147113, "critic_loss": 0.6249059689640999, "actor_loss": -23.512475261688234, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.753432512283325, "step": 117000}
{"episode_reward": 198.3731364515213, "episode": 118.0, "batch_reward": 0.21678541220724581, "critic_loss": 0.6852854214310646, "actor_loss": -23.670802631378173, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.557118892669678, "step": 118000}
{"episode_reward": 317.5915303005533, "episode": 119.0, "batch_reward": 0.2185626982152462, "critic_loss": 0.6800915612876415, "actor_loss": -23.93249694633484, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.194830179214478, "step": 119000}
{"episode_reward": 492.2881277648537, "episode": 120.0, "batch_reward": 0.22040093252062798, "critic_loss": 0.6195866083204746, "actor_loss": -23.358029794692992, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.150121212005615, "step": 120000}
{"episode_reward": 471.7212082517843, "episode": 121.0, "batch_reward": 0.22177464909851552, "critic_loss": 0.6352318888008595, "actor_loss": -23.97598042678833, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.32400059700012, "step": 121000}
{"episode_reward": 326.4545384316746, "episode": 122.0, "batch_reward": 0.22339768339693547, "critic_loss": 0.6372356353700162, "actor_loss": -24.383784887313844, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.728712558746338, "step": 122000}
{"episode_reward": 455.9786055095616, "episode": 123.0, "batch_reward": 0.22545200929045678, "critic_loss": 0.6515375842154026, "actor_loss": -24.761269987106324, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.74927282333374, "step": 123000}
{"episode_reward": 425.8861107065702, "episode": 124.0, "batch_reward": 0.22744370917975903, "critic_loss": 0.6608954139649869, "actor_loss": -24.68934127807617, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.39119267463684, "step": 124000}
{"episode_reward": 477.0180801989001, "episode": 125.0, "batch_reward": 0.22821788437664509, "critic_loss": 0.656105574041605, "actor_loss": -24.511891206741332, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.9032940864563, "step": 125000}
{"episode_reward": 293.45906931831274, "episode": 126.0, "batch_reward": 0.2293938255906105, "critic_loss": 0.6808247213661671, "actor_loss": -25.079472648620605, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.728551626205444, "step": 126000}
{"episode_reward": 197.84882312954883, "episode": 127.0, "batch_reward": 0.22957142977416514, "critic_loss": 0.6760084182322025, "actor_loss": -24.629425989151002, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.34225821495056, "step": 127000}
{"episode_reward": 353.4970139438858, "episode": 128.0, "batch_reward": 0.23057104732096195, "critic_loss": 0.6454376528561115, "actor_loss": -24.452300008773804, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.182217121124268, "step": 128000}
{"episode_reward": 313.04316424262265, "episode": 129.0, "batch_reward": 0.23097892752289773, "critic_loss": 0.669150805413723, "actor_loss": -24.94041403579712, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.959453582763672, "step": 129000}
{"episode_reward": 477.58257490556787, "episode": 130.0, "batch_reward": 0.23211755500733852, "critic_loss": 0.666369650632143, "actor_loss": -25.26501394844055, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.106223106384277, "step": 130000}
{"episode_reward": 69.82234147021472, "episode": 131.0, "batch_reward": 0.23170392602682113, "critic_loss": 0.6483064780831337, "actor_loss": -24.269923435211183, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.70622253417969, "step": 131000}
{"episode_reward": 487.367707459051, "episode": 132.0, "batch_reward": 0.23412044155597686, "critic_loss": 0.6614827884435653, "actor_loss": -25.545473011016846, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.08220601081848, "step": 132000}
{"episode_reward": 456.2269408577308, "episode": 133.0, "batch_reward": 0.2356299723982811, "critic_loss": 0.678973650932312, "actor_loss": -24.815475772857667, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.1613552570343, "step": 133000}
{"episode_reward": 447.2059691937789, "episode": 134.0, "batch_reward": 0.23657786904275419, "critic_loss": 0.7120553968101739, "actor_loss": -25.248194143295287, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.105822324752808, "step": 134000}
{"episode_reward": 522.9575966202771, "episode": 135.0, "batch_reward": 0.23835251438617705, "critic_loss": 0.630750387340784, "actor_loss": -25.85091328048706, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.999550580978394, "step": 135000}
{"episode_reward": 331.97030819438504, "episode": 136.0, "batch_reward": 0.24042943884432316, "critic_loss": 0.6125486496686935, "actor_loss": -25.530269548416136, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.19795250892639, "step": 136000}
{"episode_reward": 420.0526795122662, "episode": 137.0, "batch_reward": 0.24051682524383067, "critic_loss": 0.6284283495545387, "actor_loss": -25.931788816452027, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.63082218170166, "step": 137000}
{"episode_reward": 154.91077199179614, "episode": 138.0, "batch_reward": 0.23959107728302478, "critic_loss": 0.6598169448971748, "actor_loss": -26.24497403717041, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.718153476715088, "step": 138000}
{"episode_reward": 419.0068233740534, "episode": 139.0, "batch_reward": 0.24154755595326424, "critic_loss": 0.6751972555816174, "actor_loss": -25.398831260681153, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.073527812957764, "step": 139000}
{"episode_reward": 458.9883576787618, "episode": 140.0, "batch_reward": 0.24191066685318946, "critic_loss": 0.65060584923625, "actor_loss": -26.336858669281007, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.474523544311523, "step": 140000}
{"episode_reward": 406.8989050479902, "episode": 141.0, "batch_reward": 0.24570062582194804, "critic_loss": 0.6699078693985939, "actor_loss": -26.14201114654541, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.583571672439575, "step": 141000}
{"episode_reward": 413.0577774422805, "episode": 142.0, "batch_reward": 0.2451078472584486, "critic_loss": 0.6916351363360882, "actor_loss": -26.1235627117157, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.79387331008911, "step": 142000}
{"episode_reward": 448.3987727798718, "episode": 143.0, "batch_reward": 0.2471193019449711, "critic_loss": 0.6838136380016804, "actor_loss": -26.259120615005493, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.689085483551025, "step": 143000}
{"episode_reward": 414.3384028126644, "episode": 144.0, "batch_reward": 0.2482106371074915, "critic_loss": 0.6995603610277176, "actor_loss": -26.660844203948976, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.069242477416992, "step": 144000}
{"episode_reward": 472.06254378903, "episode": 145.0, "batch_reward": 0.24917995572090149, "critic_loss": 0.6742147659063339, "actor_loss": -26.67686437988281, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.47261691093445, "step": 145000}
{"episode_reward": 484.95939779592715, "episode": 146.0, "batch_reward": 0.2510328166782856, "critic_loss": 0.6923260425031185, "actor_loss": -26.2017070274353, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.710723400115967, "step": 146000}
{"episode_reward": 515.2667975766166, "episode": 147.0, "batch_reward": 0.25247168631851674, "critic_loss": 0.6644001369476318, "actor_loss": -26.733676191329955, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.056445121765137, "step": 147000}
{"episode_reward": 531.8525278034817, "episode": 148.0, "batch_reward": 0.25529802864789963, "critic_loss": 0.6449812819063664, "actor_loss": -26.71790016937256, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.741035223007202, "step": 148000}
{"episode_reward": 506.99814335622574, "episode": 149.0, "batch_reward": 0.2577183420956135, "critic_loss": 0.6201333798468113, "actor_loss": -27.250650297164917, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.993332147598267, "step": 149000}
{"episode_reward": 496.64848577403467, "episode": 150.0, "batch_reward": 0.25709866861999037, "critic_loss": 0.6480319246649742, "actor_loss": -27.43912780380249, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
