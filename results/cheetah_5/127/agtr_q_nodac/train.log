{"episode": 1.0, "duration": 20.110487937927246, "episode_reward": 4.859792814687425, "step": 1000}
{"episode": 2.0, "duration": 1.8569505214691162, "episode_reward": 550.1572824113056, "step": 2000}
{"episode": 3.0, "batch_reward": 0.2631376275631856, "actor_loss": -38.80698349896599, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 63.2444965839386, "episode_reward": 68.98738389381461, "step": 3000}
{"episode": 4.0, "batch_reward": 0.19732428820431233, "actor_loss": -35.23816847991943, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.126699447631836, "episode_reward": 149.29098452729343, "step": 4000}
{"episode": 5.0, "batch_reward": 0.18762507033348083, "actor_loss": -34.5656706161499, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.455824851989746, "episode_reward": 171.39407893474822, "step": 5000}
{"episode": 6.0, "batch_reward": 0.18697271017730235, "actor_loss": -33.99863238143921, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.112106561660767, "episode_reward": 139.82885291285325, "step": 6000}
{"episode": 7.0, "batch_reward": 0.1848497639298439, "actor_loss": -32.630859218597415, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.422096967697144, "episode_reward": 272.322703051345, "step": 7000}
{"episode": 8.0, "batch_reward": 0.18773806191980838, "actor_loss": -31.984952423095702, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.068523406982422, "episode_reward": 63.90168717858856, "step": 8000}
{"episode": 9.0, "batch_reward": 0.1804060978293419, "actor_loss": -30.641690208435058, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.73011541366577, "episode_reward": 271.5216050003132, "step": 9000}
{"episode": 10.0, "batch_reward": 0.183105642542243, "actor_loss": -30.390954612731935, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.509629726409912, "episode_reward": 53.91979369259736, "step": 10000}
{"episode": 11.0, "batch_reward": 0.17809328266978264, "actor_loss": -29.334740535736085, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 41.1799955368042, "episode_reward": 265.33051654083795, "step": 11000}
{"episode": 12.0, "batch_reward": 0.17809670977294445, "actor_loss": -29.168798976898195, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.812883377075195, "episode_reward": 46.712196180018836, "step": 12000}
{"episode": 13.0, "batch_reward": 0.16840147341042758, "actor_loss": -27.742680950164797, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.49877619743347, "episode_reward": 61.64691784276159, "step": 13000}
{"episode": 14.0, "batch_reward": 0.16479003154486419, "actor_loss": -27.047992603302003, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.903543949127197, "episode_reward": 172.2904926501473, "step": 14000}
{"episode": 15.0, "batch_reward": 0.1683357091397047, "actor_loss": -27.150627655029297, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.00267744064331, "episode_reward": 305.72612195034543, "step": 15000}
{"episode": 16.0, "batch_reward": 0.17743261447548866, "actor_loss": -27.75615617752075, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.967782974243164, "episode_reward": 286.8475886202768, "step": 16000}
{"episode": 17.0, "batch_reward": 0.18014989505708218, "actor_loss": -27.761952838897706, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.512553691864014, "episode_reward": 204.71717668561527, "step": 17000}
{"episode": 18.0, "batch_reward": 0.17994843865185975, "actor_loss": -27.843933975219727, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.24184799194336, "episode_reward": 70.76509252872765, "step": 18000}
{"episode": 19.0, "batch_reward": 0.17705906005203723, "actor_loss": -27.321729724884033, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.820504903793335, "episode_reward": 187.94913653912135, "step": 19000}
{"episode": 20.0, "batch_reward": 0.17700838232040406, "actor_loss": -27.136676849365234, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.31859803199768, "episode_reward": 140.37284366675695, "step": 20000}
{"episode": 21.0, "batch_reward": 0.17417943981289863, "actor_loss": -26.62260263824463, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 41.385610818862915, "episode_reward": 125.57031751093447, "step": 21000}
{"episode": 22.0, "batch_reward": 0.1747072505056858, "actor_loss": -26.525218448638917, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.866888999938965, "episode_reward": 329.0678261595662, "step": 22000}
{"episode": 23.0, "batch_reward": 0.18229208752512932, "actor_loss": -27.119468727111816, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.486092567443848, "episode_reward": 203.04956495602428, "step": 23000}
{"episode": 24.0, "batch_reward": 0.18299996137619018, "actor_loss": -27.0842141494751, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.901202917099, "episode_reward": 327.2472790903551, "step": 24000}
{"episode": 25.0, "batch_reward": 0.18348855778574943, "actor_loss": -27.184927974700926, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.44122886657715, "episode_reward": 20.830659597604026, "step": 25000}
{"episode": 26.0, "batch_reward": 0.1828447288274765, "actor_loss": -26.98265414810181, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.984769821166992, "episode_reward": 280.54941311105665, "step": 26000}
{"episode": 27.0, "batch_reward": 0.1848055407702923, "actor_loss": -27.111714832305907, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.947492837905884, "episode_reward": 203.14626594046598, "step": 27000}
{"episode": 28.0, "batch_reward": 0.1891827688664198, "actor_loss": -27.274205448150635, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.432652950286865, "episode_reward": 463.3931918254811, "step": 28000}
{"episode": 29.0, "batch_reward": 0.1935298623293638, "actor_loss": -27.583359794616698, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.724772930145264, "episode_reward": 115.15432822393109, "step": 29000}
{"episode": 30.0, "batch_reward": 0.19411040584743022, "actor_loss": -27.433382095336913, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.807409286499023, "episode_reward": 411.0873352831528, "step": 30000}
{"episode": 31.0, "batch_reward": 0.2013991749882698, "actor_loss": -28.04116718673706, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 41.358301639556885, "episode_reward": 335.3822566245363, "step": 31000}
{"episode": 32.0, "batch_reward": 0.20323146168887615, "actor_loss": -28.215974716186523, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.677412509918213, "episode_reward": 201.46182383233898, "step": 32000}
{"episode": 33.0, "batch_reward": 0.20290524636209012, "actor_loss": -28.29745849609375, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.56845498085022, "episode_reward": 129.4760668225971, "step": 33000}
{"episode": 34.0, "batch_reward": 0.20396540577709674, "actor_loss": -28.266234313964844, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.745176315307617, "episode_reward": 445.7802884843483, "step": 34000}
{"episode": 35.0, "batch_reward": 0.20865007650852202, "actor_loss": -28.71822328186035, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.915674686431885, "episode_reward": 235.5499296031342, "step": 35000}
{"episode": 36.0, "batch_reward": 0.20842345240712165, "actor_loss": -28.54996290588379, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.210705757141113, "episode_reward": 121.26694039778624, "step": 36000}
{"episode": 37.0, "batch_reward": 0.20867902466654778, "actor_loss": -28.461473541259764, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.794722318649292, "episode_reward": 357.8431468345472, "step": 37000}
{"episode": 38.0, "batch_reward": 0.213290700763464, "actor_loss": -28.665807601928712, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.712101221084595, "episode_reward": 330.22639275915236, "step": 38000}
{"episode": 39.0, "batch_reward": 0.21492970521748067, "actor_loss": -28.68161894226074, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.39140295982361, "episode_reward": 341.2011640952527, "step": 39000}
{"episode": 40.0, "batch_reward": 0.21562323454022408, "actor_loss": -28.736312831878664, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.603306770324707, "episode_reward": 77.25136709750379, "step": 40000}
{"episode": 41.0, "batch_reward": 0.212608605787158, "actor_loss": -28.351548725128175, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 41.154866218566895, "episode_reward": 81.21952617108676, "step": 41000}
{"episode": 42.0, "batch_reward": 0.20953919960558415, "actor_loss": -28.258255126953124, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.570033073425293, "episode_reward": 81.94437500277705, "step": 42000}
{"episode": 43.0, "batch_reward": 0.2082852671444416, "actor_loss": -28.20271011734009, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.75009274482727, "episode_reward": 334.66729812076323, "step": 43000}
{"episode": 44.0, "batch_reward": 0.21140588112175465, "actor_loss": -28.459106193542482, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.87541103363037, "episode_reward": 326.1728820199127, "step": 44000}
{"episode": 45.0, "batch_reward": 0.2136969948261976, "actor_loss": -28.658975696563722, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 25.653090000152588, "episode_reward": 374.91924141862245, "step": 45000}
{"episode": 46.0, "batch_reward": 0.2172254920601845, "actor_loss": -28.982418563842774, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.882455110549927, "episode_reward": 311.184284955487, "step": 46000}
{"episode": 47.0, "batch_reward": 0.21909406788647176, "actor_loss": -28.94460466003418, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.583541870117188, "episode_reward": 243.4570993661222, "step": 47000}
{"episode": 48.0, "batch_reward": 0.2190774019509554, "actor_loss": -28.84036084365845, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.148838758468628, "episode_reward": 123.81676064408414, "step": 48000}
{"episode": 49.0, "batch_reward": 0.2170326160788536, "actor_loss": -28.6368360748291, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.222292184829712, "episode_reward": 225.83206629840754, "step": 49000}
{"episode": 50.0, "batch_reward": 0.2186641702800989, "actor_loss": -28.670991638183594, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.467157125473022, "episode_reward": 313.1135443662599, "step": 50000}
{"episode": 51.0, "batch_reward": 0.2195036128014326, "actor_loss": -28.717004062652588, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 40.3389847278595, "episode_reward": 184.22517093214606, "step": 51000}
{"episode": 52.0, "batch_reward": 0.21898679141700267, "actor_loss": -28.639057987213135, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.938840866088867, "episode_reward": 138.06860397349269, "step": 52000}
{"episode": 53.0, "batch_reward": 0.21846980720758438, "actor_loss": -28.495397106170653, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.65231418609619, "episode_reward": 295.01297294294056, "step": 53000}
{"episode": 54.0, "batch_reward": 0.21796528060734272, "actor_loss": -28.20360251235962, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.779309272766113, "episode_reward": 104.09599650142869, "step": 54000}
{"episode": 55.0, "batch_reward": 0.21640307851135732, "actor_loss": -27.99733946609497, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.644016981124878, "episode_reward": 227.16106307968295, "step": 55000}
{"episode": 56.0, "batch_reward": 0.2175367772579193, "actor_loss": -27.893126281738283, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.28835892677307, "episode_reward": 184.3025783546215, "step": 56000}
{"episode": 57.0, "batch_reward": 0.2173993341475725, "actor_loss": -27.869185306549074, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.396724700927734, "episode_reward": 375.24272400796224, "step": 57000}
{"episode": 58.0, "batch_reward": 0.21919652557373046, "actor_loss": -28.006449630737304, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.81973886489868, "episode_reward": 289.6733933354398, "step": 58000}
{"episode": 59.0, "batch_reward": 0.21950342832505704, "actor_loss": -27.79795976638794, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.470616102218628, "episode_reward": 71.84033069958548, "step": 59000}
{"episode": 60.0, "batch_reward": 0.21769126354157925, "actor_loss": -27.715026973724367, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.328299045562744, "episode_reward": 246.1771522135063, "step": 60000}
{"episode": 61.0, "batch_reward": 0.21760863265395164, "actor_loss": -27.605215534210206, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 41.435468435287476, "episode_reward": 129.9757108396177, "step": 61000}
{"episode": 62.0, "batch_reward": 0.2174182729125023, "actor_loss": -27.56060180282593, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.543432235717773, "episode_reward": 211.05629243922235, "step": 62000}
{"episode": 63.0, "batch_reward": 0.21623821601271628, "actor_loss": -27.37619076156616, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.610161304473877, "episode_reward": 130.31751618930377, "step": 63000}
{"episode": 64.0, "batch_reward": 0.2141179026514292, "actor_loss": -27.12636973953247, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.558922052383423, "episode_reward": 48.449823003306534, "step": 64000}
{"episode": 65.0, "batch_reward": 0.21339006812870503, "actor_loss": -26.93447108078003, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.752907276153564, "episode_reward": 261.1975599219401, "step": 65000}
{"episode": 66.0, "batch_reward": 0.21436551387608052, "actor_loss": -27.040509677886963, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.507566452026367, "episode_reward": 377.73564534914976, "step": 66000}
{"episode": 67.0, "batch_reward": 0.2161657739877701, "actor_loss": -26.95676258468628, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.468955278396606, "episode_reward": 245.41274814456202, "step": 67000}
{"episode": 68.0, "batch_reward": 0.21699893435835838, "actor_loss": -27.10169638824463, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.675158500671387, "episode_reward": 191.75470912908594, "step": 68000}
{"episode": 69.0, "batch_reward": 0.215994682058692, "actor_loss": -26.921215854644775, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.49627375602722, "episode_reward": 320.2079038594403, "step": 69000}
{"episode": 70.0, "batch_reward": 0.21855659645795822, "actor_loss": -27.112048301696777, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.279133558273315, "episode_reward": 310.02154121161664, "step": 70000}
{"episode": 71.0, "batch_reward": 0.21854459770023824, "actor_loss": -27.074441913604737, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 41.18545198440552, "episode_reward": 183.9254419246161, "step": 71000}
{"episode": 72.0, "batch_reward": 0.22012675248086452, "actor_loss": -27.157041938781738, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.640596628189087, "episode_reward": 470.5679500906277, "step": 72000}
{"episode": 73.0, "batch_reward": 0.22286033940315247, "actor_loss": -27.433692378997804, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.637497901916504, "episode_reward": 424.6031546310892, "step": 73000}
{"episode": 74.0, "batch_reward": 0.22507578633725644, "actor_loss": -27.656596714019777, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.909387350082397, "episode_reward": 381.4793674630845, "step": 74000}
{"episode": 75.0, "batch_reward": 0.22625956311821938, "actor_loss": -27.755798202514647, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.757625341415405, "episode_reward": 184.37432363479667, "step": 75000}
{"episode": 76.0, "batch_reward": 0.22615809778869153, "actor_loss": -27.699328979492186, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.789365530014038, "episode_reward": 119.46400671458942, "step": 76000}
{"episode": 77.0, "batch_reward": 0.22479380472004415, "actor_loss": -27.411216381072997, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.85759949684143, "episode_reward": 400.74252526687616, "step": 77000}
{"episode": 78.0, "batch_reward": 0.22852760142087936, "actor_loss": -27.826423427581787, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 25.227959632873535, "episode_reward": 431.1038160913989, "step": 78000}
{"episode": 79.0, "batch_reward": 0.23170974889397622, "actor_loss": -27.958353340148925, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.280898332595825, "episode_reward": 330.27403924821346, "step": 79000}
{"episode": 80.0, "batch_reward": 0.2312844249755144, "actor_loss": -27.80632141494751, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.019291877746582, "episode_reward": 144.73999465156984, "step": 80000}
{"episode": 81.0, "batch_reward": 0.23079677166044713, "actor_loss": -27.809288738250732, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 40.440223693847656, "episode_reward": 496.93989596357466, "step": 81000}
{"episode": 82.0, "batch_reward": 0.23322504018247128, "actor_loss": -28.050522293090822, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.811984062194824, "episode_reward": 264.8226502128056, "step": 82000}
{"episode": 83.0, "batch_reward": 0.23380307500064373, "actor_loss": -28.060481128692626, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.717868328094482, "episode_reward": 380.39007826199605, "step": 83000}
{"episode": 84.0, "batch_reward": 0.23577608449757098, "actor_loss": -28.22325082397461, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.447789669036865, "episode_reward": 468.5087483160663, "step": 84000}
{"episode": 85.0, "batch_reward": 0.23755295987427236, "actor_loss": -28.46855718612671, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.614129304885864, "episode_reward": 391.068617669944, "step": 85000}
{"episode": 86.0, "batch_reward": 0.23997836209833623, "actor_loss": -28.666386833190916, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.507585763931274, "episode_reward": 419.26803567210266, "step": 86000}
{"episode": 87.0, "batch_reward": 0.24293396051228047, "actor_loss": -28.856617866516114, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.30809736251831, "episode_reward": 482.5146161922937, "step": 87000}
{"episode": 88.0, "batch_reward": 0.24532106214761734, "actor_loss": -29.219620323181154, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.45500683784485, "episode_reward": 359.34014989005317, "step": 88000}
{"episode": 89.0, "batch_reward": 0.24610915903747083, "actor_loss": -29.202678245544433, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.82654047012329, "episode_reward": 396.86760749800584, "step": 89000}
{"episode": 90.0, "batch_reward": 0.2498979365080595, "actor_loss": -29.474981281280517, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.142690420150757, "episode_reward": 464.1574363336224, "step": 90000}
{"episode": 91.0, "batch_reward": 0.2501789548397064, "actor_loss": -29.57005732345581, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 39.014915227890015, "episode_reward": 493.2951832705728, "step": 91000}
{"episode": 92.0, "batch_reward": 0.2529436685591936, "actor_loss": -29.859186508178713, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.72271990776062, "episode_reward": 415.76400970439164, "step": 92000}
{"episode": 93.0, "batch_reward": 0.25575153809785844, "actor_loss": -30.146372974395753, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.82595181465149, "episode_reward": 533.8913181191923, "step": 93000}
{"episode": 94.0, "batch_reward": 0.25891348665952685, "actor_loss": -30.428740547180176, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.55107045173645, "episode_reward": 472.23911314178184, "step": 94000}
{"episode": 95.0, "batch_reward": 0.26049461628496645, "actor_loss": -30.508857631683348, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.547733068466187, "episode_reward": 448.6764562047256, "step": 95000}
{"episode": 96.0, "batch_reward": 0.2625450821518898, "actor_loss": -30.641299194335936, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.40712881088257, "episode_reward": 219.0741937398263, "step": 96000}
{"episode": 97.0, "batch_reward": 0.2626799820959568, "actor_loss": -30.662669399261475, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.763535261154175, "episode_reward": 488.9250008944744, "step": 97000}
{"episode": 98.0, "batch_reward": 0.2637998940050602, "actor_loss": -30.711635848999023, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.03182053565979, "episode_reward": 271.0193824782388, "step": 98000}
{"episode": 99.0, "batch_reward": 0.26520729222893713, "actor_loss": -30.777710830688477, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.44072985649109, "episode_reward": 495.8041618722996, "step": 99000}
{"episode": 100.0, "batch_reward": 0.26760237519443036, "actor_loss": -31.087122997283934, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.430846691131592, "episode_reward": 416.0312783525453, "step": 100000}
{"episode": 101.0, "batch_reward": 0.26866315385699274, "actor_loss": -31.00995666885376, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.028645038604736, "episode_reward": 486.3811863220237, "step": 101000}
{"episode": 102.0, "batch_reward": 0.2705421976596117, "actor_loss": -31.17551365661621, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.654497385025024, "episode_reward": 542.1626859134244, "step": 102000}
{"episode": 103.0, "batch_reward": 0.27356777316331865, "actor_loss": -31.542143405914306, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.655828952789307, "episode_reward": 263.2507815624718, "step": 103000}
{"episode": 104.0, "batch_reward": 0.2727652358561754, "actor_loss": -31.390003192901613, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.115283250808716, "episode_reward": 497.18526731553754, "step": 104000}
{"episode": 105.0, "batch_reward": 0.2749618381857872, "actor_loss": -31.721248355865477, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.67883825302124, "episode_reward": 317.1268697595812, "step": 105000}
{"episode": 106.0, "batch_reward": 0.27541486544907096, "actor_loss": -31.692870170593263, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.597564935684204, "episode_reward": 495.13049686182023, "step": 106000}
{"episode": 107.0, "batch_reward": 0.2769317070841789, "actor_loss": -31.81817631149292, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.807804107666016, "episode_reward": 443.0073855966648, "step": 107000}
{"episode": 108.0, "batch_reward": 0.2788010892868042, "actor_loss": -31.9838772315979, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.35196805000305, "episode_reward": 487.5384605290716, "step": 108000}
{"episode": 109.0, "batch_reward": 0.2814546822309494, "actor_loss": -32.16360460281372, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.70198392868042, "episode_reward": 310.131260102995, "step": 109000}
{"episode": 110.0, "batch_reward": 0.28131897780299187, "actor_loss": -32.14109773254395, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.536597728729248, "episode_reward": 500.8463353870551, "step": 110000}
{"episode": 111.0, "batch_reward": 0.2845591999143362, "actor_loss": -32.60482936477661, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.38135886192322, "episode_reward": 531.3479822445404, "step": 111000}
{"episode": 112.0, "batch_reward": 0.28524128974974156, "actor_loss": -32.52517149353027, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.22117280960083, "episode_reward": 429.09657783800174, "step": 112000}
{"episode": 113.0, "batch_reward": 0.2865595847964287, "actor_loss": -32.72008818817139, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.556376695632935, "episode_reward": 409.6933379946822, "step": 113000}
{"episode": 114.0, "batch_reward": 0.2869686540365219, "actor_loss": -32.7176891708374, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.333523511886597, "episode_reward": 348.51159434985266, "step": 114000}
{"episode": 115.0, "batch_reward": 0.28824667362868783, "actor_loss": -32.72906803131104, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.771219491958618, "episode_reward": 239.63866564824434, "step": 115000}
{"episode": 116.0, "batch_reward": 0.28734980154037476, "actor_loss": -32.6291421585083, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.58953547477722, "episode_reward": 227.7780893146287, "step": 116000}
{"episode": 117.0, "batch_reward": 0.2877726287841797, "actor_loss": -32.670694194793704, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.132225036621094, "episode_reward": 523.7543442720216, "step": 117000}
{"episode": 118.0, "batch_reward": 0.29063983730971815, "actor_loss": -32.89690030670166, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.913241147994995, "episode_reward": 499.6672417593065, "step": 118000}
{"episode": 119.0, "batch_reward": 0.2908868034332991, "actor_loss": -32.94863499450683, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.81309413909912, "episode_reward": 573.620055303207, "step": 119000}
{"episode": 120.0, "batch_reward": 0.2932149237245321, "actor_loss": -33.12735084533691, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.782959699630737, "episode_reward": 503.91863669064435, "step": 120000}
{"episode": 121.0, "batch_reward": 0.2956147367507219, "actor_loss": -33.24604775619507, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.77851319313049, "episode_reward": 365.1359053552875, "step": 121000}
{"episode": 122.0, "batch_reward": 0.29560041573643686, "actor_loss": -33.18806849288941, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.897599458694458, "episode_reward": 415.71912817296504, "step": 122000}
{"episode": 123.0, "batch_reward": 0.29670570307970046, "actor_loss": -33.41950288772583, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.424025535583496, "episode_reward": 472.68447644412794, "step": 123000}
{"episode": 124.0, "batch_reward": 0.2976475518196821, "actor_loss": -33.28567399215698, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.028499603271484, "episode_reward": 234.22980663557988, "step": 124000}
{"episode": 125.0, "batch_reward": 0.29831630416214466, "actor_loss": -33.47493198013306, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.654135704040527, "episode_reward": 464.4669114690864, "step": 125000}
{"episode": 126.0, "batch_reward": 0.299566541492939, "actor_loss": -33.60512460708618, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.81040930747986, "episode_reward": 467.28939896002447, "step": 126000}
{"episode": 127.0, "batch_reward": 0.2993042075037956, "actor_loss": -33.54253538131714, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.758304834365845, "episode_reward": 85.14212816233973, "step": 127000}
{"episode": 128.0, "batch_reward": 0.29853777852654456, "actor_loss": -33.50554880142212, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.245693683624268, "episode_reward": 294.86175864785986, "step": 128000}
{"episode": 129.0, "batch_reward": 0.2983436420559883, "actor_loss": -33.4558317604065, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.364893674850464, "episode_reward": 343.8377297481647, "step": 129000}
{"episode": 130.0, "batch_reward": 0.2985168612897396, "actor_loss": -33.498812980651856, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.632161617279053, "episode_reward": 169.641257753423, "step": 130000}
{"episode": 131.0, "batch_reward": 0.29843485651910306, "actor_loss": -33.47274345779419, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 38.58390712738037, "episode_reward": 550.2672670634682, "step": 131000}
{"episode": 132.0, "batch_reward": 0.29983606980741023, "actor_loss": -33.59984730148315, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.80318522453308, "episode_reward": 202.07850996070474, "step": 132000}
{"episode": 133.0, "batch_reward": 0.3005246543586254, "actor_loss": -33.65730966949463, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.70652675628662, "episode_reward": 463.3398624281566, "step": 133000}
{"episode": 134.0, "batch_reward": 0.30127674621343614, "actor_loss": -33.601162399291994, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.318196773529053, "episode_reward": 470.05678153368126, "step": 134000}
{"episode": 135.0, "batch_reward": 0.3020344343036413, "actor_loss": -33.79286574554443, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.60908055305481, "episode_reward": 491.88297343352644, "step": 135000}
{"episode": 136.0, "batch_reward": 0.3036588214188814, "actor_loss": -33.86148435974121, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.47425365447998, "episode_reward": 486.8068934557344, "step": 136000}
{"episode": 137.0, "batch_reward": 0.3045311061441898, "actor_loss": -34.12646021270752, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.798900842666626, "episode_reward": 495.87697849975547, "step": 137000}
{"episode": 138.0, "batch_reward": 0.30574585872888566, "actor_loss": -33.922803146362305, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.496166229248047, "episode_reward": 509.1246963897188, "step": 138000}
{"episode": 139.0, "batch_reward": 0.3077564018368721, "actor_loss": -34.20469054031372, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.757582664489746, "episode_reward": 550.9857687637715, "step": 139000}
{"episode": 140.0, "batch_reward": 0.30720962773263455, "actor_loss": -34.17262003707886, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.84033226966858, "episode_reward": 165.84877358571111, "step": 140000}
{"episode": 141.0, "batch_reward": 0.30893672020733354, "actor_loss": -34.284185520172116, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 40.428611755371094, "episode_reward": 464.95225074057515, "step": 141000}
{"episode": 142.0, "batch_reward": 0.30853663459420205, "actor_loss": -34.14984126281738, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.71442413330078, "episode_reward": 142.66243665280203, "step": 142000}
{"episode": 143.0, "batch_reward": 0.3088797743618488, "actor_loss": -34.30363161849976, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.70400357246399, "episode_reward": 462.8810255358309, "step": 143000}
{"episode": 144.0, "batch_reward": 0.30981557893753053, "actor_loss": -34.33346820449829, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.691181898117065, "episode_reward": 587.553260783528, "step": 144000}
{"episode": 145.0, "batch_reward": 0.3110427362918854, "actor_loss": -34.47068741226196, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.304564714431763, "episode_reward": 507.0410358625059, "step": 145000}
{"episode": 146.0, "batch_reward": 0.3120102845132351, "actor_loss": -34.46336780548096, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.911059617996216, "episode_reward": 532.5320101435638, "step": 146000}
{"episode": 147.0, "batch_reward": 0.31331641820073125, "actor_loss": -34.62411966705322, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.887112617492676, "episode_reward": 397.2103611939277, "step": 147000}
{"episode": 148.0, "batch_reward": 0.31411588567495347, "actor_loss": -34.697619132995605, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.04359197616577, "episode_reward": 558.6401208703328, "step": 148000}
{"episode": 149.0, "batch_reward": 0.31560958582162857, "actor_loss": -34.83101419067383, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.846551418304443, "episode_reward": 218.03737108947934, "step": 149000}
{"episode": 150.0, "batch_reward": 0.31513673695921895, "actor_loss": -34.78891772460938, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
