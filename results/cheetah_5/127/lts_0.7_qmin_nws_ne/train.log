{"episode_reward": 0.0, "episode": 1.0, "duration": 17.559204816818237, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.5153708457946777, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.26032350355185996, "critic_loss": 0.021552615495530312, "actor_loss": -29.706944166284266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.16539931297302, "step": 3000}
{"episode_reward": 3.2213252005861444, "episode": 4.0, "batch_reward": 0.16188486256450416, "critic_loss": 0.01006432688399218, "actor_loss": -25.918341894626618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.359867095947266, "step": 4000}
{"episode_reward": 3.2533740257351287, "episode": 5.0, "batch_reward": 0.12557960160449147, "critic_loss": 0.016446304188109936, "actor_loss": -24.28470383119583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.52585768699646, "step": 5000}
{"episode_reward": 2.9298638887131014, "episode": 6.0, "batch_reward": 0.10221728996559977, "critic_loss": 0.010692066685529425, "actor_loss": -24.268985783576966, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.787134647369385, "step": 6000}
{"episode_reward": 1.9918502724105573, "episode": 7.0, "batch_reward": 0.08725913959369064, "critic_loss": 0.015334427004447208, "actor_loss": -23.38915549945831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.628254175186157, "step": 7000}
{"episode_reward": 1.532710771227096, "episode": 8.0, "batch_reward": 0.07600783257558942, "critic_loss": 0.012919660217128695, "actor_loss": -23.243243008613586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.31338620185852, "step": 8000}
{"episode_reward": 2.4488715040159352, "episode": 9.0, "batch_reward": 0.06709567768499256, "critic_loss": 0.01664922612439841, "actor_loss": -22.887983649253844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.54719614982605, "step": 9000}
{"episode_reward": 2.6134440621131216, "episode": 10.0, "batch_reward": 0.06076537221483886, "critic_loss": 0.016456350420834497, "actor_loss": -23.602343502759933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.63864493370056, "step": 10000}
{"episode_reward": 3.158677028087519, "episode": 11.0, "batch_reward": 0.0560234325225465, "critic_loss": 0.013994571397663094, "actor_loss": -22.54894389653206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.4488320350647, "step": 11000}
{"episode_reward": 3.3000168985990714, "episode": 12.0, "batch_reward": 0.04978252182295546, "critic_loss": 0.01542053013993427, "actor_loss": -22.593803039312363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05132532119751, "step": 12000}
{"episode_reward": 2.8010637842330928, "episode": 13.0, "batch_reward": 0.04638955178391188, "critic_loss": 0.024288499847869387, "actor_loss": -21.994467385530474, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.69652223587036, "step": 13000}
{"episode_reward": 2.8034503083011857, "episode": 14.0, "batch_reward": 0.04366462027374655, "critic_loss": 0.013637805130856577, "actor_loss": -21.6849540681839, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.48862886428833, "step": 14000}
{"episode_reward": 3.974397520006179, "episode": 15.0, "batch_reward": 0.040372921640984716, "critic_loss": 0.014820631427806803, "actor_loss": -21.842266510486603, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.253663778305054, "step": 15000}
{"episode_reward": 2.823127661468729, "episode": 16.0, "batch_reward": 0.0381859829351306, "critic_loss": 0.01606724382727407, "actor_loss": -22.396104124307634, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.655251502990723, "step": 16000}
{"episode_reward": 3.4499092589833404, "episode": 17.0, "batch_reward": 0.03592770650633611, "critic_loss": 0.01778073274344206, "actor_loss": -21.066892246723175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.715584993362427, "step": 17000}
{"episode_reward": 2.070965512046859, "episode": 18.0, "batch_reward": 0.03492809960478917, "critic_loss": 0.015077994957915506, "actor_loss": -21.4062505903244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.437004327774048, "step": 18000}
{"episode_reward": 4.859334239008819, "episode": 19.0, "batch_reward": 0.03278158220509067, "critic_loss": 0.014399812997260597, "actor_loss": -21.320935099601744, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.40437912940979, "step": 19000}
{"episode_reward": 2.5365916787853173, "episode": 20.0, "batch_reward": 0.031202030241955073, "critic_loss": 0.015505899495328776, "actor_loss": -22.690499749422074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.683780431747437, "step": 20000}
{"episode_reward": 2.741264357433856, "episode": 21.0, "batch_reward": 0.029012525168713183, "critic_loss": 0.013870691652817187, "actor_loss": -20.82226006436348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.40182566642761, "step": 21000}
{"episode_reward": 2.9919769559428038, "episode": 22.0, "batch_reward": 0.028647407999495045, "critic_loss": 0.016794089823786634, "actor_loss": -21.860549846410752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04792308807373, "step": 22000}
{"episode_reward": 4.139913081418456, "episode": 23.0, "batch_reward": 0.027297560172621162, "critic_loss": 0.012543237422883977, "actor_loss": -20.928294679880143, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.70288109779358, "step": 23000}
{"episode_reward": 3.364661015531094, "episode": 24.0, "batch_reward": 0.026184924082364888, "critic_loss": 0.020394064556632657, "actor_loss": -21.620130368828775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.71277642250061, "step": 24000}
{"episode_reward": 2.7261609815564523, "episode": 25.0, "batch_reward": 0.02582563811703585, "critic_loss": 0.01297386055951938, "actor_loss": -22.25305782532692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.90263819694519, "step": 25000}
{"episode_reward": 3.697179327386781, "episode": 26.0, "batch_reward": 0.024557024952839127, "critic_loss": 0.015151488894945941, "actor_loss": -21.171599171996117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.699867010116577, "step": 26000}
{"episode_reward": 2.700609002063491, "episode": 27.0, "batch_reward": 0.024304321695351974, "critic_loss": 0.01189353601381299, "actor_loss": -21.0982916662693, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.724573850631714, "step": 27000}
{"episode_reward": 2.8742479487775516, "episode": 28.0, "batch_reward": 0.023355844097910448, "critic_loss": 0.011916780606698011, "actor_loss": -20.9394251973629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.38645315170288, "step": 28000}
{"episode_reward": 3.2690484473635015, "episode": 29.0, "batch_reward": 0.022046381478663533, "critic_loss": 0.018447202712326544, "actor_loss": -21.12834032869339, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.887881755828857, "step": 29000}
{"episode_reward": 2.363300315900984, "episode": 30.0, "batch_reward": 0.02175015773414634, "critic_loss": 0.010087211265665245, "actor_loss": -20.683932416558267, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.70219087600708, "step": 30000}
{"episode_reward": 3.1090971735660498, "episode": 31.0, "batch_reward": 0.020863216610159725, "critic_loss": 0.012898348877701209, "actor_loss": -20.445192175149916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.31626343727112, "step": 31000}
{"episode_reward": 2.4391450184284196, "episode": 32.0, "batch_reward": 0.020521951305447147, "critic_loss": 0.013986827751155943, "actor_loss": -20.65557168161869, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.939464330673218, "step": 32000}
{"episode_reward": 5.8583800954328, "episode": 33.0, "batch_reward": 0.020042999221477658, "critic_loss": 0.01265799106907798, "actor_loss": -21.125041594266893, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.626577138900757, "step": 33000}
{"episode_reward": 3.4830464723451833, "episode": 34.0, "batch_reward": 0.01963983592367731, "critic_loss": 0.014582134841097286, "actor_loss": -20.988111102104188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.618547439575195, "step": 34000}
{"episode_reward": 1.1592486645843314, "episode": 35.0, "batch_reward": 0.01828081977518741, "critic_loss": 0.012694514749106019, "actor_loss": -21.214418263435363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.09935426712036, "step": 35000}
{"episode_reward": 3.492098863641693, "episode": 36.0, "batch_reward": 0.01807517663529143, "critic_loss": 0.012962577237252845, "actor_loss": -21.88425155365467, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.688960552215576, "step": 36000}
{"episode_reward": 0.7386759104107294, "episode": 37.0, "batch_reward": 0.018053849160089157, "critic_loss": 0.016240285382664296, "actor_loss": -20.325276464819908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.619303941726685, "step": 37000}
{"episode_reward": 2.9634588445238688, "episode": 38.0, "batch_reward": 0.017381060741841793, "critic_loss": 0.009191041775076883, "actor_loss": -19.67827710598707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.54483985900879, "step": 38000}
{"episode_reward": 1.141338591773364, "episode": 39.0, "batch_reward": 0.017237510063685478, "critic_loss": 0.0129855689201504, "actor_loss": -20.442547066688537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31399130821228, "step": 39000}
{"episode_reward": 0.9679804772604379, "episode": 40.0, "batch_reward": 0.01674255391652696, "critic_loss": 0.010242657116919872, "actor_loss": -20.680103917121887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.643726110458374, "step": 40000}
{"episode_reward": 1.6744888855244935, "episode": 41.0, "batch_reward": 0.01627123491722159, "critic_loss": 0.010728681277134456, "actor_loss": -20.130592644274234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.55322051048279, "step": 41000}
{"episode_reward": 2.2267377466100586, "episode": 42.0, "batch_reward": 0.016067069642595015, "critic_loss": 0.01050225983146811, "actor_loss": -20.172284054279327, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.812828063964844, "step": 42000}
{"episode_reward": 2.052475332491717, "episode": 43.0, "batch_reward": 0.015492698979796842, "critic_loss": 0.016173580100235996, "actor_loss": -20.24890445947647, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.671427488327026, "step": 43000}
{"episode_reward": 1.060760910245793, "episode": 44.0, "batch_reward": 0.015478039486333727, "critic_loss": 0.009130104184383526, "actor_loss": -22.29854083263874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.02675461769104, "step": 44000}
{"episode_reward": 2.8669411912245057, "episode": 45.0, "batch_reward": 0.01487532511120662, "critic_loss": 0.008800304422460613, "actor_loss": -21.16017548120022, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.080533266067505, "step": 45000}
{"episode_reward": 3.153040788066316, "episode": 46.0, "batch_reward": 0.014437558512669056, "critic_loss": 0.012917967011482687, "actor_loss": -19.76348371744156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.64375615119934, "step": 46000}
{"episode_reward": 1.863893908268941, "episode": 47.0, "batch_reward": 0.014285344287520275, "critic_loss": 0.01000643063930329, "actor_loss": -20.604297821342946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.689008474349976, "step": 47000}
{"episode_reward": 2.340775340750342, "episode": 48.0, "batch_reward": 0.014238289934466592, "critic_loss": 0.012686644476139918, "actor_loss": -20.188694628834725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.75298523902893, "step": 48000}
{"episode_reward": 2.1578862504802183, "episode": 49.0, "batch_reward": 0.014156272941851056, "critic_loss": 0.00900861721599358, "actor_loss": -21.641861623108387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.684560298919678, "step": 49000}
{"episode_reward": 2.0409577483005443, "episode": 50.0, "batch_reward": 0.013767444011173212, "critic_loss": 0.012382979706249898, "actor_loss": -20.610506379842757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.63659977912903, "step": 50000}
{"episode_reward": 3.0431955621988056, "episode": 51.0, "batch_reward": 0.013596079375944101, "critic_loss": 0.010193133009001031, "actor_loss": -20.265106985986233, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.780224084854126, "step": 51000}
{"episode_reward": 2.0394661014375917, "episode": 52.0, "batch_reward": 0.013422411366249434, "critic_loss": 0.00990644113754388, "actor_loss": -20.24510908716917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.379228830337524, "step": 52000}
{"episode_reward": 1.5547741969809752, "episode": 53.0, "batch_reward": 0.013181595031404867, "critic_loss": 0.010438444384461036, "actor_loss": -21.11353175586462, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.681707620620728, "step": 53000}
{"episode_reward": 1.5764221935693299, "episode": 54.0, "batch_reward": 0.012900225429912099, "critic_loss": 0.012979809260970797, "actor_loss": -21.692897817730902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.112284421920776, "step": 54000}
{"episode_reward": 2.308099000482358, "episode": 55.0, "batch_reward": 0.012998461461975239, "critic_loss": 0.010335485635485383, "actor_loss": -20.949407333672045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.531780004501343, "step": 55000}
{"episode_reward": 2.5028810083349993, "episode": 56.0, "batch_reward": 0.012393886328791268, "critic_loss": 0.008290160989767174, "actor_loss": -20.63651437103748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12325620651245, "step": 56000}
{"episode_reward": 1.7786089464368333, "episode": 57.0, "batch_reward": 0.012352803357411176, "critic_loss": 0.01185837809277291, "actor_loss": -20.585576818645002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.71718168258667, "step": 57000}
{"episode_reward": 3.492589787581811, "episode": 58.0, "batch_reward": 0.012078895944869146, "critic_loss": 0.00940197414168506, "actor_loss": -20.579965745151043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21815013885498, "step": 58000}
{"episode_reward": 2.3463423183117533, "episode": 59.0, "batch_reward": 0.011913514000014402, "critic_loss": 0.010181546535139205, "actor_loss": -20.22508356386423, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.65769052505493, "step": 59000}
{"episode_reward": 2.1333651165123384, "episode": 60.0, "batch_reward": 0.011971898256917484, "critic_loss": 0.009110554280938231, "actor_loss": -20.678824382841587, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.818418741226196, "step": 60000}
{"episode_reward": 1.5339667049293133, "episode": 61.0, "batch_reward": 0.011893781394581311, "critic_loss": 0.012723646842263407, "actor_loss": -20.32095459139347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.15244698524475, "step": 61000}
{"episode_reward": 1.3919111701677525, "episode": 62.0, "batch_reward": 0.011837632384267636, "critic_loss": 0.010338378502259729, "actor_loss": -20.653892136871814, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.48921227455139, "step": 62000}
{"episode_reward": 2.974977782359105, "episode": 63.0, "batch_reward": 0.011366238021291792, "critic_loss": 0.009923156806762564, "actor_loss": -20.747886251866817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.656904935836792, "step": 63000}
{"episode_reward": 1.777982611290363, "episode": 64.0, "batch_reward": 0.011115299175609834, "critic_loss": 0.006659054621981341, "actor_loss": -20.60983382421732, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.648388624191284, "step": 64000}
{"episode_reward": 1.1766769868494356, "episode": 65.0, "batch_reward": 0.01094245683599729, "critic_loss": 0.00839096459010034, "actor_loss": -20.114920030117034, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.574371099472046, "step": 65000}
{"episode_reward": 2.6625532691041114, "episode": 66.0, "batch_reward": 0.010789742273977027, "critic_loss": 0.008101056287443498, "actor_loss": -20.375500493824482, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.39887237548828, "step": 66000}
{"episode_reward": 1.63395542944271, "episode": 67.0, "batch_reward": 0.010904259967966937, "critic_loss": 0.01049104253067344, "actor_loss": -21.09325713199377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.628199577331543, "step": 67000}
{"episode_reward": 1.7382154132454883, "episode": 68.0, "batch_reward": 0.010570809022290632, "critic_loss": 0.008582535204855957, "actor_loss": -22.189355121165512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08499312400818, "step": 68000}
{"episode_reward": 1.9164875997662594, "episode": 69.0, "batch_reward": 0.010585518074803986, "critic_loss": 0.008588508037486463, "actor_loss": -19.809732921242713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.34994149208069, "step": 69000}
{"episode_reward": 1.7302642437138243, "episode": 70.0, "batch_reward": 0.01047686165268533, "critic_loss": 0.006080622544744983, "actor_loss": -20.43771261256933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.661800861358643, "step": 70000}
{"episode_reward": 1.7118844820948964, "episode": 71.0, "batch_reward": 0.010385602147784084, "critic_loss": 0.008840177599020536, "actor_loss": -19.595788015037776, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.157785415649414, "step": 71000}
{"episode_reward": 0.745341334173318, "episode": 72.0, "batch_reward": 0.010294463314116, "critic_loss": 0.006230214818919194, "actor_loss": -20.208076665461064, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.581342458724976, "step": 72000}
{"episode_reward": 1.7110343226398648, "episode": 73.0, "batch_reward": 0.01019411696807947, "critic_loss": 0.0074939168570708715, "actor_loss": -20.428933179974557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.63379430770874, "step": 73000}
{"episode_reward": 2.0966219230753236, "episode": 74.0, "batch_reward": 0.00976348187844269, "critic_loss": 0.008357578706083587, "actor_loss": -19.8014966558218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.71864891052246, "step": 74000}
{"episode_reward": 2.651187670353771, "episode": 75.0, "batch_reward": 0.009580857088323683, "critic_loss": 0.004631084183434723, "actor_loss": -20.22354734554887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.55910849571228, "step": 75000}
{"episode_reward": 1.4062404752531714, "episode": 76.0, "batch_reward": 0.009896774129709228, "critic_loss": 0.00766452956230205, "actor_loss": -20.01254800912738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.511213779449463, "step": 76000}
{"episode_reward": 2.797077604101181, "episode": 77.0, "batch_reward": 0.009951078532612883, "critic_loss": 0.00760385969071649, "actor_loss": -20.1775431586802, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.675361394882202, "step": 77000}
{"episode_reward": 2.6578951704538136, "episode": 78.0, "batch_reward": 0.009999856071430259, "critic_loss": 0.004310917086229892, "actor_loss": -20.72184781381488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1904354095459, "step": 78000}
{"episode_reward": 2.1110496479484073, "episode": 79.0, "batch_reward": 0.009376886817160994, "critic_loss": 0.006112313938705483, "actor_loss": -21.052338857889175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.256959199905396, "step": 79000}
{"episode_reward": 2.5553048578714224, "episode": 80.0, "batch_reward": 0.009436642715008929, "critic_loss": 0.006040977947806823, "actor_loss": -20.685944575488566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.648897886276245, "step": 80000}
{"episode_reward": 1.1284889346144662, "episode": 81.0, "batch_reward": 0.00902473014802672, "critic_loss": 0.006779353458769038, "actor_loss": -19.956989503473043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.940990686416626, "step": 81000}
{"episode_reward": 2.9969439934468447, "episode": 82.0, "batch_reward": 0.009033154507167638, "critic_loss": 0.005803182050425675, "actor_loss": -19.676063936203718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.84814739227295, "step": 82000}
{"episode_reward": 2.184391307826407, "episode": 83.0, "batch_reward": 0.009109684642287903, "critic_loss": 0.0050070061092046675, "actor_loss": -20.165337533682585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.71874976158142, "step": 83000}
{"episode_reward": 2.4567374075189736, "episode": 84.0, "batch_reward": 0.008938562061986887, "critic_loss": 0.0063787157721671974, "actor_loss": -20.976388161838056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.969537019729614, "step": 84000}
{"episode_reward": 3.4729933231028283, "episode": 85.0, "batch_reward": 0.008884970518876798, "critic_loss": 0.00520446374353196, "actor_loss": -20.605955129027368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.768598556518555, "step": 85000}
{"episode_reward": 1.9319383563755461, "episode": 86.0, "batch_reward": 0.009002323290682398, "critic_loss": 0.0057314559374790405, "actor_loss": -19.300564705461262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.037821292877197, "step": 86000}
{"episode_reward": 3.441586384277164, "episode": 87.0, "batch_reward": 0.008828156957169995, "critic_loss": 0.005540958480662084, "actor_loss": -21.4882970148921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.694801807403564, "step": 87000}
{"episode_reward": 2.524370387167464, "episode": 88.0, "batch_reward": 0.008388296399731189, "critic_loss": 0.0060048943539877655, "actor_loss": -19.55404092296958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.825018167495728, "step": 88000}
{"episode_reward": 1.4434612051145146, "episode": 89.0, "batch_reward": 0.00873584602610208, "critic_loss": 0.005402236212954449, "actor_loss": -19.71796112331748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.126540422439575, "step": 89000}
{"episode_reward": 2.4656871758598866, "episode": 90.0, "batch_reward": 0.008758546339464374, "critic_loss": 0.0056740782641863914, "actor_loss": -19.737269664615393, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.682894706726074, "step": 90000}
{"episode_reward": 2.1272922936330194, "episode": 91.0, "batch_reward": 0.008507605195976794, "critic_loss": 0.007430297500904999, "actor_loss": -19.55311132800579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.88742208480835, "step": 91000}
{"episode_reward": 2.0352123798225223, "episode": 92.0, "batch_reward": 0.008359376778593287, "critic_loss": 0.00670485934986209, "actor_loss": -20.34619315636158, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.749842405319214, "step": 92000}
{"episode_reward": 2.7170511896771212, "episode": 93.0, "batch_reward": 0.008278545388253405, "critic_loss": 0.005890027290617581, "actor_loss": -19.443942918926478, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.692318439483643, "step": 93000}
{"episode_reward": 2.5765508434910718, "episode": 94.0, "batch_reward": 0.008213444434688426, "critic_loss": 0.008098679356073262, "actor_loss": -20.172017437696457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.847357988357544, "step": 94000}
{"episode_reward": 2.9597241348719403, "episode": 95.0, "batch_reward": 0.008067644516471774, "critic_loss": 0.004759729204008181, "actor_loss": -20.964348488241434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.793131589889526, "step": 95000}
{"episode_reward": 3.1081170220023284, "episode": 96.0, "batch_reward": 0.008434699815814383, "critic_loss": 0.00965099835761066, "actor_loss": -20.45456567361951, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.141403675079346, "step": 96000}
{"episode_reward": 2.2478162088709506, "episode": 97.0, "batch_reward": 0.008213951794779859, "critic_loss": 0.006902840367052704, "actor_loss": -19.243000921934843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.72006106376648, "step": 97000}
{"episode_reward": 1.976212502724083, "episode": 98.0, "batch_reward": 0.007901490357820876, "critic_loss": 0.005655814454788924, "actor_loss": -21.62631744900346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109808444976807, "step": 98000}
{"episode_reward": 2.141899248911373, "episode": 99.0, "batch_reward": 0.007924515054794029, "critic_loss": 0.006011083061544923, "actor_loss": -19.58399560841918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.83424210548401, "step": 99000}
{"episode_reward": 2.102632475921972, "episode": 100.0, "batch_reward": 0.007992653726832942, "critic_loss": 0.007435014593844244, "actor_loss": -19.57999659985304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89137101173401, "step": 100000}
{"episode_reward": 2.769811720224797, "episode": 101.0, "batch_reward": 0.008061808898928576, "critic_loss": 0.006697823035967303, "actor_loss": -19.42276508411765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.938472747802734, "step": 101000}
{"episode_reward": 2.535855823253355, "episode": 102.0, "batch_reward": 0.008100565118598751, "critic_loss": 0.008426603182248072, "actor_loss": -20.50163898792863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.57550549507141, "step": 102000}
{"episode_reward": 2.7728729101839305, "episode": 103.0, "batch_reward": 0.008107431603362783, "critic_loss": 0.005153914731461554, "actor_loss": -19.6027236866951, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03783631324768, "step": 103000}
{"episode_reward": 2.8521963653631235, "episode": 104.0, "batch_reward": 0.007960846564034, "critic_loss": 0.008224546226425445, "actor_loss": -19.536030990213156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.703173398971558, "step": 104000}
{"episode_reward": 2.5956472359869482, "episode": 105.0, "batch_reward": 0.007789495565346442, "critic_loss": 0.0057188775179238295, "actor_loss": -19.981006855100393, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.333020448684692, "step": 105000}
{"episode_reward": 1.7232406021340627, "episode": 106.0, "batch_reward": 0.007344874411355704, "critic_loss": 0.007343220765164005, "actor_loss": -19.72790411296487, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.55549430847168, "step": 106000}
{"episode_reward": 3.0765342575651515, "episode": 107.0, "batch_reward": 0.007661541894893162, "critic_loss": 0.008697555438848212, "actor_loss": -18.69423146647215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.678295135498047, "step": 107000}
{"episode_reward": 2.3617527896050463, "episode": 108.0, "batch_reward": 0.007879033896839246, "critic_loss": 0.005800152174706454, "actor_loss": -20.603419554144143, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.629403591156006, "step": 108000}
{"episode_reward": 2.3042698158558874, "episode": 109.0, "batch_reward": 0.007331749757286161, "critic_loss": 0.008383436642790912, "actor_loss": -19.719095113664867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.790735006332397, "step": 109000}
{"episode_reward": 2.5505949678411257, "episode": 110.0, "batch_reward": 0.007729897021665238, "critic_loss": 0.006783005672928994, "actor_loss": -20.702055614322425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.876710891723633, "step": 110000}
{"episode_reward": 1.978010884083284, "episode": 111.0, "batch_reward": 0.007377349311136641, "critic_loss": 0.007062720162633923, "actor_loss": -19.166474869966507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.38652300834656, "step": 111000}
{"episode_reward": 1.8010138481300246, "episode": 112.0, "batch_reward": 0.0074667998120421545, "critic_loss": 0.007187285108899232, "actor_loss": -20.621559290975334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.904056787490845, "step": 112000}
{"episode_reward": 2.8348812365539704, "episode": 113.0, "batch_reward": 0.0074141338439658285, "critic_loss": 0.007864078891681857, "actor_loss": -19.63642578917742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.89031672477722, "step": 113000}
{"episode_reward": 2.7979150782076294, "episode": 114.0, "batch_reward": 0.0074539409057470035, "critic_loss": 0.007554659374465701, "actor_loss": -20.183335153073074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.63053607940674, "step": 114000}
{"episode_reward": 3.3550225294698692, "episode": 115.0, "batch_reward": 0.006991201935103163, "critic_loss": 0.007516380375614972, "actor_loss": -19.6923256162107, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.685676097869873, "step": 115000}
{"episode_reward": 2.3331457851739827, "episode": 116.0, "batch_reward": 0.007278131182072684, "critic_loss": 0.005634913134126691, "actor_loss": -20.274164560735226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.622880458831787, "step": 116000}
{"episode_reward": 1.3511842799695735, "episode": 117.0, "batch_reward": 0.007085510486853309, "critic_loss": 0.0058573831825488015, "actor_loss": -19.31141179291904, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.345301151275635, "step": 117000}
{"episode_reward": 1.3795237029654648, "episode": 118.0, "batch_reward": 0.0069616398421349, "critic_loss": 0.006090620136921643, "actor_loss": -19.189502211734652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.687016487121582, "step": 118000}
{"episode_reward": 1.6315982393129091, "episode": 119.0, "batch_reward": 0.0072837658982025455, "critic_loss": 0.005238633843007847, "actor_loss": -19.697372886806725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.367573261260986, "step": 119000}
{"episode_reward": 2.067419717066924, "episode": 120.0, "batch_reward": 0.00724222531914711, "critic_loss": 0.004646775426270323, "actor_loss": -19.015185755625367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.358711004257202, "step": 120000}
{"episode_reward": 1.6291617911446492, "episode": 121.0, "batch_reward": 0.006851490905391984, "critic_loss": 0.004973338316412992, "actor_loss": -19.334321018069982, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.351398944854736, "step": 121000}
{"episode_reward": 2.1586655691807906, "episode": 122.0, "batch_reward": 0.0068497410301351916, "critic_loss": 0.004513667022169102, "actor_loss": -20.185366331741214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.67372703552246, "step": 122000}
{"episode_reward": 3.165194213487454, "episode": 123.0, "batch_reward": 0.0069469894680660215, "critic_loss": 0.00522147854535433, "actor_loss": -19.99727595537901, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.967498779296875, "step": 123000}
{"episode_reward": 2.7839837703045336, "episode": 124.0, "batch_reward": 0.007128893506946042, "critic_loss": 0.005408996014026343, "actor_loss": -20.340182584941388, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.670952081680298, "step": 124000}
{"episode_reward": 2.0511041431606385, "episode": 125.0, "batch_reward": 0.006678900503320619, "critic_loss": 0.0034399066550686256, "actor_loss": -19.581326382398604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.645819425582886, "step": 125000}
{"episode_reward": 1.1491899883378784, "episode": 126.0, "batch_reward": 0.006908205176354386, "critic_loss": 0.005170297927317734, "actor_loss": -20.346321818768978, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.61275362968445, "step": 126000}
{"episode_reward": 3.9907701522300796, "episode": 127.0, "batch_reward": 0.006776147690485231, "critic_loss": 0.005170298490833375, "actor_loss": -20.361462255492807, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.264379262924194, "step": 127000}
{"episode_reward": 2.0557459236178737, "episode": 128.0, "batch_reward": 0.006773041821201332, "critic_loss": 0.005779899624467361, "actor_loss": -20.120489085018633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.719805240631104, "step": 128000}
{"episode_reward": 1.4778368232963053, "episode": 129.0, "batch_reward": 0.006862736717681401, "critic_loss": 0.0041294611174234885, "actor_loss": -19.856505765631795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66140604019165, "step": 129000}
{"episode_reward": 2.0616380715070726, "episode": 130.0, "batch_reward": 0.006530351848923601, "critic_loss": 0.004302603892749175, "actor_loss": -20.569280856341123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.54125165939331, "step": 130000}
{"episode_reward": 1.689349598390505, "episode": 131.0, "batch_reward": 0.006592108040000312, "critic_loss": 0.006396758659277111, "actor_loss": -18.70195294223726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.694857597351074, "step": 131000}
{"episode_reward": 1.4610120510782452, "episode": 132.0, "batch_reward": 0.0065468671960989015, "critic_loss": 0.005249368248070823, "actor_loss": -20.617934524655343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.717426538467407, "step": 132000}
{"episode_reward": 2.428607193431297, "episode": 133.0, "batch_reward": 0.006530608391854912, "critic_loss": 0.004894405807775911, "actor_loss": -19.437971242249013, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.454692363739014, "step": 133000}
{"episode_reward": 1.8406767418980396, "episode": 134.0, "batch_reward": 0.006779640528257005, "critic_loss": 0.004545909537671832, "actor_loss": -20.065415005013346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.181622982025146, "step": 134000}
{"episode_reward": 3.286530550542532, "episode": 135.0, "batch_reward": 0.006272107436438091, "critic_loss": 0.004619347927473427, "actor_loss": -20.66850315476954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.673717498779297, "step": 135000}
{"episode_reward": 2.5415260045000942, "episode": 136.0, "batch_reward": 0.006574903885368258, "critic_loss": 0.006268925360040157, "actor_loss": -19.834895502150058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.733936309814453, "step": 136000}
{"episode_reward": 2.3752565558503873, "episode": 137.0, "batch_reward": 0.006378955591702834, "critic_loss": 0.0044019598744052925, "actor_loss": -20.092601625338197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.42686939239502, "step": 137000}
{"episode_reward": 2.5449697810396437, "episode": 138.0, "batch_reward": 0.006401930062798783, "critic_loss": 0.005811818468762795, "actor_loss": -19.997286248669027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.859084844589233, "step": 138000}
{"episode_reward": 1.5872822777164757, "episode": 139.0, "batch_reward": 0.0062609656423446725, "critic_loss": 0.00477950949044316, "actor_loss": -19.484437499791383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.712425708770752, "step": 139000}
{"episode_reward": 3.8990459691130326, "episode": 140.0, "batch_reward": 0.006593122338992543, "critic_loss": 0.004243285329692299, "actor_loss": -20.899568506494166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.69233202934265, "step": 140000}
{"episode_reward": 3.191783400070485, "episode": 141.0, "batch_reward": 0.006298594490857795, "critic_loss": 0.003678392747839098, "actor_loss": -20.09521043741703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.35195589065552, "step": 141000}
{"episode_reward": 2.2595472679337107, "episode": 142.0, "batch_reward": 0.006290986715815961, "critic_loss": 0.005197040066239424, "actor_loss": -19.873370415344834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.690314054489136, "step": 142000}
{"episode_reward": 1.6451384911430247, "episode": 143.0, "batch_reward": 0.006450253553921357, "critic_loss": 0.0060139771008616665, "actor_loss": -20.057078839465976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.624494552612305, "step": 143000}
{"episode_reward": 5.343499904908421, "episode": 144.0, "batch_reward": 0.0062590852167923, "critic_loss": 0.003943040388316149, "actor_loss": -21.104260050952433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.651582956314087, "step": 144000}
{"episode_reward": 1.676701117422619, "episode": 145.0, "batch_reward": 0.0060901820395374675, "critic_loss": 0.0044753456130711125, "actor_loss": -20.198331670090557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.65410828590393, "step": 145000}
{"episode_reward": 3.0825470369593457, "episode": 146.0, "batch_reward": 0.006073413800564594, "critic_loss": 0.006286131684828433, "actor_loss": -18.74254799555242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.668222904205322, "step": 146000}
{"episode_reward": 1.6234179842468988, "episode": 147.0, "batch_reward": 0.006279291422222741, "critic_loss": 0.004154122544437996, "actor_loss": -19.816927867531778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.697652101516724, "step": 147000}
{"episode_reward": 2.252207025403446, "episode": 148.0, "batch_reward": 0.006075009523308836, "critic_loss": 0.00468906108403462, "actor_loss": -20.41886255414784, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.21763586997986, "step": 148000}
{"episode_reward": 1.979259063515205, "episode": 149.0, "batch_reward": 0.006115713476319797, "critic_loss": 0.0032394626077075373, "actor_loss": -20.254589216127993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.890608549118042, "step": 149000}
{"episode_reward": 3.120929652328253, "episode": 150.0, "batch_reward": 0.005855224819038995, "critic_loss": 0.0033538183090204257, "actor_loss": -20.293494286566972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
