{"episode_reward": 0.0, "episode": 1.0, "duration": 19.851560592651367, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.7710027694702148, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.2663580557830177, "critic_loss": 0.04909839778958449, "actor_loss": -25.41421072118405, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 68.44177222251892, "step": 3000}
{"episode_reward": 162.46632675346646, "episode": 4.0, "batch_reward": 0.218316291436553, "critic_loss": 0.05787114875391126, "actor_loss": -20.370950889527798, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.92520833015442, "step": 4000}
{"episode_reward": 49.48484108620515, "episode": 5.0, "batch_reward": 0.18491248600184917, "critic_loss": 0.050613994002342226, "actor_loss": -16.82601899790764, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.91174340248108, "step": 5000}
{"episode_reward": 96.88554541368177, "episode": 6.0, "batch_reward": 0.16080463891476393, "critic_loss": 0.052781566089019176, "actor_loss": -15.788998472303152, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.333768367767334, "step": 6000}
{"episode_reward": 30.16382574879498, "episode": 7.0, "batch_reward": 0.138470659814775, "critic_loss": 0.05487027877196669, "actor_loss": -13.19030994090438, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.089799642562866, "step": 7000}
{"episode_reward": 37.2679906114864, "episode": 8.0, "batch_reward": 0.13070516081154346, "critic_loss": 0.06481678498536349, "actor_loss": -14.040701850563288, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.937011241912842, "step": 8000}
{"episode_reward": 62.605603493147576, "episode": 9.0, "batch_reward": 0.12024397373199464, "critic_loss": 0.06282317604124546, "actor_loss": -13.504009877860547, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.711495637893677, "step": 9000}
{"episode_reward": 47.356758477250516, "episode": 10.0, "batch_reward": 0.11662054455280305, "critic_loss": 0.07825671075284481, "actor_loss": -13.13039885956049, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.610039234161377, "step": 10000}
{"episode_reward": 148.4704977755085, "episode": 11.0, "batch_reward": 0.11949647199362516, "critic_loss": 0.09265627406910062, "actor_loss": -13.535728479713201, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.381998777389526, "step": 11000}
{"episode_reward": 104.97896169447996, "episode": 12.0, "batch_reward": 0.11675965646654367, "critic_loss": 0.09205605494603515, "actor_loss": -13.958071729891001, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.975730419158936, "step": 12000}
{"episode_reward": 66.47772977402907, "episode": 13.0, "batch_reward": 0.11087042167782783, "critic_loss": 0.09671848356351256, "actor_loss": -13.179203685805202, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.86469316482544, "step": 13000}
{"episode_reward": 41.02372076441581, "episode": 14.0, "batch_reward": 0.10789624037593604, "critic_loss": 0.1003228677995503, "actor_loss": -13.334919708639383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.53464698791504, "step": 14000}
{"episode_reward": 145.32524213878727, "episode": 15.0, "batch_reward": 0.10888130977004766, "critic_loss": 0.10323612013086676, "actor_loss": -14.793464941442013, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.588117361068726, "step": 15000}
{"episode_reward": 72.72822449971686, "episode": 16.0, "batch_reward": 0.10847706672549248, "critic_loss": 0.09983342900499702, "actor_loss": -14.609238758981228, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.615108013153076, "step": 16000}
{"episode_reward": 143.98031624186743, "episode": 17.0, "batch_reward": 0.11146913895756007, "critic_loss": 0.12309635329246521, "actor_loss": -14.869813034251333, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.50703763961792, "step": 17000}
{"episode_reward": 153.57798781277342, "episode": 18.0, "batch_reward": 0.11528263907134532, "critic_loss": 0.14957587224245072, "actor_loss": -15.266029849410057, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41608452796936, "step": 18000}
{"episode_reward": 127.6702948764105, "episode": 19.0, "batch_reward": 0.11402479742467403, "critic_loss": 0.16693788335472345, "actor_loss": -15.3052303545475, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.965927839279175, "step": 19000}
{"episode_reward": 69.63937931753873, "episode": 20.0, "batch_reward": 0.11080497090518475, "critic_loss": 0.17727770905196666, "actor_loss": -15.801403728365898, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.635883331298828, "step": 20000}
{"episode_reward": 64.79172828038264, "episode": 21.0, "batch_reward": 0.11139582753181458, "critic_loss": 0.18253246608376503, "actor_loss": -14.381555755138397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.43569588661194, "step": 21000}
{"episode_reward": 228.3583577301605, "episode": 22.0, "batch_reward": 0.11472469887882471, "critic_loss": 0.19982457212358712, "actor_loss": -15.884373034238815, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.97843623161316, "step": 22000}
{"episode_reward": 90.92096454983206, "episode": 23.0, "batch_reward": 0.11822318197786807, "critic_loss": 0.2356215550750494, "actor_loss": -15.394282405138016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.33022117614746, "step": 23000}
{"episode_reward": 276.9833137621834, "episode": 24.0, "batch_reward": 0.12020050991326571, "critic_loss": 0.2392426270172, "actor_loss": -15.979190697193145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.932997941970825, "step": 24000}
{"episode_reward": 65.57162593003508, "episode": 25.0, "batch_reward": 0.12260547161847353, "critic_loss": 0.24243697925657035, "actor_loss": -16.440311434268953, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.618455410003662, "step": 25000}
{"episode_reward": 268.3774250587231, "episode": 26.0, "batch_reward": 0.12475867216289044, "critic_loss": 0.25416112124919893, "actor_loss": -16.204677011489867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.48875403404236, "step": 26000}
{"episode_reward": 114.514326696571, "episode": 27.0, "batch_reward": 0.12424149903655052, "critic_loss": 0.2210638254508376, "actor_loss": -15.813496390342712, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.24831223487854, "step": 27000}
{"episode_reward": 127.85872728426894, "episode": 28.0, "batch_reward": 0.12435075199604034, "critic_loss": 0.2616144910529256, "actor_loss": -16.415158069610595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.57139015197754, "step": 28000}
{"episode_reward": 77.67471003045861, "episode": 29.0, "batch_reward": 0.12542099437117576, "critic_loss": 0.24695391450077295, "actor_loss": -15.984607057571411, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.632617473602295, "step": 29000}
{"episode_reward": 331.080598128252, "episode": 30.0, "batch_reward": 0.13047383500635623, "critic_loss": 0.2514079729914665, "actor_loss": -16.054331293106078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.014960050582886, "step": 30000}
{"episode_reward": 108.32151421974193, "episode": 31.0, "batch_reward": 0.1306359855532646, "critic_loss": 0.27076461354643105, "actor_loss": -16.284177384376527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.03200888633728, "step": 31000}
{"episode_reward": 182.1869588907947, "episode": 32.0, "batch_reward": 0.13111786779761314, "critic_loss": 0.27286934192478657, "actor_loss": -16.56085370540619, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.973445415496826, "step": 32000}
{"episode_reward": 102.64719934148856, "episode": 33.0, "batch_reward": 0.1301461236551404, "critic_loss": 0.2551840900927782, "actor_loss": -16.505530848503113, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.793824195861816, "step": 33000}
{"episode_reward": 90.2808140227018, "episode": 34.0, "batch_reward": 0.13115591647475958, "critic_loss": 0.2657910507246852, "actor_loss": -16.377364569664003, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.699527740478516, "step": 34000}
{"episode_reward": 289.4039710184055, "episode": 35.0, "batch_reward": 0.13455346308648586, "critic_loss": 0.31358229407668115, "actor_loss": -16.995478245735168, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.465889930725098, "step": 35000}
{"episode_reward": 211.71045534439878, "episode": 36.0, "batch_reward": 0.13359339464455844, "critic_loss": 0.289891528211534, "actor_loss": -17.444567923545836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.350468635559082, "step": 36000}
{"episode_reward": 39.97579273175564, "episode": 37.0, "batch_reward": 0.13565666054934264, "critic_loss": 0.31047131785750387, "actor_loss": -16.9274863243103, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.928840398788452, "step": 37000}
{"episode_reward": 307.54761833168646, "episode": 38.0, "batch_reward": 0.13838518477231265, "critic_loss": 0.32996952553838493, "actor_loss": -17.11111756706238, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.6057608127594, "step": 38000}
{"episode_reward": 102.56633620291204, "episode": 39.0, "batch_reward": 0.13803142046928404, "critic_loss": 0.33904853074252606, "actor_loss": -17.083632996559142, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.177393913269043, "step": 39000}
{"episode_reward": 166.45157010603813, "episode": 40.0, "batch_reward": 0.1395210654065013, "critic_loss": 0.3575802657306194, "actor_loss": -17.323866077423094, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.069618940353394, "step": 40000}
{"episode_reward": 230.06991325825155, "episode": 41.0, "batch_reward": 0.14201986189186572, "critic_loss": 0.38727925391495227, "actor_loss": -17.017478907585144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.503204345703125, "step": 41000}
{"episode_reward": 245.68673105868658, "episode": 42.0, "batch_reward": 0.144708719573915, "critic_loss": 0.38887506966292856, "actor_loss": -17.77662619972229, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.097589254379272, "step": 42000}
{"episode_reward": 382.4305208788804, "episode": 43.0, "batch_reward": 0.14933927427977323, "critic_loss": 0.3839930496662855, "actor_loss": -18.47566102409363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.95313000679016, "step": 43000}
{"episode_reward": 245.34104324839984, "episode": 44.0, "batch_reward": 0.15166638942062854, "critic_loss": 0.34607598723471167, "actor_loss": -19.26481150627136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.873295068740845, "step": 44000}
{"episode_reward": 308.06627861665, "episode": 45.0, "batch_reward": 0.1559324078336358, "critic_loss": 0.37626152361929416, "actor_loss": -19.241578842163086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.881332635879517, "step": 45000}
{"episode_reward": 293.71386342100965, "episode": 46.0, "batch_reward": 0.15885467322915792, "critic_loss": 0.3582274585217238, "actor_loss": -18.823456985473634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.23610830307007, "step": 46000}
{"episode_reward": 375.53886396331626, "episode": 47.0, "batch_reward": 0.16192677837610245, "critic_loss": 0.3581512452363968, "actor_loss": -19.44793279647827, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.32002592086792, "step": 47000}
{"episode_reward": 80.22013094361272, "episode": 48.0, "batch_reward": 0.16107167006283998, "critic_loss": 0.3423980903476477, "actor_loss": -19.265140186309814, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.13219666481018, "step": 48000}
{"episode_reward": 197.16525601494976, "episode": 49.0, "batch_reward": 0.16213974083215, "critic_loss": 0.33487454263865946, "actor_loss": -19.878777448654176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.463759183883667, "step": 49000}
{"episode_reward": 323.9548983470678, "episode": 50.0, "batch_reward": 0.16627211632579564, "critic_loss": 0.33405522398650644, "actor_loss": -20.008244132995607, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.435237169265747, "step": 50000}
{"episode_reward": 356.26828996662334, "episode": 51.0, "batch_reward": 0.17060784296691417, "critic_loss": 0.3629536899328232, "actor_loss": -20.282647972106933, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.51797676086426, "step": 51000}
{"episode_reward": 395.9729238071605, "episode": 52.0, "batch_reward": 0.17449088813364505, "critic_loss": 0.3538226815611124, "actor_loss": -20.161557010650636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27100896835327, "step": 52000}
{"episode_reward": 359.71733594104353, "episode": 53.0, "batch_reward": 0.17647718338668347, "critic_loss": 0.32672460183501245, "actor_loss": -20.63140326499939, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.28273320198059, "step": 53000}
{"episode_reward": 147.69439767837207, "episode": 54.0, "batch_reward": 0.17707317367196082, "critic_loss": 0.3579661655575037, "actor_loss": -21.035826881408692, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.810950994491577, "step": 54000}
{"episode_reward": 283.91877063710865, "episode": 55.0, "batch_reward": 0.17982994782924652, "critic_loss": 0.33832881903648376, "actor_loss": -20.634887083053588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.385903120040894, "step": 55000}
{"episode_reward": 411.70421008546197, "episode": 56.0, "batch_reward": 0.18418770183622837, "critic_loss": 0.35935712671279907, "actor_loss": -21.11616019630432, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.9427330493927, "step": 56000}
{"episode_reward": 399.19293953161883, "episode": 57.0, "batch_reward": 0.18755100928246976, "critic_loss": 0.3558991403579712, "actor_loss": -21.22277686691284, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.095620155334473, "step": 57000}
{"episode_reward": 303.8522372528118, "episode": 58.0, "batch_reward": 0.18772065711021424, "critic_loss": 0.3629035511910915, "actor_loss": -21.375784141540528, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.675354480743408, "step": 58000}
{"episode_reward": 107.5516807317974, "episode": 59.0, "batch_reward": 0.18637773595750332, "critic_loss": 0.31754404233396055, "actor_loss": -21.342436931610106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.385211944580078, "step": 59000}
{"episode_reward": 154.51767915237355, "episode": 60.0, "batch_reward": 0.18719878740608692, "critic_loss": 0.31411222928762433, "actor_loss": -21.395196964263917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.256418704986572, "step": 60000}
{"episode_reward": 405.09846943397844, "episode": 61.0, "batch_reward": 0.19096662014722823, "critic_loss": 0.3190798310190439, "actor_loss": -21.306482027053832, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.16757345199585, "step": 61000}
{"episode_reward": 249.0514377695773, "episode": 62.0, "batch_reward": 0.19022274436056613, "critic_loss": 0.3320493426471949, "actor_loss": -21.683729848861695, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.481042623519897, "step": 62000}
{"episode_reward": 83.42462754716486, "episode": 63.0, "batch_reward": 0.18958465020358561, "critic_loss": 0.3160639601126313, "actor_loss": -21.13624437713623, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.26365303993225, "step": 63000}
{"episode_reward": 173.31468789605736, "episode": 64.0, "batch_reward": 0.18746906381845474, "critic_loss": 0.30793439884483814, "actor_loss": -21.013380687713624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.155921697616577, "step": 64000}
{"episode_reward": 61.5886902575136, "episode": 65.0, "batch_reward": 0.18771116569638252, "critic_loss": 0.3246825015246868, "actor_loss": -21.077647304534914, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.261391401290894, "step": 65000}
{"episode_reward": 409.2273958038334, "episode": 66.0, "batch_reward": 0.19104098305106162, "critic_loss": 0.3183274482339621, "actor_loss": -21.242388124465943, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.721916913986206, "step": 66000}
{"episode_reward": 358.15674192738084, "episode": 67.0, "batch_reward": 0.19310738806426525, "critic_loss": 0.349051118299365, "actor_loss": -21.648870122909546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.537893772125244, "step": 67000}
{"episode_reward": 215.71801484350266, "episode": 68.0, "batch_reward": 0.19414904937148095, "critic_loss": 0.34827479726076127, "actor_loss": -22.105141912460326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.699181079864502, "step": 68000}
{"episode_reward": 350.91996868046795, "episode": 69.0, "batch_reward": 0.19582441307604312, "critic_loss": 0.3464893946349621, "actor_loss": -21.472353116989137, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.464263916015625, "step": 69000}
{"episode_reward": 277.4639834356306, "episode": 70.0, "batch_reward": 0.1963475392907858, "critic_loss": 0.349772303506732, "actor_loss": -21.436359920501708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.79565167427063, "step": 70000}
{"episode_reward": 165.63391197485532, "episode": 71.0, "batch_reward": 0.1965461278706789, "critic_loss": 0.3388814445734024, "actor_loss": -21.431164352416992, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.429670572280884, "step": 71000}
{"episode_reward": 397.92859670729024, "episode": 72.0, "batch_reward": 0.20072534884512425, "critic_loss": 0.3205991968661547, "actor_loss": -21.90506253814697, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.159919500350952, "step": 72000}
{"episode_reward": 474.25217702731965, "episode": 73.0, "batch_reward": 0.20220797537267207, "critic_loss": 0.32285800102353096, "actor_loss": -22.269049137115477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.2892165184021, "step": 73000}
{"episode_reward": 97.08307835478124, "episode": 74.0, "batch_reward": 0.201317262083292, "critic_loss": 0.32918415597081185, "actor_loss": -22.1305507850647, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.378531455993652, "step": 74000}
{"episode_reward": 379.8715368356817, "episode": 75.0, "batch_reward": 0.2052979227602482, "critic_loss": 0.3367973188459873, "actor_loss": -22.407627252578735, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.488808631896973, "step": 75000}
{"episode_reward": 402.2865805238658, "episode": 76.0, "batch_reward": 0.2070872236341238, "critic_loss": 0.328336776509881, "actor_loss": -22.502894607543944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.89985179901123, "step": 76000}
{"episode_reward": 299.3331988389989, "episode": 77.0, "batch_reward": 0.20932074855268, "critic_loss": 0.3157998806387186, "actor_loss": -22.763696165084838, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.076892137527466, "step": 77000}
{"episode_reward": 412.1953096516524, "episode": 78.0, "batch_reward": 0.211627609282732, "critic_loss": 0.3315379250943661, "actor_loss": -22.88115598106384, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.253098964691162, "step": 78000}
{"episode_reward": 396.16236101823006, "episode": 79.0, "batch_reward": 0.2144698894172907, "critic_loss": 0.3270570694953203, "actor_loss": -23.299125375747682, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.509392023086548, "step": 79000}
{"episode_reward": 465.42857679893956, "episode": 80.0, "batch_reward": 0.21671641221642493, "critic_loss": 0.35509554827213285, "actor_loss": -23.58080338859558, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.501922607421875, "step": 80000}
{"episode_reward": 199.03506938594484, "episode": 81.0, "batch_reward": 0.21709880615770816, "critic_loss": 0.35588610035181045, "actor_loss": -23.3839706363678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.18821907043457, "step": 81000}
{"episode_reward": 257.1872408085287, "episode": 82.0, "batch_reward": 0.21670148657262325, "critic_loss": 0.3416441953629255, "actor_loss": -23.13622435569763, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.798394203186035, "step": 82000}
{"episode_reward": 414.5594138428593, "episode": 83.0, "batch_reward": 0.21978302586078644, "critic_loss": 0.367976062476635, "actor_loss": -23.736044815063476, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.847530841827393, "step": 83000}
{"episode_reward": 428.0104280682172, "episode": 84.0, "batch_reward": 0.22323196572065354, "critic_loss": 0.3650426138937473, "actor_loss": -24.19727412414551, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.312976598739624, "step": 84000}
{"episode_reward": 443.21874568068097, "episode": 85.0, "batch_reward": 0.223809655636549, "critic_loss": 0.3541365770250559, "actor_loss": -23.968344078063964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.410736083984375, "step": 85000}
{"episode_reward": 338.3344935607903, "episode": 86.0, "batch_reward": 0.2256487903445959, "critic_loss": 0.3479300879389048, "actor_loss": -24.054602031707763, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.40764093399048, "step": 86000}
{"episode_reward": 296.6762592759929, "episode": 87.0, "batch_reward": 0.22649033696949483, "critic_loss": 0.3963040542751551, "actor_loss": -24.714715518951415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.21450710296631, "step": 87000}
{"episode_reward": 132.35977059966825, "episode": 88.0, "batch_reward": 0.22544807410240172, "critic_loss": 0.393116470515728, "actor_loss": -23.92073789024353, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.79289746284485, "step": 88000}
{"episode_reward": 472.3877728863301, "episode": 89.0, "batch_reward": 0.22888027557730675, "critic_loss": 0.4030558640062809, "actor_loss": -24.114375553131104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.53763484954834, "step": 89000}
{"episode_reward": 483.9602741856063, "episode": 90.0, "batch_reward": 0.2324678821414709, "critic_loss": 0.4016060591489077, "actor_loss": -24.533485023498535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.71020269393921, "step": 90000}
{"episode_reward": 479.87271443047814, "episode": 91.0, "batch_reward": 0.23339918105304241, "critic_loss": 0.38078548718988897, "actor_loss": -24.601780380249025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.79582214355469, "step": 91000}
{"episode_reward": 115.34682771554164, "episode": 92.0, "batch_reward": 0.23245329935848713, "critic_loss": 0.4133439792096615, "actor_loss": -24.897525783538818, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.021928071975708, "step": 92000}
{"episode_reward": 297.6799730832793, "episode": 93.0, "batch_reward": 0.23415814563632012, "critic_loss": 0.38763551054894924, "actor_loss": -24.60654197502136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.469716787338257, "step": 93000}
{"episode_reward": 485.9791282854316, "episode": 94.0, "batch_reward": 0.23582565511763096, "critic_loss": 0.40909250383079054, "actor_loss": -25.184643348693847, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.38260555267334, "step": 94000}
{"episode_reward": 413.2865708229172, "episode": 95.0, "batch_reward": 0.23621664176881313, "critic_loss": 0.3973872606754303, "actor_loss": -25.515191062927247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.373693704605103, "step": 95000}
{"episode_reward": 60.545224278812995, "episode": 96.0, "batch_reward": 0.23568122093379498, "critic_loss": 0.42368269227445127, "actor_loss": -24.966894233703613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.552977323532104, "step": 96000}
{"episode_reward": 188.8376383338297, "episode": 97.0, "batch_reward": 0.23576550908386706, "critic_loss": 0.41677005383372306, "actor_loss": -24.66053550338745, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.160955667495728, "step": 97000}
{"episode_reward": 498.51410706745304, "episode": 98.0, "batch_reward": 0.236742109850049, "critic_loss": 0.44525749917328356, "actor_loss": -25.573952491760252, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.012907028198242, "step": 98000}
{"episode_reward": 272.76070091716315, "episode": 99.0, "batch_reward": 0.23911553341150285, "critic_loss": 0.4397585340440273, "actor_loss": -25.06474981689453, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.405980587005615, "step": 99000}
{"episode_reward": 478.76385168228796, "episode": 100.0, "batch_reward": 0.24194136662781238, "critic_loss": 0.46259376662969587, "actor_loss": -25.394738956451416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.698835134506226, "step": 100000}
{"episode_reward": 497.7704461785668, "episode": 101.0, "batch_reward": 0.24355259132385254, "critic_loss": 0.4239821419417858, "actor_loss": -25.39475096511841, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.512181758880615, "step": 101000}
{"episode_reward": 285.51575231895725, "episode": 102.0, "batch_reward": 0.2439251694381237, "critic_loss": 0.4655692523270845, "actor_loss": -25.573549087524412, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 26.03662919998169, "step": 102000}
{"episode_reward": 477.83149026225243, "episode": 103.0, "batch_reward": 0.24694317811727523, "critic_loss": 0.4535505893975496, "actor_loss": -25.87068337249756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.64444351196289, "step": 103000}
{"episode_reward": 488.46002919962, "episode": 104.0, "batch_reward": 0.24912476153671742, "critic_loss": 0.4414130926579237, "actor_loss": -25.756530490875242, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.070525407791138, "step": 104000}
{"episode_reward": 431.42288563930737, "episode": 105.0, "batch_reward": 0.25179980002343655, "critic_loss": 0.45979402121901514, "actor_loss": -26.097931175231935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.92786169052124, "step": 105000}
{"episode_reward": 534.9341480345687, "episode": 106.0, "batch_reward": 0.2544752340614796, "critic_loss": 0.45574014174938204, "actor_loss": -26.409707656860352, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.9424889087677, "step": 106000}
{"episode_reward": 566.5046732003299, "episode": 107.0, "batch_reward": 0.255011205881834, "critic_loss": 0.42624744240939616, "actor_loss": -26.082648181915282, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.705124855041504, "step": 107000}
{"episode_reward": 113.9884416393098, "episode": 108.0, "batch_reward": 0.2542949921786785, "critic_loss": 0.4408196264654398, "actor_loss": -26.628465717315674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.820125579833984, "step": 108000}
{"episode_reward": 201.95186701343735, "episode": 109.0, "batch_reward": 0.25380557180941105, "critic_loss": 0.42026897029578686, "actor_loss": -26.256030055999755, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.915483951568604, "step": 109000}
{"episode_reward": 202.19145363081114, "episode": 110.0, "batch_reward": 0.2544312603920698, "critic_loss": 0.4383240421712399, "actor_loss": -26.786939910888673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.851754903793335, "step": 110000}
{"episode_reward": 291.2815380889737, "episode": 111.0, "batch_reward": 0.25501517559587955, "critic_loss": 0.4643614000231028, "actor_loss": -26.23365869140625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.84751844406128, "step": 111000}
{"episode_reward": 481.98011128028674, "episode": 112.0, "batch_reward": 0.25599432954192164, "critic_loss": 0.4649511436522007, "actor_loss": -26.716739330291748, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.901546716690063, "step": 112000}
{"episode_reward": 373.94046028534325, "episode": 113.0, "batch_reward": 0.25743002465367315, "critic_loss": 0.43570473036170004, "actor_loss": -26.551404624938964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.783636569976807, "step": 113000}
{"episode_reward": 476.4765578078397, "episode": 114.0, "batch_reward": 0.2583724411278963, "critic_loss": 0.46041680333018303, "actor_loss": -26.81025549697876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.6900851726532, "step": 114000}
{"episode_reward": 81.44273914659586, "episode": 115.0, "batch_reward": 0.2573632026463747, "critic_loss": 0.4540040681511164, "actor_loss": -26.726855937957765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.856316328048706, "step": 115000}
{"episode_reward": 193.2318076125196, "episode": 116.0, "batch_reward": 0.25573720666766164, "critic_loss": 0.44731857311725615, "actor_loss": -26.348868724823, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.299419164657593, "step": 116000}
{"episode_reward": 194.88873076198013, "episode": 117.0, "batch_reward": 0.2568076993227005, "critic_loss": 0.4229970223456621, "actor_loss": -26.284930011749267, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.668213367462158, "step": 117000}
{"episode_reward": 563.7366632576282, "episode": 118.0, "batch_reward": 0.25919860243797305, "critic_loss": 0.4543728286921978, "actor_loss": -26.576709033966065, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.251570224761963, "step": 118000}
{"episode_reward": 367.2003049775317, "episode": 119.0, "batch_reward": 0.2604976794570684, "critic_loss": 0.4286891832649708, "actor_loss": -26.64726329421997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.901185035705566, "step": 119000}
{"episode_reward": 433.3839304502241, "episode": 120.0, "batch_reward": 0.2617949464917183, "critic_loss": 0.4413509685844183, "actor_loss": -26.76300796508789, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.81463623046875, "step": 120000}
{"episode_reward": 527.6341265121806, "episode": 121.0, "batch_reward": 0.2638182501941919, "critic_loss": 0.4503899451345205, "actor_loss": -26.908632850646974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.79905867576599, "step": 121000}
{"episode_reward": 337.2855315998589, "episode": 122.0, "batch_reward": 0.2645613177716732, "critic_loss": 0.4337745462357998, "actor_loss": -27.198000438690187, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.92129611968994, "step": 122000}
{"episode_reward": 546.6932270480086, "episode": 123.0, "batch_reward": 0.2670541267693043, "critic_loss": 0.44683264984190463, "actor_loss": -27.286627239227293, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.361251831054688, "step": 123000}
{"episode_reward": 512.6339095049358, "episode": 124.0, "batch_reward": 0.2693949029147625, "critic_loss": 0.43905912682414056, "actor_loss": -27.7848006401062, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.04554009437561, "step": 124000}
{"episode_reward": 476.737713775766, "episode": 125.0, "batch_reward": 0.26894505962729454, "critic_loss": 0.4692681236565113, "actor_loss": -27.53885395050049, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.893913507461548, "step": 125000}
{"episode_reward": 418.14055229352897, "episode": 126.0, "batch_reward": 0.27202595727145673, "critic_loss": 0.4671873799264431, "actor_loss": -27.892436538696288, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.288681030273438, "step": 126000}
{"episode_reward": 420.0860759724791, "episode": 127.0, "batch_reward": 0.27218097127974034, "critic_loss": 0.4899215130209923, "actor_loss": -27.793154258728027, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.69238567352295, "step": 127000}
{"episode_reward": 355.4082988177058, "episode": 128.0, "batch_reward": 0.273732669994235, "critic_loss": 0.4812863395959139, "actor_loss": -27.849714221954347, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.15800428390503, "step": 128000}
{"episode_reward": 461.10339419774095, "episode": 129.0, "batch_reward": 0.2750492131561041, "critic_loss": 0.46469519636034967, "actor_loss": -27.924108425140382, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.08924174308777, "step": 129000}
{"episode_reward": 476.1245949089897, "episode": 130.0, "batch_reward": 0.27612726199626925, "critic_loss": 0.4476545790731907, "actor_loss": -28.014170787811278, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.385713577270508, "step": 130000}
{"episode_reward": 496.5405474922505, "episode": 131.0, "batch_reward": 0.2784420263916254, "critic_loss": 0.46165155901014804, "actor_loss": -27.768503452301026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.55001974105835, "step": 131000}
{"episode_reward": 223.4353497726404, "episode": 132.0, "batch_reward": 0.278491324454546, "critic_loss": 0.4685974467098713, "actor_loss": -28.21547215652466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.877917766571045, "step": 132000}
{"episode_reward": 501.8569854187817, "episode": 133.0, "batch_reward": 0.2801228785812855, "critic_loss": 0.45458293971419333, "actor_loss": -27.9113821182251, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.88306188583374, "step": 133000}
{"episode_reward": 518.359770736093, "episode": 134.0, "batch_reward": 0.2804405103623867, "critic_loss": 0.4382108795493841, "actor_loss": -28.19989870452881, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.463544130325317, "step": 134000}
{"episode_reward": 489.6117543473457, "episode": 135.0, "batch_reward": 0.28175172007083893, "critic_loss": 0.4934523762911558, "actor_loss": -28.419101249694823, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.79729700088501, "step": 135000}
{"episode_reward": 274.77761461825685, "episode": 136.0, "batch_reward": 0.2843533748090267, "critic_loss": 0.47146184387803075, "actor_loss": -28.665428520202635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.249518394470215, "step": 136000}
{"episode_reward": 556.5106029419237, "episode": 137.0, "batch_reward": 0.2841336257010698, "critic_loss": 0.48740351502597334, "actor_loss": -28.50365055847168, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.72248673439026, "step": 137000}
{"episode_reward": 431.05997490380395, "episode": 138.0, "batch_reward": 0.28589787732064725, "critic_loss": 0.48945028096437454, "actor_loss": -28.735243461608885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.01330041885376, "step": 138000}
{"episode_reward": 505.444988922259, "episode": 139.0, "batch_reward": 0.2864117650687695, "critic_loss": 0.5090875476151705, "actor_loss": -28.613590698242188, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.813472270965576, "step": 139000}
{"episode_reward": 185.8094838268125, "episode": 140.0, "batch_reward": 0.28560126984119416, "critic_loss": 0.48437285448610784, "actor_loss": -28.92102332687378, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.319928884506226, "step": 140000}
{"episode_reward": 460.66960674867073, "episode": 141.0, "batch_reward": 0.288855776026845, "critic_loss": 0.510584860637784, "actor_loss": -28.783399810791014, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.26378893852234, "step": 141000}
{"episode_reward": 508.34787082675757, "episode": 142.0, "batch_reward": 0.28864438815414906, "critic_loss": 0.5172420667111873, "actor_loss": -28.833411975860596, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.900872230529785, "step": 142000}
{"episode_reward": 130.4139699762751, "episode": 143.0, "batch_reward": 0.28815101063251497, "critic_loss": 0.4964325994104147, "actor_loss": -28.592859970092775, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.726428270339966, "step": 143000}
{"episode_reward": 473.68746947235536, "episode": 144.0, "batch_reward": 0.2904315221607685, "critic_loss": 0.49641239584982394, "actor_loss": -29.124470180511473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.116362810134888, "step": 144000}
{"episode_reward": 525.0597867910085, "episode": 145.0, "batch_reward": 0.2901026225835085, "critic_loss": 0.5283911554962397, "actor_loss": -29.081079795837404, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.874183654785156, "step": 145000}
{"episode_reward": 164.34957853655496, "episode": 146.0, "batch_reward": 0.2901223865300417, "critic_loss": 0.555857832044363, "actor_loss": -28.785835258483885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.951906442642212, "step": 146000}
{"episode_reward": 513.9438529520089, "episode": 147.0, "batch_reward": 0.291983653485775, "critic_loss": 0.5265314337164163, "actor_loss": -29.087949604034424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.203678131103516, "step": 147000}
{"episode_reward": 361.20805460593385, "episode": 148.0, "batch_reward": 0.29198132410645483, "critic_loss": 0.5430129550248385, "actor_loss": -29.164574443817138, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.787391424179077, "step": 148000}
{"episode_reward": 388.2607389972842, "episode": 149.0, "batch_reward": 0.2938530547320843, "critic_loss": 0.5508057008087635, "actor_loss": -29.237334655761718, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.90596842765808, "step": 149000}
{"episode_reward": 493.0402038229953, "episode": 150.0, "batch_reward": 0.29493148501217364, "critic_loss": 0.560895501345396, "actor_loss": -29.276128997802733, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
