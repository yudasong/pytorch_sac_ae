{"episode_reward": 0.0, "episode": 1.0, "duration": 24.359169006347656, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 2.1657748222351074, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.2832731224966669, "critic_loss": 0.47036311214727017, "actor_loss": -39.54418228778328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 81.97276496887207, "step": 3000}
{"episode_reward": 401.3874506669315, "episode": 4.0, "batch_reward": 0.2949512961655855, "critic_loss": 1.6900050579309462, "actor_loss": -39.52873935699463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.744999885559082, "step": 4000}
{"episode_reward": 240.38325684966657, "episode": 5.0, "batch_reward": 0.26917311960458756, "critic_loss": 2.444366753697395, "actor_loss": -38.55926371002197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.739720106124878, "step": 5000}
{"episode_reward": 51.74057095059833, "episode": 6.0, "batch_reward": 0.22848623871803284, "critic_loss": 2.39731789457798, "actor_loss": -36.73152719116211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.345496892929077, "step": 6000}
{"episode_reward": 19.629918199628676, "episode": 7.0, "batch_reward": 0.2033872802555561, "critic_loss": 2.272946569442749, "actor_loss": -35.93428834152222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.437106370925903, "step": 7000}
{"episode_reward": 85.31763540670303, "episode": 8.0, "batch_reward": 0.19815152306854725, "critic_loss": 1.5261800991296768, "actor_loss": -33.87897319412232, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.16452193260193, "step": 8000}
{"episode_reward": 258.6925362933512, "episode": 9.0, "batch_reward": 0.2047161549180746, "critic_loss": 1.20825679063797, "actor_loss": -33.27778249740601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.99698567390442, "step": 9000}
{"episode_reward": 302.6560024262468, "episode": 10.0, "batch_reward": 0.2080635118484497, "critic_loss": 0.9366567173600197, "actor_loss": -32.6407225151062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.637719869613647, "step": 10000}
{"episode_reward": 206.69429860394857, "episode": 11.0, "batch_reward": 0.20990180499851704, "critic_loss": 0.8472775568962098, "actor_loss": -32.88549901580811, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.04296278953552, "step": 11000}
{"episode_reward": 298.51695953661596, "episode": 12.0, "batch_reward": 0.2280510525852442, "critic_loss": 0.8525235181748867, "actor_loss": -33.49016312789917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.8070809841156, "step": 12000}
{"episode_reward": 407.5021711806676, "episode": 13.0, "batch_reward": 0.23961679750680923, "critic_loss": 0.8043963361382485, "actor_loss": -32.94761526107788, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.13470482826233, "step": 13000}
{"episode_reward": 278.920266817139, "episode": 14.0, "batch_reward": 0.23116419203579425, "critic_loss": 0.7066774833798408, "actor_loss": -31.98909443664551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.309253215789795, "step": 14000}
{"episode_reward": 6.540057271613691, "episode": 15.0, "batch_reward": 0.2287579369843006, "critic_loss": 0.745602980941534, "actor_loss": -32.084397022247316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.323835372924805, "step": 15000}
{"episode_reward": 450.21313812343453, "episode": 16.0, "batch_reward": 0.24179861102998257, "critic_loss": 0.789356115937233, "actor_loss": -32.381161293029784, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.15697479248047, "step": 16000}
{"episode_reward": 346.5928705532159, "episode": 17.0, "batch_reward": 0.24122247964143753, "critic_loss": 0.7666827761530877, "actor_loss": -31.174350887298584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.463214874267578, "step": 17000}
{"episode_reward": 82.71613778064403, "episode": 18.0, "batch_reward": 0.24223894116282463, "critic_loss": 0.7514294621944427, "actor_loss": -30.875853282928468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.11865735054016, "step": 18000}
{"episode_reward": 549.1325498199172, "episode": 19.0, "batch_reward": 0.25831246131658553, "critic_loss": 0.7645933257341385, "actor_loss": -31.74285055541992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.306779861450195, "step": 19000}
{"episode_reward": 523.21635437293, "episode": 20.0, "batch_reward": 0.27170796439051625, "critic_loss": 0.7501017230153084, "actor_loss": -32.790952270507816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.00835871696472, "step": 20000}
{"episode_reward": 516.1208705030202, "episode": 21.0, "batch_reward": 0.28373538111150265, "critic_loss": 0.7229654732346534, "actor_loss": -32.61614958190918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 53.6519889831543, "step": 21000}
{"episode_reward": 489.80295401699505, "episode": 22.0, "batch_reward": 0.282235758125782, "critic_loss": 0.6499164631962776, "actor_loss": -33.1401999130249, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.348628759384155, "step": 22000}
{"episode_reward": 6.993052583438502, "episode": 23.0, "batch_reward": 0.281275061711669, "critic_loss": 0.6155536194443703, "actor_loss": -32.89095951080322, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.87011194229126, "step": 23000}
{"episode_reward": 550.634917073024, "episode": 24.0, "batch_reward": 0.289282040849328, "critic_loss": 0.6011639028191567, "actor_loss": -33.54615140914917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.21172523498535, "step": 24000}
{"episode_reward": 466.41330141449413, "episode": 25.0, "batch_reward": 0.29945636276900767, "critic_loss": 0.5820134600698947, "actor_loss": -34.289932800292966, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.37282967567444, "step": 25000}
{"episode_reward": 484.254405670008, "episode": 26.0, "batch_reward": 0.2967736190408468, "critic_loss": 0.5436160465180874, "actor_loss": -33.73500740814209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.299115419387817, "step": 26000}
{"episode_reward": 5.0989472527077675, "episode": 27.0, "batch_reward": 0.2924703294932842, "critic_loss": 0.5278926396369934, "actor_loss": -33.699509021759035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.221237421035767, "step": 27000}
{"episode_reward": 240.11117339084404, "episode": 28.0, "batch_reward": 0.29389615435898303, "critic_loss": 0.5243835003376007, "actor_loss": -33.25567251968384, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.094523429870605, "step": 28000}
{"episode_reward": 536.5297575119336, "episode": 29.0, "batch_reward": 0.30167884185910226, "critic_loss": 0.533156653881073, "actor_loss": -33.7776542930603, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.612090826034546, "step": 29000}
{"episode_reward": 500.5667633958211, "episode": 30.0, "batch_reward": 0.3027715862244368, "critic_loss": 0.5347694557905197, "actor_loss": -33.177852489471434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.321603298187256, "step": 30000}
{"episode_reward": 11.973309037194364, "episode": 31.0, "batch_reward": 0.2993912042379379, "critic_loss": 0.565785687237978, "actor_loss": -33.64716014862061, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.74708652496338, "step": 31000}
{"episode_reward": 556.8046572362055, "episode": 32.0, "batch_reward": 0.30751912608742715, "critic_loss": 0.5956871110796929, "actor_loss": -34.3603830909729, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.65621018409729, "step": 32000}
{"episode_reward": 530.741052681525, "episode": 33.0, "batch_reward": 0.3096323413699865, "critic_loss": 0.6074398100376129, "actor_loss": -34.20425664901733, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.40384316444397, "step": 33000}
{"episode_reward": 167.60801397554596, "episode": 34.0, "batch_reward": 0.3099670687168837, "critic_loss": 0.6212373532652855, "actor_loss": -34.06165579605103, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.860759496688843, "step": 34000}
{"episode_reward": 488.0742896179756, "episode": 35.0, "batch_reward": 0.31170160791277884, "critic_loss": 0.6621974889039993, "actor_loss": -33.962054306030275, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.250829458236694, "step": 35000}
{"episode_reward": 363.2929866350014, "episode": 36.0, "batch_reward": 0.3163464474380016, "critic_loss": 0.659663315653801, "actor_loss": -34.57251741790771, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.180351734161377, "step": 36000}
{"episode_reward": 487.2885830709482, "episode": 37.0, "batch_reward": 0.3212494376599789, "critic_loss": 0.73415670722723, "actor_loss": -34.18353018569946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.168949604034424, "step": 37000}
{"episode_reward": 489.011682731855, "episode": 38.0, "batch_reward": 0.32721420082449915, "critic_loss": 0.7206075294017792, "actor_loss": -34.18887340164184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.436548948287964, "step": 38000}
{"episode_reward": 636.1163359261898, "episode": 39.0, "batch_reward": 0.3313226836323738, "critic_loss": 0.7331911769807339, "actor_loss": -34.39782931518555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.875160455703735, "step": 39000}
{"episode_reward": 425.6684818985061, "episode": 40.0, "batch_reward": 0.3325174298584461, "critic_loss": 0.747493787676096, "actor_loss": -34.909564010620116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.926164865493774, "step": 40000}
{"episode_reward": 229.66202174732734, "episode": 41.0, "batch_reward": 0.33362647441029547, "critic_loss": 0.7561933456361294, "actor_loss": -34.592383785247804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.98171401023865, "step": 41000}
{"episode_reward": 502.5600178512514, "episode": 42.0, "batch_reward": 0.3382520803809166, "critic_loss": 0.8170739498436451, "actor_loss": -34.78071987915039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.40886950492859, "step": 42000}
{"episode_reward": 548.2797828826151, "episode": 43.0, "batch_reward": 0.3423551555275917, "critic_loss": 0.8002667819559575, "actor_loss": -35.04900037002564, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.810570240020752, "step": 43000}
{"episode_reward": 510.5408986092718, "episode": 44.0, "batch_reward": 0.3426385223567486, "critic_loss": 0.8256472880840302, "actor_loss": -36.011385509490964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.04392409324646, "step": 44000}
{"episode_reward": 138.30532563148154, "episode": 45.0, "batch_reward": 0.3404073407649994, "critic_loss": 0.8859284809231758, "actor_loss": -35.05870728302002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.318044900894165, "step": 45000}
{"episode_reward": 498.8375474552961, "episode": 46.0, "batch_reward": 0.3427688027322292, "critic_loss": 0.8544866302609444, "actor_loss": -34.42238920211792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.95406413078308, "step": 46000}
{"episode_reward": 528.9486125555652, "episode": 47.0, "batch_reward": 0.3462147487699985, "critic_loss": 0.9189090808033943, "actor_loss": -34.975139038085935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.059688329696655, "step": 47000}
{"episode_reward": 514.5595868448794, "episode": 48.0, "batch_reward": 0.3530044775903225, "critic_loss": 0.9370224790573121, "actor_loss": -35.276568855285646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.880112171173096, "step": 48000}
{"episode_reward": 538.7018218813429, "episode": 49.0, "batch_reward": 0.35358631348609926, "critic_loss": 0.9643740445971489, "actor_loss": -35.9556732711792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.287545442581177, "step": 49000}
{"episode_reward": 136.55845632643596, "episode": 50.0, "batch_reward": 0.3523721967935562, "critic_loss": 0.9406241059601307, "actor_loss": -35.37064629745483, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.7481906414032, "step": 50000}
{"episode_reward": 594.0097045168337, "episode": 51.0, "batch_reward": 0.3565795750319958, "critic_loss": 0.9531808775961399, "actor_loss": -35.52098442459106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.81420397758484, "step": 51000}
{"episode_reward": 601.3170691036657, "episode": 52.0, "batch_reward": 0.3616028826832771, "critic_loss": 0.966195733487606, "actor_loss": -35.704918521881105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.15357756614685, "step": 52000}
{"episode_reward": 571.0507786652161, "episode": 53.0, "batch_reward": 0.3647719083428383, "critic_loss": 0.9630541824102402, "actor_loss": -36.41482012176514, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.715765237808228, "step": 53000}
{"episode_reward": 480.0054302956335, "episode": 54.0, "batch_reward": 0.3676770294010639, "critic_loss": 1.0047851882874965, "actor_loss": -36.849103538513184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.739651679992676, "step": 54000}
{"episode_reward": 512.461937874492, "episode": 55.0, "batch_reward": 0.36923154604434966, "critic_loss": 1.031237492799759, "actor_loss": -36.667508808135985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.17238759994507, "step": 55000}
{"episode_reward": 477.44641585865094, "episode": 56.0, "batch_reward": 0.3733466448783874, "critic_loss": 1.0363794488310814, "actor_loss": -36.892397090911864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.400142669677734, "step": 56000}
{"episode_reward": 548.2909638571526, "episode": 57.0, "batch_reward": 0.37605345526337625, "critic_loss": 1.0348939315676688, "actor_loss": -36.92960655212402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.995901584625244, "step": 57000}
{"episode_reward": 568.8915650249482, "episode": 58.0, "batch_reward": 0.37811360266804694, "critic_loss": 1.0137236097455025, "actor_loss": -37.35217365264893, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.706344842910767, "step": 58000}
{"episode_reward": 547.900442011688, "episode": 59.0, "batch_reward": 0.3814905806183815, "critic_loss": 0.9907767400145531, "actor_loss": -37.43445859527588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.601736307144165, "step": 59000}
{"episode_reward": 451.5016223672517, "episode": 60.0, "batch_reward": 0.38396677166223525, "critic_loss": 0.9732295206189155, "actor_loss": -37.61945394897461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.46739673614502, "step": 60000}
{"episode_reward": 623.206866219717, "episode": 61.0, "batch_reward": 0.38517318019270896, "critic_loss": 1.0227879071235657, "actor_loss": -37.547428050994874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.887497425079346, "step": 61000}
{"episode_reward": 520.0664029430858, "episode": 62.0, "batch_reward": 0.38893478628993033, "critic_loss": 0.995400522351265, "actor_loss": -37.85417845916748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.18482995033264, "step": 62000}
{"episode_reward": 562.3239222708784, "episode": 63.0, "batch_reward": 0.39143002972006796, "critic_loss": 1.0050761338472367, "actor_loss": -38.20842202758789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.96336579322815, "step": 63000}
{"episode_reward": 533.2081212122295, "episode": 64.0, "batch_reward": 0.39423239466547966, "critic_loss": 0.981398679792881, "actor_loss": -38.57878328704834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.084892749786377, "step": 64000}
{"episode_reward": 506.74383829493496, "episode": 65.0, "batch_reward": 0.39518938899040224, "critic_loss": 1.040840576171875, "actor_loss": -38.23081486511231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.200130939483643, "step": 65000}
{"episode_reward": 537.0379206376994, "episode": 66.0, "batch_reward": 0.39872675329446794, "critic_loss": 1.0423515924215316, "actor_loss": -38.44363597488403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.47071886062622, "step": 66000}
{"episode_reward": 635.0006011179861, "episode": 67.0, "batch_reward": 0.4003097659647465, "critic_loss": 1.0095046768188476, "actor_loss": -39.16949236679077, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.339962005615234, "step": 67000}
{"episode_reward": 334.33132242160247, "episode": 68.0, "batch_reward": 0.40100936782360075, "critic_loss": 1.0326955996155738, "actor_loss": -39.34797467041015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.158954620361328, "step": 68000}
{"episode_reward": 587.484135337161, "episode": 69.0, "batch_reward": 0.4028551324009895, "critic_loss": 1.0581694106459618, "actor_loss": -38.53726124572754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.922382354736328, "step": 69000}
{"episode_reward": 608.4620842695603, "episode": 70.0, "batch_reward": 0.4073588438332081, "critic_loss": 1.0877731807231903, "actor_loss": -38.957217903137206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.206793785095215, "step": 70000}
{"episode_reward": 579.3754604549746, "episode": 71.0, "batch_reward": 0.4088900089263916, "critic_loss": 1.0672939019203187, "actor_loss": -38.79382885360718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.55427408218384, "step": 71000}
{"episode_reward": 540.0402419529977, "episode": 72.0, "batch_reward": 0.4096201706528664, "critic_loss": 1.0541611217856408, "actor_loss": -39.576595653533936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.43978476524353, "step": 72000}
{"episode_reward": 583.0712953207081, "episode": 73.0, "batch_reward": 0.41113288098573686, "critic_loss": 1.1297777792811394, "actor_loss": -39.55536515808105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.193761348724365, "step": 73000}
{"episode_reward": 159.9372408210183, "episode": 74.0, "batch_reward": 0.4088074627220631, "critic_loss": 1.1202804592251778, "actor_loss": -38.907341564178466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.47553515434265, "step": 74000}
{"episode_reward": 579.1050948489091, "episode": 75.0, "batch_reward": 0.4103310007452965, "critic_loss": 1.1487504416704177, "actor_loss": -38.98462146759033, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.398093223571777, "step": 75000}
{"episode_reward": 298.1164563232214, "episode": 76.0, "batch_reward": 0.40991171172261237, "critic_loss": 1.191775778055191, "actor_loss": -39.24635926055908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.93667435646057, "step": 76000}
{"episode_reward": 522.4280907479412, "episode": 77.0, "batch_reward": 0.4106161473989487, "critic_loss": 1.2385538331270218, "actor_loss": -39.001075855255124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.273882389068604, "step": 77000}
{"episode_reward": 563.4199044388299, "episode": 78.0, "batch_reward": 0.4140258021950722, "critic_loss": 1.2185723959207535, "actor_loss": -39.41902871322632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.365005254745483, "step": 78000}
{"episode_reward": 588.9088465758286, "episode": 79.0, "batch_reward": 0.41545302072167395, "critic_loss": 1.230428394973278, "actor_loss": -40.10364931488037, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.031648635864258, "step": 79000}
{"episode_reward": 555.6773049120184, "episode": 80.0, "batch_reward": 0.41688929960131643, "critic_loss": 1.2861935882568358, "actor_loss": -39.87422550201416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.870469093322754, "step": 80000}
{"episode_reward": 578.4017211713333, "episode": 81.0, "batch_reward": 0.4199417322278023, "critic_loss": 1.3079178416132926, "actor_loss": -39.56571005249023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.40704703330994, "step": 81000}
{"episode_reward": 567.016299717244, "episode": 82.0, "batch_reward": 0.421698755979538, "critic_loss": 1.310125986635685, "actor_loss": -39.709999851226804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.276357412338257, "step": 82000}
{"episode_reward": 610.1552850765828, "episode": 83.0, "batch_reward": 0.42360803988575935, "critic_loss": 1.257467688202858, "actor_loss": -40.14044938278198, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.296862602233887, "step": 83000}
{"episode_reward": 604.7740564981659, "episode": 84.0, "batch_reward": 0.42556890013813975, "critic_loss": 1.2274016845822335, "actor_loss": -40.673956813812254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.4084951877594, "step": 84000}
{"episode_reward": 636.8785756468315, "episode": 85.0, "batch_reward": 0.42669203552603724, "critic_loss": 1.1686185283660888, "actor_loss": -40.495329204559326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.746918439865112, "step": 85000}
{"episode_reward": 491.2230328356729, "episode": 86.0, "batch_reward": 0.42886633348464964, "critic_loss": 1.1866138395071029, "actor_loss": -40.576117923736575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.94908881187439, "step": 86000}
{"episode_reward": 545.0309920409433, "episode": 87.0, "batch_reward": 0.4302189068198204, "critic_loss": 1.1728075273036958, "actor_loss": -40.88617710113525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.278433561325073, "step": 87000}
{"episode_reward": 505.5914651951369, "episode": 88.0, "batch_reward": 0.43159859949350354, "critic_loss": 1.1959259703159333, "actor_loss": -40.56710629272461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.36789298057556, "step": 88000}
{"episode_reward": 630.8655018782605, "episode": 89.0, "batch_reward": 0.4318193556070328, "critic_loss": 1.1867134855389596, "actor_loss": -40.86438363647461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.680724382400513, "step": 89000}
{"episode_reward": 115.53460589359409, "episode": 90.0, "batch_reward": 0.4293821268975735, "critic_loss": 1.201824577987194, "actor_loss": -40.4260280380249, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.7999849319458, "step": 90000}
{"episode_reward": 449.60432854011225, "episode": 91.0, "batch_reward": 0.430150800973177, "critic_loss": 1.212194362461567, "actor_loss": -40.54010486984253, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.18957734107971, "step": 91000}
{"episode_reward": 623.8115112789463, "episode": 92.0, "batch_reward": 0.43313679459691046, "critic_loss": 1.2559490424394608, "actor_loss": -41.28672719955444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.147695302963257, "step": 92000}
{"episode_reward": 634.2530761257103, "episode": 93.0, "batch_reward": 0.4344245759248734, "critic_loss": 1.180736215531826, "actor_loss": -40.881808544158936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.05351758003235, "step": 93000}
{"episode_reward": 646.1218485228659, "episode": 94.0, "batch_reward": 0.437442029863596, "critic_loss": 1.1887621265649795, "actor_loss": -41.347622398376465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.54035186767578, "step": 94000}
{"episode_reward": 611.4842053893228, "episode": 95.0, "batch_reward": 0.4381650126874447, "critic_loss": 1.186812185049057, "actor_loss": -41.82407403182983, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.679168939590454, "step": 95000}
{"episode_reward": 479.23048999379233, "episode": 96.0, "batch_reward": 0.44075228241086006, "critic_loss": 1.2032798354029655, "actor_loss": -41.843809749603274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.307899951934814, "step": 96000}
{"episode_reward": 603.102242244637, "episode": 97.0, "batch_reward": 0.4400525674819946, "critic_loss": 1.214200440466404, "actor_loss": -41.6291611366272, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.402459859848022, "step": 97000}
{"episode_reward": 630.6117760629118, "episode": 98.0, "batch_reward": 0.44344105681777, "critic_loss": 1.2428757041096687, "actor_loss": -42.34218235397339, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.06084418296814, "step": 98000}
{"episode_reward": 641.9306756033013, "episode": 99.0, "batch_reward": 0.44497554790973665, "critic_loss": 1.2998241125941277, "actor_loss": -41.975837020874025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.38925552368164, "step": 99000}
{"episode_reward": 610.2023646085386, "episode": 100.0, "batch_reward": 0.4461121969521046, "critic_loss": 1.2468402615189553, "actor_loss": -42.33314588928223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.656713724136353, "step": 100000}
{"episode_reward": 614.2476531693725, "episode": 101.0, "batch_reward": 0.4463237502276897, "critic_loss": 1.299154345333576, "actor_loss": -41.88421311950684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.25425887107849, "step": 101000}
{"episode_reward": 497.3394408123848, "episode": 102.0, "batch_reward": 0.44975968503952024, "critic_loss": 1.2564357886314392, "actor_loss": -42.6142846031189, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.320085525512695, "step": 102000}
{"episode_reward": 628.393799520673, "episode": 103.0, "batch_reward": 0.44903850156068803, "critic_loss": 1.2618693562746048, "actor_loss": -42.07222226333618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.570048570632935, "step": 103000}
{"episode_reward": 642.7049298512791, "episode": 104.0, "batch_reward": 0.452017747938633, "critic_loss": 1.2238727995157241, "actor_loss": -42.230134803771975, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.663454294204712, "step": 104000}
{"episode_reward": 606.4484178256598, "episode": 105.0, "batch_reward": 0.45394953349232675, "critic_loss": 1.269733725309372, "actor_loss": -42.61796924972534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.282679557800293, "step": 105000}
{"episode_reward": 613.7259032470898, "episode": 106.0, "batch_reward": 0.4554447757899761, "critic_loss": 1.2207760995626449, "actor_loss": -42.86641035461426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.933473110198975, "step": 106000}
{"episode_reward": 571.2049688519669, "episode": 107.0, "batch_reward": 0.4551666487455368, "critic_loss": 1.272008912563324, "actor_loss": -42.43115427780151, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.416616439819336, "step": 107000}
{"episode_reward": 442.6062157167955, "episode": 108.0, "batch_reward": 0.4545043574273586, "critic_loss": 1.2513507928848266, "actor_loss": -42.97310298156738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.507022857666016, "step": 108000}
{"episode_reward": 277.9784631730446, "episode": 109.0, "batch_reward": 0.4558522006571293, "critic_loss": 1.2472988523244857, "actor_loss": -42.7747509803772, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.013302087783813, "step": 109000}
{"episode_reward": 616.0634138695501, "episode": 110.0, "batch_reward": 0.45596997562050817, "critic_loss": 1.2628889278173447, "actor_loss": -43.306758899688724, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.642815828323364, "step": 110000}
{"episode_reward": 543.0563905588732, "episode": 111.0, "batch_reward": 0.4567197603881359, "critic_loss": 1.2735598545074462, "actor_loss": -42.753980869293216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 53.97413992881775, "step": 111000}
{"episode_reward": 592.3135135671739, "episode": 112.0, "batch_reward": 0.45708227080106734, "critic_loss": 1.3174003525376319, "actor_loss": -42.80855792999267, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.706690788269043, "step": 112000}
{"episode_reward": 515.1044698803062, "episode": 113.0, "batch_reward": 0.457511084407568, "critic_loss": 1.3189707930088044, "actor_loss": -42.741867130279545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.745028972625732, "step": 113000}
{"episode_reward": 523.126701784984, "episode": 114.0, "batch_reward": 0.45907311835885045, "critic_loss": 1.3268966919779777, "actor_loss": -43.22903907775879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.513063192367554, "step": 114000}
{"episode_reward": 601.6835615423263, "episode": 115.0, "batch_reward": 0.461365417778492, "critic_loss": 1.3479747564196587, "actor_loss": -43.2769447555542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.444647550582886, "step": 115000}
{"episode_reward": 625.265536238881, "episode": 116.0, "batch_reward": 0.4624350368976593, "critic_loss": 1.3758653708696365, "actor_loss": -43.469002014160154, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.36153483390808, "step": 116000}
{"episode_reward": 648.9734789582199, "episode": 117.0, "batch_reward": 0.4649481569826603, "critic_loss": 1.412587488770485, "actor_loss": -43.22184407043457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.55542492866516, "step": 117000}
{"episode_reward": 631.0049268812983, "episode": 118.0, "batch_reward": 0.4649218263924122, "critic_loss": 1.391482621908188, "actor_loss": -43.445616451263426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.970166444778442, "step": 118000}
{"episode_reward": 345.76169312086375, "episode": 119.0, "batch_reward": 0.46411247116327287, "critic_loss": 1.413371054828167, "actor_loss": -43.55531953811646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.018949270248413, "step": 119000}
{"episode_reward": 567.0710326979032, "episode": 120.0, "batch_reward": 0.4634314224123955, "critic_loss": 1.3874778370261192, "actor_loss": -42.77571474838257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.11656403541565, "step": 120000}
{"episode_reward": 571.346888264302, "episode": 121.0, "batch_reward": 0.4660729739367962, "critic_loss": 1.4347619851827622, "actor_loss": -43.400533485412595, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.05325388908386, "step": 121000}
{"episode_reward": 616.4676993038222, "episode": 122.0, "batch_reward": 0.46696222960948947, "critic_loss": 1.4105514028668404, "actor_loss": -43.772802742004394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.639195442199707, "step": 122000}
{"episode_reward": 572.6854606191553, "episode": 123.0, "batch_reward": 0.46815144962072375, "critic_loss": 1.3860566038489341, "actor_loss": -43.975140312194824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.428642988204956, "step": 123000}
{"episode_reward": 594.9785003733097, "episode": 124.0, "batch_reward": 0.4690946490466595, "critic_loss": 1.4056189331412314, "actor_loss": -43.96870766067505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.189993143081665, "step": 124000}
{"episode_reward": 575.7923788484206, "episode": 125.0, "batch_reward": 0.4673562659025192, "critic_loss": 1.52921150046587, "actor_loss": -43.62821252441406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.9805748462677, "step": 125000}
{"episode_reward": 115.64175288355693, "episode": 126.0, "batch_reward": 0.4663997020125389, "critic_loss": 1.531938205420971, "actor_loss": -43.836992446899416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.457674264907837, "step": 126000}
{"episode_reward": 644.4963668632372, "episode": 127.0, "batch_reward": 0.46847025033831596, "critic_loss": 1.6353207784891128, "actor_loss": -43.65064206695557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.02921152114868, "step": 127000}
{"episode_reward": 630.6172607139792, "episode": 128.0, "batch_reward": 0.4694639172852039, "critic_loss": 1.57123449164629, "actor_loss": -43.53199270629883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.45673441886902, "step": 128000}
{"episode_reward": 545.9370382008706, "episode": 129.0, "batch_reward": 0.4702882347404957, "critic_loss": 1.5588091861605644, "actor_loss": -43.990352363586425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.229909896850586, "step": 129000}
{"episode_reward": 667.9074580503677, "episode": 130.0, "batch_reward": 0.47181312918663026, "critic_loss": 1.5184565171003341, "actor_loss": -44.19301567077637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.093382835388184, "step": 130000}
{"episode_reward": 616.4236122392576, "episode": 131.0, "batch_reward": 0.47387789142131803, "critic_loss": 1.5019122580885886, "actor_loss": -43.61454253768921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 53.902897357940674, "step": 131000}
{"episode_reward": 646.4774150468334, "episode": 132.0, "batch_reward": 0.47409833320975303, "critic_loss": 1.438490549325943, "actor_loss": -44.57482349395752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.426193475723267, "step": 132000}
{"episode_reward": 619.2077960635867, "episode": 133.0, "batch_reward": 0.4751482897400856, "critic_loss": 1.4766168904304504, "actor_loss": -43.90080616378784, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.23917055130005, "step": 133000}
{"episode_reward": 576.4900644567773, "episode": 134.0, "batch_reward": 0.47592453834414483, "critic_loss": 1.42223304271698, "actor_loss": -44.3311851272583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.026466608047485, "step": 134000}
{"episode_reward": 604.6472334235787, "episode": 135.0, "batch_reward": 0.47592732700705526, "critic_loss": 1.4565188217759133, "actor_loss": -44.524819965362546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.322447299957275, "step": 135000}
{"episode_reward": 617.6105524317011, "episode": 136.0, "batch_reward": 0.4778928178548813, "critic_loss": 1.4553130233287812, "actor_loss": -44.426602813720706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.421184539794922, "step": 136000}
{"episode_reward": 633.9624282725655, "episode": 137.0, "batch_reward": 0.47903710237145425, "critic_loss": 1.4897047990560532, "actor_loss": -44.77213930130005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.29001808166504, "step": 137000}
{"episode_reward": 625.1168678133266, "episode": 138.0, "batch_reward": 0.4807682335078716, "critic_loss": 1.537281392812729, "actor_loss": -45.24348751449585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.40654468536377, "step": 138000}
{"episode_reward": 621.080916024378, "episode": 139.0, "batch_reward": 0.48089913913607596, "critic_loss": 1.5596450181603432, "actor_loss": -44.479166595458985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.242509841918945, "step": 139000}
{"episode_reward": 645.2092641080919, "episode": 140.0, "batch_reward": 0.4816706013381481, "critic_loss": 1.5675443363785744, "actor_loss": -45.25139822769165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.666621446609497, "step": 140000}
{"episode_reward": 650.6794664716082, "episode": 141.0, "batch_reward": 0.48431387639045714, "critic_loss": 1.5258539043664932, "actor_loss": -45.17432794189453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.1589891910553, "step": 141000}
{"episode_reward": 563.8361233910512, "episode": 142.0, "batch_reward": 0.4836885076761246, "critic_loss": 1.563498382270336, "actor_loss": -45.00016843032837, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.0490403175354, "step": 142000}
{"episode_reward": 660.0996452685321, "episode": 143.0, "batch_reward": 0.48484643098711966, "critic_loss": 1.6009879571795465, "actor_loss": -45.29299972915649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.87497901916504, "step": 143000}
{"episode_reward": 517.5036910501494, "episode": 144.0, "batch_reward": 0.4856020895242691, "critic_loss": 1.63548926872015, "actor_loss": -45.43047165679932, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.91659164428711, "step": 144000}
{"episode_reward": 621.9628671311681, "episode": 145.0, "batch_reward": 0.4869422197639942, "critic_loss": 1.6557945411801338, "actor_loss": -45.54533945465088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.78884720802307, "step": 145000}
{"episode_reward": 641.9647573393873, "episode": 146.0, "batch_reward": 0.4871465075612068, "critic_loss": 1.641182690501213, "actor_loss": -45.031393600463865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.057626247406006, "step": 146000}
{"episode_reward": 622.4760690575, "episode": 147.0, "batch_reward": 0.487241741925478, "critic_loss": 1.5796237854361534, "actor_loss": -45.43770372009277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.565421104431152, "step": 147000}
{"episode_reward": 596.964123646362, "episode": 148.0, "batch_reward": 0.4900911138653755, "critic_loss": 1.6114122554063797, "actor_loss": -45.57942485809326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.426900625228882, "step": 148000}
{"episode_reward": 619.5670895498076, "episode": 149.0, "batch_reward": 0.4898642067909241, "critic_loss": 1.61969200694561, "actor_loss": -45.71370379638672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.454105377197266, "step": 149000}
{"episode_reward": 619.4258407008093, "episode": 150.0, "batch_reward": 0.48987214079499247, "critic_loss": 1.6093243466615677, "actor_loss": -45.92424918365479, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
