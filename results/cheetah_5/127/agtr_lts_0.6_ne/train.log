{"episode_reward": 0.0, "episode": 1.0, "duration": 17.975033044815063, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.536604881286621, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.27756789176612745, "critic_loss": 0.2654674238674082, "actor_loss": -39.75713072704668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 69.6725971698761, "step": 3000}
{"episode_reward": 212.63335611133482, "episode": 4.0, "batch_reward": 0.2717214722931385, "critic_loss": 0.3201039603352547, "actor_loss": -35.15193393325806, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.904273748397827, "step": 4000}
{"episode_reward": 289.08036577470546, "episode": 5.0, "batch_reward": 0.27862835232913497, "critic_loss": 0.5123101514279842, "actor_loss": -33.90170022201538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.866786241531372, "step": 5000}
{"episode_reward": 370.3683215673474, "episode": 6.0, "batch_reward": 0.28894074127078057, "critic_loss": 0.6541845253407955, "actor_loss": -34.25718760299683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.86469292640686, "step": 6000}
{"episode_reward": 307.0640584777196, "episode": 7.0, "batch_reward": 0.29829588352143765, "critic_loss": 0.7108995455801487, "actor_loss": -35.038259098052976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.866788864135742, "step": 7000}
{"episode_reward": 505.81857255490854, "episode": 8.0, "batch_reward": 0.3252111018449068, "critic_loss": 0.6744025586545468, "actor_loss": -36.990374111175534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.88479518890381, "step": 8000}
{"episode_reward": 491.90402927525435, "episode": 9.0, "batch_reward": 0.3396039871871471, "critic_loss": 0.7546836533546448, "actor_loss": -38.44204192352295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.847299814224243, "step": 9000}
{"episode_reward": 410.2797687259552, "episode": 10.0, "batch_reward": 0.33869380375742913, "critic_loss": 0.7126962464153767, "actor_loss": -38.93068872833252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.803414821624756, "step": 10000}
{"episode_reward": 240.36433716607232, "episode": 11.0, "batch_reward": 0.3467712436020374, "critic_loss": 0.7677911184430123, "actor_loss": -39.56676233673096, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.77552247047424, "step": 11000}
{"episode_reward": 534.9260327592717, "episode": 12.0, "batch_reward": 0.3614039242267609, "critic_loss": 0.8236307253241539, "actor_loss": -40.15147430419922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.790942192077637, "step": 12000}
{"episode_reward": 547.8684457200605, "episode": 13.0, "batch_reward": 0.3741991806924343, "critic_loss": 0.9636217185854912, "actor_loss": -41.12925915527344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.314661741256714, "step": 13000}
{"episode_reward": 512.2817751641848, "episode": 14.0, "batch_reward": 0.3753016524910927, "critic_loss": 1.0266781768202782, "actor_loss": -40.89278092193604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.550193309783936, "step": 14000}
{"episode_reward": 112.5794774368481, "episode": 15.0, "batch_reward": 0.3513495502769947, "critic_loss": 0.956002133488655, "actor_loss": -39.19236959838867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.935414791107178, "step": 15000}
{"episode_reward": 10.295063161079945, "episode": 16.0, "batch_reward": 0.32981146410107615, "critic_loss": 0.9408760870099068, "actor_loss": -38.88852415466309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.956684827804565, "step": 16000}
{"episode_reward": 5.325589524773218, "episode": 17.0, "batch_reward": 0.3118760044723749, "critic_loss": 1.0501044632196426, "actor_loss": -38.46220309448242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.933766841888428, "step": 17000}
{"episode_reward": 56.5739421716299, "episode": 18.0, "batch_reward": 0.30542425221204755, "critic_loss": 1.2445371205806732, "actor_loss": -38.34723053741455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.982882261276245, "step": 18000}
{"episode_reward": 376.70435003578535, "episode": 19.0, "batch_reward": 0.3065297078490257, "critic_loss": 1.4661942615509034, "actor_loss": -38.38303116607666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.928038358688354, "step": 19000}
{"episode_reward": 220.27842438954792, "episode": 20.0, "batch_reward": 0.3041670875698328, "critic_loss": 1.420011079788208, "actor_loss": -37.429415351867675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.946075439453125, "step": 20000}
{"episode_reward": 269.6474724121701, "episode": 21.0, "batch_reward": 0.3011842966377735, "critic_loss": 1.4472339833378791, "actor_loss": -37.2707942314148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.94154167175293, "step": 21000}
{"episode_reward": 386.33265722606694, "episode": 22.0, "batch_reward": 0.30611389356851576, "critic_loss": 1.4210148045420647, "actor_loss": -37.302957420349124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.899975538253784, "step": 22000}
{"episode_reward": 469.8067149247564, "episode": 23.0, "batch_reward": 0.31506849120557306, "critic_loss": 1.492812301814556, "actor_loss": -37.89337728500366, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.928009271621704, "step": 23000}
{"episode_reward": 528.3120191711342, "episode": 24.0, "batch_reward": 0.3207989100217819, "critic_loss": 1.74145454287529, "actor_loss": -38.18600161743164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.94806957244873, "step": 24000}
{"episode_reward": 241.47268437644405, "episode": 25.0, "batch_reward": 0.3180154787749052, "critic_loss": 1.7485731611251831, "actor_loss": -37.6924993095398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.906046867370605, "step": 25000}
{"episode_reward": 442.81022875108727, "episode": 26.0, "batch_reward": 0.3182228703945875, "critic_loss": 1.6951081731319428, "actor_loss": -37.53405629730224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.954405546188354, "step": 26000}
{"episode_reward": 19.16677080602046, "episode": 27.0, "batch_reward": 0.312296672642231, "critic_loss": 1.8764940336942673, "actor_loss": -37.38645241165161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.934245586395264, "step": 27000}
{"episode_reward": 362.2483569378246, "episode": 28.0, "batch_reward": 0.31509566500782965, "critic_loss": 1.9911372470855713, "actor_loss": -37.604819362640384, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.895904064178467, "step": 28000}
{"episode_reward": 501.17523841783014, "episode": 29.0, "batch_reward": 0.3150447795242071, "critic_loss": 1.904122165083885, "actor_loss": -38.231338497161865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.96353530883789, "step": 29000}
{"episode_reward": 98.17065216888702, "episode": 30.0, "batch_reward": 0.31318390698730947, "critic_loss": 2.0222980123758316, "actor_loss": -38.70451528930664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.906254053115845, "step": 30000}
{"episode_reward": 425.06104246115, "episode": 31.0, "batch_reward": 0.3198066082149744, "critic_loss": 2.0703308291435243, "actor_loss": -39.013539775848386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.866206645965576, "step": 31000}
{"episode_reward": 441.8477372342084, "episode": 32.0, "batch_reward": 0.3193805204331875, "critic_loss": 2.219926302075386, "actor_loss": -38.80669075393677, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.869510650634766, "step": 32000}
{"episode_reward": 244.31957595874846, "episode": 33.0, "batch_reward": 0.3154876842200756, "critic_loss": 2.0408390272855756, "actor_loss": -38.28274809265137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.921343088150024, "step": 33000}
{"episode_reward": 55.69215682967844, "episode": 34.0, "batch_reward": 0.30607640950381754, "critic_loss": 1.846492267012596, "actor_loss": -37.64708881759643, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.938782453536987, "step": 34000}
{"episode_reward": 5.337034596561156, "episode": 35.0, "batch_reward": 0.29787277138233187, "critic_loss": 1.723875425696373, "actor_loss": -37.32139111328125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.953401803970337, "step": 35000}
{"episode_reward": 6.7941450965292605, "episode": 36.0, "batch_reward": 0.28936463268101215, "critic_loss": 1.5357204481959343, "actor_loss": -36.775679557800295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.93324851989746, "step": 36000}
{"episode_reward": 4.040477585122053, "episode": 37.0, "batch_reward": 0.28066291515529157, "critic_loss": 1.4078857984542847, "actor_loss": -36.81506113433838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.89521837234497, "step": 37000}
{"episode_reward": 4.3739382365791695, "episode": 38.0, "batch_reward": 0.2739661029875278, "critic_loss": 1.2288306604623795, "actor_loss": -36.39926490020752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.932432413101196, "step": 38000}
{"episode_reward": 5.834355365366707, "episode": 39.0, "batch_reward": 0.2657696667164564, "critic_loss": 1.1213354006409646, "actor_loss": -36.049119174957276, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.870943784713745, "step": 39000}
{"episode_reward": 6.78903338853961, "episode": 40.0, "batch_reward": 0.2604356085062027, "critic_loss": 1.0131946967244148, "actor_loss": -35.70559765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.89198660850525, "step": 40000}
{"episode_reward": 7.423168682173447, "episode": 41.0, "batch_reward": 0.25377993626892564, "critic_loss": 0.9052541045546532, "actor_loss": -35.44557601547241, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.01301693916321, "step": 41000}
{"episode_reward": 5.429132967047106, "episode": 42.0, "batch_reward": 0.24947530062496662, "critic_loss": 0.8412057505548001, "actor_loss": -35.186847732543946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.85964059829712, "step": 42000}
{"episode_reward": 3.917928767225041, "episode": 43.0, "batch_reward": 0.2416699674129486, "critic_loss": 0.7678100676238537, "actor_loss": -34.69791562271118, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.813138961791992, "step": 43000}
{"episode_reward": 8.207043571352965, "episode": 44.0, "batch_reward": 0.2391314126998186, "critic_loss": 0.7465323724448681, "actor_loss": -34.30711473846436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.849602222442627, "step": 44000}
{"episode_reward": 150.3334756285552, "episode": 45.0, "batch_reward": 0.23479224902391432, "critic_loss": 0.7593670707643032, "actor_loss": -34.099554832458495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.787927627563477, "step": 45000}
{"episode_reward": 11.333200529968314, "episode": 46.0, "batch_reward": 0.23391406811773777, "critic_loss": 0.8002965633273125, "actor_loss": -33.91197232818603, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.270860195159912, "step": 46000}
{"episode_reward": 423.79055092131097, "episode": 47.0, "batch_reward": 0.2381189621835947, "critic_loss": 0.8736083965301513, "actor_loss": -34.00000680541992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.915311098098755, "step": 47000}
{"episode_reward": 406.57748177583915, "episode": 48.0, "batch_reward": 0.24213090857863426, "critic_loss": 0.9719325067996979, "actor_loss": -34.0298945274353, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.94367504119873, "step": 48000}
{"episode_reward": 541.7837311714909, "episode": 49.0, "batch_reward": 0.24670256297290324, "critic_loss": 1.0616678482592106, "actor_loss": -34.11748384475708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.978179693222046, "step": 49000}
{"episode_reward": 264.2120992174307, "episode": 50.0, "batch_reward": 0.2504281733185053, "critic_loss": 1.160415502667427, "actor_loss": -34.269874351501464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.930397987365723, "step": 50000}
{"episode_reward": 575.9360113999799, "episode": 51.0, "batch_reward": 0.25087282961606977, "critic_loss": 1.3894325193166732, "actor_loss": -34.15711966705322, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.993107318878174, "step": 51000}
{"episode_reward": 44.495978822532585, "episode": 52.0, "batch_reward": 0.24976797308027746, "critic_loss": 1.2919614149928094, "actor_loss": -34.18374597930908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.922086000442505, "step": 52000}
{"episode_reward": 455.35505759590654, "episode": 53.0, "batch_reward": 0.25542060340940953, "critic_loss": 1.1486087393760682, "actor_loss": -34.48307238388062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.902815580368042, "step": 53000}
{"episode_reward": 494.4952654259756, "episode": 54.0, "batch_reward": 0.25942485715448854, "critic_loss": 1.0975323820114136, "actor_loss": -34.45467166519165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.954604148864746, "step": 54000}
{"episode_reward": 492.96449630030924, "episode": 55.0, "batch_reward": 0.2643379693478346, "critic_loss": 1.1122485947012901, "actor_loss": -34.40483261108398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.91079831123352, "step": 55000}
{"episode_reward": 503.6743328078658, "episode": 56.0, "batch_reward": 0.26784236282110213, "critic_loss": 1.1088125602602958, "actor_loss": -34.40531558227539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.95544147491455, "step": 56000}
{"episode_reward": 468.82137382030646, "episode": 57.0, "batch_reward": 0.26983283218741416, "critic_loss": 1.1591857244968415, "actor_loss": -34.20306014251709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.926700830459595, "step": 57000}
{"episode_reward": 85.28352075647936, "episode": 58.0, "batch_reward": 0.26767652992904184, "critic_loss": 1.1332565302252768, "actor_loss": -33.96117140197754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.919885635375977, "step": 58000}
{"episode_reward": 377.9078651301624, "episode": 59.0, "batch_reward": 0.26857960505783557, "critic_loss": 1.1946171221733093, "actor_loss": -33.970429084777834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.007421731948853, "step": 59000}
{"episode_reward": 51.582122589831926, "episode": 60.0, "batch_reward": 0.2649595803022385, "critic_loss": 1.1577596580982208, "actor_loss": -33.85591640090942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.136144161224365, "step": 60000}
{"episode_reward": 202.79883717076873, "episode": 61.0, "batch_reward": 0.2645221785157919, "critic_loss": 1.045368048518896, "actor_loss": -33.5576212387085, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.0051007270813, "step": 61000}
{"episode_reward": 315.93189929249496, "episode": 62.0, "batch_reward": 0.2660725582689047, "critic_loss": 0.9960762590765954, "actor_loss": -33.4584475440979, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.896146059036255, "step": 62000}
{"episode_reward": 305.60735657805, "episode": 63.0, "batch_reward": 0.26516383078694344, "critic_loss": 0.9385528858006, "actor_loss": -33.40751503372192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.90604305267334, "step": 63000}
{"episode_reward": 330.4047293299357, "episode": 64.0, "batch_reward": 0.26641796535253526, "critic_loss": 0.9044981971383095, "actor_loss": -33.08978845596314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.86180067062378, "step": 64000}
{"episode_reward": 227.24913587431018, "episode": 65.0, "batch_reward": 0.2668473522663116, "critic_loss": 0.8438247102200985, "actor_loss": -32.921905170440674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.926676511764526, "step": 65000}
{"episode_reward": 536.1487844647075, "episode": 66.0, "batch_reward": 0.2724495947808027, "critic_loss": 0.8431074637770652, "actor_loss": -32.91931162643433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.15268349647522, "step": 66000}
{"episode_reward": 583.5560986557088, "episode": 67.0, "batch_reward": 0.2778092275112867, "critic_loss": 0.8101274567544461, "actor_loss": -33.09324715042114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.950831651687622, "step": 67000}
{"episode_reward": 560.8570595680883, "episode": 68.0, "batch_reward": 0.28025733001530173, "critic_loss": 0.8054315812289715, "actor_loss": -33.13397226333618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.8926100730896, "step": 68000}
{"episode_reward": 539.9431352196794, "episode": 69.0, "batch_reward": 0.2835462795048952, "critic_loss": 0.7532987901568413, "actor_loss": -32.93497118759155, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.900136470794678, "step": 69000}
{"episode_reward": 476.6749530846937, "episode": 70.0, "batch_reward": 0.28616618989408016, "critic_loss": 0.794548209786415, "actor_loss": -32.81613331222534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.916808605194092, "step": 70000}
{"episode_reward": 179.4889992522338, "episode": 71.0, "batch_reward": 0.28557029004395007, "critic_loss": 0.8097888172268868, "actor_loss": -32.518922863006594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.9111168384552, "step": 71000}
{"episode_reward": 305.55008753524, "episode": 72.0, "batch_reward": 0.2865490023046732, "critic_loss": 0.756980778157711, "actor_loss": -32.45089143371582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.876073122024536, "step": 72000}
{"episode_reward": 557.711382956445, "episode": 73.0, "batch_reward": 0.29010399186611174, "critic_loss": 0.7082214109897613, "actor_loss": -32.526137928009035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.855130434036255, "step": 73000}
{"episode_reward": 554.1868515345457, "episode": 74.0, "batch_reward": 0.29305659905076026, "critic_loss": 0.7374125362932682, "actor_loss": -32.59942109298706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.833268404006958, "step": 74000}
{"episode_reward": 564.4066048876462, "episode": 75.0, "batch_reward": 0.2972076048403978, "critic_loss": 0.7142160621285438, "actor_loss": -32.78533511734009, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.86194634437561, "step": 75000}
{"episode_reward": 678.1370340715723, "episode": 76.0, "batch_reward": 0.3031254532635212, "critic_loss": 0.7286525857448578, "actor_loss": -33.1227126083374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.815670490264893, "step": 76000}
{"episode_reward": 608.4618517468797, "episode": 77.0, "batch_reward": 0.30699282394349575, "critic_loss": 0.7023644594848156, "actor_loss": -33.39033201599121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.824150800704956, "step": 77000}
{"episode_reward": 574.6489718645252, "episode": 78.0, "batch_reward": 0.31024393509328363, "critic_loss": 0.6869921739399433, "actor_loss": -33.401576946258544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.462804794311523, "step": 78000}
{"episode_reward": 568.2760132133628, "episode": 79.0, "batch_reward": 0.3129987665563822, "critic_loss": 0.6599670827686787, "actor_loss": -33.71936310958862, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.651183366775513, "step": 79000}
{"episode_reward": 606.8512564110155, "episode": 80.0, "batch_reward": 0.3157766287922859, "critic_loss": 0.6653695405125618, "actor_loss": -33.84577341461182, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.946213245391846, "step": 80000}
{"episode_reward": 596.651449300992, "episode": 81.0, "batch_reward": 0.3207518905550241, "critic_loss": 0.6761417708396912, "actor_loss": -34.28154753112793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.963565826416016, "step": 81000}
{"episode_reward": 589.686851842971, "episode": 82.0, "batch_reward": 0.3237289916872978, "critic_loss": 0.6839098487198353, "actor_loss": -34.147397422790526, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.94005560874939, "step": 82000}
{"episode_reward": 547.8210292811892, "episode": 83.0, "batch_reward": 0.3253399837017059, "critic_loss": 0.7070926959812641, "actor_loss": -34.487544826507566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.910183429718018, "step": 83000}
{"episode_reward": 449.28862776278424, "episode": 84.0, "batch_reward": 0.3279254705905914, "critic_loss": 0.7905360450744628, "actor_loss": -34.497545558929446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.96170997619629, "step": 84000}
{"episode_reward": 299.9168669933536, "episode": 85.0, "batch_reward": 0.32650972917675974, "critic_loss": 0.6883362946212291, "actor_loss": -34.19397569274902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.911296129226685, "step": 85000}
{"episode_reward": 589.9198250022145, "episode": 86.0, "batch_reward": 0.33035233080387116, "critic_loss": 0.7292355748713016, "actor_loss": -34.49627117156982, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.959702491760254, "step": 86000}
{"episode_reward": 584.2034078973717, "episode": 87.0, "batch_reward": 0.33413020591437814, "critic_loss": 0.7706214454770088, "actor_loss": -34.85986293411255, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.907992124557495, "step": 87000}
{"episode_reward": 564.548248740725, "episode": 88.0, "batch_reward": 0.3355210494697094, "critic_loss": 0.9044285076260566, "actor_loss": -34.5135856590271, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.968367099761963, "step": 88000}
{"episode_reward": 496.71514280028816, "episode": 89.0, "batch_reward": 0.33844205844402314, "critic_loss": 0.9364956516623497, "actor_loss": -34.71693939971924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.942323207855225, "step": 89000}
{"episode_reward": 633.8916910519115, "episode": 90.0, "batch_reward": 0.3413946686387062, "critic_loss": 0.9353805134892463, "actor_loss": -34.903148490905764, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.899693965911865, "step": 90000}
{"episode_reward": 617.7962932366709, "episode": 91.0, "batch_reward": 0.34320480808615683, "critic_loss": 0.8997929847538472, "actor_loss": -34.93966486358642, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.9922034740448, "step": 91000}
{"episode_reward": 421.47193304760583, "episode": 92.0, "batch_reward": 0.34623671650886534, "critic_loss": 0.8288803277313709, "actor_loss": -35.37614946365356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.887362718582153, "step": 92000}
{"episode_reward": 501.06489457932946, "episode": 93.0, "batch_reward": 0.34681577441096306, "critic_loss": 0.8374414322674274, "actor_loss": -35.163634830474855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.934624433517456, "step": 93000}
{"episode_reward": 665.3987616921709, "episode": 94.0, "batch_reward": 0.3494221575856209, "critic_loss": 0.8318780780434608, "actor_loss": -35.565404312133786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.939091444015503, "step": 94000}
{"episode_reward": 611.3474296577293, "episode": 95.0, "batch_reward": 0.353563920468092, "critic_loss": 0.8144191417396068, "actor_loss": -36.12536835098267, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.882383823394775, "step": 95000}
{"episode_reward": 583.900836304923, "episode": 96.0, "batch_reward": 0.3570259375870228, "critic_loss": 0.8875645507276059, "actor_loss": -36.04126583099365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.900171756744385, "step": 96000}
{"episode_reward": 638.0721826565045, "episode": 97.0, "batch_reward": 0.35921749553084376, "critic_loss": 0.8240110978782177, "actor_loss": -35.863036853790284, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.88097858428955, "step": 97000}
{"episode_reward": 595.2765364184543, "episode": 98.0, "batch_reward": 0.36056088599562647, "critic_loss": 0.8180735920965672, "actor_loss": -36.644962329864505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.94157361984253, "step": 98000}
{"episode_reward": 579.7851707263712, "episode": 99.0, "batch_reward": 0.3631005889177322, "critic_loss": 0.8776908860206604, "actor_loss": -36.5001768913269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.916442155838013, "step": 99000}
{"episode_reward": 601.5097598783351, "episode": 100.0, "batch_reward": 0.3635294612646103, "critic_loss": 1.066719616174698, "actor_loss": -36.40699499130249, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.92370343208313, "step": 100000}
{"episode_reward": 180.1908925464941, "episode": 101.0, "batch_reward": 0.3627904985845089, "critic_loss": 1.01341390183568, "actor_loss": -36.352885456085204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.930079221725464, "step": 101000}
{"episode_reward": 553.0594128382535, "episode": 102.0, "batch_reward": 0.36594492599368095, "critic_loss": 0.9787909341454506, "actor_loss": -36.767603439331054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.900592803955078, "step": 102000}
{"episode_reward": 479.76225506456063, "episode": 103.0, "batch_reward": 0.3666335863173008, "critic_loss": 0.8990300729274749, "actor_loss": -36.83907894897461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.87474799156189, "step": 103000}
{"episode_reward": 597.7752952693672, "episode": 104.0, "batch_reward": 0.36857537466287615, "critic_loss": 0.9353186367750168, "actor_loss": -36.67393536758423, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.85364580154419, "step": 104000}
{"episode_reward": 593.9003858624006, "episode": 105.0, "batch_reward": 0.37046691673994064, "critic_loss": 1.000331066071987, "actor_loss": -36.79794075012207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.88495635986328, "step": 105000}
{"episode_reward": 575.5457626355712, "episode": 106.0, "batch_reward": 0.3724577811658382, "critic_loss": 0.8995585589408874, "actor_loss": -37.13590181350708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.840596437454224, "step": 106000}
{"episode_reward": 544.078425215008, "episode": 107.0, "batch_reward": 0.37377553364634514, "critic_loss": 0.8946930330097675, "actor_loss": -37.114131145477295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.834253311157227, "step": 107000}
{"episode_reward": 523.2530817207153, "episode": 108.0, "batch_reward": 0.3763707255721092, "critic_loss": 0.8739216464161873, "actor_loss": -37.67989072036743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.815727710723877, "step": 108000}
{"episode_reward": 576.7153547781273, "episode": 109.0, "batch_reward": 0.3787441792488098, "critic_loss": 0.8778220919966697, "actor_loss": -37.717915309906004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.852145671844482, "step": 109000}
{"episode_reward": 633.7026364284754, "episode": 110.0, "batch_reward": 0.38037159195542336, "critic_loss": 0.8260033747851848, "actor_loss": -38.14407065582275, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.758437156677246, "step": 110000}
{"episode_reward": 603.0112439864902, "episode": 111.0, "batch_reward": 0.38163406133651734, "critic_loss": 0.836347010731697, "actor_loss": -37.77071646881104, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.51462411880493, "step": 111000}
{"episode_reward": 584.1306574871163, "episode": 112.0, "batch_reward": 0.3835437012910843, "critic_loss": 0.8282819884121418, "actor_loss": -38.209008224487306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.94742512702942, "step": 112000}
{"episode_reward": 628.3887909038584, "episode": 113.0, "batch_reward": 0.3852154521048069, "critic_loss": 0.8115821447074413, "actor_loss": -38.1101498336792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.93580198287964, "step": 113000}
{"episode_reward": 588.2748427982702, "episode": 114.0, "batch_reward": 0.38798722201585767, "critic_loss": 0.7998233565986157, "actor_loss": -38.48694679260254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.900298595428467, "step": 114000}
{"episode_reward": 646.3072502169799, "episode": 115.0, "batch_reward": 0.3898844629228115, "critic_loss": 0.7957170279622078, "actor_loss": -38.53740995788574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.9320969581604, "step": 115000}
{"episode_reward": 565.2001344359248, "episode": 116.0, "batch_reward": 0.3932787235379219, "critic_loss": 0.7790988086462021, "actor_loss": -38.80104644393921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.933753490447998, "step": 116000}
{"episode_reward": 652.7881996913022, "episode": 117.0, "batch_reward": 0.3944692145884037, "critic_loss": 0.7493563163876533, "actor_loss": -38.76942054748535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.919639825820923, "step": 117000}
{"episode_reward": 582.4089210796034, "episode": 118.0, "batch_reward": 0.39579881671071054, "critic_loss": 0.7778478018343449, "actor_loss": -38.977651763916015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.89934015274048, "step": 118000}
{"episode_reward": 621.1801166658388, "episode": 119.0, "batch_reward": 0.397676653534174, "critic_loss": 0.7946267203986644, "actor_loss": -39.00854761886597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.961135387420654, "step": 119000}
{"episode_reward": 631.8108270052728, "episode": 120.0, "batch_reward": 0.4007122958004475, "critic_loss": 0.7598785035312176, "actor_loss": -39.331099029541015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.898258924484253, "step": 120000}
{"episode_reward": 674.3125999741153, "episode": 121.0, "batch_reward": 0.4017711453437805, "critic_loss": 0.7691322017014026, "actor_loss": -39.39475717926025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.937886238098145, "step": 121000}
{"episode_reward": 661.0713278717665, "episode": 122.0, "batch_reward": 0.40330135309696197, "critic_loss": 0.7640129396617412, "actor_loss": -39.63429679870605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.892791748046875, "step": 122000}
{"episode_reward": 641.7317307167476, "episode": 123.0, "batch_reward": 0.40547809943556784, "critic_loss": 0.738148947685957, "actor_loss": -39.809556129455565, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.935855627059937, "step": 123000}
{"episode_reward": 588.7388643128063, "episode": 124.0, "batch_reward": 0.4066354831457138, "critic_loss": 0.754011081635952, "actor_loss": -40.05573198318481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.925068140029907, "step": 124000}
{"episode_reward": 543.0021905936989, "episode": 125.0, "batch_reward": 0.4073751517534256, "critic_loss": 0.7814302043914795, "actor_loss": -39.94030313110351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.87239384651184, "step": 125000}
{"episode_reward": 600.6258009053581, "episode": 126.0, "batch_reward": 0.4092011149227619, "critic_loss": 0.7755966008305549, "actor_loss": -40.14262668609619, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.93311858177185, "step": 126000}
{"episode_reward": 646.2515110088937, "episode": 127.0, "batch_reward": 0.4118783675134182, "critic_loss": 0.7472042110860347, "actor_loss": -40.425334266662595, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.90638303756714, "step": 127000}
{"episode_reward": 630.8925055557041, "episode": 128.0, "batch_reward": 0.41332454711198807, "critic_loss": 0.7463979308903217, "actor_loss": -40.59197060394287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.850374937057495, "step": 128000}
{"episode_reward": 651.6435968293906, "episode": 129.0, "batch_reward": 0.41518659302592276, "critic_loss": 0.7696021422743797, "actor_loss": -40.58300122833252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.876622438430786, "step": 129000}
{"episode_reward": 641.6976331862005, "episode": 130.0, "batch_reward": 0.4173504509627819, "critic_loss": 0.7448313066363335, "actor_loss": -40.804021965026855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.902341842651367, "step": 130000}
{"episode_reward": 659.5540629715816, "episode": 131.0, "batch_reward": 0.4196441135406494, "critic_loss": 0.7315554750263691, "actor_loss": -40.70247826385498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.90503001213074, "step": 131000}
{"episode_reward": 617.5674864238948, "episode": 132.0, "batch_reward": 0.42080574652552605, "critic_loss": 0.7281631124317646, "actor_loss": -41.054204208374024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.914597272872925, "step": 132000}
{"episode_reward": 687.2183301055663, "episode": 133.0, "batch_reward": 0.42198192247748373, "critic_loss": 0.7272882874906063, "actor_loss": -40.986932189941406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.903043031692505, "step": 133000}
{"episode_reward": 607.955385992348, "episode": 134.0, "batch_reward": 0.42258402052521704, "critic_loss": 0.7097749353349209, "actor_loss": -41.26036260986328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.903990268707275, "step": 134000}
{"episode_reward": 654.7423584969335, "episode": 135.0, "batch_reward": 0.4257279317975044, "critic_loss": 0.7242325964868068, "actor_loss": -41.5372481918335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.853870630264282, "step": 135000}
{"episode_reward": 665.3798132562077, "episode": 136.0, "batch_reward": 0.4277291900217533, "critic_loss": 0.7092608594000339, "actor_loss": -41.81095199584961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.899302005767822, "step": 136000}
{"episode_reward": 654.7016641273783, "episode": 137.0, "batch_reward": 0.4285855632722378, "critic_loss": 0.6807948377728462, "actor_loss": -41.688164772033694, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.85483431816101, "step": 137000}
{"episode_reward": 675.1635421419264, "episode": 138.0, "batch_reward": 0.43157056778669356, "critic_loss": 0.6792185027003288, "actor_loss": -41.887332160949704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.846614599227905, "step": 138000}
{"episode_reward": 672.973463731502, "episode": 139.0, "batch_reward": 0.43203075930476187, "critic_loss": 0.6909874329268932, "actor_loss": -42.073044090271, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.83172631263733, "step": 139000}
{"episode_reward": 650.0010094775961, "episode": 140.0, "batch_reward": 0.4338306137919426, "critic_loss": 0.6517474486529827, "actor_loss": -42.321223739624024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.85365915298462, "step": 140000}
{"episode_reward": 614.5433797413647, "episode": 141.0, "batch_reward": 0.43689547726511957, "critic_loss": 0.6738783173263073, "actor_loss": -42.40169505310059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.81977319717407, "step": 141000}
{"episode_reward": 632.8421018173914, "episode": 142.0, "batch_reward": 0.4368673183321953, "critic_loss": 0.664403564542532, "actor_loss": -42.45399122619629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.77374243736267, "step": 142000}
{"episode_reward": 661.4704594855591, "episode": 143.0, "batch_reward": 0.4370601449906826, "critic_loss": 0.6701041899621487, "actor_loss": -42.414695594787595, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.270511150360107, "step": 143000}
{"episode_reward": 671.6797544262605, "episode": 144.0, "batch_reward": 0.43885955640673635, "critic_loss": 0.6866122937202453, "actor_loss": -42.6147826538086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.951706647872925, "step": 144000}
{"episode_reward": 639.964645350302, "episode": 145.0, "batch_reward": 0.44128345733880997, "critic_loss": 0.6835613785386085, "actor_loss": -42.80005827331543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.958800315856934, "step": 145000}
{"episode_reward": 636.1729706098989, "episode": 146.0, "batch_reward": 0.44124403756856917, "critic_loss": 0.6604973165690899, "actor_loss": -42.700962677001954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.98266911506653, "step": 146000}
{"episode_reward": 702.2851497251409, "episode": 147.0, "batch_reward": 0.4428383680284023, "critic_loss": 0.6911974196434021, "actor_loss": -43.11357804870605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.918421030044556, "step": 147000}
{"episode_reward": 598.2051643379225, "episode": 148.0, "batch_reward": 0.445692144960165, "critic_loss": 0.6974092149734497, "actor_loss": -43.304462440490724, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.931082010269165, "step": 148000}
{"episode_reward": 664.9867459092965, "episode": 149.0, "batch_reward": 0.4482918038368225, "critic_loss": 0.7219011582732201, "actor_loss": -43.44324775695801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.936503887176514, "step": 149000}
{"episode_reward": 649.8956382831866, "episode": 150.0, "batch_reward": 0.4478413446247578, "critic_loss": 0.7035183380842209, "actor_loss": -43.32674250793457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
