{"episode_reward": 0.0, "episode": 1.0, "duration": 14.100889444351196, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.222923994064331, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.26275661806338385, "critic_loss": 0.06140530818844138, "actor_loss": -31.351362953911355, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 74.37971186637878, "step": 3000}
{"episode_reward": 27.10053371826286, "episode": 4.0, "batch_reward": 0.1832656718939543, "critic_loss": 0.05347867080755532, "actor_loss": -21.797486531496048, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.80307412147522, "step": 4000}
{"episode_reward": 81.72861341140194, "episode": 5.0, "batch_reward": 0.15422535908222199, "critic_loss": 0.04807526330836117, "actor_loss": -19.74381626391411, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.885502338409424, "step": 5000}
{"episode_reward": 52.93031610154889, "episode": 6.0, "batch_reward": 0.1387385009676218, "critic_loss": 0.05658330792374909, "actor_loss": -17.57015018731356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.497543573379517, "step": 6000}
{"episode_reward": 118.44315577490015, "episode": 7.0, "batch_reward": 0.13580013059079646, "critic_loss": 0.05992210757918656, "actor_loss": -18.730237974345684, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.43620467185974, "step": 7000}
{"episode_reward": 127.67861358928617, "episode": 8.0, "batch_reward": 0.14418412958085536, "critic_loss": 0.08930169709026814, "actor_loss": -18.72169769075513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.463464975357056, "step": 8000}
{"episode_reward": 242.66970781625355, "episode": 9.0, "batch_reward": 0.148646650493145, "critic_loss": 0.08752574860304595, "actor_loss": -18.743266348972917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.381980180740356, "step": 9000}
{"episode_reward": 125.67422522484246, "episode": 10.0, "batch_reward": 0.14476158449798823, "critic_loss": 0.08879799976944923, "actor_loss": -18.183308031737806, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.710267305374146, "step": 10000}
{"episode_reward": 62.62505359545445, "episode": 11.0, "batch_reward": 0.1349772402346134, "critic_loss": 0.07738922356441617, "actor_loss": -15.893289823547006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.98833513259888, "step": 11000}
{"episode_reward": 14.572891081686908, "episode": 12.0, "batch_reward": 0.12910571019351483, "critic_loss": 0.1044913846515119, "actor_loss": -15.349404321707786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.816431045532227, "step": 12000}
{"episode_reward": 121.98579018077955, "episode": 13.0, "batch_reward": 0.13148759011924266, "critic_loss": 0.11370837382227182, "actor_loss": -15.98867840975523, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.05963945388794, "step": 13000}
{"episode_reward": 214.29579575162512, "episode": 14.0, "batch_reward": 0.1325836481601, "critic_loss": 0.13402889205142857, "actor_loss": -14.6917140789181, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.285852909088135, "step": 14000}
{"episode_reward": 66.40941703050756, "episode": 15.0, "batch_reward": 0.13016566319018602, "critic_loss": 0.1280266405083239, "actor_loss": -14.230636245816946, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.935271978378296, "step": 15000}
{"episode_reward": 120.10370663452471, "episode": 16.0, "batch_reward": 0.1298084198832512, "critic_loss": 0.15047649231553079, "actor_loss": -14.768172939985991, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.562673330307007, "step": 16000}
{"episode_reward": 138.4160004790352, "episode": 17.0, "batch_reward": 0.13109670957922936, "critic_loss": 0.14780809259787203, "actor_loss": -14.033160554170609, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.169495105743408, "step": 17000}
{"episode_reward": 133.36335858868824, "episode": 18.0, "batch_reward": 0.1297509994879365, "critic_loss": 0.16609138479828833, "actor_loss": -13.68269863152504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.536951780319214, "step": 18000}
{"episode_reward": 78.1469241434097, "episode": 19.0, "batch_reward": 0.1266807634755969, "critic_loss": 0.2033925618454814, "actor_loss": -13.528434135437012, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.63427758216858, "step": 19000}
{"episode_reward": 98.90057741400865, "episode": 20.0, "batch_reward": 0.1253038411140442, "critic_loss": 0.19517310923337935, "actor_loss": -13.10234851384163, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.806094646453857, "step": 20000}
{"episode_reward": 173.79315038707492, "episode": 21.0, "batch_reward": 0.12925270342081785, "critic_loss": 0.20488263902813197, "actor_loss": -14.579547544956208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.72348761558533, "step": 21000}
{"episode_reward": 229.5214418445304, "episode": 22.0, "batch_reward": 0.1346973076015711, "critic_loss": 0.21207277829945087, "actor_loss": -13.566710541248321, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.950331449508667, "step": 22000}
{"episode_reward": 249.19640639655867, "episode": 23.0, "batch_reward": 0.1405989849641919, "critic_loss": 0.23009999475628137, "actor_loss": -14.694610703468323, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.12573552131653, "step": 23000}
{"episode_reward": 168.9228869053115, "episode": 24.0, "batch_reward": 0.14116282933950425, "critic_loss": 0.21412659561634065, "actor_loss": -14.77810934638977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.82902765274048, "step": 24000}
{"episode_reward": 145.05066311521688, "episode": 25.0, "batch_reward": 0.1410674035102129, "critic_loss": 0.21767147982865573, "actor_loss": -14.307702506065368, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.200616359710693, "step": 25000}
{"episode_reward": 143.08522647975508, "episode": 26.0, "batch_reward": 0.14362614566087722, "critic_loss": 0.21239861347526312, "actor_loss": -14.614420845985412, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.424306392669678, "step": 26000}
{"episode_reward": 372.90927075252273, "episode": 27.0, "batch_reward": 0.15052315965294838, "critic_loss": 0.25268827509880065, "actor_loss": -15.286302097320556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.30168652534485, "step": 27000}
{"episode_reward": 237.88367418225684, "episode": 28.0, "batch_reward": 0.15576974821090697, "critic_loss": 0.27403247909247874, "actor_loss": -15.414023805618287, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.670960426330566, "step": 28000}
{"episode_reward": 371.98744716159865, "episode": 29.0, "batch_reward": 0.15891670495271681, "critic_loss": 0.32294258062541487, "actor_loss": -15.849695019721985, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.48666024208069, "step": 29000}
{"episode_reward": 88.51530241590615, "episode": 30.0, "batch_reward": 0.1602655872926116, "critic_loss": 0.3234230852872133, "actor_loss": -16.481964157104493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.192896127700806, "step": 30000}
{"episode_reward": 241.7273586930644, "episode": 31.0, "batch_reward": 0.159915816873312, "critic_loss": 0.2857836676388979, "actor_loss": -16.134873947143554, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.021466970443726, "step": 31000}
{"episode_reward": 106.14353208147637, "episode": 32.0, "batch_reward": 0.16036444422602653, "critic_loss": 0.32798332142829895, "actor_loss": -15.842150371551513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.988166093826294, "step": 32000}
{"episode_reward": 181.89056457555273, "episode": 33.0, "batch_reward": 0.16085583699494602, "critic_loss": 0.29425892075896265, "actor_loss": -16.086936571121218, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.925970792770386, "step": 33000}
{"episode_reward": 199.57831396764482, "episode": 34.0, "batch_reward": 0.16220468778163194, "critic_loss": 0.29675967802107334, "actor_loss": -16.34095817375183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.23155665397644, "step": 34000}
{"episode_reward": 171.23666636597963, "episode": 35.0, "batch_reward": 0.162866433493793, "critic_loss": 0.27972928124666213, "actor_loss": -16.12896885681152, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.954479694366455, "step": 35000}
{"episode_reward": 255.43576898218421, "episode": 36.0, "batch_reward": 0.1640672252550721, "critic_loss": 0.2794761605262756, "actor_loss": -16.11047676849365, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.750128507614136, "step": 36000}
{"episode_reward": 136.39770885207952, "episode": 37.0, "batch_reward": 0.16103714445978404, "critic_loss": 0.2986807374805212, "actor_loss": -16.499222843170166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.549842596054077, "step": 37000}
{"episode_reward": 46.07231970177422, "episode": 38.0, "batch_reward": 0.16205046489834785, "critic_loss": 0.2964456685781479, "actor_loss": -16.782857055664063, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.942137718200684, "step": 38000}
{"episode_reward": 337.2449903423202, "episode": 39.0, "batch_reward": 0.16503086707741021, "critic_loss": 0.3143290388137102, "actor_loss": -16.999990043640135, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.59878897666931, "step": 39000}
{"episode_reward": 298.23853928405345, "episode": 40.0, "batch_reward": 0.16804839162528515, "critic_loss": 0.33052826112508776, "actor_loss": -17.35094556236267, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.144335508346558, "step": 40000}
{"episode_reward": 163.47601602610467, "episode": 41.0, "batch_reward": 0.16619650158286095, "critic_loss": 0.32538826493918893, "actor_loss": -17.65446848487854, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.87967276573181, "step": 41000}
{"episode_reward": 104.65778966546053, "episode": 42.0, "batch_reward": 0.16845040061324834, "critic_loss": 0.32298004043102263, "actor_loss": -17.705911108016966, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.899893522262573, "step": 42000}
{"episode_reward": 288.719778473577, "episode": 43.0, "batch_reward": 0.1687191858291626, "critic_loss": 0.32770242685079576, "actor_loss": -17.94265843582153, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.40780019760132, "step": 43000}
{"episode_reward": 149.34605029556343, "episode": 44.0, "batch_reward": 0.1674517443627119, "critic_loss": 0.35252899760752915, "actor_loss": -17.439585977554323, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.867018699645996, "step": 44000}
{"episode_reward": 72.98536965020403, "episode": 45.0, "batch_reward": 0.16723557870090008, "critic_loss": 0.28856640187650917, "actor_loss": -17.781872838974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.03817582130432, "step": 45000}
{"episode_reward": 189.30214934588253, "episode": 46.0, "batch_reward": 0.16523387756943703, "critic_loss": 0.3067593012228608, "actor_loss": -18.089968746185303, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.951942920684814, "step": 46000}
{"episode_reward": 47.233790883169405, "episode": 47.0, "batch_reward": 0.16517787586152555, "critic_loss": 0.30235777896642685, "actor_loss": -17.953680835723876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.75686502456665, "step": 47000}
{"episode_reward": 163.28059294318288, "episode": 48.0, "batch_reward": 0.16646496434509755, "critic_loss": 0.30599723921716215, "actor_loss": -18.218100034713746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.097031354904175, "step": 48000}
{"episode_reward": 350.6686622063036, "episode": 49.0, "batch_reward": 0.16865197803080081, "critic_loss": 0.31100543958693744, "actor_loss": -18.388659446716307, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.25004005432129, "step": 49000}
{"episode_reward": 120.47906343188774, "episode": 50.0, "batch_reward": 0.16937307461351156, "critic_loss": 0.31094375990331174, "actor_loss": -18.62767081642151, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.60078191757202, "step": 50000}
{"episode_reward": 372.01731040136985, "episode": 51.0, "batch_reward": 0.17159776724874973, "critic_loss": 0.30731685655564067, "actor_loss": -18.95849120903015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.3518168926239, "step": 51000}
{"episode_reward": 230.43761628044427, "episode": 52.0, "batch_reward": 0.17216014383733272, "critic_loss": 0.2804268262386322, "actor_loss": -19.196657215118407, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.312504291534424, "step": 52000}
{"episode_reward": 76.81097431559773, "episode": 53.0, "batch_reward": 0.1726380731910467, "critic_loss": 0.2762933585345745, "actor_loss": -19.21026117706299, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.801662921905518, "step": 53000}
{"episode_reward": 270.8423508009363, "episode": 54.0, "batch_reward": 0.1729724623262882, "critic_loss": 0.29994921396672725, "actor_loss": -19.395472394943237, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.26166868209839, "step": 54000}
{"episode_reward": 210.64101712558173, "episode": 55.0, "batch_reward": 0.1755062836110592, "critic_loss": 0.29124783231317997, "actor_loss": -19.632025577545168, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.621601343154907, "step": 55000}
{"episode_reward": 473.7027418331546, "episode": 56.0, "batch_reward": 0.1790958410948515, "critic_loss": 0.2858123523145914, "actor_loss": -19.940961700439452, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.7544207572937, "step": 56000}
{"episode_reward": 142.33233969782083, "episode": 57.0, "batch_reward": 0.1775579192638397, "critic_loss": 0.25781034024804833, "actor_loss": -19.88396277618408, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.688342094421387, "step": 57000}
{"episode_reward": 116.72594131153046, "episode": 58.0, "batch_reward": 0.17699844093620778, "critic_loss": 0.2716209810003638, "actor_loss": -19.956271003723145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.60964322090149, "step": 58000}
{"episode_reward": 205.78826037308716, "episode": 59.0, "batch_reward": 0.17683139291405678, "critic_loss": 0.2740903788357973, "actor_loss": -20.03621781539917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.52542781829834, "step": 59000}
{"episode_reward": 158.3555428183931, "episode": 60.0, "batch_reward": 0.17766129192709923, "critic_loss": 0.2714331372231245, "actor_loss": -20.20844407272339, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.036453008651733, "step": 60000}
{"episode_reward": 200.34295842291928, "episode": 61.0, "batch_reward": 0.17873353698849678, "critic_loss": 0.2793753641024232, "actor_loss": -20.34083226776123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.13958811759949, "step": 61000}
{"episode_reward": 305.07568692125966, "episode": 62.0, "batch_reward": 0.17949606142938138, "critic_loss": 0.2785885292291641, "actor_loss": -20.445501735687255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.7498779296875, "step": 62000}
{"episode_reward": 83.8906882962321, "episode": 63.0, "batch_reward": 0.17739538353681564, "critic_loss": 0.26079201786220074, "actor_loss": -20.298296001434327, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.663849592208862, "step": 63000}
{"episode_reward": 115.1740558857469, "episode": 64.0, "batch_reward": 0.17895733727514743, "critic_loss": 0.27794841733574865, "actor_loss": -20.42673014831543, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.797284841537476, "step": 64000}
{"episode_reward": 422.5468360987279, "episode": 65.0, "batch_reward": 0.18194815728068353, "critic_loss": 0.27114688198268416, "actor_loss": -20.780030586242678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.069026947021484, "step": 65000}
{"episode_reward": 337.8778679885215, "episode": 66.0, "batch_reward": 0.18335225056111812, "critic_loss": 0.2747155630290508, "actor_loss": -20.94035972213745, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.06881093978882, "step": 66000}
{"episode_reward": 111.03356718477559, "episode": 67.0, "batch_reward": 0.18381403793394566, "critic_loss": 0.28634268514811995, "actor_loss": -20.9465961227417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.014103412628174, "step": 67000}
{"episode_reward": 291.27900546744655, "episode": 68.0, "batch_reward": 0.18473905916512012, "critic_loss": 0.2806077693402767, "actor_loss": -21.089489654541016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.44383978843689, "step": 68000}
{"episode_reward": 385.1351599660108, "episode": 69.0, "batch_reward": 0.18592167004942894, "critic_loss": 0.2877145950347185, "actor_loss": -21.175453498840334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.80120301246643, "step": 69000}
{"episode_reward": 92.27698977291328, "episode": 70.0, "batch_reward": 0.1847752984315157, "critic_loss": 0.3183272484093905, "actor_loss": -21.05279130935669, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.818095684051514, "step": 70000}
{"episode_reward": 71.88823956301155, "episode": 71.0, "batch_reward": 0.18282579897344112, "critic_loss": 0.29953230772912504, "actor_loss": -20.88830905532837, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.17329502105713, "step": 71000}
{"episode_reward": 63.16878828627782, "episode": 72.0, "batch_reward": 0.18344480879604816, "critic_loss": 0.3024283715635538, "actor_loss": -20.946661365509033, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.629259824752808, "step": 72000}
{"episode_reward": 217.3172197050416, "episode": 73.0, "batch_reward": 0.18365114541351796, "critic_loss": 0.30523677667975424, "actor_loss": -20.98439884185791, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.24274206161499, "step": 73000}
{"episode_reward": 369.09730249037534, "episode": 74.0, "batch_reward": 0.18622729900479318, "critic_loss": 0.3077857987135649, "actor_loss": -21.1795938873291, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.795688152313232, "step": 74000}
{"episode_reward": 330.45322158970635, "episode": 75.0, "batch_reward": 0.18726829899847508, "critic_loss": 0.30587022441625594, "actor_loss": -21.220467418670655, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.067960023880005, "step": 75000}
{"episode_reward": 239.939845271428, "episode": 76.0, "batch_reward": 0.18871151730418206, "critic_loss": 0.3229727977067232, "actor_loss": -21.26150302505493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.066250562667847, "step": 76000}
{"episode_reward": 279.4640370052815, "episode": 77.0, "batch_reward": 0.19030078452825547, "critic_loss": 0.3195333867967129, "actor_loss": -21.407805770874024, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.073570013046265, "step": 77000}
{"episode_reward": 286.4583516906356, "episode": 78.0, "batch_reward": 0.1904858272820711, "critic_loss": 0.30883115163445474, "actor_loss": -21.269162677764893, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.09978699684143, "step": 78000}
{"episode_reward": 177.53718327465063, "episode": 79.0, "batch_reward": 0.1914374488890171, "critic_loss": 0.35049738629162314, "actor_loss": -21.36341262817383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.183866262435913, "step": 79000}
{"episode_reward": 289.61201167393943, "episode": 80.0, "batch_reward": 0.19034531879425048, "critic_loss": 0.3133289402723312, "actor_loss": -21.375076709747315, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.962122678756714, "step": 80000}
{"episode_reward": 45.514261246657746, "episode": 81.0, "batch_reward": 0.19034317296743392, "critic_loss": 0.3301844129785895, "actor_loss": -21.38614992904663, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.81131386756897, "step": 81000}
{"episode_reward": 171.99973087604346, "episode": 82.0, "batch_reward": 0.190519818007946, "critic_loss": 0.34590600451827047, "actor_loss": -21.243249660491944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.171154737472534, "step": 82000}
{"episode_reward": 384.8384860870553, "episode": 83.0, "batch_reward": 0.1913476200401783, "critic_loss": 0.32354206098616123, "actor_loss": -21.25315187072754, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.62027931213379, "step": 83000}
{"episode_reward": 140.60482553300838, "episode": 84.0, "batch_reward": 0.19139323711395265, "critic_loss": 0.3645654515773058, "actor_loss": -21.232004470825196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.749021291732788, "step": 84000}
{"episode_reward": 147.8935483330588, "episode": 85.0, "batch_reward": 0.19055326990783214, "critic_loss": 0.3309366743862629, "actor_loss": -21.094390102386473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.27021837234497, "step": 85000}
{"episode_reward": 191.88989395012226, "episode": 86.0, "batch_reward": 0.1914186148196459, "critic_loss": 0.32260282487422226, "actor_loss": -21.143874794006347, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.0928053855896, "step": 86000}
{"episode_reward": 348.6831878262641, "episode": 87.0, "batch_reward": 0.1939415515512228, "critic_loss": 0.33974133503437043, "actor_loss": -21.185777042388917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.720253944396973, "step": 87000}
{"episode_reward": 349.4955197613762, "episode": 88.0, "batch_reward": 0.19428653727471829, "critic_loss": 0.3534709456264973, "actor_loss": -21.171621334075926, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.265525817871094, "step": 88000}
{"episode_reward": 270.6957874977173, "episode": 89.0, "batch_reward": 0.196580995246768, "critic_loss": 0.3381394197717309, "actor_loss": -21.36015071487427, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.266724824905396, "step": 89000}
{"episode_reward": 456.07601499802433, "episode": 90.0, "batch_reward": 0.1998420312702656, "critic_loss": 0.3474647302851081, "actor_loss": -21.53132879638672, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.80050539970398, "step": 90000}
{"episode_reward": 255.92725033088874, "episode": 91.0, "batch_reward": 0.20063901501893996, "critic_loss": 0.35360875068604947, "actor_loss": -21.638529502868654, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.06505012512207, "step": 91000}
{"episode_reward": 275.383480214751, "episode": 92.0, "batch_reward": 0.20007393580675126, "critic_loss": 0.34673770855367186, "actor_loss": -21.505837532043458, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.88477373123169, "step": 92000}
{"episode_reward": 183.9879122742179, "episode": 93.0, "batch_reward": 0.1996418671756983, "critic_loss": 0.3444510074853897, "actor_loss": -21.570247440338136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.64074730873108, "step": 93000}
{"episode_reward": 332.7461659074396, "episode": 94.0, "batch_reward": 0.20106968696415425, "critic_loss": 0.3605941303372383, "actor_loss": -21.619174869537353, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.854201793670654, "step": 94000}
{"episode_reward": 207.87334866270288, "episode": 95.0, "batch_reward": 0.2018201815187931, "critic_loss": 0.38517233708500864, "actor_loss": -21.650775714874268, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.15896511077881, "step": 95000}
{"episode_reward": 453.0298664515731, "episode": 96.0, "batch_reward": 0.205556144669652, "critic_loss": 0.3503480086773634, "actor_loss": -22.027882316589356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.70665216445923, "step": 96000}
{"episode_reward": 415.19057069740006, "episode": 97.0, "batch_reward": 0.20633557675778866, "critic_loss": 0.3633699540495873, "actor_loss": -22.123626262664796, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.1848566532135, "step": 97000}
{"episode_reward": 311.94590757783817, "episode": 98.0, "batch_reward": 0.20583893236517906, "critic_loss": 0.38637337312102316, "actor_loss": -22.033922142028807, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.49264121055603, "step": 98000}
{"episode_reward": 17.324496227426422, "episode": 99.0, "batch_reward": 0.2065536604821682, "critic_loss": 0.3550554746836424, "actor_loss": -22.158971214294432, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.76235818862915, "step": 99000}
{"episode_reward": 390.07857408163864, "episode": 100.0, "batch_reward": 0.20753713051974773, "critic_loss": 0.36676800683140753, "actor_loss": -22.149478324890136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.175033807754517, "step": 100000}
{"episode_reward": 471.58919084796713, "episode": 101.0, "batch_reward": 0.21054703460633756, "critic_loss": 0.34595217821002006, "actor_loss": -22.479755069732665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.912757873535156, "step": 101000}
{"episode_reward": 447.3272252223533, "episode": 102.0, "batch_reward": 0.21269029262661934, "critic_loss": 0.37117399218678476, "actor_loss": -22.612817543029784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.15380620956421, "step": 102000}
{"episode_reward": 402.1323728122411, "episode": 103.0, "batch_reward": 0.21415945208072662, "critic_loss": 0.3887050193697214, "actor_loss": -22.722095481872557, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.04244303703308, "step": 103000}
{"episode_reward": 176.23346102529894, "episode": 104.0, "batch_reward": 0.21461696913838388, "critic_loss": 0.3704290538877249, "actor_loss": -22.6532797164917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.073225259780884, "step": 104000}
{"episode_reward": 443.8074329726268, "episode": 105.0, "batch_reward": 0.21585408513247967, "critic_loss": 0.3728015656918287, "actor_loss": -22.745921909332274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.821118354797363, "step": 105000}
{"episode_reward": 147.38183296093823, "episode": 106.0, "batch_reward": 0.21584723502397538, "critic_loss": 0.3795837132334709, "actor_loss": -22.820040592193603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.831432342529297, "step": 106000}
{"episode_reward": 290.0134152519763, "episode": 107.0, "batch_reward": 0.2164241087883711, "critic_loss": 0.4156909186989069, "actor_loss": -22.72453701400757, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.088751792907715, "step": 107000}
{"episode_reward": 355.90101181226663, "episode": 108.0, "batch_reward": 0.21770509196817875, "critic_loss": 0.35449112263321875, "actor_loss": -22.790620677948, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.84279227256775, "step": 108000}
{"episode_reward": 475.599515953349, "episode": 109.0, "batch_reward": 0.22036808548867703, "critic_loss": 0.3986551964133978, "actor_loss": -22.969379344940187, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.79458713531494, "step": 109000}
{"episode_reward": 380.5162894671438, "episode": 110.0, "batch_reward": 0.22132073034346103, "critic_loss": 0.397232781752944, "actor_loss": -23.000875312805174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.79831051826477, "step": 110000}
{"episode_reward": 477.2917115954196, "episode": 111.0, "batch_reward": 0.2233812665194273, "critic_loss": 0.4044898481965065, "actor_loss": -23.224088886260986, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.27950406074524, "step": 111000}
{"episode_reward": 419.8162720199372, "episode": 112.0, "batch_reward": 0.22638088470697404, "critic_loss": 0.4076154953688383, "actor_loss": -23.440862472534178, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.760754346847534, "step": 112000}
{"episode_reward": 450.735443383866, "episode": 113.0, "batch_reward": 0.22824152947962284, "critic_loss": 0.39255807927250863, "actor_loss": -23.59920334625244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.21376657485962, "step": 113000}
{"episode_reward": 483.28846293422777, "episode": 114.0, "batch_reward": 0.22943996927142143, "critic_loss": 0.40193912369012835, "actor_loss": -23.676988079071045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.44291114807129, "step": 114000}
{"episode_reward": 196.3279155823488, "episode": 115.0, "batch_reward": 0.22827716425061226, "critic_loss": 0.3753720695972443, "actor_loss": -23.586930564880372, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.68197464942932, "step": 115000}
{"episode_reward": 164.18115545352785, "episode": 116.0, "batch_reward": 0.2289133967012167, "critic_loss": 0.408506179690361, "actor_loss": -23.580702613830567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.912866353988647, "step": 116000}
{"episode_reward": 150.90151670302492, "episode": 117.0, "batch_reward": 0.2288488954603672, "critic_loss": 0.40632160678505896, "actor_loss": -23.57547512435913, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.001929759979248, "step": 117000}
{"episode_reward": 492.53055689805836, "episode": 118.0, "batch_reward": 0.23025477139651776, "critic_loss": 0.37349760277569294, "actor_loss": -23.692428401947023, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.619211196899414, "step": 118000}
{"episode_reward": 508.24816834760355, "episode": 119.0, "batch_reward": 0.2319935626834631, "critic_loss": 0.428561795681715, "actor_loss": -23.808528770446777, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.551259756088257, "step": 119000}
{"episode_reward": 161.1879946484299, "episode": 120.0, "batch_reward": 0.23207376319169998, "critic_loss": 0.38977016021311284, "actor_loss": -23.823148567199706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.099992513656616, "step": 120000}
{"episode_reward": 417.92255232094607, "episode": 121.0, "batch_reward": 0.23326099483668805, "critic_loss": 0.3907944815605879, "actor_loss": -23.814797115325927, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.703104734420776, "step": 121000}
{"episode_reward": 490.4000571119197, "episode": 122.0, "batch_reward": 0.23492258447408676, "critic_loss": 0.4195433662086725, "actor_loss": -23.96687972640991, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.68073844909668, "step": 122000}
{"episode_reward": 138.68534228601135, "episode": 123.0, "batch_reward": 0.2355865209698677, "critic_loss": 0.4247488553971052, "actor_loss": -24.072813358306885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.610347270965576, "step": 123000}
{"episode_reward": 566.1279557487424, "episode": 124.0, "batch_reward": 0.23810502845048903, "critic_loss": 0.4071168890148401, "actor_loss": -24.2493797454834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.240506410598755, "step": 124000}
{"episode_reward": 190.06893806483353, "episode": 125.0, "batch_reward": 0.2373708559423685, "critic_loss": 0.4326735464632511, "actor_loss": -24.085763790130617, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.558480978012085, "step": 125000}
{"episode_reward": 544.1855170650762, "episode": 126.0, "batch_reward": 0.23980668902397156, "critic_loss": 0.3951148125976324, "actor_loss": -24.31319297027588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.85734248161316, "step": 126000}
{"episode_reward": 436.2656291266445, "episode": 127.0, "batch_reward": 0.24100758208334447, "critic_loss": 0.4180645519942045, "actor_loss": -24.46081992340088, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.280555248260498, "step": 127000}
{"episode_reward": 161.8394581328836, "episode": 128.0, "batch_reward": 0.24111456556618213, "critic_loss": 0.41998376630246637, "actor_loss": -24.471051704406737, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.98271155357361, "step": 128000}
{"episode_reward": 550.5743118511904, "episode": 129.0, "batch_reward": 0.2441892694234848, "critic_loss": 0.43694522182643414, "actor_loss": -24.66296315383911, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.49395513534546, "step": 129000}
{"episode_reward": 569.0994271684963, "episode": 130.0, "batch_reward": 0.24544307786226272, "critic_loss": 0.403300028860569, "actor_loss": -24.6495975151062, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.717977046966553, "step": 130000}
{"episode_reward": 283.5749790192682, "episode": 131.0, "batch_reward": 0.24696149019896985, "critic_loss": 0.4055256132185459, "actor_loss": -24.863687126159668, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.417494773864746, "step": 131000}
{"episode_reward": 558.8952656334982, "episode": 132.0, "batch_reward": 0.24920469924807548, "critic_loss": 0.4106261777728796, "actor_loss": -25.05950707244873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.82912039756775, "step": 132000}
{"episode_reward": 619.0903962279235, "episode": 133.0, "batch_reward": 0.25106712967157363, "critic_loss": 0.4187843700349331, "actor_loss": -25.034037364959715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.987695455551147, "step": 133000}
{"episode_reward": 594.8005963883979, "episode": 134.0, "batch_reward": 0.253633321121335, "critic_loss": 0.3976497327834368, "actor_loss": -25.36313968658447, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.040737867355347, "step": 134000}
{"episode_reward": 571.3551997941399, "episode": 135.0, "batch_reward": 0.25511514930427076, "critic_loss": 0.4329820248037577, "actor_loss": -25.31086961746216, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.820677995681763, "step": 135000}
{"episode_reward": 274.05827988886546, "episode": 136.0, "batch_reward": 0.2576167620420456, "critic_loss": 0.41352072058618067, "actor_loss": -25.522033687591552, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.491233110427856, "step": 136000}
{"episode_reward": 464.89729540321343, "episode": 137.0, "batch_reward": 0.2591646364480257, "critic_loss": 0.41177101629972457, "actor_loss": -25.655633399963378, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.596619129180908, "step": 137000}
{"episode_reward": 540.155258119476, "episode": 138.0, "batch_reward": 0.2596468298137188, "critic_loss": 0.42190414218604566, "actor_loss": -25.60915627670288, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.003997087478638, "step": 138000}
{"episode_reward": 579.9460835430685, "episode": 139.0, "batch_reward": 0.26223228418827055, "critic_loss": 0.42449491168558595, "actor_loss": -25.835686603546144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.138800621032715, "step": 139000}
{"episode_reward": 157.26276599044664, "episode": 140.0, "batch_reward": 0.2599813658297062, "critic_loss": 0.440597504556179, "actor_loss": -25.673812084197998, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.96379590034485, "step": 140000}
{"episode_reward": 163.83049286805775, "episode": 141.0, "batch_reward": 0.2617770951837301, "critic_loss": 0.4148543935120106, "actor_loss": -25.83154433822632, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.267683029174805, "step": 141000}
{"episode_reward": 411.2568961065537, "episode": 142.0, "batch_reward": 0.2620107759684324, "critic_loss": 0.42702414529025556, "actor_loss": -25.866273960113524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.18050765991211, "step": 142000}
{"episode_reward": 538.2230198482915, "episode": 143.0, "batch_reward": 0.26433075647056103, "critic_loss": 0.44863820405304433, "actor_loss": -26.11666176223755, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.527304649353027, "step": 143000}
{"episode_reward": 456.277934419421, "episode": 144.0, "batch_reward": 0.2643050624579191, "critic_loss": 0.4600161845088005, "actor_loss": -25.9424803314209, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.24772071838379, "step": 144000}
{"episode_reward": 146.8215950168931, "episode": 145.0, "batch_reward": 0.26399922485649585, "critic_loss": 0.42426552504301074, "actor_loss": -26.04008448791504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.84801483154297, "step": 145000}
{"episode_reward": 556.7871418095057, "episode": 146.0, "batch_reward": 0.2658570220321417, "critic_loss": 0.45873933705687525, "actor_loss": -26.164055725097658, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.186787366867065, "step": 146000}
{"episode_reward": 595.6651679841028, "episode": 147.0, "batch_reward": 0.2679311496168375, "critic_loss": 0.4228498016744852, "actor_loss": -26.55414698791504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.84734845161438, "step": 147000}
{"episode_reward": 449.6012151155282, "episode": 148.0, "batch_reward": 0.26971919916570186, "critic_loss": 0.43796758227050303, "actor_loss": -26.507283100128173, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.31117296218872, "step": 148000}
{"episode_reward": 441.15630990438933, "episode": 149.0, "batch_reward": 0.2723593933135271, "critic_loss": 0.3966268375664949, "actor_loss": -26.824752826690673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.234891176223755, "step": 149000}
{"episode_reward": 547.9576777497357, "episode": 150.0, "batch_reward": 0.2731592465490103, "critic_loss": 0.42566775995492934, "actor_loss": -26.81110636520386, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
