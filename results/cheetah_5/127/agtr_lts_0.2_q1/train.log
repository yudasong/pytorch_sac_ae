{"episode_reward": 0.0, "episode": 1.0, "duration": 17.72616171836853, "step": 1000}
{"episode_reward": 4.859792814687425, "episode": 2.0, "duration": 1.4902753829956055, "step": 2000}
{"episode_reward": 550.1572824113056, "episode": 3.0, "batch_reward": 0.2626843492700164, "critic_loss": 0.6845301782619798, "actor_loss": -41.9006536834094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 66.8458845615387, "step": 3000}
{"episode_reward": 70.0384163229116, "episode": 4.0, "batch_reward": 0.1818064310774207, "critic_loss": 0.8418679875135422, "actor_loss": -49.405969520568846, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.991962671279907, "step": 4000}
{"episode_reward": 5.065688164619561, "episode": 5.0, "batch_reward": 0.1411858699284494, "critic_loss": 1.2631569845676422, "actor_loss": -57.05697929763794, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.86877155303955, "step": 5000}
{"episode_reward": 2.4139537343303963, "episode": 6.0, "batch_reward": 0.11461833195015789, "critic_loss": 1.0483364588618278, "actor_loss": -60.95630321121216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.93060827255249, "step": 6000}
{"episode_reward": 2.2862722922019065, "episode": 7.0, "batch_reward": 0.09786728374287486, "critic_loss": 1.2022249814867974, "actor_loss": -62.708498039245605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34314513206482, "step": 7000}
{"episode_reward": 1.0642367095215726, "episode": 8.0, "batch_reward": 0.085089977260679, "critic_loss": 0.9891461309790611, "actor_loss": -61.87137732696533, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.309398412704468, "step": 8000}
{"episode_reward": 0.634449608747265, "episode": 9.0, "batch_reward": 0.07481100420095027, "critic_loss": 0.9079231968224049, "actor_loss": -59.53581353378296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.176477909088135, "step": 9000}
{"episode_reward": 1.3993864855904377, "episode": 10.0, "batch_reward": 0.06758513976074755, "critic_loss": 0.7368001049160957, "actor_loss": -56.38498876953125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.301316738128662, "step": 10000}
{"episode_reward": 4.780229627829183, "episode": 11.0, "batch_reward": 0.0623235773332417, "critic_loss": 0.6649124327003956, "actor_loss": -54.53684635162354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.41495370864868, "step": 11000}
{"episode_reward": 9.482874669359004, "episode": 12.0, "batch_reward": 0.05981282952800393, "critic_loss": 0.7524982785582542, "actor_loss": -51.64866675186157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.146075963974, "step": 12000}
{"episode_reward": 74.0688319721765, "episode": 13.0, "batch_reward": 0.05820237756147981, "critic_loss": 0.6216105714440345, "actor_loss": -50.91021202087402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.79560136795044, "step": 13000}
{"episode_reward": 6.6552037687873105, "episode": 14.0, "batch_reward": 0.054734833128750326, "critic_loss": 0.7158510681688786, "actor_loss": -48.94071206665039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.656102418899536, "step": 14000}
{"episode_reward": 6.846007777529674, "episode": 15.0, "batch_reward": 0.05102648447081447, "critic_loss": 0.62938280954957, "actor_loss": -48.11073949813843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.380172967910767, "step": 15000}
{"episode_reward": 12.619400853512909, "episode": 16.0, "batch_reward": 0.04862170553393662, "critic_loss": 0.5552629954218864, "actor_loss": -47.584495006561276, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.179952383041382, "step": 16000}
{"episode_reward": 7.80366781347996, "episode": 17.0, "batch_reward": 0.04614720197301358, "critic_loss": 0.4529985440671444, "actor_loss": -45.94337104415894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.201316833496094, "step": 17000}
{"episode_reward": 4.234914992805987, "episode": 18.0, "batch_reward": 0.044598758567124606, "critic_loss": 0.3618508242070675, "actor_loss": -45.422727527618406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.052432537078857, "step": 18000}
{"episode_reward": 3.176665127095862, "episode": 19.0, "batch_reward": 0.04165198240429163, "critic_loss": 0.30307810799777507, "actor_loss": -44.30090420150757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.047850370407104, "step": 19000}
{"episode_reward": 1.9091098190627007, "episode": 20.0, "batch_reward": 0.039605786634609105, "critic_loss": 0.24597145339101553, "actor_loss": -43.49251583099365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.834542274475098, "step": 20000}
{"episode_reward": 0.4846948633658167, "episode": 21.0, "batch_reward": 0.03684136965125799, "critic_loss": 0.2183326521292329, "actor_loss": -42.17311670303345, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.93254780769348, "step": 21000}
{"episode_reward": 0.22460252966433603, "episode": 22.0, "batch_reward": 0.03602129001170397, "critic_loss": 0.19752437454462052, "actor_loss": -39.836915798187256, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.677464962005615, "step": 22000}
{"episode_reward": 9.886705796378957, "episode": 23.0, "batch_reward": 0.03462701147608459, "critic_loss": 0.1733108283355832, "actor_loss": -39.146162448883054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.68336772918701, "step": 23000}
{"episode_reward": 3.325650135975174, "episode": 24.0, "batch_reward": 0.03326205719448626, "critic_loss": 0.15880320897325872, "actor_loss": -37.302184818267826, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.957260370254517, "step": 24000}
{"episode_reward": 2.744304992719814, "episode": 25.0, "batch_reward": 0.03252463415404782, "critic_loss": 0.15432804908975958, "actor_loss": -36.28930430221558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.471657752990723, "step": 25000}
{"episode_reward": 4.294362040990962, "episode": 26.0, "batch_reward": 0.031156350925099104, "critic_loss": 0.1988597561828792, "actor_loss": -35.10625443267822, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.57357382774353, "step": 26000}
{"episode_reward": 4.772790209629633, "episode": 27.0, "batch_reward": 0.030798037657979876, "critic_loss": 0.20032438326999544, "actor_loss": -33.757238792419436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.234689474105835, "step": 27000}
{"episode_reward": 11.163608353332881, "episode": 28.0, "batch_reward": 0.03133359082462266, "critic_loss": 0.24325035816431045, "actor_loss": -32.49483324813843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.216068029403687, "step": 28000}
{"episode_reward": 72.70348927019519, "episode": 29.0, "batch_reward": 0.03329814473818988, "critic_loss": 0.31901755468547344, "actor_loss": -31.645819625854493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.22802448272705, "step": 29000}
{"episode_reward": 157.93321096179113, "episode": 30.0, "batch_reward": 0.037768098608590664, "critic_loss": 0.3033024780601263, "actor_loss": -31.322847644805908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.127263069152832, "step": 30000}
{"episode_reward": 97.63046269250839, "episode": 31.0, "batch_reward": 0.03752078043948859, "critic_loss": 0.33508639539778234, "actor_loss": -30.375916049957276, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.53171682357788, "step": 31000}
{"episode_reward": 10.529841653482327, "episode": 32.0, "batch_reward": 0.03974698509275913, "critic_loss": 0.41934615817666054, "actor_loss": -30.120617267608644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.28056573867798, "step": 32000}
{"episode_reward": 127.82254939819042, "episode": 33.0, "batch_reward": 0.03990611765906215, "critic_loss": 0.5150969915986061, "actor_loss": -30.430504306793214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.98717474937439, "step": 33000}
{"episode_reward": 37.254258779357755, "episode": 34.0, "batch_reward": 0.039622746168635786, "critic_loss": 0.5368136044740677, "actor_loss": -30.721299057006835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.02611804008484, "step": 34000}
{"episode_reward": 14.900438246467928, "episode": 35.0, "batch_reward": 0.038896969448775055, "critic_loss": 0.6085557793825864, "actor_loss": -29.55029987335205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.3026340007782, "step": 35000}
{"episode_reward": 91.37862624076526, "episode": 36.0, "batch_reward": 0.04118310634419322, "critic_loss": 0.5207362183481454, "actor_loss": -29.479312007904053, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.373955011367798, "step": 36000}
{"episode_reward": 91.33698041819616, "episode": 37.0, "batch_reward": 0.042078499795868994, "critic_loss": 0.4269795417636633, "actor_loss": -28.50605168914795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.320061445236206, "step": 37000}
{"episode_reward": 25.62317390748063, "episode": 38.0, "batch_reward": 0.04082838908210397, "critic_loss": 0.37710104389488697, "actor_loss": -27.13664064025879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.497323989868164, "step": 38000}
{"episode_reward": 12.314522676113876, "episode": 39.0, "batch_reward": 0.040798968628048896, "critic_loss": 0.32126143787056205, "actor_loss": -25.827385746002196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.117751121520996, "step": 39000}
{"episode_reward": 41.48052999913639, "episode": 40.0, "batch_reward": 0.04314344722405076, "critic_loss": 0.372269682019949, "actor_loss": -25.076788547515868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.582304000854492, "step": 40000}
{"episode_reward": 238.880393703146, "episode": 41.0, "batch_reward": 0.048060695121064784, "critic_loss": 0.33155933560431006, "actor_loss": -24.327184711456297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.82853841781616, "step": 41000}
{"episode_reward": 214.48985062454432, "episode": 42.0, "batch_reward": 0.05132356231845915, "critic_loss": 0.28573335557430984, "actor_loss": -23.428414894104005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.5312762260437, "step": 42000}
{"episode_reward": 244.2477156216198, "episode": 43.0, "batch_reward": 0.05548979979380965, "critic_loss": 0.29865724907070396, "actor_loss": -22.658132522583006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.702529430389404, "step": 43000}
{"episode_reward": 123.45645756304785, "episode": 44.0, "batch_reward": 0.056422772258520125, "critic_loss": 0.29336263743788005, "actor_loss": -21.801229858398436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88955569267273, "step": 44000}
{"episode_reward": 119.78108621270977, "episode": 45.0, "batch_reward": 0.060466258354485033, "critic_loss": 0.2988852648511529, "actor_loss": -21.263527591705323, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.364640474319458, "step": 45000}
{"episode_reward": 372.5217526338447, "episode": 46.0, "batch_reward": 0.06620295031741262, "critic_loss": 0.3135509984195232, "actor_loss": -20.822100074768066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.600764274597168, "step": 46000}
{"episode_reward": 234.14842961876974, "episode": 47.0, "batch_reward": 0.07144260841608048, "critic_loss": 0.29231678530573846, "actor_loss": -20.457174697875978, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0250883102417, "step": 47000}
{"episode_reward": 386.3241152138464, "episode": 48.0, "batch_reward": 0.07741922356188297, "critic_loss": 0.28830207605659963, "actor_loss": -20.277928279876708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.972753047943115, "step": 48000}
{"episode_reward": 363.0998303895993, "episode": 49.0, "batch_reward": 0.08021297592297197, "critic_loss": 0.27766885809600356, "actor_loss": -20.393631786346436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.76374912261963, "step": 49000}
{"episode_reward": 8.589023631977122, "episode": 50.0, "batch_reward": 0.08086539709195495, "critic_loss": 0.24985461162775754, "actor_loss": -20.378853382110595, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.500855922698975, "step": 50000}
{"episode_reward": 248.13532078894204, "episode": 51.0, "batch_reward": 0.08499132343009114, "critic_loss": 0.24308581982553004, "actor_loss": -20.38913208770752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.36145567893982, "step": 51000}
{"episode_reward": 379.4470374432364, "episode": 52.0, "batch_reward": 0.09168935314193367, "critic_loss": 0.2389830740839243, "actor_loss": -20.341387657165527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.957630157470703, "step": 52000}
{"episode_reward": 336.0375714994011, "episode": 53.0, "batch_reward": 0.0962499778792262, "critic_loss": 0.23931487520039083, "actor_loss": -20.3407745513916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.55552840232849, "step": 53000}
{"episode_reward": 376.1963395444755, "episode": 54.0, "batch_reward": 0.09917538614571095, "critic_loss": 0.2577479224279523, "actor_loss": -19.994561950683593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.124849796295166, "step": 54000}
{"episode_reward": 109.20103301996535, "episode": 55.0, "batch_reward": 0.10050305955857039, "critic_loss": 0.27083165415376426, "actor_loss": -19.754617904663085, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.637982845306396, "step": 55000}
{"episode_reward": 197.4848610092881, "episode": 56.0, "batch_reward": 0.10237070412188769, "critic_loss": 0.2795483120530844, "actor_loss": -19.56744599533081, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.049483060836792, "step": 56000}
{"episode_reward": 321.1135721224789, "episode": 57.0, "batch_reward": 0.1050106679275632, "critic_loss": 0.27753195896744726, "actor_loss": -19.350430461883544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.718682765960693, "step": 57000}
{"episode_reward": 80.933768692144, "episode": 58.0, "batch_reward": 0.10631416045874358, "critic_loss": 0.302279646627605, "actor_loss": -19.145862268447875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.058518648147583, "step": 58000}
{"episode_reward": 290.7741585110375, "episode": 59.0, "batch_reward": 0.10854673033952714, "critic_loss": 0.326595625936985, "actor_loss": -18.76311788749695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.858833074569702, "step": 59000}
{"episode_reward": 362.7609485642588, "episode": 60.0, "batch_reward": 0.11458642549812793, "critic_loss": 0.35271753306686876, "actor_loss": -18.806794357299804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.426934957504272, "step": 60000}
{"episode_reward": 412.4950285803111, "episode": 61.0, "batch_reward": 0.11725373806059361, "critic_loss": 0.366081406801939, "actor_loss": -18.669034051895142, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.900864601135254, "step": 61000}
{"episode_reward": 108.78293116700601, "episode": 62.0, "batch_reward": 0.11689648169279099, "critic_loss": 0.3520127532631159, "actor_loss": -18.32936120605469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.61205768585205, "step": 62000}
{"episode_reward": 91.01691167243365, "episode": 63.0, "batch_reward": 0.11692924232035876, "critic_loss": 0.33857628726959227, "actor_loss": -17.831220163345336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.702520847320557, "step": 63000}
{"episode_reward": 77.21093120270807, "episode": 64.0, "batch_reward": 0.1173552067130804, "critic_loss": 0.34148037803173065, "actor_loss": -17.842918935775756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.193462371826172, "step": 64000}
{"episode_reward": 263.7337481775246, "episode": 65.0, "batch_reward": 0.11993943790346384, "critic_loss": 0.3426769551336765, "actor_loss": -17.91258087158203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.68792986869812, "step": 65000}
{"episode_reward": 453.3671397708914, "episode": 66.0, "batch_reward": 0.12312377517670393, "critic_loss": 0.34885327304899694, "actor_loss": -18.122774045944215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.992237329483032, "step": 66000}
{"episode_reward": 92.32162939059691, "episode": 67.0, "batch_reward": 0.12470295210182666, "critic_loss": 0.33994266963005065, "actor_loss": -18.072804012298583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.983376264572144, "step": 67000}
{"episode_reward": 411.93253442909895, "episode": 68.0, "batch_reward": 0.12847966347634793, "critic_loss": 0.33563272780179976, "actor_loss": -18.21501954078674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.681228637695312, "step": 68000}
{"episode_reward": 200.28731323120192, "episode": 69.0, "batch_reward": 0.12857706052809953, "critic_loss": 0.3547910380512476, "actor_loss": -17.53247985458374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.706403970718384, "step": 69000}
{"episode_reward": 128.0723536893323, "episode": 70.0, "batch_reward": 0.13000520105659963, "critic_loss": 0.3531504195034504, "actor_loss": -17.45967200469971, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.407169580459595, "step": 70000}
{"episode_reward": 374.64094095573114, "episode": 71.0, "batch_reward": 0.1335284962207079, "critic_loss": 0.36155363637208937, "actor_loss": -17.598129417419432, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.2601432800293, "step": 71000}
{"episode_reward": 275.49511315824685, "episode": 72.0, "batch_reward": 0.13637416997551918, "critic_loss": 0.3732354797273874, "actor_loss": -17.621701810836793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.841625928878784, "step": 72000}
{"episode_reward": 577.2950495451423, "episode": 73.0, "batch_reward": 0.1415536766499281, "critic_loss": 0.36769350318610666, "actor_loss": -17.946255043029787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.200722694396973, "step": 73000}
{"episode_reward": 277.7347690820327, "episode": 74.0, "batch_reward": 0.14188843113929034, "critic_loss": 0.37414616952836516, "actor_loss": -17.55396549606323, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.46527600288391, "step": 74000}
{"episode_reward": 235.1163595652857, "episode": 75.0, "batch_reward": 0.1428430813923478, "critic_loss": 0.3861392999738455, "actor_loss": -17.37849684906006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.510556936264038, "step": 75000}
{"episode_reward": 114.47205057662134, "episode": 76.0, "batch_reward": 0.14501710367947818, "critic_loss": 0.37724337908625605, "actor_loss": -17.56990322303772, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.23573327064514, "step": 76000}
{"episode_reward": 366.26745156230044, "episode": 77.0, "batch_reward": 0.14811651910096407, "critic_loss": 0.39298014348745347, "actor_loss": -17.605988019943236, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.05477023124695, "step": 77000}
{"episode_reward": 488.2632013634041, "episode": 78.0, "batch_reward": 0.15178596279770135, "critic_loss": 0.3923923302441835, "actor_loss": -17.90076522064209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.642879009246826, "step": 78000}
{"episode_reward": 472.40152445504856, "episode": 79.0, "batch_reward": 0.15641234636306764, "critic_loss": 0.39936844488978385, "actor_loss": -18.248969148635865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.246286630630493, "step": 79000}
{"episode_reward": 305.4166580386999, "episode": 80.0, "batch_reward": 0.15713531523942947, "critic_loss": 0.40292698825895784, "actor_loss": -18.374456384658814, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.85791325569153, "step": 80000}
{"episode_reward": 280.9462848852266, "episode": 81.0, "batch_reward": 0.15954175471514465, "critic_loss": 0.3902723721563816, "actor_loss": -18.479011478424074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.77013111114502, "step": 81000}
{"episode_reward": 554.2763916292015, "episode": 82.0, "batch_reward": 0.16367302392423153, "critic_loss": 0.3832881235480309, "actor_loss": -18.467420091629027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.43961215019226, "step": 82000}
{"episode_reward": 302.35339531974574, "episode": 83.0, "batch_reward": 0.16655290892720223, "critic_loss": 0.3689003105312586, "actor_loss": -18.90591383934021, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.644080638885498, "step": 83000}
{"episode_reward": 535.1836826563272, "episode": 84.0, "batch_reward": 0.17011770452558994, "critic_loss": 0.39812911477684976, "actor_loss": -18.837602899551392, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.353962898254395, "step": 84000}
{"episode_reward": 455.74978021662616, "episode": 85.0, "batch_reward": 0.17191995625942946, "critic_loss": 0.3977179106920958, "actor_loss": -18.943023370742797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.213778018951416, "step": 85000}
{"episode_reward": 149.55692042323088, "episode": 86.0, "batch_reward": 0.1734234751984477, "critic_loss": 0.3902419227361679, "actor_loss": -19.148348958969116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.334879636764526, "step": 86000}
{"episode_reward": 540.7361225540469, "episode": 87.0, "batch_reward": 0.17788124805688857, "critic_loss": 0.40752328726649284, "actor_loss": -19.506380767822264, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.99666428565979, "step": 87000}
{"episode_reward": 551.1866938764573, "episode": 88.0, "batch_reward": 0.18024922631680965, "critic_loss": 0.4111879512369633, "actor_loss": -19.241995876312256, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.33430290222168, "step": 88000}
{"episode_reward": 172.84744893057663, "episode": 89.0, "batch_reward": 0.18058380830287935, "critic_loss": 0.4094568745493889, "actor_loss": -19.359934732437132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.26566481590271, "step": 89000}
{"episode_reward": 170.73823749627593, "episode": 90.0, "batch_reward": 0.18249311493337153, "critic_loss": 0.42955439469218254, "actor_loss": -19.51172533416748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.240170001983643, "step": 90000}
{"episode_reward": 553.4340092025033, "episode": 91.0, "batch_reward": 0.18520981523394583, "critic_loss": 0.4198728443086147, "actor_loss": -19.536075380325318, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.749247550964355, "step": 91000}
{"episode_reward": 447.72683703237686, "episode": 92.0, "batch_reward": 0.18707745568454265, "critic_loss": 0.4169553648978472, "actor_loss": -19.667671152114867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.323827505111694, "step": 92000}
{"episode_reward": 91.61468929450677, "episode": 93.0, "batch_reward": 0.18590018554776908, "critic_loss": 0.4328556060343981, "actor_loss": -19.541953210830687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.103766918182373, "step": 93000}
{"episode_reward": 137.09005288070705, "episode": 94.0, "batch_reward": 0.18793094182014466, "critic_loss": 0.45200626671314237, "actor_loss": -19.468824207305907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.699586629867554, "step": 94000}
{"episode_reward": 581.7184907558112, "episode": 95.0, "batch_reward": 0.1901411540955305, "critic_loss": 0.45584461991488934, "actor_loss": -20.028428064346315, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.505487203598022, "step": 95000}
{"episode_reward": 573.6781442790029, "episode": 96.0, "batch_reward": 0.19678545320034027, "critic_loss": 0.4686316701322794, "actor_loss": -20.189814855575563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.833491325378418, "step": 96000}
{"episode_reward": 554.1972114391439, "episode": 97.0, "batch_reward": 0.19880926977097987, "critic_loss": 0.42732677662372587, "actor_loss": -20.49556142616272, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.153713941574097, "step": 97000}
{"episode_reward": 551.0934434834812, "episode": 98.0, "batch_reward": 0.2030073492974043, "critic_loss": 0.4424327328056097, "actor_loss": -21.275587032318114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.529495000839233, "step": 98000}
{"episode_reward": 602.5864670933452, "episode": 99.0, "batch_reward": 0.2063490555882454, "critic_loss": 0.44984519691765307, "actor_loss": -20.856699573516845, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.349907159805298, "step": 99000}
{"episode_reward": 556.7640690769008, "episode": 100.0, "batch_reward": 0.2114206911176443, "critic_loss": 0.46337370540201667, "actor_loss": -21.40147268676758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.871498107910156, "step": 100000}
{"episode_reward": 608.1311966386381, "episode": 101.0, "batch_reward": 0.21434854054450989, "critic_loss": 0.46541191419959066, "actor_loss": -21.575732067108156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.626588106155396, "step": 101000}
{"episode_reward": 558.9998432714689, "episode": 102.0, "batch_reward": 0.21756789237260818, "critic_loss": 0.46921249987185, "actor_loss": -21.939956031799316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.496198892593384, "step": 102000}
{"episode_reward": 462.49009028828243, "episode": 103.0, "batch_reward": 0.22043713112175464, "critic_loss": 0.4676946347653866, "actor_loss": -22.248841133117676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.72701907157898, "step": 103000}
{"episode_reward": 623.0440279900656, "episode": 104.0, "batch_reward": 0.2243163982629776, "critic_loss": 0.470673670142889, "actor_loss": -22.306890548706054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.350245475769043, "step": 104000}
{"episode_reward": 599.8199945713735, "episode": 105.0, "batch_reward": 0.2277153784930706, "critic_loss": 0.4796606609523296, "actor_loss": -22.681818418502807, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.298187732696533, "step": 105000}
{"episode_reward": 584.6380155402221, "episode": 106.0, "batch_reward": 0.23160982577502728, "critic_loss": 0.49525758434832096, "actor_loss": -23.05103787612915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.685405015945435, "step": 106000}
{"episode_reward": 573.4011916724754, "episode": 107.0, "batch_reward": 0.23404724490642548, "critic_loss": 0.4948796487897634, "actor_loss": -23.371979862213134, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.649538278579712, "step": 107000}
{"episode_reward": 518.8569816430745, "episode": 108.0, "batch_reward": 0.23695115664601327, "critic_loss": 0.4919986203610897, "actor_loss": -23.834926025390626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.318105697631836, "step": 108000}
{"episode_reward": 617.2717464334869, "episode": 109.0, "batch_reward": 0.24176016277074813, "critic_loss": 0.5108303633630276, "actor_loss": -24.046801120758058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.936095714569092, "step": 109000}
{"episode_reward": 448.2196230293821, "episode": 110.0, "batch_reward": 0.2438098867535591, "critic_loss": 0.48025079056620595, "actor_loss": -24.437493793487548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.054948806762695, "step": 110000}
{"episode_reward": 595.1008423245138, "episode": 111.0, "batch_reward": 0.24408358949422837, "critic_loss": 0.49735169266164303, "actor_loss": -24.31632339859009, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.73987698554993, "step": 111000}
{"episode_reward": 275.3478224663626, "episode": 112.0, "batch_reward": 0.2453769423365593, "critic_loss": 0.5011296173036098, "actor_loss": -24.507251289367677, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.436123609542847, "step": 112000}
{"episode_reward": 674.8575625408473, "episode": 113.0, "batch_reward": 0.24909718278050422, "critic_loss": 0.5006774709820747, "actor_loss": -24.679835445404052, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.34533977508545, "step": 113000}
{"episode_reward": 585.7859823375884, "episode": 114.0, "batch_reward": 0.2512552894502878, "critic_loss": 0.48973061655461786, "actor_loss": -25.089827697753908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.910942792892456, "step": 114000}
{"episode_reward": 570.5573934942327, "episode": 115.0, "batch_reward": 0.25467860378324986, "critic_loss": 0.48939212143421174, "actor_loss": -25.289712242126466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.157317638397217, "step": 115000}
{"episode_reward": 246.40273895025226, "episode": 116.0, "batch_reward": 0.25627156837284565, "critic_loss": 0.4844697835743427, "actor_loss": -25.287735973358153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.307526111602783, "step": 116000}
{"episode_reward": 647.8640672808078, "episode": 117.0, "batch_reward": 0.25969895891845224, "critic_loss": 0.5249368828684091, "actor_loss": -25.417107074737547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.71238660812378, "step": 117000}
{"episode_reward": 404.7260710261189, "episode": 118.0, "batch_reward": 0.25951787239313123, "critic_loss": 0.533073915541172, "actor_loss": -25.685019409179688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.28768563270569, "step": 118000}
{"episode_reward": 334.966030714699, "episode": 119.0, "batch_reward": 0.25973195365071294, "critic_loss": 0.5375969887375832, "actor_loss": -25.390682922363283, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.521629333496094, "step": 119000}
{"episode_reward": 276.751574789162, "episode": 120.0, "batch_reward": 0.25976771134138105, "critic_loss": 0.5352799814343453, "actor_loss": -25.342974384307862, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.75274634361267, "step": 120000}
{"episode_reward": 421.2871009456571, "episode": 121.0, "batch_reward": 0.26098976846039296, "critic_loss": 0.5640924756377935, "actor_loss": -25.41391709136963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.99747443199158, "step": 121000}
{"episode_reward": 636.5720933523891, "episode": 122.0, "batch_reward": 0.2660447901934385, "critic_loss": 0.5690522190481424, "actor_loss": -25.883627521514892, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.99130606651306, "step": 122000}
{"episode_reward": 632.6405851495831, "episode": 123.0, "batch_reward": 0.268143544703722, "critic_loss": 0.5610561701655388, "actor_loss": -26.09101266479492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.877033710479736, "step": 123000}
{"episode_reward": 636.4368746639406, "episode": 124.0, "batch_reward": 0.27167591446638106, "critic_loss": 0.5955282701253891, "actor_loss": -26.377927646636962, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.91021203994751, "step": 124000}
{"episode_reward": 591.9759590069918, "episode": 125.0, "batch_reward": 0.27163322089612485, "critic_loss": 0.5763810756802559, "actor_loss": -26.374290851593017, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.461161375045776, "step": 125000}
{"episode_reward": 79.48275396561678, "episode": 126.0, "batch_reward": 0.27231109224259853, "critic_loss": 0.5643692558705806, "actor_loss": -26.44892136001587, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.913151502609253, "step": 126000}
{"episode_reward": 636.0972800162654, "episode": 127.0, "batch_reward": 0.27384653089940547, "critic_loss": 0.5725853860676289, "actor_loss": -26.55958651351929, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.102855920791626, "step": 127000}
{"episode_reward": 159.5951879788807, "episode": 128.0, "batch_reward": 0.27406897459924223, "critic_loss": 0.591535051137209, "actor_loss": -26.623902473449707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.709174394607544, "step": 128000}
{"episode_reward": 246.66040577076262, "episode": 129.0, "batch_reward": 0.2749094737172127, "critic_loss": 0.587272467687726, "actor_loss": -26.705375301361084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.862914085388184, "step": 129000}
{"episode_reward": 636.4609160337528, "episode": 130.0, "batch_reward": 0.2755249254852533, "critic_loss": 0.5713057297468186, "actor_loss": -26.774098361968996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.201165914535522, "step": 130000}
{"episode_reward": 102.9869789786289, "episode": 131.0, "batch_reward": 0.27526138004660605, "critic_loss": 0.5820323572158813, "actor_loss": -26.604255561828612, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.93903183937073, "step": 131000}
{"episode_reward": 629.6493967860276, "episode": 132.0, "batch_reward": 0.2783227954804897, "critic_loss": 0.5599470959305763, "actor_loss": -26.82179711151123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986354112625122, "step": 132000}
{"episode_reward": 575.3335472984124, "episode": 133.0, "batch_reward": 0.2791643386632204, "critic_loss": 0.5678801318705082, "actor_loss": -26.998124332427977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.12238907814026, "step": 133000}
{"episode_reward": 134.30790154146067, "episode": 134.0, "batch_reward": 0.278551302716136, "critic_loss": 0.540753636687994, "actor_loss": -27.213823944091796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.399964094161987, "step": 134000}
{"episode_reward": 534.84536261915, "episode": 135.0, "batch_reward": 0.2809376183152199, "critic_loss": 0.5717615668177605, "actor_loss": -27.34673257827759, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.114248514175415, "step": 135000}
{"episode_reward": 622.5984363574032, "episode": 136.0, "batch_reward": 0.28451984383165835, "critic_loss": 0.603973956644535, "actor_loss": -27.45232593917847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.974384546279907, "step": 136000}
{"episode_reward": 592.4041020891626, "episode": 137.0, "batch_reward": 0.28598584996163845, "critic_loss": 0.586777230411768, "actor_loss": -27.778276805877685, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.290783643722534, "step": 137000}
{"episode_reward": 664.139030398642, "episode": 138.0, "batch_reward": 0.2886240918785334, "critic_loss": 0.5972416721582413, "actor_loss": -27.816139152526855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.127994537353516, "step": 138000}
{"episode_reward": 694.0112331690106, "episode": 139.0, "batch_reward": 0.29231051172316075, "critic_loss": 0.6207419764399529, "actor_loss": -27.96423676300049, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.3309326171875, "step": 139000}
{"episode_reward": 613.3341246317626, "episode": 140.0, "batch_reward": 0.2916454572379589, "critic_loss": 0.6277548366487026, "actor_loss": -27.8043111076355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.771056175231934, "step": 140000}
{"episode_reward": 311.1465032514469, "episode": 141.0, "batch_reward": 0.29606816510856154, "critic_loss": 0.6372195733189583, "actor_loss": -28.30141117477417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.66145586967468, "step": 141000}
{"episode_reward": 641.0526680253383, "episode": 142.0, "batch_reward": 0.2961501851826906, "critic_loss": 0.6585457967817784, "actor_loss": -28.254544338226317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.392921924591064, "step": 142000}
{"episode_reward": 209.20917778085706, "episode": 143.0, "batch_reward": 0.2962158130854368, "critic_loss": 0.6949776944816113, "actor_loss": -28.24821333694458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.018222332000732, "step": 143000}
{"episode_reward": 282.09318400887, "episode": 144.0, "batch_reward": 0.2957632535547018, "critic_loss": 0.6992899140715599, "actor_loss": -28.14932092666626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.89257287979126, "step": 144000}
{"episode_reward": 589.2990020925682, "episode": 145.0, "batch_reward": 0.2969438904374838, "critic_loss": 0.7118867186307907, "actor_loss": -28.231801124572755, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.585981845855713, "step": 145000}
{"episode_reward": 292.3830075906465, "episode": 146.0, "batch_reward": 0.2964874586164951, "critic_loss": 0.6921490088403225, "actor_loss": -28.242304267883302, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.890685081481934, "step": 146000}
{"episode_reward": 666.6416291584034, "episode": 147.0, "batch_reward": 0.2988590898513794, "critic_loss": 0.7119627935886383, "actor_loss": -28.278118007659913, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.802594900131226, "step": 147000}
{"episode_reward": 693.7661531626909, "episode": 148.0, "batch_reward": 0.3025095539987087, "critic_loss": 0.6758523409664631, "actor_loss": -28.610514472961427, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.84762191772461, "step": 148000}
{"episode_reward": 650.6163772686126, "episode": 149.0, "batch_reward": 0.3063700371682644, "critic_loss": 0.7098109989762306, "actor_loss": -28.845666500091554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.985861778259277, "step": 149000}
{"episode_reward": 570.6553348652928, "episode": 150.0, "batch_reward": 0.30697041608393194, "critic_loss": 0.7061869929134845, "actor_loss": -29.005660312652587, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
