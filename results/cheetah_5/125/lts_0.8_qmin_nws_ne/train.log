{"episode_reward": 0.0, "episode": 1.0, "duration": 18.8185555934906, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.8472139835357666, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2793271005372279, "critic_loss": 0.017906081483029537, "actor_loss": -38.97469149534108, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 68.64262986183167, "step": 3000}
{"episode_reward": 2.6491211416059115, "episode": 4.0, "batch_reward": 0.17317141188681126, "critic_loss": 0.010683342650299892, "actor_loss": -34.710662784576414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.345323085784912, "step": 4000}
{"episode_reward": 3.753715905014141, "episode": 5.0, "batch_reward": 0.13333398746699096, "critic_loss": 0.008978378749452532, "actor_loss": -31.272894974708557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.47459316253662, "step": 5000}
{"episode_reward": 3.5778574964034533, "episode": 6.0, "batch_reward": 0.10951221412792801, "critic_loss": 0.010842278332565911, "actor_loss": -31.07100212574005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.249253034591675, "step": 6000}
{"episode_reward": 3.9443462255744333, "episode": 7.0, "batch_reward": 0.0935425104163587, "critic_loss": 0.013572639247984625, "actor_loss": -30.746544055461882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.945953369140625, "step": 7000}
{"episode_reward": 3.945397837571437, "episode": 8.0, "batch_reward": 0.08241864027455449, "critic_loss": 0.00987103191879578, "actor_loss": -29.709697156190874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.80392098426819, "step": 8000}
{"episode_reward": 4.5644871811509296, "episode": 9.0, "batch_reward": 0.07242075120657683, "critic_loss": 0.011932425434933976, "actor_loss": -29.29870029306412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.670072317123413, "step": 9000}
{"episode_reward": 3.200390402750328, "episode": 10.0, "batch_reward": 0.06596532618626952, "critic_loss": 0.020894298492115923, "actor_loss": -29.282476866006853, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.140048503875732, "step": 10000}
{"episode_reward": 3.433244843302956, "episode": 11.0, "batch_reward": 0.060014659050852064, "critic_loss": 0.011124342399125454, "actor_loss": -28.87057433128357, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.54487061500549, "step": 11000}
{"episode_reward": 3.789079978006904, "episode": 12.0, "batch_reward": 0.05549554275348782, "critic_loss": 0.012407396396563854, "actor_loss": -27.997790816545486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.35518193244934, "step": 12000}
{"episode_reward": 4.593131094308149, "episode": 13.0, "batch_reward": 0.050686735313385724, "critic_loss": 0.015879867374547756, "actor_loss": -28.183778902769088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.689430713653564, "step": 13000}
{"episode_reward": 2.9369884480811743, "episode": 14.0, "batch_reward": 0.046779141828417775, "critic_loss": 0.01603933261107886, "actor_loss": -27.055036504745484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.982948064804077, "step": 14000}
{"episode_reward": 3.1134524034940556, "episode": 15.0, "batch_reward": 0.04439471690636128, "critic_loss": 0.012406701010535471, "actor_loss": -29.75651583623886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.138591766357422, "step": 15000}
{"episode_reward": 6.120972190468961, "episode": 16.0, "batch_reward": 0.0412564333723858, "critic_loss": 0.016934756643662695, "actor_loss": -27.876619786024094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.820882081985474, "step": 16000}
{"episode_reward": 3.176338766873777, "episode": 17.0, "batch_reward": 0.03951766797620803, "critic_loss": 0.01641313101450214, "actor_loss": -28.49787986898422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.56667184829712, "step": 17000}
{"episode_reward": 3.8665594882146648, "episode": 18.0, "batch_reward": 0.0374975933204405, "critic_loss": 0.019264694003621116, "actor_loss": -27.800038507461547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.093727111816406, "step": 18000}
{"episode_reward": 3.7177009764776603, "episode": 19.0, "batch_reward": 0.03553615440567955, "critic_loss": 0.01862285099748988, "actor_loss": -26.769280074477194, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.463900804519653, "step": 19000}
{"episode_reward": 5.69814703913176, "episode": 20.0, "batch_reward": 0.03359716170700267, "critic_loss": 0.0199648956466699, "actor_loss": -27.922709339141846, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.93474578857422, "step": 20000}
{"episode_reward": 2.5894683479507536, "episode": 21.0, "batch_reward": 0.032890837361104784, "critic_loss": 0.017695972717076073, "actor_loss": -27.809209896326067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.712287187576294, "step": 21000}
{"episode_reward": 4.617509559805332, "episode": 22.0, "batch_reward": 0.031126012388151138, "critic_loss": 0.02025380410233629, "actor_loss": -27.601709758639334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.93863272666931, "step": 22000}
{"episode_reward": 5.0496865082859115, "episode": 23.0, "batch_reward": 0.030514899769099428, "critic_loss": 0.022849638300132938, "actor_loss": -28.51337467300892, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.879069566726685, "step": 23000}
{"episode_reward": 4.017776447795975, "episode": 24.0, "batch_reward": 0.028888697028392925, "critic_loss": 0.01631505855591968, "actor_loss": -27.699589040756226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.795190572738647, "step": 24000}
{"episode_reward": 3.792891291077394, "episode": 25.0, "batch_reward": 0.027813381769694386, "critic_loss": 0.018192954851750983, "actor_loss": -27.122739760935307, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.69850993156433, "step": 25000}
{"episode_reward": 3.9059672632996922, "episode": 26.0, "batch_reward": 0.026683140088804066, "critic_loss": 0.01603433257501456, "actor_loss": -28.075391688704492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.52194380760193, "step": 26000}
{"episode_reward": 3.2117964742974516, "episode": 27.0, "batch_reward": 0.02632652263576165, "critic_loss": 0.019669594220176806, "actor_loss": -27.158831316530705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.467527151107788, "step": 27000}
{"episode_reward": 2.7096305011636623, "episode": 28.0, "batch_reward": 0.02503637573774904, "critic_loss": 0.017915014278623857, "actor_loss": -26.732047173023226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.983808755874634, "step": 28000}
{"episode_reward": 3.0080245957968894, "episode": 29.0, "batch_reward": 0.025221797125181182, "critic_loss": 0.01913007653571549, "actor_loss": -27.33886320412159, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.060202598571777, "step": 29000}
{"episode_reward": 3.8293900248777444, "episode": 30.0, "batch_reward": 0.023445355723844843, "critic_loss": 0.012925024055410177, "actor_loss": -26.67182198923826, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.310086011886597, "step": 30000}
{"episode_reward": 3.9132951432484804, "episode": 31.0, "batch_reward": 0.02297723561548628, "critic_loss": 0.016405450632824795, "actor_loss": -26.742064589619638, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.29271650314331, "step": 31000}
{"episode_reward": 3.744523568432661, "episode": 32.0, "batch_reward": 0.02215122663183138, "critic_loss": 0.018983465823257575, "actor_loss": -26.095272539556028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.510379314422607, "step": 32000}
{"episode_reward": 3.751134272991107, "episode": 33.0, "batch_reward": 0.021892908016918226, "critic_loss": 0.014227555313060292, "actor_loss": -27.118543090462683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96851348876953, "step": 33000}
{"episode_reward": 3.2130324907889247, "episode": 34.0, "batch_reward": 0.021299961360171437, "critic_loss": 0.019086793030146508, "actor_loss": -26.03007698202133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.474257946014404, "step": 34000}
{"episode_reward": 3.371005508090713, "episode": 35.0, "batch_reward": 0.020558535105315967, "critic_loss": 0.015086476612108527, "actor_loss": -27.53069091910124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.677290439605713, "step": 35000}
{"episode_reward": 3.7264982786654164, "episode": 36.0, "batch_reward": 0.020089176359819248, "critic_loss": 0.01734542003844399, "actor_loss": -25.771578876137735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.598742485046387, "step": 36000}
{"episode_reward": 4.078024269943361, "episode": 37.0, "batch_reward": 0.019875161454314366, "critic_loss": 0.0215018775734643, "actor_loss": -27.272824075996876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.488197803497314, "step": 37000}
{"episode_reward": 3.1977136293417128, "episode": 38.0, "batch_reward": 0.019519075534772126, "critic_loss": 0.01035427656621323, "actor_loss": -27.115771531105043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.549504280090332, "step": 38000}
{"episode_reward": 4.0517815658492315, "episode": 39.0, "batch_reward": 0.018897976327920334, "critic_loss": 0.016186983829655218, "actor_loss": -27.113621856570244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.730899572372437, "step": 39000}
{"episode_reward": 3.749992251724155, "episode": 40.0, "batch_reward": 0.01873752132663503, "critic_loss": 0.01763779358236934, "actor_loss": -27.34412898632884, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.890913248062134, "step": 40000}
{"episode_reward": 4.082632923266037, "episode": 41.0, "batch_reward": 0.018506332555320113, "critic_loss": 0.013719122645125027, "actor_loss": -27.429024749040604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.104525327682495, "step": 41000}
{"episode_reward": 5.632304949333324, "episode": 42.0, "batch_reward": 0.01770228015515022, "critic_loss": 0.012735828746343032, "actor_loss": -26.248242174744608, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.100700616836548, "step": 42000}
{"episode_reward": 4.424742048253088, "episode": 43.0, "batch_reward": 0.017709464970510454, "critic_loss": 0.012533523205565871, "actor_loss": -26.578284699082374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.81935977935791, "step": 43000}
{"episode_reward": 4.937332728741184, "episode": 44.0, "batch_reward": 0.017267354676732793, "critic_loss": 0.008134715602136567, "actor_loss": -26.389269471347333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.618870973587036, "step": 44000}
{"episode_reward": 3.9690057075506178, "episode": 45.0, "batch_reward": 0.017235312504228203, "critic_loss": 0.009775867594900773, "actor_loss": -26.531422972619534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.181844234466553, "step": 45000}
{"episode_reward": 3.2906965572718643, "episode": 46.0, "batch_reward": 0.016564131838968023, "critic_loss": 0.012586605793228955, "actor_loss": -26.377421770602464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.68597960472107, "step": 46000}
{"episode_reward": 3.2040619389755274, "episode": 47.0, "batch_reward": 0.016927610971033572, "critic_loss": 0.010532360375684221, "actor_loss": -27.01881343898177, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.25416851043701, "step": 47000}
{"episode_reward": 3.8279669593488075, "episode": 48.0, "batch_reward": 0.016143839250784366, "critic_loss": 0.010490082994918338, "actor_loss": -26.55852520763874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.274360179901123, "step": 48000}
{"episode_reward": 4.609907758160985, "episode": 49.0, "batch_reward": 0.01620477684494108, "critic_loss": 0.012163736641014111, "actor_loss": -27.447640215605496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.332335233688354, "step": 49000}
{"episode_reward": 2.8127850813898467, "episode": 50.0, "batch_reward": 0.015333233249839396, "critic_loss": 0.013917957455443684, "actor_loss": -26.42587384492159, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.042715549468994, "step": 50000}
{"episode_reward": 3.0666252939571077, "episode": 51.0, "batch_reward": 0.015268237427342683, "critic_loss": 0.006231696610280778, "actor_loss": -26.642152549088003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.81674337387085, "step": 51000}
{"episode_reward": 3.096834920238897, "episode": 52.0, "batch_reward": 0.01521312540746294, "critic_loss": 0.010338885007397039, "actor_loss": -26.414544285476207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.80294156074524, "step": 52000}
{"episode_reward": 3.4169443924139946, "episode": 53.0, "batch_reward": 0.01516523336363025, "critic_loss": 0.01050285299650568, "actor_loss": -26.754971148192883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.70344114303589, "step": 53000}
{"episode_reward": 3.220341423965275, "episode": 54.0, "batch_reward": 0.014439020740101114, "critic_loss": 0.013632618544696015, "actor_loss": -26.3297845441401, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.824554204940796, "step": 54000}
{"episode_reward": 6.771081871890561, "episode": 55.0, "batch_reward": 0.014791095124091953, "critic_loss": 0.009540649315458722, "actor_loss": -27.4801146915257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.29097890853882, "step": 55000}
{"episode_reward": 3.5257557270457105, "episode": 56.0, "batch_reward": 0.014393826549407095, "critic_loss": 0.009662103194408701, "actor_loss": -27.095177584320307, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.26310396194458, "step": 56000}
{"episode_reward": 4.351872238468322, "episode": 57.0, "batch_reward": 0.01399168079975061, "critic_loss": 0.01389422670291242, "actor_loss": -26.108059865042566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.895825147628784, "step": 57000}
{"episode_reward": 4.503934381826974, "episode": 58.0, "batch_reward": 0.014202673716237768, "critic_loss": 0.008934320254265913, "actor_loss": -26.420795174315572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.649059534072876, "step": 58000}
{"episode_reward": 3.2581449179272814, "episode": 59.0, "batch_reward": 0.013569140573265031, "critic_loss": 0.014836651968464138, "actor_loss": -25.99722065576911, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.44533920288086, "step": 59000}
{"episode_reward": 3.3638228986175034, "episode": 60.0, "batch_reward": 0.013794267479795962, "critic_loss": 0.010080465249659028, "actor_loss": -26.239646731466056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.16351819038391, "step": 60000}
{"episode_reward": 4.460197728468993, "episode": 61.0, "batch_reward": 0.013639025939162821, "critic_loss": 0.009450413917074912, "actor_loss": -25.83814297398925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.63960599899292, "step": 61000}
{"episode_reward": 4.079103020167613, "episode": 62.0, "batch_reward": 0.013618617760948836, "critic_loss": 0.011002363557374337, "actor_loss": -27.11129205366969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.05389952659607, "step": 62000}
{"episode_reward": 3.2196635600811874, "episode": 63.0, "batch_reward": 0.013263688190840185, "critic_loss": 0.009012371450371575, "actor_loss": -26.32062893123925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.057345867156982, "step": 63000}
{"episode_reward": 3.381798254626361, "episode": 64.0, "batch_reward": 0.012695008057169617, "critic_loss": 0.012222500610005228, "actor_loss": -26.4112771166265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.010732650756836, "step": 64000}
{"episode_reward": 3.342086051700021, "episode": 65.0, "batch_reward": 0.012769589048111811, "critic_loss": 0.008714159376540919, "actor_loss": -25.987152636900543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.249501943588257, "step": 65000}
{"episode_reward": 2.68579144093835, "episode": 66.0, "batch_reward": 0.012856226205360144, "critic_loss": 0.012436019230452075, "actor_loss": -26.196653719037773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.719156980514526, "step": 66000}
{"episode_reward": 3.642368199374612, "episode": 67.0, "batch_reward": 0.0126282511127647, "critic_loss": 0.0077115024450249625, "actor_loss": -26.418158384010194, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.025846004486084, "step": 67000}
{"episode_reward": 4.7772984267677145, "episode": 68.0, "batch_reward": 0.01238259458518587, "critic_loss": 0.009739740330245696, "actor_loss": -25.93901168654859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.343499183654785, "step": 68000}
{"episode_reward": 3.834193733845103, "episode": 69.0, "batch_reward": 0.012130036893999205, "critic_loss": 0.008427695572303492, "actor_loss": -26.20610865202546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.891157627105713, "step": 69000}
{"episode_reward": 3.094107900067268, "episode": 70.0, "batch_reward": 0.01239225382823497, "critic_loss": 0.008876540459968964, "actor_loss": -26.465666994065046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.842214822769165, "step": 70000}
{"episode_reward": 3.6625488450407633, "episode": 71.0, "batch_reward": 0.01239727858104743, "critic_loss": 0.010768420190855978, "actor_loss": -26.746948705419896, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.06480646133423, "step": 71000}
{"episode_reward": 2.9659059878173237, "episode": 72.0, "batch_reward": 0.012180645512416958, "critic_loss": 0.00991064997499052, "actor_loss": -26.794179236054422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.821718215942383, "step": 72000}
{"episode_reward": 3.6396870245023867, "episode": 73.0, "batch_reward": 0.011998704677680508, "critic_loss": 0.01043919654628553, "actor_loss": -26.312824775874613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.51965570449829, "step": 73000}
{"episode_reward": 2.611364526343922, "episode": 74.0, "batch_reward": 0.01161432865820825, "critic_loss": 0.007613446502604347, "actor_loss": -26.897607515126467, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.548839569091797, "step": 74000}
{"episode_reward": 3.050583795422766, "episode": 75.0, "batch_reward": 0.011461460938910022, "critic_loss": 0.006018279599928064, "actor_loss": -26.157531339704992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.629971027374268, "step": 75000}
{"episode_reward": 2.1068213277117467, "episode": 76.0, "batch_reward": 0.011557216287590563, "critic_loss": 0.006935243166153669, "actor_loss": -26.486914032951, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.68125891685486, "step": 76000}
{"episode_reward": 4.325358211042472, "episode": 77.0, "batch_reward": 0.011381455174880102, "critic_loss": 0.008076285966650176, "actor_loss": -25.77610604915023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.519185543060303, "step": 77000}
{"episode_reward": 3.000808242299227, "episode": 78.0, "batch_reward": 0.01163072506710887, "critic_loss": 0.00992523984143918, "actor_loss": -26.561565756753087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.012078285217285, "step": 78000}
{"episode_reward": 3.8387043664726583, "episode": 79.0, "batch_reward": 0.010940768147120252, "critic_loss": 0.0056090842839621475, "actor_loss": -24.784635668203233, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.346905946731567, "step": 79000}
{"episode_reward": 4.173861391612581, "episode": 80.0, "batch_reward": 0.010952548678964377, "critic_loss": 0.009085518196654447, "actor_loss": -25.79716935390234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.91662859916687, "step": 80000}
{"episode_reward": 3.6410325297029233, "episode": 81.0, "batch_reward": 0.010719375773333014, "critic_loss": 0.008309647447851603, "actor_loss": -25.595388421207666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.44439244270325, "step": 81000}
{"episode_reward": 3.0680433711731045, "episode": 82.0, "batch_reward": 0.011069834606023505, "critic_loss": 0.007714227677133749, "actor_loss": -27.057078125283123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.23375129699707, "step": 82000}
{"episode_reward": 4.130125929196233, "episode": 83.0, "batch_reward": 0.010540558133739978, "critic_loss": 0.012268355489781243, "actor_loss": -25.590514645829796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.22842264175415, "step": 83000}
{"episode_reward": 3.6827736142475453, "episode": 84.0, "batch_reward": 0.010410341127309947, "critic_loss": 0.007873518843276542, "actor_loss": -27.522341324687005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5753116607666, "step": 84000}
{"episode_reward": 4.897600426545592, "episode": 85.0, "batch_reward": 0.010769059373997152, "critic_loss": 0.0075680219567366295, "actor_loss": -26.309449802353978, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.844232320785522, "step": 85000}
{"episode_reward": 3.188778787648865, "episode": 86.0, "batch_reward": 0.010496468965662644, "critic_loss": 0.007513515787475626, "actor_loss": -26.213139271587135, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.188182592391968, "step": 86000}
{"episode_reward": 4.369213400286169, "episode": 87.0, "batch_reward": 0.010609238765668124, "critic_loss": 0.006358414672249637, "actor_loss": -26.04769359880686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.937918186187744, "step": 87000}
{"episode_reward": 3.5251254215406167, "episode": 88.0, "batch_reward": 0.010544928007060661, "critic_loss": 0.00704112245250144, "actor_loss": -25.390395552173256, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.38602924346924, "step": 88000}
{"episode_reward": 3.9651342769227433, "episode": 89.0, "batch_reward": 0.010571144429501146, "critic_loss": 0.006700328065540816, "actor_loss": -26.296595629751682, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.358925342559814, "step": 89000}
{"episode_reward": 3.526713929643119, "episode": 90.0, "batch_reward": 0.010296946921152994, "critic_loss": 0.00834672224213864, "actor_loss": -26.681685732394456, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00662326812744, "step": 90000}
{"episode_reward": 3.584971895746747, "episode": 91.0, "batch_reward": 0.010548513451591133, "critic_loss": 0.005240877469819679, "actor_loss": -26.223043930202724, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.95879125595093, "step": 91000}
{"episode_reward": 3.1625254595145016, "episode": 92.0, "batch_reward": 0.010290847860975191, "critic_loss": 0.006235579609587148, "actor_loss": -26.03090060968697, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.172248125076294, "step": 92000}
{"episode_reward": 4.0444269174457395, "episode": 93.0, "batch_reward": 0.010076414166716858, "critic_loss": 0.004402443414997834, "actor_loss": -25.56556339405477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.980172157287598, "step": 93000}
{"episode_reward": 4.150013600320927, "episode": 94.0, "batch_reward": 0.009924331187503412, "critic_loss": 0.005653395742789144, "actor_loss": -26.13878167241812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.979919910430908, "step": 94000}
{"episode_reward": 4.007058090537469, "episode": 95.0, "batch_reward": 0.009941593201830983, "critic_loss": 0.006015903913801594, "actor_loss": -26.399147875502706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.946945905685425, "step": 95000}
{"episode_reward": 3.3406272405404778, "episode": 96.0, "batch_reward": 0.009915736256632954, "critic_loss": 0.0043739992284099576, "actor_loss": -26.572992948502304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.434581756591797, "step": 96000}
{"episode_reward": 3.5562577495518566, "episode": 97.0, "batch_reward": 0.010027786603197456, "critic_loss": 0.005407897607386985, "actor_loss": -26.991172403380276, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.489049434661865, "step": 97000}
{"episode_reward": 4.370071556966225, "episode": 98.0, "batch_reward": 0.009791321843047627, "critic_loss": 0.005623374308503117, "actor_loss": -26.43254229900241, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.155566692352295, "step": 98000}
{"episode_reward": 3.6378149451741653, "episode": 99.0, "batch_reward": 0.009596970284823328, "critic_loss": 0.005422359716525534, "actor_loss": -25.59061020322889, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.748597383499146, "step": 99000}
{"episode_reward": 4.4860528307245895, "episode": 100.0, "batch_reward": 0.009723164267838001, "critic_loss": 0.006053682502046286, "actor_loss": -26.190906473077835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.29176115989685, "step": 100000}
{"episode_reward": 4.278698130647543, "episode": 101.0, "batch_reward": 0.00956174191692844, "critic_loss": 0.0068186961838364365, "actor_loss": -26.243039932407438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.12861633300781, "step": 101000}
{"episode_reward": 3.412036182234638, "episode": 102.0, "batch_reward": 0.00969327513477765, "critic_loss": 0.005155266687826952, "actor_loss": -25.729127536699174, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.815217971801758, "step": 102000}
{"episode_reward": 3.203222885509242, "episode": 103.0, "batch_reward": 0.009686742804478853, "critic_loss": 0.00677470726800675, "actor_loss": -26.513653394535183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.831610679626465, "step": 103000}
{"episode_reward": 2.2673942522902393, "episode": 104.0, "batch_reward": 0.009326254495186731, "critic_loss": 0.007764386438204383, "actor_loss": -26.558178119577466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.980812549591064, "step": 104000}
{"episode_reward": 2.346622820302132, "episode": 105.0, "batch_reward": 0.009597002822207287, "critic_loss": 0.0056022497751764605, "actor_loss": -26.44469127880782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5595486164093, "step": 105000}
{"episode_reward": 3.7820546800933004, "episode": 106.0, "batch_reward": 0.009360519141657277, "critic_loss": 0.008980405835325654, "actor_loss": -26.10860713658482, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.772878885269165, "step": 106000}
{"episode_reward": 3.3562307447932818, "episode": 107.0, "batch_reward": 0.009340246995678172, "critic_loss": 0.007096382736104715, "actor_loss": -26.626741792418063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.724143266677856, "step": 107000}
{"episode_reward": 4.307601014960569, "episode": 108.0, "batch_reward": 0.009214368836022913, "critic_loss": 0.004860199896924314, "actor_loss": -26.155389236830175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.898106336593628, "step": 108000}
{"episode_reward": 2.539392120243049, "episode": 109.0, "batch_reward": 0.008954389397287741, "critic_loss": 0.0060232506504253255, "actor_loss": -27.44354199002683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.770753383636475, "step": 109000}
{"episode_reward": 3.5777586157749357, "episode": 110.0, "batch_reward": 0.00891395242442377, "critic_loss": 0.004309046826310805, "actor_loss": -26.849667757436634, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.466553449630737, "step": 110000}
{"episode_reward": 3.6195401194361856, "episode": 111.0, "batch_reward": 0.0089687386774458, "critic_loss": 0.0052468073785348675, "actor_loss": -26.805281939692794, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.792195081710815, "step": 111000}
{"episode_reward": 3.683447198927465, "episode": 112.0, "batch_reward": 0.00908235928695649, "critic_loss": 0.00511049775214633, "actor_loss": -25.6836931739077, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.850767612457275, "step": 112000}
{"episode_reward": 3.92884173788069, "episode": 113.0, "batch_reward": 0.00881867924425751, "critic_loss": 0.0043002524331168385, "actor_loss": -26.53130906058848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.783976316452026, "step": 113000}
{"episode_reward": 3.5090692660739715, "episode": 114.0, "batch_reward": 0.008802976049249992, "critic_loss": 0.005533345343857945, "actor_loss": -27.108399825282394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.546427011489868, "step": 114000}
{"episode_reward": 3.2384801475908036, "episode": 115.0, "batch_reward": 0.008890167569508776, "critic_loss": 0.007174839736806462, "actor_loss": -26.32339922617376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.502048015594482, "step": 115000}
{"episode_reward": 3.592724576625132, "episode": 116.0, "batch_reward": 0.008821474967058748, "critic_loss": 0.004535916189815907, "actor_loss": -26.272746799752117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.501391410827637, "step": 116000}
{"episode_reward": 3.624449306481973, "episode": 117.0, "batch_reward": 0.008934902643784881, "critic_loss": 0.004121030307389447, "actor_loss": -25.966922818616034, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.135398864746094, "step": 117000}
{"episode_reward": 3.8923068196174535, "episode": 118.0, "batch_reward": 0.00892149298870936, "critic_loss": 0.0054820641692567736, "actor_loss": -26.47640520389378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.041335821151733, "step": 118000}
{"episode_reward": 3.838267985849635, "episode": 119.0, "batch_reward": 0.008661844083340838, "critic_loss": 0.004984961932997976, "actor_loss": -26.595347233071923, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.211096048355103, "step": 119000}
{"episode_reward": 6.069554068721772, "episode": 120.0, "batch_reward": 0.008506505884462967, "critic_loss": 0.00466457382360386, "actor_loss": -26.262357094578444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.247114419937134, "step": 120000}
{"episode_reward": 3.450121559048755, "episode": 121.0, "batch_reward": 0.008680425003170967, "critic_loss": 0.004009342546385596, "actor_loss": -25.613472808510064, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.01546621322632, "step": 121000}
{"episode_reward": 4.455688615903692, "episode": 122.0, "batch_reward": 0.008675340009853243, "critic_loss": 0.0034228184737003175, "actor_loss": -25.991590386260302, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.4661705493927, "step": 122000}
{"episode_reward": 5.787831688162508, "episode": 123.0, "batch_reward": 0.008630396298132836, "critic_loss": 0.004079386609810172, "actor_loss": -25.017545336663723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.75805115699768, "step": 123000}
{"episode_reward": 3.3871269281861975, "episode": 124.0, "batch_reward": 0.008440891740145161, "critic_loss": 0.004046374683457543, "actor_loss": -25.805895074840635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.066165447235107, "step": 124000}
{"episode_reward": 3.1921477280200756, "episode": 125.0, "batch_reward": 0.008370943221729248, "critic_loss": 0.004813950889059925, "actor_loss": -25.54280803624168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.45812225341797, "step": 125000}
{"episode_reward": 3.242839493841838, "episode": 126.0, "batch_reward": 0.008251188318477943, "critic_loss": 0.004579407257006096, "actor_loss": -24.94215994624421, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.74824333190918, "step": 126000}
{"episode_reward": 3.7906616331617764, "episode": 127.0, "batch_reward": 0.008419338945299388, "critic_loss": 0.0027358499541442144, "actor_loss": -26.17472737487033, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.984275579452515, "step": 127000}
{"episode_reward": 4.111226523417749, "episode": 128.0, "batch_reward": 0.008269712680485099, "critic_loss": 0.003432766378558881, "actor_loss": -27.006179597716777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.65698552131653, "step": 128000}
{"episode_reward": 3.4972027093358014, "episode": 129.0, "batch_reward": 0.008396622572327032, "critic_loss": 0.0031998424415214687, "actor_loss": -26.29437276250124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.748588800430298, "step": 129000}
{"episode_reward": 3.6299514359018574, "episode": 130.0, "batch_reward": 0.008160259122028947, "critic_loss": 0.0026961039543675724, "actor_loss": -26.15504969875142, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.242337226867676, "step": 130000}
{"episode_reward": 3.323766841754149, "episode": 131.0, "batch_reward": 0.008281515941023826, "critic_loss": 0.0036405748713295907, "actor_loss": -26.813922706913203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.74068832397461, "step": 131000}
{"episode_reward": 4.208890688576534, "episode": 132.0, "batch_reward": 0.008347979688085616, "critic_loss": 0.0027649288204847837, "actor_loss": -26.682768951062112, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.37164545059204, "step": 132000}
{"episode_reward": 3.6169828095080723, "episode": 133.0, "batch_reward": 0.008201313428115099, "critic_loss": 0.0028317496714225852, "actor_loss": -26.28895469128713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.222092628479004, "step": 133000}
{"episode_reward": 2.9874611752181104, "episode": 134.0, "batch_reward": 0.008279577016597614, "critic_loss": 0.003448348848542082, "actor_loss": -26.673004071496425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.319659948349, "step": 134000}
{"episode_reward": 5.1772652849696925, "episode": 135.0, "batch_reward": 0.00824291850021109, "critic_loss": 0.002684945513574348, "actor_loss": -26.403264315124602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.657516479492188, "step": 135000}
{"episode_reward": 5.17954505125917, "episode": 136.0, "batch_reward": 0.007957711902912706, "critic_loss": 0.0030789852118468844, "actor_loss": -27.375008247978986, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.974058389663696, "step": 136000}
{"episode_reward": 2.6086753940828777, "episode": 137.0, "batch_reward": 0.008015205063391477, "critic_loss": 0.0036848107544574303, "actor_loss": -26.602289125189184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.420324325561523, "step": 137000}
{"episode_reward": 3.9720292494210767, "episode": 138.0, "batch_reward": 0.008324951843824237, "critic_loss": 0.002576204618962947, "actor_loss": -25.066589209567756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.406298398971558, "step": 138000}
{"episode_reward": 4.479443379110236, "episode": 139.0, "batch_reward": 0.00817468204558827, "critic_loss": 0.003148415446303261, "actor_loss": -25.581720480784774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.11103057861328, "step": 139000}
{"episode_reward": 3.4204947371818863, "episode": 140.0, "batch_reward": 0.007870975255034864, "critic_loss": 0.004125980183678621, "actor_loss": -24.98874100801721, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.00671100616455, "step": 140000}
{"episode_reward": 3.013981821614807, "episode": 141.0, "batch_reward": 0.007901398937916384, "critic_loss": 0.0028182741375494514, "actor_loss": -25.490057226847856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.32457494735718, "step": 141000}
{"episode_reward": 3.2051316044953744, "episode": 142.0, "batch_reward": 0.008076160974800586, "critic_loss": 0.00299206328670698, "actor_loss": -25.765409438319505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.53504228591919, "step": 142000}
{"episode_reward": 3.5576513978169486, "episode": 143.0, "batch_reward": 0.00794717313325964, "critic_loss": 0.0030862099476507863, "actor_loss": -26.276614591758698, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98163890838623, "step": 143000}
{"episode_reward": 4.639876516659956, "episode": 144.0, "batch_reward": 0.008110378990648315, "critic_loss": 0.0031801956539093228, "actor_loss": -26.086199082132428, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.520427465438843, "step": 144000}
{"episode_reward": 3.8056454331907648, "episode": 145.0, "batch_reward": 0.007866302227601409, "critic_loss": 0.003533978050589212, "actor_loss": -25.747780866432937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.99440336227417, "step": 145000}
{"episode_reward": 2.674260329461393, "episode": 146.0, "batch_reward": 0.007831661397358403, "critic_loss": 0.0026767282468208578, "actor_loss": -25.563024333819747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997170448303223, "step": 146000}
{"episode_reward": 4.737480762626057, "episode": 147.0, "batch_reward": 0.007601300788111985, "critic_loss": 0.0031504568673481116, "actor_loss": -26.569736813049765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.32893395423889, "step": 147000}
{"episode_reward": 3.7712385233753762, "episode": 148.0, "batch_reward": 0.00820955305895768, "critic_loss": 0.0032745148200192488, "actor_loss": -25.771972886946052, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.60620093345642, "step": 148000}
{"episode_reward": 2.667883094999555, "episode": 149.0, "batch_reward": 0.007790991399437189, "critic_loss": 0.0030413755299232435, "actor_loss": -26.141211626030504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.145617723464966, "step": 149000}
{"episode_reward": 5.750331017894978, "episode": 150.0, "batch_reward": 0.0076592813343741, "critic_loss": 0.0034110042592074025, "actor_loss": -25.237300214260816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
