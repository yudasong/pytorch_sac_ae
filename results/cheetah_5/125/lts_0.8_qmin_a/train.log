{"episode_reward": 0.0, "episode": 1.0, "duration": 17.80032777786255, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.5151293277740479, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2821254245179142, "critic_loss": 0.030110377770677463, "actor_loss": -40.02657006423855, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 62.06523847579956, "step": 3000}
{"episode_reward": 63.004496480087916, "episode": 4.0, "batch_reward": 0.19084794645011424, "critic_loss": 0.03752819242142141, "actor_loss": -35.57942060424387, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.916818141937256, "step": 4000}
{"episode_reward": 5.576006348998665, "episode": 5.0, "batch_reward": 0.15112405110895633, "critic_loss": 0.04908042072504759, "actor_loss": -32.163293634697794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.166423559188843, "step": 5000}
{"episode_reward": 49.07017173152432, "episode": 6.0, "batch_reward": 0.13001381266862155, "critic_loss": 0.040369825847446916, "actor_loss": -32.22129483266175, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.881292581558228, "step": 6000}
{"episode_reward": 11.949404522945398, "episode": 7.0, "batch_reward": 0.11142272194474935, "critic_loss": 0.04102987810224295, "actor_loss": -32.12981220278144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.69995880126953, "step": 7000}
{"episode_reward": 8.818066044428422, "episode": 8.0, "batch_reward": 0.100547666978091, "critic_loss": 0.04577445575594902, "actor_loss": -31.015103991642594, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.529968738555908, "step": 8000}
{"episode_reward": 49.32537901990872, "episode": 9.0, "batch_reward": 0.09498952506855131, "critic_loss": 0.052893710469827056, "actor_loss": -30.686004098415374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.551209688186646, "step": 9000}
{"episode_reward": 57.8853744630972, "episode": 10.0, "batch_reward": 0.09480396559461951, "critic_loss": 0.06734572761505843, "actor_loss": -30.830112125635146, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.671653032302856, "step": 10000}
{"episode_reward": 146.5270173122422, "episode": 11.0, "batch_reward": 0.10501313103735446, "critic_loss": 0.11437617733329535, "actor_loss": -30.59034168253839, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.371806383132935, "step": 11000}
{"episode_reward": 228.18702587028372, "episode": 12.0, "batch_reward": 0.11371471209824086, "critic_loss": 0.11618867858499289, "actor_loss": -30.11224107991159, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.725934505462646, "step": 12000}
{"episode_reward": 158.18957598602438, "episode": 13.0, "batch_reward": 0.11844402504712344, "critic_loss": 0.12737924498319625, "actor_loss": -30.1589321449697, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.15655207633972, "step": 13000}
{"episode_reward": 159.72854618212457, "episode": 14.0, "batch_reward": 0.1183987071737647, "critic_loss": 0.13773998836055398, "actor_loss": -28.47732489733398, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.51249361038208, "step": 14000}
{"episode_reward": 171.731359769076, "episode": 15.0, "batch_reward": 0.12199256597459317, "critic_loss": 0.17007627857476473, "actor_loss": -31.436635850340128, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88111901283264, "step": 15000}
{"episode_reward": 90.19716630543256, "episode": 16.0, "batch_reward": 0.12089175579696894, "critic_loss": 0.1875540140196681, "actor_loss": -29.0221573317647, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.127174139022827, "step": 16000}
{"episode_reward": 169.14702909775718, "episode": 17.0, "batch_reward": 0.12376301881670952, "critic_loss": 0.20013562440127133, "actor_loss": -29.87956466650963, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.979263067245483, "step": 17000}
{"episode_reward": 122.73375735823706, "episode": 18.0, "batch_reward": 0.12213437616080046, "critic_loss": 0.20156483752280474, "actor_loss": -28.53555693602562, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.52043843269348, "step": 18000}
{"episode_reward": 56.64826298089766, "episode": 19.0, "batch_reward": 0.12133524822443724, "critic_loss": 0.22419135776907206, "actor_loss": -27.26781025147438, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.41481924057007, "step": 19000}
{"episode_reward": 207.544601640647, "episode": 20.0, "batch_reward": 0.1236312805712223, "critic_loss": 0.22011532094329594, "actor_loss": -28.447682866573334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.962849140167236, "step": 20000}
{"episode_reward": 81.78474519468315, "episode": 21.0, "batch_reward": 0.12029306704550982, "critic_loss": 0.22462592235207557, "actor_loss": -27.59718053817749, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.06336808204651, "step": 21000}
{"episode_reward": 32.75621076386295, "episode": 22.0, "batch_reward": 0.1175362706258893, "critic_loss": 0.2356868626922369, "actor_loss": -26.70442367887497, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.920236587524414, "step": 22000}
{"episode_reward": 76.03996670107252, "episode": 23.0, "batch_reward": 0.11754617647826672, "critic_loss": 0.23526833435893058, "actor_loss": -27.186295644521714, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.132989406585693, "step": 23000}
{"episode_reward": 171.7326612924728, "episode": 24.0, "batch_reward": 0.11957914559543133, "critic_loss": 0.25716384668648246, "actor_loss": -27.006112473487853, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.23629069328308, "step": 24000}
{"episode_reward": 225.93225351390666, "episode": 25.0, "batch_reward": 0.12321924718469382, "critic_loss": 0.2810560849457979, "actor_loss": -26.728989767074584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.143226623535156, "step": 25000}
{"episode_reward": 140.8158598477568, "episode": 26.0, "batch_reward": 0.12484945209324359, "critic_loss": 0.2551060253679752, "actor_loss": -27.582238257884978, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.510212659835815, "step": 26000}
{"episode_reward": 253.95084613899408, "episode": 27.0, "batch_reward": 0.13124194720387458, "critic_loss": 0.272855439811945, "actor_loss": -27.39365209197998, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.726009845733643, "step": 27000}
{"episode_reward": 284.5193006252536, "episode": 28.0, "batch_reward": 0.13432824191451073, "critic_loss": 0.3137704578638077, "actor_loss": -27.085291011810302, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.26577401161194, "step": 28000}
{"episode_reward": 86.6164872415257, "episode": 29.0, "batch_reward": 0.13481286552548408, "critic_loss": 0.33169226357340814, "actor_loss": -27.298757860183716, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.97932267189026, "step": 29000}
{"episode_reward": 199.59466031365233, "episode": 30.0, "batch_reward": 0.13598773975670336, "critic_loss": 0.3651472405940294, "actor_loss": -26.73385263633728, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.67348074913025, "step": 30000}
{"episode_reward": 172.2862848881894, "episode": 31.0, "batch_reward": 0.13857719369232654, "critic_loss": 0.3557594292908907, "actor_loss": -26.996190896987915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.46444606781006, "step": 31000}
{"episode_reward": 333.3135007492175, "episode": 32.0, "batch_reward": 0.1430312442034483, "critic_loss": 0.40346926198899746, "actor_loss": -26.82431177043915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.687899351119995, "step": 32000}
{"episode_reward": 130.9257943129325, "episode": 33.0, "batch_reward": 0.14362525096535683, "critic_loss": 0.4245815521031618, "actor_loss": -27.332976402282714, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.537870407104492, "step": 33000}
{"episode_reward": 212.50832057791243, "episode": 34.0, "batch_reward": 0.1469614673703909, "critic_loss": 0.4794476642757654, "actor_loss": -26.825230620384215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.878740787506104, "step": 34000}
{"episode_reward": 339.9669824542666, "episode": 35.0, "batch_reward": 0.1523035472780466, "critic_loss": 0.46162799997627735, "actor_loss": -28.402861650466917, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.655456066131592, "step": 35000}
{"episode_reward": 344.5477270262808, "episode": 36.0, "batch_reward": 0.15640115094929932, "critic_loss": 0.49357841435074806, "actor_loss": -27.60480083656311, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.522709131240845, "step": 36000}
{"episode_reward": 328.35142524522405, "episode": 37.0, "batch_reward": 0.16070923006534577, "critic_loss": 0.5101500903218985, "actor_loss": -28.97310134601593, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.51632046699524, "step": 37000}
{"episode_reward": 195.61409617736385, "episode": 38.0, "batch_reward": 0.1637520017400384, "critic_loss": 0.5239873489737511, "actor_loss": -28.929101366043092, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.6646888256073, "step": 38000}
{"episode_reward": 421.7704187900856, "episode": 39.0, "batch_reward": 0.16945970071852207, "critic_loss": 0.5842735756784677, "actor_loss": -29.452709970474242, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.821332693099976, "step": 39000}
{"episode_reward": 229.07322980726073, "episode": 40.0, "batch_reward": 0.170868501663208, "critic_loss": 0.6153658532649279, "actor_loss": -29.536952095031737, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.02806067466736, "step": 40000}
{"episode_reward": 229.48485062679967, "episode": 41.0, "batch_reward": 0.17164974045753478, "critic_loss": 0.6236063880622387, "actor_loss": -29.38785041999817, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.5076048374176, "step": 41000}
{"episode_reward": 165.4222936945692, "episode": 42.0, "batch_reward": 0.17284301686286926, "critic_loss": 0.6418759758770466, "actor_loss": -28.48015005683899, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.614226579666138, "step": 42000}
{"episode_reward": 209.2718128865248, "episode": 43.0, "batch_reward": 0.1724890591651201, "critic_loss": 0.6449171491265296, "actor_loss": -28.453231441497802, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.82079815864563, "step": 43000}
{"episode_reward": 134.10172095540688, "episode": 44.0, "batch_reward": 0.17195496959984302, "critic_loss": 0.6134853344261646, "actor_loss": -28.10610960006714, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.894409656524658, "step": 44000}
{"episode_reward": 151.2798230305463, "episode": 45.0, "batch_reward": 0.17224797965586186, "critic_loss": 0.6234374402463436, "actor_loss": -28.17637335586548, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.317960262298584, "step": 45000}
{"episode_reward": 313.89478698988756, "episode": 46.0, "batch_reward": 0.17483922907710076, "critic_loss": 0.7504266994893551, "actor_loss": -28.49724949645996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.72697424888611, "step": 46000}
{"episode_reward": 274.5586168601461, "episode": 47.0, "batch_reward": 0.1759934285879135, "critic_loss": 0.7289199032783509, "actor_loss": -28.69576573944092, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.099869966506958, "step": 47000}
{"episode_reward": 91.24442552464228, "episode": 48.0, "batch_reward": 0.17442607894539833, "critic_loss": 0.6805964169502259, "actor_loss": -28.25383902168274, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.233636617660522, "step": 48000}
{"episode_reward": 147.31522995020723, "episode": 49.0, "batch_reward": 0.1753216851055622, "critic_loss": 0.6717152253985404, "actor_loss": -28.649557289123535, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.719116687774658, "step": 49000}
{"episode_reward": 353.76152380232327, "episode": 50.0, "batch_reward": 0.1771998814791441, "critic_loss": 0.7431323261857032, "actor_loss": -28.255688373565675, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.06547236442566, "step": 50000}
{"episode_reward": 171.08218432668562, "episode": 51.0, "batch_reward": 0.17814697647094727, "critic_loss": 0.6580889915823936, "actor_loss": -28.37236273765564, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.49811148643494, "step": 51000}
{"episode_reward": 161.1290126486029, "episode": 52.0, "batch_reward": 0.1790055712759495, "critic_loss": 0.6650481266528367, "actor_loss": -28.15755281829834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.1244900226593, "step": 52000}
{"episode_reward": 417.6226314868822, "episode": 53.0, "batch_reward": 0.1826748998761177, "critic_loss": 0.6862820754051209, "actor_loss": -28.836710102081298, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.022120714187622, "step": 53000}
{"episode_reward": 352.60767861867333, "episode": 54.0, "batch_reward": 0.18683516490459443, "critic_loss": 0.6543376416414977, "actor_loss": -28.82712182044983, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.08810806274414, "step": 54000}
{"episode_reward": 401.5008267590297, "episode": 55.0, "batch_reward": 0.19100542309880256, "critic_loss": 0.6561263244450092, "actor_loss": -29.861755081176756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.064402103424072, "step": 55000}
{"episode_reward": 362.9768654587527, "episode": 56.0, "batch_reward": 0.19208130632340908, "critic_loss": 0.6103579655587673, "actor_loss": -29.69951162147522, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.832706212997437, "step": 56000}
{"episode_reward": 319.6530367419652, "episode": 57.0, "batch_reward": 0.19663212157785892, "critic_loss": 0.6000260454118251, "actor_loss": -29.50939630317688, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.499828100204468, "step": 57000}
{"episode_reward": 402.59240037843716, "episode": 58.0, "batch_reward": 0.19993471370637417, "critic_loss": 0.6146320612430572, "actor_loss": -29.88865323829651, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.55841875076294, "step": 58000}
{"episode_reward": 448.22140136669816, "episode": 59.0, "batch_reward": 0.20418623879551887, "critic_loss": 0.6214438189268112, "actor_loss": -30.09203666305542, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.68707513809204, "step": 59000}
{"episode_reward": 417.7252321644082, "episode": 60.0, "batch_reward": 0.20654345263540744, "critic_loss": 0.6320568208396434, "actor_loss": -30.460386234283447, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.407198190689087, "step": 60000}
{"episode_reward": 272.592376400872, "episode": 61.0, "batch_reward": 0.2086384240090847, "critic_loss": 0.6247190418541432, "actor_loss": -30.358357137680052, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.76426959037781, "step": 61000}
{"episode_reward": 373.0647487756617, "episode": 62.0, "batch_reward": 0.21003490421175958, "critic_loss": 0.6269029708504676, "actor_loss": -31.137957376480102, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.869750261306763, "step": 62000}
{"episode_reward": 247.58749690808068, "episode": 63.0, "batch_reward": 0.21117303320765496, "critic_loss": 0.6217217145860195, "actor_loss": -30.734824438095092, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.070921421051025, "step": 63000}
{"episode_reward": 413.6493215884215, "episode": 64.0, "batch_reward": 0.21404302996397018, "critic_loss": 0.613546660721302, "actor_loss": -31.04757258224487, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.388273000717163, "step": 64000}
{"episode_reward": 407.5051365913144, "episode": 65.0, "batch_reward": 0.21753571325540544, "critic_loss": 0.6294350090920925, "actor_loss": -31.194345010757445, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.007861852645874, "step": 65000}
{"episode_reward": 459.5771993253363, "episode": 66.0, "batch_reward": 0.22273828853666783, "critic_loss": 0.5704434484839439, "actor_loss": -31.596781175613405, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.054292917251587, "step": 66000}
{"episode_reward": 417.44403045452265, "episode": 67.0, "batch_reward": 0.22488491736352445, "critic_loss": 0.5792342298924923, "actor_loss": -31.96817144012451, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.719188451766968, "step": 67000}
{"episode_reward": 465.22180409192816, "episode": 68.0, "batch_reward": 0.2278056201338768, "critic_loss": 0.5537606694400311, "actor_loss": -32.078265031814574, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.795175075531006, "step": 68000}
{"episode_reward": 355.8985070823222, "episode": 69.0, "batch_reward": 0.22942918932437897, "critic_loss": 0.5395737291872501, "actor_loss": -32.258643579483035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.866840362548828, "step": 69000}
{"episode_reward": 485.28993518087185, "episode": 70.0, "batch_reward": 0.2341589443385601, "critic_loss": 0.5639613119065762, "actor_loss": -32.716695356369016, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.2633798122406, "step": 70000}
{"episode_reward": 473.35367521083344, "episode": 71.0, "batch_reward": 0.2367289139777422, "critic_loss": 0.5675469749867916, "actor_loss": -33.05941086769104, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.22048997879028, "step": 71000}
{"episode_reward": 288.6366275776407, "episode": 72.0, "batch_reward": 0.23802074366807938, "critic_loss": 0.5359210475683213, "actor_loss": -33.18557836914062, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.240814924240112, "step": 72000}
{"episode_reward": 244.1699229637147, "episode": 73.0, "batch_reward": 0.23709719823300837, "critic_loss": 0.52172871530056, "actor_loss": -32.61051238822937, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.124592304229736, "step": 73000}
{"episode_reward": 271.1148607235156, "episode": 74.0, "batch_reward": 0.2380094421505928, "critic_loss": 0.5314050571471453, "actor_loss": -33.05409668159485, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.03697156906128, "step": 74000}
{"episode_reward": 376.0671113946079, "episode": 75.0, "batch_reward": 0.24077719789743424, "critic_loss": 0.5443236085474491, "actor_loss": -32.80195608329773, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.36099648475647, "step": 75000}
{"episode_reward": 473.233373023516, "episode": 76.0, "batch_reward": 0.2436697279959917, "critic_loss": 0.5808915665745735, "actor_loss": -33.1447873916626, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.164445400238037, "step": 76000}
{"episode_reward": 509.9645200269477, "episode": 77.0, "batch_reward": 0.24711723883450032, "critic_loss": 0.5222476575672627, "actor_loss": -33.0921425113678, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.06623601913452, "step": 77000}
{"episode_reward": 517.3584451585693, "episode": 78.0, "batch_reward": 0.25068329690396784, "critic_loss": 0.5543370070457458, "actor_loss": -33.69783703994751, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.667110919952393, "step": 78000}
{"episode_reward": 316.32450857371504, "episode": 79.0, "batch_reward": 0.2498431642651558, "critic_loss": 0.5441726053208112, "actor_loss": -32.695348247528074, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.64270806312561, "step": 79000}
{"episode_reward": 469.3155502108784, "episode": 80.0, "batch_reward": 0.2535329330712557, "critic_loss": 0.4920305355638266, "actor_loss": -33.590928409576414, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.808109283447266, "step": 80000}
{"episode_reward": 502.60988382406816, "episode": 81.0, "batch_reward": 0.25739173075556754, "critic_loss": 0.5290969395637513, "actor_loss": -33.716263450622556, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.922088623046875, "step": 81000}
{"episode_reward": 528.5885569956221, "episode": 82.0, "batch_reward": 0.26036011043190954, "critic_loss": 0.5167004568576813, "actor_loss": -34.76731238555908, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.04077672958374, "step": 82000}
{"episode_reward": 245.23794667282976, "episode": 83.0, "batch_reward": 0.2589669107496738, "critic_loss": 0.5684826981723309, "actor_loss": -33.74521158981323, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.503178596496582, "step": 83000}
{"episode_reward": 122.61695654022998, "episode": 84.0, "batch_reward": 0.25717467564344404, "critic_loss": 0.5379524586051703, "actor_loss": -34.58107004547119, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.954429864883423, "step": 84000}
{"episode_reward": 110.85945034470808, "episode": 85.0, "batch_reward": 0.25672360916435716, "critic_loss": 0.5569479154497385, "actor_loss": -33.85070936584473, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.112626552581787, "step": 85000}
{"episode_reward": 339.65906640387635, "episode": 86.0, "batch_reward": 0.2571952096223831, "critic_loss": 0.5943385821729898, "actor_loss": -33.726443870544436, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.989421367645264, "step": 86000}
{"episode_reward": 506.56485561814367, "episode": 87.0, "batch_reward": 0.2601103986799717, "critic_loss": 0.5802910384386778, "actor_loss": -33.97832459259033, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.13094711303711, "step": 87000}
{"episode_reward": 263.65523870965296, "episode": 88.0, "batch_reward": 0.2605731280297041, "critic_loss": 0.6264454004466533, "actor_loss": -33.48347277832031, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.974092960357666, "step": 88000}
{"episode_reward": 387.6914213896367, "episode": 89.0, "batch_reward": 0.2605912250578403, "critic_loss": 0.5905955407619476, "actor_loss": -34.04225375747681, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.82840847969055, "step": 89000}
{"episode_reward": 380.1920293127112, "episode": 90.0, "batch_reward": 0.2621558319032192, "critic_loss": 0.5644171261489391, "actor_loss": -34.38462398910522, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.2395658493042, "step": 90000}
{"episode_reward": 238.0492712715723, "episode": 91.0, "batch_reward": 0.26166597452759743, "critic_loss": 0.6591126781851053, "actor_loss": -33.93760210037232, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.77190017700195, "step": 91000}
{"episode_reward": 69.42356626697585, "episode": 92.0, "batch_reward": 0.26149330779910085, "critic_loss": 0.6342398941516876, "actor_loss": -33.73243664932251, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.135005712509155, "step": 92000}
{"episode_reward": 529.7132830327639, "episode": 93.0, "batch_reward": 0.2636822670251131, "critic_loss": 0.6389134885072708, "actor_loss": -33.7085857963562, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.342429637908936, "step": 93000}
{"episode_reward": 514.3172398192826, "episode": 94.0, "batch_reward": 0.2660930059701204, "critic_loss": 0.628822185575962, "actor_loss": -34.39270102310181, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.808851957321167, "step": 94000}
{"episode_reward": 496.672479973074, "episode": 95.0, "batch_reward": 0.2690004118233919, "critic_loss": 0.6287429369986057, "actor_loss": -34.63226483535767, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.53394889831543, "step": 95000}
{"episode_reward": 525.4391854775728, "episode": 96.0, "batch_reward": 0.27109461663663387, "critic_loss": 0.6173414181470871, "actor_loss": -34.89248575973511, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.74736785888672, "step": 96000}
{"episode_reward": 327.892005794643, "episode": 97.0, "batch_reward": 0.27217364166677, "critic_loss": 0.5642721390724182, "actor_loss": -35.107084991455075, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88308811187744, "step": 97000}
{"episode_reward": 515.2052404145124, "episode": 98.0, "batch_reward": 0.2754283801317215, "critic_loss": 0.5810657230019569, "actor_loss": -35.11718437576294, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.027493000030518, "step": 98000}
{"episode_reward": 537.4153460075271, "episode": 99.0, "batch_reward": 0.277554480060935, "critic_loss": 0.6158833375126124, "actor_loss": -34.83771807098389, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.915371656417847, "step": 99000}
{"episode_reward": 528.6617993201943, "episode": 100.0, "batch_reward": 0.2808178644031286, "critic_loss": 0.6008189462125302, "actor_loss": -35.28628090286255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.922239542007446, "step": 100000}
{"episode_reward": 391.9015838300085, "episode": 101.0, "batch_reward": 0.28139666773378846, "critic_loss": 0.6232400597631931, "actor_loss": -35.32872278594971, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.967267990112305, "step": 101000}
{"episode_reward": 583.8278561572844, "episode": 102.0, "batch_reward": 0.2838061658889055, "critic_loss": 0.5389559307098388, "actor_loss": -35.386191905975345, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87760090827942, "step": 102000}
{"episode_reward": 563.5927376025211, "episode": 103.0, "batch_reward": 0.2864816634207964, "critic_loss": 0.5280657303035259, "actor_loss": -36.10164661788941, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.24525785446167, "step": 103000}
{"episode_reward": 505.4211904984283, "episode": 104.0, "batch_reward": 0.28997549138963225, "critic_loss": 0.5560944868922234, "actor_loss": -36.223021438598636, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.150163412094116, "step": 104000}
{"episode_reward": 498.457419988581, "episode": 105.0, "batch_reward": 0.2911141026318073, "critic_loss": 0.5669552243798971, "actor_loss": -36.2927155418396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.010640621185303, "step": 105000}
{"episode_reward": 528.5012106918292, "episode": 106.0, "batch_reward": 0.29262207017838954, "critic_loss": 0.575054862588644, "actor_loss": -36.33074340438843, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.933135986328125, "step": 106000}
{"episode_reward": 464.29435758947733, "episode": 107.0, "batch_reward": 0.2950499311685562, "critic_loss": 0.5727864062786102, "actor_loss": -36.85540182876587, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.275129318237305, "step": 107000}
{"episode_reward": 492.86293998393603, "episode": 108.0, "batch_reward": 0.29730974590778353, "critic_loss": 0.5453709499239922, "actor_loss": -36.76743906021118, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.228542804718018, "step": 108000}
{"episode_reward": 530.7696303530437, "episode": 109.0, "batch_reward": 0.29881568913161755, "critic_loss": 0.5917712911665439, "actor_loss": -37.522774909973144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.00480318069458, "step": 109000}
{"episode_reward": 472.79786182039186, "episode": 110.0, "batch_reward": 0.30129878045618536, "critic_loss": 0.5926624126434327, "actor_loss": -37.37549681472778, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88409447669983, "step": 110000}
{"episode_reward": 542.4945451727094, "episode": 111.0, "batch_reward": 0.30236767418682575, "critic_loss": 0.5879826948344707, "actor_loss": -37.62600555419922, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.499396324157715, "step": 111000}
{"episode_reward": 526.9377793260413, "episode": 112.0, "batch_reward": 0.3042683535814285, "critic_loss": 0.5845030315071345, "actor_loss": -37.02687351226807, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.677767515182495, "step": 112000}
{"episode_reward": 509.2737987740309, "episode": 113.0, "batch_reward": 0.3072803971469402, "critic_loss": 0.5467641222774983, "actor_loss": -37.90432657623291, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.97598099708557, "step": 113000}
{"episode_reward": 528.2809682598777, "episode": 114.0, "batch_reward": 0.3084313682615757, "critic_loss": 0.5708125582486391, "actor_loss": -38.2647737121582, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.083616733551025, "step": 114000}
{"episode_reward": 554.5589239714897, "episode": 115.0, "batch_reward": 0.3110489445924759, "critic_loss": 0.5754814580380917, "actor_loss": -38.08873290252686, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.317424774169922, "step": 115000}
{"episode_reward": 540.9198309637713, "episode": 116.0, "batch_reward": 0.3120226958990097, "critic_loss": 0.543842348843813, "actor_loss": -38.08041072082519, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.15235161781311, "step": 116000}
{"episode_reward": 210.9978856560195, "episode": 117.0, "batch_reward": 0.31258293116092684, "critic_loss": 0.5306159347593784, "actor_loss": -37.949833572387696, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.943780183792114, "step": 117000}
{"episode_reward": 559.4358824911718, "episode": 118.0, "batch_reward": 0.3141282918155193, "critic_loss": 0.5955057992786169, "actor_loss": -38.308245712280275, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.04652690887451, "step": 118000}
{"episode_reward": 529.497188326227, "episode": 119.0, "batch_reward": 0.3160543424785137, "critic_loss": 0.5194858081489802, "actor_loss": -38.687406944274905, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.240195512771606, "step": 119000}
{"episode_reward": 547.9724078867358, "episode": 120.0, "batch_reward": 0.31678173220157624, "critic_loss": 0.5279006272703409, "actor_loss": -38.473043678283695, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.842790365219116, "step": 120000}
{"episode_reward": 496.88598019119587, "episode": 121.0, "batch_reward": 0.32070859694480897, "critic_loss": 0.5123204186558723, "actor_loss": -38.41903560638428, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.50989627838135, "step": 121000}
{"episode_reward": 506.8084535445995, "episode": 122.0, "batch_reward": 0.32013083216547966, "critic_loss": 0.4928448657542467, "actor_loss": -38.60582985687256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.948503971099854, "step": 122000}
{"episode_reward": 521.3045849243039, "episode": 123.0, "batch_reward": 0.32388780869543554, "critic_loss": 0.5009686272144318, "actor_loss": -38.49036162567138, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.36139678955078, "step": 123000}
{"episode_reward": 523.2745215408202, "episode": 124.0, "batch_reward": 0.3239892880320549, "critic_loss": 0.5090827242285013, "actor_loss": -38.952231719970705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.260582447052002, "step": 124000}
{"episode_reward": 517.6459079286274, "episode": 125.0, "batch_reward": 0.3252772082388401, "critic_loss": 0.46646762500703337, "actor_loss": -38.92929012680054, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.04664897918701, "step": 125000}
{"episode_reward": 525.6184209015487, "episode": 126.0, "batch_reward": 0.32676694494485853, "critic_loss": 0.4693847184628248, "actor_loss": -38.70355633926392, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.916132926940918, "step": 126000}
{"episode_reward": 546.2184424552589, "episode": 127.0, "batch_reward": 0.32879700225591657, "critic_loss": 0.4899144273847342, "actor_loss": -39.539460998535155, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97318983078003, "step": 127000}
{"episode_reward": 551.6866443527341, "episode": 128.0, "batch_reward": 0.3305019209086895, "critic_loss": 0.4803138955682516, "actor_loss": -40.167300338745115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.10299777984619, "step": 128000}
{"episode_reward": 551.3073513429018, "episode": 129.0, "batch_reward": 0.33259274712204934, "critic_loss": 0.5262916462123394, "actor_loss": -39.930065509796144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07659649848938, "step": 129000}
{"episode_reward": 557.0271663955367, "episode": 130.0, "batch_reward": 0.3337640078365803, "critic_loss": 0.4824035317897797, "actor_loss": -40.00291148376465, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.633983612060547, "step": 130000}
{"episode_reward": 548.251542291307, "episode": 131.0, "batch_reward": 0.33619656202197074, "critic_loss": 0.47209107857942584, "actor_loss": -40.487697834014895, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.53056979179382, "step": 131000}
{"episode_reward": 542.8329112194202, "episode": 132.0, "batch_reward": 0.33814118105173113, "critic_loss": 0.5040175993144512, "actor_loss": -40.46626162338257, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.224881172180176, "step": 132000}
{"episode_reward": 546.5138022244786, "episode": 133.0, "batch_reward": 0.3386674419939518, "critic_loss": 0.5103089605271817, "actor_loss": -40.493732971191406, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.801931381225586, "step": 133000}
{"episode_reward": 500.1752427289767, "episode": 134.0, "batch_reward": 0.34011898988485334, "critic_loss": 0.5249547222852707, "actor_loss": -40.82337285232544, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.068230152130127, "step": 134000}
{"episode_reward": 567.1274425625439, "episode": 135.0, "batch_reward": 0.34122265249490735, "critic_loss": 0.5317267956882715, "actor_loss": -40.807741065979, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.147491693496704, "step": 135000}
{"episode_reward": 541.5904133440407, "episode": 136.0, "batch_reward": 0.34351099172234534, "critic_loss": 0.49752063186466694, "actor_loss": -41.43738884735107, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.898056030273438, "step": 136000}
{"episode_reward": 555.6199479290393, "episode": 137.0, "batch_reward": 0.3447478304207325, "critic_loss": 0.5203504511415958, "actor_loss": -41.157460796356204, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.901618242263794, "step": 137000}
{"episode_reward": 568.2280025752585, "episode": 138.0, "batch_reward": 0.3471960382461548, "critic_loss": 0.49562438581883905, "actor_loss": -40.5921711769104, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.122607707977295, "step": 138000}
{"episode_reward": 546.8573630866028, "episode": 139.0, "batch_reward": 0.34783096706867217, "critic_loss": 0.47136232382059096, "actor_loss": -40.922746761322024, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88700580596924, "step": 139000}
{"episode_reward": 523.670765006449, "episode": 140.0, "batch_reward": 0.3483311230540276, "critic_loss": 0.4771257993131876, "actor_loss": -40.806837047576906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.662022829055786, "step": 140000}
{"episode_reward": 557.4103297939712, "episode": 141.0, "batch_reward": 0.35081823375821114, "critic_loss": 0.48887799502909185, "actor_loss": -41.091081493377686, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.98638391494751, "step": 141000}
{"episode_reward": 564.6478626947346, "episode": 142.0, "batch_reward": 0.35155058300495146, "critic_loss": 0.48354190692305565, "actor_loss": -41.337272441864016, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89348030090332, "step": 142000}
{"episode_reward": 572.9656632747873, "episode": 143.0, "batch_reward": 0.35419908827543256, "critic_loss": 0.5140080102980137, "actor_loss": -41.713650619506836, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.029890775680542, "step": 143000}
{"episode_reward": 419.2636583685934, "episode": 144.0, "batch_reward": 0.35363158252835275, "critic_loss": 0.513579072996974, "actor_loss": -41.7691343460083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.842614889144897, "step": 144000}
{"episode_reward": 542.5805754345342, "episode": 145.0, "batch_reward": 0.35614471128582953, "critic_loss": 0.4893826092928648, "actor_loss": -41.714633724212646, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.462812185287476, "step": 145000}
{"episode_reward": 564.4799902192901, "episode": 146.0, "batch_reward": 0.35576486569643023, "critic_loss": 0.4751355079114437, "actor_loss": -41.76248721313477, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.165162801742554, "step": 146000}
{"episode_reward": 494.92048396869154, "episode": 147.0, "batch_reward": 0.35723850286006925, "critic_loss": 0.5145544276833535, "actor_loss": -42.2977558631897, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.70675539970398, "step": 147000}
{"episode_reward": 546.9549650584385, "episode": 148.0, "batch_reward": 0.35971534380316733, "critic_loss": 0.5345242386013269, "actor_loss": -42.07614559936523, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.601680040359497, "step": 148000}
{"episode_reward": 581.1904495321387, "episode": 149.0, "batch_reward": 0.3611377464532852, "critic_loss": 0.5100517130494118, "actor_loss": -42.34961904525757, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.8524968624115, "step": 149000}
{"episode_reward": 581.4973074913522, "episode": 150.0, "batch_reward": 0.3629725684821606, "critic_loss": 0.574302129521966, "actor_loss": -42.10351708984375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
