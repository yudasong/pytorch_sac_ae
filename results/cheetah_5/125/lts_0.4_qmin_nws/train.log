{"episode_reward": 0.0, "episode": 1.0, "duration": 19.900158166885376, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.5535473823547363, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.28225579957697305, "critic_loss": 0.03341314734418409, "actor_loss": -19.866273165546303, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 68.34870862960815, "step": 3000}
{"episode_reward": 32.3035403680258, "episode": 4.0, "batch_reward": 0.19150350098311902, "critic_loss": 0.04359234486706555, "actor_loss": -13.53361771813035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.318101406097412, "step": 4000}
{"episode_reward": 50.088401724957386, "episode": 5.0, "batch_reward": 0.1521979416012764, "critic_loss": 0.03774157178215683, "actor_loss": -9.847073204115032, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.91901993751526, "step": 5000}
{"episode_reward": 23.657651449439136, "episode": 6.0, "batch_reward": 0.13198073209077119, "critic_loss": 0.03501518626324832, "actor_loss": -11.57685731653869, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.482787609100342, "step": 6000}
{"episode_reward": 51.66200180764996, "episode": 7.0, "batch_reward": 0.11832928153872489, "critic_loss": 0.040189039589837196, "actor_loss": -12.471851756244899, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.184001445770264, "step": 7000}
{"episode_reward": 45.02490051674299, "episode": 8.0, "batch_reward": 0.10936272987350822, "critic_loss": 0.043085041938349604, "actor_loss": -12.25493497262895, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.42702293395996, "step": 8000}
{"episode_reward": 54.2529691180798, "episode": 9.0, "batch_reward": 0.10375469570234418, "critic_loss": 0.05148890485800803, "actor_loss": -13.981578580379486, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.093213081359863, "step": 9000}
{"episode_reward": 61.790967919923354, "episode": 10.0, "batch_reward": 0.10202379548549652, "critic_loss": 0.06096947408095002, "actor_loss": -13.305107175171376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.11228370666504, "step": 10000}
{"episode_reward": 110.00347718868707, "episode": 11.0, "batch_reward": 0.10157868771627546, "critic_loss": 0.07993367526680231, "actor_loss": -13.424244530379772, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.191405296325684, "step": 11000}
{"episode_reward": 47.60887861895786, "episode": 12.0, "batch_reward": 0.09702250622957945, "critic_loss": 0.08761428759247064, "actor_loss": -13.113678375959397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.317981958389282, "step": 12000}
{"episode_reward": 55.59514161129717, "episode": 13.0, "batch_reward": 0.0952749783694744, "critic_loss": 0.09436594719812275, "actor_loss": -13.333157108306885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54238200187683, "step": 13000}
{"episode_reward": 124.51013387456783, "episode": 14.0, "batch_reward": 0.09927076422795654, "critic_loss": 0.12152476199716329, "actor_loss": -12.7080140376091, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.526320934295654, "step": 14000}
{"episode_reward": 178.45044578614463, "episode": 15.0, "batch_reward": 0.1023868917003274, "critic_loss": 0.12336315407603979, "actor_loss": -14.864173495769501, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.772571563720703, "step": 15000}
{"episode_reward": 71.0215749163799, "episode": 16.0, "batch_reward": 0.1005231132619083, "critic_loss": 0.14291876880079507, "actor_loss": -15.029831758022308, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.452603101730347, "step": 16000}
{"episode_reward": 146.56850390208672, "episode": 17.0, "batch_reward": 0.10518179458379745, "critic_loss": 0.15251863765716553, "actor_loss": -14.500804937839508, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.978262186050415, "step": 17000}
{"episode_reward": 121.51251662852744, "episode": 18.0, "batch_reward": 0.10247119177877903, "critic_loss": 0.17034135869890452, "actor_loss": -14.67296329975128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.72766351699829, "step": 18000}
{"episode_reward": 27.122145257465313, "episode": 19.0, "batch_reward": 0.10113152018189431, "critic_loss": 0.20863582661002875, "actor_loss": -15.7713955783844, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.12637948989868, "step": 19000}
{"episode_reward": 101.09045043754158, "episode": 20.0, "batch_reward": 0.10116130960732699, "critic_loss": 0.183171756491065, "actor_loss": -16.13263773345947, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.646313667297363, "step": 20000}
{"episode_reward": 121.98569363544864, "episode": 21.0, "batch_reward": 0.10128363907337189, "critic_loss": 0.1660109766870737, "actor_loss": -16.213733107566835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.98607563972473, "step": 21000}
{"episode_reward": 56.23690567030011, "episode": 22.0, "batch_reward": 0.0970561634376645, "critic_loss": 0.12641326007246972, "actor_loss": -15.823627695083617, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.000850200653076, "step": 22000}
{"episode_reward": 19.979896393916672, "episode": 23.0, "batch_reward": 0.09467171915248036, "critic_loss": 0.12116892320290208, "actor_loss": -15.068772238731384, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.328927993774414, "step": 23000}
{"episode_reward": 35.114936221742695, "episode": 24.0, "batch_reward": 0.09419888067990541, "critic_loss": 0.1416145815588534, "actor_loss": -15.512125220298767, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.18067455291748, "step": 24000}
{"episode_reward": 107.87996033310453, "episode": 25.0, "batch_reward": 0.09477966424450278, "critic_loss": 0.146776170194149, "actor_loss": -14.887083602905273, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.69339156150818, "step": 25000}
{"episode_reward": 226.10663906775983, "episode": 26.0, "batch_reward": 0.10004022201895714, "critic_loss": 0.17795211692899465, "actor_loss": -15.690186723709106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.1950101852417, "step": 26000}
{"episode_reward": 149.71934396378114, "episode": 27.0, "batch_reward": 0.10076488839834928, "critic_loss": 0.16858865551650523, "actor_loss": -15.710726243972779, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.025065422058105, "step": 27000}
{"episode_reward": 61.13174494364937, "episode": 28.0, "batch_reward": 0.10238667124509812, "critic_loss": 0.20886325901001693, "actor_loss": -15.633706844329835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.236469507217407, "step": 28000}
{"episode_reward": 293.88864063760906, "episode": 29.0, "batch_reward": 0.10641036459058523, "critic_loss": 0.200211963750422, "actor_loss": -16.399248306274416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.44717574119568, "step": 29000}
{"episode_reward": 54.71242922064547, "episode": 30.0, "batch_reward": 0.1064440122693777, "critic_loss": 0.21658036252856255, "actor_loss": -16.303515397071838, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.743842601776123, "step": 30000}
{"episode_reward": 272.34917249666466, "episode": 31.0, "batch_reward": 0.11163623598963023, "critic_loss": 0.2330332518145442, "actor_loss": -16.77169873046875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.75592398643494, "step": 31000}
{"episode_reward": 145.7865106516752, "episode": 32.0, "batch_reward": 0.11243714024871587, "critic_loss": 0.24425102992355824, "actor_loss": -17.757217079162597, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.904683113098145, "step": 32000}
{"episode_reward": 185.56076754173077, "episode": 33.0, "batch_reward": 0.11536763349920512, "critic_loss": 0.26035667621344327, "actor_loss": -17.858652696609497, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.23379898071289, "step": 33000}
{"episode_reward": 207.46716890717326, "episode": 34.0, "batch_reward": 0.1175980247631669, "critic_loss": 0.2691511973142624, "actor_loss": -16.97026302909851, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.458978176116943, "step": 34000}
{"episode_reward": 192.47265109442228, "episode": 35.0, "batch_reward": 0.1200175752416253, "critic_loss": 0.3097039355933666, "actor_loss": -18.159546480178832, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.58804750442505, "step": 35000}
{"episode_reward": 139.16829083858843, "episode": 36.0, "batch_reward": 0.1196582024767995, "critic_loss": 0.3087843244969845, "actor_loss": -18.034226922988893, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.71799659729004, "step": 36000}
{"episode_reward": 237.6745174842018, "episode": 37.0, "batch_reward": 0.12358161449432373, "critic_loss": 0.3134098784476519, "actor_loss": -18.32434250640869, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.360239505767822, "step": 37000}
{"episode_reward": 150.17092234939048, "episode": 38.0, "batch_reward": 0.12457230526208878, "critic_loss": 0.3327875893712044, "actor_loss": -18.54037829589844, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.253759384155273, "step": 38000}
{"episode_reward": 232.56015749163348, "episode": 39.0, "batch_reward": 0.12738165063410997, "critic_loss": 0.33358988946676255, "actor_loss": -19.641895517349244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.873559713363647, "step": 39000}
{"episode_reward": 175.55862143365596, "episode": 40.0, "batch_reward": 0.1281961603537202, "critic_loss": 0.35907620407640933, "actor_loss": -19.18082776260376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.31255054473877, "step": 40000}
{"episode_reward": 130.51179137935495, "episode": 41.0, "batch_reward": 0.12954086865484715, "critic_loss": 0.3690907552987337, "actor_loss": -19.47968589782715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.35307478904724, "step": 41000}
{"episode_reward": 300.44033319389547, "episode": 42.0, "batch_reward": 0.1335103279426694, "critic_loss": 0.4612771786302328, "actor_loss": -19.876370334625243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.721412658691406, "step": 42000}
{"episode_reward": 333.2969371469592, "episode": 43.0, "batch_reward": 0.1378087332472205, "critic_loss": 0.4734604886472225, "actor_loss": -20.43438874053955, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.79667854309082, "step": 43000}
{"episode_reward": 210.69102996462323, "episode": 44.0, "batch_reward": 0.13800624921172858, "critic_loss": 0.43788376174867155, "actor_loss": -20.184833618164063, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.536938190460205, "step": 44000}
{"episode_reward": 71.84561519937574, "episode": 45.0, "batch_reward": 0.1382221068441868, "critic_loss": 0.4867745113670826, "actor_loss": -21.081193412780763, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.193422079086304, "step": 45000}
{"episode_reward": 338.70940185578206, "episode": 46.0, "batch_reward": 0.1417355926632881, "critic_loss": 0.5063997548669577, "actor_loss": -21.315494842529297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.054692029953003, "step": 46000}
{"episode_reward": 154.4362078763163, "episode": 47.0, "batch_reward": 0.14365396066009997, "critic_loss": 0.4765063240677118, "actor_loss": -21.196760467529298, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.958343505859375, "step": 47000}
{"episode_reward": 252.6993569279137, "episode": 48.0, "batch_reward": 0.14401178578287363, "critic_loss": 0.5010476511567831, "actor_loss": -21.274796882629396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.447741985321045, "step": 48000}
{"episode_reward": 117.10948008519276, "episode": 49.0, "batch_reward": 0.14592759758234025, "critic_loss": 0.5067248203158379, "actor_loss": -21.676691190719605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.930830001831055, "step": 49000}
{"episode_reward": 408.32497456305737, "episode": 50.0, "batch_reward": 0.14751138063520194, "critic_loss": 0.5446521142125129, "actor_loss": -21.741332887649538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.268725872039795, "step": 50000}
{"episode_reward": 89.72860334492476, "episode": 51.0, "batch_reward": 0.1482112416177988, "critic_loss": 0.5084251760542393, "actor_loss": -21.703080591201783, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.09968280792236, "step": 51000}
{"episode_reward": 288.372237811663, "episode": 52.0, "batch_reward": 0.1508104546815157, "critic_loss": 0.5230327264815569, "actor_loss": -22.35218357658386, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.188143730163574, "step": 52000}
{"episode_reward": 225.13969265983164, "episode": 53.0, "batch_reward": 0.15377232374250888, "critic_loss": 0.5144475591480732, "actor_loss": -22.59249070930481, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.552725315093994, "step": 53000}
{"episode_reward": 344.9913406995105, "episode": 54.0, "batch_reward": 0.15695381446182727, "critic_loss": 0.5420316977500915, "actor_loss": -22.789595666885376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.09955906867981, "step": 54000}
{"episode_reward": 389.17727727001096, "episode": 55.0, "batch_reward": 0.15843002934008837, "critic_loss": 0.543197236508131, "actor_loss": -22.521947563171388, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.58160424232483, "step": 55000}
{"episode_reward": 19.57698229421747, "episode": 56.0, "batch_reward": 0.1589204011335969, "critic_loss": 0.5468400101959705, "actor_loss": -23.03212958908081, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.593294382095337, "step": 56000}
{"episode_reward": 436.08817332124386, "episode": 57.0, "batch_reward": 0.16368119283020496, "critic_loss": 0.5491543176323176, "actor_loss": -23.484300523757934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.445521354675293, "step": 57000}
{"episode_reward": 305.75591375668705, "episode": 58.0, "batch_reward": 0.16665023697912693, "critic_loss": 0.5278848341703415, "actor_loss": -23.33895411300659, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.390815258026123, "step": 58000}
{"episode_reward": 322.2889050104027, "episode": 59.0, "batch_reward": 0.1688536251336336, "critic_loss": 0.5265237325876951, "actor_loss": -24.083257751464842, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.207393884658813, "step": 59000}
{"episode_reward": 386.6832757506361, "episode": 60.0, "batch_reward": 0.17242895394563676, "critic_loss": 0.5694206770956516, "actor_loss": -24.70328328704834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.1833176612854, "step": 60000}
{"episode_reward": 340.2840369788504, "episode": 61.0, "batch_reward": 0.17519512189924716, "critic_loss": 0.5816711954474449, "actor_loss": -24.711300434112548, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.019182443618774, "step": 61000}
{"episode_reward": 259.8938502537537, "episode": 62.0, "batch_reward": 0.17567763970047234, "critic_loss": 0.5529707508832217, "actor_loss": -24.58839097213745, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.242841005325317, "step": 62000}
{"episode_reward": 167.6803447345383, "episode": 63.0, "batch_reward": 0.174221573010087, "critic_loss": 0.574878065764904, "actor_loss": -24.520869853973387, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.343966722488403, "step": 63000}
{"episode_reward": 89.4721381215059, "episode": 64.0, "batch_reward": 0.17511867874860765, "critic_loss": 0.569501456528902, "actor_loss": -24.53990838241577, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3476459980011, "step": 64000}
{"episode_reward": 345.28391476283923, "episode": 65.0, "batch_reward": 0.17808309698104857, "critic_loss": 0.5741620171368123, "actor_loss": -25.029938396453858, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.13873291015625, "step": 65000}
{"episode_reward": 367.5592532736258, "episode": 66.0, "batch_reward": 0.17972460633516313, "critic_loss": 0.6203346298933029, "actor_loss": -25.160176357269286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.83873748779297, "step": 66000}
{"episode_reward": 110.3511077559985, "episode": 67.0, "batch_reward": 0.17916510280966758, "critic_loss": 0.5951994234770537, "actor_loss": -25.27815831375122, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.123196601867676, "step": 67000}
{"episode_reward": 251.3174419267645, "episode": 68.0, "batch_reward": 0.180548218652606, "critic_loss": 0.6230393686890602, "actor_loss": -24.78197594833374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.851781845092773, "step": 68000}
{"episode_reward": 383.59583774752826, "episode": 69.0, "batch_reward": 0.18199441294372082, "critic_loss": 0.6173991438746452, "actor_loss": -25.26793159866333, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.86055088043213, "step": 69000}
{"episode_reward": 95.12611821660039, "episode": 70.0, "batch_reward": 0.182549433991313, "critic_loss": 0.6782485674917698, "actor_loss": -25.474909252166746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.543299436569214, "step": 70000}
{"episode_reward": 396.63421053938134, "episode": 71.0, "batch_reward": 0.1848232997506857, "critic_loss": 0.622440297037363, "actor_loss": -25.30057681274414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.74845027923584, "step": 71000}
{"episode_reward": 154.55693652414374, "episode": 72.0, "batch_reward": 0.18459172423183917, "critic_loss": 0.6078558384031058, "actor_loss": -25.400171405792236, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.638847827911377, "step": 72000}
{"episode_reward": 354.03189853699376, "episode": 73.0, "batch_reward": 0.18719985465705394, "critic_loss": 0.5913422348797321, "actor_loss": -25.674454959869387, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.55245304107666, "step": 73000}
{"episode_reward": 351.18581434058063, "episode": 74.0, "batch_reward": 0.18795510390400885, "critic_loss": 0.5520173026919365, "actor_loss": -25.881055389404295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.696967840194702, "step": 74000}
{"episode_reward": 116.4673978943393, "episode": 75.0, "batch_reward": 0.1869078403264284, "critic_loss": 0.6088234085291624, "actor_loss": -25.635931812286376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.337308406829834, "step": 75000}
{"episode_reward": 91.31971926640566, "episode": 76.0, "batch_reward": 0.18698701877892018, "critic_loss": 0.7057436568439007, "actor_loss": -25.661295265197754, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.151414155960083, "step": 76000}
{"episode_reward": 399.35318070293636, "episode": 77.0, "batch_reward": 0.18772568601369857, "critic_loss": 0.7791169609427452, "actor_loss": -26.32484483718872, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.903815507888794, "step": 77000}
{"episode_reward": 17.58387527019846, "episode": 78.0, "batch_reward": 0.18598040169477462, "critic_loss": 0.6222855416238308, "actor_loss": -26.47435715866089, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.978100776672363, "step": 78000}
{"episode_reward": 29.04129012857123, "episode": 79.0, "batch_reward": 0.1832692098915577, "critic_loss": 0.5234447223544121, "actor_loss": -26.317500160217286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.439619302749634, "step": 79000}
{"episode_reward": 28.905087021291536, "episode": 80.0, "batch_reward": 0.18153635548055172, "critic_loss": 0.4856216218024492, "actor_loss": -26.372368701934814, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.997108697891235, "step": 80000}
{"episode_reward": 38.975128800611415, "episode": 81.0, "batch_reward": 0.1820984223484993, "critic_loss": 0.46685001462697984, "actor_loss": -26.591426692962646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.057660818099976, "step": 81000}
{"episode_reward": 416.05003938765213, "episode": 82.0, "batch_reward": 0.18453444890677928, "critic_loss": 0.4505095820426941, "actor_loss": -26.79392808151245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.083100080490112, "step": 82000}
{"episode_reward": 487.29022222642936, "episode": 83.0, "batch_reward": 0.18845738810300827, "critic_loss": 0.4560935609340668, "actor_loss": -26.81075570678711, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.64671516418457, "step": 83000}
{"episode_reward": 430.56489012599684, "episode": 84.0, "batch_reward": 0.1918063753992319, "critic_loss": 0.4818541700839996, "actor_loss": -26.92469550704956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.303617000579834, "step": 84000}
{"episode_reward": 330.6606799703913, "episode": 85.0, "batch_reward": 0.1922786326408386, "critic_loss": 0.525022538036108, "actor_loss": -26.75133401107788, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.11053228378296, "step": 85000}
{"episode_reward": 288.7606232649659, "episode": 86.0, "batch_reward": 0.19416845501959323, "critic_loss": 0.5264371461272239, "actor_loss": -26.515852172851563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.731905460357666, "step": 86000}
{"episode_reward": 410.9191345529829, "episode": 87.0, "batch_reward": 0.19636006151139737, "critic_loss": 0.552538082525134, "actor_loss": -26.362495723724365, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.743824243545532, "step": 87000}
{"episode_reward": 475.32846226341206, "episode": 88.0, "batch_reward": 0.2009506687670946, "critic_loss": 0.5050138300657272, "actor_loss": -26.460734539031982, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.465516567230225, "step": 88000}
{"episode_reward": 451.85386917457674, "episode": 89.0, "batch_reward": 0.20050175781548024, "critic_loss": 0.5136806312948465, "actor_loss": -26.554038261413574, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.70949387550354, "step": 89000}
{"episode_reward": 103.82507424749674, "episode": 90.0, "batch_reward": 0.20236764121055603, "critic_loss": 0.5028913108557462, "actor_loss": -26.952392593383788, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.82307744026184, "step": 90000}
{"episode_reward": 491.31909686472545, "episode": 91.0, "batch_reward": 0.2054858224093914, "critic_loss": 0.48964377234876155, "actor_loss": -26.800300827026366, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.40538167953491, "step": 91000}
{"episode_reward": 486.7284823150211, "episode": 92.0, "batch_reward": 0.20877590039372443, "critic_loss": 0.46527424444258214, "actor_loss": -27.375002407073975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.795933961868286, "step": 92000}
{"episode_reward": 525.5443724229231, "episode": 93.0, "batch_reward": 0.21152448646724223, "critic_loss": 0.46763045896589756, "actor_loss": -27.14606559371948, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.100248098373413, "step": 93000}
{"episode_reward": 546.4684509240938, "episode": 94.0, "batch_reward": 0.21567126253247262, "critic_loss": 0.4708868573009968, "actor_loss": -27.738651008605956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.356511116027832, "step": 94000}
{"episode_reward": 551.3080962856299, "episode": 95.0, "batch_reward": 0.21910396052896977, "critic_loss": 0.4799905522018671, "actor_loss": -28.185628875732423, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.94313621520996, "step": 95000}
{"episode_reward": 518.0258170507603, "episode": 96.0, "batch_reward": 0.22231918741762638, "critic_loss": 0.4530792386084795, "actor_loss": -28.228980087280274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.52652072906494, "step": 96000}
{"episode_reward": 516.6963256329183, "episode": 97.0, "batch_reward": 0.22600478807091712, "critic_loss": 0.4439754187762737, "actor_loss": -28.659180072784423, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.615221738815308, "step": 97000}
{"episode_reward": 516.3309817242737, "episode": 98.0, "batch_reward": 0.22843400882184506, "critic_loss": 0.42384434631466866, "actor_loss": -28.751531734466553, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.83212661743164, "step": 98000}
{"episode_reward": 244.1524039640701, "episode": 99.0, "batch_reward": 0.22835943710803985, "critic_loss": 0.42138486155867577, "actor_loss": -28.644707286834716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.678239583969116, "step": 99000}
{"episode_reward": 540.722098942289, "episode": 100.0, "batch_reward": 0.2313341472148895, "critic_loss": 0.45392452338337896, "actor_loss": -28.63104066848755, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.957037448883057, "step": 100000}
{"episode_reward": 266.69049227120036, "episode": 101.0, "batch_reward": 0.23098972828686237, "critic_loss": 0.45062590289115906, "actor_loss": -29.018737255096436, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.71269249916077, "step": 101000}
{"episode_reward": 535.9088856428504, "episode": 102.0, "batch_reward": 0.2332414395213127, "critic_loss": 0.462465047031641, "actor_loss": -29.161941040039064, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.835838794708252, "step": 102000}
{"episode_reward": 284.25706820277964, "episode": 103.0, "batch_reward": 0.2341193381845951, "critic_loss": 0.47898988845944407, "actor_loss": -29.169467765808104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.063354015350342, "step": 103000}
{"episode_reward": 137.54138048211612, "episode": 104.0, "batch_reward": 0.23541123096644878, "critic_loss": 0.4680520681589842, "actor_loss": -29.123012535095214, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.064159631729126, "step": 104000}
{"episode_reward": 556.7245126493935, "episode": 105.0, "batch_reward": 0.2377828893959522, "critic_loss": 0.4589976715147495, "actor_loss": -29.004368976593017, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.011910676956177, "step": 105000}
{"episode_reward": 430.01301748272476, "episode": 106.0, "batch_reward": 0.239563368588686, "critic_loss": 0.4841737246662378, "actor_loss": -29.052112033843994, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.80788016319275, "step": 106000}
{"episode_reward": 551.9203830436876, "episode": 107.0, "batch_reward": 0.24239213886857033, "critic_loss": 0.46489207631349566, "actor_loss": -29.714060611724854, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.340932846069336, "step": 107000}
{"episode_reward": 565.3810051832947, "episode": 108.0, "batch_reward": 0.2454451998770237, "critic_loss": 0.4591811773777008, "actor_loss": -30.182266792297362, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.596257209777832, "step": 108000}
{"episode_reward": 564.9350014703219, "episode": 109.0, "batch_reward": 0.2487958336174488, "critic_loss": 0.414257339656353, "actor_loss": -30.291616680145264, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.092862606048584, "step": 109000}
{"episode_reward": 597.1696252222931, "episode": 110.0, "batch_reward": 0.2502620989382267, "critic_loss": 0.4257447044700384, "actor_loss": -30.541613971710206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.853080987930298, "step": 110000}
{"episode_reward": 196.84271976143464, "episode": 111.0, "batch_reward": 0.25044678536057474, "critic_loss": 0.42917473962903024, "actor_loss": -30.394510707855225, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.636330366134644, "step": 111000}
{"episode_reward": 567.201374267946, "episode": 112.0, "batch_reward": 0.2544474499076605, "critic_loss": 0.3839812702536583, "actor_loss": -30.551336589813232, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.627281188964844, "step": 112000}
{"episode_reward": 551.2837378528046, "episode": 113.0, "batch_reward": 0.25659302148222923, "critic_loss": 0.4194414947926998, "actor_loss": -30.83587056350708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.429856777191162, "step": 113000}
{"episode_reward": 585.914619589489, "episode": 114.0, "batch_reward": 0.2593357626348734, "critic_loss": 0.4441556029766798, "actor_loss": -31.488015712738036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.97201919555664, "step": 114000}
{"episode_reward": 555.5081291459868, "episode": 115.0, "batch_reward": 0.26155691558122635, "critic_loss": 0.3908437653034925, "actor_loss": -31.356794673919676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.36199164390564, "step": 115000}
{"episode_reward": 531.995209153958, "episode": 116.0, "batch_reward": 0.2646126433163881, "critic_loss": 0.37571875590085985, "actor_loss": -31.882431324005125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.548235177993774, "step": 116000}
{"episode_reward": 559.6330915995294, "episode": 117.0, "batch_reward": 0.2672659428119659, "critic_loss": 0.3743752289414406, "actor_loss": -31.826405616760255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.991665840148926, "step": 117000}
{"episode_reward": 552.4943159993071, "episode": 118.0, "batch_reward": 0.26826884303987025, "critic_loss": 0.3908944561183453, "actor_loss": -32.123234718322756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.701683282852173, "step": 118000}
{"episode_reward": 225.4525036024602, "episode": 119.0, "batch_reward": 0.2699528973698616, "critic_loss": 0.38544552080333233, "actor_loss": -32.05398342895508, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.944358825683594, "step": 119000}
{"episode_reward": 537.4438899628028, "episode": 120.0, "batch_reward": 0.2707877913415432, "critic_loss": 0.3848278844505548, "actor_loss": -31.76459275817871, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.89409565925598, "step": 120000}
{"episode_reward": 510.44479560593527, "episode": 121.0, "batch_reward": 0.27441939125955106, "critic_loss": 0.3837776117920876, "actor_loss": -32.15362360000611, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.236955404281616, "step": 121000}
{"episode_reward": 558.3951782545963, "episode": 122.0, "batch_reward": 0.27613484194874766, "critic_loss": 0.41278398835659025, "actor_loss": -32.48004998779297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.06573748588562, "step": 122000}
{"episode_reward": 585.0058234513516, "episode": 123.0, "batch_reward": 0.27813897536695004, "critic_loss": 0.4006603530943394, "actor_loss": -32.410848030090335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.6695556640625, "step": 123000}
{"episode_reward": 441.08480650694923, "episode": 124.0, "batch_reward": 0.2788374090343714, "critic_loss": 0.3738939546644688, "actor_loss": -32.69211809539795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54533815383911, "step": 124000}
{"episode_reward": 593.2233669233312, "episode": 125.0, "batch_reward": 0.2822642955929041, "critic_loss": 0.3654066927433014, "actor_loss": -32.82783796310425, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.47109293937683, "step": 125000}
{"episode_reward": 542.0105127542597, "episode": 126.0, "batch_reward": 0.2836947914659977, "critic_loss": 0.44249483032524584, "actor_loss": -33.2660443611145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.608920574188232, "step": 126000}
{"episode_reward": 611.4574890205729, "episode": 127.0, "batch_reward": 0.28655247612297535, "critic_loss": 0.40571932670474053, "actor_loss": -33.40661060333252, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.420315742492676, "step": 127000}
{"episode_reward": 594.9323562005128, "episode": 128.0, "batch_reward": 0.28877345731854437, "critic_loss": 0.3491086455285549, "actor_loss": -33.70647284317017, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.84992742538452, "step": 128000}
{"episode_reward": 535.8510465166123, "episode": 129.0, "batch_reward": 0.29074544133245944, "critic_loss": 0.42550082455575466, "actor_loss": -33.947610534667966, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.951494216918945, "step": 129000}
{"episode_reward": 610.6220421067901, "episode": 130.0, "batch_reward": 0.29314967623353005, "critic_loss": 0.4117838759869337, "actor_loss": -33.87011769866943, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.10757803916931, "step": 130000}
{"episode_reward": 633.0297728734859, "episode": 131.0, "batch_reward": 0.2971036278307438, "critic_loss": 0.4068564519286156, "actor_loss": -34.249725650787354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.57572078704834, "step": 131000}
{"episode_reward": 566.0685739650254, "episode": 132.0, "batch_reward": 0.2987318396270275, "critic_loss": 0.36178496715426445, "actor_loss": -34.336051067352294, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.427433252334595, "step": 132000}
{"episode_reward": 625.5604478217924, "episode": 133.0, "batch_reward": 0.3011678031086922, "critic_loss": 0.38618241403996945, "actor_loss": -34.85414874649048, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.700783491134644, "step": 133000}
{"episode_reward": 570.4610019363957, "episode": 134.0, "batch_reward": 0.30307199676334856, "critic_loss": 0.40589941400289536, "actor_loss": -35.15730905532837, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.240488290786743, "step": 134000}
{"episode_reward": 534.8746249183754, "episode": 135.0, "batch_reward": 0.30393857930600643, "critic_loss": 0.37330844624340537, "actor_loss": -34.7599207496643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.744842290878296, "step": 135000}
{"episode_reward": 250.39473942102163, "episode": 136.0, "batch_reward": 0.3039416222274303, "critic_loss": 0.3575266876369715, "actor_loss": -34.808829837799074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.547529458999634, "step": 136000}
{"episode_reward": 586.6329520495572, "episode": 137.0, "batch_reward": 0.3060125830620527, "critic_loss": 0.40301148168742656, "actor_loss": -34.8377066192627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30448603630066, "step": 137000}
{"episode_reward": 588.4713497200677, "episode": 138.0, "batch_reward": 0.3084751142412424, "critic_loss": 0.3960299073904753, "actor_loss": -34.93850882339478, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.187464714050293, "step": 138000}
{"episode_reward": 252.4261843872137, "episode": 139.0, "batch_reward": 0.30756605038046836, "critic_loss": 0.42192166732251646, "actor_loss": -34.957694972991945, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.369659423828125, "step": 139000}
{"episode_reward": 574.5203994899003, "episode": 140.0, "batch_reward": 0.30806467252969744, "critic_loss": 0.43371681110560895, "actor_loss": -34.84515317153931, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.039990425109863, "step": 140000}
{"episode_reward": 565.887045855006, "episode": 141.0, "batch_reward": 0.3118693350851536, "critic_loss": 0.4275316296815872, "actor_loss": -35.09951583480835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.61002445220947, "step": 141000}
{"episode_reward": 552.3585200036838, "episode": 142.0, "batch_reward": 0.313082396581769, "critic_loss": 0.40972365415096285, "actor_loss": -35.29069263076782, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.589548110961914, "step": 142000}
{"episode_reward": 626.7835046419519, "episode": 143.0, "batch_reward": 0.31454033075273036, "critic_loss": 0.3675232767611742, "actor_loss": -35.492403282165526, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.364453554153442, "step": 143000}
{"episode_reward": 371.9770213170017, "episode": 144.0, "batch_reward": 0.3154485647380352, "critic_loss": 0.42689857551455496, "actor_loss": -35.51390861511231, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.403581380844116, "step": 144000}
{"episode_reward": 400.4653176313324, "episode": 145.0, "batch_reward": 0.31765282386541366, "critic_loss": 0.39211537791788575, "actor_loss": -35.725406688690185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.56768250465393, "step": 145000}
{"episode_reward": 585.2376065366304, "episode": 146.0, "batch_reward": 0.3182874338924885, "critic_loss": 0.36333656787872315, "actor_loss": -36.02552111053467, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.567643880844116, "step": 146000}
{"episode_reward": 597.0917733359587, "episode": 147.0, "batch_reward": 0.31978014574944974, "critic_loss": 0.38464570498466494, "actor_loss": -35.96914270782471, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.161368131637573, "step": 147000}
{"episode_reward": 512.6223977404774, "episode": 148.0, "batch_reward": 0.32182140997052194, "critic_loss": 0.38702248956263063, "actor_loss": -36.15458354949951, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.438093423843384, "step": 148000}
{"episode_reward": 602.056306751336, "episode": 149.0, "batch_reward": 0.3234915707111359, "critic_loss": 0.36528164610266683, "actor_loss": -36.28602187347412, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.96367597579956, "step": 149000}
{"episode_reward": 581.0307748460536, "episode": 150.0, "batch_reward": 0.32591515699028967, "critic_loss": 0.36720439727604387, "actor_loss": -36.57528030776977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
