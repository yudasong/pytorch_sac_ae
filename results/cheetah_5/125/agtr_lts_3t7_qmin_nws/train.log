{"episode_reward": 0.0, "episode": 1.0, "duration": 13.418371200561523, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.0050461292266846, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.27945970585392726, "critic_loss": 0.08038230819696583, "actor_loss": -42.720442103424006, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 72.5408980846405, "step": 3000}
{"episode_reward": 4.41685674627011, "episode": 4.0, "batch_reward": 0.17550759544223546, "critic_loss": 0.08133128591254353, "actor_loss": -27.355197459220886, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.947468280792236, "step": 4000}
{"episode_reward": 33.91903656060921, "episode": 5.0, "batch_reward": 0.1423963626548648, "critic_loss": 0.06931735390610994, "actor_loss": -26.702683386325837, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.09243106842041, "step": 5000}
{"episode_reward": 14.528904841292299, "episode": 6.0, "batch_reward": 0.11920080293715, "critic_loss": 0.05054169439151883, "actor_loss": -27.02645463514328, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.06694793701172, "step": 6000}
{"episode_reward": 39.26633099711361, "episode": 7.0, "batch_reward": 0.10759317195042968, "critic_loss": 0.04863558182865381, "actor_loss": -26.02143203783035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.19883131980896, "step": 7000}
{"episode_reward": 26.304337466966956, "episode": 8.0, "batch_reward": 0.09779082319140434, "critic_loss": 0.04247376114875078, "actor_loss": -26.250549532413483, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.80439853668213, "step": 8000}
{"episode_reward": 30.073420777766405, "episode": 9.0, "batch_reward": 0.09308076324686408, "critic_loss": 0.053178314805030824, "actor_loss": -24.303977413654327, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.878199577331543, "step": 9000}
{"episode_reward": 75.90712185638886, "episode": 10.0, "batch_reward": 0.09089761298149825, "critic_loss": 0.06121369525976479, "actor_loss": -23.950157977104187, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.61450695991516, "step": 10000}
{"episode_reward": 96.706322299779, "episode": 11.0, "batch_reward": 0.09159632128477097, "critic_loss": 0.06096455451101065, "actor_loss": -22.344298236846925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.373186349868774, "step": 11000}
{"episode_reward": 100.02641780820906, "episode": 12.0, "batch_reward": 0.0924871762022376, "critic_loss": 0.06468001688271761, "actor_loss": -22.425496341228484, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.59881091117859, "step": 12000}
{"episode_reward": 86.1097093097243, "episode": 13.0, "batch_reward": 0.09226845927536488, "critic_loss": 0.07384662023186683, "actor_loss": -22.41374843645096, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.10436749458313, "step": 13000}
{"episode_reward": 111.99679353729564, "episode": 14.0, "batch_reward": 0.09215584049373865, "critic_loss": 0.08796866245567798, "actor_loss": -23.520444668769837, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.956745147705078, "step": 14000}
{"episode_reward": 55.700703604515, "episode": 15.0, "batch_reward": 0.09301237297430634, "critic_loss": 0.10027961546555161, "actor_loss": -21.066567464351653, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.258835077285767, "step": 15000}
{"episode_reward": 153.8871291513373, "episode": 16.0, "batch_reward": 0.09622321208193899, "critic_loss": 0.1324841734468937, "actor_loss": -20.483274711072443, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.029551029205322, "step": 16000}
{"episode_reward": 116.41776644362606, "episode": 17.0, "batch_reward": 0.09993898105621338, "critic_loss": 0.15455967170000076, "actor_loss": -21.113758983552454, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.35276484489441, "step": 17000}
{"episode_reward": 199.38575302740813, "episode": 18.0, "batch_reward": 0.1049397988691926, "critic_loss": 0.1575281133800745, "actor_loss": -21.668953987315298, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.76130247116089, "step": 18000}
{"episode_reward": 135.12843702391436, "episode": 19.0, "batch_reward": 0.10626988818496466, "critic_loss": 0.16907621281594037, "actor_loss": -19.261910017609598, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14281725883484, "step": 19000}
{"episode_reward": 144.46586117930204, "episode": 20.0, "batch_reward": 0.10524592062830924, "critic_loss": 0.14915774914622307, "actor_loss": -18.72572151437402, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.2566659450531, "step": 20000}
{"episode_reward": 81.15527176691936, "episode": 21.0, "batch_reward": 0.10575630136579275, "critic_loss": 0.15988270598649978, "actor_loss": -18.27939322093129, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.84349584579468, "step": 21000}
{"episode_reward": 152.42272610467825, "episode": 22.0, "batch_reward": 0.11036199520528317, "critic_loss": 0.19226183225214483, "actor_loss": -18.90578344026208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.31782031059265, "step": 22000}
{"episode_reward": 213.59299995868682, "episode": 23.0, "batch_reward": 0.11374045504629612, "critic_loss": 0.18557412451505662, "actor_loss": -20.113751295804978, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.551006078720093, "step": 23000}
{"episode_reward": 148.5417875794155, "episode": 24.0, "batch_reward": 0.11458824812620878, "critic_loss": 0.20482558826357125, "actor_loss": -18.942746612071993, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.794064044952393, "step": 24000}
{"episode_reward": 109.28043711677692, "episode": 25.0, "batch_reward": 0.11441684506088495, "critic_loss": 0.24442060882598163, "actor_loss": -19.554374372005462, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.112746715545654, "step": 25000}
{"episode_reward": 147.7174412098726, "episode": 26.0, "batch_reward": 0.11521865011006593, "critic_loss": 0.23073526868969202, "actor_loss": -19.444484179019927, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.862674474716187, "step": 26000}
{"episode_reward": 204.3528355553249, "episode": 27.0, "batch_reward": 0.12024610890448094, "critic_loss": 0.2120394342392683, "actor_loss": -19.569995772361754, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.603805780410767, "step": 27000}
{"episode_reward": 189.94339524902827, "episode": 28.0, "batch_reward": 0.12153485568612814, "critic_loss": 0.21377396740019322, "actor_loss": -19.418279419898987, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.983454704284668, "step": 28000}
{"episode_reward": 103.61286248568376, "episode": 29.0, "batch_reward": 0.12060781259089709, "critic_loss": 0.19310308904200793, "actor_loss": -18.004093437194825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.61126470565796, "step": 29000}
{"episode_reward": 49.76916115679426, "episode": 30.0, "batch_reward": 0.11786233806610108, "critic_loss": 0.20224476266652347, "actor_loss": -18.009067370414733, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.150980234146118, "step": 30000}
{"episode_reward": 90.27078982101608, "episode": 31.0, "batch_reward": 0.11646240820735693, "critic_loss": 0.20560926048457623, "actor_loss": -17.54228042602539, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.79234480857849, "step": 31000}
{"episode_reward": 45.22081124986765, "episode": 32.0, "batch_reward": 0.11733521626144648, "critic_loss": 0.231191868878901, "actor_loss": -17.43924002170563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.920751810073853, "step": 32000}
{"episode_reward": 302.88351750995446, "episode": 33.0, "batch_reward": 0.12298316565155983, "critic_loss": 0.26583202086389063, "actor_loss": -17.542437094688417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.783311128616333, "step": 33000}
{"episode_reward": 323.2031243437022, "episode": 34.0, "batch_reward": 0.1290449186861515, "critic_loss": 0.2628371661603451, "actor_loss": -19.361480491638183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.55915904045105, "step": 34000}
{"episode_reward": 320.206487937802, "episode": 35.0, "batch_reward": 0.13298663722723722, "critic_loss": 0.25632508857548236, "actor_loss": -18.57384291267395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.343379974365234, "step": 35000}
{"episode_reward": 146.29977384560635, "episode": 36.0, "batch_reward": 0.13459898040443657, "critic_loss": 0.2791546559780836, "actor_loss": -19.40948378944397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.764774799346924, "step": 36000}
{"episode_reward": 328.2074234103404, "episode": 37.0, "batch_reward": 0.13837267615646123, "critic_loss": 0.29991786673665044, "actor_loss": -19.09921109199524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.72059202194214, "step": 37000}
{"episode_reward": 144.68280408922905, "episode": 38.0, "batch_reward": 0.13869657911360264, "critic_loss": 0.2956741883158684, "actor_loss": -18.67085677909851, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.245060205459595, "step": 38000}
{"episode_reward": 123.87046201025763, "episode": 39.0, "batch_reward": 0.13905148217827082, "critic_loss": 0.29262643785774706, "actor_loss": -18.75195657348633, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.978618144989014, "step": 39000}
{"episode_reward": 247.88126262653955, "episode": 40.0, "batch_reward": 0.14088020598888398, "critic_loss": 0.2912038827687502, "actor_loss": -19.093672786712645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.302942991256714, "step": 40000}
{"episode_reward": 110.39440897383774, "episode": 41.0, "batch_reward": 0.1404005071669817, "critic_loss": 0.28561701284348967, "actor_loss": -19.058740215301512, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.2522759437561, "step": 41000}
{"episode_reward": 160.7074772852857, "episode": 42.0, "batch_reward": 0.1427932981327176, "critic_loss": 0.30873342163860795, "actor_loss": -19.878518650054932, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.942742347717285, "step": 42000}
{"episode_reward": 293.7758398519795, "episode": 43.0, "batch_reward": 0.14656861909478902, "critic_loss": 0.33510044364631175, "actor_loss": -20.15998869895935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.275630950927734, "step": 43000}
{"episode_reward": 310.09935103684796, "episode": 44.0, "batch_reward": 0.14903898610174657, "critic_loss": 0.33922068662941457, "actor_loss": -20.454333005905152, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.851317167282104, "step": 44000}
{"episode_reward": 279.72891087358136, "episode": 45.0, "batch_reward": 0.1515270627066493, "critic_loss": 0.34140849439799786, "actor_loss": -20.74711064147949, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.538546085357666, "step": 45000}
{"episode_reward": 139.08121242755365, "episode": 46.0, "batch_reward": 0.15248468543589117, "critic_loss": 0.34083161917328836, "actor_loss": -20.98818216705322, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.833688497543335, "step": 46000}
{"episode_reward": 342.7218928387767, "episode": 47.0, "batch_reward": 0.15580577591061592, "critic_loss": 0.3946414804160595, "actor_loss": -20.849362747192384, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.76694107055664, "step": 47000}
{"episode_reward": 98.33223438388279, "episode": 48.0, "batch_reward": 0.15305097857117653, "critic_loss": 0.34484584753215314, "actor_loss": -20.923826360702513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.859257698059082, "step": 48000}
{"episode_reward": 47.551335299889246, "episode": 49.0, "batch_reward": 0.1521893007233739, "critic_loss": 0.3621640838235617, "actor_loss": -21.127151237487794, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.065913200378418, "step": 49000}
{"episode_reward": 147.96747405098563, "episode": 50.0, "batch_reward": 0.15028572895377873, "critic_loss": 0.35391882617771625, "actor_loss": -21.262813732147215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.079261302947998, "step": 50000}
{"episode_reward": 64.01535960085336, "episode": 51.0, "batch_reward": 0.1500683177858591, "critic_loss": 0.38624628357589247, "actor_loss": -21.4552212600708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.322620153427124, "step": 51000}
{"episode_reward": 182.33694989671142, "episode": 52.0, "batch_reward": 0.15044123435765505, "critic_loss": 0.3666167498379946, "actor_loss": -21.774253688812255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.97410821914673, "step": 52000}
{"episode_reward": 111.59063416054867, "episode": 53.0, "batch_reward": 0.15167985898256303, "critic_loss": 0.419985940977931, "actor_loss": -21.926715198516845, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.945048093795776, "step": 53000}
{"episode_reward": 401.312289547313, "episode": 54.0, "batch_reward": 0.15617495898902417, "critic_loss": 0.4302779356539249, "actor_loss": -22.574680549621583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.716788291931152, "step": 54000}
{"episode_reward": 339.23473509326135, "episode": 55.0, "batch_reward": 0.15866573066264392, "critic_loss": 0.4918066930770874, "actor_loss": -22.91349072265625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.581383228302002, "step": 55000}
{"episode_reward": 204.08376542758953, "episode": 56.0, "batch_reward": 0.15976291071623563, "critic_loss": 0.49383491587638856, "actor_loss": -23.27688292312622, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.001245260238647, "step": 56000}
{"episode_reward": 288.1119594650646, "episode": 57.0, "batch_reward": 0.16244716306030751, "critic_loss": 0.44488295963406566, "actor_loss": -23.602775051116943, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.576472759246826, "step": 57000}
{"episode_reward": 235.41601919641278, "episode": 58.0, "batch_reward": 0.16431184212863445, "critic_loss": 0.5295982837826013, "actor_loss": -23.958263763427734, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.21286106109619, "step": 58000}
{"episode_reward": 320.4990749282573, "episode": 59.0, "batch_reward": 0.16466229559481144, "critic_loss": 0.5010139780640602, "actor_loss": -24.07151276779175, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.67502188682556, "step": 59000}
{"episode_reward": 103.74746785517178, "episode": 60.0, "batch_reward": 0.16497784235328436, "critic_loss": 0.515443828612566, "actor_loss": -24.10591905593872, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.796200037002563, "step": 60000}
{"episode_reward": 183.5614738490099, "episode": 61.0, "batch_reward": 0.16613899931311607, "critic_loss": 0.5099250152260065, "actor_loss": -24.368085998535157, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.48424434661865, "step": 61000}
{"episode_reward": 352.12424706433455, "episode": 62.0, "batch_reward": 0.16846348114311696, "critic_loss": 0.5099667048454285, "actor_loss": -24.357912593841554, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.093881130218506, "step": 62000}
{"episode_reward": 235.25775615731527, "episode": 63.0, "batch_reward": 0.16763272139430047, "critic_loss": 0.5148032800108194, "actor_loss": -24.44996236038208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.032509565353394, "step": 63000}
{"episode_reward": 110.67807458247557, "episode": 64.0, "batch_reward": 0.1676529119759798, "critic_loss": 0.5074309400618077, "actor_loss": -24.4310389213562, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.413424968719482, "step": 64000}
{"episode_reward": 118.25818360155708, "episode": 65.0, "batch_reward": 0.16840957549214364, "critic_loss": 0.5553049596548081, "actor_loss": -24.327571254730223, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.315730810165405, "step": 65000}
{"episode_reward": 345.0023928745852, "episode": 66.0, "batch_reward": 0.17068776862323284, "critic_loss": 0.5717998363524676, "actor_loss": -24.91077974700928, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.729081630706787, "step": 66000}
{"episode_reward": 341.0073973213526, "episode": 67.0, "batch_reward": 0.1724472008049488, "critic_loss": 0.5411964654475451, "actor_loss": -24.95310856628418, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.928820610046387, "step": 67000}
{"episode_reward": 118.31810120267336, "episode": 68.0, "batch_reward": 0.17167038215696812, "critic_loss": 0.5606362239420414, "actor_loss": -25.058522415161132, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.263423681259155, "step": 68000}
{"episode_reward": 326.8800542880781, "episode": 69.0, "batch_reward": 0.17230010506510735, "critic_loss": 0.5838491736352444, "actor_loss": -25.136414260864257, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14147973060608, "step": 69000}
{"episode_reward": 61.973059586741144, "episode": 70.0, "batch_reward": 0.17258380211889743, "critic_loss": 0.5905592062622309, "actor_loss": -25.06675262069702, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.395475387573242, "step": 70000}
{"episode_reward": 164.55819050882997, "episode": 71.0, "batch_reward": 0.17296986609697343, "critic_loss": 0.7032169793397188, "actor_loss": -25.220309879302977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.4343523979187, "step": 71000}
{"episode_reward": 150.73805860880742, "episode": 72.0, "batch_reward": 0.17103427158296108, "critic_loss": 0.5823710743486882, "actor_loss": -24.964715007781983, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.977051258087158, "step": 72000}
{"episode_reward": 85.86230754707016, "episode": 73.0, "batch_reward": 0.17162901039421558, "critic_loss": 0.5617103799134493, "actor_loss": -25.136787605285644, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41181492805481, "step": 73000}
{"episode_reward": 392.57375100652246, "episode": 74.0, "batch_reward": 0.17419646805524827, "critic_loss": 0.5859402837902308, "actor_loss": -25.485216709136964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.665299654006958, "step": 74000}
{"episode_reward": 371.61469976873576, "episode": 75.0, "batch_reward": 0.17606047102808953, "critic_loss": 0.6183035941272974, "actor_loss": -25.685207195281983, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.63290762901306, "step": 75000}
{"episode_reward": 101.8380498794128, "episode": 76.0, "batch_reward": 0.1761134379953146, "critic_loss": 0.5746239544898272, "actor_loss": -25.499628440856934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.11733913421631, "step": 76000}
{"episode_reward": 338.8711849261365, "episode": 77.0, "batch_reward": 0.17668284951150418, "critic_loss": 0.5994738141745329, "actor_loss": -25.76109175491333, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.00544571876526, "step": 77000}
{"episode_reward": 97.26027292366005, "episode": 78.0, "batch_reward": 0.1768682865202427, "critic_loss": 0.6431517179012298, "actor_loss": -25.644386024475097, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.251391172409058, "step": 78000}
{"episode_reward": 177.123606196361, "episode": 79.0, "batch_reward": 0.1762760578095913, "critic_loss": 0.6269806336462498, "actor_loss": -25.796941036224364, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.790142059326172, "step": 79000}
{"episode_reward": 64.9916264119128, "episode": 80.0, "batch_reward": 0.1755106999874115, "critic_loss": 0.6783229741603136, "actor_loss": -25.530674297332762, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.315975189208984, "step": 80000}
{"episode_reward": 277.3261596519323, "episode": 81.0, "batch_reward": 0.17706166723370553, "critic_loss": 0.5964371824711561, "actor_loss": -25.732476650238038, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.476120471954346, "step": 81000}
{"episode_reward": 344.99981626777105, "episode": 82.0, "batch_reward": 0.17848124700784684, "critic_loss": 0.5662882103770971, "actor_loss": -25.825626636505127, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.01583504676819, "step": 82000}
{"episode_reward": 167.56692225017292, "episode": 83.0, "batch_reward": 0.17868159336596728, "critic_loss": 0.5847619027644396, "actor_loss": -25.91852586364746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.125211238861084, "step": 83000}
{"episode_reward": 363.83786857411314, "episode": 84.0, "batch_reward": 0.18102716527879237, "critic_loss": 0.628764545455575, "actor_loss": -26.13123733520508, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.1208553314209, "step": 84000}
{"episode_reward": 376.8065932208555, "episode": 85.0, "batch_reward": 0.18276745110750198, "critic_loss": 0.6865798120647669, "actor_loss": -26.279651679992675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.304884672164917, "step": 85000}
{"episode_reward": 129.49283935140116, "episode": 86.0, "batch_reward": 0.1829585862159729, "critic_loss": 0.6293183846473693, "actor_loss": -26.19920892715454, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.99565315246582, "step": 86000}
{"episode_reward": 322.28749034425425, "episode": 87.0, "batch_reward": 0.18527502378821373, "critic_loss": 0.5841075776517392, "actor_loss": -26.429626449584962, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.86124348640442, "step": 87000}
{"episode_reward": 423.9303094738899, "episode": 88.0, "batch_reward": 0.1857115041464567, "critic_loss": 0.6365802337080241, "actor_loss": -26.4911651763916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23189115524292, "step": 88000}
{"episode_reward": 121.53385188587708, "episode": 89.0, "batch_reward": 0.18605211408436298, "critic_loss": 0.641036603987217, "actor_loss": -26.410258224487304, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.748130559921265, "step": 89000}
{"episode_reward": 433.8912500941542, "episode": 90.0, "batch_reward": 0.18808296278119088, "critic_loss": 0.6994712065458297, "actor_loss": -26.613420646667482, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.981587648391724, "step": 90000}
{"episode_reward": 71.56286651158824, "episode": 91.0, "batch_reward": 0.18809964615106584, "critic_loss": 0.6554020111560821, "actor_loss": -26.429078022003175, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.387547731399536, "step": 91000}
{"episode_reward": 181.20074324425994, "episode": 92.0, "batch_reward": 0.18728322683274745, "critic_loss": 0.6017334625720978, "actor_loss": -26.320953186035155, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.69057011604309, "step": 92000}
{"episode_reward": 178.06107487083295, "episode": 93.0, "batch_reward": 0.18675661720335485, "critic_loss": 0.6390125360041857, "actor_loss": -26.241334102630614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54851746559143, "step": 93000}
{"episode_reward": 221.71051867025702, "episode": 94.0, "batch_reward": 0.18722788405418395, "critic_loss": 0.670123458430171, "actor_loss": -26.27562603378296, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.146888971328735, "step": 94000}
{"episode_reward": 161.70991039390776, "episode": 95.0, "batch_reward": 0.18714385314285756, "critic_loss": 0.6548756286799907, "actor_loss": -26.0388092918396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.711668014526367, "step": 95000}
{"episode_reward": 152.46580208946767, "episode": 96.0, "batch_reward": 0.18825622837245465, "critic_loss": 0.7629877488464117, "actor_loss": -26.092653728485107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.397837162017822, "step": 96000}
{"episode_reward": 294.59985482528776, "episode": 97.0, "batch_reward": 0.1876118377149105, "critic_loss": 0.7196446861177683, "actor_loss": -26.029076175689696, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.98867106437683, "step": 97000}
{"episode_reward": 109.57220321670677, "episode": 98.0, "batch_reward": 0.18812409967184066, "critic_loss": 0.6175980048924684, "actor_loss": -25.880467666625975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.454668521881104, "step": 98000}
{"episode_reward": 425.654053266309, "episode": 99.0, "batch_reward": 0.1895625234991312, "critic_loss": 0.6841462936252356, "actor_loss": -26.0956746673584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.84178590774536, "step": 99000}
{"episode_reward": 148.79282123987696, "episode": 100.0, "batch_reward": 0.19008728370070457, "critic_loss": 0.6792398900687695, "actor_loss": -26.146495906829834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.046452522277832, "step": 100000}
{"episode_reward": 349.7000300915206, "episode": 101.0, "batch_reward": 0.19191480040550232, "critic_loss": 0.7101491180956364, "actor_loss": -26.235187786102294, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.10387992858887, "step": 101000}
{"episode_reward": 294.8700935236678, "episode": 102.0, "batch_reward": 0.19201686923205852, "critic_loss": 0.6221527436226606, "actor_loss": -26.215397830963134, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.81883668899536, "step": 102000}
{"episode_reward": 428.1688394592768, "episode": 103.0, "batch_reward": 0.19464616271853447, "critic_loss": 0.6322013052105904, "actor_loss": -26.415376499176027, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.207801342010498, "step": 103000}
{"episode_reward": 241.20686173187647, "episode": 104.0, "batch_reward": 0.19559081637859344, "critic_loss": 0.6222001298218965, "actor_loss": -26.359846702575684, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.53929829597473, "step": 104000}
{"episode_reward": 443.56674910030335, "episode": 105.0, "batch_reward": 0.19813266742229463, "critic_loss": 0.6897431283295155, "actor_loss": -26.466927059173585, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.71673059463501, "step": 105000}
{"episode_reward": 319.4877115340074, "episode": 106.0, "batch_reward": 0.1981733262091875, "critic_loss": 0.7128054537326097, "actor_loss": -26.48010391616821, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27894926071167, "step": 106000}
{"episode_reward": 190.04226285105773, "episode": 107.0, "batch_reward": 0.19914728584885596, "critic_loss": 0.690922825589776, "actor_loss": -26.47854479598999, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.015573501586914, "step": 107000}
{"episode_reward": 399.03501347263, "episode": 108.0, "batch_reward": 0.20053360550105573, "critic_loss": 0.6905777281969786, "actor_loss": -26.50288367843628, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14890146255493, "step": 108000}
{"episode_reward": 418.711019806675, "episode": 109.0, "batch_reward": 0.2022896095663309, "critic_loss": 0.6973727162480354, "actor_loss": -26.60185298919678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.800980806350708, "step": 109000}
{"episode_reward": 368.93849235218755, "episode": 110.0, "batch_reward": 0.20358727955818176, "critic_loss": 0.6812158911377192, "actor_loss": -26.67215754699707, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.06760001182556, "step": 110000}
{"episode_reward": 115.96624987981691, "episode": 111.0, "batch_reward": 0.20197438879311086, "critic_loss": 0.7054128495901824, "actor_loss": -26.540004920959472, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.03423762321472, "step": 111000}
{"episode_reward": 174.04162988566338, "episode": 112.0, "batch_reward": 0.20298321455717086, "critic_loss": 0.6890508193522692, "actor_loss": -26.412931159973144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.12063431739807, "step": 112000}
{"episode_reward": 264.56858286274144, "episode": 113.0, "batch_reward": 0.20375614254176616, "critic_loss": 0.678987043350935, "actor_loss": -26.553505939483642, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.03999400138855, "step": 113000}
{"episode_reward": 262.2984793770838, "episode": 114.0, "batch_reward": 0.20429968404769897, "critic_loss": 0.6348628100901842, "actor_loss": -26.54500309753418, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.05698537826538, "step": 114000}
{"episode_reward": 408.1307411638174, "episode": 115.0, "batch_reward": 0.2067318044602871, "critic_loss": 0.6349523669630289, "actor_loss": -26.610228134155275, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.76964831352234, "step": 115000}
{"episode_reward": 344.8532027665635, "episode": 116.0, "batch_reward": 0.2083694344609976, "critic_loss": 0.5739027308523655, "actor_loss": -26.869768611907958, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.289928913116455, "step": 116000}
{"episode_reward": 498.0435078374072, "episode": 117.0, "batch_reward": 0.2098675018399954, "critic_loss": 0.6308866307884454, "actor_loss": -26.9552583732605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.97603988647461, "step": 117000}
{"episode_reward": 433.4475224129853, "episode": 118.0, "batch_reward": 0.2106791272163391, "critic_loss": 0.5831573636531829, "actor_loss": -26.93409909439087, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.997470378875732, "step": 118000}
{"episode_reward": 179.81165120418038, "episode": 119.0, "batch_reward": 0.21144416876137256, "critic_loss": 0.5951878972798585, "actor_loss": -27.02957316970825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.0506534576416, "step": 119000}
{"episode_reward": 122.48176467819297, "episode": 120.0, "batch_reward": 0.21066142286360265, "critic_loss": 0.5534504161030054, "actor_loss": -26.760346942901613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.831806898117065, "step": 120000}
{"episode_reward": 448.9404173253001, "episode": 121.0, "batch_reward": 0.21371469403803348, "critic_loss": 0.6001990001499653, "actor_loss": -26.95152900695801, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.656960010528564, "step": 121000}
{"episode_reward": 446.90299913880307, "episode": 122.0, "batch_reward": 0.21512268075346946, "critic_loss": 0.5418821889460087, "actor_loss": -27.000724876403808, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.538586616516113, "step": 122000}
{"episode_reward": 486.6114074054392, "episode": 123.0, "batch_reward": 0.2172126403003931, "critic_loss": 0.5408672120571136, "actor_loss": -27.13639129638672, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.432509899139404, "step": 123000}
{"episode_reward": 476.0484669092764, "episode": 124.0, "batch_reward": 0.21834623762965202, "critic_loss": 0.4978434181958437, "actor_loss": -27.186545001983642, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.874309539794922, "step": 124000}
{"episode_reward": 509.027554861179, "episode": 125.0, "batch_reward": 0.2210213485211134, "critic_loss": 0.47123770470917226, "actor_loss": -27.429280067443848, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.713762283325195, "step": 125000}
{"episode_reward": 506.7589564928815, "episode": 126.0, "batch_reward": 0.22332722958922385, "critic_loss": 0.5108249647468328, "actor_loss": -27.661234897613525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.286263465881348, "step": 126000}
{"episode_reward": 535.4048038114169, "episode": 127.0, "batch_reward": 0.22643794740736484, "critic_loss": 0.44040268433094026, "actor_loss": -27.788881172180176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.013832330703735, "step": 127000}
{"episode_reward": 505.3945875170644, "episode": 128.0, "batch_reward": 0.22843653197586536, "critic_loss": 0.4769728593081236, "actor_loss": -27.934747882843016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.98406672477722, "step": 128000}
{"episode_reward": 562.927793376742, "episode": 129.0, "batch_reward": 0.23014983071386813, "critic_loss": 0.4164246329069138, "actor_loss": -28.09528328704834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.856884956359863, "step": 129000}
{"episode_reward": 548.5241387479939, "episode": 130.0, "batch_reward": 0.23316243891417981, "critic_loss": 0.4432560283243656, "actor_loss": -28.33962066268921, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.69104290008545, "step": 130000}
{"episode_reward": 501.67835853026355, "episode": 131.0, "batch_reward": 0.23646777856349946, "critic_loss": 0.4320246701985598, "actor_loss": -28.385693435668944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.389851570129395, "step": 131000}
{"episode_reward": 507.601976014395, "episode": 132.0, "batch_reward": 0.23851683001220225, "critic_loss": 0.43835268160700797, "actor_loss": -28.73510382080078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.167055130004883, "step": 132000}
{"episode_reward": 530.3719059756831, "episode": 133.0, "batch_reward": 0.24005699795484542, "critic_loss": 0.4035084629356861, "actor_loss": -28.962669097900392, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.08868432044983, "step": 133000}
{"episode_reward": 497.72356037070995, "episode": 134.0, "batch_reward": 0.24196996338665486, "critic_loss": 0.4006863917261362, "actor_loss": -29.057256370544433, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.038251161575317, "step": 134000}
{"episode_reward": 552.687521403484, "episode": 135.0, "batch_reward": 0.24369202184677125, "critic_loss": 0.3634706469923258, "actor_loss": -29.278749382019043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23591136932373, "step": 135000}
{"episode_reward": 447.7430971883907, "episode": 136.0, "batch_reward": 0.24487846188247203, "critic_loss": 0.35713007020950316, "actor_loss": -29.170721138000488, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.348231554031372, "step": 136000}
{"episode_reward": 537.4515376743983, "episode": 137.0, "batch_reward": 0.24798237051069735, "critic_loss": 0.3868708983361721, "actor_loss": -29.38486099624634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.05094575881958, "step": 137000}
{"episode_reward": 502.84207671452947, "episode": 138.0, "batch_reward": 0.24995721399784088, "critic_loss": 0.3555773051083088, "actor_loss": -29.509473526000978, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.11610746383667, "step": 138000}
{"episode_reward": 576.8538857700303, "episode": 139.0, "batch_reward": 0.25224469205737116, "critic_loss": 0.3795024929344654, "actor_loss": -29.783057609558107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.273619651794434, "step": 139000}
{"episode_reward": 578.3801867397982, "episode": 140.0, "batch_reward": 0.2549553984999657, "critic_loss": 0.3500497957766056, "actor_loss": -29.861648384094238, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.655856370925903, "step": 140000}
{"episode_reward": 508.13546181856515, "episode": 141.0, "batch_reward": 0.2561600315719843, "critic_loss": 0.33813910734653474, "actor_loss": -29.817079303741455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.944650411605835, "step": 141000}
{"episode_reward": 533.3859244607537, "episode": 142.0, "batch_reward": 0.2583299387544394, "critic_loss": 0.3404826477020979, "actor_loss": -30.011639305114745, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.723246097564697, "step": 142000}
{"episode_reward": 553.1241302899326, "episode": 143.0, "batch_reward": 0.2602517738640308, "critic_loss": 0.34062602342665194, "actor_loss": -30.135360858917235, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.92945694923401, "step": 143000}
{"episode_reward": 517.2524992134244, "episode": 144.0, "batch_reward": 0.2623812816590071, "critic_loss": 0.3590224129408598, "actor_loss": -30.1992841796875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.009516954421997, "step": 144000}
{"episode_reward": 572.215996306673, "episode": 145.0, "batch_reward": 0.26422176192700864, "critic_loss": 0.32541523267328737, "actor_loss": -30.29251321029663, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.97670340538025, "step": 145000}
{"episode_reward": 520.1080426588376, "episode": 146.0, "batch_reward": 0.26484411576390265, "critic_loss": 0.32528083117306233, "actor_loss": -30.605965717315673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.578819751739502, "step": 146000}
{"episode_reward": 563.7557295409966, "episode": 147.0, "batch_reward": 0.2671684299409389, "critic_loss": 0.30202345579862594, "actor_loss": -30.43472491455078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.612886905670166, "step": 147000}
{"episode_reward": 563.6151749252688, "episode": 148.0, "batch_reward": 0.2702648011893034, "critic_loss": 0.32296194510161874, "actor_loss": -30.83096115112305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.538515329360962, "step": 148000}
{"episode_reward": 606.4024685019718, "episode": 149.0, "batch_reward": 0.2726757389307022, "critic_loss": 0.3353679365813732, "actor_loss": -31.000916290283204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.959967374801636, "step": 149000}
{"episode_reward": 325.84301429217066, "episode": 150.0, "batch_reward": 0.2734652619808912, "critic_loss": 0.3028206840902567, "actor_loss": -31.144203815460205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
