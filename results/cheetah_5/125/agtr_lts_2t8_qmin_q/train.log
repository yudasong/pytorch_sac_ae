{"episode_reward": 0.0, "episode": 1.0, "duration": 13.8642737865448, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.2132666110992432, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2821841881290282, "critic_loss": 0.15184279495838404, "actor_loss": -47.66272550585175, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 68.95045304298401, "step": 3000}
{"episode_reward": 61.64402026932978, "episode": 4.0, "batch_reward": 0.20604306000471115, "critic_loss": 0.14863504625856877, "actor_loss": -41.52734368896484, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.659523725509644, "step": 4000}
{"episode_reward": 100.61235098350514, "episode": 5.0, "batch_reward": 0.18149206981807947, "critic_loss": 0.34988741029798986, "actor_loss": -37.57861817550659, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.93382954597473, "step": 5000}
{"episode_reward": 126.58073965235631, "episode": 6.0, "batch_reward": 0.17816383075714112, "critic_loss": 0.23232685731351377, "actor_loss": -36.44209860229492, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.824772596359253, "step": 6000}
{"episode_reward": 168.91505650431162, "episode": 7.0, "batch_reward": 0.17150439393520356, "critic_loss": 0.2218686009645462, "actor_loss": -34.56314738464356, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.87483263015747, "step": 7000}
{"episode_reward": 102.31468851007868, "episode": 8.0, "batch_reward": 0.16607596722245216, "critic_loss": 0.2317243926972151, "actor_loss": -33.16555107879638, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.906548023223877, "step": 8000}
{"episode_reward": 200.7985532911448, "episode": 9.0, "batch_reward": 0.16698914882540702, "critic_loss": 0.2393552595824003, "actor_loss": -32.594776191711425, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.29963755607605, "step": 9000}
{"episode_reward": 97.7811823637911, "episode": 10.0, "batch_reward": 0.16524760212749243, "critic_loss": 0.24144169680029154, "actor_loss": -32.040465244293216, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.916850090026855, "step": 10000}
{"episode_reward": 229.2144277210408, "episode": 11.0, "batch_reward": 0.1612685173973441, "critic_loss": 0.22879367819428445, "actor_loss": -31.175938537597656, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.01732921600342, "step": 11000}
{"episode_reward": 10.548369269410745, "episode": 12.0, "batch_reward": 0.1534900548234582, "critic_loss": 0.22611283019185066, "actor_loss": -30.218771060943602, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.64572238922119, "step": 12000}
{"episode_reward": 165.92805686651664, "episode": 13.0, "batch_reward": 0.158699472874403, "critic_loss": 0.25339422905445097, "actor_loss": -30.544617698669434, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.922902822494507, "step": 13000}
{"episode_reward": 260.6761456639918, "episode": 14.0, "batch_reward": 0.1672172904089093, "critic_loss": 0.25577788983285427, "actor_loss": -31.497232234954833, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.391350269317627, "step": 14000}
{"episode_reward": 327.7027890248472, "episode": 15.0, "batch_reward": 0.1771537639349699, "critic_loss": 0.254061208486557, "actor_loss": -31.529157745361328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.288443565368652, "step": 15000}
{"episode_reward": 212.79609545786093, "episode": 16.0, "batch_reward": 0.18071455377340317, "critic_loss": 0.25811526492238046, "actor_loss": -31.567715744018553, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.825591802597046, "step": 16000}
{"episode_reward": 231.33996691331552, "episode": 17.0, "batch_reward": 0.1845655721127987, "critic_loss": 0.26988445363938807, "actor_loss": -31.75419199371338, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.02492880821228, "step": 17000}
{"episode_reward": 324.61070655097456, "episode": 18.0, "batch_reward": 0.19536584116518496, "critic_loss": 0.294492799654603, "actor_loss": -32.21379021453858, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.605150938034058, "step": 18000}
{"episode_reward": 416.597172885905, "episode": 19.0, "batch_reward": 0.20331168618798257, "critic_loss": 0.30264379119873047, "actor_loss": -32.147264793396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.193483352661133, "step": 19000}
{"episode_reward": 204.50626178308823, "episode": 20.0, "batch_reward": 0.2040648013651371, "critic_loss": 0.31977086973190305, "actor_loss": -31.62194353866577, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.25879144668579, "step": 20000}
{"episode_reward": 271.62318569320826, "episode": 21.0, "batch_reward": 0.20846399036049842, "critic_loss": 0.37426299655437467, "actor_loss": -31.310876220703125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.050461530685425, "step": 21000}
{"episode_reward": 245.59899663050982, "episode": 22.0, "batch_reward": 0.21233761087059974, "critic_loss": 0.42553599558770655, "actor_loss": -31.703146942138673, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.21603798866272, "step": 22000}
{"episode_reward": 433.76391435186923, "episode": 23.0, "batch_reward": 0.21883681233227253, "critic_loss": 0.5505894045084715, "actor_loss": -32.62223084640503, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.293287992477417, "step": 23000}
{"episode_reward": 173.76729391763908, "episode": 24.0, "batch_reward": 0.21842605313658714, "critic_loss": 0.6754389355182647, "actor_loss": -32.47217139816284, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.39075493812561, "step": 24000}
{"episode_reward": 438.09690463217123, "episode": 25.0, "batch_reward": 0.22855927972495557, "critic_loss": 0.9952539247274399, "actor_loss": -34.04168774795532, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.884228229522705, "step": 25000}
{"episode_reward": 426.79778170293224, "episode": 26.0, "batch_reward": 0.22743717156350612, "critic_loss": 1.7958368284106254, "actor_loss": -34.98491055679321, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.068182945251465, "step": 26000}
{"episode_reward": 15.873366903817566, "episode": 27.0, "batch_reward": 0.22117070829868316, "critic_loss": 2.294268550157547, "actor_loss": -35.99673392486572, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.092534065246582, "step": 27000}
{"episode_reward": 9.325599133070035, "episode": 28.0, "batch_reward": 0.21432368063926696, "critic_loss": 2.6946842569112777, "actor_loss": -37.66312829589844, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.192270278930664, "step": 28000}
{"episode_reward": 18.681155160639697, "episode": 29.0, "batch_reward": 0.20745922127366065, "critic_loss": 2.7263365010023115, "actor_loss": -38.91110950469971, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.34830069541931, "step": 29000}
{"episode_reward": 32.01342211539463, "episode": 30.0, "batch_reward": 0.200708005130291, "critic_loss": 2.9962640587091447, "actor_loss": -40.23945029067993, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.154741048812866, "step": 30000}
{"episode_reward": 13.264000576958468, "episode": 31.0, "batch_reward": 0.19541733717918397, "critic_loss": 3.4992568507194517, "actor_loss": -43.37507367324829, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.18599820137024, "step": 31000}
{"episode_reward": 13.247751910277904, "episode": 32.0, "batch_reward": 0.18834107266366482, "critic_loss": 3.4990345804691314, "actor_loss": -45.91699949264526, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.582369565963745, "step": 32000}
{"episode_reward": 12.582789992738478, "episode": 33.0, "batch_reward": 0.18296019758284093, "critic_loss": 3.154287169933319, "actor_loss": -48.28904655075073, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.015843152999878, "step": 33000}
{"episode_reward": 24.85259122633729, "episode": 34.0, "batch_reward": 0.17842423470318317, "critic_loss": 3.266209527730942, "actor_loss": -48.77990385055542, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.091907501220703, "step": 34000}
{"episode_reward": 18.40886569360111, "episode": 35.0, "batch_reward": 0.17263402345776557, "critic_loss": 3.5736815311908723, "actor_loss": -52.11583404541015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.012656211853027, "step": 35000}
{"episode_reward": 9.4353086311516, "episode": 36.0, "batch_reward": 0.16923590295761823, "critic_loss": 3.918574907660484, "actor_loss": -52.82912968063354, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.074880361557007, "step": 36000}
{"episode_reward": 14.126176315411492, "episode": 37.0, "batch_reward": 0.16512004549056292, "critic_loss": 4.235070053577423, "actor_loss": -55.475417922973634, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.265952587127686, "step": 37000}
{"episode_reward": 26.09932017464135, "episode": 38.0, "batch_reward": 0.1611781479641795, "critic_loss": 4.893786778450012, "actor_loss": -58.489944393157955, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.204005479812622, "step": 38000}
{"episode_reward": 18.693118990617403, "episode": 39.0, "batch_reward": 0.15709933627396822, "critic_loss": 5.346775887727738, "actor_loss": -60.5025133895874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.08461308479309, "step": 39000}
{"episode_reward": 28.673761473211805, "episode": 40.0, "batch_reward": 0.1538776032179594, "critic_loss": 5.09304075217247, "actor_loss": -62.24566070556641, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.34921360015869, "step": 40000}
{"episode_reward": 15.576349464812662, "episode": 41.0, "batch_reward": 0.15101499374210833, "critic_loss": 4.586525101900101, "actor_loss": -62.7348952255249, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.23099184036255, "step": 41000}
{"episode_reward": 13.60190063711864, "episode": 42.0, "batch_reward": 0.1474269556030631, "critic_loss": 4.193901855587959, "actor_loss": -62.311829154968265, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.596604824066162, "step": 42000}
{"episode_reward": 22.736102878834355, "episode": 43.0, "batch_reward": 0.14344916653633116, "critic_loss": 3.694752177834511, "actor_loss": -63.18008839035034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.29617667198181, "step": 43000}
{"episode_reward": 33.21678514552919, "episode": 44.0, "batch_reward": 0.14185243121534585, "critic_loss": 3.515179740905762, "actor_loss": -63.400946102142335, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.289300441741943, "step": 44000}
{"episode_reward": 49.993167226803656, "episode": 45.0, "batch_reward": 0.14112334129214288, "critic_loss": 3.323160440325737, "actor_loss": -64.41346120452882, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.263643741607666, "step": 45000}
{"episode_reward": 82.51007426171954, "episode": 46.0, "batch_reward": 0.13905137120187283, "critic_loss": 3.0254227051734923, "actor_loss": -63.57523664093018, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.505332708358765, "step": 46000}
{"episode_reward": 76.08558051751682, "episode": 47.0, "batch_reward": 0.13798782702535392, "critic_loss": 2.8708043687343596, "actor_loss": -65.43104861831665, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.01899552345276, "step": 47000}
{"episode_reward": 39.320537173104626, "episode": 48.0, "batch_reward": 0.13522335597872734, "critic_loss": 2.6279149042367935, "actor_loss": -62.64141399765015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.33638286590576, "step": 48000}
{"episode_reward": 25.546265965563578, "episode": 49.0, "batch_reward": 0.13375393717736006, "critic_loss": 2.4794336327314377, "actor_loss": -63.655375415802, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.249317407608032, "step": 49000}
{"episode_reward": 47.66671458316765, "episode": 50.0, "batch_reward": 0.13130272451788186, "critic_loss": 2.233249860405922, "actor_loss": -61.810092895507815, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.420379638671875, "step": 50000}
{"episode_reward": 39.91190038367492, "episode": 51.0, "batch_reward": 0.12987983436137437, "critic_loss": 2.1718741521835327, "actor_loss": -60.63363918304444, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.41091537475586, "step": 51000}
{"episode_reward": 34.67556537110918, "episode": 52.0, "batch_reward": 0.1287294387817383, "critic_loss": 2.0288149416446686, "actor_loss": -59.141694412231445, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.33105206489563, "step": 52000}
{"episode_reward": 35.77592166242315, "episode": 53.0, "batch_reward": 0.12620482710748912, "critic_loss": 2.0309055789113044, "actor_loss": -58.32690645980835, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.641475677490234, "step": 53000}
{"episode_reward": 16.036953028197193, "episode": 54.0, "batch_reward": 0.12391543051600457, "critic_loss": 1.895687153697014, "actor_loss": -57.09898135375977, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.19609022140503, "step": 54000}
{"episode_reward": 29.333440959621917, "episode": 55.0, "batch_reward": 0.12090179330855608, "critic_loss": 1.7495466328263283, "actor_loss": -56.96012943267822, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.98929262161255, "step": 55000}
{"episode_reward": 17.25717806130023, "episode": 56.0, "batch_reward": 0.12096348269283771, "critic_loss": 1.6011350080966948, "actor_loss": -55.66720949935913, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.475931882858276, "step": 56000}
{"episode_reward": 25.763125169741997, "episode": 57.0, "batch_reward": 0.11795049814507365, "critic_loss": 1.572165509223938, "actor_loss": -53.53481313705444, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.225334882736206, "step": 57000}
{"episode_reward": 20.53703614593018, "episode": 58.0, "batch_reward": 0.11943411829322577, "critic_loss": 1.545328576028347, "actor_loss": -53.43440656280517, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.56217622756958, "step": 58000}
{"episode_reward": 259.20263127088907, "episode": 59.0, "batch_reward": 0.12190491002053022, "critic_loss": 1.6919200962781906, "actor_loss": -52.76673363113403, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.524721384048462, "step": 59000}
{"episode_reward": 274.81225544962086, "episode": 60.0, "batch_reward": 0.12196763211488723, "critic_loss": 1.6932126038074493, "actor_loss": -52.82791981887817, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.936198711395264, "step": 60000}
{"episode_reward": 27.675808499935552, "episode": 61.0, "batch_reward": 0.12217002696543931, "critic_loss": 1.5782702685594558, "actor_loss": -52.638089511871335, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.26793313026428, "step": 61000}
{"episode_reward": 202.62193510639324, "episode": 62.0, "batch_reward": 0.12324800653755665, "critic_loss": 1.3625296481847764, "actor_loss": -53.00051229476929, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.19676947593689, "step": 62000}
{"episode_reward": 101.4534746724189, "episode": 63.0, "batch_reward": 0.12069539785385132, "critic_loss": 1.1584022934436797, "actor_loss": -51.53766661071777, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.14441990852356, "step": 63000}
{"episode_reward": 7.993600143307802, "episode": 64.0, "batch_reward": 0.11977588481456042, "critic_loss": 1.0900664096474648, "actor_loss": -51.2064319229126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.402200937271118, "step": 64000}
{"episode_reward": 18.891393845478614, "episode": 65.0, "batch_reward": 0.11806625950336457, "critic_loss": 0.9465455256104469, "actor_loss": -49.89858187103272, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.334615468978882, "step": 65000}
{"episode_reward": 24.1375422981124, "episode": 66.0, "batch_reward": 0.11820370074361562, "critic_loss": 0.9308595776557922, "actor_loss": -49.237264251708986, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.56525731086731, "step": 66000}
{"episode_reward": 356.12785468558155, "episode": 67.0, "batch_reward": 0.12213181936740876, "critic_loss": 0.9304940787255764, "actor_loss": -48.87005805969238, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.40520215034485, "step": 67000}
{"episode_reward": 408.9515651364499, "episode": 68.0, "batch_reward": 0.1273627290725708, "critic_loss": 0.8947345781624317, "actor_loss": -47.9100283241272, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.309407949447632, "step": 68000}
{"episode_reward": 462.6287249647942, "episode": 69.0, "batch_reward": 0.13140846616774798, "critic_loss": 0.8200680933892727, "actor_loss": -47.368920398712156, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.584161520004272, "step": 69000}
{"episode_reward": 415.6084043821628, "episode": 70.0, "batch_reward": 0.13512989044934512, "critic_loss": 0.9030970190167427, "actor_loss": -46.77924032592774, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.753365755081177, "step": 70000}
{"episode_reward": 216.84727973362087, "episode": 71.0, "batch_reward": 0.13666018576920033, "critic_loss": 0.9531013821363449, "actor_loss": -46.14086988067627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.960461378097534, "step": 71000}
{"episode_reward": 284.34519092353986, "episode": 72.0, "batch_reward": 0.13655288225412368, "critic_loss": 1.0089148066937923, "actor_loss": -45.19302719497681, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.34410262107849, "step": 72000}
{"episode_reward": 60.526515583579936, "episode": 73.0, "batch_reward": 0.13640181978791951, "critic_loss": 1.2986057434380054, "actor_loss": -44.32711771774292, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.710172176361084, "step": 73000}
{"episode_reward": 37.8406837782889, "episode": 74.0, "batch_reward": 0.13445333083719016, "critic_loss": 1.1576785305738448, "actor_loss": -43.835496620178226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.46779751777649, "step": 74000}
{"episode_reward": 28.29251284822154, "episode": 75.0, "batch_reward": 0.13364528403431178, "critic_loss": 1.1240330855250358, "actor_loss": -43.61869984436035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.159733057022095, "step": 75000}
{"episode_reward": 28.573689634869275, "episode": 76.0, "batch_reward": 0.13157707291841508, "critic_loss": 1.1709424644112587, "actor_loss": -43.86355871963501, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.977941274642944, "step": 76000}
{"episode_reward": 17.72251833846769, "episode": 77.0, "batch_reward": 0.13074697039276362, "critic_loss": 1.0861625555157661, "actor_loss": -43.10822431564331, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.34921956062317, "step": 77000}
{"episode_reward": 12.164587993132, "episode": 78.0, "batch_reward": 0.1290099770873785, "critic_loss": 0.8859773409366608, "actor_loss": -42.766835411071774, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.190058946609497, "step": 78000}
{"episode_reward": 30.032147002183997, "episode": 79.0, "batch_reward": 0.12723324076086281, "critic_loss": 0.7594922118782997, "actor_loss": -40.95272071456909, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.458110332489014, "step": 79000}
{"episode_reward": 11.706993799009576, "episode": 80.0, "batch_reward": 0.1247256338968873, "critic_loss": 0.684592262506485, "actor_loss": -40.60962855529785, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.667487859725952, "step": 80000}
{"episode_reward": 4.969132267340764, "episode": 81.0, "batch_reward": 0.1240096420198679, "critic_loss": 0.5914879451096058, "actor_loss": -39.621519466400144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.96263551712036, "step": 81000}
{"episode_reward": 28.265621309461153, "episode": 82.0, "batch_reward": 0.12335579623281956, "critic_loss": 0.5512301581203938, "actor_loss": -39.46163256454468, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.704214572906494, "step": 82000}
{"episode_reward": 31.220179731915046, "episode": 83.0, "batch_reward": 0.12193186361342669, "critic_loss": 0.5418715972602367, "actor_loss": -37.56585820770264, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.344166040420532, "step": 83000}
{"episode_reward": 43.84101157642886, "episode": 84.0, "batch_reward": 0.12063063396513463, "critic_loss": 0.49892373287677766, "actor_loss": -37.172421157836915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.545176029205322, "step": 84000}
{"episode_reward": 18.677777944487158, "episode": 85.0, "batch_reward": 0.12008770035207271, "critic_loss": 0.44300841468572616, "actor_loss": -35.90948652648926, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.67446231842041, "step": 85000}
{"episode_reward": 181.91677787761353, "episode": 86.0, "batch_reward": 0.12257065308839082, "critic_loss": 0.40938102307915686, "actor_loss": -35.366655673980716, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.08201313018799, "step": 86000}
{"episode_reward": 367.8089114464703, "episode": 87.0, "batch_reward": 0.1253673430159688, "critic_loss": 0.3943306804597378, "actor_loss": -34.882329742431644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.895530462265015, "step": 87000}
{"episode_reward": 426.4015817589034, "episode": 88.0, "batch_reward": 0.12679819925874472, "critic_loss": 0.36351549887657164, "actor_loss": -34.195690837860106, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.042868852615356, "step": 88000}
{"episode_reward": 31.070436919367474, "episode": 89.0, "batch_reward": 0.12619165916740893, "critic_loss": 0.3312326589077711, "actor_loss": -33.75992183303833, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.335116147994995, "step": 89000}
{"episode_reward": 22.0552616006325, "episode": 90.0, "batch_reward": 0.12700646191835405, "critic_loss": 0.3145556690096855, "actor_loss": -33.21221560287476, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.20455002784729, "step": 90000}
{"episode_reward": 425.8758662072156, "episode": 91.0, "batch_reward": 0.13053854109346866, "critic_loss": 0.28717712906002996, "actor_loss": -32.602996994018554, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.18756628036499, "step": 91000}
{"episode_reward": 444.2225599088057, "episode": 92.0, "batch_reward": 0.13339452295750379, "critic_loss": 0.28699863675236703, "actor_loss": -32.08157511901855, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.280632495880127, "step": 92000}
{"episode_reward": 475.35063054361774, "episode": 93.0, "batch_reward": 0.13727659484744073, "critic_loss": 0.2933352860361338, "actor_loss": -31.708216201782225, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.37432885169983, "step": 93000}
{"episode_reward": 407.4439812206784, "episode": 94.0, "batch_reward": 0.13999824230372906, "critic_loss": 0.2884224384129047, "actor_loss": -31.32081840133667, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.595395803451538, "step": 94000}
{"episode_reward": 572.0627329355355, "episode": 95.0, "batch_reward": 0.14500467735528946, "critic_loss": 0.28785207532346246, "actor_loss": -31.229371620178224, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.21479606628418, "step": 95000}
{"episode_reward": 540.4172617227662, "episode": 96.0, "batch_reward": 0.1494686780720949, "critic_loss": 0.2875885119438171, "actor_loss": -31.06781187057495, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.299198389053345, "step": 96000}
{"episode_reward": 541.5194061798616, "episode": 97.0, "batch_reward": 0.15367534226924182, "critic_loss": 0.27413574273884295, "actor_loss": -30.863390739440916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.060011863708496, "step": 97000}
{"episode_reward": 541.2186137583257, "episode": 98.0, "batch_reward": 0.15785049475729465, "critic_loss": 0.2644847645610571, "actor_loss": -30.76628424835205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.421372413635254, "step": 98000}
{"episode_reward": 538.7331668660904, "episode": 99.0, "batch_reward": 0.16110754928737878, "critic_loss": 0.2737731901854277, "actor_loss": -30.602435943603517, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.254581689834595, "step": 99000}
{"episode_reward": 541.5717583729097, "episode": 100.0, "batch_reward": 0.16546711456030608, "critic_loss": 0.2596132254451513, "actor_loss": -30.506561363220214, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.328067541122437, "step": 100000}
{"episode_reward": 539.4993208994424, "episode": 101.0, "batch_reward": 0.16817357859015464, "critic_loss": 0.24942518301308156, "actor_loss": -30.534550453186036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.743207931518555, "step": 101000}
{"episode_reward": 527.7071779952282, "episode": 102.0, "batch_reward": 0.1716028055176139, "critic_loss": 0.23561901964992285, "actor_loss": -30.286565143585204, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.24726128578186, "step": 102000}
{"episode_reward": 563.889536439231, "episode": 103.0, "batch_reward": 0.17609257420897484, "critic_loss": 0.23959986682236195, "actor_loss": -30.35294023513794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.44486951828003, "step": 103000}
{"episode_reward": 550.3834255563074, "episode": 104.0, "batch_reward": 0.18006546407938004, "critic_loss": 0.23730167307704686, "actor_loss": -30.1848246383667, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.2772798538208, "step": 104000}
{"episode_reward": 536.7895095077142, "episode": 105.0, "batch_reward": 0.18270359075814485, "critic_loss": 0.2417803983837366, "actor_loss": -30.00763204956055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.520262002944946, "step": 105000}
{"episode_reward": 199.71757885527387, "episode": 106.0, "batch_reward": 0.1829212423413992, "critic_loss": 0.24319594513624906, "actor_loss": -29.886662761688232, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.16614294052124, "step": 106000}
{"episode_reward": 532.1598271705532, "episode": 107.0, "batch_reward": 0.18563333792984485, "critic_loss": 0.24823963019251824, "actor_loss": -29.72730280303955, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.249268770217896, "step": 107000}
{"episode_reward": 276.98385887598613, "episode": 108.0, "batch_reward": 0.18690289574861527, "critic_loss": 0.28895012935996056, "actor_loss": -29.611774932861326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.16340160369873, "step": 108000}
{"episode_reward": 526.2606095344877, "episode": 109.0, "batch_reward": 0.19015102426707745, "critic_loss": 0.26575817284733055, "actor_loss": -29.316725902557373, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.65419888496399, "step": 109000}
{"episode_reward": 253.76788072373745, "episode": 110.0, "batch_reward": 0.19126408912241458, "critic_loss": 0.31987599447369575, "actor_loss": -29.25320603942871, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.29674220085144, "step": 110000}
{"episode_reward": 488.2039120478197, "episode": 111.0, "batch_reward": 0.192830722078681, "critic_loss": 0.28582545153796673, "actor_loss": -29.209798065185545, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.2292046546936, "step": 111000}
{"episode_reward": 536.7260545015487, "episode": 112.0, "batch_reward": 0.19593296594917775, "critic_loss": 0.28654107014089825, "actor_loss": -29.44122589111328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.752484798431396, "step": 112000}
{"episode_reward": 492.1264518824271, "episode": 113.0, "batch_reward": 0.1995172157138586, "critic_loss": 0.28309287421405316, "actor_loss": -29.519018634796144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.376882076263428, "step": 113000}
{"episode_reward": 593.5950582571254, "episode": 114.0, "batch_reward": 0.20390231262147426, "critic_loss": 0.23861329602450132, "actor_loss": -29.553730934143065, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.978386163711548, "step": 114000}
{"episode_reward": 601.045000155282, "episode": 115.0, "batch_reward": 0.20664056204259396, "critic_loss": 0.25696347090601923, "actor_loss": -29.670870944976805, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.146592140197754, "step": 115000}
{"episode_reward": 565.989553896397, "episode": 116.0, "batch_reward": 0.2098285993486643, "critic_loss": 0.229848277926445, "actor_loss": -29.707788036346436, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.279411792755127, "step": 116000}
{"episode_reward": 612.2227478336019, "episode": 117.0, "batch_reward": 0.213125984236598, "critic_loss": 0.24217608797550202, "actor_loss": -30.00784300994873, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.17440128326416, "step": 117000}
{"episode_reward": 458.1212526160427, "episode": 118.0, "batch_reward": 0.21542915773391724, "critic_loss": 0.23833509352058171, "actor_loss": -29.751952060699463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.109598398208618, "step": 118000}
{"episode_reward": 292.73227086834834, "episode": 119.0, "batch_reward": 0.21620312058925628, "critic_loss": 0.2640386612191796, "actor_loss": -29.812753589630127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.209417819976807, "step": 119000}
{"episode_reward": 395.51131673177656, "episode": 120.0, "batch_reward": 0.21659496860206126, "critic_loss": 0.2767315527945757, "actor_loss": -29.48687741088867, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.288651943206787, "step": 120000}
{"episode_reward": 268.9445053627527, "episode": 121.0, "batch_reward": 0.21893070890009403, "critic_loss": 0.30007545982301237, "actor_loss": -29.546696353912353, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.340086698532104, "step": 121000}
{"episode_reward": 527.3081788498706, "episode": 122.0, "batch_reward": 0.21992848919332028, "critic_loss": 0.3175591458529234, "actor_loss": -29.57527983856201, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.113747119903564, "step": 122000}
{"episode_reward": 550.933723988495, "episode": 123.0, "batch_reward": 0.22356795266270638, "critic_loss": 0.2961758274063468, "actor_loss": -29.851499614715575, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.15652084350586, "step": 123000}
{"episode_reward": 552.2615156469988, "episode": 124.0, "batch_reward": 0.22464538688957691, "critic_loss": 0.2903622099235654, "actor_loss": -29.791035533905028, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.477166175842285, "step": 124000}
{"episode_reward": 616.0080028891912, "episode": 125.0, "batch_reward": 0.22859050585329532, "critic_loss": 0.31726105374097824, "actor_loss": -29.982478584289552, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.890642404556274, "step": 125000}
{"episode_reward": 555.3198153656008, "episode": 126.0, "batch_reward": 0.23207072472572327, "critic_loss": 0.3431337974220514, "actor_loss": -30.315410346984862, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.1613347530365, "step": 126000}
{"episode_reward": 593.5660708422371, "episode": 127.0, "batch_reward": 0.2340392510294914, "critic_loss": 0.3023053633570671, "actor_loss": -30.096285858154296, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.060903787612915, "step": 127000}
{"episode_reward": 611.3903156466018, "episode": 128.0, "batch_reward": 0.23729546163976192, "critic_loss": 0.34793515715003015, "actor_loss": -29.98511569213867, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.240501403808594, "step": 128000}
{"episode_reward": 601.8768659342923, "episode": 129.0, "batch_reward": 0.24003535689413547, "critic_loss": 0.31060177186131477, "actor_loss": -30.34942541503906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.335885524749756, "step": 129000}
{"episode_reward": 577.1374368089046, "episode": 130.0, "batch_reward": 0.24195631735026837, "critic_loss": 0.3074838240593672, "actor_loss": -30.504917419433593, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.06568479537964, "step": 130000}
{"episode_reward": 514.9484826227131, "episode": 131.0, "batch_reward": 0.24538228951394558, "critic_loss": 0.33718038080632684, "actor_loss": -30.571060901641847, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.17343735694885, "step": 131000}
{"episode_reward": 607.0484462029211, "episode": 132.0, "batch_reward": 0.2487397872954607, "critic_loss": 0.3365572270452976, "actor_loss": -30.66716304397583, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.014519214630127, "step": 132000}
{"episode_reward": 565.8631455619214, "episode": 133.0, "batch_reward": 0.2503090945929289, "critic_loss": 0.2676161462664604, "actor_loss": -31.002660671234132, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.215606451034546, "step": 133000}
{"episode_reward": 612.4109896182284, "episode": 134.0, "batch_reward": 0.2520125769525766, "critic_loss": 0.2809239369928837, "actor_loss": -31.000646308898926, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.206101179122925, "step": 134000}
{"episode_reward": 582.0985301275231, "episode": 135.0, "batch_reward": 0.25524404445290566, "critic_loss": 0.2892389225438237, "actor_loss": -31.213811332702637, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.057605743408203, "step": 135000}
{"episode_reward": 584.7378692596194, "episode": 136.0, "batch_reward": 0.25748766292631625, "critic_loss": 0.30071557304263113, "actor_loss": -31.171305896759034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.61999535560608, "step": 136000}
{"episode_reward": 609.4272964090644, "episode": 137.0, "batch_reward": 0.259633579492569, "critic_loss": 0.28074001463502646, "actor_loss": -31.579442390441894, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.425886154174805, "step": 137000}
{"episode_reward": 578.5099762529206, "episode": 138.0, "batch_reward": 0.26320950290560724, "critic_loss": 0.2610531680136919, "actor_loss": -32.18049510574341, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.440443754196167, "step": 138000}
{"episode_reward": 610.3983968047734, "episode": 139.0, "batch_reward": 0.264726179048419, "critic_loss": 0.29969507079571484, "actor_loss": -32.162510112762455, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.192957639694214, "step": 139000}
{"episode_reward": 573.108284914361, "episode": 140.0, "batch_reward": 0.2660145724415779, "critic_loss": 0.2887939557880163, "actor_loss": -32.299318161010746, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.24096441268921, "step": 140000}
{"episode_reward": 579.8775695741081, "episode": 141.0, "batch_reward": 0.2694886800795794, "critic_loss": 0.3013275994062424, "actor_loss": -32.37188920593262, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.38314890861511, "step": 141000}
{"episode_reward": 632.7265826344346, "episode": 142.0, "batch_reward": 0.27281090611219405, "critic_loss": 0.2802772838920355, "actor_loss": -32.41948337173462, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.941786766052246, "step": 142000}
{"episode_reward": 617.5699045650814, "episode": 143.0, "batch_reward": 0.2738790437877178, "critic_loss": 0.2752526661604643, "actor_loss": -32.47813235092163, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.578600645065308, "step": 143000}
{"episode_reward": 548.6068203783127, "episode": 144.0, "batch_reward": 0.2781038095206022, "critic_loss": 0.2913040932714939, "actor_loss": -32.88013935852051, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.246421813964844, "step": 144000}
{"episode_reward": 617.8843825482686, "episode": 145.0, "batch_reward": 0.2803626248091459, "critic_loss": 0.2783459124863148, "actor_loss": -32.95990905380249, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.725127696990967, "step": 145000}
{"episode_reward": 637.0908579863574, "episode": 146.0, "batch_reward": 0.280156445518136, "critic_loss": 0.3082973499745131, "actor_loss": -33.118068313598634, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.90764832496643, "step": 146000}
{"episode_reward": 269.55087896675747, "episode": 147.0, "batch_reward": 0.28012982119619845, "critic_loss": 0.30129776081442833, "actor_loss": -32.765557163238526, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.632386445999146, "step": 147000}
{"episode_reward": 616.6031468037523, "episode": 148.0, "batch_reward": 0.2846907231062651, "critic_loss": 0.30123923256248236, "actor_loss": -33.3452508354187, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.98668122291565, "step": 148000}
{"episode_reward": 632.7488986999905, "episode": 149.0, "batch_reward": 0.286108223259449, "critic_loss": 0.3235871533975005, "actor_loss": -33.42264446258545, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.398908138275146, "step": 149000}
{"episode_reward": 617.8759746221922, "episode": 150.0, "batch_reward": 0.28839964857697487, "critic_loss": 0.3002026735842228, "actor_loss": -33.860640392303466, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
