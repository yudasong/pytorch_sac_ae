{"episode_reward": 0.0, "episode": 1.0, "duration": 17.565694570541382, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.5769226551055908, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.28155227267332733, "critic_loss": 0.15380012261873485, "actor_loss": -47.29858015746582, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 62.39671230316162, "step": 3000}
{"episode_reward": 23.353647683742143, "episode": 4.0, "batch_reward": 0.19553993164002895, "critic_loss": 0.14271343445777893, "actor_loss": -38.34547612380982, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.378421306610107, "step": 4000}
{"episode_reward": 94.78477201930176, "episode": 5.0, "batch_reward": 0.16854954914748668, "critic_loss": 0.1466326131299138, "actor_loss": -35.975115787506105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.064123392105103, "step": 5000}
{"episode_reward": 91.09891012910849, "episode": 6.0, "batch_reward": 0.1541697982698679, "critic_loss": 0.16925927490741013, "actor_loss": -36.129051471710206, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.20760154724121, "step": 6000}
{"episode_reward": 134.6708414947161, "episode": 7.0, "batch_reward": 0.15304475221782923, "critic_loss": 0.18448508719354867, "actor_loss": -35.913557792663575, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.72355842590332, "step": 7000}
{"episode_reward": 74.900909208904, "episode": 8.0, "batch_reward": 0.1433410270512104, "critic_loss": 0.18193778944015504, "actor_loss": -33.44637043762207, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.433700799942017, "step": 8000}
{"episode_reward": 75.42141024594169, "episode": 9.0, "batch_reward": 0.13130967050045728, "critic_loss": 0.19503730817139148, "actor_loss": -31.638113689422607, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.404091596603394, "step": 9000}
{"episode_reward": 74.65147299948366, "episode": 10.0, "batch_reward": 0.1345580613836646, "critic_loss": 0.2418453656435013, "actor_loss": -32.05325675201416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.197725534439087, "step": 10000}
{"episode_reward": 173.2715244503202, "episode": 11.0, "batch_reward": 0.1369891898408532, "critic_loss": 0.25529645921289923, "actor_loss": -31.713601524353027, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.8835244178772, "step": 11000}
{"episode_reward": 175.6692835131273, "episode": 12.0, "batch_reward": 0.141739598877728, "critic_loss": 0.25743177518248556, "actor_loss": -32.12359130859375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.984668970108032, "step": 12000}
{"episode_reward": 268.4093881120861, "episode": 13.0, "batch_reward": 0.1507013225108385, "critic_loss": 0.26721858376264573, "actor_loss": -32.44170379638672, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.03784704208374, "step": 13000}
{"episode_reward": 134.57044126797254, "episode": 14.0, "batch_reward": 0.14299892971664668, "critic_loss": 0.24411455862224102, "actor_loss": -30.94547864151001, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.01880121231079, "step": 14000}
{"episode_reward": 29.727713705612853, "episode": 15.0, "batch_reward": 0.14358312363922596, "critic_loss": 0.2582663518190384, "actor_loss": -30.750971611022948, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.976696729660034, "step": 15000}
{"episode_reward": 310.8367564484043, "episode": 16.0, "batch_reward": 0.15624419913440943, "critic_loss": 0.3036801514923573, "actor_loss": -31.980661613464356, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.773447036743164, "step": 16000}
{"episode_reward": 392.5711902787612, "episode": 17.0, "batch_reward": 0.17271454752981663, "critic_loss": 0.33960726799070834, "actor_loss": -33.55618799591065, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.358204126358032, "step": 17000}
{"episode_reward": 447.81961689589934, "episode": 18.0, "batch_reward": 0.18843295693397522, "critic_loss": 0.30310788993537424, "actor_loss": -34.85276427841187, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.02703356742859, "step": 18000}
{"episode_reward": 444.06106947351657, "episode": 19.0, "batch_reward": 0.19937500490248203, "critic_loss": 0.302830730587244, "actor_loss": -35.584565853118896, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.967089891433716, "step": 19000}
{"episode_reward": 344.6928214208987, "episode": 20.0, "batch_reward": 0.20888700051605702, "critic_loss": 0.2798545856177807, "actor_loss": -36.28456962966919, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.1616108417511, "step": 20000}
{"episode_reward": 427.9215787348069, "episode": 21.0, "batch_reward": 0.21630531722307206, "critic_loss": 0.31022996580600737, "actor_loss": -36.5385203704834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.929192543029785, "step": 21000}
{"episode_reward": 182.57903160368426, "episode": 22.0, "batch_reward": 0.21769057615101337, "critic_loss": 0.283759410366416, "actor_loss": -36.157990447998046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.34459614753723, "step": 22000}
{"episode_reward": 383.19484752012403, "episode": 23.0, "batch_reward": 0.2258991148173809, "critic_loss": 0.26337112414836883, "actor_loss": -36.33686724853516, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.42350721359253, "step": 23000}
{"episode_reward": 308.3131003314439, "episode": 24.0, "batch_reward": 0.22990354834496976, "critic_loss": 0.2695160268843174, "actor_loss": -36.33598336791992, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.6074275970459, "step": 24000}
{"episode_reward": 396.69735088141226, "episode": 25.0, "batch_reward": 0.2331417374908924, "critic_loss": 0.2768700837492943, "actor_loss": -35.86758841705322, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.013328790664673, "step": 25000}
{"episode_reward": 179.22014441977564, "episode": 26.0, "batch_reward": 0.22731261979043485, "critic_loss": 0.3240199803858995, "actor_loss": -35.47548354721069, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.148322820663452, "step": 26000}
{"episode_reward": 214.17621561159118, "episode": 27.0, "batch_reward": 0.2335505395233631, "critic_loss": 0.3121466768682003, "actor_loss": -35.90752013397217, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.05519151687622, "step": 27000}
{"episode_reward": 481.7382541373236, "episode": 28.0, "batch_reward": 0.23808986732363702, "critic_loss": 0.30504682566225527, "actor_loss": -36.131201774597166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.016721725463867, "step": 28000}
{"episode_reward": 289.32702277047946, "episode": 29.0, "batch_reward": 0.24163973160088062, "critic_loss": 0.2704309813082218, "actor_loss": -36.01382270812988, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.685978174209595, "step": 29000}
{"episode_reward": 152.9366631813222, "episode": 30.0, "batch_reward": 0.24141379038989544, "critic_loss": 0.23981928022205828, "actor_loss": -35.50594598388672, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.298229932785034, "step": 30000}
{"episode_reward": 414.85543969563474, "episode": 31.0, "batch_reward": 0.24303159694373608, "critic_loss": 0.22639787463843822, "actor_loss": -35.34837744522095, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.720807790756226, "step": 31000}
{"episode_reward": 330.6599586072064, "episode": 32.0, "batch_reward": 0.2443601228147745, "critic_loss": 0.22025467495620252, "actor_loss": -35.45002703857422, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.481956005096436, "step": 32000}
{"episode_reward": 226.5206170136329, "episode": 33.0, "batch_reward": 0.24911003749072552, "critic_loss": 0.22271076425909997, "actor_loss": -35.51114326858521, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.43081760406494, "step": 33000}
{"episode_reward": 535.3909196937146, "episode": 34.0, "batch_reward": 0.2571954186856747, "critic_loss": 0.224879732131958, "actor_loss": -35.760352867126464, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.972841024398804, "step": 34000}
{"episode_reward": 496.74759421694046, "episode": 35.0, "batch_reward": 0.26466796137392523, "critic_loss": 0.24252629658579827, "actor_loss": -36.246614459991456, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.277629852294922, "step": 35000}
{"episode_reward": 553.2911013405493, "episode": 36.0, "batch_reward": 0.2721096271127462, "critic_loss": 0.24663903293013573, "actor_loss": -36.64088181304932, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.82889223098755, "step": 36000}
{"episode_reward": 322.0851061719308, "episode": 37.0, "batch_reward": 0.26971062003076074, "critic_loss": 0.25710585387051105, "actor_loss": -35.84052408218384, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.003636598587036, "step": 37000}
{"episode_reward": 166.20767218630937, "episode": 38.0, "batch_reward": 0.2697358178794384, "critic_loss": 0.2719445193260908, "actor_loss": -35.479339012146, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.533658266067505, "step": 38000}
{"episode_reward": 255.87388493654046, "episode": 39.0, "batch_reward": 0.2725508297234774, "critic_loss": 0.28242497746646406, "actor_loss": -35.84718259048462, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.94920825958252, "step": 39000}
{"episode_reward": 593.9059133263281, "episode": 40.0, "batch_reward": 0.2792360735088587, "critic_loss": 0.2710941861867905, "actor_loss": -36.29000595474243, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.98938536643982, "step": 40000}
{"episode_reward": 590.7671579275602, "episode": 41.0, "batch_reward": 0.2870356763154268, "critic_loss": 0.2838610270619392, "actor_loss": -36.8568480796814, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.977736473083496, "step": 41000}
{"episode_reward": 550.6260349961422, "episode": 42.0, "batch_reward": 0.2940878338366747, "critic_loss": 0.2664027995467186, "actor_loss": -37.104225494384764, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.439784288406372, "step": 42000}
{"episode_reward": 466.34070963487, "episode": 43.0, "batch_reward": 0.2972848991006613, "critic_loss": 0.2597673959732056, "actor_loss": -37.43475514984131, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.027815580368042, "step": 43000}
{"episode_reward": 583.3000298609057, "episode": 44.0, "batch_reward": 0.3042978210747242, "critic_loss": 0.25351792912185195, "actor_loss": -38.02903502655029, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.425816535949707, "step": 44000}
{"episode_reward": 616.1055697345004, "episode": 45.0, "batch_reward": 0.311793173789978, "critic_loss": 0.2472328485995531, "actor_loss": -38.592422538757326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.058069467544556, "step": 45000}
{"episode_reward": 621.2362482625315, "episode": 46.0, "batch_reward": 0.3171519743800163, "critic_loss": 0.237902207583189, "actor_loss": -38.990378837585446, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.983120918273926, "step": 46000}
{"episode_reward": 592.5240138278847, "episode": 47.0, "batch_reward": 0.32585316282510757, "critic_loss": 0.2422978862375021, "actor_loss": -39.40295212173462, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.103971242904663, "step": 47000}
{"episode_reward": 600.1399218997536, "episode": 48.0, "batch_reward": 0.32922102546691895, "critic_loss": 0.24520336191356182, "actor_loss": -39.54421339416504, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.40086841583252, "step": 48000}
{"episode_reward": 508.58588200199, "episode": 49.0, "batch_reward": 0.3334913500547409, "critic_loss": 0.2557513012290001, "actor_loss": -39.81697138214111, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.99831199645996, "step": 49000}
{"episode_reward": 556.4315444335075, "episode": 50.0, "batch_reward": 0.33718805107474326, "critic_loss": 0.2555427635163069, "actor_loss": -40.10107099151611, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.510162353515625, "step": 50000}
{"episode_reward": 565.9223064397468, "episode": 51.0, "batch_reward": 0.3424897463023663, "critic_loss": 0.2567544662356377, "actor_loss": -40.32761814117432, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.540815591812134, "step": 51000}
{"episode_reward": 588.9510928762161, "episode": 52.0, "batch_reward": 0.34755413568019866, "critic_loss": 0.25724918286502363, "actor_loss": -40.97214598083496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.024187326431274, "step": 52000}
{"episode_reward": 578.6738225032203, "episode": 53.0, "batch_reward": 0.35253790000081064, "critic_loss": 0.2590767257809639, "actor_loss": -41.212224227905274, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.872051239013672, "step": 53000}
{"episode_reward": 643.1390121178603, "episode": 54.0, "batch_reward": 0.35778399541974065, "critic_loss": 0.25274896901845934, "actor_loss": -41.47388193511963, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.34124493598938, "step": 54000}
{"episode_reward": 601.6245967355163, "episode": 55.0, "batch_reward": 0.36175162574648856, "critic_loss": 0.2585517110526562, "actor_loss": -41.72418798828125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.25754976272583, "step": 55000}
{"episode_reward": 431.7666021778429, "episode": 56.0, "batch_reward": 0.36333685463666915, "critic_loss": 0.2612290005683899, "actor_loss": -41.763277572631836, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.610069274902344, "step": 56000}
{"episode_reward": 623.7418841291036, "episode": 57.0, "batch_reward": 0.3684024474918842, "critic_loss": 0.2739816946089268, "actor_loss": -42.1550669631958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.416883945465088, "step": 57000}
{"episode_reward": 397.51923584493886, "episode": 58.0, "batch_reward": 0.3695009243786335, "critic_loss": 0.2607301278859377, "actor_loss": -41.93778344726562, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.08274555206299, "step": 58000}
{"episode_reward": 635.1105574042832, "episode": 59.0, "batch_reward": 0.37294474494457247, "critic_loss": 0.2763376729935408, "actor_loss": -42.471955192565915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96868324279785, "step": 59000}
{"episode_reward": 554.9793582430804, "episode": 60.0, "batch_reward": 0.3758527520596981, "critic_loss": 0.2783434903621674, "actor_loss": -42.61236511230469, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.97439217567444, "step": 60000}
{"episode_reward": 530.816232702892, "episode": 61.0, "batch_reward": 0.3787676045000553, "critic_loss": 0.28722185765206815, "actor_loss": -42.60974713134765, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.95615482330322, "step": 61000}
{"episode_reward": 595.7047485623884, "episode": 62.0, "batch_reward": 0.3791896948516369, "critic_loss": 0.2906551636010408, "actor_loss": -42.47828968811035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.855396509170532, "step": 62000}
{"episode_reward": 522.608213342382, "episode": 63.0, "batch_reward": 0.38291927140951154, "critic_loss": 0.2721705069541931, "actor_loss": -42.976749336242676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.346642017364502, "step": 63000}
{"episode_reward": 620.1743215492825, "episode": 64.0, "batch_reward": 0.387464429885149, "critic_loss": 0.2976995252966881, "actor_loss": -43.28480055999756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.044942140579224, "step": 64000}
{"episode_reward": 653.6572787613094, "episode": 65.0, "batch_reward": 0.3917955152988434, "critic_loss": 0.29038739784061907, "actor_loss": -43.59418880462646, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.384621381759644, "step": 65000}
{"episode_reward": 651.0073311356423, "episode": 66.0, "batch_reward": 0.39673667418956754, "critic_loss": 0.2900415666848421, "actor_loss": -43.90188137054443, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.310174226760864, "step": 66000}
{"episode_reward": 648.4067832330128, "episode": 67.0, "batch_reward": 0.39975753700733185, "critic_loss": 0.2841962419599295, "actor_loss": -44.498606758117674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.66003942489624, "step": 67000}
{"episode_reward": 613.2653692155233, "episode": 68.0, "batch_reward": 0.40327123713493346, "critic_loss": 0.2912504506409168, "actor_loss": -44.419263298034664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.98763656616211, "step": 68000}
{"episode_reward": 544.694948268758, "episode": 69.0, "batch_reward": 0.404567246645689, "critic_loss": 0.3961223177164793, "actor_loss": -44.65831317901611, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.07236099243164, "step": 69000}
{"episode_reward": 590.1329881962208, "episode": 70.0, "batch_reward": 0.4041725567877293, "critic_loss": 0.48044949470460413, "actor_loss": -44.85334673309326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.981945514678955, "step": 70000}
{"episode_reward": 102.91008037660396, "episode": 71.0, "batch_reward": 0.4011005392372608, "critic_loss": 0.5191781301647425, "actor_loss": -44.9609536819458, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.993602991104126, "step": 71000}
{"episode_reward": 10.799584046510603, "episode": 72.0, "batch_reward": 0.3968214603662491, "critic_loss": 0.5185974870175123, "actor_loss": -45.027070945739744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.47851252555847, "step": 72000}
{"episode_reward": 340.48362211922324, "episode": 73.0, "batch_reward": 0.39321973076462746, "critic_loss": 0.4946480084806681, "actor_loss": -44.95715871429444, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.26545810699463, "step": 73000}
{"episode_reward": 30.750032719934097, "episode": 74.0, "batch_reward": 0.3916116193830967, "critic_loss": 0.5070938385725021, "actor_loss": -44.978564125061034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.016414165496826, "step": 74000}
{"episode_reward": 265.0122371717614, "episode": 75.0, "batch_reward": 0.387798348814249, "critic_loss": 0.5953991549313068, "actor_loss": -44.86183827209473, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.86058521270752, "step": 75000}
{"episode_reward": 319.59434082190995, "episode": 76.0, "batch_reward": 0.388755400121212, "critic_loss": 0.6552397154271603, "actor_loss": -45.1726887588501, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.951339960098267, "step": 76000}
{"episode_reward": 511.65944442900667, "episode": 77.0, "batch_reward": 0.3875830504596233, "critic_loss": 0.7513313433229923, "actor_loss": -45.18197664642334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.003433227539062, "step": 77000}
{"episode_reward": 16.41192208430957, "episode": 78.0, "batch_reward": 0.3837125728428364, "critic_loss": 0.7224544552266597, "actor_loss": -45.18050552368164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.405529022216797, "step": 78000}
{"episode_reward": 8.82047866250075, "episode": 79.0, "batch_reward": 0.37851043114066124, "critic_loss": 0.6914707760214805, "actor_loss": -45.004503982543945, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.398648738861084, "step": 79000}
{"episode_reward": 13.085575403743526, "episode": 80.0, "batch_reward": 0.37271876430511475, "critic_loss": 0.6882494026124477, "actor_loss": -44.66193168640137, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.130239248275757, "step": 80000}
{"episode_reward": 24.002755938128097, "episode": 81.0, "batch_reward": 0.36887669342756274, "critic_loss": 0.6791004070341587, "actor_loss": -44.6995757522583, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.18005394935608, "step": 81000}
{"episode_reward": 9.511137121959953, "episode": 82.0, "batch_reward": 0.36447091394662856, "critic_loss": 0.7204255700409412, "actor_loss": -44.52113459777832, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.59288501739502, "step": 82000}
{"episode_reward": 2.164287618592015, "episode": 83.0, "batch_reward": 0.3596856028139591, "critic_loss": 0.7537709891796112, "actor_loss": -44.48361260223389, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.04491400718689, "step": 83000}
{"episode_reward": 12.726061478584253, "episode": 84.0, "batch_reward": 0.3562045169770718, "critic_loss": 0.7053907618820667, "actor_loss": -44.33065868377685, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.32785654067993, "step": 84000}
{"episode_reward": 7.185053008267487, "episode": 85.0, "batch_reward": 0.35012781220674516, "critic_loss": 0.7048405020236969, "actor_loss": -43.98211376190186, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.102240085601807, "step": 85000}
{"episode_reward": 8.307238801083697, "episode": 86.0, "batch_reward": 0.347738191395998, "critic_loss": 0.7077166042029858, "actor_loss": -43.70089113616943, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.061301946640015, "step": 86000}
{"episode_reward": 4.564401702249092, "episode": 87.0, "batch_reward": 0.34432534262537956, "critic_loss": 0.7943632043302059, "actor_loss": -43.635504623413084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.764885902404785, "step": 87000}
{"episode_reward": 4.499454710602825, "episode": 88.0, "batch_reward": 0.3409035472869873, "critic_loss": 1.2372210720479488, "actor_loss": -43.59805047607422, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.143739461898804, "step": 88000}
{"episode_reward": 13.447712180584686, "episode": 89.0, "batch_reward": 0.3362355282008648, "critic_loss": 1.7631399131417274, "actor_loss": -44.31810696411133, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.991211652755737, "step": 89000}
{"episode_reward": 6.218237761264026, "episode": 90.0, "batch_reward": 0.33284098395705225, "critic_loss": 2.739769285440445, "actor_loss": -46.219176803588866, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.456042528152466, "step": 90000}
{"episode_reward": 19.363188979766463, "episode": 91.0, "batch_reward": 0.32956105268001556, "critic_loss": 3.6742781178951263, "actor_loss": -48.24228318023682, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.514304637908936, "step": 91000}
{"episode_reward": 14.814188402655546, "episode": 92.0, "batch_reward": 0.3278536633849144, "critic_loss": 4.53990643286705, "actor_loss": -49.547199256896974, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.94015622138977, "step": 92000}
{"episode_reward": 11.268307088014463, "episode": 93.0, "batch_reward": 0.32172520500421525, "critic_loss": 5.387320278406143, "actor_loss": -52.103053413391116, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.146826028823853, "step": 93000}
{"episode_reward": 6.568692349176041, "episode": 94.0, "batch_reward": 0.31770133118331434, "critic_loss": 5.6388981306552886, "actor_loss": -53.77983818817139, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.20066809654236, "step": 94000}
{"episode_reward": 5.300029537638349, "episode": 95.0, "batch_reward": 0.3151367644369602, "critic_loss": 5.869297356128692, "actor_loss": -55.4333808517456, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.158395290374756, "step": 95000}
{"episode_reward": 9.696329298633447, "episode": 96.0, "batch_reward": 0.3121183031052351, "critic_loss": 6.1594419882297515, "actor_loss": -56.770054656982424, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.535043954849243, "step": 96000}
{"episode_reward": 18.907223382411775, "episode": 97.0, "batch_reward": 0.31080205607414246, "critic_loss": 6.740741798639298, "actor_loss": -58.45248303222656, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.37065315246582, "step": 97000}
{"episode_reward": 23.51782096095678, "episode": 98.0, "batch_reward": 0.30814187817275523, "critic_loss": 7.253780258655548, "actor_loss": -59.21481024169922, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.54143452644348, "step": 98000}
{"episode_reward": 36.46098493428917, "episode": 99.0, "batch_reward": 0.30228947748243806, "critic_loss": 7.132442738771439, "actor_loss": -60.23507633972168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.030073165893555, "step": 99000}
{"episode_reward": 22.86876594474079, "episode": 100.0, "batch_reward": 0.30293861366808417, "critic_loss": 6.72674830698967, "actor_loss": -61.44887197113037, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.731606245040894, "step": 100000}
{"episode_reward": 86.38553113412726, "episode": 101.0, "batch_reward": 0.2996976883113384, "critic_loss": 6.174334385871887, "actor_loss": -60.73097103881836, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.28379559516907, "step": 101000}
{"episode_reward": 23.99625238352119, "episode": 102.0, "batch_reward": 0.2977014452815056, "critic_loss": 5.800545922994614, "actor_loss": -61.560763687133786, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.082882165908813, "step": 102000}
{"episode_reward": 329.7964392796621, "episode": 103.0, "batch_reward": 0.29828579659759996, "critic_loss": 5.298867913722992, "actor_loss": -62.359145187377926, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.448615789413452, "step": 103000}
{"episode_reward": 283.6984374298212, "episode": 104.0, "batch_reward": 0.29743652023375033, "critic_loss": 4.651808572053909, "actor_loss": -63.19140431213379, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.207637071609497, "step": 104000}
{"episode_reward": 255.25469304745343, "episode": 105.0, "batch_reward": 0.2980973954498768, "critic_loss": 3.9172332223653794, "actor_loss": -64.41317138671874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.11899423599243, "step": 105000}
{"episode_reward": 229.7088352304401, "episode": 106.0, "batch_reward": 0.2955139598697424, "critic_loss": 3.718541718006134, "actor_loss": -64.79038455963135, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.67283296585083, "step": 106000}
{"episode_reward": 140.34067686350278, "episode": 107.0, "batch_reward": 0.29405472289025786, "critic_loss": 3.1627134791612623, "actor_loss": -63.76039012908936, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.234269380569458, "step": 107000}
{"episode_reward": 223.02636189542767, "episode": 108.0, "batch_reward": 0.29576674538850783, "critic_loss": 2.700137509465218, "actor_loss": -62.94428343963623, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.022738456726074, "step": 108000}
{"episode_reward": 266.0109574283753, "episode": 109.0, "batch_reward": 0.2926672272980213, "critic_loss": 2.4186938792467116, "actor_loss": -62.36740592193603, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.997819900512695, "step": 109000}
{"episode_reward": 37.15133479053637, "episode": 110.0, "batch_reward": 0.2906940052211285, "critic_loss": 2.126319207370281, "actor_loss": -61.852727363586425, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.922558307647705, "step": 110000}
{"episode_reward": 35.601407937387194, "episode": 111.0, "batch_reward": 0.288477764159441, "critic_loss": 1.9760273541212081, "actor_loss": -60.91848904418946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.08807039260864, "step": 111000}
{"episode_reward": 6.849001975648612, "episode": 112.0, "batch_reward": 0.2859682434648275, "critic_loss": 1.701183322429657, "actor_loss": -60.19567778778076, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.007526636123657, "step": 112000}
{"episode_reward": 23.135551303540854, "episode": 113.0, "batch_reward": 0.28480121119320395, "critic_loss": 1.3983834741711616, "actor_loss": -59.350250831604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.935276985168457, "step": 113000}
{"episode_reward": 20.397644288003093, "episode": 114.0, "batch_reward": 0.2807647190093994, "critic_loss": 1.2952575285434722, "actor_loss": -58.18473677062988, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.154037714004517, "step": 114000}
{"episode_reward": 52.90432387952353, "episode": 115.0, "batch_reward": 0.2808548493236303, "critic_loss": 1.1492604909539224, "actor_loss": -58.45208324432373, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.01722002029419, "step": 115000}
{"episode_reward": 226.53987443341995, "episode": 116.0, "batch_reward": 0.27894395266473293, "critic_loss": 1.1810958431363106, "actor_loss": -57.13529151916504, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.44322371482849, "step": 116000}
{"episode_reward": 136.8051713777328, "episode": 117.0, "batch_reward": 0.27743337336182594, "critic_loss": 1.1814141296446323, "actor_loss": -55.7965719833374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.424818992614746, "step": 117000}
{"episode_reward": 387.863844686536, "episode": 118.0, "batch_reward": 0.279743311971426, "critic_loss": 1.0924143444299699, "actor_loss": -54.705294586181644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.73639726638794, "step": 118000}
{"episode_reward": 388.22385869485566, "episode": 119.0, "batch_reward": 0.28027726289629934, "critic_loss": 1.071656340956688, "actor_loss": -54.89153818511963, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.0077645778656, "step": 119000}
{"episode_reward": 397.2287207337485, "episode": 120.0, "batch_reward": 0.28009682850539686, "critic_loss": 0.9144064663350582, "actor_loss": -54.01721969604492, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.359721899032593, "step": 120000}
{"episode_reward": 417.42207893617444, "episode": 121.0, "batch_reward": 0.283725326448679, "critic_loss": 0.8924666478335858, "actor_loss": -53.52677851867676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.662713289260864, "step": 121000}
{"episode_reward": 565.6790205431253, "episode": 122.0, "batch_reward": 0.2856575819551945, "critic_loss": 0.8135488564372063, "actor_loss": -52.50250986480713, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.951775789260864, "step": 122000}
{"episode_reward": 434.59410837187176, "episode": 123.0, "batch_reward": 0.2872326083779335, "critic_loss": 0.7602072348892689, "actor_loss": -51.4973412399292, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.169228076934814, "step": 123000}
{"episode_reward": 459.53203216711194, "episode": 124.0, "batch_reward": 0.288250220566988, "critic_loss": 0.7254993825554847, "actor_loss": -50.61140962219238, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.993223667144775, "step": 124000}
{"episode_reward": 328.6529854881011, "episode": 125.0, "batch_reward": 0.28884239053726196, "critic_loss": 0.6818034093976021, "actor_loss": -50.064416015625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.81318163871765, "step": 125000}
{"episode_reward": 497.717756276176, "episode": 126.0, "batch_reward": 0.29025227135419845, "critic_loss": 0.662776421636343, "actor_loss": -49.22096586608887, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.31850838661194, "step": 126000}
{"episode_reward": 459.3958550645284, "episode": 127.0, "batch_reward": 0.2919372342079878, "critic_loss": 0.6498253585994244, "actor_loss": -48.397892082214355, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.08075714111328, "step": 127000}
{"episode_reward": 578.0363630575754, "episode": 128.0, "batch_reward": 0.29285026374459266, "critic_loss": 0.6674966612160206, "actor_loss": -47.61648124694824, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.01575779914856, "step": 128000}
{"episode_reward": 280.332950765008, "episode": 129.0, "batch_reward": 0.29321215714514254, "critic_loss": 0.6967167949974536, "actor_loss": -46.572910629272464, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.95381760597229, "step": 129000}
{"episode_reward": 614.8664356144275, "episode": 130.0, "batch_reward": 0.2964949918985367, "critic_loss": 0.6708476379215718, "actor_loss": -46.51497027587891, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.083691358566284, "step": 130000}
{"episode_reward": 543.4042275229016, "episode": 131.0, "batch_reward": 0.2986922529935837, "critic_loss": 0.6688561114668846, "actor_loss": -46.00071223449707, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.449843883514404, "step": 131000}
{"episode_reward": 606.3520582809444, "episode": 132.0, "batch_reward": 0.300768936753273, "critic_loss": 0.6652323768734932, "actor_loss": -45.74542707824707, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.450511693954468, "step": 132000}
{"episode_reward": 606.8125933079217, "episode": 133.0, "batch_reward": 0.3027184101641178, "critic_loss": 0.6700485774874687, "actor_loss": -45.11628533935547, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.08731174468994, "step": 133000}
{"episode_reward": 583.965096758627, "episode": 134.0, "batch_reward": 0.3048603372722864, "critic_loss": 0.5973121850788593, "actor_loss": -44.67758346557617, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.975483179092407, "step": 134000}
{"episode_reward": 602.83601573926, "episode": 135.0, "batch_reward": 0.3069816100895405, "critic_loss": 0.5652669694721699, "actor_loss": -44.49212969970703, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.996948719024658, "step": 135000}
{"episode_reward": 618.4775710129394, "episode": 136.0, "batch_reward": 0.30872791256010534, "critic_loss": 0.5695756120234727, "actor_loss": -44.35835546875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.959983825683594, "step": 136000}
{"episode_reward": 600.9882371848761, "episode": 137.0, "batch_reward": 0.31176143464446066, "critic_loss": 0.5575678703784943, "actor_loss": -44.24962774658203, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.990840673446655, "step": 137000}
{"episode_reward": 538.2884524373351, "episode": 138.0, "batch_reward": 0.31421765124797824, "critic_loss": 0.524858556419611, "actor_loss": -43.8842345199585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.517770767211914, "step": 138000}
{"episode_reward": 603.0789406815436, "episode": 139.0, "batch_reward": 0.3154695342183113, "critic_loss": 0.5228630896806717, "actor_loss": -43.73110732269287, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.505804777145386, "step": 139000}
{"episode_reward": 627.1456211493153, "episode": 140.0, "batch_reward": 0.31847582483291625, "critic_loss": 0.5020281401872635, "actor_loss": -43.574873237609864, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.332438945770264, "step": 140000}
{"episode_reward": 598.5050018945961, "episode": 141.0, "batch_reward": 0.3202745364010334, "critic_loss": 0.5051385114639998, "actor_loss": -43.2504702835083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.77683615684509, "step": 141000}
{"episode_reward": 245.99380277438843, "episode": 142.0, "batch_reward": 0.3189322237074375, "critic_loss": 0.4842599327266216, "actor_loss": -42.81006441497803, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.90418553352356, "step": 142000}
{"episode_reward": 608.0007146690176, "episode": 143.0, "batch_reward": 0.3225624942034483, "critic_loss": 0.5243188433349133, "actor_loss": -42.94513463592529, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.996466159820557, "step": 143000}
{"episode_reward": 564.8096740954674, "episode": 144.0, "batch_reward": 0.32272051125764845, "critic_loss": 0.4866766143143177, "actor_loss": -42.604070671081544, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.228142499923706, "step": 144000}
{"episode_reward": 626.5579894160683, "episode": 145.0, "batch_reward": 0.32639978793263436, "critic_loss": 0.45473850339651106, "actor_loss": -42.71635410308838, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.39560866355896, "step": 145000}
{"episode_reward": 657.5094701496905, "episode": 146.0, "batch_reward": 0.32636360806226733, "critic_loss": 0.4734924694001675, "actor_loss": -42.445306648254395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.453327655792236, "step": 146000}
{"episode_reward": 594.9770425434417, "episode": 147.0, "batch_reward": 0.3290932966172695, "critic_loss": 0.4584071424603462, "actor_loss": -42.38045341491699, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.00909924507141, "step": 147000}
{"episode_reward": 601.6468071963557, "episode": 148.0, "batch_reward": 0.3317688203454018, "critic_loss": 0.44020984260737894, "actor_loss": -42.33205498504638, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.76099920272827, "step": 148000}
{"episode_reward": 662.2080033275646, "episode": 149.0, "batch_reward": 0.3328827624320984, "critic_loss": 0.4218853276968002, "actor_loss": -42.137190315246585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.18804359436035, "step": 149000}
{"episode_reward": 627.4998628152883, "episode": 150.0, "batch_reward": 0.3357042369544506, "critic_loss": 0.41634840974211695, "actor_loss": -42.281413444519046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
