{"episode_reward": 0.0, "episode": 1.0, "duration": 19.64762544631958, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.6367897987365723, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2810900088954902, "critic_loss": 0.06532853570738488, "actor_loss": -38.78222171825712, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 69.43438863754272, "step": 3000}
{"episode_reward": 25.250157428947986, "episode": 4.0, "batch_reward": 0.18225678984820842, "critic_loss": 0.12215970505215228, "actor_loss": -24.900628868579865, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.969263315200806, "step": 4000}
{"episode_reward": 16.29631615431159, "episode": 5.0, "batch_reward": 0.15076106841862202, "critic_loss": 0.0718313968628645, "actor_loss": -18.60735677719116, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.001116275787354, "step": 5000}
{"episode_reward": 110.8017985445333, "episode": 6.0, "batch_reward": 0.13625168833881618, "critic_loss": 0.06791742437705398, "actor_loss": -21.060250841617584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.139854907989502, "step": 6000}
{"episode_reward": 15.141723216413883, "episode": 7.0, "batch_reward": 0.1209849670380354, "critic_loss": 0.06574059434980153, "actor_loss": -22.312102051734925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.03777766227722, "step": 7000}
{"episode_reward": 45.889684419971495, "episode": 8.0, "batch_reward": 0.11213612796366215, "critic_loss": 0.0647690510917455, "actor_loss": -22.16993327665329, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.952361345291138, "step": 8000}
{"episode_reward": 58.21298913650101, "episode": 9.0, "batch_reward": 0.10481663954257965, "critic_loss": 0.06125258934125304, "actor_loss": -22.850931690216065, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.11623454093933, "step": 9000}
{"episode_reward": 57.8806628077845, "episode": 10.0, "batch_reward": 0.10134323181211949, "critic_loss": 0.0584903205037117, "actor_loss": -23.576694221019746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.391188144683838, "step": 10000}
{"episode_reward": 74.15167255698002, "episode": 11.0, "batch_reward": 0.09822427152097225, "critic_loss": 0.05694818307645619, "actor_loss": -23.933293318271637, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.77945613861084, "step": 11000}
{"episode_reward": 61.22752627589483, "episode": 12.0, "batch_reward": 0.09526685293018818, "critic_loss": 0.060963115330785515, "actor_loss": -23.669413374900817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.052123308181763, "step": 12000}
{"episode_reward": 72.61691533166432, "episode": 13.0, "batch_reward": 0.09355573974922299, "critic_loss": 0.05763857719488442, "actor_loss": -24.580213605880736, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.230616092681885, "step": 13000}
{"episode_reward": 80.22238623986655, "episode": 14.0, "batch_reward": 0.09402866080030799, "critic_loss": 0.06750856863334775, "actor_loss": -23.899463050365448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.93780016899109, "step": 14000}
{"episode_reward": 122.40437036220018, "episode": 15.0, "batch_reward": 0.0959866019822657, "critic_loss": 0.0647203529458493, "actor_loss": -27.427420124053956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.37957215309143, "step": 15000}
{"episode_reward": 130.21876863554598, "episode": 16.0, "batch_reward": 0.0980480279698968, "critic_loss": 0.0633555921278894, "actor_loss": -25.90326615357399, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.940512657165527, "step": 16000}
{"episode_reward": 122.97660608595478, "episode": 17.0, "batch_reward": 0.09893834679573775, "critic_loss": 0.07192531553283334, "actor_loss": -27.061959612846376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.193723917007446, "step": 17000}
{"episode_reward": 93.15784933281735, "episode": 18.0, "batch_reward": 0.0991081619374454, "critic_loss": 0.06704989071190358, "actor_loss": -26.64645465993881, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.085569620132446, "step": 18000}
{"episode_reward": 119.74964841742894, "episode": 19.0, "batch_reward": 0.10094821065664292, "critic_loss": 0.08697266575321555, "actor_loss": -25.807551558554174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.2294819355011, "step": 19000}
{"episode_reward": 98.09240186811414, "episode": 20.0, "batch_reward": 0.10073434519767761, "critic_loss": 0.11435453695803881, "actor_loss": -27.168730527162552, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.898174285888672, "step": 20000}
{"episode_reward": 155.2289749925441, "episode": 21.0, "batch_reward": 0.1026177051141858, "critic_loss": 0.11046955985575914, "actor_loss": -27.38216407251358, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.137758016586304, "step": 21000}
{"episode_reward": 87.48275522342126, "episode": 22.0, "batch_reward": 0.10363617243617773, "critic_loss": 0.11729681535065174, "actor_loss": -27.4892698738575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.882659673690796, "step": 22000}
{"episode_reward": 173.17895592024738, "episode": 23.0, "batch_reward": 0.10714475295692683, "critic_loss": 0.13111901414394378, "actor_loss": -28.808382511287927, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.74543023109436, "step": 23000}
{"episode_reward": 176.02894500918285, "episode": 24.0, "batch_reward": 0.10979115261137486, "critic_loss": 0.1752479577586055, "actor_loss": -28.05133615845442, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54969835281372, "step": 24000}
{"episode_reward": 174.26844419070727, "episode": 25.0, "batch_reward": 0.11189658046513797, "critic_loss": 0.18094960594922305, "actor_loss": -27.419682260602713, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.899231672286987, "step": 25000}
{"episode_reward": 208.8999435951025, "episode": 26.0, "batch_reward": 0.11527019054442644, "critic_loss": 0.1865368217751384, "actor_loss": -28.831109896183015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.18675947189331, "step": 26000}
{"episode_reward": 135.0978833061989, "episode": 27.0, "batch_reward": 0.11586707371473312, "critic_loss": 0.17727772143483161, "actor_loss": -27.673821043640377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.285688638687134, "step": 27000}
{"episode_reward": 142.16785641978123, "episode": 28.0, "batch_reward": 0.11813191994279623, "critic_loss": 0.21224439081549645, "actor_loss": -27.373816933840512, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.65396809577942, "step": 28000}
{"episode_reward": 187.91153820438808, "episode": 29.0, "batch_reward": 0.12178699397295713, "critic_loss": 0.23757025611400603, "actor_loss": -28.388635900467634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.915751934051514, "step": 29000}
{"episode_reward": 251.11590138405148, "episode": 30.0, "batch_reward": 0.125216537989676, "critic_loss": 0.27722436213493346, "actor_loss": -28.077098117113113, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.421996116638184, "step": 30000}
{"episode_reward": 250.93964646006353, "episode": 31.0, "batch_reward": 0.12984151074290276, "critic_loss": 0.3216768689602613, "actor_loss": -28.599394646406175, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.75546383857727, "step": 31000}
{"episode_reward": 262.6465298627247, "episode": 32.0, "batch_reward": 0.13420345540344716, "critic_loss": 0.3273096675425768, "actor_loss": -28.3538486828804, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.063792943954468, "step": 32000}
{"episode_reward": 262.04005193421204, "episode": 33.0, "batch_reward": 0.13811485251784325, "critic_loss": 0.32805996139347554, "actor_loss": -29.65634650349617, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.657326221466064, "step": 33000}
{"episode_reward": 170.44216096180867, "episode": 34.0, "batch_reward": 0.139026453666389, "critic_loss": 0.3037878473103046, "actor_loss": -28.49551541352272, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.264421463012695, "step": 34000}
{"episode_reward": 247.2602619602744, "episode": 35.0, "batch_reward": 0.13941948834061624, "critic_loss": 0.30085731035470964, "actor_loss": -29.958810563087464, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.009420156478882, "step": 35000}
{"episode_reward": 21.29236926380005, "episode": 36.0, "batch_reward": 0.13783899672329425, "critic_loss": 0.31590347234904764, "actor_loss": -28.180844646930694, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.781898975372314, "step": 36000}
{"episode_reward": 213.31083783213316, "episode": 37.0, "batch_reward": 0.1396093349084258, "critic_loss": 0.3226548381000757, "actor_loss": -29.717474269390106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.484145402908325, "step": 37000}
{"episode_reward": 184.9781058436828, "episode": 38.0, "batch_reward": 0.14236439087241887, "critic_loss": 0.3450634989142418, "actor_loss": -29.74848605298996, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.83861231803894, "step": 38000}
{"episode_reward": 227.4445621185687, "episode": 39.0, "batch_reward": 0.1441421141847968, "critic_loss": 0.34027594739198685, "actor_loss": -30.10763915872574, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.136641025543213, "step": 39000}
{"episode_reward": 236.06702988807737, "episode": 40.0, "batch_reward": 0.1468282853513956, "critic_loss": 0.3092911401391029, "actor_loss": -30.47937966156006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.341800451278687, "step": 40000}
{"episode_reward": 268.6649800655107, "episode": 41.0, "batch_reward": 0.14835643226653336, "critic_loss": 0.2948747637718916, "actor_loss": -30.654758150100708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.736223459243774, "step": 41000}
{"episode_reward": 75.56910234815246, "episode": 42.0, "batch_reward": 0.14652139788120985, "critic_loss": 0.3188543995022774, "actor_loss": -29.18872090911865, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.194807291030884, "step": 42000}
{"episode_reward": 108.30580894991422, "episode": 43.0, "batch_reward": 0.14722541220486163, "critic_loss": 0.32588580684363844, "actor_loss": -29.368938159942626, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54388928413391, "step": 43000}
{"episode_reward": 281.9250735600693, "episode": 44.0, "batch_reward": 0.14977430079132317, "critic_loss": 0.32044156089425085, "actor_loss": -29.518270987510682, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.030282258987427, "step": 44000}
{"episode_reward": 240.25340012150474, "episode": 45.0, "batch_reward": 0.15254462476074696, "critic_loss": 0.3361768710464239, "actor_loss": -29.96483622646332, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.919032096862793, "step": 45000}
{"episode_reward": 300.35813137653105, "episode": 46.0, "batch_reward": 0.15549103370308875, "critic_loss": 0.3012437840104103, "actor_loss": -30.115073493003845, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.34027910232544, "step": 46000}
{"episode_reward": 287.93830324175946, "episode": 47.0, "batch_reward": 0.15929888051748275, "critic_loss": 0.2876002551466227, "actor_loss": -31.008393936157226, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.031773567199707, "step": 47000}
{"episode_reward": 269.332049943156, "episode": 48.0, "batch_reward": 0.16079978401958941, "critic_loss": 0.290774740383029, "actor_loss": -30.809221584320067, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.465115308761597, "step": 48000}
{"episode_reward": 289.5629745769049, "episode": 49.0, "batch_reward": 0.1634884984791279, "critic_loss": 0.29500599576532843, "actor_loss": -31.68188862991333, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.291125297546387, "step": 49000}
{"episode_reward": 247.01439710445848, "episode": 50.0, "batch_reward": 0.1641113882213831, "critic_loss": 0.2890298620611429, "actor_loss": -31.078873998641967, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.131036281585693, "step": 50000}
{"episode_reward": 265.0143585744971, "episode": 51.0, "batch_reward": 0.1666660018712282, "critic_loss": 0.3165522459149361, "actor_loss": -31.49675663661957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.47239065170288, "step": 51000}
{"episode_reward": 191.8317285924155, "episode": 52.0, "batch_reward": 0.16789517210423946, "critic_loss": 0.3531452564522624, "actor_loss": -31.288736170768736, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.314825296401978, "step": 52000}
{"episode_reward": 302.3989347931229, "episode": 53.0, "batch_reward": 0.17008736069500446, "critic_loss": 0.3493705140501261, "actor_loss": -31.716181770324706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.380177974700928, "step": 53000}
{"episode_reward": 191.53641732968742, "episode": 54.0, "batch_reward": 0.16987736515700816, "critic_loss": 0.3128069834411144, "actor_loss": -31.285444122314452, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.72709012031555, "step": 54000}
{"episode_reward": 256.4094941829513, "episode": 55.0, "batch_reward": 0.17256291931867598, "critic_loss": 0.31260380550473926, "actor_loss": -32.454190515518185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.55954074859619, "step": 55000}
{"episode_reward": 247.4421948699267, "episode": 56.0, "batch_reward": 0.17377687251567842, "critic_loss": 0.32579594300687315, "actor_loss": -32.313805896759035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.5386700630188, "step": 56000}
{"episode_reward": 272.8241780619695, "episode": 57.0, "batch_reward": 0.1756094623208046, "critic_loss": 0.3217326295077801, "actor_loss": -31.72117065048218, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.641388654708862, "step": 57000}
{"episode_reward": 324.21182888586685, "episode": 58.0, "batch_reward": 0.17768716491758824, "critic_loss": 0.3722857818901539, "actor_loss": -32.247371532440184, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.300225019454956, "step": 58000}
{"episode_reward": 312.0258282745081, "episode": 59.0, "batch_reward": 0.18096522669494153, "critic_loss": 0.42957421745359897, "actor_loss": -32.1570415058136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.08512544631958, "step": 59000}
{"episode_reward": 386.8122483224582, "episode": 60.0, "batch_reward": 0.18353747756779193, "critic_loss": 0.40894958969950673, "actor_loss": -32.63457227325439, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.205244541168213, "step": 60000}
{"episode_reward": 286.26374091590964, "episode": 61.0, "batch_reward": 0.18541514571011067, "critic_loss": 0.4129680166840553, "actor_loss": -32.471254316329954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.22247624397278, "step": 61000}
{"episode_reward": 243.39838279501583, "episode": 62.0, "batch_reward": 0.18666626532375813, "critic_loss": 0.42767890755832194, "actor_loss": -33.447831184387205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.733384132385254, "step": 62000}
{"episode_reward": 297.26810863113633, "episode": 63.0, "batch_reward": 0.18791699482500554, "critic_loss": 0.4693393503278494, "actor_loss": -32.86291872024536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.900853395462036, "step": 63000}
{"episode_reward": 309.40590989686734, "episode": 64.0, "batch_reward": 0.18908282965421677, "critic_loss": 0.46919857524335384, "actor_loss": -32.90447071647644, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.129252195358276, "step": 64000}
{"episode_reward": 126.48434365875855, "episode": 65.0, "batch_reward": 0.18979151770472527, "critic_loss": 0.47710199835896494, "actor_loss": -32.562895544052125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.328853130340576, "step": 65000}
{"episode_reward": 382.58616699767697, "episode": 66.0, "batch_reward": 0.19229852843284606, "critic_loss": 0.46050053477287295, "actor_loss": -32.86066673660278, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.63162398338318, "step": 66000}
{"episode_reward": 348.4065128476648, "episode": 67.0, "batch_reward": 0.1949331485182047, "critic_loss": 0.4522788875848055, "actor_loss": -33.248201438903806, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.18651843070984, "step": 67000}
{"episode_reward": 378.15542325294683, "episode": 68.0, "batch_reward": 0.1966400085389614, "critic_loss": 0.4928418529778719, "actor_loss": -33.13523237228394, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.432695865631104, "step": 68000}
{"episode_reward": 198.25530578573378, "episode": 69.0, "batch_reward": 0.1971199372857809, "critic_loss": 0.5519469748735428, "actor_loss": -33.25236159324646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.703783988952637, "step": 69000}
{"episode_reward": 357.820069290178, "episode": 70.0, "batch_reward": 0.20002015393972397, "critic_loss": 0.5468472747057677, "actor_loss": -33.63572180175781, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.069661617279053, "step": 70000}
{"episode_reward": 370.96453782565914, "episode": 71.0, "batch_reward": 0.2019063474535942, "critic_loss": 0.5696761528104544, "actor_loss": -34.01205561065674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.466596841812134, "step": 71000}
{"episode_reward": 244.16361174307212, "episode": 72.0, "batch_reward": 0.20302028328180313, "critic_loss": 0.5582860149741172, "actor_loss": -34.082964056015015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.04126000404358, "step": 72000}
{"episode_reward": 381.37014597361616, "episode": 73.0, "batch_reward": 0.2055168382972479, "critic_loss": 0.5129163925647735, "actor_loss": -33.96483462333679, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.867106676101685, "step": 73000}
{"episode_reward": 406.54732816684026, "episode": 74.0, "batch_reward": 0.20816539752483368, "critic_loss": 0.5819910877645016, "actor_loss": -34.555509634017945, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.62001895904541, "step": 74000}
{"episode_reward": 381.7233605804963, "episode": 75.0, "batch_reward": 0.21008557042479514, "critic_loss": 0.5149143035709858, "actor_loss": -34.320191190719605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.57755732536316, "step": 75000}
{"episode_reward": 327.15216848211537, "episode": 76.0, "batch_reward": 0.21234497076272965, "critic_loss": 0.5202506716251374, "actor_loss": -34.62362446975708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.586273908615112, "step": 76000}
{"episode_reward": 422.6562424114542, "episode": 77.0, "batch_reward": 0.21429060897231103, "critic_loss": 0.5586071241497993, "actor_loss": -34.32794157409668, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.4849636554718, "step": 77000}
{"episode_reward": 363.32511226063684, "episode": 78.0, "batch_reward": 0.2173698610216379, "critic_loss": 0.5193915862590075, "actor_loss": -35.119303136825565, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.21557903289795, "step": 78000}
{"episode_reward": 411.7081533715796, "episode": 79.0, "batch_reward": 0.21835236194729804, "critic_loss": 0.4946932439059019, "actor_loss": -34.0262253036499, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.848735809326172, "step": 79000}
{"episode_reward": 403.2363408668394, "episode": 80.0, "batch_reward": 0.2215335195362568, "critic_loss": 0.5413322406560183, "actor_loss": -34.90138405418396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.309502840042114, "step": 80000}
{"episode_reward": 358.77169006440107, "episode": 81.0, "batch_reward": 0.2221480010598898, "critic_loss": 0.552001859843731, "actor_loss": -34.85326668930054, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.510826110839844, "step": 81000}
{"episode_reward": 271.3686806820938, "episode": 82.0, "batch_reward": 0.2226606598496437, "critic_loss": 0.5265774948149919, "actor_loss": -35.80275797271729, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.277572631835938, "step": 82000}
{"episode_reward": 16.915971171106317, "episode": 83.0, "batch_reward": 0.22198613944649698, "critic_loss": 0.5121544416248799, "actor_loss": -34.70529800415039, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.581498622894287, "step": 83000}
{"episode_reward": 422.53868764485594, "episode": 84.0, "batch_reward": 0.22395023380219936, "critic_loss": 0.5313438225984574, "actor_loss": -36.18746192550659, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.40946125984192, "step": 84000}
{"episode_reward": 385.7687244800148, "episode": 85.0, "batch_reward": 0.22530570596456528, "critic_loss": 0.5271445210278034, "actor_loss": -35.34892741203308, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.63099431991577, "step": 85000}
{"episode_reward": 450.7980627223373, "episode": 86.0, "batch_reward": 0.22824437212944032, "critic_loss": 0.5017063358128071, "actor_loss": -35.59041027641296, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.862637519836426, "step": 86000}
{"episode_reward": 436.39742644951355, "episode": 87.0, "batch_reward": 0.23056730729341507, "critic_loss": 0.48872998005151747, "actor_loss": -35.71652202987671, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.170531034469604, "step": 87000}
{"episode_reward": 433.5681333331421, "episode": 88.0, "batch_reward": 0.232166848808527, "critic_loss": 0.45912735541164873, "actor_loss": -35.30025597763061, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.48633098602295, "step": 88000}
{"episode_reward": 174.1274601949847, "episode": 89.0, "batch_reward": 0.23145616863667964, "critic_loss": 0.45300955322384834, "actor_loss": -35.75519760131836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.331875562667847, "step": 89000}
{"episode_reward": 174.82575102156798, "episode": 90.0, "batch_reward": 0.2318001804202795, "critic_loss": 0.4614099872261286, "actor_loss": -35.884490741729735, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.9202823638916, "step": 90000}
{"episode_reward": 447.6776201245256, "episode": 91.0, "batch_reward": 0.23433750446140766, "critic_loss": 0.46621862733364106, "actor_loss": -35.775974514007565, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.335045337677, "step": 91000}
{"episode_reward": 450.7280698104162, "episode": 92.0, "batch_reward": 0.2376022140085697, "critic_loss": 0.4693093064129353, "actor_loss": -35.93101979827881, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.533644676208496, "step": 92000}
{"episode_reward": 498.68077558990007, "episode": 93.0, "batch_reward": 0.2390982908755541, "critic_loss": 0.4668683891296387, "actor_loss": -35.8713532409668, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.074836254119873, "step": 93000}
{"episode_reward": 473.7585941581614, "episode": 94.0, "batch_reward": 0.24178366233408452, "critic_loss": 0.4478728287816048, "actor_loss": -36.47746586608887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.48826789855957, "step": 94000}
{"episode_reward": 433.3553265398912, "episode": 95.0, "batch_reward": 0.24358326984941958, "critic_loss": 0.4461163283288479, "actor_loss": -36.71968103408813, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.787378787994385, "step": 95000}
{"episode_reward": 407.6597328474441, "episode": 96.0, "batch_reward": 0.24527763186395168, "critic_loss": 0.43332165463268757, "actor_loss": -36.95195861053467, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.349970817565918, "step": 96000}
{"episode_reward": 478.65011094924216, "episode": 97.0, "batch_reward": 0.24806114788353442, "critic_loss": 0.4294554481059313, "actor_loss": -37.447224040985105, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.971593856811523, "step": 97000}
{"episode_reward": 430.79210481957426, "episode": 98.0, "batch_reward": 0.25030278077721596, "critic_loss": 0.4408831739872694, "actor_loss": -37.26026159667969, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.910263299942017, "step": 98000}
{"episode_reward": 418.2278389373913, "episode": 99.0, "batch_reward": 0.25122535586357114, "critic_loss": 0.4464912295788527, "actor_loss": -36.73052229690552, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.17706561088562, "step": 99000}
{"episode_reward": 265.9811141206193, "episode": 100.0, "batch_reward": 0.25330449302494523, "critic_loss": 0.43564132119715215, "actor_loss": -37.2169623336792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.57658100128174, "step": 100000}
{"episode_reward": 503.03380886845355, "episode": 101.0, "batch_reward": 0.2543447457998991, "critic_loss": 0.4316099673211575, "actor_loss": -37.372024593353274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.56412601470947, "step": 101000}
{"episode_reward": 473.3027996317719, "episode": 102.0, "batch_reward": 0.2560945646315813, "critic_loss": 0.43108289009332657, "actor_loss": -37.23156070327759, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.98632502555847, "step": 102000}
{"episode_reward": 417.37045642684575, "episode": 103.0, "batch_reward": 0.25752257560193537, "critic_loss": 0.4791111831367016, "actor_loss": -37.67363387298584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.834014654159546, "step": 103000}
{"episode_reward": 284.48245562967116, "episode": 104.0, "batch_reward": 0.2593828834742308, "critic_loss": 0.43276689027249815, "actor_loss": -37.63262427139282, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.712857007980347, "step": 104000}
{"episode_reward": 513.5569871615925, "episode": 105.0, "batch_reward": 0.2608229158371687, "critic_loss": 0.46142931185662744, "actor_loss": -37.70306335449219, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.094218730926514, "step": 105000}
{"episode_reward": 415.2709699886003, "episode": 106.0, "batch_reward": 0.2623778508603573, "critic_loss": 0.4881104972958565, "actor_loss": -37.69256303024292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.585360765457153, "step": 106000}
{"episode_reward": 522.9349567003927, "episode": 107.0, "batch_reward": 0.26446146026253703, "critic_loss": 0.463485832080245, "actor_loss": -38.065994422912595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.91760492324829, "step": 107000}
{"episode_reward": 235.24304472839876, "episode": 108.0, "batch_reward": 0.26465439645946026, "critic_loss": 0.48682208780944347, "actor_loss": -37.76587843322754, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.301827430725098, "step": 108000}
{"episode_reward": 490.61956219448626, "episode": 109.0, "batch_reward": 0.2665934153944254, "critic_loss": 0.4876807877272368, "actor_loss": -38.67618843460083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.837218761444092, "step": 109000}
{"episode_reward": 434.71967689313334, "episode": 110.0, "batch_reward": 0.2681856206059456, "critic_loss": 0.5122273305803537, "actor_loss": -38.309515895843504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.59364914894104, "step": 110000}
{"episode_reward": 470.64389550358203, "episode": 111.0, "batch_reward": 0.2699879838079214, "critic_loss": 0.5319541870504618, "actor_loss": -38.592468502044674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.26081895828247, "step": 111000}
{"episode_reward": 456.34424644399985, "episode": 112.0, "batch_reward": 0.2720602479875088, "critic_loss": 0.46892836314439773, "actor_loss": -37.91782538986206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.694867849349976, "step": 112000}
{"episode_reward": 484.9862957941783, "episode": 113.0, "batch_reward": 0.27389135807752607, "critic_loss": 0.495472003147006, "actor_loss": -38.67957633972168, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30234122276306, "step": 113000}
{"episode_reward": 495.61047229979255, "episode": 114.0, "batch_reward": 0.2756868986785412, "critic_loss": 0.5199477275013924, "actor_loss": -39.10963383483887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.010407209396362, "step": 114000}
{"episode_reward": 517.3325228516698, "episode": 115.0, "batch_reward": 0.27808605040609835, "critic_loss": 0.5219866039305925, "actor_loss": -38.92096529388428, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.443628311157227, "step": 115000}
{"episode_reward": 491.9103357141415, "episode": 116.0, "batch_reward": 0.2798473985940218, "critic_loss": 0.49918327732384205, "actor_loss": -38.90631155014038, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.937594413757324, "step": 116000}
{"episode_reward": 505.0960600021714, "episode": 117.0, "batch_reward": 0.28246710282564164, "critic_loss": 0.5306691703945399, "actor_loss": -38.955882125854494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.007019519805908, "step": 117000}
{"episode_reward": 502.670417296863, "episode": 118.0, "batch_reward": 0.2825585980564356, "critic_loss": 0.5241570074111224, "actor_loss": -39.20617805862427, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.725473403930664, "step": 118000}
{"episode_reward": 170.42238766843275, "episode": 119.0, "batch_reward": 0.2831810320317745, "critic_loss": 0.4971915161162615, "actor_loss": -39.415821170806886, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.906550407409668, "step": 119000}
{"episode_reward": 500.4105885677099, "episode": 120.0, "batch_reward": 0.2834405175298452, "critic_loss": 0.5611758609712124, "actor_loss": -39.097817543029784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.011396884918213, "step": 120000}
{"episode_reward": 470.636181604446, "episode": 121.0, "batch_reward": 0.2860029068291187, "critic_loss": 0.5385169223099947, "actor_loss": -38.96176119232178, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.97095537185669, "step": 121000}
{"episode_reward": 513.8146734385382, "episode": 122.0, "batch_reward": 0.28811554791033267, "critic_loss": 0.5424702406823635, "actor_loss": -39.24530936431885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.411445379257202, "step": 122000}
{"episode_reward": 466.56278235057385, "episode": 123.0, "batch_reward": 0.2906932020634413, "critic_loss": 0.5141028280854225, "actor_loss": -38.935252571105956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.62079691886902, "step": 123000}
{"episode_reward": 554.7652441309683, "episode": 124.0, "batch_reward": 0.2905423938035965, "critic_loss": 0.5116967963576317, "actor_loss": -39.43083121871948, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.422832250595093, "step": 124000}
{"episode_reward": 506.1265368045335, "episode": 125.0, "batch_reward": 0.2929164300262928, "critic_loss": 0.5270567519515753, "actor_loss": -39.31253865432739, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.225730657577515, "step": 125000}
{"episode_reward": 230.31532912627483, "episode": 126.0, "batch_reward": 0.291789343804121, "critic_loss": 0.558426101654768, "actor_loss": -38.9329921836853, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.870018005371094, "step": 126000}
{"episode_reward": 507.4014456115471, "episode": 127.0, "batch_reward": 0.2941975589543581, "critic_loss": 0.5238717883974314, "actor_loss": -39.77081593704224, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.607381343841553, "step": 127000}
{"episode_reward": 406.75112248642876, "episode": 128.0, "batch_reward": 0.29496635527908804, "critic_loss": 0.5510484263896942, "actor_loss": -40.26578630065918, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.456666469573975, "step": 128000}
{"episode_reward": 500.2606375352017, "episode": 129.0, "batch_reward": 0.2964421418756247, "critic_loss": 0.5777527536451816, "actor_loss": -40.085490558624265, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.283928394317627, "step": 129000}
{"episode_reward": 506.9988846144069, "episode": 130.0, "batch_reward": 0.29865442743897436, "critic_loss": 0.5572373790442944, "actor_loss": -40.002283798217775, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.725507974624634, "step": 130000}
{"episode_reward": 531.61321741143, "episode": 131.0, "batch_reward": 0.30120101997256277, "critic_loss": 0.5005814024209976, "actor_loss": -40.57052969360352, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.40429329872131, "step": 131000}
{"episode_reward": 505.35147473028894, "episode": 132.0, "batch_reward": 0.30195122489333154, "critic_loss": 0.4966667858660221, "actor_loss": -40.59103673171997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.804613828659058, "step": 132000}
{"episode_reward": 524.1502275834644, "episode": 133.0, "batch_reward": 0.30360446965694426, "critic_loss": 0.5040130182504654, "actor_loss": -40.592564643859866, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.965664386749268, "step": 133000}
{"episode_reward": 532.2584435719059, "episode": 134.0, "batch_reward": 0.30375493793189523, "critic_loss": 0.5173078387379646, "actor_loss": -40.66735586166382, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.196409702301025, "step": 134000}
{"episode_reward": 265.88350756521044, "episode": 135.0, "batch_reward": 0.304405091881752, "critic_loss": 0.5328917454183102, "actor_loss": -40.528406929016114, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.61407971382141, "step": 135000}
{"episode_reward": 528.2340136459617, "episode": 136.0, "batch_reward": 0.3067661755681038, "critic_loss": 0.5327295153588056, "actor_loss": -41.31348421096802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.688664436340332, "step": 136000}
{"episode_reward": 548.4387443129456, "episode": 137.0, "batch_reward": 0.3076207937598228, "critic_loss": 0.5666575658768416, "actor_loss": -40.98637335968017, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.56411385536194, "step": 137000}
{"episode_reward": 506.6924818529313, "episode": 138.0, "batch_reward": 0.3098668957054615, "critic_loss": 0.5393287499547005, "actor_loss": -40.27551216125488, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.46936821937561, "step": 138000}
{"episode_reward": 325.8195753371185, "episode": 139.0, "batch_reward": 0.30900015130639075, "critic_loss": 0.5655351874232292, "actor_loss": -40.3780465888977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.692084312438965, "step": 139000}
{"episode_reward": 499.5568906616021, "episode": 140.0, "batch_reward": 0.31004844295978545, "critic_loss": 0.5612277588099241, "actor_loss": -40.2136861000061, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.772702932357788, "step": 140000}
{"episode_reward": 489.29560896354724, "episode": 141.0, "batch_reward": 0.31308866596221924, "critic_loss": 0.5617721276134252, "actor_loss": -40.73379638290405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.67462348937988, "step": 141000}
{"episode_reward": 537.9491064119351, "episode": 142.0, "batch_reward": 0.31373087520897386, "critic_loss": 0.5885843923091888, "actor_loss": -40.76808317184448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.98826551437378, "step": 142000}
{"episode_reward": 541.9396781564449, "episode": 143.0, "batch_reward": 0.3154097872674465, "critic_loss": 0.5637198386490345, "actor_loss": -41.2133010597229, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.09084939956665, "step": 143000}
{"episode_reward": 554.1621595404785, "episode": 144.0, "batch_reward": 0.3179490270912647, "critic_loss": 0.5580215819180012, "actor_loss": -41.48249560546875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.631015300750732, "step": 144000}
{"episode_reward": 554.0545954224676, "episode": 145.0, "batch_reward": 0.319691535204649, "critic_loss": 0.543084936991334, "actor_loss": -41.47703837585449, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.824219942092896, "step": 145000}
{"episode_reward": 571.194924867123, "episode": 146.0, "batch_reward": 0.32039875829219816, "critic_loss": 0.5589398709535599, "actor_loss": -41.45232050704956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.551572799682617, "step": 146000}
{"episode_reward": 373.2257350223496, "episode": 147.0, "batch_reward": 0.3209634808897972, "critic_loss": 0.5251497052311898, "actor_loss": -41.86541066741943, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.162886142730713, "step": 147000}
{"episode_reward": 539.6186259704125, "episode": 148.0, "batch_reward": 0.3239081205427647, "critic_loss": 0.5408646615594626, "actor_loss": -41.72816062164306, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.906791925430298, "step": 148000}
{"episode_reward": 528.3143101647431, "episode": 149.0, "batch_reward": 0.3247129975259304, "critic_loss": 0.5201921732723713, "actor_loss": -41.942848072052, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.45515751838684, "step": 149000}
{"episode_reward": 544.9590358506586, "episode": 150.0, "batch_reward": 0.3257214793562889, "critic_loss": 0.5525547731220722, "actor_loss": -41.602997673034665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
