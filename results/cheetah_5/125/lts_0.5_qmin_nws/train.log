{"episode_reward": 0.0, "episode": 1.0, "duration": 20.969022274017334, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.653127670288086, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2818864485240849, "critic_loss": 0.03703001667750069, "actor_loss": -24.719732421709516, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 67.73446941375732, "step": 3000}
{"episode_reward": 31.946962800379648, "episode": 4.0, "batch_reward": 0.18844695570319892, "critic_loss": 0.0590176710486412, "actor_loss": -16.055894926518203, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.651520252227783, "step": 4000}
{"episode_reward": 34.54286280324277, "episode": 5.0, "batch_reward": 0.15115465449541807, "critic_loss": 0.04572269793972373, "actor_loss": -12.61095740133524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.378116846084595, "step": 5000}
{"episode_reward": 51.3606743696735, "episode": 6.0, "batch_reward": 0.132447917945683, "critic_loss": 0.04634580560773611, "actor_loss": -14.002893241532147, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.113181829452515, "step": 6000}
{"episode_reward": 62.83482284552968, "episode": 7.0, "batch_reward": 0.12244425254315137, "critic_loss": 0.055465629536658526, "actor_loss": -14.96406080828607, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.087069749832153, "step": 7000}
{"episode_reward": 32.93044583642167, "episode": 8.0, "batch_reward": 0.1116532428637147, "critic_loss": 0.06194453648477793, "actor_loss": -13.906805638179183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.574544191360474, "step": 8000}
{"episode_reward": 39.60441149438766, "episode": 9.0, "batch_reward": 0.10303129055723548, "critic_loss": 0.06062138662673533, "actor_loss": -13.728140326574445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.849323272705078, "step": 9000}
{"episode_reward": 68.64446667475237, "episode": 10.0, "batch_reward": 0.10119293951243162, "critic_loss": 0.06627055291086435, "actor_loss": -13.780508901312947, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.420573949813843, "step": 10000}
{"episode_reward": 82.10693349514962, "episode": 11.0, "batch_reward": 0.10011233716085553, "critic_loss": 0.07979100190475583, "actor_loss": -14.885745829477907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.373451471328735, "step": 11000}
{"episode_reward": 83.81831656574742, "episode": 12.0, "batch_reward": 0.09856199554726482, "critic_loss": 0.0815772959124297, "actor_loss": -13.538547523528338, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.610682487487793, "step": 12000}
{"episode_reward": 57.809517095942816, "episode": 13.0, "batch_reward": 0.09730826850607992, "critic_loss": 0.0943959481343627, "actor_loss": -13.19081709305942, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.17870020866394, "step": 13000}
{"episode_reward": 169.99153115347954, "episode": 14.0, "batch_reward": 0.1018518204241991, "critic_loss": 0.1121278166398406, "actor_loss": -13.429048802182079, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.900354862213135, "step": 14000}
{"episode_reward": 129.98445564584696, "episode": 15.0, "batch_reward": 0.10424104176461696, "critic_loss": 0.12412700939178467, "actor_loss": -15.959587141603231, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.731415033340454, "step": 15000}
{"episode_reward": 167.12979251902806, "episode": 16.0, "batch_reward": 0.10705466786026954, "critic_loss": 0.13628618814051152, "actor_loss": -16.488371235370636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.991409301757812, "step": 16000}
{"episode_reward": 124.79110102297273, "episode": 17.0, "batch_reward": 0.1090858496055007, "critic_loss": 0.15155164913088084, "actor_loss": -16.081004153728486, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.76252317428589, "step": 17000}
{"episode_reward": 103.78557496447588, "episode": 18.0, "batch_reward": 0.10689550976455212, "critic_loss": 0.16432029002159834, "actor_loss": -15.679940916776657, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.946511268615723, "step": 18000}
{"episode_reward": 29.973618370311883, "episode": 19.0, "batch_reward": 0.10603672406822442, "critic_loss": 0.20707846763730048, "actor_loss": -16.159513329982758, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.50712490081787, "step": 19000}
{"episode_reward": 117.97174628337692, "episode": 20.0, "batch_reward": 0.10558209851384164, "critic_loss": 0.21682061178982256, "actor_loss": -16.597941789150237, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.137110948562622, "step": 20000}
{"episode_reward": 158.52700462843282, "episode": 21.0, "batch_reward": 0.1077384715154767, "critic_loss": 0.2019767294600606, "actor_loss": -17.379049911975862, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.69675898551941, "step": 21000}
{"episode_reward": 85.56230978375584, "episode": 22.0, "batch_reward": 0.10759382655471564, "critic_loss": 0.20156990241259337, "actor_loss": -16.7289491353035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.727054357528687, "step": 22000}
{"episode_reward": 124.17535601090935, "episode": 23.0, "batch_reward": 0.10864313521981239, "critic_loss": 0.199363390609622, "actor_loss": -16.54598916053772, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.23926281929016, "step": 23000}
{"episode_reward": 134.79909936427163, "episode": 24.0, "batch_reward": 0.10840815205127001, "critic_loss": 0.21799772357940675, "actor_loss": -17.31083017349243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.21366286277771, "step": 24000}
{"episode_reward": 90.21098547285136, "episode": 25.0, "batch_reward": 0.10995904941111803, "critic_loss": 0.2606347068846226, "actor_loss": -16.626558672904967, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.985042810440063, "step": 25000}
{"episode_reward": 212.10914245559485, "episode": 26.0, "batch_reward": 0.11370729494094849, "critic_loss": 0.2732795081958175, "actor_loss": -16.918887672424315, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.80570125579834, "step": 26000}
{"episode_reward": 191.60269113731798, "episode": 27.0, "batch_reward": 0.11587943268567323, "critic_loss": 0.2863117823153734, "actor_loss": -17.142829728126525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.500917196273804, "step": 27000}
{"episode_reward": 111.82004794921623, "episode": 28.0, "batch_reward": 0.11652622566372156, "critic_loss": 0.2972299038544297, "actor_loss": -17.27079685306549, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.969061851501465, "step": 28000}
{"episode_reward": 270.07825709413765, "episode": 29.0, "batch_reward": 0.12400928619503974, "critic_loss": 0.361873562887311, "actor_loss": -18.684922731399535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.633702993392944, "step": 29000}
{"episode_reward": 315.2539775696069, "episode": 30.0, "batch_reward": 0.12793942913413048, "critic_loss": 0.3792967710644007, "actor_loss": -18.81884192276001, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.42370915412903, "step": 30000}
{"episode_reward": 121.38638091426881, "episode": 31.0, "batch_reward": 0.12881349819153548, "critic_loss": 0.360530114993453, "actor_loss": -19.13124950027466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.42704892158508, "step": 31000}
{"episode_reward": 220.50618581572854, "episode": 32.0, "batch_reward": 0.13145132829248904, "critic_loss": 0.3930393718034029, "actor_loss": -19.51083214187622, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.67667531967163, "step": 32000}
{"episode_reward": 269.2625515254611, "episode": 33.0, "batch_reward": 0.13579241767525674, "critic_loss": 0.3956495732665062, "actor_loss": -19.983408308029176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.976810455322266, "step": 33000}
{"episode_reward": 247.92598528027733, "episode": 34.0, "batch_reward": 0.1385550089031458, "critic_loss": 0.4013349786400795, "actor_loss": -19.43999796485901, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.769144535064697, "step": 34000}
{"episode_reward": 165.0971933844237, "episode": 35.0, "batch_reward": 0.1387456933259964, "critic_loss": 0.435598613217473, "actor_loss": -20.48374534034729, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.99426031112671, "step": 35000}
{"episode_reward": 102.61172387012282, "episode": 36.0, "batch_reward": 0.13822955451905727, "critic_loss": 0.4497196885049343, "actor_loss": -20.06388842010498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.89585781097412, "step": 36000}
{"episode_reward": 256.47415926353096, "episode": 37.0, "batch_reward": 0.14070142740756272, "critic_loss": 0.40806073623895645, "actor_loss": -20.397885112762452, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.892605543136597, "step": 37000}
{"episode_reward": 113.84870085264278, "episode": 38.0, "batch_reward": 0.1402993682101369, "critic_loss": 0.4639544969052076, "actor_loss": -20.826829681396486, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.443861722946167, "step": 38000}
{"episode_reward": 95.23926813197502, "episode": 39.0, "batch_reward": 0.13921882594376803, "critic_loss": 0.4541641599088907, "actor_loss": -21.33345017814636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.057225227355957, "step": 39000}
{"episode_reward": 215.69978366675704, "episode": 40.0, "batch_reward": 0.14144635017961263, "critic_loss": 0.4978941490352154, "actor_loss": -21.458493183135985, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.1062114238739, "step": 40000}
{"episode_reward": 244.99785366696776, "episode": 41.0, "batch_reward": 0.14330664009600877, "critic_loss": 0.5092047686427832, "actor_loss": -21.60125222969055, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.00124931335449, "step": 41000}
{"episode_reward": 56.561824707179326, "episode": 42.0, "batch_reward": 0.1431581701040268, "critic_loss": 0.48938616777956484, "actor_loss": -21.3334711894989, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.6025710105896, "step": 42000}
{"episode_reward": 346.3281296044379, "episode": 43.0, "batch_reward": 0.14810264030843973, "critic_loss": 0.5246968644410371, "actor_loss": -22.07522325515747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.74204993247986, "step": 43000}
{"episode_reward": 336.2987855485553, "episode": 44.0, "batch_reward": 0.15135181967914105, "critic_loss": 0.531284101381898, "actor_loss": -22.274140647888185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.18659806251526, "step": 44000}
{"episode_reward": 156.0547195413403, "episode": 45.0, "batch_reward": 0.15179908099770545, "critic_loss": 0.5139963981360197, "actor_loss": -22.797050966262816, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.58230185508728, "step": 45000}
{"episode_reward": 221.88781615154508, "episode": 46.0, "batch_reward": 0.15135540344566106, "critic_loss": 0.4979678496569395, "actor_loss": -22.673043941497802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.04794454574585, "step": 46000}
{"episode_reward": 49.79718238539998, "episode": 47.0, "batch_reward": 0.15147080101072788, "critic_loss": 0.5226908323466778, "actor_loss": -22.50043731880188, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.22039484977722, "step": 47000}
{"episode_reward": 266.01879513415344, "episode": 48.0, "batch_reward": 0.15230235958099364, "critic_loss": 0.5245348960459232, "actor_loss": -22.506504117965697, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.534340858459473, "step": 48000}
{"episode_reward": 99.80377040887767, "episode": 49.0, "batch_reward": 0.15296771334856749, "critic_loss": 0.5223365186601877, "actor_loss": -22.761937629699705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.387299299240112, "step": 49000}
{"episode_reward": 335.7721883502102, "episode": 50.0, "batch_reward": 0.15567189784348012, "critic_loss": 0.5393845978379249, "actor_loss": -23.256836599349974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.279367685317993, "step": 50000}
{"episode_reward": 297.95271028708567, "episode": 51.0, "batch_reward": 0.15960431204736233, "critic_loss": 0.49025831288099286, "actor_loss": -23.36137044906616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.82523512840271, "step": 51000}
{"episode_reward": 343.9856008841621, "episode": 52.0, "batch_reward": 0.16253368480503558, "critic_loss": 0.5380419370085001, "actor_loss": -24.1230455493927, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.754106521606445, "step": 52000}
{"episode_reward": 293.6212475130444, "episode": 53.0, "batch_reward": 0.1655684707313776, "critic_loss": 0.518650349020958, "actor_loss": -24.28648981666565, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.858599185943604, "step": 53000}
{"episode_reward": 260.2302764642935, "episode": 54.0, "batch_reward": 0.16713341354578734, "critic_loss": 0.5165210677981377, "actor_loss": -24.474642808914183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.839991092681885, "step": 54000}
{"episode_reward": 279.6550662842759, "episode": 55.0, "batch_reward": 0.16961369509994983, "critic_loss": 0.522424400895834, "actor_loss": -24.425826959609985, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.974870204925537, "step": 55000}
{"episode_reward": 344.21426454050686, "episode": 56.0, "batch_reward": 0.17106392081081867, "critic_loss": 0.582959374949336, "actor_loss": -24.994452476501465, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.48798966407776, "step": 56000}
{"episode_reward": 103.7057143497971, "episode": 57.0, "batch_reward": 0.1721033286601305, "critic_loss": 0.5390862370431423, "actor_loss": -25.10278203392029, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.676936864852905, "step": 57000}
{"episode_reward": 391.0719004427816, "episode": 58.0, "batch_reward": 0.17524300165474416, "critic_loss": 0.5740461056381464, "actor_loss": -24.884662445068358, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.81378746032715, "step": 58000}
{"episode_reward": 261.4942524698874, "episode": 59.0, "batch_reward": 0.17508647927641868, "critic_loss": 0.5371610955297947, "actor_loss": -24.90091219329834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.43380331993103, "step": 59000}
{"episode_reward": 102.7843484965954, "episode": 60.0, "batch_reward": 0.17576700733602046, "critic_loss": 0.547555348277092, "actor_loss": -25.88422105026245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.21218514442444, "step": 60000}
{"episode_reward": 350.2587521619785, "episode": 61.0, "batch_reward": 0.17825771659612655, "critic_loss": 0.5715925661623478, "actor_loss": -25.337215225219726, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.70030856132507, "step": 61000}
{"episode_reward": 195.0013995765292, "episode": 62.0, "batch_reward": 0.1776544536948204, "critic_loss": 0.5435026423335075, "actor_loss": -25.075494373321533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.78512716293335, "step": 62000}
{"episode_reward": 159.694386463556, "episode": 63.0, "batch_reward": 0.17797347894310953, "critic_loss": 0.5638525356650352, "actor_loss": -25.50159349822998, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.179527759552002, "step": 63000}
{"episode_reward": 311.4011569125715, "episode": 64.0, "batch_reward": 0.18050222362577914, "critic_loss": 0.5993895955979824, "actor_loss": -25.43544314956665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.670914888381958, "step": 64000}
{"episode_reward": 395.8661000882615, "episode": 65.0, "batch_reward": 0.18446322782337665, "critic_loss": 0.6067988895177842, "actor_loss": -26.001073673248293, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.305310487747192, "step": 65000}
{"episode_reward": 403.79785848031037, "episode": 66.0, "batch_reward": 0.187043119892478, "critic_loss": 0.6189768131673336, "actor_loss": -26.193422275543213, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.064119815826416, "step": 66000}
{"episode_reward": 278.4596855028123, "episode": 67.0, "batch_reward": 0.1887627921551466, "critic_loss": 0.5950483740866184, "actor_loss": -26.53774990081787, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.930872917175293, "step": 67000}
{"episode_reward": 229.752555379543, "episode": 68.0, "batch_reward": 0.18866771624982356, "critic_loss": 0.5799946762174368, "actor_loss": -25.854003162384032, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.191599369049072, "step": 68000}
{"episode_reward": 222.58561721670262, "episode": 69.0, "batch_reward": 0.18782332633435725, "critic_loss": 0.6115346020013094, "actor_loss": -26.0777875289917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.54632568359375, "step": 69000}
{"episode_reward": 113.15431512942061, "episode": 70.0, "batch_reward": 0.18748959143459798, "critic_loss": 0.6286503492891788, "actor_loss": -26.16587074279785, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.76956582069397, "step": 70000}
{"episode_reward": 128.80946994933242, "episode": 71.0, "batch_reward": 0.18643800194561483, "critic_loss": 0.5787854446172714, "actor_loss": -25.603957054138185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.358869791030884, "step": 71000}
{"episode_reward": 91.91421845882775, "episode": 72.0, "batch_reward": 0.18591238957643508, "critic_loss": 0.6334925498664379, "actor_loss": -25.687161556243897, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.509783029556274, "step": 72000}
{"episode_reward": 308.2477962887212, "episode": 73.0, "batch_reward": 0.18837901891767977, "critic_loss": 0.6670475981235504, "actor_loss": -25.92486001205444, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.691574573516846, "step": 73000}
{"episode_reward": 291.669571708478, "episode": 74.0, "batch_reward": 0.18966032922267914, "critic_loss": 0.6401625634282827, "actor_loss": -26.24026634979248, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.47109317779541, "step": 74000}
{"episode_reward": 251.9436459475559, "episode": 75.0, "batch_reward": 0.19021564383804798, "critic_loss": 0.6633500063121319, "actor_loss": -26.129361507415773, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.851345539093018, "step": 75000}
{"episode_reward": 185.29912567990345, "episode": 76.0, "batch_reward": 0.19090121921896935, "critic_loss": 0.7118443274497985, "actor_loss": -25.992666973114012, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.133840084075928, "step": 76000}
{"episode_reward": 321.0392504938031, "episode": 77.0, "batch_reward": 0.19024016781151296, "critic_loss": 0.7239275464117527, "actor_loss": -26.003464435577392, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.862180471420288, "step": 77000}
{"episode_reward": 70.59744370206933, "episode": 78.0, "batch_reward": 0.1897252804785967, "critic_loss": 0.9464824468195439, "actor_loss": -26.243816326141356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.575624465942383, "step": 78000}
{"episode_reward": 177.79809319601162, "episode": 79.0, "batch_reward": 0.18795446844398975, "critic_loss": 1.6885931617021561, "actor_loss": -26.41933055114746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.42221474647522, "step": 79000}
{"episode_reward": 8.587478294634906, "episode": 80.0, "batch_reward": 0.18603953328728676, "critic_loss": 3.056915595650673, "actor_loss": -28.520542278289795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.827428340911865, "step": 80000}
{"episode_reward": 5.515761762320232, "episode": 81.0, "batch_reward": 0.18346835893392563, "critic_loss": 2.9119743498563766, "actor_loss": -30.2270577545166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.26933264732361, "step": 81000}
{"episode_reward": 4.10637443043675, "episode": 82.0, "batch_reward": 0.1816652242541313, "critic_loss": 2.542943987131119, "actor_loss": -31.04288249588013, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.433801651000977, "step": 82000}
{"episode_reward": 3.576298359270393, "episode": 83.0, "batch_reward": 0.17884697234630584, "critic_loss": 2.0965352932214736, "actor_loss": -31.32975991821289, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.422141551971436, "step": 83000}
{"episode_reward": 2.9959119850841205, "episode": 84.0, "batch_reward": 0.17752319905161856, "critic_loss": 1.7914095934033394, "actor_loss": -31.66030443572998, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.57756280899048, "step": 84000}
{"episode_reward": 8.246623064486238, "episode": 85.0, "batch_reward": 0.17477952305227518, "critic_loss": 1.522761406838894, "actor_loss": -31.96523790359497, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.8592312335968, "step": 85000}
{"episode_reward": 3.6256219891527377, "episode": 86.0, "batch_reward": 0.173532111287117, "critic_loss": 1.3265133387446404, "actor_loss": -32.224444175720215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.917232275009155, "step": 86000}
{"episode_reward": 5.161252726894369, "episode": 87.0, "batch_reward": 0.1714410385787487, "critic_loss": 1.1053563633859158, "actor_loss": -32.13201115036011, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.9804949760437, "step": 87000}
{"episode_reward": 6.224782450580504, "episode": 88.0, "batch_reward": 0.1697651998102665, "critic_loss": 0.9688678323924541, "actor_loss": -32.140143028259274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.471341133117676, "step": 88000}
{"episode_reward": 18.386767649602394, "episode": 89.0, "batch_reward": 0.16780643753707408, "critic_loss": 0.8224552157223225, "actor_loss": -31.973695613861086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.898913383483887, "step": 89000}
{"episode_reward": 46.19398863732267, "episode": 90.0, "batch_reward": 0.16649148757010698, "critic_loss": 0.7415351962149144, "actor_loss": -31.66259220504761, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.83623719215393, "step": 90000}
{"episode_reward": 97.8684576320638, "episode": 91.0, "batch_reward": 0.16625029952079057, "critic_loss": 0.667461720496416, "actor_loss": -31.327966369628907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.25506567955017, "step": 91000}
{"episode_reward": 124.28741707301988, "episode": 92.0, "batch_reward": 0.1666222742497921, "critic_loss": 0.6103311505317688, "actor_loss": -31.099783515930177, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.06786346435547, "step": 92000}
{"episode_reward": 141.52857350559196, "episode": 93.0, "batch_reward": 0.1650467391908169, "critic_loss": 0.5450133225321769, "actor_loss": -30.799153537750243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.143996953964233, "step": 93000}
{"episode_reward": 132.0916641665402, "episode": 94.0, "batch_reward": 0.1650392418652773, "critic_loss": 0.5403183612674475, "actor_loss": -30.462986766815185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.553126335144043, "step": 94000}
{"episode_reward": 162.20679338547185, "episode": 95.0, "batch_reward": 0.1652123921662569, "critic_loss": 0.49358719873428347, "actor_loss": -30.34629178237915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.312692642211914, "step": 95000}
{"episode_reward": 196.65052521929002, "episode": 96.0, "batch_reward": 0.16597042172402143, "critic_loss": 0.4396220052987337, "actor_loss": -29.869352840423584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.123886108398438, "step": 96000}
{"episode_reward": 266.13834276256415, "episode": 97.0, "batch_reward": 0.16838429033756255, "critic_loss": 0.3988724460452795, "actor_loss": -29.774140659332275, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.79835271835327, "step": 97000}
{"episode_reward": 291.7352405037214, "episode": 98.0, "batch_reward": 0.16965119057148695, "critic_loss": 0.41795721837878225, "actor_loss": -29.424708709716796, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.233986616134644, "step": 98000}
{"episode_reward": 381.9516395894486, "episode": 99.0, "batch_reward": 0.1700204506367445, "critic_loss": 0.4227086547315121, "actor_loss": -29.067927028656005, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.67184805870056, "step": 99000}
{"episode_reward": 302.8154220607276, "episode": 100.0, "batch_reward": 0.17252378799021245, "critic_loss": 0.4351127963215113, "actor_loss": -28.762473152160645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.07304310798645, "step": 100000}
{"episode_reward": 265.5739020314382, "episode": 101.0, "batch_reward": 0.17270093129575254, "critic_loss": 0.4386770278960466, "actor_loss": -28.727873138427736, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.65386939048767, "step": 101000}
{"episode_reward": 383.29964679586647, "episode": 102.0, "batch_reward": 0.17491083043813704, "critic_loss": 0.4034630602151155, "actor_loss": -28.46387313461304, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.323649883270264, "step": 102000}
{"episode_reward": 357.9534520915769, "episode": 103.0, "batch_reward": 0.1771697904020548, "critic_loss": 0.4157997425198555, "actor_loss": -28.44582427215576, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.881309270858765, "step": 103000}
{"episode_reward": 354.80746648968983, "episode": 104.0, "batch_reward": 0.1784135019928217, "critic_loss": 0.3916513924449682, "actor_loss": -28.11566431427002, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.61305856704712, "step": 104000}
{"episode_reward": 349.73997719648446, "episode": 105.0, "batch_reward": 0.18138643188774586, "critic_loss": 0.4204330676943064, "actor_loss": -28.187703742980958, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.396023273468018, "step": 105000}
{"episode_reward": 339.2623176525538, "episode": 106.0, "batch_reward": 0.18165647554397582, "critic_loss": 0.4315225060135126, "actor_loss": -27.797945816040038, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.40168070793152, "step": 106000}
{"episode_reward": 420.9527439357939, "episode": 107.0, "batch_reward": 0.18486631564795972, "critic_loss": 0.42799926102161406, "actor_loss": -28.060807849884032, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.26139998435974, "step": 107000}
{"episode_reward": 472.0908666876349, "episode": 108.0, "batch_reward": 0.18733550432324408, "critic_loss": 0.4421001678556204, "actor_loss": -28.147280437469483, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.920494079589844, "step": 108000}
{"episode_reward": 492.261338942633, "episode": 109.0, "batch_reward": 0.189353451654315, "critic_loss": 0.43209039679169653, "actor_loss": -28.090126861572266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.863492250442505, "step": 109000}
{"episode_reward": 393.9444212334802, "episode": 110.0, "batch_reward": 0.1922049373984337, "critic_loss": 0.4164966222494841, "actor_loss": -28.373571090698242, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.07124662399292, "step": 110000}
{"episode_reward": 378.77641435180067, "episode": 111.0, "batch_reward": 0.19410446654260158, "critic_loss": 0.4283334483355284, "actor_loss": -28.574600589752198, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.90626883506775, "step": 111000}
{"episode_reward": 423.9468311222807, "episode": 112.0, "batch_reward": 0.19644757311046124, "critic_loss": 0.426939883351326, "actor_loss": -28.251891582489012, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.29751968383789, "step": 112000}
{"episode_reward": 422.1771216571241, "episode": 113.0, "batch_reward": 0.19778407061100006, "critic_loss": 0.4229765385091305, "actor_loss": -28.131235458374025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34682297706604, "step": 113000}
{"episode_reward": 470.50673962450696, "episode": 114.0, "batch_reward": 0.19989622955024242, "critic_loss": 0.4102026674598455, "actor_loss": -28.76908086013794, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.770325422286987, "step": 114000}
{"episode_reward": 420.30725651800907, "episode": 115.0, "batch_reward": 0.2021392571926117, "critic_loss": 0.41901924812793734, "actor_loss": -28.534412788391112, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.402533054351807, "step": 115000}
{"episode_reward": 375.2534622079186, "episode": 116.0, "batch_reward": 0.2030121629089117, "critic_loss": 0.443900433704257, "actor_loss": -28.656107902526855, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.628312587738037, "step": 116000}
{"episode_reward": 241.8200874483923, "episode": 117.0, "batch_reward": 0.2027185800820589, "critic_loss": 0.4331723530739546, "actor_loss": -28.181166370391846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.888182878494263, "step": 117000}
{"episode_reward": 463.3041317335559, "episode": 118.0, "batch_reward": 0.20586953276395797, "critic_loss": 0.43650642287731173, "actor_loss": -28.578625568389892, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.255701541900635, "step": 118000}
{"episode_reward": 214.69938593305795, "episode": 119.0, "batch_reward": 0.2057264128178358, "critic_loss": 0.4345560163706541, "actor_loss": -28.676778900146484, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.683705806732178, "step": 119000}
{"episode_reward": 405.52133017289975, "episode": 120.0, "batch_reward": 0.20719043597579, "critic_loss": 0.454369562715292, "actor_loss": -28.229910926818846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.249720811843872, "step": 120000}
{"episode_reward": 499.48201185238094, "episode": 121.0, "batch_reward": 0.2110652839690447, "critic_loss": 0.4449042319059372, "actor_loss": -28.759245094299317, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.556222915649414, "step": 121000}
{"episode_reward": 471.0532982355111, "episode": 122.0, "batch_reward": 0.21310323487222194, "critic_loss": 0.4621665454953909, "actor_loss": -29.12807818984985, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.29829740524292, "step": 122000}
{"episode_reward": 509.52031586047633, "episode": 123.0, "batch_reward": 0.21591374449431897, "critic_loss": 0.4382836556583643, "actor_loss": -28.759035446166994, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.243722200393677, "step": 123000}
{"episode_reward": 473.4629033892681, "episode": 124.0, "batch_reward": 0.21660053759813308, "critic_loss": 0.44674036088585856, "actor_loss": -29.27073123931885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.299378633499146, "step": 124000}
{"episode_reward": 438.5998124480831, "episode": 125.0, "batch_reward": 0.21818142242729663, "critic_loss": 0.43685387054085734, "actor_loss": -28.880900981903075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.021490812301636, "step": 125000}
{"episode_reward": 477.5890290108025, "episode": 126.0, "batch_reward": 0.22045884382724762, "critic_loss": 0.4194963620305061, "actor_loss": -29.586452033996583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.75600004196167, "step": 126000}
{"episode_reward": 484.7761617078906, "episode": 127.0, "batch_reward": 0.22271523961424827, "critic_loss": 0.4275709806382656, "actor_loss": -29.78037706756592, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.4644832611084, "step": 127000}
{"episode_reward": 488.16278008475973, "episode": 128.0, "batch_reward": 0.22529905726015567, "critic_loss": 0.41403898818790913, "actor_loss": -29.870945865631104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.951520919799805, "step": 128000}
{"episode_reward": 518.8049738879087, "episode": 129.0, "batch_reward": 0.2272152851819992, "critic_loss": 0.40033249148726463, "actor_loss": -30.13096057510376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.723852396011353, "step": 129000}
{"episode_reward": 488.5520307647878, "episode": 130.0, "batch_reward": 0.22921698273718358, "critic_loss": 0.39273495104908945, "actor_loss": -30.338570903778077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.122019052505493, "step": 130000}
{"episode_reward": 481.8366412770008, "episode": 131.0, "batch_reward": 0.23243426950275897, "critic_loss": 0.3896631086021662, "actor_loss": -30.551828407287598, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.227516174316406, "step": 131000}
{"episode_reward": 481.3927719436288, "episode": 132.0, "batch_reward": 0.23304511423408986, "critic_loss": 0.3979858011007309, "actor_loss": -30.31436519241333, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.290101289749146, "step": 132000}
{"episode_reward": 491.6084647578099, "episode": 133.0, "batch_reward": 0.2354142190515995, "critic_loss": 0.4087094001173973, "actor_loss": -30.7080631980896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.41913104057312, "step": 133000}
{"episode_reward": 547.117399247407, "episode": 134.0, "batch_reward": 0.2375745039731264, "critic_loss": 0.41900166453421117, "actor_loss": -31.031466800689696, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.52843976020813, "step": 134000}
{"episode_reward": 508.4453694430409, "episode": 135.0, "batch_reward": 0.23942742842435838, "critic_loss": 0.4004089323878288, "actor_loss": -30.949832405090334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.578574895858765, "step": 135000}
{"episode_reward": 516.0052384058594, "episode": 136.0, "batch_reward": 0.24160246884822845, "critic_loss": 0.38839232344925406, "actor_loss": -31.35449415588379, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.663594245910645, "step": 136000}
{"episode_reward": 532.9701965998862, "episode": 137.0, "batch_reward": 0.24361652582883836, "critic_loss": 0.3882346400618553, "actor_loss": -31.226751399993898, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.895068883895874, "step": 137000}
{"episode_reward": 500.71108786201876, "episode": 138.0, "batch_reward": 0.24640163482725622, "critic_loss": 0.36571441566944124, "actor_loss": -31.144763885498048, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.491854429244995, "step": 138000}
{"episode_reward": 568.4074506774793, "episode": 139.0, "batch_reward": 0.24801640693843366, "critic_loss": 0.37078724582493305, "actor_loss": -31.44452043914795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.94905138015747, "step": 139000}
{"episode_reward": 539.8150069954658, "episode": 140.0, "batch_reward": 0.24963639959692954, "critic_loss": 0.36716244952380656, "actor_loss": -31.32185835647583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.764599084854126, "step": 140000}
{"episode_reward": 533.2262057528332, "episode": 141.0, "batch_reward": 0.2527920979857445, "critic_loss": 0.3683944549411535, "actor_loss": -31.353808208465576, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.25185990333557, "step": 141000}
{"episode_reward": 533.1655216656535, "episode": 142.0, "batch_reward": 0.2537574251890182, "critic_loss": 0.3394080256223679, "actor_loss": -31.961601806640626, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.925856113433838, "step": 142000}
{"episode_reward": 545.8487084798124, "episode": 143.0, "batch_reward": 0.256453981295228, "critic_loss": 0.3623293362855911, "actor_loss": -31.961863262176514, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.722370862960815, "step": 143000}
{"episode_reward": 516.6584554857104, "episode": 144.0, "batch_reward": 0.25894677796959875, "critic_loss": 0.3536416059434414, "actor_loss": -32.37753033065796, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.33120846748352, "step": 144000}
{"episode_reward": 498.76301568638286, "episode": 145.0, "batch_reward": 0.26114922077953817, "critic_loss": 0.33479622699320316, "actor_loss": -32.31756285476685, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.19576144218445, "step": 145000}
{"episode_reward": 495.4605698771103, "episode": 146.0, "batch_reward": 0.26068075054883955, "critic_loss": 0.3084922824501991, "actor_loss": -32.7429175567627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.91224956512451, "step": 146000}
{"episode_reward": 538.1129611027593, "episode": 147.0, "batch_reward": 0.2624286148548126, "critic_loss": 0.32562970788776874, "actor_loss": -32.66419761276245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.36369490623474, "step": 147000}
{"episode_reward": 545.9703411831953, "episode": 148.0, "batch_reward": 0.2655444643199444, "critic_loss": 0.3352537654489279, "actor_loss": -32.890164436340335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.390697956085205, "step": 148000}
{"episode_reward": 582.8282166519987, "episode": 149.0, "batch_reward": 0.26715660209953784, "critic_loss": 0.35650571808218956, "actor_loss": -33.05703941726684, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.418479681015015, "step": 149000}
{"episode_reward": 521.2949927799203, "episode": 150.0, "batch_reward": 0.269065992474556, "critic_loss": 0.34563078053295615, "actor_loss": -33.42665631484985, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
