{"episode_reward": 0.0, "episode": 1.0, "duration": 18.56675672531128, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.6273772716522217, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.31364655300910255, "critic_loss": 0.11243069334382333, "actor_loss": -49.28302940438871, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 86.21342086791992, "step": 3000}
{"episode_reward": 637.6277701217232, "episode": 4.0, "batch_reward": 0.4219924255013466, "critic_loss": 0.14190099357813596, "actor_loss": -56.76909324645996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.110289335250854, "step": 4000}
{"episode_reward": 601.9229777149765, "episode": 5.0, "batch_reward": 0.4529322375357151, "critic_loss": 0.2189067873880267, "actor_loss": -57.842139236450194, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.094929218292236, "step": 5000}
{"episode_reward": 362.62673313308585, "episode": 6.0, "batch_reward": 0.43192582625150683, "critic_loss": 0.3188261518031359, "actor_loss": -54.96517097473144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.87968921661377, "step": 6000}
{"episode_reward": 372.8208623410931, "episode": 7.0, "batch_reward": 0.42589098706841466, "critic_loss": 0.34457058799266815, "actor_loss": -53.96328060150147, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.034860849380493, "step": 7000}
{"episode_reward": 498.17836686013226, "episode": 8.0, "batch_reward": 0.42150825944542886, "critic_loss": 0.3634226658642292, "actor_loss": -53.03366439056396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.78620457649231, "step": 8000}
{"episode_reward": 109.39764060434253, "episode": 9.0, "batch_reward": 0.39893258434534073, "critic_loss": 0.3359044013917446, "actor_loss": -50.62036276245117, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.286877870559692, "step": 9000}
{"episode_reward": 515.9932385704444, "episode": 10.0, "batch_reward": 0.416449394762516, "critic_loss": 0.3060457985252142, "actor_loss": -51.8825090713501, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.488542795181274, "step": 10000}
{"episode_reward": 608.7968375627042, "episode": 11.0, "batch_reward": 0.43315766245126724, "critic_loss": 0.33366771003603934, "actor_loss": -53.37013117980957, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.698203325271606, "step": 11000}
{"episode_reward": 587.4829896306812, "episode": 12.0, "batch_reward": 0.4481564503312111, "critic_loss": 0.3331838595718145, "actor_loss": -54.27579531097412, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.39669370651245, "step": 12000}
{"episode_reward": 608.0309046770657, "episode": 13.0, "batch_reward": 0.45696468275785446, "critic_loss": 0.3555783368498087, "actor_loss": -54.851582588195804, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.413329124450684, "step": 13000}
{"episode_reward": 546.942994988228, "episode": 14.0, "batch_reward": 0.46642839589715, "critic_loss": 0.34412563697993753, "actor_loss": -55.316750457763675, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.88028049468994, "step": 14000}
{"episode_reward": 598.2407803658989, "episode": 15.0, "batch_reward": 0.4752494253218174, "critic_loss": 0.3241885095238686, "actor_loss": -56.03982398223877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.55013108253479, "step": 15000}
{"episode_reward": 572.9566264485394, "episode": 16.0, "batch_reward": 0.4825706275701523, "critic_loss": 0.2689289596825838, "actor_loss": -56.31571828460693, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.331300020217896, "step": 16000}
{"episode_reward": 595.6732746412305, "episode": 17.0, "batch_reward": 0.4859510902762413, "critic_loss": 0.25761740016937257, "actor_loss": -56.432182502746585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.023704528808594, "step": 17000}
{"episode_reward": 497.79303802324995, "episode": 18.0, "batch_reward": 0.48555115470290183, "critic_loss": 0.25413170805573465, "actor_loss": -56.13293455505371, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.478987216949463, "step": 18000}
{"episode_reward": 450.8733397045122, "episode": 19.0, "batch_reward": 0.48651991951465606, "critic_loss": 0.22689942143857478, "actor_loss": -56.0596849899292, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.150535821914673, "step": 19000}
{"episode_reward": 554.1125930100312, "episode": 20.0, "batch_reward": 0.48984995499253275, "critic_loss": 0.21000222046673298, "actor_loss": -56.00007823181152, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.909311056137085, "step": 20000}
{"episode_reward": 563.3414222029662, "episode": 21.0, "batch_reward": 0.4932960085272789, "critic_loss": 0.1933115605339408, "actor_loss": -56.203383934021, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.95170497894287, "step": 21000}
{"episode_reward": 548.0390529722442, "episode": 22.0, "batch_reward": 0.4966528632044792, "critic_loss": 0.1805119942575693, "actor_loss": -56.253205764770506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.11187720298767, "step": 22000}
{"episode_reward": 553.6200501896208, "episode": 23.0, "batch_reward": 0.5008618391454219, "critic_loss": 0.18127947806566955, "actor_loss": -56.25648564147949, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.9861798286438, "step": 23000}
{"episode_reward": 563.666554134126, "episode": 24.0, "batch_reward": 0.5033636710047722, "critic_loss": 0.17885062889754771, "actor_loss": -56.138051315307614, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.35864567756653, "step": 24000}
{"episode_reward": 625.8097636149952, "episode": 25.0, "batch_reward": 0.5035735357999802, "critic_loss": 0.1807834377363324, "actor_loss": -56.16060832977295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.601908683776855, "step": 25000}
{"episode_reward": 514.4224014765617, "episode": 26.0, "batch_reward": 0.5066969695985317, "critic_loss": 0.17034682235866785, "actor_loss": -56.14282341003418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.19906258583069, "step": 26000}
{"episode_reward": 614.891196157276, "episode": 27.0, "batch_reward": 0.5124543922245502, "critic_loss": 0.16913291296362876, "actor_loss": -56.34268742370605, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.1150963306427, "step": 27000}
{"episode_reward": 584.5467665862761, "episode": 28.0, "batch_reward": 0.5167952954471111, "critic_loss": 0.16604409234970807, "actor_loss": -56.446401763916015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.90614366531372, "step": 28000}
{"episode_reward": 627.7725526305369, "episode": 29.0, "batch_reward": 0.5189743278324604, "critic_loss": 0.16107288489490748, "actor_loss": -56.40289073944092, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.91832423210144, "step": 29000}
{"episode_reward": 602.0303509870074, "episode": 30.0, "batch_reward": 0.5222717971801758, "critic_loss": 0.1544472478553653, "actor_loss": -56.551229736328125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.83354878425598, "step": 30000}
{"episode_reward": 636.3980084811119, "episode": 31.0, "batch_reward": 0.5261181927919388, "critic_loss": 0.15605489280819893, "actor_loss": -56.67108583831787, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.42286133766174, "step": 31000}
{"episode_reward": 668.7229636962625, "episode": 32.0, "batch_reward": 0.530368649750948, "critic_loss": 0.1529838145375252, "actor_loss": -56.71984397888183, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.601035594940186, "step": 32000}
{"episode_reward": 643.9721580559299, "episode": 33.0, "batch_reward": 0.532692559748888, "critic_loss": 0.15316557989269494, "actor_loss": -56.97375819396973, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.72402000427246, "step": 33000}
{"episode_reward": 596.2363389829687, "episode": 34.0, "batch_reward": 0.534685448050499, "critic_loss": 0.15112237499654294, "actor_loss": -57.29979147338867, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.224435329437256, "step": 34000}
{"episode_reward": 630.3352130328137, "episode": 35.0, "batch_reward": 0.5370901730060578, "critic_loss": 0.15161504083126784, "actor_loss": -57.12737183380127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.080176830291748, "step": 35000}
{"episode_reward": 628.0663334950672, "episode": 36.0, "batch_reward": 0.5402683390974998, "critic_loss": 0.14866483107209205, "actor_loss": -57.40522537994385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.979918718338013, "step": 36000}
{"episode_reward": 656.7428117342226, "episode": 37.0, "batch_reward": 0.5439622796475887, "critic_loss": 0.14977822078019382, "actor_loss": -57.62876657104492, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.424583196640015, "step": 37000}
{"episode_reward": 655.423099444059, "episode": 38.0, "batch_reward": 0.5470643944144249, "critic_loss": 0.1604504601210356, "actor_loss": -57.672328315734866, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.709279537200928, "step": 38000}
{"episode_reward": 654.4253124028733, "episode": 39.0, "batch_reward": 0.5496882609128952, "critic_loss": 0.1744315497651696, "actor_loss": -57.71771215820313, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.359307289123535, "step": 39000}
{"episode_reward": 661.93598591783, "episode": 40.0, "batch_reward": 0.5508607303500176, "critic_loss": 0.2102769920229912, "actor_loss": -57.8282328338623, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.467382192611694, "step": 40000}
{"episode_reward": 617.5853211095525, "episode": 41.0, "batch_reward": 0.5537850337922573, "critic_loss": 0.19324506552517415, "actor_loss": -58.01742277526856, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.573808431625366, "step": 41000}
{"episode_reward": 673.6153539571324, "episode": 42.0, "batch_reward": 0.5575294183492661, "critic_loss": 0.1798725964128971, "actor_loss": -58.45672594451904, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.869555950164795, "step": 42000}
{"episode_reward": 659.9316584673143, "episode": 43.0, "batch_reward": 0.5596203884780407, "critic_loss": 0.18014200559258461, "actor_loss": -58.59895906829834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.88568902015686, "step": 43000}
{"episode_reward": 625.3554004161047, "episode": 44.0, "batch_reward": 0.5558637251853943, "critic_loss": 0.17720517399907112, "actor_loss": -58.46121531677246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.658162593841553, "step": 44000}
{"episode_reward": 302.1292845959269, "episode": 45.0, "batch_reward": 0.5542559198439121, "critic_loss": 0.16447828070819379, "actor_loss": -58.152084564208984, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.9758038520813, "step": 45000}
{"episode_reward": 639.7600398862226, "episode": 46.0, "batch_reward": 0.5512275879085063, "critic_loss": 0.16760457722842692, "actor_loss": -58.07168714141846, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.041231632232666, "step": 46000}
{"episode_reward": 223.99260782031132, "episode": 47.0, "batch_reward": 0.5492785699665547, "critic_loss": 0.1600958947762847, "actor_loss": -58.051892196655274, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.96319842338562, "step": 47000}
{"episode_reward": 611.3245907925553, "episode": 48.0, "batch_reward": 0.5512561689317227, "critic_loss": 0.1553396869674325, "actor_loss": -58.27680544281006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.203168630599976, "step": 48000}
{"episode_reward": 672.4204386731413, "episode": 49.0, "batch_reward": 0.555134378105402, "critic_loss": 0.1566291824877262, "actor_loss": -58.43972040557861, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.247517108917236, "step": 49000}
{"episode_reward": 676.4785165283455, "episode": 50.0, "batch_reward": 0.5565088799297809, "critic_loss": 0.16223385831713677, "actor_loss": -58.363096939086915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.278360843658447, "step": 50000}
{"episode_reward": 643.8115327439738, "episode": 51.0, "batch_reward": 0.5568320920467377, "critic_loss": 0.15975530441850425, "actor_loss": -58.669954139709475, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.79035043716431, "step": 51000}
{"episode_reward": 635.4743749450329, "episode": 52.0, "batch_reward": 0.5589411225318909, "critic_loss": 0.15777472764998673, "actor_loss": -58.56368747711181, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.68485927581787, "step": 52000}
{"episode_reward": 665.5420756621525, "episode": 53.0, "batch_reward": 0.5627138024568558, "critic_loss": 0.1542385359555483, "actor_loss": -58.87881848907471, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.021045446395874, "step": 53000}
{"episode_reward": 682.9106108513391, "episode": 54.0, "batch_reward": 0.5638336029648781, "critic_loss": 0.15052026203274727, "actor_loss": -58.97129623413086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.11684489250183, "step": 54000}
{"episode_reward": 666.59610734013, "episode": 55.0, "batch_reward": 0.5653702235817909, "critic_loss": 0.15467733125388622, "actor_loss": -59.176974273681644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.959392309188843, "step": 55000}
{"episode_reward": 666.2064454345826, "episode": 56.0, "batch_reward": 0.5681234034895897, "critic_loss": 0.1577809728011489, "actor_loss": -59.14425673675537, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.45849633216858, "step": 56000}
{"episode_reward": 662.613634017877, "episode": 57.0, "batch_reward": 0.5704632337093354, "critic_loss": 0.15018325236439706, "actor_loss": -59.20891404724121, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.183559894561768, "step": 57000}
{"episode_reward": 695.8524680388213, "episode": 58.0, "batch_reward": 0.5713956070542335, "critic_loss": 0.15242706633359193, "actor_loss": -59.62932172393799, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.221723556518555, "step": 58000}
{"episode_reward": 667.9444412766039, "episode": 59.0, "batch_reward": 0.5729575387239456, "critic_loss": 0.15186470388621093, "actor_loss": -59.78195621490479, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.924159049987793, "step": 59000}
{"episode_reward": 675.4598569020131, "episode": 60.0, "batch_reward": 0.5746719072461128, "critic_loss": 0.15339947540313006, "actor_loss": -59.61084650421142, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.046290397644043, "step": 60000}
{"episode_reward": 690.9115272177086, "episode": 61.0, "batch_reward": 0.5752104411721229, "critic_loss": 0.1503209956884384, "actor_loss": -59.951699211120605, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.40318846702576, "step": 61000}
{"episode_reward": 616.5986287748988, "episode": 62.0, "batch_reward": 0.5769692586064339, "critic_loss": 0.15034135503321885, "actor_loss": -60.14387572479248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.174628734588623, "step": 62000}
{"episode_reward": 696.8172652132058, "episode": 63.0, "batch_reward": 0.5782165721654892, "critic_loss": 0.1478261028304696, "actor_loss": -60.10386071014404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.24799156188965, "step": 63000}
{"episode_reward": 658.3095096365034, "episode": 64.0, "batch_reward": 0.5804622516334057, "critic_loss": 0.14499465603381395, "actor_loss": -60.38793519592285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.88967776298523, "step": 64000}
{"episode_reward": 677.6906900839684, "episode": 65.0, "batch_reward": 0.5821833872199058, "critic_loss": 0.14893617739528417, "actor_loss": -60.44533068084717, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.07904863357544, "step": 65000}
{"episode_reward": 679.2080321459308, "episode": 66.0, "batch_reward": 0.5826958208084106, "critic_loss": 0.15268982227146627, "actor_loss": -60.53069570159912, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.764280080795288, "step": 66000}
{"episode_reward": 636.924679692908, "episode": 67.0, "batch_reward": 0.5835264929533005, "critic_loss": 0.15777088558673857, "actor_loss": -60.40238009643555, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.640352487564087, "step": 67000}
{"episode_reward": 648.0355691753255, "episode": 68.0, "batch_reward": 0.5852106627225876, "critic_loss": 0.16415779872238637, "actor_loss": -60.87274638366699, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.098112106323242, "step": 68000}
{"episode_reward": 674.8381856306387, "episode": 69.0, "batch_reward": 0.5857938473820686, "critic_loss": 0.159936713591218, "actor_loss": -60.8555758895874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.262216806411743, "step": 69000}
{"episode_reward": 649.0021300722716, "episode": 70.0, "batch_reward": 0.5874237329959869, "critic_loss": 0.16260756159573794, "actor_loss": -60.8447529296875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.98738121986389, "step": 70000}
{"episode_reward": 683.1690887424039, "episode": 71.0, "batch_reward": 0.5882850443124771, "critic_loss": 0.16506028982251883, "actor_loss": -61.098790687561035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 45.024027824401855, "step": 71000}
{"episode_reward": 680.2828098499109, "episode": 72.0, "batch_reward": 0.5906621751785278, "critic_loss": 0.16215727226436139, "actor_loss": -61.21677850341797, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.696817636489868, "step": 72000}
{"episode_reward": 688.1333935818739, "episode": 73.0, "batch_reward": 0.5904798936247826, "critic_loss": 0.1644386666789651, "actor_loss": -61.277567848205564, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.137749910354614, "step": 73000}
{"episode_reward": 649.110872378968, "episode": 74.0, "batch_reward": 0.5925688837766647, "critic_loss": 0.16318419552594424, "actor_loss": -61.35376484680176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.667001962661743, "step": 74000}
{"episode_reward": 675.5493208646546, "episode": 75.0, "batch_reward": 0.5934512919783592, "critic_loss": 0.16746764847636222, "actor_loss": -61.43756463623047, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.71635127067566, "step": 75000}
{"episode_reward": 711.5655095793438, "episode": 76.0, "batch_reward": 0.5961338988542557, "critic_loss": 0.16229376930743455, "actor_loss": -61.734034141540526, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.484728813171387, "step": 76000}
{"episode_reward": 705.8217772708362, "episode": 77.0, "batch_reward": 0.596555737376213, "critic_loss": 0.16467106455564498, "actor_loss": -61.72070345306396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.965354442596436, "step": 77000}
{"episode_reward": 687.2055155877609, "episode": 78.0, "batch_reward": 0.5982007144093513, "critic_loss": 0.17510973091423512, "actor_loss": -61.77649062347412, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.990612745285034, "step": 78000}
{"episode_reward": 634.4389934381333, "episode": 79.0, "batch_reward": 0.5981319628357887, "critic_loss": 0.17695771168917418, "actor_loss": -62.05130497741699, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.54783535003662, "step": 79000}
{"episode_reward": 660.4890959603865, "episode": 80.0, "batch_reward": 0.5997507802844048, "critic_loss": 0.1781338286846876, "actor_loss": -62.09909394073486, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.459876537322998, "step": 80000}
{"episode_reward": 672.6988537823743, "episode": 81.0, "batch_reward": 0.5992887358665466, "critic_loss": 0.17915024603903293, "actor_loss": -62.10080683898926, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.70004892349243, "step": 81000}
{"episode_reward": 637.4075457087731, "episode": 82.0, "batch_reward": 0.6007082293629646, "critic_loss": 0.1974770395681262, "actor_loss": -61.977858612060544, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.75956964492798, "step": 82000}
{"episode_reward": 670.6539232175215, "episode": 83.0, "batch_reward": 0.6011251463890076, "critic_loss": 0.19196155928075315, "actor_loss": -62.24055094146728, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.08954119682312, "step": 83000}
{"episode_reward": 675.8341291350156, "episode": 84.0, "batch_reward": 0.6024393011927605, "critic_loss": 0.1953232277482748, "actor_loss": -62.382956489562986, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.93206000328064, "step": 84000}
{"episode_reward": 646.4257346180507, "episode": 85.0, "batch_reward": 0.6019497130513192, "critic_loss": 0.1954215058237314, "actor_loss": -62.309984840393064, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.820083379745483, "step": 85000}
{"episode_reward": 683.231380936199, "episode": 86.0, "batch_reward": 0.6027108428478241, "critic_loss": 0.19938284093141556, "actor_loss": -62.393555397033694, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.199168920516968, "step": 86000}
{"episode_reward": 624.7652405939199, "episode": 87.0, "batch_reward": 0.602894967854023, "critic_loss": 0.20619454614073038, "actor_loss": -62.515805297851564, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.096381664276123, "step": 87000}
{"episode_reward": 709.7068369938888, "episode": 88.0, "batch_reward": 0.6064436888098717, "critic_loss": 0.21166634463518857, "actor_loss": -62.891330505371094, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.505188465118408, "step": 88000}
{"episode_reward": 686.1266678323175, "episode": 89.0, "batch_reward": 0.6054650012254715, "critic_loss": 0.22648753824830056, "actor_loss": -62.76650607299805, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.119940996170044, "step": 89000}
{"episode_reward": 700.0691450324667, "episode": 90.0, "batch_reward": 0.6062703890800476, "critic_loss": 0.21623550340533257, "actor_loss": -62.74125095367432, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.203736782073975, "step": 90000}
{"episode_reward": 647.4040129059, "episode": 91.0, "batch_reward": 0.6073606375455857, "critic_loss": 0.244829330265522, "actor_loss": -62.91849765777588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.48469519615173, "step": 91000}
{"episode_reward": 688.4726773332399, "episode": 92.0, "batch_reward": 0.6088083256483078, "critic_loss": 0.26910511050373315, "actor_loss": -63.168536140441894, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.875730514526367, "step": 92000}
{"episode_reward": 638.6321372028948, "episode": 93.0, "batch_reward": 0.6069462059140205, "critic_loss": 0.29657814526557924, "actor_loss": -63.09201840209961, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.002169370651245, "step": 93000}
{"episode_reward": 687.9379814147836, "episode": 94.0, "batch_reward": 0.6078359617590904, "critic_loss": 0.312486817188561, "actor_loss": -63.242478965759275, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.982017993927002, "step": 94000}
{"episode_reward": 544.5874939763215, "episode": 95.0, "batch_reward": 0.60732314068079, "critic_loss": 0.30690649973601103, "actor_loss": -63.08602056884766, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.565175533294678, "step": 95000}
{"episode_reward": 690.34839367395, "episode": 96.0, "batch_reward": 0.608941304564476, "critic_loss": 0.29320773242414, "actor_loss": -63.351682914733885, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.335386276245117, "step": 96000}
{"episode_reward": 698.8749059523058, "episode": 97.0, "batch_reward": 0.6106292068362236, "critic_loss": 0.3266337589249015, "actor_loss": -63.407446685791015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.886199712753296, "step": 97000}
{"episode_reward": 646.1767668554099, "episode": 98.0, "batch_reward": 0.610895210802555, "critic_loss": 0.3348666324466467, "actor_loss": -63.62630419921875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.795462131500244, "step": 98000}
{"episode_reward": 681.9394230107855, "episode": 99.0, "batch_reward": 0.6110778793692588, "critic_loss": 0.35221075028181076, "actor_loss": -63.62074453735352, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.898162841796875, "step": 99000}
{"episode_reward": 703.004867824711, "episode": 100.0, "batch_reward": 0.6139520685076714, "critic_loss": 0.3508983493298292, "actor_loss": -63.88192697906494, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.179233074188232, "step": 100000}
{"episode_reward": 675.7137627282125, "episode": 101.0, "batch_reward": 0.6125091785192489, "critic_loss": 0.35822321198880674, "actor_loss": -63.68242529296875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.761927366256714, "step": 101000}
{"episode_reward": 637.1294381195734, "episode": 102.0, "batch_reward": 0.6132625955939293, "critic_loss": 0.40066154485940936, "actor_loss": -63.90634053039551, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.61949896812439, "step": 102000}
{"episode_reward": 721.7947870441179, "episode": 103.0, "batch_reward": 0.6141803398132324, "critic_loss": 0.4606334789097309, "actor_loss": -64.10331505584716, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.634020805358887, "step": 103000}
{"episode_reward": 703.3389719737071, "episode": 104.0, "batch_reward": 0.6156847413182258, "critic_loss": 0.4926671869084239, "actor_loss": -64.23997896575928, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.030385494232178, "step": 104000}
{"episode_reward": 693.2496882063247, "episode": 105.0, "batch_reward": 0.6171126319169998, "critic_loss": 0.5649352959245444, "actor_loss": -64.37360847473144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.997607469558716, "step": 105000}
{"episode_reward": 678.5607128464542, "episode": 106.0, "batch_reward": 0.6168618938326835, "critic_loss": 0.693149765715003, "actor_loss": -64.61440467834473, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.09635329246521, "step": 106000}
{"episode_reward": 676.7762933187794, "episode": 107.0, "batch_reward": 0.6171685402989388, "critic_loss": 0.7856235345304012, "actor_loss": -64.60269178009034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.122179746627808, "step": 107000}
{"episode_reward": 685.6149844275544, "episode": 108.0, "batch_reward": 0.6191376659274102, "critic_loss": 1.3513863043934107, "actor_loss": -64.85651068115234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.181908130645752, "step": 108000}
{"episode_reward": 694.4921434718007, "episode": 109.0, "batch_reward": 0.6186040374040603, "critic_loss": 5.781138267815113, "actor_loss": -65.11552870178222, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.127806425094604, "step": 109000}
{"episode_reward": 562.8749856063047, "episode": 110.0, "batch_reward": 0.6156652226448059, "critic_loss": 16.104825650811197, "actor_loss": -67.4863353729248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.54009771347046, "step": 110000}
{"episode_reward": 84.18626948955536, "episode": 111.0, "batch_reward": 0.6110964248180389, "critic_loss": 24.455695614814758, "actor_loss": -73.83502365112305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.72363829612732, "step": 111000}
{"episode_reward": 74.28448265558227, "episode": 112.0, "batch_reward": 0.6062783573865891, "critic_loss": 31.402982098579407, "actor_loss": -78.7834324798584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.518710136413574, "step": 112000}
{"episode_reward": 238.5259020752276, "episode": 113.0, "batch_reward": 0.6031174119710923, "critic_loss": 36.43976512908935, "actor_loss": -83.41864326477051, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.028338193893433, "step": 113000}
{"episode_reward": 176.43510217491064, "episode": 114.0, "batch_reward": 0.5979340827465057, "critic_loss": 42.006124691009525, "actor_loss": -92.62177136230468, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.542720317840576, "step": 114000}
{"episode_reward": 63.61647341081312, "episode": 115.0, "batch_reward": 0.5937771158218383, "critic_loss": 45.77567134284973, "actor_loss": -98.63827313232422, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.420085430145264, "step": 115000}
{"episode_reward": 79.06211723922833, "episode": 116.0, "batch_reward": 0.5905273079276084, "critic_loss": 44.775330612182614, "actor_loss": -106.05326041412353, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.797070264816284, "step": 116000}
{"episode_reward": 216.37301843254593, "episode": 117.0, "batch_reward": 0.5865461015701294, "critic_loss": 48.65398712348938, "actor_loss": -109.49248296356201, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.140379190444946, "step": 117000}
{"episode_reward": 47.277432227583944, "episode": 118.0, "batch_reward": 0.5823423046469688, "critic_loss": 58.72138087463379, "actor_loss": -118.04203837585449, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.308290481567383, "step": 118000}
{"episode_reward": 153.80694722623488, "episode": 119.0, "batch_reward": 0.5787350177168846, "critic_loss": 60.824409921646115, "actor_loss": -123.13668976593017, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.13387107849121, "step": 119000}
{"episode_reward": 83.31026285443093, "episode": 120.0, "batch_reward": 0.5729010657072068, "critic_loss": 62.32600909805298, "actor_loss": -121.38181619262696, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.147692918777466, "step": 120000}
{"episode_reward": 24.241137673041482, "episode": 121.0, "batch_reward": 0.5694729542732239, "critic_loss": 58.79966405296326, "actor_loss": -125.55132663726806, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.559680223464966, "step": 121000}
{"episode_reward": 81.94804841092542, "episode": 122.0, "batch_reward": 0.5647736942470074, "critic_loss": 55.20369702148437, "actor_loss": -129.69285543060303, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.818938493728638, "step": 122000}
{"episode_reward": 77.34353798243518, "episode": 123.0, "batch_reward": 0.562446110099554, "critic_loss": 48.31260153961182, "actor_loss": -126.40793659973144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.53414511680603, "step": 123000}
{"episode_reward": 94.55651021701588, "episode": 124.0, "batch_reward": 0.5585004839003086, "critic_loss": 39.64578716468811, "actor_loss": -132.5918860244751, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.203060626983643, "step": 124000}
{"episode_reward": 35.91187077327832, "episode": 125.0, "batch_reward": 0.5539927729070186, "critic_loss": 33.0503114528656, "actor_loss": -128.5866677093506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.308975219726562, "step": 125000}
{"episode_reward": 138.1028049862879, "episode": 126.0, "batch_reward": 0.5505789513289928, "critic_loss": 25.49659119319916, "actor_loss": -134.55123859405518, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.11507296562195, "step": 126000}
{"episode_reward": 286.5848599321128, "episode": 127.0, "batch_reward": 0.549550615310669, "critic_loss": 20.686239744186402, "actor_loss": -133.99272798156738, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.288515329360962, "step": 127000}
{"episode_reward": 278.8284173837958, "episode": 128.0, "batch_reward": 0.5461593182981014, "critic_loss": 17.787941535949706, "actor_loss": -131.45755031585693, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.528741598129272, "step": 128000}
{"episode_reward": 46.35400139198234, "episode": 129.0, "batch_reward": 0.5428224014639854, "critic_loss": 15.146419868469238, "actor_loss": -130.22208641052245, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.440922737121582, "step": 129000}
{"episode_reward": 115.6520050461842, "episode": 130.0, "batch_reward": 0.5389115957915783, "critic_loss": 13.163878558158874, "actor_loss": -129.04270217895507, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.372037172317505, "step": 130000}
{"episode_reward": 167.70109382697396, "episode": 131.0, "batch_reward": 0.5360516831874848, "critic_loss": 11.1256733751297, "actor_loss": -126.63486146545411, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 45.90844202041626, "step": 131000}
{"episode_reward": 293.35857036573435, "episode": 132.0, "batch_reward": 0.5348554577827453, "critic_loss": 9.068233323574066, "actor_loss": -122.04391912841797, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.626379013061523, "step": 132000}
{"episode_reward": 115.92010352744018, "episode": 133.0, "batch_reward": 0.5309754650294781, "critic_loss": 7.393018180131913, "actor_loss": -121.66606274414063, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.763919353485107, "step": 133000}
{"episode_reward": 200.13617201073808, "episode": 134.0, "batch_reward": 0.5298547837734222, "critic_loss": 6.116554782390595, "actor_loss": -121.71843858337402, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.971489906311035, "step": 134000}
{"episode_reward": 39.23068081941717, "episode": 135.0, "batch_reward": 0.5280064315199852, "critic_loss": 4.991009388923645, "actor_loss": -116.5350140991211, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.68902015686035, "step": 135000}
{"episode_reward": 303.4821957679885, "episode": 136.0, "batch_reward": 0.5229916817843914, "critic_loss": 4.128132951259613, "actor_loss": -116.04434188079834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.1207492351532, "step": 136000}
{"episode_reward": 43.21286523285045, "episode": 137.0, "batch_reward": 0.518789395660162, "critic_loss": 3.898093482255936, "actor_loss": -110.22938256072997, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.009400367736816, "step": 137000}
{"episode_reward": 40.3520314555337, "episode": 138.0, "batch_reward": 0.5181612730622291, "critic_loss": 3.6326869008541105, "actor_loss": -105.20191748046875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.11063504219055, "step": 138000}
{"episode_reward": 110.30422012049516, "episode": 139.0, "batch_reward": 0.5126782636940479, "critic_loss": 3.36564346075058, "actor_loss": -103.57017352294922, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.817362785339355, "step": 139000}
{"episode_reward": 156.64933285822661, "episode": 140.0, "batch_reward": 0.5112641625404358, "critic_loss": 3.2362285525798797, "actor_loss": -100.48470416259765, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.56499218940735, "step": 140000}
{"episode_reward": 366.68676388955777, "episode": 141.0, "batch_reward": 0.5106849133968353, "critic_loss": 2.9533180638551713, "actor_loss": -96.9467102279663, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.54916954040527, "step": 141000}
{"episode_reward": 25.431409858107166, "episode": 142.0, "batch_reward": 0.5085084038376808, "critic_loss": 2.7061862070560454, "actor_loss": -98.7746125869751, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.312729358673096, "step": 142000}
{"episode_reward": 151.00120758594176, "episode": 143.0, "batch_reward": 0.5046776090562344, "critic_loss": 2.6365270091295243, "actor_loss": -94.5057165222168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.044249057769775, "step": 143000}
{"episode_reward": 436.89499263087475, "episode": 144.0, "batch_reward": 0.5047895673215389, "critic_loss": 2.606456572294235, "actor_loss": -93.66313653564453, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.73486065864563, "step": 144000}
{"episode_reward": 523.0011140246623, "episode": 145.0, "batch_reward": 0.5040434038043022, "critic_loss": 2.4568626128435134, "actor_loss": -90.85398933410644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.84092140197754, "step": 145000}
{"episode_reward": 582.8330480415098, "episode": 146.0, "batch_reward": 0.5059064696133136, "critic_loss": 2.3381627473831177, "actor_loss": -91.46157898712158, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.104689836502075, "step": 146000}
{"episode_reward": 593.4434235202137, "episode": 147.0, "batch_reward": 0.5069065487086772, "critic_loss": 2.3420522532463073, "actor_loss": -89.08251696777344, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.11573100090027, "step": 147000}
{"episode_reward": 485.71220985171396, "episode": 148.0, "batch_reward": 0.5058698612451553, "critic_loss": 2.3195037125349045, "actor_loss": -87.61982528686524, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.068116903305054, "step": 148000}
{"episode_reward": 213.5454815629476, "episode": 149.0, "batch_reward": 0.5041426835954189, "critic_loss": 2.1841204773187637, "actor_loss": -86.04749365997314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.29849648475647, "step": 149000}
{"episode_reward": 654.6042858887886, "episode": 150.0, "batch_reward": 0.5042903441488743, "critic_loss": 1.9297597284317016, "actor_loss": -85.12318497467041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
