{"episode": 1.0, "duration": 16.86639642715454, "episode_reward": 7.579367547095394, "step": 1000}
{"episode": 2.0, "duration": 1.479334831237793, "episode_reward": 587.3438790414032, "step": 2000}
{"episode": 3.0, "batch_reward": 0.31364655300910255, "critic_loss": 0.11243069334382333, "actor_loss": -49.28302940438871, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 66.13556051254272, "episode_reward": 637.6277701217232, "step": 3000}
{"episode": 4.0, "batch_reward": 0.4219924255013466, "critic_loss": 0.14190099357813596, "actor_loss": -56.76909324645996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.777552604675293, "episode_reward": 601.9229777149765, "step": 4000}
{"episode": 5.0, "batch_reward": 0.4529322375357151, "critic_loss": 0.2189067873880267, "actor_loss": -57.842139236450194, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.77250075340271, "episode_reward": 362.62673313308585, "step": 5000}
{"episode": 6.0, "batch_reward": 0.43192582625150683, "critic_loss": 0.3188261518031359, "actor_loss": -54.96517097473144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.76416826248169, "episode_reward": 372.8208623410931, "step": 6000}
{"episode": 7.0, "batch_reward": 0.42589098706841466, "critic_loss": 0.34457058799266815, "actor_loss": -53.96328060150147, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.77132296562195, "episode_reward": 498.17836686013226, "step": 7000}
{"episode": 8.0, "batch_reward": 0.42150825944542886, "critic_loss": 0.3634226658642292, "actor_loss": -53.03366439056396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.53788733482361, "episode_reward": 109.39764060434253, "step": 8000}
{"episode": 9.0, "batch_reward": 0.39893258434534073, "critic_loss": 0.3359044013917446, "actor_loss": -50.62036276245117, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.638241291046143, "episode_reward": 515.9932385704444, "step": 9000}
{"episode": 10.0, "batch_reward": 0.4150239514708519, "critic_loss": 0.31631641183793546, "actor_loss": -50.11285805511475, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 3506.069267272949, "episode_reward": 589.9232018901331, "step": 10000}
{"episode": 11.0, "batch_reward": 0.43509017300605773, "critic_loss": 0.33044279330968857, "actor_loss": -51.41671006774902, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.28725600242615, "episode_reward": 620.8419047471235, "step": 11000}
{"episode": 12.0, "batch_reward": 0.44975734522938726, "critic_loss": 0.3307895443290472, "actor_loss": -51.26808135986328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 393.71858382225037, "episode_reward": 595.3763290998927, "step": 12000}
{"episode": 13.0, "batch_reward": 0.45889166882634164, "critic_loss": 0.34271333418786526, "actor_loss": -51.818953033447265, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.49632477760315, "episode_reward": 557.9883482811957, "step": 13000}
{"episode": 14.0, "batch_reward": 0.4680510457754135, "critic_loss": 0.3186742485165596, "actor_loss": -51.957811408996584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 393.83698868751526, "episode_reward": 559.5000318181692, "step": 14000}
{"episode": 15.0, "batch_reward": 0.4718026479482651, "critic_loss": 0.3043582351207733, "actor_loss": -51.47995590972901, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.800519943237305, "episode_reward": 519.2463829374294, "step": 15000}
{"episode": 16.0, "batch_reward": 0.4729976496994495, "critic_loss": 0.3172424093335867, "actor_loss": -50.595059951782225, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 392.3783905506134, "episode_reward": 326.4998898806838, "step": 16000}
{"episode": 17.0, "batch_reward": 0.4573936815559864, "critic_loss": 0.26556626237928865, "actor_loss": -48.949408737182615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.77873730659485, "episode_reward": 300.9820903382921, "step": 17000}
{"episode": 18.0, "batch_reward": 0.45328350239992143, "critic_loss": 0.2476534499078989, "actor_loss": -48.20269705963135, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.73247814178467, "episode_reward": 452.213295783501, "step": 18000}
{"episode": 19.0, "batch_reward": 0.45561963120102883, "critic_loss": 0.2233667237535119, "actor_loss": -48.203724746704104, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.836106538772583, "episode_reward": 515.4607411686359, "step": 19000}
{"episode": 20.0, "batch_reward": 0.46050422376394273, "critic_loss": 0.21444789676368237, "actor_loss": -47.61072088623047, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.5402889251709, "episode_reward": 523.6235826064891, "step": 20000}
{"episode": 21.0, "batch_reward": 0.4625286006331444, "critic_loss": 0.20008132183551788, "actor_loss": -47.5177063293457, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.25339221954346, "episode_reward": 561.1144204130131, "step": 21000}
{"episode": 22.0, "batch_reward": 0.4695102125108242, "critic_loss": 0.20710325259715318, "actor_loss": -47.391262329101565, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.14730310440063, "episode_reward": 537.6218549839729, "step": 22000}
{"episode": 23.0, "batch_reward": 0.4691170753538609, "critic_loss": 0.20793362599611281, "actor_loss": -47.14340871429443, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.73568606376648, "episode_reward": 543.0189372324883, "step": 23000}
{"episode": 24.0, "batch_reward": 0.4750088953077793, "critic_loss": 0.20680747286230325, "actor_loss": -46.932912643432616, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.5865333080292, "episode_reward": 584.3061718097231, "step": 24000}
{"episode": 25.0, "batch_reward": 0.47914836305379865, "critic_loss": 0.20501321440935136, "actor_loss": -47.375690116882325, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.889657258987427, "episode_reward": 602.9476272930301, "step": 25000}
{"episode": 26.0, "batch_reward": 0.48210950124263763, "critic_loss": 0.20485944996774197, "actor_loss": -46.77186731719971, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.7079391479492, "episode_reward": 527.953872830501, "step": 26000}
{"episode": 27.0, "batch_reward": 0.48460103529691695, "critic_loss": 0.2013836623877287, "actor_loss": -46.76930099487305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.810373783111572, "episode_reward": 583.3452591087519, "step": 27000}
{"episode": 28.0, "batch_reward": 0.48951552829146383, "critic_loss": 0.19874912468343972, "actor_loss": -46.74532175445557, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.8531711101532, "episode_reward": 577.6296830768968, "step": 28000}
{"episode": 29.0, "batch_reward": 0.49247736421227456, "critic_loss": 0.1990445586964488, "actor_loss": -46.66569808197021, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.771954774856567, "episode_reward": 595.5692235655308, "step": 29000}
{"episode": 30.0, "batch_reward": 0.49511531668901443, "critic_loss": 0.19988255160301924, "actor_loss": -46.81572218322754, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.25674533843994, "episode_reward": 577.3307767734542, "step": 30000}
{"episode": 31.0, "batch_reward": 0.4991064257323742, "critic_loss": 0.18670479637384416, "actor_loss": -47.0793182144165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.365156173706055, "episode_reward": 603.9323983588148, "step": 31000}
{"episode": 32.0, "batch_reward": 0.5014569413363934, "critic_loss": 0.18836128862947227, "actor_loss": -46.84497440338135, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.5487458705902, "episode_reward": 589.288556180353, "step": 32000}
{"episode": 33.0, "batch_reward": 0.5052541221380233, "critic_loss": 0.181735436424613, "actor_loss": -47.0379439086914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.843889951705933, "episode_reward": 592.9521268629252, "step": 33000}
{"episode": 34.0, "batch_reward": 0.5069913447499276, "critic_loss": 0.18954097390174865, "actor_loss": -46.97770447540283, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.6544210910797, "episode_reward": 581.9102047548489, "step": 34000}
{"episode": 35.0, "batch_reward": 0.5094219855070115, "critic_loss": 0.1911280569732189, "actor_loss": -47.12245160675049, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.665531873703003, "episode_reward": 614.3707502147183, "step": 35000}
{"episode": 36.0, "batch_reward": 0.5123354170918465, "critic_loss": 0.19799896185845137, "actor_loss": -46.9811089477539, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.3345239162445, "episode_reward": 617.0473097221438, "step": 36000}
{"episode": 37.0, "batch_reward": 0.5147074748277665, "critic_loss": 0.20117703343182802, "actor_loss": -47.160249450683594, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.862414360046387, "episode_reward": 630.1832789969412, "step": 37000}
{"episode": 38.0, "batch_reward": 0.5196878799498081, "critic_loss": 0.1985316834077239, "actor_loss": -47.33832422637939, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.20880603790283, "episode_reward": 606.0922412516077, "step": 38000}
{"episode": 39.0, "batch_reward": 0.5202640193998813, "critic_loss": 0.1920526363402605, "actor_loss": -47.35896953582764, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.98202633857727, "episode_reward": 609.8083654294135, "step": 39000}
{"episode": 40.0, "batch_reward": 0.5247019105255604, "critic_loss": 0.20541579104214908, "actor_loss": -47.38990041351318, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.0548722743988, "episode_reward": 599.1375220013537, "step": 40000}
{"episode": 41.0, "batch_reward": 0.5255699615776539, "critic_loss": 0.21529602746665477, "actor_loss": -47.516090354919434, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.328670501708984, "episode_reward": 618.5509301656425, "step": 41000}
{"episode": 42.0, "batch_reward": 0.527376405209303, "critic_loss": 0.19735824610292912, "actor_loss": -47.6703422088623, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 383.17139077186584, "episode_reward": 624.7107365143557, "step": 42000}
{"episode": 43.0, "batch_reward": 0.5286993449926376, "critic_loss": 0.19380518151819706, "actor_loss": -47.6737825012207, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.8818998336792, "episode_reward": 564.649410499126, "step": 43000}
{"episode": 44.0, "batch_reward": 0.5304546224474906, "critic_loss": 0.19257978013902902, "actor_loss": -47.60135238647461, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 389.1820020675659, "episode_reward": 638.2527051341509, "step": 44000}
{"episode": 45.0, "batch_reward": 0.5334738437235356, "critic_loss": 0.19173807686567307, "actor_loss": -47.681444961547854, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.916464805603027, "episode_reward": 614.1560620328489, "step": 45000}
{"episode": 46.0, "batch_reward": 0.5348981600403786, "critic_loss": 0.18268526282161474, "actor_loss": -47.79898160552978, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.0556571483612, "episode_reward": 613.5282497888817, "step": 46000}
{"episode": 47.0, "batch_reward": 0.5366524634957314, "critic_loss": 0.18029790546000005, "actor_loss": -47.76651327514649, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.60778570175171, "episode_reward": 603.5781042651411, "step": 47000}
{"episode": 48.0, "batch_reward": 0.5372125236690044, "critic_loss": 0.17712255729734896, "actor_loss": -47.81869310760498, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.8465042114258, "episode_reward": 584.2707445643433, "step": 48000}
{"episode": 49.0, "batch_reward": 0.53883194231987, "critic_loss": 0.17317017157375814, "actor_loss": -48.011959197998046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.917248964309692, "episode_reward": 604.8729833988281, "step": 49000}
{"episode": 50.0, "batch_reward": 0.5391381166279315, "critic_loss": 0.1660138691291213, "actor_loss": -47.850540832519535, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.5848183631897, "episode_reward": 607.4811157840857, "step": 50000}
{"episode": 51.0, "batch_reward": 0.5407667059898377, "critic_loss": 0.1643237060829997, "actor_loss": -48.11410250091553, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.30184841156006, "episode_reward": 603.2175678967027, "step": 51000}
{"episode": 52.0, "batch_reward": 0.5418436486124992, "critic_loss": 0.17194534511119128, "actor_loss": -47.98003911590576, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.32485246658325, "episode_reward": 609.6323111036488, "step": 52000}
{"episode": 53.0, "batch_reward": 0.5436683945059776, "critic_loss": 0.17413777053356172, "actor_loss": -48.047007080078124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.823127508163452, "episode_reward": 594.3480765455026, "step": 53000}
{"episode": 54.0, "batch_reward": 0.5454393309354783, "critic_loss": 0.1719338196963072, "actor_loss": -48.057495933532714, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.05639696121216, "episode_reward": 577.1688471140192, "step": 54000}
{"episode": 55.0, "batch_reward": 0.5439232714474201, "critic_loss": 0.18192723141610623, "actor_loss": -47.84365506744385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.92859125137329, "episode_reward": 603.8922474931913, "step": 55000}
{"episode": 56.0, "batch_reward": 0.5464840928018093, "critic_loss": 0.17361753547936679, "actor_loss": -47.97252825927735, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 389.9696478843689, "episode_reward": 588.101360024953, "step": 56000}
{"episode": 57.0, "batch_reward": 0.5456477435827255, "critic_loss": 0.17264133109152316, "actor_loss": -48.08287755584717, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.88287091255188, "episode_reward": 591.2918020092549, "step": 57000}
{"episode": 58.0, "batch_reward": 0.5474753292798996, "critic_loss": 0.1715563975647092, "actor_loss": -48.08084102630615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.89163422584534, "episode_reward": 598.3306026016033, "step": 58000}
{"episode": 59.0, "batch_reward": 0.5482422415316105, "critic_loss": 0.17502859223634004, "actor_loss": -47.97108033752441, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.922459363937378, "episode_reward": 562.865522821651, "step": 59000}
{"episode": 60.0, "batch_reward": 0.5486717756688595, "critic_loss": 0.169483198992908, "actor_loss": -47.95958306121826, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.5775227546692, "episode_reward": 604.944385922247, "step": 60000}
{"episode": 61.0, "batch_reward": 0.5481451043188572, "critic_loss": 0.16611525002121924, "actor_loss": -48.0662056427002, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.132017374038696, "episode_reward": 558.0484260180368, "step": 61000}
{"episode": 62.0, "batch_reward": 0.5500867429375649, "critic_loss": 0.17252927029132842, "actor_loss": -47.71805069732666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.70348143577576, "episode_reward": 594.9424548267966, "step": 62000}
{"episode": 63.0, "batch_reward": 0.54934043815732, "critic_loss": 0.17235473520308733, "actor_loss": -48.01357614135742, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.76836633682251, "episode_reward": 542.8456840709107, "step": 63000}
{"episode": 64.0, "batch_reward": 0.5512270317077637, "critic_loss": 0.16916130051761866, "actor_loss": -48.064319747924806, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.01682448387146, "episode_reward": 617.2122588557236, "step": 64000}
{"episode": 65.0, "batch_reward": 0.5505516139268876, "critic_loss": 0.1717975776568055, "actor_loss": -47.89236451721192, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.738604068756104, "episode_reward": 573.8216389207275, "step": 65000}
{"episode": 66.0, "batch_reward": 0.5520670111775399, "critic_loss": 0.1669923643693328, "actor_loss": -47.95278298187256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.2631764411926, "episode_reward": 623.4439708436441, "step": 66000}
{"episode": 67.0, "batch_reward": 0.5532224319279194, "critic_loss": 0.17011717992275954, "actor_loss": -47.85772698974609, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.576321363449097, "episode_reward": 599.7252943234394, "step": 67000}
{"episode": 68.0, "batch_reward": 0.5542597779929638, "critic_loss": 0.16313683899492026, "actor_loss": -48.02061589813233, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 389.7915925979614, "episode_reward": 588.5866132360484, "step": 68000}
{"episode": 69.0, "batch_reward": 0.554105841845274, "critic_loss": 0.16778802108764648, "actor_loss": -47.90032574462891, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.916853427886963, "episode_reward": 592.024970924483, "step": 69000}
{"episode": 70.0, "batch_reward": 0.5543239607512951, "critic_loss": 0.16439446409046649, "actor_loss": -48.07489707183838, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 389.76229548454285, "episode_reward": 610.1319845883561, "step": 70000}
{"episode": 71.0, "batch_reward": 0.5555972808599472, "critic_loss": 0.1587564387843013, "actor_loss": -48.16872542572021, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.36373281478882, "episode_reward": 618.9005360240683, "step": 71000}
{"episode": 72.0, "batch_reward": 0.5559655479490757, "critic_loss": 0.1622589004561305, "actor_loss": -48.25988939666748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 389.67453789711, "episode_reward": 591.7667314905915, "step": 72000}
{"episode": 73.0, "batch_reward": 0.5560550332963466, "critic_loss": 0.16285890525579452, "actor_loss": -48.03634994506836, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.780274629592896, "episode_reward": 597.9658222532506, "step": 73000}
{"episode": 74.0, "batch_reward": 0.5572305439412594, "critic_loss": 0.1723795655965805, "actor_loss": -48.42518839263916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 389.99033308029175, "episode_reward": 600.3255122050908, "step": 74000}
{"episode": 75.0, "batch_reward": 0.5591835354566574, "critic_loss": 0.17363093046098949, "actor_loss": -48.39882273864746, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.61651110649109, "episode_reward": 619.9836401711035, "step": 75000}
{"episode": 76.0, "batch_reward": 0.5590570459365845, "critic_loss": 0.17052873083949088, "actor_loss": -48.5420435256958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.01418805122375, "episode_reward": 610.4139060454539, "step": 76000}
{"episode": 77.0, "batch_reward": 0.5584809088110924, "critic_loss": 0.16837052860856055, "actor_loss": -48.252787384033205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.93265151977539, "episode_reward": 606.9047289923956, "step": 77000}
{"episode": 78.0, "batch_reward": 0.5606847834289074, "critic_loss": 0.16784538735449314, "actor_loss": -48.550080825805665, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.47901606559753, "episode_reward": 626.0114469956335, "step": 78000}
{"episode": 79.0, "batch_reward": 0.5609657874107361, "critic_loss": 0.16303265228122474, "actor_loss": -48.518300415039064, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.03158187866211, "episode_reward": 604.5678723152416, "step": 79000}
{"episode": 80.0, "batch_reward": 0.5612454817295075, "critic_loss": 0.16148748959600925, "actor_loss": -48.76322083282471, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.3530464172363, "episode_reward": 624.5149707217676, "step": 80000}
{"episode": 81.0, "batch_reward": 0.5623842093348503, "critic_loss": 0.16138120894879102, "actor_loss": -48.92218225860596, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.400714635849, "episode_reward": 625.1543028160185, "step": 81000}
{"episode": 82.0, "batch_reward": 0.563040538072586, "critic_loss": 0.16344864764809608, "actor_loss": -48.98988545227051, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.8538157939911, "episode_reward": 619.5486432000723, "step": 82000}
{"episode": 83.0, "batch_reward": 0.5638469794392585, "critic_loss": 0.16172034707665445, "actor_loss": -49.18238662719727, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.67678999900818, "episode_reward": 616.4444121858481, "step": 83000}
{"episode": 84.0, "batch_reward": 0.5643602275252342, "critic_loss": 0.1628527092561126, "actor_loss": -49.0089751663208, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.68316626548767, "episode_reward": 606.2149282111727, "step": 84000}
{"episode": 85.0, "batch_reward": 0.5638557641506196, "critic_loss": 0.16962115395069122, "actor_loss": -49.13305815887451, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.95978856086731, "episode_reward": 620.1668528869108, "step": 85000}
{"episode": 86.0, "batch_reward": 0.5660094026923179, "critic_loss": 0.16771253520995377, "actor_loss": -49.13270221710205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.8376338481903, "episode_reward": 592.2586361455178, "step": 86000}
{"episode": 87.0, "batch_reward": 0.5658298130631447, "critic_loss": 0.16922022569179535, "actor_loss": -49.43613378143311, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.001922130584717, "episode_reward": 633.9054933479132, "step": 87000}
{"episode": 88.0, "batch_reward": 0.5670383198857307, "critic_loss": 0.16863889557123185, "actor_loss": -49.29132845306396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.1552858352661, "episode_reward": 629.4485083681726, "step": 88000}
{"episode": 89.0, "batch_reward": 0.5673421249687671, "critic_loss": 0.16695415511727332, "actor_loss": -49.441977668762206, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.600955486297607, "episode_reward": 583.6867032251545, "step": 89000}
{"episode": 90.0, "batch_reward": 0.5682570167779922, "critic_loss": 0.16629792112857103, "actor_loss": -49.733921211242674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.6996340751648, "episode_reward": 583.7836230672273, "step": 90000}
{"episode": 91.0, "batch_reward": 0.5691213912963867, "critic_loss": 0.16994036438316107, "actor_loss": -49.57243479919433, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.378283977508545, "episode_reward": 611.6465601605734, "step": 91000}
{"episode": 92.0, "batch_reward": 0.5683902742266655, "critic_loss": 0.1737292177900672, "actor_loss": -49.75043183898926, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 383.14229011535645, "episode_reward": 626.8861546380953, "step": 92000}
{"episode": 93.0, "batch_reward": 0.5685809054970741, "critic_loss": 0.17681746181845664, "actor_loss": -49.776636581420895, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.942952156066895, "episode_reward": 604.340270617381, "step": 93000}
{"episode": 94.0, "batch_reward": 0.5693630027770996, "critic_loss": 0.16787861120700837, "actor_loss": -50.01967724609375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 389.60730957984924, "episode_reward": 619.0484778171744, "step": 94000}
{"episode": 95.0, "batch_reward": 0.5701512342095375, "critic_loss": 0.17552043955773114, "actor_loss": -49.82940056610107, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.753294229507446, "episode_reward": 610.9909030618062, "step": 95000}
{"episode": 96.0, "batch_reward": 0.5716132972240447, "critic_loss": 0.1734810873940587, "actor_loss": -50.30468099975586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 389.8576602935791, "episode_reward": 619.3973212998641, "step": 96000}
{"episode": 97.0, "batch_reward": 0.572481684923172, "critic_loss": 0.17995413098484278, "actor_loss": -50.146548011779785, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.021193504333496, "episode_reward": 656.6341258199428, "step": 97000}
{"episode": 98.0, "batch_reward": 0.5714431720972061, "critic_loss": 0.18042591519653797, "actor_loss": -50.214660636901854, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 389.82340598106384, "episode_reward": 612.9290740892137, "step": 98000}
{"episode": 99.0, "batch_reward": 0.5718379417061805, "critic_loss": 0.17280586156994104, "actor_loss": -50.20174743652344, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.5986111164093, "episode_reward": 633.6707475415977, "step": 99000}
{"episode": 100.0, "batch_reward": 0.5731196476221084, "critic_loss": 0.17367503894865513, "actor_loss": -50.64424496459961, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.306067943573, "episode_reward": 654.2923090335596, "step": 100000}
{"episode": 101.0, "batch_reward": 0.5735503530502319, "critic_loss": 0.17042879585921764, "actor_loss": -50.49843650817871, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.230491638183594, "episode_reward": 622.4019915461473, "step": 101000}
{"episode": 102.0, "batch_reward": 0.5740571914315223, "critic_loss": 0.17072985188663006, "actor_loss": -50.12996265411377, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.5611324310303, "episode_reward": 600.6872082614647, "step": 102000}
{"episode": 103.0, "batch_reward": 0.5737053938508033, "critic_loss": 0.17795485657453536, "actor_loss": -50.27095160675049, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.935560941696167, "episode_reward": 642.2435598488734, "step": 103000}
{"episode": 104.0, "batch_reward": 0.5751055418252945, "critic_loss": 0.17301619295030832, "actor_loss": -50.36521829223633, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.0144946575165, "episode_reward": 634.849957286794, "step": 104000}
{"episode": 105.0, "batch_reward": 0.5751781021356582, "critic_loss": 0.17150313611328602, "actor_loss": -50.185460151672366, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.6413311958313, "episode_reward": 645.8499080609347, "step": 105000}
{"episode": 106.0, "batch_reward": 0.5756168784499168, "critic_loss": 0.17091007972508668, "actor_loss": -50.133890266418454, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.6351544857025, "episode_reward": 630.781449082141, "step": 106000}
{"episode": 107.0, "batch_reward": 0.576691195011139, "critic_loss": 0.1734675662368536, "actor_loss": -50.18587296295166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.58868145942688, "episode_reward": 627.9858625394495, "step": 107000}
{"episode": 108.0, "batch_reward": 0.578060683786869, "critic_loss": 0.17636797396093606, "actor_loss": -50.33570512390137, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.4596338272095, "episode_reward": 640.278923349761, "step": 108000}
{"episode": 109.0, "batch_reward": 0.5777597267627717, "critic_loss": 0.1773014690950513, "actor_loss": -50.601985275268554, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.03975200653076, "episode_reward": 650.9694797024944, "step": 109000}
{"episode": 110.0, "batch_reward": 0.5783550660014153, "critic_loss": 0.1805313628986478, "actor_loss": -50.12522389221191, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.3358705043793, "episode_reward": 640.6520267051536, "step": 110000}
{"episode": 111.0, "batch_reward": 0.5785123721957207, "critic_loss": 0.18705526164919137, "actor_loss": -50.51625365447998, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.14735984802246, "episode_reward": 637.3006827722263, "step": 111000}
{"episode": 112.0, "batch_reward": 0.579308856010437, "critic_loss": 0.18237845878303052, "actor_loss": -50.34664298248291, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.01484847068787, "episode_reward": 640.1441910020759, "step": 112000}
{"episode": 113.0, "batch_reward": 0.5802668136954308, "critic_loss": 0.1838400089517236, "actor_loss": -50.547360656738284, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.80789351463318, "episode_reward": 635.7696487626241, "step": 113000}
{"episode": 114.0, "batch_reward": 0.5816725956201554, "critic_loss": 0.19110655324906112, "actor_loss": -50.50987392425537, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.0516517162323, "episode_reward": 645.5020691620882, "step": 114000}
{"episode": 115.0, "batch_reward": 0.5800304143428803, "critic_loss": 0.1895672876983881, "actor_loss": -50.52828994750976, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.60960602760315, "episode_reward": 658.4563512422325, "step": 115000}
{"episode": 116.0, "batch_reward": 0.5821358366012573, "critic_loss": 0.19684336845576764, "actor_loss": -50.869640396118164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.7687838077545, "episode_reward": 620.6709992118018, "step": 116000}
{"episode": 117.0, "batch_reward": 0.5826005136370659, "critic_loss": 0.19890302836894988, "actor_loss": -50.98312476348877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.981691122055054, "episode_reward": 638.6051699439347, "step": 117000}
{"episode": 118.0, "batch_reward": 0.5823718472719193, "critic_loss": 0.19109615730494262, "actor_loss": -50.82810599517822, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.2335226535797, "episode_reward": 636.9400350269078, "step": 118000}
{"episode": 119.0, "batch_reward": 0.5820316947698593, "critic_loss": 0.1986262413933873, "actor_loss": -51.029066734313965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.00240421295166, "episode_reward": 644.6420713555583, "step": 119000}
{"episode": 120.0, "batch_reward": 0.5823874975442886, "critic_loss": 0.20383078306913377, "actor_loss": -50.9676354598999, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 389.9043209552765, "episode_reward": 612.2969947163367, "step": 120000}
{"episode": 121.0, "batch_reward": 0.5840451118350029, "critic_loss": 0.19780457376688718, "actor_loss": -50.964377014160156, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.44738960266113, "episode_reward": 618.9457203628143, "step": 121000}
{"episode": 122.0, "batch_reward": 0.584491085767746, "critic_loss": 0.20312588436156512, "actor_loss": -51.18040000152588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.2828633785248, "episode_reward": 636.4667453491224, "step": 122000}
{"episode": 123.0, "batch_reward": 0.5853057224750519, "critic_loss": 0.20961175233125687, "actor_loss": -51.18832876586914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.955084562301636, "episode_reward": 586.048229830854, "step": 123000}
{"episode": 124.0, "batch_reward": 0.5841397604942322, "critic_loss": 0.21124538148194552, "actor_loss": -51.13888705444336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.16858887672424, "episode_reward": 637.4830347740821, "step": 124000}
{"episode": 125.0, "batch_reward": 0.5852875489592552, "critic_loss": 0.21585354080796243, "actor_loss": -51.348790115356444, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.942106008529663, "episode_reward": 632.7880029430664, "step": 125000}
{"episode": 126.0, "batch_reward": 0.5868378469944, "critic_loss": 0.20944733749330044, "actor_loss": -51.79036795043945, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.2928786277771, "episode_reward": 659.7062704773786, "step": 126000}
{"episode": 127.0, "batch_reward": 0.5854875379800797, "critic_loss": 0.20424731617420913, "actor_loss": -51.576325759887695, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.768255710601807, "episode_reward": 656.4246410628765, "step": 127000}
{"episode": 128.0, "batch_reward": 0.5872000474333763, "critic_loss": 0.20759555116295814, "actor_loss": -51.96061856079102, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.63359236717224, "episode_reward": 619.5522181133027, "step": 128000}
{"episode": 129.0, "batch_reward": 0.5859140701293946, "critic_loss": 0.2166944418847561, "actor_loss": -52.091622383117674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.62659978866577, "episode_reward": 637.6010553963266, "step": 129000}
{"episode": 130.0, "batch_reward": 0.5871973331570626, "critic_loss": 0.22439020360261203, "actor_loss": -52.30593699645996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.8641266822815, "episode_reward": 594.4174811969185, "step": 130000}
{"episode": 131.0, "batch_reward": 0.5875589264035225, "critic_loss": 0.22182189412415027, "actor_loss": -52.13150168609619, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.40425634384155, "episode_reward": 615.2298786989587, "step": 131000}
{"episode": 132.0, "batch_reward": 0.5869233150482178, "critic_loss": 0.24071093249320985, "actor_loss": -52.61932488250732, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.51457238197327, "episode_reward": 660.2518459136473, "step": 132000}
{"episode": 133.0, "batch_reward": 0.5875737164020538, "critic_loss": 0.2519941953420639, "actor_loss": -52.71241344451904, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.968531608581543, "episode_reward": 644.5675396530426, "step": 133000}
{"episode": 134.0, "batch_reward": 0.5886321498155593, "critic_loss": 0.26237595139443876, "actor_loss": -53.48536250305176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.61474657058716, "episode_reward": 664.4470432660614, "step": 134000}
{"episode": 135.0, "batch_reward": 0.5890734704136849, "critic_loss": 0.2711319085359573, "actor_loss": -53.561973594665524, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.99823832511902, "episode_reward": 655.8561594455153, "step": 135000}
{"episode": 136.0, "batch_reward": 0.5899450559616088, "critic_loss": 0.32656737497448923, "actor_loss": -53.81901029205322, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.2216579914093, "episode_reward": 657.581378060764, "step": 136000}
{"episode": 137.0, "batch_reward": 0.589873400092125, "critic_loss": 0.3278192740008235, "actor_loss": -53.86884524536133, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.769172430038452, "episode_reward": 665.769143980432, "step": 137000}
{"episode": 138.0, "batch_reward": 0.5914832330346107, "critic_loss": 0.3733793834969401, "actor_loss": -54.351782791137694, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.1981110572815, "episode_reward": 622.8597527796368, "step": 138000}
{"episode": 139.0, "batch_reward": 0.589865929543972, "critic_loss": 0.4714419152587652, "actor_loss": -54.41101089477539, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.00694704055786, "episode_reward": 24.386804554763813, "step": 139000}
{"episode": 140.0, "batch_reward": 0.5867690212130546, "critic_loss": 0.6610421050786972, "actor_loss": -54.60333024597168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.1821265220642, "episode_reward": 620.6922222243302, "step": 140000}
{"episode": 141.0, "batch_reward": 0.5862041323781013, "critic_loss": 0.5000261542201042, "actor_loss": -54.662496559143065, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.39666175842285, "episode_reward": 631.7783653972174, "step": 141000}
{"episode": 142.0, "batch_reward": 0.5868286922574043, "critic_loss": 0.6176803269088268, "actor_loss": -54.97377197265625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 383.22744154930115, "episode_reward": 619.9363864010627, "step": 142000}
{"episode": 143.0, "batch_reward": 0.5880417233109474, "critic_loss": 0.5505327413976192, "actor_loss": -54.992389167785646, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.97483468055725, "episode_reward": 635.0683331688505, "step": 143000}
{"episode": 144.0, "batch_reward": 0.5877449443936348, "critic_loss": 0.5477764217630029, "actor_loss": -55.265992317199704, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 389.7807984352112, "episode_reward": 625.7306162652515, "step": 144000}
{"episode": 145.0, "batch_reward": 0.588363429903984, "critic_loss": 0.5663036182224751, "actor_loss": -55.3923643951416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.858217000961304, "episode_reward": 639.3750018608093, "step": 145000}
{"episode": 146.0, "batch_reward": 0.5891447479724884, "critic_loss": 0.7170971640869975, "actor_loss": -55.59115640258789, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.183562040329, "episode_reward": 609.7145692795548, "step": 146000}
{"episode": 147.0, "batch_reward": 0.5883676819205285, "critic_loss": 0.6235112869143487, "actor_loss": -55.61898104095459, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.026081800460815, "episode_reward": 645.2670747739326, "step": 147000}
{"episode": 148.0, "batch_reward": 0.5886161704659462, "critic_loss": 0.5704458924382925, "actor_loss": -55.737345016479495, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.2943799495697, "episode_reward": 623.6564910963181, "step": 148000}
{"episode": 149.0, "batch_reward": 0.5889525746107102, "critic_loss": 0.5623955491036177, "actor_loss": -55.77058413696289, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.634382009506226, "episode_reward": 629.902457734548, "step": 149000}
{"episode": 150.0, "batch_reward": 0.5893087236285209, "critic_loss": 0.628741203315556, "actor_loss": -55.813337738037106, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
