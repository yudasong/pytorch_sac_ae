{"episode": 1.0, "duration": 17.807373762130737, "episode_reward": 7.579367547095394, "step": 1000}
{"episode": 2.0, "duration": 1.567446231842041, "episode_reward": 587.3438790414032, "step": 2000}
{"episode": 3.0, "batch_reward": 0.30543643169579565, "critic_loss": 0.13980610723563455, "actor_loss": -48.68006146550417, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 89.21718978881836, "episode_reward": 487.9461276911668, "step": 3000}
{"episode": 4.0, "batch_reward": 0.36744616490602494, "critic_loss": 0.3344608393907547, "actor_loss": -51.590952514648436, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.62110471725464, "episode_reward": 497.8156649716608, "step": 4000}
{"episode": 5.0, "batch_reward": 0.3978945254981518, "critic_loss": 0.44359072437882424, "actor_loss": -52.830447227478025, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.36850905418396, "episode_reward": 498.86056006824595, "step": 5000}
{"episode": 6.0, "batch_reward": 0.4133989734947681, "critic_loss": 0.4370293143838644, "actor_loss": -53.44177392578125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.322648763656616, "episode_reward": 495.53439440032525, "step": 6000}
{"episode": 7.0, "batch_reward": 0.43252131122350695, "critic_loss": 0.3527886983603239, "actor_loss": -54.479232833862305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.45631217956543, "episode_reward": 560.1715225408876, "step": 7000}
{"episode": 8.0, "batch_reward": 0.4515809832513332, "critic_loss": 0.32899937380850314, "actor_loss": -55.48317734527588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.5439031124115, "episode_reward": 565.6375886981215, "step": 8000}
{"episode": 9.0, "batch_reward": 0.4608186834454536, "critic_loss": 0.33292476762831213, "actor_loss": -55.95347825622559, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.001959800720215, "episode_reward": 493.3974062183296, "step": 9000}
{"episode": 10.0, "batch_reward": 0.46552872502803805, "critic_loss": 0.3607775733023882, "actor_loss": -49.43127676391602, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 4467.508812665939, "episode_reward": 550.9592582570729, "step": 10000}
{"episode": 11.0, "batch_reward": 0.47086501368880274, "critic_loss": 0.3312215949296951, "actor_loss": -49.53848230743408, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 45.60272932052612, "episode_reward": 329.8341973512375, "step": 11000}
{"episode": 12.0, "batch_reward": 0.44624848636984826, "critic_loss": 0.3118621210604906, "actor_loss": -43.41196356964112, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 477.22088098526, "episode_reward": 59.67817479218936, "step": 12000}
{"episode": 13.0, "batch_reward": 0.42678465923666953, "critic_loss": 0.30812413470447064, "actor_loss": -41.61109469604492, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.679874897003174, "episode_reward": 487.6255462013306, "step": 13000}
{"episode": 14.0, "batch_reward": 0.4351119705140591, "critic_loss": 0.34015086889266966, "actor_loss": -40.80325995635987, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 516.4382817745209, "episode_reward": 536.0075410236161, "step": 14000}
{"episode": 15.0, "batch_reward": 0.44008587720990183, "critic_loss": 0.3238281492441893, "actor_loss": -41.42735942077637, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.454187870025635, "episode_reward": 531.0116989806268, "step": 15000}
{"episode": 16.0, "batch_reward": 0.44525714361667634, "critic_loss": 0.3168997836560011, "actor_loss": -40.789494117736815, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 490.39524269104004, "episode_reward": 520.5160565422701, "step": 16000}
{"episode": 17.0, "batch_reward": 0.45174585524201394, "critic_loss": 0.2970675257742405, "actor_loss": -41.37902744293213, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.64011287689209, "episode_reward": 566.9400676152662, "step": 17000}
{"episode": 18.0, "batch_reward": 0.4591223593354225, "critic_loss": 0.2785490931123495, "actor_loss": -41.165524948120115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 473.58986926078796, "episode_reward": 550.1181048837753, "step": 18000}
{"episode": 19.0, "batch_reward": 0.4638350235521793, "critic_loss": 0.2769334299713373, "actor_loss": -41.491023460388185, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.699414014816284, "episode_reward": 577.8689045349587, "step": 19000}
{"episode": 20.0, "batch_reward": 0.471523723334074, "critic_loss": 0.2647988066226244, "actor_loss": -41.1935068359375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 471.60670495033264, "episode_reward": 587.4432006295106, "step": 20000}
{"episode": 21.0, "batch_reward": 0.4764618294239044, "critic_loss": 0.24992391750216483, "actor_loss": -41.459172760009764, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 45.08451867103577, "episode_reward": 583.7943915073416, "step": 21000}
{"episode": 22.0, "batch_reward": 0.4801707847416401, "critic_loss": 0.25121243561804296, "actor_loss": -40.96290809631348, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 523.2920711040497, "episode_reward": 559.0534266219026, "step": 22000}
{"episode": 23.0, "batch_reward": 0.48361721852421763, "critic_loss": 0.24745997244119644, "actor_loss": -41.3930615234375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.0755033493042, "episode_reward": 568.2627970643542, "step": 23000}
{"episode": 24.0, "batch_reward": 0.4869941338002682, "critic_loss": 0.2429097521007061, "actor_loss": -40.97273452758789, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 495.41481947898865, "episode_reward": 532.038639811175, "step": 24000}
{"episode": 25.0, "batch_reward": 0.4897770691215992, "critic_loss": 0.24218315032124518, "actor_loss": -41.28055694580078, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.727229595184326, "episode_reward": 530.0479536360608, "step": 25000}
{"episode": 26.0, "batch_reward": 0.4903458004295826, "critic_loss": 0.24339207117259504, "actor_loss": -40.22763303375244, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 472.831223487854, "episode_reward": 528.8778658656445, "step": 26000}
{"episode": 27.0, "batch_reward": 0.49102623614668844, "critic_loss": 0.2504233524054289, "actor_loss": -40.25934677124023, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.164989709854126, "episode_reward": 533.478537683124, "step": 27000}
{"episode": 28.0, "batch_reward": 0.4929017147421837, "critic_loss": 0.26842081037163734, "actor_loss": -39.43571622467041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 490.62984442710876, "episode_reward": 437.30174365159195, "step": 28000}
{"episode": 29.0, "batch_reward": 0.49262284976243975, "critic_loss": 0.273316607311368, "actor_loss": -39.44974383544922, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.981011629104614, "episode_reward": 533.1043006077787, "step": 29000}
{"episode": 30.0, "batch_reward": 0.4928799486458302, "critic_loss": 0.2887656573653221, "actor_loss": -39.01157829284668, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 499.41548562049866, "episode_reward": 438.31470085691274, "step": 30000}
{"episode": 31.0, "batch_reward": 0.49142332130670546, "critic_loss": 0.2976813459545374, "actor_loss": -38.76956081390381, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 50.459991455078125, "episode_reward": 552.5356066850843, "step": 31000}
{"episode": 32.0, "batch_reward": 0.49153883215785027, "critic_loss": 0.30636687111854555, "actor_loss": -37.718322517395016, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 481.9779167175293, "episode_reward": 505.7658671094778, "step": 32000}
{"episode": 33.0, "batch_reward": 0.49157015001773835, "critic_loss": 0.30837309843301774, "actor_loss": -37.74528023529053, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.222185373306274, "episode_reward": 515.0052374320082, "step": 33000}
{"episode": 34.0, "batch_reward": 0.49497324708104135, "critic_loss": 0.31737048618495467, "actor_loss": -37.64250764465332, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 473.4639115333557, "episode_reward": 531.0647145172271, "step": 34000}
{"episode": 35.0, "batch_reward": 0.4957009471058845, "critic_loss": 0.3112739386558533, "actor_loss": -37.72031436920166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 31.00282621383667, "episode_reward": 547.5730298886866, "step": 35000}
{"episode": 36.0, "batch_reward": 0.49562333536148073, "critic_loss": 0.3005036505907774, "actor_loss": -38.050424987792965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 474.8632724285126, "episode_reward": 514.3816112168699, "step": 36000}
{"episode": 37.0, "batch_reward": 0.4971432727277279, "critic_loss": 0.29503533855080605, "actor_loss": -38.186974617004395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.736868381500244, "episode_reward": 564.323660258535, "step": 37000}
{"episode": 38.0, "batch_reward": 0.4987665132880211, "critic_loss": 0.28383285512030126, "actor_loss": -38.37233927154541, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 505.72594237327576, "episode_reward": 576.2302263263342, "step": 38000}
{"episode": 39.0, "batch_reward": 0.5014437056481839, "critic_loss": 0.29139420975744723, "actor_loss": -38.61270517730713, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.777465105056763, "episode_reward": 542.6787727909923, "step": 39000}
{"episode": 40.0, "batch_reward": 0.5007296213805675, "critic_loss": 0.3081919228285551, "actor_loss": -38.85996814727783, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 495.37582898139954, "episode_reward": 521.1105727773879, "step": 40000}
{"episode": 41.0, "batch_reward": 0.5029784507751465, "critic_loss": 0.29873565934598445, "actor_loss": -39.08820579528808, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 42.25017523765564, "episode_reward": 565.0440727121772, "step": 41000}
{"episode": 42.0, "batch_reward": 0.5040788820385933, "critic_loss": 0.29898718231916427, "actor_loss": -38.87636249542236, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 502.1561470031738, "episode_reward": 552.4737529751626, "step": 42000}
{"episode": 43.0, "batch_reward": 0.505779568195343, "critic_loss": 0.2932303458750248, "actor_loss": -38.99113712310791, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.14346432685852, "episode_reward": 558.3094596618728, "step": 43000}
{"episode": 44.0, "batch_reward": 0.50693566852808, "critic_loss": 0.29526774543523787, "actor_loss": -38.889249382019045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 440.85293555259705, "episode_reward": 591.6512315726485, "step": 44000}
{"episode": 45.0, "batch_reward": 0.5062579587697983, "critic_loss": 0.2794947476089001, "actor_loss": -38.9420492477417, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.648261547088623, "episode_reward": 532.8637395512922, "step": 45000}
{"episode": 46.0, "batch_reward": 0.5083676847517491, "critic_loss": 0.2679092766046524, "actor_loss": -38.90259926605225, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 509.64894342422485, "episode_reward": 616.1310583041634, "step": 46000}
{"episode": 47.0, "batch_reward": 0.511631263256073, "critic_loss": 0.25980100297927855, "actor_loss": -39.196168113708495, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.976933479309082, "episode_reward": 612.6167555606805, "step": 47000}
{"episode": 48.0, "batch_reward": 0.5137211920917034, "critic_loss": 0.2679066265821457, "actor_loss": -39.78665947723389, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 511.9400751590729, "episode_reward": 577.3347853141564, "step": 48000}
{"episode": 49.0, "batch_reward": 0.5154507445991039, "critic_loss": 0.2648720804452896, "actor_loss": -40.01979832458496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.723376035690308, "episode_reward": 622.8908987498002, "step": 49000}
{"episode": 50.0, "batch_reward": 0.516861647605896, "critic_loss": 0.26581733517348766, "actor_loss": -40.68600231933594, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 453.5900237560272, "episode_reward": 624.4106532710593, "step": 50000}
{"episode": 51.0, "batch_reward": 0.5194484348595142, "critic_loss": 0.26233758544921876, "actor_loss": -40.97052479553223, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 43.233468770980835, "episode_reward": 632.5299122178207, "step": 51000}
{"episode": 52.0, "batch_reward": 0.5220561147928238, "critic_loss": 0.2627476277798414, "actor_loss": -41.40709555053711, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 493.421098947525, "episode_reward": 632.924415598068, "step": 52000}
{"episode": 53.0, "batch_reward": 0.5232043496966362, "critic_loss": 0.2651129612028599, "actor_loss": -41.59858783721924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.706125259399414, "episode_reward": 642.2698279202536, "step": 53000}
{"episode": 54.0, "batch_reward": 0.5251143532991409, "critic_loss": 0.2595402031093836, "actor_loss": -41.86375494384766, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 513.6643867492676, "episode_reward": 636.4180252496789, "step": 54000}
{"episode": 55.0, "batch_reward": 0.5279743418991566, "critic_loss": 0.2647626125365496, "actor_loss": -42.27896012878418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.697863817214966, "episode_reward": 648.2643807981201, "step": 55000}
{"episode": 56.0, "batch_reward": 0.530242163926363, "critic_loss": 0.2653825677484274, "actor_loss": -42.967078483581545, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 508.21318078041077, "episode_reward": 605.9458128621351, "step": 56000}
{"episode": 57.0, "batch_reward": 0.5314690124094487, "critic_loss": 0.2649067372083664, "actor_loss": -43.28215437316894, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.73160696029663, "episode_reward": 606.9417228244514, "step": 57000}
{"episode": 58.0, "batch_reward": 0.5330286285579204, "critic_loss": 0.25904193744063375, "actor_loss": -43.87257912445068, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 456.47237372398376, "episode_reward": 612.5714636638338, "step": 58000}
{"episode": 59.0, "batch_reward": 0.5344971134662628, "critic_loss": 0.2518307668864727, "actor_loss": -44.13020350646973, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.71368408203125, "episode_reward": 593.3917013600757, "step": 59000}
{"episode": 60.0, "batch_reward": 0.5354082378149032, "critic_loss": 0.24986327446997167, "actor_loss": -44.70612197875977, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 435.5930449962616, "episode_reward": 586.564516589438, "step": 60000}
{"episode": 61.0, "batch_reward": 0.5366316125392914, "critic_loss": 0.24140767151117326, "actor_loss": -44.95583879852295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 46.46273756027222, "episode_reward": 595.3846363695296, "step": 61000}
{"episode": 62.0, "batch_reward": 0.5358557822108269, "critic_loss": 0.2329683101028204, "actor_loss": -45.154155891418455, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 476.86517095565796, "episode_reward": 581.5981985412958, "step": 62000}
{"episode": 63.0, "batch_reward": 0.5378795720338821, "critic_loss": 0.22608154768496752, "actor_loss": -45.40946138763428, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.892857313156128, "episode_reward": 617.3110441142857, "step": 63000}
{"episode": 64.0, "batch_reward": 0.5394309429526329, "critic_loss": 0.26113832929730413, "actor_loss": -45.50397137451172, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 497.00704193115234, "episode_reward": 542.154195644928, "step": 64000}
{"episode": 65.0, "batch_reward": 0.538272177696228, "critic_loss": 0.2406010100543499, "actor_loss": -45.48684783935547, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.01304578781128, "episode_reward": 549.0361147056343, "step": 65000}
{"episode": 66.0, "batch_reward": 0.5387274540364743, "critic_loss": 0.2395223995000124, "actor_loss": -45.40254013824463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 488.7039248943329, "episode_reward": 599.9983910707803, "step": 66000}
{"episode": 67.0, "batch_reward": 0.539470920920372, "critic_loss": 0.2221635258346796, "actor_loss": -45.58410092926025, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.9327654838562, "episode_reward": 600.8353081927676, "step": 67000}
{"episode": 68.0, "batch_reward": 0.5406712328791619, "critic_loss": 0.21899495931714774, "actor_loss": -45.6525997467041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 504.4499011039734, "episode_reward": 599.1651112768138, "step": 68000}
{"episode": 69.0, "batch_reward": 0.5406204918026924, "critic_loss": 0.2162471056059003, "actor_loss": -45.71525704193115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.455039501190186, "episode_reward": 615.2949385500696, "step": 69000}
{"episode": 70.0, "batch_reward": 0.5435492632389068, "critic_loss": 0.2027944637015462, "actor_loss": -46.05584654998779, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 467.64833188056946, "episode_reward": 623.6233720405337, "step": 70000}
{"episode": 71.0, "batch_reward": 0.5430046156346798, "critic_loss": 0.19240808517485858, "actor_loss": -46.21166527557373, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 45.04357647895813, "episode_reward": 599.5857074828496, "step": 71000}
{"episode": 72.0, "batch_reward": 0.5446454520821571, "critic_loss": 0.19004112800210715, "actor_loss": -46.37696197509766, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 465.53420853614807, "episode_reward": 601.0323721015017, "step": 72000}
{"episode": 73.0, "batch_reward": 0.5451622649431228, "critic_loss": 0.18685743314772843, "actor_loss": -46.46457035064697, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.780909538269043, "episode_reward": 607.8100261110167, "step": 73000}
{"episode": 74.0, "batch_reward": 0.5462517205774784, "critic_loss": 0.1822174881324172, "actor_loss": -46.862973449707034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 494.5968179702759, "episode_reward": 591.8092956139764, "step": 74000}
{"episode": 75.0, "batch_reward": 0.547540743291378, "critic_loss": 0.17196939828246832, "actor_loss": -47.10444271850586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.93613910675049, "episode_reward": 589.8009566611689, "step": 75000}
{"episode": 76.0, "batch_reward": 0.5477287274599075, "critic_loss": 0.1735940132290125, "actor_loss": -47.358311325073245, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 440.2501018047333, "episode_reward": 606.2525069569725, "step": 76000}
{"episode": 77.0, "batch_reward": 0.5482237404584884, "critic_loss": 0.17046532997488975, "actor_loss": -47.430607215881345, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.371773958206177, "episode_reward": 631.0550767985675, "step": 77000}
{"episode": 78.0, "batch_reward": 0.5495942455530166, "critic_loss": 0.1765053492411971, "actor_loss": -47.822026962280276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 481.48075008392334, "episode_reward": 579.285858442416, "step": 78000}
{"episode": 79.0, "batch_reward": 0.5499455715417862, "critic_loss": 0.16929114010185004, "actor_loss": -47.893941299438474, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.957502365112305, "episode_reward": 577.5304131872728, "step": 79000}
{"episode": 80.0, "batch_reward": 0.5497367450296878, "critic_loss": 0.16728538258373737, "actor_loss": -48.075589553833005, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 451.16442036628723, "episode_reward": 620.8112034725532, "step": 80000}
{"episode": 81.0, "batch_reward": 0.5515565765500069, "critic_loss": 0.1588645966053009, "actor_loss": -48.33433494567871, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.87889623641968, "episode_reward": 627.3043955787092, "step": 81000}
{"episode": 82.0, "batch_reward": 0.5515661208033562, "critic_loss": 0.1778885458856821, "actor_loss": -48.30990908050537, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 494.5933132171631, "episode_reward": 305.88345862825275, "step": 82000}
{"episode": 83.0, "batch_reward": 0.549391548216343, "critic_loss": 0.1734958774149418, "actor_loss": -48.1650319442749, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.334346055984497, "episode_reward": 618.8322103290823, "step": 83000}
{"episode": 84.0, "batch_reward": 0.5491710204184055, "critic_loss": 0.17578690510243178, "actor_loss": -48.39729167938233, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 541.5921995639801, "episode_reward": 626.9670346062337, "step": 84000}
{"episode": 85.0, "batch_reward": 0.5518865453898907, "critic_loss": 0.16635381828248502, "actor_loss": -48.655052551269534, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.763512134552002, "episode_reward": 609.2782883976519, "step": 85000}
{"episode": 86.0, "batch_reward": 0.5519366626143456, "critic_loss": 0.1689391917362809, "actor_loss": -48.82681595611572, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 506.5413444042206, "episode_reward": 620.4063976277271, "step": 86000}
{"episode": 87.0, "batch_reward": 0.5517182101011276, "critic_loss": 0.16674985257536173, "actor_loss": -48.87749026489258, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.71551537513733, "episode_reward": 632.5482799901918, "step": 87000}
{"episode": 88.0, "batch_reward": 0.5532367645204067, "critic_loss": 0.15508979784697294, "actor_loss": -49.02890342712402, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 409.9421765804291, "episode_reward": 622.6863172275711, "step": 88000}
{"episode": 89.0, "batch_reward": 0.5534581001996994, "critic_loss": 0.17056953670084476, "actor_loss": -49.213119674682616, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.787718534469604, "episode_reward": 639.6786935353103, "step": 89000}
{"episode": 90.0, "batch_reward": 0.5555440470576286, "critic_loss": 0.1697339216992259, "actor_loss": -49.562960105895996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 483.5038845539093, "episode_reward": 647.4341118628911, "step": 90000}
{"episode": 91.0, "batch_reward": 0.5557462892532349, "critic_loss": 0.15946588931232691, "actor_loss": -49.61755290985107, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 43.29833126068115, "episode_reward": 655.9633011923646, "step": 91000}
{"episode": 92.0, "batch_reward": 0.5567312895059585, "critic_loss": 0.14760270935297012, "actor_loss": -49.88337456512451, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 430.5225112438202, "episode_reward": 649.5645408095572, "step": 92000}
{"episode": 93.0, "batch_reward": 0.5573255212903023, "critic_loss": 0.1597794961556792, "actor_loss": -49.97024765777588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.35625982284546, "episode_reward": 627.0560446920169, "step": 93000}
{"episode": 94.0, "batch_reward": 0.5593446580767631, "critic_loss": 0.1444925546646118, "actor_loss": -50.19700175476074, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 501.45241951942444, "episode_reward": 668.5597312734777, "step": 94000}
{"episode": 95.0, "batch_reward": 0.5595363545715809, "critic_loss": 0.15156442376971244, "actor_loss": -50.37676872253418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.160250425338745, "episode_reward": 615.8625259253183, "step": 95000}
{"episode": 96.0, "batch_reward": 0.5605159096121788, "critic_loss": 0.13965328680723907, "actor_loss": -50.77122478485107, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 484.2575876712799, "episode_reward": 655.5465276958927, "step": 96000}
{"episode": 97.0, "batch_reward": 0.5615381905138492, "critic_loss": 0.1366709877476096, "actor_loss": -51.083852561950685, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.55061149597168, "episode_reward": 629.6023488523165, "step": 97000}
{"episode": 98.0, "batch_reward": 0.5629038811326027, "critic_loss": 0.14664309559762478, "actor_loss": -51.29580191802979, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 481.1415011882782, "episode_reward": 673.3735481387916, "step": 98000}
{"episode": 99.0, "batch_reward": 0.5637639593482018, "critic_loss": 0.13810515521094202, "actor_loss": -51.5281667098999, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.45691704750061, "episode_reward": 668.0401163332649, "step": 99000}
{"episode": 100.0, "batch_reward": 0.5642519779801368, "critic_loss": 0.14017650853097438, "actor_loss": -51.63623336791992, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 504.07926392555237, "episode_reward": 633.0602683232974, "step": 100000}
{"episode": 101.0, "batch_reward": 0.5656069155931472, "critic_loss": 0.14162932474911213, "actor_loss": -51.87635439300537, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 43.00990629196167, "episode_reward": 665.5088902797497, "step": 101000}
{"episode": 102.0, "batch_reward": 0.5661734044551849, "critic_loss": 0.13523449108749627, "actor_loss": -51.97474529266358, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 495.44380497932434, "episode_reward": 682.7700341129384, "step": 102000}
{"episode": 103.0, "batch_reward": 0.5669397090673447, "critic_loss": 0.13398580246418715, "actor_loss": -52.230971771240235, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.781363248825073, "episode_reward": 678.571094044276, "step": 103000}
{"episode": 104.0, "batch_reward": 0.5684974647760391, "critic_loss": 0.13340831463783978, "actor_loss": -52.60519757843018, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 537.2159578800201, "episode_reward": 661.4408171004935, "step": 104000}
{"episode": 105.0, "batch_reward": 0.5700248199701309, "critic_loss": 0.14453285133466123, "actor_loss": -52.861526153564455, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.61000967025757, "episode_reward": 665.6059800304805, "step": 105000}
{"episode": 106.0, "batch_reward": 0.5704199334383011, "critic_loss": 0.13824407655373216, "actor_loss": -52.99953495788574, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 493.06859064102173, "episode_reward": 655.8706995775931, "step": 106000}
{"episode": 107.0, "batch_reward": 0.5716040213108062, "critic_loss": 0.1414365970790386, "actor_loss": -53.299575592041016, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.726247787475586, "episode_reward": 684.3738894459303, "step": 107000}
{"episode": 108.0, "batch_reward": 0.5718856263160705, "critic_loss": 0.1565943898484111, "actor_loss": -53.31192218780517, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 461.4232883453369, "episode_reward": 670.6979243176404, "step": 108000}
{"episode": 109.0, "batch_reward": 0.5725248422622681, "critic_loss": 0.15063552056252957, "actor_loss": -53.44578968048096, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 31.494888305664062, "episode_reward": 674.1855863794651, "step": 109000}
{"episode": 110.0, "batch_reward": 0.5740593225359917, "critic_loss": 0.15596807930991052, "actor_loss": -53.6940961151123, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 488.35315561294556, "episode_reward": 662.7716133384916, "step": 110000}
{"episode": 111.0, "batch_reward": 0.5746892673373223, "critic_loss": 0.1524312015771866, "actor_loss": -53.81990692138672, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.39634418487549, "episode_reward": 657.1724544448381, "step": 111000}
{"episode": 112.0, "batch_reward": 0.5762280127406121, "critic_loss": 0.17518280331045388, "actor_loss": -54.05493687438965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 488.6929495334625, "episode_reward": 643.4885270798234, "step": 112000}
{"episode": 113.0, "batch_reward": 0.5759844211935997, "critic_loss": 0.18071658324450254, "actor_loss": -54.25015179443359, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.78854489326477, "episode_reward": 681.1153327323424, "step": 113000}
{"episode": 114.0, "batch_reward": 0.5768279478549957, "critic_loss": 0.1954984426945448, "actor_loss": -54.51752710723877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 499.0966317653656, "episode_reward": 669.4129279785358, "step": 114000}
{"episode": 115.0, "batch_reward": 0.5777446269392967, "critic_loss": 0.19561200453341007, "actor_loss": -54.791011848449706, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.598761320114136, "episode_reward": 693.8341444851429, "step": 115000}
{"episode": 116.0, "batch_reward": 0.5786143338084221, "critic_loss": 0.24736847600340844, "actor_loss": -55.179467971801756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 509.2814517021179, "episode_reward": 700.9563278158294, "step": 116000}
{"episode": 117.0, "batch_reward": 0.5791349076032638, "critic_loss": 0.22893025577813386, "actor_loss": -55.36839362335205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.01653242111206, "episode_reward": 675.6213209154218, "step": 117000}
{"episode": 118.0, "batch_reward": 0.580749637901783, "critic_loss": 0.3694804727807641, "actor_loss": -55.70536054992676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 522.0718157291412, "episode_reward": 658.1732838592172, "step": 118000}
{"episode": 119.0, "batch_reward": 0.581661576807499, "critic_loss": 0.47015215004235505, "actor_loss": -55.983893844604495, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.6540207862854, "episode_reward": 645.3977686750135, "step": 119000}
{"episode": 120.0, "batch_reward": 0.58161164778471, "critic_loss": 0.5294343748614192, "actor_loss": -56.26034448242188, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 443.652704000473, "episode_reward": 691.3692776423405, "step": 120000}
{"episode": 121.0, "batch_reward": 0.5809951080679894, "critic_loss": 1.0573779772296548, "actor_loss": -56.36897693634033, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.24291729927063, "episode_reward": 57.30131023667688, "step": 121000}
{"episode": 122.0, "batch_reward": 0.5787452086806297, "critic_loss": 0.7821182082146406, "actor_loss": -56.35060991668701, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 455.97207021713257, "episode_reward": 638.732322069989, "step": 122000}
{"episode": 123.0, "batch_reward": 0.5771058046221733, "critic_loss": 3.115826909802854, "actor_loss": -56.670093307495115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.851045846939087, "episode_reward": 45.12650607922536, "step": 123000}
{"episode": 124.0, "batch_reward": 0.5721539297103881, "critic_loss": 7.650274462342262, "actor_loss": -58.01239614868164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 499.47739720344543, "episode_reward": 18.903926025932616, "step": 124000}
{"episode": 125.0, "batch_reward": 0.5678200204372406, "critic_loss": 7.669219307124615, "actor_loss": -60.61332698059082, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.223400115966797, "episode_reward": 25.15149959092014, "step": 125000}
{"episode": 126.0, "batch_reward": 0.5641877164244652, "critic_loss": 6.285135771274566, "actor_loss": -63.108149513244626, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 525.7966256141663, "episode_reward": 62.35065321288891, "step": 126000}
{"episode": 127.0, "batch_reward": 0.558945513010025, "critic_loss": 8.60353043526411, "actor_loss": -66.74521424102784, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.005728483200073, "episode_reward": 49.40530108185987, "step": 127000}
{"episode": 128.0, "batch_reward": 0.5560229022204876, "critic_loss": 6.453677785992622, "actor_loss": -70.50303776550292, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 480.31033539772034, "episode_reward": 166.05433519786484, "step": 128000}
{"episode": 129.0, "batch_reward": 0.5529400118589402, "critic_loss": 5.463567311167717, "actor_loss": -74.21750169372558, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.95194363594055, "episode_reward": 88.70958682625255, "step": 129000}
{"episode": 130.0, "batch_reward": 0.5503766024112702, "critic_loss": 5.144514030575753, "actor_loss": -77.33088980102539, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 442.05303406715393, "episode_reward": 137.15024958595032, "step": 130000}
{"episode": 131.0, "batch_reward": 0.545399362385273, "critic_loss": 3.772913404107094, "actor_loss": -79.3304279937744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 48.91438031196594, "episode_reward": 165.40588003298444, "step": 131000}
{"episode": 132.0, "batch_reward": 0.5434852685928345, "critic_loss": 2.448068849384785, "actor_loss": -80.83412045288085, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 478.10032081604004, "episode_reward": 219.48771282712553, "step": 132000}
{"episode": 133.0, "batch_reward": 0.5414428573548794, "critic_loss": 1.9575985093116761, "actor_loss": -81.66065080261231, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.160226345062256, "episode_reward": 125.18737927862107, "step": 133000}
{"episode": 134.0, "batch_reward": 0.5373457922637462, "critic_loss": 1.6163823826909065, "actor_loss": -81.13907751464843, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 476.79860639572144, "episode_reward": 125.01311548862247, "step": 134000}
{"episode": 135.0, "batch_reward": 0.5349142234623432, "critic_loss": 1.4523311581611633, "actor_loss": -80.76708505249023, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.37414050102234, "episode_reward": 55.7306326936234, "step": 135000}
{"episode": 136.0, "batch_reward": 0.5311978328227996, "critic_loss": 1.299019473195076, "actor_loss": -80.05273490905762, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 458.80787229537964, "episode_reward": 47.5124030251552, "step": 136000}
{"episode": 137.0, "batch_reward": 0.528635590851307, "critic_loss": 1.203407728254795, "actor_loss": -79.45224085998535, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.84531569480896, "episode_reward": 77.07701907929392, "step": 137000}
{"episode": 138.0, "batch_reward": 0.5252154051661492, "critic_loss": 1.0463590471148492, "actor_loss": -78.76433491516113, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 481.1979305744171, "episode_reward": 79.14408847295165, "step": 138000}
{"episode": 139.0, "batch_reward": 0.5217169986367226, "critic_loss": 0.9781293431520462, "actor_loss": -78.07263174438476, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.252644538879395, "episode_reward": 29.92950201316865, "step": 139000}
{"episode": 140.0, "batch_reward": 0.5182307435572148, "critic_loss": 1.3217835723161697, "actor_loss": -76.7719077758789, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 437.1893835067749, "episode_reward": 288.15715911907876, "step": 140000}
{"episode": 141.0, "batch_reward": 0.5156393911838532, "critic_loss": 1.0619813879430293, "actor_loss": -76.24237657165527, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 45.75901961326599, "episode_reward": 321.9580074504625, "step": 141000}
{"episode": 142.0, "batch_reward": 0.5149797315299511, "critic_loss": 0.9869891918003559, "actor_loss": -75.38352282714844, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 469.78727531433105, "episode_reward": 224.80968456427132, "step": 142000}
{"episode": 143.0, "batch_reward": 0.5130537550449371, "critic_loss": 0.9273345248401165, "actor_loss": -74.59646453857422, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.253875017166138, "episode_reward": 253.01674282756906, "step": 143000}
{"episode": 144.0, "batch_reward": 0.5089102880954742, "critic_loss": 0.9567981971502304, "actor_loss": -73.79657981872559, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 491.68537402153015, "episode_reward": 41.021346096198236, "step": 144000}
{"episode": 145.0, "batch_reward": 0.509288893789053, "critic_loss": 0.8629815950095654, "actor_loss": -73.26494178771972, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.819456100463867, "episode_reward": 327.28127437807456, "step": 145000}
{"episode": 146.0, "batch_reward": 0.5064634655714035, "critic_loss": 0.7984349952340126, "actor_loss": -72.3838412399292, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 474.54023599624634, "episode_reward": 190.66685048036635, "step": 146000}
{"episode": 147.0, "batch_reward": 0.5041531675159932, "critic_loss": 0.8312716140151024, "actor_loss": -71.51758241271973, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.651634693145752, "episode_reward": 145.39320629448625, "step": 147000}
{"episode": 148.0, "batch_reward": 0.5025779128670692, "critic_loss": 0.7165045608133077, "actor_loss": -70.97263695526124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 445.9188838005066, "episode_reward": 205.62325846150327, "step": 148000}
{"episode": 149.0, "batch_reward": 0.5006238396465779, "critic_loss": 0.698885530680418, "actor_loss": -70.2958770751953, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.99610161781311, "episode_reward": 383.8872730029024, "step": 149000}
{"episode": 150.0, "batch_reward": 0.4993917739391327, "critic_loss": 0.8576772646009923, "actor_loss": -69.44952973175049, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
