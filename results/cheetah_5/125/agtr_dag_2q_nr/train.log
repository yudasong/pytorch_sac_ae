{"episode": 1.0, "duration": 16.69718599319458, "episode_reward": 7.579367547095394, "step": 1000}
{"episode": 2.0, "duration": 1.5745625495910645, "episode_reward": 587.3438790414032, "step": 2000}
{"episode": 3.0, "batch_reward": 0.30543643169579565, "critic_loss": 0.13980610723563455, "actor_loss": -48.68006146550417, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 82.82114171981812, "episode_reward": 487.9461276911668, "step": 3000}
{"episode": 4.0, "batch_reward": 0.36744616490602494, "critic_loss": 0.3344608393907547, "actor_loss": -51.590952514648436, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.504892110824585, "episode_reward": 497.8156649716608, "step": 4000}
{"episode": 5.0, "batch_reward": 0.3978945254981518, "critic_loss": 0.44359072437882424, "actor_loss": -52.830447227478025, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.452524662017822, "episode_reward": 498.86056006824595, "step": 5000}
{"episode": 6.0, "batch_reward": 0.4133989734947681, "critic_loss": 0.4370293143838644, "actor_loss": -53.44177392578125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.00442099571228, "episode_reward": 495.53439440032525, "step": 6000}
{"episode": 7.0, "batch_reward": 0.43252131122350695, "critic_loss": 0.3527886983603239, "actor_loss": -54.479232833862305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.24046802520752, "episode_reward": 560.1715225408876, "step": 7000}
{"episode": 8.0, "batch_reward": 0.4515809832513332, "critic_loss": 0.32899937380850314, "actor_loss": -55.48317734527588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.487103939056396, "episode_reward": 565.6375886981215, "step": 8000}
{"episode": 9.0, "batch_reward": 0.4608186834454536, "critic_loss": 0.33292476762831213, "actor_loss": -55.95347825622559, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.607361316680908, "episode_reward": 493.3974062183296, "step": 9000}
{"episode": 10.0, "batch_reward": 0.46552872502803805, "critic_loss": 0.3607775733023882, "actor_loss": -49.43127676391602, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 3817.7482833862305, "episode_reward": 550.9592582570729, "step": 10000}
{"episode": 11.0, "batch_reward": 0.47086501368880274, "critic_loss": 0.3312215949296951, "actor_loss": -49.53848230743408, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 42.03017449378967, "episode_reward": 329.8341973512375, "step": 11000}
{"episode": 12.0, "batch_reward": 0.44624848636984826, "critic_loss": 0.3118621210604906, "actor_loss": -43.41196356964112, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 460.3524737358093, "episode_reward": 59.67817479218936, "step": 12000}
{"episode": 13.0, "batch_reward": 0.42678465923666953, "critic_loss": 0.30812413470447064, "actor_loss": -41.61109469604492, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.622730016708374, "episode_reward": 487.6255462013306, "step": 13000}
{"episode": 14.0, "batch_reward": 0.4351119705140591, "critic_loss": 0.34015086889266966, "actor_loss": -40.80325995635987, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 462.1230511665344, "episode_reward": 536.0075410236161, "step": 14000}
{"episode": 15.0, "batch_reward": 0.44008587720990183, "critic_loss": 0.3238281492441893, "actor_loss": -41.42735942077637, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.329007387161255, "episode_reward": 531.0116989806268, "step": 15000}
{"episode": 16.0, "batch_reward": 0.4460920135676861, "critic_loss": 0.30749705363810065, "actor_loss": -40.64586954498291, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 496.25703501701355, "episode_reward": 541.2167563901236, "step": 16000}
{"episode": 17.0, "batch_reward": 0.4529441998898983, "critic_loss": 0.2870447253882885, "actor_loss": -41.2906226272583, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.708067178726196, "episode_reward": 547.9816800573993, "step": 17000}
{"episode": 18.0, "batch_reward": 0.4589916281402111, "critic_loss": 0.26028335869312286, "actor_loss": -40.8030188293457, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 483.22815108299255, "episode_reward": 546.8345074303152, "step": 18000}
{"episode": 19.0, "batch_reward": 0.4636192878484726, "critic_loss": 0.24746469919383526, "actor_loss": -41.115755561828614, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.20128059387207, "episode_reward": 574.6406896391877, "step": 19000}
{"episode": 20.0, "batch_reward": 0.4685748480260372, "critic_loss": 0.24753028196096422, "actor_loss": -41.09351164245606, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 519.6681070327759, "episode_reward": 511.7228297249312, "step": 20000}
{"episode": 21.0, "batch_reward": 0.4720254735648632, "critic_loss": 0.22627393563091755, "actor_loss": -41.29203789520264, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 42.48805642127991, "episode_reward": 563.2582251721325, "step": 21000}
{"episode": 22.0, "batch_reward": 0.4756154468655586, "critic_loss": 0.22775770477950574, "actor_loss": -41.50861863708496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 530.1808993816376, "episode_reward": 520.2361917010049, "step": 22000}
{"episode": 23.0, "batch_reward": 0.4766929052770138, "critic_loss": 0.21309171107411384, "actor_loss": -41.7924842300415, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.59527611732483, "episode_reward": 520.3235319712553, "step": 23000}
{"episode": 24.0, "batch_reward": 0.4782051258683205, "critic_loss": 0.20519507840275764, "actor_loss": -41.75792276763916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 554.4834208488464, "episode_reward": 512.6838160977823, "step": 24000}
{"episode": 25.0, "batch_reward": 0.4815390441417694, "critic_loss": 0.20555865395069123, "actor_loss": -42.11789444732666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.131657600402832, "episode_reward": 532.3103746517274, "step": 25000}
{"episode": 26.0, "batch_reward": 0.4829796770513058, "critic_loss": 0.19607313504070042, "actor_loss": -42.07099346923828, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 572.910692691803, "episode_reward": 549.5753379752513, "step": 26000}
{"episode": 27.0, "batch_reward": 0.4847188525795937, "critic_loss": 0.20344484340399505, "actor_loss": -42.18236325073242, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.22055411338806, "episode_reward": 570.833875482345, "step": 27000}
{"episode": 28.0, "batch_reward": 0.48869654995203016, "critic_loss": 0.21295397708564998, "actor_loss": -42.376164367675784, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 537.9382965564728, "episode_reward": 560.9073539171933, "step": 28000}
{"episode": 29.0, "batch_reward": 0.4917266109883785, "critic_loss": 0.21321598647534848, "actor_loss": -42.64294132995605, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.298520803451538, "episode_reward": 559.5310938428019, "step": 29000}
{"episode": 30.0, "batch_reward": 0.49364599281549454, "critic_loss": 0.208657369248569, "actor_loss": -42.42036751556397, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 557.6671867370605, "episode_reward": 556.3640331019122, "step": 30000}
{"episode": 31.0, "batch_reward": 0.4954562830924988, "critic_loss": 0.21256645860522985, "actor_loss": -42.58299654388428, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 46.499549865722656, "episode_reward": 540.7779781591425, "step": 31000}
{"episode": 32.0, "batch_reward": 0.49579511806368826, "critic_loss": 0.21376436010748148, "actor_loss": -42.53461167907715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 565.746547460556, "episode_reward": 531.028137341146, "step": 32000}
{"episode": 33.0, "batch_reward": 0.49640380883216856, "critic_loss": 0.20337532458454372, "actor_loss": -42.59022890472412, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.33501386642456, "episode_reward": 529.662730669026, "step": 33000}
{"episode": 34.0, "batch_reward": 0.4995427854955196, "critic_loss": 0.21578701442480086, "actor_loss": -42.93771464538574, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 547.3487610816956, "episode_reward": 551.46691737448, "step": 34000}
{"episode": 35.0, "batch_reward": 0.5006003575623036, "critic_loss": 0.21826992358267308, "actor_loss": -42.996688247680666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.37367272377014, "episode_reward": 518.9766996604142, "step": 35000}
{"episode": 36.0, "batch_reward": 0.4990399834215641, "critic_loss": 0.23106743715703487, "actor_loss": -43.14991381835937, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 567.8701069355011, "episode_reward": 507.6376329638129, "step": 36000}
{"episode": 37.0, "batch_reward": 0.49505911993980406, "critic_loss": 0.24903698610514402, "actor_loss": -42.70822116088867, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.45013689994812, "episode_reward": 42.044935001290604, "step": 37000}
{"episode": 38.0, "batch_reward": 0.4891617715954781, "critic_loss": 0.2420640566572547, "actor_loss": -42.5385433883667, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 568.6357755661011, "episode_reward": 592.6708215683807, "step": 38000}
{"episode": 39.0, "batch_reward": 0.49173354625701904, "critic_loss": 0.2476689053028822, "actor_loss": -42.62779558563233, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.625158548355103, "episode_reward": 578.965809828048, "step": 39000}
{"episode": 40.0, "batch_reward": 0.4936724591851234, "critic_loss": 0.249356105491519, "actor_loss": -42.74787823486328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 537.4537084102631, "episode_reward": 592.0506430546097, "step": 40000}
{"episode": 41.0, "batch_reward": 0.49694917592406274, "critic_loss": 0.23584613688290118, "actor_loss": -43.07852653503418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 42.906819343566895, "episode_reward": 595.7208301328114, "step": 41000}
{"episode": 42.0, "batch_reward": 0.49878049311041833, "critic_loss": 0.24004037040472032, "actor_loss": -43.549636917114256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 575.5981011390686, "episode_reward": 553.9284098294053, "step": 42000}
{"episode": 43.0, "batch_reward": 0.5002804689705372, "critic_loss": 0.23573158530890942, "actor_loss": -43.58930493927002, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.021799325942993, "episode_reward": 588.7436554497915, "step": 43000}
{"episode": 44.0, "batch_reward": 0.5022366024255752, "critic_loss": 0.22152080553770065, "actor_loss": -43.8638967590332, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 577.3276731967926, "episode_reward": 562.3679874948236, "step": 44000}
{"episode": 45.0, "batch_reward": 0.5022962536513805, "critic_loss": 0.23644755727052688, "actor_loss": -43.92669934082031, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.963605403900146, "episode_reward": 576.2838244944678, "step": 45000}
{"episode": 46.0, "batch_reward": 0.5041344646811485, "critic_loss": 0.2162372453212738, "actor_loss": -44.03017486572266, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 580.091320514679, "episode_reward": 595.8102325232302, "step": 46000}
{"episode": 47.0, "batch_reward": 0.5071263142228126, "critic_loss": 0.2374170536994934, "actor_loss": -44.271916282653805, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.46604895591736, "episode_reward": 548.8238330033759, "step": 47000}
{"episode": 48.0, "batch_reward": 0.5085914218127727, "critic_loss": 0.23157456991821526, "actor_loss": -44.29705849456787, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 575.113439321518, "episode_reward": 625.3359878279198, "step": 48000}
{"episode": 49.0, "batch_reward": 0.510059939712286, "critic_loss": 0.22370860755443572, "actor_loss": -44.46279169464111, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.668370723724365, "episode_reward": 590.0741907955727, "step": 49000}
{"episode": 50.0, "batch_reward": 0.5114032990932464, "critic_loss": 0.21590876460075378, "actor_loss": -44.76288078308105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 540.7991278171539, "episode_reward": 590.2664944345681, "step": 50000}
{"episode": 51.0, "batch_reward": 0.5129295857846737, "critic_loss": 0.20694424956291915, "actor_loss": -44.90789138031006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 43.93842267990112, "episode_reward": 576.7696336586129, "step": 51000}
{"episode": 52.0, "batch_reward": 0.5150704334676266, "critic_loss": 0.2055461082905531, "actor_loss": -45.06937572479248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 567.1943378448486, "episode_reward": 591.2491609062957, "step": 52000}
{"episode": 53.0, "batch_reward": 0.515726540863514, "critic_loss": 0.19634015906602145, "actor_loss": -45.1711781539917, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.450779914855957, "episode_reward": 588.3691580601323, "step": 53000}
{"episode": 54.0, "batch_reward": 0.5165162380933762, "critic_loss": 0.20260223004221917, "actor_loss": -45.36577130126953, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 579.1832690238953, "episode_reward": 591.8633098560974, "step": 54000}
{"episode": 55.0, "batch_reward": 0.518925694167614, "critic_loss": 0.20542155754566194, "actor_loss": -45.624801971435545, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.432299375534058, "episode_reward": 616.0863224251442, "step": 55000}
{"episode": 56.0, "batch_reward": 0.5214418674409389, "critic_loss": 0.21488625530153513, "actor_loss": -45.565340644836425, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 584.3936543464661, "episode_reward": 626.9019386176637, "step": 56000}
{"episode": 57.0, "batch_reward": 0.5225767270028591, "critic_loss": 0.18394261050969363, "actor_loss": -45.7880620803833, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.65404772758484, "episode_reward": 617.6038929250419, "step": 57000}
{"episode": 58.0, "batch_reward": 0.525059708148241, "critic_loss": 0.18862450356036425, "actor_loss": -46.20230304718017, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 584.1619436740875, "episode_reward": 628.7919360861623, "step": 58000}
{"episode": 59.0, "batch_reward": 0.5264730238616466, "critic_loss": 0.16402895137667656, "actor_loss": -46.39532780456543, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.589667797088623, "episode_reward": 602.1030719231748, "step": 59000}
{"episode": 60.0, "batch_reward": 0.5279354609251022, "critic_loss": 0.1625672292634845, "actor_loss": -46.41266081237793, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 595.904262304306, "episode_reward": 625.3130623648423, "step": 60000}
{"episode": 61.0, "batch_reward": 0.5292903893589973, "critic_loss": 0.16607203140854834, "actor_loss": -46.621213279724124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 45.57032132148743, "episode_reward": 591.8132299195963, "step": 61000}
{"episode": 62.0, "batch_reward": 0.5293983515799046, "critic_loss": 0.1584655929207802, "actor_loss": -46.726311622619626, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 615.9878783226013, "episode_reward": 599.2980991223043, "step": 62000}
{"episode": 63.0, "batch_reward": 0.5313457434773445, "critic_loss": 0.15579059260338546, "actor_loss": -46.92584440612793, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 31.128795862197876, "episode_reward": 636.5721001148781, "step": 63000}
{"episode": 64.0, "batch_reward": 0.5330359477996827, "critic_loss": 0.15739116787165403, "actor_loss": -46.83535551452637, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 574.8119683265686, "episode_reward": 589.0512012347136, "step": 64000}
{"episode": 65.0, "batch_reward": 0.5334272964000701, "critic_loss": 0.14454896613955498, "actor_loss": -46.919095924377444, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.448733806610107, "episode_reward": 614.4822826758311, "step": 65000}
{"episode": 66.0, "batch_reward": 0.5342005513906479, "critic_loss": 0.150160187959671, "actor_loss": -46.93075947570801, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 555.4275588989258, "episode_reward": 610.1820187160844, "step": 66000}
{"episode": 67.0, "batch_reward": 0.5361489458382129, "critic_loss": 0.14305064872652293, "actor_loss": -47.1733381729126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.913875341415405, "episode_reward": 636.6437827515007, "step": 67000}
{"episode": 68.0, "batch_reward": 0.5379286805689335, "critic_loss": 0.14551259326934815, "actor_loss": -47.14334250640869, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 548.9569964408875, "episode_reward": 646.6125946087126, "step": 68000}
{"episode": 69.0, "batch_reward": 0.5385052543878556, "critic_loss": 0.1449310237541795, "actor_loss": -47.22366815185547, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.271090507507324, "episode_reward": 601.4401247729253, "step": 69000}
{"episode": 70.0, "batch_reward": 0.5406724996566773, "critic_loss": 0.15103696355596186, "actor_loss": -47.32483135986328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 582.4955999851227, "episode_reward": 623.8507834809202, "step": 70000}
{"episode": 71.0, "batch_reward": 0.5406270492374897, "critic_loss": 0.13939050415903328, "actor_loss": -47.49029061126709, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 46.16787314414978, "episode_reward": 634.8207072220528, "step": 71000}
{"episode": 72.0, "batch_reward": 0.5419654180109501, "critic_loss": 0.1391026261597872, "actor_loss": -47.57577625274658, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 586.874148607254, "episode_reward": 607.449163110442, "step": 72000}
{"episode": 73.0, "batch_reward": 0.5424822843670845, "critic_loss": 0.12775055035948754, "actor_loss": -47.64585085296631, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.148247003555298, "episode_reward": 612.003547288669, "step": 73000}
{"episode": 74.0, "batch_reward": 0.5444795363843441, "critic_loss": 0.1468390149846673, "actor_loss": -47.99237157440186, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 587.0636858940125, "episode_reward": 651.2217211955967, "step": 74000}
{"episode": 75.0, "batch_reward": 0.546380613565445, "critic_loss": 0.13322891934216022, "actor_loss": -48.26179902648926, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.042267322540283, "episode_reward": 607.2206630879517, "step": 75000}
{"episode": 76.0, "batch_reward": 0.5467634271681309, "critic_loss": 0.13079076743125914, "actor_loss": -48.61140403747559, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 587.8311631679535, "episode_reward": 634.718875661973, "step": 76000}
{"episode": 77.0, "batch_reward": 0.5478287871479988, "critic_loss": 0.12944915864244103, "actor_loss": -48.71285698699951, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.214414834976196, "episode_reward": 636.6484258200513, "step": 77000}
{"episode": 78.0, "batch_reward": 0.5498052510619164, "critic_loss": 0.13602915206924082, "actor_loss": -49.05982855987549, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 594.9413418769836, "episode_reward": 655.9875696583837, "step": 78000}
{"episode": 79.0, "batch_reward": 0.5507115338146686, "critic_loss": 0.13863768749684097, "actor_loss": -49.10905898284912, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 32.42263603210449, "episode_reward": 658.7164878218267, "step": 79000}
{"episode": 80.0, "batch_reward": 0.551002256244421, "critic_loss": 0.14663817911222576, "actor_loss": -49.340006828308105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 549.2029285430908, "episode_reward": 633.2261049229934, "step": 80000}
{"episode": 81.0, "batch_reward": 0.5531806662082672, "critic_loss": 0.13450403140857817, "actor_loss": -49.55977478790283, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 51.833927631378174, "episode_reward": 673.0253152986429, "step": 81000}
{"episode": 82.0, "batch_reward": 0.5546063082814217, "critic_loss": 0.1404743426144123, "actor_loss": -49.49693258666992, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 519.4135613441467, "episode_reward": 663.5278365949721, "step": 82000}
{"episode": 83.0, "batch_reward": 0.5564241862595082, "critic_loss": 0.1531903288513422, "actor_loss": -49.77672576904297, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.75061058998108, "episode_reward": 700.190143050848, "step": 83000}
{"episode": 84.0, "batch_reward": 0.5565417151153088, "critic_loss": 0.1483268631398678, "actor_loss": -49.960370651245114, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 579.4477386474609, "episode_reward": 675.8148539628744, "step": 84000}
{"episode": 85.0, "batch_reward": 0.5595662004053593, "critic_loss": 0.15678325341269375, "actor_loss": -50.232458129882815, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.2877893447876, "episode_reward": 637.8976934880841, "step": 85000}
{"episode": 86.0, "batch_reward": 0.559886645257473, "critic_loss": 0.17146944697201252, "actor_loss": -50.12270520782471, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 532.0337874889374, "episode_reward": 676.1632242826361, "step": 86000}
{"episode": 87.0, "batch_reward": 0.5611046998500824, "critic_loss": 0.16172781911864878, "actor_loss": -50.27064539337158, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.038475036621094, "episode_reward": 659.4249693170057, "step": 87000}
{"episode": 88.0, "batch_reward": 0.5618598202466965, "critic_loss": 0.17298631804436446, "actor_loss": -50.20132247161865, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 530.2446732521057, "episode_reward": 638.4877620746792, "step": 88000}
{"episode": 89.0, "batch_reward": 0.5624237134456634, "critic_loss": 0.21311337654292584, "actor_loss": -50.43064754486084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.48898410797119, "episode_reward": 625.6161683150865, "step": 89000}
{"episode": 90.0, "batch_reward": 0.5640944759845734, "critic_loss": 0.2274944024384022, "actor_loss": -50.724486289978024, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 603.3820052146912, "episode_reward": 639.8258411448054, "step": 90000}
{"episode": 91.0, "batch_reward": 0.5647781474590301, "critic_loss": 0.23642251932621003, "actor_loss": -50.85178944396973, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 42.121094942092896, "episode_reward": 640.9607694051927, "step": 91000}
{"episode": 92.0, "batch_reward": 0.5650035743713379, "critic_loss": 0.3604623787403107, "actor_loss": -50.89512142181397, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 574.1259171962738, "episode_reward": 666.3592326699575, "step": 92000}
{"episode": 93.0, "batch_reward": 0.5663267631530762, "critic_loss": 0.3849524621590972, "actor_loss": -51.06242167663574, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.415764093399048, "episode_reward": 666.1657925591536, "step": 93000}
{"episode": 94.0, "batch_reward": 0.5679785388708115, "critic_loss": 0.43335159265995027, "actor_loss": -51.35776588439941, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 576.2982337474823, "episode_reward": 646.5834493951961, "step": 94000}
{"episode": 95.0, "batch_reward": 0.5681042648255825, "critic_loss": 0.5717458374127745, "actor_loss": -51.54769706726074, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.619292736053467, "episode_reward": 644.4890766227417, "step": 95000}
{"episode": 96.0, "batch_reward": 0.568895828962326, "critic_loss": 0.9039113376140594, "actor_loss": -51.994702583312986, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 508.1704640388489, "episode_reward": 664.3579764805099, "step": 96000}
{"episode": 97.0, "batch_reward": 0.5700385764837265, "critic_loss": 1.4703181083202361, "actor_loss": -52.69322858428955, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.46604561805725, "episode_reward": 650.5185828399094, "step": 97000}
{"episode": 98.0, "batch_reward": 0.5711687254309654, "critic_loss": 1.9994380611330271, "actor_loss": -53.3114916305542, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 575.7246079444885, "episode_reward": 638.6398690199256, "step": 98000}
{"episode": 99.0, "batch_reward": 0.5712008668780327, "critic_loss": 4.361035370469093, "actor_loss": -54.60737968444824, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.050079584121704, "episode_reward": 374.6452252167469, "step": 99000}
{"episode": 100.0, "batch_reward": 0.5679185719490051, "critic_loss": 6.005105658173561, "actor_loss": -56.50709801483154, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 594.927903175354, "episode_reward": 149.81627810012503, "step": 100000}
{"episode": 101.0, "batch_reward": 0.5647342960834503, "critic_loss": 7.829115188241005, "actor_loss": -60.867000411987306, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 43.8852002620697, "episode_reward": 283.44470485057195, "step": 101000}
{"episode": 102.0, "batch_reward": 0.5591107333898544, "critic_loss": 10.880584974050523, "actor_loss": -67.46164222717285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 558.5769283771515, "episode_reward": 21.21437026854209, "step": 102000}
{"episode": 103.0, "batch_reward": 0.5544757886230945, "critic_loss": 17.22011818599701, "actor_loss": -76.88492024230958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.48755192756653, "episode_reward": 128.64278762888765, "step": 103000}
{"episode": 104.0, "batch_reward": 0.5505924726128578, "critic_loss": 19.49516472387314, "actor_loss": -85.95233128356934, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 546.9014375209808, "episode_reward": 46.17559925030479, "step": 104000}
{"episode": 105.0, "batch_reward": 0.5472257888317108, "critic_loss": 17.68257608127594, "actor_loss": -93.27910073852539, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.56529188156128, "episode_reward": 95.79846507446526, "step": 105000}
{"episode": 106.0, "batch_reward": 0.54195204859972, "critic_loss": 16.333918938159943, "actor_loss": -99.72310400390624, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 597.8075802326202, "episode_reward": 34.262196323566464, "step": 106000}
{"episode": 107.0, "batch_reward": 0.536654856711626, "critic_loss": 15.947231706619263, "actor_loss": -104.80879974365234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.41385793685913, "episode_reward": 78.56620509030932, "step": 107000}
{"episode": 108.0, "batch_reward": 0.5318690043985843, "critic_loss": 16.470878688812256, "actor_loss": -108.40095631408691, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 546.5437016487122, "episode_reward": 18.61346219527368, "step": 108000}
{"episode": 109.0, "batch_reward": 0.5271806306242943, "critic_loss": 14.388223032951355, "actor_loss": -110.551064453125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.536980152130127, "episode_reward": 178.4264533884818, "step": 109000}
{"episode": 110.0, "batch_reward": 0.5254748793840408, "critic_loss": 12.696878165721893, "actor_loss": -113.03598568725586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 577.7024974822998, "episode_reward": 54.840688423141195, "step": 110000}
{"episode": 111.0, "batch_reward": 0.5199829971194267, "critic_loss": 12.018835896492005, "actor_loss": -115.15969036865235, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 48.365333795547485, "episode_reward": 11.092237747030845, "step": 111000}
{"episode": 112.0, "batch_reward": 0.5169870466589928, "critic_loss": 10.251782493591309, "actor_loss": -118.36750691223145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 590.8097639083862, "episode_reward": 205.10597183313163, "step": 112000}
{"episode": 113.0, "batch_reward": 0.5126662231087684, "critic_loss": 8.364058778524399, "actor_loss": -120.55739389038087, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.785034894943237, "episode_reward": 82.40819024813555, "step": 113000}
{"episode": 114.0, "batch_reward": 0.5088458853960037, "critic_loss": 6.62106555891037, "actor_loss": -121.34298768615723, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 525.6587784290314, "episode_reward": 48.461542298115084, "step": 114000}
{"episode": 115.0, "batch_reward": 0.5067046190202236, "critic_loss": 5.449827162504196, "actor_loss": -120.46815213012695, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.60219693183899, "episode_reward": 65.00172178822235, "step": 115000}
{"episode": 116.0, "batch_reward": 0.5033510449826717, "critic_loss": 4.901287140607834, "actor_loss": -118.60003414916993, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 555.1374821662903, "episode_reward": 350.363014839316, "step": 116000}
{"episode": 117.0, "batch_reward": 0.5002536642551422, "critic_loss": 4.284377986431122, "actor_loss": -117.16342288208008, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.681692838668823, "episode_reward": 244.36518516963343, "step": 117000}
{"episode": 118.0, "batch_reward": 0.4992869079709053, "critic_loss": 3.844258723497391, "actor_loss": -115.91299449157715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 613.3671679496765, "episode_reward": 389.6224483606786, "step": 118000}
{"episode": 119.0, "batch_reward": 0.49834397026896476, "critic_loss": 3.4762639005184175, "actor_loss": -114.6990230255127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.686286211013794, "episode_reward": 256.03693920157826, "step": 119000}
{"episode": 120.0, "batch_reward": 0.49642314836382867, "critic_loss": 3.0036536020040514, "actor_loss": -113.28304751586914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 553.6403684616089, "episode_reward": 62.7702432815538, "step": 120000}
{"episode": 121.0, "batch_reward": 0.4928107586801052, "critic_loss": 2.646918829679489, "actor_loss": -111.48464212036133, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 46.40873169898987, "episode_reward": 90.15143507366109, "step": 121000}
{"episode": 122.0, "batch_reward": 0.48977024337649344, "critic_loss": 2.288456929922104, "actor_loss": -109.62675495910645, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 578.5335772037506, "episode_reward": 158.79259495876923, "step": 122000}
{"episode": 123.0, "batch_reward": 0.4868501463830471, "critic_loss": 2.0138109243512154, "actor_loss": -107.36747750854492, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.47838854789734, "episode_reward": 112.52133575265852, "step": 123000}
{"episode": 124.0, "batch_reward": 0.48375954109430314, "critic_loss": 1.8192951615452766, "actor_loss": -104.99318907165528, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 561.4786279201508, "episode_reward": 201.67444387249395, "step": 124000}
{"episode": 125.0, "batch_reward": 0.4818806233108044, "critic_loss": 1.533371069788933, "actor_loss": -103.19292323303223, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.715079069137573, "episode_reward": 476.91069040078514, "step": 125000}
{"episode": 126.0, "batch_reward": 0.47990363436937333, "critic_loss": 1.5175055302381515, "actor_loss": -101.10837670898438, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 585.3415620326996, "episode_reward": 14.436434734030724, "step": 126000}
{"episode": 127.0, "batch_reward": 0.4763192980289459, "critic_loss": 1.426117026090622, "actor_loss": -98.96795307922363, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.824392795562744, "episode_reward": 15.18526008230104, "step": 127000}
{"episode": 128.0, "batch_reward": 0.47420928794145584, "critic_loss": 1.3813010242581367, "actor_loss": -97.25736791992188, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 571.5797219276428, "episode_reward": 538.9990769782505, "step": 128000}
{"episode": 129.0, "batch_reward": 0.4747521109879017, "critic_loss": 1.3105878846645356, "actor_loss": -95.73957545471191, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.886168718338013, "episode_reward": 383.0336437390758, "step": 129000}
{"episode": 130.0, "batch_reward": 0.4734029353260994, "critic_loss": 1.199486996471882, "actor_loss": -93.84564677429199, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 565.9428815841675, "episode_reward": 466.3790179977471, "step": 130000}
{"episode": 131.0, "batch_reward": 0.47344747620821, "critic_loss": 1.1573732907772065, "actor_loss": -92.21795469665527, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.07494497299194, "episode_reward": 153.4933233277738, "step": 131000}
{"episode": 132.0, "batch_reward": 0.47177355566620827, "critic_loss": 1.0296133944392205, "actor_loss": -90.59791024780273, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 586.3028738498688, "episode_reward": 540.818255590541, "step": 132000}
{"episode": 133.0, "batch_reward": 0.4712402611076832, "critic_loss": 1.0567724336385727, "actor_loss": -89.08444401550292, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.259177923202515, "episode_reward": 193.95721200702218, "step": 133000}
{"episode": 134.0, "batch_reward": 0.47059733697772027, "critic_loss": 0.9703158259987831, "actor_loss": -87.4538384399414, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 570.6398158073425, "episode_reward": 605.3546119895253, "step": 134000}
{"episode": 135.0, "batch_reward": 0.4712028661072254, "critic_loss": 0.9969935808181762, "actor_loss": -86.23766316223144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 32.20024132728577, "episode_reward": 517.6074719812094, "step": 135000}
{"episode": 136.0, "batch_reward": 0.4713980330228806, "critic_loss": 1.0453724583983421, "actor_loss": -84.76906271362304, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 608.0813875198364, "episode_reward": 514.3887800621196, "step": 136000}
{"episode": 137.0, "batch_reward": 0.4718098274767399, "critic_loss": 0.9514351801276207, "actor_loss": -83.40711882019043, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.873263597488403, "episode_reward": 560.606172625547, "step": 137000}
{"episode": 138.0, "batch_reward": 0.47311649003624917, "critic_loss": 0.9081928882300854, "actor_loss": -82.38246447753906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 546.2284619808197, "episode_reward": 555.5540326778502, "step": 138000}
{"episode": 139.0, "batch_reward": 0.4734317187666893, "critic_loss": 0.8539499005377292, "actor_loss": -81.18772241210938, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.146266222000122, "episode_reward": 610.6527672357888, "step": 139000}
{"episode": 140.0, "batch_reward": 0.47424633845686914, "critic_loss": 0.8264301817417145, "actor_loss": -79.97842280578614, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 587.2121629714966, "episode_reward": 655.7379241000988, "step": 140000}
{"episode": 141.0, "batch_reward": 0.47546212521195413, "critic_loss": 0.7908167649805545, "actor_loss": -79.1039236755371, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 48.039934158325195, "episode_reward": 626.0155875259568, "step": 141000}
{"episode": 142.0, "batch_reward": 0.4766628175675869, "critic_loss": 0.7816459637582303, "actor_loss": -78.00686645507812, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 594.0464522838593, "episode_reward": 379.3501186760526, "step": 142000}
{"episode": 143.0, "batch_reward": 0.47620808136463166, "critic_loss": 0.7979771037399769, "actor_loss": -76.8587825012207, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.304314851760864, "episode_reward": 629.7009900203515, "step": 143000}
{"episode": 144.0, "batch_reward": 0.4757708442211151, "critic_loss": 0.7624671712815762, "actor_loss": -75.87087156677246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 610.4488008022308, "episode_reward": 625.7126220046293, "step": 144000}
{"episode": 145.0, "batch_reward": 0.47764973214268686, "critic_loss": 0.7201758054494858, "actor_loss": -74.9825569152832, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.657339811325073, "episode_reward": 580.1890344932017, "step": 145000}
{"episode": 146.0, "batch_reward": 0.47899108120799067, "critic_loss": 0.7261105066537857, "actor_loss": -74.1809308013916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 593.128915309906, "episode_reward": 583.8482766735904, "step": 146000}
{"episode": 147.0, "batch_reward": 0.4799014023542404, "critic_loss": 0.6992090166807174, "actor_loss": -73.25608815002441, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.74247646331787, "episode_reward": 340.32958908261236, "step": 147000}
{"episode": 148.0, "batch_reward": 0.47996495449543, "critic_loss": 0.6521743090748787, "actor_loss": -72.45224526977539, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 596.7133505344391, "episode_reward": 544.6710543942409, "step": 148000}
{"episode": 149.0, "batch_reward": 0.4793154398202896, "critic_loss": 0.6667525244951248, "actor_loss": -71.5641493988037, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.22807216644287, "episode_reward": 557.5533063736644, "step": 149000}
{"episode": 150.0, "batch_reward": 0.4801332304477692, "critic_loss": 0.6447330947518348, "actor_loss": -70.80031919860839, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
