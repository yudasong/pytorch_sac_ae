{"episode_reward": 0.0, "episode": 1.0, "duration": 17.17413902282715, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.5508530139923096, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2849136364384467, "critic_loss": 0.03754345757673113, "actor_loss": -34.91353371023473, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 62.2466766834259, "step": 3000}
{"episode_reward": 76.14284697687138, "episode": 4.0, "batch_reward": 0.2072320146560669, "critic_loss": 0.09249308462068438, "actor_loss": -23.908856391489504, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.04899501800537, "step": 4000}
{"episode_reward": 65.52526346054002, "episode": 5.0, "batch_reward": 0.17261771747469903, "critic_loss": 0.08492235501110554, "actor_loss": -19.406240547060968, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.78490424156189, "step": 5000}
{"episode_reward": 104.59298852700313, "episode": 6.0, "batch_reward": 0.15460083258152008, "critic_loss": 0.07542833941429854, "actor_loss": -21.499124916523694, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.126794576644897, "step": 6000}
{"episode_reward": 47.82460982033857, "episode": 7.0, "batch_reward": 0.13845607601106166, "critic_loss": 0.0794905529730022, "actor_loss": -23.63191503481567, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.976062059402466, "step": 7000}
{"episode_reward": 46.37725377655098, "episode": 8.0, "batch_reward": 0.12937762761116028, "critic_loss": 0.08198590956255794, "actor_loss": -21.786369267985226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.654895782470703, "step": 8000}
{"episode_reward": 54.16728440094402, "episode": 9.0, "batch_reward": 0.11899331652373075, "critic_loss": 0.079265949010849, "actor_loss": -21.824937617436053, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.527796745300293, "step": 9000}
{"episode_reward": 78.10972803311024, "episode": 10.0, "batch_reward": 0.11342307670414448, "critic_loss": 0.08006975055113434, "actor_loss": -22.235797428026796, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.837186813354492, "step": 10000}
{"episode_reward": 18.24138322908339, "episode": 11.0, "batch_reward": 0.10466494461148977, "critic_loss": 0.08425722679495812, "actor_loss": -23.017207279384134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.002458333969116, "step": 11000}
{"episode_reward": 25.53928741314884, "episode": 12.0, "batch_reward": 0.0970914874188602, "critic_loss": 0.08648739900439978, "actor_loss": -22.102774374440312, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.023866176605225, "step": 12000}
{"episode_reward": 7.338156119328259, "episode": 13.0, "batch_reward": 0.09147789399325848, "critic_loss": 0.08385250575467944, "actor_loss": -22.23348353010416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.826601266860962, "step": 13000}
{"episode_reward": 39.75653905504988, "episode": 14.0, "batch_reward": 0.0868339504301548, "critic_loss": 0.09261511265486479, "actor_loss": -20.593345570102333, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.88069176673889, "step": 14000}
{"episode_reward": 39.99119837929068, "episode": 15.0, "batch_reward": 0.0862789118848741, "critic_loss": 0.11357332626730203, "actor_loss": -23.86508520567417, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93331003189087, "step": 15000}
{"episode_reward": 122.26311146129922, "episode": 16.0, "batch_reward": 0.08695713629201055, "critic_loss": 0.13044032522290944, "actor_loss": -22.862618361577393, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.649889707565308, "step": 16000}
{"episode_reward": 63.80709340621945, "episode": 17.0, "batch_reward": 0.0859865418151021, "critic_loss": 0.1441652147769928, "actor_loss": -21.94514866273105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.851197481155396, "step": 17000}
{"episode_reward": 70.94909395067545, "episode": 18.0, "batch_reward": 0.08704570595547557, "critic_loss": 0.1808360545784235, "actor_loss": -22.55722652579844, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.145597457885742, "step": 18000}
{"episode_reward": 146.8156852022422, "episode": 19.0, "batch_reward": 0.09067857337370515, "critic_loss": 0.18410302110016347, "actor_loss": -22.736541655033825, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.226006269454956, "step": 19000}
{"episode_reward": 173.4696943376272, "episode": 20.0, "batch_reward": 0.09461697616428137, "critic_loss": 0.19961630156636237, "actor_loss": -24.063892695695163, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.990968465805054, "step": 20000}
{"episode_reward": 174.94873047943628, "episode": 21.0, "batch_reward": 0.09979333581030368, "critic_loss": 0.22701604624092578, "actor_loss": -24.653244450479747, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.429327726364136, "step": 21000}
{"episode_reward": 170.09660024711405, "episode": 22.0, "batch_reward": 0.10254237299412489, "critic_loss": 0.25249272721260785, "actor_loss": -24.29968284893036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.067126989364624, "step": 22000}
{"episode_reward": 172.7961322477982, "episode": 23.0, "batch_reward": 0.10570999322086573, "critic_loss": 0.26340053623914716, "actor_loss": -25.168971355557442, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.98394536972046, "step": 23000}
{"episode_reward": 112.28023549408904, "episode": 24.0, "batch_reward": 0.10598665709048509, "critic_loss": 0.2888641070872545, "actor_loss": -24.994300169348715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.57273507118225, "step": 24000}
{"episode_reward": 203.3069970421647, "episode": 25.0, "batch_reward": 0.1099032863676548, "critic_loss": 0.3075840901434422, "actor_loss": -24.222803715467453, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.562195301055908, "step": 25000}
{"episode_reward": 158.80582535390664, "episode": 26.0, "batch_reward": 0.11219892440736294, "critic_loss": 0.2906725143045187, "actor_loss": -24.864818915843962, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.648369312286377, "step": 26000}
{"episode_reward": 206.5212920254224, "episode": 27.0, "batch_reward": 0.11437620634585619, "critic_loss": 0.3088343440741301, "actor_loss": -25.14745655441284, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.784006595611572, "step": 27000}
{"episode_reward": 82.92393546846311, "episode": 28.0, "batch_reward": 0.11562996616959571, "critic_loss": 0.34034478659927847, "actor_loss": -24.487375875473024, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.249107599258423, "step": 28000}
{"episode_reward": 269.1522987928952, "episode": 29.0, "batch_reward": 0.12253341912478209, "critic_loss": 0.3265430803447962, "actor_loss": -25.773859792709352, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88628077507019, "step": 29000}
{"episode_reward": 255.40226391797427, "episode": 30.0, "batch_reward": 0.12555985478311776, "critic_loss": 0.3440650244504213, "actor_loss": -25.383650164604187, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.00967764854431, "step": 30000}
{"episode_reward": 196.56266421657702, "episode": 31.0, "batch_reward": 0.12553258796036243, "critic_loss": 0.3357845182269812, "actor_loss": -26.15066937446594, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.280237913131714, "step": 31000}
{"episode_reward": 49.41444457260316, "episode": 32.0, "batch_reward": 0.12577300007641315, "critic_loss": 0.31856639601290226, "actor_loss": -25.30410716342926, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.18901491165161, "step": 32000}
{"episode_reward": 234.5511058739105, "episode": 33.0, "batch_reward": 0.12797026050835847, "critic_loss": 0.32345391991734507, "actor_loss": -26.43898055934906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.656697988510132, "step": 33000}
{"episode_reward": 100.91389990174203, "episode": 34.0, "batch_reward": 0.12835239184647798, "critic_loss": 0.2922707844078541, "actor_loss": -25.19274859046936, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.062148571014404, "step": 34000}
{"episode_reward": 313.94928154369677, "episode": 35.0, "batch_reward": 0.1325897022113204, "critic_loss": 0.3136334624290466, "actor_loss": -26.273188813209533, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.4752197265625, "step": 35000}
{"episode_reward": 107.7076150922657, "episode": 36.0, "batch_reward": 0.13108529037982225, "critic_loss": 0.3100163409560919, "actor_loss": -24.91009352684021, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.985573291778564, "step": 36000}
{"episode_reward": 219.24451009327305, "episode": 37.0, "batch_reward": 0.13287132389098405, "critic_loss": 0.3202738352417946, "actor_loss": -25.71340626525879, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.158725023269653, "step": 37000}
{"episode_reward": 79.53980972911377, "episode": 38.0, "batch_reward": 0.13247291802614927, "critic_loss": 0.3487313138097525, "actor_loss": -25.8312806558609, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.038862466812134, "step": 38000}
{"episode_reward": 104.62421366238924, "episode": 39.0, "batch_reward": 0.1322576388567686, "critic_loss": 0.3798852038681507, "actor_loss": -25.913339413642884, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.321240663528442, "step": 39000}
{"episode_reward": 239.337148504733, "episode": 40.0, "batch_reward": 0.1351531501710415, "critic_loss": 0.38762299621105195, "actor_loss": -26.321297263145446, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.74428939819336, "step": 40000}
{"episode_reward": 210.73433625413247, "episode": 41.0, "batch_reward": 0.13755601546913385, "critic_loss": 0.38197095815837384, "actor_loss": -26.40259028530121, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.332783937454224, "step": 41000}
{"episode_reward": 278.8952047730309, "episode": 42.0, "batch_reward": 0.1408523914963007, "critic_loss": 0.42158982588350774, "actor_loss": -26.014540731430053, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.995307683944702, "step": 42000}
{"episode_reward": 308.91372581845775, "episode": 43.0, "batch_reward": 0.1456445933431387, "critic_loss": 0.4683220886439085, "actor_loss": -26.44148433303833, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.931426286697388, "step": 43000}
{"episode_reward": 344.45778596641907, "episode": 44.0, "batch_reward": 0.14881001720577477, "critic_loss": 0.41420589266717434, "actor_loss": -26.471185138702392, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.986525297164917, "step": 44000}
{"episode_reward": 296.8699541124132, "episode": 45.0, "batch_reward": 0.1527692347690463, "critic_loss": 0.43945585304498674, "actor_loss": -27.522312505722045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.66822123527527, "step": 45000}
{"episode_reward": 288.92789356856093, "episode": 46.0, "batch_reward": 0.155763738617301, "critic_loss": 0.489531246855855, "actor_loss": -27.380761875152587, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.50054168701172, "step": 46000}
{"episode_reward": 311.95491112685625, "episode": 47.0, "batch_reward": 0.16015749728679657, "critic_loss": 0.4907681959122419, "actor_loss": -28.14728747177124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.561408519744873, "step": 47000}
{"episode_reward": 332.8684145470352, "episode": 48.0, "batch_reward": 0.16229928403347732, "critic_loss": 0.5038138942420483, "actor_loss": -27.426829624176026, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.74020481109619, "step": 48000}
{"episode_reward": 297.0440015052908, "episode": 49.0, "batch_reward": 0.16730757430195808, "critic_loss": 0.5405597345530987, "actor_loss": -28.89316698074341, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.037923097610474, "step": 49000}
{"episode_reward": 389.76949529913225, "episode": 50.0, "batch_reward": 0.16964707911014557, "critic_loss": 0.5179441510438919, "actor_loss": -29.208592657089234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.755282640457153, "step": 50000}
{"episode_reward": 288.99187206493775, "episode": 51.0, "batch_reward": 0.17230094067007304, "critic_loss": 0.5088349482268095, "actor_loss": -29.366360904693604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.60097289085388, "step": 51000}
{"episode_reward": 324.0721830813681, "episode": 52.0, "batch_reward": 0.1762808641344309, "critic_loss": 0.5205666603595018, "actor_loss": -29.69707155609131, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.697219133377075, "step": 52000}
{"episode_reward": 393.2449393197391, "episode": 53.0, "batch_reward": 0.17924100865423678, "critic_loss": 0.5287311677783728, "actor_loss": -29.60293832397461, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.64095425605774, "step": 53000}
{"episode_reward": 116.63268077845326, "episode": 54.0, "batch_reward": 0.1784118387401104, "critic_loss": 0.4943890207409859, "actor_loss": -29.62864570236206, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.453295707702637, "step": 54000}
{"episode_reward": 312.6566585071789, "episode": 55.0, "batch_reward": 0.18064027282595635, "critic_loss": 0.4988574270606041, "actor_loss": -29.770963485717772, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.69698977470398, "step": 55000}
{"episode_reward": 142.17261425920074, "episode": 56.0, "batch_reward": 0.18007403464615346, "critic_loss": 0.5544591754078865, "actor_loss": -29.90185898399353, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.918959379196167, "step": 56000}
{"episode_reward": 252.5361928807914, "episode": 57.0, "batch_reward": 0.18289141553640365, "critic_loss": 0.5532315924465656, "actor_loss": -29.66465652656555, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.36246371269226, "step": 57000}
{"episode_reward": 314.53288067067376, "episode": 58.0, "batch_reward": 0.18357609839737415, "critic_loss": 0.564826771080494, "actor_loss": -29.289362998962403, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.656246662139893, "step": 58000}
{"episode_reward": 79.35245406508277, "episode": 59.0, "batch_reward": 0.18087551929056644, "critic_loss": 0.5565792512148618, "actor_loss": -28.64173800086975, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.024474382400513, "step": 59000}
{"episode_reward": 124.54043065913115, "episode": 60.0, "batch_reward": 0.18090398405492306, "critic_loss": 0.568965241998434, "actor_loss": -29.208642517089842, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.726468086242676, "step": 60000}
{"episode_reward": 184.70982886169668, "episode": 61.0, "batch_reward": 0.1821882249414921, "critic_loss": 0.532083202213049, "actor_loss": -28.91880860900879, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.19284915924072, "step": 61000}
{"episode_reward": 422.3981824785596, "episode": 62.0, "batch_reward": 0.1857521372437477, "critic_loss": 0.566477750852704, "actor_loss": -29.631511501312257, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.24366068840027, "step": 62000}
{"episode_reward": 268.7093017544771, "episode": 63.0, "batch_reward": 0.18514742486178876, "critic_loss": 0.5529070988893509, "actor_loss": -28.93151813316345, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.04451012611389, "step": 63000}
{"episode_reward": 139.14176514749875, "episode": 64.0, "batch_reward": 0.1858112648278475, "critic_loss": 0.5058645423203707, "actor_loss": -29.289139463424682, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.129162311553955, "step": 64000}
{"episode_reward": 406.8866860191373, "episode": 65.0, "batch_reward": 0.19020530362427235, "critic_loss": 0.5463177997022867, "actor_loss": -29.539314474105836, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.70384693145752, "step": 65000}
{"episode_reward": 439.7177364029614, "episode": 66.0, "batch_reward": 0.1936550970375538, "critic_loss": 0.5388729593008756, "actor_loss": -29.814123929977416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.929680824279785, "step": 66000}
{"episode_reward": 318.66284207641314, "episode": 67.0, "batch_reward": 0.19427465122938156, "critic_loss": 0.5352095782458782, "actor_loss": -30.029199953079225, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.020453453063965, "step": 67000}
{"episode_reward": 252.85350907581056, "episode": 68.0, "batch_reward": 0.1954121851325035, "critic_loss": 0.5363458475619555, "actor_loss": -29.316566829681395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.670925617218018, "step": 68000}
{"episode_reward": 201.13371512346305, "episode": 69.0, "batch_reward": 0.19529087971150874, "critic_loss": 0.5261502565592527, "actor_loss": -29.233367023468016, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.275193691253662, "step": 69000}
{"episode_reward": 321.5577633131915, "episode": 70.0, "batch_reward": 0.1971158299446106, "critic_loss": 0.5517227031886578, "actor_loss": -30.16727332687378, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.02945327758789, "step": 70000}
{"episode_reward": 175.2486367432859, "episode": 71.0, "batch_reward": 0.1979181557148695, "critic_loss": 0.5488756559491158, "actor_loss": -29.905817390441893, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.97311735153198, "step": 71000}
{"episode_reward": 447.93630187727547, "episode": 72.0, "batch_reward": 0.20148495003581046, "critic_loss": 0.5740316874086857, "actor_loss": -29.99445845603943, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.05922293663025, "step": 72000}
{"episode_reward": 286.2482055972637, "episode": 73.0, "batch_reward": 0.20248154333233834, "critic_loss": 0.5563024570941925, "actor_loss": -30.12218553352356, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.06611680984497, "step": 73000}
{"episode_reward": 266.20724596794327, "episode": 74.0, "batch_reward": 0.20309049715101718, "critic_loss": 0.539906966522336, "actor_loss": -30.247765556335448, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.233898401260376, "step": 74000}
{"episode_reward": 96.38370830125253, "episode": 75.0, "batch_reward": 0.20260613086819648, "critic_loss": 0.5520458480715752, "actor_loss": -30.242817247390747, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.991421937942505, "step": 75000}
{"episode_reward": 483.90226297228554, "episode": 76.0, "batch_reward": 0.20579029209911823, "critic_loss": 0.5082817083746195, "actor_loss": -30.54620869255066, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.67912483215332, "step": 76000}
{"episode_reward": 437.3522548341927, "episode": 77.0, "batch_reward": 0.20833427788317205, "critic_loss": 0.5137916328310966, "actor_loss": -30.151541259765626, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.195311069488525, "step": 77000}
{"episode_reward": 235.07261438769265, "episode": 78.0, "batch_reward": 0.20872232477366925, "critic_loss": 0.5157945459187031, "actor_loss": -30.44116054725647, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.985161066055298, "step": 78000}
{"episode_reward": 221.6746990380215, "episode": 79.0, "batch_reward": 0.20744318558275698, "critic_loss": 0.460063723936677, "actor_loss": -29.507528408050536, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.73474431037903, "step": 79000}
{"episode_reward": 91.64567777392821, "episode": 80.0, "batch_reward": 0.20794087255001067, "critic_loss": 0.4708802631646395, "actor_loss": -29.91991135406494, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92463970184326, "step": 80000}
{"episode_reward": 405.6272652119186, "episode": 81.0, "batch_reward": 0.21062223456799983, "critic_loss": 0.46964719860255716, "actor_loss": -30.20701832962036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.78255486488342, "step": 81000}
{"episode_reward": 446.5580012947363, "episode": 82.0, "batch_reward": 0.2129501922428608, "critic_loss": 0.5341405510604381, "actor_loss": -30.886880702972412, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.39307713508606, "step": 82000}
{"episode_reward": 313.96225291252773, "episode": 83.0, "batch_reward": 0.2129008795171976, "critic_loss": 0.5160805355906487, "actor_loss": -29.76384563446045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.080472469329834, "step": 83000}
{"episode_reward": 98.11574435512605, "episode": 84.0, "batch_reward": 0.2123907894641161, "critic_loss": 0.511695135012269, "actor_loss": -30.324361511230467, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.0009708404541, "step": 84000}
{"episode_reward": 399.22455471556924, "episode": 85.0, "batch_reward": 0.21483619178831578, "critic_loss": 0.48841241148114206, "actor_loss": -30.42292592048645, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.766891717910767, "step": 85000}
{"episode_reward": 454.4827435432279, "episode": 86.0, "batch_reward": 0.21783724822103978, "critic_loss": 0.4790543697327375, "actor_loss": -30.4619547290802, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.562689065933228, "step": 86000}
{"episode_reward": 448.77377696179065, "episode": 87.0, "batch_reward": 0.22078141368925572, "critic_loss": 0.4831456023454666, "actor_loss": -30.606930049896242, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.676090002059937, "step": 87000}
{"episode_reward": 445.07961277450875, "episode": 88.0, "batch_reward": 0.22165281073749066, "critic_loss": 0.4434844352006912, "actor_loss": -30.145885915756224, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.324817419052124, "step": 88000}
{"episode_reward": 96.54102377150517, "episode": 89.0, "batch_reward": 0.2219318803101778, "critic_loss": 0.45282201915979386, "actor_loss": -30.945632061004638, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.83626413345337, "step": 89000}
{"episode_reward": 514.5081466887025, "episode": 90.0, "batch_reward": 0.22507904134690762, "critic_loss": 0.4671461637020111, "actor_loss": -31.61960094833374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.616548776626587, "step": 90000}
{"episode_reward": 440.25931301618357, "episode": 91.0, "batch_reward": 0.2258144392669201, "critic_loss": 0.45439415661990645, "actor_loss": -30.882052600860597, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.4523389339447, "step": 91000}
{"episode_reward": 107.66276516822766, "episode": 92.0, "batch_reward": 0.2260449632704258, "critic_loss": 0.4157209888696671, "actor_loss": -30.594432920455933, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.65479612350464, "step": 92000}
{"episode_reward": 445.19827512159014, "episode": 93.0, "batch_reward": 0.22849248006939887, "critic_loss": 0.4388023980259895, "actor_loss": -30.854306631088257, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.469377994537354, "step": 93000}
{"episode_reward": 468.4694615261512, "episode": 94.0, "batch_reward": 0.23136404359340668, "critic_loss": 0.4357821121811867, "actor_loss": -31.1435015335083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.83596920967102, "step": 94000}
{"episode_reward": 471.74110710681117, "episode": 95.0, "batch_reward": 0.2342914754152298, "critic_loss": 0.4187605213820934, "actor_loss": -32.108563819885255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95601987838745, "step": 95000}
{"episode_reward": 526.0740737078174, "episode": 96.0, "batch_reward": 0.23705240043997763, "critic_loss": 0.42993618981540205, "actor_loss": -32.20051285552979, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.689671754837036, "step": 96000}
{"episode_reward": 400.9452941383512, "episode": 97.0, "batch_reward": 0.23885834042727946, "critic_loss": 0.42314061902463435, "actor_loss": -32.50331938552856, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.766912698745728, "step": 97000}
{"episode_reward": 559.3263749041781, "episode": 98.0, "batch_reward": 0.2424480678588152, "critic_loss": 0.4120130871832371, "actor_loss": -31.862287616729738, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9841365814209, "step": 98000}
{"episode_reward": 498.4624250434446, "episode": 99.0, "batch_reward": 0.24250585417449474, "critic_loss": 0.412260445356369, "actor_loss": -31.92509875869751, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.36155605316162, "step": 99000}
{"episode_reward": 23.411108844723852, "episode": 100.0, "batch_reward": 0.24352947430312633, "critic_loss": 0.39378074237704275, "actor_loss": -32.131239521026615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.379384756088257, "step": 100000}
{"episode_reward": 453.7582738691086, "episode": 101.0, "batch_reward": 0.24259882047772408, "critic_loss": 0.47197496111691, "actor_loss": -32.21201585006714, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.59553527832031, "step": 101000}
{"episode_reward": 100.71330293241425, "episode": 102.0, "batch_reward": 0.24187600745260715, "critic_loss": 0.39497576528787615, "actor_loss": -32.02884841918945, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.628451347351074, "step": 102000}
{"episode_reward": 247.25154154310803, "episode": 103.0, "batch_reward": 0.24224853846430777, "critic_loss": 0.4348338174968958, "actor_loss": -31.87688066101074, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.66899275779724, "step": 103000}
{"episode_reward": 448.0753032024489, "episode": 104.0, "batch_reward": 0.24578692199289798, "critic_loss": 0.4230165755301714, "actor_loss": -32.05598451995849, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.779250383377075, "step": 104000}
{"episode_reward": 520.4758862990664, "episode": 105.0, "batch_reward": 0.24809167528152465, "critic_loss": 0.43282825614511966, "actor_loss": -32.31297039794922, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.286911725997925, "step": 105000}
{"episode_reward": 507.5172969619636, "episode": 106.0, "batch_reward": 0.25046012352406977, "critic_loss": 0.4404436777532101, "actor_loss": -32.21363882446289, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.908462524414062, "step": 106000}
{"episode_reward": 507.66077767860423, "episode": 107.0, "batch_reward": 0.2522228662520647, "critic_loss": 0.42309738107025624, "actor_loss": -32.706866237640384, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.060033082962036, "step": 107000}
{"episode_reward": 241.97421060147587, "episode": 108.0, "batch_reward": 0.25229978694021704, "critic_loss": 0.45927173835039137, "actor_loss": -32.50683875274658, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.450246572494507, "step": 108000}
{"episode_reward": 483.8723322579568, "episode": 109.0, "batch_reward": 0.25419373451173305, "critic_loss": 0.4707789001762867, "actor_loss": -33.055969039916995, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.04276728630066, "step": 109000}
{"episode_reward": 456.820130283256, "episode": 110.0, "batch_reward": 0.25597251902520657, "critic_loss": 0.4423407852500677, "actor_loss": -32.85780963897705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.077184438705444, "step": 110000}
{"episode_reward": 505.0243920643283, "episode": 111.0, "batch_reward": 0.2584192885756493, "critic_loss": 0.4456278232634068, "actor_loss": -33.70421529769897, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.97686147689819, "step": 111000}
{"episode_reward": 443.7312065023149, "episode": 112.0, "batch_reward": 0.26059977596998213, "critic_loss": 0.4462865252494812, "actor_loss": -33.24482075881958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.09023642539978, "step": 112000}
{"episode_reward": 484.7443587295289, "episode": 113.0, "batch_reward": 0.26261969546973707, "critic_loss": 0.4478991977572441, "actor_loss": -33.52683723449707, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.61840558052063, "step": 113000}
{"episode_reward": 455.1316327404694, "episode": 114.0, "batch_reward": 0.26374226926267147, "critic_loss": 0.45323461258411407, "actor_loss": -33.958757793426514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97152876853943, "step": 114000}
{"episode_reward": 462.45083895580865, "episode": 115.0, "batch_reward": 0.2663701632916927, "critic_loss": 0.4495756255090237, "actor_loss": -33.82885264968872, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.73030138015747, "step": 115000}
{"episode_reward": 515.7415377337803, "episode": 116.0, "batch_reward": 0.2681020052433014, "critic_loss": 0.4419624629765749, "actor_loss": -33.99720171356201, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.678975105285645, "step": 116000}
{"episode_reward": 516.0207333871401, "episode": 117.0, "batch_reward": 0.26926699535548687, "critic_loss": 0.4914265302121639, "actor_loss": -33.963629039764406, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.952887773513794, "step": 117000}
{"episode_reward": 195.16226076276283, "episode": 118.0, "batch_reward": 0.2695576663017273, "critic_loss": 0.44576633191108705, "actor_loss": -34.17452561187744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.552613258361816, "step": 118000}
{"episode_reward": 572.5395577998925, "episode": 119.0, "batch_reward": 0.2726362087279558, "critic_loss": 0.4880374854654074, "actor_loss": -34.62496284866333, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.673197746276855, "step": 119000}
{"episode_reward": 496.2837844737762, "episode": 120.0, "batch_reward": 0.2728388216197491, "critic_loss": 0.4824674705564976, "actor_loss": -34.008538082122804, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.119725942611694, "step": 120000}
{"episode_reward": 526.9082221903222, "episode": 121.0, "batch_reward": 0.2763858210295439, "critic_loss": 0.48932824194431307, "actor_loss": -34.402332736968994, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.54878520965576, "step": 121000}
{"episode_reward": 237.13113435537758, "episode": 122.0, "batch_reward": 0.2756790490746498, "critic_loss": 0.4710005577802658, "actor_loss": -34.40984056472778, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.95034670829773, "step": 122000}
{"episode_reward": 475.6411496310487, "episode": 123.0, "batch_reward": 0.27771950626373293, "critic_loss": 0.4663011135160923, "actor_loss": -33.633693893432614, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.26858925819397, "step": 123000}
{"episode_reward": 523.7119717002781, "episode": 124.0, "batch_reward": 0.2790170719921589, "critic_loss": 0.4998406132757664, "actor_loss": -34.661731857299806, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.10546326637268, "step": 124000}
{"episode_reward": 349.0115848324532, "episode": 125.0, "batch_reward": 0.2803280524611473, "critic_loss": 0.5012656390219927, "actor_loss": -34.48312411499023, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.12248396873474, "step": 125000}
{"episode_reward": 554.6769489540148, "episode": 126.0, "batch_reward": 0.28255153766274455, "critic_loss": 0.4959144757091999, "actor_loss": -34.975711109161374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.483866214752197, "step": 126000}
{"episode_reward": 573.035553435635, "episode": 127.0, "batch_reward": 0.28420974569022656, "critic_loss": 0.5056981390714645, "actor_loss": -34.93991725921631, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.154062271118164, "step": 127000}
{"episode_reward": 534.9733389795128, "episode": 128.0, "batch_reward": 0.286101098805666, "critic_loss": 0.49218056501448154, "actor_loss": -35.60543727874756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.848914623260498, "step": 128000}
{"episode_reward": 583.1559138276494, "episode": 129.0, "batch_reward": 0.28845334964990615, "critic_loss": 0.460481207922101, "actor_loss": -35.78190456008911, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.673025131225586, "step": 129000}
{"episode_reward": 518.912972129071, "episode": 130.0, "batch_reward": 0.29062626434862615, "critic_loss": 0.4987895725220442, "actor_loss": -35.658935783386234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.488168954849243, "step": 130000}
{"episode_reward": 517.9020575510079, "episode": 131.0, "batch_reward": 0.2929107755422592, "critic_loss": 0.48684418949484826, "actor_loss": -36.426634811401364, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.92662453651428, "step": 131000}
{"episode_reward": 554.3478606790279, "episode": 132.0, "batch_reward": 0.29506263037025926, "critic_loss": 0.4929988219588995, "actor_loss": -36.07418753051758, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.09133267402649, "step": 132000}
{"episode_reward": 515.9953692027365, "episode": 133.0, "batch_reward": 0.2951689278483391, "critic_loss": 0.4740666010826826, "actor_loss": -36.339094181060794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.024953365325928, "step": 133000}
{"episode_reward": 518.8489053018327, "episode": 134.0, "batch_reward": 0.2970396255850792, "critic_loss": 0.46898934005200865, "actor_loss": -36.37039754486084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.564915657043457, "step": 134000}
{"episode_reward": 533.7584689829814, "episode": 135.0, "batch_reward": 0.30012134082615377, "critic_loss": 0.4594762429893017, "actor_loss": -36.8368745803833, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.67371892929077, "step": 135000}
{"episode_reward": 511.6888887707783, "episode": 136.0, "batch_reward": 0.30107088984549046, "critic_loss": 0.4920560608804226, "actor_loss": -37.37122365570068, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.964582443237305, "step": 136000}
{"episode_reward": 286.00379788996617, "episode": 137.0, "batch_reward": 0.3004214390963316, "critic_loss": 0.509230384349823, "actor_loss": -36.56208394241333, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.1828453540802, "step": 137000}
{"episode_reward": 559.7366232865836, "episode": 138.0, "batch_reward": 0.30317960181832315, "critic_loss": 0.5389493128806353, "actor_loss": -36.53109968948364, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.323758602142334, "step": 138000}
{"episode_reward": 543.4023127207721, "episode": 139.0, "batch_reward": 0.30466939163208007, "critic_loss": 0.5213989722430706, "actor_loss": -36.77847485733032, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.07701587677002, "step": 139000}
{"episode_reward": 548.6081301910866, "episode": 140.0, "batch_reward": 0.30538659742474555, "critic_loss": 0.4999083690047264, "actor_loss": -36.73247667312622, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.452338695526123, "step": 140000}
{"episode_reward": 484.32461729597003, "episode": 141.0, "batch_reward": 0.30703216457366944, "critic_loss": 0.5322848531603813, "actor_loss": -36.703852783203125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.25804615020752, "step": 141000}
{"episode_reward": 552.5610263692123, "episode": 142.0, "batch_reward": 0.3091836289465427, "critic_loss": 0.4814789133518934, "actor_loss": -37.1609063835144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.48331570625305, "step": 142000}
{"episode_reward": 551.8161934068362, "episode": 143.0, "batch_reward": 0.310898226454854, "critic_loss": 0.48154714827239514, "actor_loss": -37.40724545288086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.992472171783447, "step": 143000}
{"episode_reward": 477.85382568651085, "episode": 144.0, "batch_reward": 0.31264906919002533, "critic_loss": 0.47622794657945633, "actor_loss": -37.78504066085815, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.635308504104614, "step": 144000}
{"episode_reward": 557.1158240217189, "episode": 145.0, "batch_reward": 0.3150475604236126, "critic_loss": 0.4754445782601833, "actor_loss": -37.70663369369507, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.661511421203613, "step": 145000}
{"episode_reward": 561.2177004793148, "episode": 146.0, "batch_reward": 0.314591935813427, "critic_loss": 0.4822433166950941, "actor_loss": -37.71283030700683, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.373852491378784, "step": 146000}
{"episode_reward": 537.8254693990659, "episode": 147.0, "batch_reward": 0.3165557933449745, "critic_loss": 0.4869365309625864, "actor_loss": -38.12237756347656, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.669331550598145, "step": 147000}
{"episode_reward": 559.9818191775057, "episode": 148.0, "batch_reward": 0.3194380433857441, "critic_loss": 0.49531577549874783, "actor_loss": -37.83066798400879, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.68541646003723, "step": 148000}
{"episode_reward": 524.8360585311299, "episode": 149.0, "batch_reward": 0.3204128130078316, "critic_loss": 0.473787598580122, "actor_loss": -38.173510536193845, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.197771072387695, "step": 149000}
{"episode_reward": 412.12573955500204, "episode": 150.0, "batch_reward": 0.32155379354953767, "critic_loss": 0.4345700002163649, "actor_loss": -38.18214793395996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
