{"episode_reward": 0.0, "episode": 1.0, "duration": 17.903886795043945, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.542917251586914, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2804576759985901, "critic_loss": 0.12836659764954847, "actor_loss": -47.04538288856803, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 64.03863716125488, "step": 3000}
{"episode_reward": 14.180909255438621, "episode": 4.0, "batch_reward": 0.19150267206132413, "critic_loss": 0.13744646507129074, "actor_loss": -36.85039437866211, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.53088903427124, "step": 4000}
{"episode_reward": 80.84016377849052, "episode": 5.0, "batch_reward": 0.1695242350846529, "critic_loss": 0.1366071730926633, "actor_loss": -33.689337421417235, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.85594344139099, "step": 5000}
{"episode_reward": 173.5463756173704, "episode": 6.0, "batch_reward": 0.175474014185369, "critic_loss": 0.17307586383074522, "actor_loss": -35.19463675689697, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.908254623413086, "step": 6000}
{"episode_reward": 213.52071056597455, "episode": 7.0, "batch_reward": 0.17911442264914512, "critic_loss": 0.21093240152299403, "actor_loss": -35.9899370765686, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.026606559753418, "step": 7000}
{"episode_reward": 156.01941530047435, "episode": 8.0, "batch_reward": 0.1765569317638874, "critic_loss": 0.24495329242944716, "actor_loss": -35.47357656478882, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.456453561782837, "step": 8000}
{"episode_reward": 179.0704548955406, "episode": 9.0, "batch_reward": 0.1785118858963251, "critic_loss": 0.237791620478034, "actor_loss": -35.33551907730102, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.152689933776855, "step": 9000}
{"episode_reward": 206.4621695143909, "episode": 10.0, "batch_reward": 0.1877737687975168, "critic_loss": 0.22786543545126914, "actor_loss": -35.3548490524292, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.700828313827515, "step": 10000}
{"episode_reward": 364.82532602571064, "episode": 11.0, "batch_reward": 0.2028391380906105, "critic_loss": 0.2417599218338728, "actor_loss": -36.30375950241089, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.8313148021698, "step": 11000}
{"episode_reward": 337.0716771744935, "episode": 12.0, "batch_reward": 0.2159807643443346, "critic_loss": 0.27849330328404903, "actor_loss": -37.14150584411621, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.90240740776062, "step": 12000}
{"episode_reward": 287.6026333967913, "episode": 13.0, "batch_reward": 0.22263545958697795, "critic_loss": 0.2776281281411648, "actor_loss": -37.06870532226562, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.11282467842102, "step": 13000}
{"episode_reward": 396.9986003533356, "episode": 14.0, "batch_reward": 0.23314102767407893, "critic_loss": 0.3054271387159824, "actor_loss": -37.652476486206055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.472859859466553, "step": 14000}
{"episode_reward": 248.03229198295966, "episode": 15.0, "batch_reward": 0.2376910789012909, "critic_loss": 0.30878183183074, "actor_loss": -37.48465474700928, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.691593885421753, "step": 15000}
{"episode_reward": 390.00081135079796, "episode": 16.0, "batch_reward": 0.2459049081802368, "critic_loss": 0.3058516478985548, "actor_loss": -38.04680455780029, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.002305507659912, "step": 16000}
{"episode_reward": 377.07244430746704, "episode": 17.0, "batch_reward": 0.25488703288137915, "critic_loss": 0.3109551772326231, "actor_loss": -38.41252244567871, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.532925128936768, "step": 17000}
{"episode_reward": 356.3450633314107, "episode": 18.0, "batch_reward": 0.2610991208106279, "critic_loss": 0.3163498722165823, "actor_loss": -38.31782762908936, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.061837911605835, "step": 18000}
{"episode_reward": 431.4033554343935, "episode": 19.0, "batch_reward": 0.26956642998754976, "critic_loss": 0.31254619227349756, "actor_loss": -38.9577947845459, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.822645664215088, "step": 19000}
{"episode_reward": 426.53981712496443, "episode": 20.0, "batch_reward": 0.2767450633943081, "critic_loss": 0.31532372543215753, "actor_loss": -39.472348205566405, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.055742979049683, "step": 20000}
{"episode_reward": 422.8083132227938, "episode": 21.0, "batch_reward": 0.28717810866236687, "critic_loss": 0.31133281616866587, "actor_loss": -40.15975305175781, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.66741895675659, "step": 21000}
{"episode_reward": 526.8009265723912, "episode": 22.0, "batch_reward": 0.2970669991672039, "critic_loss": 0.3202816373258829, "actor_loss": -40.58562724304199, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.597606420516968, "step": 22000}
{"episode_reward": 379.57997695568037, "episode": 23.0, "batch_reward": 0.2979620175510645, "critic_loss": 0.34749481874704363, "actor_loss": -39.93812634277344, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.52463984489441, "step": 23000}
{"episode_reward": 194.0429046077214, "episode": 24.0, "batch_reward": 0.2947948065251112, "critic_loss": 0.35403186711668966, "actor_loss": -39.60384340286255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.622346878051758, "step": 24000}
{"episode_reward": 392.1435930720192, "episode": 25.0, "batch_reward": 0.3010704608261585, "critic_loss": 0.3623337400108576, "actor_loss": -39.794321731567386, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.816878080368042, "step": 25000}
{"episode_reward": 467.6627577347195, "episode": 26.0, "batch_reward": 0.3052331941127777, "critic_loss": 0.46568165309727194, "actor_loss": -40.10366408538818, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.911622524261475, "step": 26000}
{"episode_reward": 532.0527649370791, "episode": 27.0, "batch_reward": 0.30905695173144343, "critic_loss": 0.7299431865513325, "actor_loss": -40.59331192779541, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.535284519195557, "step": 27000}
{"episode_reward": 24.244839994757655, "episode": 28.0, "batch_reward": 0.3019939192086458, "critic_loss": 0.733328863054514, "actor_loss": -40.668751358032225, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.903385400772095, "step": 28000}
{"episode_reward": 323.02815826769194, "episode": 29.0, "batch_reward": 0.2991163525879383, "critic_loss": 0.8311097855567933, "actor_loss": -41.17981273651123, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.784995555877686, "step": 29000}
{"episode_reward": 7.430750403950542, "episode": 30.0, "batch_reward": 0.29305480687320234, "critic_loss": 0.8204344361126423, "actor_loss": -41.23564044952393, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.98815608024597, "step": 30000}
{"episode_reward": 218.80005925036727, "episode": 31.0, "batch_reward": 0.28810461680591104, "critic_loss": 0.9955285206139087, "actor_loss": -41.00147169494629, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.007128953933716, "step": 31000}
{"episode_reward": 76.59515795566222, "episode": 32.0, "batch_reward": 0.2798155851662159, "critic_loss": 1.115614715218544, "actor_loss": -41.20473023986816, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.476400136947632, "step": 32000}
{"episode_reward": 8.13190356528297, "episode": 33.0, "batch_reward": 0.2712509945780039, "critic_loss": 1.1241340955495835, "actor_loss": -41.259887870788575, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.547240018844604, "step": 33000}
{"episode_reward": 5.899533177520341, "episode": 34.0, "batch_reward": 0.26342419861257077, "critic_loss": 1.1608736864328384, "actor_loss": -41.49836943054199, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.69019889831543, "step": 34000}
{"episode_reward": 4.922327177881254, "episode": 35.0, "batch_reward": 0.2554269618690014, "critic_loss": 1.2457112392783165, "actor_loss": -41.74976468658447, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.853543758392334, "step": 35000}
{"episode_reward": 7.510002140252035, "episode": 36.0, "batch_reward": 0.24883721254765986, "critic_loss": 1.3504024208188057, "actor_loss": -42.021712890625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.34267234802246, "step": 36000}
{"episode_reward": 2.204428963100666, "episode": 37.0, "batch_reward": 0.24203444887697698, "critic_loss": 1.4911135814785956, "actor_loss": -42.54647296905517, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.542938470840454, "step": 37000}
{"episode_reward": 1.3632390877110754, "episode": 38.0, "batch_reward": 0.23574062249064445, "critic_loss": 1.5797367374897002, "actor_loss": -43.188364952087404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.740010023117065, "step": 38000}
{"episode_reward": 0.7463506725338762, "episode": 39.0, "batch_reward": 0.22967149463295936, "critic_loss": 1.8134359028935432, "actor_loss": -43.105296928405764, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.611868858337402, "step": 39000}
{"episode_reward": 6.840548888985011, "episode": 40.0, "batch_reward": 0.22326608571410178, "critic_loss": 2.470078230023384, "actor_loss": -44.27132740020752, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.945805072784424, "step": 40000}
{"episode_reward": 3.974531594118282, "episode": 41.0, "batch_reward": 0.2192717282921076, "critic_loss": 3.497701854586601, "actor_loss": -46.160608604431154, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.57848930358887, "step": 41000}
{"episode_reward": 4.82626938944411, "episode": 42.0, "batch_reward": 0.21440825976431369, "critic_loss": 4.922252070188522, "actor_loss": -48.80234566497803, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.04220986366272, "step": 42000}
{"episode_reward": 50.44568114349858, "episode": 43.0, "batch_reward": 0.2096528989970684, "critic_loss": 5.34466364812851, "actor_loss": -51.24687251281738, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.637092113494873, "step": 43000}
{"episode_reward": 69.49300197355102, "episode": 44.0, "batch_reward": 0.20616653805971147, "critic_loss": 6.493783669948578, "actor_loss": -53.23409107971192, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.765751838684082, "step": 44000}
{"episode_reward": 40.32506617048719, "episode": 45.0, "batch_reward": 0.20357455703616142, "critic_loss": 7.907073079347611, "actor_loss": -53.87912448883057, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.433854579925537, "step": 45000}
{"episode_reward": 73.50040918503204, "episode": 46.0, "batch_reward": 0.19995268207788466, "critic_loss": 9.665908451080321, "actor_loss": -56.75504768371582, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.51895785331726, "step": 46000}
{"episode_reward": 41.78570206821059, "episode": 47.0, "batch_reward": 0.19710916162282227, "critic_loss": 11.868361880302428, "actor_loss": -59.701751976013185, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.603069305419922, "step": 47000}
{"episode_reward": 58.64616132876738, "episode": 48.0, "batch_reward": 0.19379492361843587, "critic_loss": 13.921945556640624, "actor_loss": -62.72015545654297, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.821603536605835, "step": 48000}
{"episode_reward": 43.79610991398123, "episode": 49.0, "batch_reward": 0.18978816163539886, "critic_loss": 15.142235702991485, "actor_loss": -63.77072494888306, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.56053113937378, "step": 49000}
{"episode_reward": 14.476390113901186, "episode": 50.0, "batch_reward": 0.18707842721045018, "critic_loss": 16.945929295539855, "actor_loss": -66.39195880126952, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.259243488311768, "step": 50000}
{"episode_reward": 36.79659206017763, "episode": 51.0, "batch_reward": 0.18416408912837506, "critic_loss": 16.57536829662323, "actor_loss": -70.35845065689087, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.085065603256226, "step": 51000}
{"episode_reward": 20.731836895258642, "episode": 52.0, "batch_reward": 0.18113169398158788, "critic_loss": 15.36423238658905, "actor_loss": -70.33685639190674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.526832342147827, "step": 52000}
{"episode_reward": 24.10555854508974, "episode": 53.0, "batch_reward": 0.17743455056101085, "critic_loss": 14.74377359008789, "actor_loss": -74.72773427963257, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.66976499557495, "step": 53000}
{"episode_reward": 24.625416511246076, "episode": 54.0, "batch_reward": 0.1744000333547592, "critic_loss": 14.046883927345275, "actor_loss": -77.9026510772705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.41258430480957, "step": 54000}
{"episode_reward": 29.46329600388731, "episode": 55.0, "batch_reward": 0.17198173718899487, "critic_loss": 13.444932247638702, "actor_loss": -83.36610355758667, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.50694513320923, "step": 55000}
{"episode_reward": 14.818892794338861, "episode": 56.0, "batch_reward": 0.16958045732975005, "critic_loss": 12.512023576259613, "actor_loss": -80.69286229324341, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.50236463546753, "step": 56000}
{"episode_reward": 24.27483868992432, "episode": 57.0, "batch_reward": 0.1656450355798006, "critic_loss": 11.154141974449157, "actor_loss": -80.58398177719116, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.503033876419067, "step": 57000}
{"episode_reward": 21.206362489632873, "episode": 58.0, "batch_reward": 0.16493030983954668, "critic_loss": 10.434362089633941, "actor_loss": -85.31084972763061, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.522274255752563, "step": 58000}
{"episode_reward": 40.167225140098, "episode": 59.0, "batch_reward": 0.16231922810524702, "critic_loss": 9.293632452487946, "actor_loss": -81.20930995178223, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.313621997833252, "step": 59000}
{"episode_reward": 21.696695479656128, "episode": 60.0, "batch_reward": 0.16035558097809552, "critic_loss": 8.053174333810807, "actor_loss": -78.7211362876892, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.69288945198059, "step": 60000}
{"episode_reward": 15.011947727068097, "episode": 61.0, "batch_reward": 0.15767269058525563, "critic_loss": 7.714787630319595, "actor_loss": -79.64043824386597, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.24427533149719, "step": 61000}
{"episode_reward": 24.413809015864, "episode": 62.0, "batch_reward": 0.15486420105397702, "critic_loss": 7.176277390003205, "actor_loss": -78.88777394104004, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.184953927993774, "step": 62000}
{"episode_reward": 14.833834523533453, "episode": 63.0, "batch_reward": 0.15216724222153424, "critic_loss": 7.052112344026566, "actor_loss": -76.76251714706422, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.642449140548706, "step": 63000}
{"episode_reward": 33.40156040471828, "episode": 64.0, "batch_reward": 0.15083212070167065, "critic_loss": 6.900427647352219, "actor_loss": -74.80610205459595, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.54136037826538, "step": 64000}
{"episode_reward": 38.47013750505792, "episode": 65.0, "batch_reward": 0.14993619169294833, "critic_loss": 7.027701508522034, "actor_loss": -72.25206882095337, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.30103325843811, "step": 65000}
{"episode_reward": 27.477877778136882, "episode": 66.0, "batch_reward": 0.14628127006441355, "critic_loss": 7.369695903539657, "actor_loss": -70.92797560882569, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.82364773750305, "step": 66000}
{"episode_reward": 14.18506223410268, "episode": 67.0, "batch_reward": 0.145166748277843, "critic_loss": 7.655366650342941, "actor_loss": -67.0289803314209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.7832350730896, "step": 67000}
{"episode_reward": 16.83706798504301, "episode": 68.0, "batch_reward": 0.14431249498575927, "critic_loss": 9.16636833333969, "actor_loss": -70.97203340530396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.967890977859497, "step": 68000}
{"episode_reward": 23.887457044057843, "episode": 69.0, "batch_reward": 0.14145697053521872, "critic_loss": 10.528978213310241, "actor_loss": -67.88601388931275, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.793450832366943, "step": 69000}
{"episode_reward": 20.538855511640822, "episode": 70.0, "batch_reward": 0.14085653672367335, "critic_loss": 12.595817848682403, "actor_loss": -67.80021493530273, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.050002813339233, "step": 70000}
{"episode_reward": 28.872582775773274, "episode": 71.0, "batch_reward": 0.13901953262835742, "critic_loss": 14.053440218925475, "actor_loss": -71.99780771255493, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.48639369010925, "step": 71000}
{"episode_reward": 17.808979443343603, "episode": 72.0, "batch_reward": 0.13686510951071978, "critic_loss": 14.059044400691986, "actor_loss": -71.97372629165649, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.7184956073761, "step": 72000}
{"episode_reward": 25.187827903981386, "episode": 73.0, "batch_reward": 0.13514293774217367, "critic_loss": 14.105943376064301, "actor_loss": -71.66972732162476, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.643800973892212, "step": 73000}
{"episode_reward": 24.018752290619293, "episode": 74.0, "batch_reward": 0.13444351564347745, "critic_loss": 14.102913170814514, "actor_loss": -71.34598289871215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.092079401016235, "step": 74000}
{"episode_reward": 35.78580068091732, "episode": 75.0, "batch_reward": 0.13247200144827365, "critic_loss": 14.34124655866623, "actor_loss": -72.02369203948975, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.768510103225708, "step": 75000}
{"episode_reward": 23.65490773435586, "episode": 76.0, "batch_reward": 0.1314444269761443, "critic_loss": 13.323933797359466, "actor_loss": -72.25609893798828, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.619600296020508, "step": 76000}
{"episode_reward": 31.36670084290996, "episode": 77.0, "batch_reward": 0.12993821664154528, "critic_loss": 12.344007812976837, "actor_loss": -71.97779619979859, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.806909799575806, "step": 77000}
{"episode_reward": 30.504543397936196, "episode": 78.0, "batch_reward": 0.12879251465946437, "critic_loss": 11.574138207912444, "actor_loss": -69.71006267166138, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.847114086151123, "step": 78000}
{"episode_reward": 40.64018881597278, "episode": 79.0, "batch_reward": 0.12728564439713955, "critic_loss": 10.681647987365723, "actor_loss": -71.56958434295655, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.013012886047363, "step": 79000}
{"episode_reward": 36.62201880869337, "episode": 80.0, "batch_reward": 0.124950876429677, "critic_loss": 9.859380445241928, "actor_loss": -70.58577629470825, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.465067386627197, "step": 80000}
{"episode_reward": 34.636398807960376, "episode": 81.0, "batch_reward": 0.1243543969914317, "critic_loss": 9.091213582992554, "actor_loss": -66.9333429031372, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.76602602005005, "step": 81000}
{"episode_reward": 30.044879158401894, "episode": 82.0, "batch_reward": 0.12349199703335761, "critic_loss": 8.593469223499298, "actor_loss": -66.02229516601562, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.64542555809021, "step": 82000}
{"episode_reward": 26.00907042667312, "episode": 83.0, "batch_reward": 0.12287338893115521, "critic_loss": 8.1728551197052, "actor_loss": -65.5421798248291, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.519027709960938, "step": 83000}
{"episode_reward": 175.6146157711985, "episode": 84.0, "batch_reward": 0.12288729859888553, "critic_loss": 8.02599196600914, "actor_loss": -64.2436604385376, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.46096396446228, "step": 84000}
{"episode_reward": 52.768874009916644, "episode": 85.0, "batch_reward": 0.12377428017556667, "critic_loss": 8.541533790826797, "actor_loss": -63.84059431838989, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.72451686859131, "step": 85000}
{"episode_reward": 242.72567927540635, "episode": 86.0, "batch_reward": 0.1253895677253604, "critic_loss": 8.443024706363678, "actor_loss": -64.71521979141235, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.660901069641113, "step": 86000}
{"episode_reward": 118.53453816925345, "episode": 87.0, "batch_reward": 0.1244585204422474, "critic_loss": 8.186018620967864, "actor_loss": -64.82839614105225, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.136449575424194, "step": 87000}
{"episode_reward": 56.87423346811642, "episode": 88.0, "batch_reward": 0.12454029061645269, "critic_loss": 8.042452754497528, "actor_loss": -64.64310219955445, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.842413425445557, "step": 88000}
{"episode_reward": 84.0872355261665, "episode": 89.0, "batch_reward": 0.1239576059281826, "critic_loss": 7.928674506425858, "actor_loss": -62.519930282592775, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.67251491546631, "step": 89000}
{"episode_reward": 81.89882444926936, "episode": 90.0, "batch_reward": 0.12398635602742433, "critic_loss": 7.785429121732712, "actor_loss": -60.8898537940979, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.68062710762024, "step": 90000}
{"episode_reward": 241.08004205789587, "episode": 91.0, "batch_reward": 0.1256066133901477, "critic_loss": 7.432076296329498, "actor_loss": -62.12615625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.57201790809631, "step": 91000}
{"episode_reward": 370.87248022798354, "episode": 92.0, "batch_reward": 0.12802067288756372, "critic_loss": 6.67080212020874, "actor_loss": -60.556354919433595, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.523369073867798, "step": 92000}
{"episode_reward": 454.1165612369872, "episode": 93.0, "batch_reward": 0.130407487899065, "critic_loss": 6.38067191195488, "actor_loss": -61.482467163085936, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.961928844451904, "step": 93000}
{"episode_reward": 99.45916366775614, "episode": 94.0, "batch_reward": 0.1312380279302597, "critic_loss": 5.902292600154877, "actor_loss": -60.19545100784302, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.83137345314026, "step": 94000}
{"episode_reward": 395.86651832949684, "episode": 95.0, "batch_reward": 0.13451911421120166, "critic_loss": 5.610371402978897, "actor_loss": -58.69746044921875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.311689376831055, "step": 95000}
{"episode_reward": 517.8994995767408, "episode": 96.0, "batch_reward": 0.13859041572362185, "critic_loss": 5.204882593631744, "actor_loss": -59.595856513977054, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.52571940422058, "step": 96000}
{"episode_reward": 403.5907046211512, "episode": 97.0, "batch_reward": 0.14217251947522164, "critic_loss": 5.129404285192489, "actor_loss": -58.856653007507326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.386780261993408, "step": 97000}
{"episode_reward": 390.9426389965667, "episode": 98.0, "batch_reward": 0.14373361488431693, "critic_loss": 4.3661973443031314, "actor_loss": -58.9885599861145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.87031626701355, "step": 98000}
{"episode_reward": 378.6300662067025, "episode": 99.0, "batch_reward": 0.14555551575869322, "critic_loss": 3.8028806824684143, "actor_loss": -59.02092735671997, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.804457902908325, "step": 99000}
{"episode_reward": 467.77848398401824, "episode": 100.0, "batch_reward": 0.14856370001286268, "critic_loss": 3.5252496993541715, "actor_loss": -59.70789760971069, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.710307359695435, "step": 100000}
{"episode_reward": 458.6391530574084, "episode": 101.0, "batch_reward": 0.15189281695336104, "critic_loss": 3.072900375723839, "actor_loss": -56.833011611938474, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.10591197013855, "step": 101000}
{"episode_reward": 375.88838042938113, "episode": 102.0, "batch_reward": 0.15534200494736433, "critic_loss": 2.609228271484375, "actor_loss": -56.67135069656372, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.500253915786743, "step": 102000}
{"episode_reward": 451.6983101867881, "episode": 103.0, "batch_reward": 0.15799065701663495, "critic_loss": 2.3933812146782873, "actor_loss": -56.18455188369751, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.26713228225708, "step": 103000}
{"episode_reward": 409.2826615236471, "episode": 104.0, "batch_reward": 0.15862734189629554, "critic_loss": 2.141683189570904, "actor_loss": -54.66588234329224, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.63217854499817, "step": 104000}
{"episode_reward": 272.9642662993792, "episode": 105.0, "batch_reward": 0.16134276911616324, "critic_loss": 1.9953030605316162, "actor_loss": -55.841145679473875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.52955913543701, "step": 105000}
{"episode_reward": 403.86256124100834, "episode": 106.0, "batch_reward": 0.1634950430095196, "critic_loss": 1.7866301746964455, "actor_loss": -55.44840533828735, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.194491863250732, "step": 106000}
{"episode_reward": 214.98828670831708, "episode": 107.0, "batch_reward": 0.16349901118129492, "critic_loss": 1.6258469304442407, "actor_loss": -52.169020488739015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.38619875907898, "step": 107000}
{"episode_reward": 406.99254976351614, "episode": 108.0, "batch_reward": 0.16308570151776075, "critic_loss": 1.4989332266449928, "actor_loss": -49.8810050163269, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.548794507980347, "step": 108000}
{"episode_reward": 3.27859281388365, "episode": 109.0, "batch_reward": 0.16345169267058374, "critic_loss": 1.469035547196865, "actor_loss": -49.43715460586548, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.994126081466675, "step": 109000}
{"episode_reward": 82.8033550120129, "episode": 110.0, "batch_reward": 0.16432528468221427, "critic_loss": 1.3955377051234246, "actor_loss": -47.6450440864563, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.811331510543823, "step": 110000}
{"episode_reward": 470.3417594731979, "episode": 111.0, "batch_reward": 0.16525139209628106, "critic_loss": 1.277539076924324, "actor_loss": -47.08492269515991, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.202826499938965, "step": 111000}
{"episode_reward": 277.60796843172943, "episode": 112.0, "batch_reward": 0.16638838311284782, "critic_loss": 1.335096254169941, "actor_loss": -46.10466846847534, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.82280921936035, "step": 112000}
{"episode_reward": 105.76732252775292, "episode": 113.0, "batch_reward": 0.1662347857132554, "critic_loss": 1.2341473006010055, "actor_loss": -44.85881918716431, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.624021530151367, "step": 113000}
{"episode_reward": 179.46535974518156, "episode": 114.0, "batch_reward": 0.1680566062629223, "critic_loss": 1.118478534847498, "actor_loss": -43.045682899475096, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.549493551254272, "step": 114000}
{"episode_reward": 496.16143978759186, "episode": 115.0, "batch_reward": 0.1705087740123272, "critic_loss": 1.1143900316655635, "actor_loss": -42.97944686508179, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.46563696861267, "step": 115000}
{"episode_reward": 483.89542633560956, "episode": 116.0, "batch_reward": 0.1733470594212413, "critic_loss": 1.0285836471021175, "actor_loss": -41.87145623779297, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.920918464660645, "step": 116000}
{"episode_reward": 455.0841654635467, "episode": 117.0, "batch_reward": 0.17468429014831782, "critic_loss": 0.9864362653791905, "actor_loss": -41.63888377380371, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.785548210144043, "step": 117000}
{"episode_reward": 483.89602932111563, "episode": 118.0, "batch_reward": 0.17896468742191793, "critic_loss": 0.8876328662931919, "actor_loss": -40.511641536712645, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.53271770477295, "step": 118000}
{"episode_reward": 546.3146153403566, "episode": 119.0, "batch_reward": 0.18129762941598893, "critic_loss": 0.7923552588522434, "actor_loss": -40.74822006607056, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.76172137260437, "step": 119000}
{"episode_reward": 458.2627068242287, "episode": 120.0, "batch_reward": 0.18420253694057465, "critic_loss": 0.8332657627165317, "actor_loss": -40.53081237411499, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.65052366256714, "step": 120000}
{"episode_reward": 503.60860680959837, "episode": 121.0, "batch_reward": 0.18695658552646638, "critic_loss": 0.7007681156098843, "actor_loss": -39.62067339706421, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.60269379615784, "step": 121000}
{"episode_reward": 516.1660771404551, "episode": 122.0, "batch_reward": 0.18869305700063704, "critic_loss": 0.6592739795744419, "actor_loss": -38.853497203826905, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.93999671936035, "step": 122000}
{"episode_reward": 550.3468158603569, "episode": 123.0, "batch_reward": 0.19196767723560335, "critic_loss": 0.6439549843668938, "actor_loss": -38.70547312927246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.926013708114624, "step": 123000}
{"episode_reward": 547.0615243175583, "episode": 124.0, "batch_reward": 0.19402705530822278, "critic_loss": 0.607459185063839, "actor_loss": -37.91717459869385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.566240549087524, "step": 124000}
{"episode_reward": 524.578575841658, "episode": 125.0, "batch_reward": 0.1972870305031538, "critic_loss": 0.5524287950694561, "actor_loss": -37.75290409851074, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.574201822280884, "step": 125000}
{"episode_reward": 531.9640439711849, "episode": 126.0, "batch_reward": 0.2003307518362999, "critic_loss": 0.5181216228008271, "actor_loss": -37.08225996780396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.731184482574463, "step": 126000}
{"episode_reward": 552.9601187359641, "episode": 127.0, "batch_reward": 0.20263181978464126, "critic_loss": 0.5114756493419409, "actor_loss": -36.744140548706056, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.53217363357544, "step": 127000}
{"episode_reward": 569.1078454457175, "episode": 128.0, "batch_reward": 0.20547674502432348, "critic_loss": 0.4671490658223629, "actor_loss": -36.195964660644535, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.620527744293213, "step": 128000}
{"episode_reward": 563.9302304331114, "episode": 129.0, "batch_reward": 0.20742212523519993, "critic_loss": 0.41625175492465494, "actor_loss": -35.78079025268555, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.865920543670654, "step": 129000}
{"episode_reward": 536.728537789149, "episode": 130.0, "batch_reward": 0.210803883805871, "critic_loss": 0.4277989203631878, "actor_loss": -35.772859970092775, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.330220222473145, "step": 130000}
{"episode_reward": 543.2585924429371, "episode": 131.0, "batch_reward": 0.21417882664501667, "critic_loss": 0.4197048771381378, "actor_loss": -35.60443314743042, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.92862343788147, "step": 131000}
{"episode_reward": 542.7040215431547, "episode": 132.0, "batch_reward": 0.21699534113705157, "critic_loss": 0.41333565644919873, "actor_loss": -35.24379511642456, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.862244606018066, "step": 132000}
{"episode_reward": 558.2171420590743, "episode": 133.0, "batch_reward": 0.21887729614973067, "critic_loss": 0.3947932971119881, "actor_loss": -34.921133743286134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.64319086074829, "step": 133000}
{"episode_reward": 565.1564354248499, "episode": 134.0, "batch_reward": 0.22091493460536002, "critic_loss": 0.4125391243547201, "actor_loss": -34.767698066711425, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.98224925994873, "step": 134000}
{"episode_reward": 569.1470837244464, "episode": 135.0, "batch_reward": 0.22347993411123754, "critic_loss": 0.36276155726611614, "actor_loss": -34.533899311065674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.884615182876587, "step": 135000}
{"episode_reward": 576.6053884565858, "episode": 136.0, "batch_reward": 0.2263678371757269, "critic_loss": 0.35330220791697503, "actor_loss": -34.37576480484009, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.974943161010742, "step": 136000}
{"episode_reward": 540.3618895346151, "episode": 137.0, "batch_reward": 0.2289031659960747, "critic_loss": 0.34738035476207735, "actor_loss": -34.35029001235962, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.518032550811768, "step": 137000}
{"episode_reward": 594.5869134050437, "episode": 138.0, "batch_reward": 0.23207056118547917, "critic_loss": 0.3344962430894375, "actor_loss": -34.26815859222412, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.564437866210938, "step": 138000}
{"episode_reward": 580.7699175868487, "episode": 139.0, "batch_reward": 0.2346287380307913, "critic_loss": 0.3482129065990448, "actor_loss": -34.16769832611084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.515326976776123, "step": 139000}
{"episode_reward": 575.8714493755718, "episode": 140.0, "batch_reward": 0.23689314644038678, "critic_loss": 0.32417548094689846, "actor_loss": -33.99776601791382, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.54153609275818, "step": 140000}
{"episode_reward": 586.4453778310433, "episode": 141.0, "batch_reward": 0.23863887976109982, "critic_loss": 0.34425881247222423, "actor_loss": -33.795222328186036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.49878287315369, "step": 141000}
{"episode_reward": 584.187799643705, "episode": 142.0, "batch_reward": 0.24095841909945012, "critic_loss": 0.32767673563957217, "actor_loss": -33.69794708633423, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.2278950214386, "step": 142000}
{"episode_reward": 569.9760996075096, "episode": 143.0, "batch_reward": 0.24326922781765462, "critic_loss": 0.31588294909894465, "actor_loss": -33.681290184020995, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.482881546020508, "step": 143000}
{"episode_reward": 575.6819444273259, "episode": 144.0, "batch_reward": 0.2472918644249439, "critic_loss": 0.33164326365292074, "actor_loss": -33.88174068832397, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.726330995559692, "step": 144000}
{"episode_reward": 531.4841522202098, "episode": 145.0, "batch_reward": 0.2491328704059124, "critic_loss": 0.3192041101306677, "actor_loss": -33.74350624465942, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.23038959503174, "step": 145000}
{"episode_reward": 535.0700537725152, "episode": 146.0, "batch_reward": 0.24996687090396882, "critic_loss": 0.31597475913167, "actor_loss": -33.78253053665161, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.855749368667603, "step": 146000}
{"episode_reward": 555.1225799510132, "episode": 147.0, "batch_reward": 0.2513360734730959, "critic_loss": 0.31857760782539846, "actor_loss": -33.58508214950562, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.63065242767334, "step": 147000}
{"episode_reward": 556.8168267827389, "episode": 148.0, "batch_reward": 0.2540667045861483, "critic_loss": 0.3116708755791187, "actor_loss": -33.62632550048828, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.85220766067505, "step": 148000}
{"episode_reward": 556.2699499643115, "episode": 149.0, "batch_reward": 0.25569542329013345, "critic_loss": 0.30433238635957244, "actor_loss": -33.65030871200562, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.677358150482178, "step": 149000}
{"episode_reward": 569.8953365376535, "episode": 150.0, "batch_reward": 0.25877822943031786, "critic_loss": 0.31199069975316523, "actor_loss": -33.793296031951904, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
