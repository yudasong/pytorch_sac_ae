{"episode_reward": 0.0, "episode": 1.0, "duration": 17.073762893676758, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.4837095737457275, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2823757742615134, "critic_loss": 0.02729548179945421, "actor_loss": -25.769517984379885, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 60.65286135673523, "step": 3000}
{"episode_reward": 74.6520265270819, "episode": 4.0, "batch_reward": 0.2136656825840473, "critic_loss": 0.03520268796384335, "actor_loss": -24.79781510972977, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92297649383545, "step": 4000}
{"episode_reward": 189.4673324953393, "episode": 5.0, "batch_reward": 0.19254420787096024, "critic_loss": 0.034302193094044926, "actor_loss": -21.363055304050445, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96981143951416, "step": 5000}
{"episode_reward": 35.779125254007724, "episode": 6.0, "batch_reward": 0.16992739482223987, "critic_loss": 0.04690319005586207, "actor_loss": -21.657414870738982, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97476053237915, "step": 6000}
{"episode_reward": 74.07266794122722, "episode": 7.0, "batch_reward": 0.15506457380205393, "critic_loss": 0.04390566869825125, "actor_loss": -21.845322940826417, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97430682182312, "step": 7000}
{"episode_reward": 103.94995375055069, "episode": 8.0, "batch_reward": 0.15071946664154529, "critic_loss": 0.04534806591644883, "actor_loss": -21.732379580497742, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.006855487823486, "step": 8000}
{"episode_reward": 132.4962545497403, "episode": 9.0, "batch_reward": 0.14936275354772807, "critic_loss": 0.05341025943867862, "actor_loss": -22.026308131217956, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.956384420394897, "step": 9000}
{"episode_reward": 130.44921142132773, "episode": 10.0, "batch_reward": 0.14892397341877223, "critic_loss": 0.06757375222072005, "actor_loss": -21.702040350437166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.973671674728394, "step": 10000}
{"episode_reward": 149.2004259612722, "episode": 11.0, "batch_reward": 0.14732917065173387, "critic_loss": 0.07256136168912053, "actor_loss": -23.159036801815034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.1751925945282, "step": 11000}
{"episode_reward": 160.8429394673714, "episode": 12.0, "batch_reward": 0.15104764983057975, "critic_loss": 0.09931691251695156, "actor_loss": -22.505661796569825, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.98300266265869, "step": 12000}
{"episode_reward": 169.70158847046304, "episode": 13.0, "batch_reward": 0.1538121023029089, "critic_loss": 0.11561510863527656, "actor_loss": -22.247600964546205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.99482274055481, "step": 13000}
{"episode_reward": 236.7593443545607, "episode": 14.0, "batch_reward": 0.15779852618277074, "critic_loss": 0.13285117080807685, "actor_loss": -22.016728074073793, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.00293254852295, "step": 14000}
{"episode_reward": 156.7126444072509, "episode": 15.0, "batch_reward": 0.1537479367479682, "critic_loss": 0.13730751427263022, "actor_loss": -23.69180421447754, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.106857776641846, "step": 15000}
{"episode_reward": 30.409030749657862, "episode": 16.0, "batch_reward": 0.1491892827153206, "critic_loss": 0.1302698147892952, "actor_loss": -23.0170224609375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.20381498336792, "step": 16000}
{"episode_reward": 134.7081364171729, "episode": 17.0, "batch_reward": 0.14858074766397475, "critic_loss": 0.14386890533566474, "actor_loss": -21.739543270111085, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95655131340027, "step": 17000}
{"episode_reward": 193.04436552882322, "episode": 18.0, "batch_reward": 0.1545109705850482, "critic_loss": 0.15508728874474764, "actor_loss": -21.88143387413025, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.970583200454712, "step": 18000}
{"episode_reward": 243.5353871830594, "episode": 19.0, "batch_reward": 0.15689789754152297, "critic_loss": 0.17218300060927869, "actor_loss": -22.573157642364503, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.248538970947266, "step": 19000}
{"episode_reward": 151.7056955385813, "episode": 20.0, "batch_reward": 0.15501477168500424, "critic_loss": 0.1750369108095765, "actor_loss": -22.551734533309936, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.009822368621826, "step": 20000}
{"episode_reward": 117.67674648562155, "episode": 21.0, "batch_reward": 0.15447162887454033, "critic_loss": 0.18613796697556972, "actor_loss": -23.13781486606598, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.05963754653931, "step": 21000}
{"episode_reward": 193.84700140546556, "episode": 22.0, "batch_reward": 0.1579118843525648, "critic_loss": 0.21425774747878312, "actor_loss": -22.68100834274292, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.98510503768921, "step": 22000}
{"episode_reward": 278.4877765525918, "episode": 23.0, "batch_reward": 0.1636869357600808, "critic_loss": 0.25558723413944245, "actor_loss": -22.725647872924803, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.04202628135681, "step": 23000}
{"episode_reward": 159.2920847951905, "episode": 24.0, "batch_reward": 0.16194725927710532, "critic_loss": 0.2762105960100889, "actor_loss": -23.47579561805725, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.972153425216675, "step": 24000}
{"episode_reward": 129.67026464137902, "episode": 25.0, "batch_reward": 0.15910310624539853, "critic_loss": 0.2633720279186964, "actor_loss": -22.213620182037353, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.01906156539917, "step": 25000}
{"episode_reward": 76.63217759642113, "episode": 26.0, "batch_reward": 0.15567969861626624, "critic_loss": 0.25912876001000407, "actor_loss": -21.735014177322387, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.010865449905396, "step": 26000}
{"episode_reward": 109.79641855429196, "episode": 27.0, "batch_reward": 0.1558758917823434, "critic_loss": 0.26194078489392997, "actor_loss": -21.604283906936647, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97398090362549, "step": 27000}
{"episode_reward": 147.64708974376833, "episode": 28.0, "batch_reward": 0.1561770466193557, "critic_loss": 0.2856439619958401, "actor_loss": -21.552199792861938, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97862482070923, "step": 28000}
{"episode_reward": 152.74820935832932, "episode": 29.0, "batch_reward": 0.15769063621759416, "critic_loss": 0.3064754499644041, "actor_loss": -22.440363624572754, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.935035228729248, "step": 29000}
{"episode_reward": 330.51926958157924, "episode": 30.0, "batch_reward": 0.16248852460086347, "critic_loss": 0.3485109679996967, "actor_loss": -22.963556190490724, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.945355892181396, "step": 30000}
{"episode_reward": 261.3240751434922, "episode": 31.0, "batch_reward": 0.16572498036921024, "critic_loss": 0.35276935720443725, "actor_loss": -23.60358600997925, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.13134169578552, "step": 31000}
{"episode_reward": 216.04334680208356, "episode": 32.0, "batch_reward": 0.1667803088724613, "critic_loss": 0.35041240957379344, "actor_loss": -23.805590393066407, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.959121704101562, "step": 32000}
{"episode_reward": 187.8127984619829, "episode": 33.0, "batch_reward": 0.16793472044169902, "critic_loss": 0.3746358088850975, "actor_loss": -23.7738805141449, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.965452671051025, "step": 33000}
{"episode_reward": 297.6882137483046, "episode": 34.0, "batch_reward": 0.17148667746782303, "critic_loss": 0.3953640987277031, "actor_loss": -23.30070706176758, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.964112997055054, "step": 34000}
{"episode_reward": 248.9893422637599, "episode": 35.0, "batch_reward": 0.17402677589654922, "critic_loss": 0.46011700557172297, "actor_loss": -24.73938810157776, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97933793067932, "step": 35000}
{"episode_reward": 299.5428416367494, "episode": 36.0, "batch_reward": 0.17725546863675118, "critic_loss": 0.508401509821415, "actor_loss": -24.56764033317566, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.981927394866943, "step": 36000}
{"episode_reward": 278.54886305255326, "episode": 37.0, "batch_reward": 0.18008256541192533, "critic_loss": 0.5110135294944048, "actor_loss": -24.993360298156738, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.986388206481934, "step": 37000}
{"episode_reward": 331.81907024058336, "episode": 38.0, "batch_reward": 0.18420293644070626, "critic_loss": 0.48686409255862234, "actor_loss": -25.867398611068726, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95332908630371, "step": 38000}
{"episode_reward": 303.3821861375313, "episode": 39.0, "batch_reward": 0.18480201356112957, "critic_loss": 0.4844248311817646, "actor_loss": -26.554197605133055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.001962184906006, "step": 39000}
{"episode_reward": 64.8849902427155, "episode": 40.0, "batch_reward": 0.1857969675809145, "critic_loss": 0.5185543230324984, "actor_loss": -26.43417707824707, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.952966451644897, "step": 40000}
{"episode_reward": 390.4079118471427, "episode": 41.0, "batch_reward": 0.1907028046399355, "critic_loss": 0.5178657536953688, "actor_loss": -26.75759792327881, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.08877730369568, "step": 41000}
{"episode_reward": 353.0724720165909, "episode": 42.0, "batch_reward": 0.19341716930270195, "critic_loss": 0.551442557901144, "actor_loss": -26.727569972991944, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.957379579544067, "step": 42000}
{"episode_reward": 203.68801974126862, "episode": 43.0, "batch_reward": 0.19449860990047455, "critic_loss": 0.5624659377634526, "actor_loss": -26.99059623718262, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.968316078186035, "step": 43000}
{"episode_reward": 368.5791370191973, "episode": 44.0, "batch_reward": 0.19885939225554466, "critic_loss": 0.6159859320223331, "actor_loss": -27.068275463104246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.00286102294922, "step": 44000}
{"episode_reward": 325.727922234151, "episode": 45.0, "batch_reward": 0.19830251698195933, "critic_loss": 0.6267369565665721, "actor_loss": -27.469288333892823, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97294569015503, "step": 45000}
{"episode_reward": 65.47182528057566, "episode": 46.0, "batch_reward": 0.1973704065233469, "critic_loss": 0.610841802507639, "actor_loss": -27.332299228668212, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.988593101501465, "step": 46000}
{"episode_reward": 225.55700250727128, "episode": 47.0, "batch_reward": 0.19946211265027522, "critic_loss": 0.6932285450994968, "actor_loss": -27.21946915435791, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.012436389923096, "step": 47000}
{"episode_reward": 242.0985292216996, "episode": 48.0, "batch_reward": 0.198913243919611, "critic_loss": 0.7656246438920498, "actor_loss": -26.798714820861818, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.993403911590576, "step": 48000}
{"episode_reward": 202.518577993571, "episode": 49.0, "batch_reward": 0.20020250745117665, "critic_loss": 0.7951995474398136, "actor_loss": -27.122653213500975, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.989030838012695, "step": 49000}
{"episode_reward": 368.3136458848743, "episode": 50.0, "batch_reward": 0.20352923743426798, "critic_loss": 0.6518667456209659, "actor_loss": -27.734187881469726, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.98456573486328, "step": 50000}
{"episode_reward": 450.1435406842071, "episode": 51.0, "batch_reward": 0.2079351227581501, "critic_loss": 0.7629856466948987, "actor_loss": -27.76458966445923, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.32902717590332, "step": 51000}
{"episode_reward": 274.5344673323906, "episode": 52.0, "batch_reward": 0.20899978038668632, "critic_loss": 0.7042761969566346, "actor_loss": -28.50978805923462, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.033666372299194, "step": 52000}
{"episode_reward": 421.96399366830013, "episode": 53.0, "batch_reward": 0.21427057127654553, "critic_loss": 0.7173168497681618, "actor_loss": -28.849888946533202, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.02480387687683, "step": 53000}
{"episode_reward": 392.5446905168261, "episode": 54.0, "batch_reward": 0.21527035728096963, "critic_loss": 0.6894076889753342, "actor_loss": -28.92269425201416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.043421268463135, "step": 54000}
{"episode_reward": 91.69698212039448, "episode": 55.0, "batch_reward": 0.21554875904321671, "critic_loss": 0.6788929443359375, "actor_loss": -28.545706119537353, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.02961492538452, "step": 55000}
{"episode_reward": 329.30978572368133, "episode": 56.0, "batch_reward": 0.21660623639822008, "critic_loss": 0.6899958717226982, "actor_loss": -29.160948822021485, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.018126964569092, "step": 56000}
{"episode_reward": 447.6952384001378, "episode": 57.0, "batch_reward": 0.22180084654688836, "critic_loss": 0.6475645471513272, "actor_loss": -29.70383010482788, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.976747274398804, "step": 57000}
{"episode_reward": 401.6661167244697, "episode": 58.0, "batch_reward": 0.22421621164679528, "critic_loss": 0.6577726946175099, "actor_loss": -29.3587544631958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.99336576461792, "step": 58000}
{"episode_reward": 228.50559151744335, "episode": 59.0, "batch_reward": 0.22445882120728491, "critic_loss": 0.6076349821090699, "actor_loss": -29.49537624359131, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.979722499847412, "step": 59000}
{"episode_reward": 295.3405473153764, "episode": 60.0, "batch_reward": 0.22559921199083327, "critic_loss": 0.70724194252491, "actor_loss": -30.35923695755005, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96831727027893, "step": 60000}
{"episode_reward": 291.7872581596378, "episode": 61.0, "batch_reward": 0.22650588071346284, "critic_loss": 0.6529961984157562, "actor_loss": -29.558561115264894, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.12405490875244, "step": 61000}
{"episode_reward": 414.7960727301483, "episode": 62.0, "batch_reward": 0.2297509522140026, "critic_loss": 0.6031416398882866, "actor_loss": -29.834650932312012, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97908878326416, "step": 62000}
{"episode_reward": 468.21198226452304, "episode": 63.0, "batch_reward": 0.23314077700674535, "critic_loss": 0.6602552662789821, "actor_loss": -30.467087551116943, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95021939277649, "step": 63000}
{"episode_reward": 478.29158466737, "episode": 64.0, "batch_reward": 0.23741900098323823, "critic_loss": 0.6344961141943931, "actor_loss": -30.725060050964355, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.99284601211548, "step": 64000}
{"episode_reward": 441.4559855134051, "episode": 65.0, "batch_reward": 0.24054086782038211, "critic_loss": 0.6547800555229187, "actor_loss": -31.088604782104493, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.99190044403076, "step": 65000}
{"episode_reward": 486.80938747104045, "episode": 66.0, "batch_reward": 0.24515649880468846, "critic_loss": 0.6343793116211891, "actor_loss": -31.35933335494995, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.927314281463623, "step": 66000}
{"episode_reward": 411.7822231483266, "episode": 67.0, "batch_reward": 0.24682036954164505, "critic_loss": 0.6166931798756122, "actor_loss": -31.868813610076906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96593713760376, "step": 67000}
{"episode_reward": 395.68004840163115, "episode": 68.0, "batch_reward": 0.248852157458663, "critic_loss": 0.6686843896508217, "actor_loss": -31.35335662841797, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.017829179763794, "step": 68000}
{"episode_reward": 269.78677881018837, "episode": 69.0, "batch_reward": 0.24905105462670327, "critic_loss": 0.6386292558610439, "actor_loss": -31.62867679977417, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.970733165740967, "step": 69000}
{"episode_reward": 254.81301339698902, "episode": 70.0, "batch_reward": 0.24922445645928382, "critic_loss": 0.6465910986065865, "actor_loss": -31.56391551208496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.973586082458496, "step": 70000}
{"episode_reward": 321.5893409135248, "episode": 71.0, "batch_reward": 0.24997381143271924, "critic_loss": 0.5857803708910942, "actor_loss": -31.13738677215576, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.18845820426941, "step": 71000}
{"episode_reward": 215.56142057828603, "episode": 72.0, "batch_reward": 0.2506038971245289, "critic_loss": 0.6314579757452011, "actor_loss": -31.186444339752196, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.968541383743286, "step": 72000}
{"episode_reward": 422.0632729725454, "episode": 73.0, "batch_reward": 0.25249364441633226, "critic_loss": 0.7111372333168984, "actor_loss": -31.36172283935547, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95718812942505, "step": 73000}
{"episode_reward": 535.8728643174651, "episode": 74.0, "batch_reward": 0.2567342761904001, "critic_loss": 0.6691431593894959, "actor_loss": -31.924361415863036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.957651615142822, "step": 74000}
{"episode_reward": 450.81526873200016, "episode": 75.0, "batch_reward": 0.25940650747716426, "critic_loss": 0.7123841351568699, "actor_loss": -31.905244644165037, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.984211683273315, "step": 75000}
{"episode_reward": 507.9146725144833, "episode": 76.0, "batch_reward": 0.26253574185073375, "critic_loss": 0.6479254774749279, "actor_loss": -32.08257649612427, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.975512266159058, "step": 76000}
{"episode_reward": 363.24561729736416, "episode": 77.0, "batch_reward": 0.26364173971116545, "critic_loss": 0.6614449170678854, "actor_loss": -32.06475881576538, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.99217677116394, "step": 77000}
{"episode_reward": 512.3430403501078, "episode": 78.0, "batch_reward": 0.26769227434694765, "critic_loss": 0.595361393302679, "actor_loss": -32.68203693389893, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.927626371383667, "step": 78000}
{"episode_reward": 498.34389260520504, "episode": 79.0, "batch_reward": 0.269708922252059, "critic_loss": 0.5839117701947689, "actor_loss": -32.30940989685059, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.98640775680542, "step": 79000}
{"episode_reward": 502.90793812652436, "episode": 80.0, "batch_reward": 0.2729388541728258, "critic_loss": 0.5762068005204201, "actor_loss": -32.622946411132816, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95181703567505, "step": 80000}
{"episode_reward": 374.9774496086041, "episode": 81.0, "batch_reward": 0.2751339426785707, "critic_loss": 0.5569537028372288, "actor_loss": -32.89654425048828, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.082026720047, "step": 81000}
{"episode_reward": 494.3907951354697, "episode": 82.0, "batch_reward": 0.2783269308656454, "critic_loss": 0.5581355484724044, "actor_loss": -33.50114775848389, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97357940673828, "step": 82000}
{"episode_reward": 521.8943662507967, "episode": 83.0, "batch_reward": 0.279534540489316, "critic_loss": 0.577121295362711, "actor_loss": -33.33626622772217, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.99736738204956, "step": 83000}
{"episode_reward": 454.6538099796317, "episode": 84.0, "batch_reward": 0.2807416525632143, "critic_loss": 0.5686540731191635, "actor_loss": -33.3893959197998, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.979183435440063, "step": 84000}
{"episode_reward": 145.43807121050256, "episode": 85.0, "batch_reward": 0.27975379726290706, "critic_loss": 0.5657891466021537, "actor_loss": -33.384098075866696, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.977479934692383, "step": 85000}
{"episode_reward": 447.0174185087659, "episode": 86.0, "batch_reward": 0.28232236766815183, "critic_loss": 0.5560719204246998, "actor_loss": -33.26545788192749, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.99545168876648, "step": 86000}
{"episode_reward": 399.50696260996426, "episode": 87.0, "batch_reward": 0.2825905382633209, "critic_loss": 0.5351832660138607, "actor_loss": -33.12716949462891, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97632074356079, "step": 87000}
{"episode_reward": 224.28112267863023, "episode": 88.0, "batch_reward": 0.28178313466906546, "critic_loss": 0.5516117455363274, "actor_loss": -32.710275939941404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.983020544052124, "step": 88000}
{"episode_reward": 195.3151881212541, "episode": 89.0, "batch_reward": 0.280360617056489, "critic_loss": 0.5752455235719681, "actor_loss": -32.74063306045532, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.995487928390503, "step": 89000}
{"episode_reward": 220.47424595800837, "episode": 90.0, "batch_reward": 0.2809540539085865, "critic_loss": 0.5488919690102338, "actor_loss": -33.07107117080688, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93448257446289, "step": 90000}
{"episode_reward": 354.65742372948984, "episode": 91.0, "batch_reward": 0.2828790726661682, "critic_loss": 0.5647354616969824, "actor_loss": -32.80736595153809, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.12732172012329, "step": 91000}
{"episode_reward": 563.0498978836733, "episode": 92.0, "batch_reward": 0.2860320123285055, "critic_loss": 0.5415016765445471, "actor_loss": -33.12782607650757, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.997034072875977, "step": 92000}
{"episode_reward": 557.8201398096226, "episode": 93.0, "batch_reward": 0.2882184829860926, "critic_loss": 0.5195534806698561, "actor_loss": -33.11105464172363, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.997463941574097, "step": 93000}
{"episode_reward": 545.0494451139268, "episode": 94.0, "batch_reward": 0.2919064280539751, "critic_loss": 0.5102171004712581, "actor_loss": -33.4826103515625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.990684032440186, "step": 94000}
{"episode_reward": 574.1588385295132, "episode": 95.0, "batch_reward": 0.2937577898055315, "critic_loss": 0.5014339591413737, "actor_loss": -34.03669803619385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97119426727295, "step": 95000}
{"episode_reward": 540.4892200198651, "episode": 96.0, "batch_reward": 0.2960326671004295, "critic_loss": 0.5497716806679964, "actor_loss": -33.994205848693845, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.980390548706055, "step": 96000}
{"episode_reward": 394.0596211125875, "episode": 97.0, "batch_reward": 0.2974505915790796, "critic_loss": 0.5127468219697475, "actor_loss": -34.18885590362549, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96557331085205, "step": 97000}
{"episode_reward": 441.5612591302591, "episode": 98.0, "batch_reward": 0.2981287537366152, "critic_loss": 0.5131715304851532, "actor_loss": -33.986154060363766, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.010650396347046, "step": 98000}
{"episode_reward": 312.4222480869907, "episode": 99.0, "batch_reward": 0.29951736441254617, "critic_loss": 0.5458513158708811, "actor_loss": -34.14146324539185, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.987525701522827, "step": 99000}
{"episode_reward": 558.5838907705494, "episode": 100.0, "batch_reward": 0.3031045204252005, "critic_loss": 0.4576678754091263, "actor_loss": -34.246270503997806, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.958890676498413, "step": 100000}
{"episode_reward": 519.0903200205565, "episode": 101.0, "batch_reward": 0.3038417834341526, "critic_loss": 0.44419310730695727, "actor_loss": -34.695581768035886, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.12230587005615, "step": 101000}
{"episode_reward": 555.9461541263481, "episode": 102.0, "batch_reward": 0.3053691896796227, "critic_loss": 0.48150027115643024, "actor_loss": -34.603110916137695, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.951284885406494, "step": 102000}
{"episode_reward": 544.9413165479335, "episode": 103.0, "batch_reward": 0.30796708101034165, "critic_loss": 0.5076964524239301, "actor_loss": -34.969886806488034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.00441002845764, "step": 103000}
{"episode_reward": 354.28451145197477, "episode": 104.0, "batch_reward": 0.3098150962293148, "critic_loss": 0.45527398079633713, "actor_loss": -34.8589468536377, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.006381034851074, "step": 104000}
{"episode_reward": 519.7780909770256, "episode": 105.0, "batch_reward": 0.3123674579560757, "critic_loss": 0.47159425090253354, "actor_loss": -35.20174906158447, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.974428415298462, "step": 105000}
{"episode_reward": 585.4937151837983, "episode": 106.0, "batch_reward": 0.3135860683768988, "critic_loss": 0.5054735719710588, "actor_loss": -34.963732471466066, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.999178409576416, "step": 106000}
{"episode_reward": 580.9312467863994, "episode": 107.0, "batch_reward": 0.3170611063241959, "critic_loss": 0.46422026051580906, "actor_loss": -35.612477294921874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.012885332107544, "step": 107000}
{"episode_reward": 597.3099156171804, "episode": 108.0, "batch_reward": 0.3168527297079563, "critic_loss": 0.4511312448978424, "actor_loss": -35.58572292327881, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.952373266220093, "step": 108000}
{"episode_reward": 13.779427741444644, "episode": 109.0, "batch_reward": 0.31657330256700517, "critic_loss": 0.4527636473476887, "actor_loss": -35.579936645507814, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.978548765182495, "step": 109000}
{"episode_reward": 575.3920543525215, "episode": 110.0, "batch_reward": 0.3186149251461029, "critic_loss": 0.47106850977241993, "actor_loss": -35.86602948379517, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.0062415599823, "step": 110000}
{"episode_reward": 296.92414417307407, "episode": 111.0, "batch_reward": 0.3182492847442627, "critic_loss": 0.49447873198986053, "actor_loss": -36.06717029571533, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.14626717567444, "step": 111000}
{"episode_reward": 505.1908628326975, "episode": 112.0, "batch_reward": 0.32022277992963794, "critic_loss": 0.4531504789739847, "actor_loss": -35.67590113830566, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.991358280181885, "step": 112000}
{"episode_reward": 554.9602383718102, "episode": 113.0, "batch_reward": 0.3196694971323013, "critic_loss": 0.48006740598380565, "actor_loss": -35.58183023071289, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.984006643295288, "step": 113000}
{"episode_reward": 12.46138579951401, "episode": 114.0, "batch_reward": 0.31957965835928914, "critic_loss": 0.4841969759166241, "actor_loss": -36.114060398101806, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.939904928207397, "step": 114000}
{"episode_reward": 346.25443663724934, "episode": 115.0, "batch_reward": 0.31857465946674346, "critic_loss": 0.5266503002643586, "actor_loss": -35.66273082733154, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95742654800415, "step": 115000}
{"episode_reward": 588.3913608566002, "episode": 116.0, "batch_reward": 0.3226393503546715, "critic_loss": 0.4493612727969885, "actor_loss": -36.13311450195312, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.984091997146606, "step": 116000}
{"episode_reward": 594.5356958694978, "episode": 117.0, "batch_reward": 0.3245728027224541, "critic_loss": 0.45768159845471384, "actor_loss": -35.97335860824585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.958123922348022, "step": 117000}
{"episode_reward": 579.9963839241111, "episode": 118.0, "batch_reward": 0.3265551081299782, "critic_loss": 0.4615639299303293, "actor_loss": -36.35930257034302, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95390748977661, "step": 118000}
{"episode_reward": 623.6165681903024, "episode": 119.0, "batch_reward": 0.3296569454073906, "critic_loss": 0.44381111350655555, "actor_loss": -36.660623863220216, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9919650554657, "step": 119000}
{"episode_reward": 566.4398533763995, "episode": 120.0, "batch_reward": 0.33062024775147436, "critic_loss": 0.4599036203324795, "actor_loss": -36.51421571731567, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97223138809204, "step": 120000}
{"episode_reward": 596.0862757915809, "episode": 121.0, "batch_reward": 0.33428027683496475, "critic_loss": 0.4448011146634817, "actor_loss": -36.98223690414429, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.14809703826904, "step": 121000}
{"episode_reward": 545.9027228477033, "episode": 122.0, "batch_reward": 0.3347035744488239, "critic_loss": 0.4280626347959042, "actor_loss": -37.18067278671265, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.021378993988037, "step": 122000}
{"episode_reward": 555.04654571622, "episode": 123.0, "batch_reward": 0.33782461577653883, "critic_loss": 0.48276509696245196, "actor_loss": -37.125014656066895, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97962236404419, "step": 123000}
{"episode_reward": 597.7972442760833, "episode": 124.0, "batch_reward": 0.33737424391508103, "critic_loss": 0.4667392444908619, "actor_loss": -37.43901724243164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.98877239227295, "step": 124000}
{"episode_reward": 47.07787560459155, "episode": 125.0, "batch_reward": 0.3364150334596634, "critic_loss": 0.5173005452305078, "actor_loss": -36.984166744232176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.99465823173523, "step": 125000}
{"episode_reward": 592.9451311358221, "episode": 126.0, "batch_reward": 0.3386499067544937, "critic_loss": 0.4674737714082003, "actor_loss": -37.67482015609741, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.965880870819092, "step": 126000}
{"episode_reward": 595.9217880993141, "episode": 127.0, "batch_reward": 0.340481735855341, "critic_loss": 0.445711947247386, "actor_loss": -37.75135153198242, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.987404584884644, "step": 127000}
{"episode_reward": 568.20861047373, "episode": 128.0, "batch_reward": 0.3423983522951603, "critic_loss": 0.5112203246355057, "actor_loss": -37.918344970703124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97429132461548, "step": 128000}
{"episode_reward": 602.952189400291, "episode": 129.0, "batch_reward": 0.3429474056661129, "critic_loss": 0.46812223364412786, "actor_loss": -38.04809362411499, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.975623846054077, "step": 129000}
{"episode_reward": 328.73408229288725, "episode": 130.0, "batch_reward": 0.3431099545657635, "critic_loss": 0.49886495804786685, "actor_loss": -37.87535516738892, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.977181434631348, "step": 130000}
{"episode_reward": 79.58791670075571, "episode": 131.0, "batch_reward": 0.34173452189564707, "critic_loss": 0.5412066576480865, "actor_loss": -37.8002656326294, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.13914704322815, "step": 131000}
{"episode_reward": 61.68200263281264, "episode": 132.0, "batch_reward": 0.341029503852129, "critic_loss": 0.48603757144510745, "actor_loss": -37.55588575744629, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.005091667175293, "step": 132000}
{"episode_reward": 557.4709604522106, "episode": 133.0, "batch_reward": 0.3415555489063263, "critic_loss": 0.5083407629728317, "actor_loss": -37.899356784820554, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.983127117156982, "step": 133000}
{"episode_reward": 592.3890774791709, "episode": 134.0, "batch_reward": 0.3437295027077198, "critic_loss": 0.54893207103014, "actor_loss": -38.174737285614015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.008103370666504, "step": 134000}
{"episode_reward": 597.1738026784369, "episode": 135.0, "batch_reward": 0.3460016060769558, "critic_loss": 0.5042065991908312, "actor_loss": -38.21537588882446, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.3352632522583, "step": 135000}
{"episode_reward": 569.372165457917, "episode": 136.0, "batch_reward": 0.3475167438983917, "critic_loss": 0.5164212462008, "actor_loss": -38.384969989776614, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.336060285568237, "step": 136000}
{"episode_reward": 580.8672130540359, "episode": 137.0, "batch_reward": 0.34820822536945345, "critic_loss": 0.5620664169341326, "actor_loss": -38.12880516815186, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.01918387413025, "step": 137000}
{"episode_reward": 317.65625368603156, "episode": 138.0, "batch_reward": 0.3494336716532707, "critic_loss": 0.5934799892902374, "actor_loss": -38.13662001037598, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.133336544036865, "step": 138000}
{"episode_reward": 591.9582099861501, "episode": 139.0, "batch_reward": 0.34896165183186534, "critic_loss": 0.5360435374230147, "actor_loss": -38.17984315109253, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.991291761398315, "step": 139000}
{"episode_reward": 603.4240086240665, "episode": 140.0, "batch_reward": 0.35264566880464554, "critic_loss": 0.5331302493065596, "actor_loss": -38.2928299331665, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.01818823814392, "step": 140000}
{"episode_reward": 541.70464522696, "episode": 141.0, "batch_reward": 0.35233524012565615, "critic_loss": 0.5159294743537903, "actor_loss": -38.21585079956055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.68636417388916, "step": 141000}
{"episode_reward": 624.3651491381042, "episode": 142.0, "batch_reward": 0.3550615092515945, "critic_loss": 0.5246575036346912, "actor_loss": -38.889646907806394, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.42002558708191, "step": 142000}
{"episode_reward": 574.7851302892551, "episode": 143.0, "batch_reward": 0.35781151136755945, "critic_loss": 0.5278355576992035, "actor_loss": -38.84946166992187, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.1527259349823, "step": 143000}
{"episode_reward": 605.1633617743524, "episode": 144.0, "batch_reward": 0.3575843547284603, "critic_loss": 0.5166778867840767, "actor_loss": -39.110825435638425, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.217286586761475, "step": 144000}
{"episode_reward": 25.532735144460787, "episode": 145.0, "batch_reward": 0.35798806270956995, "critic_loss": 0.5048261896669864, "actor_loss": -38.98192598342896, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.4544620513916, "step": 145000}
{"episode_reward": 622.2377151785619, "episode": 146.0, "batch_reward": 0.35838201534748076, "critic_loss": 0.5076654656380415, "actor_loss": -39.28071733856201, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.56057572364807, "step": 146000}
{"episode_reward": 565.4308161075309, "episode": 147.0, "batch_reward": 0.35886670687794686, "critic_loss": 0.5000468809604645, "actor_loss": -39.167906665802, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.166717052459717, "step": 147000}
{"episode_reward": 612.3152020156448, "episode": 148.0, "batch_reward": 0.3622084051370621, "critic_loss": 0.5391449373662471, "actor_loss": -39.451819141387936, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.067373037338257, "step": 148000}
{"episode_reward": 619.7816303419536, "episode": 149.0, "batch_reward": 0.36431924560666085, "critic_loss": 0.5080907199680805, "actor_loss": -39.71330392456055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.54424500465393, "step": 149000}
{"episode_reward": 633.0473482814912, "episode": 150.0, "batch_reward": 0.3664241009056568, "critic_loss": 0.5241913676261902, "actor_loss": -39.91419261932373, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
