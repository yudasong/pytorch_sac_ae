{"episode_reward": 0.0, "episode": 1.0, "duration": 17.493937253952026, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.5095534324645996, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2827450761490164, "critic_loss": 0.1391620425958958, "actor_loss": -47.06166720075481, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 62.05238080024719, "step": 3000}
{"episode_reward": 44.002245403570136, "episode": 4.0, "batch_reward": 0.215147030338645, "critic_loss": 0.2271773920468986, "actor_loss": -37.98647897338867, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.042813062667847, "step": 4000}
{"episode_reward": 226.8134008896027, "episode": 5.0, "batch_reward": 0.19821320345997812, "critic_loss": 0.14886985881626605, "actor_loss": -35.84656409835815, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.050985097885132, "step": 5000}
{"episode_reward": 84.5938729023013, "episode": 6.0, "batch_reward": 0.18188902017474173, "critic_loss": 0.1792517916560173, "actor_loss": -34.80987830734253, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.392812252044678, "step": 6000}
{"episode_reward": 91.1511734257175, "episode": 7.0, "batch_reward": 0.17369789443910122, "critic_loss": 0.19065805783122777, "actor_loss": -33.50652616119385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.20114755630493, "step": 7000}
{"episode_reward": 206.43492919277, "episode": 8.0, "batch_reward": 0.18487094925343991, "critic_loss": 0.21126443658024072, "actor_loss": -33.855827606201174, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.47804021835327, "step": 8000}
{"episode_reward": 261.82079930985054, "episode": 9.0, "batch_reward": 0.19010359908640384, "critic_loss": 0.22583815040439367, "actor_loss": -34.61422245025635, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.322185277938843, "step": 9000}
{"episode_reward": 308.333946739031, "episode": 10.0, "batch_reward": 0.2013476386666298, "critic_loss": 0.24986190836131572, "actor_loss": -35.02299876785278, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.27370595932007, "step": 10000}
{"episode_reward": 119.69054546700207, "episode": 11.0, "batch_reward": 0.19084298087656498, "critic_loss": 0.3101619917303324, "actor_loss": -33.45732461547851, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.721516132354736, "step": 11000}
{"episode_reward": 148.32315382252932, "episode": 12.0, "batch_reward": 0.19662659618258477, "critic_loss": 0.30091367222368715, "actor_loss": -33.586044193267824, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.140114545822144, "step": 12000}
{"episode_reward": 361.9236784933592, "episode": 13.0, "batch_reward": 0.20063380363583566, "critic_loss": 0.2835496220588684, "actor_loss": -33.17583567810058, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.063061237335205, "step": 13000}
{"episode_reward": 76.44504377213687, "episode": 14.0, "batch_reward": 0.1984260639846325, "critic_loss": 0.31639504550397396, "actor_loss": -32.28711975479126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.730236768722534, "step": 14000}
{"episode_reward": 384.08159683880245, "episode": 15.0, "batch_reward": 0.20867883269488813, "critic_loss": 0.3086105474382639, "actor_loss": -33.65052047348023, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.490116596221924, "step": 15000}
{"episode_reward": 260.88992270552956, "episode": 16.0, "batch_reward": 0.21640976388752461, "critic_loss": 0.2863789812475443, "actor_loss": -33.7336131362915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.39271855354309, "step": 16000}
{"episode_reward": 454.7598013217171, "episode": 17.0, "batch_reward": 0.22504851523041725, "critic_loss": 0.2841784432381392, "actor_loss": -33.90024154663086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.089626789093018, "step": 17000}
{"episode_reward": 112.54215721691884, "episode": 18.0, "batch_reward": 0.2225111880749464, "critic_loss": 0.2788537818044424, "actor_loss": -33.27039809036255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.331445932388306, "step": 18000}
{"episode_reward": 385.51924931065787, "episode": 19.0, "batch_reward": 0.23316204479336738, "critic_loss": 0.28668924105167387, "actor_loss": -33.945820621490476, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.181945085525513, "step": 19000}
{"episode_reward": 451.0210779936654, "episode": 20.0, "batch_reward": 0.24435550087690353, "critic_loss": 0.28509658947587013, "actor_loss": -35.200197116851804, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.995787143707275, "step": 20000}
{"episode_reward": 429.206540634012, "episode": 21.0, "batch_reward": 0.2524666575193405, "critic_loss": 0.2985457402020693, "actor_loss": -35.70616255569458, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.79828977584839, "step": 21000}
{"episode_reward": 302.2174495741108, "episode": 22.0, "batch_reward": 0.2564513863325119, "critic_loss": 0.3066554012149572, "actor_loss": -35.340672065734864, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.15566396713257, "step": 22000}
{"episode_reward": 448.94879946518745, "episode": 23.0, "batch_reward": 0.26044721204042437, "critic_loss": 0.3269870976358652, "actor_loss": -35.36726720046997, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.013768434524536, "step": 23000}
{"episode_reward": 130.81275045382242, "episode": 24.0, "batch_reward": 0.26028260827064514, "critic_loss": 0.40840365743637086, "actor_loss": -35.236540100097656, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.519548892974854, "step": 24000}
{"episode_reward": 508.3313205567487, "episode": 25.0, "batch_reward": 0.27042768163979053, "critic_loss": 0.755173032656312, "actor_loss": -35.845333183288574, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.19553780555725, "step": 25000}
{"episode_reward": 506.17140985538094, "episode": 26.0, "batch_reward": 0.27714087009429933, "critic_loss": 1.9856917659640312, "actor_loss": -36.58365618515015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.00277614593506, "step": 26000}
{"episode_reward": 503.1393665416326, "episode": 27.0, "batch_reward": 0.28553498154878615, "critic_loss": 5.693916480243206, "actor_loss": -37.67505499267578, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.188657760620117, "step": 27000}
{"episode_reward": 227.58398645379353, "episode": 28.0, "batch_reward": 0.28020115867257117, "critic_loss": 9.606267145335675, "actor_loss": -37.402001247406005, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.362457990646362, "step": 28000}
{"episode_reward": 84.13604915334233, "episode": 29.0, "batch_reward": 0.27344698236882686, "critic_loss": 30.50658572411537, "actor_loss": -38.42194129943848, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.36632227897644, "step": 29000}
{"episode_reward": 51.452670766450325, "episode": 30.0, "batch_reward": 0.2644472586363554, "critic_loss": 71.91721823215485, "actor_loss": -45.33352349853516, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.05921745300293, "step": 30000}
{"episode_reward": 38.84551332748872, "episode": 31.0, "batch_reward": 0.2576751140356064, "critic_loss": 110.31067752075195, "actor_loss": -59.27961003112793, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.08590865135193, "step": 31000}
{"episode_reward": 15.768345521828433, "episode": 32.0, "batch_reward": 0.24892268189787864, "critic_loss": 125.4061202507019, "actor_loss": -72.04332730102539, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.1651291847229, "step": 32000}
{"episode_reward": 27.34537788774915, "episode": 33.0, "batch_reward": 0.2418913896083832, "critic_loss": 113.96241427993775, "actor_loss": -80.6532407836914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07209587097168, "step": 33000}
{"episode_reward": 26.9534075520119, "episode": 34.0, "batch_reward": 0.23589555794000625, "critic_loss": 97.18625217819213, "actor_loss": -94.46476117324829, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.221712112426758, "step": 34000}
{"episode_reward": 56.70015849411096, "episode": 35.0, "batch_reward": 0.2303518280237913, "critic_loss": 93.35731650161743, "actor_loss": -90.90879674911498, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.8175151348114, "step": 35000}
{"episode_reward": 30.64765221749821, "episode": 36.0, "batch_reward": 0.2243820889443159, "critic_loss": 81.15292581176757, "actor_loss": -104.94756228256226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.078325986862183, "step": 36000}
{"episode_reward": 14.577276913209376, "episode": 37.0, "batch_reward": 0.2188817064613104, "critic_loss": 69.16750649642944, "actor_loss": -102.62529485321045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.34472370147705, "step": 37000}
{"episode_reward": 23.750991163562446, "episode": 38.0, "batch_reward": 0.21477238400280477, "critic_loss": 62.05899114608765, "actor_loss": -101.92688524627685, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.394503593444824, "step": 38000}
{"episode_reward": 56.17049931729244, "episode": 39.0, "batch_reward": 0.2100816766768694, "critic_loss": 58.451449642181394, "actor_loss": -97.05114443588256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.204899072647095, "step": 39000}
{"episode_reward": 34.44903781698575, "episode": 40.0, "batch_reward": 0.20550594986975193, "critic_loss": 54.66697604179382, "actor_loss": -98.55874076843261, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9859356880188, "step": 40000}
{"episode_reward": 16.945370735564904, "episode": 41.0, "batch_reward": 0.20307839627563953, "critic_loss": 50.99253500366211, "actor_loss": -97.52809338378906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.61840033531189, "step": 41000}
{"episode_reward": 86.4891818962558, "episode": 42.0, "batch_reward": 0.198965921536088, "critic_loss": 47.57888842773438, "actor_loss": -99.78450054550171, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.063536882400513, "step": 42000}
{"episode_reward": 67.48251374318926, "episode": 43.0, "batch_reward": 0.1975628063082695, "critic_loss": 46.67013801574707, "actor_loss": -99.10993601226807, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.653481006622314, "step": 43000}
{"episode_reward": 330.8275996889783, "episode": 44.0, "batch_reward": 0.2010090795904398, "critic_loss": 44.71820647621155, "actor_loss": -103.70788051223755, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.368703365325928, "step": 44000}
{"episode_reward": 386.02121347958723, "episode": 45.0, "batch_reward": 0.20143012154102324, "critic_loss": 42.30575952720642, "actor_loss": -96.3906346282959, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.02696394920349, "step": 45000}
{"episode_reward": 4.888882844695919, "episode": 46.0, "batch_reward": 0.1970649831146002, "critic_loss": 38.03161536026001, "actor_loss": -100.255177192688, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.06364417076111, "step": 46000}
{"episode_reward": 16.540139106637703, "episode": 47.0, "batch_reward": 0.19393036212027073, "critic_loss": 33.43273244285584, "actor_loss": -99.75626015472412, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.187451124191284, "step": 47000}
{"episode_reward": 5.334756533762935, "episode": 48.0, "batch_reward": 0.19008067589253186, "critic_loss": 28.872560181617736, "actor_loss": -103.22136919403076, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.45516061782837, "step": 48000}
{"episode_reward": 7.843195136778799, "episode": 49.0, "batch_reward": 0.18581641598045825, "critic_loss": 24.054824484825133, "actor_loss": -95.05411967849732, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.47864580154419, "step": 49000}
{"episode_reward": 9.26419652298957, "episode": 50.0, "batch_reward": 0.1823369015455246, "critic_loss": 20.278334303855896, "actor_loss": -95.56853371810914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.03515338897705, "step": 50000}
{"episode_reward": 37.614428454113074, "episode": 51.0, "batch_reward": 0.18005598838627337, "critic_loss": 17.8325908536911, "actor_loss": -97.46374600219727, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.79570960998535, "step": 51000}
{"episode_reward": 7.713668894648357, "episode": 52.0, "batch_reward": 0.17638650242984294, "critic_loss": 15.2833834066391, "actor_loss": -87.80482371139526, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.05334711074829, "step": 52000}
{"episode_reward": 53.291016763810426, "episode": 53.0, "batch_reward": 0.1767214466035366, "critic_loss": 13.660349268436432, "actor_loss": -90.33262395095825, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.70341444015503, "step": 53000}
{"episode_reward": 311.49196596581544, "episode": 54.0, "batch_reward": 0.17825177465379238, "critic_loss": 12.06675599861145, "actor_loss": -86.18184841537476, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.227119207382202, "step": 54000}
{"episode_reward": 254.2304203300017, "episode": 55.0, "batch_reward": 0.17721134246885775, "critic_loss": 10.256587436676025, "actor_loss": -87.61059827804566, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.467315435409546, "step": 55000}
{"episode_reward": 103.40289169845614, "episode": 56.0, "batch_reward": 0.1763985947817564, "critic_loss": 8.701039673328399, "actor_loss": -80.41931986999512, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.034566164016724, "step": 56000}
{"episode_reward": 103.86913300534528, "episode": 57.0, "batch_reward": 0.17772940154373645, "critic_loss": 8.223976841926575, "actor_loss": -82.13223720169067, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.352364778518677, "step": 57000}
{"episode_reward": 234.90690114046987, "episode": 58.0, "batch_reward": 0.17966390642523766, "critic_loss": 7.746676931858063, "actor_loss": -82.6453316078186, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.10204243659973, "step": 58000}
{"episode_reward": 462.03189648625556, "episode": 59.0, "batch_reward": 0.1847289981395006, "critic_loss": 7.4180949387550355, "actor_loss": -81.90444692611695, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.020159244537354, "step": 59000}
{"episode_reward": 395.2267051814349, "episode": 60.0, "batch_reward": 0.18804791264235973, "critic_loss": 7.0106120707988735, "actor_loss": -76.25539319229127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.873143911361694, "step": 60000}
{"episode_reward": 481.7380591168941, "episode": 61.0, "batch_reward": 0.1931266011893749, "critic_loss": 5.729828510284424, "actor_loss": -76.42381597137451, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.821500301361084, "step": 61000}
{"episode_reward": 429.10911163131476, "episode": 62.0, "batch_reward": 0.19640207992494108, "critic_loss": 5.144985876321792, "actor_loss": -75.98490231323242, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.04540991783142, "step": 62000}
{"episode_reward": 431.4604411804737, "episode": 63.0, "batch_reward": 0.19938600021600722, "critic_loss": 4.634898007154464, "actor_loss": -74.74524741363525, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.985960245132446, "step": 63000}
{"episode_reward": 435.619227032315, "episode": 64.0, "batch_reward": 0.20390503153204917, "critic_loss": 4.103709004640579, "actor_loss": -72.08574584960938, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.27435564994812, "step": 64000}
{"episode_reward": 478.9278704376666, "episode": 65.0, "batch_reward": 0.20771267437934876, "critic_loss": 3.770142625927925, "actor_loss": -71.26898710250855, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.138236045837402, "step": 65000}
{"episode_reward": 304.9878681913919, "episode": 66.0, "batch_reward": 0.209672012925148, "critic_loss": 3.524832604646683, "actor_loss": -68.22066636657715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.32073450088501, "step": 66000}
{"episode_reward": 445.17207327750725, "episode": 67.0, "batch_reward": 0.21172124926745892, "critic_loss": 3.224791907310486, "actor_loss": -63.92456348800659, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.285831451416016, "step": 67000}
{"episode_reward": 222.43953684752609, "episode": 68.0, "batch_reward": 0.21342541880905627, "critic_loss": 3.0095335450172422, "actor_loss": -66.40135683441162, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.104893922805786, "step": 68000}
{"episode_reward": 377.4923760553741, "episode": 69.0, "batch_reward": 0.21385399827361107, "critic_loss": 2.7985095620155334, "actor_loss": -63.190517307281496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.046145915985107, "step": 69000}
{"episode_reward": 105.39218876626896, "episode": 70.0, "batch_reward": 0.21434216791391372, "critic_loss": 2.555903397679329, "actor_loss": -60.5080931892395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.16947340965271, "step": 70000}
{"episode_reward": 318.2465049820182, "episode": 71.0, "batch_reward": 0.21549866873025894, "critic_loss": 2.570241189599037, "actor_loss": -61.14166597366333, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.7570858001709, "step": 71000}
{"episode_reward": 152.74871530789017, "episode": 72.0, "batch_reward": 0.21537456959486007, "critic_loss": 2.4465613211393356, "actor_loss": -59.01643920135498, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.036773920059204, "step": 72000}
{"episode_reward": 526.5500654537828, "episode": 73.0, "batch_reward": 0.21971846167743206, "critic_loss": 2.5821323076486586, "actor_loss": -58.34227635574341, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.829560041427612, "step": 73000}
{"episode_reward": 347.8503573474483, "episode": 74.0, "batch_reward": 0.22085696294903756, "critic_loss": 2.318743967652321, "actor_loss": -55.44350629425049, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.627589464187622, "step": 74000}
{"episode_reward": 173.9340577400217, "episode": 75.0, "batch_reward": 0.2194153936058283, "critic_loss": 2.4501433602571487, "actor_loss": -53.41138386917114, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.653754234313965, "step": 75000}
{"episode_reward": 135.4085755912678, "episode": 76.0, "batch_reward": 0.21919968383014202, "critic_loss": 2.357176461815834, "actor_loss": -52.684355991363525, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.814105987548828, "step": 76000}
{"episode_reward": 476.4418391564664, "episode": 77.0, "batch_reward": 0.22149763950705528, "critic_loss": 2.295706168949604, "actor_loss": -51.95422562789917, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.446383476257324, "step": 77000}
{"episode_reward": 155.46920806961577, "episode": 78.0, "batch_reward": 0.22195256704092026, "critic_loss": 2.538868598759174, "actor_loss": -49.95602161407471, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.26755142211914, "step": 78000}
{"episode_reward": 378.85845519908383, "episode": 79.0, "batch_reward": 0.2238440204113722, "critic_loss": 2.2936392037272455, "actor_loss": -51.82576927566528, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.037597179412842, "step": 79000}
{"episode_reward": 320.7164809667597, "episode": 80.0, "batch_reward": 0.22504600156843663, "critic_loss": 2.2147334257364273, "actor_loss": -49.32157375335694, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.2087299823761, "step": 80000}
{"episode_reward": 557.5775977749648, "episode": 81.0, "batch_reward": 0.22857596825063228, "critic_loss": 2.2213381468653677, "actor_loss": -48.66868295288086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.453006982803345, "step": 81000}
{"episode_reward": 541.0452702166125, "episode": 82.0, "batch_reward": 0.23465043199062346, "critic_loss": 2.199459020137787, "actor_loss": -46.9057253036499, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.24611806869507, "step": 82000}
{"episode_reward": 505.9134043396371, "episode": 83.0, "batch_reward": 0.23761966444551944, "critic_loss": 2.3820178616046905, "actor_loss": -47.856412757873535, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.454476356506348, "step": 83000}
{"episode_reward": 529.7049130032401, "episode": 84.0, "batch_reward": 0.23953113101422788, "critic_loss": 2.641706736564636, "actor_loss": -46.079381732940675, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.784783363342285, "step": 84000}
{"episode_reward": 459.7037758972715, "episode": 85.0, "batch_reward": 0.24281256498396397, "critic_loss": 2.7990216205716134, "actor_loss": -46.15566851043701, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.37472367286682, "step": 85000}
{"episode_reward": 546.6642094553536, "episode": 86.0, "batch_reward": 0.24664339527487755, "critic_loss": 3.060828449189663, "actor_loss": -46.90788595962525, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.38154101371765, "step": 86000}
{"episode_reward": 514.5758512672778, "episode": 87.0, "batch_reward": 0.24932727390527726, "critic_loss": 3.652905056476593, "actor_loss": -45.831654006958004, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.935681104660034, "step": 87000}
{"episode_reward": 493.1602209433244, "episode": 88.0, "batch_reward": 0.2515271403938532, "critic_loss": 5.179360191702843, "actor_loss": -46.060129161834716, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.73917508125305, "step": 88000}
{"episode_reward": 498.8642744364706, "episode": 89.0, "batch_reward": 0.25297626812756063, "critic_loss": 10.330894044399262, "actor_loss": -46.451967933654785, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.014055013656616, "step": 89000}
{"episode_reward": 5.6866609252348415, "episode": 90.0, "batch_reward": 0.2497885209918022, "critic_loss": 16.902963377952577, "actor_loss": -47.28311737060547, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.053648233413696, "step": 90000}
{"episode_reward": 6.826764524408037, "episode": 91.0, "batch_reward": 0.24759655268490313, "critic_loss": 24.455384846687316, "actor_loss": -50.45879944610596, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.66491746902466, "step": 91000}
{"episode_reward": 5.439478010675425, "episode": 92.0, "batch_reward": 0.2440816398859024, "critic_loss": 30.953610553741456, "actor_loss": -53.583902591705325, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.89468765258789, "step": 92000}
{"episode_reward": 7.692172091312526, "episode": 93.0, "batch_reward": 0.24179645639657973, "critic_loss": 35.45404277610779, "actor_loss": -58.581182628631595, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.583020448684692, "step": 93000}
{"episode_reward": 4.561435146675977, "episode": 94.0, "batch_reward": 0.2395490691959858, "critic_loss": 34.01496407699585, "actor_loss": -64.3938469581604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.63404870033264, "step": 94000}
{"episode_reward": 6.825901013604296, "episode": 95.0, "batch_reward": 0.2369291233867407, "critic_loss": 31.055637180328368, "actor_loss": -66.15739906311035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.931806564331055, "step": 95000}
{"episode_reward": 8.994298461356497, "episode": 96.0, "batch_reward": 0.23354262925684452, "critic_loss": 25.527134965896607, "actor_loss": -69.78724334335327, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.03249192237854, "step": 96000}
{"episode_reward": 20.15797073158368, "episode": 97.0, "batch_reward": 0.2319784370213747, "critic_loss": 21.19880779361725, "actor_loss": -70.37127802658081, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.232975482940674, "step": 97000}
{"episode_reward": 71.58969221543936, "episode": 98.0, "batch_reward": 0.23124949239194392, "critic_loss": 17.68497386932373, "actor_loss": -74.29407693481446, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.99403691291809, "step": 98000}
{"episode_reward": 79.94549519421548, "episode": 99.0, "batch_reward": 0.22897451403737068, "critic_loss": 14.534196632862091, "actor_loss": -73.59618344116211, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.101271390914917, "step": 99000}
{"episode_reward": 87.9848853423015, "episode": 100.0, "batch_reward": 0.22712712325155734, "critic_loss": 11.840604882240296, "actor_loss": -75.32090492248535, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.55878973007202, "step": 100000}
{"episode_reward": 83.45949605311911, "episode": 101.0, "batch_reward": 0.2268511919826269, "critic_loss": 10.095803692817688, "actor_loss": -72.68793789672851, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.6204559803009, "step": 101000}
{"episode_reward": 105.2117636320675, "episode": 102.0, "batch_reward": 0.22599853663146496, "critic_loss": 8.34168820142746, "actor_loss": -73.13317224884034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.61591601371765, "step": 102000}
{"episode_reward": 168.7775433114855, "episode": 103.0, "batch_reward": 0.22428298656642437, "critic_loss": 6.991949506521225, "actor_loss": -72.5115763092041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.875081539154053, "step": 103000}
{"episode_reward": 44.93041335773703, "episode": 104.0, "batch_reward": 0.22439156599342824, "critic_loss": 5.704267527580261, "actor_loss": -70.28692375946045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.86768364906311, "step": 104000}
{"episode_reward": 266.069814484367, "episode": 105.0, "batch_reward": 0.22467388470470906, "critic_loss": 4.933731264352798, "actor_loss": -69.61043809509277, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.804181337356567, "step": 105000}
{"episode_reward": 254.54891526162612, "episode": 106.0, "batch_reward": 0.22459257338941097, "critic_loss": 4.101920701742173, "actor_loss": -69.00181272125243, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.623560190200806, "step": 106000}
{"episode_reward": 298.8058007028221, "episode": 107.0, "batch_reward": 0.22561086963117122, "critic_loss": 3.697242770791054, "actor_loss": -68.3684591369629, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.729987144470215, "step": 107000}
{"episode_reward": 376.0150503792374, "episode": 108.0, "batch_reward": 0.22642347200214863, "critic_loss": 3.3653845117092134, "actor_loss": -66.06138807678222, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.960996866226196, "step": 108000}
{"episode_reward": 381.51560478945174, "episode": 109.0, "batch_reward": 0.22852897396683694, "critic_loss": 3.0500360625982283, "actor_loss": -62.93816205596924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.151482105255127, "step": 109000}
{"episode_reward": 397.47241104091694, "episode": 110.0, "batch_reward": 0.230390910461545, "critic_loss": 2.5880013850927353, "actor_loss": -62.95963272857666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.562129497528076, "step": 110000}
{"episode_reward": 409.58057220201533, "episode": 111.0, "batch_reward": 0.23068788103759288, "critic_loss": 2.3076347294449806, "actor_loss": -60.6696834564209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.61859941482544, "step": 111000}
{"episode_reward": 396.7038624099681, "episode": 112.0, "batch_reward": 0.2333534183204174, "critic_loss": 2.318145015180111, "actor_loss": -60.99766641235352, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.128674507141113, "step": 112000}
{"episode_reward": 459.5361714764028, "episode": 113.0, "batch_reward": 0.23474049997329713, "critic_loss": 2.1297064391970633, "actor_loss": -60.2705802154541, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.884244203567505, "step": 113000}
{"episode_reward": 433.30192246050024, "episode": 114.0, "batch_reward": 0.23659687225520612, "critic_loss": 1.925918803870678, "actor_loss": -56.10624198913574, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.55129647254944, "step": 114000}
{"episode_reward": 436.986581887302, "episode": 115.0, "batch_reward": 0.23958250258862973, "critic_loss": 1.7447319256663323, "actor_loss": -56.51948006439209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.010884523391724, "step": 115000}
{"episode_reward": 509.837319295732, "episode": 116.0, "batch_reward": 0.24150850416719913, "critic_loss": 1.4899685512185097, "actor_loss": -54.62957762145996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.370697021484375, "step": 116000}
{"episode_reward": 535.9725473000087, "episode": 117.0, "batch_reward": 0.24446347381174566, "critic_loss": 1.4796469261050225, "actor_loss": -55.86309561920166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.16268277168274, "step": 117000}
{"episode_reward": 534.5118325713418, "episode": 118.0, "batch_reward": 0.2458398103415966, "critic_loss": 1.229083848953247, "actor_loss": -53.15728216552734, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.078009366989136, "step": 118000}
{"episode_reward": 525.0392366294498, "episode": 119.0, "batch_reward": 0.24804521353542805, "critic_loss": 1.1794560225605966, "actor_loss": -52.180949645996094, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.02920126914978, "step": 119000}
{"episode_reward": 529.8262592822094, "episode": 120.0, "batch_reward": 0.25036161522567274, "critic_loss": 1.0986878077089786, "actor_loss": -52.10277515411377, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.19455337524414, "step": 120000}
{"episode_reward": 506.45597784461927, "episode": 121.0, "batch_reward": 0.2533734969347715, "critic_loss": 1.0589542849957942, "actor_loss": -51.32087441253662, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.089531898498535, "step": 121000}
{"episode_reward": 517.1831506950587, "episode": 122.0, "batch_reward": 0.25488941664993764, "critic_loss": 0.9708497566282749, "actor_loss": -50.383067474365234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.200220823287964, "step": 122000}
{"episode_reward": 591.4845630603782, "episode": 123.0, "batch_reward": 0.25865075464546683, "critic_loss": 0.9259483515322209, "actor_loss": -51.031033126831055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.769577026367188, "step": 123000}
{"episode_reward": 512.2185188550733, "episode": 124.0, "batch_reward": 0.2599447469413281, "critic_loss": 0.8827803846597672, "actor_loss": -49.22440259552002, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.945547103881836, "step": 124000}
{"episode_reward": 468.3182120013523, "episode": 125.0, "batch_reward": 0.26233452731370926, "critic_loss": 0.8566358342170716, "actor_loss": -48.9335463104248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.024250030517578, "step": 125000}
{"episode_reward": 553.3619462443912, "episode": 126.0, "batch_reward": 0.264264630228281, "critic_loss": 0.8876833964884281, "actor_loss": -47.79067625427246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.725452423095703, "step": 126000}
{"episode_reward": 542.0969473405436, "episode": 127.0, "batch_reward": 0.2670484940856695, "critic_loss": 0.8894857508540154, "actor_loss": -47.47761570739746, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.215157985687256, "step": 127000}
{"episode_reward": 397.01896454068856, "episode": 128.0, "batch_reward": 0.26669757583737375, "critic_loss": 0.9027071328759193, "actor_loss": -46.726521980285646, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.085145950317383, "step": 128000}
{"episode_reward": 466.6151554974583, "episode": 129.0, "batch_reward": 0.2679778283238411, "critic_loss": 0.8782163967490196, "actor_loss": -46.02712830352783, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.08220148086548, "step": 129000}
{"episode_reward": 534.3567141891743, "episode": 130.0, "batch_reward": 0.2713500390946865, "critic_loss": 0.8823125154078006, "actor_loss": -45.61130732727051, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.45923614501953, "step": 130000}
{"episode_reward": 553.1471381527001, "episode": 131.0, "batch_reward": 0.2742054085433483, "critic_loss": 0.8340190040767193, "actor_loss": -45.1864888381958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.10121417045593, "step": 131000}
{"episode_reward": 501.6595491343307, "episode": 132.0, "batch_reward": 0.27612858763337134, "critic_loss": 0.8244231899976731, "actor_loss": -44.80763627624512, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.93861150741577, "step": 132000}
{"episode_reward": 496.34248617574485, "episode": 133.0, "batch_reward": 0.27695510897040365, "critic_loss": 0.8315638563930988, "actor_loss": -44.56022439575195, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.43106985092163, "step": 133000}
{"episode_reward": 550.4116065085436, "episode": 134.0, "batch_reward": 0.27868882335722445, "critic_loss": 0.8672416340708733, "actor_loss": -44.07197811126709, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.77409029006958, "step": 134000}
{"episode_reward": 530.7396101334265, "episode": 135.0, "batch_reward": 0.28045929488539695, "critic_loss": 0.9129819525778293, "actor_loss": -43.753002685546875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.23882031440735, "step": 135000}
{"episode_reward": 550.9946916097161, "episode": 136.0, "batch_reward": 0.28250378945469856, "critic_loss": 0.906621594697237, "actor_loss": -43.5338696975708, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.44724178314209, "step": 136000}
{"episode_reward": 573.4204880228283, "episode": 137.0, "batch_reward": 0.284344864025712, "critic_loss": 0.9372043256163597, "actor_loss": -43.46220797729492, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.853177309036255, "step": 137000}
{"episode_reward": 555.685739568559, "episode": 138.0, "batch_reward": 0.2863816634714603, "critic_loss": 0.9101601261496544, "actor_loss": -43.20414500427246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.841413021087646, "step": 138000}
{"episode_reward": 428.01561528947116, "episode": 139.0, "batch_reward": 0.28814905864000323, "critic_loss": 0.936468026548624, "actor_loss": -42.923178245544435, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.629924297332764, "step": 139000}
{"episode_reward": 586.3293112155803, "episode": 140.0, "batch_reward": 0.29043675453960893, "critic_loss": 0.8769791746139526, "actor_loss": -42.75768772125244, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.555509090423584, "step": 140000}
{"episode_reward": 542.5695182015096, "episode": 141.0, "batch_reward": 0.29099505373835566, "critic_loss": 0.8587861877679824, "actor_loss": -42.42102048492432, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.431312084198, "step": 141000}
{"episode_reward": 582.8669335670781, "episode": 142.0, "batch_reward": 0.29248903574049473, "critic_loss": 0.8017005693018436, "actor_loss": -42.345602500915525, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.224711656570435, "step": 142000}
{"episode_reward": 592.5906424566276, "episode": 143.0, "batch_reward": 0.2968650580495596, "critic_loss": 0.8041549807786942, "actor_loss": -42.22747556304932, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.264710187911987, "step": 143000}
{"episode_reward": 599.4875200158539, "episode": 144.0, "batch_reward": 0.298010377779603, "critic_loss": 0.7844269274175167, "actor_loss": -42.08795126342773, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.84931468963623, "step": 144000}
{"episode_reward": 574.1836198431545, "episode": 145.0, "batch_reward": 0.30086142997443677, "critic_loss": 0.7903536399304867, "actor_loss": -41.970554588317874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.857545375823975, "step": 145000}
{"episode_reward": 613.9081849400936, "episode": 146.0, "batch_reward": 0.30216674686968326, "critic_loss": 0.7632654765844346, "actor_loss": -41.84718305206299, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.266568422317505, "step": 146000}
{"episode_reward": 590.2421631135575, "episode": 147.0, "batch_reward": 0.30371411800384523, "critic_loss": 0.729913021594286, "actor_loss": -41.68819610595703, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.788617849349976, "step": 147000}
{"episode_reward": 573.5743985966818, "episode": 148.0, "batch_reward": 0.3063697408437729, "critic_loss": 0.7311987989246845, "actor_loss": -41.548115768432616, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.633299350738525, "step": 148000}
{"episode_reward": 540.4073158920268, "episode": 149.0, "batch_reward": 0.3082173769772053, "critic_loss": 0.6672467056214809, "actor_loss": -41.546381729125976, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.53837823867798, "step": 149000}
{"episode_reward": 617.9319840289629, "episode": 150.0, "batch_reward": 0.31091831023991107, "critic_loss": 0.6231402310431003, "actor_loss": -41.64259456634522, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
