{"episode_reward": 0.0, "episode": 1.0, "duration": 17.65622854232788, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.4924736022949219, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.280520388253453, "critic_loss": 0.026489868582322294, "actor_loss": -30.75644312956098, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 62.5068883895874, "step": 3000}
{"episode_reward": 42.51220267670389, "episode": 4.0, "batch_reward": 0.1879177897796035, "critic_loss": 0.03818810321576893, "actor_loss": -27.3815674482584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.724326372146606, "step": 4000}
{"episode_reward": 35.455820948329546, "episode": 5.0, "batch_reward": 0.16008094061166048, "critic_loss": 0.05224627794511616, "actor_loss": -22.52387002336979, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.849955081939697, "step": 5000}
{"episode_reward": 129.44403541656294, "episode": 6.0, "batch_reward": 0.15699088272452355, "critic_loss": 0.052721191419288514, "actor_loss": -23.557886018276214, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91477656364441, "step": 6000}
{"episode_reward": 159.88852956839506, "episode": 7.0, "batch_reward": 0.15569842881709337, "critic_loss": 0.06164194886758924, "actor_loss": -25.92990558719635, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.28377342224121, "step": 7000}
{"episode_reward": 77.83411946233436, "episode": 8.0, "batch_reward": 0.14839359883964062, "critic_loss": 0.06331860103458166, "actor_loss": -23.873346799850463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.67379379272461, "step": 8000}
{"episode_reward": 173.5704851431381, "episode": 9.0, "batch_reward": 0.14986545231193305, "critic_loss": 0.08214390783756971, "actor_loss": -23.42381462097168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.06919836997986, "step": 9000}
{"episode_reward": 93.16796331235537, "episode": 10.0, "batch_reward": 0.14595242781192064, "critic_loss": 0.09212135963886976, "actor_loss": -23.07350219964981, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.360203742980957, "step": 10000}
{"episode_reward": 102.78573915812909, "episode": 11.0, "batch_reward": 0.14020676458626985, "critic_loss": 0.08440288323909044, "actor_loss": -22.432694538593292, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.47802257537842, "step": 11000}
{"episode_reward": 90.88797639474274, "episode": 12.0, "batch_reward": 0.13681351330131292, "critic_loss": 0.08731800536811352, "actor_loss": -20.18948436307907, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.361222505569458, "step": 12000}
{"episode_reward": 98.2619329141277, "episode": 13.0, "batch_reward": 0.13738422644138337, "critic_loss": 0.11289740004763008, "actor_loss": -20.380564153194427, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.632954359054565, "step": 13000}
{"episode_reward": 222.13356384141042, "episode": 14.0, "batch_reward": 0.1395820288732648, "critic_loss": 0.1263404906615615, "actor_loss": -19.224235127449035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.162064790725708, "step": 14000}
{"episode_reward": 128.80232437826822, "episode": 15.0, "batch_reward": 0.14491345290094615, "critic_loss": 0.15702829160913825, "actor_loss": -21.89749797677994, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.295759916305542, "step": 15000}
{"episode_reward": 297.94900599879276, "episode": 16.0, "batch_reward": 0.1482310125529766, "critic_loss": 0.16782193589955569, "actor_loss": -21.776575859069823, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.027050018310547, "step": 16000}
{"episode_reward": 96.00070527869083, "episode": 17.0, "batch_reward": 0.14567680299282074, "critic_loss": 0.15452346428483724, "actor_loss": -20.32858822250366, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.58999276161194, "step": 17000}
{"episode_reward": 58.086678376069415, "episode": 18.0, "batch_reward": 0.1422312909513712, "critic_loss": 0.17208664402365684, "actor_loss": -20.188830941200255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.896782159805298, "step": 18000}
{"episode_reward": 171.2138668710511, "episode": 19.0, "batch_reward": 0.14254531601816417, "critic_loss": 0.1903662158176303, "actor_loss": -19.99487288093567, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.160015106201172, "step": 19000}
{"episode_reward": 76.17196961295885, "episode": 20.0, "batch_reward": 0.13939197035133838, "critic_loss": 0.20401679442077875, "actor_loss": -20.92161380290985, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.398460388183594, "step": 20000}
{"episode_reward": 90.4600991951489, "episode": 21.0, "batch_reward": 0.13778321547806263, "critic_loss": 0.20085806986689567, "actor_loss": -20.832940845489503, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.13284158706665, "step": 21000}
{"episode_reward": 104.48637055376555, "episode": 22.0, "batch_reward": 0.1366320250108838, "critic_loss": 0.21419968025386332, "actor_loss": -20.035124227523802, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.395148515701294, "step": 22000}
{"episode_reward": 204.1008039965024, "episode": 23.0, "batch_reward": 0.13954340229183435, "critic_loss": 0.24655916066467762, "actor_loss": -20.186265138626098, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.878600597381592, "step": 23000}
{"episode_reward": 130.76621822915607, "episode": 24.0, "batch_reward": 0.1381888148188591, "critic_loss": 0.24397461698204279, "actor_loss": -21.031310532569886, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.187862873077393, "step": 24000}
{"episode_reward": 149.5759775137472, "episode": 25.0, "batch_reward": 0.13938758428394796, "critic_loss": 0.23549388850480318, "actor_loss": -20.45672764015198, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.7517249584198, "step": 25000}
{"episode_reward": 146.48759235376423, "episode": 26.0, "batch_reward": 0.1393450761884451, "critic_loss": 0.27041016455739736, "actor_loss": -20.309784440040588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.852004528045654, "step": 26000}
{"episode_reward": 122.38927554836138, "episode": 27.0, "batch_reward": 0.14128189948946238, "critic_loss": 0.26739351961016655, "actor_loss": -20.92799449157715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.057313680648804, "step": 27000}
{"episode_reward": 270.79028973741316, "episode": 28.0, "batch_reward": 0.14538399589061737, "critic_loss": 0.2822104654833674, "actor_loss": -20.853915108680724, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.177197694778442, "step": 28000}
{"episode_reward": 250.17024075078814, "episode": 29.0, "batch_reward": 0.14977914506196977, "critic_loss": 0.2914445475563407, "actor_loss": -21.851879755020143, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.350998640060425, "step": 29000}
{"episode_reward": 273.6771052165267, "episode": 30.0, "batch_reward": 0.15268180859833955, "critic_loss": 0.27300653159618377, "actor_loss": -21.844157333374024, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.017608880996704, "step": 30000}
{"episode_reward": 201.0158036999122, "episode": 31.0, "batch_reward": 0.1530333366766572, "critic_loss": 0.27197742250561713, "actor_loss": -22.23284133338928, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.368849754333496, "step": 31000}
{"episode_reward": 107.06493444596713, "episode": 32.0, "batch_reward": 0.1508908915668726, "critic_loss": 0.26273369894176724, "actor_loss": -22.208374164581297, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.209786891937256, "step": 32000}
{"episode_reward": 71.9792786445133, "episode": 33.0, "batch_reward": 0.14769596974551677, "critic_loss": 0.24007426077872515, "actor_loss": -21.96993801021576, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.911791563034058, "step": 33000}
{"episode_reward": 18.038390294368366, "episode": 34.0, "batch_reward": 0.1473578592389822, "critic_loss": 0.27921712943911553, "actor_loss": -20.92087644958496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.542424201965332, "step": 34000}
{"episode_reward": 346.9276088221954, "episode": 35.0, "batch_reward": 0.15269931633025408, "critic_loss": 0.3151631910949945, "actor_loss": -22.386520944595336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.081242561340332, "step": 35000}
{"episode_reward": 235.2299684286093, "episode": 36.0, "batch_reward": 0.15544745322316886, "critic_loss": 0.3505415267497301, "actor_loss": -21.665555597305296, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.898197650909424, "step": 36000}
{"episode_reward": 346.6793058712169, "episode": 37.0, "batch_reward": 0.15781535083800555, "critic_loss": 0.3534645811915398, "actor_loss": -22.193628318786622, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.060948848724365, "step": 37000}
{"episode_reward": 71.90507654838723, "episode": 38.0, "batch_reward": 0.1588472530543804, "critic_loss": 0.37836158587038515, "actor_loss": -22.287686796188353, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.87343454360962, "step": 38000}
{"episode_reward": 290.20358888711644, "episode": 39.0, "batch_reward": 0.16048419726639987, "critic_loss": 0.34602118414640426, "actor_loss": -23.009416612625124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.14311122894287, "step": 39000}
{"episode_reward": 168.76891161181, "episode": 40.0, "batch_reward": 0.15909445584565401, "critic_loss": 0.33721670711040497, "actor_loss": -22.731267980575563, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.265377044677734, "step": 40000}
{"episode_reward": 23.60907463409099, "episode": 41.0, "batch_reward": 0.1587006083279848, "critic_loss": 0.35303027875721454, "actor_loss": -22.692718305587768, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.83525252342224, "step": 41000}
{"episode_reward": 279.0932260306792, "episode": 42.0, "batch_reward": 0.16250609897077084, "critic_loss": 0.3408959687948227, "actor_loss": -22.721130653381348, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.63946270942688, "step": 42000}
{"episode_reward": 319.7339837847166, "episode": 43.0, "batch_reward": 0.164919288367033, "critic_loss": 0.35434883973002435, "actor_loss": -23.13399644088745, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.875832319259644, "step": 43000}
{"episode_reward": 337.2492712393332, "episode": 44.0, "batch_reward": 0.16930526983737945, "critic_loss": 0.37634320463240145, "actor_loss": -23.11681940841675, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.594547033309937, "step": 44000}
{"episode_reward": 342.1794432321533, "episode": 45.0, "batch_reward": 0.17405640207231043, "critic_loss": 0.40505884739756587, "actor_loss": -24.447449644088746, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.079809427261353, "step": 45000}
{"episode_reward": 411.77040456218015, "episode": 46.0, "batch_reward": 0.17779436483979225, "critic_loss": 0.43330691400170324, "actor_loss": -24.460905223846435, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.878050565719604, "step": 46000}
{"episode_reward": 237.10092967198935, "episode": 47.0, "batch_reward": 0.1808688588142395, "critic_loss": 0.44583352410793303, "actor_loss": -24.626000675201418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.620699644088745, "step": 47000}
{"episode_reward": 436.1482590622268, "episode": 48.0, "batch_reward": 0.18526413786411286, "critic_loss": 0.45497166047990323, "actor_loss": -24.740441593170168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.511077642440796, "step": 48000}
{"episode_reward": 256.1619948477724, "episode": 49.0, "batch_reward": 0.1871739946603775, "critic_loss": 0.4493608768582344, "actor_loss": -25.352779552459715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89869213104248, "step": 49000}
{"episode_reward": 341.8901624045154, "episode": 50.0, "batch_reward": 0.18876821634173394, "critic_loss": 0.47087610071897507, "actor_loss": -25.578428680419922, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.063806772232056, "step": 50000}
{"episode_reward": 231.61392325670536, "episode": 51.0, "batch_reward": 0.18987654109299182, "critic_loss": 0.4755547793805599, "actor_loss": -25.420076723098756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.872363805770874, "step": 51000}
{"episode_reward": 375.5804025934162, "episode": 52.0, "batch_reward": 0.1933806541711092, "critic_loss": 0.5025337846875191, "actor_loss": -26.501535551071168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.94729256629944, "step": 52000}
{"episode_reward": 279.6411830925422, "episode": 53.0, "batch_reward": 0.19593510989844798, "critic_loss": 0.6157008041441441, "actor_loss": -26.44580563545227, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.155206203460693, "step": 53000}
{"episode_reward": 348.77764537051496, "episode": 54.0, "batch_reward": 0.19768043415248393, "critic_loss": 0.6140282773375512, "actor_loss": -26.739109380722045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91282057762146, "step": 54000}
{"episode_reward": 153.19526402375638, "episode": 55.0, "batch_reward": 0.19845237179100514, "critic_loss": 0.5668974784910679, "actor_loss": -26.621483757019043, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.458688020706177, "step": 55000}
{"episode_reward": 352.8523108690597, "episode": 56.0, "batch_reward": 0.20088339495658875, "critic_loss": 0.6082967760562896, "actor_loss": -27.381347719192505, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.33611035346985, "step": 56000}
{"episode_reward": 201.72077081754398, "episode": 57.0, "batch_reward": 0.20183375868201256, "critic_loss": 0.626695871502161, "actor_loss": -27.042609642028808, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.275834798812866, "step": 57000}
{"episode_reward": 303.118892615688, "episode": 58.0, "batch_reward": 0.20427477729320526, "critic_loss": 0.6711573434174061, "actor_loss": -26.864852096557616, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.783758878707886, "step": 58000}
{"episode_reward": 495.28319439472426, "episode": 59.0, "batch_reward": 0.20846304649114608, "critic_loss": 0.6419964901208878, "actor_loss": -27.336501869201662, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.49744176864624, "step": 59000}
{"episode_reward": 444.6344904506577, "episode": 60.0, "batch_reward": 0.2112057698071003, "critic_loss": 0.6190945259034634, "actor_loss": -28.0566367149353, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.904085159301758, "step": 60000}
{"episode_reward": 197.72660915922788, "episode": 61.0, "batch_reward": 0.21309203688800335, "critic_loss": 0.6305295685827732, "actor_loss": -28.05454248428345, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.4992938041687, "step": 61000}
{"episode_reward": 508.392711765917, "episode": 62.0, "batch_reward": 0.21686478106677531, "critic_loss": 0.7070131323933602, "actor_loss": -28.2396356010437, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.075653076171875, "step": 62000}
{"episode_reward": 467.32329792657526, "episode": 63.0, "batch_reward": 0.21771558746695518, "critic_loss": 0.7116184423863888, "actor_loss": -28.29462947845459, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.74391222000122, "step": 63000}
{"episode_reward": 89.90609866699099, "episode": 64.0, "batch_reward": 0.21677218836545945, "critic_loss": 0.6941385069787502, "actor_loss": -28.278516269683838, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.115888595581055, "step": 64000}
{"episode_reward": 159.64757617638517, "episode": 65.0, "batch_reward": 0.21702801851928233, "critic_loss": 0.6766908380389214, "actor_loss": -28.25141352081299, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90096139907837, "step": 65000}
{"episode_reward": 462.9139614089222, "episode": 66.0, "batch_reward": 0.22247478979825974, "critic_loss": 0.7307718116343022, "actor_loss": -28.936059059143066, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.423166275024414, "step": 66000}
{"episode_reward": 437.7256532319156, "episode": 67.0, "batch_reward": 0.22243576347827912, "critic_loss": 0.6691362561583519, "actor_loss": -29.3368590965271, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.3016300201416, "step": 67000}
{"episode_reward": 154.7317394674982, "episode": 68.0, "batch_reward": 0.22211487589776516, "critic_loss": 0.625048926115036, "actor_loss": -28.677841579437256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.33322238922119, "step": 68000}
{"episode_reward": 276.4535964608406, "episode": 69.0, "batch_reward": 0.22271330799162387, "critic_loss": 0.6177858543694019, "actor_loss": -28.917289058685302, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.74307370185852, "step": 69000}
{"episode_reward": 278.05580192486997, "episode": 70.0, "batch_reward": 0.22560554300248623, "critic_loss": 0.6340128592699766, "actor_loss": -29.40531721496582, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.240609407424927, "step": 70000}
{"episode_reward": 553.8581922155928, "episode": 71.0, "batch_reward": 0.22956101159751416, "critic_loss": 0.6095614349842071, "actor_loss": -29.333055561065674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.53812885284424, "step": 71000}
{"episode_reward": 411.88106845939245, "episode": 72.0, "batch_reward": 0.23239510591328144, "critic_loss": 0.7197597307860851, "actor_loss": -29.476316928863525, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.285910606384277, "step": 72000}
{"episode_reward": 294.9142658152369, "episode": 73.0, "batch_reward": 0.23373245112597943, "critic_loss": 0.6599295316040515, "actor_loss": -29.40604795074463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.00529646873474, "step": 73000}
{"episode_reward": 494.73493538643885, "episode": 74.0, "batch_reward": 0.2364016782939434, "critic_loss": 0.6889962429702282, "actor_loss": -30.042037189483644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.791340827941895, "step": 74000}
{"episode_reward": 365.1002953740592, "episode": 75.0, "batch_reward": 0.23927500726282597, "critic_loss": 0.6399378026425838, "actor_loss": -30.308397174835203, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.107821464538574, "step": 75000}
{"episode_reward": 497.67836960527546, "episode": 76.0, "batch_reward": 0.24131476792693138, "critic_loss": 0.6856593172550202, "actor_loss": -30.36378342437744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.920722484588623, "step": 76000}
{"episode_reward": 255.2455655184473, "episode": 77.0, "batch_reward": 0.24176677662134172, "critic_loss": 0.6593575011491776, "actor_loss": -30.366098434448244, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.25848364830017, "step": 77000}
{"episode_reward": 491.9151991930936, "episode": 78.0, "batch_reward": 0.246191071420908, "critic_loss": 0.6833994201719761, "actor_loss": -30.796127838134765, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.473413705825806, "step": 78000}
{"episode_reward": 477.4111816685006, "episode": 79.0, "batch_reward": 0.2483373803794384, "critic_loss": 0.6427774487882852, "actor_loss": -30.305309413909914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.640778064727783, "step": 79000}
{"episode_reward": 504.504521736739, "episode": 80.0, "batch_reward": 0.2520636499375105, "critic_loss": 0.593808283239603, "actor_loss": -31.10864440917969, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.858341217041016, "step": 80000}
{"episode_reward": 519.0808203098179, "episode": 81.0, "batch_reward": 0.25545568609237673, "critic_loss": 0.6311209640353919, "actor_loss": -31.367531806945802, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.664122104644775, "step": 81000}
{"episode_reward": 472.41422206410977, "episode": 82.0, "batch_reward": 0.2580913513600826, "critic_loss": 0.6439169363975525, "actor_loss": -32.27606081390381, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.80833625793457, "step": 82000}
{"episode_reward": 434.1377178878397, "episode": 83.0, "batch_reward": 0.26082197260856627, "critic_loss": 0.574309432014823, "actor_loss": -31.956226772308348, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.870099782943726, "step": 83000}
{"episode_reward": 542.8381759099675, "episode": 84.0, "batch_reward": 0.26416826419532297, "critic_loss": 0.5648914599120617, "actor_loss": -32.615160064697264, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.174956798553467, "step": 84000}
{"episode_reward": 511.69224079750524, "episode": 85.0, "batch_reward": 0.26574799236655233, "critic_loss": 0.5638360714167356, "actor_loss": -32.73466711044311, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.555789470672607, "step": 85000}
{"episode_reward": 532.4162997351366, "episode": 86.0, "batch_reward": 0.26922988826036454, "critic_loss": 0.5853977081775665, "actor_loss": -32.56372714614868, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.921688556671143, "step": 86000}
{"episode_reward": 472.6375406814934, "episode": 87.0, "batch_reward": 0.27259997856616974, "critic_loss": 0.5615161409974099, "actor_loss": -33.24914742660523, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.34087610244751, "step": 87000}
{"episode_reward": 600.6210276660842, "episode": 88.0, "batch_reward": 0.27610461436212064, "critic_loss": 0.588988019168377, "actor_loss": -33.38004361724853, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.002840042114258, "step": 88000}
{"episode_reward": 533.2437025643934, "episode": 89.0, "batch_reward": 0.2777409882992506, "critic_loss": 0.5539677731692791, "actor_loss": -33.53139699935913, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.504279613494873, "step": 89000}
{"episode_reward": 530.7530270497034, "episode": 90.0, "batch_reward": 0.28071586164832113, "critic_loss": 0.540866939753294, "actor_loss": -34.21231376266479, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.905601978302002, "step": 90000}
{"episode_reward": 476.1572926805733, "episode": 91.0, "batch_reward": 0.28290025824308396, "critic_loss": 0.5369920884817838, "actor_loss": -33.85057190322876, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.43977212905884, "step": 91000}
{"episode_reward": 455.2529757205959, "episode": 92.0, "batch_reward": 0.2854622687548399, "critic_loss": 0.5516882016956807, "actor_loss": -34.24693406295776, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.080122709274292, "step": 92000}
{"episode_reward": 523.6239852831102, "episode": 93.0, "batch_reward": 0.2876112408638, "critic_loss": 0.4999590018242598, "actor_loss": -34.44131896209717, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89421010017395, "step": 93000}
{"episode_reward": 496.4069626127276, "episode": 94.0, "batch_reward": 0.29049965025484564, "critic_loss": 0.5307125017046929, "actor_loss": -34.74118002319336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.777910232543945, "step": 94000}
{"episode_reward": 564.9724902715171, "episode": 95.0, "batch_reward": 0.29318650798499585, "critic_loss": 0.47875149914622306, "actor_loss": -35.25906231307983, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.825128316879272, "step": 95000}
{"episode_reward": 542.3187168535098, "episode": 96.0, "batch_reward": 0.2952973967343569, "critic_loss": 0.5008169517219067, "actor_loss": -35.262224117279054, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.856427431106567, "step": 96000}
{"episode_reward": 511.71584763726605, "episode": 97.0, "batch_reward": 0.2985538462549448, "critic_loss": 0.5016821717619896, "actor_loss": -35.73063106918335, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.21399426460266, "step": 97000}
{"episode_reward": 587.7047597597585, "episode": 98.0, "batch_reward": 0.3009603185355663, "critic_loss": 0.4822226328551769, "actor_loss": -35.511155723571775, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.52803134918213, "step": 98000}
{"episode_reward": 543.1671509542592, "episode": 99.0, "batch_reward": 0.303829282566905, "critic_loss": 0.46287179261446, "actor_loss": -35.8380143699646, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.884446620941162, "step": 99000}
{"episode_reward": 569.003288890153, "episode": 100.0, "batch_reward": 0.3072949892282486, "critic_loss": 0.48212300573289396, "actor_loss": -35.780888572692874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.054736375808716, "step": 100000}
{"episode_reward": 587.3105933480828, "episode": 101.0, "batch_reward": 0.30996785819530487, "critic_loss": 0.4710937292724848, "actor_loss": -36.32814212799072, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.227344036102295, "step": 101000}
{"episode_reward": 578.4760366135487, "episode": 102.0, "batch_reward": 0.3113920778185129, "critic_loss": 0.4834243657886982, "actor_loss": -36.39839496612549, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.603572368621826, "step": 102000}
{"episode_reward": 622.473147557728, "episode": 103.0, "batch_reward": 0.3140106090456247, "critic_loss": 0.456537660241127, "actor_loss": -36.595472801208494, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.974573612213135, "step": 103000}
{"episode_reward": 632.6335701113438, "episode": 104.0, "batch_reward": 0.3178751530647278, "critic_loss": 0.4809194430410862, "actor_loss": -36.76189697647095, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.012937784194946, "step": 104000}
{"episode_reward": 503.8580116184324, "episode": 105.0, "batch_reward": 0.31962497082352637, "critic_loss": 0.4819803771972656, "actor_loss": -36.930611282348636, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.265687704086304, "step": 105000}
{"episode_reward": 549.8340155158952, "episode": 106.0, "batch_reward": 0.32089080679416654, "critic_loss": 0.44753650940954687, "actor_loss": -36.98996664428711, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.719582557678223, "step": 106000}
{"episode_reward": 618.8226464512521, "episode": 107.0, "batch_reward": 0.3245624940991402, "critic_loss": 0.48438289877772334, "actor_loss": -37.1594140586853, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.894001960754395, "step": 107000}
{"episode_reward": 547.8356757547189, "episode": 108.0, "batch_reward": 0.3267736610472202, "critic_loss": 0.47882468250393867, "actor_loss": -37.49168259048462, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.927478790283203, "step": 108000}
{"episode_reward": 558.821506803459, "episode": 109.0, "batch_reward": 0.32727080428600314, "critic_loss": 0.48265095287561416, "actor_loss": -37.72624411010742, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.880165338516235, "step": 109000}
{"episode_reward": 182.88472092023474, "episode": 110.0, "batch_reward": 0.32725778967142105, "critic_loss": 0.4997587254494429, "actor_loss": -37.478468406677244, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.901302337646484, "step": 110000}
{"episode_reward": 557.8721784900528, "episode": 111.0, "batch_reward": 0.32993835645914077, "critic_loss": 0.5122943655401468, "actor_loss": -38.081756732940676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.26587414741516, "step": 111000}
{"episode_reward": 611.9254037319447, "episode": 112.0, "batch_reward": 0.33263638997077943, "critic_loss": 0.47927460800111293, "actor_loss": -37.99851059341431, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88502526283264, "step": 112000}
{"episode_reward": 619.0769239001093, "episode": 113.0, "batch_reward": 0.33492166838049886, "critic_loss": 0.46146288357675075, "actor_loss": -38.028333736419675, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.187655448913574, "step": 113000}
{"episode_reward": 602.9622110323362, "episode": 114.0, "batch_reward": 0.33751975670456885, "critic_loss": 0.46824252425134183, "actor_loss": -38.987385009765624, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.504433631896973, "step": 114000}
{"episode_reward": 622.6172652649922, "episode": 115.0, "batch_reward": 0.33953247845172885, "critic_loss": 0.48935197547078135, "actor_loss": -38.64989078521729, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.30739665031433, "step": 115000}
{"episode_reward": 622.4953438137993, "episode": 116.0, "batch_reward": 0.343218994140625, "critic_loss": 0.4923198426216841, "actor_loss": -39.25287630844116, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.163537740707397, "step": 116000}
{"episode_reward": 607.8711045683126, "episode": 117.0, "batch_reward": 0.34472268596291544, "critic_loss": 0.48692106911540034, "actor_loss": -38.874481220245364, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.882927417755127, "step": 117000}
{"episode_reward": 600.551545915947, "episode": 118.0, "batch_reward": 0.34674214804172515, "critic_loss": 0.45412344074249267, "actor_loss": -39.353430198669436, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.165592670440674, "step": 118000}
{"episode_reward": 648.19599079381, "episode": 119.0, "batch_reward": 0.34975537690520286, "critic_loss": 0.45163824543356895, "actor_loss": -39.81550638961792, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.429933309555054, "step": 119000}
{"episode_reward": 574.2577353526128, "episode": 120.0, "batch_reward": 0.35064595395326614, "critic_loss": 0.47511737477779387, "actor_loss": -39.45384199142456, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.37272024154663, "step": 120000}
{"episode_reward": 606.6674701664168, "episode": 121.0, "batch_reward": 0.3540579568743706, "critic_loss": 0.4762701524943113, "actor_loss": -39.82067015457153, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.27895140647888, "step": 121000}
{"episode_reward": 627.7464905156435, "episode": 122.0, "batch_reward": 0.35474125820398333, "critic_loss": 0.47282489520311355, "actor_loss": -40.01025880813599, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.441738605499268, "step": 122000}
{"episode_reward": 560.8200492175666, "episode": 123.0, "batch_reward": 0.359032104074955, "critic_loss": 0.4420124566406012, "actor_loss": -39.81697526550293, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.22868537902832, "step": 123000}
{"episode_reward": 605.4918349907977, "episode": 124.0, "batch_reward": 0.35794399777054786, "critic_loss": 0.43309949605166914, "actor_loss": -40.26848889541626, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89809799194336, "step": 124000}
{"episode_reward": 555.9339620504098, "episode": 125.0, "batch_reward": 0.36098961034417154, "critic_loss": 0.46077262829244137, "actor_loss": -40.334901782989505, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.168777465820312, "step": 125000}
{"episode_reward": 485.50176165552915, "episode": 126.0, "batch_reward": 0.3617228905260563, "critic_loss": 0.455812205389142, "actor_loss": -40.71984225845337, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.501362085342407, "step": 126000}
{"episode_reward": 595.9673761135396, "episode": 127.0, "batch_reward": 0.36263241022825243, "critic_loss": 0.45514892899990084, "actor_loss": -40.665750411987304, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.117114067077637, "step": 127000}
{"episode_reward": 570.1067139222389, "episode": 128.0, "batch_reward": 0.36463890805840493, "critic_loss": 0.468934488967061, "actor_loss": -40.78959632873535, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.278931379318237, "step": 128000}
{"episode_reward": 566.6665397829414, "episode": 129.0, "batch_reward": 0.3668623188138008, "critic_loss": 0.46611794002354145, "actor_loss": -41.29399319839477, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.040346145629883, "step": 129000}
{"episode_reward": 638.8363838903501, "episode": 130.0, "batch_reward": 0.36905833330750465, "critic_loss": 0.4582104945331812, "actor_loss": -41.36914055633545, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.0096116065979, "step": 130000}
{"episode_reward": 547.2490810670299, "episode": 131.0, "batch_reward": 0.3710352808535099, "critic_loss": 0.46048458309471607, "actor_loss": -41.65079666900635, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.45717644691467, "step": 131000}
{"episode_reward": 601.1776178467316, "episode": 132.0, "batch_reward": 0.372386654406786, "critic_loss": 0.44873723955452444, "actor_loss": -41.63046517944336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.03628921508789, "step": 132000}
{"episode_reward": 632.6159198954956, "episode": 133.0, "batch_reward": 0.37385383459925653, "critic_loss": 0.46642596761882305, "actor_loss": -41.68046293258667, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.55746364593506, "step": 133000}
{"episode_reward": 636.8298677105025, "episode": 134.0, "batch_reward": 0.37532441172003744, "critic_loss": 0.4576233374029398, "actor_loss": -41.96414631652832, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.017233848571777, "step": 134000}
{"episode_reward": 576.3718004441561, "episode": 135.0, "batch_reward": 0.377092199742794, "critic_loss": 0.4597568512260914, "actor_loss": -42.064121486663815, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.33251404762268, "step": 135000}
{"episode_reward": 603.3692987274267, "episode": 136.0, "batch_reward": 0.3805017142891884, "critic_loss": 0.49342870464920996, "actor_loss": -42.56958840560913, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.692346572875977, "step": 136000}
{"episode_reward": 637.0976097804303, "episode": 137.0, "batch_reward": 0.3808074831366539, "critic_loss": 0.4648979171067476, "actor_loss": -42.42503008651733, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.16713523864746, "step": 137000}
{"episode_reward": 632.0777697107792, "episode": 138.0, "batch_reward": 0.38326302453875544, "critic_loss": 0.48343820233643053, "actor_loss": -42.22773780059814, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.18132185935974, "step": 138000}
{"episode_reward": 621.8765480047356, "episode": 139.0, "batch_reward": 0.38427936455607414, "critic_loss": 0.45806488367915155, "actor_loss": -42.41606505584717, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.01247763633728, "step": 139000}
{"episode_reward": 638.931109636132, "episode": 140.0, "batch_reward": 0.38503688177466394, "critic_loss": 0.46469065284729005, "actor_loss": -42.4314158782959, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.74123191833496, "step": 140000}
{"episode_reward": 553.9569659453736, "episode": 141.0, "batch_reward": 0.38744395804405213, "critic_loss": 0.46007451868057253, "actor_loss": -42.379619491577145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.406410694122314, "step": 141000}
{"episode_reward": 563.5345355790585, "episode": 142.0, "batch_reward": 0.38856336593627927, "critic_loss": 0.4817887356281281, "actor_loss": -42.788761573791504, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.57620072364807, "step": 142000}
{"episode_reward": 627.7750298128775, "episode": 143.0, "batch_reward": 0.39169549563527106, "critic_loss": 0.458262393027544, "actor_loss": -43.05100586700439, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.95240330696106, "step": 143000}
{"episode_reward": 623.1712423851396, "episode": 144.0, "batch_reward": 0.3922643429636955, "critic_loss": 0.4793751504868269, "actor_loss": -43.31221809005737, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.895458221435547, "step": 144000}
{"episode_reward": 620.3066375522681, "episode": 145.0, "batch_reward": 0.39540204367041587, "critic_loss": 0.49308437910676, "actor_loss": -43.31516157531738, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.557682752609253, "step": 145000}
{"episode_reward": 636.6219438864352, "episode": 146.0, "batch_reward": 0.39398012575507163, "critic_loss": 0.4474676654487848, "actor_loss": -43.39406071472168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.239471673965454, "step": 146000}
{"episode_reward": 602.2895064040154, "episode": 147.0, "batch_reward": 0.3959348098635673, "critic_loss": 0.4462074326872826, "actor_loss": -43.59586533355713, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.160329341888428, "step": 147000}
{"episode_reward": 609.7653906844484, "episode": 148.0, "batch_reward": 0.3992778812646866, "critic_loss": 0.46188179577887056, "actor_loss": -43.66983332061768, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.889262199401855, "step": 148000}
{"episode_reward": 624.6023208939541, "episode": 149.0, "batch_reward": 0.39984314659237863, "critic_loss": 0.4588655857592821, "actor_loss": -43.698266036987306, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.26695489883423, "step": 149000}
{"episode_reward": 614.0318132019336, "episode": 150.0, "batch_reward": 0.4025044432878494, "critic_loss": 0.4536985467225313, "actor_loss": -44.179229637145994, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
