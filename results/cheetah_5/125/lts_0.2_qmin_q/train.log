{"episode_reward": 0.0, "episode": 1.0, "duration": 18.56940531730652, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.537672519683838, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.28672595040406257, "critic_loss": 0.15735904661992584, "actor_loss": -47.78385755547336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 64.38205242156982, "step": 3000}
{"episode_reward": 118.01575338619254, "episode": 4.0, "batch_reward": 0.2170828121006489, "critic_loss": 0.16292588260024787, "actor_loss": -43.51934662628174, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.112839221954346, "step": 4000}
{"episode_reward": 121.87110883091077, "episode": 5.0, "batch_reward": 0.20434306105971337, "critic_loss": 0.21152474046498537, "actor_loss": -43.040372924804686, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.379587650299072, "step": 5000}
{"episode_reward": 249.46217235096898, "episode": 6.0, "batch_reward": 0.21612610690295697, "critic_loss": 0.24394945861399173, "actor_loss": -43.17984394836426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.79526424407959, "step": 6000}
{"episode_reward": 185.89777394146796, "episode": 7.0, "batch_reward": 0.21003259156644344, "critic_loss": 0.35576652447879314, "actor_loss": -41.89627179718018, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.59587335586548, "step": 7000}
{"episode_reward": 239.0168632318479, "episode": 8.0, "batch_reward": 0.21409882754087448, "critic_loss": 0.24418295495212078, "actor_loss": -41.649573318481444, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.389183044433594, "step": 8000}
{"episode_reward": 116.73125776481734, "episode": 9.0, "batch_reward": 0.21070023666322232, "critic_loss": 0.24266515550017356, "actor_loss": -40.5885481338501, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.264988660812378, "step": 9000}
{"episode_reward": 345.67926708822444, "episode": 10.0, "batch_reward": 0.2201914955675602, "critic_loss": 0.29232727010548115, "actor_loss": -40.78218579101563, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.702101707458496, "step": 10000}
{"episode_reward": 167.1814610591021, "episode": 11.0, "batch_reward": 0.208326824426651, "critic_loss": 0.3052945370525122, "actor_loss": -39.22445457839966, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.89125347137451, "step": 11000}
{"episode_reward": 51.563400662887055, "episode": 12.0, "batch_reward": 0.19296402005851268, "critic_loss": 0.30396064910292625, "actor_loss": -37.88441449356079, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.407553672790527, "step": 12000}
{"episode_reward": 33.045563996981045, "episode": 13.0, "batch_reward": 0.18887135538458824, "critic_loss": 0.33816830195486547, "actor_loss": -37.688614524841306, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.1480610370636, "step": 13000}
{"episode_reward": 263.5366509750303, "episode": 14.0, "batch_reward": 0.19032087747752666, "critic_loss": 0.34320759075880053, "actor_loss": -38.058938346862796, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.427934885025024, "step": 14000}
{"episode_reward": 224.96823764286455, "episode": 15.0, "batch_reward": 0.19883712975680828, "critic_loss": 0.35197221133112905, "actor_loss": -38.455240135192874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.37254285812378, "step": 15000}
{"episode_reward": 384.19931031620814, "episode": 16.0, "batch_reward": 0.2067941042035818, "critic_loss": 0.3692164274007082, "actor_loss": -38.95619839859009, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.396504878997803, "step": 16000}
{"episode_reward": 310.4309528332144, "episode": 17.0, "batch_reward": 0.2191434703618288, "critic_loss": 0.35694079035520554, "actor_loss": -39.95740542221069, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.38710331916809, "step": 17000}
{"episode_reward": 413.7951073700612, "episode": 18.0, "batch_reward": 0.22615998090803624, "critic_loss": 0.3554111175984144, "actor_loss": -40.06201379394531, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.503578662872314, "step": 18000}
{"episode_reward": 185.14449749692258, "episode": 19.0, "batch_reward": 0.22675489681959152, "critic_loss": 0.40307242193818094, "actor_loss": -39.30062889862061, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.272125244140625, "step": 19000}
{"episode_reward": 333.56230579266355, "episode": 20.0, "batch_reward": 0.22670065839588643, "critic_loss": 0.4300495065897703, "actor_loss": -38.862373985290525, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.380123376846313, "step": 20000}
{"episode_reward": 112.07310659274467, "episode": 21.0, "batch_reward": 0.21981643807888032, "critic_loss": 0.7187045587450266, "actor_loss": -37.77144318771362, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.606964349746704, "step": 21000}
{"episode_reward": 45.42020373343786, "episode": 22.0, "batch_reward": 0.21087848202884196, "critic_loss": 0.5052463382482528, "actor_loss": -37.07631511306763, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.4029643535614, "step": 22000}
{"episode_reward": 55.59610659413457, "episode": 23.0, "batch_reward": 0.21112694004178048, "critic_loss": 0.5061920601427555, "actor_loss": -37.21855736923218, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.016660928726196, "step": 23000}
{"episode_reward": 362.145220840306, "episode": 24.0, "batch_reward": 0.2137901862412691, "critic_loss": 0.5187976168692112, "actor_loss": -37.308778881072996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.813305854797363, "step": 24000}
{"episode_reward": 259.2828927467627, "episode": 25.0, "batch_reward": 0.2161203695833683, "critic_loss": 0.5074166187494993, "actor_loss": -37.23586952590942, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.877824544906616, "step": 25000}
{"episode_reward": 178.15289866876353, "episode": 26.0, "batch_reward": 0.2121418700814247, "critic_loss": 0.4977892228662968, "actor_loss": -36.66848488235474, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.806538820266724, "step": 26000}
{"episode_reward": 106.32055233833928, "episode": 27.0, "batch_reward": 0.20672378876805306, "critic_loss": 0.5805731486976147, "actor_loss": -35.873093601226806, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.774494171142578, "step": 27000}
{"episode_reward": 31.329219894976596, "episode": 28.0, "batch_reward": 0.20453567714989185, "critic_loss": 0.5717490009963513, "actor_loss": -35.524836811065676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.434613704681396, "step": 28000}
{"episode_reward": 174.91516344192658, "episode": 29.0, "batch_reward": 0.2037977495342493, "critic_loss": 0.6110638214945793, "actor_loss": -35.41123630905151, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.38852047920227, "step": 29000}
{"episode_reward": 281.2459783591566, "episode": 30.0, "batch_reward": 0.2083638896793127, "critic_loss": 0.5680977250039577, "actor_loss": -35.4930174369812, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.600635290145874, "step": 30000}
{"episode_reward": 439.6169507417871, "episode": 31.0, "batch_reward": 0.2143676457107067, "critic_loss": 0.5433485005795956, "actor_loss": -35.883489513397215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.06721067428589, "step": 31000}
{"episode_reward": 399.91145014689243, "episode": 32.0, "batch_reward": 0.21991678027808667, "critic_loss": 0.5314422936141491, "actor_loss": -35.94643119049072, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.186163902282715, "step": 32000}
{"episode_reward": 328.339891998878, "episode": 33.0, "batch_reward": 0.2198625537008047, "critic_loss": 0.5042603294253349, "actor_loss": -35.60689952087402, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.660168170928955, "step": 33000}
{"episode_reward": 72.78819222118243, "episode": 34.0, "batch_reward": 0.2150571269094944, "critic_loss": 0.44549171936511994, "actor_loss": -35.34457272338867, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.43021011352539, "step": 34000}
{"episode_reward": 36.736264848270885, "episode": 35.0, "batch_reward": 0.21081419549882413, "critic_loss": 0.4453350972533226, "actor_loss": -34.716808631896974, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.765368461608887, "step": 35000}
{"episode_reward": 87.2690667431614, "episode": 36.0, "batch_reward": 0.20730919732153416, "critic_loss": 0.4364504233598709, "actor_loss": -33.835291343688965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.834988117218018, "step": 36000}
{"episode_reward": 80.2825106583494, "episode": 37.0, "batch_reward": 0.20553661273419857, "critic_loss": 0.4504149077236652, "actor_loss": -33.537723213195804, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.002256870269775, "step": 37000}
{"episode_reward": 284.81903444159303, "episode": 38.0, "batch_reward": 0.20868725487589837, "critic_loss": 0.5035288195312023, "actor_loss": -33.628568378448485, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.397711753845215, "step": 38000}
{"episode_reward": 373.5132996635751, "episode": 39.0, "batch_reward": 0.2133501841723919, "critic_loss": 0.5121738230288029, "actor_loss": -33.609465709686276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.7354953289032, "step": 39000}
{"episode_reward": 358.14543146611754, "episode": 40.0, "batch_reward": 0.21230256554484367, "critic_loss": 0.5152661110162735, "actor_loss": -33.198204860687255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.11693835258484, "step": 40000}
{"episode_reward": 4.852386341459799, "episode": 41.0, "batch_reward": 0.20707791474461557, "critic_loss": 0.5284792823791504, "actor_loss": -32.93587384414673, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.800617694854736, "step": 41000}
{"episode_reward": 3.2156398905528536, "episode": 42.0, "batch_reward": 0.20307652255892752, "critic_loss": 0.5405988919436931, "actor_loss": -32.79502300262451, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.619118213653564, "step": 42000}
{"episode_reward": 5.5885299151674905, "episode": 43.0, "batch_reward": 0.19819773218035697, "critic_loss": 0.538443726181984, "actor_loss": -32.617346466064454, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.447960138320923, "step": 43000}
{"episode_reward": 9.203242787954043, "episode": 44.0, "batch_reward": 0.19394038616120815, "critic_loss": 0.5382446194887162, "actor_loss": -32.38238856887818, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.116701126098633, "step": 44000}
{"episode_reward": 25.527244564324942, "episode": 45.0, "batch_reward": 0.19207284957170487, "critic_loss": 0.5686843066513538, "actor_loss": -32.02776715087891, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.885640859603882, "step": 45000}
{"episode_reward": 167.29248276015502, "episode": 46.0, "batch_reward": 0.1906317992657423, "critic_loss": 0.5976965174078941, "actor_loss": -31.575217140197754, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.09542226791382, "step": 46000}
{"episode_reward": 83.11074969192093, "episode": 47.0, "batch_reward": 0.18817648714780807, "critic_loss": 0.5770237349569798, "actor_loss": -31.041010162353516, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.41567373275757, "step": 47000}
{"episode_reward": 75.22069291894634, "episode": 48.0, "batch_reward": 0.1860116896033287, "critic_loss": 0.5868685276806355, "actor_loss": -30.693004493713378, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.791168451309204, "step": 48000}
{"episode_reward": 100.13170628573714, "episode": 49.0, "batch_reward": 0.18830187283456326, "critic_loss": 0.571152214795351, "actor_loss": -30.70664852142334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.511247634887695, "step": 49000}
{"episode_reward": 377.56369502113904, "episode": 50.0, "batch_reward": 0.1910096680223942, "critic_loss": 0.5623381717801094, "actor_loss": -30.55645411682129, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.416836500167847, "step": 50000}
{"episode_reward": 448.6400194710677, "episode": 51.0, "batch_reward": 0.19539423781633378, "critic_loss": 0.5595347809493542, "actor_loss": -30.716771102905273, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.37386155128479, "step": 51000}
{"episode_reward": 254.67057372735508, "episode": 52.0, "batch_reward": 0.1965023217946291, "critic_loss": 0.5500941489040851, "actor_loss": -30.512275730133055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.591179609298706, "step": 52000}
{"episode_reward": 367.99983852165883, "episode": 53.0, "batch_reward": 0.1998917517364025, "critic_loss": 0.5690449340045453, "actor_loss": -30.71120468902588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.00098490715027, "step": 53000}
{"episode_reward": 333.8598650705432, "episode": 54.0, "batch_reward": 0.20119349907338618, "critic_loss": 0.5727032881677151, "actor_loss": -30.848503597259523, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.398839712142944, "step": 54000}
{"episode_reward": 297.977067436039, "episode": 55.0, "batch_reward": 0.2023799181431532, "critic_loss": 0.5755972418487072, "actor_loss": -30.767690769195557, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.941123247146606, "step": 55000}
{"episode_reward": 260.0678888859749, "episode": 56.0, "batch_reward": 0.20462431828677655, "critic_loss": 0.62171082046628, "actor_loss": -30.872039009094237, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.74820852279663, "step": 56000}
{"episode_reward": 213.87896425594303, "episode": 57.0, "batch_reward": 0.2053718353509903, "critic_loss": 0.6532508052885533, "actor_loss": -30.826055187225343, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.406303882598877, "step": 57000}
{"episode_reward": 452.73578947267475, "episode": 58.0, "batch_reward": 0.20994654227793216, "critic_loss": 0.6845779043734074, "actor_loss": -30.88906588745117, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.806350708007812, "step": 58000}
{"episode_reward": 291.87457086116257, "episode": 59.0, "batch_reward": 0.2081659501940012, "critic_loss": 0.7323536720275879, "actor_loss": -30.827159549713134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.799015998840332, "step": 59000}
{"episode_reward": 15.213017606489903, "episode": 60.0, "batch_reward": 0.2055669927895069, "critic_loss": 0.7248771312832832, "actor_loss": -30.628032970428468, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.643569946289062, "step": 60000}
{"episode_reward": 2.3513162954301197, "episode": 61.0, "batch_reward": 0.20144739873707296, "critic_loss": 0.758806484401226, "actor_loss": -30.34004493713379, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.25445532798767, "step": 61000}
{"episode_reward": 18.787215352370247, "episode": 62.0, "batch_reward": 0.20256121234595775, "critic_loss": 0.8258241948485374, "actor_loss": -30.34895916748047, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.41275930404663, "step": 62000}
{"episode_reward": 506.06146258009215, "episode": 63.0, "batch_reward": 0.20427550719678403, "critic_loss": 0.9262077454924583, "actor_loss": -30.363118255615234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.047858715057373, "step": 63000}
{"episode_reward": 35.120486183418095, "episode": 64.0, "batch_reward": 0.20177382712066175, "critic_loss": 1.1330031734108925, "actor_loss": -30.07204889678955, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.760223627090454, "step": 64000}
{"episode_reward": 27.273040461143168, "episode": 65.0, "batch_reward": 0.1989071638137102, "critic_loss": 1.432549652159214, "actor_loss": -30.443577823638915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.545849084854126, "step": 65000}
{"episode_reward": 111.87109052044036, "episode": 66.0, "batch_reward": 0.19777711313962937, "critic_loss": 1.6529417738318444, "actor_loss": -30.609086574554443, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.606899738311768, "step": 66000}
{"episode_reward": 36.75502746997646, "episode": 67.0, "batch_reward": 0.19427385647594927, "critic_loss": 2.0974756172895432, "actor_loss": -30.444082149505615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.92772388458252, "step": 67000}
{"episode_reward": 40.03011116730355, "episode": 68.0, "batch_reward": 0.19228417053818703, "critic_loss": 2.6023452153205873, "actor_loss": -30.729285942077638, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.25501298904419, "step": 68000}
{"episode_reward": 27.244379025878683, "episode": 69.0, "batch_reward": 0.18996381652355193, "critic_loss": 3.0900256066322327, "actor_loss": -31.353797679901124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.42093253135681, "step": 69000}
{"episode_reward": 16.162272159361734, "episode": 70.0, "batch_reward": 0.1875105112195015, "critic_loss": 4.100761207103729, "actor_loss": -32.3458805809021, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.63202977180481, "step": 70000}
{"episode_reward": 20.2136346682785, "episode": 71.0, "batch_reward": 0.18492555394768714, "critic_loss": 5.387302757143974, "actor_loss": -33.44880020141601, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.40515732765198, "step": 71000}
{"episode_reward": 63.66801409261052, "episode": 72.0, "batch_reward": 0.18408886095881463, "critic_loss": 7.009845277070999, "actor_loss": -35.44697116470337, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.17267107963562, "step": 72000}
{"episode_reward": 25.97351350014844, "episode": 73.0, "batch_reward": 0.18104788316786288, "critic_loss": 7.42312109375, "actor_loss": -37.37639142227173, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.61811637878418, "step": 73000}
{"episode_reward": 46.340310085445296, "episode": 74.0, "batch_reward": 0.17884754218161106, "critic_loss": 7.495695126533509, "actor_loss": -39.66694092941284, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.671478509902954, "step": 74000}
{"episode_reward": 22.594655128435125, "episode": 75.0, "batch_reward": 0.1763008231446147, "critic_loss": 7.760558717727661, "actor_loss": -43.011746631622316, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.733961820602417, "step": 75000}
{"episode_reward": 31.789275962081966, "episode": 76.0, "batch_reward": 0.1756842096596956, "critic_loss": 7.82152517747879, "actor_loss": -46.07334142303467, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.804619073867798, "step": 76000}
{"episode_reward": 25.679805966890736, "episode": 77.0, "batch_reward": 0.17330577583611012, "critic_loss": 7.423691948413849, "actor_loss": -47.31270009231567, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.622310876846313, "step": 77000}
{"episode_reward": 29.060204976089974, "episode": 78.0, "batch_reward": 0.1719315062686801, "critic_loss": 7.7665550425052645, "actor_loss": -48.87757582473755, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.426231145858765, "step": 78000}
{"episode_reward": 47.31151266694818, "episode": 79.0, "batch_reward": 0.16918955940008162, "critic_loss": 8.323309516906738, "actor_loss": -51.11582901000977, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.351741552352905, "step": 79000}
{"episode_reward": 22.755436828504255, "episode": 80.0, "batch_reward": 0.16742977076023818, "critic_loss": 8.529701758384705, "actor_loss": -53.36926644134522, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.416638135910034, "step": 80000}
{"episode_reward": 24.378576932278747, "episode": 81.0, "batch_reward": 0.16613508053123952, "critic_loss": 8.035977331399918, "actor_loss": -53.56475567245484, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.92110013961792, "step": 81000}
{"episode_reward": 18.544055255207653, "episode": 82.0, "batch_reward": 0.16495211730152368, "critic_loss": 7.7380197374820705, "actor_loss": -55.21927391433716, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.804376125335693, "step": 82000}
{"episode_reward": 71.97619802210163, "episode": 83.0, "batch_reward": 0.1626921935006976, "critic_loss": 7.25272169303894, "actor_loss": -54.88089144515991, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.335315942764282, "step": 83000}
{"episode_reward": 49.62902302681444, "episode": 84.0, "batch_reward": 0.16199626713991166, "critic_loss": 6.476877062559128, "actor_loss": -54.609658027648926, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.404457330703735, "step": 84000}
{"episode_reward": 73.53970144465674, "episode": 85.0, "batch_reward": 0.16111474354565145, "critic_loss": 5.884734005212784, "actor_loss": -55.510517353057864, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.435033559799194, "step": 85000}
{"episode_reward": 36.61384419937437, "episode": 86.0, "batch_reward": 0.1599767884016037, "critic_loss": 4.9184263191223145, "actor_loss": -54.56424663543701, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.62402868270874, "step": 86000}
{"episode_reward": 57.18732399282993, "episode": 87.0, "batch_reward": 0.15938903047889472, "critic_loss": 4.068952557206154, "actor_loss": -53.90434420394897, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.489968061447144, "step": 87000}
{"episode_reward": 58.51450731666869, "episode": 88.0, "batch_reward": 0.158310129314661, "critic_loss": 3.549057905435562, "actor_loss": -52.81289548873902, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.944029808044434, "step": 88000}
{"episode_reward": 105.27077935899881, "episode": 89.0, "batch_reward": 0.156989657998085, "critic_loss": 3.0193127110004423, "actor_loss": -51.282907318115235, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.909806966781616, "step": 89000}
{"episode_reward": 107.28285323857484, "episode": 90.0, "batch_reward": 0.15689612431824207, "critic_loss": 2.5802058279514313, "actor_loss": -50.50381447982788, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.66579508781433, "step": 90000}
{"episode_reward": 194.0979952951755, "episode": 91.0, "batch_reward": 0.15749250688403846, "critic_loss": 2.0860504068136216, "actor_loss": -50.04863528060913, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.72203207015991, "step": 91000}
{"episode_reward": 259.0220557446532, "episode": 92.0, "batch_reward": 0.15913668936491013, "critic_loss": 1.7727784081101416, "actor_loss": -48.83698552703857, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.897761344909668, "step": 92000}
{"episode_reward": 233.5606205946721, "episode": 93.0, "batch_reward": 0.15913325030356645, "critic_loss": 1.500351092517376, "actor_loss": -48.568402378082276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.785999536514282, "step": 93000}
{"episode_reward": 201.3185106190551, "episode": 94.0, "batch_reward": 0.15845381888747215, "critic_loss": 1.3198510885834693, "actor_loss": -46.76810368728638, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.780063152313232, "step": 94000}
{"episode_reward": 127.88331379972105, "episode": 95.0, "batch_reward": 0.15929362013190984, "critic_loss": 1.1907254508137703, "actor_loss": -45.45219541931152, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.916037559509277, "step": 95000}
{"episode_reward": 248.07104303114806, "episode": 96.0, "batch_reward": 0.16097577326744794, "critic_loss": 1.0740252673625945, "actor_loss": -44.915203380584714, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.901904821395874, "step": 96000}
{"episode_reward": 326.4585227153299, "episode": 97.0, "batch_reward": 0.16323148895055056, "critic_loss": 0.9684218922555446, "actor_loss": -44.05210191345215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.396490812301636, "step": 97000}
{"episode_reward": 334.54279761640004, "episode": 98.0, "batch_reward": 0.16475818521529437, "critic_loss": 0.8603794840872288, "actor_loss": -42.931960681915285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.303588151931763, "step": 98000}
{"episode_reward": 356.6585920748764, "episode": 99.0, "batch_reward": 0.16523823914676905, "critic_loss": 0.8057414675951005, "actor_loss": -41.98306449508667, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.81094765663147, "step": 99000}
{"episode_reward": 242.14077417246838, "episode": 100.0, "batch_reward": 0.16634945644438268, "critic_loss": 0.7259884381890297, "actor_loss": -41.220137649536134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.595739603042603, "step": 100000}
{"episode_reward": 36.60652115845416, "episode": 101.0, "batch_reward": 0.16584799157828092, "critic_loss": 0.6840526854097844, "actor_loss": -39.93964042282104, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.19705772399902, "step": 101000}
{"episode_reward": 340.3763019226322, "episode": 102.0, "batch_reward": 0.1670178349763155, "critic_loss": 0.6554243950247765, "actor_loss": -38.75998222732544, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.036609411239624, "step": 102000}
{"episode_reward": 65.41206178186026, "episode": 103.0, "batch_reward": 0.16784294145554304, "critic_loss": 0.5985687192082405, "actor_loss": -38.151196460723874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.410308837890625, "step": 103000}
{"episode_reward": 402.15032132305674, "episode": 104.0, "batch_reward": 0.16854318031668664, "critic_loss": 0.580710113197565, "actor_loss": -37.5012890586853, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.847063064575195, "step": 104000}
{"episode_reward": 471.63299903019686, "episode": 105.0, "batch_reward": 0.17231255188584327, "critic_loss": 0.5491932878494262, "actor_loss": -36.99486208724976, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.761982440948486, "step": 105000}
{"episode_reward": 341.6259401586729, "episode": 106.0, "batch_reward": 0.1729456972926855, "critic_loss": 0.5155373686999083, "actor_loss": -36.59399953842163, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.570995569229126, "step": 106000}
{"episode_reward": 386.33906552400674, "episode": 107.0, "batch_reward": 0.17524381178617476, "critic_loss": 0.48653661701083184, "actor_loss": -36.04506290817261, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.616015195846558, "step": 107000}
{"episode_reward": 414.68550796672895, "episode": 108.0, "batch_reward": 0.1783032667338848, "critic_loss": 0.4657185330539942, "actor_loss": -35.55210475540161, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.91807794570923, "step": 108000}
{"episode_reward": 448.73367697508235, "episode": 109.0, "batch_reward": 0.18086031241714953, "critic_loss": 0.45012605920433996, "actor_loss": -35.09222158813476, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.0097873210907, "step": 109000}
{"episode_reward": 414.52937992480304, "episode": 110.0, "batch_reward": 0.1823209590613842, "critic_loss": 0.43292812402546405, "actor_loss": -34.69676316452026, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.403191804885864, "step": 110000}
{"episode_reward": 417.8146543776305, "episode": 111.0, "batch_reward": 0.183886010363698, "critic_loss": 0.42329497304558755, "actor_loss": -34.32001512527466, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.75290083885193, "step": 111000}
{"episode_reward": 316.3557737647868, "episode": 112.0, "batch_reward": 0.1853212521672249, "critic_loss": 0.40049775782227515, "actor_loss": -34.007071529388426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.974037170410156, "step": 112000}
{"episode_reward": 417.9901673987589, "episode": 113.0, "batch_reward": 0.18746424008905888, "critic_loss": 0.42331550805270673, "actor_loss": -33.6671086807251, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.3905770778656, "step": 113000}
{"episode_reward": 328.62864759751915, "episode": 114.0, "batch_reward": 0.18857171005010606, "critic_loss": 0.42028899954259397, "actor_loss": -33.21726717758179, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.520436763763428, "step": 114000}
{"episode_reward": 239.03091950916127, "episode": 115.0, "batch_reward": 0.18946322272717953, "critic_loss": 0.429479512155056, "actor_loss": -32.66456036758423, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.10868525505066, "step": 115000}
{"episode_reward": 343.8310847646263, "episode": 116.0, "batch_reward": 0.1907579502314329, "critic_loss": 0.43695853927731515, "actor_loss": -32.1798784828186, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.39688992500305, "step": 116000}
{"episode_reward": 377.74955643835693, "episode": 117.0, "batch_reward": 0.19136188533902168, "critic_loss": 0.4752108059823513, "actor_loss": -31.77149454879761, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.35716199874878, "step": 117000}
{"episode_reward": 199.925392350201, "episode": 118.0, "batch_reward": 0.19331758159399032, "critic_loss": 0.513207349255681, "actor_loss": -31.403534042358398, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.30626344680786, "step": 118000}
{"episode_reward": 396.6318872614238, "episode": 119.0, "batch_reward": 0.19379822500050067, "critic_loss": 0.5682291961312294, "actor_loss": -31.341523475646973, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.40176749229431, "step": 119000}
{"episode_reward": 408.69989574982094, "episode": 120.0, "batch_reward": 0.19626793991029262, "critic_loss": 0.5609615166783333, "actor_loss": -31.0316127243042, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.194466829299927, "step": 120000}
{"episode_reward": 504.66644335923877, "episode": 121.0, "batch_reward": 0.19954489490389823, "critic_loss": 0.5857559063732624, "actor_loss": -30.97763207244873, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.30791521072388, "step": 121000}
{"episode_reward": 364.9174321819065, "episode": 122.0, "batch_reward": 0.19909685641527175, "critic_loss": 0.6459099764823913, "actor_loss": -30.70369002151489, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.933813333511353, "step": 122000}
{"episode_reward": 409.3881101129912, "episode": 123.0, "batch_reward": 0.2011505708694458, "critic_loss": 0.669860568255186, "actor_loss": -30.807892639160155, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.92616295814514, "step": 123000}
{"episode_reward": 180.53681476930174, "episode": 124.0, "batch_reward": 0.20090755696594714, "critic_loss": 0.7115388603508472, "actor_loss": -30.555810146331787, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.66866135597229, "step": 124000}
{"episode_reward": 410.7815253438464, "episode": 125.0, "batch_reward": 0.20296705640852453, "critic_loss": 0.7431028454899787, "actor_loss": -30.543046394348146, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.06646728515625, "step": 125000}
{"episode_reward": 460.3706737264971, "episode": 126.0, "batch_reward": 0.2051605103313923, "critic_loss": 0.7839006846547126, "actor_loss": -30.51022286605835, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.9320547580719, "step": 126000}
{"episode_reward": 443.0948359469719, "episode": 127.0, "batch_reward": 0.20769065555930138, "critic_loss": 0.7859642312824726, "actor_loss": -30.553905250549317, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.75593137741089, "step": 127000}
{"episode_reward": 513.8520809507046, "episode": 128.0, "batch_reward": 0.20960805185139178, "critic_loss": 0.7994610413610935, "actor_loss": -30.612545391082765, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.491954565048218, "step": 128000}
{"episode_reward": 472.00155392473465, "episode": 129.0, "batch_reward": 0.21125062416493892, "critic_loss": 0.8079059408307075, "actor_loss": -30.978884765625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.85986328125, "step": 129000}
{"episode_reward": 526.2196677338629, "episode": 130.0, "batch_reward": 0.21430439822375774, "critic_loss": 0.798515641361475, "actor_loss": -30.969500469207762, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.70367193222046, "step": 130000}
{"episode_reward": 478.69299770186717, "episode": 131.0, "batch_reward": 0.21630469925701618, "critic_loss": 0.780892410069704, "actor_loss": -31.083425415039063, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.126851320266724, "step": 131000}
{"episode_reward": 578.0421955425808, "episode": 132.0, "batch_reward": 0.21922276873886584, "critic_loss": 0.8241738523542881, "actor_loss": -30.98742470932007, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.917282104492188, "step": 132000}
{"episode_reward": 536.161139064113, "episode": 133.0, "batch_reward": 0.22147599257528783, "critic_loss": 0.9159444219768047, "actor_loss": -31.173553562164308, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.726436376571655, "step": 133000}
{"episode_reward": 496.5693237684847, "episode": 134.0, "batch_reward": 0.22216388888657093, "critic_loss": 1.8270742666721345, "actor_loss": -31.96523805999756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.53142786026001, "step": 134000}
{"episode_reward": 78.21262101738839, "episode": 135.0, "batch_reward": 0.22070900601148605, "critic_loss": 2.7489815191030504, "actor_loss": -34.74532061767578, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.927730083465576, "step": 135000}
{"episode_reward": 18.518500157881647, "episode": 136.0, "batch_reward": 0.21872686366736888, "critic_loss": 2.0036131883859634, "actor_loss": -35.80604700469971, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.71459698677063, "step": 136000}
{"episode_reward": 18.055488798582406, "episode": 137.0, "batch_reward": 0.21723744213581087, "critic_loss": 2.004745678424835, "actor_loss": -38.006588062286376, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.510756731033325, "step": 137000}
{"episode_reward": 6.076203986981885, "episode": 138.0, "batch_reward": 0.21714043205976485, "critic_loss": 2.2912798429727554, "actor_loss": -39.896875450134274, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.885905504226685, "step": 138000}
{"episode_reward": 4.974719277493441, "episode": 139.0, "batch_reward": 0.2144393555521965, "critic_loss": 2.264962230205536, "actor_loss": -40.566912685394286, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.032856941223145, "step": 139000}
{"episode_reward": 7.788855437133568, "episode": 140.0, "batch_reward": 0.2116905332952738, "critic_loss": 2.0547438161969187, "actor_loss": -40.78108312225342, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.408782482147217, "step": 140000}
{"episode_reward": 3.873796494938392, "episode": 141.0, "batch_reward": 0.2121509189158678, "critic_loss": 1.761615681231022, "actor_loss": -40.88681646347046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.722227334976196, "step": 141000}
{"episode_reward": 13.839266212198188, "episode": 142.0, "batch_reward": 0.20971236591041087, "critic_loss": 1.5414745163917543, "actor_loss": -40.83935385894775, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.792781114578247, "step": 142000}
{"episode_reward": 8.815203256633685, "episode": 143.0, "batch_reward": 0.2082751475274563, "critic_loss": 1.3430993477106095, "actor_loss": -40.356462463378904, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.57210874557495, "step": 143000}
{"episode_reward": 83.87256806892614, "episode": 144.0, "batch_reward": 0.2099608428031206, "critic_loss": 1.1649406002163887, "actor_loss": -40.05606545257568, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.93082332611084, "step": 144000}
{"episode_reward": 322.7118948278522, "episode": 145.0, "batch_reward": 0.21023686349391937, "critic_loss": 1.05984941893816, "actor_loss": -39.71573782730103, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.504962682724, "step": 145000}
{"episode_reward": 222.24782702853346, "episode": 146.0, "batch_reward": 0.20859899297356604, "critic_loss": 0.9205127550363541, "actor_loss": -39.10865269470215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.59394073486328, "step": 146000}
{"episode_reward": 30.26931081570848, "episode": 147.0, "batch_reward": 0.20837708565592766, "critic_loss": 0.8101697566509247, "actor_loss": -38.569227947235106, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.350051879882812, "step": 147000}
{"episode_reward": 194.70653160793302, "episode": 148.0, "batch_reward": 0.20809008775651455, "critic_loss": 0.7240589981973171, "actor_loss": -37.89501420211792, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.520576000213623, "step": 148000}
{"episode_reward": 2.5570446944660934, "episode": 149.0, "batch_reward": 0.20569702018797398, "critic_loss": 0.6348502458930015, "actor_loss": -37.60804808807373, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.39581847190857, "step": 149000}
{"episode_reward": 3.7186867886439674, "episode": 150.0, "batch_reward": 0.20472941647469997, "critic_loss": 0.5532960080057383, "actor_loss": -36.92800972747803, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
