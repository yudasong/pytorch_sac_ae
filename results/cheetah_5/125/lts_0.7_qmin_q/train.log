{"episode_reward": 0.0, "episode": 1.0, "duration": 18.98887801170349, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.546342134475708, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.28374149350473665, "critic_loss": 0.15250110927324528, "actor_loss": -47.050583236834775, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 64.52742981910706, "step": 3000}
{"episode_reward": 48.58755286863818, "episode": 4.0, "batch_reward": 0.19603477245569229, "critic_loss": 0.12661331091821193, "actor_loss": -36.486228446960446, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.10236692428589, "step": 4000}
{"episode_reward": 76.80753101008006, "episode": 5.0, "batch_reward": 0.17739239389449357, "critic_loss": 0.2641239124536514, "actor_loss": -34.67134942626953, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.98720645904541, "step": 5000}
{"episode_reward": 132.2641329133131, "episode": 6.0, "batch_reward": 0.1673606551364064, "critic_loss": 0.1762833547666669, "actor_loss": -32.54518710327149, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.52826738357544, "step": 6000}
{"episode_reward": 181.87452036427706, "episode": 7.0, "batch_reward": 0.17860214003175498, "critic_loss": 0.23242106976360083, "actor_loss": -34.044197792053225, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.607380867004395, "step": 7000}
{"episode_reward": 293.19486989505674, "episode": 8.0, "batch_reward": 0.18983883995562792, "critic_loss": 0.2376973086297512, "actor_loss": -33.906237586975095, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.020456314086914, "step": 8000}
{"episode_reward": 124.6716617206705, "episode": 9.0, "batch_reward": 0.18763141341507436, "critic_loss": 0.25151457950472833, "actor_loss": -33.048222927093505, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.29163908958435, "step": 9000}
{"episode_reward": 243.90366433423358, "episode": 10.0, "batch_reward": 0.18840278194844723, "critic_loss": 0.2682979481369257, "actor_loss": -33.18507340240478, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.72882318496704, "step": 10000}
{"episode_reward": 116.20299863464786, "episode": 11.0, "batch_reward": 0.17639511974900962, "critic_loss": 0.2718023788481951, "actor_loss": -31.682385192871095, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.23501396179199, "step": 11000}
{"episode_reward": 45.66853267050624, "episode": 12.0, "batch_reward": 0.17102934969216585, "critic_loss": 0.29454344598948956, "actor_loss": -30.856395751953126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.421910285949707, "step": 12000}
{"episode_reward": 279.2051581103572, "episode": 13.0, "batch_reward": 0.18631716708838938, "critic_loss": 0.31300795677304266, "actor_loss": -32.14339929199219, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.450976848602295, "step": 13000}
{"episode_reward": 432.8123212428475, "episode": 14.0, "batch_reward": 0.1950658849924803, "critic_loss": 0.29675624224543573, "actor_loss": -32.33233500671387, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.949008464813232, "step": 14000}
{"episode_reward": 86.43425593232737, "episode": 15.0, "batch_reward": 0.19358526042103769, "critic_loss": 0.31675611171126367, "actor_loss": -32.47032796096802, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.89208984375, "step": 15000}
{"episode_reward": 302.87039863962855, "episode": 16.0, "batch_reward": 0.20384996478259562, "critic_loss": 0.3237916197478771, "actor_loss": -32.888653560638424, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.829922914505005, "step": 16000}
{"episode_reward": 447.6324842748507, "episode": 17.0, "batch_reward": 0.21835635243356227, "critic_loss": 0.3293001116812229, "actor_loss": -33.61684701919555, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.958598852157593, "step": 17000}
{"episode_reward": 405.6377059838227, "episode": 18.0, "batch_reward": 0.23063081821799278, "critic_loss": 0.3191741535067558, "actor_loss": -34.53861386871338, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.06256604194641, "step": 18000}
{"episode_reward": 498.939117027566, "episode": 19.0, "batch_reward": 0.24337378519773484, "critic_loss": 0.3396798768788576, "actor_loss": -35.17280939102173, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.05782961845398, "step": 19000}
{"episode_reward": 367.06932924451297, "episode": 20.0, "batch_reward": 0.24654578647017478, "critic_loss": 0.33210940888524054, "actor_loss": -35.28437924575805, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.802791357040405, "step": 20000}
{"episode_reward": 199.89064680088535, "episode": 21.0, "batch_reward": 0.24487039175629616, "critic_loss": 0.32691219909489155, "actor_loss": -34.52431272888184, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.10465884208679, "step": 21000}
{"episode_reward": 145.61994415030912, "episode": 22.0, "batch_reward": 0.2411985023468733, "critic_loss": 0.328889133900404, "actor_loss": -33.389310459136965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.18279194831848, "step": 22000}
{"episode_reward": 222.6387093110055, "episode": 23.0, "batch_reward": 0.24108569252490997, "critic_loss": 0.35516553743183615, "actor_loss": -33.51824063110352, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.36631178855896, "step": 23000}
{"episode_reward": 355.14170341112117, "episode": 24.0, "batch_reward": 0.24808307692408563, "critic_loss": 0.3612641283273697, "actor_loss": -34.03555514907837, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.262059688568115, "step": 24000}
{"episode_reward": 497.6209604579222, "episode": 25.0, "batch_reward": 0.2577385841012001, "critic_loss": 0.33958461514115335, "actor_loss": -34.367355003356934, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.85368537902832, "step": 25000}
{"episode_reward": 504.1520658188383, "episode": 26.0, "batch_reward": 0.26679519198834895, "critic_loss": 0.3339784572720528, "actor_loss": -35.32348058319092, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.5718891620636, "step": 26000}
{"episode_reward": 511.5553236164472, "episode": 27.0, "batch_reward": 0.27294855687022207, "critic_loss": 0.3360480964779854, "actor_loss": -35.49847229003906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.631420373916626, "step": 27000}
{"episode_reward": 134.61254772413682, "episode": 28.0, "batch_reward": 0.27151967817544936, "critic_loss": 0.3266879621595144, "actor_loss": -34.86267710494995, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.915302753448486, "step": 28000}
{"episode_reward": 474.9012834659826, "episode": 29.0, "batch_reward": 0.2808298182338476, "critic_loss": 0.308764719709754, "actor_loss": -35.94128232955933, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.1053307056427, "step": 29000}
{"episode_reward": 521.2344711417686, "episode": 30.0, "batch_reward": 0.28861572974920274, "critic_loss": 0.3138908184170723, "actor_loss": -36.2542331199646, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.732004165649414, "step": 30000}
{"episode_reward": 530.2398627371161, "episode": 31.0, "batch_reward": 0.290235065639019, "critic_loss": 0.32751728311181066, "actor_loss": -36.644691535949704, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.936702251434326, "step": 31000}
{"episode_reward": 172.61914427876292, "episode": 32.0, "batch_reward": 0.2891825716942549, "critic_loss": 0.36508369334042073, "actor_loss": -36.235736255645755, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.969245195388794, "step": 32000}
{"episode_reward": 293.85670466551755, "episode": 33.0, "batch_reward": 0.2918435975462198, "critic_loss": 0.3591792417913675, "actor_loss": -36.694388469696044, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.692049264907837, "step": 33000}
{"episode_reward": 508.6400536409991, "episode": 34.0, "batch_reward": 0.2971668172776699, "critic_loss": 0.3468658766150475, "actor_loss": -36.563370838165284, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.388848781585693, "step": 34000}
{"episode_reward": 500.5652903217143, "episode": 35.0, "batch_reward": 0.3034730781018734, "critic_loss": 0.3537661269009113, "actor_loss": -37.568194671630856, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.873217582702637, "step": 35000}
{"episode_reward": 440.6271192003431, "episode": 36.0, "batch_reward": 0.3039690210074186, "critic_loss": 0.3432397614270449, "actor_loss": -36.68418998718262, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.851348161697388, "step": 36000}
{"episode_reward": 159.939570661742, "episode": 37.0, "batch_reward": 0.3035952395796776, "critic_loss": 0.3734850352406502, "actor_loss": -36.97159759140015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.6330988407135, "step": 37000}
{"episode_reward": 523.1442374925167, "episode": 38.0, "batch_reward": 0.31056998594105245, "critic_loss": 0.3485188036412001, "actor_loss": -37.71578291702271, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.855409383773804, "step": 38000}
{"episode_reward": 541.261930905878, "episode": 39.0, "batch_reward": 0.315103777050972, "critic_loss": 0.35148847246170045, "actor_loss": -38.211401355743405, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.076229095458984, "step": 39000}
{"episode_reward": 487.93846945745145, "episode": 40.0, "batch_reward": 0.3193468254506588, "critic_loss": 0.3387650871127844, "actor_loss": -38.5577460861206, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.108262062072754, "step": 40000}
{"episode_reward": 541.8479075783155, "episode": 41.0, "batch_reward": 0.3263651025295258, "critic_loss": 0.31625594331324103, "actor_loss": -38.966088596343994, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.178839921951294, "step": 41000}
{"episode_reward": 555.5227586954421, "episode": 42.0, "batch_reward": 0.33190901574492454, "critic_loss": 0.3178055356442928, "actor_loss": -39.03202537918091, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.090582132339478, "step": 42000}
{"episode_reward": 560.287619747266, "episode": 43.0, "batch_reward": 0.33671539318561555, "critic_loss": 0.31165097975730893, "actor_loss": -39.48334955978394, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.922136306762695, "step": 43000}
{"episode_reward": 549.2128569057754, "episode": 44.0, "batch_reward": 0.3416227634549141, "critic_loss": 0.3234615985751152, "actor_loss": -39.64709456253052, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.242010354995728, "step": 44000}
{"episode_reward": 564.0760226616013, "episode": 45.0, "batch_reward": 0.34599857199192047, "critic_loss": 0.3187150673121214, "actor_loss": -40.39147315216064, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.914363145828247, "step": 45000}
{"episode_reward": 520.469052594023, "episode": 46.0, "batch_reward": 0.3483437501788139, "critic_loss": 0.3138345966339111, "actor_loss": -40.45150638198852, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.107703924179077, "step": 46000}
{"episode_reward": 536.6710023171742, "episode": 47.0, "batch_reward": 0.353951034873724, "critic_loss": 0.31567651431262495, "actor_loss": -41.096727031707765, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.969560861587524, "step": 47000}
{"episode_reward": 510.81009635739656, "episode": 48.0, "batch_reward": 0.3569307934343815, "critic_loss": 0.30977507822215555, "actor_loss": -40.728134468078615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.232946634292603, "step": 48000}
{"episode_reward": 544.7275331094203, "episode": 49.0, "batch_reward": 0.36193967574834823, "critic_loss": 0.30264198841154577, "actor_loss": -41.763960605621335, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.890637397766113, "step": 49000}
{"episode_reward": 578.4384119628155, "episode": 50.0, "batch_reward": 0.36545657855272295, "critic_loss": 0.30848998758196833, "actor_loss": -42.02664357757568, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.57095956802368, "step": 50000}
{"episode_reward": 587.2998556929921, "episode": 51.0, "batch_reward": 0.3704861926436424, "critic_loss": 0.28666798742115496, "actor_loss": -42.462890884399414, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.16976499557495, "step": 51000}
{"episode_reward": 541.2363523885608, "episode": 52.0, "batch_reward": 0.37316533222794535, "critic_loss": 0.2881950757354498, "actor_loss": -42.69089643096924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.928022384643555, "step": 52000}
{"episode_reward": 570.0013399220726, "episode": 53.0, "batch_reward": 0.37831633105874063, "critic_loss": 0.28651076231896877, "actor_loss": -42.95234875488281, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.816744327545166, "step": 53000}
{"episode_reward": 567.2324118038472, "episode": 54.0, "batch_reward": 0.3807516315877438, "critic_loss": 0.2815406214445829, "actor_loss": -43.363942237854005, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.439610958099365, "step": 54000}
{"episode_reward": 564.4289022570109, "episode": 55.0, "batch_reward": 0.38337435048818586, "critic_loss": 0.294273647531867, "actor_loss": -43.52563207244873, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.90285301208496, "step": 55000}
{"episode_reward": 518.1740012147409, "episode": 56.0, "batch_reward": 0.3872298398911953, "critic_loss": 0.2940751026421785, "actor_loss": -43.96728321838379, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.557276487350464, "step": 56000}
{"episode_reward": 572.6011868159962, "episode": 57.0, "batch_reward": 0.3908293647170067, "critic_loss": 0.2999845898449421, "actor_loss": -44.159091178894045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.930173873901367, "step": 57000}
{"episode_reward": 567.8730230670641, "episode": 58.0, "batch_reward": 0.39432284158468245, "critic_loss": 0.2927399654239416, "actor_loss": -44.24663310241699, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.90977907180786, "step": 58000}
{"episode_reward": 570.2883064931293, "episode": 59.0, "batch_reward": 0.39644057500362395, "critic_loss": 0.28342581340670586, "actor_loss": -44.37083924484253, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.16155695915222, "step": 59000}
{"episode_reward": 579.9662203469653, "episode": 60.0, "batch_reward": 0.39916981518268585, "critic_loss": 0.2857213843911886, "actor_loss": -45.022924419403076, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.078033685684204, "step": 60000}
{"episode_reward": 581.1946660859181, "episode": 61.0, "batch_reward": 0.40189726185798647, "critic_loss": 0.2796147250533104, "actor_loss": -45.00665102005005, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.78235054016113, "step": 61000}
{"episode_reward": 593.315942717449, "episode": 62.0, "batch_reward": 0.40533492040634156, "critic_loss": 0.2901640978902578, "actor_loss": -45.51914024734497, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.902420043945312, "step": 62000}
{"episode_reward": 594.9244383846445, "episode": 63.0, "batch_reward": 0.4078951130509377, "critic_loss": 0.28383009707927703, "actor_loss": -45.38290437316895, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.39571499824524, "step": 63000}
{"episode_reward": 625.0560600695385, "episode": 64.0, "batch_reward": 0.4121805003285408, "critic_loss": 0.2936793762296438, "actor_loss": -45.99676365280151, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.044021368026733, "step": 64000}
{"episode_reward": 604.1133030698543, "episode": 65.0, "batch_reward": 0.4148190045952797, "critic_loss": 0.2943469990342856, "actor_loss": -46.1608390045166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.66744089126587, "step": 65000}
{"episode_reward": 565.6600203289889, "episode": 66.0, "batch_reward": 0.4182860481441021, "critic_loss": 0.2998863113075495, "actor_loss": -46.460731033325196, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.56228017807007, "step": 66000}
{"episode_reward": 604.4549869762028, "episode": 67.0, "batch_reward": 0.419033105134964, "critic_loss": 0.2938174343556166, "actor_loss": -46.69537116241455, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.906233310699463, "step": 67000}
{"episode_reward": 556.2670516409589, "episode": 68.0, "batch_reward": 0.4219529849290848, "critic_loss": 0.31685924994945525, "actor_loss": -46.422277465820315, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.929474115371704, "step": 68000}
{"episode_reward": 595.2004894677407, "episode": 69.0, "batch_reward": 0.42385652390122414, "critic_loss": 0.3187300710231066, "actor_loss": -46.656287223815916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.6888325214386, "step": 69000}
{"episode_reward": 611.9451112098722, "episode": 70.0, "batch_reward": 0.4273490113914013, "critic_loss": 0.3159739507138729, "actor_loss": -47.488169723510744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.43025040626526, "step": 70000}
{"episode_reward": 599.9952864428531, "episode": 71.0, "batch_reward": 0.4296854477822781, "critic_loss": 0.3204874584823847, "actor_loss": -47.495332702636716, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.77500557899475, "step": 71000}
{"episode_reward": 586.4343671788864, "episode": 72.0, "batch_reward": 0.4329315865933895, "critic_loss": 0.31222166891396047, "actor_loss": -47.5713197555542, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.66743540763855, "step": 72000}
{"episode_reward": 613.7473220759277, "episode": 73.0, "batch_reward": 0.4340362827181816, "critic_loss": 0.31846763072907924, "actor_loss": -47.70296623229981, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.612571954727173, "step": 73000}
{"episode_reward": 586.0545373757662, "episode": 74.0, "batch_reward": 0.4370642971098423, "critic_loss": 0.31645178635418414, "actor_loss": -48.20455553436279, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.779805183410645, "step": 74000}
{"episode_reward": 573.5652359377003, "episode": 75.0, "batch_reward": 0.4374624869823456, "critic_loss": 0.32167661969363687, "actor_loss": -48.29069827270508, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.257481813430786, "step": 75000}
{"episode_reward": 499.9571546825285, "episode": 76.0, "batch_reward": 0.43874713733792303, "critic_loss": 0.32024705623090266, "actor_loss": -48.564723648071286, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.72692894935608, "step": 76000}
{"episode_reward": 546.7112015455348, "episode": 77.0, "batch_reward": 0.44102339377999306, "critic_loss": 0.3208924271762371, "actor_loss": -48.23101166534424, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.950589656829834, "step": 77000}
{"episode_reward": 627.8331722137666, "episode": 78.0, "batch_reward": 0.4437962832450867, "critic_loss": 0.3197406514286995, "actor_loss": -48.81850035095215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.92655301094055, "step": 78000}
{"episode_reward": 632.6960299616081, "episode": 79.0, "batch_reward": 0.4452150527536869, "critic_loss": 0.317981271520257, "actor_loss": -48.34910280609131, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.386098384857178, "step": 79000}
{"episode_reward": 618.6204807152793, "episode": 80.0, "batch_reward": 0.44827494302392007, "critic_loss": 0.3093074828535318, "actor_loss": -48.96184658813477, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.630075931549072, "step": 80000}
{"episode_reward": 622.9506845130337, "episode": 81.0, "batch_reward": 0.45024873939156534, "critic_loss": 0.3122045495212078, "actor_loss": -49.30239280700684, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.63974213600159, "step": 81000}
{"episode_reward": 515.3792688070832, "episode": 82.0, "batch_reward": 0.45165165862441065, "critic_loss": 0.3101899219304323, "actor_loss": -49.958351669311526, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.77583956718445, "step": 82000}
{"episode_reward": 627.1852375012559, "episode": 83.0, "batch_reward": 0.45313182851672174, "critic_loss": 0.2917018712759018, "actor_loss": -49.23791716003418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.95064353942871, "step": 83000}
{"episode_reward": 610.099873703548, "episode": 84.0, "batch_reward": 0.4549471563100815, "critic_loss": 0.30583730641007423, "actor_loss": -49.90648618316651, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.079230308532715, "step": 84000}
{"episode_reward": 611.7041169473433, "episode": 85.0, "batch_reward": 0.4555736806988716, "critic_loss": 0.2941580398082733, "actor_loss": -49.87804335784912, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.29243016242981, "step": 85000}
{"episode_reward": 631.5952644973088, "episode": 86.0, "batch_reward": 0.4582144429981709, "critic_loss": 0.2949964016079903, "actor_loss": -49.80676977539063, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.97653341293335, "step": 86000}
{"episode_reward": 593.9807998851265, "episode": 87.0, "batch_reward": 0.46020931074023247, "critic_loss": 0.28814825300872327, "actor_loss": -50.065690788269045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.036990880966187, "step": 87000}
{"episode_reward": 616.7581290737015, "episode": 88.0, "batch_reward": 0.46209313663840296, "critic_loss": 0.2912548819333315, "actor_loss": -49.88501039886474, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.960071086883545, "step": 88000}
{"episode_reward": 625.4228535647649, "episode": 89.0, "batch_reward": 0.4624706145524979, "critic_loss": 0.2992066744565964, "actor_loss": -50.49642515563965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.69459342956543, "step": 89000}
{"episode_reward": 546.9629406176219, "episode": 90.0, "batch_reward": 0.46444483095407485, "critic_loss": 0.28593338118493555, "actor_loss": -51.075326217651366, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.42421531677246, "step": 90000}
{"episode_reward": 595.9797857652931, "episode": 91.0, "batch_reward": 0.4663291153907776, "critic_loss": 0.2951128153800964, "actor_loss": -50.65215358734131, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.60691285133362, "step": 91000}
{"episode_reward": 609.0169050151354, "episode": 92.0, "batch_reward": 0.4690615535974503, "critic_loss": 0.2956836134046316, "actor_loss": -50.75907888793945, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.932167768478394, "step": 92000}
{"episode_reward": 629.3417446878958, "episode": 93.0, "batch_reward": 0.4685363435149193, "critic_loss": 0.30510298658907414, "actor_loss": -50.75917646026611, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.95233416557312, "step": 93000}
{"episode_reward": 528.0726899233819, "episode": 94.0, "batch_reward": 0.4692232517302036, "critic_loss": 0.29657370525598525, "actor_loss": -50.84102062988281, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.915813207626343, "step": 94000}
{"episode_reward": 607.5488270889059, "episode": 95.0, "batch_reward": 0.4709166164696217, "critic_loss": 0.2996349369585514, "actor_loss": -51.4839571762085, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.902490854263306, "step": 95000}
{"episode_reward": 623.1303441779309, "episode": 96.0, "batch_reward": 0.4727248356938362, "critic_loss": 0.311668283700943, "actor_loss": -51.61110702514648, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.3762788772583, "step": 96000}
{"episode_reward": 607.9924632849753, "episode": 97.0, "batch_reward": 0.47431362506747243, "critic_loss": 0.3040490276515484, "actor_loss": -51.75955512237549, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.904290914535522, "step": 97000}
{"episode_reward": 593.0425601485072, "episode": 98.0, "batch_reward": 0.4761003434360027, "critic_loss": 0.3192898159772158, "actor_loss": -51.47899765014648, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.08824849128723, "step": 98000}
{"episode_reward": 614.546769536169, "episode": 99.0, "batch_reward": 0.47730114036798477, "critic_loss": 0.31132242718338965, "actor_loss": -51.518572410583495, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.964430332183838, "step": 99000}
{"episode_reward": 639.6547896930446, "episode": 100.0, "batch_reward": 0.4794773062467575, "critic_loss": 0.3040454068481922, "actor_loss": -51.73314931488037, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.027135610580444, "step": 100000}
{"episode_reward": 579.5556086711641, "episode": 101.0, "batch_reward": 0.4797115372121334, "critic_loss": 0.29723823215067385, "actor_loss": -51.99232976531982, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.217897176742554, "step": 101000}
{"episode_reward": 579.6149967611098, "episode": 102.0, "batch_reward": 0.48036764526367187, "critic_loss": 0.30363415597379206, "actor_loss": -52.03150397491455, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.084463834762573, "step": 102000}
{"episode_reward": 597.0501412498976, "episode": 103.0, "batch_reward": 0.4812781957089901, "critic_loss": 0.3096072729974985, "actor_loss": -52.01361170196533, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.13280940055847, "step": 103000}
{"episode_reward": 622.5126348302286, "episode": 104.0, "batch_reward": 0.4837043458223343, "critic_loss": 0.3076629336923361, "actor_loss": -52.28867984771728, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.88243579864502, "step": 104000}
{"episode_reward": 582.3912178555378, "episode": 105.0, "batch_reward": 0.4855984725952148, "critic_loss": 0.30385565938055514, "actor_loss": -52.46499110412598, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.125845193862915, "step": 105000}
{"episode_reward": 602.1893019896696, "episode": 106.0, "batch_reward": 0.48457340997457504, "critic_loss": 0.28980537070333956, "actor_loss": -52.09572301483154, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.05976700782776, "step": 106000}
{"episode_reward": 586.2816919492797, "episode": 107.0, "batch_reward": 0.4861175894141197, "critic_loss": 0.3049679785221815, "actor_loss": -52.45758933258057, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.924366235733032, "step": 107000}
{"episode_reward": 355.2295224892527, "episode": 108.0, "batch_reward": 0.4856768150627613, "critic_loss": 0.33438695296645166, "actor_loss": -52.32437322235108, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.466752767562866, "step": 108000}
{"episode_reward": 615.5278003718978, "episode": 109.0, "batch_reward": 0.48620552828907965, "critic_loss": 0.31513817091286184, "actor_loss": -52.572524238586425, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.88902735710144, "step": 109000}
{"episode_reward": 628.5507500976527, "episode": 110.0, "batch_reward": 0.48509682759642603, "critic_loss": 0.3377483159303665, "actor_loss": -52.205879447937015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.1502525806427, "step": 110000}
{"episode_reward": 206.265961246613, "episode": 111.0, "batch_reward": 0.4852312219440937, "critic_loss": 0.32635866291821003, "actor_loss": -52.757847953796386, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.51636457443237, "step": 111000}
{"episode_reward": 574.3640077321262, "episode": 112.0, "batch_reward": 0.4864258810579777, "critic_loss": 0.3265907196551561, "actor_loss": -52.51925402832031, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.20950484275818, "step": 112000}
{"episode_reward": 633.7431440672858, "episode": 113.0, "batch_reward": 0.48780849188566205, "critic_loss": 0.3284071701020002, "actor_loss": -52.604028190612794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.923526525497437, "step": 113000}
{"episode_reward": 631.7578739833664, "episode": 114.0, "batch_reward": 0.4878867183327675, "critic_loss": 0.32439688363671304, "actor_loss": -52.7977833404541, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.392416954040527, "step": 114000}
{"episode_reward": 594.7880661394576, "episode": 115.0, "batch_reward": 0.48921084865927694, "critic_loss": 0.3264173818230629, "actor_loss": -52.81303707885742, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.687658071517944, "step": 115000}
{"episode_reward": 567.2195467627197, "episode": 116.0, "batch_reward": 0.4903703518509865, "critic_loss": 0.33398102210462094, "actor_loss": -52.912441246032714, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.949764490127563, "step": 116000}
{"episode_reward": 621.2804581918261, "episode": 117.0, "batch_reward": 0.49228354305028915, "critic_loss": 0.3287771092355251, "actor_loss": -52.98034281158447, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.958189487457275, "step": 117000}
{"episode_reward": 642.6450772924951, "episode": 118.0, "batch_reward": 0.49195610091090203, "critic_loss": 0.3209453860372305, "actor_loss": -53.09720669555664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.607151985168457, "step": 118000}
{"episode_reward": 645.3717670558567, "episode": 119.0, "batch_reward": 0.49351874125003814, "critic_loss": 0.32305241310596466, "actor_loss": -53.3317731628418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.742518424987793, "step": 119000}
{"episode_reward": 650.1065657058512, "episode": 120.0, "batch_reward": 0.49300093626976016, "critic_loss": 0.3109210437089205, "actor_loss": -52.880519897460935, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.820466995239258, "step": 120000}
{"episode_reward": 580.3795073620862, "episode": 121.0, "batch_reward": 0.49570099702477455, "critic_loss": 0.3172976130247116, "actor_loss": -53.21196078491211, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.859989404678345, "step": 121000}
{"episode_reward": 617.0290730500171, "episode": 122.0, "batch_reward": 0.49621266970038413, "critic_loss": 0.3211696298122406, "actor_loss": -53.178782577514646, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.140213012695312, "step": 122000}
{"episode_reward": 598.7673916449864, "episode": 123.0, "batch_reward": 0.49790603840351105, "critic_loss": 0.32692165473103524, "actor_loss": -52.80296866607666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.84087371826172, "step": 123000}
{"episode_reward": 354.3385286124212, "episode": 124.0, "batch_reward": 0.49711467409133914, "critic_loss": 0.3268091879338026, "actor_loss": -53.33361533355713, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.27944278717041, "step": 124000}
{"episode_reward": 644.3788160981965, "episode": 125.0, "batch_reward": 0.4974511196911335, "critic_loss": 0.33844843642413613, "actor_loss": -53.38538327789307, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.789499759674072, "step": 125000}
{"episode_reward": 612.1884180235505, "episode": 126.0, "batch_reward": 0.49856952399015425, "critic_loss": 0.3362929861545563, "actor_loss": -53.50294063568115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.9047372341156, "step": 126000}
{"episode_reward": 671.2080438916768, "episode": 127.0, "batch_reward": 0.5004707784950733, "critic_loss": 0.3348832414448261, "actor_loss": -53.62312455749512, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.869735956192017, "step": 127000}
{"episode_reward": 624.5033903259695, "episode": 128.0, "batch_reward": 0.50062134796381, "critic_loss": 0.3375713101476431, "actor_loss": -53.92781455993652, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.39000177383423, "step": 128000}
{"episode_reward": 623.3300305771446, "episode": 129.0, "batch_reward": 0.501574799746275, "critic_loss": 0.3244077784270048, "actor_loss": -54.107629264831544, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.55183482170105, "step": 129000}
{"episode_reward": 624.7056498051556, "episode": 130.0, "batch_reward": 0.5025093878209591, "critic_loss": 0.33188858376443386, "actor_loss": -53.834924209594725, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.879084825515747, "step": 130000}
{"episode_reward": 536.7917477221647, "episode": 131.0, "batch_reward": 0.5035739557445049, "critic_loss": 0.3182435363084078, "actor_loss": -54.35548913574219, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.40089154243469, "step": 131000}
{"episode_reward": 642.3241151796876, "episode": 132.0, "batch_reward": 0.5054136063754558, "critic_loss": 0.3176127766221762, "actor_loss": -54.05916961669922, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.81345772743225, "step": 132000}
{"episode_reward": 636.6531144053048, "episode": 133.0, "batch_reward": 0.5044241409599781, "critic_loss": 0.31318880189955234, "actor_loss": -54.22496182250977, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.02488422393799, "step": 133000}
{"episode_reward": 613.5289788816846, "episode": 134.0, "batch_reward": 0.5063117018938065, "critic_loss": 0.321000887170434, "actor_loss": -54.419482299804685, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.86674475669861, "step": 134000}
{"episode_reward": 621.6273630519626, "episode": 135.0, "batch_reward": 0.5075407581925392, "critic_loss": 0.3343604042828083, "actor_loss": -54.56069021606445, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.823620319366455, "step": 135000}
{"episode_reward": 624.3981225549517, "episode": 136.0, "batch_reward": 0.5071173587143422, "critic_loss": 0.34240099424123766, "actor_loss": -54.76835892486572, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.623125076293945, "step": 136000}
{"episode_reward": 423.75531432302193, "episode": 137.0, "batch_reward": 0.5060138953924179, "critic_loss": 0.3587810185700655, "actor_loss": -54.212905380249026, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.94846272468567, "step": 137000}
{"episode_reward": 655.156243655255, "episode": 138.0, "batch_reward": 0.5086840737462044, "critic_loss": 0.34497416846454143, "actor_loss": -54.29331121826172, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.4614315032959, "step": 138000}
{"episode_reward": 659.0971840596724, "episode": 139.0, "batch_reward": 0.5087731773257256, "critic_loss": 0.3363177547156811, "actor_loss": -54.386856895446776, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.192636966705322, "step": 139000}
{"episode_reward": 641.9451725118173, "episode": 140.0, "batch_reward": 0.5096027585566044, "critic_loss": 0.3373059805333614, "actor_loss": -54.38920314788818, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.957153797149658, "step": 140000}
{"episode_reward": 656.824761711517, "episode": 141.0, "batch_reward": 0.5119789656698703, "critic_loss": 0.3367209141850471, "actor_loss": -54.45938272094727, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.16390681266785, "step": 141000}
{"episode_reward": 641.7092041317433, "episode": 142.0, "batch_reward": 0.5118700037002564, "critic_loss": 0.3302040521204472, "actor_loss": -54.616638809204105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.784034490585327, "step": 142000}
{"episode_reward": 666.1819074480169, "episode": 143.0, "batch_reward": 0.5138247395455837, "critic_loss": 0.33913084830343726, "actor_loss": -54.920487884521485, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.838279962539673, "step": 143000}
{"episode_reward": 619.7266615311122, "episode": 144.0, "batch_reward": 0.5146635372042656, "critic_loss": 0.3268679273277521, "actor_loss": -55.1427940826416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.88917875289917, "step": 144000}
{"episode_reward": 619.5002476981492, "episode": 145.0, "batch_reward": 0.5155664532482624, "critic_loss": 0.33518525105714797, "actor_loss": -55.010930404663085, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.66075301170349, "step": 145000}
{"episode_reward": 661.2700769073836, "episode": 146.0, "batch_reward": 0.5144272421300411, "critic_loss": 0.3449930727630854, "actor_loss": -54.90268444824219, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.74393916130066, "step": 146000}
{"episode_reward": 631.056676935512, "episode": 147.0, "batch_reward": 0.51646365827322, "critic_loss": 0.35489681066572665, "actor_loss": -55.257393592834475, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.090960025787354, "step": 147000}
{"episode_reward": 625.8965744482425, "episode": 148.0, "batch_reward": 0.5179799675643444, "critic_loss": 0.3359924378693104, "actor_loss": -54.978234298706056, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.882691144943237, "step": 148000}
{"episode_reward": 630.8143626458568, "episode": 149.0, "batch_reward": 0.5183065058887005, "critic_loss": 0.34682259398698806, "actor_loss": -55.22640693664551, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.96432113647461, "step": 149000}
{"episode_reward": 594.1199865210502, "episode": 150.0, "batch_reward": 0.5197662506401539, "critic_loss": 0.3278345481902361, "actor_loss": -55.34537092590332, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
