{"episode_reward": 0.0, "episode": 1.0, "duration": 19.45561170578003, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.592301368713379, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2808089272186493, "critic_loss": 0.030851905922634915, "actor_loss": -15.446710300047462, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 70.17022585868835, "step": 3000}
{"episode_reward": 21.394546863642518, "episode": 4.0, "batch_reward": 0.18029108899831772, "critic_loss": 0.025768970942124724, "actor_loss": -13.368336627006531, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27578830718994, "step": 4000}
{"episode_reward": 22.306794108605256, "episode": 5.0, "batch_reward": 0.14884402479231357, "critic_loss": 0.04483923018351197, "actor_loss": -10.805179293870927, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.23088049888611, "step": 5000}
{"episode_reward": 91.18948512210527, "episode": 6.0, "batch_reward": 0.136687284052372, "critic_loss": 0.05735320663638413, "actor_loss": -10.779367679178716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.96363663673401, "step": 6000}
{"episode_reward": 39.36685860466626, "episode": 7.0, "batch_reward": 0.11972793599963188, "critic_loss": 0.05581946805678308, "actor_loss": -9.513806962043047, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.548537969589233, "step": 7000}
{"episode_reward": 18.794770028137187, "episode": 8.0, "batch_reward": 0.11071985322237014, "critic_loss": 0.06261440418474376, "actor_loss": -9.041332340478897, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.92155623435974, "step": 8000}
{"episode_reward": 79.83865828785937, "episode": 9.0, "batch_reward": 0.10640553417056799, "critic_loss": 0.0725398109164089, "actor_loss": -10.822852698087692, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.75969648361206, "step": 9000}
{"episode_reward": 90.85857238389241, "episode": 10.0, "batch_reward": 0.10860716842859984, "critic_loss": 0.07208000004291534, "actor_loss": -10.372394612669945, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.70991849899292, "step": 10000}
{"episode_reward": 168.28986050681937, "episode": 11.0, "batch_reward": 0.11406521800160407, "critic_loss": 0.08108618580549955, "actor_loss": -12.566247059822082, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.41616940498352, "step": 11000}
{"episode_reward": 134.2073353155017, "episode": 12.0, "batch_reward": 0.11602730343490839, "critic_loss": 0.09259908082708716, "actor_loss": -12.858780024051667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.021075010299683, "step": 12000}
{"episode_reward": 135.74130857507183, "episode": 13.0, "batch_reward": 0.1169977001324296, "critic_loss": 0.09162722255662084, "actor_loss": -13.467112386226654, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.445210456848145, "step": 13000}
{"episode_reward": 141.24985438165012, "episode": 14.0, "batch_reward": 0.1197128227353096, "critic_loss": 0.10030945479869842, "actor_loss": -13.011856382846831, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.980710744857788, "step": 14000}
{"episode_reward": 133.76912212977626, "episode": 15.0, "batch_reward": 0.1211652453392744, "critic_loss": 0.11580153435841203, "actor_loss": -14.753395255565643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.683197259902954, "step": 15000}
{"episode_reward": 152.6436187029977, "episode": 16.0, "batch_reward": 0.12083017937839031, "critic_loss": 0.1154691789932549, "actor_loss": -14.687074620246888, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.873452186584473, "step": 16000}
{"episode_reward": 101.76615078244821, "episode": 17.0, "batch_reward": 0.12394751836359501, "critic_loss": 0.1446970296278596, "actor_loss": -14.56978400707245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.667328357696533, "step": 17000}
{"episode_reward": 212.17299810594469, "episode": 18.0, "batch_reward": 0.1260248311534524, "critic_loss": 0.14394019982963802, "actor_loss": -14.41966830444336, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.523619413375854, "step": 18000}
{"episode_reward": 88.28691362203081, "episode": 19.0, "batch_reward": 0.12622128915041686, "critic_loss": 0.15443519839644432, "actor_loss": -16.188087673187255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.722344875335693, "step": 19000}
{"episode_reward": 164.05307249662084, "episode": 20.0, "batch_reward": 0.1272199606448412, "critic_loss": 0.15991371554881334, "actor_loss": -16.112897132873535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.951370000839233, "step": 20000}
{"episode_reward": 145.31932589552463, "episode": 21.0, "batch_reward": 0.12764108519256115, "critic_loss": 0.14972539330273868, "actor_loss": -16.859952569007874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.53471899032593, "step": 21000}
{"episode_reward": 96.08266048829667, "episode": 22.0, "batch_reward": 0.12511586060374974, "critic_loss": 0.15030567100644113, "actor_loss": -15.79103648853302, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.652925491333008, "step": 22000}
{"episode_reward": 69.04554825179443, "episode": 23.0, "batch_reward": 0.12367756614089012, "critic_loss": 0.15990519038587808, "actor_loss": -14.841435480117799, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.287370681762695, "step": 23000}
{"episode_reward": 82.40051992328438, "episode": 24.0, "batch_reward": 0.1240462454482913, "critic_loss": 0.20378623152524233, "actor_loss": -15.786006203651429, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.295525789260864, "step": 24000}
{"episode_reward": 264.5493382383977, "episode": 25.0, "batch_reward": 0.12974709463119508, "critic_loss": 0.2085328633710742, "actor_loss": -16.61058317565918, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.50640320777893, "step": 25000}
{"episode_reward": 246.61906189290772, "episode": 26.0, "batch_reward": 0.13139537156373263, "critic_loss": 0.22126985850185155, "actor_loss": -16.907520696640013, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.46584129333496, "step": 26000}
{"episode_reward": 88.95142935656484, "episode": 27.0, "batch_reward": 0.13230247722566127, "critic_loss": 0.21390520407259464, "actor_loss": -17.017962591171266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.054680585861206, "step": 27000}
{"episode_reward": 146.92000723361116, "episode": 28.0, "batch_reward": 0.12970824209600687, "critic_loss": 0.209550872720778, "actor_loss": -17.205000663757325, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.69287347793579, "step": 28000}
{"episode_reward": 38.86674420538233, "episode": 29.0, "batch_reward": 0.13216308519244194, "critic_loss": 0.26635767333954574, "actor_loss": -17.552761287689208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.920694828033447, "step": 29000}
{"episode_reward": 318.6471120606163, "episode": 30.0, "batch_reward": 0.13234637861698867, "critic_loss": 0.23812150256335735, "actor_loss": -17.687124584198, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.40065312385559, "step": 30000}
{"episode_reward": 16.29092001886404, "episode": 31.0, "batch_reward": 0.13261684569716453, "critic_loss": 0.25829014898091557, "actor_loss": -17.86992914581299, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.94229459762573, "step": 31000}
{"episode_reward": 244.30262751718948, "episode": 32.0, "batch_reward": 0.13414727697521447, "critic_loss": 0.2872557915598154, "actor_loss": -18.83021171760559, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.456836938858032, "step": 32000}
{"episode_reward": 125.73418102648631, "episode": 33.0, "batch_reward": 0.13500781885534524, "critic_loss": 0.28606097666174174, "actor_loss": -18.75113077354431, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.71920394897461, "step": 33000}
{"episode_reward": 195.3830860799586, "episode": 34.0, "batch_reward": 0.13609957094490527, "critic_loss": 0.30932530675828457, "actor_loss": -18.460778636932375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.113354206085205, "step": 34000}
{"episode_reward": 183.82546168824672, "episode": 35.0, "batch_reward": 0.13578871693462133, "critic_loss": 0.3423456405103207, "actor_loss": -19.216466550827025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.27065134048462, "step": 35000}
{"episode_reward": 18.445402952359654, "episode": 36.0, "batch_reward": 0.13297046640515328, "critic_loss": 0.32896276058256624, "actor_loss": -19.13644728279114, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30392360687256, "step": 36000}
{"episode_reward": 84.38080020273549, "episode": 37.0, "batch_reward": 0.13297917595505715, "critic_loss": 0.4173259111940861, "actor_loss": -19.062023139953613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.22381091117859, "step": 37000}
{"episode_reward": 240.58878796286797, "episode": 38.0, "batch_reward": 0.13559439132362605, "critic_loss": 0.42239760345220567, "actor_loss": -19.234172193527222, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.80188488960266, "step": 38000}
{"episode_reward": 103.98209708891433, "episode": 39.0, "batch_reward": 0.13550081989169122, "critic_loss": 0.4445212865024805, "actor_loss": -20.23878726577759, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.372220039367676, "step": 39000}
{"episode_reward": 287.6756462458762, "episode": 40.0, "batch_reward": 0.1383181649595499, "critic_loss": 0.5080184056460857, "actor_loss": -20.61815878677368, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.860310554504395, "step": 40000}
{"episode_reward": 88.910239548121, "episode": 41.0, "batch_reward": 0.13847219282388687, "critic_loss": 0.499978566378355, "actor_loss": -20.953769243240355, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.376737117767334, "step": 41000}
{"episode_reward": 195.59335090564795, "episode": 42.0, "batch_reward": 0.13740143139660357, "critic_loss": 0.5080528604239225, "actor_loss": -20.45566753768921, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.918330192565918, "step": 42000}
{"episode_reward": 54.82346494151317, "episode": 43.0, "batch_reward": 0.13886543286591768, "critic_loss": 0.48323670871555807, "actor_loss": -20.988174728393556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.763696908950806, "step": 43000}
{"episode_reward": 339.9965183748851, "episode": 44.0, "batch_reward": 0.1425988003537059, "critic_loss": 0.534775816038251, "actor_loss": -21.36104006385803, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.02093243598938, "step": 44000}
{"episode_reward": 189.16257972366046, "episode": 45.0, "batch_reward": 0.1428582269847393, "critic_loss": 0.5076083049327135, "actor_loss": -21.68040626335144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.216938734054565, "step": 45000}
{"episode_reward": 118.2667904749841, "episode": 46.0, "batch_reward": 0.14264714274555446, "critic_loss": 0.5030544312745333, "actor_loss": -21.88306036758423, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.479270458221436, "step": 46000}
{"episode_reward": 269.2030794793627, "episode": 47.0, "batch_reward": 0.14400746221840383, "critic_loss": 0.5267399736344814, "actor_loss": -21.837310539245607, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.914523363113403, "step": 47000}
{"episode_reward": 45.05240984129615, "episode": 48.0, "batch_reward": 0.14423460645973682, "critic_loss": 0.544744856223464, "actor_loss": -21.92920516586304, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.327775478363037, "step": 48000}
{"episode_reward": 253.74106127035458, "episode": 49.0, "batch_reward": 0.14694941381365062, "critic_loss": 0.5345418160706759, "actor_loss": -22.41678343963623, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.641195058822632, "step": 49000}
{"episode_reward": 304.8243881375627, "episode": 50.0, "batch_reward": 0.14881313046067954, "critic_loss": 0.6096246838271618, "actor_loss": -22.809994102478026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.895140886306763, "step": 50000}
{"episode_reward": 301.8154452426221, "episode": 51.0, "batch_reward": 0.15027944668382406, "critic_loss": 0.6121198859214783, "actor_loss": -23.271680252075196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.944446086883545, "step": 51000}
{"episode_reward": 104.52586373689272, "episode": 52.0, "batch_reward": 0.15042413045465947, "critic_loss": 0.5874315190911293, "actor_loss": -23.764785911560057, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.40070652961731, "step": 52000}
{"episode_reward": 131.83419795096796, "episode": 53.0, "batch_reward": 0.15043672989308834, "critic_loss": 0.578563630670309, "actor_loss": -23.694152538299562, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.109785318374634, "step": 53000}
{"episode_reward": 126.49044930887787, "episode": 54.0, "batch_reward": 0.15025867000222207, "critic_loss": 0.5434448351562023, "actor_loss": -23.500931343078612, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.798640727996826, "step": 54000}
{"episode_reward": 264.77099793476907, "episode": 55.0, "batch_reward": 0.15128457786887883, "critic_loss": 0.6280120374560356, "actor_loss": -23.572518463134767, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.201208353042603, "step": 55000}
{"episode_reward": 199.62883630299066, "episode": 56.0, "batch_reward": 0.1537348095998168, "critic_loss": 0.6456228186190128, "actor_loss": -24.114373329162596, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.73362135887146, "step": 56000}
{"episode_reward": 320.87513368452124, "episode": 57.0, "batch_reward": 0.15523095378279686, "critic_loss": 0.6609763047099113, "actor_loss": -24.54081311035156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.281249523162842, "step": 57000}
{"episode_reward": 40.98100308165756, "episode": 58.0, "batch_reward": 0.15422476942837238, "critic_loss": 0.6507982883155345, "actor_loss": -24.267513332366942, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.615169525146484, "step": 58000}
{"episode_reward": 121.4564432362224, "episode": 59.0, "batch_reward": 0.15539254865050317, "critic_loss": 0.6506611770093441, "actor_loss": -24.728775035858153, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.819947719573975, "step": 59000}
{"episode_reward": 411.72327300070793, "episode": 60.0, "batch_reward": 0.15886024388670922, "critic_loss": 0.6578069984912872, "actor_loss": -25.2390842628479, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54030704498291, "step": 60000}
{"episode_reward": 388.98641067207734, "episode": 61.0, "batch_reward": 0.16169631941616536, "critic_loss": 0.6540404981970787, "actor_loss": -25.34351988220215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.93371772766113, "step": 61000}
{"episode_reward": 254.7943986168914, "episode": 62.0, "batch_reward": 0.1644264983087778, "critic_loss": 0.6568253466486931, "actor_loss": -25.51339096069336, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.891092777252197, "step": 62000}
{"episode_reward": 244.6520021723928, "episode": 63.0, "batch_reward": 0.16331714466959238, "critic_loss": 0.6639163005948067, "actor_loss": -25.71597124862671, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.919886589050293, "step": 63000}
{"episode_reward": 217.98405429887495, "episode": 64.0, "batch_reward": 0.16348690152168274, "critic_loss": 0.6711795112788678, "actor_loss": -25.97665328216553, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.550727128982544, "step": 64000}
{"episode_reward": 1.245135794399416, "episode": 65.0, "batch_reward": 0.1622098888605833, "critic_loss": 0.645457807391882, "actor_loss": -26.213980728149416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.177839756011963, "step": 65000}
{"episode_reward": 194.03051356542687, "episode": 66.0, "batch_reward": 0.16300378002226354, "critic_loss": 0.6007630598545074, "actor_loss": -26.208787574768067, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.01218819618225, "step": 66000}
{"episode_reward": 94.79694809179955, "episode": 67.0, "batch_reward": 0.16072641446441413, "critic_loss": 0.5564326541125775, "actor_loss": -26.07431438446045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.01663899421692, "step": 67000}
{"episode_reward": 132.80829991332106, "episode": 68.0, "batch_reward": 0.15981381572782993, "critic_loss": 0.5344059190899134, "actor_loss": -25.907259994506838, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.793386459350586, "step": 68000}
{"episode_reward": 4.549431596638088, "episode": 69.0, "batch_reward": 0.15746145033836365, "critic_loss": 0.5033151595443487, "actor_loss": -25.74927604675293, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.520610332489014, "step": 69000}
{"episode_reward": 4.761616776104255, "episode": 70.0, "batch_reward": 0.15522385938465597, "critic_loss": 0.4790045872628689, "actor_loss": -25.92157773590088, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.608482360839844, "step": 70000}
{"episode_reward": 7.357381377408749, "episode": 71.0, "batch_reward": 0.1544800030142069, "critic_loss": 0.4800429036319256, "actor_loss": -25.900052661895753, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.39016938209534, "step": 71000}
{"episode_reward": 57.66802902349065, "episode": 72.0, "batch_reward": 0.15485376804322004, "critic_loss": 0.49370709961652753, "actor_loss": -25.854019474029542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.98439311981201, "step": 72000}
{"episode_reward": 278.7618490286608, "episode": 73.0, "batch_reward": 0.15500790490210056, "critic_loss": 0.5127545676231384, "actor_loss": -25.92183966064453, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.224668502807617, "step": 73000}
{"episode_reward": 68.40902350406286, "episode": 74.0, "batch_reward": 0.1531682179272175, "critic_loss": 0.4849509886652231, "actor_loss": -25.714121417999266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.200849771499634, "step": 74000}
{"episode_reward": 52.622761559450865, "episode": 75.0, "batch_reward": 0.15413619009405374, "critic_loss": 0.47649808698892593, "actor_loss": -25.717478328704836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.151488780975342, "step": 75000}
{"episode_reward": 391.6580638410636, "episode": 76.0, "batch_reward": 0.1545512805953622, "critic_loss": 0.48307562902569773, "actor_loss": -25.75883836364746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.468081951141357, "step": 76000}
{"episode_reward": 10.582931477738462, "episode": 77.0, "batch_reward": 0.1531186022311449, "critic_loss": 0.4607026160657406, "actor_loss": -25.866411945343017, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.608545303344727, "step": 77000}
{"episode_reward": 14.092616133916685, "episode": 78.0, "batch_reward": 0.15319482673704624, "critic_loss": 0.4308835131376982, "actor_loss": -25.899442546844483, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.664355039596558, "step": 78000}
{"episode_reward": 311.79511445926664, "episode": 79.0, "batch_reward": 0.15263257150352, "critic_loss": 0.3854263340830803, "actor_loss": -25.537965393066408, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.570632696151733, "step": 79000}
{"episode_reward": 163.5564336256623, "episode": 80.0, "batch_reward": 0.15421810276061296, "critic_loss": 0.45367631459236146, "actor_loss": -25.542244079589842, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.89266300201416, "step": 80000}
{"episode_reward": 198.4487302656249, "episode": 81.0, "batch_reward": 0.15574975793063642, "critic_loss": 0.43944739319384096, "actor_loss": -25.549425315856933, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.944852113723755, "step": 81000}
{"episode_reward": 356.86018992994474, "episode": 82.0, "batch_reward": 0.1590319421440363, "critic_loss": 0.4494246214479208, "actor_loss": -25.57517484664917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.767606258392334, "step": 82000}
{"episode_reward": 415.4889359186099, "episode": 83.0, "batch_reward": 0.16158734894543886, "critic_loss": 0.4317522312402725, "actor_loss": -25.690867725372314, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.078044891357422, "step": 83000}
{"episode_reward": 366.5792097930064, "episode": 84.0, "batch_reward": 0.16349238134920596, "critic_loss": 0.450250089943409, "actor_loss": -25.50726581954956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.923677682876587, "step": 84000}
{"episode_reward": 390.618364143649, "episode": 85.0, "batch_reward": 0.16570189376175404, "critic_loss": 0.4843742551058531, "actor_loss": -25.576779808044435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.261480808258057, "step": 85000}
{"episode_reward": 251.0806805596548, "episode": 86.0, "batch_reward": 0.1673132548108697, "critic_loss": 0.4795663342475891, "actor_loss": -25.5626279296875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41676616668701, "step": 86000}
{"episode_reward": 294.2216802308264, "episode": 87.0, "batch_reward": 0.1687300998494029, "critic_loss": 0.48448949252068996, "actor_loss": -25.539283000946046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.881391286849976, "step": 87000}
{"episode_reward": 328.4898558902632, "episode": 88.0, "batch_reward": 0.17038261051476003, "critic_loss": 0.4826083962470293, "actor_loss": -25.50968211364746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.051220417022705, "step": 88000}
{"episode_reward": 191.8962272144439, "episode": 89.0, "batch_reward": 0.17020541615784168, "critic_loss": 0.46063447988033296, "actor_loss": -25.317022575378417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.334282875061035, "step": 89000}
{"episode_reward": 446.39868488231224, "episode": 90.0, "batch_reward": 0.17426387670636176, "critic_loss": 0.4737200057804585, "actor_loss": -25.838915641784666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.196085453033447, "step": 90000}
{"episode_reward": 393.52820264664956, "episode": 91.0, "batch_reward": 0.1767320048213005, "critic_loss": 0.4989810286909342, "actor_loss": -25.723693744659425, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.649770736694336, "step": 91000}
{"episode_reward": 461.1768620568023, "episode": 92.0, "batch_reward": 0.17794131672382354, "critic_loss": 0.4932682223469019, "actor_loss": -26.259862747192383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.304075241088867, "step": 92000}
{"episode_reward": 66.6394656007895, "episode": 93.0, "batch_reward": 0.17800183729827404, "critic_loss": 0.4980170082896948, "actor_loss": -25.974585483551024, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.17152690887451, "step": 93000}
{"episode_reward": 176.90305004847758, "episode": 94.0, "batch_reward": 0.17945388382673264, "critic_loss": 0.485636653393507, "actor_loss": -26.245418544769286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.793004989624023, "step": 94000}
{"episode_reward": 441.2702697161886, "episode": 95.0, "batch_reward": 0.17992035591602326, "critic_loss": 0.48361516384780406, "actor_loss": -26.221557830810546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.467514276504517, "step": 95000}
{"episode_reward": 120.78188104547179, "episode": 96.0, "batch_reward": 0.18083749659359455, "critic_loss": 0.4582936280220747, "actor_loss": -26.02167065048218, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.823786973953247, "step": 96000}
{"episode_reward": 222.32202997995145, "episode": 97.0, "batch_reward": 0.18020852084457875, "critic_loss": 0.43122047947347164, "actor_loss": -25.917723823547362, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.041629314422607, "step": 97000}
{"episode_reward": 171.42927051088844, "episode": 98.0, "batch_reward": 0.1802668003439903, "critic_loss": 0.48479601784050463, "actor_loss": -25.819112720489503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.658767461776733, "step": 98000}
{"episode_reward": 156.90610721220415, "episode": 99.0, "batch_reward": 0.1797374653071165, "critic_loss": 0.46388930149376395, "actor_loss": -25.46173009490967, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.581511974334717, "step": 99000}
{"episode_reward": 190.0921490355225, "episode": 100.0, "batch_reward": 0.18089244160056114, "critic_loss": 0.4892865675240755, "actor_loss": -25.513553005218505, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.65789294242859, "step": 100000}
{"episode_reward": 390.69114993897557, "episode": 101.0, "batch_reward": 0.18306432320177554, "critic_loss": 0.4721698162704706, "actor_loss": -25.755324867248536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.96944260597229, "step": 101000}
{"episode_reward": 451.8503946756959, "episode": 102.0, "batch_reward": 0.18575696355104446, "critic_loss": 0.4536567487567663, "actor_loss": -25.882798038482665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.913999557495117, "step": 102000}
{"episode_reward": 457.1259511752625, "episode": 103.0, "batch_reward": 0.18789399810135365, "critic_loss": 0.4789860849827528, "actor_loss": -25.936562530517577, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.073452472686768, "step": 103000}
{"episode_reward": 237.3041618484792, "episode": 104.0, "batch_reward": 0.188244235470891, "critic_loss": 0.4562259778827429, "actor_loss": -25.867641494750977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30031108856201, "step": 104000}
{"episode_reward": 223.0706903923247, "episode": 105.0, "batch_reward": 0.18970163761079312, "critic_loss": 0.4415271711200476, "actor_loss": -25.71188782501221, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.887587070465088, "step": 105000}
{"episode_reward": 493.95821565247303, "episode": 106.0, "batch_reward": 0.1923289476633072, "critic_loss": 0.4316726434975863, "actor_loss": -25.7962038230896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.78641700744629, "step": 106000}
{"episode_reward": 468.9145507352527, "episode": 107.0, "batch_reward": 0.19437292140722276, "critic_loss": 0.43871496567130086, "actor_loss": -26.180294361114502, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.043285131454468, "step": 107000}
{"episode_reward": 328.37479050361395, "episode": 108.0, "batch_reward": 0.19564112089574337, "critic_loss": 0.4309941299557686, "actor_loss": -26.397585887908935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.297192335128784, "step": 108000}
{"episode_reward": 488.09357822573753, "episode": 109.0, "batch_reward": 0.19907019913196564, "critic_loss": 0.42299779869616033, "actor_loss": -26.58798062515259, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.520333528518677, "step": 109000}
{"episode_reward": 521.7188766810253, "episode": 110.0, "batch_reward": 0.20172232569754123, "critic_loss": 0.401943986967206, "actor_loss": -26.69821788406372, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.901780128479004, "step": 110000}
{"episode_reward": 473.776451277466, "episode": 111.0, "batch_reward": 0.20455556881427764, "critic_loss": 0.3920058254599571, "actor_loss": -26.980526287078856, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.61605477333069, "step": 111000}
{"episode_reward": 423.04345794096906, "episode": 112.0, "batch_reward": 0.20651893566548823, "critic_loss": 0.42199500449001787, "actor_loss": -26.944726432800294, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54710054397583, "step": 112000}
{"episode_reward": 431.5210087088847, "episode": 113.0, "batch_reward": 0.20817202307283877, "critic_loss": 0.3877595775127411, "actor_loss": -27.109310527801515, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.83294653892517, "step": 113000}
{"episode_reward": 529.3253786138594, "episode": 114.0, "batch_reward": 0.2111373414248228, "critic_loss": 0.4139003111422062, "actor_loss": -27.324050090789793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.210450410842896, "step": 114000}
{"episode_reward": 480.36423922773525, "episode": 115.0, "batch_reward": 0.21335071840882303, "critic_loss": 0.37150776527822016, "actor_loss": -27.38688327026367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.613752365112305, "step": 115000}
{"episode_reward": 498.60305784396616, "episode": 116.0, "batch_reward": 0.21612014456093312, "critic_loss": 0.38767776438593865, "actor_loss": -27.765309925079347, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.55515718460083, "step": 116000}
{"episode_reward": 527.9850762739513, "episode": 117.0, "batch_reward": 0.21902557069063186, "critic_loss": 0.3812490952908993, "actor_loss": -27.901147903442382, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.62987518310547, "step": 117000}
{"episode_reward": 547.2954780076351, "episode": 118.0, "batch_reward": 0.2206866558343172, "critic_loss": 0.36375572049617766, "actor_loss": -28.142070236206056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.400968551635742, "step": 118000}
{"episode_reward": 547.6600695446199, "episode": 119.0, "batch_reward": 0.22394372831285, "critic_loss": 0.3740796257555485, "actor_loss": -28.05624068069458, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.21520233154297, "step": 119000}
{"episode_reward": 506.47460593429156, "episode": 120.0, "batch_reward": 0.22623412024974823, "critic_loss": 0.37120988430082796, "actor_loss": -28.060945007324218, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.51369047164917, "step": 120000}
{"episode_reward": 540.9716455549072, "episode": 121.0, "batch_reward": 0.23020857863128186, "critic_loss": 0.3848741279840469, "actor_loss": -28.37231220626831, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.198041677474976, "step": 121000}
{"episode_reward": 551.2047236789379, "episode": 122.0, "batch_reward": 0.23149612052738666, "critic_loss": 0.36888758820295336, "actor_loss": -28.563661304473875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.267431497573853, "step": 122000}
{"episode_reward": 511.8656226106112, "episode": 123.0, "batch_reward": 0.23476683831214903, "critic_loss": 0.37177987983822824, "actor_loss": -28.944984043121337, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.579174041748047, "step": 123000}
{"episode_reward": 532.0603801191115, "episode": 124.0, "batch_reward": 0.23664272986352444, "critic_loss": 0.42970291739702227, "actor_loss": -29.31605850982666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.250136613845825, "step": 124000}
{"episode_reward": 567.6778568511378, "episode": 125.0, "batch_reward": 0.2397022946178913, "critic_loss": 0.4191926020681858, "actor_loss": -29.502997493743898, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.6316237449646, "step": 125000}
{"episode_reward": 544.7579310584554, "episode": 126.0, "batch_reward": 0.24244016833603382, "critic_loss": 0.42180719347298146, "actor_loss": -29.915074558258056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.729981660842896, "step": 126000}
{"episode_reward": 550.5523475060095, "episode": 127.0, "batch_reward": 0.2452101613730192, "critic_loss": 0.39984919911623, "actor_loss": -30.253072395324708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.996412992477417, "step": 127000}
{"episode_reward": 573.1625479358099, "episode": 128.0, "batch_reward": 0.24610852319002152, "critic_loss": 0.4147420081049204, "actor_loss": -30.417039253234865, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.34596872329712, "step": 128000}
{"episode_reward": 519.6585823433447, "episode": 129.0, "batch_reward": 0.24757630540430545, "critic_loss": 0.43283240753412244, "actor_loss": -30.806449085235595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.8519184589386, "step": 129000}
{"episode_reward": 586.4506653932466, "episode": 130.0, "batch_reward": 0.2509275057464838, "critic_loss": 0.3958863193243742, "actor_loss": -30.550937442779542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.601385593414307, "step": 130000}
{"episode_reward": 519.4977234319878, "episode": 131.0, "batch_reward": 0.253620120793581, "critic_loss": 0.39151369616389275, "actor_loss": -31.064687175750734, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.8306941986084, "step": 131000}
{"episode_reward": 382.5866685744111, "episode": 132.0, "batch_reward": 0.25496165907382967, "critic_loss": 0.35241596432030203, "actor_loss": -30.9088956489563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.207384824752808, "step": 132000}
{"episode_reward": 563.3437267074494, "episode": 133.0, "batch_reward": 0.25697094279527666, "critic_loss": 0.3590290260314941, "actor_loss": -31.5597233543396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.225879907608032, "step": 133000}
{"episode_reward": 594.5272515711677, "episode": 134.0, "batch_reward": 0.2589707165658474, "critic_loss": 0.37532650457322597, "actor_loss": -31.622956310272215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23276448249817, "step": 134000}
{"episode_reward": 546.4810449417067, "episode": 135.0, "batch_reward": 0.2617083962112665, "critic_loss": 0.3560460762530565, "actor_loss": -31.615133232116698, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.85479164123535, "step": 135000}
{"episode_reward": 556.7067391888727, "episode": 136.0, "batch_reward": 0.26310903584957124, "critic_loss": 0.38699531289935113, "actor_loss": -31.70416072463989, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34215235710144, "step": 136000}
{"episode_reward": 556.6413096860516, "episode": 137.0, "batch_reward": 0.2648871153444052, "critic_loss": 0.37944479647278784, "actor_loss": -31.646165309906007, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.47746229171753, "step": 137000}
{"episode_reward": 233.0942615277982, "episode": 138.0, "batch_reward": 0.2665860286653042, "critic_loss": 0.3615177983641624, "actor_loss": -31.784423835754396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.002827167510986, "step": 138000}
{"episode_reward": 583.1912443706619, "episode": 139.0, "batch_reward": 0.26755592523515226, "critic_loss": 0.3809484505057335, "actor_loss": -32.00077737426758, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.097089767456055, "step": 139000}
{"episode_reward": 585.8249736972534, "episode": 140.0, "batch_reward": 0.26977147805690765, "critic_loss": 0.36646243415772917, "actor_loss": -32.100317878723146, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.34555697441101, "step": 140000}
{"episode_reward": 553.9111167411453, "episode": 141.0, "batch_reward": 0.27156942626833913, "critic_loss": 0.357604200899601, "actor_loss": -32.11084422302246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.58534526824951, "step": 141000}
{"episode_reward": 559.2789626491872, "episode": 142.0, "batch_reward": 0.27393210750818253, "critic_loss": 0.3500528025776148, "actor_loss": -32.16113943481445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.10754108428955, "step": 142000}
{"episode_reward": 611.5070602828923, "episode": 143.0, "batch_reward": 0.277056565746665, "critic_loss": 0.3540309679210186, "actor_loss": -32.68974414825439, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.962212800979614, "step": 143000}
{"episode_reward": 567.1635123909233, "episode": 144.0, "batch_reward": 0.2786401347666979, "critic_loss": 0.3455200092941523, "actor_loss": -32.69332229995727, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.671977758407593, "step": 144000}
{"episode_reward": 282.5318995123235, "episode": 145.0, "batch_reward": 0.2792580945491791, "critic_loss": 0.35946037213504317, "actor_loss": -32.561965831756595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.824819803237915, "step": 145000}
{"episode_reward": 587.060560746852, "episode": 146.0, "batch_reward": 0.2807457757592201, "critic_loss": 0.34786743581295015, "actor_loss": -33.209375465393066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.37519383430481, "step": 146000}
{"episode_reward": 593.8976258087672, "episode": 147.0, "batch_reward": 0.282914508163929, "critic_loss": 0.3509408890083432, "actor_loss": -33.07392964553833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.594255208969116, "step": 147000}
{"episode_reward": 488.61613053686807, "episode": 148.0, "batch_reward": 0.2843038274049759, "critic_loss": 0.3628988722711802, "actor_loss": -33.25808023834229, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.844234943389893, "step": 148000}
{"episode_reward": 602.8370831442033, "episode": 149.0, "batch_reward": 0.2868334294706583, "critic_loss": 0.36310195855796334, "actor_loss": -33.42065007019043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.16322660446167, "step": 149000}
{"episode_reward": 621.3842112210916, "episode": 150.0, "batch_reward": 0.2892461596131325, "critic_loss": 0.35020943681895733, "actor_loss": -33.626989772796634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
