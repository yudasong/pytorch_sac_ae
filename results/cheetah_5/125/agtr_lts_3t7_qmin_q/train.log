{"episode_reward": 0.0, "episode": 1.0, "duration": 13.7591233253479, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.1925468444824219, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2859318416122199, "critic_loss": 0.23328172045326026, "actor_loss": -47.515418108771826, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 66.31711506843567, "step": 3000}
{"episode_reward": 122.43254396376086, "episode": 4.0, "batch_reward": 0.2350457679927349, "critic_loss": 0.1931820143312216, "actor_loss": -41.63872180938721, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.603651762008667, "step": 4000}
{"episode_reward": 287.98580556378687, "episode": 5.0, "batch_reward": 0.23501055924594402, "critic_loss": 0.21245817310363055, "actor_loss": -41.91411043548584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.711960077285767, "step": 5000}
{"episode_reward": 134.1036118659952, "episode": 6.0, "batch_reward": 0.21955443507432937, "critic_loss": 0.22284075789898633, "actor_loss": -40.30599395751953, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.457897663116455, "step": 6000}
{"episode_reward": 112.7793883699575, "episode": 7.0, "batch_reward": 0.20580951246619225, "critic_loss": 0.2153611151203513, "actor_loss": -37.19042451095581, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.41677951812744, "step": 7000}
{"episode_reward": 127.49190061307752, "episode": 8.0, "batch_reward": 0.20121947959065437, "critic_loss": 0.22610437355935573, "actor_loss": -35.637556095123294, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.33239221572876, "step": 8000}
{"episode_reward": 260.72018424404587, "episode": 9.0, "batch_reward": 0.20936489926278593, "critic_loss": 0.26199631961435077, "actor_loss": -35.14938318252563, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.437121152877808, "step": 9000}
{"episode_reward": 267.22838661872885, "episode": 10.0, "batch_reward": 0.21316895145177842, "critic_loss": 0.2490575734823942, "actor_loss": -34.79832137298584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.177597761154175, "step": 10000}
{"episode_reward": 159.08517019860918, "episode": 11.0, "batch_reward": 0.20290875333547592, "critic_loss": 0.24427171552181243, "actor_loss": -33.36202779388428, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.176005125045776, "step": 11000}
{"episode_reward": 150.5392591267544, "episode": 12.0, "batch_reward": 0.21243470580875873, "critic_loss": 0.23554366514086722, "actor_loss": -33.83625877761841, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.33957052230835, "step": 12000}
{"episode_reward": 499.39481222180905, "episode": 13.0, "batch_reward": 0.22741406132280825, "critic_loss": 0.25617839872837067, "actor_loss": -34.86851805496216, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.878890991210938, "step": 13000}
{"episode_reward": 257.03830414931434, "episode": 14.0, "batch_reward": 0.23200434052944183, "critic_loss": 0.28959265261888506, "actor_loss": -35.3484243850708, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.382112979888916, "step": 14000}
{"episode_reward": 267.41003515285587, "episode": 15.0, "batch_reward": 0.23396529942750932, "critic_loss": 0.3015505502671003, "actor_loss": -34.55155099487305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.416476249694824, "step": 15000}
{"episode_reward": 382.4403267246249, "episode": 16.0, "batch_reward": 0.24484484076499938, "critic_loss": 0.29447854313254357, "actor_loss": -34.98499187850952, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.789050340652466, "step": 16000}
{"episode_reward": 292.4290670900799, "episode": 17.0, "batch_reward": 0.24773700375854968, "critic_loss": 0.2831737116575241, "actor_loss": -35.301588047027586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.726970434188843, "step": 17000}
{"episode_reward": 367.2660007072479, "episode": 18.0, "batch_reward": 0.2548143560886383, "critic_loss": 0.31805562806129456, "actor_loss": -35.53566478729248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.50011110305786, "step": 18000}
{"episode_reward": 280.7438953068821, "episode": 19.0, "batch_reward": 0.25498954054713246, "critic_loss": 0.3110723511278629, "actor_loss": -34.87996844863891, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.258731842041016, "step": 19000}
{"episode_reward": 227.03177633799646, "episode": 20.0, "batch_reward": 0.25048666056990626, "critic_loss": 0.28940687634050843, "actor_loss": -34.08715036010742, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.653095245361328, "step": 20000}
{"episode_reward": 306.88517348951103, "episode": 21.0, "batch_reward": 0.258138020709157, "critic_loss": 0.2780807514041662, "actor_loss": -34.53018288040161, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.41575050354004, "step": 21000}
{"episode_reward": 322.4088822420587, "episode": 22.0, "batch_reward": 0.26149081157147885, "critic_loss": 0.27575825425982475, "actor_loss": -34.5755952835083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.357690572738647, "step": 22000}
{"episode_reward": 403.1381048183021, "episode": 23.0, "batch_reward": 0.26956156162917616, "critic_loss": 0.27266097839176656, "actor_loss": -35.25665365982056, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.606276512145996, "step": 23000}
{"episode_reward": 487.54597558579616, "episode": 24.0, "batch_reward": 0.27681284242868426, "critic_loss": 0.29821349668502806, "actor_loss": -35.212199619293216, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.692680597305298, "step": 24000}
{"episode_reward": 493.2043498206702, "episode": 25.0, "batch_reward": 0.28707086223363876, "critic_loss": 0.27783304010331633, "actor_loss": -36.361361667633055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.552823543548584, "step": 25000}
{"episode_reward": 559.8378533943354, "episode": 26.0, "batch_reward": 0.2924518739879131, "critic_loss": 0.2784457667917013, "actor_loss": -36.3202548751831, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.481321334838867, "step": 26000}
{"episode_reward": 193.7052374329716, "episode": 27.0, "batch_reward": 0.2931564045250416, "critic_loss": 0.2794754192978144, "actor_loss": -36.09875708770752, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.259142875671387, "step": 27000}
{"episode_reward": 485.9314482111751, "episode": 28.0, "batch_reward": 0.3013646346628666, "critic_loss": 0.28084012839198114, "actor_loss": -36.7890747795105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.33268451690674, "step": 28000}
{"episode_reward": 528.3666039097801, "episode": 29.0, "batch_reward": 0.30885958939790725, "critic_loss": 0.29442886167764665, "actor_loss": -36.834119991302494, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.492162227630615, "step": 29000}
{"episode_reward": 443.6398432914473, "episode": 30.0, "batch_reward": 0.3120108768194914, "critic_loss": 0.33741824960708616, "actor_loss": -37.071777332305906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.608569860458374, "step": 30000}
{"episode_reward": 243.54901922693531, "episode": 31.0, "batch_reward": 0.31092941442131994, "critic_loss": 0.5174267549663782, "actor_loss": -36.526185779571534, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.6623010635376, "step": 31000}
{"episode_reward": 450.20406910678304, "episode": 32.0, "batch_reward": 0.3142032309025526, "critic_loss": 0.6710868077874184, "actor_loss": -36.88937294387817, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.704302072525024, "step": 32000}
{"episode_reward": 473.9985345855293, "episode": 33.0, "batch_reward": 0.3211170499920845, "critic_loss": 0.5933263215571641, "actor_loss": -37.3241621131897, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.66660451889038, "step": 33000}
{"episode_reward": 580.9807494574519, "episode": 34.0, "batch_reward": 0.323813446700573, "critic_loss": 0.6257573487609625, "actor_loss": -37.8223434638977, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.156787872314453, "step": 34000}
{"episode_reward": 137.69950153755596, "episode": 35.0, "batch_reward": 0.3233060149848461, "critic_loss": 0.6929853354990483, "actor_loss": -37.18673748397827, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.927788257598877, "step": 35000}
{"episode_reward": 544.331434049231, "episode": 36.0, "batch_reward": 0.3282362238168716, "critic_loss": 0.7749348790943622, "actor_loss": -37.97351850128174, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.48343014717102, "step": 36000}
{"episode_reward": 602.06531986667, "episode": 37.0, "batch_reward": 0.33514288619160654, "critic_loss": 0.7164096813201905, "actor_loss": -38.27176700592041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.485124588012695, "step": 37000}
{"episode_reward": 395.70105686916435, "episode": 38.0, "batch_reward": 0.338876908659935, "critic_loss": 0.8344316645860672, "actor_loss": -38.52767802810669, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.840604066848755, "step": 38000}
{"episode_reward": 554.2661084504466, "episode": 39.0, "batch_reward": 0.3447900919020176, "critic_loss": 0.9885343932211399, "actor_loss": -38.76511396789551, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.708056926727295, "step": 39000}
{"episode_reward": 596.106979427271, "episode": 40.0, "batch_reward": 0.35027280303835867, "critic_loss": 1.0581220895051957, "actor_loss": -39.509201179504394, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.42653465270996, "step": 40000}
{"episode_reward": 548.7372319871818, "episode": 41.0, "batch_reward": 0.3555302487015724, "critic_loss": 1.1177801878154279, "actor_loss": -40.124065185546876, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.98485064506531, "step": 41000}
{"episode_reward": 563.0596811256253, "episode": 42.0, "batch_reward": 0.36118635556101797, "critic_loss": 1.3747564767599105, "actor_loss": -40.944682823181154, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.70989418029785, "step": 42000}
{"episode_reward": 579.5248474706904, "episode": 43.0, "batch_reward": 0.36549794328212737, "critic_loss": 1.6323634666204452, "actor_loss": -41.81725922393799, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.235438585281372, "step": 43000}
{"episode_reward": 557.7967155811704, "episode": 44.0, "batch_reward": 0.36884852150082587, "critic_loss": 1.9157412875294686, "actor_loss": -42.77855311584473, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.19455099105835, "step": 44000}
{"episode_reward": 542.870756302208, "episode": 45.0, "batch_reward": 0.37104974123835566, "critic_loss": 2.417070650458336, "actor_loss": -43.33346466064453, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.392088413238525, "step": 45000}
{"episode_reward": 265.85147015214676, "episode": 46.0, "batch_reward": 0.36815699416399, "critic_loss": 2.767535238146782, "actor_loss": -43.945341346740726, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.647644996643066, "step": 46000}
{"episode_reward": 204.79171192940498, "episode": 47.0, "batch_reward": 0.36456913179159167, "critic_loss": 3.358777561426163, "actor_loss": -44.538574951171874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.613996505737305, "step": 47000}
{"episode_reward": 57.16779346752941, "episode": 48.0, "batch_reward": 0.35661601558327677, "critic_loss": 3.906486097931862, "actor_loss": -45.32438798522949, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.630909204483032, "step": 48000}
{"episode_reward": 128.33253810194526, "episode": 49.0, "batch_reward": 0.3520508415699005, "critic_loss": 4.895696794271469, "actor_loss": -46.873888275146484, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.64346671104431, "step": 49000}
{"episode_reward": 44.90109334672863, "episode": 50.0, "batch_reward": 0.3451525576412678, "critic_loss": 6.364716732978821, "actor_loss": -48.19666062164307, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.526813507080078, "step": 50000}
{"episode_reward": 91.52635316298968, "episode": 51.0, "batch_reward": 0.34151649090647695, "critic_loss": 8.855871253967285, "actor_loss": -50.168585037231445, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.70313596725464, "step": 51000}
{"episode_reward": 31.281015013208847, "episode": 52.0, "batch_reward": 0.3330155792534351, "critic_loss": 12.819641452789307, "actor_loss": -53.883813926696774, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.64435362815857, "step": 52000}
{"episode_reward": 1.612185144828592, "episode": 53.0, "batch_reward": 0.32763179194927217, "critic_loss": 16.622348521232606, "actor_loss": -58.9821025390625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.669475078582764, "step": 53000}
{"episode_reward": 1.0918555992095804, "episode": 54.0, "batch_reward": 0.32185985910892484, "critic_loss": 21.1162199754715, "actor_loss": -65.2298477783203, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.645527362823486, "step": 54000}
{"episode_reward": 8.128418669697497, "episode": 55.0, "batch_reward": 0.316124309360981, "critic_loss": 22.82387728214264, "actor_loss": -71.9877670211792, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.76679277420044, "step": 55000}
{"episode_reward": 33.25353002336103, "episode": 56.0, "batch_reward": 0.3103274988234043, "critic_loss": 21.253954122543334, "actor_loss": -78.76070806121827, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.64409065246582, "step": 56000}
{"episode_reward": 39.488336245791466, "episode": 57.0, "batch_reward": 0.3069399179816246, "critic_loss": 17.80208635044098, "actor_loss": -83.83005261993408, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.520033836364746, "step": 57000}
{"episode_reward": 23.112958062593474, "episode": 58.0, "batch_reward": 0.3009597602635622, "critic_loss": 14.996749512195587, "actor_loss": -87.57463819122314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.568663120269775, "step": 58000}
{"episode_reward": 59.39733324142951, "episode": 59.0, "batch_reward": 0.29832389537990095, "critic_loss": 12.94639214515686, "actor_loss": -91.71241403961182, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.241573572158813, "step": 59000}
{"episode_reward": 58.87838289986688, "episode": 60.0, "batch_reward": 0.2929898392856121, "critic_loss": 10.921117926597596, "actor_loss": -96.11412372589112, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.117053270339966, "step": 60000}
{"episode_reward": 19.494607275683485, "episode": 61.0, "batch_reward": 0.28911136086285116, "critic_loss": 9.14046249294281, "actor_loss": -96.66900093841552, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.49091863632202, "step": 61000}
{"episode_reward": 38.274881476842786, "episode": 62.0, "batch_reward": 0.28451945406198503, "critic_loss": 7.815604744911194, "actor_loss": -98.26061264801025, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.15476894378662, "step": 62000}
{"episode_reward": 28.94509670813929, "episode": 63.0, "batch_reward": 0.2801457983851433, "critic_loss": 6.638165020227432, "actor_loss": -94.9019746246338, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.776825428009033, "step": 63000}
{"episode_reward": 24.808373941718543, "episode": 64.0, "batch_reward": 0.276904483795166, "critic_loss": 5.372536780118942, "actor_loss": -94.51788893127441, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.467381954193115, "step": 64000}
{"episode_reward": 48.72174702296768, "episode": 65.0, "batch_reward": 0.27303072428703307, "critic_loss": 4.578623317480087, "actor_loss": -92.05519941711425, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.65072202682495, "step": 65000}
{"episode_reward": 64.24697403354422, "episode": 66.0, "batch_reward": 0.26923501294851304, "critic_loss": 4.026860666275025, "actor_loss": -89.93175616455078, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.766377449035645, "step": 66000}
{"episode_reward": 36.83045163791363, "episode": 67.0, "batch_reward": 0.2666724648475647, "critic_loss": 3.590252002596855, "actor_loss": -88.09224756622315, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.796292066574097, "step": 67000}
{"episode_reward": 120.83657360927369, "episode": 68.0, "batch_reward": 0.26396081610023975, "critic_loss": 3.22630440056324, "actor_loss": -83.16418769836426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.765451908111572, "step": 68000}
{"episode_reward": 255.55203570400465, "episode": 69.0, "batch_reward": 0.2655277772396803, "critic_loss": 2.699315579533577, "actor_loss": -81.4182554397583, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.46549892425537, "step": 69000}
{"episode_reward": 259.9715822826758, "episode": 70.0, "batch_reward": 0.2649703235924244, "critic_loss": 2.3024950639009476, "actor_loss": -82.05530952453613, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.525532245635986, "step": 70000}
{"episode_reward": 242.38052058697377, "episode": 71.0, "batch_reward": 0.2649692457020283, "critic_loss": 1.9960412197113038, "actor_loss": -79.65514297485352, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.51324701309204, "step": 71000}
{"episode_reward": 165.2740781110927, "episode": 72.0, "batch_reward": 0.26197889386117457, "critic_loss": 1.8110479493141174, "actor_loss": -76.24662308502197, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.823031425476074, "step": 72000}
{"episode_reward": 40.43960042084251, "episode": 73.0, "batch_reward": 0.2604082116931677, "critic_loss": 1.7133040373325348, "actor_loss": -74.83199617767335, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.51282548904419, "step": 73000}
{"episode_reward": 266.45723971001564, "episode": 74.0, "batch_reward": 0.2594415358006954, "critic_loss": 1.530777788937092, "actor_loss": -73.71663245391845, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.791285514831543, "step": 74000}
{"episode_reward": 2.0921109094183046, "episode": 75.0, "batch_reward": 0.2551582417488098, "critic_loss": 1.3699165598154068, "actor_loss": -71.98351475524902, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.62068200111389, "step": 75000}
{"episode_reward": 169.2730418545452, "episode": 76.0, "batch_reward": 0.25723628140985966, "critic_loss": 1.2367771722078322, "actor_loss": -71.23593919372559, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.878602027893066, "step": 76000}
{"episode_reward": 328.0867838435414, "episode": 77.0, "batch_reward": 0.2580125998705626, "critic_loss": 1.1009568474292755, "actor_loss": -68.08229954528808, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.570960521697998, "step": 77000}
{"episode_reward": 334.228071427774, "episode": 78.0, "batch_reward": 0.25916251695156095, "critic_loss": 1.011444015264511, "actor_loss": -67.24088782501221, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.907597303390503, "step": 78000}
{"episode_reward": 376.11321387062935, "episode": 79.0, "batch_reward": 0.2595077135413885, "critic_loss": 0.9440214075148106, "actor_loss": -64.065910446167, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.92961573600769, "step": 79000}
{"episode_reward": 361.22820670835006, "episode": 80.0, "batch_reward": 0.2612950156778097, "critic_loss": 0.9906341056823731, "actor_loss": -63.84291974639893, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.798985481262207, "step": 80000}
{"episode_reward": 146.3308588585704, "episode": 81.0, "batch_reward": 0.25931947864592075, "critic_loss": 0.8868448605835437, "actor_loss": -62.69439980316162, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.66030669212341, "step": 81000}
{"episode_reward": 270.4244248424418, "episode": 82.0, "batch_reward": 0.2593395725041628, "critic_loss": 0.7601788304448128, "actor_loss": -62.33841111755371, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.730340480804443, "step": 82000}
{"episode_reward": 378.76069691221693, "episode": 83.0, "batch_reward": 0.262069025143981, "critic_loss": 0.7496108648777008, "actor_loss": -59.29365634155273, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.869795083999634, "step": 83000}
{"episode_reward": 387.641770828437, "episode": 84.0, "batch_reward": 0.26298115149140355, "critic_loss": 0.6751431612670422, "actor_loss": -59.49962218475342, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.519415140151978, "step": 84000}
{"episode_reward": 500.94633490869114, "episode": 85.0, "batch_reward": 0.2656165099591017, "critic_loss": 0.6306036884188652, "actor_loss": -58.05595099639893, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.864001512527466, "step": 85000}
{"episode_reward": 416.48539760067405, "episode": 86.0, "batch_reward": 0.26733013431727887, "critic_loss": 0.6843090088665486, "actor_loss": -56.491333633422855, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.61311650276184, "step": 86000}
{"episode_reward": 133.67787274486864, "episode": 87.0, "batch_reward": 0.26721181866526605, "critic_loss": 0.6732082968354225, "actor_loss": -55.17434845733643, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.32608938217163, "step": 87000}
{"episode_reward": 433.999059699239, "episode": 88.0, "batch_reward": 0.2685931372344494, "critic_loss": 0.6579153500795364, "actor_loss": -53.87984197235107, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.542184352874756, "step": 88000}
{"episode_reward": 405.8890099294456, "episode": 89.0, "batch_reward": 0.26905693823099136, "critic_loss": 0.7056925967931748, "actor_loss": -54.036351539611815, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.429057598114014, "step": 89000}
{"episode_reward": 290.53158097028444, "episode": 90.0, "batch_reward": 0.2697788604348898, "critic_loss": 0.6899358702600003, "actor_loss": -53.666837463378904, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.430363655090332, "step": 90000}
{"episode_reward": 423.844413438287, "episode": 91.0, "batch_reward": 0.2710251414477825, "critic_loss": 0.6733419206738472, "actor_loss": -52.154485855102536, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.52370595932007, "step": 91000}
{"episode_reward": 403.9150607096981, "episode": 92.0, "batch_reward": 0.2718388092070818, "critic_loss": 0.633875828653574, "actor_loss": -51.19731279754639, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.66009831428528, "step": 92000}
{"episode_reward": 55.8323164364535, "episode": 93.0, "batch_reward": 0.2693595118075609, "critic_loss": 0.5965845202803611, "actor_loss": -50.147347373962404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.67678165435791, "step": 93000}
{"episode_reward": 36.26584873919307, "episode": 94.0, "batch_reward": 0.26620228339731694, "critic_loss": 0.5592909690439701, "actor_loss": -49.330622436523434, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.407076358795166, "step": 94000}
{"episode_reward": 3.4309859476234426, "episode": 95.0, "batch_reward": 0.263114732503891, "critic_loss": 0.5149284506738185, "actor_loss": -49.23218277740479, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.478260278701782, "step": 95000}
{"episode_reward": 2.0324708441689774, "episode": 96.0, "batch_reward": 0.26021015441417694, "critic_loss": 0.5015993856489659, "actor_loss": -48.29485273742676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.40661120414734, "step": 96000}
{"episode_reward": 2.4352600972990457, "episode": 97.0, "batch_reward": 0.25846597212553024, "critic_loss": 0.4653211753964424, "actor_loss": -47.715015632629395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.62034845352173, "step": 97000}
{"episode_reward": 1.0506399349216795, "episode": 98.0, "batch_reward": 0.254542743191123, "critic_loss": 0.45721699196100235, "actor_loss": -46.20991551208496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.480734825134277, "step": 98000}
{"episode_reward": 1.8448829932051722, "episode": 99.0, "batch_reward": 0.2524176675826311, "critic_loss": 0.4610662311911583, "actor_loss": -45.5139315032959, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.4714572429657, "step": 99000}
{"episode_reward": 2.0493328254033285, "episode": 100.0, "batch_reward": 0.25090587013959886, "critic_loss": 0.44619270592927934, "actor_loss": -44.88757655334473, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.662829399108887, "step": 100000}
{"episode_reward": 162.00881562267267, "episode": 101.0, "batch_reward": 0.2525406780540943, "critic_loss": 0.46676691725850106, "actor_loss": -44.42918434906006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.82585597038269, "step": 101000}
{"episode_reward": 471.11209035838056, "episode": 102.0, "batch_reward": 0.25323768021166326, "critic_loss": 0.4843411718457937, "actor_loss": -43.88140232849121, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.951273918151855, "step": 102000}
{"episode_reward": 376.65840115344, "episode": 103.0, "batch_reward": 0.255130988702178, "critic_loss": 0.5043434078544379, "actor_loss": -43.622003753662106, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.57277250289917, "step": 103000}
{"episode_reward": 561.1660547891289, "episode": 104.0, "batch_reward": 0.256725628182292, "critic_loss": 0.517558738052845, "actor_loss": -43.23950845336914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.30250859260559, "step": 104000}
{"episode_reward": 446.0130398663025, "episode": 105.0, "batch_reward": 0.26004009960591795, "critic_loss": 0.5045572741925717, "actor_loss": -42.79633736419678, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.436378240585327, "step": 105000}
{"episode_reward": 464.08672431947554, "episode": 106.0, "batch_reward": 0.2611359652876854, "critic_loss": 0.5893501074463129, "actor_loss": -42.244080299377444, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.818706512451172, "step": 106000}
{"episode_reward": 458.89974435940513, "episode": 107.0, "batch_reward": 0.2631405508071184, "critic_loss": 0.6381200423538684, "actor_loss": -41.95816860198975, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.39376401901245, "step": 107000}
{"episode_reward": 608.6644271892559, "episode": 108.0, "batch_reward": 0.2669426285922527, "critic_loss": 0.7068398333191872, "actor_loss": -41.882191459655765, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.611958742141724, "step": 108000}
{"episode_reward": 583.4868375677246, "episode": 109.0, "batch_reward": 0.26937128591537474, "critic_loss": 0.8379358562529087, "actor_loss": -41.67922552490234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.8192036151886, "step": 109000}
{"episode_reward": 606.6825456074204, "episode": 110.0, "batch_reward": 0.2731159417629242, "critic_loss": 1.1277806514799595, "actor_loss": -41.644338302612304, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.793760299682617, "step": 110000}
{"episode_reward": 632.1063003307592, "episode": 111.0, "batch_reward": 0.2750812404751778, "critic_loss": 1.4799552662372588, "actor_loss": -41.52747031402588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.59117341041565, "step": 111000}
{"episode_reward": 102.57089900938608, "episode": 112.0, "batch_reward": 0.2752651843577623, "critic_loss": 1.5455887819230556, "actor_loss": -41.20729797363281, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.400108814239502, "step": 112000}
{"episode_reward": 587.7862674205973, "episode": 113.0, "batch_reward": 0.2755140166729689, "critic_loss": 1.9408313231468202, "actor_loss": -41.09854596710205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.132293701171875, "step": 113000}
{"episode_reward": 104.17123060195856, "episode": 114.0, "batch_reward": 0.27702006193995476, "critic_loss": 1.848672004133463, "actor_loss": -40.87818450164795, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.810217142105103, "step": 114000}
{"episode_reward": 561.8541258918958, "episode": 115.0, "batch_reward": 0.2775388001203537, "critic_loss": 2.1035250590741637, "actor_loss": -40.71276972961426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.40915036201477, "step": 115000}
{"episode_reward": 284.0813259517787, "episode": 116.0, "batch_reward": 0.27689045448601246, "critic_loss": 2.5629733271896837, "actor_loss": -40.62076932525635, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.71892809867859, "step": 116000}
{"episode_reward": 26.336416016998353, "episode": 117.0, "batch_reward": 0.2742582519203424, "critic_loss": 2.972982908785343, "actor_loss": -40.52138024902344, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.90147113800049, "step": 117000}
{"episode_reward": 51.12695057234913, "episode": 118.0, "batch_reward": 0.2728617365807295, "critic_loss": 4.611213649094105, "actor_loss": -40.83291094970703, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.894561767578125, "step": 118000}
{"episode_reward": 110.09938989261539, "episode": 119.0, "batch_reward": 0.2714104828685522, "critic_loss": 7.760577819108963, "actor_loss": -41.39883547210693, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.422209978103638, "step": 119000}
{"episode_reward": 63.18512504767468, "episode": 120.0, "batch_reward": 0.2699922758340836, "critic_loss": 11.048090817689896, "actor_loss": -42.97961142730713, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.6509051322937, "step": 120000}
{"episode_reward": 83.4776685034856, "episode": 121.0, "batch_reward": 0.26849905408918856, "critic_loss": 14.409096855640412, "actor_loss": -45.55969480895996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.462701082229614, "step": 121000}
{"episode_reward": 60.56812591686017, "episode": 122.0, "batch_reward": 0.26558042089641093, "critic_loss": 18.834296397686003, "actor_loss": -49.23220108413696, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.377423763275146, "step": 122000}
{"episode_reward": 30.96617329126016, "episode": 123.0, "batch_reward": 0.26433257445693015, "critic_loss": 25.662712485313417, "actor_loss": -52.04477972412109, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.652904272079468, "step": 123000}
{"episode_reward": 14.964363197352647, "episode": 124.0, "batch_reward": 0.26264955350756647, "critic_loss": 27.756938494682313, "actor_loss": -58.03891399383545, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.36466670036316, "step": 124000}
{"episode_reward": 10.125412321698292, "episode": 125.0, "batch_reward": 0.2618502392619848, "critic_loss": 30.81350279998779, "actor_loss": -63.40150954437256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.024137020111084, "step": 125000}
{"episode_reward": 53.84402353585584, "episode": 126.0, "batch_reward": 0.2579528755098581, "critic_loss": 28.095041584014893, "actor_loss": -66.58957637023926, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.672271013259888, "step": 126000}
{"episode_reward": 43.83721187950081, "episode": 127.0, "batch_reward": 0.25792200143635274, "critic_loss": 28.17465942955017, "actor_loss": -69.29679936218261, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.28748893737793, "step": 127000}
{"episode_reward": 26.548024683918396, "episode": 128.0, "batch_reward": 0.2539765759706497, "critic_loss": 28.484543862342836, "actor_loss": -72.65497640228271, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.555716514587402, "step": 128000}
{"episode_reward": 10.715490508547756, "episode": 129.0, "batch_reward": 0.25362008342146874, "critic_loss": 28.07467360973358, "actor_loss": -74.56352064514161, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.83419632911682, "step": 129000}
{"episode_reward": 19.4650205041222, "episode": 130.0, "batch_reward": 0.2517774405628443, "critic_loss": 28.845033679962157, "actor_loss": -75.38140165710449, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.25283169746399, "step": 130000}
{"episode_reward": 39.04512944836423, "episode": 131.0, "batch_reward": 0.2500810950547457, "critic_loss": 27.68475517463684, "actor_loss": -79.27699385070801, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.4986047744751, "step": 131000}
{"episode_reward": 19.931463915862974, "episode": 132.0, "batch_reward": 0.24813633905351162, "critic_loss": 26.90612639427185, "actor_loss": -78.85259888458252, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.37857174873352, "step": 132000}
{"episode_reward": 29.178894548281605, "episode": 133.0, "batch_reward": 0.24544755344092845, "critic_loss": 24.532321717262267, "actor_loss": -79.75699957275391, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.040141105651855, "step": 133000}
{"episode_reward": 20.404335080713114, "episode": 134.0, "batch_reward": 0.24533391077816485, "critic_loss": 22.060964551925657, "actor_loss": -80.41568645477295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.62929677963257, "step": 134000}
{"episode_reward": 21.270150954073515, "episode": 135.0, "batch_reward": 0.24441856199502945, "critic_loss": 20.75205365371704, "actor_loss": -80.7091037940979, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.481522798538208, "step": 135000}
{"episode_reward": 150.9271608836495, "episode": 136.0, "batch_reward": 0.2419651358425617, "critic_loss": 17.867307862758636, "actor_loss": -81.65921382141113, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.217585802078247, "step": 136000}
{"episode_reward": 262.42239097881395, "episode": 137.0, "batch_reward": 0.24291439378261567, "critic_loss": 16.302825105190276, "actor_loss": -78.85584465789795, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.588490962982178, "step": 137000}
{"episode_reward": 489.9700402930872, "episode": 138.0, "batch_reward": 0.24580699689686297, "critic_loss": 14.526604904651641, "actor_loss": -78.55023416900634, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.786254405975342, "step": 138000}
{"episode_reward": 246.02714170971066, "episode": 139.0, "batch_reward": 0.24515881302952766, "critic_loss": 13.52828134059906, "actor_loss": -78.43780146026612, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.737077474594116, "step": 139000}
{"episode_reward": 45.27605115708193, "episode": 140.0, "batch_reward": 0.2447554297596216, "critic_loss": 12.441331148147583, "actor_loss": -77.09709354400634, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.03156018257141, "step": 140000}
{"episode_reward": 78.55813070106619, "episode": 141.0, "batch_reward": 0.2414554238021374, "critic_loss": 10.675841371059418, "actor_loss": -74.89020328903199, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.91102862358093, "step": 141000}
{"episode_reward": 62.4363069115043, "episode": 142.0, "batch_reward": 0.2406321905851364, "critic_loss": 9.216245755434036, "actor_loss": -75.55469263076782, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.92166519165039, "step": 142000}
{"episode_reward": 106.0001037682735, "episode": 143.0, "batch_reward": 0.24031655034422875, "critic_loss": 8.06851825261116, "actor_loss": -74.68281317138671, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.672718286514282, "step": 143000}
{"episode_reward": 170.65101996729513, "episode": 144.0, "batch_reward": 0.23891258384287356, "critic_loss": 7.295396928548813, "actor_loss": -73.98828549957275, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.46656036376953, "step": 144000}
{"episode_reward": 94.69409524134731, "episode": 145.0, "batch_reward": 0.2371058871150017, "critic_loss": 6.44135102057457, "actor_loss": -72.45375966262817, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.74664545059204, "step": 145000}
{"episode_reward": 35.407264487713114, "episode": 146.0, "batch_reward": 0.23734947936236858, "critic_loss": 6.005203174829483, "actor_loss": -71.60467432403564, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.599375247955322, "step": 146000}
{"episode_reward": 108.14721959763331, "episode": 147.0, "batch_reward": 0.23611173969507218, "critic_loss": 5.666829364538192, "actor_loss": -71.7074001197815, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.48075580596924, "step": 147000}
{"episode_reward": 134.1221200081948, "episode": 148.0, "batch_reward": 0.2352309089899063, "critic_loss": 5.305834454774857, "actor_loss": -69.08494481277465, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.260518074035645, "step": 148000}
{"episode_reward": 76.2584146857362, "episode": 149.0, "batch_reward": 0.2346337887942791, "critic_loss": 5.994877592086792, "actor_loss": -68.91588896179199, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.673070669174194, "step": 149000}
{"episode_reward": 37.06606715664985, "episode": 150.0, "batch_reward": 0.2317396130412817, "critic_loss": 5.055914453744888, "actor_loss": -68.13759725952148, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
