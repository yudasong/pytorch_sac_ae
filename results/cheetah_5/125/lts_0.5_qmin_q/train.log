{"episode_reward": 0.0, "episode": 1.0, "duration": 18.18665599822998, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.512655258178711, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.28456796319654043, "critic_loss": 0.1537164420127948, "actor_loss": -47.396213555917974, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 63.01200318336487, "step": 3000}
{"episode_reward": 93.39939958257722, "episode": 4.0, "batch_reward": 0.21793674142658712, "critic_loss": 0.1482814749851823, "actor_loss": -39.653937644958496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.500917673110962, "step": 4000}
{"episode_reward": 92.61360582105956, "episode": 5.0, "batch_reward": 0.19125786347687243, "critic_loss": 0.1783926109969616, "actor_loss": -35.30332674407959, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.406351566314697, "step": 5000}
{"episode_reward": 176.8287174702167, "episode": 6.0, "batch_reward": 0.19459875087440015, "critic_loss": 0.21510807652771474, "actor_loss": -35.88568719863892, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.513580322265625, "step": 6000}
{"episode_reward": 198.4915780240479, "episode": 7.0, "batch_reward": 0.1835535784959793, "critic_loss": 0.2046887711584568, "actor_loss": -33.329561737060544, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.789714336395264, "step": 7000}
{"episode_reward": 45.169331787269115, "episode": 8.0, "batch_reward": 0.16512168334424496, "critic_loss": 0.18475415803492068, "actor_loss": -30.445016983032225, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.19198179244995, "step": 8000}
{"episode_reward": 38.61281637502761, "episode": 9.0, "batch_reward": 0.151829782679677, "critic_loss": 0.19964888443797826, "actor_loss": -28.628764225006105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.963162899017334, "step": 9000}
{"episode_reward": 67.47040665648397, "episode": 10.0, "batch_reward": 0.14751492508500813, "critic_loss": 0.21391402799636125, "actor_loss": -28.259954063415528, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.490864038467407, "step": 10000}
{"episode_reward": 225.94899291116212, "episode": 11.0, "batch_reward": 0.1593607874289155, "critic_loss": 0.2398470424413681, "actor_loss": -29.915070671081544, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.19522953033447, "step": 11000}
{"episode_reward": 304.6670241834453, "episode": 12.0, "batch_reward": 0.1708536555469036, "critic_loss": 0.27086992566287516, "actor_loss": -31.129533473968507, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.044281482696533, "step": 12000}
{"episode_reward": 282.94618332361205, "episode": 13.0, "batch_reward": 0.17763822025060655, "critic_loss": 0.27499490846693514, "actor_loss": -32.02325871276855, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.62423300743103, "step": 13000}
{"episode_reward": 172.6987028117047, "episode": 14.0, "batch_reward": 0.17658557663857938, "critic_loss": 0.3016034681499004, "actor_loss": -31.815477226257325, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.65844440460205, "step": 14000}
{"episode_reward": 165.682822506457, "episode": 15.0, "batch_reward": 0.1753598988354206, "critic_loss": 0.342247177913785, "actor_loss": -31.35428171157837, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.136858463287354, "step": 15000}
{"episode_reward": 105.06862690021467, "episode": 16.0, "batch_reward": 0.1699334701448679, "critic_loss": 0.5622082359343767, "actor_loss": -30.38213368988037, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.457714557647705, "step": 16000}
{"episode_reward": 85.6657427247979, "episode": 17.0, "batch_reward": 0.17183755326271058, "critic_loss": 0.8048818378895521, "actor_loss": -30.061075881958008, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.835566997528076, "step": 17000}
{"episode_reward": 452.93804287060925, "episode": 18.0, "batch_reward": 0.18779366129636765, "critic_loss": 0.8661964356303214, "actor_loss": -31.13495371246338, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.173053741455078, "step": 18000}
{"episode_reward": 314.34501895743443, "episode": 19.0, "batch_reward": 0.19348596601188184, "critic_loss": 1.1073392200767993, "actor_loss": -31.273596214294432, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.879516124725342, "step": 19000}
{"episode_reward": 234.35386513597132, "episode": 20.0, "batch_reward": 0.19469337777793408, "critic_loss": 1.235272306650877, "actor_loss": -31.104943183898925, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.106783390045166, "step": 20000}
{"episode_reward": 199.59820418697325, "episode": 21.0, "batch_reward": 0.1891999163478613, "critic_loss": 1.5168323232531546, "actor_loss": -30.368671379089356, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.63729500770569, "step": 21000}
{"episode_reward": 30.893922759493375, "episode": 22.0, "batch_reward": 0.18280805614590645, "critic_loss": 1.862748216867447, "actor_loss": -29.68726064300537, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.32657217979431, "step": 22000}
{"episode_reward": 62.980664874852906, "episode": 23.0, "batch_reward": 0.17690790481865407, "critic_loss": 2.1312329471707345, "actor_loss": -29.44502056503296, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.0582377910614, "step": 23000}
{"episode_reward": 20.99725250473792, "episode": 24.0, "batch_reward": 0.17080919536203146, "critic_loss": 2.5332906861305236, "actor_loss": -29.93420548248291, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.180661916732788, "step": 24000}
{"episode_reward": 53.57588918773474, "episode": 25.0, "batch_reward": 0.16605105662345887, "critic_loss": 2.5515341243743896, "actor_loss": -30.649086696624757, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.655386686325073, "step": 25000}
{"episode_reward": 81.61554244113357, "episode": 26.0, "batch_reward": 0.16240333736687898, "critic_loss": 2.5362729412317275, "actor_loss": -31.127708030700685, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.525732040405273, "step": 26000}
{"episode_reward": 59.58813077401595, "episode": 27.0, "batch_reward": 0.16053164557367564, "critic_loss": 2.6075360504388807, "actor_loss": -31.862023975372313, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.446449518203735, "step": 27000}
{"episode_reward": 159.65378509520357, "episode": 28.0, "batch_reward": 0.16014999901503324, "critic_loss": 2.552039729356766, "actor_loss": -33.011575954437255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.31211805343628, "step": 28000}
{"episode_reward": 106.24054111717804, "episode": 29.0, "batch_reward": 0.15868145281076432, "critic_loss": 2.5820136058330534, "actor_loss": -33.305496967315676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.481659173965454, "step": 29000}
{"episode_reward": 153.08741090374608, "episode": 30.0, "batch_reward": 0.1579014421477914, "critic_loss": 2.5826208156347277, "actor_loss": -33.781547061920165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.531423330307007, "step": 30000}
{"episode_reward": 91.42357159462381, "episode": 31.0, "batch_reward": 0.15576773107796907, "critic_loss": 2.5127133243083954, "actor_loss": -33.67451989746094, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.6885621547699, "step": 31000}
{"episode_reward": 99.46717845678388, "episode": 32.0, "batch_reward": 0.15348028113693, "critic_loss": 2.4585659477710724, "actor_loss": -33.55608157348633, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.274020671844482, "step": 32000}
{"episode_reward": 219.81001679342347, "episode": 33.0, "batch_reward": 0.1539702076613903, "critic_loss": 2.253398851633072, "actor_loss": -33.93842432785034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.17108941078186, "step": 33000}
{"episode_reward": 55.4991196190376, "episode": 34.0, "batch_reward": 0.1518236150443554, "critic_loss": 2.0658064879179, "actor_loss": -34.82765086746216, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.352123022079468, "step": 34000}
{"episode_reward": 142.13444669306867, "episode": 35.0, "batch_reward": 0.15087611870467663, "critic_loss": 1.934613196849823, "actor_loss": -33.78667747879028, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.43854856491089, "step": 35000}
{"episode_reward": 43.16942893418093, "episode": 36.0, "batch_reward": 0.147461663082242, "critic_loss": 1.7067431371808053, "actor_loss": -33.867042175292966, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.62756848335266, "step": 36000}
{"episode_reward": 19.650509313824614, "episode": 37.0, "batch_reward": 0.14355272204428912, "critic_loss": 1.5454235144853592, "actor_loss": -33.890967460632325, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.211495399475098, "step": 37000}
{"episode_reward": 1.9584823080890226, "episode": 38.0, "batch_reward": 0.1414211732670665, "critic_loss": 1.628163311600685, "actor_loss": -33.30093188858032, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.340757608413696, "step": 38000}
{"episode_reward": 109.48224899964752, "episode": 39.0, "batch_reward": 0.14241771447658538, "critic_loss": 1.5884041153788566, "actor_loss": -32.75914504241943, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.356980085372925, "step": 39000}
{"episode_reward": 270.73601888859366, "episode": 40.0, "batch_reward": 0.14284974025189875, "critic_loss": 1.5390763500332831, "actor_loss": -32.68579438400268, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.208808183670044, "step": 40000}
{"episode_reward": 117.43486927554135, "episode": 41.0, "batch_reward": 0.14278706037253142, "critic_loss": 1.4733164707422257, "actor_loss": -32.632546772003174, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.11435604095459, "step": 41000}
{"episode_reward": 91.38586462456584, "episode": 42.0, "batch_reward": 0.14314433898776768, "critic_loss": 1.565994165956974, "actor_loss": -32.80663762664795, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.692205667495728, "step": 42000}
{"episode_reward": 223.64651439888584, "episode": 43.0, "batch_reward": 0.14339858923107385, "critic_loss": 1.4154596585035324, "actor_loss": -32.7178243598938, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.16793155670166, "step": 43000}
{"episode_reward": 147.00952760081196, "episode": 44.0, "batch_reward": 0.1442874573841691, "critic_loss": 1.4203807385563851, "actor_loss": -32.80678357315063, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.24894380569458, "step": 44000}
{"episode_reward": 206.91399090672914, "episode": 45.0, "batch_reward": 0.14930942998826505, "critic_loss": 1.4218905819058418, "actor_loss": -32.88517273330689, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.04021143913269, "step": 45000}
{"episode_reward": 325.991464972846, "episode": 46.0, "batch_reward": 0.15239725191891193, "critic_loss": 1.3839578134417534, "actor_loss": -32.87500569534302, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.158483743667603, "step": 46000}
{"episode_reward": 439.5449834885543, "episode": 47.0, "batch_reward": 0.15967622272670268, "critic_loss": 1.240266354560852, "actor_loss": -33.40364692687988, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.34286594390869, "step": 47000}
{"episode_reward": 463.5738038001896, "episode": 48.0, "batch_reward": 0.1651446855291724, "critic_loss": 1.1428808035254479, "actor_loss": -33.89876095199585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.592007160186768, "step": 48000}
{"episode_reward": 398.11830503180573, "episode": 49.0, "batch_reward": 0.16906765899807213, "critic_loss": 1.070019020974636, "actor_loss": -33.44609664154053, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.139936923980713, "step": 49000}
{"episode_reward": 191.50114980866152, "episode": 50.0, "batch_reward": 0.17035907362401487, "critic_loss": 0.9843804864287377, "actor_loss": -33.00701868057251, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.19682765007019, "step": 50000}
{"episode_reward": 430.39838383080104, "episode": 51.0, "batch_reward": 0.17574989986419678, "critic_loss": 0.9165739520192147, "actor_loss": -33.58572003555298, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.43875455856323, "step": 51000}
{"episode_reward": 499.45706828859596, "episode": 52.0, "batch_reward": 0.18309505927562714, "critic_loss": 0.8913892613649368, "actor_loss": -33.41401137924194, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.31284213066101, "step": 52000}
{"episode_reward": 514.2974370535233, "episode": 53.0, "batch_reward": 0.18910552155971527, "critic_loss": 0.7920683462619782, "actor_loss": -33.76037085342407, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.21315860748291, "step": 53000}
{"episode_reward": 453.6947761942297, "episode": 54.0, "batch_reward": 0.19268658924102783, "critic_loss": 0.7098503031134605, "actor_loss": -33.81493863296509, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.66867756843567, "step": 54000}
{"episode_reward": 333.358106277749, "episode": 55.0, "batch_reward": 0.19487897612154484, "critic_loss": 0.665875941991806, "actor_loss": -33.654632217407226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.709192752838135, "step": 55000}
{"episode_reward": 400.0188229915092, "episode": 56.0, "batch_reward": 0.20015178486704827, "critic_loss": 0.7619264491796494, "actor_loss": -33.539278507232666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.159730672836304, "step": 56000}
{"episode_reward": 369.91755003193487, "episode": 57.0, "batch_reward": 0.20247784647345543, "critic_loss": 0.6715421549081803, "actor_loss": -33.509737823486326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.461270332336426, "step": 57000}
{"episode_reward": 476.7640814642955, "episode": 58.0, "batch_reward": 0.20876354312896728, "critic_loss": 0.5589960905015469, "actor_loss": -33.64307186508179, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.071578979492188, "step": 58000}
{"episode_reward": 467.056237613813, "episode": 59.0, "batch_reward": 0.21169623118638992, "critic_loss": 0.5433235186636448, "actor_loss": -33.503135620117185, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.294421195983887, "step": 59000}
{"episode_reward": 382.14885326150824, "episode": 60.0, "batch_reward": 0.2149872041195631, "critic_loss": 0.5119656319767236, "actor_loss": -33.43022045898437, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.77752161026001, "step": 60000}
{"episode_reward": 480.7653141260022, "episode": 61.0, "batch_reward": 0.21943764826655388, "critic_loss": 0.5128873676657677, "actor_loss": -33.37661071014404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.28524136543274, "step": 61000}
{"episode_reward": 500.81209404297664, "episode": 62.0, "batch_reward": 0.22437652239203454, "critic_loss": 0.4958987840861082, "actor_loss": -33.46342181396484, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.20425319671631, "step": 62000}
{"episode_reward": 544.2755910700993, "episode": 63.0, "batch_reward": 0.22835647788643837, "critic_loss": 0.4587345561981201, "actor_loss": -33.636566822052, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.79893732070923, "step": 63000}
{"episode_reward": 556.1866418540857, "episode": 64.0, "batch_reward": 0.2316792003363371, "critic_loss": 0.45839518547058106, "actor_loss": -33.43080201721192, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.595855712890625, "step": 64000}
{"episode_reward": 95.8839993420958, "episode": 65.0, "batch_reward": 0.23240151031315326, "critic_loss": 0.46882519364356995, "actor_loss": -33.19512637329102, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.42117691040039, "step": 65000}
{"episode_reward": 536.8029818881629, "episode": 66.0, "batch_reward": 0.23726808607578279, "critic_loss": 0.4422612148076296, "actor_loss": -33.26874559020996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.16929316520691, "step": 66000}
{"episode_reward": 550.8396002094978, "episode": 67.0, "batch_reward": 0.24168151228129864, "critic_loss": 0.45303123140335083, "actor_loss": -33.55128928375244, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.18540096282959, "step": 67000}
{"episode_reward": 518.4888411105155, "episode": 68.0, "batch_reward": 0.24558107803761958, "critic_loss": 0.46207951901853084, "actor_loss": -33.423170551300046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.380922317504883, "step": 68000}
{"episode_reward": 595.8907649357825, "episode": 69.0, "batch_reward": 0.2501325765252113, "critic_loss": 0.4408034237027168, "actor_loss": -33.76581098937988, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.23606014251709, "step": 69000}
{"episode_reward": 515.8708944878271, "episode": 70.0, "batch_reward": 0.25473223242163656, "critic_loss": 0.435713055446744, "actor_loss": -33.925322689056394, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.661882877349854, "step": 70000}
{"episode_reward": 520.5497441811116, "episode": 71.0, "batch_reward": 0.25844362688064576, "critic_loss": 0.4450440254509449, "actor_loss": -33.8128574256897, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.401137828826904, "step": 71000}
{"episode_reward": 491.5488648470439, "episode": 72.0, "batch_reward": 0.261586234152317, "critic_loss": 0.42455081462860106, "actor_loss": -33.85907927322388, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.164461612701416, "step": 72000}
{"episode_reward": 539.8810531605862, "episode": 73.0, "batch_reward": 0.26523704479634763, "critic_loss": 0.42685629683732984, "actor_loss": -34.000161277771, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.35968780517578, "step": 73000}
{"episode_reward": 525.2653674328186, "episode": 74.0, "batch_reward": 0.2682269580513239, "critic_loss": 0.42789395393431184, "actor_loss": -34.2636330947876, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.191303491592407, "step": 74000}
{"episode_reward": 458.8039354264418, "episode": 75.0, "batch_reward": 0.27280247063934804, "critic_loss": 0.44548596216738223, "actor_loss": -34.38663915634155, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.17328643798828, "step": 75000}
{"episode_reward": 562.8487007049267, "episode": 76.0, "batch_reward": 0.27444939866662027, "critic_loss": 0.4416928211003542, "actor_loss": -34.21665738296509, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.71676206588745, "step": 76000}
{"episode_reward": 467.32973169331484, "episode": 77.0, "batch_reward": 0.2781936984956265, "critic_loss": 0.4521832067221403, "actor_loss": -34.425707138061526, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.462076663970947, "step": 77000}
{"episode_reward": 557.5362010499273, "episode": 78.0, "batch_reward": 0.2817526255398989, "critic_loss": 0.44196002814173696, "actor_loss": -34.84102434539795, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.48742437362671, "step": 78000}
{"episode_reward": 524.4313214921968, "episode": 79.0, "batch_reward": 0.28369949562847613, "critic_loss": 0.4352524773925543, "actor_loss": -34.53910136795044, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.19454598426819, "step": 79000}
{"episode_reward": 510.9230800404918, "episode": 80.0, "batch_reward": 0.28737609580159185, "critic_loss": 0.4291188165694475, "actor_loss": -34.83648447418213, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.98435688018799, "step": 80000}
{"episode_reward": 515.8212739985931, "episode": 81.0, "batch_reward": 0.29051746560633185, "critic_loss": 0.4233288604915142, "actor_loss": -35.14435112762451, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.27969431877136, "step": 81000}
{"episode_reward": 327.9272465300566, "episode": 82.0, "batch_reward": 0.2913951110392809, "critic_loss": 0.43112401954829693, "actor_loss": -35.36266765213013, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.344019412994385, "step": 82000}
{"episode_reward": 541.9651164548801, "episode": 83.0, "batch_reward": 0.2938799851685762, "critic_loss": 0.3976948452889919, "actor_loss": -35.28550164794922, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.68595290184021, "step": 83000}
{"episode_reward": 556.7531231690396, "episode": 84.0, "batch_reward": 0.2974875877946615, "critic_loss": 0.3948611775636673, "actor_loss": -35.428561225891116, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.441566228866577, "step": 84000}
{"episode_reward": 555.8217457071786, "episode": 85.0, "batch_reward": 0.2998412584066391, "critic_loss": 0.3998355067372322, "actor_loss": -35.69536647415161, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.15298557281494, "step": 85000}
{"episode_reward": 521.5346542650808, "episode": 86.0, "batch_reward": 0.30248469053208826, "critic_loss": 0.3802497376650572, "actor_loss": -35.44350867843628, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.435105085372925, "step": 86000}
{"episode_reward": 520.9502110033945, "episode": 87.0, "batch_reward": 0.30496639005839826, "critic_loss": 0.36843186639249326, "actor_loss": -35.62721660614014, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.294848680496216, "step": 87000}
{"episode_reward": 554.0828388437537, "episode": 88.0, "batch_reward": 0.30811994305253027, "critic_loss": 0.3583535938858986, "actor_loss": -35.589651664733886, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.27718734741211, "step": 88000}
{"episode_reward": 547.6043387903844, "episode": 89.0, "batch_reward": 0.3115288383364677, "critic_loss": 0.3410100921392441, "actor_loss": -36.0044075126648, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.727728128433228, "step": 89000}
{"episode_reward": 578.3047021869256, "episode": 90.0, "batch_reward": 0.3134512896835804, "critic_loss": 0.36465268735587597, "actor_loss": -36.400185417175294, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.471999645233154, "step": 90000}
{"episode_reward": 512.9829478731725, "episode": 91.0, "batch_reward": 0.3164226248860359, "critic_loss": 0.3433608088046312, "actor_loss": -36.34338150405884, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.69744277000427, "step": 91000}
{"episode_reward": 584.6203841963558, "episode": 92.0, "batch_reward": 0.31849348287284374, "critic_loss": 0.3403977694064379, "actor_loss": -36.439890422821044, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.316313982009888, "step": 92000}
{"episode_reward": 531.4633137068344, "episode": 93.0, "batch_reward": 0.3202672556042671, "critic_loss": 0.35141564151644705, "actor_loss": -36.67531900024414, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.3329336643219, "step": 93000}
{"episode_reward": 585.354892679678, "episode": 94.0, "batch_reward": 0.32388821864128114, "critic_loss": 0.3471919237822294, "actor_loss": -36.670060001373294, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.184218883514404, "step": 94000}
{"episode_reward": 606.6929351114289, "episode": 95.0, "batch_reward": 0.3273337290287018, "critic_loss": 0.3395149037837982, "actor_loss": -37.49010708618164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.394527196884155, "step": 95000}
{"episode_reward": 579.4188646893854, "episode": 96.0, "batch_reward": 0.32838753309845925, "critic_loss": 0.35234384806454183, "actor_loss": -37.31672202682495, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.538415908813477, "step": 96000}
{"episode_reward": 551.4215902412152, "episode": 97.0, "batch_reward": 0.3319979604780674, "critic_loss": 0.34233511896431446, "actor_loss": -37.668748306274416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.50529956817627, "step": 97000}
{"episode_reward": 592.7253574722151, "episode": 98.0, "batch_reward": 0.3346631403267384, "critic_loss": 0.36964165575802327, "actor_loss": -37.713546981811525, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.149919748306274, "step": 98000}
{"episode_reward": 511.9333701750964, "episode": 99.0, "batch_reward": 0.33618689042329786, "critic_loss": 0.3589921187758446, "actor_loss": -37.842882930755614, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.01280641555786, "step": 99000}
{"episode_reward": 554.467084809898, "episode": 100.0, "batch_reward": 0.3402897152304649, "critic_loss": 0.3559771244078875, "actor_loss": -37.769806381225585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.40626096725464, "step": 100000}
{"episode_reward": 584.3553876129882, "episode": 101.0, "batch_reward": 0.3410515129566193, "critic_loss": 0.3553813802152872, "actor_loss": -38.3264818611145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.61136341094971, "step": 101000}
{"episode_reward": 540.3041676661984, "episode": 102.0, "batch_reward": 0.3427981570959091, "critic_loss": 0.3717336284071207, "actor_loss": -38.49088888931274, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.131208419799805, "step": 102000}
{"episode_reward": 591.3193082059202, "episode": 103.0, "batch_reward": 0.3442772761285305, "critic_loss": 0.3785513598024845, "actor_loss": -38.50179106521607, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.019625902175903, "step": 103000}
{"episode_reward": 573.3880453127606, "episode": 104.0, "batch_reward": 0.3484867533147335, "critic_loss": 0.3648791879862547, "actor_loss": -38.771776210784914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.183741807937622, "step": 104000}
{"episode_reward": 587.0180859395695, "episode": 105.0, "batch_reward": 0.3506194817721844, "critic_loss": 0.37696040257811547, "actor_loss": -38.912602416992186, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.798625469207764, "step": 105000}
{"episode_reward": 613.0436047868628, "episode": 106.0, "batch_reward": 0.3510949612557888, "critic_loss": 0.40502127961814405, "actor_loss": -38.81471471786499, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.2404522895813, "step": 106000}
{"episode_reward": 274.6820354478342, "episode": 107.0, "batch_reward": 0.35212206491827963, "critic_loss": 0.40765568782389167, "actor_loss": -39.04071910476684, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.21734595298767, "step": 107000}
{"episode_reward": 581.851002822255, "episode": 108.0, "batch_reward": 0.354483748704195, "critic_loss": 0.39165102007985114, "actor_loss": -39.309459484100344, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.127393007278442, "step": 108000}
{"episode_reward": 620.1718017554564, "episode": 109.0, "batch_reward": 0.3560564111173153, "critic_loss": 0.37175433768332006, "actor_loss": -39.44780813217163, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.41929316520691, "step": 109000}
{"episode_reward": 552.7629069324076, "episode": 110.0, "batch_reward": 0.3580927200913429, "critic_loss": 0.37637696270644666, "actor_loss": -39.704458278656006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.084394454956055, "step": 110000}
{"episode_reward": 601.9315749934716, "episode": 111.0, "batch_reward": 0.3609607807397842, "critic_loss": 0.36798078756034375, "actor_loss": -40.10343148422241, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.97684860229492, "step": 111000}
{"episode_reward": 574.7106235493056, "episode": 112.0, "batch_reward": 0.3625583776831627, "critic_loss": 0.34894009797275066, "actor_loss": -40.010416923522946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.428736448287964, "step": 112000}
{"episode_reward": 625.585945370252, "episode": 113.0, "batch_reward": 0.36505151948332787, "critic_loss": 0.36474434021115304, "actor_loss": -40.045600551605226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.823421478271484, "step": 113000}
{"episode_reward": 580.6597855760185, "episode": 114.0, "batch_reward": 0.365752125620842, "critic_loss": 0.3462691902369261, "actor_loss": -40.63454809951782, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.153573513031006, "step": 114000}
{"episode_reward": 609.4852141232211, "episode": 115.0, "batch_reward": 0.3692302506268024, "critic_loss": 0.38344547291100023, "actor_loss": -40.615037334442135, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.039770364761353, "step": 115000}
{"episode_reward": 267.81459194023296, "episode": 116.0, "batch_reward": 0.368105908125639, "critic_loss": 0.3696904373764992, "actor_loss": -40.70556308746338, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.368340015411377, "step": 116000}
{"episode_reward": 582.4919801259515, "episode": 117.0, "batch_reward": 0.3694198080599308, "critic_loss": 0.3699136944413185, "actor_loss": -40.46341303253174, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.20993208885193, "step": 117000}
{"episode_reward": 544.1633700329357, "episode": 118.0, "batch_reward": 0.3707472167611122, "critic_loss": 0.358872480019927, "actor_loss": -40.77973212432861, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.596069812774658, "step": 118000}
{"episode_reward": 633.2076702547503, "episode": 119.0, "batch_reward": 0.3735494414269924, "critic_loss": 0.35786187586188317, "actor_loss": -41.258499740600584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.46549391746521, "step": 119000}
{"episode_reward": 609.1847902045816, "episode": 120.0, "batch_reward": 0.3738235078155994, "critic_loss": 0.3753514742702246, "actor_loss": -40.956886234283445, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.19304132461548, "step": 120000}
{"episode_reward": 624.7425605925322, "episode": 121.0, "batch_reward": 0.3778646613657475, "critic_loss": 0.3629655947983265, "actor_loss": -41.516236457824704, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.68474197387695, "step": 121000}
{"episode_reward": 616.0040854353604, "episode": 122.0, "batch_reward": 0.379702705681324, "critic_loss": 0.3652635087221861, "actor_loss": -42.020758193969726, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.293464422225952, "step": 122000}
{"episode_reward": 631.6022029726637, "episode": 123.0, "batch_reward": 0.38263701781630516, "critic_loss": 0.3610049809962511, "actor_loss": -41.83282907104492, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.198373079299927, "step": 123000}
{"episode_reward": 592.5512165004635, "episode": 124.0, "batch_reward": 0.3830725966095924, "critic_loss": 0.3693136381208897, "actor_loss": -42.25044960784912, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.90760374069214, "step": 124000}
{"episode_reward": 630.361344395739, "episode": 125.0, "batch_reward": 0.38482396641373634, "critic_loss": 0.3756313603371382, "actor_loss": -42.104002227783205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.420292615890503, "step": 125000}
{"episode_reward": 620.8364200075986, "episode": 126.0, "batch_reward": 0.3873180420398712, "critic_loss": 0.37400993560254575, "actor_loss": -42.713106224060056, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.421415090560913, "step": 126000}
{"episode_reward": 627.9987420290723, "episode": 127.0, "batch_reward": 0.3880471152663231, "critic_loss": 0.3940508168041706, "actor_loss": -42.863511100769045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.600709438323975, "step": 127000}
{"episode_reward": 577.4594977596415, "episode": 128.0, "batch_reward": 0.3905027401149273, "critic_loss": 0.42067455883324145, "actor_loss": -43.104519332885744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.518418550491333, "step": 128000}
{"episode_reward": 617.3741577751656, "episode": 129.0, "batch_reward": 0.39225794532895086, "critic_loss": 0.43368362614512446, "actor_loss": -43.35937565612793, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.77767515182495, "step": 129000}
{"episode_reward": 588.8966262052721, "episode": 130.0, "batch_reward": 0.39353792279958727, "critic_loss": 0.46267528328299523, "actor_loss": -43.449158302307126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.155226230621338, "step": 130000}
{"episode_reward": 617.6457278663162, "episode": 131.0, "batch_reward": 0.39620177710056304, "critic_loss": 0.48372763516008854, "actor_loss": -43.934313201904295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.390018463134766, "step": 131000}
{"episode_reward": 614.3533880674246, "episode": 132.0, "batch_reward": 0.39796678990125656, "critic_loss": 0.5279770983755588, "actor_loss": -43.847806205749514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.390053510665894, "step": 132000}
{"episode_reward": 660.0379990521044, "episode": 133.0, "batch_reward": 0.39827597388625147, "critic_loss": 0.5285599354207515, "actor_loss": -44.2323136138916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.29713225364685, "step": 133000}
{"episode_reward": 602.1148616006805, "episode": 134.0, "batch_reward": 0.3998169984519482, "critic_loss": 0.5434712241888047, "actor_loss": -44.52896923065185, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.697338819503784, "step": 134000}
{"episode_reward": 610.495936779537, "episode": 135.0, "batch_reward": 0.4024086990952492, "critic_loss": 0.5285334623008966, "actor_loss": -44.52083528900147, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.420220613479614, "step": 135000}
{"episode_reward": 603.4135251720169, "episode": 136.0, "batch_reward": 0.4043497880101204, "critic_loss": 0.5396964183747769, "actor_loss": -45.04233399963379, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.1481831073761, "step": 136000}
{"episode_reward": 626.9842298202591, "episode": 137.0, "batch_reward": 0.40478989097476004, "critic_loss": 0.5861840478330851, "actor_loss": -44.97362725830078, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.542997121810913, "step": 137000}
{"episode_reward": 638.3574348290439, "episode": 138.0, "batch_reward": 0.4069495614171028, "critic_loss": 0.5869511959701776, "actor_loss": -45.16592092895508, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.42920207977295, "step": 138000}
{"episode_reward": 641.1797927531311, "episode": 139.0, "batch_reward": 0.4089703202843666, "critic_loss": 0.5852272575348616, "actor_loss": -45.280637329101566, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.480756044387817, "step": 139000}
{"episode_reward": 626.7811462254261, "episode": 140.0, "batch_reward": 0.40906249725818633, "critic_loss": 0.6093651450872422, "actor_loss": -45.323666648864744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.19642686843872, "step": 140000}
{"episode_reward": 635.5100348974177, "episode": 141.0, "batch_reward": 0.4123651964366436, "critic_loss": 0.6154990875720978, "actor_loss": -45.62004341888428, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.21800518035889, "step": 141000}
{"episode_reward": 654.1788306605514, "episode": 142.0, "batch_reward": 0.4139234982430935, "critic_loss": 0.6712249224931002, "actor_loss": -45.85255852508545, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.688880681991577, "step": 142000}
{"episode_reward": 671.4285728008591, "episode": 143.0, "batch_reward": 0.4157039429843426, "critic_loss": 0.6721230973750353, "actor_loss": -46.01186447906494, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.203030347824097, "step": 143000}
{"episode_reward": 645.4928360267509, "episode": 144.0, "batch_reward": 0.41803650513291357, "critic_loss": 0.7168730107396841, "actor_loss": -46.393472618103026, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.709412097930908, "step": 144000}
{"episode_reward": 435.03640209055123, "episode": 145.0, "batch_reward": 0.41775486451387406, "critic_loss": 0.7739876928329468, "actor_loss": -46.35449517059326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.833820104599, "step": 145000}
{"episode_reward": 625.6656480518839, "episode": 146.0, "batch_reward": 0.41759154561161993, "critic_loss": 0.8700483393222094, "actor_loss": -46.529838386535644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.25277018547058, "step": 146000}
{"episode_reward": 624.1176595650624, "episode": 147.0, "batch_reward": 0.4197008081972599, "critic_loss": 0.9387866556346417, "actor_loss": -46.67423564147949, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.60590410232544, "step": 147000}
{"episode_reward": 614.1887454233098, "episode": 148.0, "batch_reward": 0.4222122372984886, "critic_loss": 0.9360911736190319, "actor_loss": -46.94425768280029, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.561732053756714, "step": 148000}
{"episode_reward": 637.0772570473092, "episode": 149.0, "batch_reward": 0.42283287924528123, "critic_loss": 1.0371850598454475, "actor_loss": -47.160889297485355, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.534881114959717, "step": 149000}
{"episode_reward": 671.6882178667465, "episode": 150.0, "batch_reward": 0.42441682195663455, "critic_loss": 1.0592497987747191, "actor_loss": -47.42182624816895, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
