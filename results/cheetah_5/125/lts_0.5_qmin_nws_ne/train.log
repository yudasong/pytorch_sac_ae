{"episode_reward": 0.0, "episode": 1.0, "duration": 21.13005542755127, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.7804646492004395, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.27947416792773694, "critic_loss": 0.018262338173591536, "actor_loss": -26.822706869190313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 68.95250248908997, "step": 3000}
{"episode_reward": 4.847634499304442, "episode": 4.0, "batch_reward": 0.17391480477899313, "critic_loss": 0.01268166671693325, "actor_loss": -25.132829351425173, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.586612224578857, "step": 4000}
{"episode_reward": 5.701648571608911, "episode": 5.0, "batch_reward": 0.13453890087082981, "critic_loss": 0.016118696013232695, "actor_loss": -21.623996965408324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.829352378845215, "step": 5000}
{"episode_reward": 5.672408428601359, "episode": 6.0, "batch_reward": 0.11084654185920954, "critic_loss": 0.01111089645908214, "actor_loss": -21.49471266746521, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.810280084609985, "step": 6000}
{"episode_reward": 5.513001913504981, "episode": 7.0, "batch_reward": 0.0948152669146657, "critic_loss": 0.013093010079814121, "actor_loss": -21.791621654510497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.165750980377197, "step": 7000}
{"episode_reward": 5.661069960721073, "episode": 8.0, "batch_reward": 0.08369201633147895, "critic_loss": 0.01950534761371091, "actor_loss": -21.073929368495943, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.891207218170166, "step": 8000}
{"episode_reward": 4.661929107953092, "episode": 9.0, "batch_reward": 0.07363612589798868, "critic_loss": 0.017811655529541896, "actor_loss": -20.580598575115204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.042089223861694, "step": 9000}
{"episode_reward": 5.369488562550205, "episode": 10.0, "batch_reward": 0.06733969104662538, "critic_loss": 0.013158317043911665, "actor_loss": -19.743647595882415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.308401346206665, "step": 10000}
{"episode_reward": 6.186286633445572, "episode": 11.0, "batch_reward": 0.061489693200215696, "critic_loss": 0.016853914859937504, "actor_loss": -20.546508107662202, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.444331645965576, "step": 11000}
{"episode_reward": 4.947830866820006, "episode": 12.0, "batch_reward": 0.056895962677896025, "critic_loss": 0.019435623912955634, "actor_loss": -19.39335426950455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.07351303100586, "step": 12000}
{"episode_reward": 5.750709562619944, "episode": 13.0, "batch_reward": 0.05208387147262693, "critic_loss": 0.009988425067858771, "actor_loss": -18.786686000823973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.207592725753784, "step": 13000}
{"episode_reward": 4.251408520585314, "episode": 14.0, "batch_reward": 0.04821066865697503, "critic_loss": 0.020262414917931893, "actor_loss": -17.850963522911073, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.712973594665527, "step": 14000}
{"episode_reward": 4.816477798987519, "episode": 15.0, "batch_reward": 0.04575294258352369, "critic_loss": 0.016941840120474807, "actor_loss": -19.91885281085968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.68500852584839, "step": 15000}
{"episode_reward": 5.131157494334548, "episode": 16.0, "batch_reward": 0.04251631658710539, "critic_loss": 0.01107041330600623, "actor_loss": -19.626366974830628, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.428524494171143, "step": 16000}
{"episode_reward": 5.150173007579558, "episode": 17.0, "batch_reward": 0.04078156332857907, "critic_loss": 0.015962561881169676, "actor_loss": -18.30913546705246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.26332378387451, "step": 17000}
{"episode_reward": 3.832113991142674, "episode": 18.0, "batch_reward": 0.038723342837765816, "critic_loss": 0.012330421446124092, "actor_loss": -17.668181315422057, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.887210845947266, "step": 18000}
{"episode_reward": 5.223325586058199, "episode": 19.0, "batch_reward": 0.036720162755344066, "critic_loss": 0.018399827528977765, "actor_loss": -18.164818561792373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.593334436416626, "step": 19000}
{"episode_reward": 4.996224462274128, "episode": 20.0, "batch_reward": 0.03475230028526857, "critic_loss": 0.012834635847364552, "actor_loss": -18.422432141780853, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.12554955482483, "step": 20000}
{"episode_reward": 5.011022175804373, "episode": 21.0, "batch_reward": 0.0340935546704568, "critic_loss": 0.02206327710376354, "actor_loss": -18.802263954877855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.25935339927673, "step": 21000}
{"episode_reward": 5.721732948312571, "episode": 22.0, "batch_reward": 0.03231976121291518, "critic_loss": 0.012201207586855162, "actor_loss": -17.728529351234435, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.376194715499878, "step": 22000}
{"episode_reward": 6.6169881395148265, "episode": 23.0, "batch_reward": 0.031711020241957155, "critic_loss": 0.014205932022596244, "actor_loss": -17.22399883699417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.590680360794067, "step": 23000}
{"episode_reward": 4.48525083741871, "episode": 24.0, "batch_reward": 0.030040486054029317, "critic_loss": 0.01562780730018858, "actor_loss": -18.22167925286293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.44547128677368, "step": 24000}
{"episode_reward": 4.893559161690204, "episode": 25.0, "batch_reward": 0.028958467753604056, "critic_loss": 0.017247570706706027, "actor_loss": -16.975941242218017, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.2805917263031, "step": 25000}
{"episode_reward": 4.540937217455451, "episode": 26.0, "batch_reward": 0.02789414232270792, "critic_loss": 0.009045043511519907, "actor_loss": -16.77315151500702, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.07069420814514, "step": 26000}
{"episode_reward": 5.637168957696662, "episode": 27.0, "batch_reward": 0.027501016869209707, "critic_loss": 0.014382321158540436, "actor_loss": -16.65944875383377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.75675868988037, "step": 27000}
{"episode_reward": 2.970350454055601, "episode": 28.0, "batch_reward": 0.026250739221926778, "critic_loss": 0.01161956751710386, "actor_loss": -16.352609884262083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.701125621795654, "step": 28000}
{"episode_reward": 5.182364753176688, "episode": 29.0, "batch_reward": 0.02645053799171001, "critic_loss": 0.009725487318472005, "actor_loss": -17.386483020067214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.525310516357422, "step": 29000}
{"episode_reward": 5.299614002435804, "episode": 30.0, "batch_reward": 0.02465168063621968, "critic_loss": 0.014090800973470322, "actor_loss": -17.073195362329482, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.60393261909485, "step": 30000}
{"episode_reward": 4.503442199291125, "episode": 31.0, "batch_reward": 0.02424562332360074, "critic_loss": 0.008858327412861399, "actor_loss": -17.428003525972365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.54970335960388, "step": 31000}
{"episode_reward": 5.9010217447526525, "episode": 32.0, "batch_reward": 0.02339886996592395, "critic_loss": 0.011739780023461207, "actor_loss": -17.32694105374813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.141507863998413, "step": 32000}
{"episode_reward": 6.737842286319398, "episode": 33.0, "batch_reward": 0.02317174296407029, "critic_loss": 0.011690770460889326, "actor_loss": -17.007500668525697, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.23394751548767, "step": 33000}
{"episode_reward": 3.695330447722897, "episode": 34.0, "batch_reward": 0.02259272783668712, "critic_loss": 0.00932142729338375, "actor_loss": -15.224949890971184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.655364990234375, "step": 34000}
{"episode_reward": 6.525439799181632, "episode": 35.0, "batch_reward": 0.021842740517109632, "critic_loss": 0.011304369711695472, "actor_loss": -17.042651742577554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.403736114501953, "step": 35000}
{"episode_reward": 4.655720658785496, "episode": 36.0, "batch_reward": 0.02139183252956718, "critic_loss": 0.008728196018870222, "actor_loss": -15.908776946783066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.2703914642334, "step": 36000}
{"episode_reward": 5.6511706045869206, "episode": 37.0, "batch_reward": 0.02119651026558131, "critic_loss": 0.012583649299514946, "actor_loss": -15.687672723293305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.40885901451111, "step": 37000}
{"episode_reward": 5.87995493038431, "episode": 38.0, "batch_reward": 0.020883980359416455, "critic_loss": 0.008589973696973174, "actor_loss": -16.556823647260664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.37614607810974, "step": 38000}
{"episode_reward": 5.745572861337241, "episode": 39.0, "batch_reward": 0.020193153155967595, "critic_loss": 0.013714477314482791, "actor_loss": -17.636146399378777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.61110234260559, "step": 39000}
{"episode_reward": 3.444391085034316, "episode": 40.0, "batch_reward": 0.020075222115963697, "critic_loss": 0.007852232545556035, "actor_loss": -17.299300009965897, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.24761176109314, "step": 40000}
{"episode_reward": 5.856707335963026, "episode": 41.0, "batch_reward": 0.01981480835052207, "critic_loss": 0.010619466531352373, "actor_loss": -17.06027559030056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.17692255973816, "step": 41000}
{"episode_reward": 6.862636266908579, "episode": 42.0, "batch_reward": 0.01901057101623155, "critic_loss": 0.008152890540659428, "actor_loss": -16.366900197982787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.08273673057556, "step": 42000}
{"episode_reward": 4.49311116044005, "episode": 43.0, "batch_reward": 0.01897309496696107, "critic_loss": 0.013473124749376439, "actor_loss": -16.600808250308038, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.757885932922363, "step": 43000}
{"episode_reward": 4.807636909825129, "episode": 44.0, "batch_reward": 0.01852359023410827, "critic_loss": 0.007178119955351576, "actor_loss": -16.295261028289794, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.795332431793213, "step": 44000}
{"episode_reward": 5.9384554502728415, "episode": 45.0, "batch_reward": 0.018521879393141715, "critic_loss": 0.009482791583315702, "actor_loss": -17.28071355021, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.984153509140015, "step": 45000}
{"episode_reward": 4.864900433737032, "episode": 46.0, "batch_reward": 0.01784426264790818, "critic_loss": 0.00882957362695015, "actor_loss": -17.182532251834868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.328598022460938, "step": 46000}
{"episode_reward": 4.637668245107362, "episode": 47.0, "batch_reward": 0.01819385895319283, "critic_loss": 0.011411354541414766, "actor_loss": -16.556348689258098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.467142820358276, "step": 47000}
{"episode_reward": 5.197974647222761, "episode": 48.0, "batch_reward": 0.017386679574381562, "critic_loss": 0.006848268632500549, "actor_loss": -15.929375931859017, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.232275009155273, "step": 48000}
{"episode_reward": 5.214835837466961, "episode": 49.0, "batch_reward": 0.01749277961021289, "critic_loss": 0.011251188684953378, "actor_loss": -16.455368572056294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.377763986587524, "step": 49000}
{"episode_reward": 5.360049747784204, "episode": 50.0, "batch_reward": 0.016666358670219778, "critic_loss": 0.011271376568445703, "actor_loss": -16.635048040151595, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.249042510986328, "step": 50000}
{"episode_reward": 5.921232173202941, "episode": 51.0, "batch_reward": 0.01662308763572946, "critic_loss": 0.0063037372708495245, "actor_loss": -15.488767277300358, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.204206466674805, "step": 51000}
{"episode_reward": 4.638061716053911, "episode": 52.0, "batch_reward": 0.01648566813766956, "critic_loss": 0.012724141552011133, "actor_loss": -17.03930454027653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.35415482521057, "step": 52000}
{"episode_reward": 3.9937084112997785, "episode": 53.0, "batch_reward": 0.01650214627897367, "critic_loss": 0.006151852839408093, "actor_loss": -16.50501770097017, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.052817821502686, "step": 53000}
{"episode_reward": 3.660991814163375, "episode": 54.0, "batch_reward": 0.015708991292165592, "critic_loss": 0.00901761407185404, "actor_loss": -16.578324770867823, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.64916729927063, "step": 54000}
{"episode_reward": 6.156707333873602, "episode": 55.0, "batch_reward": 0.016042336842045188, "critic_loss": 0.0063151853677991315, "actor_loss": -15.571910220086574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.825953483581543, "step": 55000}
{"episode_reward": 4.911461444878165, "episode": 56.0, "batch_reward": 0.01566665297350846, "critic_loss": 0.009011498872045194, "actor_loss": -16.854663277208804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97045660018921, "step": 56000}
{"episode_reward": 4.977371527391946, "episode": 57.0, "batch_reward": 0.015226700281258672, "critic_loss": 0.006923751027541584, "actor_loss": -17.026501547932625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.967792510986328, "step": 57000}
{"episode_reward": 4.646885516440241, "episode": 58.0, "batch_reward": 0.015447111841291189, "critic_loss": 0.008363897786010056, "actor_loss": -15.352561381578445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.72133779525757, "step": 58000}
{"episode_reward": 7.662959075189733, "episode": 59.0, "batch_reward": 0.01486700715473853, "critic_loss": 0.019865842163082563, "actor_loss": -15.737410458385945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.146333932876587, "step": 59000}
{"episode_reward": 4.921867213240739, "episode": 60.0, "batch_reward": 0.015113909035921096, "critic_loss": 0.00510663932665193, "actor_loss": -17.871483794033526, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.99657964706421, "step": 60000}
{"episode_reward": 7.425899553884257, "episode": 61.0, "batch_reward": 0.014941921187564731, "critic_loss": 0.005975653814006364, "actor_loss": -15.75013490319252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.19326400756836, "step": 61000}
{"episode_reward": 4.425081702548025, "episode": 62.0, "batch_reward": 0.014902582744136453, "critic_loss": 0.007562970296821732, "actor_loss": -15.414903886556626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.942864418029785, "step": 62000}
{"episode_reward": 4.012193300444659, "episode": 63.0, "batch_reward": 0.014548076268052683, "critic_loss": 0.007565660267224303, "actor_loss": -16.504197532892228, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.202823162078857, "step": 63000}
{"episode_reward": 4.629442405657985, "episode": 64.0, "batch_reward": 0.014008128952700644, "critic_loss": 0.004546541827221517, "actor_loss": -15.960488762527705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.917618989944458, "step": 64000}
{"episode_reward": 4.986779367801398, "episode": 65.0, "batch_reward": 0.014080159141682088, "critic_loss": 0.007831651425163727, "actor_loss": -16.417376374304293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.233927249908447, "step": 65000}
{"episode_reward": 3.8462297099630804, "episode": 66.0, "batch_reward": 0.014193984538316726, "critic_loss": 0.006784981190750841, "actor_loss": -16.558303452938794, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.81645393371582, "step": 66000}
{"episode_reward": 5.254359449664005, "episode": 67.0, "batch_reward": 0.013914851814508439, "critic_loss": 0.005632264183463121, "actor_loss": -17.627493417590856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.299927711486816, "step": 67000}
{"episode_reward": 5.642052283204015, "episode": 68.0, "batch_reward": 0.013680220545036719, "critic_loss": 0.008158583378171897, "actor_loss": -15.303819769442082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.653423309326172, "step": 68000}
{"episode_reward": 3.9161121585084557, "episode": 69.0, "batch_reward": 0.013409016146790236, "critic_loss": 0.004453136323791114, "actor_loss": -16.60867772194743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.814696073532104, "step": 69000}
{"episode_reward": 3.9820503690621134, "episode": 70.0, "batch_reward": 0.013663943815976382, "critic_loss": 0.006624545510872849, "actor_loss": -16.91361945554614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.918517351150513, "step": 70000}
{"episode_reward": 4.721374335469419, "episode": 71.0, "batch_reward": 0.013693161647533997, "critic_loss": 0.005555744263503584, "actor_loss": -15.516812775850296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.877042055130005, "step": 71000}
{"episode_reward": 3.7783715473933217, "episode": 72.0, "batch_reward": 0.013445379299577325, "critic_loss": 0.005649816053686664, "actor_loss": -15.99373695525527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.600175142288208, "step": 72000}
{"episode_reward": 4.123750421817069, "episode": 73.0, "batch_reward": 0.013235652190167457, "critic_loss": 0.007790083050800604, "actor_loss": -16.024253817141055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.488776683807373, "step": 73000}
{"episode_reward": 4.369511673597018, "episode": 74.0, "batch_reward": 0.012887906033312902, "critic_loss": 0.005454844927880913, "actor_loss": -16.765073178619147, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.695953607559204, "step": 74000}
{"episode_reward": 4.779816471407687, "episode": 75.0, "batch_reward": 0.012719917707378044, "critic_loss": 0.005963317882022238, "actor_loss": -16.35504147979617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.27613353729248, "step": 75000}
{"episode_reward": 2.568737038029651, "episode": 76.0, "batch_reward": 0.012809552621794864, "critic_loss": 0.009556779104139422, "actor_loss": -16.181018471240996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.540812730789185, "step": 76000}
{"episode_reward": 5.580768763426544, "episode": 77.0, "batch_reward": 0.012616504952544346, "critic_loss": 0.004842794508876977, "actor_loss": -16.173134037345648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.66484785079956, "step": 77000}
{"episode_reward": 4.2409565964330715, "episode": 78.0, "batch_reward": 0.012899020510027184, "critic_loss": 0.005842040216492024, "actor_loss": -16.984099143087864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.49427366256714, "step": 78000}
{"episode_reward": 5.686793150562591, "episode": 79.0, "batch_reward": 0.012203832044731825, "critic_loss": 0.006255294899878208, "actor_loss": -15.274027711629868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.41927456855774, "step": 79000}
{"episode_reward": 6.4847755700930865, "episode": 80.0, "batch_reward": 0.012249021884519607, "critic_loss": 0.007251957599728485, "actor_loss": -15.500487536400557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.309386491775513, "step": 80000}
{"episode_reward": 5.605703725351232, "episode": 81.0, "batch_reward": 0.011978980168933048, "critic_loss": 0.00783775004860945, "actor_loss": -16.097260572880508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.38302683830261, "step": 81000}
{"episode_reward": 4.287237679042963, "episode": 82.0, "batch_reward": 0.012377777484478429, "critic_loss": 0.006805910769486218, "actor_loss": -17.317943069666622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.482884883880615, "step": 82000}
{"episode_reward": 5.8343883305323665, "episode": 83.0, "batch_reward": 0.011849654126446695, "critic_loss": 0.005776248722686433, "actor_loss": -16.28491496644914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.81605553627014, "step": 83000}
{"episode_reward": 4.938961765348201, "episode": 84.0, "batch_reward": 0.01171966036572121, "critic_loss": 0.00718141739233397, "actor_loss": -16.34767434707284, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.58481240272522, "step": 84000}
{"episode_reward": 6.770672617400463, "episode": 85.0, "batch_reward": 0.012083273907424882, "critic_loss": 0.0064605734304059295, "actor_loss": -16.852262503415346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.92929458618164, "step": 85000}
{"episode_reward": 4.770262644805495, "episode": 86.0, "batch_reward": 0.011765319246565924, "critic_loss": 0.005579221306375984, "actor_loss": -15.897052086547017, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.75487732887268, "step": 86000}
{"episode_reward": 6.024270298593861, "episode": 87.0, "batch_reward": 0.011874699076404795, "critic_loss": 0.004769561715613236, "actor_loss": -16.052117234021424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.858811616897583, "step": 87000}
{"episode_reward": 4.89327981011023, "episode": 88.0, "batch_reward": 0.01185491473437287, "critic_loss": 0.00879594389119302, "actor_loss": -15.054369122460484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.86527705192566, "step": 88000}
{"episode_reward": 6.560432702991071, "episode": 89.0, "batch_reward": 0.01187517187697813, "critic_loss": 0.0044477696694739275, "actor_loss": -15.798141340479255, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.176377058029175, "step": 89000}
{"episode_reward": 5.250514078067331, "episode": 90.0, "batch_reward": 0.011594846153166145, "critic_loss": 0.0047845021392276975, "actor_loss": -16.597967421978712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.81397557258606, "step": 90000}
{"episode_reward": 4.923645344848634, "episode": 91.0, "batch_reward": 0.011860093736089766, "critic_loss": 0.004960330612244434, "actor_loss": -15.843966543152929, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.88110661506653, "step": 91000}
{"episode_reward": 3.646481728314165, "episode": 92.0, "batch_reward": 0.011618986880406737, "critic_loss": 0.007987906019436195, "actor_loss": -15.718344863340258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993038177490234, "step": 92000}
{"episode_reward": 6.482956098714958, "episode": 93.0, "batch_reward": 0.011405203262344003, "critic_loss": 0.003929612026862742, "actor_loss": -15.58054230697453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.34996724128723, "step": 93000}
{"episode_reward": 5.704915635374206, "episode": 94.0, "batch_reward": 0.01127414317894727, "critic_loss": 0.006137621710033272, "actor_loss": -15.14386675222218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.656357526779175, "step": 94000}
{"episode_reward": 4.547460867741683, "episode": 95.0, "batch_reward": 0.011272208573529497, "critic_loss": 0.005272114398889243, "actor_loss": -16.697224584266543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.051268577575684, "step": 95000}
{"episode_reward": 6.892545668592127, "episode": 96.0, "batch_reward": 0.011273110260255634, "critic_loss": 0.006296914732796722, "actor_loss": -15.861942513138056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.748697996139526, "step": 96000}
{"episode_reward": 5.3049638207861785, "episode": 97.0, "batch_reward": 0.01132749210554175, "critic_loss": 0.005427161677391269, "actor_loss": -16.145740331575276, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.231208086013794, "step": 97000}
{"episode_reward": 5.828124227607359, "episode": 98.0, "batch_reward": 0.011133415796328336, "critic_loss": 0.005656598345391103, "actor_loss": -15.78679050001502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.24412965774536, "step": 98000}
{"episode_reward": 4.79401319487927, "episode": 99.0, "batch_reward": 0.010943934094859288, "critic_loss": 0.00383951551062637, "actor_loss": -15.783036346241833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.757816791534424, "step": 99000}
{"episode_reward": 6.561654429341163, "episode": 100.0, "batch_reward": 0.011087278750957922, "critic_loss": 0.004982995870086597, "actor_loss": -15.176949624165893, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.255136728286743, "step": 100000}
{"episode_reward": 6.7011778783379565, "episode": 101.0, "batch_reward": 0.010944918770343065, "critic_loss": 0.00575929795319098, "actor_loss": -16.33767920899391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.90886473655701, "step": 101000}
{"episode_reward": 4.497692663030742, "episode": 102.0, "batch_reward": 0.011051670365966857, "critic_loss": 0.004759004043778986, "actor_loss": -15.850007569640875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.772263526916504, "step": 102000}
{"episode_reward": 4.8494261668895815, "episode": 103.0, "batch_reward": 0.011082154501928017, "critic_loss": 0.004841204347714665, "actor_loss": -15.97785593174398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.677692890167236, "step": 103000}
{"episode_reward": 4.517567796568789, "episode": 104.0, "batch_reward": 0.010716982987243683, "critic_loss": 0.004744890414753172, "actor_loss": -15.707168975785375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.45820903778076, "step": 104000}
{"episode_reward": 3.5267175674353535, "episode": 105.0, "batch_reward": 0.010984279361320659, "critic_loss": 0.004283599181522732, "actor_loss": -15.728914212852716, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.134092092514038, "step": 105000}
{"episode_reward": 4.837104310863522, "episode": 106.0, "batch_reward": 0.010743905734037981, "critic_loss": 0.006192247617749672, "actor_loss": -14.973815864622592, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.572561025619507, "step": 106000}
{"episode_reward": 3.7385579287197714, "episode": 107.0, "batch_reward": 0.010706403318559751, "critic_loss": 0.007750551934776013, "actor_loss": -15.593190925166011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.50047206878662, "step": 107000}
{"episode_reward": 4.936647758603588, "episode": 108.0, "batch_reward": 0.0105508963316679, "critic_loss": 0.0027843836710890173, "actor_loss": -15.761407745957374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.172951459884644, "step": 108000}
{"episode_reward": 4.092135088792758, "episode": 109.0, "batch_reward": 0.010325015583308414, "critic_loss": 0.00483691581524181, "actor_loss": -15.812509458184243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.59303116798401, "step": 109000}
{"episode_reward": 4.918073998413084, "episode": 110.0, "batch_reward": 0.010307176360627637, "critic_loss": 0.004378458538827544, "actor_loss": -16.301898518934845, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.019424438476562, "step": 110000}
{"episode_reward": 5.8554996537844985, "episode": 111.0, "batch_reward": 0.01035033541638404, "critic_loss": 0.00396268366138247, "actor_loss": -16.507542359218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.55184745788574, "step": 111000}
{"episode_reward": 4.672115953729505, "episode": 112.0, "batch_reward": 0.010459082132671028, "critic_loss": 0.004409767147612001, "actor_loss": -15.62421962197125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.742809057235718, "step": 112000}
{"episode_reward": 4.246531858448323, "episode": 113.0, "batch_reward": 0.01013200289523229, "critic_loss": 0.004984978696418694, "actor_loss": -15.25351099897921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.813582181930542, "step": 113000}
{"episode_reward": 3.7141094303929134, "episode": 114.0, "batch_reward": 0.010126518234843389, "critic_loss": 0.003963024947217491, "actor_loss": -16.676055603340266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.436095237731934, "step": 114000}
{"episode_reward": 5.293814726656848, "episode": 115.0, "batch_reward": 0.01021539619518444, "critic_loss": 0.004877787657322188, "actor_loss": -15.799147548422217, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.236103773117065, "step": 115000}
{"episode_reward": 5.675163344882858, "episode": 116.0, "batch_reward": 0.01015884980885312, "critic_loss": 0.003726884616989992, "actor_loss": -16.31245886681974, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.778825521469116, "step": 116000}
{"episode_reward": 6.0167532550084815, "episode": 117.0, "batch_reward": 0.010288349249633028, "critic_loss": 0.006712246372357186, "actor_loss": -15.28123179063201, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.517725944519043, "step": 117000}
{"episode_reward": 6.394875661327676, "episode": 118.0, "batch_reward": 0.010291250153211877, "critic_loss": 0.003413901627936866, "actor_loss": -16.0115359505713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.369239807128906, "step": 118000}
{"episode_reward": 4.4475669766712, "episode": 119.0, "batch_reward": 0.010028231589123606, "critic_loss": 0.00428044267030782, "actor_loss": -15.995875702053308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.13954734802246, "step": 119000}
{"episode_reward": 6.570546995146315, "episode": 120.0, "batch_reward": 0.00984863917180337, "critic_loss": 0.0036389721666928382, "actor_loss": -15.058389069184662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.267733573913574, "step": 120000}
{"episode_reward": 5.331053380999795, "episode": 121.0, "batch_reward": 0.010051119488663971, "critic_loss": 0.007570721347394283, "actor_loss": -15.679474445179105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.03788137435913, "step": 121000}
{"episode_reward": 7.061489735001675, "episode": 122.0, "batch_reward": 0.010038637602236122, "critic_loss": 0.004075647680474503, "actor_loss": -16.345954990550876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.79298424720764, "step": 122000}
{"episode_reward": 5.736073390276281, "episode": 123.0, "batch_reward": 0.00997422398882918, "critic_loss": 0.005409209165227366, "actor_loss": -15.165676661536098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.71607756614685, "step": 123000}
{"episode_reward": 4.896325039515628, "episode": 124.0, "batch_reward": 0.009791018463904039, "critic_loss": 0.00339671926995652, "actor_loss": -16.16499745620787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.41122055053711, "step": 124000}
{"episode_reward": 4.230227587559224, "episode": 125.0, "batch_reward": 0.009740374812390656, "critic_loss": 0.004555096897041949, "actor_loss": -14.864075476571918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.304866075515747, "step": 125000}
{"episode_reward": 4.264169624910242, "episode": 126.0, "batch_reward": 0.009610160036012531, "critic_loss": 0.0057998007319692985, "actor_loss": -16.216234776213764, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.781808614730835, "step": 126000}
{"episode_reward": 4.483660591817105, "episode": 127.0, "batch_reward": 0.009752786361146718, "critic_loss": 0.0036347557330227574, "actor_loss": -16.281622509658337, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.819274425506592, "step": 127000}
{"episode_reward": 4.741399118393519, "episode": 128.0, "batch_reward": 0.009618707854300737, "critic_loss": 0.0039252624360597115, "actor_loss": -16.082788495570423, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.337794065475464, "step": 128000}
{"episode_reward": 5.670528659043189, "episode": 129.0, "batch_reward": 0.009708210229873657, "critic_loss": 0.004584788125379419, "actor_loss": -16.27537548421323, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.680100679397583, "step": 129000}
{"episode_reward": 6.233341965994861, "episode": 130.0, "batch_reward": 0.009531082421541213, "critic_loss": 0.004455294360188418, "actor_loss": -16.384011462360622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.990550756454468, "step": 130000}
{"episode_reward": 4.945277215165624, "episode": 131.0, "batch_reward": 0.009650319806765765, "critic_loss": 0.005209417374680924, "actor_loss": -16.3943095870167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.82919216156006, "step": 131000}
{"episode_reward": 4.914381657058847, "episode": 132.0, "batch_reward": 0.009720710160210729, "critic_loss": 0.00407267738624796, "actor_loss": -15.706900103330613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34985041618347, "step": 132000}
{"episode_reward": 4.791346041017022, "episode": 133.0, "batch_reward": 0.009533345314674079, "critic_loss": 0.004858350362577766, "actor_loss": -16.199750038057566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.958559036254883, "step": 133000}
{"episode_reward": 3.306001645000727, "episode": 134.0, "batch_reward": 0.009624485306208953, "critic_loss": 0.004087482352471852, "actor_loss": -16.69309540271759, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.359956741333008, "step": 134000}
{"episode_reward": 9.178562786023791, "episode": 135.0, "batch_reward": 0.009622344225179404, "critic_loss": 0.003398114326118957, "actor_loss": -15.997087486475706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.177767992019653, "step": 135000}
{"episode_reward": 7.4801593484941185, "episode": 136.0, "batch_reward": 0.009348210210446269, "critic_loss": 0.0034487879785883705, "actor_loss": -16.61485718743503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.441291332244873, "step": 136000}
{"episode_reward": 4.1902770948160395, "episode": 137.0, "batch_reward": 0.009396005862858147, "critic_loss": 0.0036286641894694186, "actor_loss": -15.812550425350667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.98315405845642, "step": 137000}
{"episode_reward": 6.1061601893911925, "episode": 138.0, "batch_reward": 0.009726757559692488, "critic_loss": 0.0030494820675230584, "actor_loss": -15.026724854230881, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.32996106147766, "step": 138000}
{"episode_reward": 5.910540258121608, "episode": 139.0, "batch_reward": 0.009559422805905342, "critic_loss": 0.0035229307936970144, "actor_loss": -15.207338093265891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.266313076019287, "step": 139000}
{"episode_reward": 3.732236443088925, "episode": 140.0, "batch_reward": 0.009243408063892275, "critic_loss": 0.005624203716455668, "actor_loss": -14.763452161587775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.85096311569214, "step": 140000}
{"episode_reward": 6.090591689824264, "episode": 141.0, "batch_reward": 0.009313175314106047, "critic_loss": 0.004004679058358306, "actor_loss": -14.252968245826661, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.05778646469116, "step": 141000}
{"episode_reward": 3.3412682756545062, "episode": 142.0, "batch_reward": 0.009464374803705142, "critic_loss": 0.004941896068186907, "actor_loss": -15.70017843849957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.692561149597168, "step": 142000}
{"episode_reward": 4.328804928966155, "episode": 143.0, "batch_reward": 0.009340659888228402, "critic_loss": 0.0038431675194515263, "actor_loss": -14.880911160752177, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.216334104537964, "step": 143000}
{"episode_reward": 4.961330024000751, "episode": 144.0, "batch_reward": 0.009475541197694838, "critic_loss": 0.004077022291836329, "actor_loss": -15.316006299749017, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.66062068939209, "step": 144000}
{"episode_reward": 4.774322183925296, "episode": 145.0, "batch_reward": 0.009228758851299063, "critic_loss": 0.0042137950892865775, "actor_loss": -14.866000600561499, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.632330417633057, "step": 145000}
{"episode_reward": 3.891665901900156, "episode": 146.0, "batch_reward": 0.009179013994522393, "critic_loss": 0.002485648055044294, "actor_loss": -15.807965938821434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.1160409450531, "step": 146000}
{"episode_reward": 7.005016466822916, "episode": 147.0, "batch_reward": 0.008971853591501712, "critic_loss": 0.003504933063406497, "actor_loss": -15.337528293848038, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.10180902481079, "step": 147000}
{"episode_reward": 6.094836078081035, "episode": 148.0, "batch_reward": 0.009606632055016235, "critic_loss": 0.004955504134042712, "actor_loss": -15.456047706261277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.48266863822937, "step": 148000}
{"episode_reward": 3.9542124472175386, "episode": 149.0, "batch_reward": 0.009151395899243653, "critic_loss": 0.004141847760343808, "actor_loss": -15.492942052409052, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.456337928771973, "step": 149000}
{"episode_reward": 6.382934860693185, "episode": 150.0, "batch_reward": 0.009040676982607692, "critic_loss": 0.004496735391359834, "actor_loss": -15.743117919027805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
