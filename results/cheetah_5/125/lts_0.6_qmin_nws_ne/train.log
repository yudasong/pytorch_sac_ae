{"episode_reward": 0.0, "episode": 1.0, "duration": 19.127739906311035, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.6639046669006348, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2794741676643953, "critic_loss": 0.01794713802339721, "actor_loss": -31.3801022706812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 69.00699877738953, "step": 3000}
{"episode_reward": 4.847632180023548, "episode": 4.0, "batch_reward": 0.1739148040935397, "critic_loss": 0.013313537335488946, "actor_loss": -27.993097281455995, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.03348660469055, "step": 4000}
{"episode_reward": 5.701646982354737, "episode": 5.0, "batch_reward": 0.13453889903053642, "critic_loss": 0.014670067354803905, "actor_loss": -24.21094599246979, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.952468156814575, "step": 5000}
{"episode_reward": 5.6724037582600415, "episode": 6.0, "batch_reward": 0.11084654029086233, "critic_loss": 0.012765528677031398, "actor_loss": -23.953542345046998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.667147159576416, "step": 6000}
{"episode_reward": 5.512999689154359, "episode": 7.0, "batch_reward": 0.09481526553630829, "critic_loss": 0.015852369707543404, "actor_loss": -25.292205741882324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.4903302192688, "step": 7000}
{"episode_reward": 5.661071850245986, "episode": 8.0, "batch_reward": 0.08369201472401619, "critic_loss": 0.015525885249488055, "actor_loss": -23.893766007900236, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.20367693901062, "step": 8000}
{"episode_reward": 4.66192729494427, "episode": 9.0, "batch_reward": 0.07363612478040159, "critic_loss": 0.017920766815193927, "actor_loss": -22.795451632976533, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.34695029258728, "step": 9000}
{"episode_reward": 5.369490340522071, "episode": 10.0, "batch_reward": 0.0673396900780499, "critic_loss": 0.012760930356569588, "actor_loss": -23.07225430774689, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.506098747253418, "step": 10000}
{"episode_reward": 6.186286424370071, "episode": 11.0, "batch_reward": 0.06148969223350286, "critic_loss": 0.018719955678796394, "actor_loss": -23.266805762290954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.52419900894165, "step": 11000}
{"episode_reward": 4.947830514106546, "episode": 12.0, "batch_reward": 0.05689596218988299, "critic_loss": 0.018380301155033522, "actor_loss": -21.6291288189888, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.048863410949707, "step": 12000}
{"episode_reward": 5.750712627330137, "episode": 13.0, "batch_reward": 0.0520838710963726, "critic_loss": 0.00991999379551271, "actor_loss": -21.784959929466247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.874016523361206, "step": 13000}
{"episode_reward": 4.251409050271015, "episode": 14.0, "batch_reward": 0.04821066828258336, "critic_loss": 0.020507080235984177, "actor_loss": -20.069778829574584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.961010694503784, "step": 14000}
{"episode_reward": 4.816480397288887, "episode": 15.0, "batch_reward": 0.045752942495979367, "critic_loss": 0.012218147562874947, "actor_loss": -22.572229592323303, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.49207639694214, "step": 15000}
{"episode_reward": 5.1311573138332855, "episode": 16.0, "batch_reward": 0.04251631615217775, "critic_loss": 0.011819110437005292, "actor_loss": -22.1003187046051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.25209951400757, "step": 16000}
{"episode_reward": 5.15017317294325, "episode": 17.0, "batch_reward": 0.040781563025899234, "critic_loss": 0.014345027669100091, "actor_loss": -20.778396716117857, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.070708990097046, "step": 17000}
{"episode_reward": 3.8321134338758998, "episode": 18.0, "batch_reward": 0.038723342606797814, "critic_loss": 0.013603447878849692, "actor_loss": -20.681756813764572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.935404300689697, "step": 18000}
{"episode_reward": 5.223325448738789, "episode": 19.0, "batch_reward": 0.036720162550918756, "critic_loss": 0.016568631778936832, "actor_loss": -19.99296631240845, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.043140411376953, "step": 19000}
{"episode_reward": 4.996224665357319, "episode": 20.0, "batch_reward": 0.03475230007432401, "critic_loss": 0.012544055560952984, "actor_loss": -21.63974008345604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.74423336982727, "step": 20000}
{"episode_reward": 5.0110222909779765, "episode": 21.0, "batch_reward": 0.03409355447348207, "critic_loss": 0.017089050347945885, "actor_loss": -21.597394073486328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.582621812820435, "step": 21000}
{"episode_reward": 5.721733030065985, "episode": 22.0, "batch_reward": 0.032319760992191734, "critic_loss": 0.011136921819939744, "actor_loss": -20.536399600982666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.495688915252686, "step": 22000}
{"episode_reward": 6.6169880481964825, "episode": 23.0, "batch_reward": 0.031711020010057836, "critic_loss": 0.014348619625932769, "actor_loss": -20.102894011735916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.36764430999756, "step": 23000}
{"episode_reward": 4.485250840440974, "episode": 24.0, "batch_reward": 0.030040485840756446, "critic_loss": 0.013943810432450845, "actor_loss": -20.99808340525627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.132517099380493, "step": 24000}
{"episode_reward": 4.8935591171759505, "episode": 25.0, "batch_reward": 0.028958467633463443, "critic_loss": 0.01535673133606906, "actor_loss": -20.11172510290146, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.142647743225098, "step": 25000}
{"episode_reward": 4.540937180064704, "episode": 26.0, "batch_reward": 0.027894142243778335, "critic_loss": 0.008330143697356107, "actor_loss": -19.851026544570924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.55415678024292, "step": 26000}
{"episode_reward": 5.637168941606329, "episode": 27.0, "batch_reward": 0.027501016767229883, "critic_loss": 0.014586992416006979, "actor_loss": -20.592139572620393, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.82603430747986, "step": 27000}
{"episode_reward": 2.9703504549534454, "episode": 28.0, "batch_reward": 0.026250738994218408, "critic_loss": 0.011123999942443334, "actor_loss": -19.63053737139702, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.190788745880127, "step": 28000}
{"episode_reward": 5.182364757311485, "episode": 29.0, "batch_reward": 0.0264505379460752, "critic_loss": 0.008999577805079753, "actor_loss": -20.432853353261947, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.74124264717102, "step": 29000}
{"episode_reward": 5.299614016730903, "episode": 30.0, "batch_reward": 0.024651680536800995, "critic_loss": 0.013727032441733173, "actor_loss": -19.76356835484505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.847626209259033, "step": 30000}
{"episode_reward": 4.50344220211818, "episode": 31.0, "batch_reward": 0.02424562316434458, "critic_loss": 0.008033126594295026, "actor_loss": -20.11981906199455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.44386076927185, "step": 31000}
{"episode_reward": 5.90102178993087, "episode": 32.0, "batch_reward": 0.023398869858123363, "critic_loss": 0.01256725683849072, "actor_loss": -20.451556956410407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.3643958568573, "step": 32000}
{"episode_reward": 6.73784230190777, "episode": 33.0, "batch_reward": 0.02317174286721274, "critic_loss": 0.010639606977143558, "actor_loss": -20.625327627182006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.26921844482422, "step": 33000}
{"episode_reward": 3.6953304550460224, "episode": 34.0, "batch_reward": 0.022592727730982004, "critic_loss": 0.00949582419267972, "actor_loss": -18.834595625281334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.852202653884888, "step": 34000}
{"episode_reward": 6.525439798134426, "episode": 35.0, "batch_reward": 0.02184274047240615, "critic_loss": 0.012141476251883433, "actor_loss": -20.484716618180276, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.240729570388794, "step": 35000}
{"episode_reward": 4.6557206564311135, "episode": 36.0, "batch_reward": 0.02139183248998597, "critic_loss": 0.008651890797278612, "actor_loss": -18.68620484864712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.946374654769897, "step": 36000}
{"episode_reward": 5.6511706045869206, "episode": 37.0, "batch_reward": 0.021196510087698697, "critic_loss": 0.012327851834212197, "actor_loss": -19.253900000810624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3128821849823, "step": 37000}
{"episode_reward": 5.879954931011822, "episode": 38.0, "batch_reward": 0.020883980250917374, "critic_loss": 0.008713669908611337, "actor_loss": -19.458403559803962, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.220587968826294, "step": 38000}
{"episode_reward": 5.745572862255422, "episode": 39.0, "batch_reward": 0.0201931530716829, "critic_loss": 0.009681868086685426, "actor_loss": -20.425500980973244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5671226978302, "step": 39000}
{"episode_reward": 3.4443910872653474, "episode": 40.0, "batch_reward": 0.020075221963692456, "critic_loss": 0.008837054683404857, "actor_loss": -20.149045459747313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.537574291229248, "step": 40000}
{"episode_reward": 5.856707335045282, "episode": 41.0, "batch_reward": 0.019814808322582395, "critic_loss": 0.012829794776873314, "actor_loss": -20.154274555683138, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.866530418395996, "step": 41000}
{"episode_reward": 6.86263626704607, "episode": 42.0, "batch_reward": 0.019010570883750917, "critic_loss": 0.009736094871943352, "actor_loss": -19.520244891643525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.746290683746338, "step": 42000}
{"episode_reward": 4.49311116118884, "episode": 43.0, "batch_reward": 0.018973094878485426, "critic_loss": 0.009214217103406554, "actor_loss": -19.64095427596569, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.911046981811523, "step": 43000}
{"episode_reward": 4.807636909825129, "episode": 44.0, "batch_reward": 0.018523590179625897, "critic_loss": 0.007014494815142825, "actor_loss": -18.780979397177695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.835042238235474, "step": 44000}
{"episode_reward": 5.938455451914562, "episode": 45.0, "batch_reward": 0.018521879355888813, "critic_loss": 0.010517778511799407, "actor_loss": -20.26173334789276, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.153294801712036, "step": 45000}
{"episode_reward": 4.864900433737032, "episode": 46.0, "batch_reward": 0.017844262611120938, "critic_loss": 0.008741002126596868, "actor_loss": -19.37652972149849, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.526752710342407, "step": 46000}
{"episode_reward": 4.637668245107362, "episode": 47.0, "batch_reward": 0.018193858926650135, "critic_loss": 0.009776453056605532, "actor_loss": -19.30464325642586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.04478406906128, "step": 47000}
{"episode_reward": 5.197974647222761, "episode": 48.0, "batch_reward": 0.01738667950918898, "critic_loss": 0.007493083266788744, "actor_loss": -18.614640211701392, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.791389226913452, "step": 48000}
{"episode_reward": 5.214835837466961, "episode": 49.0, "batch_reward": 0.017492779574124144, "critic_loss": 0.010067545022408012, "actor_loss": -19.819950383007527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.269025564193726, "step": 49000}
{"episode_reward": 5.360049747784204, "episode": 50.0, "batch_reward": 0.016666358617832885, "critic_loss": 0.009122184292733437, "actor_loss": -19.325148386359214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.432018280029297, "step": 50000}
{"episode_reward": 5.9212321742762395, "episode": 51.0, "batch_reward": 0.016623087477870287, "critic_loss": 0.007412955419204082, "actor_loss": -18.728477278530598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.627949953079224, "step": 51000}
{"episode_reward": 4.638061716053911, "episode": 52.0, "batch_reward": 0.01648566801706329, "critic_loss": 0.009358270672761137, "actor_loss": -20.219866584777833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.869850397109985, "step": 52000}
{"episode_reward": 3.9937084112997785, "episode": 53.0, "batch_reward": 0.016502146196784452, "critic_loss": 0.008160762947125477, "actor_loss": -19.37960315936804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.257229328155518, "step": 53000}
{"episode_reward": 3.660991814163375, "episode": 54.0, "batch_reward": 0.015708991239545868, "critic_loss": 0.008844882474382757, "actor_loss": -19.8880222594738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.016451358795166, "step": 54000}
{"episode_reward": 6.156707333873602, "episode": 55.0, "batch_reward": 0.016042336765676738, "critic_loss": 0.0075027404837455835, "actor_loss": -19.19477881860733, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23753571510315, "step": 55000}
{"episode_reward": 4.911461444878165, "episode": 56.0, "batch_reward": 0.015666652894346045, "critic_loss": 0.007768015607376583, "actor_loss": -20.35695550906658, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.403419971466064, "step": 56000}
{"episode_reward": 4.977371527391946, "episode": 57.0, "batch_reward": 0.01522670020814985, "critic_loss": 0.011177671076336992, "actor_loss": -19.544585268378256, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.88692879676819, "step": 57000}
{"episode_reward": 4.646885516440241, "episode": 58.0, "batch_reward": 0.015447111727669835, "critic_loss": 0.007306761337371427, "actor_loss": -18.855275719344615, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06501865386963, "step": 58000}
{"episode_reward": 7.662959075189733, "episode": 59.0, "batch_reward": 0.01486700709350407, "critic_loss": 0.018869640598248225, "actor_loss": -18.807900260031225, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.076138496398926, "step": 59000}
{"episode_reward": 4.921867213240739, "episode": 60.0, "batch_reward": 0.015113908984698355, "critic_loss": 0.00441050645330688, "actor_loss": -19.899380689382554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.734375476837158, "step": 60000}
{"episode_reward": 7.425899553884257, "episode": 61.0, "batch_reward": 0.014941921050660311, "critic_loss": 0.006460035817261087, "actor_loss": -19.443852755606173, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.27746391296387, "step": 61000}
{"episode_reward": 4.425081702548025, "episode": 62.0, "batch_reward": 0.014902582664741202, "critic_loss": 0.006926325781038031, "actor_loss": -19.048825087606907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.15825128555298, "step": 62000}
{"episode_reward": 4.012193300665039, "episode": 63.0, "batch_reward": 0.014548076179577037, "critic_loss": 0.006338767505862051, "actor_loss": -18.842240232408045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.966671228408813, "step": 63000}
{"episode_reward": 4.629442405657985, "episode": 64.0, "batch_reward": 0.014008128868648783, "critic_loss": 0.007501136899911216, "actor_loss": -19.164440819054843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.020220041275024, "step": 64000}
{"episode_reward": 4.986779367801398, "episode": 65.0, "batch_reward": 0.014080159104662015, "critic_loss": 0.006423630519377184, "actor_loss": -18.947055631548167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.715893268585205, "step": 65000}
{"episode_reward": 3.8462297099630804, "episode": 66.0, "batch_reward": 0.014193984499201178, "critic_loss": 0.007422526902460959, "actor_loss": -19.518926646977665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.152767181396484, "step": 66000}
{"episode_reward": 5.254359449664005, "episode": 67.0, "batch_reward": 0.013914851751411333, "critic_loss": 0.004604149777296698, "actor_loss": -20.46705082374811, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.84711980819702, "step": 67000}
{"episode_reward": 5.642052283204015, "episode": 68.0, "batch_reward": 0.013680220517329872, "critic_loss": 0.00803927771349845, "actor_loss": -18.70298195692897, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.84442377090454, "step": 68000}
{"episode_reward": 3.9161121585084557, "episode": 69.0, "batch_reward": 0.013409016099991277, "critic_loss": 0.005033970115007833, "actor_loss": -19.390053205251693, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.327347993850708, "step": 69000}
{"episode_reward": 3.9820503690621134, "episode": 70.0, "batch_reward": 0.013663943789899349, "critic_loss": 0.005827482427193899, "actor_loss": -19.820430517077448, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.26812744140625, "step": 70000}
{"episode_reward": 4.721374335469419, "episode": 71.0, "batch_reward": 0.013693161632167175, "critic_loss": 0.006569434470380656, "actor_loss": -18.731376600474118, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.74882936477661, "step": 71000}
{"episode_reward": 3.7783715473933217, "episode": 72.0, "batch_reward": 0.013445379268145189, "critic_loss": 0.0045687941871437945, "actor_loss": -18.968344958007336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.981448888778687, "step": 72000}
{"episode_reward": 4.123750421817069, "episode": 73.0, "batch_reward": 0.013235652196221054, "critic_loss": 0.008318794911065196, "actor_loss": -18.748837382763625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.12269401550293, "step": 73000}
{"episode_reward": 4.369511673597018, "episode": 74.0, "batch_reward": 0.012887905979761853, "critic_loss": 0.004458463207789464, "actor_loss": -19.740371483296155, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.317450523376465, "step": 74000}
{"episode_reward": 4.779816471407687, "episode": 75.0, "batch_reward": 0.012719917708775029, "critic_loss": 0.005218057524747565, "actor_loss": -19.824688789218666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.444505214691162, "step": 75000}
{"episode_reward": 2.568737038029651, "episode": 76.0, "batch_reward": 0.012809552528895438, "critic_loss": 0.0061294043725210945, "actor_loss": -19.46037464863062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.102959632873535, "step": 76000}
{"episode_reward": 5.580768763426544, "episode": 77.0, "batch_reward": 0.0126165048670955, "critic_loss": 0.004960990391584346, "actor_loss": -19.267034675449132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.064038276672363, "step": 77000}
{"episode_reward": 4.2409565964330715, "episode": 78.0, "batch_reward": 0.012899020443903283, "critic_loss": 0.005473210133357497, "actor_loss": -19.706092549741268, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.30087661743164, "step": 78000}
{"episode_reward": 5.686793150562591, "episode": 79.0, "batch_reward": 0.012203831970924511, "critic_loss": 0.005054752654163167, "actor_loss": -17.50423390969634, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.8822603225708, "step": 79000}
{"episode_reward": 6.4847755700930865, "episode": 80.0, "batch_reward": 0.012249021884053945, "critic_loss": 0.0067430444443307355, "actor_loss": -18.726104897260665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.22523283958435, "step": 80000}
{"episode_reward": 5.605703725351232, "episode": 81.0, "batch_reward": 0.011978980114916339, "critic_loss": 0.005144109497712634, "actor_loss": -18.76913532307744, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.286476135253906, "step": 81000}
{"episode_reward": 4.287237679042963, "episode": 82.0, "batch_reward": 0.012377777454908936, "critic_loss": 0.0045005335427413225, "actor_loss": -20.42481258752942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.924387216567993, "step": 82000}
{"episode_reward": 5.8343883305323665, "episode": 83.0, "batch_reward": 0.011849654148099943, "critic_loss": 0.007372088812509901, "actor_loss": -18.5873956399858, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.660209894180298, "step": 83000}
{"episode_reward": 4.938961765348201, "episode": 84.0, "batch_reward": 0.011719660279341041, "critic_loss": 0.008051643959857756, "actor_loss": -19.943223750263453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.07397150993347, "step": 84000}
{"episode_reward": 6.770672617400463, "episode": 85.0, "batch_reward": 0.012083273869007826, "critic_loss": 0.004229803025067667, "actor_loss": -19.701637337833642, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.47956919670105, "step": 85000}
{"episode_reward": 4.770262644805495, "episode": 86.0, "batch_reward": 0.011765319193713366, "critic_loss": 0.004044259071102715, "actor_loss": -18.37133620405197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.892027378082275, "step": 86000}
{"episode_reward": 6.024270298593861, "episode": 87.0, "batch_reward": 0.011874699047533795, "critic_loss": 0.005858761591487564, "actor_loss": -19.388883314341307, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.964855432510376, "step": 87000}
{"episode_reward": 4.89327981011023, "episode": 88.0, "batch_reward": 0.011854914683150128, "critic_loss": 0.0055291905508638595, "actor_loss": -18.761649190187455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.37871026992798, "step": 88000}
{"episode_reward": 6.560432702991071, "episode": 89.0, "batch_reward": 0.011875171827618033, "critic_loss": 0.004158005314064212, "actor_loss": -19.068819296225904, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.780148029327393, "step": 89000}
{"episode_reward": 5.250514078067331, "episode": 90.0, "batch_reward": 0.011594846092630178, "critic_loss": 0.005570379793032771, "actor_loss": -19.68159203711152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.29201889038086, "step": 90000}
{"episode_reward": 4.923645344848634, "episode": 91.0, "batch_reward": 0.011860093680676073, "critic_loss": 0.00426041199221072, "actor_loss": -18.55928414365649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.98810839653015, "step": 91000}
{"episode_reward": 3.646481728314165, "episode": 92.0, "batch_reward": 0.011618986800778656, "critic_loss": 0.005416749340089154, "actor_loss": -18.995704824969174, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.656221866607666, "step": 92000}
{"episode_reward": 6.482956098714958, "episode": 93.0, "batch_reward": 0.01140520320669748, "critic_loss": 0.0035448840328026563, "actor_loss": -18.917325061246753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.818652868270874, "step": 93000}
{"episode_reward": 5.704915635374206, "episode": 94.0, "batch_reward": 0.011274143161950632, "critic_loss": 0.006075398249246064, "actor_loss": -18.974426587849855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.915656089782715, "step": 94000}
{"episode_reward": 4.547460867741683, "episode": 95.0, "batch_reward": 0.011272208545124158, "critic_loss": 0.0036986053531290965, "actor_loss": -19.851182837337255, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.62539839744568, "step": 95000}
{"episode_reward": 6.892545668592127, "episode": 96.0, "batch_reward": 0.011273110244423151, "critic_loss": 0.004668350549633033, "actor_loss": -19.451136232435704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.093425750732422, "step": 96000}
{"episode_reward": 5.3049638207861785, "episode": 97.0, "batch_reward": 0.011327492084819823, "critic_loss": 0.004612416717718588, "actor_loss": -19.922695148944854, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.01889657974243, "step": 97000}
{"episode_reward": 5.828124227607359, "episode": 98.0, "batch_reward": 0.011133415787713602, "critic_loss": 0.004986021031232667, "actor_loss": -18.945984782785178, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.110413312911987, "step": 98000}
{"episode_reward": 4.79401319487927, "episode": 99.0, "batch_reward": 0.010943934072740375, "critic_loss": 0.0035635442070197313, "actor_loss": -19.193681964039804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.11758017539978, "step": 99000}
{"episode_reward": 6.561654429341163, "episode": 100.0, "batch_reward": 0.011087278694147244, "critic_loss": 0.003502476194407791, "actor_loss": -18.652342415839435, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.20015811920166, "step": 100000}
{"episode_reward": 6.7011778783379565, "episode": 101.0, "batch_reward": 0.010944918724242598, "critic_loss": 0.008690766876374255, "actor_loss": -19.375986170455814, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.20094966888428, "step": 101000}
{"episode_reward": 4.497692663030742, "episode": 102.0, "batch_reward": 0.011051670318935067, "critic_loss": 0.0044202368415208184, "actor_loss": -19.01341756348312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.487640619277954, "step": 102000}
{"episode_reward": 4.8494261668895815, "episode": 103.0, "batch_reward": 0.01108215447026305, "critic_loss": 0.00489285435203783, "actor_loss": -18.76816669009626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.27284812927246, "step": 103000}
{"episode_reward": 4.517567796568789, "episode": 104.0, "batch_reward": 0.010716982971411198, "critic_loss": 0.003977385686310299, "actor_loss": -18.994152390897273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.23755407333374, "step": 104000}
{"episode_reward": 3.5267175674353535, "episode": 105.0, "batch_reward": 0.010984279323369265, "critic_loss": 0.004701575411985686, "actor_loss": -18.828410697847605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.227477312088013, "step": 105000}
{"episode_reward": 4.837104310863522, "episode": 106.0, "batch_reward": 0.010743905700743198, "critic_loss": 0.00519371872953343, "actor_loss": -18.449472599387168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.427010774612427, "step": 106000}
{"episode_reward": 3.7385579287197714, "episode": 107.0, "batch_reward": 0.01070640327874571, "critic_loss": 0.006805139079573564, "actor_loss": -18.26344366838038, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.645137310028076, "step": 107000}
{"episode_reward": 4.936647758603588, "episode": 108.0, "batch_reward": 0.01055089632445015, "critic_loss": 0.0024412745483787146, "actor_loss": -18.557468729302286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.509674787521362, "step": 108000}
{"episode_reward": 4.092135088792758, "episode": 109.0, "batch_reward": 0.010325015546521172, "critic_loss": 0.0034040284238362802, "actor_loss": -19.47212546853721, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.01532292366028, "step": 109000}
{"episode_reward": 4.918073998413084, "episode": 110.0, "batch_reward": 0.010307176309172064, "critic_loss": 0.005392363895218295, "actor_loss": -18.845870960995555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.854975938796997, "step": 110000}
{"episode_reward": 5.8554996537844985, "episode": 111.0, "batch_reward": 0.010350335421040654, "critic_loss": 0.003867567789115128, "actor_loss": -19.422984593629838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.232102394104004, "step": 111000}
{"episode_reward": 4.672115953729505, "episode": 112.0, "batch_reward": 0.01045908209029585, "critic_loss": 0.0048790427385974906, "actor_loss": -18.662230144545436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.042080402374268, "step": 112000}
{"episode_reward": 4.246531858448323, "episode": 113.0, "batch_reward": 0.010132002838421613, "critic_loss": 0.004272727558221959, "actor_loss": -18.230060432270168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.904000282287598, "step": 113000}
{"episode_reward": 3.7141094303929134, "episode": 114.0, "batch_reward": 0.010126518196659162, "critic_loss": 0.004012550181112602, "actor_loss": -20.084920022815467, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.917101860046387, "step": 114000}
{"episode_reward": 5.293814726656848, "episode": 115.0, "batch_reward": 0.010215396146988496, "critic_loss": 0.004773491572821513, "actor_loss": -19.14599855194986, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.718976974487305, "step": 115000}
{"episode_reward": 5.675163344882858, "episode": 116.0, "batch_reward": 0.01015884981653653, "critic_loss": 0.003487496420646494, "actor_loss": -19.842455458387732, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.59276556968689, "step": 116000}
{"episode_reward": 6.0167532550084815, "episode": 117.0, "batch_reward": 0.01028834921051748, "critic_loss": 0.006089990582710016, "actor_loss": -18.12947338089347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109623193740845, "step": 117000}
{"episode_reward": 6.394875661327676, "episode": 118.0, "batch_reward": 0.010291250139707699, "critic_loss": 0.0038705542843963485, "actor_loss": -19.42394421826303, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.650521516799927, "step": 118000}
{"episode_reward": 4.4475669766712, "episode": 119.0, "batch_reward": 0.0100282315579243, "critic_loss": 0.004972845151780348, "actor_loss": -19.59366792269051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.208745002746582, "step": 119000}
{"episode_reward": 6.570546995146315, "episode": 120.0, "batch_reward": 0.009848639131523668, "critic_loss": 0.0029565261693132927, "actor_loss": -18.778123488917945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.637521266937256, "step": 120000}
{"episode_reward": 5.331053380999795, "episode": 121.0, "batch_reward": 0.010051119439071044, "critic_loss": 0.005684037412735051, "actor_loss": -18.839840839758516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.07160186767578, "step": 121000}
{"episode_reward": 7.061489735001675, "episode": 122.0, "batch_reward": 0.010038637585472316, "critic_loss": 0.003745024890777131, "actor_loss": -18.947551465958355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.55322027206421, "step": 122000}
{"episode_reward": 5.736073390276281, "episode": 123.0, "batch_reward": 0.009974223980912938, "critic_loss": 0.006499828418978722, "actor_loss": -17.328693469956516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.251975059509277, "step": 123000}
{"episode_reward": 4.896325039515628, "episode": 124.0, "batch_reward": 0.0097910184210632, "critic_loss": 0.004577494289180322, "actor_loss": -18.767604106783867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.87717604637146, "step": 124000}
{"episode_reward": 4.230227587559224, "episode": 125.0, "batch_reward": 0.00974037477420643, "critic_loss": 0.0038067963822832097, "actor_loss": -18.39296588717401, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.554571390151978, "step": 125000}
{"episode_reward": 4.264169624910242, "episode": 126.0, "batch_reward": 0.00961016000318341, "critic_loss": 0.004612642156331276, "actor_loss": -19.126179726079105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.907289028167725, "step": 126000}
{"episode_reward": 4.483660591817105, "episode": 127.0, "batch_reward": 0.009752786344150081, "critic_loss": 0.0033046536188485335, "actor_loss": -18.694529322952032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.89149808883667, "step": 127000}
{"episode_reward": 4.741399118393519, "episode": 128.0, "batch_reward": 0.009618707857793196, "critic_loss": 0.004022159807958814, "actor_loss": -18.74447456100583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.77666974067688, "step": 128000}
{"episode_reward": 5.670528659043189, "episode": 129.0, "batch_reward": 0.0097082102089189, "critic_loss": 0.005025713254726724, "actor_loss": -19.3703195001781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.756393671035767, "step": 129000}
{"episode_reward": 6.233341965994861, "episode": 130.0, "batch_reward": 0.009531082390574739, "critic_loss": 0.0038697114985770894, "actor_loss": -19.35777773152292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.08018922805786, "step": 130000}
{"episode_reward": 4.945277215165624, "episode": 131.0, "batch_reward": 0.009650319763226434, "critic_loss": 0.004380982027410937, "actor_loss": -19.617925120472908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.156269550323486, "step": 131000}
{"episode_reward": 4.914381657058847, "episode": 132.0, "batch_reward": 0.009720710104098543, "critic_loss": 0.0036928481120048675, "actor_loss": -19.42543776462972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.766658306121826, "step": 132000}
{"episode_reward": 4.791346041017022, "episode": 133.0, "batch_reward": 0.009533345310715959, "critic_loss": 0.004400947463429475, "actor_loss": -18.800143446564675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.847106218338013, "step": 133000}
{"episode_reward": 3.306001645000727, "episode": 134.0, "batch_reward": 0.00962448524683714, "critic_loss": 0.005493969813949662, "actor_loss": -19.4164194547534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.967446327209473, "step": 134000}
{"episode_reward": 9.178562786023791, "episode": 135.0, "batch_reward": 0.009622344190720469, "critic_loss": 0.0033619910524212175, "actor_loss": -19.467217034295203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.002283573150635, "step": 135000}
{"episode_reward": 7.4801593484941185, "episode": 136.0, "batch_reward": 0.009348210199503227, "critic_loss": 0.0028295554264477687, "actor_loss": -19.960288936421275, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.229429960250854, "step": 136000}
{"episode_reward": 4.1902770948160395, "episode": 137.0, "batch_reward": 0.009396005858667195, "critic_loss": 0.003789756424324878, "actor_loss": -19.157345340192318, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.864748001098633, "step": 137000}
{"episode_reward": 6.1061601893911925, "episode": 138.0, "batch_reward": 0.009726757556432859, "critic_loss": 0.0035419268490586545, "actor_loss": -17.999822364136577, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.69197654724121, "step": 138000}
{"episode_reward": 5.910540258121608, "episode": 139.0, "batch_reward": 0.009559422790305689, "critic_loss": 0.003106332462251885, "actor_loss": -18.243263650283218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.194958209991455, "step": 139000}
{"episode_reward": 3.732236443088925, "episode": 140.0, "batch_reward": 0.009243408043868839, "critic_loss": 0.0049444069770979695, "actor_loss": -18.048807852730157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.923139333724976, "step": 140000}
{"episode_reward": 6.090591689824264, "episode": 141.0, "batch_reward": 0.009313175284536556, "critic_loss": 0.0034655324208870296, "actor_loss": -17.597621592909096, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.107481718063354, "step": 141000}
{"episode_reward": 3.3412682756545062, "episode": 142.0, "batch_reward": 0.009464374736882747, "critic_loss": 0.004997541985416319, "actor_loss": -18.544277057722212, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.878581047058105, "step": 142000}
{"episode_reward": 4.328804928966155, "episode": 143.0, "batch_reward": 0.00934065987286158, "critic_loss": 0.0021321720212727087, "actor_loss": -18.221906209886075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.12792706489563, "step": 143000}
{"episode_reward": 4.961330024000751, "episode": 144.0, "batch_reward": 0.00947554120235145, "critic_loss": 0.004243548648148135, "actor_loss": -18.968925766438247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.545153617858887, "step": 144000}
{"episode_reward": 4.774322183925296, "episode": 145.0, "batch_reward": 0.00922875882871449, "critic_loss": 0.0038627956249911223, "actor_loss": -18.020138375833632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.25461483001709, "step": 145000}
{"episode_reward": 3.891665901900156, "episode": 146.0, "batch_reward": 0.009179014014312998, "critic_loss": 0.0026344297059768, "actor_loss": -18.34382556913793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.322911262512207, "step": 146000}
{"episode_reward": 7.005016466822916, "episode": 147.0, "batch_reward": 0.008971853584749624, "critic_loss": 0.0029518612917963766, "actor_loss": -18.989726446196435, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.683509349822998, "step": 147000}
{"episode_reward": 6.094836078081035, "episode": 148.0, "batch_reward": 0.00960663203918375, "critic_loss": 0.004393397699313937, "actor_loss": -18.11768842445314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.80931568145752, "step": 148000}
{"episode_reward": 3.9542124472175386, "episode": 149.0, "batch_reward": 0.00915139584057033, "critic_loss": 0.0034348034084468963, "actor_loss": -18.091941348180175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.39018750190735, "step": 149000}
{"episode_reward": 6.382934860693185, "episode": 150.0, "batch_reward": 0.009040676972130313, "critic_loss": 0.004494801803397422, "actor_loss": -18.651804833725095, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
