{"episode_reward": 0.0, "episode": 1.0, "duration": 17.354608297348022, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.5080499649047852, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.28230467183802993, "critic_loss": 0.02535582514974764, "actor_loss": -21.00817963507484, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 61.19408845901489, "step": 3000}
{"episode_reward": 70.48521940181008, "episode": 4.0, "batch_reward": 0.20585783836245536, "critic_loss": 0.03331304597761482, "actor_loss": -19.381417219638823, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.0666184425354, "step": 4000}
{"episode_reward": 64.98361892304943, "episode": 5.0, "batch_reward": 0.16823812801390886, "critic_loss": 0.03456019369605929, "actor_loss": -14.22533504486084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07048463821411, "step": 5000}
{"episode_reward": 42.48511313554822, "episode": 6.0, "batch_reward": 0.14159624411165714, "critic_loss": 0.04068195679225028, "actor_loss": -15.803684340238572, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.080872297286987, "step": 6000}
{"episode_reward": 46.74943821783811, "episode": 7.0, "batch_reward": 0.1303591576218605, "critic_loss": 0.050483016047626735, "actor_loss": -16.405218246936798, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.070953369140625, "step": 7000}
{"episode_reward": 114.53007299971468, "episode": 8.0, "batch_reward": 0.12524351271241904, "critic_loss": 0.04974821941927075, "actor_loss": -15.92584531211853, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.105088710784912, "step": 8000}
{"episode_reward": 9.85782410653827, "episode": 9.0, "batch_reward": 0.11487403327971697, "critic_loss": 0.0634201835244894, "actor_loss": -17.631957953453064, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.057018756866455, "step": 9000}
{"episode_reward": 80.06273490046702, "episode": 10.0, "batch_reward": 0.11752624465525151, "critic_loss": 0.0953783666677773, "actor_loss": -17.35746888637543, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.089173793792725, "step": 10000}
{"episode_reward": 212.78497081053382, "episode": 11.0, "batch_reward": 0.1274112730100751, "critic_loss": 0.13256185057014228, "actor_loss": -18.090660606384276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.72685122489929, "step": 11000}
{"episode_reward": 129.9062721852986, "episode": 12.0, "batch_reward": 0.12227479529380798, "critic_loss": 0.11136159426346422, "actor_loss": -17.494729004859924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.05219078063965, "step": 12000}
{"episode_reward": 50.90541110647365, "episode": 13.0, "batch_reward": 0.11950938215106725, "critic_loss": 0.11867031934857368, "actor_loss": -17.128246517181395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.052349090576172, "step": 13000}
{"episode_reward": 110.50979358946839, "episode": 14.0, "batch_reward": 0.12240557567030191, "critic_loss": 0.15163265113532542, "actor_loss": -16.017024875640868, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.364518880844116, "step": 14000}
{"episode_reward": 327.7129242200163, "episode": 15.0, "batch_reward": 0.1354928615167737, "critic_loss": 0.1905116328448057, "actor_loss": -18.4594902677536, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.053564310073853, "step": 15000}
{"episode_reward": 154.63402848041937, "episode": 16.0, "batch_reward": 0.13763333294540644, "critic_loss": 0.1889144143462181, "actor_loss": -18.870520293235778, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.03866481781006, "step": 16000}
{"episode_reward": 273.6915051152905, "episode": 17.0, "batch_reward": 0.14481885413825513, "critic_loss": 0.19311998627334834, "actor_loss": -18.650057485580444, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.053245544433594, "step": 17000}
{"episode_reward": 227.51831762025904, "episode": 18.0, "batch_reward": 0.14984578546881674, "critic_loss": 0.20955411399155854, "actor_loss": -19.48376034736633, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.090958833694458, "step": 18000}
{"episode_reward": 268.00110063160315, "episode": 19.0, "batch_reward": 0.1562284309491515, "critic_loss": 0.2436850536763668, "actor_loss": -21.054274463653563, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.070587396621704, "step": 19000}
{"episode_reward": 223.81315537511097, "episode": 20.0, "batch_reward": 0.16009605918079614, "critic_loss": 0.27396973566710947, "actor_loss": -21.69767727470398, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.037418127059937, "step": 20000}
{"episode_reward": 192.60829847848115, "episode": 21.0, "batch_reward": 0.1598098252043128, "critic_loss": 0.29282850401103494, "actor_loss": -22.044728145599365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.480031967163086, "step": 21000}
{"episode_reward": 136.21749815262248, "episode": 22.0, "batch_reward": 0.1615292353630066, "critic_loss": 0.27479003520309925, "actor_loss": -21.74172338104248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.08186626434326, "step": 22000}
{"episode_reward": 186.7100915793176, "episode": 23.0, "batch_reward": 0.16287788641452788, "critic_loss": 0.2752577542364597, "actor_loss": -21.040446472167968, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.089573860168457, "step": 23000}
{"episode_reward": 286.37697635411155, "episode": 24.0, "batch_reward": 0.16630098713934421, "critic_loss": 0.33837621650099753, "actor_loss": -22.415570516586303, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.069236993789673, "step": 24000}
{"episode_reward": 218.21315639433547, "episode": 25.0, "batch_reward": 0.16946904430538415, "critic_loss": 0.31953758202493193, "actor_loss": -22.044688558578493, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.089996099472046, "step": 25000}
{"episode_reward": 291.95450707738905, "episode": 26.0, "batch_reward": 0.16998019896447658, "critic_loss": 0.3125592742562294, "actor_loss": -22.55370842552185, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.083252668380737, "step": 26000}
{"episode_reward": 50.45648900468264, "episode": 27.0, "batch_reward": 0.17083309617638587, "critic_loss": 0.32103403614461423, "actor_loss": -22.56384390640259, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07782244682312, "step": 27000}
{"episode_reward": 267.3522626830022, "episode": 28.0, "batch_reward": 0.17416921563446522, "critic_loss": 0.33421726770699023, "actor_loss": -22.83872926712036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07465648651123, "step": 28000}
{"episode_reward": 274.1129895985256, "episode": 29.0, "batch_reward": 0.1776158216446638, "critic_loss": 0.3585084473490715, "actor_loss": -23.78608204460144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.062209367752075, "step": 29000}
{"episode_reward": 277.83072012981154, "episode": 30.0, "batch_reward": 0.17938938288390635, "critic_loss": 0.38705082336068153, "actor_loss": -23.744750762939454, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07031750679016, "step": 30000}
{"episode_reward": 115.09223895269388, "episode": 31.0, "batch_reward": 0.18026626533269882, "critic_loss": 0.3979595303982496, "actor_loss": -23.934366691589357, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.459238052368164, "step": 31000}
{"episode_reward": 431.1689623794303, "episode": 32.0, "batch_reward": 0.18628164914250372, "critic_loss": 0.4031926102787256, "actor_loss": -25.14569108200073, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.04840111732483, "step": 32000}
{"episode_reward": 290.2148290851425, "episode": 33.0, "batch_reward": 0.18923188020288945, "critic_loss": 0.42176793287694453, "actor_loss": -25.258269914627075, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.066754817962646, "step": 33000}
{"episode_reward": 205.86279300537927, "episode": 34.0, "batch_reward": 0.1865545332580805, "critic_loss": 0.388410815268755, "actor_loss": -23.838420421600343, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.108983039855957, "step": 34000}
{"episode_reward": 32.79731471503065, "episode": 35.0, "batch_reward": 0.18416185320913792, "critic_loss": 0.42051998847723004, "actor_loss": -24.370391746520998, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.069880485534668, "step": 35000}
{"episode_reward": 112.15753339945348, "episode": 36.0, "batch_reward": 0.183417321190238, "critic_loss": 0.4004963759183884, "actor_loss": -23.97869161224365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.084826469421387, "step": 36000}
{"episode_reward": 272.7554872653979, "episode": 37.0, "batch_reward": 0.1861177744269371, "critic_loss": 0.4116665613502264, "actor_loss": -23.995169788360595, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.11550259590149, "step": 37000}
{"episode_reward": 273.3470373152943, "episode": 38.0, "batch_reward": 0.1908114203363657, "critic_loss": 0.40708181926608084, "actor_loss": -24.417746940612794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.03595995903015, "step": 38000}
{"episode_reward": 377.68230370492853, "episode": 39.0, "batch_reward": 0.19260451053082944, "critic_loss": 0.4230815889686346, "actor_loss": -25.42766512298584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.04113245010376, "step": 39000}
{"episode_reward": 279.2531081584788, "episode": 40.0, "batch_reward": 0.19597727543115614, "critic_loss": 0.43160265518724916, "actor_loss": -25.172383968353273, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07354474067688, "step": 40000}
{"episode_reward": 305.64100202483155, "episode": 41.0, "batch_reward": 0.19849747829139233, "critic_loss": 0.4519438266903162, "actor_loss": -25.496431064605712, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.449418783187866, "step": 41000}
{"episode_reward": 318.6705488053987, "episode": 42.0, "batch_reward": 0.20181057167053224, "critic_loss": 0.47738223360478876, "actor_loss": -25.67524139404297, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.06497287750244, "step": 42000}
{"episode_reward": 340.74782959761063, "episode": 43.0, "batch_reward": 0.20312488669157028, "critic_loss": 0.5235713189691306, "actor_loss": -25.842154251098634, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.079427003860474, "step": 43000}
{"episode_reward": 133.76811186739496, "episode": 44.0, "batch_reward": 0.20200270007550716, "critic_loss": 0.5080173171907664, "actor_loss": -25.449425605773925, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.084835052490234, "step": 44000}
{"episode_reward": 218.18690262402484, "episode": 45.0, "batch_reward": 0.20386358101665975, "critic_loss": 0.5021704478412866, "actor_loss": -26.156853794097902, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.05760884284973, "step": 45000}
{"episode_reward": 301.7350924308364, "episode": 46.0, "batch_reward": 0.20507035095989704, "critic_loss": 0.49804714813828466, "actor_loss": -26.165499446868896, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.078922986984253, "step": 46000}
{"episode_reward": 303.87468316628076, "episode": 47.0, "batch_reward": 0.20935846355557441, "critic_loss": 0.5335642635077238, "actor_loss": -26.264450042724608, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.085698127746582, "step": 47000}
{"episode_reward": 463.9409693041637, "episode": 48.0, "batch_reward": 0.21420087283849717, "critic_loss": 0.5158536809384823, "actor_loss": -26.575329662322996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07406711578369, "step": 48000}
{"episode_reward": 470.2531307207805, "episode": 49.0, "batch_reward": 0.21860184206068517, "critic_loss": 0.5076955877244472, "actor_loss": -27.298603771209716, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.070249795913696, "step": 49000}
{"episode_reward": 301.70040177496776, "episode": 50.0, "batch_reward": 0.21993787178397178, "critic_loss": 0.5221277367323637, "actor_loss": -27.309917667388916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.03770089149475, "step": 50000}
{"episode_reward": 347.3456909866349, "episode": 51.0, "batch_reward": 0.22360963436961173, "critic_loss": 0.4911616677343845, "actor_loss": -27.409688987731933, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.52206468582153, "step": 51000}
{"episode_reward": 414.62683039649824, "episode": 52.0, "batch_reward": 0.22657758828997612, "critic_loss": 0.5193722061514855, "actor_loss": -28.184963035583497, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.104866981506348, "step": 52000}
{"episode_reward": 252.15046573659393, "episode": 53.0, "batch_reward": 0.22818957680463792, "critic_loss": 0.5517213453948497, "actor_loss": -28.26508430480957, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.06518864631653, "step": 53000}
{"episode_reward": 383.7361231204162, "episode": 54.0, "batch_reward": 0.22978210479021072, "critic_loss": 0.5297195149362087, "actor_loss": -28.39034410095215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.09740710258484, "step": 54000}
{"episode_reward": 300.0327222067143, "episode": 55.0, "batch_reward": 0.22840201412141323, "critic_loss": 0.5513631407618522, "actor_loss": -27.59643918991089, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.084048748016357, "step": 55000}
{"episode_reward": 91.95329951777981, "episode": 56.0, "batch_reward": 0.2289482254832983, "critic_loss": 0.5232507035285234, "actor_loss": -28.238166221618652, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.056461811065674, "step": 56000}
{"episode_reward": 313.40897981272724, "episode": 57.0, "batch_reward": 0.23126172433793546, "critic_loss": 0.5581266493797302, "actor_loss": -28.31521304321289, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.082091808319092, "step": 57000}
{"episode_reward": 442.40498725850074, "episode": 58.0, "batch_reward": 0.2341316147148609, "critic_loss": 0.5641614088118077, "actor_loss": -28.025098529815672, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.095550060272217, "step": 58000}
{"episode_reward": 299.9403142810228, "episode": 59.0, "batch_reward": 0.23584216725826262, "critic_loss": 0.538407115072012, "actor_loss": -28.513760009765626, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.050445079803467, "step": 59000}
{"episode_reward": 454.68989643859123, "episode": 60.0, "batch_reward": 0.23970385901629926, "critic_loss": 0.513229863896966, "actor_loss": -29.0892539100647, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.06314444541931, "step": 60000}
{"episode_reward": 396.37648544571175, "episode": 61.0, "batch_reward": 0.24242236933112143, "critic_loss": 0.5183223405182361, "actor_loss": -28.940179225921632, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.521381855010986, "step": 61000}
{"episode_reward": 438.2101468787651, "episode": 62.0, "batch_reward": 0.24536798997223377, "critic_loss": 0.4860826202183962, "actor_loss": -29.135665313720704, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.077147722244263, "step": 62000}
{"episode_reward": 440.40414192215314, "episode": 63.0, "batch_reward": 0.2479077043533325, "critic_loss": 0.48289222140610216, "actor_loss": -29.461996479034426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.088497161865234, "step": 63000}
{"episode_reward": 418.15133150882247, "episode": 64.0, "batch_reward": 0.24956018671393396, "critic_loss": 0.4524037923365831, "actor_loss": -29.516909420013427, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.05248188972473, "step": 64000}
{"episode_reward": 376.2418213503926, "episode": 65.0, "batch_reward": 0.2526752543002367, "critic_loss": 0.4481627628058195, "actor_loss": -29.91948104095459, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.04659128189087, "step": 65000}
{"episode_reward": 314.33739689124167, "episode": 66.0, "batch_reward": 0.25288173304498196, "critic_loss": 0.47768722864985463, "actor_loss": -29.82012607192993, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07245445251465, "step": 66000}
{"episode_reward": 176.9770196669663, "episode": 67.0, "batch_reward": 0.2524775262922049, "critic_loss": 0.4477347037792206, "actor_loss": -30.02241994857788, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.039536952972412, "step": 67000}
{"episode_reward": 398.505374647698, "episode": 68.0, "batch_reward": 0.25375942680239677, "critic_loss": 0.47270606619119643, "actor_loss": -29.35490518951416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.08641767501831, "step": 68000}
{"episode_reward": 327.8656956977521, "episode": 69.0, "batch_reward": 0.25442754220962527, "critic_loss": 0.5074222021996975, "actor_loss": -29.68370540237427, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.089158535003662, "step": 69000}
{"episode_reward": 131.376910473635, "episode": 70.0, "batch_reward": 0.2533332868516445, "critic_loss": 0.5253101729452611, "actor_loss": -29.66833920288086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.066412210464478, "step": 70000}
{"episode_reward": 392.0291178915243, "episode": 71.0, "batch_reward": 0.2563044930845499, "critic_loss": 0.484538679882884, "actor_loss": -29.368143478393556, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.548020124435425, "step": 71000}
{"episode_reward": 474.9566364783184, "episode": 72.0, "batch_reward": 0.25926706241071223, "critic_loss": 0.47758127069473266, "actor_loss": -29.715661796569826, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.095974922180176, "step": 72000}
{"episode_reward": 481.8505807399447, "episode": 73.0, "batch_reward": 0.26226214596629144, "critic_loss": 0.5013451879620552, "actor_loss": -30.058544620513917, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.08893632888794, "step": 73000}
{"episode_reward": 452.5970731369814, "episode": 74.0, "batch_reward": 0.2639853810220957, "critic_loss": 0.4340589331686497, "actor_loss": -30.342755729675293, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.092552423477173, "step": 74000}
{"episode_reward": 448.346479380406, "episode": 75.0, "batch_reward": 0.2677129829823971, "critic_loss": 0.4615415447205305, "actor_loss": -30.54037801361084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.0884370803833, "step": 75000}
{"episode_reward": 510.25170216993274, "episode": 76.0, "batch_reward": 0.27067481982707975, "critic_loss": 0.4605331789404154, "actor_loss": -30.58858617401123, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.070894241333008, "step": 76000}
{"episode_reward": 286.9140723589336, "episode": 77.0, "batch_reward": 0.27209565667808056, "critic_loss": 0.44737567561864855, "actor_loss": -30.724409809112547, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.092720985412598, "step": 77000}
{"episode_reward": 483.7731911184918, "episode": 78.0, "batch_reward": 0.27425299060344693, "critic_loss": 0.43188389533758165, "actor_loss": -31.10254042816162, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.076470613479614, "step": 78000}
{"episode_reward": 445.51256526384657, "episode": 79.0, "batch_reward": 0.2747204262316227, "critic_loss": 0.4435154986232519, "actor_loss": -30.77370272064209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.090720653533936, "step": 79000}
{"episode_reward": 189.13044283279214, "episode": 80.0, "batch_reward": 0.27267480437457564, "critic_loss": 0.4272160112708807, "actor_loss": -30.546124698638916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.09702467918396, "step": 80000}
{"episode_reward": 108.83495697717, "episode": 81.0, "batch_reward": 0.2714246851056814, "critic_loss": 0.4330334944874048, "actor_loss": -30.753363021850586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.47417664527893, "step": 81000}
{"episode_reward": 110.37115872161759, "episode": 82.0, "batch_reward": 0.27044181908667086, "critic_loss": 0.4043082972466946, "actor_loss": -30.64993808364868, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.063233852386475, "step": 82000}
{"episode_reward": 513.4869649496253, "episode": 83.0, "batch_reward": 0.2735844138264656, "critic_loss": 0.4031752999871969, "actor_loss": -30.863904392242432, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.087000846862793, "step": 83000}
{"episode_reward": 443.8357051940396, "episode": 84.0, "batch_reward": 0.276731728091836, "critic_loss": 0.41983158837258816, "actor_loss": -31.31686595535278, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.094445943832397, "step": 84000}
{"episode_reward": 487.8377705036777, "episode": 85.0, "batch_reward": 0.27844219429790973, "critic_loss": 0.412798531845212, "actor_loss": -31.398980697631835, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.04393696784973, "step": 85000}
{"episode_reward": 476.0974064579219, "episode": 86.0, "batch_reward": 0.28104998214542865, "critic_loss": 0.41209137108922006, "actor_loss": -31.306994060516356, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.086790561676025, "step": 86000}
{"episode_reward": 494.6847051573786, "episode": 87.0, "batch_reward": 0.2814828560948372, "critic_loss": 0.4164807038158178, "actor_loss": -31.069944187164307, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.10385775566101, "step": 87000}
{"episode_reward": 375.68354704203966, "episode": 88.0, "batch_reward": 0.28312048262357714, "critic_loss": 0.41366867603361607, "actor_loss": -31.050170429229738, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07401752471924, "step": 88000}
{"episode_reward": 169.17956367609696, "episode": 89.0, "batch_reward": 0.2820235545039177, "critic_loss": 0.4336569223701954, "actor_loss": -31.134865760803223, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.087233304977417, "step": 89000}
{"episode_reward": 550.6548332883993, "episode": 90.0, "batch_reward": 0.2857055581063032, "critic_loss": 0.41781777988374236, "actor_loss": -31.56238939666748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.08435320854187, "step": 90000}
{"episode_reward": 555.1976411815068, "episode": 91.0, "batch_reward": 0.28886714869737623, "critic_loss": 0.4231499769687653, "actor_loss": -31.404462108612062, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.49658226966858, "step": 91000}
{"episode_reward": 531.7904208445765, "episode": 92.0, "batch_reward": 0.29125148317217825, "critic_loss": 0.4195212341398001, "actor_loss": -32.09707246398926, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.077720403671265, "step": 92000}
{"episode_reward": 447.7539401081204, "episode": 93.0, "batch_reward": 0.29279862892627717, "critic_loss": 0.43617702317237855, "actor_loss": -31.96876300430298, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.075803518295288, "step": 93000}
{"episode_reward": 459.5631971750103, "episode": 94.0, "batch_reward": 0.2949014623016119, "critic_loss": 0.41528236834704874, "actor_loss": -32.350000797271726, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.073904514312744, "step": 94000}
{"episode_reward": 548.32951111162, "episode": 95.0, "batch_reward": 0.2978772821128368, "critic_loss": 0.4513708930760622, "actor_loss": -32.88288402938843, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.062169551849365, "step": 95000}
{"episode_reward": 552.2551797977529, "episode": 96.0, "batch_reward": 0.2998497003763914, "critic_loss": 0.42516006268560885, "actor_loss": -32.73104274749756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.073312282562256, "step": 96000}
{"episode_reward": 504.7470966119426, "episode": 97.0, "batch_reward": 0.30203055377304555, "critic_loss": 0.4310506333261728, "actor_loss": -33.15554021072388, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.08580470085144, "step": 97000}
{"episode_reward": 439.9530540481087, "episode": 98.0, "batch_reward": 0.30408649422228334, "critic_loss": 0.4419700126349926, "actor_loss": -33.27378095626831, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.08839440345764, "step": 98000}
{"episode_reward": 541.0222980930458, "episode": 99.0, "batch_reward": 0.30603888086974623, "critic_loss": 0.42780652236938477, "actor_loss": -33.360881843566894, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.084249258041382, "step": 99000}
{"episode_reward": 541.2609498412368, "episode": 100.0, "batch_reward": 0.30886991751194, "critic_loss": 0.4437381754219532, "actor_loss": -33.44474566268921, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.09475541114807, "step": 100000}
{"episode_reward": 520.5797461912379, "episode": 101.0, "batch_reward": 0.3110962144434452, "critic_loss": 0.40530406442284583, "actor_loss": -34.07229329299927, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.49113631248474, "step": 101000}
{"episode_reward": 558.7726266172448, "episode": 102.0, "batch_reward": 0.3129498350322247, "critic_loss": 0.40211925515532493, "actor_loss": -34.219888301849366, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.100674629211426, "step": 102000}
{"episode_reward": 576.3992245918565, "episode": 103.0, "batch_reward": 0.3150267975628376, "critic_loss": 0.41133869126439093, "actor_loss": -34.338159236907956, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.080689191818237, "step": 103000}
{"episode_reward": 559.8881735772173, "episode": 104.0, "batch_reward": 0.318821398049593, "critic_loss": 0.3902078353762627, "actor_loss": -34.64930345916748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.06274962425232, "step": 104000}
{"episode_reward": 562.6295926206496, "episode": 105.0, "batch_reward": 0.3200613358914852, "critic_loss": 0.3918063437640667, "actor_loss": -34.33138199234009, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.11193323135376, "step": 105000}
{"episode_reward": 178.94867318520622, "episode": 106.0, "batch_reward": 0.31894900411367416, "critic_loss": 0.3908777811229229, "actor_loss": -34.16969016647339, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.070558309555054, "step": 106000}
{"episode_reward": 523.4393520562754, "episode": 107.0, "batch_reward": 0.32053218853473664, "critic_loss": 0.39390228013694284, "actor_loss": -34.78223003387451, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.069672107696533, "step": 107000}
{"episode_reward": 319.93161040050956, "episode": 108.0, "batch_reward": 0.321172255218029, "critic_loss": 0.3843952523469925, "actor_loss": -35.00825272750855, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.08393383026123, "step": 108000}
{"episode_reward": 582.2177649943139, "episode": 109.0, "batch_reward": 0.3231285017430782, "critic_loss": 0.40625036583840846, "actor_loss": -34.90188264846802, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.054100513458252, "step": 109000}
{"episode_reward": 338.9665603678686, "episode": 110.0, "batch_reward": 0.32306993600726125, "critic_loss": 0.38236112432181835, "actor_loss": -35.180130531311036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.04971957206726, "step": 110000}
{"episode_reward": 563.6972928716002, "episode": 111.0, "batch_reward": 0.3266699535548687, "critic_loss": 0.4193941645473242, "actor_loss": -35.30658401489258, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.5061240196228, "step": 111000}
{"episode_reward": 572.2460443652122, "episode": 112.0, "batch_reward": 0.32864766716957095, "critic_loss": 0.39679142759740355, "actor_loss": -35.36564901351929, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07766842842102, "step": 112000}
{"episode_reward": 613.7326668698289, "episode": 113.0, "batch_reward": 0.3306550034880638, "critic_loss": 0.3928332695811987, "actor_loss": -35.7613194770813, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.058412790298462, "step": 113000}
{"episode_reward": 597.5200203648654, "episode": 114.0, "batch_reward": 0.3332364189326763, "critic_loss": 0.3804495195746422, "actor_loss": -36.19930631637573, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.09919285774231, "step": 114000}
{"episode_reward": 570.0911214664511, "episode": 115.0, "batch_reward": 0.33499107298254965, "critic_loss": 0.41097276252508164, "actor_loss": -36.09028358459473, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.108193159103394, "step": 115000}
{"episode_reward": 553.5803543074114, "episode": 116.0, "batch_reward": 0.33716570466756823, "critic_loss": 0.3909074956923723, "actor_loss": -36.55767616653442, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.058109045028687, "step": 116000}
{"episode_reward": 533.0305822339495, "episode": 117.0, "batch_reward": 0.3392358326613903, "critic_loss": 0.3871270996928215, "actor_loss": -36.47853422546387, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.073194980621338, "step": 117000}
{"episode_reward": 600.3845410451912, "episode": 118.0, "batch_reward": 0.3411912747621536, "critic_loss": 0.3879059506058693, "actor_loss": -36.883801555633546, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.093459129333496, "step": 118000}
{"episode_reward": 563.1486317764565, "episode": 119.0, "batch_reward": 0.34223580548167226, "critic_loss": 0.3878657575696707, "actor_loss": -36.74791107559204, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.078312873840332, "step": 119000}
{"episode_reward": 574.601078698803, "episode": 120.0, "batch_reward": 0.3440830152332783, "critic_loss": 0.3756949196755886, "actor_loss": -36.583241966247556, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.090749979019165, "step": 120000}
{"episode_reward": 560.1828628836897, "episode": 121.0, "batch_reward": 0.34761137363314626, "critic_loss": 0.37216515056788924, "actor_loss": -37.073470397949215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.4791579246521, "step": 121000}
{"episode_reward": 634.4286499663659, "episode": 122.0, "batch_reward": 0.34907607367634774, "critic_loss": 0.3889410091638565, "actor_loss": -37.4319250869751, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.085191011428833, "step": 122000}
{"episode_reward": 632.2677319871912, "episode": 123.0, "batch_reward": 0.3518771765232086, "critic_loss": 0.3899664743244648, "actor_loss": -37.365989372253416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.09583592414856, "step": 123000}
{"episode_reward": 597.6123394492653, "episode": 124.0, "batch_reward": 0.3527716823220253, "critic_loss": 0.3751899975091219, "actor_loss": -37.800500621795656, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.06157612800598, "step": 124000}
{"episode_reward": 605.746823114713, "episode": 125.0, "batch_reward": 0.3562133381962776, "critic_loss": 0.37418701517581937, "actor_loss": -37.981733139038084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.11616349220276, "step": 125000}
{"episode_reward": 642.535602691261, "episode": 126.0, "batch_reward": 0.3575445362627506, "critic_loss": 0.39956164215505124, "actor_loss": -38.42713332366943, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.081866025924683, "step": 126000}
{"episode_reward": 618.4971052072294, "episode": 127.0, "batch_reward": 0.3598161922097206, "critic_loss": 0.37689894655346873, "actor_loss": -38.53515189361572, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.062363147735596, "step": 127000}
{"episode_reward": 625.3758762079827, "episode": 128.0, "batch_reward": 0.36149552336335183, "critic_loss": 0.39579246608912944, "actor_loss": -38.816509117126465, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.096122980117798, "step": 128000}
{"episode_reward": 614.7795004094077, "episode": 129.0, "batch_reward": 0.36320560616254804, "critic_loss": 0.3829497750401497, "actor_loss": -39.157134185791016, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.097020864486694, "step": 129000}
{"episode_reward": 578.3970801338679, "episode": 130.0, "batch_reward": 0.36607578510046007, "critic_loss": 0.4002088571190834, "actor_loss": -38.986687644958494, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.067909955978394, "step": 130000}
{"episode_reward": 602.311372105774, "episode": 131.0, "batch_reward": 0.3684646081328392, "critic_loss": 0.3535660567730665, "actor_loss": -39.323794231414794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.49033999443054, "step": 131000}
{"episode_reward": 646.2103490180052, "episode": 132.0, "batch_reward": 0.37025117790699, "critic_loss": 0.37432440723478794, "actor_loss": -39.443401847839354, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.06442904472351, "step": 132000}
{"episode_reward": 609.4801479536563, "episode": 133.0, "batch_reward": 0.37050943437218664, "critic_loss": 0.40568798771500586, "actor_loss": -39.92880237579346, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.054441690444946, "step": 133000}
{"episode_reward": 604.4673396785106, "episode": 134.0, "batch_reward": 0.3721307058930397, "critic_loss": 0.36700560070574284, "actor_loss": -40.16373658752441, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.081249475479126, "step": 134000}
{"episode_reward": 608.3333538762125, "episode": 135.0, "batch_reward": 0.37451096427440644, "critic_loss": 0.3705028831958771, "actor_loss": -39.91909965133667, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.06544589996338, "step": 135000}
{"episode_reward": 607.2281100447908, "episode": 136.0, "batch_reward": 0.3770438757240772, "critic_loss": 0.3654848171025515, "actor_loss": -40.297461128234865, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.08371138572693, "step": 136000}
{"episode_reward": 631.1753796455273, "episode": 137.0, "batch_reward": 0.37719833049178125, "critic_loss": 0.3763286069780588, "actor_loss": -40.221788932800294, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.074196100234985, "step": 137000}
{"episode_reward": 586.1520944582826, "episode": 138.0, "batch_reward": 0.3795740070641041, "critic_loss": 0.3894011162221432, "actor_loss": -40.38402610015869, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.044148445129395, "step": 138000}
{"episode_reward": 645.224414358843, "episode": 139.0, "batch_reward": 0.3795569342970848, "critic_loss": 0.37741078816354273, "actor_loss": -40.49465301513672, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.076701879501343, "step": 139000}
{"episode_reward": 96.1218600182942, "episode": 140.0, "batch_reward": 0.37892482352256773, "critic_loss": 0.3778031229972839, "actor_loss": -40.3731291809082, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07013726234436, "step": 140000}
{"episode_reward": 641.6603340604178, "episode": 141.0, "batch_reward": 0.38118474844098094, "critic_loss": 0.36731617264449595, "actor_loss": -40.443391868591306, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.48013615608215, "step": 141000}
{"episode_reward": 652.7745732007577, "episode": 142.0, "batch_reward": 0.38336474844813345, "critic_loss": 0.38814303378760817, "actor_loss": -40.67596863174438, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.099785327911377, "step": 142000}
{"episode_reward": 614.9492971584602, "episode": 143.0, "batch_reward": 0.3850792056918144, "critic_loss": 0.38596892638504504, "actor_loss": -40.99306416320801, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.08341908454895, "step": 143000}
{"episode_reward": 564.0541162561433, "episode": 144.0, "batch_reward": 0.38672633543610574, "critic_loss": 0.35840235409140586, "actor_loss": -41.2256588973999, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.093388319015503, "step": 144000}
{"episode_reward": 630.6105759042987, "episode": 145.0, "batch_reward": 0.38930034431815147, "critic_loss": 0.3576691953986883, "actor_loss": -41.43825456237793, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.071257829666138, "step": 145000}
{"episode_reward": 622.129751498768, "episode": 146.0, "batch_reward": 0.3888077866733074, "critic_loss": 0.36413679429888723, "actor_loss": -41.77746036529541, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.069622039794922, "step": 146000}
{"episode_reward": 647.6737190228488, "episode": 147.0, "batch_reward": 0.39078508973121645, "critic_loss": 0.3901704005599022, "actor_loss": -41.702812225341795, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.093987226486206, "step": 147000}
{"episode_reward": 634.1623600603006, "episode": 148.0, "batch_reward": 0.3930435882806778, "critic_loss": 0.3879975210875273, "actor_loss": -41.94896949005127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.095775604248047, "step": 148000}
{"episode_reward": 658.2628837023702, "episode": 149.0, "batch_reward": 0.3953132754564285, "critic_loss": 0.38246042653918266, "actor_loss": -42.139396141052245, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.068729400634766, "step": 149000}
{"episode_reward": 612.3365467713343, "episode": 150.0, "batch_reward": 0.3976100702881813, "critic_loss": 0.37468537119030954, "actor_loss": -42.40987878417969, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
