{"episode_reward": 0.0, "episode": 1.0, "duration": 15.585799932479858, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.3321881294250488, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.28475882540288944, "critic_loss": 0.03146381043959763, "actor_loss": -39.449854273893905, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 70.73072361946106, "step": 3000}
{"episode_reward": 168.38266597878638, "episode": 4.0, "batch_reward": 0.24409959550201893, "critic_loss": 0.054538654582574966, "actor_loss": -33.25197411966324, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.032946825027466, "step": 4000}
{"episode_reward": 168.20116684297602, "episode": 5.0, "batch_reward": 0.21961166480183603, "critic_loss": 0.06349463845044374, "actor_loss": -31.882633095145227, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.030587911605835, "step": 5000}
{"episode_reward": 93.5452118557253, "episode": 6.0, "batch_reward": 0.1936770037561655, "critic_loss": 0.0694999896325171, "actor_loss": -28.309366207003592, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.249502420425415, "step": 6000}
{"episode_reward": 83.56461284197594, "episode": 7.0, "batch_reward": 0.17631831355392932, "critic_loss": 0.0882682698778808, "actor_loss": -26.302476746439932, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.324767351150513, "step": 7000}
{"episode_reward": 76.43727969133664, "episode": 8.0, "batch_reward": 0.16399761215597392, "critic_loss": 0.11304757392778993, "actor_loss": -26.241843109369277, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.353171586990356, "step": 8000}
{"episode_reward": 120.10177877188157, "episode": 9.0, "batch_reward": 0.1544583396986127, "critic_loss": 0.11357167526707053, "actor_loss": -23.648718980669976, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.810669422149658, "step": 9000}
{"episode_reward": 13.342706963091176, "episode": 10.0, "batch_reward": 0.14757895377278327, "critic_loss": 0.1168147757872939, "actor_loss": -24.006051654934883, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.695191383361816, "step": 10000}
{"episode_reward": 189.92696730324772, "episode": 11.0, "batch_reward": 0.1474073624536395, "critic_loss": 0.12197260294854641, "actor_loss": -23.01051617240906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.7154700756073, "step": 11000}
{"episode_reward": 57.151047862313916, "episode": 12.0, "batch_reward": 0.13806490896642207, "critic_loss": 0.11440211282297968, "actor_loss": -21.780244085550308, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.100550889968872, "step": 12000}
{"episode_reward": 22.308518868083468, "episode": 13.0, "batch_reward": 0.13291050009429456, "critic_loss": 0.13711003629118204, "actor_loss": -20.9379424559474, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.828544855117798, "step": 13000}
{"episode_reward": 148.96360178295726, "episode": 14.0, "batch_reward": 0.13502748764306308, "critic_loss": 0.15678219301998617, "actor_loss": -22.357041771173478, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.914003133773804, "step": 14000}
{"episode_reward": 227.4456432910341, "episode": 15.0, "batch_reward": 0.14231898585706948, "critic_loss": 0.18624879616498946, "actor_loss": -21.134493402719496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.15633487701416, "step": 15000}
{"episode_reward": 129.1019733406618, "episode": 16.0, "batch_reward": 0.13762017071992158, "critic_loss": 0.151986444786191, "actor_loss": -20.495814304113388, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.805969715118408, "step": 16000}
{"episode_reward": 56.07243813087639, "episode": 17.0, "batch_reward": 0.1360651450827718, "critic_loss": 0.17700856307148932, "actor_loss": -20.648875730514526, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.821707487106323, "step": 17000}
{"episode_reward": 179.6147505004865, "episode": 18.0, "batch_reward": 0.1391679292693734, "critic_loss": 0.17389192394912242, "actor_loss": -20.47281946015358, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.175534963607788, "step": 18000}
{"episode_reward": 187.8972962767433, "episode": 19.0, "batch_reward": 0.13861956655979157, "critic_loss": 0.17855773162841798, "actor_loss": -19.458877693653108, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.58008623123169, "step": 19000}
{"episode_reward": 72.2145287852672, "episode": 20.0, "batch_reward": 0.13585280184447765, "critic_loss": 0.21600913366675376, "actor_loss": -18.751801411628723, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.04810619354248, "step": 20000}
{"episode_reward": 77.71356506740919, "episode": 21.0, "batch_reward": 0.13333413955569268, "critic_loss": 0.23225218461453914, "actor_loss": -17.467211142063142, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.523226261138916, "step": 21000}
{"episode_reward": 69.07975506864405, "episode": 22.0, "batch_reward": 0.13242843072861432, "critic_loss": 0.24658082830905914, "actor_loss": -18.0159924993515, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.532365322113037, "step": 22000}
{"episode_reward": 245.41230395939067, "episode": 23.0, "batch_reward": 0.13647128674387932, "critic_loss": 0.26373339363187553, "actor_loss": -18.934884315490724, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.717408657073975, "step": 23000}
{"episode_reward": 119.01809072548706, "episode": 24.0, "batch_reward": 0.13389079751819372, "critic_loss": 0.28717548882961275, "actor_loss": -17.722518069267274, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.92373275756836, "step": 24000}
{"episode_reward": 55.68530753041742, "episode": 25.0, "batch_reward": 0.1340963913947344, "critic_loss": 0.3123605061471462, "actor_loss": -18.37248928833008, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.78121066093445, "step": 25000}
{"episode_reward": 292.15768648990326, "episode": 26.0, "batch_reward": 0.13587977584451438, "critic_loss": 0.3478979987502098, "actor_loss": -18.526389288902283, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.656281232833862, "step": 26000}
{"episode_reward": 46.14779712648656, "episode": 27.0, "batch_reward": 0.13740499398112296, "critic_loss": 0.3676954696625471, "actor_loss": -18.484249841690062, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.512977600097656, "step": 27000}
{"episode_reward": 207.31469000598807, "episode": 28.0, "batch_reward": 0.14043189164996148, "critic_loss": 0.36192170061171053, "actor_loss": -18.560496925354006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.29706645011902, "step": 28000}
{"episode_reward": 266.16688720539224, "episode": 29.0, "batch_reward": 0.14435890016704797, "critic_loss": 0.37644483922421934, "actor_loss": -17.798153120994566, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.578517198562622, "step": 29000}
{"episode_reward": 313.9949458013185, "episode": 30.0, "batch_reward": 0.1498725281059742, "critic_loss": 0.4586018174439669, "actor_loss": -18.829749901771546, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.307175159454346, "step": 30000}
{"episode_reward": 211.77073395955065, "episode": 31.0, "batch_reward": 0.1522829591780901, "critic_loss": 0.47923245622217653, "actor_loss": -18.473659107208253, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.77303600311279, "step": 31000}
{"episode_reward": 202.97579806380642, "episode": 32.0, "batch_reward": 0.15348497372865677, "critic_loss": 0.5747504934370518, "actor_loss": -18.7767831325531, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.84449028968811, "step": 32000}
{"episode_reward": 297.42343380455367, "episode": 33.0, "batch_reward": 0.15834553385525943, "critic_loss": 0.6578201117515564, "actor_loss": -19.140540807723998, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.74034881591797, "step": 33000}
{"episode_reward": 178.83842213589273, "episode": 34.0, "batch_reward": 0.15833982177823783, "critic_loss": 0.5744816445112229, "actor_loss": -20.217897407531737, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.666773080825806, "step": 34000}
{"episode_reward": 182.44298811686494, "episode": 35.0, "batch_reward": 0.15976811852306128, "critic_loss": 0.5328989462256432, "actor_loss": -19.574477191925048, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.971077919006348, "step": 35000}
{"episode_reward": 358.3267189878849, "episode": 36.0, "batch_reward": 0.16424130710214377, "critic_loss": 0.5355249566584825, "actor_loss": -20.867627222061156, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.84119749069214, "step": 36000}
{"episode_reward": 273.03306947785387, "episode": 37.0, "batch_reward": 0.16520206939429044, "critic_loss": 0.47153787717223167, "actor_loss": -20.692286170959473, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.941559076309204, "step": 37000}
{"episode_reward": 45.51762772628151, "episode": 38.0, "batch_reward": 0.16502753675729037, "critic_loss": 0.4477496380656958, "actor_loss": -20.375212188720702, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.40166687965393, "step": 38000}
{"episode_reward": 310.61776903355684, "episode": 39.0, "batch_reward": 0.16840457792580127, "critic_loss": 0.44776810939610007, "actor_loss": -20.650563327789307, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.074625253677368, "step": 39000}
{"episode_reward": 313.0248964027154, "episode": 40.0, "batch_reward": 0.1726457472592592, "critic_loss": 0.42997606106102465, "actor_loss": -21.034561742782593, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.89398431777954, "step": 40000}
{"episode_reward": 325.9573911596463, "episode": 41.0, "batch_reward": 0.17641196578741072, "critic_loss": 0.4147952205836773, "actor_loss": -21.590571342468262, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.85691595077515, "step": 41000}
{"episode_reward": 293.27307534543553, "episode": 42.0, "batch_reward": 0.17963537883758546, "critic_loss": 0.4211458088606596, "actor_loss": -22.179548149108886, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.33246088027954, "step": 42000}
{"episode_reward": 340.6911143206237, "episode": 43.0, "batch_reward": 0.18250735761225223, "critic_loss": 0.40444398173689844, "actor_loss": -22.345541131973267, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.996538400650024, "step": 43000}
{"episode_reward": 337.9642390767796, "episode": 44.0, "batch_reward": 0.18547982054948806, "critic_loss": 0.40579612377285956, "actor_loss": -22.70524933242798, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.653062105178833, "step": 44000}
{"episode_reward": 157.8594716272468, "episode": 45.0, "batch_reward": 0.1843112504929304, "critic_loss": 0.3821986449807882, "actor_loss": -22.48309506225586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.957456827163696, "step": 45000}
{"episode_reward": 142.08766401884128, "episode": 46.0, "batch_reward": 0.183549003303051, "critic_loss": 0.3540801627188921, "actor_loss": -22.580971120834352, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.713188886642456, "step": 46000}
{"episode_reward": 140.31653583443506, "episode": 47.0, "batch_reward": 0.1830038882046938, "critic_loss": 0.37758100594580174, "actor_loss": -21.86681640434265, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.856489896774292, "step": 47000}
{"episode_reward": 107.17756705654894, "episode": 48.0, "batch_reward": 0.1816657840758562, "critic_loss": 0.38125973415374753, "actor_loss": -22.292303968429565, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.21271800994873, "step": 48000}
{"episode_reward": 177.0214060582309, "episode": 49.0, "batch_reward": 0.18164054767787458, "critic_loss": 0.3881070713996887, "actor_loss": -21.85526900482178, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.245919227600098, "step": 49000}
{"episode_reward": 130.26694638556702, "episode": 50.0, "batch_reward": 0.17951198907196522, "critic_loss": 0.4061496422588825, "actor_loss": -21.778226585388182, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.738994359970093, "step": 50000}
{"episode_reward": 178.04470299292026, "episode": 51.0, "batch_reward": 0.18068575243651866, "critic_loss": 0.41735485556721685, "actor_loss": -22.046053581237793, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.414963722229004, "step": 51000}
{"episode_reward": 320.73971858576925, "episode": 52.0, "batch_reward": 0.1832798923999071, "critic_loss": 0.4102678898870945, "actor_loss": -22.4620118598938, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.737393617630005, "step": 52000}
{"episode_reward": 203.5016677409034, "episode": 53.0, "batch_reward": 0.18370133379101752, "critic_loss": 0.42203637813031675, "actor_loss": -22.43773747253418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.91985511779785, "step": 53000}
{"episode_reward": 155.5571644751495, "episode": 54.0, "batch_reward": 0.18108084873855115, "critic_loss": 0.4107745736837387, "actor_loss": -22.410362754821776, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.193585634231567, "step": 54000}
{"episode_reward": 37.09369432571904, "episode": 55.0, "batch_reward": 0.18098527953028679, "critic_loss": 0.4253904924243689, "actor_loss": -22.23098885726929, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.87230896949768, "step": 55000}
{"episode_reward": 245.8118242134876, "episode": 56.0, "batch_reward": 0.1815313833206892, "critic_loss": 0.4183034788072109, "actor_loss": -22.514860614776612, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.89020037651062, "step": 56000}
{"episode_reward": 249.2109457299807, "episode": 57.0, "batch_reward": 0.18100288455188274, "critic_loss": 0.45546769443154334, "actor_loss": -22.803815166473388, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.010518550872803, "step": 57000}
{"episode_reward": 12.763155671009427, "episode": 58.0, "batch_reward": 0.1796457944214344, "critic_loss": 0.40933657766878606, "actor_loss": -22.636547218322754, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.520061254501343, "step": 58000}
{"episode_reward": 82.48186813065897, "episode": 59.0, "batch_reward": 0.17924383483827114, "critic_loss": 0.4109924382716417, "actor_loss": -22.827280254364013, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.187433004379272, "step": 59000}
{"episode_reward": 325.291136901468, "episode": 60.0, "batch_reward": 0.17964098785817623, "critic_loss": 0.42145377264916895, "actor_loss": -23.048078899383544, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.684038877487183, "step": 60000}
{"episode_reward": 218.82800714470827, "episode": 61.0, "batch_reward": 0.18261533476412295, "critic_loss": 0.4222453214377165, "actor_loss": -23.371351802825927, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.25352430343628, "step": 61000}
{"episode_reward": 356.84209747930646, "episode": 62.0, "batch_reward": 0.18493904872238637, "critic_loss": 0.456881003767252, "actor_loss": -23.239746864318846, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.091765880584717, "step": 62000}
{"episode_reward": 408.88827632208296, "episode": 63.0, "batch_reward": 0.18838704735040665, "critic_loss": 0.4345792825073004, "actor_loss": -23.722778812408446, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.62813138961792, "step": 63000}
{"episode_reward": 429.45597935443965, "episode": 64.0, "batch_reward": 0.1916500077843666, "critic_loss": 0.5003442873507739, "actor_loss": -23.988517742156983, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.941710710525513, "step": 64000}
{"episode_reward": 279.98015348083277, "episode": 65.0, "batch_reward": 0.1926936507076025, "critic_loss": 0.5083434986025095, "actor_loss": -24.07190662765503, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.275386810302734, "step": 65000}
{"episode_reward": 213.4801409153303, "episode": 66.0, "batch_reward": 0.1936512294858694, "critic_loss": 0.4828574168384075, "actor_loss": -24.203412776947022, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.034868240356445, "step": 66000}
{"episode_reward": 276.15323414820756, "episode": 67.0, "batch_reward": 0.19496845264732837, "critic_loss": 0.4880252963155508, "actor_loss": -24.163055534362794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.8863627910614, "step": 67000}
{"episode_reward": 296.2500087571107, "episode": 68.0, "batch_reward": 0.1941232595294714, "critic_loss": 0.4963872708529234, "actor_loss": -24.293828132629393, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.801619052886963, "step": 68000}
{"episode_reward": 77.11728144003206, "episode": 69.0, "batch_reward": 0.1942162983715534, "critic_loss": 0.5394161860048771, "actor_loss": -24.153835048675536, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.88765287399292, "step": 69000}
{"episode_reward": 246.9164658476499, "episode": 70.0, "batch_reward": 0.19463806243240833, "critic_loss": 0.5264714585840702, "actor_loss": -24.167648628234865, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.539379835128784, "step": 70000}
{"episode_reward": 326.9471157891721, "episode": 71.0, "batch_reward": 0.1964313418865204, "critic_loss": 0.5392109416723251, "actor_loss": -24.245732452392577, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.22843337059021, "step": 71000}
{"episode_reward": 250.663032988302, "episode": 72.0, "batch_reward": 0.19794108602404595, "critic_loss": 0.5630992130488157, "actor_loss": -24.276813579559327, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.193291187286377, "step": 72000}
{"episode_reward": 282.0568794856248, "episode": 73.0, "batch_reward": 0.19991001023352145, "critic_loss": 0.5259853948503733, "actor_loss": -24.54390657043457, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.922610759735107, "step": 73000}
{"episode_reward": 416.56520148397334, "episode": 74.0, "batch_reward": 0.2021018363237381, "critic_loss": 0.5322841184437275, "actor_loss": -24.651816844940186, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.775782823562622, "step": 74000}
{"episode_reward": 186.4531079452807, "episode": 75.0, "batch_reward": 0.20203201980888844, "critic_loss": 0.5492550841867924, "actor_loss": -24.888459156036376, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.89696192741394, "step": 75000}
{"episode_reward": 415.91197006110514, "episode": 76.0, "batch_reward": 0.2058559995442629, "critic_loss": 0.5525536126047372, "actor_loss": -24.99506336593628, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.056905031204224, "step": 76000}
{"episode_reward": 403.23378090783797, "episode": 77.0, "batch_reward": 0.20794653779268266, "critic_loss": 0.5377836457341909, "actor_loss": -25.560066013336183, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.246154069900513, "step": 77000}
{"episode_reward": 409.2329505800236, "episode": 78.0, "batch_reward": 0.21112108436226845, "critic_loss": 0.5285708373039961, "actor_loss": -25.65256982421875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.267305612564087, "step": 78000}
{"episode_reward": 432.3136788754772, "episode": 79.0, "batch_reward": 0.2128828876465559, "critic_loss": 0.516859389692545, "actor_loss": -26.013988960266115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.506840229034424, "step": 79000}
{"episode_reward": 234.38526654613173, "episode": 80.0, "batch_reward": 0.21300583878159524, "critic_loss": 0.5163953684270381, "actor_loss": -25.731219776153566, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.84639024734497, "step": 80000}
{"episode_reward": 165.093048260858, "episode": 81.0, "batch_reward": 0.2119924755394459, "critic_loss": 0.5166057638972997, "actor_loss": -25.820904163360595, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.343448877334595, "step": 81000}
{"episode_reward": 245.11400739357103, "episode": 82.0, "batch_reward": 0.21340218392014504, "critic_loss": 0.5284757245332002, "actor_loss": -25.636988048553466, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.378934860229492, "step": 82000}
{"episode_reward": 497.5851689823558, "episode": 83.0, "batch_reward": 0.21665628369152545, "critic_loss": 0.5698908399641514, "actor_loss": -26.218757961273194, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.136133193969727, "step": 83000}
{"episode_reward": 382.15913518178905, "episode": 84.0, "batch_reward": 0.21812841323018073, "critic_loss": 0.5353685838729143, "actor_loss": -25.924719547271728, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.234648942947388, "step": 84000}
{"episode_reward": 200.94621139404347, "episode": 85.0, "batch_reward": 0.21825868214666844, "critic_loss": 0.5624149731099606, "actor_loss": -26.233549499511717, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.85939311981201, "step": 85000}
{"episode_reward": 341.2712893386155, "episode": 86.0, "batch_reward": 0.2199350416660309, "critic_loss": 0.5454334668666124, "actor_loss": -26.222515926361083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.112667083740234, "step": 86000}
{"episode_reward": 390.62279623823474, "episode": 87.0, "batch_reward": 0.2217568896263838, "critic_loss": 0.5678858439028263, "actor_loss": -26.51569771194458, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.85044002532959, "step": 87000}
{"episode_reward": 418.05766396822446, "episode": 88.0, "batch_reward": 0.22293771821260452, "critic_loss": 0.5624901876747608, "actor_loss": -26.683973754882814, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.052443504333496, "step": 88000}
{"episode_reward": 52.74593250086739, "episode": 89.0, "batch_reward": 0.22101391668617726, "critic_loss": 0.5902063164263963, "actor_loss": -26.389836685180665, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.06908106803894, "step": 89000}
{"episode_reward": 390.7936904659826, "episode": 90.0, "batch_reward": 0.22334425136446953, "critic_loss": 0.5543097251355648, "actor_loss": -26.611317501068115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.9274263381958, "step": 90000}
{"episode_reward": 328.7257002251401, "episode": 91.0, "batch_reward": 0.2259981990158558, "critic_loss": 0.5522947351932526, "actor_loss": -26.900760574340822, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.88718104362488, "step": 91000}
{"episode_reward": 512.1258265398137, "episode": 92.0, "batch_reward": 0.2289094030112028, "critic_loss": 0.5185746823847294, "actor_loss": -27.320883701324462, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.251420736312866, "step": 92000}
{"episode_reward": 399.37960533170207, "episode": 93.0, "batch_reward": 0.23052780225872993, "critic_loss": 0.5346942782700062, "actor_loss": -27.43662232208252, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.754791259765625, "step": 93000}
{"episode_reward": 447.6391161433367, "episode": 94.0, "batch_reward": 0.23358948765695095, "critic_loss": 0.4821972405314445, "actor_loss": -27.60289105987549, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.066006898880005, "step": 94000}
{"episode_reward": 526.6552911080308, "episode": 95.0, "batch_reward": 0.2365603046864271, "critic_loss": 0.4858023416399956, "actor_loss": -27.78698041534424, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.20650625228882, "step": 95000}
{"episode_reward": 591.9513347110819, "episode": 96.0, "batch_reward": 0.23996379409730434, "critic_loss": 0.5024259638637304, "actor_loss": -27.975323234558104, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.306654691696167, "step": 96000}
{"episode_reward": 506.2853511536813, "episode": 97.0, "batch_reward": 0.2416302338540554, "critic_loss": 0.5250294656902552, "actor_loss": -28.075256271362306, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.01333975791931, "step": 97000}
{"episode_reward": 287.1647421912283, "episode": 98.0, "batch_reward": 0.24208105392754078, "critic_loss": 0.5176807832121849, "actor_loss": -28.11264549636841, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.979337692260742, "step": 98000}
{"episode_reward": 215.79715331517815, "episode": 99.0, "batch_reward": 0.24287660486996174, "critic_loss": 0.46739133924245835, "actor_loss": -28.337149173736574, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.989176273345947, "step": 99000}
{"episode_reward": 493.7928172555061, "episode": 100.0, "batch_reward": 0.24611920949816704, "critic_loss": 0.4727131935656071, "actor_loss": -28.530238327026368, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.61677646636963, "step": 100000}
{"episode_reward": 574.668629333477, "episode": 101.0, "batch_reward": 0.24899605858325957, "critic_loss": 0.46448258857429026, "actor_loss": -28.748683860778808, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.61309313774109, "step": 101000}
{"episode_reward": 620.9129110848439, "episode": 102.0, "batch_reward": 0.25076799146831036, "critic_loss": 0.44921516387164595, "actor_loss": -28.971092144012452, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.097012758255005, "step": 102000}
{"episode_reward": 483.2119812347635, "episode": 103.0, "batch_reward": 0.253840678691864, "critic_loss": 0.4715954099595547, "actor_loss": -29.166890480041506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.196622133255005, "step": 103000}
{"episode_reward": 437.2297364137397, "episode": 104.0, "batch_reward": 0.25593943920731543, "critic_loss": 0.41909758603572844, "actor_loss": -29.31903014755249, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.80876612663269, "step": 104000}
{"episode_reward": 228.9201687043794, "episode": 105.0, "batch_reward": 0.2556607873141766, "critic_loss": 0.43798339340090753, "actor_loss": -29.42284786605835, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.055668354034424, "step": 105000}
{"episode_reward": 331.77310917393885, "episode": 106.0, "batch_reward": 0.2566240030676126, "critic_loss": 0.43144456000626086, "actor_loss": -29.55167699813843, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.9761164188385, "step": 106000}
{"episode_reward": 616.9816449713356, "episode": 107.0, "batch_reward": 0.2592763483226299, "critic_loss": 0.4377850665748119, "actor_loss": -29.69981043243408, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.716954469680786, "step": 107000}
{"episode_reward": 300.1060175131588, "episode": 108.0, "batch_reward": 0.25961309304833413, "critic_loss": 0.44019482530653475, "actor_loss": -29.707633476257325, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.983771085739136, "step": 108000}
{"episode_reward": 506.8061321164759, "episode": 109.0, "batch_reward": 0.2615690703392029, "critic_loss": 0.4498969478011131, "actor_loss": -29.558220436096192, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.099388122558594, "step": 109000}
{"episode_reward": 255.68223770061874, "episode": 110.0, "batch_reward": 0.2616141214966774, "critic_loss": 0.4194104468375444, "actor_loss": -29.6433907623291, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.701143741607666, "step": 110000}
{"episode_reward": 326.6746655376355, "episode": 111.0, "batch_reward": 0.263854269310832, "critic_loss": 0.42214744217693806, "actor_loss": -29.872418117523193, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.367733001708984, "step": 111000}
{"episode_reward": 642.3579239694095, "episode": 112.0, "batch_reward": 0.26744828662276265, "critic_loss": 0.45517686527967455, "actor_loss": -30.240968551635742, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.352370262145996, "step": 112000}
{"episode_reward": 551.0743784251853, "episode": 113.0, "batch_reward": 0.2683784714639187, "critic_loss": 0.44062782630324365, "actor_loss": -30.308627201080323, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.027215242385864, "step": 113000}
{"episode_reward": 524.290503837492, "episode": 114.0, "batch_reward": 0.27135153524577615, "critic_loss": 0.4070391976386309, "actor_loss": -30.30685520553589, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.571439027786255, "step": 114000}
{"episode_reward": 392.47043880176534, "episode": 115.0, "batch_reward": 0.27213203097879884, "critic_loss": 0.4035032031536102, "actor_loss": -30.429400203704834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.02237892150879, "step": 115000}
{"episode_reward": 588.6038420494045, "episode": 116.0, "batch_reward": 0.27497868755459787, "critic_loss": 0.40356937400996684, "actor_loss": -30.74098167800903, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.476216554641724, "step": 116000}
{"episode_reward": 179.67314626576052, "episode": 117.0, "batch_reward": 0.274912781342864, "critic_loss": 0.3849311265051365, "actor_loss": -30.77835210800171, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.80583381652832, "step": 117000}
{"episode_reward": 556.4227226219829, "episode": 118.0, "batch_reward": 0.27795556107163427, "critic_loss": 0.3911756941229105, "actor_loss": -30.708726516723633, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.122580528259277, "step": 118000}
{"episode_reward": 580.0998650025507, "episode": 119.0, "batch_reward": 0.2797644500881433, "critic_loss": 0.3780539071261883, "actor_loss": -30.986253231048583, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.156687259674072, "step": 119000}
{"episode_reward": 417.4288129050923, "episode": 120.0, "batch_reward": 0.27940643317997454, "critic_loss": 0.3951671949625015, "actor_loss": -30.946847133636474, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.82466197013855, "step": 120000}
{"episode_reward": 250.38062335977446, "episode": 121.0, "batch_reward": 0.281361703902483, "critic_loss": 0.4400534041672945, "actor_loss": -31.080780387878416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.72323441505432, "step": 121000}
{"episode_reward": 569.5962340050694, "episode": 122.0, "batch_reward": 0.2834009966403246, "critic_loss": 0.4196809459775686, "actor_loss": -31.268955852508544, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.879902839660645, "step": 122000}
{"episode_reward": 552.2867836414479, "episode": 123.0, "batch_reward": 0.2861124597936869, "critic_loss": 0.4054059376716614, "actor_loss": -31.519692253112794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.977863788604736, "step": 123000}
{"episode_reward": 579.6782892577988, "episode": 124.0, "batch_reward": 0.28729521602392194, "critic_loss": 0.42149606737494466, "actor_loss": -31.546746913909914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.2572078704834, "step": 124000}
{"episode_reward": 627.9491196799796, "episode": 125.0, "batch_reward": 0.2904929236024618, "critic_loss": 0.39934487238526345, "actor_loss": -31.92225232696533, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.785258769989014, "step": 125000}
{"episode_reward": 591.0290367853452, "episode": 126.0, "batch_reward": 0.2906701153516769, "critic_loss": 0.40030390770733354, "actor_loss": -31.9970262260437, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.81119704246521, "step": 126000}
{"episode_reward": 30.598171899219253, "episode": 127.0, "batch_reward": 0.28971173518896104, "critic_loss": 0.41638627798855304, "actor_loss": -31.547828754425048, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.426835298538208, "step": 127000}
{"episode_reward": 409.3641886545445, "episode": 128.0, "batch_reward": 0.29114531236886976, "critic_loss": 0.40257976032793524, "actor_loss": -31.664915576934813, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.872188806533813, "step": 128000}
{"episode_reward": 642.2576827205462, "episode": 129.0, "batch_reward": 0.2943703678995371, "critic_loss": 0.40491136042773723, "actor_loss": -31.917502128601075, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.54150366783142, "step": 129000}
{"episode_reward": 584.127468357102, "episode": 130.0, "batch_reward": 0.29648804977536203, "critic_loss": 0.38439722047746183, "actor_loss": -32.103525451660154, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.892945766448975, "step": 130000}
{"episode_reward": 570.0184678655992, "episode": 131.0, "batch_reward": 0.29955380070209503, "critic_loss": 0.40851791815459726, "actor_loss": -32.30474481582642, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.72799730300903, "step": 131000}
{"episode_reward": 550.111965714335, "episode": 132.0, "batch_reward": 0.3008333979845047, "critic_loss": 0.4296325405091047, "actor_loss": -32.45766764068603, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.279426097869873, "step": 132000}
{"episode_reward": 602.3266206157905, "episode": 133.0, "batch_reward": 0.3004977869093418, "critic_loss": 0.4093704164922237, "actor_loss": -32.510410076141355, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.467271089553833, "step": 133000}
{"episode_reward": 109.94776285592626, "episode": 134.0, "batch_reward": 0.3003289189040661, "critic_loss": 0.4478614728748798, "actor_loss": -32.47580488586426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.028833866119385, "step": 134000}
{"episode_reward": 590.1507260673309, "episode": 135.0, "batch_reward": 0.3036366313397884, "critic_loss": 0.44048539620637894, "actor_loss": -32.71830237197876, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.795555353164673, "step": 135000}
{"episode_reward": 568.4152386505666, "episode": 136.0, "batch_reward": 0.305519022166729, "critic_loss": 0.44312559209764, "actor_loss": -32.685906845092774, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.181583642959595, "step": 136000}
{"episode_reward": 576.4287256263458, "episode": 137.0, "batch_reward": 0.30689733619987963, "critic_loss": 0.46541791869699956, "actor_loss": -33.06918030929565, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.596168279647827, "step": 137000}
{"episode_reward": 546.5758962994643, "episode": 138.0, "batch_reward": 0.3092160138338804, "critic_loss": 0.4162745206952095, "actor_loss": -33.60834293365478, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.31281089782715, "step": 138000}
{"episode_reward": 633.6468208076368, "episode": 139.0, "batch_reward": 0.3111211476922035, "critic_loss": 0.40382717798650264, "actor_loss": -33.68742866134644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.01048755645752, "step": 139000}
{"episode_reward": 589.8277311495442, "episode": 140.0, "batch_reward": 0.3118125053346157, "critic_loss": 0.41283468264341355, "actor_loss": -33.82358110046387, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.121164798736572, "step": 140000}
{"episode_reward": 621.5187103143734, "episode": 141.0, "batch_reward": 0.31581426495313647, "critic_loss": 0.4143290064334869, "actor_loss": -34.14435048675537, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.166292905807495, "step": 141000}
{"episode_reward": 610.2527483613995, "episode": 142.0, "batch_reward": 0.3179455226957798, "critic_loss": 0.3919056348502636, "actor_loss": -34.15063948059082, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.963531017303467, "step": 142000}
{"episode_reward": 634.2079614248427, "episode": 143.0, "batch_reward": 0.32091158810257914, "critic_loss": 0.4111157453656197, "actor_loss": -34.45598066711426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.440120697021484, "step": 143000}
{"episode_reward": 665.3189512257019, "episode": 144.0, "batch_reward": 0.32215039429068565, "critic_loss": 0.3954934737384319, "actor_loss": -34.68604361343384, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.07409429550171, "step": 144000}
{"episode_reward": 583.8903422786964, "episode": 145.0, "batch_reward": 0.32595014888048174, "critic_loss": 0.3772624722570181, "actor_loss": -34.89801668930054, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.792235374450684, "step": 145000}
{"episode_reward": 658.6973999453718, "episode": 146.0, "batch_reward": 0.3258890064358711, "critic_loss": 0.37292166428267953, "actor_loss": -35.12410943222046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.269572496414185, "step": 146000}
{"episode_reward": 632.8668694414192, "episode": 147.0, "batch_reward": 0.326780098259449, "critic_loss": 0.3845771890282631, "actor_loss": -34.87388537979126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.024569511413574, "step": 147000}
{"episode_reward": 540.126258250223, "episode": 148.0, "batch_reward": 0.33042104423046115, "critic_loss": 0.3743291952311993, "actor_loss": -35.3938546333313, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.372811794281006, "step": 148000}
{"episode_reward": 450.198886172943, "episode": 149.0, "batch_reward": 0.33102199202775956, "critic_loss": 0.39461587692797184, "actor_loss": -35.30813021087646, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.136990308761597, "step": 149000}
{"episode_reward": 527.7561951606662, "episode": 150.0, "batch_reward": 0.3332340740263462, "critic_loss": 0.38907301388680937, "actor_loss": -35.647023067474365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
