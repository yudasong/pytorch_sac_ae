{"episode_reward": 0.0, "episode": 1.0, "duration": 17.18552327156067, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.4955670833587646, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.28603598937049396, "critic_loss": 0.025209717511529523, "actor_loss": -16.3143976528038, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 60.6541383266449, "step": 3000}
{"episode_reward": 113.73533335694749, "episode": 4.0, "batch_reward": 0.21050301797688006, "critic_loss": 0.041361372607760134, "actor_loss": -12.731986130714416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.810629844665527, "step": 4000}
{"episode_reward": 26.717293601152868, "episode": 5.0, "batch_reward": 0.17113192114233972, "critic_loss": 0.04597562790475786, "actor_loss": -7.667504877090454, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.19468879699707, "step": 5000}
{"episode_reward": 117.14221435264503, "episode": 6.0, "batch_reward": 0.16289610451459885, "critic_loss": 0.05706242743693292, "actor_loss": -8.983833676338195, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.200801610946655, "step": 6000}
{"episode_reward": 82.30228529040052, "episode": 7.0, "batch_reward": 0.1544375034943223, "critic_loss": 0.061928610494360326, "actor_loss": -9.463511667251588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.845568418502808, "step": 7000}
{"episode_reward": 97.47669607875166, "episode": 8.0, "batch_reward": 0.1439901543930173, "critic_loss": 0.05577653878927231, "actor_loss": -9.148900560855866, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.868696689605713, "step": 8000}
{"episode_reward": 102.15160957419438, "episode": 9.0, "batch_reward": 0.14645064359903334, "critic_loss": 0.09791691595315934, "actor_loss": -11.124238073349, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.848918199539185, "step": 9000}
{"episode_reward": 237.9518605663147, "episode": 10.0, "batch_reward": 0.15696879456192256, "critic_loss": 0.135787521161139, "actor_loss": -11.705354862213134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.8862087726593, "step": 10000}
{"episode_reward": 251.54756206506448, "episode": 11.0, "batch_reward": 0.1628684252873063, "critic_loss": 0.13695111463963985, "actor_loss": -13.550234977722168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.12441396713257, "step": 11000}
{"episode_reward": 156.38842843627987, "episode": 12.0, "batch_reward": 0.1587597252205014, "critic_loss": 0.13654424148052932, "actor_loss": -13.5563345079422, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87886881828308, "step": 12000}
{"episode_reward": 54.00053884391023, "episode": 13.0, "batch_reward": 0.15872041822224855, "critic_loss": 0.14044707784801722, "actor_loss": -14.011290244102478, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.886364698410034, "step": 13000}
{"episode_reward": 298.9015319582014, "episode": 14.0, "batch_reward": 0.15871252013742923, "critic_loss": 0.14089676977694035, "actor_loss": -13.803052055358886, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.904856204986572, "step": 14000}
{"episode_reward": 17.54029866388661, "episode": 15.0, "batch_reward": 0.156640966899693, "critic_loss": 0.16939348164200782, "actor_loss": -15.078920544624328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.879380226135254, "step": 15000}
{"episode_reward": 227.68774344753163, "episode": 16.0, "batch_reward": 0.15633878620713948, "critic_loss": 0.19262245567888023, "actor_loss": -15.486437036514282, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.890662670135498, "step": 16000}
{"episode_reward": 140.1167099369536, "episode": 17.0, "batch_reward": 0.15805882121622564, "critic_loss": 0.20037391916662456, "actor_loss": -15.715747724533081, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.900130033493042, "step": 17000}
{"episode_reward": 216.39362664425767, "episode": 18.0, "batch_reward": 0.16280976705253125, "critic_loss": 0.21503173081576823, "actor_loss": -16.26808719444275, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90218949317932, "step": 18000}
{"episode_reward": 196.89999673453707, "episode": 19.0, "batch_reward": 0.16496077093482017, "critic_loss": 0.21079291889071464, "actor_loss": -17.774692153930665, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.896430492401123, "step": 19000}
{"episode_reward": 245.05526884294534, "episode": 20.0, "batch_reward": 0.1714398865252733, "critic_loss": 0.23203521824628115, "actor_loss": -18.336732763290406, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.884950876235962, "step": 20000}
{"episode_reward": 348.6950337877407, "episode": 21.0, "batch_reward": 0.18117776614427566, "critic_loss": 0.24798139536380767, "actor_loss": -19.817299476623536, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.125354528427124, "step": 21000}
{"episode_reward": 391.91665923984965, "episode": 22.0, "batch_reward": 0.19017598989605905, "critic_loss": 0.2569736590832472, "actor_loss": -19.987244651794434, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.86319923400879, "step": 22000}
{"episode_reward": 323.4916101736335, "episode": 23.0, "batch_reward": 0.19481862099468708, "critic_loss": 0.2873846090734005, "actor_loss": -19.96083864402771, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.913817167282104, "step": 23000}
{"episode_reward": 225.30807227749597, "episode": 24.0, "batch_reward": 0.1976750470995903, "critic_loss": 0.2952596352547407, "actor_loss": -21.117355409622192, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.835770845413208, "step": 24000}
{"episode_reward": 406.9300510877382, "episode": 25.0, "batch_reward": 0.206187820404768, "critic_loss": 0.2941122464835644, "actor_loss": -21.982133646011352, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.905028343200684, "step": 25000}
{"episode_reward": 392.5527876513033, "episode": 26.0, "batch_reward": 0.2115013548284769, "critic_loss": 0.31280582588911054, "actor_loss": -22.758234161376954, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.888647317886353, "step": 26000}
{"episode_reward": 377.2288090625823, "episode": 27.0, "batch_reward": 0.21806201177835466, "critic_loss": 0.3313146959096193, "actor_loss": -23.54319528198242, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87395739555359, "step": 27000}
{"episode_reward": 312.01227119065686, "episode": 28.0, "batch_reward": 0.22188476726412773, "critic_loss": 0.343783054292202, "actor_loss": -24.17310509490967, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.892073154449463, "step": 28000}
{"episode_reward": 196.13847669005756, "episode": 29.0, "batch_reward": 0.22139547151327132, "critic_loss": 0.33838784496486185, "actor_loss": -24.284037216186523, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89043951034546, "step": 29000}
{"episode_reward": 274.99156972561354, "episode": 30.0, "batch_reward": 0.22244045059382916, "critic_loss": 0.35105013561248777, "actor_loss": -24.488829486846925, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.876501321792603, "step": 30000}
{"episode_reward": 205.46720291124197, "episode": 31.0, "batch_reward": 0.22364971777796747, "critic_loss": 0.36044604060053825, "actor_loss": -24.60999983596802, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.143028020858765, "step": 31000}
{"episode_reward": 425.52764569439233, "episode": 32.0, "batch_reward": 0.22558474989235403, "critic_loss": 0.34126483942568303, "actor_loss": -25.454503730773926, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.86906385421753, "step": 32000}
{"episode_reward": 49.36987955331185, "episode": 33.0, "batch_reward": 0.22389674210548402, "critic_loss": 0.37212839621305466, "actor_loss": -25.108532794952392, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.895862102508545, "step": 33000}
{"episode_reward": 374.8096985099441, "episode": 34.0, "batch_reward": 0.22990284816920759, "critic_loss": 0.39904041109979155, "actor_loss": -25.294372554779052, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.903384685516357, "step": 34000}
{"episode_reward": 437.4219438304543, "episode": 35.0, "batch_reward": 0.2324477875381708, "critic_loss": 0.4398150245845318, "actor_loss": -26.152866847991945, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88739323616028, "step": 35000}
{"episode_reward": 132.8550012122006, "episode": 36.0, "batch_reward": 0.23074828791618346, "critic_loss": 0.47944843278825283, "actor_loss": -26.046837505340577, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.883557319641113, "step": 36000}
{"episode_reward": 286.1311735284745, "episode": 37.0, "batch_reward": 0.23191023355722426, "critic_loss": 0.5096338631212711, "actor_loss": -26.073293632507323, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89555525779724, "step": 37000}
{"episode_reward": 225.6819872108337, "episode": 38.0, "batch_reward": 0.23284786708652974, "critic_loss": 0.534225427672267, "actor_loss": -26.103224292755126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.890887022018433, "step": 38000}
{"episode_reward": 228.67927326068445, "episode": 39.0, "batch_reward": 0.23383543759584427, "critic_loss": 0.5347857051789761, "actor_loss": -26.902600036621095, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.919132471084595, "step": 39000}
{"episode_reward": 325.4227707241593, "episode": 40.0, "batch_reward": 0.2359675956070423, "critic_loss": 0.5750523623526096, "actor_loss": -27.068572570800782, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.840891361236572, "step": 40000}
{"episode_reward": 337.0323430572182, "episode": 41.0, "batch_reward": 0.23833490118384362, "critic_loss": 0.613946766346693, "actor_loss": -27.495705429077148, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.17336678504944, "step": 41000}
{"episode_reward": 237.30963490123685, "episode": 42.0, "batch_reward": 0.23747954386472703, "critic_loss": 0.6412704521417618, "actor_loss": -27.154925323486328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89358687400818, "step": 42000}
{"episode_reward": 373.0484037367216, "episode": 43.0, "batch_reward": 0.23788766092061997, "critic_loss": 0.647294061422348, "actor_loss": -27.332660652160644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89399743080139, "step": 43000}
{"episode_reward": 71.49929877573413, "episode": 44.0, "batch_reward": 0.23644388665258884, "critic_loss": 0.6701829954087735, "actor_loss": -27.5584471244812, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.928438425064087, "step": 44000}
{"episode_reward": 338.8471752995308, "episode": 45.0, "batch_reward": 0.23974614299833774, "critic_loss": 0.7011063061058521, "actor_loss": -28.246028316497803, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.859611749649048, "step": 45000}
{"episode_reward": 436.604076650401, "episode": 46.0, "batch_reward": 0.24226374436914921, "critic_loss": 0.6636138324141503, "actor_loss": -28.809777038574218, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.850629091262817, "step": 46000}
{"episode_reward": 162.891150155775, "episode": 47.0, "batch_reward": 0.24308638344705105, "critic_loss": 0.6400268704891204, "actor_loss": -28.813086139678955, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.904688119888306, "step": 47000}
{"episode_reward": 380.27352387346696, "episode": 48.0, "batch_reward": 0.24332501669228077, "critic_loss": 0.652369824320078, "actor_loss": -29.087360000610353, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89452886581421, "step": 48000}
{"episode_reward": 178.68784707210384, "episode": 49.0, "batch_reward": 0.2443138217777014, "critic_loss": 0.630623689442873, "actor_loss": -29.31824380493164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.893028497695923, "step": 49000}
{"episode_reward": 408.870927949692, "episode": 50.0, "batch_reward": 0.24449489726126195, "critic_loss": 0.5955520142912865, "actor_loss": -29.452458213806153, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91780138015747, "step": 50000}
{"episode_reward": 325.40574456107214, "episode": 51.0, "batch_reward": 0.24754627139866353, "critic_loss": 0.6512414574623108, "actor_loss": -29.692043907165527, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.14708113670349, "step": 51000}
{"episode_reward": 210.50917231043846, "episode": 52.0, "batch_reward": 0.24479176659882068, "critic_loss": 0.5956539938151837, "actor_loss": -29.729645206451416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.933156967163086, "step": 52000}
{"episode_reward": 41.929853192730256, "episode": 53.0, "batch_reward": 0.2435194958895445, "critic_loss": 0.6446668992638588, "actor_loss": -29.61603717803955, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.926964282989502, "step": 53000}
{"episode_reward": 190.04257347424831, "episode": 54.0, "batch_reward": 0.24340905950963498, "critic_loss": 0.6945624832808971, "actor_loss": -29.437860443115234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95160436630249, "step": 54000}
{"episode_reward": 318.1583342611658, "episode": 55.0, "batch_reward": 0.24209653569757938, "critic_loss": 0.6286838521659375, "actor_loss": -29.1070678024292, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.926848649978638, "step": 55000}
{"episode_reward": 116.48493598835073, "episode": 56.0, "batch_reward": 0.24127352516353132, "critic_loss": 0.6265200218856335, "actor_loss": -29.32482776260376, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.946048974990845, "step": 56000}
{"episode_reward": 258.11510996036316, "episode": 57.0, "batch_reward": 0.2408177814334631, "critic_loss": 0.6670132179856301, "actor_loss": -29.224771533966063, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89908766746521, "step": 57000}
{"episode_reward": 120.07427020741014, "episode": 58.0, "batch_reward": 0.2400519177913666, "critic_loss": 0.6452693229913712, "actor_loss": -29.02591966629028, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.897869348526, "step": 58000}
{"episode_reward": 169.49411918886165, "episode": 59.0, "batch_reward": 0.2396296356767416, "critic_loss": 0.6270123228728771, "actor_loss": -29.201804210662843, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88891339302063, "step": 59000}
{"episode_reward": 446.7900660127847, "episode": 60.0, "batch_reward": 0.2424422554820776, "critic_loss": 0.6361446901857853, "actor_loss": -29.38530577468872, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.942131280899048, "step": 60000}
{"episode_reward": 394.16498413199946, "episode": 61.0, "batch_reward": 0.24439230839908124, "critic_loss": 0.5898120188117028, "actor_loss": -29.516839416503906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.1615686416626, "step": 61000}
{"episode_reward": 434.21164465176525, "episode": 62.0, "batch_reward": 0.24700438289344312, "critic_loss": 0.600662472486496, "actor_loss": -29.547315544128416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.891822814941406, "step": 62000}
{"episode_reward": 297.41304062916026, "episode": 63.0, "batch_reward": 0.2480924894809723, "critic_loss": 0.5973193791806698, "actor_loss": -29.794146209716796, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90585446357727, "step": 63000}
{"episode_reward": 265.46136676455245, "episode": 64.0, "batch_reward": 0.24970530121028423, "critic_loss": 0.5992065092325211, "actor_loss": -29.705271228790284, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90873432159424, "step": 64000}
{"episode_reward": 509.7965957001366, "episode": 65.0, "batch_reward": 0.2534299369305372, "critic_loss": 0.5647273428589106, "actor_loss": -30.058129623413087, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87094020843506, "step": 65000}
{"episode_reward": 444.8521789601959, "episode": 66.0, "batch_reward": 0.25652806882560253, "critic_loss": 0.6018474766612053, "actor_loss": -30.292911151885985, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.86153483390808, "step": 66000}
{"episode_reward": 477.10965807049814, "episode": 67.0, "batch_reward": 0.25961675849556926, "critic_loss": 0.5749992145597935, "actor_loss": -30.49586897277832, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.868969917297363, "step": 67000}
{"episode_reward": 413.82677616463, "episode": 68.0, "batch_reward": 0.2610373612195253, "critic_loss": 0.5401851725280284, "actor_loss": -30.424617084503176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.920578718185425, "step": 68000}
{"episode_reward": 368.24624717531924, "episode": 69.0, "batch_reward": 0.26267970579862593, "critic_loss": 0.5379042693376541, "actor_loss": -30.49113906097412, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.898364543914795, "step": 69000}
{"episode_reward": 264.64832365961274, "episode": 70.0, "batch_reward": 0.2631352711170912, "critic_loss": 0.5459489881396293, "actor_loss": -30.630993949890136, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.915247917175293, "step": 70000}
{"episode_reward": 374.5858910838865, "episode": 71.0, "batch_reward": 0.26629433257877827, "critic_loss": 0.5262156072854995, "actor_loss": -30.800845581054688, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.12123370170593, "step": 71000}
{"episode_reward": 491.0026320168458, "episode": 72.0, "batch_reward": 0.26758646401762964, "critic_loss": 0.5193775063753128, "actor_loss": -30.902015964508056, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.908544301986694, "step": 72000}
{"episode_reward": 221.9944018080151, "episode": 73.0, "batch_reward": 0.26753196634352205, "critic_loss": 0.5136829323768616, "actor_loss": -30.749380294799806, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.913359880447388, "step": 73000}
{"episode_reward": 442.24228073774975, "episode": 74.0, "batch_reward": 0.26979880744218826, "critic_loss": 0.5126265764087439, "actor_loss": -30.935279708862303, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91186237335205, "step": 74000}
{"episode_reward": 446.4862356873315, "episode": 75.0, "batch_reward": 0.27373628398776056, "critic_loss": 0.5142452101707459, "actor_loss": -31.078492748260498, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.929569721221924, "step": 75000}
{"episode_reward": 480.2216770737187, "episode": 76.0, "batch_reward": 0.27513010609149935, "critic_loss": 0.5368815714716911, "actor_loss": -30.88739733886719, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.883808374404907, "step": 76000}
{"episode_reward": 467.06602969701623, "episode": 77.0, "batch_reward": 0.27689895005524157, "critic_loss": 0.4885832911133766, "actor_loss": -30.99301529312134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.899652242660522, "step": 77000}
{"episode_reward": 243.6702579295866, "episode": 78.0, "batch_reward": 0.27641887560486794, "critic_loss": 0.5073564025759697, "actor_loss": -30.920231540679932, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.938467502593994, "step": 78000}
{"episode_reward": 200.1952149230264, "episode": 79.0, "batch_reward": 0.27645976378023623, "critic_loss": 0.4935676995664835, "actor_loss": -30.669206737518312, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.905929803848267, "step": 79000}
{"episode_reward": 559.5868321638047, "episode": 80.0, "batch_reward": 0.27957899890840054, "critic_loss": 0.4959135453701019, "actor_loss": -30.8253677444458, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.898247003555298, "step": 80000}
{"episode_reward": 497.8841912357315, "episode": 81.0, "batch_reward": 0.28294372929632666, "critic_loss": 0.5000579275041819, "actor_loss": -31.131115802764892, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.354658365249634, "step": 81000}
{"episode_reward": 596.909407684182, "episode": 82.0, "batch_reward": 0.2871739889830351, "critic_loss": 0.486297111466527, "actor_loss": -31.41241759490967, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95090937614441, "step": 82000}
{"episode_reward": 522.1390309318276, "episode": 83.0, "batch_reward": 0.28885679723322394, "critic_loss": 0.48005789823830125, "actor_loss": -31.666290115356446, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.950456619262695, "step": 83000}
{"episode_reward": 230.95085567684367, "episode": 84.0, "batch_reward": 0.28876231122016904, "critic_loss": 0.4594998867958784, "actor_loss": -31.48508490371704, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91576313972473, "step": 84000}
{"episode_reward": 356.0684871765868, "episode": 85.0, "batch_reward": 0.28900360806286335, "critic_loss": 0.4740205155611038, "actor_loss": -31.33089785385132, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91714835166931, "step": 85000}
{"episode_reward": 505.1402741707291, "episode": 86.0, "batch_reward": 0.2924196289330721, "critic_loss": 0.43672759747505185, "actor_loss": -31.57940132904053, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.924850463867188, "step": 86000}
{"episode_reward": 587.9223049278233, "episode": 87.0, "batch_reward": 0.29598349268734453, "critic_loss": 0.4265874741226435, "actor_loss": -31.808887298583983, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.947373867034912, "step": 87000}
{"episode_reward": 503.2010690644237, "episode": 88.0, "batch_reward": 0.2981196476370096, "critic_loss": 0.4730252988189459, "actor_loss": -31.975853576660157, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9027202129364, "step": 88000}
{"episode_reward": 569.6385151377841, "episode": 89.0, "batch_reward": 0.3014210622012615, "critic_loss": 0.425087573453784, "actor_loss": -32.11289961242676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9096577167511, "step": 89000}
{"episode_reward": 542.1166883334967, "episode": 90.0, "batch_reward": 0.30301976792514324, "critic_loss": 0.4376889345794916, "actor_loss": -32.49274785232544, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.920803785324097, "step": 90000}
{"episode_reward": 545.4637080716627, "episode": 91.0, "batch_reward": 0.3069770129621029, "critic_loss": 0.4373171692639589, "actor_loss": -32.40514659118652, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.505473136901855, "step": 91000}
{"episode_reward": 605.0505823058822, "episode": 92.0, "batch_reward": 0.3097061174511909, "critic_loss": 0.43299173541367053, "actor_loss": -33.09017153167725, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90625762939453, "step": 92000}
{"episode_reward": 517.7170532380069, "episode": 93.0, "batch_reward": 0.3121164397448301, "critic_loss": 0.4018588717728853, "actor_loss": -32.92208658218384, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.967089414596558, "step": 93000}
{"episode_reward": 547.760376732031, "episode": 94.0, "batch_reward": 0.313039579719305, "critic_loss": 0.41378662385046483, "actor_loss": -33.34654396057129, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93978452682495, "step": 94000}
{"episode_reward": 76.4779255677889, "episode": 95.0, "batch_reward": 0.3108671824634075, "critic_loss": 0.4037071380466223, "actor_loss": -33.126668533325194, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93192148208618, "step": 95000}
{"episode_reward": 593.2220173163995, "episode": 96.0, "batch_reward": 0.3145648213624954, "critic_loss": 0.38885903531312943, "actor_loss": -33.192104801177976, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.942435026168823, "step": 96000}
{"episode_reward": 515.5055077809898, "episode": 97.0, "batch_reward": 0.31663042813539505, "critic_loss": 0.43464327429234983, "actor_loss": -33.40599781799317, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.899699687957764, "step": 97000}
{"episode_reward": 518.530063978054, "episode": 98.0, "batch_reward": 0.3199291102290153, "critic_loss": 0.408664506316185, "actor_loss": -33.94118984222412, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93925666809082, "step": 98000}
{"episode_reward": 557.0007557202564, "episode": 99.0, "batch_reward": 0.32096860659122467, "critic_loss": 0.4264064047187567, "actor_loss": -33.76442771911621, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.937292098999023, "step": 99000}
{"episode_reward": 581.0762772620443, "episode": 100.0, "batch_reward": 0.3247624179720879, "critic_loss": 0.39526231004297735, "actor_loss": -33.933391815185544, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.909384727478027, "step": 100000}
{"episode_reward": 561.3007203318859, "episode": 101.0, "batch_reward": 0.3265820830464363, "critic_loss": 0.42203894233703615, "actor_loss": -34.25815877532959, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.13247513771057, "step": 101000}
{"episode_reward": 599.1066174420215, "episode": 102.0, "batch_reward": 0.3278287494182587, "critic_loss": 0.4101955950260162, "actor_loss": -34.443310920715334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.912400484085083, "step": 102000}
{"episode_reward": 571.3618256020661, "episode": 103.0, "batch_reward": 0.33053630602359774, "critic_loss": 0.39557954189181327, "actor_loss": -34.59985036468506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91136908531189, "step": 103000}
{"episode_reward": 558.1489837167203, "episode": 104.0, "batch_reward": 0.33394931080937384, "critic_loss": 0.4102632815986872, "actor_loss": -34.76703815078735, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.872666835784912, "step": 104000}
{"episode_reward": 581.5593390265878, "episode": 105.0, "batch_reward": 0.3372566410303116, "critic_loss": 0.39966690945625305, "actor_loss": -34.93108870315552, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.922161102294922, "step": 105000}
{"episode_reward": 618.1921733296668, "episode": 106.0, "batch_reward": 0.3382953625917435, "critic_loss": 0.39183611145615577, "actor_loss": -34.96433195114136, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.883062601089478, "step": 106000}
{"episode_reward": 321.89541948890223, "episode": 107.0, "batch_reward": 0.33871956953406335, "critic_loss": 0.41005679258704186, "actor_loss": -35.11069481277466, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.895254135131836, "step": 107000}
{"episode_reward": 599.9314633088281, "episode": 108.0, "batch_reward": 0.3411458984911442, "critic_loss": 0.4048624748587608, "actor_loss": -35.429496921539304, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89822769165039, "step": 108000}
{"episode_reward": 472.6771837518168, "episode": 109.0, "batch_reward": 0.3412884888648987, "critic_loss": 0.41859416395425797, "actor_loss": -35.586327007293704, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.911357164382935, "step": 109000}
{"episode_reward": 180.72348346626367, "episode": 110.0, "batch_reward": 0.34110792857408523, "critic_loss": 0.4167889544814825, "actor_loss": -35.37226781463623, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89356803894043, "step": 110000}
{"episode_reward": 459.9071876224071, "episode": 111.0, "batch_reward": 0.3422363648414612, "critic_loss": 0.40179704186320303, "actor_loss": -35.486417232513425, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.129250049591064, "step": 111000}
{"episode_reward": 617.8442347192381, "episode": 112.0, "batch_reward": 0.34297856906056406, "critic_loss": 0.4154035652279854, "actor_loss": -35.51907482910156, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90187406539917, "step": 112000}
{"episode_reward": 192.4161988218743, "episode": 113.0, "batch_reward": 0.34441918647289277, "critic_loss": 0.43981083415448663, "actor_loss": -35.80614669036865, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87981152534485, "step": 113000}
{"episode_reward": 564.4985968621548, "episode": 114.0, "batch_reward": 0.3448281450867653, "critic_loss": 0.4492770453542471, "actor_loss": -35.780597942352294, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87373423576355, "step": 114000}
{"episode_reward": 293.8878873629683, "episode": 115.0, "batch_reward": 0.34519549041986464, "critic_loss": 0.43705804252624514, "actor_loss": -35.54342387008667, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.895097017288208, "step": 115000}
{"episode_reward": 581.8154022934079, "episode": 116.0, "batch_reward": 0.3479218012392521, "critic_loss": 0.4720752385556698, "actor_loss": -35.992038845062254, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87262535095215, "step": 116000}
{"episode_reward": 584.852732157886, "episode": 117.0, "batch_reward": 0.34896141695976257, "critic_loss": 0.46560256189107896, "actor_loss": -36.13259505844116, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.8673198223114, "step": 117000}
{"episode_reward": 616.5863016633213, "episode": 118.0, "batch_reward": 0.35072106501460076, "critic_loss": 0.47695987117290495, "actor_loss": -36.28737686157226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.871710538864136, "step": 118000}
{"episode_reward": 620.6639921548006, "episode": 119.0, "batch_reward": 0.3535795197188854, "critic_loss": 0.49618554528057573, "actor_loss": -36.33053424835205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.892978191375732, "step": 119000}
{"episode_reward": 606.587891805212, "episode": 120.0, "batch_reward": 0.3549827213287354, "critic_loss": 0.4454603415876627, "actor_loss": -36.31333044052124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.920004844665527, "step": 120000}
{"episode_reward": 542.455244815814, "episode": 121.0, "batch_reward": 0.3580540084540844, "critic_loss": 0.4808000062406063, "actor_loss": -36.567507793426515, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.16748642921448, "step": 121000}
{"episode_reward": 367.65042564020854, "episode": 122.0, "batch_reward": 0.35745073038339614, "critic_loss": 0.4534013135433197, "actor_loss": -36.639917644500734, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.864206075668335, "step": 122000}
{"episode_reward": 615.6544416071655, "episode": 123.0, "batch_reward": 0.36110129311680794, "critic_loss": 0.44642339438199996, "actor_loss": -37.02443127441406, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87898278236389, "step": 123000}
{"episode_reward": 587.1262000881086, "episode": 124.0, "batch_reward": 0.36147170659899713, "critic_loss": 0.4581989078521729, "actor_loss": -37.216955883026124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.912542581558228, "step": 124000}
{"episode_reward": 607.3098223768756, "episode": 125.0, "batch_reward": 0.36358106151223185, "critic_loss": 0.4532328440696001, "actor_loss": -37.303304374694825, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87063980102539, "step": 125000}
{"episode_reward": 540.7055140726014, "episode": 126.0, "batch_reward": 0.3643600598871708, "critic_loss": 0.4582569105774164, "actor_loss": -37.48347142791748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.874502182006836, "step": 126000}
{"episode_reward": 599.6231933445165, "episode": 127.0, "batch_reward": 0.36663093835115435, "critic_loss": 0.45112083783745766, "actor_loss": -37.73727465820313, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.935400009155273, "step": 127000}
{"episode_reward": 648.335699239896, "episode": 128.0, "batch_reward": 0.36863070806860926, "critic_loss": 0.4714587859064341, "actor_loss": -37.9575239906311, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.85210347175598, "step": 128000}
{"episode_reward": 615.5741318463913, "episode": 129.0, "batch_reward": 0.370097859531641, "critic_loss": 0.44827770967781544, "actor_loss": -38.26778582763672, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.876240253448486, "step": 129000}
{"episode_reward": 555.4501793620632, "episode": 130.0, "batch_reward": 0.3711344363987446, "critic_loss": 0.46043793581426146, "actor_loss": -37.998721702575686, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.917831897735596, "step": 130000}
{"episode_reward": 584.4949249302929, "episode": 131.0, "batch_reward": 0.3735264962017536, "critic_loss": 0.465380952835083, "actor_loss": -38.37441265106201, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.14661383628845, "step": 131000}
{"episode_reward": 595.6926361856351, "episode": 132.0, "batch_reward": 0.3752919721007347, "critic_loss": 0.4350957888066769, "actor_loss": -38.32628481292725, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.889758348464966, "step": 132000}
{"episode_reward": 605.7200023478064, "episode": 133.0, "batch_reward": 0.37591159069538116, "critic_loss": 0.44450232400000095, "actor_loss": -38.6948540687561, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.938077449798584, "step": 133000}
{"episode_reward": 646.4446560685218, "episode": 134.0, "batch_reward": 0.3780530328154564, "critic_loss": 0.4658887243419886, "actor_loss": -38.904087882995604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.890886783599854, "step": 134000}
{"episode_reward": 581.5711407498294, "episode": 135.0, "batch_reward": 0.3809447681605816, "critic_loss": 0.4511586939245462, "actor_loss": -38.92491377258301, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.881298065185547, "step": 135000}
{"episode_reward": 540.3946100952468, "episode": 136.0, "batch_reward": 0.3814850841164589, "critic_loss": 0.43614686040580275, "actor_loss": -38.996160270690915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88414764404297, "step": 136000}
{"episode_reward": 623.9680015719117, "episode": 137.0, "batch_reward": 0.3830695329606533, "critic_loss": 0.4281447470784187, "actor_loss": -39.21018434143066, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.874654293060303, "step": 137000}
{"episode_reward": 588.5408004182145, "episode": 138.0, "batch_reward": 0.3855169848203659, "critic_loss": 0.4262638467997312, "actor_loss": -39.19907572174072, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.879976749420166, "step": 138000}
{"episode_reward": 582.9720951074237, "episode": 139.0, "batch_reward": 0.3859110906720161, "critic_loss": 0.4591673582792282, "actor_loss": -39.505035278320314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.908840894699097, "step": 139000}
{"episode_reward": 572.0693744017848, "episode": 140.0, "batch_reward": 0.38741888058185575, "critic_loss": 0.4392511305063963, "actor_loss": -39.57623194885254, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.867157459259033, "step": 140000}
{"episode_reward": 579.9019070100613, "episode": 141.0, "batch_reward": 0.38835921123623846, "critic_loss": 0.4481476603150368, "actor_loss": -39.455661457061765, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.147061824798584, "step": 141000}
{"episode_reward": 632.456266056038, "episode": 142.0, "batch_reward": 0.3905681911110878, "critic_loss": 0.43410968786478044, "actor_loss": -39.517810443878176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.924924850463867, "step": 142000}
{"episode_reward": 669.104661463003, "episode": 143.0, "batch_reward": 0.3924037174880505, "critic_loss": 0.45644994741678235, "actor_loss": -39.870965171813964, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.894253969192505, "step": 143000}
{"episode_reward": 571.8704793275315, "episode": 144.0, "batch_reward": 0.39446644446253776, "critic_loss": 0.4210248222351074, "actor_loss": -40.083949455261234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.900174140930176, "step": 144000}
{"episode_reward": 596.3317455038685, "episode": 145.0, "batch_reward": 0.3952134578824043, "critic_loss": 0.4450527523458004, "actor_loss": -40.08471044158936, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91149067878723, "step": 145000}
{"episode_reward": 174.00732190914363, "episode": 146.0, "batch_reward": 0.3936765891313553, "critic_loss": 0.4324191799610853, "actor_loss": -40.314772773742675, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.878937244415283, "step": 146000}
{"episode_reward": 591.8763854194091, "episode": 147.0, "batch_reward": 0.39416396218538285, "critic_loss": 0.44741726468503473, "actor_loss": -40.15992195892334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.877098321914673, "step": 147000}
{"episode_reward": 619.5819432005745, "episode": 148.0, "batch_reward": 0.3976591591835022, "critic_loss": 0.45133968348801135, "actor_loss": -40.458579460144044, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88530707359314, "step": 148000}
{"episode_reward": 615.1139461406111, "episode": 149.0, "batch_reward": 0.39837766271829606, "critic_loss": 0.44371913355588916, "actor_loss": -40.42185720825195, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.873191356658936, "step": 149000}
{"episode_reward": 642.0026960596285, "episode": 150.0, "batch_reward": 0.4019432970881462, "critic_loss": 0.4540040032565594, "actor_loss": -41.001515663146975, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
