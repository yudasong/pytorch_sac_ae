{"episode_reward": 0.0, "episode": 1.0, "duration": 15.537569522857666, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.349506139755249, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2842420431555172, "critic_loss": 0.03586588247479494, "actor_loss": -43.709081339248485, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 66.8582284450531, "step": 3000}
{"episode_reward": 101.84769293589738, "episode": 4.0, "batch_reward": 0.2026983510106802, "critic_loss": 0.05164590941555798, "actor_loss": -36.052737732440235, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.791927099227905, "step": 4000}
{"episode_reward": 35.89225824471482, "episode": 5.0, "batch_reward": 0.16856667758524418, "critic_loss": 0.05656668007560074, "actor_loss": -34.46956353203952, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.597680807113647, "step": 5000}
{"episode_reward": 86.92617655903895, "episode": 6.0, "batch_reward": 0.16368505929410457, "critic_loss": 0.06848753889277577, "actor_loss": -33.693340990439054, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.5110924243927, "step": 6000}
{"episode_reward": 142.48769869633054, "episode": 7.0, "batch_reward": 0.1529040688201785, "critic_loss": 0.05369810195639729, "actor_loss": -31.637984595388176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.436152696609497, "step": 7000}
{"episode_reward": 79.58200038911309, "episode": 8.0, "batch_reward": 0.14114769653230905, "critic_loss": 0.04984130791015923, "actor_loss": -31.41280242922902, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.805096864700317, "step": 8000}
{"episode_reward": 24.551962980042838, "episode": 9.0, "batch_reward": 0.12882705498486757, "critic_loss": 0.04956624703109264, "actor_loss": -29.095758696883916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.16241455078125, "step": 9000}
{"episode_reward": 62.13846309764881, "episode": 10.0, "batch_reward": 0.1253680274039507, "critic_loss": 0.052882913133129476, "actor_loss": -29.622567446798087, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.940623998641968, "step": 10000}
{"episode_reward": 113.56953870232904, "episode": 11.0, "batch_reward": 0.12841253817081452, "critic_loss": 0.06856973029486835, "actor_loss": -27.719647407472134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.62165307998657, "step": 11000}
{"episode_reward": 211.9094467050004, "episode": 12.0, "batch_reward": 0.13274875023961066, "critic_loss": 0.07706342746317386, "actor_loss": -27.486695870116353, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.411651372909546, "step": 12000}
{"episode_reward": 104.40114100805862, "episode": 13.0, "batch_reward": 0.13220128253102303, "critic_loss": 0.08748202241584659, "actor_loss": -26.70894436019659, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.43442130088806, "step": 13000}
{"episode_reward": 171.36213434400537, "episode": 14.0, "batch_reward": 0.13434636168181896, "critic_loss": 0.10988976979628205, "actor_loss": -27.13937876749039, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.443413734436035, "step": 14000}
{"episode_reward": 180.4891985445207, "episode": 15.0, "batch_reward": 0.13832644994556903, "critic_loss": 0.12379529128968715, "actor_loss": -25.312581907600165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.791547536849976, "step": 15000}
{"episode_reward": 198.59448492841886, "episode": 16.0, "batch_reward": 0.1443179585263133, "critic_loss": 0.15633058190345764, "actor_loss": -25.0487628633976, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.35965323448181, "step": 16000}
{"episode_reward": 352.7811270569367, "episode": 17.0, "batch_reward": 0.15327029382437468, "critic_loss": 0.22485260932147502, "actor_loss": -26.15052295732498, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.40936255455017, "step": 17000}
{"episode_reward": 90.89566343032934, "episode": 18.0, "batch_reward": 0.15173862233012914, "critic_loss": 0.18760271134227513, "actor_loss": -25.79986302757263, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.42496609687805, "step": 18000}
{"episode_reward": 158.1653576878913, "episode": 19.0, "batch_reward": 0.1531333035379648, "critic_loss": 0.20802504735440017, "actor_loss": -23.35708556985855, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.846193313598633, "step": 19000}
{"episode_reward": 241.2919383528839, "episode": 20.0, "batch_reward": 0.15462532522529362, "critic_loss": 0.22709367452561854, "actor_loss": -22.78106877708435, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.766786098480225, "step": 20000}
{"episode_reward": 98.09294419101886, "episode": 21.0, "batch_reward": 0.15343394875526428, "critic_loss": 0.2390661596953869, "actor_loss": -21.97574912261963, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.645874977111816, "step": 21000}
{"episode_reward": 138.94158288733794, "episode": 22.0, "batch_reward": 0.15393842717260123, "critic_loss": 0.28782708125561474, "actor_loss": -22.187475548744203, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.899881839752197, "step": 22000}
{"episode_reward": 251.65467314720306, "episode": 23.0, "batch_reward": 0.156244042634964, "critic_loss": 0.3017719615548849, "actor_loss": -23.154493001937865, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.679717779159546, "step": 23000}
{"episode_reward": 68.50375892037452, "episode": 24.0, "batch_reward": 0.1536743164435029, "critic_loss": 0.2833124547749758, "actor_loss": -21.517363760948182, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.32477617263794, "step": 24000}
{"episode_reward": 133.108854104843, "episode": 25.0, "batch_reward": 0.1534906056597829, "critic_loss": 0.327056325443089, "actor_loss": -21.858569382667543, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.914371013641357, "step": 25000}
{"episode_reward": 179.31553209752164, "episode": 26.0, "batch_reward": 0.15255883713811635, "critic_loss": 0.3197030646577477, "actor_loss": -21.336415135383607, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.84543800354004, "step": 26000}
{"episode_reward": 112.65052928066713, "episode": 27.0, "batch_reward": 0.1550413726270199, "critic_loss": 0.31065463623404505, "actor_loss": -20.954752680778505, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.446128845214844, "step": 27000}
{"episode_reward": 379.91037109280694, "episode": 28.0, "batch_reward": 0.16105134760588408, "critic_loss": 0.30172521695494653, "actor_loss": -21.592597213745115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.46961498260498, "step": 28000}
{"episode_reward": 249.62514967445972, "episode": 29.0, "batch_reward": 0.16705890250205993, "critic_loss": 0.3039527872204781, "actor_loss": -21.238057367324828, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.30418062210083, "step": 29000}
{"episode_reward": 345.3853072430233, "episode": 30.0, "batch_reward": 0.17063348940014839, "critic_loss": 0.3595609410703182, "actor_loss": -21.66836251449585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.073888063430786, "step": 30000}
{"episode_reward": 168.91990465401508, "episode": 31.0, "batch_reward": 0.17106686276197433, "critic_loss": 0.32040066523849964, "actor_loss": -21.26847563934326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.93031668663025, "step": 31000}
{"episode_reward": 181.50102455699604, "episode": 32.0, "batch_reward": 0.17252629247307777, "critic_loss": 0.34856704287230966, "actor_loss": -20.964617078781128, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.88680362701416, "step": 32000}
{"episode_reward": 449.74436643185794, "episode": 33.0, "batch_reward": 0.1780578683912754, "critic_loss": 0.3315091458261013, "actor_loss": -21.141130535125733, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.325258493423462, "step": 33000}
{"episode_reward": 84.80510283416453, "episode": 34.0, "batch_reward": 0.17819444186985492, "critic_loss": 0.35634892554581166, "actor_loss": -22.368544513702393, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.613848209381104, "step": 34000}
{"episode_reward": 272.9774556802817, "episode": 35.0, "batch_reward": 0.17761418618261815, "critic_loss": 0.3473034584224224, "actor_loss": -21.111424381256104, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.580062866210938, "step": 35000}
{"episode_reward": 56.78268089845518, "episode": 36.0, "batch_reward": 0.17648408113420008, "critic_loss": 0.3334212312400341, "actor_loss": -21.763355604171753, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.183006525039673, "step": 36000}
{"episode_reward": 301.7529491531752, "episode": 37.0, "batch_reward": 0.17878178437054157, "critic_loss": 0.3411079363077879, "actor_loss": -21.162657552719118, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.627713203430176, "step": 37000}
{"episode_reward": 182.21052111920122, "episode": 38.0, "batch_reward": 0.1789710295945406, "critic_loss": 0.3799654817730188, "actor_loss": -20.712269233703612, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.2092707157135, "step": 38000}
{"episode_reward": 100.19716133572281, "episode": 39.0, "batch_reward": 0.1788011827468872, "critic_loss": 0.38663149666786195, "actor_loss": -20.568683275222778, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.756659984588623, "step": 39000}
{"episode_reward": 351.0038908753617, "episode": 40.0, "batch_reward": 0.18260454465448855, "critic_loss": 0.5092255201339722, "actor_loss": -21.220456424713134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.2927885055542, "step": 40000}
{"episode_reward": 368.3751434574928, "episode": 41.0, "batch_reward": 0.18716184820234777, "critic_loss": 0.4332474266588688, "actor_loss": -21.604773279190063, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.49550700187683, "step": 41000}
{"episode_reward": 274.974048882572, "episode": 42.0, "batch_reward": 0.1874180403649807, "critic_loss": 0.43956318993866444, "actor_loss": -22.129359172821044, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.642807722091675, "step": 42000}
{"episode_reward": 75.81151061077102, "episode": 43.0, "batch_reward": 0.1856357828825712, "critic_loss": 0.43285066550970075, "actor_loss": -21.799830825805664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.270976781845093, "step": 43000}
{"episode_reward": 135.7435871944992, "episode": 44.0, "batch_reward": 0.18637436857819556, "critic_loss": 0.47047524884343145, "actor_loss": -22.005029216766356, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.662753582000732, "step": 44000}
{"episode_reward": 391.71146696865964, "episode": 45.0, "batch_reward": 0.1899718500971794, "critic_loss": 0.46713677571713924, "actor_loss": -22.392933654785157, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.443203687667847, "step": 45000}
{"episode_reward": 288.59240170270266, "episode": 46.0, "batch_reward": 0.1919242236316204, "critic_loss": 0.4873490180820227, "actor_loss": -22.654548427581787, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.52354669570923, "step": 46000}
{"episode_reward": 185.54378683106708, "episode": 47.0, "batch_reward": 0.19276427179574968, "critic_loss": 0.44371855464577675, "actor_loss": -22.272971992492675, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.58036518096924, "step": 47000}
{"episode_reward": 190.97324068908415, "episode": 48.0, "batch_reward": 0.19064775469899178, "critic_loss": 0.4750418897867203, "actor_loss": -22.173707695007323, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.66605520248413, "step": 48000}
{"episode_reward": 112.63580176054899, "episode": 49.0, "batch_reward": 0.1908377820700407, "critic_loss": 0.4551488522440195, "actor_loss": -22.33714429855347, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.242011547088623, "step": 49000}
{"episode_reward": 185.33481651873456, "episode": 50.0, "batch_reward": 0.18927189949154855, "critic_loss": 0.5175298061817885, "actor_loss": -22.28063377380371, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.336673736572266, "step": 50000}
{"episode_reward": 197.11548479517688, "episode": 51.0, "batch_reward": 0.1896022534966469, "critic_loss": 0.45435301172733306, "actor_loss": -22.438756858825684, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.18664312362671, "step": 51000}
{"episode_reward": 169.18046772255929, "episode": 52.0, "batch_reward": 0.188452895835042, "critic_loss": 0.43777384465932845, "actor_loss": -22.567904319763183, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.59184193611145, "step": 52000}
{"episode_reward": 89.19339322799814, "episode": 53.0, "batch_reward": 0.18717444829642774, "critic_loss": 0.463723980858922, "actor_loss": -22.472121200561524, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.606197834014893, "step": 53000}
{"episode_reward": 156.5123719760804, "episode": 54.0, "batch_reward": 0.1876761235743761, "critic_loss": 0.46537304849922656, "actor_loss": -22.7560631942749, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.756530046463013, "step": 54000}
{"episode_reward": 315.29218899886246, "episode": 55.0, "batch_reward": 0.19138547308743, "critic_loss": 0.5002557621598244, "actor_loss": -23.078432941436766, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.83902359008789, "step": 55000}
{"episode_reward": 495.26249481308486, "episode": 56.0, "batch_reward": 0.19546282598376274, "critic_loss": 0.48233240804076194, "actor_loss": -23.63128688812256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.435127019882202, "step": 56000}
{"episode_reward": 171.54579299178667, "episode": 57.0, "batch_reward": 0.19540997797250748, "critic_loss": 0.45453141716122625, "actor_loss": -23.602831260681153, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.687411069869995, "step": 57000}
{"episode_reward": 433.0223477389425, "episode": 58.0, "batch_reward": 0.19903161755204202, "critic_loss": 0.5106080320626497, "actor_loss": -24.173594913482667, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.779166221618652, "step": 58000}
{"episode_reward": 127.14945570564343, "episode": 59.0, "batch_reward": 0.19697153854370117, "critic_loss": 0.43988337182998655, "actor_loss": -24.071893924713134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.58202338218689, "step": 59000}
{"episode_reward": 79.30297933211929, "episode": 60.0, "batch_reward": 0.19519541922211647, "critic_loss": 0.471594375282526, "actor_loss": -23.909035549163818, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.693835258483887, "step": 60000}
{"episode_reward": 133.88314224438, "episode": 61.0, "batch_reward": 0.19609135012328624, "critic_loss": 0.5287767073065043, "actor_loss": -24.262006969451903, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.32072949409485, "step": 61000}
{"episode_reward": 308.3844421508991, "episode": 62.0, "batch_reward": 0.19642323790490626, "critic_loss": 0.4597860717922449, "actor_loss": -24.061817962646483, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.11192560195923, "step": 62000}
{"episode_reward": 304.4049226376789, "episode": 63.0, "batch_reward": 0.19712327951192857, "critic_loss": 0.5128328007310629, "actor_loss": -24.25236958694458, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.989754915237427, "step": 63000}
{"episode_reward": 159.476483738966, "episode": 64.0, "batch_reward": 0.1975907547622919, "critic_loss": 0.48981361398100853, "actor_loss": -24.326116416931153, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.681928157806396, "step": 64000}
{"episode_reward": 335.67829017300244, "episode": 65.0, "batch_reward": 0.20015595526993274, "critic_loss": 0.5475884775072336, "actor_loss": -24.672878952026366, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.746976613998413, "step": 65000}
{"episode_reward": 292.94964581315617, "episode": 66.0, "batch_reward": 0.20051107504963875, "critic_loss": 0.5663049646914006, "actor_loss": -24.916855457305907, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.51127552986145, "step": 66000}
{"episode_reward": 147.46517990181863, "episode": 67.0, "batch_reward": 0.2002209704220295, "critic_loss": 0.48904295709729195, "actor_loss": -24.725857082366943, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.048842191696167, "step": 67000}
{"episode_reward": 173.839835686776, "episode": 68.0, "batch_reward": 0.1996357795149088, "critic_loss": 0.4997141954302788, "actor_loss": -24.76980827331543, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.56131362915039, "step": 68000}
{"episode_reward": 210.0734823887526, "episode": 69.0, "batch_reward": 0.2010913569033146, "critic_loss": 0.5032355061918498, "actor_loss": -24.87348875808716, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.52305293083191, "step": 69000}
{"episode_reward": 506.38685773641646, "episode": 70.0, "batch_reward": 0.20358977675437928, "critic_loss": 0.4868154439777136, "actor_loss": -25.165882850646973, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.407501697540283, "step": 70000}
{"episode_reward": 324.89268693615435, "episode": 71.0, "batch_reward": 0.20788379506766796, "critic_loss": 0.47589507459104063, "actor_loss": -25.56690718460083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.21986651420593, "step": 71000}
{"episode_reward": 417.8079388630663, "episode": 72.0, "batch_reward": 0.20969637632369995, "critic_loss": 0.5121946815550328, "actor_loss": -25.64043095779419, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.2621808052063, "step": 72000}
{"episode_reward": 507.1332804130885, "episode": 73.0, "batch_reward": 0.21429130207002162, "critic_loss": 0.4304497611969709, "actor_loss": -26.12893517303467, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.359432697296143, "step": 73000}
{"episode_reward": 338.36039094868755, "episode": 74.0, "batch_reward": 0.216223569303751, "critic_loss": 0.38748821093142033, "actor_loss": -26.36986697769165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.507955074310303, "step": 74000}
{"episode_reward": 501.2030009178069, "episode": 75.0, "batch_reward": 0.21879488204419612, "critic_loss": 0.44771260526776313, "actor_loss": -26.658741760253907, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.381480932235718, "step": 75000}
{"episode_reward": 167.30875904763676, "episode": 76.0, "batch_reward": 0.21856219157576562, "critic_loss": 0.4130336168408394, "actor_loss": -26.513408416748046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.21305274963379, "step": 76000}
{"episode_reward": 346.7442458498833, "episode": 77.0, "batch_reward": 0.22029512859880923, "critic_loss": 0.4585500241369009, "actor_loss": -26.74383572769165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.10977292060852, "step": 77000}
{"episode_reward": 257.1391194680414, "episode": 78.0, "batch_reward": 0.21955918295681476, "critic_loss": 0.4155774837732315, "actor_loss": -26.6005576171875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.61104726791382, "step": 78000}
{"episode_reward": 17.398248657380787, "episode": 79.0, "batch_reward": 0.21931652511656285, "critic_loss": 0.42332140371203425, "actor_loss": -26.75260834503174, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.767234325408936, "step": 79000}
{"episode_reward": 541.8539049398532, "episode": 80.0, "batch_reward": 0.2227922924309969, "critic_loss": 0.4035372742414475, "actor_loss": -26.941749366760256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.54778480529785, "step": 80000}
{"episode_reward": 478.55624236565694, "episode": 81.0, "batch_reward": 0.2263061020076275, "critic_loss": 0.41901253801584243, "actor_loss": -27.171293872833253, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.697527170181274, "step": 81000}
{"episode_reward": 464.9056402638692, "episode": 82.0, "batch_reward": 0.22941611877083778, "critic_loss": 0.42008277752995493, "actor_loss": -27.2650336227417, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.48186731338501, "step": 82000}
{"episode_reward": 288.1002286717107, "episode": 83.0, "batch_reward": 0.23048579168319702, "critic_loss": 0.39849378575384614, "actor_loss": -27.384075359344482, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.57545757293701, "step": 83000}
{"episode_reward": 437.54025699243056, "episode": 84.0, "batch_reward": 0.2324243911355734, "critic_loss": 0.41486649167537687, "actor_loss": -27.432947368621825, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.426170110702515, "step": 84000}
{"episode_reward": 509.56028374797467, "episode": 85.0, "batch_reward": 0.23519909578561782, "critic_loss": 0.41326091048121455, "actor_loss": -27.531372085571288, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.807770490646362, "step": 85000}
{"episode_reward": 261.0451207313815, "episode": 86.0, "batch_reward": 0.23542141059041025, "critic_loss": 0.432099295899272, "actor_loss": -27.499367046356202, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.59405517578125, "step": 86000}
{"episode_reward": 249.67570897898634, "episode": 87.0, "batch_reward": 0.23563588055968285, "critic_loss": 0.41898646169900894, "actor_loss": -27.493286888122558, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.80405879020691, "step": 87000}
{"episode_reward": 271.98605167580234, "episode": 88.0, "batch_reward": 0.23536322803795337, "critic_loss": 0.4296174769848585, "actor_loss": -27.38708186340332, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.86531686782837, "step": 88000}
{"episode_reward": 310.92281531547405, "episode": 89.0, "batch_reward": 0.23696184766292572, "critic_loss": 0.47547466775774955, "actor_loss": -27.586768726348875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.693504095077515, "step": 89000}
{"episode_reward": 497.80608083454996, "episode": 90.0, "batch_reward": 0.23827621187269687, "critic_loss": 0.4758147522807121, "actor_loss": -27.59148781967163, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.646020889282227, "step": 90000}
{"episode_reward": 354.46249281160084, "episode": 91.0, "batch_reward": 0.24174642626941203, "critic_loss": 0.5111711445599795, "actor_loss": -27.812628555297852, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.01274085044861, "step": 91000}
{"episode_reward": 492.64442911345446, "episode": 92.0, "batch_reward": 0.24409676752984524, "critic_loss": 0.42698009563982486, "actor_loss": -28.073120994567873, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.48116445541382, "step": 92000}
{"episode_reward": 540.142058433948, "episode": 93.0, "batch_reward": 0.2468514473438263, "critic_loss": 0.4098055697083473, "actor_loss": -28.508785305023192, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.429275274276733, "step": 93000}
{"episode_reward": 468.5441086323527, "episode": 94.0, "batch_reward": 0.24970277886092662, "critic_loss": 0.41872844415903093, "actor_loss": -28.592006267547607, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.296525955200195, "step": 94000}
{"episode_reward": 487.6485428350132, "episode": 95.0, "batch_reward": 0.2519455431550741, "critic_loss": 0.413945729508996, "actor_loss": -28.818168884277345, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.082642793655396, "step": 95000}
{"episode_reward": 415.2973685638205, "episode": 96.0, "batch_reward": 0.25337754571437837, "critic_loss": 0.42243916699290274, "actor_loss": -28.853675212860107, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.536786317825317, "step": 96000}
{"episode_reward": 433.234557155531, "episode": 97.0, "batch_reward": 0.2557017641961575, "critic_loss": 0.3670262594372034, "actor_loss": -29.138736740112304, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.10673999786377, "step": 97000}
{"episode_reward": 491.8609269503471, "episode": 98.0, "batch_reward": 0.2581909132152796, "critic_loss": 0.4245963858664036, "actor_loss": -29.282085388183592, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.626492738723755, "step": 98000}
{"episode_reward": 482.84392037810903, "episode": 99.0, "batch_reward": 0.2598386768549681, "critic_loss": 0.38077241949737073, "actor_loss": -29.503073696136475, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.78154158592224, "step": 99000}
{"episode_reward": 307.2076010174015, "episode": 100.0, "batch_reward": 0.2629668012410402, "critic_loss": 0.41825072427093984, "actor_loss": -29.75888405227661, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.619765043258667, "step": 100000}
{"episode_reward": 517.7874806130798, "episode": 101.0, "batch_reward": 0.2625601793527603, "critic_loss": 0.44366387635469434, "actor_loss": -29.652477195739745, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.73584461212158, "step": 101000}
{"episode_reward": 274.4053005856143, "episode": 102.0, "batch_reward": 0.26107769745588305, "critic_loss": 0.42318393927812575, "actor_loss": -29.486261920928953, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.726186275482178, "step": 102000}
{"episode_reward": 123.19364589064875, "episode": 103.0, "batch_reward": 0.26156136514246464, "critic_loss": 0.4291705333143473, "actor_loss": -29.44411557006836, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.528740167617798, "step": 103000}
{"episode_reward": 497.42324349406204, "episode": 104.0, "batch_reward": 0.2646839932054281, "critic_loss": 0.43679081769287587, "actor_loss": -29.49497906112671, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.27437925338745, "step": 104000}
{"episode_reward": 432.58174953138644, "episode": 105.0, "batch_reward": 0.26592328499257567, "critic_loss": 0.42524808816611764, "actor_loss": -29.704373641967774, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.36647605895996, "step": 105000}
{"episode_reward": 486.9494273340214, "episode": 106.0, "batch_reward": 0.26712543445825576, "critic_loss": 0.40813987179100514, "actor_loss": -29.948970672607423, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.29267954826355, "step": 106000}
{"episode_reward": 513.9289416072663, "episode": 107.0, "batch_reward": 0.27115660744905473, "critic_loss": 0.38974652732908727, "actor_loss": -30.254011768341066, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.209197759628296, "step": 107000}
{"episode_reward": 566.6932923952811, "episode": 108.0, "batch_reward": 0.2729438118040562, "critic_loss": 0.39453487657010555, "actor_loss": -30.36005624771118, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.613556146621704, "step": 108000}
{"episode_reward": 476.5176374925121, "episode": 109.0, "batch_reward": 0.2754097540974617, "critic_loss": 0.3918632778525353, "actor_loss": -30.322692276000975, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.68683886528015, "step": 109000}
{"episode_reward": 416.4780414871657, "episode": 110.0, "batch_reward": 0.27581971280276774, "critic_loss": 0.36339485231786967, "actor_loss": -30.47279425048828, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.744280099868774, "step": 110000}
{"episode_reward": 280.8398730744944, "episode": 111.0, "batch_reward": 0.2758856835961342, "critic_loss": 0.3975957209765911, "actor_loss": -30.5160047454834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.87065887451172, "step": 111000}
{"episode_reward": 336.60304313736583, "episode": 112.0, "batch_reward": 0.2772423102259636, "critic_loss": 0.37428470312058926, "actor_loss": -30.528814994812013, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.26289653778076, "step": 112000}
{"episode_reward": 348.5460152876499, "episode": 113.0, "batch_reward": 0.2783093199133873, "critic_loss": 0.41472785614430907, "actor_loss": -30.77167817687988, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.54654860496521, "step": 113000}
{"episode_reward": 585.8090020684124, "episode": 114.0, "batch_reward": 0.2806624175161123, "critic_loss": 0.39605657120049, "actor_loss": -30.76209349822998, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.018075466156006, "step": 114000}
{"episode_reward": 523.7967019576732, "episode": 115.0, "batch_reward": 0.28309229186177254, "critic_loss": 0.33632246616482736, "actor_loss": -30.92871230316162, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.20098876953125, "step": 115000}
{"episode_reward": 464.7617324455976, "episode": 116.0, "batch_reward": 0.28501971645653246, "critic_loss": 0.3675153025239706, "actor_loss": -31.216448638916017, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.5801420211792, "step": 116000}
{"episode_reward": 597.2186603691383, "episode": 117.0, "batch_reward": 0.2869016822129488, "critic_loss": 0.34988231156766414, "actor_loss": -31.471255039215087, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.637319326400757, "step": 117000}
{"episode_reward": 600.1559824458, "episode": 118.0, "batch_reward": 0.28919466224312784, "critic_loss": 0.35174921829998496, "actor_loss": -31.62270266723633, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.580463886260986, "step": 118000}
{"episode_reward": 453.2623732163654, "episode": 119.0, "batch_reward": 0.29087292206287385, "critic_loss": 0.3601162376999855, "actor_loss": -31.834041957855224, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.65838861465454, "step": 119000}
{"episode_reward": 281.74676962357046, "episode": 120.0, "batch_reward": 0.2907263769954443, "critic_loss": 0.38050322100520134, "actor_loss": -31.814040222167968, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.856769800186157, "step": 120000}
{"episode_reward": 530.2182925106989, "episode": 121.0, "batch_reward": 0.29294236686825753, "critic_loss": 0.3727689428776503, "actor_loss": -31.801604900360108, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.94394016265869, "step": 121000}
{"episode_reward": 558.4398955715341, "episode": 122.0, "batch_reward": 0.2953446732312441, "critic_loss": 0.37724761307239535, "actor_loss": -31.974993335723877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.421451807022095, "step": 122000}
{"episode_reward": 529.6962740975271, "episode": 123.0, "batch_reward": 0.2971996111869812, "critic_loss": 0.3894787169992924, "actor_loss": -32.21415105438233, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.127174139022827, "step": 123000}
{"episode_reward": 282.87172599372707, "episode": 124.0, "batch_reward": 0.2950823141038418, "critic_loss": 0.423215464502573, "actor_loss": -32.16946703720093, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.352277517318726, "step": 124000}
{"episode_reward": 178.2401371683156, "episode": 125.0, "batch_reward": 0.2945993378609419, "critic_loss": 0.3984868332147598, "actor_loss": -31.871979385375976, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.286510944366455, "step": 125000}
{"episode_reward": 327.97169902145697, "episode": 126.0, "batch_reward": 0.2948837424367666, "critic_loss": 0.403899685010314, "actor_loss": -32.24519750595093, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.42555570602417, "step": 126000}
{"episode_reward": 179.62487167156524, "episode": 127.0, "batch_reward": 0.2947311133295298, "critic_loss": 0.36941130402684214, "actor_loss": -31.86486619949341, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.976794004440308, "step": 127000}
{"episode_reward": 560.4080848367649, "episode": 128.0, "batch_reward": 0.29715477649867533, "critic_loss": 0.3754273512214422, "actor_loss": -32.23014724349976, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.91420817375183, "step": 128000}
{"episode_reward": 410.82446152874263, "episode": 129.0, "batch_reward": 0.29807525673508645, "critic_loss": 0.3713215403705835, "actor_loss": -32.395736122131346, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.607136011123657, "step": 129000}
{"episode_reward": 505.3236886919035, "episode": 130.0, "batch_reward": 0.2990561113655567, "critic_loss": 0.393410273835063, "actor_loss": -32.5470382270813, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.721309900283813, "step": 130000}
{"episode_reward": 497.3806408721829, "episode": 131.0, "batch_reward": 0.301977466404438, "critic_loss": 0.4022350186258554, "actor_loss": -32.567804779052736, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.25456619262695, "step": 131000}
{"episode_reward": 600.3096569098236, "episode": 132.0, "batch_reward": 0.30334198103845117, "critic_loss": 0.4183588721007109, "actor_loss": -32.88923034286499, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.47317600250244, "step": 132000}
{"episode_reward": 382.16241537611444, "episode": 133.0, "batch_reward": 0.3048751517236233, "critic_loss": 0.3934236120581627, "actor_loss": -33.11045421218872, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.320218324661255, "step": 133000}
{"episode_reward": 615.0046713076824, "episode": 134.0, "batch_reward": 0.3065587701499462, "critic_loss": 0.41496882133185864, "actor_loss": -33.152144947052, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.11818265914917, "step": 134000}
{"episode_reward": 590.973193366042, "episode": 135.0, "batch_reward": 0.3096997458338738, "critic_loss": 0.440319563254714, "actor_loss": -33.59245854949951, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.976502418518066, "step": 135000}
{"episode_reward": 530.2717370860807, "episode": 136.0, "batch_reward": 0.3104099713116884, "critic_loss": 0.43078117406368255, "actor_loss": -33.667320930480955, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.81446623802185, "step": 136000}
{"episode_reward": 624.6001316158807, "episode": 137.0, "batch_reward": 0.3125675307661295, "critic_loss": 0.43444589149951934, "actor_loss": -34.04084080505371, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.633466005325317, "step": 137000}
{"episode_reward": 581.6725739870868, "episode": 138.0, "batch_reward": 0.31607857809960843, "critic_loss": 0.45242095993459225, "actor_loss": -34.41927424240112, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.389846563339233, "step": 138000}
{"episode_reward": 620.7378073472578, "episode": 139.0, "batch_reward": 0.31749866643548014, "critic_loss": 0.4558914654403925, "actor_loss": -34.613114589691165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.83596968650818, "step": 139000}
{"episode_reward": 611.8000532310607, "episode": 140.0, "batch_reward": 0.3183524784743786, "critic_loss": 0.4089596248716116, "actor_loss": -34.75794323730469, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.528247833251953, "step": 140000}
{"episode_reward": 596.12985785972, "episode": 141.0, "batch_reward": 0.32069876056909563, "critic_loss": 0.3838507332205772, "actor_loss": -35.030885875701905, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.17353558540344, "step": 141000}
{"episode_reward": 622.063180022914, "episode": 142.0, "batch_reward": 0.32336783054471013, "critic_loss": 0.4158010064214468, "actor_loss": -35.18323249816895, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.355119228363037, "step": 142000}
{"episode_reward": 543.653797067853, "episode": 143.0, "batch_reward": 0.32514192241430284, "critic_loss": 0.3936431926190853, "actor_loss": -35.393408824920655, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.52688980102539, "step": 143000}
{"episode_reward": 614.2459322510763, "episode": 144.0, "batch_reward": 0.32639009219408033, "critic_loss": 0.414520722001791, "actor_loss": -35.56099560165405, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.441810369491577, "step": 144000}
{"episode_reward": 589.0501410630823, "episode": 145.0, "batch_reward": 0.3290831741690636, "critic_loss": 0.3750137469917536, "actor_loss": -35.67997456741333, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.56820273399353, "step": 145000}
{"episode_reward": 567.2292844681081, "episode": 146.0, "batch_reward": 0.32883500295877455, "critic_loss": 0.3929288579672575, "actor_loss": -35.96481029510498, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.122016191482544, "step": 146000}
{"episode_reward": 591.8705021287608, "episode": 147.0, "batch_reward": 0.33077399352192877, "critic_loss": 0.4016458845883608, "actor_loss": -35.845820167541504, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.416735649108887, "step": 147000}
{"episode_reward": 591.2490671189379, "episode": 148.0, "batch_reward": 0.3350526272654533, "critic_loss": 0.39482029797136786, "actor_loss": -36.4438143157959, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.75810718536377, "step": 148000}
{"episode_reward": 627.0590147058472, "episode": 149.0, "batch_reward": 0.3361196238994598, "critic_loss": 0.38142520426213744, "actor_loss": -36.42196629333496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.571629762649536, "step": 149000}
{"episode_reward": 638.6361143537691, "episode": 150.0, "batch_reward": 0.33758331805467606, "critic_loss": 0.37644308610260485, "actor_loss": -36.67672248840332, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
