{"episode_reward": 0.0, "episode": 1.0, "duration": 13.748535394668579, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.2122671604156494, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2840493217075853, "critic_loss": 0.16597974662727696, "actor_loss": -47.632097829671416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 70.87989497184753, "step": 3000}
{"episode_reward": 76.68708995624812, "episode": 4.0, "batch_reward": 0.2143992470949888, "critic_loss": 0.2001904718130827, "actor_loss": -41.187710021972656, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.31494402885437, "step": 4000}
{"episode_reward": 190.53335581333272, "episode": 5.0, "batch_reward": 0.21482277324795723, "critic_loss": 0.1928958090469241, "actor_loss": -41.25388944244385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.55599617958069, "step": 5000}
{"episode_reward": 240.7383034821717, "episode": 6.0, "batch_reward": 0.21104026088118552, "critic_loss": 0.18451449335366488, "actor_loss": -39.397294979095456, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.469285249710083, "step": 6000}
{"episode_reward": 80.00998983073421, "episode": 7.0, "batch_reward": 0.18987674716114997, "critic_loss": 0.18316080902516843, "actor_loss": -34.83420640182495, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.495235681533813, "step": 7000}
{"episode_reward": 71.67090523513441, "episode": 8.0, "batch_reward": 0.18302161694318056, "critic_loss": 0.2053992127031088, "actor_loss": -33.39182019042969, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.389877796173096, "step": 8000}
{"episode_reward": 264.689703453207, "episode": 9.0, "batch_reward": 0.19575765746831894, "critic_loss": 0.23558956198394299, "actor_loss": -34.094238273620604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.42415738105774, "step": 9000}
{"episode_reward": 323.4212877541513, "episode": 10.0, "batch_reward": 0.20453806272149086, "critic_loss": 0.2560684516876936, "actor_loss": -35.17587224960327, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.89177107810974, "step": 10000}
{"episode_reward": 250.90369358304844, "episode": 11.0, "batch_reward": 0.21070987971127034, "critic_loss": 0.265568056166172, "actor_loss": -35.10874488449097, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.370500326156616, "step": 11000}
{"episode_reward": 303.29190979900557, "episode": 12.0, "batch_reward": 0.2166909355968237, "critic_loss": 0.28861487422138454, "actor_loss": -35.64883921432495, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.37792181968689, "step": 12000}
{"episode_reward": 267.4040561810801, "episode": 13.0, "batch_reward": 0.22499087886512278, "critic_loss": 0.2915483748018742, "actor_loss": -35.890113109588626, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.86019992828369, "step": 13000}
{"episode_reward": 223.17263240521964, "episode": 14.0, "batch_reward": 0.22682254788279532, "critic_loss": 0.28917094203829763, "actor_loss": -36.07464404296875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.87399125099182, "step": 14000}
{"episode_reward": 400.7929380106847, "episode": 15.0, "batch_reward": 0.24012701624631883, "critic_loss": 0.29697651985287665, "actor_loss": -36.28420760726929, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.54468321800232, "step": 15000}
{"episode_reward": 473.9226204906609, "episode": 16.0, "batch_reward": 0.24864037643373013, "critic_loss": 0.28540672332048417, "actor_loss": -36.29577874755859, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.80715250968933, "step": 16000}
{"episode_reward": 130.5675504295755, "episode": 17.0, "batch_reward": 0.24624830159544944, "critic_loss": 0.2679599936753511, "actor_loss": -35.99015229034424, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.647841691970825, "step": 17000}
{"episode_reward": 245.45048646919568, "episode": 18.0, "batch_reward": 0.24931141896545886, "critic_loss": 0.29390325385332106, "actor_loss": -35.662716796875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.38275671005249, "step": 18000}
{"episode_reward": 375.0023812673345, "episode": 19.0, "batch_reward": 0.2560071758329868, "critic_loss": 0.2926593976020813, "actor_loss": -34.90542889785767, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.570541620254517, "step": 19000}
{"episode_reward": 453.26779470501447, "episode": 20.0, "batch_reward": 0.2633610122203827, "critic_loss": 0.30854859805107115, "actor_loss": -35.02538818359375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.699957609176636, "step": 20000}
{"episode_reward": 289.147607162387, "episode": 21.0, "batch_reward": 0.26812700207531454, "critic_loss": 0.2699896730333567, "actor_loss": -34.85279222869873, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.598533153533936, "step": 21000}
{"episode_reward": 513.9075519943171, "episode": 22.0, "batch_reward": 0.27889357434213163, "critic_loss": 0.3136594050824642, "actor_loss": -35.481685802459715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.12137460708618, "step": 22000}
{"episode_reward": 485.9296759776053, "episode": 23.0, "batch_reward": 0.2904361021667719, "critic_loss": 0.31609224413335324, "actor_loss": -36.7651781463623, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.717490911483765, "step": 23000}
{"episode_reward": 513.5668032031239, "episode": 24.0, "batch_reward": 0.29708886589109895, "critic_loss": 0.37015545623004437, "actor_loss": -36.899340217590336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.8939425945282, "step": 24000}
{"episode_reward": 520.4326366435824, "episode": 25.0, "batch_reward": 0.3059841955602169, "critic_loss": 0.4209396443068981, "actor_loss": -38.22662363815308, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.24092388153076, "step": 25000}
{"episode_reward": 533.0378021610692, "episode": 26.0, "batch_reward": 0.3145892395377159, "critic_loss": 0.5228473295271396, "actor_loss": -38.8192290725708, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.387813091278076, "step": 26000}
{"episode_reward": 532.3917488194905, "episode": 27.0, "batch_reward": 0.32401643896102905, "critic_loss": 0.5027076125144958, "actor_loss": -39.5460983467102, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.748748302459717, "step": 27000}
{"episode_reward": 522.2882430351157, "episode": 28.0, "batch_reward": 0.3282479041516781, "critic_loss": 0.5645696232914925, "actor_loss": -39.962006851196286, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.735484838485718, "step": 28000}
{"episode_reward": 212.83758130862157, "episode": 29.0, "batch_reward": 0.3204288392364979, "critic_loss": 1.020443091750145, "actor_loss": -39.96467820739746, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.982702255249023, "step": 29000}
{"episode_reward": 24.637531496058514, "episode": 30.0, "batch_reward": 0.309934414640069, "critic_loss": 1.0745587940812111, "actor_loss": -40.15317738342285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.605796813964844, "step": 30000}
{"episode_reward": 10.927469326957596, "episode": 31.0, "batch_reward": 0.30034069110453127, "critic_loss": 0.9488506191372872, "actor_loss": -40.367478347778324, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.55946731567383, "step": 31000}
{"episode_reward": 17.788816268852106, "episode": 32.0, "batch_reward": 0.29070790754258635, "critic_loss": 0.9678657052516937, "actor_loss": -40.35217795562744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.269942045211792, "step": 32000}
{"episode_reward": 23.28604285801065, "episode": 33.0, "batch_reward": 0.2815799080133438, "critic_loss": 0.9560636482536793, "actor_loss": -40.400425544738766, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.822655200958252, "step": 33000}
{"episode_reward": 12.609641230119255, "episode": 34.0, "batch_reward": 0.27429883915185926, "critic_loss": 0.7738260576426983, "actor_loss": -40.61303653717041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.807291746139526, "step": 34000}
{"episode_reward": 8.233372809861088, "episode": 35.0, "batch_reward": 0.2661572705954313, "critic_loss": 0.6679870044887066, "actor_loss": -40.54980844116211, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.58741855621338, "step": 35000}
{"episode_reward": 135.2028808483349, "episode": 36.0, "batch_reward": 0.2670934426635504, "critic_loss": 0.6285525986552238, "actor_loss": -40.566029541015624, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.034921646118164, "step": 36000}
{"episode_reward": 387.94041597867744, "episode": 37.0, "batch_reward": 0.2716359442025423, "critic_loss": 0.5791859576106071, "actor_loss": -40.594161659240726, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.926257371902466, "step": 37000}
{"episode_reward": 492.15487747891854, "episode": 38.0, "batch_reward": 0.2753501642793417, "critic_loss": 0.578499454677105, "actor_loss": -40.743635200500485, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.942599058151245, "step": 38000}
{"episode_reward": 376.76779255373475, "episode": 39.0, "batch_reward": 0.2776206947118044, "critic_loss": 0.5959543915688992, "actor_loss": -40.81881562042236, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.58079981803894, "step": 39000}
{"episode_reward": 252.7253268409738, "episode": 40.0, "batch_reward": 0.27532455664873123, "critic_loss": 0.5918398180902005, "actor_loss": -40.68998153686523, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.872938871383667, "step": 40000}
{"episode_reward": 4.350888513058469, "episode": 41.0, "batch_reward": 0.2680170135498047, "critic_loss": 0.5597338637709618, "actor_loss": -40.521972114562985, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.40051746368408, "step": 41000}
{"episode_reward": 2.091046027365512, "episode": 42.0, "batch_reward": 0.26212374933063987, "critic_loss": 0.5722190151512623, "actor_loss": -40.236215606689456, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.77526617050171, "step": 42000}
{"episode_reward": 2.0202607055009016, "episode": 43.0, "batch_reward": 0.2548854336887598, "critic_loss": 0.5881714105904102, "actor_loss": -39.99051657104492, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.105650901794434, "step": 43000}
{"episode_reward": 0.9632887378961823, "episode": 44.0, "batch_reward": 0.24886081555485726, "critic_loss": 0.6475552181601525, "actor_loss": -39.832127632141116, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.91371989250183, "step": 44000}
{"episode_reward": 2.9362426311302534, "episode": 45.0, "batch_reward": 0.24401878246665, "critic_loss": 0.7078616074323654, "actor_loss": -39.81291316986084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.84866213798523, "step": 45000}
{"episode_reward": 3.0740356384617074, "episode": 46.0, "batch_reward": 0.2379566193819046, "critic_loss": 0.8613109183609485, "actor_loss": -39.96455068206787, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.860076665878296, "step": 46000}
{"episode_reward": 30.279833620450443, "episode": 47.0, "batch_reward": 0.23460374239087106, "critic_loss": 1.0862885736227035, "actor_loss": -40.573993339538575, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.503867864608765, "step": 47000}
{"episode_reward": 18.06281327864619, "episode": 48.0, "batch_reward": 0.22987729290127754, "critic_loss": 1.1533933482766152, "actor_loss": -41.63096459960938, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.73846411705017, "step": 48000}
{"episode_reward": 15.12715533081629, "episode": 49.0, "batch_reward": 0.2247509446889162, "critic_loss": 1.3141547540426255, "actor_loss": -42.441084663391116, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.747917413711548, "step": 49000}
{"episode_reward": 12.311210778365751, "episode": 50.0, "batch_reward": 0.221122179672122, "critic_loss": 1.8223695518970489, "actor_loss": -43.327497009277344, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.44688081741333, "step": 50000}
{"episode_reward": 12.221376987180449, "episode": 51.0, "batch_reward": 0.2178862246721983, "critic_loss": 2.1930866543650627, "actor_loss": -45.190615310668946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.021589040756226, "step": 51000}
{"episode_reward": 17.71697387102935, "episode": 52.0, "batch_reward": 0.21297560842335225, "critic_loss": 2.718773473858833, "actor_loss": -47.03945915985108, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.323704719543457, "step": 52000}
{"episode_reward": 13.262830102984266, "episode": 53.0, "batch_reward": 0.20940537019073963, "critic_loss": 2.8505487422943117, "actor_loss": -49.60186032485962, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.203295469284058, "step": 53000}
{"episode_reward": 13.541435040061387, "episode": 54.0, "batch_reward": 0.20493845093250274, "critic_loss": 2.934100708603859, "actor_loss": -52.49417406463623, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.19600749015808, "step": 54000}
{"episode_reward": 10.111980491482742, "episode": 55.0, "batch_reward": 0.20135922423005104, "critic_loss": 2.983792134642601, "actor_loss": -55.06267195892334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.91099452972412, "step": 55000}
{"episode_reward": 19.435049862167926, "episode": 56.0, "batch_reward": 0.19860849000513553, "critic_loss": 2.9983720215559004, "actor_loss": -56.127489616394044, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.176806211471558, "step": 56000}
{"episode_reward": 25.016256074487732, "episode": 57.0, "batch_reward": 0.1947545915991068, "critic_loss": 2.860861265540123, "actor_loss": -57.50149984741211, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.700996160507202, "step": 57000}
{"episode_reward": 15.493615318146587, "episode": 58.0, "batch_reward": 0.19199477408826351, "critic_loss": 2.5368297415971757, "actor_loss": -57.908331504821774, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.695918560028076, "step": 58000}
{"episode_reward": 25.75484048710175, "episode": 59.0, "batch_reward": 0.189043067663908, "critic_loss": 2.216540443897247, "actor_loss": -58.187434200286866, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.304073572158813, "step": 59000}
{"episode_reward": 10.701259082394984, "episode": 60.0, "batch_reward": 0.18642406597733496, "critic_loss": 2.0441307114362717, "actor_loss": -59.30932983016968, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.030077695846558, "step": 60000}
{"episode_reward": 23.69050957914232, "episode": 61.0, "batch_reward": 0.1838399636298418, "critic_loss": 1.9650788938999175, "actor_loss": -58.97743067550659, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.50230097770691, "step": 61000}
{"episode_reward": 26.05730716208046, "episode": 62.0, "batch_reward": 0.18138806388527154, "critic_loss": 1.9029406408071519, "actor_loss": -59.489200263977054, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.881662607192993, "step": 62000}
{"episode_reward": 22.44959454540221, "episode": 63.0, "batch_reward": 0.178465416431427, "critic_loss": 1.7880054020285607, "actor_loss": -58.47247074127197, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.047471284866333, "step": 63000}
{"episode_reward": 13.941998153205297, "episode": 64.0, "batch_reward": 0.17650832759588958, "critic_loss": 1.7348817544579507, "actor_loss": -57.7076452293396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.92139434814453, "step": 64000}
{"episode_reward": 29.259525935241847, "episode": 65.0, "batch_reward": 0.17355138148367405, "critic_loss": 1.5383572544455528, "actor_loss": -56.64114588165283, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.872823238372803, "step": 65000}
{"episode_reward": 35.67942843424177, "episode": 66.0, "batch_reward": 0.17095608308166266, "critic_loss": 1.3782999688386917, "actor_loss": -54.95616704559326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.96227192878723, "step": 66000}
{"episode_reward": 51.326486870162576, "episode": 67.0, "batch_reward": 0.16939698088169097, "critic_loss": 1.3319905465245248, "actor_loss": -54.17319278717041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.042935609817505, "step": 67000}
{"episode_reward": 56.85758303367425, "episode": 68.0, "batch_reward": 0.16881517089903356, "critic_loss": 1.2088024979233742, "actor_loss": -52.37014645385742, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.297289609909058, "step": 68000}
{"episode_reward": 49.297592974351105, "episode": 69.0, "batch_reward": 0.16874826585501432, "critic_loss": 1.134580516040325, "actor_loss": -51.677881507873536, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.933207988739014, "step": 69000}
{"episode_reward": 257.89311324622895, "episode": 70.0, "batch_reward": 0.16898523038625718, "critic_loss": 1.0830401818752289, "actor_loss": -51.16202254486084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.657912254333496, "step": 70000}
{"episode_reward": 25.588620768853563, "episode": 71.0, "batch_reward": 0.16573366677761078, "critic_loss": 1.0566986336708069, "actor_loss": -49.605493507385255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.64550852775574, "step": 71000}
{"episode_reward": 21.206032972569957, "episode": 72.0, "batch_reward": 0.1659415667951107, "critic_loss": 1.04986888602376, "actor_loss": -48.93563667678833, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.91333818435669, "step": 72000}
{"episode_reward": 251.28319241947563, "episode": 73.0, "batch_reward": 0.16632254853099585, "critic_loss": 1.0913946138620376, "actor_loss": -48.23694208145142, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.071999311447144, "step": 73000}
{"episode_reward": 385.16383786002274, "episode": 74.0, "batch_reward": 0.17077909450232984, "critic_loss": 1.140746616601944, "actor_loss": -48.25413436126709, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.06734323501587, "step": 74000}
{"episode_reward": 478.0865318155997, "episode": 75.0, "batch_reward": 0.17195281817018987, "critic_loss": 1.0383724905848504, "actor_loss": -48.20696615982056, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.074990272521973, "step": 75000}
{"episode_reward": 128.69173752564802, "episode": 76.0, "batch_reward": 0.17435267692804338, "critic_loss": 1.0228012063801288, "actor_loss": -47.93025225830078, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.968703269958496, "step": 76000}
{"episode_reward": 492.24873681931206, "episode": 77.0, "batch_reward": 0.17768227171897888, "critic_loss": 0.9780463414788246, "actor_loss": -47.41415424346924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.021517276763916, "step": 77000}
{"episode_reward": 357.4043207284296, "episode": 78.0, "batch_reward": 0.1810429095849395, "critic_loss": 0.9897503449916839, "actor_loss": -47.390997062683105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.819361925125122, "step": 78000}
{"episode_reward": 603.4497484308807, "episode": 79.0, "batch_reward": 0.18351623602211475, "critic_loss": 0.9662556167840958, "actor_loss": -46.276407821655276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.06095576286316, "step": 79000}
{"episode_reward": 22.97863547531219, "episode": 80.0, "batch_reward": 0.18144744227826595, "critic_loss": 0.8831093920469284, "actor_loss": -45.6966918296814, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.901260137557983, "step": 80000}
{"episode_reward": 32.809750894865275, "episode": 81.0, "batch_reward": 0.18216041795909405, "critic_loss": 0.8903815684318542, "actor_loss": -44.77206848144531, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.14027404785156, "step": 81000}
{"episode_reward": 536.8686237316298, "episode": 82.0, "batch_reward": 0.1853175882846117, "critic_loss": 1.0874432342350482, "actor_loss": -44.73136683654785, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.39097833633423, "step": 82000}
{"episode_reward": 326.49741322141665, "episode": 83.0, "batch_reward": 0.1893514885008335, "critic_loss": 0.9363730728626252, "actor_loss": -43.9482474975586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.24016547203064, "step": 83000}
{"episode_reward": 369.2284066359925, "episode": 84.0, "batch_reward": 0.19113762710988522, "critic_loss": 0.8433698705434799, "actor_loss": -43.4038526725769, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.89739966392517, "step": 84000}
{"episode_reward": 591.6541983909074, "episode": 85.0, "batch_reward": 0.1950826990902424, "critic_loss": 0.8415443560481072, "actor_loss": -43.56272623062134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.95596933364868, "step": 85000}
{"episode_reward": 484.636074758891, "episode": 86.0, "batch_reward": 0.20068822966516017, "critic_loss": 0.8664782858490944, "actor_loss": -43.328986682891845, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.104174613952637, "step": 86000}
{"episode_reward": 638.4252683352548, "episode": 87.0, "batch_reward": 0.20441241912543773, "critic_loss": 0.7750599556863308, "actor_loss": -43.16402642440796, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.171749353408813, "step": 87000}
{"episode_reward": 620.8073304067406, "episode": 88.0, "batch_reward": 0.20920697042346, "critic_loss": 0.9303521647155285, "actor_loss": -42.74328260040283, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.952492237091064, "step": 88000}
{"episode_reward": 483.75980187058104, "episode": 89.0, "batch_reward": 0.21203838351368903, "critic_loss": 0.844973091840744, "actor_loss": -42.42493567276001, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.03285503387451, "step": 89000}
{"episode_reward": 514.4271415420194, "episode": 90.0, "batch_reward": 0.21475910425186157, "critic_loss": 0.7939237714707852, "actor_loss": -42.28708218002319, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.959099054336548, "step": 90000}
{"episode_reward": 459.1056966839021, "episode": 91.0, "batch_reward": 0.21743932956457138, "critic_loss": 0.7877014439105987, "actor_loss": -41.772964263916016, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.17803144454956, "step": 91000}
{"episode_reward": 548.2389237526778, "episode": 92.0, "batch_reward": 0.2204730922728777, "critic_loss": 0.7603137703239917, "actor_loss": -41.51559017181396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.887537240982056, "step": 92000}
{"episode_reward": 534.2628096865202, "episode": 93.0, "batch_reward": 0.22482634867727758, "critic_loss": 0.6874843070209027, "actor_loss": -41.000518962860106, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.878671646118164, "step": 93000}
{"episode_reward": 620.4657517498844, "episode": 94.0, "batch_reward": 0.22931076833605765, "critic_loss": 0.7026436555087566, "actor_loss": -41.19321236801147, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.799572467803955, "step": 94000}
{"episode_reward": 534.218345214061, "episode": 95.0, "batch_reward": 0.2321813307851553, "critic_loss": 0.6473056999593974, "actor_loss": -41.01734677886963, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.762680053710938, "step": 95000}
{"episode_reward": 591.9257907688507, "episode": 96.0, "batch_reward": 0.23604744927585125, "critic_loss": 0.5974484782516957, "actor_loss": -40.853203941345214, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.73005247116089, "step": 96000}
{"episode_reward": 282.84634785951573, "episode": 97.0, "batch_reward": 0.23641917584836483, "critic_loss": 0.5400052587091922, "actor_loss": -40.31456251525879, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.952532052993774, "step": 97000}
{"episode_reward": 547.9004752974931, "episode": 98.0, "batch_reward": 0.23946383690834044, "critic_loss": 0.48116904278099537, "actor_loss": -40.03801928710938, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.89332389831543, "step": 98000}
{"episode_reward": 598.4820242188756, "episode": 99.0, "batch_reward": 0.24383836367726325, "critic_loss": 0.5075840611308813, "actor_loss": -39.787185066223145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.926314115524292, "step": 99000}
{"episode_reward": 535.6633471940494, "episode": 100.0, "batch_reward": 0.2454941155463457, "critic_loss": 0.49624860064685344, "actor_loss": -39.38561832427978, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.03121066093445, "step": 100000}
{"episode_reward": 527.3545835931941, "episode": 101.0, "batch_reward": 0.250184446439147, "critic_loss": 0.43888193532824515, "actor_loss": -39.33430867767334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.90035343170166, "step": 101000}
{"episode_reward": 637.0377505088583, "episode": 102.0, "batch_reward": 0.25275579699873924, "critic_loss": 0.4555553137809038, "actor_loss": -39.08223831939697, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.593599557876587, "step": 102000}
{"episode_reward": 591.1433633972283, "episode": 103.0, "batch_reward": 0.2552539506852627, "critic_loss": 0.46482955816388133, "actor_loss": -38.98715689086914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.771018981933594, "step": 103000}
{"episode_reward": 401.03656017127895, "episode": 104.0, "batch_reward": 0.2572593144327402, "critic_loss": 0.44141046023368835, "actor_loss": -38.54940572357178, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.674612760543823, "step": 104000}
{"episode_reward": 538.6045605194416, "episode": 105.0, "batch_reward": 0.2603640153855085, "critic_loss": 0.42947317534685137, "actor_loss": -38.553297981262205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.3710355758667, "step": 105000}
{"episode_reward": 623.219129399305, "episode": 106.0, "batch_reward": 0.26390792468190194, "critic_loss": 0.4648151016235352, "actor_loss": -38.46190010070801, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.796138525009155, "step": 106000}
{"episode_reward": 271.4714887765396, "episode": 107.0, "batch_reward": 0.264169170320034, "critic_loss": 0.44108961237967015, "actor_loss": -38.0398514251709, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.489720106124878, "step": 107000}
{"episode_reward": 575.226773634843, "episode": 108.0, "batch_reward": 0.26592287722229957, "critic_loss": 0.4449530519247055, "actor_loss": -37.77392673110962, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.83914279937744, "step": 108000}
{"episode_reward": 636.6799222255629, "episode": 109.0, "batch_reward": 0.2711341367661953, "critic_loss": 0.41295188730955124, "actor_loss": -38.095976013183595, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.06757426261902, "step": 109000}
{"episode_reward": 620.3786261641168, "episode": 110.0, "batch_reward": 0.2750197557359934, "critic_loss": 0.374971973747015, "actor_loss": -38.01071211242676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.83892321586609, "step": 110000}
{"episode_reward": 689.7255122850522, "episode": 111.0, "batch_reward": 0.27633227622509005, "critic_loss": 0.3898082168996334, "actor_loss": -37.87180911254883, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.76455044746399, "step": 111000}
{"episode_reward": 624.3276199021909, "episode": 112.0, "batch_reward": 0.28013906480371953, "critic_loss": 0.3526449885070324, "actor_loss": -37.97485504150391, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.00356674194336, "step": 112000}
{"episode_reward": 592.0990931162278, "episode": 113.0, "batch_reward": 0.2824541236311197, "critic_loss": 0.39918687334656716, "actor_loss": -38.07006130218506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.16571617126465, "step": 113000}
{"episode_reward": 454.8067089242483, "episode": 114.0, "batch_reward": 0.2854529726654291, "critic_loss": 0.4189167429357767, "actor_loss": -37.857204467773435, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.667661428451538, "step": 114000}
{"episode_reward": 552.6890833660256, "episode": 115.0, "batch_reward": 0.2863239162713289, "critic_loss": 0.39536040379106996, "actor_loss": -37.71868975067139, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.74850058555603, "step": 115000}
{"episode_reward": 581.5296970779746, "episode": 116.0, "batch_reward": 0.2904262598752975, "critic_loss": 0.37065985876321794, "actor_loss": -37.91677841186524, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.6662917137146, "step": 116000}
{"episode_reward": 665.5013114801332, "episode": 117.0, "batch_reward": 0.2938681908547878, "critic_loss": 0.3578388458490372, "actor_loss": -38.0539606590271, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.14790654182434, "step": 117000}
{"episode_reward": 660.6901465298387, "episode": 118.0, "batch_reward": 0.2970642719119787, "critic_loss": 0.3645361562669277, "actor_loss": -38.19180017089844, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.757914304733276, "step": 118000}
{"episode_reward": 692.633940774342, "episode": 119.0, "batch_reward": 0.3007571809440851, "critic_loss": 0.3398327532857656, "actor_loss": -38.45952215576172, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.081356048583984, "step": 119000}
{"episode_reward": 674.1202798599817, "episode": 120.0, "batch_reward": 0.30274422021210196, "critic_loss": 0.34397698985040187, "actor_loss": -38.34261589050293, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.02353310585022, "step": 120000}
{"episode_reward": 646.5698859337799, "episode": 121.0, "batch_reward": 0.3057498637139797, "critic_loss": 0.37340530987083914, "actor_loss": -38.298867095947266, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.17957258224487, "step": 121000}
{"episode_reward": 182.00564478728876, "episode": 122.0, "batch_reward": 0.30404119159281257, "critic_loss": 0.3658238614499569, "actor_loss": -38.07343613815308, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.106443166732788, "step": 122000}
{"episode_reward": 628.8908268658397, "episode": 123.0, "batch_reward": 0.30697451934218406, "critic_loss": 0.3291462863534689, "actor_loss": -38.28643291091919, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.08907651901245, "step": 123000}
{"episode_reward": 665.5563349784326, "episode": 124.0, "batch_reward": 0.30961518797278403, "critic_loss": 0.3518172520250082, "actor_loss": -38.29195659637451, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.858034372329712, "step": 124000}
{"episode_reward": 621.6382558353483, "episode": 125.0, "batch_reward": 0.3126200013011694, "critic_loss": 0.35177089174091813, "actor_loss": -38.46080689239502, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.091323852539062, "step": 125000}
{"episode_reward": 699.4360140542161, "episode": 126.0, "batch_reward": 0.31543691819906233, "critic_loss": 0.3490840215086937, "actor_loss": -38.6240304107666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.95341467857361, "step": 126000}
{"episode_reward": 669.9041153630742, "episode": 127.0, "batch_reward": 0.31857099203765393, "critic_loss": 0.33124188654124737, "actor_loss": -38.64879891204834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.61372685432434, "step": 127000}
{"episode_reward": 451.58492127017786, "episode": 128.0, "batch_reward": 0.3187851032614708, "critic_loss": 0.3603332836925983, "actor_loss": -38.66718212127685, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.78616952896118, "step": 128000}
{"episode_reward": 602.0551781578984, "episode": 129.0, "batch_reward": 0.3211198083758354, "critic_loss": 0.37501901617646216, "actor_loss": -38.815984115600585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.11191964149475, "step": 129000}
{"episode_reward": 681.868811188575, "episode": 130.0, "batch_reward": 0.323265829205513, "critic_loss": 0.36824927739799024, "actor_loss": -39.07484445953369, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.635716438293457, "step": 130000}
{"episode_reward": 679.8590707481122, "episode": 131.0, "batch_reward": 0.3276368395984173, "critic_loss": 0.3755050074607134, "actor_loss": -39.099619361877444, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.179492235183716, "step": 131000}
{"episode_reward": 318.76915728622276, "episode": 132.0, "batch_reward": 0.327619289368391, "critic_loss": 0.37729031771421434, "actor_loss": -39.003849830627445, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.758321046829224, "step": 132000}
{"episode_reward": 257.2069815616681, "episode": 133.0, "batch_reward": 0.3267049718797207, "critic_loss": 0.3628084473013878, "actor_loss": -39.0115396194458, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.77929162979126, "step": 133000}
{"episode_reward": 689.5034561839744, "episode": 134.0, "batch_reward": 0.32850932839512825, "critic_loss": 0.3562733918130398, "actor_loss": -39.13950063323975, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.79257321357727, "step": 134000}
{"episode_reward": 654.8240301135609, "episode": 135.0, "batch_reward": 0.33149159491062163, "critic_loss": 0.3545835943520069, "actor_loss": -39.23198588562012, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.635292530059814, "step": 135000}
{"episode_reward": 678.2556715686737, "episode": 136.0, "batch_reward": 0.33544752433896063, "critic_loss": 0.3538772696852684, "actor_loss": -39.4801489944458, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.690505027770996, "step": 136000}
{"episode_reward": 713.1329075162593, "episode": 137.0, "batch_reward": 0.33672034659981726, "critic_loss": 0.33684411498904226, "actor_loss": -39.54791265869141, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.712098598480225, "step": 137000}
{"episode_reward": 686.8675573564531, "episode": 138.0, "batch_reward": 0.3414813714325428, "critic_loss": 0.3209262332469225, "actor_loss": -40.12696784210205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.83387279510498, "step": 138000}
{"episode_reward": 686.1999407714502, "episode": 139.0, "batch_reward": 0.3408545005917549, "critic_loss": 0.3308803931772709, "actor_loss": -39.8571104888916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.108097553253174, "step": 139000}
{"episode_reward": 31.161233974975055, "episode": 140.0, "batch_reward": 0.33967509952187536, "critic_loss": 0.35136715845763683, "actor_loss": -39.7043183670044, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.713202714920044, "step": 140000}
{"episode_reward": 380.43204507450537, "episode": 141.0, "batch_reward": 0.3384978865087032, "critic_loss": 0.34347411812841894, "actor_loss": -39.3572082824707, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.145663022994995, "step": 141000}
{"episode_reward": 591.7579967762513, "episode": 142.0, "batch_reward": 0.34175008034706117, "critic_loss": 0.35269167110323907, "actor_loss": -39.38583500671387, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.648523330688477, "step": 142000}
{"episode_reward": 650.4113842441797, "episode": 143.0, "batch_reward": 0.3432122361958027, "critic_loss": 0.3652566426694393, "actor_loss": -39.39150289916992, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.844160795211792, "step": 143000}
{"episode_reward": 691.7257280963214, "episode": 144.0, "batch_reward": 0.3486084472835064, "critic_loss": 0.372551216468215, "actor_loss": -39.78669319152832, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.39988350868225, "step": 144000}
{"episode_reward": 630.5620975058015, "episode": 145.0, "batch_reward": 0.34843905639648437, "critic_loss": 0.34897032934427263, "actor_loss": -39.618383346557614, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.931540727615356, "step": 145000}
{"episode_reward": 636.619157100414, "episode": 146.0, "batch_reward": 0.3501427619755268, "critic_loss": 0.36218140548467637, "actor_loss": -39.946954246520995, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.792476415634155, "step": 146000}
{"episode_reward": 641.3135406925973, "episode": 147.0, "batch_reward": 0.3520046658217907, "critic_loss": 0.3594474930167198, "actor_loss": -39.906006980895995, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.79543924331665, "step": 147000}
{"episode_reward": 695.6494692633956, "episode": 148.0, "batch_reward": 0.35523182624578475, "critic_loss": 0.317838063493371, "actor_loss": -40.25353209686279, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.90350079536438, "step": 148000}
{"episode_reward": 651.3193768716569, "episode": 149.0, "batch_reward": 0.35815701180696485, "critic_loss": 0.33258879429101945, "actor_loss": -40.581913429260254, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.14154052734375, "step": 149000}
{"episode_reward": 705.8983986543666, "episode": 150.0, "batch_reward": 0.3602670866549015, "critic_loss": 0.3412980281114578, "actor_loss": -40.90003981781006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
