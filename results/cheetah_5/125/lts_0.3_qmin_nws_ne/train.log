{"episode_reward": 0.0, "episode": 1.0, "duration": 17.665536165237427, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.5245296955108643, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2794741694357404, "critic_loss": 0.018766865722177332, "actor_loss": -17.733016299364827, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 68.13346219062805, "step": 3000}
{"episode_reward": 4.847647877381193, "episode": 4.0, "batch_reward": 0.17391481072455645, "critic_loss": 0.012510564533993601, "actor_loss": -18.72540134239197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.0705783367157, "step": 4000}
{"episode_reward": 5.701656784196384, "episode": 5.0, "batch_reward": 0.13453890956938266, "critic_loss": 0.01426479617948644, "actor_loss": -15.731479681015015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.318296194076538, "step": 5000}
{"episode_reward": 5.672427409370001, "episode": 6.0, "batch_reward": 0.1108465518206358, "critic_loss": 0.01373247331706807, "actor_loss": -15.494851818084717, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.821674823760986, "step": 6000}
{"episode_reward": 5.5130204090788615, "episode": 7.0, "batch_reward": 0.09481527483835817, "critic_loss": 0.01320589426229708, "actor_loss": -15.427997129440307, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.75634741783142, "step": 7000}
{"episode_reward": 5.661065907100434, "episode": 8.0, "batch_reward": 0.08369202451221645, "critic_loss": 0.02067072093905881, "actor_loss": -14.396764209747314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.095995664596558, "step": 8000}
{"episode_reward": 4.6619347866934815, "episode": 9.0, "batch_reward": 0.07363613210618496, "critic_loss": 0.015019330703071319, "actor_loss": -15.17694924068451, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.977246046066284, "step": 9000}
{"episode_reward": 5.369481337801211, "episode": 10.0, "batch_reward": 0.06733969593048096, "critic_loss": 0.012724001158960163, "actor_loss": -13.469295375347137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.705297231674194, "step": 10000}
{"episode_reward": 6.186279164390772, "episode": 11.0, "batch_reward": 0.06148969804495573, "critic_loss": 0.01937245065555908, "actor_loss": -14.624329077720642, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.11644244194031, "step": 11000}
{"episode_reward": 4.947831131313909, "episode": 12.0, "batch_reward": 0.05689596723951399, "critic_loss": 0.015120144686778076, "actor_loss": -13.955964798927306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.574907541275024, "step": 12000}
{"episode_reward": 5.750715110478963, "episode": 13.0, "batch_reward": 0.05208387609943747, "critic_loss": 0.013861184357199819, "actor_loss": -13.632592489719391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.495277881622314, "step": 13000}
{"episode_reward": 4.251409108598392, "episode": 14.0, "batch_reward": 0.048210672647692264, "critic_loss": 0.02319342078140471, "actor_loss": -12.174635021686553, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.637442350387573, "step": 14000}
{"episode_reward": 4.816480035568381, "episode": 15.0, "batch_reward": 0.045752946462482215, "critic_loss": 0.016293363411794416, "actor_loss": -13.57650918006897, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.867620706558228, "step": 15000}
{"episode_reward": 5.131157533922081, "episode": 16.0, "batch_reward": 0.042516320621594786, "critic_loss": 0.011719417912187054, "actor_loss": -13.260388925552368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.24655818939209, "step": 16000}
{"episode_reward": 5.15017338970649, "episode": 17.0, "batch_reward": 0.040781566434539854, "critic_loss": 0.020554715604288502, "actor_loss": -12.339657179355621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.341601133346558, "step": 17000}
{"episode_reward": 3.832113055585586, "episode": 18.0, "batch_reward": 0.03872334579564631, "critic_loss": 0.01089212374429917, "actor_loss": -11.381116346836091, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10967779159546, "step": 18000}
{"episode_reward": 5.223325733475879, "episode": 19.0, "batch_reward": 0.03672016534209251, "critic_loss": 0.016919015140389092, "actor_loss": -13.156957643032074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.658079385757446, "step": 19000}
{"episode_reward": 4.996224538603666, "episode": 20.0, "batch_reward": 0.034752303265966476, "critic_loss": 0.014463169298367575, "actor_loss": -12.580544336318969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.340490579605103, "step": 20000}
{"episode_reward": 5.011022183443241, "episode": 21.0, "batch_reward": 0.03409355762694031, "critic_loss": 0.01657095454557566, "actor_loss": -13.418817055225372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.29577612876892, "step": 21000}
{"episode_reward": 5.72173282496438, "episode": 22.0, "batch_reward": 0.032319763783365485, "critic_loss": 0.012070183036499657, "actor_loss": -11.981074397563935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.892521858215332, "step": 22000}
{"episode_reward": 6.6169880777267185, "episode": 23.0, "batch_reward": 0.031711022668052466, "critic_loss": 0.016064367609098552, "actor_loss": -10.516285163402557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.689979791641235, "step": 23000}
{"episode_reward": 4.485250839843895, "episode": 24.0, "batch_reward": 0.030040488217025995, "critic_loss": 0.013476553864020389, "actor_loss": -11.563827514171601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.778230667114258, "step": 24000}
{"episode_reward": 4.89355916189971, "episode": 25.0, "batch_reward": 0.028958469641394913, "critic_loss": 0.019114667629473843, "actor_loss": -11.26209450006485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.16430425643921, "step": 25000}
{"episode_reward": 4.54093729546561, "episode": 26.0, "batch_reward": 0.02789414467709139, "critic_loss": 0.007320887182548176, "actor_loss": -11.290049377918244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.64673638343811, "step": 26000}
{"episode_reward": 5.637169237666707, "episode": 27.0, "batch_reward": 0.02750101899821311, "critic_loss": 0.013431854958354961, "actor_loss": -11.173323630332947, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.805604457855225, "step": 27000}
{"episode_reward": 2.9703503912973956, "episode": 28.0, "batch_reward": 0.02625074124475941, "critic_loss": 0.014817170339811128, "actor_loss": -11.27158894586563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.093574047088623, "step": 28000}
{"episode_reward": 5.182358852177256, "episode": 29.0, "batch_reward": 0.02645053949067369, "critic_loss": 0.009450733880454209, "actor_loss": -11.212144699335099, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.050743103027344, "step": 29000}
{"episode_reward": 5.299614030019115, "episode": 30.0, "batch_reward": 0.024651682407129557, "critic_loss": 0.013415766525198705, "actor_loss": -11.009459250450135, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.308175563812256, "step": 30000}
{"episode_reward": 4.503442197486506, "episode": 31.0, "batch_reward": 0.02424562491988763, "critic_loss": 0.008888894624324167, "actor_loss": -10.627448984384536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.509742975234985, "step": 31000}
{"episode_reward": 5.9010217123211675, "episode": 32.0, "batch_reward": 0.02339887166628614, "critic_loss": 0.01080373012452037, "actor_loss": -11.799120374202728, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.032891511917114, "step": 32000}
{"episode_reward": 6.7378422741709905, "episode": 33.0, "batch_reward": 0.02317174438619986, "critic_loss": 0.011170105621014954, "actor_loss": -11.104194939136505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.886672258377075, "step": 33000}
{"episode_reward": 3.6953304435382455, "episode": 34.0, "batch_reward": 0.022592729537282138, "critic_loss": 0.009727605337218847, "actor_loss": -9.3152240087986, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.31763982772827, "step": 34000}
{"episode_reward": 6.525439799705204, "episode": 35.0, "batch_reward": 0.02184274191968143, "critic_loss": 0.01202167988740257, "actor_loss": -10.771310955405236, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.761738538742065, "step": 35000}
{"episode_reward": 4.655720662065538, "episode": 36.0, "batch_reward": 0.02139183400850743, "critic_loss": 0.007929391692508943, "actor_loss": -10.725109873652459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.715965270996094, "step": 36000}
{"episode_reward": 5.6511706045869206, "episode": 37.0, "batch_reward": 0.02119651148514822, "critic_loss": 0.014121812059544027, "actor_loss": -10.189051263809205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.808733463287354, "step": 37000}
{"episode_reward": 5.87995492975682, "episode": 38.0, "batch_reward": 0.020883981745224448, "critic_loss": 0.00713904057641048, "actor_loss": -9.65544055044651, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.914969205856323, "step": 38000}
{"episode_reward": 5.745572860878117, "episode": 39.0, "batch_reward": 0.020193154374836014, "critic_loss": 0.013845174674439477, "actor_loss": -11.407848598599434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.305347442626953, "step": 39000}
{"episode_reward": 3.4443910835469773, "episode": 40.0, "batch_reward": 0.02007522355020046, "critic_loss": 0.009637365046015475, "actor_loss": -11.111046538949013, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.349598169326782, "step": 40000}
{"episode_reward": 5.856707336880758, "episode": 41.0, "batch_reward": 0.019814809353556485, "critic_loss": 0.008115544582760776, "actor_loss": -11.243555376291274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.21220922470093, "step": 41000}
{"episode_reward": 6.862636266633634, "episode": 42.0, "batch_reward": 0.01901057231775485, "critic_loss": 0.011621339387187618, "actor_loss": -9.499956931114196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.794301986694336, "step": 42000}
{"episode_reward": 4.4931111589424955, "episode": 43.0, "batch_reward": 0.018973096057306973, "critic_loss": 0.009488699034322054, "actor_loss": -9.978038273215294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.108066082000732, "step": 43000}
{"episode_reward": 4.807636909825129, "episode": 44.0, "batch_reward": 0.01852359126927331, "critic_loss": 0.006975550611095969, "actor_loss": -10.217496098518371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.978185415267944, "step": 44000}
{"episode_reward": 5.9384554502728415, "episode": 45.0, "batch_reward": 0.018521880508866162, "critic_loss": 0.00942169171522255, "actor_loss": -10.94905330312252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.80733895301819, "step": 45000}
{"episode_reward": 4.864900434026458, "episode": 46.0, "batch_reward": 0.017844263549428432, "critic_loss": 0.009286292060627602, "actor_loss": -11.208229813218116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.072018146514893, "step": 46000}
{"episode_reward": 4.637668245107362, "episode": 47.0, "batch_reward": 0.01819385986402631, "critic_loss": 0.010036758280490176, "actor_loss": -10.333287847399712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.167470455169678, "step": 47000}
{"episode_reward": 5.197974646473016, "episode": 48.0, "batch_reward": 0.017386680556228384, "critic_loss": 0.007304897317051654, "actor_loss": -9.9512813154459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.750815391540527, "step": 48000}
{"episode_reward": 5.214835837466961, "episode": 49.0, "batch_reward": 0.01749278070963919, "critic_loss": 0.008834780080345809, "actor_loss": -10.788776638031006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.241430282592773, "step": 49000}
{"episode_reward": 5.3600497481190645, "episode": 50.0, "batch_reward": 0.016666359677445144, "critic_loss": 0.008654618345142808, "actor_loss": -10.040795293867587, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.444754600524902, "step": 50000}
{"episode_reward": 5.921232173202941, "episode": 51.0, "batch_reward": 0.016623088903725148, "critic_loss": 0.00764307262825605, "actor_loss": -9.264659279048443, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.234997272491455, "step": 51000}
{"episode_reward": 4.638061716053911, "episode": 52.0, "batch_reward": 0.016485669291112573, "critic_loss": 0.012647871238688822, "actor_loss": -11.11207303750515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.433431386947632, "step": 52000}
{"episode_reward": 3.9937084112997785, "episode": 53.0, "batch_reward": 0.016502147326013072, "critic_loss": 0.007170541398794739, "actor_loss": -10.869507980167866, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.663976907730103, "step": 53000}
{"episode_reward": 3.660991814163375, "episode": 54.0, "batch_reward": 0.015708992379019036, "critic_loss": 0.007952993555722059, "actor_loss": -9.89141517931223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.767318725585938, "step": 54000}
{"episode_reward": 6.156707333873602, "episode": 55.0, "batch_reward": 0.01604233772889711, "critic_loss": 0.006695413505367469, "actor_loss": -9.321220616340637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.50643754005432, "step": 55000}
{"episode_reward": 4.911461444878165, "episode": 56.0, "batch_reward": 0.015666653770022094, "critic_loss": 0.00834957639122149, "actor_loss": -9.740188657760621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.768153429031372, "step": 56000}
{"episode_reward": 4.977371527391946, "episode": 57.0, "batch_reward": 0.015226701172068716, "critic_loss": 0.006436446070074453, "actor_loss": -10.517904452502728, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.196088790893555, "step": 57000}
{"episode_reward": 4.646885516440241, "episode": 58.0, "batch_reward": 0.015447112881578505, "critic_loss": 0.006638142450654414, "actor_loss": -8.597105328023433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.83297896385193, "step": 58000}
{"episode_reward": 7.662959075189733, "episode": 59.0, "batch_reward": 0.014867007767083123, "critic_loss": 0.017175006128352835, "actor_loss": -10.946023464083671, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.749197483062744, "step": 59000}
{"episode_reward": 4.921867213240739, "episode": 60.0, "batch_reward": 0.015113909794948996, "critic_loss": 0.00399032074616116, "actor_loss": -10.427651870191097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.499885320663452, "step": 60000}
{"episode_reward": 7.425899553884257, "episode": 61.0, "batch_reward": 0.01494192201970145, "critic_loss": 0.0046853169456589966, "actor_loss": -9.787776516616345, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.17473244667053, "step": 61000}
{"episode_reward": 4.425081702548025, "episode": 62.0, "batch_reward": 0.014902583573246374, "critic_loss": 0.006447494345164159, "actor_loss": -8.535446955025195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.92002272605896, "step": 62000}
{"episode_reward": 4.012193300665039, "episode": 63.0, "batch_reward": 0.014548077224288136, "critic_loss": 0.005542285050280043, "actor_loss": -9.805439469456672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.729761600494385, "step": 63000}
{"episode_reward": 4.629442405657985, "episode": 64.0, "batch_reward": 0.014008129913127049, "critic_loss": 0.006161218414199539, "actor_loss": -9.516061855494977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.58055567741394, "step": 64000}
{"episode_reward": 4.986779367801398, "episode": 65.0, "batch_reward": 0.014080159894190728, "critic_loss": 0.005836485355044715, "actor_loss": -10.031604172289372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.597695112228394, "step": 65000}
{"episode_reward": 3.8462297099630804, "episode": 66.0, "batch_reward": 0.014193985245190562, "critic_loss": 0.006682937016157666, "actor_loss": -10.045276371896266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.38124418258667, "step": 66000}
{"episode_reward": 5.254359449664005, "episode": 67.0, "batch_reward": 0.013914852558402345, "critic_loss": 0.00645039968524361, "actor_loss": -11.052212132871151, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.58892846107483, "step": 67000}
{"episode_reward": 5.642052283204015, "episode": 68.0, "batch_reward": 0.013680221293587237, "critic_loss": 0.00864216020902677, "actor_loss": -9.40695798498392, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.125179290771484, "step": 68000}
{"episode_reward": 3.9161121585084557, "episode": 69.0, "batch_reward": 0.01340901699475944, "critic_loss": 0.0053892240533605215, "actor_loss": -9.290903458058834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.8537437915802, "step": 69000}
{"episode_reward": 3.9820503690621134, "episode": 70.0, "batch_reward": 0.013663944595027715, "critic_loss": 0.004985125585721107, "actor_loss": -10.220133742570876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.360415935516357, "step": 70000}
{"episode_reward": 4.721374335469419, "episode": 71.0, "batch_reward": 0.013693162197247147, "critic_loss": 0.00735296137635305, "actor_loss": -9.503025897741317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.51638960838318, "step": 71000}
{"episode_reward": 3.7783715473933217, "episode": 72.0, "batch_reward": 0.013445379890035837, "critic_loss": 0.004670728089360637, "actor_loss": -9.791609261393548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.436171293258667, "step": 72000}
{"episode_reward": 4.123750421817069, "episode": 73.0, "batch_reward": 0.01323565271217376, "critic_loss": 0.006002550623103162, "actor_loss": -10.008240973383188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.776161909103394, "step": 73000}
{"episode_reward": 4.369511673597018, "episode": 74.0, "batch_reward": 0.01288790673064068, "critic_loss": 0.00545398256376211, "actor_loss": -10.195268135786057, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.553129196166992, "step": 74000}
{"episode_reward": 4.779816471407687, "episode": 75.0, "batch_reward": 0.012719918132061138, "critic_loss": 0.005658570683794096, "actor_loss": -9.53186114153266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.682072401046753, "step": 75000}
{"episode_reward": 2.568737038029651, "episode": 76.0, "batch_reward": 0.012809553247410803, "critic_loss": 0.0057184798978705655, "actor_loss": -9.663822959005833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.996397018432617, "step": 76000}
{"episode_reward": 5.580768763426544, "episode": 77.0, "batch_reward": 0.012616505663609133, "critic_loss": 0.005980647563061211, "actor_loss": -9.71906601908803, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.134408473968506, "step": 77000}
{"episode_reward": 4.2409565964330715, "episode": 78.0, "batch_reward": 0.012899021229008214, "critic_loss": 0.005179334190543159, "actor_loss": -9.910762933582067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.815245628356934, "step": 78000}
{"episode_reward": 5.686793150562591, "episode": 79.0, "batch_reward": 0.012203832643572242, "critic_loss": 0.004798593211489788, "actor_loss": -9.37331651082635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.72805619239807, "step": 79000}
{"episode_reward": 6.4847755700930865, "episode": 80.0, "batch_reward": 0.012249022390926257, "critic_loss": 0.007458249357441673, "actor_loss": -9.158831432044506, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02856945991516, "step": 80000}
{"episode_reward": 5.605703725351232, "episode": 81.0, "batch_reward": 0.011978980872780084, "critic_loss": 0.004382747929281322, "actor_loss": -10.126232655853032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.354952573776245, "step": 81000}
{"episode_reward": 4.287237679042963, "episode": 82.0, "batch_reward": 0.01237777791148983, "critic_loss": 0.007674885796601302, "actor_loss": -9.98378014421463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.78761315345764, "step": 82000}
{"episode_reward": 5.8343883305323665, "episode": 83.0, "batch_reward": 0.011849654673598707, "critic_loss": 0.0056074928617526896, "actor_loss": -10.313103425770999, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.577194690704346, "step": 83000}
{"episode_reward": 4.938961765348201, "episode": 84.0, "batch_reward": 0.011719660878647118, "critic_loss": 0.007205808350496227, "actor_loss": -10.065618668407202, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.676318168640137, "step": 84000}
{"episode_reward": 6.770672617400463, "episode": 85.0, "batch_reward": 0.012083274510223419, "critic_loss": 0.00534122543506237, "actor_loss": -9.513222466766834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.223808526992798, "step": 85000}
{"episode_reward": 4.770262644805495, "episode": 86.0, "batch_reward": 0.011765319767408073, "critic_loss": 0.0046168693953804905, "actor_loss": -9.854375990271569, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.943971157073975, "step": 86000}
{"episode_reward": 6.024270298593861, "episode": 87.0, "batch_reward": 0.011874699563486501, "critic_loss": 0.004832159677040181, "actor_loss": -9.630285278022289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.369920015335083, "step": 87000}
{"episode_reward": 4.89327981011023, "episode": 88.0, "batch_reward": 0.01185491523402743, "critic_loss": 0.010548677326318284, "actor_loss": -9.561366783052684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.89817523956299, "step": 88000}
{"episode_reward": 6.560432702991071, "episode": 89.0, "batch_reward": 0.011875172471627593, "critic_loss": 0.004722291751932062, "actor_loss": -8.820729124426842, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.362889289855957, "step": 89000}
{"episode_reward": 5.250514078067331, "episode": 90.0, "batch_reward": 0.011594846701715142, "critic_loss": 0.005581288286797644, "actor_loss": -9.989247554421425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.853696823120117, "step": 90000}
{"episode_reward": 4.923645344848634, "episode": 91.0, "batch_reward": 0.011860094372415916, "critic_loss": 0.004484990793411271, "actor_loss": -8.92852012309432, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.086971282958984, "step": 91000}
{"episode_reward": 3.646481728314165, "episode": 92.0, "batch_reward": 0.011618987425928935, "critic_loss": 0.005593134544891655, "actor_loss": -10.534281843781471, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.977635622024536, "step": 92000}
{"episode_reward": 6.482956098714958, "episode": 93.0, "batch_reward": 0.011405203792033717, "critic_loss": 0.004769591598189436, "actor_loss": -9.287293800204992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.68969178199768, "step": 93000}
{"episode_reward": 5.704915635374206, "episode": 94.0, "batch_reward": 0.011274143730057404, "critic_loss": 0.005581071642271127, "actor_loss": -10.395287799358368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.59845209121704, "step": 94000}
{"episode_reward": 4.547460867741683, "episode": 95.0, "batch_reward": 0.0112722089975141, "critic_loss": 0.0038630426878953584, "actor_loss": -10.215649577111005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.441322088241577, "step": 95000}
{"episode_reward": 6.892545668592127, "episode": 96.0, "batch_reward": 0.011273110729642212, "critic_loss": 0.005675520246251836, "actor_loss": -9.940694699510932, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.28549838066101, "step": 96000}
{"episode_reward": 5.3049638207861785, "episode": 97.0, "batch_reward": 0.011327492473414167, "critic_loss": 0.005011624805745669, "actor_loss": -9.790480943471193, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.671401262283325, "step": 97000}
{"episode_reward": 5.828124227607359, "episode": 98.0, "batch_reward": 0.011133416212163865, "critic_loss": 0.005619208594223892, "actor_loss": -10.235853149324656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.794963836669922, "step": 98000}
{"episode_reward": 4.79401319487927, "episode": 99.0, "batch_reward": 0.010943934565875679, "critic_loss": 0.004567358689360844, "actor_loss": -9.736942398324608, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.506954669952393, "step": 99000}
{"episode_reward": 6.561654429341163, "episode": 100.0, "batch_reward": 0.01108727923478, "critic_loss": 0.004170564982341602, "actor_loss": -9.562486623093486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.840839624404907, "step": 100000}
{"episode_reward": 6.7011778783379565, "episode": 101.0, "batch_reward": 0.010944919089088217, "critic_loss": 0.008461205670449999, "actor_loss": -10.411060513302683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.97758412361145, "step": 101000}
{"episode_reward": 4.497692663030742, "episode": 102.0, "batch_reward": 0.011051670904736965, "critic_loss": 0.0045805687407773805, "actor_loss": -10.10887961037457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.513949394226074, "step": 102000}
{"episode_reward": 4.8494261668895815, "episode": 103.0, "batch_reward": 0.011082155251409858, "critic_loss": 0.0042954692429775605, "actor_loss": -9.92248505346477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.937061309814453, "step": 103000}
{"episode_reward": 4.517567796568789, "episode": 104.0, "batch_reward": 0.010716983371414244, "critic_loss": 0.005154299324822205, "actor_loss": -9.770345340415835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.41572594642639, "step": 104000}
{"episode_reward": 3.5267175674353535, "episode": 105.0, "batch_reward": 0.010984279815340415, "critic_loss": 0.004828045411479252, "actor_loss": -8.921736311078071, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.19423246383667, "step": 105000}
{"episode_reward": 4.837104310863522, "episode": 106.0, "batch_reward": 0.01074390627979301, "critic_loss": 0.0061584285355202155, "actor_loss": -8.292102331787348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.54397416114807, "step": 106000}
{"episode_reward": 3.7385579287197714, "episode": 107.0, "batch_reward": 0.010706403818447143, "critic_loss": 0.00806989922952198, "actor_loss": -9.276422204047442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.696277379989624, "step": 107000}
{"episode_reward": 4.936647758603588, "episode": 108.0, "batch_reward": 0.010550896700005979, "critic_loss": 0.003221155649960565, "actor_loss": -10.058821907445788, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.365238189697266, "step": 108000}
{"episode_reward": 4.092135088792758, "episode": 109.0, "batch_reward": 0.010325015966081992, "critic_loss": 0.0043235963954648465, "actor_loss": -9.986328087151051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.909470319747925, "step": 109000}
{"episode_reward": 4.918073998413084, "episode": 110.0, "batch_reward": 0.010307176888687536, "critic_loss": 0.005143239509830892, "actor_loss": -9.916319131955504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.149176359176636, "step": 110000}
{"episode_reward": 5.8554996537844985, "episode": 111.0, "batch_reward": 0.010350335682975128, "critic_loss": 0.0038063171014364344, "actor_loss": -9.925158194437623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.73965764045715, "step": 111000}
{"episode_reward": 4.672115953729505, "episode": 112.0, "batch_reward": 0.010459082549670711, "critic_loss": 0.004419557392800926, "actor_loss": -9.909896711319686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.972416639328003, "step": 112000}
{"episode_reward": 4.246531858448323, "episode": 113.0, "batch_reward": 0.010132003386039286, "critic_loss": 0.0037578310894896276, "actor_loss": -10.03250511354208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.96237540245056, "step": 113000}
{"episode_reward": 3.7141094303929134, "episode": 114.0, "batch_reward": 0.010126518525648862, "critic_loss": 0.005417996139141906, "actor_loss": -10.153380678579211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.12446093559265, "step": 114000}
{"episode_reward": 5.293814726656848, "episode": 115.0, "batch_reward": 0.01021539675188251, "critic_loss": 0.003874264503916493, "actor_loss": -9.151005935624243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.92677640914917, "step": 115000}
{"episode_reward": 5.675163344882858, "episode": 116.0, "batch_reward": 0.010158850139938294, "critic_loss": 0.003695222583846771, "actor_loss": -9.849746130630374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.297780990600586, "step": 116000}
{"episode_reward": 6.0167532550084815, "episode": 117.0, "batch_reward": 0.010288349719485269, "critic_loss": 0.005106571651231207, "actor_loss": -10.12086647310853, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.451778173446655, "step": 117000}
{"episode_reward": 6.394875661327676, "episode": 118.0, "batch_reward": 0.010291250442853197, "critic_loss": 0.004707343898895488, "actor_loss": -10.47936160378158, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092512845993042, "step": 118000}
{"episode_reward": 4.4475669766712, "episode": 119.0, "batch_reward": 0.010028232051758096, "critic_loss": 0.004392326555964246, "actor_loss": -9.039005395799876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.74649405479431, "step": 119000}
{"episode_reward": 6.570546995146315, "episode": 120.0, "batch_reward": 0.009848639546195045, "critic_loss": 0.003710193639031786, "actor_loss": -8.655684472426772, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.204657554626465, "step": 120000}
{"episode_reward": 5.331053380999795, "episode": 121.0, "batch_reward": 0.010051120000425726, "critic_loss": 0.005092238203018496, "actor_loss": -8.538083281725646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.25478792190552, "step": 121000}
{"episode_reward": 7.061489735001675, "episode": 122.0, "batch_reward": 0.01003863794519566, "critic_loss": 0.004477571073213767, "actor_loss": -8.894243861407041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.0189471244812, "step": 122000}
{"episode_reward": 5.736073390276281, "episode": 123.0, "batch_reward": 0.00997422435390763, "critic_loss": 0.003797134625077888, "actor_loss": -9.388827196136116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.771360397338867, "step": 123000}
{"episode_reward": 4.896325039515628, "episode": 124.0, "batch_reward": 0.009791018973104656, "critic_loss": 0.004445270840042212, "actor_loss": -9.582057248771191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.303728580474854, "step": 124000}
{"episode_reward": 4.230227587559224, "episode": 125.0, "batch_reward": 0.009740375278051943, "critic_loss": 0.003134555268814438, "actor_loss": -9.210604505077004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.56176257133484, "step": 125000}
{"episode_reward": 4.264169624910242, "episode": 126.0, "batch_reward": 0.009610160351498052, "critic_loss": 0.005179344383053831, "actor_loss": -9.569419297665357, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.56180739402771, "step": 126000}
{"episode_reward": 4.483660591817105, "episode": 127.0, "batch_reward": 0.009752786689437926, "critic_loss": 0.0034408381667162756, "actor_loss": -9.947056424915791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.309351444244385, "step": 127000}
{"episode_reward": 4.741399118393519, "episode": 128.0, "batch_reward": 0.009618708084570243, "critic_loss": 0.0042078851362020945, "actor_loss": -10.36640761436522, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.188766479492188, "step": 128000}
{"episode_reward": 5.670528659043189, "episode": 129.0, "batch_reward": 0.009708210741635411, "critic_loss": 0.005384290174661146, "actor_loss": -11.117207999244332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18503165245056, "step": 129000}
{"episode_reward": 6.233341965994861, "episode": 130.0, "batch_reward": 0.00953108282876201, "critic_loss": 0.003154278428708494, "actor_loss": -9.491874241247773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.09813117980957, "step": 130000}
{"episode_reward": 4.945277215165624, "episode": 131.0, "batch_reward": 0.009650320262182504, "critic_loss": 0.004722835084779945, "actor_loss": -10.24726273009181, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.997764110565186, "step": 131000}
{"episode_reward": 4.914381657058847, "episode": 132.0, "batch_reward": 0.009720710695721209, "critic_loss": 0.0042274128892095175, "actor_loss": -9.124971633911132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.984143495559692, "step": 132000}
{"episode_reward": 4.791346041017022, "episode": 133.0, "batch_reward": 0.009533345813862979, "critic_loss": 0.004073932563864219, "actor_loss": -10.611722754493355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.383026599884033, "step": 133000}
{"episode_reward": 3.306001645000727, "episode": 134.0, "batch_reward": 0.009624485770473257, "critic_loss": 0.0036847352382173995, "actor_loss": -10.73033955513686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.823372840881348, "step": 134000}
{"episode_reward": 9.178562786023791, "episode": 135.0, "batch_reward": 0.009622344695962966, "critic_loss": 0.003575185138157394, "actor_loss": -9.909392218254506, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97730302810669, "step": 135000}
{"episode_reward": 7.4801593484941185, "episode": 136.0, "batch_reward": 0.009348210409283637, "critic_loss": 0.0030830424513842445, "actor_loss": -9.970416621170939, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981847286224365, "step": 136000}
{"episode_reward": 4.1902770948160395, "episode": 137.0, "batch_reward": 0.00939600623678416, "critic_loss": 0.004178166866455286, "actor_loss": -9.16672172984481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.7437162399292, "step": 137000}
{"episode_reward": 6.1061601893911925, "episode": 138.0, "batch_reward": 0.009726757847703993, "critic_loss": 0.003246711919142399, "actor_loss": -8.75404611721635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.09128737449646, "step": 138000}
{"episode_reward": 5.910540258121608, "episode": 139.0, "batch_reward": 0.009559423100436107, "critic_loss": 0.0033593781174276957, "actor_loss": -9.431405468553304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.84635877609253, "step": 139000}
{"episode_reward": 3.732236443088925, "episode": 140.0, "batch_reward": 0.009243408331647515, "critic_loss": 0.004698318903654581, "actor_loss": -9.606781196027994, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.564177751541138, "step": 140000}
{"episode_reward": 6.090591689824264, "episode": 141.0, "batch_reward": 0.009313175718532875, "critic_loss": 0.0035954693892417708, "actor_loss": -8.78975880086422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.62716484069824, "step": 141000}
{"episode_reward": 3.3412682756545062, "episode": 142.0, "batch_reward": 0.00946437524096109, "critic_loss": 0.004089169005426811, "actor_loss": -8.561958092525602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.865989446640015, "step": 142000}
{"episode_reward": 4.328804928966155, "episode": 143.0, "batch_reward": 0.00934066016995348, "critic_loss": 0.00290098594531446, "actor_loss": -9.354258369848132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.79586362838745, "step": 143000}
{"episode_reward": 4.961330024000751, "episode": 144.0, "batch_reward": 0.00947554157092236, "critic_loss": 0.0034669603669462957, "actor_loss": -8.736815384529532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.53894829750061, "step": 144000}
{"episode_reward": 4.774322183925296, "episode": 145.0, "batch_reward": 0.009228759149555116, "critic_loss": 0.0037100467846321408, "actor_loss": -8.471369695149361, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22186517715454, "step": 145000}
{"episode_reward": 3.891665901900156, "episode": 146.0, "batch_reward": 0.009179014244582505, "critic_loss": 0.003238300096229068, "actor_loss": -9.658838817186654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.000530242919922, "step": 146000}
{"episode_reward": 7.005016466822916, "episode": 147.0, "batch_reward": 0.00897185384761542, "critic_loss": 0.003067497353818908, "actor_loss": -9.18944141639769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.95919394493103, "step": 147000}
{"episode_reward": 6.094836078081035, "episode": 148.0, "batch_reward": 0.00960663234302774, "critic_loss": 0.004125015370347682, "actor_loss": -9.364707227811218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.52965259552002, "step": 148000}
{"episode_reward": 3.9542124472175386, "episode": 149.0, "batch_reward": 0.009151396295288577, "critic_loss": 0.0032609845194310765, "actor_loss": -8.656427744440734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.28585433959961, "step": 149000}
{"episode_reward": 6.382934860693185, "episode": 150.0, "batch_reward": 0.009040677293436602, "critic_loss": 0.005922753291510162, "actor_loss": -9.155900524027645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
