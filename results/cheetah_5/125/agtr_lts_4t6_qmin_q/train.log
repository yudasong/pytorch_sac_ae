{"episode_reward": 0.0, "episode": 1.0, "duration": 13.795055866241455, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.1891591548919678, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2851381297408044, "critic_loss": 0.15130747116359325, "actor_loss": -47.15682050102756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 70.47651672363281, "step": 3000}
{"episode_reward": 72.38648919067191, "episode": 4.0, "batch_reward": 0.20660932378470898, "critic_loss": 0.5861029116846621, "actor_loss": -37.51483791732788, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.3670597076416, "step": 4000}
{"episode_reward": 84.61088590863837, "episode": 5.0, "batch_reward": 0.1883278638124466, "critic_loss": 0.18183835914731025, "actor_loss": -36.419244224548336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.710095167160034, "step": 5000}
{"episode_reward": 232.0001636614552, "episode": 6.0, "batch_reward": 0.19544881968200206, "critic_loss": 0.2195462051331997, "actor_loss": -37.1556358795166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.091580629348755, "step": 6000}
{"episode_reward": 185.36846037357338, "episode": 7.0, "batch_reward": 0.18790058191120623, "critic_loss": 0.22548035129159688, "actor_loss": -35.69737187576294, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.87175679206848, "step": 7000}
{"episode_reward": 67.77034521972315, "episode": 8.0, "batch_reward": 0.17817249662429094, "critic_loss": 0.22266939778625966, "actor_loss": -32.898583484649656, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.376965522766113, "step": 8000}
{"episode_reward": 121.88627745938227, "episode": 9.0, "batch_reward": 0.1770045060813427, "critic_loss": 0.26841046318411826, "actor_loss": -31.838571968078615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.367807149887085, "step": 9000}
{"episode_reward": 329.90521548957304, "episode": 10.0, "batch_reward": 0.19549276426434517, "critic_loss": 0.24629147369414567, "actor_loss": -33.42259778213501, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.84894633293152, "step": 10000}
{"episode_reward": 335.64594688247206, "episode": 11.0, "batch_reward": 0.20639063037931918, "critic_loss": 0.23811521453410386, "actor_loss": -34.36806659698486, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.2859411239624, "step": 11000}
{"episode_reward": 275.253275159432, "episode": 12.0, "batch_reward": 0.2032321574985981, "critic_loss": 0.20316799277812242, "actor_loss": -33.42544538497925, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.3227219581604, "step": 12000}
{"episode_reward": 45.689450952730745, "episode": 13.0, "batch_reward": 0.19403354822099209, "critic_loss": 0.21093944835662842, "actor_loss": -31.80176634979248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.26907753944397, "step": 13000}
{"episode_reward": 100.82524305215823, "episode": 14.0, "batch_reward": 0.19306913839280607, "critic_loss": 0.21290336187928915, "actor_loss": -31.366473575592043, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.123322248458862, "step": 14000}
{"episode_reward": 399.07876557645517, "episode": 15.0, "batch_reward": 0.20789888551831245, "critic_loss": 0.23118547317385674, "actor_loss": -32.35576842880249, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.78098750114441, "step": 15000}
{"episode_reward": 400.33750678371604, "episode": 16.0, "batch_reward": 0.2224330404251814, "critic_loss": 0.23803655543923377, "actor_loss": -33.34613826751709, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.049986124038696, "step": 16000}
{"episode_reward": 456.17821268500614, "episode": 17.0, "batch_reward": 0.23696556554734707, "critic_loss": 0.2420398503690958, "actor_loss": -34.593724376678466, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.33633518218994, "step": 17000}
{"episode_reward": 460.5586351460494, "episode": 18.0, "batch_reward": 0.2485362683981657, "critic_loss": 0.22234718368947506, "actor_loss": -35.33842217254639, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.81505298614502, "step": 18000}
{"episode_reward": 323.74850418248843, "episode": 19.0, "batch_reward": 0.25449952121078967, "critic_loss": 0.2116630407869816, "actor_loss": -35.28416549301147, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.29966115951538, "step": 19000}
{"episode_reward": 478.15671026809815, "episode": 20.0, "batch_reward": 0.26594330202043054, "critic_loss": 0.20286390188336373, "actor_loss": -35.975754302978515, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.517318725585938, "step": 20000}
{"episode_reward": 492.26436093488195, "episode": 21.0, "batch_reward": 0.2749676327854395, "critic_loss": 0.20906334705650806, "actor_loss": -36.52299143218994, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.92237067222595, "step": 21000}
{"episode_reward": 455.4704387094273, "episode": 22.0, "batch_reward": 0.28613807548582554, "critic_loss": 0.19409163951873779, "actor_loss": -37.52871654129029, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.282557487487793, "step": 22000}
{"episode_reward": 496.5605508238226, "episode": 23.0, "batch_reward": 0.29555811332166193, "critic_loss": 0.19106955986469984, "actor_loss": -38.20210642623901, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.14288568496704, "step": 23000}
{"episode_reward": 532.9384011332845, "episode": 24.0, "batch_reward": 0.3054373714029789, "critic_loss": 0.19320635337382555, "actor_loss": -38.6344843788147, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.84729790687561, "step": 24000}
{"episode_reward": 509.2146058987007, "episode": 25.0, "batch_reward": 0.3139259402155876, "critic_loss": 0.20092603519558908, "actor_loss": -39.38565772247314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.064847230911255, "step": 25000}
{"episode_reward": 598.1060534231866, "episode": 26.0, "batch_reward": 0.32329141841828823, "critic_loss": 0.23651718533784152, "actor_loss": -39.95953401565552, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.42084813117981, "step": 26000}
{"episode_reward": 561.0558331412217, "episode": 27.0, "batch_reward": 0.33013349962234495, "critic_loss": 0.26915407133102415, "actor_loss": -40.219181327819825, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.01789164543152, "step": 27000}
{"episode_reward": 187.60714675577515, "episode": 28.0, "batch_reward": 0.3264283955693245, "critic_loss": 0.2889070778489113, "actor_loss": -39.47777262878418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.27518320083618, "step": 28000}
{"episode_reward": 233.73049027832437, "episode": 29.0, "batch_reward": 0.32337441650033, "critic_loss": 0.29087705160677435, "actor_loss": -38.822066402435304, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.731961727142334, "step": 29000}
{"episode_reward": 405.9234384905289, "episode": 30.0, "batch_reward": 0.32794904348254206, "critic_loss": 0.2676672661602497, "actor_loss": -39.11117803573608, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.612136363983154, "step": 30000}
{"episode_reward": 510.19993219977925, "episode": 31.0, "batch_reward": 0.33503077751398086, "critic_loss": 0.257242334485054, "actor_loss": -39.541915016174315, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.42888021469116, "step": 31000}
{"episode_reward": 584.118730045726, "episode": 32.0, "batch_reward": 0.3417957381606102, "critic_loss": 0.2637986501902342, "actor_loss": -40.16506551361084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.039905071258545, "step": 32000}
{"episode_reward": 472.9785184727725, "episode": 33.0, "batch_reward": 0.3466106888949871, "critic_loss": 0.2635804850310087, "actor_loss": -40.416403633117675, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.182142972946167, "step": 33000}
{"episode_reward": 599.8423013668314, "episode": 34.0, "batch_reward": 0.351321827173233, "critic_loss": 0.2683891731351614, "actor_loss": -41.069421813964844, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.30179738998413, "step": 34000}
{"episode_reward": 232.34380557530366, "episode": 35.0, "batch_reward": 0.3496880788207054, "critic_loss": 0.24937581955641508, "actor_loss": -40.369425506591796, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.285579919815063, "step": 35000}
{"episode_reward": 546.7247159810498, "episode": 36.0, "batch_reward": 0.35399052140116694, "critic_loss": 0.23192622390389442, "actor_loss": -41.01643419647217, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.368215799331665, "step": 36000}
{"episode_reward": 521.5122846393881, "episode": 37.0, "batch_reward": 0.35892258325219156, "critic_loss": 0.23948768300563097, "actor_loss": -41.26522849273682, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.530829668045044, "step": 37000}
{"episode_reward": 415.1931075473699, "episode": 38.0, "batch_reward": 0.3621365951299667, "critic_loss": 0.2263361957371235, "actor_loss": -41.04347648620605, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.930165767669678, "step": 38000}
{"episode_reward": 595.8805049311072, "episode": 39.0, "batch_reward": 0.3665361271202564, "critic_loss": 0.21868621646612882, "actor_loss": -41.11816612243652, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.498175382614136, "step": 39000}
{"episode_reward": 415.3139293931436, "episode": 40.0, "batch_reward": 0.3695043828189373, "critic_loss": 0.23348682156950235, "actor_loss": -41.125562187194824, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.311931371688843, "step": 40000}
{"episode_reward": 560.7917780811008, "episode": 41.0, "batch_reward": 0.3739693594574928, "critic_loss": 0.21659696908295153, "actor_loss": -41.452630416870115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.22239017486572, "step": 41000}
{"episode_reward": 603.0590183708598, "episode": 42.0, "batch_reward": 0.37998780313134195, "critic_loss": 0.2223641385063529, "actor_loss": -41.901937599182126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.960877418518066, "step": 42000}
{"episode_reward": 599.7959489072856, "episode": 43.0, "batch_reward": 0.38405787155032156, "critic_loss": 0.22301765000075102, "actor_loss": -42.37532009124756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.005295038223267, "step": 43000}
{"episode_reward": 562.1842251043029, "episode": 44.0, "batch_reward": 0.38836098048090933, "critic_loss": 0.22142179955542088, "actor_loss": -42.78322968292236, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.135640144348145, "step": 44000}
{"episode_reward": 591.4821413121053, "episode": 45.0, "batch_reward": 0.39332343885302545, "critic_loss": 0.2387885178923607, "actor_loss": -42.83921224975586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.567928791046143, "step": 45000}
{"episode_reward": 634.6701307160731, "episode": 46.0, "batch_reward": 0.3980587192773819, "critic_loss": 0.2896589143425226, "actor_loss": -43.50299161529541, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.36872172355652, "step": 46000}
{"episode_reward": 580.5754092918139, "episode": 47.0, "batch_reward": 0.40303947868943213, "critic_loss": 0.3765826025009155, "actor_loss": -43.87852812957764, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.478954076766968, "step": 47000}
{"episode_reward": 595.3926502316044, "episode": 48.0, "batch_reward": 0.40668008252978327, "critic_loss": 0.47551412247121333, "actor_loss": -44.607368522644045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.22661328315735, "step": 48000}
{"episode_reward": 582.226414727772, "episode": 49.0, "batch_reward": 0.4107488317787647, "critic_loss": 0.6801146170347929, "actor_loss": -44.85892319488526, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.893832445144653, "step": 49000}
{"episode_reward": 614.4990356780391, "episode": 50.0, "batch_reward": 0.41290837034583094, "critic_loss": 0.83595926271379, "actor_loss": -45.169807075500486, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.280028820037842, "step": 50000}
{"episode_reward": 561.6687269240037, "episode": 51.0, "batch_reward": 0.417982362806797, "critic_loss": 0.8948411465585232, "actor_loss": -45.833517616271976, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.687463998794556, "step": 51000}
{"episode_reward": 608.5282349805675, "episode": 52.0, "batch_reward": 0.41700134658813476, "critic_loss": 1.2157892194986344, "actor_loss": -46.07693741607666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.274388551712036, "step": 52000}
{"episode_reward": 16.28999228849371, "episode": 53.0, "batch_reward": 0.4142592114508152, "critic_loss": 1.4811344879865647, "actor_loss": -46.85948266601562, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.224185705184937, "step": 53000}
{"episode_reward": 589.9818473461366, "episode": 54.0, "batch_reward": 0.4120659231841564, "critic_loss": 2.085409011363983, "actor_loss": -47.10476781463623, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.449101209640503, "step": 54000}
{"episode_reward": 44.05752627477835, "episode": 55.0, "batch_reward": 0.40579120552539827, "critic_loss": 2.8262016468048095, "actor_loss": -48.16119941711426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.411871910095215, "step": 55000}
{"episode_reward": 18.790434422745562, "episode": 56.0, "batch_reward": 0.3980952466726303, "critic_loss": 4.343391721844673, "actor_loss": -49.85665853118896, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.32845115661621, "step": 56000}
{"episode_reward": 14.857791198887723, "episode": 57.0, "batch_reward": 0.3919252662360668, "critic_loss": 7.799046276330948, "actor_loss": -52.08841747283935, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.157204151153564, "step": 57000}
{"episode_reward": 12.52374271930799, "episode": 58.0, "batch_reward": 0.38428538540005686, "critic_loss": 12.077114070415497, "actor_loss": -54.43797592163086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.90622115135193, "step": 58000}
{"episode_reward": 11.183300461676328, "episode": 59.0, "batch_reward": 0.378319638967514, "critic_loss": 12.89988816857338, "actor_loss": -58.28400885772705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.745657205581665, "step": 59000}
{"episode_reward": 26.53738653382354, "episode": 60.0, "batch_reward": 0.3736651463508606, "critic_loss": 11.918346859931946, "actor_loss": -63.098097763061524, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.26330256462097, "step": 60000}
{"episode_reward": 69.48925587140613, "episode": 61.0, "batch_reward": 0.3677700167298317, "critic_loss": 12.24102212190628, "actor_loss": -66.34803254699708, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.956472635269165, "step": 61000}
{"episode_reward": 34.82505899397306, "episode": 62.0, "batch_reward": 0.3618448347747326, "critic_loss": 10.729172892570496, "actor_loss": -68.71534386444092, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.222132682800293, "step": 62000}
{"episode_reward": 25.717937908621654, "episode": 63.0, "batch_reward": 0.3557516870498657, "critic_loss": 9.341766400814056, "actor_loss": -70.87192328643799, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.070616483688354, "step": 63000}
{"episode_reward": 13.474143311852366, "episode": 64.0, "batch_reward": 0.3509263003766537, "critic_loss": 8.49698801612854, "actor_loss": -73.37941373443604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.364444971084595, "step": 64000}
{"episode_reward": 33.24680844203663, "episode": 65.0, "batch_reward": 0.3462775274515152, "critic_loss": 7.404578392505646, "actor_loss": -74.1648508682251, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.395329475402832, "step": 65000}
{"episode_reward": 9.239383122282995, "episode": 66.0, "batch_reward": 0.3413350510895252, "critic_loss": 6.816231596231461, "actor_loss": -76.37133550262452, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.41752600669861, "step": 66000}
{"episode_reward": 13.628126956622106, "episode": 67.0, "batch_reward": 0.3360290455520153, "critic_loss": 6.379635199785232, "actor_loss": -78.5234489364624, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.30478858947754, "step": 67000}
{"episode_reward": 12.982303024235229, "episode": 68.0, "batch_reward": 0.3301912838816643, "critic_loss": 5.7196662313938145, "actor_loss": -75.11877073669433, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.32450842857361, "step": 68000}
{"episode_reward": 10.479481834375948, "episode": 69.0, "batch_reward": 0.32709840711951255, "critic_loss": 5.031177126169204, "actor_loss": -75.70556287384034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.23241138458252, "step": 69000}
{"episode_reward": 23.33246362014419, "episode": 70.0, "batch_reward": 0.3234042246043682, "critic_loss": 4.503397448062897, "actor_loss": -75.55657936096192, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.58504605293274, "step": 70000}
{"episode_reward": 92.2063790022984, "episode": 71.0, "batch_reward": 0.3199495160579681, "critic_loss": 3.8942658038139344, "actor_loss": -72.1952141418457, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.20584487915039, "step": 71000}
{"episode_reward": 41.14422176052159, "episode": 72.0, "batch_reward": 0.31779028016328814, "critic_loss": 3.387430965423584, "actor_loss": -71.43710941314697, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.40575909614563, "step": 72000}
{"episode_reward": 283.48083828197167, "episode": 73.0, "batch_reward": 0.3168444886058569, "critic_loss": 2.968575077533722, "actor_loss": -70.03433547210693, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.099650859832764, "step": 73000}
{"episode_reward": 188.0251666310742, "episode": 74.0, "batch_reward": 0.31650873263180257, "critic_loss": 2.539346485376358, "actor_loss": -70.40136376190186, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.15697193145752, "step": 74000}
{"episode_reward": 314.87180190402523, "episode": 75.0, "batch_reward": 0.31299308335781095, "critic_loss": 2.2781991810798643, "actor_loss": -69.2233966064453, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.503466844558716, "step": 75000}
{"episode_reward": 354.00739076550883, "episode": 76.0, "batch_reward": 0.3158652062565088, "critic_loss": 2.0886865926980973, "actor_loss": -67.86005628967285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.21416664123535, "step": 76000}
{"episode_reward": 312.0727908746401, "episode": 77.0, "batch_reward": 0.3174637622088194, "critic_loss": 2.1001469869613647, "actor_loss": -66.53939595031738, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.279503107070923, "step": 77000}
{"episode_reward": 396.51276258584994, "episode": 78.0, "batch_reward": 0.3181202363669872, "critic_loss": 1.9223866410255432, "actor_loss": -66.11486961364746, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.870779752731323, "step": 78000}
{"episode_reward": 474.4646200925287, "episode": 79.0, "batch_reward": 0.31859221078455446, "critic_loss": 1.9149030348062515, "actor_loss": -62.30728677368164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.2097909450531, "step": 79000}
{"episode_reward": 208.65698311127363, "episode": 80.0, "batch_reward": 0.31752714529633524, "critic_loss": 1.810272742331028, "actor_loss": -62.48176095581055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.14459538459778, "step": 80000}
{"episode_reward": 314.47193696383385, "episode": 81.0, "batch_reward": 0.3164782927930355, "critic_loss": 1.7003837105035782, "actor_loss": -61.11341403198242, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.39632987976074, "step": 81000}
{"episode_reward": 264.06771190890424, "episode": 82.0, "batch_reward": 0.31629010662436485, "critic_loss": 1.606006679713726, "actor_loss": -61.67687122344971, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.326669454574585, "step": 82000}
{"episode_reward": 487.1918933570004, "episode": 83.0, "batch_reward": 0.319183348685503, "critic_loss": 1.6560199109315872, "actor_loss": -59.14825994873047, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.458306074142456, "step": 83000}
{"episode_reward": 324.9586167326075, "episode": 84.0, "batch_reward": 0.3189040420949459, "critic_loss": 1.4540168586969375, "actor_loss": -59.33585923004151, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.331626415252686, "step": 84000}
{"episode_reward": 234.4357931806631, "episode": 85.0, "batch_reward": 0.3182778328210115, "critic_loss": 1.4210759235620498, "actor_loss": -57.9556647567749, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.188204288482666, "step": 85000}
{"episode_reward": 392.74747218537755, "episode": 86.0, "batch_reward": 0.3215921545177698, "critic_loss": 1.3391512221097945, "actor_loss": -56.04112525177002, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.333193063735962, "step": 86000}
{"episode_reward": 608.1333967954063, "episode": 87.0, "batch_reward": 0.32316506795585154, "critic_loss": 1.2656193507909774, "actor_loss": -56.1879411315918, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.373969554901123, "step": 87000}
{"episode_reward": 559.7506075642025, "episode": 88.0, "batch_reward": 0.3264066095352173, "critic_loss": 1.2162971799373627, "actor_loss": -55.36355846405029, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.103076457977295, "step": 88000}
{"episode_reward": 617.3811634112899, "episode": 89.0, "batch_reward": 0.329218766361475, "critic_loss": 1.107189237833023, "actor_loss": -55.18171570587158, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.405402660369873, "step": 89000}
{"episode_reward": 639.6130746780659, "episode": 90.0, "batch_reward": 0.331401119351387, "critic_loss": 1.0539725611805917, "actor_loss": -55.130139533996584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.542423248291016, "step": 90000}
{"episode_reward": 616.1405855924128, "episode": 91.0, "batch_reward": 0.33528769955039023, "critic_loss": 0.9459641489386559, "actor_loss": -54.000194244384765, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.121476888656616, "step": 91000}
{"episode_reward": 409.20485439360664, "episode": 92.0, "batch_reward": 0.33667803651094436, "critic_loss": 0.8923596438467503, "actor_loss": -53.86801226043701, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.301011562347412, "step": 92000}
{"episode_reward": 557.1373916981206, "episode": 93.0, "batch_reward": 0.3376634427607059, "critic_loss": 0.8225098446011543, "actor_loss": -53.18738928985596, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.77666473388672, "step": 93000}
{"episode_reward": 578.3536179588742, "episode": 94.0, "batch_reward": 0.3417398273050785, "critic_loss": 0.7844772240519524, "actor_loss": -53.012430671691895, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.187825918197632, "step": 94000}
{"episode_reward": 600.6554399559883, "episode": 95.0, "batch_reward": 0.3432231482565403, "critic_loss": 0.745708842843771, "actor_loss": -52.98610776519775, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.382176637649536, "step": 95000}
{"episode_reward": 605.119563839828, "episode": 96.0, "batch_reward": 0.34807962587475777, "critic_loss": 0.7010857307314873, "actor_loss": -52.630966133117674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.39750647544861, "step": 96000}
{"episode_reward": 643.6216793172355, "episode": 97.0, "batch_reward": 0.3518465246260166, "critic_loss": 0.6512812537252903, "actor_loss": -52.554621925354006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.46740746498108, "step": 97000}
{"episode_reward": 654.9310284893405, "episode": 98.0, "batch_reward": 0.35315452671051023, "critic_loss": 0.6031793049573898, "actor_loss": -51.817607917785644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.98196005821228, "step": 98000}
{"episode_reward": 636.997709453505, "episode": 99.0, "batch_reward": 0.3558043918609619, "critic_loss": 0.5906437378525734, "actor_loss": -51.45278515625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.499719381332397, "step": 99000}
{"episode_reward": 663.0931749647924, "episode": 100.0, "batch_reward": 0.35856862369179726, "critic_loss": 0.56213016051054, "actor_loss": -51.00108540344238, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.250574111938477, "step": 100000}
{"episode_reward": 239.7524999693831, "episode": 101.0, "batch_reward": 0.35935729315876963, "critic_loss": 0.5604994736611844, "actor_loss": -50.87702870178223, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.2719361782074, "step": 101000}
{"episode_reward": 623.3755325351831, "episode": 102.0, "batch_reward": 0.360493214070797, "critic_loss": 0.5307996410131455, "actor_loss": -50.22647193145752, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.510467290878296, "step": 102000}
{"episode_reward": 635.6778020197945, "episode": 103.0, "batch_reward": 0.36264008095860484, "critic_loss": 0.5304247076958418, "actor_loss": -49.90938343811035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.444780826568604, "step": 103000}
{"episode_reward": 595.1011728135682, "episode": 104.0, "batch_reward": 0.3652589687407017, "critic_loss": 0.4970594071298838, "actor_loss": -49.80298393249512, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.254400491714478, "step": 104000}
{"episode_reward": 577.1383647212019, "episode": 105.0, "batch_reward": 0.3689508454799652, "critic_loss": 0.47275785259902475, "actor_loss": -49.67375563049316, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.620365858078003, "step": 105000}
{"episode_reward": 660.2999146402947, "episode": 106.0, "batch_reward": 0.370409294962883, "critic_loss": 0.46769612716138365, "actor_loss": -49.309070480346676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.075859546661377, "step": 106000}
{"episode_reward": 647.2888828653624, "episode": 107.0, "batch_reward": 0.37376136931777, "critic_loss": 0.4426424759477377, "actor_loss": -49.00213159942627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.827994108200073, "step": 107000}
{"episode_reward": 664.7559491999942, "episode": 108.0, "batch_reward": 0.37571292248368265, "critic_loss": 0.41960525096952916, "actor_loss": -48.90625866699219, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.756582975387573, "step": 108000}
{"episode_reward": 649.8338411791784, "episode": 109.0, "batch_reward": 0.37923743692040446, "critic_loss": 0.40713518093526363, "actor_loss": -48.9797991104126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.69966149330139, "step": 109000}
{"episode_reward": 664.074601769161, "episode": 110.0, "batch_reward": 0.38054072645306586, "critic_loss": 0.43037626692652703, "actor_loss": -48.678821975708004, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.190540313720703, "step": 110000}
{"episode_reward": 620.0505867541227, "episode": 111.0, "batch_reward": 0.38283144611120223, "critic_loss": 0.4120967050790787, "actor_loss": -48.595617683410644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.15363264083862, "step": 111000}
{"episode_reward": 665.0830224190054, "episode": 112.0, "batch_reward": 0.385829642534256, "critic_loss": 0.41031005565822126, "actor_loss": -48.42942256164551, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.085864543914795, "step": 112000}
{"episode_reward": 637.1494901196787, "episode": 113.0, "batch_reward": 0.3886958369910717, "critic_loss": 0.38505510552227495, "actor_loss": -48.43266083526611, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.503131866455078, "step": 113000}
{"episode_reward": 603.8401199994125, "episode": 114.0, "batch_reward": 0.39113492277264594, "critic_loss": 0.38642358012497424, "actor_loss": -48.31329080200195, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.411014556884766, "step": 114000}
{"episode_reward": 645.8615391103614, "episode": 115.0, "batch_reward": 0.3914509372711182, "critic_loss": 0.40224694833159447, "actor_loss": -48.20514126586914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.97992491722107, "step": 115000}
{"episode_reward": 645.4506558535137, "episode": 116.0, "batch_reward": 0.3945612840652466, "critic_loss": 0.38111596724390984, "actor_loss": -48.17794302368164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.34963059425354, "step": 116000}
{"episode_reward": 654.8358597580283, "episode": 117.0, "batch_reward": 0.39632852891087533, "critic_loss": 0.36938373681902886, "actor_loss": -47.97548373413086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.330607652664185, "step": 117000}
{"episode_reward": 633.0662186678151, "episode": 118.0, "batch_reward": 0.39934645375609396, "critic_loss": 0.3700700045078993, "actor_loss": -47.93758650970459, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.377816677093506, "step": 118000}
{"episode_reward": 629.848864950431, "episode": 119.0, "batch_reward": 0.39985210946202276, "critic_loss": 0.35588799574971197, "actor_loss": -47.97466554260254, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.259549617767334, "step": 119000}
{"episode_reward": 604.1626471549482, "episode": 120.0, "batch_reward": 0.40209723490476607, "critic_loss": 0.3755431573092938, "actor_loss": -47.82550698852539, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.1368145942688, "step": 120000}
{"episode_reward": 485.2093291796131, "episode": 121.0, "batch_reward": 0.4041508460044861, "critic_loss": 0.36115470217168333, "actor_loss": -47.638160110473635, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.32886505126953, "step": 121000}
{"episode_reward": 634.818668467566, "episode": 122.0, "batch_reward": 0.40528388440608976, "critic_loss": 0.34515990449488165, "actor_loss": -47.567814247131345, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.094991207122803, "step": 122000}
{"episode_reward": 675.2236197011479, "episode": 123.0, "batch_reward": 0.40681591203808787, "critic_loss": 0.35368003909289836, "actor_loss": -47.56985903930664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.43194603919983, "step": 123000}
{"episode_reward": 620.5833254590148, "episode": 124.0, "batch_reward": 0.4084382603764534, "critic_loss": 0.35361277469992636, "actor_loss": -47.329222076416016, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.101357460021973, "step": 124000}
{"episode_reward": 618.4697396324478, "episode": 125.0, "batch_reward": 0.41144502300024033, "critic_loss": 0.35666046787798406, "actor_loss": -47.53303507995606, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.02635931968689, "step": 125000}
{"episode_reward": 546.048780466345, "episode": 126.0, "batch_reward": 0.41103960981965065, "critic_loss": 0.37992948506772517, "actor_loss": -47.257469299316405, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.204143285751343, "step": 126000}
{"episode_reward": 648.5729216742699, "episode": 127.0, "batch_reward": 0.4143024651110172, "critic_loss": 0.3971760644167662, "actor_loss": -47.45889167785644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.158525466918945, "step": 127000}
{"episode_reward": 618.8099597128064, "episode": 128.0, "batch_reward": 0.4149945695400238, "critic_loss": 0.41258837017416955, "actor_loss": -47.39145262145996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.0887234210968, "step": 128000}
{"episode_reward": 641.038274245774, "episode": 129.0, "batch_reward": 0.41602548292279246, "critic_loss": 0.35711568911373615, "actor_loss": -47.32176351928711, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.108407020568848, "step": 129000}
{"episode_reward": 614.9705366157389, "episode": 130.0, "batch_reward": 0.41923525974154474, "critic_loss": 0.36316279673576357, "actor_loss": -47.47042175292969, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.474871397018433, "step": 130000}
{"episode_reward": 592.728289612909, "episode": 131.0, "batch_reward": 0.4201876367628574, "critic_loss": 0.37367286956310275, "actor_loss": -47.22274448394776, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.23944711685181, "step": 131000}
{"episode_reward": 611.0256188529505, "episode": 132.0, "batch_reward": 0.4213423536717892, "critic_loss": 0.3715642970353365, "actor_loss": -47.27753699493408, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.49295997619629, "step": 132000}
{"episode_reward": 610.9194810410257, "episode": 133.0, "batch_reward": 0.4219877146184444, "critic_loss": 0.3488180741518736, "actor_loss": -47.3680712890625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.15599226951599, "step": 133000}
{"episode_reward": 649.1884076691864, "episode": 134.0, "batch_reward": 0.42409764710068704, "critic_loss": 0.34641404746472837, "actor_loss": -47.34112627410889, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.601224422454834, "step": 134000}
{"episode_reward": 637.039335409311, "episode": 135.0, "batch_reward": 0.42547340190410615, "critic_loss": 0.3346232515722513, "actor_loss": -47.40472229003906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.215451955795288, "step": 135000}
{"episode_reward": 624.7471078969729, "episode": 136.0, "batch_reward": 0.4274092990756035, "critic_loss": 0.3197975045591593, "actor_loss": -47.42228500366211, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.619458436965942, "step": 136000}
{"episode_reward": 625.3981136531555, "episode": 137.0, "batch_reward": 0.4287818697690964, "critic_loss": 0.32859191435575485, "actor_loss": -47.53839817047119, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.530562162399292, "step": 137000}
{"episode_reward": 625.5313221309298, "episode": 138.0, "batch_reward": 0.4314947736263275, "critic_loss": 0.33571031799912454, "actor_loss": -48.01153581237793, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.07140016555786, "step": 138000}
{"episode_reward": 635.4809283071594, "episode": 139.0, "batch_reward": 0.43200518015027045, "critic_loss": 0.32183950120210647, "actor_loss": -47.75712577056885, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.307034015655518, "step": 139000}
{"episode_reward": 629.9962845454313, "episode": 140.0, "batch_reward": 0.4334620759189129, "critic_loss": 0.3085233165472746, "actor_loss": -47.839521942138674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.644402027130127, "step": 140000}
{"episode_reward": 397.2444343195366, "episode": 141.0, "batch_reward": 0.43174988731741903, "critic_loss": 0.3124745509773493, "actor_loss": -47.65920846557617, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.57457518577576, "step": 141000}
{"episode_reward": 588.2748958088282, "episode": 142.0, "batch_reward": 0.4329430438578129, "critic_loss": 0.3172961582690477, "actor_loss": -47.41146429443359, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.69483184814453, "step": 142000}
{"episode_reward": 639.9211149458209, "episode": 143.0, "batch_reward": 0.4341099174618721, "critic_loss": 0.33801479715108873, "actor_loss": -47.5486555480957, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.375133752822876, "step": 143000}
{"episode_reward": 561.2325873972258, "episode": 144.0, "batch_reward": 0.4364520736634731, "critic_loss": 0.324438756108284, "actor_loss": -47.60928092956543, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.429048538208008, "step": 144000}
{"episode_reward": 631.4290961930052, "episode": 145.0, "batch_reward": 0.4386582808792591, "critic_loss": 0.3183687240183353, "actor_loss": -47.803729789733886, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.237046480178833, "step": 145000}
{"episode_reward": 609.0188098767676, "episode": 146.0, "batch_reward": 0.4380728534758091, "critic_loss": 0.32456637200713156, "actor_loss": -47.812513381958006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.62285089492798, "step": 146000}
{"episode_reward": 635.767246960817, "episode": 147.0, "batch_reward": 0.43976841285824775, "critic_loss": 0.32423516434431077, "actor_loss": -47.691103759765625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.45561456680298, "step": 147000}
{"episode_reward": 652.2648160257304, "episode": 148.0, "batch_reward": 0.4416760329902172, "critic_loss": 0.3084251246005297, "actor_loss": -47.98472965240479, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.43699550628662, "step": 148000}
{"episode_reward": 646.3713178656103, "episode": 149.0, "batch_reward": 0.4439579985439777, "critic_loss": 0.32170828461647033, "actor_loss": -48.0756516494751, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.38379979133606, "step": 149000}
{"episode_reward": 660.5844711256216, "episode": 150.0, "batch_reward": 0.4446651611328125, "critic_loss": 0.31830286425352095, "actor_loss": -48.021471031188966, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
