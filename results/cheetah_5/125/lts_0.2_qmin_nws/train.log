{"episode_reward": 0.0, "episode": 1.0, "duration": 18.908292770385742, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.5415010452270508, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.28092564086430705, "critic_loss": 0.02193419963727597, "actor_loss": -11.166180215641802, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 69.34135317802429, "step": 3000}
{"episode_reward": 19.82045120060082, "episode": 4.0, "batch_reward": 0.19966825152933598, "critic_loss": 0.03632732772268355, "actor_loss": -11.012729140281678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.716975450515747, "step": 4000}
{"episode_reward": 147.08816192161592, "episode": 5.0, "batch_reward": 0.17342168302834035, "critic_loss": 0.03758565909601748, "actor_loss": -9.804153773784638, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.970118761062622, "step": 5000}
{"episode_reward": 28.90061861739909, "episode": 6.0, "batch_reward": 0.14599326622486114, "critic_loss": 0.03566838521603495, "actor_loss": -9.129141189098359, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.494436502456665, "step": 6000}
{"episode_reward": 45.88308383370322, "episode": 7.0, "batch_reward": 0.13582414044439792, "critic_loss": 0.049869760498404504, "actor_loss": -10.03982355260849, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.329028129577637, "step": 7000}
{"episode_reward": 121.2328356829727, "episode": 8.0, "batch_reward": 0.13714771719276905, "critic_loss": 0.06080113666132093, "actor_loss": -10.417195355892181, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.092649459838867, "step": 8000}
{"episode_reward": 147.99952587228825, "episode": 9.0, "batch_reward": 0.13568613835424184, "critic_loss": 0.07257331916503608, "actor_loss": -11.50791715335846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.21023964881897, "step": 9000}
{"episode_reward": 140.77530805239178, "episode": 10.0, "batch_reward": 0.14108487609773873, "critic_loss": 0.09519723067060112, "actor_loss": -11.900122051239014, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.118486881256104, "step": 10000}
{"episode_reward": 219.87834965421928, "episode": 11.0, "batch_reward": 0.14706062909960746, "critic_loss": 0.10886227211728693, "actor_loss": -13.756473569869994, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.427348136901855, "step": 11000}
{"episode_reward": 120.31972730548206, "episode": 12.0, "batch_reward": 0.14559813226014376, "critic_loss": 0.10028154895827174, "actor_loss": -13.15649156665802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.571494340896606, "step": 12000}
{"episode_reward": 109.05442574896706, "episode": 13.0, "batch_reward": 0.13980273831635714, "critic_loss": 0.10606715266034007, "actor_loss": -13.445172614097595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.473280429840088, "step": 13000}
{"episode_reward": 108.86833195072055, "episode": 14.0, "batch_reward": 0.14339337772130967, "critic_loss": 0.141586224488914, "actor_loss": -13.916850296020508, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.489804983139038, "step": 14000}
{"episode_reward": 327.0395670466147, "episode": 15.0, "batch_reward": 0.14980696146935224, "critic_loss": 0.15230474983155728, "actor_loss": -14.744752130508424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.56587266921997, "step": 15000}
{"episode_reward": 59.93923255469949, "episode": 16.0, "batch_reward": 0.1429379877001047, "critic_loss": 0.19338674914091825, "actor_loss": -14.451430011749268, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.40652632713318, "step": 16000}
{"episode_reward": 34.752192053363565, "episode": 17.0, "batch_reward": 0.14007904613763095, "critic_loss": 0.18453623495996, "actor_loss": -14.072395006179809, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.13244938850403, "step": 17000}
{"episode_reward": 242.57878769894344, "episode": 18.0, "batch_reward": 0.14367225059866906, "critic_loss": 0.18429692298173905, "actor_loss": -14.673482957839965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.345575094223022, "step": 18000}
{"episode_reward": 54.1511707591719, "episode": 19.0, "batch_reward": 0.13947511141747237, "critic_loss": 0.17590049501508476, "actor_loss": -15.151324493408204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.83380627632141, "step": 19000}
{"episode_reward": 87.62520535189303, "episode": 20.0, "batch_reward": 0.14057372479885816, "critic_loss": 0.1885463787317276, "actor_loss": -15.411683530807496, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.981014013290405, "step": 20000}
{"episode_reward": 198.1056557666197, "episode": 21.0, "batch_reward": 0.14113167144358157, "critic_loss": 0.20724111045897006, "actor_loss": -15.840144439697266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.86628317832947, "step": 21000}
{"episode_reward": 107.937453147017, "episode": 22.0, "batch_reward": 0.14146136666089296, "critic_loss": 0.22169636030495166, "actor_loss": -15.951234291076661, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.18045949935913, "step": 22000}
{"episode_reward": 281.5098491154282, "episode": 23.0, "batch_reward": 0.14886602319031955, "critic_loss": 0.23690110477805137, "actor_loss": -16.450450359344483, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14554190635681, "step": 23000}
{"episode_reward": 261.49832854390587, "episode": 24.0, "batch_reward": 0.15200325015187263, "critic_loss": 0.24068369853496552, "actor_loss": -17.23219875717163, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.691003561019897, "step": 24000}
{"episode_reward": 170.0557366074211, "episode": 25.0, "batch_reward": 0.1530208229869604, "critic_loss": 0.23094934180378915, "actor_loss": -17.39941992378235, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.366157054901123, "step": 25000}
{"episode_reward": 276.64874834398717, "episode": 26.0, "batch_reward": 0.15487058585137128, "critic_loss": 0.24925066227465867, "actor_loss": -17.81390254020691, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.003015756607056, "step": 26000}
{"episode_reward": 82.26216274312938, "episode": 27.0, "batch_reward": 0.1545119653493166, "critic_loss": 0.2775340494513512, "actor_loss": -18.023714876174928, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.160129070281982, "step": 27000}
{"episode_reward": 145.7213834657453, "episode": 28.0, "batch_reward": 0.15445362681150437, "critic_loss": 0.314329665735364, "actor_loss": -18.28600862121582, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.575750827789307, "step": 28000}
{"episode_reward": 268.28521026109263, "episode": 29.0, "batch_reward": 0.15859628097712994, "critic_loss": 0.3504425593987107, "actor_loss": -18.764103803634644, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.902037858963013, "step": 29000}
{"episode_reward": 173.34541940099672, "episode": 30.0, "batch_reward": 0.15615158698707818, "critic_loss": 0.33175113086402414, "actor_loss": -18.645567111968994, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.600513458251953, "step": 30000}
{"episode_reward": 49.47168603554837, "episode": 31.0, "batch_reward": 0.15523325573652982, "critic_loss": 0.35480042883753776, "actor_loss": -18.589348251342773, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.76073884963989, "step": 31000}
{"episode_reward": 131.8610497879055, "episode": 32.0, "batch_reward": 0.15558550169318913, "critic_loss": 0.3740287083983421, "actor_loss": -18.85971466636658, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.651009798049927, "step": 32000}
{"episode_reward": 294.45048977507344, "episode": 33.0, "batch_reward": 0.1587072149813175, "critic_loss": 0.39689907762408255, "actor_loss": -19.272122072219847, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.488917112350464, "step": 33000}
{"episode_reward": 243.72662609469938, "episode": 34.0, "batch_reward": 0.1600237988308072, "critic_loss": 0.42040290945768355, "actor_loss": -19.41816673088074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.12856888771057, "step": 34000}
{"episode_reward": 120.62392577000797, "episode": 35.0, "batch_reward": 0.15753535115718842, "critic_loss": 0.40784420581161973, "actor_loss": -19.631571670532228, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.4699866771698, "step": 35000}
{"episode_reward": 37.6756090667531, "episode": 36.0, "batch_reward": 0.15589348393678665, "critic_loss": 0.4333007909655571, "actor_loss": -19.686982009887696, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.915163040161133, "step": 36000}
{"episode_reward": 131.78480184878606, "episode": 37.0, "batch_reward": 0.15414194887876512, "critic_loss": 0.427886307567358, "actor_loss": -19.684881879806518, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.906550884246826, "step": 37000}
{"episode_reward": 55.986564409666094, "episode": 38.0, "batch_reward": 0.15338270664960146, "critic_loss": 0.48275986628234385, "actor_loss": -19.729116436004638, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.182327270507812, "step": 38000}
{"episode_reward": 153.4986978825296, "episode": 39.0, "batch_reward": 0.1517177766188979, "critic_loss": 0.5030726142972708, "actor_loss": -20.082544662475588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.897112369537354, "step": 39000}
{"episode_reward": 84.18246604146609, "episode": 40.0, "batch_reward": 0.15077701345086097, "critic_loss": 0.48791533160209655, "actor_loss": -20.05204991531372, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.952570915222168, "step": 40000}
{"episode_reward": 90.78679961602494, "episode": 41.0, "batch_reward": 0.14887701987475158, "critic_loss": 0.5030116365700961, "actor_loss": -19.909192003250123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.50094723701477, "step": 41000}
{"episode_reward": 46.14209120004399, "episode": 42.0, "batch_reward": 0.14912455876171588, "critic_loss": 0.581457416832447, "actor_loss": -19.73955591392517, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.80561852455139, "step": 42000}
{"episode_reward": 283.65865067210217, "episode": 43.0, "batch_reward": 0.1496372190490365, "critic_loss": 0.6618142948150635, "actor_loss": -20.357279651641846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3301682472229, "step": 43000}
{"episode_reward": 105.7693102021026, "episode": 44.0, "batch_reward": 0.15148287654668094, "critic_loss": 0.661735618621111, "actor_loss": -20.673185018539428, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.01389169692993, "step": 44000}
{"episode_reward": 383.6932842306379, "episode": 45.0, "batch_reward": 0.1553955093920231, "critic_loss": 0.7139437971115112, "actor_loss": -21.28810330581665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.782718181610107, "step": 45000}
{"episode_reward": 292.7372282395793, "episode": 46.0, "batch_reward": 0.15762513246387244, "critic_loss": 0.7548222182691098, "actor_loss": -21.786237300872802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.25019884109497, "step": 46000}
{"episode_reward": 87.26304932614825, "episode": 47.0, "batch_reward": 0.15802122392505408, "critic_loss": 0.7360279278457165, "actor_loss": -21.78956843185425, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.602675676345825, "step": 47000}
{"episode_reward": 279.57956127499347, "episode": 48.0, "batch_reward": 0.15791568066179754, "critic_loss": 0.7838192559480667, "actor_loss": -22.076665855407715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.082533359527588, "step": 48000}
{"episode_reward": 94.36639965649158, "episode": 49.0, "batch_reward": 0.15818688789755106, "critic_loss": 0.818175492823124, "actor_loss": -22.251297691345215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.032327890396118, "step": 49000}
{"episode_reward": 172.64151907570232, "episode": 50.0, "batch_reward": 0.1567591614574194, "critic_loss": 0.7871591601371765, "actor_loss": -22.270202632904052, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.519627332687378, "step": 50000}
{"episode_reward": 140.33645101179906, "episode": 51.0, "batch_reward": 0.15790335323661567, "critic_loss": 0.7511568219065666, "actor_loss": -22.699710460662843, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.72536087036133, "step": 51000}
{"episode_reward": 229.57940757439897, "episode": 52.0, "batch_reward": 0.15859746889024973, "critic_loss": 0.7403686392009259, "actor_loss": -22.860765747070314, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.353752374649048, "step": 52000}
{"episode_reward": 45.082373670846145, "episode": 53.0, "batch_reward": 0.1579220233783126, "critic_loss": 0.7244931430220604, "actor_loss": -22.740896587371825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.095185041427612, "step": 53000}
{"episode_reward": 301.17965690065233, "episode": 54.0, "batch_reward": 0.15871724711358548, "critic_loss": 0.811226031601429, "actor_loss": -22.767264003753663, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.668075561523438, "step": 54000}
{"episode_reward": 121.97336283264278, "episode": 55.0, "batch_reward": 0.15920366775244474, "critic_loss": 0.6785265980958939, "actor_loss": -22.741159408569334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.201195240020752, "step": 55000}
{"episode_reward": 235.21490986223637, "episode": 56.0, "batch_reward": 0.16213342203944922, "critic_loss": 0.8124630810618401, "actor_loss": -23.114754154205322, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.20661997795105, "step": 56000}
{"episode_reward": 417.49691647779986, "episode": 57.0, "batch_reward": 0.16659260143339633, "critic_loss": 0.920267869323492, "actor_loss": -23.652674812316896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.898502588272095, "step": 57000}
{"episode_reward": 394.77489065620654, "episode": 58.0, "batch_reward": 0.16926685757189988, "critic_loss": 0.8433288332521915, "actor_loss": -23.85482215118408, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.94722867012024, "step": 58000}
{"episode_reward": 130.2275195941788, "episode": 59.0, "batch_reward": 0.1686371260136366, "critic_loss": 0.9042018002867699, "actor_loss": -23.636672550201418, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.469369888305664, "step": 59000}
{"episode_reward": 152.1990651500962, "episode": 60.0, "batch_reward": 0.1697822805941105, "critic_loss": 0.8816402679383755, "actor_loss": -23.817269538879394, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.252029418945312, "step": 60000}
{"episode_reward": 396.5313154707468, "episode": 61.0, "batch_reward": 0.17284825024008751, "critic_loss": 0.8324504846632481, "actor_loss": -24.05038207626343, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.32849144935608, "step": 61000}
{"episode_reward": 301.7328253586681, "episode": 62.0, "batch_reward": 0.17424261850118636, "critic_loss": 0.9449156225323677, "actor_loss": -24.317342384338378, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.444389581680298, "step": 62000}
{"episode_reward": 255.15118722573422, "episode": 63.0, "batch_reward": 0.17509459209442138, "critic_loss": 0.964074450969696, "actor_loss": -24.373792392730714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.036436796188354, "step": 63000}
{"episode_reward": 176.39010472764005, "episode": 64.0, "batch_reward": 0.17411294730007648, "critic_loss": 0.8075603377819062, "actor_loss": -24.175452533721923, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.11315941810608, "step": 64000}
{"episode_reward": 63.827106345324445, "episode": 65.0, "batch_reward": 0.17403541126847266, "critic_loss": 0.99575997620821, "actor_loss": -24.261925930023192, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.47758412361145, "step": 65000}
{"episode_reward": 302.2498693212579, "episode": 66.0, "batch_reward": 0.175351803869009, "critic_loss": 0.9215340152978897, "actor_loss": -24.4723005027771, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.763710498809814, "step": 66000}
{"episode_reward": 149.9641561539795, "episode": 67.0, "batch_reward": 0.1752455313205719, "critic_loss": 1.2151606058180333, "actor_loss": -24.342438400268556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.821574687957764, "step": 67000}
{"episode_reward": 301.0765564539984, "episode": 68.0, "batch_reward": 0.17721768122911452, "critic_loss": 1.2964794946312905, "actor_loss": -24.696074436187743, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.046623706817627, "step": 68000}
{"episode_reward": 215.24622197629284, "episode": 69.0, "batch_reward": 0.1779917147308588, "critic_loss": 1.2303345540761947, "actor_loss": -24.831497035980224, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.875007390975952, "step": 69000}
{"episode_reward": 347.8286778533313, "episode": 70.0, "batch_reward": 0.1795775755494833, "critic_loss": 1.1654842664301395, "actor_loss": -24.958811195373535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.63119339942932, "step": 70000}
{"episode_reward": 199.67148909885253, "episode": 71.0, "batch_reward": 0.17986013655364513, "critic_loss": 1.282608773469925, "actor_loss": -25.208038917541504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.36802697181702, "step": 71000}
{"episode_reward": 153.63124606524718, "episode": 72.0, "batch_reward": 0.1797257883399725, "critic_loss": 1.1461011385023594, "actor_loss": -25.23934335708618, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.022595405578613, "step": 72000}
{"episode_reward": 175.78759684897017, "episode": 73.0, "batch_reward": 0.17913065400719644, "critic_loss": 1.392733487457037, "actor_loss": -25.177290355682374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.6276593208313, "step": 73000}
{"episode_reward": 116.07486450318788, "episode": 74.0, "batch_reward": 0.1774964072406292, "critic_loss": 1.2489069367349148, "actor_loss": -25.176707027435302, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.867652416229248, "step": 74000}
{"episode_reward": 75.56274696801825, "episode": 75.0, "batch_reward": 0.17679095529019834, "critic_loss": 1.42299946013093, "actor_loss": -25.16853411102295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.56604313850403, "step": 75000}
{"episode_reward": 47.392430700594396, "episode": 76.0, "batch_reward": 0.17511538915336133, "critic_loss": 1.261183464050293, "actor_loss": -24.94478667831421, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.28363585472107, "step": 76000}
{"episode_reward": 144.2022042595723, "episode": 77.0, "batch_reward": 0.17534151096642017, "critic_loss": 2.1115052219033243, "actor_loss": -25.26013575744629, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.143857955932617, "step": 77000}
{"episode_reward": 87.19797543547341, "episode": 78.0, "batch_reward": 0.1745186320245266, "critic_loss": 1.6252192580997944, "actor_loss": -25.3246104888916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.948212385177612, "step": 78000}
{"episode_reward": 213.46131076769598, "episode": 79.0, "batch_reward": 0.17438328598439692, "critic_loss": 2.3534626237750054, "actor_loss": -25.435931507110595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.079521894454956, "step": 79000}
{"episode_reward": 80.59191413757645, "episode": 80.0, "batch_reward": 0.17295323272049426, "critic_loss": 2.036704732775688, "actor_loss": -25.26211228942871, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.881513833999634, "step": 80000}
{"episode_reward": 291.69597051815424, "episode": 81.0, "batch_reward": 0.17488528925925492, "critic_loss": 1.9592393032312394, "actor_loss": -25.564072929382323, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.34019184112549, "step": 81000}
{"episode_reward": 146.22350861395887, "episode": 82.0, "batch_reward": 0.17454918718338014, "critic_loss": 2.6540583027005193, "actor_loss": -25.900304149627686, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.91757583618164, "step": 82000}
{"episode_reward": 172.3510091821539, "episode": 83.0, "batch_reward": 0.1748735193312168, "critic_loss": 2.759996843934059, "actor_loss": -26.17870975494385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.767290830612183, "step": 83000}
{"episode_reward": 209.08446138710218, "episode": 84.0, "batch_reward": 0.17396412153542043, "critic_loss": 3.0559381767511367, "actor_loss": -26.268509353637697, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.957966089248657, "step": 84000}
{"episode_reward": 14.525095212024045, "episode": 85.0, "batch_reward": 0.1729152051359415, "critic_loss": 4.893823369145394, "actor_loss": -26.405076553344728, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.243696212768555, "step": 85000}
{"episode_reward": 166.12981996238452, "episode": 86.0, "batch_reward": 0.17129580514132978, "critic_loss": 5.303100667357445, "actor_loss": -26.889344020843506, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.95206594467163, "step": 86000}
{"episode_reward": 14.701677837505155, "episode": 87.0, "batch_reward": 0.17074083003401758, "critic_loss": 5.676341524422169, "actor_loss": -27.299413120269776, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.14618182182312, "step": 87000}
{"episode_reward": 32.705374635786676, "episode": 88.0, "batch_reward": 0.1682929129600525, "critic_loss": 6.313996288657188, "actor_loss": -27.772135650634766, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.095022439956665, "step": 88000}
{"episode_reward": 49.53372419327202, "episode": 89.0, "batch_reward": 0.16668042394518853, "critic_loss": 6.5544284472465515, "actor_loss": -28.055086093902588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.972238063812256, "step": 89000}
{"episode_reward": 45.10694663753081, "episode": 90.0, "batch_reward": 0.16671934093534946, "critic_loss": 7.570798496603966, "actor_loss": -28.789858318328857, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.131109714508057, "step": 90000}
{"episode_reward": 92.14900827292688, "episode": 91.0, "batch_reward": 0.16568776293098927, "critic_loss": 9.095737601876259, "actor_loss": -29.338339237213134, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.13130712509155, "step": 91000}
{"episode_reward": 35.0442091066182, "episode": 92.0, "batch_reward": 0.16449145670235157, "critic_loss": 10.301302076816558, "actor_loss": -30.735399673461913, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.171457767486572, "step": 92000}
{"episode_reward": 91.30865092124118, "episode": 93.0, "batch_reward": 0.16275655417889356, "critic_loss": 10.044789319515228, "actor_loss": -31.959389408111573, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.194607496261597, "step": 93000}
{"episode_reward": 47.64271021000349, "episode": 94.0, "batch_reward": 0.16126144132763148, "critic_loss": 11.883720791578293, "actor_loss": -33.182984107971194, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.646740913391113, "step": 94000}
{"episode_reward": 25.71942318892108, "episode": 95.0, "batch_reward": 0.16009663755446674, "critic_loss": 13.717479553461075, "actor_loss": -34.28896168136597, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.042452335357666, "step": 95000}
{"episode_reward": 16.022310966900623, "episode": 96.0, "batch_reward": 0.1582050907239318, "critic_loss": 12.69956595826149, "actor_loss": -36.07034914016724, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.376054763793945, "step": 96000}
{"episode_reward": 56.705419010954536, "episode": 97.0, "batch_reward": 0.15756921315193176, "critic_loss": 19.90656299352646, "actor_loss": -37.88976627349854, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.42404580116272, "step": 97000}
{"episode_reward": 59.737742299461964, "episode": 98.0, "batch_reward": 0.1564622057825327, "critic_loss": 25.645419095516203, "actor_loss": -39.774169506073, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.215879201889038, "step": 98000}
{"episode_reward": 6.58671665611274, "episode": 99.0, "batch_reward": 0.15392534820735454, "critic_loss": 19.447699956417082, "actor_loss": -42.11831018447876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.907121896743774, "step": 99000}
{"episode_reward": 17.023373846738956, "episode": 100.0, "batch_reward": 0.1541900885105133, "critic_loss": 25.605137790203095, "actor_loss": -44.77760975646973, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.881473064422607, "step": 100000}
{"episode_reward": 16.855264468450336, "episode": 101.0, "batch_reward": 0.152568981744349, "critic_loss": 23.075284547805786, "actor_loss": -46.13965776062012, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.49701285362244, "step": 101000}
{"episode_reward": 71.59522108647344, "episode": 102.0, "batch_reward": 0.1518020730316639, "critic_loss": 26.11329030036926, "actor_loss": -48.27622436141968, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.871168851852417, "step": 102000}
{"episode_reward": 76.19946664574489, "episode": 103.0, "batch_reward": 0.15078315550088883, "critic_loss": 38.25880437660217, "actor_loss": -50.411448757171634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.565052032470703, "step": 103000}
{"episode_reward": 37.65372575990704, "episode": 104.0, "batch_reward": 0.1496629278510809, "critic_loss": 35.390823173522946, "actor_loss": -53.672250438690185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.427510023117065, "step": 104000}
{"episode_reward": 22.447970890636437, "episode": 105.0, "batch_reward": 0.14813438389450312, "critic_loss": 47.31771683311462, "actor_loss": -57.2581187210083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.730470657348633, "step": 105000}
{"episode_reward": 13.46534238541121, "episode": 106.0, "batch_reward": 0.1475827018395066, "critic_loss": 37.38704902362824, "actor_loss": -61.193908107757565, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.505733728408813, "step": 106000}
{"episode_reward": 12.047438964720373, "episode": 107.0, "batch_reward": 0.14551635885983705, "critic_loss": 58.578655676841734, "actor_loss": -63.692382579803464, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.150795936584473, "step": 107000}
{"episode_reward": 32.4947627655706, "episode": 108.0, "batch_reward": 0.14523013205081226, "critic_loss": 56.06727650928497, "actor_loss": -65.96134155273438, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41647744178772, "step": 108000}
{"episode_reward": 16.610775175736418, "episode": 109.0, "batch_reward": 0.14246477961540222, "critic_loss": 54.00872926330566, "actor_loss": -69.6099913520813, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.681580781936646, "step": 109000}
{"episode_reward": 12.97579443695339, "episode": 110.0, "batch_reward": 0.14178236381709575, "critic_loss": 68.59239266586303, "actor_loss": -74.56023810577392, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.60599160194397, "step": 110000}
{"episode_reward": 30.79910259239752, "episode": 111.0, "batch_reward": 0.14193607974797487, "critic_loss": 73.09433209991455, "actor_loss": -77.73232359313965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.19793701171875, "step": 111000}
{"episode_reward": 39.63974184007911, "episode": 112.0, "batch_reward": 0.13990129212290048, "critic_loss": 76.22401380348205, "actor_loss": -84.62700159835815, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.45088267326355, "step": 112000}
{"episode_reward": 31.397443673682904, "episode": 113.0, "batch_reward": 0.14017178672552108, "critic_loss": 98.59691240310669, "actor_loss": -91.20057610702514, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.940485954284668, "step": 113000}
{"episode_reward": 53.66694491411738, "episode": 114.0, "batch_reward": 0.1381343842446804, "critic_loss": 95.10887500953675, "actor_loss": -95.99518046951295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.776657342910767, "step": 114000}
{"episode_reward": 15.416866272987669, "episode": 115.0, "batch_reward": 0.13819688043743372, "critic_loss": 97.0953780593872, "actor_loss": -101.94358635139466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.57505488395691, "step": 115000}
{"episode_reward": 38.497602949361834, "episode": 116.0, "batch_reward": 0.13693197034299373, "critic_loss": 98.47857694625854, "actor_loss": -109.24786165618896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.290072917938232, "step": 116000}
{"episode_reward": 62.14775402576661, "episode": 117.0, "batch_reward": 0.13571408270299434, "critic_loss": 133.61757876586915, "actor_loss": -113.07522153472901, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.895747900009155, "step": 117000}
{"episode_reward": 44.41233818510307, "episode": 118.0, "batch_reward": 0.13522160689532756, "critic_loss": 147.87983070755004, "actor_loss": -119.35520933532715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.230908155441284, "step": 118000}
{"episode_reward": 25.729707300014034, "episode": 119.0, "batch_reward": 0.1347333806604147, "critic_loss": 128.64850191497803, "actor_loss": -125.01200548171997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.16675353050232, "step": 119000}
{"episode_reward": 51.12323741013767, "episode": 120.0, "batch_reward": 0.13328334161639213, "critic_loss": 177.91766062164308, "actor_loss": -133.0688509025574, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.61026883125305, "step": 120000}
{"episode_reward": 31.319521800385054, "episode": 121.0, "batch_reward": 0.1332487758398056, "critic_loss": 169.4330585823059, "actor_loss": -135.04572694778443, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.55818319320679, "step": 121000}
{"episode_reward": 24.957557266371275, "episode": 122.0, "batch_reward": 0.13242392698675395, "critic_loss": 220.58618872833253, "actor_loss": -140.21224048233032, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.05088448524475, "step": 122000}
{"episode_reward": 48.802104059947, "episode": 123.0, "batch_reward": 0.13137492682784796, "critic_loss": 178.16071299743652, "actor_loss": -144.6982945327759, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.236228704452515, "step": 123000}
{"episode_reward": 58.94378879080338, "episode": 124.0, "batch_reward": 0.1308113597109914, "critic_loss": 227.25334310531616, "actor_loss": -149.87029422760008, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.880930185317993, "step": 124000}
{"episode_reward": 45.95740651136168, "episode": 125.0, "batch_reward": 0.13069116475433112, "critic_loss": 233.4487053604126, "actor_loss": -154.66595476913452, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.312602758407593, "step": 125000}
{"episode_reward": 37.1909279115056, "episode": 126.0, "batch_reward": 0.1294044935181737, "critic_loss": 362.18989586639407, "actor_loss": -155.193009929657, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.9030921459198, "step": 126000}
{"episode_reward": 49.48573080858545, "episode": 127.0, "batch_reward": 0.1297276235371828, "critic_loss": 333.48300971221926, "actor_loss": -160.7955217781067, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.178731679916382, "step": 127000}
{"episode_reward": 9.975381106956963, "episode": 128.0, "batch_reward": 0.12775638228654862, "critic_loss": 322.1326177215576, "actor_loss": -164.17242250442504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.465803861618042, "step": 128000}
{"episode_reward": 77.19568611173577, "episode": 129.0, "batch_reward": 0.12736867202073335, "critic_loss": 450.4839460906982, "actor_loss": -165.65350827789305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.595263242721558, "step": 129000}
{"episode_reward": 33.7796084993983, "episode": 130.0, "batch_reward": 0.12678960612416268, "critic_loss": 426.18198932647704, "actor_loss": -173.7168390007019, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.06011438369751, "step": 130000}
{"episode_reward": 18.19777361392626, "episode": 131.0, "batch_reward": 0.12634183660149576, "critic_loss": 463.5984050064087, "actor_loss": -185.3812046279907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.57229924201965, "step": 131000}
{"episode_reward": 61.898134077888365, "episode": 132.0, "batch_reward": 0.1257885486930609, "critic_loss": 573.9052964248657, "actor_loss": -195.34414847373964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.85453462600708, "step": 132000}
{"episode_reward": 35.80412772504897, "episode": 133.0, "batch_reward": 0.1244793107956648, "critic_loss": 653.2255524139405, "actor_loss": -197.06508423614503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.419508695602417, "step": 133000}
{"episode_reward": 9.270138714435046, "episode": 134.0, "batch_reward": 0.12424998139590025, "critic_loss": 620.8086941986084, "actor_loss": -208.3635908203125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.256307125091553, "step": 134000}
{"episode_reward": 16.58658595392339, "episode": 135.0, "batch_reward": 0.12373974931240082, "critic_loss": 825.5193379058838, "actor_loss": -224.23788217926025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.319860458374023, "step": 135000}
{"episode_reward": 40.064036548086214, "episode": 136.0, "batch_reward": 0.12247565346211195, "critic_loss": 817.8269111633301, "actor_loss": -223.91658182907105, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.032907962799072, "step": 136000}
{"episode_reward": 45.0449637924672, "episode": 137.0, "batch_reward": 0.12147705795615911, "critic_loss": 883.9849243316651, "actor_loss": -248.09849501800537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.224257946014404, "step": 137000}
{"episode_reward": 33.95529176595954, "episode": 138.0, "batch_reward": 0.12149340572953224, "critic_loss": 1120.0433145751954, "actor_loss": -260.289704246521, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.849019527435303, "step": 138000}
{"episode_reward": 16.785094589283943, "episode": 139.0, "batch_reward": 0.12067503387480974, "critic_loss": 893.0138715515137, "actor_loss": -265.6881648082733, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.11746120452881, "step": 139000}
{"episode_reward": 20.45427777480932, "episode": 140.0, "batch_reward": 0.12070513781160117, "critic_loss": 1165.3138135375978, "actor_loss": -279.26235361862183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.271395921707153, "step": 140000}
{"episode_reward": 15.375108915736893, "episode": 141.0, "batch_reward": 0.11917737644910813, "critic_loss": 1065.1869655761718, "actor_loss": -297.11783752822873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.80083751678467, "step": 141000}
{"episode_reward": 7.308306247953006, "episode": 142.0, "batch_reward": 0.11831254616379738, "critic_loss": 1121.7938626098633, "actor_loss": -325.54041371154784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.485358238220215, "step": 142000}
{"episode_reward": 9.09835422675748, "episode": 143.0, "batch_reward": 0.11824249145388603, "critic_loss": 1379.5551160278321, "actor_loss": -326.0625233783722, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.498791456222534, "step": 143000}
{"episode_reward": 11.704051970754577, "episode": 144.0, "batch_reward": 0.11640479738265276, "critic_loss": 1419.514226409912, "actor_loss": -338.75382997894286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.87766194343567, "step": 144000}
{"episode_reward": 50.10961417990159, "episode": 145.0, "batch_reward": 0.1163827442228794, "critic_loss": 1842.3978409423828, "actor_loss": -364.3712322540283, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.529786348342896, "step": 145000}
{"episode_reward": 16.036304532829554, "episode": 146.0, "batch_reward": 0.11545122341066599, "critic_loss": 1575.4423053894043, "actor_loss": -373.0921765670776, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.957019090652466, "step": 146000}
{"episode_reward": 30.834842241971128, "episode": 147.0, "batch_reward": 0.11481731460988522, "critic_loss": 1834.6516325988769, "actor_loss": -381.7270031776428, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.233137845993042, "step": 147000}
{"episode_reward": 37.49410163948604, "episode": 148.0, "batch_reward": 0.11461237853765488, "critic_loss": 2459.9265571594237, "actor_loss": -397.6737042293549, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.660093784332275, "step": 148000}
{"episode_reward": 24.43138515540161, "episode": 149.0, "batch_reward": 0.11377655114978552, "critic_loss": 3124.589607208252, "actor_loss": -424.23545701789857, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.637758255004883, "step": 149000}
{"episode_reward": 11.306823405355875, "episode": 150.0, "batch_reward": 0.11272529897093773, "critic_loss": 3316.923317504883, "actor_loss": -436.28782201957705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
