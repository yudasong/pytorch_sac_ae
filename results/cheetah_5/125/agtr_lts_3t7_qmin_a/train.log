{"episode_reward": 0.0, "episode": 1.0, "duration": 13.044846057891846, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.05269193649292, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2840306726236191, "critic_loss": 0.02982986278281674, "actor_loss": -34.8324073465901, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 72.08773946762085, "step": 3000}
{"episode_reward": 137.37170938861047, "episode": 4.0, "batch_reward": 0.23318527407944203, "critic_loss": 0.0470755696259439, "actor_loss": -28.487107631444932, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.18410348892212, "step": 4000}
{"episode_reward": 164.86858278082246, "episode": 5.0, "batch_reward": 0.21435834750533103, "critic_loss": 0.05121720284596085, "actor_loss": -30.78208863091469, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.18013310432434, "step": 5000}
{"episode_reward": 140.38708803787475, "episode": 6.0, "batch_reward": 0.1929220226407051, "critic_loss": 0.04675539126247168, "actor_loss": -28.718486367702486, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.392189741134644, "step": 6000}
{"episode_reward": 75.31090314077262, "episode": 7.0, "batch_reward": 0.17979782740771771, "critic_loss": 0.04741509729065001, "actor_loss": -27.598962723493575, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.314972162246704, "step": 7000}
{"episode_reward": 131.55999634725438, "episode": 8.0, "batch_reward": 0.17574249755591154, "critic_loss": 0.057867113584652546, "actor_loss": -28.086513473272323, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.866740465164185, "step": 8000}
{"episode_reward": 149.25526675717617, "episode": 9.0, "batch_reward": 0.17409182359278202, "critic_loss": 0.07009051492810249, "actor_loss": -26.046456547737122, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.907180547714233, "step": 9000}
{"episode_reward": 168.22077499210957, "episode": 10.0, "batch_reward": 0.1752817444205284, "critic_loss": 0.08857054761052131, "actor_loss": -27.22930629825592, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.05995774269104, "step": 10000}
{"episode_reward": 247.33092937191225, "episode": 11.0, "batch_reward": 0.18250176610052585, "critic_loss": 0.10856670680269599, "actor_loss": -27.312704553604124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.911608934402466, "step": 11000}
{"episode_reward": 256.8269374070892, "episode": 12.0, "batch_reward": 0.18859209789335726, "critic_loss": 0.11450198506563902, "actor_loss": -26.997508219718934, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.857831239700317, "step": 12000}
{"episode_reward": 161.23437136636207, "episode": 13.0, "batch_reward": 0.18719929033517838, "critic_loss": 0.12516425332054495, "actor_loss": -26.026814058303835, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.368579626083374, "step": 13000}
{"episode_reward": 178.48805481806147, "episode": 14.0, "batch_reward": 0.18120439764857293, "critic_loss": 0.13186138015985488, "actor_loss": -26.40869998073578, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.33605694770813, "step": 14000}
{"episode_reward": 51.60767358407781, "episode": 15.0, "batch_reward": 0.17694089521467685, "critic_loss": 0.1468026743605733, "actor_loss": -23.74904043197632, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.45469069480896, "step": 15000}
{"episode_reward": 219.0820095760428, "episode": 16.0, "batch_reward": 0.17962848913669585, "critic_loss": 0.1726140991896391, "actor_loss": -23.979529523849486, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.858159065246582, "step": 16000}
{"episode_reward": 258.61386797402264, "episode": 17.0, "batch_reward": 0.18581869740784168, "critic_loss": 0.22872330583631992, "actor_loss": -25.84640493297577, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.615690231323242, "step": 17000}
{"episode_reward": 255.3843629590146, "episode": 18.0, "batch_reward": 0.19173010517656802, "critic_loss": 0.2538487746715546, "actor_loss": -25.95494899559021, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.402944564819336, "step": 18000}
{"episode_reward": 325.2201769977768, "episode": 19.0, "batch_reward": 0.19896215352416038, "critic_loss": 0.2747289622798562, "actor_loss": -25.63408381843567, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.754708766937256, "step": 19000}
{"episode_reward": 268.152872093567, "episode": 20.0, "batch_reward": 0.1992832201719284, "critic_loss": 0.2964748058915138, "actor_loss": -24.918864133834838, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.998151302337646, "step": 20000}
{"episode_reward": 159.58152482881127, "episode": 21.0, "batch_reward": 0.19686505755782127, "critic_loss": 0.2643490176871419, "actor_loss": -24.191350688934325, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.09475588798523, "step": 21000}
{"episode_reward": 224.5951496612341, "episode": 22.0, "batch_reward": 0.19873023469746112, "critic_loss": 0.2515283327624202, "actor_loss": -25.209700101852416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.798311233520508, "step": 22000}
{"episode_reward": 127.47873033206986, "episode": 23.0, "batch_reward": 0.19601454629004, "critic_loss": 0.24440141106396915, "actor_loss": -25.3714810256958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.738882064819336, "step": 23000}
{"episode_reward": 144.12934802269984, "episode": 24.0, "batch_reward": 0.19282935443520546, "critic_loss": 0.26592208920419214, "actor_loss": -23.996894063949586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.5586416721344, "step": 24000}
{"episode_reward": 113.44538420913445, "episode": 25.0, "batch_reward": 0.19266942374408244, "critic_loss": 0.3127520678192377, "actor_loss": -24.657383544921874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.109630584716797, "step": 25000}
{"episode_reward": 372.6758344801489, "episode": 26.0, "batch_reward": 0.19839213374257086, "critic_loss": 0.3380800461769104, "actor_loss": -25.333236974716186, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.821573972702026, "step": 26000}
{"episode_reward": 355.3026751958398, "episode": 27.0, "batch_reward": 0.20448511323332785, "critic_loss": 0.3416008553057909, "actor_loss": -25.64892851448059, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.465607404708862, "step": 27000}
{"episode_reward": 181.66829740161785, "episode": 28.0, "batch_reward": 0.20460685731470585, "critic_loss": 0.32294443300366404, "actor_loss": -25.736717958450317, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.925174474716187, "step": 28000}
{"episode_reward": 317.53286971596896, "episode": 29.0, "batch_reward": 0.20920909494161605, "critic_loss": 0.41559985269606114, "actor_loss": -25.349324964523316, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.26876974105835, "step": 29000}
{"episode_reward": 337.34161570826245, "episode": 30.0, "batch_reward": 0.2141210567355156, "critic_loss": 0.40538316042721273, "actor_loss": -26.16207780456543, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.969984769821167, "step": 30000}
{"episode_reward": 407.539010486371, "episode": 31.0, "batch_reward": 0.21415459813177587, "critic_loss": 0.36279841646552086, "actor_loss": -25.632428760528565, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.74553990364075, "step": 31000}
{"episode_reward": 24.009877791258486, "episode": 32.0, "batch_reward": 0.21191187807917594, "critic_loss": 0.3692940644025803, "actor_loss": -25.587759298324585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.65507173538208, "step": 32000}
{"episode_reward": 314.68394898810647, "episode": 33.0, "batch_reward": 0.2155546618849039, "critic_loss": 0.386862564265728, "actor_loss": -26.079957992553712, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.823317289352417, "step": 33000}
{"episode_reward": 295.7636025100604, "episode": 34.0, "batch_reward": 0.21493306809663773, "critic_loss": 0.380122709184885, "actor_loss": -26.911686603546144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.591909170150757, "step": 34000}
{"episode_reward": 22.264998614078827, "episode": 35.0, "batch_reward": 0.21279830846190453, "critic_loss": 0.4016852059811354, "actor_loss": -25.68156728935242, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.29071593284607, "step": 35000}
{"episode_reward": 366.34503544612386, "episode": 36.0, "batch_reward": 0.21517452766001224, "critic_loss": 0.3625521745681763, "actor_loss": -26.74030759048462, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.752957105636597, "step": 36000}
{"episode_reward": 165.9798203726368, "episode": 37.0, "batch_reward": 0.21600674580037593, "critic_loss": 0.37761254332959654, "actor_loss": -26.375770719528198, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.42820930480957, "step": 37000}
{"episode_reward": 384.0777034917929, "episode": 38.0, "batch_reward": 0.21917769305408, "critic_loss": 0.39420316280424594, "actor_loss": -26.417560104370118, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.122960329055786, "step": 38000}
{"episode_reward": 133.9641152233733, "episode": 39.0, "batch_reward": 0.21779293021559715, "critic_loss": 0.38349112075567243, "actor_loss": -25.629471126556396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.71632671356201, "step": 39000}
{"episode_reward": 370.1952333234226, "episode": 40.0, "batch_reward": 0.22139252576231958, "critic_loss": 0.42066631415486333, "actor_loss": -26.155509044647218, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.69476866722107, "step": 40000}
{"episode_reward": 211.81115366612838, "episode": 41.0, "batch_reward": 0.22076822543144226, "critic_loss": 0.4140816557556391, "actor_loss": -26.06756739807129, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.398629665374756, "step": 41000}
{"episode_reward": 235.24886743694208, "episode": 42.0, "batch_reward": 0.22232958044111728, "critic_loss": 0.43016201597452164, "actor_loss": -26.49342216873169, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.622559785842896, "step": 42000}
{"episode_reward": 368.78643287570986, "episode": 43.0, "batch_reward": 0.2246012376099825, "critic_loss": 0.45460872124135493, "actor_loss": -26.586242351531983, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.452478170394897, "step": 43000}
{"episode_reward": 214.0776681862938, "episode": 44.0, "batch_reward": 0.2256323540210724, "critic_loss": 0.4607838131934404, "actor_loss": -27.02878209686279, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.45101022720337, "step": 44000}
{"episode_reward": 402.2208511620301, "episode": 45.0, "batch_reward": 0.22644671720266343, "critic_loss": 0.45559139481186867, "actor_loss": -26.432065326690672, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.73469853401184, "step": 45000}
{"episode_reward": 67.07609556841513, "episode": 46.0, "batch_reward": 0.22381862279772757, "critic_loss": 0.44241454899311067, "actor_loss": -26.622524909973144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.842419862747192, "step": 46000}
{"episode_reward": 177.8277168340408, "episode": 47.0, "batch_reward": 0.22347006326913835, "critic_loss": 0.4422020029127598, "actor_loss": -26.31770674133301, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.250388860702515, "step": 47000}
{"episode_reward": 109.1241504820623, "episode": 48.0, "batch_reward": 0.22291651971638202, "critic_loss": 0.44278737364709375, "actor_loss": -26.698614406585694, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.0409836769104, "step": 48000}
{"episode_reward": 407.41366073328163, "episode": 49.0, "batch_reward": 0.22706989514827727, "critic_loss": 0.4773811056762934, "actor_loss": -26.580567920684814, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.5341694355011, "step": 49000}
{"episode_reward": 468.8646297687162, "episode": 50.0, "batch_reward": 0.23066656596958637, "critic_loss": 0.4459175723791122, "actor_loss": -27.06202252960205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.124330520629883, "step": 50000}
{"episode_reward": 406.87294907360877, "episode": 51.0, "batch_reward": 0.23403729064762593, "critic_loss": 0.4174275009483099, "actor_loss": -27.460993801116942, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.363110065460205, "step": 51000}
{"episode_reward": 129.85087711066691, "episode": 52.0, "batch_reward": 0.23254727084934712, "critic_loss": 0.4048071734905243, "actor_loss": -27.340640239715576, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.881422519683838, "step": 52000}
{"episode_reward": 410.91324593439936, "episode": 53.0, "batch_reward": 0.2341486599445343, "critic_loss": 0.4377453716993332, "actor_loss": -27.776405517578127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.39977478981018, "step": 53000}
{"episode_reward": 125.55022891221242, "episode": 54.0, "batch_reward": 0.23306808602809906, "critic_loss": 0.434629493907094, "actor_loss": -27.68128575897217, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.706697702407837, "step": 54000}
{"episode_reward": 170.43675017992186, "episode": 55.0, "batch_reward": 0.23302949357032776, "critic_loss": 0.4438624135553837, "actor_loss": -27.59980100631714, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.816806077957153, "step": 55000}
{"episode_reward": 323.2836370900249, "episode": 56.0, "batch_reward": 0.23477377158403395, "critic_loss": 0.4473646212220192, "actor_loss": -27.72357305908203, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.949965953826904, "step": 56000}
{"episode_reward": 458.73580597365805, "episode": 57.0, "batch_reward": 0.2391099607348442, "critic_loss": 0.4442448759377003, "actor_loss": -28.232419742584227, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.464572429656982, "step": 57000}
{"episode_reward": 451.82779522112406, "episode": 58.0, "batch_reward": 0.2437381008565426, "critic_loss": 0.4150810964554548, "actor_loss": -28.882467220306395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.89163064956665, "step": 58000}
{"episode_reward": 484.10723102509866, "episode": 59.0, "batch_reward": 0.24567904986441136, "critic_loss": 0.39528675206005576, "actor_loss": -29.115554027557373, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.718261241912842, "step": 59000}
{"episode_reward": 150.0804483203954, "episode": 60.0, "batch_reward": 0.24477012413740157, "critic_loss": 0.41504289290308954, "actor_loss": -28.875856357574463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.65258264541626, "step": 60000}
{"episode_reward": 264.19538397874754, "episode": 61.0, "batch_reward": 0.24354697440564632, "critic_loss": 0.4291290571242571, "actor_loss": -28.88603060913086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.43262457847595, "step": 61000}
{"episode_reward": 78.24657520925615, "episode": 62.0, "batch_reward": 0.2422652519196272, "critic_loss": 0.41077171136438845, "actor_loss": -28.534798194885255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.52207660675049, "step": 62000}
{"episode_reward": 482.87385002920905, "episode": 63.0, "batch_reward": 0.24494673815369605, "critic_loss": 0.4426471224576235, "actor_loss": -28.989838275909424, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.932597637176514, "step": 63000}
{"episode_reward": 209.93613247995881, "episode": 64.0, "batch_reward": 0.24536254058778287, "critic_loss": 0.4180510265827179, "actor_loss": -28.793394260406494, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.41053342819214, "step": 64000}
{"episode_reward": 423.69918941083023, "episode": 65.0, "batch_reward": 0.24670876318216323, "critic_loss": 0.4696716165840626, "actor_loss": -28.991132625579834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.95173692703247, "step": 65000}
{"episode_reward": 119.78739109638522, "episode": 66.0, "batch_reward": 0.24666702105104923, "critic_loss": 0.3872737303078175, "actor_loss": -29.02043310928345, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.06954860687256, "step": 66000}
{"episode_reward": 416.989136814409, "episode": 67.0, "batch_reward": 0.24693958289921283, "critic_loss": 0.3959600843936205, "actor_loss": -29.001640167236328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.808467626571655, "step": 67000}
{"episode_reward": 73.02300618844876, "episode": 68.0, "batch_reward": 0.24621254628896713, "critic_loss": 0.39631254063546656, "actor_loss": -29.28833266830444, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.979324340820312, "step": 68000}
{"episode_reward": 324.3946633146866, "episode": 69.0, "batch_reward": 0.24634194925427436, "critic_loss": 0.4755878431200981, "actor_loss": -29.032066131591797, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.079452991485596, "step": 69000}
{"episode_reward": 147.0999838571374, "episode": 70.0, "batch_reward": 0.2448205722719431, "critic_loss": 0.414214947193861, "actor_loss": -28.45414178085327, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.78914523124695, "step": 70000}
{"episode_reward": 243.4103724881527, "episode": 71.0, "batch_reward": 0.2467079706043005, "critic_loss": 0.45908490504324434, "actor_loss": -28.715841152191164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.49052929878235, "step": 71000}
{"episode_reward": 191.4704301508801, "episode": 72.0, "batch_reward": 0.24459182767570017, "critic_loss": 0.44745461352169513, "actor_loss": -28.49872346878052, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.858640432357788, "step": 72000}
{"episode_reward": 148.88809332257676, "episode": 73.0, "batch_reward": 0.2438144064992666, "critic_loss": 0.4585599679648876, "actor_loss": -28.393234760284425, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.827296257019043, "step": 73000}
{"episode_reward": 548.6301093062352, "episode": 74.0, "batch_reward": 0.2497283725887537, "critic_loss": 0.414647928237915, "actor_loss": -28.74213402557373, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.86181330680847, "step": 74000}
{"episode_reward": 550.4235027393432, "episode": 75.0, "batch_reward": 0.250968442261219, "critic_loss": 0.41658768667280677, "actor_loss": -28.838755905151366, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.894900798797607, "step": 75000}
{"episode_reward": 123.07184241855525, "episode": 76.0, "batch_reward": 0.25117175386846063, "critic_loss": 0.3708718371838331, "actor_loss": -28.650299098968507, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.32437300682068, "step": 76000}
{"episode_reward": 370.78638774734685, "episode": 77.0, "batch_reward": 0.25164669124782085, "critic_loss": 0.4245149915665388, "actor_loss": -28.869954986572267, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.225650548934937, "step": 77000}
{"episode_reward": 484.7620559388433, "episode": 78.0, "batch_reward": 0.25284001997113226, "critic_loss": 0.3919296416044235, "actor_loss": -28.91924536514282, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.46664547920227, "step": 78000}
{"episode_reward": 25.03140839413312, "episode": 79.0, "batch_reward": 0.2504426123797894, "critic_loss": 0.3766417898386717, "actor_loss": -29.041084720611572, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.876770734786987, "step": 79000}
{"episode_reward": 59.381062607487095, "episode": 80.0, "batch_reward": 0.25075598433613777, "critic_loss": 0.409400416508317, "actor_loss": -28.814056102752687, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.732670307159424, "step": 80000}
{"episode_reward": 508.924087328839, "episode": 81.0, "batch_reward": 0.25432358534634114, "critic_loss": 0.39802021235227586, "actor_loss": -28.967342761993407, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.596821784973145, "step": 81000}
{"episode_reward": 586.7243650207032, "episode": 82.0, "batch_reward": 0.25788381160795687, "critic_loss": 0.34959413908421993, "actor_loss": -28.957111518859865, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.670165061950684, "step": 82000}
{"episode_reward": 548.62255346118, "episode": 83.0, "batch_reward": 0.26007989031076434, "critic_loss": 0.3278995166569948, "actor_loss": -29.65258882522583, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.32129168510437, "step": 83000}
{"episode_reward": 519.0758181369218, "episode": 84.0, "batch_reward": 0.2638887094706297, "critic_loss": 0.372180503025651, "actor_loss": -29.486777305603027, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.798742294311523, "step": 84000}
{"episode_reward": 264.48224900310476, "episode": 85.0, "batch_reward": 0.2643427783548832, "critic_loss": 0.3657012332379818, "actor_loss": -29.626230892181397, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.494411945343018, "step": 85000}
{"episode_reward": 465.3513128807486, "episode": 86.0, "batch_reward": 0.26686127193272113, "critic_loss": 0.35746743793785574, "actor_loss": -30.036853778839113, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.16696786880493, "step": 86000}
{"episode_reward": 573.2630459736982, "episode": 87.0, "batch_reward": 0.2700846830159426, "critic_loss": 0.34167324793338777, "actor_loss": -30.278512100219725, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.8779239654541, "step": 87000}
{"episode_reward": 570.9648672305855, "episode": 88.0, "batch_reward": 0.2739551145732403, "critic_loss": 0.3740801174342632, "actor_loss": -30.859818965911867, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.898322582244873, "step": 88000}
{"episode_reward": 544.5345707268068, "episode": 89.0, "batch_reward": 0.27660576432943346, "critic_loss": 0.32924738876521586, "actor_loss": -30.58527225112915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.744405031204224, "step": 89000}
{"episode_reward": 472.66515401949096, "episode": 90.0, "batch_reward": 0.27839799676835536, "critic_loss": 0.35990814001113175, "actor_loss": -30.6112172164917, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.726243257522583, "step": 90000}
{"episode_reward": 567.247077884291, "episode": 91.0, "batch_reward": 0.2831900067180395, "critic_loss": 0.3553100522458553, "actor_loss": -31.27280517578125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.50640368461609, "step": 91000}
{"episode_reward": 439.67003699336703, "episode": 92.0, "batch_reward": 0.2835083243846893, "critic_loss": 0.40576495008170604, "actor_loss": -31.43864910507202, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.36249327659607, "step": 92000}
{"episode_reward": 529.0810493059149, "episode": 93.0, "batch_reward": 0.2866863989382982, "critic_loss": 0.3530830955058336, "actor_loss": -31.723969444274903, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.896679162979126, "step": 93000}
{"episode_reward": 582.5838456086765, "episode": 94.0, "batch_reward": 0.29041389681398866, "critic_loss": 0.4007776430100203, "actor_loss": -32.05107377243042, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.91025424003601, "step": 94000}
{"episode_reward": 588.9418510458779, "episode": 95.0, "batch_reward": 0.29233754774928095, "critic_loss": 0.35021294225752353, "actor_loss": -31.78892238998413, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.8499653339386, "step": 95000}
{"episode_reward": 570.563045558101, "episode": 96.0, "batch_reward": 0.29652838994562625, "critic_loss": 0.39149262256920336, "actor_loss": -32.31796730804443, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.077709913253784, "step": 96000}
{"episode_reward": 557.3759722272619, "episode": 97.0, "batch_reward": 0.29817215651273726, "critic_loss": 0.40360929395258427, "actor_loss": -32.33671356201172, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.686421394348145, "step": 97000}
{"episode_reward": 447.90670945950205, "episode": 98.0, "batch_reward": 0.29765719155967235, "critic_loss": 0.3763698001801968, "actor_loss": -32.759628322601316, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.11494731903076, "step": 98000}
{"episode_reward": 53.34994722227326, "episode": 99.0, "batch_reward": 0.29700361895561217, "critic_loss": 0.4697968093305826, "actor_loss": -32.64267484664917, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.071290254592896, "step": 99000}
{"episode_reward": 564.5369833936659, "episode": 100.0, "batch_reward": 0.30085476753115653, "critic_loss": 0.3744053319692612, "actor_loss": -32.94992005157471, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.56648564338684, "step": 100000}
{"episode_reward": 574.073631604692, "episode": 101.0, "batch_reward": 0.3016587248295546, "critic_loss": 0.4017100235372782, "actor_loss": -32.91705508804321, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.54350447654724, "step": 101000}
{"episode_reward": 459.8253534977293, "episode": 102.0, "batch_reward": 0.3032057183533907, "critic_loss": 0.39329002279043196, "actor_loss": -33.15076554489136, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.159618854522705, "step": 102000}
{"episode_reward": 613.9509557017426, "episode": 103.0, "batch_reward": 0.3072882783710957, "critic_loss": 0.3685470850020647, "actor_loss": -33.51967218017578, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.183953285217285, "step": 103000}
{"episode_reward": 546.5272552542751, "episode": 104.0, "batch_reward": 0.3107839401513338, "critic_loss": 0.40562334847450254, "actor_loss": -33.801565353393556, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.94603729248047, "step": 104000}
{"episode_reward": 580.7528575675168, "episode": 105.0, "batch_reward": 0.31311517260968685, "critic_loss": 0.4474027609080076, "actor_loss": -33.993103202819825, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.684176683425903, "step": 105000}
{"episode_reward": 602.7297038761039, "episode": 106.0, "batch_reward": 0.3149951919019222, "critic_loss": 0.4401886412203312, "actor_loss": -34.47647012710571, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.09879422187805, "step": 106000}
{"episode_reward": 593.7822917377666, "episode": 107.0, "batch_reward": 0.3180999648869038, "critic_loss": 0.4035273534208536, "actor_loss": -34.55726356506348, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.92977023124695, "step": 107000}
{"episode_reward": 502.240493146514, "episode": 108.0, "batch_reward": 0.31913390961289406, "critic_loss": 0.3848805756568909, "actor_loss": -34.65121411895752, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.777857780456543, "step": 108000}
{"episode_reward": 496.19709002062706, "episode": 109.0, "batch_reward": 0.32150065270066264, "critic_loss": 0.4145608569085598, "actor_loss": -34.597833339691164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.885297536849976, "step": 109000}
{"episode_reward": 585.690822366188, "episode": 110.0, "batch_reward": 0.3234869710505009, "critic_loss": 0.43820442658662795, "actor_loss": -34.98752093505859, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.55696725845337, "step": 110000}
{"episode_reward": 632.0512424000405, "episode": 111.0, "batch_reward": 0.32605788043141365, "critic_loss": 0.43661672930419443, "actor_loss": -34.97859544372559, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.74424481391907, "step": 111000}
{"episode_reward": 651.945112540042, "episode": 112.0, "batch_reward": 0.3283460225760937, "critic_loss": 0.47487674295902255, "actor_loss": -35.34117687606812, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.352635145187378, "step": 112000}
{"episode_reward": 183.37368550462855, "episode": 113.0, "batch_reward": 0.32819701260328293, "critic_loss": 0.4358157054036856, "actor_loss": -35.27467248153687, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.168847799301147, "step": 113000}
{"episode_reward": 610.5560405672562, "episode": 114.0, "batch_reward": 0.3303542558550835, "critic_loss": 0.4981804233789444, "actor_loss": -35.46039463806152, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.903882026672363, "step": 114000}
{"episode_reward": 348.7724957299455, "episode": 115.0, "batch_reward": 0.3306480670273304, "critic_loss": 0.44324378645420076, "actor_loss": -35.49851322937012, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.422664642333984, "step": 115000}
{"episode_reward": 305.745830281903, "episode": 116.0, "batch_reward": 0.3299880444407463, "critic_loss": 0.4414823687821627, "actor_loss": -35.41272815322876, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.12121868133545, "step": 116000}
{"episode_reward": 319.0990733694695, "episode": 117.0, "batch_reward": 0.32968752378225324, "critic_loss": 0.45694928815960884, "actor_loss": -35.61905724716186, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.599686861038208, "step": 117000}
{"episode_reward": 277.219261025724, "episode": 118.0, "batch_reward": 0.3295735373198986, "critic_loss": 0.47201717081665995, "actor_loss": -35.35797483444214, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.940281629562378, "step": 118000}
{"episode_reward": 237.4115339375178, "episode": 119.0, "batch_reward": 0.33007472863793375, "critic_loss": 0.5007007289081812, "actor_loss": -35.42973267745972, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.309001922607422, "step": 119000}
{"episode_reward": 469.68847215404224, "episode": 120.0, "batch_reward": 0.32941167122125625, "critic_loss": 0.5373788905441761, "actor_loss": -35.671938735961916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.639825105667114, "step": 120000}
{"episode_reward": 294.3685485362133, "episode": 121.0, "batch_reward": 0.331512831389904, "critic_loss": 0.5407279498428106, "actor_loss": -35.68600172424316, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.639610290527344, "step": 121000}
{"episode_reward": 630.1979866201448, "episode": 122.0, "batch_reward": 0.33208462843298914, "critic_loss": 0.5113063499629498, "actor_loss": -35.791709053039554, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.156394958496094, "step": 122000}
{"episode_reward": 654.2407574916022, "episode": 123.0, "batch_reward": 0.33502692899107933, "critic_loss": 0.515495718434453, "actor_loss": -36.19838921737671, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.612294912338257, "step": 123000}
{"episode_reward": 444.06936843681433, "episode": 124.0, "batch_reward": 0.33505862298607825, "critic_loss": 0.5044415395110845, "actor_loss": -35.94352892684937, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.106423139572144, "step": 124000}
{"episode_reward": 613.8471910540513, "episode": 125.0, "batch_reward": 0.3376872462630272, "critic_loss": 0.5646022273600102, "actor_loss": -36.10773753738403, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.776580810546875, "step": 125000}
{"episode_reward": 596.5912311161984, "episode": 126.0, "batch_reward": 0.33863620710372927, "critic_loss": 0.46926762390136717, "actor_loss": -36.256313556671145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.926063776016235, "step": 126000}
{"episode_reward": 187.057932887448, "episode": 127.0, "batch_reward": 0.3394537306129932, "critic_loss": 0.526680025652051, "actor_loss": -36.28178931808472, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.914856433868408, "step": 127000}
{"episode_reward": 606.1586088626609, "episode": 128.0, "batch_reward": 0.3417647275924683, "critic_loss": 0.49517488294839856, "actor_loss": -36.38627278900147, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.389362573623657, "step": 128000}
{"episode_reward": 618.0324931577196, "episode": 129.0, "batch_reward": 0.3416759199500084, "critic_loss": 0.5095988624244928, "actor_loss": -36.3234525718689, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.064796686172485, "step": 129000}
{"episode_reward": 656.8449579624304, "episode": 130.0, "batch_reward": 0.34599385115504266, "critic_loss": 0.5153402494043112, "actor_loss": -36.877790451049805, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.95868682861328, "step": 130000}
{"episode_reward": 635.5607824525083, "episode": 131.0, "batch_reward": 0.34960072207450865, "critic_loss": 0.4887331095337868, "actor_loss": -36.88824440383911, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.8726761341095, "step": 131000}
{"episode_reward": 655.6816450344892, "episode": 132.0, "batch_reward": 0.3507679008543491, "critic_loss": 0.4942957853525877, "actor_loss": -37.22048119354248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.662405729293823, "step": 132000}
{"episode_reward": 499.97592477903896, "episode": 133.0, "batch_reward": 0.35134877389669417, "critic_loss": 0.5248771970272064, "actor_loss": -37.279191955566404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.389832019805908, "step": 133000}
{"episode_reward": 663.6730699909783, "episode": 134.0, "batch_reward": 0.35328678143024445, "critic_loss": 0.45768209947645666, "actor_loss": -37.39431470108032, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.992259979248047, "step": 134000}
{"episode_reward": 636.6523301363649, "episode": 135.0, "batch_reward": 0.3562909898161888, "critic_loss": 0.5584675756543874, "actor_loss": -37.67099415969849, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.66486096382141, "step": 135000}
{"episode_reward": 428.44506883492335, "episode": 136.0, "batch_reward": 0.355995261400938, "critic_loss": 0.5426596751958132, "actor_loss": -37.46632749557495, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.378435850143433, "step": 136000}
{"episode_reward": 212.13496571612401, "episode": 137.0, "batch_reward": 0.3561698268353939, "critic_loss": 0.5230527085065841, "actor_loss": -37.82784253692627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.720131635665894, "step": 137000}
{"episode_reward": 627.7339631416346, "episode": 138.0, "batch_reward": 0.35687554651498793, "critic_loss": 0.4950481110215187, "actor_loss": -37.991528713226316, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.947334051132202, "step": 138000}
{"episode_reward": 137.13241384603634, "episode": 139.0, "batch_reward": 0.35464080271124837, "critic_loss": 0.5285449591428042, "actor_loss": -37.7454116859436, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.152947425842285, "step": 139000}
{"episode_reward": 458.7017074228899, "episode": 140.0, "batch_reward": 0.35600788420438767, "critic_loss": 0.5338587237894535, "actor_loss": -37.80240761566162, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.62495231628418, "step": 140000}
{"episode_reward": 636.5539666842744, "episode": 141.0, "batch_reward": 0.35915425843000415, "critic_loss": 0.541858422011137, "actor_loss": -38.184361320495604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.8235297203064, "step": 141000}
{"episode_reward": 634.9541310427437, "episode": 142.0, "batch_reward": 0.3605026087760925, "critic_loss": 0.5029374229609966, "actor_loss": -38.046920181274416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.589434385299683, "step": 142000}
{"episode_reward": 486.6991815350583, "episode": 143.0, "batch_reward": 0.36040490421652793, "critic_loss": 0.5320217692106962, "actor_loss": -37.943968685150146, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.974178075790405, "step": 143000}
{"episode_reward": 284.3282201010781, "episode": 144.0, "batch_reward": 0.3619131017327309, "critic_loss": 0.5790441584140062, "actor_loss": -38.20417118835449, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.05888533592224, "step": 144000}
{"episode_reward": 610.4905368858219, "episode": 145.0, "batch_reward": 0.3639082883298397, "critic_loss": 0.5238088672608137, "actor_loss": -38.3340622215271, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.064743995666504, "step": 145000}
{"episode_reward": 632.9711954069845, "episode": 146.0, "batch_reward": 0.36330575409531596, "critic_loss": 0.5535346962511539, "actor_loss": -38.46228273773193, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.616708993911743, "step": 146000}
{"episode_reward": 596.8463101597184, "episode": 147.0, "batch_reward": 0.365361160159111, "critic_loss": 0.57819999101758, "actor_loss": -38.44950510406494, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.632940530776978, "step": 147000}
{"episode_reward": 567.2374327006538, "episode": 148.0, "batch_reward": 0.36723143893480303, "critic_loss": 0.5768370490819216, "actor_loss": -38.768711101531984, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.862300395965576, "step": 148000}
{"episode_reward": 605.3487958375415, "episode": 149.0, "batch_reward": 0.3698157595992088, "critic_loss": 0.5789810892939568, "actor_loss": -38.910377197265625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.542065382003784, "step": 149000}
{"episode_reward": 628.5009224069121, "episode": 150.0, "batch_reward": 0.37232913956046104, "critic_loss": 0.6130224862098694, "actor_loss": -39.181201663970946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
