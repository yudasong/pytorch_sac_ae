{"episode_reward": 0.0, "episode": 1.0, "duration": 13.991879940032959, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.2582981586456299, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.28030614866420167, "critic_loss": 0.05792676999192361, "actor_loss": -38.75825285571221, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 74.27375435829163, "step": 3000}
{"episode_reward": 33.42676636600403, "episode": 4.0, "batch_reward": 0.18236942579597235, "critic_loss": 0.07052791646495461, "actor_loss": -27.510995900034903, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27423071861267, "step": 4000}
{"episode_reward": 9.616226005493637, "episode": 5.0, "batch_reward": 0.14143278217315675, "critic_loss": 0.0557212049998343, "actor_loss": -27.803400681257248, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.089191436767578, "step": 5000}
{"episode_reward": 2.564343785125249, "episode": 6.0, "batch_reward": 0.11618428395316005, "critic_loss": 0.04090849840082228, "actor_loss": -26.798847745656968, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41755199432373, "step": 6000}
{"episode_reward": 6.732565420231069, "episode": 7.0, "batch_reward": 0.10023814062774182, "critic_loss": 0.03832289192080498, "actor_loss": -25.33550113129616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.191490411758423, "step": 7000}
{"episode_reward": 13.739154058233723, "episode": 8.0, "batch_reward": 0.09314667628705502, "critic_loss": 0.0654773814957589, "actor_loss": -25.59656201171875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.542664051055908, "step": 8000}
{"episode_reward": 93.69479514327345, "episode": 9.0, "batch_reward": 0.08998188666626811, "critic_loss": 0.056387807205319405, "actor_loss": -23.491504046678543, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.59229302406311, "step": 9000}
{"episode_reward": 48.55222269313071, "episode": 10.0, "batch_reward": 0.08625102138519287, "critic_loss": 0.07115002112835646, "actor_loss": -24.762847076654435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.25837731361389, "step": 10000}
{"episode_reward": 23.76800023387311, "episode": 11.0, "batch_reward": 0.07982169533893466, "critic_loss": 0.06676765026524663, "actor_loss": -23.26363176834583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.26617956161499, "step": 11000}
{"episode_reward": 17.63601839124643, "episode": 12.0, "batch_reward": 0.07703495733067393, "critic_loss": 0.10518855621106922, "actor_loss": -23.06701074755192, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.46056032180786, "step": 12000}
{"episode_reward": 105.03900846584526, "episode": 13.0, "batch_reward": 0.0831612536534667, "critic_loss": 0.1581105784997344, "actor_loss": -22.455567147612573, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.831661701202393, "step": 13000}
{"episode_reward": 174.6346010532099, "episode": 14.0, "batch_reward": 0.09264964893087745, "critic_loss": 0.18591563063114883, "actor_loss": -23.571549728810787, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3328115940094, "step": 14000}
{"episode_reward": 232.7548942101165, "episode": 15.0, "batch_reward": 0.09924241475015878, "critic_loss": 0.19172038862854243, "actor_loss": -21.522250409677625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.590567350387573, "step": 15000}
{"episode_reward": 213.37947122420888, "episode": 16.0, "batch_reward": 0.10588893055543304, "critic_loss": 0.18193140769004823, "actor_loss": -21.905866168692707, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54372811317444, "step": 16000}
{"episode_reward": 113.92474267145386, "episode": 17.0, "batch_reward": 0.10658158810436726, "critic_loss": 0.20154880376905202, "actor_loss": -22.25766193237901, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.02216124534607, "step": 17000}
{"episode_reward": 138.91667053212743, "episode": 18.0, "batch_reward": 0.11064659489691257, "critic_loss": 0.18669066268205642, "actor_loss": -22.39835928416252, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.361127138137817, "step": 18000}
{"episode_reward": 223.60350535322175, "episode": 19.0, "batch_reward": 0.11298218753188849, "critic_loss": 0.1898766415938735, "actor_loss": -21.058525444746017, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.580504417419434, "step": 19000}
{"episode_reward": 55.744659098296424, "episode": 20.0, "batch_reward": 0.11161652402579784, "critic_loss": 0.2193856610134244, "actor_loss": -20.282795496225358, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.446319818496704, "step": 20000}
{"episode_reward": 125.06802440820857, "episode": 21.0, "batch_reward": 0.11366729528456926, "critic_loss": 0.22089302576333283, "actor_loss": -19.487394952774046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.030744552612305, "step": 21000}
{"episode_reward": 195.7457668794562, "episode": 22.0, "batch_reward": 0.11821175554394722, "critic_loss": 0.23021182084083558, "actor_loss": -20.716943068504335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.857801914215088, "step": 22000}
{"episode_reward": 216.436342382755, "episode": 23.0, "batch_reward": 0.12253049765527248, "critic_loss": 0.22572080563008784, "actor_loss": -21.88008787059784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.05266308784485, "step": 23000}
{"episode_reward": 193.3480540670511, "episode": 24.0, "batch_reward": 0.12439343013614416, "critic_loss": 0.21875304368138312, "actor_loss": -21.014840297698974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.516207218170166, "step": 24000}
{"episode_reward": 218.98885748567233, "episode": 25.0, "batch_reward": 0.1289821885600686, "critic_loss": 0.25483806094527245, "actor_loss": -21.87909017562866, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.505826473236084, "step": 25000}
{"episode_reward": 156.56825664920495, "episode": 26.0, "batch_reward": 0.12917849070578813, "critic_loss": 0.2553275581151247, "actor_loss": -21.568614566802978, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.51521062850952, "step": 26000}
{"episode_reward": 134.7608518649715, "episode": 27.0, "batch_reward": 0.1324233765974641, "critic_loss": 0.27105490578711033, "actor_loss": -21.48112598991394, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.162424087524414, "step": 27000}
{"episode_reward": 282.90269753208486, "episode": 28.0, "batch_reward": 0.1355559803545475, "critic_loss": 0.2649804041981697, "actor_loss": -21.688400162696837, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.750297784805298, "step": 28000}
{"episode_reward": 224.86971463276072, "episode": 29.0, "batch_reward": 0.13779954928904772, "critic_loss": 0.29557604345679284, "actor_loss": -20.50092047405243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.203760147094727, "step": 29000}
{"episode_reward": 46.24078507256997, "episode": 30.0, "batch_reward": 0.1375472634732723, "critic_loss": 0.3017164763361216, "actor_loss": -20.701362233161927, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.316059827804565, "step": 30000}
{"episode_reward": 260.2578408952994, "episode": 31.0, "batch_reward": 0.14117194267362357, "critic_loss": 0.31740311639010904, "actor_loss": -20.34408231163025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.82780981063843, "step": 31000}
{"episode_reward": 319.44075586432, "episode": 32.0, "batch_reward": 0.14680373819172382, "critic_loss": 0.3578223380297422, "actor_loss": -20.893069900512696, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.77234697341919, "step": 32000}
{"episode_reward": 292.6228875055494, "episode": 33.0, "batch_reward": 0.1512099491879344, "critic_loss": 0.3702391082644463, "actor_loss": -21.048691259384157, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.83825945854187, "step": 33000}
{"episode_reward": 232.70994578858014, "episode": 34.0, "batch_reward": 0.15259011499583722, "critic_loss": 0.36928544825315474, "actor_loss": -22.337736192703247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.075501203536987, "step": 34000}
{"episode_reward": 172.80279659623082, "episode": 35.0, "batch_reward": 0.1541640082076192, "critic_loss": 0.37169808211922645, "actor_loss": -21.181392601013183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.581944465637207, "step": 35000}
{"episode_reward": 237.25449629003745, "episode": 36.0, "batch_reward": 0.1556869112625718, "critic_loss": 0.391732567474246, "actor_loss": -22.081982316970826, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.599192142486572, "step": 36000}
{"episode_reward": 194.7118588556782, "episode": 37.0, "batch_reward": 0.15708213593810796, "critic_loss": 0.39503368248045445, "actor_loss": -21.664786031723022, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.434498071670532, "step": 37000}
{"episode_reward": 293.8318914932496, "episode": 38.0, "batch_reward": 0.16202201368659735, "critic_loss": 0.4922464116662741, "actor_loss": -21.424088285446167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.520628690719604, "step": 38000}
{"episode_reward": 244.35756559075074, "episode": 39.0, "batch_reward": 0.16160116942971944, "critic_loss": 0.4855337754487991, "actor_loss": -21.06472900772095, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.53279447555542, "step": 39000}
{"episode_reward": 103.22652714982888, "episode": 40.0, "batch_reward": 0.1616322263479233, "critic_loss": 0.4990058928728104, "actor_loss": -20.970847707748412, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.67112636566162, "step": 40000}
{"episode_reward": 282.6183653760207, "episode": 41.0, "batch_reward": 0.165005485445261, "critic_loss": 0.5383523461818696, "actor_loss": -21.509892837524415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.67300581932068, "step": 41000}
{"episode_reward": 248.80555750381552, "episode": 42.0, "batch_reward": 0.1670162196457386, "critic_loss": 0.5391630076020956, "actor_loss": -21.972085779190063, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.180585384368896, "step": 42000}
{"episode_reward": 206.39900284458304, "episode": 43.0, "batch_reward": 0.16625399262458085, "critic_loss": 0.5398535293638707, "actor_loss": -21.71858390045166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.43753433227539, "step": 43000}
{"episode_reward": 90.6925153621244, "episode": 44.0, "batch_reward": 0.16632104209065438, "critic_loss": 0.5233341220021248, "actor_loss": -21.98766526031494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.760685443878174, "step": 44000}
{"episode_reward": 384.02701869660035, "episode": 45.0, "batch_reward": 0.1718665965050459, "critic_loss": 0.5186693343818187, "actor_loss": -22.49487712287903, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.71530294418335, "step": 45000}
{"episode_reward": 363.6070228699516, "episode": 46.0, "batch_reward": 0.1727697011679411, "critic_loss": 0.5017194775342941, "actor_loss": -23.024924793243407, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34725332260132, "step": 46000}
{"episode_reward": 71.60681960005755, "episode": 47.0, "batch_reward": 0.17416413804888725, "critic_loss": 0.5243869786560535, "actor_loss": -22.577983219146727, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.649611711502075, "step": 47000}
{"episode_reward": 302.84334318021536, "episode": 48.0, "batch_reward": 0.17609637162089348, "critic_loss": 0.5289585327059031, "actor_loss": -23.40373638534546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.00944209098816, "step": 48000}
{"episode_reward": 278.6034244227215, "episode": 49.0, "batch_reward": 0.17660201400518416, "critic_loss": 0.5865204195380211, "actor_loss": -22.85677660369873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.67570996284485, "step": 49000}
{"episode_reward": 79.60287032036429, "episode": 50.0, "batch_reward": 0.17436937886476517, "critic_loss": 0.589003815278411, "actor_loss": -22.881466953277588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.534588098526, "step": 50000}
{"episode_reward": 154.8151969486003, "episode": 51.0, "batch_reward": 0.1752029547393322, "critic_loss": 0.5951238233596087, "actor_loss": -23.10792268371582, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.62267446517944, "step": 51000}
{"episode_reward": 154.5830917178501, "episode": 52.0, "batch_reward": 0.17477454666793346, "critic_loss": 0.5202968366146088, "actor_loss": -23.281951385498047, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.76652717590332, "step": 52000}
{"episode_reward": 268.2867795870567, "episode": 53.0, "batch_reward": 0.17715526400506496, "critic_loss": 0.5341946201771498, "actor_loss": -23.720659996032715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.75671076774597, "step": 53000}
{"episode_reward": 293.0250277128169, "episode": 54.0, "batch_reward": 0.17891456148028373, "critic_loss": 0.5612006479948759, "actor_loss": -24.33270020675659, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.990169286727905, "step": 54000}
{"episode_reward": 250.07846416928575, "episode": 55.0, "batch_reward": 0.17978176006674768, "critic_loss": 0.5165585539340973, "actor_loss": -24.189873935699463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.026142835617065, "step": 55000}
{"episode_reward": 123.14534873609871, "episode": 56.0, "batch_reward": 0.1796300918906927, "critic_loss": 0.5861315008252859, "actor_loss": -24.479788917541505, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.784913778305054, "step": 56000}
{"episode_reward": 315.5530670849933, "episode": 57.0, "batch_reward": 0.18202921475470066, "critic_loss": 0.5903776270747185, "actor_loss": -25.152883045196532, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.801563501358032, "step": 57000}
{"episode_reward": 148.79202523355343, "episode": 58.0, "batch_reward": 0.18021266363561153, "critic_loss": 0.5763758706897497, "actor_loss": -24.960814933776856, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.877351760864258, "step": 58000}
{"episode_reward": 126.09962239339575, "episode": 59.0, "batch_reward": 0.18104812581837176, "critic_loss": 0.6182781502604484, "actor_loss": -25.138968200683593, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.851900577545166, "step": 59000}
{"episode_reward": 337.09999412928295, "episode": 60.0, "batch_reward": 0.18321704991161825, "critic_loss": 0.6151043260097504, "actor_loss": -25.500937271118165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.64606285095215, "step": 60000}
{"episode_reward": 185.09306285841802, "episode": 61.0, "batch_reward": 0.18271772366762162, "critic_loss": 0.6332574501037598, "actor_loss": -25.56478949356079, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.97655272483826, "step": 61000}
{"episode_reward": 137.14802721175533, "episode": 62.0, "batch_reward": 0.1805426365286112, "critic_loss": 0.5894103751480579, "actor_loss": -25.08192116546631, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.15275526046753, "step": 62000}
{"episode_reward": 52.78089743852406, "episode": 63.0, "batch_reward": 0.17766639971733092, "critic_loss": 0.7170898897796869, "actor_loss": -24.989073291778563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.46155095100403, "step": 63000}
{"episode_reward": 109.30668011631174, "episode": 64.0, "batch_reward": 0.17780385573208332, "critic_loss": 0.6530259471684694, "actor_loss": -25.051928436279297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.599181175231934, "step": 64000}
{"episode_reward": 116.70184765362852, "episode": 65.0, "batch_reward": 0.1770386125445366, "critic_loss": 0.6592263393104076, "actor_loss": -25.15028996658325, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.189899921417236, "step": 65000}
{"episode_reward": 89.69150868525662, "episode": 66.0, "batch_reward": 0.1762272049486637, "critic_loss": 0.6662267408967019, "actor_loss": -25.083182662963868, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.62806797027588, "step": 66000}
{"episode_reward": 85.69657605972262, "episode": 67.0, "batch_reward": 0.1740066117197275, "critic_loss": 0.6218951385766268, "actor_loss": -24.894530227661132, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.698264598846436, "step": 67000}
{"episode_reward": 55.32239881446281, "episode": 68.0, "batch_reward": 0.17229334484785797, "critic_loss": 0.7663960047364234, "actor_loss": -24.803023986816406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.842037439346313, "step": 68000}
{"episode_reward": 166.43372042371308, "episode": 69.0, "batch_reward": 0.17282709313184022, "critic_loss": 0.7815351833254099, "actor_loss": -24.770160789489747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.87050199508667, "step": 69000}
{"episode_reward": 239.178544466802, "episode": 70.0, "batch_reward": 0.174274273827672, "critic_loss": 0.7385683803260327, "actor_loss": -25.00761986541748, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.671719551086426, "step": 70000}
{"episode_reward": 354.77304601878666, "episode": 71.0, "batch_reward": 0.1778003857806325, "critic_loss": 0.7187778552472591, "actor_loss": -25.35868716430664, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.2627968788147, "step": 71000}
{"episode_reward": 297.8036288977166, "episode": 72.0, "batch_reward": 0.1781077438443899, "critic_loss": 0.7158215139806271, "actor_loss": -25.31133618545532, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.73187804222107, "step": 72000}
{"episode_reward": 139.97738275067087, "episode": 73.0, "batch_reward": 0.17640299742668866, "critic_loss": 0.6761949402093888, "actor_loss": -25.30874765777588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.519277811050415, "step": 73000}
{"episode_reward": 46.455127737346814, "episode": 74.0, "batch_reward": 0.17529467467963694, "critic_loss": 0.7404233873486519, "actor_loss": -24.956015453338622, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.97739005088806, "step": 74000}
{"episode_reward": 202.1977094897978, "episode": 75.0, "batch_reward": 0.17701134204864502, "critic_loss": 0.734532395735383, "actor_loss": -25.2755221786499, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.60064387321472, "step": 75000}
{"episode_reward": 245.31539540215653, "episode": 76.0, "batch_reward": 0.17708457079529763, "critic_loss": 0.7051884371042252, "actor_loss": -25.229831169128417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.644035577774048, "step": 76000}
{"episode_reward": 357.67957072126995, "episode": 77.0, "batch_reward": 0.18072564579546452, "critic_loss": 0.6820815478861332, "actor_loss": -25.739937770843508, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.326011657714844, "step": 77000}
{"episode_reward": 201.27969315498862, "episode": 78.0, "batch_reward": 0.17945276233553886, "critic_loss": 0.6744328670948744, "actor_loss": -25.448944679260254, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.74235725402832, "step": 78000}
{"episode_reward": 137.1959212958458, "episode": 79.0, "batch_reward": 0.17994564041495323, "critic_loss": 0.6961975340545178, "actor_loss": -25.769083923339842, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.83651065826416, "step": 79000}
{"episode_reward": 280.2391262715263, "episode": 80.0, "batch_reward": 0.18033100375533104, "critic_loss": 0.6333255278468132, "actor_loss": -25.485127841949463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.725332498550415, "step": 80000}
{"episode_reward": 442.17403064528884, "episode": 81.0, "batch_reward": 0.18531376147270204, "critic_loss": 0.6678828285336494, "actor_loss": -25.95101467895508, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.94268774986267, "step": 81000}
{"episode_reward": 469.5746008202683, "episode": 82.0, "batch_reward": 0.18877155067026616, "critic_loss": 0.5920390256494283, "actor_loss": -26.116244480133055, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.698736906051636, "step": 82000}
{"episode_reward": 393.0386351280989, "episode": 83.0, "batch_reward": 0.19116067454218866, "critic_loss": 0.6059765473604203, "actor_loss": -26.49022261428833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.629382133483887, "step": 83000}
{"episode_reward": 447.69491923050225, "episode": 84.0, "batch_reward": 0.19239176607131958, "critic_loss": 0.690569733440876, "actor_loss": -26.351325103759766, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.829556703567505, "step": 84000}
{"episode_reward": 210.23508368977494, "episode": 85.0, "batch_reward": 0.19371435177326202, "critic_loss": 0.6182555980086326, "actor_loss": -26.62141911315918, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.549293041229248, "step": 85000}
{"episode_reward": 380.3410806106811, "episode": 86.0, "batch_reward": 0.19547765162587166, "critic_loss": 0.6481930227577686, "actor_loss": -26.70378715133667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.507180213928223, "step": 86000}
{"episode_reward": 462.2764458968848, "episode": 87.0, "batch_reward": 0.19939533686637878, "critic_loss": 0.6276550351977348, "actor_loss": -27.152110050201415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.979740619659424, "step": 87000}
{"episode_reward": 400.40748593375105, "episode": 88.0, "batch_reward": 0.2020008326768875, "critic_loss": 0.6362774173915386, "actor_loss": -27.507577938079834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.73252248764038, "step": 88000}
{"episode_reward": 517.524103920131, "episode": 89.0, "batch_reward": 0.20490142147243023, "critic_loss": 0.5556788893491029, "actor_loss": -27.56887031555176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.90156865119934, "step": 89000}
{"episode_reward": 406.52329742093025, "episode": 90.0, "batch_reward": 0.2051719538718462, "critic_loss": 0.580588284060359, "actor_loss": -27.561843852996827, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.47394895553589, "step": 90000}
{"episode_reward": 49.447385525085586, "episode": 91.0, "batch_reward": 0.20396917527914046, "critic_loss": 0.5351749614775181, "actor_loss": -27.39680859375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.72463083267212, "step": 91000}
{"episode_reward": 31.19987479541233, "episode": 92.0, "batch_reward": 0.2039727096706629, "critic_loss": 0.5236263234466314, "actor_loss": -27.36615718460083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.761205673217773, "step": 92000}
{"episode_reward": 347.15563584498466, "episode": 93.0, "batch_reward": 0.20343213415145875, "critic_loss": 0.5171973570436239, "actor_loss": -27.22172311782837, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.909269094467163, "step": 93000}
{"episode_reward": 39.07701568553724, "episode": 94.0, "batch_reward": 0.20398912627995014, "critic_loss": 0.49321796414256097, "actor_loss": -27.227657508850097, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.859363555908203, "step": 94000}
{"episode_reward": 494.587346498583, "episode": 95.0, "batch_reward": 0.20697367899119853, "critic_loss": 0.4899131055623293, "actor_loss": -27.41017512512207, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.57628870010376, "step": 95000}
{"episode_reward": 490.66161682783354, "episode": 96.0, "batch_reward": 0.20747591297328472, "critic_loss": 0.468445822224021, "actor_loss": -27.325162563323975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.754314184188843, "step": 96000}
{"episode_reward": 33.85003396614829, "episode": 97.0, "batch_reward": 0.2068206771016121, "critic_loss": 0.47304227328300474, "actor_loss": -27.21523131942749, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.675307989120483, "step": 97000}
{"episode_reward": 191.0883815992992, "episode": 98.0, "batch_reward": 0.20700776860117912, "critic_loss": 0.5032313428074121, "actor_loss": -27.206166942596436, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.48323917388916, "step": 98000}
{"episode_reward": 490.0158677196538, "episode": 99.0, "batch_reward": 0.21006009009480475, "critic_loss": 0.49414421094954014, "actor_loss": -27.590363258361815, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.730647087097168, "step": 99000}
{"episode_reward": 507.4306833765622, "episode": 100.0, "batch_reward": 0.2133493711054325, "critic_loss": 0.48109739223122594, "actor_loss": -27.816365936279297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.505584478378296, "step": 100000}
{"episode_reward": 519.8568883578816, "episode": 101.0, "batch_reward": 0.21530754010379313, "critic_loss": 0.542276452049613, "actor_loss": -28.182441806793214, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.971619606018066, "step": 101000}
{"episode_reward": 2.015097954943996, "episode": 102.0, "batch_reward": 0.21218861761689187, "critic_loss": 0.5283631004691124, "actor_loss": -28.258902153015136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.564977407455444, "step": 102000}
{"episode_reward": 1.7030218137679736, "episode": 103.0, "batch_reward": 0.2116341888308525, "critic_loss": 0.5059728292524814, "actor_loss": -28.606174270629882, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.337751865386963, "step": 103000}
{"episode_reward": 421.37171016215734, "episode": 104.0, "batch_reward": 0.21288517957925795, "critic_loss": 0.5105069254785776, "actor_loss": -28.86109529876709, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.723331928253174, "step": 104000}
{"episode_reward": 3.362565928047883, "episode": 105.0, "batch_reward": 0.21001648604869844, "critic_loss": 0.5609549693316221, "actor_loss": -29.05148239517212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.449631214141846, "step": 105000}
{"episode_reward": 4.176661752408109, "episode": 106.0, "batch_reward": 0.20843622897565364, "critic_loss": 0.5219436251074075, "actor_loss": -29.273329154968263, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.173454999923706, "step": 106000}
{"episode_reward": 2.9097391158335055, "episode": 107.0, "batch_reward": 0.20630126337707042, "critic_loss": 0.5011286329030991, "actor_loss": -29.29231219482422, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.686463832855225, "step": 107000}
{"episode_reward": 1.4825126437974478, "episode": 108.0, "batch_reward": 0.20447718980908394, "critic_loss": 0.5092808325737714, "actor_loss": -29.20934550476074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.601481199264526, "step": 108000}
{"episode_reward": 2.7704273047959327, "episode": 109.0, "batch_reward": 0.2017644230723381, "critic_loss": 0.5031171685904264, "actor_loss": -29.097933490753174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.791917085647583, "step": 109000}
{"episode_reward": 2.9523631589527417, "episode": 110.0, "batch_reward": 0.2008478120416403, "critic_loss": 0.4628631444275379, "actor_loss": -29.300479625701904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.635648488998413, "step": 110000}
{"episode_reward": 5.641301088211929, "episode": 111.0, "batch_reward": 0.19841984997689724, "critic_loss": 0.45923544771969316, "actor_loss": -29.172682041168212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.91026973724365, "step": 111000}
{"episode_reward": 0.6289691460027722, "episode": 112.0, "batch_reward": 0.1968753223568201, "critic_loss": 0.4252456139922142, "actor_loss": -29.157291809082032, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.49444603919983, "step": 112000}
{"episode_reward": 0.4383378160012632, "episode": 113.0, "batch_reward": 0.1955221307426691, "critic_loss": 0.3739358104020357, "actor_loss": -29.02340403366089, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.891921281814575, "step": 113000}
{"episode_reward": 1.0399296894699988, "episode": 114.0, "batch_reward": 0.19341286817193032, "critic_loss": 0.40814088106155394, "actor_loss": -28.760109111785887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.75342297554016, "step": 114000}
{"episode_reward": 0.6124264228053401, "episode": 115.0, "batch_reward": 0.19204399959743024, "critic_loss": 0.361248612254858, "actor_loss": -28.801317665100097, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.820501804351807, "step": 115000}
{"episode_reward": 0.5209534993572342, "episode": 116.0, "batch_reward": 0.19103268860280515, "critic_loss": 0.3882674363553524, "actor_loss": -28.753427879333497, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.381538152694702, "step": 116000}
{"episode_reward": 1.515778667050602, "episode": 117.0, "batch_reward": 0.1906562932729721, "critic_loss": 0.36282144479453565, "actor_loss": -28.61597560119629, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.8276264667511, "step": 117000}
{"episode_reward": 340.17609595737963, "episode": 118.0, "batch_reward": 0.19179320135712624, "critic_loss": 0.3715473514944315, "actor_loss": -28.31211166381836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.930986166000366, "step": 118000}
{"episode_reward": 280.67707702490605, "episode": 119.0, "batch_reward": 0.1928181386888027, "critic_loss": 0.39202423974871636, "actor_loss": -28.140267776489257, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.049583196640015, "step": 119000}
{"episode_reward": 489.95818040962996, "episode": 120.0, "batch_reward": 0.1950321864336729, "critic_loss": 0.4071357820481062, "actor_loss": -28.233091426849366, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.842536687850952, "step": 120000}
{"episode_reward": 529.8029734094664, "episode": 121.0, "batch_reward": 0.19789523528516292, "critic_loss": 0.4114041830450296, "actor_loss": -28.411760063171386, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.67838454246521, "step": 121000}
{"episode_reward": 556.7978690793592, "episode": 122.0, "batch_reward": 0.2015416659116745, "critic_loss": 0.41185612699389457, "actor_loss": -28.47035001373291, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.891145944595337, "step": 122000}
{"episode_reward": 517.5331541066197, "episode": 123.0, "batch_reward": 0.2047320412248373, "critic_loss": 0.39506566101312635, "actor_loss": -28.72336217498779, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.028634786605835, "step": 123000}
{"episode_reward": 530.593639792868, "episode": 124.0, "batch_reward": 0.20476458786427976, "critic_loss": 0.41825309716165066, "actor_loss": -28.50374045562744, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27857279777527, "step": 124000}
{"episode_reward": 274.40716058717226, "episode": 125.0, "batch_reward": 0.20805428497493267, "critic_loss": 0.4224284171760082, "actor_loss": -28.81578363418579, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.741692066192627, "step": 125000}
{"episode_reward": 535.9480941436781, "episode": 126.0, "batch_reward": 0.20905518870055675, "critic_loss": 0.38833117704093456, "actor_loss": -29.019809818267824, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.358427047729492, "step": 126000}
{"episode_reward": 509.73473970233476, "episode": 127.0, "batch_reward": 0.2119076227992773, "critic_loss": 0.3854780373573303, "actor_loss": -28.9756083984375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.69036102294922, "step": 127000}
{"episode_reward": 598.2941345772176, "episode": 128.0, "batch_reward": 0.21470717327296734, "critic_loss": 0.3748667684346437, "actor_loss": -29.04046102142334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.75685715675354, "step": 128000}
{"episode_reward": 546.3214112044635, "episode": 129.0, "batch_reward": 0.21635151219367982, "critic_loss": 0.3601643900871277, "actor_loss": -29.41867657852173, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.69735550880432, "step": 129000}
{"episode_reward": 570.8941370605052, "episode": 130.0, "batch_reward": 0.21934516231715678, "critic_loss": 0.39721207551658155, "actor_loss": -29.71005512237549, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.677800178527832, "step": 130000}
{"episode_reward": 539.8255652404382, "episode": 131.0, "batch_reward": 0.2235829951316118, "critic_loss": 0.3530207789838314, "actor_loss": -29.96672750091553, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.0284960269928, "step": 131000}
{"episode_reward": 578.0595867184086, "episode": 132.0, "batch_reward": 0.22610798205435276, "critic_loss": 0.3627663420289755, "actor_loss": -30.23499255371094, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.878475189208984, "step": 132000}
{"episode_reward": 568.9826346561209, "episode": 133.0, "batch_reward": 0.22859935609996318, "critic_loss": 0.3428152220547199, "actor_loss": -30.610866714477538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.050701379776, "step": 133000}
{"episode_reward": 596.781794528278, "episode": 134.0, "batch_reward": 0.22989653877913951, "critic_loss": 0.3535942965224385, "actor_loss": -30.62002233123779, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.735667943954468, "step": 134000}
{"episode_reward": 584.37910941877, "episode": 135.0, "batch_reward": 0.23315556398034096, "critic_loss": 0.3443007982522249, "actor_loss": -30.91401644897461, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.65450096130371, "step": 135000}
{"episode_reward": 542.2114015174506, "episode": 136.0, "batch_reward": 0.23624009184539319, "critic_loss": 0.34655811482667925, "actor_loss": -30.814716453552247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.56455397605896, "step": 136000}
{"episode_reward": 558.3200779785656, "episode": 137.0, "batch_reward": 0.23587356823682784, "critic_loss": 0.329781333565712, "actor_loss": -31.00351239013672, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.844982624053955, "step": 137000}
{"episode_reward": 11.83276870420769, "episode": 138.0, "batch_reward": 0.23612776815891265, "critic_loss": 0.3345493723601103, "actor_loss": -31.282348876953126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.996788501739502, "step": 138000}
{"episode_reward": 395.95329301476374, "episode": 139.0, "batch_reward": 0.2369234314262867, "critic_loss": 0.3390892542302609, "actor_loss": -31.429420551300048, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.353694438934326, "step": 139000}
{"episode_reward": 184.65699914858598, "episode": 140.0, "batch_reward": 0.23649619859457016, "critic_loss": 0.3329088570177555, "actor_loss": -31.50368263244629, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23588514328003, "step": 140000}
{"episode_reward": 597.7089274427382, "episode": 141.0, "batch_reward": 0.23982154548168183, "critic_loss": 0.3406058510094881, "actor_loss": -31.530856670379638, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.75535821914673, "step": 141000}
{"episode_reward": 438.5788874531768, "episode": 142.0, "batch_reward": 0.240137839153409, "critic_loss": 0.3164384580552578, "actor_loss": -31.470974239349367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.52936053276062, "step": 142000}
{"episode_reward": 110.78095803511063, "episode": 143.0, "batch_reward": 0.24127570289373398, "critic_loss": 0.32380752313137057, "actor_loss": -31.46675736618042, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.911062717437744, "step": 143000}
{"episode_reward": 557.2728731113527, "episode": 144.0, "batch_reward": 0.2414086199849844, "critic_loss": 0.34096942172944544, "actor_loss": -31.565324867248535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.277477264404297, "step": 144000}
{"episode_reward": 71.3025606297874, "episode": 145.0, "batch_reward": 0.2421041508167982, "critic_loss": 0.3476440843194723, "actor_loss": -31.51321425628662, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.353217124938965, "step": 145000}
{"episode_reward": 550.1533740689724, "episode": 146.0, "batch_reward": 0.24310321220755576, "critic_loss": 0.3098218663483858, "actor_loss": -31.538147972106934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.881266355514526, "step": 146000}
{"episode_reward": 587.9329881114837, "episode": 147.0, "batch_reward": 0.2450140227675438, "critic_loss": 0.33105113802850245, "actor_loss": -31.51309581375122, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.668214559555054, "step": 147000}
{"episode_reward": 597.6303329607273, "episode": 148.0, "batch_reward": 0.2484702644199133, "critic_loss": 0.3227154064178467, "actor_loss": -31.818020561218262, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.990315198898315, "step": 148000}
{"episode_reward": 169.2056072654128, "episode": 149.0, "batch_reward": 0.2463981785774231, "critic_loss": 0.31588032498955726, "actor_loss": -31.575315689086914, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.42679238319397, "step": 149000}
{"episode_reward": 305.94696357684364, "episode": 150.0, "batch_reward": 0.24921605265140534, "critic_loss": 0.36793383191525936, "actor_loss": -31.96033867263794, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
