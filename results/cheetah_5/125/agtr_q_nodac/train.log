{"episode": 1.0, "duration": 11.400660276412964, "episode_reward": 7.579367547095394, "step": 1000}
{"episode": 2.0, "duration": 1.0272867679595947, "episode_reward": 587.3438790414032, "step": 2000}
{"episode": 3.0, "batch_reward": 0.281274997197258, "actor_loss": -48.202552006215086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 53.121883153915405, "episode_reward": 23.74517794277326, "step": 3000}
{"episode": 4.0, "batch_reward": 0.1829277354478836, "actor_loss": -42.723971221923826, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.4542076587677, "episode_reward": 66.19003596108979, "step": 4000}
{"episode": 5.0, "batch_reward": 0.17352623234689235, "actor_loss": -40.398315933227536, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.996158123016357, "episode_reward": 141.31819007005737, "step": 5000}
{"episode": 6.0, "batch_reward": 0.16293353863805532, "actor_loss": -37.02643965911865, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.20706820487976, "episode_reward": 134.5774406777876, "step": 6000}
{"episode": 7.0, "batch_reward": 0.15151293796300888, "actor_loss": -35.43215965652466, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.941515922546387, "episode_reward": 35.26771991221244, "step": 7000}
{"episode": 8.0, "batch_reward": 0.1380653002858162, "actor_loss": -32.91793634414673, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.247230529785156, "episode_reward": 58.43671798373871, "step": 8000}
{"episode": 9.0, "batch_reward": 0.13523656853288413, "actor_loss": -32.94399461364746, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.227067947387695, "episode_reward": 200.80374291528446, "step": 9000}
{"episode": 10.0, "batch_reward": 0.13915473283827304, "actor_loss": -32.70263449478149, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.279069900512695, "episode_reward": 84.25536607396282, "step": 10000}
{"episode": 11.0, "batch_reward": 0.13520022273808718, "actor_loss": -31.8863349609375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 39.762338399887085, "episode_reward": 115.31811525283513, "step": 11000}
{"episode": 12.0, "batch_reward": 0.1334669387564063, "actor_loss": -31.568494396209715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.98374652862549, "episode_reward": 148.3611757773235, "step": 12000}
{"episode": 13.0, "batch_reward": 0.1357147399112582, "actor_loss": -32.38061568450928, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.83154582977295, "episode_reward": 249.37049449821743, "step": 13000}
{"episode": 14.0, "batch_reward": 0.14581442154943944, "actor_loss": -33.247937183380124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.52397322654724, "episode_reward": 251.45343375763605, "step": 14000}
{"episode": 15.0, "batch_reward": 0.14893522964417935, "actor_loss": -33.863039855957034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.987784147262573, "episode_reward": 78.80787330956821, "step": 15000}
{"episode": 16.0, "batch_reward": 0.14609917776286602, "actor_loss": -33.71228360748291, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.15998125076294, "episode_reward": 208.54974945313907, "step": 16000}
{"episode": 17.0, "batch_reward": 0.15293271204084158, "actor_loss": -34.45154383468628, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.644237995147705, "episode_reward": 259.46345592420465, "step": 17000}
{"episode": 18.0, "batch_reward": 0.157798209130764, "actor_loss": -34.871537815093994, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.765089750289917, "episode_reward": 175.0775044818708, "step": 18000}
{"episode": 19.0, "batch_reward": 0.15740158341079952, "actor_loss": -35.12377611541748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.37969207763672, "episode_reward": 220.71040866966365, "step": 19000}
{"episode": 20.0, "batch_reward": 0.16203888875246047, "actor_loss": -35.64386728668213, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.765154600143433, "episode_reward": 277.3393852188537, "step": 20000}
{"episode": 21.0, "batch_reward": 0.1659935930967331, "actor_loss": -35.88049844741821, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 39.3643536567688, "episode_reward": 106.83566892562692, "step": 21000}
{"episode": 22.0, "batch_reward": 0.16299719926714898, "actor_loss": -34.96016158676147, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.04934525489807, "episode_reward": 100.55499806403114, "step": 22000}
{"episode": 23.0, "batch_reward": 0.16060584089159965, "actor_loss": -34.45969069671631, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.33558678627014, "episode_reward": 177.6986141435802, "step": 23000}
{"episode": 24.0, "batch_reward": 0.16082977813482285, "actor_loss": -34.731238723754885, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.145369291305542, "episode_reward": 139.82120791257293, "step": 24000}
{"episode": 25.0, "batch_reward": 0.1624006499275565, "actor_loss": -35.03761943817139, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.078503131866455, "episode_reward": 301.3441316933389, "step": 25000}
{"episode": 26.0, "batch_reward": 0.16728154268860818, "actor_loss": -35.55339952850342, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.226737022399902, "episode_reward": 331.49892071753993, "step": 26000}
{"episode": 27.0, "batch_reward": 0.17316911366581916, "actor_loss": -36.01932091522217, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.921191692352295, "episode_reward": 233.24599257328433, "step": 27000}
{"episode": 28.0, "batch_reward": 0.17594242393970488, "actor_loss": -36.25142427062988, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.448480129241943, "episode_reward": 261.46928908982846, "step": 28000}
{"episode": 29.0, "batch_reward": 0.17864498482644559, "actor_loss": -36.41624294281006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.95880103111267, "episode_reward": 135.12715661060815, "step": 29000}
{"episode": 30.0, "batch_reward": 0.17736904127895833, "actor_loss": -35.976971672058106, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.94781231880188, "episode_reward": 178.98999507773672, "step": 30000}
{"episode": 31.0, "batch_reward": 0.178280860260129, "actor_loss": -35.81865605163574, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.7979576587677, "episode_reward": 318.89793414843336, "step": 31000}
{"episode": 32.0, "batch_reward": 0.18190414164960383, "actor_loss": -35.8784114074707, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.27308201789856, "episode_reward": 168.99283287998585, "step": 32000}
{"episode": 33.0, "batch_reward": 0.18175743938982486, "actor_loss": -35.53652007675171, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.69844937324524, "episode_reward": 271.3376920005974, "step": 33000}
{"episode": 34.0, "batch_reward": 0.18295321206748485, "actor_loss": -35.649310703277585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.680744409561157, "episode_reward": 116.4919438099473, "step": 34000}
{"episode": 35.0, "batch_reward": 0.18163465188443662, "actor_loss": -35.24149286270141, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.834342002868652, "episode_reward": 141.13611950866172, "step": 35000}
{"episode": 36.0, "batch_reward": 0.1821838943362236, "actor_loss": -35.07455588912964, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.308716535568237, "episode_reward": 321.6147009788125, "step": 36000}
{"episode": 37.0, "batch_reward": 0.18685459312796593, "actor_loss": -35.23672913742065, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.986343145370483, "episode_reward": 417.64805847128093, "step": 37000}
{"episode": 38.0, "batch_reward": 0.19120445775985717, "actor_loss": -35.75800008773804, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.29895257949829, "episode_reward": 289.88129477291864, "step": 38000}
{"episode": 39.0, "batch_reward": 0.1949921734035015, "actor_loss": -36.066759117126466, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.076201677322388, "episode_reward": 243.381987306554, "step": 39000}
{"episode": 40.0, "batch_reward": 0.19664105902612208, "actor_loss": -36.06013624572754, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.824479818344116, "episode_reward": 418.91560458965034, "step": 40000}
{"episode": 41.0, "batch_reward": 0.19857748898863792, "actor_loss": -36.0166720199585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.55688810348511, "episode_reward": 40.223194148446936, "step": 41000}
{"episode": 42.0, "batch_reward": 0.19734443263709545, "actor_loss": -35.82893014526367, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.625674962997437, "episode_reward": 345.76385808484804, "step": 42000}
{"episode": 43.0, "batch_reward": 0.2005099052786827, "actor_loss": -35.99627405166626, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.064210176467896, "episode_reward": 146.67097074062696, "step": 43000}
{"episode": 44.0, "batch_reward": 0.20001421663165092, "actor_loss": -35.807037746429444, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.862447500228882, "episode_reward": 395.2686949035124, "step": 44000}
{"episode": 45.0, "batch_reward": 0.20548248352110385, "actor_loss": -36.24316301345825, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.535513639450073, "episode_reward": 349.84702633307836, "step": 45000}
{"episode": 46.0, "batch_reward": 0.20808110097050667, "actor_loss": -36.425972984313965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.19355607032776, "episode_reward": 261.19479880359273, "step": 46000}
{"episode": 47.0, "batch_reward": 0.20779706859588623, "actor_loss": -36.1772985534668, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.350357055664062, "episode_reward": 282.08900592614407, "step": 47000}
{"episode": 48.0, "batch_reward": 0.21039481203258037, "actor_loss": -36.51908010482788, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.27993607521057, "episode_reward": 245.94377194781615, "step": 48000}
{"episode": 49.0, "batch_reward": 0.2109944007396698, "actor_loss": -36.34681387710571, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.523866415023804, "episode_reward": 407.5278338736114, "step": 49000}
{"episode": 50.0, "batch_reward": 0.21377236962318422, "actor_loss": -36.60435483169556, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.919124841690063, "episode_reward": 366.38958853633494, "step": 50000}
{"episode": 51.0, "batch_reward": 0.2190353346168995, "actor_loss": -37.142931591033935, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.93099355697632, "episode_reward": 424.97571339546334, "step": 51000}
{"episode": 52.0, "batch_reward": 0.2204417087882757, "actor_loss": -37.19317664337158, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.806933641433716, "episode_reward": 222.01710954083157, "step": 52000}
{"episode": 53.0, "batch_reward": 0.22140658730268478, "actor_loss": -37.019006072998046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.9005184173584, "episode_reward": 130.40304879678249, "step": 53000}
{"episode": 54.0, "batch_reward": 0.21808243027329444, "actor_loss": -36.484480171203614, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.578199863433838, "episode_reward": 67.95208273778586, "step": 54000}
{"episode": 55.0, "batch_reward": 0.21635515238344669, "actor_loss": -36.13994028091431, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.681135177612305, "episode_reward": 191.37024163478884, "step": 55000}
{"episode": 56.0, "batch_reward": 0.21747779224812985, "actor_loss": -35.993278224945065, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.939387321472168, "episode_reward": 367.71243382757, "step": 56000}
{"episode": 57.0, "batch_reward": 0.2198221078813076, "actor_loss": -36.17853747940063, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.329594373703003, "episode_reward": 443.3248660909372, "step": 57000}
{"episode": 58.0, "batch_reward": 0.22371743077039719, "actor_loss": -36.476791858673096, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.766945123672485, "episode_reward": 254.45875960019598, "step": 58000}
{"episode": 59.0, "batch_reward": 0.2258067850023508, "actor_loss": -36.62887019348145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.802803993225098, "episode_reward": 469.7195052755821, "step": 59000}
{"episode": 60.0, "batch_reward": 0.22835584612190724, "actor_loss": -36.79525037765503, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.924696922302246, "episode_reward": 441.3861315283394, "step": 60000}
{"episode": 61.0, "batch_reward": 0.23379153202474118, "actor_loss": -37.17693203735352, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 39.20522451400757, "episode_reward": 508.68101539552526, "step": 61000}
{"episode": 62.0, "batch_reward": 0.2362993901371956, "actor_loss": -37.456884239196775, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.751761436462402, "episode_reward": 356.0860416712959, "step": 62000}
{"episode": 63.0, "batch_reward": 0.23737825992703437, "actor_loss": -37.611291725158694, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.06608510017395, "episode_reward": 246.464827262546, "step": 63000}
{"episode": 64.0, "batch_reward": 0.23768959374725818, "actor_loss": -37.51887521362305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.012264013290405, "episode_reward": 154.10731829144763, "step": 64000}
{"episode": 65.0, "batch_reward": 0.23461842752993106, "actor_loss": -37.10735300445557, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.196008920669556, "episode_reward": 43.8726100946606, "step": 65000}
{"episode": 66.0, "batch_reward": 0.23369139325618743, "actor_loss": -36.73884175872803, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.873291730880737, "episode_reward": 364.51368213687846, "step": 66000}
{"episode": 67.0, "batch_reward": 0.2368897228091955, "actor_loss": -37.18306201171875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.86276888847351, "episode_reward": 463.51645797241673, "step": 67000}
{"episode": 68.0, "batch_reward": 0.23919478058815002, "actor_loss": -37.26447035598755, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.625011682510376, "episode_reward": 493.8321787784516, "step": 68000}
{"episode": 69.0, "batch_reward": 0.24403704103827475, "actor_loss": -37.74295713806152, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.69643473625183, "episode_reward": 460.5597892461858, "step": 69000}
{"episode": 70.0, "batch_reward": 0.2462606747895479, "actor_loss": -37.97175777053833, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.679985523223877, "episode_reward": 428.9364663283229, "step": 70000}
{"episode": 71.0, "batch_reward": 0.24991362413764, "actor_loss": -38.28956880187988, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 39.17194318771362, "episode_reward": 436.29911303685145, "step": 71000}
{"episode": 72.0, "batch_reward": 0.25195771829783914, "actor_loss": -38.367328712463376, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.97308039665222, "episode_reward": 458.32400436143905, "step": 72000}
{"episode": 73.0, "batch_reward": 0.2537286888808012, "actor_loss": -38.45835660552979, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.222849130630493, "episode_reward": 443.16137123102664, "step": 73000}
{"episode": 74.0, "batch_reward": 0.2571164531558752, "actor_loss": -38.791416549682616, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.292681217193604, "episode_reward": 377.0897457213513, "step": 74000}
{"episode": 75.0, "batch_reward": 0.25892962419986726, "actor_loss": -38.923097480773926, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.039616584777832, "episode_reward": 376.1306859361977, "step": 75000}
{"episode": 76.0, "batch_reward": 0.2605647775828838, "actor_loss": -39.10552982330322, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.031583309173584, "episode_reward": 371.0470755139028, "step": 76000}
{"episode": 77.0, "batch_reward": 0.2612827417552471, "actor_loss": -39.07492723083496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.818355321884155, "episode_reward": 384.0444932731627, "step": 77000}
{"episode": 78.0, "batch_reward": 0.2634356160908937, "actor_loss": -39.30219445800781, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.048749923706055, "episode_reward": 434.2788445810994, "step": 78000}
{"episode": 79.0, "batch_reward": 0.26508361142873765, "actor_loss": -39.481928543090824, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.625805377960205, "episode_reward": 390.7433019422855, "step": 79000}
{"episode": 80.0, "batch_reward": 0.26676579731702804, "actor_loss": -39.60882665252686, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.64875102043152, "episode_reward": 418.37448343373455, "step": 80000}
{"episode": 81.0, "batch_reward": 0.2689242546111345, "actor_loss": -39.82660872650146, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 39.4344437122345, "episode_reward": 455.5764620408385, "step": 81000}
{"episode": 82.0, "batch_reward": 0.2719917643964291, "actor_loss": -40.08489214324951, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.1877281665802, "episode_reward": 394.4665346256188, "step": 82000}
{"episode": 83.0, "batch_reward": 0.27382651847600936, "actor_loss": -40.039719291687014, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.381561994552612, "episode_reward": 505.95785040580284, "step": 83000}
{"episode": 84.0, "batch_reward": 0.2750365729629993, "actor_loss": -40.306103660583496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.80171799659729, "episode_reward": 425.391939035397, "step": 84000}
{"episode": 85.0, "batch_reward": 0.27735037280619146, "actor_loss": -40.44148624420166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.357589960098267, "episode_reward": 483.11170078005125, "step": 85000}
{"episode": 86.0, "batch_reward": 0.27927564465999605, "actor_loss": -40.64030180358887, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.143798112869263, "episode_reward": 470.69387971739246, "step": 86000}
{"episode": 87.0, "batch_reward": 0.28337097372114656, "actor_loss": -40.83208492279053, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.943899393081665, "episode_reward": 502.26201555206444, "step": 87000}
{"episode": 88.0, "batch_reward": 0.2846425542831421, "actor_loss": -41.01996235656738, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.427661418914795, "episode_reward": 513.9666115935119, "step": 88000}
{"episode": 89.0, "batch_reward": 0.2864350835829973, "actor_loss": -41.20810121154785, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.53993558883667, "episode_reward": 433.18755077724757, "step": 89000}
{"episode": 90.0, "batch_reward": 0.28682237324118615, "actor_loss": -41.14074283599854, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.19001269340515, "episode_reward": 86.29080585205047, "step": 90000}
{"episode": 91.0, "batch_reward": 0.2866973452717066, "actor_loss": -40.95735333251953, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 39.27400207519531, "episode_reward": 499.02432770138756, "step": 91000}
{"episode": 92.0, "batch_reward": 0.28943381279706953, "actor_loss": -41.30978952026367, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.717581510543823, "episode_reward": 462.7668430698123, "step": 92000}
{"episode": 93.0, "batch_reward": 0.29003411675989627, "actor_loss": -41.388857765197756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.84718346595764, "episode_reward": 448.75898068872027, "step": 93000}
{"episode": 94.0, "batch_reward": 0.29189390915632246, "actor_loss": -41.53068755340576, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.16380786895752, "episode_reward": 468.3113509501384, "step": 94000}
{"episode": 95.0, "batch_reward": 0.292627453148365, "actor_loss": -41.655237243652344, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.08441138267517, "episode_reward": 132.9434044619364, "step": 95000}
{"episode": 96.0, "batch_reward": 0.29163907264173033, "actor_loss": -41.54255921936035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.698437213897705, "episode_reward": 503.6462724457119, "step": 96000}
{"episode": 97.0, "batch_reward": 0.2921951574832201, "actor_loss": -41.42604891204834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.656879425048828, "episode_reward": 385.36326058908816, "step": 97000}
{"episode": 98.0, "batch_reward": 0.29568890802562237, "actor_loss": -41.74215007781982, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.089012384414673, "episode_reward": 501.55575489687055, "step": 98000}
{"episode": 99.0, "batch_reward": 0.2981651424765587, "actor_loss": -42.01483866119385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.0526921749115, "episode_reward": 507.6946832233971, "step": 99000}
{"episode": 100.0, "batch_reward": 0.29999025058746337, "actor_loss": -42.16453531646729, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.367398500442505, "episode_reward": 494.80980611405636, "step": 100000}
{"episode": 101.0, "batch_reward": 0.30301532489061356, "actor_loss": -42.330652549743654, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 39.32003092765808, "episode_reward": 531.8601362382716, "step": 101000}
{"episode": 102.0, "batch_reward": 0.30423860436677935, "actor_loss": -42.593255432128906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.117627382278442, "episode_reward": 474.5243222299608, "step": 102000}
{"episode": 103.0, "batch_reward": 0.3050452165007591, "actor_loss": -42.635860069274905, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.11322259902954, "episode_reward": 444.43000460349054, "step": 103000}
{"episode": 104.0, "batch_reward": 0.30619133460521697, "actor_loss": -42.7357137298584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.181469202041626, "episode_reward": 427.5421678349962, "step": 104000}
{"episode": 105.0, "batch_reward": 0.30883219110965726, "actor_loss": -42.82024371337891, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.177363634109497, "episode_reward": 501.85103795881423, "step": 105000}
{"episode": 106.0, "batch_reward": 0.3108585057258606, "actor_loss": -43.05052515411377, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.160337209701538, "episode_reward": 490.3303536621963, "step": 106000}
{"episode": 107.0, "batch_reward": 0.3117471871078014, "actor_loss": -43.119900871276855, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.634925842285156, "episode_reward": 528.3583749000661, "step": 107000}
{"episode": 108.0, "batch_reward": 0.3144130546748638, "actor_loss": -43.41195018005371, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.992706298828125, "episode_reward": 474.8146709389142, "step": 108000}
{"episode": 109.0, "batch_reward": 0.31592870131134987, "actor_loss": -43.50709746551514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.545737504959106, "episode_reward": 464.7295911705179, "step": 109000}
{"episode": 110.0, "batch_reward": 0.31633251217007635, "actor_loss": -43.511447265625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.221635580062866, "episode_reward": 535.9461344290245, "step": 110000}
{"episode": 111.0, "batch_reward": 0.3185082387924194, "actor_loss": -43.66414138793945, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.820744037628174, "episode_reward": 436.8318428174685, "step": 111000}
{"episode": 112.0, "batch_reward": 0.3195221659839153, "actor_loss": -43.71447394561768, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.016164779663086, "episode_reward": 526.9301816110609, "step": 112000}
{"episode": 113.0, "batch_reward": 0.32188685876131057, "actor_loss": -43.981815628051756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.306316137313843, "episode_reward": 228.10171476943611, "step": 113000}
{"episode": 114.0, "batch_reward": 0.3208228533267975, "actor_loss": -43.86689226531983, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.46803379058838, "episode_reward": 530.7033984319186, "step": 114000}
{"episode": 115.0, "batch_reward": 0.3230845088660717, "actor_loss": -43.89935440826416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.03749680519104, "episode_reward": 411.62345682917123, "step": 115000}
{"episode": 116.0, "batch_reward": 0.3232325332760811, "actor_loss": -43.970251037597656, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.210904836654663, "episode_reward": 510.81951416993775, "step": 116000}
{"episode": 117.0, "batch_reward": 0.3261318826675415, "actor_loss": -44.30882061767578, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.973572731018066, "episode_reward": 497.9181302190596, "step": 117000}
{"episode": 118.0, "batch_reward": 0.3268661799430847, "actor_loss": -44.23313000488281, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.838414907455444, "episode_reward": 275.9601775724681, "step": 118000}
{"episode": 119.0, "batch_reward": 0.32593289196491243, "actor_loss": -44.113603507995606, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.010299921035767, "episode_reward": 521.0651799150046, "step": 119000}
{"episode": 120.0, "batch_reward": 0.32693457990884783, "actor_loss": -44.145936073303226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.31760311126709, "episode_reward": 432.371755673145, "step": 120000}
{"episode": 121.0, "batch_reward": 0.328479386806488, "actor_loss": -44.351695137023924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 39.30094575881958, "episode_reward": 535.3604387522771, "step": 121000}
{"episode": 122.0, "batch_reward": 0.3311941236257553, "actor_loss": -44.65070094299316, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.97934103012085, "episode_reward": 466.4396259947984, "step": 122000}
{"episode": 123.0, "batch_reward": 0.3310181100964546, "actor_loss": -44.5310502243042, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.4726881980896, "episode_reward": 504.96088670005065, "step": 123000}
{"episode": 124.0, "batch_reward": 0.3341562867462635, "actor_loss": -44.85297953796387, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.178148984909058, "episode_reward": 533.216055904113, "step": 124000}
{"episode": 125.0, "batch_reward": 0.33454703840613365, "actor_loss": -44.68829222106934, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.307729482650757, "episode_reward": 170.5147105040313, "step": 125000}
{"episode": 126.0, "batch_reward": 0.3328803234100342, "actor_loss": -44.63741446685791, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.973846197128296, "episode_reward": 523.9710627963383, "step": 126000}
{"episode": 127.0, "batch_reward": 0.3348843260407448, "actor_loss": -44.69557074737549, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.513399600982666, "episode_reward": 532.1051340002523, "step": 127000}
{"episode": 128.0, "batch_reward": 0.33569400531053545, "actor_loss": -44.884012802124026, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.001764059066772, "episode_reward": 512.7176268085024, "step": 128000}
{"episode": 129.0, "batch_reward": 0.3378894307911396, "actor_loss": -45.034791816711426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.409677267074585, "episode_reward": 512.9625282273558, "step": 129000}
{"episode": 130.0, "batch_reward": 0.33912700149416924, "actor_loss": -45.12999350738525, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.99943470954895, "episode_reward": 535.2227990311834, "step": 130000}
{"episode": 131.0, "batch_reward": 0.3402003243267536, "actor_loss": -45.10937227630615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.110986948013306, "episode_reward": 497.1391826803704, "step": 131000}
{"episode": 132.0, "batch_reward": 0.341053859770298, "actor_loss": -45.1466402053833, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.36690402030945, "episode_reward": 207.97346584313144, "step": 132000}
{"episode": 133.0, "batch_reward": 0.3413446091711521, "actor_loss": -45.21472025299072, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.51146650314331, "episode_reward": 497.4196054192397, "step": 133000}
{"episode": 134.0, "batch_reward": 0.34129492768645286, "actor_loss": -45.28733639526367, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.25911855697632, "episode_reward": 505.7255560300428, "step": 134000}
{"episode": 135.0, "batch_reward": 0.34329564806818963, "actor_loss": -45.4106547164917, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.81175136566162, "episode_reward": 558.0376719615152, "step": 135000}
{"episode": 136.0, "batch_reward": 0.34539125007390975, "actor_loss": -45.597850555419924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.116071701049805, "episode_reward": 561.5999087647186, "step": 136000}
{"episode": 137.0, "batch_reward": 0.34616627702116964, "actor_loss": -45.75492261505127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.053125619888306, "episode_reward": 568.7184426156625, "step": 137000}
{"episode": 138.0, "batch_reward": 0.3477199950814247, "actor_loss": -45.761179817199704, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.162877559661865, "episode_reward": 460.6718996905293, "step": 138000}
{"episode": 139.0, "batch_reward": 0.348375427365303, "actor_loss": -45.821778175354005, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.2774395942688, "episode_reward": 549.3676155916779, "step": 139000}
{"episode": 140.0, "batch_reward": 0.34990392112731933, "actor_loss": -46.03071288299561, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.117223024368286, "episode_reward": 569.8234683321065, "step": 140000}
{"episode": 141.0, "batch_reward": 0.3515483439862728, "actor_loss": -46.1735690536499, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.49310541152954, "episode_reward": 514.7690642229021, "step": 141000}
{"episode": 142.0, "batch_reward": 0.35221347951889037, "actor_loss": -46.078713661193845, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.808181762695312, "episode_reward": 492.84011345434755, "step": 142000}
{"episode": 143.0, "batch_reward": 0.3533529899418354, "actor_loss": -46.181815467834475, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.765603065490723, "episode_reward": 539.0659063699524, "step": 143000}
{"episode": 144.0, "batch_reward": 0.35534213024377825, "actor_loss": -46.518397270202634, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.171522855758667, "episode_reward": 541.6650826893838, "step": 144000}
{"episode": 145.0, "batch_reward": 0.3563919491171837, "actor_loss": -46.579455169677736, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.227712631225586, "episode_reward": 566.0132740064101, "step": 145000}
{"episode": 146.0, "batch_reward": 0.35735085290670393, "actor_loss": -46.506990951538086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.113742351531982, "episode_reward": 96.14399778944512, "step": 146000}
{"episode": 147.0, "batch_reward": 0.3543262103497982, "actor_loss": -46.251750198364256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.645979166030884, "episode_reward": 517.4707763264803, "step": 147000}
{"episode": 148.0, "batch_reward": 0.35797993794083593, "actor_loss": -46.552839691162106, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.255318880081177, "episode_reward": 552.6387499178585, "step": 148000}
{"episode": 149.0, "batch_reward": 0.3589307800233364, "actor_loss": -46.57787471008301, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.785931825637817, "episode_reward": 539.1413282031267, "step": 149000}
{"episode": 150.0, "batch_reward": 0.3609036446213722, "actor_loss": -46.73839519500732, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
