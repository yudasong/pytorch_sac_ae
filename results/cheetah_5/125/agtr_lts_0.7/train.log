{"episode_reward": 0.0, "episode": 1.0, "duration": 16.984851360321045, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.4586007595062256, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.3166730629429892, "critic_loss": 0.11967926715146943, "actor_loss": -49.59658943075521, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.02385640144348, "step": 3000}
{"episode_reward": 700.2247045421698, "episode": 4.0, "batch_reward": 0.4496785092353821, "critic_loss": 0.16819303524494172, "actor_loss": -58.058945121765134, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.693949937820435, "step": 4000}
{"episode_reward": 663.9878669400084, "episode": 5.0, "batch_reward": 0.4864722083210945, "critic_loss": 0.18807174979150296, "actor_loss": -60.23696538543701, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.686328172683716, "step": 5000}
{"episode_reward": 568.3940687472863, "episode": 6.0, "batch_reward": 0.501032720297575, "critic_loss": 0.2263237796649337, "actor_loss": -60.56688883209228, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.65450406074524, "step": 6000}
{"episode_reward": 543.663220326873, "episode": 7.0, "batch_reward": 0.5008354834020138, "critic_loss": 0.2509728986918926, "actor_loss": -59.309856201171876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.668744802474976, "step": 7000}
{"episode_reward": 517.3409816586657, "episode": 8.0, "batch_reward": 0.5080379274487495, "critic_loss": 0.27224316373467444, "actor_loss": -59.78569706726074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.65661311149597, "step": 8000}
{"episode_reward": 510.9883004333701, "episode": 9.0, "batch_reward": 0.5036858251392842, "critic_loss": 0.3158930284380913, "actor_loss": -58.88431587219238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.661034107208252, "step": 9000}
{"episode_reward": 280.61484407219615, "episode": 10.0, "batch_reward": 0.49198255383968353, "critic_loss": 0.273578381434083, "actor_loss": -57.076835929870605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66278839111328, "step": 10000}
{"episode_reward": 668.5483734304861, "episode": 11.0, "batch_reward": 0.5063802464306355, "critic_loss": 0.29900531283020976, "actor_loss": -57.980137107849124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.67175340652466, "step": 11000}
{"episode_reward": 666.1328275561837, "episode": 12.0, "batch_reward": 0.5215816385447979, "critic_loss": 0.291922881141305, "actor_loss": -59.05693239593506, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.657039403915405, "step": 12000}
{"episode_reward": 698.9063950649308, "episode": 13.0, "batch_reward": 0.5355754601061344, "critic_loss": 0.29767757740616796, "actor_loss": -59.996996200561526, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.67123317718506, "step": 13000}
{"episode_reward": 653.0980142614999, "episode": 14.0, "batch_reward": 0.5457825414836407, "critic_loss": 0.29768288922309877, "actor_loss": -60.80024235534668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.663340091705322, "step": 14000}
{"episode_reward": 670.4697615941482, "episode": 15.0, "batch_reward": 0.5516914587914944, "critic_loss": 0.306128537401557, "actor_loss": -60.60778246307373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.649775743484497, "step": 15000}
{"episode_reward": 524.8057394713144, "episode": 16.0, "batch_reward": 0.5526841992735863, "critic_loss": 0.2836828294247389, "actor_loss": -60.13994635772705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66235637664795, "step": 16000}
{"episode_reward": 642.2171586001884, "episode": 17.0, "batch_reward": 0.5546922896802425, "critic_loss": 0.3180501331239939, "actor_loss": -60.3814613494873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.68347430229187, "step": 17000}
{"episode_reward": 622.3255203893921, "episode": 18.0, "batch_reward": 0.5479133043587208, "critic_loss": 0.36256318651139735, "actor_loss": -59.458166839599606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.696054220199585, "step": 18000}
{"episode_reward": 69.53569111810137, "episode": 19.0, "batch_reward": 0.53159509319067, "critic_loss": 0.3600275049358606, "actor_loss": -57.83917641448975, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.67384910583496, "step": 19000}
{"episode_reward": 469.23780030942976, "episode": 20.0, "batch_reward": 0.5300116262137889, "critic_loss": 0.39195843698084354, "actor_loss": -57.30585131072998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.659006118774414, "step": 20000}
{"episode_reward": 590.9218975899245, "episode": 21.0, "batch_reward": 0.5308527246117591, "critic_loss": 0.44436763861775397, "actor_loss": -57.46578224182129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.6499457359314, "step": 21000}
{"episode_reward": 575.8192820832304, "episode": 22.0, "batch_reward": 0.5358990200161934, "critic_loss": 0.5111094345152378, "actor_loss": -57.938098304748536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.665199518203735, "step": 22000}
{"episode_reward": 647.532050535952, "episode": 23.0, "batch_reward": 0.5290968258976936, "critic_loss": 0.532288581520319, "actor_loss": -57.157635795593265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.672330141067505, "step": 23000}
{"episode_reward": 23.59100802033776, "episode": 24.0, "batch_reward": 0.5134892652630806, "critic_loss": 0.5277938456535339, "actor_loss": -55.803891502380374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.65987777709961, "step": 24000}
{"episode_reward": 436.05912017511537, "episode": 25.0, "batch_reward": 0.5147888542711735, "critic_loss": 0.4698929104357958, "actor_loss": -56.371753463745115, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.667081832885742, "step": 25000}
{"episode_reward": 625.7834493869748, "episode": 26.0, "batch_reward": 0.5152746661007405, "critic_loss": 0.4904221289008856, "actor_loss": -56.050969841003415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.664883852005005, "step": 26000}
{"episode_reward": 614.5048350559849, "episode": 27.0, "batch_reward": 0.5218120774924755, "critic_loss": 0.4976727032214403, "actor_loss": -56.71625877380371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.675511837005615, "step": 27000}
{"episode_reward": 598.9294381157474, "episode": 28.0, "batch_reward": 0.5257140492200851, "critic_loss": 0.524920595124364, "actor_loss": -57.03458339691162, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.65502429008484, "step": 28000}
{"episode_reward": 587.9842942567738, "episode": 29.0, "batch_reward": 0.5197336636781692, "critic_loss": 0.5503418272584677, "actor_loss": -56.3529429397583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.670246124267578, "step": 29000}
{"episode_reward": 43.70558556350387, "episode": 30.0, "batch_reward": 0.511694494754076, "critic_loss": 0.573767761439085, "actor_loss": -55.6884443359375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.659133911132812, "step": 30000}
{"episode_reward": 620.4927642254875, "episode": 31.0, "batch_reward": 0.5150684043765068, "critic_loss": 0.6275184247046709, "actor_loss": -55.92927307128906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.69219517707825, "step": 31000}
{"episode_reward": 639.941914232797, "episode": 32.0, "batch_reward": 0.5182760136425495, "critic_loss": 0.6605206916630268, "actor_loss": -56.08779864501953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.959808349609375, "step": 32000}
{"episode_reward": 653.8312497821549, "episode": 33.0, "batch_reward": 0.5223395701050758, "critic_loss": 0.7660553936958313, "actor_loss": -56.54238665771484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.638901472091675, "step": 33000}
{"episode_reward": 625.5556641299735, "episode": 34.0, "batch_reward": 0.5244217303395271, "critic_loss": 0.9071842999756337, "actor_loss": -56.96668515014648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.63618803024292, "step": 34000}
{"episode_reward": 603.2105944486974, "episode": 35.0, "batch_reward": 0.5265277614295483, "critic_loss": 1.097265550017357, "actor_loss": -57.155628593444824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.63435125350952, "step": 35000}
{"episode_reward": 649.457424539752, "episode": 36.0, "batch_reward": 0.5306149240136147, "critic_loss": 1.5623528100550175, "actor_loss": -57.57164389801025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.661678314208984, "step": 36000}
{"episode_reward": 561.1786276025974, "episode": 37.0, "batch_reward": 0.5327938081026077, "critic_loss": 2.0988701671659946, "actor_loss": -57.876513153076175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.67392134666443, "step": 37000}
{"episode_reward": 632.3019200259033, "episode": 38.0, "batch_reward": 0.5336410181224346, "critic_loss": 2.6444334325790404, "actor_loss": -58.065465370178224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.661450386047363, "step": 38000}
{"episode_reward": 633.3807824861484, "episode": 39.0, "batch_reward": 0.5337730603516102, "critic_loss": 5.001747692614794, "actor_loss": -58.135103088378905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.667128324508667, "step": 39000}
{"episode_reward": 200.00425499156322, "episode": 40.0, "batch_reward": 0.5276007554531097, "critic_loss": 4.913268418490887, "actor_loss": -57.88232056427002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.64980721473694, "step": 40000}
{"episode_reward": 636.7615123851879, "episode": 41.0, "batch_reward": 0.5318898329138756, "critic_loss": 6.992831135809421, "actor_loss": -58.54530833435059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.62863564491272, "step": 41000}
{"episode_reward": 616.2963762630961, "episode": 42.0, "batch_reward": 0.5352129074931145, "critic_loss": 7.160751959264278, "actor_loss": -59.13268812561035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.672918558120728, "step": 42000}
{"episode_reward": 677.9244934757565, "episode": 43.0, "batch_reward": 0.5378238409161568, "critic_loss": 9.567951682806015, "actor_loss": -59.31835820007324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.673341989517212, "step": 43000}
{"episode_reward": 599.093031698243, "episode": 44.0, "batch_reward": 0.5394071220159531, "critic_loss": 13.755752817332745, "actor_loss": -60.06476614379883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.67558264732361, "step": 44000}
{"episode_reward": 676.3561184340484, "episode": 45.0, "batch_reward": 0.5396027573943138, "critic_loss": 15.436273628413677, "actor_loss": -60.33299801635742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.664953231811523, "step": 45000}
{"episode_reward": 546.6625957646693, "episode": 46.0, "batch_reward": 0.5410051358640194, "critic_loss": 20.88121211528778, "actor_loss": -60.61253593444824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66157627105713, "step": 46000}
{"episode_reward": 607.6694274550416, "episode": 47.0, "batch_reward": 0.5419054297804833, "critic_loss": 40.789713203430175, "actor_loss": -61.18371020507813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.660714626312256, "step": 47000}
{"episode_reward": 465.1798291114273, "episode": 48.0, "batch_reward": 0.5376461091637611, "critic_loss": 57.6558297328949, "actor_loss": -66.24391478729248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.678470611572266, "step": 48000}
{"episode_reward": 165.5517812518966, "episode": 49.0, "batch_reward": 0.5308810850977898, "critic_loss": 72.32020073509216, "actor_loss": -70.56455826568603, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.659503698349, "step": 49000}
{"episode_reward": 316.4976913165665, "episode": 50.0, "batch_reward": 0.5272917615175248, "critic_loss": 113.5925703201294, "actor_loss": -75.6852698059082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.64789891242981, "step": 50000}
{"episode_reward": 328.96298484092995, "episode": 51.0, "batch_reward": 0.5204341387748719, "critic_loss": 138.88775366973877, "actor_loss": -79.51560127258301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.64535117149353, "step": 51000}
{"episode_reward": 182.9574648067536, "episode": 52.0, "batch_reward": 0.514956215530634, "critic_loss": 156.47031191253663, "actor_loss": -83.195987739563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.650933504104614, "step": 52000}
{"episode_reward": 179.21947832713047, "episode": 53.0, "batch_reward": 0.5079360930025577, "critic_loss": 170.86376840209962, "actor_loss": -88.8738363647461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.957088708877563, "step": 53000}
{"episode_reward": 90.05441905287945, "episode": 54.0, "batch_reward": 0.49976554358005526, "critic_loss": 205.19600592041016, "actor_loss": -91.05459435272216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.62911558151245, "step": 54000}
{"episode_reward": 136.0064977819147, "episode": 55.0, "batch_reward": 0.49459820598363874, "critic_loss": 225.6089175567627, "actor_loss": -96.51621904754639, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.622517347335815, "step": 55000}
{"episode_reward": 98.65841903150236, "episode": 56.0, "batch_reward": 0.4845451616644859, "critic_loss": 257.76430088043213, "actor_loss": -101.07401300048828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.634804248809814, "step": 56000}
{"episode_reward": 28.4396070175775, "episode": 57.0, "batch_reward": 0.4782894079983234, "critic_loss": 285.9723451843262, "actor_loss": -107.91522125244141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.68345069885254, "step": 57000}
{"episode_reward": 18.38529616405097, "episode": 58.0, "batch_reward": 0.46880360436439517, "critic_loss": 308.1229342498779, "actor_loss": -117.61252000427245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.679177045822144, "step": 58000}
{"episode_reward": 3.2600630840095794, "episode": 59.0, "batch_reward": 0.4622514057457447, "critic_loss": 320.57733961486815, "actor_loss": -125.1682222366333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.704091787338257, "step": 59000}
{"episode_reward": 9.012085983726557, "episode": 60.0, "batch_reward": 0.4534652255475521, "critic_loss": 340.3465637207031, "actor_loss": -123.85770495605469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.684226989746094, "step": 60000}
{"episode_reward": 7.900149913480616, "episode": 61.0, "batch_reward": 0.44716794618964195, "critic_loss": 353.10727980041503, "actor_loss": -131.99400215148927, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.78187370300293, "step": 61000}
{"episode_reward": 8.300248291839281, "episode": 62.0, "batch_reward": 0.4379837849736214, "critic_loss": 370.9814464416504, "actor_loss": -130.37081718444824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.677745580673218, "step": 62000}
{"episode_reward": 34.92894728322754, "episode": 63.0, "batch_reward": 0.4330970148742199, "critic_loss": 400.9453036193848, "actor_loss": -141.26236218261718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.67086958885193, "step": 63000}
{"episode_reward": 8.970235236326717, "episode": 64.0, "batch_reward": 0.42509321600198746, "critic_loss": 423.5954868621826, "actor_loss": -140.2548379974365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66299533843994, "step": 64000}
{"episode_reward": 15.636830907957192, "episode": 65.0, "batch_reward": 0.4204850361347198, "critic_loss": 452.00846464538574, "actor_loss": -147.284551071167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66137957572937, "step": 65000}
{"episode_reward": 8.570081955037749, "episode": 66.0, "batch_reward": 0.41226400452852247, "critic_loss": 454.31369923400877, "actor_loss": -150.62078466033935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.681708335876465, "step": 66000}
{"episode_reward": 13.87807872116508, "episode": 67.0, "batch_reward": 0.40752738478779793, "critic_loss": 476.38863414001463, "actor_loss": -154.1266399383545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.657249927520752, "step": 67000}
{"episode_reward": 14.27678821969467, "episode": 68.0, "batch_reward": 0.40161664474010467, "critic_loss": 489.7730570983887, "actor_loss": -174.80370190429687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.6791353225708, "step": 68000}
{"episode_reward": 19.989823114075975, "episode": 69.0, "batch_reward": 0.3960189872384071, "critic_loss": 505.83334129333497, "actor_loss": -183.7706357269287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.666372537612915, "step": 69000}
{"episode_reward": 9.315694034872275, "episode": 70.0, "batch_reward": 0.38944910287857054, "critic_loss": 527.2070745544434, "actor_loss": -174.5880798187256, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66618776321411, "step": 70000}
{"episode_reward": 47.04741989713874, "episode": 71.0, "batch_reward": 0.3863349431157112, "critic_loss": 583.7103206481934, "actor_loss": -189.3276713180542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.732924699783325, "step": 71000}
{"episode_reward": 85.39313347840204, "episode": 72.0, "batch_reward": 0.3821164934635162, "critic_loss": 631.9242549133301, "actor_loss": -203.06454990386962, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.673244953155518, "step": 72000}
{"episode_reward": 33.01181421118689, "episode": 73.0, "batch_reward": 0.3761866833269596, "critic_loss": 658.2446372680664, "actor_loss": -208.40228004455565, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.65106177330017, "step": 73000}
{"episode_reward": 75.61560015555487, "episode": 74.0, "batch_reward": 0.37266853561997415, "critic_loss": 744.8446883087158, "actor_loss": -204.9549223022461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.659600973129272, "step": 74000}
{"episode_reward": 32.1814517882437, "episode": 75.0, "batch_reward": 0.36735492399334907, "critic_loss": 679.1101314697265, "actor_loss": -211.99586603546143, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.658661365509033, "step": 75000}
{"episode_reward": 102.43697860474973, "episode": 76.0, "batch_reward": 0.3671204070150852, "critic_loss": 704.6263467407226, "actor_loss": -206.07674192810057, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66127610206604, "step": 76000}
{"episode_reward": 76.58014897841547, "episode": 77.0, "batch_reward": 0.3630968173146248, "critic_loss": 701.5340033874512, "actor_loss": -231.41681213378905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.65827250480652, "step": 77000}
{"episode_reward": 112.03117454948891, "episode": 78.0, "batch_reward": 0.3583848909139633, "critic_loss": 720.8356875915528, "actor_loss": -225.2344433670044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.64824080467224, "step": 78000}
{"episode_reward": 55.97450056129059, "episode": 79.0, "batch_reward": 0.3550813844203949, "critic_loss": 672.8292788696289, "actor_loss": -250.4325957183838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.640937328338623, "step": 79000}
{"episode_reward": 74.34822996713172, "episode": 80.0, "batch_reward": 0.3513818737864494, "critic_loss": 665.4766782226562, "actor_loss": -235.257210067749, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.65449094772339, "step": 80000}
{"episode_reward": 42.65199965466309, "episode": 81.0, "batch_reward": 0.34551510149240494, "critic_loss": 629.9371036071777, "actor_loss": -228.42555040740967, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.702356576919556, "step": 81000}
{"episode_reward": 23.940927947170653, "episode": 82.0, "batch_reward": 0.3418070229589939, "critic_loss": 592.2840390930176, "actor_loss": -202.7438094177246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.656290531158447, "step": 82000}
{"episode_reward": 53.260174424201715, "episode": 83.0, "batch_reward": 0.33919186705350873, "critic_loss": 547.436327178955, "actor_loss": -241.62352489471436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.672771453857422, "step": 83000}
{"episode_reward": 40.12206275246649, "episode": 84.0, "batch_reward": 0.3355366992950439, "critic_loss": 514.9696534576416, "actor_loss": -212.43520079803466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.669848680496216, "step": 84000}
{"episode_reward": 94.25599872021591, "episode": 85.0, "batch_reward": 0.3329553197622299, "critic_loss": 511.7841159973145, "actor_loss": -217.11799298095704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66611385345459, "step": 85000}
{"episode_reward": 25.714514066037314, "episode": 86.0, "batch_reward": 0.32956281790137293, "critic_loss": 505.5885599212647, "actor_loss": -221.52421118164062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.67216968536377, "step": 86000}
{"episode_reward": 108.33279482100608, "episode": 87.0, "batch_reward": 0.3284179028570652, "critic_loss": 521.7622246704102, "actor_loss": -221.07954920959472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.650309801101685, "step": 87000}
{"episode_reward": 75.45148160481864, "episode": 88.0, "batch_reward": 0.32534030577540396, "critic_loss": 520.4307286987305, "actor_loss": -230.95394903564454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.658580541610718, "step": 88000}
{"episode_reward": 48.420106677202604, "episode": 89.0, "batch_reward": 0.32148507818579675, "critic_loss": 526.2059812774659, "actor_loss": -201.5564853286743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66603684425354, "step": 89000}
{"episode_reward": 70.51725893179075, "episode": 90.0, "batch_reward": 0.3178209656625986, "critic_loss": 548.831825302124, "actor_loss": -187.62292124176025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.673407077789307, "step": 90000}
{"episode_reward": 75.24418268350388, "episode": 91.0, "batch_reward": 0.31496715927124025, "critic_loss": 555.0640800323487, "actor_loss": -206.24491358947753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.770005226135254, "step": 91000}
{"episode_reward": 76.14488828707616, "episode": 92.0, "batch_reward": 0.3125700766146183, "critic_loss": 569.5640370788574, "actor_loss": -213.9338379058838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66476607322693, "step": 92000}
{"episode_reward": 59.84852813384521, "episode": 93.0, "batch_reward": 0.30924234858155253, "critic_loss": 577.9970285644531, "actor_loss": -211.156640335083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.665600538253784, "step": 93000}
{"episode_reward": 16.75388910314585, "episode": 94.0, "batch_reward": 0.30722467140853404, "critic_loss": 602.4196989135742, "actor_loss": -208.49368258666993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.661237716674805, "step": 94000}
{"episode_reward": 72.48636466324335, "episode": 95.0, "batch_reward": 0.3035615054965019, "critic_loss": 599.037393951416, "actor_loss": -185.34864266967773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.65886116027832, "step": 95000}
{"episode_reward": 39.78207693772297, "episode": 96.0, "batch_reward": 0.3025544900149107, "critic_loss": 612.4509556427003, "actor_loss": -186.09055662536622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.655526399612427, "step": 96000}
{"episode_reward": 124.39360843954346, "episode": 97.0, "batch_reward": 0.3015533072948456, "critic_loss": 618.3050187377929, "actor_loss": -180.6436939086914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.658459186553955, "step": 97000}
{"episode_reward": 167.06494698924428, "episode": 98.0, "batch_reward": 0.29754453790187835, "critic_loss": 613.3825151672363, "actor_loss": -203.3269129638672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.655707120895386, "step": 98000}
{"episode_reward": 10.316867203632802, "episode": 99.0, "batch_reward": 0.29415495865046976, "critic_loss": 587.0108828125, "actor_loss": -202.0087003135681, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.682432889938354, "step": 99000}
{"episode_reward": 11.267434475637623, "episode": 100.0, "batch_reward": 0.2935393043458462, "critic_loss": 615.2189800872803, "actor_loss": -197.72979765319823, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.650031805038452, "step": 100000}
{"episode_reward": 121.37467711101078, "episode": 101.0, "batch_reward": 0.2934925067871809, "critic_loss": 612.8378559265137, "actor_loss": -191.28856828308105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.71209788322449, "step": 101000}
{"episode_reward": 123.37671407461848, "episode": 102.0, "batch_reward": 0.29085907152295115, "critic_loss": 597.5044926605225, "actor_loss": -194.48567881011962, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.672178745269775, "step": 102000}
{"episode_reward": 6.29908345592928, "episode": 103.0, "batch_reward": 0.28751838533580304, "critic_loss": 582.9502308197021, "actor_loss": -189.6921980743408, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66633629798889, "step": 103000}
{"episode_reward": 29.88093708858343, "episode": 104.0, "batch_reward": 0.284167480930686, "critic_loss": 556.5304405670166, "actor_loss": -190.46587701797486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.662896394729614, "step": 104000}
{"episode_reward": 56.691186742173784, "episode": 105.0, "batch_reward": 0.28362158508598806, "critic_loss": 560.4137112884522, "actor_loss": -188.7725313873291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.658358097076416, "step": 105000}
{"episode_reward": 132.68469784875867, "episode": 106.0, "batch_reward": 0.28258771358430385, "critic_loss": 599.7425428619384, "actor_loss": -199.10604039382935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.652613162994385, "step": 106000}
{"episode_reward": 79.4287096504363, "episode": 107.0, "batch_reward": 0.2782222359031439, "critic_loss": 582.3509837036133, "actor_loss": -182.33546900177, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.653138399124146, "step": 107000}
{"episode_reward": 29.535990419520314, "episode": 108.0, "batch_reward": 0.2765367419868708, "critic_loss": 659.726665512085, "actor_loss": -185.08601471710205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.65084171295166, "step": 108000}
{"episode_reward": 92.45449805459829, "episode": 109.0, "batch_reward": 0.2739016289710999, "critic_loss": 746.4293163452148, "actor_loss": -171.27974827575684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.654956579208374, "step": 109000}
{"episode_reward": 53.051505462314694, "episode": 110.0, "batch_reward": 0.27331593646109104, "critic_loss": 814.8132301635742, "actor_loss": -183.62359451675414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66997790336609, "step": 110000}
{"episode_reward": 57.505665761508126, "episode": 111.0, "batch_reward": 0.27122613455355166, "critic_loss": 859.5923126220703, "actor_loss": -168.34211938476562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.77037477493286, "step": 111000}
{"episode_reward": 176.80910166142758, "episode": 112.0, "batch_reward": 0.2693378136008978, "critic_loss": 859.8802505493164, "actor_loss": -183.92924048233033, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.67578434944153, "step": 112000}
{"episode_reward": 41.360363670968916, "episode": 113.0, "batch_reward": 0.2687889606654644, "critic_loss": 887.400376953125, "actor_loss": -184.25646310424804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.661130905151367, "step": 113000}
{"episode_reward": 18.102115610361658, "episode": 114.0, "batch_reward": 0.2673210489600897, "critic_loss": 882.1079070129394, "actor_loss": -173.07283320236206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.659390449523926, "step": 114000}
{"episode_reward": 62.38426727937992, "episode": 115.0, "batch_reward": 0.26349053280055523, "critic_loss": 933.1959704589843, "actor_loss": -183.67526485824584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.65890383720398, "step": 115000}
{"episode_reward": 52.698620094999946, "episode": 116.0, "batch_reward": 0.26091341146826746, "critic_loss": 1071.797934020996, "actor_loss": -181.91116473770143, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.672398805618286, "step": 116000}
{"episode_reward": 39.45219853578915, "episode": 117.0, "batch_reward": 0.258849921092391, "critic_loss": 941.0698718261718, "actor_loss": -186.54570433425903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.67352032661438, "step": 117000}
{"episode_reward": 58.038107068644095, "episode": 118.0, "batch_reward": 0.25878795272111893, "critic_loss": 917.4416903381348, "actor_loss": -184.6014467277527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.659960985183716, "step": 118000}
{"episode_reward": 37.21003252239264, "episode": 119.0, "batch_reward": 0.25702125392854214, "critic_loss": 917.3933334960938, "actor_loss": -183.49584099578857, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.670713901519775, "step": 119000}
{"episode_reward": 20.406986125211358, "episode": 120.0, "batch_reward": 0.2549735509753227, "critic_loss": 882.5453172302246, "actor_loss": -202.62796124267578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.659483432769775, "step": 120000}
{"episode_reward": 56.79492499856635, "episode": 121.0, "batch_reward": 0.2532586285173893, "critic_loss": 859.5260354919434, "actor_loss": -197.78797533798218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.74403786659241, "step": 121000}
{"episode_reward": 31.731262046998374, "episode": 122.0, "batch_reward": 0.2511908974200487, "critic_loss": 814.7210271606446, "actor_loss": -196.8602938232422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.67348861694336, "step": 122000}
{"episode_reward": 5.513463184910127, "episode": 123.0, "batch_reward": 0.24854550744593143, "critic_loss": 755.2419447937011, "actor_loss": -221.15368619918823, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.65630316734314, "step": 123000}
{"episode_reward": 88.74819349651891, "episode": 124.0, "batch_reward": 0.24710131368041038, "critic_loss": 811.2950730285645, "actor_loss": -194.59277641677858, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.6826434135437, "step": 124000}
{"episode_reward": 105.51054092736575, "episode": 125.0, "batch_reward": 0.24677785755693912, "critic_loss": 767.1399920654297, "actor_loss": -197.09142640304566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.67908477783203, "step": 125000}
{"episode_reward": 125.6749032413356, "episode": 126.0, "batch_reward": 0.2456679884493351, "critic_loss": 827.3005387268066, "actor_loss": -191.63274617385864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.68604350090027, "step": 126000}
{"episode_reward": 73.15405276211587, "episode": 127.0, "batch_reward": 0.24535598464310168, "critic_loss": 817.4691490478516, "actor_loss": -193.88094940948486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.664514541625977, "step": 127000}
{"episode_reward": 112.67146441411165, "episode": 128.0, "batch_reward": 0.24186921444535256, "critic_loss": 902.058825592041, "actor_loss": -176.10018494415283, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.671944618225098, "step": 128000}
{"episode_reward": 16.36858783494965, "episode": 129.0, "batch_reward": 0.24253323265910148, "critic_loss": 860.7638861694336, "actor_loss": -177.28218727493285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.64668560028076, "step": 129000}
{"episode_reward": 165.01355269058166, "episode": 130.0, "batch_reward": 0.24111547861993313, "critic_loss": 875.5703535461425, "actor_loss": -191.81754319381713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.65411400794983, "step": 130000}
{"episode_reward": 61.35882463149927, "episode": 131.0, "batch_reward": 0.2386154049038887, "critic_loss": 897.6879424743653, "actor_loss": -169.54971917343138, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.73527240753174, "step": 131000}
{"episode_reward": 62.89353846495214, "episode": 132.0, "batch_reward": 0.23858213317394256, "critic_loss": 894.5770189208985, "actor_loss": -189.39549143218994, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.654186248779297, "step": 132000}
{"episode_reward": 70.75617251112178, "episode": 133.0, "batch_reward": 0.23754071742296218, "critic_loss": 940.7652763061524, "actor_loss": -186.28334593963623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.64992117881775, "step": 133000}
{"episode_reward": 67.19991261955208, "episode": 134.0, "batch_reward": 0.23650161057710647, "critic_loss": 1004.185111114502, "actor_loss": -186.42895476913452, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.656479835510254, "step": 134000}
{"episode_reward": 61.51967803776878, "episode": 135.0, "batch_reward": 0.23499821577966212, "critic_loss": 1047.4252594299317, "actor_loss": -182.49110664749145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66261053085327, "step": 135000}
{"episode_reward": 124.68436006227877, "episode": 136.0, "batch_reward": 0.232434038028121, "critic_loss": 1003.048435974121, "actor_loss": -167.37516709136963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.669005632400513, "step": 136000}
{"episode_reward": 71.3447867481399, "episode": 137.0, "batch_reward": 0.23272571101784706, "critic_loss": 1051.8466341247558, "actor_loss": -195.15797088623046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.674811124801636, "step": 137000}
{"episode_reward": 44.870635829771416, "episode": 138.0, "batch_reward": 0.23196654850244522, "critic_loss": 916.7339364318848, "actor_loss": -202.97609814453125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.665489673614502, "step": 138000}
{"episode_reward": 108.91985810274635, "episode": 139.0, "batch_reward": 0.23026307836174964, "critic_loss": 815.8318128356933, "actor_loss": -197.78973989486695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.67217779159546, "step": 139000}
{"episode_reward": 280.70746897274597, "episode": 140.0, "batch_reward": 0.2320669917911291, "critic_loss": 833.9133120117187, "actor_loss": -199.433891040802, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.671963453292847, "step": 140000}
{"episode_reward": 131.3847010293844, "episode": 141.0, "batch_reward": 0.23063751175999642, "critic_loss": 734.3609554595947, "actor_loss": -202.0071219444275, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.74003314971924, "step": 141000}
{"episode_reward": 117.14890028158658, "episode": 142.0, "batch_reward": 0.22972162683308125, "critic_loss": 721.5628777770996, "actor_loss": -187.0154644317627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66451358795166, "step": 142000}
{"episode_reward": 153.63209394640145, "episode": 143.0, "batch_reward": 0.22865146440267564, "critic_loss": 711.4950615844726, "actor_loss": -179.80870957565307, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66450524330139, "step": 143000}
{"episode_reward": 296.40337100454053, "episode": 144.0, "batch_reward": 0.22857176887989045, "critic_loss": 705.2078093566895, "actor_loss": -171.77150497436523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.646522521972656, "step": 144000}
{"episode_reward": 80.51578592757944, "episode": 145.0, "batch_reward": 0.22762014067173003, "critic_loss": 693.8031791534423, "actor_loss": -174.47641703033446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.654377222061157, "step": 145000}
{"episode_reward": 110.99689430598636, "episode": 146.0, "batch_reward": 0.22884582766890527, "critic_loss": 739.040060119629, "actor_loss": -179.26461293792724, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.651325941085815, "step": 146000}
{"episode_reward": 198.57444199827566, "episode": 147.0, "batch_reward": 0.2269821783453226, "critic_loss": 768.0841058959961, "actor_loss": -165.51731619262696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.645243644714355, "step": 147000}
{"episode_reward": 189.98934982960495, "episode": 148.0, "batch_reward": 0.22780039417743683, "critic_loss": 755.105142654419, "actor_loss": -179.56349937438964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.656691312789917, "step": 148000}
{"episode_reward": 314.26432608670336, "episode": 149.0, "batch_reward": 0.22784329026937486, "critic_loss": 769.5688287353515, "actor_loss": -166.5926954460144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.65226912498474, "step": 149000}
{"episode_reward": 178.65704349999658, "episode": 150.0, "batch_reward": 0.22662018258869648, "critic_loss": 736.3451753997803, "actor_loss": -164.47575952148438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
