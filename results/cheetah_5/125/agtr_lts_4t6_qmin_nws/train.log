{"episode_reward": 0.0, "episode": 1.0, "duration": 13.893747806549072, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.2289564609527588, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2826701732387778, "critic_loss": 0.043855847365080955, "actor_loss": -29.078893333843418, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 72.91861367225647, "step": 3000}
{"episode_reward": 45.10491083501512, "episode": 4.0, "batch_reward": 0.1890209942087531, "critic_loss": 0.07152820505388081, "actor_loss": -14.89494531212002, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.548861742019653, "step": 4000}
{"episode_reward": 21.620446740900594, "episode": 5.0, "batch_reward": 0.15822440126538276, "critic_loss": 0.05663904480077326, "actor_loss": -13.771083232969046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.20569086074829, "step": 5000}
{"episode_reward": 85.59551991853108, "episode": 6.0, "batch_reward": 0.135905816398561, "critic_loss": 0.05202346175163984, "actor_loss": -12.10776040558517, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.059893131256104, "step": 6000}
{"episode_reward": 7.207358582336581, "episode": 7.0, "batch_reward": 0.12017418312281371, "critic_loss": 0.059776296785101296, "actor_loss": -12.705020521998405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.522661685943604, "step": 7000}
{"episode_reward": 67.96429608851803, "episode": 8.0, "batch_reward": 0.11294870039820672, "critic_loss": 0.06281687369942665, "actor_loss": -13.682228095561266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.99984622001648, "step": 8000}
{"episode_reward": 46.01313061389787, "episode": 9.0, "batch_reward": 0.10304715013876557, "critic_loss": 0.0682217642813921, "actor_loss": -13.055852470487356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.155649662017822, "step": 9000}
{"episode_reward": 29.169433421840306, "episode": 10.0, "batch_reward": 0.09855227499455213, "critic_loss": 0.06245083030685782, "actor_loss": -14.443099183619022, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.45533037185669, "step": 10000}
{"episode_reward": 57.88046994612433, "episode": 11.0, "batch_reward": 0.09344564951583743, "critic_loss": 0.0547819928266108, "actor_loss": -14.343865283221007, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.628875732421875, "step": 11000}
{"episode_reward": 51.181751072025264, "episode": 12.0, "batch_reward": 0.08980291555076837, "critic_loss": 0.060431765424087645, "actor_loss": -14.839989795178175, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.70103693008423, "step": 12000}
{"episode_reward": 43.96455538605991, "episode": 13.0, "batch_reward": 0.08495494604855776, "critic_loss": 0.06850637044012546, "actor_loss": -14.50495808956027, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.481701612472534, "step": 13000}
{"episode_reward": 19.550288603808614, "episode": 14.0, "batch_reward": 0.08161940449103713, "critic_loss": 0.07286130055040121, "actor_loss": -15.480527289360762, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.020970582962036, "step": 14000}
{"episode_reward": 64.98635003203513, "episode": 15.0, "batch_reward": 0.08103480076044797, "critic_loss": 0.07256500987149775, "actor_loss": -13.616833241194486, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41163921356201, "step": 15000}
{"episode_reward": 86.87126089696277, "episode": 16.0, "batch_reward": 0.08078724579513073, "critic_loss": 0.08362747624143958, "actor_loss": -13.747400245308876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.00553274154663, "step": 16000}
{"episode_reward": 88.39116031691283, "episode": 17.0, "batch_reward": 0.08219526376947761, "critic_loss": 0.10206290214881301, "actor_loss": -15.072812121480704, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.416269779205322, "step": 17000}
{"episode_reward": 108.15577890251852, "episode": 18.0, "batch_reward": 0.08512711070105433, "critic_loss": 0.12148472501337529, "actor_loss": -15.694518469199538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.011348485946655, "step": 18000}
{"episode_reward": 147.50665618426058, "episode": 19.0, "batch_reward": 0.09037288725376129, "critic_loss": 0.15923058040812613, "actor_loss": -15.79211314895749, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.188379764556885, "step": 19000}
{"episode_reward": 198.9377939974759, "episode": 20.0, "batch_reward": 0.09489557865262031, "critic_loss": 0.19891740636527538, "actor_loss": -15.484321607217193, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.334221124649048, "step": 20000}
{"episode_reward": 141.4207242669728, "episode": 21.0, "batch_reward": 0.09792336515709758, "critic_loss": 0.22159663742035626, "actor_loss": -15.096047877520324, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.32123398780823, "step": 21000}
{"episode_reward": 185.2091840185701, "episode": 22.0, "batch_reward": 0.09945195232331752, "critic_loss": 0.22422531450539826, "actor_loss": -16.238487457156182, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.358977794647217, "step": 22000}
{"episode_reward": 51.47599275125977, "episode": 23.0, "batch_reward": 0.0976363960430026, "critic_loss": 0.2504793072119355, "actor_loss": -16.456945616722106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.209594249725342, "step": 23000}
{"episode_reward": 43.90563169018434, "episode": 24.0, "batch_reward": 0.09486522355675697, "critic_loss": 0.2410997095182538, "actor_loss": -15.522155165195466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.850127458572388, "step": 24000}
{"episode_reward": 56.16812763779317, "episode": 25.0, "batch_reward": 0.09501649338379502, "critic_loss": 0.284916990481317, "actor_loss": -16.29877005815506, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.208765745162964, "step": 25000}
{"episode_reward": 121.93115158445089, "episode": 26.0, "batch_reward": 0.09636383692920208, "critic_loss": 0.316364110276103, "actor_loss": -16.569220203876494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.128221035003662, "step": 26000}
{"episode_reward": 131.42777256317228, "episode": 27.0, "batch_reward": 0.09793704254180192, "critic_loss": 0.330307719796896, "actor_loss": -16.66003332185745, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.33051085472107, "step": 27000}
{"episode_reward": 159.97426414795558, "episode": 28.0, "batch_reward": 0.10021745543181897, "critic_loss": 0.3277423035055399, "actor_loss": -17.179450274944305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.660168647766113, "step": 28000}
{"episode_reward": 191.26242487585804, "episode": 29.0, "batch_reward": 0.1020498932749033, "critic_loss": 0.32992403768002987, "actor_loss": -16.642553460121153, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.24350881576538, "step": 29000}
{"episode_reward": 43.98730260569448, "episode": 30.0, "batch_reward": 0.10191171543300152, "critic_loss": 0.34915792836248877, "actor_loss": -16.83222833251953, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.56010937690735, "step": 30000}
{"episode_reward": 154.7097444113436, "episode": 31.0, "batch_reward": 0.10343114536628127, "critic_loss": 0.3621103562414646, "actor_loss": -16.800764528274534, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.41170787811279, "step": 31000}
{"episode_reward": 223.91855683743506, "episode": 32.0, "batch_reward": 0.10753939495235681, "critic_loss": 0.3959436553120613, "actor_loss": -17.521558994293212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.633057832717896, "step": 32000}
{"episode_reward": 255.1384657213386, "episode": 33.0, "batch_reward": 0.11059861837327481, "critic_loss": 0.39786109010875226, "actor_loss": -17.914484871864317, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.03227949142456, "step": 33000}
{"episode_reward": 87.05938177294588, "episode": 34.0, "batch_reward": 0.11227529672533273, "critic_loss": 0.4124739761352539, "actor_loss": -18.785388920783998, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.254450798034668, "step": 34000}
{"episode_reward": 297.1231246315391, "episode": 35.0, "batch_reward": 0.11578994599729776, "critic_loss": 0.43141228203475473, "actor_loss": -18.390009033203125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.275784492492676, "step": 35000}
{"episode_reward": 113.9164731301977, "episode": 36.0, "batch_reward": 0.11549328538775444, "critic_loss": 0.4397044399231672, "actor_loss": -19.32544186782837, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.068105936050415, "step": 36000}
{"episode_reward": 143.24220656721548, "episode": 37.0, "batch_reward": 0.11490227310359478, "critic_loss": 0.4450923995375633, "actor_loss": -19.00970291137695, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.610395669937134, "step": 37000}
{"episode_reward": 77.31120705551601, "episode": 38.0, "batch_reward": 0.11580952851474285, "critic_loss": 0.47547863994538786, "actor_loss": -18.582493856430055, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41847515106201, "step": 38000}
{"episode_reward": 104.00756506450679, "episode": 39.0, "batch_reward": 0.11635875486582517, "critic_loss": 0.45904894241690636, "actor_loss": -18.10121409034729, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.659362316131592, "step": 39000}
{"episode_reward": 237.64196505587856, "episode": 40.0, "batch_reward": 0.11883282308280468, "critic_loss": 0.4614540576338768, "actor_loss": -18.62944620513916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34509038925171, "step": 40000}
{"episode_reward": 249.6291707890012, "episode": 41.0, "batch_reward": 0.12273665164411068, "critic_loss": 0.4655487302988768, "actor_loss": -18.954350070953367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.37041163444519, "step": 41000}
{"episode_reward": 173.8241067034129, "episode": 42.0, "batch_reward": 0.12472265105694533, "critic_loss": 0.470385771587491, "actor_loss": -19.406737941741945, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.58218002319336, "step": 42000}
{"episode_reward": 329.07981315671, "episode": 43.0, "batch_reward": 0.1301892766058445, "critic_loss": 0.5191133912652731, "actor_loss": -20.0414771194458, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.28038191795349, "step": 43000}
{"episode_reward": 340.46999607210614, "episode": 44.0, "batch_reward": 0.13337230396270752, "critic_loss": 0.5193045613616705, "actor_loss": -20.607119676589967, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.06560468673706, "step": 44000}
{"episode_reward": 261.6717452539168, "episode": 45.0, "batch_reward": 0.13477654784172774, "critic_loss": 0.47501431588828563, "actor_loss": -20.334079881668092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.119603157043457, "step": 45000}
{"episode_reward": 67.18852588694746, "episode": 46.0, "batch_reward": 0.13504865086078643, "critic_loss": 0.5195016468167305, "actor_loss": -20.508248529434205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.279483318328857, "step": 46000}
{"episode_reward": 316.2757437490842, "episode": 47.0, "batch_reward": 0.1395815191194415, "critic_loss": 0.60417631880939, "actor_loss": -20.877619413375854, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.725040435791016, "step": 47000}
{"episode_reward": 215.9758147149557, "episode": 48.0, "batch_reward": 0.13932906565070152, "critic_loss": 0.532388053894043, "actor_loss": -21.12900848197937, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.15247631072998, "step": 48000}
{"episode_reward": 137.9523702277667, "episode": 49.0, "batch_reward": 0.13954422613978387, "critic_loss": 0.49739215010404586, "actor_loss": -20.71493108177185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.585002660751343, "step": 49000}
{"episode_reward": 110.55843148493845, "episode": 50.0, "batch_reward": 0.13896344044059514, "critic_loss": 0.533762932881713, "actor_loss": -20.905699405670166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.36927032470703, "step": 50000}
{"episode_reward": 275.87074732241985, "episode": 51.0, "batch_reward": 0.14061450608074666, "critic_loss": 0.5057182890325784, "actor_loss": -21.301045606613158, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.723024129867554, "step": 51000}
{"episode_reward": 63.29868304782947, "episode": 52.0, "batch_reward": 0.13999704095721244, "critic_loss": 0.47673032312095165, "actor_loss": -20.520620557785033, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.39898657798767, "step": 52000}
{"episode_reward": 159.67770884208582, "episode": 53.0, "batch_reward": 0.14090193857252598, "critic_loss": 0.525795055270195, "actor_loss": -20.853650636672974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.31631588935852, "step": 53000}
{"episode_reward": 158.43225115822767, "episode": 54.0, "batch_reward": 0.14135340301692487, "critic_loss": 0.45715830363333226, "actor_loss": -20.646831228256225, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.569462060928345, "step": 54000}
{"episode_reward": 318.80270893512, "episode": 55.0, "batch_reward": 0.14391413381695747, "critic_loss": 0.49147505168616773, "actor_loss": -21.128393829345704, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.137303829193115, "step": 55000}
{"episode_reward": 104.2004667456639, "episode": 56.0, "batch_reward": 0.1415986295863986, "critic_loss": 0.49872455531358717, "actor_loss": -20.447535390853883, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.333437204360962, "step": 56000}
{"episode_reward": 24.5425126109175, "episode": 57.0, "batch_reward": 0.1429107561632991, "critic_loss": 0.4478844431191683, "actor_loss": -20.791102991104125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.208100080490112, "step": 57000}
{"episode_reward": 300.2641621792386, "episode": 58.0, "batch_reward": 0.14564500378072262, "critic_loss": 0.47092294369637966, "actor_loss": -21.431145626068115, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.29268479347229, "step": 58000}
{"episode_reward": 263.15839086268176, "episode": 59.0, "batch_reward": 0.1460573807656765, "critic_loss": 0.512282981455326, "actor_loss": -21.329282667160033, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.29718327522278, "step": 59000}
{"episode_reward": 113.43802664997237, "episode": 60.0, "batch_reward": 0.14647289641201497, "critic_loss": 0.47224367886781693, "actor_loss": -21.03733269882202, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.61909770965576, "step": 60000}
{"episode_reward": 179.6656944044645, "episode": 61.0, "batch_reward": 0.14610208539664746, "critic_loss": 0.46367260156571866, "actor_loss": -21.137467723846434, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.11609506607056, "step": 61000}
{"episode_reward": 204.40744932019027, "episode": 62.0, "batch_reward": 0.1473468800932169, "critic_loss": 0.5113111942410469, "actor_loss": -21.259215267181396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.272569179534912, "step": 62000}
{"episode_reward": 241.35441863555522, "episode": 63.0, "batch_reward": 0.1490342556387186, "critic_loss": 0.484887263700366, "actor_loss": -21.55667104911804, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.277709245681763, "step": 63000}
{"episode_reward": 228.37471435302606, "episode": 64.0, "batch_reward": 0.15029499512910843, "critic_loss": 0.4705636370331049, "actor_loss": -21.311962671279908, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.288936138153076, "step": 64000}
{"episode_reward": 283.57650665307204, "episode": 65.0, "batch_reward": 0.15160742677748204, "critic_loss": 0.5071661070883274, "actor_loss": -21.485751050949098, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.672030687332153, "step": 65000}
{"episode_reward": 189.61333528621572, "episode": 66.0, "batch_reward": 0.1524684731066227, "critic_loss": 0.4804343586564064, "actor_loss": -21.374622344970703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.46808886528015, "step": 66000}
{"episode_reward": 129.4955486161266, "episode": 67.0, "batch_reward": 0.153024658896029, "critic_loss": 0.44782598221302033, "actor_loss": -21.017736017227172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.813049793243408, "step": 67000}
{"episode_reward": 227.65370376306097, "episode": 68.0, "batch_reward": 0.1541600847542286, "critic_loss": 0.4829054962694645, "actor_loss": -21.662077856063842, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23372483253479, "step": 68000}
{"episode_reward": 256.2050299761713, "episode": 69.0, "batch_reward": 0.1552470303028822, "critic_loss": 0.5005751504153013, "actor_loss": -21.408055814743044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.395257711410522, "step": 69000}
{"episode_reward": 240.5805783466374, "episode": 70.0, "batch_reward": 0.15681384988129138, "critic_loss": 0.5028352029025555, "actor_loss": -21.392470708847046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.021485328674316, "step": 70000}
{"episode_reward": 371.96276564826877, "episode": 71.0, "batch_reward": 0.16087594743072986, "critic_loss": 0.5009123670607806, "actor_loss": -22.112619012832642, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.41428232192993, "step": 71000}
{"episode_reward": 278.3154898492425, "episode": 72.0, "batch_reward": 0.16143173619359732, "critic_loss": 0.5379350031018257, "actor_loss": -22.121234899520875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.366125106811523, "step": 72000}
{"episode_reward": 370.5020335346924, "episode": 73.0, "batch_reward": 0.1646946939304471, "critic_loss": 0.5808649512529374, "actor_loss": -22.419323234558107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.509080410003662, "step": 73000}
{"episode_reward": 250.86430127034353, "episode": 74.0, "batch_reward": 0.16538354815542697, "critic_loss": 0.5103476839065552, "actor_loss": -22.12036519241333, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.20768094062805, "step": 74000}
{"episode_reward": 248.1612213133254, "episode": 75.0, "batch_reward": 0.1673870656862855, "critic_loss": 0.48258810567855837, "actor_loss": -22.34725598335266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.18951725959778, "step": 75000}
{"episode_reward": 389.945666003949, "episode": 76.0, "batch_reward": 0.16946668352931737, "critic_loss": 0.47643533720076087, "actor_loss": -22.472979961395264, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.665854692459106, "step": 76000}
{"episode_reward": 183.9322708764893, "episode": 77.0, "batch_reward": 0.16921084867417813, "critic_loss": 0.4699584826081991, "actor_loss": -22.57576681137085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.33301830291748, "step": 77000}
{"episode_reward": 161.79400932914587, "episode": 78.0, "batch_reward": 0.17086110562086104, "critic_loss": 0.5070944990664721, "actor_loss": -22.550645999908447, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.091490983963013, "step": 78000}
{"episode_reward": 426.64644307716475, "episode": 79.0, "batch_reward": 0.17238579592108727, "critic_loss": 0.4938646345287561, "actor_loss": -23.44161547279358, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.548412799835205, "step": 79000}
{"episode_reward": 388.6718567350554, "episode": 80.0, "batch_reward": 0.1743863261565566, "critic_loss": 0.4454389485567808, "actor_loss": -22.962668462753296, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.642244815826416, "step": 80000}
{"episode_reward": 54.22706771172037, "episode": 81.0, "batch_reward": 0.1749078364521265, "critic_loss": 0.46160214695334434, "actor_loss": -22.892853540420532, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.7947211265564, "step": 81000}
{"episode_reward": 397.44189725503634, "episode": 82.0, "batch_reward": 0.17647655029594897, "critic_loss": 0.4493908560574055, "actor_loss": -22.603296604156494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.847999811172485, "step": 82000}
{"episode_reward": 97.66316466816374, "episode": 83.0, "batch_reward": 0.17724684911966324, "critic_loss": 0.4438559167832136, "actor_loss": -23.31301233100891, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.10552668571472, "step": 83000}
{"episode_reward": 392.3512132020641, "episode": 84.0, "batch_reward": 0.17795437182486057, "critic_loss": 0.41453754779696467, "actor_loss": -22.915401386260985, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.854811429977417, "step": 84000}
{"episode_reward": 209.6938724055506, "episode": 85.0, "batch_reward": 0.1795555067062378, "critic_loss": 0.44169129626452924, "actor_loss": -23.023114265441894, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.28854012489319, "step": 85000}
{"episode_reward": 301.15200497419386, "episode": 86.0, "batch_reward": 0.18124677437543868, "critic_loss": 0.45128086040914056, "actor_loss": -23.516887033462524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.05676770210266, "step": 86000}
{"episode_reward": 420.16863708324667, "episode": 87.0, "batch_reward": 0.18305582441389562, "critic_loss": 0.4082772801667452, "actor_loss": -23.446790203094483, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.367698192596436, "step": 87000}
{"episode_reward": 189.38007304719736, "episode": 88.0, "batch_reward": 0.18241254043579103, "critic_loss": 0.4345294522941113, "actor_loss": -23.435130432128908, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.131367683410645, "step": 88000}
{"episode_reward": 190.46192166968154, "episode": 89.0, "batch_reward": 0.18317470075190068, "critic_loss": 0.4510033121854067, "actor_loss": -23.33050015258789, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.65641498565674, "step": 89000}
{"episode_reward": 202.2120466324912, "episode": 90.0, "batch_reward": 0.18352896293997764, "critic_loss": 0.43049086366593836, "actor_loss": -23.123548082351686, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27559781074524, "step": 90000}
{"episode_reward": 415.8239161759843, "episode": 91.0, "batch_reward": 0.18647279123961927, "critic_loss": 0.4115704119056463, "actor_loss": -23.705563676834107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.53897953033447, "step": 91000}
{"episode_reward": 444.33516158992677, "episode": 92.0, "batch_reward": 0.1893970233052969, "critic_loss": 0.3997228816449642, "actor_loss": -23.78686046218872, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.93469500541687, "step": 92000}
{"episode_reward": 263.7889796864339, "episode": 93.0, "batch_reward": 0.18979731027781963, "critic_loss": 0.40377475306391714, "actor_loss": -23.843152954101562, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.99134373664856, "step": 93000}
{"episode_reward": 228.66680176965008, "episode": 94.0, "batch_reward": 0.1915527044981718, "critic_loss": 0.41868919172883035, "actor_loss": -23.97410143661499, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.981905698776245, "step": 94000}
{"episode_reward": 374.27895891986026, "episode": 95.0, "batch_reward": 0.19198052144050598, "critic_loss": 0.43862297044694426, "actor_loss": -23.646733058929442, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.40044140815735, "step": 95000}
{"episode_reward": 194.6623464160553, "episode": 96.0, "batch_reward": 0.19184912821650504, "critic_loss": 0.38003212366998196, "actor_loss": -23.76547555923462, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.91649103164673, "step": 96000}
{"episode_reward": 305.72899352213983, "episode": 97.0, "batch_reward": 0.1929086603075266, "critic_loss": 0.39857796183228494, "actor_loss": -23.757154663085938, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.373287200927734, "step": 97000}
{"episode_reward": 145.17103773825485, "episode": 98.0, "batch_reward": 0.19348307514190674, "critic_loss": 0.38881833338737487, "actor_loss": -24.06359033203125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.275521993637085, "step": 98000}
{"episode_reward": 353.27333703178425, "episode": 99.0, "batch_reward": 0.19482014825940133, "critic_loss": 0.40448836410045624, "actor_loss": -24.03952505874634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.706679105758667, "step": 99000}
{"episode_reward": 481.2918180188673, "episode": 100.0, "batch_reward": 0.19823325976729392, "critic_loss": 0.4131272563189268, "actor_loss": -24.538185901641846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.322904348373413, "step": 100000}
{"episode_reward": 205.87747981600316, "episode": 101.0, "batch_reward": 0.19819765397906303, "critic_loss": 0.4151463417559862, "actor_loss": -24.163480350494385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.75098013877869, "step": 101000}
{"episode_reward": 478.8579029877714, "episode": 102.0, "batch_reward": 0.19907432913780213, "critic_loss": 0.3849040704220533, "actor_loss": -24.454026767730713, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.107547998428345, "step": 102000}
{"episode_reward": 207.17284801329393, "episode": 103.0, "batch_reward": 0.20068658037483691, "critic_loss": 0.4178657818138599, "actor_loss": -24.58930743789673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.072953939437866, "step": 103000}
{"episode_reward": 347.0787398699493, "episode": 104.0, "batch_reward": 0.20255233784019946, "critic_loss": 0.4018426986634731, "actor_loss": -24.537746509552, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.709635972976685, "step": 104000}
{"episode_reward": 421.72745427889276, "episode": 105.0, "batch_reward": 0.20465156881511212, "critic_loss": 0.42117393636703493, "actor_loss": -24.914625221252443, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.074928283691406, "step": 105000}
{"episode_reward": 419.36866650119373, "episode": 106.0, "batch_reward": 0.20611182801425457, "critic_loss": 0.40527053663134577, "actor_loss": -25.038295707702638, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.984217405319214, "step": 106000}
{"episode_reward": 470.4442491534801, "episode": 107.0, "batch_reward": 0.20814023926854133, "critic_loss": 0.41398351003229616, "actor_loss": -25.411666290283204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.353193283081055, "step": 107000}
{"episode_reward": 169.57312138916149, "episode": 108.0, "batch_reward": 0.20773336516320706, "critic_loss": 0.42157691209018233, "actor_loss": -25.079201431274413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.608357429504395, "step": 108000}
{"episode_reward": 170.05477190983135, "episode": 109.0, "batch_reward": 0.2083506034463644, "critic_loss": 0.3890528727769852, "actor_loss": -24.825889221191407, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.656408309936523, "step": 109000}
{"episode_reward": 434.15560050945993, "episode": 110.0, "batch_reward": 0.2106015596240759, "critic_loss": 0.43327780778706076, "actor_loss": -25.163336936950685, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.62460732460022, "step": 110000}
{"episode_reward": 475.19837933181935, "episode": 111.0, "batch_reward": 0.21310859483480454, "critic_loss": 0.4228202381134033, "actor_loss": -25.308744121551513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.11394739151001, "step": 111000}
{"episode_reward": 508.37345440696384, "episode": 112.0, "batch_reward": 0.21521876701712608, "critic_loss": 0.4409087121039629, "actor_loss": -25.61141676712036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.394410610198975, "step": 112000}
{"episode_reward": 518.7046718553538, "episode": 113.0, "batch_reward": 0.21725564873218536, "critic_loss": 0.4161567594110966, "actor_loss": -26.02720180130005, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30407404899597, "step": 113000}
{"episode_reward": 394.78751418548353, "episode": 114.0, "batch_reward": 0.21947795717418195, "critic_loss": 0.3930343027859926, "actor_loss": -25.618401432037352, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.502561807632446, "step": 114000}
{"episode_reward": 517.564174498857, "episode": 115.0, "batch_reward": 0.2223953633606434, "critic_loss": 0.37557153129577636, "actor_loss": -26.20041004562378, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.07706379890442, "step": 115000}
{"episode_reward": 344.26808457804736, "episode": 116.0, "batch_reward": 0.22387734873592854, "critic_loss": 0.36647352305054665, "actor_loss": -26.025283332824706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.486164808273315, "step": 116000}
{"episode_reward": 518.5194179181628, "episode": 117.0, "batch_reward": 0.2258904298990965, "critic_loss": 0.36528113384544847, "actor_loss": -26.77697607421875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.77106785774231, "step": 117000}
{"episode_reward": 509.4525884843994, "episode": 118.0, "batch_reward": 0.22876004180312157, "critic_loss": 0.355783535271883, "actor_loss": -26.53374346923828, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.44803524017334, "step": 118000}
{"episode_reward": 526.604804249445, "episode": 119.0, "batch_reward": 0.23053075298666953, "critic_loss": 0.36575298362970354, "actor_loss": -26.72027490234375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.394694566726685, "step": 119000}
{"episode_reward": 569.9539499705104, "episode": 120.0, "batch_reward": 0.23257365815341471, "critic_loss": 0.3932962758988142, "actor_loss": -27.13462718963623, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.711206674575806, "step": 120000}
{"episode_reward": 215.5861756645673, "episode": 121.0, "batch_reward": 0.23432109861075878, "critic_loss": 0.35404057501256464, "actor_loss": -27.211231594085692, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.4856059551239, "step": 121000}
{"episode_reward": 504.4306927403288, "episode": 122.0, "batch_reward": 0.23630854950845243, "critic_loss": 0.3570995744764805, "actor_loss": -27.345059673309326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.424797773361206, "step": 122000}
{"episode_reward": 535.8040422932019, "episode": 123.0, "batch_reward": 0.23853285992145537, "critic_loss": 0.3522217246741056, "actor_loss": -27.930529010772705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.208271026611328, "step": 123000}
{"episode_reward": 486.278556612429, "episode": 124.0, "batch_reward": 0.23950556501746179, "critic_loss": 0.3431062627881765, "actor_loss": -27.58904108810425, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3539400100708, "step": 124000}
{"episode_reward": 519.0089764272329, "episode": 125.0, "batch_reward": 0.2436840583384037, "critic_loss": 0.31590576423704625, "actor_loss": -28.034905403137206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.25810742378235, "step": 125000}
{"episode_reward": 554.7739104936331, "episode": 126.0, "batch_reward": 0.24468724846839904, "critic_loss": 0.35141817043721674, "actor_loss": -28.00954165649414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.679524660110474, "step": 126000}
{"episode_reward": 583.1446499616774, "episode": 127.0, "batch_reward": 0.24740572403371333, "critic_loss": 0.3469767983704805, "actor_loss": -28.34036181640625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.855052709579468, "step": 127000}
{"episode_reward": 245.3314251257613, "episode": 128.0, "batch_reward": 0.24732321055233478, "critic_loss": 0.35028264816105364, "actor_loss": -28.225110095977783, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.19718623161316, "step": 128000}
{"episode_reward": 552.2521772963227, "episode": 129.0, "batch_reward": 0.24957621710002423, "critic_loss": 0.3495329335331917, "actor_loss": -28.260187259674073, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.342767000198364, "step": 129000}
{"episode_reward": 548.0259121422508, "episode": 130.0, "batch_reward": 0.2518247333467007, "critic_loss": 0.3568933466374874, "actor_loss": -28.433549980163573, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.897500038146973, "step": 130000}
{"episode_reward": 523.6642780790287, "episode": 131.0, "batch_reward": 0.25552763064205647, "critic_loss": 0.360325016528368, "actor_loss": -28.67037632369995, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.63029909133911, "step": 131000}
{"episode_reward": 450.0814308950214, "episode": 132.0, "batch_reward": 0.2562088449448347, "critic_loss": 0.35916267827898263, "actor_loss": -28.873522312164308, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.379366397857666, "step": 132000}
{"episode_reward": 556.9992442930427, "episode": 133.0, "batch_reward": 0.2571401007473469, "critic_loss": 0.3676320996209979, "actor_loss": -29.27975188064575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.49097490310669, "step": 133000}
{"episode_reward": 161.97955385613673, "episode": 134.0, "batch_reward": 0.2562901759445667, "critic_loss": 0.3709970422387123, "actor_loss": -28.891739509582518, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.20664691925049, "step": 134000}
{"episode_reward": 422.59848722303553, "episode": 135.0, "batch_reward": 0.2582044097930193, "critic_loss": 0.3542888584882021, "actor_loss": -29.080611877441406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.448058128356934, "step": 135000}
{"episode_reward": 603.5481270104024, "episode": 136.0, "batch_reward": 0.26077732725441455, "critic_loss": 0.3725620685964823, "actor_loss": -29.234312343597413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.52662420272827, "step": 136000}
{"episode_reward": 611.260645705651, "episode": 137.0, "batch_reward": 0.2626773244589567, "critic_loss": 0.36752331164479257, "actor_loss": -29.755255619049073, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.440929889678955, "step": 137000}
{"episode_reward": 305.6023450507689, "episode": 138.0, "batch_reward": 0.2640394172370434, "critic_loss": 0.34660867968201636, "actor_loss": -30.069117630004882, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.287802696228027, "step": 138000}
{"episode_reward": 343.01220531249226, "episode": 139.0, "batch_reward": 0.2637708116918802, "critic_loss": 0.37839958296716214, "actor_loss": -30.066375186920165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.224628448486328, "step": 139000}
{"episode_reward": 566.104113169814, "episode": 140.0, "batch_reward": 0.26544821260869506, "critic_loss": 0.3655135451704264, "actor_loss": -30.142094604492186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.09471821784973, "step": 140000}
{"episode_reward": 595.3307911081677, "episode": 141.0, "batch_reward": 0.2696981067061424, "critic_loss": 0.3814147935509682, "actor_loss": -30.675557193756102, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.147931814193726, "step": 141000}
{"episode_reward": 542.3457885117562, "episode": 142.0, "batch_reward": 0.26987051391601563, "critic_loss": 0.3866543533951044, "actor_loss": -30.379212776184083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.943394899368286, "step": 142000}
{"episode_reward": 331.7613974258827, "episode": 143.0, "batch_reward": 0.2720469986796379, "critic_loss": 0.34347831274569035, "actor_loss": -30.656902034759522, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.476115942001343, "step": 143000}
{"episode_reward": 561.4996939770955, "episode": 144.0, "batch_reward": 0.27338288363814356, "critic_loss": 0.351767344892025, "actor_loss": -30.71806141281128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.200552940368652, "step": 144000}
{"episode_reward": 254.03159119115793, "episode": 145.0, "batch_reward": 0.27389656610786917, "critic_loss": 0.38039928214251995, "actor_loss": -30.947750930786132, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.207764387130737, "step": 145000}
{"episode_reward": 554.6236746061688, "episode": 146.0, "batch_reward": 0.27494654558598997, "critic_loss": 0.3429187111854553, "actor_loss": -31.038498542785643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.637235164642334, "step": 146000}
{"episode_reward": 490.0309922121402, "episode": 147.0, "batch_reward": 0.2765784738510847, "critic_loss": 0.3689475320726633, "actor_loss": -30.88244334411621, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.9975643157959, "step": 147000}
{"episode_reward": 609.6333495654561, "episode": 148.0, "batch_reward": 0.2793225455880165, "critic_loss": 0.35246052454411986, "actor_loss": -31.461814964294433, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.185729503631592, "step": 148000}
{"episode_reward": 565.1230846740392, "episode": 149.0, "batch_reward": 0.2811942376047373, "critic_loss": 0.37802910794317723, "actor_loss": -31.553574756622314, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.726365327835083, "step": 149000}
{"episode_reward": 539.3327545014857, "episode": 150.0, "batch_reward": 0.28190193425118926, "critic_loss": 0.37074580474197866, "actor_loss": -31.397136325836183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
