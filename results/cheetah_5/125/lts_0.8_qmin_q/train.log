{"episode_reward": 0.0, "episode": 1.0, "duration": 18.50885820388794, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.587756872177124, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2854990821683276, "critic_loss": 0.17116416438981746, "actor_loss": -47.616510787359374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 63.92993140220642, "step": 3000}
{"episode_reward": 111.78706635953317, "episode": 4.0, "batch_reward": 0.21289705860614777, "critic_loss": 0.1097962232194841, "actor_loss": -37.58731019973755, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.656322956085205, "step": 4000}
{"episode_reward": 46.028201551066736, "episode": 5.0, "batch_reward": 0.17910827956348657, "critic_loss": 0.14451152564957737, "actor_loss": -33.34764640045166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.016323566436768, "step": 5000}
{"episode_reward": 159.511953990127, "episode": 6.0, "batch_reward": 0.1895853456556797, "critic_loss": 0.27626049222052096, "actor_loss": -35.11097867584228, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.042019844055176, "step": 6000}
{"episode_reward": 305.06646921777445, "episode": 7.0, "batch_reward": 0.19312614412605764, "critic_loss": 0.20763845597207548, "actor_loss": -34.56235089874268, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.799025535583496, "step": 7000}
{"episode_reward": 50.32291170290506, "episode": 8.0, "batch_reward": 0.18565419583022594, "critic_loss": 0.2320613370463252, "actor_loss": -32.801669326782225, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.36021661758423, "step": 8000}
{"episode_reward": 261.3096107204122, "episode": 9.0, "batch_reward": 0.19320495265722276, "critic_loss": 0.2905057260841131, "actor_loss": -33.72966998672485, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.92974615097046, "step": 9000}
{"episode_reward": 280.255687833406, "episode": 10.0, "batch_reward": 0.19781749379634858, "critic_loss": 0.2706213337928057, "actor_loss": -34.09517330932617, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.759246826171875, "step": 10000}
{"episode_reward": 90.82218162616427, "episode": 11.0, "batch_reward": 0.19106150087714197, "critic_loss": 0.27790102130919697, "actor_loss": -32.866510692596435, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.69124627113342, "step": 11000}
{"episode_reward": 178.1965762093271, "episode": 12.0, "batch_reward": 0.19533697117865084, "critic_loss": 0.2990138420909643, "actor_loss": -32.56041793441772, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.173019886016846, "step": 12000}
{"episode_reward": 349.05460305281247, "episode": 13.0, "batch_reward": 0.20354517728090285, "critic_loss": 0.30114683912694457, "actor_loss": -32.59683205413818, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.72832727432251, "step": 13000}
{"episode_reward": 159.4673332877806, "episode": 14.0, "batch_reward": 0.203548727363348, "critic_loss": 0.28933232606947423, "actor_loss": -31.504248695373533, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.187190532684326, "step": 14000}
{"episode_reward": 298.5471609791774, "episode": 15.0, "batch_reward": 0.2106230189204216, "critic_loss": 0.30573528829216956, "actor_loss": -32.687515850067136, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.876904249191284, "step": 15000}
{"episode_reward": 377.90942753736374, "episode": 16.0, "batch_reward": 0.2218841877281666, "critic_loss": 0.31724039614200594, "actor_loss": -32.93114158630371, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.26965832710266, "step": 16000}
{"episode_reward": 336.14651780936555, "episode": 17.0, "batch_reward": 0.22784121103584767, "critic_loss": 0.33260228553414345, "actor_loss": -33.64300827026367, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.177479028701782, "step": 17000}
{"episode_reward": 373.6332564692483, "episode": 18.0, "batch_reward": 0.23566014876961708, "critic_loss": 0.3240442199110985, "actor_loss": -33.98315653991699, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.31699252128601, "step": 18000}
{"episode_reward": 227.50844830863355, "episode": 19.0, "batch_reward": 0.23596406921744348, "critic_loss": 0.3184493952691555, "actor_loss": -33.390404941558835, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.941738843917847, "step": 19000}
{"episode_reward": 275.8973745575321, "episode": 20.0, "batch_reward": 0.23806999295949935, "critic_loss": 0.33053509655594826, "actor_loss": -33.94051081848144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.70099687576294, "step": 20000}
{"episode_reward": 368.32046005168337, "episode": 21.0, "batch_reward": 0.2418267106860876, "critic_loss": 0.3612713481336832, "actor_loss": -34.28543468475342, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.8357572555542, "step": 21000}
{"episode_reward": 192.5166837533606, "episode": 22.0, "batch_reward": 0.2390682696402073, "critic_loss": 0.3858727628290653, "actor_loss": -33.67268082046509, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.959731340408325, "step": 22000}
{"episode_reward": 223.5346626998567, "episode": 23.0, "batch_reward": 0.23611408515274523, "critic_loss": 0.3971534127444029, "actor_loss": -33.54112292861939, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.73954677581787, "step": 23000}
{"episode_reward": 46.124681875931465, "episode": 24.0, "batch_reward": 0.23193269959092142, "critic_loss": 0.41992580705881116, "actor_loss": -32.84883888244629, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.025134325027466, "step": 24000}
{"episode_reward": 206.0804565031241, "episode": 25.0, "batch_reward": 0.2310143343359232, "critic_loss": 0.4128947607278824, "actor_loss": -32.36890517044068, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.93596649169922, "step": 25000}
{"episode_reward": 343.581439093518, "episode": 26.0, "batch_reward": 0.23050657111406325, "critic_loss": 0.40789949034154416, "actor_loss": -32.681663471221924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.083661794662476, "step": 26000}
{"episode_reward": 62.601801283884534, "episode": 27.0, "batch_reward": 0.23063806764781475, "critic_loss": 0.41229516407847405, "actor_loss": -32.014617279052736, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.15755009651184, "step": 27000}
{"episode_reward": 382.6338191776618, "episode": 28.0, "batch_reward": 0.23671586927771568, "critic_loss": 0.43545835334062577, "actor_loss": -32.369356182098386, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.85707950592041, "step": 28000}
{"episode_reward": 430.2202446666555, "episode": 29.0, "batch_reward": 0.2448864688426256, "critic_loss": 0.42693602791428564, "actor_loss": -33.35452235031128, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.975215673446655, "step": 29000}
{"episode_reward": 463.6139419827914, "episode": 30.0, "batch_reward": 0.252760435923934, "critic_loss": 0.43241626214981077, "actor_loss": -33.440974533081054, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.004849195480347, "step": 30000}
{"episode_reward": 518.7185062289193, "episode": 31.0, "batch_reward": 0.2560002827495337, "critic_loss": 0.4532062117755413, "actor_loss": -33.78224126434326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.67529916763306, "step": 31000}
{"episode_reward": 124.46824868546969, "episode": 32.0, "batch_reward": 0.24969693821668626, "critic_loss": 0.44830190429091454, "actor_loss": -32.67639643096924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.082345008850098, "step": 32000}
{"episode_reward": 63.879425983816986, "episode": 33.0, "batch_reward": 0.25105283765494824, "critic_loss": 0.469159264460206, "actor_loss": -33.128624141693116, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.07380771636963, "step": 33000}
{"episode_reward": 495.30871293037416, "episode": 34.0, "batch_reward": 0.2572166903316975, "critic_loss": 0.49897139555215836, "actor_loss": -33.13110473251343, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.629146337509155, "step": 34000}
{"episode_reward": 512.3277381987183, "episode": 35.0, "batch_reward": 0.26035601879656317, "critic_loss": 0.5100961140990258, "actor_loss": -33.933259479522704, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.9080810546875, "step": 35000}
{"episode_reward": 96.29708945191376, "episode": 36.0, "batch_reward": 0.25696790263056757, "critic_loss": 0.4928604532778263, "actor_loss": -32.66327822494507, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.393452167510986, "step": 36000}
{"episode_reward": 173.62092737766102, "episode": 37.0, "batch_reward": 0.25634563636779784, "critic_loss": 0.5242523821890355, "actor_loss": -33.24365145874023, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.6617169380188, "step": 37000}
{"episode_reward": 337.5193103549741, "episode": 38.0, "batch_reward": 0.2600884182602167, "critic_loss": 0.5222666929364205, "actor_loss": -33.35914289093017, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.41571879386902, "step": 38000}
{"episode_reward": 448.10896507654684, "episode": 39.0, "batch_reward": 0.2659500577300787, "critic_loss": 0.4973783859908581, "actor_loss": -33.92818578720093, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.972931385040283, "step": 39000}
{"episode_reward": 525.5908768600497, "episode": 40.0, "batch_reward": 0.27128554932773113, "critic_loss": 0.5268281008303165, "actor_loss": -34.41570139312744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.893572092056274, "step": 40000}
{"episode_reward": 503.99105291061335, "episode": 41.0, "batch_reward": 0.2774237148910761, "critic_loss": 0.5541407034993172, "actor_loss": -34.94249356842041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.879408836364746, "step": 41000}
{"episode_reward": 462.53822355354157, "episode": 42.0, "batch_reward": 0.2821024387329817, "critic_loss": 0.5125941341817379, "actor_loss": -34.79260671615601, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.099952936172485, "step": 42000}
{"episode_reward": 532.2595368650076, "episode": 43.0, "batch_reward": 0.2858393248170614, "critic_loss": 0.5113499824106693, "actor_loss": -35.15648811340332, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.123893976211548, "step": 43000}
{"episode_reward": 226.2938458322894, "episode": 44.0, "batch_reward": 0.28735938949882983, "critic_loss": 0.48390010626614094, "actor_loss": -35.01725029754639, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.15420365333557, "step": 44000}
{"episode_reward": 558.1960347570722, "episode": 45.0, "batch_reward": 0.2921891588121653, "critic_loss": 0.48123064197599885, "actor_loss": -35.422944694519046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.935909032821655, "step": 45000}
{"episode_reward": 555.7407050397421, "episode": 46.0, "batch_reward": 0.29616613128781316, "critic_loss": 0.47279847753047943, "actor_loss": -35.749166538238526, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.420292139053345, "step": 46000}
{"episode_reward": 266.37476899901213, "episode": 47.0, "batch_reward": 0.29647071845829487, "critic_loss": 0.4943417348265648, "actor_loss": -35.92430784225464, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.909559965133667, "step": 47000}
{"episode_reward": 328.3305437660371, "episode": 48.0, "batch_reward": 0.29752424313127995, "critic_loss": 0.4896159018576145, "actor_loss": -35.74623264694214, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.007066011428833, "step": 48000}
{"episode_reward": 506.1409323649193, "episode": 49.0, "batch_reward": 0.3033672009110451, "critic_loss": 0.46905173528194427, "actor_loss": -36.6797173538208, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.472128868103027, "step": 49000}
{"episode_reward": 561.2066514824518, "episode": 50.0, "batch_reward": 0.30617298080027106, "critic_loss": 0.4830966662466526, "actor_loss": -36.46524268722534, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.020795106887817, "step": 50000}
{"episode_reward": 513.5731525135293, "episode": 51.0, "batch_reward": 0.31208308927714823, "critic_loss": 0.4970598074197769, "actor_loss": -37.15925133895874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.62119913101196, "step": 51000}
{"episode_reward": 399.06388954951524, "episode": 52.0, "batch_reward": 0.3130884736329317, "critic_loss": 0.5014355757534504, "actor_loss": -37.015128932952884, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.686943769454956, "step": 52000}
{"episode_reward": 462.2870041502838, "episode": 53.0, "batch_reward": 0.31700154328346253, "critic_loss": 0.5294667682349682, "actor_loss": -37.46065589523315, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.26321315765381, "step": 53000}
{"episode_reward": 582.4632820009502, "episode": 54.0, "batch_reward": 0.3209846525490284, "critic_loss": 0.5354664767682552, "actor_loss": -37.43298243713379, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.853548526763916, "step": 54000}
{"episode_reward": 554.2764983661656, "episode": 55.0, "batch_reward": 0.3228555215299129, "critic_loss": 0.5385580911040306, "actor_loss": -38.324670444488525, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.964935541152954, "step": 55000}
{"episode_reward": 189.0029071109925, "episode": 56.0, "batch_reward": 0.31900896432995796, "critic_loss": 0.6104478715062142, "actor_loss": -37.793161724090574, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.763490200042725, "step": 56000}
{"episode_reward": 22.259098091498892, "episode": 57.0, "batch_reward": 0.3165348679870367, "critic_loss": 0.5388887486159801, "actor_loss": -36.896277458190916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.90481925010681, "step": 57000}
{"episode_reward": 478.76015964258096, "episode": 58.0, "batch_reward": 0.3213973999917507, "critic_loss": 0.5441699581742286, "actor_loss": -37.65670018768311, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.17554521560669, "step": 58000}
{"episode_reward": 515.3916405634224, "episode": 59.0, "batch_reward": 0.32542794960737226, "critic_loss": 0.5617403249144555, "actor_loss": -37.61913728713989, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.305020570755005, "step": 59000}
{"episode_reward": 538.6194655357037, "episode": 60.0, "batch_reward": 0.32718430158495904, "critic_loss": 0.5785056999921798, "actor_loss": -37.977879138946534, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.00965714454651, "step": 60000}
{"episode_reward": 500.7755446491024, "episode": 61.0, "batch_reward": 0.3304471459984779, "critic_loss": 0.5863168463408946, "actor_loss": -38.10310400390625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.529385566711426, "step": 61000}
{"episode_reward": 516.8339252745778, "episode": 62.0, "batch_reward": 0.33266267758607865, "critic_loss": 0.5837542429864406, "actor_loss": -39.009866664886474, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.30935049057007, "step": 62000}
{"episode_reward": 552.6612270513252, "episode": 63.0, "batch_reward": 0.33645242083072663, "critic_loss": 0.6040564987957477, "actor_loss": -39.02890103912353, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.785966157913208, "step": 63000}
{"episode_reward": 532.78131336425, "episode": 64.0, "batch_reward": 0.339828859269619, "critic_loss": 0.5829359046518803, "actor_loss": -39.286716079711915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.976441621780396, "step": 64000}
{"episode_reward": 585.819593582639, "episode": 65.0, "batch_reward": 0.3436414805352688, "critic_loss": 0.5838580605983734, "actor_loss": -39.33259724426269, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.108282327651978, "step": 65000}
{"episode_reward": 560.9298109258668, "episode": 66.0, "batch_reward": 0.347662179350853, "critic_loss": 0.5784237497150898, "actor_loss": -39.750653007507324, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.031169176101685, "step": 66000}
{"episode_reward": 586.8909626211737, "episode": 67.0, "batch_reward": 0.351318985670805, "critic_loss": 0.597596449226141, "actor_loss": -40.319258106231686, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.18425726890564, "step": 67000}
{"episode_reward": 582.6494124054555, "episode": 68.0, "batch_reward": 0.3536163331270218, "critic_loss": 0.5687496418952942, "actor_loss": -40.219188758850095, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.993960857391357, "step": 68000}
{"episode_reward": 582.7029686315734, "episode": 69.0, "batch_reward": 0.3574845831096172, "critic_loss": 0.5486293706893921, "actor_loss": -40.872137447357176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.282833576202393, "step": 69000}
{"episode_reward": 601.1099151689256, "episode": 70.0, "batch_reward": 0.36041957449913026, "critic_loss": 0.5522252505421639, "actor_loss": -41.104926666259765, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.85462713241577, "step": 70000}
{"episode_reward": 606.0248108920554, "episode": 71.0, "batch_reward": 0.3654137965142727, "critic_loss": 0.5768736702203751, "actor_loss": -41.75007679367065, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.753907203674316, "step": 71000}
{"episode_reward": 534.4671344362154, "episode": 72.0, "batch_reward": 0.36754076585173606, "critic_loss": 0.5634793704748153, "actor_loss": -41.92086869430542, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.13691735267639, "step": 72000}
{"episode_reward": 602.8735209867023, "episode": 73.0, "batch_reward": 0.36967017832398413, "critic_loss": 0.5516655762493611, "actor_loss": -41.80517286300659, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.642534017562866, "step": 73000}
{"episode_reward": 539.8460781325265, "episode": 74.0, "batch_reward": 0.3724644601941109, "critic_loss": 0.5658183054924011, "actor_loss": -42.332307594299316, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.169055938720703, "step": 74000}
{"episode_reward": 572.4704178356927, "episode": 75.0, "batch_reward": 0.3765160206258297, "critic_loss": 0.5823119703531265, "actor_loss": -42.36356136703491, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.899447202682495, "step": 75000}
{"episode_reward": 602.3802219004874, "episode": 76.0, "batch_reward": 0.3784237081706524, "critic_loss": 0.5808689283132553, "actor_loss": -42.672016971588135, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.72991108894348, "step": 76000}
{"episode_reward": 592.3231859771632, "episode": 77.0, "batch_reward": 0.3805319785475731, "critic_loss": 0.5783758047819137, "actor_loss": -42.51817467880249, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.58871054649353, "step": 77000}
{"episode_reward": 516.4967567162374, "episode": 78.0, "batch_reward": 0.38360509121418, "critic_loss": 0.6009947300255298, "actor_loss": -43.187238052368166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.963327407836914, "step": 78000}
{"episode_reward": 539.2163853149749, "episode": 79.0, "batch_reward": 0.38381998375058174, "critic_loss": 0.5968317475318908, "actor_loss": -42.308708976745606, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.163411378860474, "step": 79000}
{"episode_reward": 557.9110625689741, "episode": 80.0, "batch_reward": 0.38705620741844177, "critic_loss": 0.5752890891730785, "actor_loss": -43.142388999938966, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.76433038711548, "step": 80000}
{"episode_reward": 584.4640408784372, "episode": 81.0, "batch_reward": 0.3900213090181351, "critic_loss": 0.5836421115100384, "actor_loss": -43.49020063400268, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.19671559333801, "step": 81000}
{"episode_reward": 544.1730611662667, "episode": 82.0, "batch_reward": 0.3922622290551662, "critic_loss": 0.6039921815693379, "actor_loss": -44.34545277404785, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.69812798500061, "step": 82000}
{"episode_reward": 589.9539086689405, "episode": 83.0, "batch_reward": 0.39453655898571016, "critic_loss": 0.6320018224418164, "actor_loss": -43.871856666564945, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.87156891822815, "step": 83000}
{"episode_reward": 606.7565349337208, "episode": 84.0, "batch_reward": 0.39633397218585015, "critic_loss": 0.6242133678793907, "actor_loss": -45.09623828887939, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.14699125289917, "step": 84000}
{"episode_reward": 488.1096068708141, "episode": 85.0, "batch_reward": 0.39636709302663803, "critic_loss": 0.607029258698225, "actor_loss": -44.451465335845946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.126532316207886, "step": 85000}
{"episode_reward": 545.1842443766278, "episode": 86.0, "batch_reward": 0.3996399878561497, "critic_loss": 0.6348673567175865, "actor_loss": -44.728353885650634, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.778991222381592, "step": 86000}
{"episode_reward": 576.6917612321464, "episode": 87.0, "batch_reward": 0.401538588732481, "critic_loss": 0.618383416891098, "actor_loss": -44.806782787323, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.523833513259888, "step": 87000}
{"episode_reward": 593.7828417080481, "episode": 88.0, "batch_reward": 0.40301952555775644, "critic_loss": 0.6160935807526111, "actor_loss": -44.58776978683472, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.94260287284851, "step": 88000}
{"episode_reward": 608.7842444883953, "episode": 89.0, "batch_reward": 0.4061850208938122, "critic_loss": 0.6347589864730835, "actor_loss": -45.28840057754517, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.52517580986023, "step": 89000}
{"episode_reward": 618.7250740589257, "episode": 90.0, "batch_reward": 0.4083056845963001, "critic_loss": 0.6330430012345314, "actor_loss": -45.84034071731568, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.761600017547607, "step": 90000}
{"episode_reward": 588.1989293392708, "episode": 91.0, "batch_reward": 0.41014210623502734, "critic_loss": 0.6031539466977119, "actor_loss": -45.67515734481812, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.925801038742065, "step": 91000}
{"episode_reward": 586.9583058542092, "episode": 92.0, "batch_reward": 0.4130845963358879, "critic_loss": 0.6120897907018662, "actor_loss": -45.84394505310058, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.709289073944092, "step": 92000}
{"episode_reward": 568.8333388130807, "episode": 93.0, "batch_reward": 0.41336387833952903, "critic_loss": 0.6105004815757274, "actor_loss": -45.71272416305542, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.65316390991211, "step": 93000}
{"episode_reward": 615.8390562572728, "episode": 94.0, "batch_reward": 0.4151371209025383, "critic_loss": 0.6022366136610507, "actor_loss": -46.2204154510498, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.964442253112793, "step": 94000}
{"episode_reward": 577.2476300820365, "episode": 95.0, "batch_reward": 0.4168874828219414, "critic_loss": 0.589075226932764, "actor_loss": -46.40651239013672, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.647709846496582, "step": 95000}
{"episode_reward": 578.8410693924485, "episode": 96.0, "batch_reward": 0.41882326897978783, "critic_loss": 0.5757750645875931, "actor_loss": -46.7013134765625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.977405071258545, "step": 96000}
{"episode_reward": 575.4272520359115, "episode": 97.0, "batch_reward": 0.42092190489172937, "critic_loss": 0.5837232393026351, "actor_loss": -47.01709537887573, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.942135095596313, "step": 97000}
{"episode_reward": 571.3646210561612, "episode": 98.0, "batch_reward": 0.4225335120856762, "critic_loss": 0.5840632237493992, "actor_loss": -47.032495277404784, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.92672371864319, "step": 98000}
{"episode_reward": 603.8711265719991, "episode": 99.0, "batch_reward": 0.42420481678843497, "critic_loss": 0.5803896073102951, "actor_loss": -46.64140354156494, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.734744548797607, "step": 99000}
{"episode_reward": 615.7703759158686, "episode": 100.0, "batch_reward": 0.42708935028314593, "critic_loss": 0.566435284525156, "actor_loss": -47.21363129043579, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.44972562789917, "step": 100000}
{"episode_reward": 569.1991124929439, "episode": 101.0, "batch_reward": 0.42774508720636367, "critic_loss": 0.5710834513902664, "actor_loss": -47.228262462615966, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.53424334526062, "step": 101000}
{"episode_reward": 615.1431417424816, "episode": 102.0, "batch_reward": 0.4283797327578068, "critic_loss": 0.5765002182424068, "actor_loss": -47.23519775390625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.98798656463623, "step": 102000}
{"episode_reward": 619.5261654454787, "episode": 103.0, "batch_reward": 0.43115803319215773, "critic_loss": 0.570916919708252, "actor_loss": -47.82679248809814, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.124356746673584, "step": 103000}
{"episode_reward": 607.5463631689079, "episode": 104.0, "batch_reward": 0.4327241194844246, "critic_loss": 0.5783252951800824, "actor_loss": -47.98418899154663, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.87067437171936, "step": 104000}
{"episode_reward": 541.3327915721219, "episode": 105.0, "batch_reward": 0.4345432222187519, "critic_loss": 0.6060537972599268, "actor_loss": -48.1033726348877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.316675186157227, "step": 105000}
{"episode_reward": 535.0636976936286, "episode": 106.0, "batch_reward": 0.4343560618162155, "critic_loss": 0.5919440731704235, "actor_loss": -47.93537668991089, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.734065294265747, "step": 106000}
{"episode_reward": 600.4368402829666, "episode": 107.0, "batch_reward": 0.43698224192857743, "critic_loss": 0.5506795960664749, "actor_loss": -48.365494609832766, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.068253755569458, "step": 107000}
{"episode_reward": 616.3744920768019, "episode": 108.0, "batch_reward": 0.4394652119576931, "critic_loss": 0.5511865004301071, "actor_loss": -48.45160385131836, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.793639659881592, "step": 108000}
{"episode_reward": 599.8847780303662, "episode": 109.0, "batch_reward": 0.43992227759957314, "critic_loss": 0.5709832412302493, "actor_loss": -49.18307088470459, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.726502418518066, "step": 109000}
{"episode_reward": 572.4491957085872, "episode": 110.0, "batch_reward": 0.4404234703183174, "critic_loss": 0.5793847237527371, "actor_loss": -48.888736724853516, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.486180067062378, "step": 110000}
{"episode_reward": 530.6399250501914, "episode": 111.0, "batch_reward": 0.44220544448494914, "critic_loss": 0.5809504762887955, "actor_loss": -48.939233085632324, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.608832359313965, "step": 111000}
{"episode_reward": 630.0421770316615, "episode": 112.0, "batch_reward": 0.4440257512629032, "critic_loss": 0.5714180212318897, "actor_loss": -48.69562286376953, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.905797481536865, "step": 112000}
{"episode_reward": 566.3378664251878, "episode": 113.0, "batch_reward": 0.445024112701416, "critic_loss": 0.5856168536841869, "actor_loss": -49.17445335388184, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.041531085968018, "step": 113000}
{"episode_reward": 611.6596671550675, "episode": 114.0, "batch_reward": 0.44544923582673074, "critic_loss": 0.5850947116315365, "actor_loss": -49.48972192382813, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.73503565788269, "step": 114000}
{"episode_reward": 425.10948268369515, "episode": 115.0, "batch_reward": 0.4455303391516209, "critic_loss": 0.599075726211071, "actor_loss": -49.179666053771975, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.565021991729736, "step": 115000}
{"episode_reward": 543.1926041822815, "episode": 116.0, "batch_reward": 0.44730466687679293, "critic_loss": 0.589024151802063, "actor_loss": -49.26023932647705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.80695915222168, "step": 116000}
{"episode_reward": 602.6259871547296, "episode": 117.0, "batch_reward": 0.44862010353803633, "critic_loss": 0.5485599719882012, "actor_loss": -49.294769203186036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.818227291107178, "step": 117000}
{"episode_reward": 620.9416458362224, "episode": 118.0, "batch_reward": 0.44962129071354867, "critic_loss": 0.5239261410832405, "actor_loss": -49.506303520202636, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.94647765159607, "step": 118000}
{"episode_reward": 629.6427920042694, "episode": 119.0, "batch_reward": 0.45178496235609056, "critic_loss": 0.5309305372238159, "actor_loss": -49.85990865707397, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.77444338798523, "step": 119000}
{"episode_reward": 594.8212412196324, "episode": 120.0, "batch_reward": 0.4504380325675011, "critic_loss": 0.537671515852213, "actor_loss": -49.59595436859131, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.63235592842102, "step": 120000}
{"episode_reward": 630.8415284687202, "episode": 121.0, "batch_reward": 0.45347249019145963, "critic_loss": 0.5154301203489303, "actor_loss": -49.496181930541994, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.47732090950012, "step": 121000}
{"episode_reward": 609.1704508481749, "episode": 122.0, "batch_reward": 0.45407275572419165, "critic_loss": 0.5421703351438045, "actor_loss": -49.76523194885254, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.605002880096436, "step": 122000}
{"episode_reward": 556.8274460726105, "episode": 123.0, "batch_reward": 0.4570243307352066, "critic_loss": 0.5368785226643086, "actor_loss": -49.528419372558595, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.61264705657959, "step": 123000}
{"episode_reward": 607.9146102147733, "episode": 124.0, "batch_reward": 0.45712365573644637, "critic_loss": 0.5238289904296398, "actor_loss": -50.119439971923825, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.91047978401184, "step": 124000}
{"episode_reward": 615.5526512605285, "episode": 125.0, "batch_reward": 0.45919855365157125, "critic_loss": 0.5164296975284814, "actor_loss": -50.013705253601074, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.922194004058838, "step": 125000}
{"episode_reward": 626.1134466511802, "episode": 126.0, "batch_reward": 0.4594752714037895, "critic_loss": 0.5028204148560762, "actor_loss": -49.9232338180542, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.75780963897705, "step": 126000}
{"episode_reward": 615.8632128160094, "episode": 127.0, "batch_reward": 0.4603887574374676, "critic_loss": 0.5001001597940922, "actor_loss": -50.525084739685056, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.451054334640503, "step": 127000}
{"episode_reward": 568.2719121121501, "episode": 128.0, "batch_reward": 0.461732486307621, "critic_loss": 0.4939504834860563, "actor_loss": -50.96382419586182, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.97906756401062, "step": 128000}
{"episode_reward": 599.3759381787203, "episode": 129.0, "batch_reward": 0.4631116576194763, "critic_loss": 0.5120543773025275, "actor_loss": -50.82821033477783, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.009129285812378, "step": 129000}
{"episode_reward": 591.8040272977594, "episode": 130.0, "batch_reward": 0.46336561703681944, "critic_loss": 0.5045658051520586, "actor_loss": -50.73049055480957, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.554362773895264, "step": 130000}
{"episode_reward": 566.3226471973854, "episode": 131.0, "batch_reward": 0.46531206387281415, "critic_loss": 0.49604185318946836, "actor_loss": -51.1952359085083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.73056602478027, "step": 131000}
{"episode_reward": 561.0986037649083, "episode": 132.0, "batch_reward": 0.46627618768811224, "critic_loss": 0.5131528654694557, "actor_loss": -51.23707817840576, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.04563307762146, "step": 132000}
{"episode_reward": 611.8472259827554, "episode": 133.0, "batch_reward": 0.4658706230819225, "critic_loss": 0.4952657371163368, "actor_loss": -51.08353873443603, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.163641452789307, "step": 133000}
{"episode_reward": 588.2625627943255, "episode": 134.0, "batch_reward": 0.46730129098892215, "critic_loss": 0.5285033375322818, "actor_loss": -51.27607762145996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.945355892181396, "step": 134000}
{"episode_reward": 585.6668023020134, "episode": 135.0, "batch_reward": 0.469109845072031, "critic_loss": 0.5616719610691071, "actor_loss": -51.3919465713501, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.33996081352234, "step": 135000}
{"episode_reward": 622.2547354077117, "episode": 136.0, "batch_reward": 0.4698641387224197, "critic_loss": 0.5701283944547176, "actor_loss": -51.90726840972901, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.97629165649414, "step": 136000}
{"episode_reward": 565.9243545451956, "episode": 137.0, "batch_reward": 0.46838657814264295, "critic_loss": 0.5981878167986869, "actor_loss": -51.51026742553711, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.121386766433716, "step": 137000}
{"episode_reward": 591.045227458611, "episode": 138.0, "batch_reward": 0.47126534953713417, "critic_loss": 0.5881910953819752, "actor_loss": -51.03260661315918, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.261157512664795, "step": 138000}
{"episode_reward": 587.057061844393, "episode": 139.0, "batch_reward": 0.4710487788319588, "critic_loss": 0.6007076524496079, "actor_loss": -51.17672135925293, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.030107975006104, "step": 139000}
{"episode_reward": 611.3841852762692, "episode": 140.0, "batch_reward": 0.4716162104606628, "critic_loss": 0.5667276273965836, "actor_loss": -50.98948059844971, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.1651930809021, "step": 140000}
{"episode_reward": 602.6340053687012, "episode": 141.0, "batch_reward": 0.473398459225893, "critic_loss": 0.6077815575897694, "actor_loss": -51.338049690246585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.00691890716553, "step": 141000}
{"episode_reward": 555.8278324300462, "episode": 142.0, "batch_reward": 0.4740687694549561, "critic_loss": 0.5839831734001637, "actor_loss": -51.456613082885745, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.00683283805847, "step": 142000}
{"episode_reward": 626.6146410069301, "episode": 143.0, "batch_reward": 0.4759763885438442, "critic_loss": 0.5759673909246922, "actor_loss": -51.86225854492187, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.888357639312744, "step": 143000}
{"episode_reward": 561.6009679806083, "episode": 144.0, "batch_reward": 0.47608267548680305, "critic_loss": 0.605965697824955, "actor_loss": -51.93770951843262, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.098536491394043, "step": 144000}
{"episode_reward": 545.2067066423704, "episode": 145.0, "batch_reward": 0.4777633227705956, "critic_loss": 0.6333187264502048, "actor_loss": -51.94776527404785, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.04537534713745, "step": 145000}
{"episode_reward": 608.1114438862983, "episode": 146.0, "batch_reward": 0.47646038818359376, "critic_loss": 0.617708744764328, "actor_loss": -51.80513577270508, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.698668479919434, "step": 146000}
{"episode_reward": 588.215437490571, "episode": 147.0, "batch_reward": 0.4775232686698437, "critic_loss": 0.5940443151891232, "actor_loss": -52.285844123840334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.8693265914917, "step": 147000}
{"episode_reward": 612.3421788615899, "episode": 148.0, "batch_reward": 0.47994975942373275, "critic_loss": 0.5924680843949318, "actor_loss": -52.01614134979248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.174984216690063, "step": 148000}
{"episode_reward": 602.1420018675853, "episode": 149.0, "batch_reward": 0.480018608123064, "critic_loss": 0.6010132439136505, "actor_loss": -52.257555656433105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.01444172859192, "step": 149000}
{"episode_reward": 594.0740800754647, "episode": 150.0, "batch_reward": 0.48142074605822566, "critic_loss": 0.6003264923691749, "actor_loss": -52.01766165924072, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
