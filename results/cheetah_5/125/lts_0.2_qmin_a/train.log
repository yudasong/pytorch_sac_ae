{"episode_reward": 0.0, "episode": 1.0, "duration": 17.28335213661194, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.4860053062438965, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2832671898569652, "critic_loss": 0.02428838474180384, "actor_loss": -11.9091826362633, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 60.350221395492554, "step": 3000}
{"episode_reward": 141.75676187473357, "episode": 4.0, "batch_reward": 0.22496333254873752, "critic_loss": 0.04598908116947859, "actor_loss": -14.082207650184632, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87839365005493, "step": 4000}
{"episode_reward": 64.36717944998506, "episode": 5.0, "batch_reward": 0.1878155787438154, "critic_loss": 0.04893194594606757, "actor_loss": -11.794250883102418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.950664520263672, "step": 5000}
{"episode_reward": 64.84963366054829, "episode": 6.0, "batch_reward": 0.16186841835826635, "critic_loss": 0.04707355540432036, "actor_loss": -11.038259206771851, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9111590385437, "step": 6000}
{"episode_reward": 71.3292760104704, "episode": 7.0, "batch_reward": 0.14972031682729722, "critic_loss": 0.06052283942326903, "actor_loss": -11.536177040100098, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91961169242859, "step": 7000}
{"episode_reward": 54.3559216343594, "episode": 8.0, "batch_reward": 0.1364903903827071, "critic_loss": 0.05826940913312137, "actor_loss": -11.216715023994446, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9450101852417, "step": 8000}
{"episode_reward": 53.084105228015225, "episode": 9.0, "batch_reward": 0.12789318802952768, "critic_loss": 0.06593579055741429, "actor_loss": -11.25579981136322, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.893028736114502, "step": 9000}
{"episode_reward": 62.30966597113067, "episode": 10.0, "batch_reward": 0.1225497986972332, "critic_loss": 0.08068595692142844, "actor_loss": -11.213355456352234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.938069581985474, "step": 10000}
{"episode_reward": 59.34765775232419, "episode": 11.0, "batch_reward": 0.11976398665457964, "critic_loss": 0.10697906782105565, "actor_loss": -12.225320596694946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.3594331741333, "step": 11000}
{"episode_reward": 149.23721544333225, "episode": 12.0, "batch_reward": 0.11792603937536478, "critic_loss": 0.10679680375754833, "actor_loss": -11.926386451721191, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.931509733200073, "step": 12000}
{"episode_reward": 43.10130081341909, "episode": 13.0, "batch_reward": 0.11435234461724758, "critic_loss": 0.14607812621444463, "actor_loss": -12.230815774917602, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90182089805603, "step": 13000}
{"episode_reward": 161.86655203799768, "episode": 14.0, "batch_reward": 0.11345886386930942, "critic_loss": 0.14942777337878943, "actor_loss": -12.50237103843689, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.932023286819458, "step": 14000}
{"episode_reward": 17.42216398406521, "episode": 15.0, "batch_reward": 0.11200247718393802, "critic_loss": 0.15682137382403016, "actor_loss": -12.832227783203125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.910239934921265, "step": 15000}
{"episode_reward": 133.65751234180962, "episode": 16.0, "batch_reward": 0.11218165745586157, "critic_loss": 0.19845200001448393, "actor_loss": -13.272992801666259, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.921767950057983, "step": 16000}
{"episode_reward": 101.70256955902005, "episode": 17.0, "batch_reward": 0.1123718024790287, "critic_loss": 0.261941270634532, "actor_loss": -13.414066251754761, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.906760454177856, "step": 17000}
{"episode_reward": 143.9901948233347, "episode": 18.0, "batch_reward": 0.11370130605250597, "critic_loss": 0.27715249674767256, "actor_loss": -14.107185525894165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.907972812652588, "step": 18000}
{"episode_reward": 120.59193364285613, "episode": 19.0, "batch_reward": 0.1102760140299797, "critic_loss": 0.2602970053702593, "actor_loss": -15.27707872390747, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91612696647644, "step": 19000}
{"episode_reward": 17.091849223919656, "episode": 20.0, "batch_reward": 0.10844073623418808, "critic_loss": 0.26740028290450574, "actor_loss": -15.86832258605957, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.905436038970947, "step": 20000}
{"episode_reward": 173.55471279432723, "episode": 21.0, "batch_reward": 0.11275269161909819, "critic_loss": 0.2788208341374993, "actor_loss": -16.79491880607605, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.30253481864929, "step": 21000}
{"episode_reward": 89.93254853629662, "episode": 22.0, "batch_reward": 0.10969514991343021, "critic_loss": 0.25823071965575217, "actor_loss": -16.639699304580688, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.911291122436523, "step": 22000}
{"episode_reward": 47.09682170911976, "episode": 23.0, "batch_reward": 0.11210543391853571, "critic_loss": 0.2804205208718777, "actor_loss": -16.75027668762207, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.940393924713135, "step": 23000}
{"episode_reward": 324.6477255474546, "episode": 24.0, "batch_reward": 0.1190971409752965, "critic_loss": 0.31243535262346267, "actor_loss": -17.75461722755432, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89017081260681, "step": 24000}
{"episode_reward": 221.39148140557307, "episode": 25.0, "batch_reward": 0.11989718751609325, "critic_loss": 0.30699731862545016, "actor_loss": -18.06411029434204, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.939808130264282, "step": 25000}
{"episode_reward": 43.861803899400776, "episode": 26.0, "batch_reward": 0.11699779540300369, "critic_loss": 0.34071498808264733, "actor_loss": -18.170879234313965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.94399118423462, "step": 26000}
{"episode_reward": 48.16196352860601, "episode": 27.0, "batch_reward": 0.11777931171655655, "critic_loss": 0.33580999965965747, "actor_loss": -18.47688041114807, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.900655031204224, "step": 27000}
{"episode_reward": 180.8798143236518, "episode": 28.0, "batch_reward": 0.11829483666270971, "critic_loss": 0.34779161848127843, "actor_loss": -18.773341808319092, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91597080230713, "step": 28000}
{"episode_reward": 95.00404749738838, "episode": 29.0, "batch_reward": 0.11927191707491874, "critic_loss": 0.34302576383948324, "actor_loss": -18.978966062545776, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92275357246399, "step": 29000}
{"episode_reward": 177.0247336897611, "episode": 30.0, "batch_reward": 0.11945109616219997, "critic_loss": 0.38062983368337155, "actor_loss": -19.150318567276003, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.895678520202637, "step": 30000}
{"episode_reward": 77.66099739512491, "episode": 31.0, "batch_reward": 0.1175170808956027, "critic_loss": 0.3769259994328022, "actor_loss": -19.19759836387634, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.26352262496948, "step": 31000}
{"episode_reward": 83.30418138032636, "episode": 32.0, "batch_reward": 0.11612826436012984, "critic_loss": 0.36647449265420434, "actor_loss": -19.298438146591188, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.925092697143555, "step": 32000}
{"episode_reward": 44.219869874859675, "episode": 33.0, "batch_reward": 0.11401072449237108, "critic_loss": 0.3774399787038565, "actor_loss": -19.056416479110716, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.922917127609253, "step": 33000}
{"episode_reward": 65.60240161425642, "episode": 34.0, "batch_reward": 0.11423406805843114, "critic_loss": 0.3658767128884792, "actor_loss": -19.18762933921814, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93541383743286, "step": 34000}
{"episode_reward": 138.46480567809346, "episode": 35.0, "batch_reward": 0.11587341170758009, "critic_loss": 0.4017763146460056, "actor_loss": -19.480877883911134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.895492792129517, "step": 35000}
{"episode_reward": 251.59855444569, "episode": 36.0, "batch_reward": 0.11749848403781653, "critic_loss": 0.3850088382512331, "actor_loss": -19.731056983947752, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.924243450164795, "step": 36000}
{"episode_reward": 91.43030429311145, "episode": 37.0, "batch_reward": 0.11590741569548846, "critic_loss": 0.3964918470531702, "actor_loss": -19.598433750152587, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.918511152267456, "step": 37000}
{"episode_reward": 55.95894044907446, "episode": 38.0, "batch_reward": 0.11581940276920795, "critic_loss": 0.39228334853053093, "actor_loss": -19.877303146362305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92496156692505, "step": 38000}
{"episode_reward": 148.64697822751376, "episode": 39.0, "batch_reward": 0.11916426061838865, "critic_loss": 0.46263481517136096, "actor_loss": -20.43425982093811, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.924198150634766, "step": 39000}
{"episode_reward": 369.752173894764, "episode": 40.0, "batch_reward": 0.12476802328974008, "critic_loss": 0.4919998252093792, "actor_loss": -20.84728787994385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.904703617095947, "step": 40000}
{"episode_reward": 224.2671288293885, "episode": 41.0, "batch_reward": 0.12613618502765894, "critic_loss": 0.43234014144539834, "actor_loss": -20.85200284576416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.257558822631836, "step": 41000}
{"episode_reward": 171.69089765566522, "episode": 42.0, "batch_reward": 0.127448425360024, "critic_loss": 0.4235559629201889, "actor_loss": -20.77259337615967, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.941061973571777, "step": 42000}
{"episode_reward": 211.25160723788642, "episode": 43.0, "batch_reward": 0.1301851920709014, "critic_loss": 0.5329547416269779, "actor_loss": -20.987832096099854, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.901599407196045, "step": 43000}
{"episode_reward": 299.5472051069678, "episode": 44.0, "batch_reward": 0.13318671161681414, "critic_loss": 0.5228834259063005, "actor_loss": -21.03182049560547, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.937316179275513, "step": 44000}
{"episode_reward": 131.98687004092153, "episode": 45.0, "batch_reward": 0.134968736872077, "critic_loss": 0.5368602002412081, "actor_loss": -21.19578926849365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.872319221496582, "step": 45000}
{"episode_reward": 320.7516240977772, "episode": 46.0, "batch_reward": 0.1381036801710725, "critic_loss": 0.516571554645896, "actor_loss": -21.482116550445557, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.902267694473267, "step": 46000}
{"episode_reward": 227.93183096765077, "episode": 47.0, "batch_reward": 0.1406518825441599, "critic_loss": 0.5400194046199321, "actor_loss": -21.590726902008058, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.928906440734863, "step": 47000}
{"episode_reward": 252.2342758427723, "episode": 48.0, "batch_reward": 0.14122314849495887, "critic_loss": 0.584640558630228, "actor_loss": -21.50009073638916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.916857719421387, "step": 48000}
{"episode_reward": 95.64593740772496, "episode": 49.0, "batch_reward": 0.14189937533438204, "critic_loss": 0.5911076617538928, "actor_loss": -21.560826663970946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9305260181427, "step": 49000}
{"episode_reward": 204.43621373801466, "episode": 50.0, "batch_reward": 0.1421722484305501, "critic_loss": 0.5840048344135285, "actor_loss": -21.526079727172853, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.911476612091064, "step": 50000}
{"episode_reward": 228.18947628200584, "episode": 51.0, "batch_reward": 0.14277843813598157, "critic_loss": 0.5881372385621071, "actor_loss": -21.62049474334717, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.25247764587402, "step": 51000}
{"episode_reward": 87.55426136977108, "episode": 52.0, "batch_reward": 0.14274847860634327, "critic_loss": 0.6143839200139045, "actor_loss": -21.720319271087646, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89647674560547, "step": 52000}
{"episode_reward": 188.69020974325647, "episode": 53.0, "batch_reward": 0.14364551907032727, "critic_loss": 0.6173369537889958, "actor_loss": -21.734965160369875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.94566822052002, "step": 53000}
{"episode_reward": 177.17862818054414, "episode": 54.0, "batch_reward": 0.14364180643856525, "critic_loss": 0.644486910700798, "actor_loss": -21.424594173431398, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93264102935791, "step": 54000}
{"episode_reward": 108.89725603742684, "episode": 55.0, "batch_reward": 0.14428952758759261, "critic_loss": 0.7453403126597404, "actor_loss": -21.438976997375487, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88077998161316, "step": 55000}
{"episode_reward": 317.70329706875884, "episode": 56.0, "batch_reward": 0.1466359890550375, "critic_loss": 0.7139264488220215, "actor_loss": -21.896720775604248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.94425368309021, "step": 56000}
{"episode_reward": 140.67986176342427, "episode": 57.0, "batch_reward": 0.14594793289899827, "critic_loss": 0.7415815416276454, "actor_loss": -21.842528228759765, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92359447479248, "step": 57000}
{"episode_reward": 90.60117291558446, "episode": 58.0, "batch_reward": 0.1455213281288743, "critic_loss": 0.7745818981528282, "actor_loss": -21.5596876411438, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.877902507781982, "step": 58000}
{"episode_reward": 119.26374846196485, "episode": 59.0, "batch_reward": 0.1466126485466957, "critic_loss": 0.8268851623535156, "actor_loss": -21.885264503479004, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.892765522003174, "step": 59000}
{"episode_reward": 363.06202507198475, "episode": 60.0, "batch_reward": 0.14840611573308707, "critic_loss": 0.8808567461073399, "actor_loss": -22.18858144760132, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91507387161255, "step": 60000}
{"episode_reward": 148.7522228287238, "episode": 61.0, "batch_reward": 0.14843065006285905, "critic_loss": 0.8692365208864212, "actor_loss": -22.13530920791626, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.24813961982727, "step": 61000}
{"episode_reward": 69.20899425236081, "episode": 62.0, "batch_reward": 0.1470739694684744, "critic_loss": 0.9247916706502438, "actor_loss": -21.94787413787842, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.938355207443237, "step": 62000}
{"episode_reward": 83.36673646665433, "episode": 63.0, "batch_reward": 0.14688348826020955, "critic_loss": 1.0378528171479702, "actor_loss": -22.038806270599366, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.908543348312378, "step": 63000}
{"episode_reward": 372.42784055895737, "episode": 64.0, "batch_reward": 0.14953335769474507, "critic_loss": 1.1304796622693538, "actor_loss": -22.357072536468507, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.939432859420776, "step": 64000}
{"episode_reward": 109.72136610884344, "episode": 65.0, "batch_reward": 0.14969912726432086, "critic_loss": 0.9432758601903916, "actor_loss": -22.40974827194214, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.898760318756104, "step": 65000}
{"episode_reward": 336.0604821702847, "episode": 66.0, "batch_reward": 0.15350434684753417, "critic_loss": 1.1228420058488846, "actor_loss": -22.94594008255005, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89397883415222, "step": 66000}
{"episode_reward": 200.57267076370147, "episode": 67.0, "batch_reward": 0.1513020576760173, "critic_loss": 1.043364186257124, "actor_loss": -22.62886859512329, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.911219835281372, "step": 67000}
{"episode_reward": 23.829820835404334, "episode": 68.0, "batch_reward": 0.15033429274708032, "critic_loss": 0.9896060179173947, "actor_loss": -22.527137290954588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.946213960647583, "step": 68000}
{"episode_reward": 114.86162523705543, "episode": 69.0, "batch_reward": 0.150115593098104, "critic_loss": 1.0750590735971928, "actor_loss": -22.524097297668458, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91224980354309, "step": 69000}
{"episode_reward": 176.58366488361037, "episode": 70.0, "batch_reward": 0.1505429193675518, "critic_loss": 1.0105174266994, "actor_loss": -22.57972922515869, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.913224697113037, "step": 70000}
{"episode_reward": 121.93947711422108, "episode": 71.0, "batch_reward": 0.15079946682602166, "critic_loss": 1.0817480075359345, "actor_loss": -22.634979389190672, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.267998933792114, "step": 71000}
{"episode_reward": 285.9465645254164, "episode": 72.0, "batch_reward": 0.15325901214033366, "critic_loss": 1.0701360599398613, "actor_loss": -23.036835609436036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.966195344924927, "step": 72000}
{"episode_reward": 311.42907810714627, "episode": 73.0, "batch_reward": 0.15402042539417743, "critic_loss": 1.1093640856146811, "actor_loss": -23.059333786010743, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.962666273117065, "step": 73000}
{"episode_reward": 88.47094985345315, "episode": 74.0, "batch_reward": 0.15418508430570363, "critic_loss": 1.0928434481620788, "actor_loss": -23.057541564941406, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.947878122329712, "step": 74000}
{"episode_reward": 185.612472685704, "episode": 75.0, "batch_reward": 0.15469399404525758, "critic_loss": 1.1153674136698246, "actor_loss": -23.125526035308837, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.940606117248535, "step": 75000}
{"episode_reward": 359.8295849571185, "episode": 76.0, "batch_reward": 0.1574402497559786, "critic_loss": 1.1291860972046852, "actor_loss": -23.265565189361574, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89356780052185, "step": 76000}
{"episode_reward": 344.63466660590007, "episode": 77.0, "batch_reward": 0.1606501984745264, "critic_loss": 1.2597926241159438, "actor_loss": -23.665313591003418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92173457145691, "step": 77000}
{"episode_reward": 298.7924106619742, "episode": 78.0, "batch_reward": 0.16216146380454302, "critic_loss": 1.1985330564379693, "actor_loss": -23.82329270172119, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95040512084961, "step": 78000}
{"episode_reward": 358.25117057754835, "episode": 79.0, "batch_reward": 0.1630393870472908, "critic_loss": 1.1899627879261971, "actor_loss": -23.83196446609497, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90719985961914, "step": 79000}
{"episode_reward": 319.79594987833485, "episode": 80.0, "batch_reward": 0.1650381730645895, "critic_loss": 1.1973740341067314, "actor_loss": -23.88477051925659, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.940352201461792, "step": 80000}
{"episode_reward": 76.23912844919764, "episode": 81.0, "batch_reward": 0.1641494529992342, "critic_loss": 1.1147838651537896, "actor_loss": -23.822854907989502, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.30365610122681, "step": 81000}
{"episode_reward": 108.42605160992913, "episode": 82.0, "batch_reward": 0.1644192846119404, "critic_loss": 1.163398584842682, "actor_loss": -23.848336734771728, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.957605361938477, "step": 82000}
{"episode_reward": 172.23487321168543, "episode": 83.0, "batch_reward": 0.16382098457962274, "critic_loss": 1.1382620578408242, "actor_loss": -23.62894931411743, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.964584589004517, "step": 83000}
{"episode_reward": 129.56521808082442, "episode": 84.0, "batch_reward": 0.16272304317355155, "critic_loss": 1.1898184494972228, "actor_loss": -23.486330680847168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95881986618042, "step": 84000}
{"episode_reward": 73.5714341365944, "episode": 85.0, "batch_reward": 0.16293623042106628, "critic_loss": 1.1461397415697574, "actor_loss": -23.46908947753906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.957170486450195, "step": 85000}
{"episode_reward": 211.88635024704794, "episode": 86.0, "batch_reward": 0.16244420767575501, "critic_loss": 1.0897268755435943, "actor_loss": -23.294806941986085, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95860743522644, "step": 86000}
{"episode_reward": 140.36020863927376, "episode": 87.0, "batch_reward": 0.16325457503646612, "critic_loss": 1.164048918247223, "actor_loss": -23.24968280029297, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95743680000305, "step": 87000}
{"episode_reward": 241.41733181701278, "episode": 88.0, "batch_reward": 0.1636280625537038, "critic_loss": 1.2231110556423663, "actor_loss": -23.139389862060547, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.935195207595825, "step": 88000}
{"episode_reward": 131.56196073941896, "episode": 89.0, "batch_reward": 0.16387095448374747, "critic_loss": 1.0554467260837554, "actor_loss": -23.199222770690916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90090322494507, "step": 89000}
{"episode_reward": 433.5382626957876, "episode": 90.0, "batch_reward": 0.1672825406193733, "critic_loss": 1.1219041196405888, "actor_loss": -23.557324390411377, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93178081512451, "step": 90000}
{"episode_reward": 478.49645552318935, "episode": 91.0, "batch_reward": 0.16951080220937728, "critic_loss": 1.1118163809776307, "actor_loss": -23.635144165039062, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.35544991493225, "step": 91000}
{"episode_reward": 92.26730826080468, "episode": 92.0, "batch_reward": 0.16984102874994278, "critic_loss": 1.1013030815422535, "actor_loss": -23.635648204803466, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.970479011535645, "step": 92000}
{"episode_reward": 258.4682779559079, "episode": 93.0, "batch_reward": 0.16935243088006974, "critic_loss": 0.9837994698882103, "actor_loss": -23.372770820617674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.998028993606567, "step": 93000}
{"episode_reward": 70.0010292971337, "episode": 94.0, "batch_reward": 0.16924631568789483, "critic_loss": 1.0376366411447524, "actor_loss": -23.473293205261232, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.950254440307617, "step": 94000}
{"episode_reward": 368.3634463414927, "episode": 95.0, "batch_reward": 0.1717875816375017, "critic_loss": 0.9693749427497387, "actor_loss": -23.86242839050293, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.917412042617798, "step": 95000}
{"episode_reward": 424.0079750921941, "episode": 96.0, "batch_reward": 0.17420676228404045, "critic_loss": 1.0635111546814442, "actor_loss": -23.652584495544435, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.976622343063354, "step": 96000}
{"episode_reward": 373.5372571877675, "episode": 97.0, "batch_reward": 0.17720915634930134, "critic_loss": 0.9460572212934494, "actor_loss": -24.153646224975585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.94584035873413, "step": 97000}
{"episode_reward": 436.9233866068447, "episode": 98.0, "batch_reward": 0.17975759968161584, "critic_loss": 0.9433471876382827, "actor_loss": -24.271177185058594, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.956243753433228, "step": 98000}
{"episode_reward": 414.85249460978804, "episode": 99.0, "batch_reward": 0.18004911325871945, "critic_loss": 0.8627940083742142, "actor_loss": -24.179364501953124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.976508855819702, "step": 99000}
{"episode_reward": 126.72092413141307, "episode": 100.0, "batch_reward": 0.18169007337093354, "critic_loss": 0.8521982355415821, "actor_loss": -24.156861240386963, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.924620389938354, "step": 100000}
{"episode_reward": 426.40221256313686, "episode": 101.0, "batch_reward": 0.18351403449475764, "critic_loss": 0.8319691429138184, "actor_loss": -24.30767751312256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.260992765426636, "step": 101000}
{"episode_reward": 334.40064390796994, "episode": 102.0, "batch_reward": 0.1843196551501751, "critic_loss": 0.760328134149313, "actor_loss": -24.233198722839354, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.948984146118164, "step": 102000}
{"episode_reward": 365.02512791647894, "episode": 103.0, "batch_reward": 0.18592569296061992, "critic_loss": 0.7747825620770454, "actor_loss": -24.36618368148804, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91697335243225, "step": 103000}
{"episode_reward": 219.10111371601704, "episode": 104.0, "batch_reward": 0.18682374015450479, "critic_loss": 0.8590379634201527, "actor_loss": -24.116405738830565, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92424440383911, "step": 104000}
{"episode_reward": 217.9156441667489, "episode": 105.0, "batch_reward": 0.18663161727786065, "critic_loss": 0.8087195612192154, "actor_loss": -24.052858448028566, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.947160482406616, "step": 105000}
{"episode_reward": 178.01513544970993, "episode": 106.0, "batch_reward": 0.18614832243323326, "critic_loss": 0.8421610726714134, "actor_loss": -23.967080852508545, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.933942079544067, "step": 106000}
{"episode_reward": 197.19088166452917, "episode": 107.0, "batch_reward": 0.18697502310574055, "critic_loss": 0.7985850307941437, "actor_loss": -24.004148174285888, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.907042503356934, "step": 107000}
{"episode_reward": 469.1765887521041, "episode": 108.0, "batch_reward": 0.188751552477479, "critic_loss": 0.7825340627133847, "actor_loss": -24.051030433654784, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.912848711013794, "step": 108000}
{"episode_reward": 337.4487383330442, "episode": 109.0, "batch_reward": 0.19010553827881813, "critic_loss": 0.7450648346245289, "actor_loss": -23.990416477203368, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.904574632644653, "step": 109000}
{"episode_reward": 118.82453830169038, "episode": 110.0, "batch_reward": 0.18982437893748283, "critic_loss": 0.7303318739533424, "actor_loss": -23.89209390258789, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91667604446411, "step": 110000}
{"episode_reward": 189.13319957548393, "episode": 111.0, "batch_reward": 0.1909950171560049, "critic_loss": 0.7321358073949814, "actor_loss": -23.933692432403564, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.25692439079285, "step": 111000}
{"episode_reward": 503.8663214019517, "episode": 112.0, "batch_reward": 0.1933903037160635, "critic_loss": 0.6758425868451595, "actor_loss": -23.83900590133667, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.900774002075195, "step": 112000}
{"episode_reward": 185.71067983433832, "episode": 113.0, "batch_reward": 0.1925702848881483, "critic_loss": 0.7259744092524052, "actor_loss": -23.748233779907228, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9276385307312, "step": 113000}
{"episode_reward": 235.4403671823982, "episode": 114.0, "batch_reward": 0.19244158509373666, "critic_loss": 0.6285081656575203, "actor_loss": -23.687431667327882, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97015118598938, "step": 114000}
{"episode_reward": 107.48718900429371, "episode": 115.0, "batch_reward": 0.1927946943640709, "critic_loss": 0.6336021415889264, "actor_loss": -23.622355731964113, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87481713294983, "step": 115000}
{"episode_reward": 395.02367964094066, "episode": 116.0, "batch_reward": 0.19484316681325436, "critic_loss": 0.6673631923347711, "actor_loss": -23.753975967407225, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.941604137420654, "step": 116000}
{"episode_reward": 215.1284425060081, "episode": 117.0, "batch_reward": 0.1953060014396906, "critic_loss": 0.6228805963099003, "actor_loss": -23.705044261932372, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.927712202072144, "step": 117000}
{"episode_reward": 510.2724098633122, "episode": 118.0, "batch_reward": 0.1968971128463745, "critic_loss": 0.6965451167523861, "actor_loss": -23.52014493179321, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.911208629608154, "step": 118000}
{"episode_reward": 127.59496284404072, "episode": 119.0, "batch_reward": 0.19745166411995888, "critic_loss": 0.6150661092549562, "actor_loss": -23.630324645996094, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.888450145721436, "step": 119000}
{"episode_reward": 511.0665042695376, "episode": 120.0, "batch_reward": 0.1985445713698864, "critic_loss": 0.6347797469049692, "actor_loss": -23.515951721191406, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.933428287506104, "step": 120000}
{"episode_reward": 404.9822882329572, "episode": 121.0, "batch_reward": 0.2022409584671259, "critic_loss": 0.5609487486630678, "actor_loss": -23.871262481689453, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.29196310043335, "step": 121000}
{"episode_reward": 490.39711407798393, "episode": 122.0, "batch_reward": 0.20493989142775534, "critic_loss": 0.5758047644942998, "actor_loss": -23.95300774383545, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.910050868988037, "step": 122000}
{"episode_reward": 501.5531184245187, "episode": 123.0, "batch_reward": 0.20735451218485831, "critic_loss": 0.5922586277872324, "actor_loss": -24.185073749542237, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.950690031051636, "step": 123000}
{"episode_reward": 517.8584383484298, "episode": 124.0, "batch_reward": 0.208331846088171, "critic_loss": 0.5300324232429265, "actor_loss": -24.172108318328856, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.964386701583862, "step": 124000}
{"episode_reward": 527.4583519145824, "episode": 125.0, "batch_reward": 0.2111484956741333, "critic_loss": 0.5093597044497729, "actor_loss": -24.269021759033205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.920570373535156, "step": 125000}
{"episode_reward": 341.63928334706844, "episode": 126.0, "batch_reward": 0.2116376738101244, "critic_loss": 0.48942604547739027, "actor_loss": -24.30912068939209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.920479774475098, "step": 126000}
{"episode_reward": 510.1387552305675, "episode": 127.0, "batch_reward": 0.21450476974248886, "critic_loss": 0.4944231823086739, "actor_loss": -24.489131271362304, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90446138381958, "step": 127000}
{"episode_reward": 450.1609584169716, "episode": 128.0, "batch_reward": 0.21696446014940737, "critic_loss": 0.4625908919125795, "actor_loss": -24.66149433517456, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.911958932876587, "step": 128000}
{"episode_reward": 509.4379218806769, "episode": 129.0, "batch_reward": 0.21782074442505836, "critic_loss": 0.46364653699100017, "actor_loss": -24.856135112762452, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.933135509490967, "step": 129000}
{"episode_reward": 245.53725699936342, "episode": 130.0, "batch_reward": 0.21825661960244178, "critic_loss": 0.48673768688738345, "actor_loss": -24.614073261260987, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.917999505996704, "step": 130000}
{"episode_reward": 329.89163262543246, "episode": 131.0, "batch_reward": 0.2208130585104227, "critic_loss": 0.4599002950191498, "actor_loss": -24.83617572784424, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.24206304550171, "step": 131000}
{"episode_reward": 507.04426099491917, "episode": 132.0, "batch_reward": 0.22039243452250956, "critic_loss": 0.4669950129389763, "actor_loss": -24.51255195236206, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.922990322113037, "step": 132000}
{"episode_reward": 137.03880136439105, "episode": 133.0, "batch_reward": 0.22074640715122223, "critic_loss": 0.4451144328415394, "actor_loss": -24.63685879135132, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.955174922943115, "step": 133000}
{"episode_reward": 121.79041654221041, "episode": 134.0, "batch_reward": 0.22038275937736035, "critic_loss": 0.4670601512938738, "actor_loss": -24.54763615036011, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.913550853729248, "step": 134000}
{"episode_reward": 329.1704228410799, "episode": 135.0, "batch_reward": 0.22148066438734532, "critic_loss": 0.46473865580558776, "actor_loss": -24.42261227798462, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.919759511947632, "step": 135000}
{"episode_reward": 434.8640650392384, "episode": 136.0, "batch_reward": 0.2230566997975111, "critic_loss": 0.4299249256104231, "actor_loss": -24.730741161346437, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93920135498047, "step": 136000}
{"episode_reward": 524.0951824427834, "episode": 137.0, "batch_reward": 0.225773016884923, "critic_loss": 0.4750817259848118, "actor_loss": -24.674513278961182, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92039942741394, "step": 137000}
{"episode_reward": 289.8324302353076, "episode": 138.0, "batch_reward": 0.22661508034169675, "critic_loss": 0.45520694749057294, "actor_loss": -24.71396823120117, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.898905992507935, "step": 138000}
{"episode_reward": 569.9430556003292, "episode": 139.0, "batch_reward": 0.22856079030036927, "critic_loss": 0.44988180258870125, "actor_loss": -24.963463695526123, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.94636869430542, "step": 139000}
{"episode_reward": 326.0410786212289, "episode": 140.0, "batch_reward": 0.22819803312420844, "critic_loss": 0.4606018452346325, "actor_loss": -24.78030554199219, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93400263786316, "step": 140000}
{"episode_reward": 523.4779560485425, "episode": 141.0, "batch_reward": 0.230965653732419, "critic_loss": 0.48502419498562815, "actor_loss": -24.945168285369874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.262133836746216, "step": 141000}
{"episode_reward": 436.61935580825514, "episode": 142.0, "batch_reward": 0.2322298859357834, "critic_loss": 0.42304838909208775, "actor_loss": -24.88086854171753, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.933069467544556, "step": 142000}
{"episode_reward": 380.5924340560028, "episode": 143.0, "batch_reward": 0.23383442060649395, "critic_loss": 0.43859456333518027, "actor_loss": -25.185564704895018, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.875014781951904, "step": 143000}
{"episode_reward": 568.1160006006829, "episode": 144.0, "batch_reward": 0.23538922257721423, "critic_loss": 0.4403759192675352, "actor_loss": -25.358765991210937, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.908090591430664, "step": 144000}
{"episode_reward": 185.03702457400735, "episode": 145.0, "batch_reward": 0.23647171430289746, "critic_loss": 0.43935154324769976, "actor_loss": -25.170128219604493, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.959206581115723, "step": 145000}
{"episode_reward": 607.3046221589797, "episode": 146.0, "batch_reward": 0.23782683265209198, "critic_loss": 0.4375755892843008, "actor_loss": -25.500907974243162, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.931368350982666, "step": 146000}
{"episode_reward": 561.0861251659256, "episode": 147.0, "batch_reward": 0.23918045745790004, "critic_loss": 0.4684811282902956, "actor_loss": -25.589005729675293, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89302968978882, "step": 147000}
{"episode_reward": 586.1561677143868, "episode": 148.0, "batch_reward": 0.24342183896899222, "critic_loss": 0.4167008224278688, "actor_loss": -26.036980766296388, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.94726300239563, "step": 148000}
{"episode_reward": 205.967199139683, "episode": 149.0, "batch_reward": 0.24235769549012184, "critic_loss": 0.4347284319549799, "actor_loss": -25.670268058776855, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.909669876098633, "step": 149000}
{"episode_reward": 590.3753298641899, "episode": 150.0, "batch_reward": 0.24609443244338036, "critic_loss": 0.4367675717920065, "actor_loss": -26.10837686920166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
