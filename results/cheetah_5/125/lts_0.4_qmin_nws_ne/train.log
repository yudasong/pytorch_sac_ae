{"episode_reward": 0.0, "episode": 1.0, "duration": 18.730894804000854, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.6789929866790771, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2794741684345453, "critic_loss": 0.018170296816200655, "actor_loss": -22.26173322205963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 69.52182507514954, "step": 3000}
{"episode_reward": 4.8476395032175885, "episode": 4.0, "batch_reward": 0.17391480679064988, "critic_loss": 0.011588657597545534, "actor_loss": -22.128237193107605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.805058479309082, "step": 4000}
{"episode_reward": 5.70165163647293, "episode": 5.0, "batch_reward": 0.13453890386223794, "critic_loss": 0.013189415967091918, "actor_loss": -17.71315664482117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.89539098739624, "step": 5000}
{"episode_reward": 5.672415326732499, "episode": 6.0, "batch_reward": 0.1108465451337397, "critic_loss": 0.013424599003279582, "actor_loss": -18.44836378479004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.58279013633728, "step": 6000}
{"episode_reward": 5.5130048374876655, "episode": 7.0, "batch_reward": 0.09481526915356517, "critic_loss": 0.014123329794034361, "actor_loss": -18.260710494041444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.811358213424683, "step": 7000}
{"episode_reward": 5.66106674884942, "episode": 8.0, "batch_reward": 0.08369201794825494, "critic_loss": 0.016363181035965683, "actor_loss": -17.109415579319002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.171335220336914, "step": 8000}
{"episode_reward": 4.661927122988992, "episode": 9.0, "batch_reward": 0.07363612713105977, "critic_loss": 0.01805235982919112, "actor_loss": -18.1371328291893, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.869342803955078, "step": 9000}
{"episode_reward": 5.369488811013823, "episode": 10.0, "batch_reward": 0.06733969254232942, "critic_loss": 0.012451165217906237, "actor_loss": -16.99594083213806, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.695927143096924, "step": 10000}
{"episode_reward": 6.186288152371156, "episode": 11.0, "batch_reward": 0.061489694779738785, "critic_loss": 0.01777307986817323, "actor_loss": -16.744205258846282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.78843069076538, "step": 11000}
{"episode_reward": 4.947830952294526, "episode": 12.0, "batch_reward": 0.056895963558927176, "critic_loss": 0.019960603019455448, "actor_loss": -16.555691409587862, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.398937463760376, "step": 12000}
{"episode_reward": 5.750703349493365, "episode": 13.0, "batch_reward": 0.05208387221582234, "critic_loss": 0.011041094887419604, "actor_loss": -16.359882182121275, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.26544189453125, "step": 13000}
{"episode_reward": 4.25140768511029, "episode": 14.0, "batch_reward": 0.048210669089108704, "critic_loss": 0.022947870964067987, "actor_loss": -14.485483407974243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.320209741592407, "step": 14000}
{"episode_reward": 4.816474718248249, "episode": 15.0, "batch_reward": 0.04575294292904437, "critic_loss": 0.012499527489126194, "actor_loss": -16.198846491336823, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.7181339263916, "step": 15000}
{"episode_reward": 5.131158294077697, "episode": 16.0, "batch_reward": 0.04251631701923907, "critic_loss": 0.012870223039761186, "actor_loss": -16.203880569934846, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.514290809631348, "step": 16000}
{"episode_reward": 5.150172542945555, "episode": 17.0, "batch_reward": 0.04078156371694058, "critic_loss": 0.01813396362680942, "actor_loss": -14.706327799797059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.920442819595337, "step": 17000}
{"episode_reward": 3.8321160031416057, "episode": 18.0, "batch_reward": 0.03872334310784936, "critic_loss": 0.012131098177691455, "actor_loss": -14.838030045509338, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.345898151397705, "step": 18000}
{"episode_reward": 5.223325057804302, "episode": 19.0, "batch_reward": 0.03672016300214455, "critic_loss": 0.020345354614837562, "actor_loss": -15.810724769353866, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.236432552337646, "step": 19000}
{"episode_reward": 4.996224323173275, "episode": 20.0, "batch_reward": 0.034752300523221494, "critic_loss": 0.010542514149041381, "actor_loss": -15.943223096847534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.803601026535034, "step": 20000}
{"episode_reward": 5.0110219626391945, "episode": 21.0, "batch_reward": 0.03409355496428907, "critic_loss": 0.014975487105490175, "actor_loss": -15.959349652051925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.0836763381958, "step": 21000}
{"episode_reward": 5.721732440493191, "episode": 22.0, "batch_reward": 0.032319761368911716, "critic_loss": 0.01514415209548315, "actor_loss": -15.363810393810272, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.669194221496582, "step": 22000}
{"episode_reward": 6.616988027964346, "episode": 23.0, "batch_reward": 0.03171102040307596, "critic_loss": 0.01687153481587302, "actor_loss": -14.026059059858323, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.073981046676636, "step": 23000}
{"episode_reward": 4.485250856105868, "episode": 24.0, "batch_reward": 0.03004048633389175, "critic_loss": 0.013563664596062154, "actor_loss": -15.088510568618775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.794017553329468, "step": 24000}
{"episode_reward": 4.893559155455193, "episode": 25.0, "batch_reward": 0.02895846786443144, "critic_loss": 0.018616423025261612, "actor_loss": -13.716686150074006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.43750286102295, "step": 25000}
{"episode_reward": 4.540937096253974, "episode": 26.0, "batch_reward": 0.027894142671488226, "critic_loss": 0.009298679423052817, "actor_loss": -14.228949783563614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.287081480026245, "step": 26000}
{"episode_reward": 5.637168884851856, "episode": 27.0, "batch_reward": 0.027501017107162625, "critic_loss": 0.014659815597406122, "actor_loss": -14.187317816972733, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.137987852096558, "step": 27000}
{"episode_reward": 2.9703504574681023, "episode": 28.0, "batch_reward": 0.026250739346258344, "critic_loss": 0.013007755713770166, "actor_loss": -13.689727769374848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.615590572357178, "step": 28000}
{"episode_reward": 5.182364735227109, "episode": 29.0, "batch_reward": 0.026450538109987973, "critic_loss": 0.010208125709497836, "actor_loss": -14.541184626340867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.861181020736694, "step": 29000}
{"episode_reward": 5.299614054832198, "episode": 30.0, "batch_reward": 0.024651680783601478, "critic_loss": 0.011875378947734135, "actor_loss": -13.863830785274505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.732465505599976, "step": 30000}
{"episode_reward": 4.503442198813368, "episode": 31.0, "batch_reward": 0.024245623508468272, "critic_loss": 0.010582975825935136, "actor_loss": -13.784341151356697, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.90554881095886, "step": 31000}
{"episode_reward": 5.9010217331052655, "episode": 32.0, "batch_reward": 0.02339887015009299, "critic_loss": 0.012116126860317308, "actor_loss": -15.083353900432586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.684471130371094, "step": 32000}
{"episode_reward": 6.737842280625679, "episode": 33.0, "batch_reward": 0.023171743053011597, "critic_loss": 0.016341220461559714, "actor_loss": -14.699637909770011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.771685123443604, "step": 33000}
{"episode_reward": 3.695330446676728, "episode": 34.0, "batch_reward": 0.02259272803971544, "critic_loss": 0.00772757836204255, "actor_loss": -12.001587793111801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.407288789749146, "step": 34000}
{"episode_reward": 6.525439799181632, "episode": 35.0, "batch_reward": 0.021842740652151405, "critic_loss": 0.014890520501765422, "actor_loss": -13.944900536417961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.01237940788269, "step": 35000}
{"episode_reward": 4.655720665505742, "episode": 36.0, "batch_reward": 0.02139183271303773, "critic_loss": 0.006915901169137214, "actor_loss": -13.476957488298416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.00130558013916, "step": 36000}
{"episode_reward": 5.6511706045869206, "episode": 37.0, "batch_reward": 0.021196510318666695, "critic_loss": 0.012459289785576403, "actor_loss": -12.885546785354615, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.71655774116516, "step": 37000}
{"episode_reward": 5.87995493038431, "episode": 38.0, "batch_reward": 0.02088398055639118, "critic_loss": 0.007022241618862608, "actor_loss": -12.96340051305294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.625895261764526, "step": 38000}
{"episode_reward": 5.745572861337241, "episode": 39.0, "batch_reward": 0.02019315324467607, "critic_loss": 0.011075813805597136, "actor_loss": -14.719057294249534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.747024536132812, "step": 39000}
{"episode_reward": 3.444391085034316, "episode": 40.0, "batch_reward": 0.02007522224029526, "critic_loss": 0.009341556695857435, "actor_loss": -13.456531952619553, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.284409999847412, "step": 40000}
{"episode_reward": 5.856707335963026, "episode": 41.0, "batch_reward": 0.019814808428520337, "critic_loss": 0.009880993204918923, "actor_loss": -13.767190540909768, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.89402389526367, "step": 41000}
{"episode_reward": 6.862636266771117, "episode": 42.0, "batch_reward": 0.019010571265360342, "critic_loss": 0.013172557786776451, "actor_loss": -13.492014874696732, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.205312252044678, "step": 42000}
{"episode_reward": 4.49311116044005, "episode": 43.0, "batch_reward": 0.018973095052642747, "critic_loss": 0.0064623558364692146, "actor_loss": -13.544069093942642, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.544968843460083, "step": 43000}
{"episode_reward": 4.807636909825129, "episode": 44.0, "batch_reward": 0.01852359035005793, "critic_loss": 0.008005239162419457, "actor_loss": -12.866287404179573, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.94738006591797, "step": 44000}
{"episode_reward": 5.9384554502728415, "episode": 45.0, "batch_reward": 0.018521879518404602, "critic_loss": 0.00904485763370758, "actor_loss": -14.527589510917663, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.933936834335327, "step": 45000}
{"episode_reward": 4.864900433737032, "episode": 46.0, "batch_reward": 0.01784426272427663, "critic_loss": 0.01046087729917781, "actor_loss": -14.00039589768648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.494410276412964, "step": 46000}
{"episode_reward": 4.637668245107362, "episode": 47.0, "batch_reward": 0.01819385902862996, "critic_loss": 0.007931398513333989, "actor_loss": -13.497088107824325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.839033365249634, "step": 47000}
{"episode_reward": 5.197974647222761, "episode": 48.0, "batch_reward": 0.017386679724091664, "critic_loss": 0.006469170181939262, "actor_loss": -13.052236783266068, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.58721923828125, "step": 48000}
{"episode_reward": 5.214835837466961, "episode": 49.0, "batch_reward": 0.017492779809981585, "critic_loss": 0.010520068695652298, "actor_loss": -13.825019502341748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.271289110183716, "step": 49000}
{"episode_reward": 5.360049747784204, "episode": 50.0, "batch_reward": 0.016666358796646817, "critic_loss": 0.006739453226851765, "actor_loss": -13.511584636211396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.36122179031372, "step": 50000}
{"episode_reward": 5.921232173202941, "episode": 51.0, "batch_reward": 0.016623087733983993, "critic_loss": 0.008122119092353388, "actor_loss": -12.48955392086506, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.57144498825073, "step": 51000}
{"episode_reward": 4.638061716053911, "episode": 52.0, "batch_reward": 0.01648566829925403, "critic_loss": 0.012755486575435498, "actor_loss": -14.09709392219782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.817190647125244, "step": 52000}
{"episode_reward": 3.9937084112997785, "episode": 53.0, "batch_reward": 0.016502146454993635, "critic_loss": 0.00646024517522892, "actor_loss": -13.989871477484703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.88895583152771, "step": 53000}
{"episode_reward": 3.660991814163375, "episode": 54.0, "batch_reward": 0.01570899143000133, "critic_loss": 0.009036808772551013, "actor_loss": -13.692488827168942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.019761323928833, "step": 54000}
{"episode_reward": 6.156707333873602, "episode": 55.0, "batch_reward": 0.01604233694029972, "critic_loss": 0.0056820685124694134, "actor_loss": -12.325136317551136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.581926345825195, "step": 55000}
{"episode_reward": 4.911461444878165, "episode": 56.0, "batch_reward": 0.01566665302682668, "critic_loss": 0.010434147584819585, "actor_loss": -13.726310780882836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.367231130599976, "step": 56000}
{"episode_reward": 4.977371527391946, "episode": 57.0, "batch_reward": 0.015226700376253574, "critic_loss": 0.010418112737504998, "actor_loss": -13.768101484358311, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.350242137908936, "step": 57000}
{"episode_reward": 4.646885516440241, "episode": 58.0, "batch_reward": 0.015447111956775188, "critic_loss": 0.006961586903271382, "actor_loss": -12.02594316214323, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.723868131637573, "step": 58000}
{"episode_reward": 7.662959075189733, "episode": 59.0, "batch_reward": 0.014867007214576006, "critic_loss": 0.010934974852541928, "actor_loss": -13.270625048935413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.815128803253174, "step": 59000}
{"episode_reward": 4.921867213240739, "episode": 60.0, "batch_reward": 0.015113909128587693, "critic_loss": 0.006753209108836018, "actor_loss": -13.862327416360378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.543678045272827, "step": 60000}
{"episode_reward": 7.425899553884257, "episode": 61.0, "batch_reward": 0.014941921280231326, "critic_loss": 0.006120636147432378, "actor_loss": -12.91567296564579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.9256067276001, "step": 61000}
{"episode_reward": 4.425081702548025, "episode": 62.0, "batch_reward": 0.014902582878945395, "critic_loss": 0.0057386244761728445, "actor_loss": -12.455604559361934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.911062955856323, "step": 62000}
{"episode_reward": 4.012193300444659, "episode": 63.0, "batch_reward": 0.014548076401697472, "critic_loss": 0.0056171867637312975, "actor_loss": -12.739527234613895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.209279775619507, "step": 63000}
{"episode_reward": 4.629442405657985, "episode": 64.0, "batch_reward": 0.014008129066554829, "critic_loss": 0.0058918952679669016, "actor_loss": -12.760141699612142, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.734225273132324, "step": 64000}
{"episode_reward": 4.986779367801398, "episode": 65.0, "batch_reward": 0.014080159239238128, "critic_loss": 0.007794237099558813, "actor_loss": -13.336091289997102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.397132873535156, "step": 65000}
{"episode_reward": 3.8462297099630804, "episode": 66.0, "batch_reward": 0.014193984634010122, "critic_loss": 0.006456999973597704, "actor_loss": -13.35346163919568, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.427329778671265, "step": 66000}
{"episode_reward": 5.254359449664005, "episode": 67.0, "batch_reward": 0.013914851875742897, "critic_loss": 0.006076344899905962, "actor_loss": -14.48615490925312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19491744041443, "step": 67000}
{"episode_reward": 5.642052283204015, "episode": 68.0, "batch_reward": 0.01368022061791271, "critic_loss": 0.006971671932245954, "actor_loss": -12.158358345240355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.572428941726685, "step": 68000}
{"episode_reward": 3.9161121585084557, "episode": 69.0, "batch_reward": 0.013409016227349638, "critic_loss": 0.005788081423124822, "actor_loss": -13.398141798108815, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.729258060455322, "step": 69000}
{"episode_reward": 3.9820503690621134, "episode": 70.0, "batch_reward": 0.013663943935418501, "critic_loss": 0.005116477421412128, "actor_loss": -13.764181426137686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.900643825531006, "step": 70000}
{"episode_reward": 4.721374335469419, "episode": 71.0, "batch_reward": 0.013693161668954417, "critic_loss": 0.00737256076427002, "actor_loss": -12.300427730083465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.946141719818115, "step": 71000}
{"episode_reward": 3.7783715473933217, "episode": 72.0, "batch_reward": 0.013445379345677792, "critic_loss": 0.003914679020941549, "actor_loss": -12.652759679585696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.121726036071777, "step": 72000}
{"episode_reward": 4.123750421817069, "episode": 73.0, "batch_reward": 0.01323565220972523, "critic_loss": 0.005942907199831098, "actor_loss": -12.93303559345007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.689990997314453, "step": 73000}
{"episode_reward": 4.369511673597018, "episode": 74.0, "batch_reward": 0.012887906082440167, "critic_loss": 0.004500912169307412, "actor_loss": -13.432162871301173, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.73399066925049, "step": 74000}
{"episode_reward": 4.779816471407687, "episode": 75.0, "batch_reward": 0.012719917708775029, "critic_loss": 0.005601706062909216, "actor_loss": -12.893649967074394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.463485717773438, "step": 75000}
{"episode_reward": 2.568737038029651, "episode": 76.0, "batch_reward": 0.012809552700491621, "critic_loss": 0.0054559211940941165, "actor_loss": -12.839610789120197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.956122159957886, "step": 76000}
{"episode_reward": 5.580768763426544, "episode": 77.0, "batch_reward": 0.012616505059646442, "critic_loss": 0.00634862388241163, "actor_loss": -12.953074634134769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.794668197631836, "step": 77000}
{"episode_reward": 4.2409565964330715, "episode": 78.0, "batch_reward": 0.012899020571028813, "critic_loss": 0.005413948455607169, "actor_loss": -13.395954580068588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.566239595413208, "step": 78000}
{"episode_reward": 5.686793150562591, "episode": 79.0, "batch_reward": 0.012203832105966286, "critic_loss": 0.005660339630092494, "actor_loss": -12.30292592445016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.605974435806274, "step": 79000}
{"episode_reward": 6.4847755700930865, "episode": 80.0, "batch_reward": 0.012249021894298493, "critic_loss": 0.0071194423132255906, "actor_loss": -12.345218548744917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.653301000595093, "step": 80000}
{"episode_reward": 5.605703725351232, "episode": 81.0, "batch_reward": 0.011978980221785606, "critic_loss": 0.004784541326574981, "actor_loss": -13.313441597908735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.95652747154236, "step": 81000}
{"episode_reward": 4.287237679042963, "episode": 82.0, "batch_reward": 0.012377777490997686, "critic_loss": 0.0050460777147091, "actor_loss": -13.35958080753684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.756808042526245, "step": 82000}
{"episode_reward": 5.8343883305323665, "episode": 83.0, "batch_reward": 0.011849654166959225, "critic_loss": 0.006922559533006279, "actor_loss": -13.192638799905778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.957157373428345, "step": 83000}
{"episode_reward": 4.938961765348201, "episode": 84.0, "batch_reward": 0.011719660440227016, "critic_loss": 0.007910225013823947, "actor_loss": -13.620905565381051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.47688889503479, "step": 84000}
{"episode_reward": 6.770672617400463, "episode": 85.0, "batch_reward": 0.012083273927215487, "critic_loss": 0.00441640193524654, "actor_loss": -13.626335486710072, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.099591970443726, "step": 85000}
{"episode_reward": 4.770262644805495, "episode": 86.0, "batch_reward": 0.011765319330617785, "critic_loss": 0.004611659067420988, "actor_loss": -13.03691417990625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.290279150009155, "step": 86000}
{"episode_reward": 6.024270298593861, "episode": 87.0, "batch_reward": 0.01187469912134111, "critic_loss": 0.005278111257328419, "actor_loss": -12.254656537145376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.442158937454224, "step": 87000}
{"episode_reward": 4.89327981011023, "episode": 88.0, "batch_reward": 0.01185491479979828, "critic_loss": 0.005592368952973629, "actor_loss": -11.875342056199909, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.55557632446289, "step": 88000}
{"episode_reward": 6.560432702991071, "episode": 89.0, "batch_reward": 0.011875171933788807, "critic_loss": 0.004082299534537015, "actor_loss": -12.619620680347085, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.958306312561035, "step": 89000}
{"episode_reward": 5.250514078067331, "episode": 90.0, "batch_reward": 0.011594846246531234, "critic_loss": 0.0049508354710560525, "actor_loss": -13.049419745817781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.14510703086853, "step": 90000}
{"episode_reward": 4.923645344848634, "episode": 91.0, "batch_reward": 0.011860093803843483, "critic_loss": 0.00400831855762226, "actor_loss": -12.36047921858728, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.80696082115173, "step": 91000}
{"episode_reward": 3.646481728314165, "episode": 92.0, "batch_reward": 0.011618986971443519, "critic_loss": 0.0068630533652030866, "actor_loss": -13.103016789644956, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.937208652496338, "step": 92000}
{"episode_reward": 6.482956098714958, "episode": 93.0, "batch_reward": 0.011405203290516511, "critic_loss": 0.0038813727626984475, "actor_loss": -12.28571845676005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.32285475730896, "step": 93000}
{"episode_reward": 5.704915635374206, "episode": 94.0, "batch_reward": 0.011274143246700986, "critic_loss": 0.005700093938299688, "actor_loss": -12.654741758808493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.549137353897095, "step": 94000}
{"episode_reward": 4.547460867741683, "episode": 95.0, "batch_reward": 0.011272208616603167, "critic_loss": 0.004314893078138994, "actor_loss": -13.466652287259699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.943483114242554, "step": 95000}
{"episode_reward": 6.892545668592127, "episode": 96.0, "batch_reward": 0.011273110304493458, "critic_loss": 0.004715513800038025, "actor_loss": -12.697920373097062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.026775121688843, "step": 96000}
{"episode_reward": 5.3049638207861785, "episode": 97.0, "batch_reward": 0.01132749211951159, "critic_loss": 0.007121923186183267, "actor_loss": -13.290123800337314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.81722068786621, "step": 97000}
{"episode_reward": 5.828124227607359, "episode": 98.0, "batch_reward": 0.011133415783988312, "critic_loss": 0.0038560632227308813, "actor_loss": -12.8093842202276, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.618894338607788, "step": 98000}
{"episode_reward": 4.79401319487927, "episode": 99.0, "batch_reward": 0.010943934135371819, "critic_loss": 0.004775279478664743, "actor_loss": -12.679245460137725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.45715045928955, "step": 99000}
{"episode_reward": 6.561654429341163, "episode": 100.0, "batch_reward": 0.011087278813822194, "critic_loss": 0.004740232011245098, "actor_loss": -12.256763605341316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.951815366744995, "step": 100000}
{"episode_reward": 6.7011778783379565, "episode": 101.0, "batch_reward": 0.010944918801775201, "critic_loss": 0.006271906261106778, "actor_loss": -13.417902174159885, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.22063899040222, "step": 101000}
{"episode_reward": 4.497692663030742, "episode": 102.0, "batch_reward": 0.01105167042510584, "critic_loss": 0.0041354939586963155, "actor_loss": -13.173866389349103, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.807839155197144, "step": 102000}
{"episode_reward": 4.8494261668895815, "episode": 103.0, "batch_reward": 0.01108215458644554, "critic_loss": 0.0051454969262558735, "actor_loss": -13.054250349357725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.52928590774536, "step": 103000}
{"episode_reward": 4.517567796568789, "episode": 104.0, "batch_reward": 0.010716982985148206, "critic_loss": 0.0037854949704851605, "actor_loss": -13.090291016161443, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.152767181396484, "step": 104000}
{"episode_reward": 3.5267175674353535, "episode": 105.0, "batch_reward": 0.010984279403463006, "critic_loss": 0.004003923659409338, "actor_loss": -11.621509564444423, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.063265800476074, "step": 105000}
{"episode_reward": 4.837104310863522, "episode": 106.0, "batch_reward": 0.010743905808078125, "critic_loss": 0.0051901127714445465, "actor_loss": -11.114552525103091, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.165801525115967, "step": 106000}
{"episode_reward": 3.7385579287197714, "episode": 107.0, "batch_reward": 0.0107064033257775, "critic_loss": 0.006488619625590218, "actor_loss": -12.662730272889137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.74548029899597, "step": 107000}
{"episode_reward": 4.936647758603588, "episode": 108.0, "batch_reward": 0.010550896358210594, "critic_loss": 0.0021794571760910915, "actor_loss": -13.140946911513806, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.085991621017456, "step": 108000}
{"episode_reward": 4.092135088792758, "episode": 109.0, "batch_reward": 0.010325015639420598, "critic_loss": 0.0034070370259869378, "actor_loss": -12.573968770943582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.30395197868347, "step": 109000}
{"episode_reward": 4.918073998413084, "episode": 110.0, "batch_reward": 0.010307176367379725, "critic_loss": 0.004418209509720327, "actor_loss": -13.188975644990801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.98046374320984, "step": 110000}
{"episode_reward": 5.8554996537844985, "episode": 111.0, "batch_reward": 0.010350335395429284, "critic_loss": 0.0041875884036926435, "actor_loss": -12.710231248870492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.31750774383545, "step": 111000}
{"episode_reward": 4.672115953729505, "episode": 112.0, "batch_reward": 0.010459082193439826, "critic_loss": 0.005097594620216114, "actor_loss": -12.447466805793345, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.074503898620605, "step": 112000}
{"episode_reward": 4.246531858448323, "episode": 113.0, "batch_reward": 0.010132002986967564, "critic_loss": 0.004007003738923231, "actor_loss": -12.633537974745035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.610960721969604, "step": 113000}
{"episode_reward": 3.7141094303929134, "episode": 114.0, "batch_reward": 0.010126518238568678, "critic_loss": 0.0037300544337340396, "actor_loss": -13.746583155617119, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.388044834136963, "step": 114000}
{"episode_reward": 5.293814726656848, "episode": 115.0, "batch_reward": 0.010215396281564608, "critic_loss": 0.0034138319642515852, "actor_loss": -12.80815730215609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.139445543289185, "step": 115000}
{"episode_reward": 5.675163344882858, "episode": 116.0, "batch_reward": 0.01015884983446449, "critic_loss": 0.004104667480234639, "actor_loss": -13.51085921703279, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.088891983032227, "step": 116000}
{"episode_reward": 6.0167532550084815, "episode": 117.0, "batch_reward": 0.010288349316921085, "critic_loss": 0.006334225637998315, "actor_loss": -12.789046855904163, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.717512130737305, "step": 117000}
{"episode_reward": 6.394875661327676, "episode": 118.0, "batch_reward": 0.010291250215144827, "critic_loss": 0.0033718559016269866, "actor_loss": -13.894492058902978, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.668378353118896, "step": 118000}
{"episode_reward": 4.4475669766712, "episode": 119.0, "batch_reward": 0.010028231613803656, "critic_loss": 0.003889136540157779, "actor_loss": -12.516509909272195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.362001419067383, "step": 119000}
{"episode_reward": 6.570546995146315, "episode": 120.0, "batch_reward": 0.009848639264935628, "critic_loss": 0.0038249862754455534, "actor_loss": -11.63982180723548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.464936017990112, "step": 120000}
{"episode_reward": 5.331053380999795, "episode": 121.0, "batch_reward": 0.010051119557814672, "critic_loss": 0.005651572145674436, "actor_loss": -12.19868363147974, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.01055145263672, "step": 121000}
{"episode_reward": 7.061489735001675, "episode": 122.0, "batch_reward": 0.010038637629942969, "critic_loss": 0.0035570418560309917, "actor_loss": -12.553180993884801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.105188608169556, "step": 122000}
{"episode_reward": 5.736073390276281, "episode": 123.0, "batch_reward": 0.00997422400303185, "critic_loss": 0.004936870160607214, "actor_loss": -11.811066393211483, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.149904251098633, "step": 123000}
{"episode_reward": 4.896325039515628, "episode": 124.0, "batch_reward": 0.009791018541436642, "critic_loss": 0.004393836044400814, "actor_loss": -12.686165100052953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.62624430656433, "step": 124000}
{"episode_reward": 4.230227587559224, "episode": 125.0, "batch_reward": 0.009740374848013744, "critic_loss": 0.004321116301522125, "actor_loss": -12.004540489286184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.411616802215576, "step": 125000}
{"episode_reward": 4.264169624910242, "episode": 126.0, "batch_reward": 0.009610160061856731, "critic_loss": 0.0039402577615837795, "actor_loss": -13.106493664056062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.091395378112793, "step": 126000}
{"episode_reward": 4.483660591817105, "episode": 127.0, "batch_reward": 0.009752786370692774, "critic_loss": 0.00392256118557998, "actor_loss": -12.926332279607653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.32929825782776, "step": 127000}
{"episode_reward": 4.741399118393519, "episode": 128.0, "batch_reward": 0.00961870784778148, "critic_loss": 0.0034593172432360007, "actor_loss": -13.34662091127038, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.349379301071167, "step": 128000}
{"episode_reward": 5.670528659043189, "episode": 129.0, "batch_reward": 0.009708210301352665, "critic_loss": 0.005875346125947544, "actor_loss": -13.665513202980161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.892371654510498, "step": 129000}
{"episode_reward": 6.233341965994861, "episode": 130.0, "batch_reward": 0.009531082472531125, "critic_loss": 0.003623429156039492, "actor_loss": -12.475153812736274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.85068655014038, "step": 130000}
{"episode_reward": 4.945277215165624, "episode": 131.0, "batch_reward": 0.009650319843320177, "critic_loss": 0.004967449156756629, "actor_loss": -12.8616139036268, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.38542175292969, "step": 131000}
{"episode_reward": 4.914381657058847, "episode": 132.0, "batch_reward": 0.009720710243098438, "critic_loss": 0.0045059079957281934, "actor_loss": -12.55023642745614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.016621351242065, "step": 132000}
{"episode_reward": 4.791346041017022, "episode": 133.0, "batch_reward": 0.009533345334930346, "critic_loss": 0.005010195737770119, "actor_loss": -13.661989336311818, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.84221053123474, "step": 133000}
{"episode_reward": 3.306001645000727, "episode": 134.0, "batch_reward": 0.009624485389562324, "critic_loss": 0.0030971459851789405, "actor_loss": -14.152161433160305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.46018934249878, "step": 134000}
{"episode_reward": 9.178562786023791, "episode": 135.0, "batch_reward": 0.009622344297822565, "critic_loss": 0.003870159278223582, "actor_loss": -12.586699918448925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.06131672859192, "step": 135000}
{"episode_reward": 7.4801593484941185, "episode": 136.0, "batch_reward": 0.00934821021510288, "critic_loss": 0.0035382606853527248, "actor_loss": -12.831219310447574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.649393558502197, "step": 136000}
{"episode_reward": 4.1902770948160395, "episode": 137.0, "batch_reward": 0.009396005908958614, "critic_loss": 0.0036508584382827394, "actor_loss": -12.338397169888019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.65068006515503, "step": 137000}
{"episode_reward": 6.1061601893911925, "episode": 138.0, "batch_reward": 0.009726757573429496, "critic_loss": 0.0032704379066708497, "actor_loss": -11.679564421087504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.284998655319214, "step": 138000}
{"episode_reward": 5.910540258121608, "episode": 139.0, "batch_reward": 0.00955942281219177, "critic_loss": 0.0036923761358120828, "actor_loss": -12.046591016471385, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.239720821380615, "step": 139000}
{"episode_reward": 3.732236443088925, "episode": 140.0, "batch_reward": 0.009243408088339494, "critic_loss": 0.004882869798217143, "actor_loss": -11.850557565793395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.631036043167114, "step": 140000}
{"episode_reward": 6.090591689824264, "episode": 141.0, "batch_reward": 0.0093131753327325, "critic_loss": 0.0037662855092348763, "actor_loss": -11.652948762834072, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.7073290348053, "step": 141000}
{"episode_reward": 3.3412682756545062, "episode": 142.0, "batch_reward": 0.00946437484305352, "critic_loss": 0.003646583329056739, "actor_loss": -12.106542688459157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.69054126739502, "step": 142000}
{"episode_reward": 4.328804928966155, "episode": 143.0, "batch_reward": 0.009340659900801256, "critic_loss": 0.003604484998315456, "actor_loss": -11.968761178866028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.21682119369507, "step": 143000}
{"episode_reward": 4.961330024000751, "episode": 144.0, "batch_reward": 0.009475541238905863, "critic_loss": 0.005310947761761781, "actor_loss": -11.722105126008392, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.421321392059326, "step": 144000}
{"episode_reward": 4.774322183925296, "episode": 145.0, "batch_reward": 0.00922875887923874, "critic_loss": 0.0052438858836103466, "actor_loss": -12.079622656092047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.456669330596924, "step": 145000}
{"episode_reward": 3.891665901900156, "episode": 146.0, "batch_reward": 0.009179014047142118, "critic_loss": 0.002336747685818409, "actor_loss": -13.145781072184443, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.976726293563843, "step": 146000}
{"episode_reward": 7.005016466822916, "episode": 147.0, "batch_reward": 0.008971853609196842, "critic_loss": 0.002850136712171661, "actor_loss": -12.426996672719717, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.9093074798584, "step": 147000}
{"episode_reward": 6.094836078081035, "episode": 148.0, "batch_reward": 0.009606632068986072, "critic_loss": 0.00437803424843878, "actor_loss": -12.29385473895073, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.200806856155396, "step": 148000}
{"episode_reward": 3.9542124472175386, "episode": 149.0, "batch_reward": 0.009151395946741104, "critic_loss": 0.003374760051301564, "actor_loss": -12.329600592508912, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.83005428314209, "step": 149000}
{"episode_reward": 6.382934860693185, "episode": 150.0, "batch_reward": 0.009040677034994588, "critic_loss": 0.003805219029294676, "actor_loss": -12.520611597776412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
