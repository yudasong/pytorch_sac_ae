{"episode_reward": 0.0, "episode": 1.0, "duration": 18.782207250595093, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.6526083946228027, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.2794741794799876, "critic_loss": 0.018057383763348908, "actor_loss": -13.137463705389857, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 70.31320524215698, "step": 3000}
{"episode_reward": 4.847728170826021, "episode": 4.0, "batch_reward": 0.17391483760625123, "critic_loss": 0.01282922812155448, "actor_loss": -14.706579592704774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.095613718032837, "step": 4000}
{"episode_reward": 5.701670400560672, "episode": 5.0, "batch_reward": 0.1345388250350952, "critic_loss": 0.012693723096745088, "actor_loss": -13.025673687934875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.755611419677734, "step": 5000}
{"episode_reward": 5.672107826453326, "episode": 6.0, "batch_reward": 0.11084650450199843, "critic_loss": 0.014808467917609959, "actor_loss": -12.243463718414306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.59436583518982, "step": 6000}
{"episode_reward": 5.5129118838341995, "episode": 7.0, "batch_reward": 0.0948151889666915, "critic_loss": 0.014214337290264665, "actor_loss": -12.293504922866822, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.74224328994751, "step": 7000}
{"episode_reward": 5.661383167060711, "episode": 8.0, "batch_reward": 0.08367789952456951, "critic_loss": 0.019299157477915288, "actor_loss": -12.394113472938537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.7102370262146, "step": 8000}
{"episode_reward": 4.024474732306867, "episode": 9.0, "batch_reward": 0.0738601198848337, "critic_loss": 0.017099469389766454, "actor_loss": -13.645608631134033, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.722402811050415, "step": 9000}
{"episode_reward": 6.572856098812892, "episode": 10.0, "batch_reward": 0.06762641859985888, "critic_loss": 0.0234948146129027, "actor_loss": -12.854259077072143, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.96302032470703, "step": 10000}
{"episode_reward": 6.643447917855704, "episode": 11.0, "batch_reward": 0.06159405155852437, "critic_loss": 0.014257145287236199, "actor_loss": -13.366476865768433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.4854621887207, "step": 11000}
{"episode_reward": 4.136170532484591, "episode": 12.0, "batch_reward": 0.05695822877064347, "critic_loss": 0.018605571354273705, "actor_loss": -11.68460979938507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.384851455688477, "step": 12000}
{"episode_reward": 5.229916778370512, "episode": 13.0, "batch_reward": 0.05226722480729222, "critic_loss": 0.011773412924259902, "actor_loss": -11.414049190044404, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90818762779236, "step": 13000}
{"episode_reward": 6.082488344526829, "episode": 14.0, "batch_reward": 0.048349699188955125, "critic_loss": 0.02605998694966547, "actor_loss": -10.774035387516022, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.89970088005066, "step": 14000}
{"episode_reward": 4.766881971537087, "episode": 15.0, "batch_reward": 0.04592620993219316, "critic_loss": 0.009873035875847563, "actor_loss": -10.720590345859527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.89460277557373, "step": 15000}
{"episode_reward": 6.029061862703876, "episode": 16.0, "batch_reward": 0.042741585935465995, "critic_loss": 0.015826571573037653, "actor_loss": -10.684236842155457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.40345048904419, "step": 16000}
{"episode_reward": 5.179235030897359, "episode": 17.0, "batch_reward": 0.04103378602396697, "critic_loss": 0.017543573229340838, "actor_loss": -9.601879787445068, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.084413051605225, "step": 17000}
{"episode_reward": 6.279521408524825, "episode": 18.0, "batch_reward": 0.03915290423296392, "critic_loss": 0.01157146706408821, "actor_loss": -9.083808731555939, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.6238009929657, "step": 18000}
{"episode_reward": 6.199416536922822, "episode": 19.0, "batch_reward": 0.0371678866376169, "critic_loss": 0.02588179710926488, "actor_loss": -10.580128075122833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.25007462501526, "step": 19000}
{"episode_reward": 6.591539191769042, "episode": 20.0, "batch_reward": 0.03520373724214733, "critic_loss": 0.011997429270297288, "actor_loss": -9.933906357288361, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.128240823745728, "step": 20000}
{"episode_reward": 6.837748765834235, "episode": 21.0, "batch_reward": 0.034584144349675626, "critic_loss": 0.013207944378606043, "actor_loss": -10.357781140327454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.187283754348755, "step": 21000}
{"episode_reward": 6.172801913279705, "episode": 22.0, "batch_reward": 0.03282952696457505, "critic_loss": 0.011229535726364702, "actor_loss": -9.666148298740387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.340035676956177, "step": 22000}
{"episode_reward": 6.648496912182071, "episode": 23.0, "batch_reward": 0.03215722641069442, "critic_loss": 0.01197029942960944, "actor_loss": -8.454510659456252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.322043418884277, "step": 23000}
{"episode_reward": 6.430698432585221, "episode": 24.0, "batch_reward": 0.030593670699279756, "critic_loss": 0.015781233752612023, "actor_loss": -8.50200059580803, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.811137199401855, "step": 24000}
{"episode_reward": 4.539256258988049, "episode": 25.0, "batch_reward": 0.029474959233077243, "critic_loss": 0.01532568135985639, "actor_loss": -8.90201917695999, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.276628255844116, "step": 25000}
{"episode_reward": 4.419462145087534, "episode": 26.0, "batch_reward": 0.0283290734263137, "critic_loss": 0.009616999434889294, "actor_loss": -8.61893915104866, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.263507843017578, "step": 26000}
{"episode_reward": 5.773416619527476, "episode": 27.0, "batch_reward": 0.028007167641539127, "critic_loss": 0.018342799811740407, "actor_loss": -8.551248861551285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.433898448944092, "step": 27000}
{"episode_reward": 5.4748080904914245, "episode": 28.0, "batch_reward": 0.026774430949939414, "critic_loss": 0.01059108910674695, "actor_loss": -8.535089412212372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.592714548110962, "step": 28000}
{"episode_reward": 6.342626010653526, "episode": 29.0, "batch_reward": 0.02701169711071998, "critic_loss": 0.012352645078091883, "actor_loss": -8.432776927709579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.371042490005493, "step": 29000}
{"episode_reward": 6.873603440020057, "episode": 30.0, "batch_reward": 0.025287411620374768, "critic_loss": 0.012580780931399204, "actor_loss": -8.5003958735466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.964805603027344, "step": 30000}
{"episode_reward": 6.896897491965964, "episode": 31.0, "batch_reward": 0.02484865005267784, "critic_loss": 0.009117856807191856, "actor_loss": -8.474780355215072, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.04598307609558, "step": 31000}
{"episode_reward": 5.516841427487238, "episode": 32.0, "batch_reward": 0.02398411174165085, "critic_loss": 0.0115840152380988, "actor_loss": -8.591424606323242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.45972180366516, "step": 32000}
{"episode_reward": 5.854809903402612, "episode": 33.0, "batch_reward": 0.02370778399379924, "critic_loss": 0.011172740519337821, "actor_loss": -8.556789728164674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.42540693283081, "step": 33000}
{"episode_reward": 5.532359372794546, "episode": 34.0, "batch_reward": 0.023193595578428358, "critic_loss": 0.009966078405152075, "actor_loss": -7.339149538755417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.696532487869263, "step": 34000}
{"episode_reward": 6.610229294147589, "episode": 35.0, "batch_reward": 0.022444139361847193, "critic_loss": 0.010267161444586236, "actor_loss": -8.118809170007706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.470205545425415, "step": 35000}
{"episode_reward": 5.030777555214118, "episode": 36.0, "batch_reward": 0.02200817284313962, "critic_loss": 0.007117297035409137, "actor_loss": -8.440226772546769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.370208978652954, "step": 36000}
{"episode_reward": 5.659618544251777, "episode": 37.0, "batch_reward": 0.02177511854330078, "critic_loss": 0.008314516051555984, "actor_loss": -7.470291987657547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.53548264503479, "step": 37000}
{"episode_reward": 6.77350206888988, "episode": 38.0, "batch_reward": 0.021471976932138204, "critic_loss": 0.009345246895216406, "actor_loss": -7.55222930598259, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.72917675971985, "step": 38000}
{"episode_reward": 7.048930189772977, "episode": 39.0, "batch_reward": 0.020877012418117374, "critic_loss": 0.006755036594578996, "actor_loss": -8.635494215011597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.78986430168152, "step": 39000}
{"episode_reward": 4.976099393427091, "episode": 40.0, "batch_reward": 0.020702502601314336, "critic_loss": 0.008011633688409348, "actor_loss": -8.250674074411393, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.29458475112915, "step": 40000}
{"episode_reward": 4.808415959667742, "episode": 41.0, "batch_reward": 0.020327144616050646, "critic_loss": 0.010585168488963972, "actor_loss": -8.29896296441555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.06561350822449, "step": 41000}
{"episode_reward": 5.091144770296634, "episode": 42.0, "batch_reward": 0.019505427617114036, "critic_loss": 0.007324419771437533, "actor_loss": -6.965144578456878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.745033264160156, "step": 42000}
{"episode_reward": 4.709314071844055, "episode": 43.0, "batch_reward": 0.019509384971344843, "critic_loss": 0.009198187704081647, "actor_loss": -7.569200044155121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.47660255432129, "step": 43000}
{"episode_reward": 5.891376852642289, "episode": 44.0, "batch_reward": 0.019170521542662754, "critic_loss": 0.006857704929483589, "actor_loss": -7.568927220106125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.18680500984192, "step": 44000}
{"episode_reward": 6.581191712535832, "episode": 45.0, "batch_reward": 0.019069850731175394, "critic_loss": 0.008602158231195062, "actor_loss": -8.300545845508575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.70241928100586, "step": 45000}
{"episode_reward": 5.127951148731267, "episode": 46.0, "batch_reward": 0.018416786226443948, "critic_loss": 0.006453224795463029, "actor_loss": -8.614473340630532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.405423402786255, "step": 46000}
{"episode_reward": 6.021873140106158, "episode": 47.0, "batch_reward": 0.018723628264619038, "critic_loss": 0.008374235751281957, "actor_loss": -7.779727008461952, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.09335947036743, "step": 47000}
{"episode_reward": 5.2389817214596945, "episode": 48.0, "batch_reward": 0.017915019775740802, "critic_loss": 0.0056866296083317135, "actor_loss": -7.0482001080513, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.851866960525513, "step": 48000}
{"episode_reward": 6.891951939849326, "episode": 49.0, "batch_reward": 0.017998653549468144, "critic_loss": 0.008844272566377185, "actor_loss": -8.072880712270736, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.150015592575073, "step": 49000}
{"episode_reward": 5.359076716125775, "episode": 50.0, "batch_reward": 0.017186934255762027, "critic_loss": 0.005779407667752821, "actor_loss": -7.737252168416977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.567007541656494, "step": 50000}
{"episode_reward": 6.281583423762945, "episode": 51.0, "batch_reward": 0.01716782739968039, "critic_loss": 0.006884760344866663, "actor_loss": -7.059378514766693, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.89801549911499, "step": 51000}
{"episode_reward": 6.121339703698228, "episode": 52.0, "batch_reward": 0.017124475832562894, "critic_loss": 0.0071791255707503296, "actor_loss": -8.584396951794623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.023768186569214, "step": 52000}
{"episode_reward": 5.229284311361455, "episode": 53.0, "batch_reward": 0.017085551366675646, "critic_loss": 0.00632002883014502, "actor_loss": -8.079245408535003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.239420413970947, "step": 53000}
{"episode_reward": 6.361819758770645, "episode": 54.0, "batch_reward": 0.016355994537007063, "critic_loss": 0.004651984993950464, "actor_loss": -6.7741500110626225, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.705532789230347, "step": 54000}
{"episode_reward": 5.9837022889972555, "episode": 55.0, "batch_reward": 0.016628474001307042, "critic_loss": 0.006349470783694414, "actor_loss": -6.8203672133684154, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.440693616867065, "step": 55000}
{"episode_reward": 6.22488953707967, "episode": 56.0, "batch_reward": 0.01626709179044701, "critic_loss": 0.005430568686948391, "actor_loss": -6.86230749475956, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.862797260284424, "step": 56000}
{"episode_reward": 6.010620293035942, "episode": 57.0, "batch_reward": 0.01590192868327722, "critic_loss": 0.005794750536151696, "actor_loss": -7.966484364569187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.640442609786987, "step": 57000}
{"episode_reward": 6.319252073580064, "episode": 58.0, "batch_reward": 0.016068118960596622, "critic_loss": 0.0061577815694035965, "actor_loss": -6.324728136539459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.841758251190186, "step": 58000}
{"episode_reward": 5.7037641750140695, "episode": 59.0, "batch_reward": 0.015453101322287693, "critic_loss": 0.0075973236556747, "actor_loss": -7.962832271277905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.71226716041565, "step": 59000}
{"episode_reward": 6.281934633276398, "episode": 60.0, "batch_reward": 0.015666646969038994, "critic_loss": 0.004215237772557884, "actor_loss": -8.197005390167236, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.854299783706665, "step": 60000}
{"episode_reward": 5.149969961029931, "episode": 61.0, "batch_reward": 0.015537027072161437, "critic_loss": 0.006679482354520587, "actor_loss": -6.657407347083092, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.035635471343994, "step": 61000}
{"episode_reward": 7.188734077500072, "episode": 62.0, "batch_reward": 0.015547893261536955, "critic_loss": 0.004544521157746203, "actor_loss": -6.309897070407867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.017237901687622, "step": 62000}
{"episode_reward": 5.675303318136081, "episode": 63.0, "batch_reward": 0.015218126476276666, "critic_loss": 0.004834986427682452, "actor_loss": -7.602631713926792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.45063805580139, "step": 63000}
{"episode_reward": 5.952861205553107, "episode": 64.0, "batch_reward": 0.01468410072568804, "critic_loss": 0.006225669118721271, "actor_loss": -6.91132703602314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.09314775466919, "step": 64000}
{"episode_reward": 6.243744096951278, "episode": 65.0, "batch_reward": 0.014758258918765933, "critic_loss": 0.004429443662142148, "actor_loss": -6.92694468420744, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.911100387573242, "step": 65000}
{"episode_reward": 5.028876522830874, "episode": 66.0, "batch_reward": 0.01484513424569741, "critic_loss": 0.005494186176772928, "actor_loss": -7.313683247387409, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.035845518112183, "step": 66000}
{"episode_reward": 5.01633593547389, "episode": 67.0, "batch_reward": 0.014577030596788972, "critic_loss": 0.005317669008043595, "actor_loss": -7.536545731008053, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.411255359649658, "step": 67000}
{"episode_reward": 6.282946587150312, "episode": 68.0, "batch_reward": 0.014341628060676157, "critic_loss": 0.0044855674121645275, "actor_loss": -6.74227774900198, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.837198734283447, "step": 68000}
{"episode_reward": 4.4542545973673215, "episode": 69.0, "batch_reward": 0.014096738517750054, "critic_loss": 0.005841828847682336, "actor_loss": -7.067877684295177, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.480581521987915, "step": 69000}
{"episode_reward": 6.719394478108514, "episode": 70.0, "batch_reward": 0.014368955901358277, "critic_loss": 0.004456709371792386, "actor_loss": -7.247096114635467, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.382113695144653, "step": 70000}
{"episode_reward": 6.386290165377962, "episode": 71.0, "batch_reward": 0.01434750530612655, "critic_loss": 0.005539793797681341, "actor_loss": -6.871903869509697, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.87176275253296, "step": 71000}
{"episode_reward": 5.301147711081568, "episode": 72.0, "batch_reward": 0.014142779354238882, "critic_loss": 0.004115695411339403, "actor_loss": -7.237031691551208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16381025314331, "step": 72000}
{"episode_reward": 5.161478604828768, "episode": 73.0, "batch_reward": 0.01397635268443264, "critic_loss": 0.00569398246682249, "actor_loss": -7.215012749135494, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.74308443069458, "step": 73000}
{"episode_reward": 6.38508706368556, "episode": 74.0, "batch_reward": 0.013590334123466163, "critic_loss": 0.0050015176935994535, "actor_loss": -7.267693894684315, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.63397479057312, "step": 74000}
{"episode_reward": 4.987586703434221, "episode": 75.0, "batch_reward": 0.013410023001022637, "critic_loss": 0.003311707683256827, "actor_loss": -6.724498454093933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.33071541786194, "step": 75000}
{"episode_reward": 5.729397358441412, "episode": 76.0, "batch_reward": 0.013476014907471835, "critic_loss": 0.0044882205571047966, "actor_loss": -6.292213112831115, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.389546155929565, "step": 76000}
{"episode_reward": 5.322529515052006, "episode": 77.0, "batch_reward": 0.013357717426959426, "critic_loss": 0.0057297235466248824, "actor_loss": -7.097726394712925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.73695182800293, "step": 77000}
{"episode_reward": 5.131456542890976, "episode": 78.0, "batch_reward": 0.013674446632852779, "critic_loss": 0.004525807400932535, "actor_loss": -7.358982281267643, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.673672437667847, "step": 78000}
{"episode_reward": 6.148417631086864, "episode": 79.0, "batch_reward": 0.012964828804368153, "critic_loss": 0.003860818756307708, "actor_loss": -6.761113489329815, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.553436040878296, "step": 79000}
{"episode_reward": 5.874163995486946, "episode": 80.0, "batch_reward": 0.012967434079851955, "critic_loss": 0.006242826784320641, "actor_loss": -6.368388297975064, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.940710306167603, "step": 80000}
{"episode_reward": 5.612438732808185, "episode": 81.0, "batch_reward": 0.012804358340799809, "critic_loss": 0.003718333624507068, "actor_loss": -7.598746694028377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.87355446815491, "step": 81000}
{"episode_reward": 7.0716087211027245, "episode": 82.0, "batch_reward": 0.013062516334932297, "critic_loss": 0.007058969883073587, "actor_loss": -6.763811327397823, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.79625391960144, "step": 82000}
{"episode_reward": 6.419332726148646, "episode": 83.0, "batch_reward": 0.01252792773488909, "critic_loss": 0.0045972501118958465, "actor_loss": -7.215593057453632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.52305769920349, "step": 83000}
{"episode_reward": 6.265354394981715, "episode": 84.0, "batch_reward": 0.012414990446763113, "critic_loss": 0.007606885838758899, "actor_loss": -7.466351522117853, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.161885976791382, "step": 84000}
{"episode_reward": 5.723741607453904, "episode": 85.0, "batch_reward": 0.012828161970013753, "critic_loss": 0.005570548882154981, "actor_loss": -6.788115597933531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90724539756775, "step": 85000}
{"episode_reward": 5.18582393123393, "episode": 86.0, "batch_reward": 0.012509093603119255, "critic_loss": 0.005179110188735649, "actor_loss": -6.817047307640314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.4981906414032, "step": 86000}
{"episode_reward": 6.3908837794105064, "episode": 87.0, "batch_reward": 0.012563767403829843, "critic_loss": 0.0034289809922047427, "actor_loss": -6.447948762446642, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.545965433120728, "step": 87000}
{"episode_reward": 5.687582625381088, "episode": 88.0, "batch_reward": 0.012537762849126012, "critic_loss": 0.008392679758107988, "actor_loss": -6.437767687082291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.543088674545288, "step": 88000}
{"episode_reward": 5.760043777845188, "episode": 89.0, "batch_reward": 0.012614013565238565, "critic_loss": 0.003665262873430038, "actor_loss": -6.811773290783167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.593209266662598, "step": 89000}
{"episode_reward": 5.202527364122576, "episode": 90.0, "batch_reward": 0.01225171185284853, "critic_loss": 0.004328347149246838, "actor_loss": -7.190241386324168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.39456820487976, "step": 90000}
{"episode_reward": 5.278892263050403, "episode": 91.0, "batch_reward": 0.01259458136977628, "critic_loss": 0.0036535440894949717, "actor_loss": -6.623804893046618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.12447810173035, "step": 91000}
{"episode_reward": 5.063889603599484, "episode": 92.0, "batch_reward": 0.012223097874317319, "critic_loss": 0.005350594505056506, "actor_loss": -6.8695072759985925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.929377794265747, "step": 92000}
{"episode_reward": 5.087677477266483, "episode": 93.0, "batch_reward": 0.012115667059319093, "critic_loss": 0.003996074873750331, "actor_loss": -6.111215911358595, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.96371841430664, "step": 93000}
{"episode_reward": 6.605918312189057, "episode": 94.0, "batch_reward": 0.011939982557902113, "critic_loss": 0.005163749255123549, "actor_loss": -6.781044898152351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.706881523132324, "step": 94000}
{"episode_reward": 6.804598135416631, "episode": 95.0, "batch_reward": 0.01198804351151921, "critic_loss": 0.003497506322019035, "actor_loss": -7.60476612636447, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.38090753555298, "step": 95000}
{"episode_reward": 5.567496421765759, "episode": 96.0, "batch_reward": 0.011917434419272467, "critic_loss": 0.004447898058278952, "actor_loss": -7.005261185586453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.350246906280518, "step": 96000}
{"episode_reward": 5.479627506042235, "episode": 97.0, "batch_reward": 0.011975859926547856, "critic_loss": 0.0034964449112012516, "actor_loss": -7.035511140942574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.914321422576904, "step": 97000}
{"episode_reward": 7.721759391654387, "episode": 98.0, "batch_reward": 0.011834418894490228, "critic_loss": 0.005085141222371021, "actor_loss": -7.111078535348177, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.35540199279785, "step": 98000}
{"episode_reward": 6.752598387286101, "episode": 99.0, "batch_reward": 0.011618262309581042, "critic_loss": 0.003987257311702706, "actor_loss": -6.927961277157069, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.349346160888672, "step": 99000}
{"episode_reward": 5.531044040032954, "episode": 100.0, "batch_reward": 0.011715490828501061, "critic_loss": 0.003424553210294107, "actor_loss": -6.9382437611222265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.137646198272705, "step": 100000}
{"episode_reward": 6.735497910779865, "episode": 101.0, "batch_reward": 0.011570670763030649, "critic_loss": 0.0067214030139439275, "actor_loss": -7.229655245125294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.66144347190857, "step": 101000}
{"episode_reward": 6.8629564950471735, "episode": 102.0, "batch_reward": 0.011685580881778151, "critic_loss": 0.003536876843543723, "actor_loss": -7.360000202089548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.911614656448364, "step": 102000}
{"episode_reward": 6.127194633999866, "episode": 103.0, "batch_reward": 0.011718828487908468, "critic_loss": 0.004048096799408086, "actor_loss": -7.169481038242578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.73952078819275, "step": 103000}
{"episode_reward": 4.584843476836001, "episode": 104.0, "batch_reward": 0.01143304564175196, "critic_loss": 0.004163645224442007, "actor_loss": -6.584775189936161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.901934146881104, "step": 104000}
{"episode_reward": 5.724746255492027, "episode": 105.0, "batch_reward": 0.011579593003960326, "critic_loss": 0.0036903308751352597, "actor_loss": -6.222288185834885, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.926333904266357, "step": 105000}
{"episode_reward": 6.269250320732816, "episode": 106.0, "batch_reward": 0.011423241402255372, "critic_loss": 0.0035121464382391423, "actor_loss": -5.716120580881834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.360849618911743, "step": 106000}
{"episode_reward": 5.460924860072497, "episode": 107.0, "batch_reward": 0.01144040503515862, "critic_loss": 0.004558176330901915, "actor_loss": -6.338291817128658, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.19326376914978, "step": 107000}
{"episode_reward": 6.053662887735511, "episode": 108.0, "batch_reward": 0.011229206584626809, "critic_loss": 0.003702168613759568, "actor_loss": -7.325520326524973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.972784280776978, "step": 108000}
{"episode_reward": 5.025371731343737, "episode": 109.0, "batch_reward": 0.011041555056348443, "critic_loss": 0.002907944174337899, "actor_loss": -7.003772001504898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.183239936828613, "step": 109000}
{"episode_reward": 4.771815448604245, "episode": 110.0, "batch_reward": 0.011028162366943433, "critic_loss": 0.0055653200990345795, "actor_loss": -6.931482166588307, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.068594932556152, "step": 110000}
{"episode_reward": 6.11733588365901, "episode": 111.0, "batch_reward": 0.011053891973337159, "critic_loss": 0.0025915967787150294, "actor_loss": -7.631318588405848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.22512459754944, "step": 111000}
{"episode_reward": 5.886974752718003, "episode": 112.0, "batch_reward": 0.011156768552493304, "critic_loss": 0.00357255194048048, "actor_loss": -6.666940560936927, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.64570164680481, "step": 112000}
{"episode_reward": 4.164358885154722, "episode": 113.0, "batch_reward": 0.010784000842599199, "critic_loss": 0.004402543647855054, "actor_loss": -6.524918328821659, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.437557220458984, "step": 113000}
{"episode_reward": 4.618607447888989, "episode": 114.0, "batch_reward": 0.010846272410592064, "critic_loss": 0.0034097784970363136, "actor_loss": -6.898641459941864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.643311738967896, "step": 114000}
{"episode_reward": 4.704412509784978, "episode": 115.0, "batch_reward": 0.010890692283399403, "critic_loss": 0.003954282575985416, "actor_loss": -6.64217986574769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.768290758132935, "step": 115000}
{"episode_reward": 6.066014221182309, "episode": 116.0, "batch_reward": 0.010837774138897657, "critic_loss": 0.003385161231359234, "actor_loss": -6.720055485337973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.733036756515503, "step": 116000}
{"episode_reward": 5.053655805523437, "episode": 117.0, "batch_reward": 0.010946892912965267, "critic_loss": 0.003754551576770609, "actor_loss": -6.859567439645529, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.488216876983643, "step": 117000}
{"episode_reward": 5.866265330109143, "episode": 118.0, "batch_reward": 0.01094795983377844, "critic_loss": 0.003888408965896815, "actor_loss": -6.463703095898032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.498907566070557, "step": 118000}
{"episode_reward": 6.003620912523405, "episode": 119.0, "batch_reward": 0.010712677013128996, "critic_loss": 0.00319940432254225, "actor_loss": -6.256087373316288, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.24426293373108, "step": 119000}
{"episode_reward": 6.029461098335805, "episode": 120.0, "batch_reward": 0.010533589080208912, "critic_loss": 0.0026714430931897367, "actor_loss": -5.67343133699894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.924309492111206, "step": 120000}
{"episode_reward": 5.058280465514095, "episode": 121.0, "batch_reward": 0.010674932481255383, "critic_loss": 0.004909179957583547, "actor_loss": -6.500315875977278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.90768218040466, "step": 121000}
{"episode_reward": 6.764115931192099, "episode": 122.0, "batch_reward": 0.0107400455432944, "critic_loss": 0.0031749234861927107, "actor_loss": -6.4271347503960135, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077703952789307, "step": 122000}
{"episode_reward": 5.772832275664471, "episode": 123.0, "batch_reward": 0.010639176418306306, "critic_loss": 0.004098215519246878, "actor_loss": -6.296533621534705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.03948473930359, "step": 123000}
{"episode_reward": 6.75802513007401, "episode": 124.0, "batch_reward": 0.010522822773782536, "critic_loss": 0.0033842991855053696, "actor_loss": -6.240769777566195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.138710737228394, "step": 124000}
{"episode_reward": 6.33560261568091, "episode": 125.0, "batch_reward": 0.01040269560017623, "critic_loss": 0.0032014569508901332, "actor_loss": -6.553217524647713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.253811597824097, "step": 125000}
{"episode_reward": 6.683003478229806, "episode": 126.0, "batch_reward": 0.010286651602480561, "critic_loss": 0.0033510740737547166, "actor_loss": -6.853127163767815, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.864503383636475, "step": 126000}
{"episode_reward": 5.779867514692751, "episode": 127.0, "batch_reward": 0.010460196558386087, "critic_loss": 0.002756947217771085, "actor_loss": -6.9768675040751695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.939266681671143, "step": 127000}
{"episode_reward": 5.901682897311697, "episode": 128.0, "batch_reward": 0.010387885513482615, "critic_loss": 0.0028843480384384747, "actor_loss": -7.093222083389759, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.284969329833984, "step": 128000}
{"episode_reward": 5.045116066240226, "episode": 129.0, "batch_reward": 0.01040890806983225, "critic_loss": 0.003641143445071066, "actor_loss": -7.9237346278578045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.853761672973633, "step": 129000}
{"episode_reward": 6.446403669621441, "episode": 130.0, "batch_reward": 0.010199619486462325, "critic_loss": 0.00337049112492241, "actor_loss": -7.276344716697931, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.7029070854187, "step": 130000}
{"episode_reward": 6.672464238712727, "episode": 131.0, "batch_reward": 0.01030243376456201, "critic_loss": 0.0038354193035920617, "actor_loss": -6.970533615067601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.5690655708313, "step": 131000}
{"episode_reward": 5.896350314025823, "episode": 132.0, "batch_reward": 0.010371906120795757, "critic_loss": 0.002649929019913543, "actor_loss": -6.518506478443742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.224467754364014, "step": 132000}
{"episode_reward": 6.06095340211744, "episode": 133.0, "batch_reward": 0.010253215363482013, "critic_loss": 0.003623669136868557, "actor_loss": -7.223958321973681, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.293872833251953, "step": 133000}
{"episode_reward": 4.771140520266481, "episode": 134.0, "batch_reward": 0.010355968522373587, "critic_loss": 0.0029467178942868487, "actor_loss": -7.099596744582057, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.89377188682556, "step": 134000}
{"episode_reward": 6.790697393334127, "episode": 135.0, "batch_reward": 0.010188278392655774, "critic_loss": 0.004383356138307135, "actor_loss": -6.260800842031837, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22914743423462, "step": 135000}
{"episode_reward": 4.628880799363374, "episode": 136.0, "batch_reward": 0.010036168756894767, "critic_loss": 0.0025392393694201017, "actor_loss": -7.519488498896361, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.403332948684692, "step": 136000}
{"episode_reward": 5.706986066869573, "episode": 137.0, "batch_reward": 0.010088915775297209, "critic_loss": 0.0037110954142408445, "actor_loss": -6.062014512211085, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.448033094406128, "step": 137000}
{"episode_reward": 5.426108144423056, "episode": 138.0, "batch_reward": 0.010298661448061467, "critic_loss": 0.0026434623158129397, "actor_loss": -6.0145198689252135, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.50438165664673, "step": 138000}
{"episode_reward": 5.707473126015303, "episode": 139.0, "batch_reward": 0.010204543883679435, "critic_loss": 0.00394189536588965, "actor_loss": -6.822998251318932, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.04814863204956, "step": 139000}
{"episode_reward": 5.547224483963169, "episode": 140.0, "batch_reward": 0.009871421497315168, "critic_loss": 0.0026807401968108025, "actor_loss": -6.753820517405868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.950546503067017, "step": 140000}
{"episode_reward": 6.083512322586527, "episode": 141.0, "batch_reward": 0.009902716952608899, "critic_loss": 0.0025004622074193323, "actor_loss": -6.424273711711169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.135300397872925, "step": 141000}
{"episode_reward": 6.5796871564606585, "episode": 142.0, "batch_reward": 0.010123676199000328, "critic_loss": 0.0028314722239156254, "actor_loss": -5.43089614456892, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.728667974472046, "step": 142000}
{"episode_reward": 5.403539739984213, "episode": 143.0, "batch_reward": 0.009943427421851083, "critic_loss": 0.0025990672752814136, "actor_loss": -6.487404468044638, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.15178680419922, "step": 143000}
{"episode_reward": 6.326904929051457, "episode": 144.0, "batch_reward": 0.0101390496250242, "critic_loss": 0.0025405906311643774, "actor_loss": -6.168674406915903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.224565505981445, "step": 144000}
{"episode_reward": 6.064820859292409, "episode": 145.0, "batch_reward": 0.009861968729412184, "critic_loss": 0.003226416682184208, "actor_loss": -5.51602835097909, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.875107049942017, "step": 145000}
{"episode_reward": 6.887607633075393, "episode": 146.0, "batch_reward": 0.009864565852330998, "critic_loss": 0.0028958142344927182, "actor_loss": -5.969347366720438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.368596076965332, "step": 146000}
{"episode_reward": 5.35172943638048, "episode": 147.0, "batch_reward": 0.009655902330297977, "critic_loss": 0.002820645389641868, "actor_loss": -6.201148569196462, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.302654504776, "step": 147000}
{"episode_reward": 7.464821082904418, "episode": 148.0, "batch_reward": 0.010194123481400311, "critic_loss": 0.00355556153022917, "actor_loss": -6.680107618570328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.71878218650818, "step": 148000}
{"episode_reward": 6.156901486950252, "episode": 149.0, "batch_reward": 0.009851272872416302, "critic_loss": 0.0035633551178179913, "actor_loss": -5.6482401300221685, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.189178228378296, "step": 149000}
{"episode_reward": 5.617340227661784, "episode": 150.0, "batch_reward": 0.009731609391747043, "critic_loss": 0.0025324786488054086, "actor_loss": -5.955082052871585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
