{"episode_reward": 0.0, "episode": 1.0, "duration": 18.35714602470398, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.53350830078125, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.27947416744080333, "critic_loss": 0.01865410523519551, "actor_loss": -35.55482647037294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 70.53777194023132, "step": 3000}
{"episode_reward": 4.8476305420382095, "episode": 4.0, "batch_reward": 0.1739148034825921, "critic_loss": 0.011851974973920733, "actor_loss": -31.187190247535707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.172710180282593, "step": 4000}
{"episode_reward": 5.701646517925907, "episode": 5.0, "batch_reward": 0.1345388979502022, "critic_loss": 0.015363924900069832, "actor_loss": -27.213172574043273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.413353204727173, "step": 5000}
{"episode_reward": 5.672400836449255, "episode": 6.0, "batch_reward": 0.11084653942659498, "critic_loss": 0.013532882826635614, "actor_loss": -27.541940198898317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.09673023223877, "step": 6000}
{"episode_reward": 5.512999445987654, "episode": 7.0, "batch_reward": 0.09481526529788971, "critic_loss": 0.015131716879317537, "actor_loss": -29.038940150260924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.072515964508057, "step": 7000}
{"episode_reward": 5.66107552763598, "episode": 8.0, "batch_reward": 0.08369201467558741, "critic_loss": 0.013838204482453875, "actor_loss": -27.076076800346375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.88186001777649, "step": 8000}
{"episode_reward": 4.661928307542034, "episode": 9.0, "batch_reward": 0.07363612480647862, "critic_loss": 0.021031435468234123, "actor_loss": -26.24734589242935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.442272901535034, "step": 9000}
{"episode_reward": 5.369490411106362, "episode": 10.0, "batch_reward": 0.06733968997001648, "critic_loss": 0.014583646043436602, "actor_loss": -25.85851729774475, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.30293035507202, "step": 10000}
{"episode_reward": 6.1862862654608906, "episode": 11.0, "batch_reward": 0.06148969209380448, "critic_loss": 0.018770940114511178, "actor_loss": -25.99307698774338, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.901344537734985, "step": 11000}
{"episode_reward": 4.947829577124982, "episode": 12.0, "batch_reward": 0.05689596202038229, "critic_loss": 0.019728944012895225, "actor_loss": -24.774418390274047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.088297128677368, "step": 12000}
{"episode_reward": 5.7507136033631605, "episode": 13.0, "batch_reward": 0.052083871053531766, "critic_loss": 0.009716251559788362, "actor_loss": -24.800092445373537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.333558559417725, "step": 13000}
{"episode_reward": 4.251408453654438, "episode": 14.0, "batch_reward": 0.048210667924955486, "critic_loss": 0.02186517559806816, "actor_loss": -23.70128628015518, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.35726547241211, "step": 14000}
{"episode_reward": 4.816477084746492, "episode": 15.0, "batch_reward": 0.04575294208806008, "critic_loss": 0.013780039154575206, "actor_loss": -26.25155402183533, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.249674320220947, "step": 15000}
{"episode_reward": 5.131157098779448, "episode": 16.0, "batch_reward": 0.04251631579175592, "critic_loss": 0.013436102487961761, "actor_loss": -24.896778100967406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.065824508666992, "step": 16000}
{"episode_reward": 5.150172875497331, "episode": 17.0, "batch_reward": 0.04078156285267323, "critic_loss": 0.023236851929104886, "actor_loss": -23.833897940158845, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.360896348953247, "step": 17000}
{"episode_reward": 3.832114237947039, "episode": 18.0, "batch_reward": 0.038723342468030754, "critic_loss": 0.010153477755840868, "actor_loss": -24.034426916360854, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.392505645751953, "step": 18000}
{"episode_reward": 5.2233257108836835, "episode": 19.0, "batch_reward": 0.036720162433572116, "critic_loss": 0.017600659961346538, "actor_loss": -23.700380860805513, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.092592000961304, "step": 19000}
{"episode_reward": 4.996224370246685, "episode": 20.0, "batch_reward": 0.034752299865242094, "critic_loss": 0.016854867227957582, "actor_loss": -24.39050371289253, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.56201195716858, "step": 20000}
{"episode_reward": 5.011021956171529, "episode": 21.0, "batch_reward": 0.034093554152641446, "critic_loss": 0.0170162518559664, "actor_loss": -24.46946562409401, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.50677680969238, "step": 21000}
{"episode_reward": 5.721732348756214, "episode": 22.0, "batch_reward": 0.03231976075377315, "critic_loss": 0.015949248362681828, "actor_loss": -23.713515408277512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.745802640914917, "step": 22000}
{"episode_reward": 6.616987953539034, "episode": 23.0, "batch_reward": 0.03171101979725063, "critic_loss": 0.01722006419498939, "actor_loss": -24.294683928251267, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.703157424926758, "step": 23000}
{"episode_reward": 4.4852508461991505, "episode": 24.0, "batch_reward": 0.030040485627483578, "critic_loss": 0.014673820801574039, "actor_loss": -24.16450381064415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.450843334197998, "step": 24000}
{"episode_reward": 4.893559107533701, "episode": 25.0, "batch_reward": 0.028958467424381525, "critic_loss": 0.01508486911424552, "actor_loss": -22.994572040319444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.89338970184326, "step": 25000}
{"episode_reward": 4.540937144867275, "episode": 26.0, "batch_reward": 0.02789414197462611, "critic_loss": 0.013155947193619795, "actor_loss": -23.395202603578568, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.501314640045166, "step": 26000}
{"episode_reward": 5.637168920994153, "episode": 27.0, "batch_reward": 0.027501016492955388, "critic_loss": 0.013667856598505751, "actor_loss": -23.541117709636687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.457205772399902, "step": 27000}
{"episode_reward": 2.970350457508733, "episode": 28.0, "batch_reward": 0.02625073884706944, "critic_loss": 0.013960677310591564, "actor_loss": -22.755041199922562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.46774458885193, "step": 28000}
{"episode_reward": 5.182364746365217, "episode": 29.0, "batch_reward": 0.026450537709519266, "critic_loss": 0.011334749903617193, "actor_loss": -23.565429049253463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.310139656066895, "step": 29000}
{"episode_reward": 5.299614008346509, "episode": 30.0, "batch_reward": 0.02465168031817302, "critic_loss": 0.012757397689536447, "actor_loss": -22.60408395767212, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.511554718017578, "step": 30000}
{"episode_reward": 4.503442199291125, "episode": 31.0, "batch_reward": 0.024245623000897467, "critic_loss": 0.011764151634823066, "actor_loss": -23.503939548254014, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.39092683792114, "step": 31000}
{"episode_reward": 5.901021752912728, "episode": 32.0, "batch_reward": 0.023398869638098403, "critic_loss": 0.011465453683282249, "actor_loss": -22.685984424352647, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.5027277469635, "step": 32000}
{"episode_reward": 6.73784228783153, "episode": 33.0, "batch_reward": 0.023171742634382098, "critic_loss": 0.014840305314486614, "actor_loss": -23.766819544434547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.399097442626953, "step": 33000}
{"episode_reward": 3.695330448769056, "episode": 34.0, "batch_reward": 0.022592727584764362, "critic_loss": 0.010041896583439666, "actor_loss": -22.409210626244544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.61282992362976, "step": 34000}
{"episode_reward": 6.525439798919805, "episode": 35.0, "batch_reward": 0.021842740307096393, "critic_loss": 0.010558048917882843, "actor_loss": -23.381975147247314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.52877163887024, "step": 35000}
{"episode_reward": 4.655720657692138, "episode": 36.0, "batch_reward": 0.02139183233771473, "critic_loss": 0.0087267770106846, "actor_loss": -21.76790773844719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.573954582214355, "step": 36000}
{"episode_reward": 5.6511706045869206, "episode": 37.0, "batch_reward": 0.021196509994566442, "critic_loss": 0.017921122190251482, "actor_loss": -22.7685606187582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.54065227508545, "step": 37000}
{"episode_reward": 5.87995493038431, "episode": 38.0, "batch_reward": 0.02088398012891412, "critic_loss": 0.006218601248110645, "actor_loss": -23.221355993390084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.657742977142334, "step": 38000}
{"episode_reward": 5.745572861337241, "episode": 39.0, "batch_reward": 0.020193152929423377, "critic_loss": 0.011743625938106562, "actor_loss": -23.389708945155142, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.64798092842102, "step": 39000}
{"episode_reward": 3.4443910857780002, "episode": 40.0, "batch_reward": 0.020075221757870167, "critic_loss": 0.010282512525038328, "actor_loss": -23.609476338505743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.30148720741272, "step": 40000}
{"episode_reward": 5.856707335963026, "episode": 41.0, "batch_reward": 0.019814808209892364, "critic_loss": 0.009065464595230879, "actor_loss": -23.188648877978324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.797486305236816, "step": 41000}
{"episode_reward": 6.862636266908579, "episode": 42.0, "batch_reward": 0.01901057068258524, "critic_loss": 0.011879720545053716, "actor_loss": -22.313117101311683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.909240007400513, "step": 42000}
{"episode_reward": 4.49311116044005, "episode": 43.0, "batch_reward": 0.01897309474274516, "critic_loss": 0.009289015496557113, "actor_loss": -22.435467680573463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.835055828094482, "step": 43000}
{"episode_reward": 4.807636909825129, "episode": 44.0, "batch_reward": 0.01852359007159248, "critic_loss": 0.0077042901861132124, "actor_loss": -21.999194363594054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.35979914665222, "step": 44000}
{"episode_reward": 5.938455451914562, "episode": 45.0, "batch_reward": 0.018521879225270824, "critic_loss": 0.011915686564316274, "actor_loss": -22.86349410223961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.49661159515381, "step": 45000}
{"episode_reward": 4.864900433737032, "episode": 46.0, "batch_reward": 0.017844262493774295, "critic_loss": 0.008486174189369195, "actor_loss": -22.284433743834494, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.387389421463013, "step": 46000}
{"episode_reward": 4.637668245107362, "episode": 47.0, "batch_reward": 0.018193858803715556, "critic_loss": 0.0074848321284516715, "actor_loss": -22.945588727772236, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.031806230545044, "step": 47000}
{"episode_reward": 5.197974647222761, "episode": 48.0, "batch_reward": 0.017386679349234328, "critic_loss": 0.008071277131064562, "actor_loss": -21.402203218221665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.937031745910645, "step": 48000}
{"episode_reward": 5.214835837466961, "episode": 49.0, "batch_reward": 0.01749277943209745, "critic_loss": 0.010066400295734638, "actor_loss": -23.033273321688174, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.664196252822876, "step": 49000}
{"episode_reward": 5.360049747784204, "episode": 50.0, "batch_reward": 0.016666358539834617, "critic_loss": 0.00768997722081258, "actor_loss": -22.846873148083688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09126305580139, "step": 50000}
{"episode_reward": 5.921232173202941, "episode": 51.0, "batch_reward": 0.016623087322339417, "critic_loss": 0.008391913666288019, "actor_loss": -22.746570346713067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.374762535095215, "step": 51000}
{"episode_reward": 4.638061716053911, "episode": 52.0, "batch_reward": 0.01648566792649217, "critic_loss": 0.01107857148029143, "actor_loss": -22.887655361294748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.356020212173462, "step": 52000}
{"episode_reward": 3.9937084112997785, "episode": 53.0, "batch_reward": 0.016502146093640476, "critic_loss": 0.008033998099403106, "actor_loss": -22.53633551734686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.921252965927124, "step": 53000}
{"episode_reward": 3.660991814163375, "episode": 54.0, "batch_reward": 0.015708991108695045, "critic_loss": 0.007625456639638287, "actor_loss": -22.862049251556396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.621206521987915, "step": 54000}
{"episode_reward": 6.156707333873602, "episode": 55.0, "batch_reward": 0.016042336671147496, "critic_loss": 0.006482209827809129, "actor_loss": -22.90563358449936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.76563858985901, "step": 55000}
{"episode_reward": 4.911461444878165, "episode": 56.0, "batch_reward": 0.01566665279516019, "critic_loss": 0.00786393338078051, "actor_loss": -23.082760079801083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.242284297943115, "step": 56000}
{"episode_reward": 4.977371527391946, "episode": 57.0, "batch_reward": 0.015226700061466545, "critic_loss": 0.011600299392972375, "actor_loss": -22.697461093008517, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.415624380111694, "step": 57000}
{"episode_reward": 4.646885516440241, "episode": 58.0, "batch_reward": 0.015447111629880965, "critic_loss": 0.005594201319996501, "actor_loss": -22.136224160015583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.800469398498535, "step": 58000}
{"episode_reward": 7.662959075189733, "episode": 59.0, "batch_reward": 0.014867007033899426, "critic_loss": 0.01758555808501842, "actor_loss": -21.906103646576405, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.347387552261353, "step": 59000}
{"episode_reward": 4.921867213240739, "episode": 60.0, "batch_reward": 0.015113908879924566, "critic_loss": 0.005292451684159459, "actor_loss": -22.754786276459694, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.649986267089844, "step": 60000}
{"episode_reward": 7.425899553884257, "episode": 61.0, "batch_reward": 0.014941920986864716, "critic_loss": 0.006113439589025802, "actor_loss": -22.236826613366603, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.64424180984497, "step": 61000}
{"episode_reward": 4.425081702548025, "episode": 62.0, "batch_reward": 0.014902582610724495, "critic_loss": 0.007071208628214663, "actor_loss": -22.892599347293377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.696974277496338, "step": 62000}
{"episode_reward": 4.012193300665039, "episode": 63.0, "batch_reward": 0.014548076098319143, "critic_loss": 0.005728005824130378, "actor_loss": -22.070001012563704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.880863428115845, "step": 63000}
{"episode_reward": 4.629442405657985, "episode": 64.0, "batch_reward": 0.014008128765271976, "critic_loss": 0.007037405919050798, "actor_loss": -22.518228211462496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.597899675369263, "step": 64000}
{"episode_reward": 4.986779367801398, "episode": 65.0, "batch_reward": 0.014080158979166299, "critic_loss": 0.00752104489436897, "actor_loss": -22.4830735206604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.6744167804718, "step": 65000}
{"episode_reward": 3.8462297099630804, "episode": 66.0, "batch_reward": 0.014193984393496067, "critic_loss": 0.007758124833431793, "actor_loss": -22.55916768217087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.327537298202515, "step": 66000}
{"episode_reward": 5.254359449664005, "episode": 67.0, "batch_reward": 0.013914851660374553, "critic_loss": 0.00533239193278132, "actor_loss": -22.832072051167486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.529358625411987, "step": 67000}
{"episode_reward": 5.642052283204015, "episode": 68.0, "batch_reward": 0.013680220468668267, "critic_loss": 0.008690549456223379, "actor_loss": -21.49892596912384, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.049779653549194, "step": 68000}
{"episode_reward": 3.9161121585084557, "episode": 69.0, "batch_reward": 0.013409016026416793, "critic_loss": 0.005016095375889563, "actor_loss": -21.50657420527935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.66065812110901, "step": 69000}
{"episode_reward": 3.9820503690621134, "episode": 70.0, "batch_reward": 0.013663943699328229, "critic_loss": 0.005701983740815195, "actor_loss": -22.736592779606582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.933924913406372, "step": 70000}
{"episode_reward": 4.721374335469419, "episode": 71.0, "batch_reward": 0.013693161555333063, "critic_loss": 0.0066193305237247846, "actor_loss": -22.390742338895798, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.137152671813965, "step": 71000}
{"episode_reward": 3.7783715473933217, "episode": 72.0, "batch_reward": 0.013445379188517109, "critic_loss": 0.004308966289187083, "actor_loss": -22.007921976476908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.962751865386963, "step": 72000}
{"episode_reward": 4.123750421817069, "episode": 73.0, "batch_reward": 0.013235652128234505, "critic_loss": 0.0076063373306969875, "actor_loss": -22.158644935131072, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.919411182403564, "step": 73000}
{"episode_reward": 4.369511673597018, "episode": 74.0, "batch_reward": 0.01288790590967983, "critic_loss": 0.006121809293734259, "actor_loss": -22.713844285666944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.809163808822632, "step": 74000}
{"episode_reward": 4.779816471407687, "episode": 75.0, "batch_reward": 0.012719917660579085, "critic_loss": 0.00520217081203009, "actor_loss": -22.54971124243736, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.6964054107666, "step": 75000}
{"episode_reward": 2.568737038029651, "episode": 76.0, "batch_reward": 0.012809552496764808, "critic_loss": 0.008710943497935658, "actor_loss": -23.056528047889472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.178666591644287, "step": 76000}
{"episode_reward": 5.580768763426544, "episode": 77.0, "batch_reward": 0.012616504772100598, "critic_loss": 0.005155229346797569, "actor_loss": -21.93308810058236, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.346346855163574, "step": 77000}
{"episode_reward": 4.2409565964330715, "episode": 78.0, "batch_reward": 0.012899020397802816, "critic_loss": 0.006513464912728523, "actor_loss": -22.43310524609685, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.63131070137024, "step": 78000}
{"episode_reward": 5.686793150562591, "episode": 79.0, "batch_reward": 0.012203831892926245, "critic_loss": 0.004170159826353484, "actor_loss": -21.04045389151573, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.418769359588623, "step": 79000}
{"episode_reward": 6.4847755700930865, "episode": 80.0, "batch_reward": 0.012249021833064035, "critic_loss": 0.007070872175201658, "actor_loss": -21.949984286248682, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.709291696548462, "step": 80000}
{"episode_reward": 5.605703725351232, "episode": 81.0, "batch_reward": 0.011978980059735477, "critic_loss": 0.004679539903794648, "actor_loss": -22.1127076895535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.07438039779663, "step": 81000}
{"episode_reward": 4.287237679042963, "episode": 82.0, "batch_reward": 0.012377777425805106, "critic_loss": 0.006524841877486324, "actor_loss": -23.272370079308747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.980053424835205, "step": 82000}
{"episode_reward": 5.8343883305323665, "episode": 83.0, "batch_reward": 0.011849654051242397, "critic_loss": 0.006407245578127913, "actor_loss": -21.249460681796073, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.419072151184082, "step": 83000}
{"episode_reward": 4.938961765348201, "episode": 84.0, "batch_reward": 0.011719660229049623, "critic_loss": 0.007137933717094711, "actor_loss": -22.73016826212406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.132628679275513, "step": 84000}
{"episode_reward": 6.770672617400463, "episode": 85.0, "batch_reward": 0.012083273803582414, "critic_loss": 0.004759521490741463, "actor_loss": -22.432218420922755, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.13327169418335, "step": 85000}
{"episode_reward": 4.770262644805495, "episode": 86.0, "batch_reward": 0.011765319143189117, "critic_loss": 0.00491511745050957, "actor_loss": -21.909765751332046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60603952407837, "step": 86000}
{"episode_reward": 6.024270298593861, "episode": 87.0, "batch_reward": 0.011874698985368014, "critic_loss": 0.0052754195388552035, "actor_loss": -21.80971219751239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.088690519332886, "step": 87000}
{"episode_reward": 4.89327981011023, "episode": 88.0, "batch_reward": 0.01185491462587379, "critic_loss": 0.009369049190718215, "actor_loss": -21.117911127328874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.312754154205322, "step": 88000}
{"episode_reward": 6.560432702991071, "episode": 89.0, "batch_reward": 0.011875171741005034, "critic_loss": 0.0036168364395416574, "actor_loss": -22.54455456414819, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.891514539718628, "step": 89000}
{"episode_reward": 5.250514078067331, "episode": 90.0, "batch_reward": 0.011594846019521356, "critic_loss": 0.004975612058711704, "actor_loss": -23.219539250373842, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.106843948364258, "step": 90000}
{"episode_reward": 4.923645344848634, "episode": 91.0, "batch_reward": 0.011860093620372936, "critic_loss": 0.004903896897172672, "actor_loss": -22.035230723485352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.9801881313324, "step": 91000}
{"episode_reward": 3.646481728314165, "episode": 92.0, "batch_reward": 0.01161898674722761, "critic_loss": 0.006559921131658484, "actor_loss": -21.541142632737756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.625113010406494, "step": 92000}
{"episode_reward": 6.482956098714958, "episode": 93.0, "batch_reward": 0.011405203162692487, "critic_loss": 0.004737922145621269, "actor_loss": -21.58494762672484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.253478050231934, "step": 93000}
{"episode_reward": 5.704915635374206, "episode": 94.0, "batch_reward": 0.011274143073940649, "critic_loss": 0.0054675410214622385, "actor_loss": -21.64401354010403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.865660190582275, "step": 94000}
{"episode_reward": 4.547460867741683, "episode": 95.0, "batch_reward": 0.01127220846991986, "critic_loss": 0.0045389337201486345, "actor_loss": -22.953329618632793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.77257776260376, "step": 95000}
{"episode_reward": 6.892545668592127, "episode": 96.0, "batch_reward": 0.011273110195528716, "critic_loss": 0.004081981519120746, "actor_loss": -22.863701509848237, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.062599897384644, "step": 96000}
{"episode_reward": 5.3049638207861785, "episode": 97.0, "batch_reward": 0.011327492041746155, "critic_loss": 0.00951452698502544, "actor_loss": -23.20759793205559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.65958833694458, "step": 97000}
{"episode_reward": 5.828124227607359, "episode": 98.0, "batch_reward": 0.011133415754651651, "critic_loss": 0.0037425178519915787, "actor_loss": -21.612486884996294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.679993152618408, "step": 98000}
{"episode_reward": 4.79401319487927, "episode": 99.0, "batch_reward": 0.010943934039212764, "critic_loss": 0.004185837356213596, "actor_loss": -21.671275593936443, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.520496606826782, "step": 99000}
{"episode_reward": 6.561654429341163, "episode": 100.0, "batch_reward": 0.011087278671795502, "critic_loss": 0.0034830536126683, "actor_loss": -21.935026494845747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.578661918640137, "step": 100000}
{"episode_reward": 6.7011778783379565, "episode": 101.0, "batch_reward": 0.010944918675813825, "critic_loss": 0.0059375357373937735, "actor_loss": -22.34977982401848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.347373962402344, "step": 101000}
{"episode_reward": 4.497692663030742, "episode": 102.0, "batch_reward": 0.011051670229295268, "critic_loss": 0.004256886380768265, "actor_loss": -22.107393542811273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.277594804763794, "step": 102000}
{"episode_reward": 4.8494261668895815, "episode": 103.0, "batch_reward": 0.011082154382951558, "critic_loss": 0.005565734107032767, "actor_loss": -21.986859371230008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.93912982940674, "step": 103000}
{"episode_reward": 4.517567796568789, "episode": 104.0, "batch_reward": 0.010716982903424651, "critic_loss": 0.004258354548095668, "actor_loss": -21.96455669131875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.90342903137207, "step": 104000}
{"episode_reward": 3.5267175674353535, "episode": 105.0, "batch_reward": 0.010984279284020886, "critic_loss": 0.004314784842063091, "actor_loss": -21.983300951331852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.640827655792236, "step": 105000}
{"episode_reward": 4.837104310863522, "episode": 106.0, "batch_reward": 0.01074390565068461, "critic_loss": 0.004193475501684588, "actor_loss": -21.23070804658532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.014018297195435, "step": 106000}
{"episode_reward": 3.7385579287197714, "episode": 107.0, "batch_reward": 0.010706403235904872, "critic_loss": 0.006253470863615803, "actor_loss": -21.848609068736433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.820683479309082, "step": 107000}
{"episode_reward": 4.936647758603588, "episode": 108.0, "batch_reward": 0.01055089625553228, "critic_loss": 0.0028642492368453534, "actor_loss": -21.774278066411615, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.025841236114502, "step": 108000}
{"episode_reward": 4.092135088792758, "episode": 109.0, "batch_reward": 0.010325015510432422, "critic_loss": 0.0031752524503826864, "actor_loss": -22.563591680049896, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.529651880264282, "step": 109000}
{"episode_reward": 4.918073998413084, "episode": 110.0, "batch_reward": 0.010307176262373105, "critic_loss": 0.005297774181963177, "actor_loss": -21.818208779349924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.212769031524658, "step": 110000}
{"episode_reward": 5.8554996537844985, "episode": 111.0, "batch_reward": 0.010350335342809557, "critic_loss": 0.0030287378945649834, "actor_loss": -22.951158787027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.89047312736511, "step": 111000}
{"episode_reward": 4.672115953729505, "episode": 112.0, "batch_reward": 0.010459082043031231, "critic_loss": 0.005409594894757902, "actor_loss": -21.815937834441662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.07437562942505, "step": 112000}
{"episode_reward": 4.246531858448323, "episode": 113.0, "batch_reward": 0.010132002759026364, "critic_loss": 0.0033173567370467934, "actor_loss": -21.820428918123245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.91425609588623, "step": 113000}
{"episode_reward": 3.7141094303929134, "episode": 114.0, "batch_reward": 0.010126518161967397, "critic_loss": 0.003608717114722822, "actor_loss": -22.560960633590817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.147274017333984, "step": 114000}
{"episode_reward": 5.293814726656848, "episode": 115.0, "batch_reward": 0.010215396078303456, "critic_loss": 0.004822037956102577, "actor_loss": -21.930712426647545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.87797975540161, "step": 115000}
{"episode_reward": 5.675163344882858, "episode": 116.0, "batch_reward": 0.010158849760890007, "critic_loss": 0.0034680328838294374, "actor_loss": -22.131234063088893, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.793861150741577, "step": 116000}
{"episode_reward": 6.0167532550084815, "episode": 117.0, "batch_reward": 0.010288349128095432, "critic_loss": 0.00478059410390415, "actor_loss": -21.970704224973918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.894174098968506, "step": 117000}
{"episode_reward": 6.394875661327676, "episode": 118.0, "batch_reward": 0.010291250088252128, "critic_loss": 0.004030998920163256, "actor_loss": -22.272460402414204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.372427940368652, "step": 118000}
{"episode_reward": 4.4475669766712, "episode": 119.0, "batch_reward": 0.010028231511358171, "critic_loss": 0.005473601321340538, "actor_loss": -22.438854188427328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.86103391647339, "step": 119000}
{"episode_reward": 6.570546995146315, "episode": 120.0, "batch_reward": 0.009848639079369604, "critic_loss": 0.0028533633774495684, "actor_loss": -21.439566487640143, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.745740175247192, "step": 120000}
{"episode_reward": 5.331053380999795, "episode": 121.0, "batch_reward": 0.010051119416253642, "critic_loss": 0.004385707946872572, "actor_loss": -21.747408506810665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.59019947052002, "step": 121000}
{"episode_reward": 7.061489735001675, "episode": 122.0, "batch_reward": 0.010038637537509203, "critic_loss": 0.004176763675517578, "actor_loss": -21.611045394584536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.587461233139038, "step": 122000}
{"episode_reward": 5.736073390276281, "episode": 123.0, "batch_reward": 0.009974223939236254, "critic_loss": 0.004593853376245533, "actor_loss": -20.05422282499075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23464035987854, "step": 123000}
{"episode_reward": 4.896325039515628, "episode": 124.0, "batch_reward": 0.009791018363786862, "critic_loss": 0.004603707715585188, "actor_loss": -21.5569600186795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.149628400802612, "step": 124000}
{"episode_reward": 4.230227587559224, "episode": 125.0, "batch_reward": 0.009740374719491228, "critic_loss": 0.0030608390146226157, "actor_loss": -21.680084968701006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.2473361492157, "step": 125000}
{"episode_reward": 4.264169624910242, "episode": 126.0, "batch_reward": 0.009610159986186773, "critic_loss": 0.004741634075864567, "actor_loss": -21.669216023176908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.88163995742798, "step": 126000}
{"episode_reward": 4.483660591817105, "episode": 127.0, "batch_reward": 0.00975278630410321, "critic_loss": 0.004186269264842849, "actor_loss": -21.547014786437153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.103435516357422, "step": 127000}
{"episode_reward": 4.741399118393519, "episode": 128.0, "batch_reward": 0.009618707826593891, "critic_loss": 0.003375367179243767, "actor_loss": -22.588847612500192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.76563549041748, "step": 128000}
{"episode_reward": 5.670528659043189, "episode": 129.0, "batch_reward": 0.009708210156997665, "critic_loss": 0.005016902849492908, "actor_loss": -22.654021062240005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.529987812042236, "step": 129000}
{"episode_reward": 6.233341965994861, "episode": 130.0, "batch_reward": 0.009531082341913135, "critic_loss": 0.004012643720096094, "actor_loss": -21.835626498728992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15638017654419, "step": 130000}
{"episode_reward": 4.945277215165624, "episode": 131.0, "batch_reward": 0.009650319717591628, "critic_loss": 0.00430546306008182, "actor_loss": -23.148874656394124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.72430682182312, "step": 131000}
{"episode_reward": 4.914381657058847, "episode": 132.0, "batch_reward": 0.009720710067776963, "critic_loss": 0.0028679336989516743, "actor_loss": -22.095172071814538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.47696280479431, "step": 132000}
{"episode_reward": 4.791346041017022, "episode": 133.0, "batch_reward": 0.009533345283009111, "critic_loss": 0.004249060424313939, "actor_loss": -22.336300980612634, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.86597728729248, "step": 133000}
{"episode_reward": 3.306001645000727, "episode": 134.0, "batch_reward": 0.009624485204694793, "critic_loss": 0.003229222312060301, "actor_loss": -22.45760329824686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.751431941986084, "step": 134000}
{"episode_reward": 9.178562786023791, "episode": 135.0, "batch_reward": 0.009622344128787517, "critic_loss": 0.003544432228154619, "actor_loss": -22.5732266253829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.988089084625244, "step": 135000}
{"episode_reward": 7.4801593484941185, "episode": 136.0, "batch_reward": 0.00934821017133072, "critic_loss": 0.0033330557174049316, "actor_loss": -23.370586310997606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.638282537460327, "step": 136000}
{"episode_reward": 4.1902770948160395, "episode": 137.0, "batch_reward": 0.009396005818387494, "critic_loss": 0.0035190862747476784, "actor_loss": -21.887525081574918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5827214717865, "step": 137000}
{"episode_reward": 6.1061601893911925, "episode": 138.0, "batch_reward": 0.009726757534546777, "critic_loss": 0.002522223329455301, "actor_loss": -21.41707630456984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.894367456436157, "step": 138000}
{"episode_reward": 5.910540258121608, "episode": 139.0, "batch_reward": 0.009559422756545246, "critic_loss": 0.003668085220750072, "actor_loss": -21.593276328429578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.739999771118164, "step": 139000}
{"episode_reward": 3.732236443088925, "episode": 140.0, "batch_reward": 0.009243408023612574, "critic_loss": 0.004865474229685788, "actor_loss": -21.402385220572352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.988489151000977, "step": 140000}
{"episode_reward": 6.090591689824264, "episode": 141.0, "batch_reward": 0.009313175256829708, "critic_loss": 0.0027489772281696786, "actor_loss": -21.07626554620266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.65425419807434, "step": 141000}
{"episode_reward": 3.3412682756545062, "episode": 142.0, "batch_reward": 0.00946437470964156, "critic_loss": 0.004736841929719958, "actor_loss": -21.96227392990887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.346460103988647, "step": 142000}
{"episode_reward": 4.328804928966155, "episode": 143.0, "batch_reward": 0.00934065983700566, "critic_loss": 0.0033879790478313224, "actor_loss": -22.008712952911853, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.565696001052856, "step": 143000}
{"episode_reward": 4.961330024000751, "episode": 144.0, "batch_reward": 0.009475541163468734, "critic_loss": 0.0041131213093322004, "actor_loss": -22.26183376647532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.51117753982544, "step": 144000}
{"episode_reward": 4.774322183925296, "episode": 145.0, "batch_reward": 0.009228758778888731, "critic_loss": 0.004255557959695579, "actor_loss": -21.873181948304175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.313292503356934, "step": 145000}
{"episode_reward": 3.891665901900156, "episode": 146.0, "batch_reward": 0.009179013988468796, "critic_loss": 0.0026545864071304097, "actor_loss": -21.634357039600612, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.726588010787964, "step": 146000}
{"episode_reward": 7.005016466822916, "episode": 147.0, "batch_reward": 0.00897185353632085, "critic_loss": 0.0030307610407398896, "actor_loss": -22.094570619121193, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.417484998703003, "step": 147000}
{"episode_reward": 6.094836078081035, "episode": 148.0, "batch_reward": 0.00960663200262934, "critic_loss": 0.004289985542651266, "actor_loss": -21.15981337068975, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.553030729293823, "step": 148000}
{"episode_reward": 3.9542124472175386, "episode": 149.0, "batch_reward": 0.009151395817752928, "critic_loss": 0.00381253822187864, "actor_loss": -21.689641723394395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.374056577682495, "step": 149000}
{"episode_reward": 6.382934860693185, "episode": 150.0, "batch_reward": 0.00904067694558762, "critic_loss": 0.0037920904959610198, "actor_loss": -21.631154722198843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
