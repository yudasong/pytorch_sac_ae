{"episode_reward": 0.0, "episode": 1.0, "duration": 19.188703060150146, "step": 1000}
{"episode_reward": 7.579367547095394, "episode": 2.0, "duration": 1.5329461097717285, "step": 2000}
{"episode_reward": 587.3438790414032, "episode": 3.0, "batch_reward": 0.282991270138129, "critic_loss": 0.041366765524188345, "actor_loss": -33.84392308750722, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 69.41093254089355, "step": 3000}
{"episode_reward": 36.31308565274213, "episode": 4.0, "batch_reward": 0.18700764393806457, "critic_loss": 0.05176829491741955, "actor_loss": -17.723237101152538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.085078477859497, "step": 4000}
{"episode_reward": 25.36772030512197, "episode": 5.0, "batch_reward": 0.1529376208409667, "critic_loss": 0.0697092329133302, "actor_loss": -12.454160332545639, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.80341410636902, "step": 5000}
{"episode_reward": 93.92080007413533, "episode": 6.0, "batch_reward": 0.14243961322307586, "critic_loss": 0.059985841002315285, "actor_loss": -13.998136094398797, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.496016025543213, "step": 6000}
{"episode_reward": 79.85312843969061, "episode": 7.0, "batch_reward": 0.13428968351334333, "critic_loss": 0.054619300190359356, "actor_loss": -15.606459971949459, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.426621437072754, "step": 7000}
{"episode_reward": 83.36586255056363, "episode": 8.0, "batch_reward": 0.1264391817972064, "critic_loss": 0.05426863214373589, "actor_loss": -15.950827980726958, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.80502438545227, "step": 8000}
{"episode_reward": 78.24647686553374, "episode": 9.0, "batch_reward": 0.12009390004724264, "critic_loss": 0.06407611061818898, "actor_loss": -16.673433360546827, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.7278413772583, "step": 9000}
{"episode_reward": 60.7171360290082, "episode": 10.0, "batch_reward": 0.11505700372904538, "critic_loss": 0.05534215257130563, "actor_loss": -17.6844195818007, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.910282850265503, "step": 10000}
{"episode_reward": 82.96438273327078, "episode": 11.0, "batch_reward": 0.11108969234675169, "critic_loss": 0.05207265410758555, "actor_loss": -18.834293779850007, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.096466302871704, "step": 11000}
{"episode_reward": 47.825872685241464, "episode": 12.0, "batch_reward": 0.10466294268518686, "critic_loss": 0.05597567551024258, "actor_loss": -18.48222570544481, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.230504989624023, "step": 12000}
{"episode_reward": 38.24476785333853, "episode": 13.0, "batch_reward": 0.09935034599900246, "critic_loss": 0.051723845975473526, "actor_loss": -19.25271795067191, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.51694965362549, "step": 13000}
{"episode_reward": 41.038354977770645, "episode": 14.0, "batch_reward": 0.09555425815656782, "critic_loss": 0.05989900221303105, "actor_loss": -18.80714985063672, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.89722228050232, "step": 14000}
{"episode_reward": 61.754104923289916, "episode": 15.0, "batch_reward": 0.09293623214960098, "critic_loss": 0.0499183080419898, "actor_loss": -21.81412150888145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.79154634475708, "step": 15000}
{"episode_reward": 42.729976386482996, "episode": 16.0, "batch_reward": 0.09039983155205845, "critic_loss": 0.05566764376871288, "actor_loss": -20.97969059574604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.206153869628906, "step": 16000}
{"episode_reward": 81.40169637719438, "episode": 17.0, "batch_reward": 0.09034380960464478, "critic_loss": 0.06061236339248717, "actor_loss": -20.40465135280788, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.31001091003418, "step": 17000}
{"episode_reward": 92.04125690068008, "episode": 18.0, "batch_reward": 0.09193063792586327, "critic_loss": 0.08451332164555789, "actor_loss": -21.10132110878825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.014297485351562, "step": 18000}
{"episode_reward": 113.36025144300696, "episode": 19.0, "batch_reward": 0.092082454636693, "critic_loss": 0.12743204040080308, "actor_loss": -20.89363402752578, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.43248438835144, "step": 19000}
{"episode_reward": 64.81604320425055, "episode": 20.0, "batch_reward": 0.09262418672442436, "critic_loss": 0.14117736653238536, "actor_loss": -21.654751171469687, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.04450035095215, "step": 20000}
{"episode_reward": 145.48817071572657, "episode": 21.0, "batch_reward": 0.09705916453897953, "critic_loss": 0.1619664466008544, "actor_loss": -21.96500035405159, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.85959243774414, "step": 21000}
{"episode_reward": 190.30763016886203, "episode": 22.0, "batch_reward": 0.1012532339990139, "critic_loss": 0.18269180254638195, "actor_loss": -21.572830905735493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.534735202789307, "step": 22000}
{"episode_reward": 243.58926743314433, "episode": 23.0, "batch_reward": 0.10683064567297697, "critic_loss": 0.23109591280668973, "actor_loss": -22.529397202968596, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.095086812973022, "step": 23000}
{"episode_reward": 140.57396625158324, "episode": 24.0, "batch_reward": 0.10545443930476904, "critic_loss": 0.219973544344306, "actor_loss": -22.02373927974701, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.38726258277893, "step": 24000}
{"episode_reward": 53.15102546530295, "episode": 25.0, "batch_reward": 0.10281512629985809, "critic_loss": 0.23363345967978238, "actor_loss": -20.775834512352944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.776424407958984, "step": 25000}
{"episode_reward": 29.09022310414711, "episode": 26.0, "batch_reward": 0.10162674528360367, "critic_loss": 0.2630284327045083, "actor_loss": -21.19589221405983, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.15453338623047, "step": 26000}
{"episode_reward": 119.0340021306137, "episode": 27.0, "batch_reward": 0.10232748748362064, "critic_loss": 0.2762325873672962, "actor_loss": -21.651174988746643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.009582042694092, "step": 27000}
{"episode_reward": 164.52212359771136, "episode": 28.0, "batch_reward": 0.10556898314505815, "critic_loss": 0.27454383462667464, "actor_loss": -21.56341285800934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.106626987457275, "step": 28000}
{"episode_reward": 202.57984658256962, "episode": 29.0, "batch_reward": 0.10909752000868321, "critic_loss": 0.2851568717211485, "actor_loss": -22.51235742855072, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.784218072891235, "step": 29000}
{"episode_reward": 124.01579076498702, "episode": 30.0, "batch_reward": 0.1079596209898591, "critic_loss": 0.28116954055428506, "actor_loss": -21.704428669452668, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.323492765426636, "step": 30000}
{"episode_reward": 78.63865672731025, "episode": 31.0, "batch_reward": 0.10947466737776995, "critic_loss": 0.3064026640802622, "actor_loss": -22.387746565818787, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.94106602668762, "step": 31000}
{"episode_reward": 236.93368997046252, "episode": 32.0, "batch_reward": 0.11200653766840696, "critic_loss": 0.29903515668213365, "actor_loss": -21.791866460323334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.670148849487305, "step": 32000}
{"episode_reward": 113.57256145445949, "episode": 33.0, "batch_reward": 0.11284488012641668, "critic_loss": 0.2998280830383301, "actor_loss": -22.731409433364867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.594404458999634, "step": 33000}
{"episode_reward": 217.84375284268955, "episode": 34.0, "batch_reward": 0.11527942084521055, "critic_loss": 0.3032941739857197, "actor_loss": -21.86812253522873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.11249876022339, "step": 34000}
{"episode_reward": 215.08349181699427, "episode": 35.0, "batch_reward": 0.11908689938485623, "critic_loss": 0.33421848268806936, "actor_loss": -23.0397067527771, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.695507049560547, "step": 35000}
{"episode_reward": 239.47788772107748, "episode": 36.0, "batch_reward": 0.12288348190486431, "critic_loss": 0.37475346998870374, "actor_loss": -22.31998582935333, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.553300619125366, "step": 36000}
{"episode_reward": 296.0644984159215, "episode": 37.0, "batch_reward": 0.1268125471174717, "critic_loss": 0.35081531563401225, "actor_loss": -23.43188235282898, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.516266345977783, "step": 37000}
{"episode_reward": 253.33195884608415, "episode": 38.0, "batch_reward": 0.12909924176335336, "critic_loss": 0.3752675777077675, "actor_loss": -24.017158211708068, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27906560897827, "step": 38000}
{"episode_reward": 86.1963710712885, "episode": 39.0, "batch_reward": 0.12788919100165366, "critic_loss": 0.3573211626410484, "actor_loss": -23.99730459022522, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.063931941986084, "step": 39000}
{"episode_reward": 105.45237993275462, "episode": 40.0, "batch_reward": 0.12906598168611527, "critic_loss": 0.37367763701081275, "actor_loss": -24.049619761466978, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.236274003982544, "step": 40000}
{"episode_reward": 249.44017956915732, "episode": 41.0, "batch_reward": 0.13188409448415042, "critic_loss": 0.36946174432337286, "actor_loss": -24.265732963562012, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.655327558517456, "step": 41000}
{"episode_reward": 221.98513905521781, "episode": 42.0, "batch_reward": 0.1337049274519086, "critic_loss": 0.35376278902590275, "actor_loss": -23.81213356590271, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.466312885284424, "step": 42000}
{"episode_reward": 209.94005845516364, "episode": 43.0, "batch_reward": 0.135150081820786, "critic_loss": 0.3848381884396076, "actor_loss": -24.115449729919433, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.375067234039307, "step": 43000}
{"episode_reward": 138.64000344342995, "episode": 44.0, "batch_reward": 0.1362552392780781, "critic_loss": 0.36363812723755834, "actor_loss": -23.781492171287535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.114181995391846, "step": 44000}
{"episode_reward": 296.06895903650366, "episode": 45.0, "batch_reward": 0.14047006310522556, "critic_loss": 0.3758717547357082, "actor_loss": -24.83691488170624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.546152591705322, "step": 45000}
{"episode_reward": 306.4165769202349, "episode": 46.0, "batch_reward": 0.14288467859476806, "critic_loss": 0.4154745709300041, "actor_loss": -24.56229501438141, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.724040508270264, "step": 46000}
{"episode_reward": 228.68218821683354, "episode": 47.0, "batch_reward": 0.14675834596157075, "critic_loss": 0.394591796875, "actor_loss": -25.39531244850159, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.126546144485474, "step": 47000}
{"episode_reward": 301.92659424155045, "episode": 48.0, "batch_reward": 0.1487084358856082, "critic_loss": 0.3870108127593994, "actor_loss": -24.612028817176817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.813936710357666, "step": 48000}
{"episode_reward": 268.4582545847202, "episode": 49.0, "batch_reward": 0.15075128671526908, "critic_loss": 0.3579064774811268, "actor_loss": -25.902693645477296, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.854324102401733, "step": 49000}
{"episode_reward": 160.273701153382, "episode": 50.0, "batch_reward": 0.1510024225488305, "critic_loss": 0.3607010776102543, "actor_loss": -25.920410506248473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.203185081481934, "step": 50000}
{"episode_reward": 299.15591239992557, "episode": 51.0, "batch_reward": 0.15349733129888773, "critic_loss": 0.38846052369475365, "actor_loss": -26.14408836555481, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.09871697425842, "step": 51000}
{"episode_reward": 147.09062508041112, "episode": 52.0, "batch_reward": 0.15399046245217324, "critic_loss": 0.37836110742390155, "actor_loss": -26.133885890960695, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.193102598190308, "step": 52000}
{"episode_reward": 323.5936970092558, "episode": 53.0, "batch_reward": 0.1566550350263715, "critic_loss": 0.3819735872894526, "actor_loss": -26.00485212612152, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.595787525177002, "step": 53000}
{"episode_reward": 105.86915290557918, "episode": 54.0, "batch_reward": 0.15596263625472784, "critic_loss": 0.37427402967214585, "actor_loss": -26.14030004119873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.172149658203125, "step": 54000}
{"episode_reward": 286.59714222655145, "episode": 55.0, "batch_reward": 0.15973651659488677, "critic_loss": 0.3770377088785172, "actor_loss": -26.40128841972351, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.929564476013184, "step": 55000}
{"episode_reward": 326.3639315524881, "episode": 56.0, "batch_reward": 0.16230842769891024, "critic_loss": 0.3595365242809057, "actor_loss": -26.893269840240478, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.785929441452026, "step": 56000}
{"episode_reward": 348.06205384035013, "episode": 57.0, "batch_reward": 0.16588983350992204, "critic_loss": 0.39202179113030433, "actor_loss": -26.82993800354004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.696490049362183, "step": 57000}
{"episode_reward": 338.166963000251, "episode": 58.0, "batch_reward": 0.16895952236652373, "critic_loss": 0.395545999750495, "actor_loss": -26.883605472564696, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.646074771881104, "step": 58000}
{"episode_reward": 348.6937899515002, "episode": 59.0, "batch_reward": 0.17136424557864666, "critic_loss": 0.44963479454815386, "actor_loss": -26.77407657623291, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.086031675338745, "step": 59000}
{"episode_reward": 206.1231001193748, "episode": 60.0, "batch_reward": 0.17251492469012739, "critic_loss": 0.43987301050126554, "actor_loss": -27.503512254714966, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.45109534263611, "step": 60000}
{"episode_reward": 375.8480721314905, "episode": 61.0, "batch_reward": 0.17643874894082545, "critic_loss": 0.4153041493147612, "actor_loss": -27.45543055343628, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.745001792907715, "step": 61000}
{"episode_reward": 375.98002957874655, "episode": 62.0, "batch_reward": 0.17804257479310034, "critic_loss": 0.4579717079401016, "actor_loss": -28.08429393196106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.02424168586731, "step": 62000}
{"episode_reward": 312.7630544750542, "episode": 63.0, "batch_reward": 0.18066306565701962, "critic_loss": 0.43548841489851475, "actor_loss": -27.777963960647583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.16247296333313, "step": 63000}
{"episode_reward": 374.94874030511767, "episode": 64.0, "batch_reward": 0.18446208655834198, "critic_loss": 0.4376953089237213, "actor_loss": -28.437782217025756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.422221183776855, "step": 64000}
{"episode_reward": 457.1326073084275, "episode": 65.0, "batch_reward": 0.1880553359389305, "critic_loss": 0.4303861413896084, "actor_loss": -28.67191877365112, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.505427360534668, "step": 65000}
{"episode_reward": 393.17804463768647, "episode": 66.0, "batch_reward": 0.19200269150733948, "critic_loss": 0.4452430140674114, "actor_loss": -28.993509784698485, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.058826446533203, "step": 66000}
{"episode_reward": 290.4150668271275, "episode": 67.0, "batch_reward": 0.19332075060904025, "critic_loss": 0.42654432478547094, "actor_loss": -29.298392087936403, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.847191095352173, "step": 67000}
{"episode_reward": 396.2685627632532, "episode": 68.0, "batch_reward": 0.19648860244452954, "critic_loss": 0.43837907020747663, "actor_loss": -28.812517448425293, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.168368339538574, "step": 68000}
{"episode_reward": 380.60726158116233, "episode": 69.0, "batch_reward": 0.19888361996412277, "critic_loss": 0.42335622614622115, "actor_loss": -28.930147787094118, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.25626039505005, "step": 69000}
{"episode_reward": 383.49647505059215, "episode": 70.0, "batch_reward": 0.20155238170921802, "critic_loss": 0.44705311708152295, "actor_loss": -29.98194753074646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.513800859451294, "step": 70000}
{"episode_reward": 437.35925099756037, "episode": 71.0, "batch_reward": 0.20503357146680354, "critic_loss": 0.4443532728403807, "actor_loss": -30.170336544036864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.1079957485199, "step": 71000}
{"episode_reward": 383.4545774928564, "episode": 72.0, "batch_reward": 0.20756122548878192, "critic_loss": 0.4455725572258234, "actor_loss": -30.079003896713257, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.493587493896484, "step": 72000}
{"episode_reward": 402.9193500321531, "episode": 73.0, "batch_reward": 0.21064032979309558, "critic_loss": 0.4416571116000414, "actor_loss": -30.572995943069458, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.853658199310303, "step": 73000}
{"episode_reward": 437.9269817582922, "episode": 74.0, "batch_reward": 0.21215212509036063, "critic_loss": 0.4234901469051838, "actor_loss": -30.96710651779175, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.954607009887695, "step": 74000}
{"episode_reward": 140.08568889358912, "episode": 75.0, "batch_reward": 0.21274647636711597, "critic_loss": 0.4059123351573944, "actor_loss": -30.96053678703308, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.526365995407104, "step": 75000}
{"episode_reward": 476.1049405439857, "episode": 76.0, "batch_reward": 0.21470585295557976, "critic_loss": 0.4066873475313187, "actor_loss": -31.29206748008728, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.099426746368408, "step": 76000}
{"episode_reward": 207.83850282608913, "episode": 77.0, "batch_reward": 0.21575264555215837, "critic_loss": 0.457656962454319, "actor_loss": -30.705932476043703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.755178213119507, "step": 77000}
{"episode_reward": 447.18562109374466, "episode": 78.0, "batch_reward": 0.21924178117513657, "critic_loss": 0.4444114798158407, "actor_loss": -31.339855243682862, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.169257640838623, "step": 78000}
{"episode_reward": 441.1934268616372, "episode": 79.0, "batch_reward": 0.22089464089274408, "critic_loss": 0.41216530902683735, "actor_loss": -30.669706342697143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.19941282272339, "step": 79000}
{"episode_reward": 420.462636653451, "episode": 80.0, "batch_reward": 0.22428914844989778, "critic_loss": 0.3910293221175671, "actor_loss": -31.439831644058227, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.96906018257141, "step": 80000}
{"episode_reward": 409.2852267649909, "episode": 81.0, "batch_reward": 0.22747603291273116, "critic_loss": 0.37826467557251453, "actor_loss": -32.00790351295471, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.345332622528076, "step": 81000}
{"episode_reward": 484.26919732772706, "episode": 82.0, "batch_reward": 0.23040110740065575, "critic_loss": 0.3806711032539606, "actor_loss": -32.92189709472656, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.07356333732605, "step": 82000}
{"episode_reward": 411.1637884995045, "episode": 83.0, "batch_reward": 0.23263465371727943, "critic_loss": 0.4000220731496811, "actor_loss": -31.9735884513855, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.971100330352783, "step": 83000}
{"episode_reward": 442.48065357849373, "episode": 84.0, "batch_reward": 0.23455956466495992, "critic_loss": 0.37721436700224875, "actor_loss": -32.91055773544311, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.981447458267212, "step": 84000}
{"episode_reward": 460.0647724917973, "episode": 85.0, "batch_reward": 0.2372459913790226, "critic_loss": 0.3667105447202921, "actor_loss": -32.89822674179077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.431620836257935, "step": 85000}
{"episode_reward": 461.62291593454944, "episode": 86.0, "batch_reward": 0.23939058271050453, "critic_loss": 0.35918425385653974, "actor_loss": -32.870721004486086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.79430866241455, "step": 86000}
{"episode_reward": 455.2774823456833, "episode": 87.0, "batch_reward": 0.24168622754514218, "critic_loss": 0.3696950143873692, "actor_loss": -33.01170805740357, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.658588409423828, "step": 87000}
{"episode_reward": 475.13732213221834, "episode": 88.0, "batch_reward": 0.24372288662195205, "critic_loss": 0.3982222440838814, "actor_loss": -32.6686238861084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.081986665725708, "step": 88000}
{"episode_reward": 345.10376587167195, "episode": 89.0, "batch_reward": 0.2463174962103367, "critic_loss": 0.38386197660863397, "actor_loss": -33.853319034576415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.875409841537476, "step": 89000}
{"episode_reward": 501.3612841889764, "episode": 90.0, "batch_reward": 0.24873287393152713, "critic_loss": 0.3828486999720335, "actor_loss": -34.42741286849976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.81394648551941, "step": 90000}
{"episode_reward": 504.4576941788167, "episode": 91.0, "batch_reward": 0.2517416746765375, "critic_loss": 0.39895184136927125, "actor_loss": -33.89811634445191, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.22200560569763, "step": 91000}
{"episode_reward": 492.30419481699914, "episode": 92.0, "batch_reward": 0.2546124572753906, "critic_loss": 0.38790000589191914, "actor_loss": -33.85631441497803, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.814910888671875, "step": 92000}
{"episode_reward": 462.768794894307, "episode": 93.0, "batch_reward": 0.25686738567054274, "critic_loss": 0.3709600185453892, "actor_loss": -34.13018138122558, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.719950914382935, "step": 93000}
{"episode_reward": 495.32537936421045, "episode": 94.0, "batch_reward": 0.25953759852051733, "critic_loss": 0.4028544943332672, "actor_loss": -34.420533515930174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.812167167663574, "step": 94000}
{"episode_reward": 533.1300482364177, "episode": 95.0, "batch_reward": 0.2621617428064346, "critic_loss": 0.3749429910629988, "actor_loss": -35.37189245605469, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.233916997909546, "step": 95000}
{"episode_reward": 508.41354641051674, "episode": 96.0, "batch_reward": 0.26453118747472765, "critic_loss": 0.386180630967021, "actor_loss": -35.40233223342896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.151596546173096, "step": 96000}
{"episode_reward": 505.2041720422071, "episode": 97.0, "batch_reward": 0.26685288590192796, "critic_loss": 0.3783225468844175, "actor_loss": -35.912887104034425, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.194890022277832, "step": 97000}
{"episode_reward": 480.43589917389704, "episode": 98.0, "batch_reward": 0.2697222298234701, "critic_loss": 0.37876946859061716, "actor_loss": -35.25387539672852, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.132240056991577, "step": 98000}
{"episode_reward": 501.4560335770292, "episode": 99.0, "batch_reward": 0.27208274200558663, "critic_loss": 0.36072884894907475, "actor_loss": -35.466375930786135, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.689082145690918, "step": 99000}
{"episode_reward": 508.7075449791763, "episode": 100.0, "batch_reward": 0.2753794109970331, "critic_loss": 0.3591956236064434, "actor_loss": -35.81668514251709, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.970081329345703, "step": 100000}
{"episode_reward": 478.55039365887586, "episode": 101.0, "batch_reward": 0.27637574982643126, "critic_loss": 0.3437547297328711, "actor_loss": -36.0976753578186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.71568775177002, "step": 101000}
{"episode_reward": 532.5145592698917, "episode": 102.0, "batch_reward": 0.277560789629817, "critic_loss": 0.34168649174273014, "actor_loss": -36.2848316078186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.210169553756714, "step": 102000}
{"episode_reward": 513.1285941330464, "episode": 103.0, "batch_reward": 0.27976833428442477, "critic_loss": 0.34379134164750574, "actor_loss": -36.327642921447755, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.12944984436035, "step": 103000}
{"episode_reward": 519.6014431388526, "episode": 104.0, "batch_reward": 0.28335921519994733, "critic_loss": 0.3300342803299427, "actor_loss": -36.510072048187254, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.633867979049683, "step": 104000}
{"episode_reward": 463.1973961503345, "episode": 105.0, "batch_reward": 0.285849367082119, "critic_loss": 0.3182446630448103, "actor_loss": -36.861311122894286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.005845069885254, "step": 105000}
{"episode_reward": 503.505110265987, "episode": 106.0, "batch_reward": 0.28688922479748724, "critic_loss": 0.33095710863173006, "actor_loss": -36.50810027694702, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.22051239013672, "step": 106000}
{"episode_reward": 454.98574199760276, "episode": 107.0, "batch_reward": 0.2888151726871729, "critic_loss": 0.3560380876064301, "actor_loss": -36.965233219146725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.836503505706787, "step": 107000}
{"episode_reward": 329.55437857316093, "episode": 108.0, "batch_reward": 0.28956118021905425, "critic_loss": 0.3506205099821091, "actor_loss": -36.96616942596435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.492052793502808, "step": 108000}
{"episode_reward": 540.7300588556366, "episode": 109.0, "batch_reward": 0.29142135348916054, "critic_loss": 0.3451193331629038, "actor_loss": -37.47446629333496, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.55480432510376, "step": 109000}
{"episode_reward": 520.6368270185486, "episode": 110.0, "batch_reward": 0.29349527090787886, "critic_loss": 0.35626366041600704, "actor_loss": -37.19592894744873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.485892057418823, "step": 110000}
{"episode_reward": 513.433875551131, "episode": 111.0, "batch_reward": 0.29637338833510873, "critic_loss": 0.35463423328101634, "actor_loss": -38.17596769332886, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.722527265548706, "step": 111000}
{"episode_reward": 546.648058568113, "episode": 112.0, "batch_reward": 0.2977256950139999, "critic_loss": 0.3822166792601347, "actor_loss": -37.57136140823364, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.41328263282776, "step": 112000}
{"episode_reward": 465.36182342160583, "episode": 113.0, "batch_reward": 0.29956231999397276, "critic_loss": 0.37393966130912304, "actor_loss": -37.84072724914551, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.836113929748535, "step": 113000}
{"episode_reward": 532.5250494171512, "episode": 114.0, "batch_reward": 0.3011521633118391, "critic_loss": 0.3574244641363621, "actor_loss": -38.363032329559324, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.652456283569336, "step": 114000}
{"episode_reward": 557.588037829039, "episode": 115.0, "batch_reward": 0.3034902698397636, "critic_loss": 0.37110607628524306, "actor_loss": -38.14678726959229, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.07117795944214, "step": 115000}
{"episode_reward": 470.79355319226624, "episode": 116.0, "batch_reward": 0.30562991100549697, "critic_loss": 0.3864652053266764, "actor_loss": -38.46139733123779, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.24348020553589, "step": 116000}
{"episode_reward": 558.0996799044357, "episode": 117.0, "batch_reward": 0.3071934387385845, "critic_loss": 0.37877971313893793, "actor_loss": -38.39455375289917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.00888156890869, "step": 117000}
{"episode_reward": 250.7202883387897, "episode": 118.0, "batch_reward": 0.306875172406435, "critic_loss": 0.37593655444681645, "actor_loss": -38.54081402206421, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.832165718078613, "step": 118000}
{"episode_reward": 481.4249250878326, "episode": 119.0, "batch_reward": 0.3088997351825237, "critic_loss": 0.42774520081281664, "actor_loss": -38.728418910980224, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.580963373184204, "step": 119000}
{"episode_reward": 544.3837440674862, "episode": 120.0, "batch_reward": 0.30910084655880926, "critic_loss": 0.4112842960208654, "actor_loss": -38.33575336074829, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.98111653327942, "step": 120000}
{"episode_reward": 478.7092244638418, "episode": 121.0, "batch_reward": 0.3119246991276741, "critic_loss": 0.43102896492183207, "actor_loss": -38.59079893493652, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.342444896698, "step": 121000}
{"episode_reward": 437.86760613540923, "episode": 122.0, "batch_reward": 0.3125542632341385, "critic_loss": 0.44843910267949105, "actor_loss": -38.730925033569335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.534920692443848, "step": 122000}
{"episode_reward": 536.4873193908647, "episode": 123.0, "batch_reward": 0.31572869250178337, "critic_loss": 0.42477805085480214, "actor_loss": -38.05467653274536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.111546993255615, "step": 123000}
{"episode_reward": 555.1065983757226, "episode": 124.0, "batch_reward": 0.3162919031381607, "critic_loss": 0.4576161489635706, "actor_loss": -38.99617864227295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.396065950393677, "step": 124000}
{"episode_reward": 525.2925816806692, "episode": 125.0, "batch_reward": 0.3174899045825005, "critic_loss": 0.43348589289188383, "actor_loss": -39.137310661315915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.334670305252075, "step": 125000}
{"episode_reward": 546.6349432082505, "episode": 126.0, "batch_reward": 0.3196966226696968, "critic_loss": 0.4153914151787758, "actor_loss": -39.511748504638675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.449074506759644, "step": 126000}
{"episode_reward": 538.0138518876935, "episode": 127.0, "batch_reward": 0.32207369166612626, "critic_loss": 0.4159567727446556, "actor_loss": -39.516975479125975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.209012269973755, "step": 127000}
{"episode_reward": 587.226069495483, "episode": 128.0, "batch_reward": 0.3231048363447189, "critic_loss": 0.4125774254500866, "actor_loss": -40.11219609832764, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.196309089660645, "step": 128000}
{"episode_reward": 528.3617221371592, "episode": 129.0, "batch_reward": 0.3250850231349468, "critic_loss": 0.41953430508077144, "actor_loss": -40.3687034072876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.373871326446533, "step": 129000}
{"episode_reward": 547.6014375641021, "episode": 130.0, "batch_reward": 0.3274893679916859, "critic_loss": 0.41861731971800326, "actor_loss": -40.09907402801514, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.69057297706604, "step": 130000}
{"episode_reward": 542.455299422065, "episode": 131.0, "batch_reward": 0.3289556014537811, "critic_loss": 0.43749400712549685, "actor_loss": -40.93083249664306, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.85181927680969, "step": 131000}
{"episode_reward": 493.61935603318415, "episode": 132.0, "batch_reward": 0.331172694504261, "critic_loss": 0.4390273457020521, "actor_loss": -40.43376815032959, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.654783487319946, "step": 132000}
{"episode_reward": 557.9339141166935, "episode": 133.0, "batch_reward": 0.33082043290138247, "critic_loss": 0.4285744495093822, "actor_loss": -40.62441761779785, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.674928665161133, "step": 133000}
{"episode_reward": 527.0081107040604, "episode": 134.0, "batch_reward": 0.3325750669836998, "critic_loss": 0.45399322536587716, "actor_loss": -40.81490069580078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.427850484848022, "step": 134000}
{"episode_reward": 465.0353522868001, "episode": 135.0, "batch_reward": 0.33442236605286596, "critic_loss": 0.47335216754674914, "actor_loss": -40.971567646026614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.852466821670532, "step": 135000}
{"episode_reward": 539.6484539365623, "episode": 136.0, "batch_reward": 0.33609180811047557, "critic_loss": 0.46810988907516005, "actor_loss": -41.548062923431395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.215574741363525, "step": 136000}
{"episode_reward": 580.8474255375096, "episode": 137.0, "batch_reward": 0.3366517067849636, "critic_loss": 0.45826820923388006, "actor_loss": -40.85775792694092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.10296607017517, "step": 137000}
{"episode_reward": 500.7190028134914, "episode": 138.0, "batch_reward": 0.3386065907478332, "critic_loss": 0.4855652674585581, "actor_loss": -40.81574306869507, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.592206716537476, "step": 138000}
{"episode_reward": 554.9498410438491, "episode": 139.0, "batch_reward": 0.33989583772420884, "critic_loss": 0.4746162930727005, "actor_loss": -41.02895988845825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.274402141571045, "step": 139000}
{"episode_reward": 557.3730580387956, "episode": 140.0, "batch_reward": 0.33996652337908745, "critic_loss": 0.4651793952137232, "actor_loss": -40.96271445083618, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.38976788520813, "step": 140000}
{"episode_reward": 454.81823918057825, "episode": 141.0, "batch_reward": 0.342622777402401, "critic_loss": 0.46077326814830305, "actor_loss": -41.045913589477536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.973793506622314, "step": 141000}
{"episode_reward": 528.1613941283657, "episode": 142.0, "batch_reward": 0.3438136248588562, "critic_loss": 0.46421814684569834, "actor_loss": -41.396764137268065, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.24189019203186, "step": 142000}
{"episode_reward": 594.5507233794767, "episode": 143.0, "batch_reward": 0.34602172175049783, "critic_loss": 0.4584513859152794, "actor_loss": -41.69615246582031, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.1849205493927, "step": 143000}
{"episode_reward": 525.3633969108236, "episode": 144.0, "batch_reward": 0.34748562589287757, "critic_loss": 0.45845804406702517, "actor_loss": -42.0618920173645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.25967836380005, "step": 144000}
{"episode_reward": 563.1117666893717, "episode": 145.0, "batch_reward": 0.3493571419417858, "critic_loss": 0.4553310831338167, "actor_loss": -42.04886205291748, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.868754625320435, "step": 145000}
{"episode_reward": 579.5850324503407, "episode": 146.0, "batch_reward": 0.34910572522878647, "critic_loss": 0.4581344446837902, "actor_loss": -41.79926453781128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.648906469345093, "step": 146000}
{"episode_reward": 573.2223401779805, "episode": 147.0, "batch_reward": 0.3511655834317207, "critic_loss": 0.48140311636030675, "actor_loss": -42.30091451644898, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.53039002418518, "step": 147000}
{"episode_reward": 525.9331277310341, "episode": 148.0, "batch_reward": 0.35319751837849617, "critic_loss": 0.4415551321208477, "actor_loss": -41.87058469009399, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.64096450805664, "step": 148000}
{"episode_reward": 532.559854950318, "episode": 149.0, "batch_reward": 0.35487077975273135, "critic_loss": 0.4566811458170414, "actor_loss": -42.31522045516968, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.424296140670776, "step": 149000}
{"episode_reward": 594.8643973136097, "episode": 150.0, "batch_reward": 0.3566639446020126, "critic_loss": 0.4730862680673599, "actor_loss": -42.457064445495604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
