{"episode_reward": 0.0, "episode": 1.0, "duration": 17.524763107299805, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.5137784481048584, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.2593826225208179, "critic_loss": 0.016539859226940522, "actor_loss": -19.908067704487344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.68198299407959, "step": 3000}
{"episode_reward": 6.877370728228908, "episode": 4.0, "batch_reward": 0.16188004027307035, "critic_loss": 0.017868123767198995, "actor_loss": -18.64874563932419, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.359358549118042, "step": 4000}
{"episode_reward": 4.2067925379797835, "episode": 5.0, "batch_reward": 0.12626155199855565, "critic_loss": 0.010094400625675917, "actor_loss": -17.961866009235383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.385950088500977, "step": 5000}
{"episode_reward": 2.866446122696045, "episode": 6.0, "batch_reward": 0.10370988288894295, "critic_loss": 0.017221178729785607, "actor_loss": -17.386450743198395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35236620903015, "step": 6000}
{"episode_reward": 2.6908084842483397, "episode": 7.0, "batch_reward": 0.08776890654116869, "critic_loss": 0.019586871400475502, "actor_loss": -15.97989427804947, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36684775352478, "step": 7000}
{"episode_reward": 2.9216988333588656, "episode": 8.0, "batch_reward": 0.07675256951153278, "critic_loss": 0.021135414176853374, "actor_loss": -16.885274128913878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.357787132263184, "step": 8000}
{"episode_reward": 2.7245663248883405, "episode": 9.0, "batch_reward": 0.06791775163821875, "critic_loss": 0.017560657429974525, "actor_loss": -15.77134030199051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.389036417007446, "step": 9000}
{"episode_reward": 2.847479899224834, "episode": 10.0, "batch_reward": 0.06096303669922054, "critic_loss": 0.021507322760531678, "actor_loss": -15.949012823343278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.379565954208374, "step": 10000}
{"episode_reward": 2.396129023802109, "episode": 11.0, "batch_reward": 0.05475903885997832, "critic_loss": 0.02662826313939877, "actor_loss": -14.979023046255111, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.965816020965576, "step": 11000}
{"episode_reward": 1.7384300187762922, "episode": 12.0, "batch_reward": 0.050979534433223304, "critic_loss": 0.01817258328991011, "actor_loss": -15.627284418106079, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38966965675354, "step": 12000}
{"episode_reward": 2.8140746470616227, "episode": 13.0, "batch_reward": 0.04688037837855518, "critic_loss": 0.022181816424941644, "actor_loss": -15.16565947175026, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.354338884353638, "step": 13000}
{"episode_reward": 3.5576436184342732, "episode": 14.0, "batch_reward": 0.0438435797970742, "critic_loss": 0.026791986777912825, "actor_loss": -16.149586127758027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.372708320617676, "step": 14000}
{"episode_reward": 3.094303791660663, "episode": 15.0, "batch_reward": 0.04121848001517355, "critic_loss": 0.022757443211390636, "actor_loss": -14.962260486125945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.323519229888916, "step": 15000}
{"episode_reward": 2.592504947892762, "episode": 16.0, "batch_reward": 0.03862945330329239, "critic_loss": 0.022144099226105027, "actor_loss": -14.784923908472061, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33214831352234, "step": 16000}
{"episode_reward": 3.144812302817187, "episode": 17.0, "batch_reward": 0.036004048119997606, "critic_loss": 0.018835001690778883, "actor_loss": -15.076217305660247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33247184753418, "step": 17000}
{"episode_reward": 2.4685758641911573, "episode": 18.0, "batch_reward": 0.034470491901040075, "critic_loss": 0.025598963211872616, "actor_loss": -15.730004572629928, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.343793869018555, "step": 18000}
{"episode_reward": 2.641042446240941, "episode": 19.0, "batch_reward": 0.03219042963418178, "critic_loss": 0.027019476486835628, "actor_loss": -14.549582738757133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37180185317993, "step": 19000}
{"episode_reward": 2.9802950248450997, "episode": 20.0, "batch_reward": 0.031215815741568804, "critic_loss": 0.024320665707520676, "actor_loss": -14.848174505114555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.361607313156128, "step": 20000}
{"episode_reward": 3.1569688356612917, "episode": 21.0, "batch_reward": 0.029830292404163627, "critic_loss": 0.03216355395672144, "actor_loss": -14.552781895637512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.92218518257141, "step": 21000}
{"episode_reward": 2.3304588508214787, "episode": 22.0, "batch_reward": 0.028328713577007874, "critic_loss": 0.018455344955669716, "actor_loss": -14.633916781067848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.339629411697388, "step": 22000}
{"episode_reward": 1.3125829133750844, "episode": 23.0, "batch_reward": 0.027681182332336903, "critic_loss": 0.02826902171666734, "actor_loss": -13.922535445690155, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.355735540390015, "step": 23000}
{"episode_reward": 2.54448710143971, "episode": 24.0, "batch_reward": 0.026271154986694457, "critic_loss": 0.022286594271601644, "actor_loss": -13.050107220053674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37560486793518, "step": 24000}
{"episode_reward": 1.7890825884811525, "episode": 25.0, "batch_reward": 0.024539625133154913, "critic_loss": 0.019345876729727023, "actor_loss": -14.462161107301712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31040596961975, "step": 25000}
{"episode_reward": 3.7788933247552157, "episode": 26.0, "batch_reward": 0.024262958555016666, "critic_loss": 0.022050398404389854, "actor_loss": -13.478983725905419, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.361531019210815, "step": 26000}
{"episode_reward": 1.7209282120809792, "episode": 27.0, "batch_reward": 0.023405779000837356, "critic_loss": 0.02555987853577244, "actor_loss": -13.177118404746055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.369810581207275, "step": 27000}
{"episode_reward": 3.7513909128405256, "episode": 28.0, "batch_reward": 0.022614225913072005, "critic_loss": 0.022395761500141817, "actor_loss": -14.146176433086396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.303222179412842, "step": 28000}
{"episode_reward": 3.7352150075717887, "episode": 29.0, "batch_reward": 0.022070779686793687, "critic_loss": 0.01863984284296748, "actor_loss": -13.466562637925149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.374881744384766, "step": 29000}
{"episode_reward": 2.6939518006524557, "episode": 30.0, "batch_reward": 0.02134788170689717, "critic_loss": 0.029434217248985078, "actor_loss": -13.368553116381168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.369290351867676, "step": 30000}
{"episode_reward": 3.5306734560929582, "episode": 31.0, "batch_reward": 0.021062998483888803, "critic_loss": 0.021135004547832067, "actor_loss": -14.998249366343021, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.92177963256836, "step": 31000}
{"episode_reward": 2.50283452036569, "episode": 32.0, "batch_reward": 0.020167961520841344, "critic_loss": 0.022667758522264193, "actor_loss": -13.578857260346412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34871768951416, "step": 32000}
{"episode_reward": 3.4666264459232914, "episode": 33.0, "batch_reward": 0.019183456253726035, "critic_loss": 0.027398137804382713, "actor_loss": -13.66378807157278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.331736087799072, "step": 33000}
{"episode_reward": 3.6305586015905353, "episode": 34.0, "batch_reward": 0.019348541943123566, "critic_loss": 0.026237046948415808, "actor_loss": -14.2755619199872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.359225034713745, "step": 34000}
{"episode_reward": 2.944402617194709, "episode": 35.0, "batch_reward": 0.018816595643758774, "critic_loss": 0.023579798772756476, "actor_loss": -13.514059658229352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38143539428711, "step": 35000}
{"episode_reward": 3.1127669509683775, "episode": 36.0, "batch_reward": 0.018290844225673935, "critic_loss": 0.02188248851419485, "actor_loss": -14.202434904634952, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.333352088928223, "step": 36000}
{"episode_reward": 3.2353356755291296, "episode": 37.0, "batch_reward": 0.01791627920488827, "critic_loss": 0.031895502944767944, "actor_loss": -13.448367903888226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.369561195373535, "step": 37000}
{"episode_reward": 2.042153741154845, "episode": 38.0, "batch_reward": 0.018113567881518976, "critic_loss": 0.030496155721804825, "actor_loss": -13.390532964885235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37504482269287, "step": 38000}
{"episode_reward": 4.230245572806379, "episode": 39.0, "batch_reward": 0.017381832265411505, "critic_loss": 0.030729757109074853, "actor_loss": -13.759167520403862, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.365442752838135, "step": 39000}
{"episode_reward": 3.2308203423830215, "episode": 40.0, "batch_reward": 0.016948945031734185, "critic_loss": 0.032116706873406654, "actor_loss": -14.79489826619625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.375285863876343, "step": 40000}
{"episode_reward": 2.5908396633353994, "episode": 41.0, "batch_reward": 0.016849315810482948, "critic_loss": 0.02902671545863268, "actor_loss": -13.969213849902154, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.93518304824829, "step": 41000}
{"episode_reward": 3.6695423645719796, "episode": 42.0, "batch_reward": 0.016100934722227976, "critic_loss": 0.026327436414707337, "actor_loss": -14.041044103860855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.344675064086914, "step": 42000}
{"episode_reward": 2.6447699126661854, "episode": 43.0, "batch_reward": 0.016090005378704517, "critic_loss": 0.029507193928962807, "actor_loss": -14.233772503733634, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36540961265564, "step": 43000}
{"episode_reward": 3.7479125567413716, "episode": 44.0, "batch_reward": 0.01564860977756325, "critic_loss": 0.031032321226783097, "actor_loss": -13.529065627515315, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.330878734588623, "step": 44000}
{"episode_reward": 2.085215730449176, "episode": 45.0, "batch_reward": 0.015384203655878082, "critic_loss": 0.03299350310418231, "actor_loss": -12.407657257139682, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35832929611206, "step": 45000}
{"episode_reward": 1.5719361317221443, "episode": 46.0, "batch_reward": 0.015237155159702524, "critic_loss": 0.022308612647248083, "actor_loss": -12.091429197132587, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.383766889572144, "step": 46000}
{"episode_reward": 2.2373005689660523, "episode": 47.0, "batch_reward": 0.01455353647226002, "critic_loss": 0.021804311653380863, "actor_loss": -13.754893190443516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.368322610855103, "step": 47000}
{"episode_reward": 2.822103219047709, "episode": 48.0, "batch_reward": 0.01461660461151041, "critic_loss": 0.02334304872165376, "actor_loss": -13.028451547801495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.356266736984253, "step": 48000}
{"episode_reward": 2.335715717255356, "episode": 49.0, "batch_reward": 0.014472181622171775, "critic_loss": 0.022625045696957388, "actor_loss": -13.471167022526265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36696982383728, "step": 49000}
{"episode_reward": 2.537522546119847, "episode": 50.0, "batch_reward": 0.013607491448754444, "critic_loss": 0.022194864831792074, "actor_loss": -13.145762600958347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32485032081604, "step": 50000}
{"episode_reward": 2.255963238741181, "episode": 51.0, "batch_reward": 0.013634900442673825, "critic_loss": 0.027359017552167644, "actor_loss": -13.133612569391728, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.91914987564087, "step": 51000}
{"episode_reward": 4.6855025787643765, "episode": 52.0, "batch_reward": 0.013476196447270923, "critic_loss": 0.025533700990665237, "actor_loss": -12.69979933553934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.351047039031982, "step": 52000}
{"episode_reward": 2.835330798033595, "episode": 53.0, "batch_reward": 0.01362177646229975, "critic_loss": 0.032072372852562696, "actor_loss": -14.085169624745847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37366485595703, "step": 53000}
{"episode_reward": 2.0219522011245297, "episode": 54.0, "batch_reward": 0.012699906017514877, "critic_loss": 0.028933548891436657, "actor_loss": -13.566610923171043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.380000591278076, "step": 54000}
{"episode_reward": 1.254945418122341, "episode": 55.0, "batch_reward": 0.012663797576678917, "critic_loss": 0.043233582299217234, "actor_loss": -13.607695771574974, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.360809087753296, "step": 55000}
{"episode_reward": 1.6554483595897114, "episode": 56.0, "batch_reward": 0.012728037392138503, "critic_loss": 0.025295233330019984, "actor_loss": -14.077644025653601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34858012199402, "step": 56000}
{"episode_reward": 2.0604178794721557, "episode": 57.0, "batch_reward": 0.012226361996494234, "critic_loss": 0.027177812587477094, "actor_loss": -13.581444591641427, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.373918056488037, "step": 57000}
{"episode_reward": 1.6210326611178323, "episode": 58.0, "batch_reward": 0.01204697413451504, "critic_loss": 0.03698226627867553, "actor_loss": -14.131729136824609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.318174362182617, "step": 58000}
{"episode_reward": 3.259132837602634, "episode": 59.0, "batch_reward": 0.012090337051427922, "critic_loss": 0.026769959784680396, "actor_loss": -13.999003906160594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.355297327041626, "step": 59000}
{"episode_reward": 3.1392479219435208, "episode": 60.0, "batch_reward": 0.012061918342486024, "critic_loss": 0.028946109687080026, "actor_loss": -12.94724253386259, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.389307975769043, "step": 60000}
{"episode_reward": 3.323696956208311, "episode": 61.0, "batch_reward": 0.011573489213478751, "critic_loss": 0.019954037910843908, "actor_loss": -13.420070396631957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.875351667404175, "step": 61000}
{"episode_reward": 3.1127219888995747, "episode": 62.0, "batch_reward": 0.01176820551196579, "critic_loss": 0.025425989138275328, "actor_loss": -12.096824578553438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.335419178009033, "step": 62000}
{"episode_reward": 3.31027542939145, "episode": 63.0, "batch_reward": 0.01160450186172966, "critic_loss": 0.024148284978131415, "actor_loss": -12.966057186186314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31187129020691, "step": 63000}
{"episode_reward": 2.398380924788693, "episode": 64.0, "batch_reward": 0.011394209963269532, "critic_loss": 0.039387383659013724, "actor_loss": -14.28482233068347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38133215904236, "step": 64000}
{"episode_reward": 2.3008669960346273, "episode": 65.0, "batch_reward": 0.011279106908245013, "critic_loss": 0.02751876095157786, "actor_loss": -12.843816163212061, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38524055480957, "step": 65000}
{"episode_reward": 2.9036728179568936, "episode": 66.0, "batch_reward": 0.011002438340219668, "critic_loss": 0.031142193471008797, "actor_loss": -13.35867005982995, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33209538459778, "step": 66000}
{"episode_reward": 2.6657477116801314, "episode": 67.0, "batch_reward": 0.011163480597198941, "critic_loss": 0.044838767423316314, "actor_loss": -13.059152082234622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32538151741028, "step": 67000}
{"episode_reward": 3.8486818339200726, "episode": 68.0, "batch_reward": 0.01104948817146942, "critic_loss": 0.035304320147704855, "actor_loss": -14.413824062019586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33429741859436, "step": 68000}
{"episode_reward": 3.548416832843895, "episode": 69.0, "batch_reward": 0.010933686926262454, "critic_loss": 0.033956218670660746, "actor_loss": -13.032697062313556, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.343658685684204, "step": 69000}
{"episode_reward": 3.626085055521277, "episode": 70.0, "batch_reward": 0.010838675341568887, "critic_loss": 0.03580753571762034, "actor_loss": -12.588946596503257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36915636062622, "step": 70000}
{"episode_reward": 3.177662747581601, "episode": 71.0, "batch_reward": 0.01068968371010851, "critic_loss": 0.02813080472762522, "actor_loss": -12.478074266165494, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.96560215950012, "step": 71000}
{"episode_reward": 2.669766429026437, "episode": 72.0, "batch_reward": 0.010313197009381839, "critic_loss": 0.03519532910132693, "actor_loss": -12.777791510432959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37010407447815, "step": 72000}
{"episode_reward": 3.011712268902347, "episode": 73.0, "batch_reward": 0.010371804412105121, "critic_loss": 0.028972977686171363, "actor_loss": -13.119407782554626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.487183094024658, "step": 73000}
{"episode_reward": 2.310759145087074, "episode": 74.0, "batch_reward": 0.010015928973560222, "critic_loss": 0.031534912504612295, "actor_loss": -12.981541039973497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.639292001724243, "step": 74000}
{"episode_reward": 2.515894486910077, "episode": 75.0, "batch_reward": 0.010198906904435716, "critic_loss": 0.052044585852214366, "actor_loss": -13.84512366566062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.318914890289307, "step": 75000}
{"episode_reward": 2.459316096920025, "episode": 76.0, "batch_reward": 0.010021472753956914, "critic_loss": 0.027412662987961085, "actor_loss": -14.33303150525689, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.338395595550537, "step": 76000}
{"episode_reward": 2.924643776425287, "episode": 77.0, "batch_reward": 0.010034439919050783, "critic_loss": 0.036261830957286294, "actor_loss": -13.569423852145672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.352358102798462, "step": 77000}
{"episode_reward": 2.579467068275438, "episode": 78.0, "batch_reward": 0.00960650420782622, "critic_loss": 0.034743466592073675, "actor_loss": -13.029449556082486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.371989250183105, "step": 78000}
{"episode_reward": 2.570643982169101, "episode": 79.0, "batch_reward": 0.009617827205802313, "critic_loss": 0.030458149282094383, "actor_loss": -13.564830813765527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.362252473831177, "step": 79000}
{"episode_reward": 2.42893528550841, "episode": 80.0, "batch_reward": 0.009956479545799084, "critic_loss": 0.03256769717051793, "actor_loss": -13.413609074681997, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.370108366012573, "step": 80000}
{"episode_reward": 2.1080238074226783, "episode": 81.0, "batch_reward": 0.009508346285670996, "critic_loss": 0.045957874361090945, "actor_loss": -13.619810331583023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.94312334060669, "step": 81000}
{"episode_reward": 3.562931327391165, "episode": 82.0, "batch_reward": 0.009656278022914194, "critic_loss": 0.04787619425023149, "actor_loss": -14.293353349328042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.371313333511353, "step": 82000}
{"episode_reward": 4.336853534461327, "episode": 83.0, "batch_reward": 0.009494172002421692, "critic_loss": 0.03915908520280209, "actor_loss": -12.604301999360324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3684024810791, "step": 83000}
{"episode_reward": 2.3282927748815547, "episode": 84.0, "batch_reward": 0.009381784161669203, "critic_loss": 0.05670931553236005, "actor_loss": -13.526535519301891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.327429056167603, "step": 84000}
{"episode_reward": 3.6469536760521932, "episode": 85.0, "batch_reward": 0.009233146209153347, "critic_loss": 0.05566921228727006, "actor_loss": -13.376550162166357, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.368359565734863, "step": 85000}
{"episode_reward": 4.934462291048086, "episode": 86.0, "batch_reward": 0.009503217666759156, "critic_loss": 0.0543865873305258, "actor_loss": -13.217206891357899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.337347507476807, "step": 86000}
{"episode_reward": 2.8444786983026766, "episode": 87.0, "batch_reward": 0.009549049413297326, "critic_loss": 0.13971031570230116, "actor_loss": -13.179728454321623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34452486038208, "step": 87000}
{"episode_reward": 2.802696601905922, "episode": 88.0, "batch_reward": 0.009154485533363186, "critic_loss": 0.10191776219941676, "actor_loss": -12.48989278703928, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37670588493347, "step": 88000}
{"episode_reward": 2.5956548132208135, "episode": 89.0, "batch_reward": 0.009130929330014624, "critic_loss": 0.0739375536225707, "actor_loss": -12.728546639829874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34983468055725, "step": 89000}
{"episode_reward": 2.238988982230082, "episode": 90.0, "batch_reward": 0.009037174785509706, "critic_loss": 0.04335348471181351, "actor_loss": -13.042388721168042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.371163606643677, "step": 90000}
{"episode_reward": 2.049852144939689, "episode": 91.0, "batch_reward": 0.009045322169666178, "critic_loss": 0.02447251555103867, "actor_loss": -12.808648078620434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.94399070739746, "step": 91000}
{"episode_reward": 2.445449507270073, "episode": 92.0, "batch_reward": 0.008867577719851397, "critic_loss": 0.016844089548692865, "actor_loss": -11.203627909392118, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33477258682251, "step": 92000}
{"episode_reward": 1.8441686724292834, "episode": 93.0, "batch_reward": 0.008865756155690178, "critic_loss": 0.010638208247037255, "actor_loss": -12.463851120591164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.371173620224, "step": 93000}
{"episode_reward": 3.234474252852824, "episode": 94.0, "batch_reward": 0.00891871809179429, "critic_loss": 0.008138403490949714, "actor_loss": -11.509971904456615, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.357133150100708, "step": 94000}
{"episode_reward": 2.853809672185764, "episode": 95.0, "batch_reward": 0.008887309093610383, "critic_loss": 0.005865493294746556, "actor_loss": -13.32048370590806, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.333019971847534, "step": 95000}
{"episode_reward": 2.4111797647974442, "episode": 96.0, "batch_reward": 0.008491632308578119, "critic_loss": 0.00299373884373199, "actor_loss": -11.553826880544424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36809206008911, "step": 96000}
{"episode_reward": 3.2437786174849546, "episode": 97.0, "batch_reward": 0.00852176967880223, "critic_loss": 0.003525220996067219, "actor_loss": -13.375530180633069, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36225128173828, "step": 97000}
{"episode_reward": 2.2002225268244535, "episode": 98.0, "batch_reward": 0.008789363630698063, "critic_loss": 0.0029904785444014124, "actor_loss": -13.903952585250138, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.336907148361206, "step": 98000}
{"episode_reward": 2.192766028335026, "episode": 99.0, "batch_reward": 0.008460140467388555, "critic_loss": 0.0025153325112260063, "actor_loss": -12.562243835657835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.376636505126953, "step": 99000}
{"episode_reward": 2.2707740096971114, "episode": 100.0, "batch_reward": 0.008319634302170016, "critic_loss": 0.0024538557253181354, "actor_loss": -12.1893428889215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.361000776290894, "step": 100000}
{"episode_reward": 1.4787804379505622, "episode": 101.0, "batch_reward": 0.008355543542304077, "critic_loss": 0.00315213492816838, "actor_loss": -11.995113666594028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.04434823989868, "step": 101000}
{"episode_reward": 4.538370090939931, "episode": 102.0, "batch_reward": 0.00823577088280581, "critic_loss": 0.0032135622921450704, "actor_loss": -12.94927803197503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35253381729126, "step": 102000}
{"episode_reward": 1.8531532869198801, "episode": 103.0, "batch_reward": 0.008137687571463175, "critic_loss": 0.0028437728473727475, "actor_loss": -11.93095583820343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31195831298828, "step": 103000}
{"episode_reward": 2.13803390198698, "episode": 104.0, "batch_reward": 0.008160399025888183, "critic_loss": 0.004763300989863637, "actor_loss": -13.348815823405982, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35639715194702, "step": 104000}
{"episode_reward": 2.667350160368203, "episode": 105.0, "batch_reward": 0.008108934068121016, "critic_loss": 0.005984912804298801, "actor_loss": -11.89026242697239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.364232063293457, "step": 105000}
{"episode_reward": 1.6432346591844391, "episode": 106.0, "batch_reward": 0.007812245741602965, "critic_loss": 0.007382955339817272, "actor_loss": -12.104139008522033, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.336171627044678, "step": 106000}
{"episode_reward": 3.1796808629028335, "episode": 107.0, "batch_reward": 0.007738311295863241, "critic_loss": 0.007284908732734039, "actor_loss": -12.592638514041901, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.372076988220215, "step": 107000}
{"episode_reward": 2.7888868305574674, "episode": 108.0, "batch_reward": 0.007866829228936695, "critic_loss": 0.004489698357843736, "actor_loss": -12.604863891094922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3613543510437, "step": 108000}
{"episode_reward": 2.7403084639019024, "episode": 109.0, "batch_reward": 0.008013024020707235, "critic_loss": 0.007943914742361812, "actor_loss": -13.523556900709867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.333805799484253, "step": 109000}
{"episode_reward": 2.545578576560122, "episode": 110.0, "batch_reward": 0.008028696974855847, "critic_loss": 0.00961757738578308, "actor_loss": -13.347128645122051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.386467218399048, "step": 110000}
{"episode_reward": 2.7394237381106805, "episode": 111.0, "batch_reward": 0.007654241488082334, "critic_loss": 0.009148920078259834, "actor_loss": -12.091556392520665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.946831941604614, "step": 111000}
{"episode_reward": 1.759181481530959, "episode": 112.0, "batch_reward": 0.007912032404798083, "critic_loss": 0.014995962874869291, "actor_loss": -12.241481497913599, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.344849348068237, "step": 112000}
{"episode_reward": 2.070581432557205, "episode": 113.0, "batch_reward": 0.007443985628313385, "critic_loss": 0.010597227543097687, "actor_loss": -11.536606674730777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.387969732284546, "step": 113000}
{"episode_reward": 2.5178788220678867, "episode": 114.0, "batch_reward": 0.0077135241586947815, "critic_loss": 0.01650937800639076, "actor_loss": -12.877492605894805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.345504999160767, "step": 114000}
{"episode_reward": 2.7190615592347527, "episode": 115.0, "batch_reward": 0.0075178709056926895, "critic_loss": 0.014738051866159367, "actor_loss": -14.18051375707984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35151958465576, "step": 115000}
{"episode_reward": 3.328579795007523, "episode": 116.0, "batch_reward": 0.0073386664297431705, "critic_loss": 0.01674170464871713, "actor_loss": -13.427104521274567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.370203256607056, "step": 116000}
{"episode_reward": 2.548110678638673, "episode": 117.0, "batch_reward": 0.007398425708641298, "critic_loss": 0.027052233595997677, "actor_loss": -12.702160877108573, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.333235502243042, "step": 117000}
{"episode_reward": 1.5137351001601207, "episode": 118.0, "batch_reward": 0.007421901408350095, "critic_loss": 0.018152514791669093, "actor_loss": -12.140320975124835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.336801767349243, "step": 118000}
{"episode_reward": 2.877519878890504, "episode": 119.0, "batch_reward": 0.0075421838270267475, "critic_loss": 0.022396088921581396, "actor_loss": -12.226853917658328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.372761249542236, "step": 119000}
{"episode_reward": 3.523663175863671, "episode": 120.0, "batch_reward": 0.0072393656143685805, "critic_loss": 0.01845797551104624, "actor_loss": -13.437418883532287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35070037841797, "step": 120000}
{"episode_reward": 3.146056214181059, "episode": 121.0, "batch_reward": 0.007254494653199799, "critic_loss": 0.037556941582384755, "actor_loss": -12.610598229914904, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.99821209907532, "step": 121000}
{"episode_reward": 2.3702367813257554, "episode": 122.0, "batch_reward": 0.0073325242836726826, "critic_loss": 0.03094116766094521, "actor_loss": -14.517346351593734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30980610847473, "step": 122000}
{"episode_reward": 3.1705775568168653, "episode": 123.0, "batch_reward": 0.007254262209520675, "critic_loss": 0.02091779122706066, "actor_loss": -14.936820735245943, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33399224281311, "step": 123000}
{"episode_reward": 2.4283151947442723, "episode": 124.0, "batch_reward": 0.007413807266973891, "critic_loss": 0.02530693486239761, "actor_loss": -14.046627431452274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.361131191253662, "step": 124000}
{"episode_reward": 2.9584074681557007, "episode": 125.0, "batch_reward": 0.00700316051102709, "critic_loss": 0.02289014813662652, "actor_loss": -13.333986191809178, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.443751096725464, "step": 125000}
{"episode_reward": 2.156821523176321, "episode": 126.0, "batch_reward": 0.006953307899646461, "critic_loss": 0.020393358260807872, "actor_loss": -13.097511697977781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.583922863006592, "step": 126000}
{"episode_reward": 2.3029470981518196, "episode": 127.0, "batch_reward": 0.006989369704737328, "critic_loss": 0.01764691348694032, "actor_loss": -13.698875993400812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.340937614440918, "step": 127000}
{"episode_reward": 3.0730216483456667, "episode": 128.0, "batch_reward": 0.00704747271060478, "critic_loss": 0.021007878761018218, "actor_loss": -12.826579412072897, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31294083595276, "step": 128000}
{"episode_reward": 2.007239480551754, "episode": 129.0, "batch_reward": 0.006955382243497297, "critic_loss": 0.020410854860434483, "actor_loss": -12.858631837457418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.365413904190063, "step": 129000}
{"episode_reward": 2.9776824409780733, "episode": 130.0, "batch_reward": 0.007133570328122005, "critic_loss": 0.02602709170678281, "actor_loss": -13.683918550759554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.353503704071045, "step": 130000}
{"episode_reward": 4.519344903235593, "episode": 131.0, "batch_reward": 0.007072142518707551, "critic_loss": 0.019632993713770704, "actor_loss": -11.72032471510768, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.93043899536133, "step": 131000}
{"episode_reward": 2.0242709379521586, "episode": 132.0, "batch_reward": 0.007207931263023056, "critic_loss": 0.017420872700189646, "actor_loss": -12.671579024016857, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39738178253174, "step": 132000}
{"episode_reward": 1.8970917417411175, "episode": 133.0, "batch_reward": 0.006954002879094333, "critic_loss": 0.013509969757855287, "actor_loss": -13.042877323895693, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.342581272125244, "step": 133000}
{"episode_reward": 2.4871261841847097, "episode": 134.0, "batch_reward": 0.006946200115839019, "critic_loss": 0.01613926223864837, "actor_loss": -13.033170686483384, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.367109060287476, "step": 134000}
{"episode_reward": 1.6657269994326664, "episode": 135.0, "batch_reward": 0.007156604534364306, "critic_loss": 0.02129681371850893, "actor_loss": -13.566507148265838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.400320529937744, "step": 135000}
{"episode_reward": 1.47549800283283, "episode": 136.0, "batch_reward": 0.006810174211044796, "critic_loss": 0.018586426143272546, "actor_loss": -13.687701673328876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.348682165145874, "step": 136000}
{"episode_reward": 1.7707301078653073, "episode": 137.0, "batch_reward": 0.0068643526062369346, "critic_loss": 0.03160695295523328, "actor_loss": -13.59438049352169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.353087186813354, "step": 137000}
{"episode_reward": 2.01343434482514, "episode": 138.0, "batch_reward": 0.006786841604160145, "critic_loss": 0.023826372600691682, "actor_loss": -12.590512710660697, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37839984893799, "step": 138000}
{"episode_reward": 2.749731148238427, "episode": 139.0, "batch_reward": 0.006609469668124803, "critic_loss": 0.03118415427595028, "actor_loss": -12.238471421450377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33050799369812, "step": 139000}
{"episode_reward": 2.2840728923318023, "episode": 140.0, "batch_reward": 0.0070107781853294, "critic_loss": 0.032135207434970656, "actor_loss": -11.857766279429198, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.360731840133667, "step": 140000}
{"episode_reward": 4.240652836884737, "episode": 141.0, "batch_reward": 0.006644693557173014, "critic_loss": 0.036040504917342335, "actor_loss": -13.443994965791703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.97263264656067, "step": 141000}
{"episode_reward": 2.946599866759901, "episode": 142.0, "batch_reward": 0.006657718701055274, "critic_loss": 0.03617566000000079, "actor_loss": -13.485366594254971, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.343247175216675, "step": 142000}
{"episode_reward": 2.453639990412597, "episode": 143.0, "batch_reward": 0.006708317305892706, "critic_loss": 0.04416878472440294, "actor_loss": -14.067918582379818, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35442590713501, "step": 143000}
{"episode_reward": 2.542673006941183, "episode": 144.0, "batch_reward": 0.006733260646578856, "critic_loss": 0.048128921834657376, "actor_loss": -12.855306329458951, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.372140169143677, "step": 144000}
{"episode_reward": 2.585021590380859, "episode": 145.0, "batch_reward": 0.006592384058632888, "critic_loss": 0.05600888021224819, "actor_loss": -14.364779312103988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34946060180664, "step": 145000}
{"episode_reward": 2.741496361923419, "episode": 146.0, "batch_reward": 0.006347365939873271, "critic_loss": 0.040322399292716, "actor_loss": -12.54358624562621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.361793518066406, "step": 146000}
{"episode_reward": 1.9260008662741344, "episode": 147.0, "batch_reward": 0.006629778435453772, "critic_loss": 0.060810613779154664, "actor_loss": -13.51332046547532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.343310594558716, "step": 147000}
{"episode_reward": 2.8968145011821385, "episode": 148.0, "batch_reward": 0.006408035371918231, "critic_loss": 0.051492497495084534, "actor_loss": -13.007651383042335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.356909036636353, "step": 148000}
{"episode_reward": 2.4782702537527155, "episode": 149.0, "batch_reward": 0.006474489278742112, "critic_loss": 0.06495300429013878, "actor_loss": -12.515729855120181, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.350781202316284, "step": 149000}
{"episode_reward": 2.398354273775615, "episode": 150.0, "batch_reward": 0.006318311088951305, "critic_loss": 0.058384087427606576, "actor_loss": -13.0158191537261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
