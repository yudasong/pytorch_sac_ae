{"episode_reward": 0.0, "episode": 1.0, "duration": 17.551806688308716, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.5274879932403564, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.261604830657454, "critic_loss": 0.02738336262905864, "actor_loss": -14.516375566322525, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 60.799355030059814, "step": 3000}
{"episode_reward": 34.213110741657964, "episode": 4.0, "batch_reward": 0.17928637947887183, "critic_loss": 0.01935842068027705, "actor_loss": -13.475691103696823, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06600856781006, "step": 4000}
{"episode_reward": 76.58393408044459, "episode": 5.0, "batch_reward": 0.15097692622244357, "critic_loss": 0.024557424806058405, "actor_loss": -11.486160382509231, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.064549922943115, "step": 5000}
{"episode_reward": 16.909830485756085, "episode": 6.0, "batch_reward": 0.12818525926023722, "critic_loss": 0.05867367944587022, "actor_loss": -10.372472501516341, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.084007501602173, "step": 6000}
{"episode_reward": 27.59968060540207, "episode": 7.0, "batch_reward": 0.11092193583026529, "critic_loss": 0.03239286531507969, "actor_loss": -8.71453548502922, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.085031986236572, "step": 7000}
{"episode_reward": 22.17341017528148, "episode": 8.0, "batch_reward": 0.11121968714520335, "critic_loss": 0.06435469555482268, "actor_loss": -10.131281947612763, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.058716297149658, "step": 8000}
{"episode_reward": 185.79707244981725, "episode": 9.0, "batch_reward": 0.11384151168167592, "critic_loss": 0.06345068174041808, "actor_loss": -9.786050890922546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.056262254714966, "step": 9000}
{"episode_reward": 66.50402017511868, "episode": 10.0, "batch_reward": 0.10655142118036746, "critic_loss": 0.06671366811543702, "actor_loss": -10.211328439712524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.065741777420044, "step": 10000}
{"episode_reward": 80.99663532504931, "episode": 11.0, "batch_reward": 0.10996182604879141, "critic_loss": 0.08938859986886383, "actor_loss": -9.932142632484435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.47057890892029, "step": 11000}
{"episode_reward": 158.050746303692, "episode": 12.0, "batch_reward": 0.11674032689630985, "critic_loss": 0.0952639377489686, "actor_loss": -11.47562082195282, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.049519777297974, "step": 12000}
{"episode_reward": 253.91031802123914, "episode": 13.0, "batch_reward": 0.12140270542353392, "critic_loss": 0.10296731718629598, "actor_loss": -11.9457485704422, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.071651458740234, "step": 13000}
{"episode_reward": 54.446504682473474, "episode": 14.0, "batch_reward": 0.1168534683957696, "critic_loss": 0.09452228182926774, "actor_loss": -12.246348814964295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04948329925537, "step": 14000}
{"episode_reward": 66.70458146247586, "episode": 15.0, "batch_reward": 0.118904196113348, "critic_loss": 0.11868914308771492, "actor_loss": -12.483843053817749, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.052546501159668, "step": 15000}
{"episode_reward": 271.08592941746855, "episode": 16.0, "batch_reward": 0.1250595736503601, "critic_loss": 0.12055761736258865, "actor_loss": -13.005327215194702, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06549882888794, "step": 16000}
{"episode_reward": 91.11945273222797, "episode": 17.0, "batch_reward": 0.12124067110568285, "critic_loss": 0.11630902403593063, "actor_loss": -12.733204146385193, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.024534225463867, "step": 17000}
{"episode_reward": 61.89810152103496, "episode": 18.0, "batch_reward": 0.12291062211990357, "critic_loss": 0.13021200270205735, "actor_loss": -13.344610598564149, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0419979095459, "step": 18000}
{"episode_reward": 231.37999770949668, "episode": 19.0, "batch_reward": 0.12572828596830368, "critic_loss": 0.14256137112528086, "actor_loss": -13.492258464813233, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.062341451644897, "step": 19000}
{"episode_reward": 130.18154559661332, "episode": 20.0, "batch_reward": 0.12521446826308966, "critic_loss": 0.14471755787730217, "actor_loss": -13.776384288787842, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.031250953674316, "step": 20000}
{"episode_reward": 83.40829976891298, "episode": 21.0, "batch_reward": 0.12289423537254333, "critic_loss": 0.15361095595732333, "actor_loss": -13.658809896469116, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.5177640914917, "step": 21000}
{"episode_reward": 105.71216115318393, "episode": 22.0, "batch_reward": 0.12234113456308841, "critic_loss": 0.15396548978239297, "actor_loss": -13.819109568595886, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06525468826294, "step": 22000}
{"episode_reward": 81.23433020617543, "episode": 23.0, "batch_reward": 0.12312989919632673, "critic_loss": 0.17003489423915744, "actor_loss": -13.759571434020996, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04019546508789, "step": 23000}
{"episode_reward": 153.20908039720968, "episode": 24.0, "batch_reward": 0.12230785413831473, "critic_loss": 0.197203871101141, "actor_loss": -14.090692386627197, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.449707746505737, "step": 24000}
{"episode_reward": 201.8462544844361, "episode": 25.0, "batch_reward": 0.12498131843656302, "critic_loss": 0.20569960727542638, "actor_loss": -14.869142469406128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.073649406433105, "step": 25000}
{"episode_reward": 76.60933872022288, "episode": 26.0, "batch_reward": 0.12260690547525882, "critic_loss": 0.20939341324567795, "actor_loss": -14.65829216003418, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.031981706619263, "step": 26000}
{"episode_reward": 41.583949135465566, "episode": 27.0, "batch_reward": 0.1216628212183714, "critic_loss": 0.22747952174395322, "actor_loss": -14.911946268081666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.033578634262085, "step": 27000}
{"episode_reward": 162.86883456836645, "episode": 28.0, "batch_reward": 0.12501611413806676, "critic_loss": 0.2599863782823086, "actor_loss": -15.55177158164978, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04374623298645, "step": 28000}
{"episode_reward": 242.4780210589041, "episode": 29.0, "batch_reward": 0.1277521376758814, "critic_loss": 0.30200086212158206, "actor_loss": -15.820613668441773, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0550799369812, "step": 29000}
{"episode_reward": 248.4063079297883, "episode": 30.0, "batch_reward": 0.1324664697125554, "critic_loss": 0.3204174891412258, "actor_loss": -16.604428037643434, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.069364070892334, "step": 30000}
{"episode_reward": 237.77278426575836, "episode": 31.0, "batch_reward": 0.13666130197048187, "critic_loss": 0.35015701285004613, "actor_loss": -17.260359384536745, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.551756143569946, "step": 31000}
{"episode_reward": 276.7780605390983, "episode": 32.0, "batch_reward": 0.1400163919776678, "critic_loss": 0.3524698789417744, "actor_loss": -17.564637464523315, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.033040046691895, "step": 32000}
{"episode_reward": 331.30863104913857, "episode": 33.0, "batch_reward": 0.1459994687139988, "critic_loss": 0.41711323729157446, "actor_loss": -18.44663140296936, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.058534622192383, "step": 33000}
{"episode_reward": 336.8679009186271, "episode": 34.0, "batch_reward": 0.15245508293807505, "critic_loss": 0.43321328158676625, "actor_loss": -19.252285762786865, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.069958448410034, "step": 34000}
{"episode_reward": 300.8561540256158, "episode": 35.0, "batch_reward": 0.15310706293582915, "critic_loss": 0.44144406643509865, "actor_loss": -19.245368822097777, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05290412902832, "step": 35000}
{"episode_reward": 17.74534843697832, "episode": 36.0, "batch_reward": 0.1526198853328824, "critic_loss": 0.428950743034482, "actor_loss": -19.64864412879944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04375982284546, "step": 36000}
{"episode_reward": 300.12461363554763, "episode": 37.0, "batch_reward": 0.15410135454684495, "critic_loss": 0.4170165710747242, "actor_loss": -19.733499057769777, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.100332736968994, "step": 37000}
{"episode_reward": 48.67663675291017, "episode": 38.0, "batch_reward": 0.1544160908088088, "critic_loss": 0.4337948334664106, "actor_loss": -20.08759394645691, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.042529344558716, "step": 38000}
{"episode_reward": 311.357423610424, "episode": 39.0, "batch_reward": 0.15802582809329033, "critic_loss": 0.44709033577144147, "actor_loss": -21.125657178878786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04895520210266, "step": 39000}
{"episode_reward": 289.63095738387085, "episode": 40.0, "batch_reward": 0.16123750884085894, "critic_loss": 0.4385835231691599, "actor_loss": -21.743192043304443, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.076416492462158, "step": 40000}
{"episode_reward": 192.08748506870901, "episode": 41.0, "batch_reward": 0.16195082575827838, "critic_loss": 0.4109678949415684, "actor_loss": -21.90411199951172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.53003692626953, "step": 41000}
{"episode_reward": 253.24003081259397, "episode": 42.0, "batch_reward": 0.1643668599128723, "critic_loss": 0.42523510366678235, "actor_loss": -22.123729835510254, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06168484687805, "step": 42000}
{"episode_reward": 257.87957946041075, "episode": 43.0, "batch_reward": 0.16643538630008697, "critic_loss": 0.4359516423493624, "actor_loss": -22.434794410705567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0435950756073, "step": 43000}
{"episode_reward": 290.3196593237857, "episode": 44.0, "batch_reward": 0.16686643993109465, "critic_loss": 0.4703163404017687, "actor_loss": -22.519026306152345, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.08076000213623, "step": 44000}
{"episode_reward": 54.612340097204005, "episode": 45.0, "batch_reward": 0.16593054516613484, "critic_loss": 0.4640062864273787, "actor_loss": -22.293484535217285, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.078254461288452, "step": 45000}
{"episode_reward": 121.02933479549863, "episode": 46.0, "batch_reward": 0.16381287706643344, "critic_loss": 0.4646773108989, "actor_loss": -22.195795753479004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07219886779785, "step": 46000}
{"episode_reward": 63.79510921695304, "episode": 47.0, "batch_reward": 0.16170380323380232, "critic_loss": 0.44546621111035345, "actor_loss": -22.23699050140381, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.09093165397644, "step": 47000}
{"episode_reward": 118.00930680416964, "episode": 48.0, "batch_reward": 0.16090119276195763, "critic_loss": 0.4619876662790775, "actor_loss": -22.047132007598876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.101253271102905, "step": 48000}
{"episode_reward": 88.08455000452503, "episode": 49.0, "batch_reward": 0.16136086013168097, "critic_loss": 0.4893006235212088, "actor_loss": -22.106376079559325, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.091151237487793, "step": 49000}
{"episode_reward": 266.41275444439145, "episode": 50.0, "batch_reward": 0.16062192026525735, "critic_loss": 0.4975120255053043, "actor_loss": -22.24587692642212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.17965030670166, "step": 50000}
{"episode_reward": 74.9490573071979, "episode": 51.0, "batch_reward": 0.15957499699294567, "critic_loss": 0.4985777840912342, "actor_loss": -22.158809635162353, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.67878532409668, "step": 51000}
{"episode_reward": 145.98579911529657, "episode": 52.0, "batch_reward": 0.16040962383896112, "critic_loss": 0.5323320059478283, "actor_loss": -22.16964973449707, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.053338289260864, "step": 52000}
{"episode_reward": 108.1126040912299, "episode": 53.0, "batch_reward": 0.15983872427791357, "critic_loss": 0.5534934100210667, "actor_loss": -22.409074394226074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0272216796875, "step": 53000}
{"episode_reward": 152.79610107411204, "episode": 54.0, "batch_reward": 0.15921334566920994, "critic_loss": 0.5950026309490204, "actor_loss": -22.209590637207032, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.074422359466553, "step": 54000}
{"episode_reward": 312.2388375483121, "episode": 55.0, "batch_reward": 0.16325730699300767, "critic_loss": 0.6926877587586642, "actor_loss": -22.834319332122803, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.087323427200317, "step": 55000}
{"episode_reward": 422.8527011269963, "episode": 56.0, "batch_reward": 0.16723907690495252, "critic_loss": 0.7740152110159397, "actor_loss": -23.232274349212645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.044101238250732, "step": 56000}
{"episode_reward": 187.20976259735968, "episode": 57.0, "batch_reward": 0.16837903399765491, "critic_loss": 0.7999423869550228, "actor_loss": -23.234733337402343, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07181215286255, "step": 57000}
{"episode_reward": 326.3234239300255, "episode": 58.0, "batch_reward": 0.17005767644941808, "critic_loss": 0.806683482170105, "actor_loss": -23.491723587036134, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07475709915161, "step": 58000}
{"episode_reward": 253.4259629548053, "episode": 59.0, "batch_reward": 0.17067594967782498, "critic_loss": 0.7353996336460114, "actor_loss": -23.40830248260498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05759048461914, "step": 59000}
{"episode_reward": 84.4707015111708, "episode": 60.0, "batch_reward": 0.17144587363302707, "critic_loss": 0.7977806526720523, "actor_loss": -23.399804252624513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.078269481658936, "step": 60000}
{"episode_reward": 371.5766426219412, "episode": 61.0, "batch_reward": 0.17272641099989414, "critic_loss": 0.7231584468781949, "actor_loss": -23.579023597717285, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.56594228744507, "step": 61000}
{"episode_reward": 143.83496867535385, "episode": 62.0, "batch_reward": 0.17315881411731243, "critic_loss": 0.6912937802225352, "actor_loss": -23.587786777496337, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.065147399902344, "step": 62000}
{"episode_reward": 106.77953176231117, "episode": 63.0, "batch_reward": 0.17234753669798375, "critic_loss": 0.6339648850560188, "actor_loss": -23.635573657989504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0883891582489, "step": 63000}
{"episode_reward": 201.04218580858478, "episode": 64.0, "batch_reward": 0.17272081699967384, "critic_loss": 0.6883509186506271, "actor_loss": -23.76490155029297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.043551445007324, "step": 64000}
{"episode_reward": 200.5686337112241, "episode": 65.0, "batch_reward": 0.17369967660307883, "critic_loss": 0.7081580399423838, "actor_loss": -23.736251956939697, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.08736276626587, "step": 65000}
{"episode_reward": 389.7457405168037, "episode": 66.0, "batch_reward": 0.17696240286529064, "critic_loss": 0.7493262912482023, "actor_loss": -23.92060646057129, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.086069583892822, "step": 66000}
{"episode_reward": 350.4750618510533, "episode": 67.0, "batch_reward": 0.1777277344018221, "critic_loss": 0.7338483474254608, "actor_loss": -24.125403942108154, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.048525094985962, "step": 67000}
{"episode_reward": 96.51217286096463, "episode": 68.0, "batch_reward": 0.1775049022436142, "critic_loss": 0.6954788585305214, "actor_loss": -24.056429782867433, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06350564956665, "step": 68000}
{"episode_reward": 374.36591567275747, "episode": 69.0, "batch_reward": 0.18180337169766425, "critic_loss": 0.660791973605752, "actor_loss": -24.30650559616089, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.081657886505127, "step": 69000}
{"episode_reward": 306.7254554333137, "episode": 70.0, "batch_reward": 0.18308181250095368, "critic_loss": 0.6812822299599648, "actor_loss": -24.353140560150145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.057008266448975, "step": 70000}
{"episode_reward": 368.3303761206222, "episode": 71.0, "batch_reward": 0.18597249925136566, "critic_loss": 0.690193868637085, "actor_loss": -24.642919017791748, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.49743318557739, "step": 71000}
{"episode_reward": 381.7267681014082, "episode": 72.0, "batch_reward": 0.18821396215260028, "critic_loss": 0.7701582002937793, "actor_loss": -24.719976108551027, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.068902492523193, "step": 72000}
{"episode_reward": 337.458598133323, "episode": 73.0, "batch_reward": 0.1902422353476286, "critic_loss": 0.774145746320486, "actor_loss": -24.98890280151367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.074477672576904, "step": 73000}
{"episode_reward": 241.62748575664344, "episode": 74.0, "batch_reward": 0.19112340646982193, "critic_loss": 0.6681793902814388, "actor_loss": -24.896927448272706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04002809524536, "step": 74000}
{"episode_reward": 270.2520003729914, "episode": 75.0, "batch_reward": 0.19239384600520135, "critic_loss": 0.6420538673251868, "actor_loss": -25.040557598114013, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05254888534546, "step": 75000}
{"episode_reward": 268.5601669893275, "episode": 76.0, "batch_reward": 0.19326834258437156, "critic_loss": 0.6631942872405052, "actor_loss": -25.186005867004393, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05448079109192, "step": 76000}
{"episode_reward": 399.5486219606447, "episode": 77.0, "batch_reward": 0.19618960916996003, "critic_loss": 0.6191491601765156, "actor_loss": -25.25769524383545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.035473585128784, "step": 77000}
{"episode_reward": 423.2448416057552, "episode": 78.0, "batch_reward": 0.19866482697427273, "critic_loss": 0.6032610016167164, "actor_loss": -25.425047534942628, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06180214881897, "step": 78000}
{"episode_reward": 414.0536668419564, "episode": 79.0, "batch_reward": 0.2020951006859541, "critic_loss": 0.5828566774129867, "actor_loss": -25.606880126953126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.059374809265137, "step": 79000}
{"episode_reward": 384.6401477495893, "episode": 80.0, "batch_reward": 0.20463070450723173, "critic_loss": 0.5175785715281963, "actor_loss": -25.74642050552368, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02859401702881, "step": 80000}
{"episode_reward": 350.9012678749221, "episode": 81.0, "batch_reward": 0.20635547579824925, "critic_loss": 0.49990108770132063, "actor_loss": -25.823113006591797, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.48980164527893, "step": 81000}
{"episode_reward": 385.3761237123523, "episode": 82.0, "batch_reward": 0.20794994010031223, "critic_loss": 0.5121511139720678, "actor_loss": -25.999045936584473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.051848888397217, "step": 82000}
{"episode_reward": 358.2449557166252, "episode": 83.0, "batch_reward": 0.21065843611955642, "critic_loss": 0.4904881605654955, "actor_loss": -25.785384868621826, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06445336341858, "step": 83000}
{"episode_reward": 433.29062741536706, "episode": 84.0, "batch_reward": 0.21235309453308582, "critic_loss": 0.47033316050469876, "actor_loss": -26.02252503967285, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07689142227173, "step": 84000}
{"episode_reward": 453.8022106522272, "episode": 85.0, "batch_reward": 0.2149410948306322, "critic_loss": 0.44690600503981115, "actor_loss": -26.250169845581055, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.052990198135376, "step": 85000}
{"episode_reward": 469.43099519342053, "episode": 86.0, "batch_reward": 0.2179319617897272, "critic_loss": 0.4356862456053495, "actor_loss": -26.542642810821533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.059710264205933, "step": 86000}
{"episode_reward": 325.88265778760376, "episode": 87.0, "batch_reward": 0.2197038282752037, "critic_loss": 0.4492305511236191, "actor_loss": -26.355789890289305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.083145141601562, "step": 87000}
{"episode_reward": 444.2257011898153, "episode": 88.0, "batch_reward": 0.22174735079705715, "critic_loss": 0.4514399189800024, "actor_loss": -26.49888218688965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04561471939087, "step": 88000}
{"episode_reward": 335.7642330006117, "episode": 89.0, "batch_reward": 0.2241590613126755, "critic_loss": 0.4268856312185526, "actor_loss": -26.54508596420288, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.070281267166138, "step": 89000}
{"episode_reward": 431.9806377038268, "episode": 90.0, "batch_reward": 0.22587306904792787, "critic_loss": 0.45270697279274463, "actor_loss": -26.873955085754396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.069409370422363, "step": 90000}
{"episode_reward": 451.23643359489694, "episode": 91.0, "batch_reward": 0.22807118298113346, "critic_loss": 0.42270165449380875, "actor_loss": -26.99467956161499, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.48058032989502, "step": 91000}
{"episode_reward": 412.37778812483134, "episode": 92.0, "batch_reward": 0.22977247738838197, "critic_loss": 0.4123349320590496, "actor_loss": -26.725391418457033, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.070074796676636, "step": 92000}
{"episode_reward": 342.27672785847875, "episode": 93.0, "batch_reward": 0.2314887605905533, "critic_loss": 0.4358909965902567, "actor_loss": -27.000787620544433, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.09175992012024, "step": 93000}
{"episode_reward": 489.7782777235709, "episode": 94.0, "batch_reward": 0.23507412873208522, "critic_loss": 0.3990115365087986, "actor_loss": -27.059804023742675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.056996822357178, "step": 94000}
{"episode_reward": 486.8005696922126, "episode": 95.0, "batch_reward": 0.23746387849748135, "critic_loss": 0.40499573275446893, "actor_loss": -27.46375720977783, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.03760862350464, "step": 95000}
{"episode_reward": 471.19050590734645, "episode": 96.0, "batch_reward": 0.23995349290966989, "critic_loss": 0.37932515642046927, "actor_loss": -27.5662000541687, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.084006547927856, "step": 96000}
{"episode_reward": 483.5289734972611, "episode": 97.0, "batch_reward": 0.24187156692147255, "critic_loss": 0.3635102624297142, "actor_loss": -27.998824363708497, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06518578529358, "step": 97000}
{"episode_reward": 463.07690928358653, "episode": 98.0, "batch_reward": 0.24521740782260895, "critic_loss": 0.3781591717153788, "actor_loss": -28.24683606338501, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04938769340515, "step": 98000}
{"episode_reward": 506.26072043435613, "episode": 99.0, "batch_reward": 0.24727074643969535, "critic_loss": 0.37336296737194063, "actor_loss": -28.204496074676513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07303762435913, "step": 99000}
{"episode_reward": 485.18057449087945, "episode": 100.0, "batch_reward": 0.24906482419371606, "critic_loss": 0.3614249714463949, "actor_loss": -28.190368278503417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06767177581787, "step": 100000}
{"episode_reward": 492.5856834692391, "episode": 101.0, "batch_reward": 0.2515863541960716, "critic_loss": 0.34108171504735946, "actor_loss": -28.414916984558104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.527743101119995, "step": 101000}
{"episode_reward": 414.9038390496409, "episode": 102.0, "batch_reward": 0.2524498802423477, "critic_loss": 0.3344174820333719, "actor_loss": -28.476207744598387, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.104009866714478, "step": 102000}
{"episode_reward": 405.78824180876524, "episode": 103.0, "batch_reward": 0.2549707132726908, "critic_loss": 0.3481872211098671, "actor_loss": -28.569749431610106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.057540893554688, "step": 103000}
{"episode_reward": 498.6664696926972, "episode": 104.0, "batch_reward": 0.2576234932392836, "critic_loss": 0.34853505474328994, "actor_loss": -29.073492649078368, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.058187246322632, "step": 104000}
{"episode_reward": 469.6949476433669, "episode": 105.0, "batch_reward": 0.2587460565418005, "critic_loss": 0.33706923767924307, "actor_loss": -28.856897438049316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.09087038040161, "step": 105000}
{"episode_reward": 540.9349389102919, "episode": 106.0, "batch_reward": 0.26158765847980975, "critic_loss": 0.32797086046636104, "actor_loss": -29.09667094039917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.045320510864258, "step": 106000}
{"episode_reward": 513.5236515158184, "episode": 107.0, "batch_reward": 0.2640425696372986, "critic_loss": 0.32373864942789077, "actor_loss": -29.390703784942627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.087575912475586, "step": 107000}
{"episode_reward": 284.96095242664893, "episode": 108.0, "batch_reward": 0.2645565509945154, "critic_loss": 0.3461346885710955, "actor_loss": -29.38221227645874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.084123134613037, "step": 108000}
{"episode_reward": 395.0097060968602, "episode": 109.0, "batch_reward": 0.26640080796182153, "critic_loss": 0.3562340303361416, "actor_loss": -29.789559020996094, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.055134296417236, "step": 109000}
{"episode_reward": 495.29892879262445, "episode": 110.0, "batch_reward": 0.26804069513082507, "critic_loss": 0.35440757176280024, "actor_loss": -29.76598741531372, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.079530000686646, "step": 110000}
{"episode_reward": 450.6302887811754, "episode": 111.0, "batch_reward": 0.2695653219670057, "critic_loss": 0.356906220510602, "actor_loss": -29.78484997558594, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.525033473968506, "step": 111000}
{"episode_reward": 404.3003778558402, "episode": 112.0, "batch_reward": 0.27021409590542317, "critic_loss": 0.382352950707078, "actor_loss": -29.664998401641846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.083115816116333, "step": 112000}
{"episode_reward": 333.54776887856383, "episode": 113.0, "batch_reward": 0.27253786204755304, "critic_loss": 0.386089290201664, "actor_loss": -29.778763542175295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.064253091812134, "step": 113000}
{"episode_reward": 527.8577900616124, "episode": 114.0, "batch_reward": 0.2740837062895298, "critic_loss": 0.39835441449284553, "actor_loss": -30.32119606781006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07258653640747, "step": 114000}
{"episode_reward": 552.4252824062413, "episode": 115.0, "batch_reward": 0.276467563778162, "critic_loss": 0.35234766447544097, "actor_loss": -30.519566226959228, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.072754383087158, "step": 115000}
{"episode_reward": 537.5856152981812, "episode": 116.0, "batch_reward": 0.2784857905805111, "critic_loss": 0.34904555866122244, "actor_loss": -30.66900220489502, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.044979095458984, "step": 116000}
{"episode_reward": 490.6089670070749, "episode": 117.0, "batch_reward": 0.28015979343652725, "critic_loss": 0.3467090493142605, "actor_loss": -30.83357667160034, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.08813977241516, "step": 117000}
{"episode_reward": 464.8183531063146, "episode": 118.0, "batch_reward": 0.2817072577178478, "critic_loss": 0.3583530851006508, "actor_loss": -30.654221549987792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.047706842422485, "step": 118000}
{"episode_reward": 549.0258081198822, "episode": 119.0, "batch_reward": 0.28405759486556054, "critic_loss": 0.33264776174724103, "actor_loss": -30.921188556671144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.034343719482422, "step": 119000}
{"episode_reward": 531.9282903762698, "episode": 120.0, "batch_reward": 0.2860952776223421, "critic_loss": 0.35207776102423666, "actor_loss": -31.23515127182007, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.096003770828247, "step": 120000}
{"episode_reward": 272.40347332715953, "episode": 121.0, "batch_reward": 0.28666409131884574, "critic_loss": 0.3321703310608864, "actor_loss": -31.118348278045655, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.556809186935425, "step": 121000}
{"episode_reward": 493.7837919053822, "episode": 122.0, "batch_reward": 0.28833992606401443, "critic_loss": 0.35263880859315394, "actor_loss": -31.529085456848144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.084043979644775, "step": 122000}
{"episode_reward": 534.6024065694821, "episode": 123.0, "batch_reward": 0.2891929408013821, "critic_loss": 0.33076613065600396, "actor_loss": -31.92661322402954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.055967092514038, "step": 123000}
{"episode_reward": 527.7525397825162, "episode": 124.0, "batch_reward": 0.29237514281272886, "critic_loss": 0.337838328294456, "actor_loss": -32.008605434417724, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04904055595398, "step": 124000}
{"episode_reward": 552.206747550575, "episode": 125.0, "batch_reward": 0.2943089082986116, "critic_loss": 0.333447128534317, "actor_loss": -31.69185930633545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06657385826111, "step": 125000}
{"episode_reward": 529.2328887326474, "episode": 126.0, "batch_reward": 0.2957704919874668, "critic_loss": 0.34314010247588156, "actor_loss": -31.93921717071533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.063802003860474, "step": 126000}
{"episode_reward": 557.9311611826708, "episode": 127.0, "batch_reward": 0.2970860546380281, "critic_loss": 0.349515687301755, "actor_loss": -32.24029853057861, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.407321453094482, "step": 127000}
{"episode_reward": 501.04831047646684, "episode": 128.0, "batch_reward": 0.2989107416123152, "critic_loss": 0.3551338311582804, "actor_loss": -32.0562685508728, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.062979698181152, "step": 128000}
{"episode_reward": 565.0862412179819, "episode": 129.0, "batch_reward": 0.3012243444621563, "critic_loss": 0.32892983229458334, "actor_loss": -32.433118927001956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.013229608535767, "step": 129000}
{"episode_reward": 531.0156043394376, "episode": 130.0, "batch_reward": 0.3041596357673407, "critic_loss": 0.3483153735846281, "actor_loss": -32.875114036560056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.992865562438965, "step": 130000}
{"episode_reward": 500.27971519638805, "episode": 131.0, "batch_reward": 0.3040959413200617, "critic_loss": 0.3544286250174046, "actor_loss": -32.39621760940552, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.55751347541809, "step": 131000}
{"episode_reward": 424.7633743415735, "episode": 132.0, "batch_reward": 0.30525519543886187, "critic_loss": 0.3441567039191723, "actor_loss": -32.784554916381836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.014840126037598, "step": 132000}
{"episode_reward": 545.1076798157446, "episode": 133.0, "batch_reward": 0.30613753439486024, "critic_loss": 0.32846765288710594, "actor_loss": -32.89394033050537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.056134462356567, "step": 133000}
{"episode_reward": 497.027403869495, "episode": 134.0, "batch_reward": 0.30789995174109935, "critic_loss": 0.3534048471525311, "actor_loss": -33.071758201599124, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.075342655181885, "step": 134000}
{"episode_reward": 522.5208118886927, "episode": 135.0, "batch_reward": 0.31100121796131136, "critic_loss": 0.3687341382801533, "actor_loss": -33.38606001663208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.031323432922363, "step": 135000}
{"episode_reward": 583.1927717901303, "episode": 136.0, "batch_reward": 0.3113402106612921, "critic_loss": 0.3444397452026606, "actor_loss": -33.263768547058106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06650185585022, "step": 136000}
{"episode_reward": 556.5638065155383, "episode": 137.0, "batch_reward": 0.3143356981575489, "critic_loss": 0.3432095995396376, "actor_loss": -33.79496073150635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.079916954040527, "step": 137000}
{"episode_reward": 550.4900404143503, "episode": 138.0, "batch_reward": 0.31549555200338364, "critic_loss": 0.36059256130456924, "actor_loss": -33.49922328186035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.063751935958862, "step": 138000}
{"episode_reward": 593.7812036305132, "episode": 139.0, "batch_reward": 0.3184144856929779, "critic_loss": 0.33514669424295424, "actor_loss": -33.83895516204834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.059587478637695, "step": 139000}
{"episode_reward": 421.10979128889613, "episode": 140.0, "batch_reward": 0.3189006922543049, "critic_loss": 0.3259877087175846, "actor_loss": -33.853384101867675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.032543659210205, "step": 140000}
{"episode_reward": 567.5581726175242, "episode": 141.0, "batch_reward": 0.31987631314992904, "critic_loss": 0.32265748213231565, "actor_loss": -34.108107837677004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.48829126358032, "step": 141000}
{"episode_reward": 592.1237014250048, "episode": 142.0, "batch_reward": 0.3228714482486248, "critic_loss": 0.3313171630054712, "actor_loss": -34.34353425216675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.036958932876587, "step": 142000}
{"episode_reward": 556.6035165721587, "episode": 143.0, "batch_reward": 0.3240909160971642, "critic_loss": 0.35102689564228057, "actor_loss": -34.51392461013794, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.079833030700684, "step": 143000}
{"episode_reward": 532.6542349526331, "episode": 144.0, "batch_reward": 0.32618537229299543, "critic_loss": 0.3318135086297989, "actor_loss": -34.653266529083254, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.056626796722412, "step": 144000}
{"episode_reward": 574.4502315506613, "episode": 145.0, "batch_reward": 0.3264582264125347, "critic_loss": 0.331277859762311, "actor_loss": -34.88277909469605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.060834646224976, "step": 145000}
{"episode_reward": 109.95373768922664, "episode": 146.0, "batch_reward": 0.3256335693597794, "critic_loss": 0.357590542063117, "actor_loss": -34.54063631439209, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.054453134536743, "step": 146000}
{"episode_reward": 579.2657929356448, "episode": 147.0, "batch_reward": 0.3282213504016399, "critic_loss": 0.36288187411427497, "actor_loss": -34.80570701980591, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.066802263259888, "step": 147000}
{"episode_reward": 577.507562180537, "episode": 148.0, "batch_reward": 0.32915043106675146, "critic_loss": 0.3388991655707359, "actor_loss": -35.00347262954712, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.064913988113403, "step": 148000}
{"episode_reward": 577.3455235915335, "episode": 149.0, "batch_reward": 0.3304089892506599, "critic_loss": 0.3424073623716831, "actor_loss": -35.05235964202881, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.093477964401245, "step": 149000}
{"episode_reward": 600.1274229985837, "episode": 150.0, "batch_reward": 0.3330349867641926, "critic_loss": 0.34863983681797983, "actor_loss": -35.17926681518555, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
