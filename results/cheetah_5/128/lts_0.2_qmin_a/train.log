{"episode_reward": 0.0, "episode": 1.0, "duration": 17.099376440048218, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.5047833919525146, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.26748582533933035, "critic_loss": 0.023585502025660433, "actor_loss": -10.886468074408596, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254236, "duration": 61.141889572143555, "step": 3000}
{"episode_reward": 83.69274475458994, "episode": 4.0, "batch_reward": 0.20420861449837685, "critic_loss": 0.03937609212379903, "actor_loss": -11.656292359352111, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.775604963302612, "step": 4000}
{"episode_reward": 180.0886959159955, "episode": 5.0, "batch_reward": 0.20291288015246392, "critic_loss": 0.046101544043980536, "actor_loss": -12.378481568336486, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.717795610427856, "step": 5000}
{"episode_reward": 182.69231665882324, "episode": 6.0, "batch_reward": 0.1920337249264121, "critic_loss": 0.05820762812718749, "actor_loss": -12.221643491744995, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.618210792541504, "step": 6000}
{"episode_reward": 70.32444620816827, "episode": 7.0, "batch_reward": 0.1780794554948807, "critic_loss": 0.06304108756966889, "actor_loss": -11.70982979106903, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.63751769065857, "step": 7000}
{"episode_reward": 124.29955316535151, "episode": 8.0, "batch_reward": 0.1697343084588647, "critic_loss": 0.06710601007193327, "actor_loss": -12.926517157554626, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.778542518615723, "step": 8000}
{"episode_reward": 116.39571049861149, "episode": 9.0, "batch_reward": 0.16818370590358972, "critic_loss": 0.08796394115686416, "actor_loss": -12.586835287094116, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.108718633651733, "step": 9000}
{"episode_reward": 159.74794748524184, "episode": 10.0, "batch_reward": 0.15798151960223913, "critic_loss": 0.08534702051430941, "actor_loss": -12.80479836845398, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.164560317993164, "step": 10000}
{"episode_reward": 44.04744588778604, "episode": 11.0, "batch_reward": 0.14411941005289555, "critic_loss": 0.09059932100400328, "actor_loss": -12.369342054367065, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.49367809295654, "step": 11000}
{"episode_reward": 11.42055450917355, "episode": 12.0, "batch_reward": 0.13563807072490452, "critic_loss": 0.09606663427129387, "actor_loss": -12.496936714172364, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.626027822494507, "step": 12000}
{"episode_reward": 40.96145661030526, "episode": 13.0, "batch_reward": 0.13246902649849654, "critic_loss": 0.1413172370828688, "actor_loss": -13.280921691894532, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.02456045150757, "step": 13000}
{"episode_reward": 129.62655776942216, "episode": 14.0, "batch_reward": 0.13638114946335553, "critic_loss": 0.14437590315937995, "actor_loss": -14.642902770996093, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.26466679573059, "step": 14000}
{"episode_reward": 347.5206044505892, "episode": 15.0, "batch_reward": 0.14515254870802163, "critic_loss": 0.14761989573016762, "actor_loss": -15.5376452293396, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.61480951309204, "step": 15000}
{"episode_reward": 91.75321880547409, "episode": 16.0, "batch_reward": 0.13983818820863964, "critic_loss": 0.15505686145275832, "actor_loss": -15.585464408874511, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.137761116027832, "step": 16000}
{"episode_reward": 41.62648379600621, "episode": 17.0, "batch_reward": 0.14190280039608477, "critic_loss": 0.17354641066119075, "actor_loss": -16.227224594116212, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.107045888900757, "step": 17000}
{"episode_reward": 320.6994525955592, "episode": 18.0, "batch_reward": 0.14818666078895332, "critic_loss": 0.19145935744047166, "actor_loss": -17.123760248184205, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.62532949447632, "step": 18000}
{"episode_reward": 135.7972192552291, "episode": 19.0, "batch_reward": 0.14735412733256817, "critic_loss": 0.20769668348878623, "actor_loss": -17.54141112136841, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.709125995635986, "step": 19000}
{"episode_reward": 126.38490558355407, "episode": 20.0, "batch_reward": 0.14984117440134287, "critic_loss": 0.19668494022637606, "actor_loss": -17.921478830337524, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.848934173583984, "step": 20000}
{"episode_reward": 360.0892577174906, "episode": 21.0, "batch_reward": 0.15574438589066267, "critic_loss": 0.21144404707103967, "actor_loss": -18.37992731666565, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.44121694564819, "step": 21000}
{"episode_reward": 67.44942607130594, "episode": 22.0, "batch_reward": 0.15197711428999902, "critic_loss": 0.22187374020367862, "actor_loss": -18.587901889801024, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.049802541732788, "step": 22000}
{"episode_reward": 137.81737390270908, "episode": 23.0, "batch_reward": 0.14949318651854993, "critic_loss": 0.21508654130995272, "actor_loss": -18.352907873153686, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.607696533203125, "step": 23000}
{"episode_reward": 58.397925290108944, "episode": 24.0, "batch_reward": 0.14807834516465665, "critic_loss": 0.22594407541304826, "actor_loss": -18.594441602706908, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.638679265975952, "step": 24000}
{"episode_reward": 118.10130242006858, "episode": 25.0, "batch_reward": 0.14438931447267533, "critic_loss": 0.20920248758047819, "actor_loss": -18.544764701843263, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.78468918800354, "step": 25000}
{"episode_reward": 84.5687949071695, "episode": 26.0, "batch_reward": 0.14496085607260464, "critic_loss": 0.24025826095044614, "actor_loss": -18.60973695373535, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.1802818775177, "step": 26000}
{"episode_reward": 207.231187728114, "episode": 27.0, "batch_reward": 0.1480206617861986, "critic_loss": 0.2541996760591865, "actor_loss": -18.813344638824464, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.634291648864746, "step": 27000}
{"episode_reward": 202.8939854052058, "episode": 28.0, "batch_reward": 0.14751572112739086, "critic_loss": 0.2701097415983677, "actor_loss": -18.681338872909546, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.80086898803711, "step": 28000}
{"episode_reward": 146.23856698139838, "episode": 29.0, "batch_reward": 0.15048377963155507, "critic_loss": 0.3018628943264484, "actor_loss": -18.927121688842774, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.589605569839478, "step": 29000}
{"episode_reward": 246.24535228524945, "episode": 30.0, "batch_reward": 0.15390385711193086, "critic_loss": 0.3325270259603858, "actor_loss": -19.19197264099121, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.641988277435303, "step": 30000}
{"episode_reward": 266.47526783792466, "episode": 31.0, "batch_reward": 0.15742592292279006, "critic_loss": 0.356680742457509, "actor_loss": -19.480664363861084, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.2984299659729, "step": 31000}
{"episode_reward": 278.839111076754, "episode": 32.0, "batch_reward": 0.16026877332478762, "critic_loss": 0.3791864947974682, "actor_loss": -19.618988704681396, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.86935043334961, "step": 32000}
{"episode_reward": 169.17371311228504, "episode": 33.0, "batch_reward": 0.15873904254287483, "critic_loss": 0.40349344176054003, "actor_loss": -19.452920566558838, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.364049673080444, "step": 33000}
{"episode_reward": 97.2544628701211, "episode": 34.0, "batch_reward": 0.159744313493371, "critic_loss": 0.3796263021156192, "actor_loss": -19.473200227737426, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.888000011444092, "step": 34000}
{"episode_reward": 176.91546131930727, "episode": 35.0, "batch_reward": 0.16085967780649663, "critic_loss": 0.40962808156013486, "actor_loss": -19.576928661346436, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.66934108734131, "step": 35000}
{"episode_reward": 324.61443815809963, "episode": 36.0, "batch_reward": 0.16480508882552386, "critic_loss": 0.44665908768773077, "actor_loss": -19.997267841339113, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.683078289031982, "step": 36000}
{"episode_reward": 181.49803541156254, "episode": 37.0, "batch_reward": 0.1632007745951414, "critic_loss": 0.4114838733077049, "actor_loss": -19.79621394920349, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.39274764060974, "step": 37000}
{"episode_reward": 90.33980043031418, "episode": 38.0, "batch_reward": 0.16507130821049212, "critic_loss": 0.4459326341152191, "actor_loss": -19.955082132339477, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.637047290802002, "step": 38000}
{"episode_reward": 357.1990363400597, "episode": 39.0, "batch_reward": 0.1666996448263526, "critic_loss": 0.4628766643553972, "actor_loss": -20.04985502624512, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.647869110107422, "step": 39000}
{"episode_reward": 141.45768386176547, "episode": 40.0, "batch_reward": 0.16839553018659353, "critic_loss": 0.4894865868240595, "actor_loss": -20.290923202514648, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.8408944606781, "step": 40000}
{"episode_reward": 366.5997911495682, "episode": 41.0, "batch_reward": 0.171162822753191, "critic_loss": 0.515428582072258, "actor_loss": -20.574631549835207, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.54823970794678, "step": 41000}
{"episode_reward": 216.56102721928647, "episode": 42.0, "batch_reward": 0.17090389228612185, "critic_loss": 0.5195656094700098, "actor_loss": -20.51974768066406, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.99891424179077, "step": 42000}
{"episode_reward": 68.63322361745503, "episode": 43.0, "batch_reward": 0.1700569452047348, "critic_loss": 0.5066326212733984, "actor_loss": -20.475422134399412, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.07479763031006, "step": 43000}
{"episode_reward": 301.95440389033723, "episode": 44.0, "batch_reward": 0.17295960503071547, "critic_loss": 0.5371871673613786, "actor_loss": -20.817523712158202, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.060544729232788, "step": 44000}
{"episode_reward": 96.66166572713469, "episode": 45.0, "batch_reward": 0.17277549947053195, "critic_loss": 0.5761148179620504, "actor_loss": -20.669554553985595, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.013185262680054, "step": 45000}
{"episode_reward": 208.99366039602796, "episode": 46.0, "batch_reward": 0.17268933684378862, "critic_loss": 0.5649942139238119, "actor_loss": -20.69131111526489, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.357769012451172, "step": 46000}
{"episode_reward": 172.74093776473478, "episode": 47.0, "batch_reward": 0.17351598613709213, "critic_loss": 0.553585355013609, "actor_loss": -20.888032180786134, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.627054929733276, "step": 47000}
{"episode_reward": 282.959886366275, "episode": 48.0, "batch_reward": 0.1741291548460722, "critic_loss": 0.5880029570609331, "actor_loss": -20.86367289352417, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.058303117752075, "step": 48000}
{"episode_reward": 109.48016385332942, "episode": 49.0, "batch_reward": 0.17512788280844688, "critic_loss": 0.6440044039040804, "actor_loss": -21.005568893432617, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.31261897087097, "step": 49000}
{"episode_reward": 229.3824329771344, "episode": 50.0, "batch_reward": 0.17302965015918018, "critic_loss": 0.667785313859582, "actor_loss": -20.816696601867676, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.61610770225525, "step": 50000}
{"episode_reward": 63.77546148179232, "episode": 51.0, "batch_reward": 0.17324367743730545, "critic_loss": 0.6807378062307835, "actor_loss": -20.955805278778076, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.77400755882263, "step": 51000}
{"episode_reward": 360.78029129784056, "episode": 52.0, "batch_reward": 0.17643250884115697, "critic_loss": 0.6987591211646795, "actor_loss": -21.243495323181154, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.894070148468018, "step": 52000}
{"episode_reward": 151.54533569530903, "episode": 53.0, "batch_reward": 0.17595969165861608, "critic_loss": 0.6885527726709842, "actor_loss": -21.233050479888917, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.435803413391113, "step": 53000}
{"episode_reward": 136.87261633381652, "episode": 54.0, "batch_reward": 0.17416054163128136, "critic_loss": 0.6944556454122066, "actor_loss": -21.050034812927247, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.98120427131653, "step": 54000}
{"episode_reward": 91.47668368530883, "episode": 55.0, "batch_reward": 0.17331178389489652, "critic_loss": 0.6502549293041229, "actor_loss": -21.00770997619629, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.653116464614868, "step": 55000}
{"episode_reward": 64.6328708707011, "episode": 56.0, "batch_reward": 0.17067510305345057, "critic_loss": 0.619584944665432, "actor_loss": -21.017165538787843, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.67262029647827, "step": 56000}
{"episode_reward": 14.03207761642733, "episode": 57.0, "batch_reward": 0.16961767387390136, "critic_loss": 0.6740726317018271, "actor_loss": -20.812509651184083, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.025119304656982, "step": 57000}
{"episode_reward": 267.07883753720336, "episode": 58.0, "batch_reward": 0.16971759600937367, "critic_loss": 0.6450042300671339, "actor_loss": -20.82250662612915, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.671260118484497, "step": 58000}
{"episode_reward": 156.4255575033606, "episode": 59.0, "batch_reward": 0.1714129818379879, "critic_loss": 0.5932370475828648, "actor_loss": -20.956273963928222, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.363754510879517, "step": 59000}
{"episode_reward": 389.37281277917873, "episode": 60.0, "batch_reward": 0.17294444897025824, "critic_loss": 0.5534554266482592, "actor_loss": -21.023258686065674, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.139138221740723, "step": 60000}
{"episode_reward": 143.13420478262904, "episode": 61.0, "batch_reward": 0.1744257995635271, "critic_loss": 0.5496010862141848, "actor_loss": -21.31783046722412, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.25247764587402, "step": 61000}
{"episode_reward": 242.48889760828283, "episode": 62.0, "batch_reward": 0.17517311131954194, "critic_loss": 0.5463107788264752, "actor_loss": -21.456099210739136, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.001616716384888, "step": 62000}
{"episode_reward": 343.89012374706584, "episode": 63.0, "batch_reward": 0.1780939952582121, "critic_loss": 0.5736161286830902, "actor_loss": -21.569089260101318, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.886126279830933, "step": 63000}
{"episode_reward": 258.6352754245663, "episode": 64.0, "batch_reward": 0.17757870897650718, "critic_loss": 0.5689339522719383, "actor_loss": -21.501238582611084, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.97601819038391, "step": 64000}
{"episode_reward": 83.25294561622759, "episode": 65.0, "batch_reward": 0.17669432607293128, "critic_loss": 0.5702173222154379, "actor_loss": -21.460625186920165, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.880040645599365, "step": 65000}
{"episode_reward": 100.7174805532852, "episode": 66.0, "batch_reward": 0.1757694602161646, "critic_loss": 0.5568400568366051, "actor_loss": -21.23339412498474, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.777057647705078, "step": 66000}
{"episode_reward": 151.56140421008632, "episode": 67.0, "batch_reward": 0.17567262314260007, "critic_loss": 0.560938688993454, "actor_loss": -21.14374645614624, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.814656257629395, "step": 67000}
{"episode_reward": 205.77927633152427, "episode": 68.0, "batch_reward": 0.1764462338536978, "critic_loss": 0.5444595724791288, "actor_loss": -21.20288877105713, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.094011783599854, "step": 68000}
{"episode_reward": 152.48572647640808, "episode": 69.0, "batch_reward": 0.1749225597679615, "critic_loss": 0.5288041960597039, "actor_loss": -20.917991958618163, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.116665601730347, "step": 69000}
{"episode_reward": 147.4559660558808, "episode": 70.0, "batch_reward": 0.17508578050136567, "critic_loss": 0.530684962362051, "actor_loss": -20.937410839080812, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.63043713569641, "step": 70000}
{"episode_reward": 108.70803404052575, "episode": 71.0, "batch_reward": 0.17390376353263856, "critic_loss": 0.5242435055226088, "actor_loss": -20.7997887840271, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.28464484214783, "step": 71000}
{"episode_reward": 86.27807716097627, "episode": 72.0, "batch_reward": 0.17332932251691818, "critic_loss": 0.5581082311719656, "actor_loss": -20.553806205749513, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.644821166992188, "step": 72000}
{"episode_reward": 161.33116951499244, "episode": 73.0, "batch_reward": 0.17379943135380746, "critic_loss": 0.5347728474587202, "actor_loss": -20.656887855529785, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.965842485427856, "step": 73000}
{"episode_reward": 425.69251691905, "episode": 74.0, "batch_reward": 0.17623004618287086, "critic_loss": 0.5041274700164795, "actor_loss": -20.870830087661744, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.09068274497986, "step": 74000}
{"episode_reward": 209.36872421011125, "episode": 75.0, "batch_reward": 0.1773389931321144, "critic_loss": 0.4999766607284546, "actor_loss": -20.891100467681884, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.070959329605103, "step": 75000}
{"episode_reward": 274.6304293180404, "episode": 76.0, "batch_reward": 0.17757981210947038, "critic_loss": 0.5463939158022404, "actor_loss": -20.79606960296631, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.601123332977295, "step": 76000}
{"episode_reward": 127.36744402310302, "episode": 77.0, "batch_reward": 0.17685550253093243, "critic_loss": 0.49924554185569286, "actor_loss": -20.74179499053955, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.714840412139893, "step": 77000}
{"episode_reward": 91.17580476658462, "episode": 78.0, "batch_reward": 0.1762003449499607, "critic_loss": 0.5550892996490002, "actor_loss": -20.4212829284668, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.029478073120117, "step": 78000}
{"episode_reward": 138.96385967870876, "episode": 79.0, "batch_reward": 0.1767049627378583, "critic_loss": 0.5302883199453354, "actor_loss": -20.42045545578003, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.622430086135864, "step": 79000}
{"episode_reward": 301.95362667652904, "episode": 80.0, "batch_reward": 0.17753852407634257, "critic_loss": 0.5347730483859777, "actor_loss": -20.500891639709472, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.946903705596924, "step": 80000}
{"episode_reward": 138.3852279235009, "episode": 81.0, "batch_reward": 0.17798727244138718, "critic_loss": 0.5307157407253981, "actor_loss": -20.585592685699464, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.108553886413574, "step": 81000}
{"episode_reward": 301.69800713607094, "episode": 82.0, "batch_reward": 0.17830195516347885, "critic_loss": 0.5554995613396168, "actor_loss": -20.491371925354002, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.646345615386963, "step": 82000}
{"episode_reward": 123.19691016454836, "episode": 83.0, "batch_reward": 0.17721882236748934, "critic_loss": 0.5108846011608839, "actor_loss": -20.333992547988892, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.019444227218628, "step": 83000}
{"episode_reward": 186.36705867710359, "episode": 84.0, "batch_reward": 0.177089967250824, "critic_loss": 0.5337730888426304, "actor_loss": -20.285428895950318, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.18516778945923, "step": 84000}
{"episode_reward": 114.2209717951563, "episode": 85.0, "batch_reward": 0.17717407593131065, "critic_loss": 0.5543763393908739, "actor_loss": -20.080837656021117, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.682249307632446, "step": 85000}
{"episode_reward": 192.4473345375166, "episode": 86.0, "batch_reward": 0.17699557788670062, "critic_loss": 0.5454357202053071, "actor_loss": -20.151649116516115, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.81703233718872, "step": 86000}
{"episode_reward": 91.86069353710194, "episode": 87.0, "batch_reward": 0.17726206733286382, "critic_loss": 0.6233550744950771, "actor_loss": -20.101090579986572, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.760664224624634, "step": 87000}
{"episode_reward": 262.2050991305653, "episode": 88.0, "batch_reward": 0.17675649158656598, "critic_loss": 0.5818167610019446, "actor_loss": -19.923037315368653, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.839918613433838, "step": 88000}
{"episode_reward": 351.9640424632565, "episode": 89.0, "batch_reward": 0.17924894504249095, "critic_loss": 0.6214638798087835, "actor_loss": -20.224606025695802, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.82667827606201, "step": 89000}
{"episode_reward": 165.61089830477948, "episode": 90.0, "batch_reward": 0.1781465474665165, "critic_loss": 0.5741246909499168, "actor_loss": -20.09892483139038, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.158063411712646, "step": 90000}
{"episode_reward": 125.29657678619829, "episode": 91.0, "batch_reward": 0.17771939833462239, "critic_loss": 0.5402168915420771, "actor_loss": -19.81605580711365, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.93829941749573, "step": 91000}
{"episode_reward": 208.66395683802227, "episode": 92.0, "batch_reward": 0.17982140332460403, "critic_loss": 0.5402865783721209, "actor_loss": -20.001188760757447, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.85613465309143, "step": 92000}
{"episode_reward": 489.9856720049757, "episode": 93.0, "batch_reward": 0.18204882517457008, "critic_loss": 0.49765251080691814, "actor_loss": -20.07782177734375, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.5082368850708, "step": 93000}
{"episode_reward": 256.3929048653343, "episode": 94.0, "batch_reward": 0.1834245988726616, "critic_loss": 0.5342687722295523, "actor_loss": -20.159389776229858, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.6712589263916, "step": 94000}
{"episode_reward": 164.97877326899803, "episode": 95.0, "batch_reward": 0.18324348102509974, "critic_loss": 0.47933786614239215, "actor_loss": -20.151850122451783, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.509880781173706, "step": 95000}
{"episode_reward": 464.65045563900367, "episode": 96.0, "batch_reward": 0.18712437343597413, "critic_loss": 0.5014111639410257, "actor_loss": -20.37621975517273, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.164051294326782, "step": 96000}
{"episode_reward": 451.7407191535214, "episode": 97.0, "batch_reward": 0.187028666138649, "critic_loss": 0.5501289130598307, "actor_loss": -20.492742568969728, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.810991048812866, "step": 97000}
{"episode_reward": 76.21894524994048, "episode": 98.0, "batch_reward": 0.18653211914002896, "critic_loss": 0.4925628802925348, "actor_loss": -20.609343940734863, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.23246717453003, "step": 98000}
{"episode_reward": 87.22375997941153, "episode": 99.0, "batch_reward": 0.18674375069141388, "critic_loss": 0.5137548074871302, "actor_loss": -20.385650115966797, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.936232566833496, "step": 99000}
{"episode_reward": 274.59009530363085, "episode": 100.0, "batch_reward": 0.18742647433280946, "critic_loss": 0.5088258526921272, "actor_loss": -20.203556890487672, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.74781370162964, "step": 100000}
{"episode_reward": 206.8334142149385, "episode": 101.0, "batch_reward": 0.18869081212580205, "critic_loss": 0.49237551108002664, "actor_loss": -20.361059251785278, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.42266035079956, "step": 101000}
{"episode_reward": 469.432056316526, "episode": 102.0, "batch_reward": 0.18976889444887637, "critic_loss": 0.49943945613503454, "actor_loss": -20.62818613052368, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.27524471282959, "step": 102000}
{"episode_reward": 139.11298316596074, "episode": 103.0, "batch_reward": 0.18994189600646497, "critic_loss": 0.44430054458975793, "actor_loss": -20.435652980804445, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.75534987449646, "step": 103000}
{"episode_reward": 202.72220027743546, "episode": 104.0, "batch_reward": 0.1905995873361826, "critic_loss": 0.47156217317283156, "actor_loss": -20.618666746139528, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.129998922348022, "step": 104000}
{"episode_reward": 179.79544098049288, "episode": 105.0, "batch_reward": 0.1897773935943842, "critic_loss": 0.4886052119880915, "actor_loss": -20.422415447235107, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.50049591064453, "step": 105000}
{"episode_reward": 116.13840707705832, "episode": 106.0, "batch_reward": 0.18953145790100098, "critic_loss": 0.4582683836370707, "actor_loss": -20.462529592514038, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.653248071670532, "step": 106000}
{"episode_reward": 442.0521141901952, "episode": 107.0, "batch_reward": 0.19124756854772568, "critic_loss": 0.48845879866182806, "actor_loss": -20.606547037124635, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.10121488571167, "step": 107000}
{"episode_reward": 446.0929697812184, "episode": 108.0, "batch_reward": 0.19482598501443862, "critic_loss": 0.5026117569506169, "actor_loss": -20.916794750213622, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.690335035324097, "step": 108000}
{"episode_reward": 438.9347397159022, "episode": 109.0, "batch_reward": 0.19605063737928868, "critic_loss": 0.4222768026739359, "actor_loss": -21.12388546562195, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.599352836608887, "step": 109000}
{"episode_reward": 287.69095906394386, "episode": 110.0, "batch_reward": 0.19734313188493252, "critic_loss": 0.4304932286143303, "actor_loss": -21.119036241531372, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.002797603607178, "step": 110000}
{"episode_reward": 140.57518747840643, "episode": 111.0, "batch_reward": 0.19813265711069106, "critic_loss": 0.43889429554343223, "actor_loss": -20.988450714111327, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.41444730758667, "step": 111000}
{"episode_reward": 541.0802167317598, "episode": 112.0, "batch_reward": 0.19988746730983256, "critic_loss": 0.45026782308518887, "actor_loss": -21.090016830444338, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.369678735733032, "step": 112000}
{"episode_reward": 294.9970539790023, "episode": 113.0, "batch_reward": 0.2012876895815134, "critic_loss": 0.4676554907113314, "actor_loss": -21.207499771118165, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.91645884513855, "step": 113000}
{"episode_reward": 498.54053876990525, "episode": 114.0, "batch_reward": 0.2018436622172594, "critic_loss": 0.4234302053898573, "actor_loss": -21.403360763549806, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.657602310180664, "step": 114000}
{"episode_reward": 77.53194723398762, "episode": 115.0, "batch_reward": 0.20343316900730132, "critic_loss": 0.4163681213259697, "actor_loss": -21.423212551116944, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.229610204696655, "step": 115000}
{"episode_reward": 472.5847689093547, "episode": 116.0, "batch_reward": 0.2051690899133682, "critic_loss": 0.4319277546405792, "actor_loss": -21.663805015563966, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.964946031570435, "step": 116000}
{"episode_reward": 557.1677000475158, "episode": 117.0, "batch_reward": 0.20783934950828553, "critic_loss": 0.426777808368206, "actor_loss": -21.803466415405275, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.649036645889282, "step": 117000}
{"episode_reward": 415.7270987370058, "episode": 118.0, "batch_reward": 0.20910029284656048, "critic_loss": 0.434599215015769, "actor_loss": -21.959746887207032, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.877690315246582, "step": 118000}
{"episode_reward": 169.08102757341516, "episode": 119.0, "batch_reward": 0.20889409990608693, "critic_loss": 0.41424058260023594, "actor_loss": -21.771342807769777, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.041308879852295, "step": 119000}
{"episode_reward": 473.71255322633476, "episode": 120.0, "batch_reward": 0.21086813899874687, "critic_loss": 0.4285426956564188, "actor_loss": -22.039885719299317, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.74616312980652, "step": 120000}
{"episode_reward": 400.18949589846477, "episode": 121.0, "batch_reward": 0.21363218574225903, "critic_loss": 0.42014056858420373, "actor_loss": -22.16775259780884, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.40116000175476, "step": 121000}
{"episode_reward": 503.63921109817636, "episode": 122.0, "batch_reward": 0.2159373796582222, "critic_loss": 0.41647816862165926, "actor_loss": -22.36865230178833, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.59780192375183, "step": 122000}
{"episode_reward": 325.4767776557687, "episode": 123.0, "batch_reward": 0.2156316212117672, "critic_loss": 0.41796603851020336, "actor_loss": -22.599486938476563, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.639288902282715, "step": 123000}
{"episode_reward": 321.1541688161953, "episode": 124.0, "batch_reward": 0.21707233349978924, "critic_loss": 0.3968226829022169, "actor_loss": -22.586654529571533, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.042583465576172, "step": 124000}
{"episode_reward": 335.0385471110449, "episode": 125.0, "batch_reward": 0.21855739925801754, "critic_loss": 0.38219250552356243, "actor_loss": -22.314491737365724, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.41297459602356, "step": 125000}
{"episode_reward": 479.4976181832151, "episode": 126.0, "batch_reward": 0.2204220093637705, "critic_loss": 0.41495654311031105, "actor_loss": -22.634936794281007, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.807621717453003, "step": 126000}
{"episode_reward": 530.1273458772627, "episode": 127.0, "batch_reward": 0.22368871815502644, "critic_loss": 0.39818151442706584, "actor_loss": -22.905039615631104, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.879196166992188, "step": 127000}
{"episode_reward": 588.575094342273, "episode": 128.0, "batch_reward": 0.22539724951982498, "critic_loss": 0.4202147391140461, "actor_loss": -22.89895380783081, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.302387237548828, "step": 128000}
{"episode_reward": 511.4521719635805, "episode": 129.0, "batch_reward": 0.22736095817387103, "critic_loss": 0.42047467875480654, "actor_loss": -23.154630184173584, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.646843910217285, "step": 129000}
{"episode_reward": 499.98222081866913, "episode": 130.0, "batch_reward": 0.23039587159454822, "critic_loss": 0.46326756914705036, "actor_loss": -23.563114143371582, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.811470985412598, "step": 130000}
{"episode_reward": 516.4908444333846, "episode": 131.0, "batch_reward": 0.23233302007615567, "critic_loss": 0.44566974899172784, "actor_loss": -23.345054737091065, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.86203455924988, "step": 131000}
{"episode_reward": 534.6530363107983, "episode": 132.0, "batch_reward": 0.23304529950022698, "critic_loss": 0.4333468875139952, "actor_loss": -23.865836841583253, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.028331756591797, "step": 132000}
{"episode_reward": 202.52170740781523, "episode": 133.0, "batch_reward": 0.23388304337859153, "critic_loss": 0.41575835466384886, "actor_loss": -23.69760000991821, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.799116373062134, "step": 133000}
{"episode_reward": 515.2690574563986, "episode": 134.0, "batch_reward": 0.23691040271520614, "critic_loss": 0.40939521335065365, "actor_loss": -24.144450759887697, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.710505962371826, "step": 134000}
{"episode_reward": 186.3726961260499, "episode": 135.0, "batch_reward": 0.2363129869401455, "critic_loss": 0.39674447698891163, "actor_loss": -24.070513198852538, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.641074657440186, "step": 135000}
{"episode_reward": 527.1988544991324, "episode": 136.0, "batch_reward": 0.2372780029028654, "critic_loss": 0.38664376898109915, "actor_loss": -24.146781150817873, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.153289556503296, "step": 136000}
{"episode_reward": 544.1223785947117, "episode": 137.0, "batch_reward": 0.24113043449819088, "critic_loss": 0.39552155897021296, "actor_loss": -24.727041362762453, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.14945650100708, "step": 137000}
{"episode_reward": 541.6677864465594, "episode": 138.0, "batch_reward": 0.24267546409368515, "critic_loss": 0.39730638806521895, "actor_loss": -24.430351837158202, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.80850648880005, "step": 138000}
{"episode_reward": 499.006668278804, "episode": 139.0, "batch_reward": 0.2449059098213911, "critic_loss": 0.40594843310117723, "actor_loss": -24.620402587890624, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.198960781097412, "step": 139000}
{"episode_reward": 536.7081520751691, "episode": 140.0, "batch_reward": 0.24638375994563103, "critic_loss": 0.3890529638305306, "actor_loss": -24.789821369171143, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.58457350730896, "step": 140000}
{"episode_reward": 554.3606964516923, "episode": 141.0, "batch_reward": 0.24862507304549217, "critic_loss": 0.38820799978077414, "actor_loss": -25.024092212677, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.040597677230835, "step": 141000}
{"episode_reward": 564.6023427982757, "episode": 142.0, "batch_reward": 0.25216422909498215, "critic_loss": 0.4056399013698101, "actor_loss": -25.376793369293214, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.371079444885254, "step": 142000}
{"episode_reward": 563.017870621363, "episode": 143.0, "batch_reward": 0.25359661200642586, "critic_loss": 0.43558118514716626, "actor_loss": -25.526959392547607, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.661147832870483, "step": 143000}
{"episode_reward": 547.9237676429761, "episode": 144.0, "batch_reward": 0.2569416398853064, "critic_loss": 0.40667588421702383, "actor_loss": -25.73160793685913, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.774187326431274, "step": 144000}
{"episode_reward": 419.80307386171376, "episode": 145.0, "batch_reward": 0.2571944950670004, "critic_loss": 0.37678718656301496, "actor_loss": -25.818475986480713, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.08373999595642, "step": 145000}
{"episode_reward": 555.9485252421816, "episode": 146.0, "batch_reward": 0.25844897466897965, "critic_loss": 0.38660472983121874, "actor_loss": -25.861686222076415, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.12966275215149, "step": 146000}
{"episode_reward": 518.589480199662, "episode": 147.0, "batch_reward": 0.2609657164663076, "critic_loss": 0.36828317277133465, "actor_loss": -26.070994235992433, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.047841787338257, "step": 147000}
{"episode_reward": 552.3016102189864, "episode": 148.0, "batch_reward": 0.2622625520527363, "critic_loss": 0.3874528323560953, "actor_loss": -26.086283603668214, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.96400737762451, "step": 148000}
{"episode_reward": 596.7952953739792, "episode": 149.0, "batch_reward": 0.26357319194078443, "critic_loss": 0.355557563751936, "actor_loss": -26.394457332611083, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.48060703277588, "step": 149000}
{"episode_reward": 578.2918128935337, "episode": 150.0, "batch_reward": 0.26593390993773935, "critic_loss": 0.39285204230248927, "actor_loss": -26.42761585998535, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "step": 150000}
