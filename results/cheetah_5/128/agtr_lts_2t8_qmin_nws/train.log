{"episode_reward": 0.0, "episode": 1.0, "duration": 13.955784797668457, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.2302649021148682, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.2615385039393685, "critic_loss": 0.14279202139548516, "actor_loss": -33.865538692196495, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 72.6951916217804, "step": 3000}
{"episode_reward": 25.110628625899167, "episode": 4.0, "batch_reward": 0.16775618404150008, "critic_loss": 0.06452941461652517, "actor_loss": -22.775590322494505, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.267475843429565, "step": 4000}
{"episode_reward": 5.31137946393556, "episode": 5.0, "batch_reward": 0.1304047211036086, "critic_loss": 0.036795406606048346, "actor_loss": -22.475921321868896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.18686056137085, "step": 5000}
{"episode_reward": 2.1766868323068245, "episode": 6.0, "batch_reward": 0.10704346231743693, "critic_loss": 0.03677339327149093, "actor_loss": -22.50421097946167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.40729522705078, "step": 6000}
{"episode_reward": 2.6578624813813647, "episode": 7.0, "batch_reward": 0.09072807629406453, "critic_loss": 0.03551452942099422, "actor_loss": -23.477773704528808, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.956363201141357, "step": 7000}
{"episode_reward": 2.944448865739447, "episode": 8.0, "batch_reward": 0.07934185959026217, "critic_loss": 0.03366465715877712, "actor_loss": -20.08118196582794, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.95774555206299, "step": 8000}
{"episode_reward": 3.8145444586974766, "episode": 9.0, "batch_reward": 0.07037146125733852, "critic_loss": 0.029636877643875778, "actor_loss": -21.185637251853944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.981003046035767, "step": 9000}
{"episode_reward": 6.698703231261408, "episode": 10.0, "batch_reward": 0.0638887162413448, "critic_loss": 0.02926738859899342, "actor_loss": -19.953849906921388, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.58660364151001, "step": 10000}
{"episode_reward": 9.658058325034066, "episode": 11.0, "batch_reward": 0.060161734752357005, "critic_loss": 0.029275242207571862, "actor_loss": -21.79883329105377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.2209255695343, "step": 11000}
{"episode_reward": 46.59259243600589, "episode": 12.0, "batch_reward": 0.060132134607061745, "critic_loss": 0.035561208955943585, "actor_loss": -18.59837263393402, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.63233494758606, "step": 12000}
{"episode_reward": 46.01975656647774, "episode": 13.0, "batch_reward": 0.0594794542491436, "critic_loss": 0.03813601393997669, "actor_loss": -18.33828888130188, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.868818521499634, "step": 13000}
{"episode_reward": 73.92503749614067, "episode": 14.0, "batch_reward": 0.06044193035550415, "critic_loss": 0.030346146411262452, "actor_loss": -15.651313943862915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.140779972076416, "step": 14000}
{"episode_reward": 46.80425784051374, "episode": 15.0, "batch_reward": 0.06044640959426761, "critic_loss": 0.03702190679963678, "actor_loss": -16.45206072807312, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3193576335907, "step": 15000}
{"episode_reward": 95.63879787230171, "episode": 16.0, "batch_reward": 0.06137325015850365, "critic_loss": 0.03766936829313636, "actor_loss": -15.817002223968506, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.92843747138977, "step": 16000}
{"episode_reward": 74.35716439744834, "episode": 17.0, "batch_reward": 0.06214814836718142, "critic_loss": 0.04264022565912455, "actor_loss": -15.27479064321518, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.859628438949585, "step": 17000}
{"episode_reward": 54.89563995806688, "episode": 18.0, "batch_reward": 0.06317232276126743, "critic_loss": 0.05090600630175322, "actor_loss": -13.8969243850708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.804017305374146, "step": 18000}
{"episode_reward": 91.64191738026301, "episode": 19.0, "batch_reward": 0.06461642406508326, "critic_loss": 0.05131377396173775, "actor_loss": -15.055677728176118, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.946497917175293, "step": 19000}
{"episode_reward": 107.61093415136148, "episode": 20.0, "batch_reward": 0.06594893849641084, "critic_loss": 0.06059969582594931, "actor_loss": -14.353309979677201, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.94730043411255, "step": 20000}
{"episode_reward": 62.28424503375714, "episode": 21.0, "batch_reward": 0.06714914051443338, "critic_loss": 0.06853205986879767, "actor_loss": -14.525429320335387, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.47316288948059, "step": 21000}
{"episode_reward": 142.70369036927056, "episode": 22.0, "batch_reward": 0.07036684817820787, "critic_loss": 0.078883834624663, "actor_loss": -13.7478237388134, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.36241912841797, "step": 22000}
{"episode_reward": 102.97876254790927, "episode": 23.0, "batch_reward": 0.07279070886597037, "critic_loss": 0.0880070071592927, "actor_loss": -14.52167903263867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.85106873512268, "step": 23000}
{"episode_reward": 86.46985314046496, "episode": 24.0, "batch_reward": 0.07459734661132097, "critic_loss": 0.10538218067958952, "actor_loss": -14.983856765955686, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.39653754234314, "step": 24000}
{"episode_reward": 202.59724461486655, "episode": 25.0, "batch_reward": 0.07852236539497971, "critic_loss": 0.11780964179337025, "actor_loss": -13.708954849891365, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.934749364852905, "step": 25000}
{"episode_reward": 159.93338672120757, "episode": 26.0, "batch_reward": 0.0832628573179245, "critic_loss": 0.13344333242624998, "actor_loss": -14.883270820200444, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.971025466918945, "step": 26000}
{"episode_reward": 204.61937381892514, "episode": 27.0, "batch_reward": 0.08540446714311838, "critic_loss": 0.13933505861461162, "actor_loss": -14.52136197733879, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.04049062728882, "step": 27000}
{"episode_reward": 110.80106306255631, "episode": 28.0, "batch_reward": 0.08711166717112065, "critic_loss": 0.13203618727996946, "actor_loss": -13.832835464954377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.201762437820435, "step": 28000}
{"episode_reward": 100.18633876119503, "episode": 29.0, "batch_reward": 0.08695869632437825, "critic_loss": 0.12724020067602396, "actor_loss": -14.080786673545838, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.38528084754944, "step": 29000}
{"episode_reward": 80.84496532613883, "episode": 30.0, "batch_reward": 0.08855155961960554, "critic_loss": 0.14815396835282446, "actor_loss": -14.793367761611938, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.16819953918457, "step": 30000}
{"episode_reward": 193.59972709068455, "episode": 31.0, "batch_reward": 0.09278924382477999, "critic_loss": 0.15438521871715785, "actor_loss": -13.779234343528747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.126970052719116, "step": 31000}
{"episode_reward": 300.0548474503653, "episode": 32.0, "batch_reward": 0.0981239091232419, "critic_loss": 0.21760214114189147, "actor_loss": -14.551931457519531, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.217877864837646, "step": 32000}
{"episode_reward": 259.8336922412922, "episode": 33.0, "batch_reward": 0.10021625914424657, "critic_loss": 0.21178386490792037, "actor_loss": -14.282113561630249, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.674072742462158, "step": 33000}
{"episode_reward": 31.551738853612676, "episode": 34.0, "batch_reward": 0.10079017136245966, "critic_loss": 0.20655168403685092, "actor_loss": -14.377674964904784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.796110153198242, "step": 34000}
{"episode_reward": 107.08179221513477, "episode": 35.0, "batch_reward": 0.10107906572520733, "critic_loss": 0.21000182154774666, "actor_loss": -15.759975662231446, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32615375518799, "step": 35000}
{"episode_reward": 186.92360302604826, "episode": 36.0, "batch_reward": 0.10550162993371487, "critic_loss": 0.2287917678207159, "actor_loss": -14.919956479072571, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.92239236831665, "step": 36000}
{"episode_reward": 285.8857435976149, "episode": 37.0, "batch_reward": 0.11034060503542423, "critic_loss": 0.23337042578309775, "actor_loss": -15.984507511138917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.142931699752808, "step": 37000}
{"episode_reward": 329.2254169013552, "episode": 38.0, "batch_reward": 0.11630422747135162, "critic_loss": 0.2481143956631422, "actor_loss": -16.548155910491943, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.417123794555664, "step": 38000}
{"episode_reward": 317.70403059078154, "episode": 39.0, "batch_reward": 0.12118946568667889, "critic_loss": 0.28155720918625593, "actor_loss": -16.16594819545746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.204102993011475, "step": 39000}
{"episode_reward": 303.081825819572, "episode": 40.0, "batch_reward": 0.12519062560796737, "critic_loss": 0.2994224055409431, "actor_loss": -16.13903032684326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.327782154083252, "step": 40000}
{"episode_reward": 226.2188779872931, "episode": 41.0, "batch_reward": 0.12748445633798838, "critic_loss": 0.2959951152279973, "actor_loss": -16.987820207595824, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.68109726905823, "step": 41000}
{"episode_reward": 296.0361209938758, "episode": 42.0, "batch_reward": 0.13127788516134023, "critic_loss": 0.29369860865175723, "actor_loss": -17.40564866256714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.88265299797058, "step": 42000}
{"episode_reward": 113.70272107880648, "episode": 43.0, "batch_reward": 0.13123127692192793, "critic_loss": 0.3260148650556803, "actor_loss": -17.037362545013426, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.58718514442444, "step": 43000}
{"episode_reward": 315.7174738187313, "episode": 44.0, "batch_reward": 0.1358458220884204, "critic_loss": 0.3023716882765293, "actor_loss": -18.10004649543762, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.425615787506104, "step": 44000}
{"episode_reward": 236.86500032282507, "episode": 45.0, "batch_reward": 0.13879580926150084, "critic_loss": 0.31845079140365123, "actor_loss": -18.788809492111206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.232642650604248, "step": 45000}
{"episode_reward": 328.7637564276382, "episode": 46.0, "batch_reward": 0.1438314604088664, "critic_loss": 0.33560743952542543, "actor_loss": -18.928515012741087, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.261234998703003, "step": 46000}
{"episode_reward": 391.6241038579829, "episode": 47.0, "batch_reward": 0.14858215360343457, "critic_loss": 0.3177513605058193, "actor_loss": -19.570608270645142, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.194395542144775, "step": 47000}
{"episode_reward": 383.11639218016046, "episode": 48.0, "batch_reward": 0.15267476335167884, "critic_loss": 0.3549241818934679, "actor_loss": -20.132658302307128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.161669492721558, "step": 48000}
{"episode_reward": 367.7951110367383, "episode": 49.0, "batch_reward": 0.15615029114484788, "critic_loss": 0.3546793596148491, "actor_loss": -20.211517650604247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.083036422729492, "step": 49000}
{"episode_reward": 70.32827226905962, "episode": 50.0, "batch_reward": 0.1544185007289052, "critic_loss": 0.3302975767999887, "actor_loss": -20.585052684783935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.173251628875732, "step": 50000}
{"episode_reward": 211.47461792351035, "episode": 51.0, "batch_reward": 0.15422960198670627, "critic_loss": 0.3448841114938259, "actor_loss": -20.654918643951415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.29988932609558, "step": 51000}
{"episode_reward": 147.7858543014242, "episode": 52.0, "batch_reward": 0.15514356765151024, "critic_loss": 0.32832122886180876, "actor_loss": -21.29584854888916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.036474227905273, "step": 52000}
{"episode_reward": 207.04120270721998, "episode": 53.0, "batch_reward": 0.15609495209902524, "critic_loss": 0.32729631297290324, "actor_loss": -21.442395118713378, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.019827127456665, "step": 53000}
{"episode_reward": 252.6145060115618, "episode": 54.0, "batch_reward": 0.15653800500184298, "critic_loss": 0.32651155748963356, "actor_loss": -21.54053153991699, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.76159644126892, "step": 54000}
{"episode_reward": 162.86136623041185, "episode": 55.0, "batch_reward": 0.16026201727986336, "critic_loss": 0.34163122707605365, "actor_loss": -21.920922397613527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.085502862930298, "step": 55000}
{"episode_reward": 427.0681264875367, "episode": 56.0, "batch_reward": 0.16253986085951327, "critic_loss": 0.3555012773573399, "actor_loss": -22.238666076660156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.471101999282837, "step": 56000}
{"episode_reward": 117.91842696559426, "episode": 57.0, "batch_reward": 0.16383742374181748, "critic_loss": 0.352407212972641, "actor_loss": -22.437365131378172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.182487964630127, "step": 57000}
{"episode_reward": 451.87361491442226, "episode": 58.0, "batch_reward": 0.16763631043583155, "critic_loss": 0.36691257908940317, "actor_loss": -22.84524573135376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.151554584503174, "step": 58000}
{"episode_reward": 199.54065442488726, "episode": 59.0, "batch_reward": 0.1684812104701996, "critic_loss": 0.35214458625018596, "actor_loss": -22.677495861053465, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.62290072441101, "step": 59000}
{"episode_reward": 133.35530358672779, "episode": 60.0, "batch_reward": 0.1680390846580267, "critic_loss": 0.35676841811835763, "actor_loss": -23.062084209442137, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.02871346473694, "step": 60000}
{"episode_reward": 207.9288558731097, "episode": 61.0, "batch_reward": 0.16716423023492097, "critic_loss": 0.3403923695087433, "actor_loss": -23.22847282409668, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.28342008590698, "step": 61000}
{"episode_reward": 103.37980257700683, "episode": 62.0, "batch_reward": 0.1685294412150979, "critic_loss": 0.34929611553251744, "actor_loss": -23.39365002441406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.98906135559082, "step": 62000}
{"episode_reward": 433.95201661909283, "episode": 63.0, "batch_reward": 0.17307356311380864, "critic_loss": 0.37021904535591604, "actor_loss": -23.791511440277098, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.816142082214355, "step": 63000}
{"episode_reward": 410.08337479103193, "episode": 64.0, "batch_reward": 0.17610290339589119, "critic_loss": 0.36840140601992605, "actor_loss": -23.88620474243164, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.617630004882812, "step": 64000}
{"episode_reward": 395.9892493585609, "episode": 65.0, "batch_reward": 0.1790826063901186, "critic_loss": 0.4129916794151068, "actor_loss": -24.262226833343504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.46356701850891, "step": 65000}
{"episode_reward": 325.7773646328855, "episode": 66.0, "batch_reward": 0.18193213053047658, "critic_loss": 0.4073022963553667, "actor_loss": -24.413646541595458, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.448402166366577, "step": 66000}
{"episode_reward": 289.9487338956276, "episode": 67.0, "batch_reward": 0.18393542397022247, "critic_loss": 0.3755318730920553, "actor_loss": -24.89813725280762, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.481641054153442, "step": 67000}
{"episode_reward": 327.41935608488984, "episode": 68.0, "batch_reward": 0.18688051280379295, "critic_loss": 0.42841004878282546, "actor_loss": -25.338613075256347, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.100792407989502, "step": 68000}
{"episode_reward": 255.8457010422324, "episode": 69.0, "batch_reward": 0.18725566667318344, "critic_loss": 0.4183442145884037, "actor_loss": -25.458532409667967, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.52778649330139, "step": 69000}
{"episode_reward": 285.6396787049839, "episode": 70.0, "batch_reward": 0.18702604612708093, "critic_loss": 0.44833423897624014, "actor_loss": -25.471341632843018, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.302945852279663, "step": 70000}
{"episode_reward": 178.07286545624092, "episode": 71.0, "batch_reward": 0.18693635675311088, "critic_loss": 0.41285051554441454, "actor_loss": -25.420322368621825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.79693031311035, "step": 71000}
{"episode_reward": 99.46234333665763, "episode": 72.0, "batch_reward": 0.18558242926001547, "critic_loss": 0.4439372283369303, "actor_loss": -25.21137268829346, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.793991804122925, "step": 72000}
{"episode_reward": 135.43251135354575, "episode": 73.0, "batch_reward": 0.18633306409418582, "critic_loss": 0.4307378769814968, "actor_loss": -25.462639949798582, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.39830207824707, "step": 73000}
{"episode_reward": 287.80104631955425, "episode": 74.0, "batch_reward": 0.18739252269268036, "critic_loss": 0.38377577486634257, "actor_loss": -25.601953048706054, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.162024974822998, "step": 74000}
{"episode_reward": 450.00501079687183, "episode": 75.0, "batch_reward": 0.19154622009396552, "critic_loss": 0.41051329123973845, "actor_loss": -25.581524467468263, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.96673083305359, "step": 75000}
{"episode_reward": 234.59360904444569, "episode": 76.0, "batch_reward": 0.190849324837327, "critic_loss": 0.39140058343112466, "actor_loss": -25.67419814300537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.431445360183716, "step": 76000}
{"episode_reward": 235.03494724417683, "episode": 77.0, "batch_reward": 0.19222234191000462, "critic_loss": 0.37545347103476523, "actor_loss": -25.864832706451416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.68792986869812, "step": 77000}
{"episode_reward": 390.1418884144117, "episode": 78.0, "batch_reward": 0.1932809949219227, "critic_loss": 0.3973515748977661, "actor_loss": -25.93942653274536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.317819356918335, "step": 78000}
{"episode_reward": 59.756393969444154, "episode": 79.0, "batch_reward": 0.19240052653849124, "critic_loss": 0.3688085725009441, "actor_loss": -25.593754791259766, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.49369716644287, "step": 79000}
{"episode_reward": 221.27721779939054, "episode": 80.0, "batch_reward": 0.19245951341092588, "critic_loss": 0.3643949322104454, "actor_loss": -25.52260935974121, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.56215476989746, "step": 80000}
{"episode_reward": 239.85814990656198, "episode": 81.0, "batch_reward": 0.19401474103331565, "critic_loss": 0.3535134920477867, "actor_loss": -25.668653350830077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.749504804611206, "step": 81000}
{"episode_reward": 287.12196941694566, "episode": 82.0, "batch_reward": 0.19495225133001803, "critic_loss": 0.3456715971529484, "actor_loss": -25.833822372436522, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.935325384140015, "step": 82000}
{"episode_reward": 307.16932315688575, "episode": 83.0, "batch_reward": 0.19768803855776787, "critic_loss": 0.3387346307486296, "actor_loss": -25.88124927139282, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.409569263458252, "step": 83000}
{"episode_reward": 455.18414943812746, "episode": 84.0, "batch_reward": 0.19807870197296143, "critic_loss": 0.3297161858826876, "actor_loss": -25.975822536468506, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.272160291671753, "step": 84000}
{"episode_reward": 61.923699762147336, "episode": 85.0, "batch_reward": 0.1962406962811947, "critic_loss": 0.3153603526502848, "actor_loss": -25.605265686035157, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.314836978912354, "step": 85000}
{"episode_reward": 117.3205592055187, "episode": 86.0, "batch_reward": 0.19674231180548668, "critic_loss": 0.3362241795957088, "actor_loss": -25.771733242034912, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.26340126991272, "step": 86000}
{"episode_reward": 308.2640287758401, "episode": 87.0, "batch_reward": 0.1983623885512352, "critic_loss": 0.34107302348315716, "actor_loss": -25.686349990844725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.172818183898926, "step": 87000}
{"episode_reward": 404.80793424248935, "episode": 88.0, "batch_reward": 0.19998770785331726, "critic_loss": 0.3257206659913063, "actor_loss": -25.885069400787355, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.007572889328003, "step": 88000}
{"episode_reward": 262.18233927915026, "episode": 89.0, "batch_reward": 0.20183976069092752, "critic_loss": 0.36436571078002455, "actor_loss": -25.888981018066406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41158437728882, "step": 89000}
{"episode_reward": 394.38495826094066, "episode": 90.0, "batch_reward": 0.20237493789196015, "critic_loss": 0.3655831490904093, "actor_loss": -26.08781067657471, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.19764804840088, "step": 90000}
{"episode_reward": 232.65557725625044, "episode": 91.0, "batch_reward": 0.20351396316289902, "critic_loss": 0.36964346854388713, "actor_loss": -25.917099349975587, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.369680404663086, "step": 91000}
{"episode_reward": 370.3718216799589, "episode": 92.0, "batch_reward": 0.2039316981136799, "critic_loss": 0.40542201007902623, "actor_loss": -25.999270404815675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.52686333656311, "step": 92000}
{"episode_reward": 106.97799447939424, "episode": 93.0, "batch_reward": 0.20470526233315467, "critic_loss": 0.41544948776066304, "actor_loss": -25.952846817016603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.93571376800537, "step": 93000}
{"episode_reward": 437.279389805684, "episode": 94.0, "batch_reward": 0.2078048171252012, "critic_loss": 0.41922338208556176, "actor_loss": -26.366675575256348, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.396851062774658, "step": 94000}
{"episode_reward": 439.5008669273302, "episode": 95.0, "batch_reward": 0.20942533306777478, "critic_loss": 0.38158326849341395, "actor_loss": -26.338794818878174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.208898544311523, "step": 95000}
{"episode_reward": 410.106201677206, "episode": 96.0, "batch_reward": 0.21021875289082528, "critic_loss": 0.3772629080116749, "actor_loss": -26.27520265197754, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.565072298049927, "step": 96000}
{"episode_reward": 91.52941396399399, "episode": 97.0, "batch_reward": 0.20950485895574092, "critic_loss": 0.3744351187199354, "actor_loss": -26.082617248535158, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.44434642791748, "step": 97000}
{"episode_reward": 448.18541603717097, "episode": 98.0, "batch_reward": 0.21337191085517407, "critic_loss": 0.3891691688895226, "actor_loss": -26.256935081481934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.222302198410034, "step": 98000}
{"episode_reward": 357.50725027559605, "episode": 99.0, "batch_reward": 0.21363679963350296, "critic_loss": 0.38924170266091823, "actor_loss": -26.170610664367675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.432000398635864, "step": 99000}
{"episode_reward": 239.0043337007888, "episode": 100.0, "batch_reward": 0.21560713258385658, "critic_loss": 0.4038274717181921, "actor_loss": -26.314077560424806, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.25877070426941, "step": 100000}
{"episode_reward": 402.3643843379579, "episode": 101.0, "batch_reward": 0.21480320465564728, "critic_loss": 0.40967653337121007, "actor_loss": -26.341532707214355, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.70501184463501, "step": 101000}
{"episode_reward": 61.917874408900126, "episode": 102.0, "batch_reward": 0.21567265744507313, "critic_loss": 0.3854807066619396, "actor_loss": -26.118939586639403, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.654882431030273, "step": 102000}
{"episode_reward": 537.5557574725581, "episode": 103.0, "batch_reward": 0.21887221018970013, "critic_loss": 0.38879242588579654, "actor_loss": -26.530224002838136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.726526021957397, "step": 103000}
{"episode_reward": 495.6441269259896, "episode": 104.0, "batch_reward": 0.22241818383336068, "critic_loss": 0.42917791472375394, "actor_loss": -26.510511909484862, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.208091497421265, "step": 104000}
{"episode_reward": 513.0638673959351, "episode": 105.0, "batch_reward": 0.223323768094182, "critic_loss": 0.4099387267678976, "actor_loss": -26.671322399139406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.258483171463013, "step": 105000}
{"episode_reward": 546.6804023322273, "episode": 106.0, "batch_reward": 0.22633667805790902, "critic_loss": 0.4057752391546965, "actor_loss": -26.845069347381592, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.585583209991455, "step": 106000}
{"episode_reward": 477.8047941383461, "episode": 107.0, "batch_reward": 0.22956884679198264, "critic_loss": 0.36644080638885496, "actor_loss": -27.073740745544434, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.31645941734314, "step": 107000}
{"episode_reward": 562.5268862026971, "episode": 108.0, "batch_reward": 0.23220526717603207, "critic_loss": 0.36555239585042, "actor_loss": -27.203831638336183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.358094453811646, "step": 108000}
{"episode_reward": 500.55732274392744, "episode": 109.0, "batch_reward": 0.23491848948597907, "critic_loss": 0.36565027906000613, "actor_loss": -27.42977159500122, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.540242433547974, "step": 109000}
{"episode_reward": 458.41016790718925, "episode": 110.0, "batch_reward": 0.23642461943626403, "critic_loss": 0.387861136585474, "actor_loss": -27.44860744857788, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.174264907836914, "step": 110000}
{"episode_reward": 162.87732572964842, "episode": 111.0, "batch_reward": 0.23660083402693272, "critic_loss": 0.3823511997014284, "actor_loss": -27.501640476226807, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.364027976989746, "step": 111000}
{"episode_reward": 515.3107040838463, "episode": 112.0, "batch_reward": 0.23746466052532195, "critic_loss": 0.404916339173913, "actor_loss": -27.501490390777587, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.865248203277588, "step": 112000}
{"episode_reward": 497.8775713648261, "episode": 113.0, "batch_reward": 0.24098368652164937, "critic_loss": 0.3899042522460222, "actor_loss": -27.959561767578126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.81937575340271, "step": 113000}
{"episode_reward": 265.1559264200821, "episode": 114.0, "batch_reward": 0.24119177389144897, "critic_loss": 0.4142164057344198, "actor_loss": -27.672285346984864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.619264125823975, "step": 114000}
{"episode_reward": 464.90560892782236, "episode": 115.0, "batch_reward": 0.24384375603497027, "critic_loss": 0.34564370642602443, "actor_loss": -27.84822306060791, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.961675882339478, "step": 115000}
{"episode_reward": 538.3816940347125, "episode": 116.0, "batch_reward": 0.2450648936033249, "critic_loss": 0.3755505370348692, "actor_loss": -27.928769218444824, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.449873447418213, "step": 116000}
{"episode_reward": 287.69783688110493, "episode": 117.0, "batch_reward": 0.24638320127129554, "critic_loss": 0.35784358482062817, "actor_loss": -28.14387958908081, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.227921724319458, "step": 117000}
{"episode_reward": 277.82009462471365, "episode": 118.0, "batch_reward": 0.24668427513539792, "critic_loss": 0.372006855994463, "actor_loss": -28.21572215270996, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.628859758377075, "step": 118000}
{"episode_reward": 574.4946827564804, "episode": 119.0, "batch_reward": 0.2478328802883625, "critic_loss": 0.38216408383846284, "actor_loss": -28.241194244384765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34594702720642, "step": 119000}
{"episode_reward": 540.1706196239882, "episode": 120.0, "batch_reward": 0.25227691236138344, "critic_loss": 0.3637371231764555, "actor_loss": -28.3877278175354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.12711477279663, "step": 120000}
{"episode_reward": 546.3759870250668, "episode": 121.0, "batch_reward": 0.25517843005061147, "critic_loss": 0.35357284200191497, "actor_loss": -28.7449344329834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.52911996841431, "step": 121000}
{"episode_reward": 537.2698980724002, "episode": 122.0, "batch_reward": 0.25797418773174285, "critic_loss": 0.39645136168599127, "actor_loss": -28.858921272277833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.79880952835083, "step": 122000}
{"episode_reward": 534.1802188804519, "episode": 123.0, "batch_reward": 0.2581901498883963, "critic_loss": 0.3597576908767223, "actor_loss": -28.907901374816895, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.18532419204712, "step": 123000}
{"episode_reward": 268.496500869921, "episode": 124.0, "batch_reward": 0.25905362178385255, "critic_loss": 0.39618556188046933, "actor_loss": -29.034513107299805, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.470417499542236, "step": 124000}
{"episode_reward": 562.8199384679413, "episode": 125.0, "batch_reward": 0.26196593993902206, "critic_loss": 0.35338063187897206, "actor_loss": -29.056691593170164, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.050431489944458, "step": 125000}
{"episode_reward": 580.2778797044543, "episode": 126.0, "batch_reward": 0.2637412912249565, "critic_loss": 0.37018416076898575, "actor_loss": -29.366533367156983, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22357439994812, "step": 126000}
{"episode_reward": 364.9910220777942, "episode": 127.0, "batch_reward": 0.264245904609561, "critic_loss": 0.34228933304548265, "actor_loss": -29.428089626312257, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.284379720687866, "step": 127000}
{"episode_reward": 566.6459690268862, "episode": 128.0, "batch_reward": 0.266532520070672, "critic_loss": 0.35484368580579756, "actor_loss": -29.654919418334963, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.203436374664307, "step": 128000}
{"episode_reward": 519.1029230467173, "episode": 129.0, "batch_reward": 0.2689271714091301, "critic_loss": 0.34844729006290437, "actor_loss": -29.893319919586183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.2171630859375, "step": 129000}
{"episode_reward": 573.3935230404005, "episode": 130.0, "batch_reward": 0.27213212160766126, "critic_loss": 0.3716279933899641, "actor_loss": -30.199507373809816, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.227067470550537, "step": 130000}
{"episode_reward": 533.6332459169088, "episode": 131.0, "batch_reward": 0.272989174798131, "critic_loss": 0.36335800601541995, "actor_loss": -30.439835834503175, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.53527522087097, "step": 131000}
{"episode_reward": 570.2614959584224, "episode": 132.0, "batch_reward": 0.27434366062283516, "critic_loss": 0.3546585016846657, "actor_loss": -30.490373596191407, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.714263439178467, "step": 132000}
{"episode_reward": 368.72925150616106, "episode": 133.0, "batch_reward": 0.2752685356885195, "critic_loss": 0.3795119298696518, "actor_loss": -30.32315594100952, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.631340265274048, "step": 133000}
{"episode_reward": 558.3575946218878, "episode": 134.0, "batch_reward": 0.27904806603491306, "critic_loss": 0.35223709896206856, "actor_loss": -30.68408059310913, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.39688467979431, "step": 134000}
{"episode_reward": 532.8343987480572, "episode": 135.0, "batch_reward": 0.2806774576753378, "critic_loss": 0.36446234917640685, "actor_loss": -30.63543447113037, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.228373527526855, "step": 135000}
{"episode_reward": 569.8525868517677, "episode": 136.0, "batch_reward": 0.2821167324334383, "critic_loss": 0.3705252982228994, "actor_loss": -30.843524780273437, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.24008083343506, "step": 136000}
{"episode_reward": 538.1049407162599, "episode": 137.0, "batch_reward": 0.2847613150179386, "critic_loss": 0.35985959993302824, "actor_loss": -31.201498874664306, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.340636014938354, "step": 137000}
{"episode_reward": 609.7096723514238, "episode": 138.0, "batch_reward": 0.2872681540995836, "critic_loss": 0.37238186404109, "actor_loss": -31.59523133087158, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.579033613204956, "step": 138000}
{"episode_reward": 560.0039226077754, "episode": 139.0, "batch_reward": 0.2883736486136913, "critic_loss": 0.3612237350940704, "actor_loss": -31.709797428131104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.526804447174072, "step": 139000}
{"episode_reward": 578.067758784816, "episode": 140.0, "batch_reward": 0.29046344588696954, "critic_loss": 0.36571727496385575, "actor_loss": -31.813694541931152, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.135785341262817, "step": 140000}
{"episode_reward": 549.3475024463371, "episode": 141.0, "batch_reward": 0.2930387606173754, "critic_loss": 0.3465786977261305, "actor_loss": -31.938204837799073, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.93943452835083, "step": 141000}
{"episode_reward": 585.6845411051637, "episode": 142.0, "batch_reward": 0.2957508879005909, "critic_loss": 0.3730964924916625, "actor_loss": -32.15517559814453, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.83979558944702, "step": 142000}
{"episode_reward": 579.2364878837087, "episode": 143.0, "batch_reward": 0.29743263132870196, "critic_loss": 0.34380655889213085, "actor_loss": -32.23299775695801, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.569079399108887, "step": 143000}
{"episode_reward": 648.9072945938243, "episode": 144.0, "batch_reward": 0.30010218764841556, "critic_loss": 0.34524511483311654, "actor_loss": -32.47555037689209, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.34727191925049, "step": 144000}
{"episode_reward": 619.2219949435445, "episode": 145.0, "batch_reward": 0.3013343747705221, "critic_loss": 0.3424563781172037, "actor_loss": -32.33200426864624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.203447341918945, "step": 145000}
{"episode_reward": 603.5177648854961, "episode": 146.0, "batch_reward": 0.3026363658756018, "critic_loss": 0.354935446113348, "actor_loss": -32.84183053207398, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.40132188796997, "step": 146000}
{"episode_reward": 548.8054756034265, "episode": 147.0, "batch_reward": 0.30552739852666855, "critic_loss": 0.3531418298333883, "actor_loss": -33.087587619781495, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32952570915222, "step": 147000}
{"episode_reward": 430.4760096154799, "episode": 148.0, "batch_reward": 0.305865617454052, "critic_loss": 0.34744593712687494, "actor_loss": -33.12877963638306, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.08359694480896, "step": 148000}
{"episode_reward": 579.4402334773598, "episode": 149.0, "batch_reward": 0.30686959640681744, "critic_loss": 0.315151293233037, "actor_loss": -33.27974842071533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.87390112876892, "step": 149000}
{"episode_reward": 569.5667167774446, "episode": 150.0, "batch_reward": 0.30948913751542567, "critic_loss": 0.3481168799549341, "actor_loss": -33.47513720703125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
