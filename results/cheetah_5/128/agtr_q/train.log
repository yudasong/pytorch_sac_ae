{"episode": 1.0, "duration": 21.08114242553711, "episode_reward": 5.218604035389536, "step": 1000}
{"episode": 2.0, "duration": 1.6742148399353027, "episode_reward": 548.2612263124905, "step": 2000}
{"episode": 3.0, "batch_reward": 0.2639956759160342, "actor_loss": -44.82048316457931, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254236, "duration": 51.010493516922, "episode_reward": 116.57045931392659, "step": 3000}
{"episode": 4.0, "batch_reward": 0.21515215094387533, "actor_loss": -40.55480736541748, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.860788583755493, "episode_reward": 136.01662058264833, "step": 4000}
{"episode": 5.0, "batch_reward": 0.19257297118008138, "actor_loss": -36.54636200714111, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.312291145324707, "episode_reward": 101.62985907739528, "step": 5000}
{"episode": 6.0, "batch_reward": 0.1725468433946371, "actor_loss": -34.08056889724732, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 15.690541744232178, "episode_reward": 69.14487895174157, "step": 6000}
{"episode": 7.0, "batch_reward": 0.16093659553676842, "actor_loss": -33.02365007781982, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.592888355255127, "episode_reward": 140.4771713679954, "step": 7000}
{"episode": 8.0, "batch_reward": 0.16663326620310545, "actor_loss": -33.65081371307373, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.604694366455078, "episode_reward": 238.52080719436543, "step": 8000}
{"episode": 9.0, "batch_reward": 0.16719600664824247, "actor_loss": -32.70779781723022, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.450862407684326, "episode_reward": 110.68216386723839, "step": 9000}
{"episode": 10.0, "batch_reward": 0.15940980552881956, "actor_loss": -28.49479552078247, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 3921.993063211441, "episode_reward": 78.43449687512401, "step": 10000}
{"episode": 11.0, "batch_reward": 0.1538796571418643, "actor_loss": -27.813443733215333, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.261767864227295, "episode_reward": 158.19195546225453, "step": 11000}
{"episode": 12.0, "batch_reward": 0.15420654456317426, "actor_loss": -25.650637001037598, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 435.39067459106445, "episode_reward": 139.6680198155676, "step": 12000}
{"episode": 13.0, "batch_reward": 0.1530133660659194, "actor_loss": -25.714711902618408, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.21874690055847, "episode_reward": 98.32584244516475, "step": 13000}
{"episode": 14.0, "batch_reward": 0.15106008390337228, "actor_loss": -23.16915284729004, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 435.867698431015, "episode_reward": 166.06464022487276, "step": 14000}
{"episode": 15.0, "batch_reward": 0.14652895513176917, "actor_loss": -22.627797077178954, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.84152865409851, "episode_reward": 38.9886440723868, "step": 15000}
{"episode": 16.0, "batch_reward": 0.14532147528231143, "actor_loss": -21.0129333152771, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 430.9995086193085, "episode_reward": 271.66607450430865, "step": 16000}
{"episode": 17.0, "batch_reward": 0.152736942730844, "actor_loss": -21.812268692016602, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.023081302642822, "episode_reward": 284.75566060948466, "step": 17000}
{"episode": 18.0, "batch_reward": 0.16164747070521115, "actor_loss": -21.28482108306885, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 427.07794189453125, "episode_reward": 310.40853663477105, "step": 18000}
{"episode": 19.0, "batch_reward": 0.169314036950469, "actor_loss": -21.72775650405884, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.638595819473267, "episode_reward": 296.42627768716346, "step": 19000}
{"episode": 20.0, "batch_reward": 0.17686062481999398, "actor_loss": -21.198033138275147, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 432.61963987350464, "episode_reward": 275.39400711219633, "step": 20000}
{"episode": 21.0, "batch_reward": 0.18357279703021048, "actor_loss": -21.635283264160158, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 34.78110313415527, "episode_reward": 406.7265490016024, "step": 21000}
{"episode": 22.0, "batch_reward": 0.19209104885160924, "actor_loss": -21.431401149749757, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 419.5868675708771, "episode_reward": 226.2766865957896, "step": 22000}
{"episode": 23.0, "batch_reward": 0.19570548214018346, "actor_loss": -21.546393520355224, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.619446516036987, "episode_reward": 283.26696103530696, "step": 23000}
{"episode": 24.0, "batch_reward": 0.19753145323693752, "actor_loss": -20.768308486938476, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 424.1274223327637, "episode_reward": 378.8882879802288, "step": 24000}
{"episode": 25.0, "batch_reward": 0.20631509958207608, "actor_loss": -21.34780532836914, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.909963369369507, "episode_reward": 320.1375519927346, "step": 25000}
{"episode": 26.0, "batch_reward": 0.2094339207857847, "actor_loss": -21.018215171813964, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 434.10824275016785, "episode_reward": 375.48016863710234, "step": 26000}
{"episode": 27.0, "batch_reward": 0.21792190966010094, "actor_loss": -21.68141961669922, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.787549018859863, "episode_reward": 446.22059174958827, "step": 27000}
{"episode": 28.0, "batch_reward": 0.22366314519941807, "actor_loss": -21.61532071685791, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 426.8139910697937, "episode_reward": 373.18654533140733, "step": 28000}
{"episode": 29.0, "batch_reward": 0.2314447990655899, "actor_loss": -22.210343898773193, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.528783798217773, "episode_reward": 427.90023550370734, "step": 29000}
{"episode": 30.0, "batch_reward": 0.23625229439139367, "actor_loss": -22.37833422088623, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 438.1520881652832, "episode_reward": 375.64713347395315, "step": 30000}
{"episode": 31.0, "batch_reward": 0.24202994744479656, "actor_loss": -22.782393440246583, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.47441077232361, "episode_reward": 416.1513117804992, "step": 31000}
{"episode": 32.0, "batch_reward": 0.246812237277627, "actor_loss": -23.0477659034729, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 430.4686462879181, "episode_reward": 359.4899288728125, "step": 32000}
{"episode": 33.0, "batch_reward": 0.25191063867509367, "actor_loss": -23.424500411987303, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.457563161849976, "episode_reward": 404.0703960769736, "step": 33000}
{"episode": 34.0, "batch_reward": 0.2564042452722788, "actor_loss": -23.576965644836427, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 426.27362990379333, "episode_reward": 437.3989957025079, "step": 34000}
{"episode": 35.0, "batch_reward": 0.260271290063858, "actor_loss": -23.797809810638427, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.081568241119385, "episode_reward": 401.0273365149168, "step": 35000}
{"episode": 36.0, "batch_reward": 0.2657680223584175, "actor_loss": -23.881896068573, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 437.7182950973511, "episode_reward": 447.21821745210536, "step": 36000}
{"episode": 37.0, "batch_reward": 0.2707133193165064, "actor_loss": -24.23102367019653, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.924355268478394, "episode_reward": 467.3306486323904, "step": 37000}
{"episode": 38.0, "batch_reward": 0.2734675271064043, "actor_loss": -24.194060581207275, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 430.78841400146484, "episode_reward": 167.3783065011202, "step": 38000}
{"episode": 39.0, "batch_reward": 0.27223922879993917, "actor_loss": -24.035210605621337, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.64920711517334, "episode_reward": 439.6276113655121, "step": 39000}
{"episode": 40.0, "batch_reward": 0.2764377963989973, "actor_loss": -24.444606342315673, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 432.5406572818756, "episode_reward": 400.7443089200043, "step": 40000}
{"episode": 41.0, "batch_reward": 0.2796684906184673, "actor_loss": -24.632447021484374, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 33.4718062877655, "episode_reward": 441.25231661538135, "step": 41000}
{"episode": 42.0, "batch_reward": 0.2819630564749241, "actor_loss": -24.697854904174804, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 423.6477224826813, "episode_reward": 257.9131558948172, "step": 42000}
{"episode": 43.0, "batch_reward": 0.2827913198471069, "actor_loss": -24.74255313873291, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.49492597579956, "episode_reward": 419.2610060945162, "step": 43000}
{"episode": 44.0, "batch_reward": 0.28737743459641935, "actor_loss": -25.174043884277342, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 410.3962996006012, "episode_reward": 401.39172256714795, "step": 44000}
{"episode": 45.0, "batch_reward": 0.2889165113121271, "actor_loss": -25.34443035507202, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.23118257522583, "episode_reward": 454.86971848845036, "step": 45000}
{"episode": 46.0, "batch_reward": 0.29236894109845163, "actor_loss": -25.421409366607666, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 412.48830938339233, "episode_reward": 495.2888596434012, "step": 46000}
{"episode": 47.0, "batch_reward": 0.2973866871893406, "actor_loss": -25.704690490722655, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.65807271003723, "episode_reward": 486.18033316165076, "step": 47000}
{"episode": 48.0, "batch_reward": 0.30017879471182823, "actor_loss": -26.083940040588377, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 425.0882532596588, "episode_reward": 461.76752147619345, "step": 48000}
{"episode": 49.0, "batch_reward": 0.30509443920850754, "actor_loss": -26.459182342529296, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.382519006729126, "episode_reward": 502.4287699204285, "step": 49000}
{"episode": 50.0, "batch_reward": 0.30880116653442385, "actor_loss": -26.72284127044678, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 423.66861510276794, "episode_reward": 538.912429484143, "step": 50000}
{"episode": 51.0, "batch_reward": 0.31292298033833504, "actor_loss": -27.040252948760987, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 34.66999530792236, "episode_reward": 513.8716623618274, "step": 51000}
{"episode": 52.0, "batch_reward": 0.3178084233105183, "actor_loss": -27.50686215209961, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 431.5760736465454, "episode_reward": 533.5239357396288, "step": 52000}
{"episode": 53.0, "batch_reward": 0.32142680436372756, "actor_loss": -27.9189690322876, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.68594741821289, "episode_reward": 544.4836450193372, "step": 53000}
{"episode": 54.0, "batch_reward": 0.3255189794898033, "actor_loss": -28.24967674255371, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 427.0116980075836, "episode_reward": 537.5527333701363, "step": 54000}
{"episode": 55.0, "batch_reward": 0.32878431925177576, "actor_loss": -28.451640522003174, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.353559970855713, "episode_reward": 520.7573493443846, "step": 55000}
{"episode": 56.0, "batch_reward": 0.33187456405162813, "actor_loss": -28.92845069885254, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 434.415403842926, "episode_reward": 465.20493535210164, "step": 56000}
{"episode": 57.0, "batch_reward": 0.33527870616316796, "actor_loss": -29.14756977081299, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.23813271522522, "episode_reward": 578.2025103472965, "step": 57000}
{"episode": 58.0, "batch_reward": 0.33957874166965485, "actor_loss": -29.106719844818116, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 435.03809905052185, "episode_reward": 446.047556255586, "step": 58000}
{"episode": 59.0, "batch_reward": 0.34160790196061136, "actor_loss": -29.238427989959717, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.353273153305054, "episode_reward": 506.6460765372765, "step": 59000}
{"episode": 60.0, "batch_reward": 0.34392612835764885, "actor_loss": -29.250539321899414, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 430.8463296890259, "episode_reward": 541.9157522394727, "step": 60000}
{"episode": 61.0, "batch_reward": 0.34786898612976075, "actor_loss": -29.65809711074829, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 32.47542691230774, "episode_reward": 543.3571527887657, "step": 61000}
{"episode": 62.0, "batch_reward": 0.3508895394206047, "actor_loss": -29.964421466827392, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 437.9167950153351, "episode_reward": 550.6567265901446, "step": 62000}
{"episode": 63.0, "batch_reward": 0.35290153002738955, "actor_loss": -30.10282228088379, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.25411581993103, "episode_reward": 486.521788318759, "step": 63000}
{"episode": 64.0, "batch_reward": 0.35530949193239214, "actor_loss": -29.700907676696776, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 431.78691816329956, "episode_reward": 261.79224762722504, "step": 64000}
{"episode": 65.0, "batch_reward": 0.354644390553236, "actor_loss": -29.685420433044435, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.80070924758911, "episode_reward": 491.2197624456159, "step": 65000}
{"episode": 66.0, "batch_reward": 0.35593281054496767, "actor_loss": -29.36768879699707, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 433.2929711341858, "episode_reward": 518.6547177465653, "step": 66000}
{"episode": 67.0, "batch_reward": 0.3592712741494179, "actor_loss": -29.765960422515867, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.739108324050903, "episode_reward": 558.5646693272876, "step": 67000}
{"episode": 68.0, "batch_reward": 0.36203320035338404, "actor_loss": -29.490516830444335, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 430.59468126296997, "episode_reward": 515.762177683816, "step": 68000}
{"episode": 69.0, "batch_reward": 0.36420288917422294, "actor_loss": -29.6842596244812, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.976609706878662, "episode_reward": 525.9635396940957, "step": 69000}
{"episode": 70.0, "batch_reward": 0.36658469411730765, "actor_loss": -29.810559688568116, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 434.37492418289185, "episode_reward": 506.3485860776843, "step": 70000}
{"episode": 71.0, "batch_reward": 0.3682036721110344, "actor_loss": -30.03964719772339, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 34.176300048828125, "episode_reward": 561.8171132558136, "step": 71000}
{"episode": 72.0, "batch_reward": 0.3684513293504715, "actor_loss": -29.70017635345459, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 435.7069935798645, "episode_reward": 145.92329060705592, "step": 72000}
{"episode": 73.0, "batch_reward": 0.3678417393863201, "actor_loss": -29.7347117767334, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.422585248947144, "episode_reward": 580.5329127544037, "step": 73000}
{"episode": 74.0, "batch_reward": 0.3699051009118557, "actor_loss": -29.596808197021485, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 429.1495006084442, "episode_reward": 477.92857181589716, "step": 74000}
{"episode": 75.0, "batch_reward": 0.37272729218006134, "actor_loss": -29.798344703674317, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.85497760772705, "episode_reward": 535.0099855819424, "step": 75000}
{"episode": 76.0, "batch_reward": 0.3754347406923771, "actor_loss": -30.39043310546875, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 436.83407163619995, "episode_reward": 571.76675962965, "step": 76000}
{"episode": 77.0, "batch_reward": 0.37829783421754837, "actor_loss": -30.595880489349366, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.329806804656982, "episode_reward": 522.9096727163545, "step": 77000}
{"episode": 78.0, "batch_reward": 0.37935351637005804, "actor_loss": -30.583785388946534, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 432.48137736320496, "episode_reward": 559.7148197370817, "step": 78000}
{"episode": 79.0, "batch_reward": 0.3813984922468662, "actor_loss": -30.738438369750977, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.2068088054657, "episode_reward": 400.5396060372538, "step": 79000}
{"episode": 80.0, "batch_reward": 0.38125277385115625, "actor_loss": -30.921816822052, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 434.7423286437988, "episode_reward": 507.00336903716266, "step": 80000}
{"episode": 81.0, "batch_reward": 0.3824418945610523, "actor_loss": -30.980266086578368, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.123162508010864, "episode_reward": 534.8711426180117, "step": 81000}
{"episode": 82.0, "batch_reward": 0.38416305762529374, "actor_loss": -31.008803092956544, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 424.19844222068787, "episode_reward": 556.4635244526663, "step": 82000}
{"episode": 83.0, "batch_reward": 0.3870885362327099, "actor_loss": -31.20084680938721, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 15.946056842803955, "episode_reward": 516.3987325334326, "step": 83000}
{"episode": 84.0, "batch_reward": 0.38886024191975593, "actor_loss": -31.422525150299073, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 411.5676255226135, "episode_reward": 567.0490499932426, "step": 84000}
{"episode": 85.0, "batch_reward": 0.38997317317128183, "actor_loss": -31.502633445739747, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.591797351837158, "episode_reward": 539.6308753771013, "step": 85000}
{"episode": 86.0, "batch_reward": 0.39295433059334756, "actor_loss": -31.369900581359865, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 415.0699758529663, "episode_reward": 557.3413897204591, "step": 86000}
{"episode": 87.0, "batch_reward": 0.39326605275273324, "actor_loss": -31.440638095855714, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.77172541618347, "episode_reward": 483.80626372088597, "step": 87000}
{"episode": 88.0, "batch_reward": 0.39676792329549787, "actor_loss": -31.520141399383544, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 409.71556854248047, "episode_reward": 532.4616339126345, "step": 88000}
{"episode": 89.0, "batch_reward": 0.39711369985342027, "actor_loss": -31.626924938201903, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.82795000076294, "episode_reward": 527.0258688868319, "step": 89000}
{"episode": 90.0, "batch_reward": 0.39888859990239145, "actor_loss": -31.669095920562743, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 418.4158329963684, "episode_reward": 557.9151292917969, "step": 90000}
{"episode": 91.0, "batch_reward": 0.4001870749890804, "actor_loss": -31.810026397705077, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 34.24386405944824, "episode_reward": 528.4844881028043, "step": 91000}
{"episode": 92.0, "batch_reward": 0.4011945222020149, "actor_loss": -32.24124115371704, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 400.68895983695984, "episode_reward": 493.82417467082763, "step": 92000}
{"episode": 93.0, "batch_reward": 0.40177906438708305, "actor_loss": -32.32556452560425, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.40716814994812, "episode_reward": 510.8878378570062, "step": 93000}
{"episode": 94.0, "batch_reward": 0.40433728650212286, "actor_loss": -32.18434929275513, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 432.7280366420746, "episode_reward": 485.9829654680854, "step": 94000}
{"episode": 95.0, "batch_reward": 0.4043023757040501, "actor_loss": -32.053368518829345, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.107429265975952, "episode_reward": 559.2508869604449, "step": 95000}
{"episode": 96.0, "batch_reward": 0.4064112353026867, "actor_loss": -32.402495449066166, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 428.9302957057953, "episode_reward": 560.4121861694035, "step": 96000}
{"episode": 97.0, "batch_reward": 0.40776329073309897, "actor_loss": -32.43377714157104, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.86188578605652, "episode_reward": 517.0524810518514, "step": 97000}
{"episode": 98.0, "batch_reward": 0.40992480477690696, "actor_loss": -32.69379228591919, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 435.2999086380005, "episode_reward": 548.3974148970912, "step": 98000}
{"episode": 99.0, "batch_reward": 0.40964234179258346, "actor_loss": -32.693756553649905, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.687750339508057, "episode_reward": 535.356252180664, "step": 99000}
{"episode": 100.0, "batch_reward": 0.41218942296504973, "actor_loss": -32.86108511734009, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 432.14750599861145, "episode_reward": 540.7338418965118, "step": 100000}
{"episode": 101.0, "batch_reward": 0.4125833411514759, "actor_loss": -32.85640133666992, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.783623695373535, "episode_reward": 555.820890661455, "step": 101000}
{"episode": 102.0, "batch_reward": 0.4130366623401642, "actor_loss": -33.04349584579468, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 427.7495906352997, "episode_reward": 484.9195317269866, "step": 102000}
{"episode": 103.0, "batch_reward": 0.41499858379364013, "actor_loss": -33.26167139816284, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.667795658111572, "episode_reward": 532.3018430599054, "step": 103000}
{"episode": 104.0, "batch_reward": 0.41498513299226764, "actor_loss": -32.729571231842044, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 435.98206520080566, "episode_reward": 530.7342789221191, "step": 104000}
{"episode": 105.0, "batch_reward": 0.417471791356802, "actor_loss": -33.01176640701294, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.90988302230835, "episode_reward": 487.2172850343676, "step": 105000}
{"episode": 106.0, "batch_reward": 0.41709463101625444, "actor_loss": -32.98503192901612, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 431.8538534641266, "episode_reward": 544.7605664703764, "step": 106000}
{"episode": 107.0, "batch_reward": 0.4183625232577324, "actor_loss": -33.07691473007202, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.16723942756653, "episode_reward": 546.201668473233, "step": 107000}
{"episode": 108.0, "batch_reward": 0.4202666229605675, "actor_loss": -33.328063873291015, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 435.8633041381836, "episode_reward": 537.5578871388645, "step": 108000}
{"episode": 109.0, "batch_reward": 0.42103367668390274, "actor_loss": -33.42453756332397, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.029705286026, "episode_reward": 525.9653054122136, "step": 109000}
{"episode": 110.0, "batch_reward": 0.42255094403028487, "actor_loss": -32.76275970840454, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 428.1071207523346, "episode_reward": 535.8942678061283, "step": 110000}
{"episode": 111.0, "batch_reward": 0.4232174441218376, "actor_loss": -32.9500426902771, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 32.95552349090576, "episode_reward": 523.9769793753308, "step": 111000}
{"episode": 112.0, "batch_reward": 0.4245589333474636, "actor_loss": -32.9148577003479, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 414.39393734931946, "episode_reward": 505.773439309672, "step": 112000}
{"episode": 113.0, "batch_reward": 0.4245312877893448, "actor_loss": -33.00452233886719, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.740964889526367, "episode_reward": 543.887887610673, "step": 113000}
{"episode": 114.0, "batch_reward": 0.4258214923143387, "actor_loss": -33.2918981590271, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 417.22587966918945, "episode_reward": 561.8735769661839, "step": 114000}
{"episode": 115.0, "batch_reward": 0.4275467406511307, "actor_loss": -33.44990405654907, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.71772074699402, "episode_reward": 574.946467925798, "step": 115000}
{"episode": 116.0, "batch_reward": 0.428167220890522, "actor_loss": -33.40887786483765, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 414.48704648017883, "episode_reward": 576.0180692743054, "step": 116000}
{"episode": 117.0, "batch_reward": 0.4314097724556923, "actor_loss": -33.647225410461424, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.120601177215576, "episode_reward": 558.7373325569724, "step": 117000}
{"episode": 118.0, "batch_reward": 0.43070323222875595, "actor_loss": -33.33541513442993, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 431.56472539901733, "episode_reward": 568.6579246477183, "step": 118000}
{"episode": 119.0, "batch_reward": 0.43278884968161585, "actor_loss": -33.4701421585083, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.83823537826538, "episode_reward": 567.8025739639845, "step": 119000}
{"episode": 120.0, "batch_reward": 0.4329235743880272, "actor_loss": -33.59848668670654, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 438.9180178642273, "episode_reward": 559.4843562128989, "step": 120000}
{"episode": 121.0, "batch_reward": 0.43408434399962426, "actor_loss": -33.59869383239746, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.96424651145935, "episode_reward": 531.5645321290385, "step": 121000}
{"episode": 122.0, "batch_reward": 0.43472577691078185, "actor_loss": -33.24705597305298, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 434.3314709663391, "episode_reward": 546.3647345491972, "step": 122000}
{"episode": 123.0, "batch_reward": 0.43584705394506457, "actor_loss": -33.31467583465576, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.179522037506104, "episode_reward": 542.4090982841263, "step": 123000}
{"episode": 124.0, "batch_reward": 0.4365472108721733, "actor_loss": -33.55949589920044, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 431.73693346977234, "episode_reward": 537.7902422084421, "step": 124000}
{"episode": 125.0, "batch_reward": 0.43770110020041464, "actor_loss": -33.671025207519534, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.68879985809326, "episode_reward": 580.1208640802035, "step": 125000}
{"episode": 126.0, "batch_reward": 0.4392481788098812, "actor_loss": -33.58026814651489, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 421.0675015449524, "episode_reward": 559.4048107566645, "step": 126000}
{"episode": 127.0, "batch_reward": 0.43979091456532476, "actor_loss": -33.617142135620114, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.317949533462524, "episode_reward": 558.616187717134, "step": 127000}
{"episode": 128.0, "batch_reward": 0.4407685098350048, "actor_loss": -33.718582447052, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 431.7615761756897, "episode_reward": 591.3737693516942, "step": 128000}
{"episode": 129.0, "batch_reward": 0.441996909737587, "actor_loss": -33.81990709686279, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.469966411590576, "episode_reward": 574.586719071021, "step": 129000}
{"episode": 130.0, "batch_reward": 0.44359454241394997, "actor_loss": -33.8116637802124, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 436.8728184700012, "episode_reward": 582.973392600921, "step": 130000}
{"episode": 131.0, "batch_reward": 0.4434216618537903, "actor_loss": -33.792483093261716, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 32.91714787483215, "episode_reward": 560.0980142432562, "step": 131000}
{"episode": 132.0, "batch_reward": 0.44585148227214816, "actor_loss": -33.6572848815918, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 438.6803276538849, "episode_reward": 596.0216856181448, "step": 132000}
{"episode": 133.0, "batch_reward": 0.44667023947834966, "actor_loss": -33.76769446182251, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.309792518615723, "episode_reward": 600.5938487709496, "step": 133000}
{"episode": 134.0, "batch_reward": 0.4470077386498451, "actor_loss": -33.7964769821167, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 434.43719577789307, "episode_reward": 576.2667283706594, "step": 134000}
{"episode": 135.0, "batch_reward": 0.44813276174664496, "actor_loss": -33.89988270187378, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.271799564361572, "episode_reward": 598.5347124144545, "step": 135000}
{"episode": 136.0, "batch_reward": 0.44954843363165853, "actor_loss": -34.00569323348999, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 440.4968936443329, "episode_reward": 595.6438780419873, "step": 136000}
{"episode": 137.0, "batch_reward": 0.45023870050907133, "actor_loss": -34.10780631256104, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.62304186820984, "episode_reward": 590.7139840207672, "step": 137000}
{"episode": 138.0, "batch_reward": 0.45157259625196455, "actor_loss": -34.13385596466065, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 431.6422097682953, "episode_reward": 489.29471336911456, "step": 138000}
{"episode": 139.0, "batch_reward": 0.45210516586899757, "actor_loss": -34.31758361053467, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.032946825027466, "episode_reward": 556.1138634930824, "step": 139000}
{"episode": 140.0, "batch_reward": 0.4528110307753086, "actor_loss": -34.112511127471926, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 436.1005802154541, "episode_reward": 571.3789723271504, "step": 140000}
{"episode": 141.0, "batch_reward": 0.45339726328849794, "actor_loss": -34.19722156143188, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 34.187748432159424, "episode_reward": 593.4350222369601, "step": 141000}
{"episode": 142.0, "batch_reward": 0.4545357454121113, "actor_loss": -34.18898677444458, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 429.7680027484894, "episode_reward": 605.8154278981885, "step": 142000}
{"episode": 143.0, "batch_reward": 0.4555926379561424, "actor_loss": -34.35017535400391, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.488511085510254, "episode_reward": 577.5740063068218, "step": 143000}
{"episode": 144.0, "batch_reward": 0.45691600531339643, "actor_loss": -34.34170107269287, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 433.63683581352234, "episode_reward": 586.034974760245, "step": 144000}
{"episode": 145.0, "batch_reward": 0.4565631091296673, "actor_loss": -34.29138808441162, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.508155584335327, "episode_reward": 562.8326622915131, "step": 145000}
{"episode": 146.0, "batch_reward": 0.45753571537137033, "actor_loss": -34.501301414489745, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 443.32662320137024, "episode_reward": 557.9310229277982, "step": 146000}
{"episode": 147.0, "batch_reward": 0.45902905383706094, "actor_loss": -34.69370237731933, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.011467218399048, "episode_reward": 573.7910934821518, "step": 147000}
{"episode": 148.0, "batch_reward": 0.4586039344072342, "actor_loss": -34.848406414031984, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 443.9620552062988, "episode_reward": 557.7106292952565, "step": 148000}
{"episode": 149.0, "batch_reward": 0.4598404622375965, "actor_loss": -35.027537746429445, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.556591272354126, "episode_reward": 552.0098356000549, "step": 149000}
{"episode": 150.0, "batch_reward": 0.46062254852056506, "actor_loss": -34.94892587280273, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "step": 150000}
