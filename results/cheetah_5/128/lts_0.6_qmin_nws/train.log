{"episode_reward": 0.0, "episode": 1.0, "duration": 17.520567655563354, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.5064992904663086, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.2606169854592943, "critic_loss": 0.06463632681824717, "actor_loss": -26.718360012891342, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 60.519672870635986, "step": 3000}
{"episode_reward": 14.73519825090295, "episode": 4.0, "batch_reward": 0.16388663064688444, "critic_loss": 0.024744620680809022, "actor_loss": -22.413055740356445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.033360481262207, "step": 4000}
{"episode_reward": 2.740479163511768, "episode": 5.0, "batch_reward": 0.12781154641881584, "critic_loss": 0.026144925270229578, "actor_loss": -21.704924770355223, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05267906188965, "step": 5000}
{"episode_reward": 4.495594291070351, "episode": 6.0, "batch_reward": 0.1057089879438281, "critic_loss": 0.028043454739265145, "actor_loss": -21.582267607688905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05219340324402, "step": 6000}
{"episode_reward": 10.486505500263798, "episode": 7.0, "batch_reward": 0.09089318518340588, "critic_loss": 0.02684066257067025, "actor_loss": -21.771483186006545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.979478120803833, "step": 7000}
{"episode_reward": 12.451944803986445, "episode": 8.0, "batch_reward": 0.08146290701627731, "critic_loss": 0.026172613673843444, "actor_loss": -20.771793688058853, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.037342071533203, "step": 8000}
{"episode_reward": 23.19069436722056, "episode": 9.0, "batch_reward": 0.07404541358724237, "critic_loss": 0.027040758703835308, "actor_loss": -20.04812797498703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.010480403900146, "step": 9000}
{"episode_reward": 12.398326678206306, "episode": 10.0, "batch_reward": 0.068642217669636, "critic_loss": 0.02948647430166602, "actor_loss": -21.195815796852113, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.009812116622925, "step": 10000}
{"episode_reward": 30.152159465210147, "episode": 11.0, "batch_reward": 0.06337597160413862, "critic_loss": 0.027285541946068408, "actor_loss": -19.325178461551666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.48763608932495, "step": 11000}
{"episode_reward": 29.677702467616736, "episode": 12.0, "batch_reward": 0.06267303572781384, "critic_loss": 0.04897558578941971, "actor_loss": -21.104216749429703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.002924919128418, "step": 12000}
{"episode_reward": 78.77128344164649, "episode": 13.0, "batch_reward": 0.06524602828733624, "critic_loss": 0.0779335420448333, "actor_loss": -21.168487341821194, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.037851095199585, "step": 13000}
{"episode_reward": 55.08154115366848, "episode": 14.0, "batch_reward": 0.0652164508625865, "critic_loss": 0.09055308963917195, "actor_loss": -19.83549725419283, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.9984233379364, "step": 14000}
{"episode_reward": 139.44843575814753, "episode": 15.0, "batch_reward": 0.06920462895929813, "critic_loss": 0.1068048185184598, "actor_loss": -18.744079330936074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01107668876648, "step": 15000}
{"episode_reward": 48.46963267043338, "episode": 16.0, "batch_reward": 0.06742346233874559, "critic_loss": 0.10116029166430235, "actor_loss": -19.14766297571361, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.017457723617554, "step": 16000}
{"episode_reward": 46.5992058768246, "episode": 17.0, "batch_reward": 0.06694649254530669, "critic_loss": 0.11871236681938171, "actor_loss": -19.50945178170502, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.001961708068848, "step": 17000}
{"episode_reward": 56.5140332308123, "episode": 18.0, "batch_reward": 0.06896586352586746, "critic_loss": 0.1310187513679266, "actor_loss": -18.674837294131517, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01206350326538, "step": 18000}
{"episode_reward": 220.02989630485385, "episode": 19.0, "batch_reward": 0.0758074800223112, "critic_loss": 0.17177584467828275, "actor_loss": -18.99124797423184, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.030526638031006, "step": 19000}
{"episode_reward": 97.65340033157837, "episode": 20.0, "batch_reward": 0.07698579487204552, "critic_loss": 0.19829935690015554, "actor_loss": -19.373168723732235, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.025167226791382, "step": 20000}
{"episode_reward": 91.13716344004256, "episode": 21.0, "batch_reward": 0.07651675065979362, "critic_loss": 0.18336862855404615, "actor_loss": -17.655137693345548, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.520222187042236, "step": 21000}
{"episode_reward": 46.31213958960331, "episode": 22.0, "batch_reward": 0.07694078536704183, "critic_loss": 0.18927071740478277, "actor_loss": -19.334488129377366, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.009254932403564, "step": 22000}
{"episode_reward": 118.79119799501291, "episode": 23.0, "batch_reward": 0.07915287166088819, "critic_loss": 0.20613542688637973, "actor_loss": -19.065974792003633, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.032208681106567, "step": 23000}
{"episode_reward": 110.94611514833588, "episode": 24.0, "batch_reward": 0.07954598276689649, "critic_loss": 0.1910520949959755, "actor_loss": -18.036131249427797, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04170298576355, "step": 24000}
{"episode_reward": 171.93083551414034, "episode": 25.0, "batch_reward": 0.08355895284935833, "critic_loss": 0.21152125164866448, "actor_loss": -19.476541773319244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.025509357452393, "step": 25000}
{"episode_reward": 112.35987652229718, "episode": 26.0, "batch_reward": 0.0854962086752057, "critic_loss": 0.24968929643183946, "actor_loss": -18.962919699668884, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.019431829452515, "step": 26000}
{"episode_reward": 187.42175054353402, "episode": 27.0, "batch_reward": 0.08978793248534203, "critic_loss": 0.32336583641171457, "actor_loss": -19.49488060712814, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0061137676239, "step": 27000}
{"episode_reward": 172.4591662990286, "episode": 28.0, "batch_reward": 0.09178557095676661, "critic_loss": 0.30932315092533824, "actor_loss": -19.896443605422974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.358675718307495, "step": 28000}
{"episode_reward": 94.77882784500471, "episode": 29.0, "batch_reward": 0.09217123787477613, "critic_loss": 0.3141319325640798, "actor_loss": -19.581785214424134, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00693392753601, "step": 29000}
{"episode_reward": 150.87067136776443, "episode": 30.0, "batch_reward": 0.09408942294865846, "critic_loss": 0.36560976336896417, "actor_loss": -19.10101447582245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.006165981292725, "step": 30000}
{"episode_reward": 206.06371515102444, "episode": 31.0, "batch_reward": 0.09693036478757858, "critic_loss": 0.391114955753088, "actor_loss": -20.134227435112, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.488683462142944, "step": 31000}
{"episode_reward": 61.744925345637824, "episode": 32.0, "batch_reward": 0.09684862487763167, "critic_loss": 0.3440324888974428, "actor_loss": -19.706503116607667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.011473655700684, "step": 32000}
{"episode_reward": 179.4977916468096, "episode": 33.0, "batch_reward": 0.0977486585341394, "critic_loss": 0.36717962904274465, "actor_loss": -20.39846807193756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.015915632247925, "step": 33000}
{"episode_reward": 70.03542421239888, "episode": 34.0, "batch_reward": 0.09638123881444335, "critic_loss": 0.3343193755596876, "actor_loss": -19.985531604766845, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.037986516952515, "step": 34000}
{"episode_reward": 22.90543446906496, "episode": 35.0, "batch_reward": 0.09521641347184777, "critic_loss": 0.31150342055410146, "actor_loss": -18.800830554008485, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.997004508972168, "step": 35000}
{"episode_reward": 98.29341450281207, "episode": 36.0, "batch_reward": 0.09494367364794015, "critic_loss": 0.3352359081804752, "actor_loss": -20.01884831237793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.015021562576294, "step": 36000}
{"episode_reward": 55.62582905604583, "episode": 37.0, "batch_reward": 0.09577888191118836, "critic_loss": 0.3658730424791575, "actor_loss": -19.520307688713075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.049532890319824, "step": 37000}
{"episode_reward": 231.4154672557276, "episode": 38.0, "batch_reward": 0.09979987182468177, "critic_loss": 0.3281967439800501, "actor_loss": -19.619555284500123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.97983407974243, "step": 38000}
{"episode_reward": 251.333333019629, "episode": 39.0, "batch_reward": 0.1025678104236722, "critic_loss": 0.3313172526583075, "actor_loss": -20.663853423118592, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.003538131713867, "step": 39000}
{"episode_reward": 117.07891695489793, "episode": 40.0, "batch_reward": 0.1026835082322359, "critic_loss": 0.35322882927954197, "actor_loss": -21.183826398849487, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.018614768981934, "step": 40000}
{"episode_reward": 101.43224477272645, "episode": 41.0, "batch_reward": 0.10328697523474693, "critic_loss": 0.29789371260255576, "actor_loss": -20.74067615509033, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.478179931640625, "step": 41000}
{"episode_reward": 216.14340856346652, "episode": 42.0, "batch_reward": 0.10658222522586584, "critic_loss": 0.3153060038536787, "actor_loss": -20.730174785614015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.027703762054443, "step": 42000}
{"episode_reward": 241.4269087759205, "episode": 43.0, "batch_reward": 0.10931133524328471, "critic_loss": 0.3258411090821028, "actor_loss": -21.1603731174469, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.997506380081177, "step": 43000}
{"episode_reward": 226.85454043529202, "episode": 44.0, "batch_reward": 0.1124456484913826, "critic_loss": 0.3447651453465223, "actor_loss": -20.376762871742248, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.021785497665405, "step": 44000}
{"episode_reward": 174.70963048514324, "episode": 45.0, "batch_reward": 0.11432266829162836, "critic_loss": 0.3839429358392954, "actor_loss": -20.346553686141966, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.989855766296387, "step": 45000}
{"episode_reward": 277.05973522357783, "episode": 46.0, "batch_reward": 0.11798741967231036, "critic_loss": 0.4163846314251423, "actor_loss": -21.227868221282957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.978452444076538, "step": 46000}
{"episode_reward": 279.75470387410024, "episode": 47.0, "batch_reward": 0.12033513641357421, "critic_loss": 0.3995273924320936, "actor_loss": -21.380515632629393, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.026092290878296, "step": 47000}
{"episode_reward": 281.8696939091968, "episode": 48.0, "batch_reward": 0.12462688601762056, "critic_loss": 0.388039042070508, "actor_loss": -21.695785419464112, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.983994722366333, "step": 48000}
{"episode_reward": 322.03594184778814, "episode": 49.0, "batch_reward": 0.12824738006293773, "critic_loss": 0.35980105893313885, "actor_loss": -21.98292283630371, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.008090496063232, "step": 49000}
{"episode_reward": 155.28315439764293, "episode": 50.0, "batch_reward": 0.12676008555293083, "critic_loss": 0.38822824938595296, "actor_loss": -21.785896369934083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.973748207092285, "step": 50000}
{"episode_reward": 81.47192393910622, "episode": 51.0, "batch_reward": 0.1282901530712843, "critic_loss": 0.39821825331449506, "actor_loss": -22.037488983154297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.48992991447449, "step": 51000}
{"episode_reward": 351.06602939485333, "episode": 52.0, "batch_reward": 0.13260350708663463, "critic_loss": 0.4216141124814749, "actor_loss": -22.01475296783447, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.290640830993652, "step": 52000}
{"episode_reward": 312.4470959064485, "episode": 53.0, "batch_reward": 0.13649905875325202, "critic_loss": 0.41582116490602494, "actor_loss": -22.571304485321043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.217151165008545, "step": 53000}
{"episode_reward": 201.09043143220322, "episode": 54.0, "batch_reward": 0.13801083792746066, "critic_loss": 0.41622159749269483, "actor_loss": -22.817190490722655, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.045125722885132, "step": 54000}
{"episode_reward": 387.86412357403475, "episode": 55.0, "batch_reward": 0.14243370512127876, "critic_loss": 0.4204020748883486, "actor_loss": -23.236047622680665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.045313119888306, "step": 55000}
{"episode_reward": 388.6488192049601, "episode": 56.0, "batch_reward": 0.146514964543283, "critic_loss": 0.42437656420469283, "actor_loss": -24.029692848205567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.007818937301636, "step": 56000}
{"episode_reward": 303.8712904863017, "episode": 57.0, "batch_reward": 0.14961343260109425, "critic_loss": 0.4698367279022932, "actor_loss": -24.098912647247314, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.010239124298096, "step": 57000}
{"episode_reward": 381.4979682305792, "episode": 58.0, "batch_reward": 0.15326611702144147, "critic_loss": 0.48111629877984524, "actor_loss": -24.548007272720337, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.021134614944458, "step": 58000}
{"episode_reward": 256.2392110181626, "episode": 59.0, "batch_reward": 0.15472205764055252, "critic_loss": 0.4616176720559597, "actor_loss": -24.679803606033325, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00226855278015, "step": 59000}
{"episode_reward": 144.8666725324307, "episode": 60.0, "batch_reward": 0.15277567707002163, "critic_loss": 0.4338084990978241, "actor_loss": -24.03052328681946, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.010019779205322, "step": 60000}
{"episode_reward": 49.08398139176681, "episode": 61.0, "batch_reward": 0.15365603488683702, "critic_loss": 0.4476326054930687, "actor_loss": -23.704719326019287, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.38708448410034, "step": 61000}
{"episode_reward": 428.3772884226766, "episode": 62.0, "batch_reward": 0.15591626508533954, "critic_loss": 0.40899996875226496, "actor_loss": -23.962348024368286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.028616189956665, "step": 62000}
{"episode_reward": 64.63425645106517, "episode": 63.0, "batch_reward": 0.1571858089119196, "critic_loss": 0.39319456747174264, "actor_loss": -24.14015026283264, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.028039693832397, "step": 63000}
{"episode_reward": 352.72300572427787, "episode": 64.0, "batch_reward": 0.16030270481854678, "critic_loss": 0.417090309292078, "actor_loss": -24.99947504043579, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.994285106658936, "step": 64000}
{"episode_reward": 401.71327510385385, "episode": 65.0, "batch_reward": 0.16322788329422475, "critic_loss": 0.41694490633904935, "actor_loss": -25.106076154708862, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.020047664642334, "step": 65000}
{"episode_reward": 429.77682190981614, "episode": 66.0, "batch_reward": 0.1682772060036659, "critic_loss": 0.43949316000938415, "actor_loss": -25.421570934295655, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0080406665802, "step": 66000}
{"episode_reward": 459.5535443247841, "episode": 67.0, "batch_reward": 0.17247280812263488, "critic_loss": 0.4273889532983303, "actor_loss": -25.017838315963743, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99558115005493, "step": 67000}
{"episode_reward": 394.3879114806688, "episode": 68.0, "batch_reward": 0.17551055482029915, "critic_loss": 0.4213195348829031, "actor_loss": -25.864306566238405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.017194747924805, "step": 68000}
{"episode_reward": 243.28271174730514, "episode": 69.0, "batch_reward": 0.17702797283232213, "critic_loss": 0.41073929993808267, "actor_loss": -25.645296501159667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01143527030945, "step": 69000}
{"episode_reward": 429.98449935337305, "episode": 70.0, "batch_reward": 0.18092025989294053, "critic_loss": 0.4389006284177303, "actor_loss": -25.79574680900574, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.003863096237183, "step": 70000}
{"episode_reward": 439.7626613812608, "episode": 71.0, "batch_reward": 0.1840132726728916, "critic_loss": 0.4342422570735216, "actor_loss": -26.011926191329955, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.43731713294983, "step": 71000}
{"episode_reward": 258.71619838258067, "episode": 72.0, "batch_reward": 0.18349275453388691, "critic_loss": 0.45758483597636224, "actor_loss": -26.090097131729127, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.009430646896362, "step": 72000}
{"episode_reward": 163.10928804524556, "episode": 73.0, "batch_reward": 0.1840363091081381, "critic_loss": 0.39579247030615805, "actor_loss": -26.25375075149536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01391053199768, "step": 73000}
{"episode_reward": 408.32897985657803, "episode": 74.0, "batch_reward": 0.18603504402935506, "critic_loss": 0.39548697040975095, "actor_loss": -26.389259624481202, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.989400386810303, "step": 74000}
{"episode_reward": 146.54103596501267, "episode": 75.0, "batch_reward": 0.18642235159873963, "critic_loss": 0.42550076474249365, "actor_loss": -26.86051064300537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.963138818740845, "step": 75000}
{"episode_reward": 233.18171093681002, "episode": 76.0, "batch_reward": 0.18768145950138568, "critic_loss": 0.4065598350018263, "actor_loss": -26.493821338653564, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0163836479187, "step": 76000}
{"episode_reward": 444.96437700068066, "episode": 77.0, "batch_reward": 0.19177549996972085, "critic_loss": 0.40724653509259223, "actor_loss": -26.94915817832947, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.983482360839844, "step": 77000}
{"episode_reward": 417.6171471686617, "episode": 78.0, "batch_reward": 0.19391174603998662, "critic_loss": 0.4219119430631399, "actor_loss": -26.99523394393921, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.998820781707764, "step": 78000}
{"episode_reward": 432.35013344785824, "episode": 79.0, "batch_reward": 0.19678090131282808, "critic_loss": 0.4259485108107328, "actor_loss": -27.51161827659607, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0216965675354, "step": 79000}
{"episode_reward": 375.9350461799842, "episode": 80.0, "batch_reward": 0.1996204991787672, "critic_loss": 0.4067845516204834, "actor_loss": -27.692339820861818, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.97976016998291, "step": 80000}
{"episode_reward": 446.824757771236, "episode": 81.0, "batch_reward": 0.2020408880710602, "critic_loss": 0.41313130120933056, "actor_loss": -27.679039043426513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.39427042007446, "step": 81000}
{"episode_reward": 436.56991564834465, "episode": 82.0, "batch_reward": 0.2047936804294586, "critic_loss": 0.39704362796247006, "actor_loss": -27.997884998321535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01044464111328, "step": 82000}
{"episode_reward": 413.1116476436312, "episode": 83.0, "batch_reward": 0.20828887625038625, "critic_loss": 0.38353421321511266, "actor_loss": -27.869814334869385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02312707901001, "step": 83000}
{"episode_reward": 374.0413486462699, "episode": 84.0, "batch_reward": 0.20868622875213624, "critic_loss": 0.40974748429656027, "actor_loss": -28.113856212615968, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.017184019088745, "step": 84000}
{"episode_reward": 391.8171750805289, "episode": 85.0, "batch_reward": 0.21183811086416243, "critic_loss": 0.4072086527198553, "actor_loss": -28.433632038116453, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99541735649109, "step": 85000}
{"episode_reward": 448.343717170045, "episode": 86.0, "batch_reward": 0.21439011317491533, "critic_loss": 0.38199346570670606, "actor_loss": -28.370656246185302, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.014152765274048, "step": 86000}
{"episode_reward": 491.08718426088933, "episode": 87.0, "batch_reward": 0.21797515209019183, "critic_loss": 0.4113389963209629, "actor_loss": -28.49559679031372, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.003532648086548, "step": 87000}
{"episode_reward": 474.53935577423084, "episode": 88.0, "batch_reward": 0.2209429829865694, "critic_loss": 0.3905438249707222, "actor_loss": -28.992488216400147, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.021273374557495, "step": 88000}
{"episode_reward": 500.81128331894644, "episode": 89.0, "batch_reward": 0.22367666892707347, "critic_loss": 0.3769439789801836, "actor_loss": -29.339141162872316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.031946182250977, "step": 89000}
{"episode_reward": 466.08123398766764, "episode": 90.0, "batch_reward": 0.22630482694506646, "critic_loss": 0.3845495643615723, "actor_loss": -29.366958404541016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.017195224761963, "step": 90000}
{"episode_reward": 441.6413422702596, "episode": 91.0, "batch_reward": 0.22905291305482386, "critic_loss": 0.37660086883604527, "actor_loss": -29.849312408447265, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.400676012039185, "step": 91000}
{"episode_reward": 404.1709346748318, "episode": 92.0, "batch_reward": 0.2299932145923376, "critic_loss": 0.3566596126705408, "actor_loss": -28.938536876678466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.995943069458008, "step": 92000}
{"episode_reward": 481.56496971119697, "episode": 93.0, "batch_reward": 0.23377473446726799, "critic_loss": 0.3916402852833271, "actor_loss": -29.95593468093872, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.006775379180908, "step": 93000}
{"episode_reward": 403.4205591694022, "episode": 94.0, "batch_reward": 0.2360702554732561, "critic_loss": 0.37701873598992824, "actor_loss": -29.704008071899413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.030093908309937, "step": 94000}
{"episode_reward": 506.3904757343252, "episode": 95.0, "batch_reward": 0.23783096455037595, "critic_loss": 0.3973972827196121, "actor_loss": -30.342491962432863, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.9781596660614, "step": 95000}
{"episode_reward": 471.79253866989046, "episode": 96.0, "batch_reward": 0.24153955920040607, "critic_loss": 0.38078392623364926, "actor_loss": -30.266770973205567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.005865335464478, "step": 96000}
{"episode_reward": 452.37448909222104, "episode": 97.0, "batch_reward": 0.24246736977994443, "critic_loss": 0.34975134275853637, "actor_loss": -30.65699279022217, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01997447013855, "step": 97000}
{"episode_reward": 469.13935729247567, "episode": 98.0, "batch_reward": 0.2469253308773041, "critic_loss": 0.39743516412377355, "actor_loss": -31.346718353271484, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.980671167373657, "step": 98000}
{"episode_reward": 480.27037208093526, "episode": 99.0, "batch_reward": 0.2480625695735216, "critic_loss": 0.3924117596000433, "actor_loss": -31.080432037353514, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01541566848755, "step": 99000}
{"episode_reward": 519.873483937851, "episode": 100.0, "batch_reward": 0.250098623290658, "critic_loss": 0.3840969549268484, "actor_loss": -31.369332538604738, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02502727508545, "step": 100000}
{"episode_reward": 513.5115273392224, "episode": 101.0, "batch_reward": 0.25257868856191634, "critic_loss": 0.37985563556849955, "actor_loss": -31.063041370391847, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.40354657173157, "step": 101000}
{"episode_reward": 474.7016545382633, "episode": 102.0, "batch_reward": 0.2555043358653784, "critic_loss": 0.4235860887616873, "actor_loss": -31.71988148498535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01312279701233, "step": 102000}
{"episode_reward": 525.78369910764, "episode": 103.0, "batch_reward": 0.2574943659901619, "critic_loss": 0.3750729434788227, "actor_loss": -31.518090938568115, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.03136944770813, "step": 103000}
{"episode_reward": 452.0019957863137, "episode": 104.0, "batch_reward": 0.2602712070196867, "critic_loss": 0.42217494270205497, "actor_loss": -32.43732035446167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.034868240356445, "step": 104000}
{"episode_reward": 339.5504845980942, "episode": 105.0, "batch_reward": 0.25994040407240393, "critic_loss": 0.3775360100567341, "actor_loss": -31.77602717208862, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.03324604034424, "step": 105000}
{"episode_reward": 400.9015340670003, "episode": 106.0, "batch_reward": 0.2607357326298952, "critic_loss": 0.406391018986702, "actor_loss": -32.02023600769043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02303409576416, "step": 106000}
{"episode_reward": 183.30831379205583, "episode": 107.0, "batch_reward": 0.26026821781694887, "critic_loss": 0.4106315142512321, "actor_loss": -32.18191265869141, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.014694452285767, "step": 107000}
{"episode_reward": 486.8750307583101, "episode": 108.0, "batch_reward": 0.2631569750159979, "critic_loss": 0.4298438209295273, "actor_loss": -32.28892432022095, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01842188835144, "step": 108000}
{"episode_reward": 481.6767747984605, "episode": 109.0, "batch_reward": 0.2656001092791557, "critic_loss": 0.3985574649721384, "actor_loss": -32.5083249092102, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.03582215309143, "step": 109000}
{"episode_reward": 418.02594878955017, "episode": 110.0, "batch_reward": 0.26678661453723906, "critic_loss": 0.3817034669071436, "actor_loss": -32.69148610687256, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00110626220703, "step": 110000}
{"episode_reward": 513.6917956870138, "episode": 111.0, "batch_reward": 0.2686026680469513, "critic_loss": 0.3872407736033201, "actor_loss": -32.37623690032959, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.43855690956116, "step": 111000}
{"episode_reward": 512.9708247939441, "episode": 112.0, "batch_reward": 0.27100018237531187, "critic_loss": 0.37128133772313593, "actor_loss": -32.921293766021726, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00920009613037, "step": 112000}
{"episode_reward": 488.66438599706385, "episode": 113.0, "batch_reward": 0.2744738984853029, "critic_loss": 0.3721068333238363, "actor_loss": -32.43435869598389, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01081657409668, "step": 113000}
{"episode_reward": 527.7209269722454, "episode": 114.0, "batch_reward": 0.2756620835363865, "critic_loss": 0.36479866184294224, "actor_loss": -33.214290412902834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.059223413467407, "step": 114000}
{"episode_reward": 496.19422302138406, "episode": 115.0, "batch_reward": 0.2778180020749569, "critic_loss": 0.3710429077148438, "actor_loss": -33.90697476959229, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.006139039993286, "step": 115000}
{"episode_reward": 509.0610153754653, "episode": 116.0, "batch_reward": 0.2789805334955454, "critic_loss": 0.382031496360898, "actor_loss": -33.39725967025757, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.004451513290405, "step": 116000}
{"episode_reward": 557.3437771939197, "episode": 117.0, "batch_reward": 0.2816221799701452, "critic_loss": 0.38372110433876516, "actor_loss": -33.7977537689209, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.018808603286743, "step": 117000}
{"episode_reward": 500.7687941461045, "episode": 118.0, "batch_reward": 0.28300017157197, "critic_loss": 0.37204764983057975, "actor_loss": -33.732288665771485, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.021080017089844, "step": 118000}
{"episode_reward": 483.74526132713333, "episode": 119.0, "batch_reward": 0.2853053071796894, "critic_loss": 0.37749518233537677, "actor_loss": -34.018577796936036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.999561071395874, "step": 119000}
{"episode_reward": 538.464896105053, "episode": 120.0, "batch_reward": 0.2876345498561859, "critic_loss": 0.3758877128064632, "actor_loss": -34.39014570999146, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0234477519989, "step": 120000}
{"episode_reward": 522.2577483710177, "episode": 121.0, "batch_reward": 0.2896871923208237, "critic_loss": 0.39010929253697396, "actor_loss": -34.5118952331543, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.43297362327576, "step": 121000}
{"episode_reward": 499.84765206673444, "episode": 122.0, "batch_reward": 0.2918007782995701, "critic_loss": 0.39516529040038584, "actor_loss": -34.978192070007324, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.015055418014526, "step": 122000}
{"episode_reward": 545.6590934822011, "episode": 123.0, "batch_reward": 0.29333680817484853, "critic_loss": 0.3943896614909172, "actor_loss": -35.27166484451294, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99052882194519, "step": 123000}
{"episode_reward": 508.25384662789537, "episode": 124.0, "batch_reward": 0.29474457061290743, "critic_loss": 0.39385322608053686, "actor_loss": -35.13409229660034, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.417221784591675, "step": 124000}
{"episode_reward": 484.3023968353191, "episode": 125.0, "batch_reward": 0.2964645828306675, "critic_loss": 0.35707982058823107, "actor_loss": -35.31809059143066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.017942190170288, "step": 125000}
{"episode_reward": 531.4656621478371, "episode": 126.0, "batch_reward": 0.29791845843195913, "critic_loss": 0.3812681273967028, "actor_loss": -35.71461484909057, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.978652715682983, "step": 126000}
{"episode_reward": 564.565660441995, "episode": 127.0, "batch_reward": 0.29987185934185984, "critic_loss": 0.3759274261146784, "actor_loss": -35.39492868423462, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02249002456665, "step": 127000}
{"episode_reward": 533.9536409803617, "episode": 128.0, "batch_reward": 0.30232815733551976, "critic_loss": 0.36210381183028223, "actor_loss": -35.378592342376706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.023785829544067, "step": 128000}
{"episode_reward": 548.1136787035072, "episode": 129.0, "batch_reward": 0.3044961596429348, "critic_loss": 0.3807872972488403, "actor_loss": -35.707284576416015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.023661851882935, "step": 129000}
{"episode_reward": 471.9521509190297, "episode": 130.0, "batch_reward": 0.30601581382751464, "critic_loss": 0.36711306634545326, "actor_loss": -35.78692840194702, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00968289375305, "step": 130000}
{"episode_reward": 499.0759459790091, "episode": 131.0, "batch_reward": 0.3052906753271818, "critic_loss": 0.37249344889819624, "actor_loss": -35.14876779556275, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.467355728149414, "step": 131000}
{"episode_reward": 92.92557738171358, "episode": 132.0, "batch_reward": 0.30472541476786136, "critic_loss": 0.38183087508380414, "actor_loss": -35.56613843154907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01532554626465, "step": 132000}
{"episode_reward": 536.0844161412264, "episode": 133.0, "batch_reward": 0.3061705391258001, "critic_loss": 0.3549642804712057, "actor_loss": -35.91727866363525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.033262252807617, "step": 133000}
{"episode_reward": 526.3895675230265, "episode": 134.0, "batch_reward": 0.307423685118556, "critic_loss": 0.3533913713693619, "actor_loss": -36.09023806381226, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.995049953460693, "step": 134000}
{"episode_reward": 248.50017658515225, "episode": 135.0, "batch_reward": 0.3085961799323559, "critic_loss": 0.3806112382411957, "actor_loss": -36.28100954437256, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02005362510681, "step": 135000}
{"episode_reward": 542.410716623568, "episode": 136.0, "batch_reward": 0.3092617503106594, "critic_loss": 0.3732382693588734, "actor_loss": -36.41404686355591, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01710605621338, "step": 136000}
{"episode_reward": 592.606772009943, "episode": 137.0, "batch_reward": 0.31153623458743096, "critic_loss": 0.35740305268764494, "actor_loss": -36.537670673370364, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99837636947632, "step": 137000}
{"episode_reward": 151.14632433651218, "episode": 138.0, "batch_reward": 0.3102302604466677, "critic_loss": 0.3586450841128826, "actor_loss": -35.52466389846802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.037013053894043, "step": 138000}
{"episode_reward": 582.3036244092077, "episode": 139.0, "batch_reward": 0.31363084772229194, "critic_loss": 0.38544396321475505, "actor_loss": -35.726639945983884, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05113458633423, "step": 139000}
{"episode_reward": 597.2145489884067, "episode": 140.0, "batch_reward": 0.31494707843661307, "critic_loss": 0.37037656374275685, "actor_loss": -36.159750408172606, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99980902671814, "step": 140000}
{"episode_reward": 548.0789833498856, "episode": 141.0, "batch_reward": 0.31685508555173875, "critic_loss": 0.396419022038579, "actor_loss": -36.869678699493406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.43358063697815, "step": 141000}
{"episode_reward": 611.9190184731758, "episode": 142.0, "batch_reward": 0.31800726675987245, "critic_loss": 0.4186078889518976, "actor_loss": -36.578136528015136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.014757871627808, "step": 142000}
{"episode_reward": 556.4793922703864, "episode": 143.0, "batch_reward": 0.3202080675661564, "critic_loss": 0.4278087862730026, "actor_loss": -37.1763726272583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99332022666931, "step": 143000}
{"episode_reward": 546.9729716141044, "episode": 144.0, "batch_reward": 0.3226769296228886, "critic_loss": 0.410204953327775, "actor_loss": -36.955589767456054, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.013673543930054, "step": 144000}
{"episode_reward": 563.2503255948129, "episode": 145.0, "batch_reward": 0.324037470638752, "critic_loss": 0.41570833083987235, "actor_loss": -37.88248317337036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.986816883087158, "step": 145000}
{"episode_reward": 570.346742164471, "episode": 146.0, "batch_reward": 0.32427678047120573, "critic_loss": 0.43689964060485365, "actor_loss": -36.869759815216064, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.008166074752808, "step": 146000}
{"episode_reward": 262.49725671974306, "episode": 147.0, "batch_reward": 0.3255802105665207, "critic_loss": 0.4539473547488451, "actor_loss": -37.34616778564453, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.011342525482178, "step": 147000}
{"episode_reward": 536.8277318123462, "episode": 148.0, "batch_reward": 0.3253616234064102, "critic_loss": 0.4287455646246672, "actor_loss": -37.37282334899902, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01315927505493, "step": 148000}
{"episode_reward": 594.4217310455201, "episode": 149.0, "batch_reward": 0.3280212564468384, "critic_loss": 0.5010850034654141, "actor_loss": -37.41663568115234, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.015488624572754, "step": 149000}
{"episode_reward": 593.0047781449176, "episode": 150.0, "batch_reward": 0.3300122286081314, "critic_loss": 0.483112468957901, "actor_loss": -37.45325029373169, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
