{"episode_reward": 0.0, "episode": 1.0, "duration": 15.204686880111694, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.3174116611480713, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.2883267214235444, "critic_loss": 0.15013223011500043, "actor_loss": -47.24278822704619, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 73.14656901359558, "step": 3000}
{"episode_reward": 567.5477470701159, "episode": 4.0, "batch_reward": 0.34145309306681154, "critic_loss": 0.20365514907985927, "actor_loss": -50.12124813842773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.112595081329346, "step": 4000}
{"episode_reward": 96.3749048731994, "episode": 5.0, "batch_reward": 0.3191258539110422, "critic_loss": 0.270629572339356, "actor_loss": -46.64074044036865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.26532006263733, "step": 5000}
{"episode_reward": 500.301724774922, "episode": 6.0, "batch_reward": 0.3148655135631561, "critic_loss": 0.44776995620131493, "actor_loss": -46.74748917388916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.200992107391357, "step": 6000}
{"episode_reward": 15.861084894488497, "episode": 7.0, "batch_reward": 0.29145434948801996, "critic_loss": 0.3884801695197821, "actor_loss": -44.36045991516113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.0847909450531, "step": 7000}
{"episode_reward": 385.60172700952694, "episode": 8.0, "batch_reward": 0.2829685550034046, "critic_loss": 0.345446367546916, "actor_loss": -44.441883476257324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.025516510009766, "step": 8000}
{"episode_reward": 6.065126652495088, "episode": 9.0, "batch_reward": 0.25153022579848766, "critic_loss": 0.271746538490057, "actor_loss": -44.0050421295166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.19083285331726, "step": 9000}
{"episode_reward": 5.073475833272561, "episode": 10.0, "batch_reward": 0.22381303377449513, "critic_loss": 0.2816651099771261, "actor_loss": -43.94957426452637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.39175295829773, "step": 10000}
{"episode_reward": 2.817425024521159, "episode": 11.0, "batch_reward": 0.20441202561557292, "critic_loss": 0.31152943085134027, "actor_loss": -42.69305419921875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.18442487716675, "step": 11000}
{"episode_reward": 67.28442921060942, "episode": 12.0, "batch_reward": 0.19981102910637855, "critic_loss": 0.3562014601379633, "actor_loss": -43.068020805358884, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.856624364852905, "step": 12000}
{"episode_reward": 350.8074989085969, "episode": 13.0, "batch_reward": 0.22092591886222362, "critic_loss": 0.3576044376045465, "actor_loss": -43.97969923400879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.152286052703857, "step": 13000}
{"episode_reward": 521.2834814573872, "episode": 14.0, "batch_reward": 0.24584499484300612, "critic_loss": 0.3707567263841629, "actor_loss": -44.69956586456299, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.569334268569946, "step": 14000}
{"episode_reward": 574.4178174992305, "episode": 15.0, "batch_reward": 0.2652963675558567, "critic_loss": 0.5192638047635555, "actor_loss": -45.854549949646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.602068424224854, "step": 15000}
{"episode_reward": 450.87183246759565, "episode": 16.0, "batch_reward": 0.27559778758883474, "critic_loss": 0.6286338858753443, "actor_loss": -46.1009649810791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.092256784439087, "step": 16000}
{"episode_reward": 282.6475739468013, "episode": 17.0, "batch_reward": 0.27233505026996135, "critic_loss": 0.5511444153636694, "actor_loss": -44.994547019958496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.25668215751648, "step": 17000}
{"episode_reward": 374.9387385528305, "episode": 18.0, "batch_reward": 0.2870214917808771, "critic_loss": 0.5151655801832676, "actor_loss": -45.57346041107178, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.088303327560425, "step": 18000}
{"episode_reward": 604.2533518326767, "episode": 19.0, "batch_reward": 0.29895601123571397, "critic_loss": 0.5643509457260371, "actor_loss": -45.779226943969725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.011507272720337, "step": 19000}
{"episode_reward": 460.5525985664846, "episode": 20.0, "batch_reward": 0.31090594720840453, "critic_loss": 0.5028641698211431, "actor_loss": -46.5950280380249, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.567315340042114, "step": 20000}
{"episode_reward": 575.5661546792912, "episode": 21.0, "batch_reward": 0.325711581364274, "critic_loss": 0.5158328805565834, "actor_loss": -46.70952799987793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.5001745223999, "step": 21000}
{"episode_reward": 585.7602085575966, "episode": 22.0, "batch_reward": 0.3341664348691702, "critic_loss": 0.7637773435115814, "actor_loss": -47.36273574066162, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.141071319580078, "step": 22000}
{"episode_reward": 382.77132906647006, "episode": 23.0, "batch_reward": 0.3353577981591225, "critic_loss": 1.469480079948902, "actor_loss": -46.817825164794925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.017914056777954, "step": 23000}
{"episode_reward": 310.27778379319466, "episode": 24.0, "batch_reward": 0.33639055970311166, "critic_loss": 1.3453724214434624, "actor_loss": -46.49083930969238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.384902000427246, "step": 24000}
{"episode_reward": 562.2929966251266, "episode": 25.0, "batch_reward": 0.34432155352830884, "critic_loss": 1.2322411506474018, "actor_loss": -46.95676638031006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.333369970321655, "step": 25000}
{"episode_reward": 580.6055215301499, "episode": 26.0, "batch_reward": 0.35674735632538795, "critic_loss": 1.1235997741818429, "actor_loss": -47.47851091766358, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.243990898132324, "step": 26000}
{"episode_reward": 633.3673699065074, "episode": 27.0, "batch_reward": 0.3575569189488888, "critic_loss": 1.0492290806472302, "actor_loss": -47.54361328887939, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.074637174606323, "step": 27000}
{"episode_reward": 47.26837504354218, "episode": 28.0, "batch_reward": 0.3536580805182457, "critic_loss": 0.9691984776854515, "actor_loss": -47.17357402801514, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.24760913848877, "step": 28000}
{"episode_reward": 554.0709209561068, "episode": 29.0, "batch_reward": 0.3619641127586365, "critic_loss": 0.9167214494347572, "actor_loss": -47.371369621276855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.193502187728882, "step": 29000}
{"episode_reward": 636.4175283314422, "episode": 30.0, "batch_reward": 0.3712708979845047, "critic_loss": 0.9522377941310406, "actor_loss": -47.91492551422119, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.9778151512146, "step": 30000}
{"episode_reward": 615.6118199517879, "episode": 31.0, "batch_reward": 0.3796117738485336, "critic_loss": 0.8820697222054005, "actor_loss": -48.75307528686523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.94932270050049, "step": 31000}
{"episode_reward": 631.1476465774981, "episode": 32.0, "batch_reward": 0.3877745635509491, "critic_loss": 0.9261852056384087, "actor_loss": -48.95232300567627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5054349899292, "step": 32000}
{"episode_reward": 671.1649503622523, "episode": 33.0, "batch_reward": 0.3961609646677971, "critic_loss": 1.0479911792576313, "actor_loss": -49.66905407714844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.167903184890747, "step": 33000}
{"episode_reward": 616.7769630862518, "episode": 34.0, "batch_reward": 0.40378496593236923, "critic_loss": 1.255082363128662, "actor_loss": -50.00858341217041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.875936031341553, "step": 34000}
{"episode_reward": 408.46152781411826, "episode": 35.0, "batch_reward": 0.40215710759162904, "critic_loss": 1.3644782840013503, "actor_loss": -49.663444137573244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.239529371261597, "step": 35000}
{"episode_reward": 501.0635734096008, "episode": 36.0, "batch_reward": 0.4043645825088024, "critic_loss": 1.3422784872651101, "actor_loss": -49.930968139648435, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.33415985107422, "step": 36000}
{"episode_reward": 472.2237371420539, "episode": 37.0, "batch_reward": 0.406621993124485, "critic_loss": 1.1055871954858303, "actor_loss": -49.740223442077635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.83864402770996, "step": 37000}
{"episode_reward": 548.6069545490186, "episode": 38.0, "batch_reward": 0.4101704872846603, "critic_loss": 1.1328952063024045, "actor_loss": -49.6096128692627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.69653820991516, "step": 38000}
{"episode_reward": 602.2139517180332, "episode": 39.0, "batch_reward": 0.41617099988460543, "critic_loss": 0.9849666341841221, "actor_loss": -49.721939140319826, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.503108024597168, "step": 39000}
{"episode_reward": 654.3853943339873, "episode": 40.0, "batch_reward": 0.4214758684039116, "critic_loss": 0.9112824169099331, "actor_loss": -49.9187274017334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.192429065704346, "step": 40000}
{"episode_reward": 612.936585315488, "episode": 41.0, "batch_reward": 0.4236180832386017, "critic_loss": 0.8611988196372986, "actor_loss": -49.7680983505249, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.73501658439636, "step": 41000}
{"episode_reward": 482.21012791771807, "episode": 42.0, "batch_reward": 0.42767870739102365, "critic_loss": 0.8426415001451969, "actor_loss": -49.91851113128662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.662357568740845, "step": 42000}
{"episode_reward": 588.8988272105336, "episode": 43.0, "batch_reward": 0.4333613769412041, "critic_loss": 0.7992456524968147, "actor_loss": -50.034388473510745, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.512852907180786, "step": 43000}
{"episode_reward": 641.8320877645652, "episode": 44.0, "batch_reward": 0.4343181828260422, "critic_loss": 0.7583089784383774, "actor_loss": -49.911101928710934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.304316520690918, "step": 44000}
{"episode_reward": 627.6399184120228, "episode": 45.0, "batch_reward": 0.4411750513613224, "critic_loss": 0.7466128145754337, "actor_loss": -50.107551071166995, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.40411400794983, "step": 45000}
{"episode_reward": 451.2964712912659, "episode": 46.0, "batch_reward": 0.44090578269958497, "critic_loss": 0.757572285592556, "actor_loss": -49.8863945236206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.956712007522583, "step": 46000}
{"episode_reward": 640.2609682653415, "episode": 47.0, "batch_reward": 0.4436546024084091, "critic_loss": 0.7713258170485496, "actor_loss": -49.92299917602539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.956246852874756, "step": 47000}
{"episode_reward": 436.07993787363745, "episode": 48.0, "batch_reward": 0.44468324971199036, "critic_loss": 0.7355842228233814, "actor_loss": -49.86956379699707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.048826456069946, "step": 48000}
{"episode_reward": 617.6891463350411, "episode": 49.0, "batch_reward": 0.4487345535755157, "critic_loss": 0.7264671430587769, "actor_loss": -50.04929077911377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16601872444153, "step": 49000}
{"episode_reward": 493.90792026651127, "episode": 50.0, "batch_reward": 0.44990998804569243, "critic_loss": 0.7168835690021514, "actor_loss": -50.044799629211425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.747295141220093, "step": 50000}
{"episode_reward": 630.506051574095, "episode": 51.0, "batch_reward": 0.45402774775028226, "critic_loss": 0.7209186578392982, "actor_loss": -50.323333152771, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.27285695075989, "step": 51000}
{"episode_reward": 605.0006936527556, "episode": 52.0, "batch_reward": 0.45558088168501853, "critic_loss": 0.7256160601079464, "actor_loss": -50.375206298828125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.378915548324585, "step": 52000}
{"episode_reward": 620.4881299088281, "episode": 53.0, "batch_reward": 0.4597914900183678, "critic_loss": 0.6731106055676938, "actor_loss": -50.43000385284424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.021522760391235, "step": 53000}
{"episode_reward": 609.9394924050346, "episode": 54.0, "batch_reward": 0.4620420699119568, "critic_loss": 0.647510942041874, "actor_loss": -50.50436711883545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.248387336730957, "step": 54000}
{"episode_reward": 610.5246447669444, "episode": 55.0, "batch_reward": 0.46063853001594546, "critic_loss": 0.6495017026364803, "actor_loss": -50.223595405578614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.01425337791443, "step": 55000}
{"episode_reward": 343.65930520472733, "episode": 56.0, "batch_reward": 0.4614261249899864, "critic_loss": 0.6516571216583252, "actor_loss": -50.2314709854126, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.900267362594604, "step": 56000}
{"episode_reward": 587.077404742916, "episode": 57.0, "batch_reward": 0.4651022854745388, "critic_loss": 0.6386972681879998, "actor_loss": -50.33475186920166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.89602255821228, "step": 57000}
{"episode_reward": 638.8122018470278, "episode": 58.0, "batch_reward": 0.46667892384529114, "critic_loss": 0.6110301862061024, "actor_loss": -50.31628330993652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.00398302078247, "step": 58000}
{"episode_reward": 544.0119626919093, "episode": 59.0, "batch_reward": 0.469529179751873, "critic_loss": 0.5887280322909355, "actor_loss": -50.578951034545895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.982576370239258, "step": 59000}
{"episode_reward": 599.5925048050731, "episode": 60.0, "batch_reward": 0.47193265753984454, "critic_loss": 0.5983689858615399, "actor_loss": -50.77395363616943, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22014284133911, "step": 60000}
{"episode_reward": 575.5723470981296, "episode": 61.0, "batch_reward": 0.4719127049744129, "critic_loss": 0.6010886408686638, "actor_loss": -50.749535591125486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.664106369018555, "step": 61000}
{"episode_reward": 631.0786363424995, "episode": 62.0, "batch_reward": 0.47470823988318445, "critic_loss": 0.6069923017323017, "actor_loss": -51.0580369720459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.483854293823242, "step": 62000}
{"episode_reward": 607.6022120685099, "episode": 63.0, "batch_reward": 0.4788746860921383, "critic_loss": 0.6262570041418075, "actor_loss": -51.123600730895994, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.80804467201233, "step": 63000}
{"episode_reward": 632.8159281949228, "episode": 64.0, "batch_reward": 0.48131955942511556, "critic_loss": 0.6180869687497615, "actor_loss": -51.05283051300049, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.004454374313354, "step": 64000}
{"episode_reward": 603.3876766538949, "episode": 65.0, "batch_reward": 0.48290688574314117, "critic_loss": 0.6281479378044605, "actor_loss": -51.26423764038086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.19513988494873, "step": 65000}
{"episode_reward": 658.217397460724, "episode": 66.0, "batch_reward": 0.48502194249629976, "critic_loss": 0.64805668130517, "actor_loss": -51.488864723205566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.333582401275635, "step": 66000}
{"episode_reward": 536.6714891817459, "episode": 67.0, "batch_reward": 0.4862676395177841, "critic_loss": 0.668927333265543, "actor_loss": -51.45704981994629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.175873517990112, "step": 67000}
{"episode_reward": 627.1280169455321, "episode": 68.0, "batch_reward": 0.48904747715592384, "critic_loss": 0.6884527196586132, "actor_loss": -51.67293292236328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16896939277649, "step": 68000}
{"episode_reward": 604.7727739332693, "episode": 69.0, "batch_reward": 0.49027267134189606, "critic_loss": 0.6940119120776653, "actor_loss": -51.56472030639648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.37364912033081, "step": 69000}
{"episode_reward": 603.3098188596344, "episode": 70.0, "batch_reward": 0.4904479414522648, "critic_loss": 0.6633252252042293, "actor_loss": -52.041740692138674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.363688945770264, "step": 70000}
{"episode_reward": 655.1827613034527, "episode": 71.0, "batch_reward": 0.49442293906211854, "critic_loss": 0.6979458754956722, "actor_loss": -51.89383881378174, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.55987572669983, "step": 71000}
{"episode_reward": 657.2086207340791, "episode": 72.0, "batch_reward": 0.49601992750167845, "critic_loss": 0.67981716299057, "actor_loss": -52.18427741241455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.378177642822266, "step": 72000}
{"episode_reward": 617.5144719159216, "episode": 73.0, "batch_reward": 0.49863687351346014, "critic_loss": 0.6856186245381832, "actor_loss": -52.1247476348877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.024725437164307, "step": 73000}
{"episode_reward": 610.4699408013961, "episode": 74.0, "batch_reward": 0.49935600319504736, "critic_loss": 0.6671136979460717, "actor_loss": -52.22511754608154, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.307021379470825, "step": 74000}
{"episode_reward": 660.6004022500395, "episode": 75.0, "batch_reward": 0.5015468409955501, "critic_loss": 0.6624601089060307, "actor_loss": -52.1652174911499, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.831789255142212, "step": 75000}
{"episode_reward": 646.289146484105, "episode": 76.0, "batch_reward": 0.5041194870769977, "critic_loss": 0.6463557063043117, "actor_loss": -52.44881664276123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.4834406375885, "step": 76000}
{"episode_reward": 669.4197148551513, "episode": 77.0, "batch_reward": 0.5049394784271717, "critic_loss": 0.6398481031060219, "actor_loss": -52.51492835235596, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.925033807754517, "step": 77000}
{"episode_reward": 654.5368335784248, "episode": 78.0, "batch_reward": 0.5078761664032936, "critic_loss": 0.6331232203841209, "actor_loss": -52.96550569152832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.7968168258667, "step": 78000}
{"episode_reward": 655.8389826437143, "episode": 79.0, "batch_reward": 0.5103524379730224, "critic_loss": 0.6527741778790951, "actor_loss": -52.833610565185545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.307434797286987, "step": 79000}
{"episode_reward": 636.4380820719726, "episode": 80.0, "batch_reward": 0.5108584395945072, "critic_loss": 0.6262747076451778, "actor_loss": -52.91947399902344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.041335582733154, "step": 80000}
{"episode_reward": 676.6354627815025, "episode": 81.0, "batch_reward": 0.5116392856836319, "critic_loss": 0.5847083494067192, "actor_loss": -53.000458053588865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.82231640815735, "step": 81000}
{"episode_reward": 613.9718638395605, "episode": 82.0, "batch_reward": 0.5134473861455917, "critic_loss": 0.5580637221336364, "actor_loss": -53.06547821044922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.850708484649658, "step": 82000}
{"episode_reward": 643.1597794491812, "episode": 83.0, "batch_reward": 0.5154807288050651, "critic_loss": 0.596037716537714, "actor_loss": -53.529549278259275, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.998393058776855, "step": 83000}
{"episode_reward": 658.6785962265515, "episode": 84.0, "batch_reward": 0.5165847933590412, "critic_loss": 0.6037538201510906, "actor_loss": -53.49525064086914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.003039836883545, "step": 84000}
{"episode_reward": 627.6114694664853, "episode": 85.0, "batch_reward": 0.5196834803521633, "critic_loss": 0.5759645541012287, "actor_loss": -53.67157642364502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.18355631828308, "step": 85000}
{"episode_reward": 657.1838207994158, "episode": 86.0, "batch_reward": 0.5198295362591744, "critic_loss": 0.5346443494558334, "actor_loss": -53.52777745056152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.239413022994995, "step": 86000}
{"episode_reward": 615.1066953169823, "episode": 87.0, "batch_reward": 0.5214681101441383, "critic_loss": 0.5479183382987977, "actor_loss": -53.85203340148926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.99886131286621, "step": 87000}
{"episode_reward": 640.6528310113139, "episode": 88.0, "batch_reward": 0.5228658453822136, "critic_loss": 0.5499003576338292, "actor_loss": -54.008587951660154, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.193635940551758, "step": 88000}
{"episode_reward": 599.1660808365763, "episode": 89.0, "batch_reward": 0.5236898345053196, "critic_loss": 0.562722148090601, "actor_loss": -54.0798177947998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.094409942626953, "step": 89000}
{"episode_reward": 646.5291354388244, "episode": 90.0, "batch_reward": 0.5246352731883526, "critic_loss": 0.5848340154588223, "actor_loss": -53.874339736938474, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.697806119918823, "step": 90000}
{"episode_reward": 375.27899307878647, "episode": 91.0, "batch_reward": 0.5235824297070504, "critic_loss": 0.585373434394598, "actor_loss": -53.83336254882813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.36260986328125, "step": 91000}
{"episode_reward": 670.0848619879915, "episode": 92.0, "batch_reward": 0.5234910054504871, "critic_loss": 0.5673226239979268, "actor_loss": -54.03914881134033, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.302801370620728, "step": 92000}
{"episode_reward": 663.1168636930403, "episode": 93.0, "batch_reward": 0.5265129388868809, "critic_loss": 0.5527850761115551, "actor_loss": -54.07334693908692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.916961193084717, "step": 93000}
{"episode_reward": 667.4145608454392, "episode": 94.0, "batch_reward": 0.5281876433193684, "critic_loss": 0.5791288922429085, "actor_loss": -54.45022927093506, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.85799765586853, "step": 94000}
{"episode_reward": 630.9956810031359, "episode": 95.0, "batch_reward": 0.5287061463296413, "critic_loss": 0.6060132066309452, "actor_loss": -54.26913707733154, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.847214937210083, "step": 95000}
{"episode_reward": 457.01181746051594, "episode": 96.0, "batch_reward": 0.5285687951743603, "critic_loss": 0.6060748119056225, "actor_loss": -54.268682861328124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.20526647567749, "step": 96000}
{"episode_reward": 651.0902204501175, "episode": 97.0, "batch_reward": 0.5289752704203129, "critic_loss": 0.619501078248024, "actor_loss": -54.06382290649414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.88909411430359, "step": 97000}
{"episode_reward": 636.0696621761383, "episode": 98.0, "batch_reward": 0.5319591337442398, "critic_loss": 0.6295302654504776, "actor_loss": -54.09904769134521, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.921053171157837, "step": 98000}
{"episode_reward": 646.0223345551825, "episode": 99.0, "batch_reward": 0.5315285767018795, "critic_loss": 0.5963581298589706, "actor_loss": -54.41932034301758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.05353093147278, "step": 99000}
{"episode_reward": 646.5335690514667, "episode": 100.0, "batch_reward": 0.5335027810931205, "critic_loss": 0.6354909504055977, "actor_loss": -54.69220492553711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.131927490234375, "step": 100000}
{"episode_reward": 543.402237912529, "episode": 101.0, "batch_reward": 0.5333277870714664, "critic_loss": 0.5968759793043137, "actor_loss": -54.670384284973146, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.87564277648926, "step": 101000}
{"episode_reward": 635.3022646794626, "episode": 102.0, "batch_reward": 0.5348810879588127, "critic_loss": 0.5955200073719025, "actor_loss": -54.5237892074585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.333430767059326, "step": 102000}
{"episode_reward": 654.7258189997408, "episode": 103.0, "batch_reward": 0.5353059000074863, "critic_loss": 0.6289974681437015, "actor_loss": -54.85520691680908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.57158136367798, "step": 103000}
{"episode_reward": 609.4392094039754, "episode": 104.0, "batch_reward": 0.5370910993218422, "critic_loss": 0.6109257130324841, "actor_loss": -54.64712133026123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.595813989639282, "step": 104000}
{"episode_reward": 682.5683169378307, "episode": 105.0, "batch_reward": 0.5371603053808213, "critic_loss": 0.6249724495112896, "actor_loss": -55.08479889678955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.848506450653076, "step": 105000}
{"episode_reward": 639.791325292546, "episode": 106.0, "batch_reward": 0.5390803615748883, "critic_loss": 0.6051743367016316, "actor_loss": -55.04626301574707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.979138612747192, "step": 106000}
{"episode_reward": 666.3884699554055, "episode": 107.0, "batch_reward": 0.5398203209042549, "critic_loss": 0.6178851895928383, "actor_loss": -55.075359954833985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.39773917198181, "step": 107000}
{"episode_reward": 656.9153580144571, "episode": 108.0, "batch_reward": 0.541415152490139, "critic_loss": 0.6321995161473751, "actor_loss": -55.082705139160154, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.178284883499146, "step": 108000}
{"episode_reward": 665.0544307227362, "episode": 109.0, "batch_reward": 0.5415445145964622, "critic_loss": 0.605602336242795, "actor_loss": -54.91858994293213, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.307830810546875, "step": 109000}
{"episode_reward": 661.5681999278503, "episode": 110.0, "batch_reward": 0.5428585302829743, "critic_loss": 0.6503019568324089, "actor_loss": -55.145093643188474, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.390186548233032, "step": 110000}
{"episode_reward": 633.6892890951364, "episode": 111.0, "batch_reward": 0.5440674633085728, "critic_loss": 0.6572219911217689, "actor_loss": -55.435329261779785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.64874792098999, "step": 111000}
{"episode_reward": 627.819317859893, "episode": 112.0, "batch_reward": 0.5444152879416942, "critic_loss": 0.6661813575029373, "actor_loss": -55.5629817199707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.743467569351196, "step": 112000}
{"episode_reward": 623.8411701822549, "episode": 113.0, "batch_reward": 0.546116712719202, "critic_loss": 0.6604873402118683, "actor_loss": -55.796283668518065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.992329120635986, "step": 113000}
{"episode_reward": 646.0755165178871, "episode": 114.0, "batch_reward": 0.5458723460137844, "critic_loss": 0.6790785569548606, "actor_loss": -55.488050430297854, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.70440649986267, "step": 114000}
{"episode_reward": 660.9514079702064, "episode": 115.0, "batch_reward": 0.5467900211215019, "critic_loss": 0.6759479428827763, "actor_loss": -55.446837837219235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.736496448516846, "step": 115000}
{"episode_reward": 654.9131257234907, "episode": 116.0, "batch_reward": 0.5479563028514385, "critic_loss": 0.652382426649332, "actor_loss": -55.54594922637939, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.647068977355957, "step": 116000}
{"episode_reward": 665.2373990770758, "episode": 117.0, "batch_reward": 0.5487121613025665, "critic_loss": 0.6580381357371807, "actor_loss": -55.65847917175293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.52946662902832, "step": 117000}
{"episode_reward": 646.4864872848967, "episode": 118.0, "batch_reward": 0.5495237713456154, "critic_loss": 0.7031685144007206, "actor_loss": -55.93036032104492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.30890440940857, "step": 118000}
{"episode_reward": 598.2665343006555, "episode": 119.0, "batch_reward": 0.5500130669176578, "critic_loss": 0.6789170659184456, "actor_loss": -55.913979652404784, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.355913877487183, "step": 119000}
{"episode_reward": 644.9161081393859, "episode": 120.0, "batch_reward": 0.5505512751936913, "critic_loss": 0.6527403146326541, "actor_loss": -55.89530221557617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.23046374320984, "step": 120000}
{"episode_reward": 642.5830851675639, "episode": 121.0, "batch_reward": 0.5524892616868019, "critic_loss": 0.661000621676445, "actor_loss": -56.12579793548584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.41936945915222, "step": 121000}
{"episode_reward": 650.7676854707671, "episode": 122.0, "batch_reward": 0.5538235204517842, "critic_loss": 0.6588218350708485, "actor_loss": -55.91465885925293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.930992126464844, "step": 122000}
{"episode_reward": 682.6604012620562, "episode": 123.0, "batch_reward": 0.5531296772062778, "critic_loss": 0.6640998096168041, "actor_loss": -55.68293383789062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.133559226989746, "step": 123000}
{"episode_reward": 679.217043536689, "episode": 124.0, "batch_reward": 0.554106441706419, "critic_loss": 0.6333243765234947, "actor_loss": -55.926054550170896, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.93302345275879, "step": 124000}
{"episode_reward": 664.4407521454721, "episode": 125.0, "batch_reward": 0.5566256471574307, "critic_loss": 0.6076452476084232, "actor_loss": -56.514697059631345, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.387794971466064, "step": 125000}
{"episode_reward": 658.2845847498818, "episode": 126.0, "batch_reward": 0.5558870047032833, "critic_loss": 0.6304381259381772, "actor_loss": -56.34697388458252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.611729860305786, "step": 126000}
{"episode_reward": 664.8826396733464, "episode": 127.0, "batch_reward": 0.5566920953392982, "critic_loss": 0.6465048734545707, "actor_loss": -56.1881544342041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.468613386154175, "step": 127000}
{"episode_reward": 659.0753412545491, "episode": 128.0, "batch_reward": 0.5587265886366367, "critic_loss": 0.6239771148562432, "actor_loss": -56.75122370910645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.087489128112793, "step": 128000}
{"episode_reward": 652.3215891025021, "episode": 129.0, "batch_reward": 0.5590625459551811, "critic_loss": 0.6038413927257061, "actor_loss": -56.57044593048096, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97718620300293, "step": 129000}
{"episode_reward": 679.6024762332896, "episode": 130.0, "batch_reward": 0.5585051802396774, "critic_loss": 0.6071462199389934, "actor_loss": -56.39339184570313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.545931339263916, "step": 130000}
