{"episode_reward": 0.0, "episode": 1.0, "duration": 17.297512531280518, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.5008032321929932, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.27031265654815123, "critic_loss": 0.027653910352737607, "actor_loss": -15.039933068728468, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254236, "duration": 61.86721730232239, "step": 3000}
{"episode_reward": 187.22891105029152, "episode": 4.0, "batch_reward": 0.22055806627869606, "critic_loss": 0.032303616956807675, "actor_loss": -14.887316605091096, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.97777533531189, "step": 4000}
{"episode_reward": 33.68943045495446, "episode": 5.0, "batch_reward": 0.18066640868782996, "critic_loss": 0.03053954611811787, "actor_loss": -12.065800343036651, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.30643606185913, "step": 5000}
{"episode_reward": 44.32807501940685, "episode": 6.0, "batch_reward": 0.16009119968116284, "critic_loss": 0.037306720715016124, "actor_loss": -11.397550067901612, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.141820907592773, "step": 6000}
{"episode_reward": 79.58153657209456, "episode": 7.0, "batch_reward": 0.1472327609732747, "critic_loss": 0.04149141573347151, "actor_loss": -10.443337386608123, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.849801063537598, "step": 7000}
{"episode_reward": 109.61372129461367, "episode": 8.0, "batch_reward": 0.13814578864723445, "critic_loss": 0.052982525991275904, "actor_loss": -11.652383465766906, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.567306756973267, "step": 8000}
{"episode_reward": 33.822908001871276, "episode": 9.0, "batch_reward": 0.12895393278449774, "critic_loss": 0.05653170947358012, "actor_loss": -10.698594235897064, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.241466760635376, "step": 9000}
{"episode_reward": 82.05141326873873, "episode": 10.0, "batch_reward": 0.13052799043804408, "critic_loss": 0.08488870252855123, "actor_loss": -11.34692587852478, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.83623480796814, "step": 10000}
{"episode_reward": 180.58326908160916, "episode": 11.0, "batch_reward": 0.12855445525050163, "critic_loss": 0.09863258783146739, "actor_loss": -10.630505805015565, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 38.21557402610779, "step": 11000}
{"episode_reward": 67.31007557036615, "episode": 12.0, "batch_reward": 0.12327164494991302, "critic_loss": 0.10131658911332488, "actor_loss": -11.481289311408997, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.065696477890015, "step": 12000}
{"episode_reward": 55.9297343820214, "episode": 13.0, "batch_reward": 0.11644469352811575, "critic_loss": 0.09655557105317712, "actor_loss": -11.27251201057434, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.5555202960968, "step": 13000}
{"episode_reward": 42.64839349523443, "episode": 14.0, "batch_reward": 0.10981546047329903, "critic_loss": 0.11056548119336367, "actor_loss": -11.545065927505494, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.946470022201538, "step": 14000}
{"episode_reward": 21.587651776801515, "episode": 15.0, "batch_reward": 0.10437989500164986, "critic_loss": 0.10653288837522268, "actor_loss": -11.282230575561524, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.884053707122803, "step": 15000}
{"episode_reward": 22.589735794241754, "episode": 16.0, "batch_reward": 0.10258464013785124, "critic_loss": 0.10816341653466224, "actor_loss": -11.40375100326538, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.69168496131897, "step": 16000}
{"episode_reward": 100.06891401346824, "episode": 17.0, "batch_reward": 0.09976927968859672, "critic_loss": 0.10238658561557532, "actor_loss": -11.288202473640442, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.21947193145752, "step": 17000}
{"episode_reward": 49.961994853104734, "episode": 18.0, "batch_reward": 0.09677275229245424, "critic_loss": 0.11395761523023248, "actor_loss": -11.401274394989013, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.866037607192993, "step": 18000}
{"episode_reward": 37.237268165766835, "episode": 19.0, "batch_reward": 0.09367556764185428, "critic_loss": 0.1763574365824461, "actor_loss": -11.292785418510437, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.239952325820923, "step": 19000}
{"episode_reward": 58.793700892391065, "episode": 20.0, "batch_reward": 0.09305941822007298, "critic_loss": 0.15515024891495705, "actor_loss": -11.710285820007325, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.274697065353394, "step": 20000}
{"episode_reward": 85.15650600838369, "episode": 21.0, "batch_reward": 0.09243184199184179, "critic_loss": 0.17170224275812507, "actor_loss": -11.788000529289246, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.63396716117859, "step": 21000}
{"episode_reward": 122.05783818907005, "episode": 22.0, "batch_reward": 0.09438690253347158, "critic_loss": 0.19214464941620826, "actor_loss": -12.049592408180237, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.33456587791443, "step": 22000}
{"episode_reward": 76.48595444146346, "episode": 23.0, "batch_reward": 0.09454935389012098, "critic_loss": 0.22108219691365957, "actor_loss": -12.203128607749939, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.361018180847168, "step": 23000}
{"episode_reward": 89.42548040851263, "episode": 24.0, "batch_reward": 0.09198641857877374, "critic_loss": 0.19127282522618771, "actor_loss": -12.645680812835693, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.417357206344604, "step": 24000}
{"episode_reward": 52.42512076280779, "episode": 25.0, "batch_reward": 0.0888525066897273, "critic_loss": 0.18311619300395252, "actor_loss": -13.14877188873291, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.030362129211426, "step": 25000}
{"episode_reward": 27.28306444184557, "episode": 26.0, "batch_reward": 0.08747796020656824, "critic_loss": 0.2006385542973876, "actor_loss": -13.740296377182007, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.159960508346558, "step": 26000}
{"episode_reward": 9.678787220014076, "episode": 27.0, "batch_reward": 0.08440379561111332, "critic_loss": 0.18625776428729296, "actor_loss": -14.107917974472047, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.081847190856934, "step": 27000}
{"episode_reward": 38.714030086168385, "episode": 28.0, "batch_reward": 0.08492359594255686, "critic_loss": 0.19215848527103663, "actor_loss": -14.475767372131347, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.078455686569214, "step": 28000}
{"episode_reward": 121.05758159267299, "episode": 29.0, "batch_reward": 0.08415864004939795, "critic_loss": 0.1819071124792099, "actor_loss": -14.169799459457398, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.43657112121582, "step": 29000}
{"episode_reward": 26.8437302141118, "episode": 30.0, "batch_reward": 0.08277620558440685, "critic_loss": 0.18964946753531695, "actor_loss": -14.175457822799682, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.882888317108154, "step": 30000}
{"episode_reward": 62.409111666979165, "episode": 31.0, "batch_reward": 0.08249471322447062, "critic_loss": 0.1934104915782809, "actor_loss": -14.356662677764893, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.85523581504822, "step": 31000}
{"episode_reward": 70.7584345380691, "episode": 32.0, "batch_reward": 0.08252640576288105, "critic_loss": 0.2267541006207466, "actor_loss": -14.161400819778443, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.063660383224487, "step": 32000}
{"episode_reward": 97.39383214592068, "episode": 33.0, "batch_reward": 0.08205775048956275, "critic_loss": 0.22263719040900468, "actor_loss": -14.27918791770935, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.28995394706726, "step": 33000}
{"episode_reward": 131.75779413722685, "episode": 34.0, "batch_reward": 0.08460135549679398, "critic_loss": 0.24513785741478206, "actor_loss": -14.500863803863526, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.12557888031006, "step": 34000}
{"episode_reward": 91.22609962798366, "episode": 35.0, "batch_reward": 0.08481506866589189, "critic_loss": 0.3052814153209329, "actor_loss": -14.347274728775025, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.22789430618286, "step": 35000}
{"episode_reward": 103.43526993594783, "episode": 36.0, "batch_reward": 0.08655772551894188, "critic_loss": 0.29947806540876626, "actor_loss": -14.700954236984252, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.886712312698364, "step": 36000}
{"episode_reward": 234.1536481946454, "episode": 37.0, "batch_reward": 0.09160824975371361, "critic_loss": 0.3578006184771657, "actor_loss": -15.13028413772583, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.09051513671875, "step": 37000}
{"episode_reward": 223.2588838378025, "episode": 38.0, "batch_reward": 0.09408625699207186, "critic_loss": 0.3672144037634134, "actor_loss": -15.371156402587891, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.812165021896362, "step": 38000}
{"episode_reward": 153.92608250036966, "episode": 39.0, "batch_reward": 0.09654918310046195, "critic_loss": 0.3701380877196789, "actor_loss": -15.647751956939697, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.853633403778076, "step": 39000}
{"episode_reward": 251.4219118425319, "episode": 40.0, "batch_reward": 0.0973086487799883, "critic_loss": 0.3645377864092588, "actor_loss": -15.994944534301759, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.252528190612793, "step": 40000}
{"episode_reward": 15.745650764925173, "episode": 41.0, "batch_reward": 0.09715588049590587, "critic_loss": 0.3636598587334156, "actor_loss": -16.147224140167236, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.45588541030884, "step": 41000}
{"episode_reward": 157.29380411562886, "episode": 42.0, "batch_reward": 0.10051350308954715, "critic_loss": 0.40924418936669826, "actor_loss": -16.406614459991456, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.64513850212097, "step": 42000}
{"episode_reward": 294.5855776295337, "episode": 43.0, "batch_reward": 0.10309772562235593, "critic_loss": 0.4580713409334421, "actor_loss": -16.497978504180907, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.49461007118225, "step": 43000}
{"episode_reward": 93.88370973365281, "episode": 44.0, "batch_reward": 0.10360060392320156, "critic_loss": 0.422680662676692, "actor_loss": -16.570298736572266, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.85938835144043, "step": 44000}
{"episode_reward": 161.30710890121233, "episode": 45.0, "batch_reward": 0.10348081324994564, "critic_loss": 0.4224441739171743, "actor_loss": -16.3991715965271, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.965059280395508, "step": 45000}
{"episode_reward": 73.45356863368501, "episode": 46.0, "batch_reward": 0.10524342101812363, "critic_loss": 0.4230047163814306, "actor_loss": -16.338682815551756, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.725683450698853, "step": 46000}
{"episode_reward": 234.52384968221574, "episode": 47.0, "batch_reward": 0.1081991025134921, "critic_loss": 0.4692811042368412, "actor_loss": -16.717207357406615, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.8745436668396, "step": 47000}
{"episode_reward": 360.18798012885946, "episode": 48.0, "batch_reward": 0.11509623669832945, "critic_loss": 0.5658718388527632, "actor_loss": -17.33716050720215, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.80126976966858, "step": 48000}
{"episode_reward": 416.13429606680575, "episode": 49.0, "batch_reward": 0.11737411567568778, "critic_loss": 0.5357385679930449, "actor_loss": -17.302840843200684, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.901222705841064, "step": 49000}
{"episode_reward": 62.06415846392808, "episode": 50.0, "batch_reward": 0.1164802034124732, "critic_loss": 0.5194838257282972, "actor_loss": -17.43218646812439, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.873436450958252, "step": 50000}
{"episode_reward": 143.71477698483346, "episode": 51.0, "batch_reward": 0.11782801481336355, "critic_loss": 0.505936343356967, "actor_loss": -17.648295408248902, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.56774663925171, "step": 51000}
{"episode_reward": 166.538076971852, "episode": 52.0, "batch_reward": 0.11981413159519434, "critic_loss": 0.5381594455689191, "actor_loss": -17.795279954910278, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.92011857032776, "step": 52000}
{"episode_reward": 209.47788597228242, "episode": 53.0, "batch_reward": 0.12105920626968146, "critic_loss": 0.5664322733283043, "actor_loss": -17.918839635849, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.40617299079895, "step": 53000}
{"episode_reward": 149.01255136663428, "episode": 54.0, "batch_reward": 0.12067494750767946, "critic_loss": 0.5603878970146179, "actor_loss": -17.734477031707765, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.380643367767334, "step": 54000}
{"episode_reward": 155.727875983195, "episode": 55.0, "batch_reward": 0.12025193663686513, "critic_loss": 0.5128248364478349, "actor_loss": -17.61615608406067, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.549413442611694, "step": 55000}
{"episode_reward": 12.567669100087782, "episode": 56.0, "batch_reward": 0.1201264230310917, "critic_loss": 0.49396772661805155, "actor_loss": -17.71591711807251, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.94265127182007, "step": 56000}
{"episode_reward": 257.4970654541177, "episode": 57.0, "batch_reward": 0.1233043427541852, "critic_loss": 0.5414131664186717, "actor_loss": -17.88792718887329, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.32084608078003, "step": 57000}
{"episode_reward": 371.19462813002013, "episode": 58.0, "batch_reward": 0.12683193676173687, "critic_loss": 0.5415866771191359, "actor_loss": -18.393005645751952, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.77486228942871, "step": 58000}
{"episode_reward": 220.9770157222562, "episode": 59.0, "batch_reward": 0.12908039565384388, "critic_loss": 0.5128721464127303, "actor_loss": -18.492223875045777, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.974907159805298, "step": 59000}
{"episode_reward": 172.01448553187123, "episode": 60.0, "batch_reward": 0.1277346431016922, "critic_loss": 0.5544189128130674, "actor_loss": -18.22663527107239, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.32478928565979, "step": 60000}
{"episode_reward": 50.01962602815033, "episode": 61.0, "batch_reward": 0.12827655776590108, "critic_loss": 0.5111562895923852, "actor_loss": -18.304653675079347, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.735790729522705, "step": 61000}
{"episode_reward": 321.8655989978871, "episode": 62.0, "batch_reward": 0.12987699561566116, "critic_loss": 0.5482337389588356, "actor_loss": -18.256458360671996, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.62568974494934, "step": 62000}
{"episode_reward": 90.0969910338963, "episode": 63.0, "batch_reward": 0.12873832862824203, "critic_loss": 0.5153499170988798, "actor_loss": -18.072063119888305, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.35030174255371, "step": 63000}
{"episode_reward": 22.839866395963856, "episode": 64.0, "batch_reward": 0.1283035969734192, "critic_loss": 0.5289521702378989, "actor_loss": -18.160269798278808, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.938131093978882, "step": 64000}
{"episode_reward": 319.6402077453195, "episode": 65.0, "batch_reward": 0.13311875535547732, "critic_loss": 0.5491076732575894, "actor_loss": -18.59861000061035, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.560232877731323, "step": 65000}
{"episode_reward": 395.3542384037141, "episode": 66.0, "batch_reward": 0.13526696903258562, "critic_loss": 0.5680926218330861, "actor_loss": -18.494574081420897, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.277719974517822, "step": 66000}
{"episode_reward": 186.16094548789044, "episode": 67.0, "batch_reward": 0.13630572451651096, "critic_loss": 0.5989515232890844, "actor_loss": -18.683513906478883, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.334133625030518, "step": 67000}
{"episode_reward": 217.58740103077557, "episode": 68.0, "batch_reward": 0.1363808657452464, "critic_loss": 0.5422595733553172, "actor_loss": -18.607955501556397, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.29745864868164, "step": 68000}
{"episode_reward": 44.451089606569, "episode": 69.0, "batch_reward": 0.13711310160905124, "critic_loss": 0.5901139295697212, "actor_loss": -18.566359228134154, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.44586944580078, "step": 69000}
{"episode_reward": 289.95172874797555, "episode": 70.0, "batch_reward": 0.13874067993462086, "critic_loss": 0.58065265417099, "actor_loss": -18.776455528259277, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.000256776809692, "step": 70000}
{"episode_reward": 292.38517487234935, "episode": 71.0, "batch_reward": 0.14011217622458935, "critic_loss": 0.6123730037659406, "actor_loss": -18.961397609710694, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.582581996917725, "step": 71000}
{"episode_reward": 196.0632284656449, "episode": 72.0, "batch_reward": 0.14015561103075744, "critic_loss": 0.5776465803682804, "actor_loss": -18.788032484054565, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.48858952522278, "step": 72000}
{"episode_reward": 117.98303082976332, "episode": 73.0, "batch_reward": 0.14065181805193425, "critic_loss": 0.619815274566412, "actor_loss": -19.048321283340453, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.886123418807983, "step": 73000}
{"episode_reward": 288.64377600736793, "episode": 74.0, "batch_reward": 0.14286364819854497, "critic_loss": 0.5714482558965683, "actor_loss": -19.24957111930847, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.5979106426239, "step": 74000}
{"episode_reward": 166.89182282452106, "episode": 75.0, "batch_reward": 0.1453335687071085, "critic_loss": 0.5638182788044215, "actor_loss": -19.406958740234376, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.069090604782104, "step": 75000}
{"episode_reward": 404.45783764626475, "episode": 76.0, "batch_reward": 0.14775189248472453, "critic_loss": 0.5824656018465757, "actor_loss": -19.623359535217286, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.013161420822144, "step": 76000}
{"episode_reward": 401.9720187752722, "episode": 77.0, "batch_reward": 0.15115535851567985, "critic_loss": 0.5399039515703916, "actor_loss": -20.020922124862672, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.44787907600403, "step": 77000}
{"episode_reward": 406.1955876283271, "episode": 78.0, "batch_reward": 0.1539679092988372, "critic_loss": 0.5980164179056883, "actor_loss": -20.178710863113402, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.087684869766235, "step": 78000}
{"episode_reward": 399.59633661318463, "episode": 79.0, "batch_reward": 0.15693369291722775, "critic_loss": 0.5885681825280189, "actor_loss": -20.39491837310791, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.417398691177368, "step": 79000}
{"episode_reward": 242.64410411704534, "episode": 80.0, "batch_reward": 0.1591461268365383, "critic_loss": 0.5720087116360665, "actor_loss": -20.667725078582762, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.89054012298584, "step": 80000}
{"episode_reward": 469.95763883563785, "episode": 81.0, "batch_reward": 0.16259193026274443, "critic_loss": 0.602531314983964, "actor_loss": -20.930749881744386, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.59851670265198, "step": 81000}
{"episode_reward": 286.23477150048285, "episode": 82.0, "batch_reward": 0.16244050868600607, "critic_loss": 0.5565077935308218, "actor_loss": -21.02237042236328, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.87016487121582, "step": 82000}
{"episode_reward": 178.01515926186568, "episode": 83.0, "batch_reward": 0.1648691788688302, "critic_loss": 0.5695605860054493, "actor_loss": -20.958302986145018, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.72861409187317, "step": 83000}
{"episode_reward": 432.18892682061943, "episode": 84.0, "batch_reward": 0.16726391257345677, "critic_loss": 0.5741751981824637, "actor_loss": -21.20577816963196, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.234720945358276, "step": 84000}
{"episode_reward": 396.8247022652334, "episode": 85.0, "batch_reward": 0.1699897948205471, "critic_loss": 0.5504521839916706, "actor_loss": -21.28485768890381, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.29664158821106, "step": 85000}
{"episode_reward": 489.3004814174592, "episode": 86.0, "batch_reward": 0.1724638042077422, "critic_loss": 0.5532804247885943, "actor_loss": -21.654494045257568, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.319873809814453, "step": 86000}
{"episode_reward": 463.6945656167383, "episode": 87.0, "batch_reward": 0.1763560065627098, "critic_loss": 0.5645061129927635, "actor_loss": -21.72082303237915, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.338894605636597, "step": 87000}
{"episode_reward": 150.13742237656368, "episode": 88.0, "batch_reward": 0.17592178155481816, "critic_loss": 0.5283893803209067, "actor_loss": -21.774299419403075, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.25148344039917, "step": 88000}
{"episode_reward": 344.09167589217077, "episode": 89.0, "batch_reward": 0.17912611639499665, "critic_loss": 0.5078965343236923, "actor_loss": -22.053927799224855, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.150742292404175, "step": 89000}
{"episode_reward": 440.8444749251814, "episode": 90.0, "batch_reward": 0.18025203296542167, "critic_loss": 0.5291584016531706, "actor_loss": -22.241426486968994, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.351214170455933, "step": 90000}
{"episode_reward": 273.10041890086507, "episode": 91.0, "batch_reward": 0.18301705130934715, "critic_loss": 0.5200747721493244, "actor_loss": -22.35690816116333, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.325812578201294, "step": 91000}
{"episode_reward": 404.93629607878063, "episode": 92.0, "batch_reward": 0.18439197167754173, "critic_loss": 0.495848342821002, "actor_loss": -22.216724235534667, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.083849668502808, "step": 92000}
{"episode_reward": 496.61886473786575, "episode": 93.0, "batch_reward": 0.18856926013529302, "critic_loss": 0.46899758782982826, "actor_loss": -22.625802223205568, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.068027019500732, "step": 93000}
{"episode_reward": 473.7251948105849, "episode": 94.0, "batch_reward": 0.1924696134775877, "critic_loss": 0.4621816322952509, "actor_loss": -22.869970035552978, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.926717281341553, "step": 94000}
{"episode_reward": 485.54846632937694, "episode": 95.0, "batch_reward": 0.19459123453497887, "critic_loss": 0.4331469478607178, "actor_loss": -23.062717063903808, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.42124891281128, "step": 95000}
{"episode_reward": 436.6054553877842, "episode": 96.0, "batch_reward": 0.1965448595583439, "critic_loss": 0.409852857992053, "actor_loss": -23.240190380096436, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.314573526382446, "step": 96000}
{"episode_reward": 430.93553851495733, "episode": 97.0, "batch_reward": 0.19882292696833612, "critic_loss": 0.43985850058496, "actor_loss": -23.642952816009522, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.23913550376892, "step": 97000}
{"episode_reward": 151.34718893783366, "episode": 98.0, "batch_reward": 0.1989808934479952, "critic_loss": 0.4334955874532461, "actor_loss": -23.54398118209839, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.467880249023438, "step": 98000}
{"episode_reward": 366.07184758534027, "episode": 99.0, "batch_reward": 0.20079202030599116, "critic_loss": 0.4579061452448368, "actor_loss": -23.514827629089357, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.108641386032104, "step": 99000}
{"episode_reward": 367.8436947881089, "episode": 100.0, "batch_reward": 0.20135909943282604, "critic_loss": 0.44161527466773987, "actor_loss": -23.3798404045105, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.878742694854736, "step": 100000}
{"episode_reward": 393.2041723068411, "episode": 101.0, "batch_reward": 0.20440414839982987, "critic_loss": 0.4110232044756412, "actor_loss": -23.65294948577881, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.686039209365845, "step": 101000}
{"episode_reward": 430.4606451152244, "episode": 102.0, "batch_reward": 0.20589591804146767, "critic_loss": 0.426325987547636, "actor_loss": -23.710472217559815, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.864969968795776, "step": 102000}
{"episode_reward": 431.18354532552655, "episode": 103.0, "batch_reward": 0.20769266292452812, "critic_loss": 0.41966679196059703, "actor_loss": -23.741610542297362, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.73028063774109, "step": 103000}
{"episode_reward": 380.7180955340826, "episode": 104.0, "batch_reward": 0.21053419919312, "critic_loss": 0.40223855482041837, "actor_loss": -24.078806922912598, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.668689489364624, "step": 104000}
{"episode_reward": 434.90787464862257, "episode": 105.0, "batch_reward": 0.21309711411595345, "critic_loss": 0.39237725792825223, "actor_loss": -24.039525936126708, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.90089249610901, "step": 105000}
{"episode_reward": 397.70909881364463, "episode": 106.0, "batch_reward": 0.21354559215903282, "critic_loss": 0.43090511472523213, "actor_loss": -24.172679008483886, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.135414361953735, "step": 106000}
{"episode_reward": 154.00663673463012, "episode": 107.0, "batch_reward": 0.21411085706949234, "critic_loss": 0.4395083187967539, "actor_loss": -24.152704174041748, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.578178882598877, "step": 107000}
{"episode_reward": 473.80311996986956, "episode": 108.0, "batch_reward": 0.21520305857062338, "critic_loss": 0.4172293808758259, "actor_loss": -24.294217601776122, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.871323823928833, "step": 108000}
{"episode_reward": 199.20895397796303, "episode": 109.0, "batch_reward": 0.21734300662577152, "critic_loss": 0.4494742972999811, "actor_loss": -24.65345456314087, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.114826440811157, "step": 109000}
{"episode_reward": 509.27711807089406, "episode": 110.0, "batch_reward": 0.22003797802329064, "critic_loss": 0.4138217723071575, "actor_loss": -24.679919525146484, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.816609859466553, "step": 110000}
{"episode_reward": 518.8759025470299, "episode": 111.0, "batch_reward": 0.22114019644260408, "critic_loss": 0.41825581662356853, "actor_loss": -24.56932746887207, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.71970558166504, "step": 111000}
{"episode_reward": 522.243007328724, "episode": 112.0, "batch_reward": 0.2240147692859173, "critic_loss": 0.41280673214793207, "actor_loss": -24.75146954345703, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.99260640144348, "step": 112000}
{"episode_reward": 155.1569256550742, "episode": 113.0, "batch_reward": 0.22351853112876416, "critic_loss": 0.4197596091032028, "actor_loss": -24.47742635345459, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.913028240203857, "step": 113000}
{"episode_reward": 469.31810485933687, "episode": 114.0, "batch_reward": 0.22632475733757018, "critic_loss": 0.39656123591959475, "actor_loss": -25.11046920776367, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.786193370819092, "step": 114000}
{"episode_reward": 454.9623466811611, "episode": 115.0, "batch_reward": 0.2278798201829195, "critic_loss": 0.4202091910392046, "actor_loss": -25.15964419555664, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.296051502227783, "step": 115000}
{"episode_reward": 517.5279412107161, "episode": 116.0, "batch_reward": 0.23004114221036434, "critic_loss": 0.420328334197402, "actor_loss": -25.35385939025879, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.230358362197876, "step": 116000}
{"episode_reward": 247.18146304541514, "episode": 117.0, "batch_reward": 0.22989386650919913, "critic_loss": 0.42350230342149736, "actor_loss": -25.36337818145752, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.462613821029663, "step": 117000}
{"episode_reward": 428.9246559443934, "episode": 118.0, "batch_reward": 0.23154517984390258, "critic_loss": 0.41649822798371317, "actor_loss": -25.122586391448973, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.443405866622925, "step": 118000}
{"episode_reward": 415.24599604360577, "episode": 119.0, "batch_reward": 0.23387068448960782, "critic_loss": 0.45158413526415825, "actor_loss": -25.35510382080078, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.73462700843811, "step": 119000}
{"episode_reward": 420.2498358065566, "episode": 120.0, "batch_reward": 0.23536477920413018, "critic_loss": 0.40339522321522236, "actor_loss": -25.644312770843506, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.203001260757446, "step": 120000}
{"episode_reward": 494.13475211541436, "episode": 121.0, "batch_reward": 0.23755271722376348, "critic_loss": 0.4588278700262308, "actor_loss": -25.687129470825194, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.63571548461914, "step": 121000}
{"episode_reward": 480.1570908991747, "episode": 122.0, "batch_reward": 0.24010487969219685, "critic_loss": 0.42746239629387855, "actor_loss": -26.050231155395508, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.888156175613403, "step": 122000}
{"episode_reward": 559.7183212403628, "episode": 123.0, "batch_reward": 0.24233739776909352, "critic_loss": 0.3941520150154829, "actor_loss": -26.587107181549072, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.119930505752563, "step": 123000}
{"episode_reward": 566.7064312614133, "episode": 124.0, "batch_reward": 0.24524160966277123, "critic_loss": 0.4093748698532581, "actor_loss": -26.678747333526612, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.801205158233643, "step": 124000}
{"episode_reward": 548.3867747450769, "episode": 125.0, "batch_reward": 0.24779737535119056, "critic_loss": 0.404851678147912, "actor_loss": -26.328597164154054, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.90643858909607, "step": 125000}
{"episode_reward": 439.17152963539746, "episode": 126.0, "batch_reward": 0.24798163801431655, "critic_loss": 0.43182455095648764, "actor_loss": -26.34236442947388, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.52085566520691, "step": 126000}
{"episode_reward": 329.2139908014797, "episode": 127.0, "batch_reward": 0.2480504555553198, "critic_loss": 0.42446537078917024, "actor_loss": -26.68656042480469, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.70564079284668, "step": 127000}
{"episode_reward": 363.92976731841475, "episode": 128.0, "batch_reward": 0.2503865499943495, "critic_loss": 0.45183937622606757, "actor_loss": -26.451853828430174, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.981571197509766, "step": 128000}
{"episode_reward": 546.8840148872306, "episode": 129.0, "batch_reward": 0.2518899431228638, "critic_loss": 0.4559343374222517, "actor_loss": -26.818498752593992, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.901577711105347, "step": 129000}
{"episode_reward": 500.5448625501864, "episode": 130.0, "batch_reward": 0.2547012065052986, "critic_loss": 0.4507211452871561, "actor_loss": -27.28873913192749, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.32202458381653, "step": 130000}
{"episode_reward": 314.67220257992426, "episode": 131.0, "batch_reward": 0.25456641997396945, "critic_loss": 0.40298738284409047, "actor_loss": -26.702127281188965, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.76511287689209, "step": 131000}
{"episode_reward": 521.591549928519, "episode": 132.0, "batch_reward": 0.2567806595414877, "critic_loss": 0.4407396918013692, "actor_loss": -27.130996063232423, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.115352630615234, "step": 132000}
{"episode_reward": 552.2993876770516, "episode": 133.0, "batch_reward": 0.258851120531559, "critic_loss": 0.43364289779961107, "actor_loss": -27.319983577728273, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.79657530784607, "step": 133000}
{"episode_reward": 630.9455042944263, "episode": 134.0, "batch_reward": 0.2616820631921291, "critic_loss": 0.4078565702438354, "actor_loss": -27.715449295043946, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.87086033821106, "step": 134000}
{"episode_reward": 546.7974909264531, "episode": 135.0, "batch_reward": 0.26443315370380877, "critic_loss": 0.40916381089389325, "actor_loss": -27.86887901687622, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.63052272796631, "step": 135000}
{"episode_reward": 507.0975801853066, "episode": 136.0, "batch_reward": 0.26493735671043395, "critic_loss": 0.39542726473510265, "actor_loss": -27.73864506149292, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.208555459976196, "step": 136000}
{"episode_reward": 534.5783940468832, "episode": 137.0, "batch_reward": 0.268124806240201, "critic_loss": 0.42001400335133077, "actor_loss": -28.29997515106201, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.18425226211548, "step": 137000}
{"episode_reward": 572.9077288620189, "episode": 138.0, "batch_reward": 0.2707846335619688, "critic_loss": 0.4271214218586683, "actor_loss": -28.05723485183716, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.49422264099121, "step": 138000}
{"episode_reward": 620.4053458697852, "episode": 139.0, "batch_reward": 0.2727346992641687, "critic_loss": 0.41885393707454205, "actor_loss": -28.199082557678224, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.013639211654663, "step": 139000}
{"episode_reward": 570.9270779441198, "episode": 140.0, "batch_reward": 0.27480232511460784, "critic_loss": 0.40557335133850575, "actor_loss": -28.53655324935913, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.86835551261902, "step": 140000}
{"episode_reward": 499.038189654036, "episode": 141.0, "batch_reward": 0.2760127255022526, "critic_loss": 0.4088770213276148, "actor_loss": -28.726392463684082, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.65873193740845, "step": 141000}
{"episode_reward": 553.2574166133236, "episode": 142.0, "batch_reward": 0.2782078137546778, "critic_loss": 0.42864835646748545, "actor_loss": -28.945830585479737, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.932588815689087, "step": 142000}
{"episode_reward": 587.9512885277173, "episode": 143.0, "batch_reward": 0.2808838249146938, "critic_loss": 0.4136548343747854, "actor_loss": -29.199264728546144, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.352577209472656, "step": 143000}
{"episode_reward": 545.7172873467679, "episode": 144.0, "batch_reward": 0.2834353310167789, "critic_loss": 0.42000161397457125, "actor_loss": -29.323525966644286, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.31738305091858, "step": 144000}
{"episode_reward": 524.4231958605486, "episode": 145.0, "batch_reward": 0.2843418392986059, "critic_loss": 0.42709680484235285, "actor_loss": -29.540781818389892, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.594707250595093, "step": 145000}
{"episode_reward": 336.78068419247717, "episode": 146.0, "batch_reward": 0.28489720419049264, "critic_loss": 0.43053064627945425, "actor_loss": -29.468876209259033, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.93295907974243, "step": 146000}
{"episode_reward": 583.8584759664667, "episode": 147.0, "batch_reward": 0.2873669793009758, "critic_loss": 0.4335589897334576, "actor_loss": -29.632141105651854, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.182230472564697, "step": 147000}
{"episode_reward": 487.2184602348757, "episode": 148.0, "batch_reward": 0.28728421878814697, "critic_loss": 0.4224605773240328, "actor_loss": -29.602884258270265, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.830810070037842, "step": 148000}
{"episode_reward": 569.1932810350149, "episode": 149.0, "batch_reward": 0.2886768869906664, "critic_loss": 0.4145285671055317, "actor_loss": -29.76599085998535, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.103246212005615, "step": 149000}
{"episode_reward": 547.0892822582571, "episode": 150.0, "batch_reward": 0.2916099671423435, "critic_loss": 0.41394406124949457, "actor_loss": -29.866930099487305, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "step": 150000}
