{"episode_reward": 0.0, "episode": 1.0, "duration": 17.40569567680359, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.491637945175171, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.25938262298290793, "critic_loss": 0.01677320389645053, "actor_loss": -24.177233626361655, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.189117670059204, "step": 3000}
{"episode_reward": 6.877391736491956, "episode": 4.0, "batch_reward": 0.1620742533877492, "critic_loss": 0.015978105208603665, "actor_loss": -22.444465410232542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.225452184677124, "step": 4000}
{"episode_reward": 4.83558218080579, "episode": 5.0, "batch_reward": 0.12639460166171193, "critic_loss": 0.012762583118863404, "actor_loss": -21.274789759159088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.217735767364502, "step": 5000}
{"episode_reward": 2.866451261222572, "episode": 6.0, "batch_reward": 0.10381401331350207, "critic_loss": 0.015417542891576886, "actor_loss": -20.650652742385866, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.183139085769653, "step": 6000}
{"episode_reward": 2.6908092642659316, "episode": 7.0, "batch_reward": 0.08784315294399858, "critic_loss": 0.014324120880104601, "actor_loss": -20.43166408395767, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.207156896591187, "step": 7000}
{"episode_reward": 2.921699045424192, "episode": 8.0, "batch_reward": 0.07683174528181552, "critic_loss": 0.02285477741016075, "actor_loss": -19.88766993522644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.207650423049927, "step": 8000}
{"episode_reward": 2.7245668250702666, "episode": 9.0, "batch_reward": 0.06798282618820667, "critic_loss": 0.013556670638732612, "actor_loss": -18.67162881588936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.234200954437256, "step": 9000}
{"episode_reward": 2.8474804229930433, "episode": 10.0, "batch_reward": 0.06102211778052151, "critic_loss": 0.024020001539494844, "actor_loss": -19.56384879612923, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21921730041504, "step": 10000}
{"episode_reward": 2.396129069136437, "episode": 11.0, "batch_reward": 0.05482038360275328, "critic_loss": 0.02852566633466631, "actor_loss": -18.029366255044938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.67202425003052, "step": 11000}
{"episode_reward": 1.7384298439586916, "episode": 12.0, "batch_reward": 0.051037857302464545, "critic_loss": 0.016636784579604866, "actor_loss": -19.486172290325165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19183921813965, "step": 12000}
{"episode_reward": 2.8140747341141847, "episode": 13.0, "batch_reward": 0.04694026981852949, "critic_loss": 0.025699541511246933, "actor_loss": -18.267625487804413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.200039386749268, "step": 13000}
{"episode_reward": 3.557643372382321, "episode": 14.0, "batch_reward": 0.043883809068705884, "critic_loss": 0.028752502903342247, "actor_loss": -18.18037173461914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.164751768112183, "step": 14000}
{"episode_reward": 3.0943039596263016, "episode": 15.0, "batch_reward": 0.04124852865561843, "critic_loss": 0.02150379633170087, "actor_loss": -17.61576998591423, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20585036277771, "step": 15000}
{"episode_reward": 2.5925050985354483, "episode": 16.0, "batch_reward": 0.038666871494613585, "critic_loss": 0.030626398437656462, "actor_loss": -18.73228070092201, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.232897996902466, "step": 16000}
{"episode_reward": 3.1448124821478136, "episode": 17.0, "batch_reward": 0.03603777010040358, "critic_loss": 0.025372908437624575, "actor_loss": -17.978811612844467, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.189549446105957, "step": 17000}
{"episode_reward": 2.468576059849939, "episode": 18.0, "batch_reward": 0.03450069510564208, "critic_loss": 0.03455344579881057, "actor_loss": -18.811158605098726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20200228691101, "step": 18000}
{"episode_reward": 2.641042455569859, "episode": 19.0, "batch_reward": 0.032220648612827064, "critic_loss": 0.026785960002220235, "actor_loss": -17.449142544031144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23482036590576, "step": 19000}
{"episode_reward": 2.980294875483808, "episode": 20.0, "batch_reward": 0.031245338707230987, "critic_loss": 0.02633698072854895, "actor_loss": -18.374196221113205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.182793617248535, "step": 20000}
{"episode_reward": 3.1569688970137477, "episode": 21.0, "batch_reward": 0.02985913544357754, "critic_loss": 0.03271568491036305, "actor_loss": -17.323357925772665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.6618926525116, "step": 21000}
{"episode_reward": 2.3304588101059034, "episode": 22.0, "batch_reward": 0.028370996298501268, "critic_loss": 0.027622586003039032, "actor_loss": -18.508588961958885, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.187690496444702, "step": 22000}
{"episode_reward": 1.3125829259010797, "episode": 23.0, "batch_reward": 0.027704020149540157, "critic_loss": 0.04625671162776416, "actor_loss": -17.106587856531142, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.178364992141724, "step": 23000}
{"episode_reward": 2.5444870963159962, "episode": 24.0, "batch_reward": 0.026290590938180685, "critic_loss": 0.029872939110791776, "actor_loss": -16.37666520500183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.22637939453125, "step": 24000}
{"episode_reward": 1.789082614612068, "episode": 25.0, "batch_reward": 0.024561399994883687, "critic_loss": 0.032100520423264244, "actor_loss": -17.934080478549003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15936017036438, "step": 25000}
{"episode_reward": 3.778893326368659, "episode": 26.0, "batch_reward": 0.024287035336252302, "critic_loss": 0.03479320001241285, "actor_loss": -16.421781226992607, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1838641166687, "step": 26000}
{"episode_reward": 1.7209281858451837, "episode": 27.0, "batch_reward": 0.023426800197921694, "critic_loss": 0.03160913571540732, "actor_loss": -16.55050889492035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.200457096099854, "step": 27000}
{"episode_reward": 3.751390910012467, "episode": 28.0, "batch_reward": 0.022637551981257276, "critic_loss": 0.04079499892063904, "actor_loss": -17.181085396051408, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.185067415237427, "step": 28000}
{"episode_reward": 3.73521500408833, "episode": 29.0, "batch_reward": 0.022090838596690445, "critic_loss": 0.020606061665414017, "actor_loss": -16.854431949615478, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19953680038452, "step": 29000}
{"episode_reward": 2.6939517993076985, "episode": 30.0, "batch_reward": 0.0213644253697712, "critic_loss": 0.03520140625716885, "actor_loss": -16.19383819580078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.218364715576172, "step": 30000}
{"episode_reward": 3.5306734560929582, "episode": 31.0, "batch_reward": 0.021089037837227806, "critic_loss": 0.02780883791326778, "actor_loss": -18.22567140251398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.62941908836365, "step": 31000}
{"episode_reward": 2.50283452036569, "episode": 32.0, "batch_reward": 0.020187764301896095, "critic_loss": 0.028282406060869108, "actor_loss": -16.92762671369314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.184444427490234, "step": 32000}
{"episode_reward": 3.466626447502182, "episode": 33.0, "batch_reward": 0.01919717320497148, "critic_loss": 0.024136536005331437, "actor_loss": -17.319707965195178, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20777916908264, "step": 33000}
{"episode_reward": 3.6305585997908203, "episode": 34.0, "batch_reward": 0.01936457315599546, "critic_loss": 0.03871148470282788, "actor_loss": -17.419646065056323, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.196043252944946, "step": 34000}
{"episode_reward": 2.944402610006938, "episode": 35.0, "batch_reward": 0.018832889470737427, "critic_loss": 0.021878231438444345, "actor_loss": -16.340726440131665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20944094657898, "step": 35000}
{"episode_reward": 3.112766939229676, "episode": 36.0, "batch_reward": 0.01830857557337731, "critic_loss": 0.03074854869156843, "actor_loss": -17.577833613932132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.150393962860107, "step": 36000}
{"episode_reward": 3.2353356755291296, "episode": 37.0, "batch_reward": 0.01793297307915054, "critic_loss": 0.025712829888390843, "actor_loss": -16.853866417765616, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.213461875915527, "step": 37000}
{"episode_reward": 2.0421537426030083, "episode": 38.0, "batch_reward": 0.018125529980985447, "critic_loss": 0.02289300934417406, "actor_loss": -16.35360023146868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.233314990997314, "step": 38000}
{"episode_reward": 4.230245572806379, "episode": 39.0, "batch_reward": 0.01739436541509349, "critic_loss": 0.031224584164359838, "actor_loss": -17.18964476120472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.211667776107788, "step": 39000}
{"episode_reward": 3.2308203423830215, "episode": 40.0, "batch_reward": 0.016960811745026148, "critic_loss": 0.023490228516602655, "actor_loss": -18.378111429333686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.201242208480835, "step": 40000}
{"episode_reward": 2.5908396633353994, "episode": 41.0, "batch_reward": 0.01687442231294699, "critic_loss": 0.03175331326338346, "actor_loss": -17.773573873221874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.569459676742554, "step": 41000}
{"episode_reward": 3.6695423645719796, "episode": 42.0, "batch_reward": 0.016120755288284272, "critic_loss": 0.017332167499116622, "actor_loss": -17.18066712731123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.216700077056885, "step": 42000}
{"episode_reward": 2.6447699126661854, "episode": 43.0, "batch_reward": 0.016100105008343236, "critic_loss": 0.023850309977453434, "actor_loss": -17.63277068501711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.173824787139893, "step": 43000}
{"episode_reward": 3.7479125567413716, "episode": 44.0, "batch_reward": 0.01566210130089894, "critic_loss": 0.02107781989824434, "actor_loss": -16.654430522859098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.208784818649292, "step": 44000}
{"episode_reward": 2.085215730449176, "episode": 45.0, "batch_reward": 0.01540749261667952, "critic_loss": 0.0211913517677458, "actor_loss": -16.13569686794281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.204936742782593, "step": 45000}
{"episode_reward": 1.5719361317221443, "episode": 46.0, "batch_reward": 0.015246664162958041, "critic_loss": 0.015115522553940537, "actor_loss": -16.35399727398157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17267942428589, "step": 46000}
{"episode_reward": 2.2373005689660523, "episode": 47.0, "batch_reward": 0.014567974949255586, "critic_loss": 0.019089104558777763, "actor_loss": -16.495579675614835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19961643218994, "step": 47000}
{"episode_reward": 2.822103219047709, "episode": 48.0, "batch_reward": 0.01463665371364914, "critic_loss": 0.024566044833074556, "actor_loss": -15.768630881786347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.226598262786865, "step": 48000}
{"episode_reward": 2.335715717255356, "episode": 49.0, "batch_reward": 0.014487541045295075, "critic_loss": 0.020158152257659823, "actor_loss": -15.817276295125485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19600009918213, "step": 49000}
{"episode_reward": 2.537522546119847, "episode": 50.0, "batch_reward": 0.01362084548198618, "critic_loss": 0.022903587365392015, "actor_loss": -15.804637780308724, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.210678339004517, "step": 50000}
{"episode_reward": 2.255963238741181, "episode": 51.0, "batch_reward": 0.013650431052199565, "critic_loss": 0.017584858687128873, "actor_loss": -16.289817025184632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.61091732978821, "step": 51000}
{"episode_reward": 4.6855025787643765, "episode": 52.0, "batch_reward": 0.01348928675800562, "critic_loss": 0.01860231700942677, "actor_loss": -15.86501007860899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2052161693573, "step": 52000}
{"episode_reward": 2.835330798033595, "episode": 53.0, "batch_reward": 0.013636935527669265, "critic_loss": 0.016526804190812983, "actor_loss": -16.713536025464535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19832682609558, "step": 53000}
{"episode_reward": 2.0219522011245297, "episode": 54.0, "batch_reward": 0.01271668880607467, "critic_loss": 0.01820596962615673, "actor_loss": -16.356219793349503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18678641319275, "step": 54000}
{"episode_reward": 1.254945418122341, "episode": 55.0, "batch_reward": 0.012673526343191042, "critic_loss": 0.02283917452582682, "actor_loss": -16.64823475638032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21112823486328, "step": 55000}
{"episode_reward": 1.6554483595897114, "episode": 56.0, "batch_reward": 0.012736327624996192, "critic_loss": 0.016134378611808643, "actor_loss": -17.511009034067392, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.205530643463135, "step": 56000}
{"episode_reward": 2.0604178794721557, "episode": 57.0, "batch_reward": 0.012234904968179762, "critic_loss": 0.018463425239533534, "actor_loss": -16.83932349652052, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.168179750442505, "step": 57000}
{"episode_reward": 1.6210326611178323, "episode": 58.0, "batch_reward": 0.01205727744428441, "critic_loss": 0.023593025293776007, "actor_loss": -17.14038469785452, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20524501800537, "step": 58000}
{"episode_reward": 3.259132837602634, "episode": 59.0, "batch_reward": 0.012097399520687759, "critic_loss": 0.020111011573972062, "actor_loss": -17.202451983481645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20719027519226, "step": 59000}
{"episode_reward": 3.1392479200986236, "episode": 60.0, "batch_reward": 0.01207234706718009, "critic_loss": 0.014998113381298027, "actor_loss": -16.842376731693744, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.195088863372803, "step": 60000}
{"episode_reward": 3.323696956208311, "episode": 61.0, "batch_reward": 0.011582358607440255, "critic_loss": 0.02172832358071173, "actor_loss": -16.318788593232632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.64152908325195, "step": 61000}
{"episode_reward": 3.1127219888995747, "episode": 62.0, "batch_reward": 0.011780279466998764, "critic_loss": 0.02202934550646023, "actor_loss": -15.237325822412968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19798755645752, "step": 62000}
{"episode_reward": 3.31027542939145, "episode": 63.0, "batch_reward": 0.011620965252164751, "critic_loss": 0.02205280271162337, "actor_loss": -16.45784376657009, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18617296218872, "step": 63000}
{"episode_reward": 2.398380924788693, "episode": 64.0, "batch_reward": 0.011403381417272613, "critic_loss": 0.02947308616734517, "actor_loss": -17.350554278999567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.193350076675415, "step": 64000}
{"episode_reward": 2.3008669960346273, "episode": 65.0, "batch_reward": 0.011293204547604546, "critic_loss": 0.020806545819163146, "actor_loss": -16.474307720065116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.197643756866455, "step": 65000}
{"episode_reward": 2.9036728179568936, "episode": 66.0, "batch_reward": 0.011013459790265188, "critic_loss": 0.02991632519664563, "actor_loss": -16.717885034322737, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.218705892562866, "step": 66000}
{"episode_reward": 2.6657477116801314, "episode": 67.0, "batch_reward": 0.011170988794416189, "critic_loss": 0.028013538933795643, "actor_loss": -15.851642294317484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.205329179763794, "step": 67000}
{"episode_reward": 3.8486818339200726, "episode": 68.0, "batch_reward": 0.011058745166985318, "critic_loss": 0.026054227475899097, "actor_loss": -17.271249915152787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.175516366958618, "step": 68000}
{"episode_reward": 3.548416832843895, "episode": 69.0, "batch_reward": 0.010941128548118286, "critic_loss": 0.018920072843757227, "actor_loss": -16.02558931234479, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.184934854507446, "step": 69000}
{"episode_reward": 3.626085055521277, "episode": 70.0, "batch_reward": 0.0108469033469446, "critic_loss": 0.02370206239360414, "actor_loss": -15.768991005927324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.196150541305542, "step": 70000}
{"episode_reward": 3.177662747581601, "episode": 71.0, "batch_reward": 0.010706005615880712, "critic_loss": 0.022421018376036956, "actor_loss": -15.843209182024003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.070043087005615, "step": 71000}
{"episode_reward": 2.669766429026437, "episode": 72.0, "batch_reward": 0.01032435662636999, "critic_loss": 0.019320978882671626, "actor_loss": -16.393156604766844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.167258977890015, "step": 72000}
{"episode_reward": 3.011712268902347, "episode": 73.0, "batch_reward": 0.01037664389796555, "critic_loss": 0.0210200305193066, "actor_loss": -15.765161833465099, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.183391094207764, "step": 73000}
{"episode_reward": 2.310759145087074, "episode": 74.0, "batch_reward": 0.010024451989680529, "critic_loss": 0.019225952749169665, "actor_loss": -16.474438210606575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.187615156173706, "step": 74000}
{"episode_reward": 2.515894486910077, "episode": 75.0, "batch_reward": 0.010204084721626714, "critic_loss": 0.01944222674748744, "actor_loss": -17.073330711364747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18774724006653, "step": 75000}
{"episode_reward": 2.459316096920025, "episode": 76.0, "batch_reward": 0.010026562249870039, "critic_loss": 0.012336034298663435, "actor_loss": -16.92646223798394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.227843046188354, "step": 76000}
{"episode_reward": 2.924643776425287, "episode": 77.0, "batch_reward": 0.010039977795211598, "critic_loss": 0.01849569575159694, "actor_loss": -16.101543513506652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.205596923828125, "step": 77000}
{"episode_reward": 2.579467068275438, "episode": 78.0, "batch_reward": 0.009617745774099603, "critic_loss": 0.010141664067406964, "actor_loss": -16.056279297798874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.202324390411377, "step": 78000}
{"episode_reward": 2.570643982169101, "episode": 79.0, "batch_reward": 0.009625160660478287, "critic_loss": 0.012121807232950232, "actor_loss": -17.13318474006653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.199254035949707, "step": 79000}
{"episode_reward": 2.42893528550841, "episode": 80.0, "batch_reward": 0.009968702927464618, "critic_loss": 0.013035134132551321, "actor_loss": -16.9862537189126, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.186829328536987, "step": 80000}
{"episode_reward": 2.1080238074226783, "episode": 81.0, "batch_reward": 0.009523964756168426, "critic_loss": 0.013152595184277744, "actor_loss": -16.881441121160982, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.553626537323, "step": 81000}
{"episode_reward": 3.562931327391165, "episode": 82.0, "batch_reward": 0.009662294484791346, "critic_loss": 0.01862041310097993, "actor_loss": -16.99800383901596, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21738886833191, "step": 82000}
{"episode_reward": 4.336853534461327, "episode": 83.0, "batch_reward": 0.009502724227728323, "critic_loss": 0.01124462311933894, "actor_loss": -16.208966853618623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.169357538223267, "step": 83000}
{"episode_reward": 2.3282927748815547, "episode": 84.0, "batch_reward": 0.009395733174635098, "critic_loss": 0.016529216706207082, "actor_loss": -16.650789523780347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.196285486221313, "step": 84000}
{"episode_reward": 3.6469536760521932, "episode": 85.0, "batch_reward": 0.009240913802059367, "critic_loss": 0.018273933259144542, "actor_loss": -16.699910000324248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21381902694702, "step": 85000}
{"episode_reward": 4.934462291048086, "episode": 86.0, "batch_reward": 0.009508027894771658, "critic_loss": 0.019937162721704225, "actor_loss": -15.807678045421838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.192564725875854, "step": 86000}
{"episode_reward": 2.8444786983026766, "episode": 87.0, "batch_reward": 0.00956116972246673, "critic_loss": 0.018706132901425008, "actor_loss": -16.141510316580533, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.199138164520264, "step": 87000}
{"episode_reward": 2.802696601905922, "episode": 88.0, "batch_reward": 0.009166071302373893, "critic_loss": 0.020209281611110783, "actor_loss": -15.628814887970686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.248534440994263, "step": 88000}
{"episode_reward": 2.5956548132208135, "episode": 89.0, "batch_reward": 0.00913658343977295, "critic_loss": 0.024570448556914926, "actor_loss": -16.225509622961283, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.185819387435913, "step": 89000}
{"episode_reward": 2.238988982230082, "episode": 90.0, "batch_reward": 0.009045973461004905, "critic_loss": 0.025173637720370606, "actor_loss": -16.417351537942885, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.201590061187744, "step": 90000}
{"episode_reward": 2.049852144939689, "episode": 91.0, "batch_reward": 0.009059221069328487, "critic_loss": 0.027250689876324032, "actor_loss": -16.28822380301356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.64700889587402, "step": 91000}
{"episode_reward": 2.445449507270073, "episode": 92.0, "batch_reward": 0.008876273189787754, "critic_loss": 0.04130677984719659, "actor_loss": -14.797923019528389, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20700478553772, "step": 92000}
{"episode_reward": 1.8441686724292834, "episode": 93.0, "batch_reward": 0.008872837094357237, "critic_loss": 0.02929759795859718, "actor_loss": -16.121682535260916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.223641633987427, "step": 93000}
{"episode_reward": 3.234474252852824, "episode": 94.0, "batch_reward": 0.008924105954938567, "critic_loss": 0.028652732925671442, "actor_loss": -15.160992035239936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.191094398498535, "step": 94000}
{"episode_reward": 2.853809672185764, "episode": 95.0, "batch_reward": 0.008895602608332411, "critic_loss": 0.03847490167096839, "actor_loss": -16.82999410828948, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.171119451522827, "step": 95000}
{"episode_reward": 2.4111797647974442, "episode": 96.0, "batch_reward": 0.00849225022655446, "critic_loss": 0.0246440632846934, "actor_loss": -14.837197661310434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21889567375183, "step": 96000}
{"episode_reward": 3.2437786174849546, "episode": 97.0, "batch_reward": 0.008526654510758817, "critic_loss": 0.05037835473877203, "actor_loss": -16.435477069675922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.145773887634277, "step": 97000}
{"episode_reward": 2.2002225268244535, "episode": 98.0, "batch_reward": 0.008791842449107207, "critic_loss": 0.04268323531174974, "actor_loss": -17.138289230436087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.191986083984375, "step": 98000}
{"episode_reward": 2.192766028335026, "episode": 99.0, "batch_reward": 0.008464467158191838, "critic_loss": 0.039057171296080925, "actor_loss": -16.30292270229757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.50191617012024, "step": 99000}
{"episode_reward": 2.2707740096971114, "episode": 100.0, "batch_reward": 0.008322496894397773, "critic_loss": 0.040447089655404854, "actor_loss": -16.081097855791448, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.197306394577026, "step": 100000}
{"episode_reward": 1.4787804379505622, "episode": 101.0, "batch_reward": 0.008360025972942822, "critic_loss": 0.048232494060197494, "actor_loss": -14.987772126406432, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.551480293273926, "step": 101000}
{"episode_reward": 4.538370090939931, "episode": 102.0, "batch_reward": 0.00823927652661223, "critic_loss": 0.03965616543014039, "actor_loss": -16.081282176464796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18163561820984, "step": 102000}
{"episode_reward": 1.8531532869198801, "episode": 103.0, "batch_reward": 0.008141931567923167, "critic_loss": 0.035681392081613014, "actor_loss": -14.909133736222982, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20045518875122, "step": 103000}
{"episode_reward": 2.13803390198698, "episode": 104.0, "batch_reward": 0.008164835628820583, "critic_loss": 0.05168075506445166, "actor_loss": -16.425304857820272, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19955277442932, "step": 104000}
{"episode_reward": 2.667350160368203, "episode": 105.0, "batch_reward": 0.008114994728239254, "critic_loss": 0.04097135292779421, "actor_loss": -14.958220378607512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.230738162994385, "step": 105000}
{"episode_reward": 1.6432346591844391, "episode": 106.0, "batch_reward": 0.007815516428672708, "critic_loss": 0.042699757357237106, "actor_loss": -16.08374078772962, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.199684143066406, "step": 106000}
{"episode_reward": 3.1796808629028335, "episode": 107.0, "batch_reward": 0.007743995436932892, "critic_loss": 0.05311222470042412, "actor_loss": -16.87442584899068, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.168360710144043, "step": 107000}
{"episode_reward": 2.7888868305574674, "episode": 108.0, "batch_reward": 0.007872859757277183, "critic_loss": 0.03369137352937832, "actor_loss": -15.92476355344057, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.221740007400513, "step": 108000}
{"episode_reward": 2.7403084639019024, "episode": 109.0, "batch_reward": 0.008014406966161914, "critic_loss": 0.045121536857994214, "actor_loss": -16.265300951302052, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.183825492858887, "step": 109000}
{"episode_reward": 2.545578576560122, "episode": 110.0, "batch_reward": 0.008029484633239917, "critic_loss": 0.04853583206627809, "actor_loss": -16.382199560910465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1649272441864, "step": 110000}
{"episode_reward": 2.7394237381106805, "episode": 111.0, "batch_reward": 0.007658873781794682, "critic_loss": 0.027687345743164768, "actor_loss": -15.351249416470528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.649943590164185, "step": 111000}
{"episode_reward": 1.759181481530959, "episode": 112.0, "batch_reward": 0.00791925610031467, "critic_loss": 0.02867681866570638, "actor_loss": -15.715584784597159, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1965115070343, "step": 112000}
{"episode_reward": 2.070581432557205, "episode": 113.0, "batch_reward": 0.007449364042608067, "critic_loss": 0.029008868112156052, "actor_loss": -14.777078964814544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2245090007782, "step": 113000}
{"episode_reward": 2.5178788220678867, "episode": 114.0, "batch_reward": 0.00772039543883875, "critic_loss": 0.029798542987125982, "actor_loss": -15.595776965498924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2225182056427, "step": 114000}
{"episode_reward": 2.7190615592347527, "episode": 115.0, "batch_reward": 0.007525998079567216, "critic_loss": 0.034060402303861335, "actor_loss": -17.122862894684076, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.156771659851074, "step": 115000}
{"episode_reward": 3.328579795007523, "episode": 116.0, "batch_reward": 0.007346263298066333, "critic_loss": 0.026345069460148807, "actor_loss": -16.23264971244335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.208760499954224, "step": 116000}
{"episode_reward": 2.548110678638673, "episode": 117.0, "batch_reward": 0.007403395018307492, "critic_loss": 0.03072111130553094, "actor_loss": -16.297609032914043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.212648630142212, "step": 117000}
{"episode_reward": 1.5137351001601207, "episode": 118.0, "batch_reward": 0.007427409168914892, "critic_loss": 0.016790296821571245, "actor_loss": -15.690344467356802, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.195788860321045, "step": 118000}
{"episode_reward": 2.877519878890504, "episode": 119.0, "batch_reward": 0.007549636274226941, "critic_loss": 0.029243216380004013, "actor_loss": -16.03188675932586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.220251321792603, "step": 119000}
{"episode_reward": 3.523663175863671, "episode": 120.0, "batch_reward": 0.007242009173962288, "critic_loss": 0.02503121315188764, "actor_loss": -16.430995987698434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.229525327682495, "step": 120000}
{"episode_reward": 3.146056214181059, "episode": 121.0, "batch_reward": 0.007256706528598443, "critic_loss": 0.05086601052855258, "actor_loss": -16.101638130888343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.65430665016174, "step": 121000}
{"episode_reward": 2.3702367813257554, "episode": 122.0, "batch_reward": 0.007332809525774792, "critic_loss": 0.02659557169933396, "actor_loss": -17.44019951504469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.237749099731445, "step": 122000}
{"episode_reward": 3.1705775568168653, "episode": 123.0, "batch_reward": 0.0072593308192444965, "critic_loss": 0.02513158570835367, "actor_loss": -17.4146810297966, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.196227312088013, "step": 123000}
{"episode_reward": 2.4283151947442723, "episode": 124.0, "batch_reward": 0.00741832508763764, "critic_loss": 0.02490576812866493, "actor_loss": -16.719708919122816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.215595960617065, "step": 124000}
{"episode_reward": 2.9584074681557007, "episode": 125.0, "batch_reward": 0.007007254160824232, "critic_loss": 0.019703206111385953, "actor_loss": -16.695114403426647, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.237802267074585, "step": 125000}
{"episode_reward": 2.156821523176321, "episode": 126.0, "batch_reward": 0.0069559363306034355, "critic_loss": 0.018481784656054514, "actor_loss": -16.844114070490004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15934157371521, "step": 126000}
{"episode_reward": 2.3029470981518196, "episode": 127.0, "batch_reward": 0.0069995473945746196, "critic_loss": 0.015731893975455023, "actor_loss": -16.711832482665777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.56681776046753, "step": 127000}
{"episode_reward": 3.0730216483456667, "episode": 128.0, "batch_reward": 0.007051428736071103, "critic_loss": 0.018166795928184, "actor_loss": -15.783327159628271, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.203694105148315, "step": 128000}
{"episode_reward": 2.007239480551754, "episode": 129.0, "batch_reward": 0.0069614106704248115, "critic_loss": 0.021123478139117653, "actor_loss": -16.0187382299006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.168625593185425, "step": 129000}
{"episode_reward": 2.9776824409780733, "episode": 130.0, "batch_reward": 0.007137303191702813, "critic_loss": 0.018251726749309454, "actor_loss": -16.748601613491772, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.193321228027344, "step": 130000}
{"episode_reward": 4.519344903235593, "episode": 131.0, "batch_reward": 0.007076327999471687, "critic_loss": 0.02961805961009668, "actor_loss": -14.85785267022252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.655550956726074, "step": 131000}
{"episode_reward": 2.0242709379521586, "episode": 132.0, "batch_reward": 0.007208317308221013, "critic_loss": 0.02123018360734568, "actor_loss": -15.875094356179238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21702289581299, "step": 132000}
{"episode_reward": 1.8970917417411175, "episode": 133.0, "batch_reward": 0.006961702755652368, "critic_loss": 0.022459046579715505, "actor_loss": -16.16747639846802, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2121479511261, "step": 133000}
{"episode_reward": 2.4871261841847097, "episode": 134.0, "batch_reward": 0.006948366972152144, "critic_loss": 0.02166536653021467, "actor_loss": -16.22112794162333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.22175168991089, "step": 134000}
{"episode_reward": 1.6657269994326664, "episode": 135.0, "batch_reward": 0.00716219030180946, "critic_loss": 0.023581969069266052, "actor_loss": -17.12826961298287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2118878364563, "step": 135000}
{"episode_reward": 1.47549800283283, "episode": 136.0, "batch_reward": 0.006817919873748906, "critic_loss": 0.0355583639055767, "actor_loss": -17.379903522089123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.212664127349854, "step": 136000}
{"episode_reward": 1.7707301078653073, "episode": 137.0, "batch_reward": 0.006870951410150155, "critic_loss": 0.03214367741251772, "actor_loss": -15.921883865252138, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.219595670700073, "step": 137000}
{"episode_reward": 2.0134343443158302, "episode": 138.0, "batch_reward": 0.0067889040452428166, "critic_loss": 0.022973846125583806, "actor_loss": -15.654858591780066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.217726945877075, "step": 138000}
{"episode_reward": 2.749731148238427, "episode": 139.0, "batch_reward": 0.006614469838677905, "critic_loss": 0.04391316311796254, "actor_loss": -15.187359714776278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.213773488998413, "step": 139000}
{"episode_reward": 2.2840728994538315, "episode": 140.0, "batch_reward": 0.0070147259606746955, "critic_loss": 0.04961906925168296, "actor_loss": -15.618836124882103, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.211973190307617, "step": 140000}
{"episode_reward": 4.240652836884737, "episode": 141.0, "batch_reward": 0.006647627585567534, "critic_loss": 0.0454630152803511, "actor_loss": -17.23443538607657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.63984513282776, "step": 141000}
{"episode_reward": 2.946599866759901, "episode": 142.0, "batch_reward": 0.006661272936034948, "critic_loss": 0.041399586585859655, "actor_loss": -15.712120935827494, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.231359243392944, "step": 142000}
{"episode_reward": 2.453639990412597, "episode": 143.0, "batch_reward": 0.006713522498961538, "critic_loss": 0.046568990006708194, "actor_loss": -17.455296357735993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.196568489074707, "step": 143000}
{"episode_reward": 2.542673006941183, "episode": 144.0, "batch_reward": 0.006741989393834956, "critic_loss": 0.053037160114196014, "actor_loss": -16.423549426853658, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.174164056777954, "step": 144000}
{"episode_reward": 2.585021590380859, "episode": 145.0, "batch_reward": 0.006594336770940572, "critic_loss": 0.06629144620907028, "actor_loss": -17.484582587182523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.199981689453125, "step": 145000}
{"episode_reward": 2.741496361923419, "episode": 146.0, "batch_reward": 0.006355556041235104, "critic_loss": 0.04895605250811787, "actor_loss": -16.133598633497954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.232654094696045, "step": 146000}
{"episode_reward": 1.9260008662741344, "episode": 147.0, "batch_reward": 0.0066359799026977275, "critic_loss": 0.06597643764261739, "actor_loss": -16.98244647872448, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18024706840515, "step": 147000}
{"episode_reward": 2.8968145011821385, "episode": 148.0, "batch_reward": 0.0064120764725375924, "critic_loss": 0.07607561289124715, "actor_loss": -16.511591176688672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.213057279586792, "step": 148000}
{"episode_reward": 2.4782702537527155, "episode": 149.0, "batch_reward": 0.006479458435671404, "critic_loss": 0.06487484585429774, "actor_loss": -15.739391643822193, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.198930263519287, "step": 149000}
{"episode_reward": 2.398354273775615, "episode": 150.0, "batch_reward": 0.006320828348514624, "critic_loss": 0.07119902725245629, "actor_loss": -15.930584306910633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
