{"episode_reward": 0.0, "episode": 1.0, "duration": 17.496801376342773, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.5021636486053467, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.2616808510454705, "critic_loss": 0.05437402823823776, "actor_loss": -22.313997851274, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 60.59310507774353, "step": 3000}
{"episode_reward": 42.20362139887082, "episode": 4.0, "batch_reward": 0.172060288220644, "critic_loss": 0.031027478656731545, "actor_loss": -18.929351756051183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00154948234558, "step": 4000}
{"episode_reward": 8.056679498613212, "episode": 5.0, "batch_reward": 0.1366981724910438, "critic_loss": 0.025210772784426808, "actor_loss": -17.998765151143076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.003059148788452, "step": 5000}
{"episode_reward": 18.809143396063178, "episode": 6.0, "batch_reward": 0.11722840701788664, "critic_loss": 0.031790986032225195, "actor_loss": -17.82639054057002, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.024153232574463, "step": 6000}
{"episode_reward": 46.28547487067901, "episode": 7.0, "batch_reward": 0.10815637600421905, "critic_loss": 0.043369657088071105, "actor_loss": -17.84133554947376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.993762969970703, "step": 7000}
{"episode_reward": 67.62935525210102, "episode": 8.0, "batch_reward": 0.10061510383710265, "critic_loss": 0.04268019445240498, "actor_loss": -16.578298206210135, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02990174293518, "step": 8000}
{"episode_reward": 25.461654249587095, "episode": 9.0, "batch_reward": 0.09667346966266632, "critic_loss": 0.0662753208372742, "actor_loss": -14.780710691213608, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.998878240585327, "step": 9000}
{"episode_reward": 85.03381901904669, "episode": 10.0, "batch_reward": 0.0924311358332634, "critic_loss": 0.08392141966149211, "actor_loss": -15.044196294888854, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.024937629699707, "step": 10000}
{"episode_reward": 44.69430377737896, "episode": 11.0, "batch_reward": 0.08952994782850146, "critic_loss": 0.12796568333357572, "actor_loss": -13.521877031609415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.45441174507141, "step": 11000}
{"episode_reward": 77.7842360470555, "episode": 12.0, "batch_reward": 0.09385696022585034, "critic_loss": 0.1618767474964261, "actor_loss": -15.291404927298426, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.983043909072876, "step": 12000}
{"episode_reward": 186.7797230911928, "episode": 13.0, "batch_reward": 0.09388789213076233, "critic_loss": 0.14610275531560182, "actor_loss": -14.496525729060172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.023077249526978, "step": 13000}
{"episode_reward": 22.15030913402552, "episode": 14.0, "batch_reward": 0.08893169846013188, "critic_loss": 0.1173814435787499, "actor_loss": -14.275376496315003, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99106764793396, "step": 14000}
{"episode_reward": 28.18796032045788, "episode": 15.0, "batch_reward": 0.09116256260126829, "critic_loss": 0.1351038409397006, "actor_loss": -14.053419479370117, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.001205444335938, "step": 15000}
{"episode_reward": 172.9632202886941, "episode": 16.0, "batch_reward": 0.09625648850947618, "critic_loss": 0.18115044470131397, "actor_loss": -14.862574995040893, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00074863433838, "step": 16000}
{"episode_reward": 171.72177501987989, "episode": 17.0, "batch_reward": 0.09378594789654017, "critic_loss": 0.1282958618812263, "actor_loss": -14.453249188423158, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.984315633773804, "step": 17000}
{"episode_reward": 4.379152657114582, "episode": 18.0, "batch_reward": 0.08963547510281206, "critic_loss": 0.12574070316180586, "actor_loss": -15.422872940063476, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01447057723999, "step": 18000}
{"episode_reward": 31.41654690437129, "episode": 19.0, "batch_reward": 0.08675582199543715, "critic_loss": 0.11507399296760559, "actor_loss": -15.04000000667572, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.006032466888428, "step": 19000}
{"episode_reward": 121.64834748230324, "episode": 20.0, "batch_reward": 0.09091296666115523, "critic_loss": 0.150713453091681, "actor_loss": -15.942026146888733, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01770305633545, "step": 20000}
{"episode_reward": 103.4658963866592, "episode": 21.0, "batch_reward": 0.09195681546628476, "critic_loss": 0.15520489285141228, "actor_loss": -15.335914714813232, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.534202575683594, "step": 21000}
{"episode_reward": 102.0715588270597, "episode": 22.0, "batch_reward": 0.09451478190347552, "critic_loss": 0.19689076240360737, "actor_loss": -16.03918015575409, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.979852437973022, "step": 22000}
{"episode_reward": 179.62446296565957, "episode": 23.0, "batch_reward": 0.09710227303206921, "critic_loss": 0.19593657080084084, "actor_loss": -15.512410027503968, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01200771331787, "step": 23000}
{"episode_reward": 109.17493639766563, "episode": 24.0, "batch_reward": 0.09498959178850054, "critic_loss": 0.17925492314994335, "actor_loss": -15.009243100166321, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.96537184715271, "step": 24000}
{"episode_reward": 43.69193808568455, "episode": 25.0, "batch_reward": 0.09532538655772806, "critic_loss": 0.2207538182064891, "actor_loss": -16.08693531894684, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.383901119232178, "step": 25000}
{"episode_reward": 226.40115491390063, "episode": 26.0, "batch_reward": 0.10102696440368891, "critic_loss": 0.26400635179132226, "actor_loss": -15.892417812347412, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.005772590637207, "step": 26000}
{"episode_reward": 150.68560216833015, "episode": 27.0, "batch_reward": 0.1043249614983797, "critic_loss": 0.27371344313770535, "actor_loss": -16.457645875930787, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.972607612609863, "step": 27000}
{"episode_reward": 281.3895413521569, "episode": 28.0, "batch_reward": 0.10736911023408174, "critic_loss": 0.2785405243635178, "actor_loss": -17.182937644958496, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.002234935760498, "step": 28000}
{"episode_reward": 96.6366530579854, "episode": 29.0, "batch_reward": 0.10843604977428913, "critic_loss": 0.2631239403039217, "actor_loss": -17.075250456809997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01130747795105, "step": 29000}
{"episode_reward": 169.12640228182468, "episode": 30.0, "batch_reward": 0.10990151995420457, "critic_loss": 0.2856237770244479, "actor_loss": -16.903297097206117, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.019248247146606, "step": 30000}
{"episode_reward": 105.48148554810524, "episode": 31.0, "batch_reward": 0.11160735426098109, "critic_loss": 0.29270355026423933, "actor_loss": -18.026486732482912, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.52505660057068, "step": 31000}
{"episode_reward": 197.0788356361711, "episode": 32.0, "batch_reward": 0.11424628154188395, "critic_loss": 0.3068259066045284, "actor_loss": -17.5933881483078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.001150608062744, "step": 32000}
{"episode_reward": 312.18368698357835, "episode": 33.0, "batch_reward": 0.12019748228788375, "critic_loss": 0.3738601008653641, "actor_loss": -18.410364192962646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.009061336517334, "step": 33000}
{"episode_reward": 278.88518803209246, "episode": 34.0, "batch_reward": 0.12486242183297873, "critic_loss": 0.4053842262774706, "actor_loss": -19.029095119476317, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.011518478393555, "step": 34000}
{"episode_reward": 240.50084394814215, "episode": 35.0, "batch_reward": 0.12623009515553713, "critic_loss": 0.39732037170231344, "actor_loss": -18.968408924102782, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02215313911438, "step": 35000}
{"episode_reward": 76.70683554649872, "episode": 36.0, "batch_reward": 0.12701705733686686, "critic_loss": 0.3897370103448629, "actor_loss": -19.560649057388307, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99321174621582, "step": 36000}
{"episode_reward": 163.67775524331483, "episode": 37.0, "batch_reward": 0.1275776770785451, "critic_loss": 0.38031467793881896, "actor_loss": -19.47174959754944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.010828495025635, "step": 37000}
{"episode_reward": 164.81976595479242, "episode": 38.0, "batch_reward": 0.1293461826145649, "critic_loss": 0.36911235769093037, "actor_loss": -19.43062511062622, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.988338708877563, "step": 38000}
{"episode_reward": 278.0076652183962, "episode": 39.0, "batch_reward": 0.13063747858256103, "critic_loss": 0.3921637748479843, "actor_loss": -20.186651571273803, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01427721977234, "step": 39000}
{"episode_reward": 124.18079267119579, "episode": 40.0, "batch_reward": 0.13337818779796362, "critic_loss": 0.4168752409219742, "actor_loss": -20.95853723716736, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.991503477096558, "step": 40000}
{"episode_reward": 343.84038184456085, "episode": 41.0, "batch_reward": 0.1377902363240719, "critic_loss": 0.40761788764595985, "actor_loss": -21.036512310028076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.49087905883789, "step": 41000}
{"episode_reward": 305.28875342462425, "episode": 42.0, "batch_reward": 0.14114790557324886, "critic_loss": 0.4061062712073326, "actor_loss": -21.21303067779541, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00980257987976, "step": 42000}
{"episode_reward": 206.5298241798211, "episode": 43.0, "batch_reward": 0.14421479099243878, "critic_loss": 0.41401509825885296, "actor_loss": -21.690882005691527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.007147550582886, "step": 43000}
{"episode_reward": 323.6950860677715, "episode": 44.0, "batch_reward": 0.14920050336420537, "critic_loss": 0.48949463284015654, "actor_loss": -21.815500957489014, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.007557153701782, "step": 44000}
{"episode_reward": 348.67330971500354, "episode": 45.0, "batch_reward": 0.1522853986993432, "critic_loss": 0.4876283914297819, "actor_loss": -21.920441415786744, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.003942489624023, "step": 45000}
{"episode_reward": 248.75132371063015, "episode": 46.0, "batch_reward": 0.15426544390618802, "critic_loss": 0.49213388477265835, "actor_loss": -22.062070095062257, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.006743907928467, "step": 46000}
{"episode_reward": 176.77711401804243, "episode": 47.0, "batch_reward": 0.15503382006287575, "critic_loss": 0.46841039399802686, "actor_loss": -22.209425352096556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.990580797195435, "step": 47000}
{"episode_reward": 367.4736092263042, "episode": 48.0, "batch_reward": 0.15983367601782084, "critic_loss": 0.46825296549499035, "actor_loss": -22.337911476135254, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.98792791366577, "step": 48000}
{"episode_reward": 381.1630545811631, "episode": 49.0, "batch_reward": 0.16347648260742426, "critic_loss": 0.4412353153526783, "actor_loss": -22.62560047531128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.981045484542847, "step": 49000}
{"episode_reward": 175.46911767385762, "episode": 50.0, "batch_reward": 0.16365204080194234, "critic_loss": 0.4234896302819252, "actor_loss": -22.638834129333496, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.985902547836304, "step": 50000}
{"episode_reward": 197.7848385157412, "episode": 51.0, "batch_reward": 0.1640413021221757, "critic_loss": 0.433532430768013, "actor_loss": -22.9653274269104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.84649085998535, "step": 51000}
{"episode_reward": 198.35204438578606, "episode": 52.0, "batch_reward": 0.16531909511238335, "critic_loss": 0.4274191890507936, "actor_loss": -22.792695684432985, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.075132846832275, "step": 52000}
{"episode_reward": 104.20405185530217, "episode": 53.0, "batch_reward": 0.16530348348617555, "critic_loss": 0.4513780364841223, "actor_loss": -23.03217734718323, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.98169469833374, "step": 53000}
{"episode_reward": 273.7758047507719, "episode": 54.0, "batch_reward": 0.16649731001257898, "critic_loss": 0.4552277607768774, "actor_loss": -22.997064649581908, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.048373699188232, "step": 54000}
{"episode_reward": 240.7694610305077, "episode": 55.0, "batch_reward": 0.16773669262230395, "critic_loss": 0.4438757652789354, "actor_loss": -23.182286321640014, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.086742162704468, "step": 55000}
{"episode_reward": 366.0400204975552, "episode": 56.0, "batch_reward": 0.17116547952592373, "critic_loss": 0.424223174020648, "actor_loss": -23.747097047805788, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.052224159240723, "step": 56000}
{"episode_reward": 352.59045248407193, "episode": 57.0, "batch_reward": 0.17479526054859162, "critic_loss": 0.45287006530165674, "actor_loss": -23.859614149093627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.990321397781372, "step": 57000}
{"episode_reward": 396.9017064832037, "episode": 58.0, "batch_reward": 0.1790565556138754, "critic_loss": 0.4604117632508278, "actor_loss": -24.297539152145387, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.993979930877686, "step": 58000}
{"episode_reward": 348.81108697551514, "episode": 59.0, "batch_reward": 0.18175542229413985, "critic_loss": 0.47763500379025936, "actor_loss": -24.511977462768556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99181318283081, "step": 59000}
{"episode_reward": 357.7897763333731, "episode": 60.0, "batch_reward": 0.1853760427236557, "critic_loss": 0.45452898763120175, "actor_loss": -24.72226300048828, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.003124475479126, "step": 60000}
{"episode_reward": 411.65442762066476, "episode": 61.0, "batch_reward": 0.18811926759779454, "critic_loss": 0.4721360095143318, "actor_loss": -24.87596318244934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.41447043418884, "step": 61000}
{"episode_reward": 374.83078049830954, "episode": 62.0, "batch_reward": 0.19004433058202266, "critic_loss": 0.451897044762969, "actor_loss": -24.76081315994263, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05234932899475, "step": 62000}
{"episode_reward": 54.003796564590246, "episode": 63.0, "batch_reward": 0.19002929058670998, "critic_loss": 0.4551876185536385, "actor_loss": -25.13981588745117, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0123233795166, "step": 63000}
{"episode_reward": 367.1017018473035, "episode": 64.0, "batch_reward": 0.19037050469219685, "critic_loss": 0.4642791856825352, "actor_loss": -25.483162128448487, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.003992795944214, "step": 64000}
{"episode_reward": 102.0323797797436, "episode": 65.0, "batch_reward": 0.1909888053238392, "critic_loss": 0.47643242740631103, "actor_loss": -25.211407222747802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.999838829040527, "step": 65000}
{"episode_reward": 260.40441085161063, "episode": 66.0, "batch_reward": 0.1913332148194313, "critic_loss": 0.48523605619370935, "actor_loss": -25.288237407684328, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.005479335784912, "step": 66000}
{"episode_reward": 217.65939551496527, "episode": 67.0, "batch_reward": 0.1926269881427288, "critic_loss": 0.5078826635628939, "actor_loss": -25.081666732788086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.020646333694458, "step": 67000}
{"episode_reward": 427.65215765950495, "episode": 68.0, "batch_reward": 0.19651671725511552, "critic_loss": 0.5241266302317381, "actor_loss": -25.955395122528078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.032148361206055, "step": 68000}
{"episode_reward": 327.9862656808384, "episode": 69.0, "batch_reward": 0.19796732461452485, "critic_loss": 0.5651234746128321, "actor_loss": -25.54686795425415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01724863052368, "step": 69000}
{"episode_reward": 396.88160784812385, "episode": 70.0, "batch_reward": 0.20046900825202466, "critic_loss": 0.5372440639287234, "actor_loss": -25.89797998046875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.004135370254517, "step": 70000}
{"episode_reward": 340.4299854991098, "episode": 71.0, "batch_reward": 0.2034402724802494, "critic_loss": 0.5767831624150276, "actor_loss": -26.039134185791017, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.4545202255249, "step": 71000}
{"episode_reward": 418.67261776505467, "episode": 72.0, "batch_reward": 0.20435239504277705, "critic_loss": 0.575550787165761, "actor_loss": -26.37040380859375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.033939838409424, "step": 72000}
{"episode_reward": 351.36797860333854, "episode": 73.0, "batch_reward": 0.2079853444993496, "critic_loss": 0.5882306852787733, "actor_loss": -26.58751343536377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.038943767547607, "step": 73000}
{"episode_reward": 420.6189082214833, "episode": 74.0, "batch_reward": 0.2102715893238783, "critic_loss": 0.5789680247604847, "actor_loss": -27.084015781402588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.982141256332397, "step": 74000}
{"episode_reward": 366.2387683848807, "episode": 75.0, "batch_reward": 0.21285788315534593, "critic_loss": 0.5801201776117086, "actor_loss": -27.406593254089355, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99579119682312, "step": 75000}
{"episode_reward": 455.0832903159343, "episode": 76.0, "batch_reward": 0.21545265540480613, "critic_loss": 0.6030589721500873, "actor_loss": -27.512883567810057, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.010119915008545, "step": 76000}
{"episode_reward": 204.69354460281207, "episode": 77.0, "batch_reward": 0.2160309834778309, "critic_loss": 0.5812615548968315, "actor_loss": -27.420389038085936, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.97668194770813, "step": 77000}
{"episode_reward": 410.73586838216664, "episode": 78.0, "batch_reward": 0.21840133921802043, "critic_loss": 0.628050816386938, "actor_loss": -27.473555335998537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.990219593048096, "step": 78000}
{"episode_reward": 361.3331039712127, "episode": 79.0, "batch_reward": 0.22138301955163478, "critic_loss": 0.5968878244459629, "actor_loss": -28.089150245666502, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.009224891662598, "step": 79000}
{"episode_reward": 453.07112617505504, "episode": 80.0, "batch_reward": 0.22313302293419837, "critic_loss": 0.6325221255123615, "actor_loss": -28.244711883544923, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.98701548576355, "step": 80000}
{"episode_reward": 500.85782278848455, "episode": 81.0, "batch_reward": 0.22663723385334014, "critic_loss": 0.6189040249586105, "actor_loss": -28.578521713256837, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.410836696624756, "step": 81000}
{"episode_reward": 425.8603250982259, "episode": 82.0, "batch_reward": 0.22844980275630952, "critic_loss": 0.6010221591293812, "actor_loss": -28.77885892868042, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.004581689834595, "step": 82000}
{"episode_reward": 427.7747877634056, "episode": 83.0, "batch_reward": 0.23122608019411564, "critic_loss": 0.6150550967603922, "actor_loss": -28.79314256668091, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0110924243927, "step": 83000}
{"episode_reward": 369.04682145062736, "episode": 84.0, "batch_reward": 0.231800289824605, "critic_loss": 0.6793418394774199, "actor_loss": -28.951329513549805, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.981951475143433, "step": 84000}
{"episode_reward": 246.9258997292577, "episode": 85.0, "batch_reward": 0.2325015732049942, "critic_loss": 0.6671935073137283, "actor_loss": -29.052309005737303, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.003108024597168, "step": 85000}
{"episode_reward": 436.25682976845906, "episode": 86.0, "batch_reward": 0.2355604257583618, "critic_loss": 0.63416896879673, "actor_loss": -29.000042701721192, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.006697416305542, "step": 86000}
{"episode_reward": 472.40011356632385, "episode": 87.0, "batch_reward": 0.23832043948769568, "critic_loss": 0.6337048017382622, "actor_loss": -29.28632011795044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00839638710022, "step": 87000}
{"episode_reward": 440.49427979613347, "episode": 88.0, "batch_reward": 0.2410497312694788, "critic_loss": 0.6578706732988358, "actor_loss": -29.376111351013183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.97573208808899, "step": 88000}
{"episode_reward": 463.0856527183355, "episode": 89.0, "batch_reward": 0.24355425056815147, "critic_loss": 0.6058596724122762, "actor_loss": -29.753775512695313, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01694893836975, "step": 89000}
{"episode_reward": 465.99037858417347, "episode": 90.0, "batch_reward": 0.24617876128852367, "critic_loss": 0.6105224871337414, "actor_loss": -29.997626377105714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.014796257019043, "step": 90000}
{"episode_reward": 348.6164911280384, "episode": 91.0, "batch_reward": 0.24649279142916203, "critic_loss": 0.6191856534481048, "actor_loss": -29.999393466949464, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.4385941028595, "step": 91000}
{"episode_reward": 458.49970676000146, "episode": 92.0, "batch_reward": 0.24833954456448554, "critic_loss": 0.6110007769465446, "actor_loss": -29.67723722076416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00492525100708, "step": 92000}
{"episode_reward": 263.3557049792239, "episode": 93.0, "batch_reward": 0.2505323882997036, "critic_loss": 0.6515981678962708, "actor_loss": -30.32715491104126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.995073556900024, "step": 93000}
{"episode_reward": 519.9592709318789, "episode": 94.0, "batch_reward": 0.25245058885216715, "critic_loss": 0.6013268392682075, "actor_loss": -30.086016605377196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0330228805542, "step": 94000}
{"episode_reward": 269.5321637831337, "episode": 95.0, "batch_reward": 0.2525318629294634, "critic_loss": 0.6028455246388912, "actor_loss": -30.646853927612305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.992022037506104, "step": 95000}
{"episode_reward": 513.1047511973369, "episode": 96.0, "batch_reward": 0.2553977709710598, "critic_loss": 0.5827849116325379, "actor_loss": -30.28546565628052, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02413034439087, "step": 96000}
{"episode_reward": 396.52040720474895, "episode": 97.0, "batch_reward": 0.25690237432718277, "critic_loss": 0.5536708138883114, "actor_loss": -30.87660202026367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.017268657684326, "step": 97000}
{"episode_reward": 477.17652546973227, "episode": 98.0, "batch_reward": 0.26046519669890406, "critic_loss": 0.5440335597991943, "actor_loss": -31.377836994171144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.96824073791504, "step": 98000}
{"episode_reward": 505.6682117675188, "episode": 99.0, "batch_reward": 0.26079274843633177, "critic_loss": 0.5036009236872196, "actor_loss": -31.115769123077392, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.006744861602783, "step": 99000}
{"episode_reward": 542.5555691353944, "episode": 100.0, "batch_reward": 0.26387585490942, "critic_loss": 0.5096525679677725, "actor_loss": -31.268256607055665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.029794216156006, "step": 100000}
{"episode_reward": 498.1927264640834, "episode": 101.0, "batch_reward": 0.2668140026628971, "critic_loss": 0.4965086335539818, "actor_loss": -31.20937073135376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.416078090667725, "step": 101000}
{"episode_reward": 485.7088673458058, "episode": 102.0, "batch_reward": 0.2684223636239767, "critic_loss": 0.4955424582064152, "actor_loss": -31.651989753723143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.031959056854248, "step": 102000}
{"episode_reward": 524.2385418366997, "episode": 103.0, "batch_reward": 0.2709172793477774, "critic_loss": 0.4875112327635288, "actor_loss": -31.572828868865965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.011252641677856, "step": 103000}
{"episode_reward": 548.0054731981251, "episode": 104.0, "batch_reward": 0.27511947743594645, "critic_loss": 0.4567664663791656, "actor_loss": -32.32617137908935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.014154195785522, "step": 104000}
{"episode_reward": 537.8688265100054, "episode": 105.0, "batch_reward": 0.2766509637236595, "critic_loss": 0.4808760182857513, "actor_loss": -32.123752712249754, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.019060134887695, "step": 105000}
{"episode_reward": 517.7732158935693, "episode": 106.0, "batch_reward": 0.27920024098455903, "critic_loss": 0.44612952080368995, "actor_loss": -32.63043378829956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00840663909912, "step": 106000}
{"episode_reward": 543.0901551434503, "episode": 107.0, "batch_reward": 0.2816561741530895, "critic_loss": 0.4318614533990622, "actor_loss": -32.95797240829468, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0212984085083, "step": 107000}
{"episode_reward": 563.2556048676279, "episode": 108.0, "batch_reward": 0.28455862802267073, "critic_loss": 0.4288034344315529, "actor_loss": -32.96420364761352, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.010494232177734, "step": 108000}
{"episode_reward": 560.0857862186486, "episode": 109.0, "batch_reward": 0.2876866356879473, "critic_loss": 0.45123006078600886, "actor_loss": -33.31417306137085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.020689725875854, "step": 109000}
{"episode_reward": 526.1702812218895, "episode": 110.0, "batch_reward": 0.2888698104470968, "critic_loss": 0.4424599831700325, "actor_loss": -33.349672412872316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99856400489807, "step": 110000}
{"episode_reward": 527.2606985864229, "episode": 111.0, "batch_reward": 0.29097583518922326, "critic_loss": 0.43763320046663284, "actor_loss": -33.2877414932251, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.39862036705017, "step": 111000}
{"episode_reward": 560.5128011591995, "episode": 112.0, "batch_reward": 0.29271837532520295, "critic_loss": 0.39692115227878094, "actor_loss": -33.5032950630188, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.034735202789307, "step": 112000}
{"episode_reward": 546.7457545233065, "episode": 113.0, "batch_reward": 0.2961734966337681, "critic_loss": 0.4351324856728315, "actor_loss": -33.41953022384644, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.004188060760498, "step": 113000}
{"episode_reward": 547.2918444404434, "episode": 114.0, "batch_reward": 0.298035746216774, "critic_loss": 0.42025734013319016, "actor_loss": -33.862507637023924, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00998044013977, "step": 114000}
{"episode_reward": 564.2951320003295, "episode": 115.0, "batch_reward": 0.300365141287446, "critic_loss": 0.4104408195614815, "actor_loss": -34.552493965148926, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.001627922058105, "step": 115000}
{"episode_reward": 503.71396688072144, "episode": 116.0, "batch_reward": 0.3018931618332863, "critic_loss": 0.41190751004219056, "actor_loss": -34.21443664169311, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00027894973755, "step": 116000}
{"episode_reward": 603.9471683114581, "episode": 117.0, "batch_reward": 0.30462325748801233, "critic_loss": 0.41543556690216066, "actor_loss": -34.64760095977783, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.001145601272583, "step": 117000}
{"episode_reward": 562.8295706030258, "episode": 118.0, "batch_reward": 0.3066573113203049, "critic_loss": 0.4119560740590095, "actor_loss": -34.61980661392212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.044601440429688, "step": 118000}
{"episode_reward": 492.10154227837495, "episode": 119.0, "batch_reward": 0.30730112436413765, "critic_loss": 0.4084706504046917, "actor_loss": -34.61533168029785, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99977397918701, "step": 119000}
{"episode_reward": 565.6579418766497, "episode": 120.0, "batch_reward": 0.3105328274965286, "critic_loss": 0.4033522480577231, "actor_loss": -35.13921912765503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.988908052444458, "step": 120000}
{"episode_reward": 541.9450222666106, "episode": 121.0, "batch_reward": 0.31362493567168714, "critic_loss": 0.42590856197476384, "actor_loss": -35.31338270187378, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.39942026138306, "step": 121000}
{"episode_reward": 557.4427642074819, "episode": 122.0, "batch_reward": 0.3148221202790737, "critic_loss": 0.4183096526414156, "actor_loss": -35.728415637969974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.011089086532593, "step": 122000}
{"episode_reward": 511.2682948194434, "episode": 123.0, "batch_reward": 0.3160107551217079, "critic_loss": 0.43792604964971543, "actor_loss": -35.886609504699706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.342629194259644, "step": 123000}
{"episode_reward": 549.0115515825748, "episode": 124.0, "batch_reward": 0.31789640203118325, "critic_loss": 0.41653796765208245, "actor_loss": -35.878102848052976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.022598028182983, "step": 124000}
{"episode_reward": 598.2435212641791, "episode": 125.0, "batch_reward": 0.32076909971237183, "critic_loss": 0.4401584646254778, "actor_loss": -35.99782664108277, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.98009991645813, "step": 125000}
{"episode_reward": 576.4885688221415, "episode": 126.0, "batch_reward": 0.3220973164141178, "critic_loss": 0.4649185032993555, "actor_loss": -36.10033901977539, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.984753847122192, "step": 126000}
{"episode_reward": 609.5380012918448, "episode": 127.0, "batch_reward": 0.3248451059162617, "critic_loss": 0.4539535875171423, "actor_loss": -36.373696384429934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00392174720764, "step": 127000}
{"episode_reward": 559.0536557698498, "episode": 128.0, "batch_reward": 0.32674184000492096, "critic_loss": 0.4788847385942936, "actor_loss": -36.20441632080078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.047656059265137, "step": 128000}
{"episode_reward": 569.3509307751717, "episode": 129.0, "batch_reward": 0.32803343749046326, "critic_loss": 0.568717882335186, "actor_loss": -36.2959573173523, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.005464792251587, "step": 129000}
{"episode_reward": 314.5742354527723, "episode": 130.0, "batch_reward": 0.3283515135347843, "critic_loss": 0.702367541745305, "actor_loss": -36.71664538192749, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.044790029525757, "step": 130000}
{"episode_reward": 576.1807771662767, "episode": 131.0, "batch_reward": 0.33017991015315057, "critic_loss": 0.7976485022902489, "actor_loss": -36.089756927490235, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.589877128601074, "step": 131000}
{"episode_reward": 597.6444974218421, "episode": 132.0, "batch_reward": 0.3319644056856632, "critic_loss": 0.8649296329319477, "actor_loss": -36.68577883529663, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.050912618637085, "step": 132000}
{"episode_reward": 573.6189192995662, "episode": 133.0, "batch_reward": 0.3325214086472988, "critic_loss": 0.8944298681616784, "actor_loss": -36.92541801834106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.068506479263306, "step": 133000}
{"episode_reward": 594.7181717024826, "episode": 134.0, "batch_reward": 0.3359382666349411, "critic_loss": 0.9602462817430496, "actor_loss": -37.19294649887085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.97846269607544, "step": 134000}
{"episode_reward": 440.36202033974143, "episode": 135.0, "batch_reward": 0.3362851600050926, "critic_loss": 1.178661334335804, "actor_loss": -37.737398670196534, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02636981010437, "step": 135000}
{"episode_reward": 259.41311269993366, "episode": 136.0, "batch_reward": 0.3358561245799065, "critic_loss": 1.1645352937281133, "actor_loss": -37.88505488204956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.015268325805664, "step": 136000}
{"episode_reward": 573.5186461894697, "episode": 137.0, "batch_reward": 0.33832937252521517, "critic_loss": 1.218063413977623, "actor_loss": -37.97286393356323, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99271297454834, "step": 137000}
{"episode_reward": 574.2944403716172, "episode": 138.0, "batch_reward": 0.3393451726436615, "critic_loss": 1.3147655932307243, "actor_loss": -38.169855854034424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02551555633545, "step": 138000}
{"episode_reward": 507.1634403997689, "episode": 139.0, "batch_reward": 0.341147573530674, "critic_loss": 1.2005789602398873, "actor_loss": -38.59512006759643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.034609079360962, "step": 139000}
{"episode_reward": 440.8466522284106, "episode": 140.0, "batch_reward": 0.3404403443932533, "critic_loss": 1.1925888218283653, "actor_loss": -38.83248303985596, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02052330970764, "step": 140000}
{"episode_reward": 371.88013362322374, "episode": 141.0, "batch_reward": 0.3412479777038097, "critic_loss": 1.1629608480334281, "actor_loss": -39.58302751159668, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.416661739349365, "step": 141000}
{"episode_reward": 364.8941955135367, "episode": 142.0, "batch_reward": 0.3397665898501873, "critic_loss": 1.2232459392547608, "actor_loss": -39.450123489379884, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02505588531494, "step": 142000}
{"episode_reward": 236.39662376902632, "episode": 143.0, "batch_reward": 0.3405414120554924, "critic_loss": 1.3292570600509643, "actor_loss": -39.84064115905762, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.03738307952881, "step": 143000}
{"episode_reward": 80.70795526561892, "episode": 144.0, "batch_reward": 0.3402299254834652, "critic_loss": 1.315406661272049, "actor_loss": -39.70715033721924, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.022144079208374, "step": 144000}
{"episode_reward": 527.9254213281878, "episode": 145.0, "batch_reward": 0.34077317628264425, "critic_loss": 1.2419271396398543, "actor_loss": -39.94486669921875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02335548400879, "step": 145000}
{"episode_reward": 418.97504490270813, "episode": 146.0, "batch_reward": 0.3400566165447235, "critic_loss": 1.1987906103134156, "actor_loss": -39.78622086334229, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.038654565811157, "step": 146000}
{"episode_reward": 281.7496466620253, "episode": 147.0, "batch_reward": 0.34060538199543955, "critic_loss": 1.0758262141942978, "actor_loss": -39.98852171325684, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.019458055496216, "step": 147000}
{"episode_reward": 315.1479653883492, "episode": 148.0, "batch_reward": 0.34052924582362176, "critic_loss": 1.0709703024327755, "actor_loss": -39.93470764160156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.005850553512573, "step": 148000}
{"episode_reward": 526.7307324431554, "episode": 149.0, "batch_reward": 0.341491288125515, "critic_loss": 1.0221386359035969, "actor_loss": -39.812533172607424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.991278171539307, "step": 149000}
{"episode_reward": 591.8199679042401, "episode": 150.0, "batch_reward": 0.34355490931868554, "critic_loss": 0.9822621995806694, "actor_loss": -39.85782378387451, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
