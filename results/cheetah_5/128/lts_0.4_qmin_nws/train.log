{"episode_reward": 0.0, "episode": 1.0, "duration": 17.541840314865112, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.522409439086914, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.26602164150854474, "critic_loss": 0.040567799422252714, "actor_loss": -18.21851722304547, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 62.21744704246521, "step": 3000}
{"episode_reward": 124.54453505231956, "episode": 4.0, "batch_reward": 0.1985776954293251, "critic_loss": 0.02873847608268261, "actor_loss": -14.211686904102564, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.48076295852661, "step": 4000}
{"episode_reward": 18.299375712665572, "episode": 5.0, "batch_reward": 0.15612937108427286, "critic_loss": 0.04749394747428596, "actor_loss": -11.020407234370708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.47608470916748, "step": 5000}
{"episode_reward": 7.245728955588047, "episode": 6.0, "batch_reward": 0.1360550554394722, "critic_loss": 0.05276625563390553, "actor_loss": -10.060087520450354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.492316484451294, "step": 6000}
{"episode_reward": 56.26687419516693, "episode": 7.0, "batch_reward": 0.11835755917429924, "critic_loss": 0.04893245898373425, "actor_loss": -8.867727443046867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.499343395233154, "step": 7000}
{"episode_reward": 14.073860817005926, "episode": 8.0, "batch_reward": 0.10722015979140997, "critic_loss": 0.05994401321187615, "actor_loss": -9.4145726448223, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.468994140625, "step": 8000}
{"episode_reward": 46.46570506554716, "episode": 9.0, "batch_reward": 0.0989780582934618, "critic_loss": 0.060634134912863374, "actor_loss": -8.508126724511385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.51299810409546, "step": 9000}
{"episode_reward": 29.269021883694126, "episode": 10.0, "batch_reward": 0.09538508908078075, "critic_loss": 0.07721647561900317, "actor_loss": -8.722027387499809, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.480696201324463, "step": 10000}
{"episode_reward": 116.6811876412479, "episode": 11.0, "batch_reward": 0.09685295083373785, "critic_loss": 0.08576064547523857, "actor_loss": -8.934241182923317, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.89397358894348, "step": 11000}
{"episode_reward": 84.92167414189711, "episode": 12.0, "batch_reward": 0.09302705296874046, "critic_loss": 0.08753306616097689, "actor_loss": -9.588220590591432, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.462693452835083, "step": 12000}
{"episode_reward": 85.64630660040186, "episode": 13.0, "batch_reward": 0.0938223773315549, "critic_loss": 0.10861632990464568, "actor_loss": -10.100041604280472, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.49747133255005, "step": 13000}
{"episode_reward": 85.13698777888698, "episode": 14.0, "batch_reward": 0.09442147738859058, "critic_loss": 0.12046929813548922, "actor_loss": -11.24556571817398, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.47999906539917, "step": 14000}
{"episode_reward": 130.48997413488138, "episode": 15.0, "batch_reward": 0.09920875064656139, "critic_loss": 0.13689545183628798, "actor_loss": -11.169111181259156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.4433171749115, "step": 15000}
{"episode_reward": 142.66427232861204, "episode": 16.0, "batch_reward": 0.10382940605282784, "critic_loss": 0.16231502345204354, "actor_loss": -11.678626299858093, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.47554087638855, "step": 16000}
{"episode_reward": 230.87310638632357, "episode": 17.0, "batch_reward": 0.10907326840609312, "critic_loss": 0.18977512062340976, "actor_loss": -12.596756104946136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.46584963798523, "step": 17000}
{"episode_reward": 234.53756344968218, "episode": 18.0, "batch_reward": 0.1184800970107317, "critic_loss": 0.1982349527478218, "actor_loss": -14.093825534820557, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.47523331642151, "step": 18000}
{"episode_reward": 217.8370411398739, "episode": 19.0, "batch_reward": 0.12045708563178778, "critic_loss": 0.18830096428096293, "actor_loss": -13.886254000663758, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.467745304107666, "step": 19000}
{"episode_reward": 89.08375508178871, "episode": 20.0, "batch_reward": 0.12161316362023354, "critic_loss": 0.17620811450481416, "actor_loss": -14.433343715667725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.487266063690186, "step": 20000}
{"episode_reward": 204.76373560833414, "episode": 21.0, "batch_reward": 0.12387501926720143, "critic_loss": 0.18303822150081397, "actor_loss": -14.59664474105835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.00409293174744, "step": 21000}
{"episode_reward": 68.94783351416662, "episode": 22.0, "batch_reward": 0.12121438433229924, "critic_loss": 0.17258117198199033, "actor_loss": -14.720613916397095, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.497277975082397, "step": 22000}
{"episode_reward": 123.19700960517763, "episode": 23.0, "batch_reward": 0.12344951683282852, "critic_loss": 0.20163046503067017, "actor_loss": -14.791504013061523, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.498539209365845, "step": 23000}
{"episode_reward": 180.19523768752663, "episode": 24.0, "batch_reward": 0.1255049377605319, "critic_loss": 0.21895940355956556, "actor_loss": -14.68215899848938, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.867276191711426, "step": 24000}
{"episode_reward": 189.31972519318654, "episode": 25.0, "batch_reward": 0.1274448064342141, "critic_loss": 0.22452600958943367, "actor_loss": -15.794542287826538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.476398706436157, "step": 25000}
{"episode_reward": 211.74900686431062, "episode": 26.0, "batch_reward": 0.1297347969189286, "critic_loss": 0.21420146311074495, "actor_loss": -15.704542273521424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.482438564300537, "step": 26000}
{"episode_reward": 82.32431540536305, "episode": 27.0, "batch_reward": 0.1296672777682543, "critic_loss": 0.2045907318741083, "actor_loss": -15.703228877067566, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.471226930618286, "step": 27000}
{"episode_reward": 159.64038512989217, "episode": 28.0, "batch_reward": 0.1296353411078453, "critic_loss": 0.21309305141866208, "actor_loss": -16.403620811462403, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.475374221801758, "step": 28000}
{"episode_reward": 198.99014214904537, "episode": 29.0, "batch_reward": 0.1339804692864418, "critic_loss": 0.2437517239227891, "actor_loss": -16.667886735916138, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.477256536483765, "step": 29000}
{"episode_reward": 266.65439884607235, "episode": 30.0, "batch_reward": 0.13749203967303036, "critic_loss": 0.2858034908473492, "actor_loss": -16.990004961013796, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.51400065422058, "step": 30000}
{"episode_reward": 180.82087709818995, "episode": 31.0, "batch_reward": 0.1392307034060359, "critic_loss": 0.2790555750280619, "actor_loss": -17.921279235839844, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.96625733375549, "step": 31000}
{"episode_reward": 228.86892324600697, "episode": 32.0, "batch_reward": 0.14270663689821958, "critic_loss": 0.26776767148822544, "actor_loss": -17.69511566734314, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.48218321800232, "step": 32000}
{"episode_reward": 285.2350159345174, "episode": 33.0, "batch_reward": 0.1462022402435541, "critic_loss": 0.2715291605442762, "actor_loss": -18.156288738250733, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.49107050895691, "step": 33000}
{"episode_reward": 180.58825527961088, "episode": 34.0, "batch_reward": 0.1477232336625457, "critic_loss": 0.2707911260277033, "actor_loss": -18.454629489898682, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.46199679374695, "step": 34000}
{"episode_reward": 166.1936458161719, "episode": 35.0, "batch_reward": 0.14688926241546868, "critic_loss": 0.2683157579526305, "actor_loss": -18.060500701904296, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.49036955833435, "step": 35000}
{"episode_reward": 97.75368980334535, "episode": 36.0, "batch_reward": 0.14683381779491902, "critic_loss": 0.277857505954802, "actor_loss": -18.45543619155884, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.482261180877686, "step": 36000}
{"episode_reward": 145.32412142383407, "episode": 37.0, "batch_reward": 0.1470798474624753, "critic_loss": 0.2856715444996953, "actor_loss": -18.26377527618408, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.496347904205322, "step": 37000}
{"episode_reward": 176.01163495706137, "episode": 38.0, "batch_reward": 0.14789099826663732, "critic_loss": 0.29517447467148306, "actor_loss": -18.41427656173706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.472204208374023, "step": 38000}
{"episode_reward": 264.4844856921746, "episode": 39.0, "batch_reward": 0.14946826552599668, "critic_loss": 0.31594834570586683, "actor_loss": -18.87887480545044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.47059988975525, "step": 39000}
{"episode_reward": 92.07314802958082, "episode": 40.0, "batch_reward": 0.15077104195207358, "critic_loss": 0.3510798226296902, "actor_loss": -19.456068454742432, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.479060888290405, "step": 40000}
{"episode_reward": 380.83742647985383, "episode": 41.0, "batch_reward": 0.15433572785556315, "critic_loss": 0.3827604951560497, "actor_loss": -19.679166431427003, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.92878699302673, "step": 41000}
{"episode_reward": 306.01231595704667, "episode": 42.0, "batch_reward": 0.15945913428068162, "critic_loss": 0.3464404651671648, "actor_loss": -20.168436712265013, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.497468948364258, "step": 42000}
{"episode_reward": 242.2715260696694, "episode": 43.0, "batch_reward": 0.16116553716361523, "critic_loss": 0.37055455955863, "actor_loss": -20.4479877948761, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.486277103424072, "step": 43000}
{"episode_reward": 298.9915153803584, "episode": 44.0, "batch_reward": 0.16507003279030322, "critic_loss": 0.37742535100877284, "actor_loss": -20.715575401306154, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.480919122695923, "step": 44000}
{"episode_reward": 313.70799557232954, "episode": 45.0, "batch_reward": 0.16840244446694852, "critic_loss": 0.39212596921622755, "actor_loss": -20.73481794166565, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.48611330986023, "step": 45000}
{"episode_reward": 333.6504272422127, "episode": 46.0, "batch_reward": 0.16982291339337827, "critic_loss": 0.38496869476139545, "actor_loss": -20.9600622215271, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.48613667488098, "step": 46000}
{"episode_reward": 106.57726072670184, "episode": 47.0, "batch_reward": 0.17025188087671994, "critic_loss": 0.38597523970901965, "actor_loss": -21.612335563659666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.474339246749878, "step": 47000}
{"episode_reward": 377.56815436200316, "episode": 48.0, "batch_reward": 0.17509898741543292, "critic_loss": 0.4025194375663996, "actor_loss": -21.79238907814026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.455874919891357, "step": 48000}
{"episode_reward": 320.20321846867324, "episode": 49.0, "batch_reward": 0.17660106472671033, "critic_loss": 0.3827673745602369, "actor_loss": -22.07019702911377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.487415313720703, "step": 49000}
{"episode_reward": 140.5048251095785, "episode": 50.0, "batch_reward": 0.1761216476559639, "critic_loss": 0.3795096156895161, "actor_loss": -22.000697427749635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.479621648788452, "step": 50000}
{"episode_reward": 340.0709891395529, "episode": 51.0, "batch_reward": 0.17878301633894444, "critic_loss": 0.3909377481639385, "actor_loss": -22.436510862350463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.204379081726074, "step": 51000}
{"episode_reward": 174.46110893651607, "episode": 52.0, "batch_reward": 0.18038416393101214, "critic_loss": 0.39831760761141777, "actor_loss": -22.49957515144348, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.518609046936035, "step": 52000}
{"episode_reward": 397.8491676276879, "episode": 53.0, "batch_reward": 0.18299294842779637, "critic_loss": 0.38170505008101463, "actor_loss": -23.14205476760864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.462427377700806, "step": 53000}
{"episode_reward": 125.12649511834235, "episode": 54.0, "batch_reward": 0.18236268626153468, "critic_loss": 0.3771136692613363, "actor_loss": -22.939007217407227, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.50478458404541, "step": 54000}
{"episode_reward": 198.67505151608242, "episode": 55.0, "batch_reward": 0.18399586808681487, "critic_loss": 0.38048608531057837, "actor_loss": -23.189431674957277, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.51937699317932, "step": 55000}
{"episode_reward": 428.3081086354923, "episode": 56.0, "batch_reward": 0.18734108594059945, "critic_loss": 0.399504870057106, "actor_loss": -23.548013736724855, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.51223611831665, "step": 56000}
{"episode_reward": 227.1395135901943, "episode": 57.0, "batch_reward": 0.18887948773801327, "critic_loss": 0.39826019783318045, "actor_loss": -23.656115222930907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.440486669540405, "step": 57000}
{"episode_reward": 405.46923940586333, "episode": 58.0, "batch_reward": 0.1928004059046507, "critic_loss": 0.36828507494926455, "actor_loss": -24.223173519134523, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.464343786239624, "step": 58000}
{"episode_reward": 464.6478207813888, "episode": 59.0, "batch_reward": 0.19753707142174243, "critic_loss": 0.35291122886538506, "actor_loss": -24.528012325286866, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.47548198699951, "step": 59000}
{"episode_reward": 448.0169221644163, "episode": 60.0, "batch_reward": 0.19977124772965907, "critic_loss": 0.3369114502370357, "actor_loss": -24.46077709197998, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.48981022834778, "step": 60000}
{"episode_reward": 87.6318367468926, "episode": 61.0, "batch_reward": 0.19941649907827377, "critic_loss": 0.3308342187851667, "actor_loss": -24.68426293563843, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.91348195075989, "step": 61000}
{"episode_reward": 406.4928876628035, "episode": 62.0, "batch_reward": 0.20182027399539948, "critic_loss": 0.3386710286438465, "actor_loss": -24.414015926361085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.47994112968445, "step": 62000}
{"episode_reward": 237.31677086056715, "episode": 63.0, "batch_reward": 0.20467881850898265, "critic_loss": 0.3166020123362541, "actor_loss": -24.800458038330078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.49179244041443, "step": 63000}
{"episode_reward": 473.56563861902475, "episode": 64.0, "batch_reward": 0.2069558218717575, "critic_loss": 0.3186784624010324, "actor_loss": -25.435371898651123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.461442470550537, "step": 64000}
{"episode_reward": 233.42298197483865, "episode": 65.0, "batch_reward": 0.20750119671225548, "critic_loss": 0.3289945878684521, "actor_loss": -24.944081260681152, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.4888117313385, "step": 65000}
{"episode_reward": 337.1092570598171, "episode": 66.0, "batch_reward": 0.2102417234480381, "critic_loss": 0.3424965654909611, "actor_loss": -25.315464096069334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.458672285079956, "step": 66000}
{"episode_reward": 260.9675681118694, "episode": 67.0, "batch_reward": 0.2108644061535597, "critic_loss": 0.3475019592791796, "actor_loss": -25.39680141067505, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.44105315208435, "step": 67000}
{"episode_reward": 393.33519710983734, "episode": 68.0, "batch_reward": 0.21394596311450004, "critic_loss": 0.32808180056512354, "actor_loss": -26.00327187347412, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.428144693374634, "step": 68000}
{"episode_reward": 407.37177847913307, "episode": 69.0, "batch_reward": 0.21797715367376805, "critic_loss": 0.342513359606266, "actor_loss": -25.93916792297363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.46986675262451, "step": 69000}
{"episode_reward": 501.1468245277597, "episode": 70.0, "batch_reward": 0.22109510135650634, "critic_loss": 0.31912523110210894, "actor_loss": -26.206584411621094, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.471493244171143, "step": 70000}
{"episode_reward": 456.2994697730017, "episode": 71.0, "batch_reward": 0.2245218420177698, "critic_loss": 0.3327092635780573, "actor_loss": -26.203051616668702, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.882648229599, "step": 71000}
{"episode_reward": 511.97253734166736, "episode": 72.0, "batch_reward": 0.22745762941241265, "critic_loss": 0.3252227542549372, "actor_loss": -26.600741218566895, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.46466088294983, "step": 72000}
{"episode_reward": 353.5973615732755, "episode": 73.0, "batch_reward": 0.22846977776288988, "critic_loss": 0.3308714573085308, "actor_loss": -26.839303367614747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.471473932266235, "step": 73000}
{"episode_reward": 109.81863186759394, "episode": 74.0, "batch_reward": 0.2275887708365917, "critic_loss": 0.3168265787214041, "actor_loss": -26.654008869171143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.449302434921265, "step": 74000}
{"episode_reward": 238.9293949350992, "episode": 75.0, "batch_reward": 0.2279074105322361, "critic_loss": 0.33040630719065667, "actor_loss": -26.872285263061524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.49839973449707, "step": 75000}
{"episode_reward": 193.4135770706938, "episode": 76.0, "batch_reward": 0.22786143945157528, "critic_loss": 0.310113391533494, "actor_loss": -27.013101585388185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.45539617538452, "step": 76000}
{"episode_reward": 479.8226109273222, "episode": 77.0, "batch_reward": 0.23032082217931749, "critic_loss": 0.3284767915159464, "actor_loss": -26.925374004364013, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.479547023773193, "step": 77000}
{"episode_reward": 156.25064591456163, "episode": 78.0, "batch_reward": 0.23038153341412546, "critic_loss": 0.3021845143735409, "actor_loss": -26.797932693481446, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.452152490615845, "step": 78000}
{"episode_reward": 500.2610498227347, "episode": 79.0, "batch_reward": 0.23393894900381565, "critic_loss": 0.32362665510177613, "actor_loss": -27.099335037231445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.447662115097046, "step": 79000}
{"episode_reward": 271.50265647150894, "episode": 80.0, "batch_reward": 0.23410744622349738, "critic_loss": 0.32181375221908093, "actor_loss": -27.114695446014405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.457725286483765, "step": 80000}
{"episode_reward": 491.53514997009654, "episode": 81.0, "batch_reward": 0.23740819004178046, "critic_loss": 0.3401846630871296, "actor_loss": -27.441271450042724, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.969576597213745, "step": 81000}
{"episode_reward": 450.4879562756097, "episode": 82.0, "batch_reward": 0.23872046412527562, "critic_loss": 0.3463197473585606, "actor_loss": -27.737336444854737, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.49388027191162, "step": 82000}
{"episode_reward": 212.62883570081684, "episode": 83.0, "batch_reward": 0.24009439259767532, "critic_loss": 0.3490734249651432, "actor_loss": -27.333820159912108, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.515408039093018, "step": 83000}
{"episode_reward": 472.7463259889647, "episode": 84.0, "batch_reward": 0.24191959111392497, "critic_loss": 0.32566992515325544, "actor_loss": -27.701008323669434, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.49974226951599, "step": 84000}
{"episode_reward": 514.1145688134075, "episode": 85.0, "batch_reward": 0.24577540305256843, "critic_loss": 0.307335962831974, "actor_loss": -28.076156200408935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.50106430053711, "step": 85000}
{"episode_reward": 431.6665856796559, "episode": 86.0, "batch_reward": 0.24792505098879336, "critic_loss": 0.31851239144802096, "actor_loss": -28.177774673461915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.528953790664673, "step": 86000}
{"episode_reward": 434.97359924542235, "episode": 87.0, "batch_reward": 0.2503629522323608, "critic_loss": 0.34813344018161296, "actor_loss": -28.381992252349853, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.544958114624023, "step": 87000}
{"episode_reward": 422.0184635535029, "episode": 88.0, "batch_reward": 0.2516446730941534, "critic_loss": 0.34477555511891844, "actor_loss": -28.33841680908203, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.520927906036377, "step": 88000}
{"episode_reward": 502.4588712922126, "episode": 89.0, "batch_reward": 0.25337471142411233, "critic_loss": 0.34803847734630106, "actor_loss": -28.506173572540284, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.52688193321228, "step": 89000}
{"episode_reward": 139.42385339581733, "episode": 90.0, "batch_reward": 0.2537754088044167, "critic_loss": 0.34368846216797827, "actor_loss": -28.673928829193116, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.51796531677246, "step": 90000}
{"episode_reward": 479.88029780108275, "episode": 91.0, "batch_reward": 0.25579016187787057, "critic_loss": 0.34611438174545767, "actor_loss": -28.918889610290528, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.205869913101196, "step": 91000}
{"episode_reward": 473.14624041290796, "episode": 92.0, "batch_reward": 0.2587049362361431, "critic_loss": 0.3394875859320164, "actor_loss": -28.69529722595215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.531465768814087, "step": 92000}
{"episode_reward": 473.91421516752945, "episode": 93.0, "batch_reward": 0.2608185766041279, "critic_loss": 0.346113967910409, "actor_loss": -29.199851654052733, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.479498147964478, "step": 93000}
{"episode_reward": 518.1178072310189, "episode": 94.0, "batch_reward": 0.2643432848453522, "critic_loss": 0.3425879924148321, "actor_loss": -29.287260875701904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.514574766159058, "step": 94000}
{"episode_reward": 527.8994180649187, "episode": 95.0, "batch_reward": 0.2662956606000662, "critic_loss": 0.34640132980793714, "actor_loss": -29.99401720046997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.491793870925903, "step": 95000}
{"episode_reward": 555.0549464420014, "episode": 96.0, "batch_reward": 0.27002017788589, "critic_loss": 0.334620906278491, "actor_loss": -29.837520347595216, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.501994371414185, "step": 96000}
{"episode_reward": 486.6299711342765, "episode": 97.0, "batch_reward": 0.271380491822958, "critic_loss": 0.3686717457473278, "actor_loss": -30.51167235946655, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.551764965057373, "step": 97000}
{"episode_reward": 385.1997645171665, "episode": 98.0, "batch_reward": 0.2736588731557131, "critic_loss": 0.33890456934273244, "actor_loss": -30.731636695861816, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.53933835029602, "step": 98000}
{"episode_reward": 484.2449486953035, "episode": 99.0, "batch_reward": 0.2743547783643007, "critic_loss": 0.3509604121595621, "actor_loss": -30.541563274383545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.50041699409485, "step": 99000}
{"episode_reward": 448.06880536919726, "episode": 100.0, "batch_reward": 0.27625956444442273, "critic_loss": 0.33707337045669555, "actor_loss": -30.638633377075195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.511756420135498, "step": 100000}
{"episode_reward": 481.30885794648793, "episode": 101.0, "batch_reward": 0.279135891571641, "critic_loss": 0.33066161002218725, "actor_loss": -30.878853900909423, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.840776681900024, "step": 101000}
{"episode_reward": 488.17034325380484, "episode": 102.0, "batch_reward": 0.28086115868389605, "critic_loss": 0.33856344540417194, "actor_loss": -31.1718085975647, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.47614812850952, "step": 102000}
{"episode_reward": 462.0032842566993, "episode": 103.0, "batch_reward": 0.28308808110654354, "critic_loss": 0.33135649970173836, "actor_loss": -31.239074142456055, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.461820125579834, "step": 103000}
{"episode_reward": 523.3883364318922, "episode": 104.0, "batch_reward": 0.28534030328691007, "critic_loss": 0.3240551852732897, "actor_loss": -31.703016593933107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.474050283432007, "step": 104000}
{"episode_reward": 457.64986978272077, "episode": 105.0, "batch_reward": 0.28575005438923834, "critic_loss": 0.3379550521671772, "actor_loss": -31.50653659439087, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.508223056793213, "step": 105000}
{"episode_reward": 440.87278661054427, "episode": 106.0, "batch_reward": 0.28814416740834714, "critic_loss": 0.32526653841137887, "actor_loss": -31.778540897369385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.473745346069336, "step": 106000}
{"episode_reward": 450.87576342176885, "episode": 107.0, "batch_reward": 0.2890287220925093, "critic_loss": 0.33841911020874976, "actor_loss": -31.828306312561036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.46174907684326, "step": 107000}
{"episode_reward": 239.43963579581978, "episode": 108.0, "batch_reward": 0.28952396799623964, "critic_loss": 0.3380446664839983, "actor_loss": -31.847904346466063, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.48950457572937, "step": 108000}
{"episode_reward": 525.0528329267398, "episode": 109.0, "batch_reward": 0.2922110880613327, "critic_loss": 0.36441979214549064, "actor_loss": -32.398465549468995, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.456753730773926, "step": 109000}
{"episode_reward": 545.0051991120471, "episode": 110.0, "batch_reward": 0.2945369439870119, "critic_loss": 0.3382006063014269, "actor_loss": -32.44638984298706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.473187685012817, "step": 110000}
{"episode_reward": 530.6819666220235, "episode": 111.0, "batch_reward": 0.2951310811340809, "critic_loss": 0.3428541186749935, "actor_loss": -32.24367387008667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.88627648353577, "step": 111000}
{"episode_reward": 511.21930843334667, "episode": 112.0, "batch_reward": 0.2976834784448147, "critic_loss": 0.36456191954016687, "actor_loss": -32.607033233642575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.42021131515503, "step": 112000}
{"episode_reward": 536.3802044349881, "episode": 113.0, "batch_reward": 0.3008280938416719, "critic_loss": 0.35977173763513565, "actor_loss": -32.60145394897461, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.472812175750732, "step": 113000}
{"episode_reward": 565.7256941167221, "episode": 114.0, "batch_reward": 0.30184775906801226, "critic_loss": 0.35251617190241813, "actor_loss": -33.16765075302124, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.461931228637695, "step": 114000}
{"episode_reward": 554.659332303901, "episode": 115.0, "batch_reward": 0.30449933889508246, "critic_loss": 0.3483369487524033, "actor_loss": -33.69723932647705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.46925926208496, "step": 115000}
{"episode_reward": 520.8930710649511, "episode": 116.0, "batch_reward": 0.30594037991762163, "critic_loss": 0.3681941948980093, "actor_loss": -33.51461254119873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.508141040802002, "step": 116000}
{"episode_reward": 539.1727012764319, "episode": 117.0, "batch_reward": 0.3085062587708235, "critic_loss": 0.32724382638931276, "actor_loss": -33.712901206970216, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.467927932739258, "step": 117000}
{"episode_reward": 577.8169282158407, "episode": 118.0, "batch_reward": 0.310401179343462, "critic_loss": 0.3376995397955179, "actor_loss": -33.68655250930786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.42587637901306, "step": 118000}
{"episode_reward": 522.812663078907, "episode": 119.0, "batch_reward": 0.31213560788333417, "critic_loss": 0.32781700512766837, "actor_loss": -33.818526630401614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.46816086769104, "step": 119000}
{"episode_reward": 508.12748700611934, "episode": 120.0, "batch_reward": 0.3136981983780861, "critic_loss": 0.3309169943332672, "actor_loss": -34.297447570800784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.477036237716675, "step": 120000}
{"episode_reward": 549.8507952548738, "episode": 121.0, "batch_reward": 0.31695877987146376, "critic_loss": 0.3325689347833395, "actor_loss": -34.46509344863892, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.92608690261841, "step": 121000}
{"episode_reward": 575.1208136006261, "episode": 122.0, "batch_reward": 0.3184083403944969, "critic_loss": 0.3408561395555735, "actor_loss": -34.871050128936766, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.469908952713013, "step": 122000}
{"episode_reward": 520.421817190784, "episode": 123.0, "batch_reward": 0.3196817656308413, "critic_loss": 0.3436503514945507, "actor_loss": -35.259856414794925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.447307348251343, "step": 123000}
{"episode_reward": 529.5597116654308, "episode": 124.0, "batch_reward": 0.32101586562395096, "critic_loss": 0.35326888523995875, "actor_loss": -35.103960445404056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.611820936203003, "step": 124000}
{"episode_reward": 552.5535803008474, "episode": 125.0, "batch_reward": 0.3237810542881489, "critic_loss": 0.3595574673563242, "actor_loss": -35.17390716171265, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.78963804244995, "step": 125000}
{"episode_reward": 532.8859804794773, "episode": 126.0, "batch_reward": 0.3256639008820057, "critic_loss": 0.35701894618570806, "actor_loss": -35.32278380203247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.43620491027832, "step": 126000}
{"episode_reward": 543.0473098009127, "episode": 127.0, "batch_reward": 0.3265111712217331, "critic_loss": 0.33193325458467005, "actor_loss": -35.53891246032715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.473607778549194, "step": 127000}
{"episode_reward": 603.8495411869843, "episode": 128.0, "batch_reward": 0.32901115441322326, "critic_loss": 0.349220640078187, "actor_loss": -35.5102548828125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.472883462905884, "step": 128000}
{"episode_reward": 597.080214943101, "episode": 129.0, "batch_reward": 0.3309458398222923, "critic_loss": 0.3605812193155289, "actor_loss": -35.70439069747925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.47386932373047, "step": 129000}
{"episode_reward": 556.3692607933754, "episode": 130.0, "batch_reward": 0.3326821202635765, "critic_loss": 0.3355125550478697, "actor_loss": -36.10778563308716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.490992546081543, "step": 130000}
{"episode_reward": 237.8645483454331, "episode": 131.0, "batch_reward": 0.33189774307608605, "critic_loss": 0.3298332656174898, "actor_loss": -35.5179994392395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.910773515701294, "step": 131000}
{"episode_reward": 603.8872357202191, "episode": 132.0, "batch_reward": 0.33416127413511276, "critic_loss": 0.3321933186799288, "actor_loss": -35.9834570274353, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.490434646606445, "step": 132000}
{"episode_reward": 601.4482453042227, "episode": 133.0, "batch_reward": 0.3350538094043732, "critic_loss": 0.3355601847320795, "actor_loss": -36.226905784606934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.48939871788025, "step": 133000}
{"episode_reward": 541.1255312634245, "episode": 134.0, "batch_reward": 0.33705925023555755, "critic_loss": 0.3333058001846075, "actor_loss": -36.46966679763794, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.456868886947632, "step": 134000}
{"episode_reward": 546.8220333608137, "episode": 135.0, "batch_reward": 0.33912234112620354, "critic_loss": 0.3348873693346977, "actor_loss": -36.643096061706544, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.480108737945557, "step": 135000}
{"episode_reward": 606.6335452194568, "episode": 136.0, "batch_reward": 0.3402553848922253, "critic_loss": 0.344729879334569, "actor_loss": -36.72439741134644, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.471553087234497, "step": 136000}
{"episode_reward": 290.50183778321207, "episode": 137.0, "batch_reward": 0.34119426542520526, "critic_loss": 0.3315346265733242, "actor_loss": -36.96637526321411, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.44377565383911, "step": 137000}
{"episode_reward": 494.15681679860944, "episode": 138.0, "batch_reward": 0.3425196077823639, "critic_loss": 0.34011630329489706, "actor_loss": -36.67339684295654, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.504587650299072, "step": 138000}
{"episode_reward": 615.9177500193925, "episode": 139.0, "batch_reward": 0.3442848401069641, "critic_loss": 0.3447926836758852, "actor_loss": -36.81507725524902, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.466924905776978, "step": 139000}
{"episode_reward": 520.2962693767707, "episode": 140.0, "batch_reward": 0.345053534090519, "critic_loss": 0.33516388922929763, "actor_loss": -36.87508556365967, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.456329107284546, "step": 140000}
{"episode_reward": 618.7669810322653, "episode": 141.0, "batch_reward": 0.3466829052269459, "critic_loss": 0.35648384411633016, "actor_loss": -37.360741855621335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.94772553443909, "step": 141000}
{"episode_reward": 352.5994388623687, "episode": 142.0, "batch_reward": 0.3456151303946972, "critic_loss": 0.35854532343149187, "actor_loss": -37.26396432113648, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.485692977905273, "step": 142000}
{"episode_reward": 99.58750996412063, "episode": 143.0, "batch_reward": 0.3458340200483799, "critic_loss": 0.3388143314123154, "actor_loss": -37.39657696914673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.479770183563232, "step": 143000}
{"episode_reward": 605.8713173983715, "episode": 144.0, "batch_reward": 0.348188485711813, "critic_loss": 0.35379931911826135, "actor_loss": -37.368951236724854, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.483335971832275, "step": 144000}
{"episode_reward": 636.4900290393526, "episode": 145.0, "batch_reward": 0.3501503888964653, "critic_loss": 0.3599232260882854, "actor_loss": -37.81713898468018, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.448076248168945, "step": 145000}
{"episode_reward": 602.3714144919416, "episode": 146.0, "batch_reward": 0.350624538064003, "critic_loss": 0.36905118383467195, "actor_loss": -37.33268330001831, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.48358964920044, "step": 146000}
{"episode_reward": 618.9524370555799, "episode": 147.0, "batch_reward": 0.3526441399157047, "critic_loss": 0.3640061673223972, "actor_loss": -37.83472174072266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.478675603866577, "step": 147000}
{"episode_reward": 581.4370901304403, "episode": 148.0, "batch_reward": 0.3544865898489952, "critic_loss": 0.34465359039604665, "actor_loss": -37.915179248809814, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.48943281173706, "step": 148000}
{"episode_reward": 629.1401678769901, "episode": 149.0, "batch_reward": 0.35655134680867195, "critic_loss": 0.35993939386308194, "actor_loss": -38.10339334487915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.519939661026, "step": 149000}
{"episode_reward": 650.0356284674803, "episode": 150.0, "batch_reward": 0.35826118057966233, "critic_loss": 0.3612403001487255, "actor_loss": -38.29767040634155, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
