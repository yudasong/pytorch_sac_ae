{"episode_reward": 0.0, "episode": 1.0, "duration": 13.860253810882568, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.2204053401947021, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.26107382988007555, "critic_loss": 0.06540989011734794, "actor_loss": -26.72040024361297, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 74.12607216835022, "step": 3000}
{"episode_reward": 36.287260705220234, "episode": 4.0, "batch_reward": 0.17118375673890113, "critic_loss": 0.03910745431855321, "actor_loss": -21.678356818437575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.451783895492554, "step": 4000}
{"episode_reward": 17.08043717103889, "episode": 5.0, "batch_reward": 0.14120312446728348, "critic_loss": 0.039841882770881056, "actor_loss": -21.149135518074036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.175986528396606, "step": 5000}
{"episode_reward": 38.416231410207914, "episode": 6.0, "batch_reward": 0.11788837454840541, "critic_loss": 0.034485315058380366, "actor_loss": -19.923901965141297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22577977180481, "step": 6000}
{"episode_reward": 2.755896621069704, "episode": 7.0, "batch_reward": 0.09982048952579499, "critic_loss": 0.030557631225325167, "actor_loss": -19.35765008473396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.890685319900513, "step": 7000}
{"episode_reward": 3.6544465261668435, "episode": 8.0, "batch_reward": 0.08766447983682156, "critic_loss": 0.03244976822193712, "actor_loss": -18.21397371506691, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.899831771850586, "step": 8000}
{"episode_reward": 12.237250620434683, "episode": 9.0, "batch_reward": 0.07917439991608262, "critic_loss": 0.03113589098956436, "actor_loss": -19.319088319540025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.204832553863525, "step": 9000}
{"episode_reward": 18.177718117784437, "episode": 10.0, "batch_reward": 0.07252553535625339, "critic_loss": 0.034266328431665896, "actor_loss": -18.61769269657135, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.423259496688843, "step": 10000}
{"episode_reward": 24.98594080355596, "episode": 11.0, "batch_reward": 0.06985691770911216, "critic_loss": 0.041834583536721766, "actor_loss": -19.191152835845948, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.41466403007507, "step": 11000}
{"episode_reward": 69.76574421308766, "episode": 12.0, "batch_reward": 0.0743556242287159, "critic_loss": 0.07779027717001737, "actor_loss": -17.51474943244457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.13373589515686, "step": 12000}
{"episode_reward": 114.07577001081626, "episode": 13.0, "batch_reward": 0.07515498261153698, "critic_loss": 0.07754396230541169, "actor_loss": -18.264703519403934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.06420373916626, "step": 13000}
{"episode_reward": 114.82207452553598, "episode": 14.0, "batch_reward": 0.08149475931376218, "critic_loss": 0.11598056295514107, "actor_loss": -17.621682028576732, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.310325384140015, "step": 14000}
{"episode_reward": 166.14813462955368, "episode": 15.0, "batch_reward": 0.08244561365246773, "critic_loss": 0.12418381402269006, "actor_loss": -17.92960261575878, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.922154188156128, "step": 15000}
{"episode_reward": 25.408437417406844, "episode": 16.0, "batch_reward": 0.08170268956571818, "critic_loss": 0.12941463071480394, "actor_loss": -16.671789954930542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.42066240310669, "step": 16000}
{"episode_reward": 136.28820171520795, "episode": 17.0, "batch_reward": 0.08297166491299868, "critic_loss": 0.1866913871988654, "actor_loss": -16.73103081975877, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.00951075553894, "step": 17000}
{"episode_reward": 52.98081845052265, "episode": 18.0, "batch_reward": 0.08340158330276609, "critic_loss": 0.20966298941522837, "actor_loss": -15.710932960867881, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.865161657333374, "step": 18000}
{"episode_reward": 90.30799459687964, "episode": 19.0, "batch_reward": 0.08036718047782779, "critic_loss": 0.2107646575048566, "actor_loss": -16.621818421244622, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.369683027267456, "step": 19000}
{"episode_reward": 20.57028736545484, "episode": 20.0, "batch_reward": 0.07886970937624574, "critic_loss": 0.2128888843357563, "actor_loss": -15.797521345376968, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.37034511566162, "step": 20000}
{"episode_reward": 54.36717968756049, "episode": 21.0, "batch_reward": 0.08054942391440273, "critic_loss": 0.20393749056011437, "actor_loss": -16.363918226003648, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.179282665252686, "step": 21000}
{"episode_reward": 167.74387040938106, "episode": 22.0, "batch_reward": 0.0829387644790113, "critic_loss": 0.1879512107297778, "actor_loss": -15.656064811229706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.134286880493164, "step": 22000}
{"episode_reward": 62.773229069622786, "episode": 23.0, "batch_reward": 0.0820973038598895, "critic_loss": 0.19093842996656896, "actor_loss": -16.511035391807557, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.24836754798889, "step": 23000}
{"episode_reward": 75.91673486086782, "episode": 24.0, "batch_reward": 0.08376664455235004, "critic_loss": 0.19132041601091623, "actor_loss": -16.97642695236206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.337602615356445, "step": 24000}
{"episode_reward": 206.33531951513126, "episode": 25.0, "batch_reward": 0.08788105219602585, "critic_loss": 0.18663671472668647, "actor_loss": -16.083477412223814, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.43026566505432, "step": 25000}
{"episode_reward": 181.41480285915736, "episode": 26.0, "batch_reward": 0.09108763199672103, "critic_loss": 0.16772550524771213, "actor_loss": -17.245211171150206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.60073161125183, "step": 26000}
{"episode_reward": 116.74848279088134, "episode": 27.0, "batch_reward": 0.09340759221836925, "critic_loss": 0.15776629324257374, "actor_loss": -17.089976725578307, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.520174503326416, "step": 27000}
{"episode_reward": 254.22344301972348, "episode": 28.0, "batch_reward": 0.09786481366306543, "critic_loss": 0.1908105111271143, "actor_loss": -16.997199648857116, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.60253381729126, "step": 28000}
{"episode_reward": 103.53132782274787, "episode": 29.0, "batch_reward": 0.09793112219125033, "critic_loss": 0.18329267324507237, "actor_loss": -16.995413829803468, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.390948057174683, "step": 29000}
{"episode_reward": 126.03649170951493, "episode": 30.0, "batch_reward": 0.0988583740144968, "critic_loss": 0.20424087430536747, "actor_loss": -17.496360401153563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.33849287033081, "step": 30000}
{"episode_reward": 92.37165585374875, "episode": 31.0, "batch_reward": 0.0992253018654883, "critic_loss": 0.1979392328634858, "actor_loss": -16.445681247711182, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.450624227523804, "step": 31000}
{"episode_reward": 151.1437116728131, "episode": 32.0, "batch_reward": 0.101100899271667, "critic_loss": 0.22544111002236605, "actor_loss": -17.202970076560973, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.24637794494629, "step": 32000}
{"episode_reward": 182.1916015707728, "episode": 33.0, "batch_reward": 0.10418723428249359, "critic_loss": 0.2361239173710346, "actor_loss": -16.91963591861725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.361329555511475, "step": 33000}
{"episode_reward": 322.0004856741991, "episode": 34.0, "batch_reward": 0.11140274174511433, "critic_loss": 0.24886376971006394, "actor_loss": -17.375066144943236, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.533194541931152, "step": 34000}
{"episode_reward": 291.5505840636411, "episode": 35.0, "batch_reward": 0.11454778760671616, "critic_loss": 0.23896247116476296, "actor_loss": -18.69442521572113, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.225541591644287, "step": 35000}
{"episode_reward": 93.6923940665368, "episode": 36.0, "batch_reward": 0.11604373735934496, "critic_loss": 0.25258594334125517, "actor_loss": -17.74935625267029, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.414090156555176, "step": 36000}
{"episode_reward": 208.2238102015603, "episode": 37.0, "batch_reward": 0.1156003830730915, "critic_loss": 0.2625694517046213, "actor_loss": -18.01245887565613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.273468255996704, "step": 37000}
{"episode_reward": 39.34519086833871, "episode": 38.0, "batch_reward": 0.1166725623384118, "critic_loss": 0.26950571160763503, "actor_loss": -18.779634801864624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.120534658432007, "step": 38000}
{"episode_reward": 217.9744745519986, "episode": 39.0, "batch_reward": 0.11903818187862635, "critic_loss": 0.2930944290682673, "actor_loss": -18.284998529434205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.524193048477173, "step": 39000}
{"episode_reward": 183.343431568429, "episode": 40.0, "batch_reward": 0.12166572242230177, "critic_loss": 0.2628286699578166, "actor_loss": -18.085437492370605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.400798797607422, "step": 40000}
{"episode_reward": 220.68440251818367, "episode": 41.0, "batch_reward": 0.12389426351338625, "critic_loss": 0.2510199780166149, "actor_loss": -19.035358964920043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.87061405181885, "step": 41000}
{"episode_reward": 390.14290920915386, "episode": 42.0, "batch_reward": 0.1303687249198556, "critic_loss": 0.29092663602530955, "actor_loss": -19.41989587402344, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.4854576587677, "step": 42000}
{"episode_reward": 331.86108947127786, "episode": 43.0, "batch_reward": 0.1352626705020666, "critic_loss": 0.30826345124840737, "actor_loss": -19.634576051712035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.852313995361328, "step": 43000}
{"episode_reward": 359.8096993746722, "episode": 44.0, "batch_reward": 0.14057639843970537, "critic_loss": 0.2771297724917531, "actor_loss": -21.0117327003479, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32761287689209, "step": 44000}
{"episode_reward": 288.13611473265377, "episode": 45.0, "batch_reward": 0.14221203900128604, "critic_loss": 0.28463261798024175, "actor_loss": -21.119533954620362, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.223745822906494, "step": 45000}
{"episode_reward": 124.05515713784798, "episode": 46.0, "batch_reward": 0.14136488822847604, "critic_loss": 0.2915194845572114, "actor_loss": -20.823887928009032, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.068941116333008, "step": 46000}
{"episode_reward": 95.62205563954106, "episode": 47.0, "batch_reward": 0.14080550165474415, "critic_loss": 0.3264369421750307, "actor_loss": -20.740366958618164, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.29827880859375, "step": 47000}
{"episode_reward": 281.30736590731584, "episode": 48.0, "batch_reward": 0.14502685497701168, "critic_loss": 0.3513538157790899, "actor_loss": -21.21129149246216, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.163704872131348, "step": 48000}
{"episode_reward": 387.0906488191743, "episode": 49.0, "batch_reward": 0.14970604762434958, "critic_loss": 0.4006367966234684, "actor_loss": -21.367940927505494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.253082990646362, "step": 49000}
{"episode_reward": 315.1664433753435, "episode": 50.0, "batch_reward": 0.15280204890668392, "critic_loss": 0.41582431860268115, "actor_loss": -21.745978937149047, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.08940315246582, "step": 50000}
{"episode_reward": 360.5141458831701, "episode": 51.0, "batch_reward": 0.1553182727098465, "critic_loss": 0.4277498924732208, "actor_loss": -21.876760694503783, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.47963309288025, "step": 51000}
{"episode_reward": 154.3317389091211, "episode": 52.0, "batch_reward": 0.15688276203721763, "critic_loss": 0.40476920863986016, "actor_loss": -22.29960033035278, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.471797227859497, "step": 52000}
{"episode_reward": 141.48738896421085, "episode": 53.0, "batch_reward": 0.15716531624644994, "critic_loss": 0.3784636865258217, "actor_loss": -22.27442078781128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30403995513916, "step": 53000}
{"episode_reward": 360.6058003038273, "episode": 54.0, "batch_reward": 0.15912239579111337, "critic_loss": 0.3990303022712469, "actor_loss": -22.432969167709352, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22683072090149, "step": 54000}
{"episode_reward": 114.39879325638995, "episode": 55.0, "batch_reward": 0.15951166059821845, "critic_loss": 0.39639235877990725, "actor_loss": -22.436813709259035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.208900690078735, "step": 55000}
{"episode_reward": 347.289930282488, "episode": 56.0, "batch_reward": 0.1634842062667012, "critic_loss": 0.43849895465373995, "actor_loss": -22.599474716186524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.643189191818237, "step": 56000}
{"episode_reward": 404.2642709967721, "episode": 57.0, "batch_reward": 0.16861695310473443, "critic_loss": 0.42800342887639997, "actor_loss": -23.323039503097533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.590256452560425, "step": 57000}
{"episode_reward": 445.30092487612296, "episode": 58.0, "batch_reward": 0.1718996580913663, "critic_loss": 0.424322918638587, "actor_loss": -23.45706406402588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.40545964241028, "step": 58000}
{"episode_reward": 217.8938631324705, "episode": 59.0, "batch_reward": 0.172979978851974, "critic_loss": 0.4301899061501026, "actor_loss": -23.53537518310547, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.13869333267212, "step": 59000}
{"episode_reward": 146.31287662881599, "episode": 60.0, "batch_reward": 0.17335405279695987, "critic_loss": 0.3816429593861103, "actor_loss": -23.869198169708252, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.427464962005615, "step": 60000}
{"episode_reward": 407.350079429653, "episode": 61.0, "batch_reward": 0.17505677139014006, "critic_loss": 0.39928753454238175, "actor_loss": -24.355515411376953, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.51231050491333, "step": 61000}
{"episode_reward": 137.9073086203044, "episode": 62.0, "batch_reward": 0.17648116520047188, "critic_loss": 0.41033203205466273, "actor_loss": -24.451332397460938, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.373121976852417, "step": 62000}
{"episode_reward": 403.4257402162563, "episode": 63.0, "batch_reward": 0.17942462374269963, "critic_loss": 0.38278116849064825, "actor_loss": -24.534754707336425, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.538609504699707, "step": 63000}
{"episode_reward": 166.112137206382, "episode": 64.0, "batch_reward": 0.18004197369515895, "critic_loss": 0.41372875064611436, "actor_loss": -24.089547485351563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.47091817855835, "step": 64000}
{"episode_reward": 307.16683581838134, "episode": 65.0, "batch_reward": 0.18188982950150967, "critic_loss": 0.41713618202507496, "actor_loss": -24.349053115844725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.520309686660767, "step": 65000}
{"episode_reward": 393.98963712223394, "episode": 66.0, "batch_reward": 0.18505817642807962, "critic_loss": 0.4375186152607203, "actor_loss": -24.598664394378662, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.63272476196289, "step": 66000}
{"episode_reward": 473.68434643191495, "episode": 67.0, "batch_reward": 0.1890413900613785, "critic_loss": 0.4677757134139538, "actor_loss": -25.44681003189087, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.466147661209106, "step": 67000}
{"episode_reward": 302.48338250512353, "episode": 68.0, "batch_reward": 0.1906361376941204, "critic_loss": 0.47256059862673283, "actor_loss": -25.22236450958252, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.948644638061523, "step": 68000}
{"episode_reward": 458.97635636033766, "episode": 69.0, "batch_reward": 0.19578888283669948, "critic_loss": 0.4435284428149462, "actor_loss": -25.83466286087036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.700795650482178, "step": 69000}
{"episode_reward": 311.0944646075186, "episode": 70.0, "batch_reward": 0.1960306981652975, "critic_loss": 0.4574073930382729, "actor_loss": -26.059398612976075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.283482789993286, "step": 70000}
{"episode_reward": 264.9472168628145, "episode": 71.0, "batch_reward": 0.19782273259758948, "critic_loss": 0.4517430338412523, "actor_loss": -26.085183338165283, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.698493003845215, "step": 71000}
{"episode_reward": 394.56020830771996, "episode": 72.0, "batch_reward": 0.20074897371232509, "critic_loss": 0.45528947141766546, "actor_loss": -26.288809371948243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.464375019073486, "step": 72000}
{"episode_reward": 466.4126875379003, "episode": 73.0, "batch_reward": 0.20406882508099078, "critic_loss": 0.45907292169332503, "actor_loss": -26.578087657928467, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.502099990844727, "step": 73000}
{"episode_reward": 441.81067388871224, "episode": 74.0, "batch_reward": 0.20702472826838494, "critic_loss": 0.4600808645635843, "actor_loss": -26.947991260528564, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.887598514556885, "step": 74000}
{"episode_reward": 463.26456977725877, "episode": 75.0, "batch_reward": 0.2110673897713423, "critic_loss": 0.47858494193851947, "actor_loss": -26.895501342773436, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.341339349746704, "step": 75000}
{"episode_reward": 375.82644442028385, "episode": 76.0, "batch_reward": 0.21337723848223686, "critic_loss": 0.5238029810488224, "actor_loss": -27.429644340515136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.57967495918274, "step": 76000}
{"episode_reward": 505.2202809645787, "episode": 77.0, "batch_reward": 0.21661641350388527, "critic_loss": 0.4928658763170242, "actor_loss": -27.71084745788574, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.353189945220947, "step": 77000}
{"episode_reward": 356.4671231347001, "episode": 78.0, "batch_reward": 0.21901742835342883, "critic_loss": 0.5029426349848509, "actor_loss": -27.976447296142577, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.085256099700928, "step": 78000}
{"episode_reward": 479.75108880316355, "episode": 79.0, "batch_reward": 0.22050919823348522, "critic_loss": 0.4569333270043135, "actor_loss": -27.81685319137573, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.444077730178833, "step": 79000}
{"episode_reward": 52.730719623278816, "episode": 80.0, "batch_reward": 0.219666238874197, "critic_loss": 0.43200735095143317, "actor_loss": -27.985865543365477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.272067070007324, "step": 80000}
{"episode_reward": 337.58287069356555, "episode": 81.0, "batch_reward": 0.22065697941184043, "critic_loss": 0.43169748413562775, "actor_loss": -28.089349613189697, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.479361057281494, "step": 81000}
{"episode_reward": 187.99239449202472, "episode": 82.0, "batch_reward": 0.2214852377772331, "critic_loss": 0.40277632781863215, "actor_loss": -28.056599822998045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.410725116729736, "step": 82000}
{"episode_reward": 520.9944296310157, "episode": 83.0, "batch_reward": 0.22421318592131137, "critic_loss": 0.3845982603430748, "actor_loss": -28.377361156463625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.587696075439453, "step": 83000}
{"episode_reward": 167.78197932124047, "episode": 84.0, "batch_reward": 0.22232409600913525, "critic_loss": 0.378509975194931, "actor_loss": -28.005886367797853, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.250446796417236, "step": 84000}
{"episode_reward": 234.167893383641, "episode": 85.0, "batch_reward": 0.22340805323421956, "critic_loss": 0.34672708927094936, "actor_loss": -27.960099006652833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.440619230270386, "step": 85000}
{"episode_reward": 336.82545713685494, "episode": 86.0, "batch_reward": 0.22445232182741165, "critic_loss": 0.35136691822111604, "actor_loss": -28.185501724243164, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22741675376892, "step": 86000}
{"episode_reward": 307.7554977966157, "episode": 87.0, "batch_reward": 0.22703421126306056, "critic_loss": 0.344445873260498, "actor_loss": -28.35903326034546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.218451261520386, "step": 87000}
{"episode_reward": 566.3101117850734, "episode": 88.0, "batch_reward": 0.23035417725145818, "critic_loss": 0.3352063292562962, "actor_loss": -28.618077934265138, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.476195812225342, "step": 88000}
{"episode_reward": 442.99592936869055, "episode": 89.0, "batch_reward": 0.2327316064685583, "critic_loss": 0.32847908283770083, "actor_loss": -28.661840728759767, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.317707061767578, "step": 89000}
{"episode_reward": 482.9043649661061, "episode": 90.0, "batch_reward": 0.2350215847492218, "critic_loss": 0.3577476134002209, "actor_loss": -28.931645156860352, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.604928731918335, "step": 90000}
{"episode_reward": 360.79411792979045, "episode": 91.0, "batch_reward": 0.23587117762863635, "critic_loss": 0.3769849239140749, "actor_loss": -28.86180813598633, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.72423076629639, "step": 91000}
{"episode_reward": 240.40757458985937, "episode": 92.0, "batch_reward": 0.23676390706002712, "critic_loss": 0.3550381112098694, "actor_loss": -29.407359981536864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.34465742111206, "step": 92000}
{"episode_reward": 448.0588790650732, "episode": 93.0, "batch_reward": 0.23917283767461778, "critic_loss": 0.35303671783208845, "actor_loss": -29.22356813812256, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27418541908264, "step": 93000}
{"episode_reward": 456.6332416396526, "episode": 94.0, "batch_reward": 0.24191619469225406, "critic_loss": 0.3486776163876057, "actor_loss": -29.696472923278808, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.629326581954956, "step": 94000}
{"episode_reward": 461.0894893456566, "episode": 95.0, "batch_reward": 0.24357674965262413, "critic_loss": 0.36432522571086884, "actor_loss": -29.562921112060547, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.484699487686157, "step": 95000}
{"episode_reward": 553.0355339501596, "episode": 96.0, "batch_reward": 0.24694308573007584, "critic_loss": 0.3410224604010582, "actor_loss": -29.966626163482665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.276864767074585, "step": 96000}
{"episode_reward": 489.3006559155638, "episode": 97.0, "batch_reward": 0.24860152500867844, "critic_loss": 0.34310757553577426, "actor_loss": -29.870362133026124, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.11574363708496, "step": 97000}
{"episode_reward": 191.85744649785636, "episode": 98.0, "batch_reward": 0.2501594476401806, "critic_loss": 0.35701774002611636, "actor_loss": -29.76496630477905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.50420832633972, "step": 98000}
{"episode_reward": 406.7606465283195, "episode": 99.0, "batch_reward": 0.25025857812166213, "critic_loss": 0.34280463634431363, "actor_loss": -30.05804578781128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.56772255897522, "step": 99000}
{"episode_reward": 575.449852747981, "episode": 100.0, "batch_reward": 0.2536951147168875, "critic_loss": 0.3264910351336002, "actor_loss": -30.11476252746582, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.9647159576416, "step": 100000}
{"episode_reward": 524.131131958147, "episode": 101.0, "batch_reward": 0.25675285036861895, "critic_loss": 0.3414961627423763, "actor_loss": -30.618496757507323, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.69524645805359, "step": 101000}
{"episode_reward": 503.6208330774085, "episode": 102.0, "batch_reward": 0.25915153728425505, "critic_loss": 0.3281097854524851, "actor_loss": -30.549761974334718, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34363865852356, "step": 102000}
{"episode_reward": 554.3449427758277, "episode": 103.0, "batch_reward": 0.26124683244526387, "critic_loss": 0.32458973518013956, "actor_loss": -30.882062564849853, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.726101636886597, "step": 103000}
{"episode_reward": 524.6467574128659, "episode": 104.0, "batch_reward": 0.26488433992862703, "critic_loss": 0.32993343807756903, "actor_loss": -30.738390537261964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.466665029525757, "step": 104000}
{"episode_reward": 452.75679992437915, "episode": 105.0, "batch_reward": 0.2656779764443636, "critic_loss": 0.33759683117270467, "actor_loss": -31.33508324432373, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.50937294960022, "step": 105000}
{"episode_reward": 486.86546925572225, "episode": 106.0, "batch_reward": 0.2685103832930327, "critic_loss": 0.35439066599309443, "actor_loss": -31.30676789855957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.450783491134644, "step": 106000}
{"episode_reward": 524.1414744174647, "episode": 107.0, "batch_reward": 0.2703233874738216, "critic_loss": 0.34145001332461833, "actor_loss": -31.435140899658204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.269644021987915, "step": 107000}
{"episode_reward": 266.3007458654589, "episode": 108.0, "batch_reward": 0.27105257849395276, "critic_loss": 0.3296037852913141, "actor_loss": -31.426328548431396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.596455812454224, "step": 108000}
{"episode_reward": 518.1551856137999, "episode": 109.0, "batch_reward": 0.2739026880711317, "critic_loss": 0.35981276819109914, "actor_loss": -31.661162689208986, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.571186780929565, "step": 109000}
{"episode_reward": 535.0794481421475, "episode": 110.0, "batch_reward": 0.2757038218975067, "critic_loss": 0.3500705653578043, "actor_loss": -31.63098108673096, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.188172340393066, "step": 110000}
{"episode_reward": 552.405267962055, "episode": 111.0, "batch_reward": 0.2782333570420742, "critic_loss": 0.34009383618831635, "actor_loss": -32.13421360015869, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.67276573181152, "step": 111000}
{"episode_reward": 580.2713706522585, "episode": 112.0, "batch_reward": 0.27971476353704927, "critic_loss": 0.351029050424695, "actor_loss": -31.997914085388185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.01079273223877, "step": 112000}
{"episode_reward": 555.9956766944, "episode": 113.0, "batch_reward": 0.28415453718602657, "critic_loss": 0.3524101437330246, "actor_loss": -32.7497735748291, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.113595724105835, "step": 113000}
{"episode_reward": 597.5931929629186, "episode": 114.0, "batch_reward": 0.2859119623154402, "critic_loss": 0.3549436563849449, "actor_loss": -32.77863935089111, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.464375972747803, "step": 114000}
{"episode_reward": 560.5261627608767, "episode": 115.0, "batch_reward": 0.2875265626013279, "critic_loss": 0.3442717787325382, "actor_loss": -32.53786631774902, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.415087938308716, "step": 115000}
{"episode_reward": 388.296418497434, "episode": 116.0, "batch_reward": 0.28922096818685533, "critic_loss": 0.35099398970603946, "actor_loss": -32.84749963378906, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.680628299713135, "step": 116000}
{"episode_reward": 607.4207173084794, "episode": 117.0, "batch_reward": 0.29214953592419624, "critic_loss": 0.3498504948616028, "actor_loss": -33.15179914093017, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.385011911392212, "step": 117000}
{"episode_reward": 574.2997260953822, "episode": 118.0, "batch_reward": 0.2950673685669899, "critic_loss": 0.3519537521898746, "actor_loss": -33.312042030334474, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.095844745635986, "step": 118000}
{"episode_reward": 589.9348234232433, "episode": 119.0, "batch_reward": 0.2967122715264559, "critic_loss": 0.35698106133937835, "actor_loss": -33.404093208312986, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.494491815567017, "step": 119000}
{"episode_reward": 606.435820595476, "episode": 120.0, "batch_reward": 0.29986007076501847, "critic_loss": 0.3581886662244797, "actor_loss": -33.711469982147214, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.279536724090576, "step": 120000}
{"episode_reward": 551.5458938964392, "episode": 121.0, "batch_reward": 0.3025513266324997, "critic_loss": 0.35415789775550366, "actor_loss": -33.899743438720705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.32979083061218, "step": 121000}
{"episode_reward": 584.7342303924207, "episode": 122.0, "batch_reward": 0.3049050527960062, "critic_loss": 0.3342798138260841, "actor_loss": -33.835647659301756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.13714599609375, "step": 122000}
{"episode_reward": 580.2668055227117, "episode": 123.0, "batch_reward": 0.30562991815805435, "critic_loss": 0.33969160859286784, "actor_loss": -33.947313076019284, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.755822896957397, "step": 123000}
{"episode_reward": 590.3752285662918, "episode": 124.0, "batch_reward": 0.30907409398257735, "critic_loss": 0.34731487347185613, "actor_loss": -34.45455292129517, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.8093843460083, "step": 124000}
{"episode_reward": 624.0023841934249, "episode": 125.0, "batch_reward": 0.3118831206858158, "critic_loss": 0.3358199626803398, "actor_loss": -34.60016451644898, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.357972145080566, "step": 125000}
{"episode_reward": 445.28402654679223, "episode": 126.0, "batch_reward": 0.3116846330165863, "critic_loss": 0.37255238683521746, "actor_loss": -34.52071912765503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.282209396362305, "step": 126000}
{"episode_reward": 576.9844634968917, "episode": 127.0, "batch_reward": 0.31193197026848796, "critic_loss": 0.35495441968739033, "actor_loss": -34.8883051071167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.193838834762573, "step": 127000}
{"episode_reward": 240.86331156376914, "episode": 128.0, "batch_reward": 0.31383661894500253, "critic_loss": 0.36920662158727646, "actor_loss": -35.07353783416748, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.047001600265503, "step": 128000}
{"episode_reward": 599.8562968934315, "episode": 129.0, "batch_reward": 0.31539458814263344, "critic_loss": 0.37001389619708064, "actor_loss": -35.073379055023196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.447514295578003, "step": 129000}
{"episode_reward": 604.8339336774089, "episode": 130.0, "batch_reward": 0.3184089353978634, "critic_loss": 0.3534854527711868, "actor_loss": -35.435782466888426, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.283557176589966, "step": 130000}
{"episode_reward": 337.33393959086686, "episode": 131.0, "batch_reward": 0.3172352681607008, "critic_loss": 0.3990489618480206, "actor_loss": -35.63743410110474, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.59120464324951, "step": 131000}
{"episode_reward": 541.6772340032137, "episode": 132.0, "batch_reward": 0.31968576070666316, "critic_loss": 0.41099091549217703, "actor_loss": -35.53941705322266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.821696758270264, "step": 132000}
{"episode_reward": 606.5761278976695, "episode": 133.0, "batch_reward": 0.3205750932097435, "critic_loss": 0.3920000617057085, "actor_loss": -35.50652683258057, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.37291955947876, "step": 133000}
{"episode_reward": 158.95646853807497, "episode": 134.0, "batch_reward": 0.3203336220383644, "critic_loss": 0.3829106579273939, "actor_loss": -35.47981968688965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.45205330848694, "step": 134000}
{"episode_reward": 614.5383752697846, "episode": 135.0, "batch_reward": 0.3216500125527382, "critic_loss": 0.39678666365146636, "actor_loss": -35.51542632293701, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.69064450263977, "step": 135000}
{"episode_reward": 160.77151428633866, "episode": 136.0, "batch_reward": 0.3207401999235153, "critic_loss": 0.3870812575817108, "actor_loss": -35.348311744689944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.539183616638184, "step": 136000}
{"episode_reward": 524.1504812319057, "episode": 137.0, "batch_reward": 0.32381949698925017, "critic_loss": 0.3759267521500588, "actor_loss": -35.81809517669678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.239773511886597, "step": 137000}
{"episode_reward": 590.6055641649507, "episode": 138.0, "batch_reward": 0.32639557945728304, "critic_loss": 0.38584670366346835, "actor_loss": -36.356894088745115, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.448688507080078, "step": 138000}
{"episode_reward": 576.1933854856837, "episode": 139.0, "batch_reward": 0.32841131126880646, "critic_loss": 0.38746265982091427, "actor_loss": -36.61163813400269, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.447307586669922, "step": 139000}
{"episode_reward": 607.6189899388957, "episode": 140.0, "batch_reward": 0.32845765906572344, "critic_loss": 0.3618510075211525, "actor_loss": -36.46703931045532, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.94155740737915, "step": 140000}
{"episode_reward": 585.5900953940901, "episode": 141.0, "batch_reward": 0.33081085589528086, "critic_loss": 0.38565251472592355, "actor_loss": -36.419531646728515, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.51996970176697, "step": 141000}
{"episode_reward": 571.1114941920802, "episode": 142.0, "batch_reward": 0.33207674220204353, "critic_loss": 0.38153291830420494, "actor_loss": -36.84347468948364, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.226528882980347, "step": 142000}
{"episode_reward": 602.4902194435714, "episode": 143.0, "batch_reward": 0.33525546100735665, "critic_loss": 0.39579079395532607, "actor_loss": -36.795018325805664, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.498899221420288, "step": 143000}
{"episode_reward": 531.4223346601723, "episode": 144.0, "batch_reward": 0.33739147558808325, "critic_loss": 0.4093509214669466, "actor_loss": -37.31115737915039, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.200761556625366, "step": 144000}
{"episode_reward": 638.0119082804307, "episode": 145.0, "batch_reward": 0.33852962851524354, "critic_loss": 0.3814819416999817, "actor_loss": -36.96049603271484, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.39572811126709, "step": 145000}
{"episode_reward": 637.293111907071, "episode": 146.0, "batch_reward": 0.33959793469309807, "critic_loss": 0.39577363458275794, "actor_loss": -37.50035596466064, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.53420639038086, "step": 146000}
{"episode_reward": 553.4453191316777, "episode": 147.0, "batch_reward": 0.34190720635652544, "critic_loss": 0.38225558571517465, "actor_loss": -37.49216764831543, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.182392835617065, "step": 147000}
{"episode_reward": 478.36372409579116, "episode": 148.0, "batch_reward": 0.34243013367056846, "critic_loss": 0.4116743793487549, "actor_loss": -37.55180715942383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.993807792663574, "step": 148000}
{"episode_reward": 204.26980420793026, "episode": 149.0, "batch_reward": 0.3407886125445366, "critic_loss": 0.405191785544157, "actor_loss": -37.55063605499267, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.59532356262207, "step": 149000}
{"episode_reward": 601.0044789437279, "episode": 150.0, "batch_reward": 0.3430068400502205, "critic_loss": 0.3967818038314581, "actor_loss": -37.634474815368655, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
