{"episode": 1.0, "duration": 19.55753207206726, "episode_reward": 5.218604035389536, "step": 1000}
{"episode": 2.0, "duration": 1.7890100479125977, "episode_reward": 548.2612263124905, "step": 2000}
{"episode": 3.0, "batch_reward": 0.2606263492292426, "actor_loss": -45.32076443543955, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254236, "duration": 62.885579347610474, "episode_reward": 16.898946967448072, "step": 3000}
{"episode": 4.0, "batch_reward": 0.1693218022286892, "actor_loss": -37.94919697189331, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.7123064994812, "episode_reward": 47.46352319575565, "step": 4000}
{"episode": 5.0, "batch_reward": 0.14835773458331825, "actor_loss": -34.82753848648071, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.766405820846558, "episode_reward": 115.68316639719914, "step": 5000}
{"episode": 6.0, "batch_reward": 0.13678435030579567, "actor_loss": -34.42856359863281, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.71116805076599, "episode_reward": 32.140229531838926, "step": 6000}
{"episode": 7.0, "batch_reward": 0.12145509075373412, "actor_loss": -33.91907858657837, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.759799480438232, "episode_reward": 51.05755486293788, "step": 7000}
{"episode": 8.0, "batch_reward": 0.11108771937340498, "actor_loss": -33.7176990776062, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 25.674660444259644, "episode_reward": 35.50356834451125, "step": 8000}
{"episode": 9.0, "batch_reward": 0.10694113272428513, "actor_loss": -33.754390308380124, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.781203269958496, "episode_reward": 110.4154730720245, "step": 9000}
{"episode": 10.0, "batch_reward": 0.10471384274214506, "actor_loss": -28.99881516647339, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 5356.061420440674, "episode_reward": 55.68335513939193, "step": 10000}
{"episode": 11.0, "batch_reward": 0.0987335576415062, "actor_loss": -25.983641372680665, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 38.77746772766113, "episode_reward": 34.15213308130107, "step": 11000}
{"episode": 12.0, "batch_reward": 0.09728413559123873, "actor_loss": -21.53271731567383, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 582.0581064224243, "episode_reward": 79.89751173840018, "step": 12000}
{"episode": 13.0, "batch_reward": 0.0946319136209786, "actor_loss": -19.701967504501344, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.932415008544922, "episode_reward": 47.32979515360187, "step": 13000}
{"episode": 14.0, "batch_reward": 0.09248282499238848, "actor_loss": -17.402342439651488, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 583.7429301738739, "episode_reward": 197.26385936537216, "step": 14000}
{"episode": 15.0, "batch_reward": 0.09590122315660118, "actor_loss": -17.72476142501831, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.70710849761963, "episode_reward": 27.520282913596155, "step": 15000}
{"episode": 16.0, "batch_reward": 0.09010425516963005, "actor_loss": -16.440936899185182, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 584.3745546340942, "episode_reward": 7.0221347728756935, "step": 16000}
{"episode": 17.0, "batch_reward": 0.08578130087256432, "actor_loss": -17.201376817703245, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.640156984329224, "episode_reward": 8.226947635858107, "step": 17000}
{"episode": 18.0, "batch_reward": 0.08146008499339223, "actor_loss": -17.35923093032837, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 579.4020137786865, "episode_reward": 2.604949861581578, "step": 18000}
{"episode": 19.0, "batch_reward": 0.07689763065055012, "actor_loss": -17.82602628517151, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.141384601593018, "episode_reward": 3.1371795420638384, "step": 19000}
{"episode": 20.0, "batch_reward": 0.07353510199487209, "actor_loss": -17.680956970214844, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 581.5344886779785, "episode_reward": 4.956693291063122, "step": 20000}
{"episode": 21.0, "batch_reward": 0.06983051623031497, "actor_loss": -17.951911962509154, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 42.041160583496094, "episode_reward": 8.011595272665081, "step": 21000}
{"episode": 22.0, "batch_reward": 0.06762437372282147, "actor_loss": -17.573704277038573, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 586.1054141521454, "episode_reward": 16.87633910732722, "step": 22000}
{"episode": 23.0, "batch_reward": 0.06579748874157668, "actor_loss": -17.810735355377197, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.763912200927734, "episode_reward": 85.38278929684499, "step": 23000}
{"episode": 24.0, "batch_reward": 0.06597716516256333, "actor_loss": -17.3310578956604, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 583.2288126945496, "episode_reward": 34.34537463782691, "step": 24000}
{"episode": 25.0, "batch_reward": 0.06517686162889004, "actor_loss": -17.556404960632324, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.527911901474, "episode_reward": 121.657363931147, "step": 25000}
{"episode": 26.0, "batch_reward": 0.06793549043312669, "actor_loss": -17.440785844802857, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 581.8440647125244, "episode_reward": 77.23421021551496, "step": 26000}
{"episode": 27.0, "batch_reward": 0.07049592802673578, "actor_loss": -17.56260975074768, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.63826084136963, "episode_reward": 121.91814664801666, "step": 27000}
{"episode": 28.0, "batch_reward": 0.07244601287692785, "actor_loss": -17.14133413505554, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 582.6100099086761, "episode_reward": 215.7809952559023, "step": 28000}
{"episode": 29.0, "batch_reward": 0.07655566547438503, "actor_loss": -17.66240873146057, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.51510739326477, "episode_reward": 161.1718255966978, "step": 29000}
{"episode": 30.0, "batch_reward": 0.07875327927246689, "actor_loss": -17.98450685119629, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 592.5259206295013, "episode_reward": 159.42452714440785, "step": 30000}
{"episode": 31.0, "batch_reward": 0.08167534755915404, "actor_loss": -18.281104257583618, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 31.49928593635559, "episode_reward": 113.74029074022275, "step": 31000}
{"episode": 32.0, "batch_reward": 0.08328076378628611, "actor_loss": -17.975577280044554, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 583.2433664798737, "episode_reward": 87.35689246817896, "step": 32000}
{"episode": 33.0, "batch_reward": 0.08397887689620256, "actor_loss": -17.97009942817688, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.762256383895874, "episode_reward": 207.30821270510563, "step": 33000}
{"episode": 34.0, "batch_reward": 0.08764646385237575, "actor_loss": -18.147684850692748, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 579.4905345439911, "episode_reward": 185.1753809060603, "step": 34000}
{"episode": 35.0, "batch_reward": 0.09043698177114129, "actor_loss": -18.383457983016967, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.703213214874268, "episode_reward": 288.0207678885228, "step": 35000}
{"episode": 36.0, "batch_reward": 0.09526811497658491, "actor_loss": -17.997156436920164, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 578.9463627338409, "episode_reward": 85.73766074115349, "step": 36000}
{"episode": 37.0, "batch_reward": 0.09583791738748551, "actor_loss": -17.926871728897094, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.79438304901123, "episode_reward": 157.03973849803808, "step": 37000}
{"episode": 38.0, "batch_reward": 0.09801331079006195, "actor_loss": -17.60855347061157, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 578.5858068466187, "episode_reward": 173.70191248364006, "step": 38000}
{"episode": 39.0, "batch_reward": 0.09870384698361158, "actor_loss": -17.457041400909425, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.848092317581177, "episode_reward": 144.45933098537617, "step": 39000}
{"episode": 40.0, "batch_reward": 0.10130942342430353, "actor_loss": -17.445476722717284, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 577.7605035305023, "episode_reward": 288.3109381318958, "step": 40000}
{"episode": 41.0, "batch_reward": 0.10592102894186974, "actor_loss": -17.89601893043518, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 40.00432562828064, "episode_reward": 312.5248756848404, "step": 41000}
{"episode": 42.0, "batch_reward": 0.11169845977425576, "actor_loss": -18.37765962982178, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 575.1949362754822, "episode_reward": 338.20509488607513, "step": 42000}
{"episode": 43.0, "batch_reward": 0.1168637180775404, "actor_loss": -18.795719038009643, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.627041578292847, "episode_reward": 328.70887626646186, "step": 43000}
{"episode": 44.0, "batch_reward": 0.12189897149056196, "actor_loss": -19.274594635009766, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 583.369077205658, "episode_reward": 328.0170979360002, "step": 44000}
{"episode": 45.0, "batch_reward": 0.12618710900843144, "actor_loss": -19.65148707008362, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.25626516342163, "episode_reward": 317.0294970642237, "step": 45000}
{"episode": 46.0, "batch_reward": 0.12935638415068387, "actor_loss": -19.837653980255126, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 582.2482390403748, "episode_reward": 302.8660353880381, "step": 46000}
{"episode": 47.0, "batch_reward": 0.13479458313435316, "actor_loss": -20.298670408248903, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.833168745040894, "episode_reward": 398.8282460619959, "step": 47000}
{"episode": 48.0, "batch_reward": 0.1392126547023654, "actor_loss": -20.562264930725096, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 582.5700447559357, "episode_reward": 346.1812756585871, "step": 48000}
{"episode": 49.0, "batch_reward": 0.14485975328087808, "actor_loss": -21.068766944885255, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.720744371414185, "episode_reward": 336.7720027330911, "step": 49000}
{"episode": 50.0, "batch_reward": 0.1480767041295767, "actor_loss": -21.224438926696777, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 582.2068531513214, "episode_reward": 329.5379186661998, "step": 50000}
{"episode": 51.0, "batch_reward": 0.15225257411599158, "actor_loss": -21.57215472793579, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 38.58187127113342, "episode_reward": 370.5863320441878, "step": 51000}
{"episode": 52.0, "batch_reward": 0.15647261852025987, "actor_loss": -21.60670366668701, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 580.5441732406616, "episode_reward": 369.3891390181727, "step": 52000}
{"episode": 53.0, "batch_reward": 0.15985047090798615, "actor_loss": -22.025929660797118, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.62488293647766, "episode_reward": 362.61205288780604, "step": 53000}
{"episode": 54.0, "batch_reward": 0.16406136767566204, "actor_loss": -22.39849419784546, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 582.2312808036804, "episode_reward": 356.06130593109117, "step": 54000}
{"episode": 55.0, "batch_reward": 0.16698598277568816, "actor_loss": -22.57236315536499, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.47265887260437, "episode_reward": 237.0616940753873, "step": 55000}
{"episode": 56.0, "batch_reward": 0.16847436018288137, "actor_loss": -22.447831329345703, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 580.4434177875519, "episode_reward": 379.8349888188093, "step": 56000}
{"episode": 57.0, "batch_reward": 0.17358032471686602, "actor_loss": -22.798875102996828, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 26.940376043319702, "episode_reward": 414.2123515746631, "step": 57000}
{"episode": 58.0, "batch_reward": 0.17664063777029515, "actor_loss": -23.11437439727783, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 583.9641013145447, "episode_reward": 418.716666764965, "step": 58000}
{"episode": 59.0, "batch_reward": 0.1809225363880396, "actor_loss": -23.443456985473635, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.724119186401367, "episode_reward": 417.3133812467434, "step": 59000}
{"episode": 60.0, "batch_reward": 0.18423660795390606, "actor_loss": -23.451389526367187, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 581.1835787296295, "episode_reward": 394.4418102895165, "step": 60000}
{"episode": 61.0, "batch_reward": 0.1886206609159708, "actor_loss": -23.849397827148437, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 34.91188311576843, "episode_reward": 443.2854236599329, "step": 61000}
{"episode": 62.0, "batch_reward": 0.19277730736136436, "actor_loss": -24.124854106903076, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 588.4637384414673, "episode_reward": 403.7668867458534, "step": 62000}
{"episode": 63.0, "batch_reward": 0.19619426640868187, "actor_loss": -24.454873359680175, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.706151247024536, "episode_reward": 407.3022049328293, "step": 63000}
{"episode": 64.0, "batch_reward": 0.19973628981411456, "actor_loss": -24.47180192565918, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 584.7049720287323, "episode_reward": 417.3958605670081, "step": 64000}
{"episode": 65.0, "batch_reward": 0.20301458747684956, "actor_loss": -24.73239611053467, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.960108280181885, "episode_reward": 448.3748128260827, "step": 65000}
{"episode": 66.0, "batch_reward": 0.2061949319690466, "actor_loss": -25.053925952911378, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 583.5744502544403, "episode_reward": 430.42483163865785, "step": 66000}
{"episode": 67.0, "batch_reward": 0.21036450123786926, "actor_loss": -25.355653270721437, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 25.018401384353638, "episode_reward": 461.0357477055864, "step": 67000}
{"episode": 68.0, "batch_reward": 0.21392860490083696, "actor_loss": -24.845447528839113, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 580.3743515014648, "episode_reward": 457.68979449636214, "step": 68000}
{"episode": 69.0, "batch_reward": 0.217241908416152, "actor_loss": -25.185902267456054, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.128642320632935, "episode_reward": 451.8770743335516, "step": 69000}
{"episode": 70.0, "batch_reward": 0.22077940094470977, "actor_loss": -25.545500808715822, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 587.7091257572174, "episode_reward": 412.68984699680107, "step": 70000}
{"episode": 71.0, "batch_reward": 0.22315249612927437, "actor_loss": -25.831461406707763, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 31.904077529907227, "episode_reward": 431.48427923591464, "step": 71000}
{"episode": 72.0, "batch_reward": 0.22536932460963727, "actor_loss": -25.746509380340576, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 580.4643568992615, "episode_reward": 392.1327549894264, "step": 72000}
{"episode": 73.0, "batch_reward": 0.2285427061021328, "actor_loss": -26.05712684249878, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.702679872512817, "episode_reward": 481.3797753124726, "step": 73000}
{"episode": 74.0, "batch_reward": 0.23235165436565877, "actor_loss": -25.89452682876587, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 586.7253170013428, "episode_reward": 453.7739075220127, "step": 74000}
{"episode": 75.0, "batch_reward": 0.23478152666985988, "actor_loss": -26.216348190307617, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.63457202911377, "episode_reward": 422.4617690016252, "step": 75000}
{"episode": 76.0, "batch_reward": 0.2373436526954174, "actor_loss": -26.214934356689454, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 579.2938470840454, "episode_reward": 432.56937708893025, "step": 76000}
{"episode": 77.0, "batch_reward": 0.24090644393861294, "actor_loss": -26.48203322982788, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.656833171844482, "episode_reward": 439.3809978004713, "step": 77000}
{"episode": 78.0, "batch_reward": 0.24239693039655685, "actor_loss": -26.782796855926513, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 585.9756562709808, "episode_reward": 222.92881426823473, "step": 78000}
{"episode": 79.0, "batch_reward": 0.24270915611088276, "actor_loss": -26.673984951019285, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.621934175491333, "episode_reward": 499.03149046268294, "step": 79000}
{"episode": 80.0, "batch_reward": 0.245717666387558, "actor_loss": -26.78303885269165, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 580.2102060317993, "episode_reward": 449.2838828905484, "step": 80000}
{"episode": 81.0, "batch_reward": 0.247474365696311, "actor_loss": -26.88245442199707, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 45.15634250640869, "episode_reward": 415.2089341742228, "step": 81000}
{"episode": 82.0, "batch_reward": 0.24981127160787583, "actor_loss": -26.774875930786134, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 577.2346634864807, "episode_reward": 472.58383902442336, "step": 82000}
{"episode": 83.0, "batch_reward": 0.25314385348558427, "actor_loss": -27.036792221069337, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.763468503952026, "episode_reward": 461.7301847972277, "step": 83000}
{"episode": 84.0, "batch_reward": 0.2547822842746973, "actor_loss": -27.250016738891603, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 581.0282666683197, "episode_reward": 419.73145687993815, "step": 84000}
{"episode": 85.0, "batch_reward": 0.25669688284397124, "actor_loss": -27.295316020965576, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.617804765701294, "episode_reward": 383.9641207768108, "step": 85000}
{"episode": 86.0, "batch_reward": 0.2591280062943697, "actor_loss": -27.461548851013184, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 586.0361700057983, "episode_reward": 458.84000288662565, "step": 86000}
{"episode": 87.0, "batch_reward": 0.2609000406116247, "actor_loss": -27.667356678009032, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.92290163040161, "episode_reward": 463.85341866607547, "step": 87000}
{"episode": 88.0, "batch_reward": 0.26333464941382406, "actor_loss": -28.189919651031495, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 582.9677317142487, "episode_reward": 85.03831767309079, "step": 88000}
{"episode": 89.0, "batch_reward": 0.2616067297011614, "actor_loss": -28.029193225860595, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.67739963531494, "episode_reward": 454.7502087681832, "step": 89000}
{"episode": 90.0, "batch_reward": 0.2632431750446558, "actor_loss": -27.840718032836914, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 575.6607689857483, "episode_reward": 410.40341544219547, "step": 90000}
{"episode": 91.0, "batch_reward": 0.2656681756824255, "actor_loss": -28.170204860687257, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.038307905197144, "episode_reward": 495.2680887961277, "step": 91000}
{"episode": 92.0, "batch_reward": 0.26694121642410756, "actor_loss": -28.03857865142822, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 561.2079875469208, "episode_reward": 446.6096604622814, "step": 92000}
{"episode": 93.0, "batch_reward": 0.26929510399699214, "actor_loss": -28.219293823242186, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.354323148727417, "episode_reward": 460.82564095619216, "step": 93000}
{"episode": 94.0, "batch_reward": 0.2725314420461655, "actor_loss": -28.263483909606933, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 574.8416934013367, "episode_reward": 489.9384062277429, "step": 94000}
{"episode": 95.0, "batch_reward": 0.27322813226282594, "actor_loss": -28.267139991760253, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.915998220443726, "episode_reward": 467.49685176064884, "step": 95000}
{"episode": 96.0, "batch_reward": 0.27675971861183646, "actor_loss": -28.528810382843016, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 589.1179096698761, "episode_reward": 500.93110637792654, "step": 96000}
{"episode": 97.0, "batch_reward": 0.2787930989563465, "actor_loss": -28.67180178833008, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.62799310684204, "episode_reward": 474.72483317658254, "step": 97000}
{"episode": 98.0, "batch_reward": 0.28077458940446376, "actor_loss": -29.054116104125978, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 579.4625322818756, "episode_reward": 465.95371473623703, "step": 98000}
{"episode": 99.0, "batch_reward": 0.2828022740036249, "actor_loss": -29.25933056640625, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.112707138061523, "episode_reward": 485.4123242118341, "step": 99000}
{"episode": 100.0, "batch_reward": 0.2849909334331751, "actor_loss": -29.550381832122802, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 581.786634683609, "episode_reward": 461.0375284504445, "step": 100000}
{"episode": 101.0, "batch_reward": 0.2856486739963293, "actor_loss": -29.539881858825684, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.37432408332825, "episode_reward": 541.9820331615749, "step": 101000}
{"episode": 102.0, "batch_reward": 0.28775476188957694, "actor_loss": -29.52604048538208, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 584.5886788368225, "episode_reward": 516.5401901104087, "step": 102000}
{"episode": 103.0, "batch_reward": 0.2911033556908369, "actor_loss": -29.81853707122803, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.76197910308838, "episode_reward": 510.1780205637256, "step": 103000}
{"episode": 104.0, "batch_reward": 0.29333671057224275, "actor_loss": -29.8851379776001, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 589.3001401424408, "episode_reward": 540.9420093984519, "step": 104000}
{"episode": 105.0, "batch_reward": 0.29603423154354097, "actor_loss": -30.125785079956053, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.6340115070343, "episode_reward": 467.9956054853291, "step": 105000}
{"episode": 106.0, "batch_reward": 0.2957028124183416, "actor_loss": -30.186834121704102, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 588.4208950996399, "episode_reward": 131.72693179638395, "step": 106000}
{"episode": 107.0, "batch_reward": 0.29462708012759686, "actor_loss": -29.977184059143067, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.275492191314697, "episode_reward": 517.6933840454869, "step": 107000}
{"episode": 108.0, "batch_reward": 0.2977047800421715, "actor_loss": -29.997682170867918, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 594.7845840454102, "episode_reward": 443.1530158840814, "step": 108000}
{"episode": 109.0, "batch_reward": 0.2989213696718216, "actor_loss": -30.03012522125244, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.706040859222412, "episode_reward": 523.0325441409966, "step": 109000}
{"episode": 110.0, "batch_reward": 0.30095570597052573, "actor_loss": -30.60072876739502, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 589.5182816982269, "episode_reward": 470.93474628496824, "step": 110000}
{"episode": 111.0, "batch_reward": 0.3031778107136488, "actor_loss": -30.754994163513185, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 31.78991174697876, "episode_reward": 514.8721847291381, "step": 111000}
{"episode": 112.0, "batch_reward": 0.30529556520283224, "actor_loss": -30.677605613708497, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 592.2229671478271, "episode_reward": 482.8721067652318, "step": 112000}
{"episode": 113.0, "batch_reward": 0.30525493793189523, "actor_loss": -30.7483130569458, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.45879554748535, "episode_reward": 480.2354468425451, "step": 113000}
{"episode": 114.0, "batch_reward": 0.30649183690547943, "actor_loss": -30.692044994354248, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 585.7692935466766, "episode_reward": 474.9353527881193, "step": 114000}
{"episode": 115.0, "batch_reward": 0.3088437611311674, "actor_loss": -30.924569145202636, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 24.0826632976532, "episode_reward": 494.9169692592873, "step": 115000}
{"episode": 116.0, "batch_reward": 0.3100800259411335, "actor_loss": -30.846547374725343, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 582.6741983890533, "episode_reward": 526.3885833102535, "step": 116000}
{"episode": 117.0, "batch_reward": 0.31438900527358055, "actor_loss": -31.197657608032227, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 26.49751567840576, "episode_reward": 513.0506047267821, "step": 117000}
{"episode": 118.0, "batch_reward": 0.31444904044270516, "actor_loss": -30.839915489196777, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 585.1784920692444, "episode_reward": 503.60885450134725, "step": 118000}
{"episode": 119.0, "batch_reward": 0.3162138626277447, "actor_loss": -30.91902830886841, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 27.85719871520996, "episode_reward": 467.64863536404783, "step": 119000}
{"episode": 120.0, "batch_reward": 0.3164945637881756, "actor_loss": -30.49585973739624, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 583.0685901641846, "episode_reward": 455.0396770703801, "step": 120000}
{"episode": 121.0, "batch_reward": 0.31806875094771386, "actor_loss": -30.628487884521483, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 41.22351861000061, "episode_reward": 475.1446297007776, "step": 121000}
{"episode": 122.0, "batch_reward": 0.31951558735966684, "actor_loss": -30.280946559906006, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 581.6845347881317, "episode_reward": 469.64642787365517, "step": 122000}
{"episode": 123.0, "batch_reward": 0.32027831837534904, "actor_loss": -30.381173278808593, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 28.394062519073486, "episode_reward": 495.86068287827266, "step": 123000}
{"episode": 124.0, "batch_reward": 0.3211225101649761, "actor_loss": -30.370969619750976, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 583.1030006408691, "episode_reward": 441.7492985932589, "step": 124000}
{"episode": 125.0, "batch_reward": 0.3232567564547062, "actor_loss": -30.4635239944458, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.93746280670166, "episode_reward": 480.49969895572247, "step": 125000}
{"episode": 126.0, "batch_reward": 0.32443587747216224, "actor_loss": -30.843380477905274, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 586.5017697811127, "episode_reward": 451.91849455171047, "step": 126000}
{"episode": 127.0, "batch_reward": 0.3250750665962696, "actor_loss": -30.866746391296388, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.789046049118042, "episode_reward": 491.2206529041842, "step": 127000}
{"episode": 128.0, "batch_reward": 0.3260556328892708, "actor_loss": -30.842541248321535, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 586.2442629337311, "episode_reward": 482.17074191869614, "step": 128000}
{"episode": 129.0, "batch_reward": 0.3274988558292389, "actor_loss": -30.956707386016845, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.694974422454834, "episode_reward": 451.32162251797604, "step": 129000}
{"episode": 130.0, "batch_reward": 0.3293938411772251, "actor_loss": -30.94552470397949, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 591.5603969097137, "episode_reward": 497.18448598287154, "step": 130000}
{"episode": 131.0, "batch_reward": 0.3297656508088112, "actor_loss": -30.938815269470215, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 30.11618995666504, "episode_reward": 482.9288622824323, "step": 131000}
{"episode": 132.0, "batch_reward": 0.33231939187645915, "actor_loss": -31.031305503845214, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 586.9799056053162, "episode_reward": 494.23390446797964, "step": 132000}
{"episode": 133.0, "batch_reward": 0.33314680901169774, "actor_loss": -31.069621555328368, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.748880863189697, "episode_reward": 513.5847511325892, "step": 133000}
{"episode": 134.0, "batch_reward": 0.33458654338121413, "actor_loss": -31.12922646713257, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 578.9252743721008, "episode_reward": 518.6399556561379, "step": 134000}
{"episode": 135.0, "batch_reward": 0.33446867248415946, "actor_loss": -31.055582511901857, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.312308311462402, "episode_reward": 540.3302771890603, "step": 135000}
{"episode": 136.0, "batch_reward": 0.3372023607492447, "actor_loss": -31.12658084869385, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 584.9350447654724, "episode_reward": 554.2183690176671, "step": 136000}
{"episode": 137.0, "batch_reward": 0.337768832474947, "actor_loss": -31.26512260055542, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.91420841217041, "episode_reward": 510.30701611873957, "step": 137000}
{"episode": 138.0, "batch_reward": 0.33962882959842683, "actor_loss": -31.42011625289917, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 588.7148728370667, "episode_reward": 513.2994806570971, "step": 138000}
{"episode": 139.0, "batch_reward": 0.3424078784286976, "actor_loss": -31.74985146713257, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.191312313079834, "episode_reward": 554.0711532688113, "step": 139000}
{"episode": 140.0, "batch_reward": 0.34314399540424345, "actor_loss": -31.932450450897218, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 584.5592181682587, "episode_reward": 534.099190858699, "step": 140000}
{"episode": 141.0, "batch_reward": 0.34417762407660485, "actor_loss": -31.96873073577881, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 38.80030679702759, "episode_reward": 479.6950304758233, "step": 141000}
{"episode": 142.0, "batch_reward": 0.3446056592464447, "actor_loss": -32.09261797714233, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 566.5092754364014, "episode_reward": 528.357181678362, "step": 142000}
{"episode": 143.0, "batch_reward": 0.3460684213638306, "actor_loss": -32.27374615097046, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.84485626220703, "episode_reward": 514.2419958943772, "step": 143000}
{"episode": 144.0, "batch_reward": 0.3472589755654335, "actor_loss": -32.278212509155274, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 585.4827611446381, "episode_reward": 545.7633711920566, "step": 144000}
{"episode": 145.0, "batch_reward": 0.3488076926469803, "actor_loss": -32.442368465423584, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.97190570831299, "episode_reward": 520.4664160692926, "step": 145000}
{"episode": 146.0, "batch_reward": 0.3490603516697884, "actor_loss": -32.200497497558594, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 589.2012722492218, "episode_reward": 493.23747105242364, "step": 146000}
{"episode": 147.0, "batch_reward": 0.35165906354784965, "actor_loss": -32.555245304107665, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.79547142982483, "episode_reward": 544.7564638704523, "step": 147000}
{"episode": 148.0, "batch_reward": 0.35173772034049033, "actor_loss": -32.766579929351806, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 581.5812983512878, "episode_reward": 541.9336903303861, "step": 148000}
{"episode": 149.0, "batch_reward": 0.35416985729336736, "actor_loss": -33.042112232208254, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 26.616071462631226, "episode_reward": 576.4839164139931, "step": 149000}
{"episode": 150.0, "batch_reward": 0.35490798026323317, "actor_loss": -33.17904780960083, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "step": 150000}
