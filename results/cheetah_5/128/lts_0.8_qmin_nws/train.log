{"episode_reward": 0.0, "episode": 1.0, "duration": 17.60142731666565, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.5193641185760498, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.26513528506848844, "critic_loss": 0.12897201928161967, "actor_loss": -35.57821054877687, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 60.66782593727112, "step": 3000}
{"episode_reward": 85.39448417636643, "episode": 4.0, "batch_reward": 0.18892758096009493, "critic_loss": 0.062253603881224986, "actor_loss": -27.594848648071288, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.055546045303345, "step": 4000}
{"episode_reward": 24.777303952827168, "episode": 5.0, "batch_reward": 0.14882260334864258, "critic_loss": 0.04546230042725802, "actor_loss": -27.76797634792328, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.053677082061768, "step": 5000}
{"episode_reward": 7.425017399159856, "episode": 6.0, "batch_reward": 0.12278622597455978, "critic_loss": 0.04454864352196455, "actor_loss": -26.64900916957855, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.061979055404663, "step": 6000}
{"episode_reward": 3.663948817692776, "episode": 7.0, "batch_reward": 0.1040650389753282, "critic_loss": 0.044509075865149496, "actor_loss": -27.289219667434693, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.049872159957886, "step": 7000}
{"episode_reward": 6.612515121088992, "episode": 8.0, "batch_reward": 0.0929681400321424, "critic_loss": 0.05256243438273668, "actor_loss": -28.12167008113861, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05140209197998, "step": 8000}
{"episode_reward": 25.854670772062743, "episode": 9.0, "batch_reward": 0.08372671646252275, "critic_loss": 0.04663696358352899, "actor_loss": -25.33730718231201, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.074265956878662, "step": 9000}
{"episode_reward": 5.945830690099263, "episode": 10.0, "batch_reward": 0.07602119148895145, "critic_loss": 0.04044012524466962, "actor_loss": -27.174030839920043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.066814184188843, "step": 10000}
{"episode_reward": 19.227549246912425, "episode": 11.0, "batch_reward": 0.07032117461413145, "critic_loss": 0.038815007535740735, "actor_loss": -25.602820649147034, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.658424377441406, "step": 11000}
{"episode_reward": 33.801983106406745, "episode": 12.0, "batch_reward": 0.06768655608035624, "critic_loss": 0.038658688263967636, "actor_loss": -26.514120685577392, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07038164138794, "step": 12000}
{"episode_reward": 23.026150967755786, "episode": 13.0, "batch_reward": 0.06441447799094022, "critic_loss": 0.033305981955491004, "actor_loss": -26.94443828868866, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.066707849502563, "step": 13000}
{"episode_reward": 56.2639003668294, "episode": 14.0, "batch_reward": 0.06547984898649156, "critic_loss": 0.04165384636633098, "actor_loss": -27.0917811460495, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00107216835022, "step": 14000}
{"episode_reward": 65.66201928532908, "episode": 15.0, "batch_reward": 0.0651993058603257, "critic_loss": 0.037284767393954095, "actor_loss": -25.69044691944122, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04331374168396, "step": 15000}
{"episode_reward": 79.67770768578882, "episode": 16.0, "batch_reward": 0.06653802865371108, "critic_loss": 0.03782662758976221, "actor_loss": -26.524563506126405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05143928527832, "step": 16000}
{"episode_reward": 81.78478762090468, "episode": 17.0, "batch_reward": 0.06679638782516122, "critic_loss": 0.04480105241201818, "actor_loss": -26.94507653427124, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.014743089675903, "step": 17000}
{"episode_reward": 77.28084521499459, "episode": 18.0, "batch_reward": 0.06769129726290703, "critic_loss": 0.04757469202578068, "actor_loss": -26.893596391677857, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0370090007782, "step": 18000}
{"episode_reward": 83.71706091523599, "episode": 19.0, "batch_reward": 0.0687677041105926, "critic_loss": 0.059773386498913166, "actor_loss": -26.478894280433654, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07051944732666, "step": 19000}
{"episode_reward": 94.36432294893748, "episode": 20.0, "batch_reward": 0.07210122730955482, "critic_loss": 0.06800619167089463, "actor_loss": -27.053006806850433, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01484179496765, "step": 20000}
{"episode_reward": 116.94443451290654, "episode": 21.0, "batch_reward": 0.07433567684143781, "critic_loss": 0.08257970961742103, "actor_loss": -24.418112102508545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.58240747451782, "step": 21000}
{"episode_reward": 109.87580939989749, "episode": 22.0, "batch_reward": 0.0748025860749185, "critic_loss": 0.08156031368672848, "actor_loss": -26.39415768790245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.025506496429443, "step": 22000}
{"episode_reward": 120.84226685691738, "episode": 23.0, "batch_reward": 0.07874203532934189, "critic_loss": 0.08419868193939328, "actor_loss": -26.442107565641404, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.055383682250977, "step": 23000}
{"episode_reward": 192.61594390018237, "episode": 24.0, "batch_reward": 0.08222963877767324, "critic_loss": 0.10229540880396962, "actor_loss": -25.479572509884836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.068357467651367, "step": 24000}
{"episode_reward": 113.44009021806308, "episode": 25.0, "batch_reward": 0.08271927835792303, "critic_loss": 0.1083952142521739, "actor_loss": -27.096908366799354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0429208278656, "step": 25000}
{"episode_reward": 77.48122057952114, "episode": 26.0, "batch_reward": 0.08332720481231809, "critic_loss": 0.11423365037888289, "actor_loss": -25.751019259423018, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.055649280548096, "step": 26000}
{"episode_reward": 104.72191223997108, "episode": 27.0, "batch_reward": 0.08371357326954604, "critic_loss": 0.1239847942739725, "actor_loss": -25.474124476522206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.055049180984497, "step": 27000}
{"episode_reward": 172.40915959441236, "episode": 28.0, "batch_reward": 0.08668039071187376, "critic_loss": 0.15405344357341527, "actor_loss": -25.262572936460376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.050200700759888, "step": 28000}
{"episode_reward": 89.6259972222924, "episode": 29.0, "batch_reward": 0.08839987566694617, "critic_loss": 0.16272899071872235, "actor_loss": -25.9591956711635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.032495260238647, "step": 29000}
{"episode_reward": 137.2285018949628, "episode": 30.0, "batch_reward": 0.08891663610562682, "critic_loss": 0.17312654981017112, "actor_loss": -25.387077006697655, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.10122036933899, "step": 30000}
{"episode_reward": 86.7198531049787, "episode": 31.0, "batch_reward": 0.08922761345282197, "critic_loss": 0.18388904821127652, "actor_loss": -25.007725400060416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.691155433654785, "step": 31000}
{"episode_reward": 88.23749926614443, "episode": 32.0, "batch_reward": 0.08751948635652661, "critic_loss": 0.17036576386541127, "actor_loss": -24.456798040539027, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.014344930648804, "step": 32000}
{"episode_reward": 32.472446246758565, "episode": 33.0, "batch_reward": 0.08515090109407902, "critic_loss": 0.19133210932463407, "actor_loss": -24.25380733254552, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.035738706588745, "step": 33000}
{"episode_reward": 32.67348948633761, "episode": 34.0, "batch_reward": 0.08632200939580797, "critic_loss": 0.1790449072420597, "actor_loss": -23.7568490306139, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05048704147339, "step": 34000}
{"episode_reward": 119.06468599192347, "episode": 35.0, "batch_reward": 0.0871612620614469, "critic_loss": 0.19292696129530668, "actor_loss": -23.626489037513732, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04318404197693, "step": 35000}
{"episode_reward": 184.82903838336605, "episode": 36.0, "batch_reward": 0.09026948243752123, "critic_loss": 0.23691771054267882, "actor_loss": -24.10359723687172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.042259454727173, "step": 36000}
{"episode_reward": 164.0858608498227, "episode": 37.0, "batch_reward": 0.092417674459517, "critic_loss": 0.23200639470666648, "actor_loss": -23.918016924381256, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.072471141815186, "step": 37000}
{"episode_reward": 175.60945475994407, "episode": 38.0, "batch_reward": 0.09436917365342379, "critic_loss": 0.2433983675837517, "actor_loss": -24.7313385887146, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.048978328704834, "step": 38000}
{"episode_reward": 109.29347584221638, "episode": 39.0, "batch_reward": 0.09523351124674082, "critic_loss": 0.2449621185362339, "actor_loss": -24.85943212175369, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02647638320923, "step": 39000}
{"episode_reward": 259.446259764866, "episode": 40.0, "batch_reward": 0.09939330239593983, "critic_loss": 0.2849080934971571, "actor_loss": -25.542109911441802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.052846908569336, "step": 40000}
{"episode_reward": 220.12082678912284, "episode": 41.0, "batch_reward": 0.1025312016159296, "critic_loss": 0.2944811422601342, "actor_loss": -24.8649407248497, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.57221055030823, "step": 41000}
{"episode_reward": 192.36488109549893, "episode": 42.0, "batch_reward": 0.1050641988068819, "critic_loss": 0.3101895223855972, "actor_loss": -25.1878094329834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0651912689209, "step": 42000}
{"episode_reward": 187.56659623589113, "episode": 43.0, "batch_reward": 0.1060025232359767, "critic_loss": 0.3063203947395086, "actor_loss": -25.326207048416137, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.021153450012207, "step": 43000}
{"episode_reward": 96.76338786718614, "episode": 44.0, "batch_reward": 0.10686116574704647, "critic_loss": 0.2917606876939535, "actor_loss": -24.651890127182007, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06752324104309, "step": 44000}
{"episode_reward": 181.55059414770707, "episode": 45.0, "batch_reward": 0.10803981710970402, "critic_loss": 0.3064653195589781, "actor_loss": -24.601317096710204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.056965351104736, "step": 45000}
{"episode_reward": 224.46762008914328, "episode": 46.0, "batch_reward": 0.11184188991039991, "critic_loss": 0.331550310626626, "actor_loss": -24.932751209259035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05849051475525, "step": 46000}
{"episode_reward": 330.64791212664346, "episode": 47.0, "batch_reward": 0.11480147923529148, "critic_loss": 0.3300361515879631, "actor_loss": -24.548297549247742, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.080623865127563, "step": 47000}
{"episode_reward": 262.8755977977208, "episode": 48.0, "batch_reward": 0.11771806982159615, "critic_loss": 0.3444124308079481, "actor_loss": -25.445421718597412, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.057230234146118, "step": 48000}
{"episode_reward": 120.00096858542454, "episode": 49.0, "batch_reward": 0.11962814483046531, "critic_loss": 0.3453649486899376, "actor_loss": -25.437497535705567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.033682584762573, "step": 49000}
{"episode_reward": 373.91678648885363, "episode": 50.0, "batch_reward": 0.12396263877302408, "critic_loss": 0.3749423370063305, "actor_loss": -25.13309596157074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.065401792526245, "step": 50000}
{"episode_reward": 366.6278319666505, "episode": 51.0, "batch_reward": 0.1284021673798561, "critic_loss": 0.3753633763641119, "actor_loss": -26.331117495536805, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.63239049911499, "step": 51000}
{"episode_reward": 364.59598849568465, "episode": 52.0, "batch_reward": 0.13304212418198585, "critic_loss": 0.39044653841853144, "actor_loss": -26.098075757980347, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.057573080062866, "step": 52000}
{"episode_reward": 288.1990028996496, "episode": 53.0, "batch_reward": 0.1359617769420147, "critic_loss": 0.3670675335228443, "actor_loss": -26.54326499938965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02777934074402, "step": 53000}
{"episode_reward": 308.9974210858801, "episode": 54.0, "batch_reward": 0.13927143201977016, "critic_loss": 0.3862849269658327, "actor_loss": -27.111462646484377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.03836154937744, "step": 54000}
{"episode_reward": 175.38232792941065, "episode": 55.0, "batch_reward": 0.1410834980532527, "critic_loss": 0.3762342889457941, "actor_loss": -27.37069137573242, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06550669670105, "step": 55000}
{"episode_reward": 384.3268183763018, "episode": 56.0, "batch_reward": 0.14438796975463628, "critic_loss": 0.3913735942840576, "actor_loss": -27.631213005065916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.041604042053223, "step": 56000}
{"episode_reward": 270.42443471267893, "episode": 57.0, "batch_reward": 0.14792821260541678, "critic_loss": 0.38329717953503134, "actor_loss": -27.660668655395508, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.056220531463623, "step": 57000}
{"episode_reward": 373.77502116785416, "episode": 58.0, "batch_reward": 0.15066903795301914, "critic_loss": 0.43705252282321455, "actor_loss": -27.888443313598632, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.37475275993347, "step": 58000}
{"episode_reward": 247.59227507238236, "episode": 59.0, "batch_reward": 0.15315840549021958, "critic_loss": 0.41641083018481734, "actor_loss": -28.55867773246765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.038557529449463, "step": 59000}
{"episode_reward": 229.15326413865137, "episode": 60.0, "batch_reward": 0.152639856249094, "critic_loss": 0.4072267410010099, "actor_loss": -27.704519630432127, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.034761905670166, "step": 60000}
{"episode_reward": 141.47561305026306, "episode": 61.0, "batch_reward": 0.15316956992447375, "critic_loss": 0.4436997112333775, "actor_loss": -27.522978595733644, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.52606701850891, "step": 61000}
{"episode_reward": 388.148164138769, "episode": 62.0, "batch_reward": 0.15743964432924987, "critic_loss": 0.46998802015185354, "actor_loss": -27.88398257637024, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.03181505203247, "step": 62000}
{"episode_reward": 249.9443698186044, "episode": 63.0, "batch_reward": 0.15945150789618492, "critic_loss": 0.44191945920884607, "actor_loss": -28.05594884109497, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04066038131714, "step": 63000}
{"episode_reward": 171.34699978200513, "episode": 64.0, "batch_reward": 0.16068677046895027, "critic_loss": 0.3966991733908653, "actor_loss": -28.16455669403076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.035919666290283, "step": 64000}
{"episode_reward": 441.15397086445705, "episode": 65.0, "batch_reward": 0.16386512684822083, "critic_loss": 0.3655585566163063, "actor_loss": -28.41783807373047, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.03915762901306, "step": 65000}
{"episode_reward": 368.06253051833033, "episode": 66.0, "batch_reward": 0.1672400150746107, "critic_loss": 0.3742567259222269, "actor_loss": -28.81493034172058, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04533624649048, "step": 66000}
{"episode_reward": 445.4585026976686, "episode": 67.0, "batch_reward": 0.171383456453681, "critic_loss": 0.38335702164471147, "actor_loss": -28.951448530197144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.046567916870117, "step": 67000}
{"episode_reward": 333.46113340494213, "episode": 68.0, "batch_reward": 0.1743587276339531, "critic_loss": 0.36928530523180964, "actor_loss": -29.17935400390625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02814507484436, "step": 68000}
{"episode_reward": 448.7777106504736, "episode": 69.0, "batch_reward": 0.17830693627893926, "critic_loss": 0.37948455235362055, "actor_loss": -29.0570096950531, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.046894311904907, "step": 69000}
{"episode_reward": 368.3309797635315, "episode": 70.0, "batch_reward": 0.18095165994763374, "critic_loss": 0.36627566677331924, "actor_loss": -29.709060344696045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.031167030334473, "step": 70000}
{"episode_reward": 407.67551560198297, "episode": 71.0, "batch_reward": 0.18393183739483357, "critic_loss": 0.3706621652841568, "actor_loss": -29.653630016326904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.49423670768738, "step": 71000}
{"episode_reward": 438.13281057447693, "episode": 72.0, "batch_reward": 0.18623935455083848, "critic_loss": 0.35855155549943446, "actor_loss": -30.06611347770691, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07272505760193, "step": 72000}
{"episode_reward": 144.95674135716934, "episode": 73.0, "batch_reward": 0.18710628360509873, "critic_loss": 0.3572122004181147, "actor_loss": -29.547673137664795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.069591522216797, "step": 73000}
{"episode_reward": 290.8011385345879, "episode": 74.0, "batch_reward": 0.18801246289908885, "critic_loss": 0.3605424251407385, "actor_loss": -29.467705770492554, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04521346092224, "step": 74000}
{"episode_reward": 415.2190103781178, "episode": 75.0, "batch_reward": 0.19152886985242368, "critic_loss": 0.37380851529538633, "actor_loss": -30.881554317474365, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.022749423980713, "step": 75000}
{"episode_reward": 381.75057235854456, "episode": 76.0, "batch_reward": 0.19394556131958962, "critic_loss": 0.36238251508772373, "actor_loss": -30.564935285568236, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04440402984619, "step": 76000}
{"episode_reward": 490.47178217535, "episode": 77.0, "batch_reward": 0.19802739590406418, "critic_loss": 0.33949514050781726, "actor_loss": -30.72559133720398, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02231216430664, "step": 77000}
{"episode_reward": 431.2612377554458, "episode": 78.0, "batch_reward": 0.20156594216823578, "critic_loss": 0.34827359698712823, "actor_loss": -30.78644025039673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06508469581604, "step": 78000}
{"episode_reward": 452.00625142113273, "episode": 79.0, "batch_reward": 0.20368188068270685, "critic_loss": 0.34541439543664454, "actor_loss": -31.20084306335449, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.081671476364136, "step": 79000}
{"episode_reward": 429.5151421968674, "episode": 80.0, "batch_reward": 0.20780864484608175, "critic_loss": 0.3188332092314959, "actor_loss": -31.78720893859863, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.013588666915894, "step": 80000}
{"episode_reward": 506.4776984088661, "episode": 81.0, "batch_reward": 0.21082091990113258, "critic_loss": 0.3392125913053751, "actor_loss": -31.775669286727904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.562036991119385, "step": 81000}
{"episode_reward": 470.03555680274917, "episode": 82.0, "batch_reward": 0.21379717361927034, "critic_loss": 0.33368375301361086, "actor_loss": -31.744528688430787, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05492615699768, "step": 82000}
{"episode_reward": 312.86735217903697, "episode": 83.0, "batch_reward": 0.21540419259667395, "critic_loss": 0.33746067257225515, "actor_loss": -32.20963645744324, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04808521270752, "step": 83000}
{"episode_reward": 424.17241424413413, "episode": 84.0, "batch_reward": 0.2168600714355707, "critic_loss": 0.3320076804459095, "actor_loss": -32.00349931716919, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.046823978424072, "step": 84000}
{"episode_reward": 397.53476190718715, "episode": 85.0, "batch_reward": 0.2184745910614729, "critic_loss": 0.3565698260515928, "actor_loss": -32.52725008583069, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00571608543396, "step": 85000}
{"episode_reward": 343.810287063539, "episode": 86.0, "batch_reward": 0.22056166036427022, "critic_loss": 0.3596167832016945, "actor_loss": -32.54807490539551, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.044914484024048, "step": 86000}
{"episode_reward": 423.4469921176313, "episode": 87.0, "batch_reward": 0.22403458601236342, "critic_loss": 0.3466102685779333, "actor_loss": -32.7150986251831, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.036063194274902, "step": 87000}
{"episode_reward": 490.13998656733565, "episode": 88.0, "batch_reward": 0.22668724802136422, "critic_loss": 0.3467728681713343, "actor_loss": -32.88885117912292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.051870822906494, "step": 88000}
{"episode_reward": 332.4707095682824, "episode": 89.0, "batch_reward": 0.22749821265041828, "critic_loss": 0.3522908456325531, "actor_loss": -33.01127298736572, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.036975145339966, "step": 89000}
{"episode_reward": 186.80421790288665, "episode": 90.0, "batch_reward": 0.22668485642969607, "critic_loss": 0.3483269311785698, "actor_loss": -32.01632298660278, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05045509338379, "step": 90000}
{"episode_reward": 294.85470346334495, "episode": 91.0, "batch_reward": 0.22663170474767685, "critic_loss": 0.35558011622726915, "actor_loss": -32.629643718719485, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.53518033027649, "step": 91000}
{"episode_reward": 44.75377897562907, "episode": 92.0, "batch_reward": 0.2252476126998663, "critic_loss": 0.37247395905852315, "actor_loss": -32.17027463150024, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.014095544815063, "step": 92000}
{"episode_reward": 489.84442111998027, "episode": 93.0, "batch_reward": 0.22850536531209945, "critic_loss": 0.3745967655479908, "actor_loss": -32.765691722869875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.043853759765625, "step": 93000}
{"episode_reward": 381.7631201570513, "episode": 94.0, "batch_reward": 0.23003146676719188, "critic_loss": 0.38205260103940963, "actor_loss": -32.35108562850952, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05861735343933, "step": 94000}
{"episode_reward": 136.87700659508266, "episode": 95.0, "batch_reward": 0.22829523825645448, "critic_loss": 0.37715632075071337, "actor_loss": -32.523216346740725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.000180959701538, "step": 95000}
{"episode_reward": 168.7240539056471, "episode": 96.0, "batch_reward": 0.22968466879427432, "critic_loss": 0.37851233646273613, "actor_loss": -32.564341299057006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.039660930633545, "step": 96000}
{"episode_reward": 472.1669222354482, "episode": 97.0, "batch_reward": 0.23073957592248917, "critic_loss": 0.3708063171207905, "actor_loss": -32.55257904815674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.050252676010132, "step": 97000}
{"episode_reward": 477.09650828010933, "episode": 98.0, "batch_reward": 0.23532984478771687, "critic_loss": 0.384019823461771, "actor_loss": -32.73222101593018, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.026659727096558, "step": 98000}
{"episode_reward": 474.75946361145384, "episode": 99.0, "batch_reward": 0.23740962779521943, "critic_loss": 0.40816809040308, "actor_loss": -33.04098145294189, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.057554721832275, "step": 99000}
{"episode_reward": 427.64301247566254, "episode": 100.0, "batch_reward": 0.2381033299267292, "critic_loss": 0.40824347859621046, "actor_loss": -33.08948177719116, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.062784910202026, "step": 100000}
{"episode_reward": 523.4531889366203, "episode": 101.0, "batch_reward": 0.24123159815371037, "critic_loss": 0.41311244398355484, "actor_loss": -32.920346843719486, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.557361125946045, "step": 101000}
{"episode_reward": 385.3439034651682, "episode": 102.0, "batch_reward": 0.24295848841965198, "critic_loss": 0.4142417488396168, "actor_loss": -33.53992976379394, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.052741289138794, "step": 102000}
{"episode_reward": 471.7982030286223, "episode": 103.0, "batch_reward": 0.24436475490033627, "critic_loss": 0.4420848296582699, "actor_loss": -33.25438933181763, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01382827758789, "step": 103000}
{"episode_reward": 466.61144978272057, "episode": 104.0, "batch_reward": 0.24712526206672192, "critic_loss": 0.4364326822906733, "actor_loss": -33.78274541091919, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.029279470443726, "step": 104000}
{"episode_reward": 466.6891828491521, "episode": 105.0, "batch_reward": 0.2491200882345438, "critic_loss": 0.4219860302209854, "actor_loss": -33.84686865615845, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.044689655303955, "step": 105000}
{"episode_reward": 482.80867339317155, "episode": 106.0, "batch_reward": 0.25044643847644327, "critic_loss": 0.40912385369837284, "actor_loss": -34.32581175231934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01087784767151, "step": 106000}
{"episode_reward": 409.4525001065344, "episode": 107.0, "batch_reward": 0.25186228685081, "critic_loss": 0.4077079489678144, "actor_loss": -34.26506941223145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.046549558639526, "step": 107000}
{"episode_reward": 210.7159565502094, "episode": 108.0, "batch_reward": 0.25181310296058657, "critic_loss": 0.4084645829200745, "actor_loss": -34.067753044128416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.032588481903076, "step": 108000}
{"episode_reward": 460.37252709028735, "episode": 109.0, "batch_reward": 0.2550137558281422, "critic_loss": 0.4085690434426069, "actor_loss": -34.501228183746335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.002136707305908, "step": 109000}
{"episode_reward": 470.7327725700359, "episode": 110.0, "batch_reward": 0.2563804278820753, "critic_loss": 0.3951355111896992, "actor_loss": -34.310679756164554, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02029299736023, "step": 110000}
{"episode_reward": 447.96950941418515, "episode": 111.0, "batch_reward": 0.2581746724843979, "critic_loss": 0.41013931199908255, "actor_loss": -34.50650320053101, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.501856565475464, "step": 111000}
{"episode_reward": 498.07427250612983, "episode": 112.0, "batch_reward": 0.25997791412472726, "critic_loss": 0.4116677063256502, "actor_loss": -35.09701509475708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05019974708557, "step": 112000}
{"episode_reward": 423.3776040136986, "episode": 113.0, "batch_reward": 0.26278901904821395, "critic_loss": 0.4307881644517183, "actor_loss": -34.600390625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.043993949890137, "step": 113000}
{"episode_reward": 478.76380036033044, "episode": 114.0, "batch_reward": 0.26431005336344243, "critic_loss": 0.4100567439198494, "actor_loss": -35.45002898025513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.030645847320557, "step": 114000}
{"episode_reward": 463.31238724033176, "episode": 115.0, "batch_reward": 0.26490323555469514, "critic_loss": 0.435047819763422, "actor_loss": -35.445811283111574, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.027864933013916, "step": 115000}
{"episode_reward": 522.3989226117972, "episode": 116.0, "batch_reward": 0.2666563398838043, "critic_loss": 0.4478362365961075, "actor_loss": -35.411638362884524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.033398628234863, "step": 116000}
{"episode_reward": 126.96320754023209, "episode": 117.0, "batch_reward": 0.2667029841691256, "critic_loss": 0.43537553276121616, "actor_loss": -35.39522842025757, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.046421766281128, "step": 117000}
{"episode_reward": 505.78823564205004, "episode": 118.0, "batch_reward": 0.26855404375493525, "critic_loss": 0.44739514565467836, "actor_loss": -35.38721013641357, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.03952980041504, "step": 118000}
{"episode_reward": 517.3962997100207, "episode": 119.0, "batch_reward": 0.27002715331315996, "critic_loss": 0.4444000812470913, "actor_loss": -35.451938663482665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.989289045333862, "step": 119000}
{"episode_reward": 568.0861158566623, "episode": 120.0, "batch_reward": 0.2729223857074976, "critic_loss": 0.43678687763214114, "actor_loss": -36.1760971069336, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.996115922927856, "step": 120000}
{"episode_reward": 506.7229838644582, "episode": 121.0, "batch_reward": 0.27610357038676736, "critic_loss": 0.4467686691880226, "actor_loss": -36.041851779937744, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.06307125091553, "step": 121000}
{"episode_reward": 496.53733121502955, "episode": 122.0, "batch_reward": 0.2778904385566711, "critic_loss": 0.47223213930428026, "actor_loss": -36.2668696975708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.76080322265625, "step": 122000}
{"episode_reward": 467.7762672390193, "episode": 123.0, "batch_reward": 0.27810861125588415, "critic_loss": 0.4545218161344528, "actor_loss": -36.53217278289795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.762747287750244, "step": 123000}
{"episode_reward": 493.0981528996188, "episode": 124.0, "batch_reward": 0.2806646862179041, "critic_loss": 0.4230567110478878, "actor_loss": -36.46321179962158, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.76579737663269, "step": 124000}
{"episode_reward": 523.7502000543069, "episode": 125.0, "batch_reward": 0.2818872973024845, "critic_loss": 0.44817391672730444, "actor_loss": -36.94089361572266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.734467029571533, "step": 125000}
{"episode_reward": 500.4874732515766, "episode": 126.0, "batch_reward": 0.28355592902004717, "critic_loss": 0.4377943695932627, "actor_loss": -36.880526458740235, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.78790855407715, "step": 126000}
{"episode_reward": 512.1108402588397, "episode": 127.0, "batch_reward": 0.2852022842168808, "critic_loss": 0.4510367977023125, "actor_loss": -36.70575396347046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.750056743621826, "step": 127000}
{"episode_reward": 547.8694902383825, "episode": 128.0, "batch_reward": 0.2871387251764536, "critic_loss": 0.43506662763655185, "actor_loss": -36.89159922409058, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.75119638442993, "step": 128000}
{"episode_reward": 508.9847147686843, "episode": 129.0, "batch_reward": 0.28933488138020036, "critic_loss": 0.42863426625728607, "actor_loss": -37.239518585205076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.777316331863403, "step": 129000}
{"episode_reward": 580.7111382006212, "episode": 130.0, "batch_reward": 0.29207182383537295, "critic_loss": 0.43732475993037223, "actor_loss": -37.121072448730466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.744179010391235, "step": 130000}
{"episode_reward": 525.7699210563442, "episode": 131.0, "batch_reward": 0.29339795717597006, "critic_loss": 0.4404620681852102, "actor_loss": -36.578992610931394, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.078245401382446, "step": 131000}
{"episode_reward": 440.1407720826975, "episode": 132.0, "batch_reward": 0.29414968779683115, "critic_loss": 0.4541965716779232, "actor_loss": -36.76903075027466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.748931169509888, "step": 132000}
{"episode_reward": 544.9009451527394, "episode": 133.0, "batch_reward": 0.29541077667474747, "critic_loss": 0.4104744988828897, "actor_loss": -37.73668141937256, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.733277082443237, "step": 133000}
{"episode_reward": 522.0289971016814, "episode": 134.0, "batch_reward": 0.29770413009822366, "critic_loss": 0.43219369582831857, "actor_loss": -37.855076610565185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.738399744033813, "step": 134000}
{"episode_reward": 506.593565202128, "episode": 135.0, "batch_reward": 0.2992110610604286, "critic_loss": 0.4412731232792139, "actor_loss": -38.02385472869873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.74970293045044, "step": 135000}
{"episode_reward": 459.05391543826, "episode": 136.0, "batch_reward": 0.29982236261665823, "critic_loss": 0.4537749648243189, "actor_loss": -37.902308853149414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.777397632598877, "step": 136000}
{"episode_reward": 534.708429764634, "episode": 137.0, "batch_reward": 0.30430458348989486, "critic_loss": 0.44438467305898666, "actor_loss": -38.25258746337891, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.74551820755005, "step": 137000}
{"episode_reward": 568.2214999673644, "episode": 138.0, "batch_reward": 0.30446216878294946, "critic_loss": 0.4569272235184908, "actor_loss": -37.412463497161866, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.750783681869507, "step": 138000}
{"episode_reward": 563.7032695710373, "episode": 139.0, "batch_reward": 0.30668314146995546, "critic_loss": 0.4346172980815172, "actor_loss": -37.539572372436524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.752995252609253, "step": 139000}
{"episode_reward": 544.1567864811739, "episode": 140.0, "batch_reward": 0.3078688033372164, "critic_loss": 0.4331173288226128, "actor_loss": -37.98317421340943, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.707650899887085, "step": 140000}
{"episode_reward": 542.4051262321221, "episode": 141.0, "batch_reward": 0.3091180065870285, "critic_loss": 0.46835896791517734, "actor_loss": -38.08068815612793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.077149868011475, "step": 141000}
{"episode_reward": 564.6699230568747, "episode": 142.0, "batch_reward": 0.31165549555420874, "critic_loss": 0.4396741140335798, "actor_loss": -38.499244667053226, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.765233039855957, "step": 142000}
{"episode_reward": 510.7121058741688, "episode": 143.0, "batch_reward": 0.31268679356575013, "critic_loss": 0.44944638119637964, "actor_loss": -39.129100662231444, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.74604892730713, "step": 143000}
{"episode_reward": 531.8946726238281, "episode": 144.0, "batch_reward": 0.31583863657712935, "critic_loss": 0.4951706955581903, "actor_loss": -39.07962335205078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.7389018535614, "step": 144000}
{"episode_reward": 573.3433693644936, "episode": 145.0, "batch_reward": 0.3171623770296574, "critic_loss": 0.49117533960938453, "actor_loss": -39.81452616882324, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.75886034965515, "step": 145000}
{"episode_reward": 545.5964016254864, "episode": 146.0, "batch_reward": 0.3175594130456448, "critic_loss": 0.4977970829904079, "actor_loss": -38.8825530166626, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.75529670715332, "step": 146000}
{"episode_reward": 377.92323696821063, "episode": 147.0, "batch_reward": 0.31864533087611197, "critic_loss": 0.5410240924060344, "actor_loss": -38.85499308013916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.73863124847412, "step": 147000}
{"episode_reward": 554.2213958122092, "episode": 148.0, "batch_reward": 0.31988372299075124, "critic_loss": 0.54572446128726, "actor_loss": -39.1797117805481, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.7027370929718, "step": 148000}
{"episode_reward": 542.5545831960246, "episode": 149.0, "batch_reward": 0.32042205581068994, "critic_loss": 0.5118751529157162, "actor_loss": -39.19622562026978, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.7737557888031, "step": 149000}
{"episode_reward": 524.9451773732368, "episode": 150.0, "batch_reward": 0.3225724345445633, "critic_loss": 0.5314388918429613, "actor_loss": -39.29408935165405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
