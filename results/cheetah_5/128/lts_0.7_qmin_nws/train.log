{"episode_reward": 0.0, "episode": 1.0, "duration": 17.614274978637695, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.5045714378356934, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.2600950398129914, "critic_loss": 0.10567240401662739, "actor_loss": -30.333706859435114, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 59.93633246421814, "step": 3000}
{"episode_reward": 12.787087856271192, "episode": 4.0, "batch_reward": 0.16341886243224144, "critic_loss": 0.0534846659116447, "actor_loss": -19.547582462310793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.79239058494568, "step": 4000}
{"episode_reward": 2.5442579402220122, "episode": 5.0, "batch_reward": 0.12742407856136562, "critic_loss": 0.04587506153434515, "actor_loss": -20.96086036968231, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.822066068649292, "step": 5000}
{"episode_reward": 6.531283068851252, "episode": 6.0, "batch_reward": 0.10598789428174496, "critic_loss": 0.04675163091160357, "actor_loss": -20.939069625854493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.776339530944824, "step": 6000}
{"episode_reward": 13.694173054035817, "episode": 7.0, "batch_reward": 0.0923645351678133, "critic_loss": 0.043725724862888456, "actor_loss": -21.812657988548278, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.790690183639526, "step": 7000}
{"episode_reward": 35.10037927145182, "episode": 8.0, "batch_reward": 0.0854034218788147, "critic_loss": 0.044867173317819836, "actor_loss": -20.506673630714417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.811227560043335, "step": 8000}
{"episode_reward": 32.83666175316856, "episode": 9.0, "batch_reward": 0.07952152252569794, "critic_loss": 0.04438401391170919, "actor_loss": -20.137387972831725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.77315068244934, "step": 9000}
{"episode_reward": 39.86417033814743, "episode": 10.0, "batch_reward": 0.07611883928254247, "critic_loss": 0.03468071398884058, "actor_loss": -22.160842666625978, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.786386251449585, "step": 10000}
{"episode_reward": 46.005951143718484, "episode": 11.0, "batch_reward": 0.07128290303051471, "critic_loss": 0.03480464354809373, "actor_loss": -20.892047149658204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.42911171913147, "step": 11000}
{"episode_reward": 26.095023859820948, "episode": 12.0, "batch_reward": 0.06851750273630022, "critic_loss": 0.032422369500622154, "actor_loss": -21.839211346626282, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.784578561782837, "step": 12000}
{"episode_reward": 29.699503944944727, "episode": 13.0, "batch_reward": 0.06524223086051643, "critic_loss": 0.029611204280517996, "actor_loss": -22.44214152431488, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.814438819885254, "step": 13000}
{"episode_reward": 38.605406430240905, "episode": 14.0, "batch_reward": 0.063840993527323, "critic_loss": 0.02833417749684304, "actor_loss": -22.232548617362976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.823718547821045, "step": 14000}
{"episode_reward": 50.72178193491102, "episode": 15.0, "batch_reward": 0.06340755854919553, "critic_loss": 0.02473749014083296, "actor_loss": -22.382647416591645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.815685033798218, "step": 15000}
{"episode_reward": 58.36562560291562, "episode": 16.0, "batch_reward": 0.06334392084740102, "critic_loss": 0.03257517340406776, "actor_loss": -21.70538480091095, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.82558274269104, "step": 16000}
{"episode_reward": 66.10567827926266, "episode": 17.0, "batch_reward": 0.06288154781423509, "critic_loss": 0.022236832896713167, "actor_loss": -22.43251052904129, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.800053596496582, "step": 17000}
{"episode_reward": 68.08659067997804, "episode": 18.0, "batch_reward": 0.06459261947497726, "critic_loss": 0.0234007362825796, "actor_loss": -22.20751878643036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.814768075942993, "step": 18000}
{"episode_reward": 101.38306035195608, "episode": 19.0, "batch_reward": 0.06760344427824021, "critic_loss": 0.033405444103293123, "actor_loss": -23.06937572145462, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.807178735733032, "step": 19000}
{"episode_reward": 160.55250885336721, "episode": 20.0, "batch_reward": 0.07290168457850814, "critic_loss": 0.05078484277427196, "actor_loss": -23.37307335305214, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.800374507904053, "step": 20000}
{"episode_reward": 174.17809914668476, "episode": 21.0, "batch_reward": 0.07828317176923155, "critic_loss": 0.06143479919061065, "actor_loss": -22.06166026031971, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.36150026321411, "step": 21000}
{"episode_reward": 186.21906849761166, "episode": 22.0, "batch_reward": 0.08324527681618929, "critic_loss": 0.08323206845112145, "actor_loss": -24.570326874136924, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.79894232749939, "step": 22000}
{"episode_reward": 177.6719788481401, "episode": 23.0, "batch_reward": 0.08788158031180501, "critic_loss": 0.0843414984755218, "actor_loss": -24.82698208644986, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.82503318786621, "step": 23000}
{"episode_reward": 191.0773950021326, "episode": 24.0, "batch_reward": 0.09198881878331304, "critic_loss": 0.09499294629320502, "actor_loss": -22.934090250886978, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.80689573287964, "step": 24000}
{"episode_reward": 216.56374689313998, "episode": 25.0, "batch_reward": 0.09720469224452973, "critic_loss": 0.18203565380722284, "actor_loss": -25.29765687710792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.778473377227783, "step": 25000}
{"episode_reward": 198.70058446354346, "episode": 26.0, "batch_reward": 0.09843551860004664, "critic_loss": 0.17298367363587022, "actor_loss": -23.54973664712906, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.835118770599365, "step": 26000}
{"episode_reward": 24.666473236179428, "episode": 27.0, "batch_reward": 0.0986167789325118, "critic_loss": 0.13811006243526935, "actor_loss": -24.071818688720466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.76991033554077, "step": 27000}
{"episode_reward": 178.18672945187603, "episode": 28.0, "batch_reward": 0.10225305535644293, "critic_loss": 0.17503441490978003, "actor_loss": -24.009446701705457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.10501456260681, "step": 28000}
{"episode_reward": 268.78109327669944, "episode": 29.0, "batch_reward": 0.10694563440233469, "critic_loss": 0.20687605234980583, "actor_loss": -24.66864737522602, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.797639846801758, "step": 29000}
{"episode_reward": 166.57433754696882, "episode": 30.0, "batch_reward": 0.10852608191221952, "critic_loss": 0.20999422132968903, "actor_loss": -23.82538084858656, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.772029876708984, "step": 30000}
{"episode_reward": 94.53420536516013, "episode": 31.0, "batch_reward": 0.11006641391664744, "critic_loss": 0.20008175604790449, "actor_loss": -24.366078679800033, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.28411817550659, "step": 31000}
{"episode_reward": 239.03503991685182, "episode": 32.0, "batch_reward": 0.11361144070327282, "critic_loss": 0.20403569680452346, "actor_loss": -24.344330106496813, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.743276834487915, "step": 32000}
{"episode_reward": 267.23098001424444, "episode": 33.0, "batch_reward": 0.117980110488832, "critic_loss": 0.22241902259737253, "actor_loss": -25.223955500602724, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.809314250946045, "step": 33000}
{"episode_reward": 194.8575438581485, "episode": 34.0, "batch_reward": 0.12092432191967964, "critic_loss": 0.24482276536524294, "actor_loss": -25.7843885884285, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.75314450263977, "step": 34000}
{"episode_reward": 253.49650409116182, "episode": 35.0, "batch_reward": 0.12502685279399156, "critic_loss": 0.2233441262319684, "actor_loss": -25.329773488998413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.805047750473022, "step": 35000}
{"episode_reward": 324.56495374033454, "episode": 36.0, "batch_reward": 0.13123348312079908, "critic_loss": 0.22837389592081309, "actor_loss": -26.185273339271546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.807137966156006, "step": 36000}
{"episode_reward": 320.3877202655599, "episode": 37.0, "batch_reward": 0.13613322792202234, "critic_loss": 0.2263274879604578, "actor_loss": -26.035916870117187, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.768339157104492, "step": 37000}
{"episode_reward": 320.4315833055024, "episode": 38.0, "batch_reward": 0.14013484312593938, "critic_loss": 0.22488610667735337, "actor_loss": -26.951150438308716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.78013825416565, "step": 38000}
{"episode_reward": 230.20895005608944, "episode": 39.0, "batch_reward": 0.14249176988750697, "critic_loss": 0.23778884593397379, "actor_loss": -27.395470950126647, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.811371088027954, "step": 39000}
{"episode_reward": 199.54529764546606, "episode": 40.0, "batch_reward": 0.14573439843207597, "critic_loss": 0.24508139948546886, "actor_loss": -28.219053402900695, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.7540180683136, "step": 40000}
{"episode_reward": 357.86646615675977, "episode": 41.0, "batch_reward": 0.14931343164294958, "critic_loss": 0.2470613108575344, "actor_loss": -27.87362779045105, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.26638889312744, "step": 41000}
{"episode_reward": 314.9976871846367, "episode": 42.0, "batch_reward": 0.15447575071454048, "critic_loss": 0.2477621586024761, "actor_loss": -28.21460857009888, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.78165626525879, "step": 42000}
{"episode_reward": 334.0008011771296, "episode": 43.0, "batch_reward": 0.15878659473359585, "critic_loss": 0.25260324247181415, "actor_loss": -29.149182250976562, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.784147262573242, "step": 43000}
{"episode_reward": 365.88973739690294, "episode": 44.0, "batch_reward": 0.1630888951122761, "critic_loss": 0.2532018354833126, "actor_loss": -28.59686344909668, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.78286385536194, "step": 44000}
{"episode_reward": 359.8454820657151, "episode": 45.0, "batch_reward": 0.16524386440217495, "critic_loss": 0.25541145145893096, "actor_loss": -28.04276993751526, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.78434467315674, "step": 45000}
{"episode_reward": 58.406662065951394, "episode": 46.0, "batch_reward": 0.16574857388436795, "critic_loss": 0.250860082603991, "actor_loss": -28.548207763671876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.766592502593994, "step": 46000}
{"episode_reward": 355.31095333928556, "episode": 47.0, "batch_reward": 0.16916334730386734, "critic_loss": 0.2661531447991729, "actor_loss": -28.759930698394776, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.79900550842285, "step": 47000}
{"episode_reward": 382.06236691348533, "episode": 48.0, "batch_reward": 0.17321650563180446, "critic_loss": 0.293288125038147, "actor_loss": -28.802112115859984, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.795919179916382, "step": 48000}
{"episode_reward": 339.27531173250657, "episode": 49.0, "batch_reward": 0.17821508483588697, "critic_loss": 0.34993973526358607, "actor_loss": -29.640368467330934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.792444229125977, "step": 49000}
{"episode_reward": 394.1375887825868, "episode": 50.0, "batch_reward": 0.17989182299375533, "critic_loss": 0.33180827848613265, "actor_loss": -29.301552993774415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.758089542388916, "step": 50000}
{"episode_reward": 131.53333478366994, "episode": 51.0, "batch_reward": 0.17834653013944626, "critic_loss": 0.36045915944874285, "actor_loss": -30.343529596328736, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.41871643066406, "step": 51000}
{"episode_reward": 96.84892467692737, "episode": 52.0, "batch_reward": 0.17902614329755306, "critic_loss": 0.35788644501566885, "actor_loss": -28.982274496078492, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.795397996902466, "step": 52000}
{"episode_reward": 219.77075606488785, "episode": 53.0, "batch_reward": 0.18033665174245833, "critic_loss": 0.36318915502727034, "actor_loss": -29.417828645706177, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.794981241226196, "step": 53000}
{"episode_reward": 385.1484287723823, "episode": 54.0, "batch_reward": 0.18319354340434074, "critic_loss": 0.3423164392262697, "actor_loss": -30.01469791984558, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.836222648620605, "step": 54000}
{"episode_reward": 377.82379568526557, "episode": 55.0, "batch_reward": 0.187983504652977, "critic_loss": 0.3535377696156502, "actor_loss": -30.36028778076172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.13456392288208, "step": 55000}
{"episode_reward": 449.8442980538244, "episode": 56.0, "batch_reward": 0.19194586156308652, "critic_loss": 0.3752199877649546, "actor_loss": -30.62220104217529, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.807650566101074, "step": 56000}
{"episode_reward": 395.1205270256289, "episode": 57.0, "batch_reward": 0.19614877560734748, "critic_loss": 0.3848270422071218, "actor_loss": -30.481252161026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.775386571884155, "step": 57000}
{"episode_reward": 495.2034096580235, "episode": 58.0, "batch_reward": 0.1995441395789385, "critic_loss": 0.3648969580680132, "actor_loss": -30.899436195373536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.74577236175537, "step": 58000}
{"episode_reward": 137.57010444848885, "episode": 59.0, "batch_reward": 0.2013519058972597, "critic_loss": 0.4384027300029993, "actor_loss": -31.723871959686278, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.788678884506226, "step": 59000}
{"episode_reward": 406.5447317855893, "episode": 60.0, "batch_reward": 0.20268190456926824, "critic_loss": 0.4212889909744263, "actor_loss": -31.127032579421996, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.83132576942444, "step": 60000}
{"episode_reward": 164.04698348172099, "episode": 61.0, "batch_reward": 0.2016066770553589, "critic_loss": 0.4262716228067875, "actor_loss": -30.358641899108886, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.37882089614868, "step": 61000}
{"episode_reward": 259.06868501876716, "episode": 62.0, "batch_reward": 0.20275050815939905, "critic_loss": 0.44944820713996886, "actor_loss": -30.446808055877685, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.794222831726074, "step": 62000}
{"episode_reward": 153.53719558948455, "episode": 63.0, "batch_reward": 0.20397469259798526, "critic_loss": 0.4197098007798195, "actor_loss": -30.49271415710449, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.79481601715088, "step": 63000}
{"episode_reward": 510.0779283762052, "episode": 64.0, "batch_reward": 0.20696818548440934, "critic_loss": 0.4483557619601488, "actor_loss": -31.298398485183714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.83061170578003, "step": 64000}
{"episode_reward": 195.85106315521293, "episode": 65.0, "batch_reward": 0.2086072684377432, "critic_loss": 0.4768701183348894, "actor_loss": -30.96401634979248, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.766760110855103, "step": 65000}
{"episode_reward": 401.765249445162, "episode": 66.0, "batch_reward": 0.20842648173868655, "critic_loss": 0.5110455296337605, "actor_loss": -30.997767320632935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.807875394821167, "step": 66000}
{"episode_reward": 78.69988115386526, "episode": 67.0, "batch_reward": 0.20833465778827667, "critic_loss": 0.4848698749393225, "actor_loss": -30.629133331298828, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.82647395133972, "step": 67000}
{"episode_reward": 455.9492709012758, "episode": 68.0, "batch_reward": 0.21326390251517297, "critic_loss": 0.533237625837326, "actor_loss": -31.405023509979248, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.781891345977783, "step": 68000}
{"episode_reward": 410.4748242329727, "episode": 69.0, "batch_reward": 0.21594933623075485, "critic_loss": 0.4862586690783501, "actor_loss": -31.052291732788085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.827192783355713, "step": 69000}
{"episode_reward": 435.7183341687628, "episode": 70.0, "batch_reward": 0.21814150080084801, "critic_loss": 0.5254912476539612, "actor_loss": -31.890123458862305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.787588596343994, "step": 70000}
{"episode_reward": 363.5306652948528, "episode": 71.0, "batch_reward": 0.22195673707127572, "critic_loss": 0.5198015659600497, "actor_loss": -31.913124546051026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.34272003173828, "step": 71000}
{"episode_reward": 535.0916694362055, "episode": 72.0, "batch_reward": 0.2240629872828722, "critic_loss": 0.5877474770396948, "actor_loss": -31.88120920944214, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.795276403427124, "step": 72000}
{"episode_reward": 379.10389909416085, "episode": 73.0, "batch_reward": 0.22666783025860787, "critic_loss": 0.5659453969597816, "actor_loss": -32.18256932449341, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.814018964767456, "step": 73000}
{"episode_reward": 263.9262074663791, "episode": 74.0, "batch_reward": 0.22659548585116862, "critic_loss": 0.5511548758894205, "actor_loss": -31.55069324874878, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.794638633728027, "step": 74000}
{"episode_reward": 386.15926236708873, "episode": 75.0, "batch_reward": 0.22983467806875707, "critic_loss": 0.5641587577462196, "actor_loss": -33.08657447052002, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.793424367904663, "step": 75000}
{"episode_reward": 408.9480222953966, "episode": 76.0, "batch_reward": 0.2316481238901615, "critic_loss": 0.5344821605831385, "actor_loss": -32.66958214569092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.783162593841553, "step": 76000}
{"episode_reward": 412.89360294952405, "episode": 77.0, "batch_reward": 0.23422613967955114, "critic_loss": 0.5851012863665819, "actor_loss": -32.89697729110718, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.801034927368164, "step": 77000}
{"episode_reward": 449.7859885937382, "episode": 78.0, "batch_reward": 0.23667461162805556, "critic_loss": 0.6152006293237209, "actor_loss": -32.79059981155395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.78182816505432, "step": 78000}
{"episode_reward": 223.27653736762684, "episode": 79.0, "batch_reward": 0.23630737236142157, "critic_loss": 0.6262272132039071, "actor_loss": -32.99753530883789, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.80945611000061, "step": 79000}
{"episode_reward": 92.97156206520707, "episode": 80.0, "batch_reward": 0.23561339473724366, "critic_loss": 0.6279475756138563, "actor_loss": -33.00069301223755, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.789111137390137, "step": 80000}
{"episode_reward": 458.7668755668849, "episode": 81.0, "batch_reward": 0.23732176248729228, "critic_loss": 0.5391578551530838, "actor_loss": -32.791494022369385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.3391695022583, "step": 81000}
{"episode_reward": 190.5804792219739, "episode": 82.0, "batch_reward": 0.2368868710398674, "critic_loss": 0.5061142351031304, "actor_loss": -32.54669987487793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.81284761428833, "step": 82000}
{"episode_reward": 439.2616772974638, "episode": 83.0, "batch_reward": 0.2398391020298004, "critic_loss": 0.5510790140032769, "actor_loss": -33.13960860824585, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.784616947174072, "step": 83000}
{"episode_reward": 291.1279767239944, "episode": 84.0, "batch_reward": 0.23870264388620854, "critic_loss": 0.5538413144648076, "actor_loss": -32.84788481903076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.805814266204834, "step": 84000}
{"episode_reward": 199.8551682706498, "episode": 85.0, "batch_reward": 0.23916212724149227, "critic_loss": 0.5796368424147368, "actor_loss": -33.04464027404785, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.78326916694641, "step": 85000}
{"episode_reward": 442.0908119796987, "episode": 86.0, "batch_reward": 0.24205000984668731, "critic_loss": 0.5493127126842737, "actor_loss": -32.944283988952634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.758949995040894, "step": 86000}
{"episode_reward": 387.1210888504031, "episode": 87.0, "batch_reward": 0.24394676241278648, "critic_loss": 0.5736364602148533, "actor_loss": -32.78510964202881, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.802180767059326, "step": 87000}
{"episode_reward": 405.2088230037893, "episode": 88.0, "batch_reward": 0.24546857142448425, "critic_loss": 0.5099065579175949, "actor_loss": -32.90852165603638, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.81233835220337, "step": 88000}
{"episode_reward": 373.6160425368959, "episode": 89.0, "batch_reward": 0.24669599606096745, "critic_loss": 0.5347999882698059, "actor_loss": -33.19977076339722, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.802196979522705, "step": 89000}
{"episode_reward": 168.33911098525493, "episode": 90.0, "batch_reward": 0.24545292088389398, "critic_loss": 0.5718169052749872, "actor_loss": -32.517565567016604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.795060873031616, "step": 90000}
{"episode_reward": 162.93736324424, "episode": 91.0, "batch_reward": 0.24595050932466983, "critic_loss": 0.5791645479649306, "actor_loss": -33.40245593261719, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.31451439857483, "step": 91000}
{"episode_reward": 484.7659215335661, "episode": 92.0, "batch_reward": 0.24811497025191784, "critic_loss": 0.5663510531336069, "actor_loss": -32.76169928741455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.77995252609253, "step": 92000}
{"episode_reward": 454.64360216980725, "episode": 93.0, "batch_reward": 0.25033650858700274, "critic_loss": 0.544804553091526, "actor_loss": -33.23244264984131, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.774811506271362, "step": 93000}
{"episode_reward": 378.22063582646933, "episode": 94.0, "batch_reward": 0.252357587903738, "critic_loss": 0.5935145802497864, "actor_loss": -32.91592029953003, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.803659439086914, "step": 94000}
{"episode_reward": 356.1868079842939, "episode": 95.0, "batch_reward": 0.2530854415297508, "critic_loss": 0.5526080068349838, "actor_loss": -33.44407677078247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.81452178955078, "step": 95000}
{"episode_reward": 541.0108608138324, "episode": 96.0, "batch_reward": 0.25619965587556365, "critic_loss": 0.5729134348332882, "actor_loss": -33.48897652053833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.768408060073853, "step": 96000}
{"episode_reward": 536.250656349306, "episode": 97.0, "batch_reward": 0.2586174900829792, "critic_loss": 0.5173332898318768, "actor_loss": -33.80025919723511, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.7884738445282, "step": 97000}
{"episode_reward": 498.9882194831514, "episode": 98.0, "batch_reward": 0.2620964406132698, "critic_loss": 0.5513743070065975, "actor_loss": -33.93309756469726, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.79685616493225, "step": 98000}
{"episode_reward": 422.43468064903, "episode": 99.0, "batch_reward": 0.2625931954681873, "critic_loss": 0.49958247359097, "actor_loss": -34.069551498413084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.780162572860718, "step": 99000}
{"episode_reward": 470.2646283138723, "episode": 100.0, "batch_reward": 0.2654428565055132, "critic_loss": 0.5389310196042061, "actor_loss": -34.40324848175049, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.793729543685913, "step": 100000}
{"episode_reward": 493.94963473336645, "episode": 101.0, "batch_reward": 0.26723467753827573, "critic_loss": 0.5462907170802355, "actor_loss": -34.03910881042481, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.317729473114014, "step": 101000}
{"episode_reward": 355.5337898071281, "episode": 102.0, "batch_reward": 0.26760784739255905, "critic_loss": 0.550594142794609, "actor_loss": -34.801013137817385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.79135775566101, "step": 102000}
{"episode_reward": 280.4577186750353, "episode": 103.0, "batch_reward": 0.2689301759004593, "critic_loss": 0.5446841613799334, "actor_loss": -34.17285837173462, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.8106050491333, "step": 103000}
{"episode_reward": 561.4020969560495, "episode": 104.0, "batch_reward": 0.2726560672968626, "critic_loss": 0.5809920245707035, "actor_loss": -35.14426061248779, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.778682947158813, "step": 104000}
{"episode_reward": 541.3660754651918, "episode": 105.0, "batch_reward": 0.27344833792746065, "critic_loss": 0.5686622805744409, "actor_loss": -34.363908393859866, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.80045795440674, "step": 105000}
{"episode_reward": 502.0997331159241, "episode": 106.0, "batch_reward": 0.2760800974965095, "critic_loss": 0.5060076011568307, "actor_loss": -35.08942662811279, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.776233196258545, "step": 106000}
{"episode_reward": 426.1392487100061, "episode": 107.0, "batch_reward": 0.27691774669289587, "critic_loss": 0.5023259968459606, "actor_loss": -35.12130182647705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.808369636535645, "step": 107000}
{"episode_reward": 259.0492937043808, "episode": 108.0, "batch_reward": 0.276570623010397, "critic_loss": 0.46957688382267954, "actor_loss": -34.87578184890747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.809799909591675, "step": 108000}
{"episode_reward": 211.081074695619, "episode": 109.0, "batch_reward": 0.27732185381650926, "critic_loss": 0.4910185974985361, "actor_loss": -34.91785494995117, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.76214599609375, "step": 109000}
{"episode_reward": 541.2518595345886, "episode": 110.0, "batch_reward": 0.2790997145473957, "critic_loss": 0.5087067556083202, "actor_loss": -35.09268217086792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.813106060028076, "step": 110000}
{"episode_reward": 542.1188920953799, "episode": 111.0, "batch_reward": 0.2817005452811718, "critic_loss": 0.4679090108275413, "actor_loss": -34.787481300354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.28454804420471, "step": 111000}
{"episode_reward": 534.789018624019, "episode": 112.0, "batch_reward": 0.28332957519590857, "critic_loss": 0.535208037763834, "actor_loss": -35.61087180328369, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.808024168014526, "step": 112000}
{"episode_reward": 587.9560338100066, "episode": 113.0, "batch_reward": 0.2874529257416725, "critic_loss": 0.4830933967381716, "actor_loss": -34.94607660675049, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.873080730438232, "step": 113000}
{"episode_reward": 497.0255796227764, "episode": 114.0, "batch_reward": 0.28911677886545656, "critic_loss": 0.49890246169269087, "actor_loss": -35.72400716781616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.819217443466187, "step": 114000}
{"episode_reward": 529.2977768975887, "episode": 115.0, "batch_reward": 0.2903477948755026, "critic_loss": 0.5066185995489358, "actor_loss": -36.20977202987671, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.829046964645386, "step": 115000}
{"episode_reward": 527.58654426362, "episode": 116.0, "batch_reward": 0.2927932527810335, "critic_loss": 0.5227525620609522, "actor_loss": -36.09053623962402, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.829715490341187, "step": 116000}
{"episode_reward": 514.2368141844888, "episode": 117.0, "batch_reward": 0.29411170083284377, "critic_loss": 0.5545429884940386, "actor_loss": -36.14107995986939, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.821698427200317, "step": 117000}
{"episode_reward": 492.92955935219635, "episode": 118.0, "batch_reward": 0.2962978589385748, "critic_loss": 0.5303056369572878, "actor_loss": -36.249701026916505, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.82963752746582, "step": 118000}
{"episode_reward": 609.6228867151452, "episode": 119.0, "batch_reward": 0.2989018528163433, "critic_loss": 0.5053339278101922, "actor_loss": -36.523326667785646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.829710483551025, "step": 119000}
{"episode_reward": 528.2368704584494, "episode": 120.0, "batch_reward": 0.3000232131779194, "critic_loss": 0.4841894282847643, "actor_loss": -36.81420574951172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.84157419204712, "step": 120000}
{"episode_reward": 521.9846517678646, "episode": 121.0, "batch_reward": 0.30403285136818886, "critic_loss": 0.5045735124945641, "actor_loss": -36.987718299865726, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.668031454086304, "step": 121000}
{"episode_reward": 508.79703865762025, "episode": 122.0, "batch_reward": 0.3049178328067064, "critic_loss": 0.5075605636835099, "actor_loss": -37.470398250579834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.83955955505371, "step": 122000}
{"episode_reward": 608.1682351614405, "episode": 123.0, "batch_reward": 0.3065187462121248, "critic_loss": 0.5177278727144002, "actor_loss": -37.62074231338501, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.9333233833313, "step": 123000}
{"episode_reward": 583.0790156690103, "episode": 124.0, "batch_reward": 0.30808802843093874, "critic_loss": 0.5268598367869854, "actor_loss": -37.5362886428833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.115254402160645, "step": 124000}
{"episode_reward": 531.0166510628958, "episode": 125.0, "batch_reward": 0.31115367372334, "critic_loss": 0.5415161049365997, "actor_loss": -37.913173393249515, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.82156729698181, "step": 125000}
{"episode_reward": 568.2063924027831, "episode": 126.0, "batch_reward": 0.3118340834975243, "critic_loss": 0.5473321519494057, "actor_loss": -38.2439094657898, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.82881212234497, "step": 126000}
{"episode_reward": 461.0332250577164, "episode": 127.0, "batch_reward": 0.3138095874786377, "critic_loss": 0.5129508633166552, "actor_loss": -37.74877061462402, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.826913595199585, "step": 127000}
{"episode_reward": 567.2081936868883, "episode": 128.0, "batch_reward": 0.31635092534124853, "critic_loss": 0.540136924535036, "actor_loss": -37.993107173919675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.829362154006958, "step": 128000}
{"episode_reward": 552.5371953365025, "episode": 129.0, "batch_reward": 0.31803672221302987, "critic_loss": 0.5262898553162814, "actor_loss": -38.281708560943606, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.83650302886963, "step": 129000}
{"episode_reward": 521.2776585677133, "episode": 130.0, "batch_reward": 0.3195714275538921, "critic_loss": 0.5067044027149677, "actor_loss": -38.41615266418457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.835633993148804, "step": 130000}
{"episode_reward": 543.8738089407091, "episode": 131.0, "batch_reward": 0.3202833639085293, "critic_loss": 0.5183043433278799, "actor_loss": -37.56457795333862, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.680418968200684, "step": 131000}
{"episode_reward": 521.9506907255609, "episode": 132.0, "batch_reward": 0.3220635356009007, "critic_loss": 0.4989309995472431, "actor_loss": -38.193274715423584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.858219861984253, "step": 132000}
{"episode_reward": 509.41353169967994, "episode": 133.0, "batch_reward": 0.32286311109364035, "critic_loss": 0.5031017819941044, "actor_loss": -38.72348722457886, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.841691493988037, "step": 133000}
{"episode_reward": 588.347938874449, "episode": 134.0, "batch_reward": 0.3245983831882477, "critic_loss": 0.5118646082133055, "actor_loss": -38.75717304611206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.77885103225708, "step": 134000}
{"episode_reward": 219.59252228991835, "episode": 135.0, "batch_reward": 0.32589502513408664, "critic_loss": 0.4900057488679886, "actor_loss": -38.96792882919311, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.823306798934937, "step": 135000}
{"episode_reward": 591.1081910777673, "episode": 136.0, "batch_reward": 0.3264964897632599, "critic_loss": 0.505079069301486, "actor_loss": -39.09187937164307, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.794087171554565, "step": 136000}
{"episode_reward": 449.1437291751791, "episode": 137.0, "batch_reward": 0.32910197111964223, "critic_loss": 0.5074018363207579, "actor_loss": -39.18914443588257, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.787986278533936, "step": 137000}
{"episode_reward": 544.9645207105218, "episode": 138.0, "batch_reward": 0.329543212890625, "critic_loss": 0.5208355747759342, "actor_loss": -38.46286939620972, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.84649968147278, "step": 138000}
{"episode_reward": 518.4901524779473, "episode": 139.0, "batch_reward": 0.33030993250012397, "critic_loss": 0.5454118460565806, "actor_loss": -38.2775026512146, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.81792950630188, "step": 139000}
{"episode_reward": 220.579155049699, "episode": 140.0, "batch_reward": 0.3300709598958492, "critic_loss": 0.5509206009656191, "actor_loss": -38.34874753952026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.786521911621094, "step": 140000}
{"episode_reward": 533.8003135699868, "episode": 141.0, "batch_reward": 0.33185441491007805, "critic_loss": 0.5122812180072069, "actor_loss": -39.041374546051024, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.37038993835449, "step": 141000}
{"episode_reward": 570.7087605035889, "episode": 142.0, "batch_reward": 0.3335354208946228, "critic_loss": 0.5339334386587143, "actor_loss": -39.171513530731204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.792603254318237, "step": 142000}
{"episode_reward": 571.9585362010223, "episode": 143.0, "batch_reward": 0.3354510481059551, "critic_loss": 0.5355146176069975, "actor_loss": -39.81837995147705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.80909562110901, "step": 143000}
{"episode_reward": 587.6193854881969, "episode": 144.0, "batch_reward": 0.33764952439069745, "critic_loss": 0.5422020771354437, "actor_loss": -39.598000606536864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.802008152008057, "step": 144000}
{"episode_reward": 533.491605902481, "episode": 145.0, "batch_reward": 0.3385239957869053, "critic_loss": 0.5201506836563349, "actor_loss": -40.35115218734741, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.778520822525024, "step": 145000}
{"episode_reward": 590.3010433725372, "episode": 146.0, "batch_reward": 0.3391384002566338, "critic_loss": 0.5382038310170174, "actor_loss": -39.36221709823609, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.799593210220337, "step": 146000}
{"episode_reward": 586.4265781216518, "episode": 147.0, "batch_reward": 0.341728986620903, "critic_loss": 0.5149136403799057, "actor_loss": -39.63074115371704, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.79078459739685, "step": 147000}
{"episode_reward": 587.9417735452384, "episode": 148.0, "batch_reward": 0.34387818092107775, "critic_loss": 0.4951761396676302, "actor_loss": -40.15118062591553, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.79927134513855, "step": 148000}
{"episode_reward": 545.3566124093963, "episode": 149.0, "batch_reward": 0.3440148985981941, "critic_loss": 0.504451205149293, "actor_loss": -40.25814334487915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.798452377319336, "step": 149000}
{"episode_reward": 597.4078837949921, "episode": 150.0, "batch_reward": 0.346766014456749, "critic_loss": 0.5322980527877808, "actor_loss": -40.27441764450073, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
