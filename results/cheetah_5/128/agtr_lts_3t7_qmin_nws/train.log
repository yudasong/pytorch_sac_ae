{"episode_reward": 0.0, "episode": 1.0, "duration": 12.689177751541138, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.0191357135772705, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.2644040671019762, "critic_loss": 0.12868033026920514, "actor_loss": -38.94491615929619, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 71.84083700180054, "step": 3000}
{"episode_reward": 53.71508840795001, "episode": 4.0, "batch_reward": 0.17560494283586742, "critic_loss": 0.05600161468051374, "actor_loss": -26.97202285194397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.466404914855957, "step": 4000}
{"episode_reward": 7.243639062384672, "episode": 5.0, "batch_reward": 0.139466269351542, "critic_loss": 0.048141682358458636, "actor_loss": -25.91756735610962, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.688373804092407, "step": 5000}
{"episode_reward": 34.11539840044658, "episode": 6.0, "batch_reward": 0.1203805756047368, "critic_loss": 0.06447794891893864, "actor_loss": -26.030289766311647, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.56954526901245, "step": 6000}
{"episode_reward": 30.9805191807044, "episode": 7.0, "batch_reward": 0.10693638259917497, "critic_loss": 0.06925147729367018, "actor_loss": -27.046234842300414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.797905445098877, "step": 7000}
{"episode_reward": 36.78367912181081, "episode": 8.0, "batch_reward": 0.09667804814130068, "critic_loss": 0.04871037016250193, "actor_loss": -23.952632568359373, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.037754774093628, "step": 8000}
{"episode_reward": 15.410181916773023, "episode": 9.0, "batch_reward": 0.08778201956301927, "critic_loss": 0.044033011300489304, "actor_loss": -25.167370727539062, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.772687196731567, "step": 9000}
{"episode_reward": 31.05402074596626, "episode": 10.0, "batch_reward": 0.08296074991673232, "critic_loss": 0.042811102649196985, "actor_loss": -23.159920320510864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.7160165309906, "step": 10000}
{"episode_reward": 49.035804077447885, "episode": 11.0, "batch_reward": 0.07987178841233253, "critic_loss": 0.04366489807330072, "actor_loss": -24.23204606819153, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 33.9108452796936, "step": 11000}
{"episode_reward": 62.75121134655383, "episode": 12.0, "batch_reward": 0.07904905657470226, "critic_loss": 0.0375328487418592, "actor_loss": -22.308879132270814, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.932729721069336, "step": 12000}
{"episode_reward": 56.310636583038736, "episode": 13.0, "batch_reward": 0.07613702861592174, "critic_loss": 0.03599654284864664, "actor_loss": -22.265851189613343, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.931307554244995, "step": 13000}
{"episode_reward": 40.437967394340205, "episode": 14.0, "batch_reward": 0.0741552730947733, "critic_loss": 0.03260237746406346, "actor_loss": -20.07820263671875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.156202793121338, "step": 14000}
{"episode_reward": 50.7991501208946, "episode": 15.0, "batch_reward": 0.07360802099853754, "critic_loss": 0.0319584442358464, "actor_loss": -20.335252367019653, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.132854223251343, "step": 15000}
{"episode_reward": 90.86022284867092, "episode": 16.0, "batch_reward": 0.07374017095565796, "critic_loss": 0.034265085547231136, "actor_loss": -19.486793843269346, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.499454975128174, "step": 16000}
{"episode_reward": 66.6333857121688, "episode": 17.0, "batch_reward": 0.07367925821617245, "critic_loss": 0.03525749321188778, "actor_loss": -19.19043637561798, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.491143703460693, "step": 17000}
{"episode_reward": 63.11810518756989, "episode": 18.0, "batch_reward": 0.07280300815403462, "critic_loss": 0.040386622592806815, "actor_loss": -17.40167519187927, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.98859453201294, "step": 18000}
{"episode_reward": 71.37442738282104, "episode": 19.0, "batch_reward": 0.07169874075427651, "critic_loss": 0.04121137761883437, "actor_loss": -17.96617694091797, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.2752206325531, "step": 19000}
{"episode_reward": 23.859347493011132, "episode": 20.0, "batch_reward": 0.07248302595689893, "critic_loss": 0.06338339786045254, "actor_loss": -16.754642685890197, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.21339774131775, "step": 20000}
{"episode_reward": 130.44927821181537, "episode": 21.0, "batch_reward": 0.07296077379956842, "critic_loss": 0.058613123884424564, "actor_loss": -16.739457967519762, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 33.261749505996704, "step": 21000}
{"episode_reward": 36.87090012966668, "episode": 22.0, "batch_reward": 0.07441961846873164, "critic_loss": 0.08105076545104384, "actor_loss": -15.336622544884682, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.68881058692932, "step": 22000}
{"episode_reward": 127.22355119507726, "episode": 23.0, "batch_reward": 0.0769346262216568, "critic_loss": 0.08710874428041279, "actor_loss": -16.076753640055657, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.231136798858643, "step": 23000}
{"episode_reward": 127.70576593659413, "episode": 24.0, "batch_reward": 0.08066256411373615, "critic_loss": 0.13060759502276778, "actor_loss": -16.404655675470828, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.02889394760132, "step": 24000}
{"episode_reward": 215.4009004235597, "episode": 25.0, "batch_reward": 0.08161851211637258, "critic_loss": 0.16491880470514297, "actor_loss": -14.703318078756332, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.53336501121521, "step": 25000}
{"episode_reward": 57.74824182115471, "episode": 26.0, "batch_reward": 0.08476079331338406, "critic_loss": 0.26759665145725015, "actor_loss": -16.010972513765097, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.70679807662964, "step": 26000}
{"episode_reward": 203.6786746514741, "episode": 27.0, "batch_reward": 0.08655706183984875, "critic_loss": 0.31528313176333905, "actor_loss": -16.09272185087204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.40991520881653, "step": 27000}
{"episode_reward": 88.67110068377592, "episode": 28.0, "batch_reward": 0.08647664358839392, "critic_loss": 0.31108954887092116, "actor_loss": -15.499083897590637, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.927221536636353, "step": 28000}
{"episode_reward": 67.6563542863111, "episode": 29.0, "batch_reward": 0.08467036531493068, "critic_loss": 0.35654527209699155, "actor_loss": -16.0786649646759, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.951013326644897, "step": 29000}
{"episode_reward": 30.81304415599302, "episode": 30.0, "batch_reward": 0.08279461824148894, "critic_loss": 0.29453019876778125, "actor_loss": -16.641412014961244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.429109573364258, "step": 30000}
{"episode_reward": 27.51521617943287, "episode": 31.0, "batch_reward": 0.08386128178238869, "critic_loss": 0.2549067905694246, "actor_loss": -16.5428873500824, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 33.94628143310547, "step": 31000}
{"episode_reward": 163.6094605829949, "episode": 32.0, "batch_reward": 0.08470661200210453, "critic_loss": 0.21146093718707562, "actor_loss": -16.898953256607054, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.95928454399109, "step": 32000}
{"episode_reward": 167.73785251660263, "episode": 33.0, "batch_reward": 0.08796288646385074, "critic_loss": 0.205752025231719, "actor_loss": -16.724183050155638, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.718534231185913, "step": 33000}
{"episode_reward": 285.0995129940734, "episode": 34.0, "batch_reward": 0.09509566929191351, "critic_loss": 0.24072805579006673, "actor_loss": -17.127357347488402, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.48726797103882, "step": 34000}
{"episode_reward": 269.41636415750344, "episode": 35.0, "batch_reward": 0.09979147832095624, "critic_loss": 0.24644558922201396, "actor_loss": -18.258809898376466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.78165602684021, "step": 35000}
{"episode_reward": 262.9847167352943, "episode": 36.0, "batch_reward": 0.10517676463723183, "critic_loss": 0.23604268190264702, "actor_loss": -18.025494077682495, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.12304401397705, "step": 36000}
{"episode_reward": 246.3607320003479, "episode": 37.0, "batch_reward": 0.10858878958970308, "critic_loss": 0.22492460538446904, "actor_loss": -18.451698181152345, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.148691415786743, "step": 37000}
{"episode_reward": 255.46063274156234, "episode": 38.0, "batch_reward": 0.11317859414964915, "critic_loss": 0.22884620337188244, "actor_loss": -18.3700173664093, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.722081184387207, "step": 38000}
{"episode_reward": 225.68056777228517, "episode": 39.0, "batch_reward": 0.1166597668454051, "critic_loss": 0.24194924058020115, "actor_loss": -18.341538019180298, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.169745206832886, "step": 39000}
{"episode_reward": 291.4634318140072, "episode": 40.0, "batch_reward": 0.1197000040113926, "critic_loss": 0.2783799662962556, "actor_loss": -18.35736361885071, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.832406997680664, "step": 40000}
{"episode_reward": 130.84509872737533, "episode": 41.0, "batch_reward": 0.11834376749396325, "critic_loss": 0.27101250713318586, "actor_loss": -18.65144674682617, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.959030628204346, "step": 41000}
{"episode_reward": 46.08334999587872, "episode": 42.0, "batch_reward": 0.11807364528626203, "critic_loss": 0.26403674425184726, "actor_loss": -18.524151321411132, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.94034719467163, "step": 42000}
{"episode_reward": 116.81615940513646, "episode": 43.0, "batch_reward": 0.11788753496855497, "critic_loss": 0.2620659073740244, "actor_loss": -18.27611458015442, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.943768978118896, "step": 43000}
{"episode_reward": 173.3904319684232, "episode": 44.0, "batch_reward": 0.12103028395026923, "critic_loss": 0.2531547336354852, "actor_loss": -18.90297674179077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.002206563949585, "step": 44000}
{"episode_reward": 352.03949909198303, "episode": 45.0, "batch_reward": 0.12644140265882015, "critic_loss": 0.26905435656011106, "actor_loss": -19.333229377746584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.64691710472107, "step": 45000}
{"episode_reward": 373.9178493943451, "episode": 46.0, "batch_reward": 0.13153672222793103, "critic_loss": 0.27629744552075863, "actor_loss": -19.754311939239503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.00997042655945, "step": 46000}
{"episode_reward": 333.7024422296336, "episode": 47.0, "batch_reward": 0.13559781996160747, "critic_loss": 0.2771518704742193, "actor_loss": -20.21950173187256, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.633015632629395, "step": 47000}
{"episode_reward": 350.5330164203137, "episode": 48.0, "batch_reward": 0.13942467768490313, "critic_loss": 0.24911309610307217, "actor_loss": -20.573466567993165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.032268524169922, "step": 48000}
{"episode_reward": 245.11978413899644, "episode": 49.0, "batch_reward": 0.14152322140336038, "critic_loss": 0.25077319771796464, "actor_loss": -20.49319968032837, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.19145917892456, "step": 49000}
{"episode_reward": 169.99297436633861, "episode": 50.0, "batch_reward": 0.14181170025467874, "critic_loss": 0.24415899918228387, "actor_loss": -20.660954906463623, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.802725076675415, "step": 50000}
{"episode_reward": 274.27948294265155, "episode": 51.0, "batch_reward": 0.1448280928954482, "critic_loss": 0.27689314698427914, "actor_loss": -20.423933395385742, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.933434009552, "step": 51000}
{"episode_reward": 333.6137129964827, "episode": 52.0, "batch_reward": 0.14746907587349414, "critic_loss": 0.28351457182317974, "actor_loss": -21.192397006988525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.060120820999146, "step": 52000}
{"episode_reward": 83.13273603380172, "episode": 53.0, "batch_reward": 0.14833045690506697, "critic_loss": 0.28599741119891403, "actor_loss": -21.23778907775879, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.28058695793152, "step": 53000}
{"episode_reward": 260.04329589078105, "episode": 54.0, "batch_reward": 0.14873241359740497, "critic_loss": 0.27555845920741556, "actor_loss": -21.18523452758789, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.20410919189453, "step": 54000}
{"episode_reward": 150.30907504837273, "episode": 55.0, "batch_reward": 0.1501931113600731, "critic_loss": 0.3131246413141489, "actor_loss": -21.259505447387696, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.079253435134888, "step": 55000}
{"episode_reward": 362.4279883726524, "episode": 56.0, "batch_reward": 0.15276610977947713, "critic_loss": 0.33028534933924675, "actor_loss": -21.914396129608154, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.51810598373413, "step": 56000}
{"episode_reward": 121.20053358480071, "episode": 57.0, "batch_reward": 0.15123070894181728, "critic_loss": 0.33061966840922835, "actor_loss": -21.51851765823364, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.692366123199463, "step": 57000}
{"episode_reward": 66.3361205322349, "episode": 58.0, "batch_reward": 0.15154857183992862, "critic_loss": 0.3076449762433767, "actor_loss": -21.767628532409667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.663069486618042, "step": 58000}
{"episode_reward": 322.8201200327451, "episode": 59.0, "batch_reward": 0.15281794529408216, "critic_loss": 0.31541084408760073, "actor_loss": -21.704326736450195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.20799732208252, "step": 59000}
{"episode_reward": 64.35223453538056, "episode": 60.0, "batch_reward": 0.15349451604485512, "critic_loss": 0.337212804377079, "actor_loss": -22.13789024734497, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.94447088241577, "step": 60000}
{"episode_reward": 346.68460724881186, "episode": 61.0, "batch_reward": 0.1550644032806158, "critic_loss": 0.33875118793547154, "actor_loss": -22.300296028137208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.53801155090332, "step": 61000}
{"episode_reward": 133.20099959912335, "episode": 62.0, "batch_reward": 0.15603396691381932, "critic_loss": 0.3584365228712559, "actor_loss": -22.579528102874757, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.985302925109863, "step": 62000}
{"episode_reward": 369.6240255315392, "episode": 63.0, "batch_reward": 0.15961180367320776, "critic_loss": 0.3440774989873171, "actor_loss": -22.978113094329835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.927430629730225, "step": 63000}
{"episode_reward": 367.16634157460976, "episode": 64.0, "batch_reward": 0.16086850376427173, "critic_loss": 0.33841366508603093, "actor_loss": -22.949163681030274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.45365810394287, "step": 64000}
{"episode_reward": 98.96841802979117, "episode": 65.0, "batch_reward": 0.16105290938913822, "critic_loss": 0.3746760919839144, "actor_loss": -22.869561401367186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.802269458770752, "step": 65000}
{"episode_reward": 196.04793056990246, "episode": 66.0, "batch_reward": 0.1619706409201026, "critic_loss": 0.36237162111699583, "actor_loss": -22.954520973205568, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.21685791015625, "step": 66000}
{"episode_reward": 181.0106234954154, "episode": 67.0, "batch_reward": 0.16066428708285094, "critic_loss": 0.38570100742578506, "actor_loss": -22.83095419692993, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.052444458007812, "step": 67000}
{"episode_reward": 87.28383651915465, "episode": 68.0, "batch_reward": 0.16035880537331104, "critic_loss": 0.3724181138128042, "actor_loss": -22.945257762908934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.48271346092224, "step": 68000}
{"episode_reward": 92.87827393421391, "episode": 69.0, "batch_reward": 0.1584983973503113, "critic_loss": 0.36148396381735803, "actor_loss": -22.70627540588379, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.519845962524414, "step": 69000}
{"episode_reward": 62.735880390554144, "episode": 70.0, "batch_reward": 0.15956036472320556, "critic_loss": 0.38118054124712947, "actor_loss": -22.85894328689575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.585748434066772, "step": 70000}
{"episode_reward": 248.23509765803436, "episode": 71.0, "batch_reward": 0.15976314572244882, "critic_loss": 0.38123733584582803, "actor_loss": -23.059944019317626, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.34445762634277, "step": 71000}
{"episode_reward": 368.2471678944916, "episode": 72.0, "batch_reward": 0.16274000335484742, "critic_loss": 0.3630002281069756, "actor_loss": -23.275065673828124, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.790172338485718, "step": 72000}
{"episode_reward": 224.4459302759528, "episode": 73.0, "batch_reward": 0.16386420059949158, "critic_loss": 0.37595337215065955, "actor_loss": -23.37121855545044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.323488235473633, "step": 73000}
{"episode_reward": 331.27563780329245, "episode": 74.0, "batch_reward": 0.16504961609840393, "critic_loss": 0.38632676658034326, "actor_loss": -23.60829372024536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23262619972229, "step": 74000}
{"episode_reward": 109.14728911420185, "episode": 75.0, "batch_reward": 0.16490424577146767, "critic_loss": 0.42271642638742923, "actor_loss": -23.404262950897216, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.25110673904419, "step": 75000}
{"episode_reward": 140.2917071078556, "episode": 76.0, "batch_reward": 0.16501143968105317, "critic_loss": 0.41442924508452417, "actor_loss": -23.42326557159424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.06426477432251, "step": 76000}
{"episode_reward": 444.22064226499253, "episode": 77.0, "batch_reward": 0.16853082728385926, "critic_loss": 0.42027753534913065, "actor_loss": -23.81267198562622, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.070428133010864, "step": 77000}
{"episode_reward": 221.01092180201064, "episode": 78.0, "batch_reward": 0.16881998947262764, "critic_loss": 0.41874933329224584, "actor_loss": -23.921349044799804, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.16414475440979, "step": 78000}
{"episode_reward": 258.9996132613297, "episode": 79.0, "batch_reward": 0.17081268040835856, "critic_loss": 0.4027363119274378, "actor_loss": -23.70442951965332, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.4963161945343, "step": 79000}
{"episode_reward": 206.82006221773324, "episode": 80.0, "batch_reward": 0.17101759009063244, "critic_loss": 0.4692719344496727, "actor_loss": -23.907575832366945, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.5838520526886, "step": 80000}
{"episode_reward": 208.8307171984568, "episode": 81.0, "batch_reward": 0.17245327050983905, "critic_loss": 0.4376179732680321, "actor_loss": -24.03048124694824, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.417099714279175, "step": 81000}
{"episode_reward": 447.9520062677183, "episode": 82.0, "batch_reward": 0.17368207342922687, "critic_loss": 0.4413544532507658, "actor_loss": -24.177345634460448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.087162494659424, "step": 82000}
{"episode_reward": 57.853156977667425, "episode": 83.0, "batch_reward": 0.17311606246978045, "critic_loss": 0.40989097955822945, "actor_loss": -24.228363594055175, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.008347034454346, "step": 83000}
{"episode_reward": 217.47286074869902, "episode": 84.0, "batch_reward": 0.1734005547389388, "critic_loss": 0.4366250082403421, "actor_loss": -24.087731578826904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.351309299468994, "step": 84000}
{"episode_reward": 136.88710294878533, "episode": 85.0, "batch_reward": 0.17280022199451922, "critic_loss": 0.4210557784587145, "actor_loss": -24.066860450744628, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.602378129959106, "step": 85000}
{"episode_reward": 180.209819567261, "episode": 86.0, "batch_reward": 0.17244571274518966, "critic_loss": 0.448112784832716, "actor_loss": -24.211925384521486, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.82862687110901, "step": 86000}
{"episode_reward": 205.39451159157676, "episode": 87.0, "batch_reward": 0.17397395031154156, "critic_loss": 0.45464226487278936, "actor_loss": -24.304287269592287, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.600601196289062, "step": 87000}
{"episode_reward": 401.74439406024004, "episode": 88.0, "batch_reward": 0.17744494347274303, "critic_loss": 0.44616870997846125, "actor_loss": -24.72242607498169, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.48336386680603, "step": 88000}
{"episode_reward": 404.1970654973982, "episode": 89.0, "batch_reward": 0.17908398082852364, "critic_loss": 0.43875541841983795, "actor_loss": -24.889624305725096, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.02243137359619, "step": 89000}
{"episode_reward": 266.2173599425391, "episode": 90.0, "batch_reward": 0.18058952476084233, "critic_loss": 0.40516857799887657, "actor_loss": -25.09397797012329, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.385896921157837, "step": 90000}
{"episode_reward": 449.20309956924706, "episode": 91.0, "batch_reward": 0.18362324231863023, "critic_loss": 0.44223964504897595, "actor_loss": -25.219204643249512, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.83367967605591, "step": 91000}
{"episode_reward": 428.9399154021989, "episode": 92.0, "batch_reward": 0.18626344607770443, "critic_loss": 0.4484810476973653, "actor_loss": -25.478604816436768, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41026210784912, "step": 92000}
{"episode_reward": 376.41593131444836, "episode": 93.0, "batch_reward": 0.18817062471807003, "critic_loss": 0.44064010968804357, "actor_loss": -25.461963680267335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.703620433807373, "step": 93000}
{"episode_reward": 452.3138878940719, "episode": 94.0, "batch_reward": 0.19152945348620415, "critic_loss": 0.45759037080407144, "actor_loss": -25.812641136169432, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.84775948524475, "step": 94000}
{"episode_reward": 511.13497114597294, "episode": 95.0, "batch_reward": 0.19380157482624055, "critic_loss": 0.45153372855484486, "actor_loss": -25.94428633880615, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.550825834274292, "step": 95000}
{"episode_reward": 427.65501037433876, "episode": 96.0, "batch_reward": 0.19765952302515508, "critic_loss": 0.4291337270736694, "actor_loss": -26.162831703186036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.14486861228943, "step": 96000}
{"episode_reward": 387.47240041922913, "episode": 97.0, "batch_reward": 0.19892891070246696, "critic_loss": 0.45266470178961754, "actor_loss": -26.32972420501709, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.945255279541016, "step": 97000}
{"episode_reward": 458.49839447998147, "episode": 98.0, "batch_reward": 0.2023170467764139, "critic_loss": 0.44761623880267143, "actor_loss": -26.551791893005372, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.564815759658813, "step": 98000}
{"episode_reward": 499.2614675447128, "episode": 99.0, "batch_reward": 0.20414043490588665, "critic_loss": 0.438779947206378, "actor_loss": -26.566751029968263, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.85154390335083, "step": 99000}
{"episode_reward": 489.0354360815302, "episode": 100.0, "batch_reward": 0.20746557457745074, "critic_loss": 0.43612400408089164, "actor_loss": -26.953477836608887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23876690864563, "step": 100000}
{"episode_reward": 448.3937774565957, "episode": 101.0, "batch_reward": 0.20892737299203873, "critic_loss": 0.3952121848613024, "actor_loss": -27.186333106994628, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.51196360588074, "step": 101000}
{"episode_reward": 330.8504625581504, "episode": 102.0, "batch_reward": 0.2110650755316019, "critic_loss": 0.42918936218321324, "actor_loss": -27.196477588653565, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22699809074402, "step": 102000}
{"episode_reward": 443.8672262516646, "episode": 103.0, "batch_reward": 0.21272310620546342, "critic_loss": 0.4327029523700476, "actor_loss": -27.430827335357666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.561242818832397, "step": 103000}
{"episode_reward": 206.32942950325312, "episode": 104.0, "batch_reward": 0.21384439918398856, "critic_loss": 0.46872733379900455, "actor_loss": -27.334344467163085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.63870882987976, "step": 104000}
{"episode_reward": 388.3941822122978, "episode": 105.0, "batch_reward": 0.21343846845626832, "critic_loss": 0.4445561663210392, "actor_loss": -27.382207912445068, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.353793382644653, "step": 105000}
{"episode_reward": 163.16792938136726, "episode": 106.0, "batch_reward": 0.2142922577857971, "critic_loss": 0.484644642084837, "actor_loss": -27.29797207260132, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.080533981323242, "step": 106000}
{"episode_reward": 521.1499245400934, "episode": 107.0, "batch_reward": 0.21699637465178967, "critic_loss": 0.4030845628082752, "actor_loss": -27.588964588165283, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.5401394367218, "step": 107000}
{"episode_reward": 513.710445417709, "episode": 108.0, "batch_reward": 0.21998520505428315, "critic_loss": 0.4007356082201004, "actor_loss": -27.790857372283934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.975205898284912, "step": 108000}
{"episode_reward": 512.1981249004076, "episode": 109.0, "batch_reward": 0.2235621930360794, "critic_loss": 0.376356354624033, "actor_loss": -28.02180602645874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.94522190093994, "step": 109000}
{"episode_reward": 366.3575423172025, "episode": 110.0, "batch_reward": 0.2239019863009453, "critic_loss": 0.3918086541593075, "actor_loss": -27.975106353759767, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.677489519119263, "step": 110000}
{"episode_reward": 477.61108164082185, "episode": 111.0, "batch_reward": 0.22634504276514053, "critic_loss": 0.4073231842070818, "actor_loss": -28.24708848953247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.518728494644165, "step": 111000}
{"episode_reward": 281.5984500916346, "episode": 112.0, "batch_reward": 0.2272219011336565, "critic_loss": 0.3942527524530888, "actor_loss": -28.193977291107178, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.518862009048462, "step": 112000}
{"episode_reward": 293.166420010534, "episode": 113.0, "batch_reward": 0.22707180263102056, "critic_loss": 0.4006479182094336, "actor_loss": -28.24345310974121, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.59783124923706, "step": 113000}
{"episode_reward": 108.9242957611918, "episode": 114.0, "batch_reward": 0.22606995482742787, "critic_loss": 0.38153151619434356, "actor_loss": -28.065079383850097, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.591867446899414, "step": 114000}
{"episode_reward": 108.00115529475984, "episode": 115.0, "batch_reward": 0.22635164032876492, "critic_loss": 0.37158151212334634, "actor_loss": -28.052986721038817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.365477800369263, "step": 115000}
{"episode_reward": 537.2332358000955, "episode": 116.0, "batch_reward": 0.22770859782397748, "critic_loss": 0.3934880496710539, "actor_loss": -28.180691860198973, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.6358540058136, "step": 116000}
{"episode_reward": 337.04435606243214, "episode": 117.0, "batch_reward": 0.2296172712445259, "critic_loss": 0.3974423544704914, "actor_loss": -28.24441772079468, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.366267681121826, "step": 117000}
{"episode_reward": 450.9409870993295, "episode": 118.0, "batch_reward": 0.23185500167310238, "critic_loss": 0.37415266750752924, "actor_loss": -28.528530448913575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.63317346572876, "step": 118000}
{"episode_reward": 562.6493117723312, "episode": 119.0, "batch_reward": 0.23312775909900665, "critic_loss": 0.3763430419266224, "actor_loss": -28.637780239105226, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.229447603225708, "step": 119000}
{"episode_reward": 371.26174014049116, "episode": 120.0, "batch_reward": 0.2354088309556246, "critic_loss": 0.37351446875929833, "actor_loss": -28.69311943435669, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.328126430511475, "step": 120000}
{"episode_reward": 572.0322020280307, "episode": 121.0, "batch_reward": 0.2380415227562189, "critic_loss": 0.3712785626202822, "actor_loss": -29.079913368225096, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.04148268699646, "step": 121000}
{"episode_reward": 365.1890064753185, "episode": 122.0, "batch_reward": 0.23933304327726365, "critic_loss": 0.3766331930458546, "actor_loss": -29.0251611289978, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.35127329826355, "step": 122000}
{"episode_reward": 456.57869673922204, "episode": 123.0, "batch_reward": 0.2405891432762146, "critic_loss": 0.37746174325048926, "actor_loss": -29.17776124191284, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.237910747528076, "step": 123000}
{"episode_reward": 582.4618346265089, "episode": 124.0, "batch_reward": 0.2433216343075037, "critic_loss": 0.3644703687429428, "actor_loss": -29.416837646484375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.945923805236816, "step": 124000}
{"episode_reward": 548.8688231132079, "episode": 125.0, "batch_reward": 0.24555832819640636, "critic_loss": 0.37728925140202046, "actor_loss": -29.459522289276123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.45958113670349, "step": 125000}
{"episode_reward": 503.1961058818458, "episode": 126.0, "batch_reward": 0.24758662408590318, "critic_loss": 0.40432618018984795, "actor_loss": -29.61540972137451, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.757213592529297, "step": 126000}
{"episode_reward": 345.2834418990694, "episode": 127.0, "batch_reward": 0.24814190019667148, "critic_loss": 0.37999562749266624, "actor_loss": -29.52670638656616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34509301185608, "step": 127000}
{"episode_reward": 575.6717574297835, "episode": 128.0, "batch_reward": 0.2510005312860012, "critic_loss": 0.3862930296957493, "actor_loss": -29.746882610321045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.439232110977173, "step": 128000}
{"episode_reward": 545.5658784962934, "episode": 129.0, "batch_reward": 0.25384613263607025, "critic_loss": 0.3634703547656536, "actor_loss": -29.997331302642824, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.584025859832764, "step": 129000}
{"episode_reward": 557.8624577192536, "episode": 130.0, "batch_reward": 0.25558417968451974, "critic_loss": 0.3744788382202387, "actor_loss": -30.352334728240965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.175223350524902, "step": 130000}
{"episode_reward": 393.0152766744515, "episode": 131.0, "batch_reward": 0.2569735752493143, "critic_loss": 0.38347000594437125, "actor_loss": -30.47004648590088, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.58749341964722, "step": 131000}
{"episode_reward": 593.1235166512233, "episode": 132.0, "batch_reward": 0.2587950470894575, "critic_loss": 0.3772665572017431, "actor_loss": -30.418304599761964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.345312118530273, "step": 132000}
{"episode_reward": 564.2677919410036, "episode": 133.0, "batch_reward": 0.2611217219680548, "critic_loss": 0.35865305438637735, "actor_loss": -30.64499415588379, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.351481199264526, "step": 133000}
{"episode_reward": 514.4590231733383, "episode": 134.0, "batch_reward": 0.26372617867589, "critic_loss": 0.38097731965780257, "actor_loss": -30.901208290100097, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.084113359451294, "step": 134000}
{"episode_reward": 465.330298430586, "episode": 135.0, "batch_reward": 0.26544397677481174, "critic_loss": 0.3866050128340721, "actor_loss": -30.982742267608643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.128601551055908, "step": 135000}
{"episode_reward": 450.58803851675174, "episode": 136.0, "batch_reward": 0.2663688294887543, "critic_loss": 0.3584953808486462, "actor_loss": -31.01865326309204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.93311357498169, "step": 136000}
{"episode_reward": 602.2019417408368, "episode": 137.0, "batch_reward": 0.2692374191135168, "critic_loss": 0.3820644605755806, "actor_loss": -31.249494606018068, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.145353317260742, "step": 137000}
{"episode_reward": 539.2784765848005, "episode": 138.0, "batch_reward": 0.2720174781829119, "critic_loss": 0.3792114859074354, "actor_loss": -31.509439628601076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.268990516662598, "step": 138000}
{"episode_reward": 571.0987322253637, "episode": 139.0, "batch_reward": 0.27389240176975727, "critic_loss": 0.3676428548693657, "actor_loss": -31.61157112121582, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.37504553794861, "step": 139000}
{"episode_reward": 558.4575339435164, "episode": 140.0, "batch_reward": 0.275665444880724, "critic_loss": 0.3364616773277521, "actor_loss": -31.894058536529542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.909276723861694, "step": 140000}
{"episode_reward": 586.3416979819584, "episode": 141.0, "batch_reward": 0.2755360041111708, "critic_loss": 0.3678493576794863, "actor_loss": -31.800595531463625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.35633730888367, "step": 141000}
{"episode_reward": 240.45607835871704, "episode": 142.0, "batch_reward": 0.27696732598543167, "critic_loss": 0.3536607640385628, "actor_loss": -31.729351543426514, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.56938076019287, "step": 142000}
{"episode_reward": 540.4355576114061, "episode": 143.0, "batch_reward": 0.2799970253407955, "critic_loss": 0.35978383085876703, "actor_loss": -32.0331833152771, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.212799310684204, "step": 143000}
{"episode_reward": 401.89675630201515, "episode": 144.0, "batch_reward": 0.2805598937571049, "critic_loss": 0.3833571486920118, "actor_loss": -32.13925400543213, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.012918949127197, "step": 144000}
{"episode_reward": 510.448028430866, "episode": 145.0, "batch_reward": 0.28277627332508565, "critic_loss": 0.3763248094022274, "actor_loss": -32.30766973114014, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22929835319519, "step": 145000}
{"episode_reward": 591.3139277468665, "episode": 146.0, "batch_reward": 0.28334294046461583, "critic_loss": 0.382767368555069, "actor_loss": -32.4998650970459, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.989851474761963, "step": 146000}
{"episode_reward": 611.7869372752326, "episode": 147.0, "batch_reward": 0.2870717278569937, "critic_loss": 0.39758207830786707, "actor_loss": -32.7360410079956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.106751203536987, "step": 147000}
{"episode_reward": 296.9776666154453, "episode": 148.0, "batch_reward": 0.28683770586550233, "critic_loss": 0.3896047384738922, "actor_loss": -32.73641876602173, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.667580366134644, "step": 148000}
{"episode_reward": 620.9333983762251, "episode": 149.0, "batch_reward": 0.2868395465910435, "critic_loss": 0.3648326726257801, "actor_loss": -32.77184297180176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.121949911117554, "step": 149000}
{"episode_reward": 348.8509235977962, "episode": 150.0, "batch_reward": 0.2884990540891886, "critic_loss": 0.39981130422651767, "actor_loss": -32.83612112045288, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
