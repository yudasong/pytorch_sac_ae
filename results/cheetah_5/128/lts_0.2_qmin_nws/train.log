{"episode_reward": 0.0, "episode": 1.0, "duration": 17.837676763534546, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.5409860610961914, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.2627514363050699, "critic_loss": 0.021307298310210342, "actor_loss": -10.68239230965199, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 64.74241042137146, "step": 3000}
{"episode_reward": 49.5574733806509, "episode": 4.0, "batch_reward": 0.18875692734122276, "critic_loss": 0.029827263589948416, "actor_loss": -11.544258457660675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.612356185913086, "step": 4000}
{"episode_reward": 100.71490723599405, "episode": 5.0, "batch_reward": 0.16485112925618886, "critic_loss": 0.028588914854452013, "actor_loss": -11.307100069999695, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.99156951904297, "step": 5000}
{"episode_reward": 49.95471067452659, "episode": 6.0, "batch_reward": 0.14271599422395229, "critic_loss": 0.037116439798846844, "actor_loss": -10.559099268913268, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.54447364807129, "step": 6000}
{"episode_reward": 67.99759774993221, "episode": 7.0, "batch_reward": 0.13749637674540283, "critic_loss": 0.06534590338356792, "actor_loss": -9.98836996936798, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.901675701141357, "step": 7000}
{"episode_reward": 190.92262751391786, "episode": 8.0, "batch_reward": 0.13790575955063106, "critic_loss": 0.0793883409332484, "actor_loss": -11.723680866241455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.642239570617676, "step": 8000}
{"episode_reward": 29.734096947948714, "episode": 9.0, "batch_reward": 0.13417767472565173, "critic_loss": 0.07608269644901157, "actor_loss": -11.099728735923767, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.645007610321045, "step": 9000}
{"episode_reward": 153.25157251295744, "episode": 10.0, "batch_reward": 0.1331640951409936, "critic_loss": 0.09140190557762981, "actor_loss": -11.83473380279541, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.68577265739441, "step": 10000}
{"episode_reward": 103.61180127541755, "episode": 11.0, "batch_reward": 0.1309884183332324, "critic_loss": 0.09980455777049065, "actor_loss": -12.12221408367157, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.47809410095215, "step": 11000}
{"episode_reward": 138.38325611249812, "episode": 12.0, "batch_reward": 0.1275655671879649, "critic_loss": 0.10024664053320885, "actor_loss": -12.791053401947021, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.33953309059143, "step": 12000}
{"episode_reward": 40.25410128715007, "episode": 13.0, "batch_reward": 0.1261861988529563, "critic_loss": 0.11486119423434138, "actor_loss": -13.449067792892457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.235189199447632, "step": 13000}
{"episode_reward": 214.13369581016585, "episode": 14.0, "batch_reward": 0.13222057767212392, "critic_loss": 0.14044157763570547, "actor_loss": -14.57088567352295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.595414400100708, "step": 14000}
{"episode_reward": 204.64656755176, "episode": 15.0, "batch_reward": 0.13930753303319215, "critic_loss": 0.16325625203549862, "actor_loss": -14.923861194610597, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.672791719436646, "step": 15000}
{"episode_reward": 219.64688583052526, "episode": 16.0, "batch_reward": 0.14087858252972366, "critic_loss": 0.1730158174484968, "actor_loss": -15.140869359970093, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.063286304473877, "step": 16000}
{"episode_reward": 97.51488093458184, "episode": 17.0, "batch_reward": 0.14087171860039235, "critic_loss": 0.19634462255239488, "actor_loss": -15.274447608947755, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.0086088180542, "step": 17000}
{"episode_reward": 173.08456654538273, "episode": 18.0, "batch_reward": 0.14312934952974318, "critic_loss": 0.22286017616838216, "actor_loss": -16.134316326141356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.28222346305847, "step": 18000}
{"episode_reward": 284.3581393423311, "episode": 19.0, "batch_reward": 0.14741221940517427, "critic_loss": 0.25990790148824455, "actor_loss": -16.859137334823608, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.650800466537476, "step": 19000}
{"episode_reward": 83.3038675956492, "episode": 20.0, "batch_reward": 0.14806526905298234, "critic_loss": 0.22241037656366824, "actor_loss": -17.217489391326904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.661899089813232, "step": 20000}
{"episode_reward": 265.5124189335459, "episode": 21.0, "batch_reward": 0.1506691184565425, "critic_loss": 0.22365254771709442, "actor_loss": -17.59218431854248, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.888471364974976, "step": 21000}
{"episode_reward": 86.4063074259694, "episode": 22.0, "batch_reward": 0.1494862656071782, "critic_loss": 0.2333886401876807, "actor_loss": -18.25155770111084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.576317310333252, "step": 22000}
{"episode_reward": 212.35632898337357, "episode": 23.0, "batch_reward": 0.15190069850534202, "critic_loss": 0.22399787445366381, "actor_loss": -18.14408924484253, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.645186185836792, "step": 23000}
{"episode_reward": 141.16975349799299, "episode": 24.0, "batch_reward": 0.1514368816912174, "critic_loss": 0.20969933660328388, "actor_loss": -18.501504022598265, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.586952686309814, "step": 24000}
{"episode_reward": 158.25375846554778, "episode": 25.0, "batch_reward": 0.15344937046617269, "critic_loss": 0.22981097586452962, "actor_loss": -18.731726259231568, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.745489597320557, "step": 25000}
{"episode_reward": 306.7645780152876, "episode": 26.0, "batch_reward": 0.15641475620865822, "critic_loss": 0.24120310973376036, "actor_loss": -18.853735219955443, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.565133810043335, "step": 26000}
{"episode_reward": 94.87170450291292, "episode": 27.0, "batch_reward": 0.15743498745560647, "critic_loss": 0.28621048951894046, "actor_loss": -19.240095222473144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.660744667053223, "step": 27000}
{"episode_reward": 275.2813282319578, "episode": 28.0, "batch_reward": 0.16146503418684005, "critic_loss": 0.2845877653360367, "actor_loss": -19.651855367660524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.688798904418945, "step": 28000}
{"episode_reward": 313.3837555911128, "episode": 29.0, "batch_reward": 0.16603197237849235, "critic_loss": 0.2962749424278736, "actor_loss": -20.148652845382692, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.26329493522644, "step": 29000}
{"episode_reward": 201.54101165903563, "episode": 30.0, "batch_reward": 0.16627398639917373, "critic_loss": 0.30646822790801526, "actor_loss": -20.43307593536377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.658326387405396, "step": 30000}
{"episode_reward": 180.10121076266674, "episode": 31.0, "batch_reward": 0.16749539860337972, "critic_loss": 0.3186836915016174, "actor_loss": -20.86167018890381, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.122729539871216, "step": 31000}
{"episode_reward": 236.9483512220963, "episode": 32.0, "batch_reward": 0.16974282291531562, "critic_loss": 0.30451693396270274, "actor_loss": -20.99806344604492, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.463595867156982, "step": 32000}
{"episode_reward": 265.4411211404985, "episode": 33.0, "batch_reward": 0.1730238897949457, "critic_loss": 0.32719151182472705, "actor_loss": -21.43823599243164, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.646132946014404, "step": 33000}
{"episode_reward": 289.86428440982115, "episode": 34.0, "batch_reward": 0.1757369250655174, "critic_loss": 0.3470554013699293, "actor_loss": -21.863300884246826, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.059760093688965, "step": 34000}
{"episode_reward": 126.5827205483298, "episode": 35.0, "batch_reward": 0.17510746785998343, "critic_loss": 0.3309767892509699, "actor_loss": -21.61240725326538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.646894216537476, "step": 35000}
{"episode_reward": 182.10257972391, "episode": 36.0, "batch_reward": 0.17421523946523668, "critic_loss": 0.3420631926357746, "actor_loss": -21.987700908660887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.008910417556763, "step": 36000}
{"episode_reward": 106.3270783866249, "episode": 37.0, "batch_reward": 0.17332869996130468, "critic_loss": 0.3216318039447069, "actor_loss": -21.85690051651001, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.646944522857666, "step": 37000}
{"episode_reward": 175.5148461386127, "episode": 38.0, "batch_reward": 0.17162473885715007, "critic_loss": 0.32768140418827535, "actor_loss": -21.706214614868163, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.390917778015137, "step": 38000}
{"episode_reward": 115.9872177784738, "episode": 39.0, "batch_reward": 0.1736120341718197, "critic_loss": 0.3579114474058151, "actor_loss": -21.907587867736815, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.283248901367188, "step": 39000}
{"episode_reward": 380.7481626369268, "episode": 40.0, "batch_reward": 0.1765252097323537, "critic_loss": 0.3547573963552713, "actor_loss": -22.312086120605468, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.624225854873657, "step": 40000}
{"episode_reward": 184.23506932089745, "episode": 41.0, "batch_reward": 0.17767384965717792, "critic_loss": 0.38568973788619043, "actor_loss": -22.466379318237305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.69474005699158, "step": 41000}
{"episode_reward": 314.3767614438298, "episode": 42.0, "batch_reward": 0.18141711115837098, "critic_loss": 0.3852497961968184, "actor_loss": -22.966211296081543, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.91847252845764, "step": 42000}
{"episode_reward": 241.00144917511196, "episode": 43.0, "batch_reward": 0.18273826958239078, "critic_loss": 0.40520027562975885, "actor_loss": -23.155954917907714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.65111804008484, "step": 43000}
{"episode_reward": 250.60278238662121, "episode": 44.0, "batch_reward": 0.18411925868690013, "critic_loss": 0.4525149821192026, "actor_loss": -23.458240932464598, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.610532522201538, "step": 44000}
{"episode_reward": 236.90764738757218, "episode": 45.0, "batch_reward": 0.18276382440328598, "critic_loss": 0.47542752327024934, "actor_loss": -23.30841976928711, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.3077871799469, "step": 45000}
{"episode_reward": 63.921247694470985, "episode": 46.0, "batch_reward": 0.18078513111174108, "critic_loss": 0.5328280958831311, "actor_loss": -23.1066971282959, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.070050954818726, "step": 46000}
{"episode_reward": 107.23465610284563, "episode": 47.0, "batch_reward": 0.18042541840672494, "critic_loss": 0.5763796064406633, "actor_loss": -23.36525003814697, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.614699363708496, "step": 47000}
{"episode_reward": 293.4572627618544, "episode": 48.0, "batch_reward": 0.18324525314569473, "critic_loss": 0.6804895143806934, "actor_loss": -23.677264324188233, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.689717531204224, "step": 48000}
{"episode_reward": 249.67082830649605, "episode": 49.0, "batch_reward": 0.18335662046074866, "critic_loss": 0.6647481664717197, "actor_loss": -23.81410520553589, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.714223623275757, "step": 49000}
{"episode_reward": 98.96613567238539, "episode": 50.0, "batch_reward": 0.18167896148562432, "critic_loss": 0.6993292944431305, "actor_loss": -23.641724781036377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.210676193237305, "step": 50000}
{"episode_reward": 158.94103805782893, "episode": 51.0, "batch_reward": 0.1819480031579733, "critic_loss": 0.6953371212184429, "actor_loss": -23.91157886123657, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.52780342102051, "step": 51000}
{"episode_reward": 199.1501673908546, "episode": 52.0, "batch_reward": 0.18357240822911264, "critic_loss": 0.6967326474189758, "actor_loss": -24.027867515563965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.690077543258667, "step": 52000}
{"episode_reward": 360.81758646340796, "episode": 53.0, "batch_reward": 0.18708460383117198, "critic_loss": 0.7933841786384582, "actor_loss": -24.632646617889403, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.192405700683594, "step": 53000}
{"episode_reward": 322.1948869350133, "episode": 54.0, "batch_reward": 0.18797274468839167, "critic_loss": 0.7853825159668922, "actor_loss": -24.83460234451294, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.60698366165161, "step": 54000}
{"episode_reward": 302.8711475541543, "episode": 55.0, "batch_reward": 0.19005295991897583, "critic_loss": 0.7520478157401085, "actor_loss": -25.19802381515503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.153319120407104, "step": 55000}
{"episode_reward": 159.89556403146958, "episode": 56.0, "batch_reward": 0.19095601987838745, "critic_loss": 0.7710516522228718, "actor_loss": -25.279071044921874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.437814474105835, "step": 56000}
{"episode_reward": 390.21588410778844, "episode": 57.0, "batch_reward": 0.19282928277552128, "critic_loss": 0.7896668831706047, "actor_loss": -25.593521297454835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.099108457565308, "step": 57000}
{"episode_reward": 281.2353462287829, "episode": 58.0, "batch_reward": 0.19501355716586113, "critic_loss": 0.8347610439956188, "actor_loss": -25.76574186325073, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.64531707763672, "step": 58000}
{"episode_reward": 218.93802690476923, "episode": 59.0, "batch_reward": 0.19626675958931447, "critic_loss": 0.8378257785439491, "actor_loss": -25.98376763534546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.148592472076416, "step": 59000}
{"episode_reward": 320.4260231825018, "episode": 60.0, "batch_reward": 0.19866051518917083, "critic_loss": 0.9114837440252304, "actor_loss": -26.25075238800049, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.470557689666748, "step": 60000}
{"episode_reward": 380.29536008590804, "episode": 61.0, "batch_reward": 0.19849272127449513, "critic_loss": 0.847084987193346, "actor_loss": -26.415328372955322, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.51879358291626, "step": 61000}
{"episode_reward": 101.64119068805806, "episode": 62.0, "batch_reward": 0.1989092541784048, "critic_loss": 0.8971794413924217, "actor_loss": -26.458955333709717, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.03424048423767, "step": 62000}
{"episode_reward": 307.2423794129334, "episode": 63.0, "batch_reward": 0.20165556299686432, "critic_loss": 0.8595526516735553, "actor_loss": -26.707704971313476, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.69437074661255, "step": 63000}
{"episode_reward": 255.13883262700722, "episode": 64.0, "batch_reward": 0.20176783756911754, "critic_loss": 0.9059071100354195, "actor_loss": -26.81294275665283, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.802217721939087, "step": 64000}
{"episode_reward": 356.0431430299148, "episode": 65.0, "batch_reward": 0.20526228511333466, "critic_loss": 0.9159969841241836, "actor_loss": -27.170970966339112, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.60520601272583, "step": 65000}
{"episode_reward": 372.838005373121, "episode": 66.0, "batch_reward": 0.20680881218612193, "critic_loss": 0.8816505534648895, "actor_loss": -27.218680519104005, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.744659662246704, "step": 66000}
{"episode_reward": 386.2629335542896, "episode": 67.0, "batch_reward": 0.20993379418551922, "critic_loss": 0.9273776199221611, "actor_loss": -27.586150802612305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.447235345840454, "step": 67000}
{"episode_reward": 385.4177073443777, "episode": 68.0, "batch_reward": 0.21151477286219597, "critic_loss": 0.800121788173914, "actor_loss": -27.70198411178589, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.63698101043701, "step": 68000}
{"episode_reward": 159.7199985112417, "episode": 69.0, "batch_reward": 0.21215213847160339, "critic_loss": 0.8051120564341545, "actor_loss": -27.649729751586914, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.637812852859497, "step": 69000}
{"episode_reward": 346.41291303935327, "episode": 70.0, "batch_reward": 0.21391865718364717, "critic_loss": 0.8642725802361965, "actor_loss": -28.001349811553954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.19736671447754, "step": 70000}
{"episode_reward": 345.339152712728, "episode": 71.0, "batch_reward": 0.21616761095821857, "critic_loss": 0.9454520955681801, "actor_loss": -27.892950428009033, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.03779482841492, "step": 71000}
{"episode_reward": 240.36254092323037, "episode": 72.0, "batch_reward": 0.2151407273709774, "critic_loss": 0.9067326488792896, "actor_loss": -27.88420615386963, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.647108554840088, "step": 72000}
{"episode_reward": 204.89872891332215, "episode": 73.0, "batch_reward": 0.21594500736892222, "critic_loss": 0.9013807384669781, "actor_loss": -27.870697620391844, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.262256622314453, "step": 73000}
{"episode_reward": 288.597880664825, "episode": 74.0, "batch_reward": 0.2151054639518261, "critic_loss": 0.8910315096974373, "actor_loss": -27.7868867225647, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.456644296646118, "step": 74000}
{"episode_reward": 151.22873384638174, "episode": 75.0, "batch_reward": 0.2165218117237091, "critic_loss": 0.8693748797476292, "actor_loss": -27.7036608505249, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.623541593551636, "step": 75000}
{"episode_reward": 273.4271147397215, "episode": 76.0, "batch_reward": 0.21617059127986432, "critic_loss": 0.9318177493214608, "actor_loss": -27.608353664398194, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.863078594207764, "step": 76000}
{"episode_reward": 243.593356534065, "episode": 77.0, "batch_reward": 0.2173944847136736, "critic_loss": 0.8755635259747505, "actor_loss": -27.830642192840575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.73316240310669, "step": 77000}
{"episode_reward": 378.7266851203728, "episode": 78.0, "batch_reward": 0.21923568423092366, "critic_loss": 0.8434623760581017, "actor_loss": -27.935553863525392, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.178056478500366, "step": 78000}
{"episode_reward": 398.42522977932236, "episode": 79.0, "batch_reward": 0.22162850433588027, "critic_loss": 0.8167035675048828, "actor_loss": -28.013433906555175, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.649746894836426, "step": 79000}
{"episode_reward": 288.00720624430926, "episode": 80.0, "batch_reward": 0.22267500990629197, "critic_loss": 0.7929594595730305, "actor_loss": -28.25949203872681, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.107596397399902, "step": 80000}
{"episode_reward": 395.49914615122174, "episode": 81.0, "batch_reward": 0.22465903887152672, "critic_loss": 0.7699784032404423, "actor_loss": -28.290920459747316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.46721816062927, "step": 81000}
{"episode_reward": 437.7456623028914, "episode": 82.0, "batch_reward": 0.22748612754046918, "critic_loss": 0.749442844569683, "actor_loss": -28.4762557182312, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.67285418510437, "step": 82000}
{"episode_reward": 423.3447127974329, "episode": 83.0, "batch_reward": 0.2296906090825796, "critic_loss": 0.7517218153476715, "actor_loss": -28.614626865386963, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.624719619750977, "step": 83000}
{"episode_reward": 436.4505147619104, "episode": 84.0, "batch_reward": 0.23119597019255161, "critic_loss": 0.691003304630518, "actor_loss": -28.687426418304444, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.034838438034058, "step": 84000}
{"episode_reward": 455.196673181515, "episode": 85.0, "batch_reward": 0.23454873859882355, "critic_loss": 0.6845869892835617, "actor_loss": -28.914756088256837, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.18809700012207, "step": 85000}
{"episode_reward": 486.15244774880574, "episode": 86.0, "batch_reward": 0.2369654161185026, "critic_loss": 0.6762020125985145, "actor_loss": -29.103357540130617, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.16917634010315, "step": 86000}
{"episode_reward": 218.06914140647015, "episode": 87.0, "batch_reward": 0.23831245282292365, "critic_loss": 0.6309099901914597, "actor_loss": -29.077464157104494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.159090757369995, "step": 87000}
{"episode_reward": 516.9251264436012, "episode": 88.0, "batch_reward": 0.24062951405346394, "critic_loss": 0.6135208116471768, "actor_loss": -29.300000701904295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.187657356262207, "step": 88000}
{"episode_reward": 255.7404647938529, "episode": 89.0, "batch_reward": 0.24163893496990205, "critic_loss": 0.6050310792773962, "actor_loss": -29.28852368545532, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.19785189628601, "step": 89000}
{"episode_reward": 429.98964383602845, "episode": 90.0, "batch_reward": 0.2423047559261322, "critic_loss": 0.6123381022959947, "actor_loss": -29.281154552459718, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.170044660568237, "step": 90000}
{"episode_reward": 282.55700140153476, "episode": 91.0, "batch_reward": 0.24339073482155799, "critic_loss": 0.5699684140384197, "actor_loss": -29.349981132507324, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.749979734420776, "step": 91000}
{"episode_reward": 434.44063308452746, "episode": 92.0, "batch_reward": 0.24379699571430682, "critic_loss": 0.5766727947890758, "actor_loss": -29.259908168792723, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.16836714744568, "step": 92000}
{"episode_reward": 160.2233467174557, "episode": 93.0, "batch_reward": 0.24416349732875825, "critic_loss": 0.5412843633294105, "actor_loss": -29.206792533874513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.203099012374878, "step": 93000}
{"episode_reward": 262.88990324166963, "episode": 94.0, "batch_reward": 0.24455977675318719, "critic_loss": 0.5924527491629124, "actor_loss": -29.122167823791504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.204481840133667, "step": 94000}
{"episode_reward": 248.04801642749698, "episode": 95.0, "batch_reward": 0.24478152506053447, "critic_loss": 0.6122294150441885, "actor_loss": -29.200724925994873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.15383219718933, "step": 95000}
{"episode_reward": 530.1410723143299, "episode": 96.0, "batch_reward": 0.24792743909358977, "critic_loss": 0.5668313441574574, "actor_loss": -29.402686599731446, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.177685022354126, "step": 96000}
{"episode_reward": 232.16290644904296, "episode": 97.0, "batch_reward": 0.24717518888413906, "critic_loss": 0.5900335481315852, "actor_loss": -29.197839302062988, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.20680022239685, "step": 97000}
{"episode_reward": 466.70722322949763, "episode": 98.0, "batch_reward": 0.2508811266720295, "critic_loss": 0.6160186193585396, "actor_loss": -29.505316665649413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.146563291549683, "step": 98000}
{"episode_reward": 394.09462162001887, "episode": 99.0, "batch_reward": 0.24945350363850594, "critic_loss": 0.6253860661387444, "actor_loss": -29.255327388763426, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.17960262298584, "step": 99000}
{"episode_reward": 220.43998384630308, "episode": 100.0, "batch_reward": 0.25118287628889086, "critic_loss": 0.5762825331389904, "actor_loss": -29.380445697784424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.194926500320435, "step": 100000}
{"episode_reward": 242.46227674530064, "episode": 101.0, "batch_reward": 0.2512533795386553, "critic_loss": 0.5679309752136469, "actor_loss": -29.29537759399414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.738178968429565, "step": 101000}
{"episode_reward": 355.14237249504083, "episode": 102.0, "batch_reward": 0.2520411016345024, "critic_loss": 0.5753887821733952, "actor_loss": -29.38550298309326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.185964584350586, "step": 102000}
{"episode_reward": 539.1462360341878, "episode": 103.0, "batch_reward": 0.25474551823735236, "critic_loss": 0.5371201045811176, "actor_loss": -29.340233158111573, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.19707465171814, "step": 103000}
{"episode_reward": 318.3055394824424, "episode": 104.0, "batch_reward": 0.25614567670226096, "critic_loss": 0.5344622990041972, "actor_loss": -29.521916358947752, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.171003818511963, "step": 104000}
{"episode_reward": 427.6788808548896, "episode": 105.0, "batch_reward": 0.256444511115551, "critic_loss": 0.5343527281433343, "actor_loss": -29.44057117462158, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.174681901931763, "step": 105000}
{"episode_reward": 212.2028317508874, "episode": 106.0, "batch_reward": 0.2565993469953537, "critic_loss": 0.5778608139008283, "actor_loss": -29.381832004547118, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.20022964477539, "step": 106000}
{"episode_reward": 554.9798287047857, "episode": 107.0, "batch_reward": 0.2591040329039097, "critic_loss": 0.5074492067694664, "actor_loss": -29.540888252258302, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.174837112426758, "step": 107000}
{"episode_reward": 551.8243101277485, "episode": 108.0, "batch_reward": 0.2618717525601387, "critic_loss": 0.5118969354182482, "actor_loss": -29.78179277420044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.17881965637207, "step": 108000}
{"episode_reward": 347.0348276064925, "episode": 109.0, "batch_reward": 0.2622943432182074, "critic_loss": 0.5078379023969174, "actor_loss": -29.820198394775392, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.199839115142822, "step": 109000}
{"episode_reward": 181.40574855978147, "episode": 110.0, "batch_reward": 0.2625874898731709, "critic_loss": 0.5220944311916829, "actor_loss": -29.76448007965088, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.179300785064697, "step": 110000}
{"episode_reward": 495.1869031819924, "episode": 111.0, "batch_reward": 0.26618532785773275, "critic_loss": 0.5198705295473337, "actor_loss": -29.939762020111083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.65525770187378, "step": 111000}
{"episode_reward": 647.1682283019367, "episode": 112.0, "batch_reward": 0.26807091292738916, "critic_loss": 0.5097254047691822, "actor_loss": -30.025867473602293, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.1971492767334, "step": 112000}
{"episode_reward": 577.2400707088321, "episode": 113.0, "batch_reward": 0.2707301035374403, "critic_loss": 0.5143615251332522, "actor_loss": -30.09623503112793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.167317628860474, "step": 113000}
{"episode_reward": 554.8913616961823, "episode": 114.0, "batch_reward": 0.27398600994050504, "critic_loss": 0.4870571186244488, "actor_loss": -30.409082218170166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.169769525527954, "step": 114000}
{"episode_reward": 551.6454415120423, "episode": 115.0, "batch_reward": 0.27602829979360105, "critic_loss": 0.46834913378953935, "actor_loss": -30.69514193344116, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.166115283966064, "step": 115000}
{"episode_reward": 559.3206282494585, "episode": 116.0, "batch_reward": 0.2780930727124214, "critic_loss": 0.4896903157234192, "actor_loss": -30.67505118179321, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.143782138824463, "step": 116000}
{"episode_reward": 591.0559494492226, "episode": 117.0, "batch_reward": 0.2804689419865608, "critic_loss": 0.4719234614521265, "actor_loss": -30.90946179962158, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.168707132339478, "step": 117000}
{"episode_reward": 549.5905148888828, "episode": 118.0, "batch_reward": 0.2829702067375183, "critic_loss": 0.48269834016263485, "actor_loss": -30.97519928741455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.18708062171936, "step": 118000}
{"episode_reward": 531.655989440302, "episode": 119.0, "batch_reward": 0.2850002793669701, "critic_loss": 0.47272938407957554, "actor_loss": -31.11566943359375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.12279987335205, "step": 119000}
{"episode_reward": 553.9809602994883, "episode": 120.0, "batch_reward": 0.28741623216867446, "critic_loss": 0.4809012791216373, "actor_loss": -31.487690158843993, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.16221594810486, "step": 120000}
{"episode_reward": 580.849320859117, "episode": 121.0, "batch_reward": 0.29110903045535086, "critic_loss": 0.4562741282880306, "actor_loss": -31.642728672027587, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.70744299888611, "step": 121000}
{"episode_reward": 619.0280145078153, "episode": 122.0, "batch_reward": 0.29354535438120366, "critic_loss": 0.4545360894203186, "actor_loss": -31.926092712402344, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.17792797088623, "step": 122000}
{"episode_reward": 602.8781622161054, "episode": 123.0, "batch_reward": 0.2958895830065012, "critic_loss": 0.42899978810548783, "actor_loss": -32.142940540313724, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.1533203125, "step": 123000}
{"episode_reward": 631.2531866935947, "episode": 124.0, "batch_reward": 0.29815357652306557, "critic_loss": 0.44157425802946093, "actor_loss": -32.35908354568481, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.169356107711792, "step": 124000}
{"episode_reward": 534.8024884344225, "episode": 125.0, "batch_reward": 0.2994172775298357, "critic_loss": 0.43851320472359656, "actor_loss": -32.224601146698, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.191460132598877, "step": 125000}
{"episode_reward": 591.8593064726817, "episode": 126.0, "batch_reward": 0.3027775208503008, "critic_loss": 0.4606123366653919, "actor_loss": -32.59824852371216, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.174984455108643, "step": 126000}
{"episode_reward": 644.2331262323974, "episode": 127.0, "batch_reward": 0.30538302947580814, "critic_loss": 0.45291516290605066, "actor_loss": -32.82930603790283, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.23574471473694, "step": 127000}
{"episode_reward": 590.0666244885111, "episode": 128.0, "batch_reward": 0.30767900629341605, "critic_loss": 0.4239777978211641, "actor_loss": -32.825993923187255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.49080491065979, "step": 128000}
{"episode_reward": 650.3955607025409, "episode": 129.0, "batch_reward": 0.30930070470273496, "critic_loss": 0.41021119499206543, "actor_loss": -33.048637130737305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.16902780532837, "step": 129000}
{"episode_reward": 626.6584115707174, "episode": 130.0, "batch_reward": 0.3128159529864788, "critic_loss": 0.41630241176486016, "actor_loss": -33.399937408447265, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.150546073913574, "step": 130000}
{"episode_reward": 379.9815700590099, "episode": 131.0, "batch_reward": 0.3117210582196713, "critic_loss": 0.40211600077152254, "actor_loss": -33.03093377304077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.66443061828613, "step": 131000}
{"episode_reward": 616.7743216202049, "episode": 132.0, "batch_reward": 0.31484544852375984, "critic_loss": 0.4001597354710102, "actor_loss": -33.561223148345945, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.187446355819702, "step": 132000}
{"episode_reward": 575.4262798676493, "episode": 133.0, "batch_reward": 0.3162726242095232, "critic_loss": 0.3954204199612141, "actor_loss": -33.622336540222165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.192916870117188, "step": 133000}
{"episode_reward": 638.4584431082624, "episode": 134.0, "batch_reward": 0.3194686607122421, "critic_loss": 0.4293773217499256, "actor_loss": -33.96752195739746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.18395185470581, "step": 134000}
{"episode_reward": 617.6334495812124, "episode": 135.0, "batch_reward": 0.32161370489001273, "critic_loss": 0.42340285928547383, "actor_loss": -34.081428909301756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.216725826263428, "step": 135000}
{"episode_reward": 581.964262973421, "episode": 136.0, "batch_reward": 0.322559555888176, "critic_loss": 0.4369444068819284, "actor_loss": -34.147617614746096, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.20707106590271, "step": 136000}
{"episode_reward": 569.1606895485422, "episode": 137.0, "batch_reward": 0.32558391040563583, "critic_loss": 0.4457934305667877, "actor_loss": -34.55897745513916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.164599418640137, "step": 137000}
{"episode_reward": 354.88916694567547, "episode": 138.0, "batch_reward": 0.32545696797966955, "critic_loss": 0.4098457514494658, "actor_loss": -34.29703772354126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.222583770751953, "step": 138000}
{"episode_reward": 651.1469661791508, "episode": 139.0, "batch_reward": 0.3276143499016762, "critic_loss": 0.41277917432785033, "actor_loss": -34.53035584259033, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.202357530593872, "step": 139000}
{"episode_reward": 581.761134437372, "episode": 140.0, "batch_reward": 0.3301364024579525, "critic_loss": 0.42082930006086827, "actor_loss": -34.7240546951294, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.18026638031006, "step": 140000}
{"episode_reward": 676.9580196102806, "episode": 141.0, "batch_reward": 0.33225934532284734, "critic_loss": 0.42660589453577996, "actor_loss": -34.964658332824705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.745051860809326, "step": 141000}
{"episode_reward": 565.7569996882002, "episode": 142.0, "batch_reward": 0.33390020617842675, "critic_loss": 0.42548852163553236, "actor_loss": -35.15529052734375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.166844606399536, "step": 142000}
{"episode_reward": 604.2399049659151, "episode": 143.0, "batch_reward": 0.33639362654089927, "critic_loss": 0.42141281396150587, "actor_loss": -35.317495529174806, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.203924655914307, "step": 143000}
{"episode_reward": 680.9909895556517, "episode": 144.0, "batch_reward": 0.33904010885953906, "critic_loss": 0.4051011206358671, "actor_loss": -35.65510734939575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.18953514099121, "step": 144000}
{"episode_reward": 620.5302380310546, "episode": 145.0, "batch_reward": 0.3406802694797516, "critic_loss": 0.41391246031224727, "actor_loss": -35.84347153091431, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.17212986946106, "step": 145000}
{"episode_reward": 592.4048692512916, "episode": 146.0, "batch_reward": 0.3413854720890522, "critic_loss": 0.40694762794673445, "actor_loss": -35.79262585449219, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.19554114341736, "step": 146000}
{"episode_reward": 622.4509722936676, "episode": 147.0, "batch_reward": 0.3436570518314838, "critic_loss": 0.40205846141278745, "actor_loss": -36.10702403640747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.18162250518799, "step": 147000}
{"episode_reward": 662.9091118467109, "episode": 148.0, "batch_reward": 0.3451289928555489, "critic_loss": 0.40939145028591156, "actor_loss": -36.24593655014038, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.18360185623169, "step": 148000}
{"episode_reward": 601.9371972050377, "episode": 149.0, "batch_reward": 0.34760159701108934, "critic_loss": 0.45488233236968517, "actor_loss": -36.40612422180176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.200307369232178, "step": 149000}
{"episode_reward": 639.958928970791, "episode": 150.0, "batch_reward": 0.3501238932311535, "critic_loss": 0.43671988824009894, "actor_loss": -36.64050716781616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
