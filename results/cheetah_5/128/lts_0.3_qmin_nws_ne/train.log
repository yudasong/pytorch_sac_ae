{"episode_reward": 0.0, "episode": 1.0, "duration": 17.49183177947998, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.5094122886657715, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.25928734460545605, "critic_loss": 0.016354989773920227, "actor_loss": -16.508531756418833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.60260081291199, "step": 3000}
{"episode_reward": 3.995754544472802, "episode": 4.0, "batch_reward": 0.16089550530910493, "critic_loss": 0.012063304747454822, "actor_loss": -16.717147594451905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34386372566223, "step": 4000}
{"episode_reward": 3.356626407735286, "episode": 5.0, "batch_reward": 0.12547877544537187, "critic_loss": 0.011934984779683872, "actor_loss": -15.165719841957092, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.330811738967896, "step": 5000}
{"episode_reward": 3.9507024256526, "episode": 6.0, "batch_reward": 0.1033252779878676, "critic_loss": 0.010916489460971207, "actor_loss": -14.697666167736054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.347952365875244, "step": 6000}
{"episode_reward": 4.042769081820001, "episode": 7.0, "batch_reward": 0.08772168657183647, "critic_loss": 0.011889383018016815, "actor_loss": -13.186011799812317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.343896865844727, "step": 7000}
{"episode_reward": 4.329900533385388, "episode": 8.0, "batch_reward": 0.07693938789144159, "critic_loss": 0.01865849164291285, "actor_loss": -14.882893078327179, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31727647781372, "step": 8000}
{"episode_reward": 4.3276420350082585, "episode": 9.0, "batch_reward": 0.0681316664032638, "critic_loss": 0.009036293414654211, "actor_loss": -13.419581726074219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33442783355713, "step": 9000}
{"episode_reward": 3.03969352328989, "episode": 10.0, "batch_reward": 0.06121610284224153, "critic_loss": 0.016310066020931116, "actor_loss": -13.831776785373687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.333801746368408, "step": 10000}
{"episode_reward": 3.287490509629902, "episode": 11.0, "batch_reward": 0.055090003060176966, "critic_loss": 0.017189091309381184, "actor_loss": -11.963768387794495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.882396936416626, "step": 11000}
{"episode_reward": 2.9198381134492983, "episode": 12.0, "batch_reward": 0.05140407588705421, "critic_loss": 0.010747855789260938, "actor_loss": -13.218639293670654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32113289833069, "step": 12000}
{"episode_reward": 4.581992875402826, "episode": 13.0, "batch_reward": 0.047370244298130276, "critic_loss": 0.013700170737225563, "actor_loss": -12.672021061897278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.351624250411987, "step": 13000}
{"episode_reward": 4.9127206383846955, "episode": 14.0, "batch_reward": 0.04441018338082358, "critic_loss": 0.013385190283530392, "actor_loss": -13.440352365493775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.316385984420776, "step": 14000}
{"episode_reward": 4.857784933183696, "episode": 15.0, "batch_reward": 0.04183178399689495, "critic_loss": 0.01205520347226411, "actor_loss": -13.02975379562378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.332757234573364, "step": 15000}
{"episode_reward": 3.5115091007818835, "episode": 16.0, "batch_reward": 0.03928870973177254, "critic_loss": 0.015952355342684313, "actor_loss": -13.070630306482315, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31528925895691, "step": 16000}
{"episode_reward": 4.345917986213134, "episode": 17.0, "batch_reward": 0.036716652937233446, "critic_loss": 0.013190374890749808, "actor_loss": -12.547887922763824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.316238164901733, "step": 17000}
{"episode_reward": 3.2448751898150254, "episode": 18.0, "batch_reward": 0.0352352501321584, "critic_loss": 0.01357290052989265, "actor_loss": -12.974612681150436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.317690134048462, "step": 18000}
{"episode_reward": 5.603374459720226, "episode": 19.0, "batch_reward": 0.03297431381000206, "critic_loss": 0.012306436144601321, "actor_loss": -12.283469830989837, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.333555221557617, "step": 19000}
{"episode_reward": 4.021737620690432, "episode": 20.0, "batch_reward": 0.03206656673643738, "critic_loss": 0.017345565470808653, "actor_loss": -12.656446773529053, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.330233097076416, "step": 20000}
{"episode_reward": 4.180327609308708, "episode": 21.0, "batch_reward": 0.03069718690076843, "critic_loss": 0.012035025105898966, "actor_loss": -12.073116811990738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.893470287323, "step": 21000}
{"episode_reward": 4.70699913167226, "episode": 22.0, "batch_reward": 0.029242115260101856, "critic_loss": 0.020469321001321077, "actor_loss": -12.162087750673294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.303375959396362, "step": 22000}
{"episode_reward": 3.0142236346254347, "episode": 23.0, "batch_reward": 0.02860811928473413, "critic_loss": 0.012473490713804495, "actor_loss": -11.148811062812806, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30129051208496, "step": 23000}
{"episode_reward": 5.132664070887868, "episode": 24.0, "batch_reward": 0.02731758436001837, "critic_loss": 0.013985356256249361, "actor_loss": -11.300771362543106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.320069074630737, "step": 24000}
{"episode_reward": 3.333098404904294, "episode": 25.0, "batch_reward": 0.025572510657832028, "critic_loss": 0.007997594009328169, "actor_loss": -11.835700698137284, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.287480354309082, "step": 25000}
{"episode_reward": 4.162484080973399, "episode": 26.0, "batch_reward": 0.0253086001558695, "critic_loss": 0.015658998895029072, "actor_loss": -10.954468789815902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.325902223587036, "step": 26000}
{"episode_reward": 3.8027383267309345, "episode": 27.0, "batch_reward": 0.024482965105911716, "critic_loss": 0.01962186501341057, "actor_loss": -11.199808090209961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3115975856781, "step": 27000}
{"episode_reward": 5.137605534767983, "episode": 28.0, "batch_reward": 0.02368298318143934, "critic_loss": 0.015078981690952788, "actor_loss": -11.768579290628434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29081964492798, "step": 28000}
{"episode_reward": 4.563236468050862, "episode": 29.0, "batch_reward": 0.023156076924642548, "critic_loss": 0.011561699634068645, "actor_loss": -10.848362512588501, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.294942140579224, "step": 29000}
{"episode_reward": 4.638674637693013, "episode": 30.0, "batch_reward": 0.02243331443378702, "critic_loss": 0.012420835142227589, "actor_loss": -11.17385891711712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31778621673584, "step": 30000}
{"episode_reward": 4.0845868892856725, "episode": 31.0, "batch_reward": 0.02222526718559675, "critic_loss": 0.014529813295957865, "actor_loss": -11.90947138941288, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.81482148170471, "step": 31000}
{"episode_reward": 4.9530036191622875, "episode": 32.0, "batch_reward": 0.021272001532139255, "critic_loss": 0.014491558440524386, "actor_loss": -10.768284559845924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32029104232788, "step": 32000}
{"episode_reward": 4.899253401296246, "episode": 33.0, "batch_reward": 0.020294351049000396, "critic_loss": 0.017534752941312036, "actor_loss": -11.297199841737747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.302164316177368, "step": 33000}
{"episode_reward": 3.784115648427563, "episode": 34.0, "batch_reward": 0.02046963475132361, "critic_loss": 0.020628087174583924, "actor_loss": -11.90727210187912, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31298279762268, "step": 34000}
{"episode_reward": 4.531109082775917, "episode": 35.0, "batch_reward": 0.019881249783560633, "critic_loss": 0.015577483101573307, "actor_loss": -10.85201360297203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33534836769104, "step": 35000}
{"episode_reward": 3.53866570278621, "episode": 36.0, "batch_reward": 0.01941165332798846, "critic_loss": 0.018216482101619476, "actor_loss": -11.660281333088875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.286028623580933, "step": 36000}
{"episode_reward": 3.901154614561805, "episode": 37.0, "batch_reward": 0.01902511580637656, "critic_loss": 0.01513525806265534, "actor_loss": -10.863529801130294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.326110124588013, "step": 37000}
{"episode_reward": 3.0548029198618423, "episode": 38.0, "batch_reward": 0.01916207137866877, "critic_loss": 0.014978791012545116, "actor_loss": -10.089266834497451, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33961796760559, "step": 38000}
{"episode_reward": 4.692116907772766, "episode": 39.0, "batch_reward": 0.01843503723316826, "critic_loss": 0.01739384171705751, "actor_loss": -11.078643240928649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.300491333007812, "step": 39000}
{"episode_reward": 3.8643013333167646, "episode": 40.0, "batch_reward": 0.01802745528728701, "critic_loss": 0.020219988582044608, "actor_loss": -11.988552946686745, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3075270652771, "step": 40000}
{"episode_reward": 3.432084650201287, "episode": 41.0, "batch_reward": 0.017906058459775522, "critic_loss": 0.02579337300284533, "actor_loss": -11.637619974732399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.88238883018494, "step": 41000}
{"episode_reward": 4.925520778477796, "episode": 42.0, "batch_reward": 0.017163405113853513, "critic_loss": 0.017798343594316975, "actor_loss": -11.409988233327866, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32010555267334, "step": 42000}
{"episode_reward": 4.143884034957983, "episode": 43.0, "batch_reward": 0.017168872724752874, "critic_loss": 0.014563911654346158, "actor_loss": -11.242896065592765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.312923669815063, "step": 43000}
{"episode_reward": 5.205964936809354, "episode": 44.0, "batch_reward": 0.01667159916763194, "critic_loss": 0.027846628405532103, "actor_loss": -11.14057647383213, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.299727201461792, "step": 44000}
{"episode_reward": 2.9927862764255075, "episode": 45.0, "batch_reward": 0.016455187186598778, "critic_loss": 0.014169398785321391, "actor_loss": -10.027098278522491, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.325777292251587, "step": 45000}
{"episode_reward": 3.253173279967122, "episode": 46.0, "batch_reward": 0.016337199615780264, "critic_loss": 0.017962437749200037, "actor_loss": -9.536929497480392, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33016085624695, "step": 46000}
{"episode_reward": 5.0581770952757985, "episode": 47.0, "batch_reward": 0.015669841968920083, "critic_loss": 0.018589305425499334, "actor_loss": -10.884263304710387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.314130544662476, "step": 47000}
{"episode_reward": 4.451085624216128, "episode": 48.0, "batch_reward": 0.015736492014722898, "critic_loss": 0.017667719495599157, "actor_loss": -10.518538106143474, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.313047170639038, "step": 48000}
{"episode_reward": 4.114059533094726, "episode": 49.0, "batch_reward": 0.01562902441713959, "critic_loss": 0.017315329644581653, "actor_loss": -10.688432795345783, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.324740648269653, "step": 49000}
{"episode_reward": 4.4068522546974105, "episode": 50.0, "batch_reward": 0.014775380237028003, "critic_loss": 0.017292751180473714, "actor_loss": -10.683445750892162, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.318865299224854, "step": 50000}
{"episode_reward": 3.634508351695348, "episode": 51.0, "batch_reward": 0.014778782611247153, "critic_loss": 0.018907266336202155, "actor_loss": -9.928604882717133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.91709613800049, "step": 51000}
{"episode_reward": 5.6839334485518735, "episode": 52.0, "batch_reward": 0.014634252491872758, "critic_loss": 0.020872478809964377, "actor_loss": -9.875269552767277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.327346086502075, "step": 52000}
{"episode_reward": 4.190222122807493, "episode": 53.0, "batch_reward": 0.014795460023451596, "critic_loss": 0.01734940106033173, "actor_loss": -10.834423599541187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.313907384872437, "step": 53000}
{"episode_reward": 3.288384800857606, "episode": 54.0, "batch_reward": 0.013881702456390485, "critic_loss": 0.019422848855232586, "actor_loss": -10.454657139658927, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.319631576538086, "step": 54000}
{"episode_reward": 3.664965124942325, "episode": 55.0, "batch_reward": 0.013861048335442319, "critic_loss": 0.017798784245795105, "actor_loss": -10.760567931175231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32328200340271, "step": 55000}
{"episode_reward": 2.3025105580569205, "episode": 56.0, "batch_reward": 0.013906521891010925, "critic_loss": 0.02190566552193195, "actor_loss": -11.121587393403054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.343566417694092, "step": 56000}
{"episode_reward": 4.556239153712526, "episode": 57.0, "batch_reward": 0.013413888939889148, "critic_loss": 0.017309660074330168, "actor_loss": -10.635702363014222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.324605703353882, "step": 57000}
{"episode_reward": 2.104050922986515, "episode": 58.0, "batch_reward": 0.01323813114198856, "critic_loss": 0.024063518961775117, "actor_loss": -11.389058818161487, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.320828199386597, "step": 58000}
{"episode_reward": 5.463823623844105, "episode": 59.0, "batch_reward": 0.013307022555964068, "critic_loss": 0.014333088706698617, "actor_loss": -11.181960001409054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.353779315948486, "step": 59000}
{"episode_reward": 3.6954984892005496, "episode": 60.0, "batch_reward": 0.013263132135849447, "critic_loss": 0.015792954044904037, "actor_loss": -9.764568427205086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.351759672164917, "step": 60000}
{"episode_reward": 5.393990699146868, "episode": 61.0, "batch_reward": 0.01280169019033201, "critic_loss": 0.018332188394590047, "actor_loss": -10.365120478272438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.92177367210388, "step": 61000}
{"episode_reward": 5.251543041920565, "episode": 62.0, "batch_reward": 0.01301976483175531, "critic_loss": 0.020458083324643668, "actor_loss": -9.340338262140751, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.307540893554688, "step": 62000}
{"episode_reward": 4.78206588056672, "episode": 63.0, "batch_reward": 0.012831270543159917, "critic_loss": 0.016798350493292674, "actor_loss": -10.519151071041822, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.341402292251587, "step": 63000}
{"episode_reward": 3.55063013862277, "episode": 64.0, "batch_reward": 0.012604577575111763, "critic_loss": 0.031729543035806274, "actor_loss": -11.465186712384224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.343873500823975, "step": 64000}
{"episode_reward": 4.340182024825121, "episode": 65.0, "batch_reward": 0.012558223858475685, "critic_loss": 0.01550188443280058, "actor_loss": -10.750953887045384, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31101965904236, "step": 65000}
{"episode_reward": 2.2671538689012185, "episode": 66.0, "batch_reward": 0.012233526099706068, "critic_loss": 0.016177803277081692, "actor_loss": -10.003716182380915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35474967956543, "step": 66000}
{"episode_reward": 3.0948868865839754, "episode": 67.0, "batch_reward": 0.01233469343627803, "critic_loss": 0.02605528295849217, "actor_loss": -10.243758528709412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.311158657073975, "step": 67000}
{"episode_reward": 3.4994023885829426, "episode": 68.0, "batch_reward": 0.012218785203294828, "critic_loss": 0.019627920829574576, "actor_loss": -10.505667643219233, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.323529481887817, "step": 68000}
{"episode_reward": 4.398167217473214, "episode": 69.0, "batch_reward": 0.012157651441171766, "critic_loss": 0.015554164380664587, "actor_loss": -10.148278585910797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3349609375, "step": 69000}
{"episode_reward": 6.234747830926674, "episode": 70.0, "batch_reward": 0.012015051068039611, "critic_loss": 0.02070456664748781, "actor_loss": -9.343806946069002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.330207586288452, "step": 70000}
{"episode_reward": 5.3657817197749385, "episode": 71.0, "batch_reward": 0.011897803439525888, "critic_loss": 0.017542687362540162, "actor_loss": -9.850404734402895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.864757776260376, "step": 71000}
{"episode_reward": 2.5074633147292786, "episode": 72.0, "batch_reward": 0.011504187090788036, "critic_loss": 0.020003394723658856, "actor_loss": -9.076330530762672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.319649696350098, "step": 72000}
{"episode_reward": 5.149617997293766, "episode": 73.0, "batch_reward": 0.011555935619864613, "critic_loss": 0.018803925059903123, "actor_loss": -10.497050042510033, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.298479080200195, "step": 73000}
{"episode_reward": 4.27760719319912, "episode": 74.0, "batch_reward": 0.011238946923054756, "critic_loss": 0.02053016871803993, "actor_loss": -10.076490513980389, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.304129600524902, "step": 74000}
{"episode_reward": 2.9607569420080493, "episode": 75.0, "batch_reward": 0.011388536169426516, "critic_loss": 0.021368593382489053, "actor_loss": -10.620679622918367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.385645866394043, "step": 75000}
{"episode_reward": 3.0530832632328933, "episode": 76.0, "batch_reward": 0.01125451754196547, "critic_loss": 0.016880289249616907, "actor_loss": -11.05130811932683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.56148409843445, "step": 76000}
{"episode_reward": 2.8795094124681717, "episode": 77.0, "batch_reward": 0.011184041191823781, "critic_loss": 0.013724745702245855, "actor_loss": -10.771039577484132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29221272468567, "step": 77000}
{"episode_reward": 4.907655518040511, "episode": 78.0, "batch_reward": 0.01080389076611027, "critic_loss": 0.012681427397394146, "actor_loss": -9.747268739551306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26177215576172, "step": 78000}
{"episode_reward": 3.5662462670630077, "episode": 79.0, "batch_reward": 0.010789445453323424, "critic_loss": 0.011551874691533157, "actor_loss": -10.643559910923242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28900408744812, "step": 79000}
{"episode_reward": 5.691224522950289, "episode": 80.0, "batch_reward": 0.011210709764389322, "critic_loss": 0.01289966246001859, "actor_loss": -10.464525325119496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.347180128097534, "step": 80000}
{"episode_reward": 3.139684550263187, "episode": 81.0, "batch_reward": 0.010724045072682202, "critic_loss": 0.009520269937245758, "actor_loss": -10.15060173341632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.80003333091736, "step": 81000}
{"episode_reward": 2.925306957041883, "episode": 82.0, "batch_reward": 0.01082974746171385, "critic_loss": 0.011576108194421977, "actor_loss": -11.118968335092069, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.313512802124023, "step": 82000}
{"episode_reward": 3.0166336962340505, "episode": 83.0, "batch_reward": 0.01066733319684863, "critic_loss": 0.01099296304006566, "actor_loss": -8.99402901956439, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32727837562561, "step": 83000}
{"episode_reward": 4.203321245080132, "episode": 84.0, "batch_reward": 0.010559478517621755, "critic_loss": 0.011221868029257166, "actor_loss": -10.093878031104802, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.297186374664307, "step": 84000}
{"episode_reward": 3.638721962137279, "episode": 85.0, "batch_reward": 0.010402930810349062, "critic_loss": 0.008972934061363048, "actor_loss": -10.007631880521775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.326475858688354, "step": 85000}
{"episode_reward": 5.213414897480896, "episode": 86.0, "batch_reward": 0.010634426929755136, "critic_loss": 0.010555561874709383, "actor_loss": -10.623380519926547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.352062702178955, "step": 86000}
{"episode_reward": 3.2818144502368183, "episode": 87.0, "batch_reward": 0.010652503454592078, "critic_loss": 0.00928066739514179, "actor_loss": -9.716730595588684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.309114456176758, "step": 87000}
{"episode_reward": 4.364341775008186, "episode": 88.0, "batch_reward": 0.010317186139291152, "critic_loss": 0.008863698327622842, "actor_loss": -9.627228696808219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.294308185577393, "step": 88000}
{"episode_reward": 3.123889378118446, "episode": 89.0, "batch_reward": 0.01025899522099644, "critic_loss": 0.008203031175165961, "actor_loss": -9.772510427221656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.343122482299805, "step": 89000}
{"episode_reward": 3.746969109966964, "episode": 90.0, "batch_reward": 0.01016685388260521, "critic_loss": 0.01151396368805581, "actor_loss": -10.56016238926351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29908514022827, "step": 90000}
{"episode_reward": 3.2687068326514934, "episode": 91.0, "batch_reward": 0.01018334208521992, "critic_loss": 0.006685726050222001, "actor_loss": -10.356089476242662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.87361145019531, "step": 91000}
{"episode_reward": 3.576056440074849, "episode": 92.0, "batch_reward": 0.010016039560316131, "critic_loss": 0.011770499035374088, "actor_loss": -8.924443942159414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3065505027771, "step": 92000}
{"episode_reward": 4.833653809498333, "episode": 93.0, "batch_reward": 0.0100735153532587, "critic_loss": 0.01078692611209408, "actor_loss": -9.639429241985082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30665349960327, "step": 93000}
{"episode_reward": 5.224639873663077, "episode": 94.0, "batch_reward": 0.010132708358345554, "critic_loss": 0.01633152984010303, "actor_loss": -8.880629786461592, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31281852722168, "step": 94000}
{"episode_reward": 5.541232043569229, "episode": 95.0, "batch_reward": 0.010074189627310262, "critic_loss": 0.009164654180247454, "actor_loss": -10.138245124161243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29063606262207, "step": 95000}
{"episode_reward": 3.75727538056695, "episode": 96.0, "batch_reward": 0.00969970819959417, "critic_loss": 0.007883823806841973, "actor_loss": -9.58756051710248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.335836172103882, "step": 96000}
{"episode_reward": 5.251353007444579, "episode": 97.0, "batch_reward": 0.00973177000368014, "critic_loss": 0.015528543436783365, "actor_loss": -10.94357395684719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32236886024475, "step": 97000}
{"episode_reward": 3.878469360123106, "episode": 98.0, "batch_reward": 0.01000293524726294, "critic_loss": 0.011862146968895104, "actor_loss": -11.560615684270859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28688907623291, "step": 98000}
{"episode_reward": 4.478757395300441, "episode": 99.0, "batch_reward": 0.009632364806719125, "critic_loss": 0.010593002711881126, "actor_loss": -10.135724312484264, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.312933206558228, "step": 99000}
{"episode_reward": 2.9267073853284824, "episode": 100.0, "batch_reward": 0.009506303227040916, "critic_loss": 0.014136390506442694, "actor_loss": -9.59263312137127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.71412205696106, "step": 100000}
{"episode_reward": 3.5009904476951106, "episode": 101.0, "batch_reward": 0.00957855783845298, "critic_loss": 0.01525689279868675, "actor_loss": -9.823931039959191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.80812335014343, "step": 101000}
{"episode_reward": 6.545319254680725, "episode": 102.0, "batch_reward": 0.009405357519164681, "critic_loss": 0.01478768937469431, "actor_loss": -10.144686508148908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.309157371520996, "step": 102000}
{"episode_reward": 2.885203948051754, "episode": 103.0, "batch_reward": 0.009332706299377606, "critic_loss": 0.014187746029339905, "actor_loss": -9.292415546819567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.296979427337646, "step": 103000}
{"episode_reward": 3.614790042079552, "episode": 104.0, "batch_reward": 0.009390800699125975, "critic_loss": 0.016552371494741237, "actor_loss": -10.667589274168014, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.303972721099854, "step": 104000}
{"episode_reward": 2.7698625591881036, "episode": 105.0, "batch_reward": 0.009359616642119362, "critic_loss": 0.01658399765045033, "actor_loss": -8.81371119683981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31396198272705, "step": 105000}
{"episode_reward": 2.861648532599971, "episode": 106.0, "batch_reward": 0.009033577625406906, "critic_loss": 0.01754267920451093, "actor_loss": -9.6525576569885, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.289018630981445, "step": 106000}
{"episode_reward": 3.779655625018175, "episode": 107.0, "batch_reward": 0.008952372004278003, "critic_loss": 0.01791120227348438, "actor_loss": -9.740241261422634, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.321344137191772, "step": 107000}
{"episode_reward": 3.7206675838545835, "episode": 108.0, "batch_reward": 0.009073593648383393, "critic_loss": 0.00937603822726669, "actor_loss": -9.818263306960464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.304051637649536, "step": 108000}
{"episode_reward": 3.595770079708018, "episode": 109.0, "batch_reward": 0.009212149815866724, "critic_loss": 0.019573198679747293, "actor_loss": -11.165028216823936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2996563911438, "step": 109000}
{"episode_reward": 3.5219821161231173, "episode": 110.0, "batch_reward": 0.009243588753510267, "critic_loss": 0.014737898222287186, "actor_loss": -10.786527550965548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31224250793457, "step": 110000}
{"episode_reward": 3.0224408192120107, "episode": 111.0, "batch_reward": 0.00885391667461954, "critic_loss": 0.014809408928689663, "actor_loss": -9.613876993849873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.81513476371765, "step": 111000}
{"episode_reward": 3.4499154060722814, "episode": 112.0, "batch_reward": 0.009137656747130678, "critic_loss": 0.013537260622688336, "actor_loss": -9.297866303578019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.307672023773193, "step": 112000}
{"episode_reward": 2.338105471425729, "episode": 113.0, "batch_reward": 0.008670281157596037, "critic_loss": 0.015622641465000925, "actor_loss": -8.46652596412599, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.301242351531982, "step": 113000}
{"episode_reward": 4.94969684436333, "episode": 114.0, "batch_reward": 0.008906002535950393, "critic_loss": 0.013737961098559025, "actor_loss": -10.414737147822976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.308061838150024, "step": 114000}
{"episode_reward": 3.2589757501972896, "episode": 115.0, "batch_reward": 0.008697949587134645, "critic_loss": 0.011241482501580321, "actor_loss": -10.129122734844685, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27350926399231, "step": 115000}
{"episode_reward": 5.268860466651662, "episode": 116.0, "batch_reward": 0.00852367008291185, "critic_loss": 0.017734897271519005, "actor_loss": -10.298746605604887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29767918586731, "step": 116000}
{"episode_reward": 3.0364595142766824, "episode": 117.0, "batch_reward": 0.008561461065430194, "critic_loss": 0.016849232950386067, "actor_loss": -10.31472648909688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.292978525161743, "step": 117000}
{"episode_reward": 2.40311007475732, "episode": 118.0, "batch_reward": 0.008564853947842494, "critic_loss": 0.00815447509020305, "actor_loss": -8.816843416899443, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.323331594467163, "step": 118000}
{"episode_reward": 5.814808598385498, "episode": 119.0, "batch_reward": 0.008745947886491195, "critic_loss": 0.018631961744173167, "actor_loss": -9.665183928847313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.301984786987305, "step": 119000}
{"episode_reward": 4.26172337511117, "episode": 120.0, "batch_reward": 0.008449236162472517, "critic_loss": 0.010365497142658569, "actor_loss": -10.130609815075994, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.285578966140747, "step": 120000}
{"episode_reward": 3.921353041716738, "episode": 121.0, "batch_reward": 0.008436384446453303, "critic_loss": 0.02643250298620842, "actor_loss": -9.071192913800479, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.865123987197876, "step": 121000}
{"episode_reward": 3.8943517992382457, "episode": 122.0, "batch_reward": 0.008519689055392519, "critic_loss": 0.012980291833257069, "actor_loss": -11.086083934769034, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.324163675308228, "step": 122000}
{"episode_reward": 3.504897392281719, "episode": 123.0, "batch_reward": 0.008416006448445841, "critic_loss": 0.008855077586100378, "actor_loss": -12.376284798666834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.310794353485107, "step": 123000}
{"episode_reward": 3.9172222340713265, "episode": 124.0, "batch_reward": 0.008660196257289499, "critic_loss": 0.012543392129613494, "actor_loss": -11.596040972575546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.438170671463013, "step": 124000}
{"episode_reward": 3.5783058037488313, "episode": 125.0, "batch_reward": 0.008239601641194895, "critic_loss": 0.009219390510799712, "actor_loss": -9.259749242976309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.539368867874146, "step": 125000}
{"episode_reward": 4.329308415393362, "episode": 126.0, "batch_reward": 0.008161715513560921, "critic_loss": 0.010468017857128871, "actor_loss": -9.873523397967219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.302260875701904, "step": 126000}
{"episode_reward": 3.019291102086987, "episode": 127.0, "batch_reward": 0.00819990694662556, "critic_loss": 0.012108979916316457, "actor_loss": -11.169390187770128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.264309883117676, "step": 127000}
{"episode_reward": 4.197667848121893, "episode": 128.0, "batch_reward": 0.008240984114818274, "critic_loss": 0.011295113046260668, "actor_loss": -9.444446469843388, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.308485746383667, "step": 128000}
{"episode_reward": 2.2518713357065274, "episode": 129.0, "batch_reward": 0.008155385555932298, "critic_loss": 0.010800818392373913, "actor_loss": -10.520679308101535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.298832654953003, "step": 129000}
{"episode_reward": 5.088951334574924, "episode": 130.0, "batch_reward": 0.008318722914671525, "critic_loss": 0.010677671010933408, "actor_loss": -11.126496500387788, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.289984226226807, "step": 130000}
{"episode_reward": 4.2258103288896764, "episode": 131.0, "batch_reward": 0.0082684729101602, "critic_loss": 0.013633970566930657, "actor_loss": -8.977743676558138, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.851961851119995, "step": 131000}
{"episode_reward": 6.231356428685614, "episode": 132.0, "batch_reward": 0.008401415646309033, "critic_loss": 0.016263229290547316, "actor_loss": -10.350074578553437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.270915508270264, "step": 132000}
{"episode_reward": 4.872995874087999, "episode": 133.0, "batch_reward": 0.00816597733250819, "critic_loss": 0.009040135611139704, "actor_loss": -9.88526216983795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.317065954208374, "step": 133000}
{"episode_reward": 4.027237864477595, "episode": 134.0, "batch_reward": 0.008172348440391943, "critic_loss": 0.011274846578402503, "actor_loss": -10.380406725555659, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28313899040222, "step": 134000}
{"episode_reward": 3.6488009325054525, "episode": 135.0, "batch_reward": 0.008365793100791052, "critic_loss": 0.010250742916832678, "actor_loss": -10.781389018848538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.252684116363525, "step": 135000}
{"episode_reward": 3.324555759914979, "episode": 136.0, "batch_reward": 0.008054148947354406, "critic_loss": 0.015006456152957981, "actor_loss": -10.11021720932424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.316705226898193, "step": 136000}
{"episode_reward": 4.566512163077944, "episode": 137.0, "batch_reward": 0.008113785070599988, "critic_loss": 0.01685491583562907, "actor_loss": -10.83415682131052, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31336522102356, "step": 137000}
{"episode_reward": 3.7684112808194996, "episode": 138.0, "batch_reward": 0.008013032349757851, "critic_loss": 0.01216459259448311, "actor_loss": -9.592712691739202, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.286484479904175, "step": 138000}
{"episode_reward": 3.35094736975036, "episode": 139.0, "batch_reward": 0.00786347318207845, "critic_loss": 0.022142962348465516, "actor_loss": -9.285425105065107, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.283226490020752, "step": 139000}
{"episode_reward": 5.685692780245394, "episode": 140.0, "batch_reward": 0.008272839718963951, "critic_loss": 0.013127053252093901, "actor_loss": -9.916188756540418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.278311491012573, "step": 140000}
{"episode_reward": 4.5952877476528995, "episode": 141.0, "batch_reward": 0.007896335650933907, "critic_loss": 0.0194291330074484, "actor_loss": -10.526607572242618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.84270620346069, "step": 141000}
{"episode_reward": 3.92753151813074, "episode": 142.0, "batch_reward": 0.00791255723265931, "critic_loss": 0.017358067599430798, "actor_loss": -10.100962281674146, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33313822746277, "step": 142000}
{"episode_reward": 4.863048877319993, "episode": 143.0, "batch_reward": 0.007954238425707444, "critic_loss": 0.02063042520121962, "actor_loss": -10.242728898733855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.273173332214355, "step": 143000}
{"episode_reward": 4.1716999198830775, "episode": 144.0, "batch_reward": 0.00802168928156607, "critic_loss": 0.018952619470110222, "actor_loss": -9.931662973999977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.330469369888306, "step": 144000}
{"episode_reward": 2.978220502342664, "episode": 145.0, "batch_reward": 0.007827429186785594, "critic_loss": 0.03431642898821156, "actor_loss": -10.629647960707546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32581639289856, "step": 145000}
{"episode_reward": 4.188116627763922, "episode": 146.0, "batch_reward": 0.007595542834606022, "critic_loss": 0.016729136593989096, "actor_loss": -10.201299865961074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31024193763733, "step": 146000}
{"episode_reward": 3.543546415058945, "episode": 147.0, "batch_reward": 0.007876072146231308, "critic_loss": 0.027847994185030985, "actor_loss": -10.162157310172915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.314549684524536, "step": 147000}
{"episode_reward": 3.36043824679324, "episode": 148.0, "batch_reward": 0.0076489331624470655, "critic_loss": 0.01750214446450991, "actor_loss": -9.87906867018342, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.325114250183105, "step": 148000}
{"episode_reward": 3.322846058550665, "episode": 149.0, "batch_reward": 0.007704462502384558, "critic_loss": 0.030063085256653722, "actor_loss": -9.508295809820295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.283276081085205, "step": 149000}
{"episode_reward": 3.0723769784517927, "episode": 150.0, "batch_reward": 0.007594094964209944, "critic_loss": 0.02417136361484154, "actor_loss": -8.872650019086898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
