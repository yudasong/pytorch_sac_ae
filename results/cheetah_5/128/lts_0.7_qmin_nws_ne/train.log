{"episode_reward": 0.0, "episode": 1.0, "duration": 17.474557161331177, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.5084362030029297, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.2592453764811799, "critic_loss": 0.017967508441547167, "actor_loss": -32.37270205536214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.38476634025574, "step": 3000}
{"episode_reward": 3.6037085746560305, "episode": 4.0, "batch_reward": 0.1612521392852068, "critic_loss": 0.015409928136738017, "actor_loss": -28.340076654434203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.315983533859253, "step": 4000}
{"episode_reward": 7.167823401285496, "episode": 5.0, "batch_reward": 0.12724509071558715, "critic_loss": 0.01978543979441747, "actor_loss": -28.305845804214478, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.321542024612427, "step": 5000}
{"episode_reward": 18.658518918537872, "episode": 6.0, "batch_reward": 0.10773835263773798, "critic_loss": 0.018334299521055072, "actor_loss": -27.264055767059325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.306582927703857, "step": 6000}
{"episode_reward": 15.201952006226097, "episode": 7.0, "batch_reward": 0.092721460968256, "critic_loss": 0.021620062605477868, "actor_loss": -26.98980583524704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.303757429122925, "step": 7000}
{"episode_reward": 12.015644544595316, "episode": 8.0, "batch_reward": 0.08219414368271828, "critic_loss": 0.02217497204709798, "actor_loss": -25.17211229658127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.302940130233765, "step": 8000}
{"episode_reward": 10.764796307952459, "episode": 9.0, "batch_reward": 0.07369688032194972, "critic_loss": 0.02444955493696034, "actor_loss": -24.3551392993927, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3035728931427, "step": 9000}
{"episode_reward": 9.606843127200639, "episode": 10.0, "batch_reward": 0.06679441337846219, "critic_loss": 0.024450638997368514, "actor_loss": -25.45597348713875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.290769338607788, "step": 10000}
{"episode_reward": 7.988004276539711, "episode": 11.0, "batch_reward": 0.060504103852435945, "critic_loss": 0.030459903564769776, "actor_loss": -24.074623535633087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.87026643753052, "step": 11000}
{"episode_reward": 6.188737206998022, "episode": 12.0, "batch_reward": 0.05657062834687531, "critic_loss": 0.027584157523000613, "actor_loss": -24.58712581586838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.291796922683716, "step": 12000}
{"episode_reward": 7.8216439236254685, "episode": 13.0, "batch_reward": 0.05245625224802643, "critic_loss": 0.029821725272107868, "actor_loss": -24.816631123781203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.324907302856445, "step": 13000}
{"episode_reward": 9.906820131368791, "episode": 14.0, "batch_reward": 0.04953892775811255, "critic_loss": 0.02789524234388955, "actor_loss": -24.525175478458404, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25138020515442, "step": 14000}
{"episode_reward": 10.827076468082709, "episode": 15.0, "batch_reward": 0.04693268883600831, "critic_loss": 0.03385472434363328, "actor_loss": -24.379987846136093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.271642208099365, "step": 15000}
{"episode_reward": 7.428760557077946, "episode": 16.0, "batch_reward": 0.04443437029421329, "critic_loss": 0.0364519131637644, "actor_loss": -23.636598139047624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30897355079651, "step": 16000}
{"episode_reward": 12.661512499051302, "episode": 17.0, "batch_reward": 0.04192615539347753, "critic_loss": 0.025759168338263406, "actor_loss": -24.086804073810576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.306524991989136, "step": 17000}
{"episode_reward": 7.856424920279715, "episode": 18.0, "batch_reward": 0.04046448603458703, "critic_loss": 0.047198127739713526, "actor_loss": -23.698123442530633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.288408041000366, "step": 18000}
{"episode_reward": 9.356926006248559, "episode": 19.0, "batch_reward": 0.03814919298095629, "critic_loss": 0.0366930086115608, "actor_loss": -24.132664970874785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.301105737686157, "step": 19000}
{"episode_reward": 9.546572925614694, "episode": 20.0, "batch_reward": 0.03735723915044218, "critic_loss": 0.048039950402686375, "actor_loss": -24.10719347310066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27777600288391, "step": 20000}
{"episode_reward": 12.165521095557667, "episode": 21.0, "batch_reward": 0.03604971287492663, "critic_loss": 0.049573988287011164, "actor_loss": -22.677084599852563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.84668469429016, "step": 21000}
{"episode_reward": 12.844931622577462, "episode": 22.0, "batch_reward": 0.034762048759497705, "critic_loss": 0.058153544489992784, "actor_loss": -24.433053510308266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.278979301452637, "step": 22000}
{"episode_reward": 10.54095168663698, "episode": 23.0, "batch_reward": 0.034134531483985486, "critic_loss": 0.04968138304620515, "actor_loss": -24.38366443324089, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28891897201538, "step": 23000}
{"episode_reward": 11.0372598484909, "episode": 24.0, "batch_reward": 0.03285933468304574, "critic_loss": 0.056982328660436905, "actor_loss": -22.426551802158357, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32784628868103, "step": 24000}
{"episode_reward": 7.322000671992137, "episode": 25.0, "batch_reward": 0.03109128721151501, "critic_loss": 0.051059666332090275, "actor_loss": -24.080301542401315, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27468705177307, "step": 25000}
{"episode_reward": 11.159635061237498, "episode": 26.0, "batch_reward": 0.03084459966653958, "critic_loss": 0.043007134968647734, "actor_loss": -22.79963668525219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28241801261902, "step": 26000}
{"episode_reward": 11.3411278849435, "episode": 27.0, "batch_reward": 0.030111483396030963, "critic_loss": 0.056746742149931376, "actor_loss": -23.473530612707137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.328684329986572, "step": 27000}
{"episode_reward": 9.658351488921781, "episode": 28.0, "batch_reward": 0.029209908225573598, "critic_loss": 0.05671738852455746, "actor_loss": -23.214460789620876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.293149709701538, "step": 28000}
{"episode_reward": 12.148222112538704, "episode": 29.0, "batch_reward": 0.028782541973516346, "critic_loss": 0.05305887823028024, "actor_loss": -23.296727258622646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2942955493927, "step": 29000}
{"episode_reward": 8.615678223190498, "episode": 30.0, "batch_reward": 0.028006885425187648, "critic_loss": 0.0637449941613595, "actor_loss": -22.56943468928337, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29479432106018, "step": 30000}
{"episode_reward": 10.03092737447916, "episode": 31.0, "batch_reward": 0.027729693366214635, "critic_loss": 0.0377899581999518, "actor_loss": -23.048154551029207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.83781099319458, "step": 31000}
{"episode_reward": 7.995313854542605, "episode": 32.0, "batch_reward": 0.026802414305508136, "critic_loss": 0.041306631666666364, "actor_loss": -22.705654069066046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31327795982361, "step": 32000}
{"episode_reward": 9.235460099767234, "episode": 33.0, "batch_reward": 0.02581268835067749, "critic_loss": 0.041970330946845935, "actor_loss": -23.169211052417754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.265417098999023, "step": 33000}
{"episode_reward": 10.207838188066956, "episode": 34.0, "batch_reward": 0.0259873787779361, "critic_loss": 0.045635864505136854, "actor_loss": -23.63369554078579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30371618270874, "step": 34000}
{"episode_reward": 8.367059207977656, "episode": 35.0, "batch_reward": 0.025391556094400584, "critic_loss": 0.03556922352005495, "actor_loss": -22.632314349472523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.300963878631592, "step": 35000}
{"episode_reward": 9.66849727173146, "episode": 36.0, "batch_reward": 0.0249222357776016, "critic_loss": 0.036427987300092356, "actor_loss": -22.981071542561054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.254482984542847, "step": 36000}
{"episode_reward": 13.840962635967752, "episode": 37.0, "batch_reward": 0.02457970657199621, "critic_loss": 0.030288838004518766, "actor_loss": -22.382077471494675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.284658193588257, "step": 37000}
{"episode_reward": 7.156074906632002, "episode": 38.0, "batch_reward": 0.024729594867676497, "critic_loss": 0.05410408660740359, "actor_loss": -22.984155768215658, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.323959350585938, "step": 38000}
{"episode_reward": 11.314383756913642, "episode": 39.0, "batch_reward": 0.02401585334073752, "critic_loss": 0.03307293982233386, "actor_loss": -23.45026422572136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.294597864151, "step": 39000}
{"episode_reward": 10.161447911555094, "episode": 40.0, "batch_reward": 0.023716690139845013, "critic_loss": 0.03410122342885006, "actor_loss": -24.253153887808324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28297996520996, "step": 40000}
{"episode_reward": 11.293558334408848, "episode": 41.0, "batch_reward": 0.023513394923880698, "critic_loss": 0.030495270036248256, "actor_loss": -23.522978009045126, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.855437994003296, "step": 41000}
{"episode_reward": 9.789374867447078, "episode": 42.0, "batch_reward": 0.0228358065681532, "critic_loss": 0.03497419813170564, "actor_loss": -23.316341717541217, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.285271883010864, "step": 42000}
{"episode_reward": 9.075717326058022, "episode": 43.0, "batch_reward": 0.022763229489326478, "critic_loss": 0.037066787265590394, "actor_loss": -24.174813981473445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.301798343658447, "step": 43000}
{"episode_reward": 11.429555713024996, "episode": 44.0, "batch_reward": 0.02226376463472843, "critic_loss": 0.03665625656361226, "actor_loss": -22.840550520658493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3076012134552, "step": 44000}
{"episode_reward": 9.078122604375858, "episode": 45.0, "batch_reward": 0.022086362409871073, "critic_loss": 0.0361158023365424, "actor_loss": -21.965029406309128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30935835838318, "step": 45000}
{"episode_reward": 8.30342683995579, "episode": 46.0, "batch_reward": 0.021939563205000012, "critic_loss": 0.039270830319204836, "actor_loss": -22.729188694000243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.302998781204224, "step": 46000}
{"episode_reward": 12.879661665616936, "episode": 47.0, "batch_reward": 0.021330017854459583, "critic_loss": 0.04229389446074492, "actor_loss": -22.491292840719222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31144690513611, "step": 47000}
{"episode_reward": 9.808245646547896, "episode": 48.0, "batch_reward": 0.021385013609193267, "critic_loss": 0.04248203925398411, "actor_loss": -22.1360776091218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.304563760757446, "step": 48000}
{"episode_reward": 11.215368781101324, "episode": 49.0, "batch_reward": 0.02131345538329333, "critic_loss": 0.04165007825664361, "actor_loss": -22.91387065309286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.311451196670532, "step": 49000}
{"episode_reward": 10.801650931234969, "episode": 50.0, "batch_reward": 0.020444812063127756, "critic_loss": 0.03547587006614776, "actor_loss": -22.169733416259287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.303394079208374, "step": 50000}
{"episode_reward": 7.091174308868937, "episode": 51.0, "batch_reward": 0.0204707985650748, "critic_loss": 0.059299316770018776, "actor_loss": -23.980277174681426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.83364772796631, "step": 51000}
{"episode_reward": 12.625748190858314, "episode": 52.0, "batch_reward": 0.020356050699483604, "critic_loss": 0.06479683741621557, "actor_loss": -22.05091188621521, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29741597175598, "step": 52000}
{"episode_reward": 8.403099575352266, "episode": 53.0, "batch_reward": 0.02050516827451065, "critic_loss": 0.043944083752809095, "actor_loss": -22.747756024003028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2831609249115, "step": 53000}
{"episode_reward": 10.711860195417657, "episode": 54.0, "batch_reward": 0.019647515900898724, "critic_loss": 0.03202756497784867, "actor_loss": -23.239517589092255, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.284440279006958, "step": 54000}
{"episode_reward": 8.055532411911058, "episode": 55.0, "batch_reward": 0.019567474109586327, "critic_loss": 0.030739707973349142, "actor_loss": -23.023605040311814, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30344820022583, "step": 55000}
{"episode_reward": 6.380500721718272, "episode": 56.0, "batch_reward": 0.01954960309714079, "critic_loss": 0.027248151218518615, "actor_loss": -23.182718660563232, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30160689353943, "step": 56000}
{"episode_reward": 6.554496623706315, "episode": 57.0, "batch_reward": 0.0190517462445423, "critic_loss": 0.03615502225668751, "actor_loss": -22.45022410824895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.296860218048096, "step": 57000}
{"episode_reward": 11.088459884553657, "episode": 58.0, "batch_reward": 0.018883039719425142, "critic_loss": 0.03859904166898923, "actor_loss": -22.890301805853845, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30199694633484, "step": 58000}
{"episode_reward": 9.902331114641472, "episode": 59.0, "batch_reward": 0.018899976666085422, "critic_loss": 0.03111571950072539, "actor_loss": -23.937198356598614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.305084943771362, "step": 59000}
{"episode_reward": 7.370699601228937, "episode": 60.0, "batch_reward": 0.018833702949341388, "critic_loss": 0.025136260566010607, "actor_loss": -22.919566419065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29748845100403, "step": 60000}
{"episode_reward": 11.166900833894452, "episode": 61.0, "batch_reward": 0.018449786935467272, "critic_loss": 0.025914889431762275, "actor_loss": -21.828237633526324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.8287935256958, "step": 61000}
{"episode_reward": 10.97318674736512, "episode": 62.0, "batch_reward": 0.01864399291574955, "critic_loss": 0.034960377965559016, "actor_loss": -22.088047700673343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.293503046035767, "step": 62000}
{"episode_reward": 11.320612296738766, "episode": 63.0, "batch_reward": 0.018461000726092608, "critic_loss": 0.02812957734512747, "actor_loss": -22.0664381801486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33670997619629, "step": 63000}
{"episode_reward": 9.471483716109619, "episode": 64.0, "batch_reward": 0.018224453298840673, "critic_loss": 0.024247658006104757, "actor_loss": -23.1832984713912, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.304720640182495, "step": 64000}
{"episode_reward": 6.456943629750903, "episode": 65.0, "batch_reward": 0.018172634239308535, "critic_loss": 0.02228512920977664, "actor_loss": -22.495092700988053, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.287496328353882, "step": 65000}
{"episode_reward": 9.264718062459574, "episode": 66.0, "batch_reward": 0.01788204870093614, "critic_loss": 0.020527662684675305, "actor_loss": -22.765013158410788, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28964376449585, "step": 66000}
{"episode_reward": 7.404279222832131, "episode": 67.0, "batch_reward": 0.017881437293253838, "critic_loss": 0.01683075567134074, "actor_loss": -22.125565884679556, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.70789647102356, "step": 67000}
{"episode_reward": 8.999991021140916, "episode": 68.0, "batch_reward": 0.017774231718387455, "critic_loss": 0.012807690831949003, "actor_loss": -22.874321496993304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27054476737976, "step": 68000}
{"episode_reward": 8.41726491752448, "episode": 69.0, "batch_reward": 0.017710318496450782, "critic_loss": 0.00808717721447465, "actor_loss": -21.727957717448472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26992154121399, "step": 69000}
{"episode_reward": 10.488334799700189, "episode": 70.0, "batch_reward": 0.017544603367336094, "critic_loss": 0.007811876814928837, "actor_loss": -22.803276471763848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.284480333328247, "step": 70000}
{"episode_reward": 13.013355799661426, "episode": 71.0, "batch_reward": 0.017437846278306097, "critic_loss": 0.006510154647607123, "actor_loss": -22.534146932661532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.79061245918274, "step": 71000}
{"episode_reward": 6.6237622034446115, "episode": 72.0, "batch_reward": 0.017048221847973763, "critic_loss": 0.005246643958118511, "actor_loss": -22.14433958172798, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31361746788025, "step": 72000}
{"episode_reward": 11.794270791229001, "episode": 73.0, "batch_reward": 0.01710431771632284, "critic_loss": 0.007013115348556312, "actor_loss": -22.53230714070797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.312584400177002, "step": 73000}
{"episode_reward": 8.77817102770463, "episode": 74.0, "batch_reward": 0.016761241587344558, "critic_loss": 0.006218294978374615, "actor_loss": -21.269383798986674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31098699569702, "step": 74000}
{"episode_reward": 10.115041205379319, "episode": 75.0, "batch_reward": 0.01701494253752753, "critic_loss": 0.004823298052564496, "actor_loss": -23.96260603326559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.317014694213867, "step": 75000}
{"episode_reward": 9.779722621683629, "episode": 76.0, "batch_reward": 0.016856150950770823, "critic_loss": 0.00552459231892135, "actor_loss": -22.87615764042735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.294312715530396, "step": 76000}
{"episode_reward": 7.797636505080658, "episode": 77.0, "batch_reward": 0.016756482407916336, "critic_loss": 0.005078028649877524, "actor_loss": -22.812265632748606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28798198699951, "step": 77000}
{"episode_reward": 9.228947837212141, "episode": 78.0, "batch_reward": 0.016367880563251676, "critic_loss": 0.003986553352733608, "actor_loss": -22.162427520126105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.340912342071533, "step": 78000}
{"episode_reward": 9.7111220284425, "episode": 79.0, "batch_reward": 0.016382609381806107, "critic_loss": 0.005734073239698773, "actor_loss": -23.180237686276435, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.269123077392578, "step": 79000}
{"episode_reward": 12.02489819438109, "episode": 80.0, "batch_reward": 0.016754222161602227, "critic_loss": 0.004076616700360318, "actor_loss": -23.196425735831262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.308740854263306, "step": 80000}
{"episode_reward": 6.720264099547653, "episode": 81.0, "batch_reward": 0.01626827335776761, "critic_loss": 0.00442442839074647, "actor_loss": -22.6030298922658, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.87170171737671, "step": 81000}
{"episode_reward": 9.419517991474635, "episode": 82.0, "batch_reward": 0.016430825646035374, "critic_loss": 0.004700427599920658, "actor_loss": -22.22434620782733, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30679941177368, "step": 82000}
{"episode_reward": 10.590159719130526, "episode": 83.0, "batch_reward": 0.01625824421690777, "critic_loss": 0.005786102123471209, "actor_loss": -22.808123469918968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.336832761764526, "step": 83000}
{"episode_reward": 11.7061306481125, "episode": 84.0, "batch_reward": 0.016180458975490183, "critic_loss": 0.00676638268509123, "actor_loss": -22.74662538689375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.291245937347412, "step": 84000}
{"episode_reward": 11.699341838031556, "episode": 85.0, "batch_reward": 0.016077890297863634, "critic_loss": 0.006167027014482301, "actor_loss": -23.2865842500031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.302167654037476, "step": 85000}
{"episode_reward": 9.788193227201266, "episode": 86.0, "batch_reward": 0.016286768137943, "critic_loss": 0.009093178605107824, "actor_loss": -22.494990583717822, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.310630798339844, "step": 86000}
{"episode_reward": 9.793038616339368, "episode": 87.0, "batch_reward": 0.016276837607380003, "critic_loss": 0.006390226231160341, "actor_loss": -22.034236836105585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2632839679718, "step": 87000}
{"episode_reward": 10.167842941492957, "episode": 88.0, "batch_reward": 0.01591850516013801, "critic_loss": 0.004592492349300301, "actor_loss": -22.015832488507034, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.301151990890503, "step": 88000}
{"episode_reward": 7.270618792793823, "episode": 89.0, "batch_reward": 0.015828065989539026, "critic_loss": 0.004192919588153017, "actor_loss": -22.588341206192972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.296232223510742, "step": 89000}
{"episode_reward": 9.307386571178649, "episode": 90.0, "batch_reward": 0.01576851669186726, "critic_loss": 0.004409788316334016, "actor_loss": -21.69261713936925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.286829710006714, "step": 90000}
{"episode_reward": 8.60962256111329, "episode": 91.0, "batch_reward": 0.015767993561457843, "critic_loss": 0.002561652572097955, "actor_loss": -23.445922360897065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.87099361419678, "step": 91000}
{"episode_reward": 8.022416425577136, "episode": 92.0, "batch_reward": 0.015601639301516116, "critic_loss": 0.003408642799651716, "actor_loss": -21.739481441438198, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.316815614700317, "step": 92000}
{"episode_reward": 9.230690247008445, "episode": 93.0, "batch_reward": 0.01564465333800763, "critic_loss": 0.0036496353955590166, "actor_loss": -22.36363597074151, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.372811794281006, "step": 93000}
{"episode_reward": 11.080495172841054, "episode": 94.0, "batch_reward": 0.015648458193056287, "critic_loss": 0.003571241641708184, "actor_loss": -21.37122016635537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.616010904312134, "step": 94000}
{"episode_reward": 10.19808606961609, "episode": 95.0, "batch_reward": 0.01566690844995901, "critic_loss": 0.005210901255253702, "actor_loss": -22.42703804796934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.248995780944824, "step": 95000}
{"episode_reward": 11.778502801182404, "episode": 96.0, "batch_reward": 0.01530673990258947, "critic_loss": 0.0034240392755600624, "actor_loss": -22.109057082653045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.290651082992554, "step": 96000}
{"episode_reward": 11.697627912269077, "episode": 97.0, "batch_reward": 0.015374491295777261, "critic_loss": 0.004196558074792847, "actor_loss": -22.3019651325047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31679630279541, "step": 97000}
{"episode_reward": 8.09188287274576, "episode": 98.0, "batch_reward": 0.015601334466133267, "critic_loss": 0.004238138811138924, "actor_loss": -22.187622035354376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.253348112106323, "step": 98000}
{"episode_reward": 7.2062229355408, "episode": 99.0, "batch_reward": 0.01521130674239248, "critic_loss": 0.004505410687415861, "actor_loss": -22.17785736167431, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29581880569458, "step": 99000}
{"episode_reward": 11.263832085568898, "episode": 100.0, "batch_reward": 0.015141876752953977, "critic_loss": 0.004638187241042033, "actor_loss": -22.564145924180746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31100869178772, "step": 100000}
{"episode_reward": 7.3318908319417515, "episode": 101.0, "batch_reward": 0.015268871305510402, "critic_loss": 0.0031167954110715075, "actor_loss": -21.472333298504353, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.8248405456543, "step": 101000}
{"episode_reward": 14.071691174677381, "episode": 102.0, "batch_reward": 0.015055251779034733, "critic_loss": 0.003825156736333156, "actor_loss": -23.239095137774946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31077766418457, "step": 102000}
{"episode_reward": 6.468427005317329, "episode": 103.0, "batch_reward": 0.014936989781912416, "critic_loss": 0.004417405684012919, "actor_loss": -21.781748338401318, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.316739559173584, "step": 103000}
{"episode_reward": 7.889003277900551, "episode": 104.0, "batch_reward": 0.01491419808147475, "critic_loss": 0.00557907338734367, "actor_loss": -23.250293271154167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32276153564453, "step": 104000}
{"episode_reward": 7.174653774269852, "episode": 105.0, "batch_reward": 0.014937840432394297, "critic_loss": 0.0038761955679801757, "actor_loss": -21.399095423460007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.341331958770752, "step": 105000}
{"episode_reward": 6.050076255009263, "episode": 106.0, "batch_reward": 0.014530544261448085, "critic_loss": 0.006798319763445761, "actor_loss": -22.469529739439487, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33931064605713, "step": 106000}
{"episode_reward": 9.247898769940242, "episode": 107.0, "batch_reward": 0.014465413349680602, "critic_loss": 0.007287352212762926, "actor_loss": -22.452023355811836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31881046295166, "step": 107000}
{"episode_reward": 9.404301539857334, "episode": 108.0, "batch_reward": 0.014595833507366478, "critic_loss": 0.0036290616729238536, "actor_loss": -22.39007679283619, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29123854637146, "step": 108000}
{"episode_reward": 7.965620429241815, "episode": 109.0, "batch_reward": 0.014746706116944551, "critic_loss": 0.0037145114449667746, "actor_loss": -22.22522206172347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27620029449463, "step": 109000}
{"episode_reward": 9.538319647182245, "episode": 110.0, "batch_reward": 0.014741552893072368, "critic_loss": 0.0047020914419699696, "actor_loss": -22.40585329502821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.295687437057495, "step": 110000}
{"episode_reward": 8.685758350428033, "episode": 111.0, "batch_reward": 0.014412447189446538, "critic_loss": 0.0036059700807672926, "actor_loss": -21.446136535435915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.82691192626953, "step": 111000}
{"episode_reward": 6.739791490813818, "episode": 112.0, "batch_reward": 0.0146239594114013, "critic_loss": 0.003827874045629869, "actor_loss": -22.583102534890173, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.296757459640503, "step": 112000}
{"episode_reward": 9.028058668234399, "episode": 113.0, "batch_reward": 0.014169386754278094, "critic_loss": 0.0035984679811517707, "actor_loss": -20.73327990704775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2952139377594, "step": 113000}
{"episode_reward": 11.241362569209405, "episode": 114.0, "batch_reward": 0.014466037184465676, "critic_loss": 0.0036473563528270463, "actor_loss": -21.943381945371627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30113959312439, "step": 114000}
{"episode_reward": 7.2560119180676175, "episode": 115.0, "batch_reward": 0.014225231767632067, "critic_loss": 0.004114811934749014, "actor_loss": -22.878724487155676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.299052476882935, "step": 115000}
{"episode_reward": 10.629430543095141, "episode": 116.0, "batch_reward": 0.014102359452284873, "critic_loss": 0.00446793192550831, "actor_loss": -22.300143771916627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26922369003296, "step": 116000}
{"episode_reward": 7.8895592166664015, "episode": 117.0, "batch_reward": 0.014061847484204918, "critic_loss": 0.005672139487141976, "actor_loss": -21.93410768726468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32699942588806, "step": 117000}
{"episode_reward": 8.1721921301403, "episode": 118.0, "batch_reward": 0.01410288066137582, "critic_loss": 0.003888318344615982, "actor_loss": -21.803296479612587, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30064821243286, "step": 118000}
{"episode_reward": 13.2754428677, "episode": 119.0, "batch_reward": 0.01429313012259081, "critic_loss": 0.00449692224629689, "actor_loss": -22.192670994102954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29120659828186, "step": 119000}
{"episode_reward": 10.948123100378805, "episode": 120.0, "batch_reward": 0.01391078593255952, "critic_loss": 0.004833877301338362, "actor_loss": -22.676145118683575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28685998916626, "step": 120000}
{"episode_reward": 9.421448820549946, "episode": 121.0, "batch_reward": 0.013973702057264746, "critic_loss": 0.0058960640333243644, "actor_loss": -22.234632303386928, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.8499174118042, "step": 121000}
{"episode_reward": 8.122763793152005, "episode": 122.0, "batch_reward": 0.014034320246893913, "critic_loss": 0.008690882883718587, "actor_loss": -23.269312687546016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28924584388733, "step": 122000}
{"episode_reward": 7.155687586981627, "episode": 123.0, "batch_reward": 0.013878249789122492, "critic_loss": 0.006916135571358609, "actor_loss": -23.25492532375455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.266468286514282, "step": 123000}
{"episode_reward": 10.190882546111347, "episode": 124.0, "batch_reward": 0.014160404488444328, "critic_loss": 0.00811055952188326, "actor_loss": -22.80438311550021, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.64493227005005, "step": 124000}
{"episode_reward": 9.12153670202773, "episode": 125.0, "batch_reward": 0.013773190079256892, "critic_loss": 0.006588272401117138, "actor_loss": -23.23487544438243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.323108673095703, "step": 125000}
{"episode_reward": 10.062926123110552, "episode": 126.0, "batch_reward": 0.013638934186659754, "critic_loss": 0.0057894904910644985, "actor_loss": -23.690462313026188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2617826461792, "step": 126000}
{"episode_reward": 6.043652037691409, "episode": 127.0, "batch_reward": 0.013694321973714977, "critic_loss": 0.003725501675173291, "actor_loss": -22.16753654444218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.268097400665283, "step": 127000}
{"episode_reward": 9.989402969958741, "episode": 128.0, "batch_reward": 0.013730814467649908, "critic_loss": 0.0033128496422286844, "actor_loss": -22.487115579515695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.289233446121216, "step": 128000}
{"episode_reward": 6.656477237527348, "episode": 129.0, "batch_reward": 0.013637722318060696, "critic_loss": 0.003006982054488617, "actor_loss": -22.730535760164262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.309716939926147, "step": 129000}
{"episode_reward": 9.28790785433925, "episode": 130.0, "batch_reward": 0.013766206575091929, "critic_loss": 0.003939637923205737, "actor_loss": -22.49486255389452, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.275476217269897, "step": 130000}
{"episode_reward": 10.707981151002265, "episode": 131.0, "batch_reward": 0.013717815552838146, "critic_loss": 0.0030281249581457816, "actor_loss": -20.788284098058938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.88972306251526, "step": 131000}
{"episode_reward": 10.701917701894075, "episode": 132.0, "batch_reward": 0.013906682246830315, "critic_loss": 0.0028030192206206267, "actor_loss": -21.80061224615574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.270784616470337, "step": 132000}
{"episode_reward": 7.659523133132015, "episode": 133.0, "batch_reward": 0.013633873166982084, "critic_loss": 0.002816124152697739, "actor_loss": -22.933278049886226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.292600870132446, "step": 133000}
{"episode_reward": 9.34934596664061, "episode": 134.0, "batch_reward": 0.013592469180934132, "critic_loss": 0.0030708822890446754, "actor_loss": -22.721353076308965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3386332988739, "step": 134000}
{"episode_reward": 5.675298878567027, "episode": 135.0, "batch_reward": 0.013745785056147724, "critic_loss": 0.002780245063142502, "actor_loss": -22.924317893743513, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.301833629608154, "step": 135000}
{"episode_reward": 10.143803966460023, "episode": 136.0, "batch_reward": 0.013449296749662608, "critic_loss": 0.003529559676302597, "actor_loss": -23.222490456223486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30717158317566, "step": 136000}
{"episode_reward": 9.071110766376341, "episode": 137.0, "batch_reward": 0.013594475836958737, "critic_loss": 0.0023639553385146426, "actor_loss": -23.102253381580116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29910969734192, "step": 137000}
{"episode_reward": 9.879770838117885, "episode": 138.0, "batch_reward": 0.013501096941530705, "critic_loss": 0.0020062320572906173, "actor_loss": -21.32512823471427, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.316168546676636, "step": 138000}
{"episode_reward": 7.678685677201911, "episode": 139.0, "batch_reward": 0.013269784931093454, "critic_loss": 0.0020623737435089425, "actor_loss": -20.512069992631673, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31524109840393, "step": 139000}
{"episode_reward": 12.831862394506887, "episode": 140.0, "batch_reward": 0.013708900383673608, "critic_loss": 0.0023302153414260828, "actor_loss": -21.029733462184666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.344173908233643, "step": 140000}
{"episode_reward": 9.80724666222687, "episode": 141.0, "batch_reward": 0.013299814922735095, "critic_loss": 0.0029538718958356186, "actor_loss": -22.138684442847968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.84451222419739, "step": 141000}
{"episode_reward": 8.025687052434963, "episode": 142.0, "batch_reward": 0.013288074051029981, "critic_loss": 0.0032489806152589153, "actor_loss": -21.97534710225463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.320712089538574, "step": 142000}
{"episode_reward": 9.479585427649065, "episode": 143.0, "batch_reward": 0.013351521611213684, "critic_loss": 0.0032792183652491074, "actor_loss": -23.233216035097836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28516983985901, "step": 143000}
{"episode_reward": 8.647171563859674, "episode": 144.0, "batch_reward": 0.01340419614687562, "critic_loss": 0.0038440417966776295, "actor_loss": -22.158226540982724, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.343024492263794, "step": 144000}
{"episode_reward": 10.863970255593516, "episode": 145.0, "batch_reward": 0.013247700270731001, "critic_loss": 0.003222634615696734, "actor_loss": -24.097938653409482, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.316346883773804, "step": 145000}
{"episode_reward": 8.41651323342825, "episode": 146.0, "batch_reward": 0.01304742611804977, "critic_loss": 0.0032438527811173117, "actor_loss": -21.579361649274826, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.294503927230835, "step": 146000}
{"episode_reward": 7.0432101661926145, "episode": 147.0, "batch_reward": 0.013286265301052482, "critic_loss": 0.0027505879060772715, "actor_loss": -21.966785754293202, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30567765235901, "step": 147000}
{"episode_reward": 9.904584591030675, "episode": 148.0, "batch_reward": 0.013035390216391534, "critic_loss": 0.0025732667362317442, "actor_loss": -22.341444214761257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.342292308807373, "step": 148000}
{"episode_reward": 7.822429254233901, "episode": 149.0, "batch_reward": 0.01316476003592834, "critic_loss": 0.0038278055960108757, "actor_loss": -22.660000251382588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.298914670944214, "step": 149000}
{"episode_reward": 7.384254538487553, "episode": 150.0, "batch_reward": 0.012997398368548602, "critic_loss": 0.003835088903157157, "actor_loss": -22.3960077983737, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
