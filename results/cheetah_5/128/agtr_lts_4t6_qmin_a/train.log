{"episode_reward": 0.0, "episode": 1.0, "duration": 15.043198585510254, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.3859548568725586, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.2634766800040283, "critic_loss": 0.07711162958815868, "actor_loss": -40.01643476232054, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254236, "duration": 66.75235843658447, "step": 3000}
{"episode_reward": 110.07540067806252, "episode": 4.0, "batch_reward": 0.199913035556674, "critic_loss": 0.05744119420275092, "actor_loss": -29.883338964939117, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.763113260269165, "step": 4000}
{"episode_reward": 40.72453605711656, "episode": 5.0, "batch_reward": 0.1651274550408125, "critic_loss": 0.05901948825828731, "actor_loss": -25.46042139148712, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.920619249343872, "step": 5000}
{"episode_reward": 57.12202471551828, "episode": 6.0, "batch_reward": 0.14930883739888667, "critic_loss": 0.06121978454850614, "actor_loss": -24.567949228286743, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.681169271469116, "step": 6000}
{"episode_reward": 104.58041439075342, "episode": 7.0, "batch_reward": 0.13727164195477962, "critic_loss": 0.06352527643367648, "actor_loss": -24.32777128648758, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.69566535949707, "step": 7000}
{"episode_reward": 37.92403153587613, "episode": 8.0, "batch_reward": 0.12603253339976073, "critic_loss": 0.06208316574245691, "actor_loss": -20.75089854812622, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.901606798171997, "step": 8000}
{"episode_reward": 64.31306344507104, "episode": 9.0, "batch_reward": 0.11489935360848903, "critic_loss": 0.049403651431202886, "actor_loss": -21.502800387382507, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.694088459014893, "step": 9000}
{"episode_reward": 26.966977841185116, "episode": 10.0, "batch_reward": 0.10527065223455428, "critic_loss": 0.04819149691797793, "actor_loss": -20.47761184978485, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.82693862915039, "step": 10000}
{"episode_reward": 9.367277892895448, "episode": 11.0, "batch_reward": 0.0954942647330463, "critic_loss": 0.04759007313661277, "actor_loss": -21.534554244995118, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.812034606933594, "step": 11000}
{"episode_reward": 6.270949013146997, "episode": 12.0, "batch_reward": 0.0880396797284484, "critic_loss": 0.04729866304062307, "actor_loss": -20.409201761722564, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.384141445159912, "step": 12000}
{"episode_reward": 3.223486372712937, "episode": 13.0, "batch_reward": 0.08126227393373847, "critic_loss": 0.04144729848764837, "actor_loss": -20.489441245794296, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.3698947429657, "step": 13000}
{"episode_reward": 6.032060598003624, "episode": 14.0, "batch_reward": 0.07788385771214962, "critic_loss": 0.04599110384099186, "actor_loss": -19.097996780633927, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.50095009803772, "step": 14000}
{"episode_reward": 102.40016502103063, "episode": 15.0, "batch_reward": 0.08093948578462004, "critic_loss": 0.054177698852494356, "actor_loss": -19.77520310163498, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.71376943588257, "step": 15000}
{"episode_reward": 116.48243024798094, "episode": 16.0, "batch_reward": 0.08394798158109187, "critic_loss": 0.055229200938716534, "actor_loss": -19.228430825829506, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.738921642303467, "step": 16000}
{"episode_reward": 136.09044523441966, "episode": 17.0, "batch_reward": 0.08524578062817455, "critic_loss": 0.059333873517811296, "actor_loss": -19.032665182977915, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.830383777618408, "step": 17000}
{"episode_reward": 45.51449965916929, "episode": 18.0, "batch_reward": 0.0848987253345549, "critic_loss": 0.0626876682676375, "actor_loss": -17.582329006284475, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.934589385986328, "step": 18000}
{"episode_reward": 133.52267351488038, "episode": 19.0, "batch_reward": 0.08623627287894488, "critic_loss": 0.07047329795360566, "actor_loss": -18.462638317197563, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.74350643157959, "step": 19000}
{"episode_reward": 110.17880719336526, "episode": 20.0, "batch_reward": 0.08949013962969184, "critic_loss": 0.07772802106663584, "actor_loss": -17.88494947169721, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.363325119018555, "step": 20000}
{"episode_reward": 163.91641081625556, "episode": 21.0, "batch_reward": 0.09288741544261575, "critic_loss": 0.09273675628006459, "actor_loss": -18.271033359274266, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.26484417915344, "step": 21000}
{"episode_reward": 110.78597049284136, "episode": 22.0, "batch_reward": 0.0953926824554801, "critic_loss": 0.09481923565268517, "actor_loss": -17.264046704947948, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.281479835510254, "step": 22000}
{"episode_reward": 221.3003071815883, "episode": 23.0, "batch_reward": 0.09923265196383, "critic_loss": 0.09511466509848833, "actor_loss": -18.049821046352385, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.003369092941284, "step": 23000}
{"episode_reward": 128.58492843028105, "episode": 24.0, "batch_reward": 0.09996342308074235, "critic_loss": 0.10189143032953143, "actor_loss": -18.19703227341175, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.560505390167236, "step": 24000}
{"episode_reward": 81.67474822978342, "episode": 25.0, "batch_reward": 0.09919999431073666, "critic_loss": 0.11117384857311845, "actor_loss": -16.33001869249344, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.634620904922485, "step": 25000}
{"episode_reward": 95.53192010029183, "episode": 26.0, "batch_reward": 0.09982146968692542, "critic_loss": 0.10108011581003666, "actor_loss": -17.047030072927473, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.58495044708252, "step": 26000}
{"episode_reward": 100.29449708531742, "episode": 27.0, "batch_reward": 0.0998078948482871, "critic_loss": 0.11593177525326609, "actor_loss": -16.547740805625917, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.568697929382324, "step": 27000}
{"episode_reward": 165.35444110739684, "episode": 28.0, "batch_reward": 0.10124121169745923, "critic_loss": 0.11193663202226162, "actor_loss": -15.453788011074066, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.686979055404663, "step": 28000}
{"episode_reward": 88.73099147655515, "episode": 29.0, "batch_reward": 0.10123636849224567, "critic_loss": 0.10921715472266078, "actor_loss": -15.523788132190704, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.309659957885742, "step": 29000}
{"episode_reward": 87.17034963566314, "episode": 30.0, "batch_reward": 0.10242262533307075, "critic_loss": 0.1229958504550159, "actor_loss": -15.67193485879898, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.283195734024048, "step": 30000}
{"episode_reward": 166.65487078188286, "episode": 31.0, "batch_reward": 0.10472697487473488, "critic_loss": 0.11481840592250228, "actor_loss": -15.150511713027955, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.27255201339722, "step": 31000}
{"episode_reward": 279.0428355116669, "episode": 32.0, "batch_reward": 0.11056666535884142, "critic_loss": 0.13170337400585413, "actor_loss": -15.588715920448303, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.531579971313477, "step": 32000}
{"episode_reward": 273.9156604388141, "episode": 33.0, "batch_reward": 0.11667326602339745, "critic_loss": 0.1454286912754178, "actor_loss": -15.386255697250366, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.380127906799316, "step": 33000}
{"episode_reward": 406.650552879137, "episode": 34.0, "batch_reward": 0.12445219658315182, "critic_loss": 0.16877701175957918, "actor_loss": -15.910918441772461, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.09218955039978, "step": 34000}
{"episode_reward": 196.12493288113828, "episode": 35.0, "batch_reward": 0.12715174839645624, "critic_loss": 0.1847144245877862, "actor_loss": -17.126356100082397, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.14516830444336, "step": 35000}
{"episode_reward": 279.8232660292562, "episode": 36.0, "batch_reward": 0.1298320837467909, "critic_loss": 0.21040647162497045, "actor_loss": -16.551236578941346, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.851258754730225, "step": 36000}
{"episode_reward": 143.99928818233516, "episode": 37.0, "batch_reward": 0.1329451902806759, "critic_loss": 0.21726858211308717, "actor_loss": -16.925682775497435, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.432940006256104, "step": 37000}
{"episode_reward": 359.9212095009589, "episode": 38.0, "batch_reward": 0.13617907934635878, "critic_loss": 0.21903950283676385, "actor_loss": -16.813507081985474, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.907634496688843, "step": 38000}
{"episode_reward": 120.90362056907968, "episode": 39.0, "batch_reward": 0.13692527621239423, "critic_loss": 0.237138826161623, "actor_loss": -16.64474754714966, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.723933696746826, "step": 39000}
{"episode_reward": 216.98913252564392, "episode": 40.0, "batch_reward": 0.14012520083039998, "critic_loss": 0.23404775351285934, "actor_loss": -16.54972598838806, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.938663005828857, "step": 40000}
{"episode_reward": 346.1863404943956, "episode": 41.0, "batch_reward": 0.14299863050878048, "critic_loss": 0.25149176953732966, "actor_loss": -17.33576558685303, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.02369785308838, "step": 41000}
{"episode_reward": 138.58448069607368, "episode": 42.0, "batch_reward": 0.14306274534761906, "critic_loss": 0.2569211420416832, "actor_loss": -17.3104816532135, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.03950333595276, "step": 42000}
{"episode_reward": 101.04806378122389, "episode": 43.0, "batch_reward": 0.1397760567739606, "critic_loss": 0.22420120659470558, "actor_loss": -16.850632709503174, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.22347855567932, "step": 43000}
{"episode_reward": 35.642581793920904, "episode": 44.0, "batch_reward": 0.13967514570057393, "critic_loss": 0.24436097783595323, "actor_loss": -17.4447302570343, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.041160821914673, "step": 44000}
{"episode_reward": 126.00489965547654, "episode": 45.0, "batch_reward": 0.14175317995995282, "critic_loss": 0.2553016097471118, "actor_loss": -17.68170228767395, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.57412052154541, "step": 45000}
{"episode_reward": 352.2007607821101, "episode": 46.0, "batch_reward": 0.14455565895885228, "critic_loss": 0.2799804518148303, "actor_loss": -18.043005979537963, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.184393405914307, "step": 46000}
{"episode_reward": 168.14466142627165, "episode": 47.0, "batch_reward": 0.14459101773053407, "critic_loss": 0.2977619516849518, "actor_loss": -18.370497386932374, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.290538787841797, "step": 47000}
{"episode_reward": 308.166228525376, "episode": 48.0, "batch_reward": 0.1482820656299591, "critic_loss": 0.2996046046614647, "actor_loss": -18.70342926979065, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.34550380706787, "step": 48000}
{"episode_reward": 234.8124469810029, "episode": 49.0, "batch_reward": 0.1479923505485058, "critic_loss": 0.29418684905022385, "actor_loss": -18.666996644973754, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.1864116191864, "step": 49000}
{"episode_reward": 14.827447207627115, "episode": 50.0, "batch_reward": 0.14594088496267796, "critic_loss": 0.3128936363309622, "actor_loss": -18.726687063217163, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.874647617340088, "step": 50000}
{"episode_reward": 71.10320581764503, "episode": 51.0, "batch_reward": 0.14427177561074495, "critic_loss": 0.3158588964343071, "actor_loss": -18.27767741584778, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.271090507507324, "step": 51000}
{"episode_reward": 73.61376652976101, "episode": 52.0, "batch_reward": 0.14284636980295182, "critic_loss": 0.3398756232857704, "actor_loss": -18.891483324050903, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.052857875823975, "step": 52000}
{"episode_reward": 32.74768622048041, "episode": 53.0, "batch_reward": 0.14196861326694488, "critic_loss": 0.33419675032794477, "actor_loss": -19.007262451171876, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.980395317077637, "step": 53000}
{"episode_reward": 101.06489945601916, "episode": 54.0, "batch_reward": 0.14091319892555476, "critic_loss": 0.34377723786234854, "actor_loss": -19.158796518325804, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.23731827735901, "step": 54000}
{"episode_reward": 129.50272134805186, "episode": 55.0, "batch_reward": 0.1412287695258856, "critic_loss": 0.3534804717451334, "actor_loss": -19.32629240989685, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.737274169921875, "step": 55000}
{"episode_reward": 107.25854930430336, "episode": 56.0, "batch_reward": 0.1421915661469102, "critic_loss": 0.41644831471145155, "actor_loss": -20.047504220962523, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.22689390182495, "step": 56000}
{"episode_reward": 315.0271330423424, "episode": 57.0, "batch_reward": 0.14422517889738082, "critic_loss": 0.41992446437478065, "actor_loss": -20.07962621688843, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.5128231048584, "step": 57000}
{"episode_reward": 239.40946789954918, "episode": 58.0, "batch_reward": 0.14417125608772038, "critic_loss": 0.36540939603745937, "actor_loss": -20.329699995040894, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.06216049194336, "step": 58000}
{"episode_reward": 65.79149695101279, "episode": 59.0, "batch_reward": 0.14580037403106688, "critic_loss": 0.4011871571838856, "actor_loss": -20.49442861175537, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.194370985031128, "step": 59000}
{"episode_reward": 398.9754636265249, "episode": 60.0, "batch_reward": 0.1475682299733162, "critic_loss": 0.4749580988436937, "actor_loss": -21.46207349395752, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.347063064575195, "step": 60000}
{"episode_reward": 162.69953548357662, "episode": 61.0, "batch_reward": 0.1466225662305951, "critic_loss": 0.43485497681796553, "actor_loss": -21.91080386352539, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.37369465827942, "step": 61000}
{"episode_reward": 12.530789976114532, "episode": 62.0, "batch_reward": 0.14446774549037217, "critic_loss": 0.39450356213748455, "actor_loss": -22.267799461364746, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.015443801879883, "step": 62000}
{"episode_reward": 9.703501713707942, "episode": 63.0, "batch_reward": 0.14300546162575484, "critic_loss": 0.37590214125812055, "actor_loss": -22.35374040222168, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.67734956741333, "step": 63000}
{"episode_reward": 3.7594154704458194, "episode": 64.0, "batch_reward": 0.1400774836689234, "critic_loss": 0.3171864971071482, "actor_loss": -22.205418323516845, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.498204946517944, "step": 64000}
{"episode_reward": 102.92790939505133, "episode": 65.0, "batch_reward": 0.1397987490668893, "critic_loss": 0.4015126011967659, "actor_loss": -22.14804130935669, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.197044849395752, "step": 65000}
{"episode_reward": 9.272159229355548, "episode": 66.0, "batch_reward": 0.14041721323132514, "critic_loss": 0.35576728111505507, "actor_loss": -22.31016548538208, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.751814126968384, "step": 66000}
{"episode_reward": 239.42856782046977, "episode": 67.0, "batch_reward": 0.1418868750333786, "critic_loss": 0.3045208954811096, "actor_loss": -22.39914691543579, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.117741584777832, "step": 67000}
{"episode_reward": 434.3118065522392, "episode": 68.0, "batch_reward": 0.14456792082637548, "critic_loss": 0.35133363658189776, "actor_loss": -22.659658473968506, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.049785614013672, "step": 68000}
{"episode_reward": 105.43510951150763, "episode": 69.0, "batch_reward": 0.14443297104537486, "critic_loss": 0.34954878012835977, "actor_loss": -22.646903270721435, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.119062900543213, "step": 69000}
{"episode_reward": 172.20459760732817, "episode": 70.0, "batch_reward": 0.14611234819889068, "critic_loss": 0.3348974348455668, "actor_loss": -22.79839073562622, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.761099576950073, "step": 70000}
{"episode_reward": 365.5354920382599, "episode": 71.0, "batch_reward": 0.1484379922002554, "critic_loss": 0.3925978116840124, "actor_loss": -22.997136577606202, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.753679037094116, "step": 71000}
{"episode_reward": 144.3084153615628, "episode": 72.0, "batch_reward": 0.14882025814801456, "critic_loss": 0.41134209647774694, "actor_loss": -23.177564338684082, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.310052156448364, "step": 72000}
{"episode_reward": 368.4939307844941, "episode": 73.0, "batch_reward": 0.15122463549673557, "critic_loss": 0.4056610415428877, "actor_loss": -23.286946403503418, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.259989261627197, "step": 73000}
{"episode_reward": 391.27469034536176, "episode": 74.0, "batch_reward": 0.1549845178872347, "critic_loss": 0.3868966924548149, "actor_loss": -23.804165897369383, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.22341823577881, "step": 74000}
{"episode_reward": 411.7537840229255, "episode": 75.0, "batch_reward": 0.158091791652143, "critic_loss": 0.4315740607827902, "actor_loss": -23.923428497314454, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.600080251693726, "step": 75000}
{"episode_reward": 202.81370234894078, "episode": 76.0, "batch_reward": 0.15897705072164536, "critic_loss": 0.42580346077680586, "actor_loss": -23.969635128021242, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.59071183204651, "step": 76000}
{"episode_reward": 401.8920595929452, "episode": 77.0, "batch_reward": 0.16265013939142228, "critic_loss": 0.4433765121102333, "actor_loss": -24.249530506134032, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.160563230514526, "step": 77000}
{"episode_reward": 378.15567795970384, "episode": 78.0, "batch_reward": 0.16515537958592177, "critic_loss": 0.4419752065092325, "actor_loss": -24.659776176452638, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.19322943687439, "step": 78000}
{"episode_reward": 465.44207564245954, "episode": 79.0, "batch_reward": 0.16853666330873968, "critic_loss": 0.4764471114128828, "actor_loss": -24.788267322540282, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.00417470932007, "step": 79000}
{"episode_reward": 274.21286891668126, "episode": 80.0, "batch_reward": 0.17092868472635747, "critic_loss": 0.4759396094381809, "actor_loss": -25.00544507598877, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.120973825454712, "step": 80000}
{"episode_reward": 370.0251766272146, "episode": 81.0, "batch_reward": 0.1729993360415101, "critic_loss": 0.46999187725782393, "actor_loss": -25.15141846847534, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.36893939971924, "step": 81000}
{"episode_reward": 269.75297655060257, "episode": 82.0, "batch_reward": 0.17421187976002694, "critic_loss": 0.49398455637693406, "actor_loss": -25.212942634582518, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.8331458568573, "step": 82000}
{"episode_reward": 270.8273547165745, "episode": 83.0, "batch_reward": 0.1761891711652279, "critic_loss": 0.46778803695738314, "actor_loss": -25.4753886680603, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.08901023864746, "step": 83000}
{"episode_reward": 408.11615737865924, "episode": 84.0, "batch_reward": 0.17672155463695527, "critic_loss": 0.5023205337971449, "actor_loss": -25.503182918548585, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.166222095489502, "step": 84000}
{"episode_reward": 301.79771083315234, "episode": 85.0, "batch_reward": 0.17853216050565243, "critic_loss": 0.48298731122910976, "actor_loss": -25.551112159729005, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.418731927871704, "step": 85000}
{"episode_reward": 348.35506485831286, "episode": 86.0, "batch_reward": 0.1811611906439066, "critic_loss": 0.5192933336943388, "actor_loss": -25.879439907073973, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.15740180015564, "step": 86000}
{"episode_reward": 426.7013644356492, "episode": 87.0, "batch_reward": 0.18388259476423263, "critic_loss": 0.5157388802617788, "actor_loss": -25.97528736114502, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.383852243423462, "step": 87000}
{"episode_reward": 245.5068143468787, "episode": 88.0, "batch_reward": 0.18491973119974137, "critic_loss": 0.49113508392870425, "actor_loss": -26.082337089538573, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.107466459274292, "step": 88000}
{"episode_reward": 272.56673743860983, "episode": 89.0, "batch_reward": 0.18683955331146718, "critic_loss": 0.5047098548114299, "actor_loss": -26.231091438293458, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.19409155845642, "step": 89000}
{"episode_reward": 516.0320005664377, "episode": 90.0, "batch_reward": 0.1895659188479185, "critic_loss": 0.49991758696734906, "actor_loss": -26.448641860961914, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.379441261291504, "step": 90000}
{"episode_reward": 481.48502856295596, "episode": 91.0, "batch_reward": 0.19328965306282042, "critic_loss": 0.4946629859060049, "actor_loss": -26.742480152130128, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.646568059921265, "step": 91000}
{"episode_reward": 493.1184145670727, "episode": 92.0, "batch_reward": 0.19533760291337968, "critic_loss": 0.4633134299516678, "actor_loss": -26.903880485534668, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.126535415649414, "step": 92000}
{"episode_reward": 328.3148574584852, "episode": 93.0, "batch_reward": 0.19750253258645534, "critic_loss": 0.47317498417198656, "actor_loss": -27.03497099304199, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.338446617126465, "step": 93000}
{"episode_reward": 412.74569116174615, "episode": 94.0, "batch_reward": 0.19889156801998614, "critic_loss": 0.4653318442553282, "actor_loss": -27.217162799835204, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.15855598449707, "step": 94000}
{"episode_reward": 111.47826284496115, "episode": 95.0, "batch_reward": 0.1978504796475172, "critic_loss": 0.44809902003407476, "actor_loss": -26.958530010223388, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.53198790550232, "step": 95000}
{"episode_reward": 46.8540030689155, "episode": 96.0, "batch_reward": 0.19909326142072678, "critic_loss": 0.4564233265817165, "actor_loss": -27.176549667358397, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.492560386657715, "step": 96000}
{"episode_reward": 555.8692899446188, "episode": 97.0, "batch_reward": 0.2021773090362549, "critic_loss": 0.4173473510146141, "actor_loss": -27.53053847885132, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.8615083694458, "step": 97000}
{"episode_reward": 548.7627458481993, "episode": 98.0, "batch_reward": 0.20524745509028436, "critic_loss": 0.45100135590136053, "actor_loss": -27.869948909759522, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.216333866119385, "step": 98000}
{"episode_reward": 184.4016438624533, "episode": 99.0, "batch_reward": 0.2025097317993641, "critic_loss": 0.4333866684883833, "actor_loss": -27.51489599227905, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.196165561676025, "step": 99000}
{"episode_reward": 159.0874795746433, "episode": 100.0, "batch_reward": 0.2051334640532732, "critic_loss": 0.4026742042452097, "actor_loss": -27.81260150909424, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.925716638565063, "step": 100000}
{"episode_reward": 509.20754325646215, "episode": 101.0, "batch_reward": 0.20784928479790687, "critic_loss": 0.4076345798820257, "actor_loss": -28.17649797439575, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.28473973274231, "step": 101000}
{"episode_reward": 552.6716377727071, "episode": 102.0, "batch_reward": 0.2129834015518427, "critic_loss": 0.3922088799029589, "actor_loss": -28.531486873626708, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.269603490829468, "step": 102000}
{"episode_reward": 602.0943525095078, "episode": 103.0, "batch_reward": 0.21418521106243132, "critic_loss": 0.37640876376628873, "actor_loss": -28.524621528625488, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.888888835906982, "step": 103000}
{"episode_reward": 289.39641602015644, "episode": 104.0, "batch_reward": 0.21640465447306634, "critic_loss": 0.39631299978494644, "actor_loss": -28.561225734710693, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.763928413391113, "step": 104000}
{"episode_reward": 293.05143840006923, "episode": 105.0, "batch_reward": 0.2151963883638382, "critic_loss": 0.3942832088172436, "actor_loss": -28.478571754455565, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.767675399780273, "step": 105000}
{"episode_reward": 137.325865618801, "episode": 106.0, "batch_reward": 0.21494277745485305, "critic_loss": 0.3692564263343811, "actor_loss": -28.45347691345215, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.273377180099487, "step": 106000}
{"episode_reward": 328.4367816791468, "episode": 107.0, "batch_reward": 0.2160714518725872, "critic_loss": 0.38328492982685564, "actor_loss": -28.436219551086428, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.318920850753784, "step": 107000}
{"episode_reward": 564.5835590875344, "episode": 108.0, "batch_reward": 0.22045553350448607, "critic_loss": 0.36309325489401817, "actor_loss": -28.794823791503905, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.447749376296997, "step": 108000}
{"episode_reward": 557.745630683518, "episode": 109.0, "batch_reward": 0.22241436016559601, "critic_loss": 0.35925145335495473, "actor_loss": -28.92977124404907, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.360810041427612, "step": 109000}
{"episode_reward": 277.2278130815913, "episode": 110.0, "batch_reward": 0.22355192156136036, "critic_loss": 0.3842645971626043, "actor_loss": -28.893131481170656, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.75027346611023, "step": 110000}
{"episode_reward": 231.04317951779763, "episode": 111.0, "batch_reward": 0.22398874209821223, "critic_loss": 0.3510321372151375, "actor_loss": -28.952571647644042, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.57752466201782, "step": 111000}
{"episode_reward": 545.3651047946385, "episode": 112.0, "batch_reward": 0.2259491058140993, "critic_loss": 0.3579660220593214, "actor_loss": -29.013732776641845, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.96236538887024, "step": 112000}
{"episode_reward": 570.7934855746471, "episode": 113.0, "batch_reward": 0.2305952972471714, "critic_loss": 0.3659660024270415, "actor_loss": -29.233276065826416, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.846010446548462, "step": 113000}
{"episode_reward": 408.1580444718113, "episode": 114.0, "batch_reward": 0.23086175799369812, "critic_loss": 0.37490208335220815, "actor_loss": -29.28100214385986, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.533819437026978, "step": 114000}
{"episode_reward": 589.3547226546032, "episode": 115.0, "batch_reward": 0.23443453036248685, "critic_loss": 0.38411445593833926, "actor_loss": -29.406183086395263, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.410834074020386, "step": 115000}
{"episode_reward": 498.07254680940287, "episode": 116.0, "batch_reward": 0.23572385261952877, "critic_loss": 0.37974455493688586, "actor_loss": -29.471328529357912, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.049691438674927, "step": 116000}
{"episode_reward": 390.71789396816183, "episode": 117.0, "batch_reward": 0.23889493423700334, "critic_loss": 0.3718245919346809, "actor_loss": -29.565097427368165, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.559681177139282, "step": 117000}
{"episode_reward": 607.5373321129672, "episode": 118.0, "batch_reward": 0.2415172579139471, "critic_loss": 0.39254864111542703, "actor_loss": -29.788628566741945, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.875712633132935, "step": 118000}
{"episode_reward": 579.5490483127527, "episode": 119.0, "batch_reward": 0.2437645047456026, "critic_loss": 0.3921658667176962, "actor_loss": -29.992282192230224, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.26665949821472, "step": 119000}
{"episode_reward": 592.8009846103048, "episode": 120.0, "batch_reward": 0.24647302900254725, "critic_loss": 0.3745709327608347, "actor_loss": -30.220518562316894, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.249573945999146, "step": 120000}
{"episode_reward": 647.83509880415, "episode": 121.0, "batch_reward": 0.25045909079909323, "critic_loss": 0.3609390316605568, "actor_loss": -30.572047492980957, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.742709159851074, "step": 121000}
{"episode_reward": 627.5315921693947, "episode": 122.0, "batch_reward": 0.25318360754847524, "critic_loss": 0.3632152647525072, "actor_loss": -30.590579246520996, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.737008810043335, "step": 122000}
{"episode_reward": 570.8924058802705, "episode": 123.0, "batch_reward": 0.25632485702633856, "critic_loss": 0.3526564316600561, "actor_loss": -30.92428015899658, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 23.275766134262085, "step": 123000}
{"episode_reward": 601.409396732933, "episode": 124.0, "batch_reward": 0.25858887124061586, "critic_loss": 0.38378913451731206, "actor_loss": -31.069847763061524, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 23.242034912109375, "step": 124000}
{"episode_reward": 298.4010350893892, "episode": 125.0, "batch_reward": 0.2589615675061941, "critic_loss": 0.3491973818838596, "actor_loss": -31.03537593460083, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 23.072572708129883, "step": 125000}
{"episode_reward": 675.0901588996243, "episode": 126.0, "batch_reward": 0.26335454353690146, "critic_loss": 0.3905988029837608, "actor_loss": -31.454413318634032, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.211551666259766, "step": 126000}
{"episode_reward": 592.000149869106, "episode": 127.0, "batch_reward": 0.2648060532659292, "critic_loss": 0.3755748161226511, "actor_loss": -31.417703678131105, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.715769052505493, "step": 127000}
{"episode_reward": 608.3875887630638, "episode": 128.0, "batch_reward": 0.26590582956373693, "critic_loss": 0.3622358051985502, "actor_loss": -31.540361766815185, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.397175312042236, "step": 128000}
{"episode_reward": 172.69078471654893, "episode": 129.0, "batch_reward": 0.26549180191755295, "critic_loss": 0.3706696979254484, "actor_loss": -31.547978664398194, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.283466339111328, "step": 129000}
{"episode_reward": 354.38235602784766, "episode": 130.0, "batch_reward": 0.26715493154525755, "critic_loss": 0.3653377790004015, "actor_loss": -31.729147438049317, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.18904972076416, "step": 130000}
{"episode_reward": 634.8385652239972, "episode": 131.0, "batch_reward": 0.26952858769893645, "critic_loss": 0.44329194512963294, "actor_loss": -31.731415687561036, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.65801000595093, "step": 131000}
{"episode_reward": 627.445855478604, "episode": 132.0, "batch_reward": 0.27229087506234645, "critic_loss": 0.4364879455417395, "actor_loss": -31.968742263793946, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.42945671081543, "step": 132000}
{"episode_reward": 590.2950231019262, "episode": 133.0, "batch_reward": 0.2731690051704645, "critic_loss": 0.43219671793282033, "actor_loss": -32.00037051010132, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.2814519405365, "step": 133000}
{"episode_reward": 109.10858111756671, "episode": 134.0, "batch_reward": 0.2747682327777147, "critic_loss": 0.41595312459766864, "actor_loss": -32.31290068435669, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.004858255386353, "step": 134000}
{"episode_reward": 238.31440314546342, "episode": 135.0, "batch_reward": 0.2730355774313211, "critic_loss": 0.4237219778597355, "actor_loss": -32.112367809295655, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.012844562530518, "step": 135000}
{"episode_reward": 512.4764971389922, "episode": 136.0, "batch_reward": 0.2743190216869116, "critic_loss": 0.45147895893454554, "actor_loss": -32.26981827926636, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.50892686843872, "step": 136000}
{"episode_reward": 556.691243090265, "episode": 137.0, "batch_reward": 0.2782880441993475, "critic_loss": 0.4751428075581789, "actor_loss": -32.54226108169556, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.72928547859192, "step": 137000}
{"episode_reward": 124.24260196901801, "episode": 138.0, "batch_reward": 0.2771156738847494, "critic_loss": 0.47495286354422567, "actor_loss": -32.43225007629395, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.958088636398315, "step": 138000}
{"episode_reward": 597.2249238093266, "episode": 139.0, "batch_reward": 0.278582112967968, "critic_loss": 0.40842416720092295, "actor_loss": -32.60971491241455, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.633095264434814, "step": 139000}
{"episode_reward": 187.05962062226047, "episode": 140.0, "batch_reward": 0.2784364070892334, "critic_loss": 0.3978925747871399, "actor_loss": -32.47854331207275, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 23.31341242790222, "step": 140000}
{"episode_reward": 664.9206706817268, "episode": 141.0, "batch_reward": 0.2808540358543396, "critic_loss": 0.43082266569137573, "actor_loss": -32.70703590393067, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 38.68322253227234, "step": 141000}
{"episode_reward": 307.89423817510493, "episode": 142.0, "batch_reward": 0.28023969833552836, "critic_loss": 0.4071399198025465, "actor_loss": -32.51558840942383, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.0562744140625, "step": 142000}
{"episode_reward": 691.2102620113264, "episode": 143.0, "batch_reward": 0.2845958568006754, "critic_loss": 0.4291448430120945, "actor_loss": -32.87481476974487, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.396721363067627, "step": 143000}
{"episode_reward": 337.2498877669646, "episode": 144.0, "batch_reward": 0.28499411794543267, "critic_loss": 0.4203502455204725, "actor_loss": -32.92347676467895, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.762250661849976, "step": 144000}
{"episode_reward": 595.1387554346636, "episode": 145.0, "batch_reward": 0.2872192144393921, "critic_loss": 0.41864029890298843, "actor_loss": -32.955469650268554, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.262920379638672, "step": 145000}
{"episode_reward": 543.9152480076967, "episode": 146.0, "batch_reward": 0.2871357147842646, "critic_loss": 0.4383207921534777, "actor_loss": -33.051507118225096, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.534204483032227, "step": 146000}
{"episode_reward": 519.1946156898188, "episode": 147.0, "batch_reward": 0.2907136870920658, "critic_loss": 0.4136368704587221, "actor_loss": -33.25791856384277, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.306444883346558, "step": 147000}
{"episode_reward": 558.9218046469998, "episode": 148.0, "batch_reward": 0.2906912813484669, "critic_loss": 0.41197871930897234, "actor_loss": -33.27064078140259, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.842041492462158, "step": 148000}
{"episode_reward": 93.20664212160443, "episode": 149.0, "batch_reward": 0.29092805993556975, "critic_loss": 0.432111536860466, "actor_loss": -33.20589958190918, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.052332639694214, "step": 149000}
{"episode_reward": 664.462012656948, "episode": 150.0, "batch_reward": 0.2925265567302704, "critic_loss": 0.41795568481087686, "actor_loss": -33.32447844696045, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "step": 150000}
