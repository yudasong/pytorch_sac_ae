{"episode_reward": 0.0, "episode": 1.0, "duration": 28.940362453460693, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 2.6211822032928467, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.2609082745259585, "critic_loss": 0.17345131179438944, "actor_loss": -44.05658413496624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 85.18351435661316, "step": 3000}
{"episode_reward": 17.348223245612076, "episode": 4.0, "batch_reward": 0.21370375434309244, "critic_loss": 0.347562037371099, "actor_loss": -35.04641432952881, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.115569829940796, "step": 4000}
{"episode_reward": 498.338908676202, "episode": 5.0, "batch_reward": 0.28400464057922364, "critic_loss": 0.4298408337533474, "actor_loss": -39.991350788116456, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.709574937820435, "step": 5000}
{"episode_reward": 509.75969160730085, "episode": 6.0, "batch_reward": 0.31823251785337925, "critic_loss": 0.5389674653112888, "actor_loss": -42.40939805603028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.618706464767456, "step": 6000}
{"episode_reward": 455.1177184984186, "episode": 7.0, "batch_reward": 0.35147361299395563, "critic_loss": 0.5498556408286095, "actor_loss": -44.81936376953125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.4556622505188, "step": 7000}
{"episode_reward": 607.6365850238335, "episode": 8.0, "batch_reward": 0.38023818224668504, "critic_loss": 0.6138346062004566, "actor_loss": -46.95003028869629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.86358904838562, "step": 8000}
{"episode_reward": 513.367723038221, "episode": 9.0, "batch_reward": 0.40402034962177275, "critic_loss": 0.6925732063055039, "actor_loss": -48.092161102294924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.591243267059326, "step": 9000}
{"episode_reward": 622.422311777866, "episode": 10.0, "batch_reward": 0.4223342980444431, "critic_loss": 0.6990189649760723, "actor_loss": -49.543210639953614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.209859132766724, "step": 10000}
{"episode_reward": 505.7396669535468, "episode": 11.0, "batch_reward": 0.43407489654421805, "critic_loss": 0.697973154783249, "actor_loss": -49.98637631988525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 58.58709144592285, "step": 11000}
{"episode_reward": 594.1849795460517, "episode": 12.0, "batch_reward": 0.4435815911591053, "critic_loss": 0.639997962474823, "actor_loss": -50.5393309173584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.77081799507141, "step": 12000}
{"episode_reward": 545.8522697081402, "episode": 13.0, "batch_reward": 0.4542942058146, "critic_loss": 0.6505882002711296, "actor_loss": -51.29427233886719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.585867643356323, "step": 13000}
{"episode_reward": 599.8690657674267, "episode": 14.0, "batch_reward": 0.46409282717108724, "critic_loss": 0.6053172394037246, "actor_loss": -51.952880477905275, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.87471842765808, "step": 14000}
{"episode_reward": 596.4390480307814, "episode": 15.0, "batch_reward": 0.46811095118522644, "critic_loss": 0.6599736513495446, "actor_loss": -51.78272916412354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.363162517547607, "step": 15000}
{"episode_reward": 266.771056761703, "episode": 16.0, "batch_reward": 0.45699747404456137, "critic_loss": 0.6244665552675724, "actor_loss": -50.757904136657714, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.646332502365112, "step": 16000}
{"episode_reward": 537.3401022043012, "episode": 17.0, "batch_reward": 0.46436817246675494, "critic_loss": 0.5879421273767949, "actor_loss": -51.22994160461426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.54640769958496, "step": 17000}
{"episode_reward": 581.0462904453922, "episode": 18.0, "batch_reward": 0.4715849928855896, "critic_loss": 0.5857041875720024, "actor_loss": -51.77698299407959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.796940088272095, "step": 18000}
{"episode_reward": 556.7576370841468, "episode": 19.0, "batch_reward": 0.4724101659357548, "critic_loss": 0.6213548280894756, "actor_loss": -51.79541011810303, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.37727451324463, "step": 19000}
{"episode_reward": 487.37932354174063, "episode": 20.0, "batch_reward": 0.47495354345440866, "critic_loss": 0.6517020131647587, "actor_loss": -52.19743994903565, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.315539121627808, "step": 20000}
{"episode_reward": 552.5907462196074, "episode": 21.0, "batch_reward": 0.481950166374445, "critic_loss": 0.6517573219835758, "actor_loss": -51.920610137939455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 57.9557785987854, "step": 21000}
{"episode_reward": 618.3541962890129, "episode": 22.0, "batch_reward": 0.487348796159029, "critic_loss": 0.6964055887758732, "actor_loss": -52.838907600402834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.348376989364624, "step": 22000}
{"episode_reward": 585.0560805025646, "episode": 23.0, "batch_reward": 0.49057813346385953, "critic_loss": 0.7223157470822335, "actor_loss": -52.973372901916505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.81620502471924, "step": 23000}
{"episode_reward": 588.3679295646232, "episode": 24.0, "batch_reward": 0.49766762045025825, "critic_loss": 0.6765732965767384, "actor_loss": -53.06428656005859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.085007190704346, "step": 24000}
{"episode_reward": 624.6655050627307, "episode": 25.0, "batch_reward": 0.502207802027464, "critic_loss": 0.6695412135124207, "actor_loss": -53.92590655517578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.40291738510132, "step": 25000}
{"episode_reward": 653.9850883519389, "episode": 26.0, "batch_reward": 0.5072207676172257, "critic_loss": 0.6718276324272155, "actor_loss": -53.89816036987305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.685017585754395, "step": 26000}
{"episode_reward": 642.9884004478986, "episode": 27.0, "batch_reward": 0.5099949984252453, "critic_loss": 0.6831795282661914, "actor_loss": -53.96720791625977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.46321153640747, "step": 27000}
{"episode_reward": 269.4099958435322, "episode": 28.0, "batch_reward": 0.5037064902186393, "critic_loss": 0.7071075419783592, "actor_loss": -53.043196525573734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.741499423980713, "step": 28000}
{"episode_reward": 647.5144043864666, "episode": 29.0, "batch_reward": 0.50844549497962, "critic_loss": 0.7345437643527984, "actor_loss": -53.731547439575195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.299134969711304, "step": 29000}
{"episode_reward": 602.9574199138415, "episode": 30.0, "batch_reward": 0.5121754287481308, "critic_loss": 0.7183715862333775, "actor_loss": -54.0059236831665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.49034571647644, "step": 30000}
{"episode_reward": 633.2477208820279, "episode": 31.0, "batch_reward": 0.5130489954352379, "critic_loss": 0.731629666686058, "actor_loss": -53.83474635314941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 57.36329126358032, "step": 31000}
{"episode_reward": 507.3531242191269, "episode": 32.0, "batch_reward": 0.5153651657700539, "critic_loss": 0.7577899373471737, "actor_loss": -54.10573874664307, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.650480270385742, "step": 32000}
{"episode_reward": 604.9809753743361, "episode": 33.0, "batch_reward": 0.5173029298484325, "critic_loss": 0.8177396307587623, "actor_loss": -54.374322761535645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.70737385749817, "step": 33000}
{"episode_reward": 568.2390277485813, "episode": 34.0, "batch_reward": 0.5207048098444939, "critic_loss": 0.8740737226605415, "actor_loss": -54.45826863098144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.133259057998657, "step": 34000}
{"episode_reward": 458.5451116217715, "episode": 35.0, "batch_reward": 0.5184550319612026, "critic_loss": 0.8138762834966182, "actor_loss": -53.90079647827149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.27480959892273, "step": 35000}
{"episode_reward": 666.0068519257369, "episode": 36.0, "batch_reward": 0.5220470495522023, "critic_loss": 0.7715669470727444, "actor_loss": -54.52531804656982, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.21428346633911, "step": 36000}
{"episode_reward": 597.7442166845623, "episode": 37.0, "batch_reward": 0.5233804735839367, "critic_loss": 0.7950500954687595, "actor_loss": -54.4668882522583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.52732253074646, "step": 37000}
{"episode_reward": 564.4670753779399, "episode": 38.0, "batch_reward": 0.5252383993268013, "critic_loss": 0.773491470605135, "actor_loss": -54.92610292816162, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.410287618637085, "step": 38000}
{"episode_reward": 657.9713909898966, "episode": 39.0, "batch_reward": 0.5279233482480049, "critic_loss": 0.8079658263623715, "actor_loss": -55.206037048339844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.314130783081055, "step": 39000}
{"episode_reward": 649.6947349674609, "episode": 40.0, "batch_reward": 0.5323687939345837, "critic_loss": 0.8235475725829601, "actor_loss": -55.66348281860351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.633108139038086, "step": 40000}
{"episode_reward": 659.7783802208315, "episode": 41.0, "batch_reward": 0.5341681672632694, "critic_loss": 0.8794505695700645, "actor_loss": -55.319196716308596, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 57.45810651779175, "step": 41000}
{"episode_reward": 601.2007059799554, "episode": 42.0, "batch_reward": 0.5370248947143554, "critic_loss": 0.8571552720367909, "actor_loss": -55.57105184936523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.869344234466553, "step": 42000}
{"episode_reward": 638.6661080814206, "episode": 43.0, "batch_reward": 0.5389711118340492, "critic_loss": 0.8988066756129265, "actor_loss": -55.85125363922119, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.84860920906067, "step": 43000}
{"episode_reward": 649.3188168770533, "episode": 44.0, "batch_reward": 0.5378318721354007, "critic_loss": 0.9598349692225456, "actor_loss": -55.507888648986814, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.14827537536621, "step": 44000}
{"episode_reward": 499.381628340398, "episode": 45.0, "batch_reward": 0.5414594526290893, "critic_loss": 0.9230827037990094, "actor_loss": -55.72481746673584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.288177490234375, "step": 45000}
{"episode_reward": 656.5342798045758, "episode": 46.0, "batch_reward": 0.5414924954473972, "critic_loss": 0.964097059994936, "actor_loss": -55.85324208831787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.365087509155273, "step": 46000}
{"episode_reward": 535.7699798146955, "episode": 47.0, "batch_reward": 0.5428619155585765, "critic_loss": 0.9596249735951423, "actor_loss": -55.577456748962405, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.855830669403076, "step": 47000}
{"episode_reward": 659.4810138957924, "episode": 48.0, "batch_reward": 0.5461182187497616, "critic_loss": 0.9650251948237419, "actor_loss": -56.22445407867431, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.383848905563354, "step": 48000}
{"episode_reward": 649.5948369598372, "episode": 49.0, "batch_reward": 0.5489585568904877, "critic_loss": 0.873443613409996, "actor_loss": -56.437392028808596, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.811335563659668, "step": 49000}
{"episode_reward": 639.3567732195029, "episode": 50.0, "batch_reward": 0.5478153547346591, "critic_loss": 0.8681050146222115, "actor_loss": -56.013867027282714, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.213894605636597, "step": 50000}
{"episode_reward": 634.5267506783649, "episode": 51.0, "batch_reward": 0.5507294373512268, "critic_loss": 0.8643151960670948, "actor_loss": -56.5567434387207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 56.24537658691406, "step": 51000}
{"episode_reward": 553.8553179707031, "episode": 52.0, "batch_reward": 0.5496536479592323, "critic_loss": 0.8422877747118473, "actor_loss": -56.235415649414065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.018559455871582, "step": 52000}
{"episode_reward": 636.2213383106517, "episode": 53.0, "batch_reward": 0.5530863805711269, "critic_loss": 0.843288547962904, "actor_loss": -56.68840661621094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.284221649169922, "step": 53000}
{"episode_reward": 637.4053318619734, "episode": 54.0, "batch_reward": 0.5534518437683582, "critic_loss": 0.8033710469901562, "actor_loss": -56.89235890960693, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.48432159423828, "step": 54000}
{"episode_reward": 609.1713962309881, "episode": 55.0, "batch_reward": 0.553640522390604, "critic_loss": 0.8483127908110618, "actor_loss": -57.08320156097412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.060735940933228, "step": 55000}
{"episode_reward": 580.4989501753032, "episode": 56.0, "batch_reward": 0.5540881622433662, "critic_loss": 0.8292117202579975, "actor_loss": -56.988948348999024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.28226947784424, "step": 56000}
{"episode_reward": 532.0892646451548, "episode": 57.0, "batch_reward": 0.554894315481186, "critic_loss": 0.8257763127684593, "actor_loss": -56.895739639282226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.70234966278076, "step": 57000}
{"episode_reward": 627.1405361583842, "episode": 58.0, "batch_reward": 0.5566254650950432, "critic_loss": 0.7741609862148762, "actor_loss": -57.24154428100586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.45178985595703, "step": 58000}
{"episode_reward": 664.0419352452195, "episode": 59.0, "batch_reward": 0.5581161918640136, "critic_loss": 0.8137748613357544, "actor_loss": -57.7355532913208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.624455451965332, "step": 59000}
{"episode_reward": 638.2581353543279, "episode": 60.0, "batch_reward": 0.5594020531475544, "critic_loss": 0.8627196636497975, "actor_loss": -57.34391859436035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.47123074531555, "step": 60000}
{"episode_reward": 565.2491202022137, "episode": 61.0, "batch_reward": 0.5579493160843849, "critic_loss": 0.9336466965079308, "actor_loss": -57.104559913635256, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 56.86282205581665, "step": 61000}
{"episode_reward": 439.23967901271203, "episode": 62.0, "batch_reward": 0.5574597615897655, "critic_loss": 0.9197544425427914, "actor_loss": -57.013057418823244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.78990364074707, "step": 62000}
{"episode_reward": 594.7849103702326, "episode": 63.0, "batch_reward": 0.5587748216688633, "critic_loss": 0.8786703559756279, "actor_loss": -57.29479355621338, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.22822618484497, "step": 63000}
{"episode_reward": 636.6938344862798, "episode": 64.0, "batch_reward": 0.5611193671524525, "critic_loss": 0.8840108472406865, "actor_loss": -57.49076096343994, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.97247338294983, "step": 64000}
{"episode_reward": 606.2787552865524, "episode": 65.0, "batch_reward": 0.5616972813308239, "critic_loss": 0.862507627338171, "actor_loss": -57.522105331420896, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.842039585113525, "step": 65000}
{"episode_reward": 680.3440823752695, "episode": 66.0, "batch_reward": 0.5628915588855743, "critic_loss": 0.8481518843472003, "actor_loss": -57.71863510131836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.509601593017578, "step": 66000}
{"episode_reward": 652.9905984365766, "episode": 67.0, "batch_reward": 0.5646704996824264, "critic_loss": 0.8875006832182407, "actor_loss": -57.852583404541015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.41887140274048, "step": 67000}
{"episode_reward": 669.9192640715355, "episode": 68.0, "batch_reward": 0.5667506616413593, "critic_loss": 0.8096085497736931, "actor_loss": -58.07369901275635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.531649112701416, "step": 68000}
{"episode_reward": 643.8627656575036, "episode": 69.0, "batch_reward": 0.568432103574276, "critic_loss": 0.8116876149773598, "actor_loss": -57.869856521606444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.58239722251892, "step": 69000}
{"episode_reward": 672.8075775823485, "episode": 70.0, "batch_reward": 0.5678019956350326, "critic_loss": 0.8591206727623939, "actor_loss": -58.072570526123044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.57071042060852, "step": 70000}
{"episode_reward": 648.7371539594345, "episode": 71.0, "batch_reward": 0.5691809297800065, "critic_loss": 0.8326248890161514, "actor_loss": -58.07992826080322, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 56.74179697036743, "step": 71000}
{"episode_reward": 625.6465695353426, "episode": 72.0, "batch_reward": 0.5695628252029419, "critic_loss": 0.813920311063528, "actor_loss": -58.256260597229, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.228734254837036, "step": 72000}
{"episode_reward": 621.83423735948, "episode": 73.0, "batch_reward": 0.5712977379560471, "critic_loss": 0.790592360407114, "actor_loss": -58.116010314941406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.233500719070435, "step": 73000}
{"episode_reward": 590.9875946125227, "episode": 74.0, "batch_reward": 0.5696462645530701, "critic_loss": 0.809615793377161, "actor_loss": -57.950775436401365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.73368811607361, "step": 74000}
{"episode_reward": 493.4786139274478, "episode": 75.0, "batch_reward": 0.5705474409461021, "critic_loss": 0.8346555268764496, "actor_loss": -58.54505570983887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.662580966949463, "step": 75000}
{"episode_reward": 650.1673621158271, "episode": 76.0, "batch_reward": 0.5719450784921646, "critic_loss": 0.8295949111878872, "actor_loss": -58.4990792388916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.228037118911743, "step": 76000}
{"episode_reward": 670.8191712922236, "episode": 77.0, "batch_reward": 0.5730739485025406, "critic_loss": 0.7695400690734386, "actor_loss": -58.517399040222166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.562313079833984, "step": 77000}
{"episode_reward": 658.0322894140847, "episode": 78.0, "batch_reward": 0.5730224208831787, "critic_loss": 0.7698982122540474, "actor_loss": -58.4652340927124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.46324372291565, "step": 78000}
{"episode_reward": 603.0583431698379, "episode": 79.0, "batch_reward": 0.5748343857824803, "critic_loss": 0.7386838429868221, "actor_loss": -58.66214985656738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.236567497253418, "step": 79000}
{"episode_reward": 631.4284416700349, "episode": 80.0, "batch_reward": 0.5747723340392112, "critic_loss": 0.796680240124464, "actor_loss": -58.790092628479, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.53790831565857, "step": 80000}
{"episode_reward": 676.0104214669515, "episode": 81.0, "batch_reward": 0.5752043897509574, "critic_loss": 0.8072702495753765, "actor_loss": -58.65331137084961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.56925988197327, "step": 81000}
{"episode_reward": 670.0688945090909, "episode": 82.0, "batch_reward": 0.5766354405879974, "critic_loss": 0.7915358011424541, "actor_loss": -58.64203771972656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.24086046218872, "step": 82000}
{"episode_reward": 691.3817476021408, "episode": 83.0, "batch_reward": 0.578060376048088, "critic_loss": 0.8098601842820644, "actor_loss": -58.910454460144045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.118497610092163, "step": 83000}
{"episode_reward": 638.225564756616, "episode": 84.0, "batch_reward": 0.5781740413308144, "critic_loss": 0.8349180696904659, "actor_loss": -58.807826698303224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.506636142730713, "step": 84000}
{"episode_reward": 667.8609999436669, "episode": 85.0, "batch_reward": 0.5812606595754624, "critic_loss": 0.850550185650587, "actor_loss": -59.33190504455566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.662533044815063, "step": 85000}
{"episode_reward": 591.7155629500742, "episode": 86.0, "batch_reward": 0.5803292853236198, "critic_loss": 0.8616264122128486, "actor_loss": -59.08961429595947, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.503276586532593, "step": 86000}
{"episode_reward": 540.0756008864014, "episode": 87.0, "batch_reward": 0.5800766578912735, "critic_loss": 0.8936823651194572, "actor_loss": -58.98561893463135, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.585824012756348, "step": 87000}
{"episode_reward": 594.1311033586313, "episode": 88.0, "batch_reward": 0.5795617084503174, "critic_loss": 0.928622056543827, "actor_loss": -58.88080197906494, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.688039302825928, "step": 88000}
{"episode_reward": 683.2071366425905, "episode": 89.0, "batch_reward": 0.5820061715245247, "critic_loss": 0.9008164407908916, "actor_loss": -59.12712386322021, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.757862091064453, "step": 89000}
{"episode_reward": 705.7085913411004, "episode": 90.0, "batch_reward": 0.583040884912014, "critic_loss": 0.8880474281609059, "actor_loss": -58.87667039489746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.65523624420166, "step": 90000}
{"episode_reward": 670.1122142095924, "episode": 91.0, "batch_reward": 0.5824199022054672, "critic_loss": 0.8421864710748196, "actor_loss": -59.233734954833984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.63728976249695, "step": 91000}
{"episode_reward": 575.262172707634, "episode": 92.0, "batch_reward": 0.5831918656229973, "critic_loss": 0.852557620972395, "actor_loss": -59.055450088500976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.963968753814697, "step": 92000}
{"episode_reward": 662.1402884786929, "episode": 93.0, "batch_reward": 0.5838709284067154, "critic_loss": 0.8992254674732685, "actor_loss": -59.25027839660645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.81044626235962, "step": 93000}
{"episode_reward": 535.1196346316557, "episode": 94.0, "batch_reward": 0.5839385557770729, "critic_loss": 0.9096220953166485, "actor_loss": -59.099515846252444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.114924430847168, "step": 94000}
{"episode_reward": 593.5217603734717, "episode": 95.0, "batch_reward": 0.5848440081477165, "critic_loss": 0.8875399380028248, "actor_loss": -59.34669641876221, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.3110568523407, "step": 95000}
{"episode_reward": 677.8605976608413, "episode": 96.0, "batch_reward": 0.5852749615311622, "critic_loss": 0.9027790006399155, "actor_loss": -59.408539230346676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.476190090179443, "step": 96000}
{"episode_reward": 659.9278458396385, "episode": 97.0, "batch_reward": 0.5859480894804001, "critic_loss": 0.863654192596674, "actor_loss": -59.39385001373291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.88651466369629, "step": 97000}
{"episode_reward": 688.7812779602449, "episode": 98.0, "batch_reward": 0.5866696696281433, "critic_loss": 0.8618513746261597, "actor_loss": -59.40811894226074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.497981309890747, "step": 98000}
{"episode_reward": 675.2925638779478, "episode": 99.0, "batch_reward": 0.5879912213683128, "critic_loss": 0.8902138241827487, "actor_loss": -59.50719581604004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.415805101394653, "step": 99000}
{"episode_reward": 649.2163911072646, "episode": 100.0, "batch_reward": 0.5889465801715851, "critic_loss": 0.8702783291637898, "actor_loss": -59.70120372009277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.63023281097412, "step": 100000}
{"episode_reward": 664.187678349457, "episode": 101.0, "batch_reward": 0.589334332704544, "critic_loss": 0.8880137311518193, "actor_loss": -59.50064360809326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.78463625907898, "step": 101000}
{"episode_reward": 659.3849148197786, "episode": 102.0, "batch_reward": 0.590395116686821, "critic_loss": 0.8847015043795109, "actor_loss": -59.81836134338379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.455175399780273, "step": 102000}
{"episode_reward": 677.6945971891406, "episode": 103.0, "batch_reward": 0.5912146646380424, "critic_loss": 0.9008438011407852, "actor_loss": -59.658986366271975, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.8623685836792, "step": 103000}
{"episode_reward": 669.3713041784996, "episode": 104.0, "batch_reward": 0.5918135059475899, "critic_loss": 0.9519345227777958, "actor_loss": -60.00373826599121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.266809701919556, "step": 104000}
{"episode_reward": 700.112363793309, "episode": 105.0, "batch_reward": 0.5924944871068001, "critic_loss": 0.9920045327842235, "actor_loss": -59.93412707519531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.823629140853882, "step": 105000}
{"episode_reward": 709.0166669566086, "episode": 106.0, "batch_reward": 0.5925570495724678, "critic_loss": 0.9770014430582523, "actor_loss": -60.20615128326416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.722856998443604, "step": 106000}
{"episode_reward": 546.2128648123644, "episode": 107.0, "batch_reward": 0.5932098999023437, "critic_loss": 0.9980984696745873, "actor_loss": -60.16248585510254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.427584409713745, "step": 107000}
{"episode_reward": 693.8773560567255, "episode": 108.0, "batch_reward": 0.593841547369957, "critic_loss": 1.005774396598339, "actor_loss": -60.057337608337406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.93674349784851, "step": 108000}
{"episode_reward": 662.0976295390018, "episode": 109.0, "batch_reward": 0.5939435580968857, "critic_loss": 1.007151242941618, "actor_loss": -60.12534854888916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.412281274795532, "step": 109000}
{"episode_reward": 679.5594269788381, "episode": 110.0, "batch_reward": 0.5954571279883385, "critic_loss": 1.026443736165762, "actor_loss": -60.26761534118652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.265742778778076, "step": 110000}
{"episode_reward": 678.782721361314, "episode": 111.0, "batch_reward": 0.5958334439992905, "critic_loss": 0.9815703762471676, "actor_loss": -60.285005989074705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.248045921325684, "step": 111000}
{"episode_reward": 693.214387638996, "episode": 112.0, "batch_reward": 0.5972332721948623, "critic_loss": 1.0706897292733193, "actor_loss": -60.63982428741455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.586212873458862, "step": 112000}
{"episode_reward": 679.290290558844, "episode": 113.0, "batch_reward": 0.5974511379599571, "critic_loss": 1.0049747321605682, "actor_loss": -60.30085845184326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.256094217300415, "step": 113000}
{"episode_reward": 660.5639283118437, "episode": 114.0, "batch_reward": 0.598021830022335, "critic_loss": 0.9961163291335106, "actor_loss": -60.60294233703613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.001964330673218, "step": 114000}
{"episode_reward": 682.2019950620903, "episode": 115.0, "batch_reward": 0.5987276657819748, "critic_loss": 0.99911660861969, "actor_loss": -60.70486253356933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.584046602249146, "step": 115000}
{"episode_reward": 674.9425215094911, "episode": 116.0, "batch_reward": 0.5992182111144065, "critic_loss": 1.0106284669041634, "actor_loss": -60.645839515686035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.637677669525146, "step": 116000}
{"episode_reward": 619.3276760255488, "episode": 117.0, "batch_reward": 0.5991259652972222, "critic_loss": 1.0475138576030731, "actor_loss": -60.64227560424805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.57131004333496, "step": 117000}
{"episode_reward": 598.618255931778, "episode": 118.0, "batch_reward": 0.5998066806793213, "critic_loss": 1.0595653593838215, "actor_loss": -60.608206535339356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.698655605316162, "step": 118000}
{"episode_reward": 594.9133512103639, "episode": 119.0, "batch_reward": 0.600009488582611, "critic_loss": 1.0758519934117794, "actor_loss": -60.70175427246094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.49248743057251, "step": 119000}
{"episode_reward": 608.0131824639369, "episode": 120.0, "batch_reward": 0.5996953051686287, "critic_loss": 1.0633694929778577, "actor_loss": -60.86271408081055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.354873418807983, "step": 120000}
{"episode_reward": 610.68835452027, "episode": 121.0, "batch_reward": 0.5999365458488465, "critic_loss": 1.1120754916667939, "actor_loss": -60.71750039672852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.18040180206299, "step": 121000}
{"episode_reward": 668.1104662258718, "episode": 122.0, "batch_reward": 0.6013995639681816, "critic_loss": 1.0987312197685242, "actor_loss": -60.949448997497555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.3381450176239, "step": 122000}
{"episode_reward": 661.5652662790083, "episode": 123.0, "batch_reward": 0.6008778297901154, "critic_loss": 1.0637488542795182, "actor_loss": -60.92917375183105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.51223111152649, "step": 123000}
{"episode_reward": 685.7901669269252, "episode": 124.0, "batch_reward": 0.6015696506500244, "critic_loss": 1.1619852865636349, "actor_loss": -60.72184627532959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.000256776809692, "step": 124000}
{"episode_reward": 695.3100215167722, "episode": 125.0, "batch_reward": 0.6031566550135612, "critic_loss": 1.1518233131170272, "actor_loss": -61.243890174865726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.510730981826782, "step": 125000}
{"episode_reward": 655.6454084910739, "episode": 126.0, "batch_reward": 0.6031435916423797, "critic_loss": 1.1367403344511986, "actor_loss": -61.09530782318115, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.730976104736328, "step": 126000}
{"episode_reward": 700.0393749454153, "episode": 127.0, "batch_reward": 0.603434868812561, "critic_loss": 1.1599751179218292, "actor_loss": -61.065857437133786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.66089391708374, "step": 127000}
{"episode_reward": 629.9381522096072, "episode": 128.0, "batch_reward": 0.6040415343642235, "critic_loss": 1.084129820674658, "actor_loss": -61.14254183959961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.524425745010376, "step": 128000}
{"episode_reward": 689.8492440341823, "episode": 129.0, "batch_reward": 0.6048636502027511, "critic_loss": 1.0796086275577546, "actor_loss": -61.274762741088864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.63325333595276, "step": 129000}
{"episode_reward": 711.520607423041, "episode": 130.0, "batch_reward": 0.6055173332095146, "critic_loss": 1.0926392570137977, "actor_loss": -61.01889835357666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.564316034317017, "step": 130000}
{"episode_reward": 658.8395282826722, "episode": 131.0, "batch_reward": 0.6053189066648483, "critic_loss": 1.1137932547032834, "actor_loss": -60.78858055114746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.48067855834961, "step": 131000}
{"episode_reward": 606.2100516678883, "episode": 132.0, "batch_reward": 0.6047609761357308, "critic_loss": 1.1101225160062314, "actor_loss": -60.9132996673584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.117536783218384, "step": 132000}
{"episode_reward": 681.0070447583132, "episode": 133.0, "batch_reward": 0.6057971436977386, "critic_loss": 1.049953350365162, "actor_loss": -61.30166095733642, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.543774843215942, "step": 133000}
{"episode_reward": 638.2316914982049, "episode": 134.0, "batch_reward": 0.6050277913212776, "critic_loss": 1.0310167625248432, "actor_loss": -61.27356886291504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.946501970291138, "step": 134000}
{"episode_reward": 673.8548298948816, "episode": 135.0, "batch_reward": 0.6070396465659141, "critic_loss": 1.0613962244689465, "actor_loss": -61.456983924865725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.12023687362671, "step": 135000}
{"episode_reward": 672.2109208724075, "episode": 136.0, "batch_reward": 0.6065465195775032, "critic_loss": 1.0389477169513703, "actor_loss": -61.45096704101562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.500268697738647, "step": 136000}
{"episode_reward": 607.3991735071647, "episode": 137.0, "batch_reward": 0.606505579173565, "critic_loss": 1.0791762244105338, "actor_loss": -61.33189399719238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.736562967300415, "step": 137000}
{"episode_reward": 682.3554800939256, "episode": 138.0, "batch_reward": 0.6085833596587181, "critic_loss": 1.0603957562744617, "actor_loss": -61.12454829406738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.594462156295776, "step": 138000}
{"episode_reward": 702.3723207664698, "episode": 139.0, "batch_reward": 0.6091211767196655, "critic_loss": 0.984919450610876, "actor_loss": -61.12650072479248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.391224145889282, "step": 139000}
{"episode_reward": 633.4497516244344, "episode": 140.0, "batch_reward": 0.6085079714655877, "critic_loss": 0.9774656393826008, "actor_loss": -61.30304442596436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.10906720161438, "step": 140000}
{"episode_reward": 663.2543101558551, "episode": 141.0, "batch_reward": 0.6093053196072579, "critic_loss": 0.9265419157743454, "actor_loss": -61.32762898254394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 53.995731830596924, "step": 141000}
{"episode_reward": 697.9812374830788, "episode": 142.0, "batch_reward": 0.6092799206376076, "critic_loss": 0.9755321040153503, "actor_loss": -61.3648046798706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.996889114379883, "step": 142000}
{"episode_reward": 686.2657499615377, "episode": 143.0, "batch_reward": 0.6107416184544563, "critic_loss": 0.9290155134499073, "actor_loss": -61.81931226348877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.86795473098755, "step": 143000}
{"episode_reward": 690.4031600048851, "episode": 144.0, "batch_reward": 0.6110126619338989, "critic_loss": 0.9701808786094188, "actor_loss": -61.74406815338135, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.212806224822998, "step": 144000}
{"episode_reward": 638.5235891392699, "episode": 145.0, "batch_reward": 0.611251324236393, "critic_loss": 0.9373991167247295, "actor_loss": -62.016574562072755, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.879150390625, "step": 145000}
{"episode_reward": 689.5289859470006, "episode": 146.0, "batch_reward": 0.6118795834779739, "critic_loss": 0.9534841040074825, "actor_loss": -61.62338636779785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.268622398376465, "step": 146000}
{"episode_reward": 679.9686312942748, "episode": 147.0, "batch_reward": 0.6120189294815064, "critic_loss": 0.9293198444247246, "actor_loss": -61.71795029449463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.506901264190674, "step": 147000}
{"episode_reward": 673.7525364684815, "episode": 148.0, "batch_reward": 0.6118210339546204, "critic_loss": 0.9463426832854748, "actor_loss": -61.742875228881836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.589075326919556, "step": 148000}
{"episode_reward": 698.6403667279175, "episode": 149.0, "batch_reward": 0.6133709717988968, "critic_loss": 0.914268727093935, "actor_loss": -61.89746383666992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.57546877861023, "step": 149000}
{"episode_reward": 690.4484194980432, "episode": 150.0, "batch_reward": 0.6137649384737015, "critic_loss": 0.9295277590751648, "actor_loss": -61.95517351531982, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
