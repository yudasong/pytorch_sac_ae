{"episode_reward": 0.0, "episode": 1.0, "duration": 17.33403706550598, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.502427101135254, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.2593826230127202, "critic_loss": 0.01702862258318274, "actor_loss": -28.563394931190107, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.51936173439026, "step": 3000}
{"episode_reward": 6.877390390465275, "episode": 4.0, "batch_reward": 0.16186189518123864, "critic_loss": 0.013989700292237103, "actor_loss": -25.351936255931854, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.317630290985107, "step": 4000}
{"episode_reward": 4.129837958931928, "episode": 5.0, "batch_reward": 0.12631099033355714, "critic_loss": 0.015099602198693902, "actor_loss": -24.463950037002565, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.345218658447266, "step": 5000}
{"episode_reward": 3.9507367153587802, "episode": 6.0, "batch_reward": 0.10401765959709883, "critic_loss": 0.014746142888441682, "actor_loss": -23.981404970169066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35659670829773, "step": 6000}
{"episode_reward": 4.038262759161939, "episode": 7.0, "batch_reward": 0.08827287757396698, "critic_loss": 0.012332223977195099, "actor_loss": -23.863112966060637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30598020553589, "step": 7000}
{"episode_reward": 4.329836233560015, "episode": 8.0, "batch_reward": 0.07742327041551471, "critic_loss": 0.023257118779234587, "actor_loss": -22.840415179252624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.310184478759766, "step": 8000}
{"episode_reward": 4.32762696680811, "episode": 9.0, "batch_reward": 0.06855795182473957, "critic_loss": 0.013601847393321804, "actor_loss": -22.078455209970475, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.319511890411377, "step": 9000}
{"episode_reward": 3.025799207061266, "episode": 10.0, "batch_reward": 0.06161816746741533, "critic_loss": 0.023019315101904796, "actor_loss": -22.888189011573793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.334946632385254, "step": 10000}
{"episode_reward": 3.3801544227656852, "episode": 11.0, "batch_reward": 0.055445681835524736, "critic_loss": 0.02519244556524791, "actor_loss": -21.196701294422148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.74128270149231, "step": 11000}
{"episode_reward": 2.91977169619659, "episode": 12.0, "batch_reward": 0.051710189817473294, "critic_loss": 0.016913694879389367, "actor_loss": -22.5070417971611, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.317914247512817, "step": 12000}
{"episode_reward": 4.581953281651013, "episode": 13.0, "batch_reward": 0.04767367153055966, "critic_loss": 0.02697489871806465, "actor_loss": -22.673410959005356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32711625099182, "step": 13000}
{"episode_reward": 4.912721802319328, "episode": 14.0, "batch_reward": 0.044684153844602406, "critic_loss": 0.02972906808112748, "actor_loss": -21.82978550553322, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28532910346985, "step": 14000}
{"episode_reward": 4.857782955163031, "episode": 15.0, "batch_reward": 0.0421089085964486, "critic_loss": 0.023892510060686618, "actor_loss": -20.730045773267747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.339603185653687, "step": 15000}
{"episode_reward": 3.5115699516097734, "episode": 16.0, "batch_reward": 0.03952044701296836, "critic_loss": 0.03011952620500233, "actor_loss": -21.3572848842144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35382390022278, "step": 16000}
{"episode_reward": 4.345921946605677, "episode": 17.0, "batch_reward": 0.03693693564971909, "critic_loss": 0.031624867588398047, "actor_loss": -22.022181012749673, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.301032066345215, "step": 17000}
{"episode_reward": 3.2448854462233885, "episode": 18.0, "batch_reward": 0.035445673533715305, "critic_loss": 0.02974574867502088, "actor_loss": -21.214978316545487, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32013201713562, "step": 18000}
{"episode_reward": 5.6033706638336644, "episode": 19.0, "batch_reward": 0.03317667280556634, "critic_loss": 0.029661325294757263, "actor_loss": -21.295079641103744, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32487940788269, "step": 19000}
{"episode_reward": 4.021734849627693, "episode": 20.0, "batch_reward": 0.03226580089959316, "critic_loss": 0.030792463666235562, "actor_loss": -21.838564462900163, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.299373388290405, "step": 20000}
{"episode_reward": 4.180328991470058, "episode": 21.0, "batch_reward": 0.030888742981944235, "critic_loss": 0.04099074616271537, "actor_loss": -20.178190210819245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.7245454788208, "step": 21000}
{"episode_reward": 4.706999585127364, "episode": 22.0, "batch_reward": 0.029422371821943672, "critic_loss": 0.030908090992772485, "actor_loss": -22.170902558088304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.274247407913208, "step": 22000}
{"episode_reward": 3.014223679734656, "episode": 23.0, "batch_reward": 0.028787154532503335, "critic_loss": 0.029902000460977435, "actor_loss": -21.558341604351998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.308114051818848, "step": 23000}
{"episode_reward": 5.13266406886774, "episode": 24.0, "batch_reward": 0.027488642800599337, "critic_loss": 0.03425621522156871, "actor_loss": -20.018413009881975, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.339442253112793, "step": 24000}
{"episode_reward": 3.3330977712275836, "episode": 25.0, "batch_reward": 0.025718463248573242, "critic_loss": 0.028478539207892027, "actor_loss": -21.295255260825158, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.305299758911133, "step": 25000}
{"episode_reward": 4.162484735001963, "episode": 26.0, "batch_reward": 0.02546015651198104, "critic_loss": 0.03109110051667085, "actor_loss": -20.41946599984169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3362979888916, "step": 26000}
{"episode_reward": 3.802738339823228, "episode": 27.0, "batch_reward": 0.024617167970864103, "critic_loss": 0.0342654882951756, "actor_loss": -20.558520348191262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.306888580322266, "step": 27000}
{"episode_reward": 5.13760558965019, "episode": 28.0, "batch_reward": 0.023827674370259046, "critic_loss": 0.04106157705376973, "actor_loss": -21.078798119723796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.312626361846924, "step": 28000}
{"episode_reward": 4.56323650513851, "episode": 29.0, "batch_reward": 0.023288918390171602, "critic_loss": 0.03361182042653672, "actor_loss": -20.66861748421192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.322678565979004, "step": 29000}
{"episode_reward": 4.638674538797849, "episode": 30.0, "batch_reward": 0.02256295008212328, "critic_loss": 0.044708393931461615, "actor_loss": -19.734795292794704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36701011657715, "step": 30000}
{"episode_reward": 4.084586919304435, "episode": 31.0, "batch_reward": 0.022338953197933734, "critic_loss": 0.04328917667909991, "actor_loss": -20.86149384689331, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.71531391143799, "step": 31000}
{"episode_reward": 4.9530036191622875, "episode": 32.0, "batch_reward": 0.021388303959043696, "critic_loss": 0.031280748564880924, "actor_loss": -20.20264433079958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.333481311798096, "step": 32000}
{"episode_reward": 4.89925338542639, "episode": 33.0, "batch_reward": 0.02040864511579275, "critic_loss": 0.027663206014272874, "actor_loss": -21.132165386557578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29001522064209, "step": 33000}
{"episode_reward": 3.784115661074397, "episode": 34.0, "batch_reward": 0.020583728443132714, "critic_loss": 0.02729024486518756, "actor_loss": -20.989218448340893, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.328848361968994, "step": 34000}
{"episode_reward": 4.531109073529584, "episode": 35.0, "batch_reward": 0.019991540672490375, "critic_loss": 0.027783251862070757, "actor_loss": -18.77419282823801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.351096868515015, "step": 35000}
{"episode_reward": 3.5386657024669255, "episode": 36.0, "batch_reward": 0.019511693105334415, "critic_loss": 0.024107715274469227, "actor_loss": -21.173681457042694, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32888102531433, "step": 36000}
{"episode_reward": 3.9011545900044142, "episode": 37.0, "batch_reward": 0.019120650845812635, "critic_loss": 0.02350031912153645, "actor_loss": -20.055998975038527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.324967622756958, "step": 37000}
{"episode_reward": 3.0548029261511203, "episode": 38.0, "batch_reward": 0.01926140897278674, "critic_loss": 0.030245940970169614, "actor_loss": -19.466483925580977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.351500988006592, "step": 38000}
{"episode_reward": 4.692116917177242, "episode": 39.0, "batch_reward": 0.01853609260590747, "critic_loss": 0.031169976280099945, "actor_loss": -21.167187496244907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.291932821273804, "step": 39000}
{"episode_reward": 3.8643013634343695, "episode": 40.0, "batch_reward": 0.018115142085822298, "critic_loss": 0.03966502840936301, "actor_loss": -22.220615858018398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32200336456299, "step": 40000}
{"episode_reward": 3.432084652351796, "episode": 41.0, "batch_reward": 0.018002032996853812, "critic_loss": 0.038789785928122, "actor_loss": -21.60454637491703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.73650908470154, "step": 41000}
{"episode_reward": 4.925520778363533, "episode": 42.0, "batch_reward": 0.017249350280268118, "critic_loss": 0.03393602656837902, "actor_loss": -21.0535560849905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.312751531600952, "step": 42000}
{"episode_reward": 4.1438840530472945, "episode": 43.0, "batch_reward": 0.01726055233855732, "critic_loss": 0.038051002580308704, "actor_loss": -21.526072502970695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.305584192276, "step": 43000}
{"episode_reward": 5.2059649389667, "episode": 44.0, "batch_reward": 0.016762499417178334, "critic_loss": 0.03572635484609055, "actor_loss": -19.47632772767544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.314926862716675, "step": 44000}
{"episode_reward": 2.9927862759864077, "episode": 45.0, "batch_reward": 0.01653600198403001, "critic_loss": 0.029080983993088012, "actor_loss": -19.258376596450805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.319520473480225, "step": 45000}
{"episode_reward": 3.253173286772122, "episode": 46.0, "batch_reward": 0.016414112245664, "critic_loss": 0.022015894221709457, "actor_loss": -20.175374012589455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.315345525741577, "step": 46000}
{"episode_reward": 5.058177096752473, "episode": 47.0, "batch_reward": 0.015750653705326842, "critic_loss": 0.021936558500456158, "actor_loss": -19.86197921651602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.351938247680664, "step": 47000}
{"episode_reward": 4.451085624606964, "episode": 48.0, "batch_reward": 0.01581882021506317, "critic_loss": 0.016570904831954978, "actor_loss": -19.6155728854537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32957625389099, "step": 48000}
{"episode_reward": 4.114059530875764, "episode": 49.0, "batch_reward": 0.015709406722802667, "critic_loss": 0.021404800949909257, "actor_loss": -19.98543681934476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33989119529724, "step": 49000}
{"episode_reward": 4.40685226147464, "episode": 50.0, "batch_reward": 0.014857765883672982, "critic_loss": 0.016168208692310147, "actor_loss": -19.817215434074402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.327092170715332, "step": 50000}
{"episode_reward": 3.6345083515601315, "episode": 51.0, "batch_reward": 0.014855692745652049, "critic_loss": 0.011191726719131111, "actor_loss": -20.090315243840216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.739442110061646, "step": 51000}
{"episode_reward": 5.6839334485518735, "episode": 52.0, "batch_reward": 0.014712523986585438, "critic_loss": 0.01601518336897425, "actor_loss": -19.338241126269104, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.319526195526123, "step": 52000}
{"episode_reward": 4.190222122807493, "episode": 53.0, "batch_reward": 0.014865690209902823, "critic_loss": 0.01719630829198286, "actor_loss": -19.74301366752386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.301559925079346, "step": 53000}
{"episode_reward": 3.288384799140821, "episode": 54.0, "batch_reward": 0.0139500807733275, "critic_loss": 0.014828717395255807, "actor_loss": -19.840321912258865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.328725814819336, "step": 54000}
{"episode_reward": 3.6649651244948926, "episode": 55.0, "batch_reward": 0.013925532791763544, "critic_loss": 0.01436485292344878, "actor_loss": -20.030439219474793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.331552267074585, "step": 55000}
{"episode_reward": 2.3025105580569205, "episode": 56.0, "batch_reward": 0.013971465097507461, "critic_loss": 0.013014272590269684, "actor_loss": -20.982743202984334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33513903617859, "step": 56000}
{"episode_reward": 4.556239887723881, "episode": 57.0, "batch_reward": 0.01347409116709605, "critic_loss": 0.02009362778364448, "actor_loss": -20.38879083287716, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.335245847702026, "step": 57000}
{"episode_reward": 2.104050922986515, "episode": 58.0, "batch_reward": 0.013305660683661699, "critic_loss": 0.019001910251172375, "actor_loss": -20.722137538671493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.309919118881226, "step": 58000}
{"episode_reward": 5.463823624179293, "episode": 59.0, "batch_reward": 0.013365011063404382, "critic_loss": 0.01872681148900301, "actor_loss": -21.058522879481316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.319881916046143, "step": 59000}
{"episode_reward": 3.695498490345431, "episode": 60.0, "batch_reward": 0.013324479433940724, "critic_loss": 0.01970164254498377, "actor_loss": -20.30535527163744, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.327285766601562, "step": 60000}
{"episode_reward": 5.393990699146868, "episode": 61.0, "batch_reward": 0.012860085662687197, "critic_loss": 0.023459515238981113, "actor_loss": -19.26087138271332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.70382833480835, "step": 61000}
{"episode_reward": 5.251543041920565, "episode": 62.0, "batch_reward": 0.013083552964264528, "critic_loss": 0.02287796815331967, "actor_loss": -19.49223968359828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.304840803146362, "step": 62000}
{"episode_reward": 4.78206588056672, "episode": 63.0, "batch_reward": 0.012890107340645045, "critic_loss": 0.024668792254160507, "actor_loss": -19.79586723563075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.323338747024536, "step": 63000}
{"episode_reward": 3.55063013862277, "episode": 64.0, "batch_reward": 0.012669292003847659, "critic_loss": 0.034984207026442164, "actor_loss": -21.149820570409297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2979097366333, "step": 64000}
{"episode_reward": 4.340182024825121, "episode": 65.0, "batch_reward": 0.012611616604262963, "critic_loss": 0.03165750661440688, "actor_loss": -21.020906399399042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.305638790130615, "step": 65000}
{"episode_reward": 2.2671538689012185, "episode": 66.0, "batch_reward": 0.012291875533293932, "critic_loss": 0.0321826595824532, "actor_loss": -20.832938506036996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.339641571044922, "step": 66000}
{"episode_reward": 3.0948868865839754, "episode": 67.0, "batch_reward": 0.012391431740252302, "critic_loss": 0.03140351379694766, "actor_loss": -19.164098545253278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33676290512085, "step": 67000}
{"episode_reward": 3.4994023885829426, "episode": 68.0, "batch_reward": 0.012273305227980019, "critic_loss": 0.029979206823030836, "actor_loss": -20.65897235581279, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32382893562317, "step": 68000}
{"episode_reward": 4.398167217473214, "episode": 69.0, "batch_reward": 0.012213967541698366, "critic_loss": 0.031391782216414865, "actor_loss": -19.78783678945899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.321815967559814, "step": 69000}
{"episode_reward": 6.234747830926674, "episode": 70.0, "batch_reward": 0.012068894744617864, "critic_loss": 0.038205679584265455, "actor_loss": -19.433762284964324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.413397789001465, "step": 70000}
{"episode_reward": 5.3657817197749385, "episode": 71.0, "batch_reward": 0.011948639147449284, "critic_loss": 0.03666544026266638, "actor_loss": -19.527861600905656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.80549502372742, "step": 71000}
{"episode_reward": 2.5074633147292786, "episode": 72.0, "batch_reward": 0.011556055638706311, "critic_loss": 0.05333795586548513, "actor_loss": -19.925137159287928, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.313755989074707, "step": 72000}
{"episode_reward": 5.149617997293766, "episode": 73.0, "batch_reward": 0.011603828603634611, "critic_loss": 0.04664624908217229, "actor_loss": -20.085181794255973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28611993789673, "step": 73000}
{"episode_reward": 4.27760719319912, "episode": 74.0, "batch_reward": 0.011293421775568276, "critic_loss": 0.048469899672069, "actor_loss": -20.108612694829702, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31914520263672, "step": 74000}
{"episode_reward": 2.9607569420080493, "episode": 75.0, "batch_reward": 0.01144071939191781, "critic_loss": 0.07409161278894316, "actor_loss": -21.444400361388922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3217875957489, "step": 75000}
{"episode_reward": 3.0530832632328933, "episode": 76.0, "batch_reward": 0.011300574637018144, "critic_loss": 0.06295034610926814, "actor_loss": -20.25564520934224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.314801454544067, "step": 76000}
{"episode_reward": 2.8795094124681717, "episode": 77.0, "batch_reward": 0.011228134276578202, "critic_loss": 0.08103655741430703, "actor_loss": -20.336458419471978, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31490659713745, "step": 77000}
{"episode_reward": 4.907655518040511, "episode": 78.0, "batch_reward": 0.010856643740320578, "critic_loss": 0.057504049176350235, "actor_loss": -19.999438205003738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3403537273407, "step": 78000}
{"episode_reward": 3.5662462670630077, "episode": 79.0, "batch_reward": 0.010833040566649289, "critic_loss": 0.0485439467868564, "actor_loss": -20.935449711591005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.306272268295288, "step": 79000}
{"episode_reward": 5.691224522950289, "episode": 80.0, "batch_reward": 0.01125081761740148, "critic_loss": 0.037645058145804794, "actor_loss": -20.608257494404914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.333587646484375, "step": 80000}
{"episode_reward": 3.139684550263187, "episode": 81.0, "batch_reward": 0.010769289328251034, "critic_loss": 0.016440765837527578, "actor_loss": -19.95385634788871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.702436685562134, "step": 81000}
{"episode_reward": 2.925306957041883, "episode": 82.0, "batch_reward": 0.010873385113663972, "critic_loss": 0.0075577561553946, "actor_loss": -20.33396741952002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.334583520889282, "step": 82000}
{"episode_reward": 3.0166336962340505, "episode": 83.0, "batch_reward": 0.010709632782964036, "critic_loss": 0.003055850140794064, "actor_loss": -19.748089386731387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33793020248413, "step": 83000}
{"episode_reward": 4.203321245080132, "episode": 84.0, "batch_reward": 0.010602258537197486, "critic_loss": 0.002188722210667038, "actor_loss": -20.00587398929894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.319438695907593, "step": 84000}
{"episode_reward": 3.638721962137279, "episode": 85.0, "batch_reward": 0.010448155236197635, "critic_loss": 0.001973043797937862, "actor_loss": -20.44086761158705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33397650718689, "step": 85000}
{"episode_reward": 5.213414897480896, "episode": 86.0, "batch_reward": 0.010681011297274381, "critic_loss": 0.00269358095638745, "actor_loss": -19.76341826274991, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.344624280929565, "step": 86000}
{"episode_reward": 3.2818144502368183, "episode": 87.0, "batch_reward": 0.010692745074164123, "critic_loss": 0.003366457585536409, "actor_loss": -19.23612349073589, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31545662879944, "step": 87000}
{"episode_reward": 4.364341775008186, "episode": 88.0, "batch_reward": 0.010358475347282365, "critic_loss": 0.0032990989061654546, "actor_loss": -19.627990523070096, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.337331771850586, "step": 88000}
{"episode_reward": 3.123889378118446, "episode": 89.0, "batch_reward": 0.010295507092960178, "critic_loss": 0.004078284021175932, "actor_loss": -20.227638099893927, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30305242538452, "step": 89000}
{"episode_reward": 3.746969109966964, "episode": 90.0, "batch_reward": 0.010203901783563197, "critic_loss": 0.006465776944460231, "actor_loss": -19.65033144313097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30895757675171, "step": 90000}
{"episode_reward": 3.2687068326514934, "episode": 91.0, "batch_reward": 0.010216327330563218, "critic_loss": 0.003327560856632772, "actor_loss": -20.42233620607853, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.71999192237854, "step": 91000}
{"episode_reward": 3.576056440074849, "episode": 92.0, "batch_reward": 0.0100583437057212, "critic_loss": 0.006758175433715223, "actor_loss": -18.275657628417015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3153018951416, "step": 92000}
{"episode_reward": 4.833653809498333, "episode": 93.0, "batch_reward": 0.010112328278366476, "critic_loss": 0.004668217612023, "actor_loss": -19.645396248206495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.325801134109497, "step": 93000}
{"episode_reward": 5.224639873663077, "episode": 94.0, "batch_reward": 0.010172462867572904, "critic_loss": 0.004878902700642357, "actor_loss": -18.56896559137106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34198570251465, "step": 94000}
{"episode_reward": 5.541232043569229, "episode": 95.0, "batch_reward": 0.010113818351412191, "critic_loss": 0.005742646144863101, "actor_loss": -19.716851254433394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.292023420333862, "step": 95000}
{"episode_reward": 3.75727538056695, "episode": 96.0, "batch_reward": 0.009739878508029506, "critic_loss": 0.0068325588932566465, "actor_loss": -18.837214335024356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.332971811294556, "step": 96000}
{"episode_reward": 5.251353007444579, "episode": 97.0, "batch_reward": 0.009772877658717333, "critic_loss": 0.008282985682002617, "actor_loss": -19.61363632029295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.598008632659912, "step": 97000}
{"episode_reward": 3.878469360123106, "episode": 98.0, "batch_reward": 0.010047960736788809, "critic_loss": 0.008152208211431571, "actor_loss": -20.678373272195458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.353519678115845, "step": 98000}
{"episode_reward": 4.478757395300441, "episode": 99.0, "batch_reward": 0.009671991175273432, "critic_loss": 0.008999384672293673, "actor_loss": -19.5636122071594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.306941270828247, "step": 99000}
{"episode_reward": 2.9267073853284824, "episode": 100.0, "batch_reward": 0.009542140865698457, "critic_loss": 0.010477422863128595, "actor_loss": -19.97022408120334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.308513402938843, "step": 100000}
{"episode_reward": 3.5009904476951106, "episode": 101.0, "batch_reward": 0.009610725650563836, "critic_loss": 0.009081266592671455, "actor_loss": -18.66099455116689, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.725366830825806, "step": 101000}
{"episode_reward": 6.545319254680725, "episode": 102.0, "batch_reward": 0.00944157088501379, "critic_loss": 0.014335154839332972, "actor_loss": -20.01287882605195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.297773361206055, "step": 102000}
{"episode_reward": 2.885203948051754, "episode": 103.0, "batch_reward": 0.00936830013198778, "critic_loss": 0.014158914047511644, "actor_loss": -18.889693318068982, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.283822298049927, "step": 103000}
{"episode_reward": 3.614790042079552, "episode": 104.0, "batch_reward": 0.009422142871888355, "critic_loss": 0.02059134490487486, "actor_loss": -20.773562342211605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.280866146087646, "step": 104000}
{"episode_reward": 2.7698625591881036, "episode": 105.0, "batch_reward": 0.009393042171373963, "critic_loss": 0.024939038018295834, "actor_loss": -18.658972886309027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.321012496948242, "step": 105000}
{"episode_reward": 2.861648532599971, "episode": 106.0, "batch_reward": 0.009065843411488458, "critic_loss": 0.02681169065427093, "actor_loss": -19.30155584126711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.284547328948975, "step": 106000}
{"episode_reward": 3.779655625018175, "episode": 107.0, "batch_reward": 0.008982776473974809, "critic_loss": 0.04568297231547331, "actor_loss": -19.721649555370213, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.289552450180054, "step": 107000}
{"episode_reward": 3.7206675838545835, "episode": 108.0, "batch_reward": 0.009110118795884773, "critic_loss": 0.026202229416805493, "actor_loss": -19.4687771134153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31987476348877, "step": 108000}
{"episode_reward": 3.595770079708018, "episode": 109.0, "batch_reward": 0.009248018244281411, "critic_loss": 0.018886745568852347, "actor_loss": -19.629286729723216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.299896478652954, "step": 109000}
{"episode_reward": 3.5219821161231173, "episode": 110.0, "batch_reward": 0.009280711024766788, "critic_loss": 0.01718820799158857, "actor_loss": -20.1379455640316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.307921409606934, "step": 110000}
{"episode_reward": 3.0224408192120107, "episode": 111.0, "batch_reward": 0.008892849011113866, "critic_loss": 0.014546665009911522, "actor_loss": -18.81155827474594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.73591589927673, "step": 111000}
{"episode_reward": 3.4499154060722814, "episode": 112.0, "batch_reward": 0.009174445239361376, "critic_loss": 0.01419710307521018, "actor_loss": -19.519355889499188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.315619230270386, "step": 112000}
{"episode_reward": 2.338105471425729, "episode": 113.0, "batch_reward": 0.008701206200988963, "critic_loss": 0.010761810676114692, "actor_loss": -17.921843160361053, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31618642807007, "step": 113000}
{"episode_reward": 4.94969684436333, "episode": 114.0, "batch_reward": 0.008940336226485669, "critic_loss": 0.00946432052765158, "actor_loss": -19.224414042174818, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.344826698303223, "step": 114000}
{"episode_reward": 3.2589757501972896, "episode": 115.0, "batch_reward": 0.008729415587848052, "critic_loss": 0.007019956201733294, "actor_loss": -20.662512412130834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.312660932540894, "step": 115000}
{"episode_reward": 5.268860466651662, "episode": 116.0, "batch_reward": 0.008555102695710958, "critic_loss": 0.005909198804743937, "actor_loss": -19.269017677247525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.344467639923096, "step": 116000}
{"episode_reward": 3.0364595142766824, "episode": 117.0, "batch_reward": 0.008591581187909468, "critic_loss": 0.006226802798184508, "actor_loss": -19.675088733166458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.318127632141113, "step": 117000}
{"episode_reward": 2.40311007475732, "episode": 118.0, "batch_reward": 0.008592520289123058, "critic_loss": 0.005310661960676952, "actor_loss": -19.2756123727262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32238221168518, "step": 118000}
{"episode_reward": 5.814808598385498, "episode": 119.0, "batch_reward": 0.008775373126147314, "critic_loss": 0.004787883623110247, "actor_loss": -19.81126852466166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.323339700698853, "step": 119000}
{"episode_reward": 4.26172337511117, "episode": 120.0, "batch_reward": 0.008480175235308706, "critic_loss": 0.003395022059739858, "actor_loss": -20.05071932041645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.302568435668945, "step": 120000}
{"episode_reward": 3.921353041716738, "episode": 121.0, "batch_reward": 0.00846618933719583, "critic_loss": 0.0033867019061217434, "actor_loss": -20.04885659724474, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.709872007369995, "step": 121000}
{"episode_reward": 3.8943517992382457, "episode": 122.0, "batch_reward": 0.008550731897586957, "critic_loss": 0.0025255231645387537, "actor_loss": -20.78280802446604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.319902658462524, "step": 122000}
{"episode_reward": 3.504897392281719, "episode": 123.0, "batch_reward": 0.008448518317658454, "critic_loss": 0.0018449366664608532, "actor_loss": -21.10513686621189, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.286248683929443, "step": 123000}
{"episode_reward": 3.9172222340713265, "episode": 124.0, "batch_reward": 0.008690789037849754, "critic_loss": 0.002318418819584622, "actor_loss": -20.449356787383557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.266234159469604, "step": 124000}
{"episode_reward": 3.5783058037488313, "episode": 125.0, "batch_reward": 0.008266049747355283, "critic_loss": 0.001713469481223001, "actor_loss": -20.634871540248394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.676288843154907, "step": 125000}
{"episode_reward": 4.329308415393362, "episode": 126.0, "batch_reward": 0.00819184042001143, "critic_loss": 0.0023488885031656536, "actor_loss": -21.110673778057098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28385305404663, "step": 126000}
{"episode_reward": 3.019291102086987, "episode": 127.0, "batch_reward": 0.008224046220770106, "critic_loss": 0.0023220082128973447, "actor_loss": -20.11990167272091, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21221160888672, "step": 127000}
{"episode_reward": 4.197667848121893, "episode": 128.0, "batch_reward": 0.008267382116988301, "critic_loss": 0.0032105756515993563, "actor_loss": -19.549108969449996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.300647497177124, "step": 128000}
{"episode_reward": 2.2518713357065274, "episode": 129.0, "batch_reward": 0.008184012339217589, "critic_loss": 0.0027555948411682038, "actor_loss": -20.24918014973402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.254192113876343, "step": 129000}
{"episode_reward": 5.088951334574924, "episode": 130.0, "batch_reward": 0.008348286846419797, "critic_loss": 0.0029144266780785984, "actor_loss": -19.81084686124325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26962375640869, "step": 130000}
{"episode_reward": 4.2258103288896764, "episode": 131.0, "batch_reward": 0.008295281785773113, "critic_loss": 0.00270392950938367, "actor_loss": -18.372630297750234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.73149132728577, "step": 131000}
{"episode_reward": 6.231356428685614, "episode": 132.0, "batch_reward": 0.008430890410440043, "critic_loss": 0.002641348735698557, "actor_loss": -19.746972320765256, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.296722650527954, "step": 132000}
{"episode_reward": 4.872995874087999, "episode": 133.0, "batch_reward": 0.008196746989153325, "critic_loss": 0.0022586653019970983, "actor_loss": -20.142332721918823, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.280065774917603, "step": 133000}
{"episode_reward": 4.027237864477595, "episode": 134.0, "batch_reward": 0.008201315169222652, "critic_loss": 0.0020126669103883612, "actor_loss": -20.24861121568084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31101679801941, "step": 134000}
{"episode_reward": 3.6488009325054525, "episode": 135.0, "batch_reward": 0.00839475121581927, "critic_loss": 0.0025773908988448967, "actor_loss": -20.788214482873677, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.282538890838623, "step": 135000}
{"episode_reward": 3.324555759914979, "episode": 136.0, "batch_reward": 0.008081802053609862, "critic_loss": 0.0020376162637912787, "actor_loss": -21.157217832058667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.302688598632812, "step": 136000}
{"episode_reward": 4.566512163077944, "episode": 137.0, "batch_reward": 0.008147986971307546, "critic_loss": 0.0038873940981357007, "actor_loss": -20.780505581319332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.303568363189697, "step": 137000}
{"episode_reward": 3.7684112808194996, "episode": 138.0, "batch_reward": 0.008039964155526831, "critic_loss": 0.0018798617118372931, "actor_loss": -18.624291423261166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.272619485855103, "step": 138000}
{"episode_reward": 3.35094736975036, "episode": 139.0, "batch_reward": 0.00789095374266617, "critic_loss": 0.002708970990632224, "actor_loss": -18.169925377458334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.299971342086792, "step": 139000}
{"episode_reward": 5.685692779932022, "episode": 140.0, "batch_reward": 0.008300548380240799, "critic_loss": 0.003051448929410981, "actor_loss": -19.16690364548564, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.317373037338257, "step": 140000}
{"episode_reward": 4.5952877476528995, "episode": 141.0, "batch_reward": 0.007920680606737732, "critic_loss": 0.0035481414693058467, "actor_loss": -20.643534089386463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.680474519729614, "step": 141000}
{"episode_reward": 3.92753151813074, "episode": 142.0, "batch_reward": 0.007942424455890431, "critic_loss": 0.003144348868114321, "actor_loss": -19.484778184175493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30131483078003, "step": 142000}
{"episode_reward": 4.863048877319993, "episode": 143.0, "batch_reward": 0.007982255014358088, "critic_loss": 0.0032517565013295098, "actor_loss": -20.8545328168571, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28082799911499, "step": 143000}
{"episode_reward": 4.1716999198830775, "episode": 144.0, "batch_reward": 0.008049727878533303, "critic_loss": 0.0030137956776088684, "actor_loss": -19.75330441787839, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.319581747055054, "step": 144000}
{"episode_reward": 2.978220502342664, "episode": 145.0, "batch_reward": 0.007856362538412213, "critic_loss": 0.003062989997670229, "actor_loss": -21.88498154106736, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.308051347732544, "step": 145000}
{"episode_reward": 4.188116627763922, "episode": 146.0, "batch_reward": 0.0076168258807156235, "critic_loss": 0.004022045620400604, "actor_loss": -19.094033136636018, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.279356241226196, "step": 146000}
{"episode_reward": 3.543546415058945, "episode": 147.0, "batch_reward": 0.007901842777850106, "critic_loss": 0.0032704440064590017, "actor_loss": -20.210027976930142, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29242992401123, "step": 147000}
{"episode_reward": 3.36043824679324, "episode": 148.0, "batch_reward": 0.007675915577448905, "critic_loss": 0.003458083919242199, "actor_loss": -20.529671944081784, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.316246032714844, "step": 148000}
{"episode_reward": 3.322846058550665, "episode": 149.0, "batch_reward": 0.007727702559903264, "critic_loss": 0.005183839305464062, "actor_loss": -19.8909161092937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26431918144226, "step": 149000}
{"episode_reward": 3.0723769784517927, "episode": 150.0, "batch_reward": 0.007620126213179901, "critic_loss": 0.0035581800305299113, "actor_loss": -19.810541764855383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
