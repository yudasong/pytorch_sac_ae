{"episode_reward": 0.0, "episode": 1.0, "duration": 17.235132694244385, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.4785802364349365, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.2879979118441454, "critic_loss": 0.15956747950628902, "actor_loss": -45.64964833742335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.87187957763672, "step": 3000}
{"episode_reward": 560.4917043194732, "episode": 4.0, "batch_reward": 0.3929522223472595, "critic_loss": 0.18806591488420962, "actor_loss": -51.692840744018554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98080801963806, "step": 4000}
{"episode_reward": 642.5873178651303, "episode": 5.0, "batch_reward": 0.44983055189251897, "critic_loss": 0.1778158477023244, "actor_loss": -54.94256211090088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986202716827393, "step": 5000}
{"episode_reward": 615.7303895549328, "episode": 6.0, "batch_reward": 0.47393822693824766, "critic_loss": 0.23471866085380316, "actor_loss": -56.0407548828125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.013628721237183, "step": 6000}
{"episode_reward": 524.9468530904702, "episode": 7.0, "batch_reward": 0.4850260355770588, "critic_loss": 0.2563883479386568, "actor_loss": -56.252641036987306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99368929862976, "step": 7000}
{"episode_reward": 587.3800697131967, "episode": 8.0, "batch_reward": 0.48906780219078066, "critic_loss": 0.31211632542312145, "actor_loss": -56.1920330581665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.944149494171143, "step": 8000}
{"episode_reward": 486.91522969520605, "episode": 9.0, "batch_reward": 0.4957928907573223, "critic_loss": 0.27995189659297465, "actor_loss": -56.412878196716306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93681001663208, "step": 9000}
{"episode_reward": 553.7346291310586, "episode": 10.0, "batch_reward": 0.5001357672810555, "critic_loss": 0.2794533944427967, "actor_loss": -56.45133644866944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.947731018066406, "step": 10000}
{"episode_reward": 551.1363189835765, "episode": 11.0, "batch_reward": 0.5066600984334946, "critic_loss": 0.26018439859151843, "actor_loss": -56.73917174530029, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.21708798408508, "step": 11000}
{"episode_reward": 551.1888244459233, "episode": 12.0, "batch_reward": 0.508076009631157, "critic_loss": 0.2604545336961746, "actor_loss": -56.69862873840332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.987721920013428, "step": 12000}
{"episode_reward": 556.1362336951063, "episode": 13.0, "batch_reward": 0.5144891294240952, "critic_loss": 0.2272135416716337, "actor_loss": -57.09077981567383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007932901382446, "step": 13000}
{"episode_reward": 581.3713096834995, "episode": 14.0, "batch_reward": 0.5216905532479286, "critic_loss": 0.22475655844807624, "actor_loss": -57.50673673248291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99047589302063, "step": 14000}
{"episode_reward": 645.5393344551375, "episode": 15.0, "batch_reward": 0.5287865658104419, "critic_loss": 0.2162457133755088, "actor_loss": -57.843678916931154, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98774027824402, "step": 15000}
{"episode_reward": 632.3722183495923, "episode": 16.0, "batch_reward": 0.5356774425804615, "critic_loss": 0.20669183471798896, "actor_loss": -58.31071160888672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.025697708129883, "step": 16000}
{"episode_reward": 643.9474835213335, "episode": 17.0, "batch_reward": 0.5422558671832085, "critic_loss": 0.21668965929746628, "actor_loss": -58.62169095611572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00350046157837, "step": 17000}
{"episode_reward": 638.0469298411592, "episode": 18.0, "batch_reward": 0.5496450773775577, "critic_loss": 0.210631808295846, "actor_loss": -59.1123789138794, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96585512161255, "step": 18000}
{"episode_reward": 615.1910338778183, "episode": 19.0, "batch_reward": 0.5515397065579891, "critic_loss": 0.27421334256231783, "actor_loss": -59.15042890167236, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.971856832504272, "step": 19000}
{"episode_reward": 576.5564357765604, "episode": 20.0, "batch_reward": 0.5530581438243389, "critic_loss": 0.30278631988167765, "actor_loss": -59.16239501953125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005354404449463, "step": 20000}
{"episode_reward": 618.8176574159685, "episode": 21.0, "batch_reward": 0.5557805818021297, "critic_loss": 0.2918864022791386, "actor_loss": -58.955315956115726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.28098273277283, "step": 21000}
{"episode_reward": 473.9633718337578, "episode": 22.0, "batch_reward": 0.5509978555738926, "critic_loss": 0.3126678176224232, "actor_loss": -58.54640982055664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00533413887024, "step": 22000}
{"episode_reward": 525.245790253098, "episode": 23.0, "batch_reward": 0.5500146613419056, "critic_loss": 0.3327744777649641, "actor_loss": -58.38103588104248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.014955520629883, "step": 23000}
{"episode_reward": 542.6068711329697, "episode": 24.0, "batch_reward": 0.552106918156147, "critic_loss": 0.323272036254406, "actor_loss": -58.383005653381346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02068781852722, "step": 24000}
{"episode_reward": 607.9743486826433, "episode": 25.0, "batch_reward": 0.5529489408135414, "critic_loss": 0.339466971501708, "actor_loss": -58.62489551544189, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.023945808410645, "step": 25000}
{"episode_reward": 556.3255541180299, "episode": 26.0, "batch_reward": 0.5521344321072101, "critic_loss": 0.3951989375054836, "actor_loss": -58.253194778442385, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.014965772628784, "step": 26000}
{"episode_reward": 597.4160247774482, "episode": 27.0, "batch_reward": 0.5529531546235085, "critic_loss": 0.4095594728887081, "actor_loss": -58.31430329895019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00868821144104, "step": 27000}
{"episode_reward": 510.6693666514224, "episode": 28.0, "batch_reward": 0.552667813360691, "critic_loss": 0.38169553032517434, "actor_loss": -58.179481323242186, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986494302749634, "step": 28000}
{"episode_reward": 629.823018296589, "episode": 29.0, "batch_reward": 0.5552274876832962, "critic_loss": 0.3677382713854313, "actor_loss": -58.44228388977051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96378469467163, "step": 29000}
{"episode_reward": 607.9512087334069, "episode": 30.0, "batch_reward": 0.5582079310417175, "critic_loss": 0.350181811183691, "actor_loss": -58.62942798614502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981634378433228, "step": 30000}
{"episode_reward": 647.9970306600835, "episode": 31.0, "batch_reward": 0.5602178708612919, "critic_loss": 0.3476952780932188, "actor_loss": -58.6891545715332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.24988102912903, "step": 31000}
{"episode_reward": 609.143908849687, "episode": 32.0, "batch_reward": 0.5621486969888211, "critic_loss": 0.36190672546625136, "actor_loss": -58.80743544769287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007036209106445, "step": 32000}
{"episode_reward": 605.7735264924256, "episode": 33.0, "batch_reward": 0.5634516340494156, "critic_loss": 0.35134843918681147, "actor_loss": -58.93414923858643, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02848243713379, "step": 33000}
{"episode_reward": 614.1565262701707, "episode": 34.0, "batch_reward": 0.5651642841696739, "critic_loss": 0.3589273332804441, "actor_loss": -58.958510108947756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.020615339279175, "step": 34000}
{"episode_reward": 621.230929015936, "episode": 35.0, "batch_reward": 0.5670718388557434, "critic_loss": 0.3329810549467802, "actor_loss": -59.01040057373047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.984652280807495, "step": 35000}
{"episode_reward": 618.587751493176, "episode": 36.0, "batch_reward": 0.5664800498485565, "critic_loss": 0.35808905786275863, "actor_loss": -59.041544441223145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00227451324463, "step": 36000}
{"episode_reward": 527.0429697842578, "episode": 37.0, "batch_reward": 0.5662996429800987, "critic_loss": 0.35878807969391346, "actor_loss": -59.03379496765137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01493239402771, "step": 37000}
{"episode_reward": 572.3757562950432, "episode": 38.0, "batch_reward": 0.5663730861246585, "critic_loss": 0.3339230645149946, "actor_loss": -59.0988858795166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99680209159851, "step": 38000}
{"episode_reward": 579.9214470058502, "episode": 39.0, "batch_reward": 0.567187608063221, "critic_loss": 0.34969215185940267, "actor_loss": -59.20187126159668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.975719928741455, "step": 39000}
{"episode_reward": 624.6679399787288, "episode": 40.0, "batch_reward": 0.5683295167088509, "critic_loss": 0.34318593102693556, "actor_loss": -59.25290898895263, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.984192848205566, "step": 40000}
{"episode_reward": 581.9974622960224, "episode": 41.0, "batch_reward": 0.5683264919519424, "critic_loss": 0.3568868064880371, "actor_loss": -59.00058895874024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.2681097984314, "step": 41000}
{"episode_reward": 482.6760021541712, "episode": 42.0, "batch_reward": 0.5668509632945061, "critic_loss": 0.3924899896234274, "actor_loss": -58.745858360290526, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004271984100342, "step": 42000}
{"episode_reward": 600.3828217559758, "episode": 43.0, "batch_reward": 0.5696047652959824, "critic_loss": 0.3911219364851713, "actor_loss": -59.08116593170166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003634214401245, "step": 43000}
{"episode_reward": 670.2582997955152, "episode": 44.0, "batch_reward": 0.5687455136775971, "critic_loss": 0.4149761601388454, "actor_loss": -58.86958374786377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997784852981567, "step": 44000}
{"episode_reward": 643.4598834634907, "episode": 45.0, "batch_reward": 0.5727069989442826, "critic_loss": 0.42158986791968345, "actor_loss": -59.03792576599121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990646362304688, "step": 45000}
{"episode_reward": 646.6986562693586, "episode": 46.0, "batch_reward": 0.5733558434844017, "critic_loss": 0.42006282433867453, "actor_loss": -59.23130377960205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.962608814239502, "step": 46000}
{"episode_reward": 657.1098808437554, "episode": 47.0, "batch_reward": 0.5759416841864586, "critic_loss": 0.42575965157151224, "actor_loss": -59.19111474609375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.967393398284912, "step": 47000}
{"episode_reward": 675.4145527408078, "episode": 48.0, "batch_reward": 0.5781415477991104, "critic_loss": 0.4237958157658577, "actor_loss": -59.54054104614258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.973400354385376, "step": 48000}
{"episode_reward": 649.1007059295539, "episode": 49.0, "batch_reward": 0.5803263286948204, "critic_loss": 0.41854982770979404, "actor_loss": -59.6415933380127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.018032789230347, "step": 49000}
{"episode_reward": 647.1934508748886, "episode": 50.0, "batch_reward": 0.57961842918396, "critic_loss": 0.40656881931424144, "actor_loss": -59.560025093078615, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01366376876831, "step": 50000}
{"episode_reward": 619.7179202641931, "episode": 51.0, "batch_reward": 0.5810740045309066, "critic_loss": 0.3941765242666006, "actor_loss": -59.755016387939456, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.27079701423645, "step": 51000}
{"episode_reward": 615.9224024058159, "episode": 52.0, "batch_reward": 0.5808878657221794, "critic_loss": 0.39647692994773387, "actor_loss": -59.59006318664551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02301025390625, "step": 52000}
{"episode_reward": 624.427221300616, "episode": 53.0, "batch_reward": 0.582934632897377, "critic_loss": 0.37067182655632497, "actor_loss": -59.819721557617186, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.008033514022827, "step": 53000}
{"episode_reward": 672.1429903554873, "episode": 54.0, "batch_reward": 0.5836528031229973, "critic_loss": 0.3771704049408436, "actor_loss": -59.94821583557129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98310112953186, "step": 54000}
{"episode_reward": 637.3175906858551, "episode": 55.0, "batch_reward": 0.5847259331345558, "critic_loss": 0.3638417285978794, "actor_loss": -60.140876182556156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00166940689087, "step": 55000}
{"episode_reward": 643.6640464775398, "episode": 56.0, "batch_reward": 0.5854714784026146, "critic_loss": 0.36214413510262966, "actor_loss": -60.1499663772583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990565299987793, "step": 56000}
{"episode_reward": 639.7918417017793, "episode": 57.0, "batch_reward": 0.5867266669869423, "critic_loss": 0.3608434538692236, "actor_loss": -60.15163771820068, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.983437538146973, "step": 57000}
{"episode_reward": 617.5950419192499, "episode": 58.0, "batch_reward": 0.5876170236468315, "critic_loss": 0.3802259738892317, "actor_loss": -60.29497356414795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.956465005874634, "step": 58000}
{"episode_reward": 580.8530222865464, "episode": 59.0, "batch_reward": 0.5875131255984306, "critic_loss": 0.4105447575747967, "actor_loss": -60.44014877319336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002082109451294, "step": 59000}
{"episode_reward": 597.2224331512068, "episode": 60.0, "batch_reward": 0.5875313936471939, "critic_loss": 0.4429282928556204, "actor_loss": -60.21035734558105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00114893913269, "step": 60000}
{"episode_reward": 539.0463684356481, "episode": 61.0, "batch_reward": 0.5870917603969574, "critic_loss": 0.4297877600640059, "actor_loss": -60.0985114440918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.2686710357666, "step": 61000}
{"episode_reward": 652.7029190233824, "episode": 62.0, "batch_reward": 0.5875994490981102, "critic_loss": 0.4225710438042879, "actor_loss": -60.125877212524415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99716854095459, "step": 62000}
{"episode_reward": 645.4407752273851, "episode": 63.0, "batch_reward": 0.5890940628051757, "critic_loss": 0.4206036812663078, "actor_loss": -60.37661110687256, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005000591278076, "step": 63000}
{"episode_reward": 624.3875782614275, "episode": 64.0, "batch_reward": 0.5910254284739495, "critic_loss": 0.41272239029407504, "actor_loss": -60.41150148010254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.998643159866333, "step": 64000}
{"episode_reward": 655.1155377124037, "episode": 65.0, "batch_reward": 0.5916537539958954, "critic_loss": 0.40548228566348554, "actor_loss": -60.49177589416504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.958439826965332, "step": 65000}
{"episode_reward": 677.079686480986, "episode": 66.0, "batch_reward": 0.5929595255851745, "critic_loss": 0.41369998979568484, "actor_loss": -60.669274322509764, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.925477504730225, "step": 66000}
{"episode_reward": 697.5508448160804, "episode": 67.0, "batch_reward": 0.5943150816559791, "critic_loss": 0.42049158963561056, "actor_loss": -60.68633964538574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993358373641968, "step": 67000}
{"episode_reward": 676.7382009136007, "episode": 68.0, "batch_reward": 0.5948373446464539, "critic_loss": 0.412089341878891, "actor_loss": -60.77793309020996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.989570140838623, "step": 68000}
{"episode_reward": 674.9991670071882, "episode": 69.0, "batch_reward": 0.5970179246068, "critic_loss": 0.4059898367226124, "actor_loss": -60.72740841674805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981154203414917, "step": 69000}
{"episode_reward": 614.5580736580864, "episode": 70.0, "batch_reward": 0.5961721507310868, "critic_loss": 0.40099225471913813, "actor_loss": -60.85563619995117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002684831619263, "step": 70000}
{"episode_reward": 668.1546549982379, "episode": 71.0, "batch_reward": 0.5981174517273903, "critic_loss": 0.41279516980051995, "actor_loss": -60.8690912322998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.2884566783905, "step": 71000}
{"episode_reward": 697.414503699516, "episode": 72.0, "batch_reward": 0.598762321293354, "critic_loss": 0.4190121393352747, "actor_loss": -60.99751654815674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.991223335266113, "step": 72000}
{"episode_reward": 650.7800009067086, "episode": 73.0, "batch_reward": 0.6002833212018013, "critic_loss": 0.42266477067768576, "actor_loss": -60.94770645904541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.011703729629517, "step": 73000}
{"episode_reward": 665.42487492357, "episode": 74.0, "batch_reward": 0.6008563072085381, "critic_loss": 0.4226553601026535, "actor_loss": -61.0475005569458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00664496421814, "step": 74000}
{"episode_reward": 633.4297057288902, "episode": 75.0, "batch_reward": 0.6012342042326927, "critic_loss": 0.4092099788784981, "actor_loss": -61.311453483581545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97878623008728, "step": 75000}
{"episode_reward": 672.6296208699656, "episode": 76.0, "batch_reward": 0.6016033571362496, "critic_loss": 0.3791656472235918, "actor_loss": -61.28207018280029, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.984521865844727, "step": 76000}
{"episode_reward": 617.9620705995179, "episode": 77.0, "batch_reward": 0.6022464691996574, "critic_loss": 0.39410303008556363, "actor_loss": -61.23206377410889, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95642399787903, "step": 77000}
{"episode_reward": 627.9361748568701, "episode": 78.0, "batch_reward": 0.6024687391519546, "critic_loss": 0.39668862737715244, "actor_loss": -61.232355545043944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.942870616912842, "step": 78000}
{"episode_reward": 642.3132670908594, "episode": 79.0, "batch_reward": 0.6040882097482682, "critic_loss": 0.38342595493793485, "actor_loss": -61.38150720977783, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95602822303772, "step": 79000}
{"episode_reward": 534.6750943701087, "episode": 80.0, "batch_reward": 0.6021744130849839, "critic_loss": 0.4122048318386078, "actor_loss": -61.22465855407715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00410270690918, "step": 80000}
{"episode_reward": 621.9829595057615, "episode": 81.0, "batch_reward": 0.6015503979921341, "critic_loss": 0.4219583692550659, "actor_loss": -61.06220817565918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.287158489227295, "step": 81000}
{"episode_reward": 670.6533178953127, "episode": 82.0, "batch_reward": 0.602923208117485, "critic_loss": 0.40756325276196004, "actor_loss": -61.128246414184574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.984736680984497, "step": 82000}
{"episode_reward": 691.7654458446789, "episode": 83.0, "batch_reward": 0.6034165326356887, "critic_loss": 0.4282183204293251, "actor_loss": -61.31546643066406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.965736627578735, "step": 83000}
{"episode_reward": 561.4423164795398, "episode": 84.0, "batch_reward": 0.6027637606859207, "critic_loss": 0.4356033524274826, "actor_loss": -61.08471552276611, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.954508781433105, "step": 84000}
{"episode_reward": 570.9339870829356, "episode": 85.0, "batch_reward": 0.6039475783109665, "critic_loss": 0.4547417078614235, "actor_loss": -61.28848825836182, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.945987701416016, "step": 85000}
{"episode_reward": 616.6361673172139, "episode": 86.0, "batch_reward": 0.6046183025240898, "critic_loss": 0.42146034449338915, "actor_loss": -61.28706970977783, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.974320888519287, "step": 86000}
{"episode_reward": 641.3234567971595, "episode": 87.0, "batch_reward": 0.6038813528418541, "critic_loss": 0.4476537633240223, "actor_loss": -61.21237860870362, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.021440744400024, "step": 87000}
{"episode_reward": 657.7808698779111, "episode": 88.0, "batch_reward": 0.6041138460636138, "critic_loss": 0.46286577919125554, "actor_loss": -61.2056025390625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.340275049209595, "step": 88000}
{"episode_reward": 620.8957121454332, "episode": 89.0, "batch_reward": 0.6049910320043563, "critic_loss": 0.5394401153028011, "actor_loss": -61.284919914245606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.015309810638428, "step": 89000}
{"episode_reward": 570.039759705619, "episode": 90.0, "batch_reward": 0.6052248534560204, "critic_loss": 0.568011271521449, "actor_loss": -61.1133208694458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95293402671814, "step": 90000}
{"episode_reward": 695.3763354386219, "episode": 91.0, "batch_reward": 0.6043807253241539, "critic_loss": 0.5295937311202288, "actor_loss": -61.25849831390381, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.287659645080566, "step": 91000}
{"episode_reward": 637.740660995796, "episode": 92.0, "batch_reward": 0.60559626942873, "critic_loss": 0.565783614307642, "actor_loss": -61.17083427429199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.018319606781006, "step": 92000}
{"episode_reward": 609.6059235118313, "episode": 93.0, "batch_reward": 0.6056452011466026, "critic_loss": 0.5497414572238922, "actor_loss": -61.299617790222165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.967052221298218, "step": 93000}
{"episode_reward": 610.4491488461879, "episode": 94.0, "batch_reward": 0.6057991316914558, "critic_loss": 0.6087389927208423, "actor_loss": -61.156890213012694, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.27339243888855, "step": 94000}
{"episode_reward": 609.4716461823771, "episode": 95.0, "batch_reward": 0.6058889554738999, "critic_loss": 0.6050129199922085, "actor_loss": -61.262597709655765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9563090801239, "step": 95000}
{"episode_reward": 579.5368161565558, "episode": 96.0, "batch_reward": 0.6053994879126549, "critic_loss": 0.6435555635392666, "actor_loss": -61.227003379821774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.946205377578735, "step": 96000}
{"episode_reward": 604.6697930532172, "episode": 97.0, "batch_reward": 0.6057415424585343, "critic_loss": 0.5894191621392966, "actor_loss": -61.18918669128418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96771001815796, "step": 97000}
{"episode_reward": 642.6652682284698, "episode": 98.0, "batch_reward": 0.6055579701662064, "critic_loss": 0.6489323383867741, "actor_loss": -61.14531716156006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004562616348267, "step": 98000}
{"episode_reward": 377.03386683537855, "episode": 99.0, "batch_reward": 0.6044570182561875, "critic_loss": 0.6778690370619297, "actor_loss": -60.98747508239746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.013479948043823, "step": 99000}
{"episode_reward": 663.8012465558868, "episode": 100.0, "batch_reward": 0.6045276663303375, "critic_loss": 0.6841382756531239, "actor_loss": -61.0552720413208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.998896837234497, "step": 100000}
{"episode_reward": 649.367274579154, "episode": 101.0, "batch_reward": 0.6039265975356102, "critic_loss": 0.6704783506989479, "actor_loss": -60.90487492370605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.253889083862305, "step": 101000}
{"episode_reward": 509.119408882683, "episode": 102.0, "batch_reward": 0.6042125420570373, "critic_loss": 0.6693299321830273, "actor_loss": -61.03070891571045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.008808374404907, "step": 102000}
{"episode_reward": 379.5691269914718, "episode": 103.0, "batch_reward": 0.6023042784929276, "critic_loss": 0.6755903956741095, "actor_loss": -60.67929857635498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.955187559127808, "step": 103000}
{"episode_reward": 676.0401729558839, "episode": 104.0, "batch_reward": 0.6022998920679092, "critic_loss": 0.710908483684063, "actor_loss": -60.849940689086914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97405481338501, "step": 104000}
{"episode_reward": 564.6821466332135, "episode": 105.0, "batch_reward": 0.6016238613724708, "critic_loss": 0.6534677847027779, "actor_loss": -60.73598342895508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.036314487457275, "step": 105000}
{"episode_reward": 640.1087701445219, "episode": 106.0, "batch_reward": 0.6019610461592674, "critic_loss": 0.7122171097397805, "actor_loss": -60.90953800201416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.001967906951904, "step": 106000}
{"episode_reward": 574.8894013063804, "episode": 107.0, "batch_reward": 0.6019168440699577, "critic_loss": 0.7014423754215241, "actor_loss": -60.81626537322998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97356939315796, "step": 107000}
{"episode_reward": 630.4597578266059, "episode": 108.0, "batch_reward": 0.6023829967975617, "critic_loss": 0.687544823884964, "actor_loss": -60.743813636779784, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00308656692505, "step": 108000}
{"episode_reward": 642.8799940121248, "episode": 109.0, "batch_reward": 0.6020928514003754, "critic_loss": 0.6567193189561367, "actor_loss": -60.7840474395752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.998260021209717, "step": 109000}
{"episode_reward": 599.8214243248783, "episode": 110.0, "batch_reward": 0.6024724243283271, "critic_loss": 0.7230390902161599, "actor_loss": -60.78751190948486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01808190345764, "step": 110000}
{"episode_reward": 627.8992797431982, "episode": 111.0, "batch_reward": 0.602288134932518, "critic_loss": 0.6994926186650992, "actor_loss": -60.77667367553711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.271578788757324, "step": 111000}
{"episode_reward": 627.1653894634844, "episode": 112.0, "batch_reward": 0.6024035779833794, "critic_loss": 0.6811967916190624, "actor_loss": -60.91988150024414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01185917854309, "step": 112000}
{"episode_reward": 642.3724134325892, "episode": 113.0, "batch_reward": 0.6037812502980232, "critic_loss": 0.6463117841333151, "actor_loss": -60.87901409912109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02893304824829, "step": 113000}
{"episode_reward": 623.7830747238845, "episode": 114.0, "batch_reward": 0.6016587618589401, "critic_loss": 0.6968608644008637, "actor_loss": -60.7894481048584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01044511795044, "step": 114000}
{"episode_reward": 52.501367162230466, "episode": 115.0, "batch_reward": 0.5987395087480545, "critic_loss": 0.6650257336199283, "actor_loss": -60.57286799621582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004462718963623, "step": 115000}
{"episode_reward": 654.7217051160576, "episode": 116.0, "batch_reward": 0.5995301424860954, "critic_loss": 0.6248421372175217, "actor_loss": -60.590149017333985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02204442024231, "step": 116000}
{"episode_reward": 642.5148827841372, "episode": 117.0, "batch_reward": 0.5994329478740692, "critic_loss": 0.6526073546558618, "actor_loss": -60.51662581634521, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007462739944458, "step": 117000}
{"episode_reward": 648.6627952743488, "episode": 118.0, "batch_reward": 0.5989768475294113, "critic_loss": 0.6588502261638641, "actor_loss": -60.46573191833496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99465584754944, "step": 118000}
{"episode_reward": 277.22125125911424, "episode": 119.0, "batch_reward": 0.5975025688409805, "critic_loss": 0.6872920894920826, "actor_loss": -60.2988883972168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.946935415267944, "step": 119000}
{"episode_reward": 597.0176714409123, "episode": 120.0, "batch_reward": 0.5962659519314766, "critic_loss": 0.6346131340861321, "actor_loss": -60.398658058166504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99665904045105, "step": 120000}
{"episode_reward": 665.5065281498147, "episode": 121.0, "batch_reward": 0.597605551302433, "critic_loss": 0.6629578874707222, "actor_loss": -60.28674719238281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.216158390045166, "step": 121000}
{"episode_reward": 665.9205940400388, "episode": 122.0, "batch_reward": 0.5986781803965568, "critic_loss": 0.6625556050539017, "actor_loss": -60.49380181884766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0047025680542, "step": 122000}
{"episode_reward": 581.1305470259789, "episode": 123.0, "batch_reward": 0.5977452964782715, "critic_loss": 0.5868952824324369, "actor_loss": -60.342706924438474, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.996265649795532, "step": 123000}
{"episode_reward": 655.3997995723144, "episode": 124.0, "batch_reward": 0.5986136161088943, "critic_loss": 0.6198406487554312, "actor_loss": -60.316703704833984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9843692779541, "step": 124000}
{"episode_reward": 671.731177276277, "episode": 125.0, "batch_reward": 0.6003727285265923, "critic_loss": 0.6541007825136185, "actor_loss": -60.67808024597168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00105905532837, "step": 125000}
{"episode_reward": 672.1488267280613, "episode": 126.0, "batch_reward": 0.600384112417698, "critic_loss": 0.654658738270402, "actor_loss": -60.584148628234864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0258572101593, "step": 126000}
{"episode_reward": 587.1552823735103, "episode": 127.0, "batch_reward": 0.599681420326233, "critic_loss": 0.6382762943208218, "actor_loss": -60.44532556152344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.980528831481934, "step": 127000}
{"episode_reward": 666.7433970580107, "episode": 128.0, "batch_reward": 0.6009715622663498, "critic_loss": 0.6850031213462353, "actor_loss": -60.682107208251956, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95826530456543, "step": 128000}
{"episode_reward": 652.3125749175621, "episode": 129.0, "batch_reward": 0.6000374420881271, "critic_loss": 0.6456724045574666, "actor_loss": -60.578539978027344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.971907377243042, "step": 129000}
{"episode_reward": 598.6521705447542, "episode": 130.0, "batch_reward": 0.6008861399888993, "critic_loss": 0.6431046288758516, "actor_loss": -60.462231407165525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95907735824585, "step": 130000}
{"episode_reward": 640.4707992702159, "episode": 131.0, "batch_reward": 0.6011642317771911, "critic_loss": 0.6036244611293078, "actor_loss": -60.34531027984619, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.24843454360962, "step": 131000}
{"episode_reward": 677.1633092139972, "episode": 132.0, "batch_reward": 0.6000093951821327, "critic_loss": 0.5503132753074169, "actor_loss": -60.3284202041626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.021854877471924, "step": 132000}
{"episode_reward": 639.8651306240431, "episode": 133.0, "batch_reward": 0.6009203151464463, "critic_loss": 0.5457456419765949, "actor_loss": -60.67045109558106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988069772720337, "step": 133000}
{"episode_reward": 654.3578583705795, "episode": 134.0, "batch_reward": 0.6010293127298355, "critic_loss": 0.5756826766729355, "actor_loss": -60.73882299041748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9822940826416, "step": 134000}
{"episode_reward": 654.1338167985944, "episode": 135.0, "batch_reward": 0.6024528113603592, "critic_loss": 0.6494446216821671, "actor_loss": -60.84463833618164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96786093711853, "step": 135000}
{"episode_reward": 637.7931133372249, "episode": 136.0, "batch_reward": 0.602319580078125, "critic_loss": 0.6861573041379452, "actor_loss": -60.781784393310545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.953081846237183, "step": 136000}
{"episode_reward": 671.034424489848, "episode": 137.0, "batch_reward": 0.6029991499781608, "critic_loss": 0.7677720882296563, "actor_loss": -60.80489847564697, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.965165853500366, "step": 137000}
{"episode_reward": 644.5427281698978, "episode": 138.0, "batch_reward": 0.603878556907177, "critic_loss": 0.7513749760687352, "actor_loss": -60.654246963500974, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.973817586898804, "step": 138000}
{"episode_reward": 656.1151537929348, "episode": 139.0, "batch_reward": 0.6042796765565872, "critic_loss": 0.7663685795068741, "actor_loss": -60.684771759033204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93898344039917, "step": 139000}
{"episode_reward": 615.8285775023921, "episode": 140.0, "batch_reward": 0.6035495093464851, "critic_loss": 0.7332046309262514, "actor_loss": -60.754795974731444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.984944343566895, "step": 140000}
{"episode_reward": 567.9520583070389, "episode": 141.0, "batch_reward": 0.6016346514821053, "critic_loss": 0.7477679161727429, "actor_loss": -60.6848136138916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.26256990432739, "step": 141000}
{"episode_reward": 91.56827673696672, "episode": 142.0, "batch_reward": 0.6000123535990715, "critic_loss": 0.726637478262186, "actor_loss": -60.622672790527346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.000221967697144, "step": 142000}
{"episode_reward": 575.5959954613993, "episode": 143.0, "batch_reward": 0.5995657870769501, "critic_loss": 0.7407666110396385, "actor_loss": -60.76951052856445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00367498397827, "step": 143000}
{"episode_reward": 565.9851079709447, "episode": 144.0, "batch_reward": 0.5990414965748787, "critic_loss": 0.7392857166826725, "actor_loss": -60.66974494171143, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006806135177612, "step": 144000}
{"episode_reward": 431.97882039945785, "episode": 145.0, "batch_reward": 0.5972558850646019, "critic_loss": 0.765532288223505, "actor_loss": -60.753356491088866, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.036683082580566, "step": 145000}
{"episode_reward": 6.753964418857039, "episode": 146.0, "batch_reward": 0.5927933521270752, "critic_loss": 0.8041724841594696, "actor_loss": -60.14840148162842, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.045722246170044, "step": 146000}
{"episode_reward": 233.4821882430791, "episode": 147.0, "batch_reward": 0.5914738775491715, "critic_loss": 0.6580824555307627, "actor_loss": -60.10519401550293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04052472114563, "step": 147000}
{"episode_reward": 612.2358887190137, "episode": 148.0, "batch_reward": 0.5916621409654618, "critic_loss": 0.6583852422237396, "actor_loss": -60.215075721740725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004859447479248, "step": 148000}
{"episode_reward": 501.1134098454805, "episode": 149.0, "batch_reward": 0.5912260302305221, "critic_loss": 0.6769823905229568, "actor_loss": -60.11832839202881, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.042765378952026, "step": 149000}
{"episode_reward": 627.6666853912144, "episode": 150.0, "batch_reward": 0.5914410091042519, "critic_loss": 0.6561426327526569, "actor_loss": -60.18978238677978, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
