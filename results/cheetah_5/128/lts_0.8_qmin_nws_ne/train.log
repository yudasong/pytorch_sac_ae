{"episode_reward": 0.0, "episode": 1.0, "duration": 17.508738040924072, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.512843132019043, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.2592453770674877, "critic_loss": 0.017137192867495363, "actor_loss": -36.367736383056155, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.620476484298706, "step": 3000}
{"episode_reward": 3.6037138565796947, "episode": 4.0, "batch_reward": 0.1609871331602335, "critic_loss": 0.015820394115988165, "actor_loss": -31.665811170101165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.357693433761597, "step": 4000}
{"episode_reward": 5.700431914134264, "episode": 5.0, "batch_reward": 0.12631624864041804, "critic_loss": 0.017544343742076307, "actor_loss": -30.656199963092803, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.364272832870483, "step": 5000}
{"episode_reward": 20.209618190605173, "episode": 6.0, "batch_reward": 0.11053654158487916, "critic_loss": 0.02756221982371062, "actor_loss": -29.38639896917343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35087823867798, "step": 6000}
{"episode_reward": 37.52908308078853, "episode": 7.0, "batch_reward": 0.09539552066847681, "critic_loss": 0.021414764928165825, "actor_loss": -29.343996334552767, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35873317718506, "step": 7000}
{"episode_reward": 1.473852689046328, "episode": 8.0, "batch_reward": 0.08327380756661296, "critic_loss": 0.025538505358155817, "actor_loss": -29.61937807750702, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3412344455719, "step": 8000}
{"episode_reward": 2.1341086570194863, "episode": 9.0, "batch_reward": 0.07353214249014854, "critic_loss": 0.022258443384896964, "actor_loss": -27.270082145690917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.367437839508057, "step": 9000}
{"episode_reward": 1.9365383654583046, "episode": 10.0, "batch_reward": 0.06602404675073922, "critic_loss": 0.028810176767408848, "actor_loss": -28.53468715786934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.322696924209595, "step": 10000}
{"episode_reward": 2.3105317396597957, "episode": 11.0, "batch_reward": 0.0595358741953969, "critic_loss": 0.019874679626198485, "actor_loss": -27.191097481012346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.90394449234009, "step": 11000}
{"episode_reward": 4.709969467423695, "episode": 12.0, "batch_reward": 0.055467228379100564, "critic_loss": 0.0190171418543905, "actor_loss": -27.7889638235569, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.333375215530396, "step": 12000}
{"episode_reward": 4.807856493795865, "episode": 13.0, "batch_reward": 0.0511298846937716, "critic_loss": 0.02144381688651629, "actor_loss": -28.022700748443604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.369611978530884, "step": 13000}
{"episode_reward": 4.970500312852717, "episode": 14.0, "batch_reward": 0.04789584187045694, "critic_loss": 0.020515663583762944, "actor_loss": -28.037969715118408, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37235450744629, "step": 14000}
{"episode_reward": 5.125292850074371, "episode": 15.0, "batch_reward": 0.045082465942949054, "critic_loss": 0.015039488491485826, "actor_loss": -26.80068752503395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36957812309265, "step": 15000}
{"episode_reward": 3.312483770579865, "episode": 16.0, "batch_reward": 0.04238133515883237, "critic_loss": 0.02347503919014707, "actor_loss": -27.357051468610763, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35982656478882, "step": 16000}
{"episode_reward": 4.8277228993358285, "episode": 17.0, "batch_reward": 0.039455205804202705, "critic_loss": 0.016707829477265478, "actor_loss": -27.610718140602113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.319520235061646, "step": 17000}
{"episode_reward": 3.094076310084221, "episode": 18.0, "batch_reward": 0.03792943991813809, "critic_loss": 0.01879913674853742, "actor_loss": -27.63796962928772, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.317296504974365, "step": 18000}
{"episode_reward": 5.167701879913975, "episode": 19.0, "batch_reward": 0.03545904322713613, "critic_loss": 0.014645435619051569, "actor_loss": -27.11774176156521, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.346344709396362, "step": 19000}
{"episode_reward": 3.62742276063653, "episode": 20.0, "batch_reward": 0.03446548270061612, "critic_loss": 0.019693449725105894, "actor_loss": -27.670229242920875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.350817680358887, "step": 20000}
{"episode_reward": 4.209275583314798, "episode": 21.0, "batch_reward": 0.032909858629107475, "critic_loss": 0.01871363667107653, "actor_loss": -25.6691292167902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.88926315307617, "step": 21000}
{"episode_reward": 4.663667787172084, "episode": 22.0, "batch_reward": 0.031349311667494474, "critic_loss": 0.01767488768574549, "actor_loss": -27.53328678536415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32850742340088, "step": 22000}
{"episode_reward": 2.285207053340165, "episode": 23.0, "batch_reward": 0.030679856625385582, "critic_loss": 0.014614962090854533, "actor_loss": -27.2981744222641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.363531589508057, "step": 23000}
{"episode_reward": 5.132664113461244, "episode": 24.0, "batch_reward": 0.029249645467381926, "critic_loss": 0.014864805544784759, "actor_loss": -26.23408414530754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36833381652832, "step": 24000}
{"episode_reward": 3.3281845345469403, "episode": 25.0, "batch_reward": 0.027394556374754755, "critic_loss": 0.012067260324954986, "actor_loss": -27.68447833275795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.327028512954712, "step": 25000}
{"episode_reward": 4.160333510751562, "episode": 26.0, "batch_reward": 0.027121287387097254, "critic_loss": 0.01556043139816029, "actor_loss": -26.709058997154237, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32935070991516, "step": 26000}
{"episode_reward": 3.772120484677682, "episode": 27.0, "batch_reward": 0.026228223524522035, "critic_loss": 0.01534744240285363, "actor_loss": -26.55044192290306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35817837715149, "step": 27000}
{"episode_reward": 4.941322249118496, "episode": 28.0, "batch_reward": 0.025250231816899033, "critic_loss": 0.020142524937458803, "actor_loss": -26.196082854688168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.336195945739746, "step": 28000}
{"episode_reward": 4.619862104330164, "episode": 29.0, "batch_reward": 0.024700601101852952, "critic_loss": 0.013525971244263928, "actor_loss": -26.971663902640344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.365662097930908, "step": 29000}
{"episode_reward": 4.4867173328734244, "episode": 30.0, "batch_reward": 0.02391995253274217, "critic_loss": 0.016109744078858058, "actor_loss": -26.685756646215914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.384825468063354, "step": 30000}
{"episode_reward": 3.7226960099754285, "episode": 31.0, "batch_reward": 0.02365197233716026, "critic_loss": 0.01484134629368782, "actor_loss": -26.489016550958155, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.8836088180542, "step": 31000}
{"episode_reward": 4.776082323634496, "episode": 32.0, "batch_reward": 0.022629753496032207, "critic_loss": 0.014428273741010344, "actor_loss": -26.39110531526804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.348823308944702, "step": 32000}
{"episode_reward": 5.171446024910821, "episode": 33.0, "batch_reward": 0.02163392004207708, "critic_loss": 0.015788521714886882, "actor_loss": -26.621241186261177, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31403160095215, "step": 33000}
{"episode_reward": 3.784115653914273, "episode": 34.0, "batch_reward": 0.02180851287441328, "critic_loss": 0.013283285541576333, "actor_loss": -26.335368941783905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.327847480773926, "step": 34000}
{"episode_reward": 4.623236045377574, "episode": 35.0, "batch_reward": 0.021209063841961324, "critic_loss": 0.011745322869188385, "actor_loss": -26.06545101970434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.358774423599243, "step": 35000}
{"episode_reward": 3.5065369681647485, "episode": 36.0, "batch_reward": 0.02065528613468632, "critic_loss": 0.010197320006613154, "actor_loss": -26.633530938923357, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.297301769256592, "step": 36000}
{"episode_reward": 4.367720204802572, "episode": 37.0, "batch_reward": 0.020236709371441976, "critic_loss": 0.01298765747845755, "actor_loss": -26.368737199127676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.346444129943848, "step": 37000}
{"episode_reward": 3.0536185638413875, "episode": 38.0, "batch_reward": 0.020424338210141287, "critic_loss": 0.008272179697523824, "actor_loss": -27.318826255857946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.360490322113037, "step": 38000}
{"episode_reward": 4.638450626671694, "episode": 39.0, "batch_reward": 0.019582641092129052, "critic_loss": 0.011730525870982092, "actor_loss": -27.61463594585657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.329979181289673, "step": 39000}
{"episode_reward": 3.6673042489408534, "episode": 40.0, "batch_reward": 0.019152891450561583, "critic_loss": 0.010365614297159481, "actor_loss": -28.02707005995512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.342753887176514, "step": 40000}
{"episode_reward": 3.732641866902013, "episode": 41.0, "batch_reward": 0.01903244403982535, "critic_loss": 0.014525949812014004, "actor_loss": -26.64694505351782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.94513511657715, "step": 41000}
{"episode_reward": 4.896646430281161, "episode": 42.0, "batch_reward": 0.018252336483448744, "critic_loss": 0.010478588659927481, "actor_loss": -26.82454680854082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3440899848938, "step": 42000}
{"episode_reward": 4.126464204711186, "episode": 43.0, "batch_reward": 0.01824637576146051, "critic_loss": 0.010369324897124898, "actor_loss": -27.308756828308105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34904670715332, "step": 43000}
{"episode_reward": 5.205964958376289, "episode": 44.0, "batch_reward": 0.017728391789132728, "critic_loss": 0.01588419969988172, "actor_loss": -26.339309578239916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3264582157135, "step": 44000}
{"episode_reward": 3.0201371048758725, "episode": 45.0, "batch_reward": 0.01744149948353879, "critic_loss": 0.007844133811493521, "actor_loss": -26.313013262927534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.338924169540405, "step": 45000}
{"episode_reward": 3.6089551808856575, "episode": 46.0, "batch_reward": 0.017361223300453275, "critic_loss": 0.015972420378442622, "actor_loss": -26.54404784309864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.340138912200928, "step": 46000}
{"episode_reward": 5.461210308514792, "episode": 47.0, "batch_reward": 0.016655213681980967, "critic_loss": 0.0111382996133907, "actor_loss": -25.48499567770958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.328544855117798, "step": 47000}
{"episode_reward": 3.2224839296527388, "episode": 48.0, "batch_reward": 0.01667912421375513, "critic_loss": 0.01197472637296596, "actor_loss": -26.41568750959635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34330940246582, "step": 48000}
{"episode_reward": 3.9030001964818233, "episode": 49.0, "batch_reward": 0.01655044135591015, "critic_loss": 0.012597571821534075, "actor_loss": -26.53158239966631, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.342997074127197, "step": 49000}
{"episode_reward": 4.40685226147464, "episode": 50.0, "batch_reward": 0.015681333804968743, "critic_loss": 0.012481798188120593, "actor_loss": -25.456449679791927, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32031488418579, "step": 50000}
{"episode_reward": 3.944061932876494, "episode": 51.0, "batch_reward": 0.015634821852203457, "critic_loss": 0.012870200043791555, "actor_loss": -26.76477367389202, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.8955500125885, "step": 51000}
{"episode_reward": 5.821984190240333, "episode": 52.0, "batch_reward": 0.015497208523564041, "critic_loss": 0.014001172134259832, "actor_loss": -25.712175944268704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.347575187683105, "step": 52000}
{"episode_reward": 4.195559891603012, "episode": 53.0, "batch_reward": 0.015705360285472123, "critic_loss": 0.013776452185309608, "actor_loss": -26.128398295402526, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.361257791519165, "step": 53000}
{"episode_reward": 3.6289734629419987, "episode": 54.0, "batch_reward": 0.014751909747021274, "critic_loss": 0.012588375118284603, "actor_loss": -26.637358988404273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33997631072998, "step": 54000}
{"episode_reward": 3.647244099609452, "episode": 55.0, "batch_reward": 0.014764805421000346, "critic_loss": 0.016871786390271155, "actor_loss": -26.957536768853664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.346251249313354, "step": 55000}
{"episode_reward": 2.3025105580569205, "episode": 56.0, "batch_reward": 0.014690685797017067, "critic_loss": 0.01366321265300212, "actor_loss": -26.73316460311413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32502007484436, "step": 56000}
{"episode_reward": 4.556239153712526, "episode": 57.0, "batch_reward": 0.014254610488191247, "critic_loss": 0.014096263386658392, "actor_loss": -26.452374365091323, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36296033859253, "step": 57000}
{"episode_reward": 2.104050922986515, "episode": 58.0, "batch_reward": 0.014072558710118756, "critic_loss": 0.017537529371489655, "actor_loss": -26.771886529028414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32169818878174, "step": 58000}
{"episode_reward": 5.61192863565938, "episode": 59.0, "batch_reward": 0.014107034697430208, "critic_loss": 0.013672936383023625, "actor_loss": -27.787381765305994, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.343629837036133, "step": 59000}
{"episode_reward": 4.02198986209213, "episode": 60.0, "batch_reward": 0.014007947038160638, "critic_loss": 0.01252557607248309, "actor_loss": -26.565143088668584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33173942565918, "step": 60000}
{"episode_reward": 5.348351097119573, "episode": 61.0, "batch_reward": 0.013561449257889763, "critic_loss": 0.012930601383195607, "actor_loss": -25.9616976005435, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.631845474243164, "step": 61000}
{"episode_reward": 4.537755097916461, "episode": 62.0, "batch_reward": 0.01370664907922037, "critic_loss": 0.015992790517469983, "actor_loss": -26.107563428074123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.037299871444702, "step": 62000}
{"episode_reward": 3.942006818803779, "episode": 63.0, "batch_reward": 0.013554028732236476, "critic_loss": 0.012422366321050505, "actor_loss": -26.285711257696153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.036551475524902, "step": 63000}
{"episode_reward": 3.587244979548014, "episode": 64.0, "batch_reward": 0.013336914820130915, "critic_loss": 0.019911640886508396, "actor_loss": -26.455347439020873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04670023918152, "step": 64000}
{"episode_reward": 4.117990989670012, "episode": 65.0, "batch_reward": 0.013302706461632624, "critic_loss": 0.012266423146502347, "actor_loss": -26.53501858380437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.042548418045044, "step": 65000}
{"episode_reward": 2.263502132246692, "episode": 66.0, "batch_reward": 0.012907045803964137, "critic_loss": 0.012062887447915272, "actor_loss": -26.82307960793376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.066040992736816, "step": 66000}
{"episode_reward": 3.104849653145957, "episode": 67.0, "batch_reward": 0.01300176292611286, "critic_loss": 0.012413775118984631, "actor_loss": -26.447692949801684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04732894897461, "step": 67000}
{"episode_reward": 3.43988724986012, "episode": 68.0, "batch_reward": 0.012879689828958362, "critic_loss": 0.008369158581030206, "actor_loss": -26.710646994650364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.033592462539673, "step": 68000}
{"episode_reward": 4.379925275352455, "episode": 69.0, "batch_reward": 0.012820902222534642, "critic_loss": 0.009532399046045612, "actor_loss": -25.84343396061659, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06783175468445, "step": 69000}
{"episode_reward": 5.371542740920412, "episode": 70.0, "batch_reward": 0.012659808956319466, "critic_loss": 0.010435818246158305, "actor_loss": -26.372815721273422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.069843530654907, "step": 70000}
{"episode_reward": 4.452074786099915, "episode": 71.0, "batch_reward": 0.012477956050541252, "critic_loss": 0.012985001717293927, "actor_loss": -26.163325841784477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.470887184143066, "step": 71000}
{"episode_reward": 2.507463354809891, "episode": 72.0, "batch_reward": 0.01209156071767211, "critic_loss": 0.011034330071808655, "actor_loss": -26.6047672637105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.066008806228638, "step": 72000}
{"episode_reward": 5.0804381374376, "episode": 73.0, "batch_reward": 0.012137833773624152, "critic_loss": 0.013365178111598652, "actor_loss": -25.723022697478534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.014042139053345, "step": 73000}
{"episode_reward": 4.453000703294523, "episode": 74.0, "batch_reward": 0.011787394397659228, "critic_loss": 0.01247239534729306, "actor_loss": -25.387165831893682, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03799057006836, "step": 74000}
{"episode_reward": 2.9919129337940364, "episode": 75.0, "batch_reward": 0.011953292152145878, "critic_loss": 0.01612530802922993, "actor_loss": -27.446346582710742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06475830078125, "step": 75000}
{"episode_reward": 2.9725712090877936, "episode": 76.0, "batch_reward": 0.011820793336723, "critic_loss": 0.0076833635734728884, "actor_loss": -26.542877569884062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.046414613723755, "step": 76000}
{"episode_reward": 3.4528989255349525, "episode": 77.0, "batch_reward": 0.011792649373644963, "critic_loss": 0.011330208554121783, "actor_loss": -26.13818616756797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.066574811935425, "step": 77000}
{"episode_reward": 4.907655518040511, "episode": 78.0, "batch_reward": 0.011378139346139505, "critic_loss": 0.0070418850615533305, "actor_loss": -25.794754681140184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.064191579818726, "step": 78000}
{"episode_reward": 3.5662462670630077, "episode": 79.0, "batch_reward": 0.011351831214269623, "critic_loss": 0.004995957383609494, "actor_loss": -26.451262644141913, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.02837634086609, "step": 79000}
{"episode_reward": 5.628120157892924, "episode": 80.0, "batch_reward": 0.011729275264078751, "critic_loss": 0.007221971241975552, "actor_loss": -26.799141771793366, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.038941860198975, "step": 80000}
{"episode_reward": 3.139684550263187, "episode": 81.0, "batch_reward": 0.011224680786021055, "critic_loss": 0.004988432878169988, "actor_loss": -26.496136100202797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.5037317276001, "step": 81000}
{"episode_reward": 2.925306957041883, "episode": 82.0, "batch_reward": 0.011340347142191605, "critic_loss": 0.006082790288914112, "actor_loss": -25.85382069030404, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.048035860061646, "step": 82000}
{"episode_reward": 3.00882022362206, "episode": 83.0, "batch_reward": 0.011173457248136402, "critic_loss": 0.008579422082868405, "actor_loss": -26.706999660670757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.038456201553345, "step": 83000}
{"episode_reward": 4.203321245080132, "episode": 84.0, "batch_reward": 0.01106388478120789, "critic_loss": 0.0097277150224254, "actor_loss": -26.05950807696581, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.0579731464386, "step": 84000}
{"episode_reward": 3.638721962137279, "episode": 85.0, "batch_reward": 0.010923416550038383, "critic_loss": 0.009012051390702254, "actor_loss": -27.07927141135931, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.043020486831665, "step": 85000}
{"episode_reward": 5.213414897480896, "episode": 86.0, "batch_reward": 0.01115571882086806, "critic_loss": 0.007236607612219814, "actor_loss": -26.654038657814265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.044785022735596, "step": 86000}
{"episode_reward": 3.2818144502368183, "episode": 87.0, "batch_reward": 0.01114189006946981, "critic_loss": 0.007936752303685353, "actor_loss": -26.518017822057008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04409384727478, "step": 87000}
{"episode_reward": 4.364341775008186, "episode": 88.0, "batch_reward": 0.010804942649090663, "critic_loss": 0.007354493798062322, "actor_loss": -26.43758862513304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.01424288749695, "step": 88000}
{"episode_reward": 3.123889378118446, "episode": 89.0, "batch_reward": 0.01071222866885364, "critic_loss": 0.008573485624277965, "actor_loss": -26.773688556820154, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.01140856742859, "step": 89000}
{"episode_reward": 3.746969109966964, "episode": 90.0, "batch_reward": 0.010656439560232683, "critic_loss": 0.01056562076814589, "actor_loss": -25.29574573841691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.029331922531128, "step": 90000}
{"episode_reward": 3.2687068326514934, "episode": 91.0, "batch_reward": 0.010639946268405765, "critic_loss": 0.008899617725983262, "actor_loss": -26.568036367207764, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.1886510848999, "step": 91000}
{"episode_reward": 3.576056440074849, "episode": 92.0, "batch_reward": 0.010491082022432237, "critic_loss": 0.014666317046750919, "actor_loss": -25.852346836298704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.85714817047119, "step": 92000}
{"episode_reward": 4.833653809498333, "episode": 93.0, "batch_reward": 0.010535125498194247, "critic_loss": 0.010711766421998618, "actor_loss": -26.554103820562364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.00365161895752, "step": 93000}
{"episode_reward": 5.224639873663077, "episode": 94.0, "batch_reward": 0.010568135318811983, "critic_loss": 0.013593312832672382, "actor_loss": -25.530913832515477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.015501976013184, "step": 94000}
{"episode_reward": 5.541232043569229, "episode": 95.0, "batch_reward": 0.010531827074009925, "critic_loss": 0.008485822628281313, "actor_loss": -26.272494759857654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04841661453247, "step": 95000}
{"episode_reward": 3.75727538056695, "episode": 96.0, "batch_reward": 0.01013847113098018, "critic_loss": 0.005415826902128174, "actor_loss": -26.279915437549352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.026928186416626, "step": 96000}
{"episode_reward": 5.251353007444579, "episode": 97.0, "batch_reward": 0.010196745720691978, "critic_loss": 0.012877993376911036, "actor_loss": -26.084003417029976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.007171630859375, "step": 97000}
{"episode_reward": 3.878469360123106, "episode": 98.0, "batch_reward": 0.010459499198943376, "critic_loss": 0.007384330975532066, "actor_loss": -25.966085885375737, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.96436882019043, "step": 98000}
{"episode_reward": 4.478757395300441, "episode": 99.0, "batch_reward": 0.01003896044427529, "critic_loss": 0.005515348229047958, "actor_loss": -26.005929902732372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.011011362075806, "step": 99000}
{"episode_reward": 2.9267073853284824, "episode": 100.0, "batch_reward": 0.009963643160182983, "critic_loss": 0.006657758025801741, "actor_loss": -26.152062374338506, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.007758140563965, "step": 100000}
{"episode_reward": 3.5009904476951106, "episode": 101.0, "batch_reward": 0.010035668720956892, "critic_loss": 0.005429394063510699, "actor_loss": -25.22099528634548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.02637982368469, "step": 101000}
{"episode_reward": 6.545319254680725, "episode": 102.0, "batch_reward": 0.009821088150376455, "critic_loss": 0.004104015627613989, "actor_loss": -26.39062887945771, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.691667795181274, "step": 102000}
{"episode_reward": 2.885203948051754, "episode": 103.0, "batch_reward": 0.009729528184747323, "critic_loss": 0.0045326774243221735, "actor_loss": -25.474195816889406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.805158615112305, "step": 103000}
{"episode_reward": 3.614790042079552, "episode": 104.0, "batch_reward": 0.00977312928205356, "critic_loss": 0.0054258517744674465, "actor_loss": -26.397689411461354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.821399211883545, "step": 104000}
{"episode_reward": 2.7698625591881036, "episode": 105.0, "batch_reward": 0.009781147773144767, "critic_loss": 0.0052935018223361115, "actor_loss": -25.85372892013192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.30000615119934, "step": 105000}
{"episode_reward": 2.861648532599971, "episode": 106.0, "batch_reward": 0.009430769716389478, "critic_loss": 0.006126375391453621, "actor_loss": -26.703076464682816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.861670970916748, "step": 106000}
{"episode_reward": 3.779655625018175, "episode": 107.0, "batch_reward": 0.00935018330346793, "critic_loss": 0.006616856133885449, "actor_loss": -26.301879535540937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.75437593460083, "step": 107000}
{"episode_reward": 3.7206675838545835, "episode": 108.0, "batch_reward": 0.009484017723007127, "critic_loss": 0.005510952668133541, "actor_loss": -26.11750486457348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.82631754875183, "step": 108000}
{"episode_reward": 3.595770079708018, "episode": 109.0, "batch_reward": 0.009609788831556216, "critic_loss": 0.00769619375327602, "actor_loss": -26.399292148411273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.82908320426941, "step": 109000}
{"episode_reward": 3.5219821161231173, "episode": 110.0, "batch_reward": 0.009633272289298474, "critic_loss": 0.0059225518620442015, "actor_loss": -26.141104606345294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.882812023162842, "step": 110000}
{"episode_reward": 3.0224408192120107, "episode": 111.0, "batch_reward": 0.009241445664083586, "critic_loss": 0.0074906581478644515, "actor_loss": -26.005067247986794, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.90385818481445, "step": 111000}
{"episode_reward": 3.4499154060722814, "episode": 112.0, "batch_reward": 0.009492850442882627, "critic_loss": 0.007364550703299755, "actor_loss": -26.667485974505542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.70618176460266, "step": 112000}
{"episode_reward": 2.338105471425729, "episode": 113.0, "batch_reward": 0.009052178386133165, "critic_loss": 0.008129758116148878, "actor_loss": -25.463918781653046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.58946657180786, "step": 113000}
{"episode_reward": 4.94969684436333, "episode": 114.0, "batch_reward": 0.009295869505265727, "critic_loss": 0.007904490823464585, "actor_loss": -26.69880264621973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.953364849090576, "step": 114000}
{"episode_reward": 3.2589757501972896, "episode": 115.0, "batch_reward": 0.009083151982864366, "critic_loss": 0.011837434512774053, "actor_loss": -26.749555287361144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.834378480911255, "step": 115000}
{"episode_reward": 5.268860466651662, "episode": 116.0, "batch_reward": 0.008878956178901717, "critic_loss": 0.00941471208396979, "actor_loss": -26.60610502924025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.175201177597046, "step": 116000}
{"episode_reward": 3.0364595142766824, "episode": 117.0, "batch_reward": 0.008929377833148464, "critic_loss": 0.010054255105256744, "actor_loss": -26.352426629826425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.714861631393433, "step": 117000}
{"episode_reward": 2.40311007475732, "episode": 118.0, "batch_reward": 0.00891072410554625, "critic_loss": 0.0050976829329883915, "actor_loss": -26.2319267064929, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.181758403778076, "step": 118000}
{"episode_reward": 5.814808598385498, "episode": 119.0, "batch_reward": 0.009105517024872825, "critic_loss": 0.010946748246526113, "actor_loss": -26.050381098777056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.502018213272095, "step": 119000}
{"episode_reward": 4.26172337511117, "episode": 120.0, "batch_reward": 0.008815855619963259, "critic_loss": 0.005109945232390601, "actor_loss": -27.246596843808888, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.565608978271484, "step": 120000}
{"episode_reward": 3.921353041716738, "episode": 121.0, "batch_reward": 0.008816193736623972, "critic_loss": 0.009605331283732085, "actor_loss": -26.40600237646699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.56318187713623, "step": 121000}
{"episode_reward": 3.8943517992382457, "episode": 122.0, "batch_reward": 0.00885458213975653, "critic_loss": 0.005729822776964284, "actor_loss": -26.749156520202757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.832321166992188, "step": 122000}
{"episode_reward": 3.504897392281719, "episode": 123.0, "batch_reward": 0.008770150318276137, "critic_loss": 0.004018510744135711, "actor_loss": -26.936337033867837, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.92911672592163, "step": 123000}
{"episode_reward": 3.9172222340713265, "episode": 124.0, "batch_reward": 0.008995510363252834, "critic_loss": 0.006849715874974209, "actor_loss": -26.345122747465968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.931157112121582, "step": 124000}
{"episode_reward": 3.5783058037488313, "episode": 125.0, "batch_reward": 0.008575214706361294, "critic_loss": 0.003715268536412623, "actor_loss": -27.505420986637475, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.027608633041382, "step": 125000}
{"episode_reward": 4.329308415393362, "episode": 126.0, "batch_reward": 0.008487400065176188, "critic_loss": 0.005716235771949869, "actor_loss": -26.939771280393003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.48018455505371, "step": 126000}
{"episode_reward": 3.019291102086987, "episode": 127.0, "batch_reward": 0.008551997345639393, "critic_loss": 0.005440544870150916, "actor_loss": -26.412680949792264, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.519503355026245, "step": 127000}
{"episode_reward": 4.197667848121893, "episode": 128.0, "batch_reward": 0.008596833783201873, "critic_loss": 0.004621851969968702, "actor_loss": -26.54748298431933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.43211030960083, "step": 128000}
{"episode_reward": 2.2518713357065274, "episode": 129.0, "batch_reward": 0.008510338513180614, "critic_loss": 0.004170655080677534, "actor_loss": -26.793110670223832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.637853860855103, "step": 129000}
{"episode_reward": 5.088951334574924, "episode": 130.0, "batch_reward": 0.008663128497777508, "critic_loss": 0.004925650096884056, "actor_loss": -26.100197290867566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.765772819519043, "step": 130000}
{"episode_reward": 4.2258103288896764, "episode": 131.0, "batch_reward": 0.008575659945374355, "critic_loss": 0.004763907735781686, "actor_loss": -24.79865013617277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.13770389556885, "step": 131000}
{"episode_reward": 6.231356428685614, "episode": 132.0, "batch_reward": 0.008708662589080632, "critic_loss": 0.008990524558299512, "actor_loss": -25.324892195120455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.775241374969482, "step": 132000}
{"episode_reward": 4.872995874087999, "episode": 133.0, "batch_reward": 0.008488272044807673, "critic_loss": 0.0038961426133246276, "actor_loss": -26.949747620359062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.79239535331726, "step": 133000}
{"episode_reward": 4.027237864477595, "episode": 134.0, "batch_reward": 0.008479598107049242, "critic_loss": 0.00458657822728128, "actor_loss": -26.726613338828088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.592593669891357, "step": 134000}
{"episode_reward": 3.6488009325054525, "episode": 135.0, "batch_reward": 0.008703103761188685, "critic_loss": 0.005427447585301707, "actor_loss": -27.01381020440161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.424224853515625, "step": 135000}
{"episode_reward": 3.324555759914979, "episode": 136.0, "batch_reward": 0.008390850133029744, "critic_loss": 0.005588023767741106, "actor_loss": -26.911447451725603, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.750256538391113, "step": 136000}
{"episode_reward": 4.566512163077944, "episode": 137.0, "batch_reward": 0.008422606916399672, "critic_loss": 0.006292505874633207, "actor_loss": -26.60842914481461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.89238739013672, "step": 137000}
{"episode_reward": 3.7684112808194996, "episode": 138.0, "batch_reward": 0.008315267256926745, "critic_loss": 0.003056199263846793, "actor_loss": -24.971808097407223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.792840003967285, "step": 138000}
{"episode_reward": 3.35094736975036, "episode": 139.0, "batch_reward": 0.008158180289901793, "critic_loss": 0.0060773380317041305, "actor_loss": -24.781687448486686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.69633722305298, "step": 139000}
{"episode_reward": 5.685692779932022, "episode": 140.0, "batch_reward": 0.008617855250136927, "critic_loss": 0.005366518061418901, "actor_loss": -25.45835510534048, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.024436235427856, "step": 140000}
{"episode_reward": 4.5952877476528995, "episode": 141.0, "batch_reward": 0.008220764664234593, "critic_loss": 0.0055574335639466885, "actor_loss": -25.55988750553131, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.027501344680786, "step": 141000}
{"episode_reward": 3.92753151813074, "episode": 142.0, "batch_reward": 0.008187818011501804, "critic_loss": 0.006496564805464004, "actor_loss": -25.770485397309066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.479326248168945, "step": 142000}
{"episode_reward": 4.863048877319993, "episode": 143.0, "batch_reward": 0.008260011293459683, "critic_loss": 0.004881354933248076, "actor_loss": -27.126076070949434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.946743726730347, "step": 143000}
{"episode_reward": 4.1716999198830775, "episode": 144.0, "batch_reward": 0.008352001223247498, "critic_loss": 0.005746334067756834, "actor_loss": -26.610880396321416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.644046783447266, "step": 144000}
{"episode_reward": 2.978220502342664, "episode": 145.0, "batch_reward": 0.008124013897962868, "critic_loss": 0.00909427528692322, "actor_loss": -28.024270825237036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.320161819458008, "step": 145000}
{"episode_reward": 4.188116627763922, "episode": 146.0, "batch_reward": 0.007879683828214183, "critic_loss": 0.006424701947064022, "actor_loss": -26.01130686329305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.82327675819397, "step": 146000}
{"episode_reward": 3.543546415058945, "episode": 147.0, "batch_reward": 0.008213154424680397, "critic_loss": 0.007203306267867447, "actor_loss": -25.96130184210837, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.975974559783936, "step": 147000}
{"episode_reward": 3.36043824679324, "episode": 148.0, "batch_reward": 0.007954700320027768, "critic_loss": 0.005482473241529078, "actor_loss": -26.3386195627749, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.461589574813843, "step": 148000}
{"episode_reward": 3.322846058550665, "episode": 149.0, "batch_reward": 0.007979311714414508, "critic_loss": 0.0068056892120512205, "actor_loss": -26.156164744958282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.1761953830719, "step": 149000}
{"episode_reward": 3.0723769784517927, "episode": 150.0, "batch_reward": 0.007831234421348199, "critic_loss": 0.0073619660761250994, "actor_loss": -26.266097545444964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
