{"episode_reward": 0.0, "episode": 1.0, "duration": 17.110246896743774, "step": 1000}
{"episode_reward": 5.218604035389536, "episode": 2.0, "duration": 1.4741554260253906, "step": 2000}
{"episode_reward": 548.2612263124905, "episode": 3.0, "batch_reward": 0.29045987124739586, "critic_loss": 0.14946106710496368, "actor_loss": -46.890449733054844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.87468862533569, "step": 3000}
{"episode_reward": 562.8294538157628, "episode": 4.0, "batch_reward": 0.37199581450223923, "critic_loss": 0.2574365663155913, "actor_loss": -52.54311902618408, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.913461446762085, "step": 4000}
{"episode_reward": 473.00210963809013, "episode": 5.0, "batch_reward": 0.40334948229789735, "critic_loss": 0.26443421258032324, "actor_loss": -54.14808905029297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.876513719558716, "step": 5000}
{"episode_reward": 515.4101643391516, "episode": 6.0, "batch_reward": 0.3945972519516945, "critic_loss": 0.3092581908851862, "actor_loss": -52.33895601654053, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88616967201233, "step": 6000}
{"episode_reward": 80.52738179047839, "episode": 7.0, "batch_reward": 0.35572804921865464, "critic_loss": 0.3516186076104641, "actor_loss": -48.82087461090088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.860042810440063, "step": 7000}
{"episode_reward": 364.42869450901946, "episode": 8.0, "batch_reward": 0.3714037498533726, "critic_loss": 0.31800929571688175, "actor_loss": -49.87308505249023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.915226459503174, "step": 8000}
{"episode_reward": 548.9412515600366, "episode": 9.0, "batch_reward": 0.3842980572283268, "critic_loss": 0.3532464749366045, "actor_loss": -50.90457576751709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.921239376068115, "step": 9000}
{"episode_reward": 406.7897648470907, "episode": 10.0, "batch_reward": 0.3929324641227722, "critic_loss": 0.35933574160933496, "actor_loss": -51.433675659179684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.933368921279907, "step": 10000}
{"episode_reward": 530.4630542152377, "episode": 11.0, "batch_reward": 0.40568816661834717, "critic_loss": 0.41806228782236576, "actor_loss": -52.30224263000488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.052987813949585, "step": 11000}
{"episode_reward": 556.5320051888705, "episode": 12.0, "batch_reward": 0.4184607659578323, "critic_loss": 0.49778126725554467, "actor_loss": -53.269367797851565, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.891554355621338, "step": 12000}
{"episode_reward": 535.3404644165443, "episode": 13.0, "batch_reward": 0.41127099418640134, "critic_loss": 0.6251831786036491, "actor_loss": -53.30212461853027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.898756980895996, "step": 13000}
{"episode_reward": 29.688019478694816, "episode": 14.0, "batch_reward": 0.38880219572782515, "critic_loss": 0.5777770881056785, "actor_loss": -52.17245265960693, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.86115264892578, "step": 14000}
{"episode_reward": 347.0861397266068, "episode": 15.0, "batch_reward": 0.39191268318891526, "critic_loss": 0.4867618501186371, "actor_loss": -52.75928202819824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90898299217224, "step": 15000}
{"episode_reward": 484.4918065462362, "episode": 16.0, "batch_reward": 0.39887522011995313, "critic_loss": 0.42353236736357214, "actor_loss": -53.08672212982178, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.908316373825073, "step": 16000}
{"episode_reward": 490.48648953827, "episode": 17.0, "batch_reward": 0.39259416979551315, "critic_loss": 0.4678609558045864, "actor_loss": -52.72579072570801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9027259349823, "step": 17000}
{"episode_reward": 85.79221770733422, "episode": 18.0, "batch_reward": 0.38747603914141654, "critic_loss": 0.4268063544780016, "actor_loss": -52.454222038269045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.915666818618774, "step": 18000}
{"episode_reward": 511.9811648331132, "episode": 19.0, "batch_reward": 0.3895532359480858, "critic_loss": 0.4316315912604332, "actor_loss": -52.594396995544436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.925761938095093, "step": 19000}
{"episode_reward": 400.6703279788908, "episode": 20.0, "batch_reward": 0.39261436358094215, "critic_loss": 0.39868196922540666, "actor_loss": -52.45476167297363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.916509866714478, "step": 20000}
{"episode_reward": 472.93167342864433, "episode": 21.0, "batch_reward": 0.39446653428673745, "critic_loss": 0.373336585983634, "actor_loss": -52.42373917388916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.109984159469604, "step": 21000}
{"episode_reward": 392.169177648734, "episode": 22.0, "batch_reward": 0.3976050226390362, "critic_loss": 0.3703866235464811, "actor_loss": -52.22581435394287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91988492012024, "step": 22000}
{"episode_reward": 540.4005922304308, "episode": 23.0, "batch_reward": 0.40311222195625307, "critic_loss": 0.34233758160471917, "actor_loss": -52.48704372406006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.941921949386597, "step": 23000}
{"episode_reward": 460.434394628062, "episode": 24.0, "batch_reward": 0.4091789634525776, "critic_loss": 0.36952933555841444, "actor_loss": -52.672213821411134, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.895593881607056, "step": 24000}
{"episode_reward": 480.97604842928627, "episode": 25.0, "batch_reward": 0.4098359491825104, "critic_loss": 0.3630437739640474, "actor_loss": -52.01935940551758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.910820484161377, "step": 25000}
{"episode_reward": 554.6478344808082, "episode": 26.0, "batch_reward": 0.41310468235611914, "critic_loss": 0.3525716846585274, "actor_loss": -52.07698944091797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.933104038238525, "step": 26000}
{"episode_reward": 425.4221789041103, "episode": 27.0, "batch_reward": 0.4140247094333172, "critic_loss": 0.33093716964125636, "actor_loss": -52.02330646514893, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.942542552947998, "step": 27000}
{"episode_reward": 507.3140533881878, "episode": 28.0, "batch_reward": 0.4164748666882515, "critic_loss": 0.3638894298970699, "actor_loss": -51.973235244750974, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94733691215515, "step": 28000}
{"episode_reward": 467.1033791458388, "episode": 29.0, "batch_reward": 0.4131307174861431, "critic_loss": 0.3426864486187696, "actor_loss": -51.99820576477051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.949897050857544, "step": 29000}
{"episode_reward": 3.8085222266865637, "episode": 30.0, "batch_reward": 0.3993035796582699, "critic_loss": 0.31309862990677356, "actor_loss": -51.37426206970215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93460988998413, "step": 30000}
{"episode_reward": 4.287719243777038, "episode": 31.0, "batch_reward": 0.3866497879326344, "critic_loss": 0.2903446681648493, "actor_loss": -50.42290619659424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.252981185913086, "step": 31000}
{"episode_reward": 66.57073787905748, "episode": 32.0, "batch_reward": 0.3824997698962688, "critic_loss": 0.275129953622818, "actor_loss": -50.28545928955078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92548704147339, "step": 32000}
{"episode_reward": 499.2965465076018, "episode": 33.0, "batch_reward": 0.37902138364315036, "critic_loss": 0.29272894363105295, "actor_loss": -49.958845512390134, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93858313560486, "step": 33000}
{"episode_reward": 61.80575377028523, "episode": 34.0, "batch_reward": 0.3738032491207123, "critic_loss": 0.32610636089742184, "actor_loss": -49.559366584777834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92370891571045, "step": 34000}
{"episode_reward": 414.85119758303205, "episode": 35.0, "batch_reward": 0.3796226871907711, "critic_loss": 0.3420387096852064, "actor_loss": -50.02238599395752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.929260969161987, "step": 35000}
{"episode_reward": 612.9598350429138, "episode": 36.0, "batch_reward": 0.3846713474392891, "critic_loss": 0.3916597672700882, "actor_loss": -50.52280947113037, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.932709455490112, "step": 36000}
{"episode_reward": 564.4222028906254, "episode": 37.0, "batch_reward": 0.38911966797709463, "critic_loss": 0.4926436786353588, "actor_loss": -50.63386636352539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.924781322479248, "step": 37000}
{"episode_reward": 431.22800721225457, "episode": 38.0, "batch_reward": 0.3915511020421982, "critic_loss": 0.4381052730232477, "actor_loss": -50.36073164367676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92603611946106, "step": 38000}
{"episode_reward": 612.3976181453789, "episode": 39.0, "batch_reward": 0.3972782389819622, "critic_loss": 0.4394737474322319, "actor_loss": -50.43120397949219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.924034357070923, "step": 39000}
{"episode_reward": 615.493440600992, "episode": 40.0, "batch_reward": 0.4014676632285118, "critic_loss": 0.4666019045114517, "actor_loss": -50.20765210723877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.895565271377563, "step": 40000}
{"episode_reward": 580.2817709601211, "episode": 41.0, "batch_reward": 0.40672610005736354, "critic_loss": 0.503099468588829, "actor_loss": -50.348837341308595, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.207916021347046, "step": 41000}
{"episode_reward": 514.0277796613536, "episode": 42.0, "batch_reward": 0.41059039294719696, "critic_loss": 0.49108243472874163, "actor_loss": -50.43051448059082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90329647064209, "step": 42000}
{"episode_reward": 676.6256351209012, "episode": 43.0, "batch_reward": 0.4119789439439774, "critic_loss": 0.54400059966743, "actor_loss": -50.443050300598145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.907793760299683, "step": 43000}
{"episode_reward": 3.5911024294433735, "episode": 44.0, "batch_reward": 0.40016256099939346, "critic_loss": 0.9244835363328456, "actor_loss": -50.01189613342285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90170454978943, "step": 44000}
{"episode_reward": 67.2545488053442, "episode": 45.0, "batch_reward": 0.39509697538614275, "critic_loss": 1.4664762138724328, "actor_loss": -50.38015216827392, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88948917388916, "step": 45000}
{"episode_reward": 179.58160313112114, "episode": 46.0, "batch_reward": 0.39189094987511636, "critic_loss": 1.349774349629879, "actor_loss": -50.921932159423825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.914969444274902, "step": 46000}
{"episode_reward": 175.36873299018646, "episode": 47.0, "batch_reward": 0.38560000786185267, "critic_loss": 1.1892236459255219, "actor_loss": -50.835659690856936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.887704849243164, "step": 47000}
{"episode_reward": 277.9069693502852, "episode": 48.0, "batch_reward": 0.3856784280836582, "critic_loss": 1.0842988392114639, "actor_loss": -51.71831505584717, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.870287895202637, "step": 48000}
{"episode_reward": 289.4933177272122, "episode": 49.0, "batch_reward": 0.3862425780296326, "critic_loss": 1.012418383717537, "actor_loss": -51.7482476348877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8868465423584, "step": 49000}
{"episode_reward": 605.1320375093117, "episode": 50.0, "batch_reward": 0.3870224321782589, "critic_loss": 1.0941793552041055, "actor_loss": -52.14284574127197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88326120376587, "step": 50000}
{"episode_reward": 255.2763709375131, "episode": 51.0, "batch_reward": 0.38500576955080035, "critic_loss": 1.1495721075534822, "actor_loss": -51.940029685974125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.09116291999817, "step": 51000}
{"episode_reward": 148.48969214331044, "episode": 52.0, "batch_reward": 0.380860180169344, "critic_loss": 1.1644453477859498, "actor_loss": -51.472263595581055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.887182474136353, "step": 52000}
{"episode_reward": 431.5742505663606, "episode": 53.0, "batch_reward": 0.3820758416354656, "critic_loss": 1.1201190479397773, "actor_loss": -51.35283807373047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.947615385055542, "step": 53000}
{"episode_reward": 555.6889645589479, "episode": 54.0, "batch_reward": 0.38397684586048125, "critic_loss": 1.0294716656804084, "actor_loss": -51.455071899414065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9388587474823, "step": 54000}
{"episode_reward": 486.36265461985397, "episode": 55.0, "batch_reward": 0.38733748799562456, "critic_loss": 0.9179528128504754, "actor_loss": -51.65383351898193, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92734980583191, "step": 55000}
{"episode_reward": 470.6164471131573, "episode": 56.0, "batch_reward": 0.38907407847046854, "critic_loss": 0.8050307096838951, "actor_loss": -51.377904289245606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.848216772079468, "step": 56000}
{"episode_reward": 586.0663937849446, "episode": 57.0, "batch_reward": 0.39171999672055247, "critic_loss": 0.7571301597654819, "actor_loss": -51.48695482635498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88727569580078, "step": 57000}
{"episode_reward": 522.59129408763, "episode": 58.0, "batch_reward": 0.3961323770582676, "critic_loss": 0.7311043062508106, "actor_loss": -51.47966748046875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91888189315796, "step": 58000}
{"episode_reward": 583.8132857941811, "episode": 59.0, "batch_reward": 0.39985290679335594, "critic_loss": 0.7351715536415577, "actor_loss": -51.702474235534666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92414426803589, "step": 59000}
{"episode_reward": 641.992097868166, "episode": 60.0, "batch_reward": 0.4019903175830841, "critic_loss": 0.7215488541722298, "actor_loss": -51.82103790283203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92473793029785, "step": 60000}
{"episode_reward": 593.2642146358457, "episode": 61.0, "batch_reward": 0.40550028827786444, "critic_loss": 0.6957998329401016, "actor_loss": -52.03274151611328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.1224319934845, "step": 61000}
{"episode_reward": 621.3889039782855, "episode": 62.0, "batch_reward": 0.4099678574204445, "critic_loss": 0.661116706609726, "actor_loss": -52.179868827819824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.922794342041016, "step": 62000}
{"episode_reward": 645.6783725606431, "episode": 63.0, "batch_reward": 0.41422850608825684, "critic_loss": 0.6152903931438923, "actor_loss": -52.39039252471924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.940897703170776, "step": 63000}
{"episode_reward": 631.8639975627539, "episode": 64.0, "batch_reward": 0.4168441452383995, "critic_loss": 0.5731024564504623, "actor_loss": -52.281735290527344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.951966047286987, "step": 64000}
{"episode_reward": 531.624386209461, "episode": 65.0, "batch_reward": 0.4195162626206875, "critic_loss": 0.5347486305832863, "actor_loss": -52.42557379150391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8866446018219, "step": 65000}
{"episode_reward": 629.4278209650483, "episode": 66.0, "batch_reward": 0.4218291957080364, "critic_loss": 0.5235140851885081, "actor_loss": -52.342914772033694, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.954967737197876, "step": 66000}
{"episode_reward": 635.149162455475, "episode": 67.0, "batch_reward": 0.4249771821498871, "critic_loss": 0.4996300645172596, "actor_loss": -52.491626876831056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.955249786376953, "step": 67000}
{"episode_reward": 639.7803648598649, "episode": 68.0, "batch_reward": 0.4292107717990875, "critic_loss": 0.48336058054864406, "actor_loss": -52.66287861633301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.946545839309692, "step": 68000}
{"episode_reward": 671.3226897021935, "episode": 69.0, "batch_reward": 0.43438749527931214, "critic_loss": 0.48429801598191263, "actor_loss": -53.219122123718265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.938056230545044, "step": 69000}
{"episode_reward": 660.1469653304682, "episode": 70.0, "batch_reward": 0.43386319440603255, "critic_loss": 0.471817449182272, "actor_loss": -53.36034039306641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.932810306549072, "step": 70000}
{"episode_reward": 651.0295761721496, "episode": 71.0, "batch_reward": 0.43781822502613066, "critic_loss": 0.41144643941521647, "actor_loss": -53.38385664367676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.13703155517578, "step": 71000}
{"episode_reward": 433.66858327634606, "episode": 72.0, "batch_reward": 0.43533629867434503, "critic_loss": 0.4038764950484037, "actor_loss": -53.02387398529053, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.952200412750244, "step": 72000}
{"episode_reward": 481.52378215233455, "episode": 73.0, "batch_reward": 0.43469220700860023, "critic_loss": 0.38408552898466586, "actor_loss": -52.819366477966305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96049475669861, "step": 73000}
{"episode_reward": 6.266880534784255, "episode": 74.0, "batch_reward": 0.4310722171664238, "critic_loss": 0.3606783631443977, "actor_loss": -52.45058608245849, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96236777305603, "step": 74000}
{"episode_reward": 415.27785476637587, "episode": 75.0, "batch_reward": 0.4340910460650921, "critic_loss": 0.3650243953168392, "actor_loss": -52.36675105285644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.906418561935425, "step": 75000}
{"episode_reward": 623.427201162152, "episode": 76.0, "batch_reward": 0.4354121518731117, "critic_loss": 0.37476867055892943, "actor_loss": -52.42033521270752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.889273405075073, "step": 76000}
{"episode_reward": 597.5697085401565, "episode": 77.0, "batch_reward": 0.43623087149858475, "critic_loss": 0.3806464629024267, "actor_loss": -52.39252435302734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89361834526062, "step": 77000}
{"episode_reward": 630.8145500137616, "episode": 78.0, "batch_reward": 0.4393484382927418, "critic_loss": 0.350670927003026, "actor_loss": -52.46945516967774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89514994621277, "step": 78000}
{"episode_reward": 666.4199507820829, "episode": 79.0, "batch_reward": 0.44361493790149686, "critic_loss": 0.3426512697339058, "actor_loss": -52.762968383789065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.887978076934814, "step": 79000}
{"episode_reward": 648.2861514000506, "episode": 80.0, "batch_reward": 0.44601389282941817, "critic_loss": 0.3340386120378971, "actor_loss": -52.87743196105957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.255738973617554, "step": 80000}
{"episode_reward": 679.2125952239682, "episode": 81.0, "batch_reward": 0.4492313623130321, "critic_loss": 0.33047008533775807, "actor_loss": -52.87312641906738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.072426080703735, "step": 81000}
{"episode_reward": 676.9551977135412, "episode": 82.0, "batch_reward": 0.44997269052267075, "critic_loss": 0.32986580853164194, "actor_loss": -52.915163673400876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.895326375961304, "step": 82000}
{"episode_reward": 659.1777543869848, "episode": 83.0, "batch_reward": 0.4533665128648281, "critic_loss": 0.36702029016613963, "actor_loss": -53.00865738677979, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.914177179336548, "step": 83000}
{"episode_reward": 473.51474983608875, "episode": 84.0, "batch_reward": 0.4550250822305679, "critic_loss": 0.37593224535882475, "actor_loss": -53.045316772460936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0881028175354, "step": 84000}
{"episode_reward": 631.5370405305954, "episode": 85.0, "batch_reward": 0.45564405500888827, "critic_loss": 0.3832920825779438, "actor_loss": -52.91895335388183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002655029296875, "step": 85000}
{"episode_reward": 688.8819536248939, "episode": 86.0, "batch_reward": 0.4594762359559536, "critic_loss": 0.3437589146792889, "actor_loss": -53.17120599365234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.860397577285767, "step": 86000}
{"episode_reward": 676.1732017615503, "episode": 87.0, "batch_reward": 0.4621442717313766, "critic_loss": 0.33663329982757567, "actor_loss": -53.227842582702635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.874253034591675, "step": 87000}
{"episode_reward": 689.123771134015, "episode": 88.0, "batch_reward": 0.46359455394744875, "critic_loss": 0.3532567554414272, "actor_loss": -53.31988581085205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.896093130111694, "step": 88000}
{"episode_reward": 713.6210263936568, "episode": 89.0, "batch_reward": 0.4674351093173027, "critic_loss": 0.33488884453475476, "actor_loss": -53.45687078857422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91573214530945, "step": 89000}
{"episode_reward": 685.9065928911509, "episode": 90.0, "batch_reward": 0.47013011810183525, "critic_loss": 0.32858491577208043, "actor_loss": -53.52226427459717, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.913114547729492, "step": 90000}
{"episode_reward": 693.5650550884754, "episode": 91.0, "batch_reward": 0.4715166408121586, "critic_loss": 0.31083831053972244, "actor_loss": -53.692438758850095, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.17404294013977, "step": 91000}
{"episode_reward": 685.1930807338948, "episode": 92.0, "batch_reward": 0.471954393774271, "critic_loss": 0.307630362868309, "actor_loss": -53.703540733337405, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.937947511672974, "step": 92000}
{"episode_reward": 670.5948330968496, "episode": 93.0, "batch_reward": 0.47552517205476763, "critic_loss": 0.3423944755941629, "actor_loss": -53.93123664855957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94957995414734, "step": 93000}
{"episode_reward": 536.2563784886598, "episode": 94.0, "batch_reward": 0.4776103009581566, "critic_loss": 0.3271920723319054, "actor_loss": -53.982550987243656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94996666908264, "step": 94000}
{"episode_reward": 688.6707823022016, "episode": 95.0, "batch_reward": 0.47964588966965677, "critic_loss": 0.3109664842039347, "actor_loss": -54.09084553527832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.937745571136475, "step": 95000}
{"episode_reward": 658.8514542541021, "episode": 96.0, "batch_reward": 0.48159299984574316, "critic_loss": 0.29860250978171826, "actor_loss": -54.13162674713135, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92953848838806, "step": 96000}
{"episode_reward": 629.1258959402048, "episode": 97.0, "batch_reward": 0.48366137620806693, "critic_loss": 0.28294674265384673, "actor_loss": -54.25673651123047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.904017686843872, "step": 97000}
{"episode_reward": 685.9109991237888, "episode": 98.0, "batch_reward": 0.48505057945847513, "critic_loss": 0.2737912322729826, "actor_loss": -54.26813916015625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9230535030365, "step": 98000}
{"episode_reward": 688.7504052355599, "episode": 99.0, "batch_reward": 0.48761433038115504, "critic_loss": 0.2722833202928305, "actor_loss": -54.44467456817627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.947906494140625, "step": 99000}
{"episode_reward": 699.4152794274587, "episode": 100.0, "batch_reward": 0.48870165094733237, "critic_loss": 0.27145778043568136, "actor_loss": -54.60648433685303, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.925004243850708, "step": 100000}
{"episode_reward": 651.0456384915756, "episode": 101.0, "batch_reward": 0.4894661976993084, "critic_loss": 0.2884525437504053, "actor_loss": -54.60949169921875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.02988290786743, "step": 101000}
{"episode_reward": 659.2333995869534, "episode": 102.0, "batch_reward": 0.49230039009451865, "critic_loss": 0.28212420992553233, "actor_loss": -54.67910331726074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.890316009521484, "step": 102000}
{"episode_reward": 684.8616378407555, "episode": 103.0, "batch_reward": 0.49452031230926513, "critic_loss": 0.29627222026884553, "actor_loss": -54.91765626525879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.881431341171265, "step": 103000}
{"episode_reward": 701.0285596499715, "episode": 104.0, "batch_reward": 0.49650849747657777, "critic_loss": 0.300716749638319, "actor_loss": -54.828758422851564, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89836359024048, "step": 104000}
{"episode_reward": 678.1073617275752, "episode": 105.0, "batch_reward": 0.49716779944300654, "critic_loss": 0.292889154791832, "actor_loss": -55.060294555664065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93022346496582, "step": 105000}
{"episode_reward": 705.3811094948755, "episode": 106.0, "batch_reward": 0.4998409789502621, "critic_loss": 0.30494191965460776, "actor_loss": -55.3185976486206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.907188653945923, "step": 106000}
{"episode_reward": 694.1341249475389, "episode": 107.0, "batch_reward": 0.5020661543905734, "critic_loss": 0.2912310520857573, "actor_loss": -55.39384194946289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.910527229309082, "step": 107000}
{"episode_reward": 697.5392695400536, "episode": 108.0, "batch_reward": 0.5035213917195797, "critic_loss": 0.29766352808475494, "actor_loss": -55.439565246582035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90780544281006, "step": 108000}
{"episode_reward": 738.3864161518194, "episode": 109.0, "batch_reward": 0.5057288359701634, "critic_loss": 0.2932709909230471, "actor_loss": -55.57418850708008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.909753799438477, "step": 109000}
{"episode_reward": 610.8026557782521, "episode": 110.0, "batch_reward": 0.5055892050862313, "critic_loss": 0.2871080854386091, "actor_loss": -55.61331886291504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.892932653427124, "step": 110000}
{"episode_reward": 680.8701736505012, "episode": 111.0, "batch_reward": 0.506392024576664, "critic_loss": 0.295160320520401, "actor_loss": -55.63305243682861, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.05168008804321, "step": 111000}
{"episode_reward": 365.93771308820845, "episode": 112.0, "batch_reward": 0.5066956694424153, "critic_loss": 0.3053467449992895, "actor_loss": -55.70128225708008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.858585357666016, "step": 112000}
{"episode_reward": 681.8775945245942, "episode": 113.0, "batch_reward": 0.5082355797886848, "critic_loss": 0.29389384062588214, "actor_loss": -55.63348512268066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8440682888031, "step": 113000}
{"episode_reward": 648.4783673870461, "episode": 114.0, "batch_reward": 0.510336910367012, "critic_loss": 0.30311912136524916, "actor_loss": -55.771148040771486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.892931938171387, "step": 114000}
{"episode_reward": 698.5898876527875, "episode": 115.0, "batch_reward": 0.5105474496781826, "critic_loss": 0.2955035759881139, "actor_loss": -55.83719783782959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.856680631637573, "step": 115000}
{"episode_reward": 710.2906507551363, "episode": 116.0, "batch_reward": 0.5115484477877617, "critic_loss": 0.3092980160117149, "actor_loss": -55.755962425231935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.878222942352295, "step": 116000}
{"episode_reward": 702.0855654259758, "episode": 117.0, "batch_reward": 0.5140246942937374, "critic_loss": 0.2866641469150782, "actor_loss": -56.06577768707275, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.855140686035156, "step": 117000}
{"episode_reward": 699.434147812995, "episode": 118.0, "batch_reward": 0.5164908702373505, "critic_loss": 0.28936622002720835, "actor_loss": -56.18849802398682, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.856000661849976, "step": 118000}
{"episode_reward": 703.4319101965744, "episode": 119.0, "batch_reward": 0.5187299237549305, "critic_loss": 0.28300943814218044, "actor_loss": -56.35848752593994, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.864665269851685, "step": 119000}
{"episode_reward": 710.7316454633966, "episode": 120.0, "batch_reward": 0.5193843358755111, "critic_loss": 0.27751190690696237, "actor_loss": -56.47850074768066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.897768020629883, "step": 120000}
{"episode_reward": 707.4337059393065, "episode": 121.0, "batch_reward": 0.5220649075806141, "critic_loss": 0.2790933275669813, "actor_loss": -56.592650184631346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.09560799598694, "step": 121000}
{"episode_reward": 683.1452738429657, "episode": 122.0, "batch_reward": 0.5240282907187939, "critic_loss": 0.2742351578623056, "actor_loss": -56.67294507598877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.907386302947998, "step": 122000}
{"episode_reward": 687.8871002969388, "episode": 123.0, "batch_reward": 0.5229515915811062, "critic_loss": 0.277313552044332, "actor_loss": -56.66570351409912, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.897225856781006, "step": 123000}
{"episode_reward": 682.5556225340338, "episode": 124.0, "batch_reward": 0.5249496219158173, "critic_loss": 0.27229330433160065, "actor_loss": -56.7310905380249, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.893248319625854, "step": 124000}
{"episode_reward": 697.0013197442654, "episode": 125.0, "batch_reward": 0.5267964331209659, "critic_loss": 0.2810629945248365, "actor_loss": -56.92621804046631, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88373613357544, "step": 125000}
{"episode_reward": 698.6462330059811, "episode": 126.0, "batch_reward": 0.5274445471465588, "critic_loss": 0.2647372078448534, "actor_loss": -57.05719423675537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.869770765304565, "step": 126000}
{"episode_reward": 713.1623888078166, "episode": 127.0, "batch_reward": 0.5283216584324837, "critic_loss": 0.2641685486137867, "actor_loss": -57.103760787963864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89753794670105, "step": 127000}
{"episode_reward": 707.260861957058, "episode": 128.0, "batch_reward": 0.5302497062981129, "critic_loss": 0.26688636844605207, "actor_loss": -57.2736016998291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.874330520629883, "step": 128000}
{"episode_reward": 713.1253963442877, "episode": 129.0, "batch_reward": 0.5321766787469387, "critic_loss": 0.261609432592988, "actor_loss": -57.2834153213501, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.86837911605835, "step": 129000}
{"episode_reward": 710.0871354836179, "episode": 130.0, "batch_reward": 0.5334823635816575, "critic_loss": 0.27814753202348946, "actor_loss": -57.45746391296387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.889474391937256, "step": 130000}
{"episode_reward": 649.1319637613655, "episode": 131.0, "batch_reward": 0.5346874229013919, "critic_loss": 0.2618935130238533, "actor_loss": -57.5252329864502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.103005170822144, "step": 131000}
{"episode_reward": 685.6446040841168, "episode": 132.0, "batch_reward": 0.5350774540305138, "critic_loss": 0.27018504796922205, "actor_loss": -57.5866561126709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9249050617218, "step": 132000}
{"episode_reward": 715.301495301231, "episode": 133.0, "batch_reward": 0.535642695337534, "critic_loss": 0.2659889458939433, "actor_loss": -57.71174223327637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94189429283142, "step": 133000}
{"episode_reward": 675.8733456297788, "episode": 134.0, "batch_reward": 0.5360233454108239, "critic_loss": 0.26179103447496893, "actor_loss": -57.675690643310546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91911816596985, "step": 134000}
{"episode_reward": 672.143165783795, "episode": 135.0, "batch_reward": 0.5390816471874714, "critic_loss": 0.27206538020819426, "actor_loss": -57.916654373168946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.87388515472412, "step": 135000}
{"episode_reward": 702.8670942159431, "episode": 136.0, "batch_reward": 0.5401418642103673, "critic_loss": 0.2726812963187695, "actor_loss": -57.955125831604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.880319833755493, "step": 136000}
{"episode_reward": 686.0032118537703, "episode": 137.0, "batch_reward": 0.5401452492475509, "critic_loss": 0.2625230211168528, "actor_loss": -57.92018342590332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88214683532715, "step": 137000}
{"episode_reward": 722.0069677273463, "episode": 138.0, "batch_reward": 0.5427918306291103, "critic_loss": 0.26617457934468985, "actor_loss": -58.06539887237549, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94193458557129, "step": 138000}
{"episode_reward": 733.2861428994346, "episode": 139.0, "batch_reward": 0.5438688045144081, "critic_loss": 0.2637010039538145, "actor_loss": -58.22949490356445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.923640251159668, "step": 139000}
{"episode_reward": 683.7552334042364, "episode": 140.0, "batch_reward": 0.544846855521202, "critic_loss": 0.25064237716048954, "actor_loss": -58.36617945861816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.917514324188232, "step": 140000}
{"episode_reward": 693.3691273515373, "episode": 141.0, "batch_reward": 0.5456734321117401, "critic_loss": 0.2501237828359008, "actor_loss": -58.445467681884764, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.10506200790405, "step": 141000}
{"episode_reward": 693.7990055899513, "episode": 142.0, "batch_reward": 0.5466475656330585, "critic_loss": 0.2443153886348009, "actor_loss": -58.448240776062015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.939772367477417, "step": 142000}
{"episode_reward": 709.7791685344865, "episode": 143.0, "batch_reward": 0.5478497412502765, "critic_loss": 0.2516653945893049, "actor_loss": -58.63845850372314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92513370513916, "step": 143000}
{"episode_reward": 734.4253223717317, "episode": 144.0, "batch_reward": 0.5492299658358097, "critic_loss": 0.2586341449096799, "actor_loss": -58.70675415039062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.940842628479004, "step": 144000}
{"episode_reward": 731.2911223093391, "episode": 145.0, "batch_reward": 0.5506220379173755, "critic_loss": 0.23861095494031906, "actor_loss": -58.782769653320315, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.944204092025757, "step": 145000}
{"episode_reward": 701.089109751773, "episode": 146.0, "batch_reward": 0.5514343194663525, "critic_loss": 0.2573744993582368, "actor_loss": -58.848960105896, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94884419441223, "step": 146000}
{"episode_reward": 715.1616105051058, "episode": 147.0, "batch_reward": 0.55327375587821, "critic_loss": 0.2531418830752373, "actor_loss": -58.917894989013675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95686984062195, "step": 147000}
{"episode_reward": 725.2077077646209, "episode": 148.0, "batch_reward": 0.5534292955100536, "critic_loss": 0.2477890224456787, "actor_loss": -59.06110507202148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.922333240509033, "step": 148000}
{"episode_reward": 747.6891854663254, "episode": 149.0, "batch_reward": 0.5548926710486412, "critic_loss": 0.2571432256028056, "actor_loss": -59.19387590789795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91854953765869, "step": 149000}
{"episode_reward": 704.4560413474474, "episode": 150.0, "batch_reward": 0.5562967483997345, "critic_loss": 0.25934585504978896, "actor_loss": -59.30658194732666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
