{"episode_reward": 0.0, "episode": 1.0, "duration": 21.625839710235596, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.8916141986846924, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.2792237253934791, "critic_loss": 0.19320372927209742, "actor_loss": -49.71281445471003, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 62.99606418609619, "step": 3000}
{"episode_reward": 177.46805857220807, "episode": 4.0, "batch_reward": 0.23152969314157962, "critic_loss": 0.40731809148192405, "actor_loss": -48.22727422714233, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.820087909698486, "step": 4000}
{"episode_reward": 131.02682045707633, "episode": 5.0, "batch_reward": 0.24204743775725365, "critic_loss": 0.614742058902979, "actor_loss": -47.86321074962616, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.588489294052124, "step": 5000}
{"episode_reward": 428.6742326439955, "episode": 6.0, "batch_reward": 0.2951301943063736, "critic_loss": 0.7179236367940903, "actor_loss": -49.081459309577944, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.952572107315063, "step": 6000}
{"episode_reward": 654.530209205235, "episode": 7.0, "batch_reward": 0.34683009347319604, "critic_loss": 0.7744170500338078, "actor_loss": -49.97349269962311, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.552939653396606, "step": 7000}
{"episode_reward": 552.8849099221881, "episode": 8.0, "batch_reward": 0.3715301757454872, "critic_loss": 0.951226655125618, "actor_loss": -53.91056597328186, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.571846961975098, "step": 8000}
{"episode_reward": 641.6249673490288, "episode": 9.0, "batch_reward": 0.4062476160824299, "critic_loss": 1.1846747568249703, "actor_loss": -53.08739636039734, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.825722455978394, "step": 9000}
{"episode_reward": 581.7264449632913, "episode": 10.0, "batch_reward": 0.4301012555062771, "critic_loss": 1.4031914973855018, "actor_loss": -54.12870777130127, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.73099374771118, "step": 10000}
{"episode_reward": 694.4695799243832, "episode": 11.0, "batch_reward": 0.45690107280015946, "critic_loss": 1.528167683660984, "actor_loss": -55.669753786087036, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.294482946395874, "step": 11000}
{"episode_reward": 675.8419677503165, "episode": 12.0, "batch_reward": 0.47788125467300413, "critic_loss": 1.6821520337462426, "actor_loss": -56.71437673568725, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.03562045097351, "step": 12000}
{"episode_reward": 784.9640446019105, "episode": 13.0, "batch_reward": 0.4958187862932682, "critic_loss": 1.8590432002544404, "actor_loss": -58.25194276046753, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.44278359413147, "step": 13000}
{"episode_reward": 685.9050354674313, "episode": 14.0, "batch_reward": 0.5181748411059379, "critic_loss": 2.073077664256096, "actor_loss": -58.91867264175415, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.60095977783203, "step": 14000}
{"episode_reward": 878.8516590356809, "episode": 15.0, "batch_reward": 0.5400015141069889, "critic_loss": 2.065515035152435, "actor_loss": -57.400031108856204, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.520562648773193, "step": 15000}
{"episode_reward": 828.2752064920517, "episode": 16.0, "batch_reward": 0.5625715118348599, "critic_loss": 1.9200860891342164, "actor_loss": -62.76615600967407, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.900315046310425, "step": 16000}
{"episode_reward": 911.3847419072766, "episode": 17.0, "batch_reward": 0.5810461346209049, "critic_loss": 2.0324564896821977, "actor_loss": -62.860688304901124, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.806960821151733, "step": 17000}
{"episode_reward": 838.0603461320835, "episode": 18.0, "batch_reward": 0.5912299789488316, "critic_loss": 1.9804467508792878, "actor_loss": -64.00479091262818, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.453420877456665, "step": 18000}
{"episode_reward": 712.776114649752, "episode": 19.0, "batch_reward": 0.6005326119065285, "critic_loss": 1.9620097093582154, "actor_loss": -65.21613202667237, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.223807334899902, "step": 19000}
{"episode_reward": 768.0362375100281, "episode": 20.0, "batch_reward": 0.6069886800050736, "critic_loss": 2.017582925081253, "actor_loss": -63.852691116333006, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.71049165725708, "step": 20000}
{"episode_reward": 702.9488776485723, "episode": 21.0, "batch_reward": 0.6151292024254799, "critic_loss": 2.0072707626223565, "actor_loss": -65.22378659057617, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.00452208518982, "step": 21000}
{"episode_reward": 661.5352332616544, "episode": 22.0, "batch_reward": 0.6198433762788773, "critic_loss": 2.043126710176468, "actor_loss": -65.61813061523438, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.340923309326172, "step": 22000}
{"episode_reward": 890.038842354135, "episode": 23.0, "batch_reward": 0.6272432343363762, "critic_loss": 2.1148608312606814, "actor_loss": -66.69805416870118, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.40857481956482, "step": 23000}
{"episode_reward": 774.3427364532449, "episode": 24.0, "batch_reward": 0.6365277079939842, "critic_loss": 2.1452632095813753, "actor_loss": -67.89135104370118, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.818713665008545, "step": 24000}
{"episode_reward": 947.1425153143056, "episode": 25.0, "batch_reward": 0.6475479980707168, "critic_loss": 2.1967935594320296, "actor_loss": -67.8967474746704, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.84281635284424, "step": 25000}
{"episode_reward": 836.8805446362911, "episode": 26.0, "batch_reward": 0.656242340683937, "critic_loss": 2.0767129633426666, "actor_loss": -68.50237181091309, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.69974994659424, "step": 26000}
{"episode_reward": 931.3557622644917, "episode": 27.0, "batch_reward": 0.6686001741290093, "critic_loss": 2.1505988134145735, "actor_loss": -68.65416860961913, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.861478328704834, "step": 27000}
{"episode_reward": 942.7723741734521, "episode": 28.0, "batch_reward": 0.6759979612827302, "critic_loss": 2.108204496741295, "actor_loss": -70.14701742553711, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.754430770874023, "step": 28000}
{"episode_reward": 888.0516377471981, "episode": 29.0, "batch_reward": 0.685058171570301, "critic_loss": 2.0683910253047944, "actor_loss": -69.90602147674561, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.220482110977173, "step": 29000}
{"episode_reward": 921.1742382523018, "episode": 30.0, "batch_reward": 0.6899862346053124, "critic_loss": 1.9917214970588684, "actor_loss": -70.4527138595581, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.008394241333008, "step": 30000}
{"episode_reward": 877.5763290211181, "episode": 31.0, "batch_reward": 0.6976382566690444, "critic_loss": 1.8905628781318664, "actor_loss": -71.70400480651855, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.12645077705383, "step": 31000}
{"episode_reward": 890.1069108684857, "episode": 32.0, "batch_reward": 0.7039781638979912, "critic_loss": 1.9625743672847749, "actor_loss": -71.86261582946777, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.39220952987671, "step": 32000}
{"episode_reward": 827.1917198804202, "episode": 33.0, "batch_reward": 0.7057512558102608, "critic_loss": 1.9826393996477127, "actor_loss": -71.76407857513428, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.34864902496338, "step": 33000}
{"episode_reward": 746.6965840601831, "episode": 34.0, "batch_reward": 0.7054296205043793, "critic_loss": 2.073586783885956, "actor_loss": -72.90790383148193, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.402323722839355, "step": 34000}
{"episode_reward": 772.4939375637085, "episode": 35.0, "batch_reward": 0.7104350197911262, "critic_loss": 2.0441928969621657, "actor_loss": -72.51942735290527, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.901915311813354, "step": 35000}
{"episode_reward": 867.1529274354506, "episode": 36.0, "batch_reward": 0.7172773138880729, "critic_loss": 2.2789045329093933, "actor_loss": -74.04744897460938, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.61699104309082, "step": 36000}
{"episode_reward": 878.6079690469002, "episode": 37.0, "batch_reward": 0.7179698371291161, "critic_loss": 2.2634163957834246, "actor_loss": -73.71930352783203, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.652823448181152, "step": 37000}
{"episode_reward": 634.9018699551158, "episode": 38.0, "batch_reward": 0.7197239614725113, "critic_loss": 2.4465573024749756, "actor_loss": -73.2611414718628, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.89408278465271, "step": 38000}
{"episode_reward": 952.9363888904633, "episode": 39.0, "batch_reward": 0.7249810101389885, "critic_loss": 2.201698515415192, "actor_loss": -74.39100922393798, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.803953409194946, "step": 39000}
{"episode_reward": 929.6932471726957, "episode": 40.0, "batch_reward": 0.7283788058161735, "critic_loss": 2.2955796868801115, "actor_loss": -74.684251663208, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.53302001953125, "step": 40000}
{"episode_reward": 913.6936440381369, "episode": 41.0, "batch_reward": 0.7331548389792443, "critic_loss": 2.1253214057683945, "actor_loss": -75.42398650360107, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.75719118118286, "step": 41000}
{"episode_reward": 911.776966843499, "episode": 42.0, "batch_reward": 0.7353749196529389, "critic_loss": 2.0922267507314682, "actor_loss": -74.98961451721192, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.715123653411865, "step": 42000}
{"episode_reward": 846.5575551606427, "episode": 43.0, "batch_reward": 0.741202883720398, "critic_loss": 2.107839476943016, "actor_loss": -75.76690702819825, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.49848985671997, "step": 43000}
{"episode_reward": 890.0191945849352, "episode": 44.0, "batch_reward": 0.7453009692430497, "critic_loss": 2.1612398912906645, "actor_loss": -75.55329051971435, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.39513921737671, "step": 44000}
{"episode_reward": 906.3161899989519, "episode": 45.0, "batch_reward": 0.7485187860131264, "critic_loss": 2.135021595954895, "actor_loss": -75.6810803604126, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.38348078727722, "step": 45000}
{"episode_reward": 951.5616942497119, "episode": 46.0, "batch_reward": 0.7545014494657516, "critic_loss": 1.9937367967367172, "actor_loss": -76.43342842102051, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.448359727859497, "step": 46000}
{"episode_reward": 956.1437932248131, "episode": 47.0, "batch_reward": 0.7574655184745789, "critic_loss": 1.9011612334251404, "actor_loss": -76.7929023361206, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.586153745651245, "step": 47000}
{"episode_reward": 902.6919126370104, "episode": 48.0, "batch_reward": 0.7607272919416428, "critic_loss": 1.8813473302721977, "actor_loss": -76.93876309204101, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.45750403404236, "step": 48000}
{"episode_reward": 913.170485995127, "episode": 49.0, "batch_reward": 0.7637926689386367, "critic_loss": 1.8921471226215363, "actor_loss": -77.20916165161132, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.253209114074707, "step": 49000}
{"episode_reward": 843.7860133315737, "episode": 50.0, "batch_reward": 0.7648501934409142, "critic_loss": 1.9359144626259803, "actor_loss": -76.95366989135742, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.47650694847107, "step": 50000}
{"episode_reward": 828.4844210410326, "episode": 51.0, "batch_reward": 0.767533469080925, "critic_loss": 1.886847186267376, "actor_loss": -77.46297338867187, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.68794226646423, "step": 51000}
{"episode_reward": 937.9602416136601, "episode": 52.0, "batch_reward": 0.7681431109905243, "critic_loss": 1.7993975169062615, "actor_loss": -77.75651371765137, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.391247749328613, "step": 52000}
{"episode_reward": 867.4057616506781, "episode": 53.0, "batch_reward": 0.7709779615998268, "critic_loss": 1.8041875030994414, "actor_loss": -77.21401582336426, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.364046096801758, "step": 53000}
{"episode_reward": 914.5699361783171, "episode": 54.0, "batch_reward": 0.7734634810686112, "critic_loss": 1.7866328395009041, "actor_loss": -78.57907673645019, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.282599449157715, "step": 54000}
{"episode_reward": 938.4610666518978, "episode": 55.0, "batch_reward": 0.7767994393110276, "critic_loss": 1.7435396836996078, "actor_loss": -78.41546310424805, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.510879278182983, "step": 55000}
{"episode_reward": 938.5391687405303, "episode": 56.0, "batch_reward": 0.7789648010134697, "critic_loss": 1.7889271398186684, "actor_loss": -78.0678009185791, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.365936279296875, "step": 56000}
{"episode_reward": 858.4819371742493, "episode": 57.0, "batch_reward": 0.7810847806334495, "critic_loss": 1.6646795164346695, "actor_loss": -78.6481794128418, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.75704574584961, "step": 57000}
{"episode_reward": 890.1559905065676, "episode": 58.0, "batch_reward": 0.7811354956626892, "critic_loss": 1.6518067294359207, "actor_loss": -78.66335455322266, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.826476573944092, "step": 58000}
{"episode_reward": 806.9464001006602, "episode": 59.0, "batch_reward": 0.7849454866051674, "critic_loss": 1.6092700679302216, "actor_loss": -79.01200788879395, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.69117546081543, "step": 59000}
{"episode_reward": 927.1846590969734, "episode": 60.0, "batch_reward": 0.786734511256218, "critic_loss": 1.62978889387846, "actor_loss": -78.81523822021484, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.61292338371277, "step": 60000}
{"episode_reward": 881.1566860067933, "episode": 61.0, "batch_reward": 0.7874968822598457, "critic_loss": 1.6521507318615913, "actor_loss": -79.23786897277832, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.631006479263306, "step": 61000}
{"episode_reward": 854.4402253154216, "episode": 62.0, "batch_reward": 0.7877985342144966, "critic_loss": 1.6128535732030869, "actor_loss": -78.88306871032715, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.840595483779907, "step": 62000}
{"episode_reward": 943.8709292732381, "episode": 63.0, "batch_reward": 0.7902686988711357, "critic_loss": 1.562253135740757, "actor_loss": -79.20241101074218, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.408043146133423, "step": 63000}
{"episode_reward": 943.1490092476424, "episode": 64.0, "batch_reward": 0.7948776739239692, "critic_loss": 1.5724315238595008, "actor_loss": -79.51921900939941, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.46491050720215, "step": 64000}
{"episode_reward": 925.5451148652986, "episode": 65.0, "batch_reward": 0.7940764794945717, "critic_loss": 1.6332668640613557, "actor_loss": -79.27413928222656, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.261791467666626, "step": 65000}
{"episode_reward": 880.5815008402783, "episode": 66.0, "batch_reward": 0.795597307741642, "critic_loss": 1.5828315683603287, "actor_loss": -79.51101354980469, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.044291257858276, "step": 66000}
{"episode_reward": 925.8826941841, "episode": 67.0, "batch_reward": 0.8001092029213905, "critic_loss": 1.5693635685443879, "actor_loss": -79.53710398864746, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.514897108078003, "step": 67000}
{"episode_reward": 894.3397344194088, "episode": 68.0, "batch_reward": 0.8012179323434829, "critic_loss": 1.5479286192059516, "actor_loss": -80.07709364318848, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.76554560661316, "step": 68000}
{"episode_reward": 924.6695319200337, "episode": 69.0, "batch_reward": 0.8019269405007362, "critic_loss": 1.492490328013897, "actor_loss": -80.03988400268555, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.80869174003601, "step": 69000}
{"episode_reward": 910.8624004145639, "episode": 70.0, "batch_reward": 0.804156481206417, "critic_loss": 1.5362844656705856, "actor_loss": -80.4145472869873, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.728427410125732, "step": 70000}
{"episode_reward": 858.20662698678, "episode": 71.0, "batch_reward": 0.8043089880943298, "critic_loss": 1.4990810117721558, "actor_loss": -79.87884768676757, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.05294466018677, "step": 71000}
{"episode_reward": 951.1936636283593, "episode": 72.0, "batch_reward": 0.8073657149672508, "critic_loss": 1.4740414296388626, "actor_loss": -80.40250093078613, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.57723093032837, "step": 72000}
{"episode_reward": 900.7413949775728, "episode": 73.0, "batch_reward": 0.8079499634504318, "critic_loss": 1.534255107998848, "actor_loss": -80.48259275817871, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.79420495033264, "step": 73000}
{"episode_reward": 940.6864463705617, "episode": 74.0, "batch_reward": 0.8104926525950432, "critic_loss": 1.4291887307167053, "actor_loss": -80.63376707458497, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.9751615524292, "step": 74000}
{"episode_reward": 889.5443605838615, "episode": 75.0, "batch_reward": 0.8115900046229363, "critic_loss": 1.4730944154262542, "actor_loss": -80.7772957611084, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.93584108352661, "step": 75000}
{"episode_reward": 889.6826994509058, "episode": 76.0, "batch_reward": 0.8127182112336159, "critic_loss": 1.4674026865959167, "actor_loss": -80.81426303100586, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.869528770446777, "step": 76000}
{"episode_reward": 879.7108890353514, "episode": 77.0, "batch_reward": 0.8127156537771225, "critic_loss": 1.4332164595127106, "actor_loss": -80.78139749145508, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.369569301605225, "step": 77000}
{"episode_reward": 899.476364839442, "episode": 78.0, "batch_reward": 0.8122106658816337, "critic_loss": 1.4524397150874138, "actor_loss": -80.84838816833496, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.992339611053467, "step": 78000}
{"episode_reward": 891.0897623977517, "episode": 79.0, "batch_reward": 0.8141144382357597, "critic_loss": 1.4527430556416512, "actor_loss": -80.8685587463379, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.435739040374756, "step": 79000}
{"episode_reward": 856.515279435929, "episode": 80.0, "batch_reward": 0.8153987624645234, "critic_loss": 1.4823833954930306, "actor_loss": -80.97436131286621, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.36756134033203, "step": 80000}
{"episode_reward": 871.7096117264668, "episode": 81.0, "batch_reward": 0.815853561758995, "critic_loss": 1.4609851932525635, "actor_loss": -80.87196443176269, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.80677890777588, "step": 81000}
{"episode_reward": 940.3136512169914, "episode": 82.0, "batch_reward": 0.8160528470873832, "critic_loss": 1.4854708312153817, "actor_loss": -80.98649920654297, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.35431432723999, "step": 82000}
{"episode_reward": 919.3302626510568, "episode": 83.0, "batch_reward": 0.8165129742622376, "critic_loss": 1.4559230974316597, "actor_loss": -81.38970742797852, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.018223762512207, "step": 83000}
{"episode_reward": 747.519127425378, "episode": 84.0, "batch_reward": 0.8175774096846581, "critic_loss": 1.4670367906093598, "actor_loss": -81.44762977600098, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.41919207572937, "step": 84000}
{"episode_reward": 828.0024722044949, "episode": 85.0, "batch_reward": 0.8168040800690651, "critic_loss": 1.4598337668180466, "actor_loss": -81.11575422668457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.379324197769165, "step": 85000}
{"episode_reward": 933.3858331404847, "episode": 86.0, "batch_reward": 0.8199440046548844, "critic_loss": 1.5264395886659623, "actor_loss": -81.27970011901856, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.654875993728638, "step": 86000}
{"episode_reward": 880.4114118654205, "episode": 87.0, "batch_reward": 0.8206785560846329, "critic_loss": 1.4357711314558983, "actor_loss": -81.45009986877442, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.020602464675903, "step": 87000}
{"episode_reward": 877.6385750388963, "episode": 88.0, "batch_reward": 0.8210796414613724, "critic_loss": 1.4048879685401916, "actor_loss": -81.59733805847168, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.96212601661682, "step": 88000}
{"episode_reward": 862.8583733593742, "episode": 89.0, "batch_reward": 0.8216159816384315, "critic_loss": 1.4751303160190583, "actor_loss": -81.46564860534669, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.760594129562378, "step": 89000}
{"episode_reward": 956.6539250599434, "episode": 90.0, "batch_reward": 0.8227482839226723, "critic_loss": 1.4393931078910827, "actor_loss": -81.69842233276367, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.552808046340942, "step": 90000}
{"episode_reward": 957.0641093694242, "episode": 91.0, "batch_reward": 0.8245883742570878, "critic_loss": 1.4520745679736138, "actor_loss": -81.65961486816406, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.65776181221008, "step": 91000}
{"episode_reward": 864.9230308361499, "episode": 92.0, "batch_reward": 0.8255476356744766, "critic_loss": 1.3645487907528877, "actor_loss": -81.83680477905274, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.371156454086304, "step": 92000}
{"episode_reward": 962.6927125151516, "episode": 93.0, "batch_reward": 0.8278579163551331, "critic_loss": 1.4334995493292808, "actor_loss": -81.97555760192871, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.730942249298096, "step": 93000}
{"episode_reward": 943.2568737757911, "episode": 94.0, "batch_reward": 0.827982609629631, "critic_loss": 1.5299580552577972, "actor_loss": -82.1825662536621, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.312296867370605, "step": 94000}
{"episode_reward": 875.1491419755342, "episode": 95.0, "batch_reward": 0.8275230523347855, "critic_loss": 1.5504248642921448, "actor_loss": -82.111076461792, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.36350131034851, "step": 95000}
{"episode_reward": 831.81818858034, "episode": 96.0, "batch_reward": 0.8280251868367196, "critic_loss": 1.4806938841342927, "actor_loss": -82.10879530334472, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.40493655204773, "step": 96000}
{"episode_reward": 937.4338224686531, "episode": 97.0, "batch_reward": 0.8283496245741844, "critic_loss": 1.473372725903988, "actor_loss": -82.14891340637207, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.232645988464355, "step": 97000}
{"episode_reward": 902.5820526069748, "episode": 98.0, "batch_reward": 0.8280955904722214, "critic_loss": 1.4371129844784736, "actor_loss": -82.12893891906738, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.363037109375, "step": 98000}
{"episode_reward": 803.2852201372777, "episode": 99.0, "batch_reward": 0.8282488445639611, "critic_loss": 1.5134084869623183, "actor_loss": -82.23105577087402, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.526207447052002, "step": 99000}
{"episode_reward": 889.4974913479037, "episode": 100.0, "batch_reward": 0.8310087695121765, "critic_loss": 1.4423043677210807, "actor_loss": -82.36878541564941, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.464730739593506, "step": 100000}
{"episode_reward": 904.6166674978432, "episode": 101.0, "batch_reward": 0.8317399472594261, "critic_loss": 1.5209315631389617, "actor_loss": -82.36186231994628, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.318843603134155, "step": 101000}
{"episode_reward": 937.0637137755425, "episode": 102.0, "batch_reward": 0.8318011925816536, "critic_loss": 1.48292211997509, "actor_loss": -82.56431916809082, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.512099981307983, "step": 102000}
{"episode_reward": 918.8089222144952, "episode": 103.0, "batch_reward": 0.8320483410358429, "critic_loss": 1.4713648394942285, "actor_loss": -82.33004707336426, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.498771905899048, "step": 103000}
{"episode_reward": 900.238319325004, "episode": 104.0, "batch_reward": 0.8333531929850578, "critic_loss": 1.464714370548725, "actor_loss": -82.5275608215332, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.580968141555786, "step": 104000}
{"episode_reward": 913.02987941046, "episode": 105.0, "batch_reward": 0.834179530441761, "critic_loss": 1.4527376868128776, "actor_loss": -82.43926399230958, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.98750615119934, "step": 105000}
{"episode_reward": 946.5983672839565, "episode": 106.0, "batch_reward": 0.8351427251696587, "critic_loss": 1.4535824043154717, "actor_loss": -82.77285758972168, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.36409020423889, "step": 106000}
{"episode_reward": 921.114992217128, "episode": 107.0, "batch_reward": 0.8357795618772507, "critic_loss": 1.4535360195040703, "actor_loss": -82.71365260314941, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.345116138458252, "step": 107000}
{"episode_reward": 905.2513688947141, "episode": 108.0, "batch_reward": 0.8362884546518325, "critic_loss": 1.4582333008050918, "actor_loss": -82.5239868774414, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.886010885238647, "step": 108000}
{"episode_reward": 956.189107357247, "episode": 109.0, "batch_reward": 0.8375818996429444, "critic_loss": 1.5192147020697593, "actor_loss": -82.76721905517579, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.447845935821533, "step": 109000}
{"episode_reward": 930.515377902136, "episode": 110.0, "batch_reward": 0.8384480231404304, "critic_loss": 1.534768596470356, "actor_loss": -82.76740228271484, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.51162028312683, "step": 110000}
{"episode_reward": 899.040599664996, "episode": 111.0, "batch_reward": 0.8406934819817543, "critic_loss": 1.4775084591507912, "actor_loss": -82.77368269348145, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.67081594467163, "step": 111000}
{"episode_reward": 900.04844278837, "episode": 112.0, "batch_reward": 0.8384627501368522, "critic_loss": 1.6350235154628754, "actor_loss": -82.98455464172363, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.67017960548401, "step": 112000}
{"episode_reward": 878.3288425849223, "episode": 113.0, "batch_reward": 0.8400543165802956, "critic_loss": 1.6138683159947396, "actor_loss": -82.90815553283691, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.409663200378418, "step": 113000}
{"episode_reward": 939.8188548582611, "episode": 114.0, "batch_reward": 0.8404996539950371, "critic_loss": 1.6545959713459015, "actor_loss": -83.09724273681641, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.06498908996582, "step": 114000}
{"episode_reward": 958.347624317731, "episode": 115.0, "batch_reward": 0.841847574532032, "critic_loss": 1.6517414734363556, "actor_loss": -83.01724971008301, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.174618244171143, "step": 115000}
{"episode_reward": 919.8591092335564, "episode": 116.0, "batch_reward": 0.844250730574131, "critic_loss": 1.5933325543999672, "actor_loss": -83.10250010681152, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.552778244018555, "step": 116000}
{"episode_reward": 905.6016570983915, "episode": 117.0, "batch_reward": 0.8408423910140991, "critic_loss": 1.5065207234025002, "actor_loss": -82.90921804809571, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.732382774353027, "step": 117000}
{"episode_reward": 917.7850647221846, "episode": 118.0, "batch_reward": 0.8442835015654564, "critic_loss": 1.5238003637194633, "actor_loss": -83.14978648376464, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.986461639404297, "step": 118000}
{"episode_reward": 945.0616737398573, "episode": 119.0, "batch_reward": 0.8459445369243622, "critic_loss": 1.4584439142346382, "actor_loss": -83.18455029296875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.522170782089233, "step": 119000}
{"episode_reward": 934.1774485475778, "episode": 120.0, "batch_reward": 0.8460604510903359, "critic_loss": 1.4773214691877365, "actor_loss": -83.20650489807129, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.66645646095276, "step": 120000}
{"episode_reward": 931.582351532128, "episode": 121.0, "batch_reward": 0.8463312104940415, "critic_loss": 1.4386245915293694, "actor_loss": -83.19002307128906, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.64553260803223, "step": 121000}
{"episode_reward": 914.5544317258984, "episode": 122.0, "batch_reward": 0.8466848818063736, "critic_loss": 1.4103485827445983, "actor_loss": -83.31658958435058, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.465144157409668, "step": 122000}
{"episode_reward": 923.0726170561171, "episode": 123.0, "batch_reward": 0.8476982014775276, "critic_loss": 1.2944238607287406, "actor_loss": -83.49463821411133, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.364482879638672, "step": 123000}
{"episode_reward": 930.706242608479, "episode": 124.0, "batch_reward": 0.8494144417643547, "critic_loss": 1.2757805747389794, "actor_loss": -83.52812088012695, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.95017433166504, "step": 124000}
{"episode_reward": 938.4224557595412, "episode": 125.0, "batch_reward": 0.8497210872769356, "critic_loss": 1.2691867004036903, "actor_loss": -83.54500144958496, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.40151071548462, "step": 125000}
{"episode_reward": 956.3422000005007, "episode": 126.0, "batch_reward": 0.8502975339889527, "critic_loss": 1.2671030089855193, "actor_loss": -83.54596786499023, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.342076539993286, "step": 126000}
{"episode_reward": 947.536590185397, "episode": 127.0, "batch_reward": 0.8494894901514053, "critic_loss": 1.2746489574313165, "actor_loss": -83.52286645507813, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.290233850479126, "step": 127000}
{"episode_reward": 933.0605096347294, "episode": 128.0, "batch_reward": 0.8498427318334579, "critic_loss": 1.2965756750106812, "actor_loss": -83.66003047180176, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.387996912002563, "step": 128000}
{"episode_reward": 854.4029529043972, "episode": 129.0, "batch_reward": 0.8492595112919807, "critic_loss": 1.2524761283993722, "actor_loss": -83.59731651306153, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.371748208999634, "step": 129000}
{"episode_reward": 947.9361210961684, "episode": 130.0, "batch_reward": 0.853772628724575, "critic_loss": 1.249158329486847, "actor_loss": -83.82254891967773, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.7551212310791, "step": 130000}
{"episode_reward": 887.291050907798, "episode": 131.0, "batch_reward": 0.8527631925344468, "critic_loss": 1.2362200695872307, "actor_loss": -83.7893119506836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.28120684623718, "step": 131000}
{"episode_reward": 924.1197484977359, "episode": 132.0, "batch_reward": 0.8525364011526108, "critic_loss": 1.1930144679546357, "actor_loss": -83.86035095214844, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.814278602600098, "step": 132000}
{"episode_reward": 882.1597280139814, "episode": 133.0, "batch_reward": 0.853080072760582, "critic_loss": 1.178752685636282, "actor_loss": -83.87994462585449, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.09753918647766, "step": 133000}
{"episode_reward": 939.4976853378938, "episode": 134.0, "batch_reward": 0.8522297548055648, "critic_loss": 1.2688806705474853, "actor_loss": -83.84878224182128, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.380781888961792, "step": 134000}
{"episode_reward": 884.7989309246917, "episode": 135.0, "batch_reward": 0.8532872364521027, "critic_loss": 1.2616090517044067, "actor_loss": -83.97357736206055, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.577707290649414, "step": 135000}
{"episode_reward": 900.4287122536059, "episode": 136.0, "batch_reward": 0.8537800483703614, "critic_loss": 1.1633728645741939, "actor_loss": -83.8860662689209, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.67004418373108, "step": 136000}
{"episode_reward": 947.2773746406649, "episode": 137.0, "batch_reward": 0.8540543736815452, "critic_loss": 1.1347838963866235, "actor_loss": -84.03198048400878, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.885668992996216, "step": 137000}
{"episode_reward": 935.0404985912731, "episode": 138.0, "batch_reward": 0.8565358808636665, "critic_loss": 1.1684897182285785, "actor_loss": -84.1229084625244, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.21161127090454, "step": 138000}
{"episode_reward": 924.1826435188291, "episode": 139.0, "batch_reward": 0.8561871178150177, "critic_loss": 1.1728957610726356, "actor_loss": -84.10246026611328, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.386054754257202, "step": 139000}
{"episode_reward": 918.0711399561436, "episode": 140.0, "batch_reward": 0.8569085150957108, "critic_loss": 1.1949734896421433, "actor_loss": -84.14210554504395, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.375604391098022, "step": 140000}
{"episode_reward": 943.7728810297966, "episode": 141.0, "batch_reward": 0.8551761727929116, "critic_loss": 1.1378540790081024, "actor_loss": -84.07667887878418, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.369511127471924, "step": 141000}
{"episode_reward": 929.6133267069456, "episode": 142.0, "batch_reward": 0.8568677302598954, "critic_loss": 1.1898199268579484, "actor_loss": -84.05595956420899, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.725850582122803, "step": 142000}
{"episode_reward": 890.706714902689, "episode": 143.0, "batch_reward": 0.857645224750042, "critic_loss": 1.1557779031395912, "actor_loss": -84.1486492767334, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.617308616638184, "step": 143000}
{"episode_reward": 926.7857439856109, "episode": 144.0, "batch_reward": 0.8589845494031906, "critic_loss": 1.1883035254478456, "actor_loss": -84.27079386901856, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.23338294029236, "step": 144000}
{"episode_reward": 893.1859225780177, "episode": 145.0, "batch_reward": 0.8590510851740837, "critic_loss": 1.2224629218876362, "actor_loss": -84.31500172424316, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.423346281051636, "step": 145000}
{"episode_reward": 887.3561884444123, "episode": 146.0, "batch_reward": 0.859115462899208, "critic_loss": 1.2109894981086253, "actor_loss": -84.31773826599121, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.381141185760498, "step": 146000}
{"episode_reward": 943.4048719341149, "episode": 147.0, "batch_reward": 0.8590695852637291, "critic_loss": 1.1902702907323837, "actor_loss": -84.34247579956055, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.348902702331543, "step": 147000}
{"episode_reward": 878.2022609130535, "episode": 148.0, "batch_reward": 0.8586499533653259, "critic_loss": 1.2748661457300186, "actor_loss": -84.31671612548828, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.365179300308228, "step": 148000}
{"episode_reward": 876.3527242985145, "episode": 149.0, "batch_reward": 0.8591266658306121, "critic_loss": 1.1936101447045804, "actor_loss": -84.34589277648925, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.526395559310913, "step": 149000}
{"episode_reward": 935.7892691530362, "episode": 150.0, "batch_reward": 0.8591986706256867, "critic_loss": 1.1472455207705499, "actor_loss": -84.31419598388672, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
