{"episode_reward": 0.0, "episode": 1.0, "duration": 22.43276023864746, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.9243829250335693, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.28050201971775773, "critic_loss": 0.7648765908733691, "actor_loss": -70.70589352989731, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 65.06344652175903, "step": 3000}
{"episode_reward": 301.9257230454039, "episode": 4.0, "batch_reward": 0.29349742652475835, "critic_loss": 0.9983613401055336, "actor_loss": -75.95004780578613, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.57609486579895, "step": 4000}
{"episode_reward": 391.8667302890351, "episode": 5.0, "batch_reward": 0.35171675685048104, "critic_loss": 0.8919999468326568, "actor_loss": -77.14470880126953, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.807808876037598, "step": 5000}
{"episode_reward": 636.7303028810826, "episode": 6.0, "batch_reward": 0.38164559537172316, "critic_loss": 0.8254167590737342, "actor_loss": -78.47200933837891, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.71555995941162, "step": 6000}
{"episode_reward": 459.27557217912437, "episode": 7.0, "batch_reward": 0.3689356210082769, "critic_loss": 0.821050659507513, "actor_loss": -78.966933303833, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.533649921417236, "step": 7000}
{"episode_reward": 65.94487880829152, "episode": 8.0, "batch_reward": 0.363429289072752, "critic_loss": 0.8569660561680794, "actor_loss": -78.45180325317382, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.961272954940796, "step": 8000}
{"episode_reward": 725.0548797816597, "episode": 9.0, "batch_reward": 0.4236654166579247, "critic_loss": 0.9675392899513244, "actor_loss": -79.73586169433594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.492545127868652, "step": 9000}
{"episode_reward": 922.2241465014026, "episode": 10.0, "batch_reward": 0.43328085824847223, "critic_loss": 1.2153826661109923, "actor_loss": -80.82740713500976, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.082566022872925, "step": 10000}
{"episode_reward": 35.030935926342806, "episode": 11.0, "batch_reward": 0.3936481511592865, "critic_loss": 0.9394449609518051, "actor_loss": -81.96111361694336, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.922531843185425, "step": 11000}
{"episode_reward": 27.295535992706505, "episode": 12.0, "batch_reward": 0.3613394176363945, "critic_loss": 0.8625233878195285, "actor_loss": -81.44566464233398, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.57685399055481, "step": 12000}
{"episode_reward": 17.162435097968853, "episode": 13.0, "batch_reward": 0.3658525028526783, "critic_loss": 0.8809615333378314, "actor_loss": -81.99100801086426, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.465349435806274, "step": 13000}
{"episode_reward": 903.0225591756696, "episode": 14.0, "batch_reward": 0.389083024084568, "critic_loss": 0.8859860246181488, "actor_loss": -82.1371178894043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.140458822250366, "step": 14000}
{"episode_reward": 282.000628204158, "episode": 15.0, "batch_reward": 0.3797817381620407, "critic_loss": 0.8968817890882492, "actor_loss": -82.34662196350098, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.540866374969482, "step": 15000}
{"episode_reward": 492.9362247697067, "episode": 16.0, "batch_reward": 0.4010679394900799, "critic_loss": 0.8908964401185513, "actor_loss": -81.29398078918457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.844439029693604, "step": 16000}
{"episode_reward": 813.9976167464908, "episode": 17.0, "batch_reward": 0.42329657623171807, "critic_loss": 0.9271467586159706, "actor_loss": -80.87508920288086, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.64438247680664, "step": 17000}
{"episode_reward": 842.3428007847444, "episode": 18.0, "batch_reward": 0.44964097017049787, "critic_loss": 0.9599309999644756, "actor_loss": -81.13703587341308, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.123342752456665, "step": 18000}
{"episode_reward": 860.195163825642, "episode": 19.0, "batch_reward": 0.46732552942633626, "critic_loss": 0.9328523827195168, "actor_loss": -80.9484737701416, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.5553777217865, "step": 19000}
{"episode_reward": 784.341751858182, "episode": 20.0, "batch_reward": 0.48611701211333275, "critic_loss": 0.9782464052736759, "actor_loss": -80.9787569732666, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.447622537612915, "step": 20000}
{"episode_reward": 808.2706230047414, "episode": 21.0, "batch_reward": 0.5067275577485562, "critic_loss": 0.9811755649447441, "actor_loss": -80.61244125366211, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.45644927024841, "step": 21000}
{"episode_reward": 959.3413693879743, "episode": 22.0, "batch_reward": 0.5232017316520214, "critic_loss": 1.0295789043307304, "actor_loss": -80.86766291809082, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.4719979763031, "step": 22000}
{"episode_reward": 814.6046849267555, "episode": 23.0, "batch_reward": 0.5348819643557071, "critic_loss": 1.0801268156170845, "actor_loss": -80.77554678344727, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.517112731933594, "step": 23000}
{"episode_reward": 804.5998044251925, "episode": 24.0, "batch_reward": 0.5514703053236008, "critic_loss": 0.9228040636479855, "actor_loss": -81.01587353515625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.115386962890625, "step": 24000}
{"episode_reward": 962.7339495290449, "episode": 25.0, "batch_reward": 0.5666227735579014, "critic_loss": 0.8880142692923546, "actor_loss": -81.38329608154297, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.5098295211792, "step": 25000}
{"episode_reward": 923.1346570709821, "episode": 26.0, "batch_reward": 0.5813443309962749, "critic_loss": 0.8091529007256031, "actor_loss": -81.71887704467774, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.121897220611572, "step": 26000}
{"episode_reward": 941.2443710365424, "episode": 27.0, "batch_reward": 0.594365330696106, "critic_loss": 0.7846178782880306, "actor_loss": -82.31103675842286, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.666862726211548, "step": 27000}
{"episode_reward": 916.6278919319604, "episode": 28.0, "batch_reward": 0.6036896767616272, "critic_loss": 0.8640750391483307, "actor_loss": -82.14100694274903, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.756685256958008, "step": 28000}
{"episode_reward": 795.638095503152, "episode": 29.0, "batch_reward": 0.6156809095740319, "critic_loss": 0.7705997884273529, "actor_loss": -82.49515661621093, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.67228889465332, "step": 29000}
{"episode_reward": 947.4112382105718, "episode": 30.0, "batch_reward": 0.6240711590051651, "critic_loss": 0.6987974630892276, "actor_loss": -82.35434452819824, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.694573163986206, "step": 30000}
{"episode_reward": 917.433657217984, "episode": 31.0, "batch_reward": 0.6311228469610214, "critic_loss": 0.7416775558590889, "actor_loss": -82.37028178405761, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.68125343322754, "step": 31000}
{"episode_reward": 668.2675936772769, "episode": 32.0, "batch_reward": 0.6384049724340439, "critic_loss": 0.6929614328444004, "actor_loss": -82.54207386779785, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.150025367736816, "step": 32000}
{"episode_reward": 948.5574531979494, "episode": 33.0, "batch_reward": 0.6471688323616982, "critic_loss": 0.6616180266737938, "actor_loss": -82.63938383483887, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.666510581970215, "step": 33000}
{"episode_reward": 930.8593288965016, "episode": 34.0, "batch_reward": 0.6528158437609672, "critic_loss": 0.6620866700410842, "actor_loss": -82.64983856201172, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.556748628616333, "step": 34000}
{"episode_reward": 820.8931221426334, "episode": 35.0, "batch_reward": 0.651130678832531, "critic_loss": 0.7199011768996716, "actor_loss": -82.48045234680175, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.93591332435608, "step": 35000}
{"episode_reward": 647.218589115225, "episode": 36.0, "batch_reward": 0.6591153093576432, "critic_loss": 0.7014924316108226, "actor_loss": -82.41625465393066, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.501590251922607, "step": 36000}
{"episode_reward": 919.5815721540835, "episode": 37.0, "batch_reward": 0.6686153378486633, "critic_loss": 0.6746951514184475, "actor_loss": -82.47784747314454, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.659539222717285, "step": 37000}
{"episode_reward": 948.9040126961626, "episode": 38.0, "batch_reward": 0.6734683195352554, "critic_loss": 0.6868066244125366, "actor_loss": -82.74642597961426, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.623435258865356, "step": 38000}
{"episode_reward": 907.4102540471204, "episode": 39.0, "batch_reward": 0.6800630401968956, "critic_loss": 0.7183453263342381, "actor_loss": -82.70421171569824, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.07178544998169, "step": 39000}
{"episode_reward": 843.7333798769337, "episode": 40.0, "batch_reward": 0.6827278501391411, "critic_loss": 0.7920688742697239, "actor_loss": -82.61560203552246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.538666009902954, "step": 40000}
{"episode_reward": 887.9960221671663, "episode": 41.0, "batch_reward": 0.6869466446042061, "critic_loss": 0.8235214991271496, "actor_loss": -82.70526554870605, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.872546911239624, "step": 41000}
{"episode_reward": 847.6699284555397, "episode": 42.0, "batch_reward": 0.6922542755007743, "critic_loss": 0.7998305032551288, "actor_loss": -82.74044467163085, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.61008620262146, "step": 42000}
{"episode_reward": 900.8800051598623, "episode": 43.0, "batch_reward": 0.6963453742265702, "critic_loss": 0.7729939710497856, "actor_loss": -82.8947278137207, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.419161319732666, "step": 43000}
{"episode_reward": 912.7304276197955, "episode": 44.0, "batch_reward": 0.7030964604616166, "critic_loss": 0.7579347591400146, "actor_loss": -82.94624464416503, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.78758454322815, "step": 44000}
{"episode_reward": 933.0265211436904, "episode": 45.0, "batch_reward": 0.7087709634900093, "critic_loss": 0.7395919638872147, "actor_loss": -83.12662509155274, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.746102571487427, "step": 45000}
{"episode_reward": 969.3208593319094, "episode": 46.0, "batch_reward": 0.7151255392432213, "critic_loss": 0.746943998068571, "actor_loss": -83.27905409240722, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.470139265060425, "step": 46000}
{"episode_reward": 957.055791523547, "episode": 47.0, "batch_reward": 0.7199247888922692, "critic_loss": 0.6999158003926277, "actor_loss": -83.41175657653808, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.607390880584717, "step": 47000}
{"episode_reward": 943.1637241421971, "episode": 48.0, "batch_reward": 0.7236112018823624, "critic_loss": 0.7409737909138203, "actor_loss": -83.851611328125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.577007055282593, "step": 48000}
{"episode_reward": 922.044782743228, "episode": 49.0, "batch_reward": 0.7290675076842308, "critic_loss": 0.7489376728832722, "actor_loss": -84.21392491149902, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.560149431228638, "step": 49000}
{"episode_reward": 907.5664592846778, "episode": 50.0, "batch_reward": 0.7316970474123955, "critic_loss": 0.712445190012455, "actor_loss": -84.35384649658204, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.622148036956787, "step": 50000}
{"episode_reward": 900.9564325953405, "episode": 51.0, "batch_reward": 0.7355026013255119, "critic_loss": 0.6728053141534328, "actor_loss": -84.732426071167, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.80837798118591, "step": 51000}
{"episode_reward": 952.6150738570207, "episode": 52.0, "batch_reward": 0.7377436037659645, "critic_loss": 0.6808639731109142, "actor_loss": -84.81293490600586, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.94135856628418, "step": 52000}
{"episode_reward": 939.0055499979644, "episode": 53.0, "batch_reward": 0.7436708763837815, "critic_loss": 0.6707891556024551, "actor_loss": -85.23825463867188, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.13682508468628, "step": 53000}
{"episode_reward": 923.1177714303119, "episode": 54.0, "batch_reward": 0.7452647381424904, "critic_loss": 0.6583293282687664, "actor_loss": -85.35361720275878, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.52441930770874, "step": 54000}
{"episode_reward": 930.6874317667346, "episode": 55.0, "batch_reward": 0.7477046822905541, "critic_loss": 0.637803749114275, "actor_loss": -85.41105009460449, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.87690019607544, "step": 55000}
{"episode_reward": 964.183129912975, "episode": 56.0, "batch_reward": 0.7539012546539307, "critic_loss": 0.6331419112384319, "actor_loss": -85.91520268249512, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.34563159942627, "step": 56000}
{"episode_reward": 968.1360007863536, "episode": 57.0, "batch_reward": 0.7570357991456985, "critic_loss": 0.6080442477166653, "actor_loss": -85.93636964416504, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.607622861862183, "step": 57000}
{"episode_reward": 955.8887855423927, "episode": 58.0, "batch_reward": 0.7601202481985092, "critic_loss": 0.6241497649550438, "actor_loss": -86.28951655578614, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.16551971435547, "step": 58000}
{"episode_reward": 899.1472637652527, "episode": 59.0, "batch_reward": 0.7631575194597244, "critic_loss": 0.7029001843333245, "actor_loss": -86.40736682128906, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.662476778030396, "step": 59000}
{"episode_reward": 972.0022095659107, "episode": 60.0, "batch_reward": 0.7655547814965248, "critic_loss": 0.985053488612175, "actor_loss": -86.58769944763183, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.62189483642578, "step": 60000}
{"episode_reward": 852.9572697287724, "episode": 61.0, "batch_reward": 0.768164128780365, "critic_loss": 1.2947716054320335, "actor_loss": -87.01161575317383, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.37426137924194, "step": 61000}
{"episode_reward": 903.2656547666696, "episode": 62.0, "batch_reward": 0.7695564277172089, "critic_loss": 2.215058665752411, "actor_loss": -87.99852394104003, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.67994713783264, "step": 62000}
{"episode_reward": 982.4181335781043, "episode": 63.0, "batch_reward": 0.7737513465285302, "critic_loss": 3.839484326481819, "actor_loss": -89.45451365661621, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.536246299743652, "step": 63000}
{"episode_reward": 980.1982746338006, "episode": 64.0, "batch_reward": 0.7769770153164863, "critic_loss": 5.587839747905731, "actor_loss": -91.26693096923829, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.360740184783936, "step": 64000}
{"episode_reward": 840.4422932699231, "episode": 65.0, "batch_reward": 0.7729283365011215, "critic_loss": 7.241834465205669, "actor_loss": -93.30726542663574, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.95551562309265, "step": 65000}
{"episode_reward": 207.98947250282103, "episode": 66.0, "batch_reward": 0.7608209723830223, "critic_loss": 8.194026978969575, "actor_loss": -95.42111047363281, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.51792049407959, "step": 66000}
{"episode_reward": 32.83574537161402, "episode": 67.0, "batch_reward": 0.7530023741126061, "critic_loss": 8.487345333814622, "actor_loss": -98.6869210510254, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.525195360183716, "step": 67000}
{"episode_reward": 16.7964324734541, "episode": 68.0, "batch_reward": 0.7406025050878525, "critic_loss": 9.143430389165879, "actor_loss": -101.96040229797363, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.166001558303833, "step": 68000}
{"episode_reward": 16.75247549948803, "episode": 69.0, "batch_reward": 0.7301325829625129, "critic_loss": 10.46256632423401, "actor_loss": -105.86315261840821, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.6748309135437, "step": 69000}
{"episode_reward": 25.970529675941165, "episode": 70.0, "batch_reward": 0.7207941499352455, "critic_loss": 11.757095591068268, "actor_loss": -111.43501768493653, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.960822343826294, "step": 70000}
{"episode_reward": 19.5825935580217, "episode": 71.0, "batch_reward": 0.7089800086617469, "critic_loss": 13.082400184631348, "actor_loss": -120.01619439697265, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.79589605331421, "step": 71000}
{"episode_reward": 62.10324954772499, "episode": 72.0, "batch_reward": 0.7017831932902336, "critic_loss": 15.209172007083893, "actor_loss": -129.84482373046876, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.492242336273193, "step": 72000}
{"episode_reward": 26.865160185314124, "episode": 73.0, "batch_reward": 0.6928142207860947, "critic_loss": 15.484994571208954, "actor_loss": -136.3306222229004, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.36215591430664, "step": 73000}
{"episode_reward": 30.40004436747032, "episode": 74.0, "batch_reward": 0.6828348765969277, "critic_loss": 14.066861629486084, "actor_loss": -143.1450202484131, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.420955181121826, "step": 74000}
{"episode_reward": 46.177446441198384, "episode": 75.0, "batch_reward": 0.6751737770438194, "critic_loss": 12.463174664497375, "actor_loss": -145.24993203735352, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.593324184417725, "step": 75000}
{"episode_reward": 37.83947836923778, "episode": 76.0, "batch_reward": 0.6655650345087052, "critic_loss": 10.990652338504791, "actor_loss": -145.10190132141113, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.193764686584473, "step": 76000}
{"episode_reward": 22.07316710971827, "episode": 77.0, "batch_reward": 0.6601912244558334, "critic_loss": 9.168369967937469, "actor_loss": -147.13950148010255, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.07732892036438, "step": 77000}
{"episode_reward": 47.640245381889606, "episode": 78.0, "batch_reward": 0.6498629532456398, "critic_loss": 7.641846265316009, "actor_loss": -149.26428311157227, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.754619359970093, "step": 78000}
{"episode_reward": 15.158808569409453, "episode": 79.0, "batch_reward": 0.6422623674273491, "critic_loss": 6.275915965795517, "actor_loss": -147.74856939697267, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.71879553794861, "step": 79000}
{"episode_reward": 19.417409429061, "episode": 80.0, "batch_reward": 0.6360898972153664, "critic_loss": 5.171561254739761, "actor_loss": -143.92773027038575, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.749720811843872, "step": 80000}
{"episode_reward": 19.781856415220716, "episode": 81.0, "batch_reward": 0.6248094199001789, "critic_loss": 4.366707520008087, "actor_loss": -143.88726458740234, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.03198981285095, "step": 81000}
{"episode_reward": 24.283496479642523, "episode": 82.0, "batch_reward": 0.6190476152896881, "critic_loss": 3.4715813324451448, "actor_loss": -143.47569595336915, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.791667461395264, "step": 82000}
{"episode_reward": 73.95629496928453, "episode": 83.0, "batch_reward": 0.6130027036070824, "critic_loss": 3.073896045446396, "actor_loss": -138.99468324279786, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.63561224937439, "step": 83000}
{"episode_reward": 26.103346957557395, "episode": 84.0, "batch_reward": 0.6074892943799496, "critic_loss": 2.61205447435379, "actor_loss": -139.12187132263185, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.631819248199463, "step": 84000}
{"episode_reward": 777.2025979447308, "episode": 85.0, "batch_reward": 0.6046119228899479, "critic_loss": 2.340163135051727, "actor_loss": -137.49261851501464, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.92530107498169, "step": 85000}
{"episode_reward": 23.182885719044116, "episode": 86.0, "batch_reward": 0.59742403575778, "critic_loss": 1.9677504358291626, "actor_loss": -133.0085227508545, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.794201612472534, "step": 86000}
{"episode_reward": 28.66216830197076, "episode": 87.0, "batch_reward": 0.5938087343275547, "critic_loss": 1.7165220921039581, "actor_loss": -132.6138863067627, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.73439860343933, "step": 87000}
{"episode_reward": 27.63835755801582, "episode": 88.0, "batch_reward": 0.5856200062036514, "critic_loss": 1.5363710443377494, "actor_loss": -128.86266439819335, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.675508737564087, "step": 88000}
{"episode_reward": 23.51628395260879, "episode": 89.0, "batch_reward": 0.5858757358193397, "critic_loss": 1.3147115196585655, "actor_loss": -128.91130696105958, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.416664838790894, "step": 89000}
{"episode_reward": 974.7664455412713, "episode": 90.0, "batch_reward": 0.5894435205161571, "critic_loss": 1.1444560425281525, "actor_loss": -128.0016881866455, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.118761777877808, "step": 90000}
{"episode_reward": 970.0654248938259, "episode": 91.0, "batch_reward": 0.5868714618980885, "critic_loss": 1.044582386225462, "actor_loss": -123.36294100952148, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.6787965297699, "step": 91000}
{"episode_reward": 25.401958216313545, "episode": 92.0, "batch_reward": 0.5868266294896602, "critic_loss": 0.944808465629816, "actor_loss": -120.47896545410157, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.387455463409424, "step": 92000}
{"episode_reward": 974.990298497607, "episode": 93.0, "batch_reward": 0.5942076219618321, "critic_loss": 0.8299021889567375, "actor_loss": -119.14720433044434, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.64320659637451, "step": 93000}
{"episode_reward": 987.5141109048333, "episode": 94.0, "batch_reward": 0.592801961183548, "critic_loss": 0.8514658186137676, "actor_loss": -116.12280671691894, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.641692638397217, "step": 94000}
{"episode_reward": 362.6245527767187, "episode": 95.0, "batch_reward": 0.5890389965772629, "critic_loss": 0.833834808319807, "actor_loss": -115.76173077392578, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.532288074493408, "step": 95000}
{"episode_reward": 17.46592480975177, "episode": 96.0, "batch_reward": 0.5817215085029602, "critic_loss": 0.796356416553259, "actor_loss": -110.07027442932129, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.251514196395874, "step": 96000}
{"episode_reward": 81.9683444900015, "episode": 97.0, "batch_reward": 0.5815488018393516, "critic_loss": 0.8178012448847294, "actor_loss": -109.64543852233886, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.75529432296753, "step": 97000}
{"episode_reward": 903.6701782396883, "episode": 98.0, "batch_reward": 0.5855755710303784, "critic_loss": 0.8542520953714847, "actor_loss": -109.88094062805176, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.58200430870056, "step": 98000}
{"episode_reward": 933.1479563465836, "episode": 99.0, "batch_reward": 0.5915851291120052, "critic_loss": 0.8368098070919514, "actor_loss": -105.72193470764161, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.195575714111328, "step": 99000}
{"episode_reward": 933.5244472307606, "episode": 100.0, "batch_reward": 0.5931725645065308, "critic_loss": 0.8561045252382755, "actor_loss": -105.11810746765137, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.407681941986084, "step": 100000}
{"episode_reward": 977.210781843937, "episode": 101.0, "batch_reward": 0.5977144981920719, "critic_loss": 0.8721510115861892, "actor_loss": -102.70696047973632, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.639771461486816, "step": 101000}
{"episode_reward": 975.3216810243518, "episode": 102.0, "batch_reward": 0.6021789210140706, "critic_loss": 0.8678853338360787, "actor_loss": -103.22372875976562, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.147956609725952, "step": 102000}
{"episode_reward": 982.7875359068144, "episode": 103.0, "batch_reward": 0.6052766581773757, "critic_loss": 0.8616330698132515, "actor_loss": -103.06774008178711, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.543718338012695, "step": 103000}
{"episode_reward": 962.07389163756, "episode": 104.0, "batch_reward": 0.6074120197594166, "critic_loss": 0.8417715361714363, "actor_loss": -101.39366760253907, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.12858295440674, "step": 104000}
{"episode_reward": 963.3834019231391, "episode": 105.0, "batch_reward": 0.6108806129693986, "critic_loss": 0.8399430993795395, "actor_loss": -100.53608779907226, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.316410064697266, "step": 105000}
{"episode_reward": 978.7214933324573, "episode": 106.0, "batch_reward": 0.6175670083761216, "critic_loss": 0.8653161009252072, "actor_loss": -100.0130927734375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.924686193466187, "step": 106000}
{"episode_reward": 881.3372217233016, "episode": 107.0, "batch_reward": 0.6187777255475521, "critic_loss": 0.8479049899876118, "actor_loss": -99.55003022766114, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.606350898742676, "step": 107000}
{"episode_reward": 916.1802464561815, "episode": 108.0, "batch_reward": 0.6194864487946034, "critic_loss": 0.8651866519451141, "actor_loss": -100.28175245666503, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.572195291519165, "step": 108000}
{"episode_reward": 870.005650294717, "episode": 109.0, "batch_reward": 0.6216085652709007, "critic_loss": 0.851525606572628, "actor_loss": -99.66113696289062, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.1424298286438, "step": 109000}
{"episode_reward": 952.387724004698, "episode": 110.0, "batch_reward": 0.6249072895050048, "critic_loss": 0.8040036404132843, "actor_loss": -98.96418489074708, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.543807983398438, "step": 110000}
{"episode_reward": 956.816948246714, "episode": 111.0, "batch_reward": 0.6306241255402565, "critic_loss": 0.7409728547930717, "actor_loss": -99.35565138244628, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.72647166252136, "step": 111000}
{"episode_reward": 900.1465762030102, "episode": 112.0, "batch_reward": 0.6318723860383034, "critic_loss": 0.6822286409139633, "actor_loss": -97.0804264678955, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.851582765579224, "step": 112000}
{"episode_reward": 973.1933929922678, "episode": 113.0, "batch_reward": 0.6336546286940574, "critic_loss": 0.6546704205572605, "actor_loss": -96.96005107116699, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.559311628341675, "step": 113000}
{"episode_reward": 943.2972573800099, "episode": 114.0, "batch_reward": 0.6365739858150482, "critic_loss": 0.6443099807202816, "actor_loss": -95.83544961547851, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.52013373374939, "step": 114000}
{"episode_reward": 981.734867482261, "episode": 115.0, "batch_reward": 0.6385737545490265, "critic_loss": 0.6236871602237225, "actor_loss": -95.38785307312011, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.322749853134155, "step": 115000}
{"episode_reward": 920.5976186621413, "episode": 116.0, "batch_reward": 0.6418209277391433, "critic_loss": 0.6069722420722247, "actor_loss": -95.11938372802734, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.58021640777588, "step": 116000}
{"episode_reward": 899.0003633848996, "episode": 117.0, "batch_reward": 0.642086119055748, "critic_loss": 0.6177679888308049, "actor_loss": -94.73574833679199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.729178428649902, "step": 117000}
{"episode_reward": 948.4143380173816, "episode": 118.0, "batch_reward": 0.6474190117120743, "critic_loss": 0.5996696222126484, "actor_loss": -94.0385636138916, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.577104806900024, "step": 118000}
{"episode_reward": 975.8561479856943, "episode": 119.0, "batch_reward": 0.6502369285821915, "critic_loss": 0.5876227716505528, "actor_loss": -93.82108644104004, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.865416049957275, "step": 119000}
{"episode_reward": 979.0464682977607, "episode": 120.0, "batch_reward": 0.6523059396147728, "critic_loss": 0.5691475033015013, "actor_loss": -93.84932550048828, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.63329005241394, "step": 120000}
{"episode_reward": 969.1824659826593, "episode": 121.0, "batch_reward": 0.6544412301778794, "critic_loss": 0.5764759919345379, "actor_loss": -93.08021151733398, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.84696364402771, "step": 121000}
{"episode_reward": 953.7695893709333, "episode": 122.0, "batch_reward": 0.6551920041441918, "critic_loss": 0.5514147007763386, "actor_loss": -93.04429051208496, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.713574409484863, "step": 122000}
{"episode_reward": 955.9568314088765, "episode": 123.0, "batch_reward": 0.6618795986771584, "critic_loss": 0.5265346088856458, "actor_loss": -92.57153060913086, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.586259365081787, "step": 123000}
{"episode_reward": 982.0995569157496, "episode": 124.0, "batch_reward": 0.6628462817072869, "critic_loss": 0.5459982313811779, "actor_loss": -91.84721481323243, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.661785125732422, "step": 124000}
{"episode_reward": 978.7572367007671, "episode": 125.0, "batch_reward": 0.6646797241568565, "critic_loss": 0.5367256682217121, "actor_loss": -91.8663549041748, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.079819679260254, "step": 125000}
{"episode_reward": 975.5275931561576, "episode": 126.0, "batch_reward": 0.66636778819561, "critic_loss": 0.5160376195758581, "actor_loss": -92.20379124450683, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.648232221603394, "step": 126000}
{"episode_reward": 975.6070677866259, "episode": 127.0, "batch_reward": 0.6684499470591545, "critic_loss": 0.5229171813875437, "actor_loss": -91.39768901062011, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.64853835105896, "step": 127000}
{"episode_reward": 859.1122611030789, "episode": 128.0, "batch_reward": 0.6717035149931908, "critic_loss": 0.49417516769468783, "actor_loss": -91.41200958251953, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.480549812316895, "step": 128000}
{"episode_reward": 950.4382923483561, "episode": 129.0, "batch_reward": 0.6733016117215157, "critic_loss": 0.4831141319423914, "actor_loss": -91.54697470092773, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.147796154022217, "step": 129000}
{"episode_reward": 977.6480733700863, "episode": 130.0, "batch_reward": 0.677372065782547, "critic_loss": 0.4862576189041138, "actor_loss": -91.45701936340332, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.598758459091187, "step": 130000}
{"episode_reward": 929.4429382704815, "episode": 131.0, "batch_reward": 0.6766860541105271, "critic_loss": 0.4727708366662264, "actor_loss": -91.17946545410156, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.96826195716858, "step": 131000}
{"episode_reward": 939.2037149285591, "episode": 132.0, "batch_reward": 0.6789222419261932, "critic_loss": 0.46946309925615787, "actor_loss": -91.18446643066406, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.946481943130493, "step": 132000}
{"episode_reward": 947.1348354191085, "episode": 133.0, "batch_reward": 0.6804974645972252, "critic_loss": 0.45243711933493613, "actor_loss": -91.34590295410156, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.656327486038208, "step": 133000}
{"episode_reward": 966.5182380904589, "episode": 134.0, "batch_reward": 0.6816543332934379, "critic_loss": 0.47145555418729784, "actor_loss": -90.92597102355957, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.188392162322998, "step": 134000}
{"episode_reward": 895.8639346058831, "episode": 135.0, "batch_reward": 0.6845527773499489, "critic_loss": 0.449203527495265, "actor_loss": -90.22483464050293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.900788068771362, "step": 135000}
{"episode_reward": 868.7746695073339, "episode": 136.0, "batch_reward": 0.685261744081974, "critic_loss": 0.4187006837874651, "actor_loss": -90.62840565490723, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.862976551055908, "step": 136000}
{"episode_reward": 93.63322577633745, "episode": 137.0, "batch_reward": 0.6813067653179169, "critic_loss": 0.4031277099102736, "actor_loss": -89.80701457214356, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.635592222213745, "step": 137000}
{"episode_reward": 974.2788697958229, "episode": 138.0, "batch_reward": 0.6856018496751786, "critic_loss": 0.40298305502533915, "actor_loss": -89.39214169311524, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.601683139801025, "step": 138000}
{"episode_reward": 982.3737514963186, "episode": 139.0, "batch_reward": 0.6859875398278237, "critic_loss": 0.4015139452815056, "actor_loss": -89.82657426452637, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.1939754486084, "step": 139000}
{"episode_reward": 952.0431165882594, "episode": 140.0, "batch_reward": 0.6912033832073212, "critic_loss": 0.40644494999945163, "actor_loss": -88.97142692565917, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.601256608963013, "step": 140000}
{"episode_reward": 966.6164418792881, "episode": 141.0, "batch_reward": 0.6895371727347374, "critic_loss": 0.4219089299589395, "actor_loss": -88.35771661376953, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.25543284416199, "step": 141000}
{"episode_reward": 930.2790061645601, "episode": 142.0, "batch_reward": 0.6925546285510064, "critic_loss": 0.46796513617038726, "actor_loss": -88.64217962646484, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.59508466720581, "step": 142000}
{"episode_reward": 931.0032213468962, "episode": 143.0, "batch_reward": 0.6943707866668701, "critic_loss": 0.4768369233161211, "actor_loss": -88.49740661621094, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.932629108428955, "step": 143000}
{"episode_reward": 962.172387777936, "episode": 144.0, "batch_reward": 0.6957150551676751, "critic_loss": 0.44436297588050366, "actor_loss": -88.51752940368652, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.064847707748413, "step": 144000}
{"episode_reward": 916.89237820857, "episode": 145.0, "batch_reward": 0.6967146292328834, "critic_loss": 0.4539919501841068, "actor_loss": -88.23272685241699, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.896056413650513, "step": 145000}
{"episode_reward": 919.0686097836167, "episode": 146.0, "batch_reward": 0.6990999544262886, "critic_loss": 0.46219171583652496, "actor_loss": -88.03819291687012, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.574103832244873, "step": 146000}
{"episode_reward": 977.1061223328319, "episode": 147.0, "batch_reward": 0.7005780868530274, "critic_loss": 0.4525102422684431, "actor_loss": -88.15231169128418, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.693222045898438, "step": 147000}
{"episode_reward": 938.7103421109564, "episode": 148.0, "batch_reward": 0.7010821917057037, "critic_loss": 0.4433703330308199, "actor_loss": -88.15481175231933, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.445327043533325, "step": 148000}
{"episode_reward": 923.236818628541, "episode": 149.0, "batch_reward": 0.704635400235653, "critic_loss": 0.43645506192743777, "actor_loss": -88.25860459899903, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.573439836502075, "step": 149000}
{"episode_reward": 977.3352783036294, "episode": 150.0, "batch_reward": 0.7048604286313057, "critic_loss": 0.45535280472040174, "actor_loss": -87.98402673339844, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
