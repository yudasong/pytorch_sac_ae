{"episode_reward": 0.0, "episode": 1.0, "duration": 22.712281465530396, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 2.217170476913452, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.3175907341956536, "critic_loss": 0.5509874521245078, "actor_loss": -73.96538866095754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 96.90555381774902, "step": 3000}
{"episode_reward": 852.2704588585635, "episode": 4.0, "batch_reward": 0.5016144292950631, "critic_loss": 0.6612338734567166, "actor_loss": -82.45945344543458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.16058802604675, "step": 4000}
{"episode_reward": 713.4714659116346, "episode": 5.0, "batch_reward": 0.5620954254865647, "critic_loss": 0.5997807686924934, "actor_loss": -83.93180270385743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.72321915626526, "step": 5000}
{"episode_reward": 871.9022424749055, "episode": 6.0, "batch_reward": 0.6267553877234459, "critic_loss": 0.4779122820496559, "actor_loss": -86.11851235961915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.10283970832825, "step": 6000}
{"episode_reward": 914.3394606640228, "episode": 7.0, "batch_reward": 0.610485890775919, "critic_loss": 0.525846791267395, "actor_loss": -87.23582987976074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.730637550354004, "step": 7000}
{"episode_reward": 69.60210649574154, "episode": 8.0, "batch_reward": 0.5816769199967384, "critic_loss": 0.5675125827789307, "actor_loss": -86.44888577270508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.03206181526184, "step": 8000}
{"episode_reward": 787.3514135152127, "episode": 9.0, "batch_reward": 0.6169240710735321, "critic_loss": 0.5611761557757855, "actor_loss": -87.07765068054199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.16555619239807, "step": 9000}
{"episode_reward": 930.4256534909169, "episode": 10.0, "batch_reward": 0.6477900123000145, "critic_loss": 0.6251417636573314, "actor_loss": -87.40919999694825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.263696670532227, "step": 10000}
{"episode_reward": 915.1734342057731, "episode": 11.0, "batch_reward": 0.6728224991559982, "critic_loss": 0.7132846981585026, "actor_loss": -88.7421410369873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.5076322555542, "step": 11000}
{"episode_reward": 912.4999028072958, "episode": 12.0, "batch_reward": 0.6863697862625122, "critic_loss": 0.8351638125777244, "actor_loss": -89.03985926818848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.429335832595825, "step": 12000}
{"episode_reward": 860.048899596869, "episode": 13.0, "batch_reward": 0.6891854614019394, "critic_loss": 1.0600082387328147, "actor_loss": -89.72599815368652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.75306844711304, "step": 13000}
{"episode_reward": 586.6417866313487, "episode": 14.0, "batch_reward": 0.6968420550823212, "critic_loss": 0.8077522502243519, "actor_loss": -89.75365705871582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.36111521720886, "step": 14000}
{"episode_reward": 906.8877049910046, "episode": 15.0, "batch_reward": 0.7111706260442734, "critic_loss": 0.7087480870783329, "actor_loss": -90.02312370300292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.97370147705078, "step": 15000}
{"episode_reward": 876.4727540729372, "episode": 16.0, "batch_reward": 0.7241080964207649, "critic_loss": 0.675473131775856, "actor_loss": -89.13819534301757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.7166748046875, "step": 16000}
{"episode_reward": 947.1397420484897, "episode": 17.0, "batch_reward": 0.7237492699623108, "critic_loss": 0.6918436690568924, "actor_loss": -88.58447779846192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.68803668022156, "step": 17000}
{"episode_reward": 642.4867023469792, "episode": 18.0, "batch_reward": 0.732840372979641, "critic_loss": 0.5639007706344128, "actor_loss": -88.67258180236817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.70311212539673, "step": 18000}
{"episode_reward": 919.4093427302893, "episode": 19.0, "batch_reward": 0.7409196356534958, "critic_loss": 0.4945624159574509, "actor_loss": -88.46814584350587, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.830042600631714, "step": 19000}
{"episode_reward": 957.6734527145647, "episode": 20.0, "batch_reward": 0.7323841379880905, "critic_loss": 0.5012726652622223, "actor_loss": -88.18728352355957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.42816162109375, "step": 20000}
{"episode_reward": 35.58630081695154, "episode": 21.0, "batch_reward": 0.719430859029293, "critic_loss": 0.4381358065456152, "actor_loss": -87.36006468200684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.447099685668945, "step": 21000}
{"episode_reward": 980.3484220970216, "episode": 22.0, "batch_reward": 0.7118643697500229, "critic_loss": 0.41628031384944914, "actor_loss": -87.23044386291504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.33049249649048, "step": 22000}
{"episode_reward": 24.39286260038329, "episode": 23.0, "batch_reward": 0.6955573812127114, "critic_loss": 0.43299163854122164, "actor_loss": -86.62634480285645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.31058669090271, "step": 23000}
{"episode_reward": 935.349865177907, "episode": 24.0, "batch_reward": 0.7087562289237976, "critic_loss": 0.42774625211954115, "actor_loss": -86.65863006591798, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.39764332771301, "step": 24000}
{"episode_reward": 914.4291538317528, "episode": 25.0, "batch_reward": 0.7160598125457763, "critic_loss": 0.45944809521734714, "actor_loss": -86.83015438842773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.98524188995361, "step": 25000}
{"episode_reward": 907.8383253921246, "episode": 26.0, "batch_reward": 0.7239470154047012, "critic_loss": 0.44634637419879436, "actor_loss": -86.89823873901368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.243042945861816, "step": 26000}
{"episode_reward": 877.411659558717, "episode": 27.0, "batch_reward": 0.7294632037878036, "critic_loss": 0.4738256516754627, "actor_loss": -87.1921202545166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.75412678718567, "step": 27000}
{"episode_reward": 897.2302987560424, "episode": 28.0, "batch_reward": 0.7350450842380524, "critic_loss": 0.48338198909163477, "actor_loss": -87.0101756439209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.372583627700806, "step": 28000}
{"episode_reward": 886.1292900216453, "episode": 29.0, "batch_reward": 0.7431692888736725, "critic_loss": 0.4700410910248756, "actor_loss": -87.56432829284668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.3003363609314, "step": 29000}
{"episode_reward": 974.6281772365983, "episode": 30.0, "batch_reward": 0.7461209160089493, "critic_loss": 0.503681532651186, "actor_loss": -87.51841665649414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.899934768676758, "step": 30000}
{"episode_reward": 858.4437679752865, "episode": 31.0, "batch_reward": 0.7528900182843208, "critic_loss": 0.47606901267170904, "actor_loss": -87.55207562255859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.95100927352905, "step": 31000}
{"episode_reward": 937.1822340117561, "episode": 32.0, "batch_reward": 0.759877203643322, "critic_loss": 0.4657123190909624, "actor_loss": -87.92269046020508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.2044894695282, "step": 32000}
{"episode_reward": 973.3442138674885, "episode": 33.0, "batch_reward": 0.7632145488262176, "critic_loss": 0.4583424747288227, "actor_loss": -87.90294509887696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.1218581199646, "step": 33000}
{"episode_reward": 851.490180092919, "episode": 34.0, "batch_reward": 0.7677859033942223, "critic_loss": 0.4601631539463997, "actor_loss": -88.03306550598144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.45181846618652, "step": 34000}
{"episode_reward": 919.9279986080625, "episode": 35.0, "batch_reward": 0.7670884615778923, "critic_loss": 0.5339174717664719, "actor_loss": -88.0232474975586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.21239924430847, "step": 35000}
{"episode_reward": 653.7225277884036, "episode": 36.0, "batch_reward": 0.7715997853875161, "critic_loss": 0.5431486079990864, "actor_loss": -87.86896534729004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.49715876579285, "step": 36000}
{"episode_reward": 976.334101052355, "episode": 37.0, "batch_reward": 0.7721907344460487, "critic_loss": 0.5865231764912605, "actor_loss": -87.707287109375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.292638301849365, "step": 37000}
{"episode_reward": 740.9229918174706, "episode": 38.0, "batch_reward": 0.7748568075895309, "critic_loss": 0.557594782859087, "actor_loss": -88.1545591583252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.451311111450195, "step": 38000}
{"episode_reward": 962.0526426880947, "episode": 39.0, "batch_reward": 0.7806773084998131, "critic_loss": 0.5692435096502304, "actor_loss": -88.01666596984863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.158353090286255, "step": 39000}
{"episode_reward": 961.183080069064, "episode": 40.0, "batch_reward": 0.7825805941224098, "critic_loss": 0.5500995428860187, "actor_loss": -87.96505979919434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.158636569976807, "step": 40000}
{"episode_reward": 933.4708888868639, "episode": 41.0, "batch_reward": 0.7872820302248001, "critic_loss": 0.5508497634530067, "actor_loss": -88.02412213134765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.11381077766418, "step": 41000}
{"episode_reward": 954.6506993188277, "episode": 42.0, "batch_reward": 0.7915570843815803, "critic_loss": 0.5527537068873644, "actor_loss": -88.15745155334473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.114681243896484, "step": 42000}
{"episode_reward": 965.6249421712782, "episode": 43.0, "batch_reward": 0.7952644600868225, "critic_loss": 0.5754270266592503, "actor_loss": -88.506790725708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.87543964385986, "step": 43000}
{"episode_reward": 900.048462446939, "episode": 44.0, "batch_reward": 0.7978255787491798, "critic_loss": 0.5371353172957897, "actor_loss": -88.43467373657226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.09615087509155, "step": 44000}
{"episode_reward": 942.9997698055214, "episode": 45.0, "batch_reward": 0.8007910808920861, "critic_loss": 0.5231690318286419, "actor_loss": -88.76388543701172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.113202810287476, "step": 45000}
{"episode_reward": 958.4264697679033, "episode": 46.0, "batch_reward": 0.8066592453718185, "critic_loss": 0.48195717249810693, "actor_loss": -88.79460482788086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.804291009902954, "step": 46000}
{"episode_reward": 977.3639669496167, "episode": 47.0, "batch_reward": 0.8081375533938407, "critic_loss": 0.44634990724921225, "actor_loss": -88.69582400512695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.53522324562073, "step": 47000}
{"episode_reward": 958.5570925042249, "episode": 48.0, "batch_reward": 0.8120273058414459, "critic_loss": 0.41706614530086517, "actor_loss": -89.17371214294434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.20589351654053, "step": 48000}
{"episode_reward": 949.8584701716587, "episode": 49.0, "batch_reward": 0.8134602764844895, "critic_loss": 0.4139138341099024, "actor_loss": -89.19166424560547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.566722869873047, "step": 49000}
{"episode_reward": 900.6474670064829, "episode": 50.0, "batch_reward": 0.8157218661904335, "critic_loss": 0.3924992956221104, "actor_loss": -89.15634107971191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.346330642700195, "step": 50000}
{"episode_reward": 908.745936159207, "episode": 51.0, "batch_reward": 0.8201554597616195, "critic_loss": 0.3895699612051249, "actor_loss": -89.68698538208008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 66.89892411231995, "step": 51000}
{"episode_reward": 982.2429000466443, "episode": 52.0, "batch_reward": 0.8201001923084259, "critic_loss": 0.39761131557822227, "actor_loss": -89.42332182312012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.225475788116455, "step": 52000}
{"episode_reward": 923.2361328910706, "episode": 53.0, "batch_reward": 0.8237265853285789, "critic_loss": 0.3880741495043039, "actor_loss": -89.75449493408203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.11818075180054, "step": 53000}
{"episode_reward": 909.9292434794961, "episode": 54.0, "batch_reward": 0.8249738520383835, "critic_loss": 0.36742498029768467, "actor_loss": -89.67437161254882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.857078313827515, "step": 54000}
{"episode_reward": 940.1813937309493, "episode": 55.0, "batch_reward": 0.8280188327431679, "critic_loss": 0.3634784122109413, "actor_loss": -89.72731214904785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.33278799057007, "step": 55000}
{"episode_reward": 967.5672021978805, "episode": 56.0, "batch_reward": 0.8296183346509933, "critic_loss": 0.3864046584665775, "actor_loss": -90.11358894348145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.837101459503174, "step": 56000}
{"episode_reward": 890.7370111122547, "episode": 57.0, "batch_reward": 0.831412517607212, "critic_loss": 0.3708626415729523, "actor_loss": -90.02666830444336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.52664566040039, "step": 57000}
{"episode_reward": 935.1446007540216, "episode": 58.0, "batch_reward": 0.8318929238319397, "critic_loss": 0.3759460156559944, "actor_loss": -90.25124406433106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.581053733825684, "step": 58000}
{"episode_reward": 933.4141428092389, "episode": 59.0, "batch_reward": 0.83499437469244, "critic_loss": 0.3582744624018669, "actor_loss": -90.1618448791504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.909974813461304, "step": 59000}
{"episode_reward": 981.7102514164362, "episode": 60.0, "batch_reward": 0.8356388187408448, "critic_loss": 0.4002312954366207, "actor_loss": -90.04078762817383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.597102403640747, "step": 60000}
{"episode_reward": 848.5423443133365, "episode": 61.0, "batch_reward": 0.8354894348978996, "critic_loss": 0.39694423565268516, "actor_loss": -90.03755697631836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 66.64249753952026, "step": 61000}
{"episode_reward": 913.056700942858, "episode": 62.0, "batch_reward": 0.8380016024708747, "critic_loss": 0.38063688318431377, "actor_loss": -90.22243220520019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.185131788253784, "step": 62000}
{"episode_reward": 966.6353463679482, "episode": 63.0, "batch_reward": 0.8401991927623749, "critic_loss": 0.3690808289796114, "actor_loss": -90.14845765686036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.884601354599, "step": 63000}
{"episode_reward": 979.1658730934305, "episode": 64.0, "batch_reward": 0.8435554682016373, "critic_loss": 0.38842785070836544, "actor_loss": -90.19830198669433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.314693450927734, "step": 64000}
{"episode_reward": 957.4766901031791, "episode": 65.0, "batch_reward": 0.8443869770765304, "critic_loss": 0.4130559406131506, "actor_loss": -90.44601454162597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.370037317276, "step": 65000}
{"episode_reward": 948.3493810060781, "episode": 66.0, "batch_reward": 0.8455600742101669, "critic_loss": 0.3945565418750048, "actor_loss": -90.2375405883789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.62051558494568, "step": 66000}
{"episode_reward": 985.45134066991, "episode": 67.0, "batch_reward": 0.8494945169091225, "critic_loss": 0.3995813601911068, "actor_loss": -90.43661111450196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.63068628311157, "step": 67000}
{"episode_reward": 954.6811172885255, "episode": 68.0, "batch_reward": 0.8480630152225495, "critic_loss": 0.4017154613435268, "actor_loss": -90.4240586090088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.49069380760193, "step": 68000}
{"episode_reward": 884.9168845444269, "episode": 69.0, "batch_reward": 0.8500688297152519, "critic_loss": 0.40120026920735835, "actor_loss": -90.37448133850097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.5361750125885, "step": 69000}
{"episode_reward": 976.104789797472, "episode": 70.0, "batch_reward": 0.8523494910597801, "critic_loss": 0.37104813353717325, "actor_loss": -90.62909747314453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.35958194732666, "step": 70000}
{"episode_reward": 917.999492063817, "episode": 71.0, "batch_reward": 0.8534542437791824, "critic_loss": 0.3645007571429014, "actor_loss": -90.6719910583496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.70153093338013, "step": 71000}
{"episode_reward": 960.1239474202113, "episode": 72.0, "batch_reward": 0.8551604400277137, "critic_loss": 0.36266211040318014, "actor_loss": -90.7349142150879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.82408833503723, "step": 72000}
{"episode_reward": 915.1522009477069, "episode": 73.0, "batch_reward": 0.855972950398922, "critic_loss": 0.3865890288054943, "actor_loss": -90.55674179077148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.82597303390503, "step": 73000}
{"episode_reward": 939.5401848396499, "episode": 74.0, "batch_reward": 0.8556357727646827, "critic_loss": 0.3533276942521334, "actor_loss": -90.87263789367675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.67021560668945, "step": 74000}
{"episode_reward": 958.9825563577828, "episode": 75.0, "batch_reward": 0.8594035132527351, "critic_loss": 0.34343858298659324, "actor_loss": -90.89188723754883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.93642830848694, "step": 75000}
{"episode_reward": 964.4772601584172, "episode": 76.0, "batch_reward": 0.8574631131887436, "critic_loss": 0.36697900523245336, "actor_loss": -90.77051448059082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.737767696380615, "step": 76000}
{"episode_reward": 887.3443476372385, "episode": 77.0, "batch_reward": 0.8606763721108437, "critic_loss": 0.354730110630393, "actor_loss": -91.04292866516113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.823872566223145, "step": 77000}
{"episode_reward": 977.9502348164064, "episode": 78.0, "batch_reward": 0.8597637557387352, "critic_loss": 0.3842404111623764, "actor_loss": -91.2252771911621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.770943641662598, "step": 78000}
{"episode_reward": 925.9351074401891, "episode": 79.0, "batch_reward": 0.8601684362888337, "critic_loss": 0.37261039949953556, "actor_loss": -91.21403094482422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.94233012199402, "step": 79000}
{"episode_reward": 910.3578118782435, "episode": 80.0, "batch_reward": 0.8628244259953499, "critic_loss": 0.3661943807825446, "actor_loss": -90.98325131225586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.676897525787354, "step": 80000}
{"episode_reward": 945.0614169815633, "episode": 81.0, "batch_reward": 0.8630595991015434, "critic_loss": 0.36298106010258196, "actor_loss": -91.05556533813477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.11772656440735, "step": 81000}
{"episode_reward": 947.5746821215039, "episode": 82.0, "batch_reward": 0.8636172440648079, "critic_loss": 0.3724177611246705, "actor_loss": -91.17560691833496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.9182562828064, "step": 82000}
{"episode_reward": 976.4063070145434, "episode": 83.0, "batch_reward": 0.8659390952587128, "critic_loss": 0.39649401362240316, "actor_loss": -90.91562301635742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.71166682243347, "step": 83000}
{"episode_reward": 938.0007135071004, "episode": 84.0, "batch_reward": 0.8665415685772896, "critic_loss": 0.403255951166153, "actor_loss": -91.14362855529785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.61630940437317, "step": 84000}
{"episode_reward": 907.0500181874887, "episode": 85.0, "batch_reward": 0.8663388900756835, "critic_loss": 0.40866292533278464, "actor_loss": -91.17689604187012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.78176236152649, "step": 85000}
{"episode_reward": 965.3599645740221, "episode": 86.0, "batch_reward": 0.8666774014234543, "critic_loss": 0.40694875779747963, "actor_loss": -90.92585095214844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.80977988243103, "step": 86000}
{"episode_reward": 903.5810550973954, "episode": 87.0, "batch_reward": 0.8680624044537544, "critic_loss": 0.4388280861824751, "actor_loss": -91.17449293518067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.401602506637573, "step": 87000}
{"episode_reward": 911.0608546511476, "episode": 88.0, "batch_reward": 0.8676718956232071, "critic_loss": 0.4104761737883091, "actor_loss": -90.93626216125489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.732046842575073, "step": 88000}
{"episode_reward": 972.6766676227286, "episode": 89.0, "batch_reward": 0.8695028166770935, "critic_loss": 0.40283633559942245, "actor_loss": -91.2792825164795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.146625757217407, "step": 89000}
{"episode_reward": 977.7105637971085, "episode": 90.0, "batch_reward": 0.8716137834191322, "critic_loss": 0.40369124680757523, "actor_loss": -91.59502297973633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.677058935165405, "step": 90000}
{"episode_reward": 982.5029112903732, "episode": 91.0, "batch_reward": 0.8717829300165176, "critic_loss": 0.4695243436172605, "actor_loss": -91.34380116271973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.64821743965149, "step": 91000}
{"episode_reward": 932.4657638369503, "episode": 92.0, "batch_reward": 0.8750613607168197, "critic_loss": 0.4906600501388311, "actor_loss": -91.38894036865234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.856826066970825, "step": 92000}
{"episode_reward": 971.6321223434975, "episode": 93.0, "batch_reward": 0.8755693162679672, "critic_loss": 0.5034760861247778, "actor_loss": -91.61618344116211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.834569454193115, "step": 93000}
{"episode_reward": 986.7902693864515, "episode": 94.0, "batch_reward": 0.8725895350575447, "critic_loss": 0.5479792338460684, "actor_loss": -91.57494491577148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.07099485397339, "step": 94000}
{"episode_reward": 554.3443393294331, "episode": 95.0, "batch_reward": 0.8681807235479355, "critic_loss": 0.4828828063905239, "actor_loss": -91.91007574462891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.99811291694641, "step": 95000}
{"episode_reward": 12.673662960098584, "episode": 96.0, "batch_reward": 0.8593102048635483, "critic_loss": 0.44317431685328484, "actor_loss": -91.07997583007813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.709877014160156, "step": 96000}
{"episode_reward": 526.3695928023501, "episode": 97.0, "batch_reward": 0.8545011569261551, "critic_loss": 0.4212661557942629, "actor_loss": -91.40727595520019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.342915058135986, "step": 97000}
{"episode_reward": 19.67884683468671, "episode": 98.0, "batch_reward": 0.8465111699700355, "critic_loss": 0.39164849698543547, "actor_loss": -91.71715939331055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.808115005493164, "step": 98000}
{"episode_reward": 27.97936437675154, "episode": 99.0, "batch_reward": 0.8400487825274467, "critic_loss": 0.42846144634485245, "actor_loss": -90.89020703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.488778114318848, "step": 99000}
{"episode_reward": 928.8279904296652, "episode": 100.0, "batch_reward": 0.8420926471948623, "critic_loss": 0.4275421026721597, "actor_loss": -91.07616883850098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.11024022102356, "step": 100000}
{"episode_reward": 983.8698126147829, "episode": 101.0, "batch_reward": 0.8458479517102242, "critic_loss": 0.4923644390553236, "actor_loss": -90.6914662475586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.792709827423096, "step": 101000}
{"episode_reward": 968.1834952309521, "episode": 102.0, "batch_reward": 0.8453994312286377, "critic_loss": 0.6366183727532625, "actor_loss": -91.26325666809082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.79584765434265, "step": 102000}
{"episode_reward": 708.2394739309555, "episode": 103.0, "batch_reward": 0.8428915547132492, "critic_loss": 0.8870697360634804, "actor_loss": -92.39487588500977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.66922450065613, "step": 103000}
{"episode_reward": 615.2818990956714, "episode": 104.0, "batch_reward": 0.8418053166866303, "critic_loss": 1.2114267949461937, "actor_loss": -93.58389920043945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.91849875450134, "step": 104000}
{"episode_reward": 838.9452737746296, "episode": 105.0, "batch_reward": 0.8415147685408593, "critic_loss": 1.40049057328701, "actor_loss": -94.69271507263184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.861329078674316, "step": 105000}
{"episode_reward": 677.1320808270262, "episode": 106.0, "batch_reward": 0.8378932902216911, "critic_loss": 1.4678826518058776, "actor_loss": -95.52606420898438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.810137510299683, "step": 106000}
{"episode_reward": 142.52057340473112, "episode": 107.0, "batch_reward": 0.8310956040620804, "critic_loss": 1.3751423270702363, "actor_loss": -96.37948585510254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.30141854286194, "step": 107000}
{"episode_reward": 156.49840564749192, "episode": 108.0, "batch_reward": 0.8254789769649505, "critic_loss": 1.366068479001522, "actor_loss": -97.90685250854492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.44066596031189, "step": 108000}
{"episode_reward": 94.88760747113595, "episode": 109.0, "batch_reward": 0.8160109267830848, "critic_loss": 1.4641920182704926, "actor_loss": -98.48457763671875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.91426658630371, "step": 109000}
{"episode_reward": 69.94381278450446, "episode": 110.0, "batch_reward": 0.8116033170819282, "critic_loss": 1.7057056908607482, "actor_loss": -99.26681555175782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.0471031665802, "step": 110000}
{"episode_reward": 264.2035840786673, "episode": 111.0, "batch_reward": 0.8068665250539779, "critic_loss": 1.9351949725151063, "actor_loss": -101.82782235717774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.44609355926514, "step": 111000}
{"episode_reward": 122.2345128903492, "episode": 112.0, "batch_reward": 0.8000610143542289, "critic_loss": 1.9276604826450348, "actor_loss": -101.86336856079102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.898555517196655, "step": 112000}
{"episode_reward": 130.70935722724147, "episode": 113.0, "batch_reward": 0.7973876285552979, "critic_loss": 1.6231655125021935, "actor_loss": -103.10320358276367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.374717712402344, "step": 113000}
{"episode_reward": 964.9645071105169, "episode": 114.0, "batch_reward": 0.7990502346754074, "critic_loss": 1.4169839339256287, "actor_loss": -103.02578890991211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.71168780326843, "step": 114000}
{"episode_reward": 924.8381693740906, "episode": 115.0, "batch_reward": 0.7983702271580696, "critic_loss": 1.2449386814534664, "actor_loss": -103.50225610351562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.931607246398926, "step": 115000}
{"episode_reward": 870.9661937379776, "episode": 116.0, "batch_reward": 0.8007407435774803, "critic_loss": 1.1438888609409332, "actor_loss": -103.84705236816406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.225968837738037, "step": 116000}
{"episode_reward": 926.7893083399651, "episode": 117.0, "batch_reward": 0.8005534289479256, "critic_loss": 1.0798369114995003, "actor_loss": -103.75749171447754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.14235496520996, "step": 117000}
{"episode_reward": 937.1443967662509, "episode": 118.0, "batch_reward": 0.8017545502185821, "critic_loss": 0.9847548568546772, "actor_loss": -102.88656837463378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.39259958267212, "step": 118000}
{"episode_reward": 946.6210068651926, "episode": 119.0, "batch_reward": 0.8054631992578506, "critic_loss": 0.884402189642191, "actor_loss": -102.76760177612304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.56652569770813, "step": 119000}
{"episode_reward": 978.5118837717711, "episode": 120.0, "batch_reward": 0.8059867983460426, "critic_loss": 0.8543560297489167, "actor_loss": -102.87761788940429, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.80913019180298, "step": 120000}
{"episode_reward": 970.6296188769027, "episode": 121.0, "batch_reward": 0.8075774527788162, "critic_loss": 0.7997692814469337, "actor_loss": -101.80730836486816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.01365208625793, "step": 121000}
{"episode_reward": 953.6032323199992, "episode": 122.0, "batch_reward": 0.807481322646141, "critic_loss": 0.7833390601575375, "actor_loss": -101.9188035736084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.665178537368774, "step": 122000}
{"episode_reward": 932.6580512333271, "episode": 123.0, "batch_reward": 0.8094523401260376, "critic_loss": 0.7281127619445324, "actor_loss": -101.34441575622559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.19237518310547, "step": 123000}
{"episode_reward": 981.7836370512168, "episode": 124.0, "batch_reward": 0.8111950008273124, "critic_loss": 0.7203999351859093, "actor_loss": -100.54967483520508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.60106825828552, "step": 124000}
{"episode_reward": 975.8562399983831, "episode": 125.0, "batch_reward": 0.8131681062579155, "critic_loss": 0.6615272257328033, "actor_loss": -100.6398623046875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.284137725830078, "step": 125000}
{"episode_reward": 972.1341241373955, "episode": 126.0, "batch_reward": 0.8139270648360253, "critic_loss": 0.6753480392992497, "actor_loss": -101.02044003295899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.398715496063232, "step": 126000}
{"episode_reward": 946.298618587043, "episode": 127.0, "batch_reward": 0.8140305452346802, "critic_loss": 0.6890022410154343, "actor_loss": -99.85578689575195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.62683296203613, "step": 127000}
{"episode_reward": 911.3477521143017, "episode": 128.0, "batch_reward": 0.8143529613614082, "critic_loss": 0.716402009755373, "actor_loss": -100.03755821228027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.573528289794922, "step": 128000}
{"episode_reward": 907.0414786830593, "episode": 129.0, "batch_reward": 0.8135899063944817, "critic_loss": 0.7498064954280853, "actor_loss": -100.50622830200196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.896387100219727, "step": 129000}
{"episode_reward": 913.6756668472566, "episode": 130.0, "batch_reward": 0.8185153574347496, "critic_loss": 0.7623900751173496, "actor_loss": -100.74630712890625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.74923825263977, "step": 130000}
{"episode_reward": 913.726196611979, "episode": 131.0, "batch_reward": 0.8158861142992974, "critic_loss": 0.7552302678227425, "actor_loss": -100.56133360290528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.40195369720459, "step": 131000}
{"episode_reward": 941.2130132282851, "episode": 132.0, "batch_reward": 0.818173380613327, "critic_loss": 0.6907847325801849, "actor_loss": -100.65654296875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.8044376373291, "step": 132000}
{"episode_reward": 814.3505428870229, "episode": 133.0, "batch_reward": 0.817067224919796, "critic_loss": 0.6673143915235996, "actor_loss": -101.06537750244141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.665953397750854, "step": 133000}
{"episode_reward": 926.0293950962335, "episode": 134.0, "batch_reward": 0.8180978016257286, "critic_loss": 0.6221595168858767, "actor_loss": -100.34865437316894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.767579555511475, "step": 134000}
{"episode_reward": 939.4456426784426, "episode": 135.0, "batch_reward": 0.818922613978386, "critic_loss": 0.6356322483122349, "actor_loss": -99.37478663635254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.691153049468994, "step": 135000}
{"episode_reward": 934.4892237633428, "episode": 136.0, "batch_reward": 0.8215153706669808, "critic_loss": 0.6168491456508637, "actor_loss": -100.1651828918457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.19636845588684, "step": 136000}
{"episode_reward": 943.5967162773762, "episode": 137.0, "batch_reward": 0.8209794238209724, "critic_loss": 0.5978058567047119, "actor_loss": -99.36536074829101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.93943738937378, "step": 137000}
{"episode_reward": 971.9123693134597, "episode": 138.0, "batch_reward": 0.8239518828988075, "critic_loss": 0.5973253319263458, "actor_loss": -98.69518740844727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.633726835250854, "step": 138000}
{"episode_reward": 983.2843003660516, "episode": 139.0, "batch_reward": 0.8233143065571785, "critic_loss": 0.5864633480757475, "actor_loss": -99.79768547058106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.64212656021118, "step": 139000}
{"episode_reward": 903.9471450750855, "episode": 140.0, "batch_reward": 0.8254534925222397, "critic_loss": 0.5724482256770134, "actor_loss": -98.64305764770508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.1867938041687, "step": 140000}
{"episode_reward": 983.1760077141844, "episode": 141.0, "batch_reward": 0.8238415478467941, "critic_loss": 0.5499169585108757, "actor_loss": -97.79489051818848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.917534828186035, "step": 141000}
{"episode_reward": 968.3658481820988, "episode": 142.0, "batch_reward": 0.8260489235520363, "critic_loss": 0.5388181896209717, "actor_loss": -98.42061878967286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.64289164543152, "step": 142000}
{"episode_reward": 954.0423193513985, "episode": 143.0, "batch_reward": 0.8270709986686706, "critic_loss": 0.5306591845303774, "actor_loss": -98.19090589904785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.559810400009155, "step": 143000}
{"episode_reward": 976.6202367949559, "episode": 144.0, "batch_reward": 0.8292620279788971, "critic_loss": 0.49447686959803105, "actor_loss": -97.81592698669434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.433159351348877, "step": 144000}
{"episode_reward": 938.4942562455924, "episode": 145.0, "batch_reward": 0.8297366349697113, "critic_loss": 0.4870822866111994, "actor_loss": -97.02676330566406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.03864049911499, "step": 145000}
{"episode_reward": 935.7179853567707, "episode": 146.0, "batch_reward": 0.8315014340281487, "critic_loss": 0.46599291457235814, "actor_loss": -96.62909727478028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.444424390792847, "step": 146000}
{"episode_reward": 982.2661056232251, "episode": 147.0, "batch_reward": 0.8307626469731331, "critic_loss": 0.4633775392025709, "actor_loss": -96.71279740905761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.813183069229126, "step": 147000}
{"episode_reward": 931.8118049546074, "episode": 148.0, "batch_reward": 0.8309204901456833, "critic_loss": 0.481715090572834, "actor_loss": -96.5409813079834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.713408946990967, "step": 148000}
{"episode_reward": 931.7081103339524, "episode": 149.0, "batch_reward": 0.8326688300967217, "critic_loss": 0.4751519950181246, "actor_loss": -96.4993133239746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.206157207489014, "step": 149000}
{"episode_reward": 976.1272040891827, "episode": 150.0, "batch_reward": 0.8310655049681663, "critic_loss": 0.5217925159335136, "actor_loss": -95.88047344970703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
