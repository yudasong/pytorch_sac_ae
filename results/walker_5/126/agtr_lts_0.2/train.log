{"episode_reward": 0.0, "episode": 1.0, "duration": 20.497186422348022, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.779285192489624, "step": 2000}
{"episode_reward": 847.8889533166544, "episode": 3.0, "batch_reward": 0.4768460625090095, "critic_loss": 0.29693576673411576, "actor_loss": -86.99645670951486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.97669291496277, "step": 3000}
{"episode_reward": 864.7900171586656, "episode": 4.0, "batch_reward": 0.5925347055792809, "critic_loss": 0.7543692112863064, "actor_loss": -91.79727713012696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91716241836548, "step": 4000}
{"episode_reward": 735.7094683981885, "episode": 5.0, "batch_reward": 0.6544361704587937, "critic_loss": 0.519638453155756, "actor_loss": -93.92113088989258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.887089729309082, "step": 5000}
{"episode_reward": 941.5843116844821, "episode": 6.0, "batch_reward": 0.6316574347317219, "critic_loss": 0.7154057081639766, "actor_loss": -95.30454261779785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.912977933883667, "step": 6000}
{"episode_reward": 47.84123155891187, "episode": 7.0, "batch_reward": 0.6001163676679134, "critic_loss": 0.7095888825058937, "actor_loss": -95.97168437194824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.897902727127075, "step": 7000}
{"episode_reward": 850.99365698796, "episode": 8.0, "batch_reward": 0.6389318287968636, "critic_loss": 0.6559567260146141, "actor_loss": -95.60872668457031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89317035675049, "step": 8000}
{"episode_reward": 939.175447014754, "episode": 9.0, "batch_reward": 0.6272367896139621, "critic_loss": 0.8815063967108726, "actor_loss": -96.51684228515624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91322350502014, "step": 9000}
{"episode_reward": 98.15782396476308, "episode": 10.0, "batch_reward": 0.5784867001175881, "critic_loss": 1.076998751282692, "actor_loss": -96.55537292480469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8967502117157, "step": 10000}
{"episode_reward": 257.5909321956112, "episode": 11.0, "batch_reward": 0.540821709394455, "critic_loss": 0.8821620378792286, "actor_loss": -96.50226403808594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.30143642425537, "step": 11000}
{"episode_reward": 62.937121452300296, "episode": 12.0, "batch_reward": 0.532344204068184, "critic_loss": 0.6197915980517864, "actor_loss": -95.32738145446777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89784836769104, "step": 12000}
{"episode_reward": 908.5749550476253, "episode": 13.0, "batch_reward": 0.5530034346282482, "critic_loss": 0.505072375535965, "actor_loss": -95.11036404418945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91096019744873, "step": 13000}
{"episode_reward": 805.7311637374221, "episode": 14.0, "batch_reward": 0.5619385918080807, "critic_loss": 0.49011962896585465, "actor_loss": -94.6610631866455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91912841796875, "step": 14000}
{"episode_reward": 494.9524360983911, "episode": 15.0, "batch_reward": 0.5721268242895603, "critic_loss": 0.4534793050289154, "actor_loss": -94.20943998718262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9030122756958, "step": 15000}
{"episode_reward": 854.406054253032, "episode": 16.0, "batch_reward": 0.5919903320372104, "critic_loss": 0.457622117087245, "actor_loss": -93.15039234924316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.910080432891846, "step": 16000}
{"episode_reward": 936.121839369649, "episode": 17.0, "batch_reward": 0.6123741011619568, "critic_loss": 0.4514675888866186, "actor_loss": -92.55042881774902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91282558441162, "step": 17000}
{"episode_reward": 902.27330131602, "episode": 18.0, "batch_reward": 0.6268987899720668, "critic_loss": 0.4443723124563694, "actor_loss": -92.44306864929199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89620566368103, "step": 18000}
{"episode_reward": 805.4089363767487, "episode": 19.0, "batch_reward": 0.6423244016766548, "critic_loss": 0.4493831882178783, "actor_loss": -92.21419075012207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.903923273086548, "step": 19000}
{"episode_reward": 980.2238091564125, "episode": 20.0, "batch_reward": 0.6571022768616677, "critic_loss": 0.43264579463005065, "actor_loss": -92.35180004882812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9098117351532, "step": 20000}
{"episode_reward": 952.5275526219531, "episode": 21.0, "batch_reward": 0.6751585926413536, "critic_loss": 0.4090742763876915, "actor_loss": -92.4933821105957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.14358305931091, "step": 21000}
{"episode_reward": 988.4383024587455, "episode": 22.0, "batch_reward": 0.685056032538414, "critic_loss": 0.45407132840156555, "actor_loss": -92.96417347717285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.890236139297485, "step": 22000}
{"episode_reward": 890.5820683002731, "episode": 23.0, "batch_reward": 0.6903498275876045, "critic_loss": 0.5008911754190922, "actor_loss": -93.05035577392579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89400577545166, "step": 23000}
{"episode_reward": 801.8184033790448, "episode": 24.0, "batch_reward": 0.7009792867302894, "critic_loss": 0.44656043815612795, "actor_loss": -93.22552697753906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.900585174560547, "step": 24000}
{"episode_reward": 972.5670015350056, "episode": 25.0, "batch_reward": 0.7115786559581757, "critic_loss": 0.4336127974838018, "actor_loss": -93.41921139526367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.886940956115723, "step": 25000}
{"episode_reward": 946.7183014766582, "episode": 26.0, "batch_reward": 0.7210385304689407, "critic_loss": 0.4194016050696373, "actor_loss": -93.53090745544434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.886959552764893, "step": 26000}
{"episode_reward": 975.8341410007621, "episode": 27.0, "batch_reward": 0.7318361263871193, "critic_loss": 0.4026542058438063, "actor_loss": -93.87345146179199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88327670097351, "step": 27000}
{"episode_reward": 978.1171893155173, "episode": 28.0, "batch_reward": 0.7384977291226387, "critic_loss": 0.37689230433106424, "actor_loss": -93.7830065460205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.894935607910156, "step": 28000}
{"episode_reward": 941.4187271202597, "episode": 29.0, "batch_reward": 0.748194484770298, "critic_loss": 0.367229196742177, "actor_loss": -94.0445717163086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.896977186203003, "step": 29000}
{"episode_reward": 968.3528810791455, "episode": 30.0, "batch_reward": 0.7517797309756279, "critic_loss": 0.3754551550745964, "actor_loss": -93.95890907287598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90730381011963, "step": 30000}
{"episode_reward": 925.4350536857088, "episode": 31.0, "batch_reward": 0.756882521033287, "critic_loss": 0.4257934403270483, "actor_loss": -93.92859440612793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.13529562950134, "step": 31000}
{"episode_reward": 908.8006220213766, "episode": 32.0, "batch_reward": 0.7668671714663505, "critic_loss": 0.3854040642082691, "actor_loss": -94.15041355895995, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.894217491149902, "step": 32000}
{"episode_reward": 970.5894980447192, "episode": 33.0, "batch_reward": 0.7699100447297096, "critic_loss": 0.3542900468707085, "actor_loss": -94.1015096282959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88901996612549, "step": 33000}
{"episode_reward": 949.7202971547244, "episode": 34.0, "batch_reward": 0.7768923306465149, "critic_loss": 0.3442962532937527, "actor_loss": -94.14920637512208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91460871696472, "step": 34000}
{"episode_reward": 954.1262975188504, "episode": 35.0, "batch_reward": 0.7766036257743836, "critic_loss": 0.3856166423410177, "actor_loss": -94.06260829162598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.903950691223145, "step": 35000}
{"episode_reward": 814.3970948654239, "episode": 36.0, "batch_reward": 0.7827924756407738, "critic_loss": 0.28350829720497134, "actor_loss": -94.06529231262208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.896113634109497, "step": 36000}
{"episode_reward": 967.7982333450469, "episode": 37.0, "batch_reward": 0.7885083773732185, "critic_loss": 0.3260177066773176, "actor_loss": -94.12749655151367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.904353857040405, "step": 37000}
{"episode_reward": 959.8311873016543, "episode": 38.0, "batch_reward": 0.7930241023302078, "critic_loss": 0.2812438007667661, "actor_loss": -94.25070820617675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.900732040405273, "step": 38000}
{"episode_reward": 981.203431990892, "episode": 39.0, "batch_reward": 0.7963067829012871, "critic_loss": 0.29371456772834065, "actor_loss": -94.22838343811036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89840078353882, "step": 39000}
{"episode_reward": 952.099759434829, "episode": 40.0, "batch_reward": 0.7997583879828453, "critic_loss": 0.2919940366521478, "actor_loss": -94.20449555969239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.920513153076172, "step": 40000}
{"episode_reward": 932.5978962468143, "episode": 41.0, "batch_reward": 0.8039740227460861, "critic_loss": 0.28546066238731144, "actor_loss": -94.2461951599121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.17576241493225, "step": 41000}
{"episode_reward": 962.9519889268075, "episode": 42.0, "batch_reward": 0.8074652429819107, "critic_loss": 0.2754667847082019, "actor_loss": -94.26812048339843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.929065227508545, "step": 42000}
{"episode_reward": 938.784203414386, "episode": 43.0, "batch_reward": 0.8112345371842384, "critic_loss": 0.27698956334590913, "actor_loss": -94.31897714233398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91353964805603, "step": 43000}
{"episode_reward": 944.4420770874516, "episode": 44.0, "batch_reward": 0.8148284933567047, "critic_loss": 0.272531686976552, "actor_loss": -94.24841230773926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.886050701141357, "step": 44000}
{"episode_reward": 955.5939596945161, "episode": 45.0, "batch_reward": 0.8179337807297706, "critic_loss": 0.26971148275583984, "actor_loss": -94.34575415039062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.907092094421387, "step": 45000}
{"episode_reward": 951.5605497485894, "episode": 46.0, "batch_reward": 0.8218426473140716, "critic_loss": 0.2713776858523488, "actor_loss": -94.36245770263672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.879178524017334, "step": 46000}
{"episode_reward": 979.3792504173581, "episode": 47.0, "batch_reward": 0.8227200129032135, "critic_loss": 0.27390475148707627, "actor_loss": -94.33040182495117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89073896408081, "step": 47000}
{"episode_reward": 934.3505046456642, "episode": 48.0, "batch_reward": 0.8263176696896553, "critic_loss": 0.28982791428267957, "actor_loss": -94.44782890319824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.889999628067017, "step": 48000}
{"episode_reward": 949.9344791980998, "episode": 49.0, "batch_reward": 0.8281363272070885, "critic_loss": 0.29028314481675627, "actor_loss": -94.48362335205078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.889840126037598, "step": 49000}
{"episode_reward": 878.5642225284611, "episode": 50.0, "batch_reward": 0.8297530006766319, "critic_loss": 0.30165004924684763, "actor_loss": -94.46556349182129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.886579513549805, "step": 50000}
{"episode_reward": 863.3803544922939, "episode": 51.0, "batch_reward": 0.8302249438166618, "critic_loss": 0.2929609701782465, "actor_loss": -94.5563225402832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.129968881607056, "step": 51000}
{"episode_reward": 948.1390813452679, "episode": 52.0, "batch_reward": 0.8320526546835899, "critic_loss": 0.28235974519699814, "actor_loss": -94.51984889221191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.890658855438232, "step": 52000}
{"episode_reward": 949.8995609821949, "episode": 53.0, "batch_reward": 0.8362939732670784, "critic_loss": 0.2755238207504153, "actor_loss": -94.65033164978027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.894052505493164, "step": 53000}
{"episode_reward": 955.739596201781, "episode": 54.0, "batch_reward": 0.8369234371185302, "critic_loss": 0.2836188353300095, "actor_loss": -94.61488319396973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90706157684326, "step": 54000}
{"episode_reward": 945.0049233903978, "episode": 55.0, "batch_reward": 0.8374745609760285, "critic_loss": 0.29478036607801916, "actor_loss": -94.5547548828125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.912634134292603, "step": 55000}
{"episode_reward": 938.9361729799188, "episode": 56.0, "batch_reward": 0.8415614402294159, "critic_loss": 0.30188580122590064, "actor_loss": -94.72457742309571, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.925841569900513, "step": 56000}
{"episode_reward": 983.4546455950532, "episode": 57.0, "batch_reward": 0.8446465624570847, "critic_loss": 0.2840775573775172, "actor_loss": -94.68303530883789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92106866836548, "step": 57000}
{"episode_reward": 963.0405961417156, "episode": 58.0, "batch_reward": 0.8467277771234513, "critic_loss": 0.2867078472748399, "actor_loss": -94.79142234802246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.911900758743286, "step": 58000}
{"episode_reward": 974.2813393947692, "episode": 59.0, "batch_reward": 0.8485044138431549, "critic_loss": 0.25825249730050565, "actor_loss": -94.80773100280761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89319634437561, "step": 59000}
{"episode_reward": 982.9369321524807, "episode": 60.0, "batch_reward": 0.8492863969802856, "critic_loss": 0.26869986789673567, "actor_loss": -94.83007650756836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.899885416030884, "step": 60000}
{"episode_reward": 891.4953500757779, "episode": 61.0, "batch_reward": 0.8513673105835915, "critic_loss": 0.29069785374403, "actor_loss": -94.81710487365723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.13846254348755, "step": 61000}
{"episode_reward": 938.1983481949612, "episode": 62.0, "batch_reward": 0.8517177605032921, "critic_loss": 0.2784198754504323, "actor_loss": -94.8752583618164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.920644998550415, "step": 62000}
{"episode_reward": 989.1337639936078, "episode": 63.0, "batch_reward": 0.8525692120790481, "critic_loss": 0.26458496364206074, "actor_loss": -94.87189907836914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.898412704467773, "step": 63000}
{"episode_reward": 988.2330868813955, "episode": 64.0, "batch_reward": 0.8558152661919594, "critic_loss": 0.27791343170404437, "actor_loss": -94.99609941101075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.906465530395508, "step": 64000}
{"episode_reward": 906.0932084396422, "episode": 65.0, "batch_reward": 0.8557960317134857, "critic_loss": 0.29978167431801556, "actor_loss": -94.95847012329102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.898975610733032, "step": 65000}
{"episode_reward": 881.0463885649878, "episode": 66.0, "batch_reward": 0.8575396037697792, "critic_loss": 0.26215360142290595, "actor_loss": -94.94750616455079, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.903539180755615, "step": 66000}
{"episode_reward": 983.9430202479836, "episode": 67.0, "batch_reward": 0.8606318960785866, "critic_loss": 0.27587592946738004, "actor_loss": -95.02519216918945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.919261932373047, "step": 67000}
{"episode_reward": 952.5494695086406, "episode": 68.0, "batch_reward": 0.8616764122247695, "critic_loss": 0.2880177903324366, "actor_loss": -95.00252372741699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91766119003296, "step": 68000}
{"episode_reward": 961.2592322139911, "episode": 69.0, "batch_reward": 0.8617694920301437, "critic_loss": 0.27116105004400015, "actor_loss": -94.96058210754394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.914087533950806, "step": 69000}
{"episode_reward": 984.0413692809893, "episode": 70.0, "batch_reward": 0.8644453445672989, "critic_loss": 0.2400533981770277, "actor_loss": -95.0081015625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91918921470642, "step": 70000}
{"episode_reward": 953.84869323053, "episode": 71.0, "batch_reward": 0.8647297803163528, "critic_loss": 0.26913645708560946, "actor_loss": -95.02371156311035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.13786029815674, "step": 71000}
{"episode_reward": 940.960817215196, "episode": 72.0, "batch_reward": 0.866969239115715, "critic_loss": 0.27490763857215644, "actor_loss": -95.07088024902343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.917856216430664, "step": 72000}
{"episode_reward": 949.3748201206579, "episode": 73.0, "batch_reward": 0.8670516795516015, "critic_loss": 0.26266568338125945, "actor_loss": -95.0500064239502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.922725439071655, "step": 73000}
{"episode_reward": 984.1480850440015, "episode": 74.0, "batch_reward": 0.8708177081942559, "critic_loss": 0.23217065382003785, "actor_loss": -95.17592454528808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.912028074264526, "step": 74000}
{"episode_reward": 969.4032132063705, "episode": 75.0, "batch_reward": 0.8713788338303566, "critic_loss": 0.23966690304875374, "actor_loss": -95.19325578308106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91118025779724, "step": 75000}
{"episode_reward": 971.1122089639974, "episode": 76.0, "batch_reward": 0.8720659129023552, "critic_loss": 0.2508606339544058, "actor_loss": -95.18139447021484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.895331382751465, "step": 76000}
{"episode_reward": 954.6514695797885, "episode": 77.0, "batch_reward": 0.8733648119568824, "critic_loss": 0.2342216071113944, "actor_loss": -95.2344588470459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.900927543640137, "step": 77000}
{"episode_reward": 937.7810518192388, "episode": 78.0, "batch_reward": 0.8746150656342506, "critic_loss": 0.23691732220351697, "actor_loss": -95.26417085266114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.898059844970703, "step": 78000}
{"episode_reward": 960.5748403206123, "episode": 79.0, "batch_reward": 0.8753729581236839, "critic_loss": 0.2325873594433069, "actor_loss": -95.33497442626953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.905736684799194, "step": 79000}
{"episode_reward": 957.9698169411118, "episode": 80.0, "batch_reward": 0.8770987187623978, "critic_loss": 0.23359643311053516, "actor_loss": -95.33200540161133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.901877641677856, "step": 80000}
{"episode_reward": 985.0281456824074, "episode": 81.0, "batch_reward": 0.8762862084507942, "critic_loss": 0.23952727683633565, "actor_loss": -95.30928970336915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.164912700653076, "step": 81000}
{"episode_reward": 924.3054053531885, "episode": 82.0, "batch_reward": 0.8781570082306862, "critic_loss": 0.23505361238121986, "actor_loss": -95.37724630737304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.916532278060913, "step": 82000}
{"episode_reward": 964.6941709028706, "episode": 83.0, "batch_reward": 0.8784417809844017, "critic_loss": 0.23286544761806727, "actor_loss": -95.35554682922363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91646981239319, "step": 83000}
{"episode_reward": 959.6363954205673, "episode": 84.0, "batch_reward": 0.8800350875854492, "critic_loss": 0.24040897732228042, "actor_loss": -95.44472137451172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.907223224639893, "step": 84000}
{"episode_reward": 957.4475571672222, "episode": 85.0, "batch_reward": 0.8789371853470802, "critic_loss": 0.23982471770793198, "actor_loss": -95.42116925048828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.922614574432373, "step": 85000}
{"episode_reward": 964.4267537805497, "episode": 86.0, "batch_reward": 0.8814146976470947, "critic_loss": 0.23057315267622472, "actor_loss": -95.44121951293945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.159908771514893, "step": 86000}
{"episode_reward": 959.3078154847473, "episode": 87.0, "batch_reward": 0.8825393922328949, "critic_loss": 0.23208394507318736, "actor_loss": -95.5318079071045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.944992780685425, "step": 87000}
{"episode_reward": 937.7018466236416, "episode": 88.0, "batch_reward": 0.8836187384128571, "critic_loss": 0.23547663055360318, "actor_loss": -95.53331793212891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.188647747039795, "step": 88000}
{"episode_reward": 979.289235207041, "episode": 89.0, "batch_reward": 0.8835715215802192, "critic_loss": 0.22943719320744277, "actor_loss": -95.61374403381348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.85209012031555, "step": 89000}
{"episode_reward": 964.4801692957546, "episode": 90.0, "batch_reward": 0.8847775509953499, "critic_loss": 0.22108665696531535, "actor_loss": -95.67730690002442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.873138427734375, "step": 90000}
{"episode_reward": 987.5409560569559, "episode": 91.0, "batch_reward": 0.8861092353463172, "critic_loss": 0.2203328413888812, "actor_loss": -95.6250864868164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.158764123916626, "step": 91000}
{"episode_reward": 950.3005249193908, "episode": 92.0, "batch_reward": 0.8883897656202316, "critic_loss": 0.2437801453843713, "actor_loss": -95.71291116333008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89929962158203, "step": 92000}
{"episode_reward": 972.3764678805352, "episode": 93.0, "batch_reward": 0.8896824240684509, "critic_loss": 0.22514628225564956, "actor_loss": -95.7400659942627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.909792184829712, "step": 93000}
{"episode_reward": 987.4297304453345, "episode": 94.0, "batch_reward": 0.8891285870075226, "critic_loss": 0.23252194602042436, "actor_loss": -95.7219394683838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92500400543213, "step": 94000}
{"episode_reward": 939.5871594102591, "episode": 95.0, "batch_reward": 0.8903466774821281, "critic_loss": 0.23470091991871594, "actor_loss": -95.82073664855957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.931689262390137, "step": 95000}
{"episode_reward": 966.99205347865, "episode": 96.0, "batch_reward": 0.8901066847443581, "critic_loss": 0.22191658033430575, "actor_loss": -95.67965554809571, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.917179346084595, "step": 96000}
{"episode_reward": 959.2512130374408, "episode": 97.0, "batch_reward": 0.8910810113549232, "critic_loss": 0.2285390317365527, "actor_loss": -95.74238377380371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.918622732162476, "step": 97000}
{"episode_reward": 954.7540983449585, "episode": 98.0, "batch_reward": 0.8905187339186669, "critic_loss": 0.20789261685311794, "actor_loss": -95.79339923095704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.893688678741455, "step": 98000}
{"episode_reward": 946.8687522911196, "episode": 99.0, "batch_reward": 0.8933595054745674, "critic_loss": 0.2233755572140217, "actor_loss": -95.76358868408204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.901347875595093, "step": 99000}
{"episode_reward": 923.0920009831036, "episode": 100.0, "batch_reward": 0.8923196868896485, "critic_loss": 0.22144631297886372, "actor_loss": -95.74516032409667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89455485343933, "step": 100000}
{"episode_reward": 985.546732498561, "episode": 101.0, "batch_reward": 0.8937762121558189, "critic_loss": 0.21144062606990338, "actor_loss": -95.74130354309082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.19476890563965, "step": 101000}
{"episode_reward": 987.9738014516914, "episode": 102.0, "batch_reward": 0.8945387210845948, "critic_loss": 0.22299839247763156, "actor_loss": -95.75689289855957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90550971031189, "step": 102000}
{"episode_reward": 981.0777042349418, "episode": 103.0, "batch_reward": 0.8957186847329139, "critic_loss": 0.23231716588139534, "actor_loss": -95.82154876708984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.905529975891113, "step": 103000}
{"episode_reward": 943.3770024885072, "episode": 104.0, "batch_reward": 0.8946383002400399, "critic_loss": 0.23997296231240034, "actor_loss": -95.79302336120605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89636492729187, "step": 104000}
{"episode_reward": 923.961203199889, "episode": 105.0, "batch_reward": 0.897531578719616, "critic_loss": 0.22508726325631143, "actor_loss": -95.85436683654785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91529870033264, "step": 105000}
{"episode_reward": 986.9302155354584, "episode": 106.0, "batch_reward": 0.8969945663809776, "critic_loss": 0.2232866688594222, "actor_loss": -95.89604315185547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.898030042648315, "step": 106000}
{"episode_reward": 960.2853304386643, "episode": 107.0, "batch_reward": 0.897524196445942, "critic_loss": 0.247066339969635, "actor_loss": -95.8909990386963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92168354988098, "step": 107000}
{"episode_reward": 953.9559878586228, "episode": 108.0, "batch_reward": 0.8967174252271652, "critic_loss": 0.2462827727124095, "actor_loss": -95.90019801330567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.924167156219482, "step": 108000}
{"episode_reward": 946.5512902460065, "episode": 109.0, "batch_reward": 0.8977567816972732, "critic_loss": 0.22044061021506786, "actor_loss": -95.91368714904785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.918517589569092, "step": 109000}
{"episode_reward": 974.1578749495728, "episode": 110.0, "batch_reward": 0.8996964859366416, "critic_loss": 0.2126464405655861, "actor_loss": -95.92661221313476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89364981651306, "step": 110000}
{"episode_reward": 958.927978770375, "episode": 111.0, "batch_reward": 0.8993278224468231, "critic_loss": 0.20251545188575984, "actor_loss": -95.97426454162597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.16679501533508, "step": 111000}
{"episode_reward": 979.3279175814171, "episode": 112.0, "batch_reward": 0.9009923102855683, "critic_loss": 0.22717878066748382, "actor_loss": -95.97564215087891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.898158311843872, "step": 112000}
{"episode_reward": 952.7740525254741, "episode": 113.0, "batch_reward": 0.9012603132724762, "critic_loss": 0.22107745180279018, "actor_loss": -96.03378234863281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9077045917511, "step": 113000}
{"episode_reward": 967.6831416335862, "episode": 114.0, "batch_reward": 0.9008396735787392, "critic_loss": 0.21523033974319697, "actor_loss": -95.96586492919921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90005660057068, "step": 114000}
{"episode_reward": 986.7684487777889, "episode": 115.0, "batch_reward": 0.9018687893152237, "critic_loss": 0.2293739740923047, "actor_loss": -96.04432005310059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.898595333099365, "step": 115000}
{"episode_reward": 935.652537022495, "episode": 116.0, "batch_reward": 0.9033277077674866, "critic_loss": 0.22297670284658672, "actor_loss": -96.09166110229492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.910231828689575, "step": 116000}
{"episode_reward": 940.3600061285011, "episode": 117.0, "batch_reward": 0.9016968107819557, "critic_loss": 0.21675128907710314, "actor_loss": -96.03839654541015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90803813934326, "step": 117000}
{"episode_reward": 954.5430042523756, "episode": 118.0, "batch_reward": 0.903063741505146, "critic_loss": 0.23123190730065107, "actor_loss": -96.05985940551759, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.919728755950928, "step": 118000}
{"episode_reward": 959.9880102920454, "episode": 119.0, "batch_reward": 0.9042064145803451, "critic_loss": 0.21903824558109045, "actor_loss": -96.10259205627442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.904618978500366, "step": 119000}
{"episode_reward": 976.1472550330972, "episode": 120.0, "batch_reward": 0.9038738505244255, "critic_loss": 0.2271277093142271, "actor_loss": -96.12175408935546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.901405572891235, "step": 120000}
{"episode_reward": 982.447766646793, "episode": 121.0, "batch_reward": 0.9055904996991158, "critic_loss": 0.20822513879835605, "actor_loss": -96.11190640258789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.215434551239014, "step": 121000}
{"episode_reward": 961.8202238013833, "episode": 122.0, "batch_reward": 0.905395149230957, "critic_loss": 0.21085314144939185, "actor_loss": -96.12457215881348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.908228874206543, "step": 122000}
{"episode_reward": 949.5430563262015, "episode": 123.0, "batch_reward": 0.9060269909501075, "critic_loss": 0.21704793574661016, "actor_loss": -96.13240893554688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8976411819458, "step": 123000}
{"episode_reward": 974.8278696550473, "episode": 124.0, "batch_reward": 0.9067444246411324, "critic_loss": 0.2098001830279827, "actor_loss": -96.15295602416992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89744281768799, "step": 124000}
{"episode_reward": 980.8127421076265, "episode": 125.0, "batch_reward": 0.907770768225193, "critic_loss": 0.19233737826347352, "actor_loss": -96.2273572998047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.897125482559204, "step": 125000}
{"episode_reward": 984.9745903055156, "episode": 126.0, "batch_reward": 0.9079441462755203, "critic_loss": 0.21078034748136998, "actor_loss": -96.20063676452637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93926978111267, "step": 126000}
{"episode_reward": 970.7963141397295, "episode": 127.0, "batch_reward": 0.9069165159463882, "critic_loss": 0.21292559657990934, "actor_loss": -96.14156323242187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91208553314209, "step": 127000}
{"episode_reward": 984.5133620193268, "episode": 128.0, "batch_reward": 0.9069365881085396, "critic_loss": 0.22012419708818198, "actor_loss": -96.18896406555176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.904982566833496, "step": 128000}
{"episode_reward": 968.0352116078195, "episode": 129.0, "batch_reward": 0.9086410017609596, "critic_loss": 0.21532399320602416, "actor_loss": -96.2556873474121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90579342842102, "step": 129000}
{"episode_reward": 984.0620300270463, "episode": 130.0, "batch_reward": 0.9116480199694633, "critic_loss": 0.2152974646911025, "actor_loss": -96.32799209594727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89843201637268, "step": 130000}
{"episode_reward": 958.2780226036116, "episode": 131.0, "batch_reward": 0.909973285138607, "critic_loss": 0.21301137026026845, "actor_loss": -96.2769224395752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.1766939163208, "step": 131000}
{"episode_reward": 961.5052353989531, "episode": 132.0, "batch_reward": 0.9108860511779785, "critic_loss": 0.20222782952338458, "actor_loss": -96.31824516296386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.914795398712158, "step": 132000}
{"episode_reward": 976.1544229416984, "episode": 133.0, "batch_reward": 0.9115844506621361, "critic_loss": 0.20689852016791702, "actor_loss": -96.3665065460205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.927917957305908, "step": 133000}
{"episode_reward": 971.9159815519708, "episode": 134.0, "batch_reward": 0.9105246587991714, "critic_loss": 0.1968598625846207, "actor_loss": -96.39252459716796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.905908584594727, "step": 134000}
{"episode_reward": 958.1446764162336, "episode": 135.0, "batch_reward": 0.9119466140270233, "critic_loss": 0.20573209604248405, "actor_loss": -96.34881771850586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.910417795181274, "step": 135000}
{"episode_reward": 933.6216388991852, "episode": 136.0, "batch_reward": 0.9125299614071846, "critic_loss": 0.2181815331503749, "actor_loss": -96.40907472229004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.909957885742188, "step": 136000}
{"episode_reward": 967.8555952257444, "episode": 137.0, "batch_reward": 0.9117085314393043, "critic_loss": 0.19048109352216125, "actor_loss": -96.3880302734375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.232951879501343, "step": 137000}
{"episode_reward": 987.0945328798291, "episode": 138.0, "batch_reward": 0.9148125621080399, "critic_loss": 0.1947577467225492, "actor_loss": -96.4421999206543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89664363861084, "step": 138000}
{"episode_reward": 985.4860952052544, "episode": 139.0, "batch_reward": 0.9129124707579612, "critic_loss": 0.19041500690951943, "actor_loss": -96.48072729492188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.882017374038696, "step": 139000}
{"episode_reward": 960.5784201012909, "episode": 140.0, "batch_reward": 0.9153978707790374, "critic_loss": 0.19107567016035318, "actor_loss": -96.45701681518554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.882054805755615, "step": 140000}
{"episode_reward": 983.2578288558935, "episode": 141.0, "batch_reward": 0.9134627614021301, "critic_loss": 0.19064757205173374, "actor_loss": -96.38860459899902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.19500160217285, "step": 141000}
{"episode_reward": 965.9737898787486, "episode": 142.0, "batch_reward": 0.9144789656996727, "critic_loss": 0.1911959364525974, "actor_loss": -96.51096180725098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88910460472107, "step": 142000}
{"episode_reward": 985.1747012234067, "episode": 143.0, "batch_reward": 0.9148782531619072, "critic_loss": 0.2084727366119623, "actor_loss": -96.4926314239502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.900116682052612, "step": 143000}
{"episode_reward": 878.0915218188766, "episode": 144.0, "batch_reward": 0.9145861191749572, "critic_loss": 0.2123395676165819, "actor_loss": -96.50625468444824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90845251083374, "step": 144000}
{"episode_reward": 911.8997248836863, "episode": 145.0, "batch_reward": 0.9155883560776711, "critic_loss": 0.2068018375746906, "actor_loss": -96.51203094482422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9193115234375, "step": 145000}
{"episode_reward": 948.6375525536355, "episode": 146.0, "batch_reward": 0.9155767449736595, "critic_loss": 0.2034309873059392, "actor_loss": -96.51524520874024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.930179357528687, "step": 146000}
{"episode_reward": 976.4085271909823, "episode": 147.0, "batch_reward": 0.9155032232403755, "critic_loss": 0.2189376485720277, "actor_loss": -96.51311239624023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.920352697372437, "step": 147000}
{"episode_reward": 957.9190704299741, "episode": 148.0, "batch_reward": 0.9153686212301254, "critic_loss": 0.2142865707948804, "actor_loss": -96.47476077270508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.920846700668335, "step": 148000}
{"episode_reward": 959.9657956680778, "episode": 149.0, "batch_reward": 0.9158541214466095, "critic_loss": 0.20977595439180732, "actor_loss": -96.52987214660645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90072274208069, "step": 149000}
{"episode_reward": 989.1241217792073, "episode": 150.0, "batch_reward": 0.9148043996095657, "critic_loss": 0.21750559805333614, "actor_loss": -96.42344122314454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
