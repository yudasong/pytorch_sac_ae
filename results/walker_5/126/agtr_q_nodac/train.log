{"episode": 1.0, "duration": 21.35334825515747, "episode_reward": 51.16415125024753, "step": 1000}
{"episode": 2.0, "duration": 1.8049635887145996, "episode_reward": 519.9299312670827, "step": 2000}
{"episode": 3.0, "batch_reward": 0.28021790709802413, "actor_loss": -69.04317377891098, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 66.50677442550659, "episode_reward": 277.39304716193584, "step": 3000}
{"episode": 4.0, "batch_reward": 0.3150919492989778, "actor_loss": -70.69592295837403, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.637935161590576, "episode_reward": 467.05659379456756, "step": 4000}
{"episode": 5.0, "batch_reward": 0.34834290406107904, "actor_loss": -71.67697221374512, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.46455430984497, "episode_reward": 596.0462824213713, "step": 5000}
{"episode": 6.0, "batch_reward": 0.42697786447405817, "actor_loss": -73.64037989807129, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.154131412506104, "episode_reward": 918.6686957114007, "step": 6000}
{"episode": 7.0, "batch_reward": 0.4817369885444641, "actor_loss": -75.27707933044434, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.223193645477295, "episode_reward": 736.3022324671301, "step": 7000}
{"episode": 8.0, "batch_reward": 0.5244864656329155, "actor_loss": -76.61987503051758, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.0238299369812, "episode_reward": 834.7493736220764, "step": 8000}
{"episode": 9.0, "batch_reward": 0.5610073552429676, "actor_loss": -77.58159101867676, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.08859658241272, "episode_reward": 669.4329821342822, "step": 9000}
{"episode": 10.0, "batch_reward": 0.573578369319439, "actor_loss": -78.03573686218262, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.452383518218994, "episode_reward": 708.092673854625, "step": 10000}
{"episode": 11.0, "batch_reward": 0.5786338856518268, "actor_loss": -78.27056387329101, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.921685457229614, "episode_reward": 641.4376665014521, "step": 11000}
{"episode": 12.0, "batch_reward": 0.5918214861154556, "actor_loss": -78.70020190429688, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.52999496459961, "episode_reward": 740.5440330965785, "step": 12000}
{"episode": 13.0, "batch_reward": 0.5989726248681545, "actor_loss": -78.85615951538085, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.372234344482422, "episode_reward": 786.1705277347196, "step": 13000}
{"episode": 14.0, "batch_reward": 0.6187720171809197, "actor_loss": -79.38053421020508, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.439462423324585, "episode_reward": 749.9452888639046, "step": 14000}
{"episode": 15.0, "batch_reward": 0.6265628764629364, "actor_loss": -79.6608782043457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.583991527557373, "episode_reward": 761.1526365305608, "step": 15000}
{"episode": 16.0, "batch_reward": 0.6260372681617736, "actor_loss": -79.70785102844238, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.21732997894287, "episode_reward": 585.4165422749531, "step": 16000}
{"episode": 17.0, "batch_reward": 0.6288286698460579, "actor_loss": -79.8750128479004, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.170680284500122, "episode_reward": 687.955721309373, "step": 17000}
{"episode": 18.0, "batch_reward": 0.6291406960487366, "actor_loss": -79.89632844543458, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.769070625305176, "episode_reward": 619.0785015708865, "step": 18000}
{"episode": 19.0, "batch_reward": 0.6330790639519691, "actor_loss": -79.99211424255371, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.743394136428833, "episode_reward": 641.9764635454013, "step": 19000}
{"episode": 20.0, "batch_reward": 0.6331211671233177, "actor_loss": -79.95922465515137, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.181241035461426, "episode_reward": 674.2601677019622, "step": 20000}
{"episode": 21.0, "batch_reward": 0.6307265676259994, "actor_loss": -79.94216152954101, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.003236532211304, "episode_reward": 613.7458266200691, "step": 21000}
{"episode": 22.0, "batch_reward": 0.6298711127042771, "actor_loss": -79.9750227355957, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.331392288208008, "episode_reward": 633.9171181097539, "step": 22000}
{"episode": 23.0, "batch_reward": 0.6266443613767624, "actor_loss": -79.92625610351563, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.249659299850464, "episode_reward": 564.0958366111232, "step": 23000}
{"episode": 24.0, "batch_reward": 0.6275482150912285, "actor_loss": -79.95805235290527, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.409314155578613, "episode_reward": 569.6591986371111, "step": 24000}
{"episode": 25.0, "batch_reward": 0.6268070424199105, "actor_loss": -79.98898289489746, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.444056272506714, "episode_reward": 703.356723135397, "step": 25000}
{"episode": 26.0, "batch_reward": 0.6329600442051887, "actor_loss": -80.17265161132812, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.252471923828125, "episode_reward": 731.6083538725933, "step": 26000}
{"episode": 27.0, "batch_reward": 0.63492078602314, "actor_loss": -80.15815580749512, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.41925883293152, "episode_reward": 622.653616214345, "step": 27000}
{"episode": 28.0, "batch_reward": 0.6329991803765297, "actor_loss": -80.2333709564209, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.259355306625366, "episode_reward": 665.4912067141792, "step": 28000}
{"episode": 29.0, "batch_reward": 0.6357755123376846, "actor_loss": -80.26522720336914, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.924952745437622, "episode_reward": 679.1676274762675, "step": 29000}
{"episode": 30.0, "batch_reward": 0.6347036581039429, "actor_loss": -80.31539700317383, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.46766424179077, "episode_reward": 596.1804079516763, "step": 30000}
{"episode": 31.0, "batch_reward": 0.6368638313412667, "actor_loss": -80.34596450805664, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.07284903526306, "episode_reward": 747.2565571242595, "step": 31000}
{"episode": 32.0, "batch_reward": 0.6356741210222244, "actor_loss": -80.34016700744628, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.13293433189392, "episode_reward": 594.2328968313712, "step": 32000}
{"episode": 33.0, "batch_reward": 0.6394538566470146, "actor_loss": -80.38115721130372, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.33987855911255, "episode_reward": 664.0230964091189, "step": 33000}
{"episode": 34.0, "batch_reward": 0.637907822728157, "actor_loss": -80.46290069580078, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.234971284866333, "episode_reward": 679.4138446590382, "step": 34000}
{"episode": 35.0, "batch_reward": 0.6416298003196717, "actor_loss": -80.56604823303222, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.135936975479126, "episode_reward": 731.2008949742292, "step": 35000}
{"episode": 36.0, "batch_reward": 0.6431480723023415, "actor_loss": -80.5727170715332, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.988816499710083, "episode_reward": 768.1082333804641, "step": 36000}
{"episode": 37.0, "batch_reward": 0.6453689210414887, "actor_loss": -80.70237519836425, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.14314317703247, "episode_reward": 663.5298001792878, "step": 37000}
{"episode": 38.0, "batch_reward": 0.6467554819583893, "actor_loss": -80.66051152038574, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.915013790130615, "episode_reward": 726.0968776783178, "step": 38000}
{"episode": 39.0, "batch_reward": 0.6455321598649025, "actor_loss": -80.67419764709473, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.014259099960327, "episode_reward": 519.7576515903089, "step": 39000}
{"episode": 40.0, "batch_reward": 0.6456407253146171, "actor_loss": -80.72679837036132, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.667651891708374, "episode_reward": 660.207254982737, "step": 40000}
{"episode": 41.0, "batch_reward": 0.6434535165429115, "actor_loss": -80.65934408569336, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.02671408653259, "episode_reward": 590.0151129682446, "step": 41000}
{"episode": 42.0, "batch_reward": 0.6399654468894005, "actor_loss": -80.61508609008789, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.19362163543701, "episode_reward": 509.9858550834984, "step": 42000}
{"episode": 43.0, "batch_reward": 0.6411429190039635, "actor_loss": -80.61786854553223, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.62498140335083, "episode_reward": 612.9848227828188, "step": 43000}
{"episode": 44.0, "batch_reward": 0.6404134528040886, "actor_loss": -80.63043855285645, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.36810302734375, "episode_reward": 619.9468097449338, "step": 44000}
{"episode": 45.0, "batch_reward": 0.6376283196210861, "actor_loss": -80.54587338256836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.70341157913208, "episode_reward": 637.0261645589356, "step": 45000}
{"episode": 46.0, "batch_reward": 0.6404391565918922, "actor_loss": -80.56367863464355, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.55726408958435, "episode_reward": 603.9496459501157, "step": 46000}
{"episode": 47.0, "batch_reward": 0.6384264569282532, "actor_loss": -80.49334434509278, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.251531839370728, "episode_reward": 671.032083082104, "step": 47000}
{"episode": 48.0, "batch_reward": 0.6391404238939286, "actor_loss": -80.52567884826661, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.484558820724487, "episode_reward": 509.8291297234136, "step": 48000}
{"episode": 49.0, "batch_reward": 0.636468855202198, "actor_loss": -80.41712077331543, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.23636555671692, "episode_reward": 671.5349272905985, "step": 49000}
{"episode": 50.0, "batch_reward": 0.6375195628404617, "actor_loss": -80.42433151245118, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.078885078430176, "episode_reward": 604.0646363608589, "step": 50000}
{"episode": 51.0, "batch_reward": 0.6383593203425407, "actor_loss": -80.47033656311035, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.95421314239502, "episode_reward": 654.5289558654093, "step": 51000}
{"episode": 52.0, "batch_reward": 0.6354619853496551, "actor_loss": -80.3906007232666, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.922901391983032, "episode_reward": 518.5950500326536, "step": 52000}
{"episode": 53.0, "batch_reward": 0.633017553806305, "actor_loss": -80.3982289428711, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.33890700340271, "episode_reward": 646.2506799443372, "step": 53000}
{"episode": 54.0, "batch_reward": 0.6340839841365814, "actor_loss": -80.35520851135254, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.317169666290283, "episode_reward": 678.6391424209564, "step": 54000}
{"episode": 55.0, "batch_reward": 0.6345393307209015, "actor_loss": -80.4195588684082, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.33626890182495, "episode_reward": 548.0862455299686, "step": 55000}
{"episode": 56.0, "batch_reward": 0.634436051607132, "actor_loss": -80.4041654510498, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.346290588378906, "episode_reward": 719.2295043941938, "step": 56000}
{"episode": 57.0, "batch_reward": 0.6356023173332215, "actor_loss": -80.44109965515136, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.285518884658813, "episode_reward": 711.7332390292561, "step": 57000}
{"episode": 58.0, "batch_reward": 0.6371322663724422, "actor_loss": -80.4809701538086, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.84143376350403, "episode_reward": 496.95321820922766, "step": 58000}
{"episode": 59.0, "batch_reward": 0.6351380687952042, "actor_loss": -80.45166262817382, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.68360733985901, "episode_reward": 701.1446615784122, "step": 59000}
{"episode": 60.0, "batch_reward": 0.635333497941494, "actor_loss": -80.47138708496094, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.396126985549927, "episode_reward": 520.4016115937569, "step": 60000}
{"episode": 61.0, "batch_reward": 0.6344267154335975, "actor_loss": -80.38185122680665, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.157355308532715, "episode_reward": 710.4225388037586, "step": 61000}
{"episode": 62.0, "batch_reward": 0.6344415969848632, "actor_loss": -80.40973655700684, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.012035846710205, "episode_reward": 682.4122712243902, "step": 62000}
{"episode": 63.0, "batch_reward": 0.6364064300060273, "actor_loss": -80.4775661315918, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.355127334594727, "episode_reward": 634.1558919607473, "step": 63000}
{"episode": 64.0, "batch_reward": 0.632890619635582, "actor_loss": -80.39946409606934, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.615682125091553, "episode_reward": 607.5355392701902, "step": 64000}
{"episode": 65.0, "batch_reward": 0.6354774619340897, "actor_loss": -80.48285491943359, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.146031856536865, "episode_reward": 688.906858679907, "step": 65000}
{"episode": 66.0, "batch_reward": 0.6374099113345146, "actor_loss": -80.45874851989745, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.338921308517456, "episode_reward": 623.3261082513816, "step": 66000}
{"episode": 67.0, "batch_reward": 0.6334999821782112, "actor_loss": -80.33148527526855, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.453789234161377, "episode_reward": 475.4405988961095, "step": 67000}
{"episode": 68.0, "batch_reward": 0.6322314713597298, "actor_loss": -80.26253308105468, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.545495986938477, "episode_reward": 538.4149121071373, "step": 68000}
{"episode": 69.0, "batch_reward": 0.6344063645601272, "actor_loss": -80.33889489746093, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.34460425376892, "episode_reward": 690.8164416939004, "step": 69000}
{"episode": 70.0, "batch_reward": 0.6321925208568573, "actor_loss": -80.29321855163575, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.44736623764038, "episode_reward": 521.8246879663432, "step": 70000}
{"episode": 71.0, "batch_reward": 0.6321632398366928, "actor_loss": -80.29871580505372, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.27732872962952, "episode_reward": 669.2629567550206, "step": 71000}
{"episode": 72.0, "batch_reward": 0.6314443328380585, "actor_loss": -80.29466578674317, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.266186714172363, "episode_reward": 632.9249204395064, "step": 72000}
{"episode": 73.0, "batch_reward": 0.6338485209345818, "actor_loss": -80.37177597045898, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.2512264251709, "episode_reward": 712.046713068352, "step": 73000}
{"episode": 74.0, "batch_reward": 0.6337137949466706, "actor_loss": -80.35695442199707, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.407424926757812, "episode_reward": 709.4515530450649, "step": 74000}
{"episode": 75.0, "batch_reward": 0.634995805978775, "actor_loss": -80.39285803222656, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.10534429550171, "episode_reward": 644.3710204417918, "step": 75000}
{"episode": 76.0, "batch_reward": 0.6352073269486427, "actor_loss": -80.36538143920899, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.487185955047607, "episode_reward": 683.0455476388884, "step": 76000}
{"episode": 77.0, "batch_reward": 0.6366929886341095, "actor_loss": -80.3506695098877, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.60508370399475, "episode_reward": 626.34880180375, "step": 77000}
{"episode": 78.0, "batch_reward": 0.6331459368467331, "actor_loss": -80.3711541595459, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.15901207923889, "episode_reward": 608.7253526851223, "step": 78000}
{"episode": 79.0, "batch_reward": 0.6345528293848037, "actor_loss": -80.40598104858398, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.49764084815979, "episode_reward": 535.3703167759263, "step": 79000}
{"episode": 80.0, "batch_reward": 0.6332141674160957, "actor_loss": -80.36956773376465, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.116305351257324, "episode_reward": 667.997763170485, "step": 80000}
{"episode": 81.0, "batch_reward": 0.6335352628529072, "actor_loss": -80.29742860412598, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.33759808540344, "episode_reward": 593.0647432239374, "step": 81000}
{"episode": 82.0, "batch_reward": 0.6339258695244789, "actor_loss": -80.40157937622071, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.32960033416748, "episode_reward": 782.4048437366189, "step": 82000}
{"episode": 83.0, "batch_reward": 0.6336871635913849, "actor_loss": -80.38520683288574, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.39808416366577, "episode_reward": 638.3575041893137, "step": 83000}
{"episode": 84.0, "batch_reward": 0.6353433984518051, "actor_loss": -80.34563670349121, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.120664596557617, "episode_reward": 655.3112991237329, "step": 84000}
{"episode": 85.0, "batch_reward": 0.6348662185072899, "actor_loss": -80.4112787322998, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.29401707649231, "episode_reward": 673.8856995618933, "step": 85000}
{"episode": 86.0, "batch_reward": 0.6391335722208024, "actor_loss": -80.43595863342286, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.60913848876953, "episode_reward": 754.654199854821, "step": 86000}
{"episode": 87.0, "batch_reward": 0.6387764748334884, "actor_loss": -80.53066539001465, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.767496824264526, "episode_reward": 711.407834303763, "step": 87000}
{"episode": 88.0, "batch_reward": 0.6394400300383568, "actor_loss": -80.45625863647462, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.56920075416565, "episode_reward": 594.6319600149146, "step": 88000}
{"episode": 89.0, "batch_reward": 0.6377401644587517, "actor_loss": -80.50583068847656, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.687434434890747, "episode_reward": 736.9028514744906, "step": 89000}
{"episode": 90.0, "batch_reward": 0.6393361689448357, "actor_loss": -80.44379142761231, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.194939613342285, "episode_reward": 684.2623815507868, "step": 90000}
{"episode": 91.0, "batch_reward": 0.639002548456192, "actor_loss": -80.45932554626465, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.36614799499512, "episode_reward": 655.9975342318061, "step": 91000}
{"episode": 92.0, "batch_reward": 0.6389845491051674, "actor_loss": -80.5125941772461, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.267301559448242, "episode_reward": 697.0940671591196, "step": 92000}
{"episode": 93.0, "batch_reward": 0.6399359055757523, "actor_loss": -80.52756594848633, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.09837579727173, "episode_reward": 645.1311458711858, "step": 93000}
{"episode": 94.0, "batch_reward": 0.6391420823335647, "actor_loss": -80.48435218811035, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.236663818359375, "episode_reward": 580.6358778022108, "step": 94000}
{"episode": 95.0, "batch_reward": 0.6381771132349968, "actor_loss": -80.50820164489745, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.16849112510681, "episode_reward": 550.316892270914, "step": 95000}
{"episode": 96.0, "batch_reward": 0.6380115317702293, "actor_loss": -80.40475712585449, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.455227613449097, "episode_reward": 659.3790007545804, "step": 96000}
{"episode": 97.0, "batch_reward": 0.6391396881937981, "actor_loss": -80.49291316223145, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.552443027496338, "episode_reward": 677.9081785972634, "step": 97000}
{"episode": 98.0, "batch_reward": 0.6388884028196334, "actor_loss": -80.45379949951172, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.390227794647217, "episode_reward": 629.6583584249122, "step": 98000}
{"episode": 99.0, "batch_reward": 0.6366624736189842, "actor_loss": -80.37881262207031, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.933764457702637, "episode_reward": 590.0702609056116, "step": 99000}
{"episode": 100.0, "batch_reward": 0.6387912089824677, "actor_loss": -80.51415072631836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.473925352096558, "episode_reward": 639.9613948756545, "step": 100000}
{"episode": 101.0, "batch_reward": 0.6392217031121255, "actor_loss": -80.47618020629884, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.40428400039673, "episode_reward": 682.1145842397957, "step": 101000}
{"episode": 102.0, "batch_reward": 0.6411215172410011, "actor_loss": -80.53179577636719, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.066763401031494, "episode_reward": 773.4476904232733, "step": 102000}
{"episode": 103.0, "batch_reward": 0.6403905103206634, "actor_loss": -80.50340266418458, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.175849199295044, "episode_reward": 768.3522594119229, "step": 103000}
{"episode": 104.0, "batch_reward": 0.6427021332979203, "actor_loss": -80.59750759887696, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.146295070648193, "episode_reward": 790.723519541981, "step": 104000}
{"episode": 105.0, "batch_reward": 0.6454105788469314, "actor_loss": -80.6562554321289, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.13733172416687, "episode_reward": 603.3857846118453, "step": 105000}
{"episode": 106.0, "batch_reward": 0.6417677468657493, "actor_loss": -80.54374649047851, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.860143661499023, "episode_reward": 629.0230410722953, "step": 106000}
{"episode": 107.0, "batch_reward": 0.6406578999757767, "actor_loss": -80.5075645904541, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.576342344284058, "episode_reward": 634.7341948980883, "step": 107000}
{"episode": 108.0, "batch_reward": 0.6433686764836312, "actor_loss": -80.54664587402344, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.437393188476562, "episode_reward": 618.6340920136565, "step": 108000}
{"episode": 109.0, "batch_reward": 0.6421587440371513, "actor_loss": -80.42611027526856, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.3338782787323, "episode_reward": 741.9184037082904, "step": 109000}
{"episode": 110.0, "batch_reward": 0.6432846624255181, "actor_loss": -80.5222466583252, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.430410146713257, "episode_reward": 788.2483022395163, "step": 110000}
{"episode": 111.0, "batch_reward": 0.644865773499012, "actor_loss": -80.66130862426758, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.98205327987671, "episode_reward": 695.241295922184, "step": 111000}
{"episode": 112.0, "batch_reward": 0.6454405383467674, "actor_loss": -80.5955813446045, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.118273735046387, "episode_reward": 731.9832730510152, "step": 112000}
{"episode": 113.0, "batch_reward": 0.6468355347514152, "actor_loss": -80.68855915832519, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.485324382781982, "episode_reward": 715.780465396049, "step": 113000}
{"episode": 114.0, "batch_reward": 0.6474725147485733, "actor_loss": -80.56719694519043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.481617212295532, "episode_reward": 732.3303039213226, "step": 114000}
{"episode": 115.0, "batch_reward": 0.645032975256443, "actor_loss": -80.57224465942383, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.982245683670044, "episode_reward": 472.0429211664606, "step": 115000}
{"episode": 116.0, "batch_reward": 0.6465383020043373, "actor_loss": -80.59933387756348, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.405691146850586, "episode_reward": 718.9638717683858, "step": 116000}
{"episode": 117.0, "batch_reward": 0.6461073231697082, "actor_loss": -80.51359387207032, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.240893363952637, "episode_reward": 671.1275158107068, "step": 117000}
{"episode": 118.0, "batch_reward": 0.6456028329133987, "actor_loss": -80.56292364501954, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.49910879135132, "episode_reward": 764.6133749265499, "step": 118000}
{"episode": 119.0, "batch_reward": 0.6460024724006653, "actor_loss": -80.50898348999023, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.073408365249634, "episode_reward": 705.6401193285415, "step": 119000}
{"episode": 120.0, "batch_reward": 0.6487307095527649, "actor_loss": -80.5935493927002, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.827969551086426, "episode_reward": 753.6175886036293, "step": 120000}
{"episode": 121.0, "batch_reward": 0.6475459731221199, "actor_loss": -80.60401162719727, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.66549277305603, "episode_reward": 681.3979049126602, "step": 121000}
{"episode": 122.0, "batch_reward": 0.6483217125535011, "actor_loss": -80.57633769226074, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.319422960281372, "episode_reward": 600.7370903178273, "step": 122000}
{"episode": 123.0, "batch_reward": 0.6478655453324318, "actor_loss": -80.5766070098877, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.22333002090454, "episode_reward": 808.9185376494232, "step": 123000}
{"episode": 124.0, "batch_reward": 0.6497607886195182, "actor_loss": -80.59746989440917, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.27597403526306, "episode_reward": 563.8801675047193, "step": 124000}
{"episode": 125.0, "batch_reward": 0.6493109151124954, "actor_loss": -80.61798017883301, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.54914689064026, "episode_reward": 775.5575425013037, "step": 125000}
{"episode": 126.0, "batch_reward": 0.6501665847301483, "actor_loss": -80.6367163696289, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.24409532546997, "episode_reward": 700.7467327372373, "step": 126000}
{"episode": 127.0, "batch_reward": 0.6513351020812989, "actor_loss": -80.66567391967773, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.280117750167847, "episode_reward": 700.5117773330231, "step": 127000}
{"episode": 128.0, "batch_reward": 0.6531180276274681, "actor_loss": -80.7027922821045, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.682204246520996, "episode_reward": 672.1740268431704, "step": 128000}
{"episode": 129.0, "batch_reward": 0.6500181050896645, "actor_loss": -80.66184088134766, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.005537748336792, "episode_reward": 742.0377574962694, "step": 129000}
{"episode": 130.0, "batch_reward": 0.6515903959274292, "actor_loss": -80.62685021972656, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.530942916870117, "episode_reward": 745.6006480482016, "step": 130000}
{"episode": 131.0, "batch_reward": 0.6510380798578262, "actor_loss": -80.67560748291015, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.809638023376465, "episode_reward": 594.5779987058731, "step": 131000}
{"episode": 132.0, "batch_reward": 0.6522929219603538, "actor_loss": -80.67012364196778, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.356353044509888, "episode_reward": 754.943076292406, "step": 132000}
{"episode": 133.0, "batch_reward": 0.6539411375522614, "actor_loss": -80.67966941833497, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.358843326568604, "episode_reward": 576.7382208698045, "step": 133000}
{"episode": 134.0, "batch_reward": 0.6512484396696091, "actor_loss": -80.61031546020507, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.68449306488037, "episode_reward": 595.8698860365959, "step": 134000}
{"episode": 135.0, "batch_reward": 0.6530947661995887, "actor_loss": -80.72820835876465, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.42141556739807, "episode_reward": 662.7522520430507, "step": 135000}
{"episode": 136.0, "batch_reward": 0.6525431599020958, "actor_loss": -80.67116438293456, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.812464714050293, "episode_reward": 736.4094300332704, "step": 136000}
{"episode": 137.0, "batch_reward": 0.6535469478964806, "actor_loss": -80.68957936096191, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.13799738883972, "episode_reward": 764.4840343759172, "step": 137000}
{"episode": 138.0, "batch_reward": 0.6534538499116898, "actor_loss": -80.65035443115234, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.563546657562256, "episode_reward": 761.6164174704593, "step": 138000}
{"episode": 139.0, "batch_reward": 0.6549665864109993, "actor_loss": -80.72601336669922, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.16716241836548, "episode_reward": 612.4879479169447, "step": 139000}
{"episode": 140.0, "batch_reward": 0.6524562879800796, "actor_loss": -80.60900059509278, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.778733491897583, "episode_reward": 683.8066145282542, "step": 140000}
{"episode": 141.0, "batch_reward": 0.6557221671938896, "actor_loss": -80.69734634399414, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.103673696517944, "episode_reward": 721.6874769800152, "step": 141000}
{"episode": 142.0, "batch_reward": 0.6538446426391602, "actor_loss": -80.7036983795166, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.800598621368408, "episode_reward": 669.3221687996628, "step": 142000}
{"episode": 143.0, "batch_reward": 0.6546645169854164, "actor_loss": -80.68273262023926, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.692193746566772, "episode_reward": 720.9033444664444, "step": 143000}
{"episode": 144.0, "batch_reward": 0.6556001645326615, "actor_loss": -80.70955081176758, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.72041392326355, "episode_reward": 594.8607455109147, "step": 144000}
{"episode": 145.0, "batch_reward": 0.6547029722332954, "actor_loss": -80.67210575866699, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.126779794692993, "episode_reward": 653.3565850887798, "step": 145000}
{"episode": 146.0, "batch_reward": 0.6547959332466126, "actor_loss": -80.6956376953125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.677654504776, "episode_reward": 697.7566237591633, "step": 146000}
{"episode": 147.0, "batch_reward": 0.6553246463537217, "actor_loss": -80.73904069519043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.158952236175537, "episode_reward": 660.5615175964539, "step": 147000}
{"episode": 148.0, "batch_reward": 0.6554302371740341, "actor_loss": -80.70305223083496, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.706154108047485, "episode_reward": 662.1433280493741, "step": 148000}
{"episode": 149.0, "batch_reward": 0.6536563001275063, "actor_loss": -80.67325001525879, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.46748161315918, "episode_reward": 651.4956833798688, "step": 149000}
{"episode": 150.0, "batch_reward": 0.6539629371762276, "actor_loss": -80.58791299438477, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
