{"episode_reward": 0.0, "episode": 1.0, "duration": 21.81313180923462, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.8450920581817627, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.2945645965210952, "critic_loss": 0.7083598910301436, "actor_loss": -70.16963476369551, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 64.52422738075256, "step": 3000}
{"episode_reward": 513.3787038852464, "episode": 4.0, "batch_reward": 0.3732872120141983, "critic_loss": 0.9444451646208764, "actor_loss": -75.81195013427734, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.17500376701355, "step": 4000}
{"episode_reward": 595.8734363398827, "episode": 5.0, "batch_reward": 0.45578974175453185, "critic_loss": 0.7269248393774033, "actor_loss": -77.66442486572265, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.333693265914917, "step": 5000}
{"episode_reward": 813.4813870097696, "episode": 6.0, "batch_reward": 0.5091072215735912, "critic_loss": 0.6963781979382038, "actor_loss": -79.17884057617188, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.41655397415161, "step": 6000}
{"episode_reward": 751.8134777164398, "episode": 7.0, "batch_reward": 0.5407728263735772, "critic_loss": 0.6309573632776737, "actor_loss": -79.91457102966308, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.217625379562378, "step": 7000}
{"episode_reward": 673.8091623842959, "episode": 8.0, "batch_reward": 0.5725081160366535, "critic_loss": 0.5931750751435757, "actor_loss": -80.22291828918458, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.577784776687622, "step": 8000}
{"episode_reward": 748.0164112966935, "episode": 9.0, "batch_reward": 0.5970062169432641, "critic_loss": 0.5885793742835521, "actor_loss": -80.72007006835938, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.004124402999878, "step": 9000}
{"episode_reward": 866.6086222506881, "episode": 10.0, "batch_reward": 0.6267902093231678, "critic_loss": 0.5825031288266181, "actor_loss": -81.15828257751465, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.441254138946533, "step": 10000}
{"episode_reward": 856.7082688139471, "episode": 11.0, "batch_reward": 0.6523815046548843, "critic_loss": 0.6076937618255616, "actor_loss": -82.00226977539063, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.268110275268555, "step": 11000}
{"episode_reward": 882.5783622255865, "episode": 12.0, "batch_reward": 0.6675726616978646, "critic_loss": 0.7890102072954178, "actor_loss": -82.30837139892579, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.643844604492188, "step": 12000}
{"episode_reward": 898.1969141555818, "episode": 13.0, "batch_reward": 0.6840391244292259, "critic_loss": 0.9542903460562229, "actor_loss": -83.11577188110351, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.999078512191772, "step": 13000}
{"episode_reward": 883.0994795795965, "episode": 14.0, "batch_reward": 0.69220858335495, "critic_loss": 1.0769877254664897, "actor_loss": -83.3775876159668, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.047755241394043, "step": 14000}
{"episode_reward": 764.4820920039527, "episode": 15.0, "batch_reward": 0.7023457503318786, "critic_loss": 1.2914306228756904, "actor_loss": -84.08845170593261, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.0599524974823, "step": 15000}
{"episode_reward": 859.2280048476325, "episode": 16.0, "batch_reward": 0.7174440915584565, "critic_loss": 1.5223819231987, "actor_loss": -84.09529919433594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.865829467773438, "step": 16000}
{"episode_reward": 941.8734145590388, "episode": 17.0, "batch_reward": 0.721527440726757, "critic_loss": 2.506440682888031, "actor_loss": -84.87790814208985, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.922298192977905, "step": 17000}
{"episode_reward": 487.5111262388243, "episode": 18.0, "batch_reward": 0.700226828634739, "critic_loss": 3.470840376496315, "actor_loss": -85.68996684265137, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.163862943649292, "step": 18000}
{"episode_reward": 405.3612522764743, "episode": 19.0, "batch_reward": 0.6838702511191368, "critic_loss": 3.659610054016113, "actor_loss": -85.71630270385742, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.341673612594604, "step": 19000}
{"episode_reward": 507.3084309992113, "episode": 20.0, "batch_reward": 0.68133794516325, "critic_loss": 4.743264007687569, "actor_loss": -86.53049835205078, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.391520738601685, "step": 20000}
{"episode_reward": 697.2443237390395, "episode": 21.0, "batch_reward": 0.6919926742315292, "critic_loss": 4.330653073191643, "actor_loss": -86.70762524414063, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.49327802658081, "step": 21000}
{"episode_reward": 956.0290794118514, "episode": 22.0, "batch_reward": 0.6830940220355988, "critic_loss": 5.779482524394989, "actor_loss": -88.54765962219238, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.37347722053528, "step": 22000}
{"episode_reward": 16.765527940918858, "episode": 23.0, "batch_reward": 0.6568070586323738, "critic_loss": 7.565353575229644, "actor_loss": -89.3505729675293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.196135759353638, "step": 23000}
{"episode_reward": 182.42314949155826, "episode": 24.0, "batch_reward": 0.6401987154483795, "critic_loss": 8.238675434350968, "actor_loss": -89.91860827636718, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.176931619644165, "step": 24000}
{"episode_reward": 201.69064595502056, "episode": 25.0, "batch_reward": 0.6168434335291386, "critic_loss": 9.11197125172615, "actor_loss": -90.15977215576171, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.64353370666504, "step": 25000}
{"episode_reward": 41.839967543618286, "episode": 26.0, "batch_reward": 0.5937325973510742, "critic_loss": 9.925577459812164, "actor_loss": -90.36179211425781, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.5530686378479, "step": 26000}
{"episode_reward": 24.474923204524007, "episode": 27.0, "batch_reward": 0.5746220416128636, "critic_loss": 10.380147536754608, "actor_loss": -92.19645387268066, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.488953828811646, "step": 27000}
{"episode_reward": 7.733875029632436, "episode": 28.0, "batch_reward": 0.5519838056862354, "critic_loss": 12.62376620054245, "actor_loss": -93.29606707763672, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.13056969642639, "step": 28000}
{"episode_reward": 139.07380116201432, "episode": 29.0, "batch_reward": 0.5379860748946667, "critic_loss": 13.050488407611846, "actor_loss": -96.17938096618653, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.24255609512329, "step": 29000}
{"episode_reward": 88.99032638679665, "episode": 30.0, "batch_reward": 0.5214236243367195, "critic_loss": 13.719973162174226, "actor_loss": -95.80316860961914, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.64991068840027, "step": 30000}
{"episode_reward": 6.417086612651318, "episode": 31.0, "batch_reward": 0.5025967853963376, "critic_loss": 12.957351671218872, "actor_loss": -98.03475897216796, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.97280526161194, "step": 31000}
{"episode_reward": 5.9270495000924965, "episode": 32.0, "batch_reward": 0.4858995481431484, "critic_loss": 13.649497351646424, "actor_loss": -100.96416271972656, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.976277589797974, "step": 32000}
{"episode_reward": 35.81800713708892, "episode": 33.0, "batch_reward": 0.47624941244721414, "critic_loss": 14.251625970840454, "actor_loss": -103.68389543151855, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.150686025619507, "step": 33000}
{"episode_reward": 96.78552733096615, "episode": 34.0, "batch_reward": 0.4667216852903366, "critic_loss": 15.153975126266479, "actor_loss": -102.61820051574708, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.330105781555176, "step": 34000}
{"episode_reward": 104.4028764466983, "episode": 35.0, "batch_reward": 0.45568116548657417, "critic_loss": 14.141928417205811, "actor_loss": -105.82941807556152, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.180500984191895, "step": 35000}
{"episode_reward": 70.67987398380927, "episode": 36.0, "batch_reward": 0.4438437632918358, "critic_loss": 13.330786987304688, "actor_loss": -106.78576838684081, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.71397829055786, "step": 36000}
{"episode_reward": 58.70279565528354, "episode": 37.0, "batch_reward": 0.4328921429514885, "critic_loss": 12.64252127122879, "actor_loss": -107.57764959716796, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.201531171798706, "step": 37000}
{"episode_reward": 26.587960254421823, "episode": 38.0, "batch_reward": 0.4223085035085678, "critic_loss": 11.217832767486572, "actor_loss": -112.15472416687011, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.3964262008667, "step": 38000}
{"episode_reward": 31.11489411394872, "episode": 39.0, "batch_reward": 0.41324043601751326, "critic_loss": 10.934959856510162, "actor_loss": -113.05775785827636, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.154022693634033, "step": 39000}
{"episode_reward": 71.96946846419482, "episode": 40.0, "batch_reward": 0.40480019187927246, "critic_loss": 10.960785576343536, "actor_loss": -114.28571182250977, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.322261571884155, "step": 40000}
{"episode_reward": 29.04286024394712, "episode": 41.0, "batch_reward": 0.39452121797204015, "critic_loss": 11.092427649021149, "actor_loss": -115.5104808807373, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.27029776573181, "step": 41000}
{"episode_reward": 28.87044508138132, "episode": 42.0, "batch_reward": 0.3851318484544754, "critic_loss": 11.691292101860046, "actor_loss": -118.80832357788086, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.72966456413269, "step": 42000}
{"episode_reward": 57.94566018271662, "episode": 43.0, "batch_reward": 0.3757794747948647, "critic_loss": 12.594069553852082, "actor_loss": -120.44448817443848, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.14942693710327, "step": 43000}
{"episode_reward": 39.70957591158213, "episode": 44.0, "batch_reward": 0.36920595142245294, "critic_loss": 13.269156201362609, "actor_loss": -122.6230594177246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.48614001274109, "step": 44000}
{"episode_reward": 75.14939588187927, "episode": 45.0, "batch_reward": 0.3620279774963856, "critic_loss": 13.656469101428986, "actor_loss": -125.53685278320313, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.01006770133972, "step": 45000}
{"episode_reward": 90.4475649772587, "episode": 46.0, "batch_reward": 0.35790144181251526, "critic_loss": 14.249266721725464, "actor_loss": -125.46053416442871, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.34287691116333, "step": 46000}
{"episode_reward": 111.81161390981781, "episode": 47.0, "batch_reward": 0.3521770925223827, "critic_loss": 14.318123353481292, "actor_loss": -124.5249295349121, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.060776472091675, "step": 47000}
{"episode_reward": 131.5800914691983, "episode": 48.0, "batch_reward": 0.3480224000364542, "critic_loss": 13.135191615104675, "actor_loss": -130.60529917907715, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.635131120681763, "step": 48000}
{"episode_reward": 129.18090717239073, "episode": 49.0, "batch_reward": 0.34535431665182115, "critic_loss": 11.954469959259033, "actor_loss": -129.27530583190918, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.85918378829956, "step": 49000}
{"episode_reward": 464.8357223218216, "episode": 50.0, "batch_reward": 0.3520509288609028, "critic_loss": 10.599663247585296, "actor_loss": -128.12896696472168, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.49392604827881, "step": 50000}
{"episode_reward": 877.3016246543955, "episode": 51.0, "batch_reward": 0.3636415733397007, "critic_loss": 8.815801519870758, "actor_loss": -133.02213575744628, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.614670515060425, "step": 51000}
{"episode_reward": 941.0225223945436, "episode": 52.0, "batch_reward": 0.37382044005393983, "critic_loss": 7.646567735910415, "actor_loss": -126.94121817016601, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.480793714523315, "step": 52000}
{"episode_reward": 921.130814370709, "episode": 53.0, "batch_reward": 0.37652446144819257, "critic_loss": 6.466928082942963, "actor_loss": -129.97019149780274, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.563754081726074, "step": 53000}
{"episode_reward": 197.6838833028764, "episode": 54.0, "batch_reward": 0.3830888843536377, "critic_loss": 5.383551238059997, "actor_loss": -125.27669714355468, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.38290572166443, "step": 54000}
{"episode_reward": 931.4226065576329, "episode": 55.0, "batch_reward": 0.39230233305692674, "critic_loss": 4.555793166875839, "actor_loss": -123.14129586791992, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.72440767288208, "step": 55000}
{"episode_reward": 958.5947868688486, "episode": 56.0, "batch_reward": 0.3963943033218384, "critic_loss": 4.0136729373931885, "actor_loss": -123.70094137573243, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.73906135559082, "step": 56000}
{"episode_reward": 279.2340042167657, "episode": 57.0, "batch_reward": 0.39805156314373014, "critic_loss": 3.773996411204338, "actor_loss": -120.96024586486817, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.55186176300049, "step": 57000}
{"episode_reward": 790.0731570697527, "episode": 58.0, "batch_reward": 0.40162732431292536, "critic_loss": 3.4091291198730467, "actor_loss": -121.64683415222169, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.50506901741028, "step": 58000}
{"episode_reward": 49.568439257713344, "episode": 59.0, "batch_reward": 0.4022550303041935, "critic_loss": 3.0786662015914916, "actor_loss": -118.6925719909668, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.45681381225586, "step": 59000}
{"episode_reward": 979.8634113995438, "episode": 60.0, "batch_reward": 0.4050760294795036, "critic_loss": 2.8308914024829863, "actor_loss": -115.55381715393067, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.55360746383667, "step": 60000}
{"episode_reward": 465.5245661416119, "episode": 61.0, "batch_reward": 0.4056890771985054, "critic_loss": 2.66852352976799, "actor_loss": -114.90513526916504, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.743940114974976, "step": 61000}
{"episode_reward": 362.55065561852473, "episode": 62.0, "batch_reward": 0.4099812458455563, "critic_loss": 2.4734950627088548, "actor_loss": -116.20379010009766, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.10365319252014, "step": 62000}
{"episode_reward": 973.5161934554518, "episode": 63.0, "batch_reward": 0.4214662420749664, "critic_loss": 2.2491329885721205, "actor_loss": -115.46596287536622, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.403293132781982, "step": 63000}
{"episode_reward": 970.6470010471838, "episode": 64.0, "batch_reward": 0.4266259301304817, "critic_loss": 2.1337487077713013, "actor_loss": -111.7961301574707, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.559803009033203, "step": 64000}
{"episode_reward": 898.7176115448866, "episode": 65.0, "batch_reward": 0.4290107616484165, "critic_loss": 2.033484500527382, "actor_loss": -111.45404327392578, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.132229566574097, "step": 65000}
{"episode_reward": 53.63028227544135, "episode": 66.0, "batch_reward": 0.4250369577407837, "critic_loss": 1.8891462953090667, "actor_loss": -109.49856715393067, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.39966344833374, "step": 66000}
{"episode_reward": 264.2263986848557, "episode": 67.0, "batch_reward": 0.4193920654952526, "critic_loss": 1.8537906175255776, "actor_loss": -109.12730480957032, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.164595127105713, "step": 67000}
{"episode_reward": 31.530532970228176, "episode": 68.0, "batch_reward": 0.4140003948807716, "critic_loss": 1.82982371789217, "actor_loss": -107.18116218566894, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.622536659240723, "step": 68000}
{"episode_reward": 33.72370322401356, "episode": 69.0, "batch_reward": 0.4092293725609779, "critic_loss": 1.7975777933597565, "actor_loss": -106.36754521179199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.372096061706543, "step": 69000}
{"episode_reward": 48.10512614159058, "episode": 70.0, "batch_reward": 0.40287373384833336, "critic_loss": 1.6835914227962494, "actor_loss": -103.29091728210449, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.592960357666016, "step": 70000}
{"episode_reward": 29.60698049390516, "episode": 71.0, "batch_reward": 0.4016124188303947, "critic_loss": 1.7628908583521843, "actor_loss": -103.53193644714355, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.975035190582275, "step": 71000}
{"episode_reward": 167.88431333454994, "episode": 72.0, "batch_reward": 0.39653921729326247, "critic_loss": 1.5923629783391953, "actor_loss": -101.39840293884278, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.357706785202026, "step": 72000}
{"episode_reward": 33.98859935264066, "episode": 73.0, "batch_reward": 0.3930019361674786, "critic_loss": 1.553408112168312, "actor_loss": -99.97183363342285, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.21389102935791, "step": 73000}
{"episode_reward": 167.6770738438891, "episode": 74.0, "batch_reward": 0.38986132669448853, "critic_loss": 1.4219184060692787, "actor_loss": -98.07496005249024, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.67392373085022, "step": 74000}
{"episode_reward": 515.7403771131362, "episode": 75.0, "batch_reward": 0.391198516368866, "critic_loss": 1.3740428292751312, "actor_loss": -97.48681358337403, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.159509897232056, "step": 75000}
{"episode_reward": 198.93995841908773, "episode": 76.0, "batch_reward": 0.38906144225597383, "critic_loss": 1.2919859046339988, "actor_loss": -96.08600444030762, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.336216688156128, "step": 76000}
{"episode_reward": 524.7536120075979, "episode": 77.0, "batch_reward": 0.39213332584500316, "critic_loss": 1.2959020209908485, "actor_loss": -97.15884591674805, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.876250982284546, "step": 77000}
{"episode_reward": 872.1830653748304, "episode": 78.0, "batch_reward": 0.4002207369506359, "critic_loss": 1.2536821261048317, "actor_loss": -96.30028350830078, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.85632038116455, "step": 78000}
{"episode_reward": 853.0686318309982, "episode": 79.0, "batch_reward": 0.4042452221214771, "critic_loss": 1.2290781920552254, "actor_loss": -95.52494459533692, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.525599479675293, "step": 79000}
{"episode_reward": 873.1388163567212, "episode": 80.0, "batch_reward": 0.4113756927251816, "critic_loss": 1.1424620737433433, "actor_loss": -93.56619151306153, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.331434965133667, "step": 80000}
{"episode_reward": 943.799870992942, "episode": 81.0, "batch_reward": 0.4187935934960842, "critic_loss": 1.0114731922447682, "actor_loss": -93.4384134979248, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.6998975276947, "step": 81000}
{"episode_reward": 869.8433319251887, "episode": 82.0, "batch_reward": 0.42433254000544546, "critic_loss": 0.9829111311733723, "actor_loss": -92.4210277557373, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.338148832321167, "step": 82000}
{"episode_reward": 976.3374200803139, "episode": 83.0, "batch_reward": 0.4299624091088772, "critic_loss": 0.9524762901067734, "actor_loss": -91.06599412536622, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.35554051399231, "step": 83000}
{"episode_reward": 841.1578490300979, "episode": 84.0, "batch_reward": 0.43516507548093797, "critic_loss": 0.9148352257907391, "actor_loss": -90.17507600402833, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.560335636138916, "step": 84000}
{"episode_reward": 945.4363748485243, "episode": 85.0, "batch_reward": 0.44399562627077105, "critic_loss": 0.8837730613946915, "actor_loss": -90.38061755371093, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.24673104286194, "step": 85000}
{"episode_reward": 952.0907586039377, "episode": 86.0, "batch_reward": 0.4486169868707657, "critic_loss": 0.8795340476334095, "actor_loss": -88.65724697875977, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.354621171951294, "step": 86000}
{"episode_reward": 951.1993720156352, "episode": 87.0, "batch_reward": 0.4543347225487232, "critic_loss": 0.901653110653162, "actor_loss": -88.30389491271973, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.71639132499695, "step": 87000}
{"episode_reward": 949.5672262301865, "episode": 88.0, "batch_reward": 0.45901829993724824, "critic_loss": 0.9716741941273213, "actor_loss": -88.04041087341308, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.750170946121216, "step": 88000}
{"episode_reward": 927.9237012413193, "episode": 89.0, "batch_reward": 0.46546100923419, "critic_loss": 0.9365436381995678, "actor_loss": -87.90703004455567, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.478159189224243, "step": 89000}
{"episode_reward": 941.0000205411405, "episode": 90.0, "batch_reward": 0.47131384918093683, "critic_loss": 0.9470567196309566, "actor_loss": -88.05679360961913, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.30019998550415, "step": 90000}
{"episode_reward": 975.5969104674407, "episode": 91.0, "batch_reward": 0.47494002372026445, "critic_loss": 0.9375457270741463, "actor_loss": -87.78412306213379, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.02842736244202, "step": 91000}
{"episode_reward": 919.8372337533782, "episode": 92.0, "batch_reward": 0.4812446456849575, "critic_loss": 0.9150932035148144, "actor_loss": -87.2227096862793, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.323206186294556, "step": 92000}
{"episode_reward": 959.5288263702448, "episode": 93.0, "batch_reward": 0.48537378826737404, "critic_loss": 0.9113983603417873, "actor_loss": -87.05059585571288, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.31198239326477, "step": 93000}
{"episode_reward": 982.427211145669, "episode": 94.0, "batch_reward": 0.48979179793596267, "critic_loss": 0.951767591804266, "actor_loss": -86.82464025878906, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.42109966278076, "step": 94000}
{"episode_reward": 941.6242299847925, "episode": 95.0, "batch_reward": 0.4962398760616779, "critic_loss": 0.877176970988512, "actor_loss": -87.55334140014648, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.49538278579712, "step": 95000}
{"episode_reward": 948.609349564728, "episode": 96.0, "batch_reward": 0.49961702927947044, "critic_loss": 0.8793191966116428, "actor_loss": -85.78577293395996, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.331827402114868, "step": 96000}
{"episode_reward": 948.3838325615055, "episode": 97.0, "batch_reward": 0.5041560389101505, "critic_loss": 0.8608911204040051, "actor_loss": -86.16752165222168, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.350432872772217, "step": 97000}
{"episode_reward": 800.2737339060341, "episode": 98.0, "batch_reward": 0.5086901490092277, "critic_loss": 0.8224820247590542, "actor_loss": -86.49780337524415, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.800736904144287, "step": 98000}
{"episode_reward": 912.9044654409776, "episode": 99.0, "batch_reward": 0.5115688970386982, "critic_loss": 0.7597046189010144, "actor_loss": -85.07843258666992, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.583784341812134, "step": 99000}
{"episode_reward": 921.3311059725316, "episode": 100.0, "batch_reward": 0.5150973751544953, "critic_loss": 0.7588894985318184, "actor_loss": -85.2344416809082, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.326958894729614, "step": 100000}
{"episode_reward": 973.8047827609175, "episode": 101.0, "batch_reward": 0.5205353389978409, "critic_loss": 0.7297345863580704, "actor_loss": -84.67713710021972, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.55159020423889, "step": 101000}
{"episode_reward": 964.451800376478, "episode": 102.0, "batch_reward": 0.5240190130770206, "critic_loss": 0.7058509282171727, "actor_loss": -84.76077391052246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.410590171813965, "step": 102000}
{"episode_reward": 970.1939050976038, "episode": 103.0, "batch_reward": 0.5290437360405922, "critic_loss": 0.7148325348496437, "actor_loss": -84.75328729248046, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.373369693756104, "step": 103000}
{"episode_reward": 936.5464945817563, "episode": 104.0, "batch_reward": 0.532632178902626, "critic_loss": 0.7362228157222271, "actor_loss": -84.39066635131836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.695417642593384, "step": 104000}
{"episode_reward": 938.9503205502862, "episode": 105.0, "batch_reward": 0.5353600751757622, "critic_loss": 0.6932859559059144, "actor_loss": -84.10468650817872, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.103270292282104, "step": 105000}
{"episode_reward": 966.9615365203324, "episode": 106.0, "batch_reward": 0.5398855172991752, "critic_loss": 0.7020076952576637, "actor_loss": -83.64407141113281, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.3416268825531, "step": 106000}
{"episode_reward": 903.2239704007148, "episode": 107.0, "batch_reward": 0.5432041644155979, "critic_loss": 0.7027346739768981, "actor_loss": -83.32448765563964, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.5120747089386, "step": 107000}
{"episode_reward": 914.6433603779744, "episode": 108.0, "batch_reward": 0.5473428197205067, "critic_loss": 0.7173145954012871, "actor_loss": -83.68471549987792, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.051274061203003, "step": 108000}
{"episode_reward": 883.5042924679836, "episode": 109.0, "batch_reward": 0.5506001298725605, "critic_loss": 0.7198445178866386, "actor_loss": -83.28916648864747, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.709537744522095, "step": 109000}
{"episode_reward": 938.1254369795928, "episode": 110.0, "batch_reward": 0.5535078480243683, "critic_loss": 0.6786129051148891, "actor_loss": -83.04330810546875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.324737071990967, "step": 110000}
{"episode_reward": 930.3946415987989, "episode": 111.0, "batch_reward": 0.5579337604045868, "critic_loss": 0.6697476396262646, "actor_loss": -83.39940521240234, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.87328362464905, "step": 111000}
{"episode_reward": 955.599487248594, "episode": 112.0, "batch_reward": 0.5629189668893814, "critic_loss": 0.6526947688758373, "actor_loss": -82.68220756530762, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.811103343963623, "step": 112000}
{"episode_reward": 931.4788282134556, "episode": 113.0, "batch_reward": 0.5651119846701622, "critic_loss": 0.6669969159960747, "actor_loss": -82.72828088378907, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.332706928253174, "step": 113000}
{"episode_reward": 918.115100204144, "episode": 114.0, "batch_reward": 0.5670672482252122, "critic_loss": 0.6378250905871391, "actor_loss": -82.47057252502441, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.084185123443604, "step": 114000}
{"episode_reward": 976.1999890064922, "episode": 115.0, "batch_reward": 0.5712429461479187, "critic_loss": 0.6280776330828667, "actor_loss": -82.68853587341309, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.6391339302063, "step": 115000}
{"episode_reward": 949.2183257185263, "episode": 116.0, "batch_reward": 0.576964044868946, "critic_loss": 0.6470908151268959, "actor_loss": -82.99973724365235, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.32753610610962, "step": 116000}
{"episode_reward": 938.4015751499832, "episode": 117.0, "batch_reward": 0.5793548689484597, "critic_loss": 0.6452132316231728, "actor_loss": -83.21569673156738, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.331088304519653, "step": 117000}
{"episode_reward": 951.3384795507028, "episode": 118.0, "batch_reward": 0.5809274561107158, "critic_loss": 0.6587044915556908, "actor_loss": -83.28805322265625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.299630165100098, "step": 118000}
{"episode_reward": 937.8777184460363, "episode": 119.0, "batch_reward": 0.5855125227868557, "critic_loss": 0.6832183975875378, "actor_loss": -83.2714602355957, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.739718675613403, "step": 119000}
{"episode_reward": 950.1078639782228, "episode": 120.0, "batch_reward": 0.5842507096230983, "critic_loss": 0.6219477697610855, "actor_loss": -83.25127461242676, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.600141525268555, "step": 120000}
{"episode_reward": 937.5526678276423, "episode": 121.0, "batch_reward": 0.5909023923575878, "critic_loss": 0.6066582496762276, "actor_loss": -83.00357312011718, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.89408254623413, "step": 121000}
{"episode_reward": 940.3317387864889, "episode": 122.0, "batch_reward": 0.5913559013605117, "critic_loss": 0.6244542461633682, "actor_loss": -82.90108584594726, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.458406686782837, "step": 122000}
{"episode_reward": 922.6209944321454, "episode": 123.0, "batch_reward": 0.5942568386793137, "critic_loss": 0.6301571543216705, "actor_loss": -82.7678369140625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.348774671554565, "step": 123000}
{"episode_reward": 943.4148372214191, "episode": 124.0, "batch_reward": 0.5977661617696285, "critic_loss": 0.5992739569693804, "actor_loss": -82.61867170715333, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.364036083221436, "step": 124000}
{"episode_reward": 963.4703418817595, "episode": 125.0, "batch_reward": 0.6036903003156185, "critic_loss": 0.5791595129072666, "actor_loss": -82.75700715637207, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.566086292266846, "step": 125000}
{"episode_reward": 946.7438519371545, "episode": 126.0, "batch_reward": 0.603544527053833, "critic_loss": 0.5815789223611355, "actor_loss": -82.74316551208496, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.537265062332153, "step": 126000}
{"episode_reward": 973.6707632907052, "episode": 127.0, "batch_reward": 0.607968468606472, "critic_loss": 0.5768045397847891, "actor_loss": -82.50869604492188, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.780132055282593, "step": 127000}
{"episode_reward": 926.5819432543831, "episode": 128.0, "batch_reward": 0.6091814578771592, "critic_loss": 0.5755015110522509, "actor_loss": -82.48273638916015, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.31138277053833, "step": 128000}
{"episode_reward": 942.5340733122506, "episode": 129.0, "batch_reward": 0.613763330847025, "critic_loss": 0.5768652948737144, "actor_loss": -82.64480203247071, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.740718841552734, "step": 129000}
{"episode_reward": 934.7029346106914, "episode": 130.0, "batch_reward": 0.6168571973443031, "critic_loss": 0.589410107254982, "actor_loss": -82.79524537658692, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.766862392425537, "step": 130000}
{"episode_reward": 938.9439227769846, "episode": 131.0, "batch_reward": 0.6167787544429302, "critic_loss": 0.6126806840896607, "actor_loss": -82.79560284423827, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 39.98312497138977, "step": 131000}
{"episode_reward": 946.4505248602192, "episode": 132.0, "batch_reward": 0.6181529322266579, "critic_loss": 0.5567212890386581, "actor_loss": -82.84632089233398, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.740031003952026, "step": 132000}
{"episode_reward": 928.6820933508723, "episode": 133.0, "batch_reward": 0.6224797527194024, "critic_loss": 0.5705793978571891, "actor_loss": -83.34875012207031, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.977669715881348, "step": 133000}
{"episode_reward": 948.0382979237298, "episode": 134.0, "batch_reward": 0.6248323049545288, "critic_loss": 0.5935484404563904, "actor_loss": -83.31219268798829, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.330536365509033, "step": 134000}
{"episode_reward": 952.223115792964, "episode": 135.0, "batch_reward": 0.6247336519956589, "critic_loss": 0.5526249200999737, "actor_loss": -83.00195364379883, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.022683143615723, "step": 135000}
{"episode_reward": 928.9969896807864, "episode": 136.0, "batch_reward": 0.6279408336877823, "critic_loss": 0.5679449088275432, "actor_loss": -83.39674067687989, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.768864631652832, "step": 136000}
{"episode_reward": 940.1283023940443, "episode": 137.0, "batch_reward": 0.630807973086834, "critic_loss": 0.5329625364243984, "actor_loss": -83.12067657470703, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.925679445266724, "step": 137000}
{"episode_reward": 973.6658197258511, "episode": 138.0, "batch_reward": 0.6366363015174866, "critic_loss": 0.5215859248936177, "actor_loss": -83.09086932373047, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.316360235214233, "step": 138000}
{"episode_reward": 942.5833413526535, "episode": 139.0, "batch_reward": 0.6387817408442498, "critic_loss": 0.5114405865371228, "actor_loss": -83.38692193603515, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.225570678710938, "step": 139000}
{"episode_reward": 954.576989702383, "episode": 140.0, "batch_reward": 0.6385371928811073, "critic_loss": 0.47817925491929053, "actor_loss": -83.06972088623047, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.63770341873169, "step": 140000}
{"episode_reward": 977.3293412232025, "episode": 141.0, "batch_reward": 0.6405273051559925, "critic_loss": 0.5068671767711639, "actor_loss": -82.94243960571289, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.013052463531494, "step": 141000}
{"episode_reward": 887.2651939617856, "episode": 142.0, "batch_reward": 0.641639125585556, "critic_loss": 0.5058957131356001, "actor_loss": -83.18436775207519, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.60040044784546, "step": 142000}
{"episode_reward": 950.1061566510614, "episode": 143.0, "batch_reward": 0.6445579894781113, "critic_loss": 0.5059476048499346, "actor_loss": -83.4313821105957, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.602508544921875, "step": 143000}
{"episode_reward": 924.767586253811, "episode": 144.0, "batch_reward": 0.6463960726857185, "critic_loss": 0.5054364690333605, "actor_loss": -83.31390502929688, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.699726581573486, "step": 144000}
{"episode_reward": 887.7176659603576, "episode": 145.0, "batch_reward": 0.6489621490240097, "critic_loss": 0.5186065800189972, "actor_loss": -83.1928935546875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.758840799331665, "step": 145000}
{"episode_reward": 903.5045254792227, "episode": 146.0, "batch_reward": 0.6493884969949723, "critic_loss": 0.5764123863428832, "actor_loss": -83.06778616333008, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.741575241088867, "step": 146000}
{"episode_reward": 800.4508612341269, "episode": 147.0, "batch_reward": 0.6530449040532113, "critic_loss": 0.552498886808753, "actor_loss": -83.23062707519532, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.13425374031067, "step": 147000}
{"episode_reward": 944.6298996885449, "episode": 148.0, "batch_reward": 0.6544704685807228, "critic_loss": 0.5617668230384588, "actor_loss": -83.26662782287598, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.33293604850769, "step": 148000}
{"episode_reward": 936.5231935759471, "episode": 149.0, "batch_reward": 0.6561215186715126, "critic_loss": 0.58961039057374, "actor_loss": -83.33073132324219, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.921377182006836, "step": 149000}
{"episode_reward": 930.036725765797, "episode": 150.0, "batch_reward": 0.6562296291589736, "critic_loss": 0.605135821133852, "actor_loss": -83.26183781433106, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
