{"episode_reward": 0.0, "episode": 1.0, "duration": 20.57348108291626, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.7834396362304688, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.3063100868014345, "critic_loss": 0.6245561270773033, "actor_loss": -71.49923146748934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.679770708084106, "step": 3000}
{"episode_reward": 672.6573840115622, "episode": 4.0, "batch_reward": 0.43543484607338906, "critic_loss": 0.9168718795478344, "actor_loss": -77.66820375061035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.256439447402954, "step": 4000}
{"episode_reward": 590.378251274467, "episode": 5.0, "batch_reward": 0.4733192087709904, "critic_loss": 1.0240612062811851, "actor_loss": -77.70149801635742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.297040700912476, "step": 5000}
{"episode_reward": 614.7554456111875, "episode": 6.0, "batch_reward": 0.5078071580827236, "critic_loss": 1.0092438855171204, "actor_loss": -78.29421807861328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.283374071121216, "step": 6000}
{"episode_reward": 739.0242225886121, "episode": 7.0, "batch_reward": 0.5425238634645939, "critic_loss": 0.8775763688087463, "actor_loss": -78.93829280090333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29569387435913, "step": 7000}
{"episode_reward": 797.2803076116973, "episode": 8.0, "batch_reward": 0.5814950132369995, "critic_loss": 0.7677532576322555, "actor_loss": -79.73739912414551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.270207405090332, "step": 8000}
{"episode_reward": 827.7296826700572, "episode": 9.0, "batch_reward": 0.6204526443481445, "critic_loss": 0.7740433453023434, "actor_loss": -80.50996937561035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28133487701416, "step": 9000}
{"episode_reward": 937.8567453428277, "episode": 10.0, "batch_reward": 0.6557880027890205, "critic_loss": 0.7874118053615093, "actor_loss": -81.07430657958984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.273800134658813, "step": 10000}
{"episode_reward": 951.8266043405006, "episode": 11.0, "batch_reward": 0.6831274564862251, "critic_loss": 0.7704757598340511, "actor_loss": -81.78972723388672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.65388369560242, "step": 11000}
{"episode_reward": 918.5726404768145, "episode": 12.0, "batch_reward": 0.699868045091629, "critic_loss": 0.8135829497277737, "actor_loss": -82.12433955383301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.237525939941406, "step": 12000}
{"episode_reward": 940.3360693090593, "episode": 13.0, "batch_reward": 0.7182897116541862, "critic_loss": 0.8020728231370449, "actor_loss": -82.69736491394043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.223796367645264, "step": 13000}
{"episode_reward": 922.2599449289038, "episode": 14.0, "batch_reward": 0.7342681559324264, "critic_loss": 0.7458285431861877, "actor_loss": -83.1367202758789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26000189781189, "step": 14000}
{"episode_reward": 905.9981773444696, "episode": 15.0, "batch_reward": 0.7494328553676606, "critic_loss": 0.6500929573774338, "actor_loss": -83.74613255310058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28090238571167, "step": 15000}
{"episode_reward": 967.7055970826868, "episode": 16.0, "batch_reward": 0.7555899887084961, "critic_loss": 0.7300473851859569, "actor_loss": -83.64216244506837, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.276374340057373, "step": 16000}
{"episode_reward": 689.7485367977068, "episode": 17.0, "batch_reward": 0.752760904788971, "critic_loss": 0.7917454112768173, "actor_loss": -83.57771751403808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28243088722229, "step": 17000}
{"episode_reward": 798.1204620298146, "episode": 18.0, "batch_reward": 0.7556151113510132, "critic_loss": 0.7161728557646274, "actor_loss": -83.47947308349609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.262211084365845, "step": 18000}
{"episode_reward": 794.2432299064242, "episode": 19.0, "batch_reward": 0.7537546239495277, "critic_loss": 0.7350442025661469, "actor_loss": -83.37645248413087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24682378768921, "step": 19000}
{"episode_reward": 664.1036704399183, "episode": 20.0, "batch_reward": 0.7531402842402458, "critic_loss": 0.7915277299880982, "actor_loss": -83.35106422424316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.286850929260254, "step": 20000}
{"episode_reward": 790.9620900789369, "episode": 21.0, "batch_reward": 0.7575604659914971, "critic_loss": 0.751341913074255, "actor_loss": -83.34426184082031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.609023332595825, "step": 21000}
{"episode_reward": 795.9785332567436, "episode": 22.0, "batch_reward": 0.7578669774532318, "critic_loss": 0.8019949135482312, "actor_loss": -83.3146862335205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.264020919799805, "step": 22000}
{"episode_reward": 875.7938513938769, "episode": 23.0, "batch_reward": 0.7607501458525657, "critic_loss": 0.8071867242455483, "actor_loss": -83.39034172058105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28418278694153, "step": 23000}
{"episode_reward": 813.1902708053667, "episode": 24.0, "batch_reward": 0.7665728160142898, "critic_loss": 0.7718936605751514, "actor_loss": -83.42229301452636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2796733379364, "step": 24000}
{"episode_reward": 921.3720003917273, "episode": 25.0, "batch_reward": 0.7719719850420952, "critic_loss": 0.7635021944642066, "actor_loss": -83.54551608276367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.22730326652527, "step": 25000}
{"episode_reward": 882.4362658800868, "episode": 26.0, "batch_reward": 0.7769691953659058, "critic_loss": 0.7592287350296975, "actor_loss": -83.56353427124023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.238226652145386, "step": 26000}
{"episode_reward": 938.3684576610735, "episode": 27.0, "batch_reward": 0.7827562124133111, "critic_loss": 0.7597143971025944, "actor_loss": -83.74529232788086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.231971979141235, "step": 27000}
{"episode_reward": 900.0968179488993, "episode": 28.0, "batch_reward": 0.7847699776887894, "critic_loss": 0.7383654572069644, "actor_loss": -83.76186166381837, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.270506620407104, "step": 28000}
{"episode_reward": 887.1030352091417, "episode": 29.0, "batch_reward": 0.7918310533165932, "critic_loss": 0.7520081987977028, "actor_loss": -83.99715458679199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.259267807006836, "step": 29000}
{"episode_reward": 920.801409119591, "episode": 30.0, "batch_reward": 0.7928105961680413, "critic_loss": 0.7523365322947502, "actor_loss": -84.11612358093262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28096079826355, "step": 30000}
{"episode_reward": 890.9523011542084, "episode": 31.0, "batch_reward": 0.7962989803552628, "critic_loss": 0.773251792550087, "actor_loss": -84.17985229492187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.55748438835144, "step": 31000}
{"episode_reward": 893.2338408077011, "episode": 32.0, "batch_reward": 0.7990384393930435, "critic_loss": 0.8463621971011162, "actor_loss": -84.19964407348633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.239927768707275, "step": 32000}
{"episode_reward": 822.4594973770318, "episode": 33.0, "batch_reward": 0.8027098242044449, "critic_loss": 0.7994800701141357, "actor_loss": -84.35134226989746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.241586685180664, "step": 33000}
{"episode_reward": 938.6830663216878, "episode": 34.0, "batch_reward": 0.8062405516505241, "critic_loss": 0.7855787322819233, "actor_loss": -84.45553776550292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.279461145401, "step": 34000}
{"episode_reward": 936.0702674421179, "episode": 35.0, "batch_reward": 0.8081019144058228, "critic_loss": 0.8353945672214032, "actor_loss": -84.48018084716797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.264238357543945, "step": 35000}
{"episode_reward": 840.0934253830111, "episode": 36.0, "batch_reward": 0.813306114435196, "critic_loss": 0.8346350266039372, "actor_loss": -84.4962121887207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.236799955368042, "step": 36000}
{"episode_reward": 963.3470590995618, "episode": 37.0, "batch_reward": 0.8138381986618042, "critic_loss": 0.8754078534543515, "actor_loss": -84.5592587738037, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.263556241989136, "step": 37000}
{"episode_reward": 839.8325995958193, "episode": 38.0, "batch_reward": 0.8166125822067261, "critic_loss": 0.8988074947595597, "actor_loss": -84.81647610473632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.242346048355103, "step": 38000}
{"episode_reward": 939.0421288681479, "episode": 39.0, "batch_reward": 0.8194941094517708, "critic_loss": 0.935671416848898, "actor_loss": -84.87170635986328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.254253387451172, "step": 39000}
{"episode_reward": 938.0724816894391, "episode": 40.0, "batch_reward": 0.8187662900686264, "critic_loss": 1.1228040928244591, "actor_loss": -84.82395997619629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26317048072815, "step": 40000}
{"episode_reward": 719.298047067543, "episode": 41.0, "batch_reward": 0.8167852185964585, "critic_loss": 1.2229129750728607, "actor_loss": -84.82275708007812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.54843735694885, "step": 41000}
{"episode_reward": 850.526549889376, "episode": 42.0, "batch_reward": 0.8176152599453926, "critic_loss": 1.3502369968891144, "actor_loss": -85.02471368408203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.273136615753174, "step": 42000}
{"episode_reward": 847.4716061369295, "episode": 43.0, "batch_reward": 0.8213910784125328, "critic_loss": 1.228917747080326, "actor_loss": -85.08048550415039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.270373106002808, "step": 43000}
{"episode_reward": 897.5714301988534, "episode": 44.0, "batch_reward": 0.8201657478809357, "critic_loss": 1.2836600065231323, "actor_loss": -85.11070509338379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.284648895263672, "step": 44000}
{"episode_reward": 820.404810895894, "episode": 45.0, "batch_reward": 0.8211510230302811, "critic_loss": 1.3401606185436248, "actor_loss": -85.22834017944336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.271317958831787, "step": 45000}
{"episode_reward": 842.4023913580716, "episode": 46.0, "batch_reward": 0.8239455030560493, "critic_loss": 1.299973922431469, "actor_loss": -85.2154365234375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.257225036621094, "step": 46000}
{"episode_reward": 921.0921066564913, "episode": 47.0, "batch_reward": 0.8251240518689156, "critic_loss": 1.2746336265802383, "actor_loss": -85.19318516540527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.264518976211548, "step": 47000}
{"episode_reward": 865.8128208000379, "episode": 48.0, "batch_reward": 0.8238492532968521, "critic_loss": 1.2614925562143326, "actor_loss": -85.27766772460937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.265246391296387, "step": 48000}
{"episode_reward": 721.6007088870494, "episode": 49.0, "batch_reward": 0.8212972283363342, "critic_loss": 1.2461302719712257, "actor_loss": -85.10316555786133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.221025228500366, "step": 49000}
{"episode_reward": 730.1623516327062, "episode": 50.0, "batch_reward": 0.8197180285453797, "critic_loss": 1.2898288117051124, "actor_loss": -85.15897436523437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2471661567688, "step": 50000}
{"episode_reward": 744.8806319960017, "episode": 51.0, "batch_reward": 0.8201620950102806, "critic_loss": 1.3642159075737, "actor_loss": -85.33808728027344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.63783121109009, "step": 51000}
{"episode_reward": 792.0163002039133, "episode": 52.0, "batch_reward": 0.8174216674566269, "critic_loss": 1.398978687286377, "actor_loss": -85.02721528625489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.247183799743652, "step": 52000}
{"episode_reward": 799.9999812243632, "episode": 53.0, "batch_reward": 0.8196818181872367, "critic_loss": 1.3660288697481155, "actor_loss": -85.40212069702149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28571653366089, "step": 53000}
{"episode_reward": 865.3007682769336, "episode": 54.0, "batch_reward": 0.8203851178288459, "critic_loss": 1.3140294824838639, "actor_loss": -85.26316818237305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.270995616912842, "step": 54000}
{"episode_reward": 876.1671911961787, "episode": 55.0, "batch_reward": 0.8209312338232994, "critic_loss": 1.1987537843585014, "actor_loss": -85.44559181213378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.264146327972412, "step": 55000}
{"episode_reward": 899.6636355110738, "episode": 56.0, "batch_reward": 0.8231796512007713, "critic_loss": 1.1723280158638953, "actor_loss": -85.6278642578125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27828073501587, "step": 56000}
{"episode_reward": 892.351942226331, "episode": 57.0, "batch_reward": 0.8234505391120911, "critic_loss": 1.17819456076622, "actor_loss": -85.60767533874511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27905583381653, "step": 57000}
{"episode_reward": 939.2840828593577, "episode": 58.0, "batch_reward": 0.8250329141616821, "critic_loss": 1.2100851271152497, "actor_loss": -85.78773056030273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.271251440048218, "step": 58000}
{"episode_reward": 892.5049214626982, "episode": 59.0, "batch_reward": 0.8291985175013542, "critic_loss": 1.1930304049253464, "actor_loss": -85.77918466186523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27057433128357, "step": 59000}
{"episode_reward": 944.340734675734, "episode": 60.0, "batch_reward": 0.8293872027993202, "critic_loss": 1.1654032192826271, "actor_loss": -85.64035745239258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.239874362945557, "step": 60000}
{"episode_reward": 863.7236579788425, "episode": 61.0, "batch_reward": 0.8290938678383827, "critic_loss": 1.1644774065613748, "actor_loss": -85.67831639099121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.56320571899414, "step": 61000}
{"episode_reward": 889.8149294626575, "episode": 62.0, "batch_reward": 0.8309627115130425, "critic_loss": 1.1236417500972748, "actor_loss": -85.94197625732421, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27776050567627, "step": 62000}
{"episode_reward": 963.3572003876302, "episode": 63.0, "batch_reward": 0.8328042737841607, "critic_loss": 1.0790375616550445, "actor_loss": -85.96066218566895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.283292770385742, "step": 63000}
{"episode_reward": 942.2242344813895, "episode": 64.0, "batch_reward": 0.8344826822280884, "critic_loss": 1.0432021932005882, "actor_loss": -86.0015230255127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26263952255249, "step": 64000}
{"episode_reward": 917.0408308562506, "episode": 65.0, "batch_reward": 0.8353800010085106, "critic_loss": 0.98756243288517, "actor_loss": -86.08810659790039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.251126050949097, "step": 65000}
{"episode_reward": 932.5014043141226, "episode": 66.0, "batch_reward": 0.8367812032103539, "critic_loss": 0.9434484136998653, "actor_loss": -86.15787826538086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.243085145950317, "step": 66000}
{"episode_reward": 960.3014756242617, "episode": 67.0, "batch_reward": 0.84179970484972, "critic_loss": 0.8946355234980583, "actor_loss": -86.47272813415528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.263960361480713, "step": 67000}
{"episode_reward": 943.3870598065996, "episode": 68.0, "batch_reward": 0.8401239280700683, "critic_loss": 0.886352966785431, "actor_loss": -86.34167266845704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.280738353729248, "step": 68000}
{"episode_reward": 934.4310106624619, "episode": 69.0, "batch_reward": 0.8427879316210747, "critic_loss": 0.8828582811951637, "actor_loss": -86.42044998168946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2766592502594, "step": 69000}
{"episode_reward": 944.6264397514175, "episode": 70.0, "batch_reward": 0.8436490967869759, "critic_loss": 0.8465614520609379, "actor_loss": -86.42619075012207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.276515007019043, "step": 70000}
{"episode_reward": 921.0096222645907, "episode": 71.0, "batch_reward": 0.8446254107356072, "critic_loss": 0.8413646628856659, "actor_loss": -86.47404067993165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.59661293029785, "step": 71000}
{"episode_reward": 944.1518644835458, "episode": 72.0, "batch_reward": 0.8465103633999824, "critic_loss": 0.8307472813129425, "actor_loss": -86.57191641235352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.263532400131226, "step": 72000}
{"episode_reward": 906.2319316418334, "episode": 73.0, "batch_reward": 0.8464253740310669, "critic_loss": 0.780636600524187, "actor_loss": -86.55795471191406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.281233072280884, "step": 73000}
{"episode_reward": 965.2505814084016, "episode": 74.0, "batch_reward": 0.8492233517169953, "critic_loss": 0.783505899220705, "actor_loss": -86.69982072448731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.270933389663696, "step": 74000}
{"episode_reward": 953.4332414434218, "episode": 75.0, "batch_reward": 0.8507529228329659, "critic_loss": 0.7479845533072949, "actor_loss": -86.73161241149903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.256582975387573, "step": 75000}
{"episode_reward": 946.0445723145001, "episode": 76.0, "batch_reward": 0.8514756226539612, "critic_loss": 0.7316279745995998, "actor_loss": -86.77163526916505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.228171825408936, "step": 76000}
{"episode_reward": 930.5732245294539, "episode": 77.0, "batch_reward": 0.8531465489268303, "critic_loss": 0.7168123009800911, "actor_loss": -86.90419863891601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.254244565963745, "step": 77000}
{"episode_reward": 966.3232723482333, "episode": 78.0, "batch_reward": 0.8524249802231789, "critic_loss": 0.6934999932646752, "actor_loss": -86.91869793701171, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.269457578659058, "step": 78000}
{"episode_reward": 934.793421107367, "episode": 79.0, "batch_reward": 0.8551143702268601, "critic_loss": 0.716675732344389, "actor_loss": -87.03503370666503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.273513793945312, "step": 79000}
{"episode_reward": 892.114870345645, "episode": 80.0, "batch_reward": 0.8562800338864327, "critic_loss": 0.7376086082160472, "actor_loss": -87.00941397094726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.22581148147583, "step": 80000}
{"episode_reward": 961.2231239713162, "episode": 81.0, "batch_reward": 0.8555402706861496, "critic_loss": 0.6832762616872787, "actor_loss": -87.01814785766602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.585851192474365, "step": 81000}
{"episode_reward": 933.751118614011, "episode": 82.0, "batch_reward": 0.8555436970591546, "critic_loss": 0.7075168534517288, "actor_loss": -87.14668634033202, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.275817394256592, "step": 82000}
{"episode_reward": 949.9819203888526, "episode": 83.0, "batch_reward": 0.8567760457396507, "critic_loss": 0.7548247839212417, "actor_loss": -86.95964309692383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.59564709663391, "step": 83000}
{"episode_reward": 824.7811522394079, "episode": 84.0, "batch_reward": 0.8581685166954994, "critic_loss": 0.7521591526269913, "actor_loss": -86.96126892089843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.231276035308838, "step": 84000}
{"episode_reward": 932.0143846400225, "episode": 85.0, "batch_reward": 0.8584292637109756, "critic_loss": 0.7064866949915886, "actor_loss": -87.19442874145508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.237648248672485, "step": 85000}
{"episode_reward": 960.8176624594602, "episode": 86.0, "batch_reward": 0.8601253622174263, "critic_loss": 0.7031293693184852, "actor_loss": -87.17609896850585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.261383533477783, "step": 86000}
{"episode_reward": 927.1414770518032, "episode": 87.0, "batch_reward": 0.8611055609583854, "critic_loss": 0.7194923714697361, "actor_loss": -87.01140586853028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.251583337783813, "step": 87000}
{"episode_reward": 907.4857095538081, "episode": 88.0, "batch_reward": 0.8614777328372002, "critic_loss": 0.6811187965273857, "actor_loss": -87.05608380126954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25534963607788, "step": 88000}
{"episode_reward": 966.4308954701801, "episode": 89.0, "batch_reward": 0.8623721517920494, "critic_loss": 0.6956420013904572, "actor_loss": -87.33048109436035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2674617767334, "step": 89000}
{"episode_reward": 951.2411889002984, "episode": 90.0, "batch_reward": 0.8640178485512734, "critic_loss": 0.695421029061079, "actor_loss": -87.2679804534912, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.279160261154175, "step": 90000}
{"episode_reward": 960.31094724493, "episode": 91.0, "batch_reward": 0.8644297345876694, "critic_loss": 0.6901123250126838, "actor_loss": -87.35227795410157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.91241407394409, "step": 91000}
{"episode_reward": 911.1443907120414, "episode": 92.0, "batch_reward": 0.8664999860525131, "critic_loss": 0.6630957649052143, "actor_loss": -87.43221540832519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.261343717575073, "step": 92000}
{"episode_reward": 957.2748722395755, "episode": 93.0, "batch_reward": 0.8669507885575295, "critic_loss": 0.6535884120613337, "actor_loss": -87.42120970153809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.259604930877686, "step": 93000}
{"episode_reward": 958.3790655429334, "episode": 94.0, "batch_reward": 0.8670475924611092, "critic_loss": 0.6677871108353138, "actor_loss": -87.46876126098633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.230735540390015, "step": 94000}
{"episode_reward": 935.0020985221163, "episode": 95.0, "batch_reward": 0.8671955495476723, "critic_loss": 0.6743394749462605, "actor_loss": -87.3932680053711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.257676124572754, "step": 95000}
{"episode_reward": 831.8226777478566, "episode": 96.0, "batch_reward": 0.8672818674445152, "critic_loss": 0.6672387075424194, "actor_loss": -87.42106330871582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.248863458633423, "step": 96000}
{"episode_reward": 927.7355699150958, "episode": 97.0, "batch_reward": 0.8655972051024436, "critic_loss": 0.6977182680666447, "actor_loss": -87.40958753967286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.285626649856567, "step": 97000}
{"episode_reward": 908.8370844946933, "episode": 98.0, "batch_reward": 0.8697128034234047, "critic_loss": 0.6977194419801235, "actor_loss": -87.59387333679199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.293033599853516, "step": 98000}
{"episode_reward": 941.3858665228488, "episode": 99.0, "batch_reward": 0.8671482278704643, "critic_loss": 0.7247564285993576, "actor_loss": -87.29042253112793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28137445449829, "step": 99000}
{"episode_reward": 752.8492572408231, "episode": 100.0, "batch_reward": 0.8669494280815124, "critic_loss": 0.7220684087872505, "actor_loss": -87.38367987060546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.286279439926147, "step": 100000}
{"episode_reward": 956.2145171424238, "episode": 101.0, "batch_reward": 0.8688735267519951, "critic_loss": 0.6721221330463887, "actor_loss": -87.39344680786132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.57531023025513, "step": 101000}
{"episode_reward": 962.6969760163836, "episode": 102.0, "batch_reward": 0.8701726021766663, "critic_loss": 0.6983083853721619, "actor_loss": -87.42100584411621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29112195968628, "step": 102000}
{"episode_reward": 947.9842245774483, "episode": 103.0, "batch_reward": 0.8711776624321937, "critic_loss": 0.7176875306069851, "actor_loss": -87.49649635314941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.306578874588013, "step": 103000}
{"episode_reward": 935.3740757922783, "episode": 104.0, "batch_reward": 0.8717898522019386, "critic_loss": 0.7248917146623135, "actor_loss": -87.33154528808593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.274864673614502, "step": 104000}
{"episode_reward": 941.0170558106332, "episode": 105.0, "batch_reward": 0.8716957957744599, "critic_loss": 0.6964020746946334, "actor_loss": -87.49664134216309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.254457712173462, "step": 105000}
{"episode_reward": 962.4497921488332, "episode": 106.0, "batch_reward": 0.872145364522934, "critic_loss": 0.7055221351981164, "actor_loss": -87.39541003417969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.243096590042114, "step": 106000}
{"episode_reward": 898.0462110024165, "episode": 107.0, "batch_reward": 0.8724875246286392, "critic_loss": 0.6945494718253612, "actor_loss": -87.43192430114746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27366805076599, "step": 107000}
{"episode_reward": 905.1460030031502, "episode": 108.0, "batch_reward": 0.8728997001647949, "critic_loss": 0.7191479705274105, "actor_loss": -87.7294557800293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.279054403305054, "step": 108000}
{"episode_reward": 947.6019103588368, "episode": 109.0, "batch_reward": 0.8739782417416573, "critic_loss": 0.6776323314011097, "actor_loss": -87.40907823181152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.259093523025513, "step": 109000}
{"episode_reward": 933.6631838885856, "episode": 110.0, "batch_reward": 0.8757754282951355, "critic_loss": 0.6798006095290184, "actor_loss": -87.44725875854492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.267817735671997, "step": 110000}
{"episode_reward": 927.3293203972893, "episode": 111.0, "batch_reward": 0.875225895345211, "critic_loss": 0.6795341301262379, "actor_loss": -87.78734985351562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.616795778274536, "step": 111000}
{"episode_reward": 931.9014004307843, "episode": 112.0, "batch_reward": 0.8749479437470437, "critic_loss": 0.6806973091959954, "actor_loss": -87.40375468444824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29059386253357, "step": 112000}
{"episode_reward": 920.7329595010932, "episode": 113.0, "batch_reward": 0.8764077572226524, "critic_loss": 0.6569637696594, "actor_loss": -87.65709892272949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30520272254944, "step": 113000}
{"episode_reward": 968.7629712447263, "episode": 114.0, "batch_reward": 0.876607086122036, "critic_loss": 0.6774670673012734, "actor_loss": -87.64135699462891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.284337997436523, "step": 114000}
{"episode_reward": 961.8837411320668, "episode": 115.0, "batch_reward": 0.8769573330879211, "critic_loss": 0.6626995033472777, "actor_loss": -87.68595999145508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.249984979629517, "step": 115000}
{"episode_reward": 918.534699782913, "episode": 116.0, "batch_reward": 0.878320921599865, "critic_loss": 0.6702130967080593, "actor_loss": -87.68150654602051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26879096031189, "step": 116000}
{"episode_reward": 929.1064441183674, "episode": 117.0, "batch_reward": 0.8773206512331962, "critic_loss": 0.6471883054375649, "actor_loss": -88.03405278015137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.286046028137207, "step": 117000}
{"episode_reward": 932.576699713703, "episode": 118.0, "batch_reward": 0.8782577323317527, "critic_loss": 0.6371400417387485, "actor_loss": -87.86472766113282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.289641618728638, "step": 118000}
{"episode_reward": 938.3538425945209, "episode": 119.0, "batch_reward": 0.8801898142695427, "critic_loss": 0.6198580873310566, "actor_loss": -87.8796051940918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28466796875, "step": 119000}
{"episode_reward": 956.2881996527204, "episode": 120.0, "batch_reward": 0.879688517332077, "critic_loss": 0.5924539248049259, "actor_loss": -88.05472036743164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.286368370056152, "step": 120000}
{"episode_reward": 950.5545309933073, "episode": 121.0, "batch_reward": 0.8810152000188828, "critic_loss": 0.591818750873208, "actor_loss": -88.1370954284668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.602365255355835, "step": 121000}
{"episode_reward": 933.7118857898489, "episode": 122.0, "batch_reward": 0.8801128952503204, "critic_loss": 0.6055132889449596, "actor_loss": -88.05984146118163, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31574845314026, "step": 122000}
{"episode_reward": 934.7965227044651, "episode": 123.0, "batch_reward": 0.881984019100666, "critic_loss": 0.5825944598913193, "actor_loss": -87.98509838867187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28293514251709, "step": 123000}
{"episode_reward": 965.8225073656342, "episode": 124.0, "batch_reward": 0.8819778522253037, "critic_loss": 0.5917599923163652, "actor_loss": -88.0537245941162, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24251914024353, "step": 124000}
{"episode_reward": 949.3595720688755, "episode": 125.0, "batch_reward": 0.8839760870337486, "critic_loss": 0.5767010559439659, "actor_loss": -88.15668670654297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.238396883010864, "step": 125000}
{"episode_reward": 970.1064149589471, "episode": 126.0, "batch_reward": 0.8853088247179985, "critic_loss": 0.5541290588825941, "actor_loss": -88.25725479125977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27933096885681, "step": 126000}
{"episode_reward": 969.3789250598935, "episode": 127.0, "batch_reward": 0.8844010726809501, "critic_loss": 0.5610326390862465, "actor_loss": -87.97607368469238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.261075735092163, "step": 127000}
{"episode_reward": 932.7832576570562, "episode": 128.0, "batch_reward": 0.8838016145229339, "critic_loss": 0.5738638602793217, "actor_loss": -88.14097584533691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26837992668152, "step": 128000}
{"episode_reward": 967.5989735103769, "episode": 129.0, "batch_reward": 0.8840919650793075, "critic_loss": 0.5876493626534939, "actor_loss": -88.21922839355469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.293017387390137, "step": 129000}
{"episode_reward": 953.8610288153847, "episode": 130.0, "batch_reward": 0.8863123331665993, "critic_loss": 0.6209993385076523, "actor_loss": -88.3595687866211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27718448638916, "step": 130000}
{"episode_reward": 884.6985966513538, "episode": 131.0, "batch_reward": 0.8858306224942207, "critic_loss": 0.6005038351863623, "actor_loss": -88.10506486511231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.552006483078, "step": 131000}
{"episode_reward": 893.8827470619747, "episode": 132.0, "batch_reward": 0.8854077400565148, "critic_loss": 0.5992673167735338, "actor_loss": -88.11730401611328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.295010805130005, "step": 132000}
{"episode_reward": 900.3891723573114, "episode": 133.0, "batch_reward": 0.8867224538326264, "critic_loss": 0.6036554460227489, "actor_loss": -88.38983599853516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.557474613189697, "step": 133000}
{"episode_reward": 964.7556562839904, "episode": 134.0, "batch_reward": 0.8863596341013908, "critic_loss": 0.6358116919398308, "actor_loss": -88.46744961547851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.244877099990845, "step": 134000}
{"episode_reward": 882.8207691853565, "episode": 135.0, "batch_reward": 0.8869826931357384, "critic_loss": 0.6437803042829037, "actor_loss": -88.12142562866211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.234910249710083, "step": 135000}
{"episode_reward": 930.1686828843146, "episode": 136.0, "batch_reward": 0.8870340057015419, "critic_loss": 0.6310979280471801, "actor_loss": -88.779959274292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28294849395752, "step": 136000}
{"episode_reward": 960.1010850460391, "episode": 137.0, "batch_reward": 0.8880453426241874, "critic_loss": 0.6147920523434878, "actor_loss": -88.39386485290527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.268473625183105, "step": 137000}
{"episode_reward": 968.9978518050407, "episode": 138.0, "batch_reward": 0.8894316681027412, "critic_loss": 0.5910627456456423, "actor_loss": -88.43293161010742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.295106649398804, "step": 138000}
{"episode_reward": 964.4129250945927, "episode": 139.0, "batch_reward": 0.8877701196670532, "critic_loss": 0.5763421276211739, "actor_loss": -88.4143924407959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.291553735733032, "step": 139000}
{"episode_reward": 934.7562642173393, "episode": 140.0, "batch_reward": 0.8891022723913192, "critic_loss": 0.600001033231616, "actor_loss": -88.41921266174316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.269959449768066, "step": 140000}
{"episode_reward": 957.3511168872499, "episode": 141.0, "batch_reward": 0.8879269737005234, "critic_loss": 0.613473131865263, "actor_loss": -88.29270639038086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.60797047615051, "step": 141000}
{"episode_reward": 935.5055694157327, "episode": 142.0, "batch_reward": 0.8890298197865486, "critic_loss": 0.5839490596354008, "actor_loss": -88.63602355957032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.289952516555786, "step": 142000}
{"episode_reward": 935.0704463191355, "episode": 143.0, "batch_reward": 0.8902310723662377, "critic_loss": 0.5810777667015791, "actor_loss": -88.76889448547364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2720308303833, "step": 143000}
{"episode_reward": 951.3766681803692, "episode": 144.0, "batch_reward": 0.8915233060717582, "critic_loss": 0.5938183112740517, "actor_loss": -88.4724091796875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.223101139068604, "step": 144000}
{"episode_reward": 917.4722406931952, "episode": 145.0, "batch_reward": 0.8902025371789932, "critic_loss": 0.6078684661090374, "actor_loss": -88.4860428314209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.283249616622925, "step": 145000}
{"episode_reward": 879.5798514487517, "episode": 146.0, "batch_reward": 0.8911897566318512, "critic_loss": 0.5828872719109058, "actor_loss": -88.4738794555664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.289381504058838, "step": 146000}
{"episode_reward": 958.3275277463046, "episode": 147.0, "batch_reward": 0.8915145525336265, "critic_loss": 0.5667734072059393, "actor_loss": -88.49211062622071, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.286391258239746, "step": 147000}
{"episode_reward": 929.5762520652034, "episode": 148.0, "batch_reward": 0.8897147727012634, "critic_loss": 0.6107854205965996, "actor_loss": -88.52100094604492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.280763149261475, "step": 148000}
{"episode_reward": 847.2140329882865, "episode": 149.0, "batch_reward": 0.8904417122006416, "critic_loss": 0.614185696452856, "actor_loss": -88.56422444152832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.294281482696533, "step": 149000}
{"episode_reward": 961.6585707484512, "episode": 150.0, "batch_reward": 0.8902701561450959, "critic_loss": 0.5670552796423435, "actor_loss": -88.40265922546386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
