{"episode_reward": 0.0, "episode": 1.0, "duration": 23.700172424316406, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.915823221206665, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.29719239370490597, "critic_loss": 0.8520631037898444, "actor_loss": -68.81407794135721, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 65.40665173530579, "step": 3000}
{"episode_reward": 465.4715835113124, "episode": 4.0, "batch_reward": 0.33355911476910116, "critic_loss": 1.149181440293789, "actor_loss": -71.0684306793213, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.07760190963745, "step": 4000}
{"episode_reward": 179.11270778176092, "episode": 5.0, "batch_reward": 0.33722485464811325, "critic_loss": 1.1289563697874545, "actor_loss": -71.86379435729981, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.171058654785156, "step": 5000}
{"episode_reward": 662.1336585321118, "episode": 6.0, "batch_reward": 0.40616097623109815, "critic_loss": 0.978267293393612, "actor_loss": -73.11827688598633, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.543653964996338, "step": 6000}
{"episode_reward": 743.761868959758, "episode": 7.0, "batch_reward": 0.45807182186841966, "critic_loss": 0.8524859116077423, "actor_loss": -74.17627738952636, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.824991464614868, "step": 7000}
{"episode_reward": 716.4655447855378, "episode": 8.0, "batch_reward": 0.49318116235733034, "critic_loss": 0.8316790269017219, "actor_loss": -75.24300935363769, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.54806423187256, "step": 8000}
{"episode_reward": 803.2228876828113, "episode": 9.0, "batch_reward": 0.5328908306956291, "critic_loss": 0.8460286782085895, "actor_loss": -76.10889254760743, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.038206577301025, "step": 9000}
{"episode_reward": 848.66385502633, "episode": 10.0, "batch_reward": 0.5702455755770206, "critic_loss": 0.8286516495645047, "actor_loss": -76.99184649658203, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.984291553497314, "step": 10000}
{"episode_reward": 864.4453997010661, "episode": 11.0, "batch_reward": 0.5990391396284104, "critic_loss": 0.8548286171257495, "actor_loss": -77.74496571350097, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 44.21893262863159, "step": 11000}
{"episode_reward": 812.9998707715233, "episode": 12.0, "batch_reward": 0.6163328289985657, "critic_loss": 0.8155491712093353, "actor_loss": -78.11551525878906, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.849602699279785, "step": 12000}
{"episode_reward": 884.1123932497594, "episode": 13.0, "batch_reward": 0.6322477096319199, "critic_loss": 0.8136160382926464, "actor_loss": -78.51720460510253, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.496362686157227, "step": 13000}
{"episode_reward": 817.0469568010064, "episode": 14.0, "batch_reward": 0.64924190813303, "critic_loss": 0.7675840429663658, "actor_loss": -78.87845027160644, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.930354118347168, "step": 14000}
{"episode_reward": 863.4862336542624, "episode": 15.0, "batch_reward": 0.6676326012015342, "critic_loss": 0.6876163509786128, "actor_loss": -78.9039672088623, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.052091121673584, "step": 15000}
{"episode_reward": 918.9109709327116, "episode": 16.0, "batch_reward": 0.6790098222494125, "critic_loss": 0.6771606559157372, "actor_loss": -79.75477125549317, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.662846088409424, "step": 16000}
{"episode_reward": 821.472150492578, "episode": 17.0, "batch_reward": 0.6896317893862725, "critic_loss": 0.684347073584795, "actor_loss": -79.80792640686035, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.95676589012146, "step": 17000}
{"episode_reward": 850.4806610905265, "episode": 18.0, "batch_reward": 0.6965184124112129, "critic_loss": 0.6840566831231117, "actor_loss": -79.87606895446777, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.80135989189148, "step": 18000}
{"episode_reward": 802.7772698678889, "episode": 19.0, "batch_reward": 0.7007582321166992, "critic_loss": 0.7355086632668972, "actor_loss": -79.9164306793213, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.648897409439087, "step": 19000}
{"episode_reward": 749.182226612557, "episode": 20.0, "batch_reward": 0.7065010771155358, "critic_loss": 0.7839304693043232, "actor_loss": -79.65886177062988, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.15945053100586, "step": 20000}
{"episode_reward": 844.4980742130074, "episode": 21.0, "batch_reward": 0.7165431218743324, "critic_loss": 0.7667809660732746, "actor_loss": -80.0667435913086, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.675992250442505, "step": 21000}
{"episode_reward": 927.2493214752425, "episode": 22.0, "batch_reward": 0.721208582341671, "critic_loss": 0.867016642332077, "actor_loss": -80.19467498779296, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.15058994293213, "step": 22000}
{"episode_reward": 789.1607846291095, "episode": 23.0, "batch_reward": 0.7211439229249954, "critic_loss": 0.8906270339488983, "actor_loss": -80.24044654846192, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.52031660079956, "step": 23000}
{"episode_reward": 760.1345715414374, "episode": 24.0, "batch_reward": 0.7251129490733147, "critic_loss": 0.8593012068867684, "actor_loss": -80.44455841064453, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.40307641029358, "step": 24000}
{"episode_reward": 725.4061323127145, "episode": 25.0, "batch_reward": 0.7258672076463699, "critic_loss": 0.9308025889992714, "actor_loss": -80.23883068847657, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.57374334335327, "step": 25000}
{"episode_reward": 804.9102974973268, "episode": 26.0, "batch_reward": 0.7293603130578995, "critic_loss": 0.9309608879387379, "actor_loss": -80.33883547973633, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.174702405929565, "step": 26000}
{"episode_reward": 855.156156185095, "episode": 27.0, "batch_reward": 0.7371223083734513, "critic_loss": 0.8827215618193149, "actor_loss": -80.39419799804688, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.217267990112305, "step": 27000}
{"episode_reward": 892.7609931787225, "episode": 28.0, "batch_reward": 0.7381499097347259, "critic_loss": 0.9041746520698071, "actor_loss": -80.67845385742187, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.737700939178467, "step": 28000}
{"episode_reward": 773.1673830701192, "episode": 29.0, "batch_reward": 0.7434186402559281, "critic_loss": 0.9064694145023823, "actor_loss": -80.60870649719239, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.256263971328735, "step": 29000}
{"episode_reward": 880.575097365626, "episode": 30.0, "batch_reward": 0.743652997136116, "critic_loss": 0.985951550602913, "actor_loss": -80.65832675170898, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.781633615493774, "step": 30000}
{"episode_reward": 804.1763919981951, "episode": 31.0, "batch_reward": 0.7483784908056259, "critic_loss": 0.9740498121976853, "actor_loss": -80.76136593627929, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.821834325790405, "step": 31000}
{"episode_reward": 859.0863186246548, "episode": 32.0, "batch_reward": 0.7528650557994843, "critic_loss": 0.9682787163853646, "actor_loss": -80.89251722717285, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.97417426109314, "step": 32000}
{"episode_reward": 905.4035422471663, "episode": 33.0, "batch_reward": 0.757327270269394, "critic_loss": 0.9648917194902897, "actor_loss": -80.81467021179199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.79498052597046, "step": 33000}
{"episode_reward": 890.8599534010215, "episode": 34.0, "batch_reward": 0.7611931614875793, "critic_loss": 0.9480922740101815, "actor_loss": -81.27246403503418, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.989063262939453, "step": 34000}
{"episode_reward": 866.9240966631045, "episode": 35.0, "batch_reward": 0.762912450671196, "critic_loss": 0.9864184320867062, "actor_loss": -81.07495431518555, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.528080940246582, "step": 35000}
{"episode_reward": 864.1946314675586, "episode": 36.0, "batch_reward": 0.76854448980093, "critic_loss": 0.9727912513613701, "actor_loss": -81.59455924987793, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.133151531219482, "step": 36000}
{"episode_reward": 908.6776882519699, "episode": 37.0, "batch_reward": 0.7711380073428153, "critic_loss": 1.0688693890571594, "actor_loss": -81.38879370117188, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.308393239974976, "step": 37000}
{"episode_reward": 797.1119082838803, "episode": 38.0, "batch_reward": 0.7726411799788475, "critic_loss": 1.0432735977172851, "actor_loss": -81.25710025024414, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.721784591674805, "step": 38000}
{"episode_reward": 919.1418766490119, "episode": 39.0, "batch_reward": 0.7753373616933823, "critic_loss": 1.0481958237290383, "actor_loss": -81.53374336242676, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.666715145111084, "step": 39000}
{"episode_reward": 906.9699540707592, "episode": 40.0, "batch_reward": 0.7706162031292916, "critic_loss": 1.0125840112268925, "actor_loss": -81.39196408081055, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.413522481918335, "step": 40000}
{"episode_reward": 450.8626439686415, "episode": 41.0, "batch_reward": 0.7682104125618935, "critic_loss": 1.0303025100529193, "actor_loss": -81.4577361907959, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.18373966217041, "step": 41000}
{"episode_reward": 747.6553736540175, "episode": 42.0, "batch_reward": 0.7700600205659867, "critic_loss": 1.0184984965324402, "actor_loss": -81.32512619018554, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.6210675239563, "step": 42000}
{"episode_reward": 888.4359871539893, "episode": 43.0, "batch_reward": 0.7740461223125458, "critic_loss": 1.0004405641257763, "actor_loss": -81.56265652465821, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.585822343826294, "step": 43000}
{"episode_reward": 874.4289605759683, "episode": 44.0, "batch_reward": 0.7760423935651779, "critic_loss": 0.9866678327918053, "actor_loss": -81.4513454284668, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.574626922607422, "step": 44000}
{"episode_reward": 924.784906829565, "episode": 45.0, "batch_reward": 0.7793551853895188, "critic_loss": 0.9743318802118301, "actor_loss": -81.52284066772461, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.059789657592773, "step": 45000}
{"episode_reward": 900.578150619038, "episode": 46.0, "batch_reward": 0.783788341164589, "critic_loss": 0.9013738432228565, "actor_loss": -81.88132540893555, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.710445404052734, "step": 46000}
{"episode_reward": 946.6801330038501, "episode": 47.0, "batch_reward": 0.7854039932489395, "critic_loss": 0.8768594969511032, "actor_loss": -81.94207565307617, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.372234106063843, "step": 47000}
{"episode_reward": 868.071997699835, "episode": 48.0, "batch_reward": 0.7868219183683396, "critic_loss": 0.9306391450166702, "actor_loss": -81.93886267089843, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.065701484680176, "step": 48000}
{"episode_reward": 865.4707996037133, "episode": 49.0, "batch_reward": 0.7878717312812805, "critic_loss": 0.8746233847141266, "actor_loss": -81.98443171691895, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.5523464679718, "step": 49000}
{"episode_reward": 832.8904235098889, "episode": 50.0, "batch_reward": 0.790068522810936, "critic_loss": 0.8933943249285221, "actor_loss": -81.89411372375488, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.69900107383728, "step": 50000}
{"episode_reward": 929.9781359457372, "episode": 51.0, "batch_reward": 0.7948549001216888, "critic_loss": 0.8399988894462586, "actor_loss": -82.16601136779785, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.91148400306702, "step": 51000}
{"episode_reward": 941.478703074591, "episode": 52.0, "batch_reward": 0.7926026904582977, "critic_loss": 0.854139141023159, "actor_loss": -82.17257752990723, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.038867712020874, "step": 52000}
{"episode_reward": 813.6293955432216, "episode": 53.0, "batch_reward": 0.7963993872404098, "critic_loss": 0.8420311362743378, "actor_loss": -81.9450203704834, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.36348557472229, "step": 53000}
{"episode_reward": 911.3598301115599, "episode": 54.0, "batch_reward": 0.796835786640644, "critic_loss": 0.8460411275923252, "actor_loss": -82.55015458679199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.507057905197144, "step": 54000}
{"episode_reward": 902.9381649002424, "episode": 55.0, "batch_reward": 0.8004043133258819, "critic_loss": 0.8067638448774814, "actor_loss": -82.48213262939453, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.44213366508484, "step": 55000}
{"episode_reward": 902.378818492859, "episode": 56.0, "batch_reward": 0.8038255391120911, "critic_loss": 0.7856921072006225, "actor_loss": -82.26593606567383, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.031389236450195, "step": 56000}
{"episode_reward": 946.863754036074, "episode": 57.0, "batch_reward": 0.8042099253535271, "critic_loss": 0.7757597025930881, "actor_loss": -82.524017578125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.7353298664093, "step": 57000}
{"episode_reward": 882.6932457207615, "episode": 58.0, "batch_reward": 0.80585901927948, "critic_loss": 0.7627432539761066, "actor_loss": -82.51686813354492, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.752636909484863, "step": 58000}
{"episode_reward": 875.4066133403891, "episode": 59.0, "batch_reward": 0.80793195271492, "critic_loss": 0.7739593533277511, "actor_loss": -82.71488812255859, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.869667291641235, "step": 59000}
{"episode_reward": 931.8186663064602, "episode": 60.0, "batch_reward": 0.8082582119703293, "critic_loss": 0.7869490187168121, "actor_loss": -82.52345771789551, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.72978639602661, "step": 60000}
{"episode_reward": 873.460248497076, "episode": 61.0, "batch_reward": 0.8099515266418457, "critic_loss": 0.7650456826090812, "actor_loss": -82.82411839294434, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 45.69927382469177, "step": 61000}
{"episode_reward": 870.9532933086016, "episode": 62.0, "batch_reward": 0.8102904219031334, "critic_loss": 0.7992758676707744, "actor_loss": -82.65662121582031, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.052809715270996, "step": 62000}
{"episode_reward": 965.893132584052, "episode": 63.0, "batch_reward": 0.8127370466589927, "critic_loss": 0.7327347371876239, "actor_loss": -82.83482542419434, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.06259560585022, "step": 63000}
{"episode_reward": 937.541835605717, "episode": 64.0, "batch_reward": 0.8143313310146332, "critic_loss": 0.7404422428905963, "actor_loss": -83.03230561828613, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.754732847213745, "step": 64000}
{"episode_reward": 879.4585424418877, "episode": 65.0, "batch_reward": 0.815474592268467, "critic_loss": 0.7151795225739479, "actor_loss": -82.89604364013672, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.487635135650635, "step": 65000}
{"episode_reward": 926.5946714184565, "episode": 66.0, "batch_reward": 0.8170096679329872, "critic_loss": 0.7323686424195767, "actor_loss": -83.01059867858886, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.73705506324768, "step": 66000}
{"episode_reward": 898.389465016989, "episode": 67.0, "batch_reward": 0.8207564652562142, "critic_loss": 0.7588758302927017, "actor_loss": -83.08323965454102, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.451106309890747, "step": 67000}
{"episode_reward": 836.2829006302197, "episode": 68.0, "batch_reward": 0.8181191047430039, "critic_loss": 0.7422515698671341, "actor_loss": -83.30818714904785, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.741060495376587, "step": 68000}
{"episode_reward": 855.7533366582759, "episode": 69.0, "batch_reward": 0.821168880224228, "critic_loss": 0.7275744482278824, "actor_loss": -83.29102223205567, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.325405597686768, "step": 69000}
{"episode_reward": 924.3226002020086, "episode": 70.0, "batch_reward": 0.8212896280884743, "critic_loss": 0.7523367750942707, "actor_loss": -83.40847862243652, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.20112657546997, "step": 70000}
{"episode_reward": 911.947142315557, "episode": 71.0, "batch_reward": 0.823240249991417, "critic_loss": 0.755688132852316, "actor_loss": -83.17954095458984, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.35133767127991, "step": 71000}
{"episode_reward": 943.2995879164363, "episode": 72.0, "batch_reward": 0.8260991185307502, "critic_loss": 0.7397179355919361, "actor_loss": -83.41555082702637, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.10260820388794, "step": 72000}
{"episode_reward": 848.3726842844187, "episode": 73.0, "batch_reward": 0.824949018239975, "critic_loss": 0.7674593952596187, "actor_loss": -83.41645544433594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.42277717590332, "step": 73000}
{"episode_reward": 947.2405739421649, "episode": 74.0, "batch_reward": 0.8272245200276375, "critic_loss": 0.7241752953827381, "actor_loss": -83.50838932800293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.809600591659546, "step": 74000}
{"episode_reward": 948.522319910826, "episode": 75.0, "batch_reward": 0.8291236212849618, "critic_loss": 0.7494526392817498, "actor_loss": -83.59713523864747, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.399678945541382, "step": 75000}
{"episode_reward": 940.4249081131971, "episode": 76.0, "batch_reward": 0.8303675887584686, "critic_loss": 0.7451681185364724, "actor_loss": -83.62736431884765, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.042848825454712, "step": 76000}
{"episode_reward": 908.8942862341657, "episode": 77.0, "batch_reward": 0.8320096337199211, "critic_loss": 0.7245200584232807, "actor_loss": -83.67094369506836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.178244829177856, "step": 77000}
{"episode_reward": 948.4297166065983, "episode": 78.0, "batch_reward": 0.8316836341619491, "critic_loss": 0.7509118691384792, "actor_loss": -83.64037101745606, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.311879634857178, "step": 78000}
{"episode_reward": 859.6105444191176, "episode": 79.0, "batch_reward": 0.8326197038292885, "critic_loss": 0.7199826084971428, "actor_loss": -83.71556005859375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.91850757598877, "step": 79000}
{"episode_reward": 923.3350176876728, "episode": 80.0, "batch_reward": 0.8342710663676262, "critic_loss": 0.7033251539766788, "actor_loss": -83.80888558959961, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.89066433906555, "step": 80000}
{"episode_reward": 952.4403561372206, "episode": 81.0, "batch_reward": 0.8347414631843567, "critic_loss": 0.7219827767908573, "actor_loss": -83.68744239807128, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.553863525390625, "step": 81000}
{"episode_reward": 843.6248629230291, "episode": 82.0, "batch_reward": 0.8344790782928467, "critic_loss": 0.69539046895504, "actor_loss": -83.80859226989746, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.93710207939148, "step": 82000}
{"episode_reward": 951.1811449877762, "episode": 83.0, "batch_reward": 0.8356183353066444, "critic_loss": 0.7109951603114605, "actor_loss": -83.96917121887208, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.35392737388611, "step": 83000}
{"episode_reward": 876.5024215172233, "episode": 84.0, "batch_reward": 0.8358273205757141, "critic_loss": 0.7007989104986191, "actor_loss": -84.05760517883301, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.59996795654297, "step": 84000}
{"episode_reward": 872.5513820607727, "episode": 85.0, "batch_reward": 0.836358676970005, "critic_loss": 0.7332180581092834, "actor_loss": -83.91821923828125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.738949060440063, "step": 85000}
{"episode_reward": 941.6930075222534, "episode": 86.0, "batch_reward": 0.8383168063759804, "critic_loss": 0.7098026101291179, "actor_loss": -83.98360679626465, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.794840574264526, "step": 86000}
{"episode_reward": 919.3506954742232, "episode": 87.0, "batch_reward": 0.840198809504509, "critic_loss": 0.7154177225530147, "actor_loss": -84.090046585083, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.025266647338867, "step": 87000}
{"episode_reward": 935.4258797771756, "episode": 88.0, "batch_reward": 0.8395144404768944, "critic_loss": 0.7081674599945545, "actor_loss": -84.14722673034667, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.630085229873657, "step": 88000}
{"episode_reward": 944.3065387757864, "episode": 89.0, "batch_reward": 0.8420146662592888, "critic_loss": 0.6652340596318245, "actor_loss": -84.17597727966309, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.038726091384888, "step": 89000}
{"episode_reward": 953.388314226836, "episode": 90.0, "batch_reward": 0.8420218172073364, "critic_loss": 0.6907716130316257, "actor_loss": -84.29712268066406, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.66670870780945, "step": 90000}
{"episode_reward": 960.0687622633102, "episode": 91.0, "batch_reward": 0.8440857115983963, "critic_loss": 0.6798896647542715, "actor_loss": -84.28698881530762, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 44.87786340713501, "step": 91000}
{"episode_reward": 896.731481351123, "episode": 92.0, "batch_reward": 0.8463078072667122, "critic_loss": 0.6703542543053627, "actor_loss": -84.39440963745118, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.9025239944458, "step": 92000}
{"episode_reward": 950.3113008665563, "episode": 93.0, "batch_reward": 0.8460987085700035, "critic_loss": 0.6457543566524983, "actor_loss": -84.45417953491211, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.512213945388794, "step": 93000}
{"episode_reward": 953.4238294679923, "episode": 94.0, "batch_reward": 0.8473506906032562, "critic_loss": 0.6947387199103833, "actor_loss": -84.54471946716309, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.91729712486267, "step": 94000}
{"episode_reward": 862.2468066953749, "episode": 95.0, "batch_reward": 0.8475251777768135, "critic_loss": 0.6945179263651371, "actor_loss": -84.5379767150879, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.751507997512817, "step": 95000}
{"episode_reward": 924.6986742401284, "episode": 96.0, "batch_reward": 0.8465859434604645, "critic_loss": 0.6883647476136684, "actor_loss": -84.46623245239257, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.777758598327637, "step": 96000}
{"episode_reward": 879.6814558033606, "episode": 97.0, "batch_reward": 0.8477339869141579, "critic_loss": 0.7058979659974575, "actor_loss": -84.46831753540039, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.017744779586792, "step": 97000}
{"episode_reward": 890.0998061861437, "episode": 98.0, "batch_reward": 0.8485637685656547, "critic_loss": 0.7045953748524189, "actor_loss": -84.45677378845215, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.0367112159729, "step": 98000}
{"episode_reward": 895.0795163405279, "episode": 99.0, "batch_reward": 0.8491918397545815, "critic_loss": 0.7305965359508991, "actor_loss": -84.522634475708, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.273869514465332, "step": 99000}
{"episode_reward": 813.0637126071239, "episode": 100.0, "batch_reward": 0.8486676369905471, "critic_loss": 0.7165433104038239, "actor_loss": -84.4871332397461, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.37845730781555, "step": 100000}
{"episode_reward": 929.6159006377474, "episode": 101.0, "batch_reward": 0.8502037854194641, "critic_loss": 0.7107146822214127, "actor_loss": -84.53018252563477, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.2482225894928, "step": 101000}
{"episode_reward": 935.1358379160598, "episode": 102.0, "batch_reward": 0.8510917575359345, "critic_loss": 0.6961265695393085, "actor_loss": -84.64774397277831, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.584324836730957, "step": 102000}
{"episode_reward": 927.6182182735417, "episode": 103.0, "batch_reward": 0.8512285130023957, "critic_loss": 0.7510979020893573, "actor_loss": -84.54224548339843, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.79011607170105, "step": 103000}
{"episode_reward": 886.0786274814238, "episode": 104.0, "batch_reward": 0.851464908361435, "critic_loss": 0.7148589434325695, "actor_loss": -84.60510432434081, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.228111267089844, "step": 104000}
{"episode_reward": 939.2071907404414, "episode": 105.0, "batch_reward": 0.8533027475476265, "critic_loss": 0.7056498762965202, "actor_loss": -84.55649690246582, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.090075731277466, "step": 105000}
{"episode_reward": 938.2557121546304, "episode": 106.0, "batch_reward": 0.8515584802627564, "critic_loss": 0.7453196085095406, "actor_loss": -84.73187463378906, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.208943128585815, "step": 106000}
{"episode_reward": 892.1269303992583, "episode": 107.0, "batch_reward": 0.8534523859620095, "critic_loss": 0.7408309192061424, "actor_loss": -84.65882746887208, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.57932996749878, "step": 107000}
{"episode_reward": 879.0137872415376, "episode": 108.0, "batch_reward": 0.8538513478040696, "critic_loss": 0.7072336764335633, "actor_loss": -84.58089898681641, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.5299289226532, "step": 108000}
{"episode_reward": 937.3160317088284, "episode": 109.0, "batch_reward": 0.8550254766345025, "critic_loss": 0.7106354451477528, "actor_loss": -84.76210813903809, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.222041368484497, "step": 109000}
{"episode_reward": 919.7242795514692, "episode": 110.0, "batch_reward": 0.8551366894245148, "critic_loss": 0.7043919965028763, "actor_loss": -84.72535096740722, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.476074695587158, "step": 110000}
{"episode_reward": 930.7431593932937, "episode": 111.0, "batch_reward": 0.8563806657195091, "critic_loss": 0.7089783691763878, "actor_loss": -84.7366837158203, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.13546967506409, "step": 111000}
{"episode_reward": 907.4283429845866, "episode": 112.0, "batch_reward": 0.85596517431736, "critic_loss": 0.6956047657430172, "actor_loss": -84.82843406677246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.071322917938232, "step": 112000}
{"episode_reward": 895.9040721680176, "episode": 113.0, "batch_reward": 0.857754778265953, "critic_loss": 0.6913289337009192, "actor_loss": -84.8328618774414, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.257186889648438, "step": 113000}
{"episode_reward": 951.5311753666205, "episode": 114.0, "batch_reward": 0.8573621813058853, "critic_loss": 0.6932059286832809, "actor_loss": -84.891587890625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.616703748703003, "step": 114000}
{"episode_reward": 945.4385567651918, "episode": 115.0, "batch_reward": 0.8572377815842629, "critic_loss": 0.7171176265180111, "actor_loss": -84.85009521484375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.76804232597351, "step": 115000}
{"episode_reward": 867.4498124187514, "episode": 116.0, "batch_reward": 0.8596035583019257, "critic_loss": 0.7107111851871014, "actor_loss": -84.91620407104492, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.608203887939453, "step": 116000}
{"episode_reward": 908.2338547131938, "episode": 117.0, "batch_reward": 0.8574368333816529, "critic_loss": 0.7082944674789906, "actor_loss": -84.75325323486328, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.41885805130005, "step": 117000}
{"episode_reward": 914.8356354022231, "episode": 118.0, "batch_reward": 0.8591082918047905, "critic_loss": 0.7037051569521428, "actor_loss": -84.87907035827637, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.90406847000122, "step": 118000}
{"episode_reward": 932.4301398365494, "episode": 119.0, "batch_reward": 0.8611864309906959, "critic_loss": 0.7137023785412312, "actor_loss": -84.96693151855469, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.998880624771118, "step": 119000}
{"episode_reward": 950.4154280511337, "episode": 120.0, "batch_reward": 0.8607824106812477, "critic_loss": 0.6979273881763219, "actor_loss": -84.94789999389648, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.021055459976196, "step": 120000}
{"episode_reward": 958.0455907719186, "episode": 121.0, "batch_reward": 0.8618678647279739, "critic_loss": 0.7033441365361214, "actor_loss": -85.01050576782227, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.30140233039856, "step": 121000}
{"episode_reward": 822.3022608711051, "episode": 122.0, "batch_reward": 0.8618255583047867, "critic_loss": 0.7027405023872852, "actor_loss": -84.98863346862792, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.932276487350464, "step": 122000}
{"episode_reward": 923.0777094163146, "episode": 123.0, "batch_reward": 0.8623811234235763, "critic_loss": 0.7236515121459961, "actor_loss": -85.04396687316894, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.029412031173706, "step": 123000}
{"episode_reward": 876.3543242737477, "episode": 124.0, "batch_reward": 0.8630760554671287, "critic_loss": 0.7305331285893917, "actor_loss": -85.07559007263184, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.324934482574463, "step": 124000}
{"episode_reward": 949.1428271381811, "episode": 125.0, "batch_reward": 0.8630656814575195, "critic_loss": 0.747519505739212, "actor_loss": -85.0985072479248, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.182724237442017, "step": 125000}
{"episode_reward": 943.8047361627962, "episode": 126.0, "batch_reward": 0.8639902721047401, "critic_loss": 0.7219703640341759, "actor_loss": -85.01360794067382, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.079246997833252, "step": 126000}
{"episode_reward": 952.2145057400064, "episode": 127.0, "batch_reward": 0.863867622435093, "critic_loss": 0.69438429915905, "actor_loss": -85.05334007263184, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.128987550735474, "step": 127000}
{"episode_reward": 909.1005235868071, "episode": 128.0, "batch_reward": 0.8633882750868798, "critic_loss": 0.690374731555581, "actor_loss": -85.13948194885253, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.292930126190186, "step": 128000}
{"episode_reward": 940.7560444794344, "episode": 129.0, "batch_reward": 0.8638159044384957, "critic_loss": 0.71117627120018, "actor_loss": -85.09152716064453, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.506086111068726, "step": 129000}
{"episode_reward": 929.8753942459169, "episode": 130.0, "batch_reward": 0.8668568506836891, "critic_loss": 0.6875231692045927, "actor_loss": -85.18353437805176, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.8969943523407, "step": 130000}
{"episode_reward": 918.1081529623407, "episode": 131.0, "batch_reward": 0.8668588745594025, "critic_loss": 0.7058909662365913, "actor_loss": -85.155927444458, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 44.81026864051819, "step": 131000}
{"episode_reward": 932.4775183483845, "episode": 132.0, "batch_reward": 0.8654740958213806, "critic_loss": 0.741066068559885, "actor_loss": -85.21872914123536, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.347803592681885, "step": 132000}
{"episode_reward": 870.8843387056901, "episode": 133.0, "batch_reward": 0.8669223746657372, "critic_loss": 0.7185058707296849, "actor_loss": -85.2111545715332, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.904818058013916, "step": 133000}
{"episode_reward": 940.0482738913169, "episode": 134.0, "batch_reward": 0.8671237622499466, "critic_loss": 0.7372195065617562, "actor_loss": -85.2371880645752, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.412389278411865, "step": 134000}
{"episode_reward": 941.5512427151409, "episode": 135.0, "batch_reward": 0.8678581925034523, "critic_loss": 0.7498766480982304, "actor_loss": -85.25169004821777, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.294171810150146, "step": 135000}
{"episode_reward": 779.645395447723, "episode": 136.0, "batch_reward": 0.8681361687779426, "critic_loss": 0.7564309140443802, "actor_loss": -85.22575143432617, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.208646535873413, "step": 136000}
{"episode_reward": 950.2374482435714, "episode": 137.0, "batch_reward": 0.8670787283182144, "critic_loss": 0.7540435924232006, "actor_loss": -85.33660340881347, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.58156418800354, "step": 137000}
{"episode_reward": 948.8002269423567, "episode": 138.0, "batch_reward": 0.8695298539996147, "critic_loss": 0.7783911350667476, "actor_loss": -85.37508464050293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.15272092819214, "step": 138000}
{"episode_reward": 928.5453803023617, "episode": 139.0, "batch_reward": 0.8678903512358666, "critic_loss": 0.7871434718072414, "actor_loss": -85.32897351074219, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.846863269805908, "step": 139000}
{"episode_reward": 885.2969389017617, "episode": 140.0, "batch_reward": 0.8698303064107895, "critic_loss": 0.7363245071172714, "actor_loss": -85.3493246307373, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.649664878845215, "step": 140000}
{"episode_reward": 952.0886099762487, "episode": 141.0, "batch_reward": 0.8678544556498528, "critic_loss": 0.7459953266084194, "actor_loss": -85.24724569702148, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.1687958240509, "step": 141000}
{"episode_reward": 934.6496508949989, "episode": 142.0, "batch_reward": 0.8693897230625153, "critic_loss": 0.7562203681468964, "actor_loss": -85.27323266601563, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.870964527130127, "step": 142000}
{"episode_reward": 924.593583767727, "episode": 143.0, "batch_reward": 0.8696524940133095, "critic_loss": 0.724666985809803, "actor_loss": -85.36718728637695, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.090490102767944, "step": 143000}
{"episode_reward": 952.174022910573, "episode": 144.0, "batch_reward": 0.8709234115481377, "critic_loss": 0.708766864091158, "actor_loss": -85.4106316986084, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.5056574344635, "step": 144000}
{"episode_reward": 859.5008900551937, "episode": 145.0, "batch_reward": 0.8709394643902779, "critic_loss": 0.7240709590613842, "actor_loss": -85.44179824829102, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.101823806762695, "step": 145000}
{"episode_reward": 878.9962121693673, "episode": 146.0, "batch_reward": 0.870553815484047, "critic_loss": 0.7406829522550106, "actor_loss": -85.4457442932129, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.070128440856934, "step": 146000}
{"episode_reward": 917.6918514491264, "episode": 147.0, "batch_reward": 0.870969229400158, "critic_loss": 0.7408768665492534, "actor_loss": -85.44761932373046, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.816389083862305, "step": 147000}
{"episode_reward": 899.2831682957136, "episode": 148.0, "batch_reward": 0.8699572185277938, "critic_loss": 0.742609731823206, "actor_loss": -85.41650276184082, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.931403636932373, "step": 148000}
{"episode_reward": 867.7778418154642, "episode": 149.0, "batch_reward": 0.8709435997605324, "critic_loss": 0.7444438335895538, "actor_loss": -85.47025270080566, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.82066583633423, "step": 149000}
{"episode_reward": 962.009839307567, "episode": 150.0, "batch_reward": 0.8708471944332122, "critic_loss": 0.695298568546772, "actor_loss": -85.41963972473144, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
