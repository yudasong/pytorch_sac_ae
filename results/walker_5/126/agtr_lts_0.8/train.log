{"episode_reward": 0.0, "episode": 1.0, "duration": 20.60625958442688, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.7893943786621094, "step": 2000}
{"episode_reward": 847.8889533166544, "episode": 3.0, "batch_reward": 0.47651261916038157, "critic_loss": 0.3060656912219886, "actor_loss": -84.53134898063229, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.50764489173889, "step": 3000}
{"episode_reward": 900.4809176255334, "episode": 4.0, "batch_reward": 0.5980944496095181, "critic_loss": 0.6510398223400116, "actor_loss": -87.18707429504394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087207555770874, "step": 4000}
{"episode_reward": 757.1313719424447, "episode": 5.0, "batch_reward": 0.664634065926075, "critic_loss": 0.5122900495827198, "actor_loss": -88.67077491760254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087509870529175, "step": 5000}
{"episode_reward": 934.8263646859, "episode": 6.0, "batch_reward": 0.716607195854187, "critic_loss": 0.6183525494337082, "actor_loss": -89.85824096679687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.065174341201782, "step": 6000}
{"episode_reward": 951.6362946685839, "episode": 7.0, "batch_reward": 0.743523185133934, "critic_loss": 0.8706324941217899, "actor_loss": -90.20967944335938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06088089942932, "step": 7000}
{"episode_reward": 892.5008686418729, "episode": 8.0, "batch_reward": 0.7679449927806854, "critic_loss": 0.9643286507427692, "actor_loss": -90.7878810119629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05931329727173, "step": 8000}
{"episode_reward": 896.8103838883189, "episode": 9.0, "batch_reward": 0.7896611082553864, "critic_loss": 0.9415934365987778, "actor_loss": -91.13290266418457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.062447547912598, "step": 9000}
{"episode_reward": 981.5940595619157, "episode": 10.0, "batch_reward": 0.8041992680430412, "critic_loss": 1.137563437640667, "actor_loss": -91.59538111877441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.055177211761475, "step": 10000}
{"episode_reward": 914.712432948195, "episode": 11.0, "batch_reward": 0.8207446121573448, "critic_loss": 1.4480225265026092, "actor_loss": -92.25232421875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.39956831932068, "step": 11000}
{"episode_reward": 967.0588085400285, "episode": 12.0, "batch_reward": 0.8306830545663834, "critic_loss": 2.0555041943192482, "actor_loss": -92.6843546447754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.063316583633423, "step": 12000}
{"episode_reward": 940.8073774725824, "episode": 13.0, "batch_reward": 0.8348630670905113, "critic_loss": 2.3815100672245024, "actor_loss": -92.84291583251954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.051679849624634, "step": 13000}
{"episode_reward": 901.0285554758083, "episode": 14.0, "batch_reward": 0.8439176542758942, "critic_loss": 4.130739626824856, "actor_loss": -93.42509715270997, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.061396598815918, "step": 14000}
{"episode_reward": 954.9224694793149, "episode": 15.0, "batch_reward": 0.8213710967898369, "critic_loss": 6.369616166353226, "actor_loss": -94.0232123413086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.088836908340454, "step": 15000}
{"episode_reward": 53.26381383606855, "episode": 16.0, "batch_reward": 0.7846511543393135, "critic_loss": 7.518494944095612, "actor_loss": -93.53145190429687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.075897932052612, "step": 16000}
{"episode_reward": 269.74670289136185, "episode": 17.0, "batch_reward": 0.7415765706896782, "critic_loss": 5.789200862407684, "actor_loss": -93.7387216796875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11330795288086, "step": 17000}
{"episode_reward": 25.560532842073354, "episode": 18.0, "batch_reward": 0.7015838003754615, "critic_loss": 4.217005539298057, "actor_loss": -93.33536109924316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.101920127868652, "step": 18000}
{"episode_reward": 63.11378328624998, "episode": 19.0, "batch_reward": 0.6909044344425201, "critic_loss": 2.649333108007908, "actor_loss": -92.98267660522461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.079631328582764, "step": 19000}
{"episode_reward": 973.335378820304, "episode": 20.0, "batch_reward": 0.7027748041749, "critic_loss": 1.8341128503084183, "actor_loss": -93.33090046691895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.061945915222168, "step": 20000}
{"episode_reward": 899.6982132628997, "episode": 21.0, "batch_reward": 0.7162114543914795, "critic_loss": 1.420120138168335, "actor_loss": -93.14274353027344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.54205250740051, "step": 21000}
{"episode_reward": 982.3423704814434, "episode": 22.0, "batch_reward": 0.7059802156686783, "critic_loss": 1.3679922411441803, "actor_loss": -92.76843927001953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08725905418396, "step": 22000}
{"episode_reward": 40.086629593324176, "episode": 23.0, "batch_reward": 0.6893561187982559, "critic_loss": 1.4344533147215843, "actor_loss": -91.98659677124023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.065394163131714, "step": 23000}
{"episode_reward": 647.3800541378415, "episode": 24.0, "batch_reward": 0.6895043608546257, "critic_loss": 1.6684366495609284, "actor_loss": -91.58678620910645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.057421445846558, "step": 24000}
{"episode_reward": 634.5214366853296, "episode": 25.0, "batch_reward": 0.6911887968182564, "critic_loss": 1.303851104438305, "actor_loss": -91.21043424987793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.062907695770264, "step": 25000}
{"episode_reward": 960.1476432126569, "episode": 26.0, "batch_reward": 0.6968052424788475, "critic_loss": 1.4418830743432045, "actor_loss": -90.98901351928711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0538227558136, "step": 26000}
{"episode_reward": 636.3736767954051, "episode": 27.0, "batch_reward": 0.7005128557085991, "critic_loss": 1.1887101732492447, "actor_loss": -90.8745267791748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.057433366775513, "step": 27000}
{"episode_reward": 960.1127936405948, "episode": 28.0, "batch_reward": 0.7055756569504738, "critic_loss": 1.111055612385273, "actor_loss": -90.60288368225098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.060232639312744, "step": 28000}
{"episode_reward": 928.7404849905419, "episode": 29.0, "batch_reward": 0.7172217695713043, "critic_loss": 1.0301627145707608, "actor_loss": -90.6133490447998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.057209968566895, "step": 29000}
{"episode_reward": 971.1039233698523, "episode": 30.0, "batch_reward": 0.7235924307107925, "critic_loss": 1.07808053958416, "actor_loss": -90.74055586242676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07296061515808, "step": 30000}
{"episode_reward": 877.7953127277007, "episode": 31.0, "batch_reward": 0.728305824816227, "critic_loss": 1.0627439908981324, "actor_loss": -90.78505059814454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.44162559509277, "step": 31000}
{"episode_reward": 845.941240223103, "episode": 32.0, "batch_reward": 0.7309128862023354, "critic_loss": 0.9979777321219444, "actor_loss": -90.77226119995117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.084769010543823, "step": 32000}
{"episode_reward": 858.4076748602669, "episode": 33.0, "batch_reward": 0.7334073661565781, "critic_loss": 1.1048341912329196, "actor_loss": -90.7543116607666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.074516773223877, "step": 33000}
{"episode_reward": 779.6500271889407, "episode": 34.0, "batch_reward": 0.7369877906441689, "critic_loss": 1.137115564674139, "actor_loss": -90.72644953918457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07347798347473, "step": 34000}
{"episode_reward": 885.9902837111614, "episode": 35.0, "batch_reward": 0.7420914796590805, "critic_loss": 1.1285280347466469, "actor_loss": -90.72166609191895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.079896688461304, "step": 35000}
{"episode_reward": 948.7830208345639, "episode": 36.0, "batch_reward": 0.7465163149833679, "critic_loss": 1.2066192399263382, "actor_loss": -91.00903079223633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.078839778900146, "step": 36000}
{"episode_reward": 878.0320686793665, "episode": 37.0, "batch_reward": 0.7514598551988602, "critic_loss": 1.210178715109825, "actor_loss": -90.90898823547363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.058033227920532, "step": 37000}
{"episode_reward": 836.402311008879, "episode": 38.0, "batch_reward": 0.7576452588438988, "critic_loss": 1.113798224389553, "actor_loss": -90.82236117553711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.064851760864258, "step": 38000}
{"episode_reward": 975.9075781683974, "episode": 39.0, "batch_reward": 0.7599598857760429, "critic_loss": 1.087626139640808, "actor_loss": -91.04461735534667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.062132358551025, "step": 39000}
{"episode_reward": 961.6711668772706, "episode": 40.0, "batch_reward": 0.763462774693966, "critic_loss": 1.101643382102251, "actor_loss": -91.04233869934082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06968641281128, "step": 40000}
{"episode_reward": 925.1388095286345, "episode": 41.0, "batch_reward": 0.7671967910528183, "critic_loss": 1.2818445466160775, "actor_loss": -91.29030921936035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.40004110336304, "step": 41000}
{"episode_reward": 885.769432163441, "episode": 42.0, "batch_reward": 0.7712835634350776, "critic_loss": 1.1517360732257367, "actor_loss": -91.05450869750976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.065606832504272, "step": 42000}
{"episode_reward": 971.1786312062668, "episode": 43.0, "batch_reward": 0.7757320585846901, "critic_loss": 1.1816404717564584, "actor_loss": -91.33436529541015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06402325630188, "step": 43000}
{"episode_reward": 912.5759798784247, "episode": 44.0, "batch_reward": 0.7817162061929703, "critic_loss": 1.1859302822649478, "actor_loss": -91.44698608398437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.065030574798584, "step": 44000}
{"episode_reward": 953.2140704415931, "episode": 45.0, "batch_reward": 0.7844459984302521, "critic_loss": 1.1667681946158408, "actor_loss": -91.47199098205566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085782289505005, "step": 45000}
{"episode_reward": 942.803411558533, "episode": 46.0, "batch_reward": 0.7883249052762985, "critic_loss": 1.1034752737283706, "actor_loss": -91.60969593811035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.058957815170288, "step": 46000}
{"episode_reward": 960.7765482906722, "episode": 47.0, "batch_reward": 0.790669257581234, "critic_loss": 1.0307380983233452, "actor_loss": -91.75914921569824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.064927101135254, "step": 47000}
{"episode_reward": 935.5531601856673, "episode": 48.0, "batch_reward": 0.795219242155552, "critic_loss": 1.084686714977026, "actor_loss": -91.83477819824219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.056370973587036, "step": 48000}
{"episode_reward": 945.2299924230706, "episode": 49.0, "batch_reward": 0.797816567659378, "critic_loss": 1.0188546942174435, "actor_loss": -91.98086901855469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.061981201171875, "step": 49000}
{"episode_reward": 923.6494568496474, "episode": 50.0, "batch_reward": 0.7994213285446167, "critic_loss": 0.9761623370945454, "actor_loss": -91.81134544372559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.050652027130127, "step": 50000}
{"episode_reward": 956.7816718653603, "episode": 51.0, "batch_reward": 0.8036892293095589, "critic_loss": 0.9496638217866421, "actor_loss": -92.02964216613769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.42040157318115, "step": 51000}
{"episode_reward": 968.3728018757657, "episode": 52.0, "batch_reward": 0.8048135976791382, "critic_loss": 0.9353895747959614, "actor_loss": -92.15095474243164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06693124771118, "step": 52000}
{"episode_reward": 941.086584396535, "episode": 53.0, "batch_reward": 0.8096109037995338, "critic_loss": 0.8803959143161774, "actor_loss": -91.94814981079102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.389886379241943, "step": 53000}
{"episode_reward": 960.0638506798314, "episode": 54.0, "batch_reward": 0.8124963910579681, "critic_loss": 0.8940231438577175, "actor_loss": -92.37627069091796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0661940574646, "step": 54000}
{"episode_reward": 963.5590187552546, "episode": 55.0, "batch_reward": 0.8134687185287476, "critic_loss": 0.9497056933939457, "actor_loss": -92.27073669433594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.053231954574585, "step": 55000}
{"episode_reward": 846.5648878308682, "episode": 56.0, "batch_reward": 0.8148370152711868, "critic_loss": 0.8690842509269714, "actor_loss": -92.08926434326172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06118655204773, "step": 56000}
{"episode_reward": 986.0816206409748, "episode": 57.0, "batch_reward": 0.8187437291741371, "critic_loss": 0.8683323409408331, "actor_loss": -92.41811854553222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09467124938965, "step": 57000}
{"episode_reward": 912.2688456941, "episode": 58.0, "batch_reward": 0.8206455742120743, "critic_loss": 0.8560100958645344, "actor_loss": -92.4054825592041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.308581352233887, "step": 58000}
{"episode_reward": 981.354197394846, "episode": 59.0, "batch_reward": 0.8236506569385529, "critic_loss": 0.8193862370252609, "actor_loss": -92.4804515838623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.157755374908447, "step": 59000}
{"episode_reward": 983.0416458059577, "episode": 60.0, "batch_reward": 0.8254337328672409, "critic_loss": 0.7885354112386703, "actor_loss": -92.55582939147949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.031620740890503, "step": 60000}
{"episode_reward": 911.059500507633, "episode": 61.0, "batch_reward": 0.8269689601659774, "critic_loss": 0.7727158491015435, "actor_loss": -92.684648727417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.42682933807373, "step": 61000}
{"episode_reward": 923.2346549034758, "episode": 62.0, "batch_reward": 0.8287764731049537, "critic_loss": 0.7574619331657887, "actor_loss": -92.66358090209961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.060237169265747, "step": 62000}
{"episode_reward": 987.3695419729762, "episode": 63.0, "batch_reward": 0.8292318458557129, "critic_loss": 0.7439284061789513, "actor_loss": -92.70573513793946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.073559522628784, "step": 63000}
{"episode_reward": 982.0942937467692, "episode": 64.0, "batch_reward": 0.8324697552323341, "critic_loss": 0.7044122939705849, "actor_loss": -92.8932706298828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.062789916992188, "step": 64000}
{"episode_reward": 878.3176229530799, "episode": 65.0, "batch_reward": 0.8340120384693146, "critic_loss": 0.6712419656664133, "actor_loss": -92.82123489379883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.050151586532593, "step": 65000}
{"episode_reward": 961.15912853424, "episode": 66.0, "batch_reward": 0.8362041317820549, "critic_loss": 0.6670801404565573, "actor_loss": -92.92192779541016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04854655265808, "step": 66000}
{"episode_reward": 984.5196172488812, "episode": 67.0, "batch_reward": 0.8383311080336571, "critic_loss": 0.6293960254341364, "actor_loss": -92.9046755065918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.048893213272095, "step": 67000}
{"episode_reward": 959.3009854010777, "episode": 68.0, "batch_reward": 0.8386378495693206, "critic_loss": 0.6292736793458462, "actor_loss": -93.03447930908203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.073118925094604, "step": 68000}
{"episode_reward": 960.5287849413758, "episode": 69.0, "batch_reward": 0.8423592482805252, "critic_loss": 0.6308867285847664, "actor_loss": -93.17078477478027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.062484741210938, "step": 69000}
{"episode_reward": 979.4815902290067, "episode": 70.0, "batch_reward": 0.8416647759079933, "critic_loss": 0.598378236413002, "actor_loss": -93.15967362976075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.066641330718994, "step": 70000}
{"episode_reward": 915.0781463300386, "episode": 71.0, "batch_reward": 0.8432113700509072, "critic_loss": 0.6351446647197008, "actor_loss": -93.0745654296875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.462342977523804, "step": 71000}
{"episode_reward": 853.0466220956469, "episode": 72.0, "batch_reward": 0.8449429843425751, "critic_loss": 0.6128417323380708, "actor_loss": -93.25358694458008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06347918510437, "step": 72000}
{"episode_reward": 935.8530853223582, "episode": 73.0, "batch_reward": 0.8451229664087295, "critic_loss": 0.6271578529775143, "actor_loss": -93.23561030578614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.044385194778442, "step": 73000}
{"episode_reward": 982.638253338701, "episode": 74.0, "batch_reward": 0.8465569757223129, "critic_loss": 0.634575503051281, "actor_loss": -93.23328530883789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.057470321655273, "step": 74000}
{"episode_reward": 904.9713762769209, "episode": 75.0, "batch_reward": 0.849727221250534, "critic_loss": 0.616375695809722, "actor_loss": -93.3689638824463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.064995765686035, "step": 75000}
{"episode_reward": 972.8166587981699, "episode": 76.0, "batch_reward": 0.8486191795468331, "critic_loss": 0.6903580370992423, "actor_loss": -93.2516216430664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.079615116119385, "step": 76000}
{"episode_reward": 862.7248536132134, "episode": 77.0, "batch_reward": 0.8506498020291329, "critic_loss": 0.6689940641373396, "actor_loss": -93.31901661682129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.052481174468994, "step": 77000}
{"episode_reward": 976.6255718866694, "episode": 78.0, "batch_reward": 0.8515356385707855, "critic_loss": 0.6956369890421629, "actor_loss": -93.21509448242188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.059035539627075, "step": 78000}
{"episode_reward": 956.3856047691045, "episode": 79.0, "batch_reward": 0.8513391960263252, "critic_loss": 0.6782419101595879, "actor_loss": -93.39151258850097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05174946784973, "step": 79000}
{"episode_reward": 953.1209841456523, "episode": 80.0, "batch_reward": 0.8542815118432044, "critic_loss": 0.6537060967385769, "actor_loss": -93.5409916229248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.043578386306763, "step": 80000}
{"episode_reward": 948.0123576606413, "episode": 81.0, "batch_reward": 0.8548226826190949, "critic_loss": 0.6636899556219578, "actor_loss": -93.51485263061524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.42052507400513, "step": 81000}
{"episode_reward": 917.0750796738292, "episode": 82.0, "batch_reward": 0.8555322454571724, "critic_loss": 0.6502384177595377, "actor_loss": -93.50611189270019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.066266298294067, "step": 82000}
{"episode_reward": 927.2248382731912, "episode": 83.0, "batch_reward": 0.8572871133089065, "critic_loss": 0.6576996766626835, "actor_loss": -93.55337367248535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0739107131958, "step": 83000}
{"episode_reward": 957.172433319921, "episode": 84.0, "batch_reward": 0.8559571682810784, "critic_loss": 0.6206787041723728, "actor_loss": -93.59587564086914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.068176746368408, "step": 84000}
{"episode_reward": 897.0950887676885, "episode": 85.0, "batch_reward": 0.8589715738892555, "critic_loss": 0.6355370820760727, "actor_loss": -93.61532548522949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.064280033111572, "step": 85000}
{"episode_reward": 957.0924580650237, "episode": 86.0, "batch_reward": 0.8600263257026672, "critic_loss": 0.6334875163137913, "actor_loss": -93.70007333374024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.046531438827515, "step": 86000}
{"episode_reward": 960.9756350795747, "episode": 87.0, "batch_reward": 0.8614118634462357, "critic_loss": 0.6749091658443213, "actor_loss": -93.72646343994141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0429105758667, "step": 87000}
{"episode_reward": 953.9216664129387, "episode": 88.0, "batch_reward": 0.8619909494519233, "critic_loss": 0.6346122441291809, "actor_loss": -93.75537091064453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.035282373428345, "step": 88000}
{"episode_reward": 978.4193139315585, "episode": 89.0, "batch_reward": 0.8642084022164345, "critic_loss": 0.6508920579701662, "actor_loss": -93.74511714172364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.042481422424316, "step": 89000}
{"episode_reward": 974.9008703911118, "episode": 90.0, "batch_reward": 0.864848735332489, "critic_loss": 0.6142639539390803, "actor_loss": -93.80288156127929, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0482337474823, "step": 90000}
{"episode_reward": 984.961272847919, "episode": 91.0, "batch_reward": 0.8674794946312905, "critic_loss": 0.6314564799964428, "actor_loss": -93.73876567077637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.383410930633545, "step": 91000}
{"episode_reward": 912.5355940489071, "episode": 92.0, "batch_reward": 0.8668157904744148, "critic_loss": 0.6083327340483665, "actor_loss": -93.82156617736817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.043217182159424, "step": 92000}
{"episode_reward": 980.729555390854, "episode": 93.0, "batch_reward": 0.8688497103452683, "critic_loss": 0.6017773265391588, "actor_loss": -93.94210830688476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.046735048294067, "step": 93000}
{"episode_reward": 986.0039981565903, "episode": 94.0, "batch_reward": 0.8692744219899178, "critic_loss": 0.6109531203359365, "actor_loss": -93.98291502380371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03966736793518, "step": 94000}
{"episode_reward": 957.9196191437567, "episode": 95.0, "batch_reward": 0.8699217349886894, "critic_loss": 0.6115948820710182, "actor_loss": -93.95727542114258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05539083480835, "step": 95000}
{"episode_reward": 931.0165282900324, "episode": 96.0, "batch_reward": 0.8707227633595467, "critic_loss": 0.6436276512742043, "actor_loss": -93.95496069335937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.061434030532837, "step": 96000}
{"episode_reward": 945.4568670911889, "episode": 97.0, "batch_reward": 0.8713991478681564, "critic_loss": 0.6670200161039829, "actor_loss": -94.01678778076172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.068015336990356, "step": 97000}
{"episode_reward": 963.5645898858604, "episode": 98.0, "batch_reward": 0.8731614120602608, "critic_loss": 0.6792246432602406, "actor_loss": -94.05708764648438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.062272310256958, "step": 98000}
{"episode_reward": 916.8554476900524, "episode": 99.0, "batch_reward": 0.872247832596302, "critic_loss": 0.7046409609615802, "actor_loss": -93.97644897460937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.041388034820557, "step": 99000}
{"episode_reward": 929.7462460718936, "episode": 100.0, "batch_reward": 0.8718586043715477, "critic_loss": 0.6919099068045617, "actor_loss": -94.07202891540527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.044955730438232, "step": 100000}
{"episode_reward": 990.378782770207, "episode": 101.0, "batch_reward": 0.8751573080420494, "critic_loss": 0.6897096657305956, "actor_loss": -94.10165034484864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.418617248535156, "step": 101000}
{"episode_reward": 986.8138874174114, "episode": 102.0, "batch_reward": 0.8754541024565696, "critic_loss": 0.6911000169217586, "actor_loss": -94.12094346618652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.052902698516846, "step": 102000}
{"episode_reward": 978.5527056037239, "episode": 103.0, "batch_reward": 0.8765807367563248, "critic_loss": 0.6906599875688553, "actor_loss": -94.04508984375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05475091934204, "step": 103000}
{"episode_reward": 945.4759951913383, "episode": 104.0, "batch_reward": 0.8786790517568588, "critic_loss": 0.6918890221565962, "actor_loss": -94.1580071105957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.054054260253906, "step": 104000}
{"episode_reward": 937.6561174570505, "episode": 105.0, "batch_reward": 0.8777164311408997, "critic_loss": 0.6595027588903905, "actor_loss": -94.07862316894531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.048494815826416, "step": 105000}
{"episode_reward": 980.1104520317272, "episode": 106.0, "batch_reward": 0.8770168725848198, "critic_loss": 0.6887304684519768, "actor_loss": -94.24551039123536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.046464920043945, "step": 106000}
{"episode_reward": 944.443182012042, "episode": 107.0, "batch_reward": 0.878998023211956, "critic_loss": 0.6859865460097789, "actor_loss": -94.2510198059082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04277753829956, "step": 107000}
{"episode_reward": 910.7493285681553, "episode": 108.0, "batch_reward": 0.8793870083093643, "critic_loss": 0.7036621588915587, "actor_loss": -94.1134507446289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.051747798919678, "step": 108000}
{"episode_reward": 960.6094471574512, "episode": 109.0, "batch_reward": 0.879678552031517, "critic_loss": 0.7347528659403324, "actor_loss": -94.22668312072754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.063209295272827, "step": 109000}
{"episode_reward": 900.1270284505254, "episode": 110.0, "batch_reward": 0.8809446458220482, "critic_loss": 0.7354160595834255, "actor_loss": -94.19427857971192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0638427734375, "step": 110000}
{"episode_reward": 939.1901697924432, "episode": 111.0, "batch_reward": 0.8815081332325936, "critic_loss": 0.7127733185440301, "actor_loss": -94.15024171447754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.36414194107056, "step": 111000}
{"episode_reward": 984.7906229951355, "episode": 112.0, "batch_reward": 0.8827888559699059, "critic_loss": 0.7115448122620582, "actor_loss": -94.30657568359375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06015634536743, "step": 112000}
{"episode_reward": 948.7133695019152, "episode": 113.0, "batch_reward": 0.8827870535254478, "critic_loss": 0.7343931487351656, "actor_loss": -94.36013604736328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.053704738616943, "step": 113000}
{"episode_reward": 978.9987377134075, "episode": 114.0, "batch_reward": 0.8823656426668167, "critic_loss": 0.7371982192993164, "actor_loss": -94.29272163391113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.060912370681763, "step": 114000}
{"episode_reward": 984.4935161596093, "episode": 115.0, "batch_reward": 0.8830565091371536, "critic_loss": 0.7702609812915325, "actor_loss": -94.2477341003418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.050872802734375, "step": 115000}
{"episode_reward": 852.4362015533974, "episode": 116.0, "batch_reward": 0.8869324436783791, "critic_loss": 0.7668518462926149, "actor_loss": -94.38503564453126, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04118013381958, "step": 116000}
{"episode_reward": 949.4679490301259, "episode": 117.0, "batch_reward": 0.8836082664132118, "critic_loss": 0.7735463945269585, "actor_loss": -94.13939617919922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04663634300232, "step": 117000}
{"episode_reward": 957.8723310564698, "episode": 118.0, "batch_reward": 0.8855068253278733, "critic_loss": 0.7373071391582489, "actor_loss": -94.27926515197754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04485011100769, "step": 118000}
{"episode_reward": 940.862247282295, "episode": 119.0, "batch_reward": 0.8863675496578216, "critic_loss": 0.8192603008002043, "actor_loss": -94.28083204650879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.053723573684692, "step": 119000}
{"episode_reward": 920.5842479421348, "episode": 120.0, "batch_reward": 0.8862604142427445, "critic_loss": 0.7723498145192862, "actor_loss": -94.31765458679199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.041269540786743, "step": 120000}
{"episode_reward": 976.9182935391823, "episode": 121.0, "batch_reward": 0.8878051851391793, "critic_loss": 0.7370923603028059, "actor_loss": -94.35978488159179, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.43574142456055, "step": 121000}
{"episode_reward": 961.0474110181831, "episode": 122.0, "batch_reward": 0.8872937161922455, "critic_loss": 0.773582833096385, "actor_loss": -94.37821369934082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.069293975830078, "step": 122000}
{"episode_reward": 956.6767752722791, "episode": 123.0, "batch_reward": 0.8883997743725777, "critic_loss": 0.7759311283230782, "actor_loss": -94.49745715332031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05725884437561, "step": 123000}
{"episode_reward": 979.3878844201847, "episode": 124.0, "batch_reward": 0.8890824683308601, "critic_loss": 0.7761534554809332, "actor_loss": -94.48147380065917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.034496307373047, "step": 124000}
{"episode_reward": 957.7990005083095, "episode": 125.0, "batch_reward": 0.8902937251329422, "critic_loss": 0.8083304788023233, "actor_loss": -94.52352644348144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.045456409454346, "step": 125000}
{"episode_reward": 985.6912554122832, "episode": 126.0, "batch_reward": 0.8901003583073616, "critic_loss": 0.772419663131237, "actor_loss": -94.42295404052734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.054240226745605, "step": 126000}
{"episode_reward": 968.0723841968908, "episode": 127.0, "batch_reward": 0.8893321791887283, "critic_loss": 0.7598552047163248, "actor_loss": -94.35438110351562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07040548324585, "step": 127000}
{"episode_reward": 969.224798273175, "episode": 128.0, "batch_reward": 0.8907108801603317, "critic_loss": 0.7632614451795816, "actor_loss": -94.42706137084961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.047985792160034, "step": 128000}
{"episode_reward": 921.9958083692072, "episode": 129.0, "batch_reward": 0.8900820127725602, "critic_loss": 0.7362286806702614, "actor_loss": -94.43872828674317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.054536819458008, "step": 129000}
{"episode_reward": 983.1621493999969, "episode": 130.0, "batch_reward": 0.89359966224432, "critic_loss": 0.7615637622326612, "actor_loss": -94.48397660827636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.046574354171753, "step": 130000}
{"episode_reward": 958.0237501286693, "episode": 131.0, "batch_reward": 0.8931918939948083, "critic_loss": 0.7356301929801703, "actor_loss": -94.53170751953125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.38222098350525, "step": 131000}
{"episode_reward": 960.0542684011783, "episode": 132.0, "batch_reward": 0.892881905078888, "critic_loss": 0.7298873886764049, "actor_loss": -94.60523048400879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.049206495285034, "step": 132000}
{"episode_reward": 945.2931126494719, "episode": 133.0, "batch_reward": 0.892831355035305, "critic_loss": 0.7554814763516188, "actor_loss": -94.53617950439452, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05440902709961, "step": 133000}
{"episode_reward": 924.4352852224573, "episode": 134.0, "batch_reward": 0.8948337287902832, "critic_loss": 0.7191725796312094, "actor_loss": -94.55810684204101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0441312789917, "step": 134000}
{"episode_reward": 944.0854041933345, "episode": 135.0, "batch_reward": 0.8948208832740784, "critic_loss": 0.7145001377984881, "actor_loss": -94.47961781311035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04602336883545, "step": 135000}
{"episode_reward": 927.5448913774402, "episode": 136.0, "batch_reward": 0.8954314811825752, "critic_loss": 0.6937966718822718, "actor_loss": -94.51928511047363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.065263032913208, "step": 136000}
{"episode_reward": 924.1018967308319, "episode": 137.0, "batch_reward": 0.8947931605577469, "critic_loss": 0.699514610633254, "actor_loss": -94.64141311645508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.385734796524048, "step": 137000}
{"episode_reward": 983.6218692103301, "episode": 138.0, "batch_reward": 0.897163957297802, "critic_loss": 0.727607411250472, "actor_loss": -94.63070086669921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.063100337982178, "step": 138000}
{"episode_reward": 985.5496102748355, "episode": 139.0, "batch_reward": 0.8972902793288231, "critic_loss": 0.6942208424061537, "actor_loss": -94.64714038085937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03998112678528, "step": 139000}
{"episode_reward": 957.0004824335496, "episode": 140.0, "batch_reward": 0.8974392872452736, "critic_loss": 0.6610087826102972, "actor_loss": -94.6277158355713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.032594442367554, "step": 140000}
{"episode_reward": 969.8497958692918, "episode": 141.0, "batch_reward": 0.8958143537640572, "critic_loss": 0.7191595870405435, "actor_loss": -94.58745028686523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.364624977111816, "step": 141000}
{"episode_reward": 914.727940620425, "episode": 142.0, "batch_reward": 0.8959940732717514, "critic_loss": 0.7600720934271813, "actor_loss": -94.4922135925293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.052602529525757, "step": 142000}
{"episode_reward": 959.5097151524466, "episode": 143.0, "batch_reward": 0.8972138740420341, "critic_loss": 0.7209450182914734, "actor_loss": -94.57057835388184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04065227508545, "step": 143000}
{"episode_reward": 953.7363944383244, "episode": 144.0, "batch_reward": 0.8983464452028275, "critic_loss": 0.6950386905819178, "actor_loss": -94.64802738952636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.052706241607666, "step": 144000}
{"episode_reward": 925.5836757251099, "episode": 145.0, "batch_reward": 0.8986118792295456, "critic_loss": 0.7131241109669209, "actor_loss": -94.75753169250488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.039117336273193, "step": 145000}
{"episode_reward": 937.3103005961193, "episode": 146.0, "batch_reward": 0.8983976249694824, "critic_loss": 0.7348539547920228, "actor_loss": -94.73371116638184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04859232902527, "step": 146000}
{"episode_reward": 986.7231477171748, "episode": 147.0, "batch_reward": 0.8989671090841294, "critic_loss": 0.7247146242409944, "actor_loss": -94.70788262939453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.051793813705444, "step": 147000}
{"episode_reward": 886.0843930970917, "episode": 148.0, "batch_reward": 0.8993180986046792, "critic_loss": 0.7164079867899418, "actor_loss": -94.78458038330078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06487226486206, "step": 148000}
{"episode_reward": 953.4537381304976, "episode": 149.0, "batch_reward": 0.9001263763308525, "critic_loss": 0.7159377814382315, "actor_loss": -94.7812840423584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07852578163147, "step": 149000}
{"episode_reward": 985.4369580628606, "episode": 150.0, "batch_reward": 0.8994978235960007, "critic_loss": 0.676024368211627, "actor_loss": -94.75191662597656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
