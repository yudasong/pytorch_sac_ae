{"episode_reward": 0.0, "episode": 1.0, "duration": 22.646420001983643, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.911977767944336, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.29410165432056773, "critic_loss": 0.8555475450945361, "actor_loss": -69.12561123692642, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 65.43097519874573, "step": 3000}
{"episode_reward": 394.5556992790193, "episode": 4.0, "batch_reward": 0.35086971329152583, "critic_loss": 1.0407943023443222, "actor_loss": -72.57160920715332, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.85560703277588, "step": 4000}
{"episode_reward": 475.8187500419182, "episode": 5.0, "batch_reward": 0.38536113131046296, "critic_loss": 1.0574445897340774, "actor_loss": -73.19625382995605, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.48946452140808, "step": 5000}
{"episode_reward": 634.8589042594059, "episode": 6.0, "batch_reward": 0.45054001528024673, "critic_loss": 0.9207685812711716, "actor_loss": -74.52030500793457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.76586079597473, "step": 6000}
{"episode_reward": 805.3425540053582, "episode": 7.0, "batch_reward": 0.5008036866486073, "critic_loss": 0.8971149303019047, "actor_loss": -75.62877561950684, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.663830757141113, "step": 7000}
{"episode_reward": 795.0948979879693, "episode": 8.0, "batch_reward": 0.5456003148555756, "critic_loss": 0.8633589689135551, "actor_loss": -76.69889736938477, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.426553964614868, "step": 8000}
{"episode_reward": 841.3686064966014, "episode": 9.0, "batch_reward": 0.5808160543739795, "critic_loss": 0.9086582606434822, "actor_loss": -77.416849609375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.546439170837402, "step": 9000}
{"episode_reward": 885.55225817226, "episode": 10.0, "batch_reward": 0.6174741117358208, "critic_loss": 1.0184286187887193, "actor_loss": -78.17068356323242, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.53761887550354, "step": 10000}
{"episode_reward": 900.3263588003958, "episode": 11.0, "batch_reward": 0.6329053657650947, "critic_loss": 1.1563540669083596, "actor_loss": -78.37582652282715, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.29037046432495, "step": 11000}
{"episode_reward": 551.9016553980816, "episode": 12.0, "batch_reward": 0.6309528182148934, "critic_loss": 1.1133730869293212, "actor_loss": -78.2512225189209, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.762176752090454, "step": 12000}
{"episode_reward": 816.1105733181674, "episode": 13.0, "batch_reward": 0.6422962900400162, "critic_loss": 1.1728445908427239, "actor_loss": -78.30490670776368, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.105839014053345, "step": 13000}
{"episode_reward": 849.1322893020937, "episode": 14.0, "batch_reward": 0.6566276320815086, "critic_loss": 1.3204470137953759, "actor_loss": -78.66951641845704, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.702444791793823, "step": 14000}
{"episode_reward": 685.2723863022181, "episode": 15.0, "batch_reward": 0.6655182735919952, "critic_loss": 2.1015932537317275, "actor_loss": -78.81674858093261, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.617794275283813, "step": 15000}
{"episode_reward": 813.5575290669118, "episode": 16.0, "batch_reward": 0.6629590238332749, "critic_loss": 3.6948142632246017, "actor_loss": -79.6674709777832, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.214587450027466, "step": 16000}
{"episode_reward": 334.4288490586163, "episode": 17.0, "batch_reward": 0.6288103181421757, "critic_loss": 5.677659993171692, "actor_loss": -80.88009939575196, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.763837099075317, "step": 17000}
{"episode_reward": 28.700432038685094, "episode": 18.0, "batch_reward": 0.5962254400849343, "critic_loss": 6.776542706727982, "actor_loss": -81.93052056884765, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.217857122421265, "step": 18000}
{"episode_reward": 99.81485729809881, "episode": 19.0, "batch_reward": 0.5761366674005985, "critic_loss": 7.975685868740082, "actor_loss": -82.63902923583984, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.371540069580078, "step": 19000}
{"episode_reward": 250.10543600647145, "episode": 20.0, "batch_reward": 0.5514220944344997, "critic_loss": 8.021544842481614, "actor_loss": -85.03232881164551, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.22846746444702, "step": 20000}
{"episode_reward": 26.151425839109905, "episode": 21.0, "batch_reward": 0.5413477535545826, "critic_loss": 7.157148764610291, "actor_loss": -84.87894618225097, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.13975667953491, "step": 21000}
{"episode_reward": 426.42521247503703, "episode": 22.0, "batch_reward": 0.520900682002306, "critic_loss": 7.011708421707153, "actor_loss": -86.84098016357422, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.264270782470703, "step": 22000}
{"episode_reward": 27.56614780567908, "episode": 23.0, "batch_reward": 0.5089517804980278, "critic_loss": 9.774744311332702, "actor_loss": -88.23020858764649, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.940338850021362, "step": 23000}
{"episode_reward": 529.7481986044676, "episode": 24.0, "batch_reward": 0.5008955811560154, "critic_loss": 10.864633461475373, "actor_loss": -90.28351860046386, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.949090242385864, "step": 24000}
{"episode_reward": 44.101782503238695, "episode": 25.0, "batch_reward": 0.4824737233221531, "critic_loss": 11.06556399154663, "actor_loss": -92.02134127807618, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.952336311340332, "step": 25000}
{"episode_reward": 37.93976920384486, "episode": 26.0, "batch_reward": 0.47676899647712706, "critic_loss": 10.723031258583068, "actor_loss": -91.19550654602051, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.626805782318115, "step": 26000}
{"episode_reward": 647.002710779142, "episode": 27.0, "batch_reward": 0.48624439534544944, "critic_loss": 10.033934985637664, "actor_loss": -92.1400184173584, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.38416862487793, "step": 27000}
{"episode_reward": 860.4972743010994, "episode": 28.0, "batch_reward": 0.4976206612288952, "critic_loss": 9.20488711309433, "actor_loss": -91.60828489685059, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.82359027862549, "step": 28000}
{"episode_reward": 869.0484378915964, "episode": 29.0, "batch_reward": 0.5144340828061104, "critic_loss": 8.170133590698242, "actor_loss": -93.13816233825683, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.586002588272095, "step": 29000}
{"episode_reward": 938.0388880911545, "episode": 30.0, "batch_reward": 0.5139251029789448, "critic_loss": 7.712404137611389, "actor_loss": -93.64847212219239, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.714720487594604, "step": 30000}
{"episode_reward": 54.73353415297057, "episode": 31.0, "batch_reward": 0.5108935636878014, "critic_loss": 7.155686049699783, "actor_loss": -92.39006405639648, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.56972122192383, "step": 31000}
{"episode_reward": 900.3837239945444, "episode": 32.0, "batch_reward": 0.5109730095863342, "critic_loss": 6.731858515739441, "actor_loss": -92.3202845916748, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.353410482406616, "step": 32000}
{"episode_reward": 51.212528823776765, "episode": 33.0, "batch_reward": 0.4967307883501053, "critic_loss": 5.760936672449112, "actor_loss": -92.02086994934082, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.825037479400635, "step": 33000}
{"episode_reward": 22.302946333128727, "episode": 34.0, "batch_reward": 0.48433639481663704, "critic_loss": 5.28485310959816, "actor_loss": -90.25232083129883, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.54903817176819, "step": 34000}
{"episode_reward": 269.1279138348727, "episode": 35.0, "batch_reward": 0.488518878698349, "critic_loss": 4.759139086484909, "actor_loss": -90.84991400146484, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.703011989593506, "step": 35000}
{"episode_reward": 889.9648436809085, "episode": 36.0, "batch_reward": 0.4988811147212982, "critic_loss": 4.4330369489192964, "actor_loss": -88.72548823547363, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.705827713012695, "step": 36000}
{"episode_reward": 884.4646969702267, "episode": 37.0, "batch_reward": 0.5113049141466618, "critic_loss": 4.300197516679764, "actor_loss": -89.64683224487305, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.870445728302002, "step": 37000}
{"episode_reward": 892.5136841786311, "episode": 38.0, "batch_reward": 0.5198291994333267, "critic_loss": 4.266009619235993, "actor_loss": -90.87373652648925, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.53695797920227, "step": 38000}
{"episode_reward": 895.74755939186, "episode": 39.0, "batch_reward": 0.5295901618301868, "critic_loss": 4.7905166285037994, "actor_loss": -89.37935133361816, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.125482082366943, "step": 39000}
{"episode_reward": 904.3794555353031, "episode": 40.0, "batch_reward": 0.5341789411604404, "critic_loss": 5.821070727109909, "actor_loss": -88.72637731933594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.91276240348816, "step": 40000}
{"episode_reward": 635.1056717818101, "episode": 41.0, "batch_reward": 0.5365634618997573, "critic_loss": 7.748621791839599, "actor_loss": -88.51057626342774, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.51434898376465, "step": 41000}
{"episode_reward": 277.27910733837956, "episode": 42.0, "batch_reward": 0.5265980172455311, "critic_loss": 8.05781471157074, "actor_loss": -90.37115234375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.387811183929443, "step": 42000}
{"episode_reward": 73.57035917723618, "episode": 43.0, "batch_reward": 0.525333199441433, "critic_loss": 8.167820724487305, "actor_loss": -89.33593446350098, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.89570164680481, "step": 43000}
{"episode_reward": 859.7841666278457, "episode": 44.0, "batch_reward": 0.533003098487854, "critic_loss": 8.580368345737456, "actor_loss": -91.0727759552002, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.44006657600403, "step": 44000}
{"episode_reward": 914.9899215730478, "episode": 45.0, "batch_reward": 0.5320868358910084, "critic_loss": 9.918649694442749, "actor_loss": -91.9677313079834, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.003289937973022, "step": 45000}
{"episode_reward": 129.8216880531686, "episode": 46.0, "batch_reward": 0.5258498492240906, "critic_loss": 11.498612800598144, "actor_loss": -90.70603108215332, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.406094551086426, "step": 46000}
{"episode_reward": 194.5586340961818, "episode": 47.0, "batch_reward": 0.5217074005305767, "critic_loss": 13.04695962190628, "actor_loss": -90.54418382263184, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.11287260055542, "step": 47000}
{"episode_reward": 676.610462540898, "episode": 48.0, "batch_reward": 0.5230282630622387, "critic_loss": 14.244602454662322, "actor_loss": -90.45117973327636, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.549790382385254, "step": 48000}
{"episode_reward": 334.448560712136, "episode": 49.0, "batch_reward": 0.5166325409412384, "critic_loss": 16.196346479892732, "actor_loss": -91.45178315734863, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.905154705047607, "step": 49000}
{"episode_reward": 198.09865386566133, "episode": 50.0, "batch_reward": 0.5099049225449562, "critic_loss": 16.644383382320402, "actor_loss": -93.33983392333984, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.225136280059814, "step": 50000}
{"episode_reward": 163.65730081009534, "episode": 51.0, "batch_reward": 0.5016871838271618, "critic_loss": 15.758006872177123, "actor_loss": -95.71034735107422, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.721696853637695, "step": 51000}
{"episode_reward": 101.73569827542792, "episode": 52.0, "batch_reward": 0.49761035946011545, "critic_loss": 14.507240714550019, "actor_loss": -94.32317338562012, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.906221866607666, "step": 52000}
{"episode_reward": 209.69559531492285, "episode": 53.0, "batch_reward": 0.49083024859428404, "critic_loss": 13.109291903018951, "actor_loss": -98.93178735351563, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.850679636001587, "step": 53000}
{"episode_reward": 147.48453363292478, "episode": 54.0, "batch_reward": 0.48374402403831485, "critic_loss": 12.203219798088075, "actor_loss": -94.34891108703613, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.776665449142456, "step": 54000}
{"episode_reward": 82.67880607551122, "episode": 55.0, "batch_reward": 0.47873181518912317, "critic_loss": 11.319437106132508, "actor_loss": -95.28130700683593, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.51797580718994, "step": 55000}
{"episode_reward": 189.87292280437939, "episode": 56.0, "batch_reward": 0.47126571616530416, "critic_loss": 9.686440703392028, "actor_loss": -97.56500805664062, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.243210554122925, "step": 56000}
{"episode_reward": 278.9808805209189, "episode": 57.0, "batch_reward": 0.4713719844222069, "critic_loss": 8.189231444835663, "actor_loss": -96.35702731323242, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.310796976089478, "step": 57000}
{"episode_reward": 588.5285914001325, "episode": 58.0, "batch_reward": 0.47221084296703336, "critic_loss": 7.000840191602707, "actor_loss": -95.70572898864746, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.3141348361969, "step": 58000}
{"episode_reward": 687.6532832868864, "episode": 59.0, "batch_reward": 0.48020610976219175, "critic_loss": 6.035146495103836, "actor_loss": -95.72566316223144, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.97900414466858, "step": 59000}
{"episode_reward": 855.0854860038834, "episode": 60.0, "batch_reward": 0.4854816909432411, "critic_loss": 5.409989808320999, "actor_loss": -94.93278991699219, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.222886562347412, "step": 60000}
{"episode_reward": 834.6402536937934, "episode": 61.0, "batch_reward": 0.49056061133742335, "critic_loss": 4.784985202550888, "actor_loss": -93.55714012145997, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.97227692604065, "step": 61000}
{"episode_reward": 897.2088617993008, "episode": 62.0, "batch_reward": 0.49915716710686686, "critic_loss": 4.423552356243134, "actor_loss": -95.66834324645995, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.961502075195312, "step": 62000}
{"episode_reward": 959.6921698014078, "episode": 63.0, "batch_reward": 0.5073196228444576, "critic_loss": 4.184532232284546, "actor_loss": -95.31003912353516, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.023709058761597, "step": 63000}
{"episode_reward": 896.0203759372421, "episode": 64.0, "batch_reward": 0.5119441239535809, "critic_loss": 3.8482883225679396, "actor_loss": -93.46779010009766, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.406180143356323, "step": 64000}
{"episode_reward": 867.1636459336104, "episode": 65.0, "batch_reward": 0.5160826787352562, "critic_loss": 3.7721579693555833, "actor_loss": -94.27908435058593, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.86039638519287, "step": 65000}
{"episode_reward": 855.957426172642, "episode": 66.0, "batch_reward": 0.5205840723514557, "critic_loss": 3.8483134875297544, "actor_loss": -93.47132580566407, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.339313745498657, "step": 66000}
{"episode_reward": 815.4025028016044, "episode": 67.0, "batch_reward": 0.5270800133049488, "critic_loss": 3.4493102567195892, "actor_loss": -94.54118641662598, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.053391695022583, "step": 67000}
{"episode_reward": 888.1032325654054, "episode": 68.0, "batch_reward": 0.526235543936491, "critic_loss": 3.235396624326706, "actor_loss": -92.75150672912598, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.488815784454346, "step": 68000}
{"episode_reward": 52.841942899608114, "episode": 69.0, "batch_reward": 0.522384339928627, "critic_loss": 2.9004621068239214, "actor_loss": -92.4090809173584, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.005436420440674, "step": 69000}
{"episode_reward": 183.55708241797154, "episode": 70.0, "batch_reward": 0.5177990898489953, "critic_loss": 2.6149243289232253, "actor_loss": -90.01004486083984, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.563964128494263, "step": 70000}
{"episode_reward": 573.4994445423549, "episode": 71.0, "batch_reward": 0.5210935293436051, "critic_loss": 2.431254824280739, "actor_loss": -91.71512623596192, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 45.21169829368591, "step": 71000}
{"episode_reward": 861.4456040829012, "episode": 72.0, "batch_reward": 0.5277461338043213, "critic_loss": 2.1428451855182646, "actor_loss": -89.43414649963378, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.30187726020813, "step": 72000}
{"episode_reward": 877.9004374655993, "episode": 73.0, "batch_reward": 0.5299434278011322, "critic_loss": 1.8221025420427321, "actor_loss": -88.9170193939209, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.17857336997986, "step": 73000}
{"episode_reward": 971.31500755663, "episode": 74.0, "batch_reward": 0.5380874617099762, "critic_loss": 1.6531622484326363, "actor_loss": -88.18175134277344, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.934184789657593, "step": 74000}
{"episode_reward": 951.1613003560318, "episode": 75.0, "batch_reward": 0.5453904378414154, "critic_loss": 1.5121107981204986, "actor_loss": -87.21986541748046, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.551778078079224, "step": 75000}
{"episode_reward": 947.5836179623399, "episode": 76.0, "batch_reward": 0.5483965103328228, "critic_loss": 1.4161276020407676, "actor_loss": -86.17327111816407, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.423805952072144, "step": 76000}
{"episode_reward": 940.6555409853274, "episode": 77.0, "batch_reward": 0.5522086582481861, "critic_loss": 1.371479286134243, "actor_loss": -85.56562454223632, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.447962999343872, "step": 77000}
{"episode_reward": 944.4557234874214, "episode": 78.0, "batch_reward": 0.5566144137978554, "critic_loss": 1.360667106628418, "actor_loss": -85.20281481933594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.994679927825928, "step": 78000}
{"episode_reward": 875.3630354395737, "episode": 79.0, "batch_reward": 0.5625473067164422, "critic_loss": 1.4340684367418288, "actor_loss": -84.39620254516602, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.743232488632202, "step": 79000}
{"episode_reward": 915.6134070310504, "episode": 80.0, "batch_reward": 0.5663528220951557, "critic_loss": 1.4499003823399543, "actor_loss": -83.90525285339355, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.924867630004883, "step": 80000}
{"episode_reward": 945.2655207325475, "episode": 81.0, "batch_reward": 0.5704252916872501, "critic_loss": 1.5341152111291885, "actor_loss": -83.63618383789063, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.51048421859741, "step": 81000}
{"episode_reward": 879.0601775647149, "episode": 82.0, "batch_reward": 0.5755955397486686, "critic_loss": 1.6931884252429008, "actor_loss": -83.45230746459961, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.93200397491455, "step": 82000}
{"episode_reward": 945.0980506573055, "episode": 83.0, "batch_reward": 0.5790956175029278, "critic_loss": 1.7838125056624412, "actor_loss": -82.65915426635742, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.31937074661255, "step": 83000}
{"episode_reward": 938.6248090567526, "episode": 84.0, "batch_reward": 0.5814396993219852, "critic_loss": 1.7964593351483344, "actor_loss": -82.20462322998047, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.23856520652771, "step": 84000}
{"episode_reward": 811.9936904548543, "episode": 85.0, "batch_reward": 0.5865172488093376, "critic_loss": 1.9116868985891342, "actor_loss": -82.55250685119628, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.906049251556396, "step": 85000}
{"episode_reward": 895.6750170357366, "episode": 86.0, "batch_reward": 0.5903944812119007, "critic_loss": 2.008681217432022, "actor_loss": -82.4542421875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.604796648025513, "step": 86000}
{"episode_reward": 927.0865869015415, "episode": 87.0, "batch_reward": 0.5960551139414311, "critic_loss": 2.217143534064293, "actor_loss": -82.2677605895996, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.112138509750366, "step": 87000}
{"episode_reward": 924.8635256499709, "episode": 88.0, "batch_reward": 0.5971368635296822, "critic_loss": 2.634537912607193, "actor_loss": -82.03383520507812, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.189606189727783, "step": 88000}
{"episode_reward": 868.9722229513442, "episode": 89.0, "batch_reward": 0.6028228652775287, "critic_loss": 3.1452661559581756, "actor_loss": -82.68349098205566, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.007911205291748, "step": 89000}
{"episode_reward": 918.5446123099321, "episode": 90.0, "batch_reward": 0.6043484472334385, "critic_loss": 3.10850059568882, "actor_loss": -82.55754637145996, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.28689742088318, "step": 90000}
{"episode_reward": 953.158162282528, "episode": 91.0, "batch_reward": 0.6092937164306641, "critic_loss": 2.7316397359371187, "actor_loss": -82.89946351623536, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.70929408073425, "step": 91000}
{"episode_reward": 917.6485503584296, "episode": 92.0, "batch_reward": 0.6135453437566757, "critic_loss": 2.608708697497845, "actor_loss": -83.27590296936035, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.996832132339478, "step": 92000}
{"episode_reward": 954.1205859316917, "episode": 93.0, "batch_reward": 0.6145156098008155, "critic_loss": 2.45144198346138, "actor_loss": -83.43130496215821, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.549680709838867, "step": 93000}
{"episode_reward": 953.900707787729, "episode": 94.0, "batch_reward": 0.6211537097096443, "critic_loss": 2.4275387092232705, "actor_loss": -83.25340423583984, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.52850914001465, "step": 94000}
{"episode_reward": 921.1523222206713, "episode": 95.0, "batch_reward": 0.6223422974348068, "critic_loss": 2.330730580806732, "actor_loss": -83.0886859588623, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.91584062576294, "step": 95000}
{"episode_reward": 862.5288824030168, "episode": 96.0, "batch_reward": 0.6251011493206025, "critic_loss": 2.269747544169426, "actor_loss": -83.03740927124024, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.53081250190735, "step": 96000}
{"episode_reward": 921.7242167877545, "episode": 97.0, "batch_reward": 0.6259995728135109, "critic_loss": 2.17036480396986, "actor_loss": -82.6753865814209, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.93911576271057, "step": 97000}
{"episode_reward": 842.6582820537833, "episode": 98.0, "batch_reward": 0.6306506035923958, "critic_loss": 1.9863957994580268, "actor_loss": -82.90113648986816, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.38518714904785, "step": 98000}
{"episode_reward": 841.3625722260483, "episode": 99.0, "batch_reward": 0.6314355570971966, "critic_loss": 1.8276955761909486, "actor_loss": -82.48458686828613, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.22970724105835, "step": 99000}
{"episode_reward": 895.4057552459597, "episode": 100.0, "batch_reward": 0.6332620748877525, "critic_loss": 1.7084741146564484, "actor_loss": -82.34268885803223, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.531780242919922, "step": 100000}
{"episode_reward": 935.9967172468063, "episode": 101.0, "batch_reward": 0.6346310923099517, "critic_loss": 1.6038831060528755, "actor_loss": -81.95593240356445, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.58143138885498, "step": 101000}
{"episode_reward": 124.36608066226813, "episode": 102.0, "batch_reward": 0.6336379492282868, "critic_loss": 1.4534081849455833, "actor_loss": -81.67378021240235, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.77450680732727, "step": 102000}
{"episode_reward": 927.2529333508747, "episode": 103.0, "batch_reward": 0.6357956674695014, "critic_loss": 1.358983802676201, "actor_loss": -81.60998765563964, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.724422693252563, "step": 103000}
{"episode_reward": 885.1942710707899, "episode": 104.0, "batch_reward": 0.6367436338067055, "critic_loss": 1.287972497999668, "actor_loss": -81.18281970214844, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.525736570358276, "step": 104000}
{"episode_reward": 858.6707892469062, "episode": 105.0, "batch_reward": 0.6393559321165084, "critic_loss": 1.1822656008005141, "actor_loss": -81.12768901062012, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.454858541488647, "step": 105000}
{"episode_reward": 924.4733198748362, "episode": 106.0, "batch_reward": 0.6399505332708358, "critic_loss": 1.1675046873092652, "actor_loss": -80.79470739746094, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.211620092391968, "step": 106000}
{"episode_reward": 849.8122802724841, "episode": 107.0, "batch_reward": 0.6423512089848519, "critic_loss": 1.3270454541444778, "actor_loss": -80.63813932800294, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.34902596473694, "step": 107000}
{"episode_reward": 850.0384870164493, "episode": 108.0, "batch_reward": 0.6455027718544006, "critic_loss": 1.3527057367563247, "actor_loss": -80.51606259155274, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.59487295150757, "step": 108000}
{"episode_reward": 896.7879464536701, "episode": 109.0, "batch_reward": 0.649592492878437, "critic_loss": 1.5922850643992423, "actor_loss": -80.54141337585449, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.676771879196167, "step": 109000}
{"episode_reward": 902.7865359505299, "episode": 110.0, "batch_reward": 0.6501840274930001, "critic_loss": 2.258596787750721, "actor_loss": -80.5051516418457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.503809928894043, "step": 110000}
{"episode_reward": 895.3282965349177, "episode": 111.0, "batch_reward": 0.6519419618844986, "critic_loss": 3.1298355035185814, "actor_loss": -80.94546942138672, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 46.65805411338806, "step": 111000}
{"episode_reward": 913.7946729863295, "episode": 112.0, "batch_reward": 0.6563523715138435, "critic_loss": 3.650789916038513, "actor_loss": -81.35042820739746, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.271157026290894, "step": 112000}
{"episode_reward": 906.3631200466298, "episode": 113.0, "batch_reward": 0.6581629607081413, "critic_loss": 3.2590006175041197, "actor_loss": -81.9186943511963, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.078612327575684, "step": 113000}
{"episode_reward": 961.9794729351648, "episode": 114.0, "batch_reward": 0.6600121367573738, "critic_loss": 2.9802687010765077, "actor_loss": -82.08877069091797, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.096847534179688, "step": 114000}
{"episode_reward": 929.8653024199469, "episode": 115.0, "batch_reward": 0.6620167801380158, "critic_loss": 2.8664598525762557, "actor_loss": -82.44087504577637, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.387803077697754, "step": 115000}
{"episode_reward": 928.6749797207104, "episode": 116.0, "batch_reward": 0.6674606362581254, "critic_loss": 2.750500875353813, "actor_loss": -82.82076719665527, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.020625352859497, "step": 116000}
{"episode_reward": 908.4702808680837, "episode": 117.0, "batch_reward": 0.6656143470406533, "critic_loss": 2.941800669372082, "actor_loss": -83.24041558837891, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.01575541496277, "step": 117000}
{"episode_reward": 876.7766231822012, "episode": 118.0, "batch_reward": 0.6692772964239121, "critic_loss": 2.9570979206562042, "actor_loss": -83.41470190429688, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.36431622505188, "step": 118000}
{"episode_reward": 921.5507228422058, "episode": 119.0, "batch_reward": 0.6730567339062691, "critic_loss": 3.131614533007145, "actor_loss": -83.74383192443848, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.972275257110596, "step": 119000}
{"episode_reward": 918.5830760719977, "episode": 120.0, "batch_reward": 0.6716284730434418, "critic_loss": 3.5904025076627732, "actor_loss": -84.32817752075195, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.149316549301147, "step": 120000}
{"episode_reward": 938.6693722888916, "episode": 121.0, "batch_reward": 0.6766070397496223, "critic_loss": 3.82292601108551, "actor_loss": -84.59627899169922, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.095523834228516, "step": 121000}
{"episode_reward": 937.7805766607767, "episode": 122.0, "batch_reward": 0.6795316378474235, "critic_loss": 4.1004203442335125, "actor_loss": -84.74952799987793, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.744887828826904, "step": 122000}
{"episode_reward": 883.4673285197358, "episode": 123.0, "batch_reward": 0.6783202836513519, "critic_loss": 4.414782400965691, "actor_loss": -83.99128875732421, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.42595338821411, "step": 123000}
{"episode_reward": 900.2274446385993, "episode": 124.0, "batch_reward": 0.6810371038317681, "critic_loss": 4.591462270259857, "actor_loss": -84.51440754699708, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.566742420196533, "step": 124000}
{"episode_reward": 927.1951010016869, "episode": 125.0, "batch_reward": 0.6815572888851166, "critic_loss": 4.835314150214195, "actor_loss": -84.32779643249512, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.900557279586792, "step": 125000}
{"episode_reward": 131.18303078024726, "episode": 126.0, "batch_reward": 0.6770718868970871, "critic_loss": 4.8674894994497295, "actor_loss": -84.65046934509277, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.847365140914917, "step": 126000}
{"episode_reward": 607.6646588612094, "episode": 127.0, "batch_reward": 0.673469640493393, "critic_loss": 4.813940479636193, "actor_loss": -84.20188418579102, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.73039722442627, "step": 127000}
{"episode_reward": 163.02615688646964, "episode": 128.0, "batch_reward": 0.672930260360241, "critic_loss": 5.189543326020241, "actor_loss": -84.20367347717286, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.97207999229431, "step": 128000}
{"episode_reward": 475.43036602589774, "episode": 129.0, "batch_reward": 0.6703461594581605, "critic_loss": 4.935333216071129, "actor_loss": -84.1667311706543, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.840963125228882, "step": 129000}
{"episode_reward": 237.8958504394031, "episode": 130.0, "batch_reward": 0.6683921357989311, "critic_loss": 5.164687488555908, "actor_loss": -84.15847735595703, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.839577674865723, "step": 130000}
{"episode_reward": 358.6698788599078, "episode": 131.0, "batch_reward": 0.6653403786420822, "critic_loss": 6.031776135683059, "actor_loss": -84.03575527954102, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 45.00636148452759, "step": 131000}
{"episode_reward": 222.0862165546016, "episode": 132.0, "batch_reward": 0.6593884274363517, "critic_loss": 7.378185981273651, "actor_loss": -84.11882026672363, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.68705916404724, "step": 132000}
{"episode_reward": 311.74271856482346, "episode": 133.0, "batch_reward": 0.65883754748106, "critic_loss": 7.606562014579773, "actor_loss": -85.2745818939209, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.028470993041992, "step": 133000}
{"episode_reward": 147.02225864701202, "episode": 134.0, "batch_reward": 0.658358534514904, "critic_loss": 7.135535871744156, "actor_loss": -86.57417660522461, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.957401037216187, "step": 134000}
{"episode_reward": 812.2931022881837, "episode": 135.0, "batch_reward": 0.6584865454435348, "critic_loss": 6.814359194517135, "actor_loss": -86.21270460510254, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.344447374343872, "step": 135000}
{"episode_reward": 420.06559347622425, "episode": 136.0, "batch_reward": 0.6546963489055634, "critic_loss": 8.81695143699646, "actor_loss": -89.03332571411133, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.3695809841156, "step": 136000}
{"episode_reward": 461.7845407310623, "episode": 137.0, "batch_reward": 0.6513922051787376, "critic_loss": 13.881753362178802, "actor_loss": -90.09094660949707, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.14603090286255, "step": 137000}
{"episode_reward": 232.68894537984312, "episode": 138.0, "batch_reward": 0.649408963918686, "critic_loss": 12.739081757068634, "actor_loss": -93.1635210723877, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.34104084968567, "step": 138000}
{"episode_reward": 89.99240951017232, "episode": 139.0, "batch_reward": 0.6456028549671173, "critic_loss": 9.62564230298996, "actor_loss": -95.68593795776367, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.574625253677368, "step": 139000}
{"episode_reward": 347.3683527748091, "episode": 140.0, "batch_reward": 0.6427291934490204, "critic_loss": 8.793168637275695, "actor_loss": -96.98607733154297, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.972617387771606, "step": 140000}
{"episode_reward": 252.0543645119503, "episode": 141.0, "batch_reward": 0.6404988118410111, "critic_loss": 8.526107591152192, "actor_loss": -97.02038204956055, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 44.82918906211853, "step": 141000}
{"episode_reward": 514.9023866563435, "episode": 142.0, "batch_reward": 0.6411998461484909, "critic_loss": 7.741800543308258, "actor_loss": -99.43715989685059, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.200379848480225, "step": 142000}
{"episode_reward": 708.4461115819869, "episode": 143.0, "batch_reward": 0.6400854157209397, "critic_loss": 6.756310318946839, "actor_loss": -99.51556555175782, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.1921226978302, "step": 143000}
{"episode_reward": 31.295628190449897, "episode": 144.0, "batch_reward": 0.6393417204618455, "critic_loss": 5.944231618642807, "actor_loss": -97.42620059204101, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.974372148513794, "step": 144000}
{"episode_reward": 825.0619409323383, "episode": 145.0, "batch_reward": 0.6404708006978035, "critic_loss": 5.185630289793014, "actor_loss": -96.76612139892578, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.743480920791626, "step": 145000}
{"episode_reward": 814.6620963970287, "episode": 146.0, "batch_reward": 0.6421990180015564, "critic_loss": 4.50332483124733, "actor_loss": -96.11660079956054, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.933446884155273, "step": 146000}
{"episode_reward": 923.5099510786122, "episode": 147.0, "batch_reward": 0.6420714074373245, "critic_loss": 3.881315252184868, "actor_loss": -96.29502508544923, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.547616720199585, "step": 147000}
{"episode_reward": 774.2799411472668, "episode": 148.0, "batch_reward": 0.6438123112916947, "critic_loss": 3.2797780908346175, "actor_loss": -95.51234573364258, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.124496698379517, "step": 148000}
{"episode_reward": 879.7414455193766, "episode": 149.0, "batch_reward": 0.6445962162613869, "critic_loss": 2.8904512470960615, "actor_loss": -95.41608227539062, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.269479036331177, "step": 149000}
{"episode_reward": 912.1476996232591, "episode": 150.0, "batch_reward": 0.6461865285634995, "critic_loss": 2.654237861037254, "actor_loss": -93.63403514099122, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
