{"episode_reward": 0.0, "episode": 1.0, "duration": 22.09840226173401, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.9211761951446533, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.2898513543462706, "critic_loss": 0.8032726487663437, "actor_loss": -69.23224518689311, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 65.40920162200928, "step": 3000}
{"episode_reward": 512.4471379936297, "episode": 4.0, "batch_reward": 0.39519455677270887, "critic_loss": 0.8943269717097282, "actor_loss": -74.43702876281738, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.8607497215271, "step": 4000}
{"episode_reward": 617.4326679284865, "episode": 5.0, "batch_reward": 0.38729273676872256, "critic_loss": 0.8620893662273884, "actor_loss": -74.31043572998047, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.504754781723022, "step": 5000}
{"episode_reward": 91.18974668816107, "episode": 6.0, "batch_reward": 0.38564134150743484, "critic_loss": 0.9758268628716469, "actor_loss": -74.14262208557129, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.85520076751709, "step": 6000}
{"episode_reward": 592.9250744214663, "episode": 7.0, "batch_reward": 0.41398304548859594, "critic_loss": 0.9686787130832673, "actor_loss": -74.34445179748535, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.443823099136353, "step": 7000}
{"episode_reward": 678.2086696464506, "episode": 8.0, "batch_reward": 0.4483739050626755, "critic_loss": 0.8773609864115715, "actor_loss": -74.7154174041748, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.162997007369995, "step": 8000}
{"episode_reward": 669.8094489234204, "episode": 9.0, "batch_reward": 0.48366841581463815, "critic_loss": 0.7594651057124138, "actor_loss": -75.26144662475586, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.641758918762207, "step": 9000}
{"episode_reward": 817.7179876644374, "episode": 10.0, "batch_reward": 0.5276359090209007, "critic_loss": 0.6409240450263023, "actor_loss": -75.92296154785156, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.38828420639038, "step": 10000}
{"episode_reward": 929.357423954512, "episode": 11.0, "batch_reward": 0.5612086333930493, "critic_loss": 0.6673021534085274, "actor_loss": -76.54386613464355, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.698028326034546, "step": 11000}
{"episode_reward": 858.5374548401904, "episode": 12.0, "batch_reward": 0.5825056031346321, "critic_loss": 0.7570228326022626, "actor_loss": -76.86364236450196, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.409584045410156, "step": 12000}
{"episode_reward": 806.6898857063838, "episode": 13.0, "batch_reward": 0.6039937063157559, "critic_loss": 0.7680133511722088, "actor_loss": -77.2089012298584, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.06905746459961, "step": 13000}
{"episode_reward": 871.4886777684326, "episode": 14.0, "batch_reward": 0.628469624698162, "critic_loss": 0.7339818778932095, "actor_loss": -77.83459515380859, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.454643964767456, "step": 14000}
{"episode_reward": 948.7821922348331, "episode": 15.0, "batch_reward": 0.6497485027909279, "critic_loss": 0.6847527956366539, "actor_loss": -78.33062077331543, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.730926036834717, "step": 15000}
{"episode_reward": 931.6437460262157, "episode": 16.0, "batch_reward": 0.6690437713265419, "critic_loss": 0.6571020278334617, "actor_loss": -79.0734757080078, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.411214590072632, "step": 16000}
{"episode_reward": 934.3416190584481, "episode": 17.0, "batch_reward": 0.6806067572832107, "critic_loss": 0.6791708998680115, "actor_loss": -79.37179891967773, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.567782640457153, "step": 17000}
{"episode_reward": 893.3987835792186, "episode": 18.0, "batch_reward": 0.6895781106948853, "critic_loss": 0.6741066099107266, "actor_loss": -79.6408734588623, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.703078031539917, "step": 18000}
{"episode_reward": 787.9403638040196, "episode": 19.0, "batch_reward": 0.6978785296082497, "critic_loss": 0.5969921054542064, "actor_loss": -79.93008889770508, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.032610654830933, "step": 19000}
{"episode_reward": 911.7318857788708, "episode": 20.0, "batch_reward": 0.7103187066316604, "critic_loss": 0.6024694835543632, "actor_loss": -80.1927129058838, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.650241136550903, "step": 20000}
{"episode_reward": 875.0598133888086, "episode": 21.0, "batch_reward": 0.7203810908794404, "critic_loss": 0.5379408096373082, "actor_loss": -80.58305458068848, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.260417461395264, "step": 21000}
{"episode_reward": 969.7947463853518, "episode": 22.0, "batch_reward": 0.7299777066707611, "critic_loss": 0.5418836985528469, "actor_loss": -80.89107723999024, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.779388189315796, "step": 22000}
{"episode_reward": 904.3121601829217, "episode": 23.0, "batch_reward": 0.7354970620274544, "critic_loss": 0.5179155703783035, "actor_loss": -81.07994207763672, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.75541853904724, "step": 23000}
{"episode_reward": 881.3105884536391, "episode": 24.0, "batch_reward": 0.7428444821238518, "critic_loss": 0.494961805164814, "actor_loss": -81.29403440856933, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.83877992630005, "step": 24000}
{"episode_reward": 886.6842449791835, "episode": 25.0, "batch_reward": 0.7493145897984504, "critic_loss": 0.4682162235230207, "actor_loss": -81.53020333862305, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.67141056060791, "step": 25000}
{"episode_reward": 939.1501994050487, "episode": 26.0, "batch_reward": 0.7562827860713005, "critic_loss": 0.4662205778062344, "actor_loss": -81.79328309631347, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.552778720855713, "step": 26000}
{"episode_reward": 940.8865678949727, "episode": 27.0, "batch_reward": 0.7620895334482193, "critic_loss": 0.5161964761614799, "actor_loss": -81.90397175598144, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.21765375137329, "step": 27000}
{"episode_reward": 847.2700637527236, "episode": 28.0, "batch_reward": 0.7650606949925423, "critic_loss": 0.49647044855356215, "actor_loss": -82.08729762268067, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.873852491378784, "step": 28000}
{"episode_reward": 884.9956613989847, "episode": 29.0, "batch_reward": 0.7694224643707276, "critic_loss": 0.5454942670464515, "actor_loss": -82.19679348754883, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.651320457458496, "step": 29000}
{"episode_reward": 850.8530883526296, "episode": 30.0, "batch_reward": 0.7726439003348351, "critic_loss": 0.5215251070708037, "actor_loss": -82.36070895385743, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.94438600540161, "step": 30000}
{"episode_reward": 911.562111657422, "episode": 31.0, "batch_reward": 0.775745035469532, "critic_loss": 0.5640554832816124, "actor_loss": -82.47330126953125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 45.747161626815796, "step": 31000}
{"episode_reward": 893.271369388406, "episode": 32.0, "batch_reward": 0.7819824677109718, "critic_loss": 0.6009915191829205, "actor_loss": -82.69577966308594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.05514430999756, "step": 32000}
{"episode_reward": 938.7234968668956, "episode": 33.0, "batch_reward": 0.7870680928826332, "critic_loss": 0.6195221728086472, "actor_loss": -82.85363331604005, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.52795171737671, "step": 33000}
{"episode_reward": 902.5858563485634, "episode": 34.0, "batch_reward": 0.7892813447713852, "critic_loss": 0.6498025584518909, "actor_loss": -82.99346726989747, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.003211736679077, "step": 34000}
{"episode_reward": 868.643819450967, "episode": 35.0, "batch_reward": 0.792844504415989, "critic_loss": 0.638839194059372, "actor_loss": -83.10536650085449, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.636561155319214, "step": 35000}
{"episode_reward": 928.4009107646763, "episode": 36.0, "batch_reward": 0.7984289858937264, "critic_loss": 0.601551079660654, "actor_loss": -83.27968440246582, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.479058027267456, "step": 36000}
{"episode_reward": 943.2913567057395, "episode": 37.0, "batch_reward": 0.8018603684306145, "critic_loss": 0.5965255539119244, "actor_loss": -83.3957355041504, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.725370168685913, "step": 37000}
{"episode_reward": 940.244297533064, "episode": 38.0, "batch_reward": 0.805971664249897, "critic_loss": 0.5618226533830166, "actor_loss": -83.56423323059082, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.593159198760986, "step": 38000}
{"episode_reward": 949.2650110061688, "episode": 39.0, "batch_reward": 0.808281673192978, "critic_loss": 0.5526912578046322, "actor_loss": -83.73596875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.20185351371765, "step": 39000}
{"episode_reward": 937.3962211089861, "episode": 40.0, "batch_reward": 0.8106434653401375, "critic_loss": 0.6038277542889118, "actor_loss": -83.77036737060547, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.897807121276855, "step": 40000}
{"episode_reward": 897.7178994679396, "episode": 41.0, "batch_reward": 0.8128176842927932, "critic_loss": 0.5610588337630034, "actor_loss": -83.90225894165039, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.34669518470764, "step": 41000}
{"episode_reward": 907.8268123890141, "episode": 42.0, "batch_reward": 0.8127179417014122, "critic_loss": 0.5757971695065498, "actor_loss": -84.04473927307129, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.51404094696045, "step": 42000}
{"episode_reward": 834.3764598103, "episode": 43.0, "batch_reward": 0.8165290029048919, "critic_loss": 0.5896949735581875, "actor_loss": -84.12831971740722, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.208029747009277, "step": 43000}
{"episode_reward": 898.4798454797562, "episode": 44.0, "batch_reward": 0.8170219307541847, "critic_loss": 0.6039276556968689, "actor_loss": -84.2085054321289, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.48653769493103, "step": 44000}
{"episode_reward": 803.9330372541168, "episode": 45.0, "batch_reward": 0.8190416390299797, "critic_loss": 0.5893137151896953, "actor_loss": -84.37902247619628, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.521624088287354, "step": 45000}
{"episode_reward": 945.1466747592593, "episode": 46.0, "batch_reward": 0.8208872502446175, "critic_loss": 0.5740516481101513, "actor_loss": -84.39237059020996, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.90726661682129, "step": 46000}
{"episode_reward": 942.8368798555525, "episode": 47.0, "batch_reward": 0.823372197329998, "critic_loss": 0.5644857023060322, "actor_loss": -84.44035536193847, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.905462503433228, "step": 47000}
{"episode_reward": 918.9390095502342, "episode": 48.0, "batch_reward": 0.8262627826929092, "critic_loss": 0.5567391967177391, "actor_loss": -84.61002951049805, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.909101486206055, "step": 48000}
{"episode_reward": 932.0423970578191, "episode": 49.0, "batch_reward": 0.8270423501729965, "critic_loss": 0.5535098792612553, "actor_loss": -84.63024821472168, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.47374725341797, "step": 49000}
{"episode_reward": 868.1402757664696, "episode": 50.0, "batch_reward": 0.8281913423538207, "critic_loss": 0.5242219259589911, "actor_loss": -84.76261186218262, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.087401151657104, "step": 50000}
{"episode_reward": 903.0836101817836, "episode": 51.0, "batch_reward": 0.8309538049697875, "critic_loss": 0.5110706021636724, "actor_loss": -85.06733944702148, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.17144966125488, "step": 51000}
{"episode_reward": 957.361111457989, "episode": 52.0, "batch_reward": 0.8261374353766441, "critic_loss": 0.5712802082300186, "actor_loss": -84.71202365112305, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.231906175613403, "step": 52000}
{"episode_reward": 603.2433403177077, "episode": 53.0, "batch_reward": 0.8281932299137116, "critic_loss": 0.5432094645500183, "actor_loss": -84.9658313293457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.520153522491455, "step": 53000}
{"episode_reward": 922.1369273960422, "episode": 54.0, "batch_reward": 0.8293783204555512, "critic_loss": 0.5262833535075188, "actor_loss": -84.82402522277832, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.01248526573181, "step": 54000}
{"episode_reward": 931.4565867577022, "episode": 55.0, "batch_reward": 0.830158720433712, "critic_loss": 0.5163828891813755, "actor_loss": -84.90918754577636, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.71970009803772, "step": 55000}
{"episode_reward": 912.3915036881806, "episode": 56.0, "batch_reward": 0.8342906252741814, "critic_loss": 0.5296926073729992, "actor_loss": -85.17614784240723, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.36774969100952, "step": 56000}
{"episode_reward": 964.8001602587161, "episode": 57.0, "batch_reward": 0.8349828724265098, "critic_loss": 0.5229103214740753, "actor_loss": -85.16311570739747, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.319237232208252, "step": 57000}
{"episode_reward": 921.604296231547, "episode": 58.0, "batch_reward": 0.8366025224328041, "critic_loss": 0.5265991931557655, "actor_loss": -85.35290240478515, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.93613338470459, "step": 58000}
{"episode_reward": 906.732447073303, "episode": 59.0, "batch_reward": 0.839009987950325, "critic_loss": 0.5063419433236123, "actor_loss": -85.40185029602051, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.422577381134033, "step": 59000}
{"episode_reward": 959.2603223306144, "episode": 60.0, "batch_reward": 0.8365642216205597, "critic_loss": 0.5457168719023466, "actor_loss": -85.22601776123047, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.64702033996582, "step": 60000}
{"episode_reward": 672.2428076784885, "episode": 61.0, "batch_reward": 0.8379111068248749, "critic_loss": 0.5543262689709664, "actor_loss": -85.33383297729492, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 46.246150493621826, "step": 61000}
{"episode_reward": 917.0802451180798, "episode": 62.0, "batch_reward": 0.8385488790869713, "critic_loss": 0.5330509186089039, "actor_loss": -85.59671620178223, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.040526628494263, "step": 62000}
{"episode_reward": 968.7272686254028, "episode": 63.0, "batch_reward": 0.8402189832329751, "critic_loss": 0.5008448186069727, "actor_loss": -85.65621690368653, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.892964601516724, "step": 63000}
{"episode_reward": 955.8000794531499, "episode": 64.0, "batch_reward": 0.8428652842640877, "critic_loss": 0.49050764919817447, "actor_loss": -85.70803659057617, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.62210178375244, "step": 64000}
{"episode_reward": 929.9290826060612, "episode": 65.0, "batch_reward": 0.8428266172409058, "critic_loss": 0.48705134411156176, "actor_loss": -85.78473934936524, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.50679302215576, "step": 65000}
{"episode_reward": 929.5200963775649, "episode": 66.0, "batch_reward": 0.8452129930853843, "critic_loss": 0.5072115814238787, "actor_loss": -85.84771838378906, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.60990262031555, "step": 66000}
{"episode_reward": 956.4304893822551, "episode": 67.0, "batch_reward": 0.8475077100992203, "critic_loss": 0.48455222268402576, "actor_loss": -86.12888424682617, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.70000123977661, "step": 67000}
{"episode_reward": 888.7024988862995, "episode": 68.0, "batch_reward": 0.8482557557821274, "critic_loss": 0.46818952944874764, "actor_loss": -86.09099067687988, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.511959552764893, "step": 68000}
{"episode_reward": 916.7917062511906, "episode": 69.0, "batch_reward": 0.8485300397276878, "critic_loss": 0.48354352305829523, "actor_loss": -86.12137982177734, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.10597038269043, "step": 69000}
{"episode_reward": 942.7882533089413, "episode": 70.0, "batch_reward": 0.8506953111886978, "critic_loss": 0.4767902439236641, "actor_loss": -86.17822285461426, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.10624670982361, "step": 70000}
{"episode_reward": 911.8375375936971, "episode": 71.0, "batch_reward": 0.8511208443641662, "critic_loss": 0.4498435330986977, "actor_loss": -86.18398413085937, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.2665810585022, "step": 71000}
{"episode_reward": 944.3002311716721, "episode": 72.0, "batch_reward": 0.8539963995814324, "critic_loss": 0.44397438390552996, "actor_loss": -86.32860577392579, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.905887126922607, "step": 72000}
{"episode_reward": 942.2046451765506, "episode": 73.0, "batch_reward": 0.8537165938615799, "critic_loss": 0.4201868824213743, "actor_loss": -86.36947941589355, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.42637801170349, "step": 73000}
{"episode_reward": 963.8607804931348, "episode": 74.0, "batch_reward": 0.8541528708934784, "critic_loss": 0.4466982842385769, "actor_loss": -86.37177993774414, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.43448495864868, "step": 74000}
{"episode_reward": 884.532616616662, "episode": 75.0, "batch_reward": 0.8556021080613136, "critic_loss": 0.4125363903492689, "actor_loss": -86.43944348144531, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.55307960510254, "step": 75000}
{"episode_reward": 945.4675225949247, "episode": 76.0, "batch_reward": 0.8558749937415123, "critic_loss": 0.438274498924613, "actor_loss": -86.45319929504394, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.770476579666138, "step": 76000}
{"episode_reward": 909.2909439716036, "episode": 77.0, "batch_reward": 0.8575950501561165, "critic_loss": 0.44180513760447504, "actor_loss": -86.52379901123047, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.296783924102783, "step": 77000}
{"episode_reward": 973.4334991170464, "episode": 78.0, "batch_reward": 0.8585912832617759, "critic_loss": 0.409384083583951, "actor_loss": -86.55632859802246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.9173526763916, "step": 78000}
{"episode_reward": 926.0677062790862, "episode": 79.0, "batch_reward": 0.8589928547739982, "critic_loss": 0.44230711294710634, "actor_loss": -86.63595223999023, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.60382390022278, "step": 79000}
{"episode_reward": 899.195760480382, "episode": 80.0, "batch_reward": 0.8605450550317765, "critic_loss": 0.43183384673297404, "actor_loss": -86.64318782043458, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.905820608139038, "step": 80000}
{"episode_reward": 955.0029251591451, "episode": 81.0, "batch_reward": 0.8606770724058151, "critic_loss": 0.4198265954256058, "actor_loss": -86.67092636108399, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.98452019691467, "step": 81000}
{"episode_reward": 930.2312502208366, "episode": 82.0, "batch_reward": 0.8628269249796867, "critic_loss": 0.4154354179650545, "actor_loss": -86.8208094329834, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.403478860855103, "step": 82000}
{"episode_reward": 958.8719892793266, "episode": 83.0, "batch_reward": 0.8622601094841957, "critic_loss": 0.42522524669766426, "actor_loss": -86.64308628845215, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.624443531036377, "step": 83000}
{"episode_reward": 920.9134956700562, "episode": 84.0, "batch_reward": 0.8643235911726952, "critic_loss": 0.4340154763609171, "actor_loss": -86.64842861938476, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.622816801071167, "step": 84000}
{"episode_reward": 920.7474118606277, "episode": 85.0, "batch_reward": 0.8634374219775199, "critic_loss": 0.4260704424381256, "actor_loss": -86.82293510437012, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.269665002822876, "step": 85000}
{"episode_reward": 947.8921453658435, "episode": 86.0, "batch_reward": 0.8646620565652847, "critic_loss": 0.42072281427681446, "actor_loss": -86.73949089050294, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.1703839302063, "step": 86000}
{"episode_reward": 864.898457799191, "episode": 87.0, "batch_reward": 0.8648186218738556, "critic_loss": 0.4386559613794088, "actor_loss": -86.6708136138916, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.502832651138306, "step": 87000}
{"episode_reward": 908.3949005668615, "episode": 88.0, "batch_reward": 0.8652614336609841, "critic_loss": 0.4436295994967222, "actor_loss": -86.6471746673584, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.14622974395752, "step": 88000}
{"episode_reward": 941.9501332312215, "episode": 89.0, "batch_reward": 0.8673485071063042, "critic_loss": 0.45283462266623975, "actor_loss": -86.89461917114258, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.063393115997314, "step": 89000}
{"episode_reward": 967.2802081932604, "episode": 90.0, "batch_reward": 0.8682534654736519, "critic_loss": 0.45182093264162543, "actor_loss": -86.84220828247071, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.380879402160645, "step": 90000}
{"episode_reward": 958.6589339264845, "episode": 91.0, "batch_reward": 0.868003619492054, "critic_loss": 0.45597034130990505, "actor_loss": -86.91135388183594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.53068828582764, "step": 91000}
{"episode_reward": 903.4622246191935, "episode": 92.0, "batch_reward": 0.8707078087329865, "critic_loss": 0.4559535989612341, "actor_loss": -86.99034381103516, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.251432418823242, "step": 92000}
{"episode_reward": 957.7831422912788, "episode": 93.0, "batch_reward": 0.8718332530260086, "critic_loss": 0.4416397653222084, "actor_loss": -87.00645510864258, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.238551139831543, "step": 93000}
{"episode_reward": 966.8850372117556, "episode": 94.0, "batch_reward": 0.8723264826536179, "critic_loss": 0.4318558469861746, "actor_loss": -87.04372660827637, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.674780130386353, "step": 94000}
{"episode_reward": 899.739274219079, "episode": 95.0, "batch_reward": 0.8719873387217522, "critic_loss": 0.45873583820462227, "actor_loss": -86.97548887634278, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.239309549331665, "step": 95000}
{"episode_reward": 928.4262019258153, "episode": 96.0, "batch_reward": 0.8711342549920083, "critic_loss": 0.45266899886727335, "actor_loss": -86.97356858825684, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.791821241378784, "step": 96000}
{"episode_reward": 908.0444616933057, "episode": 97.0, "batch_reward": 0.8708582155704498, "critic_loss": 0.47585622875392436, "actor_loss": -86.9940669708252, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.56529402732849, "step": 97000}
{"episode_reward": 939.4721262080456, "episode": 98.0, "batch_reward": 0.8729473484158516, "critic_loss": 0.45842662370204923, "actor_loss": -87.16921104431152, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.04337167739868, "step": 98000}
{"episode_reward": 922.4212717181929, "episode": 99.0, "batch_reward": 0.8726066477298736, "critic_loss": 0.49400510120391844, "actor_loss": -86.94886506652833, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.864773988723755, "step": 99000}
{"episode_reward": 929.7106373776339, "episode": 100.0, "batch_reward": 0.8734465329647064, "critic_loss": 0.4706323139816523, "actor_loss": -87.00116426086426, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.196741819381714, "step": 100000}
{"episode_reward": 952.0302942868306, "episode": 101.0, "batch_reward": 0.8753191587328911, "critic_loss": 0.4673493674248457, "actor_loss": -87.07400894165039, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.76486945152283, "step": 101000}
{"episode_reward": 963.2043645305571, "episode": 102.0, "batch_reward": 0.8762475175857544, "critic_loss": 0.48505480493605135, "actor_loss": -87.07043034362793, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.36467409133911, "step": 102000}
{"episode_reward": 951.8585321549398, "episode": 103.0, "batch_reward": 0.8769077492356301, "critic_loss": 0.4640371454358101, "actor_loss": -87.12493743896485, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.243563652038574, "step": 103000}
{"episode_reward": 934.4954425627096, "episode": 104.0, "batch_reward": 0.8769474290013314, "critic_loss": 0.49182899089157583, "actor_loss": -87.05129078674317, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.103866815567017, "step": 104000}
{"episode_reward": 940.7254550875449, "episode": 105.0, "batch_reward": 0.8776258665323258, "critic_loss": 0.42580438472330573, "actor_loss": -87.17298429870606, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.356083154678345, "step": 105000}
{"episode_reward": 930.7749778737684, "episode": 106.0, "batch_reward": 0.8772448895573616, "critic_loss": 0.45138926039636135, "actor_loss": -87.06381272888184, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.06538486480713, "step": 106000}
{"episode_reward": 891.5691825403245, "episode": 107.0, "batch_reward": 0.8767101593017578, "critic_loss": 0.43492433241009715, "actor_loss": -87.06454290771484, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.389972925186157, "step": 107000}
{"episode_reward": 863.1034191472706, "episode": 108.0, "batch_reward": 0.8778976572751999, "critic_loss": 0.42570414167642595, "actor_loss": -87.30345545959473, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.146657466888428, "step": 108000}
{"episode_reward": 928.9382055671385, "episode": 109.0, "batch_reward": 0.8784225634336471, "critic_loss": 0.4070184862017632, "actor_loss": -86.99264082336425, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.300151348114014, "step": 109000}
{"episode_reward": 918.158725906059, "episode": 110.0, "batch_reward": 0.8794149391055107, "critic_loss": 0.42155001233518125, "actor_loss": -86.99823933410644, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.889864683151245, "step": 110000}
{"episode_reward": 932.6145291701762, "episode": 111.0, "batch_reward": 0.8793483443856239, "critic_loss": 0.4373147468417883, "actor_loss": -87.28673699951172, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.55222010612488, "step": 111000}
{"episode_reward": 934.8868961604915, "episode": 112.0, "batch_reward": 0.8789454498291016, "critic_loss": 0.4598272676765919, "actor_loss": -86.98291247558593, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.671199560165405, "step": 112000}
{"episode_reward": 873.9561131254349, "episode": 113.0, "batch_reward": 0.8803587060570717, "critic_loss": 0.45823752319812777, "actor_loss": -87.12801487731933, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.82396936416626, "step": 113000}
{"episode_reward": 951.7516478618301, "episode": 114.0, "batch_reward": 0.8803627480864524, "critic_loss": 0.478639353826642, "actor_loss": -87.11855081176758, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.94010043144226, "step": 114000}
{"episode_reward": 955.0312476015272, "episode": 115.0, "batch_reward": 0.8813262898921966, "critic_loss": 0.4759294086992741, "actor_loss": -87.1386714630127, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.448285579681396, "step": 115000}
{"episode_reward": 947.0334479976723, "episode": 116.0, "batch_reward": 0.8826073182225227, "critic_loss": 0.47114585798978803, "actor_loss": -87.16332348632812, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.501627445220947, "step": 116000}
{"episode_reward": 929.016116460292, "episode": 117.0, "batch_reward": 0.8810807560682297, "critic_loss": 0.49144134317338467, "actor_loss": -87.38251016235351, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.8267502784729, "step": 117000}
{"episode_reward": 811.6519027040819, "episode": 118.0, "batch_reward": 0.8809290145635604, "critic_loss": 0.5038354016542435, "actor_loss": -87.26323561096191, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.161653757095337, "step": 118000}
{"episode_reward": 944.2796952581956, "episode": 119.0, "batch_reward": 0.882587208032608, "critic_loss": 0.48037104699015615, "actor_loss": -87.25902908325196, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.39778184890747, "step": 119000}
{"episode_reward": 955.454332362561, "episode": 120.0, "batch_reward": 0.8836484326720238, "critic_loss": 0.47282807689905165, "actor_loss": -87.40923626708984, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.780088663101196, "step": 120000}
{"episode_reward": 954.1052346682384, "episode": 121.0, "batch_reward": 0.8832967742085457, "critic_loss": 0.5018139041364192, "actor_loss": -87.44963282775879, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.87385606765747, "step": 121000}
{"episode_reward": 911.4683046715943, "episode": 122.0, "batch_reward": 0.8829273265004158, "critic_loss": 0.5167661792337894, "actor_loss": -87.35755722045899, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.320540189743042, "step": 122000}
{"episode_reward": 947.7334575463207, "episode": 123.0, "batch_reward": 0.8847143145799636, "critic_loss": 0.4892517782151699, "actor_loss": -87.32712339782715, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.271493196487427, "step": 123000}
{"episode_reward": 954.6507174320185, "episode": 124.0, "batch_reward": 0.885390400826931, "critic_loss": 0.5104354089647531, "actor_loss": -87.38503507995605, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.663421869277954, "step": 124000}
{"episode_reward": 957.6032389478082, "episode": 125.0, "batch_reward": 0.8869657357931137, "critic_loss": 0.48835056971013546, "actor_loss": -87.48919689941407, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.161237001419067, "step": 125000}
{"episode_reward": 955.9107556330121, "episode": 126.0, "batch_reward": 0.887022099673748, "critic_loss": 0.4903893265873194, "actor_loss": -87.51705867004395, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.141602993011475, "step": 126000}
{"episode_reward": 968.9221948014691, "episode": 127.0, "batch_reward": 0.8863973798155784, "critic_loss": 0.49780169673264024, "actor_loss": -87.3458286895752, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.239965438842773, "step": 127000}
{"episode_reward": 928.7336161388972, "episode": 128.0, "batch_reward": 0.8868434224724769, "critic_loss": 0.4954223586916924, "actor_loss": -87.50256773376465, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.28262424468994, "step": 128000}
{"episode_reward": 959.3770117970646, "episode": 129.0, "batch_reward": 0.8856685408353806, "critic_loss": 0.45049995952099564, "actor_loss": -87.53645606994628, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.4402596950531, "step": 129000}
{"episode_reward": 958.0939460445827, "episode": 130.0, "batch_reward": 0.889175412774086, "critic_loss": 0.42441624829173086, "actor_loss": -87.69526084899903, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.382108449935913, "step": 130000}
{"episode_reward": 926.3294248071404, "episode": 131.0, "batch_reward": 0.8884319267272949, "critic_loss": 0.4355424547791481, "actor_loss": -87.48406362915038, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.16002678871155, "step": 131000}
{"episode_reward": 931.1116772537227, "episode": 132.0, "batch_reward": 0.8882505087256432, "critic_loss": 0.4395197894722223, "actor_loss": -87.49728355407714, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.026031494140625, "step": 132000}
{"episode_reward": 925.2709389822379, "episode": 133.0, "batch_reward": 0.8888516866564751, "critic_loss": 0.4353372147530317, "actor_loss": -87.74140560913087, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.008530378341675, "step": 133000}
{"episode_reward": 955.3364055236134, "episode": 134.0, "batch_reward": 0.8896126814484596, "critic_loss": 0.4104614274352789, "actor_loss": -87.86083390808105, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.840803623199463, "step": 134000}
{"episode_reward": 909.1456036789782, "episode": 135.0, "batch_reward": 0.89015335303545, "critic_loss": 0.4347655737996101, "actor_loss": -87.57594161987305, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.599642515182495, "step": 135000}
{"episode_reward": 918.0653146236926, "episode": 136.0, "batch_reward": 0.8902596452832222, "critic_loss": 0.4401217877417803, "actor_loss": -88.08491069030762, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.64293646812439, "step": 136000}
{"episode_reward": 946.8659135515619, "episode": 137.0, "batch_reward": 0.8896525787115097, "critic_loss": 0.4195041976124048, "actor_loss": -87.77726440429687, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.891790866851807, "step": 137000}
{"episode_reward": 953.786440760964, "episode": 138.0, "batch_reward": 0.8920008764266968, "critic_loss": 0.4189237509071827, "actor_loss": -87.8410411682129, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.292929649353027, "step": 138000}
{"episode_reward": 965.9067541582267, "episode": 139.0, "batch_reward": 0.890958130478859, "critic_loss": 0.43390053959190844, "actor_loss": -87.86556869506836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.910375595092773, "step": 139000}
{"episode_reward": 932.5721207083199, "episode": 140.0, "batch_reward": 0.8930815289020538, "critic_loss": 0.4412078487277031, "actor_loss": -87.87508424377441, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.08956789970398, "step": 140000}
{"episode_reward": 943.4226400845089, "episode": 141.0, "batch_reward": 0.8905285548567772, "critic_loss": 0.4365305491387844, "actor_loss": -87.72584738159179, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.376282930374146, "step": 141000}
{"episode_reward": 956.9165909945489, "episode": 142.0, "batch_reward": 0.8920760610103607, "critic_loss": 0.42649156820774076, "actor_loss": -88.0069497680664, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.34604835510254, "step": 142000}
{"episode_reward": 947.0101780495828, "episode": 143.0, "batch_reward": 0.8927839994430542, "critic_loss": 0.42694330581277606, "actor_loss": -88.0981958770752, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.270522117614746, "step": 143000}
{"episode_reward": 952.3569547637513, "episode": 144.0, "batch_reward": 0.8937003934979438, "critic_loss": 0.4248030856102705, "actor_loss": -87.871941116333, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.61608910560608, "step": 144000}
{"episode_reward": 881.1635326355221, "episode": 145.0, "batch_reward": 0.8932315827608108, "critic_loss": 0.4180746608972549, "actor_loss": -87.90297511291504, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.152228355407715, "step": 145000}
{"episode_reward": 891.698663395853, "episode": 146.0, "batch_reward": 0.8937656243443489, "critic_loss": 0.4028581346273422, "actor_loss": -87.90882832336426, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.891661405563354, "step": 146000}
{"episode_reward": 968.8051011021602, "episode": 147.0, "batch_reward": 0.8940306874513626, "critic_loss": 0.4033506428897381, "actor_loss": -87.90551774597168, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.3920419216156, "step": 147000}
{"episode_reward": 888.5062494611949, "episode": 148.0, "batch_reward": 0.893218441426754, "critic_loss": 0.4127105252742767, "actor_loss": -87.9406033782959, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.7632737159729, "step": 148000}
{"episode_reward": 922.9236198316999, "episode": 149.0, "batch_reward": 0.892341743350029, "critic_loss": 0.4345836366117001, "actor_loss": -87.93899743652344, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.824021577835083, "step": 149000}
{"episode_reward": 938.9624892950001, "episode": 150.0, "batch_reward": 0.8926295852065086, "critic_loss": 0.4502860371246934, "actor_loss": -87.84311665344238, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
