{"episode_reward": 0.0, "episode": 1.0, "duration": 22.09840226173401, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.9211761951446533, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.2898513543462706, "critic_loss": 0.8032726487663437, "actor_loss": -69.23224518689311, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 65.40920162200928, "step": 3000}
{"episode_reward": 512.4471379936297, "episode": 4.0, "batch_reward": 0.39519455677270887, "critic_loss": 0.8943269717097282, "actor_loss": -74.43702876281738, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.8607497215271, "step": 4000}
{"episode_reward": 617.4326679284865, "episode": 5.0, "batch_reward": 0.38729273676872256, "critic_loss": 0.8620893662273884, "actor_loss": -74.31043572998047, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.504754781723022, "step": 5000}
{"episode_reward": 91.18974668816107, "episode": 6.0, "batch_reward": 0.38564134150743484, "critic_loss": 0.9758268628716469, "actor_loss": -74.14262208557129, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.85520076751709, "step": 6000}
{"episode_reward": 592.9250744214663, "episode": 7.0, "batch_reward": 0.41398304548859594, "critic_loss": 0.9686787130832673, "actor_loss": -74.34445179748535, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.443823099136353, "step": 7000}
{"episode_reward": 678.2086696464506, "episode": 8.0, "batch_reward": 0.4483739050626755, "critic_loss": 0.8773609864115715, "actor_loss": -74.7154174041748, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.162997007369995, "step": 8000}
{"episode_reward": 669.8094489234204, "episode": 9.0, "batch_reward": 0.48366841581463815, "critic_loss": 0.7594651057124138, "actor_loss": -75.26144662475586, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.641758918762207, "step": 9000}
{"episode_reward": 817.7179876644374, "episode": 10.0, "batch_reward": 0.5276359090209007, "critic_loss": 0.6409240450263023, "actor_loss": -75.92296154785156, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.38828420639038, "step": 10000}
{"episode_reward": 929.357423954512, "episode": 11.0, "batch_reward": 0.5612086333930493, "critic_loss": 0.6673021534085274, "actor_loss": -76.54386613464355, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.698028326034546, "step": 11000}
{"episode_reward": 858.5374548401904, "episode": 12.0, "batch_reward": 0.5825056031346321, "critic_loss": 0.7570228326022626, "actor_loss": -76.86364236450196, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.409584045410156, "step": 12000}
{"episode_reward": 806.6898857063838, "episode": 13.0, "batch_reward": 0.6039937063157559, "critic_loss": 0.7680133511722088, "actor_loss": -77.2089012298584, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.06905746459961, "step": 13000}
{"episode_reward": 871.4886777684326, "episode": 14.0, "batch_reward": 0.628469624698162, "critic_loss": 0.7339818778932095, "actor_loss": -77.83459515380859, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.454643964767456, "step": 14000}
{"episode_reward": 948.7821922348331, "episode": 15.0, "batch_reward": 0.6497485027909279, "critic_loss": 0.6847527956366539, "actor_loss": -78.33062077331543, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.730926036834717, "step": 15000}
{"episode_reward": 931.6437460262157, "episode": 16.0, "batch_reward": 0.6690437713265419, "critic_loss": 0.6571020278334617, "actor_loss": -79.0734757080078, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.411214590072632, "step": 16000}
{"episode_reward": 934.3416190584481, "episode": 17.0, "batch_reward": 0.6806067572832107, "critic_loss": 0.6791708998680115, "actor_loss": -79.37179891967773, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.567782640457153, "step": 17000}
{"episode_reward": 893.3987835792186, "episode": 18.0, "batch_reward": 0.6895781106948853, "critic_loss": 0.6741066099107266, "actor_loss": -79.6408734588623, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.703078031539917, "step": 18000}
{"episode_reward": 787.9403638040196, "episode": 19.0, "batch_reward": 0.6978785296082497, "critic_loss": 0.5969921054542064, "actor_loss": -79.93008889770508, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.032610654830933, "step": 19000}
{"episode_reward": 911.7318857788708, "episode": 20.0, "batch_reward": 0.7103187066316604, "critic_loss": 0.6024694835543632, "actor_loss": -80.1927129058838, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.650241136550903, "step": 20000}
{"episode_reward": 875.0598133888086, "episode": 21.0, "batch_reward": 0.7203810908794404, "critic_loss": 0.5379408096373082, "actor_loss": -80.58305458068848, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.260417461395264, "step": 21000}
{"episode_reward": 969.7947463853518, "episode": 22.0, "batch_reward": 0.7299777066707611, "critic_loss": 0.5418836985528469, "actor_loss": -80.89107723999024, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.779388189315796, "step": 22000}
{"episode_reward": 904.3121601829217, "episode": 23.0, "batch_reward": 0.7354970620274544, "critic_loss": 0.5179155703783035, "actor_loss": -81.07994207763672, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.75541853904724, "step": 23000}
{"episode_reward": 881.3105884536391, "episode": 24.0, "batch_reward": 0.7428444821238518, "critic_loss": 0.494961805164814, "actor_loss": -81.29403440856933, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.83877992630005, "step": 24000}
{"episode_reward": 886.6842449791835, "episode": 25.0, "batch_reward": 0.7493145897984504, "critic_loss": 0.4682162235230207, "actor_loss": -81.53020333862305, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.67141056060791, "step": 25000}
{"episode_reward": 939.1501994050487, "episode": 26.0, "batch_reward": 0.7562827860713005, "critic_loss": 0.4662205778062344, "actor_loss": -81.79328309631347, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.552778720855713, "step": 26000}
{"episode_reward": 940.8865678949727, "episode": 27.0, "batch_reward": 0.7620895334482193, "critic_loss": 0.5161964761614799, "actor_loss": -81.90397175598144, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.21765375137329, "step": 27000}
{"episode_reward": 847.2700637527236, "episode": 28.0, "batch_reward": 0.7650606949925423, "critic_loss": 0.49647044855356215, "actor_loss": -82.08729762268067, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.873852491378784, "step": 28000}
{"episode_reward": 884.9956613989847, "episode": 29.0, "batch_reward": 0.7694224643707276, "critic_loss": 0.5454942670464515, "actor_loss": -82.19679348754883, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.651320457458496, "step": 29000}
{"episode_reward": 850.8530883526296, "episode": 30.0, "batch_reward": 0.7726439003348351, "critic_loss": 0.5215251070708037, "actor_loss": -82.36070895385743, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.94438600540161, "step": 30000}
{"episode_reward": 911.562111657422, "episode": 31.0, "batch_reward": 0.775745035469532, "critic_loss": 0.5640554832816124, "actor_loss": -82.47330126953125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 45.747161626815796, "step": 31000}
{"episode_reward": 893.271369388406, "episode": 32.0, "batch_reward": 0.7819824677109718, "critic_loss": 0.6009915191829205, "actor_loss": -82.69577966308594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.05514430999756, "step": 32000}
{"episode_reward": 938.7234968668956, "episode": 33.0, "batch_reward": 0.7870680928826332, "critic_loss": 0.6195221728086472, "actor_loss": -82.85363331604005, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.52795171737671, "step": 33000}
{"episode_reward": 902.5858563485634, "episode": 34.0, "batch_reward": 0.7892813447713852, "critic_loss": 0.6498025584518909, "actor_loss": -82.99346726989747, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.003211736679077, "step": 34000}
{"episode_reward": 868.643819450967, "episode": 35.0, "batch_reward": 0.792844504415989, "critic_loss": 0.638839194059372, "actor_loss": -83.10536650085449, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.636561155319214, "step": 35000}
{"episode_reward": 928.4009107646763, "episode": 36.0, "batch_reward": 0.7984289858937264, "critic_loss": 0.601551079660654, "actor_loss": -83.27968440246582, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.479058027267456, "step": 36000}
{"episode_reward": 943.2913567057395, "episode": 37.0, "batch_reward": 0.8018603684306145, "critic_loss": 0.5965255539119244, "actor_loss": -83.3957355041504, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.725370168685913, "step": 37000}
{"episode_reward": 940.244297533064, "episode": 38.0, "batch_reward": 0.805971664249897, "critic_loss": 0.5618226533830166, "actor_loss": -83.56423323059082, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.593159198760986, "step": 38000}
{"episode_reward": 949.2650110061688, "episode": 39.0, "batch_reward": 0.808281673192978, "critic_loss": 0.5526912578046322, "actor_loss": -83.73596875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.20185351371765, "step": 39000}
{"episode_reward": 937.3962211089861, "episode": 40.0, "batch_reward": 0.8106434653401375, "critic_loss": 0.6038277542889118, "actor_loss": -83.77036737060547, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.897807121276855, "step": 40000}
{"episode_reward": 897.7178994679396, "episode": 41.0, "batch_reward": 0.8128176842927932, "critic_loss": 0.5610588337630034, "actor_loss": -83.90225894165039, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.34669518470764, "step": 41000}
{"episode_reward": 907.8268123890141, "episode": 42.0, "batch_reward": 0.8127179417014122, "critic_loss": 0.5757971695065498, "actor_loss": -84.04473927307129, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.51404094696045, "step": 42000}
{"episode_reward": 834.3764598103, "episode": 43.0, "batch_reward": 0.8165290029048919, "critic_loss": 0.5896949735581875, "actor_loss": -84.12831971740722, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.208029747009277, "step": 43000}
{"episode_reward": 898.4798454797562, "episode": 44.0, "batch_reward": 0.8170219307541847, "critic_loss": 0.6039276556968689, "actor_loss": -84.2085054321289, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.48653769493103, "step": 44000}
{"episode_reward": 803.9330372541168, "episode": 45.0, "batch_reward": 0.8190416390299797, "critic_loss": 0.5893137151896953, "actor_loss": -84.37902247619628, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.521624088287354, "step": 45000}
{"episode_reward": 945.1466747592593, "episode": 46.0, "batch_reward": 0.8208872502446175, "critic_loss": 0.5740516481101513, "actor_loss": -84.39237059020996, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.90726661682129, "step": 46000}
{"episode_reward": 942.8368798555525, "episode": 47.0, "batch_reward": 0.823372197329998, "critic_loss": 0.5644857023060322, "actor_loss": -84.44035536193847, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.905462503433228, "step": 47000}
{"episode_reward": 918.9390095502342, "episode": 48.0, "batch_reward": 0.8262627826929092, "critic_loss": 0.5567391967177391, "actor_loss": -84.61002951049805, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.909101486206055, "step": 48000}
{"episode_reward": 932.0423970578191, "episode": 49.0, "batch_reward": 0.8270423501729965, "critic_loss": 0.5535098792612553, "actor_loss": -84.63024821472168, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.47374725341797, "step": 49000}
{"episode_reward": 868.1402757664696, "episode": 50.0, "batch_reward": 0.8281913423538207, "critic_loss": 0.5242219259589911, "actor_loss": -84.76261186218262, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.087401151657104, "step": 50000}
{"episode_reward": 903.0836101817836, "episode": 51.0, "batch_reward": 0.8309538049697875, "critic_loss": 0.5110706021636724, "actor_loss": -85.06733944702148, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.17144966125488, "step": 51000}
{"episode_reward": 957.361111457989, "episode": 52.0, "batch_reward": 0.8261374353766441, "critic_loss": 0.5712802082300186, "actor_loss": -84.71202365112305, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.231906175613403, "step": 52000}
{"episode_reward": 603.2433403177077, "episode": 53.0, "batch_reward": 0.8281932299137116, "critic_loss": 0.5432094645500183, "actor_loss": -84.9658313293457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.520153522491455, "step": 53000}
{"episode_reward": 922.1369273960422, "episode": 54.0, "batch_reward": 0.8293783204555512, "critic_loss": 0.5262833535075188, "actor_loss": -84.82402522277832, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.01248526573181, "step": 54000}
{"episode_reward": 931.4565867577022, "episode": 55.0, "batch_reward": 0.830158720433712, "critic_loss": 0.5163828891813755, "actor_loss": -84.90918754577636, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.71970009803772, "step": 55000}
{"episode_reward": 912.3915036881806, "episode": 56.0, "batch_reward": 0.8342906252741814, "critic_loss": 0.5296926073729992, "actor_loss": -85.17614784240723, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.36774969100952, "step": 56000}
{"episode_reward": 964.8001602587161, "episode": 57.0, "batch_reward": 0.8349828724265098, "critic_loss": 0.5229103214740753, "actor_loss": -85.16311570739747, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.319237232208252, "step": 57000}
{"episode_reward": 921.604296231547, "episode": 58.0, "batch_reward": 0.8366025224328041, "critic_loss": 0.5265991931557655, "actor_loss": -85.35290240478515, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.93613338470459, "step": 58000}
{"episode_reward": 906.732447073303, "episode": 59.0, "batch_reward": 0.839009987950325, "critic_loss": 0.5063419433236123, "actor_loss": -85.40185029602051, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.422577381134033, "step": 59000}
{"episode_reward": 959.2603223306144, "episode": 60.0, "batch_reward": 0.8365642216205597, "critic_loss": 0.5457168719023466, "actor_loss": -85.22601776123047, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.64702033996582, "step": 60000}
{"episode_reward": 672.2428076784885, "episode": 61.0, "batch_reward": 0.8379111068248749, "critic_loss": 0.5543262689709664, "actor_loss": -85.33383297729492, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 46.246150493621826, "step": 61000}
{"episode_reward": 917.0802451180798, "episode": 62.0, "batch_reward": 0.8385488790869713, "critic_loss": 0.5330509186089039, "actor_loss": -85.59671620178223, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.040526628494263, "step": 62000}
{"episode_reward": 968.7272686254028, "episode": 63.0, "batch_reward": 0.8402189832329751, "critic_loss": 0.5008448186069727, "actor_loss": -85.65621690368653, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.892964601516724, "step": 63000}
{"episode_reward": 955.8000794531499, "episode": 64.0, "batch_reward": 0.8428652842640877, "critic_loss": 0.49050764919817447, "actor_loss": -85.70803659057617, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.62210178375244, "step": 64000}
{"episode_reward": 929.9290826060612, "episode": 65.0, "batch_reward": 0.8428266172409058, "critic_loss": 0.48705134411156176, "actor_loss": -85.78473934936524, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.50679302215576, "step": 65000}
{"episode_reward": 929.5200963775649, "episode": 66.0, "batch_reward": 0.8452129930853843, "critic_loss": 0.5072115814238787, "actor_loss": -85.84771838378906, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.60990262031555, "step": 66000}
{"episode_reward": 956.4304893822551, "episode": 67.0, "batch_reward": 0.8475077100992203, "critic_loss": 0.48455222268402576, "actor_loss": -86.12888424682617, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.70000123977661, "step": 67000}
{"episode_reward": 888.7024988862995, "episode": 68.0, "batch_reward": 0.8482557557821274, "critic_loss": 0.46818952944874764, "actor_loss": -86.09099067687988, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.511959552764893, "step": 68000}
{"episode_reward": 916.7917062511906, "episode": 69.0, "batch_reward": 0.8485300397276878, "critic_loss": 0.48354352305829523, "actor_loss": -86.12137982177734, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.10597038269043, "step": 69000}
{"episode_reward": 942.7882533089413, "episode": 70.0, "batch_reward": 0.8506953111886978, "critic_loss": 0.4767902439236641, "actor_loss": -86.17822285461426, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.10624670982361, "step": 70000}
{"episode_reward": 911.8375375936971, "episode": 71.0, "batch_reward": 0.8511208443641662, "critic_loss": 0.4498435330986977, "actor_loss": -86.18398413085937, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.2665810585022, "step": 71000}
{"episode_reward": 944.3002311716721, "episode": 72.0, "batch_reward": 0.8539963995814324, "critic_loss": 0.44397438390552996, "actor_loss": -86.32860577392579, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.905887126922607, "step": 72000}
{"episode_reward": 942.2046451765506, "episode": 73.0, "batch_reward": 0.8537165938615799, "critic_loss": 0.4201868824213743, "actor_loss": -86.36947941589355, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.42637801170349, "step": 73000}
{"episode_reward": 963.8607804931348, "episode": 74.0, "batch_reward": 0.8541528708934784, "critic_loss": 0.4466982842385769, "actor_loss": -86.37177993774414, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.43448495864868, "step": 74000}
{"episode_reward": 884.532616616662, "episode": 75.0, "batch_reward": 0.8556021080613136, "critic_loss": 0.4125363903492689, "actor_loss": -86.43944348144531, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.55307960510254, "step": 75000}
{"episode_reward": 945.4675225949247, "episode": 76.0, "batch_reward": 0.8558749937415123, "critic_loss": 0.438274498924613, "actor_loss": -86.45319929504394, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.770476579666138, "step": 76000}
{"episode_reward": 909.2909439716036, "episode": 77.0, "batch_reward": 0.8575950501561165, "critic_loss": 0.44180513760447504, "actor_loss": -86.52379901123047, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.296783924102783, "step": 77000}
{"episode_reward": 973.4334991170464, "episode": 78.0, "batch_reward": 0.8585912832617759, "critic_loss": 0.409384083583951, "actor_loss": -86.55632859802246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.9173526763916, "step": 78000}
{"episode_reward": 926.0677062790862, "episode": 79.0, "batch_reward": 0.8589928547739982, "critic_loss": 0.44230711294710634, "actor_loss": -86.63595223999023, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.60382390022278, "step": 79000}
{"episode_reward": 899.195760480382, "episode": 80.0, "batch_reward": 0.8605450550317765, "critic_loss": 0.43183384673297404, "actor_loss": -86.64318782043458, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.905820608139038, "step": 80000}
{"episode_reward": 955.0029251591451, "episode": 81.0, "batch_reward": 0.8606770724058151, "critic_loss": 0.4198265954256058, "actor_loss": -86.67092636108399, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.98452019691467, "step": 81000}
{"episode_reward": 930.2312502208366, "episode": 82.0, "batch_reward": 0.8628269249796867, "critic_loss": 0.4154354179650545, "actor_loss": -86.8208094329834, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.403478860855103, "step": 82000}
{"episode_reward": 958.8719892793266, "episode": 83.0, "batch_reward": 0.8622601094841957, "critic_loss": 0.42522524669766426, "actor_loss": -86.64308628845215, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.624443531036377, "step": 83000}
{"episode_reward": 920.9134956700562, "episode": 84.0, "batch_reward": 0.8643235911726952, "critic_loss": 0.4340154763609171, "actor_loss": -86.64842861938476, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.622816801071167, "step": 84000}
{"episode_reward": 920.7474118606277, "episode": 85.0, "batch_reward": 0.8634374219775199, "critic_loss": 0.4260704424381256, "actor_loss": -86.82293510437012, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.269665002822876, "step": 85000}
{"episode_reward": 947.8921453658435, "episode": 86.0, "batch_reward": 0.8646620565652847, "critic_loss": 0.42072281427681446, "actor_loss": -86.73949089050294, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.1703839302063, "step": 86000}
{"episode_reward": 864.898457799191, "episode": 87.0, "batch_reward": 0.8648186218738556, "critic_loss": 0.4386559613794088, "actor_loss": -86.6708136138916, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.502832651138306, "step": 87000}
{"episode_reward": 908.3949005668615, "episode": 88.0, "batch_reward": 0.8652614336609841, "critic_loss": 0.4436295994967222, "actor_loss": -86.6471746673584, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.14622974395752, "step": 88000}
