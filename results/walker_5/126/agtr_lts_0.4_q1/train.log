{"episode_reward": 0.0, "episode": 1.0, "duration": 21.263572454452515, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.851752519607544, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.27867680575876247, "critic_loss": 0.197476794373054, "actor_loss": -29.36378336614635, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 64.40983057022095, "step": 3000}
{"episode_reward": 222.54928847963672, "episode": 4.0, "batch_reward": 0.2832889535576105, "critic_loss": 0.5473217094838619, "actor_loss": -29.947858471870422, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.213687896728516, "step": 4000}
{"episode_reward": 479.84950649616786, "episode": 5.0, "batch_reward": 0.33504396231472494, "critic_loss": 0.6874654963612556, "actor_loss": -33.873912754058836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.01668381690979, "step": 5000}
{"episode_reward": 479.19075240668434, "episode": 6.0, "batch_reward": 0.38259823295474055, "critic_loss": 0.8479689111709595, "actor_loss": -35.19947678184509, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.115482807159424, "step": 6000}
{"episode_reward": 654.0542460924331, "episode": 7.0, "batch_reward": 0.4271042105257511, "critic_loss": 0.9881669015288354, "actor_loss": -38.32412101173401, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.036004781723022, "step": 7000}
{"episode_reward": 819.603172810393, "episode": 8.0, "batch_reward": 0.4763515290617943, "critic_loss": 1.082253204524517, "actor_loss": -41.9607081489563, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.016313791275024, "step": 8000}
{"episode_reward": 777.6871491598035, "episode": 9.0, "batch_reward": 0.5159691695570946, "critic_loss": 1.0808851850032806, "actor_loss": -45.686062015533444, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.897114753723145, "step": 9000}
{"episode_reward": 841.457904147722, "episode": 10.0, "batch_reward": 0.5538562761843204, "critic_loss": 1.0861671538949014, "actor_loss": -48.01877056503296, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.311010360717773, "step": 10000}
{"episode_reward": 832.4063051672829, "episode": 11.0, "batch_reward": 0.579841986745596, "critic_loss": 1.1450842601060867, "actor_loss": -48.30882621383667, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.20716452598572, "step": 11000}
{"episode_reward": 841.0356025443238, "episode": 12.0, "batch_reward": 0.5986377005875111, "critic_loss": 1.323694793879986, "actor_loss": -51.882958095550535, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.893232345581055, "step": 12000}
{"episode_reward": 815.9985116339957, "episode": 13.0, "batch_reward": 0.6152642225623131, "critic_loss": 1.211725868523121, "actor_loss": -52.10893172454834, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.558027029037476, "step": 13000}
{"episode_reward": 781.9516400951389, "episode": 14.0, "batch_reward": 0.6294760802388191, "critic_loss": 1.386226940393448, "actor_loss": -54.25087372589111, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.941731691360474, "step": 14000}
{"episode_reward": 861.2874482150372, "episode": 15.0, "batch_reward": 0.6461506461501122, "critic_loss": 1.4011222111582755, "actor_loss": -53.874833320617675, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.74925661087036, "step": 15000}
{"episode_reward": 858.6892292446485, "episode": 16.0, "batch_reward": 0.6621779776811599, "critic_loss": 1.4829910967350006, "actor_loss": -59.8886234741211, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.60773253440857, "step": 16000}
{"episode_reward": 924.1266810995171, "episode": 17.0, "batch_reward": 0.65591604834795, "critic_loss": 1.882595318198204, "actor_loss": -60.46304474639893, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.128000020980835, "step": 17000}
{"episode_reward": 263.78172580449854, "episode": 18.0, "batch_reward": 0.649799786567688, "critic_loss": 1.5438445418477058, "actor_loss": -61.03511534881592, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.78268051147461, "step": 18000}
{"episode_reward": 770.113677096835, "episode": 19.0, "batch_reward": 0.6582910770177841, "critic_loss": 1.32561258995533, "actor_loss": -62.14484362030029, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.875353574752808, "step": 19000}
{"episode_reward": 857.4604472411496, "episode": 20.0, "batch_reward": 0.6701681424379349, "critic_loss": 1.2656480791568756, "actor_loss": -62.050391471862795, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.656028032302856, "step": 20000}
{"episode_reward": 920.1753981374213, "episode": 21.0, "batch_reward": 0.6865152638554574, "critic_loss": 1.1425670238733292, "actor_loss": -64.07082495880127, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.01661944389343, "step": 21000}
{"episode_reward": 964.6964100881966, "episode": 22.0, "batch_reward": 0.6976309348940849, "critic_loss": 1.1256331423521042, "actor_loss": -63.735174270629884, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.8681583404541, "step": 22000}
{"episode_reward": 938.6712776411629, "episode": 23.0, "batch_reward": 0.7000810237526893, "critic_loss": 1.3208792503476143, "actor_loss": -65.39754230499267, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.05937123298645, "step": 23000}
{"episode_reward": 705.0208292306834, "episode": 24.0, "batch_reward": 0.7082695599198341, "critic_loss": 1.156733815729618, "actor_loss": -65.88350967407227, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.857032299041748, "step": 24000}
{"episode_reward": 951.8062271928442, "episode": 25.0, "batch_reward": 0.7139939383864403, "critic_loss": 1.1707308169603348, "actor_loss": -66.94742824554443, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.630184650421143, "step": 25000}
{"episode_reward": 860.5191006455037, "episode": 26.0, "batch_reward": 0.7223204864263535, "critic_loss": 1.1256728666424751, "actor_loss": -68.19324155426025, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.772313594818115, "step": 26000}
{"episode_reward": 900.1659606157705, "episode": 27.0, "batch_reward": 0.7309928866624832, "critic_loss": 1.151629381477833, "actor_loss": -68.00636328125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.723254203796387, "step": 27000}
{"episode_reward": 933.0917626994728, "episode": 28.0, "batch_reward": 0.7350961776375771, "critic_loss": 1.1266578191518783, "actor_loss": -69.84301429748535, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.085522413253784, "step": 28000}
{"episode_reward": 926.6206590532931, "episode": 29.0, "batch_reward": 0.7445689263343811, "critic_loss": 1.066740051239729, "actor_loss": -69.8111226272583, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.076125860214233, "step": 29000}
{"episode_reward": 970.7790499896956, "episode": 30.0, "batch_reward": 0.7444186598062515, "critic_loss": 1.1267327466011048, "actor_loss": -70.72944136047363, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.779261827468872, "step": 30000}
{"episode_reward": 733.6199464692595, "episode": 31.0, "batch_reward": 0.7481096785068512, "critic_loss": 1.120054559826851, "actor_loss": -71.89573345947265, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.37298846244812, "step": 31000}
{"episode_reward": 836.7952787139233, "episode": 32.0, "batch_reward": 0.7529467774033547, "critic_loss": 1.0789402633905412, "actor_loss": -72.03536867523194, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.141611337661743, "step": 32000}
{"episode_reward": 946.421992954708, "episode": 33.0, "batch_reward": 0.7589276466369629, "critic_loss": 1.1464034432172776, "actor_loss": -72.04292851257324, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.836281538009644, "step": 33000}
{"episode_reward": 838.0885028169512, "episode": 34.0, "batch_reward": 0.7582300475239754, "critic_loss": 1.1518026016950607, "actor_loss": -73.3657829284668, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.912890434265137, "step": 34000}
{"episode_reward": 727.4628900735436, "episode": 35.0, "batch_reward": 0.7596491510272027, "critic_loss": 1.247792146921158, "actor_loss": -73.77402268981933, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.63589382171631, "step": 35000}
{"episode_reward": 920.4554522398473, "episode": 36.0, "batch_reward": 0.7643997924923897, "critic_loss": 1.2859209703803063, "actor_loss": -74.15126301574708, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.996735334396362, "step": 36000}
{"episode_reward": 907.1517033181641, "episode": 37.0, "batch_reward": 0.7651593170166016, "critic_loss": 1.36353487855196, "actor_loss": -74.5696358795166, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.317344665527344, "step": 37000}
{"episode_reward": 696.0022511988675, "episode": 38.0, "batch_reward": 0.768549619436264, "critic_loss": 1.344672520518303, "actor_loss": -74.57788136291504, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.977739334106445, "step": 38000}
{"episode_reward": 959.5408612471832, "episode": 39.0, "batch_reward": 0.7699773638248444, "critic_loss": 1.3487494891285896, "actor_loss": -75.18753486633301, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.266744375228882, "step": 39000}
{"episode_reward": 871.874201011879, "episode": 40.0, "batch_reward": 0.7718388402462005, "critic_loss": 1.3138973479866982, "actor_loss": -75.85408399963379, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.2411150932312, "step": 40000}
{"episode_reward": 872.5934588735263, "episode": 41.0, "batch_reward": 0.7775608890652657, "critic_loss": 1.327326506793499, "actor_loss": -76.58233518981933, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.551074266433716, "step": 41000}
{"episode_reward": 946.2008028955512, "episode": 42.0, "batch_reward": 0.7793042501211166, "critic_loss": 1.244795280098915, "actor_loss": -76.60769482421875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.472720623016357, "step": 42000}
{"episode_reward": 934.4805798654917, "episode": 43.0, "batch_reward": 0.7861136500239372, "critic_loss": 1.2931254040002822, "actor_loss": -77.12015623474122, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.227344274520874, "step": 43000}
{"episode_reward": 918.4150692670385, "episode": 44.0, "batch_reward": 0.789619416475296, "critic_loss": 1.2889774410128594, "actor_loss": -77.50691790771485, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.023747444152832, "step": 44000}
{"episode_reward": 949.7784368722633, "episode": 45.0, "batch_reward": 0.7922811997532845, "critic_loss": 1.2383828936219214, "actor_loss": -77.80182699584961, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.73534083366394, "step": 45000}
{"episode_reward": 945.6703003677208, "episode": 46.0, "batch_reward": 0.7963695714473724, "critic_loss": 1.2717524562478066, "actor_loss": -78.46908930969238, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.79945468902588, "step": 46000}
{"episode_reward": 926.2139517461353, "episode": 47.0, "batch_reward": 0.7977313395142556, "critic_loss": 1.1730267330408097, "actor_loss": -78.9793390045166, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.54694938659668, "step": 47000}
{"episode_reward": 927.3358011963381, "episode": 48.0, "batch_reward": 0.7997357630133629, "critic_loss": 1.2250335812568665, "actor_loss": -79.08896183776855, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.910001039505005, "step": 48000}
{"episode_reward": 871.8343248469191, "episode": 49.0, "batch_reward": 0.8007393262386322, "critic_loss": 1.2887594109773637, "actor_loss": -79.41573997497558, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.283031940460205, "step": 49000}
{"episode_reward": 812.5871554715791, "episode": 50.0, "batch_reward": 0.8027357891201973, "critic_loss": 1.1455225368142128, "actor_loss": -79.90018267822266, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.06718635559082, "step": 50000}
{"episode_reward": 919.5590086470836, "episode": 51.0, "batch_reward": 0.8068709844350814, "critic_loss": 1.1415676262974739, "actor_loss": -80.06144206237794, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.73301434516907, "step": 51000}
{"episode_reward": 970.3114354007093, "episode": 52.0, "batch_reward": 0.8056155261993408, "critic_loss": 1.162560212433338, "actor_loss": -80.46042723083497, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.80846905708313, "step": 52000}
{"episode_reward": 901.2719632663267, "episode": 53.0, "batch_reward": 0.8083962687849998, "critic_loss": 1.2109025400280953, "actor_loss": -80.55756970214844, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.75742483139038, "step": 53000}
{"episode_reward": 639.5308137201881, "episode": 54.0, "batch_reward": 0.8045133341550827, "critic_loss": 1.4019303458333015, "actor_loss": -80.68601440429687, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.95014238357544, "step": 54000}
{"episode_reward": 822.5098011072304, "episode": 55.0, "batch_reward": 0.8064313416481018, "critic_loss": 1.2013413588404656, "actor_loss": -80.89197395324707, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.802542686462402, "step": 55000}
{"episode_reward": 931.8903786466858, "episode": 56.0, "batch_reward": 0.8098167846798897, "critic_loss": 1.2528076244592667, "actor_loss": -81.05142443847656, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.807678937911987, "step": 56000}
{"episode_reward": 954.2275695456302, "episode": 57.0, "batch_reward": 0.8105789110064506, "critic_loss": 1.244637694388628, "actor_loss": -81.27448750305176, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.60879373550415, "step": 57000}
{"episode_reward": 938.2017896489175, "episode": 58.0, "batch_reward": 0.8139150604605675, "critic_loss": 1.2639040045142174, "actor_loss": -81.52658085632324, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.836984395980835, "step": 58000}
{"episode_reward": 861.6264300917326, "episode": 59.0, "batch_reward": 0.8159154807329178, "critic_loss": 1.1683389840126037, "actor_loss": -81.87202500915528, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.093538522720337, "step": 59000}
{"episode_reward": 964.6044252543355, "episode": 60.0, "batch_reward": 0.8178741899728775, "critic_loss": 1.1603756253421307, "actor_loss": -82.07656817626953, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.40564775466919, "step": 60000}
{"episode_reward": 938.2654943994576, "episode": 61.0, "batch_reward": 0.8151348391771317, "critic_loss": 1.2544389317631721, "actor_loss": -82.08599462890625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.047837018966675, "step": 61000}
{"episode_reward": 644.6444060308045, "episode": 62.0, "batch_reward": 0.8156201977729798, "critic_loss": 1.2447200374007226, "actor_loss": -82.27601329040527, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.982475996017456, "step": 62000}
{"episode_reward": 971.3686492189357, "episode": 63.0, "batch_reward": 0.8185581628084183, "critic_loss": 1.2150236178040505, "actor_loss": -82.47293188476563, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.94923448562622, "step": 63000}
{"episode_reward": 972.4719068949064, "episode": 64.0, "batch_reward": 0.8221486856341362, "critic_loss": 1.2197626655697822, "actor_loss": -82.71316157531739, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.062599897384644, "step": 64000}
{"episode_reward": 935.3568078085465, "episode": 65.0, "batch_reward": 0.8227973049283027, "critic_loss": 1.2675961517095566, "actor_loss": -82.84957125854493, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.012296676635742, "step": 65000}
{"episode_reward": 879.287645063808, "episode": 66.0, "batch_reward": 0.8224864882826806, "critic_loss": 1.2377313705086708, "actor_loss": -83.00573039245606, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.040926456451416, "step": 66000}
{"episode_reward": 972.1890655213723, "episode": 67.0, "batch_reward": 0.8283424901962281, "critic_loss": 1.1883726494908333, "actor_loss": -83.30137809753418, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.9790997505188, "step": 67000}
{"episode_reward": 944.0480073730866, "episode": 68.0, "batch_reward": 0.8265752047896385, "critic_loss": 1.171403811454773, "actor_loss": -83.38392741394043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.83173155784607, "step": 68000}
{"episode_reward": 926.9813151381339, "episode": 69.0, "batch_reward": 0.8307020545005799, "critic_loss": 1.1569537673294543, "actor_loss": -83.59062921142578, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.534581184387207, "step": 69000}
{"episode_reward": 960.596408326208, "episode": 70.0, "batch_reward": 0.8308154249787331, "critic_loss": 1.2300346729755403, "actor_loss": -83.64408563232422, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.01931858062744, "step": 70000}
{"episode_reward": 830.245559541914, "episode": 71.0, "batch_reward": 0.8310886032581329, "critic_loss": 1.1315989370048045, "actor_loss": -83.70570491027831, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.87222194671631, "step": 71000}
{"episode_reward": 962.0719492567221, "episode": 72.0, "batch_reward": 0.8334511294364929, "critic_loss": 1.0911903440356254, "actor_loss": -83.86429646301269, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.623846530914307, "step": 72000}
{"episode_reward": 946.7787349386075, "episode": 73.0, "batch_reward": 0.8342422444820404, "critic_loss": 0.9788074851036072, "actor_loss": -83.98620166015625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.770172119140625, "step": 73000}
{"episode_reward": 970.4286947561878, "episode": 74.0, "batch_reward": 0.8372957680225372, "critic_loss": 1.1059947838783264, "actor_loss": -84.13894401550293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.157541275024414, "step": 74000}
{"episode_reward": 960.9028826677657, "episode": 75.0, "batch_reward": 0.8383854754567146, "critic_loss": 1.04701362657547, "actor_loss": -84.18508412170411, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.778713703155518, "step": 75000}
{"episode_reward": 955.4073300172192, "episode": 76.0, "batch_reward": 0.8405183056592941, "critic_loss": 0.9933380342721939, "actor_loss": -84.31459994506837, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.95219898223877, "step": 76000}
{"episode_reward": 919.5374120771645, "episode": 77.0, "batch_reward": 0.8420447282791138, "critic_loss": 1.0154650109410286, "actor_loss": -84.53463145446777, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.246442556381226, "step": 77000}
{"episode_reward": 969.7558759370907, "episode": 78.0, "batch_reward": 0.8396101000308991, "critic_loss": 1.0625801413059235, "actor_loss": -84.49474046325683, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.90239691734314, "step": 78000}
{"episode_reward": 852.7518523977255, "episode": 79.0, "batch_reward": 0.8408123898506165, "critic_loss": 1.1555474694669248, "actor_loss": -84.6948003540039, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.980315923690796, "step": 79000}
{"episode_reward": 889.8193646114048, "episode": 80.0, "batch_reward": 0.8441209247708321, "critic_loss": 1.1174301766455172, "actor_loss": -84.7957041015625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.07918882369995, "step": 80000}
{"episode_reward": 937.4803144868058, "episode": 81.0, "batch_reward": 0.8436856184601784, "critic_loss": 1.1657390352487564, "actor_loss": -84.90504400634765, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.51448917388916, "step": 81000}
{"episode_reward": 932.162369213165, "episode": 82.0, "batch_reward": 0.8451324607729912, "critic_loss": 1.0836600094735622, "actor_loss": -85.07888603210449, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.345620155334473, "step": 82000}
{"episode_reward": 953.6259362653474, "episode": 83.0, "batch_reward": 0.8457618975639343, "critic_loss": 1.0704388587772846, "actor_loss": -85.04624319458007, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.789652585983276, "step": 83000}
{"episode_reward": 889.7349199232752, "episode": 84.0, "batch_reward": 0.8469302211403846, "critic_loss": 1.1315308348238469, "actor_loss": -85.0563343963623, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.884361028671265, "step": 84000}
{"episode_reward": 899.3196628953297, "episode": 85.0, "batch_reward": 0.8473829012513161, "critic_loss": 1.0340643088817596, "actor_loss": -85.29070051574708, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.08919405937195, "step": 85000}
{"episode_reward": 960.5400365898075, "episode": 86.0, "batch_reward": 0.8489147698879242, "critic_loss": 1.043520212084055, "actor_loss": -85.33162315368652, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.17303466796875, "step": 86000}
{"episode_reward": 907.2757052239175, "episode": 87.0, "batch_reward": 0.8484621048569679, "critic_loss": 1.0796824316978455, "actor_loss": -85.35616795349121, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.250306367874146, "step": 87000}
{"episode_reward": 832.3551353116258, "episode": 88.0, "batch_reward": 0.8481991954445839, "critic_loss": 1.0484611565172672, "actor_loss": -85.38899081420898, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.626285791397095, "step": 88000}
{"episode_reward": 911.0099436613372, "episode": 89.0, "batch_reward": 0.8507331028580666, "critic_loss": 1.053896408289671, "actor_loss": -85.59927061462402, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.677525281906128, "step": 89000}
{"episode_reward": 957.9391527232262, "episode": 90.0, "batch_reward": 0.851119743347168, "critic_loss": 1.0523121023774147, "actor_loss": -85.68267260742188, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.92935585975647, "step": 90000}
{"episode_reward": 951.0811271651339, "episode": 91.0, "batch_reward": 0.8526645212173461, "critic_loss": 0.9871968989670277, "actor_loss": -85.74306549072266, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.78718900680542, "step": 91000}
{"episode_reward": 878.5802222876075, "episode": 92.0, "batch_reward": 0.854379636824131, "critic_loss": 1.0101146490871906, "actor_loss": -85.82588052368165, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.778574228286743, "step": 92000}
{"episode_reward": 927.0065690702385, "episode": 93.0, "batch_reward": 0.8535128617882729, "critic_loss": 1.0663464432656764, "actor_loss": -85.88310752868652, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.021491289138794, "step": 93000}
{"episode_reward": 945.88755125841, "episode": 94.0, "batch_reward": 0.8541670434474945, "critic_loss": 1.0546988880038262, "actor_loss": -85.89666223144532, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.21471929550171, "step": 94000}
{"episode_reward": 852.785438450285, "episode": 95.0, "batch_reward": 0.85355171251297, "critic_loss": 1.0544731142520904, "actor_loss": -85.97128620910645, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.604680061340332, "step": 95000}
{"episode_reward": 832.3974781023423, "episode": 96.0, "batch_reward": 0.8544217253923416, "critic_loss": 1.0382106421291828, "actor_loss": -85.83925122070312, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.067845344543457, "step": 96000}
{"episode_reward": 907.4877458971941, "episode": 97.0, "batch_reward": 0.8516513832807541, "critic_loss": 0.9865185109078884, "actor_loss": -85.92898591613769, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.140161275863647, "step": 97000}
{"episode_reward": 788.2085364878332, "episode": 98.0, "batch_reward": 0.8532555204629898, "critic_loss": 1.0582043461203574, "actor_loss": -86.02751782226562, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.027456521987915, "step": 98000}
{"episode_reward": 883.5118552772727, "episode": 99.0, "batch_reward": 0.8537499724626542, "critic_loss": 1.092381059497595, "actor_loss": -85.91555899047852, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.915598392486572, "step": 99000}
{"episode_reward": 914.5749675352112, "episode": 100.0, "batch_reward": 0.8544582980275154, "critic_loss": 1.009532190233469, "actor_loss": -85.96248602294922, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.350537538528442, "step": 100000}
{"episode_reward": 972.3428910227508, "episode": 101.0, "batch_reward": 0.8572212029099464, "critic_loss": 1.0619832692444324, "actor_loss": -86.07527412414551, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.10008645057678, "step": 101000}
{"episode_reward": 964.2677337243604, "episode": 102.0, "batch_reward": 0.8573921951651573, "critic_loss": 1.0123694616258145, "actor_loss": -86.10918641662597, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.91905903816223, "step": 102000}
{"episode_reward": 961.7241685184241, "episode": 103.0, "batch_reward": 0.8601306574940681, "critic_loss": 1.0273216182887555, "actor_loss": -86.29699752807618, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.5322687625885, "step": 103000}
{"episode_reward": 959.0624344752621, "episode": 104.0, "batch_reward": 0.8584096260666847, "critic_loss": 1.0782599999904632, "actor_loss": -86.16209400939941, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.568193197250366, "step": 104000}
{"episode_reward": 954.5040287973012, "episode": 105.0, "batch_reward": 0.8601332343220711, "critic_loss": 1.0257902885079384, "actor_loss": -86.23802233886718, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.7897789478302, "step": 105000}
{"episode_reward": 974.4923051566861, "episode": 106.0, "batch_reward": 0.8590406432151795, "critic_loss": 1.0136387957632542, "actor_loss": -86.27280181884765, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.892906188964844, "step": 106000}
{"episode_reward": 787.9708749274272, "episode": 107.0, "batch_reward": 0.8603859058022499, "critic_loss": 1.0101532447636128, "actor_loss": -86.23420169067383, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.939225435256958, "step": 107000}
{"episode_reward": 886.4975007583229, "episode": 108.0, "batch_reward": 0.8608038246035575, "critic_loss": 1.0562052570283413, "actor_loss": -86.45492021179199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.2577805519104, "step": 108000}
{"episode_reward": 924.8225681923813, "episode": 109.0, "batch_reward": 0.8615515189766884, "critic_loss": 0.9278167417943478, "actor_loss": -86.25022679138183, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.549540042877197, "step": 109000}
{"episode_reward": 943.8092365599811, "episode": 110.0, "batch_reward": 0.8615007770061492, "critic_loss": 0.9590907944738865, "actor_loss": -86.23570483398437, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.10731077194214, "step": 110000}
{"episode_reward": 945.239239276292, "episode": 111.0, "batch_reward": 0.8630231516361236, "critic_loss": 0.9934979147017002, "actor_loss": -86.5612843170166, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.850958824157715, "step": 111000}
{"episode_reward": 903.5226027360992, "episode": 112.0, "batch_reward": 0.8630146676301956, "critic_loss": 1.0104080632030963, "actor_loss": -86.20583926391602, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.553513765335083, "step": 112000}
{"episode_reward": 957.7266359721245, "episode": 113.0, "batch_reward": 0.8635517097711564, "critic_loss": 1.0059440983831882, "actor_loss": -86.48557719421386, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.772237300872803, "step": 113000}
{"episode_reward": 948.4751283269626, "episode": 114.0, "batch_reward": 0.8648568766713143, "critic_loss": 0.9580236169993878, "actor_loss": -86.47018408203125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.972049951553345, "step": 114000}
{"episode_reward": 967.3365251666191, "episode": 115.0, "batch_reward": 0.8651791446805001, "critic_loss": 1.0141099344193936, "actor_loss": -86.55949543762208, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.054141521453857, "step": 115000}
{"episode_reward": 840.1378572989809, "episode": 116.0, "batch_reward": 0.8667809152007103, "critic_loss": 0.9753930630683899, "actor_loss": -86.71426428222657, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.754242181777954, "step": 116000}
{"episode_reward": 941.6005593760831, "episode": 117.0, "batch_reward": 0.8648167533874511, "critic_loss": 0.996614103347063, "actor_loss": -86.79407794189453, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.85416555404663, "step": 117000}
{"episode_reward": 906.005912545763, "episode": 118.0, "batch_reward": 0.8653916990756989, "critic_loss": 0.9860496602356433, "actor_loss": -86.75107411193848, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.684574365615845, "step": 118000}
{"episode_reward": 959.3782477121712, "episode": 119.0, "batch_reward": 0.8684300511479378, "critic_loss": 0.9349862871170044, "actor_loss": -86.82671472167969, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.774511337280273, "step": 119000}
{"episode_reward": 963.7280858157285, "episode": 120.0, "batch_reward": 0.8682850551009178, "critic_loss": 0.9198475356400013, "actor_loss": -86.98718869018555, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.02934694290161, "step": 120000}
{"episode_reward": 957.1835231279123, "episode": 121.0, "batch_reward": 0.8693364265561104, "critic_loss": 1.027549902021885, "actor_loss": -86.87876246643066, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.553386211395264, "step": 121000}
{"episode_reward": 851.32920259677, "episode": 122.0, "batch_reward": 0.8684818459749222, "critic_loss": 0.907935122102499, "actor_loss": -86.8645432434082, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.017937421798706, "step": 122000}
{"episode_reward": 877.4896831358494, "episode": 123.0, "batch_reward": 0.8691196567416191, "critic_loss": 0.9451132721304893, "actor_loss": -86.79697534179688, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.44828748703003, "step": 123000}
{"episode_reward": 972.0101426183187, "episode": 124.0, "batch_reward": 0.8709137312173844, "critic_loss": 0.9492980018556118, "actor_loss": -86.86945776367187, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.424456357955933, "step": 124000}
{"episode_reward": 954.8206323660269, "episode": 125.0, "batch_reward": 0.8699741976261139, "critic_loss": 0.96832342299819, "actor_loss": -86.89904602050781, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.72225546836853, "step": 125000}
{"episode_reward": 963.3504526815337, "episode": 126.0, "batch_reward": 0.8720196405649185, "critic_loss": 0.942185254484415, "actor_loss": -87.05778010559082, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.940755128860474, "step": 126000}
{"episode_reward": 953.7427002431281, "episode": 127.0, "batch_reward": 0.8712682968974114, "critic_loss": 0.9521339789032937, "actor_loss": -86.73879187011718, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.127325773239136, "step": 127000}
{"episode_reward": 941.3360817946187, "episode": 128.0, "batch_reward": 0.8714754475951195, "critic_loss": 0.8937192735373973, "actor_loss": -87.00279905700684, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.112905502319336, "step": 128000}
{"episode_reward": 950.1126843829011, "episode": 129.0, "batch_reward": 0.8719807385206223, "critic_loss": 0.9319117899239063, "actor_loss": -87.09984228515626, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.644253969192505, "step": 129000}
{"episode_reward": 940.9128083270805, "episode": 130.0, "batch_reward": 0.8736894566416741, "critic_loss": 0.9159623809158802, "actor_loss": -87.19318823242187, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.739707469940186, "step": 130000}
{"episode_reward": 784.7981141472919, "episode": 131.0, "batch_reward": 0.8728755071163178, "critic_loss": 0.9944554794728756, "actor_loss": -87.01437188720703, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.543264627456665, "step": 131000}
{"episode_reward": 934.0180170576247, "episode": 132.0, "batch_reward": 0.8724044665694237, "critic_loss": 0.9868602973520756, "actor_loss": -86.98346188354492, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.68138599395752, "step": 132000}
{"episode_reward": 940.9079864423762, "episode": 133.0, "batch_reward": 0.8739807658195495, "critic_loss": 0.8922176790237427, "actor_loss": -87.24837229919433, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.81427526473999, "step": 133000}
{"episode_reward": 963.350565781622, "episode": 134.0, "batch_reward": 0.8744908611774445, "critic_loss": 0.9381108613610267, "actor_loss": -87.35620114135742, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.08780789375305, "step": 134000}
{"episode_reward": 941.4737872096779, "episode": 135.0, "batch_reward": 0.8750887579917908, "critic_loss": 0.9651828726828098, "actor_loss": -87.14653440856934, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.944327354431152, "step": 135000}
{"episode_reward": 928.4978866432684, "episode": 136.0, "batch_reward": 0.8755415560603141, "critic_loss": 0.9145671381354332, "actor_loss": -87.56933505249023, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.788858890533447, "step": 136000}
{"episode_reward": 960.0883241761438, "episode": 137.0, "batch_reward": 0.8752016946077347, "critic_loss": 0.980829161375761, "actor_loss": -87.26814985656738, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.923185110092163, "step": 137000}
{"episode_reward": 967.1982446215068, "episode": 138.0, "batch_reward": 0.8780033887624741, "critic_loss": 0.9962524948120117, "actor_loss": -87.34928343200684, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.286505699157715, "step": 138000}
{"episode_reward": 955.7195430503559, "episode": 139.0, "batch_reward": 0.877720826625824, "critic_loss": 1.0113041385412216, "actor_loss": -87.43810066223145, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.32140278816223, "step": 139000}
{"episode_reward": 892.9754121335529, "episode": 140.0, "batch_reward": 0.8788025832176208, "critic_loss": 0.9146842704117298, "actor_loss": -87.36510104370117, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.938851356506348, "step": 140000}
{"episode_reward": 965.885509757041, "episode": 141.0, "batch_reward": 0.8753293653130532, "critic_loss": 0.9672774511575699, "actor_loss": -87.18807975769043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.67903685569763, "step": 141000}
{"episode_reward": 847.3215757944141, "episode": 142.0, "batch_reward": 0.8770532934069634, "critic_loss": 0.9922728844583034, "actor_loss": -87.38327688598633, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.57595205307007, "step": 142000}
{"episode_reward": 932.1322566898666, "episode": 143.0, "batch_reward": 0.8771666868329048, "critic_loss": 0.9339143330156803, "actor_loss": -87.46438385009766, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.79632067680359, "step": 143000}
{"episode_reward": 929.0489352402834, "episode": 144.0, "batch_reward": 0.8788827245235443, "critic_loss": 0.967280635535717, "actor_loss": -87.45867761230468, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.979456901550293, "step": 144000}
{"episode_reward": 920.5581949875386, "episode": 145.0, "batch_reward": 0.8796428843140602, "critic_loss": 0.9899145880639553, "actor_loss": -87.4050079345703, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.61489725112915, "step": 145000}
{"episode_reward": 885.1857283480551, "episode": 146.0, "batch_reward": 0.8788888064026833, "critic_loss": 0.9590074761509896, "actor_loss": -87.35775120544433, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.392609119415283, "step": 146000}
{"episode_reward": 944.0516369609709, "episode": 147.0, "batch_reward": 0.8794044993519783, "critic_loss": 0.9236570260822773, "actor_loss": -87.5198955078125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.882818460464478, "step": 147000}
{"episode_reward": 939.7146261750593, "episode": 148.0, "batch_reward": 0.8775495757460594, "critic_loss": 0.9538664318919182, "actor_loss": -87.43355027770995, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.958125591278076, "step": 148000}
{"episode_reward": 836.4903507145648, "episode": 149.0, "batch_reward": 0.8790760093331337, "critic_loss": 0.9553466747999191, "actor_loss": -87.4584051208496, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.293540239334106, "step": 149000}
{"episode_reward": 942.530399976565, "episode": 150.0, "batch_reward": 0.8796561791300773, "critic_loss": 0.988844897955656, "actor_loss": -87.30594374084473, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
