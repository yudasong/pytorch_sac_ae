{"episode_reward": 0.0, "episode": 1.0, "duration": 20.765748500823975, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.8002119064331055, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.3138328828029372, "critic_loss": 0.6180609839186744, "actor_loss": -73.75040471816168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.27122354507446, "step": 3000}
{"episode_reward": 690.9218863453336, "episode": 4.0, "batch_reward": 0.4512792057693005, "critic_loss": 0.684319385111332, "actor_loss": -81.84906698608398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.454885244369507, "step": 4000}
{"episode_reward": 759.9666091842028, "episode": 5.0, "batch_reward": 0.5327313386201858, "critic_loss": 0.5510521864295006, "actor_loss": -83.39812841796875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.407974004745483, "step": 5000}
{"episode_reward": 680.7796123757474, "episode": 6.0, "batch_reward": 0.5644995076060295, "critic_loss": 0.5297021874785424, "actor_loss": -84.55592958068847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.429166793823242, "step": 6000}
{"episode_reward": 818.7729459050163, "episode": 7.0, "batch_reward": 0.5433613467514515, "critic_loss": 0.46056836253404615, "actor_loss": -84.64121270751953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.462592601776123, "step": 7000}
{"episode_reward": 31.406646106775604, "episode": 8.0, "batch_reward": 0.5317220919132233, "critic_loss": 0.39368989028036594, "actor_loss": -83.66040534973145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39613389968872, "step": 8000}
{"episode_reward": 929.8883742380265, "episode": 9.0, "batch_reward": 0.5789443791806698, "critic_loss": 0.3743172201067209, "actor_loss": -84.61862454223633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.412779331207275, "step": 9000}
{"episode_reward": 857.550166865636, "episode": 10.0, "batch_reward": 0.6041305282711983, "critic_loss": 0.42132695254683494, "actor_loss": -85.23775082397461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.398218631744385, "step": 10000}
{"episode_reward": 796.7107150026253, "episode": 11.0, "batch_reward": 0.6234859198927879, "critic_loss": 0.47264512738585474, "actor_loss": -86.05657888793945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.954484701156616, "step": 11000}
{"episode_reward": 830.4910528214373, "episode": 12.0, "batch_reward": 0.6404771347045899, "critic_loss": 0.476456032037735, "actor_loss": -85.72892655944824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.385459661483765, "step": 12000}
{"episode_reward": 908.2738701160484, "episode": 13.0, "batch_reward": 0.6634436231851578, "critic_loss": 0.4432589817941189, "actor_loss": -86.20831632995605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.399101495742798, "step": 13000}
{"episode_reward": 920.8851817158729, "episode": 14.0, "batch_reward": 0.6835536144971848, "critic_loss": 0.4196505465209484, "actor_loss": -86.50271667480469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.418848037719727, "step": 14000}
{"episode_reward": 910.3342302356583, "episode": 15.0, "batch_reward": 0.7000803193449974, "critic_loss": 0.40841602550446987, "actor_loss": -86.9019144744873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.414634704589844, "step": 15000}
{"episode_reward": 947.0249380233778, "episode": 16.0, "batch_reward": 0.7172844035625457, "critic_loss": 0.3701594249457121, "actor_loss": -86.76665490722657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.425368785858154, "step": 16000}
{"episode_reward": 955.272775759633, "episode": 17.0, "batch_reward": 0.7288846223354339, "critic_loss": 0.42074747575819493, "actor_loss": -86.78978799438477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.41743564605713, "step": 17000}
{"episode_reward": 902.5062229162812, "episode": 18.0, "batch_reward": 0.7393413891196251, "critic_loss": 0.4020729017704725, "actor_loss": -87.21029319763184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.42124891281128, "step": 18000}
{"episode_reward": 865.3132176380111, "episode": 19.0, "batch_reward": 0.7458643552064895, "critic_loss": 0.3958033512532711, "actor_loss": -87.28188096618652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.441598892211914, "step": 19000}
{"episode_reward": 929.5933420119051, "episode": 20.0, "batch_reward": 0.7537045675516129, "critic_loss": 0.4290897249430418, "actor_loss": -87.57338011169433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.41122531890869, "step": 20000}
{"episode_reward": 867.507325664702, "episode": 21.0, "batch_reward": 0.7629865918159485, "critic_loss": 0.3956170669347048, "actor_loss": -87.5205284576416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.819711446762085, "step": 21000}
{"episode_reward": 964.5210206279272, "episode": 22.0, "batch_reward": 0.7686177443265915, "critic_loss": 0.4343219123184681, "actor_loss": -87.92226550292969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.4007670879364, "step": 22000}
{"episode_reward": 864.8475664519798, "episode": 23.0, "batch_reward": 0.7741507839560509, "critic_loss": 0.4036532856822014, "actor_loss": -88.03816915893555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.411409616470337, "step": 23000}
{"episode_reward": 925.006455021417, "episode": 24.0, "batch_reward": 0.7757640758156776, "critic_loss": 0.40176332235336304, "actor_loss": -88.06711296081544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.428452253341675, "step": 24000}
{"episode_reward": 820.4744403862204, "episode": 25.0, "batch_reward": 0.7810471134781838, "critic_loss": 0.4012535600364208, "actor_loss": -88.2616802368164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38936710357666, "step": 25000}
{"episode_reward": 900.2541103817097, "episode": 26.0, "batch_reward": 0.786317747592926, "critic_loss": 0.4339597002863884, "actor_loss": -88.38962594604492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39045524597168, "step": 26000}
{"episode_reward": 771.888569337182, "episode": 27.0, "batch_reward": 0.7882191841602325, "critic_loss": 0.42216458705067633, "actor_loss": -88.66695895385742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.394219875335693, "step": 27000}
{"episode_reward": 927.1310654261086, "episode": 28.0, "batch_reward": 0.790977443099022, "critic_loss": 0.4022940454632044, "actor_loss": -88.43063333129882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.439637184143066, "step": 28000}
{"episode_reward": 892.2847481746934, "episode": 29.0, "batch_reward": 0.7980422012209892, "critic_loss": 0.3932084072679281, "actor_loss": -88.99311143493652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39970636367798, "step": 29000}
{"episode_reward": 981.8116562180345, "episode": 30.0, "batch_reward": 0.7998123637437821, "critic_loss": 0.4251530457288027, "actor_loss": -88.96330867004394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.40436840057373, "step": 30000}
{"episode_reward": 887.0529211883313, "episode": 31.0, "batch_reward": 0.8046587184071541, "critic_loss": 0.412137017801404, "actor_loss": -89.04630349731445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.85361409187317, "step": 31000}
{"episode_reward": 947.8436978516561, "episode": 32.0, "batch_reward": 0.809031695663929, "critic_loss": 0.3855245610922575, "actor_loss": -89.34325755310059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.401063203811646, "step": 32000}
{"episode_reward": 929.877048804276, "episode": 33.0, "batch_reward": 0.8112706647515296, "critic_loss": 0.409431704595685, "actor_loss": -89.34443901062012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.40737223625183, "step": 33000}
{"episode_reward": 886.6814017322507, "episode": 34.0, "batch_reward": 0.8153556727766991, "critic_loss": 0.4268896263986826, "actor_loss": -89.49753645324706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.437188625335693, "step": 34000}
{"episode_reward": 864.6349215294986, "episode": 35.0, "batch_reward": 0.8137534157633781, "critic_loss": 0.46248404878377913, "actor_loss": -89.61518046569824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.425636053085327, "step": 35000}
{"episode_reward": 835.2926095398487, "episode": 36.0, "batch_reward": 0.8178920691013336, "critic_loss": 0.42434692034125326, "actor_loss": -89.58347219848633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.42523193359375, "step": 36000}
{"episode_reward": 955.4521007725292, "episode": 37.0, "batch_reward": 0.8227773925065994, "critic_loss": 0.41300120696425435, "actor_loss": -89.63593452453614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.433071613311768, "step": 37000}
{"episode_reward": 951.9722306486066, "episode": 38.0, "batch_reward": 0.8253669822812081, "critic_loss": 0.40208285078406336, "actor_loss": -90.17248867797852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.430453300476074, "step": 38000}
{"episode_reward": 974.9211343966729, "episode": 39.0, "batch_reward": 0.8288142374157905, "critic_loss": 0.3956463843137026, "actor_loss": -90.10764303588867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38591694831848, "step": 39000}
{"episode_reward": 950.1414621314499, "episode": 40.0, "batch_reward": 0.8315699731111527, "critic_loss": 0.40556194211542607, "actor_loss": -90.19034645080566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.408520936965942, "step": 40000}
{"episode_reward": 887.9361385641989, "episode": 41.0, "batch_reward": 0.8284552407860756, "critic_loss": 0.39957906380295755, "actor_loss": -90.11635035705567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.88046336174011, "step": 41000}
{"episode_reward": 755.0304171429976, "episode": 42.0, "batch_reward": 0.8302743351459503, "critic_loss": 0.4006373589485884, "actor_loss": -90.26097927856445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.42362689971924, "step": 42000}
{"episode_reward": 950.1995646794569, "episode": 43.0, "batch_reward": 0.8342848114967346, "critic_loss": 0.4213838192075491, "actor_loss": -90.63239465332032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.428617477416992, "step": 43000}
{"episode_reward": 915.3359625309308, "episode": 44.0, "batch_reward": 0.834775523006916, "critic_loss": 0.43529203259944915, "actor_loss": -90.53506118774413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.397905588150024, "step": 44000}
{"episode_reward": 870.5219050358447, "episode": 45.0, "batch_reward": 0.8363466067910195, "critic_loss": 0.4535351122766733, "actor_loss": -90.76589207458495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.417599201202393, "step": 45000}
{"episode_reward": 964.0828916612194, "episode": 46.0, "batch_reward": 0.8409158371686936, "critic_loss": 0.37691919319331646, "actor_loss": -90.75283354187012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.428636074066162, "step": 46000}
{"episode_reward": 947.9286928012452, "episode": 47.0, "batch_reward": 0.8421813127398491, "critic_loss": 0.40657405540347097, "actor_loss": -90.69626225280761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.427860498428345, "step": 47000}
{"episode_reward": 955.9801947117713, "episode": 48.0, "batch_reward": 0.8439195711612701, "critic_loss": 0.3955067764222622, "actor_loss": -91.25239129638672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.446178436279297, "step": 48000}
{"episode_reward": 921.960712352347, "episode": 49.0, "batch_reward": 0.8458685069680214, "critic_loss": 0.4103313916474581, "actor_loss": -91.24095210266113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.398388624191284, "step": 49000}
{"episode_reward": 939.4548562321977, "episode": 50.0, "batch_reward": 0.8471727136969567, "critic_loss": 0.3821970385611057, "actor_loss": -91.16822834777832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.418421983718872, "step": 50000}
{"episode_reward": 923.3972336875865, "episode": 51.0, "batch_reward": 0.8508948709368706, "critic_loss": 0.3687402612864971, "actor_loss": -91.68659300231934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.886075019836426, "step": 51000}
{"episode_reward": 972.3497694781641, "episode": 52.0, "batch_reward": 0.8498918211460114, "critic_loss": 0.3900115847587585, "actor_loss": -91.39156887817383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.434582233428955, "step": 52000}
{"episode_reward": 907.7712719214232, "episode": 53.0, "batch_reward": 0.852645058810711, "critic_loss": 0.40584257735311985, "actor_loss": -91.75657232666016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.410780906677246, "step": 53000}
{"episode_reward": 944.3906855871239, "episode": 54.0, "batch_reward": 0.854069742500782, "critic_loss": 0.40095507365465166, "actor_loss": -91.70709782409668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.385666608810425, "step": 54000}
{"episode_reward": 911.9827958818327, "episode": 55.0, "batch_reward": 0.8554430466890335, "critic_loss": 0.37645979404449464, "actor_loss": -91.68737097167968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.389342546463013, "step": 55000}
{"episode_reward": 954.408157267025, "episode": 56.0, "batch_reward": 0.8592233964204788, "critic_loss": 0.3570471466034651, "actor_loss": -92.08488468933105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.398289918899536, "step": 56000}
{"episode_reward": 975.6376763053714, "episode": 57.0, "batch_reward": 0.8587283412814141, "critic_loss": 0.39202487279474735, "actor_loss": -91.91400564575196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.411229610443115, "step": 57000}
{"episode_reward": 903.945612024197, "episode": 58.0, "batch_reward": 0.860274345099926, "critic_loss": 0.3499613895565271, "actor_loss": -92.21621394348145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.427215814590454, "step": 58000}
{"episode_reward": 950.9912552333731, "episode": 59.0, "batch_reward": 0.8627934858202935, "critic_loss": 0.33953900964558126, "actor_loss": -92.15555331420899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.4287371635437, "step": 59000}
{"episode_reward": 987.2974742100386, "episode": 60.0, "batch_reward": 0.862573277592659, "critic_loss": 0.3632942489683628, "actor_loss": -92.05492218017578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.428861618041992, "step": 60000}
{"episode_reward": 871.4115179097297, "episode": 61.0, "batch_reward": 0.8639042603969574, "critic_loss": 0.3705717281550169, "actor_loss": -92.13140887451172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.86308479309082, "step": 61000}
{"episode_reward": 916.804443330642, "episode": 62.0, "batch_reward": 0.8642687713503837, "critic_loss": 0.34779966486990455, "actor_loss": -92.33814582824706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.4334819316864, "step": 62000}
{"episode_reward": 980.7917988817698, "episode": 63.0, "batch_reward": 0.8659349172115326, "critic_loss": 0.3297521368637681, "actor_loss": -92.29501986694336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.416465044021606, "step": 63000}
{"episode_reward": 986.6809365995862, "episode": 64.0, "batch_reward": 0.8694985120892524, "critic_loss": 0.3299597534686327, "actor_loss": -92.24628416442872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38787865638733, "step": 64000}
{"episode_reward": 947.7159189105541, "episode": 65.0, "batch_reward": 0.868507938861847, "critic_loss": 0.384702033162117, "actor_loss": -92.49644619750977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.404014587402344, "step": 65000}
{"episode_reward": 849.0217113099532, "episode": 66.0, "batch_reward": 0.8691006595492363, "critic_loss": 0.36793911381065847, "actor_loss": -92.20849394226074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.404849767684937, "step": 66000}
{"episode_reward": 975.046543227299, "episode": 67.0, "batch_reward": 0.8722380524873734, "critic_loss": 0.34640642470121386, "actor_loss": -92.45662104797363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.4014093875885, "step": 67000}
{"episode_reward": 944.1479868396693, "episode": 68.0, "batch_reward": 0.8707782200574875, "critic_loss": 0.35661507335305215, "actor_loss": -92.42012574768066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.413230895996094, "step": 68000}
{"episode_reward": 906.2215438578825, "episode": 69.0, "batch_reward": 0.8727223823070526, "critic_loss": 0.3759999106526375, "actor_loss": -92.34321955871582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.413988828659058, "step": 69000}
{"episode_reward": 972.2632293854566, "episode": 70.0, "batch_reward": 0.8744965224266052, "critic_loss": 0.35261129888892173, "actor_loss": -92.55242457580566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.42825698852539, "step": 70000}
{"episode_reward": 919.0562991366588, "episode": 71.0, "batch_reward": 0.8759240409135819, "critic_loss": 0.31794092197716234, "actor_loss": -92.54217153930664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.94330716133118, "step": 71000}
{"episode_reward": 960.2995874515134, "episode": 72.0, "batch_reward": 0.8768405721187592, "critic_loss": 0.3592488384693861, "actor_loss": -92.53999359130859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.429951667785645, "step": 72000}
{"episode_reward": 948.4598792713125, "episode": 73.0, "batch_reward": 0.877922834455967, "critic_loss": 0.34382121923565867, "actor_loss": -92.38191571044922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.43172812461853, "step": 73000}
{"episode_reward": 984.4250799228572, "episode": 74.0, "batch_reward": 0.8784745357632637, "critic_loss": 0.3491472700387239, "actor_loss": -92.65794798278809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.435423612594604, "step": 74000}
{"episode_reward": 950.8413759409463, "episode": 75.0, "batch_reward": 0.8802637537121772, "critic_loss": 0.34869505354762076, "actor_loss": -92.54487380981445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.426481008529663, "step": 75000}
{"episode_reward": 952.0116791904575, "episode": 76.0, "batch_reward": 0.8803991206288337, "critic_loss": 0.35955538700520995, "actor_loss": -92.36429725646973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39894437789917, "step": 76000}
{"episode_reward": 938.1303017148416, "episode": 77.0, "batch_reward": 0.8821174239516258, "critic_loss": 0.3463118412792683, "actor_loss": -92.55350688171387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.42229413986206, "step": 77000}
{"episode_reward": 984.3522095977233, "episode": 78.0, "batch_reward": 0.882410276055336, "critic_loss": 0.335984741717577, "actor_loss": -92.84520396423339, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.442196130752563, "step": 78000}
{"episode_reward": 946.0261075134113, "episode": 79.0, "batch_reward": 0.8834546995759011, "critic_loss": 0.33714321988075974, "actor_loss": -92.90466217041016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.453372955322266, "step": 79000}
{"episode_reward": 947.3848107948194, "episode": 80.0, "batch_reward": 0.8849849572777748, "critic_loss": 0.3338087038546801, "actor_loss": -92.5721150817871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.452102661132812, "step": 80000}
{"episode_reward": 951.7632103252321, "episode": 81.0, "batch_reward": 0.8837339313030242, "critic_loss": 0.3320549032688141, "actor_loss": -92.58248736572266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.897746562957764, "step": 81000}
{"episode_reward": 946.2757457573808, "episode": 82.0, "batch_reward": 0.8843633618950844, "critic_loss": 0.32988719310611486, "actor_loss": -92.76806300354004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.409645795822144, "step": 82000}
{"episode_reward": 959.3509023823702, "episode": 83.0, "batch_reward": 0.8856690565347671, "critic_loss": 0.3182753288075328, "actor_loss": -92.40748960876465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.424211978912354, "step": 83000}
{"episode_reward": 946.7454952087016, "episode": 84.0, "batch_reward": 0.8870135545730591, "critic_loss": 0.33280323588848115, "actor_loss": -92.69438471984863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.415804624557495, "step": 84000}
{"episode_reward": 906.7704921884223, "episode": 85.0, "batch_reward": 0.8863721496462822, "critic_loss": 0.3461322919726372, "actor_loss": -92.71706974792481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.43450689315796, "step": 85000}
{"episode_reward": 946.602164741574, "episode": 86.0, "batch_reward": 0.8875725014805794, "critic_loss": 0.3350483644902706, "actor_loss": -92.45218601989747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.430739402770996, "step": 86000}
{"episode_reward": 954.6963803762172, "episode": 87.0, "batch_reward": 0.8892709082365036, "critic_loss": 0.32127914065122604, "actor_loss": -92.75307164001465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.432617664337158, "step": 87000}
{"episode_reward": 948.0551545559036, "episode": 88.0, "batch_reward": 0.8892262579202652, "critic_loss": 0.3277673300206661, "actor_loss": -92.55151432800292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.43061923980713, "step": 88000}
{"episode_reward": 983.5052119887268, "episode": 89.0, "batch_reward": 0.8908184725642204, "critic_loss": 0.32405905524641276, "actor_loss": -92.95228346252442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.450050830841064, "step": 89000}
{"episode_reward": 974.0695711134591, "episode": 90.0, "batch_reward": 0.8919253134131432, "critic_loss": 0.3159398029893637, "actor_loss": -93.25765762329101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.453193426132202, "step": 90000}
{"episode_reward": 983.6588151113823, "episode": 91.0, "batch_reward": 0.8922998932600021, "critic_loss": 0.3386546888798475, "actor_loss": -92.93374055480957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.877143144607544, "step": 91000}
{"episode_reward": 908.2982516778238, "episode": 92.0, "batch_reward": 0.8936613338589668, "critic_loss": 0.31580712962150576, "actor_loss": -92.91492602539063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.423587799072266, "step": 92000}
{"episode_reward": 977.2750106193861, "episode": 93.0, "batch_reward": 0.894559480369091, "critic_loss": 0.3192593960314989, "actor_loss": -93.1062986907959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.431748151779175, "step": 93000}
{"episode_reward": 985.7775764003675, "episode": 94.0, "batch_reward": 0.8962241224050522, "critic_loss": 0.3154621346741915, "actor_loss": -93.0221188659668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.405837774276733, "step": 94000}
{"episode_reward": 951.3489099926089, "episode": 95.0, "batch_reward": 0.8945879057049752, "critic_loss": 0.29873069959878923, "actor_loss": -93.35885845947266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.434210062026978, "step": 95000}
{"episode_reward": 964.9257131414812, "episode": 96.0, "batch_reward": 0.894717769742012, "critic_loss": 0.31317035100609064, "actor_loss": -92.52950619506836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.42306923866272, "step": 96000}
{"episode_reward": 850.81188797667, "episode": 97.0, "batch_reward": 0.8952375120520591, "critic_loss": 0.33147433912009, "actor_loss": -92.8471778717041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.429603338241577, "step": 97000}
{"episode_reward": 924.7118924660696, "episode": 98.0, "batch_reward": 0.894756511092186, "critic_loss": 0.3371888233423233, "actor_loss": -93.23543794250489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.438507080078125, "step": 98000}
{"episode_reward": 865.8645574933098, "episode": 99.0, "batch_reward": 0.8946714552640915, "critic_loss": 0.34469350238889457, "actor_loss": -92.51490837097168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.375006198883057, "step": 99000}
{"episode_reward": 905.4883868789296, "episode": 100.0, "batch_reward": 0.8947322915792465, "critic_loss": 0.3672268359363079, "actor_loss": -92.72204042053222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.725228548049927, "step": 100000}
{"episode_reward": 986.567082939976, "episode": 101.0, "batch_reward": 0.8978368122577667, "critic_loss": 0.33075537654012444, "actor_loss": -92.3919139251709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.84566044807434, "step": 101000}
{"episode_reward": 975.4414137807887, "episode": 102.0, "batch_reward": 0.8978884534835816, "critic_loss": 0.3321709662526846, "actor_loss": -92.79281758117676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.4102942943573, "step": 102000}
{"episode_reward": 969.9500278319796, "episode": 103.0, "batch_reward": 0.8984299213886261, "critic_loss": 0.3465098230093718, "actor_loss": -93.01925770568847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.421956539154053, "step": 103000}
{"episode_reward": 960.5066818434016, "episode": 104.0, "batch_reward": 0.8991574526429177, "critic_loss": 0.34577292019128797, "actor_loss": -92.79593902587891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.398069143295288, "step": 104000}
{"episode_reward": 933.6628043779597, "episode": 105.0, "batch_reward": 0.8987010071873665, "critic_loss": 0.3561724430769682, "actor_loss": -92.73455487060546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.440088510513306, "step": 105000}
{"episode_reward": 962.3925914584025, "episode": 106.0, "batch_reward": 0.8985374317169189, "critic_loss": 0.3442081585302949, "actor_loss": -92.6919115600586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.428950786590576, "step": 106000}
{"episode_reward": 926.0081498325707, "episode": 107.0, "batch_reward": 0.899654735326767, "critic_loss": 0.33586922762542964, "actor_loss": -92.73411195373535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.437255144119263, "step": 107000}
{"episode_reward": 931.9547484285639, "episode": 108.0, "batch_reward": 0.8995387616753578, "critic_loss": 0.35328110168874266, "actor_loss": -93.10753735351562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.41794228553772, "step": 108000}
{"episode_reward": 945.0853128971689, "episode": 109.0, "batch_reward": 0.899878302514553, "critic_loss": 0.33067034804075957, "actor_loss": -93.04511422729492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.561872959136963, "step": 109000}
{"episode_reward": 954.3575806001609, "episode": 110.0, "batch_reward": 0.9013523225188256, "critic_loss": 0.34275628518313167, "actor_loss": -92.96896495056153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.608469247817993, "step": 110000}
{"episode_reward": 919.9878496154261, "episode": 111.0, "batch_reward": 0.9009219492077828, "critic_loss": 0.320224279537797, "actor_loss": -93.30729064941406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.90045142173767, "step": 111000}
{"episode_reward": 952.9245516220766, "episode": 112.0, "batch_reward": 0.9020473620295525, "critic_loss": 0.3386502619683743, "actor_loss": -92.79148257446289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.43407917022705, "step": 112000}
{"episode_reward": 921.7207546246856, "episode": 113.0, "batch_reward": 0.9028581932187081, "critic_loss": 0.34069179648905995, "actor_loss": -93.05434371948242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.42274045944214, "step": 113000}
{"episode_reward": 971.8475517583272, "episode": 114.0, "batch_reward": 0.9020595150589943, "critic_loss": 0.31897661377489567, "actor_loss": -92.8666064453125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.43253803253174, "step": 114000}
{"episode_reward": 978.7260016767572, "episode": 115.0, "batch_reward": 0.9019106897711754, "critic_loss": 0.3094541544541717, "actor_loss": -92.93234288024902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.417144775390625, "step": 115000}
{"episode_reward": 931.7087147817431, "episode": 116.0, "batch_reward": 0.9042455382943153, "critic_loss": 0.31744703504443167, "actor_loss": -93.15068106079102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.444542407989502, "step": 116000}
{"episode_reward": 880.0779911908297, "episode": 117.0, "batch_reward": 0.9013019164800644, "critic_loss": 0.3357851119041443, "actor_loss": -93.14183879089356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.43664526939392, "step": 117000}
{"episode_reward": 901.6962357913098, "episode": 118.0, "batch_reward": 0.9025217965841293, "critic_loss": 0.326040594317019, "actor_loss": -93.01142706298828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.448620796203613, "step": 118000}
{"episode_reward": 953.4639061273863, "episode": 119.0, "batch_reward": 0.904809671998024, "critic_loss": 0.3360053522586823, "actor_loss": -93.18702813720704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.422438621520996, "step": 119000}
{"episode_reward": 966.6071054140916, "episode": 120.0, "batch_reward": 0.9045265909433365, "critic_loss": 0.33331208835542203, "actor_loss": -93.37333935546874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.41748070716858, "step": 120000}
{"episode_reward": 968.3630111357555, "episode": 121.0, "batch_reward": 0.9041056109070778, "critic_loss": 0.3519515191912651, "actor_loss": -93.15530337524415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.87229347229004, "step": 121000}
{"episode_reward": 899.5423353887262, "episode": 122.0, "batch_reward": 0.904756729900837, "critic_loss": 0.35838535137474536, "actor_loss": -93.34002217102051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.420880794525146, "step": 122000}
{"episode_reward": 950.25172812088, "episode": 123.0, "batch_reward": 0.9047987643480301, "critic_loss": 0.3735465679988265, "actor_loss": -93.17219232177735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.44439935684204, "step": 123000}
{"episode_reward": 974.1351742379845, "episode": 124.0, "batch_reward": 0.906670438349247, "critic_loss": 0.3638685879856348, "actor_loss": -92.9638049621582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.422561168670654, "step": 124000}
{"episode_reward": 965.408021037228, "episode": 125.0, "batch_reward": 0.9061450076699257, "critic_loss": 0.3544843849912286, "actor_loss": -93.07708509826661, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.443171739578247, "step": 125000}
{"episode_reward": 956.6443922062535, "episode": 126.0, "batch_reward": 0.9069392172694206, "critic_loss": 0.34600194688141345, "actor_loss": -93.35531831359863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.43312692642212, "step": 126000}
{"episode_reward": 966.2671732329125, "episode": 127.0, "batch_reward": 0.9060208634734154, "critic_loss": 0.3386186953559518, "actor_loss": -92.97330177307128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.444451093673706, "step": 127000}
{"episode_reward": 955.6928694920691, "episode": 128.0, "batch_reward": 0.906718381524086, "critic_loss": 0.33842116267979144, "actor_loss": -93.09711376953125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.448687076568604, "step": 128000}
{"episode_reward": 950.1379710514353, "episode": 129.0, "batch_reward": 0.9063628642559052, "critic_loss": 0.312845959469676, "actor_loss": -93.32883164978027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.44132375717163, "step": 129000}
{"episode_reward": 975.7923177409897, "episode": 130.0, "batch_reward": 0.9097341278791428, "critic_loss": 0.3303174164220691, "actor_loss": -93.42133522033691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.446345329284668, "step": 130000}
{"episode_reward": 918.8029149031104, "episode": 131.0, "batch_reward": 0.9082787750959397, "critic_loss": 0.33995310555398467, "actor_loss": -93.29734692382813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.93934464454651, "step": 131000}
{"episode_reward": 947.3948946303797, "episode": 132.0, "batch_reward": 0.9070511056780816, "critic_loss": 0.32670748749375345, "actor_loss": -93.36332817077637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.407794952392578, "step": 132000}
{"episode_reward": 898.041260177222, "episode": 133.0, "batch_reward": 0.9085974197983742, "critic_loss": 0.33565249671041963, "actor_loss": -93.67356663513183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.431039094924927, "step": 133000}
{"episode_reward": 974.6875244190377, "episode": 134.0, "batch_reward": 0.9090007802248001, "critic_loss": 0.34103107384592296, "actor_loss": -93.49418086242676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.441936492919922, "step": 134000}
{"episode_reward": 934.1664394162859, "episode": 135.0, "batch_reward": 0.909866355419159, "critic_loss": 0.33979495172947644, "actor_loss": -93.20937701416015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.43486499786377, "step": 135000}
{"episode_reward": 955.0800655560203, "episode": 136.0, "batch_reward": 0.910132250726223, "critic_loss": 0.3216989517137408, "actor_loss": -93.69283079528809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51450514793396, "step": 136000}
{"episode_reward": 963.3855416516469, "episode": 137.0, "batch_reward": 0.9088629055023193, "critic_loss": 0.33403601915389297, "actor_loss": -93.40099401855468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.67201256752014, "step": 137000}
{"episode_reward": 978.8173998469679, "episode": 138.0, "batch_reward": 0.911627501487732, "critic_loss": 0.3308847758322954, "actor_loss": -93.24732759094238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.40226697921753, "step": 138000}
{"episode_reward": 968.995867793341, "episode": 139.0, "batch_reward": 0.9099377065300941, "critic_loss": 0.3153388178795576, "actor_loss": -93.89369500732423, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.379991054534912, "step": 139000}
{"episode_reward": 951.6329948035125, "episode": 140.0, "batch_reward": 0.9125542695522308, "critic_loss": 0.29369800071418284, "actor_loss": -93.503840133667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.394347429275513, "step": 140000}
{"episode_reward": 981.2496640434647, "episode": 141.0, "batch_reward": 0.9108242934942246, "critic_loss": 0.31328932573646306, "actor_loss": -93.16534461975098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.88354158401489, "step": 141000}
{"episode_reward": 955.7829357185109, "episode": 142.0, "batch_reward": 0.9112058311104775, "critic_loss": 0.29932459588348864, "actor_loss": -93.62585101318359, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.432255268096924, "step": 142000}
{"episode_reward": 950.3357304158088, "episode": 143.0, "batch_reward": 0.911828322827816, "critic_loss": 0.2987432364523411, "actor_loss": -93.70316358947754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.419541120529175, "step": 143000}
{"episode_reward": 966.2566711482897, "episode": 144.0, "batch_reward": 0.9129635419249534, "critic_loss": 0.28777419114112857, "actor_loss": -93.61306553649902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.442442893981934, "step": 144000}
{"episode_reward": 922.9013971483967, "episode": 145.0, "batch_reward": 0.9122042607069015, "critic_loss": 0.3360796594321728, "actor_loss": -93.36507849121094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.42733669281006, "step": 145000}
{"episode_reward": 861.6853942794162, "episode": 146.0, "batch_reward": 0.9127569599747658, "critic_loss": 0.32540250330418347, "actor_loss": -93.24845652770996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.42774748802185, "step": 146000}
{"episode_reward": 980.6577539167604, "episode": 147.0, "batch_reward": 0.9131786899566651, "critic_loss": 0.3056678743213415, "actor_loss": -93.48895266723633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.436679124832153, "step": 147000}
{"episode_reward": 944.0127345685294, "episode": 148.0, "batch_reward": 0.9123207415342331, "critic_loss": 0.3189064877256751, "actor_loss": -93.45956622314453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.429721355438232, "step": 148000}
{"episode_reward": 953.2614686746074, "episode": 149.0, "batch_reward": 0.9132644929289818, "critic_loss": 0.32688121373206375, "actor_loss": -93.58451574707031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.42278552055359, "step": 149000}
{"episode_reward": 984.1672738686374, "episode": 150.0, "batch_reward": 0.9118207796812058, "critic_loss": 0.32486912319809197, "actor_loss": -93.26394877624512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
