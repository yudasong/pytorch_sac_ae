{"episode_reward": 0.0, "episode": 1.0, "duration": 20.60456132888794, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.7890112400054932, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.31527748349687584, "critic_loss": 0.6033487767726431, "actor_loss": -73.770636208585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.24261713027954, "step": 3000}
{"episode_reward": 841.5807394566892, "episode": 4.0, "batch_reward": 0.5054005540013313, "critic_loss": 0.6211295875310898, "actor_loss": -82.91618095397949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.357680797576904, "step": 4000}
{"episode_reward": 743.9625208310997, "episode": 5.0, "batch_reward": 0.5585432771742344, "critic_loss": 0.621787199318409, "actor_loss": -83.99704531860351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.668355226516724, "step": 5000}
{"episode_reward": 808.1991920276455, "episode": 6.0, "batch_reward": 0.6180870167911052, "critic_loss": 0.4619504304379225, "actor_loss": -85.82047619628906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.29696249961853, "step": 6000}
{"episode_reward": 907.2476369423732, "episode": 7.0, "batch_reward": 0.6493691384792328, "critic_loss": 0.5101948116123677, "actor_loss": -87.07565739440918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.24419641494751, "step": 7000}
{"episode_reward": 818.4306609389724, "episode": 8.0, "batch_reward": 0.6728293986320496, "critic_loss": 0.6306667410731316, "actor_loss": -86.92077352905274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.286592483520508, "step": 8000}
{"episode_reward": 806.8339649978655, "episode": 9.0, "batch_reward": 0.701122094631195, "critic_loss": 0.5211951640844346, "actor_loss": -87.744662399292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.330621480941772, "step": 9000}
{"episode_reward": 944.7099272392405, "episode": 10.0, "batch_reward": 0.7194939685463906, "critic_loss": 0.5470540580451488, "actor_loss": -88.26435734558106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.330036878585815, "step": 10000}
{"episode_reward": 842.1796489836631, "episode": 11.0, "batch_reward": 0.7368113991618156, "critic_loss": 0.5106753817200661, "actor_loss": -89.10944941711426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.836259603500366, "step": 11000}
{"episode_reward": 910.4582528928466, "episode": 12.0, "batch_reward": 0.7135812748670578, "critic_loss": 0.4689395308494568, "actor_loss": -88.72561918640136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.354702711105347, "step": 12000}
{"episode_reward": 24.440514325540097, "episode": 13.0, "batch_reward": 0.6594531357884407, "critic_loss": 0.4749434064924717, "actor_loss": -88.93217192077637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.35131335258484, "step": 13000}
{"episode_reward": 26.08403566229637, "episode": 14.0, "batch_reward": 0.644106394469738, "critic_loss": 0.38176029233634473, "actor_loss": -88.80231362915039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3226215839386, "step": 14000}
{"episode_reward": 915.0196628478675, "episode": 15.0, "batch_reward": 0.6630207137465477, "critic_loss": 0.4178766176998615, "actor_loss": -89.03404777526856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.341984510421753, "step": 15000}
{"episode_reward": 944.4747530548414, "episode": 16.0, "batch_reward": 0.6551269317865371, "critic_loss": 0.3891874606013298, "actor_loss": -87.88751556396484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.325924396514893, "step": 16000}
{"episode_reward": 125.39747152879, "episode": 17.0, "batch_reward": 0.6395759208202362, "critic_loss": 0.4462786158174276, "actor_loss": -86.89558522033691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.351081132888794, "step": 17000}
{"episode_reward": 804.676285215156, "episode": 18.0, "batch_reward": 0.6499975779056549, "critic_loss": 0.4495304312705994, "actor_loss": -86.92694511413575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.340253591537476, "step": 18000}
{"episode_reward": 795.1170147356258, "episode": 19.0, "batch_reward": 0.6616664465665817, "critic_loss": 0.4707625400722027, "actor_loss": -86.662431640625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.352453470230103, "step": 19000}
{"episode_reward": 901.5551538811516, "episode": 20.0, "batch_reward": 0.674732478916645, "critic_loss": 0.5233900583386422, "actor_loss": -87.19178044128418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.348224878311157, "step": 20000}
{"episode_reward": 909.2249781424058, "episode": 21.0, "batch_reward": 0.6886284568309784, "critic_loss": 0.5263815875947475, "actor_loss": -87.35659156799316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.70801544189453, "step": 21000}
{"episode_reward": 965.5951555078974, "episode": 22.0, "batch_reward": 0.6972424194216729, "critic_loss": 0.5382425115406513, "actor_loss": -87.95836499023437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31790828704834, "step": 22000}
{"episode_reward": 885.2363286055897, "episode": 23.0, "batch_reward": 0.7037223474383354, "critic_loss": 0.6579713527262211, "actor_loss": -88.38340887451172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.342698574066162, "step": 23000}
{"episode_reward": 775.9183116021111, "episode": 24.0, "batch_reward": 0.7077492002844811, "critic_loss": 0.6875118172168732, "actor_loss": -89.07428053283691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.340935707092285, "step": 24000}
{"episode_reward": 811.443525025722, "episode": 25.0, "batch_reward": 0.7105144064426422, "critic_loss": 0.7653558628261089, "actor_loss": -89.53775524902343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.346505880355835, "step": 25000}
{"episode_reward": 800.5790964098214, "episode": 26.0, "batch_reward": 0.7168452493548393, "critic_loss": 0.7315521261096001, "actor_loss": -89.74328991699218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.346099376678467, "step": 26000}
{"episode_reward": 876.0968348756662, "episode": 27.0, "batch_reward": 0.7223745250105857, "critic_loss": 0.7464370225071907, "actor_loss": -90.22669946289062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34848189353943, "step": 27000}
{"episode_reward": 853.5592395052721, "episode": 28.0, "batch_reward": 0.7247728642821312, "critic_loss": 0.8282724799215794, "actor_loss": -89.80911389160157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.332067728042603, "step": 28000}
{"episode_reward": 804.7716048501044, "episode": 29.0, "batch_reward": 0.7321007978916169, "critic_loss": 0.768706170797348, "actor_loss": -90.52535632324219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.333435773849487, "step": 29000}
{"episode_reward": 966.4973204179821, "episode": 30.0, "batch_reward": 0.736801202595234, "critic_loss": 0.8131892486810685, "actor_loss": -90.36974194335937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3116352558136, "step": 30000}
{"episode_reward": 858.704959608098, "episode": 31.0, "batch_reward": 0.7412066972255706, "critic_loss": 0.8065053451061249, "actor_loss": -90.2859086303711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.68616032600403, "step": 31000}
{"episode_reward": 905.69174760079, "episode": 32.0, "batch_reward": 0.747831863284111, "critic_loss": 0.8468413067162037, "actor_loss": -90.76370602416992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.327133178710938, "step": 32000}
{"episode_reward": 808.2690825111918, "episode": 33.0, "batch_reward": 0.7503689724802971, "critic_loss": 0.8050415424704551, "actor_loss": -90.67699304199219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.339439392089844, "step": 33000}
{"episode_reward": 920.1743895804306, "episode": 34.0, "batch_reward": 0.7554003897905349, "critic_loss": 0.7747711921930314, "actor_loss": -90.81255860900879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.32717204093933, "step": 34000}
{"episode_reward": 945.0077073196135, "episode": 35.0, "batch_reward": 0.7575541986823082, "critic_loss": 0.8258638136088848, "actor_loss": -90.95277857971192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.372974634170532, "step": 35000}
{"episode_reward": 795.122080494131, "episode": 36.0, "batch_reward": 0.7626510813832283, "critic_loss": 0.7593948214352131, "actor_loss": -90.84139971923828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.335220336914062, "step": 36000}
{"episode_reward": 931.1539569376187, "episode": 37.0, "batch_reward": 0.7683596587181092, "critic_loss": 0.7050276246666908, "actor_loss": -90.745173828125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3315212726593, "step": 37000}
{"episode_reward": 944.5597908632855, "episode": 38.0, "batch_reward": 0.7732298446893692, "critic_loss": 0.6392155972719192, "actor_loss": -91.41160401916504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.353057384490967, "step": 38000}
{"episode_reward": 953.5454672700865, "episode": 39.0, "batch_reward": 0.7767387827038765, "critic_loss": 0.6067818606346845, "actor_loss": -91.17457391357422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.35317873954773, "step": 39000}
{"episode_reward": 911.9397368826676, "episode": 40.0, "batch_reward": 0.7782720463871956, "critic_loss": 0.5378367691338062, "actor_loss": -91.1105966796875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34722375869751, "step": 40000}
{"episode_reward": 931.8015240562969, "episode": 41.0, "batch_reward": 0.7821157912611961, "critic_loss": 0.5345459917485714, "actor_loss": -91.07062355041504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.69574475288391, "step": 41000}
{"episode_reward": 941.9116957688386, "episode": 42.0, "batch_reward": 0.7875451796650886, "critic_loss": 0.5254940621554851, "actor_loss": -91.18220077514648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.332091093063354, "step": 42000}
{"episode_reward": 976.9416625583038, "episode": 43.0, "batch_reward": 0.7919625087976455, "critic_loss": 0.5124324122071267, "actor_loss": -91.57204832458496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.335626125335693, "step": 43000}
{"episode_reward": 925.6543089471486, "episode": 44.0, "batch_reward": 0.7925927839279174, "critic_loss": 0.5119743930995464, "actor_loss": -91.38635536193847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.333534240722656, "step": 44000}
{"episode_reward": 816.9594964939263, "episode": 45.0, "batch_reward": 0.7964092568159103, "critic_loss": 0.46525472676754, "actor_loss": -91.6576185760498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.311687469482422, "step": 45000}
{"episode_reward": 968.4417900717475, "episode": 46.0, "batch_reward": 0.7997818688750267, "critic_loss": 0.4677463380843401, "actor_loss": -91.4717085571289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.337498903274536, "step": 46000}
{"episode_reward": 960.1548906157129, "episode": 47.0, "batch_reward": 0.8038902050256729, "critic_loss": 0.4288147737532854, "actor_loss": -91.26767189025878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.330275774002075, "step": 47000}
{"episode_reward": 947.8633348733641, "episode": 48.0, "batch_reward": 0.8060512638688088, "critic_loss": 0.4398097913116217, "actor_loss": -91.87971270751953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.329069137573242, "step": 48000}
{"episode_reward": 944.507994776739, "episode": 49.0, "batch_reward": 0.8083470532298088, "critic_loss": 0.4191477918922901, "actor_loss": -91.81880099487304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.310824632644653, "step": 49000}
{"episode_reward": 935.464603876027, "episode": 50.0, "batch_reward": 0.8097962050437927, "critic_loss": 0.41838582737743857, "actor_loss": -91.56761465454102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31277632713318, "step": 50000}
{"episode_reward": 918.6653401576408, "episode": 51.0, "batch_reward": 0.8130070481896401, "critic_loss": 0.41149258019030094, "actor_loss": -91.94836811828613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.73454141616821, "step": 51000}
{"episode_reward": 867.3227143319311, "episode": 52.0, "batch_reward": 0.8115170649886131, "critic_loss": 0.44290015201270583, "actor_loss": -91.5815312347412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.32245135307312, "step": 52000}
{"episode_reward": 828.4107520473159, "episode": 53.0, "batch_reward": 0.8163365235924721, "critic_loss": 0.45790347012877464, "actor_loss": -91.9010959777832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.35093355178833, "step": 53000}
{"episode_reward": 950.2825223507671, "episode": 54.0, "batch_reward": 0.8175568488240242, "critic_loss": 0.4504382776767015, "actor_loss": -91.66109790039063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.324617624282837, "step": 54000}
{"episode_reward": 926.9166296330194, "episode": 55.0, "batch_reward": 0.8190134469270706, "critic_loss": 0.4495282936245203, "actor_loss": -91.53220022583008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.341270446777344, "step": 55000}
{"episode_reward": 940.7361926344065, "episode": 56.0, "batch_reward": 0.8215374553203583, "critic_loss": 0.4547958386987448, "actor_loss": -91.88544300842285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.315441846847534, "step": 56000}
{"episode_reward": 953.9255566392799, "episode": 57.0, "batch_reward": 0.8242634185552598, "critic_loss": 0.43580606615543366, "actor_loss": -91.75575080871582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.344838619232178, "step": 57000}
{"episode_reward": 957.0556997705557, "episode": 58.0, "batch_reward": 0.8257364723086357, "critic_loss": 0.41349767765402795, "actor_loss": -92.00592295837403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.332651138305664, "step": 58000}
{"episode_reward": 947.744678331666, "episode": 59.0, "batch_reward": 0.8285095250606537, "critic_loss": 0.41678729589283464, "actor_loss": -91.95140954589844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.330517768859863, "step": 59000}
{"episode_reward": 972.7433472226943, "episode": 60.0, "batch_reward": 0.8310600433945656, "critic_loss": 0.4567825112938881, "actor_loss": -91.8510182647705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.325263500213623, "step": 60000}
{"episode_reward": 923.2862740918309, "episode": 61.0, "batch_reward": 0.832424738407135, "critic_loss": 0.42451511247456075, "actor_loss": -91.90440245056152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.7419011592865, "step": 61000}
{"episode_reward": 915.2785196399453, "episode": 62.0, "batch_reward": 0.8329287635684013, "critic_loss": 0.39937969301640985, "actor_loss": -92.13001287841797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34829568862915, "step": 62000}
{"episode_reward": 964.373321743724, "episode": 63.0, "batch_reward": 0.8357389504313469, "critic_loss": 0.4102963650673628, "actor_loss": -92.03529389953613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34703516960144, "step": 63000}
{"episode_reward": 968.0411874559567, "episode": 64.0, "batch_reward": 0.8374399267435074, "critic_loss": 0.40639834797382357, "actor_loss": -91.88071141052247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.33644986152649, "step": 64000}
{"episode_reward": 913.2457538813577, "episode": 65.0, "batch_reward": 0.8385219251513482, "critic_loss": 0.4017675965130329, "actor_loss": -92.19565434265137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.325740575790405, "step": 65000}
{"episode_reward": 956.724580926123, "episode": 66.0, "batch_reward": 0.8409585084319114, "critic_loss": 0.38071825629472733, "actor_loss": -91.89302380371093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.317720651626587, "step": 66000}
{"episode_reward": 964.6509210158324, "episode": 67.0, "batch_reward": 0.8432342230677604, "critic_loss": 0.38984327517449857, "actor_loss": -92.13124458312988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34188222885132, "step": 67000}
{"episode_reward": 946.5350464760207, "episode": 68.0, "batch_reward": 0.8434891595840454, "critic_loss": 0.3980623219162226, "actor_loss": -92.1092814025879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.349472761154175, "step": 68000}
{"episode_reward": 950.2457844884475, "episode": 69.0, "batch_reward": 0.8456222196817398, "critic_loss": 0.38352823694050314, "actor_loss": -92.02230438232422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34896159172058, "step": 69000}
{"episode_reward": 950.0985210221634, "episode": 70.0, "batch_reward": 0.8467162209153175, "critic_loss": 0.39001371698081494, "actor_loss": -92.23521369934082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.341647624969482, "step": 70000}
{"episode_reward": 896.958565295919, "episode": 71.0, "batch_reward": 0.8476523069143296, "critic_loss": 0.3832339921891689, "actor_loss": -92.26766485595704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.7261118888855, "step": 71000}
{"episode_reward": 958.3763456107632, "episode": 72.0, "batch_reward": 0.850117596745491, "critic_loss": 0.3812104474455118, "actor_loss": -92.32816403198242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.317839860916138, "step": 72000}
{"episode_reward": 920.6776306396124, "episode": 73.0, "batch_reward": 0.8497663920521736, "critic_loss": 0.370425033390522, "actor_loss": -92.01324801635742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.336577653884888, "step": 73000}
{"episode_reward": 942.9546324921698, "episode": 74.0, "batch_reward": 0.8522062165141105, "critic_loss": 0.3528263435512781, "actor_loss": -92.33168675231934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34088659286499, "step": 74000}
{"episode_reward": 952.8649502697662, "episode": 75.0, "batch_reward": 0.8519898666739464, "critic_loss": 0.39373224137723445, "actor_loss": -92.16318127441406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.339926719665527, "step": 75000}
{"episode_reward": 848.0888785432331, "episode": 76.0, "batch_reward": 0.8538782957196236, "critic_loss": 0.38941941933333873, "actor_loss": -92.00773928833007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.340621948242188, "step": 76000}
{"episode_reward": 952.3733789166059, "episode": 77.0, "batch_reward": 0.8548069359064102, "critic_loss": 0.37891362243890764, "actor_loss": -92.22938667297363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.320544719696045, "step": 77000}
{"episode_reward": 979.7442250816987, "episode": 78.0, "batch_reward": 0.8542698771357536, "critic_loss": 0.38064538991451263, "actor_loss": -92.46303871154785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.344753742218018, "step": 78000}
{"episode_reward": 916.9295675097208, "episode": 79.0, "batch_reward": 0.8542514062523842, "critic_loss": 0.39432149598002436, "actor_loss": -92.37869903564453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31862449645996, "step": 79000}
{"episode_reward": 942.0494922739438, "episode": 80.0, "batch_reward": 0.8584830412268638, "critic_loss": 0.4027813684642315, "actor_loss": -92.1085266418457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34122323989868, "step": 80000}
{"episode_reward": 968.9053281430126, "episode": 81.0, "batch_reward": 0.8571220752596855, "critic_loss": 0.3832163465023041, "actor_loss": -92.15165724182128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.673333406448364, "step": 81000}
{"episode_reward": 879.7273424750393, "episode": 82.0, "batch_reward": 0.8590914716124535, "critic_loss": 0.4038029958605766, "actor_loss": -92.2840489654541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.291686534881592, "step": 82000}
{"episode_reward": 970.6078875954713, "episode": 83.0, "batch_reward": 0.8606418623924256, "critic_loss": 0.3711248646378517, "actor_loss": -91.92648945617675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.316248178482056, "step": 83000}
{"episode_reward": 937.9056675943013, "episode": 84.0, "batch_reward": 0.8602072967886925, "critic_loss": 0.39323849765956403, "actor_loss": -92.17312852478027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.28320026397705, "step": 84000}
{"episode_reward": 848.9712051701367, "episode": 85.0, "batch_reward": 0.8601944453120232, "critic_loss": 0.4017382982522249, "actor_loss": -92.20835835266114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.287153720855713, "step": 85000}
{"episode_reward": 965.5637623456728, "episode": 86.0, "batch_reward": 0.8627285591959953, "critic_loss": 0.38480165834724905, "actor_loss": -91.90436326599121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31716823577881, "step": 86000}
{"episode_reward": 952.8561612692956, "episode": 87.0, "batch_reward": 0.8626295828819275, "critic_loss": 0.4105384407192469, "actor_loss": -92.13197383117675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.340293169021606, "step": 87000}
{"episode_reward": 908.3780674424783, "episode": 88.0, "batch_reward": 0.8651521638035774, "critic_loss": 0.3766691646426916, "actor_loss": -91.98767190551757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.342884302139282, "step": 88000}
{"episode_reward": 952.0847340082686, "episode": 89.0, "batch_reward": 0.867361502289772, "critic_loss": 0.3698829390406609, "actor_loss": -92.39602687072754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.33103632926941, "step": 89000}
{"episode_reward": 973.5903039503362, "episode": 90.0, "batch_reward": 0.8664143115878106, "critic_loss": 0.388158222168684, "actor_loss": -92.65251582336425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.342177152633667, "step": 90000}
{"episode_reward": 979.5052942055252, "episode": 91.0, "batch_reward": 0.8664687194824219, "critic_loss": 0.36696907169371845, "actor_loss": -92.29316567993165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.72000598907471, "step": 91000}
{"episode_reward": 920.3950063217186, "episode": 92.0, "batch_reward": 0.8689889337420463, "critic_loss": 0.3815421634912491, "actor_loss": -92.28764993286133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.33469581604004, "step": 92000}
{"episode_reward": 966.1842860369909, "episode": 93.0, "batch_reward": 0.8696755757927894, "critic_loss": 0.3541809450387955, "actor_loss": -92.44658236694336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.298980474472046, "step": 93000}
{"episode_reward": 978.0686839842125, "episode": 94.0, "batch_reward": 0.870810562312603, "critic_loss": 0.3466078412085772, "actor_loss": -92.36259580993652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.335806131362915, "step": 94000}
{"episode_reward": 967.6699416397026, "episode": 95.0, "batch_reward": 0.8708269647359848, "critic_loss": 0.36026665690541265, "actor_loss": -92.68567807006836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.328275442123413, "step": 95000}
{"episode_reward": 951.4434565441871, "episode": 96.0, "batch_reward": 0.8718980251550674, "critic_loss": 0.3584328095912933, "actor_loss": -91.9664359741211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.329339027404785, "step": 96000}
{"episode_reward": 921.4652559458366, "episode": 97.0, "batch_reward": 0.8728097150325775, "critic_loss": 0.37263087268173695, "actor_loss": -92.25226916503907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.330857276916504, "step": 97000}
{"episode_reward": 950.0695230505836, "episode": 98.0, "batch_reward": 0.8729730704426766, "critic_loss": 0.3697666361927986, "actor_loss": -92.64687525939941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.325088500976562, "step": 98000}
{"episode_reward": 906.9964825240132, "episode": 99.0, "batch_reward": 0.8728106196522712, "critic_loss": 0.39751836666464807, "actor_loss": -91.97719837951661, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.320085525512695, "step": 99000}
{"episode_reward": 926.8931126924485, "episode": 100.0, "batch_reward": 0.8737262035012245, "critic_loss": 0.36973461136966945, "actor_loss": -92.24686897277832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.349567890167236, "step": 100000}
{"episode_reward": 975.625733850707, "episode": 101.0, "batch_reward": 0.8759001180529594, "critic_loss": 0.3885696844905615, "actor_loss": -91.93014274597168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.65623712539673, "step": 101000}
{"episode_reward": 968.4821099608093, "episode": 102.0, "batch_reward": 0.8770185196399689, "critic_loss": 0.3691480375379324, "actor_loss": -92.34973188781738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.30296492576599, "step": 102000}
{"episode_reward": 964.5044654297988, "episode": 103.0, "batch_reward": 0.8779298465847969, "critic_loss": 0.3477369714379311, "actor_loss": -92.63026487731933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.32356858253479, "step": 103000}
{"episode_reward": 912.5363687631411, "episode": 104.0, "batch_reward": 0.8766740098595619, "critic_loss": 0.34756944674253465, "actor_loss": -92.30288191223144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.315739154815674, "step": 104000}
{"episode_reward": 951.6390319778885, "episode": 105.0, "batch_reward": 0.8783515616059303, "critic_loss": 0.3454587248489261, "actor_loss": -92.31345472717285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.288617372512817, "step": 105000}
{"episode_reward": 965.0667677484655, "episode": 106.0, "batch_reward": 0.8778686626553536, "critic_loss": 0.34155334425717593, "actor_loss": -92.25872825622558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.30847692489624, "step": 106000}
{"episode_reward": 920.134895979193, "episode": 107.0, "batch_reward": 0.8796375814080238, "critic_loss": 0.36946175214648247, "actor_loss": -92.33357046508789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.32303476333618, "step": 107000}
{"episode_reward": 919.2214570975351, "episode": 108.0, "batch_reward": 0.8791677729487419, "critic_loss": 0.3467792038619518, "actor_loss": -92.70619650268554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.321138381958008, "step": 108000}
{"episode_reward": 918.1855152023754, "episode": 109.0, "batch_reward": 0.8805789501667023, "critic_loss": 0.367183001331985, "actor_loss": -92.61252603149414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.325060606002808, "step": 109000}
{"episode_reward": 920.5029002655622, "episode": 110.0, "batch_reward": 0.8803533592224121, "critic_loss": 0.34957600662112237, "actor_loss": -92.54077534484863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.321820735931396, "step": 110000}
{"episode_reward": 953.28325230461, "episode": 111.0, "batch_reward": 0.8801761654615402, "critic_loss": 0.35015123496204614, "actor_loss": -92.84015783691406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.70050811767578, "step": 111000}
{"episode_reward": 940.217635144798, "episode": 112.0, "batch_reward": 0.8820788603425026, "critic_loss": 0.3580314272493124, "actor_loss": -92.31553594970703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34874439239502, "step": 112000}
{"episode_reward": 952.0417442458071, "episode": 113.0, "batch_reward": 0.8828818283677101, "critic_loss": 0.34730357603728773, "actor_loss": -92.57316348266602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.343514680862427, "step": 113000}
{"episode_reward": 973.4010263928024, "episode": 114.0, "batch_reward": 0.8822504216432572, "critic_loss": 0.35118256890773775, "actor_loss": -92.38273500061035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.326662063598633, "step": 114000}
{"episode_reward": 968.692787194866, "episode": 115.0, "batch_reward": 0.882665372312069, "critic_loss": 0.3830724070221186, "actor_loss": -92.44713999938965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31380033493042, "step": 115000}
{"episode_reward": 892.1959941140008, "episode": 116.0, "batch_reward": 0.8862484499812127, "critic_loss": 0.357530457213521, "actor_loss": -92.64141983032226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.325594663619995, "step": 116000}
{"episode_reward": 945.1153645213303, "episode": 117.0, "batch_reward": 0.8832065696120263, "critic_loss": 0.3559759161770344, "actor_loss": -92.63496017456055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.302918195724487, "step": 117000}
{"episode_reward": 962.1737992101876, "episode": 118.0, "batch_reward": 0.8847403318881989, "critic_loss": 0.34928698468208313, "actor_loss": -92.52226622009277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.305967330932617, "step": 118000}
{"episode_reward": 972.0993950978409, "episode": 119.0, "batch_reward": 0.8865455507040024, "critic_loss": 0.36198658757656815, "actor_loss": -92.63791975402832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.329490184783936, "step": 119000}
{"episode_reward": 978.3636349736632, "episode": 120.0, "batch_reward": 0.8870112624168396, "critic_loss": 0.3323742039874196, "actor_loss": -92.85690155029297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.348724365234375, "step": 120000}
{"episode_reward": 971.4418248984983, "episode": 121.0, "batch_reward": 0.8881564223170281, "critic_loss": 0.3593739356771111, "actor_loss": -92.59934088134766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.74577498435974, "step": 121000}
{"episode_reward": 936.1187683849614, "episode": 122.0, "batch_reward": 0.8879205162525177, "critic_loss": 0.3919539738968015, "actor_loss": -92.77815550231934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.334532976150513, "step": 122000}
{"episode_reward": 958.6417125526132, "episode": 123.0, "batch_reward": 0.8883298632502555, "critic_loss": 0.3411282863169908, "actor_loss": -92.66908471679687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3455171585083, "step": 123000}
{"episode_reward": 972.8334193735359, "episode": 124.0, "batch_reward": 0.890396156489849, "critic_loss": 0.34230768531560896, "actor_loss": -92.50435787963868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.338457822799683, "step": 124000}
{"episode_reward": 969.8878937135961, "episode": 125.0, "batch_reward": 0.8899251309037208, "critic_loss": 0.3363140942826867, "actor_loss": -92.64895042419434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.32226872444153, "step": 125000}
{"episode_reward": 971.6005045668918, "episode": 126.0, "batch_reward": 0.8914500308036805, "critic_loss": 0.3237758260965347, "actor_loss": -92.93860700988769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.282543897628784, "step": 126000}
{"episode_reward": 971.1959434351322, "episode": 127.0, "batch_reward": 0.8895907070636749, "critic_loss": 0.34306444261968133, "actor_loss": -92.53161424255372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.6478054523468, "step": 127000}
{"episode_reward": 936.0279170298863, "episode": 128.0, "batch_reward": 0.890869807600975, "critic_loss": 0.33237635061144827, "actor_loss": -92.70261067199706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.346049070358276, "step": 128000}
{"episode_reward": 947.1299126328721, "episode": 129.0, "batch_reward": 0.8913908280730247, "critic_loss": 0.34140566923469307, "actor_loss": -92.89389396667481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.60494327545166, "step": 129000}
{"episode_reward": 949.4025041049855, "episode": 130.0, "batch_reward": 0.8939714339971543, "critic_loss": 0.3296618932709098, "actor_loss": -92.95780793762206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.284959316253662, "step": 130000}
{"episode_reward": 948.3868210885116, "episode": 131.0, "batch_reward": 0.8935794232487678, "critic_loss": 0.3283994112834334, "actor_loss": -92.85295726013183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.70956063270569, "step": 131000}
{"episode_reward": 895.5764893921954, "episode": 132.0, "batch_reward": 0.8924539045095444, "critic_loss": 0.3305730493366718, "actor_loss": -92.96248208618164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34002375602722, "step": 132000}
{"episode_reward": 912.8244564711118, "episode": 133.0, "batch_reward": 0.8929355269670487, "critic_loss": 0.35630877314507964, "actor_loss": -93.19427714538574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.330852270126343, "step": 133000}
{"episode_reward": 972.546343330052, "episode": 134.0, "batch_reward": 0.8928921937346458, "critic_loss": 0.32623186717182395, "actor_loss": -93.03986170959473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.350204467773438, "step": 134000}
{"episode_reward": 937.3839840369903, "episode": 135.0, "batch_reward": 0.8935582192540169, "critic_loss": 0.3175494821369648, "actor_loss": -92.72984126281739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.35007381439209, "step": 135000}
{"episode_reward": 918.2434133268042, "episode": 136.0, "batch_reward": 0.8933198010325432, "critic_loss": 0.35044349732249974, "actor_loss": -93.20094288635254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34152364730835, "step": 136000}
{"episode_reward": 919.805892887053, "episode": 137.0, "batch_reward": 0.8936450870037079, "critic_loss": 0.35350405229628085, "actor_loss": -92.9292257232666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.33339285850525, "step": 137000}
{"episode_reward": 975.3837689250996, "episode": 138.0, "batch_reward": 0.8945552415847778, "critic_loss": 0.34123632953315974, "actor_loss": -92.73122178649902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.322041988372803, "step": 138000}
{"episode_reward": 980.9871835474808, "episode": 139.0, "batch_reward": 0.8961521022319794, "critic_loss": 0.33554836481809613, "actor_loss": -93.43494470214844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31501007080078, "step": 139000}
{"episode_reward": 936.9167735242181, "episode": 140.0, "batch_reward": 0.8966153328418731, "critic_loss": 0.3707853539139032, "actor_loss": -92.99582075500489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.330179691314697, "step": 140000}
{"episode_reward": 961.1346905768534, "episode": 141.0, "batch_reward": 0.8951966849565506, "critic_loss": 0.3417595259919763, "actor_loss": -92.66025790405273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.76951003074646, "step": 141000}
{"episode_reward": 966.4542010537472, "episode": 142.0, "batch_reward": 0.896208568572998, "critic_loss": 0.34286511984467505, "actor_loss": -93.17593026733398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31244683265686, "step": 142000}
{"episode_reward": 956.075104454927, "episode": 143.0, "batch_reward": 0.8963710919618607, "critic_loss": 0.33134005231410263, "actor_loss": -93.24709828186035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.32041072845459, "step": 143000}
{"episode_reward": 968.2279905823558, "episode": 144.0, "batch_reward": 0.8983092915415763, "critic_loss": 0.3414307559505105, "actor_loss": -93.23998565673828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.35075855255127, "step": 144000}
{"episode_reward": 921.008609156709, "episode": 145.0, "batch_reward": 0.8981518748402596, "critic_loss": 0.32245210591703655, "actor_loss": -92.9280439453125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.353819608688354, "step": 145000}
{"episode_reward": 931.0955948407397, "episode": 146.0, "batch_reward": 0.8988785010576248, "critic_loss": 0.3321770330145955, "actor_loss": -92.83881301879883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34554672241211, "step": 146000}
{"episode_reward": 972.4786307617967, "episode": 147.0, "batch_reward": 0.8987073466777802, "critic_loss": 0.34489563593268396, "actor_loss": -93.04131433105469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.308234930038452, "step": 147000}
{"episode_reward": 931.68880406842, "episode": 148.0, "batch_reward": 0.8983210752606392, "critic_loss": 0.3240796688646078, "actor_loss": -93.02451184082031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34243154525757, "step": 148000}
{"episode_reward": 951.6433220892186, "episode": 149.0, "batch_reward": 0.8972526288628578, "critic_loss": 0.32362578746676446, "actor_loss": -93.11945909118653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.345963954925537, "step": 149000}
{"episode_reward": 922.6264189674425, "episode": 150.0, "batch_reward": 0.8984212512969971, "critic_loss": 0.33026991084218027, "actor_loss": -92.86950958251953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
