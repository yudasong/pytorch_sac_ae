{"episode": 1.0, "duration": 23.173376321792603, "episode_reward": 51.16415125024753, "step": 1000}
{"episode": 2.0, "duration": 1.9090569019317627, "episode_reward": 519.9299312670827, "step": 2000}
{"episode": 1.0, "duration": 22.184751987457275, "episode_reward": 51.16415125024753, "step": 1000}
{"episode": 2.0, "duration": 2.2299060821533203, "episode_reward": 519.9299312670827, "step": 2000}
{"episode": 3.0, "batch_reward": 0.28922625247261136, "actor_loss": -69.19216558999088, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 51.242475748062134, "episode_reward": 372.7445995583477, "step": 3000}
{"episode": 3.0, "batch_reward": 0.28922625247261136, "actor_loss": -69.19216558999088, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 50.57132267951965, "episode_reward": 372.7445995583477, "step": 3000}
{"episode": 4.0, "batch_reward": 0.3566439467966557, "actor_loss": -72.1589469909668, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.36580991744995, "episode_reward": 603.6383400121134, "step": 4000}
{"episode": 4.0, "batch_reward": 0.3566439467966557, "actor_loss": -72.1589469909668, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.708431482315063, "episode_reward": 603.6383400121134, "step": 4000}
{"episode": 5.0, "batch_reward": 0.39245833742618563, "actor_loss": -73.39556941223144, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.81036114692688, "episode_reward": 532.259244677725, "step": 5000}
{"episode": 5.0, "batch_reward": 0.39245833742618563, "actor_loss": -73.39556941223144, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.401958227157593, "episode_reward": 532.259244677725, "step": 5000}
{"episode": 6.0, "batch_reward": 0.434802025616169, "actor_loss": -74.5656184539795, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.745449542999268, "episode_reward": 640.6371960327323, "step": 6000}
{"episode": 6.0, "batch_reward": 0.434802025616169, "actor_loss": -74.5656184539795, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.76927876472473, "episode_reward": 640.6371960327323, "step": 6000}
{"episode": 7.0, "batch_reward": 0.46649997159838674, "actor_loss": -75.36416606140136, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.91146421432495, "episode_reward": 660.0464446024047, "step": 7000}
{"episode": 7.0, "batch_reward": 0.46649997159838674, "actor_loss": -75.36416606140136, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.02204656600952, "episode_reward": 660.0464446024047, "step": 7000}
{"episode": 8.0, "batch_reward": 0.49946067488193513, "actor_loss": -76.27698323059082, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.864409923553467, "episode_reward": 777.0950794610279, "step": 8000}
{"episode": 8.0, "batch_reward": 0.49946067488193513, "actor_loss": -76.27698323059082, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.525190353393555, "episode_reward": 777.0950794610279, "step": 8000}
{"episode": 9.0, "batch_reward": 0.5357401399612427, "actor_loss": -77.3920083770752, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.403163194656372, "episode_reward": 791.1222642712612, "step": 9000}
{"episode": 9.0, "batch_reward": 0.5357401399612427, "actor_loss": -77.3920083770752, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.177237510681152, "episode_reward": 791.1222642712612, "step": 9000}
{"episode": 10.0, "batch_reward": 0.5582753496468067, "actor_loss": -75.2358677368164, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 4024.439412355423, "episode_reward": 756.492045428702, "step": 10000}
{"episode": 10.0, "batch_reward": 0.5582753496468067, "actor_loss": -75.2358677368164, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 4056.0116782188416, "episode_reward": 756.492045428702, "step": 10000}
{"episode": 11.0, "batch_reward": 0.5705301707684993, "actor_loss": -75.76932595825195, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.59252214431763, "episode_reward": 657.2428804340884, "step": 11000}
{"episode": 11.0, "batch_reward": 0.5705301707684993, "actor_loss": -75.76932595825195, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.347376108169556, "episode_reward": 657.2428804340884, "step": 11000}
{"episode": 12.0, "batch_reward": 0.5829175888597965, "actor_loss": -74.05132934570312, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 438.90555119514465, "episode_reward": 627.9621604217352, "step": 12000}
{"episode": 13.0, "batch_reward": 0.5863581841886043, "actor_loss": -74.18335014343262, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.79075860977173, "episode_reward": 694.3749881986016, "step": 13000}
{"episode": 12.0, "batch_reward": 0.5829175888597965, "actor_loss": -74.05132934570312, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 438.4699351787567, "episode_reward": 627.9621604217352, "step": 12000}
{"episode": 13.0, "batch_reward": 0.5863581841886043, "actor_loss": -74.18335014343262, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.439863920211792, "episode_reward": 694.3749881986016, "step": 13000}
{"episode": 14.0, "batch_reward": 0.5875529665052891, "actor_loss": -73.2237855834961, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 445.4918465614319, "episode_reward": 484.4777465210492, "step": 14000}
{"episode": 15.0, "batch_reward": 0.5874519644379615, "actor_loss": -73.2254800415039, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.615232944488525, "episode_reward": 770.5783619894806, "step": 15000}
{"episode": 14.0, "batch_reward": 0.5875529665052891, "actor_loss": -73.2237855834961, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 447.7633354663849, "episode_reward": 484.4777465210492, "step": 14000}
{"episode": 15.0, "batch_reward": 0.5874519644379615, "actor_loss": -73.2254800415039, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.584044456481934, "episode_reward": 770.5783619894806, "step": 15000}
{"episode": 16.0, "batch_reward": 0.5982387023866177, "actor_loss": -71.2594369506836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 437.5789313316345, "episode_reward": 754.6916358206356, "step": 16000}
{"episode": 17.0, "batch_reward": 0.6073503728508949, "actor_loss": -71.75109596252442, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.951674222946167, "episode_reward": 764.2616818631749, "step": 17000}
{"episode": 16.0, "batch_reward": 0.5982387023866177, "actor_loss": -71.2594369506836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 442.37721276283264, "episode_reward": 754.6916358206356, "step": 16000}
{"episode": 17.0, "batch_reward": 0.6073503728508949, "actor_loss": -71.75109596252442, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.41146159172058, "episode_reward": 764.2616818631749, "step": 17000}
{"episode": 18.0, "batch_reward": 0.6179948240220546, "actor_loss": -71.63441671752929, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 430.48441076278687, "episode_reward": 693.8295307822846, "step": 18000}
{"episode": 19.0, "batch_reward": 0.6243536835908889, "actor_loss": -71.88677665710449, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.247161865234375, "episode_reward": 753.8264235059115, "step": 19000}
{"episode": 18.0, "batch_reward": 0.6179948240220546, "actor_loss": -71.63441671752929, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 430.0975637435913, "episode_reward": 693.8295307822846, "step": 18000}
{"episode": 19.0, "batch_reward": 0.6243536835908889, "actor_loss": -71.88677665710449, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.419955015182495, "episode_reward": 753.8264235059115, "step": 19000}
{"episode": 20.0, "batch_reward": 0.6268124712705612, "actor_loss": -70.81723767089844, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 432.9445550441742, "episode_reward": 707.6128885207326, "step": 20000}
{"episode": 20.0, "batch_reward": 0.6268124712705612, "actor_loss": -70.81723767089844, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 438.6976692676544, "episode_reward": 707.6128885207326, "step": 20000}
{"episode": 21.0, "batch_reward": 0.6347056663036347, "actor_loss": -71.24799920654297, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.62683725357056, "episode_reward": 836.0667542845299, "step": 21000}
{"episode": 21.0, "batch_reward": 0.6347056663036347, "actor_loss": -71.24799920654297, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.57428956031799, "episode_reward": 836.0667542845299, "step": 21000}
{"episode": 22.0, "batch_reward": 0.6428891372680664, "actor_loss": -70.23636544799805, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 440.9579701423645, "episode_reward": 732.7804037683286, "step": 22000}
{"episode": 23.0, "batch_reward": 0.6448396352529526, "actor_loss": -70.49501837158203, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.347463607788086, "episode_reward": 669.5674992837023, "step": 23000}
{"episode": 22.0, "batch_reward": 0.6428891372680664, "actor_loss": -70.23636544799805, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 439.0635073184967, "episode_reward": 732.7804037683286, "step": 22000}
{"episode": 23.0, "batch_reward": 0.6448396352529526, "actor_loss": -70.49501837158203, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.562774419784546, "episode_reward": 669.5674992837023, "step": 23000}
{"episode": 24.0, "batch_reward": 0.6440064786076546, "actor_loss": -69.46330795288085, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 442.47427797317505, "episode_reward": 549.6600727440599, "step": 24000}
{"episode": 25.0, "batch_reward": 0.6437552216053009, "actor_loss": -69.47759887695312, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.73277997970581, "episode_reward": 738.3266251057618, "step": 25000}
{"episode": 24.0, "batch_reward": 0.6440064786076546, "actor_loss": -69.46330795288085, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 447.14739894866943, "episode_reward": 549.6600727440599, "step": 24000}
{"episode": 25.0, "batch_reward": 0.6437552216053009, "actor_loss": -69.47759887695312, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.443535804748535, "episode_reward": 738.3266251057618, "step": 25000}
{"episode": 26.0, "batch_reward": 0.6471792051196098, "actor_loss": -68.47212716674805, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.1497256755829, "episode_reward": 763.194512769268, "step": 26000}
{"episode": 27.0, "batch_reward": 0.6516859620213509, "actor_loss": -68.75920587158203, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.021742343902588, "episode_reward": 712.5070230560692, "step": 27000}
{"episode": 26.0, "batch_reward": 0.6471792051196098, "actor_loss": -68.47212716674805, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.61589336395264, "episode_reward": 763.194512769268, "step": 26000}
{"episode": 27.0, "batch_reward": 0.6516859620213509, "actor_loss": -68.75920587158203, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.940361261367798, "episode_reward": 712.5070230560692, "step": 27000}
{"episode": 28.0, "batch_reward": 0.6529071073532104, "actor_loss": -67.66261431884766, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 437.0361096858978, "episode_reward": 660.3599706553457, "step": 28000}
{"episode": 29.0, "batch_reward": 0.651843508541584, "actor_loss": -67.83017155456542, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.88234281539917, "episode_reward": 671.6317963483917, "step": 29000}
{"episode": 28.0, "batch_reward": 0.6529071073532104, "actor_loss": -67.66261431884766, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 438.34546732902527, "episode_reward": 660.3599706553457, "step": 28000}
{"episode": 29.0, "batch_reward": 0.651843508541584, "actor_loss": -67.83017155456542, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.31525754928589, "episode_reward": 671.6317963483917, "step": 29000}
{"episode": 30.0, "batch_reward": 0.6548805119991302, "actor_loss": -67.5099623260498, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 440.215167760849, "episode_reward": 707.7315789763444, "step": 30000}
{"episode": 31.0, "batch_reward": 0.654915291249752, "actor_loss": -67.70734655761719, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 39.89914917945862, "episode_reward": 683.3246061568702, "step": 31000}
{"episode": 30.0, "batch_reward": 0.6548805119991302, "actor_loss": -67.5099623260498, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.9721748828888, "episode_reward": 707.7315789763444, "step": 30000}
{"episode": 31.0, "batch_reward": 0.654915291249752, "actor_loss": -67.70734655761719, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 39.929795265197754, "episode_reward": 683.3246061568702, "step": 31000}
{"episode": 32.0, "batch_reward": 0.6578404108285903, "actor_loss": -67.04214471435547, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 444.22524547576904, "episode_reward": 569.5184888598383, "step": 32000}
{"episode": 33.0, "batch_reward": 0.655290886759758, "actor_loss": -67.03560023498535, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.910468578338623, "episode_reward": 824.3686449554726, "step": 33000}
{"episode": 32.0, "batch_reward": 0.6578404108285903, "actor_loss": -67.04214471435547, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.4660701751709, "episode_reward": 569.5184888598383, "step": 32000}
{"episode": 33.0, "batch_reward": 0.655290886759758, "actor_loss": -67.03560023498535, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.916977167129517, "episode_reward": 824.3686449554726, "step": 33000}
{"episode": 34.0, "batch_reward": 0.660137982070446, "actor_loss": -66.47534380340576, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 441.59528970718384, "episode_reward": 771.8966595470907, "step": 34000}
{"episode": 35.0, "batch_reward": 0.6638930832743645, "actor_loss": -66.84518273162841, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.742652416229248, "episode_reward": 775.0552614739986, "step": 35000}
{"episode": 34.0, "batch_reward": 0.660137982070446, "actor_loss": -66.47534380340576, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 440.6134583950043, "episode_reward": 771.8966595470907, "step": 34000}
{"episode": 35.0, "batch_reward": 0.6638930832743645, "actor_loss": -66.84518273162841, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.239928007125854, "episode_reward": 775.0552614739986, "step": 35000}
{"episode": 36.0, "batch_reward": 0.6653956340551377, "actor_loss": -66.53670388793945, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 444.65565180778503, "episode_reward": 707.951560070682, "step": 36000}
{"episode": 37.0, "batch_reward": 0.6678126924037934, "actor_loss": -66.68865800476074, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.041227102279663, "episode_reward": 766.2749948641681, "step": 37000}
{"episode": 36.0, "batch_reward": 0.6653956340551377, "actor_loss": -66.53670388793945, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 450.56770038604736, "episode_reward": 707.951560070682, "step": 36000}
{"episode": 37.0, "batch_reward": 0.6678126924037934, "actor_loss": -66.68865800476074, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.840871810913086, "episode_reward": 766.2749948641681, "step": 37000}
{"episode": 38.0, "batch_reward": 0.6712767834067345, "actor_loss": -66.39719412231446, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 431.8053653240204, "episode_reward": 750.4546250313883, "step": 38000}
{"episode": 39.0, "batch_reward": 0.6696298592090607, "actor_loss": -66.47777448272706, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.608663320541382, "episode_reward": 737.7233891259132, "step": 39000}
{"episode": 38.0, "batch_reward": 0.6712767834067345, "actor_loss": -66.39719412231446, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 431.7007956504822, "episode_reward": 750.4546250313883, "step": 38000}
{"episode": 39.0, "batch_reward": 0.6696298592090607, "actor_loss": -66.47777448272706, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.986175060272217, "episode_reward": 737.7233891259132, "step": 39000}
{"episode": 40.0, "batch_reward": 0.672327171087265, "actor_loss": -66.16769929504395, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 422.6385431289673, "episode_reward": 689.1247214431772, "step": 40000}
{"episode": 41.0, "batch_reward": 0.6759527651667595, "actor_loss": -66.47670736694336, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 36.27262043952942, "episode_reward": 745.8148961612454, "step": 41000}
{"episode": 40.0, "batch_reward": 0.672327171087265, "actor_loss": -66.16769929504395, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 424.86091709136963, "episode_reward": 689.1247214431772, "step": 40000}
{"episode": 41.0, "batch_reward": 0.6759527651667595, "actor_loss": -66.47670736694336, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 36.54178428649902, "episode_reward": 745.8148961612454, "step": 41000}
{"episode": 42.0, "batch_reward": 0.6763697080612182, "actor_loss": -66.3124606704712, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 421.00945520401, "episode_reward": 797.5158338377385, "step": 42000}
{"episode": 43.0, "batch_reward": 0.6767788698077202, "actor_loss": -66.42625682830811, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.85285711288452, "episode_reward": 741.4969677701152, "step": 43000}
{"episode": 42.0, "batch_reward": 0.6763697080612182, "actor_loss": -66.3124606704712, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 428.504643201828, "episode_reward": 797.5158338377385, "step": 42000}
{"episode": 43.0, "batch_reward": 0.6767788698077202, "actor_loss": -66.42625682830811, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.686514139175415, "episode_reward": 741.4969677701152, "step": 43000}
{"episode": 44.0, "batch_reward": 0.6792106583714486, "actor_loss": -66.28670068359375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 436.401748418808, "episode_reward": 776.850010537068, "step": 44000}
{"episode": 45.0, "batch_reward": 0.6811487262248993, "actor_loss": -66.5133284072876, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.31511926651001, "episode_reward": 773.7926002482903, "step": 45000}
{"episode": 44.0, "batch_reward": 0.6792106583714486, "actor_loss": -66.28670068359375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 436.0264537334442, "episode_reward": 776.850010537068, "step": 44000}
{"episode": 45.0, "batch_reward": 0.6811487262248993, "actor_loss": -66.5133284072876, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.023898601531982, "episode_reward": 773.7926002482903, "step": 45000}
{"episode": 46.0, "batch_reward": 0.6830477614402771, "actor_loss": -66.16464044952393, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 443.6865656375885, "episode_reward": 642.54956941813, "step": 46000}
{"episode": 47.0, "batch_reward": 0.6830770980119705, "actor_loss": -66.21237442016601, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.13638472557068, "episode_reward": 781.3203683247476, "step": 47000}
{"episode": 46.0, "batch_reward": 0.6830477614402771, "actor_loss": -66.16464044952393, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 445.1084477901459, "episode_reward": 642.54956941813, "step": 46000}
{"episode": 47.0, "batch_reward": 0.6830770980119705, "actor_loss": -66.21237442016601, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.018076181411743, "episode_reward": 781.3203683247476, "step": 47000}
{"episode": 48.0, "batch_reward": 0.6842969835996627, "actor_loss": -66.49275260925293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 434.65355110168457, "episode_reward": 722.4370313050061, "step": 48000}
{"episode": 49.0, "batch_reward": 0.6858373287916183, "actor_loss": -66.54902499389648, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.884888410568237, "episode_reward": 636.0684543180282, "step": 49000}
{"episode": 48.0, "batch_reward": 0.6842969835996627, "actor_loss": -66.49275260925293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 443.3750374317169, "episode_reward": 722.4370313050061, "step": 48000}
{"episode": 49.0, "batch_reward": 0.6858373287916183, "actor_loss": -66.54902499389648, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.313974380493164, "episode_reward": 636.0684543180282, "step": 49000}
{"episode": 50.0, "batch_reward": 0.68404864102602, "actor_loss": -67.30758791351319, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 444.791086435318, "episode_reward": 628.5992312547127, "step": 50000}
{"episode": 51.0, "batch_reward": 0.6851855896115303, "actor_loss": -67.37874752044678, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 37.39615774154663, "episode_reward": 749.7300320327985, "step": 51000}
{"episode": 50.0, "batch_reward": 0.68404864102602, "actor_loss": -67.30758791351319, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 443.29740834236145, "episode_reward": 628.5992312547127, "step": 50000}
{"episode": 51.0, "batch_reward": 0.6851855896115303, "actor_loss": -67.37874752044678, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.912545919418335, "episode_reward": 749.7300320327985, "step": 51000}
{"episode": 52.0, "batch_reward": 0.6837437401413917, "actor_loss": -67.72553105163574, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.57109022140503, "episode_reward": 573.9882589312873, "step": 52000}
{"episode": 53.0, "batch_reward": 0.6826592761874198, "actor_loss": -67.7361842956543, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.98456072807312, "episode_reward": 707.0504235213049, "step": 53000}
{"episode": 52.0, "batch_reward": 0.6837437401413917, "actor_loss": -67.72553105163574, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 445.42513489723206, "episode_reward": 573.9882589312873, "step": 52000}
{"episode": 53.0, "batch_reward": 0.6826592761874198, "actor_loss": -67.7361842956543, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.195295572280884, "episode_reward": 707.0504235213049, "step": 53000}
{"episode": 54.0, "batch_reward": 0.6850895391106605, "actor_loss": -68.31116090393067, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 441.2516005039215, "episode_reward": 746.8654971530003, "step": 54000}
{"episode": 55.0, "batch_reward": 0.6860042223930359, "actor_loss": -68.29519060516357, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.019577503204346, "episode_reward": 765.245368307506, "step": 55000}
{"episode": 54.0, "batch_reward": 0.6850895391106605, "actor_loss": -68.31116090393067, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 448.4248797893524, "episode_reward": 746.8654971530003, "step": 54000}
{"episode": 55.0, "batch_reward": 0.6860042223930359, "actor_loss": -68.29519060516357, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.088772773742676, "episode_reward": 765.245368307506, "step": 55000}
{"episode": 56.0, "batch_reward": 0.6852485946416855, "actor_loss": -68.91637866210938, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 443.4488787651062, "episode_reward": 755.153306575529, "step": 56000}
{"episode": 57.0, "batch_reward": 0.6862033597230911, "actor_loss": -68.97371690368652, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.478891611099243, "episode_reward": 721.8277819771389, "step": 57000}
{"episode": 56.0, "batch_reward": 0.6852485946416855, "actor_loss": -68.91637866210938, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 445.03876399993896, "episode_reward": 755.153306575529, "step": 56000}
{"episode": 57.0, "batch_reward": 0.6862033597230911, "actor_loss": -68.97371690368652, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.142982006072998, "episode_reward": 721.8277819771389, "step": 57000}
{"episode": 58.0, "batch_reward": 0.6886387407183647, "actor_loss": -69.8093136291504, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 449.29875111579895, "episode_reward": 726.844270668085, "step": 58000}
{"episode": 59.0, "batch_reward": 0.6887239081859589, "actor_loss": -69.80865533447266, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.781042337417603, "episode_reward": 711.0192146019152, "step": 59000}
{"episode": 58.0, "batch_reward": 0.6886387407183647, "actor_loss": -69.8093136291504, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 447.58574414253235, "episode_reward": 726.844270668085, "step": 58000}
{"episode": 59.0, "batch_reward": 0.6887239081859589, "actor_loss": -69.80865533447266, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.461972951889038, "episode_reward": 711.0192146019152, "step": 59000}
{"episode": 60.0, "batch_reward": 0.6874575402736663, "actor_loss": -70.44329022216797, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 440.9714848995209, "episode_reward": 697.6158361425997, "step": 60000}
{"episode": 61.0, "batch_reward": 0.6876013008356094, "actor_loss": -70.52645469665528, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.64897584915161, "episode_reward": 691.6732759831023, "step": 61000}
{"episode": 60.0, "batch_reward": 0.6874575402736663, "actor_loss": -70.44329022216797, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 448.21560311317444, "episode_reward": 697.6158361425997, "step": 60000}
{"episode": 61.0, "batch_reward": 0.6876013008356094, "actor_loss": -70.52645469665528, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.53963589668274, "episode_reward": 691.6732759831023, "step": 61000}
{"episode": 62.0, "batch_reward": 0.6896365087628364, "actor_loss": -71.0515518951416, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 442.8614947795868, "episode_reward": 760.8442380062842, "step": 62000}
{"episode": 63.0, "batch_reward": 0.6898785974979401, "actor_loss": -71.02379179382324, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.573317050933838, "episode_reward": 792.7202953810232, "step": 63000}
{"episode": 62.0, "batch_reward": 0.6896365087628364, "actor_loss": -71.0515518951416, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.539986371994, "episode_reward": 760.8442380062842, "step": 62000}
{"episode": 63.0, "batch_reward": 0.6898785974979401, "actor_loss": -71.02379179382324, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.517032384872437, "episode_reward": 792.7202953810232, "step": 63000}
{"episode": 64.0, "batch_reward": 0.6921496837735176, "actor_loss": -72.44727236938476, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 451.2802014350891, "episode_reward": 757.4668767710313, "step": 64000}
{"episode": 65.0, "batch_reward": 0.691902617931366, "actor_loss": -72.45480851745606, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.36836862564087, "episode_reward": 703.1823145857778, "step": 65000}
{"episode": 64.0, "batch_reward": 0.6921496837735176, "actor_loss": -72.44727236938476, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 447.8573799133301, "episode_reward": 757.4668767710313, "step": 64000}
{"episode": 65.0, "batch_reward": 0.691902617931366, "actor_loss": -72.45480851745606, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.566511631011963, "episode_reward": 703.1823145857778, "step": 65000}
{"episode": 66.0, "batch_reward": 0.6919428783655167, "actor_loss": -73.06167756652832, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 440.67979097366333, "episode_reward": 771.6247397737741, "step": 66000}
{"episode": 67.0, "batch_reward": 0.6941284477710724, "actor_loss": -73.18210803222657, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.754679203033447, "episode_reward": 664.2550716054394, "step": 67000}
{"episode": 66.0, "batch_reward": 0.6919428783655167, "actor_loss": -73.06167756652832, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 450.2185983657837, "episode_reward": 771.6247397737741, "step": 66000}
{"episode": 67.0, "batch_reward": 0.6941284477710724, "actor_loss": -73.18210803222657, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.55963945388794, "episode_reward": 664.2550716054394, "step": 67000}
{"episode": 68.0, "batch_reward": 0.6949296162724495, "actor_loss": -73.47362312316895, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 443.34065103530884, "episode_reward": 703.7041104673499, "step": 68000}
{"episode": 69.0, "batch_reward": 0.6940298083424569, "actor_loss": -73.32155087280273, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.739099979400635, "episode_reward": 777.7311084637424, "step": 69000}
{"episode": 68.0, "batch_reward": 0.6949296162724495, "actor_loss": -73.47362312316895, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 443.04186606407166, "episode_reward": 703.7041104673499, "step": 68000}
{"episode": 69.0, "batch_reward": 0.6940298083424569, "actor_loss": -73.32155087280273, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.240819454193115, "episode_reward": 777.7311084637424, "step": 69000}
{"episode": 70.0, "batch_reward": 0.6954959236979484, "actor_loss": -73.9670361328125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 445.5967526435852, "episode_reward": 714.2273180942843, "step": 70000}
{"episode": 71.0, "batch_reward": 0.6944329208135605, "actor_loss": -74.0673447265625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 39.02815628051758, "episode_reward": 672.254225258649, "step": 71000}
{"episode": 70.0, "batch_reward": 0.6954959236979484, "actor_loss": -73.9670361328125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 444.2759828567505, "episode_reward": 714.2273180942843, "step": 70000}
{"episode": 71.0, "batch_reward": 0.6944329208135605, "actor_loss": -74.0673447265625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 39.871668577194214, "episode_reward": 672.254225258649, "step": 71000}
{"episode": 72.0, "batch_reward": 0.6945324184298516, "actor_loss": -74.2253157043457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 442.57227516174316, "episode_reward": 619.5154454643481, "step": 72000}
{"episode": 73.0, "batch_reward": 0.6930733773112298, "actor_loss": -74.20200671386719, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.307010173797607, "episode_reward": 629.8914965179364, "step": 73000}
{"episode": 72.0, "batch_reward": 0.6945324184298516, "actor_loss": -74.2253157043457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 452.3631649017334, "episode_reward": 619.5154454643481, "step": 72000}
{"episode": 73.0, "batch_reward": 0.6930733773112298, "actor_loss": -74.20200671386719, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.919243574142456, "episode_reward": 629.8914965179364, "step": 73000}
{"episode": 74.0, "batch_reward": 0.6936376603841782, "actor_loss": -74.41118295288086, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 444.87685990333557, "episode_reward": 805.9501599935263, "step": 74000}
{"episode": 75.0, "batch_reward": 0.6958762967586517, "actor_loss": -74.43759269714356, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.72399926185608, "episode_reward": 806.5820471668341, "step": 75000}
{"episode": 74.0, "batch_reward": 0.6936376603841782, "actor_loss": -74.41118295288086, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.3620948791504, "episode_reward": 805.9501599935263, "step": 74000}
{"episode": 75.0, "batch_reward": 0.6958762967586517, "actor_loss": -74.43759269714356, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.48227310180664, "episode_reward": 806.5820471668341, "step": 75000}
{"episode": 76.0, "batch_reward": 0.6944660906791686, "actor_loss": -74.53707284545898, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 437.47903299331665, "episode_reward": 727.7392984853341, "step": 76000}
{"episode": 77.0, "batch_reward": 0.6955491493940353, "actor_loss": -74.76756442260742, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.732311010360718, "episode_reward": 695.9280968225174, "step": 77000}
{"episode": 76.0, "batch_reward": 0.6944660906791686, "actor_loss": -74.53707284545898, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 429.3335745334625, "episode_reward": 727.7392984853341, "step": 76000}
{"episode": 77.0, "batch_reward": 0.6955491493940353, "actor_loss": -74.76756442260742, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.830952167510986, "episode_reward": 695.9280968225174, "step": 77000}
{"episode": 78.0, "batch_reward": 0.6958902066349983, "actor_loss": -74.69880209350586, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 421.6275329589844, "episode_reward": 726.4972490000595, "step": 78000}
{"episode": 79.0, "batch_reward": 0.6950240311026573, "actor_loss": -74.83224052429199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.831420183181763, "episode_reward": 757.1685258849502, "step": 79000}
{"episode": 78.0, "batch_reward": 0.6958902066349983, "actor_loss": -74.69880209350586, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 429.98534870147705, "episode_reward": 726.4972490000595, "step": 78000}
{"episode": 79.0, "batch_reward": 0.6950240311026573, "actor_loss": -74.83224052429199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.921714067459106, "episode_reward": 757.1685258849502, "step": 79000}
{"episode": 80.0, "batch_reward": 0.6983502614498138, "actor_loss": -74.5157658996582, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 424.9231300354004, "episode_reward": 765.7906726330818, "step": 80000}
{"episode": 81.0, "batch_reward": 0.69850156468153, "actor_loss": -74.46482662963867, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 38.586331367492676, "episode_reward": 685.473620907665, "step": 81000}
{"episode": 80.0, "batch_reward": 0.6983502614498138, "actor_loss": -74.5157658996582, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 421.92064690589905, "episode_reward": 765.7906726330818, "step": 80000}
{"episode": 81.0, "batch_reward": 0.69850156468153, "actor_loss": -74.46482662963867, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.05984711647034, "episode_reward": 685.473620907665, "step": 81000}
{"episode": 82.0, "batch_reward": 0.6981162441372871, "actor_loss": -74.94675233459472, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 420.0303256511688, "episode_reward": 777.0684901124016, "step": 82000}
{"episode": 83.0, "batch_reward": 0.6980343697071075, "actor_loss": -75.04174349975585, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.860557794570923, "episode_reward": 734.0792450103545, "step": 83000}
{"episode": 82.0, "batch_reward": 0.6981162441372871, "actor_loss": -74.94675233459472, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 428.63857769966125, "episode_reward": 777.0684901124016, "step": 82000}
{"episode": 83.0, "batch_reward": 0.6980343697071075, "actor_loss": -75.04174349975585, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.88525366783142, "episode_reward": 734.0792450103545, "step": 83000}
{"episode": 84.0, "batch_reward": 0.6989208468198777, "actor_loss": -74.67067094421387, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 431.2883985042572, "episode_reward": 781.1461542866872, "step": 84000}
{"episode": 85.0, "batch_reward": 0.7028042886257172, "actor_loss": -74.85128953552245, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.936870098114014, "episode_reward": 819.6570996841493, "step": 85000}
{"episode": 84.0, "batch_reward": 0.6989208468198777, "actor_loss": -74.67067094421387, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 427.9147927761078, "episode_reward": 781.1461542866872, "step": 84000}
{"episode": 85.0, "batch_reward": 0.7028042886257172, "actor_loss": -74.85128953552245, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.942333698272705, "episode_reward": 819.6570996841493, "step": 85000}
{"episode": 86.0, "batch_reward": 0.7016399992108345, "actor_loss": -74.74250587463379, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 422.91661977767944, "episode_reward": 684.6423523630699, "step": 86000}
{"episode": 87.0, "batch_reward": 0.7014432787895203, "actor_loss": -74.67203274536134, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.35137438774109, "episode_reward": 716.5673679450933, "step": 87000}
{"episode": 86.0, "batch_reward": 0.7016399992108345, "actor_loss": -74.74250587463379, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 436.3133645057678, "episode_reward": 684.6423523630699, "step": 86000}
{"episode": 87.0, "batch_reward": 0.7014432787895203, "actor_loss": -74.67203274536134, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.183001279830933, "episode_reward": 716.5673679450933, "step": 87000}
{"episode": 88.0, "batch_reward": 0.7030950978398323, "actor_loss": -74.82239109802246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 443.7863771915436, "episode_reward": 792.006040987968, "step": 88000}
{"episode": 89.0, "batch_reward": 0.7028678308725357, "actor_loss": -74.8473461151123, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.616886615753174, "episode_reward": 768.9464123240564, "step": 89000}
{"episode": 88.0, "batch_reward": 0.7030950978398323, "actor_loss": -74.82239109802246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 443.7190754413605, "episode_reward": 792.006040987968, "step": 88000}
{"episode": 89.0, "batch_reward": 0.7028678308725357, "actor_loss": -74.8473461151123, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.256117582321167, "episode_reward": 768.9464123240564, "step": 89000}
{"episode": 90.0, "batch_reward": 0.7043770107030869, "actor_loss": -74.95735316467285, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 443.1795611381531, "episode_reward": 797.9756097220843, "step": 90000}
{"episode": 91.0, "batch_reward": 0.703541194498539, "actor_loss": -74.91385688781739, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.048474073410034, "episode_reward": 719.9148959028663, "step": 91000}
{"episode": 90.0, "batch_reward": 0.7043770107030869, "actor_loss": -74.95735316467285, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 447.9898397922516, "episode_reward": 797.9756097220843, "step": 90000}
{"episode": 91.0, "batch_reward": 0.703541194498539, "actor_loss": -74.91385688781739, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 39.85173773765564, "episode_reward": 719.9148959028663, "step": 91000}
{"episode": 92.0, "batch_reward": 0.705907145678997, "actor_loss": -74.9561795501709, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 433.31437945365906, "episode_reward": 773.2259054308735, "step": 92000}
{"episode": 93.0, "batch_reward": 0.7072984703183174, "actor_loss": -75.00277177429199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.80239224433899, "episode_reward": 786.6763278567616, "step": 93000}
{"episode": 92.0, "batch_reward": 0.705907145678997, "actor_loss": -74.9561795501709, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 440.6127259731293, "episode_reward": 773.2259054308735, "step": 92000}
{"episode": 93.0, "batch_reward": 0.7072984703183174, "actor_loss": -75.00277177429199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.869078397750854, "episode_reward": 786.6763278567616, "step": 93000}
{"episode": 94.0, "batch_reward": 0.7076758376955986, "actor_loss": -74.521935546875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 443.65267753601074, "episode_reward": 845.3398004596062, "step": 94000}
{"episode": 95.0, "batch_reward": 0.7080404302477836, "actor_loss": -74.54680563354492, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.620033264160156, "episode_reward": 820.0783869326242, "step": 95000}
{"episode": 94.0, "batch_reward": 0.7076758376955986, "actor_loss": -74.521935546875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 447.0134074687958, "episode_reward": 845.3398004596062, "step": 94000}
{"episode": 95.0, "batch_reward": 0.7080404302477836, "actor_loss": -74.54680563354492, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.213114738464355, "episode_reward": 820.0783869326242, "step": 95000}
{"episode": 96.0, "batch_reward": 0.7093569628000259, "actor_loss": -75.30521772766113, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 443.6802086830139, "episode_reward": 740.1055458969181, "step": 96000}
{"episode": 97.0, "batch_reward": 0.7095858279466629, "actor_loss": -75.30895701599121, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.83875870704651, "episode_reward": 676.5244993699235, "step": 97000}
{"episode": 96.0, "batch_reward": 0.7093569628000259, "actor_loss": -75.30521772766113, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 437.6059846878052, "episode_reward": 740.1055458969181, "step": 96000}
{"episode": 97.0, "batch_reward": 0.7095858279466629, "actor_loss": -75.30895701599121, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.959861516952515, "episode_reward": 676.5244993699235, "step": 97000}
{"episode": 98.0, "batch_reward": 0.708381051838398, "actor_loss": -75.12490295410156, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 441.3445839881897, "episode_reward": 705.4467647946362, "step": 98000}
{"episode": 99.0, "batch_reward": 0.7091661555767059, "actor_loss": -75.30610366821288, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.129329919815063, "episode_reward": 657.573053426988, "step": 99000}
{"episode": 98.0, "batch_reward": 0.708381051838398, "actor_loss": -75.12490295410156, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 455.26231575012207, "episode_reward": 705.4467647946362, "step": 98000}
{"episode": 99.0, "batch_reward": 0.7091661555767059, "actor_loss": -75.30610366821288, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.33279275894165, "episode_reward": 657.573053426988, "step": 99000}
{"episode": 100.0, "batch_reward": 0.7102095212936401, "actor_loss": -75.03669165039062, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 445.3335177898407, "episode_reward": 809.469759233945, "step": 100000}
{"episode": 101.0, "batch_reward": 0.7101282458901406, "actor_loss": -75.08474073791504, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 35.78408646583557, "episode_reward": 798.5699050543951, "step": 101000}
{"episode": 100.0, "batch_reward": 0.7102095212936401, "actor_loss": -75.03669165039062, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 442.8325901031494, "episode_reward": 809.469759233945, "step": 100000}
{"episode": 101.0, "batch_reward": 0.7101282458901406, "actor_loss": -75.08474073791504, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.4143545627594, "episode_reward": 798.5699050543951, "step": 101000}
{"episode": 102.0, "batch_reward": 0.7090899547934533, "actor_loss": -75.30804383850098, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 449.43625831604004, "episode_reward": 742.1884533183763, "step": 102000}
{"episode": 103.0, "batch_reward": 0.7105153164863587, "actor_loss": -75.31859814453125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.951695203781128, "episode_reward": 745.7848223800321, "step": 103000}
{"episode": 102.0, "batch_reward": 0.7090899547934533, "actor_loss": -75.30804383850098, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.0667521953583, "episode_reward": 742.1884533183763, "step": 102000}
{"episode": 103.0, "batch_reward": 0.7105153164863587, "actor_loss": -75.31859814453125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.89405059814453, "episode_reward": 745.7848223800321, "step": 103000}
{"episode": 104.0, "batch_reward": 0.7119238640666008, "actor_loss": -75.46160188293457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 426.52676653862, "episode_reward": 766.0683984346533, "step": 104000}
{"episode": 105.0, "batch_reward": 0.711900302529335, "actor_loss": -75.45015814208985, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.896549940109253, "episode_reward": 748.9034327150755, "step": 105000}
{"episode": 104.0, "batch_reward": 0.7119238640666008, "actor_loss": -75.46160188293457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 431.15583086013794, "episode_reward": 766.0683984346533, "step": 104000}
{"episode": 105.0, "batch_reward": 0.711900302529335, "actor_loss": -75.45015814208985, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.24499487876892, "episode_reward": 748.9034327150755, "step": 105000}
{"episode": 106.0, "batch_reward": 0.7129930285215378, "actor_loss": -75.32670515441895, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 425.5986921787262, "episode_reward": 750.3869267450139, "step": 106000}
{"episode": 107.0, "batch_reward": 0.7128264594674111, "actor_loss": -75.31571220397949, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.7298686504364, "episode_reward": 724.71033957992, "step": 107000}
{"episode": 106.0, "batch_reward": 0.7129930285215378, "actor_loss": -75.32670515441895, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 430.0128517150879, "episode_reward": 750.3869267450139, "step": 106000}
{"episode": 107.0, "batch_reward": 0.7128264594674111, "actor_loss": -75.31571220397949, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.65123701095581, "episode_reward": 724.71033957992, "step": 107000}
{"episode": 108.0, "batch_reward": 0.7136746371984481, "actor_loss": -74.86462002563476, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 428.24896597862244, "episode_reward": 769.7048470626812, "step": 108000}
{"episode": 109.0, "batch_reward": 0.7138959121704102, "actor_loss": -74.79685192871094, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.440895080566406, "episode_reward": 838.105099607055, "step": 109000}
{"episode": 108.0, "batch_reward": 0.7136746371984481, "actor_loss": -74.86462002563476, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 425.8942024707794, "episode_reward": 769.7048470626812, "step": 108000}
{"episode": 109.0, "batch_reward": 0.7138959121704102, "actor_loss": -74.79685192871094, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.940276622772217, "episode_reward": 838.105099607055, "step": 109000}
{"episode": 110.0, "batch_reward": 0.7132538139820099, "actor_loss": -74.99386161804199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 427.8096034526825, "episode_reward": 821.3909318728633, "step": 110000}
{"episode": 111.0, "batch_reward": 0.7147062214016915, "actor_loss": -74.95163154602051, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 39.784724712371826, "episode_reward": 751.9217814496465, "step": 111000}
{"episode": 110.0, "batch_reward": 0.7132538139820099, "actor_loss": -74.99386161804199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 445.5438985824585, "episode_reward": 821.3909318728633, "step": 110000}
{"episode": 111.0, "batch_reward": 0.7147062214016915, "actor_loss": -74.95163154602051, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 39.87339544296265, "episode_reward": 751.9217814496465, "step": 111000}
{"episode": 112.0, "batch_reward": 0.7152184581160546, "actor_loss": -75.24188006591797, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 448.45424008369446, "episode_reward": 765.537013859415, "step": 112000}
{"episode": 113.0, "batch_reward": 0.7159232436418533, "actor_loss": -75.22024272155761, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.93785333633423, "episode_reward": 779.8815291714303, "step": 113000}
{"episode": 112.0, "batch_reward": 0.7152184581160546, "actor_loss": -75.24188006591797, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 449.66213297843933, "episode_reward": 765.537013859415, "step": 112000}
{"episode": 113.0, "batch_reward": 0.7159232436418533, "actor_loss": -75.22024272155761, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.11796474456787, "episode_reward": 779.8815291714303, "step": 113000}
{"episode": 114.0, "batch_reward": 0.7170955629944802, "actor_loss": -75.12882287597657, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 445.4990632534027, "episode_reward": 810.8882039999562, "step": 114000}
{"episode": 115.0, "batch_reward": 0.7182167216539382, "actor_loss": -75.05869844055175, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.884418964385986, "episode_reward": 743.2614545372667, "step": 115000}
{"episode": 114.0, "batch_reward": 0.7170955629944802, "actor_loss": -75.12882287597657, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 448.7396926879883, "episode_reward": 810.8882039999562, "step": 114000}
{"episode": 115.0, "batch_reward": 0.7182167216539382, "actor_loss": -75.05869844055175, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.761568546295166, "episode_reward": 743.2614545372667, "step": 115000}
{"episode": 116.0, "batch_reward": 0.717209728360176, "actor_loss": -75.08296580505372, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 442.44322681427, "episode_reward": 754.1363456968724, "step": 116000}
{"episode": 117.0, "batch_reward": 0.7186119201779365, "actor_loss": -75.03959957885742, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.825754642486572, "episode_reward": 782.1254329015701, "step": 117000}
{"episode": 116.0, "batch_reward": 0.717209728360176, "actor_loss": -75.08296580505372, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.5668385028839, "episode_reward": 754.1363456968724, "step": 116000}
{"episode": 117.0, "batch_reward": 0.7186119201779365, "actor_loss": -75.03959957885742, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.023032903671265, "episode_reward": 782.1254329015701, "step": 117000}
{"episode": 118.0, "batch_reward": 0.7196960778236389, "actor_loss": -75.2030940246582, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 437.34156370162964, "episode_reward": 842.0065760936201, "step": 118000}
{"episode": 119.0, "batch_reward": 0.7177408581972122, "actor_loss": -75.31275735473633, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.325642108917236, "episode_reward": 822.3760052421198, "step": 119000}
{"episode": 118.0, "batch_reward": 0.7196960778236389, "actor_loss": -75.2030940246582, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 433.7053496837616, "episode_reward": 842.0065760936201, "step": 118000}
{"episode": 119.0, "batch_reward": 0.7177408581972122, "actor_loss": -75.31275735473633, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.457366943359375, "episode_reward": 822.3760052421198, "step": 119000}
{"episode": 120.0, "batch_reward": 0.720534294128418, "actor_loss": -74.97498385620118, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 441.2572317123413, "episode_reward": 760.925143760508, "step": 120000}
{"episode": 121.0, "batch_reward": 0.7219067620038986, "actor_loss": -75.15083973693848, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 39.42306852340698, "episode_reward": 670.2755051793408, "step": 121000}
{"episode": 120.0, "batch_reward": 0.720534294128418, "actor_loss": -74.97498385620118, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.60696268081665, "episode_reward": 760.925143760508, "step": 120000}
{"episode": 121.0, "batch_reward": 0.7219067620038986, "actor_loss": -75.15083973693848, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.847307443618774, "episode_reward": 670.2755051793408, "step": 121000}
{"episode": 122.0, "batch_reward": 0.7201687119007111, "actor_loss": -74.97490791320801, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 442.21209478378296, "episode_reward": 814.9458054421816, "step": 122000}
{"episode": 123.0, "batch_reward": 0.7212855914235115, "actor_loss": -75.02230667114257, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.000062465667725, "episode_reward": 783.6873638615889, "step": 123000}
{"episode": 122.0, "batch_reward": 0.7201687119007111, "actor_loss": -74.97490791320801, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 449.99167704582214, "episode_reward": 814.9458054421816, "step": 122000}
{"episode": 123.0, "batch_reward": 0.7212855914235115, "actor_loss": -75.02230667114257, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 15.967049360275269, "episode_reward": 783.6873638615889, "step": 123000}
{"episode": 124.0, "batch_reward": 0.7221927807927132, "actor_loss": -74.99217037963867, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 447.3156340122223, "episode_reward": 702.1477332003124, "step": 124000}
{"episode": 125.0, "batch_reward": 0.7219250082969666, "actor_loss": -75.11472351074218, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.442555904388428, "episode_reward": 726.5228896799057, "step": 125000}
{"episode": 124.0, "batch_reward": 0.7221927807927132, "actor_loss": -74.99217037963867, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 452.2127366065979, "episode_reward": 702.1477332003124, "step": 124000}
{"episode": 125.0, "batch_reward": 0.7219250082969666, "actor_loss": -75.11472351074218, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.728237867355347, "episode_reward": 726.5228896799057, "step": 125000}
{"episode": 126.0, "batch_reward": 0.7209016247391701, "actor_loss": -74.99565625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 445.80414056777954, "episode_reward": 713.6882145581608, "step": 126000}
{"episode": 127.0, "batch_reward": 0.7191133476495742, "actor_loss": -75.07477453613281, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.45600938796997, "episode_reward": 723.9509502483346, "step": 127000}
{"episode": 126.0, "batch_reward": 0.7209016247391701, "actor_loss": -74.99565625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 447.99470376968384, "episode_reward": 713.6882145581608, "step": 126000}
{"episode": 127.0, "batch_reward": 0.7191133476495742, "actor_loss": -75.07477453613281, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.002562999725342, "episode_reward": 723.9509502483346, "step": 127000}
{"episode": 128.0, "batch_reward": 0.7203492302894592, "actor_loss": -75.55200204467774, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 447.4723093509674, "episode_reward": 777.1349114909087, "step": 128000}
{"episode": 129.0, "batch_reward": 0.7231200767755508, "actor_loss": -75.64743768310547, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.13390851020813, "episode_reward": 735.0222087414346, "step": 129000}
{"episode": 128.0, "batch_reward": 0.7203492302894592, "actor_loss": -75.55200204467774, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 449.85007405281067, "episode_reward": 777.1349114909087, "step": 128000}
{"episode": 129.0, "batch_reward": 0.7231200767755508, "actor_loss": -75.64743768310547, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.81763529777527, "episode_reward": 735.0222087414346, "step": 129000}
{"episode": 130.0, "batch_reward": 0.7227456896901131, "actor_loss": -75.92172891235352, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.1290090084076, "episode_reward": 728.6104421434841, "step": 130000}
{"episode": 131.0, "batch_reward": 0.7217533137202263, "actor_loss": -75.84905422973632, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 36.15454626083374, "episode_reward": 767.4719049676823, "step": 131000}
{"episode": 130.0, "batch_reward": 0.7227456896901131, "actor_loss": -75.92172891235352, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 449.6525459289551, "episode_reward": 728.6104421434841, "step": 130000}
{"episode": 131.0, "batch_reward": 0.7217533137202263, "actor_loss": -75.84905422973632, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 39.78112745285034, "episode_reward": 767.4719049676823, "step": 131000}
{"episode": 132.0, "batch_reward": 0.7222132216691971, "actor_loss": -75.56851179504395, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 449.0727655887604, "episode_reward": 710.6837695369096, "step": 132000}
{"episode": 133.0, "batch_reward": 0.722782511293888, "actor_loss": -75.62375080871583, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.928186416625977, "episode_reward": 741.0631303873516, "step": 133000}
{"episode": 132.0, "batch_reward": 0.7222132216691971, "actor_loss": -75.56851179504395, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.76125288009644, "episode_reward": 710.6837695369096, "step": 132000}
{"episode": 133.0, "batch_reward": 0.722782511293888, "actor_loss": -75.62375080871583, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.641679286956787, "episode_reward": 741.0631303873516, "step": 133000}
{"episode": 134.0, "batch_reward": 0.7222999261617661, "actor_loss": -75.6748728942871, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 441.3811423778534, "episode_reward": 676.1727208215482, "step": 134000}
{"episode": 135.0, "batch_reward": 0.7200135039687157, "actor_loss": -75.68596218872071, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.469196796417236, "episode_reward": 596.6872378827497, "step": 135000}
{"episode": 134.0, "batch_reward": 0.7222999261617661, "actor_loss": -75.6748728942871, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 451.17226362228394, "episode_reward": 676.1727208215482, "step": 134000}
{"episode": 135.0, "batch_reward": 0.7200135039687157, "actor_loss": -75.68596218872071, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.529003620147705, "episode_reward": 596.6872378827497, "step": 135000}
{"episode": 136.0, "batch_reward": 0.7213199433684349, "actor_loss": -75.91283540344239, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 451.3343839645386, "episode_reward": 741.637149072853, "step": 136000}
{"episode": 137.0, "batch_reward": 0.7207194890379905, "actor_loss": -75.99273999023437, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.48307991027832, "episode_reward": 777.8359339590172, "step": 137000}
{"episode": 136.0, "batch_reward": 0.7213199433684349, "actor_loss": -75.91283540344239, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 449.61597895622253, "episode_reward": 741.637149072853, "step": 136000}
{"episode": 137.0, "batch_reward": 0.7207194890379905, "actor_loss": -75.99273999023437, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.4277241230011, "episode_reward": 777.8359339590172, "step": 137000}
{"episode": 138.0, "batch_reward": 0.7222624739408493, "actor_loss": -76.06301907348633, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 447.5319480895996, "episode_reward": 771.5725236865748, "step": 138000}
{"episode": 139.0, "batch_reward": 0.7224955899715424, "actor_loss": -76.05800123596191, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.297641277313232, "episode_reward": 754.5779282053743, "step": 139000}
{"episode": 138.0, "batch_reward": 0.7222624739408493, "actor_loss": -76.06301907348633, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 454.0241115093231, "episode_reward": 771.5725236865748, "step": 138000}
{"episode": 139.0, "batch_reward": 0.7224955899715424, "actor_loss": -76.05800123596191, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.80118179321289, "episode_reward": 754.5779282053743, "step": 139000}
{"episode": 140.0, "batch_reward": 0.7224467474818229, "actor_loss": -76.01698600769043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 452.296688079834, "episode_reward": 680.304688261471, "step": 140000}
{"episode": 141.0, "batch_reward": 0.7212471590042114, "actor_loss": -76.0359760131836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.40201258659363, "episode_reward": 744.1998993517294, "step": 141000}
{"episode": 140.0, "batch_reward": 0.7224467474818229, "actor_loss": -76.01698600769043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 451.01874470710754, "episode_reward": 680.304688261471, "step": 140000}
{"episode": 141.0, "batch_reward": 0.7212471590042114, "actor_loss": -76.0359760131836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 38.936989545822144, "episode_reward": 744.1998993517294, "step": 141000}
{"episode": 142.0, "batch_reward": 0.7212507908940315, "actor_loss": -75.8328758392334, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 437.7893588542938, "episode_reward": 540.8379413009949, "step": 142000}
{"episode": 143.0, "batch_reward": 0.7207312288284302, "actor_loss": -75.83053045654297, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 16.67035150527954, "episode_reward": 599.7099247109757, "step": 143000}
{"episode": 142.0, "batch_reward": 0.7212507908940315, "actor_loss": -75.8328758392334, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 445.1623811721802, "episode_reward": 540.8379413009949, "step": 142000}
{"episode": 143.0, "batch_reward": 0.7207312288284302, "actor_loss": -75.83053045654297, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.816662311553955, "episode_reward": 599.7099247109757, "step": 143000}
{"episode": 144.0, "batch_reward": 0.7200518242716789, "actor_loss": -75.84382331848144, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 432.75916504859924, "episode_reward": 657.2516224850259, "step": 144000}
{"episode": 145.0, "batch_reward": 0.7215808956027031, "actor_loss": -75.86546839904786, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.12189745903015, "episode_reward": 657.9790205886451, "step": 145000}
{"episode": 144.0, "batch_reward": 0.7200518242716789, "actor_loss": -75.84382331848144, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 449.14079213142395, "episode_reward": 657.2516224850259, "step": 144000}
{"episode": 145.0, "batch_reward": 0.7215808956027031, "actor_loss": -75.86546839904786, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.639517307281494, "episode_reward": 657.9790205886451, "step": 145000}
{"episode": 146.0, "batch_reward": 0.7186659076809883, "actor_loss": -75.25376502990723, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 464.45259046554565, "episode_reward": 774.5728085285534, "step": 146000}
{"episode": 147.0, "batch_reward": 0.7189153508543968, "actor_loss": -75.09140391540528, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.430211305618286, "episode_reward": 714.7419271244006, "step": 147000}
{"episode": 146.0, "batch_reward": 0.7186659076809883, "actor_loss": -75.25376502990723, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 469.6928913593292, "episode_reward": 774.5728085285534, "step": 146000}
{"episode": 147.0, "batch_reward": 0.7189153508543968, "actor_loss": -75.09140391540528, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 17.038793563842773, "episode_reward": 714.7419271244006, "step": 147000}
{"episode": 148.0, "batch_reward": 0.7193322703838348, "actor_loss": -75.18055519104004, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 494.14221358299255, "episode_reward": 727.6615725812885, "step": 148000}
{"episode": 149.0, "batch_reward": 0.7210177417397499, "actor_loss": -75.20089810180664, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 18.657654762268066, "episode_reward": 777.9272217761612, "step": 149000}
{"episode": 148.0, "batch_reward": 0.7193322703838348, "actor_loss": -75.18055519104004, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 496.85505509376526, "episode_reward": 727.6615725812885, "step": 148000}
{"episode": 149.0, "batch_reward": 0.7210177417397499, "actor_loss": -75.20089810180664, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.174086570739746, "episode_reward": 777.9272217761612, "step": 149000}
{"episode": 150.0, "batch_reward": 0.7181901261210442, "actor_loss": -74.37428202819824, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
{"episode": 150.0, "batch_reward": 0.7181901261210442, "actor_loss": -74.37428202819824, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
