{"episode": 1.0, "duration": 20.284889936447144, "episode_reward": 51.16415125024753, "step": 1000}
{"episode": 2.0, "duration": 1.7662560939788818, "episode_reward": 519.9299312670827, "step": 2000}
{"episode": 3.0, "batch_reward": 0.3124746310736744, "critic_loss": 0.6844061801496367, "actor_loss": -69.16054087345387, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 83.06445074081421, "episode_reward": 734.2586565741785, "step": 3000}
{"episode": 4.0, "batch_reward": 0.4611225853264332, "critic_loss": 0.9556816903352737, "actor_loss": -74.0814708404541, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 26.178089380264282, "episode_reward": 679.0953575279099, "step": 4000}
{"episode": 5.0, "batch_reward": 0.5148003993332386, "critic_loss": 1.1604693502187728, "actor_loss": -75.48278007507324, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.54872179031372, "episode_reward": 691.4506646742929, "step": 5000}
{"episode": 6.0, "batch_reward": 0.5566181527674198, "critic_loss": 1.204952331185341, "actor_loss": -76.54948358154297, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.486870050430298, "episode_reward": 763.5899669361872, "step": 6000}
{"episode": 7.0, "batch_reward": 0.5735821793377399, "critic_loss": 1.1925318185687066, "actor_loss": -77.1240442199707, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.570897579193115, "episode_reward": 596.35226451679, "step": 7000}
{"episode": 8.0, "batch_reward": 0.5868031957745552, "critic_loss": 1.1980111439228058, "actor_loss": -77.38650509643554, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.369251489639282, "episode_reward": 778.5957193057778, "step": 8000}
{"episode": 9.0, "batch_reward": 0.6024671449363231, "critic_loss": 1.2665134338736534, "actor_loss": -77.92353161621094, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.55868363380432, "episode_reward": 641.1653707100978, "step": 9000}
{"episode": 10.0, "batch_reward": 0.6049007810354233, "critic_loss": 1.620997746884823, "actor_loss": -72.16236808776856, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 4152.278605461121, "episode_reward": 694.1299703516164, "step": 10000}
{"episode": 11.0, "batch_reward": 0.6222713987231254, "critic_loss": 1.5223320455551148, "actor_loss": -72.87766912841796, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.40599608421326, "episode_reward": 839.0281438150136, "step": 11000}
{"episode": 12.0, "batch_reward": 0.6383311588168145, "critic_loss": 1.8423278749585152, "actor_loss": -70.39780860900879, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 523.6763010025024, "episode_reward": 711.8068292253913, "step": 12000}
{"episode": 13.0, "batch_reward": 0.6452558112740516, "critic_loss": 1.9970621811151505, "actor_loss": -70.59578228759766, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.7630033493042, "episode_reward": 794.2262576834801, "step": 13000}
{"episode": 14.0, "batch_reward": 0.6610404864549637, "critic_loss": 2.0123313658237456, "actor_loss": -69.4604457244873, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 449.43112540245056, "episode_reward": 871.0666108298968, "step": 14000}
{"episode": 15.0, "batch_reward": 0.6744213773608208, "critic_loss": 2.1210529081821443, "actor_loss": -69.99276234436036, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.299306869506836, "episode_reward": 801.6636549033763, "step": 15000}
{"episode": 16.0, "batch_reward": 0.6771130872964859, "critic_loss": 2.0997539633512496, "actor_loss": -68.99910720825196, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 442.708181142807, "episode_reward": 729.2291107201307, "step": 16000}
{"episode": 17.0, "batch_reward": 0.6816062753796578, "critic_loss": 2.0249770748615266, "actor_loss": -69.12260873413086, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.976621866226196, "episode_reward": 726.4010091783076, "step": 17000}
{"episode": 18.0, "batch_reward": 0.6861245632171631, "critic_loss": 2.038731320798397, "actor_loss": -67.99213969421386, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 472.015337228775, "episode_reward": 790.9232342844425, "step": 18000}
{"episode": 19.0, "batch_reward": 0.6924994670152664, "critic_loss": 2.053825684070587, "actor_loss": -68.31550593566895, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.48465657234192, "episode_reward": 832.7920585761455, "step": 19000}
{"episode": 20.0, "batch_reward": 0.6999354829192161, "critic_loss": 2.0502824102044106, "actor_loss": -67.53515110778808, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 440.34746646881104, "episode_reward": 819.9541778831518, "step": 20000}
{"episode": 21.0, "batch_reward": 0.7082853733897209, "critic_loss": 2.0908487824201583, "actor_loss": -67.96354658508301, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 46.041539669036865, "episode_reward": 867.9107044637732, "step": 21000}
{"episode": 22.0, "batch_reward": 0.7122250165343285, "critic_loss": 2.1161792538166044, "actor_loss": -67.38299549865722, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 496.39461183547974, "episode_reward": 806.6279676820839, "step": 22000}
{"episode": 23.0, "batch_reward": 0.7157202788591385, "critic_loss": 1.8811614691019058, "actor_loss": -67.43540351867676, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.4381320476532, "episode_reward": 780.8278982954721, "step": 23000}
{"episode": 24.0, "batch_reward": 0.7183299090266227, "critic_loss": 1.8631761074066162, "actor_loss": -66.95731689453125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 445.0227949619293, "episode_reward": 817.7335049524662, "step": 24000}
{"episode": 25.0, "batch_reward": 0.7231676108241081, "critic_loss": 1.929510502576828, "actor_loss": -67.11503231811524, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.890873193740845, "episode_reward": 787.455288969235, "step": 25000}
{"episode": 26.0, "batch_reward": 0.7211574456691742, "critic_loss": 2.038008891940117, "actor_loss": -66.78809712219238, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 486.2316176891327, "episode_reward": 623.596204945297, "step": 26000}
{"episode": 27.0, "batch_reward": 0.7223050982356072, "critic_loss": 1.8501055195331573, "actor_loss": -66.76405841064454, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.763635396957397, "episode_reward": 815.95684354461, "step": 27000}
{"episode": 28.0, "batch_reward": 0.7230220380425453, "critic_loss": 1.767570393741131, "actor_loss": -66.4566139755249, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 430.3983497619629, "episode_reward": 739.8194244105039, "step": 28000}
{"episode": 29.0, "batch_reward": 0.7285666033029556, "critic_loss": 1.7195267050862313, "actor_loss": -66.67736888122559, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.60404086112976, "episode_reward": 890.3048429660611, "step": 29000}
{"episode": 30.0, "batch_reward": 0.7316163825392723, "critic_loss": 1.685458875477314, "actor_loss": -66.85497212982177, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 473.4146182537079, "episode_reward": 776.9885351098964, "step": 30000}
{"episode": 31.0, "batch_reward": 0.7320075838565826, "critic_loss": 1.762437687933445, "actor_loss": -66.90144039916993, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.831538677215576, "episode_reward": 788.2657700620749, "step": 31000}
{"episode": 32.0, "batch_reward": 0.7325606595277786, "critic_loss": 1.8970494346022606, "actor_loss": -66.67667993164062, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.36116313934326, "episode_reward": 692.781566834007, "step": 32000}
{"episode": 33.0, "batch_reward": 0.7332815839648247, "critic_loss": 1.8670788151621818, "actor_loss": -66.68509276580811, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 26.325223684310913, "episode_reward": 848.6994956222688, "step": 33000}
{"episode": 34.0, "batch_reward": 0.7364048655033112, "critic_loss": 1.8627358617186547, "actor_loss": -66.97378501892089, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 475.418226480484, "episode_reward": 790.5417452694677, "step": 34000}
{"episode": 35.0, "batch_reward": 0.7392980577349663, "critic_loss": 1.7346825677752495, "actor_loss": -67.06485759735108, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.86697745323181, "episode_reward": 810.6100257796135, "step": 35000}
{"episode": 36.0, "batch_reward": 0.7402167814970017, "critic_loss": 1.7375638920068741, "actor_loss": -67.22263748168945, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 443.42242431640625, "episode_reward": 841.6753636001572, "step": 36000}
{"episode": 37.0, "batch_reward": 0.7434022109508515, "critic_loss": 1.725494041442871, "actor_loss": -67.40415567016602, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.320362091064453, "episode_reward": 839.944267275534, "step": 37000}
{"episode": 38.0, "batch_reward": 0.7492844581604003, "critic_loss": 1.7202726084589959, "actor_loss": -67.39622535705567, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 466.0894446372986, "episode_reward": 872.1992342729136, "step": 38000}
{"episode": 39.0, "batch_reward": 0.749433389365673, "critic_loss": 1.7301842350959777, "actor_loss": -67.4976011505127, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.69227433204651, "episode_reward": 807.2325274840414, "step": 39000}
{"episode": 40.0, "batch_reward": 0.7508612561821938, "critic_loss": 1.624615580379963, "actor_loss": -67.38449525451661, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.07439064979553, "episode_reward": 839.5463550574765, "step": 40000}
{"episode": 41.0, "batch_reward": 0.7512855180501938, "critic_loss": 1.5254333865642549, "actor_loss": -67.6729253692627, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.00962209701538, "episode_reward": 842.984253433074, "step": 41000}
{"episode": 42.0, "batch_reward": 0.7568770110607147, "critic_loss": 1.49589027094841, "actor_loss": -67.85248422241212, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 435.0521869659424, "episode_reward": 858.4217590614178, "step": 42000}
{"episode": 43.0, "batch_reward": 0.7569366930127144, "critic_loss": 1.4730143516659737, "actor_loss": -67.94146463012696, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.104190826416016, "episode_reward": 837.4163468289169, "step": 43000}
{"episode": 44.0, "batch_reward": 0.759833955347538, "critic_loss": 1.408210826933384, "actor_loss": -68.36811569213867, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 478.64759850502014, "episode_reward": 869.6556734197385, "step": 44000}
{"episode": 45.0, "batch_reward": 0.7625138491392136, "critic_loss": 1.3446773411631585, "actor_loss": -68.6690552520752, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.857614040374756, "episode_reward": 875.7777207791272, "step": 45000}
{"episode": 46.0, "batch_reward": 0.7646151342391968, "critic_loss": 1.2281230528354645, "actor_loss": -69.10597512817382, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 442.98642444610596, "episode_reward": 868.6109127153094, "step": 46000}
{"episode": 47.0, "batch_reward": 0.7670567319989204, "critic_loss": 1.213814876139164, "actor_loss": -69.23521028137208, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.006812810897827, "episode_reward": 801.1389600288347, "step": 47000}
{"episode": 48.0, "batch_reward": 0.7672743041515351, "critic_loss": 1.2807492735385895, "actor_loss": -69.48069174194336, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 444.88523507118225, "episode_reward": 802.724168003312, "step": 48000}
{"episode": 49.0, "batch_reward": 0.768377007484436, "critic_loss": 1.2058094591200352, "actor_loss": -69.56873455810548, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.79882550239563, "episode_reward": 812.5758306050744, "step": 49000}
{"episode": 50.0, "batch_reward": 0.7694460643529892, "critic_loss": 1.175867212831974, "actor_loss": -69.88799658203125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 437.57929968833923, "episode_reward": 840.7807288195702, "step": 50000}
{"episode": 51.0, "batch_reward": 0.7704544655680656, "critic_loss": 1.0904538266658783, "actor_loss": -70.0829270324707, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.49191975593567, "episode_reward": 885.1622184428676, "step": 51000}
{"episode": 52.0, "batch_reward": 0.7724415485262871, "critic_loss": 1.0434017835855485, "actor_loss": -70.56520268249511, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 465.2812452316284, "episode_reward": 852.0343472459364, "step": 52000}
{"episode": 53.0, "batch_reward": 0.7770469411611557, "critic_loss": 0.9888505534529686, "actor_loss": -70.78023733520507, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.985463857650757, "episode_reward": 866.5704808063587, "step": 53000}
{"episode": 54.0, "batch_reward": 0.7771747068166733, "critic_loss": 0.9511035982072353, "actor_loss": -71.13363772583008, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 456.0756325721741, "episode_reward": 863.840581881914, "step": 54000}
{"episode": 55.0, "batch_reward": 0.7761006744503975, "critic_loss": 0.9105298598110676, "actor_loss": -71.18225051879882, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.37942099571228, "episode_reward": 865.0938146858697, "step": 55000}
{"episode": 56.0, "batch_reward": 0.7787619059085846, "critic_loss": 0.8544468889534473, "actor_loss": -71.44545561218261, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 458.88172459602356, "episode_reward": 863.8055262590017, "step": 56000}
{"episode": 57.0, "batch_reward": 0.7812289891242981, "critic_loss": 0.8429852207005024, "actor_loss": -71.73844479370118, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 26.45507311820984, "episode_reward": 873.9894249754384, "step": 57000}
{"episode": 58.0, "batch_reward": 0.7808339093923569, "critic_loss": 0.8774694008231163, "actor_loss": -71.90208757019043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 462.2233176231384, "episode_reward": 812.3166293566425, "step": 58000}
{"episode": 59.0, "batch_reward": 0.7840153991580009, "critic_loss": 0.8136663022637367, "actor_loss": -72.14257420349121, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.712804794311523, "episode_reward": 889.66856502903, "step": 59000}
{"episode": 60.0, "batch_reward": 0.7842419041395188, "critic_loss": 0.7739625588655472, "actor_loss": -72.60046379089356, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 473.1548080444336, "episode_reward": 864.8321614900926, "step": 60000}
{"episode": 61.0, "batch_reward": 0.7853610630631447, "critic_loss": 0.7373639894127846, "actor_loss": -72.7048076019287, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.33926272392273, "episode_reward": 827.1878898052831, "step": 61000}
{"episode": 62.0, "batch_reward": 0.7880816527605057, "critic_loss": 0.6850308246016502, "actor_loss": -72.99839698791504, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 440.6674745082855, "episode_reward": 897.5873547516455, "step": 62000}
{"episode": 63.0, "batch_reward": 0.7885981167554855, "critic_loss": 0.7006928811371327, "actor_loss": -73.18934257507324, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.633288860321045, "episode_reward": 842.7953828465479, "step": 63000}
{"episode": 64.0, "batch_reward": 0.7894371782541275, "critic_loss": 0.7011758790016175, "actor_loss": -73.41533792114258, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 447.9729151725769, "episode_reward": 849.0204302534671, "step": 64000}
{"episode": 65.0, "batch_reward": 0.7908899698257447, "critic_loss": 0.6625947650372982, "actor_loss": -73.58758905029296, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.73973512649536, "episode_reward": 838.7479244134298, "step": 65000}
{"episode": 66.0, "batch_reward": 0.7925192111730576, "critic_loss": 0.6228206923604012, "actor_loss": -73.57873277282715, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 458.3578038215637, "episode_reward": 870.422570209805, "step": 66000}
{"episode": 67.0, "batch_reward": 0.7919424225687981, "critic_loss": 0.6646571733057499, "actor_loss": -73.65855224609375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.840205669403076, "episode_reward": 819.3712755074705, "step": 67000}
{"episode": 68.0, "batch_reward": 0.7944995238184929, "critic_loss": 0.6371401231884957, "actor_loss": -73.92556283569336, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 475.496399641037, "episode_reward": 859.5669765064488, "step": 68000}
{"episode": 69.0, "batch_reward": 0.7954318547844886, "critic_loss": 0.635385155081749, "actor_loss": -74.01507745361329, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.733569622039795, "episode_reward": 872.7762255123902, "step": 69000}
{"episode": 70.0, "batch_reward": 0.7943556807041168, "critic_loss": 0.6761369698643684, "actor_loss": -74.34741557312012, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 465.26922965049744, "episode_reward": 832.9645408834433, "step": 70000}
{"episode": 71.0, "batch_reward": 0.7950019299983978, "critic_loss": 0.643496070355177, "actor_loss": -74.4776967163086, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.0728394985199, "episode_reward": 869.979939145241, "step": 71000}
{"episode": 72.0, "batch_reward": 0.7941235783100128, "critic_loss": 0.6755862238109112, "actor_loss": -74.58605213928223, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 463.00977873802185, "episode_reward": 807.2387363435379, "step": 72000}
{"episode": 73.0, "batch_reward": 0.7967675594687462, "critic_loss": 0.6776692554652691, "actor_loss": -74.74676155090332, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.06399440765381, "episode_reward": 820.0948908510563, "step": 73000}
{"episode": 74.0, "batch_reward": 0.7971265321373939, "critic_loss": 0.6786577875316143, "actor_loss": -74.89254132080079, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 447.23302698135376, "episode_reward": 834.7692664916423, "step": 74000}
{"episode": 75.0, "batch_reward": 0.7974069922566414, "critic_loss": 0.6620528196394444, "actor_loss": -75.04479629516601, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.508549451828003, "episode_reward": 879.885973072475, "step": 75000}
{"episode": 76.0, "batch_reward": 0.7977198526859284, "critic_loss": 0.6317706540375948, "actor_loss": -75.23251861572265, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 458.1400134563446, "episode_reward": 869.9578290737745, "step": 76000}
{"episode": 77.0, "batch_reward": 0.8001340680718422, "critic_loss": 0.6257080367356539, "actor_loss": -75.48704898071288, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.462043046951294, "episode_reward": 904.9626032184278, "step": 77000}
{"episode": 78.0, "batch_reward": 0.8002224519252777, "critic_loss": 0.6116219853311777, "actor_loss": -75.53633065795898, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 455.2345314025879, "episode_reward": 858.9652982518892, "step": 78000}
{"episode": 79.0, "batch_reward": 0.8019085113406181, "critic_loss": 0.5801616815030575, "actor_loss": -75.76880018615722, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.49622917175293, "episode_reward": 869.1087410857748, "step": 79000}
{"episode": 80.0, "batch_reward": 0.8030556131601334, "critic_loss": 0.5838828705847263, "actor_loss": -75.94872805786133, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 462.2559609413147, "episode_reward": 901.1598317604715, "step": 80000}
{"episode": 81.0, "batch_reward": 0.8038934376835823, "critic_loss": 0.5516503947675229, "actor_loss": -76.2071343536377, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.33534860610962, "episode_reward": 856.3884058885869, "step": 81000}
{"episode": 82.0, "batch_reward": 0.8039636942744255, "critic_loss": 0.5507807143926621, "actor_loss": -76.28774595642089, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 450.15430331230164, "episode_reward": 896.2974159551201, "step": 82000}
{"episode": 83.0, "batch_reward": 0.8059636344313621, "critic_loss": 0.5532290890216828, "actor_loss": -76.46455847167968, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 27.105822801589966, "episode_reward": 875.6854368219462, "step": 83000}
{"episode": 84.0, "batch_reward": 0.8054995710849762, "critic_loss": 0.5239085674881935, "actor_loss": -76.57686056518554, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 429.5523054599762, "episode_reward": 822.3254669001979, "step": 84000}
{"episode": 85.0, "batch_reward": 0.8072792507410049, "critic_loss": 0.5082305815666914, "actor_loss": -76.7639267578125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.57090711593628, "episode_reward": 883.5779932852219, "step": 85000}
{"episode": 86.0, "batch_reward": 0.8076162822842597, "critic_loss": 0.5296232635974885, "actor_loss": -77.04375173950196, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 440.528115272522, "episode_reward": 866.3950811950169, "step": 86000}
{"episode": 87.0, "batch_reward": 0.8080849075913429, "critic_loss": 0.5114158636033534, "actor_loss": -77.20133515930176, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.846451997756958, "episode_reward": 865.1069572549632, "step": 87000}
{"episode": 88.0, "batch_reward": 0.8092794514298439, "critic_loss": 0.4979398280978203, "actor_loss": -77.39627043151856, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 480.64504766464233, "episode_reward": 896.9056382673405, "step": 88000}
{"episode": 89.0, "batch_reward": 0.8103246224522591, "critic_loss": 0.4841413817554712, "actor_loss": -77.51022836303711, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.266894102096558, "episode_reward": 904.1146118821098, "step": 89000}
{"episode": 90.0, "batch_reward": 0.8119428347349167, "critic_loss": 0.4769300087839365, "actor_loss": -77.63437603759766, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 485.12616086006165, "episode_reward": 902.8104343508732, "step": 90000}
{"episode": 91.0, "batch_reward": 0.8121888070106507, "critic_loss": 0.47663414022326467, "actor_loss": -77.82767987060546, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.28034973144531, "episode_reward": 835.1440323951168, "step": 91000}
{"episode": 92.0, "batch_reward": 0.8144001355171203, "critic_loss": 0.4694122805148363, "actor_loss": -77.96009437561035, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 445.6287305355072, "episode_reward": 901.9785199114446, "step": 92000}
{"episode": 93.0, "batch_reward": 0.8142808972597122, "critic_loss": 0.45950404977798465, "actor_loss": -78.16383265686035, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.77259373664856, "episode_reward": 895.5026607682686, "step": 93000}
{"episode": 94.0, "batch_reward": 0.8144949117898941, "critic_loss": 0.4641123069375753, "actor_loss": -78.33315496826172, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 468.48453307151794, "episode_reward": 898.9917824592958, "step": 94000}
{"episode": 95.0, "batch_reward": 0.8158133190274238, "critic_loss": 0.4449711707532406, "actor_loss": -78.50699606323242, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.890157222747803, "episode_reward": 885.0109062122835, "step": 95000}
{"episode": 96.0, "batch_reward": 0.8158103105425835, "critic_loss": 0.44658911307156085, "actor_loss": -78.65094581604004, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 439.59811449050903, "episode_reward": 871.8608528908601, "step": 96000}
{"episode": 97.0, "batch_reward": 0.8158913984298706, "critic_loss": 0.4406168629527092, "actor_loss": -78.84444744873046, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.289183616638184, "episode_reward": 877.8254379330048, "step": 97000}
{"episode": 98.0, "batch_reward": 0.8162068390250206, "critic_loss": 0.431566585034132, "actor_loss": -78.7971198272705, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 465.70275592803955, "episode_reward": 881.0862417854714, "step": 98000}
{"episode": 99.0, "batch_reward": 0.8185944163203239, "critic_loss": 0.42235691206157205, "actor_loss": -79.10996922302246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.637030363082886, "episode_reward": 890.5424011217776, "step": 99000}
{"episode": 100.0, "batch_reward": 0.8171226713061333, "critic_loss": 0.42018932569026946, "actor_loss": -79.11981101989745, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 448.8373951911926, "episode_reward": 905.0760294082071, "step": 100000}
{"episode": 101.0, "batch_reward": 0.8182029401659966, "critic_loss": 0.413611549988389, "actor_loss": -79.34745657348633, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.542847633361816, "episode_reward": 898.57362951828, "step": 101000}
{"episode": 102.0, "batch_reward": 0.8199294766187668, "critic_loss": 0.42059632237255573, "actor_loss": -79.47377262878418, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 434.7716295719147, "episode_reward": 888.4349430866093, "step": 102000}
{"episode": 103.0, "batch_reward": 0.8205705343484878, "critic_loss": 0.4392632906138897, "actor_loss": -79.63866015625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.60427165031433, "episode_reward": 888.9277287376152, "step": 103000}
{"episode": 104.0, "batch_reward": 0.8222035628557205, "critic_loss": 0.42945249772071836, "actor_loss": -79.97168617248535, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 470.50737261772156, "episode_reward": 898.8965976269252, "step": 104000}
{"episode": 105.0, "batch_reward": 0.8219009007811546, "critic_loss": 0.3968896364569664, "actor_loss": -80.12162065124512, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.58871340751648, "episode_reward": 901.9329536047059, "step": 105000}
{"episode": 106.0, "batch_reward": 0.8233026134371757, "critic_loss": 0.39885036374628546, "actor_loss": -80.31687831115723, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 434.262579202652, "episode_reward": 864.6615697851169, "step": 106000}
{"episode": 107.0, "batch_reward": 0.8216259212493896, "critic_loss": 0.3933855622410774, "actor_loss": -80.38077905273437, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.654531717300415, "episode_reward": 856.6546910204574, "step": 107000}
{"episode": 108.0, "batch_reward": 0.8233643775582313, "critic_loss": 0.36553103721141816, "actor_loss": -80.70326432800293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 491.0763785839081, "episode_reward": 772.5437688748686, "step": 108000}
{"episode": 109.0, "batch_reward": 0.8237425097823143, "critic_loss": 0.35329106299579144, "actor_loss": -80.81358535766601, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 28.05132293701172, "episode_reward": 892.3438268957058, "step": 109000}
{"episode": 110.0, "batch_reward": 0.8237596549391747, "critic_loss": 0.35490994673967363, "actor_loss": -80.97545863342285, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 450.55941438674927, "episode_reward": 882.3814361272891, "step": 110000}
{"episode": 111.0, "batch_reward": 0.8239226282238961, "critic_loss": 0.3618905497640371, "actor_loss": -81.1797537689209, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 44.90633535385132, "episode_reward": 874.0516477248926, "step": 111000}
{"episode": 112.0, "batch_reward": 0.8238223202824593, "critic_loss": 0.36467448000609876, "actor_loss": -81.44058082580567, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 442.7352855205536, "episode_reward": 890.3091995057588, "step": 112000}
{"episode": 113.0, "batch_reward": 0.8259815136790276, "critic_loss": 0.3593630259037018, "actor_loss": -81.57355049133301, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.494027376174927, "episode_reward": 847.2147274336764, "step": 113000}
{"episode": 114.0, "batch_reward": 0.8252090086936951, "critic_loss": 0.37966987769305705, "actor_loss": -81.72589991760253, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 444.5121943950653, "episode_reward": 902.3688152968344, "step": 114000}
{"episode": 115.0, "batch_reward": 0.825829851090908, "critic_loss": 0.37185793306678533, "actor_loss": -81.94254646301269, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.578701496124268, "episode_reward": 875.4211500474182, "step": 115000}
{"episode": 116.0, "batch_reward": 0.8278874730467797, "critic_loss": 0.3798761374056339, "actor_loss": -82.05860627746583, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 451.5880539417267, "episode_reward": 889.0509871535911, "step": 116000}
{"episode": 117.0, "batch_reward": 0.8269449251294136, "critic_loss": 0.3903248042166233, "actor_loss": -82.23854597473145, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.384652137756348, "episode_reward": 882.7130675154339, "step": 117000}
{"episode": 118.0, "batch_reward": 0.8271073549389839, "critic_loss": 0.3869784414470196, "actor_loss": -82.32138641357422, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 428.5214982032776, "episode_reward": 893.8216475524964, "step": 118000}
{"episode": 119.0, "batch_reward": 0.8288268854618073, "critic_loss": 0.37121957187354565, "actor_loss": -82.565677444458, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.578187942504883, "episode_reward": 886.4841082677001, "step": 119000}
{"episode": 120.0, "batch_reward": 0.8282384687662124, "critic_loss": 0.37031402917206285, "actor_loss": -82.68698335266113, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 444.64571809768677, "episode_reward": 893.7027109337141, "step": 120000}
{"episode": 121.0, "batch_reward": 0.8296989112496376, "critic_loss": 0.3500756102651358, "actor_loss": -82.94119032287598, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.51932501792908, "episode_reward": 846.5601372006922, "step": 121000}
{"episode": 122.0, "batch_reward": 0.8295205651521683, "critic_loss": 0.35801690378785134, "actor_loss": -83.01876788330078, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 463.0488495826721, "episode_reward": 890.030159800288, "step": 122000}
{"episode": 123.0, "batch_reward": 0.829875541985035, "critic_loss": 0.3499329924285412, "actor_loss": -83.20331704711914, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.635045766830444, "episode_reward": 897.2865226964016, "step": 123000}
{"episode": 124.0, "batch_reward": 0.831090058028698, "critic_loss": 0.32452500697225334, "actor_loss": -83.44906483459472, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 476.4786694049835, "episode_reward": 913.2950466682511, "step": 124000}
{"episode": 125.0, "batch_reward": 0.8314330792427063, "critic_loss": 0.3125340384095907, "actor_loss": -83.57850996398926, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.532138109207153, "episode_reward": 911.4667592137594, "step": 125000}
{"episode": 126.0, "batch_reward": 0.8310795004963875, "critic_loss": 0.3073910324051976, "actor_loss": -83.72515800476074, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.9718163013458, "episode_reward": 908.8903077152811, "step": 126000}
{"episode": 127.0, "batch_reward": 0.8317349998950958, "critic_loss": 0.30213541322946547, "actor_loss": -83.9000623474121, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.821417331695557, "episode_reward": 880.422367596374, "step": 127000}
{"episode": 128.0, "batch_reward": 0.8311552433371544, "critic_loss": 0.30704415155947207, "actor_loss": -84.00475259399414, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 436.6896495819092, "episode_reward": 911.9635936616787, "step": 128000}
{"episode": 129.0, "batch_reward": 0.8326633512377739, "critic_loss": 0.2962694184184074, "actor_loss": -84.2216019744873, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.974472761154175, "episode_reward": 901.0384651281512, "step": 129000}
{"episode": 130.0, "batch_reward": 0.8320634142160416, "critic_loss": 0.3063706751540303, "actor_loss": -84.30964944458007, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 468.87048506736755, "episode_reward": 886.1601171383664, "step": 130000}
{"episode": 131.0, "batch_reward": 0.8342281584143638, "critic_loss": 0.31177073550224305, "actor_loss": -84.53474383544922, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.50873827934265, "episode_reward": 811.1435987790998, "step": 131000}
{"episode": 132.0, "batch_reward": 0.8338997277021408, "critic_loss": 0.3112515392675996, "actor_loss": -84.59380056762696, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 462.9024443626404, "episode_reward": 822.2473372011927, "step": 132000}
{"episode": 133.0, "batch_reward": 0.8340949752926826, "critic_loss": 0.31362219257652757, "actor_loss": -84.78249588012696, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.23014187812805, "episode_reward": 892.1967330021249, "step": 133000}
{"episode": 134.0, "batch_reward": 0.8344754629135132, "critic_loss": 0.32282141160964967, "actor_loss": -84.93395269775391, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 489.6980881690979, "episode_reward": 859.8325323515298, "step": 134000}
{"episode": 135.0, "batch_reward": 0.8346691500544549, "critic_loss": 0.31305362344533205, "actor_loss": -85.02583171081542, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.492242336273193, "episode_reward": 860.9391042395156, "step": 135000}
{"episode": 136.0, "batch_reward": 0.8346614200472832, "critic_loss": 0.33001968201994897, "actor_loss": -85.16130058288574, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 471.1290545463562, "episode_reward": 894.9559869021701, "step": 136000}
{"episode": 137.0, "batch_reward": 0.833905458509922, "critic_loss": 0.31714165718108417, "actor_loss": -85.25370346069336, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.315545320510864, "episode_reward": 910.4778133998577, "step": 137000}
{"episode": 138.0, "batch_reward": 0.8353714345693588, "critic_loss": 0.30684311021864413, "actor_loss": -85.45141319274903, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 461.4533221721649, "episode_reward": 911.5864036931079, "step": 138000}
{"episode": 139.0, "batch_reward": 0.8360843105316162, "critic_loss": 0.30548666580021383, "actor_loss": -85.59473960876466, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.688257217407227, "episode_reward": 886.593904665076, "step": 139000}
{"episode": 140.0, "batch_reward": 0.836555492401123, "critic_loss": 0.30578782194852827, "actor_loss": -85.78996580505371, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 456.5067090988159, "episode_reward": 904.1835654846458, "step": 140000}
{"episode": 141.0, "batch_reward": 0.8359783105254174, "critic_loss": 0.3187432559579611, "actor_loss": -85.91294195556641, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.643471240997314, "episode_reward": 836.7292445740811, "step": 141000}
{"episode": 142.0, "batch_reward": 0.8371817520856857, "critic_loss": 0.3178237914890051, "actor_loss": -86.04797315979003, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 477.80128502845764, "episode_reward": 893.3421437961674, "step": 142000}
{"episode": 143.0, "batch_reward": 0.8372283812761306, "critic_loss": 0.31935156086087224, "actor_loss": -86.19459530639648, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.110320568084717, "episode_reward": 899.5750741415701, "step": 143000}
{"episode": 144.0, "batch_reward": 0.8370547942519188, "critic_loss": 0.2990518972426653, "actor_loss": -86.31984065246581, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 441.95085048675537, "episode_reward": 847.3671050093092, "step": 144000}
{"episode": 145.0, "batch_reward": 0.8374938712120056, "critic_loss": 0.31289759775996207, "actor_loss": -86.45426699829102, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 26.454220294952393, "episode_reward": 807.8725283482421, "step": 145000}
{"episode": 146.0, "batch_reward": 0.8381980076432228, "critic_loss": 0.29964474610984326, "actor_loss": -86.59190814208985, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 472.10075330734253, "episode_reward": 904.1034534996309, "step": 146000}
{"episode": 147.0, "batch_reward": 0.8386887772679329, "critic_loss": 0.3173133793473244, "actor_loss": -86.76813848876954, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 26.59216332435608, "episode_reward": 873.6866810643877, "step": 147000}
{"episode": 148.0, "batch_reward": 0.839018305182457, "critic_loss": 0.330597467854619, "actor_loss": -86.8467145690918, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 423.8952612876892, "episode_reward": 890.5621694990547, "step": 148000}
{"episode": 149.0, "batch_reward": 0.8376758079528809, "critic_loss": 0.3326449796259403, "actor_loss": -86.97877177429199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.351521492004395, "episode_reward": 889.753539510644, "step": 149000}
{"episode": 150.0, "batch_reward": 0.8393708400726319, "critic_loss": 0.35261364836990833, "actor_loss": -87.06456675720214, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
