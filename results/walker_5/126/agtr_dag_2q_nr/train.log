{"episode": 1.0, "duration": 20.38687038421631, "episode_reward": 51.16415125024753, "step": 1000}
{"episode": 2.0, "duration": 1.7536332607269287, "episode_reward": 519.9299312670827, "step": 2000}
{"episode": 3.0, "batch_reward": 0.3124746310736744, "critic_loss": 0.6844061801496367, "actor_loss": -69.16054087345387, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 70.50873446464539, "episode_reward": 734.2586565741785, "step": 3000}
{"episode": 4.0, "batch_reward": 0.4611225853264332, "critic_loss": 0.9556816903352737, "actor_loss": -74.0814708404541, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.912526845932007, "episode_reward": 679.0953575279099, "step": 4000}
{"episode": 5.0, "batch_reward": 0.5148003993332386, "critic_loss": 1.1604693502187728, "actor_loss": -75.48278007507324, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.65511727333069, "episode_reward": 691.4506646742929, "step": 5000}
{"episode": 6.0, "batch_reward": 0.5566181527674198, "critic_loss": 1.204952331185341, "actor_loss": -76.54948358154297, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.598121643066406, "episode_reward": 763.5899669361872, "step": 6000}
{"episode": 7.0, "batch_reward": 0.5735821793377399, "critic_loss": 1.1925318185687066, "actor_loss": -77.1240442199707, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.213184118270874, "episode_reward": 596.35226451679, "step": 7000}
{"episode": 8.0, "batch_reward": 0.5868031957745552, "critic_loss": 1.1980111439228058, "actor_loss": -77.38650509643554, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.021386861801147, "episode_reward": 778.5957193057778, "step": 8000}
{"episode": 9.0, "batch_reward": 0.6024671449363231, "critic_loss": 1.2665134338736534, "actor_loss": -77.92353161621094, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.36492085456848, "episode_reward": 641.1653707100978, "step": 9000}
{"episode": 10.0, "batch_reward": 0.6049007810354233, "critic_loss": 1.620997746884823, "actor_loss": -72.16236808776856, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 3652.424310207367, "episode_reward": 694.1299703516164, "step": 10000}
{"episode": 11.0, "batch_reward": 0.6222713987231254, "critic_loss": 1.5223320455551148, "actor_loss": -72.87766912841796, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.79869222640991, "episode_reward": 839.0281438150136, "step": 11000}
{"episode": 12.0, "batch_reward": 0.6383311588168145, "critic_loss": 1.8423278749585152, "actor_loss": -70.39780860900879, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 451.2429759502411, "episode_reward": 711.8068292253913, "step": 12000}
{"episode": 13.0, "batch_reward": 0.6452558112740516, "critic_loss": 1.9970621811151505, "actor_loss": -70.59578228759766, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.814739227294922, "episode_reward": 794.2262576834801, "step": 13000}
{"episode": 14.0, "batch_reward": 0.6610404864549637, "critic_loss": 2.0123313658237456, "actor_loss": -69.4604457244873, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 456.6394166946411, "episode_reward": 871.0666108298968, "step": 14000}
{"episode": 15.0, "batch_reward": 0.6744213773608208, "critic_loss": 2.1210529081821443, "actor_loss": -69.99276234436036, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.524510145187378, "episode_reward": 801.6636549033763, "step": 15000}
{"episode": 16.0, "batch_reward": 0.6816420421004296, "critic_loss": 2.035529150247574, "actor_loss": -69.31774890136718, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 427.49552726745605, "episode_reward": 856.5997454013666, "step": 16000}
{"episode": 17.0, "batch_reward": 0.690379016160965, "critic_loss": 2.0030815225839613, "actor_loss": -69.56811784362793, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.655841827392578, "episode_reward": 730.8072955121276, "step": 17000}
{"episode": 18.0, "batch_reward": 0.6910560986995697, "critic_loss": 2.0533358340263366, "actor_loss": -68.65033868408203, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 429.30049180984497, "episode_reward": 693.0753697555322, "step": 18000}
{"episode": 19.0, "batch_reward": 0.6926819254159927, "critic_loss": 2.157902841091156, "actor_loss": -68.62787976074219, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.410223484039307, "episode_reward": 735.4151108512278, "step": 19000}
{"episode": 20.0, "batch_reward": 0.6953980603218078, "critic_loss": 2.250917938232422, "actor_loss": -67.88861795806885, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 421.65132451057434, "episode_reward": 788.3241527363997, "step": 20000}
{"episode": 21.0, "batch_reward": 0.7019001921415329, "critic_loss": 2.268849847316742, "actor_loss": -68.10159895324708, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.84994339942932, "episode_reward": 802.9265417292353, "step": 21000}
{"episode": 22.0, "batch_reward": 0.7039807538986206, "critic_loss": 2.4518511439561843, "actor_loss": -67.30306623840332, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 430.8426585197449, "episode_reward": 729.5790577457904, "step": 22000}
{"episode": 23.0, "batch_reward": 0.7063481714129448, "critic_loss": 2.3236716949939726, "actor_loss": -67.25147401428222, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.231961488723755, "episode_reward": 802.7259940084568, "step": 23000}
{"episode": 24.0, "batch_reward": 0.7109109787940979, "critic_loss": 2.2812307752370833, "actor_loss": -66.53385639190674, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 423.84707736968994, "episode_reward": 879.0613421772352, "step": 24000}
{"episode": 25.0, "batch_reward": 0.7199168048501015, "critic_loss": 2.329457134604454, "actor_loss": -66.87584702301025, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.520124435424805, "episode_reward": 857.1955200277391, "step": 25000}
{"episode": 26.0, "batch_reward": 0.7221860400438309, "critic_loss": 2.282560983777046, "actor_loss": -66.21271073913574, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 415.4188048839569, "episode_reward": 829.4491294653583, "step": 26000}
{"episode": 27.0, "batch_reward": 0.7283560575246811, "critic_loss": 2.2766910593509673, "actor_loss": -66.46759300231933, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.533396244049072, "episode_reward": 846.1327391574337, "step": 27000}
{"episode": 28.0, "batch_reward": 0.7305635618567466, "critic_loss": 2.211067911028862, "actor_loss": -65.88583892059326, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 433.64118003845215, "episode_reward": 826.6386688387812, "step": 28000}
{"episode": 29.0, "batch_reward": 0.7374249731898308, "critic_loss": 2.0834675540924072, "actor_loss": -66.17255449676513, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.435086727142334, "episode_reward": 891.0488907934262, "step": 29000}
{"episode": 30.0, "batch_reward": 0.7383400379419327, "critic_loss": 2.1394613683223724, "actor_loss": -66.10660862731933, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 447.3579294681549, "episode_reward": 775.3610578744049, "step": 30000}
{"episode": 31.0, "batch_reward": 0.7404341624975205, "critic_loss": 2.095816071987152, "actor_loss": -66.1876293182373, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.21152091026306, "episode_reward": 779.7090967919563, "step": 31000}
{"episode": 32.0, "batch_reward": 0.741988149881363, "critic_loss": 2.008168568253517, "actor_loss": -65.83188073730469, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 414.5544149875641, "episode_reward": 871.9802756218347, "step": 32000}
{"episode": 33.0, "batch_reward": 0.7467100315690041, "critic_loss": 1.88046209359169, "actor_loss": -66.00163397216797, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.2906756401062, "episode_reward": 873.697408180397, "step": 33000}
{"episode": 34.0, "batch_reward": 0.75068570125103, "critic_loss": 1.8450553693771363, "actor_loss": -66.62438359832764, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 467.14078187942505, "episode_reward": 832.7258485124478, "step": 34000}
{"episode": 35.0, "batch_reward": 0.7535582852959632, "critic_loss": 1.8357359548807144, "actor_loss": -66.66544652557373, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.16205644607544, "episode_reward": 871.0338811357983, "step": 35000}
{"episode": 36.0, "batch_reward": 0.7547564878463745, "critic_loss": 1.8572209158539772, "actor_loss": -66.679137008667, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 515.4856851100922, "episode_reward": 806.0828269379047, "step": 36000}
{"episode": 37.0, "batch_reward": 0.7575819265842437, "critic_loss": 1.8754106447696686, "actor_loss": -66.75789476013183, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.86153483390808, "episode_reward": 820.53189114321, "step": 37000}
{"episode": 38.0, "batch_reward": 0.7613876246213913, "critic_loss": 1.71659103089571, "actor_loss": -66.77922912597656, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 478.6192581653595, "episode_reward": 896.8228914345482, "step": 38000}
{"episode": 39.0, "batch_reward": 0.7631145516633987, "critic_loss": 1.6311510174274444, "actor_loss": -67.00099645996093, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 28.21535038948059, "episode_reward": 862.31959104673, "step": 39000}
{"episode": 40.0, "batch_reward": 0.7646924498081207, "critic_loss": 1.5969539129137993, "actor_loss": -66.93621034240722, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 568.9568552970886, "episode_reward": 829.4440294840979, "step": 40000}
{"episode": 41.0, "batch_reward": 0.7662932935953141, "critic_loss": 1.5675350530147552, "actor_loss": -67.16254995727539, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.721564531326294, "episode_reward": 834.7234683019753, "step": 41000}
{"episode": 42.0, "batch_reward": 0.7686689443588257, "critic_loss": 1.55654868632555, "actor_loss": -67.1717537536621, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 491.2477197647095, "episode_reward": 857.9517463449711, "step": 42000}
{"episode": 43.0, "batch_reward": 0.7702526869773865, "critic_loss": 1.5270445639491081, "actor_loss": -67.33650938415528, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.487684965133667, "episode_reward": 829.1968518378699, "step": 43000}
{"episode": 44.0, "batch_reward": 0.7719865972995759, "critic_loss": 1.4809741033911705, "actor_loss": -67.51116404724121, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 421.63072633743286, "episode_reward": 877.3384145397, "step": 44000}
{"episode": 45.0, "batch_reward": 0.7749513626098633, "critic_loss": 1.3787535517811775, "actor_loss": -67.80912643432617, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.50219416618347, "episode_reward": 882.0890905339348, "step": 45000}
{"episode": 46.0, "batch_reward": 0.7779860751628875, "critic_loss": 1.3650119343996048, "actor_loss": -68.14511599731445, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 436.1334578990936, "episode_reward": 890.3720953010815, "step": 46000}
{"episode": 47.0, "batch_reward": 0.7798737157583236, "critic_loss": 1.3530906755924226, "actor_loss": -68.28680308532715, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.77025079727173, "episode_reward": 844.0084110894028, "step": 47000}
{"episode": 48.0, "batch_reward": 0.7814972062110901, "critic_loss": 1.272804636478424, "actor_loss": -68.47123159790038, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 478.7943880558014, "episode_reward": 836.1592344188003, "step": 48000}
{"episode": 49.0, "batch_reward": 0.7828268384933472, "critic_loss": 1.1711190150380135, "actor_loss": -68.56002989196777, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 26.343842267990112, "episode_reward": 844.3294581179011, "step": 49000}
{"episode": 50.0, "batch_reward": 0.7818373777866363, "critic_loss": 1.181291168153286, "actor_loss": -68.94023970031738, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 530.371851682663, "episode_reward": 791.8818463277711, "step": 50000}
{"episode": 51.0, "batch_reward": 0.7824946537613868, "critic_loss": 1.1531643540263177, "actor_loss": -69.17120620727539, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.42099642753601, "episode_reward": 856.1017005895861, "step": 51000}
{"episode": 52.0, "batch_reward": 0.7843934420347214, "critic_loss": 1.153161733686924, "actor_loss": -69.13935679626465, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 474.4142596721649, "episode_reward": 849.1251623657694, "step": 52000}
{"episode": 53.0, "batch_reward": 0.787561951994896, "critic_loss": 1.0531762129664421, "actor_loss": -69.34184844970703, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.52183771133423, "episode_reward": 842.3877556251624, "step": 53000}
{"episode": 54.0, "batch_reward": 0.7867437658309937, "critic_loss": 1.1032267689406872, "actor_loss": -69.41576751708985, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 433.23033618927, "episode_reward": 809.6891029602266, "step": 54000}
{"episode": 55.0, "batch_reward": 0.7860809434652328, "critic_loss": 1.0742190117239951, "actor_loss": -69.45099761962891, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.579793691635132, "episode_reward": 858.7877649216532, "step": 55000}
{"episode": 56.0, "batch_reward": 0.7871457965970039, "critic_loss": 1.0493401739597321, "actor_loss": -69.71502857971191, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 461.94741559028625, "episode_reward": 873.9724396226554, "step": 56000}
{"episode": 57.0, "batch_reward": 0.7891324821710587, "critic_loss": 0.9829272358417511, "actor_loss": -69.9018711090088, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.513541221618652, "episode_reward": 858.5023649039296, "step": 57000}
{"episode": 58.0, "batch_reward": 0.7893876816630363, "critic_loss": 0.9656720981001854, "actor_loss": -69.73866075134278, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 455.60016679763794, "episode_reward": 829.3872320735932, "step": 58000}
{"episode": 59.0, "batch_reward": 0.7921907234191895, "critic_loss": 0.9519934114217758, "actor_loss": -70.00446813964844, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.928675174713135, "episode_reward": 883.6299105430855, "step": 59000}
{"episode": 60.0, "batch_reward": 0.7924445947408676, "critic_loss": 0.9301644222438336, "actor_loss": -70.22464318847656, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 444.08079528808594, "episode_reward": 834.4047143778375, "step": 60000}
{"episode": 61.0, "batch_reward": 0.7932158916592598, "critic_loss": 0.8896088406443596, "actor_loss": -70.39396026611328, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.948070764541626, "episode_reward": 821.2946498467768, "step": 61000}
{"episode": 62.0, "batch_reward": 0.7948172347545623, "critic_loss": 0.8455543667376041, "actor_loss": -70.45093371582031, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 463.910338640213, "episode_reward": 880.1053324796513, "step": 62000}
{"episode": 63.0, "batch_reward": 0.7949722979664803, "critic_loss": 0.8058442852795124, "actor_loss": -70.62095518493652, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.644970178604126, "episode_reward": 881.7083079917974, "step": 63000}
{"episode": 64.0, "batch_reward": 0.7974756514430046, "critic_loss": 0.7653564928472042, "actor_loss": -70.81886022949219, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 441.0893976688385, "episode_reward": 871.689289311782, "step": 64000}
{"episode": 65.0, "batch_reward": 0.7986006140708923, "critic_loss": 0.7632075235247612, "actor_loss": -70.96432530212402, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.488884925842285, "episode_reward": 829.2410967321566, "step": 65000}
{"episode": 66.0, "batch_reward": 0.8005259990692138, "critic_loss": 0.7025502931475639, "actor_loss": -71.1350048675537, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 433.45187163352966, "episode_reward": 886.4163874002534, "step": 66000}
{"episode": 67.0, "batch_reward": 0.8001978726387023, "critic_loss": 0.7416255736649037, "actor_loss": -71.15771542358398, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.534149408340454, "episode_reward": 815.8920233733129, "step": 67000}
{"episode": 68.0, "batch_reward": 0.8020390105843545, "critic_loss": 0.714941253900528, "actor_loss": -71.22262762451172, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 414.7968316078186, "episode_reward": 836.6528559809965, "step": 68000}
{"episode": 69.0, "batch_reward": 0.8022914539575576, "critic_loss": 0.6989296540021896, "actor_loss": -71.2853179473877, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.459494590759277, "episode_reward": 881.8426594841814, "step": 69000}
{"episode": 70.0, "batch_reward": 0.7995784356594086, "critic_loss": 0.7196809140741826, "actor_loss": -71.26407368469238, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 445.8000690937042, "episode_reward": 755.6843714582951, "step": 70000}
{"episode": 71.0, "batch_reward": 0.8020079771280288, "critic_loss": 0.6802709105014801, "actor_loss": -71.4127078704834, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.64963150024414, "episode_reward": 862.1838734121708, "step": 71000}
{"episode": 72.0, "batch_reward": 0.8006346282362938, "critic_loss": 0.6327131143510342, "actor_loss": -71.50818873596191, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 436.67601776123047, "episode_reward": 827.1718207968403, "step": 72000}
{"episode": 73.0, "batch_reward": 0.803856549680233, "critic_loss": 0.6449297981858253, "actor_loss": -71.73284301757812, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.482479333877563, "episode_reward": 873.2318505018342, "step": 73000}
{"episode": 74.0, "batch_reward": 0.8037758694887162, "critic_loss": 0.6469865725636482, "actor_loss": -71.74191134643554, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 454.99733233451843, "episode_reward": 856.2981073543629, "step": 74000}
{"episode": 75.0, "batch_reward": 0.8038676723837852, "critic_loss": 0.6309939774572849, "actor_loss": -71.90648707580566, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.99453353881836, "episode_reward": 853.312135408408, "step": 75000}
{"episode": 76.0, "batch_reward": 0.8054051446914673, "critic_loss": 0.6174326972365379, "actor_loss": -72.0139057006836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 435.12730836868286, "episode_reward": 871.4811775535817, "step": 76000}
{"episode": 77.0, "batch_reward": 0.8068336486816406, "critic_loss": 0.5746330612301827, "actor_loss": -72.25911947631836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.235638856887817, "episode_reward": 893.063862891835, "step": 77000}
{"episode": 78.0, "batch_reward": 0.8062681949138641, "critic_loss": 0.5860351908802987, "actor_loss": -72.1995531463623, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 462.2490322589874, "episode_reward": 794.9327660953255, "step": 78000}
{"episode": 79.0, "batch_reward": 0.8075345723628998, "critic_loss": 0.5977032999694347, "actor_loss": -72.37535289001465, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.644886255264282, "episode_reward": 842.6342491109724, "step": 79000}
{"episode": 80.0, "batch_reward": 0.8077934144735336, "critic_loss": 0.5976050687730312, "actor_loss": -72.58528295898438, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 422.0858018398285, "episode_reward": 892.911147183686, "step": 80000}
{"episode": 81.0, "batch_reward": 0.8082286720275879, "critic_loss": 0.5915848523676396, "actor_loss": -72.77933807373047, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.729289293289185, "episode_reward": 866.1643161704142, "step": 81000}
{"episode": 82.0, "batch_reward": 0.808801595389843, "critic_loss": 0.5931660832166672, "actor_loss": -73.09563717651368, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 461.0427474975586, "episode_reward": 894.6765856736533, "step": 82000}
{"episode": 83.0, "batch_reward": 0.8111971294879914, "critic_loss": 0.5854631822705268, "actor_loss": -73.24579531860351, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.242261171340942, "episode_reward": 872.4403248845608, "step": 83000}
{"episode": 84.0, "batch_reward": 0.8108503637313843, "critic_loss": 0.5716993530243635, "actor_loss": -73.41425221252442, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 425.1498022079468, "episode_reward": 823.5209614409039, "step": 84000}
{"episode": 85.0, "batch_reward": 0.8117694104909897, "critic_loss": 0.5654324820935727, "actor_loss": -73.59789254760742, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.437639713287354, "episode_reward": 903.5490967746864, "step": 85000}
{"episode": 86.0, "batch_reward": 0.8121524819731712, "critic_loss": 0.5355174158811569, "actor_loss": -73.72887623596192, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 453.04997277259827, "episode_reward": 867.5906324641197, "step": 86000}
{"episode": 87.0, "batch_reward": 0.8128477979898453, "critic_loss": 0.5188848194479942, "actor_loss": -73.97110682678223, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.51959204673767, "episode_reward": 870.6669214984282, "step": 87000}
{"episode": 88.0, "batch_reward": 0.8153677420020103, "critic_loss": 0.514901469424367, "actor_loss": -74.38334370422363, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 458.25993180274963, "episode_reward": 910.6408597407037, "step": 88000}
{"episode": 89.0, "batch_reward": 0.8162031139731407, "critic_loss": 0.48924921511113645, "actor_loss": -74.60013110351562, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.93359112739563, "episode_reward": 909.9456474434588, "step": 89000}
{"episode": 90.0, "batch_reward": 0.8171835800409317, "critic_loss": 0.5038717835694552, "actor_loss": -74.74299728393555, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 469.447247505188, "episode_reward": 914.2970805194365, "step": 90000}
{"episode": 91.0, "batch_reward": 0.8168594707250595, "critic_loss": 0.5008530646413565, "actor_loss": -74.9542821044922, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.967257022857666, "episode_reward": 833.4604388939645, "step": 91000}
{"episode": 92.0, "batch_reward": 0.8183095474243164, "critic_loss": 0.4795954433232546, "actor_loss": -75.17828338623048, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 438.2563624382019, "episode_reward": 910.0775752131518, "step": 92000}
{"episode": 93.0, "batch_reward": 0.8189028304815292, "critic_loss": 0.4588988233357668, "actor_loss": -75.43811218261719, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.390394926071167, "episode_reward": 905.3331363070936, "step": 93000}
{"episode": 94.0, "batch_reward": 0.8201004384160042, "critic_loss": 0.45305868282914163, "actor_loss": -75.74730500793457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 448.69302225112915, "episode_reward": 901.0320078584712, "step": 94000}
{"episode": 95.0, "batch_reward": 0.8185720919370651, "critic_loss": 0.4563954261094332, "actor_loss": -75.88547184753418, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.003052711486816, "episode_reward": 599.1659888624313, "step": 95000}
{"episode": 96.0, "batch_reward": 0.8140281404852867, "critic_loss": 0.45281993483006955, "actor_loss": -76.07094703674316, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 471.4824106693268, "episode_reward": 292.1253465892544, "step": 96000}
{"episode": 97.0, "batch_reward": 0.8126238099932671, "critic_loss": 0.460862478479743, "actor_loss": -76.22632331848145, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.844104528427124, "episode_reward": 888.7322626134152, "step": 97000}
{"episode": 98.0, "batch_reward": 0.8126631477475166, "critic_loss": 0.4574314851462841, "actor_loss": -76.54244093322754, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 435.1436188220978, "episode_reward": 871.1531465864043, "step": 98000}
{"episode": 99.0, "batch_reward": 0.8145652492642402, "critic_loss": 0.4464297127127647, "actor_loss": -76.86844778442382, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.681941032409668, "episode_reward": 885.4445026116932, "step": 99000}
{"episode": 100.0, "batch_reward": 0.8137674120664596, "critic_loss": 0.4281802260428667, "actor_loss": -77.16261819458008, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 445.24053978919983, "episode_reward": 911.6051290295188, "step": 100000}
{"episode": 101.0, "batch_reward": 0.8155852534174919, "critic_loss": 0.40534256590902806, "actor_loss": -77.40297901916504, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.85048198699951, "episode_reward": 901.4452333165733, "step": 101000}
{"episode": 102.0, "batch_reward": 0.8163324189186096, "critic_loss": 0.4026743476688862, "actor_loss": -77.76359118652344, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 452.0154881477356, "episode_reward": 904.874115189307, "step": 102000}
{"episode": 103.0, "batch_reward": 0.8166224849224091, "critic_loss": 0.3956615082025528, "actor_loss": -77.95215747070313, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.764689207077026, "episode_reward": 878.4174293764355, "step": 103000}
{"episode": 104.0, "batch_reward": 0.8185610240101814, "critic_loss": 0.3874542084187269, "actor_loss": -78.26378674316406, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 444.627215385437, "episode_reward": 907.5559523716776, "step": 104000}
{"episode": 105.0, "batch_reward": 0.818550674378872, "critic_loss": 0.36552331503480673, "actor_loss": -78.46946405029297, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.553375959396362, "episode_reward": 911.4627940750551, "step": 105000}
{"episode": 106.0, "batch_reward": 0.8195476118922234, "critic_loss": 0.3753307015299797, "actor_loss": -78.8279075164795, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 420.4706299304962, "episode_reward": 892.275597292985, "step": 106000}
{"episode": 107.0, "batch_reward": 0.8196807335019112, "critic_loss": 0.36199047973752024, "actor_loss": -78.97596215820313, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.695892095565796, "episode_reward": 871.587145783618, "step": 107000}
{"episode": 108.0, "batch_reward": 0.8198535301089287, "critic_loss": 0.3774413645863533, "actor_loss": -79.2846651611328, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 441.362220287323, "episode_reward": 860.5818511500651, "step": 108000}
{"episode": 109.0, "batch_reward": 0.8209250602722168, "critic_loss": 0.352667226806283, "actor_loss": -79.46738258361816, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.553671836853027, "episode_reward": 899.5895151415474, "step": 109000}
{"episode": 110.0, "batch_reward": 0.8227394582033157, "critic_loss": 0.35890691213309767, "actor_loss": -79.81469836425781, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 465.79702258110046, "episode_reward": 893.044613972938, "step": 110000}
{"episode": 111.0, "batch_reward": 0.8227239445447921, "critic_loss": 0.35433824238181116, "actor_loss": -80.04900341796875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.166059255599976, "episode_reward": 889.1976083746446, "step": 111000}
{"episode": 112.0, "batch_reward": 0.8222845705151558, "critic_loss": 0.3506720984429121, "actor_loss": -80.37910269165039, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 466.115562915802, "episode_reward": 906.6675434203606, "step": 112000}
{"episode": 113.0, "batch_reward": 0.8251922359466553, "critic_loss": 0.33692925205826757, "actor_loss": -80.5628300933838, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.456195831298828, "episode_reward": 904.4742525560855, "step": 113000}
{"episode": 114.0, "batch_reward": 0.824224067389965, "critic_loss": 0.347173699170351, "actor_loss": -80.81347102355957, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 455.3211815357208, "episode_reward": 908.4809442720862, "step": 114000}
{"episode": 115.0, "batch_reward": 0.8249646047949791, "critic_loss": 0.3448248879760504, "actor_loss": -81.08114785766601, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.764614820480347, "episode_reward": 894.0917485984454, "step": 115000}
{"episode": 116.0, "batch_reward": 0.8258997164964675, "critic_loss": 0.33338615046441555, "actor_loss": -81.38144129943848, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 444.28350353240967, "episode_reward": 883.903661348768, "step": 116000}
{"episode": 117.0, "batch_reward": 0.8253885790705681, "critic_loss": 0.32163245119154454, "actor_loss": -81.55449310302734, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.477904796600342, "episode_reward": 853.3708663015149, "step": 117000}
{"episode": 118.0, "batch_reward": 0.8259756479859353, "critic_loss": 0.3332648718804121, "actor_loss": -81.84352613830566, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 439.50455927848816, "episode_reward": 903.9010860920737, "step": 118000}
{"episode": 119.0, "batch_reward": 0.8268859141469002, "critic_loss": 0.3126388005018234, "actor_loss": -82.11991180419922, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.76575207710266, "episode_reward": 905.2512219147019, "step": 119000}
{"episode": 120.0, "batch_reward": 0.8273675056695938, "critic_loss": 0.3534973690211773, "actor_loss": -82.36649270629883, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 470.3117628097534, "episode_reward": 897.1629258906761, "step": 120000}
{"episode": 121.0, "batch_reward": 0.8254622600078583, "critic_loss": 0.39703934302926064, "actor_loss": -82.59799421691895, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.62065410614014, "episode_reward": 381.1835962207802, "step": 121000}
{"episode": 122.0, "batch_reward": 0.823349448800087, "critic_loss": 0.39430378895998003, "actor_loss": -82.63728829956055, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 420.8502411842346, "episode_reward": 740.87105611118, "step": 122000}
{"episode": 123.0, "batch_reward": 0.8230235146284104, "critic_loss": 0.365422099262476, "actor_loss": -82.85433393859863, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.70016312599182, "episode_reward": 909.5471977029099, "step": 123000}
{"episode": 124.0, "batch_reward": 0.8244202347397804, "critic_loss": 0.3157820460945368, "actor_loss": -83.05606030273438, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 424.4800066947937, "episode_reward": 898.7055985615655, "step": 124000}
{"episode": 125.0, "batch_reward": 0.8262004251480103, "critic_loss": 0.3024157819002867, "actor_loss": -83.20572467041016, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.665056943893433, "episode_reward": 906.1855429128547, "step": 125000}
{"episode": 126.0, "batch_reward": 0.8255290578603744, "critic_loss": 0.29001283133029937, "actor_loss": -83.3213298034668, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 450.90509057044983, "episode_reward": 905.978372558698, "step": 126000}
{"episode": 127.0, "batch_reward": 0.8270495100021362, "critic_loss": 0.3023062445148826, "actor_loss": -83.50315534973144, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.254343271255493, "episode_reward": 866.1245321221629, "step": 127000}
{"episode": 128.0, "batch_reward": 0.8263671925663948, "critic_loss": 0.2946512308865786, "actor_loss": -83.64221452331543, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 439.29979515075684, "episode_reward": 902.6197731614166, "step": 128000}
{"episode": 129.0, "batch_reward": 0.8277893522977829, "critic_loss": 0.2952433419823647, "actor_loss": -83.83163061523437, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.50001549720764, "episode_reward": 909.8171159750092, "step": 129000}
{"episode": 130.0, "batch_reward": 0.8272029792666435, "critic_loss": 0.2941908913478255, "actor_loss": -83.99632386779786, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 430.38837599754333, "episode_reward": 868.2884752133235, "step": 130000}
{"episode": 131.0, "batch_reward": 0.8290130734443665, "critic_loss": 0.3086368734240532, "actor_loss": -84.30500631713868, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.00862264633179, "episode_reward": 888.8742493885867, "step": 131000}
{"episode": 132.0, "batch_reward": 0.8286827403306961, "critic_loss": 0.3165309829339385, "actor_loss": -84.46507449340821, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 452.66213035583496, "episode_reward": 860.2824442492928, "step": 132000}
{"episode": 133.0, "batch_reward": 0.8292231369018555, "critic_loss": 0.31764765150845053, "actor_loss": -84.732755569458, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.340527296066284, "episode_reward": 908.4494402573092, "step": 133000}
{"episode": 134.0, "batch_reward": 0.8308861019015312, "critic_loss": 0.3291482187062502, "actor_loss": -85.04822802734375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 451.31114196777344, "episode_reward": 892.8994119517382, "step": 134000}
{"episode": 135.0, "batch_reward": 0.8307387359142303, "critic_loss": 0.30963789819180965, "actor_loss": -85.17478982543945, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.87931776046753, "episode_reward": 880.7075617628943, "step": 135000}
{"episode": 136.0, "batch_reward": 0.8306266536712646, "critic_loss": 0.3243176419734955, "actor_loss": -85.3536883392334, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 471.14061760902405, "episode_reward": 880.2673908166598, "step": 136000}
{"episode": 137.0, "batch_reward": 0.8301855275034904, "critic_loss": 0.3129884822294116, "actor_loss": -85.51030438232422, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.603049278259277, "episode_reward": 918.1372901330355, "step": 137000}
{"episode": 138.0, "batch_reward": 0.8315360290408135, "critic_loss": 0.29639364843815563, "actor_loss": -85.76181922912598, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 458.6604413986206, "episode_reward": 918.626893279534, "step": 138000}
{"episode": 139.0, "batch_reward": 0.8317941505312919, "critic_loss": 0.28517572989314793, "actor_loss": -85.90007858276367, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.565083980560303, "episode_reward": 883.2301187655556, "step": 139000}
{"episode": 140.0, "batch_reward": 0.8310692261457443, "critic_loss": 0.28510114911198614, "actor_loss": -86.03803077697754, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 467.327348947525, "episode_reward": 900.4879735016364, "step": 140000}
{"episode": 141.0, "batch_reward": 0.8327477506995201, "critic_loss": 0.27003888255357744, "actor_loss": -86.22802368164062, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.75988054275513, "episode_reward": 893.3932087179782, "step": 141000}
{"episode": 142.0, "batch_reward": 0.8331877017617225, "critic_loss": 0.28156224351376297, "actor_loss": -86.36341950988769, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 426.8597483634949, "episode_reward": 899.121847382366, "step": 142000}
{"episode": 143.0, "batch_reward": 0.8325512971282005, "critic_loss": 0.2718164456635714, "actor_loss": -86.51072410583497, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 26.543291568756104, "episode_reward": 919.4620709041886, "step": 143000}
{"episode": 144.0, "batch_reward": 0.8334149812459946, "critic_loss": 0.2882098287343979, "actor_loss": -86.64852307128906, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 488.3523335456848, "episode_reward": 797.7379362842698, "step": 144000}
{"episode": 145.0, "batch_reward": 0.8325981539487839, "critic_loss": 0.2802126677036285, "actor_loss": -86.7834871826172, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.34174919128418, "episode_reward": 848.0498956680648, "step": 145000}
{"episode": 146.0, "batch_reward": 0.8350109506845474, "critic_loss": 0.2789179189950228, "actor_loss": -86.91717938232422, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 469.46528720855713, "episode_reward": 921.9587003686812, "step": 146000}
{"episode": 147.0, "batch_reward": 0.8352576660513877, "critic_loss": 0.2693878953307867, "actor_loss": -87.06989628601075, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.392431497573853, "episode_reward": 925.4815629550188, "step": 147000}
{"episode": 148.0, "batch_reward": 0.8354492272138596, "critic_loss": 0.2844123066142201, "actor_loss": -87.16620056152344, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 471.8442749977112, "episode_reward": 948.3147147851743, "step": 148000}
{"episode": 149.0, "batch_reward": 0.8356434417366981, "critic_loss": 0.29936370635032655, "actor_loss": -87.4234482574463, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 27.137796640396118, "episode_reward": 886.2298258845794, "step": 149000}
{"episode": 150.0, "batch_reward": 0.8377156598567963, "critic_loss": 0.3129059222489595, "actor_loss": -87.56961265563965, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
