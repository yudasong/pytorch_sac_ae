{"episode_reward": 0.0, "episode": 1.0, "duration": 21.320403575897217, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.8472895622253418, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.2710239769727558, "critic_loss": 0.16289777577323353, "actor_loss": -36.29164656152685, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 63.91256499290466, "step": 3000}
{"episode_reward": 97.88668970143928, "episode": 4.0, "batch_reward": 0.21368564395606518, "critic_loss": 0.3599186624586582, "actor_loss": -34.35504423904419, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.274367570877075, "step": 4000}
{"episode_reward": 131.87001748926897, "episode": 5.0, "batch_reward": 0.19699459824711085, "critic_loss": 0.463787980094552, "actor_loss": -37.449271761894224, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.748836040496826, "step": 5000}
{"episode_reward": 228.48577151848014, "episode": 6.0, "batch_reward": 0.21078027188777923, "critic_loss": 0.6589697726070881, "actor_loss": -36.26078726863861, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.640373468399048, "step": 6000}
{"episode_reward": 372.79558600730553, "episode": 7.0, "batch_reward": 0.25610575123131274, "critic_loss": 0.9246217691600322, "actor_loss": -39.38821368217468, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.895604610443115, "step": 7000}
{"episode_reward": 660.4127273854277, "episode": 8.0, "batch_reward": 0.313384715333581, "critic_loss": 1.192520992398262, "actor_loss": -44.25756213760376, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.070615768432617, "step": 8000}
{"episode_reward": 603.7415336199232, "episode": 9.0, "batch_reward": 0.34568518221378325, "critic_loss": 1.262392355799675, "actor_loss": -45.65803213500977, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.822837591171265, "step": 9000}
{"episode_reward": 518.4401706413678, "episode": 10.0, "batch_reward": 0.3706466410756111, "critic_loss": 1.4082215459346772, "actor_loss": -48.03935103607178, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.194434642791748, "step": 10000}
{"episode_reward": 624.8655635124811, "episode": 11.0, "batch_reward": 0.402209169447422, "critic_loss": 1.4992354192137718, "actor_loss": -48.300154781341554, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.371018171310425, "step": 11000}
{"episode_reward": 804.3120620955738, "episode": 12.0, "batch_reward": 0.41952392089366913, "critic_loss": 1.572014779150486, "actor_loss": -51.43525109481811, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.327472925186157, "step": 12000}
{"episode_reward": 537.8445846614237, "episode": 13.0, "batch_reward": 0.4285176289975643, "critic_loss": 1.588478569149971, "actor_loss": -51.20319927597046, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.63476276397705, "step": 13000}
{"episode_reward": 346.00580867202626, "episode": 14.0, "batch_reward": 0.4332822261750698, "critic_loss": 1.5098904512524605, "actor_loss": -53.471636581420896, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.112813472747803, "step": 14000}
{"episode_reward": 744.3733413875019, "episode": 15.0, "batch_reward": 0.4510261351764202, "critic_loss": 1.5980751224160195, "actor_loss": -52.543671600341796, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.049734592437744, "step": 15000}
{"episode_reward": 760.85957781903, "episode": 16.0, "batch_reward": 0.48076531928777694, "critic_loss": 1.5122444362640381, "actor_loss": -57.90726651000976, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.14349102973938, "step": 16000}
{"episode_reward": 942.9034809024431, "episode": 17.0, "batch_reward": 0.5064784752428532, "critic_loss": 1.5808840337395669, "actor_loss": -58.50233081054687, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.937144994735718, "step": 17000}
{"episode_reward": 884.0655581256808, "episode": 18.0, "batch_reward": 0.5300299493074417, "critic_loss": 1.5626150432229042, "actor_loss": -60.70833318328857, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.005844831466675, "step": 18000}
{"episode_reward": 928.1254406535153, "episode": 19.0, "batch_reward": 0.5486747699975968, "critic_loss": 1.548964685201645, "actor_loss": -61.74759064483643, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.635470390319824, "step": 19000}
{"episode_reward": 879.6006915417142, "episode": 20.0, "batch_reward": 0.5637062330245972, "critic_loss": 1.6990178871750832, "actor_loss": -61.078258193969724, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.185381412506104, "step": 20000}
{"episode_reward": 815.8495436666916, "episode": 21.0, "batch_reward": 0.5803955602049827, "critic_loss": 1.6709390370249748, "actor_loss": -63.58273484802246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.21484684944153, "step": 21000}
{"episode_reward": 860.4637174086708, "episode": 22.0, "batch_reward": 0.5914372925460338, "critic_loss": 1.677312290430069, "actor_loss": -64.23731578063965, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.924041032791138, "step": 22000}
{"episode_reward": 833.9133201940789, "episode": 23.0, "batch_reward": 0.5975062763094902, "critic_loss": 1.646961979329586, "actor_loss": -64.7718202972412, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.410303354263306, "step": 23000}
{"episode_reward": 801.7783344403279, "episode": 24.0, "batch_reward": 0.6125650964379311, "critic_loss": 1.5781548568606376, "actor_loss": -65.75188027191162, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.62017059326172, "step": 24000}
{"episode_reward": 893.0966191290365, "episode": 25.0, "batch_reward": 0.6213713339865208, "critic_loss": 1.5778866533637046, "actor_loss": -66.51037731933594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.799295663833618, "step": 25000}
{"episode_reward": 863.1690787141002, "episode": 26.0, "batch_reward": 0.6266361003518105, "critic_loss": 1.6308024673461914, "actor_loss": -67.71773133850098, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.94155526161194, "step": 26000}
{"episode_reward": 795.9269436318807, "episode": 27.0, "batch_reward": 0.6410948854088784, "critic_loss": 1.5189314284920692, "actor_loss": -67.70719882202148, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.87811255455017, "step": 27000}
{"episode_reward": 930.1226499792424, "episode": 28.0, "batch_reward": 0.6469768007397652, "critic_loss": 1.5555554686784745, "actor_loss": -69.32330109405518, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.28307294845581, "step": 28000}
{"episode_reward": 872.5916402599371, "episode": 29.0, "batch_reward": 0.6577867423892021, "critic_loss": 1.4874277932047844, "actor_loss": -68.96727360534668, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.737027883529663, "step": 29000}
{"episode_reward": 953.3760336693142, "episode": 30.0, "batch_reward": 0.6638467739224434, "critic_loss": 1.4634576754570008, "actor_loss": -69.80157080841064, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.61159896850586, "step": 30000}
{"episode_reward": 853.2759158702878, "episode": 31.0, "batch_reward": 0.666021970629692, "critic_loss": 1.5983984110355378, "actor_loss": -70.8368494567871, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.64897441864014, "step": 31000}
{"episode_reward": 717.247067620304, "episode": 32.0, "batch_reward": 0.6752912958860398, "critic_loss": 1.4933248192071915, "actor_loss": -71.41807761383056, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.614881992340088, "step": 32000}
{"episode_reward": 943.0559976665926, "episode": 33.0, "batch_reward": 0.6829525899291039, "critic_loss": 1.4448615186214446, "actor_loss": -71.10456838989258, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.888731956481934, "step": 33000}
{"episode_reward": 959.9680981202262, "episode": 34.0, "batch_reward": 0.6883018752336502, "critic_loss": 1.4294584476351737, "actor_loss": -72.47021269226074, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.447617769241333, "step": 34000}
{"episode_reward": 824.4494550579034, "episode": 35.0, "batch_reward": 0.6909371991753578, "critic_loss": 1.5145759578347207, "actor_loss": -72.93688074493409, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.887314558029175, "step": 35000}
{"episode_reward": 746.0540535322868, "episode": 36.0, "batch_reward": 0.6988036136627197, "critic_loss": 1.4137554827928542, "actor_loss": -73.70938264465332, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.057571172714233, "step": 36000}
{"episode_reward": 955.8125670025515, "episode": 37.0, "batch_reward": 0.7039195033311844, "critic_loss": 1.4290790941119194, "actor_loss": -73.74049061584472, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.043967485427856, "step": 37000}
{"episode_reward": 881.1408088899327, "episode": 38.0, "batch_reward": 0.7100447807908058, "critic_loss": 1.3525830169916153, "actor_loss": -73.53632521057129, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.41342258453369, "step": 38000}
{"episode_reward": 962.1670649204874, "episode": 39.0, "batch_reward": 0.7155351329445839, "critic_loss": 1.3694619352817536, "actor_loss": -74.33539788818359, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.886676788330078, "step": 39000}
{"episode_reward": 933.2946586297389, "episode": 40.0, "batch_reward": 0.7198765565156937, "critic_loss": 1.301722374856472, "actor_loss": -75.01026542663574, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.627718687057495, "step": 40000}
{"episode_reward": 934.1730155678312, "episode": 41.0, "batch_reward": 0.7246723296046257, "critic_loss": 1.3135245535969735, "actor_loss": -75.64717546081543, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.47311496734619, "step": 41000}
{"episode_reward": 940.6561565283565, "episode": 42.0, "batch_reward": 0.7305382667183876, "critic_loss": 1.2760590168833732, "actor_loss": -75.48931396484375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.858192443847656, "step": 42000}
{"episode_reward": 953.0056945470301, "episode": 43.0, "batch_reward": 0.7368299739956856, "critic_loss": 1.2177290363311768, "actor_loss": -76.08451559448243, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.081071853637695, "step": 43000}
{"episode_reward": 838.1066927198261, "episode": 44.0, "batch_reward": 0.7395231639742851, "critic_loss": 1.2155030481815339, "actor_loss": -76.19657647705078, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.37938380241394, "step": 44000}
{"episode_reward": 932.3452719005043, "episode": 45.0, "batch_reward": 0.7441316675543785, "critic_loss": 1.1875484027266503, "actor_loss": -76.39036535644532, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.967592239379883, "step": 45000}
{"episode_reward": 913.5234653720172, "episode": 46.0, "batch_reward": 0.746767809510231, "critic_loss": 1.1613794603943826, "actor_loss": -77.07677548217774, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.930050134658813, "step": 46000}
{"episode_reward": 822.6885010613055, "episode": 47.0, "batch_reward": 0.7466614913940429, "critic_loss": 1.2067559267878532, "actor_loss": -77.38655029296875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.953850746154785, "step": 47000}
{"episode_reward": 817.8326559496305, "episode": 48.0, "batch_reward": 0.7505280397534371, "critic_loss": 1.2118340022563934, "actor_loss": -77.43731126403809, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.63490343093872, "step": 48000}
{"episode_reward": 852.0911449324542, "episode": 49.0, "batch_reward": 0.7538818339109421, "critic_loss": 1.1869423673152923, "actor_loss": -77.88443797302246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.160294771194458, "step": 49000}
{"episode_reward": 925.6539363769518, "episode": 50.0, "batch_reward": 0.7540151224732399, "critic_loss": 1.2215079181194306, "actor_loss": -77.8072819519043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.598949432373047, "step": 50000}
{"episode_reward": 850.1452683775552, "episode": 51.0, "batch_reward": 0.7596652280688286, "critic_loss": 1.1763776766061782, "actor_loss": -77.86499432373047, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.31044149398804, "step": 51000}
{"episode_reward": 962.4730886750251, "episode": 52.0, "batch_reward": 0.7596397470831872, "critic_loss": 1.2512001935839654, "actor_loss": -78.56065328979493, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.968994855880737, "step": 52000}
{"episode_reward": 903.0807890321216, "episode": 53.0, "batch_reward": 0.76370179438591, "critic_loss": 1.326237592279911, "actor_loss": -78.24909243774414, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.064255714416504, "step": 53000}
{"episode_reward": 830.3858638398707, "episode": 54.0, "batch_reward": 0.7655827386975288, "critic_loss": 1.3277666021585464, "actor_loss": -79.09593029785157, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.232115745544434, "step": 54000}
{"episode_reward": 915.1094158824184, "episode": 55.0, "batch_reward": 0.7675934680700303, "critic_loss": 1.3151404433250427, "actor_loss": -79.11899209594726, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.404277086257935, "step": 55000}
{"episode_reward": 958.5366793380861, "episode": 56.0, "batch_reward": 0.7720919935107231, "critic_loss": 1.2481198836565017, "actor_loss": -79.17488912963867, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.768667459487915, "step": 56000}
{"episode_reward": 944.2884353654875, "episode": 57.0, "batch_reward": 0.7749957268238068, "critic_loss": 1.244619721710682, "actor_loss": -79.43612538146972, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.74050760269165, "step": 57000}
{"episode_reward": 904.5771802350612, "episode": 58.0, "batch_reward": 0.7757071240544319, "critic_loss": 1.2968743513226508, "actor_loss": -79.55744241333008, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.00687265396118, "step": 58000}
{"episode_reward": 890.403346762341, "episode": 59.0, "batch_reward": 0.7799351041913033, "critic_loss": 1.177838450551033, "actor_loss": -79.9653445739746, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.681034326553345, "step": 59000}
{"episode_reward": 972.7637464393482, "episode": 60.0, "batch_reward": 0.7817863800525665, "critic_loss": 1.1751643289029599, "actor_loss": -80.17211080932617, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.64144253730774, "step": 60000}
{"episode_reward": 864.6443024698883, "episode": 61.0, "batch_reward": 0.7833458589315414, "critic_loss": 1.143851104915142, "actor_loss": -80.17982391357423, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.62825107574463, "step": 61000}
{"episode_reward": 909.815174701631, "episode": 62.0, "batch_reward": 0.7861372674703598, "critic_loss": 1.1541614065766335, "actor_loss": -80.2365825805664, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.005011081695557, "step": 62000}
{"episode_reward": 975.815081562955, "episode": 63.0, "batch_reward": 0.7869485093951225, "critic_loss": 1.0995838362574577, "actor_loss": -80.40514910888672, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.078755140304565, "step": 63000}
{"episode_reward": 948.6892815952446, "episode": 64.0, "batch_reward": 0.7925490253567695, "critic_loss": 1.0968842183947562, "actor_loss": -80.74862725830079, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.750000715255737, "step": 64000}
{"episode_reward": 935.9260964125087, "episode": 65.0, "batch_reward": 0.7923290591239929, "critic_loss": 1.126940579533577, "actor_loss": -80.78221025085449, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.829130172729492, "step": 65000}
{"episode_reward": 911.661678443609, "episode": 66.0, "batch_reward": 0.7955179288387298, "critic_loss": 1.1167164353132248, "actor_loss": -81.00968214416504, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.34632658958435, "step": 66000}
{"episode_reward": 944.2132893722268, "episode": 67.0, "batch_reward": 0.7978458660244941, "critic_loss": 1.1249725690186023, "actor_loss": -81.10882829284668, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.79481029510498, "step": 67000}
{"episode_reward": 861.1794653414626, "episode": 68.0, "batch_reward": 0.7985830419659614, "critic_loss": 1.1339506922364235, "actor_loss": -81.35013359069825, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.884120225906372, "step": 68000}
{"episode_reward": 943.0249309809002, "episode": 69.0, "batch_reward": 0.7997891270518303, "critic_loss": 1.082511700630188, "actor_loss": -81.4874556274414, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.839244604110718, "step": 69000}
{"episode_reward": 935.1243401938593, "episode": 70.0, "batch_reward": 0.802665400505066, "critic_loss": 1.097189820766449, "actor_loss": -81.66352459716796, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.140251636505127, "step": 70000}
{"episode_reward": 881.8608839652675, "episode": 71.0, "batch_reward": 0.8028310388326645, "critic_loss": 1.0716035461425781, "actor_loss": -81.69316435241699, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.729352712631226, "step": 71000}
{"episode_reward": 947.7001043935605, "episode": 72.0, "batch_reward": 0.8065711824893952, "critic_loss": 1.077930855602026, "actor_loss": -81.84008976745605, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.53194808959961, "step": 72000}
{"episode_reward": 912.9797594855797, "episode": 73.0, "batch_reward": 0.8076820535063743, "critic_loss": 1.025116290062666, "actor_loss": -81.90800407409668, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.425814151763916, "step": 73000}
{"episode_reward": 967.4168261372524, "episode": 74.0, "batch_reward": 0.8102825582027435, "critic_loss": 1.0334346612393857, "actor_loss": -82.11232196044922, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.916874647140503, "step": 74000}
{"episode_reward": 954.8016286459424, "episode": 75.0, "batch_reward": 0.8123730645179749, "critic_loss": 1.0378403584361076, "actor_loss": -82.19538398742675, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.85275411605835, "step": 75000}
{"episode_reward": 955.3595094373803, "episode": 76.0, "batch_reward": 0.8139578159451485, "critic_loss": 1.0272534753978253, "actor_loss": -82.37969918823242, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.6905198097229, "step": 76000}
{"episode_reward": 899.5990556815503, "episode": 77.0, "batch_reward": 0.8151648487448693, "critic_loss": 1.0646678816378117, "actor_loss": -82.47123597717285, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.07072114944458, "step": 77000}
{"episode_reward": 967.9674554468521, "episode": 78.0, "batch_reward": 0.814504474580288, "critic_loss": 0.9579102481603623, "actor_loss": -82.4634349822998, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.83199381828308, "step": 78000}
{"episode_reward": 847.6624426372289, "episode": 79.0, "batch_reward": 0.8159954038262367, "critic_loss": 1.0012608234584333, "actor_loss": -82.58135787963867, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.99690079689026, "step": 79000}
{"episode_reward": 885.8181698593102, "episode": 80.0, "batch_reward": 0.8180248618125916, "critic_loss": 0.9987062276601791, "actor_loss": -82.67378791809082, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.594201803207397, "step": 80000}
{"episode_reward": 962.7743538656442, "episode": 81.0, "batch_reward": 0.8191948648691177, "critic_loss": 1.0349497136175632, "actor_loss": -82.76835530090332, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.285746335983276, "step": 81000}
{"episode_reward": 933.1417540711349, "episode": 82.0, "batch_reward": 0.8202192497849464, "critic_loss": 1.0382910787165165, "actor_loss": -82.86456187438965, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.57492685317993, "step": 82000}
{"episode_reward": 966.136324323406, "episode": 83.0, "batch_reward": 0.8211553077101708, "critic_loss": 0.9910082726180554, "actor_loss": -82.98296453857422, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.05955696105957, "step": 83000}
{"episode_reward": 924.495374607749, "episode": 84.0, "batch_reward": 0.8219718739390374, "critic_loss": 1.0523752556443216, "actor_loss": -83.05161799621582, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.975116968154907, "step": 84000}
{"episode_reward": 886.4441326336109, "episode": 85.0, "batch_reward": 0.823263190984726, "critic_loss": 1.0516123165786266, "actor_loss": -83.1056600189209, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.002137660980225, "step": 85000}
{"episode_reward": 930.104326936939, "episode": 86.0, "batch_reward": 0.8251373881697655, "critic_loss": 1.0455627654790878, "actor_loss": -83.17643821716308, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.693648099899292, "step": 86000}
{"episode_reward": 832.5851739409771, "episode": 87.0, "batch_reward": 0.8263243728280067, "critic_loss": 1.021783859372139, "actor_loss": -83.28553494262695, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.615943431854248, "step": 87000}
{"episode_reward": 915.4015309974429, "episode": 88.0, "batch_reward": 0.8263976060152054, "critic_loss": 0.973602251291275, "actor_loss": -83.29779551696777, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.872550010681152, "step": 88000}
{"episode_reward": 950.3224042976658, "episode": 89.0, "batch_reward": 0.8287794836163521, "critic_loss": 0.9613713056743145, "actor_loss": -83.4313879699707, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.894224166870117, "step": 89000}
{"episode_reward": 956.8502506898138, "episode": 90.0, "batch_reward": 0.8297706302404404, "critic_loss": 0.9709724630713463, "actor_loss": -83.51001203918457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.749751091003418, "step": 90000}
{"episode_reward": 964.1845228520605, "episode": 91.0, "batch_reward": 0.8303050525784492, "critic_loss": 0.9658454672396183, "actor_loss": -83.50571621704101, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.039897203445435, "step": 91000}
{"episode_reward": 873.2165807893527, "episode": 92.0, "batch_reward": 0.8325576403141022, "critic_loss": 0.9712382002174854, "actor_loss": -83.65070274353027, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.90333366394043, "step": 92000}
{"episode_reward": 966.5640634328242, "episode": 93.0, "batch_reward": 0.8336121744513512, "critic_loss": 0.9904642333090306, "actor_loss": -83.74724212646484, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.951735734939575, "step": 93000}
{"episode_reward": 933.7396617921491, "episode": 94.0, "batch_reward": 0.8349745088219642, "critic_loss": 0.988935153901577, "actor_loss": -83.82543812561035, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.916050910949707, "step": 94000}
{"episode_reward": 915.161162024971, "episode": 95.0, "batch_reward": 0.8343576993942261, "critic_loss": 0.9365909108221531, "actor_loss": -83.84516952514649, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.094984531402588, "step": 95000}
{"episode_reward": 906.5815573898697, "episode": 96.0, "batch_reward": 0.8348990971446038, "critic_loss": 0.9656627893149853, "actor_loss": -83.88296044921876, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.109785795211792, "step": 96000}
{"episode_reward": 935.8651614444573, "episode": 97.0, "batch_reward": 0.8363393985629082, "critic_loss": 0.9533915299475193, "actor_loss": -83.97374725341797, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.470717906951904, "step": 97000}
{"episode_reward": 912.5810751336444, "episode": 98.0, "batch_reward": 0.8356327646970749, "critic_loss": 0.9204356333911419, "actor_loss": -84.01856451416016, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.80909013748169, "step": 98000}
{"episode_reward": 891.2581059653173, "episode": 99.0, "batch_reward": 0.8382780833244323, "critic_loss": 0.9079725950956344, "actor_loss": -84.1483412322998, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.62727952003479, "step": 99000}
{"episode_reward": 910.464901445523, "episode": 100.0, "batch_reward": 0.8390140638351441, "critic_loss": 0.8997843745350838, "actor_loss": -84.16325924682617, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.000012159347534, "step": 100000}
{"episode_reward": 940.6999565412749, "episode": 101.0, "batch_reward": 0.8405018611550331, "critic_loss": 0.8986283119022846, "actor_loss": -84.23207371520996, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.09785008430481, "step": 101000}
{"episode_reward": 899.4436157543586, "episode": 102.0, "batch_reward": 0.840588459610939, "critic_loss": 0.9153303987085819, "actor_loss": -84.23978979492188, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.012651920318604, "step": 102000}
{"episode_reward": 930.4536162275089, "episode": 103.0, "batch_reward": 0.8416368817090988, "critic_loss": 0.9008762196004391, "actor_loss": -84.34817466735839, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.736573934555054, "step": 103000}
{"episode_reward": 943.7164535446815, "episode": 104.0, "batch_reward": 0.8419615500569344, "critic_loss": 0.8633241839110851, "actor_loss": -84.38888278198242, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.98173975944519, "step": 104000}
{"episode_reward": 929.9281868425951, "episode": 105.0, "batch_reward": 0.8430322008728981, "critic_loss": 0.8722133513689041, "actor_loss": -84.47790846252441, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.812753677368164, "step": 105000}
{"episode_reward": 938.8181652026592, "episode": 106.0, "batch_reward": 0.8434035474061966, "critic_loss": 0.8660594736635685, "actor_loss": -84.53892671203613, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.63713812828064, "step": 106000}
{"episode_reward": 905.6902069042284, "episode": 107.0, "batch_reward": 0.8451774142980576, "critic_loss": 0.8983444688618183, "actor_loss": -84.54420555114746, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.30600929260254, "step": 107000}
{"episode_reward": 898.6665737825357, "episode": 108.0, "batch_reward": 0.8433573954701423, "critic_loss": 0.9236217986047268, "actor_loss": -84.58846170043945, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.95155692100525, "step": 108000}
{"episode_reward": 850.7958362390779, "episode": 109.0, "batch_reward": 0.8444935875535011, "critic_loss": 0.8860141324698925, "actor_loss": -84.53662942504883, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.75056505203247, "step": 109000}
{"episode_reward": 916.6290596986162, "episode": 110.0, "batch_reward": 0.8460187826752663, "critic_loss": 0.8740529597699642, "actor_loss": -84.61223625183105, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.717730045318604, "step": 110000}
{"episode_reward": 935.3038607741908, "episode": 111.0, "batch_reward": 0.8458948942422867, "critic_loss": 0.8789825949072838, "actor_loss": -84.70265419006347, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.91381764411926, "step": 111000}
{"episode_reward": 920.7062914571541, "episode": 112.0, "batch_reward": 0.8466668055057526, "critic_loss": 0.9875769727528095, "actor_loss": -84.6143451538086, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.150155305862427, "step": 112000}
{"episode_reward": 783.0819149395993, "episode": 113.0, "batch_reward": 0.8471773094534873, "critic_loss": 1.000140781402588, "actor_loss": -84.71275122070313, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.862996339797974, "step": 113000}
{"episode_reward": 967.1231927394452, "episode": 114.0, "batch_reward": 0.846693828523159, "critic_loss": 0.9373838272392749, "actor_loss": -84.7168775177002, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.657678365707397, "step": 114000}
{"episode_reward": 940.5345033819353, "episode": 115.0, "batch_reward": 0.8471954988837243, "critic_loss": 0.9613692767322063, "actor_loss": -84.73421920776367, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.627434968948364, "step": 115000}
{"episode_reward": 941.3586943856336, "episode": 116.0, "batch_reward": 0.8501565291285514, "critic_loss": 0.9700146970450878, "actor_loss": -84.83004820251465, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.282896995544434, "step": 116000}
{"episode_reward": 910.0452698977621, "episode": 117.0, "batch_reward": 0.8485758364796638, "critic_loss": 0.9632049785256386, "actor_loss": -84.89632023620605, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.757707118988037, "step": 117000}
{"episode_reward": 914.2763149850804, "episode": 118.0, "batch_reward": 0.8494866185188293, "critic_loss": 0.9724422354400158, "actor_loss": -84.95699337768555, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.93943691253662, "step": 118000}
{"episode_reward": 937.5669509535741, "episode": 119.0, "batch_reward": 0.8503051338791847, "critic_loss": 0.9461037309467792, "actor_loss": -84.98196876525878, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.756314277648926, "step": 119000}
{"episode_reward": 964.1042116896049, "episode": 120.0, "batch_reward": 0.8531241378188134, "critic_loss": 0.9582262870073318, "actor_loss": -85.13308406066895, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.423943281173706, "step": 120000}
{"episode_reward": 966.6678892388328, "episode": 121.0, "batch_reward": 0.8527944808602334, "critic_loss": 0.9094759632349014, "actor_loss": -85.22112945556641, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.81066012382507, "step": 121000}
{"episode_reward": 941.5690696934005, "episode": 122.0, "batch_reward": 0.8547031227350235, "critic_loss": 0.9307493486702442, "actor_loss": -85.23284437561036, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.05928087234497, "step": 122000}
{"episode_reward": 922.4688926008382, "episode": 123.0, "batch_reward": 0.8550391918420792, "critic_loss": 0.8993206911981105, "actor_loss": -85.27062019348145, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.004095792770386, "step": 123000}
{"episode_reward": 954.9992790954623, "episode": 124.0, "batch_reward": 0.8557890744805337, "critic_loss": 0.9425745052993297, "actor_loss": -85.31911054992676, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.275476217269897, "step": 124000}
{"episode_reward": 956.2890793487089, "episode": 125.0, "batch_reward": 0.8566370643377305, "critic_loss": 0.9698986672759056, "actor_loss": -85.42157711791992, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.692338943481445, "step": 125000}
{"episode_reward": 967.0757488854324, "episode": 126.0, "batch_reward": 0.8576985857486725, "critic_loss": 0.9114020278155803, "actor_loss": -85.41664880371094, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.70944619178772, "step": 126000}
{"episode_reward": 956.8234284880417, "episode": 127.0, "batch_reward": 0.8583380895853042, "critic_loss": 0.8833429342508317, "actor_loss": -85.44262351989747, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.06342077255249, "step": 127000}
{"episode_reward": 926.433577721033, "episode": 128.0, "batch_reward": 0.8566931020021439, "critic_loss": 0.8732862764298915, "actor_loss": -85.50357228088379, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.071953058242798, "step": 128000}
{"episode_reward": 961.8064212376539, "episode": 129.0, "batch_reward": 0.8580037375688553, "critic_loss": 0.8811192851066589, "actor_loss": -85.57980685424805, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.979076147079468, "step": 129000}
{"episode_reward": 967.8511419523544, "episode": 130.0, "batch_reward": 0.8621978754401207, "critic_loss": 0.8314910802543163, "actor_loss": -85.81836091613769, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.004472255706787, "step": 130000}
{"episode_reward": 921.5500055849744, "episode": 131.0, "batch_reward": 0.8596464226841927, "critic_loss": 0.8858454577624798, "actor_loss": -85.60432019042969, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.286832332611084, "step": 131000}
{"episode_reward": 901.1160696099134, "episode": 132.0, "batch_reward": 0.8600767579674721, "critic_loss": 0.8754154223501682, "actor_loss": -85.66453160095215, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.08145546913147, "step": 132000}
{"episode_reward": 914.1362187769814, "episode": 133.0, "batch_reward": 0.8612758494019508, "critic_loss": 0.928609272301197, "actor_loss": -85.81178749084472, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.77816915512085, "step": 133000}
{"episode_reward": 965.4722483999756, "episode": 134.0, "batch_reward": 0.8617983002066613, "critic_loss": 0.9074894000291824, "actor_loss": -85.92412437438965, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.563406944274902, "step": 134000}
{"episode_reward": 918.2722049897343, "episode": 135.0, "batch_reward": 0.8618767645359039, "critic_loss": 0.9385689524412155, "actor_loss": -85.76245872497559, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.74254274368286, "step": 135000}
{"episode_reward": 914.7900685856644, "episode": 136.0, "batch_reward": 0.8633844726085663, "critic_loss": 0.8759188934266567, "actor_loss": -86.0955573425293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.594761848449707, "step": 136000}
{"episode_reward": 955.4864195604144, "episode": 137.0, "batch_reward": 0.8626033478379249, "critic_loss": 0.8559808291196823, "actor_loss": -85.89790774536132, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.756049156188965, "step": 137000}
{"episode_reward": 967.077437084896, "episode": 138.0, "batch_reward": 0.8651269673109054, "critic_loss": 0.8578385250866413, "actor_loss": -86.01256986999512, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.899760246276855, "step": 138000}
{"episode_reward": 960.7284474030008, "episode": 139.0, "batch_reward": 0.865165288746357, "critic_loss": 0.8675710536241531, "actor_loss": -86.02643914794922, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.663849353790283, "step": 139000}
{"episode_reward": 935.6460381726233, "episode": 140.0, "batch_reward": 0.8666779428124428, "critic_loss": 0.844048702687025, "actor_loss": -86.0745898590088, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.88187265396118, "step": 140000}
{"episode_reward": 952.3738411950025, "episode": 141.0, "batch_reward": 0.8656007127761841, "critic_loss": 0.8841774064898491, "actor_loss": -86.00748861694336, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.96508193016052, "step": 141000}
{"episode_reward": 956.2260577126408, "episode": 142.0, "batch_reward": 0.8659376028776169, "critic_loss": 0.8566935105919838, "actor_loss": -86.15406739807129, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.055006980895996, "step": 142000}
{"episode_reward": 949.6344203892861, "episode": 143.0, "batch_reward": 0.8668205375075341, "critic_loss": 0.9082555739283562, "actor_loss": -86.25726112365723, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.211493253707886, "step": 143000}
{"episode_reward": 960.9465185849049, "episode": 144.0, "batch_reward": 0.8683516035079956, "critic_loss": 0.8433889967501164, "actor_loss": -86.17715260314941, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.114072561264038, "step": 144000}
{"episode_reward": 897.7270528848201, "episode": 145.0, "batch_reward": 0.868004661142826, "critic_loss": 0.8220769635438919, "actor_loss": -86.23833171081543, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.07193088531494, "step": 145000}
{"episode_reward": 897.3672573695205, "episode": 146.0, "batch_reward": 0.868095831990242, "critic_loss": 0.8538652891516686, "actor_loss": -86.24865637207031, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.03601908683777, "step": 146000}
{"episode_reward": 974.6339790181023, "episode": 147.0, "batch_reward": 0.8693150848746299, "critic_loss": 0.8472441343963146, "actor_loss": -86.26470681762696, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.54996657371521, "step": 147000}
{"episode_reward": 864.952622148091, "episode": 148.0, "batch_reward": 0.8672336628437042, "critic_loss": 0.842228986889124, "actor_loss": -86.29228746032715, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.39611315727234, "step": 148000}
{"episode_reward": 888.7601139448687, "episode": 149.0, "batch_reward": 0.8679009873867035, "critic_loss": 0.8357489732205867, "actor_loss": -86.33995960998536, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.04356861114502, "step": 149000}
{"episode_reward": 946.3817390083774, "episode": 150.0, "batch_reward": 0.8678462041616439, "critic_loss": 0.8291883919537067, "actor_loss": -86.2143282775879, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
