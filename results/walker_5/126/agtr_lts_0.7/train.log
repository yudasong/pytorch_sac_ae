{"episode_reward": 0.0, "episode": 1.0, "duration": 20.524282455444336, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.7851920127868652, "step": 2000}
{"episode_reward": 847.8889533166544, "episode": 3.0, "batch_reward": 0.47229216455737527, "critic_loss": 0.3184759528036116, "actor_loss": -84.69891902989222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.655794620513916, "step": 3000}
{"episode_reward": 851.9130787053601, "episode": 4.0, "batch_reward": 0.5805590901970863, "critic_loss": 0.5991837129741907, "actor_loss": -86.55002334594727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098862409591675, "step": 4000}
{"episode_reward": 736.0624911261721, "episode": 5.0, "batch_reward": 0.6456038197875023, "critic_loss": 0.551266375362873, "actor_loss": -87.99700144958496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098119735717773, "step": 5000}
{"episode_reward": 916.2119585610449, "episode": 6.0, "batch_reward": 0.7026560215353965, "critic_loss": 0.6876637931466103, "actor_loss": -89.45080130004882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.078384399414062, "step": 6000}
{"episode_reward": 955.1284116210343, "episode": 7.0, "batch_reward": 0.7380838248729705, "critic_loss": 1.0378382730782032, "actor_loss": -90.28245330810547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108829736709595, "step": 7000}
{"episode_reward": 941.7490407251514, "episode": 8.0, "batch_reward": 0.7633628581762314, "critic_loss": 2.350535422295332, "actor_loss": -91.14263253784179, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.106956720352173, "step": 8000}
{"episode_reward": 916.930505073092, "episode": 9.0, "batch_reward": 0.7866031441092491, "critic_loss": 6.3700202085375786, "actor_loss": -92.48819354248047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09142565727234, "step": 9000}
{"episode_reward": 969.3387149465824, "episode": 10.0, "batch_reward": 0.8055634138584137, "critic_loss": 7.196947007417679, "actor_loss": -93.8336703338623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091898918151855, "step": 10000}
{"episode_reward": 837.6226085447489, "episode": 11.0, "batch_reward": 0.802478872537613, "critic_loss": 10.222123365521432, "actor_loss": -95.1392038116455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.50765919685364, "step": 11000}
{"episode_reward": 584.1456392119802, "episode": 12.0, "batch_reward": 0.7524371762275696, "critic_loss": 8.583365216493606, "actor_loss": -96.7263014831543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.118934869766235, "step": 12000}
{"episode_reward": 25.399721093653138, "episode": 13.0, "batch_reward": 0.6924281055331231, "critic_loss": 5.308675461769104, "actor_loss": -98.05777931213379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.118919610977173, "step": 13000}
{"episode_reward": 27.192194262007785, "episode": 14.0, "batch_reward": 0.6669505241513253, "critic_loss": 5.010622643947602, "actor_loss": -98.98055961608887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12096858024597, "step": 14000}
{"episode_reward": 465.90124162081554, "episode": 15.0, "batch_reward": 0.6305743336081505, "critic_loss": 5.423674706459045, "actor_loss": -102.17451466369629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13910484313965, "step": 15000}
{"episode_reward": 48.71703581931021, "episode": 16.0, "batch_reward": 0.6021234684884548, "critic_loss": 12.23163192462921, "actor_loss": -100.5211809539795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.119908571243286, "step": 16000}
{"episode_reward": 247.20593684553126, "episode": 17.0, "batch_reward": 0.5745272678136826, "critic_loss": 12.981430226325989, "actor_loss": -103.79501069641114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.139998197555542, "step": 17000}
{"episode_reward": 51.07024094169013, "episode": 18.0, "batch_reward": 0.5429222227632999, "critic_loss": 10.968402947425842, "actor_loss": -103.62834130859375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.123295783996582, "step": 18000}
{"episode_reward": 50.86609894537874, "episode": 19.0, "batch_reward": 0.5290679724514484, "critic_loss": 9.813437184810638, "actor_loss": -103.03166288757325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.114009141921997, "step": 19000}
{"episode_reward": 331.53386388170435, "episode": 20.0, "batch_reward": 0.5079870809018612, "critic_loss": 8.326867105484009, "actor_loss": -107.32920242309571, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11269760131836, "step": 20000}
{"episode_reward": 24.93840416499687, "episode": 21.0, "batch_reward": 0.5004576480090618, "critic_loss": 7.319260781049729, "actor_loss": -107.23830917358399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.43422603607178, "step": 21000}
{"episode_reward": 776.3763343360865, "episode": 22.0, "batch_reward": 0.4948047038912773, "critic_loss": 6.419007163524627, "actor_loss": -107.83495721435547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.123061418533325, "step": 22000}
{"episode_reward": 25.338608336473545, "episode": 23.0, "batch_reward": 0.4906005375981331, "critic_loss": 6.864661094665528, "actor_loss": -106.79732765197754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10572862625122, "step": 23000}
{"episode_reward": 845.5627097425796, "episode": 24.0, "batch_reward": 0.4920622525811195, "critic_loss": 6.386615316390992, "actor_loss": -105.45935192871094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.107425928115845, "step": 24000}
{"episode_reward": 29.326605490437554, "episode": 25.0, "batch_reward": 0.4741508966386318, "critic_loss": 5.175823561191558, "actor_loss": -105.82462431335449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.122395515441895, "step": 25000}
{"episode_reward": 27.661475250428374, "episode": 26.0, "batch_reward": 0.4748167989552021, "critic_loss": 4.004627427697182, "actor_loss": -104.9988957824707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11307191848755, "step": 26000}
{"episode_reward": 961.6434232396704, "episode": 27.0, "batch_reward": 0.49095622086524965, "critic_loss": 3.1311095004081726, "actor_loss": -105.48820378112794, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109524250030518, "step": 27000}
{"episode_reward": 961.8465502406758, "episode": 28.0, "batch_reward": 0.5055686759054661, "critic_loss": 2.506320110917091, "actor_loss": -102.85306199645996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108956575393677, "step": 28000}
{"episode_reward": 915.4945038785439, "episode": 29.0, "batch_reward": 0.515714821100235, "critic_loss": 2.425304619908333, "actor_loss": -103.4958857269287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.111000299453735, "step": 29000}
{"episode_reward": 429.29725018597463, "episode": 30.0, "batch_reward": 0.5183346876204014, "critic_loss": 2.0626263155341147, "actor_loss": -102.63178871154786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11505699157715, "step": 30000}
{"episode_reward": 910.4519686531532, "episode": 31.0, "batch_reward": 0.5309485921263695, "critic_loss": 1.7176219054460526, "actor_loss": -100.45554354858399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.51160788536072, "step": 31000}
{"episode_reward": 925.3749863292156, "episode": 32.0, "batch_reward": 0.5303621737360954, "critic_loss": 1.565804792702198, "actor_loss": -100.06347421264648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.126213788986206, "step": 32000}
{"episode_reward": 32.81048906614563, "episode": 33.0, "batch_reward": 0.5163205954432487, "critic_loss": 1.4636532056331635, "actor_loss": -99.30399215698242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.112775087356567, "step": 33000}
{"episode_reward": 36.76223706883185, "episode": 34.0, "batch_reward": 0.5028867731392384, "critic_loss": 1.3439762753844262, "actor_loss": -97.05559523010254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.115671396255493, "step": 34000}
{"episode_reward": 450.07655401410227, "episode": 35.0, "batch_reward": 0.5127514788210392, "critic_loss": 1.3677142575979233, "actor_loss": -98.10361895751953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.101954460144043, "step": 35000}
{"episode_reward": 933.5977452112653, "episode": 36.0, "batch_reward": 0.5195813382863999, "critic_loss": 1.1993022025227547, "actor_loss": -95.89071560668945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.084083318710327, "step": 36000}
{"episode_reward": 834.81807850702, "episode": 37.0, "batch_reward": 0.5323903026878833, "critic_loss": 1.1086070459485053, "actor_loss": -96.34865972900391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10426378250122, "step": 37000}
{"episode_reward": 959.9386814250399, "episode": 38.0, "batch_reward": 0.5444529585540294, "critic_loss": 0.9905863711237908, "actor_loss": -96.68376805114747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09942650794983, "step": 38000}
{"episode_reward": 984.458163373812, "episode": 39.0, "batch_reward": 0.5541277973055839, "critic_loss": 1.0823984304666519, "actor_loss": -95.21417927551269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.105635404586792, "step": 39000}
{"episode_reward": 915.5116269627604, "episode": 40.0, "batch_reward": 0.5613356373906135, "critic_loss": 0.9073475930988789, "actor_loss": -94.88114993286133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.106821298599243, "step": 40000}
{"episode_reward": 921.4273266897757, "episode": 41.0, "batch_reward": 0.5725561487674713, "critic_loss": 0.8327155530452728, "actor_loss": -94.29095051574707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.44314193725586, "step": 41000}
{"episode_reward": 950.6570527409405, "episode": 42.0, "batch_reward": 0.5829644978642464, "critic_loss": 0.8131514228284359, "actor_loss": -94.66737919616699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11359143257141, "step": 42000}
{"episode_reward": 948.6037610269298, "episode": 43.0, "batch_reward": 0.5910558299124241, "critic_loss": 0.7923088630884886, "actor_loss": -93.90450904846192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.122177362442017, "step": 43000}
{"episode_reward": 939.5957997458752, "episode": 44.0, "batch_reward": 0.5983916604816913, "critic_loss": 0.8178547503948211, "actor_loss": -94.32438931274415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087846040725708, "step": 44000}
{"episode_reward": 890.9294017540981, "episode": 45.0, "batch_reward": 0.6045138343274593, "critic_loss": 0.8723438446521758, "actor_loss": -94.36598982238769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.099156618118286, "step": 45000}
{"episode_reward": 901.2978747262101, "episode": 46.0, "batch_reward": 0.611407331854105, "critic_loss": 0.8009899186193943, "actor_loss": -93.76639193725586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09109878540039, "step": 46000}
{"episode_reward": 957.4838291169428, "episode": 47.0, "batch_reward": 0.6158766806423664, "critic_loss": 0.9270126953721046, "actor_loss": -93.36245126342773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100293159484863, "step": 47000}
{"episode_reward": 896.6181981745018, "episode": 48.0, "batch_reward": 0.625356842637062, "critic_loss": 0.8525582842826843, "actor_loss": -93.29020196533203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.101066827774048, "step": 48000}
{"episode_reward": 931.6272661716426, "episode": 49.0, "batch_reward": 0.6278767508864402, "critic_loss": 0.9323205710053444, "actor_loss": -93.11215800476074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.104183435440063, "step": 49000}
{"episode_reward": 825.7831819493143, "episode": 50.0, "batch_reward": 0.6352596179842949, "critic_loss": 0.8656308597326279, "actor_loss": -93.15327244567871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093942403793335, "step": 50000}
{"episode_reward": 932.7752129715388, "episode": 51.0, "batch_reward": 0.6424216505289078, "critic_loss": 0.8764201521873474, "actor_loss": -92.79925611877441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.440184116363525, "step": 51000}
{"episode_reward": 971.0313677425016, "episode": 52.0, "batch_reward": 0.6474948375821113, "critic_loss": 0.8802851893007755, "actor_loss": -92.38794776916504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.117536544799805, "step": 52000}
{"episode_reward": 936.9571875188293, "episode": 53.0, "batch_reward": 0.6551479959487915, "critic_loss": 0.7965737967044115, "actor_loss": -92.7510428314209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.104666233062744, "step": 53000}
{"episode_reward": 952.7110095349323, "episode": 54.0, "batch_reward": 0.6593250250816345, "critic_loss": 0.8358813453018665, "actor_loss": -91.89488174438476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08324933052063, "step": 54000}
{"episode_reward": 950.0144196253951, "episode": 55.0, "batch_reward": 0.6665517864227295, "critic_loss": 0.7133893489986658, "actor_loss": -91.94338423156738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.112844944000244, "step": 55000}
{"episode_reward": 980.7880052143094, "episode": 56.0, "batch_reward": 0.66919615650177, "critic_loss": 0.767046411126852, "actor_loss": -91.97119123840332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.210347175598145, "step": 56000}
{"episode_reward": 982.8459630760374, "episode": 57.0, "batch_reward": 0.6754777929782867, "critic_loss": 0.7981436023116112, "actor_loss": -91.8490414428711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.316267013549805, "step": 57000}
{"episode_reward": 927.562107361753, "episode": 58.0, "batch_reward": 0.6792517646551132, "critic_loss": 0.930669051349163, "actor_loss": -91.77694734191894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.083675146102905, "step": 58000}
{"episode_reward": 977.8045683370273, "episode": 59.0, "batch_reward": 0.6841262308955193, "critic_loss": 0.8116384215354919, "actor_loss": -91.80999369812012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.069639444351196, "step": 59000}
{"episode_reward": 985.1533580741835, "episode": 60.0, "batch_reward": 0.6896888070702553, "critic_loss": 0.8242583687603474, "actor_loss": -91.83691340637208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108330488204956, "step": 60000}
{"episode_reward": 946.3246588473202, "episode": 61.0, "batch_reward": 0.6934583224058152, "critic_loss": 0.9116218354701996, "actor_loss": -91.81093334960937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.44358825683594, "step": 61000}
{"episode_reward": 949.1355562560776, "episode": 62.0, "batch_reward": 0.6970039119720459, "critic_loss": 0.8056431452035904, "actor_loss": -92.05196951293945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.111464738845825, "step": 62000}
{"episode_reward": 983.4455694380041, "episode": 63.0, "batch_reward": 0.703098454773426, "critic_loss": 0.8363419317156077, "actor_loss": -92.18956959533692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.427993297576904, "step": 63000}
{"episode_reward": 984.4648900564763, "episode": 64.0, "batch_reward": 0.7084220597147941, "critic_loss": 0.9076890375763178, "actor_loss": -92.33022886657714, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.117833614349365, "step": 64000}
{"episode_reward": 902.6934050202204, "episode": 65.0, "batch_reward": 0.7101816790103912, "critic_loss": 0.9188231483995914, "actor_loss": -92.38380113220215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094820976257324, "step": 65000}
{"episode_reward": 957.6915412911435, "episode": 66.0, "batch_reward": 0.7142739694714546, "critic_loss": 0.8932250806987285, "actor_loss": -92.40181704711914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11633586883545, "step": 66000}
{"episode_reward": 984.8365604528714, "episode": 67.0, "batch_reward": 0.7175647853016853, "critic_loss": 0.8985019252896309, "actor_loss": -92.39747734069825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12564706802368, "step": 67000}
{"episode_reward": 953.7936639534571, "episode": 68.0, "batch_reward": 0.7213797698020935, "critic_loss": 0.9031585692167282, "actor_loss": -92.30357460021973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12645936012268, "step": 68000}
{"episode_reward": 960.207229044165, "episode": 69.0, "batch_reward": 0.7274985086321831, "critic_loss": 0.9506532132923603, "actor_loss": -92.38584587097168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.106051683425903, "step": 69000}
{"episode_reward": 968.5038772619952, "episode": 70.0, "batch_reward": 0.7274256065487862, "critic_loss": 1.1349294304698705, "actor_loss": -92.20810731506347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.112890243530273, "step": 70000}
{"episode_reward": 945.7415813423602, "episode": 71.0, "batch_reward": 0.7313761432766914, "critic_loss": 1.2383875516206027, "actor_loss": -92.42751707458496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.41824197769165, "step": 71000}
{"episode_reward": 951.5465284443967, "episode": 72.0, "batch_reward": 0.7351488824486733, "critic_loss": 1.5153996456563472, "actor_loss": -92.34410079956055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.117092609405518, "step": 72000}
{"episode_reward": 932.6789139303338, "episode": 73.0, "batch_reward": 0.7355649731159211, "critic_loss": 2.2880251611173152, "actor_loss": -92.23620123291016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.115736961364746, "step": 73000}
{"episode_reward": 896.912379914607, "episode": 74.0, "batch_reward": 0.7372668799161911, "critic_loss": 5.930660394012928, "actor_loss": -92.58262411499024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.116937398910522, "step": 74000}
{"episode_reward": 579.6653449949513, "episode": 75.0, "batch_reward": 0.7375138646960259, "critic_loss": 22.534904014348985, "actor_loss": -96.65083982849121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12479043006897, "step": 75000}
{"episode_reward": 747.2168650719694, "episode": 76.0, "batch_reward": 0.7362527123689652, "critic_loss": 49.58225015258789, "actor_loss": -106.89783915710449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12721347808838, "step": 76000}
{"episode_reward": 827.8455644244792, "episode": 77.0, "batch_reward": 0.7378074315786362, "critic_loss": 75.64314267921448, "actor_loss": -117.98736888122559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.132641553878784, "step": 77000}
{"episode_reward": 742.2492889787118, "episode": 78.0, "batch_reward": 0.7333592000007629, "critic_loss": 64.05106834030151, "actor_loss": -121.89951538085937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13426923751831, "step": 78000}
{"episode_reward": 421.53401299450564, "episode": 79.0, "batch_reward": 0.729069050014019, "critic_loss": 46.37602445793152, "actor_loss": -127.12808515930176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.160372734069824, "step": 79000}
{"episode_reward": 318.03256354296667, "episode": 80.0, "batch_reward": 0.7260091977715493, "critic_loss": 32.973023604393006, "actor_loss": -129.0722555847168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14910125732422, "step": 80000}
{"episode_reward": 243.0717247164073, "episode": 81.0, "batch_reward": 0.7240100156664848, "critic_loss": 26.33833901309967, "actor_loss": -133.61376820373536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.575783014297485, "step": 81000}
{"episode_reward": 834.2773945768026, "episode": 82.0, "batch_reward": 0.7225544475317002, "critic_loss": 22.167901049613953, "actor_loss": -132.39237147521973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.125845193862915, "step": 82000}
{"episode_reward": 964.1727008926576, "episode": 83.0, "batch_reward": 0.7294526541829109, "critic_loss": 17.000778361320496, "actor_loss": -126.25426126098633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.125206232070923, "step": 83000}
{"episode_reward": 959.3735844268659, "episode": 84.0, "batch_reward": 0.7281987945437431, "critic_loss": 13.529148441314698, "actor_loss": -125.54809629821777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.121037006378174, "step": 84000}
{"episode_reward": 934.6805541641509, "episode": 85.0, "batch_reward": 0.7332206892371178, "critic_loss": 12.245637893438339, "actor_loss": -131.1209810180664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.118112564086914, "step": 85000}
{"episode_reward": 945.0917938396046, "episode": 86.0, "batch_reward": 0.7345566185712814, "critic_loss": 10.538342957258225, "actor_loss": -128.2103778991699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.119800806045532, "step": 86000}
{"episode_reward": 956.4784724693704, "episode": 87.0, "batch_reward": 0.7375214146375656, "critic_loss": 8.636649956226348, "actor_loss": -125.96523095703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.116952896118164, "step": 87000}
{"episode_reward": 922.4943573883036, "episode": 88.0, "batch_reward": 0.7414778054356576, "critic_loss": 7.381317944049835, "actor_loss": -123.16852975463867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100811004638672, "step": 88000}
{"episode_reward": 975.7834615592609, "episode": 89.0, "batch_reward": 0.7443822763562202, "critic_loss": 5.860474263429642, "actor_loss": -126.07347584533692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109343767166138, "step": 89000}
{"episode_reward": 883.5678113191092, "episode": 90.0, "batch_reward": 0.7439297887086869, "critic_loss": 5.047652345776558, "actor_loss": -121.50966488647461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.131893157958984, "step": 90000}
{"episode_reward": 956.3546680713649, "episode": 91.0, "batch_reward": 0.7473497247695923, "critic_loss": 4.499042566180229, "actor_loss": -122.18570129394531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.40873742103577, "step": 91000}
{"episode_reward": 932.4792565336095, "episode": 92.0, "batch_reward": 0.7493184832334518, "critic_loss": 3.54099720621109, "actor_loss": -119.67230117797851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.107917547225952, "step": 92000}
{"episode_reward": 982.8986215720626, "episode": 93.0, "batch_reward": 0.7526521010994911, "critic_loss": 3.0150800827741624, "actor_loss": -117.72896858215331, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.121620655059814, "step": 93000}
{"episode_reward": 984.8260460431355, "episode": 94.0, "batch_reward": 0.7527736377716064, "critic_loss": 2.944112776339054, "actor_loss": -113.80879843139648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12731385231018, "step": 94000}
{"episode_reward": 924.0999686709272, "episode": 95.0, "batch_reward": 0.7549816992878914, "critic_loss": 2.7996159202456474, "actor_loss": -113.60982899475097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.141761302947998, "step": 95000}
{"episode_reward": 863.2349042676713, "episode": 96.0, "batch_reward": 0.7581869111657142, "critic_loss": 2.6591969821453096, "actor_loss": -114.0500492401123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15436100959778, "step": 96000}
{"episode_reward": 934.2003475127191, "episode": 97.0, "batch_reward": 0.757220385313034, "critic_loss": 2.2734808726906777, "actor_loss": -113.2751572265625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.136487007141113, "step": 97000}
{"episode_reward": 958.5474990329762, "episode": 98.0, "batch_reward": 0.760730673968792, "critic_loss": 2.1098006938099862, "actor_loss": -113.59409538269043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.151094436645508, "step": 98000}
{"episode_reward": 950.7316411694077, "episode": 99.0, "batch_reward": 0.7613744210600853, "critic_loss": 1.8990016275048256, "actor_loss": -111.47533433532715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.141651153564453, "step": 99000}
{"episode_reward": 890.239164380875, "episode": 100.0, "batch_reward": 0.7612335885167122, "critic_loss": 1.6619657619595527, "actor_loss": -110.41161711120606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11987543106079, "step": 100000}
{"episode_reward": 970.0431056623969, "episode": 101.0, "batch_reward": 0.765418794631958, "critic_loss": 1.555394917488098, "actor_loss": -110.24695486450196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.39788460731506, "step": 101000}
{"episode_reward": 985.608818253854, "episode": 102.0, "batch_reward": 0.768975050508976, "critic_loss": 1.4715155597627163, "actor_loss": -106.46496366882324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097392559051514, "step": 102000}
{"episode_reward": 926.6099328092861, "episode": 103.0, "batch_reward": 0.77144845610857, "critic_loss": 1.3958050371408464, "actor_loss": -108.94548753356933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087255477905273, "step": 103000}
{"episode_reward": 948.6761021231699, "episode": 104.0, "batch_reward": 0.770536364197731, "critic_loss": 1.3905804371535777, "actor_loss": -106.76343185424804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1311092376709, "step": 104000}
{"episode_reward": 955.0771033542463, "episode": 105.0, "batch_reward": 0.7727849033474922, "critic_loss": 1.2988522264063358, "actor_loss": -108.03848442077637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091877460479736, "step": 105000}
{"episode_reward": 982.4202297542681, "episode": 106.0, "batch_reward": 0.773953604876995, "critic_loss": 1.1810494400560856, "actor_loss": -104.55649058532715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10350728034973, "step": 106000}
{"episode_reward": 952.6194428932238, "episode": 107.0, "batch_reward": 0.7760004253387451, "critic_loss": 1.1488299921154976, "actor_loss": -105.34585400390625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1056547164917, "step": 107000}
{"episode_reward": 939.7802277954025, "episode": 108.0, "batch_reward": 0.7763607109189034, "critic_loss": 1.0615777556598187, "actor_loss": -106.45353730773925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097060680389404, "step": 108000}
{"episode_reward": 946.3568217204111, "episode": 109.0, "batch_reward": 0.7789714301228523, "critic_loss": 1.0790108228325843, "actor_loss": -103.53825747680663, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08127737045288, "step": 109000}
{"episode_reward": 896.8461150383471, "episode": 110.0, "batch_reward": 0.7811406240463257, "critic_loss": 1.0682521304786206, "actor_loss": -104.28076582336426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.096011877059937, "step": 110000}
{"episode_reward": 906.8965477415554, "episode": 111.0, "batch_reward": 0.7809136075973511, "critic_loss": 1.0633295284807682, "actor_loss": -104.41985708618164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.39778113365173, "step": 111000}
{"episode_reward": 983.5346142066525, "episode": 112.0, "batch_reward": 0.7847235985994339, "critic_loss": 1.0136923787891865, "actor_loss": -102.50716102600097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.119357585906982, "step": 112000}
{"episode_reward": 942.8894963848771, "episode": 113.0, "batch_reward": 0.7853165867924691, "critic_loss": 1.0141960723996162, "actor_loss": -102.27515284729004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.081253051757812, "step": 113000}
{"episode_reward": 982.2493302645732, "episode": 114.0, "batch_reward": 0.7874136666059494, "critic_loss": 1.0234369369149208, "actor_loss": -100.95638737487793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11235284805298, "step": 114000}
{"episode_reward": 982.9727919115303, "episode": 115.0, "batch_reward": 0.7865127086639404, "critic_loss": 0.9760102051198483, "actor_loss": -101.42961814880371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109185695648193, "step": 115000}
{"episode_reward": 960.9114124290942, "episode": 116.0, "batch_reward": 0.7930888472795486, "critic_loss": 0.928960101634264, "actor_loss": -100.97709169006347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.122743606567383, "step": 116000}
{"episode_reward": 948.255506241471, "episode": 117.0, "batch_reward": 0.7883592110872268, "critic_loss": 0.879583065032959, "actor_loss": -101.474383102417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.115879774093628, "step": 117000}
{"episode_reward": 944.3717848795153, "episode": 118.0, "batch_reward": 0.7929796901345253, "critic_loss": 0.9178218581974507, "actor_loss": -100.52777912902832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.122586488723755, "step": 118000}
{"episode_reward": 927.9559887602018, "episode": 119.0, "batch_reward": 0.7936736239790917, "critic_loss": 0.8900947431325913, "actor_loss": -99.9311837310791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.113104820251465, "step": 119000}
{"episode_reward": 958.9099222026366, "episode": 120.0, "batch_reward": 0.795780609190464, "critic_loss": 0.8366468526273966, "actor_loss": -100.29328880310058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10720682144165, "step": 120000}
{"episode_reward": 977.6070171032196, "episode": 121.0, "batch_reward": 0.7966652032732964, "critic_loss": 0.8033984009325504, "actor_loss": -100.00001010131835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.385722398757935, "step": 121000}
{"episode_reward": 916.7396669293591, "episode": 122.0, "batch_reward": 0.7981048815250397, "critic_loss": 0.8029074603021145, "actor_loss": -99.24957737731934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07885479927063, "step": 122000}
{"episode_reward": 957.4769034399333, "episode": 123.0, "batch_reward": 0.799841540157795, "critic_loss": 0.8070063717067242, "actor_loss": -98.21046365356446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.089175939559937, "step": 123000}
{"episode_reward": 981.4226077476798, "episode": 124.0, "batch_reward": 0.8013117030858994, "critic_loss": 0.8384086040109396, "actor_loss": -98.22387965393067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.070335865020752, "step": 124000}
{"episode_reward": 980.859882882708, "episode": 125.0, "batch_reward": 0.8024793680906296, "critic_loss": 0.7823391910791397, "actor_loss": -98.22810350036622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.086726903915405, "step": 125000}
{"episode_reward": 984.2218706991333, "episode": 126.0, "batch_reward": 0.803301374912262, "critic_loss": 0.7984782993346453, "actor_loss": -98.26395286560059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085245847702026, "step": 126000}
{"episode_reward": 977.7236774929131, "episode": 127.0, "batch_reward": 0.8022511393427849, "critic_loss": 0.807403928115964, "actor_loss": -97.9611724243164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08632206916809, "step": 127000}
{"episode_reward": 979.4537824646643, "episode": 128.0, "batch_reward": 0.8052923039197922, "critic_loss": 0.721956611186266, "actor_loss": -97.50836293029785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.078736305236816, "step": 128000}
{"episode_reward": 914.138342144117, "episode": 129.0, "batch_reward": 0.8054956213235855, "critic_loss": 0.7064562235027552, "actor_loss": -97.53404084777831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.084925889968872, "step": 129000}
{"episode_reward": 981.3699842024885, "episode": 130.0, "batch_reward": 0.8093299489021302, "critic_loss": 0.7844582616090775, "actor_loss": -97.47525485229492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.107402801513672, "step": 130000}
{"episode_reward": 960.1999169808316, "episode": 131.0, "batch_reward": 0.8091486818790435, "critic_loss": 0.7027855203598737, "actor_loss": -97.06891983032227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.44251585006714, "step": 131000}
{"episode_reward": 952.5029395653314, "episode": 132.0, "batch_reward": 0.8094281431436539, "critic_loss": 0.6934606142193079, "actor_loss": -96.65682849121093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0709707736969, "step": 132000}
{"episode_reward": 925.8541761029634, "episode": 133.0, "batch_reward": 0.8121499988436699, "critic_loss": 0.6838391501456499, "actor_loss": -96.64928413391114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08371663093567, "step": 133000}
{"episode_reward": 975.2947273489158, "episode": 134.0, "batch_reward": 0.8135503048300743, "critic_loss": 0.6555421304106712, "actor_loss": -96.72294194030762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.071593046188354, "step": 134000}
{"episode_reward": 962.5275340034207, "episode": 135.0, "batch_reward": 0.8145976722836494, "critic_loss": 0.6625712084770202, "actor_loss": -96.36356776428222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07355546951294, "step": 135000}
{"episode_reward": 939.0578454702273, "episode": 136.0, "batch_reward": 0.8152147646546364, "critic_loss": 0.6209272057712079, "actor_loss": -96.7071407775879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.385416507720947, "step": 136000}
{"episode_reward": 951.6755636001767, "episode": 137.0, "batch_reward": 0.8156975851655006, "critic_loss": 0.6750350368022918, "actor_loss": -95.99189427185058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.070435762405396, "step": 137000}
{"episode_reward": 981.2917925797161, "episode": 138.0, "batch_reward": 0.8168262667059898, "critic_loss": 0.672036115437746, "actor_loss": -95.75603155517578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.051405906677246, "step": 138000}
{"episode_reward": 987.4579856203084, "episode": 139.0, "batch_reward": 0.8191560667753219, "critic_loss": 0.6576925221383572, "actor_loss": -95.78807225036621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.073848009109497, "step": 139000}
{"episode_reward": 958.9839815020014, "episode": 140.0, "batch_reward": 0.8207684808969498, "critic_loss": 0.6477112776786089, "actor_loss": -95.7843106842041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.083396911621094, "step": 140000}
{"episode_reward": 986.8175989227343, "episode": 141.0, "batch_reward": 0.819514019548893, "critic_loss": 0.6219492655992508, "actor_loss": -95.51658874511719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.3439040184021, "step": 141000}
{"episode_reward": 958.86923646106, "episode": 142.0, "batch_reward": 0.8194119530320167, "critic_loss": 0.6455023879110813, "actor_loss": -95.68208053588867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08324646949768, "step": 142000}
{"episode_reward": 971.9492417465543, "episode": 143.0, "batch_reward": 0.821621674656868, "critic_loss": 0.6414538546055555, "actor_loss": -95.46643339538574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.090467929840088, "step": 143000}
{"episode_reward": 950.5110286000838, "episode": 144.0, "batch_reward": 0.8234630343317986, "critic_loss": 0.613883175805211, "actor_loss": -95.3350071105957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.079370975494385, "step": 144000}
{"episode_reward": 943.063558358014, "episode": 145.0, "batch_reward": 0.8240477961301803, "critic_loss": 0.5927138313055038, "actor_loss": -95.1491937713623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077125310897827, "step": 145000}
{"episode_reward": 924.565547169305, "episode": 146.0, "batch_reward": 0.8246681299805642, "critic_loss": 0.6467265652567148, "actor_loss": -94.9931971282959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.071928024291992, "step": 146000}
{"episode_reward": 983.8427310475267, "episode": 147.0, "batch_reward": 0.8264111931920052, "critic_loss": 0.6666551579982042, "actor_loss": -95.04117636108398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08196759223938, "step": 147000}
{"episode_reward": 937.264089263024, "episode": 148.0, "batch_reward": 0.8263747296929359, "critic_loss": 0.6744013592004776, "actor_loss": -94.87427076721191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077356338500977, "step": 148000}
{"episode_reward": 955.9019622813643, "episode": 149.0, "batch_reward": 0.828407277226448, "critic_loss": 0.5937644644975663, "actor_loss": -95.00311366271973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.103325605392456, "step": 149000}
{"episode_reward": 986.6821935837603, "episode": 150.0, "batch_reward": 0.8289710297584534, "critic_loss": 0.5943418935984373, "actor_loss": -94.72715705871582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
