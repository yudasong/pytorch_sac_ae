{"episode_reward": 0.0, "episode": 1.0, "duration": 34.20901679992676, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 3.08040452003479, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.30914653210629617, "critic_loss": 0.6420572786062468, "actor_loss": -70.23682368760493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 87.57601618766785, "step": 3000}
{"episode_reward": 642.252489340947, "episode": 4.0, "batch_reward": 0.42764593204855916, "critic_loss": 1.0694494333565234, "actor_loss": -74.51688885498046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.842355012893677, "step": 4000}
{"episode_reward": 562.9241187379903, "episode": 5.0, "batch_reward": 0.4696059442460537, "critic_loss": 0.9274707533717156, "actor_loss": -75.71717991638184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.704347372055054, "step": 5000}
{"episode_reward": 787.4348469522765, "episode": 6.0, "batch_reward": 0.5301686586737633, "critic_loss": 0.8461051176786423, "actor_loss": -77.2070479888916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.485857009887695, "step": 6000}
{"episode_reward": 705.8119676090504, "episode": 7.0, "batch_reward": 0.5479612560272217, "critic_loss": 0.8460512048304081, "actor_loss": -77.31172071838378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.55570650100708, "step": 7000}
{"episode_reward": 684.6695244423868, "episode": 8.0, "batch_reward": 0.5814869840145112, "critic_loss": 0.8330765206515789, "actor_loss": -77.91461651611328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.161645889282227, "step": 8000}
{"episode_reward": 828.5798568983454, "episode": 9.0, "batch_reward": 0.6143888244628907, "critic_loss": 0.8452730180621147, "actor_loss": -78.6607947845459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.149858474731445, "step": 9000}
{"episode_reward": 877.8549505458594, "episode": 10.0, "batch_reward": 0.6412681938409805, "critic_loss": 0.8413785842955113, "actor_loss": -79.35516220092774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.902733087539673, "step": 10000}
{"episode_reward": 887.8456460670286, "episode": 11.0, "batch_reward": 0.6660661923289299, "critic_loss": 0.8775574942827225, "actor_loss": -80.08080462646484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.48592066764832, "step": 11000}
{"episode_reward": 843.4006404653235, "episode": 12.0, "batch_reward": 0.6747295201420784, "critic_loss": 0.989456723690033, "actor_loss": -80.28014784240723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.627995252609253, "step": 12000}
{"episode_reward": 774.9137951927004, "episode": 13.0, "batch_reward": 0.6828638147115708, "critic_loss": 0.9532485898435116, "actor_loss": -80.54396719360352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.967721462249756, "step": 13000}
{"episode_reward": 819.0996979375755, "episode": 14.0, "batch_reward": 0.6953166253566742, "critic_loss": 0.8559709953665733, "actor_loss": -80.93238525390625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.780577898025513, "step": 14000}
{"episode_reward": 862.4534828150531, "episode": 15.0, "batch_reward": 0.7096507017612457, "critic_loss": 0.8250566939115525, "actor_loss": -81.21525318908691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.444432258605957, "step": 15000}
{"episode_reward": 885.8563935770521, "episode": 16.0, "batch_reward": 0.7170941730737687, "critic_loss": 0.8298710483312607, "actor_loss": -81.51595126342774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.11203956604004, "step": 16000}
{"episode_reward": 780.5236906492772, "episode": 17.0, "batch_reward": 0.7194442448616027, "critic_loss": 0.8139576503932476, "actor_loss": -81.54051403808593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.638437271118164, "step": 17000}
{"episode_reward": 818.4164840939111, "episode": 18.0, "batch_reward": 0.7253209531903267, "critic_loss": 0.8976317567825317, "actor_loss": -81.53196058654785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.50235080718994, "step": 18000}
{"episode_reward": 747.0725379700091, "episode": 19.0, "batch_reward": 0.7281442903280259, "critic_loss": 0.8561452607810497, "actor_loss": -81.59785531616211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.42617130279541, "step": 19000}
{"episode_reward": 871.6216069865669, "episode": 20.0, "batch_reward": 0.7362100156545639, "critic_loss": 0.8630781267583371, "actor_loss": -81.62458628845215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.85178017616272, "step": 20000}
{"episode_reward": 797.4620731007383, "episode": 21.0, "batch_reward": 0.7412690025568008, "critic_loss": 0.7914991448819637, "actor_loss": -81.84850717163086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.03895950317383, "step": 21000}
{"episode_reward": 866.4040766909009, "episode": 22.0, "batch_reward": 0.7453077594041825, "critic_loss": 0.8284606756567955, "actor_loss": -81.93941256713867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.8785138130188, "step": 22000}
{"episode_reward": 860.6485767629883, "episode": 23.0, "batch_reward": 0.7480118990540504, "critic_loss": 0.7562794106900692, "actor_loss": -82.08040315246582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.201757669448853, "step": 23000}
{"episode_reward": 854.189179670109, "episode": 24.0, "batch_reward": 0.7553389514088631, "critic_loss": 0.7303943545818329, "actor_loss": -82.30778753662109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.665131330490112, "step": 24000}
{"episode_reward": 888.0397156577734, "episode": 25.0, "batch_reward": 0.7604824947714806, "critic_loss": 0.729696476072073, "actor_loss": -82.34851777648926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.695648670196533, "step": 25000}
{"episode_reward": 890.0408348664675, "episode": 26.0, "batch_reward": 0.765851173043251, "critic_loss": 0.664303639948368, "actor_loss": -82.4994972076416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.199671030044556, "step": 26000}
{"episode_reward": 894.4489685774906, "episode": 27.0, "batch_reward": 0.7714375388622284, "critic_loss": 0.6726365966498852, "actor_loss": -82.59872438049317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.051379442214966, "step": 27000}
{"episode_reward": 880.3998617097328, "episode": 28.0, "batch_reward": 0.7743204650878907, "critic_loss": 0.649803953319788, "actor_loss": -82.81808609008789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.034583568572998, "step": 28000}
{"episode_reward": 865.2980957741236, "episode": 29.0, "batch_reward": 0.7792780792713165, "critic_loss": 0.6250340988039971, "actor_loss": -82.84263296508789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.17587661743164, "step": 29000}
{"episode_reward": 900.0517245663067, "episode": 30.0, "batch_reward": 0.7783274587392807, "critic_loss": 0.6708080456852913, "actor_loss": -82.85776786804199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.64760398864746, "step": 30000}
{"episode_reward": 801.8877701736889, "episode": 31.0, "batch_reward": 0.7801129644513131, "critic_loss": 0.7225970080494881, "actor_loss": -82.97862315368653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.99639582633972, "step": 31000}
{"episode_reward": 826.8064713336502, "episode": 32.0, "batch_reward": 0.7835068051218986, "critic_loss": 0.7478299593627453, "actor_loss": -83.02710911560058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.737015962600708, "step": 32000}
{"episode_reward": 814.2666656735727, "episode": 33.0, "batch_reward": 0.7829939727783203, "critic_loss": 0.7839090296328067, "actor_loss": -82.89480502319336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.340747594833374, "step": 33000}
{"episode_reward": 799.5931547484547, "episode": 34.0, "batch_reward": 0.7829135012030601, "critic_loss": 0.7707915243208409, "actor_loss": -83.07560955810547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.460391521453857, "step": 34000}
{"episode_reward": 781.7467975724219, "episode": 35.0, "batch_reward": 0.7846980558037758, "critic_loss": 0.8057598791122437, "actor_loss": -82.92617601013184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.86023235321045, "step": 35000}
{"episode_reward": 832.0659871515927, "episode": 36.0, "batch_reward": 0.7855606003403663, "critic_loss": 0.7586117580533027, "actor_loss": -83.13218473815918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.168801069259644, "step": 36000}
{"episode_reward": 867.6987681363986, "episode": 37.0, "batch_reward": 0.789899721622467, "critic_loss": 0.7939244176447392, "actor_loss": -83.09489585876464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.874167919158936, "step": 37000}
{"episode_reward": 884.0450209854791, "episode": 38.0, "batch_reward": 0.7904390155673027, "critic_loss": 0.8534545668363571, "actor_loss": -83.1000993347168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.9801025390625, "step": 38000}
{"episode_reward": 842.9719167558869, "episode": 39.0, "batch_reward": 0.7927407968044281, "critic_loss": 0.8153465729653835, "actor_loss": -83.19774674987794, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.07861852645874, "step": 39000}
{"episode_reward": 838.143758411308, "episode": 40.0, "batch_reward": 0.7935756526589394, "critic_loss": 0.8210185887515545, "actor_loss": -83.2083316192627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.19500207901001, "step": 40000}
{"episode_reward": 854.2565644115977, "episode": 41.0, "batch_reward": 0.795139403283596, "critic_loss": 0.8586363330483436, "actor_loss": -83.34807460021973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.519150733947754, "step": 41000}
{"episode_reward": 879.3636590790207, "episode": 42.0, "batch_reward": 0.7972347794771194, "critic_loss": 0.8137217003703118, "actor_loss": -83.29489138793946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.98400330543518, "step": 42000}
{"episode_reward": 894.901797963012, "episode": 43.0, "batch_reward": 0.7999270879030228, "critic_loss": 0.8345803378522396, "actor_loss": -83.4612186126709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.68662428855896, "step": 43000}
{"episode_reward": 847.8281539552287, "episode": 44.0, "batch_reward": 0.8005439524650574, "critic_loss": 0.8395763782858848, "actor_loss": -83.36639208984376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.562761783599854, "step": 44000}
{"episode_reward": 859.1367613805038, "episode": 45.0, "batch_reward": 0.8028578155040741, "critic_loss": 0.841821867018938, "actor_loss": -83.4218939666748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.57853627204895, "step": 45000}
{"episode_reward": 911.5746260072989, "episode": 46.0, "batch_reward": 0.8051467315554619, "critic_loss": 0.8394554849267006, "actor_loss": -83.62992503356934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.630274534225464, "step": 46000}
{"episode_reward": 873.1822731526382, "episode": 47.0, "batch_reward": 0.8070549702048302, "critic_loss": 0.8211815917789936, "actor_loss": -83.65966117858886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.670329093933105, "step": 47000}
{"episode_reward": 873.5211635787258, "episode": 48.0, "batch_reward": 0.8077955271601677, "critic_loss": 0.7511858251392841, "actor_loss": -83.68537342834473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.41886281967163, "step": 48000}
{"episode_reward": 888.5121484413824, "episode": 49.0, "batch_reward": 0.8090662624835968, "critic_loss": 0.7388117234110833, "actor_loss": -83.75403924560547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.567676067352295, "step": 49000}
{"episode_reward": 841.6418076837263, "episode": 50.0, "batch_reward": 0.8096619819998742, "critic_loss": 0.7264605129957199, "actor_loss": -83.71209194946289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.800805807113647, "step": 50000}
{"episode_reward": 861.2818810546595, "episode": 51.0, "batch_reward": 0.8111707810759544, "critic_loss": 0.6962533625662327, "actor_loss": -83.90209689331054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.81412100791931, "step": 51000}
{"episode_reward": 886.0422726919847, "episode": 52.0, "batch_reward": 0.8110133515596389, "critic_loss": 0.7170734605193139, "actor_loss": -83.85416584777832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.956636428833008, "step": 52000}
{"episode_reward": 807.3289334873097, "episode": 53.0, "batch_reward": 0.8149391195774078, "critic_loss": 0.7470518066287041, "actor_loss": -83.80922833251954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.80507516860962, "step": 53000}
{"episode_reward": 873.5605219572493, "episode": 54.0, "batch_reward": 0.8125673813223839, "critic_loss": 0.7024012962281704, "actor_loss": -84.12994874572755, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.453755855560303, "step": 54000}
{"episode_reward": 885.477671201782, "episode": 55.0, "batch_reward": 0.8136585530638695, "critic_loss": 0.6573351458013058, "actor_loss": -84.08474548339844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.89687943458557, "step": 55000}
{"episode_reward": 887.773646707096, "episode": 56.0, "batch_reward": 0.8153056837916374, "critic_loss": 0.7216031541526318, "actor_loss": -83.94875909423828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.69128441810608, "step": 56000}
{"episode_reward": 839.601020793725, "episode": 57.0, "batch_reward": 0.8153970001935958, "critic_loss": 0.6711125614345074, "actor_loss": -84.10997760009765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.57754111289978, "step": 57000}
{"episode_reward": 857.4428805175442, "episode": 58.0, "batch_reward": 0.818285516500473, "critic_loss": 0.6648038247227669, "actor_loss": -84.13101310729981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.0682430267334, "step": 58000}
{"episode_reward": 879.8578959963451, "episode": 59.0, "batch_reward": 0.8189889795184135, "critic_loss": 0.6880217323303223, "actor_loss": -84.21871063232422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.434198141098022, "step": 59000}
{"episode_reward": 878.6483097216283, "episode": 60.0, "batch_reward": 0.8189430968165398, "critic_loss": 0.6790365588366986, "actor_loss": -84.14759791564941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.90477418899536, "step": 60000}
{"episode_reward": 835.5309027389467, "episode": 61.0, "batch_reward": 0.819461940586567, "critic_loss": 0.6663433819413185, "actor_loss": -84.25747398376465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.5715069770813, "step": 61000}
{"episode_reward": 856.9844671611992, "episode": 62.0, "batch_reward": 0.820326101720333, "critic_loss": 0.6576143396198749, "actor_loss": -84.25003201293946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.080535650253296, "step": 62000}
{"episode_reward": 888.0234285143875, "episode": 63.0, "batch_reward": 0.8204417130351067, "critic_loss": 0.627840763181448, "actor_loss": -84.27937623596192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.584102392196655, "step": 63000}
{"episode_reward": 908.3467487097379, "episode": 64.0, "batch_reward": 0.8224019093513488, "critic_loss": 0.6063281951546668, "actor_loss": -84.4217112121582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.146555423736572, "step": 64000}
{"episode_reward": 869.8875558849477, "episode": 65.0, "batch_reward": 0.8222583646178245, "critic_loss": 0.697497022420168, "actor_loss": -84.3135255279541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.749995708465576, "step": 65000}
{"episode_reward": 747.6019542270712, "episode": 66.0, "batch_reward": 0.8216960440278054, "critic_loss": 0.682500259488821, "actor_loss": -84.33330067443848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.703371047973633, "step": 66000}
{"episode_reward": 802.5472035242971, "episode": 67.0, "batch_reward": 0.82233991843462, "critic_loss": 0.721820836186409, "actor_loss": -84.31304739379883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.83093523979187, "step": 67000}
{"episode_reward": 833.9598197040947, "episode": 68.0, "batch_reward": 0.8213026440143585, "critic_loss": 0.7415279187262058, "actor_loss": -84.41794496154785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.28342866897583, "step": 68000}
{"episode_reward": 834.2511773614208, "episode": 69.0, "batch_reward": 0.822364693403244, "critic_loss": 0.753399665504694, "actor_loss": -84.41095164489747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.626474857330322, "step": 69000}
{"episode_reward": 891.0562766124615, "episode": 70.0, "batch_reward": 0.823559686422348, "critic_loss": 0.7777961916327476, "actor_loss": -84.49972883605957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.398486852645874, "step": 70000}
{"episode_reward": 857.2622252919604, "episode": 71.0, "batch_reward": 0.8231346002221107, "critic_loss": 0.7503057704269886, "actor_loss": -84.30293505859375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.20772910118103, "step": 71000}
{"episode_reward": 877.1636297506934, "episode": 72.0, "batch_reward": 0.8252993554472924, "critic_loss": 0.7540728023946285, "actor_loss": -84.48323155212402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.50882601737976, "step": 72000}
{"episode_reward": 879.6921196372093, "episode": 73.0, "batch_reward": 0.8251612946391106, "critic_loss": 0.7593249824345112, "actor_loss": -84.4646612701416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.800114631652832, "step": 73000}
{"episode_reward": 900.7675003038337, "episode": 74.0, "batch_reward": 0.8256764823198318, "critic_loss": 0.8164357925951481, "actor_loss": -84.49885290527344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.55601406097412, "step": 74000}
{"episode_reward": 852.2546162656821, "episode": 75.0, "batch_reward": 0.8271614604592323, "critic_loss": 0.7504803793430328, "actor_loss": -84.59575595092774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.515565395355225, "step": 75000}
{"episode_reward": 878.7773646741364, "episode": 76.0, "batch_reward": 0.8271545869708061, "critic_loss": 0.8082521963715553, "actor_loss": -84.59617993164062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.679643154144287, "step": 76000}
{"episode_reward": 818.4336197590728, "episode": 77.0, "batch_reward": 0.8278400630950927, "critic_loss": 0.8213164812028408, "actor_loss": -84.60926808166504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.08171248435974, "step": 77000}
{"episode_reward": 889.0290490997603, "episode": 78.0, "batch_reward": 0.8279649088382721, "critic_loss": 0.7954049384593964, "actor_loss": -84.61067930603028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.40817141532898, "step": 78000}
{"episode_reward": 875.9691804794877, "episode": 79.0, "batch_reward": 0.8278803687095642, "critic_loss": 0.7871964189261198, "actor_loss": -84.62119584655761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.96046280860901, "step": 79000}
{"episode_reward": 828.5779186078479, "episode": 80.0, "batch_reward": 0.8297759286165237, "critic_loss": 0.773403129696846, "actor_loss": -84.72966186523438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.59077787399292, "step": 80000}
{"episode_reward": 909.3567448452337, "episode": 81.0, "batch_reward": 0.828985365986824, "critic_loss": 0.7974917134344578, "actor_loss": -84.616543258667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.176913022994995, "step": 81000}
{"episode_reward": 855.5339313746397, "episode": 82.0, "batch_reward": 0.8303533109426499, "critic_loss": 0.804583057820797, "actor_loss": -84.68845738220215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.28188514709473, "step": 82000}
{"episode_reward": 895.2680310221028, "episode": 83.0, "batch_reward": 0.8300920647382736, "critic_loss": 0.7989357625842094, "actor_loss": -84.80514764404298, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.9199435710907, "step": 83000}
{"episode_reward": 825.9732813514931, "episode": 84.0, "batch_reward": 0.830272650539875, "critic_loss": 0.8092260954082012, "actor_loss": -84.86742259216308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.352778434753418, "step": 84000}
{"episode_reward": 862.9459190146679, "episode": 85.0, "batch_reward": 0.8308887743353843, "critic_loss": 0.7778161778450012, "actor_loss": -84.69730389404297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.001711130142212, "step": 85000}
{"episode_reward": 901.8232116413957, "episode": 86.0, "batch_reward": 0.8316404421925545, "critic_loss": 0.7384352770149708, "actor_loss": -84.80390762329101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.03644633293152, "step": 86000}
{"episode_reward": 891.1373096094425, "episode": 87.0, "batch_reward": 0.8329818586111069, "critic_loss": 0.7504718833565712, "actor_loss": -84.88995910644532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.910157203674316, "step": 87000}
{"episode_reward": 884.465956023678, "episode": 88.0, "batch_reward": 0.8332073265314102, "critic_loss": 0.6985399690866471, "actor_loss": -84.90770872497559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.44054889678955, "step": 88000}
{"episode_reward": 846.4331955823355, "episode": 89.0, "batch_reward": 0.833004699409008, "critic_loss": 0.7242031923830509, "actor_loss": -84.92059097290038, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.92588758468628, "step": 89000}
{"episode_reward": 906.1272028851572, "episode": 90.0, "batch_reward": 0.8343155726790428, "critic_loss": 0.7273588598966598, "actor_loss": -85.00807012939453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.06082844734192, "step": 90000}
{"episode_reward": 911.4551174259989, "episode": 91.0, "batch_reward": 0.8349754862785339, "critic_loss": 0.6948978824913502, "actor_loss": -84.97921966552734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.04099154472351, "step": 91000}
{"episode_reward": 848.288026495038, "episode": 92.0, "batch_reward": 0.8364601281285285, "critic_loss": 0.6698710407614707, "actor_loss": -85.08323817443848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.371922969818115, "step": 92000}
{"episode_reward": 896.5978312192566, "episode": 93.0, "batch_reward": 0.8369936423301697, "critic_loss": 0.6954785041213035, "actor_loss": -85.1152703704834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.162278652191162, "step": 93000}
{"episode_reward": 909.1218823058751, "episode": 94.0, "batch_reward": 0.8368528280854225, "critic_loss": 0.7261029341518879, "actor_loss": -85.15674523925782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.873921632766724, "step": 94000}
{"episode_reward": 829.2182095650883, "episode": 95.0, "batch_reward": 0.8370989896655082, "critic_loss": 0.6957787017226219, "actor_loss": -85.13694380187988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.63668990135193, "step": 95000}
{"episode_reward": 884.2158445240237, "episode": 96.0, "batch_reward": 0.8358747599124908, "critic_loss": 0.709426786094904, "actor_loss": -85.10564416503907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.48603057861328, "step": 96000}
{"episode_reward": 883.0485614118663, "episode": 97.0, "batch_reward": 0.837178212761879, "critic_loss": 0.7330520624816418, "actor_loss": -85.12014753723145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.88441276550293, "step": 97000}
{"episode_reward": 860.4300737681367, "episode": 98.0, "batch_reward": 0.8375064668655395, "critic_loss": 0.7441565010249614, "actor_loss": -85.11019326782227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.914323329925537, "step": 98000}
{"episode_reward": 821.9136483539547, "episode": 99.0, "batch_reward": 0.8381660882234573, "critic_loss": 0.7329219235181809, "actor_loss": -85.13465061950684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.20634484291077, "step": 99000}
{"episode_reward": 890.999594793039, "episode": 100.0, "batch_reward": 0.8364287142753601, "critic_loss": 0.7790256665945053, "actor_loss": -85.09428791809081, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.528080463409424, "step": 100000}
{"episode_reward": 836.1284482157942, "episode": 101.0, "batch_reward": 0.838429888010025, "critic_loss": 0.7676299340724945, "actor_loss": -85.12849142456055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.69152212142944, "step": 101000}
{"episode_reward": 903.6751957679173, "episode": 102.0, "batch_reward": 0.8383975840806961, "critic_loss": 0.746947604984045, "actor_loss": -85.19432498168945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.398674726486206, "step": 102000}
{"episode_reward": 898.132346582721, "episode": 103.0, "batch_reward": 0.8394848148226738, "critic_loss": 0.790975942581892, "actor_loss": -85.10580267333984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.749019384384155, "step": 103000}
{"episode_reward": 883.9668897323793, "episode": 104.0, "batch_reward": 0.8375926942825317, "critic_loss": 0.762048453181982, "actor_loss": -85.1438070526123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.34219455718994, "step": 104000}
{"episode_reward": 888.2323750422299, "episode": 105.0, "batch_reward": 0.8396045278310775, "critic_loss": 0.7921783013045788, "actor_loss": -85.08608639526368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.849899291992188, "step": 105000}
{"episode_reward": 904.0849886477253, "episode": 106.0, "batch_reward": 0.840503144621849, "critic_loss": 0.8028788685500622, "actor_loss": -85.24868548583984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.9423885345459, "step": 106000}
{"episode_reward": 878.7039505678692, "episode": 107.0, "batch_reward": 0.8397069885730744, "critic_loss": 0.793414287418127, "actor_loss": -85.19981135559082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.839649438858032, "step": 107000}
{"episode_reward": 854.874371865073, "episode": 108.0, "batch_reward": 0.8409562200903893, "critic_loss": 0.7864840362071991, "actor_loss": -85.09616844177246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.09171175956726, "step": 108000}
{"episode_reward": 881.6517348274032, "episode": 109.0, "batch_reward": 0.8407017945051193, "critic_loss": 0.8394471308887005, "actor_loss": -85.24519149780274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.27641010284424, "step": 109000}
{"episode_reward": 902.12653783394, "episode": 110.0, "batch_reward": 0.841792646586895, "critic_loss": 0.8138972860872745, "actor_loss": -85.20455795288086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.878159523010254, "step": 110000}
{"episode_reward": 883.9986901662667, "episode": 111.0, "batch_reward": 0.8432128420472145, "critic_loss": 0.7973895024955273, "actor_loss": -85.20963000488281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 66.76876616477966, "step": 111000}
{"episode_reward": 899.2764102748034, "episode": 112.0, "batch_reward": 0.8425354344844818, "critic_loss": 0.796222743421793, "actor_loss": -85.32866668701172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.31472110748291, "step": 112000}
{"episode_reward": 898.598943896369, "episode": 113.0, "batch_reward": 0.8445096445679665, "critic_loss": 0.7449599795490504, "actor_loss": -85.3396893157959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.3249249458313, "step": 113000}
{"episode_reward": 898.4811616380522, "episode": 114.0, "batch_reward": 0.8431206644177437, "critic_loss": 0.7328478587269783, "actor_loss": -85.34336755371093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.087477922439575, "step": 114000}
{"episode_reward": 902.1318552866721, "episode": 115.0, "batch_reward": 0.8446839346289635, "critic_loss": 0.776153522670269, "actor_loss": -85.31791024780273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.0828640460968, "step": 115000}
{"episode_reward": 862.1051215433882, "episode": 116.0, "batch_reward": 0.8449430090785026, "critic_loss": 0.7526420887112617, "actor_loss": -85.39782437133789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.19145941734314, "step": 116000}
{"episode_reward": 888.4834351776988, "episode": 117.0, "batch_reward": 0.8441893814206123, "critic_loss": 0.7299071275889873, "actor_loss": -85.27521170043946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.855385780334473, "step": 117000}
{"episode_reward": 890.571258815384, "episode": 118.0, "batch_reward": 0.845783746778965, "critic_loss": 0.6865217528641224, "actor_loss": -85.37314082336425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.043095111846924, "step": 118000}
{"episode_reward": 897.7228041573815, "episode": 119.0, "batch_reward": 0.845517876803875, "critic_loss": 0.6910846305787564, "actor_loss": -85.4032521057129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.62936449050903, "step": 119000}
{"episode_reward": 842.9899933276167, "episode": 120.0, "batch_reward": 0.8460603213310242, "critic_loss": 0.7183275856673718, "actor_loss": -85.37158485412597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.03116488456726, "step": 120000}
{"episode_reward": 903.7770261100676, "episode": 121.0, "batch_reward": 0.8467244448065758, "critic_loss": 0.6985496486723423, "actor_loss": -85.41003858947754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 66.08677697181702, "step": 121000}
{"episode_reward": 887.3669462648211, "episode": 122.0, "batch_reward": 0.8459617784023284, "critic_loss": 0.6744255885183811, "actor_loss": -85.44425759887696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.4331431388855, "step": 122000}
{"episode_reward": 884.6103426215717, "episode": 123.0, "batch_reward": 0.846383801817894, "critic_loss": 0.686811636030674, "actor_loss": -85.52324609375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.726578950881958, "step": 123000}
{"episode_reward": 901.9937466406479, "episode": 124.0, "batch_reward": 0.8481291480064392, "critic_loss": 0.6605581949502229, "actor_loss": -85.56930529785156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.49264407157898, "step": 124000}
{"episode_reward": 904.2937346966346, "episode": 125.0, "batch_reward": 0.8490635362267495, "critic_loss": 0.6631777292340993, "actor_loss": -85.57953405761718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.78669571876526, "step": 125000}
{"episode_reward": 903.3141529356632, "episode": 126.0, "batch_reward": 0.8484075243473053, "critic_loss": 0.6860087850093841, "actor_loss": -85.53265812683105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.142924308776855, "step": 126000}
{"episode_reward": 897.0634146522915, "episode": 127.0, "batch_reward": 0.8490200460553169, "critic_loss": 0.6555853402763605, "actor_loss": -85.52137454223633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.434067249298096, "step": 127000}
{"episode_reward": 880.3619883884119, "episode": 128.0, "batch_reward": 0.8481664060950279, "critic_loss": 0.6450838560461998, "actor_loss": -85.60812896728515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.40916872024536, "step": 128000}
{"episode_reward": 898.262903021513, "episode": 129.0, "batch_reward": 0.8485027588605881, "critic_loss": 0.6679445912092924, "actor_loss": -85.56331341552735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.7197744846344, "step": 129000}
{"episode_reward": 909.120680349918, "episode": 130.0, "batch_reward": 0.8514584745168686, "critic_loss": 0.6919447869062424, "actor_loss": -85.64396473693847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.01608467102051, "step": 130000}
{"episode_reward": 846.6294609791627, "episode": 131.0, "batch_reward": 0.8505118660330773, "critic_loss": 0.655228953897953, "actor_loss": -85.63285488891601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 66.50409960746765, "step": 131000}
{"episode_reward": 883.621922165341, "episode": 132.0, "batch_reward": 0.8489369876384735, "critic_loss": 0.6777048055231571, "actor_loss": -85.64371922302246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.165666341781616, "step": 132000}
{"episode_reward": 843.2472751162696, "episode": 133.0, "batch_reward": 0.8497373231053352, "critic_loss": 0.6150662749707699, "actor_loss": -85.6627639465332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.543567895889282, "step": 133000}
{"episode_reward": 900.9042294416321, "episode": 134.0, "batch_reward": 0.850338088274002, "critic_loss": 0.620005105048418, "actor_loss": -85.6306738128662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.110981225967407, "step": 134000}
{"episode_reward": 806.7240547759784, "episode": 135.0, "batch_reward": 0.8494565605521202, "critic_loss": 0.6372340031713247, "actor_loss": -85.63477911376953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.299172401428223, "step": 135000}
{"episode_reward": 813.1475082954912, "episode": 136.0, "batch_reward": 0.850614863216877, "critic_loss": 0.6511655190438033, "actor_loss": -85.5901471710205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.012845277786255, "step": 136000}
{"episode_reward": 900.2930925549978, "episode": 137.0, "batch_reward": 0.8486636183857917, "critic_loss": 0.6524892861396074, "actor_loss": -85.65888186645508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.484717845916748, "step": 137000}
{"episode_reward": 899.92678162192, "episode": 138.0, "batch_reward": 0.8520832785964012, "critic_loss": 0.6393509426116943, "actor_loss": -85.7301148071289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.41363000869751, "step": 138000}
{"episode_reward": 904.473702931983, "episode": 139.0, "batch_reward": 0.8508461340665817, "critic_loss": 0.6292958237230778, "actor_loss": -85.66049768066407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.437005043029785, "step": 139000}
{"episode_reward": 887.2363792573217, "episode": 140.0, "batch_reward": 0.8517247526049614, "critic_loss": 0.6436858422011137, "actor_loss": -85.69376995849609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.02170705795288, "step": 140000}
{"episode_reward": 894.9453083922779, "episode": 141.0, "batch_reward": 0.8502649797201156, "critic_loss": 0.6422760525494814, "actor_loss": -85.59778889465332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 66.21423435211182, "step": 141000}
{"episode_reward": 887.5119365397921, "episode": 142.0, "batch_reward": 0.8515100550055504, "critic_loss": 0.6777860443890095, "actor_loss": -85.61002503967285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.07699680328369, "step": 142000}
{"episode_reward": 880.7637839657333, "episode": 143.0, "batch_reward": 0.8517709290981292, "critic_loss": 0.6612917678654194, "actor_loss": -85.65318090820313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.440139532089233, "step": 143000}
{"episode_reward": 905.412673618461, "episode": 144.0, "batch_reward": 0.852862052321434, "critic_loss": 0.6650223005712033, "actor_loss": -85.72935829162597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.677619695663452, "step": 144000}
{"episode_reward": 844.6302863354771, "episode": 145.0, "batch_reward": 0.8532530898451806, "critic_loss": 0.6812255508005619, "actor_loss": -85.72986880493164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.638097524642944, "step": 145000}
{"episode_reward": 878.0037937036242, "episode": 146.0, "batch_reward": 0.8525739147663116, "critic_loss": 0.7072686040401459, "actor_loss": -85.75061482238769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.401926040649414, "step": 146000}
{"episode_reward": 901.1009754403572, "episode": 147.0, "batch_reward": 0.8526540011763573, "critic_loss": 0.6787354847490787, "actor_loss": -85.72421939086914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.11279559135437, "step": 147000}
{"episode_reward": 860.5441460997737, "episode": 148.0, "batch_reward": 0.8531597498655319, "critic_loss": 0.7554048076272011, "actor_loss": -85.73394100952149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.399343967437744, "step": 148000}
{"episode_reward": 821.4435279560574, "episode": 149.0, "batch_reward": 0.8520131995677948, "critic_loss": 0.6806596724539995, "actor_loss": -85.69743266296386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.974891901016235, "step": 149000}
{"episode_reward": 867.2490870543223, "episode": 150.0, "batch_reward": 0.8523826576471328, "critic_loss": 0.7264422373473645, "actor_loss": -85.62279705810546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
