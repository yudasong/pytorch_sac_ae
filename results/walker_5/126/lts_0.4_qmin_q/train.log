{"episode_reward": 0.0, "episode": 1.0, "duration": 22.264236450195312, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.9121205806732178, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.2905651432210185, "critic_loss": 0.7117447069324069, "actor_loss": -69.68102105649389, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 62.318652868270874, "step": 3000}
{"episode_reward": 525.6004303427327, "episode": 4.0, "batch_reward": 0.39703045126795766, "critic_loss": 0.9007315661013127, "actor_loss": -74.87501039123535, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.782719612121582, "step": 4000}
{"episode_reward": 644.8931218702861, "episode": 5.0, "batch_reward": 0.453023251503706, "critic_loss": 0.8672650491595268, "actor_loss": -76.31823649597168, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.002482652664185, "step": 5000}
{"episode_reward": 599.1733447525141, "episode": 6.0, "batch_reward": 0.4749463593661785, "critic_loss": 0.8625902714431286, "actor_loss": -76.94596139526367, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.52577829360962, "step": 6000}
{"episode_reward": 573.5734442153233, "episode": 7.0, "batch_reward": 0.48067494335770605, "critic_loss": 0.7855177054405212, "actor_loss": -76.792880859375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.717185735702515, "step": 7000}
{"episode_reward": 619.909144752773, "episode": 8.0, "batch_reward": 0.5136622722744941, "critic_loss": 0.68272777441144, "actor_loss": -77.19712321472169, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.3398175239563, "step": 8000}
{"episode_reward": 612.941240458476, "episode": 9.0, "batch_reward": 0.532147457331419, "critic_loss": 0.6411027986109257, "actor_loss": -77.30086888122558, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.487247943878174, "step": 9000}
{"episode_reward": 833.1601283734025, "episode": 10.0, "batch_reward": 0.5713345295488834, "critic_loss": 0.6154029784202576, "actor_loss": -77.90655432128906, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.642876148223877, "step": 10000}
{"episode_reward": 910.4696474713653, "episode": 11.0, "batch_reward": 0.6046391066908836, "critic_loss": 0.6382100237309932, "actor_loss": -78.55052153015137, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.027423620224, "step": 11000}
{"episode_reward": 814.1844704533621, "episode": 12.0, "batch_reward": 0.6162805534005165, "critic_loss": 0.7546555526256561, "actor_loss": -78.65983848571777, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.46142840385437, "step": 12000}
{"episode_reward": 842.8791435618526, "episode": 13.0, "batch_reward": 0.635122652232647, "critic_loss": 0.7836723437011242, "actor_loss": -79.00964814758301, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.17989158630371, "step": 13000}
{"episode_reward": 885.1956358663434, "episode": 14.0, "batch_reward": 0.6568266677260399, "critic_loss": 0.7843718653619289, "actor_loss": -79.60656419372559, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.842485904693604, "step": 14000}
{"episode_reward": 882.9575963133718, "episode": 15.0, "batch_reward": 0.6735184745788574, "critic_loss": 0.8116379337310791, "actor_loss": -80.13474026489259, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.783047676086426, "step": 15000}
{"episode_reward": 938.6856590415788, "episode": 16.0, "batch_reward": 0.689916699886322, "critic_loss": 0.7389664253890514, "actor_loss": -80.65575059509277, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.4329617023468, "step": 16000}
{"episode_reward": 945.592104577948, "episode": 17.0, "batch_reward": 0.7044409675002098, "critic_loss": 0.682938018232584, "actor_loss": -81.1185848236084, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.862003803253174, "step": 17000}
{"episode_reward": 903.2559462538566, "episode": 18.0, "batch_reward": 0.7139124975204468, "critic_loss": 0.6786487421393395, "actor_loss": -81.33459228515625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.099045515060425, "step": 18000}
{"episode_reward": 868.0033105321016, "episode": 19.0, "batch_reward": 0.7220361847281456, "critic_loss": 0.6061028940081596, "actor_loss": -81.55635173034668, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.47516393661499, "step": 19000}
{"episode_reward": 877.5366242594932, "episode": 20.0, "batch_reward": 0.730842084646225, "critic_loss": 0.585949356675148, "actor_loss": -81.78727711486816, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.506937265396118, "step": 20000}
{"episode_reward": 909.2179952033218, "episode": 21.0, "batch_reward": 0.7276355749368668, "critic_loss": 0.6049841510355473, "actor_loss": -81.77932809448242, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.609272718429565, "step": 21000}
{"episode_reward": 431.05472519385563, "episode": 22.0, "batch_reward": 0.724427591919899, "critic_loss": 0.5878050004839898, "actor_loss": -81.9723500213623, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.476701498031616, "step": 22000}
{"episode_reward": 856.9975379124537, "episode": 23.0, "batch_reward": 0.7279231911897659, "critic_loss": 0.5603897449076176, "actor_loss": -81.9549482421875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.911212682724, "step": 23000}
{"episode_reward": 865.0651015970549, "episode": 24.0, "batch_reward": 0.7368129234910011, "critic_loss": 0.540327347099781, "actor_loss": -82.17210148620606, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.120017528533936, "step": 24000}
{"episode_reward": 910.803660047962, "episode": 25.0, "batch_reward": 0.7444573251008988, "critic_loss": 0.5843978397250176, "actor_loss": -82.31749526977539, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.445273876190186, "step": 25000}
{"episode_reward": 859.413930390448, "episode": 26.0, "batch_reward": 0.7485299932956696, "critic_loss": 0.6089355811476708, "actor_loss": -82.34877360534668, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.604910373687744, "step": 26000}
{"episode_reward": 882.4688798080454, "episode": 27.0, "batch_reward": 0.7536600441336632, "critic_loss": 0.5867677761018276, "actor_loss": -82.5496789855957, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.908949851989746, "step": 27000}
{"episode_reward": 890.104670034751, "episode": 28.0, "batch_reward": 0.7550673395991325, "critic_loss": 0.6383251639604568, "actor_loss": -82.55205242919922, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.33370327949524, "step": 28000}
{"episode_reward": 797.3210753172136, "episode": 29.0, "batch_reward": 0.7627864606380462, "critic_loss": 0.6206765244603157, "actor_loss": -82.76641891479493, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.480698585510254, "step": 29000}
{"episode_reward": 978.3703371527469, "episode": 30.0, "batch_reward": 0.7666200855374337, "critic_loss": 0.6116914752423763, "actor_loss": -82.90928393554688, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.309834957122803, "step": 30000}
{"episode_reward": 885.7415369832045, "episode": 31.0, "batch_reward": 0.7695815436840058, "critic_loss": 0.5949627114832401, "actor_loss": -82.97491162109375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.98342680931091, "step": 31000}
{"episode_reward": 902.110612852742, "episode": 32.0, "batch_reward": 0.7762723638415336, "critic_loss": 0.5870802695155144, "actor_loss": -83.19747247314453, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.4907329082489, "step": 32000}
{"episode_reward": 929.4294284326635, "episode": 33.0, "batch_reward": 0.7798031101822853, "critic_loss": 0.5918790652155876, "actor_loss": -83.33292744445801, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.996983289718628, "step": 33000}
{"episode_reward": 916.1080315609506, "episode": 34.0, "batch_reward": 0.7845489302277565, "critic_loss": 0.5878716731369495, "actor_loss": -83.49824209594726, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.41500234603882, "step": 34000}
{"episode_reward": 894.4972477190379, "episode": 35.0, "batch_reward": 0.788099577665329, "critic_loss": 0.5510252003371715, "actor_loss": -83.62253938293458, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.49251675605774, "step": 35000}
{"episode_reward": 944.5102942835146, "episode": 36.0, "batch_reward": 0.7932956601977348, "critic_loss": 0.555224620372057, "actor_loss": -83.7763967590332, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.46867561340332, "step": 36000}
{"episode_reward": 890.5986211216755, "episode": 37.0, "batch_reward": 0.7962088170647621, "critic_loss": 0.57419232827425, "actor_loss": -83.85617166137695, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.66869068145752, "step": 37000}
{"episode_reward": 947.2303156086497, "episode": 38.0, "batch_reward": 0.8005924362540245, "critic_loss": 0.5514135093092919, "actor_loss": -84.09639215087891, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.73940134048462, "step": 38000}
{"episode_reward": 936.1925040059991, "episode": 39.0, "batch_reward": 0.8025416080951691, "critic_loss": 0.5762088663578033, "actor_loss": -84.1659591217041, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.471158504486084, "step": 39000}
{"episode_reward": 852.5363626040361, "episode": 40.0, "batch_reward": 0.8037873676419258, "critic_loss": 0.5905908252298832, "actor_loss": -84.1740791015625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.506701469421387, "step": 40000}
{"episode_reward": 906.7180711644537, "episode": 41.0, "batch_reward": 0.8016448695659637, "critic_loss": 0.5792666460573673, "actor_loss": -84.22725770568847, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.83756160736084, "step": 41000}
{"episode_reward": 645.4440805866299, "episode": 42.0, "batch_reward": 0.8002497298717499, "critic_loss": 0.5575889995098114, "actor_loss": -84.35010734558105, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.50570273399353, "step": 42000}
{"episode_reward": 937.4033613347559, "episode": 43.0, "batch_reward": 0.8062793231010437, "critic_loss": 0.545802387446165, "actor_loss": -84.51471215820312, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.788243770599365, "step": 43000}
{"episode_reward": 923.3679310414358, "episode": 44.0, "batch_reward": 0.8103844852447509, "critic_loss": 0.5367369190454483, "actor_loss": -84.64784317016601, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.904298067092896, "step": 44000}
{"episode_reward": 951.881873298771, "episode": 45.0, "batch_reward": 0.8106516584157943, "critic_loss": 0.5104778687953949, "actor_loss": -84.76445069885254, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.31636953353882, "step": 45000}
{"episode_reward": 932.6761799155499, "episode": 46.0, "batch_reward": 0.8172500511407852, "critic_loss": 0.5107843940556049, "actor_loss": -84.89777674865722, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.443220376968384, "step": 46000}
{"episode_reward": 944.3758695472536, "episode": 47.0, "batch_reward": 0.8187571074962616, "critic_loss": 0.49024571596086025, "actor_loss": -84.87135162353516, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.927536725997925, "step": 47000}
{"episode_reward": 942.9458603060494, "episode": 48.0, "batch_reward": 0.8207204542160034, "critic_loss": 0.47773537577688696, "actor_loss": -85.10695249938965, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.832865238189697, "step": 48000}
{"episode_reward": 945.6348166121021, "episode": 49.0, "batch_reward": 0.8232036219239235, "critic_loss": 0.4862920791655779, "actor_loss": -85.21610359191895, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.500227451324463, "step": 49000}
{"episode_reward": 907.6458852499567, "episode": 50.0, "batch_reward": 0.8246220263838768, "critic_loss": 0.47180861088633536, "actor_loss": -85.18297337341309, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.467705965042114, "step": 50000}
{"episode_reward": 911.9434578794243, "episode": 51.0, "batch_reward": 0.827428953051567, "critic_loss": 0.4515936973541975, "actor_loss": -85.55072489929199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.05956959724426, "step": 51000}
{"episode_reward": 974.0852153005354, "episode": 52.0, "batch_reward": 0.8278666362762451, "critic_loss": 0.48256381806731224, "actor_loss": -85.27925595092773, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.90294623374939, "step": 52000}
{"episode_reward": 898.7409176097126, "episode": 53.0, "batch_reward": 0.8303626381158828, "critic_loss": 0.4802163697630167, "actor_loss": -85.61254049682617, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.46231961250305, "step": 53000}
{"episode_reward": 948.4305575292309, "episode": 54.0, "batch_reward": 0.8326504466533661, "critic_loss": 0.4674074490219355, "actor_loss": -85.57397842407227, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.80939531326294, "step": 54000}
{"episode_reward": 936.1692647422802, "episode": 55.0, "batch_reward": 0.8336569539904595, "critic_loss": 0.47226733465492726, "actor_loss": -85.63954608154297, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.13515329360962, "step": 55000}
{"episode_reward": 975.3021081020627, "episode": 56.0, "batch_reward": 0.8389169659614563, "critic_loss": 0.4507387191951275, "actor_loss": -85.95856750488281, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.503896951675415, "step": 56000}
{"episode_reward": 978.3558557740116, "episode": 57.0, "batch_reward": 0.8390866791009903, "critic_loss": 0.4447227109670639, "actor_loss": -85.9035245361328, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.87811851501465, "step": 57000}
{"episode_reward": 951.2643051798856, "episode": 58.0, "batch_reward": 0.8414740200638771, "critic_loss": 0.433004598736763, "actor_loss": -86.14934089660645, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.865861177444458, "step": 58000}
{"episode_reward": 839.0117354266191, "episode": 59.0, "batch_reward": 0.8426791899800301, "critic_loss": 0.43406606970727446, "actor_loss": -86.03266261291503, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.01867914199829, "step": 59000}
{"episode_reward": 974.5161123607293, "episode": 60.0, "batch_reward": 0.8414626832008362, "critic_loss": 0.42569569845497607, "actor_loss": -85.92534780883788, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.496188640594482, "step": 60000}
{"episode_reward": 679.2355274882559, "episode": 61.0, "batch_reward": 0.8338257111310959, "critic_loss": 0.4353797341138124, "actor_loss": -85.7860553894043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.51576852798462, "step": 61000}
{"episode_reward": 122.22866783237679, "episode": 62.0, "batch_reward": 0.8289064261317253, "critic_loss": 0.428060894921422, "actor_loss": -85.85438359069825, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.49732732772827, "step": 62000}
{"episode_reward": 981.1061670062035, "episode": 63.0, "batch_reward": 0.831363075017929, "critic_loss": 0.4203346834182739, "actor_loss": -85.97008978271484, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.745877981185913, "step": 63000}
{"episode_reward": 954.7298257819492, "episode": 64.0, "batch_reward": 0.8345694587230682, "critic_loss": 0.43930204044282434, "actor_loss": -85.92034359741211, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.95651602745056, "step": 64000}
{"episode_reward": 898.5680379056356, "episode": 65.0, "batch_reward": 0.8346854110956192, "critic_loss": 0.44237223932147024, "actor_loss": -86.0047582244873, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.876899480819702, "step": 65000}
{"episode_reward": 942.7355036982386, "episode": 66.0, "batch_reward": 0.8363262459039688, "critic_loss": 0.43648319397866725, "actor_loss": -86.19848370361328, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.479231595993042, "step": 66000}
{"episode_reward": 968.2732166084227, "episode": 67.0, "batch_reward": 0.8405284948945045, "critic_loss": 0.44648873053491117, "actor_loss": -86.27626271057129, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.051755666732788, "step": 67000}
{"episode_reward": 898.813751063956, "episode": 68.0, "batch_reward": 0.8388095086812973, "critic_loss": 0.41622504375874997, "actor_loss": -86.18534255981446, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.823286294937134, "step": 68000}
{"episode_reward": 943.0106845727396, "episode": 69.0, "batch_reward": 0.8402113878726959, "critic_loss": 0.41694591692090033, "actor_loss": -86.34658221435546, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.09143614768982, "step": 69000}
{"episode_reward": 971.3981736162679, "episode": 70.0, "batch_reward": 0.8442072602510452, "critic_loss": 0.4186716096997261, "actor_loss": -86.34818534851074, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.448973655700684, "step": 70000}
{"episode_reward": 895.0213126997468, "episode": 71.0, "batch_reward": 0.8436366246342659, "critic_loss": 0.404842774271965, "actor_loss": -86.44566244506836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.99917650222778, "step": 71000}
{"episode_reward": 966.3945099055411, "episode": 72.0, "batch_reward": 0.8452742646932602, "critic_loss": 0.4227533870190382, "actor_loss": -86.55259448242188, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.453518390655518, "step": 72000}
{"episode_reward": 932.6706944688391, "episode": 73.0, "batch_reward": 0.8460367460250855, "critic_loss": 0.39893177777528765, "actor_loss": -86.60269401550293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.74208426475525, "step": 73000}
{"episode_reward": 960.4600036793136, "episode": 74.0, "batch_reward": 0.8483381361961365, "critic_loss": 0.3990603631734848, "actor_loss": -86.52041156005859, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.903444528579712, "step": 74000}
{"episode_reward": 931.0174374647461, "episode": 75.0, "batch_reward": 0.8500680344104767, "critic_loss": 0.4057295804321766, "actor_loss": -86.60084512329101, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.770320177078247, "step": 75000}
{"episode_reward": 920.3762445683196, "episode": 76.0, "batch_reward": 0.8508601619005203, "critic_loss": 0.4025109167993069, "actor_loss": -86.54858306884766, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.480403184890747, "step": 76000}
{"episode_reward": 947.3083014326807, "episode": 77.0, "batch_reward": 0.8525261158347129, "critic_loss": 0.3811238577365875, "actor_loss": -86.86489892578125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.528412342071533, "step": 77000}
{"episode_reward": 964.5070900852611, "episode": 78.0, "batch_reward": 0.8519654709100724, "critic_loss": 0.3704028458595276, "actor_loss": -86.84183836364745, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.81784200668335, "step": 78000}
{"episode_reward": 943.005360301855, "episode": 79.0, "batch_reward": 0.852332432448864, "critic_loss": 0.38094873790442946, "actor_loss": -86.95988417053222, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.533267736434937, "step": 79000}
{"episode_reward": 941.8711140701283, "episode": 80.0, "batch_reward": 0.8566758484244347, "critic_loss": 0.3638037991821766, "actor_loss": -86.98879936218262, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.499138355255127, "step": 80000}
{"episode_reward": 951.9968313817341, "episode": 81.0, "batch_reward": 0.8539724861383438, "critic_loss": 0.37476597806811335, "actor_loss": -86.98391821289063, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.78946280479431, "step": 81000}
{"episode_reward": 948.1151174958765, "episode": 82.0, "batch_reward": 0.8569670559763909, "critic_loss": 0.34041898675262927, "actor_loss": -87.12476106262207, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.71807861328125, "step": 82000}
{"episode_reward": 967.8641767933956, "episode": 83.0, "batch_reward": 0.8591038421392441, "critic_loss": 0.3625704902112484, "actor_loss": -87.05015783691407, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.4930157661438, "step": 83000}
{"episode_reward": 935.6047300048863, "episode": 84.0, "batch_reward": 0.8594671123623848, "critic_loss": 0.3588127479851246, "actor_loss": -87.07966990661622, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.688771963119507, "step": 84000}
{"episode_reward": 904.1837033390357, "episode": 85.0, "batch_reward": 0.8589868928790092, "critic_loss": 0.3574308903366327, "actor_loss": -87.30380476379395, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.55351185798645, "step": 85000}
{"episode_reward": 953.2135323899164, "episode": 86.0, "batch_reward": 0.8609998270273208, "critic_loss": 0.3627243652045727, "actor_loss": -87.26055616760254, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.496551036834717, "step": 86000}
{"episode_reward": 930.1048207097522, "episode": 87.0, "batch_reward": 0.8623326815962792, "critic_loss": 0.34836597749590875, "actor_loss": -87.29013006591796, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.36323833465576, "step": 87000}
{"episode_reward": 952.7786694754559, "episode": 88.0, "batch_reward": 0.8615930431485176, "critic_loss": 0.3732917664051056, "actor_loss": -87.25846356201171, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.223445177078247, "step": 88000}
{"episode_reward": 824.3004999426554, "episode": 89.0, "batch_reward": 0.8629842889904976, "critic_loss": 0.358798015281558, "actor_loss": -87.47578598022461, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.821573495864868, "step": 89000}
{"episode_reward": 973.312865327848, "episode": 90.0, "batch_reward": 0.8638431166410446, "critic_loss": 0.3626529486179352, "actor_loss": -87.49769819641114, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.55785083770752, "step": 90000}
{"episode_reward": 978.1756346868012, "episode": 91.0, "batch_reward": 0.8640438907146454, "critic_loss": 0.35495744667947293, "actor_loss": -87.51291366577148, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.94829320907593, "step": 91000}
{"episode_reward": 914.1524411333514, "episode": 92.0, "batch_reward": 0.866010152220726, "critic_loss": 0.3553686655759811, "actor_loss": -87.58760215759277, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.470820903778076, "step": 92000}
{"episode_reward": 970.0357097084064, "episode": 93.0, "batch_reward": 0.868767509162426, "critic_loss": 0.35435760905593633, "actor_loss": -87.68264179992676, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.452585220336914, "step": 93000}
{"episode_reward": 980.2174677942885, "episode": 94.0, "batch_reward": 0.8691498792767525, "critic_loss": 0.35739266602694986, "actor_loss": -87.65283967590332, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.587252378463745, "step": 94000}
{"episode_reward": 952.3306041632513, "episode": 95.0, "batch_reward": 0.868991235256195, "critic_loss": 0.3613420900553465, "actor_loss": -87.77044338989258, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.495343446731567, "step": 95000}
{"episode_reward": 943.8268991485218, "episode": 96.0, "batch_reward": 0.8683267771601677, "critic_loss": 0.36179218043386935, "actor_loss": -87.52727709960938, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.111916065216064, "step": 96000}
{"episode_reward": 944.1444179598421, "episode": 97.0, "batch_reward": 0.8700930736660958, "critic_loss": 0.37142783659696577, "actor_loss": -87.82574147033691, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.8551344871521, "step": 97000}
{"episode_reward": 933.7964487376494, "episode": 98.0, "batch_reward": 0.8713356526494026, "critic_loss": 0.3849407579600811, "actor_loss": -87.93807795715333, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.86049461364746, "step": 98000}
{"episode_reward": 918.57800290821, "episode": 99.0, "batch_reward": 0.8714284186959267, "critic_loss": 0.4074193398579955, "actor_loss": -87.65670805358887, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.52723526954651, "step": 99000}
{"episode_reward": 906.0901754515864, "episode": 100.0, "batch_reward": 0.8713379950523377, "critic_loss": 0.4392220219224691, "actor_loss": -87.7973663482666, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.44720768928528, "step": 100000}
{"episode_reward": 960.6950736616863, "episode": 101.0, "batch_reward": 0.8732084842324257, "critic_loss": 0.39249622009694574, "actor_loss": -87.84574186706543, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.02238082885742, "step": 101000}
{"episode_reward": 962.9349270373077, "episode": 102.0, "batch_reward": 0.8746559368371963, "critic_loss": 0.36828762279450894, "actor_loss": -87.97656335449219, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.49192237854004, "step": 102000}
{"episode_reward": 972.6161982618955, "episode": 103.0, "batch_reward": 0.8752622536420822, "critic_loss": 0.36028361961245536, "actor_loss": -88.03905786132813, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.03468346595764, "step": 103000}
{"episode_reward": 941.20809004373, "episode": 104.0, "batch_reward": 0.8748914338350297, "critic_loss": 0.35995776492357257, "actor_loss": -87.92477027893067, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.388361930847168, "step": 104000}
{"episode_reward": 960.541222926206, "episode": 105.0, "batch_reward": 0.8761832122206688, "critic_loss": 0.35744386281073093, "actor_loss": -87.93343020629882, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.49394965171814, "step": 105000}
{"episode_reward": 959.7581354913876, "episode": 106.0, "batch_reward": 0.8774605419635773, "critic_loss": 0.37112889827787876, "actor_loss": -87.96776043701172, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.17956018447876, "step": 106000}
{"episode_reward": 937.9113995267599, "episode": 107.0, "batch_reward": 0.8767361754179, "critic_loss": 0.3453312820792198, "actor_loss": -87.8981170349121, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.85558843612671, "step": 107000}
{"episode_reward": 899.4711931889688, "episode": 108.0, "batch_reward": 0.8780182039737702, "critic_loss": 0.34675718438625336, "actor_loss": -88.27863488769532, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.823232412338257, "step": 108000}
{"episode_reward": 962.3315994157612, "episode": 109.0, "batch_reward": 0.8780340912938118, "critic_loss": 0.35733389465510845, "actor_loss": -87.8964239807129, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.520780086517334, "step": 109000}
{"episode_reward": 932.2875962586082, "episode": 110.0, "batch_reward": 0.8797691648006439, "critic_loss": 0.3360809280127287, "actor_loss": -87.97755477905274, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.896231651306152, "step": 110000}
{"episode_reward": 946.9039268323047, "episode": 111.0, "batch_reward": 0.8785965412259101, "critic_loss": 0.3474401708170772, "actor_loss": -88.37205307006836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.75263833999634, "step": 111000}
{"episode_reward": 930.1573997525419, "episode": 112.0, "batch_reward": 0.8796863523721695, "critic_loss": 0.35690103951096536, "actor_loss": -87.92315754699707, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.7727472782135, "step": 112000}
{"episode_reward": 948.2327577517899, "episode": 113.0, "batch_reward": 0.8807924649119377, "critic_loss": 0.3445489767566323, "actor_loss": -88.21077322387696, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.737589836120605, "step": 113000}
{"episode_reward": 972.0441969050686, "episode": 114.0, "batch_reward": 0.8809735444784165, "critic_loss": 0.3614622362852097, "actor_loss": -88.16020417785644, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.66147780418396, "step": 114000}
{"episode_reward": 978.6626699709846, "episode": 115.0, "batch_reward": 0.8826858409047127, "critic_loss": 0.36288775722682476, "actor_loss": -88.31244250488281, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.448893070220947, "step": 115000}
{"episode_reward": 946.2005739616493, "episode": 116.0, "batch_reward": 0.882888930439949, "critic_loss": 0.35651818990707396, "actor_loss": -88.43099603271484, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.60634970664978, "step": 116000}
{"episode_reward": 881.1433658021147, "episode": 117.0, "batch_reward": 0.8830037442445755, "critic_loss": 0.34692143201828, "actor_loss": -88.65092129516601, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.697224378585815, "step": 117000}
{"episode_reward": 942.237069927839, "episode": 118.0, "batch_reward": 0.8829502987861634, "critic_loss": 0.3482901287972927, "actor_loss": -88.52732510375976, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.458585262298584, "step": 118000}
{"episode_reward": 961.2281861434195, "episode": 119.0, "batch_reward": 0.885523574411869, "critic_loss": 0.35255688536167146, "actor_loss": -88.59283146667481, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.490499258041382, "step": 119000}
{"episode_reward": 977.9799058280072, "episode": 120.0, "batch_reward": 0.8844372989535332, "critic_loss": 0.3419112240150571, "actor_loss": -88.73135342407227, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.709643840789795, "step": 120000}
{"episode_reward": 960.0690060020488, "episode": 121.0, "batch_reward": 0.8860349418520928, "critic_loss": 0.33905135752260684, "actor_loss": -88.66611929321289, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.87247037887573, "step": 121000}
{"episode_reward": 937.8423103723748, "episode": 122.0, "batch_reward": 0.8852310259342193, "critic_loss": 0.3521071493700147, "actor_loss": -88.66644056701661, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.78064751625061, "step": 122000}
{"episode_reward": 927.0646758426947, "episode": 123.0, "batch_reward": 0.8859818580150605, "critic_loss": 0.3540283146128058, "actor_loss": -88.53542988586426, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.86406135559082, "step": 123000}
{"episode_reward": 960.1144019858586, "episode": 124.0, "batch_reward": 0.8877177749872207, "critic_loss": 0.3523570966720581, "actor_loss": -88.62116592407227, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.09542965888977, "step": 124000}
{"episode_reward": 946.9956292764538, "episode": 125.0, "batch_reward": 0.8882614976167679, "critic_loss": 0.34846209605038164, "actor_loss": -88.75733352661133, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.490179777145386, "step": 125000}
{"episode_reward": 964.1771742785804, "episode": 126.0, "batch_reward": 0.8881400401592254, "critic_loss": 0.3427714382410049, "actor_loss": -88.89711962890625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.367011308670044, "step": 126000}
{"episode_reward": 959.295835910198, "episode": 127.0, "batch_reward": 0.8880445865988731, "critic_loss": 0.35931880865991117, "actor_loss": -88.49456394958496, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.85876154899597, "step": 127000}
{"episode_reward": 878.161509782183, "episode": 128.0, "batch_reward": 0.8870668038129806, "critic_loss": 0.3662136936634779, "actor_loss": -88.713474899292, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.640884160995483, "step": 128000}
{"episode_reward": 960.3850888512625, "episode": 129.0, "batch_reward": 0.8879432719945908, "critic_loss": 0.3368398914635181, "actor_loss": -88.918556350708, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.51330065727234, "step": 129000}
{"episode_reward": 961.9773889962556, "episode": 130.0, "batch_reward": 0.890193609893322, "critic_loss": 0.3508071135133505, "actor_loss": -88.91725975036621, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.37743067741394, "step": 130000}
{"episode_reward": 932.5678765201241, "episode": 131.0, "batch_reward": 0.8900785499811172, "critic_loss": 0.35325642885267733, "actor_loss": -88.80334599304199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.1212317943573, "step": 131000}
{"episode_reward": 913.2513989534327, "episode": 132.0, "batch_reward": 0.8893556851148605, "critic_loss": 0.354794619359076, "actor_loss": -88.72149423217773, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.454116582870483, "step": 132000}
{"episode_reward": 896.255953040274, "episode": 133.0, "batch_reward": 0.8902340051531792, "critic_loss": 0.3541523853242397, "actor_loss": -89.0356109161377, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.955103874206543, "step": 133000}
{"episode_reward": 971.668707546423, "episode": 134.0, "batch_reward": 0.8908170850276947, "critic_loss": 0.3388240938782692, "actor_loss": -89.14674166870117, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.2462739944458, "step": 134000}
{"episode_reward": 947.0486936671233, "episode": 135.0, "batch_reward": 0.8916462712287903, "critic_loss": 0.3689667822569609, "actor_loss": -88.8185646057129, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.464559316635132, "step": 135000}
{"episode_reward": 942.6597872125378, "episode": 136.0, "batch_reward": 0.8920104487538337, "critic_loss": 0.33708777924627065, "actor_loss": -89.39261471557617, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.91493272781372, "step": 136000}
{"episode_reward": 968.0828106259221, "episode": 137.0, "batch_reward": 0.890446495115757, "critic_loss": 0.3446486956849694, "actor_loss": -88.96211053466797, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.969597578048706, "step": 137000}
{"episode_reward": 949.14475982163, "episode": 138.0, "batch_reward": 0.8935045454502105, "critic_loss": 0.3556277380809188, "actor_loss": -89.00377813720704, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.7826509475708, "step": 138000}
{"episode_reward": 967.3563352901776, "episode": 139.0, "batch_reward": 0.8925672234296799, "critic_loss": 0.3340704626888037, "actor_loss": -89.13422550964356, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.601252794265747, "step": 139000}
{"episode_reward": 908.326882373707, "episode": 140.0, "batch_reward": 0.8941346157193184, "critic_loss": 0.32913306580483914, "actor_loss": -89.05721990966796, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.217476844787598, "step": 140000}
{"episode_reward": 931.4922540875385, "episode": 141.0, "batch_reward": 0.8918067621588707, "critic_loss": 0.3665864532366395, "actor_loss": -88.9286902770996, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 44.443536043167114, "step": 141000}
{"episode_reward": 938.5505973400668, "episode": 142.0, "batch_reward": 0.89330427724123, "critic_loss": 0.34953611669689416, "actor_loss": -89.16172850036621, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.321570873260498, "step": 142000}
{"episode_reward": 929.4865953751039, "episode": 143.0, "batch_reward": 0.8932385649085045, "critic_loss": 0.3467616717368364, "actor_loss": -89.2660382232666, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.865757942199707, "step": 143000}
{"episode_reward": 968.5690666068427, "episode": 144.0, "batch_reward": 0.8943546042442322, "critic_loss": 0.33935147763043644, "actor_loss": -89.19607968139648, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.22217297554016, "step": 144000}
{"episode_reward": 924.3530724148361, "episode": 145.0, "batch_reward": 0.8950123077630997, "critic_loss": 0.34819783648848535, "actor_loss": -89.1544564666748, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.25402045249939, "step": 145000}
{"episode_reward": 916.2922707091313, "episode": 146.0, "batch_reward": 0.8951789105534553, "critic_loss": 0.3389286102950573, "actor_loss": -89.13891744995117, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.761485815048218, "step": 146000}
{"episode_reward": 967.1937280749805, "episode": 147.0, "batch_reward": 0.8949788635373116, "critic_loss": 0.353726450458169, "actor_loss": -89.25040107727051, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.561842441558838, "step": 147000}
{"episode_reward": 934.8542623061722, "episode": 148.0, "batch_reward": 0.8957206251621246, "critic_loss": 0.332310975857079, "actor_loss": -89.21701614379883, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.90997052192688, "step": 148000}
{"episode_reward": 940.0290737998382, "episode": 149.0, "batch_reward": 0.895129267334938, "critic_loss": 0.3193377485871315, "actor_loss": -89.19722061157226, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.972987174987793, "step": 149000}
{"episode_reward": 954.1249890762051, "episode": 150.0, "batch_reward": 0.8946931182742118, "critic_loss": 0.3401329721733928, "actor_loss": -89.06358070373535, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
