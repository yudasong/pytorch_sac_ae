{"episode_reward": 0.0, "episode": 1.0, "duration": 21.745275497436523, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.9046826362609863, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.272696476353928, "critic_loss": 0.2132119347067148, "actor_loss": -22.918274628252636, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 64.14042925834656, "step": 3000}
{"episode_reward": 121.48464820478733, "episode": 4.0, "batch_reward": 0.21600016397237778, "critic_loss": 0.5394843383431435, "actor_loss": -25.56530297088623, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.194836139678955, "step": 4000}
{"episode_reward": 135.49707587464343, "episode": 5.0, "batch_reward": 0.22547656942903996, "critic_loss": 0.8753502787649632, "actor_loss": -28.914727210998535, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.343787670135498, "step": 5000}
{"episode_reward": 455.777385440785, "episode": 6.0, "batch_reward": 0.26713578855991366, "critic_loss": 1.0093819653093814, "actor_loss": -28.80703451728821, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.71861743927002, "step": 6000}
{"episode_reward": 403.87780423701764, "episode": 7.0, "batch_reward": 0.2990364919602871, "critic_loss": 1.1633599311709404, "actor_loss": -31.094000799179078, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.676565647125244, "step": 7000}
{"episode_reward": 696.7085604806033, "episode": 8.0, "batch_reward": 0.3609726630747318, "critic_loss": 1.446337383210659, "actor_loss": -36.03638193130493, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.806151151657104, "step": 8000}
{"episode_reward": 765.3382712932878, "episode": 9.0, "batch_reward": 0.4183043338358402, "critic_loss": 1.4682404076457023, "actor_loss": -38.74876796340942, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.93738031387329, "step": 9000}
{"episode_reward": 844.3421756737121, "episode": 10.0, "batch_reward": 0.4464790661931038, "critic_loss": 1.6340486884117127, "actor_loss": -42.19972978210449, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.784135580062866, "step": 10000}
{"episode_reward": 517.9215173313843, "episode": 11.0, "batch_reward": 0.4623663545250893, "critic_loss": 1.6548627170920371, "actor_loss": -42.555001918792726, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.43341040611267, "step": 11000}
{"episode_reward": 578.5496636404004, "episode": 12.0, "batch_reward": 0.4742288316488266, "critic_loss": 1.627734124660492, "actor_loss": -46.677208393096926, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.36753249168396, "step": 12000}
{"episode_reward": 751.6270739175229, "episode": 13.0, "batch_reward": 0.49723015809059146, "critic_loss": 1.7031706498861312, "actor_loss": -46.79976850128174, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.286176919937134, "step": 13000}
{"episode_reward": 818.9723921644379, "episode": 14.0, "batch_reward": 0.5222545583844185, "critic_loss": 1.7570814051628112, "actor_loss": -49.47388973236084, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.66173553466797, "step": 14000}
{"episode_reward": 876.5599487155523, "episode": 15.0, "batch_reward": 0.548997845351696, "critic_loss": 1.7090542619228364, "actor_loss": -49.880446929931644, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.894472360610962, "step": 15000}
{"episode_reward": 848.0357813880578, "episode": 16.0, "batch_reward": 0.5664791461527348, "critic_loss": 1.8524758499860763, "actor_loss": -55.5496690826416, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.61346960067749, "step": 16000}
{"episode_reward": 853.118210569137, "episode": 17.0, "batch_reward": 0.5838229922354221, "critic_loss": 1.8110445028543471, "actor_loss": -57.28512008666992, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.979682445526123, "step": 17000}
{"episode_reward": 816.555022436167, "episode": 18.0, "batch_reward": 0.5969251605272293, "critic_loss": 1.6115160300135611, "actor_loss": -58.074565551757814, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.926129817962646, "step": 18000}
{"episode_reward": 883.4643298080704, "episode": 19.0, "batch_reward": 0.6132948593497276, "critic_loss": 1.545567849934101, "actor_loss": -59.776486305236816, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.543490409851074, "step": 19000}
{"episode_reward": 928.9011610086953, "episode": 20.0, "batch_reward": 0.6293230974674224, "critic_loss": 1.4306496306061744, "actor_loss": -60.12823742675781, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.10884714126587, "step": 20000}
{"episode_reward": 837.5294411668573, "episode": 21.0, "batch_reward": 0.6420367995500564, "critic_loss": 1.3447123297452928, "actor_loss": -62.046684104919436, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.383676528930664, "step": 21000}
{"episode_reward": 946.8652999718709, "episode": 22.0, "batch_reward": 0.6543843231201172, "critic_loss": 1.3782013227939607, "actor_loss": -62.472738159179684, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.73604679107666, "step": 22000}
{"episode_reward": 842.7647217136154, "episode": 23.0, "batch_reward": 0.6553079227209091, "critic_loss": 1.4556417717337609, "actor_loss": -63.901216613769535, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.534291744232178, "step": 23000}
{"episode_reward": 684.7888962771184, "episode": 24.0, "batch_reward": 0.6659885192513466, "critic_loss": 1.34396524310112, "actor_loss": -64.52334796142578, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.790928602218628, "step": 24000}
{"episode_reward": 863.4298997311936, "episode": 25.0, "batch_reward": 0.6701277768611908, "critic_loss": 1.4099888259768485, "actor_loss": -65.62955982971191, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.10305118560791, "step": 25000}
{"episode_reward": 840.1607913650834, "episode": 26.0, "batch_reward": 0.6775651746988296, "critic_loss": 1.411223240017891, "actor_loss": -66.57960848236084, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.816373825073242, "step": 26000}
{"episode_reward": 816.6939043239659, "episode": 27.0, "batch_reward": 0.6881477174758911, "critic_loss": 1.476495520055294, "actor_loss": -67.32047001647949, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.086100339889526, "step": 27000}
{"episode_reward": 921.607628483385, "episode": 28.0, "batch_reward": 0.6883603840470314, "critic_loss": 1.521121646821499, "actor_loss": -68.2617161026001, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.81862449645996, "step": 28000}
{"episode_reward": 737.5611469061312, "episode": 29.0, "batch_reward": 0.6918262891173362, "critic_loss": 1.5310629796981812, "actor_loss": -68.0346155166626, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.679948329925537, "step": 29000}
{"episode_reward": 795.9546468615127, "episode": 30.0, "batch_reward": 0.6941615347862243, "critic_loss": 1.4942780413627625, "actor_loss": -69.53873306274414, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.930893421173096, "step": 30000}
{"episode_reward": 821.7621906434529, "episode": 31.0, "batch_reward": 0.6977593032121658, "critic_loss": 1.4982397308945656, "actor_loss": -70.22440151977538, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.51265001296997, "step": 31000}
{"episode_reward": 800.0850081437275, "episode": 32.0, "batch_reward": 0.7054072231650352, "critic_loss": 1.4289359448552132, "actor_loss": -70.61719660949707, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.886228799819946, "step": 32000}
{"episode_reward": 912.3059439197011, "episode": 33.0, "batch_reward": 0.7074673570990563, "critic_loss": 1.5626783306598664, "actor_loss": -70.81973796081543, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.9300217628479, "step": 33000}
{"episode_reward": 828.7346755442143, "episode": 34.0, "batch_reward": 0.7125939716100693, "critic_loss": 1.5538006190061568, "actor_loss": -72.0037837677002, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.14428186416626, "step": 34000}
{"episode_reward": 851.3851037500274, "episode": 35.0, "batch_reward": 0.71876902115345, "critic_loss": 1.4310468299388885, "actor_loss": -72.16340110778809, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.568601608276367, "step": 35000}
{"episode_reward": 946.8514399378698, "episode": 36.0, "batch_reward": 0.726682723581791, "critic_loss": 1.4675057628154755, "actor_loss": -72.99196626281739, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.06951379776001, "step": 36000}
{"episode_reward": 815.6173923949061, "episode": 37.0, "batch_reward": 0.727661725640297, "critic_loss": 1.4454086092710494, "actor_loss": -73.47691842651368, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.797191619873047, "step": 37000}
{"episode_reward": 868.4769823909984, "episode": 38.0, "batch_reward": 0.7324021959900856, "critic_loss": 1.4188943654894828, "actor_loss": -73.5753109588623, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.06571125984192, "step": 38000}
{"episode_reward": 950.5338972599441, "episode": 39.0, "batch_reward": 0.7358108360767365, "critic_loss": 1.4129087956547737, "actor_loss": -74.16282749938965, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.243211269378662, "step": 39000}
{"episode_reward": 839.3917803478228, "episode": 40.0, "batch_reward": 0.7396154092550278, "critic_loss": 1.4497136320471764, "actor_loss": -74.68061869812011, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.448944807052612, "step": 40000}
{"episode_reward": 938.7854733788747, "episode": 41.0, "batch_reward": 0.7448523648381233, "critic_loss": 1.4205430101156236, "actor_loss": -75.22297877502442, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.06929588317871, "step": 41000}
{"episode_reward": 943.1649232503122, "episode": 42.0, "batch_reward": 0.7460302152633667, "critic_loss": 1.4385563368797303, "actor_loss": -75.45021627807617, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.101040601730347, "step": 42000}
{"episode_reward": 872.3448505172581, "episode": 43.0, "batch_reward": 0.7508787453770638, "critic_loss": 1.4748326030373573, "actor_loss": -75.85280656433106, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.86375379562378, "step": 43000}
{"episode_reward": 744.9369562686727, "episode": 44.0, "batch_reward": 0.751914315879345, "critic_loss": 1.3745508103370667, "actor_loss": -76.07439305114747, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.762526512145996, "step": 44000}
{"episode_reward": 883.3212908024501, "episode": 45.0, "batch_reward": 0.7539926841855049, "critic_loss": 1.3846139394044876, "actor_loss": -76.20957620239258, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.20304775238037, "step": 45000}
{"episode_reward": 887.278842059, "episode": 46.0, "batch_reward": 0.7590284766554832, "critic_loss": 1.3476042433977127, "actor_loss": -76.71611117553711, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.752389192581177, "step": 46000}
{"episode_reward": 947.9000522769134, "episode": 47.0, "batch_reward": 0.7630860081315041, "critic_loss": 1.3192617138028144, "actor_loss": -77.19153329467774, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.317036628723145, "step": 47000}
{"episode_reward": 929.0335313336295, "episode": 48.0, "batch_reward": 0.7663322234749794, "critic_loss": 1.3304758927822113, "actor_loss": -77.29542623901366, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.749501705169678, "step": 48000}
{"episode_reward": 909.4038679524903, "episode": 49.0, "batch_reward": 0.7698117288351058, "critic_loss": 1.284832921564579, "actor_loss": -77.78379634094239, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.69588875770569, "step": 49000}
{"episode_reward": 893.2173890000832, "episode": 50.0, "batch_reward": 0.7725962322950363, "critic_loss": 1.3120175864100456, "actor_loss": -78.22311601257324, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.002029180526733, "step": 50000}
{"episode_reward": 916.5216293487774, "episode": 51.0, "batch_reward": 0.7744650261998176, "critic_loss": 1.2763835051059722, "actor_loss": -78.40731930541992, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.06804585456848, "step": 51000}
{"episode_reward": 970.8554162317323, "episode": 52.0, "batch_reward": 0.7757117061018943, "critic_loss": 1.3086653386354445, "actor_loss": -78.77922810363769, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.007524490356445, "step": 52000}
{"episode_reward": 839.0695031677693, "episode": 53.0, "batch_reward": 0.7787890763282775, "critic_loss": 1.2396461678147317, "actor_loss": -79.0117373046875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.675426483154297, "step": 53000}
{"episode_reward": 877.2159060722212, "episode": 54.0, "batch_reward": 0.7812389849424363, "critic_loss": 1.2634935040473938, "actor_loss": -79.47730801391602, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.726511478424072, "step": 54000}
{"episode_reward": 919.991385805052, "episode": 55.0, "batch_reward": 0.7848507632017135, "critic_loss": 1.2595723688006402, "actor_loss": -79.78537535095215, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.513044595718384, "step": 55000}
{"episode_reward": 960.2546815666957, "episode": 56.0, "batch_reward": 0.7883585919737816, "critic_loss": 1.1470986233353615, "actor_loss": -80.02811199951172, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.850953102111816, "step": 56000}
{"episode_reward": 958.490579313184, "episode": 57.0, "batch_reward": 0.7884124777913094, "critic_loss": 1.2131364513635636, "actor_loss": -80.22646351623536, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.93639349937439, "step": 57000}
{"episode_reward": 863.0257664191334, "episode": 58.0, "batch_reward": 0.7911539533734322, "critic_loss": 1.2188059399724007, "actor_loss": -80.4379362335205, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.873327493667603, "step": 58000}
{"episode_reward": 878.5865602237099, "episode": 59.0, "batch_reward": 0.794380631685257, "critic_loss": 1.225504859805107, "actor_loss": -80.74295108032227, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.933125257492065, "step": 59000}
{"episode_reward": 975.0356195884492, "episode": 60.0, "batch_reward": 0.7953458340764046, "critic_loss": 1.2552582734823228, "actor_loss": -80.97567132568359, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.348169803619385, "step": 60000}
{"episode_reward": 890.4906458563049, "episode": 61.0, "batch_reward": 0.7978594914078713, "critic_loss": 1.216813167244196, "actor_loss": -81.22059217834473, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.006571769714355, "step": 61000}
{"episode_reward": 920.4639137647564, "episode": 62.0, "batch_reward": 0.7980662300586701, "critic_loss": 1.196179481446743, "actor_loss": -81.40504217529296, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.35472059249878, "step": 62000}
{"episode_reward": 963.230224711412, "episode": 63.0, "batch_reward": 0.8003177217841149, "critic_loss": 1.1122108375430106, "actor_loss": -81.64058822631836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.87053918838501, "step": 63000}
{"episode_reward": 974.0532709321454, "episode": 64.0, "batch_reward": 0.8048828790187835, "critic_loss": 1.0419383568167686, "actor_loss": -81.91403555297852, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.127222537994385, "step": 64000}
{"episode_reward": 919.022674564987, "episode": 65.0, "batch_reward": 0.8048924849629402, "critic_loss": 1.0959658339619636, "actor_loss": -82.0096672668457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.098196029663086, "step": 65000}
{"episode_reward": 834.7823871841634, "episode": 66.0, "batch_reward": 0.8058633925318718, "critic_loss": 1.1064437419772148, "actor_loss": -82.1891847076416, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.58775305747986, "step": 66000}
{"episode_reward": 930.822269463898, "episode": 67.0, "batch_reward": 0.8099159373044967, "critic_loss": 1.078954197138548, "actor_loss": -82.39894680786132, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.657509088516235, "step": 67000}
{"episode_reward": 920.230282542327, "episode": 68.0, "batch_reward": 0.8101255084872245, "critic_loss": 1.0826420893371105, "actor_loss": -82.49315647888183, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.715630292892456, "step": 68000}
{"episode_reward": 934.0396755850342, "episode": 69.0, "batch_reward": 0.8126138553619385, "critic_loss": 1.0602308611273765, "actor_loss": -82.72379959106445, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.574530601501465, "step": 69000}
{"episode_reward": 961.1673075276149, "episode": 70.0, "batch_reward": 0.8142969383597374, "critic_loss": 1.0457960440516472, "actor_loss": -82.8503963470459, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.811485528945923, "step": 70000}
{"episode_reward": 857.0538795359818, "episode": 71.0, "batch_reward": 0.8139185966849327, "critic_loss": 1.0557440705895424, "actor_loss": -83.01751692199707, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.71162438392639, "step": 71000}
{"episode_reward": 935.4802834477181, "episode": 72.0, "batch_reward": 0.8154302522540092, "critic_loss": 1.0140774758458138, "actor_loss": -83.13344142150879, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.584561347961426, "step": 72000}
{"episode_reward": 902.9658868940663, "episode": 73.0, "batch_reward": 0.8172488638162613, "critic_loss": 1.016514969855547, "actor_loss": -83.28157188415527, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.19803547859192, "step": 73000}
{"episode_reward": 973.348079698769, "episode": 74.0, "batch_reward": 0.8208539191484451, "critic_loss": 0.9886512925028801, "actor_loss": -83.45542178344726, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.93979811668396, "step": 74000}
{"episode_reward": 943.4104570323132, "episode": 75.0, "batch_reward": 0.8230318296551704, "critic_loss": 0.947994283258915, "actor_loss": -83.5916125793457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.65148115158081, "step": 75000}
{"episode_reward": 931.2655662329099, "episode": 76.0, "batch_reward": 0.8221592128872871, "critic_loss": 0.9803025482594967, "actor_loss": -83.5921706085205, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.886380195617676, "step": 76000}
{"episode_reward": 857.5878353308173, "episode": 77.0, "batch_reward": 0.8250364231467247, "critic_loss": 0.9837271255850792, "actor_loss": -83.8462338256836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.400302410125732, "step": 77000}
{"episode_reward": 963.4304067689973, "episode": 78.0, "batch_reward": 0.8253682907223702, "critic_loss": 0.9649670059680939, "actor_loss": -83.90872010803223, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.360234022140503, "step": 78000}
{"episode_reward": 842.8642687748393, "episode": 79.0, "batch_reward": 0.8246184440255165, "critic_loss": 1.0292122319936752, "actor_loss": -83.96578080749512, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.01979660987854, "step": 79000}
{"episode_reward": 939.1276316282402, "episode": 80.0, "batch_reward": 0.8289816120266914, "critic_loss": 1.015308160662651, "actor_loss": -84.07463833618164, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.982825994491577, "step": 80000}
{"episode_reward": 940.6309698152173, "episode": 81.0, "batch_reward": 0.8274663665294647, "critic_loss": 1.0046948181390762, "actor_loss": -84.1625259552002, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.25327658653259, "step": 81000}
{"episode_reward": 916.515659310439, "episode": 82.0, "batch_reward": 0.8283108839392662, "critic_loss": 1.0131151538193226, "actor_loss": -84.23027088928222, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.105095148086548, "step": 82000}
{"episode_reward": 953.980481772167, "episode": 83.0, "batch_reward": 0.8293049695491791, "critic_loss": 1.0276589375734329, "actor_loss": -84.24663615417481, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.90691089630127, "step": 83000}
{"episode_reward": 882.4883080854534, "episode": 84.0, "batch_reward": 0.8309482478499413, "critic_loss": 1.0379863792657853, "actor_loss": -84.32209716796875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.670382261276245, "step": 84000}
{"episode_reward": 891.3403541825521, "episode": 85.0, "batch_reward": 0.8305841090679169, "critic_loss": 0.9938699713051319, "actor_loss": -84.46772503662109, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.52111315727234, "step": 85000}
{"episode_reward": 868.67035685012, "episode": 86.0, "batch_reward": 0.8333422657251358, "critic_loss": 1.012511331409216, "actor_loss": -84.44693182373047, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.825645685195923, "step": 86000}
{"episode_reward": 937.0054580863673, "episode": 87.0, "batch_reward": 0.832914543569088, "critic_loss": 1.0190929993391038, "actor_loss": -84.54347828674317, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.798377752304077, "step": 87000}
{"episode_reward": 921.4374741360513, "episode": 88.0, "batch_reward": 0.8344980482459068, "critic_loss": 1.0252126092016698, "actor_loss": -84.60604850769043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.023301362991333, "step": 88000}
{"episode_reward": 879.0270585658482, "episode": 89.0, "batch_reward": 0.8356765565872193, "critic_loss": 0.9947560656666755, "actor_loss": -84.69405642700195, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.077188730239868, "step": 89000}
{"episode_reward": 965.9879524448668, "episode": 90.0, "batch_reward": 0.8356162464618683, "critic_loss": 0.9713808898627758, "actor_loss": -84.847177734375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.925318241119385, "step": 90000}
{"episode_reward": 945.1515867260382, "episode": 91.0, "batch_reward": 0.8376335746645928, "critic_loss": 1.033884996712208, "actor_loss": -84.92849291992188, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.80352067947388, "step": 91000}
{"episode_reward": 880.8816064104203, "episode": 92.0, "batch_reward": 0.8393604289293289, "critic_loss": 0.9399102421402932, "actor_loss": -84.9654232788086, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.354390382766724, "step": 92000}
{"episode_reward": 943.5129726493172, "episode": 93.0, "batch_reward": 0.8389162272810936, "critic_loss": 0.9737905345261096, "actor_loss": -85.04433085632324, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.23895812034607, "step": 93000}
{"episode_reward": 962.30357545363, "episode": 94.0, "batch_reward": 0.8409772655963897, "critic_loss": 0.9890092912912368, "actor_loss": -85.20920693969727, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.467169523239136, "step": 94000}
{"episode_reward": 941.3157312052027, "episode": 95.0, "batch_reward": 0.8421462278366089, "critic_loss": 0.9471117787957192, "actor_loss": -85.43393461608886, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.743282794952393, "step": 95000}
{"episode_reward": 936.5813295763091, "episode": 96.0, "batch_reward": 0.8422786222100258, "critic_loss": 0.9663648115694523, "actor_loss": -85.17647038269043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.113176822662354, "step": 96000}
{"episode_reward": 948.1384076640558, "episode": 97.0, "batch_reward": 0.8427794579267501, "critic_loss": 0.9811616615355014, "actor_loss": -85.40202229309082, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.75567936897278, "step": 97000}
{"episode_reward": 930.5459232234824, "episode": 98.0, "batch_reward": 0.8429928540587425, "critic_loss": 1.02910284486413, "actor_loss": -85.5154714050293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.182964086532593, "step": 98000}
{"episode_reward": 850.2518254923931, "episode": 99.0, "batch_reward": 0.8442779995203018, "critic_loss": 1.0109009709954262, "actor_loss": -85.39567446899414, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.506978750228882, "step": 99000}
{"episode_reward": 937.5255789253422, "episode": 100.0, "batch_reward": 0.8450358253121376, "critic_loss": 1.0794697227180003, "actor_loss": -85.49344836425782, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.80931043624878, "step": 100000}
{"episode_reward": 970.5961910061686, "episode": 101.0, "batch_reward": 0.8477353748083115, "critic_loss": 1.0663473387360574, "actor_loss": -85.53038754272461, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.067235469818115, "step": 101000}
{"episode_reward": 961.2726207056407, "episode": 102.0, "batch_reward": 0.8482970809340477, "critic_loss": 0.9951833213269711, "actor_loss": -85.62318740844727, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.36989140510559, "step": 102000}
{"episode_reward": 961.5591342141804, "episode": 103.0, "batch_reward": 0.8504961007237435, "critic_loss": 0.9990914074480534, "actor_loss": -85.69383143615723, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.977112293243408, "step": 103000}
{"episode_reward": 958.4273360101841, "episode": 104.0, "batch_reward": 0.8495257589221, "critic_loss": 0.9731234984695911, "actor_loss": -85.67584034729003, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.79603409767151, "step": 104000}
{"episode_reward": 948.3577781787345, "episode": 105.0, "batch_reward": 0.8509677507281304, "critic_loss": 0.9688974179923534, "actor_loss": -85.80228982543946, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.380868434906006, "step": 105000}
{"episode_reward": 952.8104533124441, "episode": 106.0, "batch_reward": 0.852112750172615, "critic_loss": 0.9678369068205357, "actor_loss": -85.85614762878419, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.97075581550598, "step": 106000}
{"episode_reward": 930.4516158959256, "episode": 107.0, "batch_reward": 0.852659545481205, "critic_loss": 0.958688134342432, "actor_loss": -85.82278248596191, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.726170539855957, "step": 107000}
{"episode_reward": 851.5122526743565, "episode": 108.0, "batch_reward": 0.8540080938935279, "critic_loss": 0.9350228388309478, "actor_loss": -86.11414485168457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.973000288009644, "step": 108000}
{"episode_reward": 915.3881678654468, "episode": 109.0, "batch_reward": 0.8523365671634674, "critic_loss": 0.9861263471841812, "actor_loss": -85.97603807067871, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.87398910522461, "step": 109000}
{"episode_reward": 898.4673808351146, "episode": 110.0, "batch_reward": 0.8546598421335221, "critic_loss": 1.0040812536478043, "actor_loss": -86.06720513916015, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.922291040420532, "step": 110000}
{"episode_reward": 944.800948823793, "episode": 111.0, "batch_reward": 0.8549575005173683, "critic_loss": 0.968273796826601, "actor_loss": -86.29350785827637, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.13441061973572, "step": 111000}
{"episode_reward": 901.4770929024703, "episode": 112.0, "batch_reward": 0.8552655402421951, "critic_loss": 0.9780542390942574, "actor_loss": -86.11453913879394, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.5421781539917, "step": 112000}
{"episode_reward": 963.6262293912026, "episode": 113.0, "batch_reward": 0.8555267102718354, "critic_loss": 0.9554128798544407, "actor_loss": -86.2432371673584, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.54256820678711, "step": 113000}
{"episode_reward": 966.4551597729462, "episode": 114.0, "batch_reward": 0.8569004279971123, "critic_loss": 0.9848716226220131, "actor_loss": -86.32181573486328, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.052518129348755, "step": 114000}
{"episode_reward": 966.4583899897721, "episode": 115.0, "batch_reward": 0.857065001308918, "critic_loss": 1.0099211554527283, "actor_loss": -86.41792115783691, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.015923261642456, "step": 115000}
{"episode_reward": 881.9255792106916, "episode": 116.0, "batch_reward": 0.8596658625602722, "critic_loss": 0.9528878556489945, "actor_loss": -86.5970291595459, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.04640293121338, "step": 116000}
{"episode_reward": 923.0108238426085, "episode": 117.0, "batch_reward": 0.8578627665638924, "critic_loss": 0.9461901024878026, "actor_loss": -86.69467388916016, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.37783980369568, "step": 117000}
{"episode_reward": 929.6171321579126, "episode": 118.0, "batch_reward": 0.859674372792244, "critic_loss": 0.937433272600174, "actor_loss": -86.72956225585938, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.872721195220947, "step": 118000}
{"episode_reward": 958.4631183637956, "episode": 119.0, "batch_reward": 0.8615998337864876, "critic_loss": 0.95120825907588, "actor_loss": -86.74807281494141, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.875410079956055, "step": 119000}
{"episode_reward": 970.15431662684, "episode": 120.0, "batch_reward": 0.8614448016881943, "critic_loss": 0.92189748904109, "actor_loss": -86.90522285461425, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.78265619277954, "step": 120000}
{"episode_reward": 953.3199562156101, "episode": 121.0, "batch_reward": 0.8615923880934715, "critic_loss": 0.9221560216248036, "actor_loss": -86.75961529541016, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.492799043655396, "step": 121000}
{"episode_reward": 941.9542905506172, "episode": 122.0, "batch_reward": 0.8629199026823043, "critic_loss": 0.8418595348894596, "actor_loss": -86.87266215515136, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.083744764328003, "step": 122000}
{"episode_reward": 941.3120599573394, "episode": 123.0, "batch_reward": 0.8640958440899849, "critic_loss": 0.9087915671765804, "actor_loss": -86.97869578552246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.806876182556152, "step": 123000}
{"episode_reward": 960.1922879107215, "episode": 124.0, "batch_reward": 0.8654078385829925, "critic_loss": 0.8758275025188923, "actor_loss": -86.9564945526123, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.035750150680542, "step": 124000}
{"episode_reward": 919.4692647231979, "episode": 125.0, "batch_reward": 0.8654342287778855, "critic_loss": 0.8852147525250912, "actor_loss": -87.1410408630371, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.76948118209839, "step": 125000}
{"episode_reward": 970.7905073328824, "episode": 126.0, "batch_reward": 0.8656194329261779, "critic_loss": 0.870016886472702, "actor_loss": -87.25043975830079, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.67798137664795, "step": 126000}
{"episode_reward": 945.5589512219847, "episode": 127.0, "batch_reward": 0.8665569498538971, "critic_loss": 0.8380333390235901, "actor_loss": -87.10231806945801, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.686660289764404, "step": 127000}
{"episode_reward": 933.3787150428911, "episode": 128.0, "batch_reward": 0.866765538752079, "critic_loss": 0.835075633585453, "actor_loss": -87.17480920410156, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.709836721420288, "step": 128000}
{"episode_reward": 954.4600881014317, "episode": 129.0, "batch_reward": 0.8666554749011993, "critic_loss": 0.8181092549562454, "actor_loss": -87.27931776428223, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.772680521011353, "step": 129000}
{"episode_reward": 954.4104835734518, "episode": 130.0, "batch_reward": 0.8676853796243668, "critic_loss": 0.8308993953168392, "actor_loss": -87.3781346282959, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.89815878868103, "step": 130000}
{"episode_reward": 903.0098920912006, "episode": 131.0, "batch_reward": 0.8679026374816895, "critic_loss": 0.8017803723812104, "actor_loss": -87.43117289733887, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.866597414016724, "step": 131000}
{"episode_reward": 897.7598165871111, "episode": 132.0, "batch_reward": 0.8676546855568886, "critic_loss": 0.8279240653514862, "actor_loss": -87.40209382629395, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.01290225982666, "step": 132000}
{"episode_reward": 931.4936213493427, "episode": 133.0, "batch_reward": 0.8690449730157852, "critic_loss": 0.8404645407795907, "actor_loss": -87.6966114501953, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.217978477478027, "step": 133000}
{"episode_reward": 971.0887351133921, "episode": 134.0, "batch_reward": 0.8686409702897072, "critic_loss": 0.8441320071816445, "actor_loss": -87.61168936157226, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.407482385635376, "step": 134000}
{"episode_reward": 862.0465637306858, "episode": 135.0, "batch_reward": 0.8694673892259598, "critic_loss": 0.8804204320907593, "actor_loss": -87.43954679870606, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.95423412322998, "step": 135000}
{"episode_reward": 952.5325523161519, "episode": 136.0, "batch_reward": 0.8710529668927193, "critic_loss": 0.8675512429773807, "actor_loss": -87.83101666259766, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.68938136100769, "step": 136000}
{"episode_reward": 945.564077291601, "episode": 137.0, "batch_reward": 0.8701105667948723, "critic_loss": 0.8285917750298977, "actor_loss": -87.64921832275391, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.895160675048828, "step": 137000}
{"episode_reward": 962.5641984746595, "episode": 138.0, "batch_reward": 0.8729237194657326, "critic_loss": 0.8202508493959904, "actor_loss": -87.61039277648926, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.55573606491089, "step": 138000}
{"episode_reward": 968.7990045749132, "episode": 139.0, "batch_reward": 0.8717363851666451, "critic_loss": 0.8762707512676716, "actor_loss": -87.80432785034179, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.990686655044556, "step": 139000}
{"episode_reward": 914.3544253366612, "episode": 140.0, "batch_reward": 0.874161891758442, "critic_loss": 0.825246536552906, "actor_loss": -87.81084632873535, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.028249502182007, "step": 140000}
{"episode_reward": 964.7039671628806, "episode": 141.0, "batch_reward": 0.8714643934965134, "critic_loss": 0.847661964148283, "actor_loss": -87.60227374267578, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.560924768447876, "step": 141000}
{"episode_reward": 890.9161156947031, "episode": 142.0, "batch_reward": 0.8734099127054215, "critic_loss": 0.8399884036779404, "actor_loss": -87.8545117340088, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.109235048294067, "step": 142000}
{"episode_reward": 945.212396216713, "episode": 143.0, "batch_reward": 0.87406756234169, "critic_loss": 0.8636700310111046, "actor_loss": -88.03177764892578, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.740511655807495, "step": 143000}
{"episode_reward": 960.5064979097657, "episode": 144.0, "batch_reward": 0.8747631793022156, "critic_loss": 0.842162729114294, "actor_loss": -87.95545011901855, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.058168649673462, "step": 144000}
{"episode_reward": 919.0868077169599, "episode": 145.0, "batch_reward": 0.8760841900706291, "critic_loss": 0.820803994834423, "actor_loss": -87.9240912322998, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.867796897888184, "step": 145000}
{"episode_reward": 917.4953885433946, "episode": 146.0, "batch_reward": 0.8749748818278312, "critic_loss": 0.8270881127417088, "actor_loss": -87.81669929504395, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.372815370559692, "step": 146000}
{"episode_reward": 973.2292913191541, "episode": 147.0, "batch_reward": 0.8744233031272888, "critic_loss": 0.8262484879791736, "actor_loss": -87.93702961730958, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.77930188179016, "step": 147000}
{"episode_reward": 926.246469445342, "episode": 148.0, "batch_reward": 0.8751881164312363, "critic_loss": 0.8125547085106373, "actor_loss": -87.9081587677002, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.688496112823486, "step": 148000}
{"episode_reward": 879.4275402404427, "episode": 149.0, "batch_reward": 0.8754307730793953, "critic_loss": 0.8348971073329449, "actor_loss": -88.05441664123535, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.87064528465271, "step": 149000}
{"episode_reward": 949.0163690730607, "episode": 150.0, "batch_reward": 0.8754258184432984, "critic_loss": 0.7922981738448143, "actor_loss": -88.0097060394287, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
