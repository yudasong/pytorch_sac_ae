{"episode_reward": 0.0, "episode": 1.0, "duration": 20.767147302627563, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.8075628280639648, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.313293858269486, "critic_loss": 0.519279159940891, "actor_loss": -72.89721738609995, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.82224988937378, "step": 3000}
{"episode_reward": 750.8057383183262, "episode": 4.0, "batch_reward": 0.48115718919038775, "critic_loss": 0.5179375975728034, "actor_loss": -80.87403645324707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.371124267578125, "step": 4000}
{"episode_reward": 816.195461554065, "episode": 5.0, "batch_reward": 0.5466960205733776, "critic_loss": 0.563240086197853, "actor_loss": -81.98419981384278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.401021003723145, "step": 5000}
{"episode_reward": 714.1740891928658, "episode": 6.0, "batch_reward": 0.5957980697751045, "critic_loss": 0.4962562780827284, "actor_loss": -83.33844604492188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.424755096435547, "step": 6000}
{"episode_reward": 888.2511733021169, "episode": 7.0, "batch_reward": 0.6291124362647533, "critic_loss": 0.5391158792674542, "actor_loss": -84.0664044494629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.434053659439087, "step": 7000}
{"episode_reward": 835.2804043793002, "episode": 8.0, "batch_reward": 0.6460499312877656, "critic_loss": 0.6488665088415145, "actor_loss": -84.15199319458007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.432868719100952, "step": 8000}
{"episode_reward": 632.5408467519964, "episode": 9.0, "batch_reward": 0.666306687772274, "critic_loss": 0.5158949315547943, "actor_loss": -84.69864739990234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.402825117111206, "step": 9000}
{"episode_reward": 926.6818103715153, "episode": 10.0, "batch_reward": 0.6848083621263504, "critic_loss": 0.5385725835561752, "actor_loss": -84.94259980773926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.40287733078003, "step": 10000}
{"episode_reward": 834.7476791098965, "episode": 11.0, "batch_reward": 0.7087610493898392, "critic_loss": 0.5027608375549316, "actor_loss": -85.81811921691894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.92167901992798, "step": 11000}
{"episode_reward": 931.4900040094537, "episode": 12.0, "batch_reward": 0.7245722008943558, "critic_loss": 0.487787083119154, "actor_loss": -85.89360382080078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.44243884086609, "step": 12000}
{"episode_reward": 913.1971407513494, "episode": 13.0, "batch_reward": 0.7373102693557739, "critic_loss": 0.5220970434695482, "actor_loss": -86.61059539794923, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.43145179748535, "step": 13000}
{"episode_reward": 900.6387311427515, "episode": 14.0, "batch_reward": 0.7508940567374229, "critic_loss": 0.4655101669728756, "actor_loss": -86.96446653747559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.428572177886963, "step": 14000}
{"episode_reward": 915.0936296913526, "episode": 15.0, "batch_reward": 0.7655911472439766, "critic_loss": 0.4536671783924103, "actor_loss": -87.74888879394531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.445892333984375, "step": 15000}
{"episode_reward": 971.2214644612895, "episode": 16.0, "batch_reward": 0.7805066829919816, "critic_loss": 0.40862010848522184, "actor_loss": -87.30419299316407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.430171728134155, "step": 16000}
{"episode_reward": 971.9995608609551, "episode": 17.0, "batch_reward": 0.7782030212283134, "critic_loss": 0.5291117317676545, "actor_loss": -87.2379933013916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.431041717529297, "step": 17000}
{"episode_reward": 722.6956578466478, "episode": 18.0, "batch_reward": 0.7845485101342201, "critic_loss": 0.4938061495125294, "actor_loss": -87.4396609954834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.441409826278687, "step": 18000}
{"episode_reward": 902.3184030750815, "episode": 19.0, "batch_reward": 0.7890303978323936, "critic_loss": 0.45150694000720976, "actor_loss": -87.42101948547364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.44257688522339, "step": 19000}
{"episode_reward": 904.1372453476515, "episode": 20.0, "batch_reward": 0.7914095290899277, "critic_loss": 0.528563930273056, "actor_loss": -87.75437536621094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.41428542137146, "step": 20000}
{"episode_reward": 822.383066134364, "episode": 21.0, "batch_reward": 0.799838979780674, "critic_loss": 0.49621985317766665, "actor_loss": -87.74454472351074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.90333342552185, "step": 21000}
{"episode_reward": 951.9293325482824, "episode": 22.0, "batch_reward": 0.8054046004414558, "critic_loss": 0.5333511270880699, "actor_loss": -88.17126220703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.41265034675598, "step": 22000}
{"episode_reward": 893.9166278585358, "episode": 23.0, "batch_reward": 0.8051835497021675, "critic_loss": 0.5565940520763397, "actor_loss": -88.02153713989257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.431668281555176, "step": 23000}
{"episode_reward": 883.8468467010417, "episode": 24.0, "batch_reward": 0.8103735893964767, "critic_loss": 0.5617600725293159, "actor_loss": -88.27658877563476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.43524956703186, "step": 24000}
{"episode_reward": 873.8251392528899, "episode": 25.0, "batch_reward": 0.8128208784461022, "critic_loss": 0.5575592924058438, "actor_loss": -88.24072338867188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.369016885757446, "step": 25000}
{"episode_reward": 861.4220805263673, "episode": 26.0, "batch_reward": 0.8177805519104004, "critic_loss": 0.47858541762828827, "actor_loss": -88.33562014770507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.42976474761963, "step": 26000}
{"episode_reward": 946.2804553929313, "episode": 27.0, "batch_reward": 0.8214198172092437, "critic_loss": 0.45892630399763584, "actor_loss": -88.46222222900391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.43353533744812, "step": 27000}
{"episode_reward": 887.5658409823887, "episode": 28.0, "batch_reward": 0.8237120449543, "critic_loss": 0.4554912464618683, "actor_loss": -88.42279959106445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.42645573616028, "step": 28000}
{"episode_reward": 929.9985301008122, "episode": 29.0, "batch_reward": 0.8291059688925743, "critic_loss": 0.4374224741309881, "actor_loss": -88.97619024658204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.4032039642334, "step": 29000}
{"episode_reward": 974.252496018765, "episode": 30.0, "batch_reward": 0.8281851840019226, "critic_loss": 0.44811618463695047, "actor_loss": -88.51264239501953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.400686264038086, "step": 30000}
{"episode_reward": 812.1456837988325, "episode": 31.0, "batch_reward": 0.8292355904579163, "critic_loss": 0.44429743407666683, "actor_loss": -88.3825764465332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.878371238708496, "step": 31000}
{"episode_reward": 873.7139827592581, "episode": 32.0, "batch_reward": 0.83314495241642, "critic_loss": 0.44610853339731693, "actor_loss": -88.60791868591309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.402033805847168, "step": 32000}
{"episode_reward": 955.654891045307, "episode": 33.0, "batch_reward": 0.837578678369522, "critic_loss": 0.44031376907229425, "actor_loss": -88.80930389404297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.41593360900879, "step": 33000}
{"episode_reward": 952.6228129497605, "episode": 34.0, "batch_reward": 0.8400942595601082, "critic_loss": 0.47651979660987853, "actor_loss": -88.58540478515626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.38804817199707, "step": 34000}
{"episode_reward": 879.7524319330245, "episode": 35.0, "batch_reward": 0.839951755464077, "critic_loss": 0.46084683790802955, "actor_loss": -88.78078747558594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.390060901641846, "step": 35000}
{"episode_reward": 880.9395121285235, "episode": 36.0, "batch_reward": 0.843968681037426, "critic_loss": 0.43743866303563117, "actor_loss": -88.69675364685058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.40137553215027, "step": 36000}
{"episode_reward": 972.1161757424604, "episode": 37.0, "batch_reward": 0.8477180479168892, "critic_loss": 0.4685678630173206, "actor_loss": -88.66836822509765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.42453908920288, "step": 37000}
{"episode_reward": 918.0538598652345, "episode": 38.0, "batch_reward": 0.8487299804091454, "critic_loss": 0.45738041077554226, "actor_loss": -89.05345755004883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.42130470275879, "step": 38000}
{"episode_reward": 927.341996934635, "episode": 39.0, "batch_reward": 0.8515328540802002, "critic_loss": 0.4315989990234375, "actor_loss": -88.92817086791992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.432921886444092, "step": 39000}
{"episode_reward": 955.3970414866199, "episode": 40.0, "batch_reward": 0.8525883548855782, "critic_loss": 0.4519784594029188, "actor_loss": -88.75711262512208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.43967843055725, "step": 40000}
{"episode_reward": 910.2005912419207, "episode": 41.0, "batch_reward": 0.8545009133815765, "critic_loss": 0.43441473224759103, "actor_loss": -88.71352684020997, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.92204761505127, "step": 41000}
{"episode_reward": 939.6314722680281, "episode": 42.0, "batch_reward": 0.8568454161882401, "critic_loss": 0.43722003771364687, "actor_loss": -88.91840641784668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.404964208602905, "step": 42000}
{"episode_reward": 978.967153316325, "episode": 43.0, "batch_reward": 0.8593534421920777, "critic_loss": 0.4515052656829357, "actor_loss": -88.89597459411621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.419949054718018, "step": 43000}
{"episode_reward": 892.6127883629463, "episode": 44.0, "batch_reward": 0.8602669519782067, "critic_loss": 0.43271821457147597, "actor_loss": -88.99812980651855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.390297889709473, "step": 44000}
{"episode_reward": 951.6656800717101, "episode": 45.0, "batch_reward": 0.8632494381070137, "critic_loss": 0.4050453241020441, "actor_loss": -89.26944300842285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.404748678207397, "step": 45000}
{"episode_reward": 967.5796170517704, "episode": 46.0, "batch_reward": 0.8661598958969117, "critic_loss": 0.40815932148694994, "actor_loss": -89.2854725189209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.408328533172607, "step": 46000}
{"episode_reward": 967.9279079736198, "episode": 47.0, "batch_reward": 0.8672559434771537, "critic_loss": 0.39205919982492926, "actor_loss": -89.0910553894043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.417915105819702, "step": 47000}
{"episode_reward": 950.6858414712965, "episode": 48.0, "batch_reward": 0.8681854684352874, "critic_loss": 0.43965320000052455, "actor_loss": -89.5110355682373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.392121076583862, "step": 48000}
{"episode_reward": 881.7821312791368, "episode": 49.0, "batch_reward": 0.8675658764243126, "critic_loss": 0.4477184950560331, "actor_loss": -89.3964047241211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.418099641799927, "step": 49000}
{"episode_reward": 867.8210008999425, "episode": 50.0, "batch_reward": 0.8680909866094589, "critic_loss": 0.41265097449719906, "actor_loss": -89.33810372924805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.375558137893677, "step": 50000}
{"episode_reward": 909.2255875151938, "episode": 51.0, "batch_reward": 0.871255252122879, "critic_loss": 0.3830945712029934, "actor_loss": -89.87096089172363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.9062774181366, "step": 51000}
{"episode_reward": 981.3475218832244, "episode": 52.0, "batch_reward": 0.8711978986263275, "critic_loss": 0.39828248795866966, "actor_loss": -89.39279736328125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.420020580291748, "step": 52000}
{"episode_reward": 940.6228049892795, "episode": 53.0, "batch_reward": 0.873093590438366, "critic_loss": 0.3944118503630161, "actor_loss": -89.87329139709473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.427144527435303, "step": 53000}
{"episode_reward": 904.7862514237615, "episode": 54.0, "batch_reward": 0.8746838413476944, "critic_loss": 0.37290608331561087, "actor_loss": -89.60003610229492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3854558467865, "step": 54000}
{"episode_reward": 948.945439255391, "episode": 55.0, "batch_reward": 0.8756214020252228, "critic_loss": 0.39492960734665394, "actor_loss": -89.6104622039795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.403364419937134, "step": 55000}
{"episode_reward": 957.5401014659001, "episode": 56.0, "batch_reward": 0.8782642094492912, "critic_loss": 0.38397886642813683, "actor_loss": -89.88228402709962, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.440208673477173, "step": 56000}
{"episode_reward": 985.3388917072076, "episode": 57.0, "batch_reward": 0.8787703666090966, "critic_loss": 0.390653028473258, "actor_loss": -89.79413180541992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.432310581207275, "step": 57000}
{"episode_reward": 946.1064040999314, "episode": 58.0, "batch_reward": 0.8802755448818207, "critic_loss": 0.3943625226318836, "actor_loss": -90.04293701171875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.40035390853882, "step": 58000}
{"episode_reward": 927.8604240825143, "episode": 59.0, "batch_reward": 0.8812746421694756, "critic_loss": 0.36430451910197736, "actor_loss": -90.00406776428223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.42917490005493, "step": 59000}
{"episode_reward": 967.1600671712466, "episode": 60.0, "batch_reward": 0.8825070104598999, "critic_loss": 0.39274257627129555, "actor_loss": -89.8502261352539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.440577507019043, "step": 60000}
{"episode_reward": 917.8131104823682, "episode": 61.0, "batch_reward": 0.8828313859701157, "critic_loss": 0.37564768972992896, "actor_loss": -89.99024858093262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.893638134002686, "step": 61000}
{"episode_reward": 933.6410854830335, "episode": 62.0, "batch_reward": 0.8845364409089088, "critic_loss": 0.3673470375388861, "actor_loss": -90.38559112548828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.432536125183105, "step": 62000}
{"episode_reward": 971.2277560452965, "episode": 63.0, "batch_reward": 0.8849441649317742, "critic_loss": 0.36288161343336106, "actor_loss": -90.45678584289551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.43448829650879, "step": 63000}
{"episode_reward": 975.2016047091599, "episode": 64.0, "batch_reward": 0.8863274055123329, "critic_loss": 0.36427528838813306, "actor_loss": -90.2970876159668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.408047199249268, "step": 64000}
{"episode_reward": 958.0295445519898, "episode": 65.0, "batch_reward": 0.8869708180427551, "critic_loss": 0.36787466548383235, "actor_loss": -90.40309211730957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.42184543609619, "step": 65000}
{"episode_reward": 949.8314573637687, "episode": 66.0, "batch_reward": 0.8881766568422318, "critic_loss": 0.3702915731817484, "actor_loss": -90.38344731140137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.441797733306885, "step": 66000}
{"episode_reward": 976.9463538388417, "episode": 67.0, "batch_reward": 0.8901763893961906, "critic_loss": 0.359004551962018, "actor_loss": -90.6071206817627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.413915634155273, "step": 67000}
{"episode_reward": 903.1245152254386, "episode": 68.0, "batch_reward": 0.8885776294469834, "critic_loss": 0.3802356813400984, "actor_loss": -90.49465977478027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.415302515029907, "step": 68000}
{"episode_reward": 910.6558344611897, "episode": 69.0, "batch_reward": 0.8906278977990151, "critic_loss": 0.34925323145091536, "actor_loss": -90.68184529113769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.438019514083862, "step": 69000}
{"episode_reward": 957.0709303937874, "episode": 70.0, "batch_reward": 0.8900553749203682, "critic_loss": 0.381218471929431, "actor_loss": -90.42202734375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.425923109054565, "step": 70000}
{"episode_reward": 857.3560402832917, "episode": 71.0, "batch_reward": 0.8902984725832939, "critic_loss": 0.37668246957659723, "actor_loss": -90.75656188964844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.93398475646973, "step": 71000}
{"episode_reward": 975.5246255977867, "episode": 72.0, "batch_reward": 0.8922498304843902, "critic_loss": 0.3672105887308717, "actor_loss": -90.67530587768555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.406555652618408, "step": 72000}
{"episode_reward": 951.441166330999, "episode": 73.0, "batch_reward": 0.892785159766674, "critic_loss": 0.34913293658196926, "actor_loss": -90.691724609375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.406017065048218, "step": 73000}
{"episode_reward": 977.9836218484213, "episode": 74.0, "batch_reward": 0.8941026563048363, "critic_loss": 0.3458313439935446, "actor_loss": -90.61009410095215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.420562744140625, "step": 74000}
{"episode_reward": 957.9102981712014, "episode": 75.0, "batch_reward": 0.8951224896907807, "critic_loss": 0.3548877317905426, "actor_loss": -90.70885670471192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.41240692138672, "step": 75000}
{"episode_reward": 955.5831460867093, "episode": 76.0, "batch_reward": 0.8942988427877426, "critic_loss": 0.37154359884560106, "actor_loss": -90.62009577941895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.429871320724487, "step": 76000}
{"episode_reward": 860.8472362497174, "episode": 77.0, "batch_reward": 0.8949952508807182, "critic_loss": 0.3656587854325771, "actor_loss": -91.09517729187012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.422301054000854, "step": 77000}
{"episode_reward": 975.1665551910071, "episode": 78.0, "batch_reward": 0.8952219777107239, "critic_loss": 0.37145122297108174, "actor_loss": -91.04904759216309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.414137601852417, "step": 78000}
{"episode_reward": 891.5517182736451, "episode": 79.0, "batch_reward": 0.8932568891644478, "critic_loss": 0.3910800604522228, "actor_loss": -91.08556401062012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.43325901031494, "step": 79000}
{"episode_reward": 684.9845652726075, "episode": 80.0, "batch_reward": 0.8941039040088653, "critic_loss": 0.40017029403150084, "actor_loss": -90.80366667175294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.410811185836792, "step": 80000}
{"episode_reward": 949.8301879433947, "episode": 81.0, "batch_reward": 0.8923885697722435, "critic_loss": 0.39875767296552656, "actor_loss": -90.92898988342286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.92525005340576, "step": 81000}
{"episode_reward": 902.3298712179634, "episode": 82.0, "batch_reward": 0.8941431229710579, "critic_loss": 0.39429034584760664, "actor_loss": -91.00261358642578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.43989062309265, "step": 82000}
{"episode_reward": 973.9555598253529, "episode": 83.0, "batch_reward": 0.8946347298622132, "critic_loss": 0.39296508561074733, "actor_loss": -90.87718635559082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.4135103225708, "step": 83000}
{"episode_reward": 933.7983965420326, "episode": 84.0, "batch_reward": 0.8956536511182785, "critic_loss": 0.38001989369094374, "actor_loss": -90.92602053833008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.429813385009766, "step": 84000}
{"episode_reward": 943.5334611870118, "episode": 85.0, "batch_reward": 0.8955926982760429, "critic_loss": 0.3708034196048975, "actor_loss": -91.25393725585937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.424394607543945, "step": 85000}
{"episode_reward": 941.5857992978337, "episode": 86.0, "batch_reward": 0.8976268756985665, "critic_loss": 0.38867034076154233, "actor_loss": -90.9556192779541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.41356325149536, "step": 86000}
{"episode_reward": 946.3216264872178, "episode": 87.0, "batch_reward": 0.8975847756266594, "critic_loss": 0.3990887730121613, "actor_loss": -91.04270545959473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.42327380180359, "step": 87000}
{"episode_reward": 956.2607843653283, "episode": 88.0, "batch_reward": 0.897541771888733, "critic_loss": 0.37787123061716554, "actor_loss": -91.07260116577149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.429064989089966, "step": 88000}
{"episode_reward": 983.1942024761332, "episode": 89.0, "batch_reward": 0.8995418306589127, "critic_loss": 0.3880883888602257, "actor_loss": -91.2384129486084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.4071683883667, "step": 89000}
{"episode_reward": 972.1019436270378, "episode": 90.0, "batch_reward": 0.9003597954511643, "critic_loss": 0.3750010466724634, "actor_loss": -91.4455092010498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.435890674591064, "step": 90000}
{"episode_reward": 978.9494127222048, "episode": 91.0, "batch_reward": 0.9001045945286751, "critic_loss": 0.3740856072306633, "actor_loss": -91.4321215057373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.87998366355896, "step": 91000}
{"episode_reward": 931.5846690295107, "episode": 92.0, "batch_reward": 0.9013412528634072, "critic_loss": 0.3643640346229076, "actor_loss": -91.30111515808106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.422977447509766, "step": 92000}
{"episode_reward": 943.493278217002, "episode": 93.0, "batch_reward": 0.9028731076717377, "critic_loss": 0.37958474792540076, "actor_loss": -91.39493733215332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.427494764328003, "step": 93000}
{"episode_reward": 975.4316033938127, "episode": 94.0, "batch_reward": 0.9028121366500854, "critic_loss": 0.36080025912076236, "actor_loss": -91.41484210205078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.430283784866333, "step": 94000}
{"episode_reward": 955.5896822031381, "episode": 95.0, "batch_reward": 0.9023661032915116, "critic_loss": 0.36402666439116, "actor_loss": -91.84676428222656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.397462606430054, "step": 95000}
{"episode_reward": 860.5040071667455, "episode": 96.0, "batch_reward": 0.9014082433581352, "critic_loss": 0.36349963238090277, "actor_loss": -91.02030516052245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.40245032310486, "step": 96000}
{"episode_reward": 956.1712122323676, "episode": 97.0, "batch_reward": 0.901826974093914, "critic_loss": 0.36352976110577584, "actor_loss": -91.32461532592774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.41008734703064, "step": 97000}
{"episode_reward": 918.293449232362, "episode": 98.0, "batch_reward": 0.9030747631788254, "critic_loss": 0.35840243950486184, "actor_loss": -91.75508157348632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.385671854019165, "step": 98000}
{"episode_reward": 956.836990832536, "episode": 99.0, "batch_reward": 0.9038540833592414, "critic_loss": 0.363903328448534, "actor_loss": -91.12470202636719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.417876720428467, "step": 99000}
{"episode_reward": 954.644838846766, "episode": 100.0, "batch_reward": 0.9033852136135101, "critic_loss": 0.3622233104258776, "actor_loss": -91.36450047302246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.432249069213867, "step": 100000}
{"episode_reward": 977.4142781845248, "episode": 101.0, "batch_reward": 0.9055368150472641, "critic_loss": 0.3572788899093866, "actor_loss": -91.23255717468261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.93665909767151, "step": 101000}
{"episode_reward": 975.3177483844748, "episode": 102.0, "batch_reward": 0.9061940379738808, "critic_loss": 0.3679195257201791, "actor_loss": -91.37872825622559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.458548307418823, "step": 102000}
{"episode_reward": 970.7359184597229, "episode": 103.0, "batch_reward": 0.9065710324048996, "critic_loss": 0.3591007198244333, "actor_loss": -91.48332731628417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.429373025894165, "step": 103000}
{"episode_reward": 877.5715518183981, "episode": 104.0, "batch_reward": 0.9049014446735382, "critic_loss": 0.3457627762183547, "actor_loss": -91.35309460449218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.448025941848755, "step": 104000}
{"episode_reward": 956.9697017616295, "episode": 105.0, "batch_reward": 0.9068021291494369, "critic_loss": 0.3478998660072684, "actor_loss": -91.42184466552735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.43336319923401, "step": 105000}
{"episode_reward": 979.8044556586309, "episode": 106.0, "batch_reward": 0.9067092945575714, "critic_loss": 0.3608975256755948, "actor_loss": -91.21267524719238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.426719665527344, "step": 106000}
{"episode_reward": 940.0824537432267, "episode": 107.0, "batch_reward": 0.9066260283589364, "critic_loss": 0.37615065820515153, "actor_loss": -91.21197731018066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.42319369316101, "step": 107000}
{"episode_reward": 917.0318334518108, "episode": 108.0, "batch_reward": 0.9075512455105782, "critic_loss": 0.36708862021565436, "actor_loss": -91.72209812927247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.431600332260132, "step": 108000}
{"episode_reward": 954.7867158095252, "episode": 109.0, "batch_reward": 0.9072836649417877, "critic_loss": 0.37145120491832495, "actor_loss": -91.38151550292969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.432598114013672, "step": 109000}
{"episode_reward": 968.8247350307129, "episode": 110.0, "batch_reward": 0.908541092634201, "critic_loss": 0.3563516232073307, "actor_loss": -91.34333544921876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.419233083724976, "step": 110000}
{"episode_reward": 945.5270203548612, "episode": 111.0, "batch_reward": 0.909160949409008, "critic_loss": 0.3521262587234378, "actor_loss": -91.84153038024903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.9031138420105, "step": 111000}
{"episode_reward": 954.5868990275517, "episode": 112.0, "batch_reward": 0.9093414559960366, "critic_loss": 0.3574462348371744, "actor_loss": -91.24416072082519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.443471670150757, "step": 112000}
{"episode_reward": 956.4037750004907, "episode": 113.0, "batch_reward": 0.9098028213381767, "critic_loss": 0.35294280564785, "actor_loss": -91.49456159973144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.432311058044434, "step": 113000}
{"episode_reward": 968.6751803221523, "episode": 114.0, "batch_reward": 0.9098125692009926, "critic_loss": 0.3572258280217648, "actor_loss": -91.47652809143067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.428025722503662, "step": 114000}
{"episode_reward": 978.0509027113753, "episode": 115.0, "batch_reward": 0.9104865267276764, "critic_loss": 0.37086763118207455, "actor_loss": -91.6433586883545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.392966508865356, "step": 115000}
{"episode_reward": 928.2250233476101, "episode": 116.0, "batch_reward": 0.9122516198158264, "critic_loss": 0.34020803529024124, "actor_loss": -91.8562225341797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.400347232818604, "step": 116000}
{"episode_reward": 954.6589892697459, "episode": 117.0, "batch_reward": 0.9109867119789123, "critic_loss": 0.35739333510398863, "actor_loss": -92.05189154052735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.42646098136902, "step": 117000}
{"episode_reward": 937.5023826134071, "episode": 118.0, "batch_reward": 0.9100285766720771, "critic_loss": 0.3599496571272612, "actor_loss": -91.84880212402344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.415565013885498, "step": 118000}
{"episode_reward": 950.8642376110876, "episode": 119.0, "batch_reward": 0.9126278855204583, "critic_loss": 0.34694848804175854, "actor_loss": -91.87756739807129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.432416915893555, "step": 119000}
{"episode_reward": 972.7610286853243, "episode": 120.0, "batch_reward": 0.9122465176582336, "critic_loss": 0.34940049820393326, "actor_loss": -92.15346626281739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.4173002243042, "step": 120000}
{"episode_reward": 946.8507089926753, "episode": 121.0, "batch_reward": 0.913693234026432, "critic_loss": 0.3461105098351836, "actor_loss": -91.77599154663086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.12896418571472, "step": 121000}
{"episode_reward": 953.108909423288, "episode": 122.0, "batch_reward": 0.9124613199234008, "critic_loss": 0.3492057901844382, "actor_loss": -91.84699272155761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.57107138633728, "step": 122000}
{"episode_reward": 954.1649725908377, "episode": 123.0, "batch_reward": 0.9128592157363892, "critic_loss": 0.340489025592804, "actor_loss": -91.77825302124023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.71330165863037, "step": 123000}
{"episode_reward": 972.5163789234698, "episode": 124.0, "batch_reward": 0.9146892958283425, "critic_loss": 0.35007083433121444, "actor_loss": -91.71899528503418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.394487619400024, "step": 124000}
{"episode_reward": 956.3032628179495, "episode": 125.0, "batch_reward": 0.9154612387418747, "critic_loss": 0.34010181432217357, "actor_loss": -91.95221492004394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.347103357315063, "step": 125000}
{"episode_reward": 979.1633222157858, "episode": 126.0, "batch_reward": 0.9151792045235634, "critic_loss": 0.33021808762848376, "actor_loss": -92.08128692626953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.393038988113403, "step": 126000}
{"episode_reward": 962.7168107064621, "episode": 127.0, "batch_reward": 0.9148658155798912, "critic_loss": 0.3504903705045581, "actor_loss": -91.69091886901856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.422683477401733, "step": 127000}
{"episode_reward": 972.8245791032858, "episode": 128.0, "batch_reward": 0.915781004011631, "critic_loss": 0.3599957465529442, "actor_loss": -91.70822509765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.436882495880127, "step": 128000}
{"episode_reward": 970.2674365175135, "episode": 129.0, "batch_reward": 0.9149987052083015, "critic_loss": 0.3529702906087041, "actor_loss": -91.88962336730957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.43515634536743, "step": 129000}
{"episode_reward": 951.6591533266768, "episode": 130.0, "batch_reward": 0.9168743957877159, "critic_loss": 0.35213489124178887, "actor_loss": -91.9879342956543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.43002986907959, "step": 130000}
{"episode_reward": 958.2831055108131, "episode": 131.0, "batch_reward": 0.91631318962574, "critic_loss": 0.3826676526814699, "actor_loss": -92.09484844970703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.92874884605408, "step": 131000}
{"episode_reward": 933.9337766459342, "episode": 132.0, "batch_reward": 0.9167775852680207, "critic_loss": 0.3709141234382987, "actor_loss": -91.98593295288086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.436964750289917, "step": 132000}
{"episode_reward": 920.7557950998686, "episode": 133.0, "batch_reward": 0.9165549126863479, "critic_loss": 0.37649223729223014, "actor_loss": -92.3684097290039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.438560962677002, "step": 133000}
{"episode_reward": 979.9879640133363, "episode": 134.0, "batch_reward": 0.9175945729017257, "critic_loss": 0.3743982692286372, "actor_loss": -92.28363548278809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.413662910461426, "step": 134000}
{"episode_reward": 933.2315576244455, "episode": 135.0, "batch_reward": 0.9170827880501747, "critic_loss": 0.36970394423604014, "actor_loss": -91.90702444458007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.40078115463257, "step": 135000}
{"episode_reward": 937.6744933393967, "episode": 136.0, "batch_reward": 0.9179182380437851, "critic_loss": 0.3420811435803771, "actor_loss": -92.50920275878906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.410373210906982, "step": 136000}
{"episode_reward": 961.9800822614083, "episode": 137.0, "batch_reward": 0.916517703473568, "critic_loss": 0.33764280201494695, "actor_loss": -92.05291325378418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.438363552093506, "step": 137000}
{"episode_reward": 944.0065413466828, "episode": 138.0, "batch_reward": 0.9193703730106354, "critic_loss": 0.33147248325496914, "actor_loss": -91.9705163269043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.44867444038391, "step": 138000}
{"episode_reward": 977.2897191381024, "episode": 139.0, "batch_reward": 0.9182840512990952, "critic_loss": 0.3526632879450917, "actor_loss": -92.34038316345215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.41512155532837, "step": 139000}
{"episode_reward": 943.7900456625173, "episode": 140.0, "batch_reward": 0.9193980633616448, "critic_loss": 0.3361406594589353, "actor_loss": -92.18025137329101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.42083740234375, "step": 140000}
{"episode_reward": 973.9417040819378, "episode": 141.0, "batch_reward": 0.917629859149456, "critic_loss": 0.33675773527473213, "actor_loss": -91.95506761169433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.93460536003113, "step": 141000}
{"episode_reward": 962.0310853427368, "episode": 142.0, "batch_reward": 0.9180911628603935, "critic_loss": 0.3259805431440473, "actor_loss": -92.33122760009766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.438958644866943, "step": 142000}
{"episode_reward": 951.7137071331696, "episode": 143.0, "batch_reward": 0.91912636500597, "critic_loss": 0.31267837242037055, "actor_loss": -92.4711349029541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.408976078033447, "step": 143000}
{"episode_reward": 960.4513011281897, "episode": 144.0, "batch_reward": 0.9201921426057815, "critic_loss": 0.3178336610272527, "actor_loss": -92.29635987854004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.420508861541748, "step": 144000}
{"episode_reward": 903.922343147966, "episode": 145.0, "batch_reward": 0.9199137807488441, "critic_loss": 0.32515432929992677, "actor_loss": -92.16335316467286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.420344829559326, "step": 145000}
{"episode_reward": 850.6104245782781, "episode": 146.0, "batch_reward": 0.920063540995121, "critic_loss": 0.34355067992955446, "actor_loss": -92.03372978210449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.428607940673828, "step": 146000}
{"episode_reward": 979.0222171387356, "episode": 147.0, "batch_reward": 0.9197207957506179, "critic_loss": 0.3413166948929429, "actor_loss": -92.28752436828613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.402170419692993, "step": 147000}
{"episode_reward": 945.3909909158303, "episode": 148.0, "batch_reward": 0.9196253696680069, "critic_loss": 0.34441266536712645, "actor_loss": -92.21778805541992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.443347454071045, "step": 148000}
{"episode_reward": 948.3552151075746, "episode": 149.0, "batch_reward": 0.9196335452795029, "critic_loss": 0.3575844989269972, "actor_loss": -92.32428858947753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.419466257095337, "step": 149000}
{"episode_reward": 936.8761266393518, "episode": 150.0, "batch_reward": 0.9194554978013039, "critic_loss": 0.3613984982073307, "actor_loss": -92.27119921875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
