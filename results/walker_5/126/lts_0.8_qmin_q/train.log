{"episode_reward": 0.0, "episode": 1.0, "duration": 21.474329710006714, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.8106582164764404, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.3052452925236156, "critic_loss": 0.9504792245378809, "actor_loss": -68.91584962537262, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 65.94420194625854, "step": 3000}
{"episode_reward": 714.2861732284908, "episode": 4.0, "batch_reward": 0.4584374389350414, "critic_loss": 1.2653283249735832, "actor_loss": -72.78661428833007, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.166310787200928, "step": 4000}
{"episode_reward": 609.2903129074462, "episode": 5.0, "batch_reward": 0.4936161261498928, "critic_loss": 1.3243595141768456, "actor_loss": -73.4055011138916, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.069140195846558, "step": 5000}
{"episode_reward": 671.3525456794068, "episode": 6.0, "batch_reward": 0.5197756637632847, "critic_loss": 1.3103856026530265, "actor_loss": -74.1886654510498, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.304254293441772, "step": 6000}
{"episode_reward": 688.4076986344576, "episode": 7.0, "batch_reward": 0.5396061923503875, "critic_loss": 1.225991455078125, "actor_loss": -74.72667776489257, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.710737705230713, "step": 7000}
{"episode_reward": 571.675040546576, "episode": 8.0, "batch_reward": 0.531693332284689, "critic_loss": 1.3019324656128883, "actor_loss": -74.85773670959473, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.580652952194214, "step": 8000}
{"episode_reward": 417.4854143290141, "episode": 9.0, "batch_reward": 0.5350265816152096, "critic_loss": 1.5412514337301255, "actor_loss": -74.66818275451661, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.64386773109436, "step": 9000}
{"episode_reward": 516.7864862076106, "episode": 10.0, "batch_reward": 0.5416690973639489, "critic_loss": 1.7404217933416366, "actor_loss": -74.8841756286621, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.264252185821533, "step": 10000}
{"episode_reward": 743.8489293190933, "episode": 11.0, "batch_reward": 0.5659612562656403, "critic_loss": 1.846112911105156, "actor_loss": -75.26370446777344, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 46.66328549385071, "step": 11000}
{"episode_reward": 874.3795281578745, "episode": 12.0, "batch_reward": 0.5884528432786464, "critic_loss": 1.9632642166614533, "actor_loss": -75.914318359375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.397417068481445, "step": 12000}
{"episode_reward": 814.952422851579, "episode": 13.0, "batch_reward": 0.6034230504631997, "critic_loss": 2.1803938759565353, "actor_loss": -76.21340655517578, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.5214741230011, "step": 13000}
{"episode_reward": 778.4393958899598, "episode": 14.0, "batch_reward": 0.6194089308381081, "critic_loss": 2.317939701080322, "actor_loss": -76.6987622680664, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.75274133682251, "step": 14000}
{"episode_reward": 831.2994196552015, "episode": 15.0, "batch_reward": 0.6356603428721428, "critic_loss": 2.8815001003742218, "actor_loss": -76.40788567352296, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.340786933898926, "step": 15000}
{"episode_reward": 887.4828945211843, "episode": 16.0, "batch_reward": 0.6463786877989769, "critic_loss": 6.3817240438461305, "actor_loss": -77.46439163208008, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.136295795440674, "step": 16000}
{"episode_reward": 729.4591816239133, "episode": 17.0, "batch_reward": 0.6514973724484444, "critic_loss": 7.890920295953751, "actor_loss": -77.43557162475587, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.77959632873535, "step": 17000}
{"episode_reward": 736.1568961797633, "episode": 18.0, "batch_reward": 0.6593650095462799, "critic_loss": 5.6927511992454525, "actor_loss": -77.80552197265625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.174182891845703, "step": 18000}
{"episode_reward": 753.701210411872, "episode": 19.0, "batch_reward": 0.6638086500763893, "critic_loss": 4.492994727373123, "actor_loss": -78.38341163635253, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.478781700134277, "step": 19000}
{"episode_reward": 839.5438722668346, "episode": 20.0, "batch_reward": 0.6727935463190079, "critic_loss": 4.578290308952331, "actor_loss": -78.47304197692871, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.794074535369873, "step": 20000}
{"episode_reward": 777.1693606933385, "episode": 21.0, "batch_reward": 0.6800233621001244, "critic_loss": 4.256623905658722, "actor_loss": -79.1818459777832, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.36664628982544, "step": 21000}
{"episode_reward": 869.3608043798722, "episode": 22.0, "batch_reward": 0.6854262409210206, "critic_loss": 4.6777728962898255, "actor_loss": -79.44926283264161, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.975791931152344, "step": 22000}
{"episode_reward": 752.0206145350157, "episode": 23.0, "batch_reward": 0.6893977069854736, "critic_loss": 4.694251494169235, "actor_loss": -79.95442222595214, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.493853330612183, "step": 23000}
{"episode_reward": 839.3364034162072, "episode": 24.0, "batch_reward": 0.6960361399650574, "critic_loss": 4.898331914663315, "actor_loss": -80.16161082458495, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.12943959236145, "step": 24000}
{"episode_reward": 853.6387308260989, "episode": 25.0, "batch_reward": 0.7056042036414146, "critic_loss": 5.158246493339538, "actor_loss": -80.66162979125977, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.589324235916138, "step": 25000}
{"episode_reward": 911.3187833163498, "episode": 26.0, "batch_reward": 0.7112667328715324, "critic_loss": 5.292721402406692, "actor_loss": -80.5851748046875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.104780912399292, "step": 26000}
{"episode_reward": 866.7331041051303, "episode": 27.0, "batch_reward": 0.7147960650324822, "critic_loss": 5.233151253700257, "actor_loss": -80.67567652893067, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.536724090576172, "step": 27000}
{"episode_reward": 755.8885169586183, "episode": 28.0, "batch_reward": 0.7202392751574517, "critic_loss": 4.900061474561691, "actor_loss": -80.92135043334962, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.703166246414185, "step": 28000}
{"episode_reward": 900.0167826085279, "episode": 29.0, "batch_reward": 0.7275153582692147, "critic_loss": 4.443559179782867, "actor_loss": -80.80378945922851, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.59396195411682, "step": 29000}
{"episode_reward": 946.1463279780845, "episode": 30.0, "batch_reward": 0.7325877995491028, "critic_loss": 3.9669642083644865, "actor_loss": -80.96362301635742, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.798535346984863, "step": 30000}
{"episode_reward": 870.5600791665291, "episode": 31.0, "batch_reward": 0.7347978129386902, "critic_loss": 3.564501746416092, "actor_loss": -81.31141946411132, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 45.225417375564575, "step": 31000}
{"episode_reward": 800.0338321029714, "episode": 32.0, "batch_reward": 0.7389169991016388, "critic_loss": 3.1039441475868226, "actor_loss": -81.34503080749512, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.540552616119385, "step": 32000}
{"episode_reward": 865.2392324962074, "episode": 33.0, "batch_reward": 0.7431122657656669, "critic_loss": 2.7653109827041624, "actor_loss": -81.38375134277344, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.80268621444702, "step": 33000}
{"episode_reward": 832.9668930450514, "episode": 34.0, "batch_reward": 0.7440789974331856, "critic_loss": 2.6318134586811066, "actor_loss": -81.46196766662598, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.562543153762817, "step": 34000}
{"episode_reward": 767.01985246789, "episode": 35.0, "batch_reward": 0.7464936876296997, "critic_loss": 2.4447333948612213, "actor_loss": -81.26982699584961, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.920677423477173, "step": 35000}
{"episode_reward": 872.7304598999037, "episode": 36.0, "batch_reward": 0.7475844147205353, "critic_loss": 2.384129954814911, "actor_loss": -81.73828456115723, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.096176862716675, "step": 36000}
{"episode_reward": 730.2069961593888, "episode": 37.0, "batch_reward": 0.7496281758546829, "critic_loss": 2.3551589477062227, "actor_loss": -81.55249394226074, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.48912763595581, "step": 37000}
{"episode_reward": 793.1905159122128, "episode": 38.0, "batch_reward": 0.7531635875105858, "critic_loss": 2.412920878648758, "actor_loss": -81.27319606018067, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.60617971420288, "step": 38000}
{"episode_reward": 872.2516833372183, "episode": 39.0, "batch_reward": 0.7549647024273872, "critic_loss": 2.3190736047029494, "actor_loss": -81.62379794311524, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.912880182266235, "step": 39000}
{"episode_reward": 853.2019036191392, "episode": 40.0, "batch_reward": 0.7558227542042733, "critic_loss": 2.3323781696558, "actor_loss": -81.57524406433106, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.07645535469055, "step": 40000}
{"episode_reward": 804.6944285360046, "episode": 41.0, "batch_reward": 0.7571268782615662, "critic_loss": 2.328677136659622, "actor_loss": -81.78783412170411, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.705992221832275, "step": 41000}
{"episode_reward": 802.3614556697582, "episode": 42.0, "batch_reward": 0.7573932755589485, "critic_loss": 2.31622273850441, "actor_loss": -81.16077178955078, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.15016746520996, "step": 42000}
{"episode_reward": 813.6876954056895, "episode": 43.0, "batch_reward": 0.7589102392196655, "critic_loss": 2.23319814401865, "actor_loss": -81.54873899841309, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.23604440689087, "step": 43000}
{"episode_reward": 821.9511104252398, "episode": 44.0, "batch_reward": 0.761354492843151, "critic_loss": 2.0792343948483465, "actor_loss": -81.54472470092773, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.590989112854004, "step": 44000}
{"episode_reward": 855.7348197194657, "episode": 45.0, "batch_reward": 0.7636740896105766, "critic_loss": 2.0756698437333108, "actor_loss": -81.45254827880859, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.970168113708496, "step": 45000}
{"episode_reward": 850.7790329002896, "episode": 46.0, "batch_reward": 0.7663545870184898, "critic_loss": 1.9791935746669769, "actor_loss": -81.49538514709472, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.943814754486084, "step": 46000}
{"episode_reward": 874.8151423101704, "episode": 47.0, "batch_reward": 0.7674454903006553, "critic_loss": 1.8856632531285287, "actor_loss": -81.68387194824219, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.271846294403076, "step": 47000}
{"episode_reward": 877.7055550919895, "episode": 48.0, "batch_reward": 0.7682510370612144, "critic_loss": 1.9799087803959847, "actor_loss": -81.61707933044434, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.073590993881226, "step": 48000}
{"episode_reward": 695.4023846808767, "episode": 49.0, "batch_reward": 0.7679689346551896, "critic_loss": 2.060733371555805, "actor_loss": -81.67476538085937, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.43127703666687, "step": 49000}
{"episode_reward": 738.1630071060575, "episode": 50.0, "batch_reward": 0.76722169059515, "critic_loss": 1.9622648865580559, "actor_loss": -81.26598127746583, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.531092882156372, "step": 50000}
{"episode_reward": 792.3535097867077, "episode": 51.0, "batch_reward": 0.7704117680191994, "critic_loss": 1.871963922560215, "actor_loss": -81.4113324432373, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 44.218130588531494, "step": 51000}
{"episode_reward": 888.8321758348379, "episode": 52.0, "batch_reward": 0.7697367505431175, "critic_loss": 1.847178464114666, "actor_loss": -81.65225862121582, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.447989225387573, "step": 52000}
{"episode_reward": 828.5286179958499, "episode": 53.0, "batch_reward": 0.7724537280797958, "critic_loss": 1.7966290415525437, "actor_loss": -81.10159698486328, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.54556965827942, "step": 53000}
{"episode_reward": 825.2420154301102, "episode": 54.0, "batch_reward": 0.7725448015332222, "critic_loss": 1.7571295782327652, "actor_loss": -81.88665348815918, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.930338382720947, "step": 54000}
{"episode_reward": 829.9065972043725, "episode": 55.0, "batch_reward": 0.7744485455751419, "critic_loss": 1.7580986896157265, "actor_loss": -81.66863066101074, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.6584734916687, "step": 55000}
{"episode_reward": 902.2454504086073, "episode": 56.0, "batch_reward": 0.7776340157985687, "critic_loss": 1.7313143432736398, "actor_loss": -81.19988520812988, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.33021306991577, "step": 56000}
{"episode_reward": 879.8763662124392, "episode": 57.0, "batch_reward": 0.7782317304611206, "critic_loss": 1.6429024191498756, "actor_loss": -81.82701712036133, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.443422317504883, "step": 57000}
{"episode_reward": 874.2501171792253, "episode": 58.0, "batch_reward": 0.7779271128773689, "critic_loss": 1.6966358612775803, "actor_loss": -81.49907229614257, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.873079299926758, "step": 58000}
{"episode_reward": 760.4055026649802, "episode": 59.0, "batch_reward": 0.7807702122330665, "critic_loss": 1.6291495963335036, "actor_loss": -81.60273538208008, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.131407499313354, "step": 59000}
{"episode_reward": 907.0572739065345, "episode": 60.0, "batch_reward": 0.7829778659939766, "critic_loss": 1.6092808845639228, "actor_loss": -81.68499278259277, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.631133317947388, "step": 60000}
{"episode_reward": 855.5059493515716, "episode": 61.0, "batch_reward": 0.7835250313282013, "critic_loss": 1.59214579308033, "actor_loss": -81.92758357238769, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.700363636016846, "step": 61000}
{"episode_reward": 843.179894317222, "episode": 62.0, "batch_reward": 0.7845271244049072, "critic_loss": 1.5601683648824691, "actor_loss": -81.53155125427246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.6543447971344, "step": 62000}
{"episode_reward": 905.355364687591, "episode": 63.0, "batch_reward": 0.7861053687334061, "critic_loss": 1.5808229803442955, "actor_loss": -81.83347198486328, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.713313341140747, "step": 63000}
{"episode_reward": 906.8933142386776, "episode": 64.0, "batch_reward": 0.7873551068902016, "critic_loss": 1.548641180038452, "actor_loss": -81.90892088317871, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.374199390411377, "step": 64000}
{"episode_reward": 874.4383449039734, "episode": 65.0, "batch_reward": 0.7889066721796989, "critic_loss": 1.5437327346801757, "actor_loss": -81.78284100341797, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.783838033676147, "step": 65000}
{"episode_reward": 869.0797930621185, "episode": 66.0, "batch_reward": 0.7894770573973656, "critic_loss": 1.4438121054172517, "actor_loss": -81.92603788757324, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.532126903533936, "step": 66000}
{"episode_reward": 873.5804944568117, "episode": 67.0, "batch_reward": 0.7922323216199875, "critic_loss": 1.4327365929484368, "actor_loss": -81.80224844360352, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.300840377807617, "step": 67000}
{"episode_reward": 881.0126241867551, "episode": 68.0, "batch_reward": 0.7923879889249802, "critic_loss": 1.3800048929452897, "actor_loss": -82.21229153442383, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.29363489151001, "step": 68000}
{"episode_reward": 886.0124399600421, "episode": 69.0, "batch_reward": 0.7940070088505745, "critic_loss": 1.3857951177358627, "actor_loss": -82.29355099487304, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.71544122695923, "step": 69000}
{"episode_reward": 884.2500042301194, "episode": 70.0, "batch_reward": 0.7954246276021004, "critic_loss": 1.3726341062784195, "actor_loss": -82.35091102600097, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.630494117736816, "step": 70000}
{"episode_reward": 832.2265248614614, "episode": 71.0, "batch_reward": 0.7963519054055214, "critic_loss": 1.3671314154863357, "actor_loss": -82.07464527893066, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.90217900276184, "step": 71000}
{"episode_reward": 889.7254443860295, "episode": 72.0, "batch_reward": 0.7985253787636757, "critic_loss": 1.391404823601246, "actor_loss": -82.56642192077636, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.43062710762024, "step": 72000}
{"episode_reward": 791.8887756082904, "episode": 73.0, "batch_reward": 0.7977752676010131, "critic_loss": 1.434988171517849, "actor_loss": -82.40643504333497, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.282837629318237, "step": 73000}
{"episode_reward": 812.3951679528399, "episode": 74.0, "batch_reward": 0.7973175966143609, "critic_loss": 1.4868019475936889, "actor_loss": -82.27600973510742, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.785929441452026, "step": 74000}
{"episode_reward": 865.3913022489028, "episode": 75.0, "batch_reward": 0.7998285992741585, "critic_loss": 1.4854236934185028, "actor_loss": -82.6483059387207, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.71441626548767, "step": 75000}
{"episode_reward": 877.7646032794252, "episode": 76.0, "batch_reward": 0.7998716898560524, "critic_loss": 1.4426944718956947, "actor_loss": -82.49862774658203, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.45323896408081, "step": 76000}
{"episode_reward": 847.5552042849147, "episode": 77.0, "batch_reward": 0.8007866688370705, "critic_loss": 1.414860622882843, "actor_loss": -82.46234362792968, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.587185382843018, "step": 77000}
{"episode_reward": 881.1028271086926, "episode": 78.0, "batch_reward": 0.8002641482949256, "critic_loss": 1.462706874191761, "actor_loss": -82.27197296142577, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.795143604278564, "step": 78000}
{"episode_reward": 834.1980122610299, "episode": 79.0, "batch_reward": 0.801726979136467, "critic_loss": 1.3759267772436141, "actor_loss": -82.60216242980957, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.885388612747192, "step": 79000}
{"episode_reward": 864.5297022445216, "episode": 80.0, "batch_reward": 0.8032505806088448, "critic_loss": 1.4102301974892617, "actor_loss": -82.72321647644043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.38441777229309, "step": 80000}
{"episode_reward": 887.950502866477, "episode": 81.0, "batch_reward": 0.802054709494114, "critic_loss": 1.5461483404040337, "actor_loss": -82.6553233795166, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.225414752960205, "step": 81000}
{"episode_reward": 801.1652929452359, "episode": 82.0, "batch_reward": 0.803144315123558, "critic_loss": 1.359783116698265, "actor_loss": -82.58783386230469, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.41992998123169, "step": 82000}
{"episode_reward": 897.9454417656681, "episode": 83.0, "batch_reward": 0.8042812097668648, "critic_loss": 1.3835276274085044, "actor_loss": -82.71403694152832, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.31042790412903, "step": 83000}
{"episode_reward": 877.8897633327277, "episode": 84.0, "batch_reward": 0.80527517837286, "critic_loss": 1.4389199334979057, "actor_loss": -83.07543920898438, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.291764974594116, "step": 84000}
{"episode_reward": 842.4226512181085, "episode": 85.0, "batch_reward": 0.8050534225702286, "critic_loss": 1.3704246173501016, "actor_loss": -82.79611268615723, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.891419410705566, "step": 85000}
{"episode_reward": 859.651074407764, "episode": 86.0, "batch_reward": 0.8054861981272697, "critic_loss": 1.3707310080528259, "actor_loss": -82.99063829040527, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.755661249160767, "step": 86000}
{"episode_reward": 883.3686586009032, "episode": 87.0, "batch_reward": 0.8074753462672234, "critic_loss": 1.3721029133796692, "actor_loss": -83.08586401367188, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.601505756378174, "step": 87000}
{"episode_reward": 807.7432914929694, "episode": 88.0, "batch_reward": 0.807302232325077, "critic_loss": 1.3376811457276345, "actor_loss": -83.12295564270019, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.329806566238403, "step": 88000}
{"episode_reward": 886.1197379370012, "episode": 89.0, "batch_reward": 0.8084030161499978, "critic_loss": 1.3436550027430056, "actor_loss": -82.96521105957031, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.395942211151123, "step": 89000}
{"episode_reward": 896.2024841175071, "episode": 90.0, "batch_reward": 0.8099638417959213, "critic_loss": 1.3455464913845063, "actor_loss": -82.99447116088866, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.670618772506714, "step": 90000}
{"episode_reward": 905.7371719904351, "episode": 91.0, "batch_reward": 0.8097316328287124, "critic_loss": 1.3539438453316688, "actor_loss": -82.86313011169433, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.602970361709595, "step": 91000}
{"episode_reward": 851.2699549885499, "episode": 92.0, "batch_reward": 0.8118425799608231, "critic_loss": 1.340197339117527, "actor_loss": -83.05728857421875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.622060298919678, "step": 92000}
{"episode_reward": 898.8447408662387, "episode": 93.0, "batch_reward": 0.8128761816620826, "critic_loss": 1.2830595160722733, "actor_loss": -83.34424978637695, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.755234479904175, "step": 93000}
{"episode_reward": 898.6247684292483, "episode": 94.0, "batch_reward": 0.8123942987322808, "critic_loss": 1.2516946176886559, "actor_loss": -83.38758041381836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.98019576072693, "step": 94000}
{"episode_reward": 838.0263708769878, "episode": 95.0, "batch_reward": 0.812807999908924, "critic_loss": 1.350862436592579, "actor_loss": -83.34784898376465, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.456761360168457, "step": 95000}
{"episode_reward": 825.2132766277774, "episode": 96.0, "batch_reward": 0.8118736003041267, "critic_loss": 1.4764737195968627, "actor_loss": -83.11852098083496, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.87567925453186, "step": 96000}
{"episode_reward": 759.9564518098434, "episode": 97.0, "batch_reward": 0.8105984449386596, "critic_loss": 1.45643118840456, "actor_loss": -83.24817124938964, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.373982191085815, "step": 97000}
{"episode_reward": 816.7478131636976, "episode": 98.0, "batch_reward": 0.8119827665090561, "critic_loss": 1.4872963940501214, "actor_loss": -83.3435989227295, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.002206325531006, "step": 98000}
{"episode_reward": 874.3297077890484, "episode": 99.0, "batch_reward": 0.8126052623987198, "critic_loss": 1.4961213186383246, "actor_loss": -83.2713224029541, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.83683729171753, "step": 99000}
{"episode_reward": 853.9786583831403, "episode": 100.0, "batch_reward": 0.8127288057804107, "critic_loss": 1.4923968715071678, "actor_loss": -83.51605360412597, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.535948753356934, "step": 100000}
{"episode_reward": 903.0730753107176, "episode": 101.0, "batch_reward": 0.8145042700767517, "critic_loss": 1.4877320347428322, "actor_loss": -83.43063436889648, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.95747637748718, "step": 101000}
{"episode_reward": 887.0524646290189, "episode": 102.0, "batch_reward": 0.8161103209257126, "critic_loss": 1.4865050495266914, "actor_loss": -83.65602868652344, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.706071376800537, "step": 102000}
{"episode_reward": 875.1146713485355, "episode": 103.0, "batch_reward": 0.8153051533699036, "critic_loss": 1.5270727459788322, "actor_loss": -83.10851974487305, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.858743906021118, "step": 103000}
{"episode_reward": 888.3007803760671, "episode": 104.0, "batch_reward": 0.816941168487072, "critic_loss": 1.5385725508332253, "actor_loss": -83.41677066040039, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.22971200942993, "step": 104000}
{"episode_reward": 893.538406566506, "episode": 105.0, "batch_reward": 0.8171400911211968, "critic_loss": 1.571931767821312, "actor_loss": -83.29636050415039, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.489897966384888, "step": 105000}
{"episode_reward": 888.0270706326157, "episode": 106.0, "batch_reward": 0.8170246791243553, "critic_loss": 1.56729690015316, "actor_loss": -83.7170431213379, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.7105815410614, "step": 106000}
{"episode_reward": 846.0781857375063, "episode": 107.0, "batch_reward": 0.8176228997707367, "critic_loss": 1.543349656522274, "actor_loss": -83.72716889953614, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.019893884658813, "step": 107000}
{"episode_reward": 849.4184066028795, "episode": 108.0, "batch_reward": 0.8195737252235412, "critic_loss": 1.5289478116035462, "actor_loss": -83.37609915161133, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.617186546325684, "step": 108000}
{"episode_reward": 886.2734286161523, "episode": 109.0, "batch_reward": 0.8182228122353554, "critic_loss": 1.5549829572439193, "actor_loss": -83.61720237731933, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.692973136901855, "step": 109000}
{"episode_reward": 871.5331356905529, "episode": 110.0, "batch_reward": 0.8199943261742592, "critic_loss": 1.6055691946148873, "actor_loss": -83.56092282104493, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.311895847320557, "step": 110000}
{"episode_reward": 806.4842614804744, "episode": 111.0, "batch_reward": 0.8195556873679161, "critic_loss": 1.5961450664401053, "actor_loss": -83.44087072753906, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 46.56492900848389, "step": 111000}
{"episode_reward": 848.1165921063325, "episode": 112.0, "batch_reward": 0.8195266035199166, "critic_loss": 1.7264080239534378, "actor_loss": -83.70350904846191, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.5371310710907, "step": 112000}
{"episode_reward": 890.9799550518456, "episode": 113.0, "batch_reward": 0.8190581021904946, "critic_loss": 1.6001460372507572, "actor_loss": -83.77620860290527, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.518731594085693, "step": 113000}
{"episode_reward": 869.989611530664, "episode": 114.0, "batch_reward": 0.8209270554184913, "critic_loss": 1.5995364696979524, "actor_loss": -83.85488182067871, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.9912269115448, "step": 114000}
{"episode_reward": 900.1106152767994, "episode": 115.0, "batch_reward": 0.820490244448185, "critic_loss": 1.6720614722967149, "actor_loss": -83.60760546875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.13174319267273, "step": 115000}
{"episode_reward": 857.2166735710233, "episode": 116.0, "batch_reward": 0.82222488707304, "critic_loss": 1.7030033284425736, "actor_loss": -83.74358793640137, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.046605587005615, "step": 116000}
{"episode_reward": 827.5290756063665, "episode": 117.0, "batch_reward": 0.82132429510355, "critic_loss": 1.668983261525631, "actor_loss": -83.33686344909668, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.01658868789673, "step": 117000}
{"episode_reward": 866.0207953556493, "episode": 118.0, "batch_reward": 0.8215494785904884, "critic_loss": 1.669742730796337, "actor_loss": -83.59720291137695, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.829144716262817, "step": 118000}
{"episode_reward": 893.2695435162265, "episode": 119.0, "batch_reward": 0.823744785785675, "critic_loss": 1.6526595452427864, "actor_loss": -83.67534378051758, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.64422369003296, "step": 119000}
{"episode_reward": 893.6634390464146, "episode": 120.0, "batch_reward": 0.8228496701717377, "critic_loss": 1.5938359113931655, "actor_loss": -83.67051954650879, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.687336921691895, "step": 120000}
{"episode_reward": 855.8870716009612, "episode": 121.0, "batch_reward": 0.8239464056491852, "critic_loss": 1.5912044414281845, "actor_loss": -83.70423986816407, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.55974745750427, "step": 121000}
{"episode_reward": 851.0988865143045, "episode": 122.0, "batch_reward": 0.8238370354175568, "critic_loss": 1.5663197207450867, "actor_loss": -83.92708610534667, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.584638595581055, "step": 122000}
{"episode_reward": 877.1963342176717, "episode": 123.0, "batch_reward": 0.8246317946910858, "critic_loss": 1.566201980650425, "actor_loss": -84.02579463195801, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.057891368865967, "step": 123000}
{"episode_reward": 902.3916071917405, "episode": 124.0, "batch_reward": 0.8256898291707039, "critic_loss": 1.5445112170279025, "actor_loss": -84.02249542236328, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.672797441482544, "step": 124000}
{"episode_reward": 898.4985564299334, "episode": 125.0, "batch_reward": 0.8261669657230377, "critic_loss": 1.4115412815213204, "actor_loss": -84.03458158874511, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.726359605789185, "step": 125000}
{"episode_reward": 888.4929684781606, "episode": 126.0, "batch_reward": 0.8264924339652061, "critic_loss": 1.3853648792505264, "actor_loss": -83.81955786132812, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.153327703475952, "step": 126000}
{"episode_reward": 900.3779060236436, "episode": 127.0, "batch_reward": 0.8264034661054611, "critic_loss": 1.460095199227333, "actor_loss": -83.75705915832519, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.583694219589233, "step": 127000}
{"episode_reward": 851.0839409526106, "episode": 128.0, "batch_reward": 0.8264212942123413, "critic_loss": 1.4244305386841296, "actor_loss": -83.84354315185547, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.721738576889038, "step": 128000}
{"episode_reward": 901.7503616393064, "episode": 129.0, "batch_reward": 0.8262693743705749, "critic_loss": 1.3412429462969304, "actor_loss": -83.90260220336914, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.24180006980896, "step": 129000}
{"episode_reward": 889.3209755952954, "episode": 130.0, "batch_reward": 0.8284551550149918, "critic_loss": 1.2439798617959021, "actor_loss": -83.92376550292968, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.81032681465149, "step": 130000}
{"episode_reward": 869.1436956069923, "episode": 131.0, "batch_reward": 0.8284554461836815, "critic_loss": 1.3143637863993645, "actor_loss": -84.05101181030274, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 43.00580048561096, "step": 131000}
{"episode_reward": 861.5945856643284, "episode": 132.0, "batch_reward": 0.8277823060154915, "critic_loss": 1.3292369277477265, "actor_loss": -84.21879759216309, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.43886709213257, "step": 132000}
{"episode_reward": 806.763131618453, "episode": 133.0, "batch_reward": 0.8277292671203613, "critic_loss": 1.394779172062874, "actor_loss": -84.09957331848145, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.97458028793335, "step": 133000}
{"episode_reward": 886.0638303769568, "episode": 134.0, "batch_reward": 0.8286469176411628, "critic_loss": 1.3315294080376625, "actor_loss": -84.03690592956544, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.012948274612427, "step": 134000}
{"episode_reward": 821.4500275517196, "episode": 135.0, "batch_reward": 0.8281595664620399, "critic_loss": 1.352966698527336, "actor_loss": -83.89957261657715, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.42116355895996, "step": 135000}
{"episode_reward": 839.0659072857675, "episode": 136.0, "batch_reward": 0.830265575170517, "critic_loss": 1.4046418867111206, "actor_loss": -83.8751736907959, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.66631770133972, "step": 136000}
{"episode_reward": 897.0489963292781, "episode": 137.0, "batch_reward": 0.8279732404947281, "critic_loss": 1.302802236020565, "actor_loss": -84.27180032348633, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.5918447971344, "step": 137000}
{"episode_reward": 889.9520469839676, "episode": 138.0, "batch_reward": 0.8310459232330323, "critic_loss": 1.3526974442303181, "actor_loss": -84.19113369750977, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.749073266983032, "step": 138000}
{"episode_reward": 897.6947339507333, "episode": 139.0, "batch_reward": 0.8295667182207107, "critic_loss": 1.3468968498110772, "actor_loss": -84.07976219177246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.70108127593994, "step": 139000}
{"episode_reward": 835.4242063322775, "episode": 140.0, "batch_reward": 0.8312385610938072, "critic_loss": 1.341100729584694, "actor_loss": -84.12063781738281, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.70565152168274, "step": 140000}
{"episode_reward": 882.815445800173, "episode": 141.0, "batch_reward": 0.8295488075017929, "critic_loss": 1.382908269584179, "actor_loss": -84.1845168762207, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.46973133087158, "step": 141000}
{"episode_reward": 888.0445828193873, "episode": 142.0, "batch_reward": 0.830407142162323, "critic_loss": 1.347861305952072, "actor_loss": -83.7589319152832, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.28188967704773, "step": 142000}
{"episode_reward": 855.9912135060486, "episode": 143.0, "batch_reward": 0.8311976299285889, "critic_loss": 1.4350725893378258, "actor_loss": -83.95536616516114, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.50947666168213, "step": 143000}
{"episode_reward": 892.4070256760165, "episode": 144.0, "batch_reward": 0.8316115104556083, "critic_loss": 1.3956228864789009, "actor_loss": -84.21161119079589, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.38175916671753, "step": 144000}
{"episode_reward": 802.980826286894, "episode": 145.0, "batch_reward": 0.8318261922001838, "critic_loss": 1.3968455567359925, "actor_loss": -84.46150099182128, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.908769845962524, "step": 145000}
{"episode_reward": 833.5145910661107, "episode": 146.0, "batch_reward": 0.8324289525747299, "critic_loss": 1.343750171482563, "actor_loss": -84.36166897583009, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.20952868461609, "step": 146000}
{"episode_reward": 885.4947197916343, "episode": 147.0, "batch_reward": 0.831862223982811, "critic_loss": 1.3528028437197208, "actor_loss": -84.16593775939941, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.5890052318573, "step": 147000}
{"episode_reward": 758.2270366645829, "episode": 148.0, "batch_reward": 0.8306979833841324, "critic_loss": 1.2921707164347171, "actor_loss": -84.39795500183105, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.590135097503662, "step": 148000}
{"episode_reward": 879.5341196073128, "episode": 149.0, "batch_reward": 0.831498779475689, "critic_loss": 1.3059783619940282, "actor_loss": -84.0798442993164, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.57325506210327, "step": 149000}
{"episode_reward": 805.7084711942413, "episode": 150.0, "batch_reward": 0.8307598029375076, "critic_loss": 1.3327284608483314, "actor_loss": -84.26168748474122, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
