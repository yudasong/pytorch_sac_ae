{"episode_reward": 0.0, "episode": 1.0, "duration": 21.892314195632935, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.9215161800384521, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.2704744104317086, "critic_loss": 0.16590005528428983, "actor_loss": -56.1617503103477, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 62.86523699760437, "step": 3000}
{"episode_reward": 83.95231577499172, "episode": 4.0, "batch_reward": 0.20749365036189557, "critic_loss": 0.29170356361567973, "actor_loss": -53.84826953816414, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.749983072280884, "step": 4000}
{"episode_reward": 137.16511357660676, "episode": 5.0, "batch_reward": 0.20318508875370025, "critic_loss": 0.35061082418262957, "actor_loss": -53.82064318418503, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.497285842895508, "step": 5000}
{"episode_reward": 248.9609006659985, "episode": 6.0, "batch_reward": 0.21532564383745192, "critic_loss": 0.4411130774617195, "actor_loss": -53.46594235086441, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.85745859146118, "step": 6000}
{"episode_reward": 270.60740213082215, "episode": 7.0, "batch_reward": 0.2269898961633444, "critic_loss": 0.5591641814112663, "actor_loss": -55.24768618297577, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.79994297027588, "step": 7000}
{"episode_reward": 401.65964633752463, "episode": 8.0, "batch_reward": 0.2622288360446692, "critic_loss": 0.670857233941555, "actor_loss": -58.797396849155426, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.182467222213745, "step": 8000}
{"episode_reward": 495.41951770088866, "episode": 9.0, "batch_reward": 0.2882567965686321, "critic_loss": 0.8066394976973533, "actor_loss": -57.97368225574493, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.65950655937195, "step": 9000}
{"episode_reward": 497.12649686874687, "episode": 10.0, "batch_reward": 0.3124599899798632, "critic_loss": 1.032955701828003, "actor_loss": -59.42857316017151, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.842469453811646, "step": 10000}
{"episode_reward": 525.5664521493865, "episode": 11.0, "batch_reward": 0.33629780055582525, "critic_loss": 1.1144928605556488, "actor_loss": -60.20163005638123, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.82021617889404, "step": 11000}
{"episode_reward": 553.9147676257385, "episode": 12.0, "batch_reward": 0.3574632846415043, "critic_loss": 1.1737997718453408, "actor_loss": -61.349740631103515, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.44398331642151, "step": 12000}
{"episode_reward": 752.5093793849358, "episode": 13.0, "batch_reward": 0.3822634683549404, "critic_loss": 1.349358172059059, "actor_loss": -61.97968144226074, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.70549988746643, "step": 13000}
{"episode_reward": 532.99820248846, "episode": 14.0, "batch_reward": 0.3930241569280624, "critic_loss": 1.7018928887844085, "actor_loss": -62.83143961143494, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.85616660118103, "step": 14000}
{"episode_reward": 589.763873236036, "episode": 15.0, "batch_reward": 0.4134515678286552, "critic_loss": 1.9576706961393355, "actor_loss": -60.653640991210935, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.391772508621216, "step": 15000}
{"episode_reward": 542.7303404922023, "episode": 16.0, "batch_reward": 0.4190165293812752, "critic_loss": 2.19119717335701, "actor_loss": -64.27424409484863, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.846327543258667, "step": 16000}
{"episode_reward": 647.8600455527546, "episode": 17.0, "batch_reward": 0.4332580304443836, "critic_loss": 2.5249801226854323, "actor_loss": -63.99067984008789, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.704073667526245, "step": 17000}
{"episode_reward": 670.8593435479731, "episode": 18.0, "batch_reward": 0.44311122193932534, "critic_loss": 2.757325276851654, "actor_loss": -64.88171323013306, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.417670011520386, "step": 18000}
{"episode_reward": 624.9184099817595, "episode": 19.0, "batch_reward": 0.4587339186370373, "critic_loss": 2.790721772193909, "actor_loss": -66.0449398727417, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.781556129455566, "step": 19000}
{"episode_reward": 821.4232162672159, "episode": 20.0, "batch_reward": 0.47282375234365465, "critic_loss": 2.7953836588859557, "actor_loss": -64.67416238403321, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.598691940307617, "step": 20000}
{"episode_reward": 632.05510942982, "episode": 21.0, "batch_reward": 0.4893598999381065, "critic_loss": 2.7130280071496964, "actor_loss": -65.88327518081665, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.83818244934082, "step": 21000}
{"episode_reward": 912.0115074292577, "episode": 22.0, "batch_reward": 0.5071040148139, "critic_loss": 2.779852385878563, "actor_loss": -66.1215949935913, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.373345375061035, "step": 22000}
{"episode_reward": 840.1346005879675, "episode": 23.0, "batch_reward": 0.5149340119659901, "critic_loss": 2.944060401558876, "actor_loss": -67.53637575912475, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.986911296844482, "step": 23000}
{"episode_reward": 571.8142619675455, "episode": 24.0, "batch_reward": 0.5218563109040261, "critic_loss": 3.0873465485572815, "actor_loss": -67.39530783081055, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.74666953086853, "step": 24000}
{"episode_reward": 712.2003588016759, "episode": 25.0, "batch_reward": 0.5329622777998447, "critic_loss": 2.90281207549572, "actor_loss": -69.2049267578125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.418423891067505, "step": 25000}
{"episode_reward": 878.7899251666206, "episode": 26.0, "batch_reward": 0.5442741008996963, "critic_loss": 2.893034705519676, "actor_loss": -68.43989080047608, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.266613245010376, "step": 26000}
{"episode_reward": 823.3811281817877, "episode": 27.0, "batch_reward": 0.5548738678991795, "critic_loss": 2.8458620351552963, "actor_loss": -69.09780834197998, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.542336225509644, "step": 27000}
{"episode_reward": 746.1109963957388, "episode": 28.0, "batch_reward": 0.559676510810852, "critic_loss": 3.057992198348045, "actor_loss": -69.97688486480713, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.36470675468445, "step": 28000}
{"episode_reward": 653.0508629066403, "episode": 29.0, "batch_reward": 0.5660889168679715, "critic_loss": 3.1672833898067476, "actor_loss": -68.91668700408935, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.17528986930847, "step": 29000}
{"episode_reward": 796.2471769599749, "episode": 30.0, "batch_reward": 0.570307735145092, "critic_loss": 3.246205684185028, "actor_loss": -69.19432292938232, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.59363579750061, "step": 30000}
{"episode_reward": 742.5504658074401, "episode": 31.0, "batch_reward": 0.5754486219882965, "critic_loss": 3.4322363550662995, "actor_loss": -71.18526898193359, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.41561555862427, "step": 31000}
{"episode_reward": 684.097758272512, "episode": 32.0, "batch_reward": 0.580416784107685, "critic_loss": 3.388943145751953, "actor_loss": -70.93639638519286, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.08031129837036, "step": 32000}
{"episode_reward": 751.7047436654507, "episode": 33.0, "batch_reward": 0.5876390589773655, "critic_loss": 3.2004464453458787, "actor_loss": -71.25693802642822, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.894733905792236, "step": 33000}
{"episode_reward": 874.8595686990308, "episode": 34.0, "batch_reward": 0.5949613395929336, "critic_loss": 3.227771191954613, "actor_loss": -71.80843781280518, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.774595022201538, "step": 34000}
{"episode_reward": 734.2693423135079, "episode": 35.0, "batch_reward": 0.5977422009706497, "critic_loss": 3.3323730380535124, "actor_loss": -71.2103447113037, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.130455493927002, "step": 35000}
{"episode_reward": 761.5708000098314, "episode": 36.0, "batch_reward": 0.6065827682614326, "critic_loss": 3.1162530218362807, "actor_loss": -73.45462537384033, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.731205224990845, "step": 36000}
{"episode_reward": 835.6214644280718, "episode": 37.0, "batch_reward": 0.6133846786618232, "critic_loss": 3.0632855684757234, "actor_loss": -72.7428620300293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.74986171722412, "step": 37000}
{"episode_reward": 863.6280731419048, "episode": 38.0, "batch_reward": 0.6212259846925735, "critic_loss": 3.016568931221962, "actor_loss": -72.21964121246337, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.75725817680359, "step": 38000}
{"episode_reward": 875.9641930365739, "episode": 39.0, "batch_reward": 0.6247598450779915, "critic_loss": 2.8967149958610534, "actor_loss": -73.78100942993164, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.034661531448364, "step": 39000}
{"episode_reward": 851.4925419104225, "episode": 40.0, "batch_reward": 0.6280784358382225, "critic_loss": 2.8048021939992904, "actor_loss": -73.85240510559082, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.12044620513916, "step": 40000}
{"episode_reward": 832.0473070832945, "episode": 41.0, "batch_reward": 0.6332394830584526, "critic_loss": 2.7922934222221376, "actor_loss": -74.81162680816651, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.16790843009949, "step": 41000}
{"episode_reward": 734.385967660997, "episode": 42.0, "batch_reward": 0.637690131008625, "critic_loss": 2.654944717049599, "actor_loss": -73.14661839294433, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.539036989212036, "step": 42000}
{"episode_reward": 904.2298792141046, "episode": 43.0, "batch_reward": 0.6430699651837349, "critic_loss": 2.553633869051933, "actor_loss": -74.60835048675537, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.37037968635559, "step": 43000}
{"episode_reward": 784.0945608142293, "episode": 44.0, "batch_reward": 0.6493593648076057, "critic_loss": 2.6095809280872344, "actor_loss": -74.84565439605713, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.723283529281616, "step": 44000}
{"episode_reward": 839.8398316236598, "episode": 45.0, "batch_reward": 0.6512636044621467, "critic_loss": 2.522722041010857, "actor_loss": -74.57477267456055, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.00711679458618, "step": 45000}
{"episode_reward": 804.6178615840406, "episode": 46.0, "batch_reward": 0.6546947064995766, "critic_loss": 2.436259173512459, "actor_loss": -74.67335488128663, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.55756378173828, "step": 46000}
{"episode_reward": 834.2409649113413, "episode": 47.0, "batch_reward": 0.6583121709823608, "critic_loss": 2.4240954325199127, "actor_loss": -75.46078026580811, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.84072518348694, "step": 47000}
{"episode_reward": 844.585555971973, "episode": 48.0, "batch_reward": 0.6633007047176361, "critic_loss": 2.3379329072237014, "actor_loss": -75.66782861328124, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.9296658039093, "step": 48000}
{"episode_reward": 800.4226837950396, "episode": 49.0, "batch_reward": 0.6661295672655105, "critic_loss": 2.2014012796878815, "actor_loss": -75.99370276641845, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.73691749572754, "step": 49000}
{"episode_reward": 811.9669700056158, "episode": 50.0, "batch_reward": 0.6684534459710121, "critic_loss": 2.1254725782871247, "actor_loss": -75.38570403289795, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.831348180770874, "step": 50000}
{"episode_reward": 798.7625052108455, "episode": 51.0, "batch_reward": 0.672014823615551, "critic_loss": 2.249248295903206, "actor_loss": -75.68642124938965, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.84427452087402, "step": 51000}
{"episode_reward": 741.3531440098939, "episode": 52.0, "batch_reward": 0.6686904898881912, "critic_loss": 2.386688040614128, "actor_loss": -76.40799011230469, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.75173807144165, "step": 52000}
{"episode_reward": 594.403084380552, "episode": 53.0, "batch_reward": 0.6688785164356231, "critic_loss": 2.3691668701171875, "actor_loss": -75.14385163116455, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.20528769493103, "step": 53000}
{"episode_reward": 720.0173679279394, "episode": 54.0, "batch_reward": 0.6707264928221702, "critic_loss": 2.296751388311386, "actor_loss": -76.83915934753418, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.6549654006958, "step": 54000}
{"episode_reward": 840.8768154056195, "episode": 55.0, "batch_reward": 0.6737618715763092, "critic_loss": 2.241936645746231, "actor_loss": -76.4489820022583, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.781656980514526, "step": 55000}
{"episode_reward": 819.3463043105793, "episode": 56.0, "batch_reward": 0.6802237918972969, "critic_loss": 2.285267996549606, "actor_loss": -75.70377335357666, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.78635549545288, "step": 56000}
{"episode_reward": 884.508688713584, "episode": 57.0, "batch_reward": 0.6813545396327972, "critic_loss": 2.2198040790557863, "actor_loss": -76.88258617401124, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.5510675907135, "step": 57000}
{"episode_reward": 841.263992602094, "episode": 58.0, "batch_reward": 0.6846446639895439, "critic_loss": 2.3242383476495743, "actor_loss": -76.54106520843506, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.5594642162323, "step": 58000}
{"episode_reward": 830.8791050060853, "episode": 59.0, "batch_reward": 0.6883083093762398, "critic_loss": 2.2753498970270156, "actor_loss": -76.80416231536866, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.688756704330444, "step": 59000}
{"episode_reward": 879.0702503608167, "episode": 60.0, "batch_reward": 0.6905329303741455, "critic_loss": 2.0536131056547164, "actor_loss": -76.87251591491699, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.534857511520386, "step": 60000}
{"episode_reward": 827.182609073009, "episode": 61.0, "batch_reward": 0.6905355870723724, "critic_loss": 2.146455120742321, "actor_loss": -77.4255785369873, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.76908612251282, "step": 61000}
{"episode_reward": 731.9299768846091, "episode": 62.0, "batch_reward": 0.6922348226308823, "critic_loss": 2.1548217458724976, "actor_loss": -76.87368328094482, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.06837511062622, "step": 62000}
{"episode_reward": 898.1815996900673, "episode": 63.0, "batch_reward": 0.6957484627962113, "critic_loss": 2.228904068470001, "actor_loss": -77.20995026397705, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.563558101654053, "step": 63000}
{"episode_reward": 875.0492886768324, "episode": 64.0, "batch_reward": 0.7003065103292465, "critic_loss": 2.0960920672416687, "actor_loss": -77.49720969390869, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.372992992401123, "step": 64000}
{"episode_reward": 877.4914805413065, "episode": 65.0, "batch_reward": 0.7001288653612137, "critic_loss": 2.2049800616502764, "actor_loss": -77.321438331604, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.344082355499268, "step": 65000}
{"episode_reward": 747.2650647444706, "episode": 66.0, "batch_reward": 0.7029896813631058, "critic_loss": 2.3021363834142683, "actor_loss": -77.54572592926026, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.712738037109375, "step": 66000}
{"episode_reward": 886.6886598939609, "episode": 67.0, "batch_reward": 0.7076611573696137, "critic_loss": 2.2140182050466537, "actor_loss": -77.38334124755859, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.373355627059937, "step": 67000}
{"episode_reward": 837.8427884541283, "episode": 68.0, "batch_reward": 0.7074318583607674, "critic_loss": 2.253771164894104, "actor_loss": -78.09082800292968, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.56667995452881, "step": 68000}
{"episode_reward": 817.4528808784969, "episode": 69.0, "batch_reward": 0.7084159237146378, "critic_loss": 2.26979723739624, "actor_loss": -78.23139093780517, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.346263647079468, "step": 69000}
{"episode_reward": 850.7496693290906, "episode": 70.0, "batch_reward": 0.7117851061820983, "critic_loss": 2.290749737739563, "actor_loss": -78.33569847106934, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.536595106124878, "step": 70000}
{"episode_reward": 784.6920264378324, "episode": 71.0, "batch_reward": 0.7109519185423852, "critic_loss": 2.185983915925026, "actor_loss": -77.84131245422363, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.10249638557434, "step": 71000}
{"episode_reward": 884.5143247716825, "episode": 72.0, "batch_reward": 0.7142254237532616, "critic_loss": 2.3107194863557816, "actor_loss": -78.72592776489257, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.38886046409607, "step": 72000}
{"episode_reward": 818.2468786536614, "episode": 73.0, "batch_reward": 0.7150615335702896, "critic_loss": 2.249915774822235, "actor_loss": -78.58908972930908, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.67426085472107, "step": 73000}
{"episode_reward": 873.5327496995043, "episode": 74.0, "batch_reward": 0.7186911406517029, "critic_loss": 2.1907224727272987, "actor_loss": -78.46486293029785, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.594053983688354, "step": 74000}
{"episode_reward": 818.7914680576711, "episode": 75.0, "batch_reward": 0.7184649823307991, "critic_loss": 2.238228983879089, "actor_loss": -79.00973278045655, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.48560404777527, "step": 75000}
{"episode_reward": 836.2638150797908, "episode": 76.0, "batch_reward": 0.7214714781045913, "critic_loss": 2.2563834812641144, "actor_loss": -78.78764246368408, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.518635749816895, "step": 76000}
{"episode_reward": 843.9724715322664, "episode": 77.0, "batch_reward": 0.7234917170405388, "critic_loss": 2.126080936551094, "actor_loss": -78.75750359344482, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.56336212158203, "step": 77000}
{"episode_reward": 880.0416154493495, "episode": 78.0, "batch_reward": 0.7238508930206299, "critic_loss": 2.1939043171405794, "actor_loss": -78.60223337554932, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.772257328033447, "step": 78000}
{"episode_reward": 778.8460959072328, "episode": 79.0, "batch_reward": 0.7237851590514183, "critic_loss": 2.1743073722720148, "actor_loss": -79.06319299316407, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.223567485809326, "step": 79000}
{"episode_reward": 767.8424274974576, "episode": 80.0, "batch_reward": 0.7269777620434761, "critic_loss": 2.0446204127669336, "actor_loss": -79.20105766296386, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.6916024684906, "step": 80000}
{"episode_reward": 858.2168029442629, "episode": 81.0, "batch_reward": 0.7248683644533157, "critic_loss": 2.106847995400429, "actor_loss": -79.1549580078125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.36511540412903, "step": 81000}
{"episode_reward": 799.353709539619, "episode": 82.0, "batch_reward": 0.7281567859053611, "critic_loss": 2.1893715645074843, "actor_loss": -79.16669607543945, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.48977756500244, "step": 82000}
{"episode_reward": 882.7973118494414, "episode": 83.0, "batch_reward": 0.7286940360665322, "critic_loss": 2.1045427837371826, "actor_loss": -79.30860141754151, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.63632559776306, "step": 83000}
{"episode_reward": 784.6507042117013, "episode": 84.0, "batch_reward": 0.731595783174038, "critic_loss": 1.9810411947369575, "actor_loss": -79.90984558105468, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.926697969436646, "step": 84000}
{"episode_reward": 819.3896901335528, "episode": 85.0, "batch_reward": 0.7303688886165619, "critic_loss": 1.9936758118867874, "actor_loss": -79.50616218566894, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.704981803894043, "step": 85000}
{"episode_reward": 854.2781669088355, "episode": 86.0, "batch_reward": 0.7331840258836746, "critic_loss": 1.9631855301260948, "actor_loss": -79.90306982421875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.52732253074646, "step": 86000}
{"episode_reward": 869.327631180178, "episode": 87.0, "batch_reward": 0.735142960190773, "critic_loss": 1.9979932037591934, "actor_loss": -79.93780361938477, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.296146154403687, "step": 87000}
{"episode_reward": 849.4774637228305, "episode": 88.0, "batch_reward": 0.7342360908985138, "critic_loss": 2.074154736995697, "actor_loss": -79.97315965270997, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.66913914680481, "step": 88000}
{"episode_reward": 732.9486875247536, "episode": 89.0, "batch_reward": 0.7353697375059128, "critic_loss": 2.1939378430843353, "actor_loss": -79.69561495971679, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.496015548706055, "step": 89000}
{"episode_reward": 802.3616916288319, "episode": 90.0, "batch_reward": 0.7368781424164772, "critic_loss": 2.2275228676199914, "actor_loss": -79.81379852294921, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.28207278251648, "step": 90000}
{"episode_reward": 747.8236042930721, "episode": 91.0, "batch_reward": 0.7360285201668739, "critic_loss": 2.2544658855199815, "actor_loss": -79.55742213439942, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.697569370269775, "step": 91000}
{"episode_reward": 817.0165191469551, "episode": 92.0, "batch_reward": 0.7392629901170731, "critic_loss": 2.2163408901691435, "actor_loss": -79.83546594238281, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.54634952545166, "step": 92000}
{"episode_reward": 842.4963847121331, "episode": 93.0, "batch_reward": 0.7395727016925812, "critic_loss": 2.152477823138237, "actor_loss": -80.27674998474122, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.230159759521484, "step": 93000}
{"episode_reward": 849.2718214085745, "episode": 94.0, "batch_reward": 0.7408311230540275, "critic_loss": 2.1987269798517226, "actor_loss": -80.37834706115723, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.755210876464844, "step": 94000}
{"episode_reward": 823.8076637289713, "episode": 95.0, "batch_reward": 0.7415001728534698, "critic_loss": 2.1219228285551073, "actor_loss": -80.37126406860351, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.844372034072876, "step": 95000}
{"episode_reward": 818.1699994574826, "episode": 96.0, "batch_reward": 0.741573771417141, "critic_loss": 2.0182236090898513, "actor_loss": -80.1800505065918, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.150975942611694, "step": 96000}
{"episode_reward": 784.535173501258, "episode": 97.0, "batch_reward": 0.7427345541715622, "critic_loss": 2.0337505665421487, "actor_loss": -80.48307263183594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.760579109191895, "step": 97000}
{"episode_reward": 863.1021372158893, "episode": 98.0, "batch_reward": 0.7419720003008843, "critic_loss": 1.9500453866124152, "actor_loss": -80.48384550476074, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.944538116455078, "step": 98000}
{"episode_reward": 788.869287468203, "episode": 99.0, "batch_reward": 0.7430099015831947, "critic_loss": 1.9890914285779, "actor_loss": -80.42299725341798, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.054009675979614, "step": 99000}
{"episode_reward": 847.0667174359259, "episode": 100.0, "batch_reward": 0.7438496459126472, "critic_loss": 1.993570093870163, "actor_loss": -80.7606128692627, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.836711406707764, "step": 100000}
{"episode_reward": 877.6885134768945, "episode": 101.0, "batch_reward": 0.7469279121160507, "critic_loss": 1.9922779056429862, "actor_loss": -80.78143547058106, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.237698554992676, "step": 101000}
{"episode_reward": 888.7730466692901, "episode": 102.0, "batch_reward": 0.7476521370410919, "critic_loss": 1.933837576508522, "actor_loss": -81.0296335144043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.396059274673462, "step": 102000}
{"episode_reward": 892.005294154108, "episode": 103.0, "batch_reward": 0.7492435981631279, "critic_loss": 1.9047868685722351, "actor_loss": -80.37074674987792, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.726460218429565, "step": 103000}
{"episode_reward": 863.0642029611478, "episode": 104.0, "batch_reward": 0.7487729433774948, "critic_loss": 1.978727561533451, "actor_loss": -80.76786305236817, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.937812328338623, "step": 104000}
{"episode_reward": 894.7894714973465, "episode": 105.0, "batch_reward": 0.7521865658164024, "critic_loss": 1.807344910800457, "actor_loss": -80.61182286071778, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.03988265991211, "step": 105000}
{"episode_reward": 869.0145352728384, "episode": 106.0, "batch_reward": 0.752741732776165, "critic_loss": 1.9491398659944534, "actor_loss": -81.26323184204101, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.747365474700928, "step": 106000}
{"episode_reward": 869.2629969114122, "episode": 107.0, "batch_reward": 0.7528326395750046, "critic_loss": 1.9589775012731552, "actor_loss": -81.14324320983887, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.674855947494507, "step": 107000}
{"episode_reward": 726.1759521591179, "episode": 108.0, "batch_reward": 0.7530524452924728, "critic_loss": 1.9269572054147721, "actor_loss": -80.68480752563477, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.05690360069275, "step": 108000}
{"episode_reward": 856.8157210933147, "episode": 109.0, "batch_reward": 0.7540467141270637, "critic_loss": 1.9937399113178254, "actor_loss": -81.08268173217773, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.468860387802124, "step": 109000}
{"episode_reward": 866.3248581755345, "episode": 110.0, "batch_reward": 0.7557512519359588, "critic_loss": 2.0108006831407548, "actor_loss": -81.01529960632324, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.387588262557983, "step": 110000}
{"episode_reward": 849.868714196781, "episode": 111.0, "batch_reward": 0.7558531776666642, "critic_loss": 2.02322148501873, "actor_loss": -80.82494073486328, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.343302726745605, "step": 111000}
{"episode_reward": 695.9192836097181, "episode": 112.0, "batch_reward": 0.7561322898864746, "critic_loss": 2.0940016387701035, "actor_loss": -81.14084574890137, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.888338088989258, "step": 112000}
{"episode_reward": 874.7697613419467, "episode": 113.0, "batch_reward": 0.7570560973286629, "critic_loss": 1.8677376952767373, "actor_loss": -81.34084280395508, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.354265451431274, "step": 113000}
{"episode_reward": 893.544740546539, "episode": 114.0, "batch_reward": 0.7569160812497139, "critic_loss": 1.8615059762597084, "actor_loss": -81.31173973083496, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.61003613471985, "step": 114000}
{"episode_reward": 903.7085530674792, "episode": 115.0, "batch_reward": 0.7589674577116966, "critic_loss": 1.917610978603363, "actor_loss": -81.07352731323242, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.628041744232178, "step": 115000}
{"episode_reward": 871.2198374711918, "episode": 116.0, "batch_reward": 0.7623797123432159, "critic_loss": 1.8335880709290504, "actor_loss": -81.38776489257812, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.517284870147705, "step": 116000}
{"episode_reward": 840.4964986292174, "episode": 117.0, "batch_reward": 0.7593177633881569, "critic_loss": 1.8444376311302184, "actor_loss": -80.71348220825195, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.302428483963013, "step": 117000}
{"episode_reward": 841.8703471493234, "episode": 118.0, "batch_reward": 0.7621914036273957, "critic_loss": 1.7775962923169135, "actor_loss": -81.19323992919922, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.316010236740112, "step": 118000}
{"episode_reward": 879.2166653856492, "episode": 119.0, "batch_reward": 0.763863623380661, "critic_loss": 1.8021458168625832, "actor_loss": -81.26109518432617, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.38932204246521, "step": 119000}
{"episode_reward": 879.8633993253172, "episode": 120.0, "batch_reward": 0.7640270723700523, "critic_loss": 1.8874640803337097, "actor_loss": -81.23607487487793, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.07463240623474, "step": 120000}
{"episode_reward": 854.7087226941168, "episode": 121.0, "batch_reward": 0.7632883692979813, "critic_loss": 1.9402379937171936, "actor_loss": -81.26718226623535, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.965805530548096, "step": 121000}
{"episode_reward": 838.6535509822, "episode": 122.0, "batch_reward": 0.7659514577388763, "critic_loss": 1.9183182538151742, "actor_loss": -81.58756056213379, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.88026523590088, "step": 122000}
{"episode_reward": 880.6401552219687, "episode": 123.0, "batch_reward": 0.7662677136063576, "critic_loss": 1.9150122247338295, "actor_loss": -81.85668392944336, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.822868824005127, "step": 123000}
{"episode_reward": 892.3190795146262, "episode": 124.0, "batch_reward": 0.7671276465654373, "critic_loss": 1.8147618732452393, "actor_loss": -81.79778395080567, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.1234290599823, "step": 124000}
{"episode_reward": 896.9407950625357, "episode": 125.0, "batch_reward": 0.7685122291445732, "critic_loss": 1.8466848901510238, "actor_loss": -81.77229417419434, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.64235758781433, "step": 125000}
{"episode_reward": 886.6690380771591, "episode": 126.0, "batch_reward": 0.7695470338463783, "critic_loss": 1.8859200026988983, "actor_loss": -81.47042419433593, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.76786470413208, "step": 126000}
{"episode_reward": 906.517847732763, "episode": 127.0, "batch_reward": 0.7696329597234726, "critic_loss": 1.9980920318961144, "actor_loss": -81.41964956665039, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.53407573699951, "step": 127000}
{"episode_reward": 841.4641595588043, "episode": 128.0, "batch_reward": 0.77038052713871, "critic_loss": 1.9759598306417465, "actor_loss": -81.53402711486817, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.84639000892639, "step": 128000}
{"episode_reward": 887.4708647754867, "episode": 129.0, "batch_reward": 0.7711231094002724, "critic_loss": 1.9280762438774108, "actor_loss": -81.6679208984375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.39441156387329, "step": 129000}
{"episode_reward": 885.1469878153302, "episode": 130.0, "batch_reward": 0.7724138369560242, "critic_loss": 1.8028113197684288, "actor_loss": -81.643169631958, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.356634616851807, "step": 130000}
{"episode_reward": 862.6085197359051, "episode": 131.0, "batch_reward": 0.7744437135457992, "critic_loss": 1.7542491279840469, "actor_loss": -81.93784280395508, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.60942602157593, "step": 131000}
{"episode_reward": 805.4479002898611, "episode": 132.0, "batch_reward": 0.7741460720896721, "critic_loss": 1.6624799412488938, "actor_loss": -82.18102851867675, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.65582823753357, "step": 132000}
{"episode_reward": 845.311803190109, "episode": 133.0, "batch_reward": 0.7752172686457633, "critic_loss": 1.6952451443076133, "actor_loss": -82.03128451538086, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.85153555870056, "step": 133000}
{"episode_reward": 893.2737211668737, "episode": 134.0, "batch_reward": 0.77398445302248, "critic_loss": 1.6066802080869675, "actor_loss": -81.88690838623047, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.858802318572998, "step": 134000}
{"episode_reward": 880.5416570917247, "episode": 135.0, "batch_reward": 0.7756798679828644, "critic_loss": 1.6530267629623414, "actor_loss": -81.76779750061036, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.412203073501587, "step": 135000}
{"episode_reward": 851.0571173993924, "episode": 136.0, "batch_reward": 0.7761394566297531, "critic_loss": 1.6109427825808524, "actor_loss": -81.6351736907959, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.417765378952026, "step": 136000}
{"episode_reward": 892.000258458625, "episode": 137.0, "batch_reward": 0.7764482973217964, "critic_loss": 1.5858959714770318, "actor_loss": -82.291445022583, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.74159288406372, "step": 137000}
{"episode_reward": 904.7634739604316, "episode": 138.0, "batch_reward": 0.7798152796626091, "critic_loss": 1.594556173324585, "actor_loss": -82.22872611999512, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.59126877784729, "step": 138000}
{"episode_reward": 900.1991395769801, "episode": 139.0, "batch_reward": 0.7786267278790474, "critic_loss": 1.5999462525248527, "actor_loss": -82.06673751831055, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.049230813980103, "step": 139000}
{"episode_reward": 879.0279189507996, "episode": 140.0, "batch_reward": 0.7805837364792824, "critic_loss": 1.5411250351071357, "actor_loss": -82.11078999328613, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.358139514923096, "step": 140000}
{"episode_reward": 873.2611720133749, "episode": 141.0, "batch_reward": 0.7785704251527786, "critic_loss": 1.6180185175538062, "actor_loss": -82.20980183410644, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.77008652687073, "step": 141000}
{"episode_reward": 839.228296104417, "episode": 142.0, "batch_reward": 0.7796198183894157, "critic_loss": 1.6633780767917634, "actor_loss": -81.70515759277343, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.755030155181885, "step": 142000}
{"episode_reward": 874.2475124252413, "episode": 143.0, "batch_reward": 0.7812416611909866, "critic_loss": 1.6936444671750068, "actor_loss": -81.9523655090332, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.479727506637573, "step": 143000}
{"episode_reward": 887.8611619632236, "episode": 144.0, "batch_reward": 0.7808164122700691, "critic_loss": 1.555735960841179, "actor_loss": -82.25962612915039, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.56057572364807, "step": 144000}
{"episode_reward": 840.5424492083207, "episode": 145.0, "batch_reward": 0.7827977187037468, "critic_loss": 1.617096937775612, "actor_loss": -82.60759219360351, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.730962991714478, "step": 145000}
{"episode_reward": 850.9654395063969, "episode": 146.0, "batch_reward": 0.784463220357895, "critic_loss": 1.6535939010977745, "actor_loss": -82.46713592529296, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.80819606781006, "step": 146000}
{"episode_reward": 899.6113078414452, "episode": 147.0, "batch_reward": 0.7829020981788635, "critic_loss": 1.6148881916999818, "actor_loss": -82.23011094665527, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.692867040634155, "step": 147000}
{"episode_reward": 861.5678593749757, "episode": 148.0, "batch_reward": 0.7830530543923377, "critic_loss": 1.5909396237134934, "actor_loss": -82.60423954772949, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.941123962402344, "step": 148000}
{"episode_reward": 866.2689002021151, "episode": 149.0, "batch_reward": 0.7838390370607377, "critic_loss": 1.5758356001377105, "actor_loss": -82.18091676330566, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.37586808204651, "step": 149000}
{"episode_reward": 893.7119295581747, "episode": 150.0, "batch_reward": 0.7850750268101693, "critic_loss": 1.5723016277551651, "actor_loss": -82.58962553405762, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
