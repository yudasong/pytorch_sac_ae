{"episode_reward": 0.0, "episode": 1.0, "duration": 21.720686435699463, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.8443024158477783, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.27703156461613143, "critic_loss": 0.22418158957700543, "actor_loss": -17.13985917226476, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 62.44719576835632, "step": 3000}
{"episode_reward": 257.70975451170165, "episode": 4.0, "batch_reward": 0.26987007121741774, "critic_loss": 0.5864558453410864, "actor_loss": -23.410576665878295, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.3558087348938, "step": 4000}
{"episode_reward": 324.252922823993, "episode": 5.0, "batch_reward": 0.2922387853115797, "critic_loss": 0.74678891903162, "actor_loss": -27.12424382019043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.469314336776733, "step": 5000}
{"episode_reward": 340.0495698512138, "episode": 6.0, "batch_reward": 0.3052701024711132, "critic_loss": 1.017156383216381, "actor_loss": -27.879729759216307, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.67341160774231, "step": 6000}
{"episode_reward": 370.46382789027115, "episode": 7.0, "batch_reward": 0.30937709315121176, "critic_loss": 1.2020183843970298, "actor_loss": -28.69219376373291, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.739460229873657, "step": 7000}
{"episode_reward": 332.5063806805726, "episode": 8.0, "batch_reward": 0.33356732691824437, "critic_loss": 1.6103964726924895, "actor_loss": -34.862579448699954, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.385680437088013, "step": 8000}
{"episode_reward": 629.0533664297305, "episode": 9.0, "batch_reward": 0.36280246803164484, "critic_loss": 1.7035247098207473, "actor_loss": -36.88351357650757, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.30104374885559, "step": 9000}
{"episode_reward": 626.2166906269427, "episode": 10.0, "batch_reward": 0.40928692775964737, "critic_loss": 1.5069597176909446, "actor_loss": -40.11314767837524, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.394724130630493, "step": 10000}
{"episode_reward": 881.9165026657155, "episode": 11.0, "batch_reward": 0.4447714637815952, "critic_loss": 1.6647063045501709, "actor_loss": -41.616437931060794, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.82264184951782, "step": 11000}
{"episode_reward": 680.8180867844957, "episode": 12.0, "batch_reward": 0.4686512467265129, "critic_loss": 1.8220366015434266, "actor_loss": -46.327128494262695, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.628593921661377, "step": 12000}
{"episode_reward": 860.0945515965809, "episode": 13.0, "batch_reward": 0.4949471917152405, "critic_loss": 1.8773924067020415, "actor_loss": -47.345236824035645, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.57654047012329, "step": 13000}
{"episode_reward": 706.2145610865565, "episode": 14.0, "batch_reward": 0.5118847543895244, "critic_loss": 1.8905096665620804, "actor_loss": -49.05224587249756, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.7181978225708, "step": 14000}
{"episode_reward": 749.8216999338841, "episode": 15.0, "batch_reward": 0.5210509457886219, "critic_loss": 1.9617399084568024, "actor_loss": -49.93687391662598, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.64542818069458, "step": 15000}
{"episode_reward": 598.1088114606604, "episode": 16.0, "batch_reward": 0.5402257539927959, "critic_loss": 1.9622659627199173, "actor_loss": -54.01176523590088, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.99493956565857, "step": 16000}
{"episode_reward": 940.2228682750037, "episode": 17.0, "batch_reward": 0.5568530502617359, "critic_loss": 1.9276241542100907, "actor_loss": -56.49876956176758, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.44125247001648, "step": 17000}
{"episode_reward": 788.8672933565755, "episode": 18.0, "batch_reward": 0.5761104160249233, "critic_loss": 1.749186087489128, "actor_loss": -57.3392953338623, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.433177947998047, "step": 18000}
{"episode_reward": 884.1392565151498, "episode": 19.0, "batch_reward": 0.5933569966554642, "critic_loss": 1.7119147832393646, "actor_loss": -59.285261253356936, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.67416524887085, "step": 19000}
{"episode_reward": 838.3716824732192, "episode": 20.0, "batch_reward": 0.6038334614038467, "critic_loss": 1.7550974264144898, "actor_loss": -60.346559928894045, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.397059679031372, "step": 20000}
{"episode_reward": 865.1045461087194, "episode": 21.0, "batch_reward": 0.6201874054670334, "critic_loss": 1.5760856268405914, "actor_loss": -62.42049785614014, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.973536252975464, "step": 21000}
{"episode_reward": 892.3566279676538, "episode": 22.0, "batch_reward": 0.6278769777417182, "critic_loss": 1.5890730286836625, "actor_loss": -62.8589520111084, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.37664818763733, "step": 22000}
{"episode_reward": 700.2581897692838, "episode": 23.0, "batch_reward": 0.6303821093440056, "critic_loss": 1.6144245887994766, "actor_loss": -63.773452796936034, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.4799165725708, "step": 23000}
{"episode_reward": 788.1357513717311, "episode": 24.0, "batch_reward": 0.636845241367817, "critic_loss": 1.5367824533581733, "actor_loss": -64.66425794219971, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.421936988830566, "step": 24000}
{"episode_reward": 807.4917520163749, "episode": 25.0, "batch_reward": 0.6477890264987946, "critic_loss": 1.5117765815258026, "actor_loss": -65.70598337554932, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.53347873687744, "step": 25000}
{"episode_reward": 902.3292027359308, "episode": 26.0, "batch_reward": 0.655220483481884, "critic_loss": 1.5619176812767983, "actor_loss": -66.8784031829834, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.641229152679443, "step": 26000}
{"episode_reward": 894.8858950081944, "episode": 27.0, "batch_reward": 0.6678134997487069, "critic_loss": 1.4647067845463753, "actor_loss": -67.72395826721191, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.676755666732788, "step": 27000}
{"episode_reward": 955.4213621800582, "episode": 28.0, "batch_reward": 0.6753429431915283, "critic_loss": 1.5061660088300706, "actor_loss": -69.30289093017578, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.053943634033203, "step": 28000}
{"episode_reward": 914.2978758598015, "episode": 29.0, "batch_reward": 0.6868103083372116, "critic_loss": 1.400596519291401, "actor_loss": -69.7666136932373, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.608622312545776, "step": 29000}
{"episode_reward": 940.1186778405457, "episode": 30.0, "batch_reward": 0.6924161092042923, "critic_loss": 1.374193092942238, "actor_loss": -70.88681880187988, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.354904651641846, "step": 30000}
{"episode_reward": 938.5668051009372, "episode": 31.0, "batch_reward": 0.7009844109416008, "critic_loss": 1.3346332730650903, "actor_loss": -71.88734159851074, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.71656060218811, "step": 31000}
{"episode_reward": 866.7201939236423, "episode": 32.0, "batch_reward": 0.7035168678760528, "critic_loss": 1.5067986532449722, "actor_loss": -72.23114469909667, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.589648962020874, "step": 32000}
{"episode_reward": 798.6058148345238, "episode": 33.0, "batch_reward": 0.7074686731696129, "critic_loss": 1.3322617295980455, "actor_loss": -72.92460502624512, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.55093741416931, "step": 33000}
{"episode_reward": 858.3496335827907, "episode": 34.0, "batch_reward": 0.7159733229875564, "critic_loss": 1.2914886626601219, "actor_loss": -73.58820402526855, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.764694690704346, "step": 34000}
{"episode_reward": 939.9499654494392, "episode": 35.0, "batch_reward": 0.7181580035686493, "critic_loss": 1.3423403733372687, "actor_loss": -74.0510899963379, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.86613130569458, "step": 35000}
{"episode_reward": 869.4049163324237, "episode": 36.0, "batch_reward": 0.7257352168560028, "critic_loss": 1.2989468956589698, "actor_loss": -74.7686584777832, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.594544649124146, "step": 36000}
{"episode_reward": 895.2529517469114, "episode": 37.0, "batch_reward": 0.7305073133111, "critic_loss": 1.317820357143879, "actor_loss": -75.43023686218261, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.372616052627563, "step": 37000}
{"episode_reward": 951.9736901688361, "episode": 38.0, "batch_reward": 0.736152341902256, "critic_loss": 1.3539175384044648, "actor_loss": -75.65610325622559, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.776219606399536, "step": 38000}
{"episode_reward": 883.3710003006059, "episode": 39.0, "batch_reward": 0.7382057211995124, "critic_loss": 1.3353677068352698, "actor_loss": -76.1616900177002, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.866705417633057, "step": 39000}
{"episode_reward": 865.2276706284703, "episode": 40.0, "batch_reward": 0.7421857329010964, "critic_loss": 1.2742238339185714, "actor_loss": -76.5919700164795, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.006455421447754, "step": 40000}
{"episode_reward": 915.8753272867411, "episode": 41.0, "batch_reward": 0.7470112618803978, "critic_loss": 1.2549784990549087, "actor_loss": -77.19938874816894, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.04101228713989, "step": 41000}
{"episode_reward": 954.6145262707431, "episode": 42.0, "batch_reward": 0.7512789382338524, "critic_loss": 1.2697749242186547, "actor_loss": -77.6751512298584, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.692530632019043, "step": 42000}
{"episode_reward": 948.8740572828553, "episode": 43.0, "batch_reward": 0.7586972564458847, "critic_loss": 1.2226037043333053, "actor_loss": -77.96291436767578, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.84005832672119, "step": 43000}
{"episode_reward": 866.6462260495455, "episode": 44.0, "batch_reward": 0.7570993143320084, "critic_loss": 1.3239673717021943, "actor_loss": -78.3238240814209, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.375470399856567, "step": 44000}
{"episode_reward": 795.6988156880175, "episode": 45.0, "batch_reward": 0.7598422039151191, "critic_loss": 1.2070789600014686, "actor_loss": -78.54084651184083, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.70739221572876, "step": 45000}
{"episode_reward": 922.7695224628673, "episode": 46.0, "batch_reward": 0.7643836743831635, "critic_loss": 1.1421786293387413, "actor_loss": -79.01105772399902, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.820908308029175, "step": 46000}
{"episode_reward": 968.0526896061423, "episode": 47.0, "batch_reward": 0.7661820253729821, "critic_loss": 1.175945569872856, "actor_loss": -79.22591213989257, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.802114486694336, "step": 47000}
{"episode_reward": 862.1172514230896, "episode": 48.0, "batch_reward": 0.7702555716633797, "critic_loss": 1.1913988586068154, "actor_loss": -79.49990148925781, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.58941388130188, "step": 48000}
{"episode_reward": 895.310240193587, "episode": 49.0, "batch_reward": 0.7735657888650894, "critic_loss": 1.13691459941864, "actor_loss": -79.77810601806641, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.411203861236572, "step": 49000}
{"episode_reward": 893.2549330738314, "episode": 50.0, "batch_reward": 0.7754187904000283, "critic_loss": 1.1883866572976112, "actor_loss": -79.95704293823242, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.33446741104126, "step": 50000}
{"episode_reward": 900.5200592357985, "episode": 51.0, "batch_reward": 0.7800249387621879, "critic_loss": 1.1177866936922074, "actor_loss": -80.39123463439941, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.131662130355835, "step": 51000}
{"episode_reward": 980.796585238595, "episode": 52.0, "batch_reward": 0.7811926302909851, "critic_loss": 1.2041920318603516, "actor_loss": -80.59588873291015, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.705721616744995, "step": 52000}
{"episode_reward": 947.7180845197382, "episode": 53.0, "batch_reward": 0.7855085425376892, "critic_loss": 1.1366554797887802, "actor_loss": -80.8841453552246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.72950315475464, "step": 53000}
{"episode_reward": 936.8603845586847, "episode": 54.0, "batch_reward": 0.7876834079623223, "critic_loss": 1.1227421583533288, "actor_loss": -81.24884629821777, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.226417064666748, "step": 54000}
{"episode_reward": 950.4049414697945, "episode": 55.0, "batch_reward": 0.7903771063089371, "critic_loss": 1.0787112319469452, "actor_loss": -81.54710343933105, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.64019536972046, "step": 55000}
{"episode_reward": 971.5875132188812, "episode": 56.0, "batch_reward": 0.7922920849323273, "critic_loss": 1.097869499862194, "actor_loss": -81.84838850402832, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.384155750274658, "step": 56000}
{"episode_reward": 886.4117641384432, "episode": 57.0, "batch_reward": 0.7967811963558197, "critic_loss": 1.058625155031681, "actor_loss": -82.1289868774414, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.50738763809204, "step": 57000}
{"episode_reward": 964.50074522624, "episode": 58.0, "batch_reward": 0.7989191547036171, "critic_loss": 1.0841087354719638, "actor_loss": -82.43472708129883, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.62886929512024, "step": 58000}
{"episode_reward": 952.8084125247892, "episode": 59.0, "batch_reward": 0.8018285699486732, "critic_loss": 1.004467885106802, "actor_loss": -82.64875018310546, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.466389656066895, "step": 59000}
{"episode_reward": 982.1615728300757, "episode": 60.0, "batch_reward": 0.8045492388010025, "critic_loss": 1.0662864173054696, "actor_loss": -82.91125521850586, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.80740213394165, "step": 60000}
{"episode_reward": 909.3595775523398, "episode": 61.0, "batch_reward": 0.806531276524067, "critic_loss": 1.0227005084753036, "actor_loss": -83.14734075927734, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.769519090652466, "step": 61000}
{"episode_reward": 938.3789998665312, "episode": 62.0, "batch_reward": 0.8074533652067184, "critic_loss": 1.0375509114265442, "actor_loss": -83.41645126342773, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.876754999160767, "step": 62000}
{"episode_reward": 969.5876198466357, "episode": 63.0, "batch_reward": 0.8103758675456048, "critic_loss": 1.0213824968636036, "actor_loss": -83.67539059448242, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.80424189567566, "step": 63000}
{"episode_reward": 976.0492574170465, "episode": 64.0, "batch_reward": 0.8149798104763031, "critic_loss": 0.9837117819488048, "actor_loss": -83.90539714050293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.9080228805542, "step": 64000}
{"episode_reward": 932.0467134868272, "episode": 65.0, "batch_reward": 0.815361075937748, "critic_loss": 1.0163990971446037, "actor_loss": -84.11714624023438, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.722371578216553, "step": 65000}
{"episode_reward": 925.3729650724766, "episode": 66.0, "batch_reward": 0.8163571093082428, "critic_loss": 0.978016196757555, "actor_loss": -84.17500450134277, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.54287838935852, "step": 66000}
{"episode_reward": 968.8290741735652, "episode": 67.0, "batch_reward": 0.81965949177742, "critic_loss": 0.8988867727220058, "actor_loss": -84.36396594238282, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.471116065979004, "step": 67000}
{"episode_reward": 917.2928844347751, "episode": 68.0, "batch_reward": 0.820122094810009, "critic_loss": 0.9935016960203648, "actor_loss": -84.47799269104004, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.626797437667847, "step": 68000}
{"episode_reward": 893.2732496011604, "episode": 69.0, "batch_reward": 0.8218029162883759, "critic_loss": 0.8716299237906933, "actor_loss": -84.48690687561034, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.407609701156616, "step": 69000}
{"episode_reward": 953.345807932977, "episode": 70.0, "batch_reward": 0.8242598580121994, "critic_loss": 0.8979400551319122, "actor_loss": -84.71194763183594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.747066020965576, "step": 70000}
{"episode_reward": 948.5961771724183, "episode": 71.0, "batch_reward": 0.8254148964881897, "critic_loss": 0.924038488805294, "actor_loss": -84.81492822265625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.49414372444153, "step": 71000}
{"episode_reward": 949.46308610996, "episode": 72.0, "batch_reward": 0.8282827973365784, "critic_loss": 0.8713667485713958, "actor_loss": -85.03363725280762, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.920023918151855, "step": 72000}
{"episode_reward": 952.9904669548669, "episode": 73.0, "batch_reward": 0.829381613612175, "critic_loss": 0.8653292245268822, "actor_loss": -85.07301091003418, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.87733292579651, "step": 73000}
{"episode_reward": 982.9466334646836, "episode": 74.0, "batch_reward": 0.8322569664120674, "critic_loss": 0.8304674705564976, "actor_loss": -85.3631637878418, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.292154788970947, "step": 74000}
{"episode_reward": 967.8983427177225, "episode": 75.0, "batch_reward": 0.8332687631845475, "critic_loss": 0.8698550130426884, "actor_loss": -85.41167192077637, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.324299573898315, "step": 75000}
{"episode_reward": 898.3782092493078, "episode": 76.0, "batch_reward": 0.8335853018760682, "critic_loss": 0.8950889459252358, "actor_loss": -85.48179734802247, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.367906093597412, "step": 76000}
{"episode_reward": 869.8097572681005, "episode": 77.0, "batch_reward": 0.835568710744381, "critic_loss": 0.8329744698703289, "actor_loss": -85.62129006958008, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.55190396308899, "step": 77000}
{"episode_reward": 974.224227079033, "episode": 78.0, "batch_reward": 0.8346843920946121, "critic_loss": 0.8282959194779396, "actor_loss": -85.77362893676758, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.87773871421814, "step": 78000}
{"episode_reward": 949.4973224351786, "episode": 79.0, "batch_reward": 0.8375148542523384, "critic_loss": 0.8348764380514622, "actor_loss": -85.9713431854248, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.363460302352905, "step": 79000}
{"episode_reward": 928.7382869132744, "episode": 80.0, "batch_reward": 0.8390394071340561, "critic_loss": 0.8512399662435055, "actor_loss": -85.93075955200196, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.798811674118042, "step": 80000}
{"episode_reward": 971.616111640377, "episode": 81.0, "batch_reward": 0.8397226685285568, "critic_loss": 0.874422977745533, "actor_loss": -86.0123137664795, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.61819124221802, "step": 81000}
{"episode_reward": 913.1217858158683, "episode": 82.0, "batch_reward": 0.8406213937401772, "critic_loss": 0.8408219777643681, "actor_loss": -86.1553516998291, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.9461612701416, "step": 82000}
{"episode_reward": 964.3899361371202, "episode": 83.0, "batch_reward": 0.841172167956829, "critic_loss": 0.8398289414048195, "actor_loss": -86.03607086181641, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.80467391014099, "step": 83000}
{"episode_reward": 921.7962371009291, "episode": 84.0, "batch_reward": 0.844330587208271, "critic_loss": 0.8386948840618134, "actor_loss": -86.30673219299317, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.03109574317932, "step": 84000}
{"episode_reward": 923.6827059217336, "episode": 85.0, "batch_reward": 0.8436257724165916, "critic_loss": 0.8588659813404084, "actor_loss": -86.40970977783203, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.693332195281982, "step": 85000}
{"episode_reward": 950.3177150093807, "episode": 86.0, "batch_reward": 0.8444826317429542, "critic_loss": 0.8240617382526397, "actor_loss": -86.33597521972656, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.258876085281372, "step": 86000}
{"episode_reward": 951.8397027172127, "episode": 87.0, "batch_reward": 0.8462523900866509, "critic_loss": 0.8271841698884964, "actor_loss": -86.57885997009278, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.36730194091797, "step": 87000}
{"episode_reward": 815.6262082146585, "episode": 88.0, "batch_reward": 0.8451336586475372, "critic_loss": 0.8734677583873272, "actor_loss": -86.48529225158691, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.710745573043823, "step": 88000}
{"episode_reward": 889.2442944445377, "episode": 89.0, "batch_reward": 0.8474252825379371, "critic_loss": 0.8178764282166958, "actor_loss": -86.85645500183105, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.649033069610596, "step": 89000}
{"episode_reward": 975.8903628075492, "episode": 90.0, "batch_reward": 0.8483098750710487, "critic_loss": 0.8498455064296723, "actor_loss": -87.10704023742676, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.760408639907837, "step": 90000}
{"episode_reward": 971.6295306207743, "episode": 91.0, "batch_reward": 0.8474517174363136, "critic_loss": 0.8571903222799301, "actor_loss": -86.91508950805664, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.94566011428833, "step": 91000}
{"episode_reward": 724.8197346136895, "episode": 92.0, "batch_reward": 0.84874680352211, "critic_loss": 0.9176326697170735, "actor_loss": -86.98322402954102, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.286640644073486, "step": 92000}
{"episode_reward": 953.7226309063722, "episode": 93.0, "batch_reward": 0.8502853977680206, "critic_loss": 0.9038619729876518, "actor_loss": -87.15851791381836, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.85653805732727, "step": 93000}
{"episode_reward": 903.4931548340127, "episode": 94.0, "batch_reward": 0.8489881772994995, "critic_loss": 0.9682967282533645, "actor_loss": -87.01704864501953, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.557552814483643, "step": 94000}
{"episode_reward": 864.0984314490995, "episode": 95.0, "batch_reward": 0.8492556930184364, "critic_loss": 0.8967791714668274, "actor_loss": -87.26532568359374, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.446539640426636, "step": 95000}
{"episode_reward": 889.3327425734633, "episode": 96.0, "batch_reward": 0.8496547041535377, "critic_loss": 0.9418838870227337, "actor_loss": -86.87567835998536, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.861921072006226, "step": 96000}
{"episode_reward": 796.213064850297, "episode": 97.0, "batch_reward": 0.8490196250081062, "critic_loss": 0.9585166716277599, "actor_loss": -87.08029335021973, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.846877336502075, "step": 97000}
{"episode_reward": 944.3333378254988, "episode": 98.0, "batch_reward": 0.8489926280975342, "critic_loss": 0.9504184266626835, "actor_loss": -87.3586326599121, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.674798488616943, "step": 98000}
{"episode_reward": 850.4359214491328, "episode": 99.0, "batch_reward": 0.8508272626399994, "critic_loss": 0.9253666425645352, "actor_loss": -87.09544944763184, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.53970170021057, "step": 99000}
{"episode_reward": 941.1304999398329, "episode": 100.0, "batch_reward": 0.8509569818973541, "critic_loss": 0.9132961038649082, "actor_loss": -87.19344316101075, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.646098136901855, "step": 100000}
{"episode_reward": 965.1663882683762, "episode": 101.0, "batch_reward": 0.8539088886976242, "critic_loss": 0.9546793682277203, "actor_loss": -87.1447275390625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.85549283027649, "step": 101000}
{"episode_reward": 970.0607618968586, "episode": 102.0, "batch_reward": 0.8545301145911217, "critic_loss": 0.9335583946406841, "actor_loss": -87.39231091308594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.857552766799927, "step": 102000}
{"episode_reward": 967.1694324591482, "episode": 103.0, "batch_reward": 0.8549351983070373, "critic_loss": 0.9023572810888291, "actor_loss": -87.56806956481934, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.52084231376648, "step": 103000}
{"episode_reward": 944.9641342179104, "episode": 104.0, "batch_reward": 0.8553187968730926, "critic_loss": 0.9768800146281719, "actor_loss": -87.46014805603028, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.78676128387451, "step": 104000}
{"episode_reward": 892.8480250244219, "episode": 105.0, "batch_reward": 0.8569071727991104, "critic_loss": 0.9283414013981819, "actor_loss": -87.48911309814453, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.847766876220703, "step": 105000}
{"episode_reward": 948.3029494515597, "episode": 106.0, "batch_reward": 0.8573990095853805, "critic_loss": 0.9584769218862057, "actor_loss": -87.62283117675781, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.47088074684143, "step": 106000}
{"episode_reward": 898.1660721664229, "episode": 107.0, "batch_reward": 0.8581935316324234, "critic_loss": 0.9531409624218941, "actor_loss": -87.65438958740235, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.578208684921265, "step": 107000}
{"episode_reward": 856.5491962970648, "episode": 108.0, "batch_reward": 0.8570816615819931, "critic_loss": 0.941817831993103, "actor_loss": -87.83791250610352, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.27203130722046, "step": 108000}
{"episode_reward": 953.2291014459344, "episode": 109.0, "batch_reward": 0.8579845790863037, "critic_loss": 0.9453812335133552, "actor_loss": -87.84363104248047, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.541398525238037, "step": 109000}
{"episode_reward": 952.8234196692872, "episode": 110.0, "batch_reward": 0.859028190433979, "critic_loss": 0.9969010843336582, "actor_loss": -87.81435182189941, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.817853689193726, "step": 110000}
{"episode_reward": 873.1418114489071, "episode": 111.0, "batch_reward": 0.8604431066513062, "critic_loss": 0.9365466958284379, "actor_loss": -88.09586436462402, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.59494686126709, "step": 111000}
{"episode_reward": 963.581713479071, "episode": 112.0, "batch_reward": 0.8625687456727028, "critic_loss": 0.9462029254734516, "actor_loss": -87.85238821411133, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.820809364318848, "step": 112000}
{"episode_reward": 972.2942523031492, "episode": 113.0, "batch_reward": 0.8622848552465439, "critic_loss": 0.9353896619975567, "actor_loss": -88.09740185546875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.630819082260132, "step": 113000}
{"episode_reward": 976.7224465652325, "episode": 114.0, "batch_reward": 0.8618426379561425, "critic_loss": 0.9444335980415344, "actor_loss": -88.00661882019043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.60517382621765, "step": 114000}
{"episode_reward": 968.5318677286016, "episode": 115.0, "batch_reward": 0.863347818672657, "critic_loss": 0.9144885396659375, "actor_loss": -88.12562316894531, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.810741662979126, "step": 115000}
{"episode_reward": 910.7660132822098, "episode": 116.0, "batch_reward": 0.8650188897252082, "critic_loss": 0.9014785122275353, "actor_loss": -88.28821769714355, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.70681595802307, "step": 116000}
{"episode_reward": 895.9482615564754, "episode": 117.0, "batch_reward": 0.8625215030908585, "critic_loss": 0.9462097436487674, "actor_loss": -88.27715725708008, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.676240921020508, "step": 117000}
{"episode_reward": 853.4967795050925, "episode": 118.0, "batch_reward": 0.8637244824171066, "critic_loss": 0.9675751053690911, "actor_loss": -88.20389866638183, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.67498779296875, "step": 118000}
{"episode_reward": 955.0601683476394, "episode": 119.0, "batch_reward": 0.8654709264039994, "critic_loss": 0.9624944537580014, "actor_loss": -88.35239540100098, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.49782156944275, "step": 119000}
{"episode_reward": 977.103685881544, "episode": 120.0, "batch_reward": 0.8655995751619339, "critic_loss": 0.9263180372714996, "actor_loss": -88.47511763000489, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.709272861480713, "step": 120000}
{"episode_reward": 946.4261956407707, "episode": 121.0, "batch_reward": 0.8655664799809456, "critic_loss": 0.9012728272676468, "actor_loss": -88.37811563110351, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.02098083496094, "step": 121000}
{"episode_reward": 935.802843826988, "episode": 122.0, "batch_reward": 0.8670207352042199, "critic_loss": 0.9342778953909874, "actor_loss": -88.51789323425292, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.170621871948242, "step": 122000}
{"episode_reward": 896.6303574752784, "episode": 123.0, "batch_reward": 0.8671770705580711, "critic_loss": 0.9003913985192775, "actor_loss": -88.50413758850098, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.77960729598999, "step": 123000}
{"episode_reward": 979.5807215111379, "episode": 124.0, "batch_reward": 0.868668880224228, "critic_loss": 0.9035967081785202, "actor_loss": -88.4254207458496, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.138598918914795, "step": 124000}
{"episode_reward": 978.9491668152605, "episode": 125.0, "batch_reward": 0.8689746115207672, "critic_loss": 0.8927056047022343, "actor_loss": -88.51554116821289, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.733813285827637, "step": 125000}
{"episode_reward": 968.8599493638901, "episode": 126.0, "batch_reward": 0.8703431534171104, "critic_loss": 0.8343418248593807, "actor_loss": -88.74092785644531, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.75477170944214, "step": 126000}
{"episode_reward": 977.0398365166363, "episode": 127.0, "batch_reward": 0.8702391100525856, "critic_loss": 0.8578604678213596, "actor_loss": -88.53826818847656, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.410280227661133, "step": 127000}
{"episode_reward": 935.2212099476386, "episode": 128.0, "batch_reward": 0.8708590825796128, "critic_loss": 0.8636046051383018, "actor_loss": -88.66633404541015, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.382866144180298, "step": 128000}
{"episode_reward": 964.8931357112983, "episode": 129.0, "batch_reward": 0.8707830601334572, "critic_loss": 0.8140866292715072, "actor_loss": -88.81707463073731, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.02621865272522, "step": 129000}
{"episode_reward": 973.8902842485522, "episode": 130.0, "batch_reward": 0.8748958175182342, "critic_loss": 0.7987974815368653, "actor_loss": -88.95561434936523, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.598522186279297, "step": 130000}
{"episode_reward": 925.3871228737964, "episode": 131.0, "batch_reward": 0.872817283809185, "critic_loss": 0.8280523744523525, "actor_loss": -88.85946180725098, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.97333312034607, "step": 131000}
{"episode_reward": 942.1734243422693, "episode": 132.0, "batch_reward": 0.8722423233389854, "critic_loss": 0.7881431249082088, "actor_loss": -88.95088218688964, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.34748125076294, "step": 132000}
{"episode_reward": 949.1074308011508, "episode": 133.0, "batch_reward": 0.8749461701512337, "critic_loss": 0.7938204738348722, "actor_loss": -89.20411920166016, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.698050498962402, "step": 133000}
{"episode_reward": 961.4624348188474, "episode": 134.0, "batch_reward": 0.8751186109185218, "critic_loss": 0.7978580984771252, "actor_loss": -89.14595547485352, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.697267532348633, "step": 134000}
{"episode_reward": 939.2074316347363, "episode": 135.0, "batch_reward": 0.8765954434871673, "critic_loss": 0.8097186084985734, "actor_loss": -89.00350540161133, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.418750524520874, "step": 135000}
{"episode_reward": 941.5278255277829, "episode": 136.0, "batch_reward": 0.8768786378502845, "critic_loss": 0.8047260273098945, "actor_loss": -89.34074465942383, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.16556692123413, "step": 136000}
{"episode_reward": 935.5856006188577, "episode": 137.0, "batch_reward": 0.8759824442863464, "critic_loss": 0.8173703794777394, "actor_loss": -89.18048826599122, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.40434956550598, "step": 137000}
{"episode_reward": 962.6521528581877, "episode": 138.0, "batch_reward": 0.8784362103939056, "critic_loss": 0.7823609645664692, "actor_loss": -89.07175389099122, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.65852999687195, "step": 138000}
{"episode_reward": 979.5086991132403, "episode": 139.0, "batch_reward": 0.8779423454403877, "critic_loss": 0.8275024517774582, "actor_loss": -89.5549094543457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.81960701942444, "step": 139000}
{"episode_reward": 942.6342438963053, "episode": 140.0, "batch_reward": 0.8796113112568855, "critic_loss": 0.7649025070667267, "actor_loss": -89.36187533569336, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.852834701538086, "step": 140000}
{"episode_reward": 967.6173410038059, "episode": 141.0, "batch_reward": 0.8771972277164459, "critic_loss": 0.8127622791826725, "actor_loss": -89.05706314086915, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.85670280456543, "step": 141000}
{"episode_reward": 826.1505158204193, "episode": 142.0, "batch_reward": 0.8772351694107056, "critic_loss": 0.7885240694284439, "actor_loss": -89.41826795959473, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.55794405937195, "step": 142000}
{"episode_reward": 951.2516996494871, "episode": 143.0, "batch_reward": 0.8780461766123772, "critic_loss": 0.7775995410978794, "actor_loss": -89.49029270935058, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.75113272666931, "step": 143000}
{"episode_reward": 974.9997127146714, "episode": 144.0, "batch_reward": 0.8805590649843216, "critic_loss": 0.7379645431935787, "actor_loss": -89.57230195617676, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.90625023841858, "step": 144000}
{"episode_reward": 936.6272213488245, "episode": 145.0, "batch_reward": 0.8799327734708786, "critic_loss": 0.7762678475379944, "actor_loss": -89.43008892822266, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.248974800109863, "step": 145000}
{"episode_reward": 868.1549453035885, "episode": 146.0, "batch_reward": 0.8797107657194138, "critic_loss": 0.7719719063639641, "actor_loss": -89.37418031311036, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.041667222976685, "step": 146000}
{"episode_reward": 984.3603131896748, "episode": 147.0, "batch_reward": 0.8799028422832489, "critic_loss": 0.7905248529613018, "actor_loss": -89.55838984680176, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.56588912010193, "step": 147000}
{"episode_reward": 837.2750394001273, "episode": 148.0, "batch_reward": 0.8790583153367042, "critic_loss": 0.799167886853218, "actor_loss": -89.54191287231446, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.88006901741028, "step": 148000}
{"episode_reward": 850.8340386590421, "episode": 149.0, "batch_reward": 0.8806325491070748, "critic_loss": 0.7726417033672333, "actor_loss": -89.70404397583007, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.05850577354431, "step": 149000}
{"episode_reward": 969.0905075721088, "episode": 150.0, "batch_reward": 0.8794282357096672, "critic_loss": 0.7839796453416348, "actor_loss": -89.47929737854004, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
