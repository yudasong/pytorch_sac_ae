{"episode_reward": 0.0, "episode": 1.0, "duration": 23.824153900146484, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.9790406227111816, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.3004354635907555, "critic_loss": 0.8273436166755992, "actor_loss": -70.62199477569348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 66.4119462966919, "step": 3000}
{"episode_reward": 586.5005952396567, "episode": 4.0, "batch_reward": 0.41927255809307096, "critic_loss": 1.2152378270030022, "actor_loss": -72.97084652709961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.628506183624268, "step": 4000}
{"episode_reward": 700.2450709297456, "episode": 5.0, "batch_reward": 0.46773315796256065, "critic_loss": 1.4336529101133346, "actor_loss": -73.50423094177246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.658379316329956, "step": 5000}
{"episode_reward": 579.2416920849055, "episode": 6.0, "batch_reward": 0.49568551498651503, "critic_loss": 1.5029238280653954, "actor_loss": -73.75578663635254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.7779278755188, "step": 6000}
{"episode_reward": 719.0899408376672, "episode": 7.0, "batch_reward": 0.5296163836717606, "critic_loss": 1.6284061585068703, "actor_loss": -74.11620097351074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.59386968612671, "step": 7000}
{"episode_reward": 583.3604065796525, "episode": 8.0, "batch_reward": 0.5522559786736965, "critic_loss": 1.5671360135674477, "actor_loss": -74.27984516906739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.788967609405518, "step": 8000}
{"episode_reward": 824.6785379398042, "episode": 9.0, "batch_reward": 0.5850939821600915, "critic_loss": 1.5829329217672348, "actor_loss": -74.75526229858399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.03293013572693, "step": 9000}
{"episode_reward": 853.3217903403569, "episode": 10.0, "batch_reward": 0.612245728969574, "critic_loss": 1.6063040342330932, "actor_loss": -75.30054367065429, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.827559232711792, "step": 10000}
{"episode_reward": 815.3108061967422, "episode": 11.0, "batch_reward": 0.6291949579119682, "critic_loss": 1.6540633445978166, "actor_loss": -75.70325268554687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.309539794921875, "step": 11000}
{"episode_reward": 793.2658330422729, "episode": 12.0, "batch_reward": 0.611998100310564, "critic_loss": 1.6553914414048194, "actor_loss": -76.16923530578613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.747305870056152, "step": 12000}
{"episode_reward": 26.63652571329494, "episode": 13.0, "batch_reward": 0.5896432012021542, "critic_loss": 1.6349603276848792, "actor_loss": -75.79243180847168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.524444341659546, "step": 13000}
{"episode_reward": 719.5168685996045, "episode": 14.0, "batch_reward": 0.6023986647129059, "critic_loss": 1.4998244351148606, "actor_loss": -75.80039978027344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.93366003036499, "step": 14000}
{"episode_reward": 766.2239739135551, "episode": 15.0, "batch_reward": 0.6182746523618698, "critic_loss": 1.417996023952961, "actor_loss": -75.79959315490723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.585988998413086, "step": 15000}
{"episode_reward": 879.1429622871756, "episode": 16.0, "batch_reward": 0.6352742254137993, "critic_loss": 1.242876433312893, "actor_loss": -76.04077528381347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.910933256149292, "step": 16000}
{"episode_reward": 903.910437234685, "episode": 17.0, "batch_reward": 0.6426688636541367, "critic_loss": 1.200395391702652, "actor_loss": -76.04630990600586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.289623260498047, "step": 17000}
{"episode_reward": 716.0251247166495, "episode": 18.0, "batch_reward": 0.632245274245739, "critic_loss": 1.1522771458029748, "actor_loss": -75.5105298461914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.295276641845703, "step": 18000}
{"episode_reward": 51.472399791403355, "episode": 19.0, "batch_reward": 0.6187474603056907, "critic_loss": 1.090691881299019, "actor_loss": -74.84081300354003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.974912405014038, "step": 19000}
{"episode_reward": 830.3461954405518, "episode": 20.0, "batch_reward": 0.6321713148355484, "critic_loss": 1.0545425928235055, "actor_loss": -74.69695654296875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.655757904052734, "step": 20000}
{"episode_reward": 828.4112989222076, "episode": 21.0, "batch_reward": 0.6423769283890725, "critic_loss": 0.9941190475225449, "actor_loss": -74.91926438903809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.64072036743164, "step": 21000}
{"episode_reward": 925.0207662399519, "episode": 22.0, "batch_reward": 0.6559769245386123, "critic_loss": 0.9986163903474807, "actor_loss": -74.90866766357422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.565508365631104, "step": 22000}
{"episode_reward": 863.9944384714283, "episode": 23.0, "batch_reward": 0.6627024849057197, "critic_loss": 1.0385376091599465, "actor_loss": -75.14632203674316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.822296380996704, "step": 23000}
{"episode_reward": 863.678657880479, "episode": 24.0, "batch_reward": 0.6726777608394623, "critic_loss": 1.0576186336278914, "actor_loss": -75.36132917785645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21640396118164, "step": 24000}
{"episode_reward": 878.3513456763588, "episode": 25.0, "batch_reward": 0.678622067630291, "critic_loss": 1.0922850722074509, "actor_loss": -75.60404566955566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.11678981781006, "step": 25000}
{"episode_reward": 857.4426853390542, "episode": 26.0, "batch_reward": 0.6883108725547791, "critic_loss": 1.1662822684645653, "actor_loss": -76.05781675720215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.864272356033325, "step": 26000}
{"episode_reward": 844.4532875670145, "episode": 27.0, "batch_reward": 0.6938508306741714, "critic_loss": 1.1309277671575546, "actor_loss": -76.06218766784669, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.548396110534668, "step": 27000}
{"episode_reward": 880.6826546931901, "episode": 28.0, "batch_reward": 0.6981733455061913, "critic_loss": 1.0770304417014123, "actor_loss": -76.51188465881347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.885836124420166, "step": 28000}
{"episode_reward": 827.7260888207069, "episode": 29.0, "batch_reward": 0.7061251984834671, "critic_loss": 1.0562896365523338, "actor_loss": -76.55986767578125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.41753077507019, "step": 29000}
{"episode_reward": 921.171800522962, "episode": 30.0, "batch_reward": 0.7119562919139862, "critic_loss": 1.0704301641583442, "actor_loss": -77.08990791320801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.3796489238739, "step": 30000}
{"episode_reward": 928.5309416898361, "episode": 31.0, "batch_reward": 0.7181799413561821, "critic_loss": 1.0730288486480712, "actor_loss": -77.52919204711914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.57707166671753, "step": 31000}
{"episode_reward": 809.6359767113511, "episode": 32.0, "batch_reward": 0.7234778493642807, "critic_loss": 1.0664304645061493, "actor_loss": -77.78371052551269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.51914143562317, "step": 32000}
{"episode_reward": 909.7185840951928, "episode": 33.0, "batch_reward": 0.7295343606472016, "critic_loss": 1.0332044895887376, "actor_loss": -78.10269172668457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.990283966064453, "step": 33000}
{"episode_reward": 925.2944315601292, "episode": 34.0, "batch_reward": 0.7341933844089508, "critic_loss": 0.9808496268987655, "actor_loss": -78.46668515014649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.552708625793457, "step": 34000}
{"episode_reward": 922.1599328108207, "episode": 35.0, "batch_reward": 0.7343766123056412, "critic_loss": 1.1154997228980064, "actor_loss": -78.49113597106934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.650234699249268, "step": 35000}
{"episode_reward": 692.2056378196816, "episode": 36.0, "batch_reward": 0.7400395945310593, "critic_loss": 1.1189235807061195, "actor_loss": -78.71484442138672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.872512102127075, "step": 36000}
{"episode_reward": 898.8868650916017, "episode": 37.0, "batch_reward": 0.745189133822918, "critic_loss": 1.1525745663642883, "actor_loss": -79.05313259887696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.780936002731323, "step": 37000}
{"episode_reward": 913.6075491029684, "episode": 38.0, "batch_reward": 0.747454807639122, "critic_loss": 1.1429536371827125, "actor_loss": -79.0245951385498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.326452255249023, "step": 38000}
{"episode_reward": 847.2665188519993, "episode": 39.0, "batch_reward": 0.7517997294664382, "critic_loss": 1.0960357230901718, "actor_loss": -79.43048750305175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97625184059143, "step": 39000}
{"episode_reward": 932.3352511126485, "episode": 40.0, "batch_reward": 0.7548386254906654, "critic_loss": 1.1149763053059578, "actor_loss": -79.68293128967285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.325814723968506, "step": 40000}
{"episode_reward": 914.7843554821192, "episode": 41.0, "batch_reward": 0.7586819363832473, "critic_loss": 1.07702096170187, "actor_loss": -80.10074296569825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.18559980392456, "step": 41000}
{"episode_reward": 923.9526482701084, "episode": 42.0, "batch_reward": 0.7637859396934509, "critic_loss": 1.0268451330065727, "actor_loss": -80.44634146118165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.377093076705933, "step": 42000}
{"episode_reward": 962.6599640885395, "episode": 43.0, "batch_reward": 0.7675715253949166, "critic_loss": 0.9780827741026878, "actor_loss": -80.73796089172363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.83700919151306, "step": 43000}
{"episode_reward": 925.1082240120376, "episode": 44.0, "batch_reward": 0.7712577516436577, "critic_loss": 0.9887561186254025, "actor_loss": -81.06885110473632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.673879384994507, "step": 44000}
{"episode_reward": 899.8328368809963, "episode": 45.0, "batch_reward": 0.7753936969041825, "critic_loss": 0.944763272434473, "actor_loss": -81.41144441223145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.885141849517822, "step": 45000}
{"episode_reward": 963.3833298523572, "episode": 46.0, "batch_reward": 0.7808857614994049, "critic_loss": 0.9559635905623436, "actor_loss": -81.84326599121094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.636653900146484, "step": 46000}
{"episode_reward": 932.4054475270051, "episode": 47.0, "batch_reward": 0.7824381643533707, "critic_loss": 0.884952205747366, "actor_loss": -82.01823483276367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.968109369277954, "step": 47000}
{"episode_reward": 953.75473705583, "episode": 48.0, "batch_reward": 0.7871758970022201, "critic_loss": 0.8501925870776177, "actor_loss": -82.41718685913087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.432143926620483, "step": 48000}
{"episode_reward": 953.1710663653578, "episode": 49.0, "batch_reward": 0.7885339222550393, "critic_loss": 0.8787408112883568, "actor_loss": -82.72082644653321, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.466518878936768, "step": 49000}
{"episode_reward": 881.3929313929434, "episode": 50.0, "batch_reward": 0.7911261206865311, "critic_loss": 0.8222005974650383, "actor_loss": -82.96118489074708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.921165466308594, "step": 50000}
{"episode_reward": 927.8856793300379, "episode": 51.0, "batch_reward": 0.7948220723867416, "critic_loss": 0.796391565054655, "actor_loss": -83.34699411010742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.81877017021179, "step": 51000}
{"episode_reward": 955.7715457552366, "episode": 52.0, "batch_reward": 0.7941203462481499, "critic_loss": 0.8499608387053013, "actor_loss": -83.42780961608887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.87310552597046, "step": 52000}
{"episode_reward": 857.4200418605242, "episode": 53.0, "batch_reward": 0.7968125221133232, "critic_loss": 0.8450342290401459, "actor_loss": -83.80569213867187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.408037185668945, "step": 53000}
{"episode_reward": 864.9213329074987, "episode": 54.0, "batch_reward": 0.7966771568059922, "critic_loss": 0.9115784208476544, "actor_loss": -84.01667010498046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.944618940353394, "step": 54000}
{"episode_reward": 800.9236957210594, "episode": 55.0, "batch_reward": 0.7984448738694191, "critic_loss": 0.915947008818388, "actor_loss": -84.18930056762696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.832706212997437, "step": 55000}
{"episode_reward": 933.1156692179754, "episode": 56.0, "batch_reward": 0.8026427198648453, "critic_loss": 0.9411887741982937, "actor_loss": -84.58571908569336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.733023643493652, "step": 56000}
{"episode_reward": 967.1764357538381, "episode": 57.0, "batch_reward": 0.8045523382425308, "critic_loss": 0.9118725419938565, "actor_loss": -84.77189659118652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.076833486557007, "step": 57000}
{"episode_reward": 916.8482333658018, "episode": 58.0, "batch_reward": 0.8060490779280662, "critic_loss": 0.9436556656360626, "actor_loss": -85.06735899353028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.338677644729614, "step": 58000}
{"episode_reward": 884.3618446865144, "episode": 59.0, "batch_reward": 0.8080230250954628, "critic_loss": 0.9148789210915566, "actor_loss": -85.33078507995606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.02885413169861, "step": 59000}
{"episode_reward": 962.0468818359848, "episode": 60.0, "batch_reward": 0.8101340200304985, "critic_loss": 0.9417300582230091, "actor_loss": -85.47510791015625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.314416646957397, "step": 60000}
{"episode_reward": 908.4660907710124, "episode": 61.0, "batch_reward": 0.8119454054236412, "critic_loss": 0.922447673290968, "actor_loss": -85.58753887939453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.33496856689453, "step": 61000}
{"episode_reward": 899.2191160705631, "episode": 62.0, "batch_reward": 0.8131861212849617, "critic_loss": 0.8704895452857018, "actor_loss": -85.82737814331054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.342279195785522, "step": 62000}
{"episode_reward": 975.8367528210299, "episode": 63.0, "batch_reward": 0.8164242307543754, "critic_loss": 0.8928347868323326, "actor_loss": -85.94244094848632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.906192779541016, "step": 63000}
{"episode_reward": 970.5706858466606, "episode": 64.0, "batch_reward": 0.8177674765586853, "critic_loss": 0.9087537857592106, "actor_loss": -86.05665327453613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.610400676727295, "step": 64000}
{"episode_reward": 910.5805605481812, "episode": 65.0, "batch_reward": 0.819256192445755, "critic_loss": 0.9570150040686131, "actor_loss": -86.36728184509278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.77465844154358, "step": 65000}
{"episode_reward": 899.3319596674521, "episode": 66.0, "batch_reward": 0.8214225839972497, "critic_loss": 0.9541871643960476, "actor_loss": -86.39512916564941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.77625036239624, "step": 66000}
{"episode_reward": 964.9271981657009, "episode": 67.0, "batch_reward": 0.8229688636660576, "critic_loss": 0.9872785777747631, "actor_loss": -86.56035305786133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.55378031730652, "step": 67000}
{"episode_reward": 840.0384310588677, "episode": 68.0, "batch_reward": 0.8226494044065475, "critic_loss": 1.0218052019178867, "actor_loss": -86.6243653869629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.017308235168457, "step": 68000}
{"episode_reward": 902.2977535541315, "episode": 69.0, "batch_reward": 0.8256201452612877, "critic_loss": 0.9850226949453353, "actor_loss": -86.6221981048584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.744450330734253, "step": 69000}
{"episode_reward": 970.8672306669846, "episode": 70.0, "batch_reward": 0.8271435422897339, "critic_loss": 0.9547528263628483, "actor_loss": -86.83295533752441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.236151933670044, "step": 70000}
{"episode_reward": 897.7691020742245, "episode": 71.0, "batch_reward": 0.8268544569611549, "critic_loss": 0.9382928242087364, "actor_loss": -86.82014456176758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.110509634017944, "step": 71000}
{"episode_reward": 948.7089470028635, "episode": 72.0, "batch_reward": 0.8305780024528503, "critic_loss": 0.9045794153511524, "actor_loss": -86.99109982299805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.909907579421997, "step": 72000}
{"episode_reward": 913.7350371938908, "episode": 73.0, "batch_reward": 0.831321552336216, "critic_loss": 0.8874368707239628, "actor_loss": -86.96963507080078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.67129111289978, "step": 73000}
{"episode_reward": 975.0460479833597, "episode": 74.0, "batch_reward": 0.8322451341152192, "critic_loss": 0.937176089078188, "actor_loss": -87.18047946166992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.32218313217163, "step": 74000}
{"episode_reward": 868.028798905849, "episode": 75.0, "batch_reward": 0.8332214753627777, "critic_loss": 0.9358370196819306, "actor_loss": -87.24012522888184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.106101751327515, "step": 75000}
{"episode_reward": 887.9795299188179, "episode": 76.0, "batch_reward": 0.8334568377137184, "critic_loss": 0.9184921347200871, "actor_loss": -87.1999375152588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.44349765777588, "step": 76000}
{"episode_reward": 915.3095758605017, "episode": 77.0, "batch_reward": 0.8366171234846115, "critic_loss": 0.9181716644763946, "actor_loss": -87.35210554504394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.519815921783447, "step": 77000}
{"episode_reward": 973.360609736533, "episode": 78.0, "batch_reward": 0.8355396069288253, "critic_loss": 0.937887060135603, "actor_loss": -87.45045895385742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.73822045326233, "step": 78000}
{"episode_reward": 926.7801857109453, "episode": 79.0, "batch_reward": 0.8372644674777985, "critic_loss": 0.9652019166350365, "actor_loss": -87.65618226623535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.299381971359253, "step": 79000}
{"episode_reward": 914.5377993784948, "episode": 80.0, "batch_reward": 0.8382512277364731, "critic_loss": 0.9745501335263252, "actor_loss": -87.57197120666504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.599268913269043, "step": 80000}
{"episode_reward": 959.514999143142, "episode": 81.0, "batch_reward": 0.8402219296097756, "critic_loss": 0.9352623282372952, "actor_loss": -87.67264965820313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.137521266937256, "step": 81000}
{"episode_reward": 937.5253243517049, "episode": 82.0, "batch_reward": 0.8409250347614289, "critic_loss": 0.9254538832902909, "actor_loss": -87.85434938049316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.674285650253296, "step": 82000}
{"episode_reward": 952.1818056506621, "episode": 83.0, "batch_reward": 0.8427640482783317, "critic_loss": 0.9244328548908234, "actor_loss": -87.75781880187988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.520349264144897, "step": 83000}
{"episode_reward": 946.2816956256663, "episode": 84.0, "batch_reward": 0.8430445926785469, "critic_loss": 0.9355030680000782, "actor_loss": -87.94393420410157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.92093062400818, "step": 84000}
{"episode_reward": 902.2968267681586, "episode": 85.0, "batch_reward": 0.8438080501556396, "critic_loss": 0.9130385082066059, "actor_loss": -88.01104090881347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.65326762199402, "step": 85000}
{"episode_reward": 913.1710270218023, "episode": 86.0, "batch_reward": 0.8441432481408119, "critic_loss": 0.9630808069705963, "actor_loss": -87.85144490051269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.24215030670166, "step": 86000}
{"episode_reward": 884.0140192775624, "episode": 87.0, "batch_reward": 0.8445674079656601, "critic_loss": 0.9828499448001384, "actor_loss": -88.06043228149414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.32126498222351, "step": 87000}
{"episode_reward": 863.4348520394018, "episode": 88.0, "batch_reward": 0.8462224467992783, "critic_loss": 0.8918784807920456, "actor_loss": -88.006634765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.435235023498535, "step": 88000}
{"episode_reward": 957.1512214096023, "episode": 89.0, "batch_reward": 0.8484076082706451, "critic_loss": 0.8939895907342434, "actor_loss": -88.3073137664795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.12120532989502, "step": 89000}
{"episode_reward": 971.931215720711, "episode": 90.0, "batch_reward": 0.8493178308010101, "critic_loss": 0.8625047134459018, "actor_loss": -88.54032208251954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.091497898101807, "step": 90000}
{"episode_reward": 969.8088368452317, "episode": 91.0, "batch_reward": 0.849384083032608, "critic_loss": 0.908441332012415, "actor_loss": -88.3750678100586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.56749963760376, "step": 91000}
{"episode_reward": 920.197912515222, "episode": 92.0, "batch_reward": 0.8516327006220817, "critic_loss": 0.8341110473871232, "actor_loss": -88.36883151245117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.65204954147339, "step": 92000}
{"episode_reward": 969.4306531617418, "episode": 93.0, "batch_reward": 0.8543729803562164, "critic_loss": 0.8652434734106064, "actor_loss": -88.60473184204102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.123363971710205, "step": 93000}
{"episode_reward": 974.2026179361726, "episode": 94.0, "batch_reward": 0.8535697293281556, "critic_loss": 0.8268727803826332, "actor_loss": -88.57046241760254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.88900852203369, "step": 94000}
{"episode_reward": 947.9495139909175, "episode": 95.0, "batch_reward": 0.8540126115083695, "critic_loss": 0.81900839433074, "actor_loss": -88.85781852722168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.28974437713623, "step": 95000}
{"episode_reward": 951.7153533954465, "episode": 96.0, "batch_reward": 0.8542162075042724, "critic_loss": 0.8230309171676635, "actor_loss": -88.4311390838623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.717832565307617, "step": 96000}
{"episode_reward": 951.0057877210534, "episode": 97.0, "batch_reward": 0.855968249797821, "critic_loss": 0.7749333665072918, "actor_loss": -88.78306340026856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.17477035522461, "step": 97000}
{"episode_reward": 947.0709770353628, "episode": 98.0, "batch_reward": 0.8564013409018516, "critic_loss": 0.8091912035644054, "actor_loss": -89.05491653442382, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.788927793502808, "step": 98000}
{"episode_reward": 885.5675701809218, "episode": 99.0, "batch_reward": 0.8574757074713707, "critic_loss": 0.7842470689415931, "actor_loss": -88.75263916015625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.1876962184906, "step": 99000}
{"episode_reward": 933.6930514414873, "episode": 100.0, "batch_reward": 0.8571302406191826, "critic_loss": 0.7715958736538887, "actor_loss": -88.90427325439452, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.57721710205078, "step": 100000}
{"episode_reward": 974.9756508484894, "episode": 101.0, "batch_reward": 0.8599467012882233, "critic_loss": 0.7468550125956536, "actor_loss": -88.86744543457031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.21430778503418, "step": 101000}
{"episode_reward": 954.215216864565, "episode": 102.0, "batch_reward": 0.8610204538702965, "critic_loss": 0.7406334738135338, "actor_loss": -89.14614305114746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.822554111480713, "step": 102000}
{"episode_reward": 977.5497381910059, "episode": 103.0, "batch_reward": 0.8614382383227348, "critic_loss": 0.7073493257164956, "actor_loss": -89.36401000976562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.7812397480011, "step": 103000}
{"episode_reward": 904.0867066348276, "episode": 104.0, "batch_reward": 0.8616866819858551, "critic_loss": 0.6973563789874315, "actor_loss": -89.20421937561035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.599701166152954, "step": 104000}
{"episode_reward": 962.1641479621446, "episode": 105.0, "batch_reward": 0.864090264081955, "critic_loss": 0.6862714132964611, "actor_loss": -89.21923106384277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.12170100212097, "step": 105000}
{"episode_reward": 972.2614638009921, "episode": 106.0, "batch_reward": 0.8632831583619118, "critic_loss": 0.6914753417372703, "actor_loss": -89.21522996520996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.124239683151245, "step": 106000}
{"episode_reward": 919.0291654352544, "episode": 107.0, "batch_reward": 0.8648302040696144, "critic_loss": 0.6628699848800897, "actor_loss": -89.27464434814453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.87962293624878, "step": 107000}
{"episode_reward": 915.896473143368, "episode": 108.0, "batch_reward": 0.864928883254528, "critic_loss": 0.676230923473835, "actor_loss": -89.53551234436036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.771175622940063, "step": 108000}
{"episode_reward": 947.2034180964941, "episode": 109.0, "batch_reward": 0.8655350585579872, "critic_loss": 0.6777551546096802, "actor_loss": -89.47867422485352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.726001501083374, "step": 109000}
{"episode_reward": 926.99389845533, "episode": 110.0, "batch_reward": 0.8667584664821625, "critic_loss": 0.6787396901249886, "actor_loss": -89.4286220703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.399045944213867, "step": 110000}
{"episode_reward": 952.7458743156709, "episode": 111.0, "batch_reward": 0.8672851687073707, "critic_loss": 0.6772866461277008, "actor_loss": -89.67662185668945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.72865033149719, "step": 111000}
{"episode_reward": 953.5638498838297, "episode": 112.0, "batch_reward": 0.8672567563056945, "critic_loss": 0.6966669116020202, "actor_loss": -89.34812649536133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.87427592277527, "step": 112000}
{"episode_reward": 842.0358949007348, "episode": 113.0, "batch_reward": 0.8686770220398903, "critic_loss": 0.6585204599201679, "actor_loss": -89.49983428955078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.834434032440186, "step": 113000}
{"episode_reward": 973.69147795347, "episode": 114.0, "batch_reward": 0.8666505903601647, "critic_loss": 0.6625279188901186, "actor_loss": -89.36835539245605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.308282375335693, "step": 114000}
{"episode_reward": 974.8671393051039, "episode": 115.0, "batch_reward": 0.8680892310738564, "critic_loss": 0.644544449955225, "actor_loss": -89.49231723022461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.950414419174194, "step": 115000}
{"episode_reward": 905.6314480197017, "episode": 116.0, "batch_reward": 0.8715183373689651, "critic_loss": 0.6932425366342068, "actor_loss": -89.59846514892578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.693368434906006, "step": 116000}
{"episode_reward": 934.6895586009938, "episode": 117.0, "batch_reward": 0.8691330216526986, "critic_loss": 0.6972568423449993, "actor_loss": -89.61644810485839, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.226787328720093, "step": 117000}
{"episode_reward": 939.0543562300364, "episode": 118.0, "batch_reward": 0.8714199633598327, "critic_loss": 0.6920728691518306, "actor_loss": -89.57969728088379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.06069564819336, "step": 118000}
{"episode_reward": 953.8905813435915, "episode": 119.0, "batch_reward": 0.8732380285859108, "critic_loss": 0.6957811131775379, "actor_loss": -89.68623239135742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.388871908187866, "step": 119000}
{"episode_reward": 952.9026950403095, "episode": 120.0, "batch_reward": 0.8732401767373085, "critic_loss": 0.6961739037930965, "actor_loss": -89.80357670593261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.80601668357849, "step": 120000}
{"episode_reward": 971.3266905516047, "episode": 121.0, "batch_reward": 0.8733706557154656, "critic_loss": 0.6842908134609461, "actor_loss": -89.68628329467774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.256821155548096, "step": 121000}
{"episode_reward": 902.1590781915082, "episode": 122.0, "batch_reward": 0.8732165367603302, "critic_loss": 0.6983454582989216, "actor_loss": -89.84300939941406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.190111875534058, "step": 122000}
{"episode_reward": 939.9052210960658, "episode": 123.0, "batch_reward": 0.874386731505394, "critic_loss": 0.7287808127552271, "actor_loss": -89.82014297485351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.764524459838867, "step": 123000}
{"episode_reward": 972.006278848507, "episode": 124.0, "batch_reward": 0.8763236543536186, "critic_loss": 0.7401339474767447, "actor_loss": -89.73159559631348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.351542949676514, "step": 124000}
{"episode_reward": 964.6381150761912, "episode": 125.0, "batch_reward": 0.8760612051486969, "critic_loss": 0.7153917524069547, "actor_loss": -89.87586805725098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.007395267486572, "step": 125000}
{"episode_reward": 973.2861409234723, "episode": 126.0, "batch_reward": 0.8776956441998481, "critic_loss": 0.7044642853736878, "actor_loss": -90.05260556030274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.8298921585083, "step": 126000}
{"episode_reward": 967.1053567529926, "episode": 127.0, "batch_reward": 0.8757661607265472, "critic_loss": 0.6933778177797795, "actor_loss": -89.79752363586425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.904804944992065, "step": 127000}
{"episode_reward": 926.7209937775388, "episode": 128.0, "batch_reward": 0.8769129046201706, "critic_loss": 0.6995488372892141, "actor_loss": -89.91718649291992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.255186080932617, "step": 128000}
{"episode_reward": 967.0622841201208, "episode": 129.0, "batch_reward": 0.8765468042492867, "critic_loss": 0.7360817582309246, "actor_loss": -90.05705278015137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.965542554855347, "step": 129000}
{"episode_reward": 929.3116700007387, "episode": 130.0, "batch_reward": 0.8802354277968407, "critic_loss": 0.7103560276329517, "actor_loss": -90.21144369506835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.773956775665283, "step": 130000}
{"episode_reward": 947.210348815298, "episode": 131.0, "batch_reward": 0.8788610270619392, "critic_loss": 0.7195947851240635, "actor_loss": -90.06454010009766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.59777283668518, "step": 131000}
{"episode_reward": 949.0442463375006, "episode": 132.0, "batch_reward": 0.8790062698721886, "critic_loss": 0.733659004509449, "actor_loss": -90.19056088256836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.725886344909668, "step": 132000}
{"episode_reward": 803.4321871202766, "episode": 133.0, "batch_reward": 0.8790917490720749, "critic_loss": 0.7685345668792725, "actor_loss": -90.32429290771485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.278176069259644, "step": 133000}
{"episode_reward": 967.1261911042386, "episode": 134.0, "batch_reward": 0.8796294165849685, "critic_loss": 0.7568544374406337, "actor_loss": -90.23638862609863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.596903562545776, "step": 134000}
{"episode_reward": 932.5029776552634, "episode": 135.0, "batch_reward": 0.8801197763681412, "critic_loss": 0.7576848524808883, "actor_loss": -89.99780317687988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.48019576072693, "step": 135000}
{"episode_reward": 844.9163975407337, "episode": 136.0, "batch_reward": 0.8791105944514275, "critic_loss": 0.7579232760667801, "actor_loss": -90.34343670654297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.786163330078125, "step": 136000}
{"episode_reward": 876.7907004889581, "episode": 137.0, "batch_reward": 0.8799205635786056, "critic_loss": 0.7791150440722704, "actor_loss": -90.18396813964844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.207778215408325, "step": 137000}
{"episode_reward": 968.3885530593303, "episode": 138.0, "batch_reward": 0.881557199716568, "critic_loss": 0.7644474488496781, "actor_loss": -90.05181726074218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.293758392333984, "step": 138000}
{"episode_reward": 967.5706137388346, "episode": 139.0, "batch_reward": 0.880778005361557, "critic_loss": 0.777088635712862, "actor_loss": -90.57282618713378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.20432949066162, "step": 139000}
{"episode_reward": 948.1011961486562, "episode": 140.0, "batch_reward": 0.8828936966061592, "critic_loss": 0.7415577104389668, "actor_loss": -90.28334573364258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.614714860916138, "step": 140000}
{"episode_reward": 968.2260827280049, "episode": 141.0, "batch_reward": 0.8806110796928406, "critic_loss": 0.7154670975804329, "actor_loss": -90.01438179016114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.16352725028992, "step": 141000}
{"episode_reward": 959.3264845558532, "episode": 142.0, "batch_reward": 0.8818064562082291, "critic_loss": 0.723860217884183, "actor_loss": -90.43020199584961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.15918278694153, "step": 142000}
{"episode_reward": 937.1059583807058, "episode": 143.0, "batch_reward": 0.8816301571130752, "critic_loss": 0.725853620365262, "actor_loss": -90.53062615966797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0366051197052, "step": 143000}
{"episode_reward": 954.1305121043257, "episode": 144.0, "batch_reward": 0.884172320008278, "critic_loss": 0.737213966935873, "actor_loss": -90.55429698181152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.487908601760864, "step": 144000}
{"episode_reward": 939.7226291792134, "episode": 145.0, "batch_reward": 0.8842779630422593, "critic_loss": 0.6881455435603857, "actor_loss": -90.38798640441894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.788254499435425, "step": 145000}
{"episode_reward": 888.4421252890199, "episode": 146.0, "batch_reward": 0.8845947774648666, "critic_loss": 0.7002840795964003, "actor_loss": -90.3755372314453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.933072566986084, "step": 146000}
{"episode_reward": 972.3767644047117, "episode": 147.0, "batch_reward": 0.884648581624031, "critic_loss": 0.701180062174797, "actor_loss": -90.48240055847168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.181684732437134, "step": 147000}
{"episode_reward": 916.3277451632049, "episode": 148.0, "batch_reward": 0.8844738781452179, "critic_loss": 0.6994284574240446, "actor_loss": -90.50578814697266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.760695457458496, "step": 148000}
{"episode_reward": 944.8485543579279, "episode": 149.0, "batch_reward": 0.8837939792871475, "critic_loss": 0.6666736826896668, "actor_loss": -90.67211082458496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.29922080039978, "step": 149000}
{"episode_reward": 964.5575629109546, "episode": 150.0, "batch_reward": 0.8847832445502282, "critic_loss": 0.6733699099570513, "actor_loss": -90.46227461242675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
