{"episode_reward": 0.0, "episode": 1.0, "duration": 20.533910512924194, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.7774932384490967, "step": 2000}
{"episode_reward": 847.8889533166544, "episode": 3.0, "batch_reward": 0.46862458484138636, "critic_loss": 0.28333321716555676, "actor_loss": -85.89305940271616, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.66461372375488, "step": 3000}
{"episode_reward": 872.0360532924992, "episode": 4.0, "batch_reward": 0.6116561325192451, "critic_loss": 0.9134041230082512, "actor_loss": -91.11032237243653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.088547945022583, "step": 4000}
{"episode_reward": 841.5264506015014, "episode": 5.0, "batch_reward": 0.6725257446169853, "critic_loss": 0.733069294989109, "actor_loss": -93.34752423095703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.073436737060547, "step": 5000}
{"episode_reward": 911.6589183329215, "episode": 6.0, "batch_reward": 0.7232462255358696, "critic_loss": 0.7625268158614635, "actor_loss": -94.94404022216797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07702112197876, "step": 6000}
{"episode_reward": 929.7184726406182, "episode": 7.0, "batch_reward": 0.7345571652650833, "critic_loss": 1.0708694981038571, "actor_loss": -95.58338465881347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092620611190796, "step": 7000}
{"episode_reward": 493.9440110004992, "episode": 8.0, "batch_reward": 0.692996375143528, "critic_loss": 1.4032762503623963, "actor_loss": -95.89385762023926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.086305379867554, "step": 8000}
{"episode_reward": 359.8950732101714, "episode": 9.0, "batch_reward": 0.6774295595884323, "critic_loss": 1.3168889322280883, "actor_loss": -95.9545933380127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0789053440094, "step": 9000}
{"episode_reward": 948.8715797617383, "episode": 10.0, "batch_reward": 0.6939528457522393, "critic_loss": 1.5746747171878814, "actor_loss": -96.29524977111816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07977557182312, "step": 10000}
{"episode_reward": 787.9039827872231, "episode": 11.0, "batch_reward": 0.6747381566762924, "critic_loss": 1.273456457912922, "actor_loss": -97.10663301086426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.58356070518494, "step": 11000}
{"episode_reward": 33.87729116586432, "episode": 12.0, "batch_reward": 0.6197280650436878, "critic_loss": 1.067541584312916, "actor_loss": -96.61638391113281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11261296272278, "step": 12000}
{"episode_reward": 24.712304249388893, "episode": 13.0, "batch_reward": 0.5691694161593914, "critic_loss": 1.050644733071327, "actor_loss": -96.70803538513184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.110015392303467, "step": 13000}
{"episode_reward": 28.161223269866635, "episode": 14.0, "batch_reward": 0.5317416104078293, "critic_loss": 1.254351792573929, "actor_loss": -95.88960784912109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.103623867034912, "step": 14000}
{"episode_reward": 36.42283719136235, "episode": 15.0, "batch_reward": 0.49493319752812387, "critic_loss": 1.1758690379261971, "actor_loss": -95.89221726989746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11203360557556, "step": 15000}
{"episode_reward": 28.29670622538756, "episode": 16.0, "batch_reward": 0.49057414749264716, "critic_loss": 1.8325649496912957, "actor_loss": -94.75611747741699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07125163078308, "step": 16000}
{"episode_reward": 855.3680233329878, "episode": 17.0, "batch_reward": 0.513468790024519, "critic_loss": 2.185277240037918, "actor_loss": -98.47676289367676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08589768409729, "step": 17000}
{"episode_reward": 852.5819328049896, "episode": 18.0, "batch_reward": 0.5323358795344829, "critic_loss": 1.810842509686947, "actor_loss": -100.55706486511231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08192276954651, "step": 18000}
{"episode_reward": 868.1627687066783, "episode": 19.0, "batch_reward": 0.5361825916469097, "critic_loss": 2.014025479674339, "actor_loss": -100.74754486083984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.084050178527832, "step": 19000}
{"episode_reward": 290.13391974129297, "episode": 20.0, "batch_reward": 0.5193573277294635, "critic_loss": 1.822582540333271, "actor_loss": -102.01598472595215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10454797744751, "step": 20000}
{"episode_reward": 67.07432085356982, "episode": 21.0, "batch_reward": 0.5043925138115883, "critic_loss": 1.4523492967486382, "actor_loss": -100.72814428710937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.573490381240845, "step": 21000}
{"episode_reward": 501.7164894036188, "episode": 22.0, "batch_reward": 0.507588130325079, "critic_loss": 1.2904945341944694, "actor_loss": -101.24735064697266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085598707199097, "step": 22000}
{"episode_reward": 486.742649956596, "episode": 23.0, "batch_reward": 0.5034341027140617, "critic_loss": 1.2103904542922974, "actor_loss": -99.05481787109375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093517303466797, "step": 23000}
{"episode_reward": 529.7022658976587, "episode": 24.0, "batch_reward": 0.5083246482610703, "critic_loss": 1.1085713093280791, "actor_loss": -98.13849032592773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11189866065979, "step": 24000}
{"episode_reward": 479.96899083770063, "episode": 25.0, "batch_reward": 0.4965006031394005, "critic_loss": 0.9189618444740772, "actor_loss": -96.48547094726563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.124103307724, "step": 25000}
{"episode_reward": 26.021861035315467, "episode": 26.0, "batch_reward": 0.49402977821230887, "critic_loss": 0.8513365573585033, "actor_loss": -94.81748802185058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082937717437744, "step": 26000}
{"episode_reward": 910.2630763886509, "episode": 27.0, "batch_reward": 0.5054031449556351, "critic_loss": 0.7757915487289428, "actor_loss": -94.51577680969238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07395911216736, "step": 27000}
{"episode_reward": 874.827460049, "episode": 28.0, "batch_reward": 0.5219176136255265, "critic_loss": 0.7724700581133366, "actor_loss": -93.03157002258301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.089090824127197, "step": 28000}
{"episode_reward": 927.7702555312991, "episode": 29.0, "batch_reward": 0.5373659680783749, "critic_loss": 0.8245376369655132, "actor_loss": -93.480364944458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.083542585372925, "step": 29000}
{"episode_reward": 902.2687547141659, "episode": 30.0, "batch_reward": 0.5500546733140945, "critic_loss": 0.8848802864551544, "actor_loss": -93.13296517944336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09774136543274, "step": 30000}
{"episode_reward": 909.4200686456818, "episode": 31.0, "batch_reward": 0.560691427230835, "critic_loss": 0.8821160835325718, "actor_loss": -92.59033219909668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.3968026638031, "step": 31000}
{"episode_reward": 926.3364288288337, "episode": 32.0, "batch_reward": 0.574149485617876, "critic_loss": 0.92601731133461, "actor_loss": -92.82520819091796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.084675550460815, "step": 32000}
{"episode_reward": 979.856211355623, "episode": 33.0, "batch_reward": 0.5871056907474995, "critic_loss": 0.9358310983777046, "actor_loss": -93.06049636840821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.060982704162598, "step": 33000}
{"episode_reward": 947.1454745942287, "episode": 34.0, "batch_reward": 0.5971714258491992, "critic_loss": 0.9232900615334511, "actor_loss": -92.51342198181152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.081972360610962, "step": 34000}
{"episode_reward": 953.1268852527319, "episode": 35.0, "batch_reward": 0.6046658872365952, "critic_loss": 0.8834248762130738, "actor_loss": -92.73609954833984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07555079460144, "step": 35000}
{"episode_reward": 943.185334112613, "episode": 36.0, "batch_reward": 0.6142063862681388, "critic_loss": 0.8896568006873131, "actor_loss": -93.00594477844238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07970905303955, "step": 36000}
{"episode_reward": 929.4805915676728, "episode": 37.0, "batch_reward": 0.6254806441366673, "critic_loss": 0.8910919037759304, "actor_loss": -92.97464851379395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.083094120025635, "step": 37000}
{"episode_reward": 899.0980580078515, "episode": 38.0, "batch_reward": 0.633830613732338, "critic_loss": 0.8345171147882938, "actor_loss": -93.47801008605957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07813024520874, "step": 38000}
{"episode_reward": 983.5462877947865, "episode": 39.0, "batch_reward": 0.6416939990222454, "critic_loss": 0.7925195207595825, "actor_loss": -93.38280673217774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.101789712905884, "step": 39000}
{"episode_reward": 958.8444237769488, "episode": 40.0, "batch_reward": 0.6466228561997414, "critic_loss": 0.7775182063877583, "actor_loss": -93.19379656982422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.086174249649048, "step": 40000}
{"episode_reward": 927.09765552531, "episode": 41.0, "batch_reward": 0.6538948751091958, "critic_loss": 0.7412656318545342, "actor_loss": -93.07961727905274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.39529871940613, "step": 41000}
{"episode_reward": 930.6694555125121, "episode": 42.0, "batch_reward": 0.6650705586671829, "critic_loss": 0.696674025118351, "actor_loss": -93.52890586853027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.081254720687866, "step": 42000}
{"episode_reward": 977.3256591689891, "episode": 43.0, "batch_reward": 0.669238060951233, "critic_loss": 0.6947021430432796, "actor_loss": -93.47152456665039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.086220264434814, "step": 43000}
{"episode_reward": 925.8440464879956, "episode": 44.0, "batch_reward": 0.675550027668476, "critic_loss": 0.6674603010118008, "actor_loss": -93.40726670837402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100573301315308, "step": 44000}
{"episode_reward": 954.4802943484, "episode": 45.0, "batch_reward": 0.6805933479070664, "critic_loss": 0.6589504124820232, "actor_loss": -93.41835429382324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.078532934188843, "step": 45000}
{"episode_reward": 953.4119415266097, "episode": 46.0, "batch_reward": 0.68887932908535, "critic_loss": 0.646239975810051, "actor_loss": -93.23393769836426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.074620485305786, "step": 46000}
{"episode_reward": 886.8974285730714, "episode": 47.0, "batch_reward": 0.6906517831683159, "critic_loss": 0.629080608844757, "actor_loss": -93.02541064453125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098783493041992, "step": 47000}
{"episode_reward": 959.3208556221059, "episode": 48.0, "batch_reward": 0.6973953155875205, "critic_loss": 0.666258873924613, "actor_loss": -93.16332690429688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09878921508789, "step": 48000}
{"episode_reward": 861.0717913392623, "episode": 49.0, "batch_reward": 0.7014799154400826, "critic_loss": 0.5906919189691544, "actor_loss": -93.10091873168945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085179567337036, "step": 49000}
{"episode_reward": 939.1735417785139, "episode": 50.0, "batch_reward": 0.7060085957050324, "critic_loss": 0.6353299574255943, "actor_loss": -92.92988748168945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.089630842208862, "step": 50000}
{"episode_reward": 875.6194782292108, "episode": 51.0, "batch_reward": 0.7122775818705559, "critic_loss": 0.6220773452669383, "actor_loss": -93.11694659423829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.44004559516907, "step": 51000}
{"episode_reward": 984.3179419688048, "episode": 52.0, "batch_reward": 0.7144100214838982, "critic_loss": 0.6580432677417993, "actor_loss": -92.63069445800781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07510256767273, "step": 52000}
{"episode_reward": 923.833331900158, "episode": 53.0, "batch_reward": 0.7221881103515625, "critic_loss": 0.6185631780326366, "actor_loss": -93.03549147033691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.071933031082153, "step": 53000}
{"episode_reward": 962.1922070804794, "episode": 54.0, "batch_reward": 0.7237687891125679, "critic_loss": 0.596882700175047, "actor_loss": -92.84146658325196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08113956451416, "step": 54000}
{"episode_reward": 940.0757430103652, "episode": 55.0, "batch_reward": 0.727032778441906, "critic_loss": 0.584728527545929, "actor_loss": -92.81604055786133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07915735244751, "step": 55000}
{"episode_reward": 987.1465824213004, "episode": 56.0, "batch_reward": 0.732900817990303, "critic_loss": 0.5852547279894352, "actor_loss": -93.01840748596192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.099452257156372, "step": 56000}
{"episode_reward": 986.9274630454274, "episode": 57.0, "batch_reward": 0.7378927057981491, "critic_loss": 0.6375529585629701, "actor_loss": -93.0010947265625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.076091051101685, "step": 57000}
{"episode_reward": 959.6633493599561, "episode": 58.0, "batch_reward": 0.7397452560067177, "critic_loss": 0.7475319302976131, "actor_loss": -93.06737834167481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.084287881851196, "step": 58000}
{"episode_reward": 918.6899866723627, "episode": 59.0, "batch_reward": 0.7439179817438125, "critic_loss": 0.9177904118299485, "actor_loss": -92.95184292602539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.064566612243652, "step": 59000}
{"episode_reward": 984.9253054116947, "episode": 60.0, "batch_reward": 0.7468088964819908, "critic_loss": 1.3035589614212513, "actor_loss": -93.03855297851563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077672243118286, "step": 60000}
{"episode_reward": 917.6505108639207, "episode": 61.0, "batch_reward": 0.7497552921175956, "critic_loss": 1.7007393371164798, "actor_loss": -93.23084446716308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.375553131103516, "step": 61000}
{"episode_reward": 819.6411157049035, "episode": 62.0, "batch_reward": 0.7516197187304496, "critic_loss": 1.8617414191961288, "actor_loss": -93.46829125976562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100841522216797, "step": 62000}
{"episode_reward": 989.9704146286962, "episode": 63.0, "batch_reward": 0.7550325986742973, "critic_loss": 2.0343136941194535, "actor_loss": -93.70388345336914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098804712295532, "step": 63000}
{"episode_reward": 985.1209009347148, "episode": 64.0, "batch_reward": 0.7534774488806725, "critic_loss": 3.5740152141451835, "actor_loss": -94.1411075744629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14041256904602, "step": 64000}
{"episode_reward": 87.01130195218666, "episode": 65.0, "batch_reward": 0.7426119515299797, "critic_loss": 4.536348318099976, "actor_loss": -95.26888595581055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108543395996094, "step": 65000}
{"episode_reward": 99.77828966961398, "episode": 66.0, "batch_reward": 0.733161365866661, "critic_loss": 6.216234759330749, "actor_loss": -96.71383073425292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.120733976364136, "step": 66000}
{"episode_reward": 115.71717249784889, "episode": 67.0, "batch_reward": 0.7245235775113106, "critic_loss": 7.083415828108787, "actor_loss": -97.47034274291993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09974765777588, "step": 67000}
{"episode_reward": 98.6358643814459, "episode": 68.0, "batch_reward": 0.7142333023548126, "critic_loss": 7.985965485095978, "actor_loss": -97.96967175292968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100083589553833, "step": 68000}
{"episode_reward": 118.55355156995522, "episode": 69.0, "batch_reward": 0.7064276351332665, "critic_loss": 7.808644899368286, "actor_loss": -99.25751896667481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10628867149353, "step": 69000}
{"episode_reward": 60.030589168796695, "episode": 70.0, "batch_reward": 0.6966625699996948, "critic_loss": 7.1272542663812635, "actor_loss": -100.37654806518555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.116122245788574, "step": 70000}
{"episode_reward": 53.72444828172657, "episode": 71.0, "batch_reward": 0.6871995605230331, "critic_loss": 6.562212145328521, "actor_loss": -102.08764447021484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.650081396102905, "step": 71000}
{"episode_reward": 84.82706215825637, "episode": 72.0, "batch_reward": 0.6800274279117584, "critic_loss": 5.334269647836686, "actor_loss": -103.97188566589355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13078737258911, "step": 72000}
{"episode_reward": 72.74432139613522, "episode": 73.0, "batch_reward": 0.6700978022813797, "critic_loss": 4.393068175792694, "actor_loss": -105.18107412719726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11772656440735, "step": 73000}
{"episode_reward": 63.909520970412416, "episode": 74.0, "batch_reward": 0.6639594254493714, "critic_loss": 3.826069540143013, "actor_loss": -105.06731411743164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.411110639572144, "step": 74000}
{"episode_reward": 109.98791317887722, "episode": 75.0, "batch_reward": 0.6557898493409157, "critic_loss": 3.0612380405664443, "actor_loss": -105.98492950439453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.099400520324707, "step": 75000}
{"episode_reward": 53.32390565065935, "episode": 76.0, "batch_reward": 0.6444029432535171, "critic_loss": 2.6776731382608414, "actor_loss": -105.11996304321289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.409234762191772, "step": 76000}
{"episode_reward": 79.93977359470503, "episode": 77.0, "batch_reward": 0.6461196185946465, "critic_loss": 2.2723201792240144, "actor_loss": -106.61998873901368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.081135272979736, "step": 77000}
{"episode_reward": 862.5061131009063, "episode": 78.0, "batch_reward": 0.6418555768728256, "critic_loss": 1.9333658827543259, "actor_loss": -105.765051071167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.105233907699585, "step": 78000}
{"episode_reward": 48.127928046824366, "episode": 79.0, "batch_reward": 0.6386755629181862, "critic_loss": 1.6425697374343873, "actor_loss": -105.3411464996338, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.067298650741577, "step": 79000}
{"episode_reward": 890.4926524045643, "episode": 80.0, "batch_reward": 0.6441154152750969, "critic_loss": 1.496505709707737, "actor_loss": -103.5803205871582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.090110301971436, "step": 80000}
{"episode_reward": 923.0999040083058, "episode": 81.0, "batch_reward": 0.6472153462171555, "critic_loss": 1.3921239275336266, "actor_loss": -103.4141685333252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.498534202575684, "step": 81000}
{"episode_reward": 911.256536926307, "episode": 82.0, "batch_reward": 0.6506062771677971, "critic_loss": 1.3255631024837493, "actor_loss": -102.58881207275391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07499647140503, "step": 82000}
{"episode_reward": 980.2630652159514, "episode": 83.0, "batch_reward": 0.6554742290973663, "critic_loss": 1.1976802464723586, "actor_loss": -101.12797589111328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082402229309082, "step": 83000}
{"episode_reward": 946.8724401630296, "episode": 84.0, "batch_reward": 0.6510859315395355, "critic_loss": 1.1434441235661508, "actor_loss": -100.38687168884277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08764886856079, "step": 84000}
{"episode_reward": 651.1047269552797, "episode": 85.0, "batch_reward": 0.6541300369501114, "critic_loss": 1.1336897532343864, "actor_loss": -101.02622409057618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07660222053528, "step": 85000}
{"episode_reward": 908.7566753803167, "episode": 86.0, "batch_reward": 0.6584547513723373, "critic_loss": 1.101490071207285, "actor_loss": -100.27536587524413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07589101791382, "step": 86000}
{"episode_reward": 954.6768112616393, "episode": 87.0, "batch_reward": 0.6637944753170013, "critic_loss": 1.041270709991455, "actor_loss": -99.94012414550781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.070427179336548, "step": 87000}
{"episode_reward": 944.8011792201052, "episode": 88.0, "batch_reward": 0.6659049769639969, "critic_loss": 0.9533653773367405, "actor_loss": -99.72002011108398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.078362464904785, "step": 88000}
{"episode_reward": 977.2642409513605, "episode": 89.0, "batch_reward": 0.6702113931775093, "critic_loss": 0.9569376429915428, "actor_loss": -99.86711070251465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085644483566284, "step": 89000}
{"episode_reward": 913.740382312101, "episode": 90.0, "batch_reward": 0.6722398010492325, "critic_loss": 0.9313635096549988, "actor_loss": -99.56581382751465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.110122442245483, "step": 90000}
{"episode_reward": 982.2803340746972, "episode": 91.0, "batch_reward": 0.6742582567930222, "critic_loss": 0.9607764532566071, "actor_loss": -99.25019540405273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.45874500274658, "step": 91000}
{"episode_reward": 848.855021147136, "episode": 92.0, "batch_reward": 0.6770268011689186, "critic_loss": 0.9693033439218998, "actor_loss": -98.75664434814453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07479977607727, "step": 92000}
{"episode_reward": 986.4652600021595, "episode": 93.0, "batch_reward": 0.682860960662365, "critic_loss": 0.9749090198874474, "actor_loss": -98.64071920776367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07915997505188, "step": 93000}
{"episode_reward": 981.5242992801851, "episode": 94.0, "batch_reward": 0.6846280261278153, "critic_loss": 0.9789266767501831, "actor_loss": -98.08378234863281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085551261901855, "step": 94000}
{"episode_reward": 860.0084489061005, "episode": 95.0, "batch_reward": 0.6866496927738189, "critic_loss": 0.9082738289535046, "actor_loss": -97.91573921203613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.073229789733887, "step": 95000}
{"episode_reward": 955.6996822253336, "episode": 96.0, "batch_reward": 0.6887410218119622, "critic_loss": 0.883856094300747, "actor_loss": -96.91919065856933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.084662199020386, "step": 96000}
{"episode_reward": 923.5704260849297, "episode": 97.0, "batch_reward": 0.6919721735119819, "critic_loss": 0.8520551126897336, "actor_loss": -97.08397290039062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.076205492019653, "step": 97000}
{"episode_reward": 961.5033404780804, "episode": 98.0, "batch_reward": 0.6932712339758873, "critic_loss": 0.8387274657487869, "actor_loss": -97.21664303588867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07663059234619, "step": 98000}
{"episode_reward": 896.4496482077948, "episode": 99.0, "batch_reward": 0.6975082013010979, "critic_loss": 0.820772926300764, "actor_loss": -96.40957806396484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08046817779541, "step": 99000}
{"episode_reward": 908.5971458925753, "episode": 100.0, "batch_reward": 0.6965824736356735, "critic_loss": 0.7960744392871857, "actor_loss": -96.6221660003662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.083545923233032, "step": 100000}
{"episode_reward": 985.6007986279625, "episode": 101.0, "batch_reward": 0.701112965285778, "critic_loss": 0.8016436886787415, "actor_loss": -96.39871923828125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.40651869773865, "step": 101000}
{"episode_reward": 987.8803916769509, "episode": 102.0, "batch_reward": 0.7050355176925659, "critic_loss": 0.7825488867461682, "actor_loss": -96.27221987915038, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.099759340286255, "step": 102000}
{"episode_reward": 959.628483162934, "episode": 103.0, "batch_reward": 0.7081773138046265, "critic_loss": 0.7296660307049752, "actor_loss": -96.11166557312012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.099084615707397, "step": 103000}
{"episode_reward": 945.8959322194751, "episode": 104.0, "batch_reward": 0.71041416066885, "critic_loss": 0.6937107848972082, "actor_loss": -95.65234712219238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09039044380188, "step": 104000}
{"episode_reward": 952.7323453669725, "episode": 105.0, "batch_reward": 0.7114449298977852, "critic_loss": 0.6775632474124431, "actor_loss": -95.48238961791992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.080812692642212, "step": 105000}
{"episode_reward": 982.9470162495553, "episode": 106.0, "batch_reward": 0.7129678528308868, "critic_loss": 0.7000021405220032, "actor_loss": -95.27607720947266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.084978342056274, "step": 106000}
{"episode_reward": 895.1982273916034, "episode": 107.0, "batch_reward": 0.7177015676498413, "critic_loss": 0.6807200982570648, "actor_loss": -95.1615284576416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.078924894332886, "step": 107000}
{"episode_reward": 854.7138204165643, "episode": 108.0, "batch_reward": 0.716468557715416, "critic_loss": 0.6700397791862488, "actor_loss": -95.41104974365234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08062195777893, "step": 108000}
{"episode_reward": 942.9020912152781, "episode": 109.0, "batch_reward": 0.7186727234125138, "critic_loss": 0.6735097497403622, "actor_loss": -94.86723930358886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08867859840393, "step": 109000}
{"episode_reward": 953.5010416994952, "episode": 110.0, "batch_reward": 0.72278996270895, "critic_loss": 0.6765851419866085, "actor_loss": -94.69859017944336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077158451080322, "step": 110000}
{"episode_reward": 962.0253202370944, "episode": 111.0, "batch_reward": 0.72292214345932, "critic_loss": 0.6922134595811367, "actor_loss": -94.93340074157715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.36910891532898, "step": 111000}
{"episode_reward": 957.8892533328967, "episode": 112.0, "batch_reward": 0.7255921435952186, "critic_loss": 0.6658314405977726, "actor_loss": -94.22236074829101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087857246398926, "step": 112000}
{"episode_reward": 951.8116154113524, "episode": 113.0, "batch_reward": 0.7285955594182014, "critic_loss": 0.6417322638928891, "actor_loss": -94.33104579162598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.084712743759155, "step": 113000}
{"episode_reward": 986.674590303695, "episode": 114.0, "batch_reward": 0.7281861867308617, "critic_loss": 0.6525906600505114, "actor_loss": -94.06137721252442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09248161315918, "step": 114000}
{"episode_reward": 985.6427354862598, "episode": 115.0, "batch_reward": 0.7302997353672981, "critic_loss": 0.6203453057408332, "actor_loss": -94.01378817749024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.102779388427734, "step": 115000}
{"episode_reward": 913.4533637932394, "episode": 116.0, "batch_reward": 0.7342331052422524, "critic_loss": 0.6497652934789657, "actor_loss": -93.98654002380371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.095648050308228, "step": 116000}
{"episode_reward": 943.5948714544357, "episode": 117.0, "batch_reward": 0.7338690182566643, "critic_loss": 0.599125973701477, "actor_loss": -94.0989861907959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.086899757385254, "step": 117000}
{"episode_reward": 942.6486418992218, "episode": 118.0, "batch_reward": 0.7397479214072228, "critic_loss": 0.6253615811765194, "actor_loss": -93.87038157653808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.089389085769653, "step": 118000}
{"episode_reward": 940.0545306302699, "episode": 119.0, "batch_reward": 0.741331345140934, "critic_loss": 0.5975324890017509, "actor_loss": -93.7170034790039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08298897743225, "step": 119000}
{"episode_reward": 983.5539327246764, "episode": 120.0, "batch_reward": 0.7410882459282875, "critic_loss": 0.5888985890597105, "actor_loss": -93.64713789367676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.078779220581055, "step": 120000}
{"episode_reward": 982.890114733008, "episode": 121.0, "batch_reward": 0.7407464947700501, "critic_loss": 0.6086210929900407, "actor_loss": -93.43628898620605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.408867597579956, "step": 121000}
{"episode_reward": 959.1168178000529, "episode": 122.0, "batch_reward": 0.7438997948169708, "critic_loss": 0.5810817318707705, "actor_loss": -93.56082983398437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0781831741333, "step": 122000}
{"episode_reward": 953.7990898040734, "episode": 123.0, "batch_reward": 0.7457534217238426, "critic_loss": 0.5910224572122097, "actor_loss": -93.49446157836914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08174705505371, "step": 123000}
{"episode_reward": 977.0201636901285, "episode": 124.0, "batch_reward": 0.7491750890016555, "critic_loss": 0.5953144866079092, "actor_loss": -93.5333202972412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.071839094161987, "step": 124000}
{"episode_reward": 986.0826731318474, "episode": 125.0, "batch_reward": 0.7517130619883537, "critic_loss": 0.5586776718199253, "actor_loss": -93.59895709228516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.068439483642578, "step": 125000}
{"episode_reward": 968.0781358610651, "episode": 126.0, "batch_reward": 0.7510933153629303, "critic_loss": 0.61720783162117, "actor_loss": -93.39761828613281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097793340682983, "step": 126000}
{"episode_reward": 976.9342276090074, "episode": 127.0, "batch_reward": 0.7534333639144898, "critic_loss": 0.5945163554996252, "actor_loss": -93.02820532226562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.095280170440674, "step": 127000}
{"episode_reward": 982.5957706306518, "episode": 128.0, "batch_reward": 0.7545672708153724, "critic_loss": 0.5493039606064558, "actor_loss": -93.0668842010498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10737371444702, "step": 128000}
{"episode_reward": 950.8434807549372, "episode": 129.0, "batch_reward": 0.7588797023296356, "critic_loss": 0.5357290192991495, "actor_loss": -93.16826106262207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109699249267578, "step": 129000}
{"episode_reward": 982.7383115628301, "episode": 130.0, "batch_reward": 0.7599820178151131, "critic_loss": 0.48908266201615336, "actor_loss": -93.15291516113281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.106459140777588, "step": 130000}
{"episode_reward": 962.5704581091479, "episode": 131.0, "batch_reward": 0.758853007376194, "critic_loss": 0.5092475614249706, "actor_loss": -93.05115690612793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.400357723236084, "step": 131000}
{"episode_reward": 892.2700241155235, "episode": 132.0, "batch_reward": 0.7597345187067985, "critic_loss": 0.5058637870848179, "actor_loss": -92.98840620422364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09460425376892, "step": 132000}
{"episode_reward": 914.476009105292, "episode": 133.0, "batch_reward": 0.7625956136584282, "critic_loss": 0.5165663293898105, "actor_loss": -93.06075311279297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14085602760315, "step": 133000}
{"episode_reward": 981.9005356479971, "episode": 134.0, "batch_reward": 0.7637554027438164, "critic_loss": 0.4980406222343445, "actor_loss": -93.06998753356933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.332228422164917, "step": 134000}
{"episode_reward": 953.174670733676, "episode": 135.0, "batch_reward": 0.7654562202095986, "critic_loss": 0.4975480618029833, "actor_loss": -92.95648283386231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.068263053894043, "step": 135000}
{"episode_reward": 948.5028008102006, "episode": 136.0, "batch_reward": 0.7672276284098625, "critic_loss": 0.48843588173389435, "actor_loss": -93.16797724914551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.050087451934814, "step": 136000}
{"episode_reward": 958.4702888058713, "episode": 137.0, "batch_reward": 0.7685057725906372, "critic_loss": 0.4907444743067026, "actor_loss": -93.0104836883545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077844381332397, "step": 137000}
{"episode_reward": 985.2519646525265, "episode": 138.0, "batch_reward": 0.7715945833325386, "critic_loss": 0.46476348066329953, "actor_loss": -93.02986595153808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09130573272705, "step": 138000}
{"episode_reward": 979.4774637896944, "episode": 139.0, "batch_reward": 0.771798478603363, "critic_loss": 0.4613690048158169, "actor_loss": -93.01149838256836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.084837675094604, "step": 139000}
{"episode_reward": 957.1257177696742, "episode": 140.0, "batch_reward": 0.7744823585152626, "critic_loss": 0.47549977803230287, "actor_loss": -93.0098166809082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08837127685547, "step": 140000}
{"episode_reward": 976.3393944530469, "episode": 141.0, "batch_reward": 0.7737579453587532, "critic_loss": 0.4870628547668457, "actor_loss": -92.83815635681152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.42850923538208, "step": 141000}
{"episode_reward": 962.8108534943674, "episode": 142.0, "batch_reward": 0.7767345468401909, "critic_loss": 0.4970201829820871, "actor_loss": -92.90550828552246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.114177465438843, "step": 142000}
{"episode_reward": 983.6715642903121, "episode": 143.0, "batch_reward": 0.7772728304862976, "critic_loss": 0.4707195252329111, "actor_loss": -92.88336367797852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109307050704956, "step": 143000}
{"episode_reward": 952.812967490787, "episode": 144.0, "batch_reward": 0.7764413368701935, "critic_loss": 0.5076291237324476, "actor_loss": -92.80312908935547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091928005218506, "step": 144000}
{"episode_reward": 926.9835649170457, "episode": 145.0, "batch_reward": 0.7788140929341316, "critic_loss": 0.46414132297039035, "actor_loss": -92.94465826416015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098671197891235, "step": 145000}
{"episode_reward": 943.3124806821477, "episode": 146.0, "batch_reward": 0.7803673833012581, "critic_loss": 0.45049197290837767, "actor_loss": -93.01574140930175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093762159347534, "step": 146000}
{"episode_reward": 972.0863472472745, "episode": 147.0, "batch_reward": 0.7830728853344917, "critic_loss": 0.4791254192441702, "actor_loss": -93.13208500671387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094098567962646, "step": 147000}
{"episode_reward": 948.9897625671846, "episode": 148.0, "batch_reward": 0.7817607344985008, "critic_loss": 0.46509947134554386, "actor_loss": -93.02025028991699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092073440551758, "step": 148000}
{"episode_reward": 954.3289422185869, "episode": 149.0, "batch_reward": 0.7844893929958343, "critic_loss": 0.46762977232038977, "actor_loss": -92.97175308227538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09689688682556, "step": 149000}
{"episode_reward": 984.2160768828235, "episode": 150.0, "batch_reward": 0.7851471333503723, "critic_loss": 0.44299394129216674, "actor_loss": -92.88952479553222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
