{"episode_reward": 0.0, "episode": 1.0, "duration": 21.766077995300293, "step": 1000}
{"episode_reward": 51.16415125024753, "episode": 2.0, "duration": 1.8696763515472412, "step": 2000}
{"episode_reward": 519.9299312670827, "episode": 3.0, "batch_reward": 0.2733240281394737, "critic_loss": 0.1753142073591497, "actor_loss": -43.218176838922865, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 64.1094000339508, "step": 3000}
{"episode_reward": 80.88552747389475, "episode": 4.0, "batch_reward": 0.2082096242904663, "critic_loss": 0.42259542697668073, "actor_loss": -41.25819779062271, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.000300884246826, "step": 4000}
{"episode_reward": 149.51840129165157, "episode": 5.0, "batch_reward": 0.20527835667133332, "critic_loss": 0.8622750965356827, "actor_loss": -42.73592468833923, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.965413093566895, "step": 5000}
{"episode_reward": 269.7238739086533, "episode": 6.0, "batch_reward": 0.21646897839009763, "critic_loss": 0.9858696999549865, "actor_loss": -41.690255110740665, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.10938858985901, "step": 6000}
{"episode_reward": 319.2970770612098, "episode": 7.0, "batch_reward": 0.24679104758799075, "critic_loss": 1.0487033806443213, "actor_loss": -43.36990504074097, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.332114458084106, "step": 7000}
{"episode_reward": 404.91433144919193, "episode": 8.0, "batch_reward": 0.26187394964694977, "critic_loss": 1.1597362529039383, "actor_loss": -47.08930603218079, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.011285066604614, "step": 8000}
{"episode_reward": 369.72498877954735, "episode": 9.0, "batch_reward": 0.28507972094416617, "critic_loss": 1.4393690197467803, "actor_loss": -46.27994376754761, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.694303035736084, "step": 9000}
{"episode_reward": 428.89251227251737, "episode": 10.0, "batch_reward": 0.30358826951682566, "critic_loss": 1.7776955797672271, "actor_loss": -48.616224502563476, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.27283763885498, "step": 10000}
{"episode_reward": 605.1108279163502, "episode": 11.0, "batch_reward": 0.3356655254364014, "critic_loss": 2.0285760456323625, "actor_loss": -49.38028971862793, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.267483949661255, "step": 11000}
{"episode_reward": 661.9232681452809, "episode": 12.0, "batch_reward": 0.36490574452281, "critic_loss": 2.2334389503002168, "actor_loss": -51.73906660461426, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.44736957550049, "step": 12000}
{"episode_reward": 704.4250126298958, "episode": 13.0, "batch_reward": 0.3891639795303345, "critic_loss": 2.4221954188346864, "actor_loss": -52.055551959991455, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.2121639251709, "step": 13000}
{"episode_reward": 518.5486071111108, "episode": 14.0, "batch_reward": 0.40359481239318845, "critic_loss": 2.3409260289669036, "actor_loss": -54.27285571670532, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.47822070121765, "step": 14000}
{"episode_reward": 766.8983366934981, "episode": 15.0, "batch_reward": 0.42933604508638384, "critic_loss": 2.2918700215816497, "actor_loss": -53.38756511688232, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.583157539367676, "step": 15000}
{"episode_reward": 809.4494676916036, "episode": 16.0, "batch_reward": 0.46012974238395693, "critic_loss": 2.212135610818863, "actor_loss": -58.682997623443605, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.515199661254883, "step": 16000}
{"episode_reward": 888.8423813601721, "episode": 17.0, "batch_reward": 0.47171888875961304, "critic_loss": 2.2178225263357163, "actor_loss": -58.898001525878904, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.03335976600647, "step": 17000}
{"episode_reward": 520.9007863621518, "episode": 18.0, "batch_reward": 0.47534086883068083, "critic_loss": 2.3820873012542725, "actor_loss": -59.75969363021851, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.942644357681274, "step": 18000}
{"episode_reward": 579.182099678832, "episode": 19.0, "batch_reward": 0.4824247702360153, "critic_loss": 2.4389216916561125, "actor_loss": -61.18357593536377, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.327308893203735, "step": 19000}
{"episode_reward": 610.74900035681, "episode": 20.0, "batch_reward": 0.4942871107161045, "critic_loss": 2.279904606938362, "actor_loss": -59.04935459136963, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.35448908805847, "step": 20000}
{"episode_reward": 853.9254443670105, "episode": 21.0, "batch_reward": 0.5125885992050171, "critic_loss": 2.3031557046175, "actor_loss": -61.91714398956299, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.53831338882446, "step": 21000}
{"episode_reward": 770.4612214934659, "episode": 22.0, "batch_reward": 0.5250534154176713, "critic_loss": 2.4847782032489776, "actor_loss": -61.64010121917725, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.492727518081665, "step": 22000}
{"episode_reward": 838.6096965999944, "episode": 23.0, "batch_reward": 0.5346835130453109, "critic_loss": 2.545472660303116, "actor_loss": -63.0238374710083, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.659854650497437, "step": 23000}
{"episode_reward": 757.7168786555649, "episode": 24.0, "batch_reward": 0.545379317432642, "critic_loss": 2.7121231529712677, "actor_loss": -63.77697392272949, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.240782260894775, "step": 24000}
{"episode_reward": 825.3146325234704, "episode": 25.0, "batch_reward": 0.5566837314665317, "critic_loss": 2.7192155290842055, "actor_loss": -64.53543806457519, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.9281222820282, "step": 25000}
{"episode_reward": 860.1978883250677, "episode": 26.0, "batch_reward": 0.5716191136837006, "critic_loss": 2.549941736936569, "actor_loss": -66.17988784790039, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.96237564086914, "step": 26000}
{"episode_reward": 913.9945296962773, "episode": 27.0, "batch_reward": 0.5873835198283196, "critic_loss": 2.4300823302268983, "actor_loss": -66.07028352355957, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.600526809692383, "step": 27000}
{"episode_reward": 869.1703626134765, "episode": 28.0, "batch_reward": 0.5911663058698178, "critic_loss": 2.470066145300865, "actor_loss": -67.13478647613525, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.9268581867218, "step": 28000}
{"episode_reward": 811.5466320115637, "episode": 29.0, "batch_reward": 0.6041423393785954, "critic_loss": 2.358731360673904, "actor_loss": -67.1595117111206, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.31359028816223, "step": 29000}
{"episode_reward": 970.2106000187484, "episode": 30.0, "batch_reward": 0.6133152610659599, "critic_loss": 2.2240758146047592, "actor_loss": -67.65966687011719, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.71649718284607, "step": 30000}
{"episode_reward": 896.8441019238084, "episode": 31.0, "batch_reward": 0.6226041927039623, "critic_loss": 2.1787177715301516, "actor_loss": -68.94408339691162, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.41341519355774, "step": 31000}
{"episode_reward": 861.3965866934835, "episode": 32.0, "batch_reward": 0.6325398737192154, "critic_loss": 2.1012186146974563, "actor_loss": -69.59597689819336, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.246840238571167, "step": 32000}
{"episode_reward": 906.202483246898, "episode": 33.0, "batch_reward": 0.6377612942457199, "critic_loss": 2.101198673248291, "actor_loss": -69.7452826461792, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.22461247444153, "step": 33000}
{"episode_reward": 827.1277968938422, "episode": 34.0, "batch_reward": 0.6433031856417656, "critic_loss": 2.195967638373375, "actor_loss": -70.93371404266358, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.341108083724976, "step": 34000}
{"episode_reward": 877.6207206687991, "episode": 35.0, "batch_reward": 0.651938716173172, "critic_loss": 2.2301543613672257, "actor_loss": -70.87199082183838, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.411691904067993, "step": 35000}
{"episode_reward": 867.6282443005746, "episode": 36.0, "batch_reward": 0.6609514914751052, "critic_loss": 2.2721637768745424, "actor_loss": -72.36418626403808, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.578815460205078, "step": 36000}
{"episode_reward": 941.3989422690847, "episode": 37.0, "batch_reward": 0.667359077334404, "critic_loss": 2.1841890165805817, "actor_loss": -72.16250234985351, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.174235105514526, "step": 37000}
{"episode_reward": 937.9298013998659, "episode": 38.0, "batch_reward": 0.6750060174465179, "critic_loss": 2.171943288207054, "actor_loss": -71.98125771331787, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.978707790374756, "step": 38000}
{"episode_reward": 898.3807674923579, "episode": 39.0, "batch_reward": 0.6780116882324219, "critic_loss": 2.179854937314987, "actor_loss": -73.1129895553589, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.023275136947632, "step": 39000}
{"episode_reward": 879.9250523979238, "episode": 40.0, "batch_reward": 0.6840403727889061, "critic_loss": 2.2472823932170867, "actor_loss": -73.79741857147216, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.90003228187561, "step": 40000}
{"episode_reward": 796.8567232266342, "episode": 41.0, "batch_reward": 0.6865177966356277, "critic_loss": 2.2466617041826247, "actor_loss": -74.23322106933594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.28999710083008, "step": 41000}
{"episode_reward": 810.121169478062, "episode": 42.0, "batch_reward": 0.6899910067915916, "critic_loss": 2.1044336025714876, "actor_loss": -73.9297184829712, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.457561016082764, "step": 42000}
{"episode_reward": 959.6461281694286, "episode": 43.0, "batch_reward": 0.6955058847665787, "critic_loss": 1.9945632041692734, "actor_loss": -74.80095893096924, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.950825929641724, "step": 43000}
{"episode_reward": 823.5931308090027, "episode": 44.0, "batch_reward": 0.700955258667469, "critic_loss": 1.9207678002715112, "actor_loss": -74.38478224182128, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.126672983169556, "step": 44000}
{"episode_reward": 865.1016262898869, "episode": 45.0, "batch_reward": 0.701226472556591, "critic_loss": 1.8924260988235473, "actor_loss": -74.4773878326416, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.64683771133423, "step": 45000}
{"episode_reward": 672.5434420979285, "episode": 46.0, "batch_reward": 0.7045201715230942, "critic_loss": 1.8130177952647208, "actor_loss": -75.48366445922852, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.21226978302002, "step": 46000}
{"episode_reward": 956.3323412390462, "episode": 47.0, "batch_reward": 0.7080039703249932, "critic_loss": 1.9044459992051124, "actor_loss": -75.83763079833984, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.36552095413208, "step": 47000}
{"episode_reward": 796.730267755657, "episode": 48.0, "batch_reward": 0.708479967713356, "critic_loss": 2.0343476912379264, "actor_loss": -76.05765812683106, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.139662742614746, "step": 48000}
{"episode_reward": 810.616367904351, "episode": 49.0, "batch_reward": 0.7116989724040031, "critic_loss": 2.023611716926098, "actor_loss": -76.32060148620606, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.03904438018799, "step": 49000}
{"episode_reward": 858.1488715740753, "episode": 50.0, "batch_reward": 0.7158245661258698, "critic_loss": 1.9301415021419526, "actor_loss": -76.29948776245118, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.478920459747314, "step": 50000}
{"episode_reward": 913.2322757816289, "episode": 51.0, "batch_reward": 0.7213170917630196, "critic_loss": 1.9310636595487594, "actor_loss": -76.49970570373536, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.67163109779358, "step": 51000}
{"episode_reward": 974.2965049366248, "episode": 52.0, "batch_reward": 0.7219036719799041, "critic_loss": 1.8856514671444893, "actor_loss": -76.98587927246093, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.306949615478516, "step": 52000}
{"episode_reward": 679.010918367826, "episode": 53.0, "batch_reward": 0.7231595357060432, "critic_loss": 1.8609270018339157, "actor_loss": -76.32834419250489, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.168521642684937, "step": 53000}
{"episode_reward": 816.4068437558327, "episode": 54.0, "batch_reward": 0.7234208766818047, "critic_loss": 1.8178617307543754, "actor_loss": -77.44761372375488, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.318091869354248, "step": 54000}
{"episode_reward": 647.3102105266055, "episode": 55.0, "batch_reward": 0.7230318655371666, "critic_loss": 1.7137787492871284, "actor_loss": -77.30958116149903, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.55302619934082, "step": 55000}
{"episode_reward": 958.1776652892676, "episode": 56.0, "batch_reward": 0.7274205514788628, "critic_loss": 1.8487182205319406, "actor_loss": -77.08830891418457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.37676239013672, "step": 56000}
{"episode_reward": 783.9660851999566, "episode": 57.0, "batch_reward": 0.7296716803312302, "critic_loss": 1.7939305389523506, "actor_loss": -77.46243984985351, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.275445461273193, "step": 57000}
{"episode_reward": 946.1823113652198, "episode": 58.0, "batch_reward": 0.7308203771710395, "critic_loss": 1.8462922446727752, "actor_loss": -77.63873559570312, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.028488159179688, "step": 58000}
{"episode_reward": 769.3546761411719, "episode": 59.0, "batch_reward": 0.7338667207956314, "critic_loss": 1.9917630773186683, "actor_loss": -77.73302015686035, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.12560486793518, "step": 59000}
{"episode_reward": 908.2953361517738, "episode": 60.0, "batch_reward": 0.734499665915966, "critic_loss": 2.0333141417503358, "actor_loss": -77.90511117553712, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.198434114456177, "step": 60000}
{"episode_reward": 791.374929641889, "episode": 61.0, "batch_reward": 0.7359890596866607, "critic_loss": 2.118441407084465, "actor_loss": -78.15419189453125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.26607942581177, "step": 61000}
{"episode_reward": 818.3757036051405, "episode": 62.0, "batch_reward": 0.7388535609841347, "critic_loss": 2.0595178804397585, "actor_loss": -77.96644514465332, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.2916202545166, "step": 62000}
{"episode_reward": 953.0482586733426, "episode": 63.0, "batch_reward": 0.7415127473473548, "critic_loss": 2.0072751022577284, "actor_loss": -78.15106359863282, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.075226306915283, "step": 63000}
{"episode_reward": 971.8748027667683, "episode": 64.0, "batch_reward": 0.7465178166627884, "critic_loss": 1.927469737291336, "actor_loss": -78.63958697509766, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.36649179458618, "step": 64000}
{"episode_reward": 914.6100693354649, "episode": 65.0, "batch_reward": 0.7477675464153289, "critic_loss": 1.8967238652706147, "actor_loss": -78.63250251770019, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.5312180519104, "step": 65000}
{"episode_reward": 899.503190332894, "episode": 66.0, "batch_reward": 0.7494489834904671, "critic_loss": 1.837666718184948, "actor_loss": -78.91011297607422, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.65028738975525, "step": 66000}
{"episode_reward": 929.2093045580881, "episode": 67.0, "batch_reward": 0.7542489663958549, "critic_loss": 1.7489391064047815, "actor_loss": -79.01022520446777, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.14710545539856, "step": 67000}
{"episode_reward": 918.9380484775743, "episode": 68.0, "batch_reward": 0.7558524923920631, "critic_loss": 1.7187675700187683, "actor_loss": -79.41616590881348, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.9444637298584, "step": 68000}
{"episode_reward": 916.6875133567861, "episode": 69.0, "batch_reward": 0.7574995482563972, "critic_loss": 1.7123346564769746, "actor_loss": -79.53856358337403, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.034778833389282, "step": 69000}
{"episode_reward": 925.0570167384354, "episode": 70.0, "batch_reward": 0.7603140396475792, "critic_loss": 1.7387699442505837, "actor_loss": -79.84755282592774, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.02837610244751, "step": 70000}
{"episode_reward": 772.9938327210582, "episode": 71.0, "batch_reward": 0.7593264352679253, "critic_loss": 1.6301418640017509, "actor_loss": -79.53498077392578, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.67930030822754, "step": 71000}
{"episode_reward": 886.3350615537215, "episode": 72.0, "batch_reward": 0.7613453751802445, "critic_loss": 1.5971380378603934, "actor_loss": -79.87151997375489, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.058655500411987, "step": 72000}
{"episode_reward": 888.9045846875961, "episode": 73.0, "batch_reward": 0.7627989957332612, "critic_loss": 1.587884780883789, "actor_loss": -79.87748602294921, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.91031575202942, "step": 73000}
{"episode_reward": 833.9577032951642, "episode": 74.0, "batch_reward": 0.7649615920782089, "critic_loss": 1.5898088248372078, "actor_loss": -80.01378039550781, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.866711139678955, "step": 74000}
{"episode_reward": 813.5613495253422, "episode": 75.0, "batch_reward": 0.7669679992794991, "critic_loss": 1.4940195951461792, "actor_loss": -80.08520112609864, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.358242511749268, "step": 75000}
{"episode_reward": 933.0184826624019, "episode": 76.0, "batch_reward": 0.7679783809185028, "critic_loss": 1.6144110544919967, "actor_loss": -80.19292602539062, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.28841543197632, "step": 76000}
{"episode_reward": 833.6501947026326, "episode": 77.0, "batch_reward": 0.7701592827439309, "critic_loss": 1.5844166845679284, "actor_loss": -80.23666793823242, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.340543031692505, "step": 77000}
{"episode_reward": 923.523083943309, "episode": 78.0, "batch_reward": 0.7689076547026634, "critic_loss": 1.5550432518720627, "actor_loss": -80.16058491516114, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.45504069328308, "step": 78000}
{"episode_reward": 868.4394986331015, "episode": 79.0, "batch_reward": 0.7724480684995652, "critic_loss": 1.5532724402546882, "actor_loss": -80.41978157043457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.270878314971924, "step": 79000}
{"episode_reward": 933.8012230319166, "episode": 80.0, "batch_reward": 0.7743881556391716, "critic_loss": 1.523633042395115, "actor_loss": -80.5629557800293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.977787494659424, "step": 80000}
{"episode_reward": 944.0649248084761, "episode": 81.0, "batch_reward": 0.7751714362502098, "critic_loss": 1.5513619068861009, "actor_loss": -80.5332113494873, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.729124784469604, "step": 81000}
{"episode_reward": 925.7257293426949, "episode": 82.0, "batch_reward": 0.7780055434107781, "critic_loss": 1.4309905878305436, "actor_loss": -80.6779123840332, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.94006633758545, "step": 82000}
{"episode_reward": 935.9899817421061, "episode": 83.0, "batch_reward": 0.7789103241562844, "critic_loss": 1.4260372201204299, "actor_loss": -80.96781051635742, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.09200358390808, "step": 83000}
{"episode_reward": 917.1231317896822, "episode": 84.0, "batch_reward": 0.7807536722421646, "critic_loss": 1.470832041323185, "actor_loss": -81.17208047485352, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.256365537643433, "step": 84000}
{"episode_reward": 899.2409288551678, "episode": 85.0, "batch_reward": 0.7821497109532356, "critic_loss": 1.4447709607481956, "actor_loss": -81.01070597839356, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.135570287704468, "step": 85000}
{"episode_reward": 938.2799894777952, "episode": 86.0, "batch_reward": 0.7845277501940727, "critic_loss": 1.4113630992174149, "actor_loss": -81.04898655700684, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.190656423568726, "step": 86000}
{"episode_reward": 914.569043654024, "episode": 87.0, "batch_reward": 0.7851681107282639, "critic_loss": 1.4059514214396476, "actor_loss": -81.21891819763184, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.022392749786377, "step": 87000}
{"episode_reward": 861.9941936502931, "episode": 88.0, "batch_reward": 0.7867487298846245, "critic_loss": 1.4090195795297622, "actor_loss": -81.31554579162598, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.525094032287598, "step": 88000}
{"episode_reward": 928.9865868035789, "episode": 89.0, "batch_reward": 0.787767001926899, "critic_loss": 1.351094575881958, "actor_loss": -81.23006129455567, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.079875230789185, "step": 89000}
{"episode_reward": 942.4144812649313, "episode": 90.0, "batch_reward": 0.790361095070839, "critic_loss": 1.3739997126460075, "actor_loss": -81.43568002319336, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.925628423690796, "step": 90000}
{"episode_reward": 937.8542753694595, "episode": 91.0, "batch_reward": 0.7910621199607849, "critic_loss": 1.3798867081403732, "actor_loss": -81.35885726928711, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.19693040847778, "step": 91000}
{"episode_reward": 852.7395245250383, "episode": 92.0, "batch_reward": 0.7928296726942062, "critic_loss": 1.380961059629917, "actor_loss": -81.4829672088623, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.910110235214233, "step": 92000}
{"episode_reward": 971.2537009982265, "episode": 93.0, "batch_reward": 0.7969340078234672, "critic_loss": 1.3293205425143242, "actor_loss": -81.65209573364258, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.054540634155273, "step": 93000}
{"episode_reward": 946.8778800713524, "episode": 94.0, "batch_reward": 0.7960502397418022, "critic_loss": 1.3203234739303589, "actor_loss": -81.75080265808106, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.087130784988403, "step": 94000}
{"episode_reward": 924.5858544618993, "episode": 95.0, "batch_reward": 0.7966833969950676, "critic_loss": 1.3041374064087867, "actor_loss": -81.79943962097168, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.666961431503296, "step": 95000}
{"episode_reward": 891.4725628142777, "episode": 96.0, "batch_reward": 0.7979104153513908, "critic_loss": 1.3150418291687966, "actor_loss": -81.82332092285156, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.62144374847412, "step": 96000}
{"episode_reward": 857.0707314912465, "episode": 97.0, "batch_reward": 0.7978666889667511, "critic_loss": 1.3681627312898637, "actor_loss": -81.83313008117676, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.95018482208252, "step": 97000}
{"episode_reward": 914.2540851335974, "episode": 98.0, "batch_reward": 0.7982503619790077, "critic_loss": 1.2946160846352577, "actor_loss": -81.77409469604493, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.378154039382935, "step": 98000}
{"episode_reward": 863.9430749372513, "episode": 99.0, "batch_reward": 0.8012594242691994, "critic_loss": 1.3518069487810136, "actor_loss": -82.08523345947266, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.235451459884644, "step": 99000}
{"episode_reward": 925.7044108102627, "episode": 100.0, "batch_reward": 0.8022507929205894, "critic_loss": 1.3326284639835357, "actor_loss": -82.06626907348632, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.934487104415894, "step": 100000}
{"episode_reward": 948.7236933875886, "episode": 101.0, "batch_reward": 0.8041853845119477, "critic_loss": 1.339543294250965, "actor_loss": -82.2339577331543, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.631120443344116, "step": 101000}
{"episode_reward": 940.8588856142184, "episode": 102.0, "batch_reward": 0.8057976950407029, "critic_loss": 1.2654588317275048, "actor_loss": -82.22698736572265, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.25301194190979, "step": 102000}
{"episode_reward": 964.9134422434437, "episode": 103.0, "batch_reward": 0.806305705666542, "critic_loss": 1.3083827201128007, "actor_loss": -82.22905833435058, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.3611102104187, "step": 103000}
{"episode_reward": 952.2992917181731, "episode": 104.0, "batch_reward": 0.8072233710885048, "critic_loss": 1.2728724493980408, "actor_loss": -82.33114765930176, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.224193811416626, "step": 104000}
{"episode_reward": 930.3633374594062, "episode": 105.0, "batch_reward": 0.8092237344384193, "critic_loss": 1.2247888659834862, "actor_loss": -82.38686361694336, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.06442642211914, "step": 105000}
{"episode_reward": 954.5872479009415, "episode": 106.0, "batch_reward": 0.8099949499964714, "critic_loss": 1.2559850366711616, "actor_loss": -82.55615057373046, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.903995752334595, "step": 106000}
{"episode_reward": 936.469790567636, "episode": 107.0, "batch_reward": 0.8120366549491882, "critic_loss": 1.242815798521042, "actor_loss": -82.50260816955566, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.876132488250732, "step": 107000}
{"episode_reward": 905.2523471415273, "episode": 108.0, "batch_reward": 0.8118005121946335, "critic_loss": 1.2326610398292541, "actor_loss": -82.500560546875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.88250994682312, "step": 108000}
{"episode_reward": 941.6222778745199, "episode": 109.0, "batch_reward": 0.8132383491396904, "critic_loss": 1.225343492805958, "actor_loss": -82.63614677429199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.912899255752563, "step": 109000}
{"episode_reward": 934.4839705619747, "episode": 110.0, "batch_reward": 0.8145214210748672, "critic_loss": 1.1610878018736839, "actor_loss": -82.74072598266602, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.406060695648193, "step": 110000}
{"episode_reward": 905.8052678629259, "episode": 111.0, "batch_reward": 0.8165588204264641, "critic_loss": 1.1791336944401265, "actor_loss": -82.67478427124023, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.41547155380249, "step": 111000}
{"episode_reward": 915.1204341046308, "episode": 112.0, "batch_reward": 0.8163998200893402, "critic_loss": 1.2132249225974083, "actor_loss": -82.88351374816895, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.15594983100891, "step": 112000}
{"episode_reward": 936.8347047046332, "episode": 113.0, "batch_reward": 0.8183911517262459, "critic_loss": 1.1689916077256202, "actor_loss": -82.8904630126953, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.917485237121582, "step": 113000}
{"episode_reward": 921.9471026405907, "episode": 114.0, "batch_reward": 0.8185248614549637, "critic_loss": 1.137866851836443, "actor_loss": -82.97428593444825, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.943274974822998, "step": 114000}
{"episode_reward": 923.3605782422153, "episode": 115.0, "batch_reward": 0.819083835363388, "critic_loss": 1.1773998746871948, "actor_loss": -82.95260423278809, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.15318202972412, "step": 115000}
{"episode_reward": 908.4508192369881, "episode": 116.0, "batch_reward": 0.8219106276035308, "critic_loss": 1.1864308140277862, "actor_loss": -83.10134153747559, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.981096029281616, "step": 116000}
{"episode_reward": 882.5408066224853, "episode": 117.0, "batch_reward": 0.8204599714875221, "critic_loss": 1.1784191963672639, "actor_loss": -82.98607299804688, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.34209179878235, "step": 117000}
{"episode_reward": 915.284646838976, "episode": 118.0, "batch_reward": 0.821162880718708, "critic_loss": 1.161096879810095, "actor_loss": -83.14846614074708, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.309163093566895, "step": 118000}
{"episode_reward": 962.703773823106, "episode": 119.0, "batch_reward": 0.8231478262543678, "critic_loss": 1.1520075585842133, "actor_loss": -83.18833924865723, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.12578058242798, "step": 119000}
{"episode_reward": 933.9694813095144, "episode": 120.0, "batch_reward": 0.8230015816092491, "critic_loss": 1.0526688694953918, "actor_loss": -83.17943022155762, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.38515877723694, "step": 120000}
{"episode_reward": 957.8067842937451, "episode": 121.0, "batch_reward": 0.8242583492398262, "critic_loss": 1.078707989603281, "actor_loss": -83.26666133117676, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.70166778564453, "step": 121000}
{"episode_reward": 933.9282731060414, "episode": 122.0, "batch_reward": 0.8260271183252335, "critic_loss": 1.0821891748011112, "actor_loss": -83.29372509765625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.00778889656067, "step": 122000}
{"episode_reward": 946.1979246713465, "episode": 123.0, "batch_reward": 0.826951918721199, "critic_loss": 1.0768454363942146, "actor_loss": -83.42270036315918, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.90180730819702, "step": 123000}
{"episode_reward": 957.4673809688508, "episode": 124.0, "batch_reward": 0.82821656280756, "critic_loss": 1.0456862431168557, "actor_loss": -83.4827022857666, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.604583501815796, "step": 124000}
{"episode_reward": 938.3761811937144, "episode": 125.0, "batch_reward": 0.8290750354528427, "critic_loss": 1.028462363064289, "actor_loss": -83.5580348815918, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.07495641708374, "step": 125000}
{"episode_reward": 960.7364658817612, "episode": 126.0, "batch_reward": 0.8303603605628014, "critic_loss": 1.050585585474968, "actor_loss": -83.52388417053223, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.919270992279053, "step": 126000}
{"episode_reward": 957.4967199554964, "episode": 127.0, "batch_reward": 0.8298435473442077, "critic_loss": 1.035099443346262, "actor_loss": -83.5851534576416, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.790611028671265, "step": 127000}
{"episode_reward": 901.172450226099, "episode": 128.0, "batch_reward": 0.8299959072470665, "critic_loss": 1.0728373755812646, "actor_loss": -83.64179501342774, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.178195476531982, "step": 128000}
{"episode_reward": 930.2952347563581, "episode": 129.0, "batch_reward": 0.8304029707312583, "critic_loss": 1.0315553157627582, "actor_loss": -83.6045874633789, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.423197269439697, "step": 129000}
{"episode_reward": 897.6312004411553, "episode": 130.0, "batch_reward": 0.8334714634418487, "critic_loss": 1.0390128506422043, "actor_loss": -83.7730788269043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.716005086898804, "step": 130000}
{"episode_reward": 893.970729645434, "episode": 131.0, "batch_reward": 0.8318840997219086, "critic_loss": 1.0504278624653816, "actor_loss": -83.73293476867676, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.79804873466492, "step": 131000}
{"episode_reward": 914.4512520377481, "episode": 132.0, "batch_reward": 0.8335047475099564, "critic_loss": 1.0215478192269802, "actor_loss": -83.84895608520507, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.093236207962036, "step": 132000}
{"episode_reward": 906.5610062448957, "episode": 133.0, "batch_reward": 0.8335811690688133, "critic_loss": 1.0490741337537766, "actor_loss": -83.80545375061035, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.333422660827637, "step": 133000}
{"episode_reward": 954.6059827523384, "episode": 134.0, "batch_reward": 0.8349247837662697, "critic_loss": 1.0488187390565873, "actor_loss": -83.81811595153809, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.445413827896118, "step": 134000}
{"episode_reward": 904.7882562392194, "episode": 135.0, "batch_reward": 0.8360860750675202, "critic_loss": 1.0587712962031364, "actor_loss": -83.94113035583496, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.09577703475952, "step": 135000}
{"episode_reward": 916.9445039682041, "episode": 136.0, "batch_reward": 0.8365818361639976, "critic_loss": 1.048919253796339, "actor_loss": -83.89347038269042, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.00036311149597, "step": 136000}
{"episode_reward": 951.2870749945074, "episode": 137.0, "batch_reward": 0.8360449087619781, "critic_loss": 1.0066710427701473, "actor_loss": -84.00933045959472, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.809009790420532, "step": 137000}
{"episode_reward": 957.8004621424559, "episode": 138.0, "batch_reward": 0.8396257717013359, "critic_loss": 1.0288775938749313, "actor_loss": -84.08830363464355, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.298109531402588, "step": 138000}
{"episode_reward": 955.5389941094782, "episode": 139.0, "batch_reward": 0.838730672121048, "critic_loss": 1.0666570453047752, "actor_loss": -84.08057885742187, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.939436197280884, "step": 139000}
{"episode_reward": 842.7107187795008, "episode": 140.0, "batch_reward": 0.8404136996269226, "critic_loss": 1.0026872712671757, "actor_loss": -84.15183435058594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.20476460456848, "step": 140000}
{"episode_reward": 949.4010361304787, "episode": 141.0, "batch_reward": 0.8395914032459258, "critic_loss": 1.046265479594469, "actor_loss": -84.07970625305175, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.488757848739624, "step": 141000}
{"episode_reward": 959.7320045016013, "episode": 142.0, "batch_reward": 0.8393734906911849, "critic_loss": 0.9966463434398174, "actor_loss": -84.11269148254395, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.429983615875244, "step": 142000}
{"episode_reward": 927.3776091614695, "episode": 143.0, "batch_reward": 0.8409359180927276, "critic_loss": 1.032729170680046, "actor_loss": -84.17482374572754, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.421543836593628, "step": 143000}
{"episode_reward": 942.6158170818412, "episode": 144.0, "batch_reward": 0.8420547791719437, "critic_loss": 0.9715376856029033, "actor_loss": -84.27783618164062, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.476446628570557, "step": 144000}
{"episode_reward": 913.6171735120336, "episode": 145.0, "batch_reward": 0.8428439529538154, "critic_loss": 1.018362203925848, "actor_loss": -84.3006570892334, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.126317977905273, "step": 145000}
{"episode_reward": 805.265664939979, "episode": 146.0, "batch_reward": 0.8424263176321983, "critic_loss": 1.140966853350401, "actor_loss": -84.25692236328125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.01114273071289, "step": 146000}
{"episode_reward": 953.2231405819609, "episode": 147.0, "batch_reward": 0.8427567034959793, "critic_loss": 0.9823858503699303, "actor_loss": -84.31382690429687, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.40480136871338, "step": 147000}
{"episode_reward": 899.665993476279, "episode": 148.0, "batch_reward": 0.8428991475701332, "critic_loss": 1.039732925862074, "actor_loss": -84.2195205230713, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.217262744903564, "step": 148000}
{"episode_reward": 830.7965867259993, "episode": 149.0, "batch_reward": 0.8421986265182495, "critic_loss": 0.9980861163139343, "actor_loss": -84.31236724853515, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.10923981666565, "step": 149000}
{"episode_reward": 914.2319315275386, "episode": 150.0, "batch_reward": 0.8424991146326065, "critic_loss": 1.0488554894030093, "actor_loss": -84.2459973602295, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "step": 150000}
