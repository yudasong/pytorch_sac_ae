{"episode_reward": 0.0, "episode": 1.0, "duration": 21.367871522903442, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.7677524089813232, "step": 2000}
{"episode_reward": 632.427646246406, "episode": 3.0, "batch_reward": 0.3317352142004857, "critic_loss": 0.23593308558304357, "actor_loss": -56.74315981292317, "actor_target_entropy": -6.0, "alpha_value": 0.004365629073060301, "duration": 60.88609719276428, "step": 3000}
{"episode_reward": 130.19074768144205, "episode": 4.0, "batch_reward": 0.27750086863338946, "critic_loss": 0.6230496859848499, "actor_loss": -54.307137469530105, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.502134561538696, "step": 4000}
{"episode_reward": 409.64651874622314, "episode": 5.0, "batch_reward": 0.3393406772017479, "critic_loss": 0.6998838644325733, "actor_loss": -56.89447729730606, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.43511199951172, "step": 5000}
{"episode_reward": 588.5777438546536, "episode": 6.0, "batch_reward": 0.3863251799941063, "critic_loss": 0.6213865129649639, "actor_loss": -56.74434946537018, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.47695779800415, "step": 6000}
{"episode_reward": 726.7712796718215, "episode": 7.0, "batch_reward": 0.42560626047849653, "critic_loss": 0.7105681055486203, "actor_loss": -59.327766806602476, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.28109645843506, "step": 7000}
{"episode_reward": 455.11497799216784, "episode": 8.0, "batch_reward": 0.4490883458852768, "critic_loss": 0.6945485389232635, "actor_loss": -61.81434606933594, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.366313695907593, "step": 8000}
{"episode_reward": 764.1078708086727, "episode": 9.0, "batch_reward": 0.4826053226590157, "critic_loss": 0.7535502967238427, "actor_loss": -59.55639582824707, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.455057621002197, "step": 9000}
{"episode_reward": 734.3348573121247, "episode": 10.0, "batch_reward": 0.48672574773430827, "critic_loss": 0.9223291190862656, "actor_loss": -62.741666313171386, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.733731746673584, "step": 10000}
{"episode_reward": 376.7060432649452, "episode": 11.0, "batch_reward": 0.49512412822246554, "critic_loss": 1.0267210280299186, "actor_loss": -61.48987194824219, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 39.85199046134949, "step": 11000}
{"episode_reward": 649.7860593049467, "episode": 12.0, "batch_reward": 0.5152246727049351, "critic_loss": 1.2453720682859422, "actor_loss": -63.5709503364563, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.459331512451172, "step": 12000}
{"episode_reward": 797.508352285248, "episode": 13.0, "batch_reward": 0.5371015492379665, "critic_loss": 1.2283515174388886, "actor_loss": -64.94104790878296, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.31555199623108, "step": 13000}
{"episode_reward": 755.0534631574629, "episode": 14.0, "batch_reward": 0.5490822723507881, "critic_loss": 1.337473301589489, "actor_loss": -65.71662099838257, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.37476348876953, "step": 14000}
{"episode_reward": 622.3596152524126, "episode": 15.0, "batch_reward": 0.5579942025840282, "critic_loss": 1.4380050821900368, "actor_loss": -64.46948922729493, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.90576171875, "step": 15000}
{"episode_reward": 806.0210222287816, "episode": 16.0, "batch_reward": 0.5732197710871696, "critic_loss": 1.415772331893444, "actor_loss": -65.9754026298523, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.295238494873047, "step": 16000}
{"episode_reward": 814.0094829377933, "episode": 17.0, "batch_reward": 0.5828527812063694, "critic_loss": 1.70919969111681, "actor_loss": -66.85215670776367, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.37050724029541, "step": 17000}
{"episode_reward": 688.9644389690123, "episode": 18.0, "batch_reward": 0.5931387300491333, "critic_loss": 1.5361812558174133, "actor_loss": -67.41742039489746, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.82793402671814, "step": 18000}
{"episode_reward": 703.5472145803017, "episode": 19.0, "batch_reward": 0.5962956343591214, "critic_loss": 1.7892059450149536, "actor_loss": -67.17403883361817, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.974350929260254, "step": 19000}
{"episode_reward": 681.9429093683942, "episode": 20.0, "batch_reward": 0.6073063071370125, "critic_loss": 1.726612091600895, "actor_loss": -68.48182389831543, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.356513261795044, "step": 20000}
{"episode_reward": 891.9736378128665, "episode": 21.0, "batch_reward": 0.6182990175485611, "critic_loss": 1.95413041138649, "actor_loss": -66.37392140960694, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.04800081253052, "step": 21000}
{"episode_reward": 760.3766700569169, "episode": 22.0, "batch_reward": 0.622258853495121, "critic_loss": 1.9499574055075646, "actor_loss": -69.15386165618897, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.379984140396118, "step": 22000}
{"episode_reward": 703.8709202481533, "episode": 23.0, "batch_reward": 0.6276100494265556, "critic_loss": 1.9688971301317215, "actor_loss": -69.25587567138672, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.884600400924683, "step": 23000}
{"episode_reward": 754.5601405137443, "episode": 24.0, "batch_reward": 0.630785784482956, "critic_loss": 2.004402621269226, "actor_loss": -68.31022724151612, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.539562940597534, "step": 24000}
{"episode_reward": 667.8645524450299, "episode": 25.0, "batch_reward": 0.6352693065404892, "critic_loss": 1.987062259554863, "actor_loss": -70.3837240447998, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.75674819946289, "step": 25000}
{"episode_reward": 843.6060608306697, "episode": 26.0, "batch_reward": 0.642735750079155, "critic_loss": 2.064249633193016, "actor_loss": -69.74028896331787, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.583138942718506, "step": 26000}
{"episode_reward": 811.6423726089283, "episode": 27.0, "batch_reward": 0.6504852090477944, "critic_loss": 2.048690146803856, "actor_loss": -69.92164491271973, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.524381399154663, "step": 27000}
{"episode_reward": 846.5860695314569, "episode": 28.0, "batch_reward": 0.6564029433131218, "critic_loss": 2.198033169031143, "actor_loss": -69.94534545898438, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.338648080825806, "step": 28000}
{"episode_reward": 724.761731351818, "episode": 29.0, "batch_reward": 0.6554250242710113, "critic_loss": 2.331753566145897, "actor_loss": -70.96989434051514, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.380640506744385, "step": 29000}
{"episode_reward": 764.0965089062195, "episode": 30.0, "batch_reward": 0.6616920943856239, "critic_loss": 2.2403836554288863, "actor_loss": -70.97275672149658, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.39453101158142, "step": 30000}
{"episode_reward": 847.3532701903482, "episode": 31.0, "batch_reward": 0.6689837449789047, "critic_loss": 2.181844837427139, "actor_loss": -71.1203259048462, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 39.57519745826721, "step": 31000}
{"episode_reward": 852.4448782017533, "episode": 32.0, "batch_reward": 0.6748084986805916, "critic_loss": 2.2049814192056654, "actor_loss": -71.41919663238525, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.94749903678894, "step": 32000}
{"episode_reward": 830.5210874144636, "episode": 33.0, "batch_reward": 0.6808731142878532, "critic_loss": 2.183782997608185, "actor_loss": -71.94150146484375, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.55552911758423, "step": 33000}
{"episode_reward": 899.9534898084648, "episode": 34.0, "batch_reward": 0.6878614048361779, "critic_loss": 2.1635765646696092, "actor_loss": -72.11172035980225, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.637068033218384, "step": 34000}
{"episode_reward": 878.3220365671759, "episode": 35.0, "batch_reward": 0.6914671558141708, "critic_loss": 2.1011273812651634, "actor_loss": -72.13227088165283, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.341840744018555, "step": 35000}
{"episode_reward": 823.7175134340107, "episode": 36.0, "batch_reward": 0.6974423832893372, "critic_loss": 2.147059986114502, "actor_loss": -72.94271669769287, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.28982973098755, "step": 36000}
{"episode_reward": 801.5445281039915, "episode": 37.0, "batch_reward": 0.6993496033549309, "critic_loss": 1.9977532777786255, "actor_loss": -72.9714372253418, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.82172989845276, "step": 37000}
{"episode_reward": 844.0872631126185, "episode": 38.0, "batch_reward": 0.699512716293335, "critic_loss": 1.936966446995735, "actor_loss": -73.80416522216797, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.32332468032837, "step": 38000}
{"episode_reward": 829.3333738557973, "episode": 39.0, "batch_reward": 0.7062274228334426, "critic_loss": 1.9273542873859406, "actor_loss": -74.29154817199706, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.90862512588501, "step": 39000}
{"episode_reward": 877.788794249331, "episode": 40.0, "batch_reward": 0.7083406016230583, "critic_loss": 1.8992924172878265, "actor_loss": -74.76407133483886, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.819693088531494, "step": 40000}
{"episode_reward": 810.025262421122, "episode": 41.0, "batch_reward": 0.7128963077068329, "critic_loss": 1.8174617576599121, "actor_loss": -74.00198768615722, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 39.443047761917114, "step": 41000}
{"episode_reward": 859.9087060214146, "episode": 42.0, "batch_reward": 0.7168483009934425, "critic_loss": 1.8184689333438873, "actor_loss": -74.29229413604736, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.49899458885193, "step": 42000}
{"episode_reward": 889.9787717190148, "episode": 43.0, "batch_reward": 0.7190078263282775, "critic_loss": 1.6809544323086738, "actor_loss": -74.80735187530517, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.59296751022339, "step": 43000}
{"episode_reward": 785.5342591991772, "episode": 44.0, "batch_reward": 0.7208842625021934, "critic_loss": 1.7603299874663354, "actor_loss": -74.3766919555664, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.842344522476196, "step": 44000}
{"episode_reward": 841.2850364819293, "episode": 45.0, "batch_reward": 0.7244206004738808, "critic_loss": 1.6793459051251411, "actor_loss": -74.59070064544677, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.382322072982788, "step": 45000}
{"episode_reward": 879.0032913720297, "episode": 46.0, "batch_reward": 0.728155009150505, "critic_loss": 1.6788920632600783, "actor_loss": -74.86139151000977, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.84916377067566, "step": 46000}
{"episode_reward": 873.5422033186675, "episode": 47.0, "batch_reward": 0.7311112143993378, "critic_loss": 1.71887926197052, "actor_loss": -74.54280590820312, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.714630365371704, "step": 47000}
{"episode_reward": 854.5055227973039, "episode": 48.0, "batch_reward": 0.7318983262181282, "critic_loss": 1.5340422554612159, "actor_loss": -75.18437377166748, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.693663835525513, "step": 48000}
{"episode_reward": 891.6746282690717, "episode": 49.0, "batch_reward": 0.7352292051911354, "critic_loss": 1.693252736210823, "actor_loss": -75.44465323638916, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.61928701400757, "step": 49000}
{"episode_reward": 740.3349205609313, "episode": 50.0, "batch_reward": 0.7356373341083526, "critic_loss": 1.6606738774180412, "actor_loss": -74.99600589752197, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.378515481948853, "step": 50000}
{"episode_reward": 836.5975965353165, "episode": 51.0, "batch_reward": 0.7391240976452828, "critic_loss": 1.6062029832601548, "actor_loss": -75.8535311050415, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.024210691452026, "step": 51000}
{"episode_reward": 857.732463927599, "episode": 52.0, "batch_reward": 0.7407427191138267, "critic_loss": 1.5977678354978562, "actor_loss": -75.51263955688476, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.370762586593628, "step": 52000}
{"episode_reward": 890.6354102281452, "episode": 53.0, "batch_reward": 0.7433218331933021, "critic_loss": 1.6310901696681976, "actor_loss": -75.86109197998047, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.624223470687866, "step": 53000}
{"episode_reward": 875.7210041044891, "episode": 54.0, "batch_reward": 0.7475834106206893, "critic_loss": 1.5927125771045685, "actor_loss": -76.34184346771241, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.306577682495117, "step": 54000}
{"episode_reward": 901.3647217326302, "episode": 55.0, "batch_reward": 0.7502875580787659, "critic_loss": 1.6271041859984399, "actor_loss": -76.58605960083008, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.8188374042511, "step": 55000}
{"episode_reward": 907.1110130461435, "episode": 56.0, "batch_reward": 0.751111285507679, "critic_loss": 1.6127146750688552, "actor_loss": -76.60130753326416, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.769522666931152, "step": 56000}
{"episode_reward": 785.087425469604, "episode": 57.0, "batch_reward": 0.7527604206204415, "critic_loss": 1.5912239664196968, "actor_loss": -76.58696714782715, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.381203413009644, "step": 57000}
{"episode_reward": 876.6359618055955, "episode": 58.0, "batch_reward": 0.7551744948625565, "critic_loss": 1.561809612751007, "actor_loss": -76.86826867675781, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.962700128555298, "step": 58000}
{"episode_reward": 876.2435898503539, "episode": 59.0, "batch_reward": 0.7567138347625733, "critic_loss": 1.554877435386181, "actor_loss": -77.3468673324585, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.359558820724487, "step": 59000}
{"episode_reward": 727.2100767889505, "episode": 60.0, "batch_reward": 0.7569444518089294, "critic_loss": 1.4717147771120072, "actor_loss": -76.90964363098145, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.611576795578003, "step": 60000}
{"episode_reward": 860.100870880654, "episode": 61.0, "batch_reward": 0.7572673181891442, "critic_loss": 1.58351596981287, "actor_loss": -76.70500328063964, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.9766845703125, "step": 61000}
{"episode_reward": 818.5256205772758, "episode": 62.0, "batch_reward": 0.7592856039404869, "critic_loss": 1.600408343076706, "actor_loss": -76.8838750152588, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.343574047088623, "step": 62000}
{"episode_reward": 863.8517429221191, "episode": 63.0, "batch_reward": 0.7596426148414612, "critic_loss": 1.6573999012112617, "actor_loss": -77.02079466247558, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.283449411392212, "step": 63000}
{"episode_reward": 781.8448565729134, "episode": 64.0, "batch_reward": 0.7621297960281372, "critic_loss": 1.6385031881928445, "actor_loss": -77.18505358886719, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.629106521606445, "step": 64000}
{"episode_reward": 790.422049045485, "episode": 65.0, "batch_reward": 0.7624419404268264, "critic_loss": 1.6853052988648414, "actor_loss": -77.3146291809082, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.28267526626587, "step": 65000}
{"episode_reward": 864.8528135698489, "episode": 66.0, "batch_reward": 0.76403719830513, "critic_loss": 1.6662930256724358, "actor_loss": -77.47853477478027, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.728878021240234, "step": 66000}
{"episode_reward": 813.9994030848417, "episode": 67.0, "batch_reward": 0.7639804546236992, "critic_loss": 1.624331102013588, "actor_loss": -77.44777342224121, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.826485633850098, "step": 67000}
{"episode_reward": 865.2860434514729, "episode": 68.0, "batch_reward": 0.7669199106693267, "critic_loss": 1.575496711075306, "actor_loss": -77.6721030883789, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.354823112487793, "step": 68000}
{"episode_reward": 894.9176537385661, "episode": 69.0, "batch_reward": 0.7684112105965615, "critic_loss": 1.6217878389954568, "actor_loss": -77.45126199340821, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.804354190826416, "step": 69000}
{"episode_reward": 880.7944277577541, "episode": 70.0, "batch_reward": 0.7695916221737862, "critic_loss": 1.572363033413887, "actor_loss": -77.68239640808106, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.45579481124878, "step": 70000}
{"episode_reward": 837.6352987503317, "episode": 71.0, "batch_reward": 0.7700361399054527, "critic_loss": 1.5494780264496804, "actor_loss": -77.67046937561035, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 38.7364866733551, "step": 71000}
{"episode_reward": 870.4651688658565, "episode": 72.0, "batch_reward": 0.7711972025632858, "critic_loss": 1.5021860315203666, "actor_loss": -77.91115263366699, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.357709407806396, "step": 72000}
{"episode_reward": 853.8003024585429, "episode": 73.0, "batch_reward": 0.7723806176185608, "critic_loss": 1.401177031993866, "actor_loss": -77.68258415222168, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.429723501205444, "step": 73000}
{"episode_reward": 873.6914871566876, "episode": 74.0, "batch_reward": 0.7737158799767494, "critic_loss": 1.4571458767652512, "actor_loss": -77.72352212524414, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.36102795600891, "step": 74000}
{"episode_reward": 878.3777036069777, "episode": 75.0, "batch_reward": 0.7773489884734154, "critic_loss": 1.4342398357391357, "actor_loss": -78.3553101348877, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.96255135536194, "step": 75000}
{"episode_reward": 815.5162414008151, "episode": 76.0, "batch_reward": 0.77577031904459, "critic_loss": 1.4812974912524224, "actor_loss": -78.09231217956543, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.123474836349487, "step": 76000}
{"episode_reward": 870.1611865036334, "episode": 77.0, "batch_reward": 0.7771600371003151, "critic_loss": 1.385284288764, "actor_loss": -78.08610206604004, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.416624546051025, "step": 77000}
{"episode_reward": 819.7204387152346, "episode": 78.0, "batch_reward": 0.7786094750165939, "critic_loss": 1.3889962587952613, "actor_loss": -78.06266221618652, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.68628454208374, "step": 78000}
{"episode_reward": 891.7098447832246, "episode": 79.0, "batch_reward": 0.7792572540044784, "critic_loss": 1.3705876053571702, "actor_loss": -78.32470330810547, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.436001777648926, "step": 79000}
{"episode_reward": 795.4211776365541, "episode": 80.0, "batch_reward": 0.7806129427552223, "critic_loss": 1.3516330506205558, "actor_loss": -78.49103204345703, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.07719659805298, "step": 80000}
{"episode_reward": 873.8660821393557, "episode": 81.0, "batch_reward": 0.7802334935069084, "critic_loss": 1.3102672806978226, "actor_loss": -78.38186274719239, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.009865522384644, "step": 81000}
{"episode_reward": 882.7611637974654, "episode": 82.0, "batch_reward": 0.7819699260592461, "critic_loss": 1.3380777274370192, "actor_loss": -78.2970786895752, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.634255170822144, "step": 82000}
{"episode_reward": 821.2906292532105, "episode": 83.0, "batch_reward": 0.7829134492874146, "critic_loss": 1.2570064652860165, "actor_loss": -78.63477883911133, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.349701166152954, "step": 83000}
{"episode_reward": 864.3326532959445, "episode": 84.0, "batch_reward": 0.782658264696598, "critic_loss": 1.239029208600521, "actor_loss": -78.44686141967773, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.797595739364624, "step": 84000}
{"episode_reward": 828.676265386224, "episode": 85.0, "batch_reward": 0.7829987115859985, "critic_loss": 1.3417465768456458, "actor_loss": -78.76438088989258, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.374011278152466, "step": 85000}
{"episode_reward": 816.988834122879, "episode": 86.0, "batch_reward": 0.7828320899009704, "critic_loss": 1.3935812918543815, "actor_loss": -78.62127766418457, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.90050721168518, "step": 86000}
{"episode_reward": 760.1267100057075, "episode": 87.0, "batch_reward": 0.784469282746315, "critic_loss": 1.4036210297942162, "actor_loss": -78.65038858032227, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.514728307724, "step": 87000}
{"episode_reward": 889.4417385353898, "episode": 88.0, "batch_reward": 0.7861926391124725, "critic_loss": 1.445610434293747, "actor_loss": -78.64927796936036, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.451016664505005, "step": 88000}
{"episode_reward": 851.1494704363639, "episode": 89.0, "batch_reward": 0.7865579403042793, "critic_loss": 1.3292378221750258, "actor_loss": -78.81625854492188, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.887887477874756, "step": 89000}
{"episode_reward": 855.6333674399037, "episode": 90.0, "batch_reward": 0.7858043175339698, "critic_loss": 1.3182280373573303, "actor_loss": -78.45869534301758, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.437145471572876, "step": 90000}
{"episode_reward": 821.7351737853971, "episode": 91.0, "batch_reward": 0.7858783288002014, "critic_loss": 1.3298676524162292, "actor_loss": -78.7366753692627, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.10954213142395, "step": 91000}
{"episode_reward": 849.6909369292486, "episode": 92.0, "batch_reward": 0.7875715461373329, "critic_loss": 1.3484006811976432, "actor_loss": -78.65233596801758, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.645618438720703, "step": 92000}
{"episode_reward": 783.5644912996046, "episode": 93.0, "batch_reward": 0.7886655446887016, "critic_loss": 1.377389217853546, "actor_loss": -78.86139860534668, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.283849000930786, "step": 93000}
{"episode_reward": 889.4792520582264, "episode": 94.0, "batch_reward": 0.7891693599820137, "critic_loss": 1.3897050113677978, "actor_loss": -78.65415505981446, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.122886419296265, "step": 94000}
{"episode_reward": 848.868586052886, "episode": 95.0, "batch_reward": 0.7896310192346573, "critic_loss": 1.4291313998103141, "actor_loss": -78.84422235107422, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.616026401519775, "step": 95000}
{"episode_reward": 830.2401133228366, "episode": 96.0, "batch_reward": 0.7906255006790162, "critic_loss": 1.3405949150919914, "actor_loss": -78.91230624389648, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.316170692443848, "step": 96000}
{"episode_reward": 904.3409690171467, "episode": 97.0, "batch_reward": 0.789362160205841, "critic_loss": 1.3561693317294121, "actor_loss": -78.84976751708984, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.842243194580078, "step": 97000}
{"episode_reward": 855.5244553929333, "episode": 98.0, "batch_reward": 0.7920591247081756, "critic_loss": 1.3647574145793915, "actor_loss": -78.89981233215332, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.002720832824707, "step": 98000}
{"episode_reward": 876.9478667664749, "episode": 99.0, "batch_reward": 0.7928394498825073, "critic_loss": 1.3621856735944748, "actor_loss": -78.99769721984863, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.34496545791626, "step": 99000}
{"episode_reward": 883.2846218708903, "episode": 100.0, "batch_reward": 0.793751711666584, "critic_loss": 1.3554723411798477, "actor_loss": -79.05416287231445, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.09442925453186, "step": 100000}
{"episode_reward": 866.7314360824645, "episode": 101.0, "batch_reward": 0.7935150732398033, "critic_loss": 1.2629714908599854, "actor_loss": -78.90054400634766, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.32000994682312, "step": 101000}
{"episode_reward": 858.4731161680702, "episode": 102.0, "batch_reward": 0.7960196614861489, "critic_loss": 1.2685220848917962, "actor_loss": -79.15982333374023, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.349769353866577, "step": 102000}
{"episode_reward": 904.4132368447473, "episode": 103.0, "batch_reward": 0.796223309636116, "critic_loss": 1.3402267127037049, "actor_loss": -79.08582380676269, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.712311506271362, "step": 103000}
{"episode_reward": 904.88308438755, "episode": 104.0, "batch_reward": 0.7981489186286926, "critic_loss": 1.3033602669239044, "actor_loss": -79.33939944458008, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.46541166305542, "step": 104000}
{"episode_reward": 870.8319159899038, "episode": 105.0, "batch_reward": 0.7971209082007408, "critic_loss": 1.3553044055700303, "actor_loss": -79.24308555603028, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.348488807678223, "step": 105000}
{"episode_reward": 889.2085318916588, "episode": 106.0, "batch_reward": 0.7983153044581414, "critic_loss": 1.3083874766230583, "actor_loss": -79.41796398925781, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.304185390472412, "step": 106000}
{"episode_reward": 897.2434412191421, "episode": 107.0, "batch_reward": 0.7988334513306617, "critic_loss": 1.3078838022947312, "actor_loss": -79.36634692382812, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.49662494659424, "step": 107000}
{"episode_reward": 888.3087907803542, "episode": 108.0, "batch_reward": 0.8004094204306602, "critic_loss": 1.3229929135143756, "actor_loss": -79.368355758667, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.372686862945557, "step": 108000}
{"episode_reward": 900.7548159022431, "episode": 109.0, "batch_reward": 0.8004206543564797, "critic_loss": 1.35870654001832, "actor_loss": -79.43109338378906, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.846962690353394, "step": 109000}
{"episode_reward": 876.9809642624402, "episode": 110.0, "batch_reward": 0.8026122188568116, "critic_loss": 1.2972872725129128, "actor_loss": -79.45380442810058, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.4273464679718, "step": 110000}
{"episode_reward": 862.367352482314, "episode": 111.0, "batch_reward": 0.8026233174800873, "critic_loss": 1.384020055770874, "actor_loss": -79.48570622253418, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 38.9106662273407, "step": 111000}
{"episode_reward": 862.5900896382713, "episode": 112.0, "batch_reward": 0.8013153764009475, "critic_loss": 1.3015818969905377, "actor_loss": -79.58302546691894, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.749245643615723, "step": 112000}
{"episode_reward": 830.8733239861784, "episode": 113.0, "batch_reward": 0.8047379366755486, "critic_loss": 1.2910792916417122, "actor_loss": -79.47608168029785, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.26080298423767, "step": 113000}
{"episode_reward": 904.7534354276949, "episode": 114.0, "batch_reward": 0.8030010046958923, "critic_loss": 1.260419265985489, "actor_loss": -79.68875405883789, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.370736598968506, "step": 114000}
{"episode_reward": 882.7765476414943, "episode": 115.0, "batch_reward": 0.8052958265542984, "critic_loss": 1.2739452978372574, "actor_loss": -79.72520529174804, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.43958020210266, "step": 115000}
{"episode_reward": 920.7255951602241, "episode": 116.0, "batch_reward": 0.8053758844137192, "critic_loss": 1.3311637107133865, "actor_loss": -79.79694549560547, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.92586040496826, "step": 116000}
{"episode_reward": 879.2888615570886, "episode": 117.0, "batch_reward": 0.8067881663441658, "critic_loss": 1.3488740319013595, "actor_loss": -79.76110250854492, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.37540578842163, "step": 117000}
{"episode_reward": 784.1496342135632, "episode": 118.0, "batch_reward": 0.8069182158708572, "critic_loss": 1.2183992933630943, "actor_loss": -79.71169407653808, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.833770751953125, "step": 118000}
{"episode_reward": 893.4929464380539, "episode": 119.0, "batch_reward": 0.8063830471038819, "critic_loss": 1.2974349283576012, "actor_loss": -79.72958302307129, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.575504779815674, "step": 119000}
{"episode_reward": 905.0739347126928, "episode": 120.0, "batch_reward": 0.807844012081623, "critic_loss": 1.2353024730682374, "actor_loss": -79.97301707458496, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.282259702682495, "step": 120000}
{"episode_reward": 867.850073837911, "episode": 121.0, "batch_reward": 0.8074468233585358, "critic_loss": 1.2434762605428695, "actor_loss": -79.85295166015625, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.48855471611023, "step": 121000}
{"episode_reward": 853.623097268129, "episode": 122.0, "batch_reward": 0.8098722505569458, "critic_loss": 1.221562163323164, "actor_loss": -79.94411599731446, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.28007173538208, "step": 122000}
{"episode_reward": 846.1122881816572, "episode": 123.0, "batch_reward": 0.8089703640937805, "critic_loss": 1.2641896439492704, "actor_loss": -79.94282901000976, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.26884412765503, "step": 123000}
{"episode_reward": 871.4120308793073, "episode": 124.0, "batch_reward": 0.8114202157855034, "critic_loss": 1.1824140869379043, "actor_loss": -79.94969760131836, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.85378122329712, "step": 124000}
{"episode_reward": 886.970778203459, "episode": 125.0, "batch_reward": 0.8117580324411392, "critic_loss": 1.247951879054308, "actor_loss": -80.13821922302246, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.437839031219482, "step": 125000}
{"episode_reward": 863.8889027212873, "episode": 126.0, "batch_reward": 0.811326903641224, "critic_loss": 1.2070824593305587, "actor_loss": -80.03314807128906, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.42493200302124, "step": 126000}
{"episode_reward": 883.9624220965219, "episode": 127.0, "batch_reward": 0.8110450660586357, "critic_loss": 1.2650038765072822, "actor_loss": -79.99638710021972, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.389574766159058, "step": 127000}
{"episode_reward": 913.7913936896318, "episode": 128.0, "batch_reward": 0.8126675452589989, "critic_loss": 1.3618433410525321, "actor_loss": -80.03409696960449, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.565821409225464, "step": 128000}
{"episode_reward": 912.8252142932082, "episode": 129.0, "batch_reward": 0.8127057910561561, "critic_loss": 1.2880334186553954, "actor_loss": -80.07924200439453, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.385109424591064, "step": 129000}
{"episode_reward": 875.8743404840403, "episode": 130.0, "batch_reward": 0.8130215713977814, "critic_loss": 1.2609470376968384, "actor_loss": -80.00468287658691, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.672240257263184, "step": 130000}
{"episode_reward": 863.657726805927, "episode": 131.0, "batch_reward": 0.8133763454556465, "critic_loss": 1.3399561977982521, "actor_loss": -79.86299453735352, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.36343336105347, "step": 131000}
{"episode_reward": 863.205773964372, "episode": 132.0, "batch_reward": 0.8132034474611283, "critic_loss": 1.2616735283136369, "actor_loss": -79.99191172790528, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.359012126922607, "step": 132000}
{"episode_reward": 886.0986204271084, "episode": 133.0, "batch_reward": 0.8130055176615715, "critic_loss": 1.2373938375115394, "actor_loss": -80.13861906433105, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.784955263137817, "step": 133000}
{"episode_reward": 800.7138671615002, "episode": 134.0, "batch_reward": 0.8150043847560883, "critic_loss": 1.263736057072878, "actor_loss": -80.18670245361328, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.51185154914856, "step": 134000}
{"episode_reward": 889.0529299789207, "episode": 135.0, "batch_reward": 0.8135029146671295, "critic_loss": 1.2313064056038856, "actor_loss": -80.2380100402832, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.94017195701599, "step": 135000}
{"episode_reward": 782.7390842513648, "episode": 136.0, "batch_reward": 0.8131880522370338, "critic_loss": 1.2157312403321265, "actor_loss": -80.20397299194336, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.8660831451416, "step": 136000}
{"episode_reward": 470.0750040861538, "episode": 137.0, "batch_reward": 0.8129457506537437, "critic_loss": 1.1966228065490723, "actor_loss": -80.11070753479004, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.445871829986572, "step": 137000}
{"episode_reward": 884.5863368763465, "episode": 138.0, "batch_reward": 0.8129149324893952, "critic_loss": 1.1822750054895879, "actor_loss": -79.94474179077149, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.870908975601196, "step": 138000}
{"episode_reward": 835.012020320037, "episode": 139.0, "batch_reward": 0.8120285155773163, "critic_loss": 1.2022327491044997, "actor_loss": -79.9413487701416, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.344542980194092, "step": 139000}
{"episode_reward": 826.2839718810285, "episode": 140.0, "batch_reward": 0.8132556518912315, "critic_loss": 1.1752647280991078, "actor_loss": -79.96522094726562, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.17431902885437, "step": 140000}
{"episode_reward": 904.7020035758861, "episode": 141.0, "batch_reward": 0.8138637130856514, "critic_loss": 1.188641371101141, "actor_loss": -80.08871035766602, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 39.63864278793335, "step": 141000}
{"episode_reward": 911.3273064272187, "episode": 142.0, "batch_reward": 0.8140079272985459, "critic_loss": 1.2287888976037502, "actor_loss": -80.14135362243653, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.81998872756958, "step": 142000}
{"episode_reward": 857.5314917371492, "episode": 143.0, "batch_reward": 0.8151029734611511, "critic_loss": 1.1670523903667926, "actor_loss": -80.28615972900391, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.48645043373108, "step": 143000}
{"episode_reward": 845.4881956124984, "episode": 144.0, "batch_reward": 0.816514696598053, "critic_loss": 1.114860270231962, "actor_loss": -80.25984846496581, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.401672840118408, "step": 144000}
{"episode_reward": 810.6414087652031, "episode": 145.0, "batch_reward": 0.8139762915968894, "critic_loss": 1.2159955768585204, "actor_loss": -80.3273569946289, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.388654947280884, "step": 145000}
{"episode_reward": 802.8045653153372, "episode": 146.0, "batch_reward": 0.8143852075338364, "critic_loss": 1.2047004635334015, "actor_loss": -80.12562384033203, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.316696882247925, "step": 146000}
{"episode_reward": 889.9967574505285, "episode": 147.0, "batch_reward": 0.8152407476902008, "critic_loss": 1.2509124467968942, "actor_loss": -80.13134378051758, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.50429606437683, "step": 147000}
{"episode_reward": 865.9164821566711, "episode": 148.0, "batch_reward": 0.8153712741732597, "critic_loss": 1.1966320986151695, "actor_loss": -80.23510406494141, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.149856328964233, "step": 148000}
{"episode_reward": 890.0091706608545, "episode": 149.0, "batch_reward": 0.8148478456139564, "critic_loss": 1.2091706948578358, "actor_loss": -80.22120318603515, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.53292942047119, "step": 149000}
{"episode_reward": 887.7078345984565, "episode": 150.0, "batch_reward": 0.8158433673381805, "critic_loss": 1.1686551011502744, "actor_loss": -80.22742933654786, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "step": 150000}
