{"episode_reward": 0.0, "episode": 1.0, "duration": 33.11294937133789, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 3.040158748626709, "step": 2000}
{"episode_reward": 632.427646246406, "episode": 3.0, "batch_reward": 0.36877892377794724, "critic_loss": 0.5978001039170869, "actor_loss": -70.69201007734637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 92.31693601608276, "step": 3000}
{"episode_reward": 761.872307008304, "episode": 4.0, "batch_reward": 0.46982977679371835, "critic_loss": 1.3876640006303786, "actor_loss": -74.47025114440918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.208168745040894, "step": 4000}
{"episode_reward": 520.7225852735365, "episode": 5.0, "batch_reward": 0.5186306520700454, "critic_loss": 1.5714109719991685, "actor_loss": -75.1897218322754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.115028858184814, "step": 5000}
{"episode_reward": 782.7433700468429, "episode": 6.0, "batch_reward": 0.5550379824638366, "critic_loss": 1.6653770747184753, "actor_loss": -75.71163903808593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.982675790786743, "step": 6000}
{"episode_reward": 734.0455909267316, "episode": 7.0, "batch_reward": 0.5943080876767636, "critic_loss": 1.5778636989593506, "actor_loss": -76.65854388427735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.618865966796875, "step": 7000}
{"episode_reward": 796.5218332416125, "episode": 8.0, "batch_reward": 0.628615704715252, "critic_loss": 1.6153023620247842, "actor_loss": -77.66964953613281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.04407453536987, "step": 8000}
{"episode_reward": 888.2759830175501, "episode": 9.0, "batch_reward": 0.6470533429384232, "critic_loss": 1.7722504314780236, "actor_loss": -78.25443933105468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.961653470993042, "step": 9000}
{"episode_reward": 591.6433153485975, "episode": 10.0, "batch_reward": 0.6479490773677826, "critic_loss": 1.6836720507740974, "actor_loss": -78.04577725219727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.89380693435669, "step": 10000}
{"episode_reward": 628.1190043916346, "episode": 11.0, "batch_reward": 0.614168493360281, "critic_loss": 1.4452299543619156, "actor_loss": -77.74748490905762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.41639304161072, "step": 11000}
{"episode_reward": 257.0167532415102, "episode": 12.0, "batch_reward": 0.6017717929184436, "critic_loss": 1.3209970410466194, "actor_loss": -77.33505308532715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.849105834960938, "step": 12000}
{"episode_reward": 448.4027265686146, "episode": 13.0, "batch_reward": 0.598670671492815, "critic_loss": 1.2182349547743798, "actor_loss": -77.00794270324707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.128737688064575, "step": 13000}
{"episode_reward": 708.8619780324155, "episode": 14.0, "batch_reward": 0.6009857768416405, "critic_loss": 1.405303105711937, "actor_loss": -76.7943200378418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.098490715026855, "step": 14000}
{"episode_reward": 506.870615267562, "episode": 15.0, "batch_reward": 0.600938890337944, "critic_loss": 1.2202433714866638, "actor_loss": -76.37401191711426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.68246579170227, "step": 15000}
{"episode_reward": 836.4422336311563, "episode": 16.0, "batch_reward": 0.6191379106640815, "critic_loss": 1.0124379403591155, "actor_loss": -76.54917301940918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.604410886764526, "step": 16000}
{"episode_reward": 894.6498618990428, "episode": 17.0, "batch_reward": 0.6343230188488961, "critic_loss": 1.0058732038736344, "actor_loss": -76.52218211364746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.99482798576355, "step": 17000}
{"episode_reward": 866.9938988950479, "episode": 18.0, "batch_reward": 0.6429968646168709, "critic_loss": 1.1171391550898553, "actor_loss": -76.53583717346191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.524753093719482, "step": 18000}
{"episode_reward": 750.9209263115039, "episode": 19.0, "batch_reward": 0.6474089397788048, "critic_loss": 1.2859121780395508, "actor_loss": -76.39576696777344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.912795543670654, "step": 19000}
{"episode_reward": 730.8156488156804, "episode": 20.0, "batch_reward": 0.6592140819430351, "critic_loss": 1.2943212913870812, "actor_loss": -76.68913331604004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.004820108413696, "step": 20000}
{"episode_reward": 904.0582130961993, "episode": 21.0, "batch_reward": 0.6681244271993637, "critic_loss": 1.2260222795009612, "actor_loss": -76.92909187316894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.20908236503601, "step": 21000}
{"episode_reward": 803.7794051862626, "episode": 22.0, "batch_reward": 0.6769659612178802, "critic_loss": 1.1520968017578126, "actor_loss": -77.28136483764648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.96059799194336, "step": 22000}
{"episode_reward": 896.3441757255124, "episode": 23.0, "batch_reward": 0.6744670880436897, "critic_loss": 1.1917837325334548, "actor_loss": -77.13020416259765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.418271780014038, "step": 23000}
{"episode_reward": 572.5025575276959, "episode": 24.0, "batch_reward": 0.6786659737825393, "critic_loss": 1.0761290770769119, "actor_loss": -77.30928689575195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.3877956867218, "step": 24000}
{"episode_reward": 832.6236781132638, "episode": 25.0, "batch_reward": 0.6876309224963189, "critic_loss": 0.978140726864338, "actor_loss": -77.5417865447998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.78078031539917, "step": 25000}
{"episode_reward": 915.7753547434654, "episode": 26.0, "batch_reward": 0.6938132604956627, "critic_loss": 0.9003303197920323, "actor_loss": -77.73299780273437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.918481826782227, "step": 26000}
{"episode_reward": 849.6732787773333, "episode": 27.0, "batch_reward": 0.7003925305008888, "critic_loss": 0.8704751694500447, "actor_loss": -77.81322737121582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.596798419952393, "step": 27000}
{"episode_reward": 859.2168643847046, "episode": 28.0, "batch_reward": 0.7072370209693909, "critic_loss": 0.8508108877837658, "actor_loss": -77.91142765808105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.804744005203247, "step": 28000}
{"episode_reward": 806.9640840508555, "episode": 29.0, "batch_reward": 0.7079881783723831, "critic_loss": 0.9155270129144192, "actor_loss": -77.97546821594239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.485985040664673, "step": 29000}
{"episode_reward": 834.3268560735411, "episode": 30.0, "batch_reward": 0.7142238219976426, "critic_loss": 0.942344446361065, "actor_loss": -78.1831773071289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.563711404800415, "step": 30000}
{"episode_reward": 881.9315315976911, "episode": 31.0, "batch_reward": 0.7210592864155769, "critic_loss": 0.9828136164546013, "actor_loss": -78.30246511840821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.46168112754822, "step": 31000}
{"episode_reward": 923.3795639754459, "episode": 32.0, "batch_reward": 0.7268417865633965, "critic_loss": 1.0302067687511445, "actor_loss": -78.55059246826171, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.626365423202515, "step": 32000}
{"episode_reward": 911.8640348714044, "episode": 33.0, "batch_reward": 0.7345131058096885, "critic_loss": 1.0748532200455665, "actor_loss": -78.76088337707519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.208751916885376, "step": 33000}
{"episode_reward": 928.5527161630023, "episode": 34.0, "batch_reward": 0.7399763501286507, "critic_loss": 1.207024275302887, "actor_loss": -78.88679418945313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.672963619232178, "step": 34000}
{"episode_reward": 890.5405147213351, "episode": 35.0, "batch_reward": 0.7430476382374763, "critic_loss": 1.3225122616887093, "actor_loss": -79.08979028320313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.386467695236206, "step": 35000}
{"episode_reward": 882.9898684293865, "episode": 36.0, "batch_reward": 0.7485949666500091, "critic_loss": 1.2678624910712242, "actor_loss": -79.31405235290528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.66595983505249, "step": 36000}
{"episode_reward": 911.9118641923441, "episode": 37.0, "batch_reward": 0.7522168591022491, "critic_loss": 1.3986680732369423, "actor_loss": -79.49792352294922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.863228797912598, "step": 37000}
{"episode_reward": 907.2238800695293, "episode": 38.0, "batch_reward": 0.7539187902212143, "critic_loss": 1.5176568284034728, "actor_loss": -79.47585893249511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.779303550720215, "step": 38000}
{"episode_reward": 897.2018221511802, "episode": 39.0, "batch_reward": 0.7605962545275688, "critic_loss": 1.3612302325367927, "actor_loss": -79.6709839630127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.493919134140015, "step": 39000}
{"episode_reward": 933.905965455781, "episode": 40.0, "batch_reward": 0.7588974379897118, "critic_loss": 1.940707778275013, "actor_loss": -79.49337283325195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.46136212348938, "step": 40000}
{"episode_reward": 585.432511302622, "episode": 41.0, "batch_reward": 0.7580502306222916, "critic_loss": 1.7427922493219377, "actor_loss": -79.57068008422851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.99222731590271, "step": 41000}
{"episode_reward": 874.0365647301453, "episode": 42.0, "batch_reward": 0.7637970932722091, "critic_loss": 1.6308276486992836, "actor_loss": -79.65197518920898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.180961847305298, "step": 42000}
{"episode_reward": 927.6072427863479, "episode": 43.0, "batch_reward": 0.7659293093681335, "critic_loss": 1.4667761274576188, "actor_loss": -79.58405905151368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.371890544891357, "step": 43000}
{"episode_reward": 848.0121076815749, "episode": 44.0, "batch_reward": 0.764917181789875, "critic_loss": 1.366948766887188, "actor_loss": -79.62313760375977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.730960369110107, "step": 44000}
{"episode_reward": 911.3329564129592, "episode": 45.0, "batch_reward": 0.7716043603420257, "critic_loss": 1.2350913215875625, "actor_loss": -79.82980403137206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.664419174194336, "step": 45000}
{"episode_reward": 860.3343392932011, "episode": 46.0, "batch_reward": 0.7725366624593735, "critic_loss": 1.114581407546997, "actor_loss": -79.80077755737305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.957828998565674, "step": 46000}
{"episode_reward": 913.0622482162997, "episode": 47.0, "batch_reward": 0.7753404245972634, "critic_loss": 1.131209166675806, "actor_loss": -79.84773220825195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.15777039527893, "step": 47000}
{"episode_reward": 763.6079389669621, "episode": 48.0, "batch_reward": 0.7744992954730987, "critic_loss": 1.0469773086905478, "actor_loss": -79.84474504089356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.6132173538208, "step": 48000}
{"episode_reward": 946.6319761476282, "episode": 49.0, "batch_reward": 0.7789279916286469, "critic_loss": 1.0123124330043793, "actor_loss": -79.90769361877442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.695785760879517, "step": 49000}
{"episode_reward": 853.3439461157884, "episode": 50.0, "batch_reward": 0.7798730918169021, "critic_loss": 0.9834300780296326, "actor_loss": -80.02891236877441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.48039436340332, "step": 50000}
{"episode_reward": 908.3592874937992, "episode": 51.0, "batch_reward": 0.7845302129387856, "critic_loss": 0.9048902271986008, "actor_loss": -79.95871940612793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.27300405502319, "step": 51000}
{"episode_reward": 897.6501159652428, "episode": 52.0, "batch_reward": 0.7856870533823967, "critic_loss": 0.9304338825643063, "actor_loss": -80.08289263916015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.985727548599243, "step": 52000}
{"episode_reward": 934.2829290301595, "episode": 53.0, "batch_reward": 0.7890005660653114, "critic_loss": 0.9317282909750938, "actor_loss": -80.09762344360351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.851978302001953, "step": 53000}
{"episode_reward": 890.5940060765898, "episode": 54.0, "batch_reward": 0.7917515429258346, "critic_loss": 0.9161911444664002, "actor_loss": -80.14838374328613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.925973653793335, "step": 54000}
{"episode_reward": 905.2456361713498, "episode": 55.0, "batch_reward": 0.7925777434110641, "critic_loss": 0.9263215578198433, "actor_loss": -80.10986744689941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.719295978546143, "step": 55000}
{"episode_reward": 935.5829006568509, "episode": 56.0, "batch_reward": 0.7941499205231667, "critic_loss": 0.9273315633833409, "actor_loss": -80.14086614990234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.641719102859497, "step": 56000}
{"episode_reward": 869.3765801539153, "episode": 57.0, "batch_reward": 0.7950785948038102, "critic_loss": 0.9271178874373436, "actor_loss": -80.19442587280274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.62261652946472, "step": 57000}
{"episode_reward": 918.4771936092137, "episode": 58.0, "batch_reward": 0.7989495043158531, "critic_loss": 0.9365040991604329, "actor_loss": -80.3227328491211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.14839005470276, "step": 58000}
{"episode_reward": 921.5362629736809, "episode": 59.0, "batch_reward": 0.800707795202732, "critic_loss": 0.9313449653983116, "actor_loss": -80.29679335021973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.761602878570557, "step": 59000}
{"episode_reward": 886.8972365553458, "episode": 60.0, "batch_reward": 0.804391083419323, "critic_loss": 0.9139230004549026, "actor_loss": -80.47711740112305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.485446453094482, "step": 60000}
{"episode_reward": 943.3059749974566, "episode": 61.0, "batch_reward": 0.8048000257611275, "critic_loss": 0.9259997650384902, "actor_loss": -80.56493487548828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.64334774017334, "step": 61000}
{"episode_reward": 928.6314265481475, "episode": 62.0, "batch_reward": 0.806549684047699, "critic_loss": 0.9157900257110596, "actor_loss": -80.64562881469726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.09955596923828, "step": 62000}
{"episode_reward": 910.5884200827846, "episode": 63.0, "batch_reward": 0.8071172541975975, "critic_loss": 0.9078030135631562, "actor_loss": -80.71544789123536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.282615184783936, "step": 63000}
{"episode_reward": 872.8150748250824, "episode": 64.0, "batch_reward": 0.810189386844635, "critic_loss": 0.8748656767904759, "actor_loss": -80.70956927490235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.952884197235107, "step": 64000}
{"episode_reward": 917.5150457404462, "episode": 65.0, "batch_reward": 0.8127264761328697, "critic_loss": 0.8615039364695549, "actor_loss": -80.84565441894532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.843050718307495, "step": 65000}
{"episode_reward": 935.706685482626, "episode": 66.0, "batch_reward": 0.8139034237861633, "critic_loss": 0.8271517291367054, "actor_loss": -80.82703645324708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.329805374145508, "step": 66000}
{"episode_reward": 911.938638346396, "episode": 67.0, "batch_reward": 0.8133555366992951, "critic_loss": 0.8457042241096496, "actor_loss": -80.93482510375976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.06977820396423, "step": 67000}
{"episode_reward": 903.8880954572365, "episode": 68.0, "batch_reward": 0.8155434640645981, "critic_loss": 0.8355634399056434, "actor_loss": -80.96074551391601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.92052388191223, "step": 68000}
{"episode_reward": 902.3988321418195, "episode": 69.0, "batch_reward": 0.819429502248764, "critic_loss": 0.8104869985282421, "actor_loss": -81.13222213745117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.594562768936157, "step": 69000}
{"episode_reward": 928.7418232312257, "episode": 70.0, "batch_reward": 0.8176994587779045, "critic_loss": 0.7970044422447682, "actor_loss": -81.0144164276123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.451059579849243, "step": 70000}
{"episode_reward": 887.713320467533, "episode": 71.0, "batch_reward": 0.8190319857597351, "critic_loss": 0.7995972496569157, "actor_loss": -81.09695932006836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.63078427314758, "step": 71000}
{"episode_reward": 849.8087332401635, "episode": 72.0, "batch_reward": 0.820297443151474, "critic_loss": 0.7933603819012642, "actor_loss": -81.1463293762207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.967660188674927, "step": 72000}
{"episode_reward": 909.9224671264842, "episode": 73.0, "batch_reward": 0.8217583054304123, "critic_loss": 0.8098267957866192, "actor_loss": -81.18028819274902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.412487268447876, "step": 73000}
{"episode_reward": 949.1977429086378, "episode": 74.0, "batch_reward": 0.8228830263614655, "critic_loss": 0.7759155087769032, "actor_loss": -81.3613846282959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.924123764038086, "step": 74000}
{"episode_reward": 921.7093778705469, "episode": 75.0, "batch_reward": 0.8247495552301407, "critic_loss": 0.7780898703336716, "actor_loss": -81.14731091308593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.302223920822144, "step": 75000}
{"episode_reward": 862.9748469156391, "episode": 76.0, "batch_reward": 0.8251325008273125, "critic_loss": 0.7999554770588875, "actor_loss": -81.21775213623047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.821512937545776, "step": 76000}
{"episode_reward": 880.5898971983089, "episode": 77.0, "batch_reward": 0.8246007072329521, "critic_loss": 0.7952394959330559, "actor_loss": -81.22957342529297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.924755573272705, "step": 77000}
{"episode_reward": 880.3743823110502, "episode": 78.0, "batch_reward": 0.8258058952093125, "critic_loss": 0.8009538142681122, "actor_loss": -81.33287187194824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.04232931137085, "step": 78000}
{"episode_reward": 911.5216712228492, "episode": 79.0, "batch_reward": 0.8282436936497688, "critic_loss": 0.7912815228104592, "actor_loss": -81.34930923461914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.337913990020752, "step": 79000}
{"episode_reward": 927.677803001028, "episode": 80.0, "batch_reward": 0.8293662390112877, "critic_loss": 0.7608697599768639, "actor_loss": -81.35998434448243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.886915683746338, "step": 80000}
{"episode_reward": 935.3617704576961, "episode": 81.0, "batch_reward": 0.8287595331668853, "critic_loss": 0.7826060009002686, "actor_loss": -81.40226039123534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.60327768325806, "step": 81000}
{"episode_reward": 919.604730644298, "episode": 82.0, "batch_reward": 0.8309360241293907, "critic_loss": 0.8045454414486886, "actor_loss": -81.57721983337402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.40657663345337, "step": 82000}
{"episode_reward": 861.212806211851, "episode": 83.0, "batch_reward": 0.8331616861820221, "critic_loss": 0.7674998732805252, "actor_loss": -81.60007026672363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.44985055923462, "step": 83000}
{"episode_reward": 939.2459590817084, "episode": 84.0, "batch_reward": 0.8329092189669609, "critic_loss": 0.7703709858655929, "actor_loss": -81.55415687561035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.756043434143066, "step": 84000}
{"episode_reward": 930.1697120810775, "episode": 85.0, "batch_reward": 0.8350917524695396, "critic_loss": 0.7520395708382129, "actor_loss": -81.5988670501709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.01893639564514, "step": 85000}
{"episode_reward": 869.6698206942674, "episode": 86.0, "batch_reward": 0.8334650923013687, "critic_loss": 0.7554063948094845, "actor_loss": -81.66524162292481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.35745644569397, "step": 86000}
{"episode_reward": 927.0407374639088, "episode": 87.0, "batch_reward": 0.8341123767495155, "critic_loss": 0.7183382926285267, "actor_loss": -81.7564546661377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.86610436439514, "step": 87000}
{"episode_reward": 946.0198294661941, "episode": 88.0, "batch_reward": 0.8365059297680855, "critic_loss": 0.7346819277703762, "actor_loss": -81.85257507324219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.906330347061157, "step": 88000}
{"episode_reward": 947.3921995574825, "episode": 89.0, "batch_reward": 0.8390548730492592, "critic_loss": 0.696829471886158, "actor_loss": -81.8708081817627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.0924711227417, "step": 89000}
{"episode_reward": 932.4285379235033, "episode": 90.0, "batch_reward": 0.838663813829422, "critic_loss": 0.7442894051373005, "actor_loss": -81.99368101501464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.091810941696167, "step": 90000}
{"episode_reward": 884.6936215652935, "episode": 91.0, "batch_reward": 0.8381307310461998, "critic_loss": 0.7221110843420029, "actor_loss": -81.7635873413086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.07854509353638, "step": 91000}
{"episode_reward": 883.7176917912009, "episode": 92.0, "batch_reward": 0.8392416460514068, "critic_loss": 0.690489286005497, "actor_loss": -82.00669886779785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.780309677124023, "step": 92000}
{"episode_reward": 928.5316385590445, "episode": 93.0, "batch_reward": 0.8404672422409057, "critic_loss": 0.6827371237874031, "actor_loss": -81.94936524963379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.857050895690918, "step": 93000}
{"episode_reward": 908.5248462588618, "episode": 94.0, "batch_reward": 0.8392953464984894, "critic_loss": 0.7251275327503681, "actor_loss": -82.11722541809083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.3673734664917, "step": 94000}
{"episode_reward": 749.6429577718336, "episode": 95.0, "batch_reward": 0.839820032119751, "critic_loss": 0.7559661962091923, "actor_loss": -82.01887542724609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.916788578033447, "step": 95000}
{"episode_reward": 923.145337694918, "episode": 96.0, "batch_reward": 0.8421006835699082, "critic_loss": 0.7513210957050324, "actor_loss": -82.02113388061524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.90037965774536, "step": 96000}
{"episode_reward": 945.1306593343396, "episode": 97.0, "batch_reward": 0.8414254249334335, "critic_loss": 0.7190310544669628, "actor_loss": -82.05881114196778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.775285959243774, "step": 97000}
{"episode_reward": 901.9321887861458, "episode": 98.0, "batch_reward": 0.8435807537436485, "critic_loss": 0.7666274872124195, "actor_loss": -82.13488737487793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.40989136695862, "step": 98000}
{"episode_reward": 905.5904222709552, "episode": 99.0, "batch_reward": 0.8449764760136604, "critic_loss": 0.8025982881784439, "actor_loss": -82.18151428222656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.054378032684326, "step": 99000}
{"episode_reward": 933.3358034347027, "episode": 100.0, "batch_reward": 0.8446858032345772, "critic_loss": 0.7598944988548756, "actor_loss": -82.14063082885743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.160671949386597, "step": 100000}
{"episode_reward": 918.7555826975347, "episode": 101.0, "batch_reward": 0.8462380384802818, "critic_loss": 0.7799887441694736, "actor_loss": -82.37578993225098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.00903487205505, "step": 101000}
{"episode_reward": 941.3662791537332, "episode": 102.0, "batch_reward": 0.8464571328163147, "critic_loss": 0.7345587700605393, "actor_loss": -82.07795484924317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.519195795059204, "step": 102000}
{"episode_reward": 937.6042216137639, "episode": 103.0, "batch_reward": 0.8479696290493012, "critic_loss": 0.7235114673376083, "actor_loss": -82.39160055541993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.831893920898438, "step": 103000}
{"episode_reward": 950.0402255182897, "episode": 104.0, "batch_reward": 0.849546089053154, "critic_loss": 0.7320105290412903, "actor_loss": -82.23691914367676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.626630544662476, "step": 104000}
{"episode_reward": 906.1737142683074, "episode": 105.0, "batch_reward": 0.8490827395319939, "critic_loss": 0.725533587217331, "actor_loss": -82.49274794006348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.25842547416687, "step": 105000}
{"episode_reward": 963.9705047401627, "episode": 106.0, "batch_reward": 0.8501971464753151, "critic_loss": 0.7165103850066662, "actor_loss": -82.38170112609863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.85642647743225, "step": 106000}
{"episode_reward": 965.1829061273584, "episode": 107.0, "batch_reward": 0.8514099382162094, "critic_loss": 0.6925546423941851, "actor_loss": -82.48813319396973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.443191289901733, "step": 107000}
{"episode_reward": 925.6817593150746, "episode": 108.0, "batch_reward": 0.8512223843336105, "critic_loss": 0.7237119342088699, "actor_loss": -82.45215396118164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.62901282310486, "step": 108000}
{"episode_reward": 964.4985367186368, "episode": 109.0, "batch_reward": 0.8526070312261581, "critic_loss": 0.7502347802221775, "actor_loss": -82.54073591613769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.10056781768799, "step": 109000}
{"episode_reward": 955.955421180874, "episode": 110.0, "batch_reward": 0.8537525396943092, "critic_loss": 0.7035556131452322, "actor_loss": -82.58473399353028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.48369026184082, "step": 110000}
{"episode_reward": 920.3337116313376, "episode": 111.0, "batch_reward": 0.8536948413252831, "critic_loss": 0.7420644199848175, "actor_loss": -82.75221716308593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.93132400512695, "step": 111000}
{"episode_reward": 908.3752503135121, "episode": 112.0, "batch_reward": 0.8540372583270073, "critic_loss": 0.7381394621580839, "actor_loss": -82.57710473632812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.801034927368164, "step": 112000}
{"episode_reward": 862.5903777673075, "episode": 113.0, "batch_reward": 0.8552637676596642, "critic_loss": 0.7137185863256454, "actor_loss": -82.9706548614502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.822022199630737, "step": 113000}
{"episode_reward": 946.6473955414853, "episode": 114.0, "batch_reward": 0.8564051948785781, "critic_loss": 0.6982258316576481, "actor_loss": -82.77884297180175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.79093837738037, "step": 114000}
{"episode_reward": 953.0324697357909, "episode": 115.0, "batch_reward": 0.857309997677803, "critic_loss": 0.6975098662376403, "actor_loss": -82.61918472290039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.29101347923279, "step": 115000}
{"episode_reward": 950.0392252163033, "episode": 116.0, "batch_reward": 0.8572060906887055, "critic_loss": 0.70434129601717, "actor_loss": -82.76504544067383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.36701226234436, "step": 116000}
{"episode_reward": 920.0272868842562, "episode": 117.0, "batch_reward": 0.8570820351243019, "critic_loss": 0.6923427053987979, "actor_loss": -82.82784823608398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.48217535018921, "step": 117000}
{"episode_reward": 896.3869846251484, "episode": 118.0, "batch_reward": 0.8577278520464897, "critic_loss": 0.69090368925035, "actor_loss": -82.82726031494141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.92484450340271, "step": 118000}
{"episode_reward": 925.7589303204822, "episode": 119.0, "batch_reward": 0.8586990631222725, "critic_loss": 0.6751154030859471, "actor_loss": -82.81916650390625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.79826545715332, "step": 119000}
{"episode_reward": 942.3746532098364, "episode": 120.0, "batch_reward": 0.8571112465262413, "critic_loss": 0.6282796167433262, "actor_loss": -82.73761555480957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.270045042037964, "step": 120000}
{"episode_reward": 953.3512653381113, "episode": 121.0, "batch_reward": 0.8593432660698891, "critic_loss": 0.6201274580359459, "actor_loss": -82.8264956665039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.62679171562195, "step": 121000}
{"episode_reward": 930.9981226476028, "episode": 122.0, "batch_reward": 0.8618105162382126, "critic_loss": 0.6685353228598833, "actor_loss": -82.7063975982666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.415940523147583, "step": 122000}
{"episode_reward": 883.1960048267974, "episode": 123.0, "batch_reward": 0.8612789194583893, "critic_loss": 0.6448987434655428, "actor_loss": -82.70206373596191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.33422541618347, "step": 123000}
{"episode_reward": 881.2846503348633, "episode": 124.0, "batch_reward": 0.8619024309515954, "critic_loss": 0.6285297527164221, "actor_loss": -82.7549335784912, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.68316984176636, "step": 124000}
{"episode_reward": 965.5804779673344, "episode": 125.0, "batch_reward": 0.8619406780600548, "critic_loss": 0.6289610710889101, "actor_loss": -82.75369874572753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.48818111419678, "step": 125000}
{"episode_reward": 894.2327088277183, "episode": 126.0, "batch_reward": 0.8617632094621658, "critic_loss": 0.6605189850032329, "actor_loss": -82.65006802368164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.796730041503906, "step": 126000}
{"episode_reward": 922.965511205081, "episode": 127.0, "batch_reward": 0.8620916468501091, "critic_loss": 0.6589884360432625, "actor_loss": -82.95974723815918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.171363353729248, "step": 127000}
{"episode_reward": 954.6748534739702, "episode": 128.0, "batch_reward": 0.8644770894050599, "critic_loss": 0.623159706145525, "actor_loss": -82.9749945526123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.04658842086792, "step": 128000}
{"episode_reward": 964.7877487884568, "episode": 129.0, "batch_reward": 0.8649681783914566, "critic_loss": 0.6146763557344675, "actor_loss": -82.94504034423828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.96144151687622, "step": 129000}
{"episode_reward": 918.8558049910123, "episode": 130.0, "batch_reward": 0.8654760026931763, "critic_loss": 0.6559437086880207, "actor_loss": -82.98733308410644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.81425666809082, "step": 130000}
{"episode_reward": 879.5809583740282, "episode": 131.0, "batch_reward": 0.862671645462513, "critic_loss": 0.6387168696522713, "actor_loss": -83.25575285339356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.94343543052673, "step": 131000}
{"episode_reward": 911.1836159038925, "episode": 132.0, "batch_reward": 0.8652919338345527, "critic_loss": 0.6222770337015391, "actor_loss": -83.17939688110351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.995723247528076, "step": 132000}
{"episode_reward": 930.6719931343026, "episode": 133.0, "batch_reward": 0.8656973746418953, "critic_loss": 0.6186293174475431, "actor_loss": -82.93537753295898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.261958599090576, "step": 133000}
{"episode_reward": 885.1754040301905, "episode": 134.0, "batch_reward": 0.8645808700919151, "critic_loss": 0.6231964221000671, "actor_loss": -82.9863465423584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.23080611228943, "step": 134000}
{"episode_reward": 917.1789070432812, "episode": 135.0, "batch_reward": 0.8650378549695015, "critic_loss": 0.5925804336667061, "actor_loss": -83.00075291442872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.24969244003296, "step": 135000}
{"episode_reward": 955.2515821698051, "episode": 136.0, "batch_reward": 0.8668189630508423, "critic_loss": 0.6264410904198885, "actor_loss": -82.96079800415039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.858805656433105, "step": 136000}
{"episode_reward": 859.6006818543048, "episode": 137.0, "batch_reward": 0.867359571158886, "critic_loss": 0.6380840518921613, "actor_loss": -82.97017478942871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.71176052093506, "step": 137000}
{"episode_reward": 928.3797514798677, "episode": 138.0, "batch_reward": 0.8681606357097625, "critic_loss": 0.6410377895534038, "actor_loss": -83.35195315551758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.17262315750122, "step": 138000}
{"episode_reward": 937.2609292755378, "episode": 139.0, "batch_reward": 0.8684404712319375, "critic_loss": 0.6163495770543814, "actor_loss": -83.51338040161133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.248319625854492, "step": 139000}
{"episode_reward": 934.4054821886424, "episode": 140.0, "batch_reward": 0.868657953441143, "critic_loss": 0.6167793135643005, "actor_loss": -83.4274345703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.21500301361084, "step": 140000}
{"episode_reward": 943.2189619522716, "episode": 141.0, "batch_reward": 0.8686392819881439, "critic_loss": 0.6103585395962, "actor_loss": -83.28012886047364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.75435280799866, "step": 141000}
{"episode_reward": 940.9117971411857, "episode": 142.0, "batch_reward": 0.8689320487976074, "critic_loss": 0.6326750513613224, "actor_loss": -83.3279644317627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.585858583450317, "step": 142000}
{"episode_reward": 900.5232239137506, "episode": 143.0, "batch_reward": 0.870011088013649, "critic_loss": 0.6346815470308066, "actor_loss": -83.09155615234376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.593725442886353, "step": 143000}
{"episode_reward": 923.6718829027222, "episode": 144.0, "batch_reward": 0.8698821758627892, "critic_loss": 0.5975514078587294, "actor_loss": -83.29820883178711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.74512767791748, "step": 144000}
{"episode_reward": 884.4239849010564, "episode": 145.0, "batch_reward": 0.8692848932147026, "critic_loss": 0.6675734408944846, "actor_loss": -82.86261836242676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.89225697517395, "step": 145000}
{"episode_reward": 909.2315770751092, "episode": 146.0, "batch_reward": 0.8696353204250336, "critic_loss": 0.6583161213994027, "actor_loss": -83.35775538635254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.297996759414673, "step": 146000}
{"episode_reward": 949.7411299001166, "episode": 147.0, "batch_reward": 0.8705942326784134, "critic_loss": 0.6236201955676078, "actor_loss": -83.36289291381836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.368083953857422, "step": 147000}
{"episode_reward": 933.7541495594181, "episode": 148.0, "batch_reward": 0.8719851477146149, "critic_loss": 0.612626852914691, "actor_loss": -83.36789242553711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.2937273979187, "step": 148000}
{"episode_reward": 928.5716681166122, "episode": 149.0, "batch_reward": 0.8707607519626618, "critic_loss": 0.5899279671162367, "actor_loss": -83.2728662109375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.082220792770386, "step": 149000}
{"episode_reward": 944.9500412540083, "episode": 150.0, "batch_reward": 0.871144846379757, "critic_loss": 0.5902383304536343, "actor_loss": -83.34654013061524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
