{"episode_reward": 0.0, "episode": 1.0, "duration": 20.580231428146362, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.796442985534668, "step": 2000}
{"episode_reward": 973.7241921866618, "episode": 3.0, "batch_reward": 0.5401134731253611, "critic_loss": 0.4644435021744326, "actor_loss": -88.31805440682132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.329148292541504, "step": 3000}
{"episode_reward": 932.0471548233506, "episode": 4.0, "batch_reward": 0.6790595753192902, "critic_loss": 0.7877759666144848, "actor_loss": -92.4891499633789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.012967824935913, "step": 4000}
{"episode_reward": 915.8469278859027, "episode": 5.0, "batch_reward": 0.7408018268942833, "critic_loss": 0.7714343551397324, "actor_loss": -93.66883366394043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00777006149292, "step": 5000}
{"episode_reward": 956.5935287248149, "episode": 6.0, "batch_reward": 0.775153377532959, "critic_loss": 0.9199669481515884, "actor_loss": -94.25086111450196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003406286239624, "step": 6000}
{"episode_reward": 922.095115850381, "episode": 7.0, "batch_reward": 0.7957762606739998, "critic_loss": 0.9530723643302917, "actor_loss": -94.56717248535156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0144202709198, "step": 7000}
{"episode_reward": 913.1277412837844, "episode": 8.0, "batch_reward": 0.8040879349112511, "critic_loss": 2.3654512941241266, "actor_loss": -94.78878494262695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.009218454360962, "step": 8000}
{"episode_reward": 847.9483926587197, "episode": 9.0, "batch_reward": 0.8189008629918099, "critic_loss": 4.000739223957062, "actor_loss": -96.16022647094726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.375551223754883, "step": 9000}
{"episode_reward": 646.3550760877724, "episode": 10.0, "batch_reward": 0.8036852431297302, "critic_loss": 4.182742183089256, "actor_loss": -96.73635780334473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.335859060287476, "step": 10000}
{"episode_reward": 978.4729051323891, "episode": 11.0, "batch_reward": 0.7770606577396393, "critic_loss": 3.8067671036720276, "actor_loss": -97.76512350463867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.4506151676178, "step": 11000}
{"episode_reward": 16.099278563565054, "episode": 12.0, "batch_reward": 0.7391013956665993, "critic_loss": 3.0596207879781723, "actor_loss": -97.91656028747559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.995164155960083, "step": 12000}
{"episode_reward": 484.2144462231352, "episode": 13.0, "batch_reward": 0.6998774728178978, "critic_loss": 2.6728417773246766, "actor_loss": -97.59920195007324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01888942718506, "step": 13000}
{"episode_reward": 120.0970856010461, "episode": 14.0, "batch_reward": 0.6556363906860352, "critic_loss": 2.269552343785763, "actor_loss": -97.67561204528809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.023313760757446, "step": 14000}
{"episode_reward": 85.27333738247, "episode": 15.0, "batch_reward": 0.6203298037350178, "critic_loss": 1.9711295438408851, "actor_loss": -97.2224988861084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.014527797698975, "step": 15000}
{"episode_reward": 155.44269914842752, "episode": 16.0, "batch_reward": 0.5956416887938977, "critic_loss": 1.8259673542380332, "actor_loss": -97.0038305053711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.011083126068115, "step": 16000}
{"episode_reward": 262.35593158226686, "episode": 17.0, "batch_reward": 0.5661404614448547, "critic_loss": 1.5057283247709274, "actor_loss": -95.43763775634766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.039767742156982, "step": 17000}
{"episode_reward": 96.72873922755802, "episode": 18.0, "batch_reward": 0.5451357290744782, "critic_loss": 1.5386032283306121, "actor_loss": -94.76533045959472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02286458015442, "step": 18000}
{"episode_reward": 207.94561631486934, "episode": 19.0, "batch_reward": 0.5262755970060825, "critic_loss": 1.5480706161856652, "actor_loss": -93.27270581054688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.028949737548828, "step": 19000}
{"episode_reward": 223.59124268341824, "episode": 20.0, "batch_reward": 0.5157772155702114, "critic_loss": 1.679650291442871, "actor_loss": -92.14503616333008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00734829902649, "step": 20000}
{"episode_reward": 468.60797637970853, "episode": 21.0, "batch_reward": 0.5102110769152641, "critic_loss": 1.6154067980051041, "actor_loss": -92.16015060424805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.53515005111694, "step": 21000}
{"episode_reward": 283.4350628927972, "episode": 22.0, "batch_reward": 0.49858871468901633, "critic_loss": 1.4411101897358893, "actor_loss": -90.2654700012207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.023374319076538, "step": 22000}
{"episode_reward": 187.40851104816537, "episode": 23.0, "batch_reward": 0.4789835394024849, "critic_loss": 1.2477538630366325, "actor_loss": -89.32501942443848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.037043809890747, "step": 23000}
{"episode_reward": 12.879737780171187, "episode": 24.0, "batch_reward": 0.45853428623080256, "critic_loss": 1.2528431845903396, "actor_loss": -89.02874383544922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.011953830718994, "step": 24000}
{"episode_reward": 185.03405066178115, "episode": 25.0, "batch_reward": 0.4604034614264965, "critic_loss": 1.4006727797389031, "actor_loss": -87.79623387145996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002554178237915, "step": 25000}
{"episode_reward": 782.6918737610182, "episode": 26.0, "batch_reward": 0.472471959233284, "critic_loss": 1.5124655234217643, "actor_loss": -87.64891087341309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00192093849182, "step": 26000}
{"episode_reward": 847.8631205829239, "episode": 27.0, "batch_reward": 0.4904189938306808, "critic_loss": 1.7168276215791702, "actor_loss": -87.59203945922852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.991095781326294, "step": 27000}
{"episode_reward": 947.8357189571719, "episode": 28.0, "batch_reward": 0.5074566468596459, "critic_loss": 1.8787337210774422, "actor_loss": -87.78451979064941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003315210342407, "step": 28000}
{"episode_reward": 987.9893825624715, "episode": 29.0, "batch_reward": 0.5240854125320912, "critic_loss": 1.885620086669922, "actor_loss": -88.12530781555176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00189232826233, "step": 29000}
{"episode_reward": 961.8561840915751, "episode": 30.0, "batch_reward": 0.5407213823199272, "critic_loss": 1.7971513961553574, "actor_loss": -88.76266763305664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.008594512939453, "step": 30000}
{"episode_reward": 959.2585981009232, "episode": 31.0, "batch_reward": 0.5513897579908371, "critic_loss": 1.609429782152176, "actor_loss": -88.93495161437988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.31918239593506, "step": 31000}
{"episode_reward": 974.5450654339583, "episode": 32.0, "batch_reward": 0.5666261833906173, "critic_loss": 1.5185753673911095, "actor_loss": -89.48868482971191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.022652626037598, "step": 32000}
{"episode_reward": 956.0827920589982, "episode": 33.0, "batch_reward": 0.5794698755145073, "critic_loss": 1.4149951241612435, "actor_loss": -89.73413676452637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01764702796936, "step": 33000}
{"episode_reward": 986.6425070155691, "episode": 34.0, "batch_reward": 0.5916899454295635, "critic_loss": 1.2558229780197143, "actor_loss": -89.91522506713868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.018553018569946, "step": 34000}
{"episode_reward": 982.8123010932467, "episode": 35.0, "batch_reward": 0.6040797103941441, "critic_loss": 1.2096239705681802, "actor_loss": -90.38885670471191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.027731895446777, "step": 35000}
{"episode_reward": 945.5129319664569, "episode": 36.0, "batch_reward": 0.612061408817768, "critic_loss": 1.2362065308094026, "actor_loss": -90.53678074645997, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.016265392303467, "step": 36000}
{"episode_reward": 941.9962410548509, "episode": 37.0, "batch_reward": 0.622292512446642, "critic_loss": 1.3795589475035668, "actor_loss": -91.02334741210937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00096893310547, "step": 37000}
{"episode_reward": 924.6499109654153, "episode": 38.0, "batch_reward": 0.6286453807055951, "critic_loss": 1.3554344172477721, "actor_loss": -91.12310485839843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01111888885498, "step": 38000}
{"episode_reward": 960.6594874004683, "episode": 39.0, "batch_reward": 0.6372725531458855, "critic_loss": 1.3785246021151543, "actor_loss": -91.30355673217774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0197811126709, "step": 39000}
{"episode_reward": 991.4707550231433, "episode": 40.0, "batch_reward": 0.6458061259388924, "critic_loss": 1.526517946511507, "actor_loss": -91.16185047912597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01106071472168, "step": 40000}
{"episode_reward": 919.8907577572886, "episode": 41.0, "batch_reward": 0.6507564918994904, "critic_loss": 1.3388126468658448, "actor_loss": -91.45904792785645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.360888957977295, "step": 41000}
{"episode_reward": 953.902468310599, "episode": 42.0, "batch_reward": 0.6604728329181672, "critic_loss": 1.2274365157186986, "actor_loss": -91.62611430358886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.008854389190674, "step": 42000}
{"episode_reward": 977.1041249205254, "episode": 43.0, "batch_reward": 0.6680687652230263, "critic_loss": 1.0561148934066296, "actor_loss": -91.59544215393066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997775554656982, "step": 43000}
{"episode_reward": 950.1434621521116, "episode": 44.0, "batch_reward": 0.67463417583704, "critic_loss": 0.8912754536271096, "actor_loss": -91.71013436889649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00495147705078, "step": 44000}
{"episode_reward": 960.8131388732834, "episode": 45.0, "batch_reward": 0.6803091917037963, "critic_loss": 0.8228858457058668, "actor_loss": -91.83545053100586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002353191375732, "step": 45000}
{"episode_reward": 959.3666895660314, "episode": 46.0, "batch_reward": 0.6881402732133866, "critic_loss": 0.8214680662155152, "actor_loss": -91.89470944213868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986815690994263, "step": 46000}
{"episode_reward": 980.4416719603744, "episode": 47.0, "batch_reward": 0.69393017578125, "critic_loss": 0.7184975018799304, "actor_loss": -91.9969924621582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.010709762573242, "step": 47000}
{"episode_reward": 962.1985045690466, "episode": 48.0, "batch_reward": 0.6976411697864533, "critic_loss": 0.6955057118535042, "actor_loss": -92.09249473571778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.015690326690674, "step": 48000}
{"episode_reward": 940.9491174900157, "episode": 49.0, "batch_reward": 0.7048961733579635, "critic_loss": 0.574223163023591, "actor_loss": -92.07295335388184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.032638788223267, "step": 49000}
{"episode_reward": 964.402621927888, "episode": 50.0, "batch_reward": 0.7071114376783371, "critic_loss": 0.5778419977575541, "actor_loss": -92.23034300231933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.996800422668457, "step": 50000}
{"episode_reward": 961.3907871280354, "episode": 51.0, "batch_reward": 0.7131196222901345, "critic_loss": 0.5173790165036917, "actor_loss": -92.12369453430176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.36806893348694, "step": 51000}
{"episode_reward": 944.7414920527922, "episode": 52.0, "batch_reward": 0.7205959972143173, "critic_loss": 0.49838664089143275, "actor_loss": -92.438201171875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99595546722412, "step": 52000}
{"episode_reward": 938.1563603569919, "episode": 53.0, "batch_reward": 0.723380573451519, "critic_loss": 0.48662012185156345, "actor_loss": -92.3753000946045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00234079360962, "step": 53000}
{"episode_reward": 943.4686711113225, "episode": 54.0, "batch_reward": 0.7288316658735275, "critic_loss": 0.457610014975071, "actor_loss": -92.41852336120606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999507904052734, "step": 54000}
{"episode_reward": 983.564213926931, "episode": 55.0, "batch_reward": 0.7312860110402107, "critic_loss": 0.4162073626071215, "actor_loss": -92.51796850585937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002092123031616, "step": 55000}
{"episode_reward": 978.5378119012637, "episode": 56.0, "batch_reward": 0.7340729347467423, "critic_loss": 0.4599964703321457, "actor_loss": -92.51176994323731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00591802597046, "step": 56000}
{"episode_reward": 937.9104133900235, "episode": 57.0, "batch_reward": 0.7404860692024231, "critic_loss": 0.4264909279346466, "actor_loss": -92.5980418395996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00774621963501, "step": 57000}
{"episode_reward": 953.4599346908813, "episode": 58.0, "batch_reward": 0.7444421488046646, "critic_loss": 0.4117038787305355, "actor_loss": -92.59651295471191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.012029886245728, "step": 58000}
{"episode_reward": 968.7656195715347, "episode": 59.0, "batch_reward": 0.7477941107749939, "critic_loss": 0.47047112421691417, "actor_loss": -92.59010066223145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99921941757202, "step": 59000}
{"episode_reward": 944.7113405257337, "episode": 60.0, "batch_reward": 0.7523787407279015, "critic_loss": 0.48408586516976354, "actor_loss": -92.76763981628417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.019026041030884, "step": 60000}
{"episode_reward": 982.4343225374398, "episode": 61.0, "batch_reward": 0.753256966650486, "critic_loss": 0.4113824351578951, "actor_loss": -92.80695985412598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.36091756820679, "step": 61000}
{"episode_reward": 930.809207305073, "episode": 62.0, "batch_reward": 0.7570850661396981, "critic_loss": 0.39555341109633446, "actor_loss": -92.7611797027588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.026553869247437, "step": 62000}
{"episode_reward": 952.6170676917637, "episode": 63.0, "batch_reward": 0.7609295491576195, "critic_loss": 0.4171765836775303, "actor_loss": -92.71322357177735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003384590148926, "step": 63000}
{"episode_reward": 939.9223141461717, "episode": 64.0, "batch_reward": 0.7635603947043419, "critic_loss": 0.40935906282067297, "actor_loss": -92.69587727355957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00836443901062, "step": 64000}
{"episode_reward": 987.0520730553475, "episode": 65.0, "batch_reward": 0.7673250477313995, "critic_loss": 0.36787703722715376, "actor_loss": -92.76087850952149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01551628112793, "step": 65000}
{"episode_reward": 932.8731439379457, "episode": 66.0, "batch_reward": 0.7707701304554939, "critic_loss": 0.4017816174030304, "actor_loss": -92.77411595153809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03148603439331, "step": 66000}
{"episode_reward": 979.1763601585182, "episode": 67.0, "batch_reward": 0.7712718383073807, "critic_loss": 0.5053583091497421, "actor_loss": -92.81513696289062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.018909692764282, "step": 67000}
{"episode_reward": 953.1750239894401, "episode": 68.0, "batch_reward": 0.7766030548214913, "critic_loss": 0.4411084280014038, "actor_loss": -92.93365797424316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0134015083313, "step": 68000}
{"episode_reward": 981.5517577057843, "episode": 69.0, "batch_reward": 0.7797883610129357, "critic_loss": 0.39567742390930655, "actor_loss": -92.97447758483887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00561833381653, "step": 69000}
{"episode_reward": 957.2531072234909, "episode": 70.0, "batch_reward": 0.7785097032189369, "critic_loss": 0.4971045460999012, "actor_loss": -92.95312425231934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00589394569397, "step": 70000}
{"episode_reward": 907.7591255629931, "episode": 71.0, "batch_reward": 0.7830891710519791, "critic_loss": 0.45218988662958143, "actor_loss": -92.98082960510254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.35533595085144, "step": 71000}
{"episode_reward": 917.6922729304214, "episode": 72.0, "batch_reward": 0.7840262123942375, "critic_loss": 0.4477736475467682, "actor_loss": -92.82413046264648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.023707628250122, "step": 72000}
{"episode_reward": 918.9193156275435, "episode": 73.0, "batch_reward": 0.7872983665466309, "critic_loss": 0.45010630932450296, "actor_loss": -92.75189701843262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999706268310547, "step": 73000}
{"episode_reward": 978.0669806048732, "episode": 74.0, "batch_reward": 0.7897851897478103, "critic_loss": 0.4760165167599916, "actor_loss": -92.84963404846191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00925064086914, "step": 74000}
{"episode_reward": 972.9417834804233, "episode": 75.0, "batch_reward": 0.792071859061718, "critic_loss": 0.4546051294803619, "actor_loss": -92.89057618713379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.013867616653442, "step": 75000}
{"episode_reward": 938.1348802623414, "episode": 76.0, "batch_reward": 0.7932472305893898, "critic_loss": 0.4586457507610321, "actor_loss": -92.88860929870606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0138897895813, "step": 76000}
{"episode_reward": 962.9984952101482, "episode": 77.0, "batch_reward": 0.7957856127023697, "critic_loss": 0.4943473417758942, "actor_loss": -92.81649215698242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01050090789795, "step": 77000}
{"episode_reward": 937.9701946722165, "episode": 78.0, "batch_reward": 0.798750856757164, "critic_loss": 0.47747181326150895, "actor_loss": -92.8505626373291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99676012992859, "step": 78000}
{"episode_reward": 984.3819166614323, "episode": 79.0, "batch_reward": 0.7994417610168457, "critic_loss": 0.48053756867349146, "actor_loss": -92.91276940917969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003364086151123, "step": 79000}
{"episode_reward": 976.5546844276549, "episode": 80.0, "batch_reward": 0.8014285408854485, "critic_loss": 0.5196846105307341, "actor_loss": -92.90625627136231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.010407209396362, "step": 80000}
{"episode_reward": 989.3778747833253, "episode": 81.0, "batch_reward": 0.8047543376088142, "critic_loss": 0.5045202141553163, "actor_loss": -93.00664881896972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.35939145088196, "step": 81000}
{"episode_reward": 976.1538603176712, "episode": 82.0, "batch_reward": 0.806051236987114, "critic_loss": 0.5144660239368677, "actor_loss": -93.01200692749023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997087717056274, "step": 82000}
{"episode_reward": 950.6920302092176, "episode": 83.0, "batch_reward": 0.8095484254956246, "critic_loss": 0.47367647610604763, "actor_loss": -93.09630990600586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.011392831802368, "step": 83000}
{"episode_reward": 975.6183325512511, "episode": 84.0, "batch_reward": 0.8105629050135612, "critic_loss": 0.48771354103088377, "actor_loss": -93.15332431030274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.016666650772095, "step": 84000}
{"episode_reward": 991.2645097880473, "episode": 85.0, "batch_reward": 0.8122652503848076, "critic_loss": 0.4538314353823662, "actor_loss": -93.16578280639648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02125382423401, "step": 85000}
{"episode_reward": 962.8663852950958, "episode": 86.0, "batch_reward": 0.8135288296341896, "critic_loss": 0.4704643851220608, "actor_loss": -93.08580825805664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.015474319458008, "step": 86000}
{"episode_reward": 930.8251080952659, "episode": 87.0, "batch_reward": 0.8148766719102859, "critic_loss": 0.4827587545365095, "actor_loss": -93.09339266967774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.022480964660645, "step": 87000}
{"episode_reward": 951.5986762874564, "episode": 88.0, "batch_reward": 0.8175223088860512, "critic_loss": 0.45354813311994074, "actor_loss": -93.21593379211426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.028775453567505, "step": 88000}
{"episode_reward": 972.251255676738, "episode": 89.0, "batch_reward": 0.8197527263760567, "critic_loss": 0.48639540126919745, "actor_loss": -93.37796160888672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.998761415481567, "step": 89000}
{"episode_reward": 962.6324949880332, "episode": 90.0, "batch_reward": 0.8216777940392495, "critic_loss": 0.4301348045915365, "actor_loss": -93.46971809387207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99754571914673, "step": 90000}
{"episode_reward": 950.1652317417708, "episode": 91.0, "batch_reward": 0.8205105816125869, "critic_loss": 0.4335645993500948, "actor_loss": -93.3688508605957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.34062337875366, "step": 91000}
{"episode_reward": 939.7759662982721, "episode": 92.0, "batch_reward": 0.8236467842459678, "critic_loss": 0.3970413402616978, "actor_loss": -93.29653004455567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.012887001037598, "step": 92000}
{"episode_reward": 985.8611072314785, "episode": 93.0, "batch_reward": 0.825097034394741, "critic_loss": 0.4468445570766926, "actor_loss": -93.44925917053223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.020239114761353, "step": 93000}
{"episode_reward": 975.9939631040203, "episode": 94.0, "batch_reward": 0.8282860628366471, "critic_loss": 0.43885436016321183, "actor_loss": -93.52457327270508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005202770233154, "step": 94000}
{"episode_reward": 974.4575234607483, "episode": 95.0, "batch_reward": 0.8270437986254692, "critic_loss": 0.3916966451704502, "actor_loss": -93.53948469543457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99269199371338, "step": 95000}
{"episode_reward": 963.2728549818418, "episode": 96.0, "batch_reward": 0.829561195909977, "critic_loss": 0.4116764068156481, "actor_loss": -93.51927688598633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.014710664749146, "step": 96000}
{"episode_reward": 980.8446045711983, "episode": 97.0, "batch_reward": 0.8305024031996727, "critic_loss": 0.42520044504106047, "actor_loss": -93.64385000610352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00080895423889, "step": 97000}
{"episode_reward": 983.7093939332542, "episode": 98.0, "batch_reward": 0.8334773467183113, "critic_loss": 0.3734554277583957, "actor_loss": -93.69815376281738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.013773918151855, "step": 98000}
{"episode_reward": 987.1478819683028, "episode": 99.0, "batch_reward": 0.833544058084488, "critic_loss": 0.3863813864439726, "actor_loss": -93.73443278503417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01974129676819, "step": 99000}
{"episode_reward": 976.585173726334, "episode": 100.0, "batch_reward": 0.8360279126763344, "critic_loss": 0.3636806121990085, "actor_loss": -93.8061622619629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03030776977539, "step": 100000}
{"episode_reward": 962.6587671296397, "episode": 101.0, "batch_reward": 0.8365110496878624, "critic_loss": 0.34883196335285904, "actor_loss": -93.85282963562011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.35715889930725, "step": 101000}
{"episode_reward": 944.5187261210987, "episode": 102.0, "batch_reward": 0.8380890532732009, "critic_loss": 0.3554176595211029, "actor_loss": -93.92590390014648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.009657382965088, "step": 102000}
{"episode_reward": 936.4576668704286, "episode": 103.0, "batch_reward": 0.8388464795947075, "critic_loss": 0.33849327298253773, "actor_loss": -93.91270310974122, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002423524856567, "step": 103000}
{"episode_reward": 983.9983669407756, "episode": 104.0, "batch_reward": 0.8417436964511872, "critic_loss": 0.3503066384270787, "actor_loss": -94.01405702209473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004460096359253, "step": 104000}
{"episode_reward": 961.6977344150113, "episode": 105.0, "batch_reward": 0.8418703131079673, "critic_loss": 0.34450132709741593, "actor_loss": -93.97358389282226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.000977277755737, "step": 105000}
{"episode_reward": 985.4825416307268, "episode": 106.0, "batch_reward": 0.8432924311757087, "critic_loss": 0.3859139267280698, "actor_loss": -94.11331521606445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007707357406616, "step": 106000}
{"episode_reward": 982.6329500918224, "episode": 107.0, "batch_reward": 0.8434995341300965, "critic_loss": 0.35206007697433234, "actor_loss": -94.10964268493652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006774425506592, "step": 107000}
{"episode_reward": 943.3216525223705, "episode": 108.0, "batch_reward": 0.8454716017842293, "critic_loss": 0.3643472795188427, "actor_loss": -94.12567947387696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00332736968994, "step": 108000}
{"episode_reward": 988.7449772269628, "episode": 109.0, "batch_reward": 0.8468134444355965, "critic_loss": 0.36353584702312947, "actor_loss": -94.05141206359863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.009711503982544, "step": 109000}
{"episode_reward": 992.5657576083544, "episode": 110.0, "batch_reward": 0.849085232257843, "critic_loss": 0.405546231970191, "actor_loss": -94.14418142700195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002566814422607, "step": 110000}
{"episode_reward": 960.9173028011852, "episode": 111.0, "batch_reward": 0.8504018515348435, "critic_loss": 0.35728299065679314, "actor_loss": -94.14471490478516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.36058068275452, "step": 111000}
{"episode_reward": 953.2121886208555, "episode": 112.0, "batch_reward": 0.8483032388091087, "critic_loss": 0.3307846719920635, "actor_loss": -94.16549629211426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.016833066940308, "step": 112000}
{"episode_reward": 944.2785057349752, "episode": 113.0, "batch_reward": 0.8512574976086617, "critic_loss": 0.31666198615729807, "actor_loss": -94.1617603302002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.021185874938965, "step": 113000}
{"episode_reward": 971.4951570899705, "episode": 114.0, "batch_reward": 0.8514079739451408, "critic_loss": 0.3317835435271263, "actor_loss": -94.17450311279296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.025299310684204, "step": 114000}
{"episode_reward": 985.8857688040941, "episode": 115.0, "batch_reward": 0.8538257856965065, "critic_loss": 0.36763833291828635, "actor_loss": -94.31645123291015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.024068593978882, "step": 115000}
{"episode_reward": 988.0997643489437, "episode": 116.0, "batch_reward": 0.8540019444227218, "critic_loss": 0.3355152848511934, "actor_loss": -94.30932453918457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.016427040100098, "step": 116000}
{"episode_reward": 959.6207876982411, "episode": 117.0, "batch_reward": 0.8536685635447502, "critic_loss": 0.3643540627807379, "actor_loss": -94.29673873901368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.011794567108154, "step": 117000}
{"episode_reward": 846.3759971183267, "episode": 118.0, "batch_reward": 0.8556682258844376, "critic_loss": 0.34295248947292567, "actor_loss": -94.26332330322266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.019259214401245, "step": 118000}
{"episode_reward": 990.2641514879325, "episode": 119.0, "batch_reward": 0.8558076671957969, "critic_loss": 0.3384810929521918, "actor_loss": -94.26712664794921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.023962020874023, "step": 119000}
{"episode_reward": 971.9818344525877, "episode": 120.0, "batch_reward": 0.8554466446638107, "critic_loss": 0.35766965041309595, "actor_loss": -94.33359426879883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.009886026382446, "step": 120000}
{"episode_reward": 986.4533087570683, "episode": 121.0, "batch_reward": 0.8578378247022629, "critic_loss": 0.3385155530795455, "actor_loss": -94.34455639648438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.348443269729614, "step": 121000}
{"episode_reward": 984.12261852796, "episode": 122.0, "batch_reward": 0.8610442932248116, "critic_loss": 0.3648124693185091, "actor_loss": -94.37052217102051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.012434720993042, "step": 122000}
{"episode_reward": 959.6702436982654, "episode": 123.0, "batch_reward": 0.8602937862277031, "critic_loss": 0.40926951402425765, "actor_loss": -94.31247090148926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005823612213135, "step": 123000}
{"episode_reward": 936.698974247825, "episode": 124.0, "batch_reward": 0.8600644845962524, "critic_loss": 0.3747550816237927, "actor_loss": -94.23750350952149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02024269104004, "step": 124000}
{"episode_reward": 991.7608007552162, "episode": 125.0, "batch_reward": 0.8625709307789803, "critic_loss": 0.38341608924418685, "actor_loss": -94.34123550415039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01443386077881, "step": 125000}
{"episode_reward": 959.3891799234453, "episode": 126.0, "batch_reward": 0.860100310087204, "critic_loss": 0.4422147483155131, "actor_loss": -94.26827322387695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.020739555358887, "step": 126000}
{"episode_reward": 891.975747361528, "episode": 127.0, "batch_reward": 0.8620838978886605, "critic_loss": 0.4232656476125121, "actor_loss": -94.22795666503906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0175199508667, "step": 127000}
{"episode_reward": 971.6703164323868, "episode": 128.0, "batch_reward": 0.8628526904582977, "critic_loss": 0.40812375578284266, "actor_loss": -94.24390345764161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.043617725372314, "step": 128000}
{"episode_reward": 974.7548038141819, "episode": 129.0, "batch_reward": 0.8650365571379661, "critic_loss": 0.4625139707028866, "actor_loss": -94.27876850891113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.008588790893555, "step": 129000}
{"episode_reward": 935.383921421586, "episode": 130.0, "batch_reward": 0.8654949541091919, "critic_loss": 0.4882301031053066, "actor_loss": -94.26720233154298, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006820678710938, "step": 130000}
{"episode_reward": 930.5058040070836, "episode": 131.0, "batch_reward": 0.8646711218357086, "critic_loss": 0.48008158814907076, "actor_loss": -94.07893215942383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.33360290527344, "step": 131000}
{"episode_reward": 962.8917307698315, "episode": 132.0, "batch_reward": 0.8646313118934631, "critic_loss": 0.4593355055898428, "actor_loss": -94.17710284423828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.012394905090332, "step": 132000}
{"episode_reward": 959.9074954749384, "episode": 133.0, "batch_reward": 0.8658413498401641, "critic_loss": 0.46046209171414376, "actor_loss": -94.2971402130127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997785568237305, "step": 133000}
{"episode_reward": 923.0818241868117, "episode": 134.0, "batch_reward": 0.8657110947966575, "critic_loss": 0.48221951952576636, "actor_loss": -94.25797981262207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.998520851135254, "step": 134000}
{"episode_reward": 924.3601035507156, "episode": 135.0, "batch_reward": 0.8658531516194343, "critic_loss": 0.5214672626107931, "actor_loss": -94.26737574768066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0108380317688, "step": 135000}
{"episode_reward": 957.0497488620961, "episode": 136.0, "batch_reward": 0.868096563398838, "critic_loss": 0.49402898487448693, "actor_loss": -94.42711109924316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01452088356018, "step": 136000}
{"episode_reward": 897.32413221569, "episode": 137.0, "batch_reward": 0.8687022376656532, "critic_loss": 0.5089743933230638, "actor_loss": -94.4300258026123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006443977355957, "step": 137000}
{"episode_reward": 987.6117331929719, "episode": 138.0, "batch_reward": 0.8694607159495353, "critic_loss": 0.4804155715480447, "actor_loss": -94.29003053283691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02887511253357, "step": 138000}
{"episode_reward": 943.6536767343027, "episode": 139.0, "batch_reward": 0.8699353876709938, "critic_loss": 0.49603799449652436, "actor_loss": -94.26859214782715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.021842002868652, "step": 139000}
{"episode_reward": 962.9754111588849, "episode": 140.0, "batch_reward": 0.8704398690462113, "critic_loss": 0.49027418361604214, "actor_loss": -94.29350840759277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.026583671569824, "step": 140000}
{"episode_reward": 952.400349208189, "episode": 141.0, "batch_reward": 0.8706103492975235, "critic_loss": 0.44178280131518843, "actor_loss": -94.36830088806153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.39145302772522, "step": 141000}
{"episode_reward": 990.0701187965619, "episode": 142.0, "batch_reward": 0.8711269974708558, "critic_loss": 0.47728406738489865, "actor_loss": -94.39953053283692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.001638174057007, "step": 142000}
{"episode_reward": 958.3960922827091, "episode": 143.0, "batch_reward": 0.8723486788272857, "critic_loss": 0.48533232484012845, "actor_loss": -94.47089205932618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006223678588867, "step": 143000}
{"episode_reward": 981.2941648470629, "episode": 144.0, "batch_reward": 0.8751365680098534, "critic_loss": 0.4512571860998869, "actor_loss": -94.47242520141602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.910495281219482, "step": 144000}
{"episode_reward": 961.021867770083, "episode": 145.0, "batch_reward": 0.8735797758102417, "critic_loss": 0.43470133715868, "actor_loss": -94.54263349914551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.886748552322388, "step": 145000}
{"episode_reward": 976.2395525157154, "episode": 146.0, "batch_reward": 0.8742181241512299, "critic_loss": 0.4637692464441061, "actor_loss": -94.397164352417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88130497932434, "step": 146000}
{"episode_reward": 988.0451217373155, "episode": 147.0, "batch_reward": 0.8761222857236862, "critic_loss": 0.4652396724820137, "actor_loss": -94.47510940551757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88046145439148, "step": 147000}
{"episode_reward": 963.9305505192843, "episode": 148.0, "batch_reward": 0.8770147354602814, "critic_loss": 0.48046317087113855, "actor_loss": -94.57233085632325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.875571250915527, "step": 148000}
{"episode_reward": 957.5436585649051, "episode": 149.0, "batch_reward": 0.8752082234621048, "critic_loss": 0.4426149595230818, "actor_loss": -94.59935011291503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.885485887527466, "step": 149000}
{"episode_reward": 988.2015268932095, "episode": 150.0, "batch_reward": 0.8781755118966103, "critic_loss": 0.4413089701831341, "actor_loss": -94.61659605407715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
