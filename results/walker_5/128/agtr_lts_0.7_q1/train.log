{"episode_reward": 0.0, "episode": 1.0, "duration": 21.07243299484253, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.8370466232299805, "step": 2000}
{"episode_reward": 632.427646246406, "episode": 3.0, "batch_reward": 0.3355702518840439, "critic_loss": 0.26974307803580583, "actor_loss": -50.05051763218884, "actor_target_entropy": -6.0, "alpha_value": 0.004365629073060301, "duration": 62.62931561470032, "step": 3000}
{"episode_reward": 155.5349351527943, "episode": 4.0, "batch_reward": 0.2823261711448431, "critic_loss": 0.5470855432748795, "actor_loss": -47.56959215927124, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.372520208358765, "step": 4000}
{"episode_reward": 288.461905464205, "episode": 5.0, "batch_reward": 0.28748149672150614, "critic_loss": 0.6504119009077549, "actor_loss": -49.44666667461395, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.73425054550171, "step": 5000}
{"episode_reward": 326.9741345934625, "episode": 6.0, "batch_reward": 0.3051247208863497, "critic_loss": 0.7095825398862362, "actor_loss": -49.56856180429459, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.81210684776306, "step": 6000}
{"episode_reward": 428.9289035816515, "episode": 7.0, "batch_reward": 0.3161687263250351, "critic_loss": 0.8215021830499172, "actor_loss": -51.03186496067047, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.765095949172974, "step": 7000}
{"episode_reward": 445.30255163766196, "episode": 8.0, "batch_reward": 0.3527552260458469, "critic_loss": 0.9488518676161766, "actor_loss": -50.12101152896881, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.880213499069214, "step": 8000}
{"episode_reward": 664.7839524672565, "episode": 9.0, "batch_reward": 0.37691068333387373, "critic_loss": 1.1850760382413865, "actor_loss": -50.65334589958191, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.635361909866333, "step": 9000}
{"episode_reward": 466.49544544529823, "episode": 10.0, "batch_reward": 0.40387870994210245, "critic_loss": 1.3718353145718574, "actor_loss": -54.317793809890745, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.451244354248047, "step": 10000}
{"episode_reward": 702.5589925763434, "episode": 11.0, "batch_reward": 0.43265520012378694, "critic_loss": 1.38012775015831, "actor_loss": -53.7645297164917, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.01778507232666, "step": 11000}
{"episode_reward": 794.5557633722317, "episode": 12.0, "batch_reward": 0.46634818956255913, "critic_loss": 1.2430421412587165, "actor_loss": -56.45196747970581, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.55495262145996, "step": 12000}
{"episode_reward": 798.6939560126264, "episode": 13.0, "batch_reward": 0.4932406786084175, "critic_loss": 1.1447742928862572, "actor_loss": -58.312386947631836, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.34935426712036, "step": 13000}
{"episode_reward": 855.5279346509216, "episode": 14.0, "batch_reward": 0.5177705594897271, "critic_loss": 1.2143038697838784, "actor_loss": -59.17622254943848, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.209686279296875, "step": 14000}
{"episode_reward": 776.6622351980998, "episode": 15.0, "batch_reward": 0.5375280483663082, "critic_loss": 1.161097165942192, "actor_loss": -60.29151501464844, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.4746413230896, "step": 15000}
{"episode_reward": 828.9611202939344, "episode": 16.0, "batch_reward": 0.5550222163498402, "critic_loss": 1.21446501994133, "actor_loss": -60.41789635848999, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.36957025527954, "step": 16000}
{"episode_reward": 763.6655031780328, "episode": 17.0, "batch_reward": 0.5690612881183624, "critic_loss": 1.273701822221279, "actor_loss": -61.953130710601805, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.497984647750854, "step": 17000}
{"episode_reward": 843.9837273323204, "episode": 18.0, "batch_reward": 0.5858804239332676, "critic_loss": 1.2721684780716895, "actor_loss": -62.67614398956299, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.689770221710205, "step": 18000}
{"episode_reward": 858.2736828926343, "episode": 19.0, "batch_reward": 0.5967859757542611, "critic_loss": 1.335924791574478, "actor_loss": -64.10862099456787, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.11354112625122, "step": 19000}
{"episode_reward": 799.2471969205463, "episode": 20.0, "batch_reward": 0.607121067404747, "critic_loss": 1.2997773181796073, "actor_loss": -64.92281639862061, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.374809980392456, "step": 20000}
{"episode_reward": 744.0150696487575, "episode": 21.0, "batch_reward": 0.6179122461676597, "critic_loss": 1.2891642392277718, "actor_loss": -64.19808868408204, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.72904109954834, "step": 21000}
{"episode_reward": 870.1880120601703, "episode": 22.0, "batch_reward": 0.6205665261149407, "critic_loss": 1.3372912179231644, "actor_loss": -66.58821992492676, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.368035316467285, "step": 22000}
{"episode_reward": 694.289967566222, "episode": 23.0, "batch_reward": 0.6316684280633926, "critic_loss": 1.265307336628437, "actor_loss": -67.2357066116333, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.856927633285522, "step": 23000}
{"episode_reward": 853.580626947402, "episode": 24.0, "batch_reward": 0.6387952095270157, "critic_loss": 1.2498604590296745, "actor_loss": -65.9856135482788, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.83333659172058, "step": 24000}
{"episode_reward": 836.5599500007265, "episode": 25.0, "batch_reward": 0.6480690024495125, "critic_loss": 1.1799239822626113, "actor_loss": -68.2491244354248, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.830466270446777, "step": 25000}
{"episode_reward": 887.4461612665076, "episode": 26.0, "batch_reward": 0.6571174836158753, "critic_loss": 1.1437529308199883, "actor_loss": -67.75814163970948, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.506518840789795, "step": 26000}
{"episode_reward": 830.4804446834794, "episode": 27.0, "batch_reward": 0.6624645124077797, "critic_loss": 1.1899636853337288, "actor_loss": -68.82414978027344, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.74925661087036, "step": 27000}
{"episode_reward": 785.3526267432339, "episode": 28.0, "batch_reward": 0.6693937682509422, "critic_loss": 1.2154215653538705, "actor_loss": -69.23911692047119, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.031238555908203, "step": 28000}
{"episode_reward": 868.3315915620202, "episode": 29.0, "batch_reward": 0.6753090270757676, "critic_loss": 1.23701892131567, "actor_loss": -69.86775090026856, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.48688769340515, "step": 29000}
{"episode_reward": 794.005819558781, "episode": 30.0, "batch_reward": 0.6810988912582397, "critic_loss": 1.1538015176057816, "actor_loss": -69.80920375061035, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.73881196975708, "step": 30000}
{"episode_reward": 894.8813952799894, "episode": 31.0, "batch_reward": 0.6873259579539299, "critic_loss": 1.1921177686452866, "actor_loss": -70.69007577514648, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.26239490509033, "step": 31000}
{"episode_reward": 770.7174440323699, "episode": 32.0, "batch_reward": 0.6904395416975021, "critic_loss": 1.2340758271217347, "actor_loss": -70.84919134521485, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.793731927871704, "step": 32000}
{"episode_reward": 860.6974466237385, "episode": 33.0, "batch_reward": 0.698424853026867, "critic_loss": 1.1633947265148163, "actor_loss": -71.69281878662109, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.243523359298706, "step": 33000}
{"episode_reward": 906.983173654931, "episode": 34.0, "batch_reward": 0.7028979974389076, "critic_loss": 1.2318677716255189, "actor_loss": -72.33611358642578, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.36122751235962, "step": 34000}
{"episode_reward": 873.7776689830235, "episode": 35.0, "batch_reward": 0.7050226175189018, "critic_loss": 1.2634857496023177, "actor_loss": -72.0002879638672, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.57188081741333, "step": 35000}
{"episode_reward": 799.58459396671, "episode": 36.0, "batch_reward": 0.7087753272652626, "critic_loss": 1.1545338351130485, "actor_loss": -72.55984104919433, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.558781385421753, "step": 36000}
{"episode_reward": 828.4039127773827, "episode": 37.0, "batch_reward": 0.7120399236679077, "critic_loss": 1.1455513148903846, "actor_loss": -72.56693049621582, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.860487461090088, "step": 37000}
{"episode_reward": 788.7920868745783, "episode": 38.0, "batch_reward": 0.7110476344227791, "critic_loss": 1.1803298399448394, "actor_loss": -73.05768717956543, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.721030712127686, "step": 38000}
{"episode_reward": 803.2644156764684, "episode": 39.0, "batch_reward": 0.7169893369674682, "critic_loss": 1.1341674978137015, "actor_loss": -73.59129170227051, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.73605704307556, "step": 39000}
{"episode_reward": 839.9551276053236, "episode": 40.0, "batch_reward": 0.716470288336277, "critic_loss": 1.1006879016160964, "actor_loss": -74.21031247711181, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.389688968658447, "step": 40000}
{"episode_reward": 791.8261685520639, "episode": 41.0, "batch_reward": 0.7219324873089791, "critic_loss": 1.146894487798214, "actor_loss": -74.11661199951172, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.15671682357788, "step": 41000}
{"episode_reward": 844.7405637638522, "episode": 42.0, "batch_reward": 0.7240040552616119, "critic_loss": 1.1266743162870407, "actor_loss": -74.25832530212402, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.633153438568115, "step": 42000}
{"episode_reward": 817.883154631528, "episode": 43.0, "batch_reward": 0.7265142313241959, "critic_loss": 1.1255947626829148, "actor_loss": -74.82157335662842, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.369810581207275, "step": 43000}
{"episode_reward": 851.908091451922, "episode": 44.0, "batch_reward": 0.728417440533638, "critic_loss": 1.1112566713690757, "actor_loss": -74.43020269012452, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.70764994621277, "step": 44000}
{"episode_reward": 853.7490365794985, "episode": 45.0, "batch_reward": 0.7318974500894546, "critic_loss": 1.0625990481376648, "actor_loss": -74.3651504058838, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.62746500968933, "step": 45000}
{"episode_reward": 822.072214858549, "episode": 46.0, "batch_reward": 0.7341214721798897, "critic_loss": 1.065542101919651, "actor_loss": -74.89677545166016, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.35338306427002, "step": 46000}
{"episode_reward": 884.4458997005723, "episode": 47.0, "batch_reward": 0.7362146998643875, "critic_loss": 1.1070672535300254, "actor_loss": -74.99210600280762, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.875277757644653, "step": 47000}
{"episode_reward": 774.2622212007191, "episode": 48.0, "batch_reward": 0.7381875997185707, "critic_loss": 1.1698412919640542, "actor_loss": -74.98209492492676, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.707867860794067, "step": 48000}
{"episode_reward": 849.0789119083569, "episode": 49.0, "batch_reward": 0.7422354718446732, "critic_loss": 1.1289671390652656, "actor_loss": -75.5002894897461, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.074557065963745, "step": 49000}
{"episode_reward": 835.8116470040238, "episode": 50.0, "batch_reward": 0.7409831674098969, "critic_loss": 1.2145713928341866, "actor_loss": -75.3985626373291, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.43666172027588, "step": 50000}
{"episode_reward": 824.034742395866, "episode": 51.0, "batch_reward": 0.7464892552495003, "critic_loss": 1.1990975829958916, "actor_loss": -76.15603245544433, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.5027129650116, "step": 51000}
{"episode_reward": 876.1627832952179, "episode": 52.0, "batch_reward": 0.7465513219237327, "critic_loss": 1.0643848755955696, "actor_loss": -75.73968325805664, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.38842535018921, "step": 52000}
{"episode_reward": 887.4240243338232, "episode": 53.0, "batch_reward": 0.7480889084339142, "critic_loss": 1.0758424298167228, "actor_loss": -76.08935510253906, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.64112663269043, "step": 53000}
{"episode_reward": 820.2741135388662, "episode": 54.0, "batch_reward": 0.7494292545318604, "critic_loss": 1.0988776779174805, "actor_loss": -76.35508610534669, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.27434778213501, "step": 54000}
{"episode_reward": 814.7357291931719, "episode": 55.0, "batch_reward": 0.7519250707626343, "critic_loss": 1.0995051097273827, "actor_loss": -76.46435078430176, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.33229112625122, "step": 55000}
{"episode_reward": 869.1814358619974, "episode": 56.0, "batch_reward": 0.7532559673786163, "critic_loss": 1.168899027645588, "actor_loss": -76.59707752990722, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.111677408218384, "step": 56000}
{"episode_reward": 816.2105606679311, "episode": 57.0, "batch_reward": 0.753645673751831, "critic_loss": 1.1260459607839584, "actor_loss": -76.46085409545898, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.63556408882141, "step": 57000}
{"episode_reward": 840.5951442331407, "episode": 58.0, "batch_reward": 0.7550715342760086, "critic_loss": 1.0910961471796037, "actor_loss": -76.73823181152343, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.42934012413025, "step": 58000}
{"episode_reward": 888.7133958293151, "episode": 59.0, "batch_reward": 0.7599313269257546, "critic_loss": 1.109589106798172, "actor_loss": -77.13043600463867, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.388868808746338, "step": 59000}
{"episode_reward": 846.9359132035813, "episode": 60.0, "batch_reward": 0.7603561838269234, "critic_loss": 1.1319346474707126, "actor_loss": -76.96623690795899, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.617233753204346, "step": 60000}
{"episode_reward": 902.8747994774185, "episode": 61.0, "batch_reward": 0.7627136063575745, "critic_loss": 1.1151144845783711, "actor_loss": -76.88153421020507, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.82943320274353, "step": 61000}
{"episode_reward": 896.1869878745549, "episode": 62.0, "batch_reward": 0.7652675817608834, "critic_loss": 1.1442070578336716, "actor_loss": -77.04521034240723, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.2244873046875, "step": 62000}
{"episode_reward": 891.3350417898209, "episode": 63.0, "batch_reward": 0.7670768438577652, "critic_loss": 1.0877917172312737, "actor_loss": -77.21773483276367, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.75953722000122, "step": 63000}
{"episode_reward": 823.7595623693522, "episode": 64.0, "batch_reward": 0.7683304952979088, "critic_loss": 1.0833010947704316, "actor_loss": -77.52939288330079, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.506535291671753, "step": 64000}
{"episode_reward": 885.1214521201779, "episode": 65.0, "batch_reward": 0.7697299646139145, "critic_loss": 1.1014524688124656, "actor_loss": -77.51571981811523, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.4322509765625, "step": 65000}
{"episode_reward": 912.7607328844904, "episode": 66.0, "batch_reward": 0.7718861562013626, "critic_loss": 1.0614383024275302, "actor_loss": -77.66686605834961, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.77201795578003, "step": 66000}
{"episode_reward": 908.5774045564991, "episode": 67.0, "batch_reward": 0.7738034052848816, "critic_loss": 1.0448889912962913, "actor_loss": -77.69955024719238, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.842792510986328, "step": 67000}
{"episode_reward": 890.4004749001217, "episode": 68.0, "batch_reward": 0.7769821339249611, "critic_loss": 0.9996631526350975, "actor_loss": -77.94563189697266, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.38903784751892, "step": 68000}
{"episode_reward": 897.1407041717475, "episode": 69.0, "batch_reward": 0.7793965191841126, "critic_loss": 0.9814903579056263, "actor_loss": -77.8928253326416, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.70993995666504, "step": 69000}
{"episode_reward": 897.0795793995104, "episode": 70.0, "batch_reward": 0.7783151564598083, "critic_loss": 0.901642501205206, "actor_loss": -78.14842350769042, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.05985927581787, "step": 70000}
{"episode_reward": 871.2531942099915, "episode": 71.0, "batch_reward": 0.7797975720763206, "critic_loss": 0.9221495263576508, "actor_loss": -78.11167031860352, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.387736558914185, "step": 71000}
{"episode_reward": 818.1696866867919, "episode": 72.0, "batch_reward": 0.7814301418662071, "critic_loss": 0.9223362399339676, "actor_loss": -78.1079818572998, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.726725101470947, "step": 72000}
{"episode_reward": 884.5245264883416, "episode": 73.0, "batch_reward": 0.7830982410311699, "critic_loss": 0.9166574858427048, "actor_loss": -78.31087257385254, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.376274824142456, "step": 73000}
{"episode_reward": 834.8498528997987, "episode": 74.0, "batch_reward": 0.7833494201302529, "critic_loss": 0.9019548467099666, "actor_loss": -78.14375805664062, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.7444167137146, "step": 74000}
{"episode_reward": 910.2537798099534, "episode": 75.0, "batch_reward": 0.7861819767355919, "critic_loss": 0.8832869432866574, "actor_loss": -78.6931919555664, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.723531007766724, "step": 75000}
{"episode_reward": 856.9471512423977, "episode": 76.0, "batch_reward": 0.7865699845552444, "critic_loss": 0.9373971760869027, "actor_loss": -78.53816181945801, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.31983733177185, "step": 76000}
{"episode_reward": 864.1046885688986, "episode": 77.0, "batch_reward": 0.7866567713618279, "critic_loss": 0.9545362612009048, "actor_loss": -78.56983847045899, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.698593378067017, "step": 77000}
{"episode_reward": 867.7223837740183, "episode": 78.0, "batch_reward": 0.7872609773278236, "critic_loss": 0.9332564011216163, "actor_loss": -78.54478472900391, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.295031309127808, "step": 78000}
{"episode_reward": 902.7691455240462, "episode": 79.0, "batch_reward": 0.7899897592067718, "critic_loss": 0.9321936377584934, "actor_loss": -78.80650073242188, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.35618567466736, "step": 79000}
{"episode_reward": 918.1556998379099, "episode": 80.0, "batch_reward": 0.7918429520726203, "critic_loss": 0.9027239078879357, "actor_loss": -78.88275444030762, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.491211891174316, "step": 80000}
{"episode_reward": 877.8566995705575, "episode": 81.0, "batch_reward": 0.79209024143219, "critic_loss": 0.9042651654779911, "actor_loss": -78.8026759185791, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.35907793045044, "step": 81000}
{"episode_reward": 883.0699345979976, "episode": 82.0, "batch_reward": 0.7912059107422829, "critic_loss": 0.9211340181529521, "actor_loss": -78.82164369201661, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.736513376235962, "step": 82000}
{"episode_reward": 840.627408384294, "episode": 83.0, "batch_reward": 0.7939851123094559, "critic_loss": 0.8993954726159573, "actor_loss": -78.98539962768555, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.760791778564453, "step": 83000}
{"episode_reward": 889.3122616772037, "episode": 84.0, "batch_reward": 0.7947674242258072, "critic_loss": 0.9097071818709374, "actor_loss": -79.04349351501465, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.9353506565094, "step": 84000}
{"episode_reward": 925.9676543091866, "episode": 85.0, "batch_reward": 0.7966357914209365, "critic_loss": 0.9223908501267433, "actor_loss": -79.18497134399414, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.40910267829895, "step": 85000}
{"episode_reward": 845.7207432949756, "episode": 86.0, "batch_reward": 0.7958205623626708, "critic_loss": 0.93544925314188, "actor_loss": -79.06639570617676, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.042323112487793, "step": 86000}
{"episode_reward": 846.6140476884757, "episode": 87.0, "batch_reward": 0.7975243085622787, "critic_loss": 0.914970995604992, "actor_loss": -79.14531797790528, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.498255014419556, "step": 87000}
{"episode_reward": 929.8662656006532, "episode": 88.0, "batch_reward": 0.800071110367775, "critic_loss": 0.9275617370307445, "actor_loss": -79.23068566894531, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.383063077926636, "step": 88000}
{"episode_reward": 924.6442846243854, "episode": 89.0, "batch_reward": 0.8019459351301194, "critic_loss": 0.9058578158915043, "actor_loss": -79.37960453796387, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.784109354019165, "step": 89000}
{"episode_reward": 905.948114087627, "episode": 90.0, "batch_reward": 0.8009507995247841, "critic_loss": 0.8570701250135898, "actor_loss": -79.38969142150879, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.74191427230835, "step": 90000}
{"episode_reward": 873.7269301838944, "episode": 91.0, "batch_reward": 0.8010017086267471, "critic_loss": 0.9523992955088615, "actor_loss": -79.5528505859375, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.29832410812378, "step": 91000}
{"episode_reward": 810.5816205210584, "episode": 92.0, "batch_reward": 0.8024980670213699, "critic_loss": 0.9287303977906703, "actor_loss": -79.45414154052735, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.885617971420288, "step": 92000}
{"episode_reward": 900.2798814804534, "episode": 93.0, "batch_reward": 0.8031951330304146, "critic_loss": 0.9043004350662232, "actor_loss": -79.58515953063964, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.666208505630493, "step": 93000}
{"episode_reward": 917.967705838787, "episode": 94.0, "batch_reward": 0.8056800321936607, "critic_loss": 0.9003215409815312, "actor_loss": -79.61668858337403, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.368346214294434, "step": 94000}
{"episode_reward": 882.2767779765527, "episode": 95.0, "batch_reward": 0.8040753428339958, "critic_loss": 0.8763129005730153, "actor_loss": -79.70703401184082, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.54266333580017, "step": 95000}
{"episode_reward": 791.6962636636109, "episode": 96.0, "batch_reward": 0.8064555819034577, "critic_loss": 0.8703405197262764, "actor_loss": -79.75152578735351, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.997408390045166, "step": 96000}
{"episode_reward": 932.5077626895052, "episode": 97.0, "batch_reward": 0.8072219443321228, "critic_loss": 0.9750068109333515, "actor_loss": -79.81414967346191, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.35504460334778, "step": 97000}
{"episode_reward": 913.0097851298483, "episode": 98.0, "batch_reward": 0.8094567685723305, "critic_loss": 0.894345106959343, "actor_loss": -79.87311473083496, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.316560745239258, "step": 98000}
{"episode_reward": 924.4218980614279, "episode": 99.0, "batch_reward": 0.8100013823509217, "critic_loss": 0.9266675896942616, "actor_loss": -80.01738305664063, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.295166969299316, "step": 99000}
{"episode_reward": 912.6264625167439, "episode": 100.0, "batch_reward": 0.8106757103800774, "critic_loss": 0.8936481717824936, "actor_loss": -80.07383915710449, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.406280040740967, "step": 100000}
{"episode_reward": 916.766231597069, "episode": 101.0, "batch_reward": 0.8101149333119393, "critic_loss": 0.866013709306717, "actor_loss": -80.06182594299317, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.98975443840027, "step": 101000}
{"episode_reward": 888.541209426807, "episode": 102.0, "batch_reward": 0.8128453352451325, "critic_loss": 0.8493694977462292, "actor_loss": -80.1755309753418, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.540332555770874, "step": 102000}
{"episode_reward": 922.9250468435566, "episode": 103.0, "batch_reward": 0.8139872873425483, "critic_loss": 0.7913623708486557, "actor_loss": -80.2577010498047, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.69434952735901, "step": 103000}
{"episode_reward": 938.6690120964137, "episode": 104.0, "batch_reward": 0.8147193232774734, "critic_loss": 0.8450410675406456, "actor_loss": -80.3037252960205, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.70479917526245, "step": 104000}
{"episode_reward": 889.665978098672, "episode": 105.0, "batch_reward": 0.8150398062467575, "critic_loss": 0.8661094036102295, "actor_loss": -80.32562725830078, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.476194620132446, "step": 105000}
{"episode_reward": 927.669785317457, "episode": 106.0, "batch_reward": 0.8155725681185723, "critic_loss": 0.8374476132690907, "actor_loss": -80.3500969543457, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.986085891723633, "step": 106000}
{"episode_reward": 915.0528189170408, "episode": 107.0, "batch_reward": 0.8151070905327797, "critic_loss": 0.7929298630952835, "actor_loss": -80.40701008605957, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.68296480178833, "step": 107000}
{"episode_reward": 914.3614573409817, "episode": 108.0, "batch_reward": 0.8170819302797317, "critic_loss": 0.8246552742123604, "actor_loss": -80.45235388183593, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.659728527069092, "step": 108000}
{"episode_reward": 921.5274223942616, "episode": 109.0, "batch_reward": 0.8195171847343444, "critic_loss": 0.7999397026598454, "actor_loss": -80.47247959899903, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.396957397460938, "step": 109000}
{"episode_reward": 920.3029561714875, "episode": 110.0, "batch_reward": 0.8209532724618912, "critic_loss": 0.7892686623930931, "actor_loss": -80.54401445007325, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.4011652469635, "step": 110000}
{"episode_reward": 905.0364712139404, "episode": 111.0, "batch_reward": 0.8193025184869767, "critic_loss": 0.8288941281437874, "actor_loss": -80.59348069763183, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.879398345947266, "step": 111000}
{"episode_reward": 857.0890372425137, "episode": 112.0, "batch_reward": 0.8192228021025658, "critic_loss": 0.8086931517124176, "actor_loss": -80.59814674377441, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.56816577911377, "step": 112000}
{"episode_reward": 848.9547360812059, "episode": 113.0, "batch_reward": 0.8221812896728515, "critic_loss": 0.775142402112484, "actor_loss": -80.72361032104492, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.729910612106323, "step": 113000}
{"episode_reward": 941.2548275844208, "episode": 114.0, "batch_reward": 0.8222807024717331, "critic_loss": 0.8200972819030284, "actor_loss": -80.74657475280762, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.60930633544922, "step": 114000}
{"episode_reward": 945.1536930409429, "episode": 115.0, "batch_reward": 0.8234888418912888, "critic_loss": 0.7729013152718544, "actor_loss": -80.75691041564941, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.533143997192383, "step": 115000}
{"episode_reward": 936.9907479124602, "episode": 116.0, "batch_reward": 0.8246060734987259, "critic_loss": 0.7887850294113159, "actor_loss": -80.85524378967285, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.740848064422607, "step": 116000}
{"episode_reward": 885.1614161703652, "episode": 117.0, "batch_reward": 0.8246176419258118, "critic_loss": 0.8145731776356697, "actor_loss": -80.8997920074463, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.699146270751953, "step": 117000}
{"episode_reward": 897.722073255384, "episode": 118.0, "batch_reward": 0.8262173311114311, "critic_loss": 0.7939998686611652, "actor_loss": -80.91923406982421, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.674373388290405, "step": 118000}
{"episode_reward": 933.0940373424976, "episode": 119.0, "batch_reward": 0.8265724693536758, "critic_loss": 0.8332408662736416, "actor_loss": -80.9687339630127, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.755147218704224, "step": 119000}
{"episode_reward": 942.9128055134504, "episode": 120.0, "batch_reward": 0.8284075477719307, "critic_loss": 0.7743964013755321, "actor_loss": -81.03717904663085, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.979604721069336, "step": 120000}
{"episode_reward": 934.5864769991996, "episode": 121.0, "batch_reward": 0.8278227669596672, "critic_loss": 0.7874115642011166, "actor_loss": -81.01030258178712, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.585384130477905, "step": 121000}
{"episode_reward": 908.3111669805102, "episode": 122.0, "batch_reward": 0.829188896536827, "critic_loss": 0.7606970389783383, "actor_loss": -81.02508474731445, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.74819564819336, "step": 122000}
{"episode_reward": 872.5573410911906, "episode": 123.0, "batch_reward": 0.8288138709664344, "critic_loss": 0.8385872551500797, "actor_loss": -81.01565628051758, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.17320156097412, "step": 123000}
{"episode_reward": 849.9484439818601, "episode": 124.0, "batch_reward": 0.829376293361187, "critic_loss": 0.8054472365677356, "actor_loss": -81.024529296875, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.952373266220093, "step": 124000}
{"episode_reward": 929.0287601307696, "episode": 125.0, "batch_reward": 0.83038515406847, "critic_loss": 0.7867610820829868, "actor_loss": -81.07766537475585, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.319316387176514, "step": 125000}
{"episode_reward": 835.3826133224093, "episode": 126.0, "batch_reward": 0.8299137861132622, "critic_loss": 0.7958717714250088, "actor_loss": -81.04683027648926, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.075117349624634, "step": 126000}
{"episode_reward": 899.8190992981934, "episode": 127.0, "batch_reward": 0.8312177750468254, "critic_loss": 0.8453373672366142, "actor_loss": -81.09890785217286, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.749207973480225, "step": 127000}
{"episode_reward": 937.5003476768652, "episode": 128.0, "batch_reward": 0.8317861655354499, "critic_loss": 0.8080053118467331, "actor_loss": -81.11305616760254, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.58648371696472, "step": 128000}
{"episode_reward": 918.6833115940814, "episode": 129.0, "batch_reward": 0.8321593722701073, "critic_loss": 0.8126019084751606, "actor_loss": -81.13654873657227, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.25122594833374, "step": 129000}
{"episode_reward": 907.865296749892, "episode": 130.0, "batch_reward": 0.833619187116623, "critic_loss": 0.8036491276621819, "actor_loss": -81.1591092376709, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.065397024154663, "step": 130000}
{"episode_reward": 868.7520975613769, "episode": 131.0, "batch_reward": 0.8327033633589744, "critic_loss": 0.8466237577199935, "actor_loss": -81.21830603027344, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.22363042831421, "step": 131000}
{"episode_reward": 899.3906072933052, "episode": 132.0, "batch_reward": 0.8339154068827629, "critic_loss": 0.7748276417255402, "actor_loss": -81.23428825378419, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.422857761383057, "step": 132000}
{"episode_reward": 887.3283856395885, "episode": 133.0, "batch_reward": 0.8324445607662201, "critic_loss": 0.7462939126491547, "actor_loss": -81.2302456817627, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.962851524353027, "step": 133000}
{"episode_reward": 849.4554741098285, "episode": 134.0, "batch_reward": 0.8333623215556145, "critic_loss": 0.7449044495224952, "actor_loss": -81.23334941101074, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.027966260910034, "step": 134000}
{"episode_reward": 926.0909784945558, "episode": 135.0, "batch_reward": 0.8337242061495781, "critic_loss": 0.8127796923220157, "actor_loss": -81.32344296264648, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.363186597824097, "step": 135000}
{"episode_reward": 914.4939260358761, "episode": 136.0, "batch_reward": 0.8344851947426796, "critic_loss": 0.8068809279501438, "actor_loss": -81.28997715759277, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.270915269851685, "step": 136000}
{"episode_reward": 820.6889406401203, "episode": 137.0, "batch_reward": 0.8350336718559265, "critic_loss": 0.8719011635482311, "actor_loss": -81.28488909912109, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.71782684326172, "step": 137000}
{"episode_reward": 915.4854974471117, "episode": 138.0, "batch_reward": 0.8357032942175865, "critic_loss": 0.8272683265209198, "actor_loss": -81.33692778015137, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.5376877784729, "step": 138000}
{"episode_reward": 853.5068615097347, "episode": 139.0, "batch_reward": 0.8365607396364212, "critic_loss": 0.9399894227385521, "actor_loss": -81.44152708435058, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.79629373550415, "step": 139000}
{"episode_reward": 902.8509533858196, "episode": 140.0, "batch_reward": 0.8355687681436539, "critic_loss": 0.8849749075472355, "actor_loss": -81.43508251953125, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.502329349517822, "step": 140000}
{"episode_reward": 883.868559011913, "episode": 141.0, "batch_reward": 0.8365763959288597, "critic_loss": 0.8889567981064319, "actor_loss": -81.4688487701416, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 38.708699464797974, "step": 141000}
{"episode_reward": 938.5213353189116, "episode": 142.0, "batch_reward": 0.8367684553265572, "critic_loss": 0.8858144210875034, "actor_loss": -81.4955636138916, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.516201496124268, "step": 142000}
{"episode_reward": 910.8677322620855, "episode": 143.0, "batch_reward": 0.8379475681781768, "critic_loss": 1.0693893162608146, "actor_loss": -81.45454896545411, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.859333753585815, "step": 143000}
{"episode_reward": 914.9841972674728, "episode": 144.0, "batch_reward": 0.8390266996622086, "critic_loss": 1.1470698103904724, "actor_loss": -81.53802168273926, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.3934543132782, "step": 144000}
{"episode_reward": 903.9583810796148, "episode": 145.0, "batch_reward": 0.8383266785144806, "critic_loss": 1.2417571480572223, "actor_loss": -81.44126617431641, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.555882692337036, "step": 145000}
{"episode_reward": 899.7073341114755, "episode": 146.0, "batch_reward": 0.8393600660562516, "critic_loss": 1.5471369972229003, "actor_loss": -81.5684133605957, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.27604627609253, "step": 146000}
{"episode_reward": 933.3881532311703, "episode": 147.0, "batch_reward": 0.8399545598626137, "critic_loss": 2.5021539153158665, "actor_loss": -81.63501820373536, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.371681690216064, "step": 147000}
{"episode_reward": 833.473062782154, "episode": 148.0, "batch_reward": 0.8361513267755508, "critic_loss": 2.741803129762411, "actor_loss": -81.66365049743652, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.577549934387207, "step": 148000}
{"episode_reward": 28.9002177954746, "episode": 149.0, "batch_reward": 0.8350852622389794, "critic_loss": 3.082176307141781, "actor_loss": -81.6613045349121, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.43279004096985, "step": 149000}
{"episode_reward": 931.4760610632168, "episode": 150.0, "batch_reward": 0.8327245185375214, "critic_loss": 2.568333497583866, "actor_loss": -81.64477394104004, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "step": 150000}
