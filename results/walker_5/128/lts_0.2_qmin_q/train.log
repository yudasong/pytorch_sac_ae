{"episode_reward": 0.0, "episode": 1.0, "duration": 23.033019304275513, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.887643814086914, "step": 2000}
{"episode_reward": 632.427646246406, "episode": 3.0, "batch_reward": 0.34252491150648845, "critic_loss": 0.8167529441130563, "actor_loss": -72.3253129773638, "actor_target_entropy": -6.0, "alpha_value": 0.004365629073060301, "duration": 65.16323757171631, "step": 3000}
{"episode_reward": 369.5643619491496, "episode": 4.0, "batch_reward": 0.3237609479278326, "critic_loss": 0.6389483276605606, "actor_loss": -79.77699934387206, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.178137063980103, "step": 4000}
{"episode_reward": 90.81822389040006, "episode": 5.0, "batch_reward": 0.2706303574442864, "critic_loss": 0.6711531559228897, "actor_loss": -80.20677488708496, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.43298101425171, "step": 5000}
{"episode_reward": 93.3299071868905, "episode": 6.0, "batch_reward": 0.23188228845596315, "critic_loss": 0.5983873614966869, "actor_loss": -80.25793870544433, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.008243083953857, "step": 6000}
{"episode_reward": 140.98165010656132, "episode": 7.0, "batch_reward": 0.2466972724199295, "critic_loss": 0.7508077791929245, "actor_loss": -80.61722570800781, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.32470393180847, "step": 7000}
{"episode_reward": 498.17675125778084, "episode": 8.0, "batch_reward": 0.26847540032863615, "critic_loss": 0.80116729336977, "actor_loss": -79.704260055542, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.858064651489258, "step": 8000}
{"episode_reward": 426.14435374196546, "episode": 9.0, "batch_reward": 0.29463844165205955, "critic_loss": 0.8925891182422638, "actor_loss": -80.05848365783692, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.49480128288269, "step": 9000}
{"episode_reward": 440.1657949837466, "episode": 10.0, "batch_reward": 0.321341653957963, "critic_loss": 0.910773284316063, "actor_loss": -79.65528952026366, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.506733417510986, "step": 10000}
{"episode_reward": 735.122148072836, "episode": 11.0, "batch_reward": 0.35109892089664935, "critic_loss": 0.8428547410964966, "actor_loss": -80.19871647644042, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 44.35551071166992, "step": 11000}
{"episode_reward": 499.12566355687244, "episode": 12.0, "batch_reward": 0.3762493568658829, "critic_loss": 0.8133839517831802, "actor_loss": -80.17338807678223, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.584266662597656, "step": 12000}
{"episode_reward": 725.2286252854404, "episode": 13.0, "batch_reward": 0.40544130572676657, "critic_loss": 0.8874807618260384, "actor_loss": -79.93188436889649, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.020057916641235, "step": 13000}
{"episode_reward": 745.9392348734468, "episode": 14.0, "batch_reward": 0.4315869381427765, "critic_loss": 0.9918397826552391, "actor_loss": -79.85609599304199, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.245041608810425, "step": 14000}
{"episode_reward": 775.4620751366907, "episode": 15.0, "batch_reward": 0.45383245491981505, "critic_loss": 1.073759498000145, "actor_loss": -80.22486683654785, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.58518075942993, "step": 15000}
{"episode_reward": 711.5560469680298, "episode": 16.0, "batch_reward": 0.47060524532198905, "critic_loss": 1.1032909848093986, "actor_loss": -80.40719734191894, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.43492293357849, "step": 16000}
{"episode_reward": 768.1634157546249, "episode": 17.0, "batch_reward": 0.48970424169301985, "critic_loss": 1.1084486402869225, "actor_loss": -80.75099678039551, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.93167495727539, "step": 17000}
{"episode_reward": 813.1569368959185, "episode": 18.0, "batch_reward": 0.5134433421492577, "critic_loss": 1.002791967689991, "actor_loss": -81.12776121520996, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.894202709197998, "step": 18000}
{"episode_reward": 922.2220222995909, "episode": 19.0, "batch_reward": 0.5245856555700302, "critic_loss": 0.9372623956799507, "actor_loss": -81.2858349609375, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.95890235900879, "step": 19000}
{"episode_reward": 698.0422065613066, "episode": 20.0, "batch_reward": 0.5423299474716187, "critic_loss": 0.860103973031044, "actor_loss": -81.91364697265625, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.066308975219727, "step": 20000}
{"episode_reward": 867.9765853651476, "episode": 21.0, "batch_reward": 0.5571590914726258, "critic_loss": 0.8421623883843422, "actor_loss": -82.4866629486084, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.86115789413452, "step": 21000}
{"episode_reward": 824.3137800497794, "episode": 22.0, "batch_reward": 0.571237468123436, "critic_loss": 0.7741566706299782, "actor_loss": -82.32470864868164, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.121937036514282, "step": 22000}
{"episode_reward": 882.1820140908044, "episode": 23.0, "batch_reward": 0.5828073836565018, "critic_loss": 0.7198918830454349, "actor_loss": -83.00550804138183, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.17344355583191, "step": 23000}
{"episode_reward": 884.2079169153916, "episode": 24.0, "batch_reward": 0.5917582670450211, "critic_loss": 0.7457399581372738, "actor_loss": -82.79153758239747, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.16315507888794, "step": 24000}
{"episode_reward": 780.6419376160771, "episode": 25.0, "batch_reward": 0.6036875569522381, "critic_loss": 0.6993478802442551, "actor_loss": -82.93617155456543, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.190992832183838, "step": 25000}
{"episode_reward": 884.0930731962673, "episode": 26.0, "batch_reward": 0.6130122299194336, "critic_loss": 0.7079861159324646, "actor_loss": -83.10416877746582, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.70114827156067, "step": 26000}
{"episode_reward": 862.4682533335426, "episode": 27.0, "batch_reward": 0.6226464353203773, "critic_loss": 0.6775850868821144, "actor_loss": -83.14870695495605, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.939164876937866, "step": 27000}
{"episode_reward": 828.8987477994194, "episode": 28.0, "batch_reward": 0.6332571839094162, "critic_loss": 0.6437376587092877, "actor_loss": -83.20921528625489, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.443604707717896, "step": 28000}
{"episode_reward": 913.5528512598041, "episode": 29.0, "batch_reward": 0.6405566518306732, "critic_loss": 0.6054943233728409, "actor_loss": -83.37260815429687, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.327521562576294, "step": 29000}
{"episode_reward": 858.6943679253518, "episode": 30.0, "batch_reward": 0.6483456179499626, "critic_loss": 0.5927539258599281, "actor_loss": -83.19225842285157, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.4649977684021, "step": 30000}
{"episode_reward": 834.9774542570291, "episode": 31.0, "batch_reward": 0.6555651289820671, "critic_loss": 0.5628066046535969, "actor_loss": -82.92370541381835, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 44.53196978569031, "step": 31000}
{"episode_reward": 921.1690750983751, "episode": 32.0, "batch_reward": 0.6635734267234802, "critic_loss": 0.5625319171249866, "actor_loss": -83.14686798095703, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.88776159286499, "step": 32000}
{"episode_reward": 853.5544089499325, "episode": 33.0, "batch_reward": 0.6694186294674873, "critic_loss": 0.5724827527105808, "actor_loss": -83.12579568481445, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.14728617668152, "step": 33000}
{"episode_reward": 863.5927834133894, "episode": 34.0, "batch_reward": 0.676975076675415, "critic_loss": 0.5473230097591877, "actor_loss": -82.93437142944336, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.49150514602661, "step": 34000}
{"episode_reward": 942.6600904391545, "episode": 35.0, "batch_reward": 0.6828770989179611, "critic_loss": 0.5626502130329609, "actor_loss": -83.29311395263672, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.409265518188477, "step": 35000}
{"episode_reward": 842.2750458691834, "episode": 36.0, "batch_reward": 0.689178336262703, "critic_loss": 0.5747396454513073, "actor_loss": -83.0130890045166, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.818622589111328, "step": 36000}
{"episode_reward": 891.0179760660758, "episode": 37.0, "batch_reward": 0.6939766411185264, "critic_loss": 0.5580923112630845, "actor_loss": -83.1967878112793, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.588146209716797, "step": 37000}
{"episode_reward": 896.6711313276628, "episode": 38.0, "batch_reward": 0.6960664430856704, "critic_loss": 0.562942320227623, "actor_loss": -83.33979508972168, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.06605839729309, "step": 38000}
{"episode_reward": 885.9280037624787, "episode": 39.0, "batch_reward": 0.703737561583519, "critic_loss": 0.5430484209060669, "actor_loss": -83.33678131103515, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.2127468585968, "step": 39000}
{"episode_reward": 962.854058337905, "episode": 40.0, "batch_reward": 0.7094039688110352, "critic_loss": 0.5453855777680874, "actor_loss": -83.25621546936036, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.859312534332275, "step": 40000}
{"episode_reward": 895.5970349926615, "episode": 41.0, "batch_reward": 0.7136726178526879, "critic_loss": 0.5428480803966522, "actor_loss": -83.50018215942383, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 44.08436703681946, "step": 41000}
{"episode_reward": 861.8908642129978, "episode": 42.0, "batch_reward": 0.7196877561211587, "critic_loss": 0.5522046034932137, "actor_loss": -83.47002470397949, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.621942281723022, "step": 42000}
{"episode_reward": 948.0541508753727, "episode": 43.0, "batch_reward": 0.7215414616465569, "critic_loss": 0.5654171814024448, "actor_loss": -83.38478793334961, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.736082792282104, "step": 43000}
{"episode_reward": 792.3568681959931, "episode": 44.0, "batch_reward": 0.7242012968659401, "critic_loss": 0.5272407501339912, "actor_loss": -83.42789878845215, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.240838527679443, "step": 44000}
{"episode_reward": 972.7967107304104, "episode": 45.0, "batch_reward": 0.7297890881896019, "critic_loss": 0.5407716506719589, "actor_loss": -83.56592594909668, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.841843128204346, "step": 45000}
{"episode_reward": 849.1627762446002, "episode": 46.0, "batch_reward": 0.7313954906463623, "critic_loss": 0.5448513206243515, "actor_loss": -83.73809312438965, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.418366193771362, "step": 46000}
{"episode_reward": 857.6715449963151, "episode": 47.0, "batch_reward": 0.7354623869657516, "critic_loss": 0.5486653631627559, "actor_loss": -83.58997468566895, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.038691520690918, "step": 47000}
{"episode_reward": 940.605799206842, "episode": 48.0, "batch_reward": 0.7404522368907929, "critic_loss": 0.5345838747620583, "actor_loss": -83.91817419433593, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.848130464553833, "step": 48000}
{"episode_reward": 969.2245260794331, "episode": 49.0, "batch_reward": 0.7456712673902511, "critic_loss": 0.5305105315744877, "actor_loss": -83.69092379760743, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.19723105430603, "step": 49000}
{"episode_reward": 935.7338938585093, "episode": 50.0, "batch_reward": 0.7475680178999901, "critic_loss": 0.5477284319996834, "actor_loss": -83.77620677185058, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.321098566055298, "step": 50000}
{"episode_reward": 852.5743881880293, "episode": 51.0, "batch_reward": 0.7489576438069343, "critic_loss": 0.5249250075519085, "actor_loss": -83.92415046691895, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.52261018753052, "step": 51000}
{"episode_reward": 902.7763197793032, "episode": 52.0, "batch_reward": 0.7537970142364502, "critic_loss": 0.5108770254105329, "actor_loss": -84.15395906066894, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.72684669494629, "step": 52000}
{"episode_reward": 906.2012971894058, "episode": 53.0, "batch_reward": 0.7578853073120118, "critic_loss": 0.5199159241318703, "actor_loss": -83.93197003173829, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.572890043258667, "step": 53000}
{"episode_reward": 935.9629703411763, "episode": 54.0, "batch_reward": 0.7613930602669716, "critic_loss": 0.48606648175418377, "actor_loss": -84.08660047912598, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.042407989501953, "step": 54000}
{"episode_reward": 970.806978137491, "episode": 55.0, "batch_reward": 0.7641203887462616, "critic_loss": 0.4951071265488863, "actor_loss": -84.1160902557373, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.417012691497803, "step": 55000}
{"episode_reward": 957.8159791872083, "episode": 56.0, "batch_reward": 0.7669774468541145, "critic_loss": 0.5001487077474595, "actor_loss": -84.13252041625977, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.773672103881836, "step": 56000}
{"episode_reward": 932.2539313297209, "episode": 57.0, "batch_reward": 0.7693115776181221, "critic_loss": 0.4803669936656952, "actor_loss": -84.41088034057617, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.026216983795166, "step": 57000}
{"episode_reward": 919.215920642138, "episode": 58.0, "batch_reward": 0.7742785338759423, "critic_loss": 0.4762677873373032, "actor_loss": -84.3557282409668, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.092411279678345, "step": 58000}
{"episode_reward": 964.8608798345253, "episode": 59.0, "batch_reward": 0.778155254125595, "critic_loss": 0.4615656691789627, "actor_loss": -84.72268032836914, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.204849004745483, "step": 59000}
{"episode_reward": 938.3202231387774, "episode": 60.0, "batch_reward": 0.7808930292725563, "critic_loss": 0.4541488796472549, "actor_loss": -84.96594850158691, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.358361959457397, "step": 60000}
{"episode_reward": 970.1520390196798, "episode": 61.0, "batch_reward": 0.7809605121016502, "critic_loss": 0.45496708737313746, "actor_loss": -84.8433221130371, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.617480993270874, "step": 61000}
{"episode_reward": 961.3367977157869, "episode": 62.0, "batch_reward": 0.7851390928030014, "critic_loss": 0.46040802101790906, "actor_loss": -85.10932498168945, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.96865153312683, "step": 62000}
{"episode_reward": 939.8323207634429, "episode": 63.0, "batch_reward": 0.7876363105177879, "critic_loss": 0.45555895125865936, "actor_loss": -85.13131001281738, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.859145402908325, "step": 63000}
{"episode_reward": 911.4832537417393, "episode": 64.0, "batch_reward": 0.7898221969604492, "critic_loss": 0.4463327916264534, "actor_loss": -85.01319448852539, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.39190125465393, "step": 64000}
{"episode_reward": 920.1289688349993, "episode": 65.0, "batch_reward": 0.7919103324413299, "critic_loss": 0.4516894728690386, "actor_loss": -85.11867636108398, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.78275465965271, "step": 65000}
{"episode_reward": 916.9795762679273, "episode": 66.0, "batch_reward": 0.7946227970719337, "critic_loss": 0.4450798720270395, "actor_loss": -85.3628981628418, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.897949695587158, "step": 66000}
{"episode_reward": 939.4831814301463, "episode": 67.0, "batch_reward": 0.7962162714004517, "critic_loss": 0.437575592443347, "actor_loss": -85.61638307189942, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.70243740081787, "step": 67000}
{"episode_reward": 951.161164290868, "episode": 68.0, "batch_reward": 0.7998800497055054, "critic_loss": 0.4286827846169472, "actor_loss": -85.58804936218262, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.670369148254395, "step": 68000}
{"episode_reward": 979.7458838915749, "episode": 69.0, "batch_reward": 0.803665723502636, "critic_loss": 0.4111525102108717, "actor_loss": -85.85263760375976, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.019821882247925, "step": 69000}
{"episode_reward": 957.6999966882867, "episode": 70.0, "batch_reward": 0.8037321625351905, "critic_loss": 0.41384209382534026, "actor_loss": -86.05129116821288, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.085289239883423, "step": 70000}
{"episode_reward": 953.1014013498508, "episode": 71.0, "batch_reward": 0.80522049254179, "critic_loss": 0.4527619317919016, "actor_loss": -85.78279867553711, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.69647550582886, "step": 71000}
{"episode_reward": 871.2788955730301, "episode": 72.0, "batch_reward": 0.8071423824429512, "critic_loss": 0.3975114658772945, "actor_loss": -86.13555590820313, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.698315143585205, "step": 72000}
{"episode_reward": 940.8143317875742, "episode": 73.0, "batch_reward": 0.8089500815272331, "critic_loss": 0.4205689220279455, "actor_loss": -85.96275775146485, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.633262872695923, "step": 73000}
{"episode_reward": 965.4610753747047, "episode": 74.0, "batch_reward": 0.8093099761605262, "critic_loss": 0.39270080530643464, "actor_loss": -85.88334761047363, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.860093116760254, "step": 74000}
{"episode_reward": 945.7039941992514, "episode": 75.0, "batch_reward": 0.8139611996412277, "critic_loss": 0.38502023576200006, "actor_loss": -85.97170498657226, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.72394061088562, "step": 75000}
{"episode_reward": 960.4120011964194, "episode": 76.0, "batch_reward": 0.8155548607110977, "critic_loss": 0.3754507015496492, "actor_loss": -85.99110679626465, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.81324863433838, "step": 76000}
{"episode_reward": 930.3338430819466, "episode": 77.0, "batch_reward": 0.8152550199627876, "critic_loss": 0.3987567769885063, "actor_loss": -86.05787854003906, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.85678505897522, "step": 77000}
{"episode_reward": 940.9031581031539, "episode": 78.0, "batch_reward": 0.8168190050125123, "critic_loss": 0.364970585078001, "actor_loss": -86.56757536315918, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.64542555809021, "step": 78000}
{"episode_reward": 973.4432626684622, "episode": 79.0, "batch_reward": 0.8211198619604111, "critic_loss": 0.3675563939213753, "actor_loss": -86.39279275512695, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.136390924453735, "step": 79000}
{"episode_reward": 983.7070851775736, "episode": 80.0, "batch_reward": 0.821412055850029, "critic_loss": 0.3702703131735325, "actor_loss": -86.51089865112304, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.189470291137695, "step": 80000}
{"episode_reward": 976.8401951970975, "episode": 81.0, "batch_reward": 0.8228168039917946, "critic_loss": 0.37162871734797953, "actor_loss": -86.48350694274902, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.17923307418823, "step": 81000}
{"episode_reward": 968.6600350961796, "episode": 82.0, "batch_reward": 0.8237770475745201, "critic_loss": 0.384661724999547, "actor_loss": -86.60782191467285, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.038821935653687, "step": 82000}
{"episode_reward": 929.6077650097449, "episode": 83.0, "batch_reward": 0.8262842693924903, "critic_loss": 0.3879871415048838, "actor_loss": -86.80574223327636, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.088926553726196, "step": 83000}
{"episode_reward": 967.5096723736733, "episode": 84.0, "batch_reward": 0.8282596800923347, "critic_loss": 0.3716167610436678, "actor_loss": -86.60226094055176, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.44008207321167, "step": 84000}
{"episode_reward": 979.6501304795119, "episode": 85.0, "batch_reward": 0.8308231595158577, "critic_loss": 0.3504718572795391, "actor_loss": -87.02642948913574, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.9112765789032, "step": 85000}
{"episode_reward": 930.436260363223, "episode": 86.0, "batch_reward": 0.8303354766964912, "critic_loss": 0.3554250787049532, "actor_loss": -86.73289402770996, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.39672827720642, "step": 86000}
{"episode_reward": 936.5367776551277, "episode": 87.0, "batch_reward": 0.8316995812058449, "critic_loss": 0.37255524438619614, "actor_loss": -86.82508662414551, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.308528184890747, "step": 87000}
{"episode_reward": 956.0966748932351, "episode": 88.0, "batch_reward": 0.8329044218063355, "critic_loss": 0.3529171706140041, "actor_loss": -87.0918489227295, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.939270496368408, "step": 88000}
{"episode_reward": 964.7759781175419, "episode": 89.0, "batch_reward": 0.8339833399057388, "critic_loss": 0.3520361586660147, "actor_loss": -86.86826475524903, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.01357936859131, "step": 89000}
{"episode_reward": 865.357009218135, "episode": 90.0, "batch_reward": 0.8340582008957863, "critic_loss": 0.3683159079104662, "actor_loss": -86.71272080993653, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.362048625946045, "step": 90000}
{"episode_reward": 886.7934572003867, "episode": 91.0, "batch_reward": 0.8342962294220925, "critic_loss": 0.3688844077438116, "actor_loss": -86.82702267456055, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.35687017440796, "step": 91000}
{"episode_reward": 915.5777045779605, "episode": 92.0, "batch_reward": 0.8356594960093499, "critic_loss": 0.3613574223816395, "actor_loss": -86.95005172729492, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.842257738113403, "step": 92000}
{"episode_reward": 972.3329854990237, "episode": 93.0, "batch_reward": 0.8378782709240913, "critic_loss": 0.34619604705274104, "actor_loss": -87.1905975036621, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.324284553527832, "step": 93000}
{"episode_reward": 913.4835969607427, "episode": 94.0, "batch_reward": 0.8393559027314186, "critic_loss": 0.3675256442427635, "actor_loss": -87.2287540588379, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.837996006011963, "step": 94000}
{"episode_reward": 940.6399083643524, "episode": 95.0, "batch_reward": 0.8387742847800255, "critic_loss": 0.37260648392140866, "actor_loss": -86.96055569458008, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.500086784362793, "step": 95000}
{"episode_reward": 886.072332348748, "episode": 96.0, "batch_reward": 0.8415434288978577, "critic_loss": 0.3669376192241907, "actor_loss": -87.3665193939209, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.90977716445923, "step": 96000}
{"episode_reward": 982.2932833143581, "episode": 97.0, "batch_reward": 0.842151890039444, "critic_loss": 0.37136131228506564, "actor_loss": -86.96113807678222, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.24879503250122, "step": 97000}
{"episode_reward": 933.3384491026754, "episode": 98.0, "batch_reward": 0.8438622296452523, "critic_loss": 0.3758190233707428, "actor_loss": -86.65229893493652, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.02163815498352, "step": 98000}
{"episode_reward": 949.6630025750732, "episode": 99.0, "batch_reward": 0.8445246425867081, "critic_loss": 0.3703619227856398, "actor_loss": -87.00111827087402, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.36489176750183, "step": 99000}
{"episode_reward": 979.5689755866067, "episode": 100.0, "batch_reward": 0.845826423048973, "critic_loss": 0.36046646791696546, "actor_loss": -87.4007314605713, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.529839038848877, "step": 100000}
{"episode_reward": 939.3031821490945, "episode": 101.0, "batch_reward": 0.8467578220367432, "critic_loss": 0.3519985329657793, "actor_loss": -87.46743882751466, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.76447868347168, "step": 101000}
{"episode_reward": 957.2181746469188, "episode": 102.0, "batch_reward": 0.8481709624528885, "critic_loss": 0.358151671692729, "actor_loss": -87.08734402465821, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.627552270889282, "step": 102000}
{"episode_reward": 967.9299060795282, "episode": 103.0, "batch_reward": 0.8490084496736526, "critic_loss": 0.3482851608544588, "actor_loss": -87.66513868713379, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.886434316635132, "step": 103000}
{"episode_reward": 987.0111919992136, "episode": 104.0, "batch_reward": 0.8518311347961426, "critic_loss": 0.35585361629724505, "actor_loss": -87.56679551696777, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.844266653060913, "step": 104000}
{"episode_reward": 950.2787290118106, "episode": 105.0, "batch_reward": 0.850752682685852, "critic_loss": 0.3474672693610191, "actor_loss": -87.83845578002929, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.218407154083252, "step": 105000}
{"episode_reward": 972.1244367362524, "episode": 106.0, "batch_reward": 0.8516263660788536, "critic_loss": 0.3257002676427364, "actor_loss": -87.63289108276368, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.563130855560303, "step": 106000}
{"episode_reward": 899.6700799852015, "episode": 107.0, "batch_reward": 0.8519084748625755, "critic_loss": 0.32701937790215013, "actor_loss": -87.69929446411133, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.76818561553955, "step": 107000}
{"episode_reward": 959.7752093416931, "episode": 108.0, "batch_reward": 0.8534463743567466, "critic_loss": 0.3320945982635021, "actor_loss": -87.78898260498048, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.640332221984863, "step": 108000}
{"episode_reward": 983.2333858636077, "episode": 109.0, "batch_reward": 0.8549052097201347, "critic_loss": 0.34166816963255403, "actor_loss": -87.5839292755127, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.43411374092102, "step": 109000}
{"episode_reward": 982.0704341420276, "episode": 110.0, "batch_reward": 0.8567226127982139, "critic_loss": 0.3351183693110943, "actor_loss": -87.63850764465332, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.558831453323364, "step": 110000}
{"episode_reward": 942.8389898713314, "episode": 111.0, "batch_reward": 0.8573972887396812, "critic_loss": 0.33432338628172875, "actor_loss": -88.021111328125, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.176252603530884, "step": 111000}
{"episode_reward": 926.1669477152301, "episode": 112.0, "batch_reward": 0.8568754656910896, "critic_loss": 0.3174066690355539, "actor_loss": -88.10298713684082, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.607953548431396, "step": 112000}
{"episode_reward": 942.7458628536349, "episode": 113.0, "batch_reward": 0.8602432661056518, "critic_loss": 0.33289886447787287, "actor_loss": -88.39293101501465, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.80994439125061, "step": 113000}
{"episode_reward": 984.1094468694089, "episode": 114.0, "batch_reward": 0.8600192353129387, "critic_loss": 0.3062941372990608, "actor_loss": -87.92912403869629, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.08295178413391, "step": 114000}
{"episode_reward": 969.7353391506858, "episode": 115.0, "batch_reward": 0.8608999119997025, "critic_loss": 0.3174173866212368, "actor_loss": -88.1349896850586, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.68902087211609, "step": 115000}
{"episode_reward": 981.4973515348142, "episode": 116.0, "batch_reward": 0.8616470792889594, "critic_loss": 0.32072267515957353, "actor_loss": -87.94792274475098, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.580150365829468, "step": 116000}
{"episode_reward": 932.7799541153266, "episode": 117.0, "batch_reward": 0.8619332685470581, "critic_loss": 0.3193849329650402, "actor_loss": -88.03186360168458, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.022682905197144, "step": 117000}
{"episode_reward": 918.3804259316005, "episode": 118.0, "batch_reward": 0.8625749354958534, "critic_loss": 0.31742188388109205, "actor_loss": -88.36948229980469, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.007622003555298, "step": 118000}
{"episode_reward": 979.587655538464, "episode": 119.0, "batch_reward": 0.8637432909607887, "critic_loss": 0.32641863375902175, "actor_loss": -88.29702206420899, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.155632495880127, "step": 119000}
{"episode_reward": 936.7662529771532, "episode": 120.0, "batch_reward": 0.8643586869835853, "critic_loss": 0.31258742552995683, "actor_loss": -88.16206262207031, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.307722091674805, "step": 120000}
{"episode_reward": 982.1927309794418, "episode": 121.0, "batch_reward": 0.8649109835028649, "critic_loss": 0.3143872416168451, "actor_loss": -88.63474085998536, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 45.56479096412659, "step": 121000}
{"episode_reward": 968.4095773302944, "episode": 122.0, "batch_reward": 0.8666202981472015, "critic_loss": 0.30927191906422374, "actor_loss": -88.3320255432129, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.97291111946106, "step": 122000}
{"episode_reward": 941.4842739268624, "episode": 123.0, "batch_reward": 0.8653589077591896, "critic_loss": 0.33624169474840165, "actor_loss": -87.97698503112792, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.371276378631592, "step": 123000}
{"episode_reward": 909.2527497174812, "episode": 124.0, "batch_reward": 0.8673775990605355, "critic_loss": 0.3246963038444519, "actor_loss": -88.02420762634277, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.464871168136597, "step": 124000}
{"episode_reward": 983.6301561221034, "episode": 125.0, "batch_reward": 0.8690303283333778, "critic_loss": 0.31235252478718756, "actor_loss": -88.73717977905274, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.861148357391357, "step": 125000}
{"episode_reward": 941.1714594584723, "episode": 126.0, "batch_reward": 0.8672287833094597, "critic_loss": 0.3320310242027044, "actor_loss": -88.27673652648926, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.684804439544678, "step": 126000}
{"episode_reward": 938.3268134775088, "episode": 127.0, "batch_reward": 0.8680946451425552, "critic_loss": 0.31950554144382476, "actor_loss": -88.1642526550293, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.732544898986816, "step": 127000}
{"episode_reward": 969.5946769328127, "episode": 128.0, "batch_reward": 0.8695345360636711, "critic_loss": 0.30488296246528623, "actor_loss": -88.69809848022462, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.972570180892944, "step": 128000}
{"episode_reward": 976.3884798472592, "episode": 129.0, "batch_reward": 0.8702086749076843, "critic_loss": 0.31502845634520055, "actor_loss": -88.58205862426757, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.144421577453613, "step": 129000}
{"episode_reward": 952.0088750268478, "episode": 130.0, "batch_reward": 0.8717376533746719, "critic_loss": 0.3226020599603653, "actor_loss": -88.21754583740234, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.02928900718689, "step": 130000}
{"episode_reward": 915.4009164575695, "episode": 131.0, "batch_reward": 0.8704701727032661, "critic_loss": 0.3162500491738319, "actor_loss": -88.83880322265625, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 44.04699444770813, "step": 131000}
{"episode_reward": 921.7279874701715, "episode": 132.0, "batch_reward": 0.871383018553257, "critic_loss": 0.30825932778418064, "actor_loss": -88.13869213867187, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.93251609802246, "step": 132000}
{"episode_reward": 956.6857876168341, "episode": 133.0, "batch_reward": 0.8701934596300125, "critic_loss": 0.32012226548790934, "actor_loss": -88.59553321838379, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.259838104248047, "step": 133000}
{"episode_reward": 842.4931724889099, "episode": 134.0, "batch_reward": 0.8712355393767357, "critic_loss": 0.31472444799542426, "actor_loss": -88.45024713134765, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.305296897888184, "step": 134000}
{"episode_reward": 955.4755873287529, "episode": 135.0, "batch_reward": 0.8720526467561722, "critic_loss": 0.3152817275896668, "actor_loss": -88.40693887329101, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.488720655441284, "step": 135000}
{"episode_reward": 950.4097163467553, "episode": 136.0, "batch_reward": 0.87298688185215, "critic_loss": 0.3159729900956154, "actor_loss": -88.47067095947266, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.71237087249756, "step": 136000}
{"episode_reward": 932.5489999421753, "episode": 137.0, "batch_reward": 0.8741462819576263, "critic_loss": 0.32936329320073127, "actor_loss": -88.18023622131348, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.536688804626465, "step": 137000}
{"episode_reward": 981.7881532629088, "episode": 138.0, "batch_reward": 0.8747026091814041, "critic_loss": 0.32937894336134194, "actor_loss": -88.6618112487793, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.10811185836792, "step": 138000}
{"episode_reward": 971.5465930057613, "episode": 139.0, "batch_reward": 0.8750991300344467, "critic_loss": 0.34625849229097366, "actor_loss": -88.75312405395508, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.36166024208069, "step": 139000}
{"episode_reward": 940.4650842024907, "episode": 140.0, "batch_reward": 0.8752527713775635, "critic_loss": 0.32947872613370416, "actor_loss": -88.65149145507813, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.354352235794067, "step": 140000}
{"episode_reward": 958.6312460614004, "episode": 141.0, "batch_reward": 0.8767990482449531, "critic_loss": 0.3126747324168682, "actor_loss": -88.71544778442383, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 46.78722286224365, "step": 141000}
{"episode_reward": 982.4906285342707, "episode": 142.0, "batch_reward": 0.8766058533787727, "critic_loss": 0.3099583425521851, "actor_loss": -88.71209838867188, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.781902313232422, "step": 142000}
{"episode_reward": 967.0865632017483, "episode": 143.0, "batch_reward": 0.8777771298289299, "critic_loss": 0.31477398854494093, "actor_loss": -88.73935423278809, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.078749179840088, "step": 143000}
{"episode_reward": 954.947526869721, "episode": 144.0, "batch_reward": 0.8791182118654252, "critic_loss": 0.3120636382699013, "actor_loss": -88.94520419311523, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.952601432800293, "step": 144000}
{"episode_reward": 932.1482945693122, "episode": 145.0, "batch_reward": 0.879330948472023, "critic_loss": 0.3161334101557732, "actor_loss": -88.75293415832519, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.224372148513794, "step": 145000}
{"episode_reward": 962.9744066093081, "episode": 146.0, "batch_reward": 0.8783070052266121, "critic_loss": 0.31919341465830803, "actor_loss": -88.80081893920898, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.746790885925293, "step": 146000}
{"episode_reward": 977.0901280098805, "episode": 147.0, "batch_reward": 0.880160511136055, "critic_loss": 0.3193024957627058, "actor_loss": -88.99984503173827, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.666977643966675, "step": 147000}
{"episode_reward": 955.2327329391318, "episode": 148.0, "batch_reward": 0.8800791929960251, "critic_loss": 0.33195766715705394, "actor_loss": -89.01490208435058, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.02794885635376, "step": 148000}
{"episode_reward": 943.4486998755368, "episode": 149.0, "batch_reward": 0.8806320418715476, "critic_loss": 0.3242030505165458, "actor_loss": -88.99751509094239, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.6021089553833, "step": 149000}
{"episode_reward": 946.745351697163, "episode": 150.0, "batch_reward": 0.8821790099143982, "critic_loss": 0.31616906718909743, "actor_loss": -89.27911782836914, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "step": 150000}
