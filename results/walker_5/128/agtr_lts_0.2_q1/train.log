{"episode_reward": 0.0, "episode": 1.0, "duration": 21.26219367980957, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.8820326328277588, "step": 2000}
{"episode_reward": 632.427646246406, "episode": 3.0, "batch_reward": 0.33211795839121755, "critic_loss": 0.23207394666559858, "actor_loss": -17.584395244335976, "actor_target_entropy": -6.0, "alpha_value": 0.004365629073060301, "duration": 62.42729163169861, "step": 3000}
{"episode_reward": 126.2719879779938, "episode": 4.0, "batch_reward": 0.2844528175443411, "critic_loss": 0.552362831056118, "actor_loss": -24.41101392364502, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.143994092941284, "step": 4000}
{"episode_reward": 350.5983747326309, "episode": 5.0, "batch_reward": 0.3170093995332718, "critic_loss": 0.755968883678317, "actor_loss": -27.534252311706542, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.702110290527344, "step": 5000}
{"episode_reward": 518.06239353551, "episode": 6.0, "batch_reward": 0.32449046975374224, "critic_loss": 1.037051945835352, "actor_loss": -29.738708965301512, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.535390853881836, "step": 6000}
{"episode_reward": 210.95968406588946, "episode": 7.0, "batch_reward": 0.3308702329546213, "critic_loss": 1.2414708199501037, "actor_loss": -31.107115234375, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.681875705718994, "step": 7000}
{"episode_reward": 578.3088119478626, "episode": 8.0, "batch_reward": 0.36494015184044837, "critic_loss": 1.3975282441973687, "actor_loss": -36.595466747283936, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.593424081802368, "step": 8000}
{"episode_reward": 438.26371014868187, "episode": 9.0, "batch_reward": 0.37351193740963934, "critic_loss": 1.5358691672086715, "actor_loss": -37.87423546218872, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.600606441497803, "step": 9000}
{"episode_reward": 585.0966275302081, "episode": 10.0, "batch_reward": 0.40350894913077356, "critic_loss": 1.4124953259825705, "actor_loss": -41.502461574554445, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.7207293510437, "step": 10000}
{"episode_reward": 655.4159335722726, "episode": 11.0, "batch_reward": 0.42775302854180336, "critic_loss": 1.3050078500509261, "actor_loss": -43.69263712310791, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.32600808143616, "step": 11000}
{"episode_reward": 684.865814780468, "episode": 12.0, "batch_reward": 0.4492846864759922, "critic_loss": 1.217194404065609, "actor_loss": -46.19965171813965, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.22494649887085, "step": 12000}
{"episode_reward": 683.6443946626105, "episode": 13.0, "batch_reward": 0.46913075950741767, "critic_loss": 1.210641923248768, "actor_loss": -48.5045196685791, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.363160133361816, "step": 13000}
{"episode_reward": 775.0564840341164, "episode": 14.0, "batch_reward": 0.48983983033895495, "critic_loss": 1.2436462285518646, "actor_loss": -51.102846717834474, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.754457473754883, "step": 14000}
{"episode_reward": 591.4935689858514, "episode": 15.0, "batch_reward": 0.5047482239902019, "critic_loss": 1.290669941186905, "actor_loss": -52.308974227905274, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.919801712036133, "step": 15000}
{"episode_reward": 889.7397201686471, "episode": 16.0, "batch_reward": 0.5267624648809432, "critic_loss": 1.3571485901474953, "actor_loss": -54.02732677459717, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.11397361755371, "step": 16000}
{"episode_reward": 737.4757787081609, "episode": 17.0, "batch_reward": 0.5394867609739303, "critic_loss": 1.55580788230896, "actor_loss": -55.13289527130127, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.33024287223816, "step": 17000}
{"episode_reward": 749.1393032885376, "episode": 18.0, "batch_reward": 0.5506440126597881, "critic_loss": 1.6438980125188827, "actor_loss": -57.08367404937744, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.782987117767334, "step": 18000}
{"episode_reward": 671.8458149719803, "episode": 19.0, "batch_reward": 0.55445764452219, "critic_loss": 1.771105539381504, "actor_loss": -58.70614498138428, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.607507467269897, "step": 19000}
{"episode_reward": 710.6956612071046, "episode": 20.0, "batch_reward": 0.5671503915786743, "critic_loss": 1.6072634868621827, "actor_loss": -60.123108375549315, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.529473781585693, "step": 20000}
{"episode_reward": 885.8626300069504, "episode": 21.0, "batch_reward": 0.5858637977838517, "critic_loss": 1.3733608914017676, "actor_loss": -61.25716890716553, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.31930160522461, "step": 21000}
{"episode_reward": 890.5984553794941, "episode": 22.0, "batch_reward": 0.59764620834589, "critic_loss": 1.2799796077609062, "actor_loss": -63.10321255493164, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.301604509353638, "step": 22000}
{"episode_reward": 774.8911721057741, "episode": 23.0, "batch_reward": 0.603451339840889, "critic_loss": 1.3762913778424264, "actor_loss": -63.36256001281738, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.556851387023926, "step": 23000}
{"episode_reward": 801.6068726969066, "episode": 24.0, "batch_reward": 0.6094216215610504, "critic_loss": 1.2923478133678437, "actor_loss": -64.46687340545654, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.17872929573059, "step": 24000}
{"episode_reward": 744.0825357262057, "episode": 25.0, "batch_reward": 0.6167156188488007, "critic_loss": 1.2964998291134835, "actor_loss": -65.33710605621337, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.54146122932434, "step": 25000}
{"episode_reward": 790.2445749421821, "episode": 26.0, "batch_reward": 0.6248073690235615, "critic_loss": 1.2809067091941833, "actor_loss": -65.86672116088867, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.774972438812256, "step": 26000}
{"episode_reward": 861.3386270492759, "episode": 27.0, "batch_reward": 0.6350009943246842, "critic_loss": 1.2020430066585541, "actor_loss": -66.65932680511474, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.995463132858276, "step": 27000}
{"episode_reward": 857.3960167838524, "episode": 28.0, "batch_reward": 0.641424723148346, "critic_loss": 1.2179764310121537, "actor_loss": -67.37257872772217, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.736345291137695, "step": 28000}
{"episode_reward": 821.8303413329464, "episode": 29.0, "batch_reward": 0.6469882295131684, "critic_loss": 1.2719676595330238, "actor_loss": -67.98086630249023, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.497946739196777, "step": 29000}
{"episode_reward": 877.8802733531768, "episode": 30.0, "batch_reward": 0.6544305858612061, "critic_loss": 1.2685779290795327, "actor_loss": -68.83860090637206, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.63800835609436, "step": 30000}
{"episode_reward": 846.5030630303426, "episode": 31.0, "batch_reward": 0.6639694780707359, "critic_loss": 1.162930316388607, "actor_loss": -69.72392195129395, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.27545166015625, "step": 31000}
{"episode_reward": 947.7728880606549, "episode": 32.0, "batch_reward": 0.6724694612622261, "critic_loss": 1.1291449664831161, "actor_loss": -70.33515586853028, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.903762340545654, "step": 32000}
{"episode_reward": 923.9758548472001, "episode": 33.0, "batch_reward": 0.6795161154270172, "critic_loss": 1.1682805144190789, "actor_loss": -70.93558784484863, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.31322407722473, "step": 33000}
{"episode_reward": 929.5181358929973, "episode": 34.0, "batch_reward": 0.6883280603885651, "critic_loss": 1.1762065611481667, "actor_loss": -71.85257075500488, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.227659702301025, "step": 34000}
{"episode_reward": 842.3235863853711, "episode": 35.0, "batch_reward": 0.6925901900529862, "critic_loss": 1.1711453335285187, "actor_loss": -72.1744439239502, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.587998628616333, "step": 35000}
{"episode_reward": 894.0256528571965, "episode": 36.0, "batch_reward": 0.6988022519946099, "critic_loss": 1.0568170873522758, "actor_loss": -72.97718594360352, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.321229934692383, "step": 36000}
{"episode_reward": 905.5814853497059, "episode": 37.0, "batch_reward": 0.703571631371975, "critic_loss": 1.0501046037077904, "actor_loss": -73.43631959533691, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.08039951324463, "step": 37000}
{"episode_reward": 875.9265588813557, "episode": 38.0, "batch_reward": 0.7063460808992386, "critic_loss": 1.1009636304974555, "actor_loss": -73.91206221008301, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.516088247299194, "step": 38000}
{"episode_reward": 900.4286111438071, "episode": 39.0, "batch_reward": 0.7128807572126389, "critic_loss": 0.9630120279192924, "actor_loss": -74.5629658203125, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.350465297698975, "step": 39000}
{"episode_reward": 948.1819516757025, "episode": 40.0, "batch_reward": 0.7166304302215576, "critic_loss": 1.0828605324625968, "actor_loss": -75.0014248046875, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.633268356323242, "step": 40000}
{"episode_reward": 871.8986677945264, "episode": 41.0, "batch_reward": 0.7223368083238602, "critic_loss": 1.0210544015467167, "actor_loss": -75.56665353393555, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.22320008277893, "step": 41000}
{"episode_reward": 919.8909399144075, "episode": 42.0, "batch_reward": 0.7288386996388435, "critic_loss": 0.9546087896823883, "actor_loss": -76.07293698120117, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.756458044052124, "step": 42000}
{"episode_reward": 950.6934217640162, "episode": 43.0, "batch_reward": 0.7308421639800071, "critic_loss": 0.9532856625914574, "actor_loss": -76.51095260620117, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.781861543655396, "step": 43000}
{"episode_reward": 819.9883373784442, "episode": 44.0, "batch_reward": 0.7320153233408928, "critic_loss": 0.9609801124930382, "actor_loss": -76.85014758300781, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.464571475982666, "step": 44000}
{"episode_reward": 891.2384722052958, "episode": 45.0, "batch_reward": 0.7383273014426232, "critic_loss": 0.9526062597036362, "actor_loss": -77.2496316833496, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.641891956329346, "step": 45000}
{"episode_reward": 910.8023913874451, "episode": 46.0, "batch_reward": 0.7425128714442253, "critic_loss": 0.9960340624153614, "actor_loss": -77.64664147949219, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.3713858127594, "step": 46000}
{"episode_reward": 954.6507582953706, "episode": 47.0, "batch_reward": 0.7464245099425316, "critic_loss": 0.8883937075734138, "actor_loss": -77.99869032287597, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.307639360427856, "step": 47000}
{"episode_reward": 928.7036491082462, "episode": 48.0, "batch_reward": 0.7493853751420975, "critic_loss": 0.8770605249106884, "actor_loss": -78.38524851989746, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.96648073196411, "step": 48000}
{"episode_reward": 958.5816105274436, "episode": 49.0, "batch_reward": 0.753846216082573, "critic_loss": 0.9998379990756512, "actor_loss": -78.69819227600098, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.590989589691162, "step": 49000}
{"episode_reward": 840.4865936028195, "episode": 50.0, "batch_reward": 0.7555371655225753, "critic_loss": 0.930281237334013, "actor_loss": -78.99116030883789, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.327008962631226, "step": 50000}
{"episode_reward": 897.637201882657, "episode": 51.0, "batch_reward": 0.7594083934426308, "critic_loss": 0.9130014075934887, "actor_loss": -79.37334892272949, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.60735630989075, "step": 51000}
{"episode_reward": 965.1479625184195, "episode": 52.0, "batch_reward": 0.7626770957708359, "critic_loss": 0.9015918385088444, "actor_loss": -79.72782305908203, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.32629632949829, "step": 52000}
{"episode_reward": 913.3866023933017, "episode": 53.0, "batch_reward": 0.7664877139925956, "critic_loss": 0.9143370896577835, "actor_loss": -79.87992127990722, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.050119638442993, "step": 53000}
{"episode_reward": 923.8228781702646, "episode": 54.0, "batch_reward": 0.7694121419191361, "critic_loss": 0.9137947781980038, "actor_loss": -80.14758796691895, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.2096586227417, "step": 54000}
{"episode_reward": 918.2014296830424, "episode": 55.0, "batch_reward": 0.7722605367302895, "critic_loss": 0.868489766061306, "actor_loss": -80.41754423522949, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.341392993927002, "step": 55000}
{"episode_reward": 961.6909786585015, "episode": 56.0, "batch_reward": 0.7739928734898567, "critic_loss": 0.9259508861899376, "actor_loss": -80.62939297485352, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.87214946746826, "step": 56000}
{"episode_reward": 859.9841876111439, "episode": 57.0, "batch_reward": 0.7772250435948372, "critic_loss": 0.9071771458983421, "actor_loss": -80.94818531799316, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.780808448791504, "step": 57000}
{"episode_reward": 950.0793875898428, "episode": 58.0, "batch_reward": 0.7791162158846855, "critic_loss": 0.8861466322243213, "actor_loss": -81.12770343017579, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.87645149230957, "step": 58000}
{"episode_reward": 939.7141061950216, "episode": 59.0, "batch_reward": 0.7826622025370598, "critic_loss": 0.9053681886792183, "actor_loss": -81.51902947998047, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.525636672973633, "step": 59000}
{"episode_reward": 926.0924065020865, "episode": 60.0, "batch_reward": 0.7853943363428116, "critic_loss": 0.8764086295366287, "actor_loss": -81.7640980834961, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.808013200759888, "step": 60000}
{"episode_reward": 958.1097911176204, "episode": 61.0, "batch_reward": 0.7868056169748306, "critic_loss": 0.8544675386250019, "actor_loss": -81.9572428741455, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.70585584640503, "step": 61000}
{"episode_reward": 957.8178372299195, "episode": 62.0, "batch_reward": 0.7907421446442604, "critic_loss": 0.8719793624579907, "actor_loss": -82.32172483825684, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.80226421356201, "step": 62000}
{"episode_reward": 941.06081240115, "episode": 63.0, "batch_reward": 0.7924538782835007, "critic_loss": 0.8368968636095524, "actor_loss": -82.48858213806152, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.33148503303528, "step": 63000}
{"episode_reward": 906.5764230632454, "episode": 64.0, "batch_reward": 0.795787358224392, "critic_loss": 0.8408029846251011, "actor_loss": -82.59814176940918, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.320173263549805, "step": 64000}
{"episode_reward": 937.9654641449441, "episode": 65.0, "batch_reward": 0.7961710951328278, "critic_loss": 0.8471044564545155, "actor_loss": -82.80843334960937, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.67573881149292, "step": 65000}
{"episode_reward": 911.6286231363883, "episode": 66.0, "batch_reward": 0.7993863588571548, "critic_loss": 0.8648096696138382, "actor_loss": -83.1162720489502, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.28045415878296, "step": 66000}
{"episode_reward": 960.9007171107777, "episode": 67.0, "batch_reward": 0.8011787189245224, "critic_loss": 0.8020820165872574, "actor_loss": -83.3872226715088, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.31931471824646, "step": 67000}
{"episode_reward": 901.1900373997885, "episode": 68.0, "batch_reward": 0.8037058790326118, "critic_loss": 0.7883030027151108, "actor_loss": -83.46102857971191, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.698391675949097, "step": 68000}
{"episode_reward": 947.7491226269874, "episode": 69.0, "batch_reward": 0.8069573512673378, "critic_loss": 0.7383487067818642, "actor_loss": -83.83218591308594, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.48987054824829, "step": 69000}
{"episode_reward": 925.4985994480604, "episode": 70.0, "batch_reward": 0.8049454291462899, "critic_loss": 0.8318451400399208, "actor_loss": -84.03059147644043, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.296072721481323, "step": 70000}
{"episode_reward": 892.8316156063984, "episode": 71.0, "batch_reward": 0.8076394881606102, "critic_loss": 0.7622358502149582, "actor_loss": -83.95661436462402, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.587238073349, "step": 71000}
{"episode_reward": 904.8253390217163, "episode": 72.0, "batch_reward": 0.807841722369194, "critic_loss": 0.7993475031852723, "actor_loss": -84.24537815856934, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.288005352020264, "step": 72000}
{"episode_reward": 858.1169096974102, "episode": 73.0, "batch_reward": 0.8104112095236778, "critic_loss": 0.7971409871280193, "actor_loss": -84.1698436279297, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.60447645187378, "step": 73000}
{"episode_reward": 952.4088508541033, "episode": 74.0, "batch_reward": 0.8125941427946091, "critic_loss": 0.7968295124471187, "actor_loss": -84.19407452392578, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.268498420715332, "step": 74000}
{"episode_reward": 959.6898984599475, "episode": 75.0, "batch_reward": 0.8151776731014252, "critic_loss": 0.8046384742259979, "actor_loss": -84.32122535705567, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.32201313972473, "step": 75000}
{"episode_reward": 952.1918398991555, "episode": 76.0, "batch_reward": 0.815973232448101, "critic_loss": 0.8074859347343445, "actor_loss": -84.45455068969727, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.782952547073364, "step": 76000}
{"episode_reward": 902.264379554291, "episode": 77.0, "batch_reward": 0.8173544381856919, "critic_loss": 0.8017712856829167, "actor_loss": -84.57967045593261, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.64366388320923, "step": 77000}
{"episode_reward": 947.0968962430405, "episode": 78.0, "batch_reward": 0.8184215335845947, "critic_loss": 0.7821828592419624, "actor_loss": -85.05834605407715, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.57265043258667, "step": 78000}
{"episode_reward": 971.7328596642418, "episode": 79.0, "batch_reward": 0.8209883864521981, "critic_loss": 0.7718854947984218, "actor_loss": -84.91656999206543, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.771122217178345, "step": 79000}
{"episode_reward": 964.6356751162975, "episode": 80.0, "batch_reward": 0.822733356654644, "critic_loss": 0.7733508857488632, "actor_loss": -85.0654125366211, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.560282468795776, "step": 80000}
{"episode_reward": 967.2813154861369, "episode": 81.0, "batch_reward": 0.8242443611621857, "critic_loss": 0.7618945716321468, "actor_loss": -85.17737954711914, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.32283329963684, "step": 81000}
{"episode_reward": 969.947193294405, "episode": 82.0, "batch_reward": 0.8242874183058738, "critic_loss": 0.7615171421766281, "actor_loss": -85.31709271240234, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.391463041305542, "step": 82000}
{"episode_reward": 953.5938615024585, "episode": 83.0, "batch_reward": 0.8267569403052331, "critic_loss": 0.7332052413821221, "actor_loss": -85.5862381439209, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.25960111618042, "step": 83000}
{"episode_reward": 954.9334220148182, "episode": 84.0, "batch_reward": 0.8294346570968628, "critic_loss": 0.6604375855326653, "actor_loss": -85.5322547454834, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.293498992919922, "step": 84000}
{"episode_reward": 976.8001246025291, "episode": 85.0, "batch_reward": 0.8310924056172371, "critic_loss": 0.682889042109251, "actor_loss": -85.9664470062256, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.483424186706543, "step": 85000}
{"episode_reward": 912.1725672119442, "episode": 86.0, "batch_reward": 0.8310465922951699, "critic_loss": 0.716952268153429, "actor_loss": -85.73631475830078, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.62352466583252, "step": 86000}
{"episode_reward": 909.6126279853728, "episode": 87.0, "batch_reward": 0.8319590867161751, "critic_loss": 0.7047994135022163, "actor_loss": -85.86237951660156, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.464256763458252, "step": 87000}
{"episode_reward": 958.9048684197566, "episode": 88.0, "batch_reward": 0.8347338646650314, "critic_loss": 0.7056730158925056, "actor_loss": -86.14171980285644, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.19890785217285, "step": 88000}
{"episode_reward": 968.5419812220697, "episode": 89.0, "batch_reward": 0.8362111025452614, "critic_loss": 0.6837041491270065, "actor_loss": -86.04440440368653, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.692724466323853, "step": 89000}
{"episode_reward": 927.147322195133, "episode": 90.0, "batch_reward": 0.8358276684880257, "critic_loss": 0.6600016403496265, "actor_loss": -85.93066513061524, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.359216451644897, "step": 90000}
{"episode_reward": 946.3895397825684, "episode": 91.0, "batch_reward": 0.8358254095315933, "critic_loss": 0.6819138535559177, "actor_loss": -85.954386428833, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.81125044822693, "step": 91000}
{"episode_reward": 837.667558938233, "episode": 92.0, "batch_reward": 0.8382498955130577, "critic_loss": 0.6825604403018951, "actor_loss": -86.10465817260742, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.498969078063965, "step": 92000}
{"episode_reward": 965.6700173858796, "episode": 93.0, "batch_reward": 0.8396592268943787, "critic_loss": 0.6857280187308789, "actor_loss": -86.3350793762207, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.87975811958313, "step": 93000}
{"episode_reward": 960.6822019282711, "episode": 94.0, "batch_reward": 0.8410783413648605, "critic_loss": 0.6511867426037788, "actor_loss": -86.4435846862793, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.682794332504272, "step": 94000}
{"episode_reward": 921.1740814273475, "episode": 95.0, "batch_reward": 0.8399740730524063, "critic_loss": 0.685267399162054, "actor_loss": -86.24565603637696, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.83784008026123, "step": 95000}
{"episode_reward": 934.5794950834751, "episode": 96.0, "batch_reward": 0.8422990651726723, "critic_loss": 0.6847020317614079, "actor_loss": -86.61768479919434, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.335854053497314, "step": 96000}
{"episode_reward": 973.9794225736757, "episode": 97.0, "batch_reward": 0.8430754842162133, "critic_loss": 0.6659859239757061, "actor_loss": -86.38523567199707, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.792922496795654, "step": 97000}
{"episode_reward": 951.2820882697656, "episode": 98.0, "batch_reward": 0.8456087886691094, "critic_loss": 0.695382368594408, "actor_loss": -86.07924028015137, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.162611484527588, "step": 98000}
{"episode_reward": 959.8918507759249, "episode": 99.0, "batch_reward": 0.8459163181781769, "critic_loss": 0.6786838023364544, "actor_loss": -86.39235218811035, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.50628137588501, "step": 99000}
{"episode_reward": 968.2516750796794, "episode": 100.0, "batch_reward": 0.8470707495212555, "critic_loss": 0.6967289959788322, "actor_loss": -86.79086598205566, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.81967258453369, "step": 100000}
{"episode_reward": 935.7467661248983, "episode": 101.0, "batch_reward": 0.848157394349575, "critic_loss": 0.662771416515112, "actor_loss": -86.8905760498047, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.89176321029663, "step": 101000}
{"episode_reward": 956.5938918306035, "episode": 102.0, "batch_reward": 0.8498586328625679, "critic_loss": 0.6552920062094927, "actor_loss": -86.63386657714844, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.556238412857056, "step": 102000}
{"episode_reward": 967.4700155405433, "episode": 103.0, "batch_reward": 0.8511149273514748, "critic_loss": 0.6411228657215834, "actor_loss": -87.14230548095703, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.37630605697632, "step": 103000}
{"episode_reward": 976.1584210044476, "episode": 104.0, "batch_reward": 0.8535046212673187, "critic_loss": 0.6572361261844635, "actor_loss": -87.03905401611328, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.203600883483887, "step": 104000}
{"episode_reward": 937.6923634275037, "episode": 105.0, "batch_reward": 0.8523376704454422, "critic_loss": 0.6413009275794029, "actor_loss": -87.27907615661621, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.06063151359558, "step": 105000}
{"episode_reward": 944.52740251855, "episode": 106.0, "batch_reward": 0.8534564236998559, "critic_loss": 0.6328306386917829, "actor_loss": -87.0733454284668, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.432172298431396, "step": 106000}
{"episode_reward": 922.042225571631, "episode": 107.0, "batch_reward": 0.8539185112118721, "critic_loss": 0.6646554475724697, "actor_loss": -87.1681000366211, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.60808801651001, "step": 107000}
{"episode_reward": 956.1683559972491, "episode": 108.0, "batch_reward": 0.854226105093956, "critic_loss": 0.6518231361210346, "actor_loss": -87.22262225341797, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.894450187683105, "step": 108000}
{"episode_reward": 966.8684058777419, "episode": 109.0, "batch_reward": 0.8560823096632958, "critic_loss": 0.6341648487895727, "actor_loss": -87.04452186584473, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.329476594924927, "step": 109000}
{"episode_reward": 975.4703405891114, "episode": 110.0, "batch_reward": 0.8573880290985108, "critic_loss": 0.6222873603105545, "actor_loss": -87.108195022583, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.736932277679443, "step": 110000}
{"episode_reward": 896.2482909978835, "episode": 111.0, "batch_reward": 0.856410843372345, "critic_loss": 0.6543132096529007, "actor_loss": -87.45736253356934, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.40506839752197, "step": 111000}
{"episode_reward": 888.4727292001146, "episode": 112.0, "batch_reward": 0.8573293920159339, "critic_loss": 0.6872597142755985, "actor_loss": -87.53226815795898, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.54276752471924, "step": 112000}
{"episode_reward": 923.8177025079788, "episode": 113.0, "batch_reward": 0.8594573184251785, "critic_loss": 0.6341305254995823, "actor_loss": -87.83734580993652, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.917461156845093, "step": 113000}
{"episode_reward": 947.7597056942175, "episode": 114.0, "batch_reward": 0.8601500591039658, "critic_loss": 0.6009000160098076, "actor_loss": -87.38674794006347, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.345611333847046, "step": 114000}
{"episode_reward": 975.7568494561815, "episode": 115.0, "batch_reward": 0.860203716814518, "critic_loss": 0.6368590787351132, "actor_loss": -87.60652786254883, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.79649829864502, "step": 115000}
{"episode_reward": 970.748881685465, "episode": 116.0, "batch_reward": 0.8602896690964699, "critic_loss": 0.6111264092624188, "actor_loss": -87.41802432250977, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.4332013130188, "step": 116000}
{"episode_reward": 923.9660437471816, "episode": 117.0, "batch_reward": 0.8623936631083489, "critic_loss": 0.6070772889703512, "actor_loss": -87.51629438781738, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.331008911132812, "step": 117000}
{"episode_reward": 916.2029230719879, "episode": 118.0, "batch_reward": 0.8621597776412964, "critic_loss": 0.6174922300875187, "actor_loss": -87.8268904876709, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.5460364818573, "step": 118000}
{"episode_reward": 973.0870318720142, "episode": 119.0, "batch_reward": 0.8624181066155434, "critic_loss": 0.5799922797679901, "actor_loss": -87.77021531677246, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.746288776397705, "step": 119000}
{"episode_reward": 970.0765722529496, "episode": 120.0, "batch_reward": 0.8636813037395478, "critic_loss": 0.6117054400146007, "actor_loss": -87.67772457885742, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.491523504257202, "step": 120000}
{"episode_reward": 966.5925755229767, "episode": 121.0, "batch_reward": 0.8639599612951279, "critic_loss": 0.6563726770132781, "actor_loss": -88.06593069458008, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.75884294509888, "step": 121000}
{"episode_reward": 956.8992012945456, "episode": 122.0, "batch_reward": 0.8666929601430893, "critic_loss": 0.5969224337935448, "actor_loss": -87.82969491577148, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.286784648895264, "step": 122000}
{"episode_reward": 959.1774346327045, "episode": 123.0, "batch_reward": 0.865205591738224, "critic_loss": 0.621888949483633, "actor_loss": -87.47373281860351, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.25880479812622, "step": 123000}
{"episode_reward": 868.3604396866555, "episode": 124.0, "batch_reward": 0.8657471596002578, "critic_loss": 0.5821524297297, "actor_loss": -87.46169987487794, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.59746766090393, "step": 124000}
{"episode_reward": 924.9555110129074, "episode": 125.0, "batch_reward": 0.8672443019151688, "critic_loss": 0.677175323292613, "actor_loss": -88.0768988494873, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.34814953804016, "step": 125000}
{"episode_reward": 910.6633220011228, "episode": 126.0, "batch_reward": 0.8663649834990501, "critic_loss": 0.6075854838043452, "actor_loss": -87.65488598632813, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.681694746017456, "step": 126000}
{"episode_reward": 949.2314088625146, "episode": 127.0, "batch_reward": 0.8678579412698746, "critic_loss": 0.6187233107984066, "actor_loss": -87.5713511505127, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.41286015510559, "step": 127000}
{"episode_reward": 936.9618464265518, "episode": 128.0, "batch_reward": 0.8688560038208961, "critic_loss": 0.6266480576992035, "actor_loss": -88.06198211669921, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.439937591552734, "step": 128000}
{"episode_reward": 974.1896938328035, "episode": 129.0, "batch_reward": 0.8692762264013291, "critic_loss": 0.6318867593258619, "actor_loss": -88.02347631835937, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.290376663208008, "step": 129000}
{"episode_reward": 928.137834197274, "episode": 130.0, "batch_reward": 0.8693981006741524, "critic_loss": 0.6487130048424006, "actor_loss": -87.60517747497559, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.658523559570312, "step": 130000}
{"episode_reward": 923.2360233675543, "episode": 131.0, "batch_reward": 0.869150515794754, "critic_loss": 0.6135289635062218, "actor_loss": -88.26829624938965, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.5527708530426, "step": 131000}
{"episode_reward": 915.6168605239803, "episode": 132.0, "batch_reward": 0.8697808747887611, "critic_loss": 0.6208571520745754, "actor_loss": -87.56471827697754, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.638218641281128, "step": 132000}
{"episode_reward": 949.0282931236441, "episode": 133.0, "batch_reward": 0.869458840250969, "critic_loss": 0.5927753111869096, "actor_loss": -88.04091716003418, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.023041009902954, "step": 133000}
{"episode_reward": 928.2770413487708, "episode": 134.0, "batch_reward": 0.8701680415272712, "critic_loss": 0.6462164687514305, "actor_loss": -87.9220099182129, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.31783628463745, "step": 134000}
{"episode_reward": 951.9588040952184, "episode": 135.0, "batch_reward": 0.870591968357563, "critic_loss": 0.6350580775737762, "actor_loss": -87.8570916595459, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.380229473114014, "step": 135000}
{"episode_reward": 962.2982611412707, "episode": 136.0, "batch_reward": 0.8717528309226036, "critic_loss": 0.617722975730896, "actor_loss": -87.90619546508789, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.5584933757782, "step": 136000}
{"episode_reward": 912.4068104304439, "episode": 137.0, "batch_reward": 0.8721815702915192, "critic_loss": 0.5841647737622261, "actor_loss": -87.61886511230469, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.44727325439453, "step": 137000}
{"episode_reward": 973.383622166659, "episode": 138.0, "batch_reward": 0.8740736230015754, "critic_loss": 0.5761772894114255, "actor_loss": -88.09795207214356, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.32864212989807, "step": 138000}
{"episode_reward": 945.5511082222813, "episode": 139.0, "batch_reward": 0.8743995907306671, "critic_loss": 0.6048610940128565, "actor_loss": -88.21066841125489, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.11220145225525, "step": 139000}
{"episode_reward": 921.1875032483123, "episode": 140.0, "batch_reward": 0.8745154579281806, "critic_loss": 0.5809070843756199, "actor_loss": -88.06196115112304, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.351262092590332, "step": 140000}
{"episode_reward": 915.8486342559968, "episode": 141.0, "batch_reward": 0.8747927756905556, "critic_loss": 0.5663861059844494, "actor_loss": -88.14277584838867, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.43999171257019, "step": 141000}
{"episode_reward": 972.7488577907976, "episode": 142.0, "batch_reward": 0.8751555392742157, "critic_loss": 0.5796986583322287, "actor_loss": -88.15618914794922, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.337336540222168, "step": 142000}
{"episode_reward": 958.946565838556, "episode": 143.0, "batch_reward": 0.8758869601488113, "critic_loss": 0.5800372658073902, "actor_loss": -88.21858172607422, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.5651752948761, "step": 143000}
{"episode_reward": 967.363938309696, "episode": 144.0, "batch_reward": 0.8775618751645088, "critic_loss": 0.5608945188224316, "actor_loss": -88.4638204498291, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.472535848617554, "step": 144000}
{"episode_reward": 946.5147950548533, "episode": 145.0, "batch_reward": 0.8774599166512489, "critic_loss": 0.5754129041582347, "actor_loss": -88.210631149292, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.539894819259644, "step": 145000}
{"episode_reward": 963.9011131451603, "episode": 146.0, "batch_reward": 0.8770176966190338, "critic_loss": 0.584943438410759, "actor_loss": -88.31582684326172, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.11356258392334, "step": 146000}
{"episode_reward": 975.6344256182988, "episode": 147.0, "batch_reward": 0.8783247653245926, "critic_loss": 0.6120291813611984, "actor_loss": -88.4447523803711, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.631467819213867, "step": 147000}
{"episode_reward": 860.8669763176273, "episode": 148.0, "batch_reward": 0.8774954424500465, "critic_loss": 0.609008794516325, "actor_loss": -88.43696824645995, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.5734281539917, "step": 148000}
{"episode_reward": 909.7166262955993, "episode": 149.0, "batch_reward": 0.8771962813735008, "critic_loss": 0.5971223654001951, "actor_loss": -88.44894569396973, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.489457845687866, "step": 149000}
{"episode_reward": 975.2529198400537, "episode": 150.0, "batch_reward": 0.8797632834911346, "critic_loss": 0.5813754222989083, "actor_loss": -88.78134130859375, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "step": 150000}
