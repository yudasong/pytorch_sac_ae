{"episode_reward": 0.0, "episode": 1.0, "duration": 22.18724298477173, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 2.1235525608062744, "step": 2000}
{"episode_reward": 632.427646246406, "episode": 3.0, "batch_reward": 0.3487629191692212, "critic_loss": 0.6534464406784315, "actor_loss": -69.20756096628105, "actor_target_entropy": -6.0, "alpha_value": 0.004365629073060301, "duration": 66.32883644104004, "step": 3000}
{"episode_reward": 445.14466035927956, "episode": 4.0, "batch_reward": 0.4137462312877178, "critic_loss": 0.8917843840718269, "actor_loss": -71.13400485229492, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.59861660003662, "step": 4000}
{"episode_reward": 666.8941987891013, "episode": 5.0, "batch_reward": 0.4808768842220306, "critic_loss": 0.9513004422187805, "actor_loss": -72.43418908691406, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.968007564544678, "step": 5000}
{"episode_reward": 762.330448499638, "episode": 6.0, "batch_reward": 0.5318917528092861, "critic_loss": 0.9918811810612679, "actor_loss": -73.74667405700684, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.082793474197388, "step": 6000}
{"episode_reward": 796.3793059547344, "episode": 7.0, "batch_reward": 0.5694100753068924, "critic_loss": 0.943961704492569, "actor_loss": -74.55171447753906, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.76266574859619, "step": 7000}
{"episode_reward": 787.4013830350129, "episode": 8.0, "batch_reward": 0.6066113735437393, "critic_loss": 0.9122333143949508, "actor_loss": -75.73532669067383, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.73319721221924, "step": 8000}
{"episode_reward": 852.0711805014888, "episode": 9.0, "batch_reward": 0.6340609446167946, "critic_loss": 0.8863099349141121, "actor_loss": -76.65605850219727, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.12842106819153, "step": 9000}
{"episode_reward": 815.1466126938027, "episode": 10.0, "batch_reward": 0.6583273399472237, "critic_loss": 0.7465434618294239, "actor_loss": -77.31680554199218, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.14515209197998, "step": 10000}
{"episode_reward": 908.15831022145, "episode": 11.0, "batch_reward": 0.6790431877374649, "critic_loss": 0.725873589605093, "actor_loss": -77.8841611328125, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.87830591201782, "step": 11000}
{"episode_reward": 852.7790460615262, "episode": 12.0, "batch_reward": 0.6959550281763077, "critic_loss": 0.78864040184021, "actor_loss": -78.20984843444825, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.542439937591553, "step": 12000}
{"episode_reward": 824.2184997482861, "episode": 13.0, "batch_reward": 0.7029670429229736, "critic_loss": 0.8996224014163017, "actor_loss": -78.31483996582031, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.841205835342407, "step": 13000}
{"episode_reward": 826.1088283316749, "episode": 14.0, "batch_reward": 0.7168310606479644, "critic_loss": 1.0518811119198799, "actor_loss": -78.69673838806152, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.507032871246338, "step": 14000}
{"episode_reward": 879.6273461209036, "episode": 15.0, "batch_reward": 0.702503941655159, "critic_loss": 1.3660331845879554, "actor_loss": -79.02465116882324, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.820276021957397, "step": 15000}
{"episode_reward": 71.16584713000199, "episode": 16.0, "batch_reward": 0.6734545257091522, "critic_loss": 1.4027954457998275, "actor_loss": -78.91885766601563, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.83620572090149, "step": 16000}
{"episode_reward": 365.47956722158443, "episode": 17.0, "batch_reward": 0.6584488037824631, "critic_loss": 1.4054898408651353, "actor_loss": -78.53632969665527, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.165220499038696, "step": 17000}
{"episode_reward": 717.0052489518177, "episode": 18.0, "batch_reward": 0.668909191608429, "critic_loss": 1.2039023008346557, "actor_loss": -78.74945358276368, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.368115425109863, "step": 18000}
{"episode_reward": 896.5553600754471, "episode": 19.0, "batch_reward": 0.669917755663395, "critic_loss": 1.2203120298981667, "actor_loss": -78.73657627868653, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.161470651626587, "step": 19000}
{"episode_reward": 479.3722097779264, "episode": 20.0, "batch_reward": 0.6681231069564819, "critic_loss": 1.1633550773262977, "actor_loss": -78.46820761108398, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.52303385734558, "step": 20000}
{"episode_reward": 734.6522534546751, "episode": 21.0, "batch_reward": 0.6524264286756516, "critic_loss": 1.1672224628925323, "actor_loss": -78.26624243164062, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.29826998710632, "step": 21000}
{"episode_reward": 25.606681874466407, "episode": 22.0, "batch_reward": 0.6429936513900757, "critic_loss": 1.0548812668919563, "actor_loss": -77.68747990417481, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.28490662574768, "step": 22000}
{"episode_reward": 908.4227424376762, "episode": 23.0, "batch_reward": 0.6530248213410378, "critic_loss": 0.9628098946213722, "actor_loss": -77.61790907287597, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.681623935699463, "step": 23000}
{"episode_reward": 863.5562119302998, "episode": 24.0, "batch_reward": 0.6603232901096344, "critic_loss": 0.8690180449187755, "actor_loss": -77.46302497863769, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.49987554550171, "step": 24000}
{"episode_reward": 760.7169417222074, "episode": 25.0, "batch_reward": 0.6682694202661514, "critic_loss": 0.7976934913098812, "actor_loss": -77.26391654968262, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.529452800750732, "step": 25000}
{"episode_reward": 924.7057517566421, "episode": 26.0, "batch_reward": 0.6685144019126892, "critic_loss": 0.7850266438722611, "actor_loss": -76.90187466430665, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.338197708129883, "step": 26000}
{"episode_reward": 635.8165849859838, "episode": 27.0, "batch_reward": 0.6724417865276336, "critic_loss": 0.7910784967243671, "actor_loss": -76.81980065917969, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.165937185287476, "step": 27000}
{"episode_reward": 771.3885133857221, "episode": 28.0, "batch_reward": 0.6777777541279792, "critic_loss": 0.7725912644565105, "actor_loss": -76.72198774719239, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.497238636016846, "step": 28000}
{"episode_reward": 855.7443276053422, "episode": 29.0, "batch_reward": 0.6838835533261299, "critic_loss": 0.8403755422234536, "actor_loss": -76.83477493286132, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.132750511169434, "step": 29000}
{"episode_reward": 845.1477651951001, "episode": 30.0, "batch_reward": 0.6910529615283012, "critic_loss": 0.8346185465753079, "actor_loss": -76.96057984924316, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.58783769607544, "step": 30000}
{"episode_reward": 875.0626784217362, "episode": 31.0, "batch_reward": 0.6995459141731262, "critic_loss": 0.8151519515514374, "actor_loss": -77.26987561035156, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 44.54525804519653, "step": 31000}
{"episode_reward": 933.3546843837721, "episode": 32.0, "batch_reward": 0.7056531051397323, "critic_loss": 0.7896152696311474, "actor_loss": -77.66740159606934, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.888288259506226, "step": 32000}
{"episode_reward": 875.2205584562619, "episode": 33.0, "batch_reward": 0.7104989128112793, "critic_loss": 0.7343062417209149, "actor_loss": -77.87650207519532, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.607778787612915, "step": 33000}
{"episode_reward": 909.9147520494262, "episode": 34.0, "batch_reward": 0.717156312406063, "critic_loss": 0.6980101103186608, "actor_loss": -77.98071505737305, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.459341049194336, "step": 34000}
{"episode_reward": 910.90805334955, "episode": 35.0, "batch_reward": 0.7228379930853843, "critic_loss": 0.6435105922222137, "actor_loss": -78.0670256652832, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.616910457611084, "step": 35000}
{"episode_reward": 890.791732418392, "episode": 36.0, "batch_reward": 0.7266645956635475, "critic_loss": 0.6029298997223377, "actor_loss": -78.17667057800293, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.77248239517212, "step": 36000}
{"episode_reward": 887.8393519555638, "episode": 37.0, "batch_reward": 0.7310861147642136, "critic_loss": 0.5975869725644588, "actor_loss": -78.2345931854248, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.447195529937744, "step": 37000}
{"episode_reward": 868.2907253839977, "episode": 38.0, "batch_reward": 0.732607932806015, "critic_loss": 0.6027729490697384, "actor_loss": -78.28932104492188, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.069372177124023, "step": 38000}
{"episode_reward": 908.0985512593187, "episode": 39.0, "batch_reward": 0.7396951734423637, "critic_loss": 0.5946272385418415, "actor_loss": -78.45175932312011, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.69618821144104, "step": 39000}
{"episode_reward": 906.0155895759868, "episode": 40.0, "batch_reward": 0.7399661051034927, "critic_loss": 0.620018058538437, "actor_loss": -78.45030290222168, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.758689641952515, "step": 40000}
{"episode_reward": 818.3686708252494, "episode": 41.0, "batch_reward": 0.74244521099329, "critic_loss": 0.6166131181716918, "actor_loss": -78.5044545135498, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.16551685333252, "step": 41000}
{"episode_reward": 870.7736288307262, "episode": 42.0, "batch_reward": 0.7489190330505371, "critic_loss": 0.6390806199908257, "actor_loss": -78.67876509094238, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.60764193534851, "step": 42000}
{"episode_reward": 900.6648939330872, "episode": 43.0, "batch_reward": 0.7508976847529412, "critic_loss": 0.6347520190477371, "actor_loss": -78.79204191589355, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.13933253288269, "step": 43000}
{"episode_reward": 834.0252372704414, "episode": 44.0, "batch_reward": 0.7513422626256943, "critic_loss": 0.6300027482807636, "actor_loss": -78.80551664733886, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.298664331436157, "step": 44000}
{"episode_reward": 865.449343018511, "episode": 45.0, "batch_reward": 0.7552381058931351, "critic_loss": 0.5922984511256218, "actor_loss": -78.96077568054199, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.384711027145386, "step": 45000}
{"episode_reward": 916.4056180439435, "episode": 46.0, "batch_reward": 0.7593831136226654, "critic_loss": 0.5821554665863514, "actor_loss": -79.10209396362305, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.62155795097351, "step": 46000}
{"episode_reward": 929.5627169228688, "episode": 47.0, "batch_reward": 0.7633538212776184, "critic_loss": 0.5709051368236542, "actor_loss": -79.21953909301757, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.720405101776123, "step": 47000}
{"episode_reward": 926.371574276835, "episode": 48.0, "batch_reward": 0.7663485680222512, "critic_loss": 0.5815185380280018, "actor_loss": -79.3184068145752, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.948679208755493, "step": 48000}
{"episode_reward": 905.6281282234521, "episode": 49.0, "batch_reward": 0.7702625583410263, "critic_loss": 0.5885258289873601, "actor_loss": -79.43569096374512, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.631064891815186, "step": 49000}
{"episode_reward": 863.6346365318042, "episode": 50.0, "batch_reward": 0.7702866175174713, "critic_loss": 0.5955411452949048, "actor_loss": -79.46908290100097, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.923161268234253, "step": 50000}
{"episode_reward": 924.2758210407239, "episode": 51.0, "batch_reward": 0.7748742561340332, "critic_loss": 0.5696775885820389, "actor_loss": -79.62607942199708, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.80901837348938, "step": 51000}
{"episode_reward": 952.5453331614465, "episode": 52.0, "batch_reward": 0.7793427219986916, "critic_loss": 0.5527560586929321, "actor_loss": -79.77820590209961, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.242088794708252, "step": 52000}
{"episode_reward": 952.0380464273061, "episode": 53.0, "batch_reward": 0.7819554719924927, "critic_loss": 0.5503008094131947, "actor_loss": -79.91866859436035, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.351107835769653, "step": 53000}
{"episode_reward": 919.0133660985632, "episode": 54.0, "batch_reward": 0.7845765535831452, "critic_loss": 0.5248650343716145, "actor_loss": -80.03012867736817, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.05906653404236, "step": 54000}
{"episode_reward": 928.9700884367734, "episode": 55.0, "batch_reward": 0.7855163851380348, "critic_loss": 0.5715861777663231, "actor_loss": -80.04461846923829, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.195093393325806, "step": 55000}
{"episode_reward": 811.4771388997472, "episode": 56.0, "batch_reward": 0.7848743742704392, "critic_loss": 0.5747630875706673, "actor_loss": -80.00636454772949, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.61199188232422, "step": 56000}
{"episode_reward": 899.417804128481, "episode": 57.0, "batch_reward": 0.7885272790193558, "critic_loss": 0.5564371668845415, "actor_loss": -80.09690927124024, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.789304971694946, "step": 57000}
{"episode_reward": 891.1177098970018, "episode": 58.0, "batch_reward": 0.7906186824440956, "critic_loss": 0.5595880576372146, "actor_loss": -80.17006076049805, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.688968658447266, "step": 58000}
{"episode_reward": 915.190257368769, "episode": 59.0, "batch_reward": 0.7929919743537903, "critic_loss": 0.5469048733711243, "actor_loss": -80.18966941833496, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.61705994606018, "step": 59000}
{"episode_reward": 899.1727781320758, "episode": 60.0, "batch_reward": 0.7962100724577904, "critic_loss": 0.5443942312002182, "actor_loss": -80.35059790039062, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.670957803726196, "step": 60000}
{"episode_reward": 955.3034919945085, "episode": 61.0, "batch_reward": 0.7984087986350059, "critic_loss": 0.5413949930071831, "actor_loss": -80.51771913146973, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.88284230232239, "step": 61000}
{"episode_reward": 943.489608771142, "episode": 62.0, "batch_reward": 0.7993620316386223, "critic_loss": 0.5099234286397696, "actor_loss": -80.57519198608398, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.9511239528656, "step": 62000}
{"episode_reward": 938.214828569096, "episode": 63.0, "batch_reward": 0.8017164039611816, "critic_loss": 0.5341843770295381, "actor_loss": -80.61717460632325, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.514018535614014, "step": 63000}
{"episode_reward": 883.265322557662, "episode": 64.0, "batch_reward": 0.8025152133703232, "critic_loss": 0.5227146896272897, "actor_loss": -80.59259875488281, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.50001311302185, "step": 64000}
{"episode_reward": 892.452222449966, "episode": 65.0, "batch_reward": 0.8049046863317489, "critic_loss": 0.5073718013763427, "actor_loss": -80.70991690063477, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.89306950569153, "step": 65000}
{"episode_reward": 929.0186271077316, "episode": 66.0, "batch_reward": 0.8080504525899888, "critic_loss": 0.5209803322404623, "actor_loss": -80.76147375488281, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.598548889160156, "step": 66000}
{"episode_reward": 932.2167417048922, "episode": 67.0, "batch_reward": 0.8086599921584129, "critic_loss": 0.4911074157506227, "actor_loss": -80.94866500854492, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.497509241104126, "step": 67000}
{"episode_reward": 934.0516566603882, "episode": 68.0, "batch_reward": 0.8118862501382828, "critic_loss": 0.4798455121517181, "actor_loss": -80.96570945739747, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.43962812423706, "step": 68000}
{"episode_reward": 961.5657788969874, "episode": 69.0, "batch_reward": 0.8140411846637726, "critic_loss": 0.47083521616458895, "actor_loss": -81.11721586608887, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.801870584487915, "step": 69000}
{"episode_reward": 954.1055816488944, "episode": 70.0, "batch_reward": 0.8141708081364631, "critic_loss": 0.49946708500385284, "actor_loss": -81.19040129089356, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.53481936454773, "step": 70000}
{"episode_reward": 867.6306758329075, "episode": 71.0, "batch_reward": 0.8146089601516724, "critic_loss": 0.4804426087886095, "actor_loss": -81.19542044067383, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.33537030220032, "step": 71000}
{"episode_reward": 925.4101293656, "episode": 72.0, "batch_reward": 0.8177516028285027, "critic_loss": 0.46139637000858785, "actor_loss": -81.28292825317382, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.421642780303955, "step": 72000}
{"episode_reward": 936.5099457507553, "episode": 73.0, "batch_reward": 0.8195106953382492, "critic_loss": 0.4495232831537724, "actor_loss": -81.29997708129883, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.720489263534546, "step": 73000}
{"episode_reward": 934.6915910658131, "episode": 74.0, "batch_reward": 0.8205969361662865, "critic_loss": 0.4639368913024664, "actor_loss": -81.41037739562988, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.46438694000244, "step": 74000}
{"episode_reward": 937.6954982077726, "episode": 75.0, "batch_reward": 0.8237141913175583, "critic_loss": 0.457677761554718, "actor_loss": -81.3430920715332, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.175312280654907, "step": 75000}
{"episode_reward": 922.0860517792365, "episode": 76.0, "batch_reward": 0.8233643522262574, "critic_loss": 0.4439787659645081, "actor_loss": -81.45317147827149, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.211641788482666, "step": 76000}
{"episode_reward": 917.7569399758567, "episode": 77.0, "batch_reward": 0.823836206316948, "critic_loss": 0.47877098609507085, "actor_loss": -81.53446531677245, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.133222579956055, "step": 77000}
{"episode_reward": 877.6293693428452, "episode": 78.0, "batch_reward": 0.8244870111942292, "critic_loss": 0.462848694473505, "actor_loss": -81.57107763671875, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.375165462493896, "step": 78000}
{"episode_reward": 951.0440028210355, "episode": 79.0, "batch_reward": 0.8274562764763832, "critic_loss": 0.4547628222554922, "actor_loss": -81.57543370056152, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.300644636154175, "step": 79000}
{"episode_reward": 950.7776251867655, "episode": 80.0, "batch_reward": 0.8288400609493256, "critic_loss": 0.46882363210618494, "actor_loss": -81.68332525634766, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.45492148399353, "step": 80000}
{"episode_reward": 950.263044822692, "episode": 81.0, "batch_reward": 0.8291385452151299, "critic_loss": 0.4745418286025524, "actor_loss": -81.73657814025879, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.52480697631836, "step": 81000}
{"episode_reward": 910.7013408916549, "episode": 82.0, "batch_reward": 0.830000417470932, "critic_loss": 0.46609937481582164, "actor_loss": -81.72272769165039, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.68616533279419, "step": 82000}
{"episode_reward": 887.2106244271719, "episode": 83.0, "batch_reward": 0.8323426911830902, "critic_loss": 0.46110110546648503, "actor_loss": -81.8347197265625, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.501375913619995, "step": 83000}
{"episode_reward": 942.1862859846278, "episode": 84.0, "batch_reward": 0.8322841829657555, "critic_loss": 0.4289162472486496, "actor_loss": -81.8426353149414, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.84910273551941, "step": 84000}
{"episode_reward": 962.9901381340293, "episode": 85.0, "batch_reward": 0.834327386200428, "critic_loss": 0.4799915724694729, "actor_loss": -81.85332345581055, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.023712158203125, "step": 85000}
{"episode_reward": 795.075298517551, "episode": 86.0, "batch_reward": 0.8336692032814026, "critic_loss": 0.5034341925680638, "actor_loss": -81.89949153137206, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.756916999816895, "step": 86000}
{"episode_reward": 906.8108237130352, "episode": 87.0, "batch_reward": 0.8336080369353295, "critic_loss": 0.4579287956207991, "actor_loss": -81.95448486328125, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.739136457443237, "step": 87000}
{"episode_reward": 934.9647608518092, "episode": 88.0, "batch_reward": 0.8362048363685608, "critic_loss": 0.4623874268978834, "actor_loss": -82.03938362121582, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.190893173217773, "step": 88000}
{"episode_reward": 936.7221273541671, "episode": 89.0, "batch_reward": 0.8380283207297325, "critic_loss": 0.45638656194508076, "actor_loss": -82.02672035217284, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.34158682823181, "step": 89000}
{"episode_reward": 930.8903695402112, "episode": 90.0, "batch_reward": 0.8356910663247108, "critic_loss": 0.4995141073167324, "actor_loss": -82.0755701599121, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.514623403549194, "step": 90000}
{"episode_reward": 853.338648899074, "episode": 91.0, "batch_reward": 0.8369583024382591, "critic_loss": 0.4995414173603058, "actor_loss": -82.02132795715332, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.777608156204224, "step": 91000}
{"episode_reward": 901.2310701649055, "episode": 92.0, "batch_reward": 0.8398060292005539, "critic_loss": 0.4664235419034958, "actor_loss": -82.38883338928223, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.78273630142212, "step": 92000}
{"episode_reward": 947.7636511681231, "episode": 93.0, "batch_reward": 0.8404488685131073, "critic_loss": 0.4657982464283705, "actor_loss": -82.22233079528809, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.923627614974976, "step": 93000}
{"episode_reward": 931.4674358665153, "episode": 94.0, "batch_reward": 0.842301284968853, "critic_loss": 0.4826180920898914, "actor_loss": -82.49079125976563, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.507084369659424, "step": 94000}
{"episode_reward": 907.3555802611266, "episode": 95.0, "batch_reward": 0.8403250828385354, "critic_loss": 0.4755677087903023, "actor_loss": -82.33955889892579, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.647777557373047, "step": 95000}
{"episode_reward": 894.7602046732909, "episode": 96.0, "batch_reward": 0.8422122935056686, "critic_loss": 0.46052472113072873, "actor_loss": -82.48873318481445, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.470070123672485, "step": 96000}
{"episode_reward": 921.0017341753615, "episode": 97.0, "batch_reward": 0.8430494076609611, "critic_loss": 0.4605549792349338, "actor_loss": -82.41247622680665, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.745254039764404, "step": 97000}
{"episode_reward": 895.4453310776576, "episode": 98.0, "batch_reward": 0.8435838504433631, "critic_loss": 0.4575989722162485, "actor_loss": -82.28417907714844, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.7706356048584, "step": 98000}
{"episode_reward": 898.4637678912723, "episode": 99.0, "batch_reward": 0.8437751803398132, "critic_loss": 0.4768529028892517, "actor_loss": -82.51001387023926, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.68902325630188, "step": 99000}
{"episode_reward": 924.637642674149, "episode": 100.0, "batch_reward": 0.8444923284649849, "critic_loss": 0.4473503064513206, "actor_loss": -82.42685845947265, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.672369480133057, "step": 100000}
{"episode_reward": 884.2248899285713, "episode": 101.0, "batch_reward": 0.8456548416018486, "critic_loss": 0.46316629511117935, "actor_loss": -82.69064392089844, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.97828912734985, "step": 101000}
{"episode_reward": 923.9038035998861, "episode": 102.0, "batch_reward": 0.8468992146849632, "critic_loss": 0.4279167538583279, "actor_loss": -82.53012525939941, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.57228684425354, "step": 102000}
{"episode_reward": 936.2429696068269, "episode": 103.0, "batch_reward": 0.8469156484007836, "critic_loss": 0.425021509334445, "actor_loss": -82.71785350036622, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.558626651763916, "step": 103000}
{"episode_reward": 948.3733409743983, "episode": 104.0, "batch_reward": 0.8479938593506813, "critic_loss": 0.4329863878339529, "actor_loss": -82.49698695373534, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.392741441726685, "step": 104000}
{"episode_reward": 900.2553823030427, "episode": 105.0, "batch_reward": 0.8478025102615356, "critic_loss": 0.45312273161113265, "actor_loss": -82.81519572448731, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.23466730117798, "step": 105000}
{"episode_reward": 940.3977277667211, "episode": 106.0, "batch_reward": 0.8499808714985847, "critic_loss": 0.4503283365219831, "actor_loss": -82.82383485412598, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.560627460479736, "step": 106000}
{"episode_reward": 931.018338984088, "episode": 107.0, "batch_reward": 0.8493529813289642, "critic_loss": 0.42496576096117494, "actor_loss": -82.80672468566894, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.536100149154663, "step": 107000}
{"episode_reward": 941.5812710051904, "episode": 108.0, "batch_reward": 0.8508258609771728, "critic_loss": 0.4136722318083048, "actor_loss": -82.87289918518067, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.68574595451355, "step": 108000}
{"episode_reward": 942.4747791258729, "episode": 109.0, "batch_reward": 0.8505195322632789, "critic_loss": 0.4019718908369541, "actor_loss": -82.81577456665039, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.545660734176636, "step": 109000}
{"episode_reward": 930.8780145133991, "episode": 110.0, "batch_reward": 0.8533711150288582, "critic_loss": 0.40847832261025907, "actor_loss": -82.85990148925781, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.170753955841064, "step": 110000}
{"episode_reward": 910.609436572256, "episode": 111.0, "batch_reward": 0.8522252957224846, "critic_loss": 0.4246907626539469, "actor_loss": -83.05893525695801, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.833529233932495, "step": 111000}
{"episode_reward": 875.3533041373297, "episode": 112.0, "batch_reward": 0.8524076009392738, "critic_loss": 0.39590601006150244, "actor_loss": -82.95448420715331, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.866188526153564, "step": 112000}
{"episode_reward": 869.7364417091123, "episode": 113.0, "batch_reward": 0.8528322013020515, "critic_loss": 0.4077110455930233, "actor_loss": -83.24487379455566, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.207005262374878, "step": 113000}
{"episode_reward": 900.5169173275555, "episode": 114.0, "batch_reward": 0.8530688730478286, "critic_loss": 0.4004325968325138, "actor_loss": -83.08712998962402, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.841554880142212, "step": 114000}
{"episode_reward": 937.5116872889882, "episode": 115.0, "batch_reward": 0.855196094930172, "critic_loss": 0.4028081899136305, "actor_loss": -82.8941403503418, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.938981533050537, "step": 115000}
{"episode_reward": 946.3100997560597, "episode": 116.0, "batch_reward": 0.8557347534298897, "critic_loss": 0.396744507163763, "actor_loss": -83.14784785461426, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.42858123779297, "step": 116000}
{"episode_reward": 875.5744370368925, "episode": 117.0, "batch_reward": 0.8550243546366691, "critic_loss": 0.4480302345454693, "actor_loss": -83.1331840209961, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.613106727600098, "step": 117000}
{"episode_reward": 882.7789473973512, "episode": 118.0, "batch_reward": 0.8559353964924812, "critic_loss": 0.4256432834118605, "actor_loss": -83.16269659423828, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.54369044303894, "step": 118000}
{"episode_reward": 932.0307434252034, "episode": 119.0, "batch_reward": 0.8551161043643951, "critic_loss": 0.4273910219818354, "actor_loss": -83.07329539489746, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.548226356506348, "step": 119000}
{"episode_reward": 901.350654817325, "episode": 120.0, "batch_reward": 0.8562443437576294, "critic_loss": 0.4111498361825943, "actor_loss": -83.1194615020752, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.112992763519287, "step": 120000}
{"episode_reward": 945.6828327962248, "episode": 121.0, "batch_reward": 0.8576279290318489, "critic_loss": 0.41143155153095723, "actor_loss": -83.10324534606933, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.38995361328125, "step": 121000}
{"episode_reward": 942.1480570916424, "episode": 122.0, "batch_reward": 0.860174402654171, "critic_loss": 0.40355293540656567, "actor_loss": -83.0303416595459, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.764925003051758, "step": 122000}
{"episode_reward": 923.5671775053878, "episode": 123.0, "batch_reward": 0.8588835410475731, "critic_loss": 0.40848554772138596, "actor_loss": -82.92796589660645, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.804677486419678, "step": 123000}
{"episode_reward": 860.0893676534387, "episode": 124.0, "batch_reward": 0.8601821141242981, "critic_loss": 0.4218628092557192, "actor_loss": -83.03990522766114, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.996949911117554, "step": 124000}
{"episode_reward": 960.6707634668818, "episode": 125.0, "batch_reward": 0.8603402860164643, "critic_loss": 0.4352144997268915, "actor_loss": -83.03591200256348, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.637761116027832, "step": 125000}
{"episode_reward": 921.7511013907982, "episode": 126.0, "batch_reward": 0.8600500118136406, "critic_loss": 0.4259582017213106, "actor_loss": -82.90446891784669, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.491307258605957, "step": 126000}
{"episode_reward": 933.1348310921669, "episode": 127.0, "batch_reward": 0.8608017249703407, "critic_loss": 0.4275834136009216, "actor_loss": -83.13998999023437, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.548227548599243, "step": 127000}
{"episode_reward": 934.6538653296531, "episode": 128.0, "batch_reward": 0.8605953347682953, "critic_loss": 0.44557461416721345, "actor_loss": -83.22444667053223, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.526922464370728, "step": 128000}
{"episode_reward": 955.8801314572331, "episode": 129.0, "batch_reward": 0.8622810540795326, "critic_loss": 0.41303366573154926, "actor_loss": -83.16191130065918, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.368041276931763, "step": 129000}
{"episode_reward": 933.2801374718078, "episode": 130.0, "batch_reward": 0.8625270370841026, "critic_loss": 0.42825447280704976, "actor_loss": -83.23118565368652, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.189723253250122, "step": 130000}
{"episode_reward": 928.103797542875, "episode": 131.0, "batch_reward": 0.862216947555542, "critic_loss": 0.4468914529532194, "actor_loss": -83.47207913208008, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 45.47320485115051, "step": 131000}
{"episode_reward": 926.8481385506765, "episode": 132.0, "batch_reward": 0.8629487692117691, "critic_loss": 0.42627586650848387, "actor_loss": -83.27728143310547, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.597693920135498, "step": 132000}
{"episode_reward": 931.1707655772682, "episode": 133.0, "batch_reward": 0.8623141749501229, "critic_loss": 0.4736540677547455, "actor_loss": -83.23605229187012, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.1418616771698, "step": 133000}
{"episode_reward": 827.4986299294072, "episode": 134.0, "batch_reward": 0.8630401321053505, "critic_loss": 0.45239450918138024, "actor_loss": -83.23932766723632, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.06112551689148, "step": 134000}
{"episode_reward": 932.7610514254927, "episode": 135.0, "batch_reward": 0.8626686520576478, "critic_loss": 0.43550752878189086, "actor_loss": -83.16432205200195, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.290544748306274, "step": 135000}
{"episode_reward": 951.9287312540165, "episode": 136.0, "batch_reward": 0.8635902824997902, "critic_loss": 0.462943645298481, "actor_loss": -83.1471261291504, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.886361837387085, "step": 136000}
{"episode_reward": 908.3135793716876, "episode": 137.0, "batch_reward": 0.8658475281000138, "critic_loss": 0.45797580958902834, "actor_loss": -83.27844300842285, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.923129558563232, "step": 137000}
{"episode_reward": 952.9850958776115, "episode": 138.0, "batch_reward": 0.8671915614008904, "critic_loss": 0.4407631290405989, "actor_loss": -83.6862864227295, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.611478805541992, "step": 138000}
{"episode_reward": 943.1613399303652, "episode": 139.0, "batch_reward": 0.8663715753555298, "critic_loss": 0.4454733188599348, "actor_loss": -83.74353889465333, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.3091082572937, "step": 139000}
{"episode_reward": 915.357967709161, "episode": 140.0, "batch_reward": 0.866030976831913, "critic_loss": 0.45611123836040496, "actor_loss": -83.5994976196289, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.54431653022766, "step": 140000}
{"episode_reward": 928.0942194738451, "episode": 141.0, "batch_reward": 0.8674432782530784, "critic_loss": 0.4372987609803677, "actor_loss": -83.44403713989257, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.06510329246521, "step": 141000}
{"episode_reward": 941.4993822221514, "episode": 142.0, "batch_reward": 0.867936425447464, "critic_loss": 0.4657095489948988, "actor_loss": -83.65064051818848, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.3796226978302, "step": 142000}
{"episode_reward": 889.358403754538, "episode": 143.0, "batch_reward": 0.8685653448700905, "critic_loss": 0.43089473298192027, "actor_loss": -83.39874938964844, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.140342712402344, "step": 143000}
{"episode_reward": 947.5083246809731, "episode": 144.0, "batch_reward": 0.8682416763305664, "critic_loss": 0.4153663895726204, "actor_loss": -83.61807032775879, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.81123661994934, "step": 144000}
{"episode_reward": 921.2697418015489, "episode": 145.0, "batch_reward": 0.8680535252690316, "critic_loss": 0.4462527651041746, "actor_loss": -83.19400738525391, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.68700122833252, "step": 145000}
{"episode_reward": 926.7664180678876, "episode": 146.0, "batch_reward": 0.869724351644516, "critic_loss": 0.4279221992045641, "actor_loss": -83.70397827148437, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.304604530334473, "step": 146000}
{"episode_reward": 949.6577528003069, "episode": 147.0, "batch_reward": 0.8696018800139427, "critic_loss": 0.42363787814974785, "actor_loss": -83.54905912780762, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.240906953811646, "step": 147000}
{"episode_reward": 926.8215947901348, "episode": 148.0, "batch_reward": 0.8696517458558083, "critic_loss": 0.44024502934515475, "actor_loss": -83.51500482177734, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.358041048049927, "step": 148000}
{"episode_reward": 925.8462274685733, "episode": 149.0, "batch_reward": 0.8695387596487999, "critic_loss": 0.43025396540760996, "actor_loss": -83.66998469543456, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.432942628860474, "step": 149000}
{"episode_reward": 945.9653788818711, "episode": 150.0, "batch_reward": 0.8705635267496109, "critic_loss": 0.4220927354544401, "actor_loss": -83.69501545715332, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "step": 150000}
