{"episode_reward": 0.0, "episode": 1.0, "duration": 21.43987798690796, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.8324604034423828, "step": 2000}
{"episode_reward": 632.427646246406, "episode": 3.0, "batch_reward": 0.334887304681466, "critic_loss": 0.3119674454790656, "actor_loss": -43.3647352803652, "actor_target_entropy": -6.0, "alpha_value": 0.004365629073060301, "duration": 63.16849184036255, "step": 3000}
{"episode_reward": 201.6523414571808, "episode": 4.0, "batch_reward": 0.31777375109493733, "critic_loss": 0.6834615463018417, "actor_loss": -42.8280589094162, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.40930199623108, "step": 4000}
{"episode_reward": 462.8940748598315, "episode": 5.0, "batch_reward": 0.3476475172638893, "critic_loss": 0.7431639793515206, "actor_loss": -44.25506924152374, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.45432734489441, "step": 5000}
{"episode_reward": 490.24618487631, "episode": 6.0, "batch_reward": 0.33924213908612727, "critic_loss": 0.6269266543984413, "actor_loss": -45.692431949615475, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.67170476913452, "step": 6000}
{"episode_reward": 23.580916086136206, "episode": 7.0, "batch_reward": 0.3243948783874512, "critic_loss": 0.6759529739022255, "actor_loss": -46.84773966217041, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.433164834976196, "step": 7000}
{"episode_reward": 610.8498252147987, "episode": 8.0, "batch_reward": 0.3621092622578144, "critic_loss": 0.7884506274759769, "actor_loss": -47.657850324630736, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.00460910797119, "step": 8000}
{"episode_reward": 594.1213136882144, "episode": 9.0, "batch_reward": 0.40140120550990105, "critic_loss": 0.8593732067346573, "actor_loss": -48.70094403266907, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.843581914901733, "step": 9000}
{"episode_reward": 737.0791903028854, "episode": 10.0, "batch_reward": 0.4446285870373249, "critic_loss": 0.8654127134978771, "actor_loss": -52.18792377471924, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.997570753097534, "step": 10000}
{"episode_reward": 756.9128637301371, "episode": 11.0, "batch_reward": 0.4710801018178463, "critic_loss": 0.8747506353259087, "actor_loss": -51.58712479019165, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.42263436317444, "step": 11000}
{"episode_reward": 844.0427208496099, "episode": 12.0, "batch_reward": 0.5061222972571849, "critic_loss": 0.8417863937616348, "actor_loss": -55.52211933135986, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.577587366104126, "step": 12000}
{"episode_reward": 783.0764393676425, "episode": 13.0, "batch_reward": 0.5269241845905781, "critic_loss": 0.9486990401744843, "actor_loss": -57.21271113204956, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.384538650512695, "step": 13000}
{"episode_reward": 852.8196170372146, "episode": 14.0, "batch_reward": 0.5518891892135144, "critic_loss": 0.9691393814086914, "actor_loss": -57.615619998931884, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.17586350440979, "step": 14000}
{"episode_reward": 846.3881761777092, "episode": 15.0, "batch_reward": 0.5649074074327946, "critic_loss": 1.103227663218975, "actor_loss": -57.38477332305908, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.717185974121094, "step": 15000}
{"episode_reward": 634.9406036057051, "episode": 16.0, "batch_reward": 0.5736085128486157, "critic_loss": 1.1119368097782134, "actor_loss": -59.24188246154785, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.45951223373413, "step": 16000}
{"episode_reward": 839.4521608382233, "episode": 17.0, "batch_reward": 0.5887672031819821, "critic_loss": 1.1480813828706742, "actor_loss": -61.12154899597168, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.03477120399475, "step": 17000}
{"episode_reward": 780.5858036900986, "episode": 18.0, "batch_reward": 0.6073573888540268, "critic_loss": 1.0945190342068671, "actor_loss": -61.369651008605956, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.857776165008545, "step": 18000}
{"episode_reward": 913.3336402675969, "episode": 19.0, "batch_reward": 0.6184434567093849, "critic_loss": 1.0398536607027054, "actor_loss": -62.40467302703858, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.652851343154907, "step": 19000}
{"episode_reward": 807.683427656006, "episode": 20.0, "batch_reward": 0.6288999955654144, "critic_loss": 1.0756863676309585, "actor_loss": -63.904042686462404, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.408453702926636, "step": 20000}
{"episode_reward": 773.1724634113427, "episode": 21.0, "batch_reward": 0.6343134920597077, "critic_loss": 1.2096684404611588, "actor_loss": -63.01735352325439, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.44406986236572, "step": 21000}
{"episode_reward": 732.8493118743562, "episode": 22.0, "batch_reward": 0.6317360706329346, "critic_loss": 1.1513005989193916, "actor_loss": -65.47887629699707, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.43889021873474, "step": 22000}
{"episode_reward": 587.9634634804822, "episode": 23.0, "batch_reward": 0.638725560605526, "critic_loss": 1.1401637381911278, "actor_loss": -65.60445684814454, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.55713415145874, "step": 23000}
{"episode_reward": 859.9904588585897, "episode": 24.0, "batch_reward": 0.6492018123865128, "critic_loss": 1.1019340957999229, "actor_loss": -65.09057060241699, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.888397932052612, "step": 24000}
{"episode_reward": 866.2472854775257, "episode": 25.0, "batch_reward": 0.6567914865016937, "critic_loss": 1.0802817606329917, "actor_loss": -66.82388272094727, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.42266535758972, "step": 25000}
{"episode_reward": 837.3422300698938, "episode": 26.0, "batch_reward": 0.664067024409771, "critic_loss": 1.1236293085813522, "actor_loss": -66.77889761352539, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.281312942504883, "step": 26000}
{"episode_reward": 895.8811338569645, "episode": 27.0, "batch_reward": 0.6704409617185593, "critic_loss": 1.1106822867393493, "actor_loss": -67.4129730911255, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.77689218521118, "step": 27000}
{"episode_reward": 832.5071947946441, "episode": 28.0, "batch_reward": 0.6796561992168426, "critic_loss": 1.0187049984931946, "actor_loss": -68.48662873077393, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.54741334915161, "step": 28000}
{"episode_reward": 920.8959667587374, "episode": 29.0, "batch_reward": 0.6878613713979721, "critic_loss": 1.042075564801693, "actor_loss": -68.90366366577149, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.1493558883667, "step": 29000}
{"episode_reward": 892.3787444307014, "episode": 30.0, "batch_reward": 0.6913994061350822, "critic_loss": 1.069392438352108, "actor_loss": -68.76644152069092, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.00831913948059, "step": 30000}
{"episode_reward": 769.724427002951, "episode": 31.0, "batch_reward": 0.6993809236288071, "critic_loss": 0.9830939569473267, "actor_loss": -70.03330625915527, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.64092779159546, "step": 31000}
{"episode_reward": 934.8837534538901, "episode": 32.0, "batch_reward": 0.7069039796590805, "critic_loss": 0.9325260437428952, "actor_loss": -70.20933433532714, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.63202667236328, "step": 32000}
{"episode_reward": 925.3597701311958, "episode": 33.0, "batch_reward": 0.7139349327683449, "critic_loss": 0.9754045194685459, "actor_loss": -71.18784381866455, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.89216923713684, "step": 33000}
{"episode_reward": 950.2830137191676, "episode": 34.0, "batch_reward": 0.7188518764972687, "critic_loss": 0.9982445759177208, "actor_loss": -71.5716142654419, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.4831440448761, "step": 34000}
{"episode_reward": 835.6236161272609, "episode": 35.0, "batch_reward": 0.7220340710878372, "critic_loss": 0.9441385132670402, "actor_loss": -70.86273418426514, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.308269262313843, "step": 35000}
{"episode_reward": 901.0565668168119, "episode": 36.0, "batch_reward": 0.7273105928897857, "critic_loss": 0.9681687460839749, "actor_loss": -72.45742010498047, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.11889624595642, "step": 36000}
{"episode_reward": 870.8457717875515, "episode": 37.0, "batch_reward": 0.7310608684420585, "critic_loss": 0.945963478565216, "actor_loss": -72.3399768447876, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.413801670074463, "step": 37000}
{"episode_reward": 913.5621832354443, "episode": 38.0, "batch_reward": 0.7325900260806084, "critic_loss": 1.0065727154910564, "actor_loss": -72.49937228393554, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.369713306427002, "step": 38000}
{"episode_reward": 862.3801456231913, "episode": 39.0, "batch_reward": 0.7397868902087211, "critic_loss": 0.9674889370501042, "actor_loss": -73.67044705963134, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.39856457710266, "step": 39000}
{"episode_reward": 934.8030991770065, "episode": 40.0, "batch_reward": 0.7405266073346138, "critic_loss": 1.0390981364548206, "actor_loss": -74.22159902191162, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.437760829925537, "step": 40000}
{"episode_reward": 768.6780202073794, "episode": 41.0, "batch_reward": 0.7438094899654388, "critic_loss": 0.9649565159082413, "actor_loss": -74.33305206298829, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.98618292808533, "step": 41000}
{"episode_reward": 890.4317514465554, "episode": 42.0, "batch_reward": 0.7479624870419502, "critic_loss": 0.9892271713018418, "actor_loss": -74.40515869140626, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.51418423652649, "step": 42000}
{"episode_reward": 866.8374014760427, "episode": 43.0, "batch_reward": 0.7512309085130692, "critic_loss": 1.0137761877775193, "actor_loss": -74.87093043518067, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.912008047103882, "step": 43000}
{"episode_reward": 832.7253940673802, "episode": 44.0, "batch_reward": 0.7519485949873924, "critic_loss": 1.006630543857813, "actor_loss": -74.43857849121093, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.85984206199646, "step": 44000}
{"episode_reward": 937.8468719615668, "episode": 45.0, "batch_reward": 0.7559871829152107, "critic_loss": 1.019247754663229, "actor_loss": -74.69474661254883, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.657845735549927, "step": 45000}
{"episode_reward": 863.9222790848647, "episode": 46.0, "batch_reward": 0.7594575096964836, "critic_loss": 1.0083123210072518, "actor_loss": -75.24645770263672, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.82622504234314, "step": 46000}
{"episode_reward": 929.7076814973483, "episode": 47.0, "batch_reward": 0.7621717180013656, "critic_loss": 1.0164890244901181, "actor_loss": -75.43833645629883, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.878630876541138, "step": 47000}
{"episode_reward": 884.2000644696491, "episode": 48.0, "batch_reward": 0.7657957340478897, "critic_loss": 0.99515971159935, "actor_loss": -75.57306079101562, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.736271858215332, "step": 48000}
{"episode_reward": 923.5376028971444, "episode": 49.0, "batch_reward": 0.7697886619567871, "critic_loss": 1.0193744679093362, "actor_loss": -75.92902444458008, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.03136134147644, "step": 49000}
{"episode_reward": 924.2752768411187, "episode": 50.0, "batch_reward": 0.7700728313326836, "critic_loss": 0.9795782245397567, "actor_loss": -76.15074058532714, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.697252988815308, "step": 50000}
{"episode_reward": 884.7193985356455, "episode": 51.0, "batch_reward": 0.773087540268898, "critic_loss": 1.035563468337059, "actor_loss": -76.36466873168945, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.18982815742493, "step": 51000}
{"episode_reward": 838.3630774375503, "episode": 52.0, "batch_reward": 0.7742767964601517, "critic_loss": 0.9969487311840057, "actor_loss": -76.44174833679199, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.580565690994263, "step": 52000}
{"episode_reward": 939.1460464738938, "episode": 53.0, "batch_reward": 0.7788460655212402, "critic_loss": 1.0184525038003922, "actor_loss": -76.75977639770508, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.43931269645691, "step": 53000}
{"episode_reward": 893.8520186932853, "episode": 54.0, "batch_reward": 0.7815513834357262, "critic_loss": 1.0159325462579727, "actor_loss": -76.98867279052735, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.281425952911377, "step": 54000}
{"episode_reward": 926.4826287197621, "episode": 55.0, "batch_reward": 0.7835148675441742, "critic_loss": 1.0679395746588707, "actor_loss": -77.26242063903808, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.799875497817993, "step": 55000}
{"episode_reward": 953.9315514290324, "episode": 56.0, "batch_reward": 0.7846816340684891, "critic_loss": 1.0040710141062736, "actor_loss": -77.50055041503906, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.549705743789673, "step": 56000}
{"episode_reward": 903.7528181443625, "episode": 57.0, "batch_reward": 0.7874466574192047, "critic_loss": 0.97021160364151, "actor_loss": -77.62994889831543, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.99169945716858, "step": 57000}
{"episode_reward": 882.1774760655196, "episode": 58.0, "batch_reward": 0.789060059428215, "critic_loss": 1.019930922806263, "actor_loss": -77.77435372924805, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.677394151687622, "step": 58000}
{"episode_reward": 839.4356228761603, "episode": 59.0, "batch_reward": 0.7907685642838478, "critic_loss": 0.9888403645157814, "actor_loss": -77.93357916259765, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.541426420211792, "step": 59000}
{"episode_reward": 871.910866453247, "episode": 60.0, "batch_reward": 0.7945026525259018, "critic_loss": 0.953621667444706, "actor_loss": -77.98392822265625, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.101112127304077, "step": 60000}
{"episode_reward": 958.6606061052582, "episode": 61.0, "batch_reward": 0.7959465849995613, "critic_loss": 0.9118308089673519, "actor_loss": -78.05998985290528, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.24316382408142, "step": 61000}
{"episode_reward": 912.0969325508527, "episode": 62.0, "batch_reward": 0.7972141185998917, "critic_loss": 0.9331416475474834, "actor_loss": -78.19400486755372, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.15019655227661, "step": 62000}
{"episode_reward": 931.6377921500692, "episode": 63.0, "batch_reward": 0.7988934907913208, "critic_loss": 0.9392689138650894, "actor_loss": -78.38104672241211, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.37583065032959, "step": 63000}
{"episode_reward": 879.9194824338189, "episode": 64.0, "batch_reward": 0.8007793574929237, "critic_loss": 0.9091768298447133, "actor_loss": -78.55829174804687, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.41042947769165, "step": 64000}
{"episode_reward": 956.0854758892659, "episode": 65.0, "batch_reward": 0.8032039231061936, "critic_loss": 0.8475709019303321, "actor_loss": -78.6676946105957, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.205324411392212, "step": 65000}
{"episode_reward": 835.9435746489382, "episode": 66.0, "batch_reward": 0.803544364631176, "critic_loss": 0.9261127662062645, "actor_loss": -78.67643716430663, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.72115182876587, "step": 66000}
{"episode_reward": 930.0238073707911, "episode": 67.0, "batch_reward": 0.8047203793525696, "critic_loss": 0.9134902797937393, "actor_loss": -78.69530824279785, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.43068814277649, "step": 67000}
{"episode_reward": 902.067773222792, "episode": 68.0, "batch_reward": 0.8085640124082565, "critic_loss": 0.9078810813426972, "actor_loss": -78.95761042785645, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.14411449432373, "step": 68000}
{"episode_reward": 926.4865126736887, "episode": 69.0, "batch_reward": 0.8097368566393852, "critic_loss": 0.8935478809773922, "actor_loss": -79.06216078186036, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.72557020187378, "step": 69000}
{"episode_reward": 935.317883236532, "episode": 70.0, "batch_reward": 0.8099940341711044, "critic_loss": 1.0346194682121277, "actor_loss": -79.09553126525878, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.846460819244385, "step": 70000}
{"episode_reward": 819.9046126828496, "episode": 71.0, "batch_reward": 0.8113006870746613, "critic_loss": 0.9669969903826714, "actor_loss": -79.18217041015625, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.265358686447144, "step": 71000}
{"episode_reward": 867.2588671808164, "episode": 72.0, "batch_reward": 0.811202635884285, "critic_loss": 0.9848751080930233, "actor_loss": -79.27687646484375, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.409514904022217, "step": 72000}
{"episode_reward": 896.3181295868479, "episode": 73.0, "batch_reward": 0.8129442413449287, "critic_loss": 0.972086404055357, "actor_loss": -79.41039678955079, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.384132146835327, "step": 73000}
{"episode_reward": 919.8050770191757, "episode": 74.0, "batch_reward": 0.8138612521290779, "critic_loss": 0.9915963791310787, "actor_loss": -79.51024862670899, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.358280181884766, "step": 74000}
{"episode_reward": 947.5278515790399, "episode": 75.0, "batch_reward": 0.8173668849468231, "critic_loss": 0.9630087771117687, "actor_loss": -79.65705393981933, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.653612852096558, "step": 75000}
{"episode_reward": 898.4367449480193, "episode": 76.0, "batch_reward": 0.8172894484400749, "critic_loss": 0.9428942457735539, "actor_loss": -79.7487406616211, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.378596782684326, "step": 76000}
{"episode_reward": 927.598663539811, "episode": 77.0, "batch_reward": 0.8175148686766625, "critic_loss": 0.9969252771437168, "actor_loss": -79.75119609069824, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.14858627319336, "step": 77000}
{"episode_reward": 865.3353101892463, "episode": 78.0, "batch_reward": 0.8178028119206429, "critic_loss": 0.9198628805577755, "actor_loss": -79.84047390747071, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.395784854888916, "step": 78000}
{"episode_reward": 888.3277787042026, "episode": 79.0, "batch_reward": 0.822214115858078, "critic_loss": 0.8966940987408161, "actor_loss": -79.93750506591797, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.381630897521973, "step": 79000}
{"episode_reward": 962.6726154995081, "episode": 80.0, "batch_reward": 0.8212094575762748, "critic_loss": 0.9406312090158463, "actor_loss": -80.08803634643554, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.057166814804077, "step": 80000}
{"episode_reward": 949.9352763305267, "episode": 81.0, "batch_reward": 0.8237204570770263, "critic_loss": 0.8856063841879368, "actor_loss": -80.10212655639648, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.549264669418335, "step": 81000}
{"episode_reward": 931.8998277406336, "episode": 82.0, "batch_reward": 0.8238817519545555, "critic_loss": 0.8858652951121331, "actor_loss": -80.23776477050781, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.73677897453308, "step": 82000}
{"episode_reward": 902.4883297391896, "episode": 83.0, "batch_reward": 0.826924191057682, "critic_loss": 0.8827047894895077, "actor_loss": -80.37418893432617, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.798547983169556, "step": 83000}
{"episode_reward": 920.0224702066394, "episode": 84.0, "batch_reward": 0.826131079852581, "critic_loss": 0.8776216236948967, "actor_loss": -80.35413568115234, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.68418788909912, "step": 84000}
{"episode_reward": 954.0494105284382, "episode": 85.0, "batch_reward": 0.8290433634519577, "critic_loss": 0.8763642301261425, "actor_loss": -80.5092896118164, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.70913338661194, "step": 85000}
{"episode_reward": 896.0542556284475, "episode": 86.0, "batch_reward": 0.8290124188661575, "critic_loss": 0.8644063737690448, "actor_loss": -80.56963829040528, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.760652542114258, "step": 86000}
{"episode_reward": 926.8897098698226, "episode": 87.0, "batch_reward": 0.8298672860264779, "critic_loss": 0.9013211108744145, "actor_loss": -80.62894758605957, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.950037002563477, "step": 87000}
{"episode_reward": 939.4654260085132, "episode": 88.0, "batch_reward": 0.8320361341238022, "critic_loss": 0.8959548343718052, "actor_loss": -80.71983633422852, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.446906328201294, "step": 88000}
{"episode_reward": 901.7277720975119, "episode": 89.0, "batch_reward": 0.8325930746793747, "critic_loss": 0.919802856773138, "actor_loss": -80.75810165405274, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.86117672920227, "step": 89000}
{"episode_reward": 889.0867845024835, "episode": 90.0, "batch_reward": 0.8314707552194596, "critic_loss": 0.8812852953970433, "actor_loss": -80.80421530151366, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.121071100234985, "step": 90000}
{"episode_reward": 877.8707168911301, "episode": 91.0, "batch_reward": 0.8323966753482819, "critic_loss": 0.8542131745517254, "actor_loss": -80.86278314208984, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.72728681564331, "step": 91000}
{"episode_reward": 903.2811764900256, "episode": 92.0, "batch_reward": 0.8335248631238937, "critic_loss": 0.8968850893080235, "actor_loss": -81.05830551147461, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.185742616653442, "step": 92000}
{"episode_reward": 928.2871903105025, "episode": 93.0, "batch_reward": 0.8347840189933777, "critic_loss": 0.8146082062125206, "actor_loss": -81.02431359863282, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.419965028762817, "step": 93000}
{"episode_reward": 920.5196993300486, "episode": 94.0, "batch_reward": 0.8361537435650825, "critic_loss": 0.8164255914390087, "actor_loss": -81.1917721710205, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.910913705825806, "step": 94000}
{"episode_reward": 930.3478963547404, "episode": 95.0, "batch_reward": 0.8348966596126557, "critic_loss": 0.8661364859640598, "actor_loss": -81.21176933288574, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.914772987365723, "step": 95000}
{"episode_reward": 913.6784276079919, "episode": 96.0, "batch_reward": 0.8389347200989723, "critic_loss": 0.797131232559681, "actor_loss": -81.32694750976563, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.798877477645874, "step": 96000}
{"episode_reward": 939.9504767875349, "episode": 97.0, "batch_reward": 0.8381530573964119, "critic_loss": 0.8489543735980988, "actor_loss": -81.3140672454834, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.88637900352478, "step": 97000}
{"episode_reward": 906.9797235213007, "episode": 98.0, "batch_reward": 0.8409485107660294, "critic_loss": 0.8534025382995606, "actor_loss": -81.30597033691406, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.809200048446655, "step": 98000}
{"episode_reward": 947.3701085886764, "episode": 99.0, "batch_reward": 0.8416656087040901, "critic_loss": 0.8013365511000157, "actor_loss": -81.4720110168457, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.433202266693115, "step": 99000}
{"episode_reward": 953.440619641483, "episode": 100.0, "batch_reward": 0.8411493746638298, "critic_loss": 0.8050417260229588, "actor_loss": -81.45496936035157, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.002925872802734, "step": 100000}
{"episode_reward": 916.8508004772979, "episode": 101.0, "batch_reward": 0.8430901650190353, "critic_loss": 0.7923792524635792, "actor_loss": -81.64067266845703, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.093538761138916, "step": 101000}
{"episode_reward": 935.437838955165, "episode": 102.0, "batch_reward": 0.844098982989788, "critic_loss": 0.7490206764638424, "actor_loss": -81.57287202453614, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.43099594116211, "step": 102000}
{"episode_reward": 938.932313329305, "episode": 103.0, "batch_reward": 0.8461701508760452, "critic_loss": 0.7181927770078183, "actor_loss": -81.84229579162597, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.552162170410156, "step": 103000}
{"episode_reward": 953.1325035687902, "episode": 104.0, "batch_reward": 0.8465527700781822, "critic_loss": 0.7852279546856881, "actor_loss": -81.64167361450195, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.658298015594482, "step": 104000}
{"episode_reward": 877.6345708368399, "episode": 105.0, "batch_reward": 0.8459926575422287, "critic_loss": 0.7333201362490654, "actor_loss": -81.8956654663086, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.51388955116272, "step": 105000}
{"episode_reward": 936.7027200508285, "episode": 106.0, "batch_reward": 0.8466160662770271, "critic_loss": 0.7645495666265487, "actor_loss": -81.91326095581054, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.191315174102783, "step": 106000}
{"episode_reward": 941.2375863042913, "episode": 107.0, "batch_reward": 0.846609961926937, "critic_loss": 0.7023717412054539, "actor_loss": -81.92236926269531, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.844687938690186, "step": 107000}
{"episode_reward": 918.2036299399998, "episode": 108.0, "batch_reward": 0.8473189668059349, "critic_loss": 0.7292461996376515, "actor_loss": -81.97038430786132, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.713902711868286, "step": 108000}
{"episode_reward": 925.729238621899, "episode": 109.0, "batch_reward": 0.8474734525680542, "critic_loss": 0.7361981479823589, "actor_loss": -81.90615100097656, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.153830528259277, "step": 109000}
{"episode_reward": 918.9005962433279, "episode": 110.0, "batch_reward": 0.8502835275530816, "critic_loss": 0.7340879130065441, "actor_loss": -81.98246287536621, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.594368934631348, "step": 110000}
{"episode_reward": 918.2702621418689, "episode": 111.0, "batch_reward": 0.8492216380238533, "critic_loss": 0.7722901400923728, "actor_loss": -82.17937135314942, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.96139478683472, "step": 111000}
{"episode_reward": 869.0480777962294, "episode": 112.0, "batch_reward": 0.8490411637425422, "critic_loss": 0.7294029052257538, "actor_loss": -82.16072019958496, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.83230710029602, "step": 112000}
{"episode_reward": 877.982396796687, "episode": 113.0, "batch_reward": 0.8517546911239624, "critic_loss": 0.710954739421606, "actor_loss": -82.40466348266601, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.537595987319946, "step": 113000}
{"episode_reward": 943.4835963819551, "episode": 114.0, "batch_reward": 0.8517813163995743, "critic_loss": 0.7306427598297596, "actor_loss": -82.30302301025391, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.701831579208374, "step": 114000}
{"episode_reward": 940.2169798480763, "episode": 115.0, "batch_reward": 0.8516903128027916, "critic_loss": 0.7194004722833633, "actor_loss": -82.11340260314941, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.922544240951538, "step": 115000}
{"episode_reward": 941.5074668854704, "episode": 116.0, "batch_reward": 0.8526710805296898, "critic_loss": 0.7230696007013321, "actor_loss": -82.3414072265625, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.759435415267944, "step": 116000}
{"episode_reward": 848.6569151536825, "episode": 117.0, "batch_reward": 0.853004547059536, "critic_loss": 0.7214750774502754, "actor_loss": -82.31997001647949, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.54448652267456, "step": 117000}
{"episode_reward": 888.4988903013085, "episode": 118.0, "batch_reward": 0.8532929180860519, "critic_loss": 0.6958457369804383, "actor_loss": -82.3146668548584, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.896536827087402, "step": 118000}
{"episode_reward": 944.0752123568606, "episode": 119.0, "batch_reward": 0.8539528958201409, "critic_loss": 0.7276292313933372, "actor_loss": -82.33685850524903, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.10678195953369, "step": 119000}
{"episode_reward": 943.2176103742313, "episode": 120.0, "batch_reward": 0.8548189373612404, "critic_loss": 0.7069701042175293, "actor_loss": -82.36688117980957, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.439821481704712, "step": 120000}
{"episode_reward": 937.1293328703057, "episode": 121.0, "batch_reward": 0.8549293950200081, "critic_loss": 0.7121766097843647, "actor_loss": -82.32718699645996, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.750308990478516, "step": 121000}
{"episode_reward": 906.4450734276596, "episode": 122.0, "batch_reward": 0.8561141371130944, "critic_loss": 0.7612446284890175, "actor_loss": -82.25552873229981, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.402310371398926, "step": 122000}
{"episode_reward": 881.5037966450595, "episode": 123.0, "batch_reward": 0.8555668568015099, "critic_loss": 0.7762401811778545, "actor_loss": -82.211617477417, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.086055278778076, "step": 123000}
{"episode_reward": 893.9478840278985, "episode": 124.0, "batch_reward": 0.8556997113227844, "critic_loss": 0.787501231521368, "actor_loss": -82.28456283569336, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.772115468978882, "step": 124000}
{"episode_reward": 897.910940237355, "episode": 125.0, "batch_reward": 0.8568960346579552, "critic_loss": 0.8601690606176853, "actor_loss": -82.28190002441406, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.9165678024292, "step": 125000}
{"episode_reward": 883.7843170913512, "episode": 126.0, "batch_reward": 0.8561274273991585, "critic_loss": 0.7991152995228767, "actor_loss": -82.20310131835937, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.817318439483643, "step": 126000}
{"episode_reward": 888.95544626296, "episode": 127.0, "batch_reward": 0.8564034521579742, "critic_loss": 0.771514394313097, "actor_loss": -82.33438615417481, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.908430576324463, "step": 127000}
{"episode_reward": 954.2304244056885, "episode": 128.0, "batch_reward": 0.8585011596679688, "critic_loss": 0.7979814879447221, "actor_loss": -82.47252742004395, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.115052223205566, "step": 128000}
{"episode_reward": 944.9674458931387, "episode": 129.0, "batch_reward": 0.8585104987621307, "critic_loss": 0.7807328010797501, "actor_loss": -82.43231855773925, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.431748151779175, "step": 129000}
{"episode_reward": 925.8501038026781, "episode": 130.0, "batch_reward": 0.8593840928673744, "critic_loss": 0.7757318134605885, "actor_loss": -82.43489324951172, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.729716777801514, "step": 130000}
{"episode_reward": 908.9905265008919, "episode": 131.0, "batch_reward": 0.8592437440156937, "critic_loss": 0.8066561272442341, "actor_loss": -82.66598461914063, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.79528021812439, "step": 131000}
{"episode_reward": 887.5239757948253, "episode": 132.0, "batch_reward": 0.8588052950501442, "critic_loss": 0.8195959813594819, "actor_loss": -82.4909951171875, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.52173399925232, "step": 132000}
{"episode_reward": 928.8549984579021, "episode": 133.0, "batch_reward": 0.8589272211790084, "critic_loss": 0.8624941883385181, "actor_loss": -82.47300436401368, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.912733554840088, "step": 133000}
{"episode_reward": 843.7070536399159, "episode": 134.0, "batch_reward": 0.8591701369285584, "critic_loss": 0.7318003505468369, "actor_loss": -82.53919636535645, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.920904636383057, "step": 134000}
{"episode_reward": 929.0746151899513, "episode": 135.0, "batch_reward": 0.8598089349865914, "critic_loss": 0.766266135931015, "actor_loss": -82.4976925201416, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.765120267868042, "step": 135000}
{"episode_reward": 883.730821148216, "episode": 136.0, "batch_reward": 0.8603628898859024, "critic_loss": 0.7746383791863918, "actor_loss": -82.46780606079102, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.8481023311615, "step": 136000}
{"episode_reward": 897.1711717647295, "episode": 137.0, "batch_reward": 0.86132246530056, "critic_loss": 0.7791334882676602, "actor_loss": -82.49270506286621, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.008101224899292, "step": 137000}
{"episode_reward": 934.2459059354302, "episode": 138.0, "batch_reward": 0.8614622496366501, "critic_loss": 0.7387195315063, "actor_loss": -82.79338285827637, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.410784006118774, "step": 138000}
{"episode_reward": 934.0642259406411, "episode": 139.0, "batch_reward": 0.8617453699111939, "critic_loss": 0.7795453816056251, "actor_loss": -82.87766313171387, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.10098147392273, "step": 139000}
{"episode_reward": 902.9629375031034, "episode": 140.0, "batch_reward": 0.860817674100399, "critic_loss": 0.7315036942064762, "actor_loss": -82.75344706726074, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.657999753952026, "step": 140000}
{"episode_reward": 924.3066564224854, "episode": 141.0, "batch_reward": 0.8625419642925263, "critic_loss": 0.670298031359911, "actor_loss": -82.6456356048584, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.843533515930176, "step": 141000}
{"episode_reward": 930.0469207668519, "episode": 142.0, "batch_reward": 0.8627389693856239, "critic_loss": 0.6998115393817425, "actor_loss": -82.7599249420166, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.775906801223755, "step": 142000}
{"episode_reward": 891.6366490256128, "episode": 143.0, "batch_reward": 0.8641779165863991, "critic_loss": 0.6728976292163134, "actor_loss": -82.62444172668457, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.410377264022827, "step": 143000}
{"episode_reward": 938.9248438825814, "episode": 144.0, "batch_reward": 0.8641242499351501, "critic_loss": 0.7639865966886282, "actor_loss": -82.77453161621094, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.595783948898315, "step": 144000}
{"episode_reward": 886.7316121258543, "episode": 145.0, "batch_reward": 0.8633703536391258, "critic_loss": 0.7690476185083389, "actor_loss": -82.44699060058593, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.722535848617554, "step": 145000}
{"episode_reward": 836.5651693421244, "episode": 146.0, "batch_reward": 0.8642023673653603, "critic_loss": 0.8014006005227565, "actor_loss": -82.7827247619629, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.78402853012085, "step": 146000}
{"episode_reward": 954.3212622140591, "episode": 147.0, "batch_reward": 0.8646874411702156, "critic_loss": 0.7434824361801148, "actor_loss": -82.74786537170411, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.394500255584717, "step": 147000}
{"episode_reward": 918.9703674727866, "episode": 148.0, "batch_reward": 0.864320826292038, "critic_loss": 0.7173498211503029, "actor_loss": -82.67406840515137, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.668813467025757, "step": 148000}
{"episode_reward": 922.9069354347308, "episode": 149.0, "batch_reward": 0.8653959264159202, "critic_loss": 0.7433286669552326, "actor_loss": -82.81386367797852, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.0535306930542, "step": 149000}
{"episode_reward": 945.9898772175169, "episode": 150.0, "batch_reward": 0.8665522678494454, "critic_loss": 0.720492356389761, "actor_loss": -82.8518402557373, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "step": 150000}
