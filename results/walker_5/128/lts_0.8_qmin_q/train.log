{"episode_reward": 0.0, "episode": 1.0, "duration": 22.11128807067871, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.8180139064788818, "step": 2000}
{"episode_reward": 632.427646246406, "episode": 3.0, "batch_reward": 0.34696731863219804, "critic_loss": 0.8392542693944087, "actor_loss": -69.00187989624561, "actor_target_entropy": -6.0, "alpha_value": 0.004365629073060301, "duration": 65.5125961303711, "step": 3000}
{"episode_reward": 460.87839216625923, "episode": 4.0, "batch_reward": 0.41431011897325515, "critic_loss": 1.405408650994301, "actor_loss": -70.28818940734864, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.422356128692627, "step": 4000}
{"episode_reward": 660.1865033715525, "episode": 5.0, "batch_reward": 0.4801245835125446, "critic_loss": 1.5256081694960595, "actor_loss": -71.83204019165039, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.096166610717773, "step": 5000}
{"episode_reward": 801.4568481827362, "episode": 6.0, "batch_reward": 0.5272096952199936, "critic_loss": 1.5424069576263428, "actor_loss": -72.60216383361816, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.516640663146973, "step": 6000}
{"episode_reward": 591.9416416603023, "episode": 7.0, "batch_reward": 0.5166709267795085, "critic_loss": 1.848629688858986, "actor_loss": -72.22516189575195, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.7460458278656, "step": 7000}
{"episode_reward": 475.34929968817926, "episode": 8.0, "batch_reward": 0.5325847438573837, "critic_loss": 2.0389430999755858, "actor_loss": -72.56460887145997, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.716251134872437, "step": 8000}
{"episode_reward": 732.7152328300989, "episode": 9.0, "batch_reward": 0.5613525069057942, "critic_loss": 2.364593489408493, "actor_loss": -72.70142683410644, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.2288601398468, "step": 9000}
{"episode_reward": 771.6610639142407, "episode": 10.0, "batch_reward": 0.5863229542076588, "critic_loss": 2.565591572880745, "actor_loss": -73.64986367797852, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.48922824859619, "step": 10000}
{"episode_reward": 796.7544858187659, "episode": 11.0, "batch_reward": 0.5832625975310802, "critic_loss": 2.9680356721878054, "actor_loss": -73.38458320617676, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.55799579620361, "step": 11000}
{"episode_reward": 383.606535663992, "episode": 12.0, "batch_reward": 0.5913855664432048, "critic_loss": 2.9814020422697065, "actor_loss": -73.82885960388184, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 26.219350814819336, "step": 12000}
{"episode_reward": 886.4642347734383, "episode": 13.0, "batch_reward": 0.6124996130764484, "critic_loss": 3.062070137619972, "actor_loss": -74.35186064147949, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.514800548553467, "step": 13000}
{"episode_reward": 873.6604218409523, "episode": 14.0, "batch_reward": 0.6327251753211022, "critic_loss": 3.122874418258667, "actor_loss": -74.89215132141113, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.381715536117554, "step": 14000}
{"episode_reward": 852.8033309214039, "episode": 15.0, "batch_reward": 0.6491370396018028, "critic_loss": 3.098631928920746, "actor_loss": -75.02744255065917, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.62205457687378, "step": 15000}
{"episode_reward": 942.7082150256027, "episode": 16.0, "batch_reward": 0.6682065703272819, "critic_loss": 2.75602459526062, "actor_loss": -75.58349981689453, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.92880916595459, "step": 16000}
{"episode_reward": 916.2240398306176, "episode": 17.0, "batch_reward": 0.6811273826956749, "critic_loss": 2.517006202697754, "actor_loss": -75.84903776550293, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.657769680023193, "step": 17000}
{"episode_reward": 836.3239487914469, "episode": 18.0, "batch_reward": 0.69012914955616, "critic_loss": 2.7026174163818357, "actor_loss": -76.10076176452637, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.19365620613098, "step": 18000}
{"episode_reward": 838.0013065062761, "episode": 19.0, "batch_reward": 0.6989610726237298, "critic_loss": 2.2732437968850134, "actor_loss": -76.15824655151367, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.550661087036133, "step": 19000}
{"episode_reward": 838.1683284231889, "episode": 20.0, "batch_reward": 0.7061537764072419, "critic_loss": 1.8369142835140229, "actor_loss": -76.36209120178222, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.298478841781616, "step": 20000}
{"episode_reward": 859.963800403414, "episode": 21.0, "batch_reward": 0.7136044053435325, "critic_loss": 1.6053625671863556, "actor_loss": -75.92322833251953, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.91941237449646, "step": 21000}
{"episode_reward": 837.5881292188063, "episode": 22.0, "batch_reward": 0.7123022345304489, "critic_loss": 1.5041554160118102, "actor_loss": -76.39386555480957, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.78848147392273, "step": 22000}
{"episode_reward": 647.9966949878022, "episode": 23.0, "batch_reward": 0.7134805803894997, "critic_loss": 1.4064866520166397, "actor_loss": -76.3220369720459, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.05137801170349, "step": 23000}
{"episode_reward": 803.4867511672443, "episode": 24.0, "batch_reward": 0.7173891989588738, "critic_loss": 1.48052222687006, "actor_loss": -76.00735429382324, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.74760341644287, "step": 24000}
{"episode_reward": 812.4839109100553, "episode": 25.0, "batch_reward": 0.7196712126135826, "critic_loss": 1.4623653612732888, "actor_loss": -76.48385932922363, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.531089305877686, "step": 25000}
{"episode_reward": 748.3142873165506, "episode": 26.0, "batch_reward": 0.7190452391505241, "critic_loss": 1.4656260165572166, "actor_loss": -76.16563507080077, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 25.862338066101074, "step": 26000}
{"episode_reward": 708.9411180619893, "episode": 27.0, "batch_reward": 0.7236151052117348, "critic_loss": 1.4431571435928345, "actor_loss": -76.11597389221191, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.1599383354187, "step": 27000}
{"episode_reward": 870.9262821395401, "episode": 28.0, "batch_reward": 0.7290122648477554, "critic_loss": 1.4736353358626366, "actor_loss": -76.17489642333985, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.163026094436646, "step": 28000}
{"episode_reward": 853.9740121731904, "episode": 29.0, "batch_reward": 0.73329998087883, "critic_loss": 1.474036978662014, "actor_loss": -76.52371766662597, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.331793308258057, "step": 29000}
{"episode_reward": 855.7400590696809, "episode": 30.0, "batch_reward": 0.737378444314003, "critic_loss": 1.4684606246352196, "actor_loss": -76.57693734741211, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.70011806488037, "step": 30000}
{"episode_reward": 862.7269443379042, "episode": 31.0, "batch_reward": 0.7429866395592689, "critic_loss": 1.4531381224989892, "actor_loss": -76.62549435424805, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 44.81026554107666, "step": 31000}
{"episode_reward": 891.6028581078233, "episode": 32.0, "batch_reward": 0.7443590152859688, "critic_loss": 1.4299862291812897, "actor_loss": -76.72903210449219, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.33793044090271, "step": 32000}
{"episode_reward": 842.109885438725, "episode": 33.0, "batch_reward": 0.7510295183062553, "critic_loss": 1.3334791577458383, "actor_loss": -76.98985586547852, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.112241506576538, "step": 33000}
{"episode_reward": 877.6411220928593, "episode": 34.0, "batch_reward": 0.7511265051364898, "critic_loss": 1.4660498256087302, "actor_loss": -76.97877418518067, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.31869411468506, "step": 34000}
{"episode_reward": 732.55657363768, "episode": 35.0, "batch_reward": 0.753464509665966, "critic_loss": 1.3029602402448655, "actor_loss": -76.93003012084961, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.369839906692505, "step": 35000}
{"episode_reward": 854.0396475242278, "episode": 36.0, "batch_reward": 0.7561039183735847, "critic_loss": 1.3118909937143326, "actor_loss": -77.30199177551269, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.521159410476685, "step": 36000}
{"episode_reward": 843.5999784113035, "episode": 37.0, "batch_reward": 0.7590665992498398, "critic_loss": 1.2758564553260803, "actor_loss": -77.27243397521973, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.484783172607422, "step": 37000}
{"episode_reward": 862.2323159996639, "episode": 38.0, "batch_reward": 0.7578975963592529, "critic_loss": 1.2898518129587173, "actor_loss": -77.63324919128418, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.87427067756653, "step": 38000}
{"episode_reward": 838.9550970255151, "episode": 39.0, "batch_reward": 0.7633054066896439, "critic_loss": 1.1881630413532258, "actor_loss": -77.90045443725586, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.6686429977417, "step": 39000}
{"episode_reward": 876.2316429613975, "episode": 40.0, "batch_reward": 0.7633621254563332, "critic_loss": 1.28378725284338, "actor_loss": -77.95559352111816, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.68724775314331, "step": 40000}
{"episode_reward": 735.4591158649795, "episode": 41.0, "batch_reward": 0.7638017519116401, "critic_loss": 1.2002952480912208, "actor_loss": -77.62905207824707, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.759674072265625, "step": 41000}
{"episode_reward": 860.3744490151814, "episode": 42.0, "batch_reward": 0.7680119650363922, "critic_loss": 1.1856526429653167, "actor_loss": -77.78183743286132, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.62511682510376, "step": 42000}
{"episode_reward": 869.0001576220031, "episode": 43.0, "batch_reward": 0.7690170553922653, "critic_loss": 1.2061531082987786, "actor_loss": -78.05927626037598, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.507093906402588, "step": 43000}
{"episode_reward": 843.5321159819124, "episode": 44.0, "batch_reward": 0.7692766807079315, "critic_loss": 1.1778453764915466, "actor_loss": -77.70872380065919, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.003725051879883, "step": 44000}
{"episode_reward": 851.7304706999067, "episode": 45.0, "batch_reward": 0.7740756752490997, "critic_loss": 1.1344733064770698, "actor_loss": -77.86893952941895, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.371851205825806, "step": 45000}
{"episode_reward": 849.012546229791, "episode": 46.0, "batch_reward": 0.7733268119096756, "critic_loss": 1.1307342359423638, "actor_loss": -78.00461813354492, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.876286268234253, "step": 46000}
{"episode_reward": 860.7227896468993, "episode": 47.0, "batch_reward": 0.7772815309762955, "critic_loss": 1.1515143772363663, "actor_loss": -77.82446963500976, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.6391499042511, "step": 47000}
{"episode_reward": 872.5854841339107, "episode": 48.0, "batch_reward": 0.7791047315001488, "critic_loss": 1.036916053712368, "actor_loss": -78.15279852294921, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 25.471747636795044, "step": 48000}
{"episode_reward": 898.7536194878777, "episode": 49.0, "batch_reward": 0.7804147900342941, "critic_loss": 1.176179345756769, "actor_loss": -78.19971466064453, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 25.14620614051819, "step": 49000}
{"episode_reward": 776.4347585725058, "episode": 50.0, "batch_reward": 0.7802110165953636, "critic_loss": 1.1424164204001426, "actor_loss": -77.92131327819824, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.908820629119873, "step": 50000}
{"episode_reward": 834.8895784368052, "episode": 51.0, "batch_reward": 0.7809010741710662, "critic_loss": 1.1577462449669838, "actor_loss": -78.33130152893067, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 39.92865705490112, "step": 51000}
{"episode_reward": 806.5356249582537, "episode": 52.0, "batch_reward": 0.7835652655959129, "critic_loss": 1.1367749596238137, "actor_loss": -78.12414668273925, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.916837215423584, "step": 52000}
{"episode_reward": 879.8105302217833, "episode": 53.0, "batch_reward": 0.7839899317026139, "critic_loss": 1.1544118490219115, "actor_loss": -78.26514633178711, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.015002012252808, "step": 53000}
{"episode_reward": 878.6597290584982, "episode": 54.0, "batch_reward": 0.7866784953474999, "critic_loss": 1.0961324462890625, "actor_loss": -78.60502474975586, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.89787268638611, "step": 54000}
{"episode_reward": 875.9127409058784, "episode": 55.0, "batch_reward": 0.7881158538460732, "critic_loss": 1.1018164936900139, "actor_loss": -78.75468894958496, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.440682649612427, "step": 55000}
{"episode_reward": 895.6808781134397, "episode": 56.0, "batch_reward": 0.7880853007435799, "critic_loss": 1.130316405892372, "actor_loss": -78.62578587341308, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.289021730422974, "step": 56000}
{"episode_reward": 820.2608751939478, "episode": 57.0, "batch_reward": 0.7897348053455353, "critic_loss": 1.1402364985346793, "actor_loss": -78.61297868347168, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.247838497161865, "step": 57000}
{"episode_reward": 842.7116966625284, "episode": 58.0, "batch_reward": 0.7930831799507141, "critic_loss": 1.0621432398557662, "actor_loss": -78.81041773986816, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.81160807609558, "step": 58000}
{"episode_reward": 898.5592489672945, "episode": 59.0, "batch_reward": 0.791066812157631, "critic_loss": 1.1611480178236961, "actor_loss": -79.04815872192383, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.40959095954895, "step": 59000}
{"episode_reward": 789.9278949746292, "episode": 60.0, "batch_reward": 0.7948212630152702, "critic_loss": 1.1237689587771893, "actor_loss": -78.81778984069824, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.962763786315918, "step": 60000}
{"episode_reward": 877.3888017339804, "episode": 61.0, "batch_reward": 0.7943737977147103, "critic_loss": 1.1186169873476028, "actor_loss": -78.75385626220704, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.11908483505249, "step": 61000}
{"episode_reward": 852.3625807953717, "episode": 62.0, "batch_reward": 0.7951633148789405, "critic_loss": 1.1270069906115532, "actor_loss": -78.76215582275391, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.428887844085693, "step": 62000}
{"episode_reward": 881.4787166046397, "episode": 63.0, "batch_reward": 0.7949829329252243, "critic_loss": 1.1643046087920665, "actor_loss": -78.81197338867187, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.03213620185852, "step": 63000}
{"episode_reward": 800.8262774645336, "episode": 64.0, "batch_reward": 0.7986876281499863, "critic_loss": 1.0964338469803334, "actor_loss": -78.97335391235352, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.032405376434326, "step": 64000}
{"episode_reward": 880.7170349655306, "episode": 65.0, "batch_reward": 0.7983444104790688, "critic_loss": 1.0918935865461827, "actor_loss": -78.98517068481445, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.439651250839233, "step": 65000}
{"episode_reward": 862.3877030725588, "episode": 66.0, "batch_reward": 0.7995633026957512, "critic_loss": 1.152579885095358, "actor_loss": -79.15801013183594, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.81751298904419, "step": 66000}
{"episode_reward": 884.1085267607162, "episode": 67.0, "batch_reward": 0.8006795062422752, "critic_loss": 1.1160201155245304, "actor_loss": -79.11733959960938, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.55203604698181, "step": 67000}
{"episode_reward": 864.6749890550338, "episode": 68.0, "batch_reward": 0.8024265821576119, "critic_loss": 1.1067706831693649, "actor_loss": -79.23140301513672, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.34714674949646, "step": 68000}
{"episode_reward": 868.8645297190969, "episode": 69.0, "batch_reward": 0.8044776725769043, "critic_loss": 1.0957180435359477, "actor_loss": -79.16049728393554, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.423741340637207, "step": 69000}
{"episode_reward": 881.1131044407788, "episode": 70.0, "batch_reward": 0.8036052842140198, "critic_loss": 1.1371442372500897, "actor_loss": -79.24705192565918, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.04431939125061, "step": 70000}
{"episode_reward": 896.5402554251993, "episode": 71.0, "batch_reward": 0.8033657171130181, "critic_loss": 1.1818359072208404, "actor_loss": -79.17870741271973, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 46.383365869522095, "step": 71000}
{"episode_reward": 739.7071781427446, "episode": 72.0, "batch_reward": 0.8037257045507431, "critic_loss": 1.2784309985637665, "actor_loss": -79.32895362854003, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.322182178497314, "step": 72000}
{"episode_reward": 857.6288183723759, "episode": 73.0, "batch_reward": 0.8050224893093109, "critic_loss": 1.2254819445014, "actor_loss": -79.19902905273437, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.602157831192017, "step": 73000}
{"episode_reward": 884.573484788472, "episode": 74.0, "batch_reward": 0.8055456135272979, "critic_loss": 1.1904444397091865, "actor_loss": -79.1822956237793, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.44449734687805, "step": 74000}
{"episode_reward": 886.0231686305456, "episode": 75.0, "batch_reward": 0.8074457342624665, "critic_loss": 1.1127623842656613, "actor_loss": -79.68180473327637, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.029083728790283, "step": 75000}
{"episode_reward": 824.7954384058837, "episode": 76.0, "batch_reward": 0.8070053365230561, "critic_loss": 1.102455764979124, "actor_loss": -79.492453414917, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.1197247505188, "step": 76000}
{"episode_reward": 864.0839783548066, "episode": 77.0, "batch_reward": 0.8074700786471367, "critic_loss": 1.1268400675356387, "actor_loss": -79.45023260498047, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.045591592788696, "step": 77000}
{"episode_reward": 879.3501372329349, "episode": 78.0, "batch_reward": 0.8081581571698189, "critic_loss": 1.1178377275168896, "actor_loss": -79.43811422729492, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.02731728553772, "step": 78000}
{"episode_reward": 898.7193806228794, "episode": 79.0, "batch_reward": 0.81084614610672, "critic_loss": 1.0398654702603818, "actor_loss": -79.66420217895508, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.469143867492676, "step": 79000}
{"episode_reward": 900.1941339922688, "episode": 80.0, "batch_reward": 0.810483295917511, "critic_loss": 1.0984004905819893, "actor_loss": -79.7757322845459, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.756962776184082, "step": 80000}
{"episode_reward": 874.8912163954913, "episode": 81.0, "batch_reward": 0.8114272909164428, "critic_loss": 1.085532409220934, "actor_loss": -79.74008801269531, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.4725227355957, "step": 81000}
{"episode_reward": 881.5980178639502, "episode": 82.0, "batch_reward": 0.8111925513148308, "critic_loss": 1.0984753334224224, "actor_loss": -79.64650494384766, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.14177417755127, "step": 82000}
{"episode_reward": 805.8838705689938, "episode": 83.0, "batch_reward": 0.8131565460562706, "critic_loss": 1.084835597395897, "actor_loss": -79.88368704223633, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.331908226013184, "step": 83000}
{"episode_reward": 909.40508370082, "episode": 84.0, "batch_reward": 0.8140564207434654, "critic_loss": 1.0485190897881984, "actor_loss": -79.78044415283203, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.497876167297363, "step": 84000}
{"episode_reward": 904.5247446630909, "episode": 85.0, "batch_reward": 0.8157384048104286, "critic_loss": 1.0770830079317093, "actor_loss": -80.03451585388184, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.54290008544922, "step": 85000}
{"episode_reward": 831.1570429668919, "episode": 86.0, "batch_reward": 0.8148574090600014, "critic_loss": 1.0140894822776318, "actor_loss": -79.94986476135254, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.999372243881226, "step": 86000}
{"episode_reward": 870.203108152148, "episode": 87.0, "batch_reward": 0.8167609862685203, "critic_loss": 1.0766398370862007, "actor_loss": -79.98649864196777, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.595874547958374, "step": 87000}
{"episode_reward": 880.7460191263099, "episode": 88.0, "batch_reward": 0.8153921177387238, "critic_loss": 1.0191576347351075, "actor_loss": -79.94763777160645, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.498074531555176, "step": 88000}
{"episode_reward": 897.6496947506847, "episode": 89.0, "batch_reward": 0.8187312033176423, "critic_loss": 1.028703266173601, "actor_loss": -80.14066592407227, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 26.352808475494385, "step": 89000}
{"episode_reward": 846.6192632864673, "episode": 90.0, "batch_reward": 0.8177673819661141, "critic_loss": 1.082809578895569, "actor_loss": -79.8470816040039, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.67734670639038, "step": 90000}
{"episode_reward": 845.3985158007919, "episode": 91.0, "batch_reward": 0.8165449405908585, "critic_loss": 1.0473688603937625, "actor_loss": -80.03390582275391, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.78598356246948, "step": 91000}
{"episode_reward": 797.3001362926236, "episode": 92.0, "batch_reward": 0.8164713742136955, "critic_loss": 1.0319726747870446, "actor_loss": -79.98999252319337, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 25.532756805419922, "step": 92000}
{"episode_reward": 887.821568183619, "episode": 93.0, "batch_reward": 0.8166392263174057, "critic_loss": 1.0910187150537967, "actor_loss": -80.08413067626954, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.720439672470093, "step": 93000}
{"episode_reward": 857.026552164783, "episode": 94.0, "batch_reward": 0.818874997138977, "critic_loss": 1.0950791004896163, "actor_loss": -80.02759580993653, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.945420503616333, "step": 94000}
{"episode_reward": 852.1069357303738, "episode": 95.0, "batch_reward": 0.8185815336704254, "critic_loss": 1.0630253701210022, "actor_loss": -80.18986727905273, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.70544695854187, "step": 95000}
{"episode_reward": 872.8967291979075, "episode": 96.0, "batch_reward": 0.8205626555681229, "critic_loss": 1.1058182688355447, "actor_loss": -80.21987937927246, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.693676471710205, "step": 96000}
{"episode_reward": 885.1876893309585, "episode": 97.0, "batch_reward": 0.8194247151613235, "critic_loss": 1.078275010317564, "actor_loss": -80.17315574645995, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.208967924118042, "step": 97000}
{"episode_reward": 807.6037617236916, "episode": 98.0, "batch_reward": 0.8210633630752564, "critic_loss": 1.0696583041548728, "actor_loss": -80.24032221984864, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.485801219940186, "step": 98000}
{"episode_reward": 880.5297466204071, "episode": 99.0, "batch_reward": 0.8219411609172821, "critic_loss": 1.051191569685936, "actor_loss": -80.26432234191894, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.139764308929443, "step": 99000}
{"episode_reward": 881.9010795254652, "episode": 100.0, "batch_reward": 0.8213994403481484, "critic_loss": 1.0291217930614949, "actor_loss": -80.3496314239502, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.661946296691895, "step": 100000}
{"episode_reward": 859.2901148280101, "episode": 101.0, "batch_reward": 0.8231673675179482, "critic_loss": 0.9931503577232361, "actor_loss": -80.27219662475586, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.91128754615784, "step": 101000}
{"episode_reward": 866.7740075985955, "episode": 102.0, "batch_reward": 0.8232703921198845, "critic_loss": 0.9781343643963337, "actor_loss": -80.42184924316406, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 25.604536056518555, "step": 102000}
{"episode_reward": 892.2680437028612, "episode": 103.0, "batch_reward": 0.8238606898188591, "critic_loss": 1.039540138244629, "actor_loss": -80.3956010131836, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.010282039642334, "step": 103000}
{"episode_reward": 906.1009932205728, "episode": 104.0, "batch_reward": 0.8250875388383865, "critic_loss": 1.011745328873396, "actor_loss": -80.57220443725586, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.264835357666016, "step": 104000}
{"episode_reward": 871.5606950682228, "episode": 105.0, "batch_reward": 0.823953608572483, "critic_loss": 1.0200654276907444, "actor_loss": -80.50537187194824, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.73781418800354, "step": 105000}
{"episode_reward": 896.7616929207427, "episode": 106.0, "batch_reward": 0.8242701420783997, "critic_loss": 0.9711544462144375, "actor_loss": -80.65288293457031, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.98854351043701, "step": 106000}
{"episode_reward": 892.6203695394814, "episode": 107.0, "batch_reward": 0.824643716096878, "critic_loss": 0.940427882373333, "actor_loss": -80.57029699707032, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.654807329177856, "step": 107000}
{"episode_reward": 868.0682272513142, "episode": 108.0, "batch_reward": 0.8259721390008926, "critic_loss": 0.9350436159074307, "actor_loss": -80.61098345947265, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.043707132339478, "step": 108000}
{"episode_reward": 873.9169323704006, "episode": 109.0, "batch_reward": 0.8265191559195518, "critic_loss": 0.9419330357909202, "actor_loss": -80.64233532714844, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.479773998260498, "step": 109000}
{"episode_reward": 874.9316529694731, "episode": 110.0, "batch_reward": 0.8267490000128747, "critic_loss": 0.9239729164838791, "actor_loss": -80.69073289489747, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.25999617576599, "step": 110000}
{"episode_reward": 869.7435938697989, "episode": 111.0, "batch_reward": 0.8268711648583412, "critic_loss": 0.9466225714981555, "actor_loss": -80.6936516571045, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.43263912200928, "step": 111000}
{"episode_reward": 801.2577854531186, "episode": 112.0, "batch_reward": 0.8259809428453445, "critic_loss": 0.958815286308527, "actor_loss": -80.72101513671875, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.894246339797974, "step": 112000}
{"episode_reward": 855.8721568368082, "episode": 113.0, "batch_reward": 0.8276636434197426, "critic_loss": 0.9466123862862587, "actor_loss": -80.69298182678223, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.420621633529663, "step": 113000}
{"episode_reward": 896.2483981537937, "episode": 114.0, "batch_reward": 0.8285516069531441, "critic_loss": 0.9690090003907681, "actor_loss": -80.82229391479493, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.31131601333618, "step": 114000}
{"episode_reward": 884.904654157722, "episode": 115.0, "batch_reward": 0.8287228467464447, "critic_loss": 0.9738427402377129, "actor_loss": -80.83064131164551, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.58199954032898, "step": 115000}
{"episode_reward": 907.252092745159, "episode": 116.0, "batch_reward": 0.8290417281985283, "critic_loss": 0.9508780978322029, "actor_loss": -80.86027084350586, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.822677850723267, "step": 116000}
{"episode_reward": 845.9300189070461, "episode": 117.0, "batch_reward": 0.8293749050498008, "critic_loss": 0.9276763612926007, "actor_loss": -80.81572312927246, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.411173343658447, "step": 117000}
{"episode_reward": 869.6053238317877, "episode": 118.0, "batch_reward": 0.8290908308029175, "critic_loss": 0.9920756140947342, "actor_loss": -80.81033171081543, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.636882543563843, "step": 118000}
{"episode_reward": 897.8054822928262, "episode": 119.0, "batch_reward": 0.8300001745820046, "critic_loss": 0.9773959543704986, "actor_loss": -80.84144493103027, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.181498527526855, "step": 119000}
{"episode_reward": 888.5066664809618, "episode": 120.0, "batch_reward": 0.8312564722895622, "critic_loss": 0.9673558275103569, "actor_loss": -81.02889796447754, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.523776054382324, "step": 120000}
{"episode_reward": 878.1577372585707, "episode": 121.0, "batch_reward": 0.8309225916266442, "critic_loss": 0.9569473080933094, "actor_loss": -80.90593647766113, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 39.82004451751709, "step": 121000}
{"episode_reward": 887.0675749969562, "episode": 122.0, "batch_reward": 0.8322162998318672, "critic_loss": 0.9368771232962608, "actor_loss": -80.97080529785157, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.005966186523438, "step": 122000}
{"episode_reward": 847.0313231377464, "episode": 123.0, "batch_reward": 0.8318115988969803, "critic_loss": 0.9896021414399147, "actor_loss": -80.96693553161622, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 25.320533990859985, "step": 123000}
{"episode_reward": 822.7681583151576, "episode": 124.0, "batch_reward": 0.8318155968189239, "critic_loss": 0.9843816601932048, "actor_loss": -80.96049348449706, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.3515625, "step": 124000}
{"episode_reward": 892.4011453496723, "episode": 125.0, "batch_reward": 0.8322871441841125, "critic_loss": 0.9072230059802532, "actor_loss": -81.09211883544921, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.134243726730347, "step": 125000}
{"episode_reward": 845.112697121984, "episode": 126.0, "batch_reward": 0.8327324333190917, "critic_loss": 0.9617621411681175, "actor_loss": -80.95505125427246, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.75610375404358, "step": 126000}
{"episode_reward": 848.0469819618506, "episode": 127.0, "batch_reward": 0.8323692405223846, "critic_loss": 0.9793093006014824, "actor_loss": -80.94823262023925, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.646190404891968, "step": 127000}
{"episode_reward": 895.8797397505718, "episode": 128.0, "batch_reward": 0.8326391025185585, "critic_loss": 0.9003673331439495, "actor_loss": -80.99751638793946, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.985382795333862, "step": 128000}
{"episode_reward": 861.5718967018538, "episode": 129.0, "batch_reward": 0.834009725689888, "critic_loss": 0.9255972439348698, "actor_loss": -81.04450073242188, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.569674253463745, "step": 129000}
{"episode_reward": 888.3100521188691, "episode": 130.0, "batch_reward": 0.8330631839036942, "critic_loss": 0.9447266343981028, "actor_loss": -80.93393615722657, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.754696369171143, "step": 130000}
{"episode_reward": 864.1063756044255, "episode": 131.0, "batch_reward": 0.8337102174758911, "critic_loss": 0.8913531149029732, "actor_loss": -80.82625135803222, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.30097317695618, "step": 131000}
{"episode_reward": 868.8611992057627, "episode": 132.0, "batch_reward": 0.8324823610186577, "critic_loss": 0.8883114636540413, "actor_loss": -80.89549615478515, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.011343240737915, "step": 132000}
{"episode_reward": 883.8819969514929, "episode": 133.0, "batch_reward": 0.8342202647328377, "critic_loss": 0.9040407403111458, "actor_loss": -81.07494850158692, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 25.044371128082275, "step": 133000}
{"episode_reward": 830.3058748238901, "episode": 134.0, "batch_reward": 0.8326189843416214, "critic_loss": 0.9119655940532684, "actor_loss": -81.05095626831054, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.575486421585083, "step": 134000}
{"episode_reward": 878.634586651644, "episode": 135.0, "batch_reward": 0.8330014551281929, "critic_loss": 0.8683869836330413, "actor_loss": -81.09928411865235, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.4337477684021, "step": 135000}
{"episode_reward": 862.2739224160649, "episode": 136.0, "batch_reward": 0.8340293847918511, "critic_loss": 0.886951284468174, "actor_loss": -81.14930276489258, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.04918360710144, "step": 136000}
{"episode_reward": 826.6619961008261, "episode": 137.0, "batch_reward": 0.8351016287207603, "critic_loss": 0.8956860248744488, "actor_loss": -81.11218925476074, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.841720819473267, "step": 137000}
{"episode_reward": 893.274003528713, "episode": 138.0, "batch_reward": 0.8348930026888848, "critic_loss": 0.8673304940760136, "actor_loss": -80.98201878356933, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.534839153289795, "step": 138000}
{"episode_reward": 823.9784426289967, "episode": 139.0, "batch_reward": 0.8350002774000168, "critic_loss": 0.8968670441806317, "actor_loss": -80.98212538146973, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.607406854629517, "step": 139000}
{"episode_reward": 859.1085539862935, "episode": 140.0, "batch_reward": 0.8355519289970398, "critic_loss": 0.8666491784155369, "actor_loss": -81.01637522888184, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.853967428207397, "step": 140000}
{"episode_reward": 892.0913846878071, "episode": 141.0, "batch_reward": 0.8351448120474816, "critic_loss": 0.8408811720609665, "actor_loss": -81.11191650390624, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.66595983505249, "step": 141000}
{"episode_reward": 892.8485837744142, "episode": 142.0, "batch_reward": 0.8352323229908943, "critic_loss": 0.8172787585854531, "actor_loss": -81.10183149719238, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.59656047821045, "step": 142000}
{"episode_reward": 879.5072826159067, "episode": 143.0, "batch_reward": 0.8363711603879929, "critic_loss": 0.832546454295516, "actor_loss": -81.27006051635742, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.302948236465454, "step": 143000}
{"episode_reward": 910.229644197048, "episode": 144.0, "batch_reward": 0.8366572113633156, "critic_loss": 0.8394286628067493, "actor_loss": -81.22153846740723, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.363937854766846, "step": 144000}
{"episode_reward": 838.2785703654598, "episode": 145.0, "batch_reward": 0.8366534701585769, "critic_loss": 0.8686494365036488, "actor_loss": -81.29445866394043, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.5632541179657, "step": 145000}
{"episode_reward": 812.3235656678911, "episode": 146.0, "batch_reward": 0.8361070570349693, "critic_loss": 0.862370381295681, "actor_loss": -81.0898547668457, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.79975438117981, "step": 146000}
{"episode_reward": 901.2659614461115, "episode": 147.0, "batch_reward": 0.8370240353345871, "critic_loss": 0.8866625473797322, "actor_loss": -81.12334976196288, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.672901391983032, "step": 147000}
{"episode_reward": 860.5146777093036, "episode": 148.0, "batch_reward": 0.836570333123207, "critic_loss": 0.8937350586354732, "actor_loss": -81.17861717224122, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.074708223342896, "step": 148000}
{"episode_reward": 872.9412168328473, "episode": 149.0, "batch_reward": 0.8371063647866249, "critic_loss": 0.889583460599184, "actor_loss": -81.1918865966797, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.147708415985107, "step": 149000}
{"episode_reward": 876.0700434414244, "episode": 150.0, "batch_reward": 0.837020427942276, "critic_loss": 0.8953054197728634, "actor_loss": -81.17807427978515, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "step": 150000}
