{"episode_reward": 0.0, "episode": 1.0, "duration": 22.026638984680176, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.9604933261871338, "step": 2000}
{"episode_reward": 632.427646246406, "episode": 3.0, "batch_reward": 0.34707115101154423, "critic_loss": 0.7537407815834012, "actor_loss": -69.49997861388208, "actor_target_entropy": -6.0, "alpha_value": 0.004365629073060301, "duration": 65.96788597106934, "step": 3000}
{"episode_reward": 501.0196085863737, "episode": 4.0, "batch_reward": 0.4178887951374054, "critic_loss": 1.234174136519432, "actor_loss": -72.24389628601074, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.316930294036865, "step": 4000}
{"episode_reward": 593.3516115045193, "episode": 5.0, "batch_reward": 0.4618251356780529, "critic_loss": 1.1612279205918312, "actor_loss": -73.46270666503906, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.10212206840515, "step": 5000}
{"episode_reward": 707.3004533246473, "episode": 6.0, "batch_reward": 0.5086579733192921, "critic_loss": 1.2640501657128334, "actor_loss": -74.45667750549316, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.14625573158264, "step": 6000}
{"episode_reward": 601.4858869910645, "episode": 7.0, "batch_reward": 0.5267609221041203, "critic_loss": 1.210386770606041, "actor_loss": -74.800396194458, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.044326066970825, "step": 7000}
{"episode_reward": 751.990912039643, "episode": 8.0, "batch_reward": 0.5634728294909, "critic_loss": 1.201668127477169, "actor_loss": -76.07925910949707, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.29869031906128, "step": 8000}
{"episode_reward": 827.3635031437836, "episode": 9.0, "batch_reward": 0.5957874784171582, "critic_loss": 1.2669054570794105, "actor_loss": -77.26236828613281, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.197084426879883, "step": 9000}
{"episode_reward": 815.7450407551391, "episode": 10.0, "batch_reward": 0.6220012681484223, "critic_loss": 1.1484307010173798, "actor_loss": -77.84780313110352, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.789193868637085, "step": 10000}
{"episode_reward": 865.670846040584, "episode": 11.0, "batch_reward": 0.6406313781738281, "critic_loss": 1.2151445950865745, "actor_loss": -78.64122984313966, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.978171825408936, "step": 11000}
{"episode_reward": 835.9049321615071, "episode": 12.0, "batch_reward": 0.6661020798683166, "critic_loss": 1.1313634397983552, "actor_loss": -79.05358235168457, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.632750511169434, "step": 12000}
{"episode_reward": 942.1335306456639, "episode": 13.0, "batch_reward": 0.6847811400294304, "critic_loss": 1.3883387038111688, "actor_loss": -79.97938116455079, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.918120861053467, "step": 13000}
{"episode_reward": 870.950922097311, "episode": 14.0, "batch_reward": 0.6894689104557037, "critic_loss": 1.8055409160852431, "actor_loss": -80.41666868591308, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.96750831604004, "step": 14000}
{"episode_reward": 424.6922837536075, "episode": 15.0, "batch_reward": 0.6529298423528671, "critic_loss": 1.8752921277284622, "actor_loss": -81.11391313171387, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.90131688117981, "step": 15000}
{"episode_reward": 43.64111764653133, "episode": 16.0, "batch_reward": 0.6112743017077445, "critic_loss": 1.755645808815956, "actor_loss": -81.18962004089356, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.59346604347229, "step": 16000}
{"episode_reward": 36.319885257746556, "episode": 17.0, "batch_reward": 0.5846081751286983, "critic_loss": 1.9597626596689224, "actor_loss": -81.52633250427246, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.728364944458008, "step": 17000}
{"episode_reward": 247.62288985253315, "episode": 18.0, "batch_reward": 0.5606173290014267, "critic_loss": 1.9988330221176147, "actor_loss": -81.20715222167969, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.0085608959198, "step": 18000}
{"episode_reward": 45.719829858784934, "episode": 19.0, "batch_reward": 0.5337161989808082, "critic_loss": 1.942691705584526, "actor_loss": -81.96774131774902, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.78086519241333, "step": 19000}
{"episode_reward": 68.0170046756846, "episode": 20.0, "batch_reward": 0.507550855666399, "critic_loss": 1.8885971761941909, "actor_loss": -81.29636381530761, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.63363003730774, "step": 20000}
{"episode_reward": 58.040550838679806, "episode": 21.0, "batch_reward": 0.48304210183024404, "critic_loss": 1.847859507918358, "actor_loss": -81.83385142517089, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 46.0369873046875, "step": 21000}
{"episode_reward": 28.275471363890478, "episode": 22.0, "batch_reward": 0.4671493358314037, "critic_loss": 1.9739495210647584, "actor_loss": -80.88109980773926, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 25.514177560806274, "step": 22000}
{"episode_reward": 138.95832913811066, "episode": 23.0, "batch_reward": 0.4478574182391167, "critic_loss": 1.897372731089592, "actor_loss": -81.4600435180664, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.533097743988037, "step": 23000}
{"episode_reward": 31.27254122808272, "episode": 24.0, "batch_reward": 0.4338845548927784, "critic_loss": 2.0294599746465685, "actor_loss": -81.47491023254395, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.562988996505737, "step": 24000}
{"episode_reward": 155.0464499797725, "episode": 25.0, "batch_reward": 0.42295672473311424, "critic_loss": 2.3103745036125183, "actor_loss": -79.83435330200196, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.801027059555054, "step": 25000}
{"episode_reward": 210.83439993488096, "episode": 26.0, "batch_reward": 0.41931729739904405, "critic_loss": 2.4996979076862336, "actor_loss": -79.91332377624512, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.893773317337036, "step": 26000}
{"episode_reward": 460.62121277144337, "episode": 27.0, "batch_reward": 0.4220871237516403, "critic_loss": 2.8018689794540403, "actor_loss": -79.44888806152343, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.16797971725464, "step": 27000}
{"episode_reward": 642.9607559119739, "episode": 28.0, "batch_reward": 0.43622812163829805, "critic_loss": 2.8801548047065735, "actor_loss": -79.2635305480957, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.53745412826538, "step": 28000}
{"episode_reward": 936.5541627958381, "episode": 29.0, "batch_reward": 0.45574640026688573, "critic_loss": 2.7820171678066252, "actor_loss": -79.78220152282715, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.770009517669678, "step": 29000}
{"episode_reward": 908.2210444501245, "episode": 30.0, "batch_reward": 0.4696045499145985, "critic_loss": 2.602888205051422, "actor_loss": -80.50998875427246, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.824880123138428, "step": 30000}
{"episode_reward": 892.6614272373488, "episode": 31.0, "batch_reward": 0.4851519304215908, "critic_loss": 2.4780099549293517, "actor_loss": -80.01064408874512, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.32127523422241, "step": 31000}
{"episode_reward": 940.7388038010521, "episode": 32.0, "batch_reward": 0.5013667367994785, "critic_loss": 2.3217171503305436, "actor_loss": -81.10165283203125, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.507555961608887, "step": 32000}
{"episode_reward": 927.5619839966353, "episode": 33.0, "batch_reward": 0.512785062611103, "critic_loss": 2.0091081428527833, "actor_loss": -81.06110363769531, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.658528089523315, "step": 33000}
{"episode_reward": 952.1558493890223, "episode": 34.0, "batch_reward": 0.5250599364042282, "critic_loss": 1.8535636528730393, "actor_loss": -81.1018605041504, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.86347246170044, "step": 34000}
{"episode_reward": 939.4836064127892, "episode": 35.0, "batch_reward": 0.538192750453949, "critic_loss": 1.726444222688675, "actor_loss": -81.92285054016114, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.481139659881592, "step": 35000}
{"episode_reward": 906.9591673659901, "episode": 36.0, "batch_reward": 0.54729646012187, "critic_loss": 1.558336534678936, "actor_loss": -81.51838903808594, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.731223821640015, "step": 36000}
{"episode_reward": 924.2103977064382, "episode": 37.0, "batch_reward": 0.5542851662933826, "critic_loss": 1.445438972234726, "actor_loss": -82.2812036895752, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.219631910324097, "step": 37000}
{"episode_reward": 742.6042881908215, "episode": 38.0, "batch_reward": 0.5545020287930965, "critic_loss": 1.2174311302304268, "actor_loss": -82.66021949768066, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.739826202392578, "step": 38000}
{"episode_reward": 528.9315588020045, "episode": 39.0, "batch_reward": 0.5605545444190502, "critic_loss": 1.0409314947128296, "actor_loss": -82.05832713317871, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.098007440567017, "step": 39000}
{"episode_reward": 866.919717711521, "episode": 40.0, "batch_reward": 0.5676940524578095, "critic_loss": 0.9358718178868294, "actor_loss": -81.04522888183594, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.07469630241394, "step": 40000}
{"episode_reward": 847.2990937376455, "episode": 41.0, "batch_reward": 0.5742714539170265, "critic_loss": 0.8935717377066612, "actor_loss": -81.08650173950195, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.52625632286072, "step": 41000}
{"episode_reward": 858.7208175684042, "episode": 42.0, "batch_reward": 0.5827612623572349, "critic_loss": 0.8562027135789394, "actor_loss": -81.12832974243165, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.638803482055664, "step": 42000}
{"episode_reward": 903.5552555336008, "episode": 43.0, "batch_reward": 0.5901783525645733, "critic_loss": 0.831995390176773, "actor_loss": -80.88914372253419, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.221925258636475, "step": 43000}
{"episode_reward": 891.3834668802629, "episode": 44.0, "batch_reward": 0.5977166587710381, "critic_loss": 0.8542974641621113, "actor_loss": -81.10107022094726, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.27895712852478, "step": 44000}
{"episode_reward": 905.1642184964193, "episode": 45.0, "batch_reward": 0.6044561005532741, "critic_loss": 0.8548778918683528, "actor_loss": -81.3396983947754, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.5871798992157, "step": 45000}
{"episode_reward": 899.9969512922464, "episode": 46.0, "batch_reward": 0.6123101927638054, "critic_loss": 0.8372949537336827, "actor_loss": -81.1428754272461, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.79050612449646, "step": 46000}
{"episode_reward": 963.4222487969544, "episode": 47.0, "batch_reward": 0.6186084154844284, "critic_loss": 0.8233607493937015, "actor_loss": -80.87060276794433, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.449302911758423, "step": 47000}
{"episode_reward": 921.9626943600397, "episode": 48.0, "batch_reward": 0.6266281006634236, "critic_loss": 0.7889119384884834, "actor_loss": -81.00678239440919, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.422402143478394, "step": 48000}
{"episode_reward": 957.5514887621139, "episode": 49.0, "batch_reward": 0.6224387922585011, "critic_loss": 0.7323546221852303, "actor_loss": -80.61933352661133, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.287068128585815, "step": 49000}
{"episode_reward": 12.06402475047578, "episode": 50.0, "batch_reward": 0.6163379022479057, "critic_loss": 0.7302701659798622, "actor_loss": -80.13977856445312, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.3242609500885, "step": 50000}
{"episode_reward": 877.4598118710334, "episode": 51.0, "batch_reward": 0.6258870998620987, "critic_loss": 0.7125002875328064, "actor_loss": -79.93606398010255, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.31878685951233, "step": 51000}
{"episode_reward": 963.3465062755923, "episode": 52.0, "batch_reward": 0.6310177597999572, "critic_loss": 0.7286761513054371, "actor_loss": -79.92429302978516, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.794459104537964, "step": 52000}
{"episode_reward": 953.096503351563, "episode": 53.0, "batch_reward": 0.638710476577282, "critic_loss": 0.7409311488866807, "actor_loss": -79.64430142211914, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.058836460113525, "step": 53000}
{"episode_reward": 942.0466670704105, "episode": 54.0, "batch_reward": 0.6434289700388909, "critic_loss": 0.729160884141922, "actor_loss": -79.72100297546386, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.7061550617218, "step": 54000}
{"episode_reward": 977.1876231543679, "episode": 55.0, "batch_reward": 0.6500310469865799, "critic_loss": 0.7160991336703301, "actor_loss": -79.85683450317383, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.665442943572998, "step": 55000}
{"episode_reward": 978.3221690033969, "episode": 56.0, "batch_reward": 0.6518462570905685, "critic_loss": 0.6802925683557988, "actor_loss": -79.56044668579102, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.19267201423645, "step": 56000}
{"episode_reward": 921.9085752561795, "episode": 57.0, "batch_reward": 0.6610134365558624, "critic_loss": 0.663870617121458, "actor_loss": -79.74725839233399, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.634839296340942, "step": 57000}
{"episode_reward": 937.1576060060822, "episode": 58.0, "batch_reward": 0.6635708978176117, "critic_loss": 0.6737267754971981, "actor_loss": -79.74531802368163, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.356141805648804, "step": 58000}
{"episode_reward": 962.2973388742244, "episode": 59.0, "batch_reward": 0.6705619441866875, "critic_loss": 0.639252104640007, "actor_loss": -79.79012908935547, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.29984712600708, "step": 59000}
{"episode_reward": 938.3118566478801, "episode": 60.0, "batch_reward": 0.6760386551022529, "critic_loss": 0.6460922341644764, "actor_loss": -79.96623321533202, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.368494749069214, "step": 60000}
{"episode_reward": 954.0178011694534, "episode": 61.0, "batch_reward": 0.6792646380066871, "critic_loss": 0.6330618302822113, "actor_loss": -80.16693725585938, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 46.49756455421448, "step": 61000}
{"episode_reward": 943.3149242199075, "episode": 62.0, "batch_reward": 0.6827588562965393, "critic_loss": 0.5964329018294812, "actor_loss": -80.47570074462891, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.76783800125122, "step": 62000}
{"episode_reward": 947.9106266572564, "episode": 63.0, "batch_reward": 0.6875587047934533, "critic_loss": 0.5908120948970318, "actor_loss": -80.24938508605958, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.15455436706543, "step": 63000}
{"episode_reward": 930.840903747693, "episode": 64.0, "batch_reward": 0.6915516341924668, "critic_loss": 0.587328051418066, "actor_loss": -80.01803108215331, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.00944757461548, "step": 64000}
{"episode_reward": 957.2590610438026, "episode": 65.0, "batch_reward": 0.6953310397267342, "critic_loss": 0.6524678013324737, "actor_loss": -80.26310792541504, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.910881519317627, "step": 65000}
{"episode_reward": 869.5323867067654, "episode": 66.0, "batch_reward": 0.7005435879230499, "critic_loss": 0.6231564121246338, "actor_loss": -80.44289219665528, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.16144561767578, "step": 66000}
{"episode_reward": 964.2182454857771, "episode": 67.0, "batch_reward": 0.7019713076353074, "critic_loss": 0.6248612352907658, "actor_loss": -80.6873804321289, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.688394784927368, "step": 67000}
{"episode_reward": 941.0885673952475, "episode": 68.0, "batch_reward": 0.7074839302301407, "critic_loss": 0.6394311075508594, "actor_loss": -80.5181863708496, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.676908254623413, "step": 68000}
{"episode_reward": 967.8519527041298, "episode": 69.0, "batch_reward": 0.7093427907824517, "critic_loss": 0.6149717229008674, "actor_loss": -80.80309483337402, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.57512855529785, "step": 69000}
{"episode_reward": 950.9974178238169, "episode": 70.0, "batch_reward": 0.7122716872692109, "critic_loss": 0.6093459022641182, "actor_loss": -80.97580555725098, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.50453233718872, "step": 70000}
{"episode_reward": 929.0853283641584, "episode": 71.0, "batch_reward": 0.7147037405967712, "critic_loss": 0.6129757862091064, "actor_loss": -80.99001168823243, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.573227882385254, "step": 71000}
{"episode_reward": 790.9281962553202, "episode": 72.0, "batch_reward": 0.7170294690728187, "critic_loss": 0.5946405053287744, "actor_loss": -80.85617279052734, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.209867000579834, "step": 72000}
{"episode_reward": 933.0656155424293, "episode": 73.0, "batch_reward": 0.7196223419904709, "critic_loss": 0.6119177809357643, "actor_loss": -80.98426911926269, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.508949279785156, "step": 73000}
{"episode_reward": 939.1230149150254, "episode": 74.0, "batch_reward": 0.7233072647452354, "critic_loss": 0.6047152821421623, "actor_loss": -80.94926916503906, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.68022131919861, "step": 74000}
{"episode_reward": 954.1305755754288, "episode": 75.0, "batch_reward": 0.7277776924371719, "critic_loss": 0.6220978388190269, "actor_loss": -80.91006175231934, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.008987426757812, "step": 75000}
{"episode_reward": 928.8778439162749, "episode": 76.0, "batch_reward": 0.7290776580572128, "critic_loss": 0.59244554489851, "actor_loss": -80.95670870971679, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.492257118225098, "step": 76000}
{"episode_reward": 926.7870631106645, "episode": 77.0, "batch_reward": 0.731511823296547, "critic_loss": 0.6114987369179725, "actor_loss": -81.23012771606446, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.121999740600586, "step": 77000}
{"episode_reward": 941.2832767946579, "episode": 78.0, "batch_reward": 0.7333334765434265, "critic_loss": 0.5588159953653813, "actor_loss": -81.2792237701416, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.02154779434204, "step": 78000}
{"episode_reward": 955.5750323398862, "episode": 79.0, "batch_reward": 0.7375671390295029, "critic_loss": 0.5712678597271442, "actor_loss": -81.2022611541748, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.142977237701416, "step": 79000}
{"episode_reward": 950.8148176055529, "episode": 80.0, "batch_reward": 0.7382758564352989, "critic_loss": 0.5294196290522813, "actor_loss": -81.19935893249512, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.862420082092285, "step": 80000}
{"episode_reward": 944.7719449873453, "episode": 81.0, "batch_reward": 0.7416482807397843, "critic_loss": 0.5278157255202531, "actor_loss": -81.24992002868652, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.924893856048584, "step": 81000}
{"episode_reward": 932.1023029794875, "episode": 82.0, "batch_reward": 0.7437642110586167, "critic_loss": 0.5335786721259356, "actor_loss": -81.21733110046387, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.602380990982056, "step": 82000}
{"episode_reward": 870.7478938385867, "episode": 83.0, "batch_reward": 0.7475406392812729, "critic_loss": 0.5591931282132864, "actor_loss": -81.57235722351074, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.394915342330933, "step": 83000}
{"episode_reward": 929.0706673444105, "episode": 84.0, "batch_reward": 0.7472589620947838, "critic_loss": 0.5621321224272251, "actor_loss": -81.49679821777343, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.57963514328003, "step": 84000}
{"episode_reward": 963.1654103604716, "episode": 85.0, "batch_reward": 0.7508977920413017, "critic_loss": 0.5980712797939778, "actor_loss": -81.5194042816162, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.979105234146118, "step": 85000}
{"episode_reward": 901.6064622285547, "episode": 86.0, "batch_reward": 0.7506220377087593, "critic_loss": 0.5647792925685644, "actor_loss": -81.62128442382813, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.521989583969116, "step": 86000}
{"episode_reward": 837.7876417616413, "episode": 87.0, "batch_reward": 0.7534547047019005, "critic_loss": 0.5830884327292443, "actor_loss": -81.66509120178223, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.794447898864746, "step": 87000}
{"episode_reward": 924.4042079301367, "episode": 88.0, "batch_reward": 0.757533173084259, "critic_loss": 0.5977461618930101, "actor_loss": -81.92751467895508, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.033748865127563, "step": 88000}
{"episode_reward": 957.1853116810311, "episode": 89.0, "batch_reward": 0.7589081636071205, "critic_loss": 0.6162732415646315, "actor_loss": -81.88856942749024, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.75992250442505, "step": 89000}
{"episode_reward": 892.4329676456787, "episode": 90.0, "batch_reward": 0.7587269161343575, "critic_loss": 0.6532985343337059, "actor_loss": -81.90638829040527, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.381219387054443, "step": 90000}
{"episode_reward": 827.3580207472279, "episode": 91.0, "batch_reward": 0.7585441825389863, "critic_loss": 0.6388329107910394, "actor_loss": -81.85929360961914, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.779884576797485, "step": 91000}
{"episode_reward": 921.1022574149893, "episode": 92.0, "batch_reward": 0.7622688454985619, "critic_loss": 0.6036365519165993, "actor_loss": -82.24725744628907, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.444490671157837, "step": 92000}
{"episode_reward": 966.2922373413681, "episode": 93.0, "batch_reward": 0.7635343230962753, "critic_loss": 0.5718999219238758, "actor_loss": -81.94991639709473, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.138622283935547, "step": 93000}
{"episode_reward": 888.3751537774305, "episode": 94.0, "batch_reward": 0.7676722044944764, "critic_loss": 0.5548636066168546, "actor_loss": -82.30931927490235, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.715696573257446, "step": 94000}
{"episode_reward": 926.9865496806092, "episode": 95.0, "batch_reward": 0.7656558410525321, "critic_loss": 0.5633443821966648, "actor_loss": -81.9061071472168, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.76671576499939, "step": 95000}
{"episode_reward": 857.800310243945, "episode": 96.0, "batch_reward": 0.7678338785767556, "critic_loss": 0.5548054506629705, "actor_loss": -82.32563215637207, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.186842441558838, "step": 96000}
{"episode_reward": 968.4268465566018, "episode": 97.0, "batch_reward": 0.7703948895335198, "critic_loss": 0.5720399609208107, "actor_loss": -82.06322102355956, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.128945350646973, "step": 97000}
{"episode_reward": 958.2819320514408, "episode": 98.0, "batch_reward": 0.7728011904358864, "critic_loss": 0.5572371052652597, "actor_loss": -81.9520712890625, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.52733302116394, "step": 98000}
{"episode_reward": 884.5968443046105, "episode": 99.0, "batch_reward": 0.7734116448760032, "critic_loss": 0.5302002760469914, "actor_loss": -82.23540159606934, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.592602014541626, "step": 99000}
{"episode_reward": 959.5695214186301, "episode": 100.0, "batch_reward": 0.7745912294983864, "critic_loss": 0.550703122228384, "actor_loss": -82.33804928588867, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.46745467185974, "step": 100000}
{"episode_reward": 899.9186696881345, "episode": 101.0, "batch_reward": 0.7758281008601189, "critic_loss": 0.5473566111624241, "actor_loss": -82.62105853271484, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.88554382324219, "step": 101000}
{"episode_reward": 953.6297407865046, "episode": 102.0, "batch_reward": 0.779074450314045, "critic_loss": 0.5554605096280575, "actor_loss": -82.4299881439209, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.137436866760254, "step": 102000}
{"episode_reward": 955.8926710708921, "episode": 103.0, "batch_reward": 0.7797865678071976, "critic_loss": 0.5394705605506896, "actor_loss": -82.76916772460937, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.94026231765747, "step": 103000}
{"episode_reward": 956.8134365037911, "episode": 104.0, "batch_reward": 0.7817810622453689, "critic_loss": 0.5098295898735523, "actor_loss": -82.50166902160645, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.356711626052856, "step": 104000}
{"episode_reward": 944.5122879752305, "episode": 105.0, "batch_reward": 0.782160879790783, "critic_loss": 0.5283538891673089, "actor_loss": -82.934263961792, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.057077407836914, "step": 105000}
{"episode_reward": 961.2622311896636, "episode": 106.0, "batch_reward": 0.7855134013295174, "critic_loss": 0.5060421405732631, "actor_loss": -82.76127125549317, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.23743772506714, "step": 106000}
{"episode_reward": 967.1820534941855, "episode": 107.0, "batch_reward": 0.7874607097506523, "critic_loss": 0.4981056566387415, "actor_loss": -82.66946212768555, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.64958095550537, "step": 107000}
{"episode_reward": 945.6280466739091, "episode": 108.0, "batch_reward": 0.787621179163456, "critic_loss": 0.5239124995470047, "actor_loss": -82.90762026977539, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.223432779312134, "step": 108000}
{"episode_reward": 971.8292925475987, "episode": 109.0, "batch_reward": 0.7898414772748947, "critic_loss": 0.5127511765658855, "actor_loss": -82.89541412353516, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.321004152297974, "step": 109000}
{"episode_reward": 971.9153388832034, "episode": 110.0, "batch_reward": 0.7917086712121963, "critic_loss": 0.5143427626192569, "actor_loss": -82.96843635559082, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.03179955482483, "step": 110000}
{"episode_reward": 924.4452293620658, "episode": 111.0, "batch_reward": 0.7928192846179009, "critic_loss": 0.4918473573923111, "actor_loss": -83.30494828796387, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 44.85469889640808, "step": 111000}
{"episode_reward": 920.3436842172965, "episode": 112.0, "batch_reward": 0.7921051160097122, "critic_loss": 0.5174696481227875, "actor_loss": -83.24798794555664, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.419853687286377, "step": 112000}
{"episode_reward": 910.1407104611235, "episode": 113.0, "batch_reward": 0.795531445145607, "critic_loss": 0.4818929574489593, "actor_loss": -83.59513366699218, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.392318725585938, "step": 113000}
{"episode_reward": 950.569830553623, "episode": 114.0, "batch_reward": 0.7957253568768501, "critic_loss": 0.4886515151709318, "actor_loss": -83.44086659240723, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.512458324432373, "step": 114000}
{"episode_reward": 953.9674333537976, "episode": 115.0, "batch_reward": 0.7981548005342484, "critic_loss": 0.5111132991462946, "actor_loss": -83.1243168182373, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.153424739837646, "step": 115000}
{"episode_reward": 947.5570984582017, "episode": 116.0, "batch_reward": 0.7989745270609856, "critic_loss": 0.4969731936305761, "actor_loss": -83.35349523925781, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.865140914916992, "step": 116000}
{"episode_reward": 933.739101609298, "episode": 117.0, "batch_reward": 0.8001636619567871, "critic_loss": 0.49740494737029073, "actor_loss": -83.41774932861328, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.532542943954468, "step": 117000}
{"episode_reward": 914.4385439036326, "episode": 118.0, "batch_reward": 0.8012303095459938, "critic_loss": 0.4927034146934748, "actor_loss": -83.56108569335937, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.785837650299072, "step": 118000}
{"episode_reward": 954.5474026487702, "episode": 119.0, "batch_reward": 0.8013532895445824, "critic_loss": 0.5077879096120596, "actor_loss": -83.48840115356445, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.86390781402588, "step": 119000}
{"episode_reward": 898.9036596840629, "episode": 120.0, "batch_reward": 0.804048577606678, "critic_loss": 0.4726775441467762, "actor_loss": -83.45254397583008, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.203673362731934, "step": 120000}
{"episode_reward": 967.9922726207442, "episode": 121.0, "batch_reward": 0.8047793160676956, "critic_loss": 0.459027010217309, "actor_loss": -83.49078703308105, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.24965739250183, "step": 121000}
{"episode_reward": 956.442265217889, "episode": 122.0, "batch_reward": 0.8075485538840294, "critic_loss": 0.4847704482376575, "actor_loss": -83.2077110748291, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.042627811431885, "step": 122000}
{"episode_reward": 914.4424064674695, "episode": 123.0, "batch_reward": 0.8057848719358445, "critic_loss": 0.5369313523769379, "actor_loss": -83.09095104980469, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.304235219955444, "step": 123000}
{"episode_reward": 927.1055352814212, "episode": 124.0, "batch_reward": 0.8085957991480828, "critic_loss": 0.48479586221277715, "actor_loss": -83.32054261779786, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.915159940719604, "step": 124000}
{"episode_reward": 966.9689175585523, "episode": 125.0, "batch_reward": 0.8097573970556259, "critic_loss": 0.49604388417303563, "actor_loss": -83.36319480895996, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.379542589187622, "step": 125000}
{"episode_reward": 895.8364559655398, "episode": 126.0, "batch_reward": 0.8096654757857322, "critic_loss": 0.5151676245480776, "actor_loss": -83.26150521850586, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.016619205474854, "step": 126000}
{"episode_reward": 945.0956529747366, "episode": 127.0, "batch_reward": 0.8096521851420403, "critic_loss": 0.5177405348122119, "actor_loss": -83.30580128479004, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 25.686593055725098, "step": 127000}
{"episode_reward": 948.4447030734447, "episode": 128.0, "batch_reward": 0.8117893994450569, "critic_loss": 0.523485815808177, "actor_loss": -83.62097970581054, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.865947008132935, "step": 128000}
{"episode_reward": 964.3876339190268, "episode": 129.0, "batch_reward": 0.8135210545659065, "critic_loss": 0.4797455242276192, "actor_loss": -83.62386975097657, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.296361207962036, "step": 129000}
{"episode_reward": 946.3464985443704, "episode": 130.0, "batch_reward": 0.8127209875583649, "critic_loss": 0.47089433947205545, "actor_loss": -83.45071739196777, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.663244247436523, "step": 130000}
{"episode_reward": 921.0492330428328, "episode": 131.0, "batch_reward": 0.813941227734089, "critic_loss": 0.4774836483746767, "actor_loss": -83.90484301757813, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 45.77752733230591, "step": 131000}
{"episode_reward": 929.1387513099173, "episode": 132.0, "batch_reward": 0.8143310367465019, "critic_loss": 0.44385709327459333, "actor_loss": -83.69405772399902, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.287137031555176, "step": 132000}
{"episode_reward": 943.8697664814972, "episode": 133.0, "batch_reward": 0.814997771680355, "critic_loss": 0.45876441010832786, "actor_loss": -83.70635632324219, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.718544244766235, "step": 133000}
{"episode_reward": 887.330256380272, "episode": 134.0, "batch_reward": 0.8159821962714195, "critic_loss": 0.4437066576182842, "actor_loss": -83.72855389404297, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.97820281982422, "step": 134000}
{"episode_reward": 942.5178481252693, "episode": 135.0, "batch_reward": 0.8164594700932503, "critic_loss": 0.42234735855460165, "actor_loss": -83.48998669433594, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.89452624320984, "step": 135000}
{"episode_reward": 958.1339474540393, "episode": 136.0, "batch_reward": 0.8191635189056397, "critic_loss": 0.4661594695448875, "actor_loss": -83.47477252197265, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.326006650924683, "step": 136000}
{"episode_reward": 919.4404176126815, "episode": 137.0, "batch_reward": 0.8191153139472008, "critic_loss": 0.4298400831222534, "actor_loss": -83.78361917114258, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.05182647705078, "step": 137000}
{"episode_reward": 960.9122739739234, "episode": 138.0, "batch_reward": 0.8212016091346741, "critic_loss": 0.4425798908472061, "actor_loss": -83.952814743042, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.233539581298828, "step": 138000}
{"episode_reward": 970.4138480257411, "episode": 139.0, "batch_reward": 0.8215313930511474, "critic_loss": 0.4537430822253227, "actor_loss": -84.10831462097168, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.148539543151855, "step": 139000}
{"episode_reward": 907.3118724715556, "episode": 140.0, "batch_reward": 0.8212634340524674, "critic_loss": 0.42794024392962454, "actor_loss": -84.05409381103516, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.49273419380188, "step": 140000}
{"episode_reward": 943.0818525022005, "episode": 141.0, "batch_reward": 0.8225902456045151, "critic_loss": 0.4072127351760864, "actor_loss": -83.71783840942383, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.69198274612427, "step": 141000}
{"episode_reward": 954.269489658118, "episode": 142.0, "batch_reward": 0.8227121560573578, "critic_loss": 0.43092235320806505, "actor_loss": -84.16765521240234, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.432376623153687, "step": 142000}
{"episode_reward": 904.330219629925, "episode": 143.0, "batch_reward": 0.8242845383286476, "critic_loss": 0.431437530875206, "actor_loss": -83.71768385314941, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.35991668701172, "step": 143000}
{"episode_reward": 933.4943660744392, "episode": 144.0, "batch_reward": 0.8260550499558449, "critic_loss": 0.44008404982089994, "actor_loss": -84.03677799987793, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.48321843147278, "step": 144000}
{"episode_reward": 897.6363411231207, "episode": 145.0, "batch_reward": 0.8252829984426499, "critic_loss": 0.431296196103096, "actor_loss": -83.72006103515625, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.097991466522217, "step": 145000}
{"episode_reward": 926.5655014304018, "episode": 146.0, "batch_reward": 0.8266808495521546, "critic_loss": 0.43172492226958276, "actor_loss": -84.0293493347168, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.33867883682251, "step": 146000}
{"episode_reward": 964.1643396084446, "episode": 147.0, "batch_reward": 0.8276250293850899, "critic_loss": 0.4387011155039072, "actor_loss": -83.86731182861328, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.847203969955444, "step": 147000}
{"episode_reward": 921.4754742914881, "episode": 148.0, "batch_reward": 0.8292231773734092, "critic_loss": 0.44027819418907166, "actor_loss": -84.06888667297363, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.95656132698059, "step": 148000}
{"episode_reward": 939.2993616822051, "episode": 149.0, "batch_reward": 0.8280884917974473, "critic_loss": 0.4386655561774969, "actor_loss": -84.25165864562989, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.986053228378296, "step": 149000}
{"episode_reward": 957.7802113986896, "episode": 150.0, "batch_reward": 0.8298331043124199, "critic_loss": 0.42539971044659614, "actor_loss": -84.22683656311035, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "step": 150000}
