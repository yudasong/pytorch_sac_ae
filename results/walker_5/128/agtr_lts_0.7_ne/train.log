{"episode_reward": 0.0, "episode": 1.0, "duration": 20.67622995376587, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.7872545719146729, "step": 2000}
{"episode_reward": 632.427646246406, "episode": 3.0, "batch_reward": 0.3597587697374379, "critic_loss": 0.8657671610299013, "actor_loss": -70.44400656075419, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.70152974128723, "step": 3000}
{"episode_reward": 616.6439713378297, "episode": 4.0, "batch_reward": 0.46630073300004005, "critic_loss": 2.159475555598736, "actor_loss": -73.50766705322266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.240763425827026, "step": 4000}
{"episode_reward": 715.6353185315587, "episode": 5.0, "batch_reward": 0.5245514626801014, "critic_loss": 2.190817330360413, "actor_loss": -74.88444618225098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.242754697799683, "step": 5000}
{"episode_reward": 779.7721651162823, "episode": 6.0, "batch_reward": 0.5676256459653377, "critic_loss": 2.440226521611214, "actor_loss": -76.02494421386719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27806043624878, "step": 6000}
{"episode_reward": 748.2247496498904, "episode": 7.0, "batch_reward": 0.6039294247925282, "critic_loss": 3.0635980476140974, "actor_loss": -76.90993942260742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.242618083953857, "step": 7000}
{"episode_reward": 818.2367341236275, "episode": 8.0, "batch_reward": 0.6386242086291313, "critic_loss": 2.4045801352858542, "actor_loss": -78.10558616638184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.285821437835693, "step": 8000}
{"episode_reward": 877.0534472791385, "episode": 9.0, "batch_reward": 0.6509438112378121, "critic_loss": 2.7106657005548476, "actor_loss": -78.62529930114746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2872416973114, "step": 9000}
{"episode_reward": 690.363477005149, "episode": 10.0, "batch_reward": 0.6680947068333626, "critic_loss": 2.007771137058735, "actor_loss": -78.85543067932129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26781988143921, "step": 10000}
{"episode_reward": 874.1928763030834, "episode": 11.0, "batch_reward": 0.6835232132673263, "critic_loss": 1.59440867292881, "actor_loss": -79.31961106872559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.557448387145996, "step": 11000}
{"episode_reward": 708.8428444836586, "episode": 12.0, "batch_reward": 0.6928327578902245, "critic_loss": 1.3459192469716073, "actor_loss": -79.23553936767578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23680567741394, "step": 12000}
{"episode_reward": 885.1055280391103, "episode": 13.0, "batch_reward": 0.7013849375844001, "critic_loss": 1.1532111836075782, "actor_loss": -79.09064370727539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.270870685577393, "step": 13000}
{"episode_reward": 799.7926929777898, "episode": 14.0, "batch_reward": 0.7054972558617592, "critic_loss": 1.0875695682168007, "actor_loss": -79.02392164611817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2766056060791, "step": 14000}
{"episode_reward": 562.9059900926643, "episode": 15.0, "batch_reward": 0.7027512489557266, "critic_loss": 1.1047491143345833, "actor_loss": -78.68008755493165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.262054681777954, "step": 15000}
{"episode_reward": 843.5463458825978, "episode": 16.0, "batch_reward": 0.7093855316638946, "critic_loss": 1.076854589343071, "actor_loss": -78.72016844177246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.240283966064453, "step": 16000}
{"episode_reward": 816.2490469568406, "episode": 17.0, "batch_reward": 0.7169975019693374, "critic_loss": 1.228821979343891, "actor_loss": -78.57716296386718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27637529373169, "step": 17000}
{"episode_reward": 702.9751408348092, "episode": 18.0, "batch_reward": 0.7191246789097786, "critic_loss": 1.3110764218568802, "actor_loss": -78.60435191345215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.284497022628784, "step": 18000}
{"episode_reward": 896.2959616415429, "episode": 19.0, "batch_reward": 0.7240663790702819, "critic_loss": 1.3117976061701775, "actor_loss": -78.53524502563477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24690079689026, "step": 19000}
{"episode_reward": 804.22585835907, "episode": 20.0, "batch_reward": 0.7292394958734513, "critic_loss": 1.3569132081866264, "actor_loss": -78.67927990722656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.270161628723145, "step": 20000}
{"episode_reward": 828.3370999860406, "episode": 21.0, "batch_reward": 0.734156971693039, "critic_loss": 1.3278007761836053, "actor_loss": -78.56384722900391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.52329754829407, "step": 21000}
{"episode_reward": 824.477457041101, "episode": 22.0, "batch_reward": 0.7387754899859429, "critic_loss": 1.318857812166214, "actor_loss": -78.75395535278321, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2482488155365, "step": 22000}
{"episode_reward": 836.9198585685839, "episode": 23.0, "batch_reward": 0.7430152844190597, "critic_loss": 1.2816869903206825, "actor_loss": -78.83088151550292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.275940895080566, "step": 23000}
{"episode_reward": 850.5962812194228, "episode": 24.0, "batch_reward": 0.7464233813285828, "critic_loss": 1.276797100007534, "actor_loss": -78.90451718139649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28025484085083, "step": 24000}
{"episode_reward": 859.2432663498572, "episode": 25.0, "batch_reward": 0.7533207466602325, "critic_loss": 1.2287738856077195, "actor_loss": -79.16871463012696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.255945920944214, "step": 25000}
{"episode_reward": 836.673687211502, "episode": 26.0, "batch_reward": 0.7529114419817925, "critic_loss": 1.1977370070815085, "actor_loss": -79.2060457611084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.280858278274536, "step": 26000}
{"episode_reward": 849.7375921227159, "episode": 27.0, "batch_reward": 0.7560488678216934, "critic_loss": 1.3097973702549934, "actor_loss": -79.26113694763184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.281397342681885, "step": 27000}
{"episode_reward": 780.3955798793497, "episode": 28.0, "batch_reward": 0.760695234298706, "critic_loss": 1.171433289349079, "actor_loss": -79.28701341247559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.270588874816895, "step": 28000}
{"episode_reward": 888.3681651865934, "episode": 29.0, "batch_reward": 0.763271018922329, "critic_loss": 1.2243672569990158, "actor_loss": -79.44578500366211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.295720100402832, "step": 29000}
{"episode_reward": 824.842708217639, "episode": 30.0, "batch_reward": 0.766204815030098, "critic_loss": 1.1432254366874695, "actor_loss": -79.53193829345703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30517339706421, "step": 30000}
{"episode_reward": 840.6669523770678, "episode": 31.0, "batch_reward": 0.770062687754631, "critic_loss": 1.1072889381051063, "actor_loss": -79.64794166564941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.727877378463745, "step": 31000}
{"episode_reward": 906.6678873152664, "episode": 32.0, "batch_reward": 0.7746473676562309, "critic_loss": 1.0543692739009858, "actor_loss": -79.8519701538086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.431347131729126, "step": 32000}
{"episode_reward": 882.5847261728343, "episode": 33.0, "batch_reward": 0.7781006826758384, "critic_loss": 1.0325444372296333, "actor_loss": -79.9398528137207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.216267585754395, "step": 33000}
{"episode_reward": 907.248414267202, "episode": 34.0, "batch_reward": 0.7820538114905358, "critic_loss": 1.046352883398533, "actor_loss": -80.12697737121582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.210901021957397, "step": 34000}
{"episode_reward": 869.6804583758802, "episode": 35.0, "batch_reward": 0.7834118081927299, "critic_loss": 1.0602922680079936, "actor_loss": -80.09835299682616, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27660083770752, "step": 35000}
{"episode_reward": 846.8237645656286, "episode": 36.0, "batch_reward": 0.7857417448163032, "critic_loss": 1.0403633008599282, "actor_loss": -80.2443002319336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.279391050338745, "step": 36000}
{"episode_reward": 869.1557374774159, "episode": 37.0, "batch_reward": 0.7882326960563659, "critic_loss": 1.0428608797490597, "actor_loss": -80.29682572937011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.280704975128174, "step": 37000}
{"episode_reward": 847.5889309310566, "episode": 38.0, "batch_reward": 0.7868472318053246, "critic_loss": 1.078751020669937, "actor_loss": -80.31145614624023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.278106451034546, "step": 38000}
{"episode_reward": 859.0118323748521, "episode": 39.0, "batch_reward": 0.7909175444245339, "critic_loss": 0.988338060349226, "actor_loss": -80.44634457397461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.280848264694214, "step": 39000}
{"episode_reward": 888.7876335043342, "episode": 40.0, "batch_reward": 0.7908324565887451, "critic_loss": 1.0091357148885727, "actor_loss": -80.43726062011719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.300143480300903, "step": 40000}
{"episode_reward": 834.0139823500183, "episode": 41.0, "batch_reward": 0.7934060385227203, "critic_loss": 0.8965853559970856, "actor_loss": -80.5519970550537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.6424286365509, "step": 41000}
{"episode_reward": 864.336509931048, "episode": 42.0, "batch_reward": 0.7976385980248452, "critic_loss": 0.8743155451118946, "actor_loss": -80.5682406463623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30434513092041, "step": 42000}
{"episode_reward": 897.7498663183628, "episode": 43.0, "batch_reward": 0.7989094167351722, "critic_loss": 0.8889254852235318, "actor_loss": -80.62756304931641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.307995557785034, "step": 43000}
{"episode_reward": 869.7344481564069, "episode": 44.0, "batch_reward": 0.7967532925009727, "critic_loss": 0.9405390972197056, "actor_loss": -80.49975587463379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.305607795715332, "step": 44000}
{"episode_reward": 794.7733656184406, "episode": 45.0, "batch_reward": 0.7997196954488754, "critic_loss": 0.9060604537129402, "actor_loss": -80.53983470153808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.298484802246094, "step": 45000}
{"episode_reward": 837.6031875703374, "episode": 46.0, "batch_reward": 0.8014986772537231, "critic_loss": 0.8147553408443928, "actor_loss": -80.69615118408203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29610323905945, "step": 46000}
{"episode_reward": 885.1731960894181, "episode": 47.0, "batch_reward": 0.803527651488781, "critic_loss": 0.7863736112117767, "actor_loss": -80.75549259948731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.312289714813232, "step": 47000}
{"episode_reward": 895.0346265953882, "episode": 48.0, "batch_reward": 0.8045318725705147, "critic_loss": 0.7806599171459675, "actor_loss": -80.79109220886231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.272758722305298, "step": 48000}
{"episode_reward": 904.2069267166862, "episode": 49.0, "batch_reward": 0.8067028037309647, "critic_loss": 0.7987245807051658, "actor_loss": -80.86719711303711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2604660987854, "step": 49000}
{"episode_reward": 855.1713001131101, "episode": 50.0, "batch_reward": 0.8071033395528794, "critic_loss": 0.7651440959274769, "actor_loss": -80.92667878723145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28658390045166, "step": 50000}
{"episode_reward": 871.167395330607, "episode": 51.0, "batch_reward": 0.8078806976079941, "critic_loss": 0.7715911441147327, "actor_loss": -80.95705368041992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.58979272842407, "step": 51000}
{"episode_reward": 901.539696794927, "episode": 52.0, "batch_reward": 0.80995004093647, "critic_loss": 0.7477513090670109, "actor_loss": -81.04292112731933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32522201538086, "step": 52000}
{"episode_reward": 903.1712198091946, "episode": 53.0, "batch_reward": 0.8124374910593033, "critic_loss": 0.7270421704351901, "actor_loss": -81.11877436828614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31171727180481, "step": 53000}
{"episode_reward": 881.5749171617847, "episode": 54.0, "batch_reward": 0.8140212559103965, "critic_loss": 0.7192404415011406, "actor_loss": -81.20516812133789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.286283016204834, "step": 54000}
{"episode_reward": 904.9997750492303, "episode": 55.0, "batch_reward": 0.8144530788660049, "critic_loss": 0.7489286701977252, "actor_loss": -81.22114054870606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27817153930664, "step": 55000}
{"episode_reward": 855.6971652175455, "episode": 56.0, "batch_reward": 0.8138167245984077, "critic_loss": 0.7366104344129563, "actor_loss": -81.26947274780274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.294532537460327, "step": 56000}
{"episode_reward": 847.0981947091269, "episode": 57.0, "batch_reward": 0.8164770894050598, "critic_loss": 0.6990723707228899, "actor_loss": -81.29785708618164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.322468757629395, "step": 57000}
{"episode_reward": 875.2779857350984, "episode": 58.0, "batch_reward": 0.817388828098774, "critic_loss": 0.665418554842472, "actor_loss": -81.3799139099121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3214590549469, "step": 58000}
{"episode_reward": 889.7205914674279, "episode": 59.0, "batch_reward": 0.8172848961949348, "critic_loss": 0.7042252644598485, "actor_loss": -81.35593179321289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.282120943069458, "step": 59000}
{"episode_reward": 801.4030361546482, "episode": 60.0, "batch_reward": 0.8195661947131156, "critic_loss": 0.6199494630992413, "actor_loss": -81.45559182739258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.61430025100708, "step": 60000}
{"episode_reward": 864.4207269917661, "episode": 61.0, "batch_reward": 0.8190479801893235, "critic_loss": 0.6437264706343412, "actor_loss": -81.49637525939941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.5218141078949, "step": 61000}
{"episode_reward": 888.4654737066388, "episode": 62.0, "batch_reward": 0.820309739947319, "critic_loss": 0.6528698957711458, "actor_loss": -81.49963148498536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.275004386901855, "step": 62000}
{"episode_reward": 889.4777971797532, "episode": 63.0, "batch_reward": 0.8217700622081756, "critic_loss": 0.6816113795638085, "actor_loss": -81.5538889465332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.301671028137207, "step": 63000}
{"episode_reward": 870.2590105898093, "episode": 64.0, "batch_reward": 0.8238661956787109, "critic_loss": 0.6425938357710839, "actor_loss": -81.57415963745117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.314257860183716, "step": 64000}
{"episode_reward": 884.3148934363323, "episode": 65.0, "batch_reward": 0.8242078222036362, "critic_loss": 0.6670925631523132, "actor_loss": -81.58476937866212, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.303141832351685, "step": 65000}
{"episode_reward": 895.069843090841, "episode": 66.0, "batch_reward": 0.8244398052096367, "critic_loss": 0.6616499202847481, "actor_loss": -81.59668283081055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.302345991134644, "step": 66000}
{"episode_reward": 878.9339361219393, "episode": 67.0, "batch_reward": 0.8251597701907157, "critic_loss": 0.7074902676641941, "actor_loss": -81.62010725402833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2833354473114, "step": 67000}
{"episode_reward": 829.3013632243449, "episode": 68.0, "batch_reward": 0.825884783565998, "critic_loss": 0.6945292790532112, "actor_loss": -81.65673295593261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29901885986328, "step": 68000}
{"episode_reward": 890.6989158258514, "episode": 69.0, "batch_reward": 0.828246659219265, "critic_loss": 0.6810850769579411, "actor_loss": -81.71616563415527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.316657066345215, "step": 69000}
{"episode_reward": 890.7253323113525, "episode": 70.0, "batch_reward": 0.8269288641810417, "critic_loss": 0.7291227442920208, "actor_loss": -81.65214617919922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.310209274291992, "step": 70000}
{"episode_reward": 851.8358190495019, "episode": 71.0, "batch_reward": 0.8274365826845169, "critic_loss": 0.7460454281270504, "actor_loss": -81.68923092651367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.64747619628906, "step": 71000}
{"episode_reward": 797.8689345753837, "episode": 72.0, "batch_reward": 0.8269568662047386, "critic_loss": 0.6816859147250652, "actor_loss": -81.64576849365234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2753005027771, "step": 72000}
{"episode_reward": 854.8242449925646, "episode": 73.0, "batch_reward": 0.8275984478592873, "critic_loss": 0.6998691684007645, "actor_loss": -81.64570704650879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.256941080093384, "step": 73000}
{"episode_reward": 865.5094450636817, "episode": 74.0, "batch_reward": 0.8289717336297036, "critic_loss": 0.7166683632433415, "actor_loss": -81.75402545166015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.290659427642822, "step": 74000}
{"episode_reward": 901.3026960539532, "episode": 75.0, "batch_reward": 0.8301861450076103, "critic_loss": 0.7130867875814438, "actor_loss": -81.68342221069337, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29181218147278, "step": 75000}
{"episode_reward": 867.2955316995261, "episode": 76.0, "batch_reward": 0.8277044075727463, "critic_loss": 0.7570250850617886, "actor_loss": -81.65551884460449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2653591632843, "step": 76000}
{"episode_reward": 816.7233874968346, "episode": 77.0, "batch_reward": 0.8288783731460572, "critic_loss": 0.7911366681754589, "actor_loss": -81.68618118286133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.260189056396484, "step": 77000}
{"episode_reward": 846.567119987991, "episode": 78.0, "batch_reward": 0.8291806135177612, "critic_loss": 0.8154602549672126, "actor_loss": -81.6782811279297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.297951698303223, "step": 78000}
{"episode_reward": 875.0736340811076, "episode": 79.0, "batch_reward": 0.8304758751988411, "critic_loss": 0.8074686259031296, "actor_loss": -81.711532913208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.291922092437744, "step": 79000}
{"episode_reward": 903.7040225608687, "episode": 80.0, "batch_reward": 0.8316847176551819, "critic_loss": 0.7731385367810726, "actor_loss": -81.71784773254394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.308934211730957, "step": 80000}
{"episode_reward": 896.5743354453235, "episode": 81.0, "batch_reward": 0.831057770371437, "critic_loss": 0.7959990679323673, "actor_loss": -81.72645561218262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.58476185798645, "step": 81000}
{"episode_reward": 887.7317478652691, "episode": 82.0, "batch_reward": 0.8321845650672912, "critic_loss": 0.8333908996880054, "actor_loss": -81.76802210998535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26839017868042, "step": 82000}
{"episode_reward": 830.0921616219725, "episode": 83.0, "batch_reward": 0.8336923034787178, "critic_loss": 0.8183903086185456, "actor_loss": -81.78312466430664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.276698350906372, "step": 83000}
{"episode_reward": 871.0834836801216, "episode": 84.0, "batch_reward": 0.8332733077406883, "critic_loss": 0.8090965856611728, "actor_loss": -81.8275079498291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29270052909851, "step": 84000}
{"episode_reward": 898.000263386606, "episode": 85.0, "batch_reward": 0.8338210903406144, "critic_loss": 0.807478161394596, "actor_loss": -81.84951890563966, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.290600061416626, "step": 85000}
{"episode_reward": 847.4740652162259, "episode": 86.0, "batch_reward": 0.8332271021008492, "critic_loss": 0.8226161068677902, "actor_loss": -81.8030099029541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30537176132202, "step": 86000}
{"episode_reward": 772.9474056213888, "episode": 87.0, "batch_reward": 0.8340229771733284, "critic_loss": 0.7961262811273336, "actor_loss": -81.86498986816406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30235767364502, "step": 87000}
{"episode_reward": 899.1666813533172, "episode": 88.0, "batch_reward": 0.8345063431859017, "critic_loss": 0.8042618826031684, "actor_loss": -81.88970254516602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.321159601211548, "step": 88000}
{"episode_reward": 916.6867523186733, "episode": 89.0, "batch_reward": 0.8359924945235252, "critic_loss": 0.7975970046818256, "actor_loss": -81.87438822937011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.312809467315674, "step": 89000}
{"episode_reward": 856.0727071232918, "episode": 90.0, "batch_reward": 0.8346490053534508, "critic_loss": 0.8549601136147976, "actor_loss": -81.91614414978028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.321917057037354, "step": 90000}
{"episode_reward": 852.1176423899875, "episode": 91.0, "batch_reward": 0.8328903895616532, "critic_loss": 0.8280265678167343, "actor_loss": -81.81354676818847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.650153160095215, "step": 91000}
{"episode_reward": 692.7243497964275, "episode": 92.0, "batch_reward": 0.8345493547916413, "critic_loss": 0.7738569995164871, "actor_loss": -81.92324868774413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31486225128174, "step": 92000}
{"episode_reward": 881.6478843051574, "episode": 93.0, "batch_reward": 0.8342335341572762, "critic_loss": 0.7663695248663426, "actor_loss": -81.90678709411621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.274359703063965, "step": 93000}
{"episode_reward": 894.2925119541766, "episode": 94.0, "batch_reward": 0.8335561064481736, "critic_loss": 0.7749065592885017, "actor_loss": -81.95756005859376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.292523622512817, "step": 94000}
{"episode_reward": 848.0401923416246, "episode": 95.0, "batch_reward": 0.8346379148364067, "critic_loss": 0.7851613309681416, "actor_loss": -81.94562489318848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.311275720596313, "step": 95000}
{"episode_reward": 793.2981031606233, "episode": 96.0, "batch_reward": 0.8356521750688553, "critic_loss": 0.7648589279055595, "actor_loss": -81.9630055847168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.315977811813354, "step": 96000}
{"episode_reward": 914.7629837075557, "episode": 97.0, "batch_reward": 0.833939664542675, "critic_loss": 0.7713985961973667, "actor_loss": -81.9048430480957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32633662223816, "step": 97000}
{"episode_reward": 848.3315567360935, "episode": 98.0, "batch_reward": 0.8346852396130562, "critic_loss": 0.7857988024652004, "actor_loss": -81.94445169067383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31919765472412, "step": 98000}
{"episode_reward": 876.6030452773891, "episode": 99.0, "batch_reward": 0.8369401842355728, "critic_loss": 0.756310448050499, "actor_loss": -82.00696250915527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32009243965149, "step": 99000}
{"episode_reward": 895.7625422897061, "episode": 100.0, "batch_reward": 0.8365840238332748, "critic_loss": 0.7703946077972651, "actor_loss": -81.97117436218262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.325042963027954, "step": 100000}
{"episode_reward": 876.9545580597397, "episode": 101.0, "batch_reward": 0.838125251352787, "critic_loss": 0.8090800974965096, "actor_loss": -82.06868183898926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.64743757247925, "step": 101000}
{"episode_reward": 890.3529103189876, "episode": 102.0, "batch_reward": 0.8378920574188232, "critic_loss": 0.7872476298213005, "actor_loss": -81.98772842407226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.278616905212402, "step": 102000}
{"episode_reward": 896.9159572611748, "episode": 103.0, "batch_reward": 0.8392839524745941, "critic_loss": 0.7279565083086491, "actor_loss": -82.14035836791992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.304829120635986, "step": 103000}
{"episode_reward": 888.8433468802526, "episode": 104.0, "batch_reward": 0.8395631800293922, "critic_loss": 0.7405783638358117, "actor_loss": -82.07243673706054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.272149562835693, "step": 104000}
{"episode_reward": 892.3829493264319, "episode": 105.0, "batch_reward": 0.8397700185179711, "critic_loss": 0.7492123140394688, "actor_loss": -82.14251811218261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.321521282196045, "step": 105000}
{"episode_reward": 892.3512673050964, "episode": 106.0, "batch_reward": 0.8385365899801255, "critic_loss": 0.7325377490520477, "actor_loss": -82.07909658813476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28749990463257, "step": 106000}
{"episode_reward": 907.0436195362893, "episode": 107.0, "batch_reward": 0.8397745870947838, "critic_loss": 0.720609842017293, "actor_loss": -82.13152258300781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.309322118759155, "step": 107000}
{"episode_reward": 893.7884356898825, "episode": 108.0, "batch_reward": 0.8405228726267815, "critic_loss": 0.71200315746665, "actor_loss": -82.13138969421387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29667043685913, "step": 108000}
{"episode_reward": 908.6080172033519, "episode": 109.0, "batch_reward": 0.8409476697444915, "critic_loss": 0.7684653809070587, "actor_loss": -82.08249156188965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.304967403411865, "step": 109000}
{"episode_reward": 913.6007094209123, "episode": 110.0, "batch_reward": 0.8419448335170746, "critic_loss": 0.8147682012915611, "actor_loss": -82.17576789855957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.325917720794678, "step": 110000}
{"episode_reward": 859.082076783229, "episode": 111.0, "batch_reward": 0.8427747340202332, "critic_loss": 0.8235665675103664, "actor_loss": -82.26040080261231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.65650820732117, "step": 111000}
{"episode_reward": 884.6452565203112, "episode": 112.0, "batch_reward": 0.842450478553772, "critic_loss": 0.8456010439395905, "actor_loss": -82.19175947570801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.293081521987915, "step": 112000}
{"episode_reward": 833.3495612310398, "episode": 113.0, "batch_reward": 0.8443602802753448, "critic_loss": 0.8367803045809269, "actor_loss": -82.31022583007812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30397081375122, "step": 113000}
{"episode_reward": 899.1244423154521, "episode": 114.0, "batch_reward": 0.8433547617197037, "critic_loss": 0.8431269699037075, "actor_loss": -82.23893827819825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.314116954803467, "step": 114000}
{"episode_reward": 905.5281483714513, "episode": 115.0, "batch_reward": 0.8435304217338562, "critic_loss": 0.7823691368103027, "actor_loss": -82.24185818481445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28508448600769, "step": 115000}
{"episode_reward": 894.5741335758515, "episode": 116.0, "batch_reward": 0.8441554987430573, "critic_loss": 0.7877988779842854, "actor_loss": -82.29394187927247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29343008995056, "step": 116000}
{"episode_reward": 809.0391541848036, "episode": 117.0, "batch_reward": 0.8450484665036202, "critic_loss": 0.7989447646141052, "actor_loss": -82.31762188720703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29069447517395, "step": 117000}
{"episode_reward": 891.0838747314236, "episode": 118.0, "batch_reward": 0.8434495030641556, "critic_loss": 0.7839784606695175, "actor_loss": -82.3117251586914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.301183223724365, "step": 118000}
{"episode_reward": 907.2794346412377, "episode": 119.0, "batch_reward": 0.8443052914142609, "critic_loss": 0.7976832460165024, "actor_loss": -82.31509506225586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30655860900879, "step": 119000}
{"episode_reward": 879.3647927828571, "episode": 120.0, "batch_reward": 0.844892441034317, "critic_loss": 0.8085791344940663, "actor_loss": -82.29458403015137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.307512044906616, "step": 120000}
{"episode_reward": 924.1235758185742, "episode": 121.0, "batch_reward": 0.8465475358963013, "critic_loss": 0.792126401528716, "actor_loss": -82.34089643859863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.6135892868042, "step": 121000}
{"episode_reward": 894.9326452932982, "episode": 122.0, "batch_reward": 0.8466065871119499, "critic_loss": 0.8189506095349789, "actor_loss": -82.3385990600586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25700068473816, "step": 122000}
{"episode_reward": 843.8751365893062, "episode": 123.0, "batch_reward": 0.8456420499682427, "critic_loss": 0.8306616030335426, "actor_loss": -82.29366535949707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.286254167556763, "step": 123000}
{"episode_reward": 855.2927218131874, "episode": 124.0, "batch_reward": 0.8467849977612495, "critic_loss": 0.7992639354169369, "actor_loss": -82.37619253540039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30539894104004, "step": 124000}
{"episode_reward": 931.6377653555585, "episode": 125.0, "batch_reward": 0.846500652551651, "critic_loss": 0.793235871002078, "actor_loss": -82.37273558044434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.307623863220215, "step": 125000}
{"episode_reward": 868.4258910123905, "episode": 126.0, "batch_reward": 0.8467981536388397, "critic_loss": 0.7989443185925483, "actor_loss": -82.26883970642089, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.310868501663208, "step": 126000}
{"episode_reward": 873.8931879071379, "episode": 127.0, "batch_reward": 0.8462052580118179, "critic_loss": 0.8697664120942354, "actor_loss": -82.36701138305664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.300793170928955, "step": 127000}
{"episode_reward": 905.5570574782204, "episode": 128.0, "batch_reward": 0.848858059167862, "critic_loss": 0.8258519797325135, "actor_loss": -82.40881915283204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26351833343506, "step": 128000}
{"episode_reward": 899.801569828656, "episode": 129.0, "batch_reward": 0.8489978511929512, "critic_loss": 0.8447923722863198, "actor_loss": -82.44069917297364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.289035320281982, "step": 129000}
{"episode_reward": 879.2339647953527, "episode": 130.0, "batch_reward": 0.8483140831589698, "critic_loss": 0.7878335731029511, "actor_loss": -82.38720384216309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.294352531433105, "step": 130000}
{"episode_reward": 816.8512123872924, "episode": 131.0, "batch_reward": 0.8477364321351051, "critic_loss": 0.8346863461732864, "actor_loss": -82.45990936279297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.61860632896423, "step": 131000}
{"episode_reward": 839.1477138675464, "episode": 132.0, "batch_reward": 0.8471008391976357, "critic_loss": 0.8255813007354736, "actor_loss": -82.43534367370606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.299307823181152, "step": 132000}
{"episode_reward": 893.2385741278591, "episode": 133.0, "batch_reward": 0.8479544159173965, "critic_loss": 0.8217455729097128, "actor_loss": -82.36936393737793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.250187158584595, "step": 133000}
{"episode_reward": 856.2218138797999, "episode": 134.0, "batch_reward": 0.8483987305760383, "critic_loss": 0.8288145388066769, "actor_loss": -82.38100117492675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23156762123108, "step": 134000}
{"episode_reward": 897.3542292176888, "episode": 135.0, "batch_reward": 0.8480644710063935, "critic_loss": 0.8505464933216572, "actor_loss": -82.42920022583007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.261763334274292, "step": 135000}
{"episode_reward": 904.2397026578208, "episode": 136.0, "batch_reward": 0.8473696597218513, "critic_loss": 0.9205054984390736, "actor_loss": -82.39190034484864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.324307441711426, "step": 136000}
{"episode_reward": 723.316976955664, "episode": 137.0, "batch_reward": 0.8482753881812095, "critic_loss": 0.8634650727510452, "actor_loss": -82.37024880981446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31074547767639, "step": 137000}
{"episode_reward": 912.9654826662319, "episode": 138.0, "batch_reward": 0.8493098331689835, "critic_loss": 0.8823902321010828, "actor_loss": -82.45168086242676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.284770011901855, "step": 138000}
{"episode_reward": 879.6202214488468, "episode": 139.0, "batch_reward": 0.8488300042748451, "critic_loss": 0.8461963128149509, "actor_loss": -82.53188699340821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.288910150527954, "step": 139000}
{"episode_reward": 869.7417047741719, "episode": 140.0, "batch_reward": 0.8490462768673896, "critic_loss": 0.886444301828742, "actor_loss": -82.48054664611817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29962968826294, "step": 140000}
{"episode_reward": 871.7412413284646, "episode": 141.0, "batch_reward": 0.8477916592955589, "critic_loss": 0.8273918454647065, "actor_loss": -82.52505433654785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.60186505317688, "step": 141000}
{"episode_reward": 907.1232692534168, "episode": 142.0, "batch_reward": 0.8491243494749069, "critic_loss": 0.8390747502595186, "actor_loss": -82.5334651184082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.277039051055908, "step": 142000}
{"episode_reward": 843.0009741277823, "episode": 143.0, "batch_reward": 0.8504917378425598, "critic_loss": 0.8406070874780417, "actor_loss": -82.49413244628906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.265215158462524, "step": 143000}
{"episode_reward": 895.0885334472479, "episode": 144.0, "batch_reward": 0.8491386676430702, "critic_loss": 0.8481226065009833, "actor_loss": -82.53627958679199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.31978178024292, "step": 144000}
{"episode_reward": 797.5270730778552, "episode": 145.0, "batch_reward": 0.848866394519806, "critic_loss": 0.8574343931972981, "actor_loss": -82.39251329040528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.291694402694702, "step": 145000}
{"episode_reward": 858.1800405714796, "episode": 146.0, "batch_reward": 0.8498599927425384, "critic_loss": 0.808750779658556, "actor_loss": -82.5341142730713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.309878826141357, "step": 146000}
{"episode_reward": 903.4979046325051, "episode": 147.0, "batch_reward": 0.8498405954837799, "critic_loss": 0.8686789291203022, "actor_loss": -82.58567501831055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.283730506896973, "step": 147000}
{"episode_reward": 874.6299516037816, "episode": 148.0, "batch_reward": 0.8504191515445709, "critic_loss": 0.836318215072155, "actor_loss": -82.61207971191406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25439953804016, "step": 148000}
{"episode_reward": 877.4246872879046, "episode": 149.0, "batch_reward": 0.8492459577918052, "critic_loss": 0.8371635844558477, "actor_loss": -82.540154006958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28540539741516, "step": 149000}
{"episode_reward": 902.157059945397, "episode": 150.0, "batch_reward": 0.851029573738575, "critic_loss": 0.8701155657768249, "actor_loss": -82.57424180603027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
