{"episode_reward": 0.0, "episode": 1.0, "duration": 20.500845193862915, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.787337303161621, "step": 2000}
{"episode_reward": 973.7241921866618, "episode": 3.0, "batch_reward": 0.5391971544350493, "critic_loss": 0.4870367845462616, "actor_loss": -88.02328333066625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.3428168296814, "step": 3000}
{"episode_reward": 937.76918238719, "episode": 4.0, "batch_reward": 0.6884694867134095, "critic_loss": 0.6747587037086487, "actor_loss": -92.03561167907715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.72141408920288, "step": 4000}
{"episode_reward": 949.1378490858636, "episode": 5.0, "batch_reward": 0.745505872964859, "critic_loss": 0.6316840784996748, "actor_loss": -92.97483535766601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.719295263290405, "step": 5000}
{"episode_reward": 935.3821783666014, "episode": 6.0, "batch_reward": 0.7837515717148781, "critic_loss": 0.5153240804821253, "actor_loss": -93.60466215515137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.715113162994385, "step": 6000}
{"episode_reward": 950.9320576832741, "episode": 7.0, "batch_reward": 0.8043808621764184, "critic_loss": 0.4069116095155478, "actor_loss": -93.79780853271484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.720125436782837, "step": 7000}
{"episode_reward": 922.8563021870563, "episode": 8.0, "batch_reward": 0.8251232372522355, "critic_loss": 0.33541372445225714, "actor_loss": -94.0692225036621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.715084314346313, "step": 8000}
{"episode_reward": 964.1008580641621, "episode": 9.0, "batch_reward": 0.8427739458084107, "critic_loss": 0.30254983021318915, "actor_loss": -94.50243788146973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.712544918060303, "step": 9000}
{"episode_reward": 959.1793551151108, "episode": 10.0, "batch_reward": 0.8567041435241699, "critic_loss": 0.25445763088762763, "actor_loss": -94.72000196838378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.719407320022583, "step": 10000}
{"episode_reward": 985.6402911094374, "episode": 11.0, "batch_reward": 0.8641204063892365, "critic_loss": 0.2849798011034727, "actor_loss": -94.84984062194825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.221375942230225, "step": 11000}
{"episode_reward": 946.3793523515271, "episode": 12.0, "batch_reward": 0.8754413636922836, "critic_loss": 0.2294998394474387, "actor_loss": -95.15335540771484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.70402240753174, "step": 12000}
{"episode_reward": 983.8758501868695, "episode": 13.0, "batch_reward": 0.8822737442851066, "critic_loss": 0.25799427342414855, "actor_loss": -95.3045993347168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.714418172836304, "step": 13000}
{"episode_reward": 962.9814367225817, "episode": 14.0, "batch_reward": 0.890343810737133, "critic_loss": 0.19676743936538696, "actor_loss": -95.51627755737304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.736578464508057, "step": 14000}
{"episode_reward": 974.9262302318626, "episode": 15.0, "batch_reward": 0.8959995591640473, "critic_loss": 0.20206719863414765, "actor_loss": -95.68999838256836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.751100540161133, "step": 15000}
{"episode_reward": 988.5373303588201, "episode": 16.0, "batch_reward": 0.9006592808961869, "critic_loss": 0.17367908663675188, "actor_loss": -95.76034930419922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.753320693969727, "step": 16000}
{"episode_reward": 985.6809127434266, "episode": 17.0, "batch_reward": 0.9052898477911949, "critic_loss": 0.1731146634966135, "actor_loss": -95.80737252807617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.728814363479614, "step": 17000}
{"episode_reward": 959.7903501094281, "episode": 18.0, "batch_reward": 0.9112163702845574, "critic_loss": 0.18864195618405938, "actor_loss": -96.02837516784668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.731662034988403, "step": 18000}
{"episode_reward": 984.3941378972493, "episode": 19.0, "batch_reward": 0.9121425245404243, "critic_loss": 0.1417016200274229, "actor_loss": -96.0397610321045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.728965520858765, "step": 19000}
{"episode_reward": 957.3995369797921, "episode": 20.0, "batch_reward": 0.915869396686554, "critic_loss": 0.12318708639964461, "actor_loss": -96.1552642364502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.739521980285645, "step": 20000}
{"episode_reward": 981.2662076616863, "episode": 21.0, "batch_reward": 0.9181231565475464, "critic_loss": 0.19725179264321924, "actor_loss": -96.07696089172363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.14750266075134, "step": 21000}
{"episode_reward": 941.7537466052478, "episode": 22.0, "batch_reward": 0.920493462562561, "critic_loss": 0.1617064769230783, "actor_loss": -96.17261465454102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.72513508796692, "step": 22000}
{"episode_reward": 955.758718038956, "episode": 23.0, "batch_reward": 0.9194707674384117, "critic_loss": 0.19073407305404544, "actor_loss": -96.10855038452148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.718765020370483, "step": 23000}
{"episode_reward": 933.7909659837313, "episode": 24.0, "batch_reward": 0.9180370147228241, "critic_loss": 0.22582033478096128, "actor_loss": -96.00796722412109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.72345471382141, "step": 24000}
{"episode_reward": 874.7681810664752, "episode": 25.0, "batch_reward": 0.9195783638358116, "critic_loss": 0.2376933523155749, "actor_loss": -96.02818933105469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.722601890563965, "step": 25000}
{"episode_reward": 945.7965703238968, "episode": 26.0, "batch_reward": 0.9166869331598282, "critic_loss": 0.2445102761685848, "actor_loss": -95.8791368560791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.71502709388733, "step": 26000}
{"episode_reward": 880.7253641750194, "episode": 27.0, "batch_reward": 0.9187491871118546, "critic_loss": 0.2504767962433398, "actor_loss": -95.8825676727295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.726690769195557, "step": 27000}
{"episode_reward": 935.9223840197089, "episode": 28.0, "batch_reward": 0.9185676284432411, "critic_loss": 0.26341744662076233, "actor_loss": -95.82152600097656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.722978353500366, "step": 28000}
{"episode_reward": 983.261194608409, "episode": 29.0, "batch_reward": 0.9221908305883407, "critic_loss": 0.2756422466337681, "actor_loss": -95.95167120361329, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.72842001914978, "step": 29000}
{"episode_reward": 962.5093452806273, "episode": 30.0, "batch_reward": 0.9225246223211289, "critic_loss": 0.25683580465614797, "actor_loss": -95.97789796447753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.750399351119995, "step": 30000}
{"episode_reward": 961.4527545145035, "episode": 31.0, "batch_reward": 0.9254425619244575, "critic_loss": 0.24378250074386595, "actor_loss": -96.00466130065918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.14600157737732, "step": 31000}
{"episode_reward": 989.449861412147, "episode": 32.0, "batch_reward": 0.9250313560962677, "critic_loss": 0.28086249738931657, "actor_loss": -95.99348765563965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.719398736953735, "step": 32000}
{"episode_reward": 911.9310104513884, "episode": 33.0, "batch_reward": 0.9259139769673348, "critic_loss": 0.28499861680716276, "actor_loss": -96.01509330749512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.73187780380249, "step": 33000}
{"episode_reward": 991.2258659401721, "episode": 34.0, "batch_reward": 0.9293622145652771, "critic_loss": 0.2632178301140666, "actor_loss": -96.08877687072754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.72788166999817, "step": 34000}
{"episode_reward": 982.749552165908, "episode": 35.0, "batch_reward": 0.9309731668829918, "critic_loss": 0.2533853894546628, "actor_loss": -96.1307204284668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.71609401702881, "step": 35000}
{"episode_reward": 962.5295220860324, "episode": 36.0, "batch_reward": 0.9296192800998688, "critic_loss": 0.2828809755593538, "actor_loss": -96.16611126708985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.720029592514038, "step": 36000}
{"episode_reward": 902.4084542562757, "episode": 37.0, "batch_reward": 0.9300435789823532, "critic_loss": 0.2556190103515983, "actor_loss": -96.13842070007324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.727014303207397, "step": 37000}
{"episode_reward": 932.0557944504468, "episode": 38.0, "batch_reward": 0.9269747459292412, "critic_loss": 0.24321575441211463, "actor_loss": -96.11163543701171, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.728346347808838, "step": 38000}
{"episode_reward": 864.716628917409, "episode": 39.0, "batch_reward": 0.9286070325374604, "critic_loss": 0.24592362528294326, "actor_loss": -96.17474620056153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.730244636535645, "step": 39000}
{"episode_reward": 972.6771989440914, "episode": 40.0, "batch_reward": 0.9276992273926735, "critic_loss": 0.23202537287771702, "actor_loss": -96.11935025024414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.725473403930664, "step": 40000}
{"episode_reward": 928.9958982218727, "episode": 41.0, "batch_reward": 0.9294467839598656, "critic_loss": 0.21632383882254363, "actor_loss": -96.1215676727295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.136295557022095, "step": 41000}
{"episode_reward": 961.1451731987585, "episode": 42.0, "batch_reward": 0.9308046969175339, "critic_loss": 0.23826634094119073, "actor_loss": -96.16497143554687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.758405447006226, "step": 42000}
{"episode_reward": 967.9217034134647, "episode": 43.0, "batch_reward": 0.931887688100338, "critic_loss": 0.23539873283728957, "actor_loss": -96.22268925476074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.746491193771362, "step": 43000}
{"episode_reward": 949.4960746432788, "episode": 44.0, "batch_reward": 0.9304114533662796, "critic_loss": 0.21281623753905296, "actor_loss": -96.13678065490723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.752159595489502, "step": 44000}
{"episode_reward": 974.5205728296106, "episode": 45.0, "batch_reward": 0.9316072120070458, "critic_loss": 0.2203023981899023, "actor_loss": -96.15370417785644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.740018129348755, "step": 45000}
{"episode_reward": 923.8368399389659, "episode": 46.0, "batch_reward": 0.9320950035452843, "critic_loss": 0.2490648075900972, "actor_loss": -96.17502371215821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.710206270217896, "step": 46000}
{"episode_reward": 976.3899457061198, "episode": 47.0, "batch_reward": 0.9327518241405487, "critic_loss": 0.2827819058634341, "actor_loss": -96.16989318847656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.73318839073181, "step": 47000}
{"episode_reward": 939.5160713524613, "episode": 48.0, "batch_reward": 0.9319494845867157, "critic_loss": 0.2599348775036633, "actor_loss": -96.16339361572265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.7268488407135, "step": 48000}
{"episode_reward": 929.9348625822457, "episode": 49.0, "batch_reward": 0.9346295100450516, "critic_loss": 0.28305579071491954, "actor_loss": -96.25418232727051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.739537477493286, "step": 49000}
{"episode_reward": 962.2476429971013, "episode": 50.0, "batch_reward": 0.9326683763861656, "critic_loss": 0.27933940530568363, "actor_loss": -96.17111616516114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.726135969161987, "step": 50000}
{"episode_reward": 960.9809012254769, "episode": 51.0, "batch_reward": 0.9348766779303551, "critic_loss": 0.2608635814152658, "actor_loss": -96.28167161560059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.088587284088135, "step": 51000}
{"episode_reward": 974.3805209270465, "episode": 52.0, "batch_reward": 0.9348960952758789, "critic_loss": 0.2915301646888256, "actor_loss": -96.21373139953613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.72036838531494, "step": 52000}
{"episode_reward": 951.8951126910428, "episode": 53.0, "batch_reward": 0.9346626266241074, "critic_loss": 0.2681971830576658, "actor_loss": -96.2141655883789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.722034454345703, "step": 53000}
{"episode_reward": 941.007386562348, "episode": 54.0, "batch_reward": 0.9362496147751809, "critic_loss": 0.26388507562875746, "actor_loss": -96.29717140197754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.718673944473267, "step": 54000}
{"episode_reward": 984.6329590483899, "episode": 55.0, "batch_reward": 0.9367455978393555, "critic_loss": 0.26293180070072414, "actor_loss": -96.33903334045411, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.737871646881104, "step": 55000}
{"episode_reward": 975.4253940732623, "episode": 56.0, "batch_reward": 0.9368205909729004, "critic_loss": 0.24449099327623844, "actor_loss": -96.3313126373291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.73646306991577, "step": 56000}
{"episode_reward": 960.5724623445462, "episode": 57.0, "batch_reward": 0.9370466188788414, "critic_loss": 0.285711589358747, "actor_loss": -96.29867590332032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.763765335083008, "step": 57000}
{"episode_reward": 943.6470299649474, "episode": 58.0, "batch_reward": 0.93806066852808, "critic_loss": 0.25290691301599144, "actor_loss": -96.3372455444336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.7571439743042, "step": 58000}
{"episode_reward": 985.4349638159317, "episode": 59.0, "batch_reward": 0.9383040052056313, "critic_loss": 0.2814770680516958, "actor_loss": -96.41141607666016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.728377103805542, "step": 59000}
{"episode_reward": 932.861904603975, "episode": 60.0, "batch_reward": 0.937599508881569, "critic_loss": 0.3134322434067726, "actor_loss": -96.29893101501465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.738149166107178, "step": 60000}
{"episode_reward": 923.9276898719255, "episode": 61.0, "batch_reward": 0.9376262858510017, "critic_loss": 0.3245523559078574, "actor_loss": -96.26343240356445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.10465335845947, "step": 61000}
{"episode_reward": 929.2481251033614, "episode": 62.0, "batch_reward": 0.9374939703345299, "critic_loss": 0.3299076049923897, "actor_loss": -96.25510710144043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.730811834335327, "step": 62000}
{"episode_reward": 949.1923252940996, "episode": 63.0, "batch_reward": 0.9375087957382202, "critic_loss": 0.37685978720337154, "actor_loss": -96.23632879638672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.735828638076782, "step": 63000}
{"episode_reward": 893.7894668294254, "episode": 64.0, "batch_reward": 0.938468431532383, "critic_loss": 0.3533467164747417, "actor_loss": -96.26076258850098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.725213766098022, "step": 64000}
{"episode_reward": 987.853882541546, "episode": 65.0, "batch_reward": 0.9382529838681221, "critic_loss": 0.334083201110363, "actor_loss": -96.26623724365234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.737330198287964, "step": 65000}
{"episode_reward": 956.9116985409433, "episode": 66.0, "batch_reward": 0.938926176071167, "critic_loss": 0.31521399184316395, "actor_loss": -96.32112023925781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.737290859222412, "step": 66000}
{"episode_reward": 981.7239129601777, "episode": 67.0, "batch_reward": 0.9389977840781212, "critic_loss": 0.29858728154748676, "actor_loss": -96.25597938537598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.719844341278076, "step": 67000}
{"episode_reward": 962.1595593454558, "episode": 68.0, "batch_reward": 0.9396636616587639, "critic_loss": 0.29423269464075563, "actor_loss": -96.31030088806152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.72232675552368, "step": 68000}
{"episode_reward": 965.05112594541, "episode": 69.0, "batch_reward": 0.9411460273265838, "critic_loss": 0.3046751142702997, "actor_loss": -96.29840338134765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.720882177352905, "step": 69000}
{"episode_reward": 961.2237951068998, "episode": 70.0, "batch_reward": 0.9399517683386802, "critic_loss": 0.3157452705949545, "actor_loss": -96.3372882080078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.740326166152954, "step": 70000}
{"episode_reward": 980.198476127219, "episode": 71.0, "batch_reward": 0.9409868832230568, "critic_loss": 0.2972008779197931, "actor_loss": -96.32768978881836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.175551652908325, "step": 71000}
{"episode_reward": 934.7677855545904, "episode": 72.0, "batch_reward": 0.940512256860733, "critic_loss": 0.2877861592769623, "actor_loss": -96.35776388549804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.729081869125366, "step": 72000}
{"episode_reward": 962.6818802726589, "episode": 73.0, "batch_reward": 0.9413112725615501, "critic_loss": 0.3152194624915719, "actor_loss": -96.29778100585938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.71739101409912, "step": 73000}
{"episode_reward": 968.2912310889882, "episode": 74.0, "batch_reward": 0.9414415306448937, "critic_loss": 0.2895966565385461, "actor_loss": -96.34178833007813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.729573726654053, "step": 74000}
{"episode_reward": 976.7562882337565, "episode": 75.0, "batch_reward": 0.9427123563289642, "critic_loss": 0.2966227885261178, "actor_loss": -96.47634497070312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.73567295074463, "step": 75000}
{"episode_reward": 943.4499825902668, "episode": 76.0, "batch_reward": 0.9417902202606201, "critic_loss": 0.30716526589542625, "actor_loss": -96.37837477111816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.759315252304077, "step": 76000}
{"episode_reward": 952.2237396012923, "episode": 77.0, "batch_reward": 0.9420204300284386, "critic_loss": 0.2786783126294613, "actor_loss": -96.37506753540039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.727929830551147, "step": 77000}
{"episode_reward": 983.5888708501373, "episode": 78.0, "batch_reward": 0.9427545319199562, "critic_loss": 0.26452484492212536, "actor_loss": -96.38844641113282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.723061084747314, "step": 78000}
{"episode_reward": 985.0684671697185, "episode": 79.0, "batch_reward": 0.9436945438981056, "critic_loss": 0.2684569451138377, "actor_loss": -96.47345364379883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.730021715164185, "step": 79000}
{"episode_reward": 984.8115064182841, "episode": 80.0, "batch_reward": 0.9439949231743813, "critic_loss": 0.2713338362425566, "actor_loss": -96.50955975341797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.7558810710907, "step": 80000}
{"episode_reward": 970.8660974304674, "episode": 81.0, "batch_reward": 0.9436614005565643, "critic_loss": 0.3066375775635242, "actor_loss": -96.44840629577637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.123334884643555, "step": 81000}
{"episode_reward": 934.0887629791338, "episode": 82.0, "batch_reward": 0.9441615003943443, "critic_loss": 0.31008554876595734, "actor_loss": -96.39831997680665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.731162786483765, "step": 82000}
{"episode_reward": 977.701906455271, "episode": 83.0, "batch_reward": 0.9447109748721123, "critic_loss": 0.313579680711031, "actor_loss": -96.50315182495117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.7401704788208, "step": 83000}
{"episode_reward": 961.2699763067966, "episode": 84.0, "batch_reward": 0.9443995783925057, "critic_loss": 0.28900481542944906, "actor_loss": -96.47017498779297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.73622703552246, "step": 84000}
{"episode_reward": 987.5489289246447, "episode": 85.0, "batch_reward": 0.9456507061123848, "critic_loss": 0.2723800368830562, "actor_loss": -96.54363906860351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.745866775512695, "step": 85000}
{"episode_reward": 959.1154706421651, "episode": 86.0, "batch_reward": 0.945759215593338, "critic_loss": 0.27350409008935095, "actor_loss": -96.52405659484863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.758919954299927, "step": 86000}
{"episode_reward": 937.3385142807804, "episode": 87.0, "batch_reward": 0.9452533165812492, "critic_loss": 0.2917164607793093, "actor_loss": -96.50079711914063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.756610870361328, "step": 87000}
{"episode_reward": 956.2692087273455, "episode": 88.0, "batch_reward": 0.9456527040600776, "critic_loss": 0.28416903025284407, "actor_loss": -96.49461473083497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.749760150909424, "step": 88000}
{"episode_reward": 976.4363729422519, "episode": 89.0, "batch_reward": 0.9466147241592408, "critic_loss": 0.2810340823233128, "actor_loss": -96.5549422607422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.73665452003479, "step": 89000}
{"episode_reward": 962.570022760764, "episode": 90.0, "batch_reward": 0.9452868509888649, "critic_loss": 0.31127514481544494, "actor_loss": -96.45342401123047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.732595443725586, "step": 90000}
{"episode_reward": 933.5411476848553, "episode": 91.0, "batch_reward": 0.9436346736550331, "critic_loss": 0.28722193851321937, "actor_loss": -96.44490293884277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.11738157272339, "step": 91000}
{"episode_reward": 942.9660334401632, "episode": 92.0, "batch_reward": 0.9456599118709564, "critic_loss": 0.2707505536675453, "actor_loss": -96.4776217956543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.731958627700806, "step": 92000}
{"episode_reward": 976.5473636401224, "episode": 93.0, "batch_reward": 0.9453121266365051, "critic_loss": 0.2755865519717336, "actor_loss": -96.49386981201172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.730736255645752, "step": 93000}
{"episode_reward": 932.3117667576448, "episode": 94.0, "batch_reward": 0.946248029589653, "critic_loss": 0.301439330868423, "actor_loss": -96.48734403991699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.753597736358643, "step": 94000}
{"episode_reward": 982.9189813330026, "episode": 95.0, "batch_reward": 0.9463043134808541, "critic_loss": 0.27467685685306786, "actor_loss": -96.5331982269287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.731512546539307, "step": 95000}
{"episode_reward": 960.7985707783345, "episode": 96.0, "batch_reward": 0.94683028870821, "critic_loss": 0.2590931514129043, "actor_loss": -96.52264794921875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.713226795196533, "step": 96000}
{"episode_reward": 972.2153123275483, "episode": 97.0, "batch_reward": 0.946728381216526, "critic_loss": 0.25914746171608566, "actor_loss": -96.5152328338623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.727823495864868, "step": 97000}
{"episode_reward": 985.0407924776616, "episode": 98.0, "batch_reward": 0.9468442994356155, "critic_loss": 0.25520865600556136, "actor_loss": -96.49130142211914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.737265586853027, "step": 98000}
{"episode_reward": 983.458245707738, "episode": 99.0, "batch_reward": 0.9476485184431076, "critic_loss": 0.2603160638362169, "actor_loss": -96.54148741149902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.761888027191162, "step": 99000}
{"episode_reward": 985.6057727798573, "episode": 100.0, "batch_reward": 0.947655270934105, "critic_loss": 0.2738012412749231, "actor_loss": -96.54056469726562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.762629747390747, "step": 100000}
{"episode_reward": 964.2019663435044, "episode": 101.0, "batch_reward": 0.9480698559880256, "critic_loss": 0.2652211114279926, "actor_loss": -96.53308561706542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.10907173156738, "step": 101000}
{"episode_reward": 949.198347006889, "episode": 102.0, "batch_reward": 0.9480489829778671, "critic_loss": 0.25196547159180044, "actor_loss": -96.56440586853027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.73464560508728, "step": 102000}
{"episode_reward": 941.8313863782777, "episode": 103.0, "batch_reward": 0.9484346044659615, "critic_loss": 0.2552270339131355, "actor_loss": -96.55246159362792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.723547220230103, "step": 103000}
{"episode_reward": 980.768364116492, "episode": 104.0, "batch_reward": 0.9487296743988991, "critic_loss": 0.24558344659209252, "actor_loss": -96.59709840393066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.72618341445923, "step": 104000}
{"episode_reward": 960.6131881354345, "episode": 105.0, "batch_reward": 0.9490173647999763, "critic_loss": 0.26576103996112943, "actor_loss": -96.57781016540527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.72869372367859, "step": 105000}
{"episode_reward": 985.7037844492373, "episode": 106.0, "batch_reward": 0.9484385739564896, "critic_loss": 0.265568604759872, "actor_loss": -96.6243907623291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.728058338165283, "step": 106000}
{"episode_reward": 984.6180488638206, "episode": 107.0, "batch_reward": 0.9489633528590202, "critic_loss": 0.2620729725025594, "actor_loss": -96.62574464416504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.731404781341553, "step": 107000}
{"episode_reward": 931.1657513098982, "episode": 108.0, "batch_reward": 0.948720676958561, "critic_loss": 0.2510196183435619, "actor_loss": -96.59185391235351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.72464919090271, "step": 108000}
{"episode_reward": 988.0215422926059, "episode": 109.0, "batch_reward": 0.949005855858326, "critic_loss": 0.25361216413602233, "actor_loss": -96.57505195617676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.7240788936615, "step": 109000}
{"episode_reward": 986.3020455070407, "episode": 110.0, "batch_reward": 0.9506777904629707, "critic_loss": 0.24949465702474116, "actor_loss": -96.63710868835449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.717955827713013, "step": 110000}
{"episode_reward": 962.8476888935292, "episode": 111.0, "batch_reward": 0.9499957324266434, "critic_loss": 0.26742186073213814, "actor_loss": -96.60371064758301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.12548804283142, "step": 111000}
{"episode_reward": 946.2377063918996, "episode": 112.0, "batch_reward": 0.9489427726268769, "critic_loss": 0.2602939540110528, "actor_loss": -96.6202721862793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.747507333755493, "step": 112000}
{"episode_reward": 956.1045553542052, "episode": 113.0, "batch_reward": 0.9499322062134743, "critic_loss": 0.25613297407329083, "actor_loss": -96.5971044769287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.762627601623535, "step": 113000}
{"episode_reward": 981.4903872028718, "episode": 114.0, "batch_reward": 0.9503584775924683, "critic_loss": 0.24303620724380015, "actor_loss": -96.64950805664063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.758920669555664, "step": 114000}
{"episode_reward": 981.1588429739738, "episode": 115.0, "batch_reward": 0.9506854156255722, "critic_loss": 0.26372441146895287, "actor_loss": -96.66905810546875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.738054752349854, "step": 115000}
{"episode_reward": 986.2755225493394, "episode": 116.0, "batch_reward": 0.9505877750515938, "critic_loss": 0.2883958471491933, "actor_loss": -96.65053814697265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.745614051818848, "step": 116000}
{"episode_reward": 965.4174193004361, "episode": 117.0, "batch_reward": 0.9504913982152939, "critic_loss": 0.2620532417185605, "actor_loss": -96.63953904724121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.728307247161865, "step": 117000}
{"episode_reward": 959.3808875138166, "episode": 118.0, "batch_reward": 0.9513047135472298, "critic_loss": 0.27218355094641444, "actor_loss": -96.64363870239258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.74158215522766, "step": 118000}
{"episode_reward": 976.2456034370974, "episode": 119.0, "batch_reward": 0.9512762902975083, "critic_loss": 0.23897293898835778, "actor_loss": -96.64423149108887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.760634183883667, "step": 119000}
{"episode_reward": 972.5405900458875, "episode": 120.0, "batch_reward": 0.9504783275723457, "critic_loss": 0.25378545494377613, "actor_loss": -96.70961813354492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.7318594455719, "step": 120000}
{"episode_reward": 986.2673192990721, "episode": 121.0, "batch_reward": 0.9507419029474259, "critic_loss": 0.2559964853823185, "actor_loss": -96.65495550537109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.11608672142029, "step": 121000}
{"episode_reward": 946.8416070564269, "episode": 122.0, "batch_reward": 0.9521124438047409, "critic_loss": 0.27831099926307795, "actor_loss": -96.68968572998047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.735548973083496, "step": 122000}
{"episode_reward": 954.148138931668, "episode": 123.0, "batch_reward": 0.9512797105312347, "critic_loss": 0.26825779674202205, "actor_loss": -96.68707717895508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.72313666343689, "step": 123000}
{"episode_reward": 980.1041227705463, "episode": 124.0, "batch_reward": 0.9522699907422065, "critic_loss": 0.24333463308587672, "actor_loss": -96.67570513916016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.731924533843994, "step": 124000}
{"episode_reward": 990.1997841969587, "episode": 125.0, "batch_reward": 0.9525058745145798, "critic_loss": 0.26786377883702517, "actor_loss": -96.76373304748535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.759450912475586, "step": 125000}
{"episode_reward": 961.5856014301294, "episode": 126.0, "batch_reward": 0.9521759759187698, "critic_loss": 0.2622143751718104, "actor_loss": -96.72602648925782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.771966457366943, "step": 126000}
{"episode_reward": 962.2005840238838, "episode": 127.0, "batch_reward": 0.9523415275812149, "critic_loss": 0.26736161383613943, "actor_loss": -96.70603248596191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77073836326599, "step": 127000}
{"episode_reward": 983.8468304670663, "episode": 128.0, "batch_reward": 0.9529094946980476, "critic_loss": 0.24473308919370174, "actor_loss": -96.73251232910157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.754528284072876, "step": 128000}
{"episode_reward": 987.9600801547479, "episode": 129.0, "batch_reward": 0.9524270967841149, "critic_loss": 0.2593131267502904, "actor_loss": -96.73453901672363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.73699164390564, "step": 129000}
{"episode_reward": 935.159858183857, "episode": 130.0, "batch_reward": 0.9522497920393944, "critic_loss": 0.26753443900123236, "actor_loss": -96.67101794433594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.732014894485474, "step": 130000}
{"episode_reward": 912.142255786448, "episode": 131.0, "batch_reward": 0.9514224503040314, "critic_loss": 0.26703062777221204, "actor_loss": -96.57171127319336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.177735805511475, "step": 131000}
{"episode_reward": 961.8861331210364, "episode": 132.0, "batch_reward": 0.9520066716074943, "critic_loss": 0.2571226451545954, "actor_loss": -96.63482421875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.738136768341064, "step": 132000}
{"episode_reward": 960.8539336187978, "episode": 133.0, "batch_reward": 0.951168987095356, "critic_loss": 0.28296617852523925, "actor_loss": -96.67632598876953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.729652166366577, "step": 133000}
{"episode_reward": 940.4832030288723, "episode": 134.0, "batch_reward": 0.9520487870573997, "critic_loss": 0.2827818369567394, "actor_loss": -96.68496818542481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.71863842010498, "step": 134000}
{"episode_reward": 956.6787189011276, "episode": 135.0, "batch_reward": 0.9518678178787231, "critic_loss": 0.2726959667056799, "actor_loss": -96.72058230590821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.7245831489563, "step": 135000}
{"episode_reward": 974.2515621881378, "episode": 136.0, "batch_reward": 0.9524725848436355, "critic_loss": 0.2795685320906341, "actor_loss": -96.72541647338868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.729501247406006, "step": 136000}
{"episode_reward": 946.747094703965, "episode": 137.0, "batch_reward": 0.9525625524520874, "critic_loss": 0.2577999067828059, "actor_loss": -96.68924848937988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.734211683273315, "step": 137000}
{"episode_reward": 981.554563263648, "episode": 138.0, "batch_reward": 0.9525856574177742, "critic_loss": 0.2878293604142964, "actor_loss": -96.58277665710449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.73676109313965, "step": 138000}
{"episode_reward": 928.8587984126209, "episode": 139.0, "batch_reward": 0.95288128054142, "critic_loss": 0.2854390782788396, "actor_loss": -96.59169985961914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.724955797195435, "step": 139000}
{"episode_reward": 963.0943852209774, "episode": 140.0, "batch_reward": 0.9527840405106545, "critic_loss": 0.3090281411372125, "actor_loss": -96.60922079467774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.726073503494263, "step": 140000}
{"episode_reward": 962.1171981999548, "episode": 141.0, "batch_reward": 0.9520999900102616, "critic_loss": 0.31558182106912136, "actor_loss": -96.64993310546875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.14159893989563, "step": 141000}
{"episode_reward": 978.2492495465204, "episode": 142.0, "batch_reward": 0.95223097717762, "critic_loss": 0.3215389987900853, "actor_loss": -96.64859675598144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.731399297714233, "step": 142000}
{"episode_reward": 967.7115931989254, "episode": 143.0, "batch_reward": 0.952790970146656, "critic_loss": 0.33056462690979244, "actor_loss": -96.7354030456543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.726158618927002, "step": 143000}
{"episode_reward": 974.7294939083936, "episode": 144.0, "batch_reward": 0.9527918761968612, "critic_loss": 0.3309635873064399, "actor_loss": -96.68106080627442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.733160257339478, "step": 144000}
{"episode_reward": 961.570144193994, "episode": 145.0, "batch_reward": 0.9525305545926094, "critic_loss": 0.30897429868206383, "actor_loss": -96.76647943115235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.72302484512329, "step": 145000}
{"episode_reward": 972.8401377912925, "episode": 146.0, "batch_reward": 0.9530628128647805, "critic_loss": 0.2955089503452182, "actor_loss": -96.66381257629395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.71960711479187, "step": 146000}
{"episode_reward": 972.5509766212434, "episode": 147.0, "batch_reward": 0.9533806340098381, "critic_loss": 0.3405245531126857, "actor_loss": -96.67860946655273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.722666263580322, "step": 147000}
{"episode_reward": 943.5620998487623, "episode": 148.0, "batch_reward": 0.9529385972619057, "critic_loss": 0.3379231857210398, "actor_loss": -96.70025866699218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.716728925704956, "step": 148000}
{"episode_reward": 963.2332227131064, "episode": 149.0, "batch_reward": 0.9530407030582428, "critic_loss": 0.3184865916222334, "actor_loss": -96.68869650268554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.730663776397705, "step": 149000}
{"episode_reward": 979.6654728285182, "episode": 150.0, "batch_reward": 0.9533783031105996, "critic_loss": 0.30259966860711573, "actor_loss": -96.70906567382812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
