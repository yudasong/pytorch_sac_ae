{"episode_reward": 0.0, "episode": 1.0, "duration": 22.316612720489502, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.8611547946929932, "step": 2000}
{"episode_reward": 632.427646246406, "episode": 3.0, "batch_reward": 0.3530258025903231, "critic_loss": 0.857512029042519, "actor_loss": -70.12794792294359, "actor_target_entropy": -6.0, "alpha_value": 0.004365629073060301, "duration": 67.21024489402771, "step": 3000}
{"episode_reward": 419.9200822573077, "episode": 4.0, "batch_reward": 0.4099836683869362, "critic_loss": 1.1406381254792213, "actor_loss": -74.057890625, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.054192304611206, "step": 4000}
{"episode_reward": 678.4035020259452, "episode": 5.0, "batch_reward": 0.4474734909534454, "critic_loss": 1.0117505674362182, "actor_loss": -75.39548866271973, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.1249418258667, "step": 5000}
{"episode_reward": 617.8100352682604, "episode": 6.0, "batch_reward": 0.492423366934061, "critic_loss": 1.0250185205936433, "actor_loss": -76.52774670410156, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.294259786605835, "step": 6000}
{"episode_reward": 666.6169336318319, "episode": 7.0, "batch_reward": 0.5221305576264859, "critic_loss": 1.0745142048597336, "actor_loss": -77.57327156066894, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.082509994506836, "step": 7000}
{"episode_reward": 712.3479635520754, "episode": 8.0, "batch_reward": 0.5469950362145901, "critic_loss": 1.026968501508236, "actor_loss": -77.83328030395508, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.80326533317566, "step": 8000}
{"episode_reward": 755.5055561395847, "episode": 9.0, "batch_reward": 0.5813962370455265, "critic_loss": 1.074772261917591, "actor_loss": -78.67635455322265, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.090838193893433, "step": 9000}
{"episode_reward": 731.1779245126777, "episode": 10.0, "batch_reward": 0.5983947968184948, "critic_loss": 1.045420280277729, "actor_loss": -79.14132879638672, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.873135805130005, "step": 10000}
{"episode_reward": 849.5013285623, "episode": 11.0, "batch_reward": 0.6172578887343406, "critic_loss": 1.009869941353798, "actor_loss": -79.839296585083, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 48.17211890220642, "step": 11000}
{"episode_reward": 560.5456855769557, "episode": 12.0, "batch_reward": 0.5857175813615322, "critic_loss": 0.9012858752310277, "actor_loss": -79.4606739654541, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.483697175979614, "step": 12000}
{"episode_reward": 76.93930690424617, "episode": 13.0, "batch_reward": 0.5476633796691894, "critic_loss": 0.7412112268805504, "actor_loss": -79.20467416381835, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.6074001789093, "step": 13000}
{"episode_reward": 75.13774421538206, "episode": 14.0, "batch_reward": 0.5186800815463066, "critic_loss": 0.6637922329008579, "actor_loss": -78.13784056091309, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.797902822494507, "step": 14000}
{"episode_reward": 527.2603465127206, "episode": 15.0, "batch_reward": 0.5356324436962605, "critic_loss": 0.6285806410014629, "actor_loss": -78.23117596435547, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 25.5096652507782, "step": 15000}
{"episode_reward": 824.2716955197686, "episode": 16.0, "batch_reward": 0.5562255703508854, "critic_loss": 0.597230887889862, "actor_loss": -78.10552473449707, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.265007495880127, "step": 16000}
{"episode_reward": 897.3910755141716, "episode": 17.0, "batch_reward": 0.5759947032630444, "critic_loss": 0.5902046652138233, "actor_loss": -77.94716943359376, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.194633960723877, "step": 17000}
{"episode_reward": 834.5057290001873, "episode": 18.0, "batch_reward": 0.5859621116816998, "critic_loss": 0.6162165164351463, "actor_loss": -77.64323608398438, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.61043405532837, "step": 18000}
{"episode_reward": 701.3029028483604, "episode": 19.0, "batch_reward": 0.5907476235926151, "critic_loss": 0.615336023837328, "actor_loss": -77.64298518371582, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.9461510181427, "step": 19000}
{"episode_reward": 779.2169639728596, "episode": 20.0, "batch_reward": 0.6078671663701535, "critic_loss": 0.5742234578728675, "actor_loss": -77.60363220214843, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.451900482177734, "step": 20000}
{"episode_reward": 913.1502127091148, "episode": 21.0, "batch_reward": 0.6201366140246392, "critic_loss": 0.5615174403190613, "actor_loss": -77.55675672912598, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.11396408081055, "step": 21000}
{"episode_reward": 858.7475953825563, "episode": 22.0, "batch_reward": 0.636008459508419, "critic_loss": 0.5275281108021737, "actor_loss": -77.66300576782227, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.163291454315186, "step": 22000}
{"episode_reward": 923.5514380356452, "episode": 23.0, "batch_reward": 0.6435069699287415, "critic_loss": 0.5657809171974659, "actor_loss": -77.75222637939453, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.114979028701782, "step": 23000}
{"episode_reward": 876.965615954798, "episode": 24.0, "batch_reward": 0.6534992029666901, "critic_loss": 0.5853893886804581, "actor_loss": -77.89469717407226, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 25.176539421081543, "step": 24000}
{"episode_reward": 864.4940717038672, "episode": 25.0, "batch_reward": 0.6660103215575218, "critic_loss": 0.5959307325184345, "actor_loss": -78.01881929016113, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.16267228126526, "step": 25000}
{"episode_reward": 920.3153219908752, "episode": 26.0, "batch_reward": 0.6719642213582993, "critic_loss": 0.5817059586346149, "actor_loss": -78.20685856628418, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.300098419189453, "step": 26000}
{"episode_reward": 883.5665461469209, "episode": 27.0, "batch_reward": 0.6805092516541481, "critic_loss": 0.5976371996700763, "actor_loss": -78.52745733642578, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.295048713684082, "step": 27000}
{"episode_reward": 857.048619228626, "episode": 28.0, "batch_reward": 0.6886727881431579, "critic_loss": 0.5425951629579068, "actor_loss": -78.54063832092285, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.182024478912354, "step": 28000}
{"episode_reward": 952.8664459388949, "episode": 29.0, "batch_reward": 0.6960985170006752, "critic_loss": 0.5119001459181308, "actor_loss": -78.81587353515626, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.08680820465088, "step": 29000}
{"episode_reward": 867.7445085339251, "episode": 30.0, "batch_reward": 0.7008033275604248, "critic_loss": 0.5056209764182568, "actor_loss": -78.89410571289062, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.198543548583984, "step": 30000}
{"episode_reward": 835.1038242341173, "episode": 31.0, "batch_reward": 0.707874088525772, "critic_loss": 0.49491448083519934, "actor_loss": -78.81571780395508, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.939961433410645, "step": 31000}
{"episode_reward": 947.7936705069304, "episode": 32.0, "batch_reward": 0.7151095126271247, "critic_loss": 0.49831756350398065, "actor_loss": -79.24029110717774, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.89586591720581, "step": 32000}
{"episode_reward": 933.2909545034714, "episode": 33.0, "batch_reward": 0.7213489038944244, "critic_loss": 0.4714815030246973, "actor_loss": -79.37149803161621, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.59081721305847, "step": 33000}
{"episode_reward": 934.001942333571, "episode": 34.0, "batch_reward": 0.7300679298639298, "critic_loss": 0.46047524094581604, "actor_loss": -79.59628840637207, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.083958625793457, "step": 34000}
{"episode_reward": 919.2252163860682, "episode": 35.0, "batch_reward": 0.7341281774640084, "critic_loss": 0.46275639736652374, "actor_loss": -79.74415492248535, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.385383367538452, "step": 35000}
{"episode_reward": 890.7356163103636, "episode": 36.0, "batch_reward": 0.7390043259263038, "critic_loss": 0.4636327438354492, "actor_loss": -79.88319401550292, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.591312885284424, "step": 36000}
{"episode_reward": 933.3351372491927, "episode": 37.0, "batch_reward": 0.7443575339913369, "critic_loss": 0.45501944614946843, "actor_loss": -80.15013276672363, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.33668541908264, "step": 37000}
{"episode_reward": 918.4920329687995, "episode": 38.0, "batch_reward": 0.7456197586059571, "critic_loss": 0.4566471124589443, "actor_loss": -80.26885189819336, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.18607258796692, "step": 38000}
{"episode_reward": 889.1187137711438, "episode": 39.0, "batch_reward": 0.7520455899238586, "critic_loss": 0.47632761220633985, "actor_loss": -80.4527474822998, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.864328384399414, "step": 39000}
{"episode_reward": 964.9335778590863, "episode": 40.0, "batch_reward": 0.7554936129450798, "critic_loss": 0.5177008043080569, "actor_loss": -80.39625248718262, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.387181758880615, "step": 40000}
{"episode_reward": 870.9879198898408, "episode": 41.0, "batch_reward": 0.75835086196661, "critic_loss": 0.5390612190663815, "actor_loss": -80.67985566711425, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.207942485809326, "step": 41000}
{"episode_reward": 925.9748550888692, "episode": 42.0, "batch_reward": 0.7648177679181098, "critic_loss": 0.4970705968439579, "actor_loss": -80.86202070617676, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.498268127441406, "step": 42000}
{"episode_reward": 918.9101706517296, "episode": 43.0, "batch_reward": 0.7672707145810127, "critic_loss": 0.5458196482360363, "actor_loss": -80.9141936340332, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.56330132484436, "step": 43000}
{"episode_reward": 867.1124499097789, "episode": 44.0, "batch_reward": 0.7688904682397842, "critic_loss": 0.5259658409059048, "actor_loss": -81.14415692138672, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.43036937713623, "step": 44000}
{"episode_reward": 946.1402871147687, "episode": 45.0, "batch_reward": 0.7736940569877625, "critic_loss": 0.5288057465851307, "actor_loss": -81.46760005187988, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.588252305984497, "step": 45000}
{"episode_reward": 911.0210086877723, "episode": 46.0, "batch_reward": 0.7766261271834374, "critic_loss": 0.5339323955327272, "actor_loss": -81.68206340026856, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.981252193450928, "step": 46000}
{"episode_reward": 947.1476429990819, "episode": 47.0, "batch_reward": 0.7791345658302307, "critic_loss": 0.5537360962182284, "actor_loss": -81.51751908874512, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.041100025177002, "step": 47000}
{"episode_reward": 864.3818715778399, "episode": 48.0, "batch_reward": 0.7802987400889396, "critic_loss": 0.5103151937127113, "actor_loss": -81.68008918762207, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.89540719985962, "step": 48000}
{"episode_reward": 960.2161125414128, "episode": 49.0, "batch_reward": 0.7862110754847527, "critic_loss": 0.4905336432904005, "actor_loss": -81.74720254516602, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 25.126856803894043, "step": 49000}
{"episode_reward": 893.4494251251889, "episode": 50.0, "batch_reward": 0.7870277525186539, "critic_loss": 0.5372581293731928, "actor_loss": -81.8997989654541, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.21136450767517, "step": 50000}
{"episode_reward": 827.0276563310293, "episode": 51.0, "batch_reward": 0.7894937369823456, "critic_loss": 0.4845841274410486, "actor_loss": -82.00297697448731, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.71185517311096, "step": 51000}
{"episode_reward": 944.507746525571, "episode": 52.0, "batch_reward": 0.7924518599510193, "critic_loss": 0.4731349581182003, "actor_loss": -82.20383058166504, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.538605451583862, "step": 52000}
{"episode_reward": 958.4481235354867, "episode": 53.0, "batch_reward": 0.7862048204541207, "critic_loss": 0.4965135040730238, "actor_loss": -81.8755711364746, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.908126831054688, "step": 53000}
{"episode_reward": 47.192530572471334, "episode": 54.0, "batch_reward": 0.7829022517204285, "critic_loss": 0.5082776737064123, "actor_loss": -81.95024711608886, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.118270874023438, "step": 54000}
{"episode_reward": 958.3236119946749, "episode": 55.0, "batch_reward": 0.7856013182401657, "critic_loss": 0.512934799104929, "actor_loss": -82.06704891967773, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.762952089309692, "step": 55000}
{"episode_reward": 966.4448429440948, "episode": 56.0, "batch_reward": 0.7860477615594864, "critic_loss": 0.5452609658837319, "actor_loss": -81.94333888244628, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.670846700668335, "step": 56000}
{"episode_reward": 841.1560593405042, "episode": 57.0, "batch_reward": 0.7892864587903022, "critic_loss": 0.5080118411630392, "actor_loss": -82.08628308105469, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.996017694473267, "step": 57000}
{"episode_reward": 914.6175812022838, "episode": 58.0, "batch_reward": 0.7918075344562531, "critic_loss": 0.5069296525418758, "actor_loss": -82.1059157409668, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.747544050216675, "step": 58000}
{"episode_reward": 958.2639253348946, "episode": 59.0, "batch_reward": 0.7931320796608925, "critic_loss": 0.5260654421448707, "actor_loss": -82.23446832275391, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.45997929573059, "step": 59000}
{"episode_reward": 932.6137397084781, "episode": 60.0, "batch_reward": 0.7981230162978172, "critic_loss": 0.4989491742551327, "actor_loss": -82.54494017028809, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.406420946121216, "step": 60000}
{"episode_reward": 966.4227628572316, "episode": 61.0, "batch_reward": 0.7998088310360909, "critic_loss": 0.4938114884346724, "actor_loss": -82.57928193664551, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 44.11049437522888, "step": 61000}
{"episode_reward": 959.3200060205269, "episode": 62.0, "batch_reward": 0.8013914338350296, "critic_loss": 0.48691818192601205, "actor_loss": -82.96953816223144, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.232675790786743, "step": 62000}
{"episode_reward": 942.092286886261, "episode": 63.0, "batch_reward": 0.8049187995195389, "critic_loss": 0.49486730779707433, "actor_loss": -82.94282136535645, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.33305025100708, "step": 63000}
{"episode_reward": 897.6984446435257, "episode": 64.0, "batch_reward": 0.8059857739210129, "critic_loss": 0.46110299886763095, "actor_loss": -82.69538078308105, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.403470277786255, "step": 64000}
{"episode_reward": 967.3173414282351, "episode": 65.0, "batch_reward": 0.8097844232320786, "critic_loss": 0.4524165523946285, "actor_loss": -83.19735655212402, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.319238662719727, "step": 65000}
{"episode_reward": 921.2762606952273, "episode": 66.0, "batch_reward": 0.8117021720409393, "critic_loss": 0.44619142201542855, "actor_loss": -83.17555258178712, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.585840463638306, "step": 66000}
{"episode_reward": 957.8913725706251, "episode": 67.0, "batch_reward": 0.8128495573401451, "critic_loss": 0.42885603454709054, "actor_loss": -83.39463069152832, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.497342824935913, "step": 67000}
{"episode_reward": 937.990410453925, "episode": 68.0, "batch_reward": 0.8157706100344658, "critic_loss": 0.43372845341265204, "actor_loss": -83.20160577392578, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.324647426605225, "step": 68000}
{"episode_reward": 955.0281061544256, "episode": 69.0, "batch_reward": 0.8174872201681137, "critic_loss": 0.41339235882461073, "actor_loss": -83.59523301696777, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.497450590133667, "step": 69000}
{"episode_reward": 964.0521805928244, "episode": 70.0, "batch_reward": 0.8167375229597091, "critic_loss": 0.4407579569220543, "actor_loss": -83.77642189025879, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.66524577140808, "step": 70000}
{"episode_reward": 945.2845694282016, "episode": 71.0, "batch_reward": 0.819653997540474, "critic_loss": 0.40922251969575885, "actor_loss": -83.89916946411132, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.10401391983032, "step": 71000}
{"episode_reward": 912.801953499256, "episode": 72.0, "batch_reward": 0.8191742733716965, "critic_loss": 0.4109513804614544, "actor_loss": -83.89193196105957, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.80917453765869, "step": 72000}
{"episode_reward": 939.7302356915022, "episode": 73.0, "batch_reward": 0.8230130460858345, "critic_loss": 0.41775118669867517, "actor_loss": -84.00899243164062, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.93587851524353, "step": 73000}
{"episode_reward": 930.5197947873955, "episode": 74.0, "batch_reward": 0.8244139392375947, "critic_loss": 0.4069310855269432, "actor_loss": -84.12124797058105, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.390379905700684, "step": 74000}
{"episode_reward": 956.7755617419747, "episode": 75.0, "batch_reward": 0.8267322575449944, "critic_loss": 0.3716060988306999, "actor_loss": -84.01926730346679, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.754521369934082, "step": 75000}
{"episode_reward": 958.4618111024669, "episode": 76.0, "batch_reward": 0.826070817053318, "critic_loss": 0.3939682201445103, "actor_loss": -83.86916703796386, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.72685408592224, "step": 76000}
{"episode_reward": 855.9219503792674, "episode": 77.0, "batch_reward": 0.828948943078518, "critic_loss": 0.4301550430804491, "actor_loss": -84.11783627319336, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.608067750930786, "step": 77000}
{"episode_reward": 939.2156189545884, "episode": 78.0, "batch_reward": 0.8293112788200379, "critic_loss": 0.39883369018137454, "actor_loss": -84.3040403289795, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.4176185131073, "step": 78000}
{"episode_reward": 955.0803814994078, "episode": 79.0, "batch_reward": 0.8323759680986405, "critic_loss": 0.3734611234813929, "actor_loss": -84.35258493041992, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.170409679412842, "step": 79000}
{"episode_reward": 964.3806060060845, "episode": 80.0, "batch_reward": 0.8329673683047295, "critic_loss": 0.3678865601122379, "actor_loss": -84.42396101379394, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.198643922805786, "step": 80000}
{"episode_reward": 975.1292935226948, "episode": 81.0, "batch_reward": 0.8356191160678863, "critic_loss": 0.38362215662002563, "actor_loss": -84.46246871948242, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 45.811020374298096, "step": 81000}
{"episode_reward": 958.7411905659426, "episode": 82.0, "batch_reward": 0.8363170687556267, "critic_loss": 0.38010485291481017, "actor_loss": -84.34234077453613, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.589343309402466, "step": 82000}
{"episode_reward": 915.5257949633424, "episode": 83.0, "batch_reward": 0.8380652157068252, "critic_loss": 0.3746201894432306, "actor_loss": -84.84222863769531, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.90762162208557, "step": 83000}
{"episode_reward": 957.7083111737471, "episode": 84.0, "batch_reward": 0.8397886053323745, "critic_loss": 0.3616631674319506, "actor_loss": -84.6840166015625, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.467429637908936, "step": 84000}
{"episode_reward": 971.0276634825393, "episode": 85.0, "batch_reward": 0.8410678577423095, "critic_loss": 0.36794473265111444, "actor_loss": -84.73160911560059, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.37866234779358, "step": 85000}
{"episode_reward": 929.1810121874015, "episode": 86.0, "batch_reward": 0.8405265457034111, "critic_loss": 0.3846075841933489, "actor_loss": -84.7748742980957, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.83400583267212, "step": 86000}
{"episode_reward": 917.8279668650554, "episode": 87.0, "batch_reward": 0.8422690590620041, "critic_loss": 0.371931431055069, "actor_loss": -84.82085270690918, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.38924264907837, "step": 87000}
{"episode_reward": 954.4907901871212, "episode": 88.0, "batch_reward": 0.8430334727764129, "critic_loss": 0.3376051948517561, "actor_loss": -85.01403749084473, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.991617918014526, "step": 88000}
{"episode_reward": 957.0770660235555, "episode": 89.0, "batch_reward": 0.8458116008043289, "critic_loss": 0.3441107419282198, "actor_loss": -85.05676551818847, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.725699424743652, "step": 89000}
{"episode_reward": 944.8241391262162, "episode": 90.0, "batch_reward": 0.8446398401856422, "critic_loss": 0.37239052782952786, "actor_loss": -84.95622335815429, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.775946140289307, "step": 90000}
{"episode_reward": 906.152694570121, "episode": 91.0, "batch_reward": 0.8448890672326088, "critic_loss": 0.3679853794425726, "actor_loss": -85.02319821166992, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.902199506759644, "step": 91000}
{"episode_reward": 927.0682455054097, "episode": 92.0, "batch_reward": 0.8462421831488609, "critic_loss": 0.3486372339874506, "actor_loss": -85.48136099243165, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.350550889968872, "step": 92000}
{"episode_reward": 959.0447747505749, "episode": 93.0, "batch_reward": 0.8484073339700698, "critic_loss": 0.33143887703865765, "actor_loss": -85.25862547302246, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.69546389579773, "step": 93000}
{"episode_reward": 952.7634688104531, "episode": 94.0, "batch_reward": 0.8492749148011207, "critic_loss": 0.3499820000231266, "actor_loss": -85.59888066101074, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.09368658065796, "step": 94000}
{"episode_reward": 910.7613035286074, "episode": 95.0, "batch_reward": 0.8496136197447777, "critic_loss": 0.360152944996953, "actor_loss": -85.22173924255371, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.05889058113098, "step": 95000}
{"episode_reward": 933.9345931554809, "episode": 96.0, "batch_reward": 0.8531638425588608, "critic_loss": 0.324786917231977, "actor_loss": -85.75591828918456, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.132959604263306, "step": 96000}
{"episode_reward": 959.552712807751, "episode": 97.0, "batch_reward": 0.8518369251489639, "critic_loss": 0.38159393836557864, "actor_loss": -85.33115599060059, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.437736988067627, "step": 97000}
{"episode_reward": 938.3555682164902, "episode": 98.0, "batch_reward": 0.85360127222538, "critic_loss": 0.34130335988104343, "actor_loss": -85.2319659576416, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.92850112915039, "step": 98000}
{"episode_reward": 954.901267798496, "episode": 99.0, "batch_reward": 0.8542027513980865, "critic_loss": 0.35920905900001526, "actor_loss": -85.642455368042, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.3383948802948, "step": 99000}
{"episode_reward": 959.105613665961, "episode": 100.0, "batch_reward": 0.8552563627958297, "critic_loss": 0.3505907816290855, "actor_loss": -85.78222813415528, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.879436016082764, "step": 100000}
{"episode_reward": 934.3340573235382, "episode": 101.0, "batch_reward": 0.8562251655459404, "critic_loss": 0.32618624721467493, "actor_loss": -85.91872245788574, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 46.26320171356201, "step": 101000}
{"episode_reward": 923.539491211231, "episode": 102.0, "batch_reward": 0.856904624402523, "critic_loss": 0.33081287987530233, "actor_loss": -85.68275677490234, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.15662980079651, "step": 102000}
{"episode_reward": 956.9572007952323, "episode": 103.0, "batch_reward": 0.8598178074359893, "critic_loss": 0.31981472523510457, "actor_loss": -86.12919891357421, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.74729824066162, "step": 103000}
{"episode_reward": 965.0358728230638, "episode": 104.0, "batch_reward": 0.8601094598770141, "critic_loss": 0.33065506125986577, "actor_loss": -85.75218997192383, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.17513656616211, "step": 104000}
{"episode_reward": 930.7844077600836, "episode": 105.0, "batch_reward": 0.8593504230976104, "critic_loss": 0.34247522106021644, "actor_loss": -86.16311865234375, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.360372066497803, "step": 105000}
{"episode_reward": 962.4859468006408, "episode": 106.0, "batch_reward": 0.8603008882403373, "critic_loss": 0.3259229982346296, "actor_loss": -86.11664930725098, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.92101502418518, "step": 106000}
{"episode_reward": 966.5320092922433, "episode": 107.0, "batch_reward": 0.8604500046372414, "critic_loss": 0.31045165383815765, "actor_loss": -86.02379681396485, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.12606692314148, "step": 107000}
{"episode_reward": 953.3414709943, "episode": 108.0, "batch_reward": 0.8617943210005761, "critic_loss": 0.31576759903132917, "actor_loss": -86.06590174865723, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.320531368255615, "step": 108000}
{"episode_reward": 969.9207003198868, "episode": 109.0, "batch_reward": 0.8625162358283996, "critic_loss": 0.32717364582419395, "actor_loss": -85.84516361999512, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.813644409179688, "step": 109000}
{"episode_reward": 965.809492419346, "episode": 110.0, "batch_reward": 0.865100563287735, "critic_loss": 0.3061936409175396, "actor_loss": -86.0168731842041, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.10326600074768, "step": 110000}
{"episode_reward": 937.5215795158413, "episode": 111.0, "batch_reward": 0.8646442580223084, "critic_loss": 0.33909012396633625, "actor_loss": -86.42522561645508, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.75552320480347, "step": 111000}
{"episode_reward": 907.0718129433512, "episode": 112.0, "batch_reward": 0.864115903198719, "critic_loss": 0.31097810704261064, "actor_loss": -86.41810694885254, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.35932731628418, "step": 112000}
{"episode_reward": 892.0431674610477, "episode": 113.0, "batch_reward": 0.8664259373545646, "critic_loss": 0.334473044782877, "actor_loss": -86.7006131439209, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.681811571121216, "step": 113000}
{"episode_reward": 926.2057360181086, "episode": 114.0, "batch_reward": 0.8668379529118538, "critic_loss": 0.3146857637986541, "actor_loss": -86.31396530151368, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.120923280715942, "step": 114000}
{"episode_reward": 971.3303564440636, "episode": 115.0, "batch_reward": 0.8670556569695472, "critic_loss": 0.32237608726322653, "actor_loss": -85.9529629058838, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.958051919937134, "step": 115000}
{"episode_reward": 956.8838576747696, "episode": 116.0, "batch_reward": 0.8683859862685204, "critic_loss": 0.29969763027876617, "actor_loss": -86.20565992736816, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.43177604675293, "step": 116000}
{"episode_reward": 937.0680838308584, "episode": 117.0, "batch_reward": 0.8680725749135018, "critic_loss": 0.3063283903673291, "actor_loss": -86.42904054260254, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.376314878463745, "step": 117000}
{"episode_reward": 929.3497311912339, "episode": 118.0, "batch_reward": 0.8682972178459167, "critic_loss": 0.30144165036827325, "actor_loss": -86.61443780517578, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.588003396987915, "step": 118000}
{"episode_reward": 958.3116883643589, "episode": 119.0, "batch_reward": 0.8696977232098579, "critic_loss": 0.319886513158679, "actor_loss": -86.61788633728027, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.271504163742065, "step": 119000}
{"episode_reward": 942.8738239921136, "episode": 120.0, "batch_reward": 0.8694962840676308, "critic_loss": 0.3079734842032194, "actor_loss": -86.3114829864502, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.27026629447937, "step": 120000}
{"episode_reward": 971.074661941781, "episode": 121.0, "batch_reward": 0.8710124263167381, "critic_loss": 0.3259660645276308, "actor_loss": -86.59639666748046, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 44.23585653305054, "step": 121000}
{"episode_reward": 928.7205868950712, "episode": 122.0, "batch_reward": 0.8723553737998009, "critic_loss": 0.34245674189925196, "actor_loss": -86.06363572692871, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.253933429718018, "step": 122000}
{"episode_reward": 947.1958315994851, "episode": 123.0, "batch_reward": 0.8723012722730636, "critic_loss": 0.32729223982989786, "actor_loss": -85.95290112304687, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.003437042236328, "step": 123000}
{"episode_reward": 934.9868447364187, "episode": 124.0, "batch_reward": 0.87181739372015, "critic_loss": 0.3157169875502586, "actor_loss": -86.17762791442871, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.698864936828613, "step": 124000}
{"episode_reward": 972.3765885774848, "episode": 125.0, "batch_reward": 0.8734389660358429, "critic_loss": 0.32952651008963585, "actor_loss": -86.47382920837403, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.942877531051636, "step": 125000}
{"episode_reward": 919.769018017349, "episode": 126.0, "batch_reward": 0.8733437075614929, "critic_loss": 0.3153265602141619, "actor_loss": -86.5420082244873, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.553642749786377, "step": 126000}
{"episode_reward": 956.2966350422381, "episode": 127.0, "batch_reward": 0.874781430542469, "critic_loss": 0.31928020730614665, "actor_loss": -86.4681607208252, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.99095129966736, "step": 127000}
{"episode_reward": 962.6014114384379, "episode": 128.0, "batch_reward": 0.8745592284202576, "critic_loss": 0.3206043462306261, "actor_loss": -86.67614125061036, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.37528085708618, "step": 128000}
{"episode_reward": 969.3704009138235, "episode": 129.0, "batch_reward": 0.8760948411226273, "critic_loss": 0.32343597915023564, "actor_loss": -86.74218106079101, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.92371892929077, "step": 129000}
{"episode_reward": 948.8059522556017, "episode": 130.0, "batch_reward": 0.8772815611958503, "critic_loss": 0.3190023761540651, "actor_loss": -86.51474449157715, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.686255931854248, "step": 130000}
{"episode_reward": 915.0889528639184, "episode": 131.0, "batch_reward": 0.8755868106484413, "critic_loss": 0.3012079163789749, "actor_loss": -87.10923703002929, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.59210562705994, "step": 131000}
{"episode_reward": 937.8274711973288, "episode": 132.0, "batch_reward": 0.8771237716674805, "critic_loss": 0.29626064527779816, "actor_loss": -86.91504621887206, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.283097982406616, "step": 132000}
{"episode_reward": 946.3155760068483, "episode": 133.0, "batch_reward": 0.8760651015043258, "critic_loss": 0.29616917414963245, "actor_loss": -86.73686912536621, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.603230714797974, "step": 133000}
{"episode_reward": 874.6635295502684, "episode": 134.0, "batch_reward": 0.877043319284916, "critic_loss": 0.28776799798756836, "actor_loss": -86.80996504211426, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.1432626247406, "step": 134000}
{"episode_reward": 941.7290331681422, "episode": 135.0, "batch_reward": 0.8774210945367813, "critic_loss": 0.3021201691403985, "actor_loss": -86.69639697265625, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.847167015075684, "step": 135000}
{"episode_reward": 964.0858871032774, "episode": 136.0, "batch_reward": 0.8786144106984138, "critic_loss": 0.29174635538458826, "actor_loss": -86.74574732971192, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.207080125808716, "step": 136000}
{"episode_reward": 908.687397413077, "episode": 137.0, "batch_reward": 0.8780588619709014, "critic_loss": 0.3026509890258312, "actor_loss": -86.72529290771485, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.793206930160522, "step": 137000}
{"episode_reward": 964.4248740687129, "episode": 138.0, "batch_reward": 0.8790816999077797, "critic_loss": 0.2912283238917589, "actor_loss": -87.08312519836426, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.512977838516235, "step": 138000}
{"episode_reward": 957.1148448487318, "episode": 139.0, "batch_reward": 0.8792585945129394, "critic_loss": 0.28922000294178724, "actor_loss": -87.19143528747558, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.91693377494812, "step": 139000}
{"episode_reward": 933.7052752059791, "episode": 140.0, "batch_reward": 0.8805519352555276, "critic_loss": 0.2890796692594886, "actor_loss": -87.40903860473632, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.25215244293213, "step": 140000}
{"episode_reward": 949.7584919333568, "episode": 141.0, "batch_reward": 0.8808297474980354, "critic_loss": 0.28092415087670086, "actor_loss": -86.96890162658691, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 44.628098249435425, "step": 141000}
{"episode_reward": 960.4625829681694, "episode": 142.0, "batch_reward": 0.8811270248889923, "critic_loss": 0.29104027336090804, "actor_loss": -86.94193244934083, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.402935028076172, "step": 142000}
{"episode_reward": 939.1869918121922, "episode": 143.0, "batch_reward": 0.8810826165676117, "critic_loss": 0.29150249062478545, "actor_loss": -86.77871548461914, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.508087396621704, "step": 143000}
{"episode_reward": 955.2799678831885, "episode": 144.0, "batch_reward": 0.8823971031308174, "critic_loss": 0.30205146020650864, "actor_loss": -87.23006881713867, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.891727685928345, "step": 144000}
{"episode_reward": 912.3101045536871, "episode": 145.0, "batch_reward": 0.8822835977673531, "critic_loss": 0.281442061252892, "actor_loss": -86.75674975585937, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.778624296188354, "step": 145000}
{"episode_reward": 947.6939693969036, "episode": 146.0, "batch_reward": 0.8824769452810287, "critic_loss": 0.288123120047152, "actor_loss": -87.34030895996094, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.61203169822693, "step": 146000}
{"episode_reward": 964.1272928307881, "episode": 147.0, "batch_reward": 0.8839001675844192, "critic_loss": 0.27874631828814744, "actor_loss": -87.12380908203124, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.976643800735474, "step": 147000}
{"episode_reward": 915.6149870787749, "episode": 148.0, "batch_reward": 0.8836452108621597, "critic_loss": 0.283013408832252, "actor_loss": -87.31685942077637, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.351471424102783, "step": 148000}
{"episode_reward": 932.0146783721855, "episode": 149.0, "batch_reward": 0.8843984741568566, "critic_loss": 0.28304356017708776, "actor_loss": -87.54316203308106, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.435446977615356, "step": 149000}
{"episode_reward": 956.2785020927045, "episode": 150.0, "batch_reward": 0.8846153787374497, "critic_loss": 0.2851758185476065, "actor_loss": -87.39849200439453, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "step": 150000}
