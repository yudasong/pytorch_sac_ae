{"episode_reward": 0.0, "episode": 1.0, "duration": 20.664954662322998, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.7931106090545654, "step": 2000}
{"episode_reward": 973.7241921866618, "episode": 3.0, "batch_reward": 0.5420995701766483, "critic_loss": 0.5967014341907984, "actor_loss": -91.49032567433711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.56022310256958, "step": 3000}
{"episode_reward": 958.3812051633158, "episode": 4.0, "batch_reward": 0.6249674683213234, "critic_loss": 2.602515665113926, "actor_loss": -104.5678367767334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10704016685486, "step": 4000}
{"episode_reward": 239.2144832336895, "episode": 5.0, "batch_reward": 0.5008813665807247, "critic_loss": 4.168507120251656, "actor_loss": -110.19216519165039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09749484062195, "step": 5000}
{"episode_reward": 29.352427361341793, "episode": 6.0, "batch_reward": 0.4178431618213654, "critic_loss": 3.3760593029260635, "actor_loss": -113.90526539611817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092607736587524, "step": 6000}
{"episode_reward": 50.23132425585412, "episode": 7.0, "batch_reward": 0.35957991307973863, "critic_loss": 2.8699649370908737, "actor_loss": -117.11660479736328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09843111038208, "step": 7000}
{"episode_reward": 38.27145904104308, "episode": 8.0, "batch_reward": 0.31513439953327177, "critic_loss": 2.327643409371376, "actor_loss": -114.39266569519043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11372971534729, "step": 8000}
{"episode_reward": 22.81087145105446, "episode": 9.0, "batch_reward": 0.28094865004718306, "critic_loss": 2.532358768224716, "actor_loss": -116.75430137634277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.096359729766846, "step": 9000}
{"episode_reward": 20.013797680158085, "episode": 10.0, "batch_reward": 0.2816310580819845, "critic_loss": 4.306099123597145, "actor_loss": -117.74590396118164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087199687957764, "step": 10000}
{"episode_reward": 556.7651924325567, "episode": 11.0, "batch_reward": 0.2798934472054243, "critic_loss": 3.9798261451721193, "actor_loss": -118.80165911865234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.58367609977722, "step": 11000}
{"episode_reward": 20.436930677486753, "episode": 12.0, "batch_reward": 0.27885113324224947, "critic_loss": 3.6719850710630415, "actor_loss": -118.31421795654298, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.103042364120483, "step": 12000}
{"episode_reward": 302.44313782390276, "episode": 13.0, "batch_reward": 0.26279193641245363, "critic_loss": 4.16457411468029, "actor_loss": -115.63996974182129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094415187835693, "step": 13000}
{"episode_reward": 174.413281181618, "episode": 14.0, "batch_reward": 0.2602117232531309, "critic_loss": 5.180076382637024, "actor_loss": -113.458625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.095791816711426, "step": 14000}
{"episode_reward": 111.9165789492842, "episode": 15.0, "batch_reward": 0.25836383336782454, "critic_loss": 7.062912128210067, "actor_loss": -113.23760307312011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082913398742676, "step": 15000}
{"episode_reward": 482.1791703773988, "episode": 16.0, "batch_reward": 0.2799193987697363, "critic_loss": 8.633887242317199, "actor_loss": -113.84352787780762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.080334901809692, "step": 16000}
{"episode_reward": 492.28078712137886, "episode": 17.0, "batch_reward": 0.2887794794589281, "critic_loss": 11.122246984004974, "actor_loss": -114.58816242980957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.088624000549316, "step": 17000}
{"episode_reward": 442.9742256275597, "episode": 18.0, "batch_reward": 0.297798525467515, "critic_loss": 11.58407737827301, "actor_loss": -114.90808535766601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077779293060303, "step": 18000}
{"episode_reward": 531.3047932536757, "episode": 19.0, "batch_reward": 0.29903255043923854, "critic_loss": 10.535960480213165, "actor_loss": -114.76900302124024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.101240873336792, "step": 19000}
{"episode_reward": 71.76159340331013, "episode": 20.0, "batch_reward": 0.3043693054318428, "critic_loss": 9.409893193721771, "actor_loss": -116.92319830322266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07605004310608, "step": 20000}
{"episode_reward": 780.3588138979209, "episode": 21.0, "batch_reward": 0.3298167795687914, "critic_loss": 9.715496032714844, "actor_loss": -120.85220695495606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.45446729660034, "step": 21000}
{"episode_reward": 853.3597802261005, "episode": 22.0, "batch_reward": 0.354245998442173, "critic_loss": 9.303557232379914, "actor_loss": -122.2569206085205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.076337814331055, "step": 22000}
{"episode_reward": 869.0481867103712, "episode": 23.0, "batch_reward": 0.37444631397724154, "critic_loss": 8.991435475826263, "actor_loss": -127.78239883422852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.41187071800232, "step": 23000}
{"episode_reward": 576.9113947197787, "episode": 24.0, "batch_reward": 0.3843573589324951, "critic_loss": 8.072101408481599, "actor_loss": -128.27458856201173, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05688166618347, "step": 24000}
{"episode_reward": 877.1476198897403, "episode": 25.0, "batch_reward": 0.4058423954546452, "critic_loss": 6.679800416469574, "actor_loss": -128.75425114440918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0450119972229, "step": 25000}
{"episode_reward": 911.8392244304904, "episode": 26.0, "batch_reward": 0.4201711364984512, "critic_loss": 5.406034358978271, "actor_loss": -129.49775563049317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085102081298828, "step": 26000}
{"episode_reward": 454.0525211821011, "episode": 27.0, "batch_reward": 0.41882564544677736, "critic_loss": 4.65781785607338, "actor_loss": -128.58316232299805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.40622591972351, "step": 27000}
{"episode_reward": 337.6859453755573, "episode": 28.0, "batch_reward": 0.42388213181495665, "critic_loss": 4.075654567480087, "actor_loss": -127.84805905151367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08432674407959, "step": 28000}
{"episode_reward": 862.4120368573202, "episode": 29.0, "batch_reward": 0.44030091327428816, "critic_loss": 3.517402452945709, "actor_loss": -127.40093266296387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0591881275177, "step": 29000}
{"episode_reward": 954.220541659749, "episode": 30.0, "batch_reward": 0.4536718873381615, "critic_loss": 3.127362071633339, "actor_loss": -125.99603926086425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.073404788970947, "step": 30000}
{"episode_reward": 761.0287551808059, "episode": 31.0, "batch_reward": 0.4678006345331669, "critic_loss": 2.4823377170562746, "actor_loss": -123.96539628601074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.415502309799194, "step": 31000}
{"episode_reward": 948.3215298095872, "episode": 32.0, "batch_reward": 0.48177566841244696, "critic_loss": 2.0921688830852507, "actor_loss": -124.36420655822754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.086780548095703, "step": 32000}
{"episode_reward": 942.8978719630769, "episode": 33.0, "batch_reward": 0.49689773228764533, "critic_loss": 1.8942049946784973, "actor_loss": -123.69965710449219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087507486343384, "step": 33000}
{"episode_reward": 974.8753289255612, "episode": 34.0, "batch_reward": 0.5126924678087235, "critic_loss": 1.67052188038826, "actor_loss": -121.11396047973633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08614158630371, "step": 34000}
{"episode_reward": 970.2901093852378, "episode": 35.0, "batch_reward": 0.5261747755110264, "critic_loss": 1.5875176196694374, "actor_loss": -122.26715782165527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08198595046997, "step": 35000}
{"episode_reward": 952.8733972809155, "episode": 36.0, "batch_reward": 0.5385302780866623, "critic_loss": 1.4470561384558678, "actor_loss": -119.34013290405274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082889080047607, "step": 36000}
{"episode_reward": 943.8683373574111, "episode": 37.0, "batch_reward": 0.5472717079222202, "critic_loss": 1.3506439554095269, "actor_loss": -119.05034704589843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092595100402832, "step": 37000}
{"episode_reward": 890.7042780614536, "episode": 38.0, "batch_reward": 0.55573427349329, "critic_loss": 1.1957017943263053, "actor_loss": -118.44960890197754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094127416610718, "step": 38000}
{"episode_reward": 954.4559218140455, "episode": 39.0, "batch_reward": 0.5686124849617481, "critic_loss": 1.1727418720722198, "actor_loss": -117.14706747436523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.090140342712402, "step": 39000}
{"episode_reward": 971.3639324508912, "episode": 40.0, "batch_reward": 0.577627552062273, "critic_loss": 1.1683979535102844, "actor_loss": -115.37488513183594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097708225250244, "step": 40000}
{"episode_reward": 948.1405107391204, "episode": 41.0, "batch_reward": 0.5849564273357392, "critic_loss": 1.1577839830517769, "actor_loss": -114.96061233520508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.40713596343994, "step": 41000}
{"episode_reward": 952.0392133865296, "episode": 42.0, "batch_reward": 0.594571717530489, "critic_loss": 1.2386888585686684, "actor_loss": -113.8001965789795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092148542404175, "step": 42000}
{"episode_reward": 902.1140163778831, "episode": 43.0, "batch_reward": 0.6032736760079861, "critic_loss": 0.9281589018106461, "actor_loss": -112.35782460021973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.075477838516235, "step": 43000}
{"episode_reward": 931.6668576645745, "episode": 44.0, "batch_reward": 0.609608953744173, "critic_loss": 0.8340694279968739, "actor_loss": -111.45273638916015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092944145202637, "step": 44000}
{"episode_reward": 947.2231011880325, "episode": 45.0, "batch_reward": 0.6163129575252533, "critic_loss": 0.8827705662846566, "actor_loss": -110.57805142211915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.078548908233643, "step": 45000}
{"episode_reward": 885.2939118249911, "episode": 46.0, "batch_reward": 0.6237238718867302, "critic_loss": 0.8300310502648354, "actor_loss": -110.02839640808105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07749056816101, "step": 46000}
{"episode_reward": 972.0968629512985, "episode": 47.0, "batch_reward": 0.6301799547076226, "critic_loss": 0.7910378248095512, "actor_loss": -108.47485647583008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08594822883606, "step": 47000}
{"episode_reward": 959.3450803529706, "episode": 48.0, "batch_reward": 0.6369046816825866, "critic_loss": 0.7366528972387314, "actor_loss": -108.39590354919433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.078368425369263, "step": 48000}
{"episode_reward": 954.528095805063, "episode": 49.0, "batch_reward": 0.6461299585700035, "critic_loss": 0.7332612761259079, "actor_loss": -106.60525714111328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091878175735474, "step": 49000}
{"episode_reward": 957.3226255244771, "episode": 50.0, "batch_reward": 0.6508382672071457, "critic_loss": 0.8005370995700359, "actor_loss": -106.08177545166015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085357189178467, "step": 50000}
{"episode_reward": 955.1931961081185, "episode": 51.0, "batch_reward": 0.6575906320810317, "critic_loss": 0.7524004947245121, "actor_loss": -105.90704298400878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.378774881362915, "step": 51000}
{"episode_reward": 974.8068621463532, "episode": 52.0, "batch_reward": 0.6640509307384491, "critic_loss": 0.7260789231061936, "actor_loss": -105.65565968322754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.080235481262207, "step": 52000}
{"episode_reward": 980.7284651857592, "episode": 53.0, "batch_reward": 0.6691714919805527, "critic_loss": 0.6788154156804085, "actor_loss": -104.27966578674317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08269429206848, "step": 53000}
{"episode_reward": 929.709969379158, "episode": 54.0, "batch_reward": 0.6738076686263085, "critic_loss": 0.6517404969632625, "actor_loss": -103.92952967834472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.083407163619995, "step": 54000}
{"episode_reward": 980.9234869050015, "episode": 55.0, "batch_reward": 0.6800968376398087, "critic_loss": 0.6247093527615071, "actor_loss": -103.22663331604004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.086726665496826, "step": 55000}
{"episode_reward": 979.0771810106615, "episode": 56.0, "batch_reward": 0.6840072748064995, "critic_loss": 0.5972464916408062, "actor_loss": -102.72354342651367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08837389945984, "step": 56000}
{"episode_reward": 947.9135470922402, "episode": 57.0, "batch_reward": 0.6890100668668747, "critic_loss": 0.6460083693563938, "actor_loss": -102.59852726745605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.090219259262085, "step": 57000}
{"episode_reward": 960.0756797792857, "episode": 58.0, "batch_reward": 0.6944803588986397, "critic_loss": 0.6087305748164654, "actor_loss": -101.82221543884278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098492860794067, "step": 58000}
{"episode_reward": 975.3065236770835, "episode": 59.0, "batch_reward": 0.7011356528401375, "critic_loss": 0.6215378951132298, "actor_loss": -101.9834147644043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08530068397522, "step": 59000}
{"episode_reward": 932.2721509120779, "episode": 60.0, "batch_reward": 0.7036097291111946, "critic_loss": 0.5845693640708923, "actor_loss": -101.5914995880127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.101447820663452, "step": 60000}
{"episode_reward": 946.6087878245285, "episode": 61.0, "batch_reward": 0.705021676003933, "critic_loss": 0.5714844868481159, "actor_loss": -100.64201414489746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.40581035614014, "step": 61000}
{"episode_reward": 951.9474675135702, "episode": 62.0, "batch_reward": 0.709179476082325, "critic_loss": 0.5669144193083048, "actor_loss": -100.44858016967774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.095425128936768, "step": 62000}
{"episode_reward": 941.5028080301013, "episode": 63.0, "batch_reward": 0.7160853704810143, "critic_loss": 0.6007922442257404, "actor_loss": -99.9895968322754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100498914718628, "step": 63000}
{"episode_reward": 924.0531172197452, "episode": 64.0, "batch_reward": 0.7186075893044471, "critic_loss": 0.590035218924284, "actor_loss": -99.45138301086426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.105087518692017, "step": 64000}
{"episode_reward": 988.3959380340663, "episode": 65.0, "batch_reward": 0.7230141240954399, "critic_loss": 0.5495959661453962, "actor_loss": -99.21912007141113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109095335006714, "step": 65000}
{"episode_reward": 937.1898728759467, "episode": 66.0, "batch_reward": 0.7264684353470803, "critic_loss": 0.5508053738325834, "actor_loss": -99.09469653320312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.102563858032227, "step": 66000}
{"episode_reward": 966.4347328045625, "episode": 67.0, "batch_reward": 0.7287944365739822, "critic_loss": 0.535044057816267, "actor_loss": -98.88159025573731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.084040641784668, "step": 67000}
{"episode_reward": 955.5864888787717, "episode": 68.0, "batch_reward": 0.7334501374959945, "critic_loss": 0.5714615499675274, "actor_loss": -98.46804005432129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.110453605651855, "step": 68000}
{"episode_reward": 973.1642115458079, "episode": 69.0, "batch_reward": 0.7369617903828621, "critic_loss": 0.5074375988692045, "actor_loss": -98.28065232849121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094200611114502, "step": 69000}
{"episode_reward": 873.4222812684505, "episode": 70.0, "batch_reward": 0.7362309391498566, "critic_loss": 0.5272612542659044, "actor_loss": -98.05462577819824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092795610427856, "step": 70000}
{"episode_reward": 956.1704164312686, "episode": 71.0, "batch_reward": 0.7418457924723625, "critic_loss": 0.5141228890269994, "actor_loss": -97.57471423339844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.4209508895874, "step": 71000}
{"episode_reward": 906.6194307553092, "episode": 72.0, "batch_reward": 0.7422784628868103, "critic_loss": 0.5355270850658417, "actor_loss": -97.50264456176758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09456467628479, "step": 72000}
{"episode_reward": 953.2101699290286, "episode": 73.0, "batch_reward": 0.7479032119512558, "critic_loss": 0.5121407062113285, "actor_loss": -97.17985475158692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093604564666748, "step": 73000}
{"episode_reward": 952.1857373091404, "episode": 74.0, "batch_reward": 0.7490598642826081, "critic_loss": 0.521949918538332, "actor_loss": -96.89033116149902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09550166130066, "step": 74000}
{"episode_reward": 975.3876387819513, "episode": 75.0, "batch_reward": 0.7528088427186013, "critic_loss": 0.5231929139792919, "actor_loss": -96.69762680053711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.090152502059937, "step": 75000}
{"episode_reward": 926.187237136961, "episode": 76.0, "batch_reward": 0.7541751247048378, "critic_loss": 0.4608870239406824, "actor_loss": -96.52669302368164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09011745452881, "step": 76000}
{"episode_reward": 961.0932698022325, "episode": 77.0, "batch_reward": 0.7565857778191567, "critic_loss": 0.4593793904185295, "actor_loss": -96.41568426513672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097349166870117, "step": 77000}
{"episode_reward": 963.8336495919996, "episode": 78.0, "batch_reward": 0.7607576693296433, "critic_loss": 0.48186721704900265, "actor_loss": -96.54961885070801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08924102783203, "step": 78000}
{"episode_reward": 983.9056842343465, "episode": 79.0, "batch_reward": 0.7636876553297043, "critic_loss": 0.4351821119338274, "actor_loss": -96.20250262451172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.103580236434937, "step": 79000}
{"episode_reward": 988.8120118898012, "episode": 80.0, "batch_reward": 0.7659894914031029, "critic_loss": 0.41469515404105184, "actor_loss": -96.10422451782226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097684621810913, "step": 80000}
{"episode_reward": 966.6237353914727, "episode": 81.0, "batch_reward": 0.7690648456215858, "critic_loss": 0.4331744562983513, "actor_loss": -95.9620263671875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.421144247055054, "step": 81000}
{"episode_reward": 953.8817619002697, "episode": 82.0, "batch_reward": 0.7690892641544342, "critic_loss": 0.4229230642914772, "actor_loss": -95.84675856018066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10229516029358, "step": 82000}
{"episode_reward": 943.5295404043226, "episode": 83.0, "batch_reward": 0.774103608071804, "critic_loss": 0.4045564561635256, "actor_loss": -95.83647033691406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.090402603149414, "step": 83000}
{"episode_reward": 976.9826039125035, "episode": 84.0, "batch_reward": 0.7757457581758499, "critic_loss": 0.38081831158697604, "actor_loss": -95.66417938232422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100512981414795, "step": 84000}
{"episode_reward": 986.9696753427071, "episode": 85.0, "batch_reward": 0.7766356157660484, "critic_loss": 0.3987689397782087, "actor_loss": -95.73838508605957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.096006870269775, "step": 85000}
{"episode_reward": 946.2972328380506, "episode": 86.0, "batch_reward": 0.7781332727074624, "critic_loss": 0.38771768207848073, "actor_loss": -95.52435758972167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094157218933105, "step": 86000}
{"episode_reward": 941.1446495744492, "episode": 87.0, "batch_reward": 0.7810553391575813, "critic_loss": 0.3736444068104029, "actor_loss": -95.44686344909668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098630666732788, "step": 87000}
{"episode_reward": 971.9646207135254, "episode": 88.0, "batch_reward": 0.7853444574475288, "critic_loss": 0.35791473084688186, "actor_loss": -95.43830529785156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.096328020095825, "step": 88000}
{"episode_reward": 977.0156754865984, "episode": 89.0, "batch_reward": 0.7862768241167069, "critic_loss": 0.36171774508059024, "actor_loss": -95.28216764831544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094372987747192, "step": 89000}
{"episode_reward": 958.3226785555479, "episode": 90.0, "batch_reward": 0.7871189519166947, "critic_loss": 0.34929641358554364, "actor_loss": -95.05184298706055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091167211532593, "step": 90000}
{"episode_reward": 944.823840606686, "episode": 91.0, "batch_reward": 0.7878644418716431, "critic_loss": 0.3772546147406101, "actor_loss": -94.91990481567383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.39470362663269, "step": 91000}
{"episode_reward": 933.2282251363329, "episode": 92.0, "batch_reward": 0.7892541791200638, "critic_loss": 0.37016540879011156, "actor_loss": -94.92268148803711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09196138381958, "step": 92000}
{"episode_reward": 967.4195527131815, "episode": 93.0, "batch_reward": 0.7920352955460548, "critic_loss": 0.3845739352852106, "actor_loss": -94.9250884552002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097877025604248, "step": 93000}
{"episode_reward": 854.2407034276195, "episode": 94.0, "batch_reward": 0.7929071811437607, "critic_loss": 0.38321169766783714, "actor_loss": -94.90049493408203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.089571952819824, "step": 94000}
{"episode_reward": 969.4447544228052, "episode": 95.0, "batch_reward": 0.7949801784753799, "critic_loss": 0.40843843266367913, "actor_loss": -94.8069342956543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094849109649658, "step": 95000}
{"episode_reward": 953.6969310383637, "episode": 96.0, "batch_reward": 0.7979031859636306, "critic_loss": 0.4584680708944798, "actor_loss": -94.79813737487792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087238550186157, "step": 96000}
{"episode_reward": 986.07770809321, "episode": 97.0, "batch_reward": 0.7974101970791817, "critic_loss": 0.6882503702491521, "actor_loss": -94.81654830932617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.095067024230957, "step": 97000}
{"episode_reward": 981.3540950861064, "episode": 98.0, "batch_reward": 0.8026861885786056, "critic_loss": 1.0398421315401793, "actor_loss": -95.00179989624023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.104506731033325, "step": 98000}
{"episode_reward": 978.4560458963203, "episode": 99.0, "batch_reward": 0.801759494125843, "critic_loss": 2.003439189568162, "actor_loss": -95.52675782775879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091242790222168, "step": 99000}
{"episode_reward": 984.354280105539, "episode": 100.0, "batch_reward": 0.804923786342144, "critic_loss": 6.408304501891136, "actor_loss": -97.33771101379395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098825216293335, "step": 100000}
{"episode_reward": 914.4363088707006, "episode": 101.0, "batch_reward": 0.7997531592845917, "critic_loss": 12.995044717669487, "actor_loss": -101.42659136962891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.51306104660034, "step": 101000}
{"episode_reward": 34.71915250036123, "episode": 102.0, "batch_reward": 0.7938289447426796, "critic_loss": 18.066073694944382, "actor_loss": -106.28095962524414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.125746250152588, "step": 102000}
{"episode_reward": 75.9590985659298, "episode": 103.0, "batch_reward": 0.787530100941658, "critic_loss": 19.610516258239745, "actor_loss": -111.07707160949707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.113346099853516, "step": 103000}
{"episode_reward": 28.447756717725305, "episode": 104.0, "batch_reward": 0.7819447098970413, "critic_loss": 17.64223375082016, "actor_loss": -112.67705261230469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11471462249756, "step": 104000}
{"episode_reward": 46.93268312094863, "episode": 105.0, "batch_reward": 0.7709236145615578, "critic_loss": 14.799846827983856, "actor_loss": -115.98652859497071, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.096976280212402, "step": 105000}
{"episode_reward": 23.8092086601849, "episode": 106.0, "batch_reward": 0.7651339889168739, "critic_loss": 13.311168382883071, "actor_loss": -117.47041523742676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09757685661316, "step": 106000}
{"episode_reward": 32.71843323870891, "episode": 107.0, "batch_reward": 0.7565537109971047, "critic_loss": 13.250052427768708, "actor_loss": -120.96181958007813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11970591545105, "step": 107000}
{"episode_reward": 64.62235598284093, "episode": 108.0, "batch_reward": 0.7515873763561248, "critic_loss": 15.698465571403503, "actor_loss": -128.24059062194823, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.105287551879883, "step": 108000}
{"episode_reward": 32.56289084575299, "episode": 109.0, "batch_reward": 0.7469354823827744, "critic_loss": 20.893864804267885, "actor_loss": -141.01763818359376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.112793684005737, "step": 109000}
{"episode_reward": 39.694425788873296, "episode": 110.0, "batch_reward": 0.739301717877388, "critic_loss": 27.539640259742736, "actor_loss": -159.12909687805177, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.103230237960815, "step": 110000}
{"episode_reward": 41.59043552726334, "episode": 111.0, "batch_reward": 0.731039970934391, "critic_loss": 33.65323074913025, "actor_loss": -183.17382791137695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.72656869888306, "step": 111000}
{"episode_reward": 24.792386196357143, "episode": 112.0, "batch_reward": 0.7267699654698372, "critic_loss": 38.700635669708255, "actor_loss": -200.2413101196289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.137348413467407, "step": 112000}
{"episode_reward": 22.42044451308128, "episode": 113.0, "batch_reward": 0.7209068880677223, "critic_loss": 40.047469047546386, "actor_loss": -211.84823307800292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.128786087036133, "step": 113000}
{"episode_reward": 18.130759204655508, "episode": 114.0, "batch_reward": 0.7137936667203904, "critic_loss": 38.90168334007263, "actor_loss": -207.4823133239746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.133506774902344, "step": 114000}
{"episode_reward": 19.749515034971868, "episode": 115.0, "batch_reward": 0.7082392076253891, "critic_loss": 34.569159668922424, "actor_loss": -212.86515798950197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.129513263702393, "step": 115000}
{"episode_reward": 57.70482805661141, "episode": 116.0, "batch_reward": 0.702345463514328, "critic_loss": 31.345286901473997, "actor_loss": -209.7588090057373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.139832735061646, "step": 116000}
{"episode_reward": 10.603518271632677, "episode": 117.0, "batch_reward": 0.6961488906145096, "critic_loss": 31.16566430568695, "actor_loss": -208.99203433227538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14879608154297, "step": 117000}
{"episode_reward": 11.236611620738683, "episode": 118.0, "batch_reward": 0.6901586187481881, "critic_loss": 35.84601383209228, "actor_loss": -214.05367848205566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.142144918441772, "step": 118000}
{"episode_reward": 17.431994651432756, "episode": 119.0, "batch_reward": 0.6841999555826187, "critic_loss": 41.28120715904236, "actor_loss": -221.26228588867187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.129502058029175, "step": 119000}
{"episode_reward": 25.53140383916531, "episode": 120.0, "batch_reward": 0.677955669939518, "critic_loss": 42.55704619026184, "actor_loss": -226.7682135620117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.123801946640015, "step": 120000}
{"episode_reward": 60.813379944989755, "episode": 121.0, "batch_reward": 0.674155422270298, "critic_loss": 42.676755352020265, "actor_loss": -238.25135696411132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.54755997657776, "step": 121000}
{"episode_reward": 340.18455322906783, "episode": 122.0, "batch_reward": 0.672772648692131, "critic_loss": 41.35616304397583, "actor_loss": -231.58843908691406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.125812768936157, "step": 122000}
{"episode_reward": 180.72943755038202, "episode": 123.0, "batch_reward": 0.6688680682182312, "critic_loss": 38.84676429462433, "actor_loss": -224.0896908416748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11898112297058, "step": 123000}
{"episode_reward": 252.0906373790515, "episode": 124.0, "batch_reward": 0.6670293831825256, "critic_loss": 34.164923358917235, "actor_loss": -221.7480796661377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09705877304077, "step": 124000}
{"episode_reward": 953.4449895872949, "episode": 125.0, "batch_reward": 0.6715667281150818, "critic_loss": 25.810679246902467, "actor_loss": -230.37178903198242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10203528404236, "step": 125000}
{"episode_reward": 947.518407388455, "episode": 126.0, "batch_reward": 0.6710941771864891, "critic_loss": 21.7240773229599, "actor_loss": -220.49898147583008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11915946006775, "step": 126000}
{"episode_reward": 875.908153470577, "episode": 127.0, "batch_reward": 0.6730891079306602, "critic_loss": 19.34977427196503, "actor_loss": -214.5567140350342, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.116832971572876, "step": 127000}
{"episode_reward": 912.0175823069975, "episode": 128.0, "batch_reward": 0.6768176007270813, "critic_loss": 16.3194165520668, "actor_loss": -219.5953883972168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094191551208496, "step": 128000}
{"episode_reward": 963.91514847411, "episode": 129.0, "batch_reward": 0.6798682829737663, "critic_loss": 15.16300207233429, "actor_loss": -214.52320600891113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092209100723267, "step": 129000}
{"episode_reward": 915.6470150623804, "episode": 130.0, "batch_reward": 0.6788109940290451, "critic_loss": 13.307810736656188, "actor_loss": -206.29862084960936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.104772090911865, "step": 130000}
{"episode_reward": 925.5047854984979, "episode": 131.0, "batch_reward": 0.6820728932619095, "critic_loss": 11.303485069751739, "actor_loss": -213.64591108703613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.420326709747314, "step": 131000}
{"episode_reward": 909.7492499272367, "episode": 132.0, "batch_reward": 0.6813083653450012, "critic_loss": 9.183154744386673, "actor_loss": -199.46416456604004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.095767736434937, "step": 132000}
{"episode_reward": 956.4438472040894, "episode": 133.0, "batch_reward": 0.6853231148123741, "critic_loss": 7.241807376623154, "actor_loss": -204.30360961914062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091164350509644, "step": 133000}
{"episode_reward": 936.243785397509, "episode": 134.0, "batch_reward": 0.684689278960228, "critic_loss": 5.911663520097733, "actor_loss": -198.02232431030274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.089589595794678, "step": 134000}
{"episode_reward": 937.2511887009891, "episode": 135.0, "batch_reward": 0.6892755636572838, "critic_loss": 4.897850184440613, "actor_loss": -193.18173210144042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09275770187378, "step": 135000}
{"episode_reward": 968.6973524886723, "episode": 136.0, "batch_reward": 0.6926697694063186, "critic_loss": 4.291639105439186, "actor_loss": -190.15246672058106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10554337501526, "step": 136000}
{"episode_reward": 934.2790833248727, "episode": 137.0, "batch_reward": 0.6930816146731377, "critic_loss": 3.5378347004652024, "actor_loss": -182.75046478271486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092888593673706, "step": 137000}
{"episode_reward": 981.9246201488126, "episode": 138.0, "batch_reward": 0.6956527092456818, "critic_loss": 3.2297940505743026, "actor_loss": -184.3674408721924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10813307762146, "step": 138000}
{"episode_reward": 979.230477011626, "episode": 139.0, "batch_reward": 0.6959995959401131, "critic_loss": 2.8005617727041243, "actor_loss": -181.32064189147948, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08845567703247, "step": 139000}
{"episode_reward": 952.0071910519524, "episode": 140.0, "batch_reward": 0.6996651428937912, "critic_loss": 2.364823175787926, "actor_loss": -176.29897840881347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09298348426819, "step": 140000}
{"episode_reward": 884.3813429327289, "episode": 141.0, "batch_reward": 0.6983450704813003, "critic_loss": 2.2580836606025696, "actor_loss": -172.30428094482423, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.42961645126343, "step": 141000}
{"episode_reward": 971.3695389646541, "episode": 142.0, "batch_reward": 0.7029602323770523, "critic_loss": 2.078239156961441, "actor_loss": -168.82429815673828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098238468170166, "step": 142000}
{"episode_reward": 979.4080435834194, "episode": 143.0, "batch_reward": 0.7032319753170013, "critic_loss": 1.7826986069083213, "actor_loss": -165.07249963378905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09384036064148, "step": 143000}
{"episode_reward": 915.6433335705909, "episode": 144.0, "batch_reward": 0.7059663080573082, "critic_loss": 1.6769962297081948, "actor_loss": -163.56971038818358, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09956407546997, "step": 144000}
{"episode_reward": 948.4186557273939, "episode": 145.0, "batch_reward": 0.7075572980046272, "critic_loss": 1.4117041228413583, "actor_loss": -158.41844802856446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09738254547119, "step": 145000}
{"episode_reward": 973.982224629283, "episode": 146.0, "batch_reward": 0.7084394037723541, "critic_loss": 1.3397063081264495, "actor_loss": -156.23190740966797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.090678691864014, "step": 146000}
{"episode_reward": 988.136117052321, "episode": 147.0, "batch_reward": 0.7118965423107148, "critic_loss": 1.2410857427120208, "actor_loss": -153.82057405090333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0942165851593, "step": 147000}
{"episode_reward": 961.9803060715292, "episode": 148.0, "batch_reward": 0.7126319281458855, "critic_loss": 1.1164580888450146, "actor_loss": -150.7482981109619, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093589544296265, "step": 148000}
{"episode_reward": 959.662217993575, "episode": 149.0, "batch_reward": 0.713554825425148, "critic_loss": 0.9924359001517296, "actor_loss": -147.67768836975097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108047008514404, "step": 149000}
{"episode_reward": 975.6834369760486, "episode": 150.0, "batch_reward": 0.7162377135157585, "critic_loss": 0.9416672271192074, "actor_loss": -146.5655097503662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
