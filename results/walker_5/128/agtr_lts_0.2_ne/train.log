{"episode_reward": 0.0, "episode": 1.0, "duration": 20.67230534553528, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.795546293258667, "step": 2000}
{"episode_reward": 632.427646246406, "episode": 3.0, "batch_reward": 0.3619021944411002, "critic_loss": 0.7590751502564765, "actor_loss": -74.83672427100723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.32343602180481, "step": 3000}
{"episode_reward": 429.48417416507175, "episode": 4.0, "batch_reward": 0.4315768782794476, "critic_loss": 1.1184458336830139, "actor_loss": -85.25347750854492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.33907389640808, "step": 4000}
{"episode_reward": 729.6043734614998, "episode": 5.0, "batch_reward": 0.4174107165038586, "critic_loss": 1.363985888659954, "actor_loss": -86.32331385803222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.35165023803711, "step": 5000}
{"episode_reward": 25.434391450264616, "episode": 6.0, "batch_reward": 0.3447186459004879, "critic_loss": 1.0968966277241707, "actor_loss": -88.38458506774903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3714382648468, "step": 6000}
{"episode_reward": 25.046590673965387, "episode": 7.0, "batch_reward": 0.29329578386247157, "critic_loss": 1.2150468775033951, "actor_loss": -90.70397358703613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.375575304031372, "step": 7000}
{"episode_reward": 25.073405831232588, "episode": 8.0, "batch_reward": 0.261473146468401, "critic_loss": 1.8735717109441756, "actor_loss": -90.63746075439452, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.340980291366577, "step": 8000}
{"episode_reward": 66.83491077390433, "episode": 9.0, "batch_reward": 0.23714004962146282, "critic_loss": 2.037124053299427, "actor_loss": -92.79155628967285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.36113739013672, "step": 9000}
{"episode_reward": 41.23368188884907, "episode": 10.0, "batch_reward": 0.22634272484481335, "critic_loss": 3.176655723452568, "actor_loss": -92.17899435424805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.382639408111572, "step": 10000}
{"episode_reward": 322.23472688940996, "episode": 11.0, "batch_reward": 0.23418828976154327, "critic_loss": 4.682204245090484, "actor_loss": -94.77521003723145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.88731861114502, "step": 11000}
{"episode_reward": 267.73870470099683, "episode": 12.0, "batch_reward": 0.25791854207217696, "critic_loss": 5.711086529493332, "actor_loss": -98.89735679626465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.38042640686035, "step": 12000}
{"episode_reward": 729.3014447306882, "episode": 13.0, "batch_reward": 0.2979262228906155, "critic_loss": 6.307767036914825, "actor_loss": -101.46070622253418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.367043495178223, "step": 13000}
{"episode_reward": 817.8852462015948, "episode": 14.0, "batch_reward": 0.338456443965435, "critic_loss": 6.02447803735733, "actor_loss": -104.39252008056641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.362595319747925, "step": 14000}
{"episode_reward": 754.2450951579486, "episode": 15.0, "batch_reward": 0.3520949368774891, "critic_loss": 5.379656296730041, "actor_loss": -108.55646760559083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34354853630066, "step": 15000}
{"episode_reward": 480.37553508881473, "episode": 16.0, "batch_reward": 0.3732768735289574, "critic_loss": 4.0732217285633086, "actor_loss": -110.3833261566162, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.358932495117188, "step": 16000}
{"episode_reward": 814.6917276366327, "episode": 17.0, "batch_reward": 0.3980913598835468, "critic_loss": 3.40237828040123, "actor_loss": -111.77477330017089, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.344181776046753, "step": 17000}
{"episode_reward": 782.3460416250929, "episode": 18.0, "batch_reward": 0.4225870393514633, "critic_loss": 3.166008808851242, "actor_loss": -111.43710888671875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34281277656555, "step": 18000}
{"episode_reward": 855.6130109323467, "episode": 19.0, "batch_reward": 0.44590966966748236, "critic_loss": 3.1070349481105803, "actor_loss": -111.3768038635254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34324884414673, "step": 19000}
{"episode_reward": 806.6877597148954, "episode": 20.0, "batch_reward": 0.46649136263132096, "critic_loss": 2.922305727005005, "actor_loss": -112.77984396362305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.348617553710938, "step": 20000}
{"episode_reward": 870.0099372549583, "episode": 21.0, "batch_reward": 0.4831976612508297, "critic_loss": 2.785082644224167, "actor_loss": -114.24121870422363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.779308557510376, "step": 21000}
{"episode_reward": 739.4887322055943, "episode": 22.0, "batch_reward": 0.49683340334892273, "critic_loss": 2.4280968191623686, "actor_loss": -111.61234748840332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.375969409942627, "step": 22000}
{"episode_reward": 822.9291484425506, "episode": 23.0, "batch_reward": 0.5121690172553063, "critic_loss": 1.9486187057495117, "actor_loss": -113.25175749206542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.373989820480347, "step": 23000}
{"episode_reward": 843.093243996967, "episode": 24.0, "batch_reward": 0.5230247387290001, "critic_loss": 1.5190677149295806, "actor_loss": -111.10396656799317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.378185033798218, "step": 24000}
{"episode_reward": 741.7995725383958, "episode": 25.0, "batch_reward": 0.5279663034379483, "critic_loss": 1.349202243089676, "actor_loss": -109.82013684082031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.384196996688843, "step": 25000}
{"episode_reward": 710.2321549508499, "episode": 26.0, "batch_reward": 0.5378914634883404, "critic_loss": 1.2509640026688575, "actor_loss": -109.50377253723144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.30680751800537, "step": 26000}
{"episode_reward": 791.5211754421973, "episode": 27.0, "batch_reward": 0.5491941590905189, "critic_loss": 1.1278515587449074, "actor_loss": -108.38457916259766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.346464157104492, "step": 27000}
{"episode_reward": 835.3737008121415, "episode": 28.0, "batch_reward": 0.5605300634801388, "critic_loss": 0.9819052197933197, "actor_loss": -107.58040997314453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.38134789466858, "step": 28000}
{"episode_reward": 855.8267102026588, "episode": 29.0, "batch_reward": 0.5688101492822171, "critic_loss": 0.9043835126757622, "actor_loss": -106.99688566589356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.373650074005127, "step": 29000}
{"episode_reward": 849.7613965834055, "episode": 30.0, "batch_reward": 0.581938663482666, "critic_loss": 0.8683462030291558, "actor_loss": -105.58805616760255, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3580424785614, "step": 30000}
{"episode_reward": 921.012303584519, "episode": 31.0, "batch_reward": 0.5912343281507492, "critic_loss": 0.8977085534930229, "actor_loss": -103.85305545043946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.79234194755554, "step": 31000}
{"episode_reward": 850.5150211482216, "episode": 32.0, "batch_reward": 0.6008154701888562, "critic_loss": 0.8387749110460281, "actor_loss": -103.92393542480468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.371102809906006, "step": 32000}
{"episode_reward": 891.9006407589867, "episode": 33.0, "batch_reward": 0.6076092458367348, "critic_loss": 0.79175082680583, "actor_loss": -103.48994897460938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.38498306274414, "step": 33000}
{"episode_reward": 791.7181110942413, "episode": 34.0, "batch_reward": 0.6163738608360291, "critic_loss": 0.7485318195819854, "actor_loss": -101.71387022399902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.35904622077942, "step": 34000}
{"episode_reward": 848.3014807480432, "episode": 35.0, "batch_reward": 0.6227779878377915, "critic_loss": 0.7017346932590007, "actor_loss": -102.54295062255859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3567111492157, "step": 35000}
{"episode_reward": 889.7315244249312, "episode": 36.0, "batch_reward": 0.6302739765644073, "critic_loss": 0.675745563864708, "actor_loss": -100.3440233001709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34485363960266, "step": 36000}
{"episode_reward": 888.0103908304367, "episode": 37.0, "batch_reward": 0.6376028346419335, "critic_loss": 0.6589300239086151, "actor_loss": -100.18803802490234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.348013401031494, "step": 37000}
{"episode_reward": 898.3107475290432, "episode": 38.0, "batch_reward": 0.6415601506829262, "critic_loss": 0.6552437903583049, "actor_loss": -99.82597598266601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.36989736557007, "step": 38000}
{"episode_reward": 876.815540099946, "episode": 39.0, "batch_reward": 0.6506238021254539, "critic_loss": 0.635782612144947, "actor_loss": -99.03759201049805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.32706093788147, "step": 39000}
{"episode_reward": 870.8298367340359, "episode": 40.0, "batch_reward": 0.6546459290385246, "critic_loss": 0.6379422055184841, "actor_loss": -97.93256329345704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.355079174041748, "step": 40000}
{"episode_reward": 874.6627710153623, "episode": 41.0, "batch_reward": 0.6584330314397812, "critic_loss": 0.6339295569062233, "actor_loss": -97.66538716125488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.76227116584778, "step": 41000}
{"episode_reward": 914.8383047009336, "episode": 42.0, "batch_reward": 0.6686363727450371, "critic_loss": 0.6158763401508331, "actor_loss": -96.86595538330079, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.345134496688843, "step": 42000}
{"episode_reward": 907.1660239271347, "episode": 43.0, "batch_reward": 0.67014788043499, "critic_loss": 0.651918360799551, "actor_loss": -95.7774683380127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.37717890739441, "step": 43000}
{"episode_reward": 808.1018796001524, "episode": 44.0, "batch_reward": 0.6747939896583557, "critic_loss": 0.6278611987233161, "actor_loss": -95.3141700592041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34820246696472, "step": 44000}
{"episode_reward": 867.0390901928778, "episode": 45.0, "batch_reward": 0.6788929769992829, "critic_loss": 0.6086227058470249, "actor_loss": -94.97173100280762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.35939311981201, "step": 45000}
{"episode_reward": 900.0684795044424, "episode": 46.0, "batch_reward": 0.6840805670022965, "critic_loss": 0.5884495371878147, "actor_loss": -94.96714389038085, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.350897789001465, "step": 46000}
{"episode_reward": 947.7135168092998, "episode": 47.0, "batch_reward": 0.6895218315124512, "critic_loss": 0.5762056239247322, "actor_loss": -94.00008819580079, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.301422595977783, "step": 47000}
{"episode_reward": 910.7280425609898, "episode": 48.0, "batch_reward": 0.6942311217188835, "critic_loss": 0.5758341992199421, "actor_loss": -94.25847198486328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.340870141983032, "step": 48000}
{"episode_reward": 963.1871931170942, "episode": 49.0, "batch_reward": 0.700142384827137, "critic_loss": 0.5860184933394194, "actor_loss": -92.95880216979981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.371866464614868, "step": 49000}
{"episode_reward": 901.158349007298, "episode": 50.0, "batch_reward": 0.7040859003067017, "critic_loss": 0.5717470970749855, "actor_loss": -92.81039097595215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.364269018173218, "step": 50000}
{"episode_reward": 901.9375448763807, "episode": 51.0, "batch_reward": 0.7087763278484345, "critic_loss": 0.5629899020791054, "actor_loss": -92.82656568908692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.79448938369751, "step": 51000}
{"episode_reward": 958.2861362341184, "episode": 52.0, "batch_reward": 0.7143928475379944, "critic_loss": 0.5600905498862266, "actor_loss": -92.91813034057617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.379787921905518, "step": 52000}
{"episode_reward": 952.0277804471467, "episode": 53.0, "batch_reward": 0.717049058675766, "critic_loss": 0.5752572784423828, "actor_loss": -91.90535330200196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.363415002822876, "step": 53000}
{"episode_reward": 918.5377970377386, "episode": 54.0, "batch_reward": 0.722134939968586, "critic_loss": 0.5403115969002247, "actor_loss": -91.96267973327636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.32135534286499, "step": 54000}
{"episode_reward": 960.9901041421149, "episode": 55.0, "batch_reward": 0.7274931045174599, "critic_loss": 0.5555014860033989, "actor_loss": -91.58976260375977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.298106908798218, "step": 55000}
{"episode_reward": 949.1363040631832, "episode": 56.0, "batch_reward": 0.7283024487495422, "critic_loss": 0.5266480886042119, "actor_loss": -91.41329808044433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31110954284668, "step": 56000}
{"episode_reward": 937.1458297621386, "episode": 57.0, "batch_reward": 0.7345766185522079, "critic_loss": 0.5144932634532452, "actor_loss": -91.69737149047852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.299261331558228, "step": 57000}
{"episode_reward": 937.3483255531521, "episode": 58.0, "batch_reward": 0.7368576964735984, "critic_loss": 0.48401747807860374, "actor_loss": -91.09531712341308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.375544548034668, "step": 58000}
{"episode_reward": 910.0892946883387, "episode": 59.0, "batch_reward": 0.741030653834343, "critic_loss": 0.5125957673192024, "actor_loss": -91.4677055053711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.372656106948853, "step": 59000}
{"episode_reward": 903.0495821709711, "episode": 60.0, "batch_reward": 0.7439450756907463, "critic_loss": 0.4599668435305357, "actor_loss": -91.47542980957031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3709237575531, "step": 60000}
{"episode_reward": 966.3493350547092, "episode": 61.0, "batch_reward": 0.7455796360373497, "critic_loss": 0.470785347238183, "actor_loss": -90.8608019104004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.80948281288147, "step": 61000}
{"episode_reward": 965.2252979397831, "episode": 62.0, "batch_reward": 0.7492834749221802, "critic_loss": 0.4949163580238819, "actor_loss": -91.11855917358399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.36201047897339, "step": 62000}
{"episode_reward": 929.8942519106306, "episode": 63.0, "batch_reward": 0.7535827311873436, "critic_loss": 0.4941158099323511, "actor_loss": -90.91677610778808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.348273992538452, "step": 63000}
{"episode_reward": 911.913178578343, "episode": 64.0, "batch_reward": 0.7569335806369781, "critic_loss": 0.4419517346471548, "actor_loss": -90.50395755004882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.33849835395813, "step": 64000}
{"episode_reward": 955.8322967563206, "episode": 65.0, "batch_reward": 0.7580065153241158, "critic_loss": 0.4388762657344341, "actor_loss": -90.33573547363281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.365895986557007, "step": 65000}
{"episode_reward": 939.3137785119162, "episode": 66.0, "batch_reward": 0.7622365136146545, "critic_loss": 0.4442164933979511, "actor_loss": -90.55633436584472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.339052200317383, "step": 66000}
{"episode_reward": 966.2786768518087, "episode": 67.0, "batch_reward": 0.7661367747187614, "critic_loss": 0.4323789568543434, "actor_loss": -90.76605711364746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.357924938201904, "step": 67000}
{"episode_reward": 946.4585432902365, "episode": 68.0, "batch_reward": 0.7693456825017929, "critic_loss": 0.41488880389928817, "actor_loss": -90.45765698242188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.39193058013916, "step": 68000}
{"episode_reward": 967.9645810177893, "episode": 69.0, "batch_reward": 0.7721012357473374, "critic_loss": 0.3915718292593956, "actor_loss": -90.70394593811035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.352185249328613, "step": 69000}
{"episode_reward": 972.5043484899171, "episode": 70.0, "batch_reward": 0.7736264777183532, "critic_loss": 0.39956957270205024, "actor_loss": -90.80017944335937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.329083681106567, "step": 70000}
{"episode_reward": 966.606079852057, "episode": 71.0, "batch_reward": 0.7770607087612152, "critic_loss": 0.40334917967021466, "actor_loss": -90.27448956298828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.836214780807495, "step": 71000}
{"episode_reward": 939.8340393730706, "episode": 72.0, "batch_reward": 0.778692675113678, "critic_loss": 0.3869295617192984, "actor_loss": -90.70768469238281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.29420232772827, "step": 72000}
{"episode_reward": 940.9817986957635, "episode": 73.0, "batch_reward": 0.7830503242611885, "critic_loss": 0.37274114541709424, "actor_loss": -90.34855569458009, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.317684173583984, "step": 73000}
{"episode_reward": 953.3660029052357, "episode": 74.0, "batch_reward": 0.7830108742117882, "critic_loss": 0.37893458123505114, "actor_loss": -90.1697389831543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.691153526306152, "step": 74000}
{"episode_reward": 943.2636085968152, "episode": 75.0, "batch_reward": 0.7857708559036255, "critic_loss": 0.38308164566755293, "actor_loss": -90.10829776000976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.364422082901, "step": 75000}
{"episode_reward": 927.4417114337862, "episode": 76.0, "batch_reward": 0.7877546416521073, "critic_loss": 0.3736581912338734, "actor_loss": -90.02678257751465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.334447622299194, "step": 76000}
{"episode_reward": 925.8290460532569, "episode": 77.0, "batch_reward": 0.7872194610238076, "critic_loss": 0.37449477925896646, "actor_loss": -90.11500625610351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.299078702926636, "step": 77000}
{"episode_reward": 875.2846286522596, "episode": 78.0, "batch_reward": 0.7905076246261596, "critic_loss": 0.3650675542205572, "actor_loss": -90.83694596862793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31493830680847, "step": 78000}
{"episode_reward": 971.3447839656018, "episode": 79.0, "batch_reward": 0.7925612732768059, "critic_loss": 0.3617999314069748, "actor_loss": -90.34677661132812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31836748123169, "step": 79000}
{"episode_reward": 981.865319240205, "episode": 80.0, "batch_reward": 0.7953126942515373, "critic_loss": 0.371668959274888, "actor_loss": -90.335078125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.329801082611084, "step": 80000}
{"episode_reward": 964.1121205142954, "episode": 81.0, "batch_reward": 0.7966951857805252, "critic_loss": 0.3584431313127279, "actor_loss": -90.22878215026856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.797213077545166, "step": 81000}
{"episode_reward": 963.6557195057147, "episode": 82.0, "batch_reward": 0.7977152476906777, "critic_loss": 0.38148038636147974, "actor_loss": -90.26099421691895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.378164768218994, "step": 82000}
{"episode_reward": 882.6598970549984, "episode": 83.0, "batch_reward": 0.8003571643233299, "critic_loss": 0.35917259971797466, "actor_loss": -90.44783935546874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.379199743270874, "step": 83000}
{"episode_reward": 970.1198987257252, "episode": 84.0, "batch_reward": 0.8013535191416741, "critic_loss": 0.3799097561091185, "actor_loss": -90.03432234191895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.366936922073364, "step": 84000}
{"episode_reward": 977.4667285533876, "episode": 85.0, "batch_reward": 0.8025537793040276, "critic_loss": 0.38638937020301817, "actor_loss": -90.42041470336915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.398215770721436, "step": 85000}
{"episode_reward": 661.2055341310574, "episode": 86.0, "batch_reward": 0.8008545886278152, "critic_loss": 0.40238071739673614, "actor_loss": -89.80074221801758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.350757122039795, "step": 86000}
{"episode_reward": 928.1057627643448, "episode": 87.0, "batch_reward": 0.8029472060799598, "critic_loss": 0.38888910990953446, "actor_loss": -89.86484729003907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.370797634124756, "step": 87000}
{"episode_reward": 960.0355067506139, "episode": 88.0, "batch_reward": 0.8064371144771576, "critic_loss": 0.383678676456213, "actor_loss": -90.1532054901123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.390286922454834, "step": 88000}
{"episode_reward": 975.4685663267999, "episode": 89.0, "batch_reward": 0.8076272282004356, "critic_loss": 0.37701036413013933, "actor_loss": -89.76507325744629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.33850121498108, "step": 89000}
{"episode_reward": 929.0735184400248, "episode": 90.0, "batch_reward": 0.8070291396975517, "critic_loss": 0.39490514469146726, "actor_loss": -89.50476589965821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.35058879852295, "step": 90000}
{"episode_reward": 905.4514964728538, "episode": 91.0, "batch_reward": 0.8086710762381554, "critic_loss": 0.4152151320427656, "actor_loss": -89.6221449432373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.84952354431152, "step": 91000}
{"episode_reward": 882.1568324910571, "episode": 92.0, "batch_reward": 0.8102698025107383, "critic_loss": 0.3808972461521625, "actor_loss": -89.72982073974609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.349400520324707, "step": 92000}
{"episode_reward": 952.0307639324639, "episode": 93.0, "batch_reward": 0.8104534669518471, "critic_loss": 0.4235324640274048, "actor_loss": -89.97547686767578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34654998779297, "step": 93000}
{"episode_reward": 872.3798079062426, "episode": 94.0, "batch_reward": 0.8114179568886757, "critic_loss": 0.44170264442265034, "actor_loss": -89.98478811645508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.365145444869995, "step": 94000}
{"episode_reward": 893.7575081973763, "episode": 95.0, "batch_reward": 0.8120846632122993, "critic_loss": 0.4528850369900465, "actor_loss": -89.6257661895752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.36723279953003, "step": 95000}
{"episode_reward": 897.7686588570441, "episode": 96.0, "batch_reward": 0.8148700345158577, "critic_loss": 0.466572275698185, "actor_loss": -90.15970231628418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.361785888671875, "step": 96000}
{"episode_reward": 959.3827909527876, "episode": 97.0, "batch_reward": 0.8149637634754181, "critic_loss": 0.4965715174227953, "actor_loss": -89.63719302368165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.36772084236145, "step": 97000}
{"episode_reward": 916.5464759099814, "episode": 98.0, "batch_reward": 0.8179110758900643, "critic_loss": 0.4842608909755945, "actor_loss": -89.19212452697754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.362144231796265, "step": 98000}
{"episode_reward": 962.9044211523161, "episode": 99.0, "batch_reward": 0.8188926270604133, "critic_loss": 0.4775249143689871, "actor_loss": -89.72514698791504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.376484394073486, "step": 99000}
{"episode_reward": 968.3556998953164, "episode": 100.0, "batch_reward": 0.8190125980377198, "critic_loss": 0.5007291481494903, "actor_loss": -90.20927352905274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.383058547973633, "step": 100000}
{"episode_reward": 946.4050050778455, "episode": 101.0, "batch_reward": 0.820945496916771, "critic_loss": 0.4902042940109968, "actor_loss": -90.25011340332031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.834187746047974, "step": 101000}
{"episode_reward": 956.9740611847345, "episode": 102.0, "batch_reward": 0.8238083615303039, "critic_loss": 0.5019043595045805, "actor_loss": -89.77629556274414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.313260555267334, "step": 102000}
{"episode_reward": 969.8744797081572, "episode": 103.0, "batch_reward": 0.8241482084989548, "critic_loss": 0.4894204943627119, "actor_loss": -90.5024386138916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31829285621643, "step": 103000}
{"episode_reward": 974.4719636820236, "episode": 104.0, "batch_reward": 0.8267492489814758, "critic_loss": 0.48744595058262347, "actor_loss": -90.31051695251465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.324172735214233, "step": 104000}
{"episode_reward": 919.2142405941498, "episode": 105.0, "batch_reward": 0.8267956193685532, "critic_loss": 0.48062938714027403, "actor_loss": -90.65457374572753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.30898642539978, "step": 105000}
{"episode_reward": 973.4689376568172, "episode": 106.0, "batch_reward": 0.8283159793615341, "critic_loss": 0.4720429077744484, "actor_loss": -90.3291681060791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.326717376708984, "step": 106000}
{"episode_reward": 970.5535759130538, "episode": 107.0, "batch_reward": 0.8281068566441536, "critic_loss": 0.44020033940672876, "actor_loss": -90.28905865478515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.310678005218506, "step": 107000}
{"episode_reward": 943.6585197617891, "episode": 108.0, "batch_reward": 0.8302981980443, "critic_loss": 0.41004011833667753, "actor_loss": -90.40447065734864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31327533721924, "step": 108000}
{"episode_reward": 974.4707092409332, "episode": 109.0, "batch_reward": 0.8314686986804009, "critic_loss": 0.41362496004998683, "actor_loss": -90.10746525573731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.294806241989136, "step": 109000}
{"episode_reward": 975.7216102703641, "episode": 110.0, "batch_reward": 0.8324131575822831, "critic_loss": 0.3973024412840605, "actor_loss": -90.09333396911622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.338958263397217, "step": 110000}
{"episode_reward": 923.4626574709307, "episode": 111.0, "batch_reward": 0.8333359281420708, "critic_loss": 0.40152508744597437, "actor_loss": -90.61874920654297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.884154319763184, "step": 111000}
{"episode_reward": 939.3202450217491, "episode": 112.0, "batch_reward": 0.8330976142287254, "critic_loss": 0.41133309437334536, "actor_loss": -90.61688388061523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.359793663024902, "step": 112000}
{"episode_reward": 915.681635484657, "episode": 113.0, "batch_reward": 0.837154172539711, "critic_loss": 0.37934300352633, "actor_loss": -91.01726866149902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34643578529358, "step": 113000}
{"episode_reward": 983.3277472703967, "episode": 114.0, "batch_reward": 0.836716620862484, "critic_loss": 0.3919016136974096, "actor_loss": -90.31365214538575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.37281060218811, "step": 114000}
{"episode_reward": 976.1588635693316, "episode": 115.0, "batch_reward": 0.8382495343089104, "critic_loss": 0.4111782408952713, "actor_loss": -90.55888095092773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.38453960418701, "step": 115000}
{"episode_reward": 980.2923792329601, "episode": 116.0, "batch_reward": 0.8397081155180931, "critic_loss": 0.40395793398469687, "actor_loss": -90.32913606262207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.383176565170288, "step": 116000}
{"episode_reward": 904.2426389619059, "episode": 117.0, "batch_reward": 0.8399065339565277, "critic_loss": 0.4241801997572184, "actor_loss": -90.37084384155274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.334394454956055, "step": 117000}
{"episode_reward": 959.4562617214848, "episode": 118.0, "batch_reward": 0.8406500310897828, "critic_loss": 0.4103273499906063, "actor_loss": -90.85401167297363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.349387407302856, "step": 118000}
{"episode_reward": 978.4242734624369, "episode": 119.0, "batch_reward": 0.841766264796257, "critic_loss": 0.403782221198082, "actor_loss": -90.79559765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.376289129257202, "step": 119000}
{"episode_reward": 979.8013303470844, "episode": 120.0, "batch_reward": 0.8428654617667198, "critic_loss": 0.41139244681596754, "actor_loss": -90.5520765991211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.401341915130615, "step": 120000}
{"episode_reward": 978.8154074656263, "episode": 121.0, "batch_reward": 0.8446349165439606, "critic_loss": 0.39234891429543495, "actor_loss": -91.19414524841308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.864691495895386, "step": 121000}
{"episode_reward": 965.9296137909436, "episode": 122.0, "batch_reward": 0.8461286580562591, "critic_loss": 0.38654764062166214, "actor_loss": -90.79531854248047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.335156440734863, "step": 122000}
{"episode_reward": 918.9771369249085, "episode": 123.0, "batch_reward": 0.845183447778225, "critic_loss": 0.39178711561858653, "actor_loss": -90.31618785095215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.37584638595581, "step": 123000}
{"episode_reward": 936.3178868653963, "episode": 124.0, "batch_reward": 0.8462860928177833, "critic_loss": 0.36897412963211534, "actor_loss": -90.34084706115722, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.37128973007202, "step": 124000}
{"episode_reward": 976.7244253318613, "episode": 125.0, "batch_reward": 0.8478967118859291, "critic_loss": 0.3811823301017284, "actor_loss": -91.2174660949707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.367918491363525, "step": 125000}
{"episode_reward": 908.6167093100827, "episode": 126.0, "batch_reward": 0.8480826098322868, "critic_loss": 0.36112314902246, "actor_loss": -90.63286476135254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.37498688697815, "step": 126000}
{"episode_reward": 943.6462614115025, "episode": 127.0, "batch_reward": 0.8488323370218277, "critic_loss": 0.36483497259020803, "actor_loss": -90.48580108642578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.366260766983032, "step": 127000}
{"episode_reward": 970.7323510361033, "episode": 128.0, "batch_reward": 0.8493814982771873, "critic_loss": 0.3820651497840881, "actor_loss": -91.17231968688965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.327641010284424, "step": 128000}
{"episode_reward": 927.1953061170973, "episode": 129.0, "batch_reward": 0.8511333834528924, "critic_loss": 0.3600266614705324, "actor_loss": -91.12256463623046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.359145164489746, "step": 129000}
{"episode_reward": 959.8584153782784, "episode": 130.0, "batch_reward": 0.8524462885260582, "critic_loss": 0.38561756920814516, "actor_loss": -90.61813812255859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.33396863937378, "step": 130000}
{"episode_reward": 889.3513868801158, "episode": 131.0, "batch_reward": 0.8517363797426224, "critic_loss": 0.382865759819746, "actor_loss": -91.50172888183593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.83425569534302, "step": 131000}
{"episode_reward": 921.3631952241141, "episode": 132.0, "batch_reward": 0.8514383243322372, "critic_loss": 0.35276871905475854, "actor_loss": -90.49281219482423, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.378987550735474, "step": 132000}
{"episode_reward": 947.5735611986845, "episode": 133.0, "batch_reward": 0.8517766556143761, "critic_loss": 0.35591032790392635, "actor_loss": -91.25118377685547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.370513677597046, "step": 133000}
{"episode_reward": 932.2271599125899, "episode": 134.0, "batch_reward": 0.8522872743010521, "critic_loss": 0.3518943580240011, "actor_loss": -91.02916571044922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.394998788833618, "step": 134000}
{"episode_reward": 952.0230642279861, "episode": 135.0, "batch_reward": 0.8531176980137825, "critic_loss": 0.3472649807855487, "actor_loss": -90.96747477722168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3959379196167, "step": 135000}
{"episode_reward": 951.7213472180455, "episode": 136.0, "batch_reward": 0.8537445597648621, "critic_loss": 0.3605092719942331, "actor_loss": -90.99294299316406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.382084608078003, "step": 136000}
{"episode_reward": 886.616867058211, "episode": 137.0, "batch_reward": 0.8569710550904274, "critic_loss": 0.3646025702059269, "actor_loss": -90.63900859069824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.370866537094116, "step": 137000}
{"episode_reward": 979.8845359104943, "episode": 138.0, "batch_reward": 0.8558180648088455, "critic_loss": 0.37253174670040606, "actor_loss": -91.19960751342774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.392113208770752, "step": 138000}
{"episode_reward": 883.5305222476535, "episode": 139.0, "batch_reward": 0.8550779901146889, "critic_loss": 0.3769286608248949, "actor_loss": -91.27624154663086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.393340587615967, "step": 139000}
{"episode_reward": 721.2770510943228, "episode": 140.0, "batch_reward": 0.8551108139753342, "critic_loss": 0.36807007776200773, "actor_loss": -91.07550944519043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.394971132278442, "step": 140000}
{"episode_reward": 955.8490169156225, "episode": 141.0, "batch_reward": 0.8552911523580551, "critic_loss": 0.36440596549957993, "actor_loss": -91.12102011108398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.85228967666626, "step": 141000}
{"episode_reward": 973.5936510907875, "episode": 142.0, "batch_reward": 0.8568037539720536, "critic_loss": 0.39527243028581144, "actor_loss": -91.15082748413086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31887149810791, "step": 142000}
{"episode_reward": 950.2867426560464, "episode": 143.0, "batch_reward": 0.8575979281067848, "critic_loss": 0.3653956492841244, "actor_loss": -91.10291708374024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34121298789978, "step": 143000}
{"episode_reward": 974.0299938600281, "episode": 144.0, "batch_reward": 0.8587374793291092, "critic_loss": 0.36204937303066254, "actor_loss": -91.41288188171387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.668638706207275, "step": 144000}
{"episode_reward": 936.9904371638548, "episode": 145.0, "batch_reward": 0.858986352801323, "critic_loss": 0.3771093197911978, "actor_loss": -91.11497402954102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.328534603118896, "step": 145000}
{"episode_reward": 962.165178598334, "episode": 146.0, "batch_reward": 0.858995702445507, "critic_loss": 0.39293175625801086, "actor_loss": -91.19073751831054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.311908721923828, "step": 146000}
{"episode_reward": 977.9148003489379, "episode": 147.0, "batch_reward": 0.8607694956660271, "critic_loss": 0.38451322188973425, "actor_loss": -91.41494525146484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.30966019630432, "step": 147000}
{"episode_reward": 936.892562847369, "episode": 148.0, "batch_reward": 0.8596282427310944, "critic_loss": 0.38538235120475295, "actor_loss": -91.38136315917968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.364458322525024, "step": 148000}
{"episode_reward": 936.3652260150003, "episode": 149.0, "batch_reward": 0.8613083292841911, "critic_loss": 0.39268746714293956, "actor_loss": -91.44269984436035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.399203777313232, "step": 149000}
{"episode_reward": 969.4741677310712, "episode": 150.0, "batch_reward": 0.8608854382038117, "critic_loss": 0.4002944995164871, "actor_loss": -91.79758428955078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
