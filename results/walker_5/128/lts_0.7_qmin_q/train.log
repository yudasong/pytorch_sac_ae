{"episode_reward": 0.0, "episode": 1.0, "duration": 23.80997657775879, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.889145851135254, "step": 2000}
{"episode_reward": 632.427646246406, "episode": 3.0, "batch_reward": 0.33812901342896945, "critic_loss": 0.759060925187648, "actor_loss": -68.75469437958289, "actor_target_entropy": -6.0, "alpha_value": 0.004365629073060301, "duration": 64.50813174247742, "step": 3000}
{"episode_reward": 297.2382675781035, "episode": 4.0, "batch_reward": 0.32095730036497117, "critic_loss": 1.1535070577859878, "actor_loss": -67.49531101989746, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.535601139068604, "step": 4000}
{"episode_reward": 365.02680278153235, "episode": 5.0, "batch_reward": 0.35532709962129594, "critic_loss": 1.1563841276168823, "actor_loss": -68.1549535598755, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.252909660339355, "step": 5000}
{"episode_reward": 334.25689826559613, "episode": 6.0, "batch_reward": 0.37023592039942743, "critic_loss": 1.1338248819112777, "actor_loss": -68.22765439605713, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.572815895080566, "step": 6000}
{"episode_reward": 729.0003064272186, "episode": 7.0, "batch_reward": 0.41190316981077196, "critic_loss": 1.3435666829943658, "actor_loss": -69.23108908081055, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.58257293701172, "step": 7000}
{"episode_reward": 582.8889340572699, "episode": 8.0, "batch_reward": 0.43051139286160467, "critic_loss": 1.5012748271822929, "actor_loss": -69.17666958618165, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.972193717956543, "step": 8000}
{"episode_reward": 597.637738388847, "episode": 9.0, "batch_reward": 0.46870174089074135, "critic_loss": 1.3582090336084365, "actor_loss": -70.12574833679199, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.420342922210693, "step": 9000}
{"episode_reward": 823.2804832240647, "episode": 10.0, "batch_reward": 0.5030560607910156, "critic_loss": 1.3665440262556077, "actor_loss": -71.22295331573487, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.944112300872803, "step": 10000}
{"episode_reward": 804.4596863303955, "episode": 11.0, "batch_reward": 0.5359982665479183, "critic_loss": 1.3432678939700127, "actor_loss": -71.86580116271972, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.18262219429016, "step": 11000}
{"episode_reward": 857.8348711794964, "episode": 12.0, "batch_reward": 0.5677501450479031, "critic_loss": 1.280784901857376, "actor_loss": -72.83480690002442, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.341519594192505, "step": 12000}
{"episode_reward": 869.148253044277, "episode": 13.0, "batch_reward": 0.5836059775948524, "critic_loss": 1.398947820186615, "actor_loss": -73.23675079345703, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.612212896347046, "step": 13000}
{"episode_reward": 763.7254121672316, "episode": 14.0, "batch_reward": 0.6020318488478661, "critic_loss": 1.6434009845256805, "actor_loss": -73.6323452758789, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.088350296020508, "step": 14000}
{"episode_reward": 845.2073209160612, "episode": 15.0, "batch_reward": 0.6210146115422249, "critic_loss": 1.8933269945979119, "actor_loss": -74.09258160400391, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.722281217575073, "step": 15000}
{"episode_reward": 909.8797753479375, "episode": 16.0, "batch_reward": 0.6390649248957634, "critic_loss": 2.0186853726506233, "actor_loss": -74.47073501586914, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.075748682022095, "step": 16000}
{"episode_reward": 901.8323997427541, "episode": 17.0, "batch_reward": 0.6491763100624085, "critic_loss": 2.209704976141453, "actor_loss": -74.74289724731446, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.44382071495056, "step": 17000}
{"episode_reward": 755.7573997380618, "episode": 18.0, "batch_reward": 0.6627632565498353, "critic_loss": 2.0508669944405558, "actor_loss": -75.20841319274902, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.588753700256348, "step": 18000}
{"episode_reward": 889.8034413095745, "episode": 19.0, "batch_reward": 0.6653596675395965, "critic_loss": 2.4357886318564415, "actor_loss": -75.32121809387208, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.674506425857544, "step": 19000}
{"episode_reward": 705.8095321067868, "episode": 20.0, "batch_reward": 0.6715928201675415, "critic_loss": 2.5746922659873963, "actor_loss": -75.5950142364502, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.579148530960083, "step": 20000}
{"episode_reward": 851.9172064990239, "episode": 21.0, "batch_reward": 0.6734415135383606, "critic_loss": 4.0782683593034745, "actor_loss": -75.74757066345215, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.894500970840454, "step": 21000}
{"episode_reward": 528.6063669254611, "episode": 22.0, "batch_reward": 0.6767660183310509, "critic_loss": 3.731427817106247, "actor_loss": -76.28553874206543, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.588849306106567, "step": 22000}
{"episode_reward": 877.7112088156573, "episode": 23.0, "batch_reward": 0.6690858696699142, "critic_loss": 5.538219927430153, "actor_loss": -76.80461152648925, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.092925310134888, "step": 23000}
{"episode_reward": 359.8436942009013, "episode": 24.0, "batch_reward": 0.6667936949133872, "critic_loss": 4.696183972239495, "actor_loss": -76.9503217010498, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.988860368728638, "step": 24000}
{"episode_reward": 783.9183953068799, "episode": 25.0, "batch_reward": 0.6754190675020217, "critic_loss": 4.7955186216831205, "actor_loss": -77.59988265991211, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.55977702140808, "step": 25000}
{"episode_reward": 792.5416872095784, "episode": 26.0, "batch_reward": 0.6761460238099098, "critic_loss": 4.610792691111564, "actor_loss": -77.72552220153808, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.244511365890503, "step": 26000}
{"episode_reward": 631.5624120678461, "episode": 27.0, "batch_reward": 0.6750596929192543, "critic_loss": 4.7481486258506775, "actor_loss": -77.9645831604004, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.91277575492859, "step": 27000}
{"episode_reward": 633.7664561245483, "episode": 28.0, "batch_reward": 0.6758178454041481, "critic_loss": 4.103027444601059, "actor_loss": -78.06556407165527, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.169174671173096, "step": 28000}
{"episode_reward": 863.8892219161354, "episode": 29.0, "batch_reward": 0.6702401092648507, "critic_loss": 3.9059371569156647, "actor_loss": -78.40840710449218, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.196353435516357, "step": 29000}
{"episode_reward": 52.08183596740548, "episode": 30.0, "batch_reward": 0.6606857911944389, "critic_loss": 3.347442165136337, "actor_loss": -78.76901266479493, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.01502227783203, "step": 30000}
{"episode_reward": 822.3929302770197, "episode": 31.0, "batch_reward": 0.6673230142593384, "critic_loss": 3.1986607165336607, "actor_loss": -78.81624507141113, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.68925857543945, "step": 31000}
{"episode_reward": 882.9988688573552, "episode": 32.0, "batch_reward": 0.6738136371970177, "critic_loss": 2.846939097046852, "actor_loss": -78.79592793273926, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.487107753753662, "step": 32000}
{"episode_reward": 870.7282258255568, "episode": 33.0, "batch_reward": 0.678496281862259, "critic_loss": 2.848995146751404, "actor_loss": -78.66063745117188, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.005987644195557, "step": 33000}
{"episode_reward": 833.4019998543965, "episode": 34.0, "batch_reward": 0.6719853854775428, "critic_loss": 2.549884940862656, "actor_loss": -78.55146141052246, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.65692400932312, "step": 34000}
{"episode_reward": 53.49039263781907, "episode": 35.0, "batch_reward": 0.6563945407867432, "critic_loss": 2.3252599128484728, "actor_loss": -78.4697635345459, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.538129091262817, "step": 35000}
{"episode_reward": 91.53180357573865, "episode": 36.0, "batch_reward": 0.6471599676012992, "critic_loss": 2.071032346904278, "actor_loss": -78.21303662109375, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.925827741622925, "step": 36000}
{"episode_reward": 741.4269877612844, "episode": 37.0, "batch_reward": 0.6510296855568886, "critic_loss": 1.8953651099205018, "actor_loss": -78.05993592834473, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.154737949371338, "step": 37000}
{"episode_reward": 747.9374121948106, "episode": 38.0, "batch_reward": 0.6441222664117813, "critic_loss": 1.6085382661819458, "actor_loss": -77.66054643249512, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.652088165283203, "step": 38000}
{"episode_reward": 99.45659103326945, "episode": 39.0, "batch_reward": 0.6308990085124969, "critic_loss": 1.4890371297597884, "actor_loss": -77.28866268920899, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.49830198287964, "step": 39000}
{"episode_reward": 108.94836940980629, "episode": 40.0, "batch_reward": 0.6164153455495834, "critic_loss": 1.3056015159487724, "actor_loss": -76.88332434082031, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.515660285949707, "step": 40000}
{"episode_reward": 44.78628649512236, "episode": 41.0, "batch_reward": 0.6117181712388993, "critic_loss": 1.242811311006546, "actor_loss": -76.61264422607422, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 44.6928071975708, "step": 41000}
{"episode_reward": 780.5007541034381, "episode": 42.0, "batch_reward": 0.6163674974441529, "critic_loss": 1.2138281722664832, "actor_loss": -76.41605519104004, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.48235034942627, "step": 42000}
{"episode_reward": 845.5843920111963, "episode": 43.0, "batch_reward": 0.6224879350066185, "critic_loss": 1.237650324523449, "actor_loss": -76.30078594970703, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.85248041152954, "step": 43000}
{"episode_reward": 852.0651891841715, "episode": 44.0, "batch_reward": 0.6249492851495743, "critic_loss": 1.2767330525517464, "actor_loss": -76.02847239685059, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.668140411376953, "step": 44000}
{"episode_reward": 840.9512696614028, "episode": 45.0, "batch_reward": 0.6315003539919853, "critic_loss": 1.2660746283531188, "actor_loss": -75.98655464172363, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.888123273849487, "step": 45000}
{"episode_reward": 814.6960551881739, "episode": 46.0, "batch_reward": 0.6364372864365577, "critic_loss": 1.3140229850411416, "actor_loss": -76.08988735961914, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.299978971481323, "step": 46000}
{"episode_reward": 872.1304247868948, "episode": 47.0, "batch_reward": 0.640641789317131, "critic_loss": 1.385268036007881, "actor_loss": -76.18795950317383, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.18574595451355, "step": 47000}
{"episode_reward": 859.8501551944723, "episode": 48.0, "batch_reward": 0.646058970451355, "critic_loss": 1.3469101984500884, "actor_loss": -76.30986813354492, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.42947030067444, "step": 48000}
{"episode_reward": 889.0135097076835, "episode": 49.0, "batch_reward": 0.6518130712509155, "critic_loss": 1.3297011369466782, "actor_loss": -76.52475607299804, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.068393230438232, "step": 49000}
{"episode_reward": 845.9254973290984, "episode": 50.0, "batch_reward": 0.6526315448284149, "critic_loss": 1.3338896206617354, "actor_loss": -76.55185012817383, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.975815296173096, "step": 50000}
{"episode_reward": 869.5416409485846, "episode": 51.0, "batch_reward": 0.6592845774888992, "critic_loss": 1.3213549764752388, "actor_loss": -76.94501350402832, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.83685541152954, "step": 51000}
{"episode_reward": 880.9296660519796, "episode": 52.0, "batch_reward": 0.6631478109955787, "critic_loss": 1.3062858834266662, "actor_loss": -76.8095149383545, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.248843669891357, "step": 52000}
{"episode_reward": 859.7506853011907, "episode": 53.0, "batch_reward": 0.667413693010807, "critic_loss": 1.1709797992110251, "actor_loss": -77.03929537963867, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.47591996192932, "step": 53000}
{"episode_reward": 873.4889197217742, "episode": 54.0, "batch_reward": 0.6708006322979927, "critic_loss": 1.1778077211976052, "actor_loss": -77.20193197631836, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.470293283462524, "step": 54000}
{"episode_reward": 877.8279125477669, "episode": 55.0, "batch_reward": 0.6741485313773156, "critic_loss": 1.133648876130581, "actor_loss": -77.2798657836914, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.295006275177002, "step": 55000}
{"episode_reward": 901.9570747927908, "episode": 56.0, "batch_reward": 0.6763083081245422, "critic_loss": 1.1579378253221513, "actor_loss": -77.25912524414062, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.829334020614624, "step": 56000}
{"episode_reward": 826.1102928259456, "episode": 57.0, "batch_reward": 0.6794266919493676, "critic_loss": 1.0943679341375827, "actor_loss": -77.22840837097168, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.72332191467285, "step": 57000}
{"episode_reward": 780.6273587051605, "episode": 58.0, "batch_reward": 0.6842744075059891, "critic_loss": 1.1068807662129403, "actor_loss": -77.44799855041504, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.132779359817505, "step": 58000}
{"episode_reward": 883.1645615991753, "episode": 59.0, "batch_reward": 0.6848456577658654, "critic_loss": 1.160329096108675, "actor_loss": -77.60460220336914, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.09682035446167, "step": 59000}
{"episode_reward": 769.4040215177863, "episode": 60.0, "batch_reward": 0.6884602033495903, "critic_loss": 1.2140490719676018, "actor_loss": -77.5463617401123, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.21877884864807, "step": 60000}
{"episode_reward": 847.8871539405762, "episode": 61.0, "batch_reward": 0.6909889628887177, "critic_loss": 1.1145082858204842, "actor_loss": -77.47517530822753, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.44082498550415, "step": 61000}
{"episode_reward": 854.8755090015983, "episode": 62.0, "batch_reward": 0.6939694466590881, "critic_loss": 1.0948988467752934, "actor_loss": -77.68979838562012, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.001054048538208, "step": 62000}
{"episode_reward": 882.9019600856741, "episode": 63.0, "batch_reward": 0.6965775543451309, "critic_loss": 1.126530589580536, "actor_loss": -77.9190099182129, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.449854850769043, "step": 63000}
{"episode_reward": 818.6362986372894, "episode": 64.0, "batch_reward": 0.6988228126764298, "critic_loss": 1.1146281611919404, "actor_loss": -78.08889050292969, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.21077299118042, "step": 64000}
{"episode_reward": 870.8496081216144, "episode": 65.0, "batch_reward": 0.7007895743250847, "critic_loss": 1.1088992620408535, "actor_loss": -78.10161587524414, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.801748514175415, "step": 65000}
{"episode_reward": 879.1643687921674, "episode": 66.0, "batch_reward": 0.7028539092540741, "critic_loss": 1.1046647156774998, "actor_loss": -78.1795122833252, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.337099313735962, "step": 66000}
{"episode_reward": 859.7842563825667, "episode": 67.0, "batch_reward": 0.7076560508608818, "critic_loss": 1.0813058498799801, "actor_loss": -78.23599424743652, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.347075700759888, "step": 67000}
{"episode_reward": 842.6883380421135, "episode": 68.0, "batch_reward": 0.707821601331234, "critic_loss": 1.1170476144254207, "actor_loss": -78.34521176147462, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.186380624771118, "step": 68000}
{"episode_reward": 885.8292678551442, "episode": 69.0, "batch_reward": 0.7121963543891907, "critic_loss": 1.106811293065548, "actor_loss": -78.41002046203613, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.61357045173645, "step": 69000}
{"episode_reward": 899.5107530904128, "episode": 70.0, "batch_reward": 0.7147525780797005, "critic_loss": 1.155925176680088, "actor_loss": -78.52071897888183, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.607397079467773, "step": 70000}
{"episode_reward": 819.7776985435003, "episode": 71.0, "batch_reward": 0.7131198682785034, "critic_loss": 1.1151731418669224, "actor_loss": -78.46961247253418, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.034329891204834, "step": 71000}
{"episode_reward": 794.3654514998765, "episode": 72.0, "batch_reward": 0.716745869398117, "critic_loss": 1.0991858225762845, "actor_loss": -78.50623414611816, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.695849657058716, "step": 72000}
{"episode_reward": 878.0932391623679, "episode": 73.0, "batch_reward": 0.717297092974186, "critic_loss": 1.1258200018405915, "actor_loss": -78.58366471862793, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.011937856674194, "step": 73000}
{"episode_reward": 773.6051373179456, "episode": 74.0, "batch_reward": 0.718267902314663, "critic_loss": 1.1698686031103134, "actor_loss": -78.6128960723877, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.835227012634277, "step": 74000}
{"episode_reward": 897.2822082015368, "episode": 75.0, "batch_reward": 0.7222477642893791, "critic_loss": 1.1508468388319015, "actor_loss": -78.81947190856934, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.246301889419556, "step": 75000}
{"episode_reward": 867.3711935940852, "episode": 76.0, "batch_reward": 0.7232833736538887, "critic_loss": 1.077439793229103, "actor_loss": -78.77025511169434, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.855195999145508, "step": 76000}
{"episode_reward": 874.4598462652248, "episode": 77.0, "batch_reward": 0.725881285905838, "critic_loss": 1.086876253426075, "actor_loss": -78.73851338195801, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.406325817108154, "step": 77000}
{"episode_reward": 877.1850742128591, "episode": 78.0, "batch_reward": 0.7284528701305389, "critic_loss": 1.0550375598073005, "actor_loss": -78.70979656982422, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.885034561157227, "step": 78000}
{"episode_reward": 898.7946396880387, "episode": 79.0, "batch_reward": 0.7315729306936264, "critic_loss": 1.0054391445815563, "actor_loss": -78.85454565429687, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.26166272163391, "step": 79000}
{"episode_reward": 903.7904625720489, "episode": 80.0, "batch_reward": 0.7320840907692909, "critic_loss": 1.0319273393154145, "actor_loss": -78.87100494384765, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.2802631855011, "step": 80000}
{"episode_reward": 890.325738272962, "episode": 81.0, "batch_reward": 0.7328906462192536, "critic_loss": 1.0419785552620888, "actor_loss": -78.7673819732666, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.70864534378052, "step": 81000}
{"episode_reward": 879.5651278830197, "episode": 82.0, "batch_reward": 0.7340201736688614, "critic_loss": 0.9985872332453728, "actor_loss": -78.7834751739502, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.90450358390808, "step": 82000}
{"episode_reward": 855.6814004203792, "episode": 83.0, "batch_reward": 0.7368008041381836, "critic_loss": 1.1127229833602905, "actor_loss": -78.92829901123046, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.87426781654358, "step": 83000}
{"episode_reward": 839.3750003935248, "episode": 84.0, "batch_reward": 0.7365997772812843, "critic_loss": 1.0149585243463517, "actor_loss": -78.84803884887695, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.7642080783844, "step": 84000}
{"episode_reward": 898.8276628033763, "episode": 85.0, "batch_reward": 0.7387767193317414, "critic_loss": 1.0990241676568986, "actor_loss": -78.92815937805176, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.7656090259552, "step": 85000}
{"episode_reward": 740.256345317487, "episode": 86.0, "batch_reward": 0.7385998060703277, "critic_loss": 1.1093074904680251, "actor_loss": -78.86433438110352, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.64723253250122, "step": 86000}
{"episode_reward": 823.8318978767877, "episode": 87.0, "batch_reward": 0.7410513058304786, "critic_loss": 1.0723901272714138, "actor_loss": -78.8178038482666, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.646573305130005, "step": 87000}
{"episode_reward": 868.9672778238464, "episode": 88.0, "batch_reward": 0.7435362975597382, "critic_loss": 1.0679466463327407, "actor_loss": -78.89026750183106, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.54251527786255, "step": 88000}
{"episode_reward": 889.1663274913236, "episode": 89.0, "batch_reward": 0.7437677064538002, "critic_loss": 1.0641693223714828, "actor_loss": -78.93575236511231, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.10261845588684, "step": 89000}
{"episode_reward": 795.1871921030086, "episode": 90.0, "batch_reward": 0.7437818915247917, "critic_loss": 1.0853950131237506, "actor_loss": -78.85570764160157, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.142520904541016, "step": 90000}
{"episode_reward": 845.0666141335621, "episode": 91.0, "batch_reward": 0.7436618712544442, "critic_loss": 1.1348399649262428, "actor_loss": -78.97374621582031, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.5206413269043, "step": 91000}
{"episode_reward": 828.6848273834954, "episode": 92.0, "batch_reward": 0.746528340101242, "critic_loss": 1.089347343325615, "actor_loss": -78.99635604858399, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.263614416122437, "step": 92000}
{"episode_reward": 898.0211207729883, "episode": 93.0, "batch_reward": 0.7476870066523552, "critic_loss": 1.0947405562400818, "actor_loss": -79.0434344329834, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.82717490196228, "step": 93000}
{"episode_reward": 886.8636505767124, "episode": 94.0, "batch_reward": 0.7493925998210907, "critic_loss": 1.124994336783886, "actor_loss": -79.0514871826172, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.60361409187317, "step": 94000}
{"episode_reward": 854.3083507550863, "episode": 95.0, "batch_reward": 0.750584262728691, "critic_loss": 1.1710335169136523, "actor_loss": -79.2375470123291, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.534085512161255, "step": 95000}
{"episode_reward": 877.3043658484173, "episode": 96.0, "batch_reward": 0.7535451251268387, "critic_loss": 1.168407566934824, "actor_loss": -79.24725466918946, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.134998559951782, "step": 96000}
{"episode_reward": 938.4424438135799, "episode": 97.0, "batch_reward": 0.7546289749741554, "critic_loss": 1.1764121850132943, "actor_loss": -79.25357992553711, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.69061851501465, "step": 97000}
{"episode_reward": 900.0888174084544, "episode": 98.0, "batch_reward": 0.7559179655909538, "critic_loss": 1.1187331219613552, "actor_loss": -79.27344839477539, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.032087564468384, "step": 98000}
{"episode_reward": 848.6516530584952, "episode": 99.0, "batch_reward": 0.7571524308919907, "critic_loss": 1.0796087760925293, "actor_loss": -79.3571124420166, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.194204568862915, "step": 99000}
{"episode_reward": 899.7221239564792, "episode": 100.0, "batch_reward": 0.7581150742769242, "critic_loss": 1.020774728357792, "actor_loss": -79.36667338562012, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.865501642227173, "step": 100000}
{"episode_reward": 863.8619154510972, "episode": 101.0, "batch_reward": 0.7597827956676483, "critic_loss": 1.0068932984173298, "actor_loss": -79.39246496582031, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.781675577163696, "step": 101000}
{"episode_reward": 874.7363594259226, "episode": 102.0, "batch_reward": 0.7624287895560264, "critic_loss": 1.0497280046641826, "actor_loss": -79.48561849975586, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.326167106628418, "step": 102000}
{"episode_reward": 884.5063459904579, "episode": 103.0, "batch_reward": 0.7620099588036537, "critic_loss": 1.025052476197481, "actor_loss": -79.48370054626464, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.822152614593506, "step": 103000}
{"episode_reward": 919.515289689704, "episode": 104.0, "batch_reward": 0.7629089604616165, "critic_loss": 1.0374725573956967, "actor_loss": -79.55050769042968, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.621416568756104, "step": 104000}
{"episode_reward": 886.9254303728334, "episode": 105.0, "batch_reward": 0.7641980170607566, "critic_loss": 0.9908207621872425, "actor_loss": -79.45768362426757, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.313745975494385, "step": 105000}
{"episode_reward": 888.3178171981159, "episode": 106.0, "batch_reward": 0.764381619989872, "critic_loss": 1.0043973550796508, "actor_loss": -79.58040830993653, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.712860584259033, "step": 106000}
{"episode_reward": 889.1708211116043, "episode": 107.0, "batch_reward": 0.7656785989999771, "critic_loss": 1.014548087120056, "actor_loss": -79.60884535217285, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 25.5425443649292, "step": 107000}
{"episode_reward": 899.8983225693121, "episode": 108.0, "batch_reward": 0.7675813989043235, "critic_loss": 1.0079378866553306, "actor_loss": -79.65532717895508, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.328248977661133, "step": 108000}
{"episode_reward": 899.1761709042032, "episode": 109.0, "batch_reward": 0.7687695670723915, "critic_loss": 1.0790406682193279, "actor_loss": -79.66830479431152, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.562914609909058, "step": 109000}
{"episode_reward": 894.3273896227169, "episode": 110.0, "batch_reward": 0.7698331170082092, "critic_loss": 1.0517728998661042, "actor_loss": -79.69883261108399, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.279167890548706, "step": 110000}
{"episode_reward": 872.9988889435365, "episode": 111.0, "batch_reward": 0.7685841886401177, "critic_loss": 1.0802097629606724, "actor_loss": -79.73117309570313, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.98564028739929, "step": 111000}
{"episode_reward": 819.6387678178396, "episode": 112.0, "batch_reward": 0.7718324407339096, "critic_loss": 1.034427634358406, "actor_loss": -79.84948165893555, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.319559574127197, "step": 112000}
{"episode_reward": 849.7070191285501, "episode": 113.0, "batch_reward": 0.7725449736118317, "critic_loss": 0.9796534174084663, "actor_loss": -79.78025636291504, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.397276163101196, "step": 113000}
{"episode_reward": 865.3906394480923, "episode": 114.0, "batch_reward": 0.7744868712425232, "critic_loss": 0.9336393667161464, "actor_loss": -79.88507484436035, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.550657749176025, "step": 114000}
{"episode_reward": 883.0774262666432, "episode": 115.0, "batch_reward": 0.7740862014889717, "critic_loss": 0.9547775116264821, "actor_loss": -79.89388438415527, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.817310571670532, "step": 115000}
{"episode_reward": 894.7103818618905, "episode": 116.0, "batch_reward": 0.7752709289193154, "critic_loss": 0.9538921845853329, "actor_loss": -79.87161917114258, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 25.87296485900879, "step": 116000}
{"episode_reward": 839.3335679475019, "episode": 117.0, "batch_reward": 0.776129853785038, "critic_loss": 0.9302557593286037, "actor_loss": -79.92354066467286, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.30543303489685, "step": 117000}
{"episode_reward": 855.3406165525074, "episode": 118.0, "batch_reward": 0.7753001321554184, "critic_loss": 0.9371464221179485, "actor_loss": -79.84067668151856, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.385258436203003, "step": 118000}
{"episode_reward": 910.9546476061298, "episode": 119.0, "batch_reward": 0.7767528771162033, "critic_loss": 0.8481791796982289, "actor_loss": -79.94228720092774, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.98726487159729, "step": 119000}
{"episode_reward": 903.354146026594, "episode": 120.0, "batch_reward": 0.7788461654782295, "critic_loss": 0.9103005528748035, "actor_loss": -80.02187608337402, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.601990461349487, "step": 120000}
{"episode_reward": 896.4288829483527, "episode": 121.0, "batch_reward": 0.7792127324342728, "critic_loss": 0.9326658872663974, "actor_loss": -79.94641122436524, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.65500044822693, "step": 121000}
{"episode_reward": 884.667882036606, "episode": 122.0, "batch_reward": 0.7796976573467255, "critic_loss": 0.929160485804081, "actor_loss": -80.0353882598877, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.03138542175293, "step": 122000}
{"episode_reward": 873.7006949893737, "episode": 123.0, "batch_reward": 0.7809820064306259, "critic_loss": 0.8908327122032642, "actor_loss": -80.09304420471192, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.672078847885132, "step": 123000}
{"episode_reward": 857.1467305940516, "episode": 124.0, "batch_reward": 0.782046090066433, "critic_loss": 0.9978503034710884, "actor_loss": -80.10773425292969, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.50686502456665, "step": 124000}
{"episode_reward": 896.9558245692291, "episode": 125.0, "batch_reward": 0.7832817938923836, "critic_loss": 1.1041686584651471, "actor_loss": -80.18885188293457, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.357608556747437, "step": 125000}
{"episode_reward": 812.8806934091715, "episode": 126.0, "batch_reward": 0.7825475890040398, "critic_loss": 1.214662678182125, "actor_loss": -80.17723518371582, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.75725555419922, "step": 126000}
{"episode_reward": 885.0497616727845, "episode": 127.0, "batch_reward": 0.7823346083760262, "critic_loss": 1.4112177831828594, "actor_loss": -80.11144567871094, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.681993007659912, "step": 127000}
{"episode_reward": 885.4478753384917, "episode": 128.0, "batch_reward": 0.7852559093832969, "critic_loss": 1.8252654054760933, "actor_loss": -80.23020874023437, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.837353467941284, "step": 128000}
{"episode_reward": 897.0426791040771, "episode": 129.0, "batch_reward": 0.7861107927560806, "critic_loss": 2.528573181807995, "actor_loss": -80.23590713500977, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 24.592726230621338, "step": 129000}
{"episode_reward": 881.2321713052743, "episode": 130.0, "batch_reward": 0.7872781999111176, "critic_loss": 3.080260797917843, "actor_loss": -80.26626010131837, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.2450749874115, "step": 130000}
{"episode_reward": 855.6514691181053, "episode": 131.0, "batch_reward": 0.7862342209815979, "critic_loss": 4.675102537512779, "actor_loss": -80.3850834197998, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.481465101242065, "step": 131000}
{"episode_reward": 859.9458517043875, "episode": 132.0, "batch_reward": 0.7864599459171295, "critic_loss": 6.284516978263855, "actor_loss": -80.77322605895996, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.288313627243042, "step": 132000}
{"episode_reward": 872.5858564407429, "episode": 133.0, "batch_reward": 0.7839412857890129, "critic_loss": 8.591478018045425, "actor_loss": -81.04355294799805, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.95125150680542, "step": 133000}
{"episode_reward": 29.97291557836972, "episode": 134.0, "batch_reward": 0.7814996365904808, "critic_loss": 9.09210106933117, "actor_loss": -81.44128482055665, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.802183151245117, "step": 134000}
{"episode_reward": 884.1062733567732, "episode": 135.0, "batch_reward": 0.7806100052595139, "critic_loss": 10.887433447718621, "actor_loss": -81.80293971252442, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.650270462036133, "step": 135000}
{"episode_reward": 816.1476459921364, "episode": 136.0, "batch_reward": 0.7806875740289688, "critic_loss": 14.043840171456337, "actor_loss": -82.11031373596191, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.001835823059082, "step": 136000}
{"episode_reward": 691.3782243212789, "episode": 137.0, "batch_reward": 0.7829720398187637, "critic_loss": 17.347157526493074, "actor_loss": -82.52636770629883, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.88199806213379, "step": 137000}
{"episode_reward": 834.4467291090311, "episode": 138.0, "batch_reward": 0.7794513389468193, "critic_loss": 20.20446342563629, "actor_loss": -83.38384477233886, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.92102313041687, "step": 138000}
{"episode_reward": 44.29713157325079, "episode": 139.0, "batch_reward": 0.7757780517339706, "critic_loss": 21.668435827732086, "actor_loss": -84.12260017395019, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.613473892211914, "step": 139000}
{"episode_reward": 238.01524053363158, "episode": 140.0, "batch_reward": 0.7706906202435494, "critic_loss": 24.432273854255676, "actor_loss": -84.558544921875, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.77570152282715, "step": 140000}
{"episode_reward": 77.2019088185107, "episode": 141.0, "batch_reward": 0.7663593672513962, "critic_loss": 25.89469043636322, "actor_loss": -84.55394290161132, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 44.27431654930115, "step": 141000}
{"episode_reward": 41.164687485885274, "episode": 142.0, "batch_reward": 0.7589040073156357, "critic_loss": 28.218379509925843, "actor_loss": -85.77476193237305, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.143248081207275, "step": 142000}
{"episode_reward": 12.235753379904676, "episode": 143.0, "batch_reward": 0.7561131504178047, "critic_loss": 35.11660359382629, "actor_loss": -86.87802209472656, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.388927221298218, "step": 143000}
{"episode_reward": 29.65048485294012, "episode": 144.0, "batch_reward": 0.7511773920059204, "critic_loss": 64.53279555892945, "actor_loss": -96.88892543029785, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.072818517684937, "step": 144000}
{"episode_reward": 22.211270183558636, "episode": 145.0, "batch_reward": 0.7458965581655502, "critic_loss": 101.73150128936767, "actor_loss": -110.01387115478515, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.244552850723267, "step": 145000}
{"episode_reward": 15.77547884245111, "episode": 146.0, "batch_reward": 0.7386964282393456, "critic_loss": 121.00868093490601, "actor_loss": -140.96703881835938, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.775430917739868, "step": 146000}
{"episode_reward": 14.225213734797723, "episode": 147.0, "batch_reward": 0.734401155591011, "critic_loss": 156.32861616897583, "actor_loss": -152.5323198852539, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.7769513130188, "step": 147000}
{"episode_reward": 12.277287415010845, "episode": 148.0, "batch_reward": 0.7311860255002975, "critic_loss": 166.6539076156616, "actor_loss": -157.56959072875978, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.679933786392212, "step": 148000}
{"episode_reward": 36.77678036612947, "episode": 149.0, "batch_reward": 0.7270641669034957, "critic_loss": 138.10858348846435, "actor_loss": -158.33577502441406, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.56944441795349, "step": 149000}
{"episode_reward": 51.353320029522195, "episode": 150.0, "batch_reward": 0.7204425222277642, "critic_loss": 126.81520443344117, "actor_loss": -162.4322897338867, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "step": 150000}
