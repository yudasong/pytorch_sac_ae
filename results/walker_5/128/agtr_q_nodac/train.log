{"episode": 1.0, "duration": 22.012622117996216, "episode_reward": 58.61337562337205, "step": 1000}
{"episode": 2.0, "duration": 1.8563268184661865, "episode_reward": 632.427646246406, "step": 2000}
{"episode": 3.0, "batch_reward": 0.34302462768598413, "actor_loss": -69.59493708372021, "actor_target_entropy": -6.0, "alpha_value": 0.004365629073060301, "duration": 61.162461280822754, "episode_reward": 343.61733598732627, "step": 3000}
{"episode": 4.0, "batch_reward": 0.34676711112260816, "actor_loss": -69.08698654174805, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.58132266998291, "episode_reward": 378.76888753016743, "step": 4000}
{"episode": 5.0, "batch_reward": 0.3556000714302063, "actor_loss": -69.03461283874512, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.534451007843018, "episode_reward": 430.8166288837021, "step": 5000}
{"episode": 6.0, "batch_reward": 0.3834065439105034, "actor_loss": -69.60900053405761, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.928667306900024, "episode_reward": 589.872205268574, "step": 6000}
{"episode": 7.0, "batch_reward": 0.42595976853370665, "actor_loss": -70.7830608215332, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.860579013824463, "episode_reward": 752.5866431196985, "step": 7000}
{"episode": 8.0, "batch_reward": 0.47562833249568937, "actor_loss": -72.172418258667, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.35439920425415, "episode_reward": 821.9370622965845, "step": 8000}
{"episode": 9.0, "batch_reward": 0.5171842619478703, "actor_loss": -73.35925184631347, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.724198579788208, "episode_reward": 798.4639900145573, "step": 9000}
{"episode": 10.0, "batch_reward": 0.5290661427974701, "actor_loss": -73.60151751708985, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.543900966644287, "episode_reward": 626.7842903925209, "step": 10000}
{"episode": 11.0, "batch_reward": 0.5334568923413754, "actor_loss": -73.6688694152832, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 45.51096510887146, "episode_reward": 402.7142552608729, "step": 11000}
{"episode": 12.0, "batch_reward": 0.5448799826204777, "actor_loss": -73.9722276763916, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.19217038154602, "episode_reward": 754.987368639688, "step": 12000}
{"episode": 13.0, "batch_reward": 0.5550596179664135, "actor_loss": -74.20593489074707, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.823010206222534, "episode_reward": 787.3969466293424, "step": 13000}
{"episode": 14.0, "batch_reward": 0.5703171665668487, "actor_loss": -74.62781964111328, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.141313552856445, "episode_reward": 715.6367476641652, "step": 14000}
{"episode": 15.0, "batch_reward": 0.5873703117966652, "actor_loss": -75.07695672607421, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.735448598861694, "episode_reward": 838.5399329385458, "step": 15000}
{"episode": 16.0, "batch_reward": 0.6025840180516243, "actor_loss": -75.4673165435791, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.567785501480103, "episode_reward": 816.3111768127463, "step": 16000}
{"episode": 17.0, "batch_reward": 0.60460899579525, "actor_loss": -75.40176118469239, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.74116611480713, "episode_reward": 605.9333659905055, "step": 17000}
{"episode": 18.0, "batch_reward": 0.6146843413710594, "actor_loss": -75.72434115600586, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.061661958694458, "episode_reward": 791.3404625542202, "step": 18000}
{"episode": 19.0, "batch_reward": 0.621706846177578, "actor_loss": -75.8650548248291, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.869035720825195, "episode_reward": 775.3931036916508, "step": 19000}
{"episode": 20.0, "batch_reward": 0.63440109282732, "actor_loss": -76.1633892364502, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.817023038864136, "episode_reward": 890.9670901630009, "step": 20000}
{"episode": 21.0, "batch_reward": 0.6457645609378815, "actor_loss": -76.41883583068848, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 45.03732705116272, "episode_reward": 815.6012469624837, "step": 21000}
{"episode": 22.0, "batch_reward": 0.6501277579069138, "actor_loss": -76.45957298278809, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.860498666763306, "episode_reward": 658.9277122084645, "step": 22000}
{"episode": 23.0, "batch_reward": 0.6494458433389664, "actor_loss": -76.49414562988281, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.822320461273193, "episode_reward": 732.4947948962217, "step": 23000}
{"episode": 24.0, "batch_reward": 0.6493657534718513, "actor_loss": -76.4257571105957, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.829127311706543, "episode_reward": 662.7305151430295, "step": 24000}
{"episode": 25.0, "batch_reward": 0.6565775184035301, "actor_loss": -76.53700462341308, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.17135453224182, "episode_reward": 756.7503122423292, "step": 25000}
{"episode": 26.0, "batch_reward": 0.6574275760650635, "actor_loss": -76.58581739807128, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.209146738052368, "episode_reward": 806.7923283485705, "step": 26000}
{"episode": 27.0, "batch_reward": 0.6662640948295593, "actor_loss": -76.78693315124512, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.25354528427124, "episode_reward": 830.8078627797734, "step": 27000}
{"episode": 28.0, "batch_reward": 0.6707198853492737, "actor_loss": -76.91358059692382, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.37819814682007, "episode_reward": 819.991804285628, "step": 28000}
{"episode": 29.0, "batch_reward": 0.67244656842947, "actor_loss": -76.88735710144043, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.445016384124756, "episode_reward": 693.0103130096935, "step": 29000}
{"episode": 30.0, "batch_reward": 0.6757204335927963, "actor_loss": -76.97343222045899, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.675734519958496, "episode_reward": 810.4589932509242, "step": 30000}
{"episode": 31.0, "batch_reward": 0.682456478357315, "actor_loss": -77.10657962036133, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 44.9935462474823, "episode_reward": 828.4460183818142, "step": 31000}
{"episode": 32.0, "batch_reward": 0.6872549396753311, "actor_loss": -77.2680841217041, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.15554141998291, "episode_reward": 843.4790304732835, "step": 32000}
{"episode": 33.0, "batch_reward": 0.6932264340519905, "actor_loss": -77.50528907775879, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.274752140045166, "episode_reward": 896.1229595836851, "step": 33000}
{"episode": 34.0, "batch_reward": 0.6969762108325959, "actor_loss": -77.5258535308838, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.83996081352234, "episode_reward": 775.7221052661072, "step": 34000}
{"episode": 35.0, "batch_reward": 0.6998381655216217, "actor_loss": -77.60359075927734, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.343377351760864, "episode_reward": 755.9336841873684, "step": 35000}
{"episode": 36.0, "batch_reward": 0.7024950674772262, "actor_loss": -77.71323712158203, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.96435832977295, "episode_reward": 794.4044624254061, "step": 36000}
{"episode": 37.0, "batch_reward": 0.7039658867120743, "actor_loss": -77.79516828918457, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.721745252609253, "episode_reward": 801.6122543527448, "step": 37000}
{"episode": 38.0, "batch_reward": 0.7012736817002296, "actor_loss": -77.69597026062011, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.919517517089844, "episode_reward": 645.9766940412642, "step": 38000}
{"episode": 39.0, "batch_reward": 0.7043490040898323, "actor_loss": -77.7626675415039, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.976173639297485, "episode_reward": 845.0588394603436, "step": 39000}
{"episode": 40.0, "batch_reward": 0.7066359894871712, "actor_loss": -77.78390759277343, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.88560724258423, "episode_reward": 774.7066955282954, "step": 40000}
{"episode": 41.0, "batch_reward": 0.7106217866539956, "actor_loss": -77.87317250061035, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 44.77602434158325, "episode_reward": 759.6275617213443, "step": 41000}
{"episode": 42.0, "batch_reward": 0.7101121771931648, "actor_loss": -77.88811660766602, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 17.83205556869507, "episode_reward": 825.0301264749774, "step": 42000}
{"episode": 43.0, "batch_reward": 0.7139450280070305, "actor_loss": -77.92800439453126, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.791023015975952, "episode_reward": 791.6494557582788, "step": 43000}
{"episode": 44.0, "batch_reward": 0.712920279443264, "actor_loss": -77.94796516418457, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.07466721534729, "episode_reward": 719.8980769100583, "step": 44000}
{"episode": 45.0, "batch_reward": 0.715741991519928, "actor_loss": -77.98825018310546, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.715477228164673, "episode_reward": 809.6919708673422, "step": 45000}
{"episode": 46.0, "batch_reward": 0.7161814315915108, "actor_loss": -78.03022512817383, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.560635089874268, "episode_reward": 735.1449713820889, "step": 46000}
{"episode": 47.0, "batch_reward": 0.7163914881944656, "actor_loss": -78.0262633972168, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.75888180732727, "episode_reward": 659.5900568239097, "step": 47000}
{"episode": 48.0, "batch_reward": 0.7169670016169548, "actor_loss": -77.98101104736328, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.867143154144287, "episode_reward": 808.1298807435121, "step": 48000}
{"episode": 49.0, "batch_reward": 0.718300028681755, "actor_loss": -78.04879745483399, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.200249910354614, "episode_reward": 779.1686137430821, "step": 49000}
{"episode": 50.0, "batch_reward": 0.7212174055576325, "actor_loss": -78.16438999938966, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.86876106262207, "episode_reward": 807.9455673832953, "step": 50000}
{"episode": 51.0, "batch_reward": 0.722457689166069, "actor_loss": -78.19140002441407, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.61194348335266, "episode_reward": 815.2614618028055, "step": 51000}
{"episode": 52.0, "batch_reward": 0.7239004436135292, "actor_loss": -78.24172343444825, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.365894317626953, "episode_reward": 854.7093837461211, "step": 52000}
{"episode": 53.0, "batch_reward": 0.7270543051362037, "actor_loss": -78.29690022277832, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.443332195281982, "episode_reward": 856.2732051735138, "step": 53000}
{"episode": 54.0, "batch_reward": 0.7273728017210961, "actor_loss": -78.3366720275879, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.699650764465332, "episode_reward": 788.9171122044403, "step": 54000}
{"episode": 55.0, "batch_reward": 0.7287481071352959, "actor_loss": -78.37514413452149, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.01245093345642, "episode_reward": 776.5880643256635, "step": 55000}
{"episode": 56.0, "batch_reward": 0.730103953063488, "actor_loss": -78.39363819885254, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.348472356796265, "episode_reward": 754.5031047783116, "step": 56000}
{"episode": 57.0, "batch_reward": 0.7314652708172799, "actor_loss": -78.44338143920899, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.5617733001709, "episode_reward": 795.9317702227986, "step": 57000}
{"episode": 58.0, "batch_reward": 0.7304823456406593, "actor_loss": -78.42632069396973, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.756486654281616, "episode_reward": 796.9449614453112, "step": 58000}
{"episode": 59.0, "batch_reward": 0.7337260464429856, "actor_loss": -78.42085775756836, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.563929080963135, "episode_reward": 818.7780490432026, "step": 59000}
{"episode": 60.0, "batch_reward": 0.7341789032816887, "actor_loss": -78.5347315826416, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.84922456741333, "episode_reward": 858.0922221528054, "step": 60000}
{"episode": 61.0, "batch_reward": 0.7355716354846954, "actor_loss": -78.54745613098144, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.36662244796753, "episode_reward": 829.8622450599414, "step": 61000}
{"episode": 62.0, "batch_reward": 0.7401323481798172, "actor_loss": -78.63866369628906, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.961084842681885, "episode_reward": 843.4276591277081, "step": 62000}
{"episode": 63.0, "batch_reward": 0.739728241443634, "actor_loss": -78.62757315063476, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.904470443725586, "episode_reward": 792.0162572735464, "step": 63000}
{"episode": 64.0, "batch_reward": 0.7412593988776207, "actor_loss": -78.64471275329589, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.573119401931763, "episode_reward": 804.7030395394864, "step": 64000}
{"episode": 65.0, "batch_reward": 0.7426345158219337, "actor_loss": -78.72104345703124, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.631913423538208, "episode_reward": 800.1678755045933, "step": 65000}
{"episode": 66.0, "batch_reward": 0.7421142821907997, "actor_loss": -78.71365135192872, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 23.0112087726593, "episode_reward": 634.6345783752759, "step": 66000}
{"episode": 67.0, "batch_reward": 0.7399810336828232, "actor_loss": -78.60411654663086, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.837822198867798, "episode_reward": 772.9916555937064, "step": 67000}
{"episode": 68.0, "batch_reward": 0.7400195189714431, "actor_loss": -78.58658544921875, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.878512382507324, "episode_reward": 693.2701873470453, "step": 68000}
{"episode": 69.0, "batch_reward": 0.742844876408577, "actor_loss": -78.67047766113281, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.549288511276245, "episode_reward": 847.6710616508697, "step": 69000}
{"episode": 70.0, "batch_reward": 0.7419288858175278, "actor_loss": -78.68655615234375, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.36799669265747, "episode_reward": 799.8903278012999, "step": 70000}
{"episode": 71.0, "batch_reward": 0.7422744860053062, "actor_loss": -78.69583421325683, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.62483191490173, "episode_reward": 834.4224980675557, "step": 71000}
{"episode": 72.0, "batch_reward": 0.7445520784854889, "actor_loss": -78.74006315612793, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.083935976028442, "episode_reward": 814.2382601135236, "step": 72000}
{"episode": 73.0, "batch_reward": 0.7442558336257935, "actor_loss": -78.70666600036621, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.141108989715576, "episode_reward": 667.1311965754156, "step": 73000}
{"episode": 74.0, "batch_reward": 0.7437788763642311, "actor_loss": -78.7168293762207, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.61684226989746, "episode_reward": 764.0347930253703, "step": 74000}
{"episode": 75.0, "batch_reward": 0.7453747814297677, "actor_loss": -78.71628236389161, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.83648443222046, "episode_reward": 828.0326714218866, "step": 75000}
{"episode": 76.0, "batch_reward": 0.7465804929733276, "actor_loss": -78.75820347595214, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.771363496780396, "episode_reward": 804.1118787913955, "step": 76000}
{"episode": 77.0, "batch_reward": 0.7452283535003662, "actor_loss": -78.73895227050781, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.911832094192505, "episode_reward": 760.8948036536975, "step": 77000}
{"episode": 78.0, "batch_reward": 0.7470890057086944, "actor_loss": -78.80224954223632, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.659931182861328, "episode_reward": 823.7185981437676, "step": 78000}
{"episode": 79.0, "batch_reward": 0.7498953374624252, "actor_loss": -78.84915002441406, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.872952699661255, "episode_reward": 814.083870884417, "step": 79000}
{"episode": 80.0, "batch_reward": 0.7488233153223991, "actor_loss": -78.81256649780273, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.710313081741333, "episode_reward": 765.8049233683107, "step": 80000}
{"episode": 81.0, "batch_reward": 0.7488216562271118, "actor_loss": -78.83170561218262, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.11643838882446, "episode_reward": 792.2485826061564, "step": 81000}
{"episode": 82.0, "batch_reward": 0.7480519061684608, "actor_loss": -78.80921255493163, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.560983896255493, "episode_reward": 774.3420619534836, "step": 82000}
{"episode": 83.0, "batch_reward": 0.7495876163244247, "actor_loss": -78.83368209838868, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.258421421051025, "episode_reward": 824.5353621373889, "step": 83000}
{"episode": 84.0, "batch_reward": 0.7500109900236129, "actor_loss": -78.85308599853515, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.66549015045166, "episode_reward": 766.8482685980222, "step": 84000}
{"episode": 85.0, "batch_reward": 0.7494097942113876, "actor_loss": -78.80426557922364, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.585144519805908, "episode_reward": 697.9688421486028, "step": 85000}
{"episode": 86.0, "batch_reward": 0.750148711502552, "actor_loss": -78.87590757751465, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.37094521522522, "episode_reward": 773.2800286293383, "step": 86000}
{"episode": 87.0, "batch_reward": 0.7500536687970162, "actor_loss": -78.81831356811523, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.687838792800903, "episode_reward": 824.7831749003285, "step": 87000}
{"episode": 88.0, "batch_reward": 0.7508540269732475, "actor_loss": -78.8307534790039, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.76334810256958, "episode_reward": 775.1550327104812, "step": 88000}
{"episode": 89.0, "batch_reward": 0.750553452372551, "actor_loss": -78.88524499511719, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.537840366363525, "episode_reward": 757.0621119795796, "step": 89000}
{"episode": 90.0, "batch_reward": 0.751225458085537, "actor_loss": -78.81020350646973, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.938969135284424, "episode_reward": 780.7979503029424, "step": 90000}
{"episode": 91.0, "batch_reward": 0.7513728793263436, "actor_loss": -78.85093624877929, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.595691204071045, "episode_reward": 777.8005770693256, "step": 91000}
{"episode": 92.0, "batch_reward": 0.7510649555325508, "actor_loss": -78.87488470458985, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 17.722010850906372, "episode_reward": 807.5641589201454, "step": 92000}
{"episode": 93.0, "batch_reward": 0.7520361494421959, "actor_loss": -78.85897772216796, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.20729684829712, "episode_reward": 833.3268492888158, "step": 93000}
{"episode": 94.0, "batch_reward": 0.7536288753747941, "actor_loss": -78.88294924926758, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.49924659729004, "episode_reward": 822.3852050434183, "step": 94000}
{"episode": 95.0, "batch_reward": 0.7550974533557891, "actor_loss": -78.95483085632324, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.43996024131775, "episode_reward": 786.7465044063885, "step": 95000}
{"episode": 96.0, "batch_reward": 0.75414485257864, "actor_loss": -78.95284330749512, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.69319438934326, "episode_reward": 752.9415492433626, "step": 96000}
{"episode": 97.0, "batch_reward": 0.7545028232932091, "actor_loss": -78.9566007232666, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.692354679107666, "episode_reward": 741.972173417906, "step": 97000}
{"episode": 98.0, "batch_reward": 0.7541490840911865, "actor_loss": -78.89863807678222, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.85918879508972, "episode_reward": 741.8323825259629, "step": 98000}
{"episode": 99.0, "batch_reward": 0.7553015655279159, "actor_loss": -78.95696282958984, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.567991018295288, "episode_reward": 807.3976898222963, "step": 99000}
{"episode": 100.0, "batch_reward": 0.7546273481845855, "actor_loss": -78.94067028808594, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.75215792655945, "episode_reward": 788.227451094124, "step": 100000}
{"episode": 101.0, "batch_reward": 0.755435342490673, "actor_loss": -78.89314912414551, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 43.00695276260376, "episode_reward": 852.3038857046505, "step": 101000}
{"episode": 102.0, "batch_reward": 0.7585096806883812, "actor_loss": -78.96228900146484, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.944819688796997, "episode_reward": 789.4429526665208, "step": 102000}
{"episode": 103.0, "batch_reward": 0.7563989651203156, "actor_loss": -78.9834363861084, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.78560709953308, "episode_reward": 818.7053579463966, "step": 103000}
{"episode": 104.0, "batch_reward": 0.7578534427285194, "actor_loss": -79.03210578918457, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.346345901489258, "episode_reward": 805.1273788316878, "step": 104000}
{"episode": 105.0, "batch_reward": 0.7591993122696876, "actor_loss": -79.02435134887695, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.4560489654541, "episode_reward": 839.4049942949291, "step": 105000}
{"episode": 106.0, "batch_reward": 0.7571991904377937, "actor_loss": -78.98679119873047, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.75436806678772, "episode_reward": 808.8034173096642, "step": 106000}
{"episode": 107.0, "batch_reward": 0.7580147148370743, "actor_loss": -79.00648083496094, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.529419422149658, "episode_reward": 801.3887518252992, "step": 107000}
{"episode": 108.0, "batch_reward": 0.7585003920197487, "actor_loss": -78.97683499145508, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.589868545532227, "episode_reward": 824.2971866316104, "step": 108000}
{"episode": 109.0, "batch_reward": 0.7599852069020271, "actor_loss": -79.06682711791993, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.100558519363403, "episode_reward": 883.9292049562114, "step": 109000}
{"episode": 110.0, "batch_reward": 0.7594654588699341, "actor_loss": -79.07436590576172, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.72555184364319, "episode_reward": 798.227570293155, "step": 110000}
{"episode": 111.0, "batch_reward": 0.7610505713224411, "actor_loss": -79.03694256591797, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.7410101890564, "episode_reward": 762.4155072273727, "step": 111000}
{"episode": 112.0, "batch_reward": 0.7601344802379608, "actor_loss": -79.06738745117187, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.110220432281494, "episode_reward": 786.5780392404412, "step": 112000}
{"episode": 113.0, "batch_reward": 0.763159785091877, "actor_loss": -79.09526461791992, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.933619499206543, "episode_reward": 766.1087598274343, "step": 113000}
{"episode": 114.0, "batch_reward": 0.7610679712295533, "actor_loss": -79.05294343566895, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.74983835220337, "episode_reward": 703.2268786454549, "step": 114000}
{"episode": 115.0, "batch_reward": 0.7603590987324714, "actor_loss": -79.07903086853027, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.929372787475586, "episode_reward": 865.3947924794628, "step": 115000}
{"episode": 116.0, "batch_reward": 0.762434670329094, "actor_loss": -79.07184313964844, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.695209980010986, "episode_reward": 765.4134739694247, "step": 116000}
{"episode": 117.0, "batch_reward": 0.7608881050944328, "actor_loss": -79.08388510131836, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.698846340179443, "episode_reward": 676.8215286754433, "step": 117000}
{"episode": 118.0, "batch_reward": 0.76031096637249, "actor_loss": -79.10297463989258, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.691645860671997, "episode_reward": 805.0984524348069, "step": 118000}
{"episode": 119.0, "batch_reward": 0.7610039896965027, "actor_loss": -79.10097555541992, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.505499124526978, "episode_reward": 810.2844858702902, "step": 119000}
{"episode": 120.0, "batch_reward": 0.7618753409385681, "actor_loss": -79.14902560424805, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.45472812652588, "episode_reward": 768.9520691171874, "step": 120000}
{"episode": 121.0, "batch_reward": 0.7614132337570191, "actor_loss": -79.07142872619629, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 39.65924572944641, "episode_reward": 803.6019979618418, "step": 121000}
{"episode": 122.0, "batch_reward": 0.7619330039024353, "actor_loss": -79.08906524658204, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.838521003723145, "episode_reward": 800.7168717144197, "step": 122000}
{"episode": 123.0, "batch_reward": 0.7625844027996064, "actor_loss": -79.14607801818848, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.593769550323486, "episode_reward": 786.0100014721702, "step": 123000}
{"episode": 124.0, "batch_reward": 0.763864439189434, "actor_loss": -79.16610191345215, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.550082206726074, "episode_reward": 859.9669219195315, "step": 124000}
{"episode": 125.0, "batch_reward": 0.7631584951877594, "actor_loss": -79.14520947265625, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.56207776069641, "episode_reward": 810.7742233625236, "step": 125000}
{"episode": 126.0, "batch_reward": 0.7652110483050346, "actor_loss": -79.17873234558105, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.44209337234497, "episode_reward": 706.7329069315132, "step": 126000}
{"episode": 127.0, "batch_reward": 0.7624156122803688, "actor_loss": -79.15732719421386, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 19.29400610923767, "episode_reward": 872.3427165812701, "step": 127000}
{"episode": 128.0, "batch_reward": 0.7645196232199669, "actor_loss": -79.19103396606445, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.795085430145264, "episode_reward": 862.3145822746559, "step": 128000}
{"episode": 129.0, "batch_reward": 0.7647728646993637, "actor_loss": -79.18011778259277, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 17.54739761352539, "episode_reward": 803.9723014979718, "step": 129000}
{"episode": 130.0, "batch_reward": 0.7657197532057762, "actor_loss": -79.17326358032227, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 17.98015260696411, "episode_reward": 823.3442837533887, "step": 130000}
{"episode": 131.0, "batch_reward": 0.7655982644557953, "actor_loss": -79.19662391662598, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 31.220564126968384, "episode_reward": 810.5582878958122, "step": 131000}
{"episode": 132.0, "batch_reward": 0.7663933701515198, "actor_loss": -79.19280526733398, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 17.420816898345947, "episode_reward": 828.1780830589533, "step": 132000}
{"episode": 133.0, "batch_reward": 0.7644133515954018, "actor_loss": -79.15688510131837, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 17.957030296325684, "episode_reward": 628.9190056813087, "step": 133000}
{"episode": 134.0, "batch_reward": 0.7653902431726456, "actor_loss": -79.22054782104492, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.20053005218506, "episode_reward": 790.5633790836673, "step": 134000}
{"episode": 135.0, "batch_reward": 0.7646036358475685, "actor_loss": -79.17842953491211, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.097774267196655, "episode_reward": 882.701522311472, "step": 135000}
{"episode": 136.0, "batch_reward": 0.7655332199335099, "actor_loss": -79.22291188049316, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.259087324142456, "episode_reward": 801.0933390489978, "step": 136000}
{"episode": 137.0, "batch_reward": 0.7664589364528656, "actor_loss": -79.18589442443847, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.371639728546143, "episode_reward": 878.0732352219736, "step": 137000}
{"episode": 138.0, "batch_reward": 0.7678280531167984, "actor_loss": -79.23608709716797, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.170913219451904, "episode_reward": 787.1921398939317, "step": 138000}
{"episode": 139.0, "batch_reward": 0.7672052052021027, "actor_loss": -79.21596841430664, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.054978847503662, "episode_reward": 849.9983080593046, "step": 139000}
{"episode": 140.0, "batch_reward": 0.7685894156694413, "actor_loss": -79.26369616699219, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.40572714805603, "episode_reward": 810.932778657784, "step": 140000}
{"episode": 141.0, "batch_reward": 0.7698570751547813, "actor_loss": -79.26015524291992, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 31.620156049728394, "episode_reward": 829.5992577888594, "step": 141000}
{"episode": 142.0, "batch_reward": 0.7690229455828667, "actor_loss": -79.21478341674805, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 17.69303870201111, "episode_reward": 847.016188826155, "step": 142000}
{"episode": 143.0, "batch_reward": 0.7718023717403412, "actor_loss": -79.29249508666992, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.05190658569336, "episode_reward": 859.2573340480425, "step": 143000}
{"episode": 144.0, "batch_reward": 0.7710872231721878, "actor_loss": -79.2074800415039, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.139670372009277, "episode_reward": 643.2238219579967, "step": 144000}
{"episode": 145.0, "batch_reward": 0.7687873828411103, "actor_loss": -79.22965655517578, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.258389234542847, "episode_reward": 813.6673568769077, "step": 145000}
{"episode": 146.0, "batch_reward": 0.7719616578817368, "actor_loss": -79.30512483215333, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.052823305130005, "episode_reward": 788.5229829061801, "step": 146000}
{"episode": 147.0, "batch_reward": 0.7687021812200546, "actor_loss": -79.26106211853028, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.41037631034851, "episode_reward": 813.8087214917905, "step": 147000}
{"episode": 148.0, "batch_reward": 0.7705808989405633, "actor_loss": -79.29603186035156, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 18.117685794830322, "episode_reward": 850.6964759523647, "step": 148000}
{"episode": 149.0, "batch_reward": 0.7690826800465583, "actor_loss": -79.22914801025391, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 17.930690050125122, "episode_reward": 805.6812107400987, "step": 149000}
{"episode": 150.0, "batch_reward": 0.7705144735574723, "actor_loss": -79.27080647277832, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "step": 150000}
