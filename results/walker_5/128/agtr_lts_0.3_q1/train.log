{"episode_reward": 0.0, "episode": 1.0, "duration": 22.17215323448181, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.9299390316009521, "step": 2000}
{"episode_reward": 632.427646246406, "episode": 3.0, "batch_reward": 0.33602069307363364, "critic_loss": 0.23428638562530268, "actor_loss": -23.8106920024117, "actor_target_entropy": -6.0, "alpha_value": 0.004365629073060301, "duration": 63.49529457092285, "step": 3000}
{"episode_reward": 236.55235463147326, "episode": 4.0, "batch_reward": 0.3288809629678726, "critic_loss": 0.5733885125517845, "actor_loss": -29.52802390098572, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.909815311431885, "step": 4000}
{"episode_reward": 355.96121628673603, "episode": 5.0, "batch_reward": 0.3276578469723463, "critic_loss": 0.7444977971315384, "actor_loss": -30.10468704032898, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.30209708213806, "step": 5000}
{"episode_reward": 420.3459587012076, "episode": 6.0, "batch_reward": 0.36144745230674746, "critic_loss": 0.8775298427343369, "actor_loss": -33.002811014175414, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.40183925628662, "step": 6000}
{"episode_reward": 643.1688643362406, "episode": 7.0, "batch_reward": 0.4023158112466335, "critic_loss": 1.0187985821962358, "actor_loss": -34.635053176879886, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.66172695159912, "step": 7000}
{"episode_reward": 520.524388148441, "episode": 8.0, "batch_reward": 0.4172132574617863, "critic_loss": 1.2974769949913025, "actor_loss": -40.24144855880737, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.40973734855652, "step": 8000}
{"episode_reward": 589.4979707246005, "episode": 9.0, "batch_reward": 0.44227911737561226, "critic_loss": 1.1939957917332649, "actor_loss": -41.014973415374754, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.797027826309204, "step": 9000}
{"episode_reward": 693.3112689518322, "episode": 10.0, "batch_reward": 0.4818069485425949, "critic_loss": 1.035785411477089, "actor_loss": -44.478938789367675, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.648757934570312, "step": 10000}
{"episode_reward": 891.3660576882497, "episode": 11.0, "batch_reward": 0.5128848014175892, "critic_loss": 1.1289578177928925, "actor_loss": -44.90262912750244, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.18197679519653, "step": 11000}
{"episode_reward": 752.6063818840265, "episode": 12.0, "batch_reward": 0.5334301135838032, "critic_loss": 1.354814077079296, "actor_loss": -48.66959253692627, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.472041845321655, "step": 12000}
{"episode_reward": 643.0192602512068, "episode": 13.0, "batch_reward": 0.5412286047637462, "critic_loss": 1.3199453924298286, "actor_loss": -49.78988740539551, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.657721042633057, "step": 13000}
{"episode_reward": 742.5389005854909, "episode": 14.0, "batch_reward": 0.5619681015014648, "critic_loss": 1.1881998306512833, "actor_loss": -52.46175954437256, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.922850131988525, "step": 14000}
{"episode_reward": 779.5968087910297, "episode": 15.0, "batch_reward": 0.5759225180745124, "critic_loss": 1.2365272653698922, "actor_loss": -53.66455909729004, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.135276079177856, "step": 15000}
{"episode_reward": 824.6994912036292, "episode": 16.0, "batch_reward": 0.5907314678132534, "critic_loss": 1.2031875994801522, "actor_loss": -55.25069213867187, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.062560319900513, "step": 16000}
{"episode_reward": 737.6779540534618, "episode": 17.0, "batch_reward": 0.5989896166324615, "critic_loss": 1.1691462174654006, "actor_loss": -56.109754119873045, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.071381330490112, "step": 17000}
{"episode_reward": 792.7580172100558, "episode": 18.0, "batch_reward": 0.6142556037306786, "critic_loss": 1.175815834581852, "actor_loss": -57.978795387268065, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.794813632965088, "step": 18000}
{"episode_reward": 873.5146505194051, "episode": 19.0, "batch_reward": 0.6276570545434952, "critic_loss": 1.1403708161115647, "actor_loss": -58.765801330566404, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.99224090576172, "step": 19000}
{"episode_reward": 902.9328125108134, "episode": 20.0, "batch_reward": 0.6413012984395027, "critic_loss": 1.0894560056328773, "actor_loss": -60.38144246673584, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.951215267181396, "step": 20000}
{"episode_reward": 859.6688816374908, "episode": 21.0, "batch_reward": 0.6557416418790817, "critic_loss": 1.1398704259991645, "actor_loss": -61.259976737976075, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.92226815223694, "step": 21000}
{"episode_reward": 891.5563619040324, "episode": 22.0, "batch_reward": 0.6650020928382874, "critic_loss": 1.145585467517376, "actor_loss": -62.542756774902344, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.006649494171143, "step": 22000}
{"episode_reward": 873.3487493614956, "episode": 23.0, "batch_reward": 0.6728532778620719, "critic_loss": 1.089890825867653, "actor_loss": -63.104896858215334, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.56616449356079, "step": 23000}
{"episode_reward": 928.1271489600284, "episode": 24.0, "batch_reward": 0.6812481127381325, "critic_loss": 1.1853929923772812, "actor_loss": -64.38419064331055, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.21668767929077, "step": 24000}
{"episode_reward": 822.7679516043149, "episode": 25.0, "batch_reward": 0.6907745224237442, "critic_loss": 1.1615317395329476, "actor_loss": -65.76177909088135, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.15874409675598, "step": 25000}
{"episode_reward": 920.1918946991152, "episode": 26.0, "batch_reward": 0.6967232364416123, "critic_loss": 1.1954769235253333, "actor_loss": -66.3177562789917, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.0861177444458, "step": 26000}
{"episode_reward": 863.5499390532358, "episode": 27.0, "batch_reward": 0.7054851222634315, "critic_loss": 1.1146936476826668, "actor_loss": -67.37373043823243, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.15921950340271, "step": 27000}
{"episode_reward": 913.1957736239558, "episode": 28.0, "batch_reward": 0.7134949645400047, "critic_loss": 1.1240521329641342, "actor_loss": -68.56498447418213, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.016624927520752, "step": 28000}
{"episode_reward": 940.5698459078193, "episode": 29.0, "batch_reward": 0.7185886922478676, "critic_loss": 1.1461412674188614, "actor_loss": -69.1199493560791, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.705654621124268, "step": 29000}
{"episode_reward": 845.35088720212, "episode": 30.0, "batch_reward": 0.7224914575219155, "critic_loss": 1.1146400398015976, "actor_loss": -69.94146891784668, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.30679750442505, "step": 30000}
{"episode_reward": 825.6198701307395, "episode": 31.0, "batch_reward": 0.729780285358429, "critic_loss": 1.0543425233364105, "actor_loss": -70.86962330627442, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.317707538604736, "step": 31000}
{"episode_reward": 904.3534528844096, "episode": 32.0, "batch_reward": 0.7336750952005386, "critic_loss": 1.0605744337439538, "actor_loss": -71.29972346496582, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.096790075302124, "step": 32000}
{"episode_reward": 920.3840085075192, "episode": 33.0, "batch_reward": 0.7412372596263885, "critic_loss": 0.9867286964952946, "actor_loss": -72.09139869689942, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.012605905532837, "step": 33000}
{"episode_reward": 951.754407030173, "episode": 34.0, "batch_reward": 0.7462296345829964, "critic_loss": 0.9060233765542507, "actor_loss": -72.80143632507324, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.865442276000977, "step": 34000}
{"episode_reward": 856.8701995388303, "episode": 35.0, "batch_reward": 0.7451467086672783, "critic_loss": 1.0261606106460095, "actor_loss": -72.93711741638184, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.453654527664185, "step": 35000}
{"episode_reward": 697.5764226190398, "episode": 36.0, "batch_reward": 0.7465617419481277, "critic_loss": 1.023504199206829, "actor_loss": -73.44794023132324, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.64537525177002, "step": 36000}
{"episode_reward": 816.6409497290974, "episode": 37.0, "batch_reward": 0.7502677323818207, "critic_loss": 1.000653225839138, "actor_loss": -73.70910731506348, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.604909658432007, "step": 37000}
{"episode_reward": 922.4909988319583, "episode": 38.0, "batch_reward": 0.7515298067927361, "critic_loss": 0.9700540601611137, "actor_loss": -73.99127336120605, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.21001696586609, "step": 38000}
{"episode_reward": 923.2985377804122, "episode": 39.0, "batch_reward": 0.7583513149619102, "critic_loss": 1.0277967376410961, "actor_loss": -74.67107620239258, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.020012617111206, "step": 39000}
{"episode_reward": 935.2479109045944, "episode": 40.0, "batch_reward": 0.7612116117477417, "critic_loss": 1.0760730949640274, "actor_loss": -75.11794921875, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.610228300094604, "step": 40000}
{"episode_reward": 862.8224396091537, "episode": 41.0, "batch_reward": 0.7652853429317474, "critic_loss": 0.9909193518161774, "actor_loss": -75.53587350463867, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.130497455596924, "step": 41000}
{"episode_reward": 917.4266568904023, "episode": 42.0, "batch_reward": 0.7701029102802277, "critic_loss": 1.0071795849502088, "actor_loss": -75.86744075012207, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.580763816833496, "step": 42000}
{"episode_reward": 925.214814330044, "episode": 43.0, "batch_reward": 0.7729638860225677, "critic_loss": 0.9827168481647969, "actor_loss": -76.29883625793457, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.10745358467102, "step": 43000}
{"episode_reward": 905.3240630472446, "episode": 44.0, "batch_reward": 0.7751949356794358, "critic_loss": 0.9622443504035473, "actor_loss": -76.6406182861328, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.997071743011475, "step": 44000}
{"episode_reward": 921.4520671280794, "episode": 45.0, "batch_reward": 0.7796308247447014, "critic_loss": 0.9558077666163445, "actor_loss": -76.99987509155274, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.846674919128418, "step": 45000}
{"episode_reward": 932.9172813250964, "episode": 46.0, "batch_reward": 0.7813604949712754, "critic_loss": 0.9155079157352447, "actor_loss": -77.39730323791504, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.102158546447754, "step": 46000}
{"episode_reward": 946.5258925445756, "episode": 47.0, "batch_reward": 0.7826537154912948, "critic_loss": 0.9356653768122196, "actor_loss": -77.74716928100585, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.918072938919067, "step": 47000}
{"episode_reward": 767.991731038896, "episode": 48.0, "batch_reward": 0.7846864401102066, "critic_loss": 0.9307689534425736, "actor_loss": -78.04524795532227, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.875384092330933, "step": 48000}
{"episode_reward": 927.8896185338108, "episode": 49.0, "batch_reward": 0.7884328858852386, "critic_loss": 0.9507866776585578, "actor_loss": -78.35877989196777, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.715171098709106, "step": 49000}
{"episode_reward": 879.8584039560526, "episode": 50.0, "batch_reward": 0.788875573515892, "critic_loss": 0.9654250464141368, "actor_loss": -78.57550875854493, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.957144021987915, "step": 50000}
{"episode_reward": 755.4677230544955, "episode": 51.0, "batch_reward": 0.7894749156832696, "critic_loss": 0.9657837467193604, "actor_loss": -78.8069854736328, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.798803091049194, "step": 51000}
{"episode_reward": 900.0452659404125, "episode": 52.0, "batch_reward": 0.7912367030382156, "critic_loss": 0.9583427723646164, "actor_loss": -79.00233528137207, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.029194116592407, "step": 52000}
{"episode_reward": 894.7054885149983, "episode": 53.0, "batch_reward": 0.7941024507880211, "critic_loss": 0.9724860500395298, "actor_loss": -79.193114944458, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.89917826652527, "step": 53000}
{"episode_reward": 878.9108671222007, "episode": 54.0, "batch_reward": 0.7944536705613137, "critic_loss": 0.9572354950606823, "actor_loss": -79.41096394348145, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.104947090148926, "step": 54000}
{"episode_reward": 956.2406832593167, "episode": 55.0, "batch_reward": 0.7990779718160629, "critic_loss": 0.9887732791900635, "actor_loss": -79.66316053771973, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.82848882675171, "step": 55000}
{"episode_reward": 944.5082242901658, "episode": 56.0, "batch_reward": 0.801281397998333, "critic_loss": 0.9480108235478402, "actor_loss": -79.8253507232666, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.858691215515137, "step": 56000}
{"episode_reward": 915.2832975153185, "episode": 57.0, "batch_reward": 0.803130425453186, "critic_loss": 0.9248171271085739, "actor_loss": -80.05966833496093, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.997690677642822, "step": 57000}
{"episode_reward": 912.6645942314768, "episode": 58.0, "batch_reward": 0.8062069899439812, "critic_loss": 0.8831233014166355, "actor_loss": -80.18826325988769, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.039498329162598, "step": 58000}
{"episode_reward": 959.3962304659663, "episode": 59.0, "batch_reward": 0.8087640268206596, "critic_loss": 0.8737764111459255, "actor_loss": -80.37981045532227, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.11921262741089, "step": 59000}
{"episode_reward": 921.0074938100103, "episode": 60.0, "batch_reward": 0.8099496114253998, "critic_loss": 0.9031828087270259, "actor_loss": -80.65514096069336, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.08562445640564, "step": 60000}
{"episode_reward": 942.7565117618313, "episode": 61.0, "batch_reward": 0.8112275100946427, "critic_loss": 0.8646654351055623, "actor_loss": -80.81719883728027, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.71638631820679, "step": 61000}
{"episode_reward": 889.9228083296402, "episode": 62.0, "batch_reward": 0.8106647962927819, "critic_loss": 0.8372005593776702, "actor_loss": -81.00333325195312, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.200313091278076, "step": 62000}
{"episode_reward": 787.7292400757168, "episode": 63.0, "batch_reward": 0.8126615105867386, "critic_loss": 0.8734586817622185, "actor_loss": -81.0587597503662, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.00469160079956, "step": 63000}
{"episode_reward": 872.8826739953071, "episode": 64.0, "batch_reward": 0.8136450484395027, "critic_loss": 0.8236980022490025, "actor_loss": -81.02389463806152, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.704979419708252, "step": 64000}
{"episode_reward": 899.0257206006851, "episode": 65.0, "batch_reward": 0.8151949335336686, "critic_loss": 0.8127637078464032, "actor_loss": -81.24521980285644, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.550607681274414, "step": 65000}
{"episode_reward": 918.2974651452917, "episode": 66.0, "batch_reward": 0.8164580719470977, "critic_loss": 0.8802924433648587, "actor_loss": -81.46304464721679, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.632006883621216, "step": 66000}
{"episode_reward": 938.0763725576426, "episode": 67.0, "batch_reward": 0.8189011583924294, "critic_loss": 0.8424617188870906, "actor_loss": -81.64268696594239, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.58420968055725, "step": 67000}
{"episode_reward": 927.5860387059469, "episode": 68.0, "batch_reward": 0.820881646156311, "critic_loss": 0.8231184948682785, "actor_loss": -81.72269468688965, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.4454984664917, "step": 68000}
{"episode_reward": 959.8476431172224, "episode": 69.0, "batch_reward": 0.8243551598191261, "critic_loss": 0.8290038955211639, "actor_loss": -81.95122758483886, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.750373363494873, "step": 69000}
{"episode_reward": 934.7891735991537, "episode": 70.0, "batch_reward": 0.823594820022583, "critic_loss": 0.7755654484927654, "actor_loss": -82.2004945526123, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.782952308654785, "step": 70000}
{"episode_reward": 940.1617585478135, "episode": 71.0, "batch_reward": 0.8253148621320725, "critic_loss": 0.7957540661692619, "actor_loss": -82.22885702514648, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.17940974235535, "step": 71000}
{"episode_reward": 898.2798725053499, "episode": 72.0, "batch_reward": 0.8251452215313911, "critic_loss": 0.8517875651419162, "actor_loss": -82.46151651000977, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.999330043792725, "step": 72000}
{"episode_reward": 790.2274795264309, "episode": 73.0, "batch_reward": 0.8264874043464661, "critic_loss": 0.8258552030622959, "actor_loss": -82.43914570617676, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.058122158050537, "step": 73000}
{"episode_reward": 918.8921739720068, "episode": 74.0, "batch_reward": 0.8273013387322425, "critic_loss": 0.8423238090574742, "actor_loss": -82.58406307983398, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.066420793533325, "step": 74000}
{"episode_reward": 942.4971579285287, "episode": 75.0, "batch_reward": 0.8303751143813133, "critic_loss": 0.7703168438374997, "actor_loss": -82.67460147094727, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.33132791519165, "step": 75000}
{"episode_reward": 917.2320824318168, "episode": 76.0, "batch_reward": 0.8291423768401146, "critic_loss": 0.8070574916899205, "actor_loss": -82.62284996032714, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.889455318450928, "step": 76000}
{"episode_reward": 922.2006591948953, "episode": 77.0, "batch_reward": 0.8318621267676354, "critic_loss": 0.8106100387573242, "actor_loss": -82.79675686645508, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.044610738754272, "step": 77000}
{"episode_reward": 945.5862855810001, "episode": 78.0, "batch_reward": 0.8319131319522858, "critic_loss": 0.7410296167135239, "actor_loss": -83.01363745117187, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.03907823562622, "step": 78000}
{"episode_reward": 961.3562393443328, "episode": 79.0, "batch_reward": 0.8359064440727234, "critic_loss": 0.7465176854431629, "actor_loss": -83.03755177307129, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.60450315475464, "step": 79000}
{"episode_reward": 966.0978847859566, "episode": 80.0, "batch_reward": 0.837454832136631, "critic_loss": 0.7630003190636635, "actor_loss": -83.24705081176758, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.11283588409424, "step": 80000}
{"episode_reward": 960.603276991375, "episode": 81.0, "batch_reward": 0.8376141710877418, "critic_loss": 0.7543175311684609, "actor_loss": -83.33608015441895, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.106149196624756, "step": 81000}
{"episode_reward": 870.4991399338377, "episode": 82.0, "batch_reward": 0.8371238449215889, "critic_loss": 0.7719801512360572, "actor_loss": -83.20003860473633, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.900275945663452, "step": 82000}
{"episode_reward": 916.9433194214356, "episode": 83.0, "batch_reward": 0.8398610737919807, "critic_loss": 0.7909913954436779, "actor_loss": -83.75024168395996, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.690292358398438, "step": 83000}
{"episode_reward": 915.1392452462364, "episode": 84.0, "batch_reward": 0.8404297336935997, "critic_loss": 0.7277013992965221, "actor_loss": -83.63250109863282, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.56864905357361, "step": 84000}
{"episode_reward": 964.0036341309882, "episode": 85.0, "batch_reward": 0.8415748465657235, "critic_loss": 0.7218507579565048, "actor_loss": -83.7584261932373, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.733702898025513, "step": 85000}
{"episode_reward": 914.7515970156471, "episode": 86.0, "batch_reward": 0.8392908830046654, "critic_loss": 0.7702526553571224, "actor_loss": -83.6121875, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.817917346954346, "step": 86000}
{"episode_reward": 779.0876790195279, "episode": 87.0, "batch_reward": 0.8403753139972687, "critic_loss": 0.754529158115387, "actor_loss": -83.84777862548827, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.60654640197754, "step": 87000}
{"episode_reward": 954.2964361351352, "episode": 88.0, "batch_reward": 0.8426474484801293, "critic_loss": 0.7279897557795048, "actor_loss": -83.92125067138672, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.747426748275757, "step": 88000}
{"episode_reward": 968.9210565401289, "episode": 89.0, "batch_reward": 0.84416090965271, "critic_loss": 0.7578595895469189, "actor_loss": -84.02736529541015, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.42604970932007, "step": 89000}
{"episode_reward": 892.1801499705497, "episode": 90.0, "batch_reward": 0.8441628960371017, "critic_loss": 0.740138048350811, "actor_loss": -83.91100480651855, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.577342987060547, "step": 90000}
{"episode_reward": 911.1320235793368, "episode": 91.0, "batch_reward": 0.8442412400245667, "critic_loss": 0.7535859080851078, "actor_loss": -83.99253793334961, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.09298896789551, "step": 91000}
{"episode_reward": 904.4644647789, "episode": 92.0, "batch_reward": 0.8461127249598503, "critic_loss": 0.7497267997264863, "actor_loss": -84.36244331359863, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.581888914108276, "step": 92000}
{"episode_reward": 951.3217348234178, "episode": 93.0, "batch_reward": 0.8470781143903733, "critic_loss": 0.7098257301449775, "actor_loss": -84.29670774841308, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.950809001922607, "step": 93000}
{"episode_reward": 936.5668617333523, "episode": 94.0, "batch_reward": 0.8480165429711342, "critic_loss": 0.6882456277310848, "actor_loss": -84.55942373657227, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.706106424331665, "step": 94000}
{"episode_reward": 910.3586669168379, "episode": 95.0, "batch_reward": 0.8480710108876228, "critic_loss": 0.7549631734788418, "actor_loss": -84.38329425048828, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.749065399169922, "step": 95000}
{"episode_reward": 879.1546102765419, "episode": 96.0, "batch_reward": 0.8496992857456207, "critic_loss": 0.7019727181494236, "actor_loss": -84.56010450744628, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.552478313446045, "step": 96000}
{"episode_reward": 951.4422139344558, "episode": 97.0, "batch_reward": 0.849480016708374, "critic_loss": 0.6926939026415349, "actor_loss": -84.3348946685791, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.42764973640442, "step": 97000}
{"episode_reward": 959.8241873462586, "episode": 98.0, "batch_reward": 0.8526130282282829, "critic_loss": 0.6877989657223225, "actor_loss": -84.26872503662109, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.619070529937744, "step": 98000}
{"episode_reward": 958.1485974328375, "episode": 99.0, "batch_reward": 0.852851318359375, "critic_loss": 0.6998075633049011, "actor_loss": -84.63507577514649, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.17048192024231, "step": 99000}
{"episode_reward": 951.3768768680445, "episode": 100.0, "batch_reward": 0.8532421070933341, "critic_loss": 0.7084437844157219, "actor_loss": -84.81907272338867, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.898428678512573, "step": 100000}
{"episode_reward": 922.2672396503485, "episode": 101.0, "batch_reward": 0.853511945784092, "critic_loss": 0.6667345495820045, "actor_loss": -84.88213424682617, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.20761227607727, "step": 101000}
{"episode_reward": 915.8472306803561, "episode": 102.0, "batch_reward": 0.8548255945444108, "critic_loss": 0.6735257847607136, "actor_loss": -84.83349662780762, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.01353907585144, "step": 102000}
{"episode_reward": 956.9423951996382, "episode": 103.0, "batch_reward": 0.855964493572712, "critic_loss": 0.6720345625579357, "actor_loss": -85.14057102966309, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.43426012992859, "step": 103000}
{"episode_reward": 959.1149051718087, "episode": 104.0, "batch_reward": 0.8569236453771591, "critic_loss": 0.6499557298272848, "actor_loss": -84.91663571166993, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.607686042785645, "step": 104000}
{"episode_reward": 930.2478188621657, "episode": 105.0, "batch_reward": 0.8572033856511116, "critic_loss": 0.661108488291502, "actor_loss": -85.35814584350587, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.03254771232605, "step": 105000}
{"episode_reward": 953.7655342722243, "episode": 106.0, "batch_reward": 0.8580864223837853, "critic_loss": 0.6196731498539447, "actor_loss": -85.2275241241455, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.30215573310852, "step": 106000}
{"episode_reward": 948.3231638628648, "episode": 107.0, "batch_reward": 0.8584964444637299, "critic_loss": 0.6531777830421924, "actor_loss": -85.29881111145019, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.60853385925293, "step": 107000}
{"episode_reward": 945.2371197630612, "episode": 108.0, "batch_reward": 0.8595219223499299, "critic_loss": 0.6117949065566063, "actor_loss": -85.34773249816895, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.909119606018066, "step": 108000}
{"episode_reward": 940.4878727598924, "episode": 109.0, "batch_reward": 0.860148003757, "critic_loss": 0.6242823384702205, "actor_loss": -85.03713674926757, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.740723133087158, "step": 109000}
{"episode_reward": 958.261184590239, "episode": 110.0, "batch_reward": 0.8626385995149612, "critic_loss": 0.6101435049325228, "actor_loss": -85.28179023742676, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.89109778404236, "step": 110000}
{"episode_reward": 919.7040709843517, "episode": 111.0, "batch_reward": 0.8620886447429656, "critic_loss": 0.6186840117573739, "actor_loss": -85.59299137878418, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.18201231956482, "step": 111000}
{"episode_reward": 932.3849325643449, "episode": 112.0, "batch_reward": 0.861629814863205, "critic_loss": 0.5986719012707472, "actor_loss": -85.69800473022461, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.607017517089844, "step": 112000}
{"episode_reward": 894.4729987856472, "episode": 113.0, "batch_reward": 0.864038297176361, "critic_loss": 0.6313183515965939, "actor_loss": -85.97753271484375, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.482805013656616, "step": 113000}
{"episode_reward": 964.5413736250937, "episode": 114.0, "batch_reward": 0.864088252723217, "critic_loss": 0.6543318187892437, "actor_loss": -85.59358390808106, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.968335390090942, "step": 114000}
{"episode_reward": 951.3344620233856, "episode": 115.0, "batch_reward": 0.865481438755989, "critic_loss": 0.6183248557448388, "actor_loss": -85.68129350280762, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.80671238899231, "step": 115000}
{"episode_reward": 955.4099516297271, "episode": 116.0, "batch_reward": 0.8653418430089951, "critic_loss": 0.61748119340837, "actor_loss": -85.67794165039062, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.517624139785767, "step": 116000}
{"episode_reward": 914.9798176180318, "episode": 117.0, "batch_reward": 0.866436414718628, "critic_loss": 0.6214403672367335, "actor_loss": -85.79665464782715, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.914910316467285, "step": 117000}
{"episode_reward": 933.3637134913024, "episode": 118.0, "batch_reward": 0.8659721100330353, "critic_loss": 0.6277859612554312, "actor_loss": -86.19196948242187, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.676053285598755, "step": 118000}
{"episode_reward": 962.0084765785979, "episode": 119.0, "batch_reward": 0.8671781075000763, "critic_loss": 0.6180484187155962, "actor_loss": -86.03934121704101, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.98490571975708, "step": 119000}
{"episode_reward": 961.0607702560686, "episode": 120.0, "batch_reward": 0.8683162221908569, "critic_loss": 0.6102080994695425, "actor_loss": -85.97518225097656, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.9745192527771, "step": 120000}
{"episode_reward": 946.9923295140699, "episode": 121.0, "batch_reward": 0.8684372298121452, "critic_loss": 0.6116492108106614, "actor_loss": -86.296853515625, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.803804874420166, "step": 121000}
{"episode_reward": 947.3129201360273, "episode": 122.0, "batch_reward": 0.8701028643846512, "critic_loss": 0.6284610280692577, "actor_loss": -85.85632691955567, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.66498589515686, "step": 122000}
{"episode_reward": 936.9496468011986, "episode": 123.0, "batch_reward": 0.8695488113760949, "critic_loss": 0.5981227450668812, "actor_loss": -85.51810073852539, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.715330839157104, "step": 123000}
{"episode_reward": 934.5428080908991, "episode": 124.0, "batch_reward": 0.870924221098423, "critic_loss": 0.6242108327299356, "actor_loss": -85.76619172668457, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.69316053390503, "step": 124000}
{"episode_reward": 831.3143807472809, "episode": 125.0, "batch_reward": 0.8712528476715088, "critic_loss": 0.6284562264531851, "actor_loss": -86.4095001373291, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.824528217315674, "step": 125000}
{"episode_reward": 929.2984228096029, "episode": 126.0, "batch_reward": 0.8699278699755668, "critic_loss": 0.6339099262058735, "actor_loss": -86.22274966430665, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.966216564178467, "step": 126000}
{"episode_reward": 940.0902685163912, "episode": 127.0, "batch_reward": 0.8708293067216873, "critic_loss": 0.6200114186108112, "actor_loss": -85.9360616455078, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.871810913085938, "step": 127000}
{"episode_reward": 887.4648699715993, "episode": 128.0, "batch_reward": 0.8715951430797577, "critic_loss": 0.6089141508936882, "actor_loss": -86.4449859008789, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.99503803253174, "step": 128000}
{"episode_reward": 966.406173324339, "episode": 129.0, "batch_reward": 0.8717608296871185, "critic_loss": 0.6171254211366176, "actor_loss": -86.22811158752441, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.127735376358032, "step": 129000}
{"episode_reward": 939.6624247435208, "episode": 130.0, "batch_reward": 0.8723376204371452, "critic_loss": 0.6472730000168085, "actor_loss": -86.09567895507813, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.84049129486084, "step": 130000}
{"episode_reward": 898.7031806892024, "episode": 131.0, "batch_reward": 0.8718544416427613, "critic_loss": 0.6106437811106443, "actor_loss": -86.67185162353516, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.457403898239136, "step": 131000}
{"episode_reward": 946.7566094531991, "episode": 132.0, "batch_reward": 0.872730048418045, "critic_loss": 0.6156433287113905, "actor_loss": -86.36204254150391, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.781442403793335, "step": 132000}
{"episode_reward": 928.0292137071432, "episode": 133.0, "batch_reward": 0.8718816417455674, "critic_loss": 0.6466766190081835, "actor_loss": -86.5213575592041, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.541617155075073, "step": 133000}
{"episode_reward": 930.0754431642712, "episode": 134.0, "batch_reward": 0.873761853337288, "critic_loss": 0.5767381170094014, "actor_loss": -86.46243705749512, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.02787184715271, "step": 134000}
{"episode_reward": 943.224721542383, "episode": 135.0, "batch_reward": 0.8735044566392899, "critic_loss": 0.5839786803126336, "actor_loss": -86.41924864196777, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.030409812927246, "step": 135000}
{"episode_reward": 908.2469921331076, "episode": 136.0, "batch_reward": 0.8734518898129463, "critic_loss": 0.648662345558405, "actor_loss": -86.59189805603027, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.99450135231018, "step": 136000}
{"episode_reward": 845.218440818885, "episode": 137.0, "batch_reward": 0.8742758387327194, "critic_loss": 0.6904092317819596, "actor_loss": -86.41143392944336, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.074610471725464, "step": 137000}
{"episode_reward": 967.0569561038134, "episode": 138.0, "batch_reward": 0.8751010402441025, "critic_loss": 0.6270960767716169, "actor_loss": -86.74526519775391, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.28296709060669, "step": 138000}
{"episode_reward": 944.0380889172872, "episode": 139.0, "batch_reward": 0.8757196972966195, "critic_loss": 0.6219957585036755, "actor_loss": -86.88293615722657, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.899957180023193, "step": 139000}
{"episode_reward": 931.7480351510422, "episode": 140.0, "batch_reward": 0.8758982793092728, "critic_loss": 0.6229174464792013, "actor_loss": -86.74650936889648, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 22.02406120300293, "step": 140000}
{"episode_reward": 941.9065516710107, "episode": 141.0, "batch_reward": 0.8764457796812057, "critic_loss": 0.6368890825808048, "actor_loss": -86.69734730529785, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.72934913635254, "step": 141000}
{"episode_reward": 961.3504874524868, "episode": 142.0, "batch_reward": 0.8770835926532745, "critic_loss": 0.6645832693576813, "actor_loss": -86.81192613220215, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.687248468399048, "step": 142000}
{"episode_reward": 875.8053335586975, "episode": 143.0, "batch_reward": 0.8766523053646088, "critic_loss": 0.61313777962327, "actor_loss": -86.82729525756837, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.840370416641235, "step": 143000}
{"episode_reward": 936.0448000368873, "episode": 144.0, "batch_reward": 0.8778168718814849, "critic_loss": 0.6206613500267267, "actor_loss": -87.01702836608887, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.011958599090576, "step": 144000}
{"episode_reward": 910.7515868675009, "episode": 145.0, "batch_reward": 0.8773259226679802, "critic_loss": 0.6467529841512442, "actor_loss": -86.81165768432618, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.466755867004395, "step": 145000}
{"episode_reward": 950.7922419914819, "episode": 146.0, "batch_reward": 0.8780101720690727, "critic_loss": 0.6578339658379555, "actor_loss": -86.98276443481446, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.85138463973999, "step": 146000}
{"episode_reward": 975.377834204123, "episode": 147.0, "batch_reward": 0.8786788527369499, "critic_loss": 0.598003532230854, "actor_loss": -87.02871520996094, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.797478437423706, "step": 147000}
{"episode_reward": 912.9492549641661, "episode": 148.0, "batch_reward": 0.878652840256691, "critic_loss": 0.6133310288488865, "actor_loss": -87.18417086791992, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.414981842041016, "step": 148000}
{"episode_reward": 934.6464451447989, "episode": 149.0, "batch_reward": 0.8785015856623649, "critic_loss": 0.6086859789639711, "actor_loss": -87.31655801391602, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.919732570648193, "step": 149000}
{"episode_reward": 954.946445138042, "episode": 150.0, "batch_reward": 0.8809681020975113, "critic_loss": 0.6056552543491125, "actor_loss": -87.58381266784669, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "step": 150000}
