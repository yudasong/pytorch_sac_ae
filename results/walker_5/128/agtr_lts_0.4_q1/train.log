{"episode_reward": 0.0, "episode": 1.0, "duration": 21.585513830184937, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.839073896408081, "step": 2000}
{"episode_reward": 632.427646246406, "episode": 3.0, "batch_reward": 0.335836051031326, "critic_loss": 0.2884782718897621, "actor_loss": -29.898321112405423, "actor_target_entropy": -6.0, "alpha_value": 0.004365629073060301, "duration": 62.548224687576294, "step": 3000}
{"episode_reward": 159.92784410562103, "episode": 4.0, "batch_reward": 0.30645089139044285, "critic_loss": 0.6709389082491398, "actor_loss": -32.77322784996033, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.632123470306396, "step": 4000}
{"episode_reward": 426.82102663697117, "episode": 5.0, "batch_reward": 0.33595678466558454, "critic_loss": 0.8409723367989064, "actor_loss": -34.57368861961365, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.401068925857544, "step": 5000}
{"episode_reward": 461.0226533290294, "episode": 6.0, "batch_reward": 0.3536438707858324, "critic_loss": 1.0681126000881196, "actor_loss": -36.96162753677368, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.776548385620117, "step": 6000}
{"episode_reward": 479.99865894180806, "episode": 7.0, "batch_reward": 0.383297569334507, "critic_loss": 1.1673837131857872, "actor_loss": -38.18914470291138, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.923876762390137, "step": 7000}
{"episode_reward": 627.8957223568366, "episode": 8.0, "batch_reward": 0.4281831343770027, "critic_loss": 1.313037970483303, "actor_loss": -43.200031742095945, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.617366313934326, "step": 8000}
{"episode_reward": 728.3154794328765, "episode": 9.0, "batch_reward": 0.45987159678339956, "critic_loss": 1.3835243612527848, "actor_loss": -44.59438026428223, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.79476523399353, "step": 9000}
{"episode_reward": 525.6693296862559, "episode": 10.0, "batch_reward": 0.45648573181033136, "critic_loss": 1.663574550330639, "actor_loss": -46.596328258514404, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.8817880153656, "step": 10000}
{"episode_reward": 509.6727682913619, "episode": 11.0, "batch_reward": 0.47288657200336454, "critic_loss": 1.6716168333888053, "actor_loss": -47.450098140716555, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.25043034553528, "step": 11000}
{"episode_reward": 800.8842802656843, "episode": 12.0, "batch_reward": 0.5100653283894062, "critic_loss": 1.5202854587435721, "actor_loss": -50.524144340515136, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.538137912750244, "step": 12000}
{"episode_reward": 905.8712526885404, "episode": 13.0, "batch_reward": 0.5391437535881997, "critic_loss": 1.4586124614477158, "actor_loss": -52.188862449645995, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.36325192451477, "step": 13000}
{"episode_reward": 883.8663890393375, "episode": 14.0, "batch_reward": 0.5669421004354954, "critic_loss": 1.4764876942634582, "actor_loss": -55.365574264526366, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.19842791557312, "step": 14000}
{"episode_reward": 899.5229596348943, "episode": 15.0, "batch_reward": 0.5893136341571807, "critic_loss": 1.4214378563165664, "actor_loss": -56.219661506652834, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.687906742095947, "step": 15000}
{"episode_reward": 914.0642470189662, "episode": 16.0, "batch_reward": 0.6102046281099319, "critic_loss": 1.3283868183493615, "actor_loss": -57.98695970153808, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.79156732559204, "step": 16000}
{"episode_reward": 937.428828226895, "episode": 17.0, "batch_reward": 0.6231369331479073, "critic_loss": 1.362235839664936, "actor_loss": -59.722182067871096, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.866315126419067, "step": 17000}
{"episode_reward": 715.1437312916787, "episode": 18.0, "batch_reward": 0.635408027112484, "critic_loss": 1.2595784478187562, "actor_loss": -61.476333694458006, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.702531337738037, "step": 18000}
{"episode_reward": 861.185447708538, "episode": 19.0, "batch_reward": 0.6431131305098534, "critic_loss": 1.1467541608214378, "actor_loss": -61.5444482421875, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.39840340614319, "step": 19000}
{"episode_reward": 752.4830154082371, "episode": 20.0, "batch_reward": 0.6511882571578026, "critic_loss": 1.10699285531044, "actor_loss": -62.722830047607424, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.489385843276978, "step": 20000}
{"episode_reward": 711.5824505955319, "episode": 21.0, "batch_reward": 0.6559608803987503, "critic_loss": 1.0058445110321046, "actor_loss": -63.3543390045166, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 42.03328323364258, "step": 21000}
{"episode_reward": 899.5226036444325, "episode": 22.0, "batch_reward": 0.6664478332996369, "critic_loss": 1.1039287398457527, "actor_loss": -64.32780362701416, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.39838409423828, "step": 22000}
{"episode_reward": 856.8928498101811, "episode": 23.0, "batch_reward": 0.6735993646979332, "critic_loss": 1.1067771538496018, "actor_loss": -64.69949137878417, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.962604999542236, "step": 23000}
{"episode_reward": 870.9693286985556, "episode": 24.0, "batch_reward": 0.6823907158970833, "critic_loss": 1.0506001425385476, "actor_loss": -65.0865938873291, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.765443563461304, "step": 24000}
{"episode_reward": 902.9554226582298, "episode": 25.0, "batch_reward": 0.6798712996840477, "critic_loss": 1.1869463142752648, "actor_loss": -66.35613996887207, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.623745918273926, "step": 25000}
{"episode_reward": 371.11578237262773, "episode": 26.0, "batch_reward": 0.6782793244719505, "critic_loss": 1.1207173949480056, "actor_loss": -66.26561791229248, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.50494909286499, "step": 26000}
{"episode_reward": 834.4889980513547, "episode": 27.0, "batch_reward": 0.6814152082204818, "critic_loss": 1.1438530935049056, "actor_loss": -66.77459664916992, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.802240133285522, "step": 27000}
{"episode_reward": 718.8309749718433, "episode": 28.0, "batch_reward": 0.6833672116398811, "critic_loss": 1.2174745951294899, "actor_loss": -67.78654804229737, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.13954520225525, "step": 28000}
{"episode_reward": 699.7619085038301, "episode": 29.0, "batch_reward": 0.6856484097242356, "critic_loss": 1.2121117242574693, "actor_loss": -68.09143393707275, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.596259832382202, "step": 29000}
{"episode_reward": 867.1991198689807, "episode": 30.0, "batch_reward": 0.69146948492527, "critic_loss": 1.3105955482125282, "actor_loss": -68.51511859893799, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.74900197982788, "step": 30000}
{"episode_reward": 818.1332680963047, "episode": 31.0, "batch_reward": 0.6975369028449059, "critic_loss": 1.1975736320614814, "actor_loss": -69.69511841583252, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.69814133644104, "step": 31000}
{"episode_reward": 928.9200645385798, "episode": 32.0, "batch_reward": 0.7042142563462257, "critic_loss": 1.2409848836064339, "actor_loss": -69.74603813934326, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.900466918945312, "step": 32000}
{"episode_reward": 913.0903540007454, "episode": 33.0, "batch_reward": 0.7123516019582748, "critic_loss": 1.3141438421010971, "actor_loss": -70.44314863586426, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.42431330680847, "step": 33000}
{"episode_reward": 943.2156985847922, "episode": 34.0, "batch_reward": 0.7192787806987763, "critic_loss": 1.1758628270626068, "actor_loss": -71.25611421203614, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.361680507659912, "step": 34000}
{"episode_reward": 879.8015153129384, "episode": 35.0, "batch_reward": 0.7206433224678039, "critic_loss": 1.2054477158784866, "actor_loss": -71.54182806396484, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.496378183364868, "step": 35000}
{"episode_reward": 769.2930242356009, "episode": 36.0, "batch_reward": 0.7242626222968102, "critic_loss": 1.1258395369648933, "actor_loss": -72.09960313415527, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.716201543807983, "step": 36000}
{"episode_reward": 902.4840539361901, "episode": 37.0, "batch_reward": 0.7273256514072418, "critic_loss": 1.131136949121952, "actor_loss": -72.33874380493164, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.346203327178955, "step": 37000}
{"episode_reward": 735.3173883205551, "episode": 38.0, "batch_reward": 0.7271733763813972, "critic_loss": 1.149539148390293, "actor_loss": -72.63881146240234, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.017375946044922, "step": 38000}
{"episode_reward": 925.3275888785521, "episode": 39.0, "batch_reward": 0.7336721946001052, "critic_loss": 1.1011588816642761, "actor_loss": -73.26083079528809, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.595993280410767, "step": 39000}
{"episode_reward": 921.8566691869325, "episode": 40.0, "batch_reward": 0.7360068268179893, "critic_loss": 1.107985181570053, "actor_loss": -73.82878305053711, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.02353525161743, "step": 40000}
{"episode_reward": 834.3716383111146, "episode": 41.0, "batch_reward": 0.7394816833138466, "critic_loss": 1.1970652241110802, "actor_loss": -74.11674856567383, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.765750885009766, "step": 41000}
{"episode_reward": 891.3685102453976, "episode": 42.0, "batch_reward": 0.7452878862023353, "critic_loss": 1.164752829670906, "actor_loss": -74.4899328918457, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.7665958404541, "step": 42000}
{"episode_reward": 938.2777005859527, "episode": 43.0, "batch_reward": 0.7484143820405006, "critic_loss": 1.0643858391046523, "actor_loss": -74.83336215209961, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.6853609085083, "step": 43000}
{"episode_reward": 884.9995905067029, "episode": 44.0, "batch_reward": 0.7511092638969421, "critic_loss": 1.1237757845520973, "actor_loss": -75.11055938720703, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.840657472610474, "step": 44000}
{"episode_reward": 899.4035498487945, "episode": 45.0, "batch_reward": 0.7533344368934631, "critic_loss": 1.0718014724850655, "actor_loss": -75.2378782196045, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.267399072647095, "step": 45000}
{"episode_reward": 775.3456141598703, "episode": 46.0, "batch_reward": 0.7559906936883927, "critic_loss": 1.026488939523697, "actor_loss": -75.51394819641114, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.55573558807373, "step": 46000}
{"episode_reward": 837.7069043769868, "episode": 47.0, "batch_reward": 0.7551018761992454, "critic_loss": 1.1004806001782417, "actor_loss": -75.94329528808593, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.807230710983276, "step": 47000}
{"episode_reward": 805.5543958308218, "episode": 48.0, "batch_reward": 0.7595142195224762, "critic_loss": 1.0856570574641227, "actor_loss": -76.07089579772949, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.28671669960022, "step": 48000}
{"episode_reward": 944.8908990272985, "episode": 49.0, "batch_reward": 0.763625873208046, "critic_loss": 1.1102286463975906, "actor_loss": -76.43956048583985, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.37421441078186, "step": 49000}
{"episode_reward": 909.3689269482308, "episode": 50.0, "batch_reward": 0.7629697004556656, "critic_loss": 1.1392798851728438, "actor_loss": -76.58661116027832, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.767629623413086, "step": 50000}
{"episode_reward": 801.5144063996103, "episode": 51.0, "batch_reward": 0.7652338336110115, "critic_loss": 1.154521823465824, "actor_loss": -76.7647045135498, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.89355421066284, "step": 51000}
{"episode_reward": 917.7482366703344, "episode": 52.0, "batch_reward": 0.7695011088252067, "critic_loss": 1.0413779540657997, "actor_loss": -77.01944076538086, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.377426147460938, "step": 52000}
{"episode_reward": 928.2850616180281, "episode": 53.0, "batch_reward": 0.7724648661613465, "critic_loss": 1.064078030884266, "actor_loss": -77.32811875915527, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.551907300949097, "step": 53000}
{"episode_reward": 924.3631324377596, "episode": 54.0, "batch_reward": 0.7739163972139359, "critic_loss": 1.0696080684661866, "actor_loss": -77.51001448059083, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.438281774520874, "step": 54000}
{"episode_reward": 927.9463495381788, "episode": 55.0, "batch_reward": 0.7785442914962769, "critic_loss": 1.0666254045665264, "actor_loss": -77.87684237670898, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.854801654815674, "step": 55000}
{"episode_reward": 940.350892644782, "episode": 56.0, "batch_reward": 0.7800843362212181, "critic_loss": 1.1347730022668838, "actor_loss": -78.01488711547852, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.787209510803223, "step": 56000}
{"episode_reward": 889.496435306094, "episode": 57.0, "batch_reward": 0.7825042682290078, "critic_loss": 1.0707308258414268, "actor_loss": -78.21410194396972, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.385199308395386, "step": 57000}
{"episode_reward": 862.7630041947383, "episode": 58.0, "batch_reward": 0.7846588585376739, "critic_loss": 1.0576936516165734, "actor_loss": -78.4140302734375, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.36237359046936, "step": 58000}
{"episode_reward": 927.4857302552799, "episode": 59.0, "batch_reward": 0.7878836468458176, "critic_loss": 1.0679612435996533, "actor_loss": -78.61725271606446, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.747148275375366, "step": 59000}
{"episode_reward": 923.1257800258547, "episode": 60.0, "batch_reward": 0.7879255108237266, "critic_loss": 1.0601042756438255, "actor_loss": -78.79171255493164, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.0567045211792, "step": 60000}
{"episode_reward": 924.3572314003576, "episode": 61.0, "batch_reward": 0.791722128868103, "critic_loss": 1.0251716811358929, "actor_loss": -79.07115681457519, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.44688034057617, "step": 61000}
{"episode_reward": 944.9776305870541, "episode": 62.0, "batch_reward": 0.7941794840693474, "critic_loss": 1.009330741494894, "actor_loss": -79.32027319335937, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.12960934638977, "step": 62000}
{"episode_reward": 925.6766859189553, "episode": 63.0, "batch_reward": 0.7945049088001251, "critic_loss": 0.9043037535548211, "actor_loss": -79.47787059020996, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.39622211456299, "step": 63000}
{"episode_reward": 921.1676118216635, "episode": 64.0, "batch_reward": 0.7982190420031547, "critic_loss": 0.9139507266283036, "actor_loss": -79.60703953552246, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.426276206970215, "step": 64000}
{"episode_reward": 950.0772049129816, "episode": 65.0, "batch_reward": 0.7988689919710159, "critic_loss": 0.9312748825252056, "actor_loss": -79.76978158569337, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.127002716064453, "step": 65000}
{"episode_reward": 875.5291198318677, "episode": 66.0, "batch_reward": 0.8024755996465683, "critic_loss": 0.9324802188575267, "actor_loss": -79.9656358795166, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.4355366230011, "step": 66000}
{"episode_reward": 938.7341641270439, "episode": 67.0, "batch_reward": 0.8042673155069351, "critic_loss": 0.9662722042798996, "actor_loss": -80.13059606933594, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.476332187652588, "step": 67000}
{"episode_reward": 875.3212053585697, "episode": 68.0, "batch_reward": 0.8053580631017685, "critic_loss": 0.8801512606143952, "actor_loss": -80.11984138488769, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.14440631866455, "step": 68000}
{"episode_reward": 950.728343405203, "episode": 69.0, "batch_reward": 0.808356128513813, "critic_loss": 0.9279629976153374, "actor_loss": -80.3791651763916, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.388145208358765, "step": 69000}
{"episode_reward": 921.6690950229446, "episode": 70.0, "batch_reward": 0.8097063919305801, "critic_loss": 0.8955853267610073, "actor_loss": -80.56557789611817, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.634677410125732, "step": 70000}
{"episode_reward": 944.5808430402332, "episode": 71.0, "batch_reward": 0.8095404881834983, "critic_loss": 0.8763173592090606, "actor_loss": -80.61031210327148, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.54003930091858, "step": 71000}
{"episode_reward": 911.9582125131492, "episode": 72.0, "batch_reward": 0.811447067797184, "critic_loss": 0.8887758197188378, "actor_loss": -80.78681480407715, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.476588487625122, "step": 72000}
{"episode_reward": 940.299964637585, "episode": 73.0, "batch_reward": 0.8128354980945587, "critic_loss": 0.8918060357272625, "actor_loss": -80.9086557006836, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.15431833267212, "step": 73000}
{"episode_reward": 938.8686530453612, "episode": 74.0, "batch_reward": 0.8159607774615287, "critic_loss": 0.853723802447319, "actor_loss": -81.09290296936035, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.389588594436646, "step": 74000}
{"episode_reward": 924.0261897103446, "episode": 75.0, "batch_reward": 0.8178000511527062, "critic_loss": 0.8396613691449165, "actor_loss": -81.18214060974121, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.20870614051819, "step": 75000}
{"episode_reward": 950.5951778328739, "episode": 76.0, "batch_reward": 0.8199069721102714, "critic_loss": 0.8686668266654014, "actor_loss": -81.2945221710205, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.648736715316772, "step": 76000}
{"episode_reward": 935.9474810193415, "episode": 77.0, "batch_reward": 0.8198150890469551, "critic_loss": 0.8414075466096401, "actor_loss": -81.39937715148926, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.454355001449585, "step": 77000}
{"episode_reward": 925.47108839361, "episode": 78.0, "batch_reward": 0.8223216422200202, "critic_loss": 0.8970956798791886, "actor_loss": -81.69494911193847, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.737958192825317, "step": 78000}
{"episode_reward": 964.0031883250394, "episode": 79.0, "batch_reward": 0.8246295090317726, "critic_loss": 0.8393387069404126, "actor_loss": -81.72255557250976, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.785056591033936, "step": 79000}
{"episode_reward": 970.2498863117735, "episode": 80.0, "batch_reward": 0.8250062488913537, "critic_loss": 0.7972724405527115, "actor_loss": -81.90492517089844, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.583295106887817, "step": 80000}
{"episode_reward": 968.9920450312362, "episode": 81.0, "batch_reward": 0.8265054161548615, "critic_loss": 0.8379569441974163, "actor_loss": -81.92029769897461, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.76844930648804, "step": 81000}
{"episode_reward": 954.7768711519639, "episode": 82.0, "batch_reward": 0.8291516616344452, "critic_loss": 0.8557850777804852, "actor_loss": -82.01202352905274, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.494076013565063, "step": 82000}
{"episode_reward": 937.8731361955151, "episode": 83.0, "batch_reward": 0.8308040071129799, "critic_loss": 0.8085917077064514, "actor_loss": -82.31510313415528, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.435103178024292, "step": 83000}
{"episode_reward": 949.0296464354608, "episode": 84.0, "batch_reward": 0.8303566220998764, "critic_loss": 0.7872634452581405, "actor_loss": -82.30604039001464, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.785141229629517, "step": 84000}
{"episode_reward": 968.9311672328746, "episode": 85.0, "batch_reward": 0.8329484125375748, "critic_loss": 0.7601044218838214, "actor_loss": -82.48789971923829, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.095046043395996, "step": 85000}
{"episode_reward": 919.9965223279193, "episode": 86.0, "batch_reward": 0.8332026312947274, "critic_loss": 0.736587489515543, "actor_loss": -82.57024481201172, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.661756992340088, "step": 86000}
{"episode_reward": 889.3989474543529, "episode": 87.0, "batch_reward": 0.8343564680218697, "critic_loss": 0.7871123857200145, "actor_loss": -82.63044729614258, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.720281839370728, "step": 87000}
{"episode_reward": 945.8510301771563, "episode": 88.0, "batch_reward": 0.8360396400094032, "critic_loss": 0.754343115657568, "actor_loss": -82.85249421691894, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.51301097869873, "step": 88000}
{"episode_reward": 970.6118185953075, "episode": 89.0, "batch_reward": 0.8383135313987732, "critic_loss": 0.7674528307020664, "actor_loss": -82.88368980407715, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.82485055923462, "step": 89000}
{"episode_reward": 934.6592506008926, "episode": 90.0, "batch_reward": 0.8379498138427734, "critic_loss": 0.8086379108428955, "actor_loss": -82.88777424621583, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.786557912826538, "step": 90000}
{"episode_reward": 851.5880247517536, "episode": 91.0, "batch_reward": 0.8369964815974236, "critic_loss": 0.8120941178202629, "actor_loss": -82.96790002441406, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.83631491661072, "step": 91000}
{"episode_reward": 921.1065103701753, "episode": 92.0, "batch_reward": 0.8396048730611801, "critic_loss": 0.7637530899643898, "actor_loss": -83.33604797363282, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.765702962875366, "step": 92000}
{"episode_reward": 952.9189519144169, "episode": 93.0, "batch_reward": 0.8402197924256325, "critic_loss": 0.786989556580782, "actor_loss": -83.20384358215333, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.506627559661865, "step": 93000}
{"episode_reward": 862.4398039491855, "episode": 94.0, "batch_reward": 0.8408656948208809, "critic_loss": 0.8251557481884957, "actor_loss": -83.44613410949707, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.288670778274536, "step": 94000}
{"episode_reward": 901.0090409032377, "episode": 95.0, "batch_reward": 0.8397047696709633, "critic_loss": 0.859765951871872, "actor_loss": -83.2081708984375, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.754705905914307, "step": 95000}
{"episode_reward": 852.7880476288535, "episode": 96.0, "batch_reward": 0.8411374596357346, "critic_loss": 0.8086545500159263, "actor_loss": -83.54397848510742, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.794126510620117, "step": 96000}
{"episode_reward": 958.872454651219, "episode": 97.0, "batch_reward": 0.8405683037042618, "critic_loss": 0.7977345936894417, "actor_loss": -83.2931026763916, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.824316024780273, "step": 97000}
{"episode_reward": 930.5973020683408, "episode": 98.0, "batch_reward": 0.8436887391805649, "critic_loss": 0.8395383672714234, "actor_loss": -83.23674385070801, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.7859308719635, "step": 98000}
{"episode_reward": 881.9518025884046, "episode": 99.0, "batch_reward": 0.8440933976769447, "critic_loss": 0.8199293555021286, "actor_loss": -83.5998296661377, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.81046175956726, "step": 99000}
{"episode_reward": 956.2309482606879, "episode": 100.0, "batch_reward": 0.8458791477680206, "critic_loss": 0.819905881255865, "actor_loss": -83.73413803100586, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.774884939193726, "step": 100000}
{"episode_reward": 921.6724802887604, "episode": 101.0, "batch_reward": 0.8459252331256867, "critic_loss": 0.8283720159232616, "actor_loss": -83.88123194885254, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.95292854309082, "step": 101000}
{"episode_reward": 800.3217553952474, "episode": 102.0, "batch_reward": 0.8453132817745209, "critic_loss": 0.7944090631306171, "actor_loss": -83.64420274353027, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.625598430633545, "step": 102000}
{"episode_reward": 921.2217754478241, "episode": 103.0, "batch_reward": 0.8468087267279625, "critic_loss": 0.7981551060974598, "actor_loss": -83.95223997497558, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.760934114456177, "step": 103000}
{"episode_reward": 940.9556870227551, "episode": 104.0, "batch_reward": 0.8481338624358177, "critic_loss": 0.8080442480444908, "actor_loss": -83.79148175048829, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.51695203781128, "step": 104000}
{"episode_reward": 937.7170434301034, "episode": 105.0, "batch_reward": 0.8491500536799431, "critic_loss": 0.7862449351549149, "actor_loss": -84.1208900604248, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.39717698097229, "step": 105000}
{"episode_reward": 969.8696579520695, "episode": 106.0, "batch_reward": 0.8483486196994782, "critic_loss": 0.7457215202450752, "actor_loss": -84.12180583190919, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.31466245651245, "step": 106000}
{"episode_reward": 955.4926990296697, "episode": 107.0, "batch_reward": 0.8499711829423905, "critic_loss": 0.7709230392575264, "actor_loss": -84.11621435546876, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.52995228767395, "step": 107000}
{"episode_reward": 921.4223793233825, "episode": 108.0, "batch_reward": 0.8505550124645234, "critic_loss": 0.7664238270819187, "actor_loss": -84.16538078308105, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.403001308441162, "step": 108000}
{"episode_reward": 952.1377917480181, "episode": 109.0, "batch_reward": 0.8521686484217643, "critic_loss": 0.7812101947665214, "actor_loss": -84.00096478271485, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.01655602455139, "step": 109000}
{"episode_reward": 943.9598382102481, "episode": 110.0, "batch_reward": 0.85162315928936, "critic_loss": 0.7714941623806953, "actor_loss": -84.06499214172364, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.815823078155518, "step": 110000}
{"episode_reward": 868.701974535497, "episode": 111.0, "batch_reward": 0.8516132838129997, "critic_loss": 0.7822737400531768, "actor_loss": -84.41801496887207, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.364092111587524, "step": 111000}
{"episode_reward": 878.0489737529456, "episode": 112.0, "batch_reward": 0.8526578181982041, "critic_loss": 0.7906354178190231, "actor_loss": -84.48173315429688, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.812377452850342, "step": 112000}
{"episode_reward": 904.6410717135508, "episode": 113.0, "batch_reward": 0.8548711371421814, "critic_loss": 0.7493596309125423, "actor_loss": -84.6916336517334, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.092777967453003, "step": 113000}
{"episode_reward": 931.8355975159359, "episode": 114.0, "batch_reward": 0.8538105170726776, "critic_loss": 0.7825982034504414, "actor_loss": -84.43219406127929, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.403611183166504, "step": 114000}
{"episode_reward": 954.3118384967066, "episode": 115.0, "batch_reward": 0.8553883462548256, "critic_loss": 0.7492465679049491, "actor_loss": -84.22259358215332, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.46740746498108, "step": 115000}
{"episode_reward": 927.9738770602052, "episode": 116.0, "batch_reward": 0.8556320064663887, "critic_loss": 0.8107003751695157, "actor_loss": -84.36941069030762, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.51605463027954, "step": 116000}
{"episode_reward": 934.4198678840736, "episode": 117.0, "batch_reward": 0.8563209382295609, "critic_loss": 0.7877803483605385, "actor_loss": -84.53960089111328, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.372695446014404, "step": 117000}
{"episode_reward": 879.409556133344, "episode": 118.0, "batch_reward": 0.8571204583644867, "critic_loss": 0.7589398104548454, "actor_loss": -84.72554267883301, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.161351680755615, "step": 118000}
{"episode_reward": 950.1039137981841, "episode": 119.0, "batch_reward": 0.8579234832525253, "critic_loss": 0.7739357092082501, "actor_loss": -84.74744743347168, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.861080408096313, "step": 119000}
{"episode_reward": 932.2183402179141, "episode": 120.0, "batch_reward": 0.8575690445303917, "critic_loss": 0.7921327507793904, "actor_loss": -84.496515914917, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.80480432510376, "step": 120000}
{"episode_reward": 948.5402779774367, "episode": 121.0, "batch_reward": 0.8585080019235611, "critic_loss": 0.7812083082795143, "actor_loss": -84.71240588378906, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.96212840080261, "step": 121000}
{"episode_reward": 918.5542192120903, "episode": 122.0, "batch_reward": 0.8612203791737556, "critic_loss": 0.7906215854883194, "actor_loss": -84.31897734069824, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.682932376861572, "step": 122000}
{"episode_reward": 903.6234207826963, "episode": 123.0, "batch_reward": 0.8599294993877411, "critic_loss": 0.8550041555166245, "actor_loss": -84.24145933532715, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.58837103843689, "step": 123000}
{"episode_reward": 912.6151081308251, "episode": 124.0, "batch_reward": 0.8598612189888954, "critic_loss": 0.8099895737469196, "actor_loss": -84.40380532836915, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.7622492313385, "step": 124000}
{"episode_reward": 946.9465648394278, "episode": 125.0, "batch_reward": 0.8608622310757637, "critic_loss": 0.7611590943038463, "actor_loss": -84.6030492401123, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.621745347976685, "step": 125000}
{"episode_reward": 909.8373658296802, "episode": 126.0, "batch_reward": 0.860362111389637, "critic_loss": 0.7410089218318462, "actor_loss": -84.62736033630371, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.81842803955078, "step": 126000}
{"episode_reward": 931.6608752561483, "episode": 127.0, "batch_reward": 0.8619425582885742, "critic_loss": 0.8074352645874023, "actor_loss": -84.5604497680664, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.782827615737915, "step": 127000}
{"episode_reward": 948.7342568546226, "episode": 128.0, "batch_reward": 0.8616494426131248, "critic_loss": 0.7824064431786537, "actor_loss": -84.79094654846192, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.700907945632935, "step": 128000}
{"episode_reward": 954.676395381863, "episode": 129.0, "batch_reward": 0.862723680973053, "critic_loss": 0.7683283677101135, "actor_loss": -84.81856799316407, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.381290674209595, "step": 129000}
{"episode_reward": 938.4134726126191, "episode": 130.0, "batch_reward": 0.8637637953758239, "critic_loss": 0.7953303548693657, "actor_loss": -84.66517095947266, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.691226720809937, "step": 130000}
{"episode_reward": 878.2677498289976, "episode": 131.0, "batch_reward": 0.8623275964856147, "critic_loss": 0.8455903988182545, "actor_loss": -85.07458596801757, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 40.60412096977234, "step": 131000}
{"episode_reward": 909.7653100110549, "episode": 132.0, "batch_reward": 0.8646338945031166, "critic_loss": 0.7580233346223831, "actor_loss": -84.95366358947754, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.75231623649597, "step": 132000}
{"episode_reward": 938.6395780590505, "episode": 133.0, "batch_reward": 0.8636700338721275, "critic_loss": 0.7978634485304356, "actor_loss": -84.88837963867188, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.984996795654297, "step": 133000}
{"episode_reward": 913.9686099358097, "episode": 134.0, "batch_reward": 0.864610156595707, "critic_loss": 0.7739082095324993, "actor_loss": -84.99044747924805, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.38385272026062, "step": 134000}
{"episode_reward": 918.510519346436, "episode": 135.0, "batch_reward": 0.8646070420742035, "critic_loss": 0.7292587877213955, "actor_loss": -84.86558993530274, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.62376117706299, "step": 135000}
{"episode_reward": 950.5381271082568, "episode": 136.0, "batch_reward": 0.8655627661943436, "critic_loss": 0.7278479036688804, "actor_loss": -84.92157800292969, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.540142059326172, "step": 136000}
{"episode_reward": 917.4457186341389, "episode": 137.0, "batch_reward": 0.8659036366343498, "critic_loss": 0.7702793622016907, "actor_loss": -84.9688367767334, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.539248943328857, "step": 137000}
{"episode_reward": 956.5803449870165, "episode": 138.0, "batch_reward": 0.8671209233403205, "critic_loss": 0.7549872826337815, "actor_loss": -85.29329437255859, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.969549417495728, "step": 138000}
{"episode_reward": 922.5799855046553, "episode": 139.0, "batch_reward": 0.8672371631264687, "critic_loss": 0.7178164188563824, "actor_loss": -85.38684063720703, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.752123832702637, "step": 139000}
{"episode_reward": 911.1896840420784, "episode": 140.0, "batch_reward": 0.8677740892767907, "critic_loss": 0.7113817251324653, "actor_loss": -85.48961396789551, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.83770513534546, "step": 140000}
{"episode_reward": 905.9652097613108, "episode": 141.0, "batch_reward": 0.8668344295024872, "critic_loss": 0.7026151650249958, "actor_loss": -85.18221673583984, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 41.18712019920349, "step": 141000}
{"episode_reward": 954.0990009587492, "episode": 142.0, "batch_reward": 0.868434817135334, "critic_loss": 0.7245291942954063, "actor_loss": -85.1614400177002, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.266831159591675, "step": 142000}
{"episode_reward": 918.8141912335749, "episode": 143.0, "batch_reward": 0.8681331629157066, "critic_loss": 0.6851475050449372, "actor_loss": -85.07025032043457, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.404136419296265, "step": 143000}
{"episode_reward": 958.4541757913584, "episode": 144.0, "batch_reward": 0.8696302411556244, "critic_loss": 0.7422812233269215, "actor_loss": -85.39591799926758, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.529993772506714, "step": 144000}
{"episode_reward": 871.5177164172609, "episode": 145.0, "batch_reward": 0.8696368762850761, "critic_loss": 0.7491655546426773, "actor_loss": -84.95421768188477, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.565401315689087, "step": 145000}
{"episode_reward": 871.2190914071878, "episode": 146.0, "batch_reward": 0.8692031942605972, "critic_loss": 0.7378687560558319, "actor_loss": -85.39088223266602, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.413864612579346, "step": 146000}
{"episode_reward": 954.3710891869633, "episode": 147.0, "batch_reward": 0.8715441780686378, "critic_loss": 0.714772046148777, "actor_loss": -85.32835638427734, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.803295612335205, "step": 147000}
{"episode_reward": 911.3338915188565, "episode": 148.0, "batch_reward": 0.8702492017149925, "critic_loss": 0.7419077023863793, "actor_loss": -85.40898233032226, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 21.46405553817749, "step": 148000}
{"episode_reward": 925.9390589077602, "episode": 149.0, "batch_reward": 0.8706404180526733, "critic_loss": 0.7829373717308045, "actor_loss": -85.62359169006348, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "duration": 20.746136903762817, "step": 149000}
{"episode_reward": 954.9826426745552, "episode": 150.0, "batch_reward": 0.8712976081967354, "critic_loss": 0.7222377845346928, "actor_loss": -85.49959649658203, "actor_target_entropy": -6.0, "alpha_value": 0.0043656290730604555, "step": 150000}
