{"episode_reward": 0.0, "episode": 1.0, "duration": 20.466230154037476, "step": 1000}
{"episode_reward": 58.61337562337205, "episode": 2.0, "duration": 1.7856972217559814, "step": 2000}
{"episode_reward": 973.7241921866618, "episode": 3.0, "batch_reward": 0.5208930069404906, "critic_loss": 0.6201753330632185, "actor_loss": -89.71201049084185, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.10926866531372, "step": 3000}
{"episode_reward": 753.0038996566974, "episode": 4.0, "batch_reward": 0.6375998996794224, "critic_loss": 0.9067676680684089, "actor_loss": -95.18930563354492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.260202169418335, "step": 4000}
{"episode_reward": 946.7124921067148, "episode": 5.0, "batch_reward": 0.6161247012913227, "critic_loss": 1.3612878703773021, "actor_loss": -96.89597250366211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.948567152023315, "step": 5000}
{"episode_reward": 161.04554244845627, "episode": 6.0, "batch_reward": 0.5332924489080906, "critic_loss": 1.4661648344397544, "actor_loss": -97.22790069580078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.912811279296875, "step": 6000}
{"episode_reward": 36.72927203391546, "episode": 7.0, "batch_reward": 0.45292744398117063, "critic_loss": 1.2810823548436165, "actor_loss": -97.70808016967773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.920003652572632, "step": 7000}
{"episode_reward": 30.2160329908925, "episode": 8.0, "batch_reward": 0.3984700582921505, "critic_loss": 0.8175371695160866, "actor_loss": -95.79776084899902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.928712129592896, "step": 8000}
{"episode_reward": 91.18284376617028, "episode": 9.0, "batch_reward": 0.4154830503463745, "critic_loss": 0.5968998422026635, "actor_loss": -95.62383966064453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92758345603943, "step": 9000}
{"episode_reward": 970.5806329469008, "episode": 10.0, "batch_reward": 0.47366300415992735, "critic_loss": 0.5086386812627316, "actor_loss": -95.0627487487793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.924081087112427, "step": 10000}
{"episode_reward": 984.0505877971498, "episode": 11.0, "batch_reward": 0.512421422213316, "critic_loss": 0.6578543955385685, "actor_loss": -94.93586294555664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.15821027755737, "step": 11000}
{"episode_reward": 893.4811124002144, "episode": 12.0, "batch_reward": 0.5568852328360081, "critic_loss": 0.599299237638712, "actor_loss": -94.57788829040527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.917707204818726, "step": 12000}
{"episode_reward": 969.6347875126353, "episode": 13.0, "batch_reward": 0.5859275831580162, "critic_loss": 0.8561224111616611, "actor_loss": -94.68487210083008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23077368736267, "step": 13000}
{"episode_reward": 951.8530745911218, "episode": 14.0, "batch_reward": 0.6157748084664345, "critic_loss": 1.2698013747930528, "actor_loss": -94.71630061340332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.890703916549683, "step": 14000}
{"episode_reward": 982.6527650327911, "episode": 15.0, "batch_reward": 0.6395756792426109, "critic_loss": 1.6132303076386452, "actor_loss": -95.67142330932617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.883566856384277, "step": 15000}
{"episode_reward": 957.1280809070747, "episode": 16.0, "batch_reward": 0.6530785007476807, "critic_loss": 2.466354119181633, "actor_loss": -96.54945640563965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.891452312469482, "step": 16000}
{"episode_reward": 762.435424635953, "episode": 17.0, "batch_reward": 0.6598552591204643, "critic_loss": 2.697411078214645, "actor_loss": -97.42383567810059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.917096376419067, "step": 17000}
{"episode_reward": 633.0461377717795, "episode": 18.0, "batch_reward": 0.6611044101715088, "critic_loss": 2.828345475554466, "actor_loss": -97.58521221923829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.216363191604614, "step": 18000}
{"episode_reward": 734.2161730998703, "episode": 19.0, "batch_reward": 0.659770361661911, "critic_loss": 2.647615038752556, "actor_loss": -97.97765496826172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.972707748413086, "step": 19000}
{"episode_reward": 767.1136541402662, "episode": 20.0, "batch_reward": 0.6609937363266944, "critic_loss": 2.4230656098127366, "actor_loss": -97.72359791564942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.915364503860474, "step": 20000}
{"episode_reward": 470.11721113438483, "episode": 21.0, "batch_reward": 0.6590734045505524, "critic_loss": 2.2616437220573427, "actor_loss": -97.75445405578613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.18905758857727, "step": 21000}
{"episode_reward": 861.9407667788381, "episode": 22.0, "batch_reward": 0.6726370533108711, "critic_loss": 2.0275737047195435, "actor_loss": -98.03371208190919, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92635679244995, "step": 22000}
{"episode_reward": 943.7932739912297, "episode": 23.0, "batch_reward": 0.6821240634918213, "critic_loss": 1.831825785279274, "actor_loss": -98.56362666320801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.956172227859497, "step": 23000}
{"episode_reward": 874.3437346950486, "episode": 24.0, "batch_reward": 0.6873812429904937, "critic_loss": 1.6605545397400856, "actor_loss": -99.30991004943847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95059108734131, "step": 24000}
{"episode_reward": 788.0151640193372, "episode": 25.0, "batch_reward": 0.6945522310733795, "critic_loss": 1.4966494305729865, "actor_loss": -99.0588975830078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.931305646896362, "step": 25000}
{"episode_reward": 901.0201704757968, "episode": 26.0, "batch_reward": 0.7000267856121063, "critic_loss": 1.461546746790409, "actor_loss": -100.04993298339843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92837142944336, "step": 26000}
{"episode_reward": 832.4755883972912, "episode": 27.0, "batch_reward": 0.7067479275465012, "critic_loss": 1.4458769826889037, "actor_loss": -100.64103575134277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.922340154647827, "step": 27000}
{"episode_reward": 924.2033530216222, "episode": 28.0, "batch_reward": 0.7160414752364158, "critic_loss": 1.3335127027034759, "actor_loss": -100.41646885681152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.922088146209717, "step": 28000}
{"episode_reward": 968.2355315668417, "episode": 29.0, "batch_reward": 0.7235705775618553, "critic_loss": 1.2517998635172845, "actor_loss": -100.90910667419433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.925089120864868, "step": 29000}
{"episode_reward": 829.5129963582301, "episode": 30.0, "batch_reward": 0.7275022248625755, "critic_loss": 1.0755487666130066, "actor_loss": -100.81282565307617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.926828861236572, "step": 30000}
{"episode_reward": 923.8532491104797, "episode": 31.0, "batch_reward": 0.7360097073316574, "critic_loss": 0.8957490218877793, "actor_loss": -99.84077346801757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.14920377731323, "step": 31000}
{"episode_reward": 975.5090626724864, "episode": 32.0, "batch_reward": 0.7406696179509162, "critic_loss": 0.8571844259798527, "actor_loss": -100.2485922241211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.936286211013794, "step": 32000}
{"episode_reward": 914.912956106271, "episode": 33.0, "batch_reward": 0.7475384285449982, "critic_loss": 0.7804910999536514, "actor_loss": -100.01202360534668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.932708740234375, "step": 33000}
{"episode_reward": 968.4746903789618, "episode": 34.0, "batch_reward": 0.7571228060126305, "critic_loss": 0.741698436498642, "actor_loss": -99.6997088470459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.925261974334717, "step": 34000}
{"episode_reward": 977.4938155016089, "episode": 35.0, "batch_reward": 0.7585960865616799, "critic_loss": 0.785554861009121, "actor_loss": -99.75073582458496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.922632932662964, "step": 35000}
{"episode_reward": 815.3322717292206, "episode": 36.0, "batch_reward": 0.7622239896655083, "critic_loss": 0.7218451234996319, "actor_loss": -99.19230317687989, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.919679880142212, "step": 36000}
{"episode_reward": 892.1005539166773, "episode": 37.0, "batch_reward": 0.7659398377537727, "critic_loss": 0.7291982156932354, "actor_loss": -99.36218528747558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.928777933120728, "step": 37000}
{"episode_reward": 930.9899958232196, "episode": 38.0, "batch_reward": 0.7697559131383895, "critic_loss": 0.6556113405227662, "actor_loss": -99.17711422729492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.926812410354614, "step": 38000}
{"episode_reward": 960.1319793618865, "episode": 39.0, "batch_reward": 0.7777473014593125, "critic_loss": 0.6090940638184548, "actor_loss": -98.96284324645995, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.935691356658936, "step": 39000}
{"episode_reward": 987.8116035378594, "episode": 40.0, "batch_reward": 0.7776750913262367, "critic_loss": 0.981034024387598, "actor_loss": -98.21247840881348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.937270402908325, "step": 40000}
{"episode_reward": 871.4505281668546, "episode": 41.0, "batch_reward": 0.7815687838792801, "critic_loss": 0.6670444330275058, "actor_loss": -98.3706116027832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.20885491371155, "step": 41000}
{"episode_reward": 866.63516355181, "episode": 42.0, "batch_reward": 0.7863873462080956, "critic_loss": 0.6156591635346412, "actor_loss": -98.14350323486327, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.946353673934937, "step": 42000}
{"episode_reward": 973.2179830365383, "episode": 43.0, "batch_reward": 0.7887628924250603, "critic_loss": 0.6776163044571877, "actor_loss": -97.89089286804199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94281315803528, "step": 43000}
{"episode_reward": 898.2351704623743, "episode": 44.0, "batch_reward": 0.7927684457302093, "critic_loss": 0.6253624204099179, "actor_loss": -97.99394871520997, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94147276878357, "step": 44000}
{"episode_reward": 976.3286852771483, "episode": 45.0, "batch_reward": 0.794247429728508, "critic_loss": 0.5853938546776771, "actor_loss": -98.13344104003906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.941265106201172, "step": 45000}
{"episode_reward": 928.5390329445996, "episode": 46.0, "batch_reward": 0.8000864759683609, "critic_loss": 0.5704540678113699, "actor_loss": -98.18122648620606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90856432914734, "step": 46000}
{"episode_reward": 984.7430734918513, "episode": 47.0, "batch_reward": 0.8030853909850121, "critic_loss": 0.5160822739303113, "actor_loss": -97.54936112976074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.922083854675293, "step": 47000}
{"episode_reward": 960.3960648366423, "episode": 48.0, "batch_reward": 0.8071087654829026, "critic_loss": 0.522240949138999, "actor_loss": -97.62980610656739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93396282196045, "step": 48000}
{"episode_reward": 982.2414966060817, "episode": 49.0, "batch_reward": 0.8111265425086022, "critic_loss": 0.473809818059206, "actor_loss": -97.4174144744873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.919728755950928, "step": 49000}
{"episode_reward": 947.0895038241154, "episode": 50.0, "batch_reward": 0.8128781036734581, "critic_loss": 0.4701668722629547, "actor_loss": -97.32944972229004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92347502708435, "step": 50000}
{"episode_reward": 957.8044799973709, "episode": 51.0, "batch_reward": 0.8148265237212181, "critic_loss": 0.4771861547380686, "actor_loss": -97.18392483520508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.19175124168396, "step": 51000}
{"episode_reward": 951.3851168790734, "episode": 52.0, "batch_reward": 0.8195690059065819, "critic_loss": 0.4249539272338152, "actor_loss": -97.1921979675293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.937586784362793, "step": 52000}
{"episode_reward": 971.8902920919368, "episode": 53.0, "batch_reward": 0.8213456871509552, "critic_loss": 0.467881841853261, "actor_loss": -96.82621163940429, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93004846572876, "step": 53000}
{"episode_reward": 917.8961311698929, "episode": 54.0, "batch_reward": 0.8236336739063262, "critic_loss": 0.4298334648609161, "actor_loss": -96.82256211853027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.925989389419556, "step": 54000}
{"episode_reward": 981.219910585699, "episode": 55.0, "batch_reward": 0.8263112146854401, "critic_loss": 0.4151547974795103, "actor_loss": -96.79354124450684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92858123779297, "step": 55000}
{"episode_reward": 971.0899351507007, "episode": 56.0, "batch_reward": 0.8281822000741959, "critic_loss": 0.49908434675633906, "actor_loss": -96.57723352050782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.933648109436035, "step": 56000}
{"episode_reward": 957.0306512317068, "episode": 57.0, "batch_reward": 0.8294778782725334, "critic_loss": 0.39636149299144746, "actor_loss": -96.53374389648438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.944722890853882, "step": 57000}
{"episode_reward": 938.7716592711844, "episode": 58.0, "batch_reward": 0.8339480963349343, "critic_loss": 0.38596084286272525, "actor_loss": -96.42057527160645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95127534866333, "step": 58000}
{"episode_reward": 971.0798750740445, "episode": 59.0, "batch_reward": 0.8345448358654975, "critic_loss": 0.37342164616286755, "actor_loss": -96.33086782836914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.941968202590942, "step": 59000}
{"episode_reward": 897.3560709733562, "episode": 60.0, "batch_reward": 0.8377113779187202, "critic_loss": 0.37423711678385735, "actor_loss": -96.41793899536133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93429684638977, "step": 60000}
{"episode_reward": 986.4172727194807, "episode": 61.0, "batch_reward": 0.8363352481722832, "critic_loss": 0.41497765374183654, "actor_loss": -96.23568913269042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.1679208278656, "step": 61000}
{"episode_reward": 862.6318806635853, "episode": 62.0, "batch_reward": 0.8394444630146026, "critic_loss": 0.45126203043758867, "actor_loss": -96.37026809692382, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.929651498794556, "step": 62000}
{"episode_reward": 952.7676482755684, "episode": 63.0, "batch_reward": 0.8413156924247742, "critic_loss": 0.42414131519198417, "actor_loss": -96.17967375183106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92442488670349, "step": 63000}
{"episode_reward": 937.2999251394406, "episode": 64.0, "batch_reward": 0.8439356389045716, "critic_loss": 0.41070938128232953, "actor_loss": -95.93462506103516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.932682275772095, "step": 64000}
{"episode_reward": 980.5242725115997, "episode": 65.0, "batch_reward": 0.8428338376283646, "critic_loss": 0.42599745747447015, "actor_loss": -95.89190725708008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.934385776519775, "step": 65000}
{"episode_reward": 950.9467553403426, "episode": 66.0, "batch_reward": 0.8461007338762283, "critic_loss": 0.4231461249291897, "actor_loss": -95.91602568054199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92630434036255, "step": 66000}
{"episode_reward": 979.7669471598165, "episode": 67.0, "batch_reward": 0.8490362437367439, "critic_loss": 0.390337293818593, "actor_loss": -95.90979981994629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.925288200378418, "step": 67000}
{"episode_reward": 961.7879550288314, "episode": 68.0, "batch_reward": 0.8504871730804443, "critic_loss": 0.44374771463871004, "actor_loss": -95.75045985412598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.930695295333862, "step": 68000}
{"episode_reward": 987.4623233281746, "episode": 69.0, "batch_reward": 0.8537876086235047, "critic_loss": 0.4013451356291771, "actor_loss": -95.84873042297363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93071961402893, "step": 69000}
{"episode_reward": 979.8059719617969, "episode": 70.0, "batch_reward": 0.8538089300990105, "critic_loss": 0.44941626623272896, "actor_loss": -95.85761949157715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92862892150879, "step": 70000}
{"episode_reward": 976.9349329780763, "episode": 71.0, "batch_reward": 0.8561184492111206, "critic_loss": 0.4866022665351629, "actor_loss": -95.82320640563965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.197208642959595, "step": 71000}
{"episode_reward": 926.4286181162726, "episode": 72.0, "batch_reward": 0.8555053677558899, "critic_loss": 0.4366563946455717, "actor_loss": -95.70015521240235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.937858819961548, "step": 72000}
{"episode_reward": 951.4634849419035, "episode": 73.0, "batch_reward": 0.8581414902210236, "critic_loss": 0.4066330148279667, "actor_loss": -95.67536123657227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.930739164352417, "step": 73000}
{"episode_reward": 892.832548479582, "episode": 74.0, "batch_reward": 0.8590368995666504, "critic_loss": 0.38862516874074937, "actor_loss": -95.65253732299804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.943315982818604, "step": 74000}
{"episode_reward": 978.9213553548489, "episode": 75.0, "batch_reward": 0.8603975736498832, "critic_loss": 0.3660957808047533, "actor_loss": -95.51286868286132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.933242559432983, "step": 75000}
{"episode_reward": 955.6219990596265, "episode": 76.0, "batch_reward": 0.8617408756613731, "critic_loss": 0.3552696936130524, "actor_loss": -95.46912713623047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92409038543701, "step": 76000}
{"episode_reward": 960.3948688503408, "episode": 77.0, "batch_reward": 0.862236836194992, "critic_loss": 0.3606202410757542, "actor_loss": -95.41502363586426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.937262535095215, "step": 77000}
{"episode_reward": 965.9861529575795, "episode": 78.0, "batch_reward": 0.865050604224205, "critic_loss": 0.3435015501230955, "actor_loss": -95.52744786071777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.931227684020996, "step": 78000}
{"episode_reward": 989.3870629771108, "episode": 79.0, "batch_reward": 0.867396743118763, "critic_loss": 0.34844703710079195, "actor_loss": -95.50179490661621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93340826034546, "step": 79000}
{"episode_reward": 987.9702972435472, "episode": 80.0, "batch_reward": 0.8673173726797104, "critic_loss": 0.33762203429639337, "actor_loss": -95.45805261230468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.934032440185547, "step": 80000}
{"episode_reward": 978.297575287267, "episode": 81.0, "batch_reward": 0.86846949416399, "critic_loss": 0.34617507191002367, "actor_loss": -95.44032565307617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.181002378463745, "step": 81000}
{"episode_reward": 979.6728262572676, "episode": 82.0, "batch_reward": 0.8696013793945313, "critic_loss": 0.34926624221354724, "actor_loss": -95.41684390258789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92896032333374, "step": 82000}
{"episode_reward": 936.0940625187012, "episode": 83.0, "batch_reward": 0.8719071925878524, "critic_loss": 0.3370691736936569, "actor_loss": -95.4633143005371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93366575241089, "step": 83000}
{"episode_reward": 978.1811511497019, "episode": 84.0, "batch_reward": 0.8717611088752747, "critic_loss": 0.3619713945686817, "actor_loss": -95.45260144042969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93948006629944, "step": 84000}
{"episode_reward": 990.8840498243507, "episode": 85.0, "batch_reward": 0.8732300381660462, "critic_loss": 0.33308657640218736, "actor_loss": -95.47236036682129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.942716121673584, "step": 85000}
{"episode_reward": 957.6714970025109, "episode": 86.0, "batch_reward": 0.8742512726187706, "critic_loss": 0.34422831447422503, "actor_loss": -95.49316415405274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93180775642395, "step": 86000}
{"episode_reward": 954.6133174546414, "episode": 87.0, "batch_reward": 0.8747751203775406, "critic_loss": 0.34374998044222593, "actor_loss": -95.44264768981934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.935036420822144, "step": 87000}
{"episode_reward": 941.9863471634418, "episode": 88.0, "batch_reward": 0.8767404208183288, "critic_loss": 0.3278005214780569, "actor_loss": -95.51604597473144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.936161041259766, "step": 88000}
{"episode_reward": 987.6799082484462, "episode": 89.0, "batch_reward": 0.877962455689907, "critic_loss": 0.32785115233808754, "actor_loss": -95.53350845336914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.925901174545288, "step": 89000}
{"episode_reward": 917.4665547978099, "episode": 90.0, "batch_reward": 0.8766683603525162, "critic_loss": 0.3513548072502017, "actor_loss": -95.47506114196777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9263174533844, "step": 90000}
{"episode_reward": 888.7495564421373, "episode": 91.0, "batch_reward": 0.8763342270255089, "critic_loss": 0.3506082450449467, "actor_loss": -95.41855184936523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.17096209526062, "step": 91000}
{"episode_reward": 960.1216073506441, "episode": 92.0, "batch_reward": 0.8775442633032798, "critic_loss": 0.33403723510354755, "actor_loss": -95.47124243164062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92729902267456, "step": 92000}
{"episode_reward": 989.2399193731528, "episode": 93.0, "batch_reward": 0.8792470896244049, "critic_loss": 0.34836973407119515, "actor_loss": -95.40873796081543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.929301977157593, "step": 93000}
{"episode_reward": 914.9482820551852, "episode": 94.0, "batch_reward": 0.881090226829052, "critic_loss": 0.3474129670038819, "actor_loss": -95.45766320800782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.929148197174072, "step": 94000}
{"episode_reward": 967.1022724283597, "episode": 95.0, "batch_reward": 0.8794727720022202, "critic_loss": 0.33966211119294165, "actor_loss": -95.36014445495606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92677116394043, "step": 95000}
{"episode_reward": 936.6506270878147, "episode": 96.0, "batch_reward": 0.8824719121456146, "critic_loss": 0.3388339701294899, "actor_loss": -95.41682342529298, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.922276735305786, "step": 96000}
{"episode_reward": 985.899981900837, "episode": 97.0, "batch_reward": 0.8825195018649101, "critic_loss": 0.3275999162942171, "actor_loss": -95.41365907287597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94731330871582, "step": 97000}
{"episode_reward": 985.3814335476114, "episode": 98.0, "batch_reward": 0.8851261810660362, "critic_loss": 0.321526070125401, "actor_loss": -95.40931602478027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.945874452590942, "step": 98000}
{"episode_reward": 981.4152110735538, "episode": 99.0, "batch_reward": 0.884976524233818, "critic_loss": 0.3039647944867611, "actor_loss": -95.48042533874512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.950549602508545, "step": 99000}
{"episode_reward": 985.2738085737421, "episode": 100.0, "batch_reward": 0.8858953772783279, "critic_loss": 0.31241020767390726, "actor_loss": -95.48558854675294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91901421546936, "step": 100000}
{"episode_reward": 962.6493451855489, "episode": 101.0, "batch_reward": 0.8866787581443787, "critic_loss": 0.3222545648217201, "actor_loss": -95.53315127563476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.17863845825195, "step": 101000}
{"episode_reward": 945.8673124063117, "episode": 102.0, "batch_reward": 0.8875382875800133, "critic_loss": 0.3274401821270585, "actor_loss": -95.49155274963378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92969536781311, "step": 102000}
{"episode_reward": 962.4283658056578, "episode": 103.0, "batch_reward": 0.8880000424981117, "critic_loss": 0.3166884053051472, "actor_loss": -95.55164707946777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.927047967910767, "step": 103000}
{"episode_reward": 988.9621703782345, "episode": 104.0, "batch_reward": 0.8891504026651382, "critic_loss": 0.30245878543704746, "actor_loss": -95.5373809967041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91403365135193, "step": 104000}
{"episode_reward": 960.9936462639895, "episode": 105.0, "batch_reward": 0.890312978386879, "critic_loss": 0.28649874150007965, "actor_loss": -95.56931523132324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92483139038086, "step": 105000}
{"episode_reward": 985.9558782772388, "episode": 106.0, "batch_reward": 0.8907130181193351, "critic_loss": 0.3056139177083969, "actor_loss": -95.5714796447754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.923612594604492, "step": 106000}
{"episode_reward": 986.7484750932919, "episode": 107.0, "batch_reward": 0.8913482953310012, "critic_loss": 0.3091924405172467, "actor_loss": -95.58200425720214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.929872035980225, "step": 107000}
{"episode_reward": 961.6271086492424, "episode": 108.0, "batch_reward": 0.8922865716814995, "critic_loss": 0.28504622090607884, "actor_loss": -95.61219923400878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.927340507507324, "step": 108000}
{"episode_reward": 989.4291933663569, "episode": 109.0, "batch_reward": 0.8927186836004257, "critic_loss": 0.30075250183045865, "actor_loss": -95.56726124572754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92923855781555, "step": 109000}
{"episode_reward": 990.9595249545008, "episode": 110.0, "batch_reward": 0.8949120092988014, "critic_loss": 0.29107306353747847, "actor_loss": -95.6478136138916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92354154586792, "step": 110000}
{"episode_reward": 961.9577221002534, "episode": 111.0, "batch_reward": 0.8959984375834465, "critic_loss": 0.27962961602211, "actor_loss": -95.71908824157715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.22845816612244, "step": 111000}
{"episode_reward": 970.3264549402379, "episode": 112.0, "batch_reward": 0.8939454209208488, "critic_loss": 0.29008433523029087, "actor_loss": -95.6669974822998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92330527305603, "step": 112000}
{"episode_reward": 829.0963301616537, "episode": 113.0, "batch_reward": 0.89532071352005, "critic_loss": 0.2793756976649165, "actor_loss": -95.70156164550781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92681097984314, "step": 113000}
{"episode_reward": 963.643531451052, "episode": 114.0, "batch_reward": 0.8959789717197418, "critic_loss": 0.29017225133627655, "actor_loss": -95.69703778076172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92560315132141, "step": 114000}
{"episode_reward": 982.949632049372, "episode": 115.0, "batch_reward": 0.8955181190371513, "critic_loss": 0.29700932247936723, "actor_loss": -95.63520060729981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93018865585327, "step": 115000}
{"episode_reward": 987.3680583727329, "episode": 116.0, "batch_reward": 0.897025236427784, "critic_loss": 0.29292638072371485, "actor_loss": -95.67195402526855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.929338216781616, "step": 116000}
{"episode_reward": 951.618908778853, "episode": 117.0, "batch_reward": 0.8972865642905236, "critic_loss": 0.29698409938812254, "actor_loss": -95.70096031188965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.926164627075195, "step": 117000}
{"episode_reward": 967.8362436806493, "episode": 118.0, "batch_reward": 0.8977860661745072, "critic_loss": 0.2881106375083327, "actor_loss": -95.71681135559082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92194962501526, "step": 118000}
{"episode_reward": 988.4650128650256, "episode": 119.0, "batch_reward": 0.8988248009085655, "critic_loss": 0.2869296362027526, "actor_loss": -95.7451614074707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.921225786209106, "step": 119000}
{"episode_reward": 982.9368845243093, "episode": 120.0, "batch_reward": 0.8992913540005684, "critic_loss": 0.28359634687006474, "actor_loss": -95.74623678588867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.937469959259033, "step": 120000}
{"episode_reward": 978.7067703376105, "episode": 121.0, "batch_reward": 0.899787658572197, "critic_loss": 0.29431433279067276, "actor_loss": -95.7393717803955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.19713568687439, "step": 121000}
{"episode_reward": 980.3631867366819, "episode": 122.0, "batch_reward": 0.9012306491732598, "critic_loss": 0.2796806999221444, "actor_loss": -95.74200920104981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.955364227294922, "step": 122000}
{"episode_reward": 934.4403062973203, "episode": 123.0, "batch_reward": 0.9001837856769562, "critic_loss": 0.2959175429716706, "actor_loss": -95.65619337463379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94132161140442, "step": 123000}
{"episode_reward": 954.1305991246265, "episode": 124.0, "batch_reward": 0.9016942858099938, "critic_loss": 0.2852544367611408, "actor_loss": -95.66524647521973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.960528135299683, "step": 124000}
{"episode_reward": 983.9911404959828, "episode": 125.0, "batch_reward": 0.9021937113404274, "critic_loss": 0.2930007606744766, "actor_loss": -95.73300085449219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.944586753845215, "step": 125000}
{"episode_reward": 959.6686867005158, "episode": 126.0, "batch_reward": 0.901597629904747, "critic_loss": 0.29422857919335366, "actor_loss": -95.71602819824218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.955265998840332, "step": 126000}
{"episode_reward": 959.6832285268035, "episode": 127.0, "batch_reward": 0.9029283351302146, "critic_loss": 0.2760247318148613, "actor_loss": -95.71399891662598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94586682319641, "step": 127000}
{"episode_reward": 987.2928407104589, "episode": 128.0, "batch_reward": 0.9040003678798676, "critic_loss": 0.29112092275172474, "actor_loss": -95.76557582092285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.932650089263916, "step": 128000}
{"episode_reward": 989.6646831117663, "episode": 129.0, "batch_reward": 0.9046080154776573, "critic_loss": 0.26471070148795844, "actor_loss": -95.72466557312012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9317729473114, "step": 129000}
{"episode_reward": 959.056472252711, "episode": 130.0, "batch_reward": 0.9039892891645431, "critic_loss": 0.2861139423772693, "actor_loss": -95.70035008239746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.933363437652588, "step": 130000}
{"episode_reward": 925.7433014357376, "episode": 131.0, "batch_reward": 0.9054710021018982, "critic_loss": 0.30884039521962403, "actor_loss": -95.7042932434082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.1637761592865, "step": 131000}
{"episode_reward": 957.6795026186272, "episode": 132.0, "batch_reward": 0.9045349947214126, "critic_loss": 0.28568203274160625, "actor_loss": -95.73334167480469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.924560070037842, "step": 132000}
{"episode_reward": 919.8199336798361, "episode": 133.0, "batch_reward": 0.9045116884708404, "critic_loss": 0.2642064732685685, "actor_loss": -95.73777308654785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.921884298324585, "step": 133000}
{"episode_reward": 963.5080083118934, "episode": 134.0, "batch_reward": 0.9052688779234886, "critic_loss": 0.27395501125603916, "actor_loss": -95.75940438842774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.924545288085938, "step": 134000}
{"episode_reward": 941.403946711756, "episode": 135.0, "batch_reward": 0.906026831805706, "critic_loss": 0.28774535164237025, "actor_loss": -95.80392233276368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.930812120437622, "step": 135000}
{"episode_reward": 979.7830965822103, "episode": 136.0, "batch_reward": 0.9056489624977112, "critic_loss": 0.27235335773974656, "actor_loss": -95.73241525268554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.947376489639282, "step": 136000}
{"episode_reward": 919.5759602298504, "episode": 137.0, "batch_reward": 0.9068038427829742, "critic_loss": 0.28132076214253904, "actor_loss": -95.79057301330566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.957932233810425, "step": 137000}
{"episode_reward": 988.4798230001522, "episode": 138.0, "batch_reward": 0.9073156043887138, "critic_loss": 0.30033894007653, "actor_loss": -95.78735453796386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95225715637207, "step": 138000}
{"episode_reward": 967.5340991510437, "episode": 139.0, "batch_reward": 0.907568343281746, "critic_loss": 0.27243867647647857, "actor_loss": -95.81353945922852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.942344665527344, "step": 139000}
{"episode_reward": 940.3843447874723, "episode": 140.0, "batch_reward": 0.907986538529396, "critic_loss": 0.28356540844589473, "actor_loss": -95.79517378234863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.929076194763184, "step": 140000}
{"episode_reward": 951.1062727885258, "episode": 141.0, "batch_reward": 0.908208467245102, "critic_loss": 0.2673695369958878, "actor_loss": -95.86939720153809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.18127155303955, "step": 141000}
{"episode_reward": 987.4964155379705, "episode": 142.0, "batch_reward": 0.9080067752599716, "critic_loss": 0.2873764428421855, "actor_loss": -95.85089410400391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.926796674728394, "step": 142000}
{"episode_reward": 952.5997491804786, "episode": 143.0, "batch_reward": 0.9086228945255279, "critic_loss": 0.2761638918183744, "actor_loss": -95.88041473388672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.935415029525757, "step": 143000}
{"episode_reward": 983.1591763611368, "episode": 144.0, "batch_reward": 0.9099231473803521, "critic_loss": 0.267387972291559, "actor_loss": -95.92272341918945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.935976266860962, "step": 144000}
{"episode_reward": 953.4194373854208, "episode": 145.0, "batch_reward": 0.9101702089309692, "critic_loss": 0.294318684771657, "actor_loss": -95.87610639953613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.937578201293945, "step": 145000}
{"episode_reward": 980.2825622891082, "episode": 146.0, "batch_reward": 0.9104557771086693, "critic_loss": 0.2803210019916296, "actor_loss": -95.90182202148438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94205069541931, "step": 146000}
{"episode_reward": 984.9424177273966, "episode": 147.0, "batch_reward": 0.9112101511359215, "critic_loss": 0.26283015267550947, "actor_loss": -95.93761473083497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92642641067505, "step": 147000}
{"episode_reward": 960.8371363519656, "episode": 148.0, "batch_reward": 0.9109771326184273, "critic_loss": 0.2653045581355691, "actor_loss": -95.94589617919922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95103406906128, "step": 148000}
{"episode_reward": 960.7609793390126, "episode": 149.0, "batch_reward": 0.9114699783921242, "critic_loss": 0.2596724503412843, "actor_loss": -95.97884080505371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9476318359375, "step": 149000}
{"episode_reward": 985.1363551382356, "episode": 150.0, "batch_reward": 0.9134594131112098, "critic_loss": 0.25540197573602197, "actor_loss": -96.0326150970459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
