{"episode_reward": 0.0, "episode": 1.0, "duration": 22.05561876296997, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.9442226886749268, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.4302151171653896, "critic_loss": 0.6339434104517883, "actor_loss": -78.1457844520865, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 66.40250015258789, "step": 3000}
{"episode_reward": 459.9310740247431, "episode": 4.0, "batch_reward": 0.48133640342950823, "critic_loss": 0.7508763428032398, "actor_loss": -84.70642926025391, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.3429012298584, "step": 4000}
{"episode_reward": 770.3385581453742, "episode": 5.0, "batch_reward": 0.529746953368187, "critic_loss": 0.6303953611850739, "actor_loss": -86.37363092041015, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.172239303588867, "step": 5000}
{"episode_reward": 703.3514487126033, "episode": 6.0, "batch_reward": 0.5156121746003628, "critic_loss": 0.6099184446334839, "actor_loss": -87.10009959411622, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.20784091949463, "step": 6000}
{"episode_reward": 32.57273384800774, "episode": 7.0, "batch_reward": 0.47110389223694804, "critic_loss": 0.6452686391174793, "actor_loss": -87.89769091796875, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.737014770507812, "step": 7000}
{"episode_reward": 301.1927506390556, "episode": 8.0, "batch_reward": 0.43313048976659774, "critic_loss": 0.626103516370058, "actor_loss": -87.10099192810058, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.750876426696777, "step": 8000}
{"episode_reward": 161.7473830322996, "episode": 9.0, "batch_reward": 0.43135230073332786, "critic_loss": 0.5945016099512577, "actor_loss": -86.45896444702149, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.57111406326294, "step": 9000}
{"episode_reward": 577.5539032547712, "episode": 10.0, "batch_reward": 0.4188574023246765, "critic_loss": 0.5674281198084354, "actor_loss": -85.25931903076172, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.1834135055542, "step": 10000}
{"episode_reward": 180.28817082836122, "episode": 11.0, "batch_reward": 0.4012030485570431, "critic_loss": 0.5317527234256267, "actor_loss": -84.21932444763183, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.61967182159424, "step": 11000}
{"episode_reward": 354.2059684812982, "episode": 12.0, "batch_reward": 0.41694245460629464, "critic_loss": 0.5147463983297348, "actor_loss": -83.26502784729004, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.96205472946167, "step": 12000}
{"episode_reward": 845.5728469046835, "episode": 13.0, "batch_reward": 0.4337394556105137, "critic_loss": 0.5079743487536907, "actor_loss": -83.57309677124023, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.73342537879944, "step": 13000}
{"episode_reward": 585.2336328867831, "episode": 14.0, "batch_reward": 0.4626259543299675, "critic_loss": 0.466065252840519, "actor_loss": -83.1417285308838, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.551961183547974, "step": 14000}
{"episode_reward": 871.6141331494963, "episode": 15.0, "batch_reward": 0.49009081944823263, "critic_loss": 0.472170111566782, "actor_loss": -83.34789651489258, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.48695158958435, "step": 15000}
{"episode_reward": 883.4172672661865, "episode": 16.0, "batch_reward": 0.5035216486155987, "critic_loss": 0.5126993198394776, "actor_loss": -83.71561973571778, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.777280807495117, "step": 16000}
{"episode_reward": 624.1951908329249, "episode": 17.0, "batch_reward": 0.5212786107063293, "critic_loss": 0.5145861577689648, "actor_loss": -83.9687107849121, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.555267095565796, "step": 17000}
{"episode_reward": 828.881455287042, "episode": 18.0, "batch_reward": 0.5426695299744606, "critic_loss": 0.4735835435092449, "actor_loss": -84.40785647583007, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.236325979232788, "step": 18000}
{"episode_reward": 884.2123220992255, "episode": 19.0, "batch_reward": 0.5611050154864788, "critic_loss": 0.4077685682028532, "actor_loss": -84.59295671081543, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.87814450263977, "step": 19000}
{"episode_reward": 931.0085835994463, "episode": 20.0, "batch_reward": 0.5800427171587944, "critic_loss": 0.38549902267754077, "actor_loss": -84.8817973022461, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.759605646133423, "step": 20000}
{"episode_reward": 945.8803830155254, "episode": 21.0, "batch_reward": 0.5963376976549626, "critic_loss": 0.3655001979023218, "actor_loss": -84.9995086517334, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.75413131713867, "step": 21000}
{"episode_reward": 865.1726976514242, "episode": 22.0, "batch_reward": 0.603254674077034, "critic_loss": 0.4016626445353031, "actor_loss": -84.4384969329834, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.540586709976196, "step": 22000}
{"episode_reward": 741.6884964636675, "episode": 23.0, "batch_reward": 0.6146122289299965, "critic_loss": 0.4249759484231472, "actor_loss": -84.82443266296387, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.40269923210144, "step": 23000}
{"episode_reward": 839.9530036651514, "episode": 24.0, "batch_reward": 0.6256125852763653, "critic_loss": 0.4715318767130375, "actor_loss": -85.13836329650879, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.188230514526367, "step": 24000}
{"episode_reward": 941.7326091733302, "episode": 25.0, "batch_reward": 0.6364967321455479, "critic_loss": 0.5588882828950882, "actor_loss": -86.15342288208008, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.012383222579956, "step": 25000}
{"episode_reward": 869.2254497474781, "episode": 26.0, "batch_reward": 0.6478139618635178, "critic_loss": 0.5417543282806874, "actor_loss": -87.22694206237793, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.985199213027954, "step": 26000}
{"episode_reward": 918.4906537254009, "episode": 27.0, "batch_reward": 0.6565754992365838, "critic_loss": 0.48858318662643435, "actor_loss": -87.95689462280274, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.736911058425903, "step": 27000}
{"episode_reward": 954.7031573546894, "episode": 28.0, "batch_reward": 0.669326267182827, "critic_loss": 0.47892048421502115, "actor_loss": -87.88552796936035, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.72449779510498, "step": 28000}
{"episode_reward": 919.6215023968375, "episode": 29.0, "batch_reward": 0.6632408391833305, "critic_loss": 0.4590210307240486, "actor_loss": -87.61045317077637, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.706084489822388, "step": 29000}
{"episode_reward": 305.9997507769085, "episode": 30.0, "batch_reward": 0.6655632094144821, "critic_loss": 0.4211211774200201, "actor_loss": -87.75534156799317, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.293259382247925, "step": 30000}
{"episode_reward": 872.5279768685887, "episode": 31.0, "batch_reward": 0.6577268027663231, "critic_loss": 0.3836227535456419, "actor_loss": -86.96787675476074, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.84972667694092, "step": 31000}
{"episode_reward": 37.30079692946918, "episode": 32.0, "batch_reward": 0.637338421702385, "critic_loss": 0.36642450535297394, "actor_loss": -85.98741624450683, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.811456441879272, "step": 32000}
{"episode_reward": 24.159908914063838, "episode": 33.0, "batch_reward": 0.6339081960618496, "critic_loss": 0.34143757693469523, "actor_loss": -85.48350898742676, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.989145278930664, "step": 33000}
{"episode_reward": 920.598557916151, "episode": 34.0, "batch_reward": 0.6411777896881103, "critic_loss": 0.32585764494538305, "actor_loss": -85.48478298950195, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.22014093399048, "step": 34000}
{"episode_reward": 955.4660316505629, "episode": 35.0, "batch_reward": 0.6408186232447625, "critic_loss": 0.34258247359097005, "actor_loss": -84.42303436279298, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.983872413635254, "step": 35000}
{"episode_reward": 430.0111107319113, "episode": 36.0, "batch_reward": 0.646637825012207, "critic_loss": 0.33713498754799365, "actor_loss": -84.24820252990723, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.043808221817017, "step": 36000}
{"episode_reward": 911.3518734564112, "episode": 37.0, "batch_reward": 0.6528331750631332, "critic_loss": 0.3881084539592266, "actor_loss": -84.36428593444825, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.431373596191406, "step": 37000}
{"episode_reward": 962.8564806335335, "episode": 38.0, "batch_reward": 0.6591716099977494, "critic_loss": 0.40602490298449995, "actor_loss": -84.85106903076172, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.98912024497986, "step": 38000}
{"episode_reward": 931.3229825315776, "episode": 39.0, "batch_reward": 0.668369447350502, "critic_loss": 0.36666282500326636, "actor_loss": -84.93300607299804, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.42783212661743, "step": 39000}
{"episode_reward": 960.8586762422846, "episode": 40.0, "batch_reward": 0.6757004975676536, "critic_loss": 0.31399326656758786, "actor_loss": -85.22760992431641, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.80759024620056, "step": 40000}
{"episode_reward": 959.9629898186727, "episode": 41.0, "batch_reward": 0.6789682030081748, "critic_loss": 0.30374099166691304, "actor_loss": -85.12611344909668, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.863001346588135, "step": 41000}
{"episode_reward": 860.4270637372905, "episode": 42.0, "batch_reward": 0.6844675084948539, "critic_loss": 0.30569939652085304, "actor_loss": -85.20500122070312, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.131059408187866, "step": 42000}
{"episode_reward": 890.9772137705609, "episode": 43.0, "batch_reward": 0.6899395418167115, "critic_loss": 0.295500526368618, "actor_loss": -85.40495343017578, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.072293996810913, "step": 43000}
{"episode_reward": 970.3185825648249, "episode": 44.0, "batch_reward": 0.6949275178909302, "critic_loss": 0.2996088470518589, "actor_loss": -85.60124838256836, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.93703055381775, "step": 44000}
{"episode_reward": 956.2232184920381, "episode": 45.0, "batch_reward": 0.7021279586553574, "critic_loss": 0.29613218834996224, "actor_loss": -85.70231512451171, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.115660905838013, "step": 45000}
{"episode_reward": 970.228806206997, "episode": 46.0, "batch_reward": 0.7077213891148567, "critic_loss": 0.2765871083587408, "actor_loss": -86.01740393066406, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.20859956741333, "step": 46000}
{"episode_reward": 960.5117601082895, "episode": 47.0, "batch_reward": 0.7151337110996246, "critic_loss": 0.31065654645860197, "actor_loss": -86.12525787353516, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.813355445861816, "step": 47000}
{"episode_reward": 926.66260993258, "episode": 48.0, "batch_reward": 0.7180234767198562, "critic_loss": 0.2814378433376551, "actor_loss": -86.30237080383301, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.93384623527527, "step": 48000}
{"episode_reward": 939.4746599287221, "episode": 49.0, "batch_reward": 0.7230964758992195, "critic_loss": 0.25517435017228124, "actor_loss": -86.4118437652588, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.46713900566101, "step": 49000}
{"episode_reward": 969.4307136252481, "episode": 50.0, "batch_reward": 0.7290313599705696, "critic_loss": 0.24408799949288368, "actor_loss": -86.63178184509277, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.244372129440308, "step": 50000}
{"episode_reward": 966.7629187578232, "episode": 51.0, "batch_reward": 0.7333394811749459, "critic_loss": 0.257130411490798, "actor_loss": -86.88193634033203, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.0813262462616, "step": 51000}
{"episode_reward": 948.6998295147528, "episode": 52.0, "batch_reward": 0.7379568506479264, "critic_loss": 0.24381876020133494, "actor_loss": -86.94692738342285, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.804181814193726, "step": 52000}
{"episode_reward": 950.7750039313972, "episode": 53.0, "batch_reward": 0.7425186154842377, "critic_loss": 0.23246659699082375, "actor_loss": -86.7739986114502, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.38825798034668, "step": 53000}
{"episode_reward": 949.4435163530434, "episode": 54.0, "batch_reward": 0.7451399194598198, "critic_loss": 0.2266190323010087, "actor_loss": -86.9874409942627, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.40636372566223, "step": 54000}
{"episode_reward": 957.6481574991753, "episode": 55.0, "batch_reward": 0.7476020414233208, "critic_loss": 0.23544107869267464, "actor_loss": -86.92305111694336, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.021641731262207, "step": 55000}
{"episode_reward": 928.8372375926313, "episode": 56.0, "batch_reward": 0.7503790568709373, "critic_loss": 0.23461838879436253, "actor_loss": -86.93235485839844, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.23997473716736, "step": 56000}
{"episode_reward": 926.219394622516, "episode": 57.0, "batch_reward": 0.754646451830864, "critic_loss": 0.238452325835824, "actor_loss": -86.9288865814209, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.28105902671814, "step": 57000}
{"episode_reward": 939.412700592667, "episode": 58.0, "batch_reward": 0.7574669618606568, "critic_loss": 0.22418649380654096, "actor_loss": -86.98446130371094, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.331289768218994, "step": 58000}
{"episode_reward": 940.3298650999147, "episode": 59.0, "batch_reward": 0.7612618193030357, "critic_loss": 0.2252246089577675, "actor_loss": -87.16311727905273, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.951995849609375, "step": 59000}
{"episode_reward": 980.3032928613827, "episode": 60.0, "batch_reward": 0.7641331750750542, "critic_loss": 0.22929445914924146, "actor_loss": -87.22460397338867, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.158987283706665, "step": 60000}
{"episode_reward": 947.4244452486295, "episode": 61.0, "batch_reward": 0.7689264917373657, "critic_loss": 0.2294206812977791, "actor_loss": -87.36703450012207, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 44.27789878845215, "step": 61000}
{"episode_reward": 936.4321032030987, "episode": 62.0, "batch_reward": 0.7716394675970077, "critic_loss": 0.22841130635142326, "actor_loss": -87.25026623535156, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.75465750694275, "step": 62000}
{"episode_reward": 955.088218294826, "episode": 63.0, "batch_reward": 0.7742124474048615, "critic_loss": 0.22777125030755996, "actor_loss": -87.52994342041016, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.26613450050354, "step": 63000}
{"episode_reward": 950.7180270287314, "episode": 64.0, "batch_reward": 0.7756857556700707, "critic_loss": 0.24269924510270358, "actor_loss": -87.43357275390625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.98409676551819, "step": 64000}
{"episode_reward": 771.1161820677598, "episode": 65.0, "batch_reward": 0.7765926263332367, "critic_loss": 0.24010121157765388, "actor_loss": -87.46802563476562, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.108055591583252, "step": 65000}
{"episode_reward": 972.5810040063836, "episode": 66.0, "batch_reward": 0.7783404933810234, "critic_loss": 0.23742567632347344, "actor_loss": -87.27389965820312, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.188055753707886, "step": 66000}
{"episode_reward": 837.9429749886261, "episode": 67.0, "batch_reward": 0.7798567166328431, "critic_loss": 0.2566432987079024, "actor_loss": -87.38831777954101, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.033900260925293, "step": 67000}
{"episode_reward": 950.8752370201694, "episode": 68.0, "batch_reward": 0.7832997999787331, "critic_loss": 0.24739690990000962, "actor_loss": -87.3433759765625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.27214479446411, "step": 68000}
{"episode_reward": 919.6263477316345, "episode": 69.0, "batch_reward": 0.7837376554608345, "critic_loss": 0.25444743686914445, "actor_loss": -87.63472354125976, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.158759117126465, "step": 69000}
{"episode_reward": 954.3336723582626, "episode": 70.0, "batch_reward": 0.7861632464528083, "critic_loss": 0.2683890086635947, "actor_loss": -87.57408909606933, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.42379641532898, "step": 70000}
{"episode_reward": 768.6404975455349, "episode": 71.0, "batch_reward": 0.7866578788757325, "critic_loss": 0.2709201282337308, "actor_loss": -87.54366387939453, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.357831954956055, "step": 71000}
{"episode_reward": 920.6660513771245, "episode": 72.0, "batch_reward": 0.7870949111580848, "critic_loss": 0.27797810450196264, "actor_loss": -87.58161842346192, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.943838596343994, "step": 72000}
{"episode_reward": 849.3260110991362, "episode": 73.0, "batch_reward": 0.7908679857850075, "critic_loss": 0.27638496438413857, "actor_loss": -87.59578930664063, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.71609139442444, "step": 73000}
{"episode_reward": 946.3825938841028, "episode": 74.0, "batch_reward": 0.790375813126564, "critic_loss": 0.27907823568582535, "actor_loss": -87.63282061767578, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.947163581848145, "step": 74000}
{"episode_reward": 963.2042318101693, "episode": 75.0, "batch_reward": 0.7931404234170913, "critic_loss": 0.29806984183192253, "actor_loss": -87.87483195495605, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.454932689666748, "step": 75000}
{"episode_reward": 913.8146651955061, "episode": 76.0, "batch_reward": 0.7945280131697655, "critic_loss": 0.27299415016174317, "actor_loss": -87.80844221496582, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.339350700378418, "step": 76000}
{"episode_reward": 843.6272769912571, "episode": 77.0, "batch_reward": 0.7945357183814049, "critic_loss": 0.29904243287444116, "actor_loss": -87.85606430053711, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.57099175453186, "step": 77000}
{"episode_reward": 900.0017977463501, "episode": 78.0, "batch_reward": 0.7992658023238182, "critic_loss": 0.2892682642489672, "actor_loss": -87.96297723388672, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.55435085296631, "step": 78000}
{"episode_reward": 973.5285282957348, "episode": 79.0, "batch_reward": 0.8004680123925209, "critic_loss": 0.2859071494266391, "actor_loss": -87.84042926025391, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.702616930007935, "step": 79000}
{"episode_reward": 953.4011873858205, "episode": 80.0, "batch_reward": 0.801780934214592, "critic_loss": 0.2708621062338352, "actor_loss": -87.77165821838379, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.14974021911621, "step": 80000}
{"episode_reward": 963.2499364131965, "episode": 81.0, "batch_reward": 0.8041181079149247, "critic_loss": 0.2740886282399297, "actor_loss": -87.888525390625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.9822051525116, "step": 81000}
{"episode_reward": 925.8519484933088, "episode": 82.0, "batch_reward": 0.8039913625717163, "critic_loss": 0.27913653167337177, "actor_loss": -87.99326840209962, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.812243223190308, "step": 82000}
{"episode_reward": 942.8793246683285, "episode": 83.0, "batch_reward": 0.8078958695530891, "critic_loss": 0.26521361237764357, "actor_loss": -88.00873052978515, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.49946665763855, "step": 83000}
{"episode_reward": 967.2038667833748, "episode": 84.0, "batch_reward": 0.8086667983531952, "critic_loss": 0.2678039897531271, "actor_loss": -88.09226042175293, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.946476936340332, "step": 84000}
{"episode_reward": 920.9867548869898, "episode": 85.0, "batch_reward": 0.8097210907936097, "critic_loss": 0.25368693567812445, "actor_loss": -88.17628030395508, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.80903720855713, "step": 85000}
{"episode_reward": 944.275335643245, "episode": 86.0, "batch_reward": 0.8134520852565765, "critic_loss": 0.26340157076716425, "actor_loss": -88.12393385314941, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.399755239486694, "step": 86000}
{"episode_reward": 939.9871531848523, "episode": 87.0, "batch_reward": 0.8147028149366379, "critic_loss": 0.25901523062586784, "actor_loss": -88.09690911865235, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.511974811553955, "step": 87000}
{"episode_reward": 970.3572763546251, "episode": 88.0, "batch_reward": 0.814624029815197, "critic_loss": 0.2532980975434184, "actor_loss": -88.23312876892089, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.050437688827515, "step": 88000}
{"episode_reward": 956.238442867013, "episode": 89.0, "batch_reward": 0.8182006772756577, "critic_loss": 0.25106198676675556, "actor_loss": -88.40208224487304, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.128385305404663, "step": 89000}
{"episode_reward": 924.5265992032628, "episode": 90.0, "batch_reward": 0.8191789724230766, "critic_loss": 0.2542304129526019, "actor_loss": -88.47516133117676, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.942819833755493, "step": 90000}
{"episode_reward": 914.8724415394225, "episode": 91.0, "batch_reward": 0.8191188575029373, "critic_loss": 0.25243023536354303, "actor_loss": -88.60695176696777, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.40387797355652, "step": 91000}
{"episode_reward": 953.882201418173, "episode": 92.0, "batch_reward": 0.8202931165695191, "critic_loss": 0.27440095925331115, "actor_loss": -88.56477597045898, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.085660934448242, "step": 92000}
{"episode_reward": 899.9671585160106, "episode": 93.0, "batch_reward": 0.820587066590786, "critic_loss": 0.2582168948501348, "actor_loss": -88.65159043884277, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.42548704147339, "step": 93000}
{"episode_reward": 938.9372133550088, "episode": 94.0, "batch_reward": 0.8232172579169273, "critic_loss": 0.2604605876505375, "actor_loss": -88.79114155578613, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.463372468948364, "step": 94000}
{"episode_reward": 892.3245772853597, "episode": 95.0, "batch_reward": 0.8228147548437118, "critic_loss": 0.2751011883020401, "actor_loss": -88.59008473205566, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.506754159927368, "step": 95000}
{"episode_reward": 870.8041943534912, "episode": 96.0, "batch_reward": 0.8239858455061913, "critic_loss": 0.2869267784357071, "actor_loss": -88.77981661987305, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.55277180671692, "step": 96000}
{"episode_reward": 906.3963371940367, "episode": 97.0, "batch_reward": 0.8254800299406052, "critic_loss": 0.26757327139377596, "actor_loss": -88.76827287292481, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.31838607788086, "step": 97000}
{"episode_reward": 976.9623984386911, "episode": 98.0, "batch_reward": 0.8261993118524551, "critic_loss": 0.2636561850532889, "actor_loss": -88.48739445495606, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.718698024749756, "step": 98000}
{"episode_reward": 970.4159398517775, "episode": 99.0, "batch_reward": 0.8278131461143494, "critic_loss": 0.25914931544661524, "actor_loss": -88.87855198669433, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.547959804534912, "step": 99000}
{"episode_reward": 959.4466866280629, "episode": 100.0, "batch_reward": 0.8293410462737083, "critic_loss": 0.25604756200313566, "actor_loss": -88.76522438049317, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.75068688392639, "step": 100000}
{"episode_reward": 960.9853422096062, "episode": 101.0, "batch_reward": 0.8292276803255081, "critic_loss": 0.2677682224661112, "actor_loss": -88.8826318359375, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 46.77453660964966, "step": 101000}
{"episode_reward": 892.7553575849139, "episode": 102.0, "batch_reward": 0.8309574934840203, "critic_loss": 0.26032203357666733, "actor_loss": -88.95430209350586, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.999574899673462, "step": 102000}
{"episode_reward": 972.9051984888371, "episode": 103.0, "batch_reward": 0.831978498518467, "critic_loss": 0.2644298114106059, "actor_loss": -89.01106561279298, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.468029260635376, "step": 103000}
{"episode_reward": 962.889464753537, "episode": 104.0, "batch_reward": 0.8352530711889267, "critic_loss": 0.26451013994961975, "actor_loss": -89.14538905334473, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.316767692565918, "step": 104000}
{"episode_reward": 965.0439966420424, "episode": 105.0, "batch_reward": 0.8347432998418808, "critic_loss": 0.2752583341524005, "actor_loss": -89.18101850891114, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.441731214523315, "step": 105000}
{"episode_reward": 958.321659530026, "episode": 106.0, "batch_reward": 0.8362508200407028, "critic_loss": 0.2627060342207551, "actor_loss": -89.33416641235351, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.879780769348145, "step": 106000}
{"episode_reward": 972.119885418298, "episode": 107.0, "batch_reward": 0.8367467069625855, "critic_loss": 0.25768999513983726, "actor_loss": -89.24264642333985, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.998642683029175, "step": 107000}
{"episode_reward": 945.8150622509548, "episode": 108.0, "batch_reward": 0.838359373986721, "critic_loss": 0.2513727298974991, "actor_loss": -89.1866372833252, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.934480905532837, "step": 108000}
{"episode_reward": 939.9532580094966, "episode": 109.0, "batch_reward": 0.8394680800437927, "critic_loss": 0.2667475091069937, "actor_loss": -89.28024327087402, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.34937047958374, "step": 109000}
{"episode_reward": 879.5590097784196, "episode": 110.0, "batch_reward": 0.8383932227492332, "critic_loss": 0.29140659230947497, "actor_loss": -89.15582009887696, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.160290479660034, "step": 110000}
{"episode_reward": 927.0740004180585, "episode": 111.0, "batch_reward": 0.8407495664954185, "critic_loss": 0.2548554881066084, "actor_loss": -89.32758282470704, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.58133625984192, "step": 111000}
{"episode_reward": 976.4627692751847, "episode": 112.0, "batch_reward": 0.8409445522427559, "critic_loss": 0.2477540944442153, "actor_loss": -89.17954188537598, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.22032141685486, "step": 112000}
{"episode_reward": 957.5853785305391, "episode": 113.0, "batch_reward": 0.8442223311066628, "critic_loss": 0.2576748623400927, "actor_loss": -89.44712036132813, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.97305130958557, "step": 113000}
{"episode_reward": 970.2682634032395, "episode": 114.0, "batch_reward": 0.845888206243515, "critic_loss": 0.266776941716671, "actor_loss": -89.43777194213867, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.81416130065918, "step": 114000}
{"episode_reward": 935.7288426037672, "episode": 115.0, "batch_reward": 0.8454653117060661, "critic_loss": 0.2620772793292999, "actor_loss": -89.50901928710938, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.295137643814087, "step": 115000}
{"episode_reward": 972.8169775717956, "episode": 116.0, "batch_reward": 0.8460704720020295, "critic_loss": 0.2698260605186224, "actor_loss": -89.56608482360839, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.207590103149414, "step": 116000}
{"episode_reward": 974.2784373956484, "episode": 117.0, "batch_reward": 0.847459165751934, "critic_loss": 0.2508302983343601, "actor_loss": -89.78924467468262, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.367597341537476, "step": 117000}
{"episode_reward": 973.7839487542468, "episode": 118.0, "batch_reward": 0.8475455828905105, "critic_loss": 0.25044221884012224, "actor_loss": -89.65753115844727, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.948368549346924, "step": 118000}
{"episode_reward": 915.3917241426005, "episode": 119.0, "batch_reward": 0.8492417265176773, "critic_loss": 0.2760574443489313, "actor_loss": -89.79380165100098, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.70579242706299, "step": 119000}
{"episode_reward": 933.1055167239606, "episode": 120.0, "batch_reward": 0.850277173101902, "critic_loss": 0.2496898447573185, "actor_loss": -89.97373138427734, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.880592584609985, "step": 120000}
{"episode_reward": 967.8142246352937, "episode": 121.0, "batch_reward": 0.8512896438837051, "critic_loss": 0.24072360237687826, "actor_loss": -89.99459616088868, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 44.81749963760376, "step": 121000}
{"episode_reward": 950.7226142265373, "episode": 122.0, "batch_reward": 0.8517079396843911, "critic_loss": 0.24260365686565638, "actor_loss": -89.9598795928955, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.530857801437378, "step": 122000}
{"episode_reward": 915.100524754206, "episode": 123.0, "batch_reward": 0.8512809335589409, "critic_loss": 0.2575704482868314, "actor_loss": -89.88446621704101, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.737019777297974, "step": 123000}
{"episode_reward": 939.7681468409986, "episode": 124.0, "batch_reward": 0.8525410906076432, "critic_loss": 0.23160250639170407, "actor_loss": -89.88422973632812, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.02842664718628, "step": 124000}
{"episode_reward": 959.0867054908686, "episode": 125.0, "batch_reward": 0.8496013388037682, "critic_loss": 0.26658852492272855, "actor_loss": -89.83295404052734, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.16209840774536, "step": 125000}
{"episode_reward": 30.884606656926284, "episode": 126.0, "batch_reward": 0.8463981229662895, "critic_loss": 0.27910205858945847, "actor_loss": -89.73522323608398, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.93476128578186, "step": 126000}
{"episode_reward": 971.222975438056, "episode": 127.0, "batch_reward": 0.8466752698421478, "critic_loss": 0.2859966016188264, "actor_loss": -89.64952545166015, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.056270599365234, "step": 127000}
{"episode_reward": 909.5765001264584, "episode": 128.0, "batch_reward": 0.8478010608553886, "critic_loss": 0.28583125899732115, "actor_loss": -89.67861019897461, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.193719625473022, "step": 128000}
{"episode_reward": 953.7742059889756, "episode": 129.0, "batch_reward": 0.8490493807196617, "critic_loss": 0.24599216866493226, "actor_loss": -89.6932251739502, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.14574408531189, "step": 129000}
{"episode_reward": 963.7705994861759, "episode": 130.0, "batch_reward": 0.8492127060890198, "critic_loss": 0.2739495851546526, "actor_loss": -89.62660595703124, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.51833939552307, "step": 130000}
{"episode_reward": 909.8651724785339, "episode": 131.0, "batch_reward": 0.8496704442501068, "critic_loss": 0.2897502177506685, "actor_loss": -89.7164140625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.49054193496704, "step": 131000}
{"episode_reward": 919.5453313732994, "episode": 132.0, "batch_reward": 0.8506889575719834, "critic_loss": 0.2745184329003096, "actor_loss": -89.74802993774414, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.52490496635437, "step": 132000}
{"episode_reward": 924.3599606895385, "episode": 133.0, "batch_reward": 0.8516982824206353, "critic_loss": 0.29202432438731196, "actor_loss": -89.89310202026367, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.574201107025146, "step": 133000}
{"episode_reward": 981.0169159440478, "episode": 134.0, "batch_reward": 0.8513646349310875, "critic_loss": 0.2661641843020916, "actor_loss": -89.64852172851562, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.162465810775757, "step": 134000}
{"episode_reward": 972.835327810732, "episode": 135.0, "batch_reward": 0.8498625596761703, "critic_loss": 0.2856343863159418, "actor_loss": -89.5533455657959, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.58729577064514, "step": 135000}
{"episode_reward": 613.5060245643834, "episode": 136.0, "batch_reward": 0.8517571331858635, "critic_loss": 0.295703784622252, "actor_loss": -89.77665191650391, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.56320834159851, "step": 136000}
{"episode_reward": 911.6016679030342, "episode": 137.0, "batch_reward": 0.8518658844828606, "critic_loss": 0.2904734871685505, "actor_loss": -89.61367422485351, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.25998044013977, "step": 137000}
{"episode_reward": 926.2129308972796, "episode": 138.0, "batch_reward": 0.8528339039683343, "critic_loss": 0.2825394403412938, "actor_loss": -89.68967021179199, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.597994565963745, "step": 138000}
{"episode_reward": 957.9645258163266, "episode": 139.0, "batch_reward": 0.8516581448316574, "critic_loss": 0.28920700822770595, "actor_loss": -89.88842094421386, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.076986074447632, "step": 139000}
{"episode_reward": 780.345232665163, "episode": 140.0, "batch_reward": 0.8518615458011627, "critic_loss": 0.2956965397298336, "actor_loss": -89.82233576965332, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.36766266822815, "step": 140000}
{"episode_reward": 928.6379208056262, "episode": 141.0, "batch_reward": 0.8550574771165848, "critic_loss": 0.2849301965907216, "actor_loss": -89.742173828125, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.47946238517761, "step": 141000}
{"episode_reward": 944.6302704672919, "episode": 142.0, "batch_reward": 0.8543678738474846, "critic_loss": 0.2909734717085958, "actor_loss": -89.83159934997559, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.994552850723267, "step": 142000}
{"episode_reward": 975.2577790740492, "episode": 143.0, "batch_reward": 0.8543850834965706, "critic_loss": 0.29848322333395483, "actor_loss": -89.7542652130127, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.894607543945312, "step": 143000}
{"episode_reward": 928.0347860054297, "episode": 144.0, "batch_reward": 0.8547673602700233, "critic_loss": 0.3014674712121487, "actor_loss": -89.70076892089844, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.24438786506653, "step": 144000}
{"episode_reward": 951.1033117860446, "episode": 145.0, "batch_reward": 0.8580272088050842, "critic_loss": 0.322770670376718, "actor_loss": -89.75334664916993, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.219225645065308, "step": 145000}
{"episode_reward": 942.6274846692502, "episode": 146.0, "batch_reward": 0.8549183245897293, "critic_loss": 0.321084838218987, "actor_loss": -89.68645434570313, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.828848361968994, "step": 146000}
{"episode_reward": 934.9880577807874, "episode": 147.0, "batch_reward": 0.8550117893218994, "critic_loss": 0.2961536397263408, "actor_loss": -89.81089093017579, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.808003664016724, "step": 147000}
{"episode_reward": 915.9994669231595, "episode": 148.0, "batch_reward": 0.8580957981944084, "critic_loss": 0.3075255449414253, "actor_loss": -89.73568618774414, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.646327257156372, "step": 148000}
{"episode_reward": 851.488241093054, "episode": 149.0, "batch_reward": 0.8568586221337319, "critic_loss": 0.33935774472355845, "actor_loss": -89.85134671020508, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.880178689956665, "step": 149000}
{"episode_reward": 793.1258995486478, "episode": 150.0, "batch_reward": 0.8562063122987748, "critic_loss": 0.3291683781594038, "actor_loss": -89.67090542602539, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "step": 150000}
