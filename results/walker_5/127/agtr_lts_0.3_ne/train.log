{"episode_reward": 0.0, "episode": 1.0, "duration": 21.951550006866455, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.9001669883728027, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.4621437323733384, "critic_loss": 0.33303147784945725, "actor_loss": -78.97067179838244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 71.43546032905579, "step": 3000}
{"episode_reward": 893.1164874126267, "episode": 4.0, "batch_reward": 0.6336409291625023, "critic_loss": 0.3656288890093565, "actor_loss": -85.76342509460449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.74064016342163, "step": 4000}
{"episode_reward": 929.1933345512202, "episode": 5.0, "batch_reward": 0.6782231819033623, "critic_loss": 0.40880298809707166, "actor_loss": -87.13789852905273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.79130530357361, "step": 5000}
{"episode_reward": 813.9333827487143, "episode": 6.0, "batch_reward": 0.7114452236294746, "critic_loss": 0.30995159097015856, "actor_loss": -87.92154542541503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.745134830474854, "step": 6000}
{"episode_reward": 872.972507448379, "episode": 7.0, "batch_reward": 0.7450603713393211, "critic_loss": 0.3177646360993385, "actor_loss": -89.19691398620606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.78864812850952, "step": 7000}
{"episode_reward": 940.6384964677092, "episode": 8.0, "batch_reward": 0.7696416791677475, "critic_loss": 0.4009983465820551, "actor_loss": -90.11355555725098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.78786325454712, "step": 8000}
{"episode_reward": 920.8333962961627, "episode": 9.0, "batch_reward": 0.7894791890382766, "critic_loss": 0.5730198227465153, "actor_loss": -91.61088600158692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.789153337478638, "step": 9000}
{"episode_reward": 957.0709499102479, "episode": 10.0, "batch_reward": 0.803345319390297, "critic_loss": 1.0514982087314129, "actor_loss": -93.62434481811523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.813859939575195, "step": 10000}
{"episode_reward": 920.826404787317, "episode": 11.0, "batch_reward": 0.7755737541913986, "critic_loss": 2.6000418605804443, "actor_loss": -97.42172735595703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.46802616119385, "step": 11000}
{"episode_reward": 30.31071916183713, "episode": 12.0, "batch_reward": 0.7359561037421226, "critic_loss": 3.4497169659137725, "actor_loss": -100.74050917053222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.804301023483276, "step": 12000}
{"episode_reward": 776.2366382578741, "episode": 13.0, "batch_reward": 0.7450043886899949, "critic_loss": 3.921022317528725, "actor_loss": -103.11582008361816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.741310358047485, "step": 13000}
{"episode_reward": 597.1775068961491, "episode": 14.0, "batch_reward": 0.7061367186903954, "critic_loss": 6.564141571521759, "actor_loss": -106.71838664245605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.772246599197388, "step": 14000}
{"episode_reward": 30.84949823260621, "episode": 15.0, "batch_reward": 0.6612755068540573, "critic_loss": 6.9700930786132815, "actor_loss": -113.55343484497071, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.729631423950195, "step": 15000}
{"episode_reward": 27.806168599001396, "episode": 16.0, "batch_reward": 0.6222659239768982, "critic_loss": 8.687157608032226, "actor_loss": -124.46518208312989, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.771522521972656, "step": 16000}
{"episode_reward": 55.79526140908489, "episode": 17.0, "batch_reward": 0.5852288942039013, "critic_loss": 12.417905902862548, "actor_loss": -143.8525153656006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.821486949920654, "step": 17000}
{"episode_reward": 28.614254059282256, "episode": 18.0, "batch_reward": 0.5557308918833732, "critic_loss": 13.054974775791168, "actor_loss": -156.77564413452149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.807579517364502, "step": 18000}
{"episode_reward": 26.93958772686718, "episode": 19.0, "batch_reward": 0.52666283634305, "critic_loss": 10.581005826473236, "actor_loss": -161.51688604736327, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.816014051437378, "step": 19000}
{"episode_reward": 74.187498993249, "episode": 20.0, "batch_reward": 0.5048546378314495, "critic_loss": 10.130379457473754, "actor_loss": -159.83880047607423, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.786580801010132, "step": 20000}
{"episode_reward": 66.64944924830216, "episode": 21.0, "batch_reward": 0.4813057689666748, "critic_loss": 8.09069101524353, "actor_loss": -164.26630215454102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.740928411483765, "step": 21000}
{"episode_reward": 28.59777277397791, "episode": 22.0, "batch_reward": 0.4612646914720535, "critic_loss": 7.049152737617493, "actor_loss": -155.0126211090088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.75210404396057, "step": 22000}
{"episode_reward": 65.33940849162745, "episode": 23.0, "batch_reward": 0.43954735100269315, "critic_loss": 6.683384279966354, "actor_loss": -159.56883767700197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.70253276824951, "step": 23000}
{"episode_reward": 28.281322504736277, "episode": 24.0, "batch_reward": 0.43661365514993666, "critic_loss": 7.243552007198334, "actor_loss": -154.41253381347656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.68753147125244, "step": 24000}
{"episode_reward": 623.3348338075721, "episode": 25.0, "batch_reward": 0.4396686053276062, "critic_loss": 5.960924211740494, "actor_loss": -154.33810456848144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.694818258285522, "step": 25000}
{"episode_reward": 578.0041654990907, "episode": 26.0, "batch_reward": 0.45137614649534225, "critic_loss": 4.718082027196884, "actor_loss": -153.4469801635742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.66096329689026, "step": 26000}
{"episode_reward": 782.8643739648761, "episode": 27.0, "batch_reward": 0.46625055450201036, "critic_loss": 4.396272717952728, "actor_loss": -151.2628932647705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.67076015472412, "step": 27000}
{"episode_reward": 798.2323529791055, "episode": 28.0, "batch_reward": 0.47718975141644476, "critic_loss": 4.229918463468552, "actor_loss": -143.0225950164795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.467185974121094, "step": 28000}
{"episode_reward": 887.8756904586045, "episode": 29.0, "batch_reward": 0.4782896308302879, "critic_loss": 4.0784714833498, "actor_loss": -148.66754650878906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.358351469039917, "step": 29000}
{"episode_reward": 23.195990182526437, "episode": 30.0, "batch_reward": 0.47356998825073243, "critic_loss": 3.3446832914352416, "actor_loss": -150.78901330566407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.7777202129364, "step": 30000}
{"episode_reward": 783.8600929483678, "episode": 31.0, "batch_reward": 0.48878410294651986, "critic_loss": 2.677994243979454, "actor_loss": -147.27922503662109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.39167857170105, "step": 31000}
{"episode_reward": 891.7243586105358, "episode": 32.0, "batch_reward": 0.49889088436961176, "critic_loss": 2.090507549285889, "actor_loss": -141.20387704467774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.78403615951538, "step": 32000}
{"episode_reward": 908.2254449165176, "episode": 33.0, "batch_reward": 0.5109999195635319, "critic_loss": 1.7225205425620078, "actor_loss": -137.4796764831543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.762112617492676, "step": 33000}
{"episode_reward": 920.5137435101217, "episode": 34.0, "batch_reward": 0.5249996650516987, "critic_loss": 1.465759414434433, "actor_loss": -142.0057061920166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.79217839241028, "step": 34000}
{"episode_reward": 928.6979909829392, "episode": 35.0, "batch_reward": 0.5278123694360256, "critic_loss": 1.3116042923331261, "actor_loss": -133.37428785705566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.767138957977295, "step": 35000}
{"episode_reward": 509.4733880180909, "episode": 36.0, "batch_reward": 0.5366490776538849, "critic_loss": 1.2134970841407775, "actor_loss": -130.8369720916748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.823304891586304, "step": 36000}
{"episode_reward": 879.2846071556677, "episode": 37.0, "batch_reward": 0.5456266457140446, "critic_loss": 1.1821395574212075, "actor_loss": -130.7335118713379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.773900270462036, "step": 37000}
{"episode_reward": 955.0716392839056, "episode": 38.0, "batch_reward": 0.5514180137813092, "critic_loss": 1.1643562440276145, "actor_loss": -127.72201223754882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.828121423721313, "step": 38000}
{"episode_reward": 680.3342800776435, "episode": 39.0, "batch_reward": 0.5567971008121967, "critic_loss": 1.0312585535943508, "actor_loss": -124.51901940917969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.82066321372986, "step": 39000}
{"episode_reward": 882.8704458698554, "episode": 40.0, "batch_reward": 0.5691082012951374, "critic_loss": 0.9693779878020287, "actor_loss": -126.260625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.755039930343628, "step": 40000}
{"episode_reward": 947.9143156246155, "episode": 41.0, "batch_reward": 0.5755490203201771, "critic_loss": 0.9648691906929016, "actor_loss": -125.87671086120605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.44847249984741, "step": 41000}
{"episode_reward": 954.1367167917963, "episode": 42.0, "batch_reward": 0.5874655787050724, "critic_loss": 0.8765932643413543, "actor_loss": -121.35667070007324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.711805820465088, "step": 42000}
{"episode_reward": 913.3753398408526, "episode": 43.0, "batch_reward": 0.5936363754272461, "critic_loss": 0.77762895154953, "actor_loss": -120.08590682983399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.79625654220581, "step": 43000}
{"episode_reward": 961.141325063322, "episode": 44.0, "batch_reward": 0.6012389743924141, "critic_loss": 0.7303137520849705, "actor_loss": -116.68365737915039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.72083830833435, "step": 44000}
{"episode_reward": 950.7995979077556, "episode": 45.0, "batch_reward": 0.6101287749409675, "critic_loss": 0.6850133354663849, "actor_loss": -116.05442179870606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.736334085464478, "step": 45000}
{"episode_reward": 959.685412710351, "episode": 46.0, "batch_reward": 0.6181051275134086, "critic_loss": 0.7178930527865887, "actor_loss": -116.43630192565918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.678382635116577, "step": 46000}
{"episode_reward": 947.6215158221431, "episode": 47.0, "batch_reward": 0.6248516331911087, "critic_loss": 0.6793663352429867, "actor_loss": -115.31046385192872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.76967692375183, "step": 47000}
{"episode_reward": 920.0078597265514, "episode": 48.0, "batch_reward": 0.6315944746136666, "critic_loss": 0.6618597832322121, "actor_loss": -114.86794456481934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.75840711593628, "step": 48000}
{"episode_reward": 936.1422657665045, "episode": 49.0, "batch_reward": 0.6365922282934189, "critic_loss": 0.6702941576838494, "actor_loss": -112.36255850219726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.775348663330078, "step": 49000}
{"episode_reward": 941.3371276475131, "episode": 50.0, "batch_reward": 0.6440362402200699, "critic_loss": 0.6237506573200226, "actor_loss": -113.40003883361817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.734886407852173, "step": 50000}
{"episode_reward": 957.6272162264589, "episode": 51.0, "batch_reward": 0.6494137594699859, "critic_loss": 0.5666823040544987, "actor_loss": -113.34709948730469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.33486223220825, "step": 51000}
{"episode_reward": 951.7385559561266, "episode": 52.0, "batch_reward": 0.6584715912342072, "critic_loss": 0.5522111108899117, "actor_loss": -114.2052317199707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.717959880828857, "step": 52000}
{"episode_reward": 937.1804340132092, "episode": 53.0, "batch_reward": 0.6613046888709069, "critic_loss": 0.49337489683926106, "actor_loss": -110.99355111694337, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.701003789901733, "step": 53000}
{"episode_reward": 950.0328877990459, "episode": 54.0, "batch_reward": 0.6673896079659462, "critic_loss": 0.44902724015712736, "actor_loss": -110.67721171569825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.658962965011597, "step": 54000}
{"episode_reward": 961.2013453035393, "episode": 55.0, "batch_reward": 0.6708450253009797, "critic_loss": 0.45550706039369104, "actor_loss": -108.93583674621583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.676514387130737, "step": 55000}
{"episode_reward": 936.8418263299159, "episode": 56.0, "batch_reward": 0.6771413342952728, "critic_loss": 0.43914951832592486, "actor_loss": -108.63510075378419, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.647422552108765, "step": 56000}
{"episode_reward": 969.8944185903733, "episode": 57.0, "batch_reward": 0.6834976149201393, "critic_loss": 0.4152920590341091, "actor_loss": -106.49512655639649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.664565086364746, "step": 57000}
{"episode_reward": 899.662847135464, "episode": 58.0, "batch_reward": 0.6855838972926139, "critic_loss": 0.38340532341599465, "actor_loss": -104.93198670959472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.673006534576416, "step": 58000}
{"episode_reward": 954.0224362818115, "episode": 59.0, "batch_reward": 0.691737514078617, "critic_loss": 0.35571444188058376, "actor_loss": -105.15251370239258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.603456020355225, "step": 59000}
{"episode_reward": 973.1623622899548, "episode": 60.0, "batch_reward": 0.6966206275820732, "critic_loss": 0.36799922490119935, "actor_loss": -103.09670581054688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.106744050979614, "step": 60000}
{"episode_reward": 967.2297675919332, "episode": 61.0, "batch_reward": 0.7012001116275788, "critic_loss": 0.325898501098156, "actor_loss": -103.11578646850586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.43021607398987, "step": 61000}
{"episode_reward": 926.9193460033555, "episode": 62.0, "batch_reward": 0.7047473801970482, "critic_loss": 0.31068071798980235, "actor_loss": -101.18184329223632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.809606313705444, "step": 62000}
{"episode_reward": 950.3422874206946, "episode": 63.0, "batch_reward": 0.7071972113251687, "critic_loss": 0.3010368362516165, "actor_loss": -101.93033456420899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.779935598373413, "step": 63000}
{"episode_reward": 956.7297878530744, "episode": 64.0, "batch_reward": 0.7127634879946708, "critic_loss": 0.31093282960355284, "actor_loss": -99.99533555603027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.75930643081665, "step": 64000}
{"episode_reward": 912.2254326346354, "episode": 65.0, "batch_reward": 0.7136820277571678, "critic_loss": 0.3153267538398504, "actor_loss": -99.27714044189453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.81127953529358, "step": 65000}
{"episode_reward": 966.3984474340912, "episode": 66.0, "batch_reward": 0.7170888893604278, "critic_loss": 0.31859063939750193, "actor_loss": -98.53588240051269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.77957820892334, "step": 66000}
{"episode_reward": 896.9849798465364, "episode": 67.0, "batch_reward": 0.7213489270210266, "critic_loss": 0.3087743204832077, "actor_loss": -97.01917315673828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.781943798065186, "step": 67000}
{"episode_reward": 954.4114177933241, "episode": 68.0, "batch_reward": 0.7241607041358947, "critic_loss": 0.32638904905319216, "actor_loss": -97.41643507385254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.78553009033203, "step": 68000}
{"episode_reward": 945.4902943407083, "episode": 69.0, "batch_reward": 0.7270517681837082, "critic_loss": 0.3253798371851444, "actor_loss": -98.01256941223144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.793426036834717, "step": 69000}
{"episode_reward": 957.1229323754322, "episode": 70.0, "batch_reward": 0.7312477120757103, "critic_loss": 0.3091203944981098, "actor_loss": -96.51748741149902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.796630144119263, "step": 70000}
{"episode_reward": 951.1061484787771, "episode": 71.0, "batch_reward": 0.7342704348564147, "critic_loss": 0.28788705925643443, "actor_loss": -96.2406683959961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.431962966918945, "step": 71000}
{"episode_reward": 919.5705935925337, "episode": 72.0, "batch_reward": 0.7346176636815072, "critic_loss": 0.3047216459810734, "actor_loss": -96.49046060180665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.78546118736267, "step": 72000}
{"episode_reward": 940.0881404984821, "episode": 73.0, "batch_reward": 0.7405108069777488, "critic_loss": 0.2864045750051737, "actor_loss": -95.95362260437011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.726941347122192, "step": 73000}
{"episode_reward": 931.5431240226535, "episode": 74.0, "batch_reward": 0.7425678325295448, "critic_loss": 0.286875655092299, "actor_loss": -95.52999143981934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.80869960784912, "step": 74000}
{"episode_reward": 971.7286900504238, "episode": 75.0, "batch_reward": 0.7423531566858291, "critic_loss": 0.30181647449731824, "actor_loss": -95.86942042541504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.78345012664795, "step": 75000}
{"episode_reward": 910.7929500751814, "episode": 76.0, "batch_reward": 0.7484537551999092, "critic_loss": 0.27269732534885405, "actor_loss": -95.23167543029786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.750714778900146, "step": 76000}
{"episode_reward": 930.9223802294963, "episode": 77.0, "batch_reward": 0.7497325053215027, "critic_loss": 0.2757957791611552, "actor_loss": -94.46987309265137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.693272829055786, "step": 77000}
{"episode_reward": 957.1698761051705, "episode": 78.0, "batch_reward": 0.7532386112809181, "critic_loss": 0.2766192637681961, "actor_loss": -94.39632431030273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.783463716506958, "step": 78000}
{"episode_reward": 977.5658450387583, "episode": 79.0, "batch_reward": 0.7562203991413117, "critic_loss": 0.25064630155265333, "actor_loss": -93.84508549499512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.76362442970276, "step": 79000}
{"episode_reward": 946.8564694036139, "episode": 80.0, "batch_reward": 0.7558779766559601, "critic_loss": 0.24540762158483267, "actor_loss": -93.45683850097656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.76628303527832, "step": 80000}
{"episode_reward": 976.8332044147602, "episode": 81.0, "batch_reward": 0.761602420091629, "critic_loss": 0.24753320564329623, "actor_loss": -93.37114141845703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.39923310279846, "step": 81000}
{"episode_reward": 952.5149554490611, "episode": 82.0, "batch_reward": 0.7613727793693542, "critic_loss": 0.24308049052208663, "actor_loss": -94.11147200012206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.719148635864258, "step": 82000}
{"episode_reward": 930.2788683967096, "episode": 83.0, "batch_reward": 0.764728409588337, "critic_loss": 0.23438737659901382, "actor_loss": -92.96087452697753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.74286913871765, "step": 83000}
{"episode_reward": 973.5599819985754, "episode": 84.0, "batch_reward": 0.7626276766657829, "critic_loss": 0.28255108699202536, "actor_loss": -93.27487594604492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.745569944381714, "step": 84000}
{"episode_reward": 609.0855584123309, "episode": 85.0, "batch_reward": 0.7653786848783493, "critic_loss": 0.2490287039205432, "actor_loss": -92.95575833129882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.72722029685974, "step": 85000}
{"episode_reward": 938.5186133334755, "episode": 86.0, "batch_reward": 0.768311348259449, "critic_loss": 0.21455375008285046, "actor_loss": -92.68900207519532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.707186937332153, "step": 86000}
{"episode_reward": 969.6941355502964, "episode": 87.0, "batch_reward": 0.7706489298939705, "critic_loss": 0.21582008004188538, "actor_loss": -92.02748020935059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.689415454864502, "step": 87000}
{"episode_reward": 979.1224295024668, "episode": 88.0, "batch_reward": 0.7722845265269279, "critic_loss": 0.22815943549573423, "actor_loss": -92.79843905639649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.65787148475647, "step": 88000}
{"episode_reward": 971.9116011793149, "episode": 89.0, "batch_reward": 0.7727487959861755, "critic_loss": 0.2136677987650037, "actor_loss": -92.6613589630127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.672067403793335, "step": 89000}
{"episode_reward": 936.9776194692228, "episode": 90.0, "batch_reward": 0.7770720444917679, "critic_loss": 0.2313781516030431, "actor_loss": -92.35748307800293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.59654140472412, "step": 90000}
{"episode_reward": 924.8831175138025, "episode": 91.0, "batch_reward": 0.777835157096386, "critic_loss": 0.21921825055778027, "actor_loss": -92.54747448730468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.03498864173889, "step": 91000}
{"episode_reward": 973.1443597064305, "episode": 92.0, "batch_reward": 0.7801335027217865, "critic_loss": 0.22212872955203056, "actor_loss": -92.08992231750489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.799978971481323, "step": 92000}
{"episode_reward": 927.9810938915554, "episode": 93.0, "batch_reward": 0.7820160156488418, "critic_loss": 0.2394820797815919, "actor_loss": -92.24123091125489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.7987060546875, "step": 93000}
{"episode_reward": 972.3151698610216, "episode": 94.0, "batch_reward": 0.7823915967941284, "critic_loss": 0.22807542821764945, "actor_loss": -92.17291229248048, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.99197769165039, "step": 94000}
{"episode_reward": 922.894420496941, "episode": 95.0, "batch_reward": 0.7836806751489639, "critic_loss": 0.2226990637332201, "actor_loss": -91.28653993225097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.83848476409912, "step": 95000}
{"episode_reward": 898.0456586038609, "episode": 96.0, "batch_reward": 0.7854952101111412, "critic_loss": 0.21259665718674658, "actor_loss": -91.71458102416992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.933545351028442, "step": 96000}
{"episode_reward": 951.5662796631756, "episode": 97.0, "batch_reward": 0.7868784767985344, "critic_loss": 0.21747589381039142, "actor_loss": -91.37418267822265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.701730012893677, "step": 97000}
{"episode_reward": 974.8645312997871, "episode": 98.0, "batch_reward": 0.7901047617197037, "critic_loss": 0.22080405005812645, "actor_loss": -90.78624682617188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.799247980117798, "step": 98000}
{"episode_reward": 971.4703034752848, "episode": 99.0, "batch_reward": 0.793496073782444, "critic_loss": 0.20849301580339671, "actor_loss": -91.27475077819824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.740126371383667, "step": 99000}
{"episode_reward": 974.3883284480246, "episode": 100.0, "batch_reward": 0.7953137995004654, "critic_loss": 0.20242992324382067, "actor_loss": -91.03007792663574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.78678035736084, "step": 100000}
{"episode_reward": 979.0683071058343, "episode": 101.0, "batch_reward": 0.7946630520224571, "critic_loss": 0.21062868174910546, "actor_loss": -91.38522947692871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.36052584648132, "step": 101000}
{"episode_reward": 932.3001886062113, "episode": 102.0, "batch_reward": 0.7983158976435661, "critic_loss": 0.21305231901258231, "actor_loss": -90.76222380065919, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.79482674598694, "step": 102000}
{"episode_reward": 978.363868156386, "episode": 103.0, "batch_reward": 0.7972183266878128, "critic_loss": 0.23470663648843765, "actor_loss": -90.76780430603027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.792627334594727, "step": 103000}
{"episode_reward": 908.3980555629535, "episode": 104.0, "batch_reward": 0.8001563830375671, "critic_loss": 0.2313195589110255, "actor_loss": -91.12198738098145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.74256205558777, "step": 104000}
{"episode_reward": 960.6998258533274, "episode": 105.0, "batch_reward": 0.8008739477396012, "critic_loss": 0.21935274015367032, "actor_loss": -91.13502157592774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.80086350440979, "step": 105000}
{"episode_reward": 962.0556927308048, "episode": 106.0, "batch_reward": 0.8028482556343078, "critic_loss": 0.22107552409172057, "actor_loss": -91.06849754333496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.74876117706299, "step": 106000}
{"episode_reward": 967.3784725311399, "episode": 107.0, "batch_reward": 0.8035697521567344, "critic_loss": 0.2121466854289174, "actor_loss": -90.99679371643066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.746901035308838, "step": 107000}
{"episode_reward": 965.6902099868139, "episode": 108.0, "batch_reward": 0.8046567797064781, "critic_loss": 0.22772326447814703, "actor_loss": -90.44179832458497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.717012643814087, "step": 108000}
{"episode_reward": 957.3400610620764, "episode": 109.0, "batch_reward": 0.8084094187617302, "critic_loss": 0.24598339036107064, "actor_loss": -90.94308328247071, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.742653608322144, "step": 109000}
{"episode_reward": 825.154977347564, "episode": 110.0, "batch_reward": 0.8080395605564118, "critic_loss": 0.24162023435533048, "actor_loss": -90.30142274475098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.750444889068604, "step": 110000}
{"episode_reward": 916.5871848694029, "episode": 111.0, "batch_reward": 0.8083124685883522, "critic_loss": 0.22637117295712234, "actor_loss": -90.67411364746094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.354759216308594, "step": 111000}
{"episode_reward": 964.6635581367068, "episode": 112.0, "batch_reward": 0.8085158572196961, "critic_loss": 0.252751302972436, "actor_loss": -90.44313137817383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.748992204666138, "step": 112000}
{"episode_reward": 968.5899926504278, "episode": 113.0, "batch_reward": 0.8133255296945572, "critic_loss": 0.22375371193885804, "actor_loss": -90.91262283325196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.731278657913208, "step": 113000}
{"episode_reward": 967.3709447935238, "episode": 114.0, "batch_reward": 0.8127861984372139, "critic_loss": 0.22831291134655476, "actor_loss": -90.54084985351562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.73617124557495, "step": 114000}
{"episode_reward": 956.1419470011717, "episode": 115.0, "batch_reward": 0.8138826209306717, "critic_loss": 0.2303323280289769, "actor_loss": -90.42239764404297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.7036452293396, "step": 115000}
{"episode_reward": 968.3211268677069, "episode": 116.0, "batch_reward": 0.8145773892402649, "critic_loss": 0.23095955935865642, "actor_loss": -90.51520980834961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.70979118347168, "step": 116000}
{"episode_reward": 976.8618683041192, "episode": 117.0, "batch_reward": 0.8185914632081985, "critic_loss": 0.2269683700054884, "actor_loss": -90.70077040100098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.670440912246704, "step": 117000}
{"episode_reward": 969.2632311791571, "episode": 118.0, "batch_reward": 0.8194742112159729, "critic_loss": 0.23165666148811578, "actor_loss": -90.70627352905274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.69387412071228, "step": 118000}
{"episode_reward": 967.5401729154381, "episode": 119.0, "batch_reward": 0.8176860338449479, "critic_loss": 0.2335704142898321, "actor_loss": -90.8194900970459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.641488313674927, "step": 119000}
{"episode_reward": 933.36095439307, "episode": 120.0, "batch_reward": 0.8201106671094894, "critic_loss": 0.243952727265656, "actor_loss": -90.83657366943359, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.663247108459473, "step": 120000}
{"episode_reward": 954.2915659071803, "episode": 121.0, "batch_reward": 0.8212304482460022, "critic_loss": 0.2206858651712537, "actor_loss": -90.91470341491699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.45587158203125, "step": 121000}
{"episode_reward": 938.2070569794092, "episode": 122.0, "batch_reward": 0.8214387187957763, "critic_loss": 0.2350607976987958, "actor_loss": -90.57238595581055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.76130986213684, "step": 122000}
{"episode_reward": 895.6534037051396, "episode": 123.0, "batch_reward": 0.8228292528986931, "critic_loss": 0.2379337709993124, "actor_loss": -90.59487030029297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.81740164756775, "step": 123000}
{"episode_reward": 963.278222711467, "episode": 124.0, "batch_reward": 0.8235223307013512, "critic_loss": 0.22188400303572417, "actor_loss": -90.4935870513916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.781917095184326, "step": 124000}
{"episode_reward": 953.9963461217045, "episode": 125.0, "batch_reward": 0.8235234471559525, "critic_loss": 0.2299796380698681, "actor_loss": -90.33846240234375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.800040245056152, "step": 125000}
{"episode_reward": 916.5729802748917, "episode": 126.0, "batch_reward": 0.8259888922572136, "critic_loss": 0.2426569844186306, "actor_loss": -90.45152955627441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.755397081375122, "step": 126000}
{"episode_reward": 977.1632087823835, "episode": 127.0, "batch_reward": 0.8269857789874077, "critic_loss": 0.2391860332712531, "actor_loss": -90.11850965881348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.807894229888916, "step": 127000}
{"episode_reward": 950.0196427105527, "episode": 128.0, "batch_reward": 0.8285074905753136, "critic_loss": 0.27906368935853243, "actor_loss": -90.44104821777344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.740144729614258, "step": 128000}
{"episode_reward": 960.0920924482366, "episode": 129.0, "batch_reward": 0.8292585702538491, "critic_loss": 0.2295523215122521, "actor_loss": -90.43813980102539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.795739889144897, "step": 129000}
{"episode_reward": 981.1106249549975, "episode": 130.0, "batch_reward": 0.8292950002551078, "critic_loss": 0.25964103657752274, "actor_loss": -90.37292768859864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.733060598373413, "step": 130000}
{"episode_reward": 909.5123681508269, "episode": 131.0, "batch_reward": 0.8316437516212464, "critic_loss": 0.22938130397349596, "actor_loss": -90.70224375915528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.41507291793823, "step": 131000}
{"episode_reward": 955.3176096978896, "episode": 132.0, "batch_reward": 0.8320444353818893, "critic_loss": 0.2392742598131299, "actor_loss": -90.54364743041992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.746797800064087, "step": 132000}
{"episode_reward": 894.2645032261333, "episode": 133.0, "batch_reward": 0.83306181037426, "critic_loss": 0.24452928885817526, "actor_loss": -90.80644841003418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.82195544242859, "step": 133000}
{"episode_reward": 972.9502354732201, "episode": 134.0, "batch_reward": 0.8324550856351852, "critic_loss": 0.24112094306200743, "actor_loss": -90.50925552368165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.776617765426636, "step": 134000}
{"episode_reward": 964.8276018651727, "episode": 135.0, "batch_reward": 0.8330223498344421, "critic_loss": 0.2593118812665343, "actor_loss": -90.24042677307129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.756165027618408, "step": 135000}
{"episode_reward": 914.6828055972587, "episode": 136.0, "batch_reward": 0.8359613117575645, "critic_loss": 0.24958656944334506, "actor_loss": -90.52741239929199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.791582345962524, "step": 136000}
{"episode_reward": 885.8709669602335, "episode": 137.0, "batch_reward": 0.8362751652598381, "critic_loss": 0.23417879935353994, "actor_loss": -90.27719277954101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.728561639785767, "step": 137000}
{"episode_reward": 917.2473282136925, "episode": 138.0, "batch_reward": 0.8354557256698608, "critic_loss": 0.22927187967300416, "actor_loss": -90.28953057861328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.745582818984985, "step": 138000}
{"episode_reward": 976.9194761723832, "episode": 139.0, "batch_reward": 0.8369501436948776, "critic_loss": 0.24169305381923914, "actor_loss": -90.43968190002441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.69948410987854, "step": 139000}
{"episode_reward": 923.3208373190321, "episode": 140.0, "batch_reward": 0.8373646110892295, "critic_loss": 0.23939202216267585, "actor_loss": -90.43375349426269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.756706476211548, "step": 140000}
{"episode_reward": 971.603688006972, "episode": 141.0, "batch_reward": 0.8401219789981842, "critic_loss": 0.2141698070988059, "actor_loss": -90.26338832092286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.37376093864441, "step": 141000}
{"episode_reward": 945.1532691711096, "episode": 142.0, "batch_reward": 0.841326246380806, "critic_loss": 0.22685243756324053, "actor_loss": -90.38016003417968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.739378452301025, "step": 142000}
{"episode_reward": 965.6713640666643, "episode": 143.0, "batch_reward": 0.8389588966965675, "critic_loss": 0.23636352603882552, "actor_loss": -90.31609815979004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.75073790550232, "step": 143000}
{"episode_reward": 939.6790916811199, "episode": 144.0, "batch_reward": 0.8406676421761513, "critic_loss": 0.2323969268128276, "actor_loss": -90.28104421997071, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.713855981826782, "step": 144000}
{"episode_reward": 935.8584835794059, "episode": 145.0, "batch_reward": 0.8423043667674065, "critic_loss": 0.24736820515990257, "actor_loss": -90.31186325073242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.73241114616394, "step": 145000}
{"episode_reward": 948.7937519315407, "episode": 146.0, "batch_reward": 0.8410793152451516, "critic_loss": 0.23754709739983082, "actor_loss": -90.3617043762207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.70666766166687, "step": 146000}
{"episode_reward": 957.0785839181796, "episode": 147.0, "batch_reward": 0.8408167338371277, "critic_loss": 0.22539746559411286, "actor_loss": -90.31528117370605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.711618900299072, "step": 147000}
{"episode_reward": 928.0220994795143, "episode": 148.0, "batch_reward": 0.8428132004141807, "critic_loss": 0.2277780447974801, "actor_loss": -90.3220072631836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.87919330596924, "step": 148000}
{"episode_reward": 915.8484964922428, "episode": 149.0, "batch_reward": 0.8440020911693573, "critic_loss": 0.236601720161736, "actor_loss": -90.60282647705078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.68436598777771, "step": 149000}
{"episode_reward": 899.4813403532153, "episode": 150.0, "batch_reward": 0.8444200859069825, "critic_loss": 0.24363813964277506, "actor_loss": -90.142371383667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
