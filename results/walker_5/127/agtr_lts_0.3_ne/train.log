{"episode_reward": 0.0, "episode": 1.0, "duration": 20.658924102783203, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.7994723320007324, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.4607101015326737, "critic_loss": 0.3217139075963288, "actor_loss": -78.83374149830831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.090635776519775, "step": 3000}
{"episode_reward": 875.5239061677319, "episode": 4.0, "batch_reward": 0.6248716117441654, "critic_loss": 0.42027900925278666, "actor_loss": -85.76279716491699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.401474952697754, "step": 4000}
{"episode_reward": 922.3734522065055, "episode": 5.0, "batch_reward": 0.6681759480237961, "critic_loss": 0.523315101981163, "actor_loss": -87.93029243469238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.714205026626587, "step": 5000}
{"episode_reward": 794.3780618658321, "episode": 6.0, "batch_reward": 0.6343712534308433, "critic_loss": 0.5336944606006145, "actor_loss": -88.14651905822754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.435644388198853, "step": 6000}
{"episode_reward": 31.185066465845363, "episode": 7.0, "batch_reward": 0.6084364144802094, "critic_loss": 0.4363620014935732, "actor_loss": -88.40878268432617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.383358240127563, "step": 7000}
{"episode_reward": 941.9064206447092, "episode": 8.0, "batch_reward": 0.6509650668501854, "critic_loss": 0.32976408514380456, "actor_loss": -88.71747579956055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.366642475128174, "step": 8000}
{"episode_reward": 926.7869270929685, "episode": 9.0, "batch_reward": 0.6858484414815903, "critic_loss": 0.27622160224616527, "actor_loss": -89.18306211853027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.359832525253296, "step": 9000}
{"episode_reward": 958.3364364483664, "episode": 10.0, "batch_reward": 0.6718917045593261, "critic_loss": 0.3204628589898348, "actor_loss": -88.79568365478515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.41192650794983, "step": 10000}
{"episode_reward": 66.49869439891957, "episode": 11.0, "batch_reward": 0.6114071958661079, "critic_loss": 0.32695399019122123, "actor_loss": -87.42483848571777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.76548385620117, "step": 11000}
{"episode_reward": 31.28288967673817, "episode": 12.0, "batch_reward": 0.597275727391243, "critic_loss": 0.29136797703802586, "actor_loss": -86.79109327697753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.362070322036743, "step": 12000}
{"episode_reward": 953.7607676334496, "episode": 13.0, "batch_reward": 0.6230638986825943, "critic_loss": 0.2694778950363398, "actor_loss": -87.33760327148437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.390015602111816, "step": 13000}
{"episode_reward": 811.0996255078285, "episode": 14.0, "batch_reward": 0.630030464887619, "critic_loss": 0.2812312236130238, "actor_loss": -86.65550018310547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36592984199524, "step": 14000}
{"episode_reward": 791.5850866650402, "episode": 15.0, "batch_reward": 0.6466110757589341, "critic_loss": 0.2643792036473751, "actor_loss": -86.55486613464356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.372632265090942, "step": 15000}
{"episode_reward": 886.741705962389, "episode": 16.0, "batch_reward": 0.6645461715459824, "critic_loss": 0.20381368585675955, "actor_loss": -86.51711352539063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38489532470703, "step": 16000}
{"episode_reward": 929.6162490698713, "episode": 17.0, "batch_reward": 0.6779392756819725, "critic_loss": 0.23523947744071483, "actor_loss": -86.54031652832032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.42001247406006, "step": 17000}
{"episode_reward": 864.5922999268313, "episode": 18.0, "batch_reward": 0.6923556461334228, "critic_loss": 0.2414651766717434, "actor_loss": -86.69210235595703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.395247220993042, "step": 18000}
{"episode_reward": 908.431912618507, "episode": 19.0, "batch_reward": 0.702560937166214, "critic_loss": 0.2276058969721198, "actor_loss": -87.09167102050782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.400596857070923, "step": 19000}
{"episode_reward": 938.2584813757176, "episode": 20.0, "batch_reward": 0.7154595392346382, "critic_loss": 0.24138431026786566, "actor_loss": -87.31404588317871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.372655391693115, "step": 20000}
{"episode_reward": 922.6128299817967, "episode": 21.0, "batch_reward": 0.7264110940098762, "critic_loss": 0.23904757790267467, "actor_loss": -87.83585417175293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.7634642124176, "step": 21000}
{"episode_reward": 910.238050913161, "episode": 22.0, "batch_reward": 0.7345248945355415, "critic_loss": 0.20997159522026776, "actor_loss": -87.67643461608887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35647940635681, "step": 22000}
{"episode_reward": 953.2636320997601, "episode": 23.0, "batch_reward": 0.7431674060821534, "critic_loss": 0.2251426280066371, "actor_loss": -88.4443035736084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.379090070724487, "step": 23000}
{"episode_reward": 899.8300752401251, "episode": 24.0, "batch_reward": 0.748680466413498, "critic_loss": 0.2099409525245428, "actor_loss": -88.43161099243164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35270667076111, "step": 24000}
{"episode_reward": 898.9858541907086, "episode": 25.0, "batch_reward": 0.7557622817158699, "critic_loss": 0.22901786609739067, "actor_loss": -88.71104554748536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.380587816238403, "step": 25000}
{"episode_reward": 890.1818805258548, "episode": 26.0, "batch_reward": 0.7630364897847176, "critic_loss": 0.2146771103143692, "actor_loss": -88.83391441345215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.379518508911133, "step": 26000}
{"episode_reward": 957.3419594319929, "episode": 27.0, "batch_reward": 0.7692584038376808, "critic_loss": 0.192985803745687, "actor_loss": -88.92503828430176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.407644033432007, "step": 27000}
{"episode_reward": 968.8739792578264, "episode": 28.0, "batch_reward": 0.7774525564312935, "critic_loss": 0.19635978938639165, "actor_loss": -88.56893408203125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39844274520874, "step": 28000}
{"episode_reward": 950.9228548095665, "episode": 29.0, "batch_reward": 0.7821031909584999, "critic_loss": 0.20772190820425748, "actor_loss": -88.88009185791016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.40886688232422, "step": 29000}
{"episode_reward": 918.377725038346, "episode": 30.0, "batch_reward": 0.7879166268110275, "critic_loss": 0.20788441179692746, "actor_loss": -89.06079374694824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.330421209335327, "step": 30000}
{"episode_reward": 896.7380983985994, "episode": 31.0, "batch_reward": 0.7922927008271218, "critic_loss": 0.19732311640679837, "actor_loss": -88.96410629272461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.714420795440674, "step": 31000}
{"episode_reward": 935.6548840629988, "episode": 32.0, "batch_reward": 0.7928632534742356, "critic_loss": 0.22647524486482143, "actor_loss": -88.72440544128418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3631854057312, "step": 32000}
{"episode_reward": 861.8899459801296, "episode": 33.0, "batch_reward": 0.7974002322554589, "critic_loss": 0.21381387174874544, "actor_loss": -88.64583869934081, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.367878437042236, "step": 33000}
{"episode_reward": 879.0716916196717, "episode": 34.0, "batch_reward": 0.8013428170084953, "critic_loss": 0.18743431387096643, "actor_loss": -89.25023686218262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.380723476409912, "step": 34000}
{"episode_reward": 944.08123593265, "episode": 35.0, "batch_reward": 0.8036537429094315, "critic_loss": 0.20089124456048013, "actor_loss": -88.8377522125244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34259867668152, "step": 35000}
{"episode_reward": 890.7781468268084, "episode": 36.0, "batch_reward": 0.8064152539372444, "critic_loss": 0.2042733118236065, "actor_loss": -88.89939474487305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.372174501419067, "step": 36000}
{"episode_reward": 893.9563895667667, "episode": 37.0, "batch_reward": 0.8103080217242241, "critic_loss": 0.1846417613774538, "actor_loss": -89.15542701721192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.382827043533325, "step": 37000}
{"episode_reward": 960.0434278967087, "episode": 38.0, "batch_reward": 0.811799723982811, "critic_loss": 0.1900106938481331, "actor_loss": -89.18846183776856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34901237487793, "step": 38000}
{"episode_reward": 920.3042385519022, "episode": 39.0, "batch_reward": 0.8146680510640144, "critic_loss": 0.20335932510346175, "actor_loss": -89.13395101928711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33744168281555, "step": 39000}
{"episode_reward": 897.5756105781204, "episode": 40.0, "batch_reward": 0.8190236343145371, "critic_loss": 0.18900600139796733, "actor_loss": -89.5283949584961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.400312900543213, "step": 40000}
{"episode_reward": 970.4189248663446, "episode": 41.0, "batch_reward": 0.8214193099737167, "critic_loss": 0.18749832606315614, "actor_loss": -89.69283515930175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.78726124763489, "step": 41000}
{"episode_reward": 957.4294153642904, "episode": 42.0, "batch_reward": 0.8254596318602562, "critic_loss": 0.19713898650556802, "actor_loss": -89.51875723266602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.379857301712036, "step": 42000}
{"episode_reward": 948.5821386868435, "episode": 43.0, "batch_reward": 0.8281356352567673, "critic_loss": 0.181366173915565, "actor_loss": -89.66517700195313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38100814819336, "step": 43000}
{"episode_reward": 966.1933891362306, "episode": 44.0, "batch_reward": 0.830274034678936, "critic_loss": 0.18444055911898613, "actor_loss": -89.51945645141602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38487410545349, "step": 44000}
{"episode_reward": 962.1066589994765, "episode": 45.0, "batch_reward": 0.8348172572255135, "critic_loss": 0.192233710616827, "actor_loss": -89.7385971069336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.410784244537354, "step": 45000}
{"episode_reward": 968.0193395351205, "episode": 46.0, "batch_reward": 0.8361414933204651, "critic_loss": 0.16502537743747234, "actor_loss": -90.02154243469238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.392914295196533, "step": 46000}
{"episode_reward": 964.9067343471165, "episode": 47.0, "batch_reward": 0.8403696850538254, "critic_loss": 0.16983724649995566, "actor_loss": -90.09045335388184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.403993606567383, "step": 47000}
{"episode_reward": 949.8739990833229, "episode": 48.0, "batch_reward": 0.8416144453287124, "critic_loss": 0.16547724018990995, "actor_loss": -90.18243771362305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39118194580078, "step": 48000}
{"episode_reward": 919.8373887147329, "episode": 49.0, "batch_reward": 0.8434720239043236, "critic_loss": 0.16199039642512797, "actor_loss": -89.99822113037109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.363085508346558, "step": 49000}
{"episode_reward": 955.8865713648993, "episode": 50.0, "batch_reward": 0.8468352403044701, "critic_loss": 0.1518351021334529, "actor_loss": -90.2501863861084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.370187044143677, "step": 50000}
{"episode_reward": 968.1749781033752, "episode": 51.0, "batch_reward": 0.8496158936619759, "critic_loss": 0.16159059622138738, "actor_loss": -90.426740234375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.80221128463745, "step": 51000}
{"episode_reward": 933.6372539647242, "episode": 52.0, "batch_reward": 0.851592409491539, "critic_loss": 0.16630608794093132, "actor_loss": -90.6322146911621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.40934944152832, "step": 52000}
{"episode_reward": 939.0355108863876, "episode": 53.0, "batch_reward": 0.8519554899930954, "critic_loss": 0.15413790062069893, "actor_loss": -90.36510311889649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.410767078399658, "step": 53000}
{"episode_reward": 957.3952698894201, "episode": 54.0, "batch_reward": 0.8550229020118714, "critic_loss": 0.14808297131210565, "actor_loss": -90.51325546264648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.41990065574646, "step": 54000}
{"episode_reward": 968.8073113776159, "episode": 55.0, "batch_reward": 0.8542486003637314, "critic_loss": 0.16206682516634463, "actor_loss": -90.4107976989746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.426510334014893, "step": 55000}
{"episode_reward": 873.3317102533321, "episode": 56.0, "batch_reward": 0.8550685306191445, "critic_loss": 0.1546607701331377, "actor_loss": -90.59197801208497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.369304895401, "step": 56000}
{"episode_reward": 958.3234617111938, "episode": 57.0, "batch_reward": 0.858557117819786, "critic_loss": 0.1574842454493046, "actor_loss": -90.50605551147461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.379077196121216, "step": 57000}
{"episode_reward": 932.6930610946547, "episode": 58.0, "batch_reward": 0.8585837275981903, "critic_loss": 0.15578774401545525, "actor_loss": -90.45006036376954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.368804216384888, "step": 58000}
{"episode_reward": 919.3530456494317, "episode": 59.0, "batch_reward": 0.8614536128044128, "critic_loss": 0.16528836973011493, "actor_loss": -90.73483634948731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.376856803894043, "step": 59000}
{"episode_reward": 966.5847546367763, "episode": 60.0, "batch_reward": 0.8611701779961586, "critic_loss": 0.15653882743418215, "actor_loss": -90.62945794677735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36517333984375, "step": 60000}
{"episode_reward": 954.4760855733812, "episode": 61.0, "batch_reward": 0.8646199398040771, "critic_loss": 0.1539459246173501, "actor_loss": -90.84304446411133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.79050278663635, "step": 61000}
{"episode_reward": 919.7036460333677, "episode": 62.0, "batch_reward": 0.8649285706877708, "critic_loss": 0.15699307537078858, "actor_loss": -90.63871597290039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.40587282180786, "step": 62000}
{"episode_reward": 945.5800728020889, "episode": 63.0, "batch_reward": 0.8654794172048569, "critic_loss": 0.15265313363075256, "actor_loss": -91.08127941894531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.428475618362427, "step": 63000}
{"episode_reward": 951.2867913014705, "episode": 64.0, "batch_reward": 0.8667829067111016, "critic_loss": 0.14984164918959142, "actor_loss": -90.84483712768555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.42863392829895, "step": 64000}
{"episode_reward": 934.1963741544001, "episode": 65.0, "batch_reward": 0.868386009812355, "critic_loss": 0.14516222806274892, "actor_loss": -90.94038578796386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.370669841766357, "step": 65000}
{"episode_reward": 969.6389377358452, "episode": 66.0, "batch_reward": 0.8681570113897323, "critic_loss": 0.16257474564388394, "actor_loss": -90.88454411315918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.396810293197632, "step": 66000}
{"episode_reward": 884.8139883449278, "episode": 67.0, "batch_reward": 0.8689257326126099, "critic_loss": 0.15966767049580813, "actor_loss": -90.60262413024903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.366347312927246, "step": 67000}
{"episode_reward": 875.5408813935652, "episode": 68.0, "batch_reward": 0.8698620930314064, "critic_loss": 0.1688378984928131, "actor_loss": -90.79874884033202, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.394531726837158, "step": 68000}
{"episode_reward": 899.1393066831372, "episode": 69.0, "batch_reward": 0.8684070385098457, "critic_loss": 0.16814118304103612, "actor_loss": -91.13569641113281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38820505142212, "step": 69000}
{"episode_reward": 897.5089319227495, "episode": 70.0, "batch_reward": 0.8708848028182984, "critic_loss": 0.1606215291582048, "actor_loss": -90.79115856933593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.389849424362183, "step": 70000}
{"episode_reward": 929.9014823055844, "episode": 71.0, "batch_reward": 0.8709528785347939, "critic_loss": 0.15848097074776887, "actor_loss": -90.8487589263916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.74693584442139, "step": 71000}
{"episode_reward": 920.5095470980846, "episode": 72.0, "batch_reward": 0.8715887046456336, "critic_loss": 0.156852458961308, "actor_loss": -91.0911171875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.400511503219604, "step": 72000}
{"episode_reward": 947.3975209118418, "episode": 73.0, "batch_reward": 0.8738746560811996, "critic_loss": 0.17100737483054398, "actor_loss": -91.03580328369141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.402682542800903, "step": 73000}
{"episode_reward": 936.3252349382414, "episode": 74.0, "batch_reward": 0.8736084177494049, "critic_loss": 0.15490422055125236, "actor_loss": -90.93246774291993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38700795173645, "step": 74000}
{"episode_reward": 964.4056634369201, "episode": 75.0, "batch_reward": 0.8745720225572586, "critic_loss": 0.1592579919323325, "actor_loss": -91.19382373046875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.376299142837524, "step": 75000}
{"episode_reward": 897.8648787874118, "episode": 76.0, "batch_reward": 0.874044528901577, "critic_loss": 0.1746624922528863, "actor_loss": -91.02225148010254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36766242980957, "step": 76000}
{"episode_reward": 754.7285343930882, "episode": 77.0, "batch_reward": 0.871780009508133, "critic_loss": 0.18340356797724963, "actor_loss": -90.84274143981933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39966058731079, "step": 77000}
{"episode_reward": 850.562352113626, "episode": 78.0, "batch_reward": 0.8750532159805298, "critic_loss": 0.1753585586696863, "actor_loss": -90.89274626159668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.393932104110718, "step": 78000}
{"episode_reward": 965.7229591686807, "episode": 79.0, "batch_reward": 0.8758726931214332, "critic_loss": 0.18030677419155836, "actor_loss": -90.74500875854493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.382066249847412, "step": 79000}
{"episode_reward": 941.3617372877493, "episode": 80.0, "batch_reward": 0.8761269915103912, "critic_loss": 0.17672325255721807, "actor_loss": -90.65007167053223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.40717387199402, "step": 80000}
{"episode_reward": 961.5655783086942, "episode": 81.0, "batch_reward": 0.8782765282988548, "critic_loss": 0.1809418107122183, "actor_loss": -90.71873336791992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.80907320976257, "step": 81000}
{"episode_reward": 939.2302878106904, "episode": 82.0, "batch_reward": 0.8768374040722847, "critic_loss": 0.1895554627329111, "actor_loss": -91.01016014099122, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.379738569259644, "step": 82000}
{"episode_reward": 937.0260261798646, "episode": 83.0, "batch_reward": 0.8790494675040245, "critic_loss": 0.17803763863444327, "actor_loss": -90.66721264648437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37140464782715, "step": 83000}
{"episode_reward": 955.3507339983146, "episode": 84.0, "batch_reward": 0.8789263516664505, "critic_loss": 0.20749847922846676, "actor_loss": -90.97749327087402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.379071950912476, "step": 84000}
{"episode_reward": 915.5390620516903, "episode": 85.0, "batch_reward": 0.8783814994692802, "critic_loss": 0.20357976169511677, "actor_loss": -90.89595318603516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.703668117523193, "step": 85000}
{"episode_reward": 922.2036237332778, "episode": 86.0, "batch_reward": 0.880462894141674, "critic_loss": 0.19299350233003498, "actor_loss": -90.94826422119141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.405823707580566, "step": 86000}
{"episode_reward": 950.7714221396432, "episode": 87.0, "batch_reward": 0.8826506248116494, "critic_loss": 0.18164314797520636, "actor_loss": -90.75584884643554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36994218826294, "step": 87000}
{"episode_reward": 970.1024507741238, "episode": 88.0, "batch_reward": 0.8815567510128022, "critic_loss": 0.19677741373330354, "actor_loss": -91.13200659179688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.358131647109985, "step": 88000}
{"episode_reward": 923.105373108319, "episode": 89.0, "batch_reward": 0.8821781144738198, "critic_loss": 0.17761040452867746, "actor_loss": -91.18040832519532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.377527952194214, "step": 89000}
{"episode_reward": 911.3699407931075, "episode": 90.0, "batch_reward": 0.8836312758922577, "critic_loss": 0.21864239111542702, "actor_loss": -91.146476272583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.361377477645874, "step": 90000}
{"episode_reward": 873.512755283667, "episode": 91.0, "batch_reward": 0.8837761041522026, "critic_loss": 0.19739532915502786, "actor_loss": -91.3670535888672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.768810510635376, "step": 91000}
{"episode_reward": 969.1808432508479, "episode": 92.0, "batch_reward": 0.8834645168185234, "critic_loss": 0.1923108934350312, "actor_loss": -91.21998570251465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.416100025177002, "step": 92000}
{"episode_reward": 894.4845681102835, "episode": 93.0, "batch_reward": 0.8830490971207619, "critic_loss": 0.177411595210433, "actor_loss": -91.43188307189942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.410507440567017, "step": 93000}
{"episode_reward": 960.195053527182, "episode": 94.0, "batch_reward": 0.8842863059043884, "critic_loss": 0.23548643197864294, "actor_loss": -91.47707594299317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.43275022506714, "step": 94000}
{"episode_reward": 899.6735897847051, "episode": 95.0, "batch_reward": 0.8841874356865883, "critic_loss": 0.19748601833730936, "actor_loss": -91.0659084777832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.418833017349243, "step": 95000}
{"episode_reward": 876.2233396424333, "episode": 96.0, "batch_reward": 0.8847505598664284, "critic_loss": 0.19577964759245514, "actor_loss": -91.43230589294434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.423176765441895, "step": 96000}
{"episode_reward": 939.4822635995539, "episode": 97.0, "batch_reward": 0.8846777874827385, "critic_loss": 0.21279402578622103, "actor_loss": -91.27800190734864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.399369955062866, "step": 97000}
{"episode_reward": 966.5056470096057, "episode": 98.0, "batch_reward": 0.8868129792213439, "critic_loss": 0.17806538313627243, "actor_loss": -90.9505258178711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.387775182724, "step": 98000}
{"episode_reward": 957.3144310037153, "episode": 99.0, "batch_reward": 0.8868608484268189, "critic_loss": 0.1762942061200738, "actor_loss": -91.23833215332031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.401105165481567, "step": 99000}
{"episode_reward": 949.6257009970686, "episode": 100.0, "batch_reward": 0.886762564599514, "critic_loss": 0.21040043327957392, "actor_loss": -91.14126011657714, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.41706943511963, "step": 100000}
{"episode_reward": 967.2321281548652, "episode": 101.0, "batch_reward": 0.8887250264883041, "critic_loss": 0.19554612095654011, "actor_loss": -91.5037392425537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.198890209198, "step": 101000}
{"episode_reward": 953.9734981129741, "episode": 102.0, "batch_reward": 0.889807187139988, "critic_loss": 0.19736601495742798, "actor_loss": -91.1442374572754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.394108772277832, "step": 102000}
{"episode_reward": 969.3534128923211, "episode": 103.0, "batch_reward": 0.8889382393956184, "critic_loss": 0.1990968699529767, "actor_loss": -91.21189093017578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.387437343597412, "step": 103000}
{"episode_reward": 954.1583920152336, "episode": 104.0, "batch_reward": 0.8909446994662285, "critic_loss": 0.1915523855239153, "actor_loss": -91.47813247680664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.379424810409546, "step": 104000}
{"episode_reward": 962.8739039085717, "episode": 105.0, "batch_reward": 0.8916648657917976, "critic_loss": 0.1793818359710276, "actor_loss": -91.53324691772461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38880181312561, "step": 105000}
{"episode_reward": 923.1944620079597, "episode": 106.0, "batch_reward": 0.891195783674717, "critic_loss": 0.17462224400043488, "actor_loss": -91.53021305847167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.42105007171631, "step": 106000}
{"episode_reward": 969.9481130129358, "episode": 107.0, "batch_reward": 0.8917006742358208, "critic_loss": 0.19654842451959847, "actor_loss": -91.58237796020508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.416297435760498, "step": 107000}
{"episode_reward": 963.584137166825, "episode": 108.0, "batch_reward": 0.8919493386745453, "critic_loss": 0.18809492269158362, "actor_loss": -91.25583888244628, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37648916244507, "step": 108000}
{"episode_reward": 956.1544119355925, "episode": 109.0, "batch_reward": 0.8944606098532677, "critic_loss": 0.1696441141627729, "actor_loss": -91.66380476379395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.402141571044922, "step": 109000}
{"episode_reward": 919.7264912240298, "episode": 110.0, "batch_reward": 0.8936550740003586, "critic_loss": 0.16856868386268617, "actor_loss": -91.22996612548827, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.405641317367554, "step": 110000}
{"episode_reward": 920.2735989267743, "episode": 111.0, "batch_reward": 0.8934877285957337, "critic_loss": 0.1757660782970488, "actor_loss": -91.52367317199707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.842673778533936, "step": 111000}
{"episode_reward": 950.6224763059704, "episode": 112.0, "batch_reward": 0.8937930132746696, "critic_loss": 0.18067014826089145, "actor_loss": -91.37733622741699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.41323971748352, "step": 112000}
{"episode_reward": 951.5608771884226, "episode": 113.0, "batch_reward": 0.8960542696118354, "critic_loss": 0.17146236050873995, "actor_loss": -91.67815773010254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.430763959884644, "step": 113000}
{"episode_reward": 973.6198566025605, "episode": 114.0, "batch_reward": 0.896122107565403, "critic_loss": 0.18447477847710253, "actor_loss": -91.5244953918457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.420891761779785, "step": 114000}
{"episode_reward": 944.3861155944047, "episode": 115.0, "batch_reward": 0.8961143845319748, "critic_loss": 0.1785020322650671, "actor_loss": -91.49834945678711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.384891986846924, "step": 115000}
{"episode_reward": 967.7026252114642, "episode": 116.0, "batch_reward": 0.897408482849598, "critic_loss": 0.18097313749417662, "actor_loss": -91.5955245666504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.367435693740845, "step": 116000}
{"episode_reward": 976.2921881093038, "episode": 117.0, "batch_reward": 0.8981897110939026, "critic_loss": 0.1706547471433878, "actor_loss": -91.77487355041504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39931869506836, "step": 117000}
{"episode_reward": 969.0677762980838, "episode": 118.0, "batch_reward": 0.8977205289602279, "critic_loss": 0.18325747260823846, "actor_loss": -91.8221567993164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.410909414291382, "step": 118000}
{"episode_reward": 888.8345564494498, "episode": 119.0, "batch_reward": 0.8987515975236893, "critic_loss": 0.1957306448817253, "actor_loss": -91.92866104125977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.44001293182373, "step": 119000}
{"episode_reward": 940.6506823964938, "episode": 120.0, "batch_reward": 0.898697130382061, "critic_loss": 0.17828664423525334, "actor_loss": -91.88168156433106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.436213731765747, "step": 120000}
{"episode_reward": 963.8515046961903, "episode": 121.0, "batch_reward": 0.8995012471079826, "critic_loss": 0.17265075905621052, "actor_loss": -91.90584716796874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.79653739929199, "step": 121000}
{"episode_reward": 950.7225916940184, "episode": 122.0, "batch_reward": 0.899561338365078, "critic_loss": 0.18766502601653337, "actor_loss": -91.69801887512207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3801589012146, "step": 122000}
{"episode_reward": 908.7986866302729, "episode": 123.0, "batch_reward": 0.899045313179493, "critic_loss": 0.17306301474571228, "actor_loss": -91.74942233276367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.405571699142456, "step": 123000}
{"episode_reward": 938.4326322166668, "episode": 124.0, "batch_reward": 0.8990620380043983, "critic_loss": 0.18136864288523794, "actor_loss": -91.73040390014648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.385521411895752, "step": 124000}
{"episode_reward": 959.798053560064, "episode": 125.0, "batch_reward": 0.8991674931645394, "critic_loss": 0.2567274452075362, "actor_loss": -91.65252754211426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.406532049179077, "step": 125000}
{"episode_reward": 946.472880963301, "episode": 126.0, "batch_reward": 0.8992917982935905, "critic_loss": 0.1747765146307647, "actor_loss": -91.65830754089356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.385563135147095, "step": 126000}
{"episode_reward": 955.9819375490808, "episode": 127.0, "batch_reward": 0.9001664226651191, "critic_loss": 0.18195146234706044, "actor_loss": -91.45678959655761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3891441822052, "step": 127000}
{"episode_reward": 941.6717599265232, "episode": 128.0, "batch_reward": 0.9014071729183197, "critic_loss": 0.1787382467277348, "actor_loss": -91.77509225463868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.376063585281372, "step": 128000}
{"episode_reward": 962.9241170283473, "episode": 129.0, "batch_reward": 0.9018982425928116, "critic_loss": 0.16497219656407833, "actor_loss": -91.79961903381347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.425859928131104, "step": 129000}
{"episode_reward": 959.6058401223239, "episode": 130.0, "batch_reward": 0.9022387210130691, "critic_loss": 0.17400235890224575, "actor_loss": -91.75178596496582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.423069953918457, "step": 130000}
{"episode_reward": 918.121010644211, "episode": 131.0, "batch_reward": 0.902218681037426, "critic_loss": 0.17678447509929537, "actor_loss": -91.94020356750488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.86670279502869, "step": 131000}
{"episode_reward": 950.3614036279233, "episode": 132.0, "batch_reward": 0.9026377758383751, "critic_loss": 0.18062956564873456, "actor_loss": -91.88567750549316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.441471099853516, "step": 132000}
{"episode_reward": 918.5451509609626, "episode": 133.0, "batch_reward": 0.9029973447918892, "critic_loss": 0.178990433357656, "actor_loss": -92.15812620544433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.436039209365845, "step": 133000}
{"episode_reward": 965.1860046775988, "episode": 134.0, "batch_reward": 0.9031863818764687, "critic_loss": 0.16319654269516468, "actor_loss": -91.87148808288575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.375890970230103, "step": 134000}
{"episode_reward": 955.3971727680305, "episode": 135.0, "batch_reward": 0.9016992006897926, "critic_loss": 0.1603218049965799, "actor_loss": -91.60010902404785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.370351314544678, "step": 135000}
{"episode_reward": 894.5621226962862, "episode": 136.0, "batch_reward": 0.9040496314167976, "critic_loss": 0.15534512647986412, "actor_loss": -91.85228504943848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.397433042526245, "step": 136000}
{"episode_reward": 914.6582333348701, "episode": 137.0, "batch_reward": 0.9039614052176476, "critic_loss": 0.16045560441911222, "actor_loss": -91.66935334777833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.41600251197815, "step": 137000}
{"episode_reward": 910.594453763502, "episode": 138.0, "batch_reward": 0.9038212705850601, "critic_loss": 0.16292998738586903, "actor_loss": -91.75196459960938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.41607165336609, "step": 138000}
{"episode_reward": 967.0969500430788, "episode": 139.0, "batch_reward": 0.9032108060717583, "critic_loss": 0.15667516801133752, "actor_loss": -91.86881694030761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.432501316070557, "step": 139000}
{"episode_reward": 904.3476981293807, "episode": 140.0, "batch_reward": 0.9031184245347976, "critic_loss": 0.1654940092638135, "actor_loss": -91.94113970947265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.422878742218018, "step": 140000}
{"episode_reward": 919.8107844878225, "episode": 141.0, "batch_reward": 0.9060245284438133, "critic_loss": 0.1583231205418706, "actor_loss": -91.86878727722168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.80399250984192, "step": 141000}
{"episode_reward": 947.0141257398503, "episode": 142.0, "batch_reward": 0.9050763266682624, "critic_loss": 0.18039499854296445, "actor_loss": -91.89153112792968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.40746235847473, "step": 142000}
{"episode_reward": 962.5930194053863, "episode": 143.0, "batch_reward": 0.9047020983099937, "critic_loss": 0.1770599742345512, "actor_loss": -91.87696591186524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.40249228477478, "step": 143000}
{"episode_reward": 924.9870885086863, "episode": 144.0, "batch_reward": 0.9041922154426575, "critic_loss": 0.16529307068884372, "actor_loss": -91.7743570098877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.404332637786865, "step": 144000}
{"episode_reward": 948.3351780278849, "episode": 145.0, "batch_reward": 0.9075804355144501, "critic_loss": 0.17955384603142738, "actor_loss": -91.8605972290039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.395333528518677, "step": 145000}
{"episode_reward": 950.2804595740754, "episode": 146.0, "batch_reward": 0.904525356888771, "critic_loss": 0.16125187490880488, "actor_loss": -91.92468116760254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.446402311325073, "step": 146000}
{"episode_reward": 920.2726580707614, "episode": 147.0, "batch_reward": 0.9043283044099808, "critic_loss": 0.16533667273074387, "actor_loss": -91.87490805053712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38240647315979, "step": 147000}
{"episode_reward": 905.797569243758, "episode": 148.0, "batch_reward": 0.9055839393138886, "critic_loss": 0.18328378973901271, "actor_loss": -91.87308169555664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.368773937225342, "step": 148000}
{"episode_reward": 956.3112276285608, "episode": 149.0, "batch_reward": 0.9064658986330032, "critic_loss": 0.19046809504926204, "actor_loss": -92.09290133666993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35120177268982, "step": 149000}
{"episode_reward": 912.105888628996, "episode": 150.0, "batch_reward": 0.9061495761275291, "critic_loss": 0.18350547979772092, "actor_loss": -91.65320944213867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
