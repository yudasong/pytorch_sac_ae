{"episode_reward": 0.0, "episode": 1.0, "duration": 20.934805631637573, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.8714158535003662, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.42024613275413475, "critic_loss": 0.15579927655414527, "actor_loss": -34.41203673243919, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 61.5727379322052, "step": 3000}
{"episode_reward": 157.7764955626929, "episode": 4.0, "batch_reward": 0.35486066463589666, "critic_loss": 0.3845787575989962, "actor_loss": -34.15109315109253, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.65303683280945, "step": 4000}
{"episode_reward": 346.42738989004107, "episode": 5.0, "batch_reward": 0.31683091558516024, "critic_loss": 0.41298465541005136, "actor_loss": -34.5862627658844, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.925787687301636, "step": 5000}
{"episode_reward": 274.16651936435375, "episode": 6.0, "batch_reward": 0.32113628555834295, "critic_loss": 0.5449333844482899, "actor_loss": -37.910981649398806, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.312679767608643, "step": 6000}
{"episode_reward": 272.4799343164683, "episode": 7.0, "batch_reward": 0.3269584124833345, "critic_loss": 0.6729562607109547, "actor_loss": -37.985162103652954, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.694754600524902, "step": 7000}
{"episode_reward": 289.9234974997069, "episode": 8.0, "batch_reward": 0.32636282755434515, "critic_loss": 0.8428142904937267, "actor_loss": -41.31387593078613, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.675206899642944, "step": 8000}
{"episode_reward": 515.7567642648277, "episode": 9.0, "batch_reward": 0.3595824116766453, "critic_loss": 1.0185610871911048, "actor_loss": -44.31258525085449, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.752313375473022, "step": 9000}
{"episode_reward": 737.1673083862598, "episode": 10.0, "batch_reward": 0.40103626242280005, "critic_loss": 1.172778981924057, "actor_loss": -46.66480611801148, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.65712261199951, "step": 10000}
{"episode_reward": 806.6111946129215, "episode": 11.0, "batch_reward": 0.44154502284526825, "critic_loss": 1.2184039027690887, "actor_loss": -49.713807621002196, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.71818518638611, "step": 11000}
{"episode_reward": 752.2122235452059, "episode": 12.0, "batch_reward": 0.4705283187031746, "critic_loss": 1.1343713405132294, "actor_loss": -51.78120861053467, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.599305391311646, "step": 12000}
{"episode_reward": 866.8266110497921, "episode": 13.0, "batch_reward": 0.50615681630373, "critic_loss": 1.1413108156323433, "actor_loss": -52.907122024536136, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.432121515274048, "step": 13000}
{"episode_reward": 905.5545846818991, "episode": 14.0, "batch_reward": 0.5351963352560997, "critic_loss": 1.1169703938364983, "actor_loss": -56.3966714553833, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.883710384368896, "step": 14000}
{"episode_reward": 889.5719917786441, "episode": 15.0, "batch_reward": 0.5593321707844734, "critic_loss": 1.048030753493309, "actor_loss": -58.917326301574704, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.2798855304718, "step": 15000}
{"episode_reward": 862.6525623481024, "episode": 16.0, "batch_reward": 0.5785872382223606, "critic_loss": 0.9955010412931442, "actor_loss": -59.42435209655762, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.19204044342041, "step": 16000}
{"episode_reward": 930.537060820224, "episode": 17.0, "batch_reward": 0.60082296615839, "critic_loss": 0.9389571520090103, "actor_loss": -61.57526512908935, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.283628940582275, "step": 17000}
{"episode_reward": 891.8966260226239, "episode": 18.0, "batch_reward": 0.6136246865987778, "critic_loss": 0.8874667524695397, "actor_loss": -62.840907775878904, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.583919525146484, "step": 18000}
{"episode_reward": 873.2230996276706, "episode": 19.0, "batch_reward": 0.6286296576261521, "critic_loss": 0.9121751691401004, "actor_loss": -64.07608476257325, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.6973237991333, "step": 19000}
{"episode_reward": 861.6428698574541, "episode": 20.0, "batch_reward": 0.6404556202888488, "critic_loss": 0.820041921555996, "actor_loss": -65.45919594573975, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.620276927947998, "step": 20000}
{"episode_reward": 878.1632725372986, "episode": 21.0, "batch_reward": 0.6543243432641029, "critic_loss": 0.8161899255812168, "actor_loss": -65.58308112335204, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.64653253555298, "step": 21000}
{"episode_reward": 843.1456057845023, "episode": 22.0, "batch_reward": 0.6629323801398277, "critic_loss": 0.8338785184323788, "actor_loss": -68.17973916625976, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.8156099319458, "step": 22000}
{"episode_reward": 943.6485847316296, "episode": 23.0, "batch_reward": 0.6772660401463508, "critic_loss": 0.8286077084243297, "actor_loss": -68.27481430053712, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.665499210357666, "step": 23000}
{"episode_reward": 919.8443210598022, "episode": 24.0, "batch_reward": 0.6846554754376412, "critic_loss": 0.8665174734294414, "actor_loss": -69.06820964050293, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.27113652229309, "step": 24000}
{"episode_reward": 896.8419269271483, "episode": 25.0, "batch_reward": 0.6962618625164032, "critic_loss": 0.8486265714168548, "actor_loss": -69.95316255187988, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.74867868423462, "step": 25000}
{"episode_reward": 918.4068587117804, "episode": 26.0, "batch_reward": 0.703172902226448, "critic_loss": 0.791367451429367, "actor_loss": -70.31374633789062, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.699917554855347, "step": 26000}
{"episode_reward": 955.8019664865251, "episode": 27.0, "batch_reward": 0.7149205161929131, "critic_loss": 0.8512524186372757, "actor_loss": -71.0014077682495, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.365257501602173, "step": 27000}
{"episode_reward": 942.0570652460107, "episode": 28.0, "batch_reward": 0.7236975690126419, "critic_loss": 0.9824877899885177, "actor_loss": -72.9267053527832, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.988497495651245, "step": 28000}
{"episode_reward": 932.6725794271053, "episode": 29.0, "batch_reward": 0.7264670686125755, "critic_loss": 1.1563162156939506, "actor_loss": -73.3739192352295, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.54408025741577, "step": 29000}
{"episode_reward": 887.1305992386416, "episode": 30.0, "batch_reward": 0.7349085286855698, "critic_loss": 1.1891995083093643, "actor_loss": -73.72120199584961, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.295453548431396, "step": 30000}
{"episode_reward": 865.7358933728209, "episode": 31.0, "batch_reward": 0.7378503271341323, "critic_loss": 1.1803239051401615, "actor_loss": -74.84177658081055, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.71501660346985, "step": 31000}
{"episode_reward": 897.7723327689896, "episode": 32.0, "batch_reward": 0.7435141057372093, "critic_loss": 1.2017148617208004, "actor_loss": -75.4361781616211, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.334517002105713, "step": 32000}
{"episode_reward": 881.1519935219342, "episode": 33.0, "batch_reward": 0.7354852228164673, "critic_loss": 1.1777331775426865, "actor_loss": -75.71969502258301, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.283304929733276, "step": 33000}
{"episode_reward": 159.36714111595035, "episode": 34.0, "batch_reward": 0.7315102928876877, "critic_loss": 1.2781292293071747, "actor_loss": -75.5514344329834, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.290530681610107, "step": 34000}
{"episode_reward": 950.00626847214, "episode": 35.0, "batch_reward": 0.7362469522953033, "critic_loss": 1.16339406183362, "actor_loss": -76.39815684509277, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.02688241004944, "step": 35000}
{"episode_reward": 874.9367593054347, "episode": 36.0, "batch_reward": 0.7386059106588364, "critic_loss": 1.0163118653297425, "actor_loss": -76.83191935729981, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.223782777786255, "step": 36000}
{"episode_reward": 893.8893722323347, "episode": 37.0, "batch_reward": 0.747850367963314, "critic_loss": 0.8324174242019653, "actor_loss": -76.93860322570801, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.107462882995605, "step": 37000}
{"episode_reward": 946.104950175459, "episode": 38.0, "batch_reward": 0.7510540591478347, "critic_loss": 0.735672604739666, "actor_loss": -77.31624452209472, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.04716682434082, "step": 38000}
{"episode_reward": 961.3235190341575, "episode": 39.0, "batch_reward": 0.7574277641177177, "critic_loss": 0.7710809541344643, "actor_loss": -77.5287055053711, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.989357709884644, "step": 39000}
{"episode_reward": 953.3756820955502, "episode": 40.0, "batch_reward": 0.761353842318058, "critic_loss": 0.6673761691451072, "actor_loss": -77.76259133911132, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.97079825401306, "step": 40000}
{"episode_reward": 966.6259797106488, "episode": 41.0, "batch_reward": 0.7676938071846962, "critic_loss": 0.7126745285987854, "actor_loss": -77.6472925567627, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.42954206466675, "step": 41000}
{"episode_reward": 959.6513615456611, "episode": 42.0, "batch_reward": 0.7706636691093445, "critic_loss": 0.7075263130366802, "actor_loss": -78.49024287414551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.111690521240234, "step": 42000}
{"episode_reward": 887.7594724722128, "episode": 43.0, "batch_reward": 0.7725509214997291, "critic_loss": 0.6901369661986828, "actor_loss": -78.83145935058593, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.514893054962158, "step": 43000}
{"episode_reward": 958.4053651316568, "episode": 44.0, "batch_reward": 0.7781953727602958, "critic_loss": 0.6412746221125126, "actor_loss": -79.35248587036133, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.69299864768982, "step": 44000}
{"episode_reward": 974.3402799040822, "episode": 45.0, "batch_reward": 0.7815885083675385, "critic_loss": 0.654260270267725, "actor_loss": -79.69540974426269, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.906142234802246, "step": 45000}
{"episode_reward": 968.4250820720217, "episode": 46.0, "batch_reward": 0.7854235646128654, "critic_loss": 0.6251991370916367, "actor_loss": -79.70026344299316, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.74003553390503, "step": 46000}
{"episode_reward": 973.1148850289965, "episode": 47.0, "batch_reward": 0.7893191995024681, "critic_loss": 0.6729930352270603, "actor_loss": -80.1811537322998, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.825392484664917, "step": 47000}
{"episode_reward": 945.6239913380444, "episode": 48.0, "batch_reward": 0.7935192880034446, "critic_loss": 0.5950866743326187, "actor_loss": -80.6874115447998, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.770291328430176, "step": 48000}
{"episode_reward": 877.0008652430281, "episode": 49.0, "batch_reward": 0.7960969638228417, "critic_loss": 0.6280556488335133, "actor_loss": -80.97587959289551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.6536066532135, "step": 49000}
{"episode_reward": 971.193082223558, "episode": 50.0, "batch_reward": 0.7970876096487045, "critic_loss": 0.6313472599089146, "actor_loss": -81.00381030273438, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.76157259941101, "step": 50000}
{"episode_reward": 760.6986239006803, "episode": 51.0, "batch_reward": 0.7984022042751312, "critic_loss": 0.6317016400247812, "actor_loss": -81.14996533203124, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.53495192527771, "step": 51000}
{"episode_reward": 929.3236379307561, "episode": 52.0, "batch_reward": 0.8006849305033684, "critic_loss": 0.6230884101092815, "actor_loss": -81.38591305541992, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.254048347473145, "step": 52000}
{"episode_reward": 948.457534721065, "episode": 53.0, "batch_reward": 0.8027061466574669, "critic_loss": 0.6479528865516185, "actor_loss": -81.83614186096192, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.212573528289795, "step": 53000}
{"episode_reward": 935.6276071358129, "episode": 54.0, "batch_reward": 0.8073533009886742, "critic_loss": 0.617269934207201, "actor_loss": -82.05091264343261, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.933932781219482, "step": 54000}
{"episode_reward": 972.5974315629337, "episode": 55.0, "batch_reward": 0.8087610346078873, "critic_loss": 0.6332817553281784, "actor_loss": -82.27524630737305, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.218491077423096, "step": 55000}
{"episode_reward": 955.6133021828183, "episode": 56.0, "batch_reward": 0.8111382604241372, "critic_loss": 0.6194458564072848, "actor_loss": -82.47213386535644, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.64301323890686, "step": 56000}
{"episode_reward": 963.1807177398282, "episode": 57.0, "batch_reward": 0.8154150566458702, "critic_loss": 0.6192552937418222, "actor_loss": -82.79101066589355, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.90911054611206, "step": 57000}
{"episode_reward": 952.2693668351909, "episode": 58.0, "batch_reward": 0.815953476011753, "critic_loss": 0.6084745640158653, "actor_loss": -83.00585899353027, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.79042625427246, "step": 58000}
{"episode_reward": 958.3389051354767, "episode": 59.0, "batch_reward": 0.8190275344848633, "critic_loss": 0.5938148928582668, "actor_loss": -83.20276370239257, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.54071831703186, "step": 59000}
{"episode_reward": 975.8547488244783, "episode": 60.0, "batch_reward": 0.8220923284888267, "critic_loss": 0.6049575460255145, "actor_loss": -83.50745706176758, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.709192991256714, "step": 60000}
{"episode_reward": 974.8776675904995, "episode": 61.0, "batch_reward": 0.8225795547962189, "critic_loss": 0.5868802648931741, "actor_loss": -83.50381736755371, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.18582487106323, "step": 61000}
{"episode_reward": 870.7959916650801, "episode": 62.0, "batch_reward": 0.8255410393476487, "critic_loss": 0.6044604305624962, "actor_loss": -83.72461456298828, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.138386249542236, "step": 62000}
{"episode_reward": 945.6790800483502, "episode": 63.0, "batch_reward": 0.8288167310357094, "critic_loss": 0.5643698886930942, "actor_loss": -83.89405484008789, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.20439887046814, "step": 63000}
{"episode_reward": 971.3990232756009, "episode": 64.0, "batch_reward": 0.8288523092269897, "critic_loss": 0.5940632438063621, "actor_loss": -83.96064447021485, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.011385440826416, "step": 64000}
{"episode_reward": 928.7475960237668, "episode": 65.0, "batch_reward": 0.8326425302624703, "critic_loss": 0.563620116353035, "actor_loss": -84.14283763122559, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.552221059799194, "step": 65000}
{"episode_reward": 964.9716288729974, "episode": 66.0, "batch_reward": 0.8318756933808327, "critic_loss": 0.5646425804048777, "actor_loss": -84.20820536804199, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.606069326400757, "step": 66000}
{"episode_reward": 915.4771119317879, "episode": 67.0, "batch_reward": 0.8336446888446808, "critic_loss": 0.5892194614410401, "actor_loss": -84.31134466552734, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.691758394241333, "step": 67000}
{"episode_reward": 941.3607763308828, "episode": 68.0, "batch_reward": 0.8357315760850906, "critic_loss": 0.6028624761998653, "actor_loss": -84.42484184265136, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.38109254837036, "step": 68000}
{"episode_reward": 923.5595335581046, "episode": 69.0, "batch_reward": 0.8354704186320305, "critic_loss": 0.6267099019289016, "actor_loss": -84.5728173828125, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.216410398483276, "step": 69000}
{"episode_reward": 900.2205427614476, "episode": 70.0, "batch_reward": 0.8375592886805534, "critic_loss": 0.6169284465312957, "actor_loss": -84.64371377563477, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.416975259780884, "step": 70000}
{"episode_reward": 909.5632550459949, "episode": 71.0, "batch_reward": 0.8386718103885651, "critic_loss": 0.6457335039824247, "actor_loss": -84.78819059753418, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.35457253456116, "step": 71000}
{"episode_reward": 919.7053408524275, "episode": 72.0, "batch_reward": 0.8389464339613915, "critic_loss": 0.6315819740593434, "actor_loss": -84.9119853515625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.242417097091675, "step": 72000}
{"episode_reward": 955.3290825981832, "episode": 73.0, "batch_reward": 0.8418479498624801, "critic_loss": 0.6374555868506432, "actor_loss": -84.97477728271484, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.253827333450317, "step": 73000}
{"episode_reward": 953.912311042767, "episode": 74.0, "batch_reward": 0.8433881251811981, "critic_loss": 0.5783215355426073, "actor_loss": -85.07332154846192, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.840993881225586, "step": 74000}
{"episode_reward": 964.4278082249058, "episode": 75.0, "batch_reward": 0.8431183428168297, "critic_loss": 0.6081297880709171, "actor_loss": -85.13416340637207, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.36838722229004, "step": 75000}
{"episode_reward": 919.7535071543896, "episode": 76.0, "batch_reward": 0.8444879212975502, "critic_loss": 0.5823255793005228, "actor_loss": -85.19052923583985, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.511507511138916, "step": 76000}
{"episode_reward": 826.4827718757259, "episode": 77.0, "batch_reward": 0.8448632229566574, "critic_loss": 0.59348747394979, "actor_loss": -85.26778207397462, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.019587755203247, "step": 77000}
{"episode_reward": 886.1736816006793, "episode": 78.0, "batch_reward": 0.8459929382801056, "critic_loss": 0.5851420394033193, "actor_loss": -85.32117140197754, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.30516028404236, "step": 78000}
{"episode_reward": 978.4697020603836, "episode": 79.0, "batch_reward": 0.8467227802276611, "critic_loss": 0.5734351324141026, "actor_loss": -85.40898219299316, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.709197998046875, "step": 79000}
{"episode_reward": 938.0272910865538, "episode": 80.0, "batch_reward": 0.8487690304517745, "critic_loss": 0.5495552830845117, "actor_loss": -85.48731639099121, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.004045009613037, "step": 80000}
{"episode_reward": 961.1971247138468, "episode": 81.0, "batch_reward": 0.8512049344182014, "critic_loss": 0.5547753155082464, "actor_loss": -85.56599977111816, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.02663016319275, "step": 81000}
{"episode_reward": 903.660826857445, "episode": 82.0, "batch_reward": 0.8491603763103485, "critic_loss": 0.6068574204444885, "actor_loss": -85.59082157897949, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.847930669784546, "step": 82000}
{"episode_reward": 826.7428389969051, "episode": 83.0, "batch_reward": 0.8526273764371872, "critic_loss": 0.5936771842241287, "actor_loss": -85.68977047729493, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.21947145462036, "step": 83000}
{"episode_reward": 969.8057317628987, "episode": 84.0, "batch_reward": 0.8516986173391342, "critic_loss": 0.6016353746801615, "actor_loss": -85.72127972412109, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.985297441482544, "step": 84000}
{"episode_reward": 868.2328083289634, "episode": 85.0, "batch_reward": 0.8514685987234115, "critic_loss": 0.6301495159268379, "actor_loss": -85.84333518981934, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.530315160751343, "step": 85000}
{"episode_reward": 941.8518783269706, "episode": 86.0, "batch_reward": 0.855213538825512, "critic_loss": 0.6415293298661708, "actor_loss": -85.93893493652344, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.551477670669556, "step": 86000}
{"episode_reward": 967.7740141757974, "episode": 87.0, "batch_reward": 0.8544544162750244, "critic_loss": 0.6193160360455513, "actor_loss": -85.95853498840331, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.512973308563232, "step": 87000}
{"episode_reward": 968.0496148716946, "episode": 88.0, "batch_reward": 0.8563414499163627, "critic_loss": 0.5996411555409431, "actor_loss": -86.0519522857666, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.69146490097046, "step": 88000}
{"episode_reward": 967.4434443241992, "episode": 89.0, "batch_reward": 0.857911773443222, "critic_loss": 0.5816076372861863, "actor_loss": -86.17266918945313, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.41936683654785, "step": 89000}
{"episode_reward": 930.4218732917882, "episode": 90.0, "batch_reward": 0.8577561742067337, "critic_loss": 0.5696326590329409, "actor_loss": -86.15947630310059, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.230042934417725, "step": 90000}
{"episode_reward": 907.5496710385947, "episode": 91.0, "batch_reward": 0.8585042271614075, "critic_loss": 0.5595353291034698, "actor_loss": -86.29360836791992, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.196500062942505, "step": 91000}
{"episode_reward": 971.2829591622207, "episode": 92.0, "batch_reward": 0.8586075403094292, "critic_loss": 0.5406627101749182, "actor_loss": -86.22218183898926, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.21924328804016, "step": 92000}
{"episode_reward": 930.5951959607381, "episode": 93.0, "batch_reward": 0.859883301973343, "critic_loss": 0.5749560196697712, "actor_loss": -86.40764630126954, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.441247940063477, "step": 93000}
{"episode_reward": 932.4537973498769, "episode": 94.0, "batch_reward": 0.8603432881832123, "critic_loss": 0.5710460355132818, "actor_loss": -86.43192790222167, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.124569416046143, "step": 94000}
{"episode_reward": 868.6499986703633, "episode": 95.0, "batch_reward": 0.8610821139216424, "critic_loss": 0.559327252984047, "actor_loss": -86.34670979309082, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.206870555877686, "step": 95000}
{"episode_reward": 922.4539579814405, "episode": 96.0, "batch_reward": 0.8626075255870819, "critic_loss": 0.6069669923186303, "actor_loss": -86.52858447265625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.326328992843628, "step": 96000}
{"episode_reward": 914.7721656816442, "episode": 97.0, "batch_reward": 0.862558195233345, "critic_loss": 0.6039260961264372, "actor_loss": -86.61193997192383, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.760406494140625, "step": 97000}
{"episode_reward": 970.7718169634536, "episode": 98.0, "batch_reward": 0.8637093089818955, "critic_loss": 0.5765091656148433, "actor_loss": -86.50333316040039, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.225069284439087, "step": 98000}
{"episode_reward": 935.2253408220914, "episode": 99.0, "batch_reward": 0.8646274091005325, "critic_loss": 0.568355763271451, "actor_loss": -86.62860945129394, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.417826175689697, "step": 99000}
{"episode_reward": 959.0013692464626, "episode": 100.0, "batch_reward": 0.8657208469510078, "critic_loss": 0.5865313374251128, "actor_loss": -86.67165908813476, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.926068782806396, "step": 100000}
{"episode_reward": 943.6362831476129, "episode": 101.0, "batch_reward": 0.865047108232975, "critic_loss": 0.5968129502534867, "actor_loss": -86.86476759338379, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.907374143600464, "step": 101000}
{"episode_reward": 939.3291116648537, "episode": 102.0, "batch_reward": 0.8683068028688431, "critic_loss": 0.5628820840120315, "actor_loss": -86.85014241027832, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.212929010391235, "step": 102000}
{"episode_reward": 974.1708760942247, "episode": 103.0, "batch_reward": 0.8679101229310036, "critic_loss": 0.5350505558401346, "actor_loss": -86.91413749694824, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.21048641204834, "step": 103000}
{"episode_reward": 966.9387269229621, "episode": 104.0, "batch_reward": 0.869193254172802, "critic_loss": 0.564780936896801, "actor_loss": -87.05622979736329, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.80953359603882, "step": 104000}
{"episode_reward": 942.5841705534092, "episode": 105.0, "batch_reward": 0.870371573805809, "critic_loss": 0.5320934069752693, "actor_loss": -87.05548738098145, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.599247455596924, "step": 105000}
{"episode_reward": 955.6378586018616, "episode": 106.0, "batch_reward": 0.8711092700958252, "critic_loss": 0.5400443510711193, "actor_loss": -87.17184605407715, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.531325101852417, "step": 106000}
{"episode_reward": 962.1069968501122, "episode": 107.0, "batch_reward": 0.8711802637577057, "critic_loss": 0.5231231711953879, "actor_loss": -87.21261141967773, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.711508750915527, "step": 107000}
{"episode_reward": 949.3978235367388, "episode": 108.0, "batch_reward": 0.8718268315792084, "critic_loss": 0.5086301499903202, "actor_loss": -87.11894355773926, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.70039939880371, "step": 108000}
{"episode_reward": 962.047399889589, "episode": 109.0, "batch_reward": 0.8729262128472328, "critic_loss": 0.5046504980921745, "actor_loss": -87.31020922851563, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.643336296081543, "step": 109000}
{"episode_reward": 893.1210586228276, "episode": 110.0, "batch_reward": 0.8711010409593583, "critic_loss": 0.5126613841205835, "actor_loss": -87.16574917602539, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.694183349609375, "step": 110000}
{"episode_reward": 893.9822941824746, "episode": 111.0, "batch_reward": 0.8732590945959091, "critic_loss": 0.49628650650382045, "actor_loss": -87.32016015625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.72229599952698, "step": 111000}
{"episode_reward": 959.1991427824274, "episode": 112.0, "batch_reward": 0.8739116860628128, "critic_loss": 0.5007453775405883, "actor_loss": -87.22171548461914, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.44451403617859, "step": 112000}
{"episode_reward": 958.1717454145487, "episode": 113.0, "batch_reward": 0.8747822839617729, "critic_loss": 0.47572051447629926, "actor_loss": -87.46163063049316, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.639163732528687, "step": 113000}
{"episode_reward": 972.3346038123211, "episode": 114.0, "batch_reward": 0.8759069120287896, "critic_loss": 0.4780777854472399, "actor_loss": -87.37521102905274, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.351839542388916, "step": 114000}
{"episode_reward": 900.5543204210511, "episode": 115.0, "batch_reward": 0.8761015632152558, "critic_loss": 0.49257852874696256, "actor_loss": -87.39677819824219, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.25713324546814, "step": 115000}
{"episode_reward": 970.1962095547144, "episode": 116.0, "batch_reward": 0.8768865458965301, "critic_loss": 0.468665233284235, "actor_loss": -87.45030673217774, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.672691345214844, "step": 116000}
{"episode_reward": 974.7725422231052, "episode": 117.0, "batch_reward": 0.8781018562912941, "critic_loss": 0.48495881190896034, "actor_loss": -87.62199575805664, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.530635833740234, "step": 117000}
{"episode_reward": 962.9672260387254, "episode": 118.0, "batch_reward": 0.8780019826889038, "critic_loss": 0.4773853195756674, "actor_loss": -87.6564292602539, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.49091911315918, "step": 118000}
{"episode_reward": 957.8425351783009, "episode": 119.0, "batch_reward": 0.8793013185858727, "critic_loss": 0.47338221429288385, "actor_loss": -87.68073068237305, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.728721380233765, "step": 119000}
{"episode_reward": 940.3768099316732, "episode": 120.0, "batch_reward": 0.878616279065609, "critic_loss": 0.45683344765007494, "actor_loss": -87.70548298645019, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.404233932495117, "step": 120000}
{"episode_reward": 960.7022224696215, "episode": 121.0, "batch_reward": 0.8809284874200821, "critic_loss": 0.49905861388146877, "actor_loss": -87.91261166381835, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.37523818016052, "step": 121000}
{"episode_reward": 874.7704951965791, "episode": 122.0, "batch_reward": 0.8796611622571945, "critic_loss": 0.47144591823220255, "actor_loss": -87.58923191833496, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.432287216186523, "step": 122000}
{"episode_reward": 899.6267325729569, "episode": 123.0, "batch_reward": 0.879990318775177, "critic_loss": 0.4969547774940729, "actor_loss": -87.72298472595214, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.8372802734375, "step": 123000}
{"episode_reward": 939.9672432619475, "episode": 124.0, "batch_reward": 0.8800213099718094, "critic_loss": 0.4908119421750307, "actor_loss": -87.67563114929199, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.324390172958374, "step": 124000}
{"episode_reward": 955.0722766040283, "episode": 125.0, "batch_reward": 0.881000899374485, "critic_loss": 0.4935026279836893, "actor_loss": -87.72749978637695, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.239367723464966, "step": 125000}
{"episode_reward": 953.5119678688327, "episode": 126.0, "batch_reward": 0.8804417266845703, "critic_loss": 0.5161051103621721, "actor_loss": -87.70942770385741, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.89270329475403, "step": 126000}
{"episode_reward": 973.5856962961113, "episode": 127.0, "batch_reward": 0.8810720817446709, "critic_loss": 0.4985688245743513, "actor_loss": -87.59400834655762, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.491572618484497, "step": 127000}
{"episode_reward": 872.322812716365, "episode": 128.0, "batch_reward": 0.8825050486922265, "critic_loss": 0.46707586987316607, "actor_loss": -87.80024166870118, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.36690855026245, "step": 128000}
{"episode_reward": 956.4856185499144, "episode": 129.0, "batch_reward": 0.8830176102519035, "critic_loss": 0.4839894715547562, "actor_loss": -87.73030366516113, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.860306978225708, "step": 129000}
{"episode_reward": 977.2284840706583, "episode": 130.0, "batch_reward": 0.883403805911541, "critic_loss": 0.4853185190707445, "actor_loss": -87.82007287597656, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.696741104125977, "step": 130000}
{"episode_reward": 926.2013351059214, "episode": 131.0, "batch_reward": 0.8846287759542465, "critic_loss": 0.5074938258230686, "actor_loss": -87.82604005432128, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.454591512680054, "step": 131000}
{"episode_reward": 952.1622233829099, "episode": 132.0, "batch_reward": 0.8849283426403999, "critic_loss": 0.4940406401604414, "actor_loss": -87.8611939239502, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.701404809951782, "step": 132000}
{"episode_reward": 890.407821725858, "episode": 133.0, "batch_reward": 0.8847522125840187, "critic_loss": 0.48908242453634737, "actor_loss": -88.07859844970703, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.360005855560303, "step": 133000}
{"episode_reward": 962.8646166914315, "episode": 134.0, "batch_reward": 0.8849974625706672, "critic_loss": 0.48464637050032616, "actor_loss": -87.9012882385254, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.7014102935791, "step": 134000}
{"episode_reward": 966.0864412985763, "episode": 135.0, "batch_reward": 0.8837203168869019, "critic_loss": 0.4886251809448004, "actor_loss": -87.80267945861816, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.61863899230957, "step": 135000}
{"episode_reward": 933.1841588565974, "episode": 136.0, "batch_reward": 0.8863992011547088, "critic_loss": 0.4802353176623583, "actor_loss": -87.93891937255859, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.41239643096924, "step": 136000}
{"episode_reward": 938.0663916527793, "episode": 137.0, "batch_reward": 0.8867458690404892, "critic_loss": 0.4974651973247528, "actor_loss": -87.90297679138183, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.018750190734863, "step": 137000}
{"episode_reward": 925.5263081960721, "episode": 138.0, "batch_reward": 0.8870179821848869, "critic_loss": 0.5094829797893763, "actor_loss": -88.00953536987305, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.744976043701172, "step": 138000}
{"episode_reward": 973.611987952929, "episode": 139.0, "batch_reward": 0.8853159250020981, "critic_loss": 0.5272295278459788, "actor_loss": -87.9712236175537, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.816843509674072, "step": 139000}
{"episode_reward": 818.5478642954945, "episode": 140.0, "batch_reward": 0.8860297262668609, "critic_loss": 0.5163251389712096, "actor_loss": -87.97355332946778, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.66783094406128, "step": 140000}
{"episode_reward": 953.7139714013128, "episode": 141.0, "batch_reward": 0.8887157292962075, "critic_loss": 0.4708981311768293, "actor_loss": -87.9717410736084, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.96799945831299, "step": 141000}
{"episode_reward": 949.1653357489483, "episode": 142.0, "batch_reward": 0.8890701886415482, "critic_loss": 0.5064912475645542, "actor_loss": -88.07714303588867, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.82437229156494, "step": 142000}
{"episode_reward": 972.6903681969237, "episode": 143.0, "batch_reward": 0.8873716343045235, "critic_loss": 0.5559958755970001, "actor_loss": -88.0654564666748, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.563437700271606, "step": 143000}
{"episode_reward": 914.0707719741376, "episode": 144.0, "batch_reward": 0.887826313316822, "critic_loss": 0.5177413678616285, "actor_loss": -88.00348422241211, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.26667547225952, "step": 144000}
{"episode_reward": 940.4047538954676, "episode": 145.0, "batch_reward": 0.8901971162557601, "critic_loss": 0.5005837343782187, "actor_loss": -88.0341429901123, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.723938465118408, "step": 145000}
{"episode_reward": 946.0195054510158, "episode": 146.0, "batch_reward": 0.888633418738842, "critic_loss": 0.5349546215981245, "actor_loss": -88.0996244354248, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.63274908065796, "step": 146000}
{"episode_reward": 874.0069155084615, "episode": 147.0, "batch_reward": 0.8879841262698174, "critic_loss": 0.5435622262656689, "actor_loss": -88.10908677673339, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.95570468902588, "step": 147000}
{"episode_reward": 932.785076479837, "episode": 148.0, "batch_reward": 0.8898285228013992, "critic_loss": 0.5336043553203345, "actor_loss": -88.22177503967285, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.543357133865356, "step": 148000}
{"episode_reward": 950.5650196887142, "episode": 149.0, "batch_reward": 0.8901809874773026, "critic_loss": 0.5490487720072269, "actor_loss": -88.1099796295166, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.941219091415405, "step": 149000}
{"episode_reward": 887.8954600290316, "episode": 150.0, "batch_reward": 0.8900880228281021, "critic_loss": 0.5129636601805687, "actor_loss": -87.97030796813965, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "step": 150000}
