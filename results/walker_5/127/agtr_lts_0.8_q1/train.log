{"episode_reward": 0.0, "episode": 1.0, "duration": 21.74663019180298, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.9222662448883057, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.4187753258565538, "critic_loss": 0.1150761050174945, "actor_loss": -63.91937939208575, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 62.418699741363525, "step": 3000}
{"episode_reward": 150.69295064534273, "episode": 4.0, "batch_reward": 0.31885914427042006, "critic_loss": 0.31958078042417765, "actor_loss": -60.72258280658722, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.831603288650513, "step": 4000}
{"episode_reward": 161.54680234981916, "episode": 5.0, "batch_reward": 0.28332590417563913, "critic_loss": 0.32958611473441124, "actor_loss": -57.41947692489624, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.235471725463867, "step": 5000}
{"episode_reward": 119.74934990558594, "episode": 6.0, "batch_reward": 0.2595980205386877, "critic_loss": 0.5223447915762663, "actor_loss": -59.67971411037445, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.59152841567993, "step": 6000}
{"episode_reward": 253.36884689388722, "episode": 7.0, "batch_reward": 0.2748548096865416, "critic_loss": 0.6687766351401806, "actor_loss": -59.17439797306061, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.1423761844635, "step": 7000}
{"episode_reward": 392.31554796151676, "episode": 8.0, "batch_reward": 0.28627931351959707, "critic_loss": 0.7609721000790596, "actor_loss": -59.32045671272278, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.303350925445557, "step": 8000}
{"episode_reward": 414.6861600681579, "episode": 9.0, "batch_reward": 0.3113265102356672, "critic_loss": 0.8330421356260777, "actor_loss": -61.19274818992615, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.028719186782837, "step": 9000}
{"episode_reward": 618.1718277511043, "episode": 10.0, "batch_reward": 0.3246721077859402, "critic_loss": 1.0676293590664863, "actor_loss": -61.84342687225342, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.433288097381592, "step": 10000}
{"episode_reward": 438.26843526244926, "episode": 11.0, "batch_reward": 0.3655978648364544, "critic_loss": 1.3831534138321877, "actor_loss": -62.60699749946594, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.122056007385254, "step": 11000}
{"episode_reward": 805.1774958818104, "episode": 12.0, "batch_reward": 0.3695802882909775, "critic_loss": 1.2696666590571404, "actor_loss": -62.488328893661496, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.109485864639282, "step": 12000}
{"episode_reward": 44.93162182525108, "episode": 13.0, "batch_reward": 0.36483107149600985, "critic_loss": 1.4168032978773117, "actor_loss": -62.199407192230225, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.132638692855835, "step": 13000}
{"episode_reward": 650.9525153922871, "episode": 14.0, "batch_reward": 0.3857312759459019, "critic_loss": 1.5876313434839249, "actor_loss": -62.69502363586426, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.74271583557129, "step": 14000}
{"episode_reward": 612.3322432081911, "episode": 15.0, "batch_reward": 0.40159140172600744, "critic_loss": 1.7948598707914352, "actor_loss": -64.84404669189453, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.74062180519104, "step": 15000}
{"episode_reward": 701.493655420601, "episode": 16.0, "batch_reward": 0.42519535750150683, "critic_loss": 1.805982673048973, "actor_loss": -65.20632657623291, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.119468450546265, "step": 16000}
{"episode_reward": 833.107013678186, "episode": 17.0, "batch_reward": 0.4540088815689087, "critic_loss": 1.8320204738378525, "actor_loss": -65.41564476776124, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.644870281219482, "step": 17000}
{"episode_reward": 873.624196871508, "episode": 18.0, "batch_reward": 0.4738131185173988, "critic_loss": 1.668016160607338, "actor_loss": -66.94198299789429, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.43376851081848, "step": 18000}
{"episode_reward": 779.1020722871164, "episode": 19.0, "batch_reward": 0.49015722393989564, "critic_loss": 1.7796479949951172, "actor_loss": -67.98093388366699, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.80884838104248, "step": 19000}
{"episode_reward": 805.9009673747235, "episode": 20.0, "batch_reward": 0.5061432386934758, "critic_loss": 1.6607263533473016, "actor_loss": -69.98697867584228, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.269577264785767, "step": 20000}
{"episode_reward": 761.0492700293927, "episode": 21.0, "batch_reward": 0.5229574948847294, "critic_loss": 1.5979606214761735, "actor_loss": -68.08891579437255, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.89500951766968, "step": 21000}
{"episode_reward": 849.8385842137909, "episode": 22.0, "batch_reward": 0.5326256560981274, "critic_loss": 1.5776870942115784, "actor_loss": -69.97290270233154, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.15115761756897, "step": 22000}
{"episode_reward": 626.5524856937849, "episode": 23.0, "batch_reward": 0.5419926608502865, "critic_loss": 1.6249352353215218, "actor_loss": -69.65773293304443, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.49754571914673, "step": 23000}
{"episode_reward": 867.7727960071636, "episode": 24.0, "batch_reward": 0.5530245903730392, "critic_loss": 1.5849634011387825, "actor_loss": -70.82097888946534, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.734267711639404, "step": 24000}
{"episode_reward": 854.4325505972115, "episode": 25.0, "batch_reward": 0.5596448302268981, "critic_loss": 1.6082826815843583, "actor_loss": -71.73092397308349, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.2245135307312, "step": 25000}
{"episode_reward": 638.5452890188963, "episode": 26.0, "batch_reward": 0.567747927904129, "critic_loss": 1.5558205386400223, "actor_loss": -71.1197042388916, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.610162019729614, "step": 26000}
{"episode_reward": 830.8943479624189, "episode": 27.0, "batch_reward": 0.5821250358819962, "critic_loss": 1.5205792179703712, "actor_loss": -72.12538110351562, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.500250577926636, "step": 27000}
{"episode_reward": 900.5227349573836, "episode": 28.0, "batch_reward": 0.5934561855494976, "critic_loss": 1.6103790917396545, "actor_loss": -72.26173386383057, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.128985166549683, "step": 28000}
{"episode_reward": 863.2105282391907, "episode": 29.0, "batch_reward": 0.5981647683978081, "critic_loss": 1.648644811987877, "actor_loss": -72.91113192749023, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.38050603866577, "step": 29000}
{"episode_reward": 828.8554783863681, "episode": 30.0, "batch_reward": 0.6090908176600933, "critic_loss": 1.6898229526281356, "actor_loss": -72.38453099822998, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.297165870666504, "step": 30000}
{"episode_reward": 824.0103005269339, "episode": 31.0, "batch_reward": 0.6140864076018333, "critic_loss": 1.813067664504051, "actor_loss": -73.82378452301026, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.959266901016235, "step": 31000}
{"episode_reward": 761.344372927866, "episode": 32.0, "batch_reward": 0.616195297151804, "critic_loss": 2.0040838947296145, "actor_loss": -74.34392596435546, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.533229112625122, "step": 32000}
{"episode_reward": 698.233921013803, "episode": 33.0, "batch_reward": 0.6153110488057136, "critic_loss": 2.1161631393432616, "actor_loss": -74.2020556640625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.545515298843384, "step": 33000}
{"episode_reward": 484.74677314916966, "episode": 34.0, "batch_reward": 0.6187936643660068, "critic_loss": 2.1813571587204934, "actor_loss": -74.40746170806885, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.664129495620728, "step": 34000}
{"episode_reward": 887.3815011043123, "episode": 35.0, "batch_reward": 0.626473368704319, "critic_loss": 2.1123564791679383, "actor_loss": -74.6059337463379, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.279005527496338, "step": 35000}
{"episode_reward": 854.8542840184294, "episode": 36.0, "batch_reward": 0.6338052300810814, "critic_loss": 2.0012813372612, "actor_loss": -75.3924149017334, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.13185715675354, "step": 36000}
{"episode_reward": 898.1459675588491, "episode": 37.0, "batch_reward": 0.6420079678893089, "critic_loss": 1.9869483778476715, "actor_loss": -74.94101187133789, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.634461164474487, "step": 37000}
{"episode_reward": 895.5792377420216, "episode": 38.0, "batch_reward": 0.6477522652745247, "critic_loss": 1.9009013532400132, "actor_loss": -74.89311096191406, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.532030820846558, "step": 38000}
{"episode_reward": 880.77432309282, "episode": 39.0, "batch_reward": 0.6432571436166763, "critic_loss": 1.9283360882401466, "actor_loss": -74.73102867126465, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.348620176315308, "step": 39000}
{"episode_reward": 25.361344229028838, "episode": 40.0, "batch_reward": 0.6373848018050193, "critic_loss": 1.8983549084663391, "actor_loss": -75.2589556503296, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.67918610572815, "step": 40000}
{"episode_reward": 942.3046934207191, "episode": 41.0, "batch_reward": 0.6461398028731347, "critic_loss": 1.859035424053669, "actor_loss": -75.34795262145997, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.84593725204468, "step": 41000}
{"episode_reward": 927.3993063463554, "episode": 42.0, "batch_reward": 0.6516770389080048, "critic_loss": 1.6717977355718612, "actor_loss": -75.74936489105225, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.649526834487915, "step": 42000}
{"episode_reward": 914.0064684601956, "episode": 43.0, "batch_reward": 0.659016556084156, "critic_loss": 1.6861816281080246, "actor_loss": -76.05925230407715, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.384544610977173, "step": 43000}
{"episode_reward": 956.331947932975, "episode": 44.0, "batch_reward": 0.6662293972969056, "critic_loss": 1.540790481209755, "actor_loss": -77.72982637786865, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.307969331741333, "step": 44000}
{"episode_reward": 945.257549428296, "episode": 45.0, "batch_reward": 0.6720133147835732, "critic_loss": 1.5825061518549919, "actor_loss": -77.147330909729, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.041722297668457, "step": 45000}
{"episode_reward": 960.4496646172051, "episode": 46.0, "batch_reward": 0.676541509449482, "critic_loss": 1.4746789351701737, "actor_loss": -76.6321208114624, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.963032722473145, "step": 46000}
{"episode_reward": 963.4368363402085, "episode": 47.0, "batch_reward": 0.6844918839931488, "critic_loss": 1.4745824421048164, "actor_loss": -77.34326625823975, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.14715027809143, "step": 47000}
{"episode_reward": 931.1335278362726, "episode": 48.0, "batch_reward": 0.6902339728474617, "critic_loss": 1.55064013838768, "actor_loss": -77.45186884307861, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.073879957199097, "step": 48000}
{"episode_reward": 914.955592589066, "episode": 49.0, "batch_reward": 0.6954373522996903, "critic_loss": 1.5126916199326514, "actor_loss": -78.51570154571533, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.323679208755493, "step": 49000}
{"episode_reward": 942.3780767075532, "episode": 50.0, "batch_reward": 0.6984337313771248, "critic_loss": 1.4732160643339156, "actor_loss": -78.24295829010009, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.294252395629883, "step": 50000}
{"episode_reward": 937.5489382608104, "episode": 51.0, "batch_reward": 0.7045207762122154, "critic_loss": 1.5584894135594367, "actor_loss": -78.43219790649414, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.62440299987793, "step": 51000}
{"episode_reward": 940.4043957837475, "episode": 52.0, "batch_reward": 0.7081782353520394, "critic_loss": 1.5625516835451125, "actor_loss": -78.3460386352539, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.356134176254272, "step": 52000}
{"episode_reward": 923.5367403748883, "episode": 53.0, "batch_reward": 0.7118357058167457, "critic_loss": 1.498794883966446, "actor_loss": -79.07794832611084, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.941612482070923, "step": 53000}
{"episode_reward": 945.8044138806035, "episode": 54.0, "batch_reward": 0.7177219862937927, "critic_loss": 1.4897721427083015, "actor_loss": -79.4798373413086, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.31091046333313, "step": 54000}
{"episode_reward": 939.052373593939, "episode": 55.0, "batch_reward": 0.7199355611801147, "critic_loss": 1.4961747068166733, "actor_loss": -79.46839008331298, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.566523551940918, "step": 55000}
{"episode_reward": 867.4682425796454, "episode": 56.0, "batch_reward": 0.7229597005844116, "critic_loss": 1.5054411036968232, "actor_loss": -79.57258834838868, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.626080751419067, "step": 56000}
{"episode_reward": 883.0239592875253, "episode": 57.0, "batch_reward": 0.7281631333827973, "critic_loss": 1.4496490728855134, "actor_loss": -79.8046187133789, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.550387382507324, "step": 57000}
{"episode_reward": 930.7138643032243, "episode": 58.0, "batch_reward": 0.7268495901226998, "critic_loss": 1.5561366978883744, "actor_loss": -79.92317155456543, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.279240369796753, "step": 58000}
{"episode_reward": 841.1403884462248, "episode": 59.0, "batch_reward": 0.7321489089131356, "critic_loss": 1.4685119633674621, "actor_loss": -80.07988882446288, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.565147399902344, "step": 59000}
{"episode_reward": 960.2810498819944, "episode": 60.0, "batch_reward": 0.7353295786976815, "critic_loss": 1.3964290150403977, "actor_loss": -80.19235806274413, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.627171754837036, "step": 60000}
{"episode_reward": 923.2984258038817, "episode": 61.0, "batch_reward": 0.7379315598607064, "critic_loss": 1.4806515635252, "actor_loss": -80.21435740661622, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.585336208343506, "step": 61000}
{"episode_reward": 850.333289573503, "episode": 62.0, "batch_reward": 0.7399271046519279, "critic_loss": 1.4796632136106491, "actor_loss": -80.42055845642089, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.5186927318573, "step": 62000}
{"episode_reward": 760.9087319570293, "episode": 63.0, "batch_reward": 0.7412954755425453, "critic_loss": 1.3436039429306983, "actor_loss": -80.51558387756347, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.50067710876465, "step": 63000}
{"episode_reward": 956.5229267697141, "episode": 64.0, "batch_reward": 0.7449358844161034, "critic_loss": 1.3409276307225226, "actor_loss": -80.78586703491212, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.77912735939026, "step": 64000}
{"episode_reward": 907.176947546187, "episode": 65.0, "batch_reward": 0.7469127924442291, "critic_loss": 1.320456043601036, "actor_loss": -80.69899206542969, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.610807180404663, "step": 65000}
{"episode_reward": 960.75688895824, "episode": 66.0, "batch_reward": 0.7493871871829033, "critic_loss": 1.3236066536903381, "actor_loss": -80.79399642944335, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.42418599128723, "step": 66000}
{"episode_reward": 918.8348192904973, "episode": 67.0, "batch_reward": 0.7525866268873215, "critic_loss": 1.408007046341896, "actor_loss": -81.18304244995117, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.57109260559082, "step": 67000}
{"episode_reward": 935.988425257345, "episode": 68.0, "batch_reward": 0.7552447633743287, "critic_loss": 1.4523501885533332, "actor_loss": -81.49492752075196, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.596450090408325, "step": 68000}
{"episode_reward": 887.1940143274743, "episode": 69.0, "batch_reward": 0.7559268616437912, "critic_loss": 1.5419124169945717, "actor_loss": -81.01226000976563, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.399316549301147, "step": 69000}
{"episode_reward": 843.0660602347015, "episode": 70.0, "batch_reward": 0.75322082811594, "critic_loss": 1.5139577860832214, "actor_loss": -81.03374618530273, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.662574529647827, "step": 70000}
{"episode_reward": 11.793601603715071, "episode": 71.0, "batch_reward": 0.7481997782588005, "critic_loss": 1.4482846734523773, "actor_loss": -80.73608740234376, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.85807943344116, "step": 71000}
{"episode_reward": 928.8107208899173, "episode": 72.0, "batch_reward": 0.7500642864108086, "critic_loss": 1.403777050256729, "actor_loss": -81.16940397644044, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.585500240325928, "step": 72000}
{"episode_reward": 858.621282862494, "episode": 73.0, "batch_reward": 0.7518201848268509, "critic_loss": 1.4611834707260132, "actor_loss": -81.24730989074708, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.33343195915222, "step": 73000}
{"episode_reward": 907.1004012862642, "episode": 74.0, "batch_reward": 0.7539026118516922, "critic_loss": 1.4416497894525528, "actor_loss": -81.06591343688964, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.166884899139404, "step": 74000}
{"episode_reward": 922.9791575072252, "episode": 75.0, "batch_reward": 0.755144935786724, "critic_loss": 1.436249660551548, "actor_loss": -81.17436824035644, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.542365550994873, "step": 75000}
{"episode_reward": 864.3246113285774, "episode": 76.0, "batch_reward": 0.7559729826450348, "critic_loss": 1.4146092267036439, "actor_loss": -81.32085343933106, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.600295305252075, "step": 76000}
{"episode_reward": 876.6665218708615, "episode": 77.0, "batch_reward": 0.758923667371273, "critic_loss": 1.5467539471387863, "actor_loss": -81.27322029113769, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.320316553115845, "step": 77000}
{"episode_reward": 917.3559041459275, "episode": 78.0, "batch_reward": 0.7613187681436538, "critic_loss": 1.3976164400577544, "actor_loss": -81.45940403747558, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.355679035186768, "step": 78000}
{"episode_reward": 940.6054823247771, "episode": 79.0, "batch_reward": 0.7625741400122642, "critic_loss": 1.4756840777993203, "actor_loss": -81.87365826416016, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.571991443634033, "step": 79000}
{"episode_reward": 939.8359780878058, "episode": 80.0, "batch_reward": 0.7667387803196907, "critic_loss": 1.4016528384685516, "actor_loss": -81.8776120300293, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.47658371925354, "step": 80000}
{"episode_reward": 968.9141648689643, "episode": 81.0, "batch_reward": 0.7694409220814705, "critic_loss": 1.4331061163544654, "actor_loss": -81.70998292541503, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.03328561782837, "step": 81000}
{"episode_reward": 906.1611975463198, "episode": 82.0, "batch_reward": 0.768328746855259, "critic_loss": 1.3825394514799119, "actor_loss": -81.75724761962891, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.257293701171875, "step": 82000}
{"episode_reward": 898.8423441933645, "episode": 83.0, "batch_reward": 0.7729769384264946, "critic_loss": 1.2775298268795015, "actor_loss": -82.09243870544434, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.16230082511902, "step": 83000}
{"episode_reward": 962.1565035592606, "episode": 84.0, "batch_reward": 0.7734242168664932, "critic_loss": 1.324672310769558, "actor_loss": -82.34045481872559, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.588539838790894, "step": 84000}
{"episode_reward": 857.1209871923425, "episode": 85.0, "batch_reward": 0.7741939311623574, "critic_loss": 1.2963906427025795, "actor_loss": -82.15756889343261, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.58718729019165, "step": 85000}
{"episode_reward": 889.4534487185125, "episode": 86.0, "batch_reward": 0.7760659798383712, "critic_loss": 1.2647692106664181, "actor_loss": -82.21548725891114, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.637622594833374, "step": 86000}
{"episode_reward": 891.0651361790036, "episode": 87.0, "batch_reward": 0.7776880860328674, "critic_loss": 1.265422489017248, "actor_loss": -82.40953015136719, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.16991424560547, "step": 87000}
{"episode_reward": 956.7974345259693, "episode": 88.0, "batch_reward": 0.7794255610108376, "critic_loss": 1.1880377952754497, "actor_loss": -82.29770375061035, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.43374514579773, "step": 88000}
{"episode_reward": 924.7862666746569, "episode": 89.0, "batch_reward": 0.780493748486042, "critic_loss": 1.1705019685029983, "actor_loss": -82.44188038635254, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.96768045425415, "step": 89000}
{"episode_reward": 854.1488456311465, "episode": 90.0, "batch_reward": 0.7830681052207947, "critic_loss": 1.1168034224808217, "actor_loss": -82.50637419128418, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.153451919555664, "step": 90000}
{"episode_reward": 913.8248404119641, "episode": 91.0, "batch_reward": 0.7840477811694145, "critic_loss": 1.104447539806366, "actor_loss": -82.57032366943359, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.22849249839783, "step": 91000}
{"episode_reward": 968.4777811912261, "episode": 92.0, "batch_reward": 0.7849140515327454, "critic_loss": 1.147658114671707, "actor_loss": -82.85130537414551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.171188831329346, "step": 92000}
{"episode_reward": 868.312957557394, "episode": 93.0, "batch_reward": 0.7850957872867584, "critic_loss": 1.126493101298809, "actor_loss": -82.63012390136718, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.28366732597351, "step": 93000}
{"episode_reward": 884.6926767188512, "episode": 94.0, "batch_reward": 0.78697097915411, "critic_loss": 1.134228577286005, "actor_loss": -82.76554818725586, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.178804397583008, "step": 94000}
{"episode_reward": 899.6503340130306, "episode": 95.0, "batch_reward": 0.7874575145840644, "critic_loss": 1.1343242056667804, "actor_loss": -82.97324098205567, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.336875677108765, "step": 95000}
{"episode_reward": 884.8948804557823, "episode": 96.0, "batch_reward": 0.7898838461041451, "critic_loss": 1.1424580847918988, "actor_loss": -83.07953216552734, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.40949296951294, "step": 96000}
{"episode_reward": 914.6760200235678, "episode": 97.0, "batch_reward": 0.7908038075566292, "critic_loss": 1.1439516607522964, "actor_loss": -82.99587226867676, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.577812910079956, "step": 97000}
{"episode_reward": 964.2946348007534, "episode": 98.0, "batch_reward": 0.7926561693549157, "critic_loss": 1.1556430599689484, "actor_loss": -83.20951347351074, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.2978093624115, "step": 98000}
{"episode_reward": 961.1962347076168, "episode": 99.0, "batch_reward": 0.7945252740979195, "critic_loss": 1.1103000175356865, "actor_loss": -83.02803852844238, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.32756495475769, "step": 99000}
{"episode_reward": 969.0556958561127, "episode": 100.0, "batch_reward": 0.7961359992027283, "critic_loss": 1.1148455348610877, "actor_loss": -83.17194075012208, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.52010202407837, "step": 100000}
{"episode_reward": 924.5651287904305, "episode": 101.0, "batch_reward": 0.7967783779501915, "critic_loss": 1.0902320173084736, "actor_loss": -83.10308520507813, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.09865975379944, "step": 101000}
{"episode_reward": 922.4590794032948, "episode": 102.0, "batch_reward": 0.8000329584479332, "critic_loss": 1.0276789669394493, "actor_loss": -83.36301396179199, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.496170043945312, "step": 102000}
{"episode_reward": 945.1723142579681, "episode": 103.0, "batch_reward": 0.7993814174532891, "critic_loss": 1.1096909002959727, "actor_loss": -83.17307876586914, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.132159948349, "step": 103000}
{"episode_reward": 908.8237708592459, "episode": 104.0, "batch_reward": 0.8024721640944481, "critic_loss": 1.1538170372247696, "actor_loss": -83.18857806396484, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.160059213638306, "step": 104000}
{"episode_reward": 943.8557652562926, "episode": 105.0, "batch_reward": 0.8019468830823898, "critic_loss": 1.0612385301589966, "actor_loss": -83.28619441223144, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.33299732208252, "step": 105000}
{"episode_reward": 907.7753534330044, "episode": 106.0, "batch_reward": 0.8042561911940574, "critic_loss": 1.0481255742907525, "actor_loss": -83.43609709167481, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.758316040039062, "step": 106000}
{"episode_reward": 955.5966336861347, "episode": 107.0, "batch_reward": 0.8036350813508034, "critic_loss": 1.065157398045063, "actor_loss": -83.28990919494629, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.280295848846436, "step": 107000}
{"episode_reward": 901.9446786128134, "episode": 108.0, "batch_reward": 0.8052304751873016, "critic_loss": 1.0884174785912037, "actor_loss": -83.54253341674804, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.6178457736969, "step": 108000}
{"episode_reward": 821.946949513959, "episode": 109.0, "batch_reward": 0.8070136185288429, "critic_loss": 1.1030673634707928, "actor_loss": -83.49478691101075, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.041754245758057, "step": 109000}
{"episode_reward": 917.6171808572129, "episode": 110.0, "batch_reward": 0.8062153133153915, "critic_loss": 1.0558244450092316, "actor_loss": -83.74764088439942, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.156516313552856, "step": 110000}
{"episode_reward": 869.0731254851132, "episode": 111.0, "batch_reward": 0.8073634009361267, "critic_loss": 1.0799053081274033, "actor_loss": -83.53867347717285, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.79059195518494, "step": 111000}
{"episode_reward": 950.3229258572644, "episode": 112.0, "batch_reward": 0.8093649221658706, "critic_loss": 1.0944677695631981, "actor_loss": -83.61700579833985, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.186161756515503, "step": 112000}
{"episode_reward": 929.6496058052549, "episode": 113.0, "batch_reward": 0.8105095821619034, "critic_loss": 1.127462371379137, "actor_loss": -83.68713784790039, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.340376615524292, "step": 113000}
{"episode_reward": 946.5625414125623, "episode": 114.0, "batch_reward": 0.8116955966949463, "critic_loss": 1.1291296674311162, "actor_loss": -83.77070985412598, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.408480405807495, "step": 114000}
{"episode_reward": 888.0754501447332, "episode": 115.0, "batch_reward": 0.8141724560260772, "critic_loss": 1.1173126457631588, "actor_loss": -83.80710023498536, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.127785682678223, "step": 115000}
{"episode_reward": 955.4495795240634, "episode": 116.0, "batch_reward": 0.8142627467513084, "critic_loss": 1.1023194759786128, "actor_loss": -83.79061814880372, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.32503843307495, "step": 116000}
{"episode_reward": 967.6820889277732, "episode": 117.0, "batch_reward": 0.8155392575263977, "critic_loss": 1.0376763004660607, "actor_loss": -83.6893070526123, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.283998012542725, "step": 117000}
{"episode_reward": 938.2217215333898, "episode": 118.0, "batch_reward": 0.8147303632497788, "critic_loss": 1.0764000724852085, "actor_loss": -83.83179939270019, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.282461404800415, "step": 118000}
{"episode_reward": 913.6596224932563, "episode": 119.0, "batch_reward": 0.8161859034895896, "critic_loss": 1.1577491720020772, "actor_loss": -83.89385833740235, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.074687242507935, "step": 119000}
{"episode_reward": 878.6919242729315, "episode": 120.0, "batch_reward": 0.8167474528551102, "critic_loss": 1.0954839046895504, "actor_loss": -83.72010139465333, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.16206693649292, "step": 120000}
{"episode_reward": 953.9007126156328, "episode": 121.0, "batch_reward": 0.8185365629196167, "critic_loss": 1.0701620263755323, "actor_loss": -83.88235943603516, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.86049437522888, "step": 121000}
{"episode_reward": 929.7171231705244, "episode": 122.0, "batch_reward": 0.8186627063155174, "critic_loss": 1.0226054028272629, "actor_loss": -83.95609336853028, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.10537886619568, "step": 122000}
{"episode_reward": 861.1166878964985, "episode": 123.0, "batch_reward": 0.8188873316645622, "critic_loss": 0.9925835371017456, "actor_loss": -84.06048300170899, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.14199733734131, "step": 123000}
{"episode_reward": 913.5128507834663, "episode": 124.0, "batch_reward": 0.8203670060634614, "critic_loss": 1.0459281392097473, "actor_loss": -84.05768734741211, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.825371503829956, "step": 124000}
{"episode_reward": 938.1270171247023, "episode": 125.0, "batch_reward": 0.8189594124555588, "critic_loss": 1.0523367401361465, "actor_loss": -83.99098204040527, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.145005226135254, "step": 125000}
{"episode_reward": 915.611975273322, "episode": 126.0, "batch_reward": 0.8209045689105987, "critic_loss": 1.0399209209680558, "actor_loss": -84.17731193542481, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.144651174545288, "step": 126000}
{"episode_reward": 961.1189814825751, "episode": 127.0, "batch_reward": 0.8219273229837417, "critic_loss": 0.9994214907884598, "actor_loss": -84.13738555908203, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.30833888053894, "step": 127000}
{"episode_reward": 908.3533378882364, "episode": 128.0, "batch_reward": 0.8227299388051033, "critic_loss": 1.0339474013745784, "actor_loss": -84.14668786621094, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.512861490249634, "step": 128000}
{"episode_reward": 947.8667200873713, "episode": 129.0, "batch_reward": 0.825262121796608, "critic_loss": 0.9773817904591561, "actor_loss": -84.22898342895508, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.22136354446411, "step": 129000}
{"episode_reward": 966.2281733049076, "episode": 130.0, "batch_reward": 0.8248083647489548, "critic_loss": 0.9885401996672154, "actor_loss": -84.32147773742676, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.04356360435486, "step": 130000}
{"episode_reward": 896.813204074172, "episode": 131.0, "batch_reward": 0.826439148902893, "critic_loss": 0.9930784385204315, "actor_loss": -84.05823893737794, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.48993682861328, "step": 131000}
{"episode_reward": 938.0450935694283, "episode": 132.0, "batch_reward": 0.8262974401712417, "critic_loss": 0.9680842973887921, "actor_loss": -84.37112530517578, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.12359094619751, "step": 132000}
{"episode_reward": 905.3028628868905, "episode": 133.0, "batch_reward": 0.8282715553641319, "critic_loss": 0.9816195021271705, "actor_loss": -84.27280995178222, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.133538007736206, "step": 133000}
{"episode_reward": 965.4391994188927, "episode": 134.0, "batch_reward": 0.8287515364885331, "critic_loss": 0.9675151385962963, "actor_loss": -84.43378639221191, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.184754848480225, "step": 134000}
{"episode_reward": 963.0945163813872, "episode": 135.0, "batch_reward": 0.8284158187508583, "critic_loss": 0.9610253670215607, "actor_loss": -84.47613119506836, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.904603004455566, "step": 135000}
{"episode_reward": 892.3673571179033, "episode": 136.0, "batch_reward": 0.8301456189751625, "critic_loss": 0.953673080086708, "actor_loss": -84.465822265625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.621816396713257, "step": 136000}
{"episode_reward": 862.7992545680869, "episode": 137.0, "batch_reward": 0.8312727712988853, "critic_loss": 0.9265943162739277, "actor_loss": -84.63745475769043, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.637134790420532, "step": 137000}
{"episode_reward": 901.69316040929, "episode": 138.0, "batch_reward": 0.8313507534265518, "critic_loss": 0.9019869745075703, "actor_loss": -84.69576403808594, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.558427333831787, "step": 138000}
{"episode_reward": 961.5426924291002, "episode": 139.0, "batch_reward": 0.830842722594738, "critic_loss": 0.9643192867338657, "actor_loss": -84.45022566223145, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.29681396484375, "step": 139000}
{"episode_reward": 931.7518287022425, "episode": 140.0, "batch_reward": 0.8316945895552635, "critic_loss": 0.9775302325487136, "actor_loss": -84.70265361022949, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.167804956436157, "step": 140000}
{"episode_reward": 874.5264227553845, "episode": 141.0, "batch_reward": 0.8338851774930954, "critic_loss": 0.9064179884791375, "actor_loss": -84.72900942993164, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.41864728927612, "step": 141000}
{"episode_reward": 903.1256957202231, "episode": 142.0, "batch_reward": 0.8339567402601242, "critic_loss": 0.9511632112562657, "actor_loss": -84.65968739318848, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.476792335510254, "step": 142000}
{"episode_reward": 950.9431480952404, "episode": 143.0, "batch_reward": 0.8325547623038292, "critic_loss": 0.9648943287730217, "actor_loss": -84.68200756835938, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.54374623298645, "step": 143000}
{"episode_reward": 886.6491404117, "episode": 144.0, "batch_reward": 0.8343280762434006, "critic_loss": 0.9438964047729969, "actor_loss": -84.8346626586914, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.643908977508545, "step": 144000}
{"episode_reward": 895.8059544868222, "episode": 145.0, "batch_reward": 0.8354806962013245, "critic_loss": 0.9788734481036663, "actor_loss": -84.83583979797363, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.806196928024292, "step": 145000}
{"episode_reward": 926.0436273788634, "episode": 146.0, "batch_reward": 0.834374064207077, "critic_loss": 0.94197949847579, "actor_loss": -84.67924792480468, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.53740382194519, "step": 146000}
{"episode_reward": 914.9243980193975, "episode": 147.0, "batch_reward": 0.8349324178695678, "critic_loss": 0.9489034070372582, "actor_loss": -84.85575546264648, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.448704719543457, "step": 147000}
{"episode_reward": 921.9467136108132, "episode": 148.0, "batch_reward": 0.8360595198869705, "critic_loss": 0.984294927984476, "actor_loss": -84.83269598388672, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.274839401245117, "step": 148000}
{"episode_reward": 868.4795060838622, "episode": 149.0, "batch_reward": 0.8383757127523422, "critic_loss": 0.9648801229298115, "actor_loss": -84.92788163757324, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.435649871826172, "step": 149000}
{"episode_reward": 919.3122142564761, "episode": 150.0, "batch_reward": 0.8383067585229874, "critic_loss": 1.0924556361734867, "actor_loss": -84.9979468536377, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "step": 150000}
