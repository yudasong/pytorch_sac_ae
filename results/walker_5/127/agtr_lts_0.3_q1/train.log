{"episode_reward": 0.0, "episode": 1.0, "duration": 22.046078205108643, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.910201072692871, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.4100535879356935, "critic_loss": 0.1462941095832314, "actor_loss": -26.727217816015784, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 64.47569179534912, "step": 3000}
{"episode_reward": 55.62099584587951, "episode": 4.0, "batch_reward": 0.2741036627590656, "critic_loss": 0.5506246444433928, "actor_loss": -29.163572709083557, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.921331644058228, "step": 4000}
{"episode_reward": 101.34417859072249, "episode": 5.0, "batch_reward": 0.2309136614650488, "critic_loss": 0.4497167559862137, "actor_loss": -28.942537408828734, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.66803550720215, "step": 5000}
{"episode_reward": 13.356203036425642, "episode": 6.0, "batch_reward": 0.19433098870515825, "critic_loss": 0.5024428779035807, "actor_loss": -30.85084977531433, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.26127290725708, "step": 6000}
{"episode_reward": 45.978371315116554, "episode": 7.0, "batch_reward": 0.2018592369556427, "critic_loss": 1.052068305760622, "actor_loss": -31.003790229797364, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.274462699890137, "step": 7000}
{"episode_reward": 398.1146300455513, "episode": 8.0, "batch_reward": 0.21740370345115662, "critic_loss": 1.6471381370425224, "actor_loss": -35.44476591491699, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.766698598861694, "step": 8000}
{"episode_reward": 280.4442906658389, "episode": 9.0, "batch_reward": 0.23441493001580238, "critic_loss": 1.8004829143881798, "actor_loss": -39.21474948501587, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.87539792060852, "step": 9000}
{"episode_reward": 419.51715690225257, "episode": 10.0, "batch_reward": 0.2514241499453783, "critic_loss": 2.2270399421453475, "actor_loss": -41.845391830444335, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.121241331100464, "step": 10000}
{"episode_reward": 459.4152559316337, "episode": 11.0, "batch_reward": 0.2814572141468525, "critic_loss": 2.589830140709877, "actor_loss": -46.62439653778076, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.08860635757446, "step": 11000}
{"episode_reward": 722.5115621924205, "episode": 12.0, "batch_reward": 0.3207571588754654, "critic_loss": 2.421031158924103, "actor_loss": -50.074597564697264, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.222910404205322, "step": 12000}
{"episode_reward": 702.9411465446897, "episode": 13.0, "batch_reward": 0.34932636335492134, "critic_loss": 2.3224114702939986, "actor_loss": -51.65149257659912, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.222091674804688, "step": 13000}
{"episode_reward": 699.735524633973, "episode": 14.0, "batch_reward": 0.38053060066699984, "critic_loss": 2.317282606601715, "actor_loss": -55.26043158721924, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.15627884864807, "step": 14000}
{"episode_reward": 737.2703638658377, "episode": 15.0, "batch_reward": 0.40880655056238174, "critic_loss": 2.113910392165184, "actor_loss": -57.68288910675049, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.360031366348267, "step": 15000}
{"episode_reward": 883.0757576367885, "episode": 16.0, "batch_reward": 0.43606179386377336, "critic_loss": 1.8936337410211563, "actor_loss": -60.333030418396, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.386208057403564, "step": 16000}
{"episode_reward": 840.5762596719035, "episode": 17.0, "batch_reward": 0.46422346115112306, "critic_loss": 1.7146775897741318, "actor_loss": -62.418230514526364, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.09644079208374, "step": 17000}
{"episode_reward": 883.0538482770011, "episode": 18.0, "batch_reward": 0.4845260395407677, "critic_loss": 1.6499326753616332, "actor_loss": -64.08690416717529, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.719180822372437, "step": 18000}
{"episode_reward": 858.6879797155545, "episode": 19.0, "batch_reward": 0.5027194072008133, "critic_loss": 1.5827737070322037, "actor_loss": -65.67348931884766, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.838579654693604, "step": 19000}
{"episode_reward": 824.2202997069915, "episode": 20.0, "batch_reward": 0.5260720503330231, "critic_loss": 1.504891602396965, "actor_loss": -67.79112120056152, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.960418701171875, "step": 20000}
{"episode_reward": 855.2997792285222, "episode": 21.0, "batch_reward": 0.5408473263680935, "critic_loss": 1.5008707010746003, "actor_loss": -68.79174980163575, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.702643632888794, "step": 21000}
{"episode_reward": 876.2914604899493, "episode": 22.0, "batch_reward": 0.5576368333399295, "critic_loss": 1.450809860765934, "actor_loss": -70.86027639770508, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.079479455947876, "step": 22000}
{"episode_reward": 921.8266330577204, "episode": 23.0, "batch_reward": 0.5740496850311756, "critic_loss": 1.4312573058605194, "actor_loss": -71.5986043548584, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.31489586830139, "step": 23000}
{"episode_reward": 896.0723499096048, "episode": 24.0, "batch_reward": 0.5846925860345363, "critic_loss": 1.4234090357422828, "actor_loss": -72.59640017700195, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.603053331375122, "step": 24000}
{"episode_reward": 883.2617816731266, "episode": 25.0, "batch_reward": 0.5975183928310871, "critic_loss": 1.4491717888712883, "actor_loss": -73.2159517211914, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.38676643371582, "step": 25000}
{"episode_reward": 853.2908352838647, "episode": 26.0, "batch_reward": 0.6081507162749767, "critic_loss": 1.2695783696770668, "actor_loss": -73.81957762145996, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.358530282974243, "step": 26000}
{"episode_reward": 947.3369739687765, "episode": 27.0, "batch_reward": 0.622375799536705, "critic_loss": 1.1632863171696664, "actor_loss": -74.73395649719238, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.300846815109253, "step": 27000}
{"episode_reward": 934.4788798805523, "episode": 28.0, "batch_reward": 0.6334954993724823, "critic_loss": 1.1134687892198563, "actor_loss": -75.62595579528809, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.551159858703613, "step": 28000}
{"episode_reward": 889.0464847521725, "episode": 29.0, "batch_reward": 0.6408819450736046, "critic_loss": 1.0056609517931938, "actor_loss": -75.86424853515625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.131190061569214, "step": 29000}
{"episode_reward": 907.545765701829, "episode": 30.0, "batch_reward": 0.6540247865319252, "critic_loss": 0.9878380333185196, "actor_loss": -76.30516899108886, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.896024465560913, "step": 30000}
{"episode_reward": 886.3297086300287, "episode": 31.0, "batch_reward": 0.6570733913779259, "critic_loss": 0.9623674067854882, "actor_loss": -76.70292449951172, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.3108127117157, "step": 31000}
{"episode_reward": 903.6255789550585, "episode": 32.0, "batch_reward": 0.6636406419277191, "critic_loss": 0.9388220728337765, "actor_loss": -77.18699491882325, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.8658607006073, "step": 32000}
{"episode_reward": 753.5208148887918, "episode": 33.0, "batch_reward": 0.6694376403689385, "critic_loss": 0.914978090852499, "actor_loss": -77.47352743530273, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.34276294708252, "step": 33000}
{"episode_reward": 926.0311796467274, "episode": 34.0, "batch_reward": 0.6780192989706993, "critic_loss": 0.9145279981195926, "actor_loss": -77.62024209594726, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.0060453414917, "step": 34000}
{"episode_reward": 963.7046553406566, "episode": 35.0, "batch_reward": 0.6851228347420693, "critic_loss": 0.8789089889228344, "actor_loss": -78.03027122497559, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.91619324684143, "step": 35000}
{"episode_reward": 899.6761572041937, "episode": 36.0, "batch_reward": 0.6890319303870202, "critic_loss": 0.8223239697217941, "actor_loss": -78.26261991882325, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.1645610332489, "step": 36000}
{"episode_reward": 844.5731458252155, "episode": 37.0, "batch_reward": 0.6969195518493653, "critic_loss": 0.8329349954128266, "actor_loss": -78.36491374206543, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.64223027229309, "step": 37000}
{"episode_reward": 956.9505610006914, "episode": 38.0, "batch_reward": 0.7026514092683792, "critic_loss": 0.7776271593272686, "actor_loss": -78.64836622619629, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.844361782073975, "step": 38000}
{"episode_reward": 951.6905905867518, "episode": 39.0, "batch_reward": 0.7096299710869789, "critic_loss": 0.7602868947684764, "actor_loss": -79.04534017944336, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.251142024993896, "step": 39000}
{"episode_reward": 953.8033502538024, "episode": 40.0, "batch_reward": 0.7159651859402657, "critic_loss": 0.7388332520127296, "actor_loss": -79.34532858276367, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.429703950881958, "step": 40000}
{"episode_reward": 966.6172510173849, "episode": 41.0, "batch_reward": 0.7220501935482025, "critic_loss": 0.7467555256187915, "actor_loss": -79.67501385498046, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.1535439491272, "step": 41000}
{"episode_reward": 962.0973152480266, "episode": 42.0, "batch_reward": 0.7278031361103058, "critic_loss": 0.7552395947873592, "actor_loss": -80.12458261108398, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.275104522705078, "step": 42000}
{"episode_reward": 935.692003170724, "episode": 43.0, "batch_reward": 0.7323866552114486, "critic_loss": 0.7038012702167035, "actor_loss": -80.41715834045411, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.33807373046875, "step": 43000}
{"episode_reward": 962.1121555924857, "episode": 44.0, "batch_reward": 0.7371760274171829, "critic_loss": 0.6948368511795998, "actor_loss": -80.67923245239258, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.272397756576538, "step": 44000}
{"episode_reward": 968.2077665803096, "episode": 45.0, "batch_reward": 0.7424303857088089, "critic_loss": 0.7011989689171314, "actor_loss": -80.93442156982422, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.27841019630432, "step": 45000}
{"episode_reward": 965.0069211029643, "episode": 46.0, "batch_reward": 0.7465495042204857, "critic_loss": 0.6292638205587864, "actor_loss": -81.17555140686035, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.722587823867798, "step": 46000}
{"episode_reward": 969.0907035012264, "episode": 47.0, "batch_reward": 0.7524419767260552, "critic_loss": 0.6764848864078522, "actor_loss": -81.43104454040527, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.067987203598022, "step": 47000}
{"episode_reward": 939.774279837792, "episode": 48.0, "batch_reward": 0.75809779971838, "critic_loss": 0.6718131692409516, "actor_loss": -81.73640731811524, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.90998888015747, "step": 48000}
{"episode_reward": 952.7801599169645, "episode": 49.0, "batch_reward": 0.7617697615623474, "critic_loss": 0.6593754150271416, "actor_loss": -81.99298979187012, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.254283905029297, "step": 49000}
{"episode_reward": 949.887850358109, "episode": 50.0, "batch_reward": 0.7622891045212745, "critic_loss": 0.6481170938909053, "actor_loss": -82.10502156066894, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.306663036346436, "step": 50000}
{"episode_reward": 855.5918785528388, "episode": 51.0, "batch_reward": 0.7656143047213554, "critic_loss": 0.637943370372057, "actor_loss": -82.4298642425537, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.35349154472351, "step": 51000}
{"episode_reward": 926.6730636583613, "episode": 52.0, "batch_reward": 0.7688805981278419, "critic_loss": 0.6339451835751534, "actor_loss": -82.52411630249023, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.8818838596344, "step": 52000}
{"episode_reward": 936.7420228590278, "episode": 53.0, "batch_reward": 0.7714707392454148, "critic_loss": 0.6668732274472714, "actor_loss": -82.70083082580567, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.63996911048889, "step": 53000}
{"episode_reward": 970.9831133741869, "episode": 54.0, "batch_reward": 0.7762906212210655, "critic_loss": 0.6269055510759354, "actor_loss": -82.9386847076416, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.56038188934326, "step": 54000}
{"episode_reward": 890.9029944473659, "episode": 55.0, "batch_reward": 0.7771237816810608, "critic_loss": 0.5837974062561989, "actor_loss": -83.0179842376709, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.865979194641113, "step": 55000}
{"episode_reward": 936.9326131815498, "episode": 56.0, "batch_reward": 0.7806831395030022, "critic_loss": 0.600380060583353, "actor_loss": -83.19703981018067, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.24905753135681, "step": 56000}
{"episode_reward": 910.9414916391768, "episode": 57.0, "batch_reward": 0.7834564874768257, "critic_loss": 0.601526372730732, "actor_loss": -83.27656079101563, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.40274953842163, "step": 57000}
{"episode_reward": 949.5337028266598, "episode": 58.0, "batch_reward": 0.7844439588189125, "critic_loss": 0.5904941165149212, "actor_loss": -83.39894932556152, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.192246198654175, "step": 58000}
{"episode_reward": 898.4184787683613, "episode": 59.0, "batch_reward": 0.7894183855652809, "critic_loss": 0.6541637624800205, "actor_loss": -83.56328643798828, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.174824476242065, "step": 59000}
{"episode_reward": 960.3429334962788, "episode": 60.0, "batch_reward": 0.7911673506498337, "critic_loss": 0.6142734302282333, "actor_loss": -83.7683519744873, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.158321380615234, "step": 60000}
{"episode_reward": 967.3019031719739, "episode": 61.0, "batch_reward": 0.7942263582348823, "critic_loss": 0.5967916752099991, "actor_loss": -83.92430868530273, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.15490651130676, "step": 61000}
{"episode_reward": 918.6052842914081, "episode": 62.0, "batch_reward": 0.7964626291394233, "critic_loss": 0.5795327104926109, "actor_loss": -84.010105758667, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.3895320892334, "step": 62000}
{"episode_reward": 915.8872805359916, "episode": 63.0, "batch_reward": 0.7979431027770042, "critic_loss": 0.5681462372839451, "actor_loss": -84.29616226196289, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.452199697494507, "step": 63000}
{"episode_reward": 970.3181444660088, "episode": 64.0, "batch_reward": 0.8008047909140587, "critic_loss": 0.5678463607132435, "actor_loss": -84.41671069335938, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.099247932434082, "step": 64000}
{"episode_reward": 926.6811454340026, "episode": 65.0, "batch_reward": 0.8024465485811233, "critic_loss": 0.5781123865544796, "actor_loss": -84.54734954833984, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.041552543640137, "step": 65000}
{"episode_reward": 958.2661819905694, "episode": 66.0, "batch_reward": 0.8032480861544609, "critic_loss": 0.5132128300964832, "actor_loss": -84.62770204162598, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.000250101089478, "step": 66000}
{"episode_reward": 869.9121451023165, "episode": 67.0, "batch_reward": 0.8052256475687027, "critic_loss": 0.5984675159156323, "actor_loss": -84.65646997070313, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.217633485794067, "step": 67000}
{"episode_reward": 867.4476246297596, "episode": 68.0, "batch_reward": 0.807370776951313, "critic_loss": 0.5804836459159851, "actor_loss": -84.7674063873291, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.03846311569214, "step": 68000}
{"episode_reward": 947.8544374606441, "episode": 69.0, "batch_reward": 0.8079863127470016, "critic_loss": 0.6083705505430699, "actor_loss": -85.00101200866699, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.23998212814331, "step": 69000}
{"episode_reward": 931.8393163619853, "episode": 70.0, "batch_reward": 0.8108271416425705, "critic_loss": 0.5896643494665623, "actor_loss": -84.94640013122559, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.324292421340942, "step": 70000}
{"episode_reward": 924.9241182108963, "episode": 71.0, "batch_reward": 0.8114992517828942, "critic_loss": 0.6121829404234886, "actor_loss": -85.03960360717774, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.50751090049744, "step": 71000}
{"episode_reward": 929.7141991881155, "episode": 72.0, "batch_reward": 0.8149122877120971, "critic_loss": 0.5917826203107834, "actor_loss": -85.2277004699707, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.925745248794556, "step": 72000}
{"episode_reward": 972.9044363114155, "episode": 73.0, "batch_reward": 0.8167161468863487, "critic_loss": 0.5789064575135708, "actor_loss": -85.28885977172851, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.86386728286743, "step": 73000}
{"episode_reward": 932.1431298021247, "episode": 74.0, "batch_reward": 0.8170305327177048, "critic_loss": 0.6155834316015244, "actor_loss": -85.3174870300293, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.185213088989258, "step": 74000}
{"episode_reward": 961.6710339658325, "episode": 75.0, "batch_reward": 0.818956840634346, "critic_loss": 0.6191712172627449, "actor_loss": -85.56023240661621, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.462775468826294, "step": 75000}
{"episode_reward": 922.4463908015454, "episode": 76.0, "batch_reward": 0.8202890428900719, "critic_loss": 0.588877612888813, "actor_loss": -85.55601110839844, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.223263025283813, "step": 76000}
{"episode_reward": 930.8380078521908, "episode": 77.0, "batch_reward": 0.8205432354211807, "critic_loss": 0.6159743078500033, "actor_loss": -85.65088566589355, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.221198081970215, "step": 77000}
{"episode_reward": 905.2155574968564, "episode": 78.0, "batch_reward": 0.8241533412337303, "critic_loss": 0.5852575802505017, "actor_loss": -85.80893421936035, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.248606204986572, "step": 78000}
{"episode_reward": 967.3349466103394, "episode": 79.0, "batch_reward": 0.8255071180462837, "critic_loss": 0.566759047344327, "actor_loss": -85.80784281921386, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.340314626693726, "step": 79000}
{"episode_reward": 930.7104360374107, "episode": 80.0, "batch_reward": 0.8267529976963996, "critic_loss": 0.5319958858042956, "actor_loss": -85.93498225402833, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.354763984680176, "step": 80000}
{"episode_reward": 973.4640970175832, "episode": 81.0, "batch_reward": 0.8303352734446525, "critic_loss": 0.5518091270327568, "actor_loss": -86.03792808532715, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.219817876815796, "step": 81000}
{"episode_reward": 969.6862806877571, "episode": 82.0, "batch_reward": 0.8295439217686653, "critic_loss": 0.5572063684016466, "actor_loss": -86.20395877075195, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.414151430130005, "step": 82000}
{"episode_reward": 932.0372510515239, "episode": 83.0, "batch_reward": 0.8337184162735939, "critic_loss": 0.5351029473692178, "actor_loss": -86.16726411437989, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.955252170562744, "step": 83000}
{"episode_reward": 969.9777549204313, "episode": 84.0, "batch_reward": 0.8334332186579704, "critic_loss": 0.5594226185977459, "actor_loss": -86.34699429321289, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.14127278327942, "step": 84000}
{"episode_reward": 933.3812696432185, "episode": 85.0, "batch_reward": 0.8328850236535073, "critic_loss": 0.5873163701891899, "actor_loss": -86.2863586730957, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.897793769836426, "step": 85000}
{"episode_reward": 913.7125382178267, "episode": 86.0, "batch_reward": 0.836674571454525, "critic_loss": 0.5109219929277897, "actor_loss": -86.457002243042, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.880144834518433, "step": 86000}
{"episode_reward": 974.1796092305535, "episode": 87.0, "batch_reward": 0.8370871905684472, "critic_loss": 0.5407452235072852, "actor_loss": -86.48354534912109, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.360486030578613, "step": 87000}
{"episode_reward": 977.3481258551993, "episode": 88.0, "batch_reward": 0.8385883528590202, "critic_loss": 0.6005153756290674, "actor_loss": -86.79226188659668, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.423526525497437, "step": 88000}
{"episode_reward": 959.7555296435465, "episode": 89.0, "batch_reward": 0.8409078782200813, "critic_loss": 0.55682294498384, "actor_loss": -86.9673451538086, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.271826028823853, "step": 89000}
{"episode_reward": 917.8244923260246, "episode": 90.0, "batch_reward": 0.8416768060326576, "critic_loss": 0.543933305233717, "actor_loss": -87.06307371520997, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.247575044631958, "step": 90000}
{"episode_reward": 919.1838205142125, "episode": 91.0, "batch_reward": 0.842290888786316, "critic_loss": 0.5391087313592434, "actor_loss": -87.30600103759765, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.44190311431885, "step": 91000}
{"episode_reward": 964.7152015958817, "episode": 92.0, "batch_reward": 0.8424875162243843, "critic_loss": 0.5412806396633386, "actor_loss": -87.32943437194824, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.333240270614624, "step": 92000}
{"episode_reward": 923.9643377311942, "episode": 93.0, "batch_reward": 0.8426048884987831, "critic_loss": 0.5698221443593502, "actor_loss": -87.46999229431152, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.064705848693848, "step": 93000}
{"episode_reward": 968.3281719886635, "episode": 94.0, "batch_reward": 0.8450093964934349, "critic_loss": 0.5346283461004495, "actor_loss": -87.58573191833496, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.92704749107361, "step": 94000}
{"episode_reward": 945.48345704394, "episode": 95.0, "batch_reward": 0.8462892006635666, "critic_loss": 0.5194002586007118, "actor_loss": -87.49292387390136, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.6047625541687, "step": 95000}
{"episode_reward": 911.3230448979523, "episode": 96.0, "batch_reward": 0.8483929362893105, "critic_loss": 0.5230055222511292, "actor_loss": -87.79328089904786, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.880446195602417, "step": 96000}
{"episode_reward": 959.3017019448592, "episode": 97.0, "batch_reward": 0.8472180356383323, "critic_loss": 0.5314718696177005, "actor_loss": -87.75328894042968, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.250763416290283, "step": 97000}
{"episode_reward": 977.4725113270704, "episode": 98.0, "batch_reward": 0.8497860472798348, "critic_loss": 0.5239387001097202, "actor_loss": -87.60038720703125, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.966193914413452, "step": 98000}
{"episode_reward": 975.6673099464914, "episode": 99.0, "batch_reward": 0.8513559898734093, "critic_loss": 0.4766133994013071, "actor_loss": -87.81950050354004, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.8731689453125, "step": 99000}
{"episode_reward": 980.1995991410271, "episode": 100.0, "batch_reward": 0.8523298744559288, "critic_loss": 0.5084773171395064, "actor_loss": -87.89815861511231, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.282342433929443, "step": 100000}
{"episode_reward": 974.7397800949593, "episode": 101.0, "batch_reward": 0.852725524187088, "critic_loss": 0.5123913334906102, "actor_loss": -88.19437696838379, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.58434438705444, "step": 101000}
{"episode_reward": 958.4326765313159, "episode": 102.0, "batch_reward": 0.8543338932394982, "critic_loss": 0.5839236019402743, "actor_loss": -88.08464813232422, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.394307613372803, "step": 102000}
{"episode_reward": 973.4171284371705, "episode": 103.0, "batch_reward": 0.8553844611048699, "critic_loss": 0.5136374996751547, "actor_loss": -88.17916343688965, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.2614848613739, "step": 103000}
{"episode_reward": 974.7030447943197, "episode": 104.0, "batch_reward": 0.8565271699428558, "critic_loss": 0.49980610243976115, "actor_loss": -88.39976069641114, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.908430099487305, "step": 104000}
{"episode_reward": 966.0596193691279, "episode": 105.0, "batch_reward": 0.8582691150903702, "critic_loss": 0.5100535903424025, "actor_loss": -88.46396446228027, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.97988796234131, "step": 105000}
{"episode_reward": 929.0067379862639, "episode": 106.0, "batch_reward": 0.8583883491158485, "critic_loss": 0.5323129203766584, "actor_loss": -88.48635757446289, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.681554555892944, "step": 106000}
{"episode_reward": 973.8806562293753, "episode": 107.0, "batch_reward": 0.8592236530780792, "critic_loss": 0.5200378031730651, "actor_loss": -88.58290319824219, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.884011268615723, "step": 107000}
{"episode_reward": 948.7716897307728, "episode": 108.0, "batch_reward": 0.859362062573433, "critic_loss": 0.5196331765502691, "actor_loss": -88.43103086853027, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.766650199890137, "step": 108000}
{"episode_reward": 881.0711104133493, "episode": 109.0, "batch_reward": 0.8608001445531845, "critic_loss": 0.5351726316809654, "actor_loss": -88.72036251831055, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.11166024208069, "step": 109000}
{"episode_reward": 938.9612346215331, "episode": 110.0, "batch_reward": 0.8600699912905693, "critic_loss": 0.5280381329804659, "actor_loss": -88.44386315917968, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.928674459457397, "step": 110000}
{"episode_reward": 925.7086224269594, "episode": 111.0, "batch_reward": 0.8618288244009018, "critic_loss": 0.520914280116558, "actor_loss": -88.70219483947754, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.63343334197998, "step": 111000}
{"episode_reward": 975.0404504918066, "episode": 112.0, "batch_reward": 0.8625033943653106, "critic_loss": 0.4879310215562582, "actor_loss": -88.60158624267578, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.89005208015442, "step": 112000}
{"episode_reward": 966.261374068253, "episode": 113.0, "batch_reward": 0.8630333184599877, "critic_loss": 0.4886815287619829, "actor_loss": -88.7878052520752, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.42971444129944, "step": 113000}
{"episode_reward": 951.9510085808004, "episode": 114.0, "batch_reward": 0.8656244115829468, "critic_loss": 0.5429466810673476, "actor_loss": -88.70021217346192, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.918219089508057, "step": 114000}
{"episode_reward": 914.1277112024051, "episode": 115.0, "batch_reward": 0.8657612300515175, "critic_loss": 0.4878347952067852, "actor_loss": -88.65926187133789, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.901052951812744, "step": 115000}
{"episode_reward": 950.688994379866, "episode": 116.0, "batch_reward": 0.8657786598205567, "critic_loss": 0.5121866738051176, "actor_loss": -88.69878742980957, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.372316122055054, "step": 116000}
{"episode_reward": 976.6465008006157, "episode": 117.0, "batch_reward": 0.8677491046190262, "critic_loss": 0.5090209171622991, "actor_loss": -88.87808959960938, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.107452630996704, "step": 117000}
{"episode_reward": 973.824642381827, "episode": 118.0, "batch_reward": 0.8667727010846138, "critic_loss": 0.4725328423678875, "actor_loss": -88.88620622253418, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.06160306930542, "step": 118000}
{"episode_reward": 923.4542724687329, "episode": 119.0, "batch_reward": 0.8687720431685447, "critic_loss": 0.48918387293815613, "actor_loss": -89.01677745056152, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.85082197189331, "step": 119000}
{"episode_reward": 941.2809832139162, "episode": 120.0, "batch_reward": 0.8683094301819801, "critic_loss": 0.498373350456357, "actor_loss": -88.9826353149414, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.967463970184326, "step": 120000}
{"episode_reward": 982.512560836165, "episode": 121.0, "batch_reward": 0.8697735258340835, "critic_loss": 0.48827866914868356, "actor_loss": -89.0484115600586, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.698856830596924, "step": 121000}
{"episode_reward": 931.8208319276589, "episode": 122.0, "batch_reward": 0.8708702330589294, "critic_loss": 0.49076480965316294, "actor_loss": -88.94393449401855, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.857512712478638, "step": 122000}
{"episode_reward": 904.9327697004785, "episode": 123.0, "batch_reward": 0.8707430104613304, "critic_loss": 0.5279769395887852, "actor_loss": -88.96788722229005, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.916215658187866, "step": 123000}
{"episode_reward": 974.8738326401224, "episode": 124.0, "batch_reward": 0.8714059209823608, "critic_loss": 0.4977395568042994, "actor_loss": -88.91330493164062, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.195550441741943, "step": 124000}
{"episode_reward": 948.0237379782592, "episode": 125.0, "batch_reward": 0.870508432328701, "critic_loss": 0.5089888228029013, "actor_loss": -88.84086433410644, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.808231115341187, "step": 125000}
{"episode_reward": 938.1464277698094, "episode": 126.0, "batch_reward": 0.8713256892561912, "critic_loss": 0.46320508094131946, "actor_loss": -88.85734968566895, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.908027172088623, "step": 126000}
{"episode_reward": 972.9499169596298, "episode": 127.0, "batch_reward": 0.8723877566456795, "critic_loss": 0.5046534960269928, "actor_loss": -88.69903971862793, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.979258060455322, "step": 127000}
{"episode_reward": 948.9464468249158, "episode": 128.0, "batch_reward": 0.8732722675800324, "critic_loss": 0.4847227873802185, "actor_loss": -88.9421565246582, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.404658317565918, "step": 128000}
{"episode_reward": 958.6318889923876, "episode": 129.0, "batch_reward": 0.8743153458237648, "critic_loss": 0.47125686942040923, "actor_loss": -88.98758633422851, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.37840223312378, "step": 129000}
{"episode_reward": 979.271988655737, "episode": 130.0, "batch_reward": 0.8745070533156395, "critic_loss": 0.45871112652122975, "actor_loss": -89.03162171936034, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.283184051513672, "step": 130000}
{"episode_reward": 919.5243914374238, "episode": 131.0, "batch_reward": 0.87533314961195, "critic_loss": 0.4813399771749973, "actor_loss": -89.1689072113037, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.82025694847107, "step": 131000}
{"episode_reward": 945.094694262175, "episode": 132.0, "batch_reward": 0.8754852370619773, "critic_loss": 0.5114749963581562, "actor_loss": -89.14035882568359, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.196129083633423, "step": 132000}
{"episode_reward": 956.7288871997291, "episode": 133.0, "batch_reward": 0.8770341790914535, "critic_loss": 0.48890035444498064, "actor_loss": -89.39392147827148, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.0735821723938, "step": 133000}
{"episode_reward": 979.9384045900064, "episode": 134.0, "batch_reward": 0.8778181719779968, "critic_loss": 0.4471008652895689, "actor_loss": -89.23413835144044, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.405282974243164, "step": 134000}
{"episode_reward": 975.7721937433912, "episode": 135.0, "batch_reward": 0.8756568086147308, "critic_loss": 0.43262620002031327, "actor_loss": -89.0286586151123, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.345778942108154, "step": 135000}
{"episode_reward": 940.6848337433819, "episode": 136.0, "batch_reward": 0.8791276177763939, "critic_loss": 0.4413518286049366, "actor_loss": -89.3182868347168, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.37939739227295, "step": 136000}
{"episode_reward": 907.2323621555217, "episode": 137.0, "batch_reward": 0.8803245507478714, "critic_loss": 0.4528761957883835, "actor_loss": -89.21760096740722, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.742685556411743, "step": 137000}
{"episode_reward": 931.5511146570508, "episode": 138.0, "batch_reward": 0.8790283622145653, "critic_loss": 0.46228973944485185, "actor_loss": -89.24626936340331, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.261417150497437, "step": 138000}
{"episode_reward": 980.1701600169389, "episode": 139.0, "batch_reward": 0.8798868294358253, "critic_loss": 0.45515340285003186, "actor_loss": -89.39680551147461, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.911445379257202, "step": 139000}
{"episode_reward": 943.5525108879045, "episode": 140.0, "batch_reward": 0.8784419703483581, "critic_loss": 0.44350562085211276, "actor_loss": -89.3811877746582, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.284931182861328, "step": 140000}
{"episode_reward": 925.2248438047677, "episode": 141.0, "batch_reward": 0.8822438387870789, "critic_loss": 0.4347470267266035, "actor_loss": -89.41634786987305, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.92461013793945, "step": 141000}
{"episode_reward": 926.4736651388209, "episode": 142.0, "batch_reward": 0.8817225129604339, "critic_loss": 0.45076423744857314, "actor_loss": -89.49539399719238, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.851510763168335, "step": 142000}
{"episode_reward": 973.2727878261114, "episode": 143.0, "batch_reward": 0.8816728309988976, "critic_loss": 0.4224049821048975, "actor_loss": -89.50937608337402, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.820546865463257, "step": 143000}
{"episode_reward": 960.4824205266063, "episode": 144.0, "batch_reward": 0.8821628776192665, "critic_loss": 0.4108334907144308, "actor_loss": -89.42306893920899, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.069921731948853, "step": 144000}
{"episode_reward": 939.6665702309709, "episode": 145.0, "batch_reward": 0.8832853707075119, "critic_loss": 0.4453714449107647, "actor_loss": -89.48095379638671, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.33329439163208, "step": 145000}
{"episode_reward": 956.1117466328857, "episode": 146.0, "batch_reward": 0.8825492480993271, "critic_loss": 0.406412769459188, "actor_loss": -89.64214671325684, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.28161120414734, "step": 146000}
{"episode_reward": 933.3613106811492, "episode": 147.0, "batch_reward": 0.8826860558986663, "critic_loss": 0.38616782520711423, "actor_loss": -89.66297329711914, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.687074184417725, "step": 147000}
{"episode_reward": 955.1657633976334, "episode": 148.0, "batch_reward": 0.8847636131048202, "critic_loss": 0.38777367839217186, "actor_loss": -89.6981785736084, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.119856595993042, "step": 148000}
{"episode_reward": 934.0653901052278, "episode": 149.0, "batch_reward": 0.8838811408281326, "critic_loss": 0.4212337114363909, "actor_loss": -89.84800671386719, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.955033779144287, "step": 149000}
{"episode_reward": 945.8225169925147, "episode": 150.0, "batch_reward": 0.8850347527861595, "critic_loss": 0.4248641147315502, "actor_loss": -89.48605737304688, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "step": 150000}
