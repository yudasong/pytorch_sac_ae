{"episode": 1.0, "duration": 21.0746591091156, "episode_reward": 61.50603977848499, "step": 1000}
{"episode": 2.0, "duration": 2.2000863552093506, "episode_reward": 808.9209525976895, "step": 2000}
{"episode": 3.0, "batch_reward": 0.4266369145844292, "actor_loss": -76.17039781305589, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 66.4665732383728, "episode_reward": 336.8975517269101, "step": 3000}
{"episode": 4.0, "batch_reward": 0.41078757989406584, "actor_loss": -76.71928283691406, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.462446689605713, "episode_reward": 619.7219018992922, "step": 4000}
{"episode": 5.0, "batch_reward": 0.4776390267908573, "actor_loss": -78.08505848693848, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.024794101715088, "episode_reward": 766.9456047797462, "step": 5000}
{"episode": 6.0, "batch_reward": 0.547342846184969, "actor_loss": -79.57272581481934, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.775941848754883, "episode_reward": 894.1093788273981, "step": 6000}
{"episode": 7.0, "batch_reward": 0.5932613249123097, "actor_loss": -80.67729223632813, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.478535413742065, "episode_reward": 838.0969875501337, "step": 7000}
{"episode": 8.0, "batch_reward": 0.625801039725542, "actor_loss": -81.5457299041748, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.175569534301758, "episode_reward": 830.904123784329, "step": 8000}
{"episode": 9.0, "batch_reward": 0.6607834817171097, "actor_loss": -82.32287579345703, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.212809801101685, "episode_reward": 945.0816892571722, "step": 9000}
{"episode": 10.0, "batch_reward": 0.6823033106923103, "actor_loss": -82.6997519683838, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 18.783395528793335, "episode_reward": 791.7496203689442, "step": 10000}
{"episode": 11.0, "batch_reward": 0.6973999543190003, "actor_loss": -83.01689793395997, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.80932879447937, "episode_reward": 867.0805910758837, "step": 11000}
{"episode": 12.0, "batch_reward": 0.7100319476723671, "actor_loss": -83.35322244262696, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.356443881988525, "episode_reward": 867.0313489652807, "step": 12000}
{"episode": 13.0, "batch_reward": 0.7230425994992257, "actor_loss": -83.67488877868652, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.56180477142334, "episode_reward": 873.0119444051934, "step": 13000}
{"episode": 14.0, "batch_reward": 0.7333235908150673, "actor_loss": -83.92282579040527, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.76695990562439, "episode_reward": 842.4935262781173, "step": 14000}
{"episode": 15.0, "batch_reward": 0.740534321129322, "actor_loss": -84.08633659362793, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.519532203674316, "episode_reward": 857.2934090805561, "step": 15000}
{"episode": 16.0, "batch_reward": 0.7488445561528206, "actor_loss": -84.3101517791748, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.147959232330322, "episode_reward": 889.1494126550435, "step": 16000}
{"episode": 17.0, "batch_reward": 0.7570541434288025, "actor_loss": -84.47389039611816, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.17412757873535, "episode_reward": 833.3779698122576, "step": 17000}
{"episode": 18.0, "batch_reward": 0.7596026688218117, "actor_loss": -84.55694212341308, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.112979412078857, "episode_reward": 800.5464468996104, "step": 18000}
{"episode": 19.0, "batch_reward": 0.7651289800405502, "actor_loss": -84.71215928649903, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.90967893600464, "episode_reward": 904.3960743316866, "step": 19000}
{"episode": 20.0, "batch_reward": 0.7738243499398232, "actor_loss": -84.91953065490722, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 19.645657777786255, "episode_reward": 909.6529128055133, "step": 20000}
{"episode": 21.0, "batch_reward": 0.778279885172844, "actor_loss": -85.04125119018555, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.093679904937744, "episode_reward": 793.5294160945226, "step": 21000}
{"episode": 22.0, "batch_reward": 0.7781839265823364, "actor_loss": -85.04433486938477, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.137317180633545, "episode_reward": 875.5601478182208, "step": 22000}
{"episode": 23.0, "batch_reward": 0.7820782814621925, "actor_loss": -85.11695922851563, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.114602088928223, "episode_reward": 846.3314741784903, "step": 23000}
{"episode": 24.0, "batch_reward": 0.7840224169492721, "actor_loss": -85.16986485290528, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.668050289154053, "episode_reward": 826.4145714895234, "step": 24000}
{"episode": 25.0, "batch_reward": 0.783366867363453, "actor_loss": -85.18769073486328, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.611409187316895, "episode_reward": 791.3208679111319, "step": 25000}
{"episode": 26.0, "batch_reward": 0.7884093376994133, "actor_loss": -85.31768141174317, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.397191047668457, "episode_reward": 902.9906497574495, "step": 26000}
{"episode": 27.0, "batch_reward": 0.7924074547290803, "actor_loss": -85.42689599609375, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.51911163330078, "episode_reward": 918.825244615126, "step": 27000}
{"episode": 28.0, "batch_reward": 0.7964335289597512, "actor_loss": -85.53635736083984, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.974140644073486, "episode_reward": 842.688601077719, "step": 28000}
{"episode": 29.0, "batch_reward": 0.7968930847644806, "actor_loss": -85.5867467803955, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.729801654815674, "episode_reward": 828.687498948519, "step": 29000}
{"episode": 30.0, "batch_reward": 0.7990714304447174, "actor_loss": -85.57807330322265, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.096471309661865, "episode_reward": 833.6287116786638, "step": 30000}
{"episode": 31.0, "batch_reward": 0.7997290444970131, "actor_loss": -85.62226713562012, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.68326783180237, "episode_reward": 815.7656850316803, "step": 31000}
{"episode": 32.0, "batch_reward": 0.7990583896636962, "actor_loss": -85.63937379455567, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.57257866859436, "episode_reward": 805.8137715190411, "step": 32000}
{"episode": 33.0, "batch_reward": 0.8024022866487504, "actor_loss": -85.72162730407715, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.026896715164185, "episode_reward": 872.8548149096245, "step": 33000}
{"episode": 34.0, "batch_reward": 0.8041473005414009, "actor_loss": -85.72930653381347, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.42180061340332, "episode_reward": 875.3286393058266, "step": 34000}
{"episode": 35.0, "batch_reward": 0.8051828892230988, "actor_loss": -85.73999363708496, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.722553730010986, "episode_reward": 861.7496166042083, "step": 35000}
{"episode": 36.0, "batch_reward": 0.8075387927293778, "actor_loss": -85.85110134887695, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.18876600265503, "episode_reward": 850.07238041297, "step": 36000}
{"episode": 37.0, "batch_reward": 0.8109849776625633, "actor_loss": -85.95342149353027, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.545758485794067, "episode_reward": 891.7801688601987, "step": 37000}
{"episode": 38.0, "batch_reward": 0.8103895435929298, "actor_loss": -85.9489306640625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.343778371810913, "episode_reward": 815.564089728255, "step": 38000}
{"episode": 39.0, "batch_reward": 0.8103104861974716, "actor_loss": -86.02299923706055, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.366612672805786, "episode_reward": 882.9168670225756, "step": 39000}
{"episode": 40.0, "batch_reward": 0.8125321704149246, "actor_loss": -86.03092745971679, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.683778285980225, "episode_reward": 911.4999570992517, "step": 40000}
{"episode": 41.0, "batch_reward": 0.8138402267098427, "actor_loss": -86.04781550598145, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.51365518569946, "episode_reward": 835.5419548255945, "step": 41000}
{"episode": 42.0, "batch_reward": 0.8158073364496231, "actor_loss": -86.14775610351562, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.321815729141235, "episode_reward": 865.5212445611868, "step": 42000}
{"episode": 43.0, "batch_reward": 0.816066442668438, "actor_loss": -86.13704396057129, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.511114358901978, "episode_reward": 899.2003280496414, "step": 43000}
{"episode": 44.0, "batch_reward": 0.8192368667721749, "actor_loss": -86.20846771240234, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.61342692375183, "episode_reward": 922.4063530629832, "step": 44000}
{"episode": 45.0, "batch_reward": 0.8204705254435539, "actor_loss": -86.25337498474121, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.55431318283081, "episode_reward": 901.6804211473709, "step": 45000}
{"episode": 46.0, "batch_reward": 0.8239298586249352, "actor_loss": -86.28244052124023, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.43410563468933, "episode_reward": 894.4600907267918, "step": 46000}
{"episode": 47.0, "batch_reward": 0.8219634881019592, "actor_loss": -86.30632369995118, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.509451389312744, "episode_reward": 795.7201077344541, "step": 47000}
{"episode": 48.0, "batch_reward": 0.8234238784313201, "actor_loss": -86.31419973754883, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.97266125679016, "episode_reward": 868.5757725408076, "step": 48000}
{"episode": 49.0, "batch_reward": 0.8242344915270805, "actor_loss": -86.32505047607422, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.646094799041748, "episode_reward": 885.2292737935596, "step": 49000}
{"episode": 50.0, "batch_reward": 0.8257880264520645, "actor_loss": -86.35792234802246, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.482243061065674, "episode_reward": 919.196773437396, "step": 50000}
{"episode": 51.0, "batch_reward": 0.8235342687368393, "actor_loss": -86.35180422973633, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.7111234664917, "episode_reward": 531.5228685512247, "step": 51000}
{"episode": 52.0, "batch_reward": 0.819825938642025, "actor_loss": -86.22809104919433, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.48797583580017, "episode_reward": 750.5374461568673, "step": 52000}
{"episode": 53.0, "batch_reward": 0.8189918068647385, "actor_loss": -86.23655905151367, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.233553886413574, "episode_reward": 870.5817286624897, "step": 53000}
{"episode": 54.0, "batch_reward": 0.8218905676603318, "actor_loss": -86.27506872558594, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.35032081604004, "episode_reward": 863.0310037382736, "step": 54000}
{"episode": 55.0, "batch_reward": 0.821685364484787, "actor_loss": -86.29260366821289, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.547359466552734, "episode_reward": 847.6684281667905, "step": 55000}
{"episode": 56.0, "batch_reward": 0.8227843672037125, "actor_loss": -86.31981533813476, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.324675798416138, "episode_reward": 888.9596769926485, "step": 56000}
{"episode": 57.0, "batch_reward": 0.8236215036511422, "actor_loss": -86.30577282714843, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.37271499633789, "episode_reward": 885.5976721787185, "step": 57000}
{"episode": 58.0, "batch_reward": 0.8238320415019988, "actor_loss": -86.2983875579834, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.040994882583618, "episode_reward": 818.9750498271972, "step": 58000}
{"episode": 59.0, "batch_reward": 0.8246769911646843, "actor_loss": -86.3239953918457, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.972713232040405, "episode_reward": 884.3503975145634, "step": 59000}
{"episode": 60.0, "batch_reward": 0.8267877311110496, "actor_loss": -86.3566219329834, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.033159255981445, "episode_reward": 902.786441499775, "step": 60000}
{"episode": 61.0, "batch_reward": 0.8265497632622719, "actor_loss": -86.34706756591797, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.36654734611511, "episode_reward": 881.7325448750826, "step": 61000}
{"episode": 62.0, "batch_reward": 0.8287478322982789, "actor_loss": -86.42241567993165, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.17891240119934, "episode_reward": 839.9735267914895, "step": 62000}
{"episode": 63.0, "batch_reward": 0.8301792747974396, "actor_loss": -86.44478088378906, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.28570532798767, "episode_reward": 935.6534134827184, "step": 63000}
{"episode": 64.0, "batch_reward": 0.8292483549118042, "actor_loss": -86.40685284423829, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.294090270996094, "episode_reward": 878.0951090533682, "step": 64000}
{"episode": 65.0, "batch_reward": 0.8301803750395775, "actor_loss": -86.45859677124024, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.07052445411682, "episode_reward": 894.805190173932, "step": 65000}
{"episode": 66.0, "batch_reward": 0.8297529485821724, "actor_loss": -86.42646626281739, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.4365496635437, "episode_reward": 853.1877730226558, "step": 66000}
{"episode": 67.0, "batch_reward": 0.8319729550480842, "actor_loss": -86.4923314666748, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.645321369171143, "episode_reward": 823.7324898280558, "step": 67000}
{"episode": 68.0, "batch_reward": 0.8315256876349449, "actor_loss": -86.47868952941894, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.601682424545288, "episode_reward": 877.6808197595478, "step": 68000}
{"episode": 69.0, "batch_reward": 0.8302508619427681, "actor_loss": -86.47135725402832, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.108004331588745, "episode_reward": 860.0533237224525, "step": 69000}
{"episode": 70.0, "batch_reward": 0.8329048563838005, "actor_loss": -86.50130851745605, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.327486991882324, "episode_reward": 833.0699147821148, "step": 70000}
{"episode": 71.0, "batch_reward": 0.8320951861143112, "actor_loss": -86.48095600891114, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 39.857264041900635, "episode_reward": 856.1509595781898, "step": 71000}
{"episode": 72.0, "batch_reward": 0.8325698208212853, "actor_loss": -86.45145909118652, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.64535164833069, "episode_reward": 882.2428685806295, "step": 72000}
{"episode": 73.0, "batch_reward": 0.8344456963539123, "actor_loss": -86.49714846801758, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.490617275238037, "episode_reward": 889.3602605371706, "step": 73000}
{"episode": 74.0, "batch_reward": 0.8344125817418099, "actor_loss": -86.53219023132324, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.605149745941162, "episode_reward": 899.0803029439288, "step": 74000}
{"episode": 75.0, "batch_reward": 0.834834729373455, "actor_loss": -86.53678404235839, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.510565519332886, "episode_reward": 842.0548370558233, "step": 75000}
{"episode": 76.0, "batch_reward": 0.8341095488071442, "actor_loss": -86.49905529785157, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.43774104118347, "episode_reward": 806.6846686640685, "step": 76000}
{"episode": 77.0, "batch_reward": 0.8334165084958076, "actor_loss": -86.50039552307129, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.885290384292603, "episode_reward": 829.1024431530634, "step": 77000}
{"episode": 78.0, "batch_reward": 0.8358211504817009, "actor_loss": -86.54518873596191, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.69491720199585, "episode_reward": 924.1977409560201, "step": 78000}
{"episode": 79.0, "batch_reward": 0.8372721780538559, "actor_loss": -86.57621505737305, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.50928831100464, "episode_reward": 918.9457946502057, "step": 79000}
{"episode": 80.0, "batch_reward": 0.836452484369278, "actor_loss": -86.5756583251953, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.385544538497925, "episode_reward": 896.7754075108768, "step": 80000}
{"episode": 81.0, "batch_reward": 0.8385424815416336, "actor_loss": -86.6355062866211, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 39.39866518974304, "episode_reward": 866.809931032085, "step": 81000}
{"episode": 82.0, "batch_reward": 0.8371554645299911, "actor_loss": -86.59103713989258, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.499205589294434, "episode_reward": 841.5121059455813, "step": 82000}
{"episode": 83.0, "batch_reward": 0.8397121739387512, "actor_loss": -86.66399195861817, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.222611665725708, "episode_reward": 913.2584237227767, "step": 83000}
{"episode": 84.0, "batch_reward": 0.8383090191483498, "actor_loss": -86.61365916442871, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.334482431411743, "episode_reward": 842.1952336866252, "step": 84000}
{"episode": 85.0, "batch_reward": 0.8393557651638984, "actor_loss": -86.64200073242188, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.554863929748535, "episode_reward": 894.9267495931468, "step": 85000}
{"episode": 86.0, "batch_reward": 0.8396526727080346, "actor_loss": -86.62576487731934, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.17796802520752, "episode_reward": 891.4002973506286, "step": 86000}
{"episode": 87.0, "batch_reward": 0.8404692575931549, "actor_loss": -86.6534009552002, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.957591772079468, "episode_reward": 901.7728168801636, "step": 87000}
{"episode": 88.0, "batch_reward": 0.8402059826850891, "actor_loss": -86.67294235229492, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.213900804519653, "episode_reward": 840.8860794613415, "step": 88000}
{"episode": 89.0, "batch_reward": 0.8408303382992744, "actor_loss": -86.65190577697754, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.381256341934204, "episode_reward": 864.218746186539, "step": 89000}
{"episode": 90.0, "batch_reward": 0.8411121544837952, "actor_loss": -86.65343215942383, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.49991273880005, "episode_reward": 854.2953149880314, "step": 90000}
{"episode": 91.0, "batch_reward": 0.8431933140158653, "actor_loss": -86.73243386840821, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.15106129646301, "episode_reward": 915.1772511420921, "step": 91000}
{"episode": 92.0, "batch_reward": 0.8429321112632752, "actor_loss": -86.65806007385254, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.432377815246582, "episode_reward": 894.6676263605221, "step": 92000}
{"episode": 93.0, "batch_reward": 0.8419540318846702, "actor_loss": -86.68118498229981, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.667515516281128, "episode_reward": 857.3443851980247, "step": 93000}
{"episode": 94.0, "batch_reward": 0.8426183180809022, "actor_loss": -86.73116870117188, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.373239755630493, "episode_reward": 874.9941951523188, "step": 94000}
{"episode": 95.0, "batch_reward": 0.844026951789856, "actor_loss": -86.71127391052246, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.216817378997803, "episode_reward": 862.3458686117397, "step": 95000}
{"episode": 96.0, "batch_reward": 0.8431270508766174, "actor_loss": -86.73130476379394, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.344034910202026, "episode_reward": 833.183633102035, "step": 96000}
{"episode": 97.0, "batch_reward": 0.8453350595831871, "actor_loss": -86.76335194396972, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.24124026298523, "episode_reward": 890.6744444213203, "step": 97000}
{"episode": 98.0, "batch_reward": 0.8434215098023414, "actor_loss": -86.7033109588623, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.674431562423706, "episode_reward": 903.1255236858669, "step": 98000}
{"episode": 99.0, "batch_reward": 0.8455291057229042, "actor_loss": -86.79763363647461, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.70493745803833, "episode_reward": 914.9953729838925, "step": 99000}
{"episode": 100.0, "batch_reward": 0.8454421225190163, "actor_loss": -86.82058599853515, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.902860641479492, "episode_reward": 888.8708042712649, "step": 100000}
{"episode": 101.0, "batch_reward": 0.8442973552346229, "actor_loss": -86.75829383850098, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.464152812957764, "episode_reward": 808.1098756778962, "step": 101000}
{"episode": 102.0, "batch_reward": 0.8459885420799256, "actor_loss": -86.83452526855469, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.41390109062195, "episode_reward": 918.0929893914, "step": 102000}
{"episode": 103.0, "batch_reward": 0.8469482741951943, "actor_loss": -86.80291868591308, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.463401079177856, "episode_reward": 930.711556872294, "step": 103000}
{"episode": 104.0, "batch_reward": 0.8479833462834359, "actor_loss": -86.88541302490235, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.370192766189575, "episode_reward": 895.362455489115, "step": 104000}
{"episode": 105.0, "batch_reward": 0.8468951242566108, "actor_loss": -86.82609994506836, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.745532035827637, "episode_reward": 849.0447893776488, "step": 105000}
{"episode": 106.0, "batch_reward": 0.8464445061087609, "actor_loss": -86.81379205322266, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.576778411865234, "episode_reward": 924.3894499372892, "step": 106000}
{"episode": 107.0, "batch_reward": 0.8480654168128967, "actor_loss": -86.85403085327148, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.08134436607361, "episode_reward": 893.5659468208632, "step": 107000}
{"episode": 108.0, "batch_reward": 0.8477674143910408, "actor_loss": -86.8605684967041, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.463260650634766, "episode_reward": 871.7206778554156, "step": 108000}
{"episode": 109.0, "batch_reward": 0.8499190438985824, "actor_loss": -86.9009585723877, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.406519889831543, "episode_reward": 857.3809217762054, "step": 109000}
{"episode": 110.0, "batch_reward": 0.8479812702536583, "actor_loss": -86.88344868469238, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 19.877506971359253, "episode_reward": 885.4343196823467, "step": 110000}
{"episode": 111.0, "batch_reward": 0.8490823815464974, "actor_loss": -86.85017297363281, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 44.34414291381836, "episode_reward": 894.827931026454, "step": 111000}
{"episode": 112.0, "batch_reward": 0.8506207097768783, "actor_loss": -86.92297413635254, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.595556259155273, "episode_reward": 904.8537519019558, "step": 112000}
{"episode": 113.0, "batch_reward": 0.8496261956095695, "actor_loss": -86.88771963500976, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.361185789108276, "episode_reward": 905.7052161190913, "step": 113000}
{"episode": 114.0, "batch_reward": 0.8517089007496834, "actor_loss": -86.940873336792, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.451266765594482, "episode_reward": 888.9759318007439, "step": 114000}
{"episode": 115.0, "batch_reward": 0.8527382063269615, "actor_loss": -86.98380438232422, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.43490481376648, "episode_reward": 905.4431474295525, "step": 115000}
{"episode": 116.0, "batch_reward": 0.8519705938696861, "actor_loss": -86.93832971191407, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 19.88162636756897, "episode_reward": 912.5204364113113, "step": 116000}
{"episode": 117.0, "batch_reward": 0.8529380156993865, "actor_loss": -86.9648289642334, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.057912826538086, "episode_reward": 921.6294944841189, "step": 117000}
{"episode": 118.0, "batch_reward": 0.8525068929195404, "actor_loss": -86.97471687316894, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.401636838912964, "episode_reward": 756.4847635010763, "step": 118000}
{"episode": 119.0, "batch_reward": 0.8511495543122292, "actor_loss": -86.89958206176757, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.327956676483154, "episode_reward": 784.6968727459333, "step": 119000}
{"episode": 120.0, "batch_reward": 0.8519504597783089, "actor_loss": -86.96823582458497, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.287487983703613, "episode_reward": 913.2386239964004, "step": 120000}
{"episode": 121.0, "batch_reward": 0.8506303037405014, "actor_loss": -86.91602165222167, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 44.73630237579346, "episode_reward": 836.3355123670007, "step": 121000}
{"episode": 122.0, "batch_reward": 0.8521125342845917, "actor_loss": -86.94742169189453, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 19.2980375289917, "episode_reward": 846.4478995967262, "step": 122000}
{"episode": 123.0, "batch_reward": 0.8519333807826042, "actor_loss": -86.94286895751954, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.50343084335327, "episode_reward": 875.1115774167423, "step": 123000}
{"episode": 124.0, "batch_reward": 0.8523224889039993, "actor_loss": -86.9684522857666, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.48627209663391, "episode_reward": 900.1458434178137, "step": 124000}
{"episode": 125.0, "batch_reward": 0.8510320900082589, "actor_loss": -86.90994519042968, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.75405240058899, "episode_reward": 843.6587619045356, "step": 125000}
{"episode": 126.0, "batch_reward": 0.851680437028408, "actor_loss": -86.9289575958252, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.55049991607666, "episode_reward": 934.9504682690916, "step": 126000}
{"episode": 127.0, "batch_reward": 0.851691876411438, "actor_loss": -86.95265893554688, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.306144952774048, "episode_reward": 802.2816424403303, "step": 127000}
{"episode": 128.0, "batch_reward": 0.8518789707422256, "actor_loss": -86.93445652770995, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.691128492355347, "episode_reward": 874.6736490594718, "step": 128000}
{"episode": 129.0, "batch_reward": 0.853111618757248, "actor_loss": -86.98660736083984, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 19.923867225646973, "episode_reward": 914.5543000990702, "step": 129000}
{"episode": 130.0, "batch_reward": 0.8522702538967133, "actor_loss": -86.96259687805176, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 19.60612154006958, "episode_reward": 848.3731449741953, "step": 130000}
{"episode": 131.0, "batch_reward": 0.8523702358603478, "actor_loss": -86.92941369628906, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.94798159599304, "episode_reward": 894.3393548074285, "step": 131000}
{"episode": 132.0, "batch_reward": 0.853593842804432, "actor_loss": -87.0102173614502, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.28541874885559, "episode_reward": 862.3276158592621, "step": 132000}
{"episode": 133.0, "batch_reward": 0.8537867863178253, "actor_loss": -86.98303849792481, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.422300577163696, "episode_reward": 917.7951826700805, "step": 133000}
{"episode": 134.0, "batch_reward": 0.8534698758125305, "actor_loss": -86.99641799926758, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.77256751060486, "episode_reward": 900.0115712764136, "step": 134000}
{"episode": 135.0, "batch_reward": 0.8530858284831047, "actor_loss": -86.96160655212402, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.63792395591736, "episode_reward": 824.7515149492925, "step": 135000}
{"episode": 136.0, "batch_reward": 0.8533745146989823, "actor_loss": -86.97006959533691, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 19.165601015090942, "episode_reward": 871.462433014034, "step": 136000}
{"episode": 137.0, "batch_reward": 0.8537249863743782, "actor_loss": -87.02056858825684, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 19.69562816619873, "episode_reward": 831.5006600360277, "step": 137000}
{"episode": 138.0, "batch_reward": 0.8546235902905465, "actor_loss": -87.03734411621093, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.200068712234497, "episode_reward": 920.1224843740844, "step": 138000}
{"episode": 139.0, "batch_reward": 0.8534788042902947, "actor_loss": -87.01634019470215, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.440812349319458, "episode_reward": 847.0416590115203, "step": 139000}
{"episode": 140.0, "batch_reward": 0.8543895449638367, "actor_loss": -87.00332817077637, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.726980209350586, "episode_reward": 847.0203458701832, "step": 140000}
{"episode": 141.0, "batch_reward": 0.8539790700674057, "actor_loss": -87.03299382019043, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.536564350128174, "episode_reward": 884.4298810318893, "step": 141000}
{"episode": 142.0, "batch_reward": 0.8551628593206405, "actor_loss": -87.06441484069825, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.901620864868164, "episode_reward": 900.7052809311521, "step": 142000}
{"episode": 143.0, "batch_reward": 0.8543260157108307, "actor_loss": -87.01851608276367, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.913890600204468, "episode_reward": 863.877089863146, "step": 143000}
{"episode": 144.0, "batch_reward": 0.8555174013376236, "actor_loss": -87.07594207763673, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.337146520614624, "episode_reward": 902.6400802960102, "step": 144000}
{"episode": 145.0, "batch_reward": 0.8547479661107064, "actor_loss": -87.04101396179199, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.42594861984253, "episode_reward": 910.3325133667197, "step": 145000}
{"episode": 146.0, "batch_reward": 0.8562231252789497, "actor_loss": -87.06030645751953, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.579421520233154, "episode_reward": 864.9656216812865, "step": 146000}
{"episode": 147.0, "batch_reward": 0.8543025798797608, "actor_loss": -87.0002522277832, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 19.8100688457489, "episode_reward": 880.9608985820945, "step": 147000}
{"episode": 148.0, "batch_reward": 0.8553176729679107, "actor_loss": -87.02568594360352, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.463782787322998, "episode_reward": 854.1195688088949, "step": 148000}
{"episode": 149.0, "batch_reward": 0.8554070274829865, "actor_loss": -87.07837753295898, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.242942571640015, "episode_reward": 871.0482101633261, "step": 149000}
{"episode": 150.0, "batch_reward": 0.8560944107174874, "actor_loss": -87.08330638122558, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "step": 150000}
