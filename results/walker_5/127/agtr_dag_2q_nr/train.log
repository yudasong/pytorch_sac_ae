{"episode": 1.0, "duration": 19.743809700012207, "episode_reward": 61.50603977848499, "step": 1000}
{"episode": 2.0, "duration": 1.701523780822754, "episode_reward": 808.9209525976895, "step": 2000}
{"episode": 3.0, "batch_reward": 0.4563328885225186, "critic_loss": 0.2779591930940096, "actor_loss": -76.34098776534539, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 71.49903893470764, "episode_reward": 831.5869373956294, "step": 3000}
{"episode": 4.0, "batch_reward": 0.606109481304884, "critic_loss": 0.25863963168859483, "actor_loss": -80.66687530517578, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.068225622177124, "episode_reward": 859.6055998095926, "step": 4000}
{"episode": 5.0, "batch_reward": 0.646655621945858, "critic_loss": 0.2915044401139021, "actor_loss": -81.55115531921386, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.12286901473999, "episode_reward": 815.298541584175, "step": 5000}
{"episode": 6.0, "batch_reward": 0.6917026314735413, "critic_loss": 0.3394808495938778, "actor_loss": -82.37514793395997, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.129952669143677, "episode_reward": 918.3664354835164, "step": 6000}
{"episode": 7.0, "batch_reward": 0.7317078464031219, "critic_loss": 0.3388580310493708, "actor_loss": -83.23332621765137, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.056817293167114, "episode_reward": 933.8290452151534, "step": 7000}
{"episode": 8.0, "batch_reward": 0.747081507563591, "critic_loss": 0.39813543535768986, "actor_loss": -83.64527267456054, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.008492708206177, "episode_reward": 846.1463662615815, "step": 8000}
{"episode": 9.0, "batch_reward": 0.7692444317936897, "critic_loss": 0.3427536414116621, "actor_loss": -84.23434883117676, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.991347789764404, "episode_reward": 942.1154516531747, "step": 9000}
{"episode": 10.0, "batch_reward": 0.7774294084906578, "critic_loss": 0.4840086065530777, "actor_loss": -76.6734048461914, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 4342.541661500931, "episode_reward": 757.812121873269, "step": 10000}
{"episode": 11.0, "batch_reward": 0.7773494362235069, "critic_loss": 0.42722683742642403, "actor_loss": -76.9379222869873, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.358644008636475, "episode_reward": 825.5849251936107, "step": 11000}
{"episode": 12.0, "batch_reward": 0.7826423199176789, "critic_loss": 0.3933981450200081, "actor_loss": -72.95710848999023, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 498.54020142555237, "episode_reward": 860.2547249131636, "step": 12000}
{"episode": 13.0, "batch_reward": 0.7896768193840981, "critic_loss": 0.3805897772610188, "actor_loss": -73.3355231628418, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.346040725708008, "episode_reward": 804.4164012445946, "step": 13000}
{"episode": 14.0, "batch_reward": 0.7877391562461853, "critic_loss": 0.4582365556061268, "actor_loss": -71.06723162841797, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 481.9917299747467, "episode_reward": 823.0084242807728, "step": 14000}
{"episode": 15.0, "batch_reward": 0.7903390444517135, "critic_loss": 0.43417507216334345, "actor_loss": -71.31890748596192, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.979917526245117, "episode_reward": 819.4706838017615, "step": 15000}
{"episode": 16.0, "batch_reward": 0.7925295930504799, "critic_loss": 0.5344132261872292, "actor_loss": -70.56140263366699, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 483.60643339157104, "episode_reward": 727.8178747932343, "step": 16000}
{"episode": 17.0, "batch_reward": 0.7884971566796303, "critic_loss": 0.5961357000768185, "actor_loss": -70.52532225036622, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.14482045173645, "episode_reward": 794.3580067179261, "step": 17000}
{"episode": 18.0, "batch_reward": 0.7879744337797165, "critic_loss": 0.6763010430634022, "actor_loss": -70.23321920776367, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 488.55216932296753, "episode_reward": 747.7129029579902, "step": 18000}
{"episode": 19.0, "batch_reward": 0.7869953619837761, "critic_loss": 0.7615828396975994, "actor_loss": -70.24871496582031, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.17082929611206, "episode_reward": 814.9603225563789, "step": 19000}
{"episode": 20.0, "batch_reward": 0.7897802070975304, "critic_loss": 0.8204382898509502, "actor_loss": -70.3675545349121, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 461.3572497367859, "episode_reward": 869.6843676025173, "step": 20000}
{"episode": 21.0, "batch_reward": 0.7922713578939438, "critic_loss": 0.8210837370455265, "actor_loss": -70.49220295715332, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.57661461830139, "episode_reward": 840.3689944311132, "step": 21000}
{"episode": 22.0, "batch_reward": 0.7964034485816955, "critic_loss": 0.7972781698405743, "actor_loss": -70.70629750061035, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 430.90794110298157, "episode_reward": 833.0442146819072, "step": 22000}
{"episode": 23.0, "batch_reward": 0.7965605202317237, "critic_loss": 0.8094432140290737, "actor_loss": -70.75711656188965, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.598253965377808, "episode_reward": 824.825806208736, "step": 23000}
{"episode": 24.0, "batch_reward": 0.8011054134368897, "critic_loss": 0.8257642968595028, "actor_loss": -70.96519960021973, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 485.0812647342682, "episode_reward": 864.6123714171821, "step": 24000}
{"episode": 25.0, "batch_reward": 0.8019542623162269, "critic_loss": 0.8336776846647262, "actor_loss": -71.1248055114746, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.58880043029785, "episode_reward": 876.6337545554419, "step": 25000}
{"episode": 26.0, "batch_reward": 0.8024822658896447, "critic_loss": 0.8435877456068993, "actor_loss": -70.98575259399414, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 459.10960245132446, "episode_reward": 852.5180631738523, "step": 26000}
{"episode": 27.0, "batch_reward": 0.807211219727993, "critic_loss": 0.7808613568544388, "actor_loss": -71.2217046508789, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.1462984085083, "episode_reward": 870.5766941118624, "step": 27000}
{"episode": 28.0, "batch_reward": 0.8070472455620765, "critic_loss": 0.9446520475745201, "actor_loss": -71.0414453125, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 426.5246946811676, "episode_reward": 833.9540793052266, "step": 28000}
{"episode": 29.0, "batch_reward": 0.8088491491675377, "critic_loss": 1.247751633822918, "actor_loss": -71.23375477600098, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.06568670272827, "episode_reward": 834.1084139109781, "step": 29000}
{"episode": 30.0, "batch_reward": 0.809785864174366, "critic_loss": 1.638198009610176, "actor_loss": -71.67548538208008, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 465.377872467041, "episode_reward": 773.7683873236612, "step": 30000}
{"episode": 31.0, "batch_reward": 0.8081264696121215, "critic_loss": 2.177704822599888, "actor_loss": -71.72718963623046, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 44.0092875957489, "episode_reward": 834.314123473247, "step": 31000}
{"episode": 32.0, "batch_reward": 0.8104769633412361, "critic_loss": 2.721068901181221, "actor_loss": -71.94284674072266, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 469.5302290916443, "episode_reward": 867.4696734586256, "step": 32000}
{"episode": 33.0, "batch_reward": 0.8115914000868797, "critic_loss": 2.975438518345356, "actor_loss": -72.17797143554688, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.54097819328308, "episode_reward": 875.5269896512821, "step": 33000}
{"episode": 34.0, "batch_reward": 0.8149362387657165, "critic_loss": 3.814508189320564, "actor_loss": -72.56792431640625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 437.99604845046997, "episode_reward": 894.909958179549, "step": 34000}
{"episode": 35.0, "batch_reward": 0.804564801633358, "critic_loss": 4.926596283197403, "actor_loss": -72.70759596252441, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.53062915802002, "episode_reward": 27.491526484333697, "step": 35000}
{"episode": 36.0, "batch_reward": 0.7902272085547447, "critic_loss": 4.706794692873955, "actor_loss": -73.03175596618652, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 450.7471823692322, "episode_reward": 825.3283123630484, "step": 36000}
{"episode": 37.0, "batch_reward": 0.7965011104345322, "critic_loss": 3.772684130370617, "actor_loss": -73.35338829040528, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.81000781059265, "episode_reward": 899.4258108349001, "step": 37000}
{"episode": 38.0, "batch_reward": 0.7979172120690345, "critic_loss": 3.3946677515506742, "actor_loss": -73.70006213378906, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 444.8815152645111, "episode_reward": 870.1157262882232, "step": 38000}
{"episode": 39.0, "batch_reward": 0.7986374125480652, "critic_loss": 3.365321272492409, "actor_loss": -73.9382552947998, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.887948751449585, "episode_reward": 871.2709366537883, "step": 39000}
{"episode": 40.0, "batch_reward": 0.802096532523632, "critic_loss": 3.0721848828196525, "actor_loss": -74.24736364746094, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 423.54672503471375, "episode_reward": 874.7260792341666, "step": 40000}
{"episode": 41.0, "batch_reward": 0.8033427916765213, "critic_loss": 3.012952573955059, "actor_loss": -74.46544659423829, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.71052670478821, "episode_reward": 889.7256839394963, "step": 41000}
{"episode": 42.0, "batch_reward": 0.7948627032637596, "critic_loss": 4.092352918684482, "actor_loss": -74.89683093261719, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 451.07940673828125, "episode_reward": 27.56615765065237, "step": 42000}
{"episode": 43.0, "batch_reward": 0.7880928368568421, "critic_loss": 3.7750560314655304, "actor_loss": -75.27327558898926, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.199443101882935, "episode_reward": 886.891404733235, "step": 43000}
{"episode": 44.0, "batch_reward": 0.7842959719896316, "critic_loss": 3.8749663178920746, "actor_loss": -75.43867895507813, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 455.85825419425964, "episode_reward": 263.27095431783124, "step": 44000}
{"episode": 45.0, "batch_reward": 0.7773509355783462, "critic_loss": 3.937288532614708, "actor_loss": -75.74662600708008, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.81302261352539, "episode_reward": 884.3100834405218, "step": 45000}
{"episode": 46.0, "batch_reward": 0.7789227672219277, "critic_loss": 4.232182843089103, "actor_loss": -76.00498901367187, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 454.64193892478943, "episode_reward": 525.6504973250726, "step": 46000}
{"episode": 47.0, "batch_reward": 0.7646739000082016, "critic_loss": 4.816881672859192, "actor_loss": -76.4473498840332, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.9500572681427, "episode_reward": 61.08345589114598, "step": 47000}
{"episode": 48.0, "batch_reward": 0.7495958901643753, "critic_loss": 4.887666209220886, "actor_loss": -76.84054536437988, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 446.968567609787, "episode_reward": 30.99485491661493, "step": 48000}
{"episode": 49.0, "batch_reward": 0.7394784532785416, "critic_loss": 4.6476906472444535, "actor_loss": -77.25437593078614, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.738121271133423, "episode_reward": 183.61522388736873, "step": 49000}
{"episode": 50.0, "batch_reward": 0.7250189352035522, "critic_loss": 4.777717936754227, "actor_loss": -77.93257110595704, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 428.8834524154663, "episode_reward": 36.270445884015324, "step": 50000}
{"episode": 51.0, "batch_reward": 0.7111919121742248, "critic_loss": 6.113701076507568, "actor_loss": -79.32910092163085, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.25325798988342, "episode_reward": 54.55528554872131, "step": 51000}
{"episode": 52.0, "batch_reward": 0.6987014909982682, "critic_loss": 7.874412915229797, "actor_loss": -81.333972946167, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 457.99005150794983, "episode_reward": 68.8260683301654, "step": 52000}
{"episode": 53.0, "batch_reward": 0.68526527261734, "critic_loss": 9.104280560970306, "actor_loss": -83.90975437927246, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.096256017684937, "episode_reward": 72.78222039455504, "step": 53000}
{"episode": 54.0, "batch_reward": 0.6764811190962792, "critic_loss": 10.070242080688477, "actor_loss": -87.29591502380372, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 444.5091378688812, "episode_reward": 112.71950336202148, "step": 54000}
{"episode": 55.0, "batch_reward": 0.6657624577283859, "critic_loss": 10.581451898574828, "actor_loss": -90.30925991821289, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.2680504322052, "episode_reward": 171.74841904763477, "step": 55000}
{"episode": 56.0, "batch_reward": 0.6596603181362152, "critic_loss": 9.443112314224242, "actor_loss": -92.25502349853515, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 475.0465841293335, "episode_reward": 224.1803257293558, "step": 56000}
{"episode": 57.0, "batch_reward": 0.6525692678093911, "critic_loss": 8.460625758171082, "actor_loss": -93.24357247924804, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.496404886245728, "episode_reward": 744.1653797465548, "step": 57000}
{"episode": 58.0, "batch_reward": 0.6546790696382523, "critic_loss": 8.169725031852723, "actor_loss": -94.37296630859375, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 441.9839313030243, "episode_reward": 864.6508938848839, "step": 58000}
{"episode": 59.0, "batch_reward": 0.6603402004241944, "critic_loss": 7.9371643037796025, "actor_loss": -95.30893472290039, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.597274780273438, "episode_reward": 662.2124514687894, "step": 59000}
{"episode": 60.0, "batch_reward": 0.6599257299304009, "critic_loss": 6.962006722688675, "actor_loss": -95.56312951660156, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 434.6932964324951, "episode_reward": 925.4496319478839, "step": 60000}
{"episode": 61.0, "batch_reward": 0.6626030801534653, "critic_loss": 6.041002429008484, "actor_loss": -95.88334896850586, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.83087086677551, "episode_reward": 845.158719680476, "step": 61000}
{"episode": 62.0, "batch_reward": 0.6677862985730171, "critic_loss": 5.24395738363266, "actor_loss": -96.35473957824708, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 453.1521511077881, "episode_reward": 861.5776550166962, "step": 62000}
{"episode": 63.0, "batch_reward": 0.6734095754623413, "critic_loss": 4.35479448735714, "actor_loss": -96.42869883728028, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.373276472091675, "episode_reward": 896.9546050497503, "step": 63000}
{"episode": 64.0, "batch_reward": 0.6689768487811089, "critic_loss": 4.028292435646057, "actor_loss": -96.44746260070801, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 462.78573083877563, "episode_reward": 313.2099952073027, "step": 64000}
{"episode": 65.0, "batch_reward": 0.6670506962537766, "critic_loss": 3.103961248397827, "actor_loss": -96.60696446228027, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.384233951568604, "episode_reward": 864.0407490633645, "step": 65000}
{"episode": 66.0, "batch_reward": 0.6691245157122612, "critic_loss": 3.0541595335006715, "actor_loss": -96.30344612121581, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 448.0711658000946, "episode_reward": 806.3407563089991, "step": 66000}
{"episode": 67.0, "batch_reward": 0.6700033762454987, "critic_loss": 2.8536445301771165, "actor_loss": -95.8102002105713, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.550264596939087, "episode_reward": 26.858976286582422, "step": 67000}
{"episode": 68.0, "batch_reward": 0.6635779806375504, "critic_loss": 2.5886111168861388, "actor_loss": -94.98986270141602, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 435.08976697921753, "episode_reward": 866.0917719453661, "step": 68000}
{"episode": 69.0, "batch_reward": 0.6678393612504006, "critic_loss": 2.3343107544779778, "actor_loss": -94.31442573547363, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.40014338493347, "episode_reward": 851.603509884371, "step": 69000}
{"episode": 70.0, "batch_reward": 0.6631376034617424, "critic_loss": 2.5030512793660162, "actor_loss": -93.03186750793456, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 471.77778935432434, "episode_reward": 18.098556629308383, "step": 70000}
{"episode": 71.0, "batch_reward": 0.6602140404582023, "critic_loss": 2.0823214948177338, "actor_loss": -92.51819450378417, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.76094460487366, "episode_reward": 836.3016157631864, "step": 71000}
{"episode": 72.0, "batch_reward": 0.6612644556164742, "critic_loss": 2.089030119895935, "actor_loss": -91.82051202392579, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 431.79685950279236, "episode_reward": 787.8006941468274, "step": 72000}
{"episode": 73.0, "batch_reward": 0.6637917744517327, "critic_loss": 2.376198989391327, "actor_loss": -91.44655690002442, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.952576637268066, "episode_reward": 745.8935407827026, "step": 73000}
{"episode": 74.0, "batch_reward": 0.6598829683065415, "critic_loss": 2.646499664127827, "actor_loss": -90.91917080688476, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 459.0899074077606, "episode_reward": 528.1021760723671, "step": 74000}
{"episode": 75.0, "batch_reward": 0.6636947026848793, "critic_loss": 2.179267108619213, "actor_loss": -90.76656924438477, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.392212390899658, "episode_reward": 844.5363986770521, "step": 75000}
{"episode": 76.0, "batch_reward": 0.6653215676546097, "critic_loss": 1.9799343329668044, "actor_loss": -90.21611804199219, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 468.110356092453, "episode_reward": 750.2604458270231, "step": 76000}
{"episode": 77.0, "batch_reward": 0.6676700028181076, "critic_loss": 2.2203180999159815, "actor_loss": -89.7145320892334, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.957159519195557, "episode_reward": 834.1685433507126, "step": 77000}
{"episode": 78.0, "batch_reward": 0.6671877406239509, "critic_loss": 2.052933713376522, "actor_loss": -89.07117211914063, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 463.85414123535156, "episode_reward": 597.77899718288, "step": 78000}
{"episode": 79.0, "batch_reward": 0.6654246854782104, "critic_loss": 2.731303735375404, "actor_loss": -88.72268444824219, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.095768690109253, "episode_reward": 309.51385964831275, "step": 79000}
{"episode": 80.0, "batch_reward": 0.6662757011055946, "critic_loss": 2.45039188849926, "actor_loss": -88.61132723999023, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 462.0667214393616, "episode_reward": 902.6084254172077, "step": 80000}
{"episode": 81.0, "batch_reward": 0.6668592494726181, "critic_loss": 2.2995732330083847, "actor_loss": -88.06338706970215, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.20693850517273, "episode_reward": 826.1141706042953, "step": 81000}
{"episode": 82.0, "batch_reward": 0.6706473802924157, "critic_loss": 2.292312132656574, "actor_loss": -87.78080989074707, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 464.2071523666382, "episode_reward": 858.8577278040244, "step": 82000}
{"episode": 83.0, "batch_reward": 0.6706459735035897, "critic_loss": 1.9831528162360192, "actor_loss": -87.56383830261231, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.524479389190674, "episode_reward": 905.8030942499887, "step": 83000}
{"episode": 84.0, "batch_reward": 0.6726697288155555, "critic_loss": 2.6233529843091965, "actor_loss": -87.31762339782715, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 477.70820689201355, "episode_reward": 808.6431823537692, "step": 84000}
{"episode": 85.0, "batch_reward": 0.6730610486865044, "critic_loss": 2.4576781041026114, "actor_loss": -87.09047692871094, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.980939388275146, "episode_reward": 786.157069437379, "step": 85000}
{"episode": 86.0, "batch_reward": 0.6768168064355851, "critic_loss": 2.2029083228111266, "actor_loss": -86.50120797729492, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 433.99929118156433, "episode_reward": 873.5518654548605, "step": 86000}
{"episode": 87.0, "batch_reward": 0.680711760699749, "critic_loss": 2.3015118317604064, "actor_loss": -86.32756437683105, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.06381058692932, "episode_reward": 902.866128360945, "step": 87000}
{"episode": 88.0, "batch_reward": 0.6784604467749595, "critic_loss": 2.4644967227578163, "actor_loss": -86.11177230834961, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 450.57827711105347, "episode_reward": 23.50371714401945, "step": 88000}
{"episode": 89.0, "batch_reward": 0.6732994922399521, "critic_loss": 2.1969280393123625, "actor_loss": -85.99016000366211, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.743986129760742, "episode_reward": 813.8608863842796, "step": 89000}
{"episode": 90.0, "batch_reward": 0.6750362777709961, "critic_loss": 2.065898871481419, "actor_loss": -85.82321272277832, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 467.05314922332764, "episode_reward": 824.4349797190163, "step": 90000}
{"episode": 91.0, "batch_reward": 0.6766234306693077, "critic_loss": 1.8558252526521684, "actor_loss": -85.65765145874023, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.61518096923828, "episode_reward": 892.1608239648294, "step": 91000}
{"episode": 92.0, "batch_reward": 0.6762924668192863, "critic_loss": 2.00170608150959, "actor_loss": -85.51743112182618, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 438.0121958255768, "episode_reward": 11.799574665842997, "step": 92000}
{"episode": 93.0, "batch_reward": 0.6732217961549759, "critic_loss": 2.048699068427086, "actor_loss": -85.45968426513672, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.290712118148804, "episode_reward": 865.4290869563844, "step": 93000}
{"episode": 94.0, "batch_reward": 0.674532380759716, "critic_loss": 2.2195011363625525, "actor_loss": -85.24460275268555, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 446.21351742744446, "episode_reward": 850.7549526451777, "step": 94000}
{"episode": 95.0, "batch_reward": 0.6744671926498413, "critic_loss": 3.723100863456726, "actor_loss": -85.99235458374024, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.875701665878296, "episode_reward": 399.0105372303822, "step": 95000}
{"episode": 96.0, "batch_reward": 0.6705098062753677, "critic_loss": 5.716433886170387, "actor_loss": -89.3508860168457, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 431.37323451042175, "episode_reward": 27.996597033017387, "step": 96000}
{"episode": 97.0, "batch_reward": 0.6637000615596771, "critic_loss": 8.19755585360527, "actor_loss": -92.5919638824463, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.69308829307556, "episode_reward": 29.264070661986143, "step": 97000}
{"episode": 98.0, "batch_reward": 0.6563687958717346, "critic_loss": 9.713225185394288, "actor_loss": -97.31124876403808, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 453.49295115470886, "episode_reward": 57.50498750055018, "step": 98000}
{"episode": 99.0, "batch_reward": 0.6507219833731651, "critic_loss": 10.941632407188415, "actor_loss": -103.82084181213379, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.54623532295227, "episode_reward": 33.482797967318696, "step": 99000}
{"episode": 100.0, "batch_reward": 0.6441691194176674, "critic_loss": 8.842267899036408, "actor_loss": -110.15277104187011, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 460.66259121894836, "episode_reward": 60.52447531658637, "step": 100000}
{"episode": 101.0, "batch_reward": 0.639267913043499, "critic_loss": 7.878659328460693, "actor_loss": -115.24691549682618, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.15378999710083, "episode_reward": 33.18143453637563, "step": 101000}
{"episode": 102.0, "batch_reward": 0.6320963131189347, "critic_loss": 8.948749344110489, "actor_loss": -119.79339073181153, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 434.0569341182709, "episode_reward": 43.550791799643356, "step": 102000}
{"episode": 103.0, "batch_reward": 0.6278790768384933, "critic_loss": 12.366314670562744, "actor_loss": -127.55977276611328, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.34679388999939, "episode_reward": 31.51085059867954, "step": 103000}
{"episode": 104.0, "batch_reward": 0.6208783505856991, "critic_loss": 14.025238309383392, "actor_loss": -136.41910711669922, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 435.50807332992554, "episode_reward": 28.788331656110426, "step": 104000}
{"episode": 105.0, "batch_reward": 0.6158699449896813, "critic_loss": 12.292737069129943, "actor_loss": -142.58404806518556, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.8283052444458, "episode_reward": 28.946413174257593, "step": 105000}
{"episode": 106.0, "batch_reward": 0.6118108572363854, "critic_loss": 9.739440251350404, "actor_loss": -145.09255969238282, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 451.04552149772644, "episode_reward": 25.023984457024447, "step": 106000}
{"episode": 107.0, "batch_reward": 0.6030026655495166, "critic_loss": 8.583824131250381, "actor_loss": -146.62351068115234, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.75385355949402, "episode_reward": 26.24042284574294, "step": 107000}
{"episode": 108.0, "batch_reward": 0.597784590870142, "critic_loss": 7.998954104423523, "actor_loss": -147.5874959716797, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 444.0650508403778, "episode_reward": 35.19245997390317, "step": 108000}
{"episode": 109.0, "batch_reward": 0.5955377126932144, "critic_loss": 7.627981639385223, "actor_loss": -148.6733793029785, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.866421461105347, "episode_reward": 159.1010906255482, "step": 109000}
{"episode": 110.0, "batch_reward": 0.5898871484696865, "critic_loss": 6.8664432861804965, "actor_loss": -149.78743823242186, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 452.54118967056274, "episode_reward": 41.57871525832701, "step": 110000}
{"episode": 111.0, "batch_reward": 0.583565743714571, "critic_loss": 6.429809817552567, "actor_loss": -150.96346139526366, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.60456323623657, "episode_reward": 29.954569234497043, "step": 111000}
{"episode": 112.0, "batch_reward": 0.5780466048717499, "critic_loss": 6.086027714729309, "actor_loss": -152.26164739990233, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 460.78393507003784, "episode_reward": 74.97192760560645, "step": 112000}
{"episode": 113.0, "batch_reward": 0.5746011429727077, "critic_loss": 6.220396922111512, "actor_loss": -154.15726708984374, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.362276315689087, "episode_reward": 31.510223575388135, "step": 113000}
{"episode": 114.0, "batch_reward": 0.5686652169823646, "critic_loss": 5.829131247758865, "actor_loss": -156.27055462646484, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 458.6409065723419, "episode_reward": 57.777269504331116, "step": 114000}
{"episode": 115.0, "batch_reward": 0.5674442712068558, "critic_loss": 4.959987432003021, "actor_loss": -157.90026113891602, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.64672565460205, "episode_reward": 34.05112749995748, "step": 115000}
{"episode": 116.0, "batch_reward": 0.5624171506464481, "critic_loss": 4.3299434220790864, "actor_loss": -159.3179638671875, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 430.2454397678375, "episode_reward": 37.86783119562928, "step": 116000}
{"episode": 117.0, "batch_reward": 0.5568209505081176, "critic_loss": 3.967571812868118, "actor_loss": -160.80112567138673, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.462944746017456, "episode_reward": 64.43396672961053, "step": 117000}
{"episode": 118.0, "batch_reward": 0.5526380270421505, "critic_loss": 3.713789743542671, "actor_loss": -161.89116845703126, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 437.93914222717285, "episode_reward": 20.663417442734687, "step": 118000}
{"episode": 119.0, "batch_reward": 0.55005591365695, "critic_loss": 3.5071944655179976, "actor_loss": -162.24659936523437, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.188995122909546, "episode_reward": 25.47160778792993, "step": 119000}
{"episode": 120.0, "batch_reward": 0.5458919291198253, "critic_loss": 3.1123261070251464, "actor_loss": -161.248748626709, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 456.3991458415985, "episode_reward": 374.3499477134132, "step": 120000}
{"episode": 121.0, "batch_reward": 0.5415917884111404, "critic_loss": 2.958526653647423, "actor_loss": -159.74234201049805, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.29889535903931, "episode_reward": 18.426995530448547, "step": 121000}
{"episode": 122.0, "batch_reward": 0.5385062320828438, "critic_loss": 2.8143925952911375, "actor_loss": -157.68425015258788, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 440.16128754615784, "episode_reward": 580.1252497381441, "step": 122000}
{"episode": 123.0, "batch_reward": 0.5405884112715721, "critic_loss": 2.5746766953468323, "actor_loss": -155.7216303100586, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.420800924301147, "episode_reward": 685.8656709298668, "step": 123000}
{"episode": 124.0, "batch_reward": 0.5402271168529987, "critic_loss": 2.250570298552513, "actor_loss": -153.77415457153322, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 409.19569516181946, "episode_reward": 26.747596510059072, "step": 124000}
{"episode": 125.0, "batch_reward": 0.5350887645483017, "critic_loss": 1.9912862175703048, "actor_loss": -151.69785995483397, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.909920930862427, "episode_reward": 27.537751186523383, "step": 125000}
{"episode": 126.0, "batch_reward": 0.5326981804072857, "critic_loss": 1.7014541333317756, "actor_loss": -149.45120208740235, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 457.45803570747375, "episode_reward": 763.6548734829427, "step": 126000}
{"episode": 127.0, "batch_reward": 0.5331563974320889, "critic_loss": 1.4414679043293, "actor_loss": -147.4481238708496, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.504515171051025, "episode_reward": 20.008639847041994, "step": 127000}
{"episode": 128.0, "batch_reward": 0.5292511672973633, "critic_loss": 1.2082238335609436, "actor_loss": -144.940244720459, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 465.04616022109985, "episode_reward": 22.638974095668473, "step": 128000}
{"episode": 129.0, "batch_reward": 0.5298593489527702, "critic_loss": 1.033911468923092, "actor_loss": -142.33294906616212, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.07780933380127, "episode_reward": 907.9391673375055, "step": 129000}
{"episode": 130.0, "batch_reward": 0.5309051597714424, "critic_loss": 0.9098492420613765, "actor_loss": -139.7213765258789, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 462.27958965301514, "episode_reward": 872.3641967783018, "step": 130000}
{"episode": 131.0, "batch_reward": 0.5338273887336255, "critic_loss": 0.810536550283432, "actor_loss": -137.1410218811035, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.887144565582275, "episode_reward": 905.2040085214065, "step": 131000}
{"episode": 132.0, "batch_reward": 0.5370946481227875, "critic_loss": 0.7936021335721016, "actor_loss": -134.74937118530272, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 466.4241394996643, "episode_reward": 851.6202061408992, "step": 132000}
{"episode": 133.0, "batch_reward": 0.5397180779874324, "critic_loss": 0.7497984113693237, "actor_loss": -132.41627001953125, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.431657552719116, "episode_reward": 909.6017145313408, "step": 133000}
{"episode": 134.0, "batch_reward": 0.5424518849253654, "critic_loss": 0.6909113512039184, "actor_loss": -130.17288304138182, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 455.39207649230957, "episode_reward": 913.3061465130048, "step": 134000}
{"episode": 135.0, "batch_reward": 0.5426718177199363, "critic_loss": 0.6598035501241684, "actor_loss": -127.77497491455078, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.1568386554718, "episode_reward": 19.322807718231086, "step": 135000}
{"episode": 136.0, "batch_reward": 0.5411630410850048, "critic_loss": 0.6376535470187664, "actor_loss": -125.71795651245117, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 443.70231556892395, "episode_reward": 846.0363021217589, "step": 136000}
{"episode": 137.0, "batch_reward": 0.5420332866907119, "critic_loss": 0.6797528699636459, "actor_loss": -123.67836364746094, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.283188581466675, "episode_reward": 826.0833480392157, "step": 137000}
{"episode": 138.0, "batch_reward": 0.5448533943593502, "critic_loss": 0.7201859839558601, "actor_loss": -122.26110293579102, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 457.0592098236084, "episode_reward": 909.0099384044337, "step": 138000}
{"episode": 139.0, "batch_reward": 0.5473733207285404, "critic_loss": 0.746867563933134, "actor_loss": -120.8953462524414, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.300945043563843, "episode_reward": 884.5128196293352, "step": 139000}
{"episode": 140.0, "batch_reward": 0.548283854752779, "critic_loss": 0.7086490363180638, "actor_loss": -119.42076992797851, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 477.0820617675781, "episode_reward": 889.6914536489627, "step": 140000}
{"episode": 141.0, "batch_reward": 0.5547245649695396, "critic_loss": 0.6664870088994503, "actor_loss": -118.38722087097167, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.2522919178009, "episode_reward": 900.9437858645114, "step": 141000}
{"episode": 142.0, "batch_reward": 0.5552931323349476, "critic_loss": 0.6431403754651547, "actor_loss": -117.03583380126953, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 477.00693798065186, "episode_reward": 905.0083556633115, "step": 142000}
{"episode": 143.0, "batch_reward": 0.5566412947773933, "critic_loss": 0.6211373644471169, "actor_loss": -115.73299450683594, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.82745623588562, "episode_reward": 889.8697841778929, "step": 143000}
{"episode": 144.0, "batch_reward": 0.5587386518418789, "critic_loss": 0.6205966220498085, "actor_loss": -114.76720260620117, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 452.07095885276794, "episode_reward": 924.7312885585217, "step": 144000}
{"episode": 145.0, "batch_reward": 0.5644261851906777, "critic_loss": 0.6112317334711551, "actor_loss": -113.82898092651367, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.15043067932129, "episode_reward": 928.1010546981714, "step": 145000}
{"episode": 146.0, "batch_reward": 0.5657098524272441, "critic_loss": 0.5652719425559044, "actor_loss": -112.80229792785644, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 456.6261992454529, "episode_reward": 886.4962957074729, "step": 146000}
{"episode": 147.0, "batch_reward": 0.5679314534664154, "critic_loss": 0.5414932895898819, "actor_loss": -111.64860539245605, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.2747745513916, "episode_reward": 902.7726868080208, "step": 147000}
{"episode": 148.0, "batch_reward": 0.5676700180470944, "critic_loss": 0.5213225702494383, "actor_loss": -110.54871337890626, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 431.79583072662354, "episode_reward": 880.439463093686, "step": 148000}
{"episode": 149.0, "batch_reward": 0.5704813950061798, "critic_loss": 0.5013438750803471, "actor_loss": -109.45415574645996, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.126787185668945, "episode_reward": 890.5840619069704, "step": 149000}
{"episode": 150.0, "batch_reward": 0.5753251936733723, "critic_loss": 0.4973043108731508, "actor_loss": -108.52258935546875, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "step": 150000}
