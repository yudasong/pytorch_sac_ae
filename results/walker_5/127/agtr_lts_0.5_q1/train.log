{"episode_reward": 0.0, "episode": 1.0, "duration": 21.638922214508057, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.8498001098632812, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.4149205051946338, "critic_loss": 0.14831119368089443, "actor_loss": -42.2423254199648, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 63.38757014274597, "step": 3000}
{"episode_reward": 103.38946939047409, "episode": 4.0, "batch_reward": 0.28686183647811414, "critic_loss": 0.39965335746109487, "actor_loss": -39.731203125, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.5470609664917, "step": 4000}
{"episode_reward": 68.03398334286099, "episode": 5.0, "batch_reward": 0.23992113050818442, "critic_loss": 0.5765828528851271, "actor_loss": -39.68830154132843, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.82669472694397, "step": 5000}
{"episode_reward": 98.59340202088457, "episode": 6.0, "batch_reward": 0.23786509400606157, "critic_loss": 0.9393033157289028, "actor_loss": -42.75700869083405, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.437036752700806, "step": 6000}
{"episode_reward": 390.54155630605953, "episode": 7.0, "batch_reward": 0.2494986975044012, "critic_loss": 0.991327010601759, "actor_loss": -41.6296585483551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.557432651519775, "step": 7000}
{"episode_reward": 177.69094964041616, "episode": 8.0, "batch_reward": 0.2554520727992058, "critic_loss": 1.0911244772076607, "actor_loss": -42.57792487335205, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.201942682266235, "step": 8000}
{"episode_reward": 360.58572265795266, "episode": 9.0, "batch_reward": 0.2743318421691656, "critic_loss": 1.3773424293994903, "actor_loss": -46.19224394416809, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.71917700767517, "step": 9000}
{"episode_reward": 594.9867387393838, "episode": 10.0, "batch_reward": 0.32017931996285914, "critic_loss": 1.6390521611571311, "actor_loss": -48.884149810791016, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.20210909843445, "step": 10000}
{"episode_reward": 779.8284584357108, "episode": 11.0, "batch_reward": 0.36407028475403785, "critic_loss": 1.9051671540737152, "actor_loss": -51.14465079116821, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.97129011154175, "step": 11000}
{"episode_reward": 828.4032615674055, "episode": 12.0, "batch_reward": 0.4064742859005928, "critic_loss": 2.076185695052147, "actor_loss": -54.21001617431641, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.327953577041626, "step": 12000}
{"episode_reward": 898.3489815267098, "episode": 13.0, "batch_reward": 0.44549819591641426, "critic_loss": 2.063332429885864, "actor_loss": -56.65896717071533, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.73137140274048, "step": 13000}
{"episode_reward": 866.8083898420472, "episode": 14.0, "batch_reward": 0.47382537040114403, "critic_loss": 2.104160692334175, "actor_loss": -59.39568439483642, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.83347201347351, "step": 14000}
{"episode_reward": 790.9205176191136, "episode": 15.0, "batch_reward": 0.4946277612745762, "critic_loss": 2.178675379514694, "actor_loss": -62.4617484664917, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.184689044952393, "step": 15000}
{"episode_reward": 751.5955678433284, "episode": 16.0, "batch_reward": 0.51600956761837, "critic_loss": 2.127059597849846, "actor_loss": -64.01112558746338, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.52137804031372, "step": 16000}
{"episode_reward": 813.6435916332506, "episode": 17.0, "batch_reward": 0.5304296877086162, "critic_loss": 2.038438330888748, "actor_loss": -65.14837186431885, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.707722187042236, "step": 17000}
{"episode_reward": 725.8304178398472, "episode": 18.0, "batch_reward": 0.5402017557024956, "critic_loss": 2.083317023873329, "actor_loss": -66.2536245880127, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.409831523895264, "step": 18000}
{"episode_reward": 769.3650127270746, "episode": 19.0, "batch_reward": 0.5586148379743099, "critic_loss": 1.7949034791588783, "actor_loss": -67.36505935668946, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.84507656097412, "step": 19000}
{"episode_reward": 914.2671655580101, "episode": 20.0, "batch_reward": 0.5692888390123844, "critic_loss": 1.859517615199089, "actor_loss": -69.0365556716919, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.780266046524048, "step": 20000}
{"episode_reward": 725.0478605203078, "episode": 21.0, "batch_reward": 0.5835711681544781, "critic_loss": 1.7320921679139136, "actor_loss": -68.65964148712158, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.808034896850586, "step": 21000}
{"episode_reward": 878.5332847859619, "episode": 22.0, "batch_reward": 0.5957090119123459, "critic_loss": 1.7023658821582794, "actor_loss": -71.10589727783203, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.9014093875885, "step": 22000}
{"episode_reward": 909.6655472985557, "episode": 23.0, "batch_reward": 0.6127626799345016, "critic_loss": 1.8360264202356338, "actor_loss": -71.72100553131104, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.083759784698486, "step": 23000}
{"episode_reward": 924.5979393293576, "episode": 24.0, "batch_reward": 0.6199951698184013, "critic_loss": 2.044662591099739, "actor_loss": -72.65234321594238, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.87360453605652, "step": 24000}
{"episode_reward": 716.0963716013797, "episode": 25.0, "batch_reward": 0.6241051689386368, "critic_loss": 2.1205308649539947, "actor_loss": -73.35770603179931, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.88606309890747, "step": 25000}
{"episode_reward": 758.7935339513317, "episode": 26.0, "batch_reward": 0.6322678360939026, "critic_loss": 1.9799550387859344, "actor_loss": -73.7854338684082, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.809223890304565, "step": 26000}
{"episode_reward": 960.4842543633233, "episode": 27.0, "batch_reward": 0.647379378080368, "critic_loss": 1.9061360576152802, "actor_loss": -74.2834660949707, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.09639048576355, "step": 27000}
{"episode_reward": 960.9356524940032, "episode": 28.0, "batch_reward": 0.657395579636097, "critic_loss": 1.8995141635537147, "actor_loss": -75.21257768249512, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.73838996887207, "step": 28000}
{"episode_reward": 927.7124313235282, "episode": 29.0, "batch_reward": 0.6654594817757606, "critic_loss": 1.7518195464015007, "actor_loss": -75.71090197753907, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.18009042739868, "step": 29000}
{"episode_reward": 918.0520511180032, "episode": 30.0, "batch_reward": 0.6730020840764046, "critic_loss": 2.35315369617939, "actor_loss": -75.80715963745118, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.751728296279907, "step": 30000}
{"episode_reward": 735.7449318154179, "episode": 31.0, "batch_reward": 0.6756507456302643, "critic_loss": 2.908712824583054, "actor_loss": -76.69623750305176, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.75090217590332, "step": 31000}
{"episode_reward": 818.5243495493463, "episode": 32.0, "batch_reward": 0.6682266601324082, "critic_loss": 2.4091346303224563, "actor_loss": -77.36216177368163, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.763389825820923, "step": 32000}
{"episode_reward": 17.057394400994674, "episode": 33.0, "batch_reward": 0.6622323895096779, "critic_loss": 2.066011072039604, "actor_loss": -77.31458840942383, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.930438995361328, "step": 33000}
{"episode_reward": 910.2518896290604, "episode": 34.0, "batch_reward": 0.6692030050158501, "critic_loss": 1.996473018169403, "actor_loss": -77.44684541320801, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.467089891433716, "step": 34000}
{"episode_reward": 848.567251485605, "episode": 35.0, "batch_reward": 0.6632010961771011, "critic_loss": 2.0857533966302872, "actor_loss": -77.88841569519043, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.50812292098999, "step": 35000}
{"episode_reward": 280.1960322750597, "episode": 36.0, "batch_reward": 0.6566166380047798, "critic_loss": 2.1326107903718947, "actor_loss": -78.18020889282226, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.93587827682495, "step": 36000}
{"episode_reward": 415.52499329730335, "episode": 37.0, "batch_reward": 0.6558580170869828, "critic_loss": 1.9968945897221566, "actor_loss": -78.31099368286132, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.415805101394653, "step": 37000}
{"episode_reward": 749.084207602678, "episode": 38.0, "batch_reward": 0.654761168718338, "critic_loss": 2.1952477548122404, "actor_loss": -78.3533439025879, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.553532123565674, "step": 38000}
{"episode_reward": 660.3680544973611, "episode": 39.0, "batch_reward": 0.6577556630373002, "critic_loss": 2.1826150047779085, "actor_loss": -78.34615762329102, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.98179793357849, "step": 39000}
{"episode_reward": 836.4027975155653, "episode": 40.0, "batch_reward": 0.6641175340414047, "critic_loss": 1.9877229336500168, "actor_loss": -78.65477940368652, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.39358639717102, "step": 40000}
{"episode_reward": 935.3700598066096, "episode": 41.0, "batch_reward": 0.6691362714171409, "critic_loss": 1.6111997773647309, "actor_loss": -78.72681541442871, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.08822202682495, "step": 41000}
{"episode_reward": 913.5606692326913, "episode": 42.0, "batch_reward": 0.6765532730817795, "critic_loss": 1.5237470048069954, "actor_loss": -78.92920458984375, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.508989334106445, "step": 42000}
{"episode_reward": 909.5668941486894, "episode": 43.0, "batch_reward": 0.6825048555135727, "critic_loss": 1.4195121183991433, "actor_loss": -79.23678134155273, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.63140892982483, "step": 43000}
{"episode_reward": 940.6353087357944, "episode": 44.0, "batch_reward": 0.6876371822357178, "critic_loss": 1.3216878119707107, "actor_loss": -79.54308868408204, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.7352294921875, "step": 44000}
{"episode_reward": 969.3144194056764, "episode": 45.0, "batch_reward": 0.6944037991762161, "critic_loss": 1.1889604820609092, "actor_loss": -79.58747422790528, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.50384283065796, "step": 45000}
{"episode_reward": 956.2396984220104, "episode": 46.0, "batch_reward": 0.6984289721250534, "critic_loss": 1.223132797062397, "actor_loss": -79.637662109375, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.51805090904236, "step": 46000}
{"episode_reward": 973.0467727419573, "episode": 47.0, "batch_reward": 0.7058750733733177, "critic_loss": 1.1862259069085122, "actor_loss": -80.02068356323242, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.182705879211426, "step": 47000}
{"episode_reward": 947.4733567993391, "episode": 48.0, "batch_reward": 0.7108585774302483, "critic_loss": 1.3898623409867286, "actor_loss": -80.21130795288086, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.528506994247437, "step": 48000}
{"episode_reward": 952.8171447767728, "episode": 49.0, "batch_reward": 0.7153567486405372, "critic_loss": 1.6429335740208626, "actor_loss": -80.78584489440918, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.523613214492798, "step": 49000}
{"episode_reward": 972.3557597660049, "episode": 50.0, "batch_reward": 0.7218564622998238, "critic_loss": 2.2351553280353547, "actor_loss": -81.33913618469238, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.30963683128357, "step": 50000}
{"episode_reward": 960.0272942229846, "episode": 51.0, "batch_reward": 0.725271033346653, "critic_loss": 3.2439356899261473, "actor_loss": -82.02025074768066, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.210004568099976, "step": 51000}
{"episode_reward": 924.2278830172721, "episode": 52.0, "batch_reward": 0.7278818656802177, "critic_loss": 5.713363855600357, "actor_loss": -83.04924696350098, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.573938846588135, "step": 52000}
{"episode_reward": 931.4770233223172, "episode": 53.0, "batch_reward": 0.7242082901597023, "critic_loss": 9.856038394451142, "actor_loss": -84.53742610168457, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.48970103263855, "step": 53000}
{"episode_reward": 35.622995750630835, "episode": 54.0, "batch_reward": 0.7187953628897666, "critic_loss": 12.848841760635375, "actor_loss": -85.81253195190429, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.517401695251465, "step": 54000}
{"episode_reward": 940.9795635233854, "episode": 55.0, "batch_reward": 0.7218070901632309, "critic_loss": 13.8337126185894, "actor_loss": -87.84052522277833, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.482823133468628, "step": 55000}
{"episode_reward": 529.5910364110321, "episode": 56.0, "batch_reward": 0.7127626939415932, "critic_loss": 16.029608413696288, "actor_loss": -90.10135284423828, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.168747425079346, "step": 56000}
{"episode_reward": 33.40361847550919, "episode": 57.0, "batch_reward": 0.7013498032093048, "critic_loss": 23.14929613351822, "actor_loss": -97.01526663208008, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.730618238449097, "step": 57000}
{"episode_reward": 18.54162105528903, "episode": 58.0, "batch_reward": 0.6876629154682159, "critic_loss": 49.155866384506226, "actor_loss": -114.28874412536621, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.004048585891724, "step": 58000}
{"episode_reward": 19.035505749603562, "episode": 59.0, "batch_reward": 0.6776056199073791, "critic_loss": 77.02578170776367, "actor_loss": -147.00520703125, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.063666105270386, "step": 59000}
{"episode_reward": 53.95649895794624, "episode": 60.0, "batch_reward": 0.6666365530490875, "critic_loss": 85.27118310165405, "actor_loss": -167.47414857482912, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.807058334350586, "step": 60000}
{"episode_reward": 16.92934856868361, "episode": 61.0, "batch_reward": 0.6571199895739556, "critic_loss": 86.15580947875976, "actor_loss": -195.56213565063476, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.46311640739441, "step": 61000}
{"episode_reward": 18.91917457131609, "episode": 62.0, "batch_reward": 0.6465758328437805, "critic_loss": 87.74510261154175, "actor_loss": -193.95646356201172, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.15459108352661, "step": 62000}
{"episode_reward": 83.25514317628532, "episode": 63.0, "batch_reward": 0.6394315316081047, "critic_loss": 82.48714654541016, "actor_loss": -216.3956262664795, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.463892221450806, "step": 63000}
{"episode_reward": 291.9666704773075, "episode": 64.0, "batch_reward": 0.6328065423369408, "critic_loss": 77.14466912460327, "actor_loss": -205.2954537963867, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.5311496257782, "step": 64000}
{"episode_reward": 357.9422852669621, "episode": 65.0, "batch_reward": 0.6318859055638313, "critic_loss": 73.16504161071778, "actor_loss": -212.03502627563478, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.361680030822754, "step": 65000}
{"episode_reward": 671.6377452115026, "episode": 66.0, "batch_reward": 0.6303331644535065, "critic_loss": 68.48728717422486, "actor_loss": -208.97695446777342, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.40994095802307, "step": 66000}
{"episode_reward": 237.91172242610892, "episode": 67.0, "batch_reward": 0.6244771008491516, "critic_loss": 63.11823028755188, "actor_loss": -200.0234794921875, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.528422594070435, "step": 67000}
{"episode_reward": 667.9762219863092, "episode": 68.0, "batch_reward": 0.626903396487236, "critic_loss": 53.27019676971435, "actor_loss": -197.92820365905763, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.631229639053345, "step": 68000}
{"episode_reward": 670.636243327324, "episode": 69.0, "batch_reward": 0.6251102131605148, "critic_loss": 46.90498308372498, "actor_loss": -208.7555922241211, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.341389656066895, "step": 69000}
{"episode_reward": 542.0483790967002, "episode": 70.0, "batch_reward": 0.6282655046582222, "critic_loss": 38.539904247283935, "actor_loss": -204.09260368347168, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.4874529838562, "step": 70000}
{"episode_reward": 913.5564855177299, "episode": 71.0, "batch_reward": 0.6307979235053063, "critic_loss": 32.4110182056427, "actor_loss": -204.9462250213623, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.13017797470093, "step": 71000}
{"episode_reward": 886.1894929376305, "episode": 72.0, "batch_reward": 0.6370757390856743, "critic_loss": 25.398738344192505, "actor_loss": -200.33953369140625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.522114992141724, "step": 72000}
{"episode_reward": 856.6870657212392, "episode": 73.0, "batch_reward": 0.6385286145806313, "critic_loss": 21.127688592910765, "actor_loss": -194.6953546142578, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.49552059173584, "step": 73000}
{"episode_reward": 870.2377070560589, "episode": 74.0, "batch_reward": 0.6442323635220528, "critic_loss": 17.229629625797273, "actor_loss": -188.28434703063965, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.859462022781372, "step": 74000}
{"episode_reward": 949.2479019552839, "episode": 75.0, "batch_reward": 0.645818598151207, "critic_loss": 14.418476784706115, "actor_loss": -183.8995633087158, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.64720129966736, "step": 75000}
{"episode_reward": 866.2652451645732, "episode": 76.0, "batch_reward": 0.6440921080708504, "critic_loss": 12.233477098464967, "actor_loss": -182.1821175842285, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.589728355407715, "step": 76000}
{"episode_reward": 18.202473800500808, "episode": 77.0, "batch_reward": 0.6402455786466599, "critic_loss": 10.654603023529052, "actor_loss": -173.4518627319336, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.666043043136597, "step": 77000}
{"episode_reward": 916.526076456493, "episode": 78.0, "batch_reward": 0.6458198491334916, "critic_loss": 9.762145636081696, "actor_loss": -173.8187315826416, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.51740574836731, "step": 78000}
{"episode_reward": 950.8089474118428, "episode": 79.0, "batch_reward": 0.6443784084320069, "critic_loss": 8.023796787500382, "actor_loss": -159.9001269683838, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.90917205810547, "step": 79000}
{"episode_reward": 15.621619452628792, "episode": 80.0, "batch_reward": 0.6402642974853515, "critic_loss": 6.89151743555069, "actor_loss": -157.4954740447998, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.68511390686035, "step": 80000}
{"episode_reward": 966.6550137264016, "episode": 81.0, "batch_reward": 0.6385320805311203, "critic_loss": 6.110124876260757, "actor_loss": -152.60813465881347, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.775569677352905, "step": 81000}
{"episode_reward": 25.843133774195103, "episode": 82.0, "batch_reward": 0.6324620288610459, "critic_loss": 5.310820710420608, "actor_loss": -155.55966766357423, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.002676486968994, "step": 82000}
{"episode_reward": 15.376055855927735, "episode": 83.0, "batch_reward": 0.6316715263128281, "critic_loss": 4.5047943787574765, "actor_loss": -145.6285976867676, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.522104263305664, "step": 83000}
{"episode_reward": 968.5418239758193, "episode": 84.0, "batch_reward": 0.6275006612539291, "critic_loss": 3.920309868097305, "actor_loss": -141.5334833984375, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.051059246063232, "step": 84000}
{"episode_reward": 14.419599745369137, "episode": 85.0, "batch_reward": 0.6219774377346039, "critic_loss": 3.4181752896308897, "actor_loss": -143.6167341003418, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.309110403060913, "step": 85000}
{"episode_reward": 13.154636665925617, "episode": 86.0, "batch_reward": 0.6179615206718445, "critic_loss": 3.174853703379631, "actor_loss": -140.08569374084473, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.873728036880493, "step": 86000}
{"episode_reward": 841.6034193539255, "episode": 87.0, "batch_reward": 0.6214292770922184, "critic_loss": 3.137500901341438, "actor_loss": -133.84716186523437, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.915569305419922, "step": 87000}
{"episode_reward": 971.3158094007911, "episode": 88.0, "batch_reward": 0.6250100845098495, "critic_loss": 2.627949101805687, "actor_loss": -131.9337003173828, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.00993299484253, "step": 88000}
{"episode_reward": 938.273016796574, "episode": 89.0, "batch_reward": 0.6256613926887512, "critic_loss": 2.1898915790915487, "actor_loss": -133.27864595031738, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.109030723571777, "step": 89000}
{"episode_reward": 22.41369611082487, "episode": 90.0, "batch_reward": 0.620642383158207, "critic_loss": 2.207441007375717, "actor_loss": -129.90341407775878, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.622847080230713, "step": 90000}
{"episode_reward": 821.2641433372419, "episode": 91.0, "batch_reward": 0.6253620900809765, "critic_loss": 2.0111107106804846, "actor_loss": -128.99930296325684, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.36308693885803, "step": 91000}
{"episode_reward": 975.5183962832665, "episode": 92.0, "batch_reward": 0.6274901534318924, "critic_loss": 1.9386514301896096, "actor_loss": -121.52633746337891, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.46308207511902, "step": 92000}
{"episode_reward": 883.3393529256377, "episode": 93.0, "batch_reward": 0.6313297017812729, "critic_loss": 2.082027171373367, "actor_loss": -123.52359222412109, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.513197422027588, "step": 93000}
{"episode_reward": 932.2352614293029, "episode": 94.0, "batch_reward": 0.6324145230054855, "critic_loss": 1.800311201095581, "actor_loss": -117.14853201293946, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.685917854309082, "step": 94000}
{"episode_reward": 916.601221851114, "episode": 95.0, "batch_reward": 0.638684590101242, "critic_loss": 1.890438967704773, "actor_loss": -112.60014323425293, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.231855869293213, "step": 95000}
{"episode_reward": 919.4224429478357, "episode": 96.0, "batch_reward": 0.6394839399456977, "critic_loss": 1.8266969003081321, "actor_loss": -114.99812242126465, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.53801655769348, "step": 96000}
{"episode_reward": 666.9945349375456, "episode": 97.0, "batch_reward": 0.6426411845684051, "critic_loss": 1.8397354939579964, "actor_loss": -114.65918064880371, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.665952444076538, "step": 97000}
{"episode_reward": 955.0609249292843, "episode": 98.0, "batch_reward": 0.6444469473958016, "critic_loss": 1.9139059008359909, "actor_loss": -108.37577096557617, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.83622407913208, "step": 98000}
{"episode_reward": 967.1007610278727, "episode": 99.0, "batch_reward": 0.6468715739846229, "critic_loss": 2.131767038822174, "actor_loss": -107.99552233886719, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.656492948532104, "step": 99000}
{"episode_reward": 974.5771699986051, "episode": 100.0, "batch_reward": 0.6505526248216629, "critic_loss": 2.6737420454621317, "actor_loss": -107.95806600952149, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.783663749694824, "step": 100000}
{"episode_reward": 871.3146469750577, "episode": 101.0, "batch_reward": 0.647499968290329, "critic_loss": 3.93820047557354, "actor_loss": -108.96621815490722, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.065972566604614, "step": 101000}
{"episode_reward": 11.911465406158444, "episode": 102.0, "batch_reward": 0.6476835941672325, "critic_loss": 4.866148488998413, "actor_loss": -107.06145442199707, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.862974166870117, "step": 102000}
{"episode_reward": 974.4009413351481, "episode": 103.0, "batch_reward": 0.6505411638617515, "critic_loss": 4.261227611541748, "actor_loss": -107.21611114501952, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.76888918876648, "step": 103000}
{"episode_reward": 936.8985296770144, "episode": 104.0, "batch_reward": 0.6470017363429069, "critic_loss": 4.064904415249824, "actor_loss": -109.64198098754883, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.427063941955566, "step": 104000}
{"episode_reward": 144.2671045850159, "episode": 105.0, "batch_reward": 0.6492234759926796, "critic_loss": 3.945157098174095, "actor_loss": -107.33859260559082, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.912673234939575, "step": 105000}
{"episode_reward": 915.1688308724094, "episode": 106.0, "batch_reward": 0.6492670316696167, "critic_loss": 3.539572790980339, "actor_loss": -107.68377320861816, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.76249051094055, "step": 106000}
{"episode_reward": 952.9891073758471, "episode": 107.0, "batch_reward": 0.6492885110974311, "critic_loss": 3.5638649332523347, "actor_loss": -105.87715040588378, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.521910429000854, "step": 107000}
{"episode_reward": 640.5843879100981, "episode": 108.0, "batch_reward": 0.6530336638092995, "critic_loss": 3.4092648893594744, "actor_loss": -101.51383653259278, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.780901670455933, "step": 108000}
{"episode_reward": 928.6305286198941, "episode": 109.0, "batch_reward": 0.6549926285147667, "critic_loss": 3.2723043709993362, "actor_loss": -102.54933143615723, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.944353103637695, "step": 109000}
{"episode_reward": 462.6920677061093, "episode": 110.0, "batch_reward": 0.6496708353459835, "critic_loss": 3.9756536288261413, "actor_loss": -100.784187210083, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.179391145706177, "step": 110000}
{"episode_reward": 51.50152010331979, "episode": 111.0, "batch_reward": 0.6453615657091141, "critic_loss": 4.1451728531122205, "actor_loss": -101.76827949523926, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.775490522384644, "step": 111000}
{"episode_reward": 45.25642813104416, "episode": 112.0, "batch_reward": 0.6401222897171974, "critic_loss": 4.297392118811607, "actor_loss": -100.04576640319824, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.23537254333496, "step": 112000}
{"episode_reward": 13.197121333387477, "episode": 113.0, "batch_reward": 0.6341848279237747, "critic_loss": 4.449305275201797, "actor_loss": -104.9952767791748, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.714731216430664, "step": 113000}
{"episode_reward": 16.16990628107734, "episode": 114.0, "batch_reward": 0.6287822808027268, "critic_loss": 4.779889833688736, "actor_loss": -104.87083247375489, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.63601565361023, "step": 114000}
{"episode_reward": 12.93333583174884, "episode": 115.0, "batch_reward": 0.623212617456913, "critic_loss": 5.590839554786682, "actor_loss": -107.44410841369628, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.563056230545044, "step": 115000}
{"episode_reward": 163.46533029615765, "episode": 116.0, "batch_reward": 0.6201864428520203, "critic_loss": 5.735799329042434, "actor_loss": -108.5780972442627, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.027020692825317, "step": 116000}
{"episode_reward": 401.6871989482035, "episode": 117.0, "batch_reward": 0.6205172542929649, "critic_loss": 5.708566837072373, "actor_loss": -110.87969035339356, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.509824514389038, "step": 117000}
{"episode_reward": 773.8252447643945, "episode": 118.0, "batch_reward": 0.6221914532780647, "critic_loss": 5.585450739383697, "actor_loss": -110.2782286376953, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.804231643676758, "step": 118000}
{"episode_reward": 862.4668855165302, "episode": 119.0, "batch_reward": 0.6206862699985504, "critic_loss": 5.0973481965065, "actor_loss": -109.27609735107421, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.022646188735962, "step": 119000}
{"episode_reward": 643.888375834396, "episode": 120.0, "batch_reward": 0.6256432319283486, "critic_loss": 4.578678374052048, "actor_loss": -108.59448826599122, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.482993125915527, "step": 120000}
{"episode_reward": 939.0589701535755, "episode": 121.0, "batch_reward": 0.6284885491132737, "critic_loss": 4.069150635719299, "actor_loss": -108.53844694519043, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.69017577171326, "step": 121000}
{"episode_reward": 919.4314583480896, "episode": 122.0, "batch_reward": 0.627744339108467, "critic_loss": 3.651070443868637, "actor_loss": -104.73495161437988, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.809025526046753, "step": 122000}
{"episode_reward": 888.8706526892538, "episode": 123.0, "batch_reward": 0.6303807166218758, "critic_loss": 3.277597075343132, "actor_loss": -104.3354937286377, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.940543174743652, "step": 123000}
{"episode_reward": 902.8135737713213, "episode": 124.0, "batch_reward": 0.6331347906589508, "critic_loss": 2.952832073688507, "actor_loss": -102.26436015319824, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.84900164604187, "step": 124000}
{"episode_reward": 956.8325712736861, "episode": 125.0, "batch_reward": 0.6371390589475632, "critic_loss": 2.916200849056244, "actor_loss": -103.43004632568359, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.40269374847412, "step": 125000}
{"episode_reward": 917.6981793449953, "episode": 126.0, "batch_reward": 0.6359357150197029, "critic_loss": 2.5889662618637086, "actor_loss": -102.37687316894531, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.584640502929688, "step": 126000}
{"episode_reward": 963.8360654115821, "episode": 127.0, "batch_reward": 0.6389066093564033, "critic_loss": 2.19750162088871, "actor_loss": -101.1582706451416, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.50148367881775, "step": 127000}
{"episode_reward": 914.2700213494919, "episode": 128.0, "batch_reward": 0.6418365985751152, "critic_loss": 1.9306171306371689, "actor_loss": -101.230931350708, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.36044669151306, "step": 128000}
{"episode_reward": 946.4000454857884, "episode": 129.0, "batch_reward": 0.6446359375119209, "critic_loss": 1.6614068592786788, "actor_loss": -100.6097614440918, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.56871461868286, "step": 129000}
{"episode_reward": 970.251052252441, "episode": 130.0, "batch_reward": 0.6458566306829453, "critic_loss": 1.5296974248886108, "actor_loss": -100.1396566619873, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.507368087768555, "step": 130000}
{"episode_reward": 918.221626713345, "episode": 131.0, "batch_reward": 0.6492385761737823, "critic_loss": 1.5088009917736054, "actor_loss": -99.65277102661133, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.4396333694458, "step": 131000}
{"episode_reward": 952.0675743463979, "episode": 132.0, "batch_reward": 0.6515164408683777, "critic_loss": 1.4008104313015939, "actor_loss": -98.26588763427735, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.84770655632019, "step": 132000}
{"episode_reward": 906.0437024471267, "episode": 133.0, "batch_reward": 0.6541178100109101, "critic_loss": 1.3084659108519554, "actor_loss": -98.73890390014648, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.221527576446533, "step": 133000}
{"episode_reward": 964.0188129621833, "episode": 134.0, "batch_reward": 0.6566973115801811, "critic_loss": 1.1996033542752267, "actor_loss": -96.7131194152832, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.612192153930664, "step": 134000}
{"episode_reward": 955.1932682436855, "episode": 135.0, "batch_reward": 0.656186183989048, "critic_loss": 1.1694639299809932, "actor_loss": -94.89497744750976, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.51404333114624, "step": 135000}
{"episode_reward": 925.5834056141641, "episode": 136.0, "batch_reward": 0.6592419457435608, "critic_loss": 1.1262250097095967, "actor_loss": -94.33674989318848, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.53010892868042, "step": 136000}
{"episode_reward": 911.5943676364878, "episode": 137.0, "batch_reward": 0.663426884651184, "critic_loss": 1.0817244382500648, "actor_loss": -94.08496020507812, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.72215175628662, "step": 137000}
{"episode_reward": 912.7967871418946, "episode": 138.0, "batch_reward": 0.6645497869849205, "critic_loss": 1.054023715674877, "actor_loss": -93.42885972595215, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.51025629043579, "step": 138000}
{"episode_reward": 968.2251100409729, "episode": 139.0, "batch_reward": 0.6648339921236038, "critic_loss": 1.051354477763176, "actor_loss": -93.65387741088867, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.87049961090088, "step": 139000}
{"episode_reward": 911.4235442701302, "episode": 140.0, "batch_reward": 0.669038248538971, "critic_loss": 1.0247421368360519, "actor_loss": -92.95163131713868, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.948795795440674, "step": 140000}
{"episode_reward": 902.7982441947936, "episode": 141.0, "batch_reward": 0.6707018566727638, "critic_loss": 1.0064608927071095, "actor_loss": -92.38681307983398, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.4123911857605, "step": 141000}
{"episode_reward": 935.8722423941258, "episode": 142.0, "batch_reward": 0.6725711731314659, "critic_loss": 1.0218930429816246, "actor_loss": -92.14200950622559, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.557563543319702, "step": 142000}
{"episode_reward": 962.5299080538541, "episode": 143.0, "batch_reward": 0.6730494966506958, "critic_loss": 1.0077366735041142, "actor_loss": -91.69868237304688, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.507962465286255, "step": 143000}
{"episode_reward": 868.4962386176087, "episode": 144.0, "batch_reward": 0.6747977822422981, "critic_loss": 0.9556290397644043, "actor_loss": -91.32214831542969, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.435755491256714, "step": 144000}
{"episode_reward": 913.931213119841, "episode": 145.0, "batch_reward": 0.6763340472579003, "critic_loss": 0.9561089271903038, "actor_loss": -90.45003489685058, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.663465976715088, "step": 145000}
{"episode_reward": 947.5814583728, "episode": 146.0, "batch_reward": 0.6761552346944809, "critic_loss": 0.9740720885097981, "actor_loss": -91.13910591125489, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.527244806289673, "step": 146000}
{"episode_reward": 919.0459318353193, "episode": 147.0, "batch_reward": 0.6793905699253082, "critic_loss": 0.919578222155571, "actor_loss": -90.51702174377441, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.5821635723114, "step": 147000}
{"episode_reward": 900.8581647478195, "episode": 148.0, "batch_reward": 0.6816012279391289, "critic_loss": 0.861872676730156, "actor_loss": -89.87352613830566, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.563249111175537, "step": 148000}
{"episode_reward": 933.4765394297511, "episode": 149.0, "batch_reward": 0.6829310277104378, "critic_loss": 0.8487184055149555, "actor_loss": -89.38712042236328, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.50464653968811, "step": 149000}
{"episode_reward": 925.436241809802, "episode": 150.0, "batch_reward": 0.6829476197957992, "critic_loss": 0.8379360121786594, "actor_loss": -88.46565689086914, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "step": 150000}
