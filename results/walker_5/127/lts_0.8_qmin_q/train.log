{"episode_reward": 0.0, "episode": 1.0, "duration": 22.452958583831787, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.8970062732696533, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.43462042386788613, "critic_loss": 0.5638790973805315, "actor_loss": -75.82731353649858, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 64.34452748298645, "step": 3000}
{"episode_reward": 553.9540029348527, "episode": 4.0, "batch_reward": 0.5267916720211506, "critic_loss": 0.5597066434323787, "actor_loss": -78.06579289245606, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.645535469055176, "step": 4000}
{"episode_reward": 857.3782079417348, "episode": 5.0, "batch_reward": 0.5963637491166591, "critic_loss": 0.49637629714608195, "actor_loss": -79.44240621948242, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.701494932174683, "step": 5000}
{"episode_reward": 883.9245081616372, "episode": 6.0, "batch_reward": 0.6487316245436668, "critic_loss": 0.4319561837017536, "actor_loss": -80.8700696105957, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.84892964363098, "step": 6000}
{"episode_reward": 877.2765543065914, "episode": 7.0, "batch_reward": 0.6911024857759476, "critic_loss": 0.4041804455369711, "actor_loss": -81.76983103942871, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.456352472305298, "step": 7000}
{"episode_reward": 924.5422061849293, "episode": 8.0, "batch_reward": 0.7109464135766029, "critic_loss": 0.41170766612887383, "actor_loss": -82.17724096679687, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.655790090560913, "step": 8000}
{"episode_reward": 833.325834040798, "episode": 9.0, "batch_reward": 0.7354441671967507, "critic_loss": 0.33763461430370806, "actor_loss": -82.86515673828124, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.775081872940063, "step": 9000}
{"episode_reward": 936.0507888684207, "episode": 10.0, "batch_reward": 0.7425000106692314, "critic_loss": 0.3393372835069895, "actor_loss": -83.03574794006347, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.388126373291016, "step": 10000}
{"episode_reward": 791.9191845622884, "episode": 11.0, "batch_reward": 0.7566393966674805, "critic_loss": 0.302520930364728, "actor_loss": -83.21441012573243, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.79073667526245, "step": 11000}
{"episode_reward": 858.691120207266, "episode": 12.0, "batch_reward": 0.7591259353160859, "critic_loss": 0.35501391227543355, "actor_loss": -83.20504974365234, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.635290145874023, "step": 12000}
{"episode_reward": 813.3749502706975, "episode": 13.0, "batch_reward": 0.7568605120182037, "critic_loss": 0.3566834731847048, "actor_loss": -83.14411164855957, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.07785701751709, "step": 13000}
{"episode_reward": 705.0329887285106, "episode": 14.0, "batch_reward": 0.7637438702583313, "critic_loss": 0.34238873539865017, "actor_loss": -83.27303791809082, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.638227939605713, "step": 14000}
{"episode_reward": 874.3664895933674, "episode": 15.0, "batch_reward": 0.7725031774640083, "critic_loss": 0.30764244857430456, "actor_loss": -83.52910426330567, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.957696199417114, "step": 15000}
{"episode_reward": 913.5799688267242, "episode": 16.0, "batch_reward": 0.7820138497948647, "critic_loss": 0.3070710386484861, "actor_loss": -83.67913626098633, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.851234912872314, "step": 16000}
{"episode_reward": 927.3173950315038, "episode": 17.0, "batch_reward": 0.7915941517949104, "critic_loss": 0.31309446729719637, "actor_loss": -83.80189096069336, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.053532361984253, "step": 17000}
{"episode_reward": 878.2549686857986, "episode": 18.0, "batch_reward": 0.79625927734375, "critic_loss": 0.3146493716835976, "actor_loss": -83.94198893737793, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.66321849822998, "step": 18000}
{"episode_reward": 888.8321202652824, "episode": 19.0, "batch_reward": 0.8011778071522713, "critic_loss": 0.3217479702979326, "actor_loss": -84.18503425598145, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.92118525505066, "step": 19000}
{"episode_reward": 922.0130608378266, "episode": 20.0, "batch_reward": 0.807953449010849, "critic_loss": 0.3328227406293154, "actor_loss": -84.50509539794922, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.525652408599854, "step": 20000}
{"episode_reward": 941.3367367616179, "episode": 21.0, "batch_reward": 0.8157986634969712, "critic_loss": 0.34083574038743975, "actor_loss": -84.33132682800293, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.02331352233887, "step": 21000}
{"episode_reward": 913.4855310751886, "episode": 22.0, "batch_reward": 0.8149737347960472, "critic_loss": 0.38878434751927854, "actor_loss": -84.53909275817871, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.741172552108765, "step": 22000}
{"episode_reward": 826.9285141347323, "episode": 23.0, "batch_reward": 0.8180470019578934, "critic_loss": 0.37233918015658857, "actor_loss": -84.5140984802246, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.70268964767456, "step": 23000}
{"episode_reward": 895.3055651794463, "episode": 24.0, "batch_reward": 0.8192888606190681, "critic_loss": 0.3723141870051622, "actor_loss": -84.68442567443847, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.897406101226807, "step": 24000}
{"episode_reward": 868.9396291289719, "episode": 25.0, "batch_reward": 0.8189303144812584, "critic_loss": 0.4093057515472174, "actor_loss": -84.71959230041504, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.01238512992859, "step": 25000}
{"episode_reward": 797.3950287820513, "episode": 26.0, "batch_reward": 0.8241156252026558, "critic_loss": 0.3748386726677418, "actor_loss": -84.7115599822998, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.29175066947937, "step": 26000}
{"episode_reward": 941.8738654782189, "episode": 27.0, "batch_reward": 0.8268109121322632, "critic_loss": 0.3887593849748373, "actor_loss": -84.88517887878417, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.24498176574707, "step": 27000}
{"episode_reward": 925.711788716843, "episode": 28.0, "batch_reward": 0.8309884758591652, "critic_loss": 0.3711692599952221, "actor_loss": -84.97615016174316, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.448434114456177, "step": 28000}
{"episode_reward": 910.6055841600338, "episode": 29.0, "batch_reward": 0.8321971033811569, "critic_loss": 0.37905824699997903, "actor_loss": -85.07192886352539, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.408282041549683, "step": 29000}
{"episode_reward": 895.2688021502312, "episode": 30.0, "batch_reward": 0.8356678446531296, "critic_loss": 0.3474220467209816, "actor_loss": -84.97282881164551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.941369771957397, "step": 30000}
{"episode_reward": 874.6458541537934, "episode": 31.0, "batch_reward": 0.8371480049490929, "critic_loss": 0.3386965119987726, "actor_loss": -85.24374089050293, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.29757761955261, "step": 31000}
{"episode_reward": 913.5259236921692, "episode": 32.0, "batch_reward": 0.8386658610105514, "critic_loss": 0.3395786897689104, "actor_loss": -85.35638781738281, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.22185969352722, "step": 32000}
{"episode_reward": 862.8661005020323, "episode": 33.0, "batch_reward": 0.8410799369812012, "critic_loss": 0.33894701628386975, "actor_loss": -85.32622155761719, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.71196937561035, "step": 33000}
{"episode_reward": 919.0839717412551, "episode": 34.0, "batch_reward": 0.8442736168503762, "critic_loss": 0.34701900970935823, "actor_loss": -85.46073417663574, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.6522159576416, "step": 34000}
{"episode_reward": 943.9780585932023, "episode": 35.0, "batch_reward": 0.8448522128462791, "critic_loss": 0.3240910910665989, "actor_loss": -85.46209706115722, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.956606149673462, "step": 35000}
{"episode_reward": 847.1448985070244, "episode": 36.0, "batch_reward": 0.8446580807566643, "critic_loss": 0.33931440304219723, "actor_loss": -85.55615991210938, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.366148471832275, "step": 36000}
{"episode_reward": 842.224726351312, "episode": 37.0, "batch_reward": 0.8476815827488899, "critic_loss": 0.33233574940264227, "actor_loss": -85.5139369506836, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.532687187194824, "step": 37000}
{"episode_reward": 939.2594185100722, "episode": 38.0, "batch_reward": 0.8493745252490044, "critic_loss": 0.3242618001550436, "actor_loss": -85.52502545166016, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.344055652618408, "step": 38000}
{"episode_reward": 930.4350200417327, "episode": 39.0, "batch_reward": 0.8445230749249458, "critic_loss": 0.34725722546875476, "actor_loss": -85.38675422668457, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.95412254333496, "step": 39000}
{"episode_reward": 660.2772043306086, "episode": 40.0, "batch_reward": 0.845607720553875, "critic_loss": 0.2970321994870901, "actor_loss": -85.60936625671387, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.478699922561646, "step": 40000}
{"episode_reward": 954.3223404946173, "episode": 41.0, "batch_reward": 0.8489442668557167, "critic_loss": 0.31200475761294366, "actor_loss": -85.59673600769042, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.28402900695801, "step": 41000}
{"episode_reward": 949.5641362249465, "episode": 42.0, "batch_reward": 0.8508368876576423, "critic_loss": 0.31574374993145465, "actor_loss": -85.70786730957032, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.88222312927246, "step": 42000}
{"episode_reward": 892.6066985677637, "episode": 43.0, "batch_reward": 0.8519795633554459, "critic_loss": 0.3107685812860727, "actor_loss": -85.74214938354493, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.595110177993774, "step": 43000}
{"episode_reward": 934.0889046929633, "episode": 44.0, "batch_reward": 0.8542369957566261, "critic_loss": 0.3007965132445097, "actor_loss": -86.01790521240234, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.344242572784424, "step": 44000}
{"episode_reward": 927.4908363405273, "episode": 45.0, "batch_reward": 0.8550322431921958, "critic_loss": 0.3130689903497696, "actor_loss": -85.8924739227295, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.762220859527588, "step": 45000}
{"episode_reward": 945.7160324302546, "episode": 46.0, "batch_reward": 0.8576042943000793, "critic_loss": 0.3416527703553438, "actor_loss": -85.91357440185547, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.72236132621765, "step": 46000}
{"episode_reward": 937.3943613996014, "episode": 47.0, "batch_reward": 0.8601491338014603, "critic_loss": 0.34055717003345487, "actor_loss": -86.01936801147461, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.86100935935974, "step": 47000}
{"episode_reward": 945.0348257832452, "episode": 48.0, "batch_reward": 0.8603040742874145, "critic_loss": 0.3296886138021946, "actor_loss": -86.00538461303711, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.979450941085815, "step": 48000}
{"episode_reward": 920.9775464272739, "episode": 49.0, "batch_reward": 0.8621457282900811, "critic_loss": 0.3295721591338515, "actor_loss": -86.22547120666503, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.554943561553955, "step": 49000}
{"episode_reward": 948.7606741725155, "episode": 50.0, "batch_reward": 0.8638291837573051, "critic_loss": 0.3588721332401037, "actor_loss": -86.20998715209961, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.843985557556152, "step": 50000}
{"episode_reward": 923.8522884069682, "episode": 51.0, "batch_reward": 0.864693537056446, "critic_loss": 0.3599026688784361, "actor_loss": -86.24407319641114, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.30883598327637, "step": 51000}
{"episode_reward": 927.4707462566722, "episode": 52.0, "batch_reward": 0.8677366009354591, "critic_loss": 0.34820215351879596, "actor_loss": -86.23494212341309, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.787184476852417, "step": 52000}
{"episode_reward": 934.4508096091159, "episode": 53.0, "batch_reward": 0.8676397019028663, "critic_loss": 0.36446110901236534, "actor_loss": -86.37069107055665, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.500306129455566, "step": 53000}
{"episode_reward": 929.5658068418501, "episode": 54.0, "batch_reward": 0.8696436606049538, "critic_loss": 0.36401308213174344, "actor_loss": -86.44661592102051, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.222915410995483, "step": 54000}
{"episode_reward": 925.362818035898, "episode": 55.0, "batch_reward": 0.8694914581775666, "critic_loss": 0.3801142155379057, "actor_loss": -86.432398147583, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.588293313980103, "step": 55000}
{"episode_reward": 940.1283339266035, "episode": 56.0, "batch_reward": 0.8710641896724701, "critic_loss": 0.39318347749114035, "actor_loss": -86.5017197265625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.555581092834473, "step": 56000}
{"episode_reward": 949.8404797392919, "episode": 57.0, "batch_reward": 0.873601135790348, "critic_loss": 0.387981592386961, "actor_loss": -86.57142733764648, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.794099807739258, "step": 57000}
{"episode_reward": 914.9436375026334, "episode": 58.0, "batch_reward": 0.8726095409989357, "critic_loss": 0.3869934310391545, "actor_loss": -86.54988343811036, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.770915508270264, "step": 58000}
{"episode_reward": 932.5533726363518, "episode": 59.0, "batch_reward": 0.8742833381295204, "critic_loss": 0.37238903948664664, "actor_loss": -86.61239776611328, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.059621334075928, "step": 59000}
{"episode_reward": 958.304616510089, "episode": 60.0, "batch_reward": 0.8758686868548393, "critic_loss": 0.3580660974383354, "actor_loss": -86.68255244445801, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.71268582344055, "step": 60000}
{"episode_reward": 937.6410404888665, "episode": 61.0, "batch_reward": 0.875482258439064, "critic_loss": 0.3801505833789706, "actor_loss": -86.60778741455078, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 45.527775049209595, "step": 61000}
{"episode_reward": 825.9898716267915, "episode": 62.0, "batch_reward": 0.8748027257323265, "critic_loss": 0.40302213706076145, "actor_loss": -86.62181282043457, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.480942249298096, "step": 62000}
{"episode_reward": 823.0929478237067, "episode": 63.0, "batch_reward": 0.8741343071460724, "critic_loss": 0.3915268035531044, "actor_loss": -86.62150953674316, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.731618404388428, "step": 63000}
{"episode_reward": 941.1301453333427, "episode": 64.0, "batch_reward": 0.8760366325378418, "critic_loss": 0.369981472492218, "actor_loss": -86.71734846496582, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.670825004577637, "step": 64000}
{"episode_reward": 883.1612051922704, "episode": 65.0, "batch_reward": 0.8755578815937042, "critic_loss": 0.36545971179008485, "actor_loss": -86.66575849914551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.10812783241272, "step": 65000}
{"episode_reward": 914.1262281325186, "episode": 66.0, "batch_reward": 0.8758635481595993, "critic_loss": 0.374488516420126, "actor_loss": -86.62431436157226, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.44453501701355, "step": 66000}
{"episode_reward": 883.8245279008507, "episode": 67.0, "batch_reward": 0.8762310764193535, "critic_loss": 0.36097831988334655, "actor_loss": -86.71068786621093, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.47560691833496, "step": 67000}
{"episode_reward": 932.8480141091137, "episode": 68.0, "batch_reward": 0.8771135169267654, "critic_loss": 0.37560875521600245, "actor_loss": -86.73578253173828, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.659492254257202, "step": 68000}
{"episode_reward": 895.0897542884142, "episode": 69.0, "batch_reward": 0.8767304717302322, "critic_loss": 0.3737172820419073, "actor_loss": -86.65928758239747, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.72350788116455, "step": 69000}
{"episode_reward": 909.7813407865548, "episode": 70.0, "batch_reward": 0.8788159295320511, "critic_loss": 0.34753925789147616, "actor_loss": -86.69619641113282, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.93593668937683, "step": 70000}
{"episode_reward": 938.292228505902, "episode": 71.0, "batch_reward": 0.8790209512114525, "critic_loss": 0.33642566898465154, "actor_loss": -86.72456344604493, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.58735394477844, "step": 71000}
{"episode_reward": 909.6556443109146, "episode": 72.0, "batch_reward": 0.8781225554347039, "critic_loss": 0.3526331582814455, "actor_loss": -86.7912391204834, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.861133813858032, "step": 72000}
{"episode_reward": 915.2812734658407, "episode": 73.0, "batch_reward": 0.8801849942207336, "critic_loss": 0.34364840857684614, "actor_loss": -86.82344120788574, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.732925415039062, "step": 73000}
{"episode_reward": 911.1225806643429, "episode": 74.0, "batch_reward": 0.8795127822756768, "critic_loss": 0.34181663289666175, "actor_loss": -86.81374304199218, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.645395755767822, "step": 74000}
{"episode_reward": 917.0119193009764, "episode": 75.0, "batch_reward": 0.88074985486269, "critic_loss": 0.34031113601475954, "actor_loss": -86.82966418457032, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.890616416931152, "step": 75000}
{"episode_reward": 908.7510126654872, "episode": 76.0, "batch_reward": 0.8817052916884422, "critic_loss": 0.34553884144127367, "actor_loss": -86.87830143737793, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.85627794265747, "step": 76000}
{"episode_reward": 880.7069049365274, "episode": 77.0, "batch_reward": 0.8799463014006614, "critic_loss": 0.35034503403306005, "actor_loss": -86.84570039367676, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.319422483444214, "step": 77000}
{"episode_reward": 902.994036892006, "episode": 78.0, "batch_reward": 0.8824029837846756, "critic_loss": 0.32539378936588764, "actor_loss": -86.90900022888184, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.14364743232727, "step": 78000}
{"episode_reward": 945.5449482222259, "episode": 79.0, "batch_reward": 0.8834073618650436, "critic_loss": 0.32649685414135454, "actor_loss": -86.98382136535645, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.978182792663574, "step": 79000}
{"episode_reward": 935.4201781279418, "episode": 80.0, "batch_reward": 0.8828000809550285, "critic_loss": 0.3346145929694176, "actor_loss": -86.96249824523926, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.379141807556152, "step": 80000}
{"episode_reward": 942.512452268218, "episode": 81.0, "batch_reward": 0.8838612126111984, "critic_loss": 0.36830070842802526, "actor_loss": -86.9622061920166, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.23760652542114, "step": 81000}
{"episode_reward": 863.1929483063863, "episode": 82.0, "batch_reward": 0.8828915891647339, "critic_loss": 0.3590509374961257, "actor_loss": -86.9176764831543, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.19481110572815, "step": 82000}
{"episode_reward": 938.3616802592737, "episode": 83.0, "batch_reward": 0.8862090760469437, "critic_loss": 0.34614029155671594, "actor_loss": -87.04359043884277, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.521141052246094, "step": 83000}
{"episode_reward": 950.0709375044598, "episode": 84.0, "batch_reward": 0.8842478501200676, "critic_loss": 0.3574936191290617, "actor_loss": -87.05112602233886, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.22603702545166, "step": 84000}
{"episode_reward": 900.8685300711808, "episode": 85.0, "batch_reward": 0.8854809856414795, "critic_loss": 0.34525087274610994, "actor_loss": -87.03112727355958, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.118107795715332, "step": 85000}
{"episode_reward": 934.8038471813779, "episode": 86.0, "batch_reward": 0.8853090331554413, "critic_loss": 0.3486430087313056, "actor_loss": -87.02589338684082, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.220317363739014, "step": 86000}
{"episode_reward": 908.793900598488, "episode": 87.0, "batch_reward": 0.8866274099946022, "critic_loss": 0.34688879089057445, "actor_loss": -87.10422030639648, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.063278675079346, "step": 87000}
{"episode_reward": 956.5040826734523, "episode": 88.0, "batch_reward": 0.8868516328334808, "critic_loss": 0.3368285776078701, "actor_loss": -87.09580442810059, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.501647233963013, "step": 88000}
{"episode_reward": 951.3802417811787, "episode": 89.0, "batch_reward": 0.8861423682570457, "critic_loss": 0.3515776639133692, "actor_loss": -87.09666806030273, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.03424382209778, "step": 89000}
{"episode_reward": 810.2457071403105, "episode": 90.0, "batch_reward": 0.8872291195392609, "critic_loss": 0.3507381167113781, "actor_loss": -87.15037049865722, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.514493227005005, "step": 90000}
{"episode_reward": 903.4705002137777, "episode": 91.0, "batch_reward": 0.8874835559129715, "critic_loss": 0.34259059448540213, "actor_loss": -87.16267108154297, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.234935998916626, "step": 91000}
{"episode_reward": 950.5507288629102, "episode": 92.0, "batch_reward": 0.8859979166984558, "critic_loss": 0.3225103028491139, "actor_loss": -87.13586050415039, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.979668378829956, "step": 92000}
{"episode_reward": 844.9154816740348, "episode": 93.0, "batch_reward": 0.8869778945446014, "critic_loss": 0.3108989112451673, "actor_loss": -87.17698132324219, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.966349601745605, "step": 93000}
{"episode_reward": 921.7610134361522, "episode": 94.0, "batch_reward": 0.8868954285383225, "critic_loss": 0.3469957799464464, "actor_loss": -87.16039846801758, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.497529983520508, "step": 94000}
{"episode_reward": 907.2916271754614, "episode": 95.0, "batch_reward": 0.8866401234269142, "critic_loss": 0.3356738537102938, "actor_loss": -87.18413401794433, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.34991717338562, "step": 95000}
{"episode_reward": 903.0605483401023, "episode": 96.0, "batch_reward": 0.8880019178986549, "critic_loss": 0.37837122835218906, "actor_loss": -87.25243629455566, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.568922519683838, "step": 96000}
{"episode_reward": 925.3060684163795, "episode": 97.0, "batch_reward": 0.8882534472346306, "critic_loss": 0.3466742499023676, "actor_loss": -87.23538169860839, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.724696159362793, "step": 97000}
{"episode_reward": 958.1310003087651, "episode": 98.0, "batch_reward": 0.8888623551130295, "critic_loss": 0.35309495199471713, "actor_loss": -87.2490001373291, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.375733613967896, "step": 98000}
{"episode_reward": 957.3796335109963, "episode": 99.0, "batch_reward": 0.8904505182504654, "critic_loss": 0.3342136452049017, "actor_loss": -87.27208784484863, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.743894338607788, "step": 99000}
{"episode_reward": 967.4206668883123, "episode": 100.0, "batch_reward": 0.8901482403874398, "critic_loss": 0.34047119435667994, "actor_loss": -87.25331791687012, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.993132829666138, "step": 100000}
{"episode_reward": 957.6221233337769, "episode": 101.0, "batch_reward": 0.891125673353672, "critic_loss": 0.35769783148914575, "actor_loss": -87.34188664245606, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 45.32517910003662, "step": 101000}
{"episode_reward": 889.1253195751004, "episode": 102.0, "batch_reward": 0.8922700167298317, "critic_loss": 0.3476047454178333, "actor_loss": -87.32814100646972, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.08382272720337, "step": 102000}
{"episode_reward": 966.7428603710661, "episode": 103.0, "batch_reward": 0.8914048171043396, "critic_loss": 0.34060113225132227, "actor_loss": -87.35595635986328, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.57844614982605, "step": 103000}
{"episode_reward": 953.6295146285607, "episode": 104.0, "batch_reward": 0.8927771354317665, "critic_loss": 0.3291341188773513, "actor_loss": -87.38125704956055, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.925469875335693, "step": 104000}
{"episode_reward": 950.386452731777, "episode": 105.0, "batch_reward": 0.8932551139593125, "critic_loss": 0.33070295049250126, "actor_loss": -87.40140811157227, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.490928173065186, "step": 105000}
{"episode_reward": 906.4703997035808, "episode": 106.0, "batch_reward": 0.8929527185559273, "critic_loss": 0.35079097193479536, "actor_loss": -87.4455855102539, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.619292497634888, "step": 106000}
{"episode_reward": 955.9626130259284, "episode": 107.0, "batch_reward": 0.8923498634696007, "critic_loss": 0.3577494395673275, "actor_loss": -87.39648542785645, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.76643133163452, "step": 107000}
{"episode_reward": 908.1858125785451, "episode": 108.0, "batch_reward": 0.8944559319019317, "critic_loss": 0.339634150929749, "actor_loss": -87.45212370300293, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.5512375831604, "step": 108000}
{"episode_reward": 958.9935717907284, "episode": 109.0, "batch_reward": 0.8956435907483101, "critic_loss": 0.34435269510000943, "actor_loss": -87.48901220703125, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.72380566596985, "step": 109000}
{"episode_reward": 919.2327032912518, "episode": 110.0, "batch_reward": 0.8941960883140564, "critic_loss": 0.34906554179638627, "actor_loss": -87.46492379760743, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.749500513076782, "step": 110000}
{"episode_reward": 906.6170248852542, "episode": 111.0, "batch_reward": 0.8942519356012344, "critic_loss": 0.3578619681894779, "actor_loss": -87.45407453918457, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.076281785964966, "step": 111000}
{"episode_reward": 929.0537321993585, "episode": 112.0, "batch_reward": 0.8950645761489868, "critic_loss": 0.34329789561033247, "actor_loss": -87.48764466857911, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.155261754989624, "step": 112000}
{"episode_reward": 942.5443166237762, "episode": 113.0, "batch_reward": 0.8967776619195938, "critic_loss": 0.3293929099738598, "actor_loss": -87.5532144317627, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.082441568374634, "step": 113000}
{"episode_reward": 967.8269756607308, "episode": 114.0, "batch_reward": 0.8970319222807884, "critic_loss": 0.327981018319726, "actor_loss": -87.54636924743653, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.07873225212097, "step": 114000}
{"episode_reward": 940.7064083480361, "episode": 115.0, "batch_reward": 0.8972474547624588, "critic_loss": 0.3366245212480426, "actor_loss": -87.5631178741455, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.05372643470764, "step": 115000}
{"episode_reward": 956.965668032652, "episode": 116.0, "batch_reward": 0.8982180193662643, "critic_loss": 0.3404477622285485, "actor_loss": -87.54280963134765, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.90053915977478, "step": 116000}
{"episode_reward": 965.2842269271625, "episode": 117.0, "batch_reward": 0.8981676775217057, "critic_loss": 0.33435573322325945, "actor_loss": -87.61115519714356, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.8869411945343, "step": 117000}
{"episode_reward": 950.9384504876703, "episode": 118.0, "batch_reward": 0.8978692342042923, "critic_loss": 0.33181281853467226, "actor_loss": -87.59484523010254, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.414552688598633, "step": 118000}
{"episode_reward": 916.4239527232303, "episode": 119.0, "batch_reward": 0.8985965684652328, "critic_loss": 0.32935937627404926, "actor_loss": -87.61069772338867, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.599372625350952, "step": 119000}
{"episode_reward": 918.6270577464396, "episode": 120.0, "batch_reward": 0.8989170556664466, "critic_loss": 0.3215310114175081, "actor_loss": -87.67229063415527, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.921614170074463, "step": 120000}
{"episode_reward": 965.3052146968226, "episode": 121.0, "batch_reward": 0.8997196449637413, "critic_loss": 0.31628488762676715, "actor_loss": -87.6587692565918, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.76981210708618, "step": 121000}
{"episode_reward": 940.1795679380936, "episode": 122.0, "batch_reward": 0.8993807989358902, "critic_loss": 0.30418352668732407, "actor_loss": -87.65456971740723, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.848043203353882, "step": 122000}
{"episode_reward": 910.0806736313408, "episode": 123.0, "batch_reward": 0.8986420530676842, "critic_loss": 0.3205470724105835, "actor_loss": -87.67697332763672, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.09755516052246, "step": 123000}
{"episode_reward": 888.9486252496636, "episode": 124.0, "batch_reward": 0.8983455885648728, "critic_loss": 0.3354320121183991, "actor_loss": -87.61620301818847, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.05659294128418, "step": 124000}
{"episode_reward": 936.0800610375998, "episode": 125.0, "batch_reward": 0.8991865476965905, "critic_loss": 0.3383834809809923, "actor_loss": -87.6636692199707, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.361701250076294, "step": 125000}
{"episode_reward": 941.4256105758849, "episode": 126.0, "batch_reward": 0.8993619460463523, "critic_loss": 0.3097027082964778, "actor_loss": -87.660711227417, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.53531241416931, "step": 126000}
{"episode_reward": 958.9974325192032, "episode": 127.0, "batch_reward": 0.899762963294983, "critic_loss": 0.3260382995158434, "actor_loss": -87.65767518615722, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.387463808059692, "step": 127000}
{"episode_reward": 875.8069626738654, "episode": 128.0, "batch_reward": 0.8999874525666237, "critic_loss": 0.30476885195821524, "actor_loss": -87.71730123901366, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.731444358825684, "step": 128000}
{"episode_reward": 948.1833306261738, "episode": 129.0, "batch_reward": 0.899905650794506, "critic_loss": 0.3111966572776437, "actor_loss": -87.67427006530762, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.44069814682007, "step": 129000}
{"episode_reward": 960.6396460724427, "episode": 130.0, "batch_reward": 0.9010904603004456, "critic_loss": 0.30901432295888664, "actor_loss": -87.70780686950684, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.9175283908844, "step": 130000}
{"episode_reward": 908.732371599562, "episode": 131.0, "batch_reward": 0.9009715452194214, "critic_loss": 0.3122805311009288, "actor_loss": -87.7784146270752, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 45.346620321273804, "step": 131000}
{"episode_reward": 949.1895550397821, "episode": 132.0, "batch_reward": 0.9009505742788315, "critic_loss": 0.3256887120380998, "actor_loss": -87.73445574951172, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.357043027877808, "step": 132000}
{"episode_reward": 904.86608348386, "episode": 133.0, "batch_reward": 0.9023606839776039, "critic_loss": 0.30454144006967543, "actor_loss": -87.82490557861328, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.221653699874878, "step": 133000}
{"episode_reward": 971.7656808251252, "episode": 134.0, "batch_reward": 0.9022136207818985, "critic_loss": 0.3245286391749978, "actor_loss": -87.77125828552246, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.020122289657593, "step": 134000}
{"episode_reward": 959.8877780926356, "episode": 135.0, "batch_reward": 0.9012481494545936, "critic_loss": 0.3215386868044734, "actor_loss": -87.74005654907226, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.291096925735474, "step": 135000}
{"episode_reward": 895.6839631222466, "episode": 136.0, "batch_reward": 0.9021002912521362, "critic_loss": 0.3281125905290246, "actor_loss": -87.82530877685546, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.82454824447632, "step": 136000}
{"episode_reward": 866.3535899352835, "episode": 137.0, "batch_reward": 0.9018329955935478, "critic_loss": 0.3265197136104107, "actor_loss": -87.8094158630371, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.582846641540527, "step": 137000}
{"episode_reward": 889.7515814685593, "episode": 138.0, "batch_reward": 0.9026908429265023, "critic_loss": 0.3355427926927805, "actor_loss": -87.75756240844727, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.074224710464478, "step": 138000}
{"episode_reward": 961.0166661973334, "episode": 139.0, "batch_reward": 0.9015139631032943, "critic_loss": 0.3222054662033916, "actor_loss": -87.77957084655762, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.21935796737671, "step": 139000}
{"episode_reward": 893.0649140818012, "episode": 140.0, "batch_reward": 0.9015629602074623, "critic_loss": 0.3431170613914728, "actor_loss": -87.73922045898438, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.918676376342773, "step": 140000}
{"episode_reward": 915.1661638999966, "episode": 141.0, "batch_reward": 0.9042874579429626, "critic_loss": 0.33490829035639763, "actor_loss": -87.88639137268066, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.29434561729431, "step": 141000}
{"episode_reward": 946.2467399356306, "episode": 142.0, "batch_reward": 0.9028106943964959, "critic_loss": 0.3219294781088829, "actor_loss": -87.82654464721679, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.82161831855774, "step": 142000}
{"episode_reward": 934.4958671933931, "episode": 143.0, "batch_reward": 0.9036249979138374, "critic_loss": 0.335614008679986, "actor_loss": -87.82136396789551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.447994709014893, "step": 143000}
{"episode_reward": 934.4290806762283, "episode": 144.0, "batch_reward": 0.9032491583824158, "critic_loss": 0.3384288042485714, "actor_loss": -87.83416795349122, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.38272261619568, "step": 144000}
{"episode_reward": 938.0094743582371, "episode": 145.0, "batch_reward": 0.9043839532136917, "critic_loss": 0.3231926221773028, "actor_loss": -87.86836351013184, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.200982093811035, "step": 145000}
{"episode_reward": 947.3417718472214, "episode": 146.0, "batch_reward": 0.9029630099534989, "critic_loss": 0.31153297577053307, "actor_loss": -87.81605070495606, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.1863751411438, "step": 146000}
{"episode_reward": 905.4341507453931, "episode": 147.0, "batch_reward": 0.9030197035074234, "critic_loss": 0.3198396417051554, "actor_loss": -87.84663291931152, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.56993341445923, "step": 147000}
{"episode_reward": 889.3535981210164, "episode": 148.0, "batch_reward": 0.9036511167287826, "critic_loss": 0.31784743718057873, "actor_loss": -87.87714054870605, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.05806875228882, "step": 148000}
{"episode_reward": 953.817448802805, "episode": 149.0, "batch_reward": 0.9042000650167465, "critic_loss": 0.31864660846441983, "actor_loss": -87.83556846618653, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.56213116645813, "step": 149000}
{"episode_reward": 908.5503835612524, "episode": 150.0, "batch_reward": 0.9040435844063759, "critic_loss": 0.32184806349128486, "actor_loss": -87.83073274230956, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "step": 150000}
