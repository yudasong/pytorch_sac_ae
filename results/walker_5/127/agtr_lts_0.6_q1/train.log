{"episode_reward": 0.0, "episode": 1.0, "duration": 21.27971911430359, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.8838303089141846, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.4187846233463955, "critic_loss": 0.1478126426092304, "actor_loss": -49.44161440796103, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 63.38952898979187, "step": 3000}
{"episode_reward": 143.67514551136966, "episode": 4.0, "batch_reward": 0.3263558042794466, "critic_loss": 0.45568102353811263, "actor_loss": -47.64951378154755, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.080397367477417, "step": 4000}
{"episode_reward": 307.21223167566706, "episode": 5.0, "batch_reward": 0.34219072525203226, "critic_loss": 0.6596831741333008, "actor_loss": -46.96067535686493, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.903504610061646, "step": 5000}
{"episode_reward": 498.0488445369344, "episode": 6.0, "batch_reward": 0.3588236095458269, "critic_loss": 0.7685494672060013, "actor_loss": -50.25254013442993, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.321178436279297, "step": 6000}
{"episode_reward": 256.282276383811, "episode": 7.0, "batch_reward": 0.339747849971056, "critic_loss": 1.0315792136788369, "actor_loss": -47.57242963218689, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.671170473098755, "step": 7000}
{"episode_reward": 277.32998833397556, "episode": 8.0, "batch_reward": 0.3453754180520773, "critic_loss": 1.212614026427269, "actor_loss": -50.666242946624756, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.896626472473145, "step": 8000}
{"episode_reward": 485.58639239043515, "episode": 9.0, "batch_reward": 0.3557947365939617, "critic_loss": 1.6226732271909714, "actor_loss": -52.254795989990235, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.31221890449524, "step": 9000}
{"episode_reward": 408.58385451776843, "episode": 10.0, "batch_reward": 0.3689654029905796, "critic_loss": 1.8892764410972596, "actor_loss": -52.825300914764405, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.936402797698975, "step": 10000}
{"episode_reward": 589.4881193796066, "episode": 11.0, "batch_reward": 0.4013286102116108, "critic_loss": 2.1385515590906143, "actor_loss": -54.281723125457766, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.11065435409546, "step": 11000}
{"episode_reward": 817.7094632991588, "episode": 12.0, "batch_reward": 0.43981811678409577, "critic_loss": 1.9737774300575257, "actor_loss": -56.798546016693116, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.88200831413269, "step": 12000}
{"episode_reward": 866.7074720041575, "episode": 13.0, "batch_reward": 0.4721205376088619, "critic_loss": 1.9456889389753342, "actor_loss": -57.79825058746338, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.509140968322754, "step": 13000}
{"episode_reward": 855.0278234044534, "episode": 14.0, "batch_reward": 0.5021617985367774, "critic_loss": 1.8950348885059356, "actor_loss": -59.190505500793456, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.675518035888672, "step": 14000}
{"episode_reward": 853.5969931412745, "episode": 15.0, "batch_reward": 0.5265614975988865, "critic_loss": 1.7553569618463516, "actor_loss": -62.507275619506835, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.575417518615723, "step": 15000}
{"episode_reward": 908.406086917707, "episode": 16.0, "batch_reward": 0.5480633508563042, "critic_loss": 1.7976979141235352, "actor_loss": -62.85844420623779, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.553179025650024, "step": 16000}
{"episode_reward": 818.236319415434, "episode": 17.0, "batch_reward": 0.5672532957494258, "critic_loss": 1.719996090054512, "actor_loss": -63.79021928405762, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.502191066741943, "step": 17000}
{"episode_reward": 861.6348251988125, "episode": 18.0, "batch_reward": 0.5840592787265778, "critic_loss": 1.7323854660391809, "actor_loss": -64.93414283752442, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.618441343307495, "step": 18000}
{"episode_reward": 885.7544348329518, "episode": 19.0, "batch_reward": 0.6032067757248879, "critic_loss": 1.480324580013752, "actor_loss": -66.22529759216309, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.566561460494995, "step": 19000}
{"episode_reward": 938.5416188498451, "episode": 20.0, "batch_reward": 0.6180625949501991, "critic_loss": 1.2887941121459008, "actor_loss": -68.23864636993409, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.004298448562622, "step": 20000}
{"episode_reward": 925.5419608699764, "episode": 21.0, "batch_reward": 0.6156987249851227, "critic_loss": 1.209029241144657, "actor_loss": -66.2190558013916, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.09981656074524, "step": 21000}
{"episode_reward": 12.776626784157026, "episode": 22.0, "batch_reward": 0.6058638420701027, "critic_loss": 1.1505594262480736, "actor_loss": -68.16629856872558, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.02332091331482, "step": 22000}
{"episode_reward": 930.5933825192513, "episode": 23.0, "batch_reward": 0.619927917957306, "critic_loss": 1.1283963580727576, "actor_loss": -67.91997448730469, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.077412843704224, "step": 23000}
{"episode_reward": 873.1740623420035, "episode": 24.0, "batch_reward": 0.6321683862805366, "critic_loss": 1.091794661641121, "actor_loss": -69.30998878479004, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.12610411643982, "step": 24000}
{"episode_reward": 932.5854293340872, "episode": 25.0, "batch_reward": 0.6443754093647003, "critic_loss": 1.0516664417982102, "actor_loss": -70.69598084259033, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.47390389442444, "step": 25000}
{"episode_reward": 923.3174888387852, "episode": 26.0, "batch_reward": 0.6546261294484138, "critic_loss": 1.0963751231431962, "actor_loss": -70.97214447021484, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.852898120880127, "step": 26000}
{"episode_reward": 946.5991790024478, "episode": 27.0, "batch_reward": 0.6654375546574592, "critic_loss": 0.9559756371378899, "actor_loss": -71.26104513549805, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.809056520462036, "step": 27000}
{"episode_reward": 954.5861871842353, "episode": 28.0, "batch_reward": 0.6763595783114433, "critic_loss": 1.0444177030920982, "actor_loss": -72.82493717193603, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.550590991973877, "step": 28000}
{"episode_reward": 929.1210147954075, "episode": 29.0, "batch_reward": 0.6828241867423057, "critic_loss": 1.0205025991201402, "actor_loss": -72.79423927307128, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.889753818511963, "step": 29000}
{"episode_reward": 904.7522336600283, "episode": 30.0, "batch_reward": 0.6936392859220505, "critic_loss": 1.0159130230545999, "actor_loss": -73.25492358398438, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.50370693206787, "step": 30000}
{"episode_reward": 872.3287880314823, "episode": 31.0, "batch_reward": 0.6951757797002792, "critic_loss": 0.9780303301215172, "actor_loss": -73.97346533966065, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.00938177108765, "step": 31000}
{"episode_reward": 816.7319371717233, "episode": 32.0, "batch_reward": 0.7018466037511826, "critic_loss": 1.0269944074749946, "actor_loss": -74.66531071472168, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.571261644363403, "step": 32000}
{"episode_reward": 878.4134412875077, "episode": 33.0, "batch_reward": 0.7049451449513435, "critic_loss": 1.063636106789112, "actor_loss": -74.89488626861572, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.511295557022095, "step": 33000}
{"episode_reward": 774.1446910750869, "episode": 34.0, "batch_reward": 0.7100186725258827, "critic_loss": 1.0224155971109867, "actor_loss": -75.27201130676269, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.710623502731323, "step": 34000}
{"episode_reward": 931.0687428385841, "episode": 35.0, "batch_reward": 0.7139187191724777, "critic_loss": 0.9906204628348351, "actor_loss": -75.83362062072754, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.53113102912903, "step": 35000}
{"episode_reward": 852.6114058381329, "episode": 36.0, "batch_reward": 0.719014692902565, "critic_loss": 0.9421460983753205, "actor_loss": -76.81135469055175, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.60045313835144, "step": 36000}
{"episode_reward": 879.5148448891758, "episode": 37.0, "batch_reward": 0.7251925647854806, "critic_loss": 0.9542182772159576, "actor_loss": -76.44340873718262, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.862428665161133, "step": 37000}
{"episode_reward": 956.7401118651338, "episode": 38.0, "batch_reward": 0.7302108842730523, "critic_loss": 0.9451027022004127, "actor_loss": -76.89472720336914, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.766435861587524, "step": 38000}
{"episode_reward": 926.6223705392532, "episode": 39.0, "batch_reward": 0.7352239990234375, "critic_loss": 0.8949135486781598, "actor_loss": -77.19160182189941, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.642281532287598, "step": 39000}
{"episode_reward": 922.3449317071729, "episode": 40.0, "batch_reward": 0.7406799347400665, "critic_loss": 0.8737287318706513, "actor_loss": -77.79329902648925, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.337458848953247, "step": 40000}
{"episode_reward": 953.8126740149627, "episode": 41.0, "batch_reward": 0.7454717901349067, "critic_loss": 0.8454757946133613, "actor_loss": -77.59749739074707, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.380234479904175, "step": 41000}
{"episode_reward": 929.0998823276435, "episode": 42.0, "batch_reward": 0.7493784536123276, "critic_loss": 0.8593675924539566, "actor_loss": -78.34842814636231, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.34031105041504, "step": 42000}
{"episode_reward": 918.2027734011456, "episode": 43.0, "batch_reward": 0.7541770256757736, "critic_loss": 0.8149816594719886, "actor_loss": -78.91957261657714, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.572028398513794, "step": 43000}
{"episode_reward": 956.5402286656673, "episode": 44.0, "batch_reward": 0.7587361775636673, "critic_loss": 0.7783197359740734, "actor_loss": -79.63827638244629, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.036151885986328, "step": 44000}
{"episode_reward": 943.3773934235727, "episode": 45.0, "batch_reward": 0.7613785204291343, "critic_loss": 0.7703594496846199, "actor_loss": -79.55885696411133, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.54965043067932, "step": 45000}
{"episode_reward": 943.0183629859147, "episode": 46.0, "batch_reward": 0.7653597574830056, "critic_loss": 0.7833813539147377, "actor_loss": -79.37193913269043, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.68096160888672, "step": 46000}
{"episode_reward": 954.757583791091, "episode": 47.0, "batch_reward": 0.7697191643714905, "critic_loss": 0.7940030266940594, "actor_loss": -79.9020440826416, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.986252307891846, "step": 47000}
{"episode_reward": 853.1281799989732, "episode": 48.0, "batch_reward": 0.7733175109028816, "critic_loss": 0.7738905401527881, "actor_loss": -80.11535108947754, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.10358190536499, "step": 48000}
{"episode_reward": 946.8577737039494, "episode": 49.0, "batch_reward": 0.7763157458901405, "critic_loss": 0.7686707898378372, "actor_loss": -80.75983460998535, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.850889682769775, "step": 49000}
{"episode_reward": 949.3685706677913, "episode": 50.0, "batch_reward": 0.7800270848274231, "critic_loss": 0.7896041029393673, "actor_loss": -80.86259532165528, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.741079330444336, "step": 50000}
{"episode_reward": 947.3392061173207, "episode": 51.0, "batch_reward": 0.7826803880929947, "critic_loss": 0.7264010960161686, "actor_loss": -81.04612347412109, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.750919818878174, "step": 51000}
{"episode_reward": 940.1603570066258, "episode": 52.0, "batch_reward": 0.7867307010293006, "critic_loss": 0.7453192503750324, "actor_loss": -80.91458949279784, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.865986585617065, "step": 52000}
{"episode_reward": 883.2095292586091, "episode": 53.0, "batch_reward": 0.7864783685803414, "critic_loss": 0.7744429211616516, "actor_loss": -81.35448905944824, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.656981706619263, "step": 53000}
{"episode_reward": 944.1834767293352, "episode": 54.0, "batch_reward": 0.7913135826587677, "critic_loss": 0.7035262033641339, "actor_loss": -81.83040808105468, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.92399263381958, "step": 54000}
{"episode_reward": 930.2868136124831, "episode": 55.0, "batch_reward": 0.7926380610466004, "critic_loss": 0.6951963818967343, "actor_loss": -81.58880310058593, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.019519567489624, "step": 55000}
{"episode_reward": 933.4355372238757, "episode": 56.0, "batch_reward": 0.7955101500749588, "critic_loss": 0.6940714178979397, "actor_loss": -81.86793376159667, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.959967136383057, "step": 56000}
{"episode_reward": 938.1679999017363, "episode": 57.0, "batch_reward": 0.797416540145874, "critic_loss": 0.716947850137949, "actor_loss": -81.94500717163086, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.989485025405884, "step": 57000}
{"episode_reward": 895.9850588198768, "episode": 58.0, "batch_reward": 0.7981909257173538, "critic_loss": 0.6640526745915413, "actor_loss": -82.14040042114257, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.953566551208496, "step": 58000}
{"episode_reward": 937.5115433638533, "episode": 59.0, "batch_reward": 0.8033595369458199, "critic_loss": 0.7062756415009499, "actor_loss": -82.35921836853028, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.590781450271606, "step": 59000}
{"episode_reward": 952.4480930182541, "episode": 60.0, "batch_reward": 0.8054058337807656, "critic_loss": 0.7166834240853787, "actor_loss": -82.67167774963379, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.948927402496338, "step": 60000}
{"episode_reward": 930.7369414213281, "episode": 61.0, "batch_reward": 0.8090851825475692, "critic_loss": 0.7332352686822414, "actor_loss": -82.55926599121094, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.25507688522339, "step": 61000}
{"episode_reward": 930.1671828801184, "episode": 62.0, "batch_reward": 0.810029229581356, "critic_loss": 0.6876971923559904, "actor_loss": -82.88859838867188, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.103533029556274, "step": 62000}
{"episode_reward": 924.9331365817118, "episode": 63.0, "batch_reward": 0.8118554272055626, "critic_loss": 0.6714750238060951, "actor_loss": -82.8218159790039, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.91383409500122, "step": 63000}
{"episode_reward": 949.7744069152803, "episode": 64.0, "batch_reward": 0.8131683803200722, "critic_loss": 0.6549727663397789, "actor_loss": -82.97188090515137, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.7897469997406, "step": 64000}
{"episode_reward": 917.9650087549702, "episode": 65.0, "batch_reward": 0.8158414786458016, "critic_loss": 0.6170506531000137, "actor_loss": -83.18622869873047, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.32807946205139, "step": 65000}
{"episode_reward": 946.5542116227181, "episode": 66.0, "batch_reward": 0.8138469190001488, "critic_loss": 0.6882591869831085, "actor_loss": -83.0746071472168, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.708446264266968, "step": 66000}
{"episode_reward": 818.5631068371315, "episode": 67.0, "batch_reward": 0.8156013821363449, "critic_loss": 0.6439042835533619, "actor_loss": -83.28379888916015, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.548547744750977, "step": 67000}
{"episode_reward": 927.8154181273106, "episode": 68.0, "batch_reward": 0.8182375892400742, "critic_loss": 0.6327269073128701, "actor_loss": -83.50754304504395, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.622422456741333, "step": 68000}
{"episode_reward": 927.4725004368346, "episode": 69.0, "batch_reward": 0.8192048778533936, "critic_loss": 0.648297912850976, "actor_loss": -83.33079083251953, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.746623992919922, "step": 69000}
{"episode_reward": 896.6819320137621, "episode": 70.0, "batch_reward": 0.8198306809067726, "critic_loss": 0.6916933519244194, "actor_loss": -83.35595376586915, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.543848276138306, "step": 70000}
{"episode_reward": 852.6909934983132, "episode": 71.0, "batch_reward": 0.8204534085392952, "critic_loss": 0.6408743455857039, "actor_loss": -83.39974891662598, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.8890335559845, "step": 71000}
{"episode_reward": 889.5866613265687, "episode": 72.0, "batch_reward": 0.8219462388753891, "critic_loss": 0.6619228253662586, "actor_loss": -83.57146508789063, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.545410633087158, "step": 72000}
{"episode_reward": 946.4708202712544, "episode": 73.0, "batch_reward": 0.8247558795809746, "critic_loss": 0.6598134125322104, "actor_loss": -83.72005627441406, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.683168411254883, "step": 73000}
{"episode_reward": 918.8164618304027, "episode": 74.0, "batch_reward": 0.8262657084465027, "critic_loss": 0.6514381803572178, "actor_loss": -83.76654304504395, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.937422037124634, "step": 74000}
{"episode_reward": 938.984555736419, "episode": 75.0, "batch_reward": 0.8250246682763099, "critic_loss": 0.6505808833539486, "actor_loss": -83.79193923950196, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.608768701553345, "step": 75000}
{"episode_reward": 874.8059394750641, "episode": 76.0, "batch_reward": 0.8274329259991646, "critic_loss": 0.6368920264840126, "actor_loss": -83.82647525024414, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.144976377487183, "step": 76000}
{"episode_reward": 923.304608246003, "episode": 77.0, "batch_reward": 0.8283125444054603, "critic_loss": 0.6699350166618824, "actor_loss": -83.99288932800293, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.3241183757782, "step": 77000}
{"episode_reward": 904.7094412985618, "episode": 78.0, "batch_reward": 0.8292858098149299, "critic_loss": 0.6561802259981632, "actor_loss": -83.99770195007324, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.646052598953247, "step": 78000}
{"episode_reward": 937.910580588751, "episode": 79.0, "batch_reward": 0.8301376079916954, "critic_loss": 0.7926997953057289, "actor_loss": -84.14039424133301, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.066112518310547, "step": 79000}
{"episode_reward": 817.1115351173839, "episode": 80.0, "batch_reward": 0.8306861420869828, "critic_loss": 0.6437652771174908, "actor_loss": -84.18945889282226, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.56382131576538, "step": 80000}
{"episode_reward": 948.2195368959419, "episode": 81.0, "batch_reward": 0.8333760560750961, "critic_loss": 0.6578123313039541, "actor_loss": -84.21751243591308, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.61466836929321, "step": 81000}
{"episode_reward": 931.2027439594702, "episode": 82.0, "batch_reward": 0.8327159952521325, "critic_loss": 0.6406133802533149, "actor_loss": -84.15207360839844, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.39525842666626, "step": 82000}
{"episode_reward": 928.8166897981648, "episode": 83.0, "batch_reward": 0.8366471109390259, "critic_loss": 0.6438993486166, "actor_loss": -84.4537001953125, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.526439905166626, "step": 83000}
{"episode_reward": 939.7480032060008, "episode": 84.0, "batch_reward": 0.8345044012069702, "critic_loss": 0.706145917236805, "actor_loss": -84.42501245117188, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.938527584075928, "step": 84000}
{"episode_reward": 832.7573627218642, "episode": 85.0, "batch_reward": 0.8351331447958946, "critic_loss": 0.6881789117753506, "actor_loss": -84.37778704833984, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.157315731048584, "step": 85000}
{"episode_reward": 878.5892322922762, "episode": 86.0, "batch_reward": 0.838421702682972, "critic_loss": 0.6861748907417059, "actor_loss": -84.48339810180664, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.819885969161987, "step": 86000}
{"episode_reward": 941.1285554071499, "episode": 87.0, "batch_reward": 0.8382818347215653, "critic_loss": 0.6755766749978066, "actor_loss": -84.62696151733398, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.02897047996521, "step": 87000}
{"episode_reward": 944.8789586962029, "episode": 88.0, "batch_reward": 0.8393696413040161, "critic_loss": 0.6610768917649984, "actor_loss": -84.50868188476562, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.408534288406372, "step": 88000}
{"episode_reward": 924.7497440928049, "episode": 89.0, "batch_reward": 0.8405335170030593, "critic_loss": 0.6722308306992054, "actor_loss": -84.50365156555176, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.865013599395752, "step": 89000}
{"episode_reward": 815.0650412301984, "episode": 90.0, "batch_reward": 0.8396028230786323, "critic_loss": 0.6645128616094589, "actor_loss": -84.53282395935058, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.95985221862793, "step": 90000}
{"episode_reward": 893.3525567793353, "episode": 91.0, "batch_reward": 0.840870927453041, "critic_loss": 0.6837711670249701, "actor_loss": -84.61886979675293, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.980432987213135, "step": 91000}
{"episode_reward": 950.5695068926933, "episode": 92.0, "batch_reward": 0.8413129762411118, "critic_loss": 0.6692500464320182, "actor_loss": -84.73520825195313, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.825464487075806, "step": 92000}
{"episode_reward": 898.2933553410794, "episode": 93.0, "batch_reward": 0.8416941179633141, "critic_loss": 0.674197175860405, "actor_loss": -84.71021788024902, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.769514560699463, "step": 93000}
{"episode_reward": 948.9056297904888, "episode": 94.0, "batch_reward": 0.8429001452326774, "critic_loss": 0.681171879246831, "actor_loss": -84.828290725708, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.169251441955566, "step": 94000}
{"episode_reward": 901.6648693646509, "episode": 95.0, "batch_reward": 0.8439265314340592, "critic_loss": 0.6854583403170109, "actor_loss": -84.95120309448242, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.71021604537964, "step": 95000}
{"episode_reward": 898.9261121953749, "episode": 96.0, "batch_reward": 0.8451353346705437, "critic_loss": 0.630175753980875, "actor_loss": -84.88016279602051, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.573650598526, "step": 96000}
{"episode_reward": 924.1004508862652, "episode": 97.0, "batch_reward": 0.8446384718418122, "critic_loss": 0.6824864120483398, "actor_loss": -84.82837179565429, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.19049620628357, "step": 97000}
{"episode_reward": 950.0646458544045, "episode": 98.0, "batch_reward": 0.8463485676050186, "critic_loss": 0.6442667442858219, "actor_loss": -85.09850590515137, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.783442497253418, "step": 98000}
{"episode_reward": 910.7100464420628, "episode": 99.0, "batch_reward": 0.8468381789326668, "critic_loss": 0.6250108447670937, "actor_loss": -84.98410638427734, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.54689598083496, "step": 99000}
{"episode_reward": 955.911355250686, "episode": 100.0, "batch_reward": 0.8477580345869065, "critic_loss": 0.6707814875990152, "actor_loss": -85.03388229370117, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.224981546401978, "step": 100000}
{"episode_reward": 954.4866915869468, "episode": 101.0, "batch_reward": 0.8483279731869697, "critic_loss": 0.6978622059524059, "actor_loss": -85.16314916992188, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.35596966743469, "step": 101000}
{"episode_reward": 913.8782713335642, "episode": 102.0, "batch_reward": 0.8515248246788979, "critic_loss": 0.6482068179100752, "actor_loss": -85.27059742736816, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.106041431427002, "step": 102000}
{"episode_reward": 950.0207811927079, "episode": 103.0, "batch_reward": 0.850112624168396, "critic_loss": 0.6688825295716524, "actor_loss": -85.24277185058594, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.10715365409851, "step": 103000}
{"episode_reward": 875.3886372901029, "episode": 104.0, "batch_reward": 0.8518941849470139, "critic_loss": 0.6400759888291359, "actor_loss": -85.25415966796875, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.758366346359253, "step": 104000}
{"episode_reward": 937.1378670234603, "episode": 105.0, "batch_reward": 0.8525608621239662, "critic_loss": 0.6233694211244584, "actor_loss": -85.2984790802002, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.5966374874115, "step": 105000}
{"episode_reward": 887.6677766267242, "episode": 106.0, "batch_reward": 0.8528048798441887, "critic_loss": 0.6167058507651091, "actor_loss": -85.31330212402344, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.43219828605652, "step": 106000}
{"episode_reward": 953.0058505467598, "episode": 107.0, "batch_reward": 0.8486768081188202, "critic_loss": 0.6540601123273373, "actor_loss": -85.10732176208496, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.626569509506226, "step": 107000}
{"episode_reward": 11.1911408334823, "episode": 108.0, "batch_reward": 0.8450739399194718, "critic_loss": 0.6685524528026581, "actor_loss": -85.1623356628418, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.671143054962158, "step": 108000}
{"episode_reward": 920.602285447857, "episode": 109.0, "batch_reward": 0.8458063158392907, "critic_loss": 0.6421104969382286, "actor_loss": -85.06251963806152, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.971877098083496, "step": 109000}
{"episode_reward": 911.0743882866846, "episode": 110.0, "batch_reward": 0.845767509996891, "critic_loss": 0.6511196283102035, "actor_loss": -85.22723899841309, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.53664231300354, "step": 110000}
{"episode_reward": 883.2649678565355, "episode": 111.0, "batch_reward": 0.8471539763212204, "critic_loss": 0.647726883739233, "actor_loss": -85.07548657226563, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.28726291656494, "step": 111000}
{"episode_reward": 952.1249262177093, "episode": 112.0, "batch_reward": 0.8470186668634415, "critic_loss": 0.6420531260818243, "actor_loss": -85.22521350097657, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.750900983810425, "step": 112000}
{"episode_reward": 941.2293252914714, "episode": 113.0, "batch_reward": 0.8497088490128517, "critic_loss": 0.5895035521090031, "actor_loss": -85.2328052520752, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.105393171310425, "step": 113000}
{"episode_reward": 955.0852759774256, "episode": 114.0, "batch_reward": 0.8509990896582603, "critic_loss": 0.6181522617787123, "actor_loss": -85.2962593536377, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.729760885238647, "step": 114000}
{"episode_reward": 935.9152339247601, "episode": 115.0, "batch_reward": 0.8514073613882065, "critic_loss": 0.5933640985935926, "actor_loss": -85.31794793701172, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.570990562438965, "step": 115000}
{"episode_reward": 954.0107674744095, "episode": 116.0, "batch_reward": 0.8509043086767196, "critic_loss": 0.5915913870632649, "actor_loss": -85.25643923950196, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.506014823913574, "step": 116000}
{"episode_reward": 955.3784906998064, "episode": 117.0, "batch_reward": 0.8514011453986168, "critic_loss": 0.5951979528814554, "actor_loss": -85.25255017089843, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.743905305862427, "step": 117000}
{"episode_reward": 952.8568820870869, "episode": 118.0, "batch_reward": 0.8533342685699463, "critic_loss": 0.6065728661417961, "actor_loss": -85.30473849487305, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.528736114501953, "step": 118000}
{"episode_reward": 944.3171274309465, "episode": 119.0, "batch_reward": 0.855034220635891, "critic_loss": 0.5921736609339714, "actor_loss": -85.33376977539062, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.92664384841919, "step": 119000}
{"episode_reward": 909.5132089218932, "episode": 120.0, "batch_reward": 0.8536015080213547, "critic_loss": 0.6578483018577099, "actor_loss": -85.38531326293945, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.564793586730957, "step": 120000}
{"episode_reward": 939.3233162643023, "episode": 121.0, "batch_reward": 0.8562832058668136, "critic_loss": 0.5995061801522971, "actor_loss": -85.43190563964843, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.46220350265503, "step": 121000}
{"episode_reward": 924.4615559111564, "episode": 122.0, "batch_reward": 0.856028865814209, "critic_loss": 0.599066055059433, "actor_loss": -85.46638175964355, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.371922731399536, "step": 122000}
{"episode_reward": 874.6975189756246, "episode": 123.0, "batch_reward": 0.8559953666329384, "critic_loss": 0.5569308042377233, "actor_loss": -85.5147366027832, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.686996936798096, "step": 123000}
{"episode_reward": 918.2162465679594, "episode": 124.0, "batch_reward": 0.8558100443482399, "critic_loss": 0.6063855851441622, "actor_loss": -85.50355355834961, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.99202013015747, "step": 124000}
{"episode_reward": 921.097277853518, "episode": 125.0, "batch_reward": 0.8560467246174812, "critic_loss": 0.5831386009007692, "actor_loss": -85.516105758667, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.83162784576416, "step": 125000}
{"episode_reward": 915.5620332861067, "episode": 126.0, "batch_reward": 0.8570482129454613, "critic_loss": 0.592565813973546, "actor_loss": -85.60752604675292, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.309929609298706, "step": 126000}
{"episode_reward": 945.5555116394166, "episode": 127.0, "batch_reward": 0.8568439584374428, "critic_loss": 0.5941254066377878, "actor_loss": -85.61941799926758, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.856422901153564, "step": 127000}
{"episode_reward": 891.9831339676222, "episode": 128.0, "batch_reward": 0.8580632628798485, "critic_loss": 0.5564830477684736, "actor_loss": -85.68541822814942, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.57515287399292, "step": 128000}
{"episode_reward": 938.7594417705154, "episode": 129.0, "batch_reward": 0.8585296298265457, "critic_loss": 0.574548769891262, "actor_loss": -85.62190341186523, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.86751699447632, "step": 129000}
{"episode_reward": 956.5392083912878, "episode": 130.0, "batch_reward": 0.8588148961663247, "critic_loss": 0.6273600754141807, "actor_loss": -85.70024461364746, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.556411027908325, "step": 130000}
{"episode_reward": 898.1171178386495, "episode": 131.0, "batch_reward": 0.8607609382271767, "critic_loss": 0.585966563731432, "actor_loss": -85.68982426452637, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.37897515296936, "step": 131000}
{"episode_reward": 936.3723457587633, "episode": 132.0, "batch_reward": 0.8612116379141808, "critic_loss": 0.548407883271575, "actor_loss": -85.79728317260742, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.322590589523315, "step": 132000}
{"episode_reward": 830.6174356634518, "episode": 133.0, "batch_reward": 0.8601305115818977, "critic_loss": 0.5438555428981781, "actor_loss": -85.73283589172364, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.571823120117188, "step": 133000}
{"episode_reward": 960.6834118433034, "episode": 134.0, "batch_reward": 0.8605870584845543, "critic_loss": 0.522356979072094, "actor_loss": -85.76337174987793, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.75953507423401, "step": 134000}
{"episode_reward": 957.5138553851984, "episode": 135.0, "batch_reward": 0.8602860490083695, "critic_loss": 0.5324147645235061, "actor_loss": -85.82530917358399, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.141584873199463, "step": 135000}
{"episode_reward": 912.476192426695, "episode": 136.0, "batch_reward": 0.8615854151248932, "critic_loss": 0.5286730909943581, "actor_loss": -85.95089855957032, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.497441291809082, "step": 136000}
{"episode_reward": 893.2827360473849, "episode": 137.0, "batch_reward": 0.8630743355154992, "critic_loss": 0.5256064167320729, "actor_loss": -85.93899656677246, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.003174543380737, "step": 137000}
{"episode_reward": 888.7008615017206, "episode": 138.0, "batch_reward": 0.8624452584981919, "critic_loss": 0.5487090608775615, "actor_loss": -85.93389433288574, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.95740556716919, "step": 138000}
{"episode_reward": 965.8131652613754, "episode": 139.0, "batch_reward": 0.8621267665028572, "critic_loss": 0.5439889283925294, "actor_loss": -85.91308364868163, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.87899947166443, "step": 139000}
{"episode_reward": 926.0758288105869, "episode": 140.0, "batch_reward": 0.8627582967877389, "critic_loss": 0.5389826101213694, "actor_loss": -85.9622078704834, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.041034936904907, "step": 140000}
{"episode_reward": 946.3019413193208, "episode": 141.0, "batch_reward": 0.8650510175824165, "critic_loss": 0.5324881812930107, "actor_loss": -86.01124559020997, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.00606179237366, "step": 141000}
{"episode_reward": 884.0390597022441, "episode": 142.0, "batch_reward": 0.864789026260376, "critic_loss": 0.5503632016777992, "actor_loss": -86.04946517944336, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.98662805557251, "step": 142000}
{"episode_reward": 943.5803772487942, "episode": 143.0, "batch_reward": 0.8650600756406784, "critic_loss": 0.519368078276515, "actor_loss": -86.03716381835937, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.121200799942017, "step": 143000}
{"episode_reward": 918.189344369744, "episode": 144.0, "batch_reward": 0.8637475245594979, "critic_loss": 0.5241431746929884, "actor_loss": -86.05877458190918, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.198344945907593, "step": 144000}
{"episode_reward": 933.1550752500614, "episode": 145.0, "batch_reward": 0.8665221021771431, "critic_loss": 0.5347995056062936, "actor_loss": -86.08778540039063, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.00067973136902, "step": 145000}
{"episode_reward": 869.0351698435785, "episode": 146.0, "batch_reward": 0.8643959084153175, "critic_loss": 0.5457793293446302, "actor_loss": -85.98411170959473, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.56326723098755, "step": 146000}
{"episode_reward": 896.670338200954, "episode": 147.0, "batch_reward": 0.8657062666416169, "critic_loss": 0.5369665506482124, "actor_loss": -86.13091743469238, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.563232898712158, "step": 147000}
{"episode_reward": 932.5994218415631, "episode": 148.0, "batch_reward": 0.8670103749632836, "critic_loss": 0.5294119808375836, "actor_loss": -86.18104318237305, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.77724313735962, "step": 148000}
{"episode_reward": 915.5987510348889, "episode": 149.0, "batch_reward": 0.8668094694018363, "critic_loss": 0.5342277919203043, "actor_loss": -86.17867643737793, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.716140270233154, "step": 149000}
{"episode_reward": 907.379381056194, "episode": 150.0, "batch_reward": 0.8668679926395416, "critic_loss": 0.5484820725470781, "actor_loss": -86.10685893249511, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "step": 150000}
