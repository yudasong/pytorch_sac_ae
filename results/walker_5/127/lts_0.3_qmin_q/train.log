{"episode_reward": 0.0, "episode": 1.0, "duration": 23.56501269340515, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 2.1193385124206543, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.4185597691368206, "critic_loss": 0.6161858403124226, "actor_loss": -77.06813845533331, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 65.03202366828918, "step": 3000}
{"episode_reward": 264.9847979677021, "episode": 4.0, "batch_reward": 0.4300946179628372, "critic_loss": 0.8041398157179356, "actor_loss": -81.57846951293945, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.045027017593384, "step": 4000}
{"episode_reward": 760.8279837813872, "episode": 5.0, "batch_reward": 0.48761437660455703, "critic_loss": 0.6333415750861168, "actor_loss": -83.35025732421875, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.249792337417603, "step": 5000}
{"episode_reward": 742.027936854299, "episode": 6.0, "batch_reward": 0.4858877282142639, "critic_loss": 0.6941763332486153, "actor_loss": -84.00523387145996, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.90484857559204, "step": 6000}
{"episode_reward": 38.05639419041701, "episode": 7.0, "batch_reward": 0.47656625348329545, "critic_loss": 0.57007741060853, "actor_loss": -84.87282246398925, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.547600507736206, "step": 7000}
{"episode_reward": 866.9581401817885, "episode": 8.0, "batch_reward": 0.5141007749736309, "critic_loss": 0.5125486653447151, "actor_loss": -85.04084503173829, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.87337064743042, "step": 8000}
{"episode_reward": 672.3945804188422, "episode": 9.0, "batch_reward": 0.5465877638459206, "critic_loss": 0.464168890863657, "actor_loss": -85.45247230529785, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.727130889892578, "step": 9000}
{"episode_reward": 889.9500817873744, "episode": 10.0, "batch_reward": 0.5400119006037712, "critic_loss": 0.45338886153697966, "actor_loss": -85.97710763549804, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.87331247329712, "step": 10000}
{"episode_reward": 24.961666922170654, "episode": 11.0, "batch_reward": 0.5100296681523323, "critic_loss": 0.44809156891703605, "actor_loss": -85.18808639526367, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.197383642196655, "step": 11000}
{"episode_reward": 628.8679209155908, "episode": 12.0, "batch_reward": 0.5355124493539334, "critic_loss": 0.40443232461810114, "actor_loss": -84.80177713012695, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.32541799545288, "step": 12000}
{"episode_reward": 650.4945540003043, "episode": 13.0, "batch_reward": 0.5335609678626061, "critic_loss": 0.42521662202477456, "actor_loss": -84.49751075744629, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.49475622177124, "step": 13000}
{"episode_reward": 373.4898957754258, "episode": 14.0, "batch_reward": 0.5043990981578826, "critic_loss": 0.40969627536833286, "actor_loss": -83.49090826416015, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.587461471557617, "step": 14000}
{"episode_reward": 22.43537641181385, "episode": 15.0, "batch_reward": 0.46964013996720316, "critic_loss": 0.34433011868596075, "actor_loss": -82.77006022644044, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.77014398574829, "step": 15000}
{"episode_reward": 69.43305682048705, "episode": 16.0, "batch_reward": 0.46586645737290383, "critic_loss": 0.365526944860816, "actor_loss": -82.06667245483399, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.236758947372437, "step": 16000}
{"episode_reward": 823.8207777640047, "episode": 17.0, "batch_reward": 0.484426386654377, "critic_loss": 0.3448281277120113, "actor_loss": -81.67552767944336, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.33014416694641, "step": 17000}
{"episode_reward": 690.4269510510469, "episode": 18.0, "batch_reward": 0.5046529271006585, "critic_loss": 0.36570572945475577, "actor_loss": -81.37229011535645, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.651997327804565, "step": 18000}
{"episode_reward": 912.2750492359155, "episode": 19.0, "batch_reward": 0.5253076415359974, "critic_loss": 0.3852657416909933, "actor_loss": -81.19596591186523, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.407261848449707, "step": 19000}
{"episode_reward": 926.7477261260378, "episode": 20.0, "batch_reward": 0.5470617688298225, "critic_loss": 0.43852062916755674, "actor_loss": -81.1790993347168, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.75453019142151, "step": 20000}
{"episode_reward": 853.1017701652553, "episode": 21.0, "batch_reward": 0.5598270174562932, "critic_loss": 0.47294950729608537, "actor_loss": -81.44647592163086, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.10151696205139, "step": 21000}
{"episode_reward": 813.831378901051, "episode": 22.0, "batch_reward": 0.5723506300449371, "critic_loss": 0.5338648046255112, "actor_loss": -81.34015876770019, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.213869333267212, "step": 22000}
{"episode_reward": 843.3846108439927, "episode": 23.0, "batch_reward": 0.5849896305799485, "critic_loss": 0.5050099714696408, "actor_loss": -81.81596192932129, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.777829885482788, "step": 23000}
{"episode_reward": 880.1745274855064, "episode": 24.0, "batch_reward": 0.5978845230042934, "critic_loss": 0.4719213208258152, "actor_loss": -81.89261950683594, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.608520030975342, "step": 24000}
{"episode_reward": 894.8470100928234, "episode": 25.0, "batch_reward": 0.6081010501086712, "critic_loss": 0.46066193863749505, "actor_loss": -82.24125271606445, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.860824584960938, "step": 25000}
{"episode_reward": 889.2281640024582, "episode": 26.0, "batch_reward": 0.623476276576519, "critic_loss": 0.43627374747395514, "actor_loss": -82.7845493927002, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.136945009231567, "step": 26000}
{"episode_reward": 952.9864933672526, "episode": 27.0, "batch_reward": 0.6339952301383018, "critic_loss": 0.39663844291865824, "actor_loss": -83.3132020111084, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.11706233024597, "step": 27000}
{"episode_reward": 927.2804713993827, "episode": 28.0, "batch_reward": 0.6453629907369614, "critic_loss": 0.3526881858110428, "actor_loss": -83.379779296875, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.676794052124023, "step": 28000}
{"episode_reward": 936.7911686839986, "episode": 29.0, "batch_reward": 0.6533093065023422, "critic_loss": 0.3519765209555626, "actor_loss": -83.77504989624023, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.076890468597412, "step": 29000}
{"episode_reward": 916.4475639777875, "episode": 30.0, "batch_reward": 0.6655134899616242, "critic_loss": 0.32346236923336985, "actor_loss": -84.20490524291992, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.237136363983154, "step": 30000}
{"episode_reward": 902.0468214138346, "episode": 31.0, "batch_reward": 0.6727721152305604, "critic_loss": 0.30866021662950516, "actor_loss": -84.31702464294433, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 45.45696544647217, "step": 31000}
{"episode_reward": 957.5388575631366, "episode": 32.0, "batch_reward": 0.6794466059803963, "critic_loss": 0.2928526594787836, "actor_loss": -84.26597035217286, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.319387435913086, "step": 32000}
{"episode_reward": 856.2497808212415, "episode": 33.0, "batch_reward": 0.6863181248307229, "critic_loss": 0.2900995119661093, "actor_loss": -84.3466439819336, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.597484350204468, "step": 33000}
{"episode_reward": 924.3943713549978, "episode": 34.0, "batch_reward": 0.6959179546833039, "critic_loss": 0.2729572640508413, "actor_loss": -84.97617259216308, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.816615343093872, "step": 34000}
{"episode_reward": 951.5088248555392, "episode": 35.0, "batch_reward": 0.6989929868578911, "critic_loss": 0.26455476428568364, "actor_loss": -84.69205346679688, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.507673978805542, "step": 35000}
{"episode_reward": 887.6919062345999, "episode": 36.0, "batch_reward": 0.705900003015995, "critic_loss": 0.2606202615648508, "actor_loss": -84.79373791503906, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.69573473930359, "step": 36000}
{"episode_reward": 924.845388380862, "episode": 37.0, "batch_reward": 0.7129695847034454, "critic_loss": 0.2604120580852032, "actor_loss": -84.8841644744873, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.47304940223694, "step": 37000}
{"episode_reward": 963.8899042149147, "episode": 38.0, "batch_reward": 0.7179535119533539, "critic_loss": 0.26013917945325377, "actor_loss": -84.93697245788574, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.850867986679077, "step": 38000}
{"episode_reward": 945.4029460796065, "episode": 39.0, "batch_reward": 0.7240068883299827, "critic_loss": 0.24165045423805714, "actor_loss": -85.09179936218261, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.257413625717163, "step": 39000}
{"episode_reward": 960.8609354749567, "episode": 40.0, "batch_reward": 0.7310911965370178, "critic_loss": 0.23255942367762328, "actor_loss": -85.51612129211426, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.319265127182007, "step": 40000}
{"episode_reward": 965.748730326587, "episode": 41.0, "batch_reward": 0.7368222702145576, "critic_loss": 0.22717743757367134, "actor_loss": -85.69334536743165, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.61724352836609, "step": 41000}
{"episode_reward": 968.0368301270015, "episode": 42.0, "batch_reward": 0.741840697646141, "critic_loss": 0.22817103401571512, "actor_loss": -85.66914755249023, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.117997646331787, "step": 42000}
{"episode_reward": 911.6163773573609, "episode": 43.0, "batch_reward": 0.7460300545096398, "critic_loss": 0.2244379796758294, "actor_loss": -85.86823742675782, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.96718668937683, "step": 43000}
{"episode_reward": 960.2684948835819, "episode": 44.0, "batch_reward": 0.7527583844065666, "critic_loss": 0.21261571929603815, "actor_loss": -85.82288270568847, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.61510157585144, "step": 44000}
{"episode_reward": 967.0237790468092, "episode": 45.0, "batch_reward": 0.7560307199954986, "critic_loss": 0.22244814129918813, "actor_loss": -85.95774473571777, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.657341241836548, "step": 45000}
{"episode_reward": 966.8080750391833, "episode": 46.0, "batch_reward": 0.7587712097167969, "critic_loss": 0.2061265688315034, "actor_loss": -86.11454469299316, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.882568359375, "step": 46000}
{"episode_reward": 972.5111593803903, "episode": 47.0, "batch_reward": 0.7660024757981301, "critic_loss": 0.21559236735850573, "actor_loss": -86.32126614379882, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.514410972595215, "step": 47000}
{"episode_reward": 959.4829412661726, "episode": 48.0, "batch_reward": 0.7687168984413147, "critic_loss": 0.2058637435361743, "actor_loss": -86.36748802185059, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.293412923812866, "step": 48000}
{"episode_reward": 948.0415912389349, "episode": 49.0, "batch_reward": 0.7725489037036896, "critic_loss": 0.20930950654298067, "actor_loss": -86.32277546691894, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.842095613479614, "step": 49000}
{"episode_reward": 969.5546486983632, "episode": 50.0, "batch_reward": 0.7783094277381897, "critic_loss": 0.19621438552439213, "actor_loss": -86.61758430480957, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.656949520111084, "step": 50000}
{"episode_reward": 970.936465973635, "episode": 51.0, "batch_reward": 0.7821485891342163, "critic_loss": 0.1949418004229665, "actor_loss": -86.79136032104492, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 46.029815435409546, "step": 51000}
{"episode_reward": 962.3427234321305, "episode": 52.0, "batch_reward": 0.7853051856160164, "critic_loss": 0.19269538155943156, "actor_loss": -86.94440751647949, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.606648445129395, "step": 52000}
{"episode_reward": 945.7995383038055, "episode": 53.0, "batch_reward": 0.7871496285200119, "critic_loss": 0.20491161315888168, "actor_loss": -86.74245329284668, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.52383279800415, "step": 53000}
{"episode_reward": 928.3286542860358, "episode": 54.0, "batch_reward": 0.7915263489484787, "critic_loss": 0.2067685637101531, "actor_loss": -86.86475337219238, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.99374771118164, "step": 54000}
{"episode_reward": 964.1043651927004, "episode": 55.0, "batch_reward": 0.792238276541233, "critic_loss": 0.20052041509002447, "actor_loss": -86.86682801818847, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.713100910186768, "step": 55000}
{"episode_reward": 894.4137630374638, "episode": 56.0, "batch_reward": 0.7946230527162552, "critic_loss": 0.19922763781249522, "actor_loss": -87.00860984802246, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.445392847061157, "step": 56000}
{"episode_reward": 958.2278071853663, "episode": 57.0, "batch_reward": 0.7983271996974945, "critic_loss": 0.1969317126572132, "actor_loss": -86.99755317687988, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.18230366706848, "step": 57000}
{"episode_reward": 964.2573289648874, "episode": 58.0, "batch_reward": 0.8003883303999901, "critic_loss": 0.20837728074193002, "actor_loss": -87.08237825012208, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.602575302124023, "step": 58000}
{"episode_reward": 928.9852389441135, "episode": 59.0, "batch_reward": 0.8037331426143646, "critic_loss": 0.19686204683035613, "actor_loss": -87.30980296325684, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.541425228118896, "step": 59000}
{"episode_reward": 977.6403180231425, "episode": 60.0, "batch_reward": 0.8063183069825173, "critic_loss": 0.19633497189730406, "actor_loss": -87.44125122070312, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.407201051712036, "step": 60000}
{"episode_reward": 975.0814128860696, "episode": 61.0, "batch_reward": 0.8102821495532989, "critic_loss": 0.20425040536373854, "actor_loss": -87.69787754821778, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.92932653427124, "step": 61000}
{"episode_reward": 962.333553248571, "episode": 62.0, "batch_reward": 0.8112157270312309, "critic_loss": 0.19411324568837882, "actor_loss": -87.65917288208007, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.881649255752563, "step": 62000}
{"episode_reward": 951.4924296163425, "episode": 63.0, "batch_reward": 0.810509915471077, "critic_loss": 0.19471901323646307, "actor_loss": -87.94180041503907, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.986414909362793, "step": 63000}
{"episode_reward": 818.1488091468625, "episode": 64.0, "batch_reward": 0.8144189618825912, "critic_loss": 0.1849780120253563, "actor_loss": -87.79972727966309, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.10469365119934, "step": 64000}
{"episode_reward": 963.8383636156734, "episode": 65.0, "batch_reward": 0.8148190206289292, "critic_loss": 0.18958569970726966, "actor_loss": -87.83976907348632, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.56665563583374, "step": 65000}
{"episode_reward": 965.3526346583398, "episode": 66.0, "batch_reward": 0.8162449094653129, "critic_loss": 0.19566654162853955, "actor_loss": -87.8282124633789, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.63722252845764, "step": 66000}
{"episode_reward": 931.5431427759697, "episode": 67.0, "batch_reward": 0.8193331064581871, "critic_loss": 0.19449394089728594, "actor_loss": -87.67772940063476, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.093278884887695, "step": 67000}
{"episode_reward": 925.1837401923958, "episode": 68.0, "batch_reward": 0.8211185371875763, "critic_loss": 0.20718438908457756, "actor_loss": -87.90215914916992, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.8694429397583, "step": 68000}
{"episode_reward": 935.379518725595, "episode": 69.0, "batch_reward": 0.8216122067570686, "critic_loss": 0.21288901751488448, "actor_loss": -88.21351435852051, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.853753089904785, "step": 69000}
{"episode_reward": 878.0755048036125, "episode": 70.0, "batch_reward": 0.8235051717162132, "critic_loss": 0.23294206242263318, "actor_loss": -87.96602716064453, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.33415675163269, "step": 70000}
{"episode_reward": 816.8272809053216, "episode": 71.0, "batch_reward": 0.8235915892720223, "critic_loss": 0.22822928459197284, "actor_loss": -87.96937557983398, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.29675054550171, "step": 71000}
{"episode_reward": 917.6612239559147, "episode": 72.0, "batch_reward": 0.8255652714967727, "critic_loss": 0.2283862893655896, "actor_loss": -88.13039732360839, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.22756052017212, "step": 72000}
{"episode_reward": 938.593166910974, "episode": 73.0, "batch_reward": 0.8263694089055061, "critic_loss": 0.2304348020479083, "actor_loss": -88.0580124206543, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.689884901046753, "step": 73000}
{"episode_reward": 931.8583411528318, "episode": 74.0, "batch_reward": 0.8265546628832817, "critic_loss": 0.23563429968059063, "actor_loss": -88.0294613647461, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.654730796813965, "step": 74000}
{"episode_reward": 964.3420912927828, "episode": 75.0, "batch_reward": 0.8284614080190659, "critic_loss": 0.23327594066411256, "actor_loss": -88.27725318908692, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.843106746673584, "step": 75000}
{"episode_reward": 916.2272558932767, "episode": 76.0, "batch_reward": 0.8310974920392037, "critic_loss": 0.2406921312212944, "actor_loss": -88.15801976013184, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.115163803100586, "step": 76000}
{"episode_reward": 924.8085600215983, "episode": 77.0, "batch_reward": 0.8303183203339577, "critic_loss": 0.26559891941398384, "actor_loss": -88.08797824096679, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.93376636505127, "step": 77000}
{"episode_reward": 921.9046804545272, "episode": 78.0, "batch_reward": 0.8337984935045243, "critic_loss": 0.23584326101839542, "actor_loss": -88.14924691772461, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.703903913497925, "step": 78000}
{"episode_reward": 958.179496107002, "episode": 79.0, "batch_reward": 0.8364316077232361, "critic_loss": 0.23263407351076604, "actor_loss": -88.15790621948243, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.116172790527344, "step": 79000}
{"episode_reward": 952.3713462596236, "episode": 80.0, "batch_reward": 0.836927021920681, "critic_loss": 0.23161170469224454, "actor_loss": -88.15668037414551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.004359245300293, "step": 80000}
{"episode_reward": 965.2050535909533, "episode": 81.0, "batch_reward": 0.8400730676054955, "critic_loss": 0.23689971762150527, "actor_loss": -88.22048223876953, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.82482719421387, "step": 81000}
{"episode_reward": 960.5580889515761, "episode": 82.0, "batch_reward": 0.8381017976999283, "critic_loss": 0.23913012967258693, "actor_loss": -88.42325660705566, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.188525199890137, "step": 82000}
{"episode_reward": 940.158394931899, "episode": 83.0, "batch_reward": 0.8408878673911094, "critic_loss": 0.24872889432311057, "actor_loss": -88.23695008850098, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.077892780303955, "step": 83000}
{"episode_reward": 956.3091033298136, "episode": 84.0, "batch_reward": 0.8429279852509498, "critic_loss": 0.24374293319135903, "actor_loss": -88.56639707946778, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.77389121055603, "step": 84000}
{"episode_reward": 913.6584833559801, "episode": 85.0, "batch_reward": 0.8415288417935372, "critic_loss": 0.2357431813776493, "actor_loss": -88.51954991149903, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.006882429122925, "step": 85000}
{"episode_reward": 937.3632151654938, "episode": 86.0, "batch_reward": 0.844698930978775, "critic_loss": 0.2450587465390563, "actor_loss": -88.58894348144531, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.62213969230652, "step": 86000}
{"episode_reward": 966.2858383960642, "episode": 87.0, "batch_reward": 0.8472616865038872, "critic_loss": 0.2307589158937335, "actor_loss": -88.51766296386718, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.900644540786743, "step": 87000}
{"episode_reward": 959.505190098818, "episode": 88.0, "batch_reward": 0.8483103646039962, "critic_loss": 0.22688348034769296, "actor_loss": -88.83721937561035, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.02203893661499, "step": 88000}
{"episode_reward": 959.7338006278416, "episode": 89.0, "batch_reward": 0.8480611698627472, "critic_loss": 0.23628489231318237, "actor_loss": -88.88789794921875, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.851963758468628, "step": 89000}
{"episode_reward": 894.4357409443965, "episode": 90.0, "batch_reward": 0.8495405850410461, "critic_loss": 0.2299732824116945, "actor_loss": -88.91121476745606, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.35035514831543, "step": 90000}
{"episode_reward": 912.938034584347, "episode": 91.0, "batch_reward": 0.8502181361317634, "critic_loss": 0.21489789641648532, "actor_loss": -89.05626330566406, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.429978370666504, "step": 91000}
{"episode_reward": 973.2836254863307, "episode": 92.0, "batch_reward": 0.8495248518586159, "critic_loss": 0.23217080450057984, "actor_loss": -88.91167991638184, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.874430894851685, "step": 92000}
{"episode_reward": 911.0085153878848, "episode": 93.0, "batch_reward": 0.8509561355710029, "critic_loss": 0.21850783151388167, "actor_loss": -89.10298780822754, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.029131412506104, "step": 93000}
{"episode_reward": 948.7772589795732, "episode": 94.0, "batch_reward": 0.8523234124183655, "critic_loss": 0.21924612513929606, "actor_loss": -89.18472724914551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.943556308746338, "step": 94000}
{"episode_reward": 930.9415477758599, "episode": 95.0, "batch_reward": 0.8524650335907936, "critic_loss": 0.21414941436052323, "actor_loss": -88.92255418395996, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.078305959701538, "step": 95000}
{"episode_reward": 935.6514463992295, "episode": 96.0, "batch_reward": 0.8538894764780999, "critic_loss": 0.2502080021351576, "actor_loss": -89.26772871398926, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.35837435722351, "step": 96000}
{"episode_reward": 910.2228061637169, "episode": 97.0, "batch_reward": 0.8531764544248581, "critic_loss": 0.21813811983913184, "actor_loss": -89.16046876525878, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.137353897094727, "step": 97000}
{"episode_reward": 971.6930439996557, "episode": 98.0, "batch_reward": 0.8557413696646691, "critic_loss": 0.21801670064032078, "actor_loss": -88.92385826110839, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.29743266105652, "step": 98000}
{"episode_reward": 964.0498514574597, "episode": 99.0, "batch_reward": 0.858223700761795, "critic_loss": 0.21426876240968704, "actor_loss": -89.16925025939942, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.850528717041016, "step": 99000}
{"episode_reward": 967.055891884287, "episode": 100.0, "batch_reward": 0.8572423452138901, "critic_loss": 0.22381018751859666, "actor_loss": -89.10336070251465, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.895177602767944, "step": 100000}
{"episode_reward": 975.2066346614979, "episode": 101.0, "batch_reward": 0.8591495113372802, "critic_loss": 0.21940131199359894, "actor_loss": -89.46903038024902, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 45.043455362319946, "step": 101000}
{"episode_reward": 943.3730693333368, "episode": 102.0, "batch_reward": 0.8604203137755394, "critic_loss": 0.21296454735845327, "actor_loss": -89.22592840576172, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.6917245388031, "step": 102000}
{"episode_reward": 968.684846365218, "episode": 103.0, "batch_reward": 0.8602143643498421, "critic_loss": 0.21062761998176574, "actor_loss": -89.26538316345214, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.52699041366577, "step": 103000}
{"episode_reward": 969.3291500587869, "episode": 104.0, "batch_reward": 0.8640649807453156, "critic_loss": 0.20804134395718574, "actor_loss": -89.50457022094727, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.676229000091553, "step": 104000}
{"episode_reward": 954.467497222457, "episode": 105.0, "batch_reward": 0.8628694186210633, "critic_loss": 0.2212037706747651, "actor_loss": -89.51968934631347, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.406446933746338, "step": 105000}
{"episode_reward": 914.0906689225071, "episode": 106.0, "batch_reward": 0.8641529204249382, "critic_loss": 0.20841633365303278, "actor_loss": -89.57186668395997, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.258830547332764, "step": 106000}
{"episode_reward": 964.4475648035523, "episode": 107.0, "batch_reward": 0.8642368711829186, "critic_loss": 0.21285677580535411, "actor_loss": -89.61102751159667, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.866137981414795, "step": 107000}
{"episode_reward": 953.6182686252789, "episode": 108.0, "batch_reward": 0.8647075402140617, "critic_loss": 0.22225441282242536, "actor_loss": -89.35367022705078, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.36364436149597, "step": 108000}
{"episode_reward": 958.4191075354635, "episode": 109.0, "batch_reward": 0.8669410920739173, "critic_loss": 0.23298141828179358, "actor_loss": -89.69339530944825, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.09140110015869, "step": 109000}
{"episode_reward": 840.6327858278079, "episode": 110.0, "batch_reward": 0.8651348065733909, "critic_loss": 0.25723213695734737, "actor_loss": -89.37795573425294, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.959701776504517, "step": 110000}
{"episode_reward": 904.2399009405393, "episode": 111.0, "batch_reward": 0.8657589163780213, "critic_loss": 0.24353077524900438, "actor_loss": -89.6215435180664, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.751720905303955, "step": 111000}
{"episode_reward": 925.1936500576069, "episode": 112.0, "batch_reward": 0.8659088561534881, "critic_loss": 0.22977272993326187, "actor_loss": -89.48714360046387, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.769036769866943, "step": 112000}
{"episode_reward": 952.4554692664698, "episode": 113.0, "batch_reward": 0.8689021351337433, "critic_loss": 0.2326971539631486, "actor_loss": -89.72729077148438, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.008556365966797, "step": 113000}
{"episode_reward": 963.9868682835978, "episode": 114.0, "batch_reward": 0.8694905813932419, "critic_loss": 0.22861871294677258, "actor_loss": -89.55584098815918, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.82442855834961, "step": 114000}
{"episode_reward": 949.6663109946218, "episode": 115.0, "batch_reward": 0.8694097635746002, "critic_loss": 0.234795035995543, "actor_loss": -89.52971435546876, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.41898536682129, "step": 115000}
{"episode_reward": 960.6212559109932, "episode": 116.0, "batch_reward": 0.8704896766543389, "critic_loss": 0.22309917335957288, "actor_loss": -89.71686726379394, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.11733889579773, "step": 116000}
{"episode_reward": 969.5708508171662, "episode": 117.0, "batch_reward": 0.8723553201556206, "critic_loss": 0.23243922428041697, "actor_loss": -89.90483010864259, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.773910760879517, "step": 117000}
{"episode_reward": 965.549751304289, "episode": 118.0, "batch_reward": 0.8723475095629692, "critic_loss": 0.243788095459342, "actor_loss": -89.90515080261231, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.86457586288452, "step": 118000}
{"episode_reward": 958.7760560327188, "episode": 119.0, "batch_reward": 0.8735182087421417, "critic_loss": 0.2326364478096366, "actor_loss": -90.028423538208, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.6389377117157, "step": 119000}
{"episode_reward": 948.6782521845837, "episode": 120.0, "batch_reward": 0.8740378333926201, "critic_loss": 0.22046262304484845, "actor_loss": -90.01686582946778, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.486855030059814, "step": 120000}
{"episode_reward": 962.3330130584744, "episode": 121.0, "batch_reward": 0.8744148225188255, "critic_loss": 0.2310809382200241, "actor_loss": -90.0879224395752, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 45.2138090133667, "step": 121000}
{"episode_reward": 952.3273267946271, "episode": 122.0, "batch_reward": 0.8752022525072097, "critic_loss": 0.22047874961048364, "actor_loss": -89.97715545654297, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.414803504943848, "step": 122000}
{"episode_reward": 922.2792586936963, "episode": 123.0, "batch_reward": 0.8747814493775368, "critic_loss": 0.21530885707959532, "actor_loss": -90.06585913085938, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.77941918373108, "step": 123000}
{"episode_reward": 960.6626111781834, "episode": 124.0, "batch_reward": 0.8741563632488251, "critic_loss": 0.22334895338863134, "actor_loss": -90.0611484375, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.974560022354126, "step": 124000}
{"episode_reward": 951.5477963284808, "episode": 125.0, "batch_reward": 0.8745749987959862, "critic_loss": 0.2209864908158779, "actor_loss": -90.02244357299804, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.867658615112305, "step": 125000}
{"episode_reward": 952.9528367940584, "episode": 126.0, "batch_reward": 0.8767085073590278, "critic_loss": 0.224752139441669, "actor_loss": -90.07317837524414, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.33490562438965, "step": 126000}
{"episode_reward": 973.1050452662599, "episode": 127.0, "batch_reward": 0.8767715482711792, "critic_loss": 0.2226940048933029, "actor_loss": -89.89934739685059, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.99130892753601, "step": 127000}
{"episode_reward": 944.3783355406396, "episode": 128.0, "batch_reward": 0.8783275064229965, "critic_loss": 0.23423124253749847, "actor_loss": -90.13845690917968, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.94874882698059, "step": 128000}
{"episode_reward": 951.8729511892737, "episode": 129.0, "batch_reward": 0.8796474299430848, "critic_loss": 0.22798877944797277, "actor_loss": -90.21715472412109, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.838777542114258, "step": 129000}
{"episode_reward": 974.8104017894893, "episode": 130.0, "batch_reward": 0.8790399528741837, "critic_loss": 0.22818925597518683, "actor_loss": -90.20002990722656, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.523164749145508, "step": 130000}
{"episode_reward": 913.4075555619225, "episode": 131.0, "batch_reward": 0.879142085492611, "critic_loss": 0.2370716708302498, "actor_loss": -90.33898216247559, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.24245309829712, "step": 131000}
{"episode_reward": 950.9602511200874, "episode": 132.0, "batch_reward": 0.8789928094148636, "critic_loss": 0.2633750154748559, "actor_loss": -90.33246290588379, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.060670852661133, "step": 132000}
{"episode_reward": 938.2578466410248, "episode": 133.0, "batch_reward": 0.8816713696122169, "critic_loss": 0.31760754019767046, "actor_loss": -90.64037101745606, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.336882829666138, "step": 133000}
{"episode_reward": 905.1446772490774, "episode": 134.0, "batch_reward": 0.8797620806097984, "critic_loss": 0.65054443128407, "actor_loss": -90.74417478942871, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.549258947372437, "step": 134000}
{"episode_reward": 810.8398164497571, "episode": 135.0, "batch_reward": 0.8788558052182197, "critic_loss": 1.1073728121519089, "actor_loss": -91.3651718902588, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.33290672302246, "step": 135000}
{"episode_reward": 910.9356671120381, "episode": 136.0, "batch_reward": 0.8808642869591713, "critic_loss": 1.3343614611625672, "actor_loss": -93.55717658996582, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.955424785614014, "step": 136000}
{"episode_reward": 828.4925081702811, "episode": 137.0, "batch_reward": 0.8774318108558655, "critic_loss": 1.3083652486801147, "actor_loss": -95.73983836364746, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.429580688476562, "step": 137000}
{"episode_reward": 324.3849958474567, "episode": 138.0, "batch_reward": 0.874566346347332, "critic_loss": 1.8007855960130692, "actor_loss": -100.53437272644042, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.95479130744934, "step": 138000}
{"episode_reward": 398.76512814451974, "episode": 139.0, "batch_reward": 0.869420749604702, "critic_loss": 2.0546175385713576, "actor_loss": -104.5236941833496, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.83385944366455, "step": 139000}
{"episode_reward": 402.42713621964606, "episode": 140.0, "batch_reward": 0.8678615155220032, "critic_loss": 1.9347722933888436, "actor_loss": -106.88702450561523, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.87725830078125, "step": 140000}
{"episode_reward": 862.657319449904, "episode": 141.0, "batch_reward": 0.871009496986866, "critic_loss": 1.7947446477413178, "actor_loss": -107.12760758972168, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.524914026260376, "step": 141000}
{"episode_reward": 938.79188246693, "episode": 142.0, "batch_reward": 0.8700108589529991, "critic_loss": 1.6160634904503823, "actor_loss": -107.45495089721679, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.3353271484375, "step": 142000}
{"episode_reward": 958.3555856157363, "episode": 143.0, "batch_reward": 0.8698384007215499, "critic_loss": 1.3424622007012368, "actor_loss": -107.42389332580566, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.793863773345947, "step": 143000}
{"episode_reward": 958.3248196403814, "episode": 144.0, "batch_reward": 0.8697701417207718, "critic_loss": 1.2345898457169533, "actor_loss": -106.64534143066406, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.606292963027954, "step": 144000}
{"episode_reward": 894.9800599717902, "episode": 145.0, "batch_reward": 0.8730329883098602, "critic_loss": 1.0447313664257527, "actor_loss": -106.55631065368652, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.682925939559937, "step": 145000}
{"episode_reward": 939.2067892379164, "episode": 146.0, "batch_reward": 0.87105962318182, "critic_loss": 0.9534475619792938, "actor_loss": -106.82444708251953, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.014936923980713, "step": 146000}
{"episode_reward": 911.0059562213397, "episode": 147.0, "batch_reward": 0.8712942638397216, "critic_loss": 0.8773870309889317, "actor_loss": -106.02070327758788, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.407286405563354, "step": 147000}
{"episode_reward": 915.7186602454705, "episode": 148.0, "batch_reward": 0.8716610211133957, "critic_loss": 0.8213598204106093, "actor_loss": -105.32005140686036, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.379899501800537, "step": 148000}
{"episode_reward": 952.6032336518037, "episode": 149.0, "batch_reward": 0.8722070514559745, "critic_loss": 0.7089825882315636, "actor_loss": -105.62383483886718, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.704219102859497, "step": 149000}
{"episode_reward": 770.323287982025, "episode": 150.0, "batch_reward": 0.8719977234005928, "critic_loss": 0.6402514542639256, "actor_loss": -103.40091569519043, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "step": 150000}
