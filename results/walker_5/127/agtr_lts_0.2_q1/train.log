{"episode_reward": 0.0, "episode": 1.0, "duration": 21.686206817626953, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.8818507194519043, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.40957612992724246, "critic_loss": 0.14922502963105294, "actor_loss": -19.51819863845566, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 62.83523344993591, "step": 3000}
{"episode_reward": 36.015076690324, "episode": 4.0, "batch_reward": 0.2770093909353018, "critic_loss": 0.4572018082514405, "actor_loss": -24.592019262313844, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.437853813171387, "step": 4000}
{"episode_reward": 92.59429786305915, "episode": 5.0, "batch_reward": 0.2628159681707621, "critic_loss": 0.7981149760186672, "actor_loss": -25.505710456848146, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.702595710754395, "step": 5000}
{"episode_reward": 334.7035115461538, "episode": 6.0, "batch_reward": 0.2701311652064323, "critic_loss": 1.1087082187235355, "actor_loss": -30.26436973953247, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.362346410751343, "step": 6000}
{"episode_reward": 212.51370425915442, "episode": 7.0, "batch_reward": 0.25657158248126505, "critic_loss": 1.4260870741009712, "actor_loss": -31.15381064224243, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.38471531867981, "step": 7000}
{"episode_reward": 334.2826370552333, "episode": 8.0, "batch_reward": 0.2919403635412455, "critic_loss": 1.6660940115451812, "actor_loss": -35.358276950836185, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.762728929519653, "step": 8000}
{"episode_reward": 614.1861865062149, "episode": 9.0, "batch_reward": 0.339920920714736, "critic_loss": 1.9708288803100587, "actor_loss": -40.5722830619812, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.036438465118408, "step": 9000}
{"episode_reward": 791.5820884917199, "episode": 10.0, "batch_reward": 0.37430542999505995, "critic_loss": 2.189874080181122, "actor_loss": -45.29452772140503, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.816540718078613, "step": 10000}
{"episode_reward": 614.1561620830832, "episode": 11.0, "batch_reward": 0.38900948694348336, "critic_loss": 2.4225447033643723, "actor_loss": -47.98842878723145, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.28509712219238, "step": 11000}
{"episode_reward": 221.32249592374188, "episode": 12.0, "batch_reward": 0.37378239586949347, "critic_loss": 2.406555352687836, "actor_loss": -50.123865913391114, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.919311046600342, "step": 12000}
{"episode_reward": 558.3173162313692, "episode": 13.0, "batch_reward": 0.40437230658531187, "critic_loss": 2.4562047203779223, "actor_loss": -52.70898356628418, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.749591588974, "step": 13000}
{"episode_reward": 762.5948946144747, "episode": 14.0, "batch_reward": 0.42138371846079825, "critic_loss": 2.542660356402397, "actor_loss": -56.245417747497555, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.460979461669922, "step": 14000}
{"episode_reward": 514.795922393143, "episode": 15.0, "batch_reward": 0.4267917337715626, "critic_loss": 2.572816551208496, "actor_loss": -58.42741076660156, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.969260931015015, "step": 15000}
{"episode_reward": 574.3720797595049, "episode": 16.0, "batch_reward": 0.4413919318020344, "critic_loss": 2.334694986104965, "actor_loss": -60.76586506652832, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.380943298339844, "step": 16000}
{"episode_reward": 762.7107831933982, "episode": 17.0, "batch_reward": 0.4621285623908043, "critic_loss": 2.103181647181511, "actor_loss": -62.899206634521484, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.323981523513794, "step": 17000}
{"episode_reward": 766.6775336311372, "episode": 18.0, "batch_reward": 0.4750754462480545, "critic_loss": 2.218489984512329, "actor_loss": -64.24040348052978, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.824636936187744, "step": 18000}
{"episode_reward": 694.3876810367103, "episode": 19.0, "batch_reward": 0.4953995290696621, "critic_loss": 2.0308588256835938, "actor_loss": -65.9785608291626, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.400869607925415, "step": 19000}
{"episode_reward": 846.181806499046, "episode": 20.0, "batch_reward": 0.5140310549736022, "critic_loss": 1.9524566893577575, "actor_loss": -67.53642124176025, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.364811658859253, "step": 20000}
{"episode_reward": 841.2088319463254, "episode": 21.0, "batch_reward": 0.5305867061913013, "critic_loss": 1.8007143360376359, "actor_loss": -68.93853215026856, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.91928744316101, "step": 21000}
{"episode_reward": 886.526857070653, "episode": 22.0, "batch_reward": 0.5480488666594029, "critic_loss": 1.7468066707849503, "actor_loss": -70.57497232055664, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.38538432121277, "step": 22000}
{"episode_reward": 932.6149833346201, "episode": 23.0, "batch_reward": 0.5651963869333267, "critic_loss": 1.683634895503521, "actor_loss": -71.40603182983398, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.963520050048828, "step": 23000}
{"episode_reward": 895.559988107159, "episode": 24.0, "batch_reward": 0.5755546579957008, "critic_loss": 1.6253615608215333, "actor_loss": -72.49252397155762, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.486475467681885, "step": 24000}
{"episode_reward": 892.2170261184133, "episode": 25.0, "batch_reward": 0.5889945071935654, "critic_loss": 1.5510683991312981, "actor_loss": -73.38132325744628, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.31813883781433, "step": 25000}
{"episode_reward": 884.4763558417222, "episode": 26.0, "batch_reward": 0.601513929784298, "critic_loss": 1.557360599219799, "actor_loss": -74.17205514526367, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.606358528137207, "step": 26000}
{"episode_reward": 900.5146178600708, "episode": 27.0, "batch_reward": 0.6151740681529045, "critic_loss": 1.4788440882563592, "actor_loss": -75.08008334350586, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.072211503982544, "step": 27000}
{"episode_reward": 921.0977054839994, "episode": 28.0, "batch_reward": 0.6254757875800133, "critic_loss": 1.3872984600663185, "actor_loss": -75.77312272644043, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.304977416992188, "step": 28000}
{"episode_reward": 909.8139285841762, "episode": 29.0, "batch_reward": 0.6313444702625275, "critic_loss": 1.3038603974580765, "actor_loss": -76.1894730682373, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.236958503723145, "step": 29000}
{"episode_reward": 791.0045049553725, "episode": 30.0, "batch_reward": 0.6421699053645133, "critic_loss": 1.2739901381134986, "actor_loss": -76.61814602661133, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.597614288330078, "step": 30000}
{"episode_reward": 912.4005276369497, "episode": 31.0, "batch_reward": 0.6502979206442833, "critic_loss": 1.2826174659132958, "actor_loss": -77.06422567749023, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.94429922103882, "step": 31000}
{"episode_reward": 911.9411979060349, "episode": 32.0, "batch_reward": 0.6571281006932259, "critic_loss": 1.2383358920812606, "actor_loss": -77.52980447387695, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.74779200553894, "step": 32000}
{"episode_reward": 905.5770106013134, "episode": 33.0, "batch_reward": 0.6644538959264755, "critic_loss": 1.2586114616394044, "actor_loss": -77.83498402404786, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.45699906349182, "step": 33000}
{"episode_reward": 895.1223731329044, "episode": 34.0, "batch_reward": 0.673584704875946, "critic_loss": 1.2573468989133836, "actor_loss": -78.48077737426757, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.17409324645996, "step": 34000}
{"episode_reward": 975.0832983393044, "episode": 35.0, "batch_reward": 0.6806821704506875, "critic_loss": 1.182687369823456, "actor_loss": -78.92866166687011, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.345306158065796, "step": 35000}
{"episode_reward": 892.4510427180044, "episode": 36.0, "batch_reward": 0.6871244403719902, "critic_loss": 1.145470978140831, "actor_loss": -79.43580688476563, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.327568769454956, "step": 36000}
{"episode_reward": 922.174466390575, "episode": 37.0, "batch_reward": 0.695138313472271, "critic_loss": 1.1130879541635514, "actor_loss": -79.93583299255371, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.22794795036316, "step": 37000}
{"episode_reward": 968.227581434979, "episode": 38.0, "batch_reward": 0.6899855778813362, "critic_loss": 1.047693759381771, "actor_loss": -80.18725630187988, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.413094758987427, "step": 38000}
{"episode_reward": 11.542430491123824, "episode": 39.0, "batch_reward": 0.6823030982613564, "critic_loss": 1.0581917963027954, "actor_loss": -80.3508422088623, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.349114179611206, "step": 39000}
{"episode_reward": 898.2447724251113, "episode": 40.0, "batch_reward": 0.6899813179373742, "critic_loss": 1.0125738844871521, "actor_loss": -80.78528230285644, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.03901219367981, "step": 40000}
{"episode_reward": 978.9217930107778, "episode": 41.0, "batch_reward": 0.6945880188941955, "critic_loss": 0.9718351798057556, "actor_loss": -81.01143266296387, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.72218370437622, "step": 41000}
{"episode_reward": 918.5111393095025, "episode": 42.0, "batch_reward": 0.7025573669075966, "critic_loss": 0.9174153429865837, "actor_loss": -81.2821834411621, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.517397165298462, "step": 42000}
{"episode_reward": 934.8993902164385, "episode": 43.0, "batch_reward": 0.7076765550971031, "critic_loss": 0.9106294105947018, "actor_loss": -81.45936961364747, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.67186164855957, "step": 43000}
{"episode_reward": 971.8889434395711, "episode": 44.0, "batch_reward": 0.7123709731101989, "critic_loss": 0.8738130009174347, "actor_loss": -81.58605937194824, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.341327667236328, "step": 44000}
{"episode_reward": 969.3603424931076, "episode": 45.0, "batch_reward": 0.7183716931939125, "critic_loss": 0.8382362085580826, "actor_loss": -81.78276473999023, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.814494848251343, "step": 45000}
{"episode_reward": 966.2413258226994, "episode": 46.0, "batch_reward": 0.7224123364686966, "critic_loss": 0.8369341811239719, "actor_loss": -81.96484378051758, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.166221857070923, "step": 46000}
{"episode_reward": 924.6206107888481, "episode": 47.0, "batch_reward": 0.7272550116181373, "critic_loss": 0.859253353625536, "actor_loss": -82.07944961547851, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.322710275650024, "step": 47000}
{"episode_reward": 910.5722583673535, "episode": 48.0, "batch_reward": 0.7319881907105446, "critic_loss": 0.8551267866492271, "actor_loss": -82.26841230773925, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.536213636398315, "step": 48000}
{"episode_reward": 945.4563774653346, "episode": 49.0, "batch_reward": 0.737596354842186, "critic_loss": 0.8581948401629925, "actor_loss": -82.45496104431152, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.754583597183228, "step": 49000}
{"episode_reward": 973.9253554060624, "episode": 50.0, "batch_reward": 0.7422552729845047, "critic_loss": 0.830697171241045, "actor_loss": -82.67282469177246, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.30859875679016, "step": 50000}
{"episode_reward": 967.5782915080347, "episode": 51.0, "batch_reward": 0.7453244585990906, "critic_loss": 0.8207870858311653, "actor_loss": -82.92133164978027, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.027297019958496, "step": 51000}
{"episode_reward": 954.0284045775844, "episode": 52.0, "batch_reward": 0.7492495009303093, "critic_loss": 0.870446211695671, "actor_loss": -83.16252471923828, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.440743684768677, "step": 52000}
{"episode_reward": 842.8723811581422, "episode": 53.0, "batch_reward": 0.7518521284461022, "critic_loss": 0.8550980959236621, "actor_loss": -83.16485668945313, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.753849744796753, "step": 53000}
{"episode_reward": 971.6194861842949, "episode": 54.0, "batch_reward": 0.7570446084737777, "critic_loss": 0.8461388204991818, "actor_loss": -83.54881123352051, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.857975006103516, "step": 54000}
{"episode_reward": 948.4646365732439, "episode": 55.0, "batch_reward": 0.760092033803463, "critic_loss": 0.8243854442834854, "actor_loss": -83.69934861755371, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.30534029006958, "step": 55000}
{"episode_reward": 957.8082476082365, "episode": 56.0, "batch_reward": 0.7632902243733406, "critic_loss": 0.8059722183942795, "actor_loss": -83.8528824005127, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.30393624305725, "step": 56000}
{"episode_reward": 955.0022827256599, "episode": 57.0, "batch_reward": 0.7672426557540893, "critic_loss": 0.7463759316504002, "actor_loss": -83.97971255493164, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.135787963867188, "step": 57000}
{"episode_reward": 920.6186022305893, "episode": 58.0, "batch_reward": 0.7657877610921859, "critic_loss": 0.7927775970697403, "actor_loss": -84.00137705993653, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.342961072921753, "step": 58000}
{"episode_reward": 809.5715859182757, "episode": 59.0, "batch_reward": 0.7704839881062507, "critic_loss": 0.8015802677571774, "actor_loss": -84.1779168395996, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.62666392326355, "step": 59000}
{"episode_reward": 971.8387513952621, "episode": 60.0, "batch_reward": 0.7730266841053963, "critic_loss": 0.7674139556288719, "actor_loss": -84.3795514831543, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.713619470596313, "step": 60000}
{"episode_reward": 974.9582485213498, "episode": 61.0, "batch_reward": 0.7771971054673195, "critic_loss": 0.7758969922959804, "actor_loss": -84.53051364135742, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.23986482620239, "step": 61000}
{"episode_reward": 961.2643087352428, "episode": 62.0, "batch_reward": 0.7786836329698562, "critic_loss": 0.7514760503172875, "actor_loss": -84.50735499572754, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.265658378601074, "step": 62000}
{"episode_reward": 904.2053720969154, "episode": 63.0, "batch_reward": 0.7825559552907944, "critic_loss": 0.7319323880076408, "actor_loss": -84.74127143859863, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.3131742477417, "step": 63000}
{"episode_reward": 947.5927939963822, "episode": 64.0, "batch_reward": 0.7832478012442589, "critic_loss": 0.7589725196361542, "actor_loss": -84.78914695739746, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.390636920928955, "step": 64000}
{"episode_reward": 954.0313558470008, "episode": 65.0, "batch_reward": 0.7864108299016952, "critic_loss": 0.73815544962883, "actor_loss": -84.88629919433593, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.967581033706665, "step": 65000}
{"episode_reward": 971.5501498405863, "episode": 66.0, "batch_reward": 0.7876934370398522, "critic_loss": 0.7178382887244225, "actor_loss": -84.87241249084472, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.348814725875854, "step": 66000}
{"episode_reward": 919.8293518687282, "episode": 67.0, "batch_reward": 0.7920628161430359, "critic_loss": 0.7337681959271432, "actor_loss": -85.09351231384278, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.5851411819458, "step": 67000}
{"episode_reward": 923.6280333344359, "episode": 68.0, "batch_reward": 0.7938551148772239, "critic_loss": 0.7131170210242271, "actor_loss": -85.05024897766113, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.172897338867188, "step": 68000}
{"episode_reward": 933.1996664381519, "episode": 69.0, "batch_reward": 0.7938438948392869, "critic_loss": 0.7425471614599228, "actor_loss": -85.2780437927246, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.555245399475098, "step": 69000}
{"episode_reward": 948.862189709625, "episode": 70.0, "batch_reward": 0.7984495593905448, "critic_loss": 0.712473625421524, "actor_loss": -85.30676640319824, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.475462436676025, "step": 70000}
{"episode_reward": 930.8636913607282, "episode": 71.0, "batch_reward": 0.7990732318162919, "critic_loss": 0.7085138473808765, "actor_loss": -85.34654602050782, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.544883251190186, "step": 71000}
{"episode_reward": 876.9122245007152, "episode": 72.0, "batch_reward": 0.7998309883475304, "critic_loss": 0.666216432183981, "actor_loss": -85.49920616149902, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.76668643951416, "step": 72000}
{"episode_reward": 957.5316784040278, "episode": 73.0, "batch_reward": 0.8030940715074539, "critic_loss": 0.6817205369472503, "actor_loss": -85.48698147583008, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.717488765716553, "step": 73000}
{"episode_reward": 953.0264855853791, "episode": 74.0, "batch_reward": 0.8047144579291343, "critic_loss": 0.6941255606710911, "actor_loss": -85.67630378723145, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.63615870475769, "step": 74000}
{"episode_reward": 936.09212883712, "episode": 75.0, "batch_reward": 0.8043951745629311, "critic_loss": 0.6964314721524716, "actor_loss": -85.83079493713379, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.740461587905884, "step": 75000}
{"episode_reward": 891.4214844857536, "episode": 76.0, "batch_reward": 0.8072762812972069, "critic_loss": 0.6656028958559036, "actor_loss": -85.76620513916015, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.099934816360474, "step": 76000}
{"episode_reward": 929.3732063432121, "episode": 77.0, "batch_reward": 0.8087410886287689, "critic_loss": 0.6810364619195461, "actor_loss": -85.87364868164063, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.50386905670166, "step": 77000}
{"episode_reward": 900.413060947514, "episode": 78.0, "batch_reward": 0.8106353833079338, "critic_loss": 0.632328019708395, "actor_loss": -85.92761618041992, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.765371084213257, "step": 78000}
{"episode_reward": 973.7888956327145, "episode": 79.0, "batch_reward": 0.811484334051609, "critic_loss": 0.6394844318330288, "actor_loss": -85.82917677307128, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.496936321258545, "step": 79000}
{"episode_reward": 939.2556423498538, "episode": 80.0, "batch_reward": 0.814411334335804, "critic_loss": 0.6633736669272184, "actor_loss": -85.91308674621582, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.32046675682068, "step": 80000}
{"episode_reward": 964.133756802298, "episode": 81.0, "batch_reward": 0.8168407529592514, "critic_loss": 0.648076449751854, "actor_loss": -85.97695846557617, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.588547468185425, "step": 81000}
{"episode_reward": 953.420121775057, "episode": 82.0, "batch_reward": 0.8173155905604362, "critic_loss": 0.6636699091494084, "actor_loss": -86.13051168823242, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.504796743392944, "step": 82000}
{"episode_reward": 945.3988624104368, "episode": 83.0, "batch_reward": 0.820348023056984, "critic_loss": 0.6393955515325069, "actor_loss": -86.1662869720459, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.138176441192627, "step": 83000}
{"episode_reward": 959.8752990366243, "episode": 84.0, "batch_reward": 0.8203618723154068, "critic_loss": 0.6264050827771426, "actor_loss": -86.2878042602539, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.325739860534668, "step": 84000}
{"episode_reward": 933.1716076243218, "episode": 85.0, "batch_reward": 0.8214174157977104, "critic_loss": 0.6656945032477379, "actor_loss": -86.39671409606933, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.620320796966553, "step": 85000}
{"episode_reward": 944.7738012568458, "episode": 86.0, "batch_reward": 0.8249825900197029, "critic_loss": 0.6294123249650001, "actor_loss": -86.46851013183594, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.947783708572388, "step": 86000}
{"episode_reward": 968.7590048309321, "episode": 87.0, "batch_reward": 0.8265029965043068, "critic_loss": 0.6232002031207085, "actor_loss": -86.55837623596192, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.322673320770264, "step": 87000}
{"episode_reward": 977.9354436787112, "episode": 88.0, "batch_reward": 0.8277281745076179, "critic_loss": 0.6387479646503925, "actor_loss": -86.7906086883545, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.755934476852417, "step": 88000}
{"episode_reward": 948.7003375365457, "episode": 89.0, "batch_reward": 0.8286404638290406, "critic_loss": 0.6123143039941787, "actor_loss": -86.82939079284668, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.317347049713135, "step": 89000}
{"episode_reward": 925.0419953490751, "episode": 90.0, "batch_reward": 0.8301661972403527, "critic_loss": 0.5724007449448109, "actor_loss": -86.89846910095216, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.410226583480835, "step": 90000}
{"episode_reward": 906.4870610038321, "episode": 91.0, "batch_reward": 0.8322007110118866, "critic_loss": 0.5712202992141246, "actor_loss": -87.20599777221679, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.730879068374634, "step": 91000}
{"episode_reward": 978.2987012242418, "episode": 92.0, "batch_reward": 0.8298717575073242, "critic_loss": 0.5891700835525989, "actor_loss": -87.13317611694336, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.32939624786377, "step": 92000}
{"episode_reward": 831.7669720608948, "episode": 93.0, "batch_reward": 0.8323022004365921, "critic_loss": 0.5899554956555366, "actor_loss": -87.21856153869629, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.0402889251709, "step": 93000}
{"episode_reward": 978.4072362447398, "episode": 94.0, "batch_reward": 0.8328658735156059, "critic_loss": 0.5622803590595722, "actor_loss": -87.28762820434571, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.453373908996582, "step": 94000}
{"episode_reward": 884.0767725092143, "episode": 95.0, "batch_reward": 0.832312558054924, "critic_loss": 0.5976697508245706, "actor_loss": -87.10205514526368, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.330674648284912, "step": 95000}
{"episode_reward": 788.4322331564271, "episode": 96.0, "batch_reward": 0.8344350373148918, "critic_loss": 0.6019802328050137, "actor_loss": -87.29414418029785, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.578227281570435, "step": 96000}
{"episode_reward": 909.4262841502403, "episode": 97.0, "batch_reward": 0.8341056994795799, "critic_loss": 0.5915546216964722, "actor_loss": -87.24954957580566, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.097280502319336, "step": 97000}
{"episode_reward": 977.0473611129254, "episode": 98.0, "batch_reward": 0.8357094130516052, "critic_loss": 0.5983026887327433, "actor_loss": -87.00371574401855, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.339303016662598, "step": 98000}
{"episode_reward": 972.1243145283175, "episode": 99.0, "batch_reward": 0.8366965590119362, "critic_loss": 0.5868139669001102, "actor_loss": -87.4231192779541, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.744897842407227, "step": 99000}
{"episode_reward": 962.3199234633529, "episode": 100.0, "batch_reward": 0.8389318171739578, "critic_loss": 0.5765411502718926, "actor_loss": -87.50697169494629, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.127052545547485, "step": 100000}
{"episode_reward": 966.2382507175126, "episode": 101.0, "batch_reward": 0.8387481916546822, "critic_loss": 0.6235101235210896, "actor_loss": -87.54643614196777, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.598341941833496, "step": 101000}
{"episode_reward": 783.6210397277416, "episode": 102.0, "batch_reward": 0.8405361649990082, "critic_loss": 0.5932382107973099, "actor_loss": -87.5844533996582, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.455564260482788, "step": 102000}
{"episode_reward": 979.6172704553038, "episode": 103.0, "batch_reward": 0.8396972670555115, "critic_loss": 0.6074521019458771, "actor_loss": -87.60388932800294, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.049524545669556, "step": 103000}
{"episode_reward": 960.4350843915146, "episode": 104.0, "batch_reward": 0.8413311700820922, "critic_loss": 0.6129888560324908, "actor_loss": -87.64882820129395, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.182385444641113, "step": 104000}
{"episode_reward": 920.5658554431678, "episode": 105.0, "batch_reward": 0.8424503898620606, "critic_loss": 0.5886993111371994, "actor_loss": -87.74260859680176, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.335248231887817, "step": 105000}
{"episode_reward": 961.6678603573142, "episode": 106.0, "batch_reward": 0.8436147609949112, "critic_loss": 0.5647927014827728, "actor_loss": -87.87183796691895, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.56506872177124, "step": 106000}
{"episode_reward": 974.6153431064059, "episode": 107.0, "batch_reward": 0.8432382963299752, "critic_loss": 0.5839401618093252, "actor_loss": -87.7647166595459, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.888665199279785, "step": 107000}
{"episode_reward": 875.1515579676674, "episode": 108.0, "batch_reward": 0.8441326174139977, "critic_loss": 0.5797492356002331, "actor_loss": -87.70190968322754, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.42309021949768, "step": 108000}
{"episode_reward": 963.1800120233579, "episode": 109.0, "batch_reward": 0.8468421066999435, "critic_loss": 0.5746150758564472, "actor_loss": -87.9446817779541, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.613719701766968, "step": 109000}
{"episode_reward": 945.4086031415679, "episode": 110.0, "batch_reward": 0.8445274453759194, "critic_loss": 0.5692660368829966, "actor_loss": -87.75233662414551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.552109956741333, "step": 110000}
{"episode_reward": 573.9674620606005, "episode": 111.0, "batch_reward": 0.8444160631299019, "critic_loss": 0.5576312663108111, "actor_loss": -87.89056881713867, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.272603034973145, "step": 111000}
{"episode_reward": 940.8978818377119, "episode": 112.0, "batch_reward": 0.8454945902228356, "critic_loss": 0.5924065985679626, "actor_loss": -87.77779724121093, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.826351165771484, "step": 112000}
{"episode_reward": 966.094848554045, "episode": 113.0, "batch_reward": 0.8469688527584076, "critic_loss": 0.5578735194504261, "actor_loss": -87.93605644226074, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.425289392471313, "step": 113000}
{"episode_reward": 968.2300079947595, "episode": 114.0, "batch_reward": 0.847870882153511, "critic_loss": 0.5653606801629066, "actor_loss": -87.88043951416016, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.5583975315094, "step": 114000}
{"episode_reward": 937.1169687476482, "episode": 115.0, "batch_reward": 0.8498151071071625, "critic_loss": 0.5973923014402389, "actor_loss": -88.07003646850586, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.570518970489502, "step": 115000}
{"episode_reward": 974.0977160147867, "episode": 116.0, "batch_reward": 0.8507903100848198, "critic_loss": 0.6063632784634828, "actor_loss": -87.99275459289551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.708582639694214, "step": 116000}
{"episode_reward": 978.7768993814694, "episode": 117.0, "batch_reward": 0.8512058558464051, "critic_loss": 0.572564160078764, "actor_loss": -88.1967488861084, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.338618755340576, "step": 117000}
{"episode_reward": 972.3202728699158, "episode": 118.0, "batch_reward": 0.8527145495414734, "critic_loss": 0.6671698054820299, "actor_loss": -88.12734648132324, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.322136402130127, "step": 118000}
{"episode_reward": 950.0555204706276, "episode": 119.0, "batch_reward": 0.8535999249815941, "critic_loss": 0.6091525196135044, "actor_loss": -88.33438334655762, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.950888872146606, "step": 119000}
{"episode_reward": 952.0727660979161, "episode": 120.0, "batch_reward": 0.8533377057313919, "critic_loss": 0.5789530655741691, "actor_loss": -88.38435325622558, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.602540731430054, "step": 120000}
{"episode_reward": 980.3479536121112, "episode": 121.0, "batch_reward": 0.8545946043729782, "critic_loss": 0.5985099926888943, "actor_loss": -88.48064192199708, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.59438920021057, "step": 121000}
{"episode_reward": 900.5442713047076, "episode": 122.0, "batch_reward": 0.8542562349438667, "critic_loss": 0.6272759225070477, "actor_loss": -88.4881647644043, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.722972869873047, "step": 122000}
{"episode_reward": 771.935264496476, "episode": 123.0, "batch_reward": 0.8546455308794976, "critic_loss": 0.5301059858053923, "actor_loss": -88.46285369873047, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.687982082366943, "step": 123000}
{"episode_reward": 966.0578039721875, "episode": 124.0, "batch_reward": 0.8547503461241722, "critic_loss": 0.5798056004345417, "actor_loss": -88.4218469543457, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.585034370422363, "step": 124000}
{"episode_reward": 977.1281431777029, "episode": 125.0, "batch_reward": 0.8545639297962189, "critic_loss": 0.5837065230160952, "actor_loss": -88.44644619750977, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.672899961471558, "step": 125000}
{"episode_reward": 956.303394986428, "episode": 126.0, "batch_reward": 0.8565507111549377, "critic_loss": 0.5860905848294496, "actor_loss": -88.51973236083984, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.845447540283203, "step": 126000}
{"episode_reward": 980.9623582444816, "episode": 127.0, "batch_reward": 0.856717389523983, "critic_loss": 0.5626421231031418, "actor_loss": -88.42976365661622, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.883009433746338, "step": 127000}
{"episode_reward": 908.6522620166317, "episode": 128.0, "batch_reward": 0.8559140198230744, "critic_loss": 0.6269547771513462, "actor_loss": -88.43920111083985, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.72761559486389, "step": 128000}
{"episode_reward": 582.937982538809, "episode": 129.0, "batch_reward": 0.8567009470462799, "critic_loss": 0.6044608899950981, "actor_loss": -88.4034937286377, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.312994480133057, "step": 129000}
{"episode_reward": 975.6469492455493, "episode": 130.0, "batch_reward": 0.856275128185749, "critic_loss": 0.6278807465732098, "actor_loss": -88.44718717956543, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.186721086502075, "step": 130000}
{"episode_reward": 927.867160980411, "episode": 131.0, "batch_reward": 0.8577680916190148, "critic_loss": 0.6302943766415119, "actor_loss": -88.67974165344238, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.57026219367981, "step": 131000}
{"episode_reward": 933.5249743145203, "episode": 132.0, "batch_reward": 0.8582636934518814, "critic_loss": 0.6384336305260658, "actor_loss": -88.7157158050537, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.806408166885376, "step": 132000}
{"episode_reward": 932.0023981664003, "episode": 133.0, "batch_reward": 0.8595095444321632, "critic_loss": 0.5807558029294014, "actor_loss": -88.87526898193359, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.7254536151886, "step": 133000}
{"episode_reward": 974.9214581899394, "episode": 134.0, "batch_reward": 0.8592041772007942, "critic_loss": 0.5697342408001422, "actor_loss": -88.66248721313477, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.344196796417236, "step": 134000}
{"episode_reward": 965.3372289770803, "episode": 135.0, "batch_reward": 0.8592268829345703, "critic_loss": 0.5685219208598137, "actor_loss": -88.63194052124024, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.864319801330566, "step": 135000}
{"episode_reward": 918.9308566139473, "episode": 136.0, "batch_reward": 0.8608760469555855, "critic_loss": 0.570797741547227, "actor_loss": -88.92305699157716, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.237165212631226, "step": 136000}
{"episode_reward": 882.36914197179, "episode": 137.0, "batch_reward": 0.8615820703506469, "critic_loss": 0.6433536169677972, "actor_loss": -88.76972230529785, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.322997331619263, "step": 137000}
{"episode_reward": 879.4175115810809, "episode": 138.0, "batch_reward": 0.86095576608181, "critic_loss": 0.5937407808452845, "actor_loss": -88.7957562866211, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.112104415893555, "step": 138000}
{"episode_reward": 976.2474111339407, "episode": 139.0, "batch_reward": 0.8598324666023255, "critic_loss": 0.5917845248878002, "actor_loss": -89.0304182434082, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.732226610183716, "step": 139000}
{"episode_reward": 849.4184962582857, "episode": 140.0, "batch_reward": 0.8608998807668686, "critic_loss": 0.5550782984793187, "actor_loss": -88.96968562316894, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.386558771133423, "step": 140000}
{"episode_reward": 973.6266294994806, "episode": 141.0, "batch_reward": 0.8638633925318718, "critic_loss": 0.5556842973977327, "actor_loss": -88.95226342773438, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.636199712753296, "step": 141000}
{"episode_reward": 946.2183890613841, "episode": 142.0, "batch_reward": 0.8633522124290466, "critic_loss": 0.5440971524715423, "actor_loss": -89.05969343566895, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.157214641571045, "step": 142000}
{"episode_reward": 844.0074175479884, "episode": 143.0, "batch_reward": 0.8628459596037865, "critic_loss": 0.5592458670288324, "actor_loss": -88.89416116333008, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.520339488983154, "step": 143000}
{"episode_reward": 959.4332217883672, "episode": 144.0, "batch_reward": 0.8631143338084221, "critic_loss": 0.5778258222490549, "actor_loss": -88.87510319519043, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.73495626449585, "step": 144000}
{"episode_reward": 941.7860485175768, "episode": 145.0, "batch_reward": 0.8657854948639869, "critic_loss": 0.5526100056469441, "actor_loss": -88.90151582336426, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.761720180511475, "step": 145000}
{"episode_reward": 949.9368558422784, "episode": 146.0, "batch_reward": 0.8634648025035858, "critic_loss": 0.6026116615980863, "actor_loss": -88.8041061553955, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.963618755340576, "step": 146000}
{"episode_reward": 917.6274880491758, "episode": 147.0, "batch_reward": 0.8628374782204628, "critic_loss": 0.5834450975358486, "actor_loss": -88.99627075195312, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.768163919448853, "step": 147000}
{"episode_reward": 924.6440471250562, "episode": 148.0, "batch_reward": 0.8653453605771064, "critic_loss": 0.6281101751625537, "actor_loss": -88.89416134643555, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.535163640975952, "step": 148000}
{"episode_reward": 952.5653889002865, "episode": 149.0, "batch_reward": 0.8659330177307129, "critic_loss": 0.5846227015256882, "actor_loss": -89.13485743713379, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.6429660320282, "step": 149000}
{"episode_reward": 919.9458486605635, "episode": 150.0, "batch_reward": 0.8660709760189056, "critic_loss": 0.6293987445235253, "actor_loss": -88.92515142822266, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "step": 150000}
