{"episode_reward": 0.0, "episode": 1.0, "duration": 23.077514171600342, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.8803777694702148, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.4216477038880991, "critic_loss": 0.4797289265060711, "actor_loss": -75.45988814226862, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 64.16896176338196, "step": 3000}
{"episode_reward": 310.2813451708952, "episode": 4.0, "batch_reward": 0.42147649881243704, "critic_loss": 0.6154945238828659, "actor_loss": -75.06437608337403, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.13107204437256, "step": 4000}
{"episode_reward": 677.184743068978, "episode": 5.0, "batch_reward": 0.49585002326965333, "critic_loss": 0.42968044003844263, "actor_loss": -77.09925959777831, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.432697772979736, "step": 5000}
{"episode_reward": 822.8313167124529, "episode": 6.0, "batch_reward": 0.5607326753437519, "critic_loss": 0.3924195633381605, "actor_loss": -78.74549235534668, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.811954259872437, "step": 6000}
{"episode_reward": 815.6845082274284, "episode": 7.0, "batch_reward": 0.6057101659774781, "critic_loss": 0.35409012585878374, "actor_loss": -79.79183238220214, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.550787925720215, "step": 7000}
{"episode_reward": 897.0453970030807, "episode": 8.0, "batch_reward": 0.6392153521180153, "critic_loss": 0.3859118407815695, "actor_loss": -80.61832447814942, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.034731149673462, "step": 8000}
{"episode_reward": 854.8407474138719, "episode": 9.0, "batch_reward": 0.6703676955699921, "critic_loss": 0.3943982285559177, "actor_loss": -81.43635168457031, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.5157630443573, "step": 9000}
{"episode_reward": 923.9969680206733, "episode": 10.0, "batch_reward": 0.6904361928701401, "critic_loss": 0.3781849916577339, "actor_loss": -82.04389053344727, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.97465682029724, "step": 10000}
{"episode_reward": 869.5648948704699, "episode": 11.0, "batch_reward": 0.7092205268144608, "critic_loss": 0.3428669190108776, "actor_loss": -82.2805868988037, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.167473793029785, "step": 11000}
{"episode_reward": 858.6596506756933, "episode": 12.0, "batch_reward": 0.7240984314084054, "critic_loss": 0.33003120735287667, "actor_loss": -82.55712748718261, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.49884295463562, "step": 12000}
{"episode_reward": 889.5050723586072, "episode": 13.0, "batch_reward": 0.7290102078318595, "critic_loss": 0.332703158184886, "actor_loss": -82.59345906066895, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.381143808364868, "step": 13000}
{"episode_reward": 802.2722790229902, "episode": 14.0, "batch_reward": 0.7407209625840188, "critic_loss": 0.29635221710801124, "actor_loss": -82.78190118408203, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.763710498809814, "step": 14000}
{"episode_reward": 876.4027735270258, "episode": 15.0, "batch_reward": 0.7520810965895652, "critic_loss": 0.2919652325063944, "actor_loss": -83.01068128967285, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.857977628707886, "step": 15000}
{"episode_reward": 909.2244251468587, "episode": 16.0, "batch_reward": 0.7614050886034965, "critic_loss": 0.2862946532666683, "actor_loss": -83.27134657287597, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.84176468849182, "step": 16000}
{"episode_reward": 906.3513103139757, "episode": 17.0, "batch_reward": 0.7698525401353836, "critic_loss": 0.3004246247857809, "actor_loss": -83.33489878845215, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.08559560775757, "step": 17000}
{"episode_reward": 851.5875609234893, "episode": 18.0, "batch_reward": 0.7747928078770637, "critic_loss": 0.27828916233778, "actor_loss": -83.42263182067872, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.289254188537598, "step": 18000}
{"episode_reward": 899.0172940812208, "episode": 19.0, "batch_reward": 0.7833224565386773, "critic_loss": 0.3008855754584074, "actor_loss": -83.64047804260254, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.406031608581543, "step": 19000}
{"episode_reward": 945.3790410251769, "episode": 20.0, "batch_reward": 0.7886523982286453, "critic_loss": 0.34392901661992076, "actor_loss": -83.93751618957519, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.811250686645508, "step": 20000}
{"episode_reward": 859.5570224878304, "episode": 21.0, "batch_reward": 0.795427792608738, "critic_loss": 0.3231232831329107, "actor_loss": -83.81649807739258, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 45.260361194610596, "step": 21000}
{"episode_reward": 917.4388871607208, "episode": 22.0, "batch_reward": 0.7980591225624084, "critic_loss": 0.3963045130223036, "actor_loss": -84.07294409179687, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.411012649536133, "step": 22000}
{"episode_reward": 873.1483846602483, "episode": 23.0, "batch_reward": 0.8029181965589524, "critic_loss": 0.4047558979541063, "actor_loss": -84.0251312713623, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.612025260925293, "step": 23000}
{"episode_reward": 904.9488062667548, "episode": 24.0, "batch_reward": 0.8072590861320496, "critic_loss": 0.36794791536033156, "actor_loss": -84.24572679138184, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.260125637054443, "step": 24000}
{"episode_reward": 937.7340743597142, "episode": 25.0, "batch_reward": 0.8116283836364746, "critic_loss": 0.37092140299081805, "actor_loss": -84.49279521179199, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.055051565170288, "step": 25000}
{"episode_reward": 905.0999454641251, "episode": 26.0, "batch_reward": 0.8171586796045304, "critic_loss": 0.34171275787055494, "actor_loss": -84.52677282714843, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.59481167793274, "step": 26000}
{"episode_reward": 953.4256942215422, "episode": 27.0, "batch_reward": 0.8229410754442215, "critic_loss": 0.33859666374325753, "actor_loss": -84.72741706848144, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.165372610092163, "step": 27000}
{"episode_reward": 951.6179677302929, "episode": 28.0, "batch_reward": 0.8252266879081727, "critic_loss": 0.3426991475075483, "actor_loss": -84.83437463378907, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.190927743911743, "step": 28000}
{"episode_reward": 911.7148156267785, "episode": 29.0, "batch_reward": 0.8283097134232521, "critic_loss": 0.3002170403003693, "actor_loss": -84.95484288024902, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.9822940826416, "step": 29000}
{"episode_reward": 919.4490326964936, "episode": 30.0, "batch_reward": 0.8321254268884659, "critic_loss": 0.3098288507759571, "actor_loss": -84.99355438232422, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.649474620819092, "step": 30000}
{"episode_reward": 874.4789810206711, "episode": 31.0, "batch_reward": 0.833318876683712, "critic_loss": 0.284408746227622, "actor_loss": -85.0721888885498, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.46198868751526, "step": 31000}
{"episode_reward": 924.4917458268573, "episode": 32.0, "batch_reward": 0.8350018734335899, "critic_loss": 0.3088739461004734, "actor_loss": -85.1891771850586, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.723147869110107, "step": 32000}
{"episode_reward": 856.2950753836244, "episode": 33.0, "batch_reward": 0.8333892031311989, "critic_loss": 0.35955435018241405, "actor_loss": -85.04309783935547, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.808212995529175, "step": 33000}
{"episode_reward": 719.7860571689436, "episode": 34.0, "batch_reward": 0.8360679513216018, "critic_loss": 0.3281122057437897, "actor_loss": -85.16377438354492, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.552961587905884, "step": 34000}
{"episode_reward": 961.8278812564384, "episode": 35.0, "batch_reward": 0.8360792369842529, "critic_loss": 0.3351855228692293, "actor_loss": -85.16826287841796, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.600364446640015, "step": 35000}
{"episode_reward": 842.8607981739954, "episode": 36.0, "batch_reward": 0.837875572860241, "critic_loss": 0.32880093502998353, "actor_loss": -85.25164123535156, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.232927322387695, "step": 36000}
{"episode_reward": 915.9201872203108, "episode": 37.0, "batch_reward": 0.8422713125348091, "critic_loss": 0.32473587134480475, "actor_loss": -85.2853942565918, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.215991258621216, "step": 37000}
{"episode_reward": 961.6788898867462, "episode": 38.0, "batch_reward": 0.8447367272377014, "critic_loss": 0.3458727236241102, "actor_loss": -85.30765158081054, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.187610626220703, "step": 38000}
{"episode_reward": 946.8023213355801, "episode": 39.0, "batch_reward": 0.8447114270329475, "critic_loss": 0.34710535254329444, "actor_loss": -85.39980618286133, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.294557571411133, "step": 39000}
{"episode_reward": 910.7455391715949, "episode": 40.0, "batch_reward": 0.848304415345192, "critic_loss": 0.3293526736050844, "actor_loss": -85.59113024902344, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.627346754074097, "step": 40000}
{"episode_reward": 953.6176605443936, "episode": 41.0, "batch_reward": 0.8502932282686233, "critic_loss": 0.33308873964846136, "actor_loss": -85.62374528503418, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 44.937827825546265, "step": 41000}
{"episode_reward": 934.6555236146136, "episode": 42.0, "batch_reward": 0.8530173384547234, "critic_loss": 0.3407616563513875, "actor_loss": -85.7679289855957, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.570252895355225, "step": 42000}
{"episode_reward": 925.4186891769069, "episode": 43.0, "batch_reward": 0.8545289887189865, "critic_loss": 0.3395928790718317, "actor_loss": -85.8140066986084, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.66225266456604, "step": 43000}
{"episode_reward": 960.4834089238915, "episode": 44.0, "batch_reward": 0.8569853243231773, "critic_loss": 0.32049088562279937, "actor_loss": -86.01008515930175, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.039761543273926, "step": 44000}
{"episode_reward": 945.4676306838486, "episode": 45.0, "batch_reward": 0.8577992604970932, "critic_loss": 0.31947713054716587, "actor_loss": -86.00021147155762, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.00103449821472, "step": 45000}
{"episode_reward": 964.5821781835116, "episode": 46.0, "batch_reward": 0.8606377002000809, "critic_loss": 0.30393788743019107, "actor_loss": -86.06236674499512, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.462913036346436, "step": 46000}
{"episode_reward": 962.4716181703691, "episode": 47.0, "batch_reward": 0.8620428944826126, "critic_loss": 0.32510962744057176, "actor_loss": -86.1002621459961, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.45502543449402, "step": 47000}
{"episode_reward": 862.3817746659389, "episode": 48.0, "batch_reward": 0.862107744038105, "critic_loss": 0.311780635856092, "actor_loss": -86.1183412322998, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.613311290740967, "step": 48000}
{"episode_reward": 917.2922823112184, "episode": 49.0, "batch_reward": 0.8637350655794144, "critic_loss": 0.30269448380172254, "actor_loss": -86.19157075500489, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.177252054214478, "step": 49000}
{"episode_reward": 959.3291529910535, "episode": 50.0, "batch_reward": 0.8664700424671173, "critic_loss": 0.3012012330144644, "actor_loss": -86.26691154479981, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.36672806739807, "step": 50000}
{"episode_reward": 946.0768208429921, "episode": 51.0, "batch_reward": 0.8669063932299614, "critic_loss": 0.31211293579638005, "actor_loss": -86.27632054138184, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.15063166618347, "step": 51000}
{"episode_reward": 940.8142668846407, "episode": 52.0, "batch_reward": 0.8676941419243812, "critic_loss": 0.3046025362685323, "actor_loss": -86.26278898620606, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.278250455856323, "step": 52000}
{"episode_reward": 848.4595908634119, "episode": 53.0, "batch_reward": 0.8673053355813026, "critic_loss": 0.2999843523949385, "actor_loss": -86.32977993774414, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.76587986946106, "step": 53000}
{"episode_reward": 915.9780147462403, "episode": 54.0, "batch_reward": 0.8704814615249634, "critic_loss": 0.28757936806976797, "actor_loss": -86.4107205505371, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.77220582962036, "step": 54000}
{"episode_reward": 945.5955417399041, "episode": 55.0, "batch_reward": 0.8715088650584221, "critic_loss": 0.28383595805615186, "actor_loss": -86.42227838134765, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.305808782577515, "step": 55000}
{"episode_reward": 940.6024537449454, "episode": 56.0, "batch_reward": 0.8718382870554924, "critic_loss": 0.30784713903069494, "actor_loss": -86.44082215881348, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.317418098449707, "step": 56000}
{"episode_reward": 942.9771152969777, "episode": 57.0, "batch_reward": 0.8744070544838906, "critic_loss": 0.29457209348678587, "actor_loss": -86.54188278198242, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.366356134414673, "step": 57000}
{"episode_reward": 933.9464777597501, "episode": 58.0, "batch_reward": 0.871941687643528, "critic_loss": 0.37691465912759303, "actor_loss": -86.4890047454834, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.410900354385376, "step": 58000}
{"episode_reward": 869.3567048061379, "episode": 59.0, "batch_reward": 0.874035126388073, "critic_loss": 0.36523061282932756, "actor_loss": -86.52204425048828, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.55091953277588, "step": 59000}
{"episode_reward": 975.3401574635654, "episode": 60.0, "batch_reward": 0.8759008105993271, "critic_loss": 0.3417883055657148, "actor_loss": -86.67155567932129, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.398810625076294, "step": 60000}
{"episode_reward": 933.6911359790038, "episode": 61.0, "batch_reward": 0.8774740211963653, "critic_loss": 0.3115453531369567, "actor_loss": -86.67070011901855, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.76818609237671, "step": 61000}
{"episode_reward": 926.7702528993435, "episode": 62.0, "batch_reward": 0.8773775252103806, "critic_loss": 0.34439273370802403, "actor_loss": -86.7014398651123, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.157365798950195, "step": 62000}
{"episode_reward": 893.5958608348667, "episode": 63.0, "batch_reward": 0.8783046842813492, "critic_loss": 0.33109963688254357, "actor_loss": -86.74449334716797, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.83957266807556, "step": 63000}
{"episode_reward": 958.4287061497915, "episode": 64.0, "batch_reward": 0.8796031115651131, "critic_loss": 0.31154312393069267, "actor_loss": -86.78785902404785, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.413694143295288, "step": 64000}
{"episode_reward": 932.2748397927845, "episode": 65.0, "batch_reward": 0.8800624849200249, "critic_loss": 0.2782652146443725, "actor_loss": -86.84293293762207, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.34947681427002, "step": 65000}
{"episode_reward": 956.911225524056, "episode": 66.0, "batch_reward": 0.8806699492931366, "critic_loss": 0.29041345524042844, "actor_loss": -86.80511547851563, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.499304056167603, "step": 66000}
{"episode_reward": 915.2007503468105, "episode": 67.0, "batch_reward": 0.8814079940915108, "critic_loss": 0.3063372339382768, "actor_loss": -86.87603399658204, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.784043788909912, "step": 67000}
{"episode_reward": 948.1557235205734, "episode": 68.0, "batch_reward": 0.8828078822493554, "critic_loss": 0.29818037707358597, "actor_loss": -86.86297357177735, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.800333976745605, "step": 68000}
{"episode_reward": 916.2024753572231, "episode": 69.0, "batch_reward": 0.8820758261084557, "critic_loss": 0.29877272836118934, "actor_loss": -86.91795114135742, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.236146450042725, "step": 69000}
{"episode_reward": 931.1932799850834, "episode": 70.0, "batch_reward": 0.884191541314125, "critic_loss": 0.31763521425426006, "actor_loss": -86.96284635925294, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.017192840576172, "step": 70000}
{"episode_reward": 944.6222910822248, "episode": 71.0, "batch_reward": 0.8842505330443382, "critic_loss": 0.285530566342175, "actor_loss": -87.01755142211914, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.97702240943909, "step": 71000}
{"episode_reward": 920.5637187583258, "episode": 72.0, "batch_reward": 0.8838015481233596, "critic_loss": 0.2870716826617718, "actor_loss": -87.01778462219238, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.712387323379517, "step": 72000}
{"episode_reward": 935.4358133023843, "episode": 73.0, "batch_reward": 0.8867268929481507, "critic_loss": 0.30626385419070723, "actor_loss": -87.09811102294921, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.229983806610107, "step": 73000}
{"episode_reward": 943.0225651161027, "episode": 74.0, "batch_reward": 0.8867583983540535, "critic_loss": 0.28520389667898416, "actor_loss": -87.13163339233398, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.24871063232422, "step": 74000}
{"episode_reward": 943.7561700015142, "episode": 75.0, "batch_reward": 0.8871103054881095, "critic_loss": 0.2765283677354455, "actor_loss": -87.16745265197754, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.088318586349487, "step": 75000}
{"episode_reward": 890.537522577432, "episode": 76.0, "batch_reward": 0.8874534837603569, "critic_loss": 0.26679086352139714, "actor_loss": -87.17346189880371, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.396953105926514, "step": 76000}
{"episode_reward": 894.2632257313912, "episode": 77.0, "batch_reward": 0.88686154961586, "critic_loss": 0.2777886153757572, "actor_loss": -87.18315486145019, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.97659397125244, "step": 77000}
{"episode_reward": 900.6792228888918, "episode": 78.0, "batch_reward": 0.8873544939756394, "critic_loss": 0.29704166585206987, "actor_loss": -87.17182682800293, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.99641227722168, "step": 78000}
{"episode_reward": 947.6866892723835, "episode": 79.0, "batch_reward": 0.8877608991861343, "critic_loss": 0.3104675877988338, "actor_loss": -87.18822465515137, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.21643900871277, "step": 79000}
{"episode_reward": 851.3495331355936, "episode": 80.0, "batch_reward": 0.8877118294239044, "critic_loss": 0.28945213139802217, "actor_loss": -87.19646162414551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.81141948699951, "step": 80000}
{"episode_reward": 955.5367155895673, "episode": 81.0, "batch_reward": 0.8889032491445541, "critic_loss": 0.2880331869572401, "actor_loss": -87.3177814025879, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.582077741622925, "step": 81000}
{"episode_reward": 907.3802346595623, "episode": 82.0, "batch_reward": 0.8876117439270019, "critic_loss": 0.30415616953372954, "actor_loss": -87.24903785705567, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.161438465118408, "step": 82000}
{"episode_reward": 891.210411403718, "episode": 83.0, "batch_reward": 0.8913971450924874, "critic_loss": 0.29973694179952143, "actor_loss": -87.32487896728516, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.839975833892822, "step": 83000}
{"episode_reward": 952.8747519946337, "episode": 84.0, "batch_reward": 0.8896277933716774, "critic_loss": 0.3136015754193068, "actor_loss": -87.29369227600098, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.868809700012207, "step": 84000}
{"episode_reward": 911.4994469996801, "episode": 85.0, "batch_reward": 0.8901791944503784, "critic_loss": 0.2969477744847536, "actor_loss": -87.30491104125977, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.513267755508423, "step": 85000}
{"episode_reward": 938.7536172129269, "episode": 86.0, "batch_reward": 0.8918592027425766, "critic_loss": 0.2883935081511736, "actor_loss": -87.40228753662109, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.135576486587524, "step": 86000}
{"episode_reward": 931.4723676249822, "episode": 87.0, "batch_reward": 0.8913928592205047, "critic_loss": 0.27553564485162496, "actor_loss": -87.31351681518555, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.55076003074646, "step": 87000}
{"episode_reward": 953.8701314351885, "episode": 88.0, "batch_reward": 0.8918513547182083, "critic_loss": 0.29967592978477475, "actor_loss": -87.4203172454834, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.83655047416687, "step": 88000}
{"episode_reward": 932.5966732727186, "episode": 89.0, "batch_reward": 0.8915190039277077, "critic_loss": 0.2882528158351779, "actor_loss": -87.36429650878907, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.798463106155396, "step": 89000}
{"episode_reward": 903.5984512188538, "episode": 90.0, "batch_reward": 0.8936909579634666, "critic_loss": 0.2769282506108284, "actor_loss": -87.48206719970703, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.04252314567566, "step": 90000}
{"episode_reward": 914.9191180633735, "episode": 91.0, "batch_reward": 0.893417363345623, "critic_loss": 0.2708765323981643, "actor_loss": -87.50000738525391, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.341712474823, "step": 91000}
{"episode_reward": 951.4374514843882, "episode": 92.0, "batch_reward": 0.8928800354599953, "critic_loss": 0.2962415549308062, "actor_loss": -87.44200685119628, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.6985764503479, "step": 92000}
{"episode_reward": 863.3014675652553, "episode": 93.0, "batch_reward": 0.8924516265392304, "critic_loss": 0.29611355505138637, "actor_loss": -87.52858525085449, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.43070936203003, "step": 93000}
{"episode_reward": 920.8588123432611, "episode": 94.0, "batch_reward": 0.8918358963131905, "critic_loss": 0.2900978899076581, "actor_loss": -87.47104428100586, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.5689857006073, "step": 94000}
{"episode_reward": 878.0907731006096, "episode": 95.0, "batch_reward": 0.8930792039632798, "critic_loss": 0.300766477689147, "actor_loss": -87.44787101745605, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.99952745437622, "step": 95000}
{"episode_reward": 915.328094396632, "episode": 96.0, "batch_reward": 0.8931854881048202, "critic_loss": 0.33402942404150965, "actor_loss": -87.51728479003906, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.240603923797607, "step": 96000}
{"episode_reward": 886.6750028798351, "episode": 97.0, "batch_reward": 0.8931230348348618, "critic_loss": 0.32026568656414744, "actor_loss": -87.55030241394043, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.06036639213562, "step": 97000}
{"episode_reward": 970.0093520320554, "episode": 98.0, "batch_reward": 0.8945302761793137, "critic_loss": 0.30273080363869664, "actor_loss": -87.49605151367187, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.427128076553345, "step": 98000}
{"episode_reward": 955.3585963961702, "episode": 99.0, "batch_reward": 0.8960894406437874, "critic_loss": 0.30463044479489326, "actor_loss": -87.61664045715332, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.107556104660034, "step": 99000}
{"episode_reward": 976.2719360868387, "episode": 100.0, "batch_reward": 0.8946750125288964, "critic_loss": 0.31224214905500414, "actor_loss": -87.57974201965332, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.972045183181763, "step": 100000}
{"episode_reward": 917.9061009819385, "episode": 101.0, "batch_reward": 0.8960513843894005, "critic_loss": 0.30192237117141485, "actor_loss": -87.67640707397462, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 45.31506323814392, "step": 101000}
{"episode_reward": 937.3533703866095, "episode": 102.0, "batch_reward": 0.8968400626182557, "critic_loss": 0.30800839015841486, "actor_loss": -87.6198444519043, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.965152502059937, "step": 102000}
{"episode_reward": 960.527757940903, "episode": 103.0, "batch_reward": 0.896714790046215, "critic_loss": 0.29979835863411425, "actor_loss": -87.73118949890137, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.578375101089478, "step": 103000}
{"episode_reward": 966.0507462355757, "episode": 104.0, "batch_reward": 0.8981862157583237, "critic_loss": 0.3043681866452098, "actor_loss": -87.73019384765625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.28132200241089, "step": 104000}
{"episode_reward": 935.4021913219656, "episode": 105.0, "batch_reward": 0.8975419580340386, "critic_loss": 0.30585720647126435, "actor_loss": -87.69657156372071, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.669960021972656, "step": 105000}
{"episode_reward": 930.1619192177783, "episode": 106.0, "batch_reward": 0.8977343680262566, "critic_loss": 0.28595841957628726, "actor_loss": -87.74146800231934, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.218392372131348, "step": 106000}
{"episode_reward": 943.0795406365036, "episode": 107.0, "batch_reward": 0.8979362953901291, "critic_loss": 0.3059768356755376, "actor_loss": -87.81025230407715, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.081010818481445, "step": 107000}
{"episode_reward": 935.8918330849839, "episode": 108.0, "batch_reward": 0.898771276473999, "critic_loss": 0.2852130919843912, "actor_loss": -87.75028494262695, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.145454168319702, "step": 108000}
{"episode_reward": 920.9699688742847, "episode": 109.0, "batch_reward": 0.9002021643519401, "critic_loss": 0.28694926837831736, "actor_loss": -87.81700019836425, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.948378801345825, "step": 109000}
{"episode_reward": 908.3363299782477, "episode": 110.0, "batch_reward": 0.8987002211213112, "critic_loss": 0.3092082929238677, "actor_loss": -87.7986735534668, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.558689832687378, "step": 110000}
{"episode_reward": 915.4333932966748, "episode": 111.0, "batch_reward": 0.8990147055387497, "critic_loss": 0.2784455064162612, "actor_loss": -87.87670668029786, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.23950409889221, "step": 111000}
{"episode_reward": 938.353995170608, "episode": 112.0, "batch_reward": 0.8985394417047501, "critic_loss": 0.3094252301901579, "actor_loss": -87.7885258026123, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.176808834075928, "step": 112000}
{"episode_reward": 843.303633980916, "episode": 113.0, "batch_reward": 0.9004578197002411, "critic_loss": 0.2967071282714605, "actor_loss": -87.9310421142578, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.381889820098877, "step": 113000}
{"episode_reward": 960.3100198066012, "episode": 114.0, "batch_reward": 0.900566210091114, "critic_loss": 0.28360611423105003, "actor_loss": -87.86011134338379, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.45784068107605, "step": 114000}
{"episode_reward": 946.1248906257215, "episode": 115.0, "batch_reward": 0.9014818215966225, "critic_loss": 0.2804856823012233, "actor_loss": -87.91589669799805, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.05161428451538, "step": 115000}
{"episode_reward": 962.6831313922014, "episode": 116.0, "batch_reward": 0.9020147508382798, "critic_loss": 0.28482579823583365, "actor_loss": -87.8725274810791, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.12030601501465, "step": 116000}
{"episode_reward": 951.4966633674317, "episode": 117.0, "batch_reward": 0.9024147851467132, "critic_loss": 0.2842739072442055, "actor_loss": -87.98963400268555, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.751488208770752, "step": 117000}
{"episode_reward": 966.9826076152897, "episode": 118.0, "batch_reward": 0.9019527908563614, "critic_loss": 0.28249598345160487, "actor_loss": -87.96945941162109, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.290912866592407, "step": 118000}
{"episode_reward": 937.1209327289188, "episode": 119.0, "batch_reward": 0.902213506937027, "critic_loss": 0.330622293703258, "actor_loss": -87.9244811706543, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.62416434288025, "step": 119000}
{"episode_reward": 865.8948898191418, "episode": 120.0, "batch_reward": 0.9015935506224633, "critic_loss": 0.3072386736944318, "actor_loss": -87.97853050231933, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.07679033279419, "step": 120000}
{"episode_reward": 952.017448997204, "episode": 121.0, "batch_reward": 0.903389106631279, "critic_loss": 0.32825681671500206, "actor_loss": -88.00441831970215, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.03165245056152, "step": 121000}
{"episode_reward": 931.7656877734971, "episode": 122.0, "batch_reward": 0.9023031612634659, "critic_loss": 0.3116441338583827, "actor_loss": -87.91904919433594, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.10940909385681, "step": 122000}
{"episode_reward": 896.1382929905138, "episode": 123.0, "batch_reward": 0.9022585698962211, "critic_loss": 0.3190205343067646, "actor_loss": -87.99402133178711, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.161948442459106, "step": 123000}
{"episode_reward": 927.2054940443758, "episode": 124.0, "batch_reward": 0.9014541580080986, "critic_loss": 0.2956071432456374, "actor_loss": -87.89702589416504, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.429978609085083, "step": 124000}
{"episode_reward": 951.790222503765, "episode": 125.0, "batch_reward": 0.9021756308674812, "critic_loss": 0.33871095076948404, "actor_loss": -87.9860772857666, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.528733253479004, "step": 125000}
{"episode_reward": 921.901446009569, "episode": 126.0, "batch_reward": 0.9027501611709595, "critic_loss": 0.34946543096750976, "actor_loss": -87.91535507202148, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.169454097747803, "step": 126000}
{"episode_reward": 958.4129517533185, "episode": 127.0, "batch_reward": 0.9032583920359611, "critic_loss": 0.33829241394996645, "actor_loss": -87.93843315124512, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.687653064727783, "step": 127000}
{"episode_reward": 909.8930487432683, "episode": 128.0, "batch_reward": 0.9033728387355805, "critic_loss": 0.3567941744253039, "actor_loss": -87.99910153198242, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.030932903289795, "step": 128000}
{"episode_reward": 883.5176954438292, "episode": 129.0, "batch_reward": 0.9031562423706054, "critic_loss": 0.3555078898742795, "actor_loss": -87.94962507629394, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.963215112686157, "step": 129000}
{"episode_reward": 960.123378385471, "episode": 130.0, "batch_reward": 0.9031121294498443, "critic_loss": 0.34191294172406195, "actor_loss": -87.94358540344238, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.666349411010742, "step": 130000}
{"episode_reward": 902.0360174922807, "episode": 131.0, "batch_reward": 0.9043986389040947, "critic_loss": 0.3550757857263088, "actor_loss": -88.08718824768066, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.17221641540527, "step": 131000}
{"episode_reward": 927.8499853843773, "episode": 132.0, "batch_reward": 0.9038690728545189, "critic_loss": 0.3573029545620084, "actor_loss": -87.95168296813965, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.3850576877594, "step": 132000}
{"episode_reward": 897.7606147685815, "episode": 133.0, "batch_reward": 0.9038093872666358, "critic_loss": 0.3325751971825957, "actor_loss": -88.07614199829102, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.989264488220215, "step": 133000}
{"episode_reward": 965.746417250894, "episode": 134.0, "batch_reward": 0.9043634447455406, "critic_loss": 0.32359818700701, "actor_loss": -88.01629376220703, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.207595825195312, "step": 134000}
{"episode_reward": 955.1827737309484, "episode": 135.0, "batch_reward": 0.9035373738408089, "critic_loss": 0.3258076537624002, "actor_loss": -87.9507827911377, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.507188081741333, "step": 135000}
{"episode_reward": 863.7877375219086, "episode": 136.0, "batch_reward": 0.9044504866003991, "critic_loss": 0.3055126306563616, "actor_loss": -88.07877371215821, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.639718532562256, "step": 136000}
{"episode_reward": 895.4957099969677, "episode": 137.0, "batch_reward": 0.9052484714984894, "critic_loss": 0.2982332680001855, "actor_loss": -88.07024522399902, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.31065011024475, "step": 137000}
{"episode_reward": 880.5565904172228, "episode": 138.0, "batch_reward": 0.9046746804714203, "critic_loss": 0.32445186430215833, "actor_loss": -88.07429142761231, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.34973454475403, "step": 138000}
{"episode_reward": 965.7834352269348, "episode": 139.0, "batch_reward": 0.9033284359574318, "critic_loss": 0.33246784628927706, "actor_loss": -88.06694645690918, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.087809801101685, "step": 139000}
{"episode_reward": 898.5335211551277, "episode": 140.0, "batch_reward": 0.9044349945187569, "critic_loss": 0.33450642169266936, "actor_loss": -87.95614524841308, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.420547008514404, "step": 140000}
{"episode_reward": 930.2313089220188, "episode": 141.0, "batch_reward": 0.9066224379539489, "critic_loss": 0.31480039432644846, "actor_loss": -88.11774932861329, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.15722608566284, "step": 141000}
{"episode_reward": 895.684689178482, "episode": 142.0, "batch_reward": 0.9053309779167176, "critic_loss": 0.3181271316334605, "actor_loss": -88.09145692443848, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.739336252212524, "step": 142000}
{"episode_reward": 955.8124731008069, "episode": 143.0, "batch_reward": 0.9049915840029716, "critic_loss": 0.3238413963764906, "actor_loss": -88.08786941528321, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.99517059326172, "step": 143000}
{"episode_reward": 908.2966761327592, "episode": 144.0, "batch_reward": 0.9045105553865432, "critic_loss": 0.32959906478226186, "actor_loss": -88.00723422241211, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.500532150268555, "step": 144000}
{"episode_reward": 937.6938961563518, "episode": 145.0, "batch_reward": 0.9064772281050683, "critic_loss": 0.3352017087414861, "actor_loss": -88.07206858825684, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.74208927154541, "step": 145000}
{"episode_reward": 941.3444319687075, "episode": 146.0, "batch_reward": 0.9048096579909325, "critic_loss": 0.3493878786712885, "actor_loss": -88.11806468200683, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.500741004943848, "step": 146000}
{"episode_reward": 900.7423545912518, "episode": 147.0, "batch_reward": 0.9046380596756936, "critic_loss": 0.33450406160950663, "actor_loss": -88.08335075378417, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.98631453514099, "step": 147000}
{"episode_reward": 900.8609617201804, "episode": 148.0, "batch_reward": 0.9052875715494156, "critic_loss": 0.3210132439956069, "actor_loss": -88.07342013549804, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.088305473327637, "step": 148000}
{"episode_reward": 933.1454450729651, "episode": 149.0, "batch_reward": 0.9065721071362496, "critic_loss": 0.3374613826945424, "actor_loss": -88.06789904785157, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.199200868606567, "step": 149000}
{"episode_reward": 894.148337223936, "episode": 150.0, "batch_reward": 0.9057235598564148, "critic_loss": 0.35447410102933646, "actor_loss": -88.02758500671386, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "step": 150000}
