{"episode_reward": 0.0, "episode": 1.0, "duration": 21.632492542266846, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.8378987312316895, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.4608415071767106, "critic_loss": 0.3314250812739402, "actor_loss": -78.49382438522284, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 70.76834011077881, "step": 3000}
{"episode_reward": 855.1300813443029, "episode": 4.0, "batch_reward": 0.6106651923954487, "critic_loss": 0.3576460996121168, "actor_loss": -84.84713093566894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.584749221801758, "step": 4000}
{"episode_reward": 853.6742376587108, "episode": 5.0, "batch_reward": 0.6514773231744766, "critic_loss": 0.32332400754094126, "actor_loss": -85.81971696472168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.58568024635315, "step": 5000}
{"episode_reward": 795.4228640005547, "episode": 6.0, "batch_reward": 0.685364239513874, "critic_loss": 0.2973787220567465, "actor_loss": -86.31503161621093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60112190246582, "step": 6000}
{"episode_reward": 862.3539610708754, "episode": 7.0, "batch_reward": 0.7238210654854774, "critic_loss": 0.2599321554601193, "actor_loss": -87.30093922424317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60029649734497, "step": 7000}
{"episode_reward": 943.8313294844396, "episode": 8.0, "batch_reward": 0.7510667696595192, "critic_loss": 0.28006606444716453, "actor_loss": -87.78283052062989, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.56105875968933, "step": 8000}
{"episode_reward": 920.9279650452962, "episode": 9.0, "batch_reward": 0.7718092224001885, "critic_loss": 0.2439483171105385, "actor_loss": -88.20387487792969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.587080240249634, "step": 9000}
{"episode_reward": 937.4335376407821, "episode": 10.0, "batch_reward": 0.7794769753217697, "critic_loss": 0.26580462470650673, "actor_loss": -88.33065055847167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.56781506538391, "step": 10000}
{"episode_reward": 843.3102683305649, "episode": 11.0, "batch_reward": 0.789727605342865, "critic_loss": 0.2624077444374561, "actor_loss": -88.30613514709472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.1856906414032, "step": 11000}
{"episode_reward": 870.6307109407985, "episode": 12.0, "batch_reward": 0.8016186485886574, "critic_loss": 0.25840427859127524, "actor_loss": -88.55840742492676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5785973072052, "step": 12000}
{"episode_reward": 944.5551222984441, "episode": 13.0, "batch_reward": 0.8123668868541718, "critic_loss": 0.25700535127520563, "actor_loss": -88.99821618652344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.63304829597473, "step": 13000}
{"episode_reward": 943.2755675463236, "episode": 14.0, "batch_reward": 0.8148058823347092, "critic_loss": 0.2725994149148464, "actor_loss": -88.8369557800293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.52395224571228, "step": 14000}
{"episode_reward": 816.2544069184884, "episode": 15.0, "batch_reward": 0.819179345369339, "critic_loss": 0.23679312460124494, "actor_loss": -88.70347331237792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.58506464958191, "step": 15000}
{"episode_reward": 896.428906357817, "episode": 16.0, "batch_reward": 0.8261536165475846, "critic_loss": 0.23153079856187106, "actor_loss": -89.18144944763183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.57441020011902, "step": 16000}
{"episode_reward": 925.7546222786017, "episode": 17.0, "batch_reward": 0.8305035861134529, "critic_loss": 0.23168798618763686, "actor_loss": -89.16054563903809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.552064418792725, "step": 17000}
{"episode_reward": 899.5534421502513, "episode": 18.0, "batch_reward": 0.833475497186184, "critic_loss": 0.20635563287883996, "actor_loss": -89.19689059448243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.51002311706543, "step": 18000}
{"episode_reward": 887.5040787784222, "episode": 19.0, "batch_reward": 0.8384254413843155, "critic_loss": 0.1904596856161952, "actor_loss": -89.3342684173584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.563809394836426, "step": 19000}
{"episode_reward": 947.0499459436502, "episode": 20.0, "batch_reward": 0.8447029044032097, "critic_loss": 0.17404476246982814, "actor_loss": -89.40468663024902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.581454515457153, "step": 20000}
{"episode_reward": 955.1607893405708, "episode": 21.0, "batch_reward": 0.851289945781231, "critic_loss": 0.19825890693068504, "actor_loss": -89.7265048828125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.160661458969116, "step": 21000}
{"episode_reward": 930.1337933970133, "episode": 22.0, "batch_reward": 0.8524984351396561, "critic_loss": 0.16865855324268342, "actor_loss": -89.30157127380372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.55820345878601, "step": 22000}
{"episode_reward": 941.5481593318048, "episode": 23.0, "batch_reward": 0.8557603498101234, "critic_loss": 0.18020428351312875, "actor_loss": -89.50805778503418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.58006000518799, "step": 23000}
{"episode_reward": 904.2295488456788, "episode": 24.0, "batch_reward": 0.8586486601233483, "critic_loss": 0.17355037982016802, "actor_loss": -89.48067274475098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.520626306533813, "step": 24000}
{"episode_reward": 940.5188000785224, "episode": 25.0, "batch_reward": 0.8628907812237739, "critic_loss": 0.18198870662599803, "actor_loss": -89.56402098083495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.52826237678528, "step": 25000}
{"episode_reward": 942.9940909647831, "episode": 26.0, "batch_reward": 0.8665245751738548, "critic_loss": 0.15216790165007116, "actor_loss": -89.72712721252441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.52197527885437, "step": 26000}
{"episode_reward": 971.3492972937744, "episode": 27.0, "batch_reward": 0.8703355808258056, "critic_loss": 0.1560820233747363, "actor_loss": -89.99996641540527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.51267695426941, "step": 27000}
{"episode_reward": 975.7088670857902, "episode": 28.0, "batch_reward": 0.8741033365130424, "critic_loss": 0.14934342785179616, "actor_loss": -89.79985009765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.44044256210327, "step": 28000}
{"episode_reward": 961.468987179121, "episode": 29.0, "batch_reward": 0.8768270324468612, "critic_loss": 0.1553047969043255, "actor_loss": -89.97309225463867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.46139621734619, "step": 29000}
{"episode_reward": 938.2396471613998, "episode": 30.0, "batch_reward": 0.876769971370697, "critic_loss": 0.1610929389372468, "actor_loss": -90.20831126403809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.4968318939209, "step": 30000}
{"episode_reward": 856.1029986719269, "episode": 31.0, "batch_reward": 0.8800657131075859, "critic_loss": 0.1571308643221855, "actor_loss": -90.09434225463868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.242950201034546, "step": 31000}
{"episode_reward": 962.587324275092, "episode": 32.0, "batch_reward": 0.8791886587142944, "critic_loss": 0.14514250368624926, "actor_loss": -90.08049934387208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.57187271118164, "step": 32000}
{"episode_reward": 893.9180969911281, "episode": 33.0, "batch_reward": 0.8807528433799744, "critic_loss": 0.15009034326672555, "actor_loss": -89.98426647949219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.603965282440186, "step": 33000}
{"episode_reward": 906.3536694075282, "episode": 34.0, "batch_reward": 0.8827738349437714, "critic_loss": 0.1474745788127184, "actor_loss": -90.39595994567871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.602216958999634, "step": 34000}
{"episode_reward": 961.1832646920133, "episode": 35.0, "batch_reward": 0.884683304131031, "critic_loss": 0.15072471718490124, "actor_loss": -90.14426550292968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.57440972328186, "step": 35000}
{"episode_reward": 911.1289921565219, "episode": 36.0, "batch_reward": 0.8850233781337739, "critic_loss": 0.14976705253869296, "actor_loss": -90.18675303649903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.612102508544922, "step": 36000}
{"episode_reward": 919.6213357911163, "episode": 37.0, "batch_reward": 0.8867061002850533, "critic_loss": 0.14946054657548666, "actor_loss": -90.37266355895996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.600834608078003, "step": 37000}
{"episode_reward": 955.3873631821249, "episode": 38.0, "batch_reward": 0.8889559161067009, "critic_loss": 0.14462798658758402, "actor_loss": -90.39276533508301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.580933809280396, "step": 38000}
{"episode_reward": 957.7266093503309, "episode": 39.0, "batch_reward": 0.8894189341664315, "critic_loss": 0.16217546926811338, "actor_loss": -90.42144604492188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.585479259490967, "step": 39000}
{"episode_reward": 960.4380040071595, "episode": 40.0, "batch_reward": 0.8919846971035004, "critic_loss": 0.1565563900321722, "actor_loss": -90.66664329528808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.6009418964386, "step": 40000}
{"episode_reward": 969.3106963159072, "episode": 41.0, "batch_reward": 0.8940621107816696, "critic_loss": 0.16198235297203065, "actor_loss": -91.13724971008301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.22283172607422, "step": 41000}
{"episode_reward": 958.1257936340622, "episode": 42.0, "batch_reward": 0.8955688672065735, "critic_loss": 0.16894330945611, "actor_loss": -90.82955429077148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.57260775566101, "step": 42000}
{"episode_reward": 958.2449832708927, "episode": 43.0, "batch_reward": 0.8969294481277466, "critic_loss": 0.18515569262951612, "actor_loss": -90.81936741638184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.593082904815674, "step": 43000}
{"episode_reward": 973.7858261298547, "episode": 44.0, "batch_reward": 0.8991777084469795, "critic_loss": 0.1668368608728051, "actor_loss": -90.70632022094726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.610987901687622, "step": 44000}
{"episode_reward": 965.2038544200803, "episode": 45.0, "batch_reward": 0.9002524929046631, "critic_loss": 0.23701088098436593, "actor_loss": -90.77471537780762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.536237001419067, "step": 45000}
{"episode_reward": 975.8305088226057, "episode": 46.0, "batch_reward": 0.9013692743182182, "critic_loss": 0.32191962661594153, "actor_loss": -91.29054144287109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.624956846237183, "step": 46000}
{"episode_reward": 947.7548247541928, "episode": 47.0, "batch_reward": 0.9022975953221322, "critic_loss": 0.5804580328464508, "actor_loss": -91.23917993164062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.595158338546753, "step": 47000}
{"episode_reward": 837.3673427290432, "episode": 48.0, "batch_reward": 0.8996450594067573, "critic_loss": 0.7207811859995127, "actor_loss": -91.03929954528809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.522172451019287, "step": 48000}
{"episode_reward": 808.5151367268323, "episode": 49.0, "batch_reward": 0.8979381895661354, "critic_loss": 0.6046510910093784, "actor_loss": -91.11886010742188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.549135208129883, "step": 49000}
{"episode_reward": 874.2879838228158, "episode": 50.0, "batch_reward": 0.8981582183837891, "critic_loss": 0.8237766789495945, "actor_loss": -91.67428553771973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.56603693962097, "step": 50000}
{"episode_reward": 908.7009912838979, "episode": 51.0, "batch_reward": 0.8985841799974441, "critic_loss": 0.8285641676187515, "actor_loss": -92.10044812011719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.310930252075195, "step": 51000}
{"episode_reward": 894.7804308007894, "episode": 52.0, "batch_reward": 0.8978502961993218, "critic_loss": 0.5611495547443628, "actor_loss": -92.27536428833008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.595789670944214, "step": 52000}
{"episode_reward": 858.6195069567711, "episode": 53.0, "batch_reward": 0.8974357708692551, "critic_loss": 0.9562193857133389, "actor_loss": -91.82939190673828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.57814884185791, "step": 53000}
{"episode_reward": 935.9281861547048, "episode": 54.0, "batch_reward": 0.898999509871006, "critic_loss": 0.9388678507208824, "actor_loss": -92.19942472839355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.564512729644775, "step": 54000}
{"episode_reward": 937.6250082756603, "episode": 55.0, "batch_reward": 0.8982623026371003, "critic_loss": 1.0609580990821124, "actor_loss": -92.15708145141602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.54482078552246, "step": 55000}
{"episode_reward": 919.5228663400837, "episode": 56.0, "batch_reward": 0.8998752065300941, "critic_loss": 1.425186687722802, "actor_loss": -92.47212971496582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.568320989608765, "step": 56000}
{"episode_reward": 963.3631715015433, "episode": 57.0, "batch_reward": 0.9015940254926682, "critic_loss": 1.9207511015832424, "actor_loss": -92.53891119384765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.521133422851562, "step": 57000}
{"episode_reward": 949.2449927002159, "episode": 58.0, "batch_reward": 0.9002818070054054, "critic_loss": 4.2833344595134255, "actor_loss": -92.62484580993652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.52639651298523, "step": 58000}
{"episode_reward": 936.1893601220261, "episode": 59.0, "batch_reward": 0.897925372004509, "critic_loss": 9.028846063196658, "actor_loss": -93.51127993774413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.48891806602478, "step": 59000}
{"episode_reward": 494.0303164006555, "episode": 60.0, "batch_reward": 0.8938101383447647, "critic_loss": 10.669019181609153, "actor_loss": -94.41341076660156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.488138675689697, "step": 60000}
{"episode_reward": 556.755863743328, "episode": 61.0, "batch_reward": 0.8848389382362366, "critic_loss": 13.69038155555725, "actor_loss": -95.99252748107911, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.18776750564575, "step": 61000}
{"episode_reward": 414.5740165744561, "episode": 62.0, "batch_reward": 0.8807969719171524, "critic_loss": 12.30684512603283, "actor_loss": -96.36774374389648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.78446054458618, "step": 62000}
{"episode_reward": 740.0349670008065, "episode": 63.0, "batch_reward": 0.8780528458952904, "critic_loss": 10.333566237926483, "actor_loss": -98.62343161010742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.565913438796997, "step": 63000}
{"episode_reward": 742.8141355634887, "episode": 64.0, "batch_reward": 0.8749963124394416, "critic_loss": 11.362329997301101, "actor_loss": -99.66732940673828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.591013193130493, "step": 64000}
{"episode_reward": 527.5060722041048, "episode": 65.0, "batch_reward": 0.8675198335051536, "critic_loss": 15.830454786777496, "actor_loss": -102.56790660095214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.625981330871582, "step": 65000}
{"episode_reward": 357.45757704863144, "episode": 66.0, "batch_reward": 0.8584142495393753, "critic_loss": 18.160877270936965, "actor_loss": -104.67038023376465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.620990753173828, "step": 66000}
{"episode_reward": 131.08031339448, "episode": 67.0, "batch_reward": 0.8461055399775506, "critic_loss": 17.88886473560333, "actor_loss": -105.5320320739746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.62261199951172, "step": 67000}
{"episode_reward": 36.668092304617595, "episode": 68.0, "batch_reward": 0.8346074023246766, "critic_loss": 17.592426501750946, "actor_loss": -111.0238231048584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.646300315856934, "step": 68000}
{"episode_reward": 42.09441606622759, "episode": 69.0, "batch_reward": 0.8219216158986091, "critic_loss": 18.470118637561797, "actor_loss": -119.8063309020996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.609769821166992, "step": 69000}
{"episode_reward": 36.72180197603895, "episode": 70.0, "batch_reward": 0.812094438135624, "critic_loss": 19.00703932905197, "actor_loss": -124.33299923706055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60060405731201, "step": 70000}
{"episode_reward": 67.9331611386715, "episode": 71.0, "batch_reward": 0.8017985223531723, "critic_loss": 19.106828833580018, "actor_loss": -132.52828132629395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.63893461227417, "step": 71000}
{"episode_reward": 32.33686489392067, "episode": 72.0, "batch_reward": 0.7910058237314225, "critic_loss": 19.002309000968932, "actor_loss": -141.92312948608398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.66068410873413, "step": 72000}
{"episode_reward": 69.74236862965368, "episode": 73.0, "batch_reward": 0.7809183362722397, "critic_loss": 18.218018916130067, "actor_loss": -146.90414022827147, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.588467597961426, "step": 73000}
{"episode_reward": 27.36138708141225, "episode": 74.0, "batch_reward": 0.7712772179841996, "critic_loss": 16.84466693210602, "actor_loss": -152.12649644470216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.594475030899048, "step": 74000}
{"episode_reward": 44.92408813541351, "episode": 75.0, "batch_reward": 0.7621149356365204, "critic_loss": 15.950598910808564, "actor_loss": -160.53600944519042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.671428203582764, "step": 75000}
{"episode_reward": 48.95637624285948, "episode": 76.0, "batch_reward": 0.7510563155412674, "critic_loss": 14.899939510345458, "actor_loss": -165.05199884033203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.56283450126648, "step": 76000}
{"episode_reward": 44.106436092637246, "episode": 77.0, "batch_reward": 0.7416753606796265, "critic_loss": 15.009743968963623, "actor_loss": -164.19284147644044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.619946718215942, "step": 77000}
{"episode_reward": 32.308285821220764, "episode": 78.0, "batch_reward": 0.7324259888529777, "critic_loss": 15.447287149906158, "actor_loss": -170.2109722595215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.63052773475647, "step": 78000}
{"episode_reward": 45.460014076190504, "episode": 79.0, "batch_reward": 0.7243476437330246, "critic_loss": 15.145383783340455, "actor_loss": -165.65783869934083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.55268120765686, "step": 79000}
{"episode_reward": 39.885535389576546, "episode": 80.0, "batch_reward": 0.7183515971899033, "critic_loss": 13.021503293514252, "actor_loss": -163.39368699645996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.606357097625732, "step": 80000}
{"episode_reward": 11.026297670515278, "episode": 81.0, "batch_reward": 0.7063005257844925, "critic_loss": 11.326435928344727, "actor_loss": -161.98437477111815, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.75743508338928, "step": 81000}
{"episode_reward": 11.641170938036103, "episode": 82.0, "batch_reward": 0.6983606786727905, "critic_loss": 10.063299770832062, "actor_loss": -167.5349204864502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.627153158187866, "step": 82000}
{"episode_reward": 75.02886660933186, "episode": 83.0, "batch_reward": 0.6915402588844299, "critic_loss": 8.754197230100631, "actor_loss": -160.59990365600586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.62217950820923, "step": 83000}
{"episode_reward": 58.183774056772734, "episode": 84.0, "batch_reward": 0.6831581939458847, "critic_loss": 7.305835687637329, "actor_loss": -158.93433967590332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5914945602417, "step": 84000}
{"episode_reward": 70.64495081195618, "episode": 85.0, "batch_reward": 0.6773402614593506, "critic_loss": 6.342320413827896, "actor_loss": -159.49339526367189, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.600297927856445, "step": 85000}
{"episode_reward": 70.81263219780371, "episode": 86.0, "batch_reward": 0.6698441556692123, "critic_loss": 5.787243684530258, "actor_loss": -154.8783064880371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.549817085266113, "step": 86000}
{"episode_reward": 680.0135711613622, "episode": 87.0, "batch_reward": 0.6731999702453614, "critic_loss": 4.89461656165123, "actor_loss": -150.80243145751953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.57424831390381, "step": 87000}
{"episode_reward": 808.0787776407066, "episode": 88.0, "batch_reward": 0.677540080845356, "critic_loss": 4.498795888662338, "actor_loss": -149.2579375152588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.761335134506226, "step": 88000}
{"episode_reward": 915.7525993625876, "episode": 89.0, "batch_reward": 0.6771231878995896, "critic_loss": 4.054877429962159, "actor_loss": -152.00582676696777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.50903558731079, "step": 89000}
{"episode_reward": 873.7619070181864, "episode": 90.0, "batch_reward": 0.6794873705506325, "critic_loss": 3.592530490040779, "actor_loss": -149.39719737243652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.45019030570984, "step": 90000}
{"episode_reward": 771.6102066444264, "episode": 91.0, "batch_reward": 0.6824636132717132, "critic_loss": 3.0951914722919462, "actor_loss": -147.9367292022705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.15813088417053, "step": 91000}
{"episode_reward": 950.372057187896, "episode": 92.0, "batch_reward": 0.682593533039093, "critic_loss": 2.8636077641248705, "actor_loss": -141.38997328186036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.671576499938965, "step": 92000}
{"episode_reward": 873.1660151965016, "episode": 93.0, "batch_reward": 0.6856191295385361, "critic_loss": 2.677583378434181, "actor_loss": -143.274304977417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.860576391220093, "step": 93000}
{"episode_reward": 917.6319545607281, "episode": 94.0, "batch_reward": 0.6878492366075516, "critic_loss": 2.2884068896770478, "actor_loss": -138.07506686401368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.61386489868164, "step": 94000}
{"episode_reward": 900.0393279694142, "episode": 95.0, "batch_reward": 0.691726225733757, "critic_loss": 2.170747360646725, "actor_loss": -132.53166149902344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.621692419052124, "step": 95000}
{"episode_reward": 937.3866871989055, "episode": 96.0, "batch_reward": 0.6917927826046943, "critic_loss": 1.94345206874609, "actor_loss": -135.29454972839355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.6161892414093, "step": 96000}
{"episode_reward": 928.5135308103262, "episode": 97.0, "batch_reward": 0.696388373374939, "critic_loss": 1.7517334250211716, "actor_loss": -133.73491429138184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.58877658843994, "step": 97000}
{"episode_reward": 971.0196355011109, "episode": 98.0, "batch_reward": 0.69915856975317, "critic_loss": 1.6005102083086968, "actor_loss": -125.95311253356934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60321044921875, "step": 98000}
{"episode_reward": 959.9697559748754, "episode": 99.0, "batch_reward": 0.7022040744423866, "critic_loss": 1.5301600954532624, "actor_loss": -127.46145484924317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.601517915725708, "step": 99000}
{"episode_reward": 973.7046150291179, "episode": 100.0, "batch_reward": 0.7030383545160294, "critic_loss": 1.5053359712362289, "actor_loss": -123.9570496673584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.56999659538269, "step": 100000}
{"episode_reward": 972.9684086034197, "episode": 101.0, "batch_reward": 0.7085011592507362, "critic_loss": 1.57132302236557, "actor_loss": -125.96609399414062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.12640953063965, "step": 101000}
{"episode_reward": 962.320782237187, "episode": 102.0, "batch_reward": 0.713496773481369, "critic_loss": 1.387675189614296, "actor_loss": -121.58656503295899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.57455277442932, "step": 102000}
{"episode_reward": 975.7698452238956, "episode": 103.0, "batch_reward": 0.7134611046910286, "critic_loss": 1.4990633669495583, "actor_loss": -120.35993923950195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.618088722229004, "step": 103000}
{"episode_reward": 962.3681824698406, "episode": 104.0, "batch_reward": 0.7146950094103813, "critic_loss": 1.5308376665115357, "actor_loss": -121.2683451385498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.572536945343018, "step": 104000}
{"episode_reward": 951.7093874085498, "episode": 105.0, "batch_reward": 0.7166813394427299, "critic_loss": 1.5982927312850952, "actor_loss": -118.87066413879394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.58261251449585, "step": 105000}
{"episode_reward": 953.3845288825623, "episode": 106.0, "batch_reward": 0.7183881230950355, "critic_loss": 1.922300810098648, "actor_loss": -117.98175622558594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.600481033325195, "step": 106000}
{"episode_reward": 953.3543955890154, "episode": 107.0, "batch_reward": 0.7206666706800461, "critic_loss": 2.3618725938796996, "actor_loss": -118.5518999633789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.531731128692627, "step": 107000}
{"episode_reward": 950.7568650753226, "episode": 108.0, "batch_reward": 0.7249731760025024, "critic_loss": 2.391220190525055, "actor_loss": -114.27370712280273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.59697151184082, "step": 108000}
{"episode_reward": 913.357271022314, "episode": 109.0, "batch_reward": 0.7252182089686394, "critic_loss": 2.637669349372387, "actor_loss": -116.61018237304687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.56654930114746, "step": 109000}
{"episode_reward": 835.7713898439534, "episode": 110.0, "batch_reward": 0.7241967323422432, "critic_loss": 4.223869674384594, "actor_loss": -112.85259606933593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.493083953857422, "step": 110000}
{"episode_reward": 837.1996563906162, "episode": 111.0, "batch_reward": 0.727778264939785, "critic_loss": 4.130252765953541, "actor_loss": -114.55350544738769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.17691898345947, "step": 111000}
{"episode_reward": 910.3515083509335, "episode": 112.0, "batch_reward": 0.7295239861011505, "critic_loss": 4.518221484601498, "actor_loss": -112.20797648620605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.59055733680725, "step": 112000}
{"episode_reward": 948.163385067499, "episode": 113.0, "batch_reward": 0.7307429651618004, "critic_loss": 4.449938791930675, "actor_loss": -114.82497142028808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.560248136520386, "step": 113000}
{"episode_reward": 810.2383657989662, "episode": 114.0, "batch_reward": 0.7324419672489166, "critic_loss": 4.442175675034523, "actor_loss": -111.34786218261719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.58339262008667, "step": 114000}
{"episode_reward": 951.0204702533107, "episode": 115.0, "batch_reward": 0.7325106720328332, "critic_loss": 5.241228628635406, "actor_loss": -110.99399234008789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.54427456855774, "step": 115000}
{"episode_reward": 787.75031425359, "episode": 116.0, "batch_reward": 0.7301322957873344, "critic_loss": 5.414064561963081, "actor_loss": -111.46928323364259, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.565593957901, "step": 116000}
{"episode_reward": 101.76818021734785, "episode": 117.0, "batch_reward": 0.7251793028712272, "critic_loss": 5.3640660458803175, "actor_loss": -112.90302584838867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.57096004486084, "step": 117000}
{"episode_reward": 89.33888327342534, "episode": 118.0, "batch_reward": 0.718241839647293, "critic_loss": 5.215991999030114, "actor_loss": -113.25322402954102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.56973648071289, "step": 118000}
{"episode_reward": 26.488951227515965, "episode": 119.0, "batch_reward": 0.7131489384770393, "critic_loss": 5.1174270844459535, "actor_loss": -115.1756199645996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.529803037643433, "step": 119000}
{"episode_reward": 193.1894175795099, "episode": 120.0, "batch_reward": 0.7097703114748001, "critic_loss": 5.205002852678299, "actor_loss": -117.98952709960938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.52832055091858, "step": 120000}
{"episode_reward": 118.02420127615463, "episode": 121.0, "batch_reward": 0.7076087582707405, "critic_loss": 4.857533128023148, "actor_loss": -121.39206967163086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.45701050758362, "step": 121000}
{"episode_reward": 174.8776380241823, "episode": 122.0, "batch_reward": 0.702885349214077, "critic_loss": 4.975969075560569, "actor_loss": -118.20439324951172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.507210969924927, "step": 122000}
{"episode_reward": 194.60000038407105, "episode": 123.0, "batch_reward": 0.6958808272480964, "critic_loss": 4.582003651976585, "actor_loss": -120.77098527526856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.480030298233032, "step": 123000}
{"episode_reward": 197.85387291892508, "episode": 124.0, "batch_reward": 0.6934275841712951, "critic_loss": 4.0501399829387665, "actor_loss": -120.55762915039062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.943832397460938, "step": 124000}
{"episode_reward": 183.06584059940695, "episode": 125.0, "batch_reward": 0.6885966428518295, "critic_loss": 3.7146460713148115, "actor_loss": -120.86609748840333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.489219427108765, "step": 125000}
{"episode_reward": 299.43313260979835, "episode": 126.0, "batch_reward": 0.6845262178182602, "critic_loss": 3.3321104106903077, "actor_loss": -120.00878820800781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.605169534683228, "step": 126000}
{"episode_reward": 387.99695927868896, "episode": 127.0, "batch_reward": 0.6839691600203515, "critic_loss": 2.996285607099533, "actor_loss": -117.28344938659669, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.63996148109436, "step": 127000}
{"episode_reward": 365.54342793488007, "episode": 128.0, "batch_reward": 0.6796733332872391, "critic_loss": 2.736033511042595, "actor_loss": -119.0073599395752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.633615016937256, "step": 128000}
{"episode_reward": 137.86647254632834, "episode": 129.0, "batch_reward": 0.6757782887220383, "critic_loss": 2.446789458870888, "actor_loss": -118.17231896972656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.595879077911377, "step": 129000}
{"episode_reward": 447.87561822138565, "episode": 130.0, "batch_reward": 0.6763314155340194, "critic_loss": 2.214654566824436, "actor_loss": -117.99588581848144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.595874071121216, "step": 130000}
{"episode_reward": 615.3847205127673, "episode": 131.0, "batch_reward": 0.6753275359272957, "critic_loss": 2.040095175564289, "actor_loss": -117.20739933776855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.260538816452026, "step": 131000}
{"episode_reward": 802.2921043548798, "episode": 132.0, "batch_reward": 0.6766577415466308, "critic_loss": 1.8881806045770646, "actor_loss": -115.971269241333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.589357137680054, "step": 132000}
{"episode_reward": 871.4910045220736, "episode": 133.0, "batch_reward": 0.6780807522535324, "critic_loss": 1.8609955711364745, "actor_loss": -118.29629768371582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.560214281082153, "step": 133000}
{"episode_reward": 966.3717128584152, "episode": 134.0, "batch_reward": 0.6817049444913864, "critic_loss": 1.5212155776023866, "actor_loss": -114.1329455871582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.625281810760498, "step": 134000}
{"episode_reward": 956.4847767872282, "episode": 135.0, "batch_reward": 0.6814952268600464, "critic_loss": 1.3199136415719985, "actor_loss": -111.56073963928223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.582156658172607, "step": 135000}
{"episode_reward": 853.2996582785402, "episode": 136.0, "batch_reward": 0.6848039492368698, "critic_loss": 1.2140548263192177, "actor_loss": -111.1650252532959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.548418760299683, "step": 136000}
{"episode_reward": 898.6498797887597, "episode": 137.0, "batch_reward": 0.6864551931619645, "critic_loss": 1.1022937155365944, "actor_loss": -109.83670152282716, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.62731432914734, "step": 137000}
{"episode_reward": 878.0098939622617, "episode": 138.0, "batch_reward": 0.6888701000213623, "critic_loss": 1.0224208304584026, "actor_loss": -109.91956018066406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.570805072784424, "step": 138000}
{"episode_reward": 953.076623568689, "episode": 139.0, "batch_reward": 0.6873344061374664, "critic_loss": 0.9577642931342125, "actor_loss": -108.62410482788086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.542539596557617, "step": 139000}
{"episode_reward": 877.0922827827386, "episode": 140.0, "batch_reward": 0.6909600962996483, "critic_loss": 0.8977461263239384, "actor_loss": -107.96600929260254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.584306001663208, "step": 140000}
{"episode_reward": 949.3839756852024, "episode": 141.0, "batch_reward": 0.6930152594447135, "critic_loss": 0.8715206669270992, "actor_loss": -105.30791064453125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.23279285430908, "step": 141000}
{"episode_reward": 937.4253204526966, "episode": 142.0, "batch_reward": 0.6928525235652924, "critic_loss": 0.8227416569590569, "actor_loss": -105.48485433959961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.451628923416138, "step": 142000}
{"episode_reward": 951.3084912490754, "episode": 143.0, "batch_reward": 0.6945477756261825, "critic_loss": 0.8143608917891979, "actor_loss": -104.97340237426758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5909640789032, "step": 143000}
{"episode_reward": 591.9715877937476, "episode": 144.0, "batch_reward": 0.6956674446463584, "critic_loss": 0.7627323474287987, "actor_loss": -103.7157790222168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.770523071289062, "step": 144000}
{"episode_reward": 942.059254637564, "episode": 145.0, "batch_reward": 0.6961407980322838, "critic_loss": 0.7349015659689904, "actor_loss": -102.50221243286133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.55714726448059, "step": 145000}
{"episode_reward": 948.5765796458048, "episode": 146.0, "batch_reward": 0.6965445961356163, "critic_loss": 0.7120965000987053, "actor_loss": -103.03971003723144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.510785818099976, "step": 146000}
{"episode_reward": 893.5999671004622, "episode": 147.0, "batch_reward": 0.7012617098093032, "critic_loss": 0.7146058048605919, "actor_loss": -101.91946711730957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.551706314086914, "step": 147000}
{"episode_reward": 949.9759110268413, "episode": 148.0, "batch_reward": 0.7016741554737091, "critic_loss": 0.7497088420391083, "actor_loss": -101.07792337036133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.542544841766357, "step": 148000}
{"episode_reward": 936.4381330154231, "episode": 149.0, "batch_reward": 0.7030643174648284, "critic_loss": 0.6637167265415191, "actor_loss": -99.88630184936524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.520859479904175, "step": 149000}
{"episode_reward": 893.5206136602694, "episode": 150.0, "batch_reward": 0.7048464434146882, "critic_loss": 0.6571489448845387, "actor_loss": -98.2459370880127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
