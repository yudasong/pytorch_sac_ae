{"episode_reward": 0.0, "episode": 1.0, "duration": 21.2341628074646, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.8915948867797852, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.4283247899814382, "critic_loss": 0.13793028485298245, "actor_loss": -56.460582424786644, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 62.568076848983765, "step": 3000}
{"episode_reward": 254.76001055041814, "episode": 4.0, "batch_reward": 0.3440724957883358, "critic_loss": 0.2688258822187781, "actor_loss": -52.2726487083435, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.209882020950317, "step": 4000}
{"episode_reward": 88.40294431792985, "episode": 5.0, "batch_reward": 0.27414981746673583, "critic_loss": 0.2996592268943787, "actor_loss": -49.68502179908752, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.40052032470703, "step": 5000}
{"episode_reward": 23.72039348219738, "episode": 6.0, "batch_reward": 0.23941964925825596, "critic_loss": 0.40513347412645817, "actor_loss": -50.6625536403656, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.41830801963806, "step": 6000}
{"episode_reward": 195.3645562914326, "episode": 7.0, "batch_reward": 0.2381472820043564, "critic_loss": 0.6292617413401603, "actor_loss": -50.11299554347992, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.331254959106445, "step": 7000}
{"episode_reward": 268.4768557338253, "episode": 8.0, "batch_reward": 0.2382066997885704, "critic_loss": 0.9556840754449367, "actor_loss": -51.17274113082886, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.41110873222351, "step": 8000}
{"episode_reward": 221.76436906912286, "episode": 9.0, "batch_reward": 0.2447070438414812, "critic_loss": 1.4306508716344832, "actor_loss": -51.64803621864319, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.5701425075531, "step": 9000}
{"episode_reward": 423.1303125679505, "episode": 10.0, "batch_reward": 0.2812468315511942, "critic_loss": 1.8418262951374054, "actor_loss": -55.16964298439026, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.380175352096558, "step": 10000}
{"episode_reward": 588.9269558269541, "episode": 11.0, "batch_reward": 0.3026586702615023, "critic_loss": 2.1070913608074187, "actor_loss": -54.972083169937136, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.60612416267395, "step": 11000}
{"episode_reward": 485.8244595897233, "episode": 12.0, "batch_reward": 0.3194892023205757, "critic_loss": 2.6085818626880646, "actor_loss": -57.10191774749756, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.05040216445923, "step": 12000}
{"episode_reward": 534.5741703027911, "episode": 13.0, "batch_reward": 0.34720779085159303, "critic_loss": 2.700778632760048, "actor_loss": -57.92371043014526, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.622901678085327, "step": 13000}
{"episode_reward": 816.6237914491653, "episode": 14.0, "batch_reward": 0.3789036731123924, "critic_loss": 2.5187528132200243, "actor_loss": -59.48143407821655, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.56144380569458, "step": 14000}
{"episode_reward": 824.054343981154, "episode": 15.0, "batch_reward": 0.4083654392361641, "critic_loss": 2.430260022878647, "actor_loss": -61.58540930938721, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.483805179595947, "step": 15000}
{"episode_reward": 762.0364897432603, "episode": 16.0, "batch_reward": 0.4314254612624645, "critic_loss": 2.256894154906273, "actor_loss": -63.85993622970581, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.63063359260559, "step": 16000}
{"episode_reward": 691.9839556860063, "episode": 17.0, "batch_reward": 0.45039538541436197, "critic_loss": 2.033010656952858, "actor_loss": -63.27908179473877, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.110344648361206, "step": 17000}
{"episode_reward": 832.9286137610115, "episode": 18.0, "batch_reward": 0.47255530244112015, "critic_loss": 1.9078277423381806, "actor_loss": -64.98809742736816, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.693952322006226, "step": 18000}
{"episode_reward": 828.0720845403524, "episode": 19.0, "batch_reward": 0.4874680531024933, "critic_loss": 1.993568667292595, "actor_loss": -65.79246630096435, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.616488456726074, "step": 19000}
{"episode_reward": 702.6329802620127, "episode": 20.0, "batch_reward": 0.5055626671612262, "critic_loss": 1.9913016256093978, "actor_loss": -68.272299659729, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.729008436203003, "step": 20000}
{"episode_reward": 921.2380041209851, "episode": 21.0, "batch_reward": 0.5262712699770927, "critic_loss": 1.90265680539608, "actor_loss": -67.28798048400878, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.725364446640015, "step": 21000}
{"episode_reward": 892.055745161917, "episode": 22.0, "batch_reward": 0.5414451441168785, "critic_loss": 1.8456157857179643, "actor_loss": -69.27640165710449, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.583030939102173, "step": 22000}
{"episode_reward": 915.9147893621445, "episode": 23.0, "batch_reward": 0.5561136030554772, "critic_loss": 1.838096764922142, "actor_loss": -69.20639635467529, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.755525827407837, "step": 23000}
{"episode_reward": 804.1700429432033, "episode": 24.0, "batch_reward": 0.5690096858739853, "critic_loss": 1.7520913400650024, "actor_loss": -70.60155787658691, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.594998121261597, "step": 24000}
{"episode_reward": 942.4771848779603, "episode": 25.0, "batch_reward": 0.5858935518860817, "critic_loss": 1.670686519742012, "actor_loss": -71.91567058563233, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.72437334060669, "step": 25000}
{"episode_reward": 926.3840842548426, "episode": 26.0, "batch_reward": 0.5975536121726036, "critic_loss": 1.6027513912916183, "actor_loss": -71.59800514984131, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.569250106811523, "step": 26000}
{"episode_reward": 948.6046761751252, "episode": 27.0, "batch_reward": 0.6121082015037537, "critic_loss": 1.541785815536976, "actor_loss": -72.28730611419678, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.355837106704712, "step": 27000}
{"episode_reward": 935.3443937261499, "episode": 28.0, "batch_reward": 0.6241112221181393, "critic_loss": 1.5799382601976395, "actor_loss": -72.71170293426513, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.512837648391724, "step": 28000}
{"episode_reward": 898.5520737447279, "episode": 29.0, "batch_reward": 0.6298928712010383, "critic_loss": 1.522267849802971, "actor_loss": -73.39673911285401, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.886247634887695, "step": 29000}
{"episode_reward": 856.7643578912374, "episode": 30.0, "batch_reward": 0.6394630857110023, "critic_loss": 1.5454795226454734, "actor_loss": -73.66945344543457, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.37617325782776, "step": 30000}
{"episode_reward": 802.7992995055687, "episode": 31.0, "batch_reward": 0.6461800116896629, "critic_loss": 1.4528634281754493, "actor_loss": -73.96943267059326, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.440067529678345, "step": 31000}
{"episode_reward": 911.8521197239946, "episode": 32.0, "batch_reward": 0.6544781734347344, "critic_loss": 1.386950435400009, "actor_loss": -74.58354151916504, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.328969478607178, "step": 32000}
{"episode_reward": 890.3776918552467, "episode": 33.0, "batch_reward": 0.6602631449699402, "critic_loss": 1.463682965695858, "actor_loss": -75.14575503540038, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.98827600479126, "step": 33000}
{"episode_reward": 853.0281000839336, "episode": 34.0, "batch_reward": 0.6681186195611953, "critic_loss": 1.3605382086634636, "actor_loss": -75.54284909820556, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.498759746551514, "step": 34000}
{"episode_reward": 950.7690314940369, "episode": 35.0, "batch_reward": 0.6769986796379089, "critic_loss": 1.326045705139637, "actor_loss": -76.10132828521729, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.36232590675354, "step": 35000}
{"episode_reward": 896.1825164763693, "episode": 36.0, "batch_reward": 0.6814651795625687, "critic_loss": 1.3395459170341493, "actor_loss": -76.87828455352783, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.110089778900146, "step": 36000}
{"episode_reward": 836.0696319924938, "episode": 37.0, "batch_reward": 0.6872127308249474, "critic_loss": 1.3363013122081757, "actor_loss": -76.28554721069337, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.518639087677002, "step": 37000}
{"episode_reward": 947.1795481368032, "episode": 38.0, "batch_reward": 0.6933593868017197, "critic_loss": 1.2856484779715538, "actor_loss": -76.27571012115479, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.352419137954712, "step": 38000}
{"episode_reward": 942.5057495288028, "episode": 39.0, "batch_reward": 0.6990771874785423, "critic_loss": 1.2664686346650122, "actor_loss": -77.0034624710083, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.189344882965088, "step": 39000}
{"episode_reward": 920.0960791058194, "episode": 40.0, "batch_reward": 0.7059552418589592, "critic_loss": 1.1752474662065506, "actor_loss": -77.55279417419433, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.467416048049927, "step": 40000}
{"episode_reward": 954.2794529752707, "episode": 41.0, "batch_reward": 0.710188742518425, "critic_loss": 1.1792112001776696, "actor_loss": -77.6043595123291, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.285194635391235, "step": 41000}
{"episode_reward": 901.9134269260563, "episode": 42.0, "batch_reward": 0.714875648200512, "critic_loss": 1.0899246311187745, "actor_loss": -77.90082579040528, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.24631690979004, "step": 42000}
{"episode_reward": 881.3800914405856, "episode": 43.0, "batch_reward": 0.7187113877534866, "critic_loss": 1.0678003039956092, "actor_loss": -78.23746731567383, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.56823229789734, "step": 43000}
{"episode_reward": 931.8485177396655, "episode": 44.0, "batch_reward": 0.7237750154137611, "critic_loss": 1.0624671318531036, "actor_loss": -79.41736720275878, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.67158055305481, "step": 44000}
{"episode_reward": 939.3006663353127, "episode": 45.0, "batch_reward": 0.7301362026333809, "critic_loss": 1.0150555963814258, "actor_loss": -79.2251734008789, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.124885320663452, "step": 45000}
{"episode_reward": 941.888961642135, "episode": 46.0, "batch_reward": 0.7326994997859001, "critic_loss": 1.0100678548514843, "actor_loss": -78.7952879486084, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.34200668334961, "step": 46000}
{"episode_reward": 916.6380623261178, "episode": 47.0, "batch_reward": 0.7373315936923027, "critic_loss": 0.9815094212889671, "actor_loss": -79.30200276184082, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.906156539916992, "step": 47000}
{"episode_reward": 880.1479370453051, "episode": 48.0, "batch_reward": 0.7412449164986611, "critic_loss": 0.9598411489129066, "actor_loss": -79.40357246398926, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.329310178756714, "step": 48000}
{"episode_reward": 923.8131171389775, "episode": 49.0, "batch_reward": 0.745060587644577, "critic_loss": 0.9199138543009758, "actor_loss": -80.1438384399414, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.45658230781555, "step": 49000}
{"episode_reward": 846.8462943248497, "episode": 50.0, "batch_reward": 0.7441946271657943, "critic_loss": 0.9778923248648643, "actor_loss": -79.82231951904296, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.854493141174316, "step": 50000}
{"episode_reward": 804.413660000313, "episode": 51.0, "batch_reward": 0.7481820361018181, "critic_loss": 0.962288742005825, "actor_loss": -79.94766781616211, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.87509107589722, "step": 51000}
{"episode_reward": 932.1007273037269, "episode": 52.0, "batch_reward": 0.7515626266002655, "critic_loss": 1.0090708276033402, "actor_loss": -79.97975544738769, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.48491334915161, "step": 52000}
{"episode_reward": 773.7034909590609, "episode": 53.0, "batch_reward": 0.7505673964619637, "critic_loss": 1.1201366328597069, "actor_loss": -80.29497319030762, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.807802200317383, "step": 53000}
{"episode_reward": 920.6812533442286, "episode": 54.0, "batch_reward": 0.7566032950878143, "critic_loss": 1.0743379672467708, "actor_loss": -80.74213409423828, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.373083353042603, "step": 54000}
{"episode_reward": 933.1892556391304, "episode": 55.0, "batch_reward": 0.7572665184736251, "critic_loss": 1.0712810904979706, "actor_loss": -80.52757901000976, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.482588529586792, "step": 55000}
{"episode_reward": 934.9235219564382, "episode": 56.0, "batch_reward": 0.7613167674541473, "critic_loss": 1.0350244147777556, "actor_loss": -80.62214315795899, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.482688903808594, "step": 56000}
{"episode_reward": 949.4686440244222, "episode": 57.0, "batch_reward": 0.765162006855011, "critic_loss": 1.0027645736634732, "actor_loss": -80.7381103363037, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.347570180892944, "step": 57000}
{"episode_reward": 918.7877854845639, "episode": 58.0, "batch_reward": 0.7662381889224053, "critic_loss": 1.0232875341773033, "actor_loss": -80.82608958435058, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.673591375350952, "step": 58000}
{"episode_reward": 901.994173770433, "episode": 59.0, "batch_reward": 0.7700774844884872, "critic_loss": 0.9953954304456711, "actor_loss": -80.8735689239502, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.475067853927612, "step": 59000}
{"episode_reward": 956.4863605744907, "episode": 60.0, "batch_reward": 0.7730642327070236, "critic_loss": 1.0104998548328876, "actor_loss": -81.2811374206543, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.584819793701172, "step": 60000}
{"episode_reward": 930.5478895140959, "episode": 61.0, "batch_reward": 0.7756753764748573, "critic_loss": 0.9441557009816169, "actor_loss": -81.27673733520508, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.44836378097534, "step": 61000}
{"episode_reward": 914.273760268769, "episode": 62.0, "batch_reward": 0.7793371060490608, "critic_loss": 1.008517938733101, "actor_loss": -81.49930813598633, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.457225561141968, "step": 62000}
{"episode_reward": 919.9189161374159, "episode": 63.0, "batch_reward": 0.780249292075634, "critic_loss": 0.9121327892839909, "actor_loss": -81.62645906066895, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.360151052474976, "step": 63000}
{"episode_reward": 941.9641407984511, "episode": 64.0, "batch_reward": 0.7820857965350151, "critic_loss": 0.8708400737345219, "actor_loss": -81.67722930908204, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.933385372161865, "step": 64000}
{"episode_reward": 897.0212623079334, "episode": 65.0, "batch_reward": 0.78477065128088, "critic_loss": 0.9024759097397328, "actor_loss": -81.71442620849609, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.356900930404663, "step": 65000}
{"episode_reward": 943.7562034937731, "episode": 66.0, "batch_reward": 0.7856930368542672, "critic_loss": 0.8903066567778587, "actor_loss": -81.8693469543457, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.58315086364746, "step": 66000}
{"episode_reward": 881.3322374875132, "episode": 67.0, "batch_reward": 0.7884594658017159, "critic_loss": 0.9159756376445294, "actor_loss": -82.18907534790038, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.342546701431274, "step": 67000}
{"episode_reward": 930.2624710403783, "episode": 68.0, "batch_reward": 0.7897597036957741, "critic_loss": 0.9191027635931969, "actor_loss": -82.53703057861328, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.550467491149902, "step": 68000}
{"episode_reward": 927.1400465167335, "episode": 69.0, "batch_reward": 0.7896383953690529, "critic_loss": 0.8909667241275311, "actor_loss": -82.07282989501954, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.43217968940735, "step": 69000}
{"episode_reward": 909.2192327219949, "episode": 70.0, "batch_reward": 0.794779517352581, "critic_loss": 0.8869259727299214, "actor_loss": -82.32425651550292, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.38571286201477, "step": 70000}
{"episode_reward": 924.3407420498097, "episode": 71.0, "batch_reward": 0.7954131952524185, "critic_loss": 0.8679903190135956, "actor_loss": -82.26413650512696, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.017998456954956, "step": 71000}
{"episode_reward": 881.4519999005973, "episode": 72.0, "batch_reward": 0.7962292623519898, "critic_loss": 0.919350232064724, "actor_loss": -82.51913569641113, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.239877223968506, "step": 72000}
{"episode_reward": 934.7695241748588, "episode": 73.0, "batch_reward": 0.7990441670417786, "critic_loss": 0.8299939647316933, "actor_loss": -82.62965133666992, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.38190746307373, "step": 73000}
{"episode_reward": 890.379615935883, "episode": 74.0, "batch_reward": 0.8013830804228783, "critic_loss": 0.8224138566851615, "actor_loss": -82.61038757324219, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.137739658355713, "step": 74000}
{"episode_reward": 939.2190182471879, "episode": 75.0, "batch_reward": 0.8008737692832947, "critic_loss": 0.8523846150934696, "actor_loss": -82.75775579833984, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.707427740097046, "step": 75000}
{"episode_reward": 873.1711651205285, "episode": 76.0, "batch_reward": 0.8018027788996697, "critic_loss": 0.8558067509233952, "actor_loss": -82.75034069824218, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.47368812561035, "step": 76000}
{"episode_reward": 895.7955398411193, "episode": 77.0, "batch_reward": 0.8035413826704025, "critic_loss": 0.9021280281841755, "actor_loss": -82.9921837310791, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.24614405632019, "step": 77000}
{"episode_reward": 897.6312382888424, "episode": 78.0, "batch_reward": 0.8058901972770691, "critic_loss": 0.8483525182306767, "actor_loss": -83.1224803466797, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.647988319396973, "step": 78000}
{"episode_reward": 858.9464565695026, "episode": 79.0, "batch_reward": 0.8054150884747505, "critic_loss": 0.8296544341444969, "actor_loss": -83.256740524292, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.746318340301514, "step": 79000}
{"episode_reward": 843.4430107618622, "episode": 80.0, "batch_reward": 0.807087877035141, "critic_loss": 0.840738762319088, "actor_loss": -83.23487788391114, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.018492460250854, "step": 80000}
{"episode_reward": 935.4994839296103, "episode": 81.0, "batch_reward": 0.8089770451784134, "critic_loss": 0.8555272289216519, "actor_loss": -83.1994200592041, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.2175350189209, "step": 81000}
{"episode_reward": 922.3382715436634, "episode": 82.0, "batch_reward": 0.8085319439768791, "critic_loss": 0.8695583857595921, "actor_loss": -83.12087126159668, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.02564835548401, "step": 82000}
{"episode_reward": 870.8043920722268, "episode": 83.0, "batch_reward": 0.8119764413833618, "critic_loss": 0.8589808416068554, "actor_loss": -83.37340771484375, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.218443393707275, "step": 83000}
{"episode_reward": 934.846256051388, "episode": 84.0, "batch_reward": 0.811030005812645, "critic_loss": 0.9005986407697201, "actor_loss": -83.49183627319336, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.330143213272095, "step": 84000}
{"episode_reward": 862.5467806376897, "episode": 85.0, "batch_reward": 0.8114885206818581, "critic_loss": 1.0283942189216613, "actor_loss": -83.4585380859375, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.871103048324585, "step": 85000}
{"episode_reward": 909.651378985142, "episode": 86.0, "batch_reward": 0.8138581700921058, "critic_loss": 0.86586958065629, "actor_loss": -83.27828161621093, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.525757312774658, "step": 86000}
{"episode_reward": 912.3274127216748, "episode": 87.0, "batch_reward": 0.8147972713708878, "critic_loss": 0.9020683813691139, "actor_loss": -83.74857861328125, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.583330869674683, "step": 87000}
{"episode_reward": 953.5593401348922, "episode": 88.0, "batch_reward": 0.8161421256661415, "critic_loss": 1.0041769274473191, "actor_loss": -83.44404971313476, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.655888319015503, "step": 88000}
{"episode_reward": 931.7771759892946, "episode": 89.0, "batch_reward": 0.8183388633728027, "critic_loss": 0.9174008347094059, "actor_loss": -83.53147679138183, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.736653089523315, "step": 89000}
{"episode_reward": 885.5605365812287, "episode": 90.0, "batch_reward": 0.8188120033144951, "critic_loss": 0.8332325955331326, "actor_loss": -83.59665963745117, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.003583669662476, "step": 90000}
{"episode_reward": 852.8666056210238, "episode": 91.0, "batch_reward": 0.81958292979002, "critic_loss": 0.9198837850987911, "actor_loss": -83.62391047668457, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.419286489486694, "step": 91000}
{"episode_reward": 899.9375317582296, "episode": 92.0, "batch_reward": 0.8181851058602333, "critic_loss": 0.9222836974561215, "actor_loss": -83.78346281433106, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.160534620285034, "step": 92000}
{"episode_reward": 753.8568977419453, "episode": 93.0, "batch_reward": 0.8192286447882652, "critic_loss": 0.8835082947015762, "actor_loss": -83.67858351135254, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.36849355697632, "step": 93000}
{"episode_reward": 914.0814202960014, "episode": 94.0, "batch_reward": 0.8192680002450943, "critic_loss": 0.9317293554544449, "actor_loss": -83.82370950317383, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.44290852546692, "step": 94000}
{"episode_reward": 897.1190208127146, "episode": 95.0, "batch_reward": 0.8208051367998123, "critic_loss": 1.0115647583305836, "actor_loss": -83.97323770141601, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.297709703445435, "step": 95000}
{"episode_reward": 903.4709618713023, "episode": 96.0, "batch_reward": 0.821992846608162, "critic_loss": 0.9117797125577927, "actor_loss": -83.89704161071778, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.341485023498535, "step": 96000}
{"episode_reward": 886.3458779088716, "episode": 97.0, "batch_reward": 0.8211610612869262, "critic_loss": 0.95271410754323, "actor_loss": -83.73201351928711, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.318792581558228, "step": 97000}
{"episode_reward": 954.3520495909582, "episode": 98.0, "batch_reward": 0.8238021335005761, "critic_loss": 0.8876751935482026, "actor_loss": -84.16043141174316, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.558898210525513, "step": 98000}
{"episode_reward": 949.4742634754951, "episode": 99.0, "batch_reward": 0.8242637003064156, "critic_loss": 0.8598973619043827, "actor_loss": -83.84938282775879, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.64951515197754, "step": 99000}
{"episode_reward": 931.529505960828, "episode": 100.0, "batch_reward": 0.8271456186771393, "critic_loss": 0.9192334725558757, "actor_loss": -83.97016076660157, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.21512222290039, "step": 100000}
{"episode_reward": 951.6504988409691, "episode": 101.0, "batch_reward": 0.8254707779884338, "critic_loss": 0.8934516747295856, "actor_loss": -83.98228646850586, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.8764111995697, "step": 101000}
{"episode_reward": 834.5087861398671, "episode": 102.0, "batch_reward": 0.8289804517626762, "critic_loss": 0.8667844120264053, "actor_loss": -84.20347134399414, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.761579036712646, "step": 102000}
{"episode_reward": 951.0687528594113, "episode": 103.0, "batch_reward": 0.8288310009837151, "critic_loss": 0.8469003439843654, "actor_loss": -84.0883921661377, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.83532452583313, "step": 103000}
{"episode_reward": 946.3155222839124, "episode": 104.0, "batch_reward": 0.8308760846853256, "critic_loss": 0.8591241055130958, "actor_loss": -84.15257740783692, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.563354015350342, "step": 104000}
{"episode_reward": 918.9931227973242, "episode": 105.0, "batch_reward": 0.8316796275377274, "critic_loss": 0.8963690457344056, "actor_loss": -84.26113627624511, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.07418417930603, "step": 105000}
{"episode_reward": 921.7172876190435, "episode": 106.0, "batch_reward": 0.8312582719326019, "critic_loss": 0.862725247234106, "actor_loss": -84.29556709289551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.567472219467163, "step": 106000}
{"episode_reward": 949.3636009216428, "episode": 107.0, "batch_reward": 0.8321867806911468, "critic_loss": 0.860361524194479, "actor_loss": -84.2144154663086, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.391037225723267, "step": 107000}
{"episode_reward": 912.8708591619635, "episode": 108.0, "batch_reward": 0.831332813680172, "critic_loss": 0.8940609923303128, "actor_loss": -84.40989224243164, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.738070964813232, "step": 108000}
{"episode_reward": 848.9929126548731, "episode": 109.0, "batch_reward": 0.8344049680829048, "critic_loss": 0.8646387513279915, "actor_loss": -84.40424206542968, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.670777320861816, "step": 109000}
{"episode_reward": 902.1064188113169, "episode": 110.0, "batch_reward": 0.8323586583733559, "critic_loss": 0.8566563319563866, "actor_loss": -84.58388565063477, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.4713191986084, "step": 110000}
{"episode_reward": 887.086528016349, "episode": 111.0, "batch_reward": 0.8349681705236435, "critic_loss": 0.8481949740350246, "actor_loss": -84.42404100036622, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.70979928970337, "step": 111000}
{"episode_reward": 947.0195578600706, "episode": 112.0, "batch_reward": 0.8362035282254219, "critic_loss": 0.7888699160516262, "actor_loss": -84.6695138244629, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.467817783355713, "step": 112000}
{"episode_reward": 922.8092613669717, "episode": 113.0, "batch_reward": 0.8367483450174331, "critic_loss": 0.7743504692316056, "actor_loss": -84.56819750976562, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.48926091194153, "step": 113000}
{"episode_reward": 945.527762035487, "episode": 114.0, "batch_reward": 0.8379076870679856, "critic_loss": 0.8287602702975273, "actor_loss": -84.71946102905274, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.738054752349854, "step": 114000}
{"episode_reward": 920.6908510945495, "episode": 115.0, "batch_reward": 0.8394222145676613, "critic_loss": 0.7802110070288182, "actor_loss": -84.71315731811524, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.934199810028076, "step": 115000}
{"episode_reward": 949.6554665765565, "episode": 116.0, "batch_reward": 0.8392139434814453, "critic_loss": 0.8041988134086132, "actor_loss": -84.74724711608887, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.538487672805786, "step": 116000}
{"episode_reward": 950.5694742412875, "episode": 117.0, "batch_reward": 0.8410152963995934, "critic_loss": 0.79694405990839, "actor_loss": -84.74265803527832, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.743090867996216, "step": 117000}
{"episode_reward": 932.1857999221124, "episode": 118.0, "batch_reward": 0.8400383052825928, "critic_loss": 0.7619355926513672, "actor_loss": -84.70693222045898, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.903937339782715, "step": 118000}
{"episode_reward": 948.1300442121936, "episode": 119.0, "batch_reward": 0.8416257122159004, "critic_loss": 0.8185248720645905, "actor_loss": -84.78892979431153, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.687644004821777, "step": 119000}
{"episode_reward": 878.1547962410417, "episode": 120.0, "batch_reward": 0.8411080331206322, "critic_loss": 0.7546349197924137, "actor_loss": -84.75469543457031, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.71120858192444, "step": 120000}
{"episode_reward": 946.1984126897768, "episode": 121.0, "batch_reward": 0.8441137257218361, "critic_loss": 0.8132522676289081, "actor_loss": -84.9109813079834, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.77767610549927, "step": 121000}
{"episode_reward": 894.0169410131114, "episode": 122.0, "batch_reward": 0.8435746949911117, "critic_loss": 0.7279501732289791, "actor_loss": -85.00676049804687, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.632160663604736, "step": 122000}
{"episode_reward": 878.2991482758111, "episode": 123.0, "batch_reward": 0.8434726479649544, "critic_loss": 0.7960203341543675, "actor_loss": -85.01168937683106, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.56264305114746, "step": 123000}
{"episode_reward": 904.6739203655578, "episode": 124.0, "batch_reward": 0.8435240051150322, "critic_loss": 0.7396186708807945, "actor_loss": -85.05971264648437, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.879314661026, "step": 124000}
{"episode_reward": 948.4733033684163, "episode": 125.0, "batch_reward": 0.8440120438933373, "critic_loss": 0.7385259314179421, "actor_loss": -85.00276145935058, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.398087739944458, "step": 125000}
{"episode_reward": 917.0705511356921, "episode": 126.0, "batch_reward": 0.8445998101234437, "critic_loss": 0.7525020976364613, "actor_loss": -85.10193087768555, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.360357999801636, "step": 126000}
{"episode_reward": 957.1964368861517, "episode": 127.0, "batch_reward": 0.8457508801221848, "critic_loss": 0.7126964692473412, "actor_loss": -85.1275902709961, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.162755727767944, "step": 127000}
{"episode_reward": 919.1738196190903, "episode": 128.0, "batch_reward": 0.8469407960176468, "critic_loss": 0.6825320598483086, "actor_loss": -85.21125550842285, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.750173330307007, "step": 128000}
{"episode_reward": 946.5007481610962, "episode": 129.0, "batch_reward": 0.8478744670152664, "critic_loss": 0.7203363807946443, "actor_loss": -85.19672300720215, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.577739477157593, "step": 129000}
{"episode_reward": 954.0175876873448, "episode": 130.0, "batch_reward": 0.8478799021244049, "critic_loss": 0.7330011232197284, "actor_loss": -85.31075971984863, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.947945833206177, "step": 130000}
{"episode_reward": 895.4822371116506, "episode": 131.0, "batch_reward": 0.8495840392708779, "critic_loss": 0.6728931228071451, "actor_loss": -85.17229351806641, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.59217691421509, "step": 131000}
{"episode_reward": 934.5591501461007, "episode": 132.0, "batch_reward": 0.8494886282086372, "critic_loss": 0.7005476902127266, "actor_loss": -85.38320588684083, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.352312803268433, "step": 132000}
{"episode_reward": 899.6870371143368, "episode": 133.0, "batch_reward": 0.8502257933020592, "critic_loss": 0.7129946257472038, "actor_loss": -85.33278984069824, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.53138279914856, "step": 133000}
{"episode_reward": 958.0153013729731, "episode": 134.0, "batch_reward": 0.8508845958709716, "critic_loss": 0.6906325303465128, "actor_loss": -85.37613165283203, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.264533281326294, "step": 134000}
{"episode_reward": 936.4537454848906, "episode": 135.0, "batch_reward": 0.8493550696969032, "critic_loss": 0.6970856871753931, "actor_loss": -85.39942901611329, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.35822367668152, "step": 135000}
{"episode_reward": 849.7178878547572, "episode": 136.0, "batch_reward": 0.8511786828041077, "critic_loss": 0.7088515560925007, "actor_loss": -85.43659057617188, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.231858491897583, "step": 136000}
{"episode_reward": 897.4978918863652, "episode": 137.0, "batch_reward": 0.8526828516125678, "critic_loss": 0.6828562947958707, "actor_loss": -85.45623666381836, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.27640414237976, "step": 137000}
{"episode_reward": 905.788554209179, "episode": 138.0, "batch_reward": 0.8514064087867736, "critic_loss": 0.7124118922352791, "actor_loss": -85.3884122467041, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.37541913986206, "step": 138000}
{"episode_reward": 926.842347759133, "episode": 139.0, "batch_reward": 0.8507172545790672, "critic_loss": 0.7422061231136322, "actor_loss": -85.38534373474121, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.27476668357849, "step": 139000}
{"episode_reward": 858.3968565160847, "episode": 140.0, "batch_reward": 0.8508903443217277, "critic_loss": 0.7120719399750233, "actor_loss": -85.43189921569824, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.631577730178833, "step": 140000}
{"episode_reward": 931.9620414838795, "episode": 141.0, "batch_reward": 0.854900126338005, "critic_loss": 0.6720482160001994, "actor_loss": -85.57340014648437, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.111979246139526, "step": 141000}
{"episode_reward": 923.6198584373313, "episode": 142.0, "batch_reward": 0.8542076511979103, "critic_loss": 0.6767178744077682, "actor_loss": -85.5834196472168, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.693275690078735, "step": 142000}
{"episode_reward": 919.5167008785767, "episode": 143.0, "batch_reward": 0.8530783920884132, "critic_loss": 0.6908985658288002, "actor_loss": -85.51361682128906, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.35771417617798, "step": 143000}
{"episode_reward": 922.966565189783, "episode": 144.0, "batch_reward": 0.853410995543003, "critic_loss": 0.7279272911846638, "actor_loss": -85.61565277099609, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.5440731048584, "step": 144000}
{"episode_reward": 925.0639663135197, "episode": 145.0, "batch_reward": 0.8564892854690552, "critic_loss": 0.6932688252925873, "actor_loss": -85.6127148284912, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.296361446380615, "step": 145000}
{"episode_reward": 929.1559833022616, "episode": 146.0, "batch_reward": 0.8554019199609757, "critic_loss": 0.7107850552201271, "actor_loss": -85.42278889465332, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.373214960098267, "step": 146000}
{"episode_reward": 911.9908215116156, "episode": 147.0, "batch_reward": 0.855136743068695, "critic_loss": 0.7174056902080774, "actor_loss": -85.61380010986328, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.707083702087402, "step": 147000}
{"episode_reward": 911.0730185719166, "episode": 148.0, "batch_reward": 0.8571855002641677, "critic_loss": 0.6739794494509697, "actor_loss": -85.6990863647461, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.529569149017334, "step": 148000}
{"episode_reward": 934.3612390320321, "episode": 149.0, "batch_reward": 0.8565938068628312, "critic_loss": 0.7043727180361747, "actor_loss": -85.63888905334473, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.490604639053345, "step": 149000}
{"episode_reward": 909.2273268668754, "episode": 150.0, "batch_reward": 0.8582415273189544, "critic_loss": 0.7211402644515037, "actor_loss": -85.60450201416016, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "step": 150000}
