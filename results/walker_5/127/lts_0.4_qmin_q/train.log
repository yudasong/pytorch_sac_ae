{"episode_reward": 0.0, "episode": 1.0, "duration": 22.166475296020508, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.9151861667633057, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.4186867720467045, "critic_loss": 0.7052833995408875, "actor_loss": -76.53320123215302, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 65.9374988079071, "step": 3000}
{"episode_reward": 232.6043212845353, "episode": 4.0, "batch_reward": 0.39927446901798247, "critic_loss": 0.8279244908988476, "actor_loss": -78.91040521240234, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.344485759735107, "step": 4000}
{"episode_reward": 628.796828409726, "episode": 5.0, "batch_reward": 0.47102569735050204, "critic_loss": 0.6260396846830845, "actor_loss": -80.75007821655274, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.853830814361572, "step": 5000}
{"episode_reward": 831.0369382138895, "episode": 6.0, "batch_reward": 0.47422123250365256, "critic_loss": 0.763717179864645, "actor_loss": -81.42207113647461, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.696482181549072, "step": 6000}
{"episode_reward": 215.94021231444924, "episode": 7.0, "batch_reward": 0.4909214703142643, "critic_loss": 0.5703552668392659, "actor_loss": -82.31300788879395, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.935446977615356, "step": 7000}
{"episode_reward": 870.1555700094835, "episode": 8.0, "batch_reward": 0.5445058213174343, "critic_loss": 0.5055875571668148, "actor_loss": -82.91939166259766, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.584312200546265, "step": 8000}
{"episode_reward": 916.7728917088201, "episode": 9.0, "batch_reward": 0.5867545976638794, "critic_loss": 0.5092954366505146, "actor_loss": -83.48576705932618, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.23412561416626, "step": 9000}
{"episode_reward": 912.0660218191607, "episode": 10.0, "batch_reward": 0.5800540998876095, "critic_loss": 0.5844329803586006, "actor_loss": -83.223677734375, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.316941738128662, "step": 10000}
{"episode_reward": 57.06865061862482, "episode": 11.0, "batch_reward": 0.5349617262184619, "critic_loss": 0.5501192330420017, "actor_loss": -82.17780923461915, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.465965270996094, "step": 11000}
{"episode_reward": 322.8767344588566, "episode": 12.0, "batch_reward": 0.54226488545537, "critic_loss": 0.4789726269990206, "actor_loss": -81.70837944030762, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.851918697357178, "step": 12000}
{"episode_reward": 866.5271779085223, "episode": 13.0, "batch_reward": 0.5676217140257358, "critic_loss": 0.42882655645906925, "actor_loss": -81.969125, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.607090950012207, "step": 13000}
{"episode_reward": 860.0976634454818, "episode": 14.0, "batch_reward": 0.5893795757293702, "critic_loss": 0.41562365111708643, "actor_loss": -81.63591792297363, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.31439757347107, "step": 14000}
{"episode_reward": 859.9285570909253, "episode": 15.0, "batch_reward": 0.6039233626127243, "critic_loss": 0.41750039276480677, "actor_loss": -81.38131776428223, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.4385883808136, "step": 15000}
{"episode_reward": 804.9968707149583, "episode": 16.0, "batch_reward": 0.6245451652109623, "critic_loss": 0.4700401102900505, "actor_loss": -81.65539886474609, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.45403480529785, "step": 16000}
{"episode_reward": 913.7216432139263, "episode": 17.0, "batch_reward": 0.6403928872942924, "critic_loss": 0.5056854487061501, "actor_loss": -81.76233697509765, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.157442808151245, "step": 17000}
{"episode_reward": 852.8715153156268, "episode": 18.0, "batch_reward": 0.6526657419204712, "critic_loss": 0.5050791474580765, "actor_loss": -81.92822932434082, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.18464422225952, "step": 18000}
{"episode_reward": 866.0574644798369, "episode": 19.0, "batch_reward": 0.6665264533162117, "critic_loss": 0.44363347387313845, "actor_loss": -82.23141488647461, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.70395064353943, "step": 19000}
{"episode_reward": 949.0056802191804, "episode": 20.0, "batch_reward": 0.681174345612526, "critic_loss": 0.4386218927651644, "actor_loss": -82.65328787231445, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.50908398628235, "step": 20000}
{"episode_reward": 952.866975383112, "episode": 21.0, "batch_reward": 0.6961573340892792, "critic_loss": 0.43006423832476137, "actor_loss": -83.12894535827637, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.4784152507782, "step": 21000}
{"episode_reward": 926.8543107937437, "episode": 22.0, "batch_reward": 0.7041537697315217, "critic_loss": 0.4206335530281067, "actor_loss": -83.24684071350097, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.937129020690918, "step": 22000}
{"episode_reward": 915.7660613680455, "episode": 23.0, "batch_reward": 0.7158329365849495, "critic_loss": 0.3776512452363968, "actor_loss": -83.57470536804199, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.76794195175171, "step": 23000}
{"episode_reward": 925.7008619435549, "episode": 24.0, "batch_reward": 0.7222708947658539, "critic_loss": 0.3717791337817907, "actor_loss": -83.68537872314454, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.55486488342285, "step": 24000}
{"episode_reward": 903.376205755139, "episode": 25.0, "batch_reward": 0.7275574140548706, "critic_loss": 0.36170451395213604, "actor_loss": -83.77263160705566, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.21399235725403, "step": 25000}
{"episode_reward": 849.741849183946, "episode": 26.0, "batch_reward": 0.7365188285708427, "critic_loss": 0.3511385025978088, "actor_loss": -84.00010260009766, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.054767608642578, "step": 26000}
{"episode_reward": 953.6280688862286, "episode": 27.0, "batch_reward": 0.743198003411293, "critic_loss": 0.32905401311814786, "actor_loss": -84.29177755737305, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.594762802124023, "step": 27000}
{"episode_reward": 961.0697186516269, "episode": 28.0, "batch_reward": 0.753595000565052, "critic_loss": 0.30784152406454085, "actor_loss": -84.43516789245605, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.57980513572693, "step": 28000}
{"episode_reward": 950.7225429239012, "episode": 29.0, "batch_reward": 0.7580300951004029, "critic_loss": 0.3159744712263346, "actor_loss": -84.61167567443847, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.417129039764404, "step": 29000}
{"episode_reward": 923.4342045289036, "episode": 30.0, "batch_reward": 0.7664782738685608, "critic_loss": 0.3064481324851513, "actor_loss": -84.89741249084473, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.352736711502075, "step": 30000}
{"episode_reward": 911.6291812246466, "episode": 31.0, "batch_reward": 0.7689522441625595, "critic_loss": 0.32348632787168025, "actor_loss": -84.90267459106445, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 45.444904804229736, "step": 31000}
{"episode_reward": 917.2206512477505, "episode": 32.0, "batch_reward": 0.7720659619569779, "critic_loss": 0.35379138477146627, "actor_loss": -84.99420083618165, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.567374229431152, "step": 32000}
{"episode_reward": 855.6965769278621, "episode": 33.0, "batch_reward": 0.776949840247631, "critic_loss": 0.33915234030783176, "actor_loss": -84.98980494689941, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.839941263198853, "step": 33000}
{"episode_reward": 938.9767729807593, "episode": 34.0, "batch_reward": 0.7825095366835594, "critic_loss": 0.3134405152499676, "actor_loss": -85.37515142822265, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.796639680862427, "step": 34000}
{"episode_reward": 954.6731428114998, "episode": 35.0, "batch_reward": 0.7858773827552795, "critic_loss": 0.3108326015770435, "actor_loss": -85.34402487182618, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.820698499679565, "step": 35000}
{"episode_reward": 899.3103188343779, "episode": 36.0, "batch_reward": 0.790463006079197, "critic_loss": 0.30971826873719693, "actor_loss": -85.56756913757324, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.507842779159546, "step": 36000}
{"episode_reward": 912.8000657409332, "episode": 37.0, "batch_reward": 0.7934827771186829, "critic_loss": 0.33943420703709126, "actor_loss": -85.89910897827149, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.724284410476685, "step": 37000}
{"episode_reward": 962.4689125048272, "episode": 38.0, "batch_reward": 0.7974948470592499, "critic_loss": 0.3616940080523491, "actor_loss": -86.07838444519042, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.447893857955933, "step": 38000}
{"episode_reward": 940.2431332823368, "episode": 39.0, "batch_reward": 0.8008828250169754, "critic_loss": 0.4054583045989275, "actor_loss": -86.31532038879395, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.99771022796631, "step": 39000}
{"episode_reward": 947.591963569429, "episode": 40.0, "batch_reward": 0.8051967113614082, "critic_loss": 0.46728755697607993, "actor_loss": -86.67472709655762, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.25129795074463, "step": 40000}
{"episode_reward": 960.8903484581045, "episode": 41.0, "batch_reward": 0.8093706077337265, "critic_loss": 0.6101075232625007, "actor_loss": -87.41895658874512, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.324992179870605, "step": 41000}
{"episode_reward": 952.4198842849088, "episode": 42.0, "batch_reward": 0.8025983611941337, "critic_loss": 0.7215097802579403, "actor_loss": -87.48603880310058, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.719711303710938, "step": 42000}
{"episode_reward": 13.49791598890703, "episode": 43.0, "batch_reward": 0.792850641489029, "critic_loss": 0.6882050650864839, "actor_loss": -87.44016683959961, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.077544689178467, "step": 43000}
{"episode_reward": 958.5062617329941, "episode": 44.0, "batch_reward": 0.7978175832033157, "critic_loss": 0.6230325543284416, "actor_loss": -87.36786906433106, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.769843339920044, "step": 44000}
{"episode_reward": 959.65104470687, "episode": 45.0, "batch_reward": 0.80031188839674, "critic_loss": 0.5223214391320944, "actor_loss": -87.36792570495605, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.132931232452393, "step": 45000}
{"episode_reward": 962.6545644884104, "episode": 46.0, "batch_reward": 0.8035704365372658, "critic_loss": 0.42446477331221105, "actor_loss": -87.67824049377441, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.508826971054077, "step": 46000}
{"episode_reward": 972.1457592792202, "episode": 47.0, "batch_reward": 0.8008444626331329, "critic_loss": 0.3783771055191755, "actor_loss": -87.36198028564453, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.275781631469727, "step": 47000}
{"episode_reward": 189.39551531934313, "episode": 48.0, "batch_reward": 0.7850687162876129, "critic_loss": 0.356923365265131, "actor_loss": -86.71647816467285, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.450251579284668, "step": 48000}
{"episode_reward": 160.94810593724725, "episode": 49.0, "batch_reward": 0.7825999336242676, "critic_loss": 0.31740103094279765, "actor_loss": -86.43355706787109, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.556734085083008, "step": 49000}
{"episode_reward": 943.5407541559362, "episode": 50.0, "batch_reward": 0.7854654551148414, "critic_loss": 0.2855977918356657, "actor_loss": -86.47936451721192, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.866936445236206, "step": 50000}
{"episode_reward": 964.6517319460144, "episode": 51.0, "batch_reward": 0.790335300564766, "critic_loss": 0.29149398316442965, "actor_loss": -86.52279154968262, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.44131374359131, "step": 51000}
{"episode_reward": 933.8456926441982, "episode": 52.0, "batch_reward": 0.7910935543775558, "critic_loss": 0.30447661550343036, "actor_loss": -86.32396374511718, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.792117834091187, "step": 52000}
{"episode_reward": 827.0039719822973, "episode": 53.0, "batch_reward": 0.7910023890137673, "critic_loss": 0.3264495536088943, "actor_loss": -85.99508100891113, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.258811235427856, "step": 53000}
{"episode_reward": 914.9122510139697, "episode": 54.0, "batch_reward": 0.7960525582432747, "critic_loss": 0.33262618762254714, "actor_loss": -86.13960914611816, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.21596908569336, "step": 54000}
{"episode_reward": 955.708443434928, "episode": 55.0, "batch_reward": 0.7970513324141503, "critic_loss": 0.34308763055503366, "actor_loss": -86.05549440002441, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.83459162712097, "step": 55000}
{"episode_reward": 953.5497688888674, "episode": 56.0, "batch_reward": 0.8004427295923233, "critic_loss": 0.36371233670413494, "actor_loss": -86.16858474731445, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.365378379821777, "step": 56000}
{"episode_reward": 937.27768995216, "episode": 57.0, "batch_reward": 0.8031758885979653, "critic_loss": 0.3632382222265005, "actor_loss": -86.19971754455567, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.104714393615723, "step": 57000}
{"episode_reward": 923.541397869935, "episode": 58.0, "batch_reward": 0.8036596466898918, "critic_loss": 0.3905207501798868, "actor_loss": -86.20628550720215, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.373661756515503, "step": 58000}
{"episode_reward": 945.6757761092191, "episode": 59.0, "batch_reward": 0.8085501053333283, "critic_loss": 0.36616734239459037, "actor_loss": -86.4501307067871, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.843055725097656, "step": 59000}
{"episode_reward": 971.3211707366822, "episode": 60.0, "batch_reward": 0.8099933605790138, "critic_loss": 0.36307101441919803, "actor_loss": -86.54496203613282, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.214538097381592, "step": 60000}
{"episode_reward": 960.9134183437873, "episode": 61.0, "batch_reward": 0.8141600310206413, "critic_loss": 0.394819970831275, "actor_loss": -86.70334252929688, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.746700286865234, "step": 61000}
{"episode_reward": 939.3100758144355, "episode": 62.0, "batch_reward": 0.8129582731723786, "critic_loss": 0.39161341458559035, "actor_loss": -86.56650102233887, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.75124430656433, "step": 62000}
{"episode_reward": 786.6018557696598, "episode": 63.0, "batch_reward": 0.8143378930687905, "critic_loss": 0.3308220670670271, "actor_loss": -86.87964306640625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.71700930595398, "step": 63000}
{"episode_reward": 954.9710878114853, "episode": 64.0, "batch_reward": 0.8153929455876351, "critic_loss": 0.3320921725779772, "actor_loss": -86.74712281799316, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.58369517326355, "step": 64000}
{"episode_reward": 915.2106521468028, "episode": 65.0, "batch_reward": 0.8168309343457222, "critic_loss": 0.31254646185040474, "actor_loss": -86.91706077575684, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.12250590324402, "step": 65000}
{"episode_reward": 921.6250051322702, "episode": 66.0, "batch_reward": 0.8171840606331825, "critic_loss": 0.32362856820225716, "actor_loss": -86.8614001159668, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.608224153518677, "step": 66000}
{"episode_reward": 892.2506630179993, "episode": 67.0, "batch_reward": 0.8210430248975754, "critic_loss": 0.3019473309740424, "actor_loss": -86.73887042236328, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.724773645401, "step": 67000}
{"episode_reward": 945.4662859718242, "episode": 68.0, "batch_reward": 0.8209650177359581, "critic_loss": 0.30161433209478855, "actor_loss": -86.7585050201416, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.63240885734558, "step": 68000}
{"episode_reward": 928.3252829213593, "episode": 69.0, "batch_reward": 0.8228001024127006, "critic_loss": 0.30979352712631225, "actor_loss": -87.0668212890625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.754085540771484, "step": 69000}
{"episode_reward": 903.6341040784779, "episode": 70.0, "batch_reward": 0.8256321285367012, "critic_loss": 0.308370352730155, "actor_loss": -86.97817533874512, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.536714553833008, "step": 70000}
{"episode_reward": 943.1156347089251, "episode": 71.0, "batch_reward": 0.8265672141313553, "critic_loss": 0.31390638765692713, "actor_loss": -87.13309642028808, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.78069591522217, "step": 71000}
{"episode_reward": 920.1336297349299, "episode": 72.0, "batch_reward": 0.8281173867583275, "critic_loss": 0.3150266358330846, "actor_loss": -87.25640647888184, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.82301163673401, "step": 72000}
{"episode_reward": 952.2268262244523, "episode": 73.0, "batch_reward": 0.8292393847703934, "critic_loss": 0.34275344122201207, "actor_loss": -87.28709107971191, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.46437430381775, "step": 73000}
{"episode_reward": 861.7139939457735, "episode": 74.0, "batch_reward": 0.8283250488042831, "critic_loss": 0.32114779952168465, "actor_loss": -87.2130555267334, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.877053260803223, "step": 74000}
{"episode_reward": 920.7964028424321, "episode": 75.0, "batch_reward": 0.830911178946495, "critic_loss": 0.3460924147069454, "actor_loss": -87.40965731811524, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.228569984436035, "step": 75000}
{"episode_reward": 917.3976243118777, "episode": 76.0, "batch_reward": 0.8312882632613182, "critic_loss": 0.3186534879282117, "actor_loss": -87.45858160400391, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.61219096183777, "step": 76000}
{"episode_reward": 856.7608413380049, "episode": 77.0, "batch_reward": 0.8319651172161102, "critic_loss": 0.3225247003808618, "actor_loss": -87.45807833862305, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.106164693832397, "step": 77000}
{"episode_reward": 899.5915057907519, "episode": 78.0, "batch_reward": 0.8343130071163177, "critic_loss": 0.3226613236218691, "actor_loss": -87.6575562286377, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.7915997505188, "step": 78000}
{"episode_reward": 975.4559820353463, "episode": 79.0, "batch_reward": 0.8359475126266479, "critic_loss": 0.3011475869193673, "actor_loss": -87.63257649230957, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.02585005760193, "step": 79000}
{"episode_reward": 947.5534754997896, "episode": 80.0, "batch_reward": 0.8368302785754204, "critic_loss": 0.3051998532637954, "actor_loss": -87.56680729675293, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.750559091567993, "step": 80000}
{"episode_reward": 966.158489274889, "episode": 81.0, "batch_reward": 0.8392662677764893, "critic_loss": 0.2788371992856264, "actor_loss": -87.63524450683593, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 45.107187032699585, "step": 81000}
{"episode_reward": 940.6583629237577, "episode": 82.0, "batch_reward": 0.8381154128313064, "critic_loss": 0.33200734892487527, "actor_loss": -87.77865446472168, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.74724245071411, "step": 82000}
{"episode_reward": 886.473276688366, "episode": 83.0, "batch_reward": 0.8420287536978721, "critic_loss": 0.29742547842115163, "actor_loss": -87.7502668762207, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.393955945968628, "step": 83000}
{"episode_reward": 961.7628565808193, "episode": 84.0, "batch_reward": 0.8415505673885345, "critic_loss": 0.2969567795544863, "actor_loss": -87.79570480346679, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.217567920684814, "step": 84000}
{"episode_reward": 903.8111819527886, "episode": 85.0, "batch_reward": 0.8420953817367554, "critic_loss": 0.2826063701957464, "actor_loss": -87.90442346191406, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.99925184249878, "step": 85000}
{"episode_reward": 945.4012277315412, "episode": 86.0, "batch_reward": 0.8441028133034706, "critic_loss": 0.2964227162450552, "actor_loss": -87.94029371643066, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.821598529815674, "step": 86000}
{"episode_reward": 965.1399616278783, "episode": 87.0, "batch_reward": 0.8463544756174087, "critic_loss": 0.27620547148585317, "actor_loss": -87.91816073608399, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.178833961486816, "step": 87000}
{"episode_reward": 974.0336928734848, "episode": 88.0, "batch_reward": 0.84585280585289, "critic_loss": 0.28869610840827226, "actor_loss": -87.92331968688964, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.143587827682495, "step": 88000}
{"episode_reward": 946.172206460603, "episode": 89.0, "batch_reward": 0.8474013795256614, "critic_loss": 0.2853779534995556, "actor_loss": -88.14399151611327, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.540022134780884, "step": 89000}
{"episode_reward": 924.5575955580055, "episode": 90.0, "batch_reward": 0.8490864498019218, "critic_loss": 0.2772800861299038, "actor_loss": -88.2077130279541, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.86902952194214, "step": 90000}
{"episode_reward": 909.6625235821061, "episode": 91.0, "batch_reward": 0.850077852845192, "critic_loss": 0.27173812918365003, "actor_loss": -88.35812991333007, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.42052698135376, "step": 91000}
{"episode_reward": 967.9800696972096, "episode": 92.0, "batch_reward": 0.8498991333842277, "critic_loss": 0.2940399627238512, "actor_loss": -88.25384001159668, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.894421577453613, "step": 92000}
{"episode_reward": 923.9151358646104, "episode": 93.0, "batch_reward": 0.8511345562934876, "critic_loss": 0.280826822757721, "actor_loss": -88.46180541992187, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.115415811538696, "step": 93000}
{"episode_reward": 947.083028493983, "episode": 94.0, "batch_reward": 0.8519018219709397, "critic_loss": 0.2636851164922118, "actor_loss": -88.36449821472168, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.764697790145874, "step": 94000}
{"episode_reward": 920.5452458456056, "episode": 95.0, "batch_reward": 0.8521539443135262, "critic_loss": 0.23547809585928917, "actor_loss": -88.19136112976074, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.381048440933228, "step": 95000}
{"episode_reward": 916.0536989058304, "episode": 96.0, "batch_reward": 0.8541354740858078, "critic_loss": 0.25027642462402583, "actor_loss": -88.50103973388671, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.405505180358887, "step": 96000}
{"episode_reward": 948.5352715105583, "episode": 97.0, "batch_reward": 0.8547326136231422, "critic_loss": 0.23050583051145077, "actor_loss": -88.56305937194824, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.767770767211914, "step": 97000}
{"episode_reward": 970.9615142987291, "episode": 98.0, "batch_reward": 0.8569822175502777, "critic_loss": 0.23404134587198497, "actor_loss": -88.265835647583, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.492613315582275, "step": 98000}
{"episode_reward": 959.8205335747805, "episode": 99.0, "batch_reward": 0.8576414349079132, "critic_loss": 0.22918652748316526, "actor_loss": -88.49042160034179, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.549586534500122, "step": 99000}
{"episode_reward": 977.1532813576772, "episode": 100.0, "batch_reward": 0.858119887650013, "critic_loss": 0.23052785946428775, "actor_loss": -88.41272302246094, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.627189874649048, "step": 100000}
{"episode_reward": 971.1182868561656, "episode": 101.0, "batch_reward": 0.8600415208339691, "critic_loss": 0.25773714584857227, "actor_loss": -88.71112519836426, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 44.2072377204895, "step": 101000}
{"episode_reward": 941.7755242886477, "episode": 102.0, "batch_reward": 0.8602626752257347, "critic_loss": 0.245749745413661, "actor_loss": -88.49933685302734, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.504065990447998, "step": 102000}
{"episode_reward": 966.6356014550684, "episode": 103.0, "batch_reward": 0.8602205164432526, "critic_loss": 0.24029918949306012, "actor_loss": -88.56595588684083, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.875324726104736, "step": 103000}
{"episode_reward": 963.2771438227267, "episode": 104.0, "batch_reward": 0.8633633155822754, "critic_loss": 0.2350583921521902, "actor_loss": -88.80924085998535, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.24382472038269, "step": 104000}
{"episode_reward": 956.4804847366057, "episode": 105.0, "batch_reward": 0.8627351985573769, "critic_loss": 0.23228163883835076, "actor_loss": -88.75896162414551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.176077365875244, "step": 105000}
{"episode_reward": 943.5186527645809, "episode": 106.0, "batch_reward": 0.8632644594311715, "critic_loss": 0.22344858787953853, "actor_loss": -88.85659373474121, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.344953298568726, "step": 106000}
{"episode_reward": 964.3342303575829, "episode": 107.0, "batch_reward": 0.8645645360350609, "critic_loss": 0.22803426188975573, "actor_loss": -88.95171910095215, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.212600708007812, "step": 107000}
{"episode_reward": 958.4514993698868, "episode": 108.0, "batch_reward": 0.8653108497858047, "critic_loss": 0.22536970891058444, "actor_loss": -88.72254777526855, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.058525323867798, "step": 108000}
{"episode_reward": 964.3150128342202, "episode": 109.0, "batch_reward": 0.8662197285294533, "critic_loss": 0.23979217037558556, "actor_loss": -88.9979701538086, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.73992395401001, "step": 109000}
{"episode_reward": 879.6148956010572, "episode": 110.0, "batch_reward": 0.866082246541977, "critic_loss": 0.2290611296892166, "actor_loss": -88.75446049499512, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.83647131919861, "step": 110000}
{"episode_reward": 903.776213367117, "episode": 111.0, "batch_reward": 0.866692346394062, "critic_loss": 0.22176885506510735, "actor_loss": -88.92701142883301, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.48497271537781, "step": 111000}
{"episode_reward": 909.9082947859338, "episode": 112.0, "batch_reward": 0.8668340324759484, "critic_loss": 0.22369679549336433, "actor_loss": -88.75172120666504, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.562401056289673, "step": 112000}
{"episode_reward": 954.2287128823813, "episode": 113.0, "batch_reward": 0.8685414317846298, "critic_loss": 0.22368451795727015, "actor_loss": -89.08948802185058, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.2740581035614, "step": 113000}
{"episode_reward": 964.3128744785095, "episode": 114.0, "batch_reward": 0.8702787130475044, "critic_loss": 0.2148428922742605, "actor_loss": -88.87007331848145, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.50331473350525, "step": 114000}
{"episode_reward": 943.8283562322757, "episode": 115.0, "batch_reward": 0.8691078906655312, "critic_loss": 0.22577691052109003, "actor_loss": -88.89724981689453, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.802518367767334, "step": 115000}
{"episode_reward": 967.0236842219551, "episode": 116.0, "batch_reward": 0.870744435608387, "critic_loss": 0.2158900351598859, "actor_loss": -88.9714866027832, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.56625199317932, "step": 116000}
{"episode_reward": 969.3813463008348, "episode": 117.0, "batch_reward": 0.8718519045114517, "critic_loss": 0.22306031190603973, "actor_loss": -89.18609381103515, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.545673608779907, "step": 117000}
{"episode_reward": 964.3314798311121, "episode": 118.0, "batch_reward": 0.8718843799829483, "critic_loss": 0.20978503128141165, "actor_loss": -89.15201998901367, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.7587730884552, "step": 118000}
{"episode_reward": 937.4511456003927, "episode": 119.0, "batch_reward": 0.8736061662435531, "critic_loss": 0.21549406418949366, "actor_loss": -89.2044069519043, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.618188619613647, "step": 119000}
{"episode_reward": 899.2488648190504, "episode": 120.0, "batch_reward": 0.8737635685801506, "critic_loss": 0.20955020518600942, "actor_loss": -89.30270845031738, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.706225156784058, "step": 120000}
{"episode_reward": 965.7913278232757, "episode": 121.0, "batch_reward": 0.8737951994538308, "critic_loss": 0.21872662249207497, "actor_loss": -89.36626528930664, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 45.11027383804321, "step": 121000}
{"episode_reward": 947.0666893249019, "episode": 122.0, "batch_reward": 0.8751428259015084, "critic_loss": 0.21791550678759813, "actor_loss": -89.05982992553712, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.37604546546936, "step": 122000}
{"episode_reward": 901.0841495650214, "episode": 123.0, "batch_reward": 0.873340710580349, "critic_loss": 0.2162485692203045, "actor_loss": -89.2144822692871, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.842103004455566, "step": 123000}
{"episode_reward": 922.356897141581, "episode": 124.0, "batch_reward": 0.8743761327266694, "critic_loss": 0.21826937330514193, "actor_loss": -89.1383920288086, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.108219861984253, "step": 124000}
{"episode_reward": 950.832928239741, "episode": 125.0, "batch_reward": 0.8750075138807297, "critic_loss": 0.21594833094254137, "actor_loss": -89.18919920349121, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.893062353134155, "step": 125000}
{"episode_reward": 940.9334299053604, "episode": 126.0, "batch_reward": 0.8749390770792961, "critic_loss": 0.21729727645963431, "actor_loss": -89.1984751739502, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.3049259185791, "step": 126000}
{"episode_reward": 963.0338080490836, "episode": 127.0, "batch_reward": 0.8757420524358749, "critic_loss": 0.21806125405058266, "actor_loss": -89.01059600830078, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.06476640701294, "step": 127000}
{"episode_reward": 889.7115261361773, "episode": 128.0, "batch_reward": 0.8769904034137725, "critic_loss": 0.2061199380606413, "actor_loss": -89.20854907226563, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.730372428894043, "step": 128000}
{"episode_reward": 954.4564344897311, "episode": 129.0, "batch_reward": 0.8760510255098343, "critic_loss": 0.20777646993845703, "actor_loss": -89.19061190795898, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.94840717315674, "step": 129000}
{"episode_reward": 959.8788741811118, "episode": 130.0, "batch_reward": 0.8776294315457344, "critic_loss": 0.21185464027523995, "actor_loss": -89.27212504577636, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.93605637550354, "step": 130000}
{"episode_reward": 913.9629401404992, "episode": 131.0, "batch_reward": 0.877859115421772, "critic_loss": 0.21085113010555506, "actor_loss": -89.28384727478027, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 41.47399115562439, "step": 131000}
{"episode_reward": 942.4582526272558, "episode": 132.0, "batch_reward": 0.878050671517849, "critic_loss": 0.22130232138931752, "actor_loss": -89.26762539672852, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.761540174484253, "step": 132000}
{"episode_reward": 895.7469539172064, "episode": 133.0, "batch_reward": 0.8794345272183418, "critic_loss": 0.21167505330219866, "actor_loss": -89.66341020202637, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.17371129989624, "step": 133000}
{"episode_reward": 967.4508304586309, "episode": 134.0, "batch_reward": 0.87964987719059, "critic_loss": 0.21024685405939816, "actor_loss": -89.38293125915527, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.245450973510742, "step": 134000}
{"episode_reward": 963.2591025309861, "episode": 135.0, "batch_reward": 0.8788270713686943, "critic_loss": 0.22516140164807438, "actor_loss": -89.20051304626465, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.531304121017456, "step": 135000}
{"episode_reward": 845.0490257875523, "episode": 136.0, "batch_reward": 0.8810065014362335, "critic_loss": 0.21560889983177184, "actor_loss": -89.34501155090332, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.96622586250305, "step": 136000}
{"episode_reward": 910.8112932716468, "episode": 137.0, "batch_reward": 0.8787218297123909, "critic_loss": 0.2266027626618743, "actor_loss": -89.22220816040038, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.623875617980957, "step": 137000}
{"episode_reward": 869.477210486102, "episode": 138.0, "batch_reward": 0.8807525498270988, "critic_loss": 0.2152613871693611, "actor_loss": -89.3330074005127, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.94019389152527, "step": 138000}
{"episode_reward": 964.9437751797836, "episode": 139.0, "batch_reward": 0.8798563988208771, "critic_loss": 0.22513253981620074, "actor_loss": -89.3398755493164, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.514683723449707, "step": 139000}
{"episode_reward": 910.7123570249572, "episode": 140.0, "batch_reward": 0.8797245351672173, "critic_loss": 0.22347516521811486, "actor_loss": -89.37547610473632, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.865238189697266, "step": 140000}
{"episode_reward": 934.1072852262066, "episode": 141.0, "batch_reward": 0.88257590508461, "critic_loss": 0.20219891915470362, "actor_loss": -89.23703437805176, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.653677225112915, "step": 141000}
{"episode_reward": 942.1533021710912, "episode": 142.0, "batch_reward": 0.8822330661416053, "critic_loss": 0.21066384008526803, "actor_loss": -89.32207806396484, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.199203968048096, "step": 142000}
{"episode_reward": 956.2905016715885, "episode": 143.0, "batch_reward": 0.8829259092211723, "critic_loss": 0.2117236316651106, "actor_loss": -89.38123509216308, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.113369464874268, "step": 143000}
{"episode_reward": 926.9268261308043, "episode": 144.0, "batch_reward": 0.8819775784015655, "critic_loss": 0.21422613455355166, "actor_loss": -89.3251064453125, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.865214109420776, "step": 144000}
{"episode_reward": 930.251675922255, "episode": 145.0, "batch_reward": 0.8843303508162499, "critic_loss": 0.21144779214635492, "actor_loss": -89.30054676818848, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.447136640548706, "step": 145000}
{"episode_reward": 947.2233990124053, "episode": 146.0, "batch_reward": 0.8831858404874802, "critic_loss": 0.22397664450109006, "actor_loss": -89.47682139587403, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.919617891311646, "step": 146000}
{"episode_reward": 892.1902230210773, "episode": 147.0, "batch_reward": 0.8827257336378097, "critic_loss": 0.22345697585493327, "actor_loss": -89.44006481933594, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.420024633407593, "step": 147000}
{"episode_reward": 923.6550921102564, "episode": 148.0, "batch_reward": 0.8835833349823952, "critic_loss": 0.22197832196205855, "actor_loss": -89.47627255249023, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.6917724609375, "step": 148000}
{"episode_reward": 961.7457583418343, "episode": 149.0, "batch_reward": 0.8840908444523812, "critic_loss": 0.2218203181400895, "actor_loss": -89.4164383392334, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.50267004966736, "step": 149000}
{"episode_reward": 890.5204266067753, "episode": 150.0, "batch_reward": 0.8846687116622924, "critic_loss": 0.21580176454037428, "actor_loss": -89.20951641845703, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "step": 150000}
