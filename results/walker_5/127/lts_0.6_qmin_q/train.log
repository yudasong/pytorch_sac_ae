{"episode_reward": 0.0, "episode": 1.0, "duration": 22.62404489517212, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.9050402641296387, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.4301557489119597, "critic_loss": 0.5026314664668106, "actor_loss": -75.92843864230262, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 67.11789584159851, "step": 3000}
{"episode_reward": 501.233527792365, "episode": 4.0, "batch_reward": 0.48956818255782125, "critic_loss": 0.6320179434418678, "actor_loss": -78.22525891113281, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.394352197647095, "step": 4000}
{"episode_reward": 759.1585920403886, "episode": 5.0, "batch_reward": 0.5564672214686871, "critic_loss": 0.5504624325633048, "actor_loss": -80.06166706848144, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.616377115249634, "step": 5000}
{"episode_reward": 832.1575934062214, "episode": 6.0, "batch_reward": 0.5970094417631626, "critic_loss": 0.5388099322766066, "actor_loss": -81.11121850585937, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.643494844436646, "step": 6000}
{"episode_reward": 740.0491880450961, "episode": 7.0, "batch_reward": 0.6381619955301285, "critic_loss": 0.43590888419747353, "actor_loss": -82.06846562194825, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.933077335357666, "step": 7000}
{"episode_reward": 904.3861086026175, "episode": 8.0, "batch_reward": 0.6475157850980758, "critic_loss": 0.46183367866277697, "actor_loss": -82.14474800109863, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.227179527282715, "step": 8000}
{"episode_reward": 651.6390650710738, "episode": 9.0, "batch_reward": 0.669629180431366, "critic_loss": 0.4097798957079649, "actor_loss": -82.49041474914551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.5690598487854, "step": 9000}
{"episode_reward": 909.3260679001494, "episode": 10.0, "batch_reward": 0.6511702377796174, "critic_loss": 0.36395433406531813, "actor_loss": -81.43103462219239, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.53831911087036, "step": 10000}
{"episode_reward": 15.527738403848232, "episode": 11.0, "batch_reward": 0.6289037842154502, "critic_loss": 0.37588825799524783, "actor_loss": -80.23886047363281, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 46.47436213493347, "step": 11000}
{"episode_reward": 878.5239153266557, "episode": 12.0, "batch_reward": 0.6536741805076599, "critic_loss": 0.31799822276830675, "actor_loss": -80.71651414489746, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.15461277961731, "step": 12000}
{"episode_reward": 929.7193122030767, "episode": 13.0, "batch_reward": 0.672800602555275, "critic_loss": 0.3121606862396002, "actor_loss": -81.18044708251954, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.7088942527771, "step": 13000}
{"episode_reward": 925.7803408285837, "episode": 14.0, "batch_reward": 0.6627363468408585, "critic_loss": 0.3162722351402044, "actor_loss": -80.95130352783202, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.186933279037476, "step": 14000}
{"episode_reward": 28.119797357676735, "episode": 15.0, "batch_reward": 0.6452541644573212, "critic_loss": 0.28387370362877845, "actor_loss": -80.425060256958, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.33396887779236, "step": 15000}
{"episode_reward": 916.8743496073627, "episode": 16.0, "batch_reward": 0.6608878505825997, "critic_loss": 0.2809517732709646, "actor_loss": -80.64403758239746, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.086568117141724, "step": 16000}
{"episode_reward": 812.250875365504, "episode": 17.0, "batch_reward": 0.6723796297311783, "critic_loss": 0.28857320874929426, "actor_loss": -80.7524550628662, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.415066719055176, "step": 17000}
{"episode_reward": 886.2436907541505, "episode": 18.0, "batch_reward": 0.6861383382678032, "critic_loss": 0.2899386535733938, "actor_loss": -80.87717936706542, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.52406883239746, "step": 18000}
{"episode_reward": 914.3054755094847, "episode": 19.0, "batch_reward": 0.6968599016070366, "critic_loss": 0.2922697254419327, "actor_loss": -81.10295001220703, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.44447422027588, "step": 19000}
{"episode_reward": 940.4139790903187, "episode": 20.0, "batch_reward": 0.7114872207045555, "critic_loss": 0.30183095110952857, "actor_loss": -81.60264552307129, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.040618181228638, "step": 20000}
{"episode_reward": 939.5585472255415, "episode": 21.0, "batch_reward": 0.7230271369814872, "critic_loss": 0.2910927589088678, "actor_loss": -81.66772540283203, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.74517846107483, "step": 21000}
{"episode_reward": 905.6103932520001, "episode": 22.0, "batch_reward": 0.7303064925670624, "critic_loss": 0.2804294438958168, "actor_loss": -82.04956999206543, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.567612409591675, "step": 22000}
{"episode_reward": 935.4411742734122, "episode": 23.0, "batch_reward": 0.7401386750936508, "critic_loss": 0.26358668398857116, "actor_loss": -82.25653134155273, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.41923475265503, "step": 23000}
{"episode_reward": 907.64557508503, "episode": 24.0, "batch_reward": 0.7454921997785569, "critic_loss": 0.2797388980537653, "actor_loss": -82.43167649841308, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.277535676956177, "step": 24000}
{"episode_reward": 884.370424452714, "episode": 25.0, "batch_reward": 0.7444996384978294, "critic_loss": 0.2970908932089806, "actor_loss": -82.54793588256835, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.98179864883423, "step": 25000}
{"episode_reward": 743.5433179263576, "episode": 26.0, "batch_reward": 0.7510668783783913, "critic_loss": 0.3303348103761673, "actor_loss": -82.63305908203125, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.08820152282715, "step": 26000}
{"episode_reward": 878.101483505743, "episode": 27.0, "batch_reward": 0.7567891172170639, "critic_loss": 0.31231655564904215, "actor_loss": -82.7038837890625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.00363802909851, "step": 27000}
{"episode_reward": 952.3778285420008, "episode": 28.0, "batch_reward": 0.7645435664653778, "critic_loss": 0.3192257103174925, "actor_loss": -83.0579114074707, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.062304258346558, "step": 28000}
{"episode_reward": 939.4017990977, "episode": 29.0, "batch_reward": 0.7696976516842842, "critic_loss": 0.37463306595385076, "actor_loss": -83.13507460021972, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.996846437454224, "step": 29000}
{"episode_reward": 879.8965178231698, "episode": 30.0, "batch_reward": 0.7743703208565712, "critic_loss": 0.3413873624503613, "actor_loss": -83.2828462677002, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.128657579421997, "step": 30000}
{"episode_reward": 904.1669968699027, "episode": 31.0, "batch_reward": 0.7781508615612984, "critic_loss": 0.32959799095988274, "actor_loss": -83.43057827758788, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.42750120162964, "step": 31000}
{"episode_reward": 927.7200626467043, "episode": 32.0, "batch_reward": 0.7822493631839752, "critic_loss": 0.31200084096193315, "actor_loss": -83.5641216430664, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.6435649394989, "step": 32000}
{"episode_reward": 924.0885710672264, "episode": 33.0, "batch_reward": 0.7883748352527619, "critic_loss": 0.28087901540100574, "actor_loss": -83.59913352966309, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.01281762123108, "step": 33000}
{"episode_reward": 936.7080162956271, "episode": 34.0, "batch_reward": 0.7930406123995781, "critic_loss": 0.25929297275841234, "actor_loss": -83.78908493041992, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.826443910598755, "step": 34000}
{"episode_reward": 949.516085370495, "episode": 35.0, "batch_reward": 0.7948919730782509, "critic_loss": 0.2500161859989166, "actor_loss": -83.82383924865722, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.506874561309814, "step": 35000}
{"episode_reward": 848.7216539835435, "episode": 36.0, "batch_reward": 0.796526035964489, "critic_loss": 0.25831448458135126, "actor_loss": -84.00887800598144, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.86044955253601, "step": 36000}
{"episode_reward": 875.8426367536407, "episode": 37.0, "batch_reward": 0.8004062812924385, "critic_loss": 0.2419744757860899, "actor_loss": -84.00073922729493, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.797348976135254, "step": 37000}
{"episode_reward": 944.839665343655, "episode": 38.0, "batch_reward": 0.8030264120101929, "critic_loss": 0.27327385849505664, "actor_loss": -84.12166716003418, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.787116289138794, "step": 38000}
{"episode_reward": 936.2736562575765, "episode": 39.0, "batch_reward": 0.806304022192955, "critic_loss": 0.2577576267719269, "actor_loss": -84.24108641052246, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.647207498550415, "step": 39000}
{"episode_reward": 935.5071699104035, "episode": 40.0, "batch_reward": 0.8094354197978973, "critic_loss": 0.2397002837061882, "actor_loss": -84.40109370422363, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.12610912322998, "step": 40000}
{"episode_reward": 958.1954262366869, "episode": 41.0, "batch_reward": 0.8151951182484627, "critic_loss": 0.242090227432549, "actor_loss": -84.48278784179688, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.39770579338074, "step": 41000}
{"episode_reward": 947.3587950316713, "episode": 42.0, "batch_reward": 0.8156951332092285, "critic_loss": 0.2528277166411281, "actor_loss": -84.63109063720704, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.630115032196045, "step": 42000}
{"episode_reward": 832.7568357789647, "episode": 43.0, "batch_reward": 0.8186595237851143, "critic_loss": 0.23595533137768507, "actor_loss": -84.74238040161133, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.446133613586426, "step": 43000}
{"episode_reward": 962.81630532438, "episode": 44.0, "batch_reward": 0.8222544145584106, "critic_loss": 0.22723572082072496, "actor_loss": -84.87807542419434, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.27688455581665, "step": 44000}
{"episode_reward": 958.9030838079216, "episode": 45.0, "batch_reward": 0.8237820520401001, "critic_loss": 0.2323868865892291, "actor_loss": -84.90361968994141, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.087897539138794, "step": 45000}
{"episode_reward": 959.8491315001843, "episode": 46.0, "batch_reward": 0.8260521172881127, "critic_loss": 0.2277745651230216, "actor_loss": -85.05826243591308, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.655951499938965, "step": 46000}
{"episode_reward": 955.3754584617068, "episode": 47.0, "batch_reward": 0.8295922290086746, "critic_loss": 0.23074963204562665, "actor_loss": -85.18096069335938, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.449536561965942, "step": 47000}
{"episode_reward": 908.706682190882, "episode": 48.0, "batch_reward": 0.8298484563827515, "critic_loss": 0.2690188089311123, "actor_loss": -85.24653524780274, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.704503297805786, "step": 48000}
{"episode_reward": 797.8187003675357, "episode": 49.0, "batch_reward": 0.8313859013915061, "critic_loss": 0.25424905520677565, "actor_loss": -85.32080967712402, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.74556064605713, "step": 49000}
{"episode_reward": 961.0650943530004, "episode": 50.0, "batch_reward": 0.8345719745159149, "critic_loss": 0.25987065739929677, "actor_loss": -85.38515559387207, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.901243448257446, "step": 50000}
{"episode_reward": 954.1468109489268, "episode": 51.0, "batch_reward": 0.8352621589303016, "critic_loss": 0.27633949686586856, "actor_loss": -85.39713529968262, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 44.75427198410034, "step": 51000}
{"episode_reward": 882.4123261660702, "episode": 52.0, "batch_reward": 0.8378425791263581, "critic_loss": 0.28229349230229855, "actor_loss": -85.46345329284668, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.991657495498657, "step": 52000}
{"episode_reward": 938.4216637174721, "episode": 53.0, "batch_reward": 0.8389219325780869, "critic_loss": 0.27080516105145214, "actor_loss": -85.53238809204102, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.227268934249878, "step": 53000}
{"episode_reward": 944.1051094623615, "episode": 54.0, "batch_reward": 0.8423991478681564, "critic_loss": 0.247548555418849, "actor_loss": -85.6730517730713, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.17202591896057, "step": 54000}
{"episode_reward": 950.440260217289, "episode": 55.0, "batch_reward": 0.8391215234994889, "critic_loss": 0.2924559643268585, "actor_loss": -85.6561810913086, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.33416175842285, "step": 55000}
{"episode_reward": 712.0199234802975, "episode": 56.0, "batch_reward": 0.8407670620083809, "critic_loss": 0.28646299792826174, "actor_loss": -85.77808137512207, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.628984212875366, "step": 56000}
{"episode_reward": 938.352607806202, "episode": 57.0, "batch_reward": 0.8429268688559532, "critic_loss": 0.27577246095240115, "actor_loss": -85.8376085357666, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.77052068710327, "step": 57000}
{"episode_reward": 938.2691960169359, "episode": 58.0, "batch_reward": 0.8419707799553872, "critic_loss": 0.25053568386286496, "actor_loss": -85.84933396911622, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.387285470962524, "step": 58000}
{"episode_reward": 947.3915295849325, "episode": 59.0, "batch_reward": 0.8461748962402343, "critic_loss": 0.23038067512214183, "actor_loss": -85.96388554382324, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.41620945930481, "step": 59000}
{"episode_reward": 968.639698410752, "episode": 60.0, "batch_reward": 0.847494916677475, "critic_loss": 0.2274079186320305, "actor_loss": -86.06416409301758, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.405685424804688, "step": 60000}
{"episode_reward": 958.1895251835314, "episode": 61.0, "batch_reward": 0.8502695719003678, "critic_loss": 0.21621172793209553, "actor_loss": -86.07743840026855, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.465336322784424, "step": 61000}
{"episode_reward": 927.7925456026047, "episode": 62.0, "batch_reward": 0.8516883538365364, "critic_loss": 0.21167893754690886, "actor_loss": -86.12814503479004, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.213640213012695, "step": 62000}
{"episode_reward": 938.8528551229874, "episode": 63.0, "batch_reward": 0.8519553709626198, "critic_loss": 0.22696831007301807, "actor_loss": -86.17041500854492, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.77442741394043, "step": 63000}
{"episode_reward": 928.080402951591, "episode": 64.0, "batch_reward": 0.8523188124299049, "critic_loss": 0.2054259392991662, "actor_loss": -86.13776135253906, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.76900601387024, "step": 64000}
{"episode_reward": 937.0129137797131, "episode": 65.0, "batch_reward": 0.8541804305911064, "critic_loss": 0.20559307251125575, "actor_loss": -86.21424490356445, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.844162225723267, "step": 65000}
{"episode_reward": 947.8829065788392, "episode": 66.0, "batch_reward": 0.8537255442738533, "critic_loss": 0.21734076024591922, "actor_loss": -86.18448780822754, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.00439190864563, "step": 66000}
{"episode_reward": 896.2476745032805, "episode": 67.0, "batch_reward": 0.8555041384100914, "critic_loss": 0.23710079953819513, "actor_loss": -86.26936880493164, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.39381766319275, "step": 67000}
{"episode_reward": 858.1521237251734, "episode": 68.0, "batch_reward": 0.8556833192706108, "critic_loss": 0.2664411279708147, "actor_loss": -86.18752268981933, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.135468006134033, "step": 68000}
{"episode_reward": 832.4952730152113, "episode": 69.0, "batch_reward": 0.8552372564077377, "critic_loss": 0.2639504090175033, "actor_loss": -86.28406457519532, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.928755283355713, "step": 69000}
{"episode_reward": 891.4393860494433, "episode": 70.0, "batch_reward": 0.8582042825818061, "critic_loss": 0.27726343294233086, "actor_loss": -86.25705326843261, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.140902757644653, "step": 70000}
{"episode_reward": 930.536774880256, "episode": 71.0, "batch_reward": 0.8573271304368972, "critic_loss": 0.26272723244130614, "actor_loss": -86.39216261291504, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 45.50162076950073, "step": 71000}
{"episode_reward": 899.8473589141602, "episode": 72.0, "batch_reward": 0.858382486820221, "critic_loss": 0.2700090117827058, "actor_loss": -86.41408413696288, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.882485151290894, "step": 72000}
{"episode_reward": 925.8842294571572, "episode": 73.0, "batch_reward": 0.858725765645504, "critic_loss": 0.2776582089290023, "actor_loss": -86.38922007751465, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.567459106445312, "step": 73000}
{"episode_reward": 900.1302063596978, "episode": 74.0, "batch_reward": 0.8591408979892731, "critic_loss": 0.2892333470061421, "actor_loss": -86.40123779296874, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.06991934776306, "step": 74000}
{"episode_reward": 935.6759733852455, "episode": 75.0, "batch_reward": 0.8593767892718315, "critic_loss": 0.2856200472712517, "actor_loss": -86.41939784240722, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.86286997795105, "step": 75000}
{"episode_reward": 911.3187948039002, "episode": 76.0, "batch_reward": 0.8614466971755028, "critic_loss": 0.2663750250712037, "actor_loss": -86.45663246154785, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.061023473739624, "step": 76000}
{"episode_reward": 879.722934841959, "episode": 77.0, "batch_reward": 0.8600557395219803, "critic_loss": 0.27321219654381274, "actor_loss": -86.47518670654297, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.41250443458557, "step": 77000}
{"episode_reward": 912.216147317833, "episode": 78.0, "batch_reward": 0.8627828441858292, "critic_loss": 0.26705272199213503, "actor_loss": -86.56168663024903, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.026430368423462, "step": 78000}
{"episode_reward": 963.1827449358364, "episode": 79.0, "batch_reward": 0.8647506613731384, "critic_loss": 0.2716813124641776, "actor_loss": -86.59639677429199, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.936092853546143, "step": 79000}
{"episode_reward": 931.9398430624109, "episode": 80.0, "batch_reward": 0.864238611638546, "critic_loss": 0.2591853190436959, "actor_loss": -86.54502149963379, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.65979290008545, "step": 80000}
{"episode_reward": 952.0723331256175, "episode": 81.0, "batch_reward": 0.8657602140307427, "critic_loss": 0.2587336558699608, "actor_loss": -86.66976406860351, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 44.45165181159973, "step": 81000}
{"episode_reward": 903.7229110396526, "episode": 82.0, "batch_reward": 0.8657413247227669, "critic_loss": 0.2634513949379325, "actor_loss": -86.65233467102051, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.573837757110596, "step": 82000}
{"episode_reward": 940.2307952895724, "episode": 83.0, "batch_reward": 0.8691561250090599, "critic_loss": 0.27274151530116797, "actor_loss": -86.69805685424805, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.720571041107178, "step": 83000}
{"episode_reward": 960.318454154047, "episode": 84.0, "batch_reward": 0.8671611341834068, "critic_loss": 0.27657089657336476, "actor_loss": -86.68611317443847, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.546858072280884, "step": 84000}
{"episode_reward": 876.3950158400085, "episode": 85.0, "batch_reward": 0.8681555485129356, "critic_loss": 0.2602078780084848, "actor_loss": -86.70550010681153, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.35031223297119, "step": 85000}
{"episode_reward": 937.9717889969194, "episode": 86.0, "batch_reward": 0.869500532925129, "critic_loss": 0.26452380783855917, "actor_loss": -86.80139430236817, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.512566804885864, "step": 86000}
{"episode_reward": 966.8451406612701, "episode": 87.0, "batch_reward": 0.8711943289041519, "critic_loss": 0.26634210968762634, "actor_loss": -86.82028273010253, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.328420877456665, "step": 87000}
{"episode_reward": 948.831126678961, "episode": 88.0, "batch_reward": 0.8709155188202858, "critic_loss": 0.262180605776608, "actor_loss": -86.84692472839356, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.381232261657715, "step": 88000}
{"episode_reward": 924.0232567167214, "episode": 89.0, "batch_reward": 0.8712606990933418, "critic_loss": 0.2537185571715236, "actor_loss": -86.85793479919434, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.808035850524902, "step": 89000}
{"episode_reward": 917.8817120435326, "episode": 90.0, "batch_reward": 0.873136526465416, "critic_loss": 0.24789400456100702, "actor_loss": -86.97819912719727, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.02423620223999, "step": 90000}
{"episode_reward": 907.5033603840303, "episode": 91.0, "batch_reward": 0.8731667802333832, "critic_loss": 0.27133651775866746, "actor_loss": -87.03209683227539, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.587653398513794, "step": 91000}
{"episode_reward": 938.8500224197065, "episode": 92.0, "batch_reward": 0.8730676640868187, "critic_loss": 0.23916249527782202, "actor_loss": -87.00630075073242, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.45307731628418, "step": 92000}
{"episode_reward": 921.9099853091154, "episode": 93.0, "batch_reward": 0.8731474022865295, "critic_loss": 0.25994522915035484, "actor_loss": -87.13372373962402, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.881055116653442, "step": 93000}
{"episode_reward": 921.0726244754247, "episode": 94.0, "batch_reward": 0.8732596790194511, "critic_loss": 0.25996986813098194, "actor_loss": -87.02191375732421, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.553663969039917, "step": 94000}
{"episode_reward": 872.4195525956757, "episode": 95.0, "batch_reward": 0.8741788030862808, "critic_loss": 0.2636371887177229, "actor_loss": -86.96935554504394, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.95085859298706, "step": 95000}
{"episode_reward": 915.2940490419559, "episode": 96.0, "batch_reward": 0.8753943804502488, "critic_loss": 0.2588252857029438, "actor_loss": -87.13715260314942, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.258193016052246, "step": 96000}
{"episode_reward": 929.1144507167048, "episode": 97.0, "batch_reward": 0.8751920209527015, "critic_loss": 0.26135494985431434, "actor_loss": -87.23562535095215, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.09977960586548, "step": 97000}
{"episode_reward": 966.6483507321311, "episode": 98.0, "batch_reward": 0.8765774854421615, "critic_loss": 0.23555943962931633, "actor_loss": -87.11346815490722, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.356861352920532, "step": 98000}
{"episode_reward": 956.6554022117978, "episode": 99.0, "batch_reward": 0.8782055020332337, "critic_loss": 0.24144057584553957, "actor_loss": -87.23987606811524, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.610119819641113, "step": 99000}
{"episode_reward": 965.2379535228586, "episode": 100.0, "batch_reward": 0.87776620221138, "critic_loss": 0.24059613797068596, "actor_loss": -87.2524134979248, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.193633317947388, "step": 100000}
{"episode_reward": 929.8120048202069, "episode": 101.0, "batch_reward": 0.8783928871750831, "critic_loss": 0.23624839132279157, "actor_loss": -87.40785049438476, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 46.51716160774231, "step": 101000}
{"episode_reward": 941.4271062071011, "episode": 102.0, "batch_reward": 0.8801063965559006, "critic_loss": 0.23472549371421336, "actor_loss": -87.31344082641601, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.489067316055298, "step": 102000}
{"episode_reward": 968.7674221247022, "episode": 103.0, "batch_reward": 0.8790130588412285, "critic_loss": 0.22948195134103297, "actor_loss": -87.28274632263184, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.451565504074097, "step": 103000}
{"episode_reward": 964.2042876551717, "episode": 104.0, "batch_reward": 0.8821399076581001, "critic_loss": 0.22610098398476838, "actor_loss": -87.51294291687012, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.72353959083557, "step": 104000}
{"episode_reward": 921.4052665638841, "episode": 105.0, "batch_reward": 0.8809277149438858, "critic_loss": 0.25967067562788726, "actor_loss": -87.45613772583008, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.42182993888855, "step": 105000}
{"episode_reward": 920.9497701939866, "episode": 106.0, "batch_reward": 0.8812354679703712, "critic_loss": 0.2409351527169347, "actor_loss": -87.5351800994873, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.888839721679688, "step": 106000}
{"episode_reward": 950.2027686505388, "episode": 107.0, "batch_reward": 0.8807351369857788, "critic_loss": 0.23990116167813538, "actor_loss": -87.56504579162598, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.903444290161133, "step": 107000}
{"episode_reward": 940.1706151770544, "episode": 108.0, "batch_reward": 0.8826802423596383, "critic_loss": 0.24175680086016654, "actor_loss": -87.41567851257324, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.834453582763672, "step": 108000}
{"episode_reward": 927.9708628407888, "episode": 109.0, "batch_reward": 0.8837400714159012, "critic_loss": 0.23721432024985553, "actor_loss": -87.56410601806641, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.830528259277344, "step": 109000}
{"episode_reward": 921.6478431013496, "episode": 110.0, "batch_reward": 0.883653005182743, "critic_loss": 0.2483263497054577, "actor_loss": -87.43920159912109, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.78993558883667, "step": 110000}
{"episode_reward": 900.8155853173477, "episode": 111.0, "batch_reward": 0.8838517922759056, "critic_loss": 0.23266695956885813, "actor_loss": -87.60907360839843, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 43.56544637680054, "step": 111000}
{"episode_reward": 959.826383348437, "episode": 112.0, "batch_reward": 0.8839109499454498, "critic_loss": 0.2302420019581914, "actor_loss": -87.50111828613281, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.280918836593628, "step": 112000}
{"episode_reward": 944.696068944992, "episode": 113.0, "batch_reward": 0.886389180958271, "critic_loss": 0.2307704935744405, "actor_loss": -87.68137538146972, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.501126050949097, "step": 113000}
{"episode_reward": 952.6627578425721, "episode": 114.0, "batch_reward": 0.8862387638092041, "critic_loss": 0.21382770930975675, "actor_loss": -87.6171706237793, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.007019996643066, "step": 114000}
{"episode_reward": 932.3256422874678, "episode": 115.0, "batch_reward": 0.8861879895925522, "critic_loss": 0.21462116335332393, "actor_loss": -87.63498594665528, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.069726705551147, "step": 115000}
{"episode_reward": 959.0772991817238, "episode": 116.0, "batch_reward": 0.8874671170711518, "critic_loss": 0.21466589660942553, "actor_loss": -87.65106855773925, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.698717832565308, "step": 116000}
{"episode_reward": 962.2659252513298, "episode": 117.0, "batch_reward": 0.8882008392810822, "critic_loss": 0.2335514442101121, "actor_loss": -87.80239633178711, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.362252712249756, "step": 117000}
{"episode_reward": 952.1272755998646, "episode": 118.0, "batch_reward": 0.8881103353500366, "critic_loss": 0.2251165827512741, "actor_loss": -87.76311285400391, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.195579290390015, "step": 118000}
{"episode_reward": 915.7228351846609, "episode": 119.0, "batch_reward": 0.8893456056118011, "critic_loss": 0.23159642761945726, "actor_loss": -87.78079698181152, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.14860486984253, "step": 119000}
{"episode_reward": 932.9193899701082, "episode": 120.0, "batch_reward": 0.8890718995332718, "critic_loss": 0.21159369207918644, "actor_loss": -87.84232960510253, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.568283796310425, "step": 120000}
{"episode_reward": 954.5566326952562, "episode": 121.0, "batch_reward": 0.8899277001023292, "critic_loss": 0.2164978219345212, "actor_loss": -87.84445883178711, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 45.9181969165802, "step": 121000}
{"episode_reward": 928.4303141359547, "episode": 122.0, "batch_reward": 0.8892846213579177, "critic_loss": 0.22342233895510435, "actor_loss": -87.78592475891114, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.04209041595459, "step": 122000}
{"episode_reward": 903.7299278810206, "episode": 123.0, "batch_reward": 0.889652162194252, "critic_loss": 0.2160642104111612, "actor_loss": -87.89802526855469, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.528501510620117, "step": 123000}
{"episode_reward": 939.5961950863298, "episode": 124.0, "batch_reward": 0.8891601067781448, "critic_loss": 0.22052561669796705, "actor_loss": -87.73462631225586, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.154203414916992, "step": 124000}
{"episode_reward": 954.1163998910052, "episode": 125.0, "batch_reward": 0.8893219578266144, "critic_loss": 0.21223972391337156, "actor_loss": -87.83717147827149, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.0848708152771, "step": 125000}
{"episode_reward": 917.1653996373212, "episode": 126.0, "batch_reward": 0.889553737461567, "critic_loss": 0.21290955846756696, "actor_loss": -87.83442358398437, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.82378315925598, "step": 126000}
{"episode_reward": 959.6996319967599, "episode": 127.0, "batch_reward": 0.8909994887709618, "critic_loss": 0.21996626006811856, "actor_loss": -87.86100459289551, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.360010385513306, "step": 127000}
{"episode_reward": 936.184271063857, "episode": 128.0, "batch_reward": 0.891832304418087, "critic_loss": 0.21553224328160286, "actor_loss": -87.88519776916505, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.529815196990967, "step": 128000}
{"episode_reward": 934.2593738344593, "episode": 129.0, "batch_reward": 0.8917239482998848, "critic_loss": 0.21382704557478427, "actor_loss": -87.95242077636719, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.537742137908936, "step": 129000}
{"episode_reward": 955.3499080119208, "episode": 130.0, "batch_reward": 0.891494225859642, "critic_loss": 0.21752846927195787, "actor_loss": -87.9109686126709, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.624581575393677, "step": 130000}
{"episode_reward": 887.0819048888018, "episode": 131.0, "batch_reward": 0.8925485075116157, "critic_loss": 0.2156308064237237, "actor_loss": -88.03549722290039, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 42.805461168289185, "step": 131000}
{"episode_reward": 941.5913921179456, "episode": 132.0, "batch_reward": 0.8917655821442604, "critic_loss": 0.21605467078089713, "actor_loss": -87.92340260314941, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.77989625930786, "step": 132000}
{"episode_reward": 897.9773143402143, "episode": 133.0, "batch_reward": 0.892837371647358, "critic_loss": 0.21310940514132382, "actor_loss": -88.11233944702148, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.861083030700684, "step": 133000}
{"episode_reward": 959.1003274217993, "episode": 134.0, "batch_reward": 0.8928111968636513, "critic_loss": 0.221367390550673, "actor_loss": -88.05077206420899, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.108335494995117, "step": 134000}
{"episode_reward": 956.9854016450277, "episode": 135.0, "batch_reward": 0.8916322227716446, "critic_loss": 0.21689997516945003, "actor_loss": -87.95388276672364, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.6944260597229, "step": 135000}
{"episode_reward": 897.8050579645677, "episode": 136.0, "batch_reward": 0.8941909815073014, "critic_loss": 0.22074922808259725, "actor_loss": -88.05341033935547, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.437001943588257, "step": 136000}
{"episode_reward": 891.9798377732883, "episode": 137.0, "batch_reward": 0.8935821672081947, "critic_loss": 0.21621041987836362, "actor_loss": -88.10765385437011, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.544383764266968, "step": 137000}
{"episode_reward": 889.6874640853587, "episode": 138.0, "batch_reward": 0.8936384916305542, "critic_loss": 0.22920890718698503, "actor_loss": -88.02583416748047, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.47258949279785, "step": 138000}
{"episode_reward": 961.6157911978502, "episode": 139.0, "batch_reward": 0.8930784752964973, "critic_loss": 0.2187285846620798, "actor_loss": -88.08747648620606, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.657307147979736, "step": 139000}
{"episode_reward": 909.1319266541295, "episode": 140.0, "batch_reward": 0.8940250850319862, "critic_loss": 0.22170135766267776, "actor_loss": -87.9898286743164, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.10465908050537, "step": 140000}
{"episode_reward": 952.8552763459508, "episode": 141.0, "batch_reward": 0.896164025247097, "critic_loss": 0.20976960804313421, "actor_loss": -88.173873046875, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 45.50226640701294, "step": 141000}
{"episode_reward": 946.4058403581943, "episode": 142.0, "batch_reward": 0.8951219450235367, "critic_loss": 0.21335793946683407, "actor_loss": -88.18905001831055, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.323240041732788, "step": 142000}
{"episode_reward": 959.9941867146538, "episode": 143.0, "batch_reward": 0.8953795688748359, "critic_loss": 0.21186277863383293, "actor_loss": -88.23609773254394, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.501879453659058, "step": 143000}
{"episode_reward": 931.8165442913601, "episode": 144.0, "batch_reward": 0.8950666272044182, "critic_loss": 0.21970795730501413, "actor_loss": -88.09320402526855, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.392844438552856, "step": 144000}
{"episode_reward": 934.463517036072, "episode": 145.0, "batch_reward": 0.8968545274138451, "critic_loss": 0.21330140593647956, "actor_loss": -88.1434504852295, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.089169025421143, "step": 145000}
{"episode_reward": 937.9584757292301, "episode": 146.0, "batch_reward": 0.8950613783597946, "critic_loss": 0.21242501948028802, "actor_loss": -88.21547822570801, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.500515937805176, "step": 146000}
{"episode_reward": 910.0027393830796, "episode": 147.0, "batch_reward": 0.8957236164808273, "critic_loss": 0.21348446461185813, "actor_loss": -88.21516539001465, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.15580725669861, "step": 147000}
{"episode_reward": 923.7396720004551, "episode": 148.0, "batch_reward": 0.8957940856814385, "critic_loss": 0.2301146765910089, "actor_loss": -88.19508457946777, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.87250280380249, "step": 148000}
{"episode_reward": 911.5774979936542, "episode": 149.0, "batch_reward": 0.8959300200939179, "critic_loss": 0.22007835453748703, "actor_loss": -88.23235621643066, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.011158227920532, "step": 149000}
{"episode_reward": 915.2505206972049, "episode": 150.0, "batch_reward": 0.8964763553142547, "critic_loss": 0.24397958919405938, "actor_loss": -88.20774514770508, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "step": 150000}
