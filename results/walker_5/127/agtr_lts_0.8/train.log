{"episode_reward": 0.0, "episode": 1.0, "duration": 20.288728952407837, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.7685260772705078, "step": 2000}
{"episode_reward": 896.1586144851467, "episode": 3.0, "batch_reward": 0.5024101815051976, "critic_loss": 0.25790083102034744, "actor_loss": -86.51601372971064, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.39804005622864, "step": 3000}
{"episode_reward": 834.7574063593106, "episode": 4.0, "batch_reward": 0.6483494587540627, "critic_loss": 0.18943404076248407, "actor_loss": -89.48120404052735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98564338684082, "step": 4000}
{"episode_reward": 979.4622603096337, "episode": 5.0, "batch_reward": 0.7155085483789444, "critic_loss": 0.21808149132877588, "actor_loss": -90.88681385803223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98206901550293, "step": 5000}
{"episode_reward": 954.1890918661904, "episode": 6.0, "batch_reward": 0.6861610009670257, "critic_loss": 0.21878317172080278, "actor_loss": -90.00079898071289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.008813619613647, "step": 6000}
{"episode_reward": 38.11544098519889, "episode": 7.0, "batch_reward": 0.6517615125775337, "critic_loss": 0.2031815063804388, "actor_loss": -88.75102534484863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.972938537597656, "step": 7000}
{"episode_reward": 963.0457064846361, "episode": 8.0, "batch_reward": 0.6912717130184174, "critic_loss": 0.22874296379089357, "actor_loss": -89.55867544555664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.972846746444702, "step": 8000}
{"episode_reward": 954.8442547866392, "episode": 9.0, "batch_reward": 0.7261522390246391, "critic_loss": 0.24646429447084664, "actor_loss": -90.47529930114746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990567207336426, "step": 9000}
{"episode_reward": 986.3262499726549, "episode": 10.0, "batch_reward": 0.7443791384696961, "critic_loss": 0.36481483045220375, "actor_loss": -90.83418397521973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.978822231292725, "step": 10000}
{"episode_reward": 895.0007310466292, "episode": 11.0, "batch_reward": 0.7444455711245537, "critic_loss": 0.590426403939724, "actor_loss": -90.58615295410156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.09102439880371, "step": 11000}
{"episode_reward": 690.1462213010777, "episode": 12.0, "batch_reward": 0.7523237851262092, "critic_loss": 0.5070692473948002, "actor_loss": -90.7353522491455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97867751121521, "step": 12000}
{"episode_reward": 906.7603259870093, "episode": 13.0, "batch_reward": 0.7694151612520218, "critic_loss": 0.5036404137015342, "actor_loss": -91.23694763183593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.985838413238525, "step": 13000}
{"episode_reward": 960.2198882354988, "episode": 14.0, "batch_reward": 0.7792456986308098, "critic_loss": 0.6229913543462753, "actor_loss": -91.58586964416504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.970001220703125, "step": 14000}
{"episode_reward": 895.8071701331071, "episode": 15.0, "batch_reward": 0.7900838790535927, "critic_loss": 0.49762128069996836, "actor_loss": -92.14490373229981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97874903678894, "step": 15000}
{"episode_reward": 955.1737799185948, "episode": 16.0, "batch_reward": 0.8019442297220231, "critic_loss": 0.4884338347315788, "actor_loss": -92.60149780273437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.970953702926636, "step": 16000}
{"episode_reward": 950.0664948038545, "episode": 17.0, "batch_reward": 0.8079630817174912, "critic_loss": 0.5820517290830612, "actor_loss": -92.71046282958984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.983019590377808, "step": 17000}
{"episode_reward": 893.4330223020993, "episode": 18.0, "batch_reward": 0.8158377315402031, "critic_loss": 0.5223536413758993, "actor_loss": -92.89413519287109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98591899871826, "step": 18000}
{"episode_reward": 921.6230675329564, "episode": 19.0, "batch_reward": 0.8217572984099388, "critic_loss": 0.48892469412088396, "actor_loss": -92.99303717041016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.983985900878906, "step": 19000}
{"episode_reward": 915.5126563152072, "episode": 20.0, "batch_reward": 0.8268816912770272, "critic_loss": 0.4507652800157666, "actor_loss": -93.16906202697754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986119985580444, "step": 20000}
{"episode_reward": 971.1182759487958, "episode": 21.0, "batch_reward": 0.8338330455422401, "critic_loss": 0.44491384087502955, "actor_loss": -93.02967063903809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.10853981971741, "step": 21000}
{"episode_reward": 928.0095429626286, "episode": 22.0, "batch_reward": 0.8350899202227593, "critic_loss": 0.45541539035737516, "actor_loss": -93.2392778930664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981918334960938, "step": 22000}
{"episode_reward": 918.9125645983573, "episode": 23.0, "batch_reward": 0.8413252227902412, "critic_loss": 0.46188133008778093, "actor_loss": -93.21441073608399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98534345626831, "step": 23000}
{"episode_reward": 950.4256735977873, "episode": 24.0, "batch_reward": 0.8458775502443313, "critic_loss": 0.40726290564984086, "actor_loss": -93.43066673278808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97711205482483, "step": 24000}
{"episode_reward": 964.2115136250276, "episode": 25.0, "batch_reward": 0.8491595786809921, "critic_loss": 0.42444922825694087, "actor_loss": -93.58879330444336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.305119037628174, "step": 25000}
{"episode_reward": 883.4004957512925, "episode": 26.0, "batch_reward": 0.8517909578084946, "critic_loss": 0.3820914039760828, "actor_loss": -93.48481730651855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97098135948181, "step": 26000}
{"episode_reward": 987.2024398009149, "episode": 27.0, "batch_reward": 0.8577709992527962, "critic_loss": 0.4062819966375828, "actor_loss": -93.75305278015136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94542169570923, "step": 27000}
{"episode_reward": 985.8749257450406, "episode": 28.0, "batch_reward": 0.862239185988903, "critic_loss": 0.41443494546413423, "actor_loss": -93.87688087463378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.957845449447632, "step": 28000}
{"episode_reward": 933.3756264674465, "episode": 29.0, "batch_reward": 0.8639454913139343, "critic_loss": 0.3864877345487475, "actor_loss": -94.0158641204834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.974886655807495, "step": 29000}
{"episode_reward": 950.5914856579851, "episode": 30.0, "batch_reward": 0.8694522767066956, "critic_loss": 0.3910272206962109, "actor_loss": -94.05025459289551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97670602798462, "step": 30000}
{"episode_reward": 946.0295241077079, "episode": 31.0, "batch_reward": 0.8690531965494156, "critic_loss": 0.4576461466550827, "actor_loss": -94.15889262390137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.10114312171936, "step": 31000}
{"episode_reward": 902.416526536962, "episode": 32.0, "batch_reward": 0.8680237985253334, "critic_loss": 0.4028262977600098, "actor_loss": -94.16900297546387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.295467376708984, "step": 32000}
{"episode_reward": 864.0646669649559, "episode": 33.0, "batch_reward": 0.8706847629547119, "critic_loss": 0.3579875009804964, "actor_loss": -94.18260992431641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96068525314331, "step": 33000}
{"episode_reward": 953.3830121560063, "episode": 34.0, "batch_reward": 0.8747579725384712, "critic_loss": 0.3414015325307846, "actor_loss": -94.35737269592285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95734667778015, "step": 34000}
{"episode_reward": 984.5040862228535, "episode": 35.0, "batch_reward": 0.8733138897418976, "critic_loss": 0.4455646312534809, "actor_loss": -94.26391046142578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.970815420150757, "step": 35000}
{"episode_reward": 803.1609318529263, "episode": 36.0, "batch_reward": 0.8763846006989479, "critic_loss": 0.4215122867524624, "actor_loss": -94.43861103820801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.979828119277954, "step": 36000}
{"episode_reward": 961.5734885621234, "episode": 37.0, "batch_reward": 0.8776656187176705, "critic_loss": 0.4398817929849029, "actor_loss": -94.3994649963379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98130202293396, "step": 37000}
{"episode_reward": 980.4859793557154, "episode": 38.0, "batch_reward": 0.8792731925845146, "critic_loss": 0.4270414525866508, "actor_loss": -94.39116152954101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97872543334961, "step": 38000}
{"episode_reward": 947.9632297835232, "episode": 39.0, "batch_reward": 0.8809182448983193, "critic_loss": 0.39745152279734614, "actor_loss": -94.39079728698731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98593235015869, "step": 39000}
{"episode_reward": 965.123883451712, "episode": 40.0, "batch_reward": 0.88399578332901, "critic_loss": 0.38113060861080883, "actor_loss": -94.58454585266114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.984369039535522, "step": 40000}
{"episode_reward": 980.4367899404492, "episode": 41.0, "batch_reward": 0.8846848096251487, "critic_loss": 0.3531039916500449, "actor_loss": -94.59525146484376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.10452365875244, "step": 41000}
{"episode_reward": 950.3934829944126, "episode": 42.0, "batch_reward": 0.886840037703514, "critic_loss": 0.3595509338453412, "actor_loss": -94.69716340637207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9822518825531, "step": 42000}
{"episode_reward": 957.7592335241352, "episode": 43.0, "batch_reward": 0.8888131590485573, "critic_loss": 0.36157344504445793, "actor_loss": -94.77345512390137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981828927993774, "step": 43000}
{"episode_reward": 985.4198454397002, "episode": 44.0, "batch_reward": 0.8907142930626869, "critic_loss": 0.3285634649842977, "actor_loss": -95.01426281738281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.976032495498657, "step": 44000}
{"episode_reward": 974.4528836140596, "episode": 45.0, "batch_reward": 0.8925979813337326, "critic_loss": 0.3068495446816087, "actor_loss": -94.96786846923828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9937641620636, "step": 45000}
{"episode_reward": 986.6935020873252, "episode": 46.0, "batch_reward": 0.8952557331323624, "critic_loss": 0.27772045194357636, "actor_loss": -94.98013558959961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.980013132095337, "step": 46000}
{"episode_reward": 987.6492575268072, "episode": 47.0, "batch_reward": 0.8985001522898673, "critic_loss": 0.2814192568287253, "actor_loss": -95.09204972839356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.992745876312256, "step": 47000}
{"episode_reward": 962.7933828167945, "episode": 48.0, "batch_reward": 0.8970209949016571, "critic_loss": 0.3003703134730458, "actor_loss": -95.04840184020996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98196268081665, "step": 48000}
{"episode_reward": 917.1959882169587, "episode": 49.0, "batch_reward": 0.8986293506026268, "critic_loss": 0.33221792663633826, "actor_loss": -95.2310322265625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99429965019226, "step": 49000}
{"episode_reward": 976.4270930551904, "episode": 50.0, "batch_reward": 0.9009667900204659, "critic_loss": 0.2824815927147865, "actor_loss": -95.22198164367676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.978347301483154, "step": 50000}
{"episode_reward": 964.1088139490884, "episode": 51.0, "batch_reward": 0.9021061559319496, "critic_loss": 0.2651773317679763, "actor_loss": -95.29524255371093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.14602446556091, "step": 51000}
{"episode_reward": 928.5022260696263, "episode": 52.0, "batch_reward": 0.9036884312629699, "critic_loss": 0.2628674408942461, "actor_loss": -95.23841773986817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98015022277832, "step": 52000}
{"episode_reward": 955.9983671995117, "episode": 53.0, "batch_reward": 0.9035616427659988, "critic_loss": 0.2943254282474518, "actor_loss": -95.3931441192627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98469114303589, "step": 53000}
{"episode_reward": 950.1453140136139, "episode": 54.0, "batch_reward": 0.9043360108733177, "critic_loss": 0.3153385966867209, "actor_loss": -95.42283459472657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981584548950195, "step": 54000}
{"episode_reward": 970.973129871657, "episode": 55.0, "batch_reward": 0.9052931351065636, "critic_loss": 0.2898655433803797, "actor_loss": -95.4412924041748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98260521888733, "step": 55000}
{"episode_reward": 947.4850815468448, "episode": 56.0, "batch_reward": 0.9054799258708954, "critic_loss": 0.29457786548137666, "actor_loss": -95.44452883911133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981422185897827, "step": 56000}
{"episode_reward": 956.197901390707, "episode": 57.0, "batch_reward": 0.9081469356417656, "critic_loss": 0.29846986079216004, "actor_loss": -95.52762997436524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99070382118225, "step": 57000}
{"episode_reward": 964.8633359228413, "episode": 58.0, "batch_reward": 0.9074887042045593, "critic_loss": 0.2912380876466632, "actor_loss": -95.55313575744628, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.989078760147095, "step": 58000}
{"episode_reward": 958.9028912502035, "episode": 59.0, "batch_reward": 0.9099939975738526, "critic_loss": 0.28457968175411225, "actor_loss": -95.56880685424805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99000120162964, "step": 59000}
{"episode_reward": 980.3367853236425, "episode": 60.0, "batch_reward": 0.9107587221860886, "critic_loss": 0.2915777388289571, "actor_loss": -95.65662065124512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990458965301514, "step": 60000}
{"episode_reward": 963.561965323853, "episode": 61.0, "batch_reward": 0.911497543990612, "critic_loss": 0.30544033768773077, "actor_loss": -95.59697261047363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.15567398071289, "step": 61000}
{"episode_reward": 965.0878342450223, "episode": 62.0, "batch_reward": 0.9120510414242744, "critic_loss": 0.303400337472558, "actor_loss": -95.63264263916015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99036169052124, "step": 62000}
{"episode_reward": 958.3723867554639, "episode": 63.0, "batch_reward": 0.9128855226635932, "critic_loss": 0.28996939717233183, "actor_loss": -95.69467744445801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98545241355896, "step": 63000}
{"episode_reward": 978.9620676332753, "episode": 64.0, "batch_reward": 0.9136237820982933, "critic_loss": 0.375687764339149, "actor_loss": -95.72175193786622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.987523317337036, "step": 64000}
{"episode_reward": 888.3622543610691, "episode": 65.0, "batch_reward": 0.913329975605011, "critic_loss": 0.33674043174833057, "actor_loss": -95.7062024230957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.987277030944824, "step": 65000}
{"episode_reward": 978.4817586336602, "episode": 66.0, "batch_reward": 0.913612868309021, "critic_loss": 0.3204904920682311, "actor_loss": -95.66727751159668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006242513656616, "step": 66000}
{"episode_reward": 913.9341776491385, "episode": 67.0, "batch_reward": 0.9137750549912452, "critic_loss": 0.3032974180206656, "actor_loss": -95.76234419250488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007763624191284, "step": 67000}
{"episode_reward": 960.9048745069618, "episode": 68.0, "batch_reward": 0.913763833642006, "critic_loss": 0.31815181006491183, "actor_loss": -95.7523881225586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99190354347229, "step": 68000}
{"episode_reward": 897.4109138483935, "episode": 69.0, "batch_reward": 0.9131229831576347, "critic_loss": 0.35636788538098335, "actor_loss": -95.65619087219238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99439811706543, "step": 69000}
{"episode_reward": 940.2752703385613, "episode": 70.0, "batch_reward": 0.9150998811125756, "critic_loss": 0.34587582333385947, "actor_loss": -95.68984121704102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986401319503784, "step": 70000}
{"episode_reward": 945.7855032436969, "episode": 71.0, "batch_reward": 0.9158119131922722, "critic_loss": 0.35750241179019215, "actor_loss": -95.68843771362305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.12440323829651, "step": 71000}
{"episode_reward": 930.5194474629685, "episode": 72.0, "batch_reward": 0.9150226399302482, "critic_loss": 0.353695484675467, "actor_loss": -95.76967268371583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99098777770996, "step": 72000}
{"episode_reward": 965.1207713075078, "episode": 73.0, "batch_reward": 0.9173703330159187, "critic_loss": 0.404568573795259, "actor_loss": -95.77139575195312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01278591156006, "step": 73000}
{"episode_reward": 938.251614196448, "episode": 74.0, "batch_reward": 0.9156724145412445, "critic_loss": 0.3715622191354632, "actor_loss": -95.6954967956543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98387861251831, "step": 74000}
{"episode_reward": 937.6415454629748, "episode": 75.0, "batch_reward": 0.9175528169274331, "critic_loss": 0.3723755325078964, "actor_loss": -95.71566192626953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002524375915527, "step": 75000}
{"episode_reward": 933.862092270291, "episode": 76.0, "batch_reward": 0.9165149925351143, "critic_loss": 0.4113407205268741, "actor_loss": -95.74836357116699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.983511924743652, "step": 76000}
{"episode_reward": 886.0044158501531, "episode": 77.0, "batch_reward": 0.9153582474589348, "critic_loss": 0.4136431589201093, "actor_loss": -95.70483462524415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.991358280181885, "step": 77000}
{"episode_reward": 915.3580583417373, "episode": 78.0, "batch_reward": 0.9173817146420479, "critic_loss": 0.42038266234844923, "actor_loss": -95.78913055419922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.017528533935547, "step": 78000}
{"episode_reward": 979.2934952733129, "episode": 79.0, "batch_reward": 0.9180563658475875, "critic_loss": 0.4179139883965254, "actor_loss": -95.85491920471192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.030659198760986, "step": 79000}
{"episode_reward": 956.0212806772739, "episode": 80.0, "batch_reward": 0.9187294788360596, "critic_loss": 0.41557412277907135, "actor_loss": -95.80839804077148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.991195917129517, "step": 80000}
{"episode_reward": 964.1796315558568, "episode": 81.0, "batch_reward": 0.9192895289659501, "critic_loss": 0.43326913461834193, "actor_loss": -95.75913446044922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.142454624176025, "step": 81000}
{"episode_reward": 921.7513738581139, "episode": 82.0, "batch_reward": 0.9170765815973282, "critic_loss": 0.40967545233666897, "actor_loss": -95.73193804931641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.984954357147217, "step": 82000}
{"episode_reward": 961.8158128836777, "episode": 83.0, "batch_reward": 0.9204165281653405, "critic_loss": 0.4427809787616134, "actor_loss": -95.8766471862793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.991886138916016, "step": 83000}
{"episode_reward": 976.8575932257802, "episode": 84.0, "batch_reward": 0.91920959597826, "critic_loss": 0.3902642940506339, "actor_loss": -95.92712118530274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993201971054077, "step": 84000}
{"episode_reward": 940.4568631526043, "episode": 85.0, "batch_reward": 0.9191114575862884, "critic_loss": 0.3837874410897493, "actor_loss": -95.88088973999024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99310278892517, "step": 85000}
{"episode_reward": 938.2241254462228, "episode": 86.0, "batch_reward": 0.920865905046463, "critic_loss": 0.39189421202987434, "actor_loss": -95.86248782348633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986828088760376, "step": 86000}
{"episode_reward": 965.3628038755328, "episode": 87.0, "batch_reward": 0.9218353066444397, "critic_loss": 0.3727979410886765, "actor_loss": -95.89109083557129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98777985572815, "step": 87000}
{"episode_reward": 984.1185648851847, "episode": 88.0, "batch_reward": 0.9218628703355789, "critic_loss": 0.3834867426678538, "actor_loss": -95.86460404968261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993520498275757, "step": 88000}
{"episode_reward": 955.7321097557516, "episode": 89.0, "batch_reward": 0.9212343841195106, "critic_loss": 0.3943567630127072, "actor_loss": -95.90291004943847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986430883407593, "step": 89000}
{"episode_reward": 914.194130832825, "episode": 90.0, "batch_reward": 0.9227843900322914, "critic_loss": 0.3975310648754239, "actor_loss": -95.91033786010742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.992772817611694, "step": 90000}
{"episode_reward": 944.1901723770804, "episode": 91.0, "batch_reward": 0.9224915755391121, "critic_loss": 0.4066733183786273, "actor_loss": -95.91872781372071, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.12207651138306, "step": 91000}
{"episode_reward": 985.9835751493409, "episode": 92.0, "batch_reward": 0.9222504199743271, "critic_loss": 0.38648567654192445, "actor_loss": -95.9867447052002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988492488861084, "step": 92000}
{"episode_reward": 949.0226981214487, "episode": 93.0, "batch_reward": 0.9227424908876419, "critic_loss": 0.3841403287872672, "actor_loss": -95.93786013793945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.996135711669922, "step": 93000}
{"episode_reward": 971.6616162826892, "episode": 94.0, "batch_reward": 0.9232093684673309, "critic_loss": 0.3962908141687512, "actor_loss": -95.99928648376465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993053674697876, "step": 94000}
{"episode_reward": 959.3757708446793, "episode": 95.0, "batch_reward": 0.923278318464756, "critic_loss": 0.42122531213611364, "actor_loss": -96.03033146667481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.987528800964355, "step": 95000}
{"episode_reward": 936.2254654806892, "episode": 96.0, "batch_reward": 0.9242596338391305, "critic_loss": 0.4177962932437658, "actor_loss": -96.05755276489258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.996777296066284, "step": 96000}
{"episode_reward": 954.8496582412918, "episode": 97.0, "batch_reward": 0.9238150144815445, "critic_loss": 0.3903529998585582, "actor_loss": -96.0387101135254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.983006477355957, "step": 97000}
{"episode_reward": 982.4517275989185, "episode": 98.0, "batch_reward": 0.9252426634430886, "critic_loss": 0.390008032746613, "actor_loss": -96.13525904846192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98264980316162, "step": 98000}
{"episode_reward": 979.7832752750638, "episode": 99.0, "batch_reward": 0.9265032181143761, "critic_loss": 0.3659874931201339, "actor_loss": -96.05650495910645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98948860168457, "step": 99000}
{"episode_reward": 986.5014279750935, "episode": 100.0, "batch_reward": 0.9243748707771301, "critic_loss": 0.3874472477734089, "actor_loss": -96.0419949798584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98954129219055, "step": 100000}
{"episode_reward": 923.206196188538, "episode": 101.0, "batch_reward": 0.9261125665903092, "critic_loss": 0.3923539669588208, "actor_loss": -96.07663932800293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.09784722328186, "step": 101000}
{"episode_reward": 952.1550888698048, "episode": 102.0, "batch_reward": 0.9271198726892471, "critic_loss": 0.3593491947725415, "actor_loss": -96.15781799316406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.989346981048584, "step": 102000}
{"episode_reward": 983.6992969648827, "episode": 103.0, "batch_reward": 0.9269857832789421, "critic_loss": 0.3271852292194963, "actor_loss": -96.10389477539063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988100051879883, "step": 103000}
{"episode_reward": 968.1248083386494, "episode": 104.0, "batch_reward": 0.9270531812310219, "critic_loss": 0.3657836475297809, "actor_loss": -96.09939918518066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.989663124084473, "step": 104000}
{"episode_reward": 956.7132617085324, "episode": 105.0, "batch_reward": 0.9273742762804031, "critic_loss": 0.38654488170146944, "actor_loss": -96.13613304138184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00079083442688, "step": 105000}
{"episode_reward": 928.8724137719228, "episode": 106.0, "batch_reward": 0.927656520664692, "critic_loss": 0.34174941486120225, "actor_loss": -96.16804875183105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.980633974075317, "step": 106000}
{"episode_reward": 947.2496949108071, "episode": 107.0, "batch_reward": 0.9271880202293395, "critic_loss": 0.36605584412813186, "actor_loss": -96.08138830566406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988749265670776, "step": 107000}
{"episode_reward": 960.0642633690395, "episode": 108.0, "batch_reward": 0.9282393510937691, "critic_loss": 0.36413823053240774, "actor_loss": -96.21834230041505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.991836309432983, "step": 108000}
{"episode_reward": 963.259585375959, "episode": 109.0, "batch_reward": 0.9297452017664909, "critic_loss": 0.361807370364666, "actor_loss": -96.23164079284668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981157302856445, "step": 109000}
{"episode_reward": 946.4294286422762, "episode": 110.0, "batch_reward": 0.9281821107268333, "critic_loss": 0.41675678819417955, "actor_loss": -96.26426718139649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97732710838318, "step": 110000}
{"episode_reward": 945.2089915797314, "episode": 111.0, "batch_reward": 0.9285291561484337, "critic_loss": 0.378605720050633, "actor_loss": -96.20535339355469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.114856481552124, "step": 111000}
{"episode_reward": 965.5771171357833, "episode": 112.0, "batch_reward": 0.9285582588911057, "critic_loss": 0.41102142722904683, "actor_loss": -96.22983328247071, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993866682052612, "step": 112000}
{"episode_reward": 962.6668153119532, "episode": 113.0, "batch_reward": 0.9306910555958748, "critic_loss": 0.3514198271110654, "actor_loss": -96.28666011047363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005493640899658, "step": 113000}
{"episode_reward": 978.4139091537196, "episode": 114.0, "batch_reward": 0.9307976646423339, "critic_loss": 0.369740533195436, "actor_loss": -96.32058432006836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981585264205933, "step": 114000}
{"episode_reward": 962.875500358448, "episode": 115.0, "batch_reward": 0.9308911093473434, "critic_loss": 0.3380771508142352, "actor_loss": -96.28989607238769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.992467403411865, "step": 115000}
{"episode_reward": 962.331035999406, "episode": 116.0, "batch_reward": 0.9309409133791924, "critic_loss": 0.3611521597206593, "actor_loss": -96.27934303283692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988213539123535, "step": 116000}
{"episode_reward": 986.2463458110614, "episode": 117.0, "batch_reward": 0.9313888576626778, "critic_loss": 0.3729912743717432, "actor_loss": -96.27332586669922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.987394332885742, "step": 117000}
{"episode_reward": 915.6494013077721, "episode": 118.0, "batch_reward": 0.9309856630563736, "critic_loss": 0.36969871844351293, "actor_loss": -96.30091851806641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99145269393921, "step": 118000}
{"episode_reward": 927.2312110100162, "episode": 119.0, "batch_reward": 0.9314678270220756, "critic_loss": 0.33096896585077046, "actor_loss": -96.3147925415039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.991596460342407, "step": 119000}
{"episode_reward": 949.1816298733605, "episode": 120.0, "batch_reward": 0.9311072517037392, "critic_loss": 0.3462342832237482, "actor_loss": -96.25972270202637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.000139474868774, "step": 120000}
{"episode_reward": 964.0860797456621, "episode": 121.0, "batch_reward": 0.93212077999115, "critic_loss": 0.3210446275398135, "actor_loss": -96.32777352905273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.122358322143555, "step": 121000}
{"episode_reward": 961.0467728841892, "episode": 122.0, "batch_reward": 0.9311910874247551, "critic_loss": 0.320068722628057, "actor_loss": -96.32577339172363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.984413623809814, "step": 122000}
{"episode_reward": 920.1623423261055, "episode": 123.0, "batch_reward": 0.9311148535013198, "critic_loss": 0.3254145164489746, "actor_loss": -96.38504383850098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.983820915222168, "step": 123000}
{"episode_reward": 912.402385012869, "episode": 124.0, "batch_reward": 0.9306338250041007, "critic_loss": 0.3253870802819729, "actor_loss": -96.32634991455078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.991957426071167, "step": 124000}
{"episode_reward": 967.608921797442, "episode": 125.0, "batch_reward": 0.9304000165462494, "critic_loss": 0.30974252919107675, "actor_loss": -96.32093208312989, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981236457824707, "step": 125000}
{"episode_reward": 954.9377644436826, "episode": 126.0, "batch_reward": 0.9299852837920188, "critic_loss": 0.32150539294630287, "actor_loss": -96.33019624328614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.985145568847656, "step": 126000}
{"episode_reward": 970.328659697368, "episode": 127.0, "batch_reward": 0.9317609884142876, "critic_loss": 0.30774752104282377, "actor_loss": -96.38288804626465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986483573913574, "step": 127000}
{"episode_reward": 957.160273099541, "episode": 128.0, "batch_reward": 0.9324432047009468, "critic_loss": 0.29607807406038045, "actor_loss": -96.34888734436035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98252272605896, "step": 128000}
{"episode_reward": 962.3340066737242, "episode": 129.0, "batch_reward": 0.9324904810786248, "critic_loss": 0.2971722056642175, "actor_loss": -96.35408345031739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.001472234725952, "step": 129000}
{"episode_reward": 982.4487928607783, "episode": 130.0, "batch_reward": 0.9327804941534996, "critic_loss": 0.30375134655833247, "actor_loss": -96.40867329406738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99738121032715, "step": 130000}
{"episode_reward": 962.3960755883834, "episode": 131.0, "batch_reward": 0.9327860363721847, "critic_loss": 0.31416972059756515, "actor_loss": -96.32688775634766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.09674024581909, "step": 131000}
{"episode_reward": 960.0247159563488, "episode": 132.0, "batch_reward": 0.9331633130908012, "critic_loss": 0.3215473583191633, "actor_loss": -96.43620845031738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.987306594848633, "step": 132000}
{"episode_reward": 941.7790039128458, "episode": 133.0, "batch_reward": 0.933867673754692, "critic_loss": 0.3044053660854697, "actor_loss": -96.40584173583984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97817897796631, "step": 133000}
{"episode_reward": 959.774552664631, "episode": 134.0, "batch_reward": 0.9345799475312233, "critic_loss": 0.336951447814703, "actor_loss": -96.42055680847167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98702836036682, "step": 134000}
{"episode_reward": 973.0610217916046, "episode": 135.0, "batch_reward": 0.9323117010593415, "critic_loss": 0.3187722123712301, "actor_loss": -96.41442070007324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988242626190186, "step": 135000}
{"episode_reward": 938.0813630445259, "episode": 136.0, "batch_reward": 0.9339271206259727, "critic_loss": 0.289990890391171, "actor_loss": -96.4276474609375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.983420848846436, "step": 136000}
{"episode_reward": 875.1537251617788, "episode": 137.0, "batch_reward": 0.9330602474808692, "critic_loss": 0.3442999514937401, "actor_loss": -96.42675173950195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997239589691162, "step": 137000}
{"episode_reward": 891.1579724156238, "episode": 138.0, "batch_reward": 0.9332160567641258, "critic_loss": 0.3162930524125695, "actor_loss": -96.45373550415039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993524312973022, "step": 138000}
{"episode_reward": 974.2702409257738, "episode": 139.0, "batch_reward": 0.9326489371061325, "critic_loss": 0.31959886563569306, "actor_loss": -96.34001992797852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01609754562378, "step": 139000}
{"episode_reward": 927.6756041356272, "episode": 140.0, "batch_reward": 0.9335479635596275, "critic_loss": 0.322773311316967, "actor_loss": -96.44192001342773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.985255241394043, "step": 140000}
{"episode_reward": 982.2224744104079, "episode": 141.0, "batch_reward": 0.9352335467338562, "critic_loss": 0.34657524518668653, "actor_loss": -96.4625304260254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.14327311515808, "step": 141000}
{"episode_reward": 952.760772460798, "episode": 142.0, "batch_reward": 0.9340441617965698, "critic_loss": 0.3387297108545899, "actor_loss": -96.38303121948242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96197009086609, "step": 142000}
{"episode_reward": 959.7261037647042, "episode": 143.0, "batch_reward": 0.9335631410479546, "critic_loss": 0.34296159959584477, "actor_loss": -96.39275967407227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9853777885437, "step": 143000}
{"episode_reward": 924.7328028218483, "episode": 144.0, "batch_reward": 0.9335680248737335, "critic_loss": 0.33159922643005846, "actor_loss": -96.4517346496582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98454475402832, "step": 144000}
{"episode_reward": 954.0068373641737, "episode": 145.0, "batch_reward": 0.9354588996767997, "critic_loss": 0.35029182813316584, "actor_loss": -96.4561849822998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98732018470764, "step": 145000}
{"episode_reward": 955.3904891342312, "episode": 146.0, "batch_reward": 0.9338982585668564, "critic_loss": 0.3418345659226179, "actor_loss": -96.29779696655274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.979682683944702, "step": 146000}
{"episode_reward": 905.3151404762044, "episode": 147.0, "batch_reward": 0.9334999240636825, "critic_loss": 0.3496353507861495, "actor_loss": -96.34695785522462, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.982971906661987, "step": 147000}
{"episode_reward": 965.1109355143417, "episode": 148.0, "batch_reward": 0.9346044442057609, "critic_loss": 0.3725008947104216, "actor_loss": -96.41973782348633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.978736877441406, "step": 148000}
{"episode_reward": 945.8827267471148, "episode": 149.0, "batch_reward": 0.9340366889238357, "critic_loss": 0.37316407124698164, "actor_loss": -96.40713865661621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988035440444946, "step": 149000}
{"episode_reward": 898.6449561521545, "episode": 150.0, "batch_reward": 0.9340490843057633, "critic_loss": 0.39102891986072064, "actor_loss": -96.40454927062989, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
