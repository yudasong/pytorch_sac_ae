{"episode_reward": 0.0, "episode": 1.0, "duration": 20.489287614822388, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.7906713485717773, "step": 2000}
{"episode_reward": 896.1586144851467, "episode": 3.0, "batch_reward": 0.49969779473219206, "critic_loss": 0.26387609789354793, "actor_loss": -86.74803752983127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.44886350631714, "step": 3000}
{"episode_reward": 630.3333822593526, "episode": 4.0, "batch_reward": 0.584633504062891, "critic_loss": 0.2506093158647418, "actor_loss": -87.75021760559082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.043174505233765, "step": 4000}
{"episode_reward": 951.816546144878, "episode": 5.0, "batch_reward": 0.6610517710447311, "critic_loss": 0.3023249776214361, "actor_loss": -89.34210832214356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03305220603943, "step": 5000}
{"episode_reward": 885.5140860867263, "episode": 6.0, "batch_reward": 0.6896877738833428, "critic_loss": 0.42653932252526283, "actor_loss": -89.65931254577637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03892230987549, "step": 6000}
{"episode_reward": 778.9093655418491, "episode": 7.0, "batch_reward": 0.719586118876934, "critic_loss": 0.4121741858571768, "actor_loss": -90.19389122009278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.037726879119873, "step": 7000}
{"episode_reward": 965.6661645337686, "episode": 8.0, "batch_reward": 0.744051049888134, "critic_loss": 0.5301267187148333, "actor_loss": -90.77832447814941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.038076877593994, "step": 8000}
{"episode_reward": 868.9634169485906, "episode": 9.0, "batch_reward": 0.7656112409830094, "critic_loss": 0.5908329523801804, "actor_loss": -91.36311036682129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.045709133148193, "step": 9000}
{"episode_reward": 930.208950500305, "episode": 10.0, "batch_reward": 0.7806007974147796, "critic_loss": 0.6163106812238693, "actor_loss": -91.78394314575195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02754783630371, "step": 10000}
{"episode_reward": 943.4986176693371, "episode": 11.0, "batch_reward": 0.795243055164814, "critic_loss": 0.5599302828609943, "actor_loss": -92.16214930725097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.31635546684265, "step": 11000}
{"episode_reward": 929.7531141869385, "episode": 12.0, "batch_reward": 0.8069087636470794, "critic_loss": 0.6104596725404262, "actor_loss": -92.54773352050782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.032729387283325, "step": 12000}
{"episode_reward": 905.6331121174978, "episode": 13.0, "batch_reward": 0.8171119531989097, "critic_loss": 0.4985826131999493, "actor_loss": -92.90180174255372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.037173986434937, "step": 13000}
{"episode_reward": 962.7227653246541, "episode": 14.0, "batch_reward": 0.8239002017974854, "critic_loss": 0.429887338206172, "actor_loss": -93.15564292907715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.028383493423462, "step": 14000}
{"episode_reward": 912.705214717588, "episode": 15.0, "batch_reward": 0.8285807932019233, "critic_loss": 0.40268731889128684, "actor_loss": -93.30675389099122, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.044375896453857, "step": 15000}
{"episode_reward": 895.8882171000276, "episode": 16.0, "batch_reward": 0.8383202247619629, "critic_loss": 0.4026289489865303, "actor_loss": -93.61835699462891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.025373935699463, "step": 16000}
{"episode_reward": 899.606460899894, "episode": 17.0, "batch_reward": 0.839138131737709, "critic_loss": 0.501999511539936, "actor_loss": -93.61382023620605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.047497510910034, "step": 17000}
{"episode_reward": 903.0458559006858, "episode": 18.0, "batch_reward": 0.8447906293869019, "critic_loss": 0.48482444101572036, "actor_loss": -93.72087284851074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.046323776245117, "step": 18000}
{"episode_reward": 914.07547030374, "episode": 19.0, "batch_reward": 0.8460849776268006, "critic_loss": 0.451174413010478, "actor_loss": -93.74945263671874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04387593269348, "step": 19000}
{"episode_reward": 942.1644848443121, "episode": 20.0, "batch_reward": 0.853275905430317, "critic_loss": 0.4253853970766068, "actor_loss": -93.97041566467286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.039917945861816, "step": 20000}
{"episode_reward": 956.7463179178632, "episode": 21.0, "batch_reward": 0.8593367103338242, "critic_loss": 0.42506568975746634, "actor_loss": -94.11501759338378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.39432954788208, "step": 21000}
{"episode_reward": 962.6134127833002, "episode": 22.0, "batch_reward": 0.8633751662969589, "critic_loss": 0.3315457184165716, "actor_loss": -94.27451345825196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.039274215698242, "step": 22000}
{"episode_reward": 974.8774386865093, "episode": 23.0, "batch_reward": 0.8677176594138145, "critic_loss": 0.3533296480178833, "actor_loss": -94.33862197875976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0462908744812, "step": 23000}
{"episode_reward": 941.5232779321457, "episode": 24.0, "batch_reward": 0.8690788121819496, "critic_loss": 0.3506030830144882, "actor_loss": -94.36375354003906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.033286333084106, "step": 24000}
{"episode_reward": 936.0251263280473, "episode": 25.0, "batch_reward": 0.8753213354945183, "critic_loss": 0.3269145123437047, "actor_loss": -94.51809602355956, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04454755783081, "step": 25000}
{"episode_reward": 962.5059470414288, "episode": 26.0, "batch_reward": 0.8780593764185906, "critic_loss": 0.27580943155288695, "actor_loss": -94.5972686767578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.043380975723267, "step": 26000}
{"episode_reward": 983.771545229424, "episode": 27.0, "batch_reward": 0.8812068161964417, "critic_loss": 0.2856923494040966, "actor_loss": -94.68631674194336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.042006731033325, "step": 27000}
{"episode_reward": 986.3452492166493, "episode": 28.0, "batch_reward": 0.8855288895964623, "critic_loss": 0.26096852391958236, "actor_loss": -94.83787367248536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04709768295288, "step": 28000}
{"episode_reward": 964.4781375321962, "episode": 29.0, "batch_reward": 0.884787810087204, "critic_loss": 0.3394972632974386, "actor_loss": -94.81912860107421, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.036661624908447, "step": 29000}
{"episode_reward": 898.1975685654036, "episode": 30.0, "batch_reward": 0.8880698102116584, "critic_loss": 0.2916826504468918, "actor_loss": -94.95602099609376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04227113723755, "step": 30000}
{"episode_reward": 932.2976326537652, "episode": 31.0, "batch_reward": 0.8901930072903633, "critic_loss": 0.3107325931712985, "actor_loss": -94.96578536987305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.32474446296692, "step": 31000}
{"episode_reward": 940.407739277966, "episode": 32.0, "batch_reward": 0.8906265271306038, "critic_loss": 0.2860522071942687, "actor_loss": -95.01879466247559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.350234031677246, "step": 32000}
{"episode_reward": 942.4143662282612, "episode": 33.0, "batch_reward": 0.8925874302983284, "critic_loss": 0.2604496077671647, "actor_loss": -95.02645268249512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.020944356918335, "step": 33000}
{"episode_reward": 955.272494777724, "episode": 34.0, "batch_reward": 0.897037004172802, "critic_loss": 0.2724468656405806, "actor_loss": -95.22020443725586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00067162513733, "step": 34000}
{"episode_reward": 984.8527766351789, "episode": 35.0, "batch_reward": 0.8962421280145645, "critic_loss": 0.2982861093878746, "actor_loss": -95.13141160583496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00955581665039, "step": 35000}
{"episode_reward": 864.9634190637923, "episode": 36.0, "batch_reward": 0.8966379296779633, "critic_loss": 0.32017673197388646, "actor_loss": -95.26404916381836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02919292449951, "step": 36000}
{"episode_reward": 946.7398846666651, "episode": 37.0, "batch_reward": 0.8992373729348183, "critic_loss": 0.26070144575089216, "actor_loss": -95.28291847229004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03278636932373, "step": 37000}
{"episode_reward": 977.9991904708229, "episode": 38.0, "batch_reward": 0.8985509767532348, "critic_loss": 0.32145791532844303, "actor_loss": -95.23663346862793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.354873180389404, "step": 38000}
{"episode_reward": 881.9859148442486, "episode": 39.0, "batch_reward": 0.8980390478372574, "critic_loss": 0.28343080829828976, "actor_loss": -95.21443464660645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02800464630127, "step": 39000}
{"episode_reward": 927.8935004499234, "episode": 40.0, "batch_reward": 0.9008271595835686, "critic_loss": 0.25446831444650886, "actor_loss": -95.38827792358398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004717350006104, "step": 40000}
{"episode_reward": 976.1262059940184, "episode": 41.0, "batch_reward": 0.9028159211277962, "critic_loss": 0.31367214999347925, "actor_loss": -95.36720358276366, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.34781050682068, "step": 41000}
{"episode_reward": 985.0952862490476, "episode": 42.0, "batch_reward": 0.9049136005640029, "critic_loss": 0.2529219933524728, "actor_loss": -95.48252989196777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.029554843902588, "step": 42000}
{"episode_reward": 950.7463538086085, "episode": 43.0, "batch_reward": 0.9052369964718818, "critic_loss": 0.26847310132533314, "actor_loss": -95.52872506713867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03394079208374, "step": 43000}
{"episode_reward": 977.9654525268406, "episode": 44.0, "batch_reward": 0.9068705884218216, "critic_loss": 0.2590500050634146, "actor_loss": -95.6031893310547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.023376941680908, "step": 44000}
{"episode_reward": 974.4651811770448, "episode": 45.0, "batch_reward": 0.9086124422550201, "critic_loss": 0.2606506802737713, "actor_loss": -95.62194995117187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.033122301101685, "step": 45000}
{"episode_reward": 984.4330867435859, "episode": 46.0, "batch_reward": 0.9111697806119918, "critic_loss": 0.2499747231155634, "actor_loss": -95.70010339355468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.025317668914795, "step": 46000}
{"episode_reward": 985.8084408158907, "episode": 47.0, "batch_reward": 0.9123165950775146, "critic_loss": 0.24133234764635564, "actor_loss": -95.70498638916015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.037756204605103, "step": 47000}
{"episode_reward": 964.0248414985582, "episode": 48.0, "batch_reward": 0.9123719018101693, "critic_loss": 0.2571094480529428, "actor_loss": -95.75318008422852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02939009666443, "step": 48000}
{"episode_reward": 952.5580490356882, "episode": 49.0, "batch_reward": 0.9131563107967376, "critic_loss": 0.2340244607925415, "actor_loss": -95.79749374389648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.038795471191406, "step": 49000}
{"episode_reward": 986.0972347943435, "episode": 50.0, "batch_reward": 0.9156236754655838, "critic_loss": 0.2451773000434041, "actor_loss": -95.87678524780273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.022098541259766, "step": 50000}
{"episode_reward": 972.6175549894635, "episode": 51.0, "batch_reward": 0.9157634568214417, "critic_loss": 0.23758396395295858, "actor_loss": -95.87083111572265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.321062088012695, "step": 51000}
{"episode_reward": 918.0887819986982, "episode": 52.0, "batch_reward": 0.916374059021473, "critic_loss": 0.2355923326089978, "actor_loss": -95.88860961914062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.040520429611206, "step": 52000}
{"episode_reward": 934.6937052797671, "episode": 53.0, "batch_reward": 0.9157750958204269, "critic_loss": 0.25680215134471657, "actor_loss": -95.88601167297364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.031240224838257, "step": 53000}
{"episode_reward": 919.5383234271453, "episode": 54.0, "batch_reward": 0.9169838669896125, "critic_loss": 0.28304839303344487, "actor_loss": -95.93503044128418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.028735637664795, "step": 54000}
{"episode_reward": 965.1832385020216, "episode": 55.0, "batch_reward": 0.9165995861291886, "critic_loss": 0.23650952462106944, "actor_loss": -95.87213095092774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.037885427474976, "step": 55000}
{"episode_reward": 919.737406982999, "episode": 56.0, "batch_reward": 0.9174436445236206, "critic_loss": 0.2586715809032321, "actor_loss": -95.93360539245606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.038583278656006, "step": 56000}
{"episode_reward": 963.491653096201, "episode": 57.0, "batch_reward": 0.9182431466579437, "critic_loss": 0.2551182734891772, "actor_loss": -95.94178298950196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.052258253097534, "step": 57000}
{"episode_reward": 913.9043874716052, "episode": 58.0, "batch_reward": 0.9180447234511375, "critic_loss": 0.27984710209071634, "actor_loss": -95.96090794372559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.041444063186646, "step": 58000}
{"episode_reward": 957.692643164209, "episode": 59.0, "batch_reward": 0.9205036208629608, "critic_loss": 0.29376090624928475, "actor_loss": -96.00721813964844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04576587677002, "step": 59000}
{"episode_reward": 982.0373085914104, "episode": 60.0, "batch_reward": 0.9208004511594773, "critic_loss": 0.27736142333596947, "actor_loss": -96.08998068237305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.040517568588257, "step": 60000}
{"episode_reward": 981.2946190710883, "episode": 61.0, "batch_reward": 0.9211962124705315, "critic_loss": 0.3032038430795074, "actor_loss": -96.03265144348144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.37408971786499, "step": 61000}
{"episode_reward": 953.8255229441774, "episode": 62.0, "batch_reward": 0.9222270686030388, "critic_loss": 0.2616218645721674, "actor_loss": -96.07718643188477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.055436372756958, "step": 62000}
{"episode_reward": 948.6402785020913, "episode": 63.0, "batch_reward": 0.9221304646134376, "critic_loss": 0.2949120325148106, "actor_loss": -96.08373115539551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03572726249695, "step": 63000}
{"episode_reward": 980.7527802157543, "episode": 64.0, "batch_reward": 0.9224297368526458, "critic_loss": 0.34040348847955465, "actor_loss": -96.09537100219727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.028935194015503, "step": 64000}
{"episode_reward": 906.3970942844402, "episode": 65.0, "batch_reward": 0.9229897060990333, "critic_loss": 0.2906765949577093, "actor_loss": -96.15194747924805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.038317680358887, "step": 65000}
{"episode_reward": 979.004302717763, "episode": 66.0, "batch_reward": 0.9220224746465683, "critic_loss": 0.40834526185318826, "actor_loss": -96.05594221496582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.041895627975464, "step": 66000}
{"episode_reward": 900.6854093343042, "episode": 67.0, "batch_reward": 0.9233020571470261, "critic_loss": 0.3488639591559768, "actor_loss": -96.17185311889648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03717565536499, "step": 67000}
{"episode_reward": 958.1467819004397, "episode": 68.0, "batch_reward": 0.9236021466255188, "critic_loss": 0.35772800067067145, "actor_loss": -96.14824462890626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.057965517044067, "step": 68000}
{"episode_reward": 958.8961077511124, "episode": 69.0, "batch_reward": 0.9233887463212013, "critic_loss": 0.3509375078827143, "actor_loss": -96.16168840026856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.042595624923706, "step": 69000}
{"episode_reward": 950.7040222608192, "episode": 70.0, "batch_reward": 0.9251634419560433, "critic_loss": 0.6026407121643425, "actor_loss": -96.17331568908692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.043696403503418, "step": 70000}
{"episode_reward": 959.473051629284, "episode": 71.0, "batch_reward": 0.9247178202867508, "critic_loss": 0.8669675162807107, "actor_loss": -96.23155877685546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.42538118362427, "step": 71000}
{"episode_reward": 887.046925367719, "episode": 72.0, "batch_reward": 0.9230316270589829, "critic_loss": 2.407722079053521, "actor_loss": -96.33350697326661, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.051894426345825, "step": 72000}
{"episode_reward": 956.1563100107713, "episode": 73.0, "batch_reward": 0.9184966387152672, "critic_loss": 4.406972949445247, "actor_loss": -96.66360105895996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.067775011062622, "step": 73000}
{"episode_reward": 34.85666364879801, "episode": 74.0, "batch_reward": 0.9127417421340942, "critic_loss": 4.267374402701854, "actor_loss": -96.85246733093261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04617714881897, "step": 74000}
{"episode_reward": 971.7063099550838, "episode": 75.0, "batch_reward": 0.9123440741896629, "critic_loss": 5.924929345458746, "actor_loss": -97.16574996948242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.041862726211548, "step": 75000}
{"episode_reward": 846.3040695431216, "episode": 76.0, "batch_reward": 0.9121508003473282, "critic_loss": 5.941452445089817, "actor_loss": -97.45836442565918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.038495779037476, "step": 76000}
{"episode_reward": 882.7989909536773, "episode": 77.0, "batch_reward": 0.9056495969295502, "critic_loss": 6.692371230840683, "actor_loss": -98.08406660461426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077715635299683, "step": 77000}
{"episode_reward": 37.415429867278554, "episode": 78.0, "batch_reward": 0.9020028643608093, "critic_loss": 7.165774749875069, "actor_loss": -99.06725128173828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04081654548645, "step": 78000}
{"episode_reward": 931.9073479625138, "episode": 79.0, "batch_reward": 0.8958066804409027, "critic_loss": 8.301446101665498, "actor_loss": -99.70113713073731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.070460557937622, "step": 79000}
{"episode_reward": 14.795883372689765, "episode": 80.0, "batch_reward": 0.8889921051859856, "critic_loss": 9.5062310256958, "actor_loss": -100.68633905029297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.048635244369507, "step": 80000}
{"episode_reward": 605.3122659069655, "episode": 81.0, "batch_reward": 0.883350435256958, "critic_loss": 11.15547734606266, "actor_loss": -102.06973425292969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.55737662315369, "step": 81000}
{"episode_reward": 154.83224637172634, "episode": 82.0, "batch_reward": 0.8712169141173363, "critic_loss": 11.140822664260865, "actor_loss": -103.90080140686035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.071996450424194, "step": 82000}
{"episode_reward": 38.62729889879442, "episode": 83.0, "batch_reward": 0.8680252093076706, "critic_loss": 11.264521395921706, "actor_loss": -103.74105834960938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.043749809265137, "step": 83000}
{"episode_reward": 807.2235708417047, "episode": 84.0, "batch_reward": 0.859996361732483, "critic_loss": 11.31094593000412, "actor_loss": -104.86689978027344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05838680267334, "step": 84000}
{"episode_reward": 13.339658417493306, "episode": 85.0, "batch_reward": 0.8517472863197326, "critic_loss": 11.833099689722061, "actor_loss": -107.98340911865235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.060800075531006, "step": 85000}
{"episode_reward": 15.04768387918063, "episode": 86.0, "batch_reward": 0.842488399207592, "critic_loss": 12.70213954782486, "actor_loss": -110.57798777770996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04616117477417, "step": 86000}
{"episode_reward": 138.8526840997616, "episode": 87.0, "batch_reward": 0.8336110901236534, "critic_loss": 13.076132325649262, "actor_loss": -110.00704573059082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07719373703003, "step": 87000}
{"episode_reward": 35.378270308125956, "episode": 88.0, "batch_reward": 0.8259126054644584, "critic_loss": 13.781888814926148, "actor_loss": -115.3761686553955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.054892778396606, "step": 88000}
{"episode_reward": 84.03977704330725, "episode": 89.0, "batch_reward": 0.8152965740561485, "critic_loss": 13.446611055374145, "actor_loss": -118.02249307250976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06317114830017, "step": 89000}
{"episode_reward": 22.31541013360249, "episode": 90.0, "batch_reward": 0.8097964526414871, "critic_loss": 13.859355219364167, "actor_loss": -119.78276741027832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.050392150878906, "step": 90000}
{"episode_reward": 252.89355039825472, "episode": 91.0, "batch_reward": 0.802095695078373, "critic_loss": 13.833699570655822, "actor_loss": -122.54772157287597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.619372606277466, "step": 91000}
{"episode_reward": 20.36977181055588, "episode": 92.0, "batch_reward": 0.7923570378422737, "critic_loss": 13.051018773078919, "actor_loss": -122.25708985900879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06012725830078, "step": 92000}
{"episode_reward": 16.70134737617559, "episode": 93.0, "batch_reward": 0.7837927513718606, "critic_loss": 11.841154147148133, "actor_loss": -126.3428263092041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.067497491836548, "step": 93000}
{"episode_reward": 43.423050117170746, "episode": 94.0, "batch_reward": 0.7748794997930527, "critic_loss": 10.692306045532227, "actor_loss": -123.65531979370117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04067826271057, "step": 94000}
{"episode_reward": 42.12099555402969, "episode": 95.0, "batch_reward": 0.7679724614024163, "critic_loss": 9.943260797977448, "actor_loss": -120.92649366760254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05627965927124, "step": 95000}
{"episode_reward": 45.70402064521202, "episode": 96.0, "batch_reward": 0.7624036866426468, "critic_loss": 8.69610113811493, "actor_loss": -125.46730670166015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.064289331436157, "step": 96000}
{"episode_reward": 14.53863683638502, "episode": 97.0, "batch_reward": 0.7538828220367432, "critic_loss": 7.789235457420349, "actor_loss": -128.76095802307128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.062524557113647, "step": 97000}
{"episode_reward": 209.2113930082645, "episode": 98.0, "batch_reward": 0.7533549672365188, "critic_loss": 6.751397646427154, "actor_loss": -120.04293478393555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.044663429260254, "step": 98000}
{"episode_reward": 776.0820399100421, "episode": 99.0, "batch_reward": 0.7514666931033135, "critic_loss": 6.452144071340561, "actor_loss": -124.81305895996094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.046494007110596, "step": 99000}
{"episode_reward": 889.6149632611521, "episode": 100.0, "batch_reward": 0.7529743956327438, "critic_loss": 5.617654551625252, "actor_loss": -124.2740771484375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.051270008087158, "step": 100000}
{"episode_reward": 897.8935401412828, "episode": 101.0, "batch_reward": 0.7518636348843575, "critic_loss": 4.931504871249199, "actor_loss": -124.99703114318848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.51661539077759, "step": 101000}
{"episode_reward": 16.236786915094555, "episode": 102.0, "batch_reward": 0.7467074746489525, "critic_loss": 4.1697848528623584, "actor_loss": -121.44841325378418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04736328125, "step": 102000}
{"episode_reward": 948.8787890501666, "episode": 103.0, "batch_reward": 0.7455882324576378, "critic_loss": 3.849055960416794, "actor_loss": -120.3870517578125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.073053121566772, "step": 103000}
{"episode_reward": 18.333152162649387, "episode": 104.0, "batch_reward": 0.7389576421380043, "critic_loss": 3.4052657259702683, "actor_loss": -122.6522744293213, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.079490661621094, "step": 104000}
{"episode_reward": 15.516072971644677, "episode": 105.0, "batch_reward": 0.7315489357113838, "critic_loss": 3.2102492888569834, "actor_loss": -121.02092074584961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07595682144165, "step": 105000}
{"episode_reward": 46.98651284034093, "episode": 106.0, "batch_reward": 0.7248295671343803, "critic_loss": 2.876178810238838, "actor_loss": -119.2229253692627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08656120300293, "step": 106000}
{"episode_reward": 15.600671682178362, "episode": 107.0, "batch_reward": 0.7185210496783256, "critic_loss": 2.511413065493107, "actor_loss": -120.25925671386719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07659411430359, "step": 107000}
{"episode_reward": 15.338863300801272, "episode": 108.0, "batch_reward": 0.7151994015574455, "critic_loss": 2.187902470171452, "actor_loss": -113.05843423461914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04626441001892, "step": 108000}
{"episode_reward": 966.2533206021594, "episode": 109.0, "batch_reward": 0.7173391101956368, "critic_loss": 2.1427897818088533, "actor_loss": -115.13164141845704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.036584615707397, "step": 109000}
{"episode_reward": 844.3389013455492, "episode": 110.0, "batch_reward": 0.7178081991672516, "critic_loss": 2.0730221965312956, "actor_loss": -110.26103593444824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.038350343704224, "step": 110000}
{"episode_reward": 917.4064192278593, "episode": 111.0, "batch_reward": 0.7210473307967186, "critic_loss": 1.9185461183190347, "actor_loss": -113.60787557983399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.47013330459595, "step": 111000}
{"episode_reward": 978.9531932591686, "episode": 112.0, "batch_reward": 0.7236951179504395, "critic_loss": 1.5840020471811294, "actor_loss": -109.1268214263916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04846739768982, "step": 112000}
{"episode_reward": 958.2338918536032, "episode": 113.0, "batch_reward": 0.7285022065043449, "critic_loss": 1.3478912748396397, "actor_loss": -110.74335209655762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05557107925415, "step": 113000}
{"episode_reward": 972.2546695040692, "episode": 114.0, "batch_reward": 0.7288866081237793, "critic_loss": 1.3178608483672143, "actor_loss": -108.55520240783692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03446340560913, "step": 114000}
{"episode_reward": 932.6901641820224, "episode": 115.0, "batch_reward": 0.7303288780450821, "critic_loss": 1.170155502974987, "actor_loss": -107.64858049011231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0611572265625, "step": 115000}
{"episode_reward": 972.810776194297, "episode": 116.0, "batch_reward": 0.7336959991455078, "critic_loss": 1.0576020805239676, "actor_loss": -106.84030738830566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.047358989715576, "step": 116000}
{"episode_reward": 986.2455973684218, "episode": 117.0, "batch_reward": 0.727999280333519, "critic_loss": 1.0312700114250184, "actor_loss": -107.12883935546876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06308603286743, "step": 117000}
{"episode_reward": 57.98739646975657, "episode": 118.0, "batch_reward": 0.7242096732854844, "critic_loss": 0.9184449547529221, "actor_loss": -105.8687658996582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.071414947509766, "step": 118000}
{"episode_reward": 30.259359727032127, "episode": 119.0, "batch_reward": 0.7202997227907181, "critic_loss": 0.795701382637024, "actor_loss": -105.06312210083007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.086238145828247, "step": 119000}
{"episode_reward": 14.935762085200956, "episode": 120.0, "batch_reward": 0.7159162345528602, "critic_loss": 0.7919928649663925, "actor_loss": -104.05728839111327, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.059532403945923, "step": 120000}
{"episode_reward": 975.2877636303011, "episode": 121.0, "batch_reward": 0.7156294564008713, "critic_loss": 0.7095127646028996, "actor_loss": -103.04202598571777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.553157567977905, "step": 121000}
{"episode_reward": 14.397193408075111, "episode": 122.0, "batch_reward": 0.708338404417038, "critic_loss": 0.7113171645104885, "actor_loss": -101.53290953063964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.075916290283203, "step": 122000}
{"episode_reward": 58.09956695568666, "episode": 123.0, "batch_reward": 0.707564945757389, "critic_loss": 0.6879023683071136, "actor_loss": -101.04321690368653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.058565139770508, "step": 123000}
{"episode_reward": 926.8617916348393, "episode": 124.0, "batch_reward": 0.7039443507194519, "critic_loss": 0.6853181920349598, "actor_loss": -99.20722760009765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07732391357422, "step": 124000}
{"episode_reward": 18.26791615153175, "episode": 125.0, "batch_reward": 0.6989977542161941, "critic_loss": 0.6996346563398838, "actor_loss": -99.33662887573242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085161924362183, "step": 125000}
{"episode_reward": 14.170880419348418, "episode": 126.0, "batch_reward": 0.6994069467186927, "critic_loss": 0.7298007719814777, "actor_loss": -98.17874995422363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.051854133605957, "step": 126000}
{"episode_reward": 957.7625467889355, "episode": 127.0, "batch_reward": 0.6959804157614708, "critic_loss": 0.7155075917094946, "actor_loss": -97.49285469055175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0733642578125, "step": 127000}
{"episode_reward": 14.371087482476804, "episode": 128.0, "batch_reward": 0.6941549764275551, "critic_loss": 0.8005836709141732, "actor_loss": -96.96022273254394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.059765815734863, "step": 128000}
{"episode_reward": 893.4897177542329, "episode": 129.0, "batch_reward": 0.6960733701586723, "critic_loss": 0.8825552006959915, "actor_loss": -96.49700312805176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04846715927124, "step": 129000}
{"episode_reward": 981.1718142641429, "episode": 130.0, "batch_reward": 0.6989318075180053, "critic_loss": 0.9311781357526779, "actor_loss": -96.11825779724121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06846594810486, "step": 130000}
{"episode_reward": 940.5778126224012, "episode": 131.0, "batch_reward": 0.7022177236676216, "critic_loss": 0.9765223549604416, "actor_loss": -96.61893534851075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.33293437957764, "step": 131000}
{"episode_reward": 962.2984813475277, "episode": 132.0, "batch_reward": 0.7014270865321159, "critic_loss": 1.053511083573103, "actor_loss": -95.7017651977539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.047815322875977, "step": 132000}
{"episode_reward": 840.6575784205038, "episode": 133.0, "batch_reward": 0.7033345840573311, "critic_loss": 1.0235129486322403, "actor_loss": -96.19511817932128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.048753261566162, "step": 133000}
{"episode_reward": 986.567280651481, "episode": 134.0, "batch_reward": 0.7057265091538429, "critic_loss": 0.9974676838219165, "actor_loss": -95.82312631225587, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.046674489974976, "step": 134000}
{"episode_reward": 910.8967112781369, "episode": 135.0, "batch_reward": 0.7046118899583816, "critic_loss": 1.0089734106063843, "actor_loss": -95.16345483398437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.055782079696655, "step": 135000}
{"episode_reward": 915.6494229140799, "episode": 136.0, "batch_reward": 0.7071027082204818, "critic_loss": 0.9420816856622696, "actor_loss": -94.93337696838378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.064817190170288, "step": 136000}
{"episode_reward": 659.3752979025135, "episode": 137.0, "batch_reward": 0.706997132897377, "critic_loss": 0.8794746606498957, "actor_loss": -94.83766036987305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.048494815826416, "step": 137000}
{"episode_reward": 898.0725753166747, "episode": 138.0, "batch_reward": 0.7112723516821862, "critic_loss": 0.8467021536827087, "actor_loss": -94.70870588684082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.052486181259155, "step": 138000}
{"episode_reward": 981.0058292074672, "episode": 139.0, "batch_reward": 0.7078379893898964, "critic_loss": 0.8642053693830967, "actor_loss": -94.56996841430664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.061130046844482, "step": 139000}
{"episode_reward": 626.9344351619409, "episode": 140.0, "batch_reward": 0.7099199067354203, "critic_loss": 0.7985027274787426, "actor_loss": -94.06444647216797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.054744720458984, "step": 140000}
{"episode_reward": 978.8329514771548, "episode": 141.0, "batch_reward": 0.7128993816971779, "critic_loss": 0.7918384420871735, "actor_loss": -94.41040087890624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.395227670669556, "step": 141000}
{"episode_reward": 938.1276286954785, "episode": 142.0, "batch_reward": 0.7163189885020256, "critic_loss": 0.8206275520324707, "actor_loss": -94.44759005737305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.047037363052368, "step": 142000}
{"episode_reward": 982.4427222239424, "episode": 143.0, "batch_reward": 0.7169798753857612, "critic_loss": 0.8408357715010643, "actor_loss": -94.5800316772461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34179949760437, "step": 143000}
{"episode_reward": 919.3544402734761, "episode": 144.0, "batch_reward": 0.7181523684859276, "critic_loss": 0.8639460247457027, "actor_loss": -94.32769812011719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.036690950393677, "step": 144000}
{"episode_reward": 945.8506394582629, "episode": 145.0, "batch_reward": 0.7201941410303115, "critic_loss": 0.758214257478714, "actor_loss": -94.36496565246583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.019988775253296, "step": 145000}
{"episode_reward": 961.1322398212925, "episode": 146.0, "batch_reward": 0.7218397201895714, "critic_loss": 0.7288242312967778, "actor_loss": -94.76504409790039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03235912322998, "step": 146000}
{"episode_reward": 921.7975152440014, "episode": 147.0, "batch_reward": 0.7230433347821236, "critic_loss": 0.7662692473232746, "actor_loss": -94.59382548522949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04584503173828, "step": 147000}
{"episode_reward": 958.1318987923652, "episode": 148.0, "batch_reward": 0.7235683885812759, "critic_loss": 0.7830773877054453, "actor_loss": -94.50602731323242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.040822505950928, "step": 148000}
{"episode_reward": 943.8245781509149, "episode": 149.0, "batch_reward": 0.7245158122777939, "critic_loss": 0.7134675805717706, "actor_loss": -94.52081750488281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.043531894683838, "step": 149000}
{"episode_reward": 920.5743092032372, "episode": 150.0, "batch_reward": 0.7252950090765953, "critic_loss": 0.7105072567164898, "actor_loss": -94.41890730285644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
