{"episode_reward": 0.0, "episode": 1.0, "duration": 28.944869995117188, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 3.0697145462036133, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.4611776725734699, "critic_loss": 0.3649461011502615, "actor_loss": -78.57231627392167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 88.26347589492798, "step": 3000}
{"episode_reward": 882.4404957550142, "episode": 4.0, "batch_reward": 0.6318371878266335, "critic_loss": 0.34351355946063994, "actor_loss": -84.74820138549805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.362704277038574, "step": 4000}
{"episode_reward": 933.7564788787408, "episode": 5.0, "batch_reward": 0.6773766142129898, "critic_loss": 0.3364009151607752, "actor_loss": -85.95114797973633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.751648426055908, "step": 5000}
{"episode_reward": 818.7934125632413, "episode": 6.0, "batch_reward": 0.7133432700634003, "critic_loss": 0.27270818418264386, "actor_loss": -86.5943550415039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.935444831848145, "step": 6000}
{"episode_reward": 895.5335590367483, "episode": 7.0, "batch_reward": 0.7498946551084519, "critic_loss": 0.22437051060795785, "actor_loss": -87.61006539916993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.39594864845276, "step": 7000}
{"episode_reward": 952.2763474848881, "episode": 8.0, "batch_reward": 0.7736346899271012, "critic_loss": 0.22216703368723392, "actor_loss": -87.95627464294434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.35722064971924, "step": 8000}
{"episode_reward": 931.4007151903259, "episode": 9.0, "batch_reward": 0.7942553065419197, "critic_loss": 0.20922206199169158, "actor_loss": -88.31482836914063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.17571139335632, "step": 9000}
{"episode_reward": 957.9808252380842, "episode": 10.0, "batch_reward": 0.7946295833587647, "critic_loss": 0.30292989160120487, "actor_loss": -88.27806245422363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.200372219085693, "step": 10000}
{"episode_reward": 772.3168743705053, "episode": 11.0, "batch_reward": 0.7990205922722816, "critic_loss": 0.2643533000797033, "actor_loss": -88.20458818054199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 58.355918169021606, "step": 11000}
{"episode_reward": 833.59861396213, "episode": 12.0, "batch_reward": 0.8091528941988945, "critic_loss": 0.2384428293555975, "actor_loss": -88.46953797912597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.88571548461914, "step": 12000}
{"episode_reward": 925.2485708690728, "episode": 13.0, "batch_reward": 0.8175529710650444, "critic_loss": 0.23706674357503651, "actor_loss": -88.88569750976562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.028590202331543, "step": 13000}
{"episode_reward": 920.645597774173, "episode": 14.0, "batch_reward": 0.8228552719950676, "critic_loss": 0.20982988183945417, "actor_loss": -88.8361634979248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.371167421340942, "step": 14000}
{"episode_reward": 886.504931678418, "episode": 15.0, "batch_reward": 0.8275617186427117, "critic_loss": 0.2021719706952572, "actor_loss": -88.77036837768554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.514047384262085, "step": 15000}
{"episode_reward": 897.6011537355026, "episode": 16.0, "batch_reward": 0.8287620457410813, "critic_loss": 0.23795305304974318, "actor_loss": -89.10605853271484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.291335821151733, "step": 16000}
{"episode_reward": 840.8635950975312, "episode": 17.0, "batch_reward": 0.8342153442502022, "critic_loss": 0.22496332938224078, "actor_loss": -89.1017654876709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.03235673904419, "step": 17000}
{"episode_reward": 905.4406597662369, "episode": 18.0, "batch_reward": 0.8372575981616974, "critic_loss": 0.22748904582858084, "actor_loss": -89.13316752624512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.340886116027832, "step": 18000}
{"episode_reward": 887.9399735961496, "episode": 19.0, "batch_reward": 0.8331184954047203, "critic_loss": 0.31900041465461254, "actor_loss": -89.0171982574463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.736847400665283, "step": 19000}
{"episode_reward": 779.3658111264918, "episode": 20.0, "batch_reward": 0.8384774449467659, "critic_loss": 0.27752322851121425, "actor_loss": -89.17559289550782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.684881687164307, "step": 20000}
{"episode_reward": 954.4600285136121, "episode": 21.0, "batch_reward": 0.8437475398778915, "critic_loss": 0.2768459490686655, "actor_loss": -89.5798992767334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 57.84732532501221, "step": 21000}
{"episode_reward": 910.7471274987345, "episode": 22.0, "batch_reward": 0.8462131721973419, "critic_loss": 0.2709936996251345, "actor_loss": -89.1840030822754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.958051919937134, "step": 22000}
{"episode_reward": 941.723628670062, "episode": 23.0, "batch_reward": 0.8502114433646202, "critic_loss": 0.26858036902546883, "actor_loss": -89.53965264892578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.827011346817017, "step": 23000}
{"episode_reward": 922.547787077369, "episode": 24.0, "batch_reward": 0.8528936037421226, "critic_loss": 0.263923535823822, "actor_loss": -89.62823974609375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.27042293548584, "step": 24000}
{"episode_reward": 909.8521661386175, "episode": 25.0, "batch_reward": 0.856126323401928, "critic_loss": 0.2707814449667931, "actor_loss": -89.76690020751953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.688632249832153, "step": 25000}
{"episode_reward": 943.2110278640384, "episode": 26.0, "batch_reward": 0.8598930321931839, "critic_loss": 0.2253041185736656, "actor_loss": -90.04850160217285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.079469680786133, "step": 26000}
{"episode_reward": 963.2583204229733, "episode": 27.0, "batch_reward": 0.8642295476198196, "critic_loss": 0.20275734128057957, "actor_loss": -90.36953657531738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.761826276779175, "step": 27000}
{"episode_reward": 975.5157173193533, "episode": 28.0, "batch_reward": 0.8675070009231567, "critic_loss": 0.23530141132324933, "actor_loss": -90.08339671325683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.861957788467407, "step": 28000}
{"episode_reward": 934.9276582043894, "episode": 29.0, "batch_reward": 0.868840381026268, "critic_loss": 0.2063537919819355, "actor_loss": -90.23823263549805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.36392307281494, "step": 29000}
{"episode_reward": 914.8674767304667, "episode": 30.0, "batch_reward": 0.871271686732769, "critic_loss": 0.2657979414463043, "actor_loss": -90.60223539733887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.632030487060547, "step": 30000}
{"episode_reward": 909.0544104121313, "episode": 31.0, "batch_reward": 0.8743463422656059, "critic_loss": 0.2056013579517603, "actor_loss": -90.40863844299317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 58.093459606170654, "step": 31000}
{"episode_reward": 962.8953623842477, "episode": 32.0, "batch_reward": 0.8738957695364952, "critic_loss": 0.22038448297232388, "actor_loss": -90.31157376098633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.80464792251587, "step": 32000}
{"episode_reward": 911.8250074934442, "episode": 33.0, "batch_reward": 0.8777177780270576, "critic_loss": 0.21674012200534343, "actor_loss": -90.26237023925782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.553946495056152, "step": 33000}
{"episode_reward": 943.4764877680516, "episode": 34.0, "batch_reward": 0.879911068379879, "critic_loss": 0.23080628246068954, "actor_loss": -90.71021694946289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.94893527030945, "step": 34000}
{"episode_reward": 938.5483006701941, "episode": 35.0, "batch_reward": 0.8789686567783356, "critic_loss": 0.268901119671762, "actor_loss": -90.30139433288574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.93672752380371, "step": 35000}
{"episode_reward": 857.9725656416629, "episode": 36.0, "batch_reward": 0.8804072071313858, "critic_loss": 0.24502926713228226, "actor_loss": -90.3365848236084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.009920358657837, "step": 36000}
{"episode_reward": 930.2395234805089, "episode": 37.0, "batch_reward": 0.882349444925785, "critic_loss": 0.2296831743121147, "actor_loss": -90.49473426818848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.66685700416565, "step": 37000}
{"episode_reward": 969.1629813474539, "episode": 38.0, "batch_reward": 0.8838418856859207, "critic_loss": 0.2496539039760828, "actor_loss": -90.4796492614746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.97161340713501, "step": 38000}
{"episode_reward": 941.9310590721685, "episode": 39.0, "batch_reward": 0.884921756029129, "critic_loss": 0.27000345958024263, "actor_loss": -90.50734982299805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.996959686279297, "step": 39000}
{"episode_reward": 957.5914456786033, "episode": 40.0, "batch_reward": 0.8877207491993904, "critic_loss": 0.26755474995076656, "actor_loss": -90.74930375671387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.90815281867981, "step": 40000}
{"episode_reward": 969.4117731881066, "episode": 41.0, "batch_reward": 0.8890971443653106, "critic_loss": 0.245780759871006, "actor_loss": -91.25047592163087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.29418420791626, "step": 41000}
{"episode_reward": 944.8613298043164, "episode": 42.0, "batch_reward": 0.8915290387868882, "critic_loss": 0.2621707001999021, "actor_loss": -90.89831544494629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.968374729156494, "step": 42000}
{"episode_reward": 959.4403088462966, "episode": 43.0, "batch_reward": 0.8922233395576477, "critic_loss": 0.19533544010668993, "actor_loss": -90.85178150939942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.721421480178833, "step": 43000}
{"episode_reward": 969.2949358775842, "episode": 44.0, "batch_reward": 0.8945274714827538, "critic_loss": 0.17575340216606855, "actor_loss": -90.67175100708008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.88072371482849, "step": 44000}
{"episode_reward": 955.0313629819146, "episode": 45.0, "batch_reward": 0.895286106467247, "critic_loss": 0.17153070083260535, "actor_loss": -90.69817495727538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.9437255859375, "step": 45000}
{"episode_reward": 963.0966137824408, "episode": 46.0, "batch_reward": 0.8976659997701645, "critic_loss": 0.16339826430380344, "actor_loss": -91.20208836364746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.204573392868042, "step": 46000}
{"episode_reward": 971.9052480881378, "episode": 47.0, "batch_reward": 0.8994731047749519, "critic_loss": 0.17897865218669176, "actor_loss": -91.04491256713867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.690011739730835, "step": 47000}
{"episode_reward": 956.5652957273452, "episode": 48.0, "batch_reward": 0.8993313699960709, "critic_loss": 0.18430483017116786, "actor_loss": -90.81451620483398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.05393934249878, "step": 48000}
{"episode_reward": 908.956602710483, "episode": 49.0, "batch_reward": 0.8989395880103112, "critic_loss": 0.1566418685130775, "actor_loss": -90.73256503295899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.828834533691406, "step": 49000}
{"episode_reward": 944.9361866168825, "episode": 50.0, "batch_reward": 0.9009508860111236, "critic_loss": 0.16969008463993668, "actor_loss": -91.04099244689941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.91763162612915, "step": 50000}
{"episode_reward": 956.5514263014202, "episode": 51.0, "batch_reward": 0.9021664663553238, "critic_loss": 0.16496916153281926, "actor_loss": -91.22838165283203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.97480487823486, "step": 51000}
{"episode_reward": 954.6737740955588, "episode": 52.0, "batch_reward": 0.9015134508013726, "critic_loss": 0.19269390893727542, "actor_loss": -91.18101824951172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.62040114402771, "step": 52000}
{"episode_reward": 836.9264661761244, "episode": 53.0, "batch_reward": 0.9005789703130722, "critic_loss": 0.2063842151723802, "actor_loss": -90.76723970031739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.9198317527771, "step": 53000}
{"episode_reward": 930.5703306537364, "episode": 54.0, "batch_reward": 0.9026102492809296, "critic_loss": 0.17278666215389968, "actor_loss": -90.99937773132324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.87388515472412, "step": 54000}
{"episode_reward": 939.1286587451023, "episode": 55.0, "batch_reward": 0.9023897911310196, "critic_loss": 0.19273118429630995, "actor_loss": -90.97376368713378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.6626398563385, "step": 55000}
{"episode_reward": 944.1477928782223, "episode": 56.0, "batch_reward": 0.9030069564580917, "critic_loss": 0.19120023030415179, "actor_loss": -91.11922381591796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.723289728164673, "step": 56000}
{"episode_reward": 950.4124051324862, "episode": 57.0, "batch_reward": 0.9050521382689476, "critic_loss": 0.1973451734930277, "actor_loss": -91.02753045654296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.954572677612305, "step": 57000}
{"episode_reward": 936.8795395228424, "episode": 58.0, "batch_reward": 0.903797652721405, "critic_loss": 0.20070468980818987, "actor_loss": -90.91623275756837, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.866488695144653, "step": 58000}
{"episode_reward": 940.7644290298934, "episode": 59.0, "batch_reward": 0.9060126584768295, "critic_loss": 0.18140982612222434, "actor_loss": -91.03360035705566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.87998676300049, "step": 59000}
{"episode_reward": 962.0346257244887, "episode": 60.0, "batch_reward": 0.9062744981646538, "critic_loss": 0.16522345286980272, "actor_loss": -91.05643321228027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.60820436477661, "step": 60000}
{"episode_reward": 936.290687000428, "episode": 61.0, "batch_reward": 0.9068218827247619, "critic_loss": 0.19234358296915888, "actor_loss": -91.23171881103515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.963021755218506, "step": 61000}
{"episode_reward": 945.4194299402325, "episode": 62.0, "batch_reward": 0.9077838544845581, "critic_loss": 0.17779594596475362, "actor_loss": -90.97831295776368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.808682441711426, "step": 62000}
{"episode_reward": 924.1638135867349, "episode": 63.0, "batch_reward": 0.9079703533649445, "critic_loss": 0.185225179027766, "actor_loss": -91.40206979370117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.573296546936035, "step": 63000}
{"episode_reward": 955.4576352551272, "episode": 64.0, "batch_reward": 0.9081957835555077, "critic_loss": 0.17371467541903257, "actor_loss": -91.12891885375977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.844127893447876, "step": 64000}
{"episode_reward": 943.6248916387431, "episode": 65.0, "batch_reward": 0.909042036831379, "critic_loss": 0.17286489517614245, "actor_loss": -91.36372528076171, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.935569286346436, "step": 65000}
{"episode_reward": 958.8914493679003, "episode": 66.0, "batch_reward": 0.9087292786240577, "critic_loss": 0.1767610449269414, "actor_loss": -91.20943701171875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.12510585784912, "step": 66000}
{"episode_reward": 876.8177899563921, "episode": 67.0, "batch_reward": 0.9096246767044067, "critic_loss": 0.16590330136194825, "actor_loss": -90.93690580749512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.895061492919922, "step": 67000}
{"episode_reward": 942.857973766804, "episode": 68.0, "batch_reward": 0.9098552110195159, "critic_loss": 0.17147557570412755, "actor_loss": -90.99230018615722, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.968496322631836, "step": 68000}
{"episode_reward": 943.3941704358627, "episode": 69.0, "batch_reward": 0.9089269533157348, "critic_loss": 0.16472510745003818, "actor_loss": -91.40379916381836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.78805947303772, "step": 69000}
{"episode_reward": 913.4246032603098, "episode": 70.0, "batch_reward": 0.9106234050989152, "critic_loss": 0.17095203874260187, "actor_loss": -91.15318566894531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.128522872924805, "step": 70000}
{"episode_reward": 950.5579621996008, "episode": 71.0, "batch_reward": 0.9106017583012581, "critic_loss": 0.17851013960316778, "actor_loss": -91.3326798248291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.481717109680176, "step": 71000}
{"episode_reward": 907.682612692303, "episode": 72.0, "batch_reward": 0.9102812423706055, "critic_loss": 0.15987250681221485, "actor_loss": -91.39363665771485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.84510040283203, "step": 72000}
{"episode_reward": 938.415144320892, "episode": 73.0, "batch_reward": 0.9107386323809624, "critic_loss": 0.19184937193244694, "actor_loss": -91.31148049926757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.695190906524658, "step": 73000}
{"episode_reward": 860.8585774120048, "episode": 74.0, "batch_reward": 0.910584617137909, "critic_loss": 0.18759306355193256, "actor_loss": -91.25716700744628, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.405882120132446, "step": 74000}
{"episode_reward": 932.4889392787109, "episode": 75.0, "batch_reward": 0.910265342593193, "critic_loss": 0.19912804927676916, "actor_loss": -91.36210906982421, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.783339262008667, "step": 75000}
{"episode_reward": 877.3411049462424, "episode": 76.0, "batch_reward": 0.9104292718172073, "critic_loss": 0.18864353456348182, "actor_loss": -91.38794145202637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.866560220718384, "step": 76000}
{"episode_reward": 858.3682412708325, "episode": 77.0, "batch_reward": 0.9087275233268738, "critic_loss": 0.22042655262351035, "actor_loss": -91.16952091979981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.828426599502563, "step": 77000}
{"episode_reward": 929.9525759691684, "episode": 78.0, "batch_reward": 0.9107882451415062, "critic_loss": 0.20322606735676527, "actor_loss": -91.40220185852051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.66722083091736, "step": 78000}
{"episode_reward": 974.3402536149426, "episode": 79.0, "batch_reward": 0.9113407669067383, "critic_loss": 0.21179587345570325, "actor_loss": -91.19134339904785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.242241621017456, "step": 79000}
{"episode_reward": 944.0313310278538, "episode": 80.0, "batch_reward": 0.9109769702553749, "critic_loss": 0.20189495619758963, "actor_loss": -91.10148608398437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.935550689697266, "step": 80000}
{"episode_reward": 952.0075679936457, "episode": 81.0, "batch_reward": 0.9126245340108872, "critic_loss": 0.1981322288364172, "actor_loss": -91.1078127746582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.77107548713684, "step": 81000}
{"episode_reward": 952.6007136787257, "episode": 82.0, "batch_reward": 0.9122113654613495, "critic_loss": 0.20031144404038786, "actor_loss": -91.36884275817872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.443061351776123, "step": 82000}
{"episode_reward": 935.1201717328262, "episode": 83.0, "batch_reward": 0.9140662727952004, "critic_loss": 0.19348244594037534, "actor_loss": -91.16584530639649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.127516269683838, "step": 83000}
{"episode_reward": 942.7324285637437, "episode": 84.0, "batch_reward": 0.9120602777004242, "critic_loss": 0.21826797196641565, "actor_loss": -91.1543713684082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.419257879257202, "step": 84000}
{"episode_reward": 891.4655584730267, "episode": 85.0, "batch_reward": 0.9126524720788002, "critic_loss": 0.19861437231674792, "actor_loss": -91.31273080444336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.050022840499878, "step": 85000}
{"episode_reward": 943.2790311616249, "episode": 86.0, "batch_reward": 0.9132845841050148, "critic_loss": 0.1913655893281102, "actor_loss": -91.25052351379395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.00742292404175, "step": 86000}
{"episode_reward": 961.4094921704209, "episode": 87.0, "batch_reward": 0.9148505086302757, "critic_loss": 0.1892989255078137, "actor_loss": -91.19269923400878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.676482439041138, "step": 87000}
{"episode_reward": 972.054015458025, "episode": 88.0, "batch_reward": 0.9139847987294197, "critic_loss": 0.20308961141109466, "actor_loss": -91.22211775207519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.855131149291992, "step": 88000}
{"episode_reward": 957.0965709070823, "episode": 89.0, "batch_reward": 0.9137681820392609, "critic_loss": 0.18843053102865814, "actor_loss": -91.52757041931153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.804760694503784, "step": 89000}
{"episode_reward": 911.3102556549806, "episode": 90.0, "batch_reward": 0.9147732855081558, "critic_loss": 0.18486332521215082, "actor_loss": -91.53546197509766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.041940689086914, "step": 90000}
{"episode_reward": 872.0233842907377, "episode": 91.0, "batch_reward": 0.9143537439107895, "critic_loss": 0.19678782403469086, "actor_loss": -91.6172771911621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.06440210342407, "step": 91000}
{"episode_reward": 949.8492873519361, "episode": 92.0, "batch_reward": 0.9145830374956131, "critic_loss": 0.19725730736926197, "actor_loss": -91.35026176452637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.873106002807617, "step": 92000}
{"episode_reward": 923.9834537789521, "episode": 93.0, "batch_reward": 0.9153336737155914, "critic_loss": 0.1985355057269335, "actor_loss": -91.6881256866455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.454928398132324, "step": 93000}
{"episode_reward": 965.0330078995073, "episode": 94.0, "batch_reward": 0.914376206099987, "critic_loss": 0.19799193576350807, "actor_loss": -91.45485700988769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.398829698562622, "step": 94000}
{"episode_reward": 927.0794289427628, "episode": 95.0, "batch_reward": 0.9132923515439033, "critic_loss": 0.2247127751931548, "actor_loss": -91.1966527709961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.1363787651062, "step": 95000}
{"episode_reward": 764.1708779608371, "episode": 96.0, "batch_reward": 0.9142681581377983, "critic_loss": 0.21669840546697378, "actor_loss": -91.58181317138671, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.7192599773407, "step": 96000}
{"episode_reward": 950.9172120361352, "episode": 97.0, "batch_reward": 0.9135070083141327, "critic_loss": 0.215603392906487, "actor_loss": -91.60526879882812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.89775514602661, "step": 97000}
{"episode_reward": 969.1534261863889, "episode": 98.0, "batch_reward": 0.9146857384443283, "critic_loss": 0.20071153325587512, "actor_loss": -91.18576676940918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.023093461990356, "step": 98000}
{"episode_reward": 965.5010437988337, "episode": 99.0, "batch_reward": 0.915477353155613, "critic_loss": 0.21173816937208176, "actor_loss": -91.45692189025878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.230809688568115, "step": 99000}
{"episode_reward": 947.2017261539282, "episode": 100.0, "batch_reward": 0.9155439713001251, "critic_loss": 0.2123018498495221, "actor_loss": -91.30215124511719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.906054496765137, "step": 100000}
{"episode_reward": 950.6871677450391, "episode": 101.0, "batch_reward": 0.9162382194399834, "critic_loss": 0.20365800084918737, "actor_loss": -91.69948469543456, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.38736891746521, "step": 101000}
{"episode_reward": 946.0751486103995, "episode": 102.0, "batch_reward": 0.9177460690140724, "critic_loss": 0.20334104676172138, "actor_loss": -91.42534674072266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.51927900314331, "step": 102000}
{"episode_reward": 971.0395254416675, "episode": 103.0, "batch_reward": 0.9168177670836448, "critic_loss": 0.20637848126888275, "actor_loss": -91.44178721618653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.0279860496521, "step": 103000}
{"episode_reward": 963.8592420491674, "episode": 104.0, "batch_reward": 0.9170939509272575, "critic_loss": 0.19855492339655756, "actor_loss": -91.6812668914795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.16557765007019, "step": 104000}
{"episode_reward": 937.4107242218396, "episode": 105.0, "batch_reward": 0.9170835705995559, "critic_loss": 0.20078553280606865, "actor_loss": -91.59930181884765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.88314414024353, "step": 105000}
{"episode_reward": 952.821328485028, "episode": 106.0, "batch_reward": 0.9178940488696098, "critic_loss": 0.19197899089381099, "actor_loss": -91.64989044189453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.828903436660767, "step": 106000}
{"episode_reward": 951.9766471575947, "episode": 107.0, "batch_reward": 0.9172445408701897, "critic_loss": 0.2007399595156312, "actor_loss": -91.78530151367187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.854060649871826, "step": 107000}
{"episode_reward": 953.183373506338, "episode": 108.0, "batch_reward": 0.9185179773569107, "critic_loss": 0.19906251849979162, "actor_loss": -91.44323489379883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.94739603996277, "step": 108000}
{"episode_reward": 966.9074603857323, "episode": 109.0, "batch_reward": 0.9192898903489113, "critic_loss": 0.19005250542983412, "actor_loss": -91.79191445922852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.87361431121826, "step": 109000}
{"episode_reward": 892.6065845509714, "episode": 110.0, "batch_reward": 0.9176313510537147, "critic_loss": 0.20439105945080518, "actor_loss": -91.42091427612304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.965235471725464, "step": 110000}
{"episode_reward": 903.1978563039372, "episode": 111.0, "batch_reward": 0.9189409818649292, "critic_loss": 0.20427095851302146, "actor_loss": -91.68700283813476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.384944677352905, "step": 111000}
{"episode_reward": 969.121740852074, "episode": 112.0, "batch_reward": 0.9186291581988335, "critic_loss": 0.1893249573558569, "actor_loss": -91.4613254852295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.46318769454956, "step": 112000}
{"episode_reward": 954.0879823750644, "episode": 113.0, "batch_reward": 0.9204485403299332, "critic_loss": 0.1792084133885801, "actor_loss": -91.8999102935791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.030081748962402, "step": 113000}
{"episode_reward": 966.5225871228532, "episode": 114.0, "batch_reward": 0.9205515125989914, "critic_loss": 0.18074430757388474, "actor_loss": -91.53171124267578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.71889901161194, "step": 114000}
{"episode_reward": 945.9319663074261, "episode": 115.0, "batch_reward": 0.9208698896169663, "critic_loss": 0.18215078055486084, "actor_loss": -91.61171963500976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.23274302482605, "step": 115000}
{"episode_reward": 964.4674553504345, "episode": 116.0, "batch_reward": 0.9206761648058891, "critic_loss": 0.19631398952007292, "actor_loss": -91.67208987426758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.15712332725525, "step": 116000}
{"episode_reward": 966.2478998687787, "episode": 117.0, "batch_reward": 0.9212314493656159, "critic_loss": 0.18547415920346974, "actor_loss": -91.94423840332031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.97249674797058, "step": 117000}
{"episode_reward": 961.62060078221, "episode": 118.0, "batch_reward": 0.9211044289469719, "critic_loss": 0.19836037508398294, "actor_loss": -91.8719613647461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.87787413597107, "step": 118000}
{"episode_reward": 960.121929642126, "episode": 119.0, "batch_reward": 0.9216231317520142, "critic_loss": 0.19101003852114082, "actor_loss": -91.90493872070313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.570927619934082, "step": 119000}
{"episode_reward": 950.508970014277, "episode": 120.0, "batch_reward": 0.922223793566227, "critic_loss": 0.19200026968121528, "actor_loss": -91.96494999694825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.792235374450684, "step": 120000}
{"episode_reward": 962.2303673177872, "episode": 121.0, "batch_reward": 0.9227815052270889, "critic_loss": 0.19565764402970673, "actor_loss": -92.14695268249511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.654133796691895, "step": 121000}
{"episode_reward": 949.9814848966787, "episode": 122.0, "batch_reward": 0.9218301820158958, "critic_loss": 0.1864458641819656, "actor_loss": -91.62659770202637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.171504497528076, "step": 122000}
{"episode_reward": 864.1764711325164, "episode": 123.0, "batch_reward": 0.9217982519268989, "critic_loss": 0.19174916857108473, "actor_loss": -91.83424179077149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.589775323867798, "step": 123000}
{"episode_reward": 952.4773454632837, "episode": 124.0, "batch_reward": 0.92033833527565, "critic_loss": 0.18687832536175847, "actor_loss": -91.6795007019043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.718826055526733, "step": 124000}
{"episode_reward": 948.409491035961, "episode": 125.0, "batch_reward": 0.9212801023721695, "critic_loss": 0.1789307589046657, "actor_loss": -91.76078526306152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.162367343902588, "step": 125000}
{"episode_reward": 949.4972061207677, "episode": 126.0, "batch_reward": 0.9214199910163879, "critic_loss": 0.18182178906723856, "actor_loss": -91.72217572021485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.587451696395874, "step": 126000}
{"episode_reward": 968.1933058695809, "episode": 127.0, "batch_reward": 0.9224733350872993, "critic_loss": 0.1817366223782301, "actor_loss": -91.50974870300293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.917799472808838, "step": 127000}
{"episode_reward": 922.0385339330616, "episode": 128.0, "batch_reward": 0.9225069759488106, "critic_loss": 0.17276044481061398, "actor_loss": -91.76624029541016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.368732690811157, "step": 128000}
{"episode_reward": 937.7845796514445, "episode": 129.0, "batch_reward": 0.9219185590147972, "critic_loss": 0.1717743108421564, "actor_loss": -91.70266319274903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.55949068069458, "step": 129000}
{"episode_reward": 966.0510201503305, "episode": 130.0, "batch_reward": 0.922730629503727, "critic_loss": 0.1845137266740203, "actor_loss": -91.79321878051758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.83770775794983, "step": 130000}
{"episode_reward": 928.5627514251746, "episode": 131.0, "batch_reward": 0.9236598796844483, "critic_loss": 0.17295839387550951, "actor_loss": -91.81938458251953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.242719888687134, "step": 131000}
{"episode_reward": 952.8679388724786, "episode": 132.0, "batch_reward": 0.9224441178441047, "critic_loss": 0.18825361943617464, "actor_loss": -91.78650369262695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.421463012695312, "step": 132000}
{"episode_reward": 908.2470775956384, "episode": 133.0, "batch_reward": 0.9239716616272926, "critic_loss": 0.17435848451405764, "actor_loss": -92.26707232666016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.19338321685791, "step": 133000}
{"episode_reward": 966.0748232488012, "episode": 134.0, "batch_reward": 0.9233598520755768, "critic_loss": 0.18338843459263443, "actor_loss": -91.87207026672364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.437355995178223, "step": 134000}
{"episode_reward": 946.0389153039413, "episode": 135.0, "batch_reward": 0.9224420810341835, "critic_loss": 0.1715021857060492, "actor_loss": -91.66067280578613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.603929042816162, "step": 135000}
{"episode_reward": 940.6314121391446, "episode": 136.0, "batch_reward": 0.9241135991811752, "critic_loss": 0.1832427037730813, "actor_loss": -91.84420677185058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.979350566864014, "step": 136000}
{"episode_reward": 887.3371172710541, "episode": 137.0, "batch_reward": 0.9238682283163071, "critic_loss": 0.17785032164677977, "actor_loss": -91.80074543762207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.533878803253174, "step": 137000}
{"episode_reward": 930.0052324951953, "episode": 138.0, "batch_reward": 0.9239507924318313, "critic_loss": 0.17816765494272113, "actor_loss": -91.97568405151367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.935763597488403, "step": 138000}
{"episode_reward": 968.0379504844977, "episode": 139.0, "batch_reward": 0.9227556313276291, "critic_loss": 0.17799393077939749, "actor_loss": -91.94008682250977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.54557204246521, "step": 139000}
{"episode_reward": 899.5305702819538, "episode": 140.0, "batch_reward": 0.9236862859725952, "critic_loss": 0.18377082546427845, "actor_loss": -91.99314057922363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.737071752548218, "step": 140000}
{"episode_reward": 967.2910233982788, "episode": 141.0, "batch_reward": 0.9259331769943238, "critic_loss": 0.1770799014903605, "actor_loss": -91.7791068725586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.54837417602539, "step": 141000}
{"episode_reward": 951.3951727613596, "episode": 142.0, "batch_reward": 0.9245100958347321, "critic_loss": 0.16762497793510556, "actor_loss": -91.9024707183838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.84769582748413, "step": 142000}
{"episode_reward": 948.6542780517757, "episode": 143.0, "batch_reward": 0.9238065638542176, "critic_loss": 0.1650292974822223, "actor_loss": -91.96663339233399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.47189998626709, "step": 143000}
{"episode_reward": 946.8073567669808, "episode": 144.0, "batch_reward": 0.9239037741422653, "critic_loss": 0.18625284128263592, "actor_loss": -91.88883155822754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.02826714515686, "step": 144000}
{"episode_reward": 949.4714964694227, "episode": 145.0, "batch_reward": 0.9256428190469742, "critic_loss": 0.1809203154705465, "actor_loss": -91.8305609741211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.10853433609009, "step": 145000}
{"episode_reward": 943.9451257741194, "episode": 146.0, "batch_reward": 0.924529993057251, "critic_loss": 0.16454484353587032, "actor_loss": -92.0749481048584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.51684832572937, "step": 146000}
{"episode_reward": 927.0820289685945, "episode": 147.0, "batch_reward": 0.9247948031425476, "critic_loss": 0.18229943391680717, "actor_loss": -91.99947312927246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.00693392753601, "step": 147000}
{"episode_reward": 955.1471407012481, "episode": 148.0, "batch_reward": 0.9250019010305405, "critic_loss": 0.1681789299938828, "actor_loss": -92.0532815246582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.4822416305542, "step": 148000}
{"episode_reward": 931.8558417866884, "episode": 149.0, "batch_reward": 0.9256647069454194, "critic_loss": 0.1579909335114062, "actor_loss": -91.93056782531738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.9729106426239, "step": 149000}
{"episode_reward": 909.381670521218, "episode": 150.0, "batch_reward": 0.9252295442819596, "critic_loss": 0.16062162904813887, "actor_loss": -91.64544854736329, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
