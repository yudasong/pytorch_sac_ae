{"episode_reward": 0.0, "episode": 1.0, "duration": 20.478472232818604, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 1.7828457355499268, "step": 2000}
{"episode_reward": 896.1586144851467, "episode": 3.0, "batch_reward": 0.508999853282819, "critic_loss": 0.25074307628972164, "actor_loss": -86.80723282660232, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.304114818573, "step": 3000}
{"episode_reward": 929.0856134850806, "episode": 4.0, "batch_reward": 0.6496769152879714, "critic_loss": 0.2396626963019371, "actor_loss": -89.3159610900879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006821155548096, "step": 4000}
{"episode_reward": 872.7650381612168, "episode": 5.0, "batch_reward": 0.6922706066966057, "critic_loss": 0.3430692517310381, "actor_loss": -90.13307432556152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.996245861053467, "step": 5000}
{"episode_reward": 834.6830863036608, "episode": 6.0, "batch_reward": 0.6803217307925224, "critic_loss": 0.3490101900100708, "actor_loss": -89.69046615600585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00822138786316, "step": 6000}
{"episode_reward": 505.8159169696377, "episode": 7.0, "batch_reward": 0.7038686555027962, "critic_loss": 0.3912683380693197, "actor_loss": -90.10592691040038, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9942729473114, "step": 7000}
{"episode_reward": 956.0583541036281, "episode": 8.0, "batch_reward": 0.7331871291399003, "critic_loss": 0.395934406042099, "actor_loss": -90.90077026367187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993676900863647, "step": 8000}
{"episode_reward": 890.001822536609, "episode": 9.0, "batch_reward": 0.7554883180856705, "critic_loss": 0.3789430311769247, "actor_loss": -91.42777684020996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00610327720642, "step": 9000}
{"episode_reward": 976.2333353437133, "episode": 10.0, "batch_reward": 0.7757784340381623, "critic_loss": 0.3684214024394751, "actor_loss": -92.05307872009277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98672127723694, "step": 10000}
{"episode_reward": 944.6090578752194, "episode": 11.0, "batch_reward": 0.7893480527997017, "critic_loss": 0.3908873724937439, "actor_loss": -92.27810725402831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.25790500640869, "step": 11000}
{"episode_reward": 897.0442460969507, "episode": 12.0, "batch_reward": 0.805560683131218, "critic_loss": 0.32057365311682223, "actor_loss": -92.73949987792969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.992587327957153, "step": 12000}
{"episode_reward": 982.4217562800687, "episode": 13.0, "batch_reward": 0.8171459854245186, "critic_loss": 0.28418448244035244, "actor_loss": -93.02731480407715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.001954317092896, "step": 13000}
{"episode_reward": 972.7077621578179, "episode": 14.0, "batch_reward": 0.8211328021287918, "critic_loss": 0.3917579774111509, "actor_loss": -93.01651710510254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98757314682007, "step": 14000}
{"episode_reward": 842.9366108237955, "episode": 15.0, "batch_reward": 0.8203621366024018, "critic_loss": 0.3374032933264971, "actor_loss": -92.84106707763672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.995662450790405, "step": 15000}
{"episode_reward": 826.5122757605092, "episode": 16.0, "batch_reward": 0.8292943227291107, "critic_loss": 0.2888340774029493, "actor_loss": -93.15094891357423, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99113965034485, "step": 16000}
{"episode_reward": 962.6729579499947, "episode": 17.0, "batch_reward": 0.8355694631934166, "critic_loss": 0.31262660552561283, "actor_loss": -93.12598529052734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.000529050827026, "step": 17000}
{"episode_reward": 897.2415356561121, "episode": 18.0, "batch_reward": 0.8387024004459381, "critic_loss": 0.3064811251088977, "actor_loss": -93.19406820678711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00532841682434, "step": 18000}
{"episode_reward": 903.7764027536583, "episode": 19.0, "batch_reward": 0.8445343551635742, "critic_loss": 0.2876484576240182, "actor_loss": -93.35356750488282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.996929168701172, "step": 19000}
{"episode_reward": 983.1198599905968, "episode": 20.0, "batch_reward": 0.8517582928538322, "critic_loss": 0.24948300274461507, "actor_loss": -93.68408699035645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007983207702637, "step": 20000}
{"episode_reward": 974.887366516378, "episode": 21.0, "batch_reward": 0.8585211858153343, "critic_loss": 0.26111472315341233, "actor_loss": -93.70127033996582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.27470898628235, "step": 21000}
{"episode_reward": 943.1740065069911, "episode": 22.0, "batch_reward": 0.8610737416744232, "critic_loss": 0.24665205651521682, "actor_loss": -93.89353630065918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.000515937805176, "step": 22000}
{"episode_reward": 976.1174012284686, "episode": 23.0, "batch_reward": 0.8650293338894844, "critic_loss": 0.27727262666076424, "actor_loss": -93.90793586730958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993191480636597, "step": 23000}
{"episode_reward": 937.884599369189, "episode": 24.0, "batch_reward": 0.8685175902247428, "critic_loss": 0.2855818402469158, "actor_loss": -94.03523277282714, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.996044635772705, "step": 24000}
{"episode_reward": 942.0415172672131, "episode": 25.0, "batch_reward": 0.8728211416602135, "critic_loss": 0.282634191326797, "actor_loss": -94.24440644836426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99274778366089, "step": 25000}
{"episode_reward": 958.1848631392286, "episode": 26.0, "batch_reward": 0.8753024281263352, "critic_loss": 0.25855513218790294, "actor_loss": -94.21714947509766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0081787109375, "step": 26000}
{"episode_reward": 984.0557526856326, "episode": 27.0, "batch_reward": 0.8801890308856964, "critic_loss": 0.2494591600075364, "actor_loss": -94.36131077575683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12498664855957, "step": 27000}
{"episode_reward": 967.44380922026, "episode": 28.0, "batch_reward": 0.8830491235256195, "critic_loss": 0.2863335721939802, "actor_loss": -94.45875712585449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.196266651153564, "step": 28000}
{"episode_reward": 938.8352373466138, "episode": 29.0, "batch_reward": 0.8822374408245086, "critic_loss": 0.3070214079543948, "actor_loss": -94.46763468933105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97254705429077, "step": 29000}
{"episode_reward": 870.3539665430288, "episode": 30.0, "batch_reward": 0.8838312771320344, "critic_loss": 0.3031270355209708, "actor_loss": -94.46989988708496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.973500967025757, "step": 30000}
{"episode_reward": 920.7464823335555, "episode": 31.0, "batch_reward": 0.8865259024500847, "critic_loss": 0.2730757927298546, "actor_loss": -94.5668584136963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.27425217628479, "step": 31000}
{"episode_reward": 962.4999793639603, "episode": 32.0, "batch_reward": 0.887112124800682, "critic_loss": 0.2725528158247471, "actor_loss": -94.59305429077149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002273082733154, "step": 32000}
{"episode_reward": 938.4315934883047, "episode": 33.0, "batch_reward": 0.8896218957304954, "critic_loss": 0.2459630837291479, "actor_loss": -94.67566043090821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.32120132446289, "step": 33000}
{"episode_reward": 953.7488035824667, "episode": 34.0, "batch_reward": 0.8915693737864494, "critic_loss": 0.29302528823912144, "actor_loss": -94.77293379211426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.991801023483276, "step": 34000}
{"episode_reward": 913.6395766324398, "episode": 35.0, "batch_reward": 0.8911162078976631, "critic_loss": 0.2972966975942254, "actor_loss": -94.72610569763184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.961894512176514, "step": 35000}
{"episode_reward": 873.5628797732016, "episode": 36.0, "batch_reward": 0.8908458876609803, "critic_loss": 0.3048179666101932, "actor_loss": -94.85836210632324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.971984386444092, "step": 36000}
{"episode_reward": 923.1337658711113, "episode": 37.0, "batch_reward": 0.8940134470462799, "critic_loss": 0.2997630601525307, "actor_loss": -94.78270780944824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993887662887573, "step": 37000}
{"episode_reward": 987.5867592202613, "episode": 38.0, "batch_reward": 0.8947638221979142, "critic_loss": 0.2813796077370644, "actor_loss": -94.81661585998535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.989854335784912, "step": 38000}
{"episode_reward": 956.4850610128839, "episode": 39.0, "batch_reward": 0.8965001413822175, "critic_loss": 0.28686798333376645, "actor_loss": -94.90345338439941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999831914901733, "step": 39000}
{"episode_reward": 977.2037519354022, "episode": 40.0, "batch_reward": 0.8992095258831978, "critic_loss": 0.2890915810316801, "actor_loss": -95.09218711853028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98219347000122, "step": 40000}
{"episode_reward": 987.5593832722016, "episode": 41.0, "batch_reward": 0.8997229080796242, "critic_loss": 0.28716028641164304, "actor_loss": -95.03669258117675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.267558336257935, "step": 41000}
{"episode_reward": 950.3569058328309, "episode": 42.0, "batch_reward": 0.9029472652673721, "critic_loss": 0.2767370681837201, "actor_loss": -95.1840773010254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98044204711914, "step": 42000}
{"episode_reward": 964.3709978424209, "episode": 43.0, "batch_reward": 0.9038689506053924, "critic_loss": 0.2766826168820262, "actor_loss": -95.20799967956543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98607087135315, "step": 43000}
{"episode_reward": 984.2219696892938, "episode": 44.0, "batch_reward": 0.9054210718870163, "critic_loss": 0.27182537104189397, "actor_loss": -95.42722044372559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9719877243042, "step": 44000}
{"episode_reward": 981.6159579429207, "episode": 45.0, "batch_reward": 0.9076060745120048, "critic_loss": 0.2558752104192972, "actor_loss": -95.41195147705078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98148536682129, "step": 45000}
{"episode_reward": 986.7692137513329, "episode": 46.0, "batch_reward": 0.909365734398365, "critic_loss": 0.25216459383070466, "actor_loss": -95.41092636108398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.974087476730347, "step": 46000}
{"episode_reward": 988.1592663881289, "episode": 47.0, "batch_reward": 0.9113506537079811, "critic_loss": 0.257825622677803, "actor_loss": -95.52231701660156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.984784364700317, "step": 47000}
{"episode_reward": 956.5325454054768, "episode": 48.0, "batch_reward": 0.9115879412293434, "critic_loss": 0.2605385283604264, "actor_loss": -95.51172413635254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.982089519500732, "step": 48000}
{"episode_reward": 959.0298523483676, "episode": 49.0, "batch_reward": 0.9119748247265815, "critic_loss": 0.2316536342203617, "actor_loss": -95.6248854522705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986564874649048, "step": 49000}
{"episode_reward": 983.9744431036356, "episode": 50.0, "batch_reward": 0.9133595901727677, "critic_loss": 0.26259775112941863, "actor_loss": -95.63248657226562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.985514402389526, "step": 50000}
{"episode_reward": 966.8991741723726, "episode": 51.0, "batch_reward": 0.9163744726777077, "critic_loss": 0.22073198924958706, "actor_loss": -95.69828738403321, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.265687227249146, "step": 51000}
{"episode_reward": 960.1151574620097, "episode": 52.0, "batch_reward": 0.9148195118904113, "critic_loss": 0.23451687394082546, "actor_loss": -95.62639332580567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990856647491455, "step": 52000}
{"episode_reward": 886.6019376834754, "episode": 53.0, "batch_reward": 0.9144532013535499, "critic_loss": 0.24474366607517004, "actor_loss": -95.71701968383789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990548133850098, "step": 53000}
{"episode_reward": 960.611215951247, "episode": 54.0, "batch_reward": 0.9169296446442604, "critic_loss": 0.2709238584637642, "actor_loss": -95.79352592468261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.991528034210205, "step": 54000}
{"episode_reward": 967.0424717867171, "episode": 55.0, "batch_reward": 0.9164659065008164, "critic_loss": 0.24993592211604118, "actor_loss": -95.75599383544922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.983899354934692, "step": 55000}
{"episode_reward": 953.0892325545308, "episode": 56.0, "batch_reward": 0.9165256098508835, "critic_loss": 0.25996187832206485, "actor_loss": -95.73665000915527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993377447128296, "step": 56000}
{"episode_reward": 956.3546705006214, "episode": 57.0, "batch_reward": 0.9194550129771233, "critic_loss": 0.28820871299505235, "actor_loss": -95.82084455871582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002026796340942, "step": 57000}
{"episode_reward": 980.2060005421961, "episode": 58.0, "batch_reward": 0.9187159956097602, "critic_loss": 0.28329929937422277, "actor_loss": -95.82257070922851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.001089096069336, "step": 58000}
{"episode_reward": 934.2555378122422, "episode": 59.0, "batch_reward": 0.9202820261120797, "critic_loss": 0.2828106890544295, "actor_loss": -95.81664999389649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99325704574585, "step": 59000}
{"episode_reward": 988.8847086097429, "episode": 60.0, "batch_reward": 0.921008612036705, "critic_loss": 0.253393973313272, "actor_loss": -95.95713609313965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00046992301941, "step": 60000}
{"episode_reward": 977.5305679972338, "episode": 61.0, "batch_reward": 0.9205060266852378, "critic_loss": 0.30373116372525694, "actor_loss": -95.855443649292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.276872873306274, "step": 61000}
{"episode_reward": 886.5640953598146, "episode": 62.0, "batch_reward": 0.9211639906764031, "critic_loss": 0.31959033343195914, "actor_loss": -95.88061541748047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99539303779602, "step": 62000}
{"episode_reward": 894.3802039215706, "episode": 63.0, "batch_reward": 0.9209869906902314, "critic_loss": 0.29732672350853684, "actor_loss": -95.90132626342773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9926335811615, "step": 63000}
{"episode_reward": 976.7859470407644, "episode": 64.0, "batch_reward": 0.9218565738201141, "critic_loss": 0.27030488674342634, "actor_loss": -95.92258990478516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990676164627075, "step": 64000}
{"episode_reward": 943.9401389498056, "episode": 65.0, "batch_reward": 0.9222015138864518, "critic_loss": 0.2791152654066682, "actor_loss": -95.92630995178223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002636671066284, "step": 65000}
{"episode_reward": 977.5507379767629, "episode": 66.0, "batch_reward": 0.922202646791935, "critic_loss": 0.2985931831523776, "actor_loss": -95.85767175292969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997835397720337, "step": 66000}
{"episode_reward": 903.4080825790892, "episode": 67.0, "batch_reward": 0.9233006572723389, "critic_loss": 0.2993955923356116, "actor_loss": -95.98094584655762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005597829818726, "step": 67000}
{"episode_reward": 954.0835646066146, "episode": 68.0, "batch_reward": 0.9229560726284981, "critic_loss": 0.28966026083379987, "actor_loss": -95.98877505493164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9977924823761, "step": 68000}
{"episode_reward": 954.2255447084257, "episode": 69.0, "batch_reward": 0.9217875621914864, "critic_loss": 0.3147376147583127, "actor_loss": -95.89526409912109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997716426849365, "step": 69000}
{"episode_reward": 891.5699311981795, "episode": 70.0, "batch_reward": 0.9236913326382638, "critic_loss": 0.3523429984971881, "actor_loss": -95.94015612792968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.992834091186523, "step": 70000}
{"episode_reward": 960.8085367409939, "episode": 71.0, "batch_reward": 0.923118473649025, "critic_loss": 0.3137099164500833, "actor_loss": -95.93950970458984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.264321088790894, "step": 71000}
{"episode_reward": 880.9251528055466, "episode": 72.0, "batch_reward": 0.9225853524804115, "critic_loss": 0.34738789828121663, "actor_loss": -95.96974649047851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.983463048934937, "step": 72000}
{"episode_reward": 965.857183663924, "episode": 73.0, "batch_reward": 0.9240918387770652, "critic_loss": 0.35552165610343217, "actor_loss": -95.94987823486328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.994665145874023, "step": 73000}
{"episode_reward": 951.5896616480411, "episode": 74.0, "batch_reward": 0.9243303454518318, "critic_loss": 0.34616989669948817, "actor_loss": -95.95949501037597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.994651794433594, "step": 74000}
{"episode_reward": 954.4579509317667, "episode": 75.0, "batch_reward": 0.9233670110106468, "critic_loss": 0.3412634264305234, "actor_loss": -95.95376959228516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99659299850464, "step": 75000}
{"episode_reward": 917.9269467437686, "episode": 76.0, "batch_reward": 0.9254615146517754, "critic_loss": 0.3239908368214965, "actor_loss": -96.00076039123535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990174531936646, "step": 76000}
{"episode_reward": 945.6346915710915, "episode": 77.0, "batch_reward": 0.9234982453584671, "critic_loss": 0.32883671546727417, "actor_loss": -95.96847811889648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99777388572693, "step": 77000}
{"episode_reward": 913.2883201140534, "episode": 78.0, "batch_reward": 0.9252415561676025, "critic_loss": 0.3519425818659365, "actor_loss": -96.05637698364258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.992300510406494, "step": 78000}
{"episode_reward": 986.577871937019, "episode": 79.0, "batch_reward": 0.9254488136768341, "critic_loss": 0.3205470453426242, "actor_loss": -96.07326219177246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993911027908325, "step": 79000}
{"episode_reward": 944.4934074318362, "episode": 80.0, "batch_reward": 0.9247688481807709, "critic_loss": 0.29527418317645787, "actor_loss": -96.02719221496582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006991386413574, "step": 80000}
{"episode_reward": 911.2248739307294, "episode": 81.0, "batch_reward": 0.9257783846259117, "critic_loss": 0.32003961864113806, "actor_loss": -96.03078509521484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.26221585273743, "step": 81000}
{"episode_reward": 977.9270628027931, "episode": 82.0, "batch_reward": 0.9255475130081177, "critic_loss": 0.34247467168420553, "actor_loss": -96.00423637390136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.998551845550537, "step": 82000}
{"episode_reward": 951.3320360923075, "episode": 83.0, "batch_reward": 0.9279511206150055, "critic_loss": 0.30636930162459614, "actor_loss": -96.10252661132813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997185468673706, "step": 83000}
{"episode_reward": 981.0994461659767, "episode": 84.0, "batch_reward": 0.9259486457705498, "critic_loss": 0.303549319088459, "actor_loss": -96.12194889831542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99434781074524, "step": 84000}
{"episode_reward": 935.1712613229571, "episode": 85.0, "batch_reward": 0.9254054974913597, "critic_loss": 0.3275276034101844, "actor_loss": -96.06790408325195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99131727218628, "step": 85000}
{"episode_reward": 950.1681579325057, "episode": 86.0, "batch_reward": 0.9271352332234383, "critic_loss": 0.3569541379585862, "actor_loss": -96.06152185058593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9992995262146, "step": 86000}
{"episode_reward": 961.2837993852183, "episode": 87.0, "batch_reward": 0.9281638405919075, "critic_loss": 0.3285050758831203, "actor_loss": -96.16744750976562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.992441415786743, "step": 87000}
{"episode_reward": 984.343972432124, "episode": 88.0, "batch_reward": 0.9276608754396438, "critic_loss": 0.33468903132528066, "actor_loss": -96.0866509399414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999939441680908, "step": 88000}
{"episode_reward": 968.4364668605431, "episode": 89.0, "batch_reward": 0.9280908898711204, "critic_loss": 0.32899171745032074, "actor_loss": -96.1049895324707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99238920211792, "step": 89000}
{"episode_reward": 910.4636254827732, "episode": 90.0, "batch_reward": 0.9294806591272354, "critic_loss": 0.32906428969651463, "actor_loss": -96.14136679077149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99346351623535, "step": 90000}
{"episode_reward": 940.0257108034884, "episode": 91.0, "batch_reward": 0.9288650421500206, "critic_loss": 0.29466583535820245, "actor_loss": -96.14475859069825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.25942015647888, "step": 91000}
{"episode_reward": 975.7340890316301, "episode": 92.0, "batch_reward": 0.9283943445682525, "critic_loss": 0.29639934830367565, "actor_loss": -96.17925657653808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99120306968689, "step": 92000}
{"episode_reward": 947.6572208725931, "episode": 93.0, "batch_reward": 0.9292047035098076, "critic_loss": 0.3085635000690818, "actor_loss": -96.15588108825683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997524738311768, "step": 93000}
{"episode_reward": 958.6560216632752, "episode": 94.0, "batch_reward": 0.9288877195119858, "critic_loss": 0.3046080007478595, "actor_loss": -96.19251196289062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00249433517456, "step": 94000}
{"episode_reward": 923.296073360438, "episode": 95.0, "batch_reward": 0.9291531754732132, "critic_loss": 0.32741049306094644, "actor_loss": -96.22370457458496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.001564264297485, "step": 95000}
{"episode_reward": 925.4538809591178, "episode": 96.0, "batch_reward": 0.9301639924645424, "critic_loss": 0.29754205398261546, "actor_loss": -96.23390516662597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004638671875, "step": 96000}
{"episode_reward": 961.8417433206406, "episode": 97.0, "batch_reward": 0.9292869611382485, "critic_loss": 0.32754146586358546, "actor_loss": -96.20707893371582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00417923927307, "step": 97000}
{"episode_reward": 984.0044159312895, "episode": 98.0, "batch_reward": 0.9303865166902542, "critic_loss": 0.3226479083672166, "actor_loss": -96.3285757598877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.996794939041138, "step": 98000}
{"episode_reward": 978.8498128576949, "episode": 99.0, "batch_reward": 0.9312103684544564, "critic_loss": 0.30444814217463134, "actor_loss": -96.24931341552734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005887269973755, "step": 99000}
{"episode_reward": 987.1768347160495, "episode": 100.0, "batch_reward": 0.9307895724177361, "critic_loss": 0.3067738847658038, "actor_loss": -96.22442254638672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002827644348145, "step": 100000}
{"episode_reward": 945.8109803480531, "episode": 101.0, "batch_reward": 0.9313201925158501, "critic_loss": 0.3246333092451096, "actor_loss": -96.2725352935791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.26455760002136, "step": 101000}
{"episode_reward": 957.5377712059516, "episode": 102.0, "batch_reward": 0.9331672394871712, "critic_loss": 0.31367840407788755, "actor_loss": -96.35377171325683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99133825302124, "step": 102000}
{"episode_reward": 986.2524006845808, "episode": 103.0, "batch_reward": 0.932840690612793, "critic_loss": 0.3027310342006385, "actor_loss": -96.37928448486328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99607014656067, "step": 103000}
{"episode_reward": 975.2159670397543, "episode": 104.0, "batch_reward": 0.9330413326621055, "critic_loss": 0.2774910628050566, "actor_loss": -96.33235144042969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98744225502014, "step": 104000}
{"episode_reward": 956.6902930515903, "episode": 105.0, "batch_reward": 0.9324745782017708, "critic_loss": 0.285618173122406, "actor_loss": -96.35734664916993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.001601219177246, "step": 105000}
{"episode_reward": 943.7582727536022, "episode": 106.0, "batch_reward": 0.9334079008102417, "critic_loss": 0.29103241681307557, "actor_loss": -96.38201817321777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.989176750183105, "step": 106000}
{"episode_reward": 977.7219402872956, "episode": 107.0, "batch_reward": 0.9331380940079689, "critic_loss": 0.2893544798903167, "actor_loss": -96.32094184875488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003182649612427, "step": 107000}
{"episode_reward": 972.8218792443218, "episode": 108.0, "batch_reward": 0.9341493926644325, "critic_loss": 0.28257714768126607, "actor_loss": -96.44246150207519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.987092971801758, "step": 108000}
{"episode_reward": 976.8837758563694, "episode": 109.0, "batch_reward": 0.9350820395350457, "critic_loss": 0.2756941764205694, "actor_loss": -96.45323481750488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98848009109497, "step": 109000}
{"episode_reward": 954.1755792619522, "episode": 110.0, "batch_reward": 0.9337424969673157, "critic_loss": 0.28788005857914684, "actor_loss": -96.45261961364746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99241614341736, "step": 110000}
{"episode_reward": 921.5138987977421, "episode": 111.0, "batch_reward": 0.9345495871901512, "critic_loss": 0.28459339747950435, "actor_loss": -96.42932391357422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.2669472694397, "step": 111000}
{"episode_reward": 979.3025167570663, "episode": 112.0, "batch_reward": 0.9342979185581207, "critic_loss": 0.28248358695209025, "actor_loss": -96.46068603515624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.995499849319458, "step": 112000}
{"episode_reward": 939.168658225724, "episode": 113.0, "batch_reward": 0.9353437963724136, "critic_loss": 0.27466885520890355, "actor_loss": -96.47737274169921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00168752670288, "step": 113000}
{"episode_reward": 971.0985007007683, "episode": 114.0, "batch_reward": 0.9360372641086578, "critic_loss": 0.2628725331127644, "actor_loss": -96.5074933013916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990556955337524, "step": 114000}
{"episode_reward": 962.4887592435356, "episode": 115.0, "batch_reward": 0.9364429898262024, "critic_loss": 0.2857585645653307, "actor_loss": -96.51866819763184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.996801376342773, "step": 115000}
{"episode_reward": 985.9209300056149, "episode": 116.0, "batch_reward": 0.9363800753355026, "critic_loss": 0.2798464887663722, "actor_loss": -96.47364413452148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999197721481323, "step": 116000}
{"episode_reward": 987.5634947653684, "episode": 117.0, "batch_reward": 0.9371768692731858, "critic_loss": 0.3187687755972147, "actor_loss": -96.51449543762207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986623525619507, "step": 117000}
{"episode_reward": 955.829804764191, "episode": 118.0, "batch_reward": 0.9361635858416557, "critic_loss": 0.3055456247627735, "actor_loss": -96.46763467407227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.998721599578857, "step": 118000}
{"episode_reward": 923.652041081484, "episode": 119.0, "batch_reward": 0.9368054889440537, "critic_loss": 0.2884383794777095, "actor_loss": -96.48403485107421, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.995322942733765, "step": 119000}
{"episode_reward": 954.0054034448193, "episode": 120.0, "batch_reward": 0.9366847433447838, "critic_loss": 0.2653331760652363, "actor_loss": -96.50698332214355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990633487701416, "step": 120000}
{"episode_reward": 984.923076449402, "episode": 121.0, "batch_reward": 0.9371497603654861, "critic_loss": 0.28395298700034616, "actor_loss": -96.53593460083007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.28767251968384, "step": 121000}
{"episode_reward": 906.6923208895518, "episode": 122.0, "batch_reward": 0.9363632736802101, "critic_loss": 0.30303849155455825, "actor_loss": -96.51791096496582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.987955570220947, "step": 122000}
{"episode_reward": 950.7873268107714, "episode": 123.0, "batch_reward": 0.9372114171385765, "critic_loss": 0.2933430949561298, "actor_loss": -96.55396315002442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004741430282593, "step": 123000}
{"episode_reward": 930.734692805839, "episode": 124.0, "batch_reward": 0.9371335834860802, "critic_loss": 0.289337790120393, "actor_loss": -96.50691064453125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997936487197876, "step": 124000}
{"episode_reward": 969.5848246348909, "episode": 125.0, "batch_reward": 0.9364612781405449, "critic_loss": 0.2811136071719229, "actor_loss": -96.49749041748046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99741840362549, "step": 125000}
{"episode_reward": 945.0959879056322, "episode": 126.0, "batch_reward": 0.9359093112945557, "critic_loss": 0.2577426530532539, "actor_loss": -96.49977076721191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99445080757141, "step": 126000}
{"episode_reward": 975.6742620061399, "episode": 127.0, "batch_reward": 0.9368882818222046, "critic_loss": 0.279034612134099, "actor_loss": -96.52144132995605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003653526306152, "step": 127000}
{"episode_reward": 952.4100857693002, "episode": 128.0, "batch_reward": 0.9371473113298416, "critic_loss": 0.2647717225477099, "actor_loss": -96.52837065124511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005382776260376, "step": 128000}
{"episode_reward": 968.146597166659, "episode": 129.0, "batch_reward": 0.9375904796719551, "critic_loss": 0.27496586804836987, "actor_loss": -96.5271427154541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0047607421875, "step": 129000}
{"episode_reward": 981.4810248679246, "episode": 130.0, "batch_reward": 0.9382754619121552, "critic_loss": 0.2760267826244235, "actor_loss": -96.58002470397949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00398302078247, "step": 130000}
{"episode_reward": 948.1028378780961, "episode": 131.0, "batch_reward": 0.9385492913126946, "critic_loss": 0.25996060131117704, "actor_loss": -96.54773483276367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.282981634140015, "step": 131000}
{"episode_reward": 960.7485007956117, "episode": 132.0, "batch_reward": 0.9383920677900315, "critic_loss": 0.2693056715168059, "actor_loss": -96.59757699584961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00290012359619, "step": 132000}
{"episode_reward": 915.8200699447652, "episode": 133.0, "batch_reward": 0.9389189073443412, "critic_loss": 0.2912869372405112, "actor_loss": -96.57330191040039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.996407747268677, "step": 133000}
{"episode_reward": 978.0555551369763, "episode": 134.0, "batch_reward": 0.9385410032868385, "critic_loss": 0.27418171966448424, "actor_loss": -96.58272833251954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.992785930633545, "step": 134000}
{"episode_reward": 975.3034311472506, "episode": 135.0, "batch_reward": 0.9375587865710259, "critic_loss": 0.2685842057354748, "actor_loss": -96.56197885131836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002503633499146, "step": 135000}
{"episode_reward": 948.7528428002158, "episode": 136.0, "batch_reward": 0.9393384450674057, "critic_loss": 0.2618079725578427, "actor_loss": -96.61826820373535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99547576904297, "step": 136000}
{"episode_reward": 935.5845596791412, "episode": 137.0, "batch_reward": 0.9386051731109619, "critic_loss": 0.2882190276645124, "actor_loss": -96.59164680480957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003405332565308, "step": 137000}
{"episode_reward": 910.3236881183591, "episode": 138.0, "batch_reward": 0.9397045096755028, "critic_loss": 0.2738790219649673, "actor_loss": -96.60778439331055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993952751159668, "step": 138000}
{"episode_reward": 983.2207370121049, "episode": 139.0, "batch_reward": 0.9378968353867531, "critic_loss": 0.2641463631242514, "actor_loss": -96.54986337280273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00142240524292, "step": 139000}
{"episode_reward": 928.5299069749365, "episode": 140.0, "batch_reward": 0.9382088733911514, "critic_loss": 0.260585290543735, "actor_loss": -96.5851287536621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00050163269043, "step": 140000}
{"episode_reward": 961.7533776217531, "episode": 141.0, "batch_reward": 0.9402570063471795, "critic_loss": 0.24648207315057516, "actor_loss": -96.66459466552735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.25834822654724, "step": 141000}
{"episode_reward": 945.0221529077094, "episode": 142.0, "batch_reward": 0.9393141813278199, "critic_loss": 0.24991399792954325, "actor_loss": -96.62118925476074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986234664916992, "step": 142000}
{"episode_reward": 982.3451260446623, "episode": 143.0, "batch_reward": 0.9389965509176255, "critic_loss": 0.2486461862400174, "actor_loss": -96.60406704711914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997298002243042, "step": 143000}
{"episode_reward": 891.4431611300638, "episode": 144.0, "batch_reward": 0.9378848330378532, "critic_loss": 0.26627954495325684, "actor_loss": -96.62035409545898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99867558479309, "step": 144000}
{"episode_reward": 925.8952597942441, "episode": 145.0, "batch_reward": 0.9400394369363785, "critic_loss": 0.23677974312007427, "actor_loss": -96.63923165893554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993645191192627, "step": 145000}
{"episode_reward": 962.8616212110805, "episode": 146.0, "batch_reward": 0.9387429265975952, "critic_loss": 0.2736484138742089, "actor_loss": -96.50417376708984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99455237388611, "step": 146000}
{"episode_reward": 933.8657142787935, "episode": 147.0, "batch_reward": 0.9384712800383568, "critic_loss": 0.2631092299595475, "actor_loss": -96.5811781616211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.146615266799927, "step": 147000}
{"episode_reward": 962.0076714373864, "episode": 148.0, "batch_reward": 0.9393468879461289, "critic_loss": 0.2787911452688277, "actor_loss": -96.62658338928223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.173869371414185, "step": 148000}
{"episode_reward": 958.8318417618127, "episode": 149.0, "batch_reward": 0.9387776090502739, "critic_loss": 0.2642158606313169, "actor_loss": -96.57527668762206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97060537338257, "step": 149000}
{"episode_reward": 861.0102443777879, "episode": 150.0, "batch_reward": 0.938633501291275, "critic_loss": 0.25653810987621545, "actor_loss": -96.58061833190918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
