{"episode_reward": 0.0, "episode": 1.0, "duration": 25.356571197509766, "step": 1000}
{"episode_reward": 61.50603977848499, "episode": 2.0, "duration": 2.5247037410736084, "step": 2000}
{"episode_reward": 808.9209525976895, "episode": 3.0, "batch_reward": 0.460911710894716, "critic_loss": 0.30277029726754906, "actor_loss": -79.54958781608346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 94.87309718132019, "step": 3000}
{"episode_reward": 855.6821198828425, "episode": 4.0, "batch_reward": 0.6141952985823155, "critic_loss": 0.4582444601804018, "actor_loss": -87.64365739440917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.443652391433716, "step": 4000}
{"episode_reward": 871.6553040492822, "episode": 5.0, "batch_reward": 0.5912462450563908, "critic_loss": 0.7838905828893185, "actor_loss": -89.2071069946289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.19896674156189, "step": 5000}
{"episode_reward": 67.86865982279298, "episode": 6.0, "batch_reward": 0.48705360847711565, "critic_loss": 0.5789014256894588, "actor_loss": -88.97220230102539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.96228337287903, "step": 6000}
{"episode_reward": 32.0180579871824, "episode": 7.0, "batch_reward": 0.4817064262330532, "critic_loss": 0.4704635433554649, "actor_loss": -89.60010466003418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.73525834083557, "step": 7000}
{"episode_reward": 897.5965849436644, "episode": 8.0, "batch_reward": 0.5366891674399376, "critic_loss": 0.43701237013936045, "actor_loss": -89.80370666503906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.95053243637085, "step": 8000}
{"episode_reward": 915.9418285127018, "episode": 9.0, "batch_reward": 0.5849943959414959, "critic_loss": 0.38332691794633866, "actor_loss": -90.03522477722169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.679433584213257, "step": 9000}
{"episode_reward": 941.8869132196801, "episode": 10.0, "batch_reward": 0.6209468821883202, "critic_loss": 0.3553222009092569, "actor_loss": -89.99332740783692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.387550354003906, "step": 10000}
{"episode_reward": 913.7213538381804, "episode": 11.0, "batch_reward": 0.644824378490448, "critic_loss": 0.3190085551887751, "actor_loss": -90.2357773590088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 53.592642068862915, "step": 11000}
{"episode_reward": 869.6166897744127, "episode": 12.0, "batch_reward": 0.6660313736200333, "critic_loss": 0.2859092063158751, "actor_loss": -90.04702359008789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.38089156150818, "step": 12000}
{"episode_reward": 791.7318610880135, "episode": 13.0, "batch_reward": 0.6762593152523041, "critic_loss": 0.25256186681985854, "actor_loss": -90.30510079956055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.891977548599243, "step": 13000}
{"episode_reward": 878.4992901000735, "episode": 14.0, "batch_reward": 0.6657828593254089, "critic_loss": 0.263289439946413, "actor_loss": -89.3973856048584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.26283073425293, "step": 14000}
{"episode_reward": 354.82513562995376, "episode": 15.0, "batch_reward": 0.6662918410897255, "critic_loss": 0.27151538912951945, "actor_loss": -88.97544010925293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.611894130706787, "step": 15000}
{"episode_reward": 874.6579826066426, "episode": 16.0, "batch_reward": 0.6835139068365097, "critic_loss": 0.2638501969128847, "actor_loss": -89.03196691894532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.58337378501892, "step": 16000}
{"episode_reward": 933.9703053551377, "episode": 17.0, "batch_reward": 0.6977425744533539, "critic_loss": 0.2567399178147316, "actor_loss": -88.9509461517334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.133299827575684, "step": 17000}
{"episode_reward": 891.321288963169, "episode": 18.0, "batch_reward": 0.6971238854527474, "critic_loss": 0.2574983541816473, "actor_loss": -88.87928352355956, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.544525146484375, "step": 18000}
{"episode_reward": 632.6893389562289, "episode": 19.0, "batch_reward": 0.7043626003861427, "critic_loss": 0.2597386753559113, "actor_loss": -88.78374104309081, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.58230710029602, "step": 19000}
{"episode_reward": 927.1380619909653, "episode": 20.0, "batch_reward": 0.7174922689199448, "critic_loss": 0.2480104541182518, "actor_loss": -89.17107336425781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.0148446559906, "step": 20000}
{"episode_reward": 948.7695619343522, "episode": 21.0, "batch_reward": 0.7279418175816535, "critic_loss": 0.30715521562099457, "actor_loss": -89.3632409210205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 50.851584911346436, "step": 21000}
{"episode_reward": 759.4908987876515, "episode": 22.0, "batch_reward": 0.726312125325203, "critic_loss": 0.3189172732681036, "actor_loss": -88.79149974060059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.20540261268616, "step": 22000}
{"episode_reward": 911.3078783104432, "episode": 23.0, "batch_reward": 0.7352285187840462, "critic_loss": 0.2779282021820545, "actor_loss": -89.24505421447753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.92646813392639, "step": 23000}
{"episode_reward": 916.0680765112285, "episode": 24.0, "batch_reward": 0.7443772571086884, "critic_loss": 0.2826302112340927, "actor_loss": -89.1086482849121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.506781101226807, "step": 24000}
{"episode_reward": 926.1217115909715, "episode": 25.0, "batch_reward": 0.7518437845110894, "critic_loss": 0.28222985357046126, "actor_loss": -89.60478392028809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.58543372154236, "step": 25000}
{"episode_reward": 929.3508925755887, "episode": 26.0, "batch_reward": 0.7592430223226547, "critic_loss": 0.26669382214546206, "actor_loss": -90.02118330383301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.805782794952393, "step": 26000}
{"episode_reward": 933.5909421089393, "episode": 27.0, "batch_reward": 0.7676696484684944, "critic_loss": 0.2604261870235205, "actor_loss": -90.33509764099121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.712648153305054, "step": 27000}
{"episode_reward": 957.973532177641, "episode": 28.0, "batch_reward": 0.773638890862465, "critic_loss": 0.24238009201735258, "actor_loss": -90.33315734863281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.439897537231445, "step": 28000}
{"episode_reward": 942.139113232844, "episode": 29.0, "batch_reward": 0.7790808731913567, "critic_loss": 0.24122472782433033, "actor_loss": -90.49374043273926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.98046040534973, "step": 29000}
{"episode_reward": 944.2956564482299, "episode": 30.0, "batch_reward": 0.786200765311718, "critic_loss": 0.24164388972520828, "actor_loss": -91.15476139831543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.61353826522827, "step": 30000}
{"episode_reward": 931.2270006317761, "episode": 31.0, "batch_reward": 0.7905009073615075, "critic_loss": 0.23339143657684328, "actor_loss": -90.93172923278809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 50.6907639503479, "step": 31000}
{"episode_reward": 948.1224870413571, "episode": 32.0, "batch_reward": 0.7903318948149681, "critic_loss": 0.2339754320308566, "actor_loss": -90.63110229492187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.747785568237305, "step": 32000}
{"episode_reward": 811.6055311131194, "episode": 33.0, "batch_reward": 0.7868980103731156, "critic_loss": 0.24545132292062044, "actor_loss": -90.54197485351563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.730210065841675, "step": 33000}
{"episode_reward": 619.207017744805, "episode": 34.0, "batch_reward": 0.7910305565595627, "critic_loss": 0.2302026757225394, "actor_loss": -91.01081405639648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.849341869354248, "step": 34000}
{"episode_reward": 958.7024271522234, "episode": 35.0, "batch_reward": 0.7941494403481484, "critic_loss": 0.24381514681130648, "actor_loss": -90.24485227966309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.24272012710571, "step": 35000}
{"episode_reward": 911.9843574289408, "episode": 36.0, "batch_reward": 0.7949858067631721, "critic_loss": 0.2421382072493434, "actor_loss": -90.40983831787109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.479818105697632, "step": 36000}
{"episode_reward": 849.1995307066594, "episode": 37.0, "batch_reward": 0.8003959369063377, "critic_loss": 0.23741833064705134, "actor_loss": -90.5674168548584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.640758752822876, "step": 37000}
{"episode_reward": 966.8021309561154, "episode": 38.0, "batch_reward": 0.8038361746668815, "critic_loss": 0.2268501310199499, "actor_loss": -90.65815751647949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.749528884887695, "step": 38000}
{"episode_reward": 950.2086874888154, "episode": 39.0, "batch_reward": 0.8077573311328888, "critic_loss": 0.23932805435359478, "actor_loss": -90.45448999023438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.6824951171875, "step": 39000}
{"episode_reward": 964.1494884869435, "episode": 40.0, "batch_reward": 0.8125398359894752, "critic_loss": 0.24544179911911487, "actor_loss": -90.86323338317871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.866634368896484, "step": 40000}
{"episode_reward": 964.7499600213782, "episode": 41.0, "batch_reward": 0.8145717276334763, "critic_loss": 0.24427981884777547, "actor_loss": -90.79932695007324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.17154598236084, "step": 41000}
{"episode_reward": 969.5888139666637, "episode": 42.0, "batch_reward": 0.8184860178828239, "critic_loss": 0.25621307228505613, "actor_loss": -90.82777673339844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.187617301940918, "step": 42000}
{"episode_reward": 937.7778484846438, "episode": 43.0, "batch_reward": 0.8213801434636117, "critic_loss": 0.26360550937801597, "actor_loss": -90.94683976745605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.89952516555786, "step": 43000}
{"episode_reward": 968.0921202793056, "episode": 44.0, "batch_reward": 0.8276102351546287, "critic_loss": 0.24326351784169675, "actor_loss": -91.13938432312011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.20450758934021, "step": 44000}
{"episode_reward": 960.8669855759963, "episode": 45.0, "batch_reward": 0.8279001882076263, "critic_loss": 0.2365059491544962, "actor_loss": -91.12004100036621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.473633766174316, "step": 45000}
{"episode_reward": 960.4364676554259, "episode": 46.0, "batch_reward": 0.8306267793774604, "critic_loss": 0.24329404328763485, "actor_loss": -91.3672642364502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.004342794418335, "step": 46000}
{"episode_reward": 976.8715975386401, "episode": 47.0, "batch_reward": 0.8335253465175628, "critic_loss": 0.25960485280305146, "actor_loss": -91.3557138671875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.653050661087036, "step": 47000}
{"episode_reward": 807.0827218279566, "episode": 48.0, "batch_reward": 0.833869060754776, "critic_loss": 0.26547630109637976, "actor_loss": -91.41418252563477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.16987729072571, "step": 48000}
{"episode_reward": 925.0353309664972, "episode": 49.0, "batch_reward": 0.8354158641695977, "critic_loss": 0.2535935565084219, "actor_loss": -91.33271040344238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.515395402908325, "step": 49000}
{"episode_reward": 963.2463837779727, "episode": 50.0, "batch_reward": 0.8377512834668159, "critic_loss": 0.25104737631976604, "actor_loss": -91.44620063781738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.806407690048218, "step": 50000}
{"episode_reward": 973.3751603842527, "episode": 51.0, "batch_reward": 0.8421688230633736, "critic_loss": 0.2411258990392089, "actor_loss": -91.6391547088623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 56.601380586624146, "step": 51000}
{"episode_reward": 951.7830293765905, "episode": 52.0, "batch_reward": 0.8436508982777595, "critic_loss": 0.23442397643625737, "actor_loss": -91.6839794921875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.449422121047974, "step": 52000}
{"episode_reward": 955.8045180629102, "episode": 53.0, "batch_reward": 0.844821444272995, "critic_loss": 0.2357141123265028, "actor_loss": -91.31506521606445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.06012558937073, "step": 53000}
{"episode_reward": 936.0190696167705, "episode": 54.0, "batch_reward": 0.8477990331053734, "critic_loss": 0.21779778684675694, "actor_loss": -91.65718083190917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.847987174987793, "step": 54000}
{"episode_reward": 972.9664566091217, "episode": 55.0, "batch_reward": 0.8485182382464409, "critic_loss": 0.228803144402802, "actor_loss": -91.5088480682373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.783644914627075, "step": 55000}
{"episode_reward": 945.5227329995251, "episode": 56.0, "batch_reward": 0.8503567329049111, "critic_loss": 0.19166142619401216, "actor_loss": -91.48930390930175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.03326344490051, "step": 56000}
{"episode_reward": 977.0795237759686, "episode": 57.0, "batch_reward": 0.8552635182142257, "critic_loss": 0.2083936014175415, "actor_loss": -91.47202423095703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.952604293823242, "step": 57000}
{"episode_reward": 960.2532747112908, "episode": 58.0, "batch_reward": 0.8538100932836532, "critic_loss": 0.2104610641747713, "actor_loss": -91.47889042663574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.115949869155884, "step": 58000}
{"episode_reward": 951.9265909599019, "episode": 59.0, "batch_reward": 0.8576555081605911, "critic_loss": 0.2141470160856843, "actor_loss": -91.58751615905761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.712778329849243, "step": 59000}
{"episode_reward": 982.6186231365813, "episode": 60.0, "batch_reward": 0.8588843879699707, "critic_loss": 0.21893849496543408, "actor_loss": -91.68049792480468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.15733337402344, "step": 60000}
{"episode_reward": 965.1727192898679, "episode": 61.0, "batch_reward": 0.8612491916418076, "critic_loss": 0.2410797577947378, "actor_loss": -91.72420660400391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 56.2589635848999, "step": 61000}
{"episode_reward": 956.5455515763807, "episode": 62.0, "batch_reward": 0.862450427532196, "critic_loss": 0.25384150819480417, "actor_loss": -91.60169207763671, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.410241842269897, "step": 62000}
{"episode_reward": 948.9009987913437, "episode": 63.0, "batch_reward": 0.8643758215308189, "critic_loss": 0.24101649567484856, "actor_loss": -92.09240739440918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.42096447944641, "step": 63000}
{"episode_reward": 967.7185382100224, "episode": 64.0, "batch_reward": 0.865257985830307, "critic_loss": 0.2584012040495873, "actor_loss": -91.89734928894043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.918330430984497, "step": 64000}
{"episode_reward": 948.747804489235, "episode": 65.0, "batch_reward": 0.8677309677004814, "critic_loss": 0.2351422083452344, "actor_loss": -92.01501176452636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.98721480369568, "step": 65000}
{"episode_reward": 970.1477770189114, "episode": 66.0, "batch_reward": 0.8667275605201721, "critic_loss": 0.24367941904067994, "actor_loss": -91.8312649383545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.69551110267639, "step": 66000}
{"episode_reward": 909.7590270383274, "episode": 67.0, "batch_reward": 0.8684555658698082, "critic_loss": 0.21589187268167734, "actor_loss": -91.97106028747558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.315510034561157, "step": 67000}
{"episode_reward": 956.211772129783, "episode": 68.0, "batch_reward": 0.8693310114145278, "critic_loss": 0.2167646845802665, "actor_loss": -91.85653356933594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.35583186149597, "step": 68000}
{"episode_reward": 942.5200145424546, "episode": 69.0, "batch_reward": 0.8694594030380249, "critic_loss": 0.2313282617405057, "actor_loss": -92.35232495117188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.385114669799805, "step": 69000}
{"episode_reward": 907.78516940165, "episode": 70.0, "batch_reward": 0.8727512353658676, "critic_loss": 0.21081372194737197, "actor_loss": -92.2377038116455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.637025833129883, "step": 70000}
{"episode_reward": 945.4128385061839, "episode": 71.0, "batch_reward": 0.8717682835459709, "critic_loss": 0.20327305476367474, "actor_loss": -92.0871881866455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.545002460479736, "step": 71000}
{"episode_reward": 940.9109262414763, "episode": 72.0, "batch_reward": 0.8729133653640747, "critic_loss": 0.21265529672801495, "actor_loss": -92.24975688171386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.858189582824707, "step": 72000}
{"episode_reward": 955.8819901714091, "episode": 73.0, "batch_reward": 0.8759409259557724, "critic_loss": 0.20385421466827391, "actor_loss": -92.18232090759277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.50768232345581, "step": 73000}
{"episode_reward": 930.8595417096083, "episode": 74.0, "batch_reward": 0.8760531144738197, "critic_loss": 0.19876461760699748, "actor_loss": -92.35950205993652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.60908055305481, "step": 74000}
{"episode_reward": 973.1435080151904, "episode": 75.0, "batch_reward": 0.8759928714632989, "critic_loss": 0.20023759151250123, "actor_loss": -92.61855661010742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.195086002349854, "step": 75000}
{"episode_reward": 911.1289731644727, "episode": 76.0, "batch_reward": 0.8765169518589974, "critic_loss": 0.19861202317476273, "actor_loss": -92.3523187713623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.129592657089233, "step": 76000}
{"episode_reward": 892.2764659898306, "episode": 77.0, "batch_reward": 0.8766519500613212, "critic_loss": 0.21538954259455204, "actor_loss": -92.45661271667481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.50597095489502, "step": 77000}
{"episode_reward": 938.5421053695699, "episode": 78.0, "batch_reward": 0.8781256615519524, "critic_loss": 0.204920503012836, "actor_loss": -92.46250071716308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.816351890563965, "step": 78000}
{"episode_reward": 980.4125226099966, "episode": 79.0, "batch_reward": 0.8796413464546203, "critic_loss": 0.19692603339999915, "actor_loss": -92.33321571350098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.16754412651062, "step": 79000}
{"episode_reward": 956.5239424897212, "episode": 80.0, "batch_reward": 0.880627610206604, "critic_loss": 0.1971716614291072, "actor_loss": -92.26493162536622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.52252459526062, "step": 80000}
{"episode_reward": 970.278639538893, "episode": 81.0, "batch_reward": 0.882591483771801, "critic_loss": 0.19321073330938815, "actor_loss": -92.31548011779785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.6177978515625, "step": 81000}
{"episode_reward": 876.2209171680265, "episode": 82.0, "batch_reward": 0.8805676158070564, "critic_loss": 0.19506098145246506, "actor_loss": -92.48853123474122, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.544359922409058, "step": 82000}
{"episode_reward": 932.9366100575874, "episode": 83.0, "batch_reward": 0.8831007591485978, "critic_loss": 0.1988203727826476, "actor_loss": -92.37629457092285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.416444301605225, "step": 83000}
{"episode_reward": 968.80135419818, "episode": 84.0, "batch_reward": 0.8808193177580833, "critic_loss": 0.20579165279120207, "actor_loss": -92.49932380676269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.880780458450317, "step": 84000}
{"episode_reward": 854.909371727659, "episode": 85.0, "batch_reward": 0.8819309797286987, "critic_loss": 0.1878612555116415, "actor_loss": -92.51960705566407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.897703409194946, "step": 85000}
{"episode_reward": 943.929152041886, "episode": 86.0, "batch_reward": 0.8838629299402236, "critic_loss": 0.21556321562826633, "actor_loss": -92.4301258392334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.398518085479736, "step": 86000}
{"episode_reward": 969.9728964070958, "episode": 87.0, "batch_reward": 0.8846613770723343, "critic_loss": 0.21912952884286643, "actor_loss": -92.36414331054688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.70190167427063, "step": 87000}
{"episode_reward": 975.7105203555869, "episode": 88.0, "batch_reward": 0.8848580151200295, "critic_loss": 0.22760111217945814, "actor_loss": -92.63575579833984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.534358978271484, "step": 88000}
{"episode_reward": 966.7787410244896, "episode": 89.0, "batch_reward": 0.8857395986914635, "critic_loss": 0.20064135079085826, "actor_loss": -92.60069792175292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.226476430892944, "step": 89000}
{"episode_reward": 916.8038690741481, "episode": 90.0, "batch_reward": 0.8876082512736321, "critic_loss": 0.1998949636295438, "actor_loss": -92.57398007202148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.169167518615723, "step": 90000}
{"episode_reward": 920.1588205092366, "episode": 91.0, "batch_reward": 0.8871805449724197, "critic_loss": 0.26470092715322974, "actor_loss": -92.71924172973632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 56.955010652542114, "step": 91000}
{"episode_reward": 969.8332583065545, "episode": 92.0, "batch_reward": 0.8878287244439125, "critic_loss": 0.2134455194696784, "actor_loss": -92.69650373840332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.015631437301636, "step": 92000}
{"episode_reward": 918.6372847158246, "episode": 93.0, "batch_reward": 0.8878701147437096, "critic_loss": 0.20475594665855168, "actor_loss": -92.81824406433105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.24752902984619, "step": 93000}
{"episode_reward": 979.6860930735036, "episode": 94.0, "batch_reward": 0.8886565372347832, "critic_loss": 0.21265711571276188, "actor_loss": -93.00712036132812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.69795036315918, "step": 94000}
{"episode_reward": 923.82761265151, "episode": 95.0, "batch_reward": 0.8887328499555588, "critic_loss": 0.21176525920256972, "actor_loss": -92.68766273498535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.995485305786133, "step": 95000}
{"episode_reward": 922.6058289848625, "episode": 96.0, "batch_reward": 0.8901536960601807, "critic_loss": 0.21783868248760702, "actor_loss": -93.05638395690917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.941222429275513, "step": 96000}
{"episode_reward": 959.2408417308338, "episode": 97.0, "batch_reward": 0.8900129644274711, "critic_loss": 0.21305990005657077, "actor_loss": -92.90682467651366, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.175750970840454, "step": 97000}
{"episode_reward": 980.9890125663669, "episode": 98.0, "batch_reward": 0.8920100754499436, "critic_loss": 0.2213449357673526, "actor_loss": -92.42685174560548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.53814935684204, "step": 98000}
{"episode_reward": 972.924092309569, "episode": 99.0, "batch_reward": 0.8929935149550438, "critic_loss": 0.19979271172732116, "actor_loss": -93.1795687713623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.17939019203186, "step": 99000}
{"episode_reward": 977.7470563374658, "episode": 100.0, "batch_reward": 0.8928485073447228, "critic_loss": 0.18789974612742663, "actor_loss": -92.95126414489746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.095346450805664, "step": 100000}
{"episode_reward": 973.2919102223518, "episode": 101.0, "batch_reward": 0.8935013095140457, "critic_loss": 0.19001709069311618, "actor_loss": -93.14955198669433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 56.94705557823181, "step": 101000}
{"episode_reward": 944.3680373462431, "episode": 102.0, "batch_reward": 0.8953502599596977, "critic_loss": 0.19472098134458066, "actor_loss": -93.14428843688965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.80532169342041, "step": 102000}
{"episode_reward": 968.5410410179677, "episode": 103.0, "batch_reward": 0.8956474933624268, "critic_loss": 0.20186368580907582, "actor_loss": -93.111480178833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.311830043792725, "step": 103000}
{"episode_reward": 971.9002085001457, "episode": 104.0, "batch_reward": 0.8963684148192406, "critic_loss": 0.21161420865356922, "actor_loss": -93.19513078308105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.08557367324829, "step": 104000}
{"episode_reward": 968.6754302188359, "episode": 105.0, "batch_reward": 0.8972945331335068, "critic_loss": 0.1849455002397299, "actor_loss": -93.2873614654541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.89236831665039, "step": 105000}
{"episode_reward": 970.7279142494714, "episode": 106.0, "batch_reward": 0.8976199107766152, "critic_loss": 0.17624123588949442, "actor_loss": -93.49287875366211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.67591166496277, "step": 106000}
{"episode_reward": 979.7115548386727, "episode": 107.0, "batch_reward": 0.898102899491787, "critic_loss": 0.1813112300634384, "actor_loss": -93.2906561279297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.956302404403687, "step": 107000}
{"episode_reward": 962.880904551149, "episode": 108.0, "batch_reward": 0.8995518303513527, "critic_loss": 0.18394073177874087, "actor_loss": -93.13177450561524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.317431688308716, "step": 108000}
{"episode_reward": 974.3550842670942, "episode": 109.0, "batch_reward": 0.9009846043586731, "critic_loss": 0.18970918406546117, "actor_loss": -93.38195565795898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.428512811660767, "step": 109000}
{"episode_reward": 953.4001534780136, "episode": 110.0, "batch_reward": 0.899301344871521, "critic_loss": 0.18027585607022048, "actor_loss": -93.0965739440918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.727735996246338, "step": 110000}
{"episode_reward": 917.6476521496223, "episode": 111.0, "batch_reward": 0.9002365251779556, "critic_loss": 0.18506414567306637, "actor_loss": -93.37003102111817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 57.04909896850586, "step": 111000}
{"episode_reward": 974.5714603289148, "episode": 112.0, "batch_reward": 0.9008771935701371, "critic_loss": 0.16707919522374867, "actor_loss": -93.15678184509278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.526541471481323, "step": 112000}
{"episode_reward": 963.7516633305642, "episode": 113.0, "batch_reward": 0.9017270530462265, "critic_loss": 0.1708773254826665, "actor_loss": -93.40770442199707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.15813446044922, "step": 113000}
{"episode_reward": 968.9279240154799, "episode": 114.0, "batch_reward": 0.9027840431332588, "critic_loss": 0.1954791614189744, "actor_loss": -93.24063655090332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.24114418029785, "step": 114000}
{"episode_reward": 953.8274203075354, "episode": 115.0, "batch_reward": 0.903135023355484, "critic_loss": 0.16659292566776276, "actor_loss": -93.37692868041992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.509928941726685, "step": 115000}
{"episode_reward": 969.5086499448781, "episode": 116.0, "batch_reward": 0.9036419181227684, "critic_loss": 0.1820572336949408, "actor_loss": -93.3663080291748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.59987711906433, "step": 116000}
{"episode_reward": 971.2776790392124, "episode": 117.0, "batch_reward": 0.905258978843689, "critic_loss": 0.17039118023961783, "actor_loss": -93.6980122833252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.53612446784973, "step": 117000}
{"episode_reward": 979.4984599513407, "episode": 118.0, "batch_reward": 0.9041953501105309, "critic_loss": 0.19387960860133172, "actor_loss": -93.35633663940429, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.444292783737183, "step": 118000}
{"episode_reward": 966.3552592904012, "episode": 119.0, "batch_reward": 0.9051074298024178, "critic_loss": 0.17840605679154395, "actor_loss": -93.56136695861817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.04237389564514, "step": 119000}
{"episode_reward": 895.8788949053476, "episode": 120.0, "batch_reward": 0.9059222592711449, "critic_loss": 0.16833870409056545, "actor_loss": -93.70187315368652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.961483240127563, "step": 120000}
{"episode_reward": 979.0203096294618, "episode": 121.0, "batch_reward": 0.9064159428477288, "critic_loss": 0.17980509757623075, "actor_loss": -93.65813893127441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 58.38171672821045, "step": 121000}
{"episode_reward": 947.0219524341718, "episode": 122.0, "batch_reward": 0.9054017288088798, "critic_loss": 0.17607049882039427, "actor_loss": -93.51714930725097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.44111728668213, "step": 122000}
{"episode_reward": 902.5719326567336, "episode": 123.0, "batch_reward": 0.9055728163719178, "critic_loss": 0.18370943195745348, "actor_loss": -93.44932817077637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.465071439743042, "step": 123000}
{"episode_reward": 930.5037616846636, "episode": 124.0, "batch_reward": 0.9051984544396401, "critic_loss": 0.18343744143098592, "actor_loss": -93.45313763427734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.464704513549805, "step": 124000}
{"episode_reward": 968.6851129878867, "episode": 125.0, "batch_reward": 0.9051083403229714, "critic_loss": 0.18318129481375217, "actor_loss": -93.47114819335937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.009624242782593, "step": 125000}
{"episode_reward": 948.2359417484322, "episode": 126.0, "batch_reward": 0.9051739438772202, "critic_loss": 0.19458260967954993, "actor_loss": -93.48807136535645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.967384338378906, "step": 126000}
{"episode_reward": 979.1927152271012, "episode": 127.0, "batch_reward": 0.9058334647417069, "critic_loss": 0.23544060617685317, "actor_loss": -93.37193672180176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.500116109848022, "step": 127000}
{"episode_reward": 861.7726167360294, "episode": 128.0, "batch_reward": 0.9066731675863265, "critic_loss": 0.2044052886143327, "actor_loss": -93.39644856262207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.388252019882202, "step": 128000}
{"episode_reward": 946.5813953312871, "episode": 129.0, "batch_reward": 0.9068811500668525, "critic_loss": 0.20546101757884025, "actor_loss": -93.29903802490234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.53536605834961, "step": 129000}
{"episode_reward": 968.2449577265113, "episode": 130.0, "batch_reward": 0.907523954808712, "critic_loss": 0.2132704997882247, "actor_loss": -93.28045161437988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.626543521881104, "step": 130000}
{"episode_reward": 919.2734854447384, "episode": 131.0, "batch_reward": 0.9087802150845528, "critic_loss": 0.2070231621041894, "actor_loss": -93.54780130004883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 57.485724687576294, "step": 131000}
{"episode_reward": 955.1717969492594, "episode": 132.0, "batch_reward": 0.9081611722111702, "critic_loss": 0.1974628721922636, "actor_loss": -93.63453335571289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.371171236038208, "step": 132000}
{"episode_reward": 920.1499505266812, "episode": 133.0, "batch_reward": 0.9085990004539489, "critic_loss": 0.21861030978336932, "actor_loss": -93.6168745727539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.367685079574585, "step": 133000}
{"episode_reward": 980.0903020758061, "episode": 134.0, "batch_reward": 0.9087252917289734, "critic_loss": 0.2066772945076227, "actor_loss": -93.31154985046386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.874711751937866, "step": 134000}
{"episode_reward": 971.9952251242913, "episode": 135.0, "batch_reward": 0.908136626958847, "critic_loss": 0.2094875443726778, "actor_loss": -93.21825758361817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.338024616241455, "step": 135000}
{"episode_reward": 943.3981724104558, "episode": 136.0, "batch_reward": 0.9101975254416466, "critic_loss": 0.18429075628891586, "actor_loss": -93.55449055480958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.313865661621094, "step": 136000}
{"episode_reward": 946.3905771310924, "episode": 137.0, "batch_reward": 0.9101704238057137, "critic_loss": 0.1918450350612402, "actor_loss": -93.35996977233887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.96722960472107, "step": 137000}
{"episode_reward": 918.9769034024243, "episode": 138.0, "batch_reward": 0.9099743274450303, "critic_loss": 0.2086548970602453, "actor_loss": -93.4170001373291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.57340908050537, "step": 138000}
{"episode_reward": 969.8211082364871, "episode": 139.0, "batch_reward": 0.9092858887910843, "critic_loss": 0.21745610670000315, "actor_loss": -93.67610041809083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.423635482788086, "step": 139000}
{"episode_reward": 886.252838405954, "episode": 140.0, "batch_reward": 0.9089085304141045, "critic_loss": 0.20397817116603256, "actor_loss": -93.6220445098877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.12138032913208, "step": 140000}
{"episode_reward": 946.9406104770577, "episode": 141.0, "batch_reward": 0.9112204548716545, "critic_loss": 0.1959799873046577, "actor_loss": -93.47392010498046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 57.658618450164795, "step": 141000}
{"episode_reward": 933.115031690224, "episode": 142.0, "batch_reward": 0.9115607379078865, "critic_loss": 0.19767176277190446, "actor_loss": -93.64661973571778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.184688806533813, "step": 142000}
{"episode_reward": 963.3866774674183, "episode": 143.0, "batch_reward": 0.9110161083340644, "critic_loss": 0.19997587440162898, "actor_loss": -93.53979473876953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.54739546775818, "step": 143000}
{"episode_reward": 964.0816767740588, "episode": 144.0, "batch_reward": 0.9105791184902191, "critic_loss": 0.21945411017537117, "actor_loss": -93.42665269470214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.394877433776855, "step": 144000}
{"episode_reward": 943.6990143741426, "episode": 145.0, "batch_reward": 0.9131769322752953, "critic_loss": 0.20173395580798387, "actor_loss": -93.49589154052734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.826435804367065, "step": 145000}
{"episode_reward": 950.6158055796003, "episode": 146.0, "batch_reward": 0.911563160777092, "critic_loss": 0.22881063406169413, "actor_loss": -93.4213003540039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.0070698261261, "step": 146000}
{"episode_reward": 956.0843358682904, "episode": 147.0, "batch_reward": 0.9113440689444542, "critic_loss": 0.20028465538471937, "actor_loss": -93.65103477478027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.54414677619934, "step": 147000}
{"episode_reward": 937.4956757008762, "episode": 148.0, "batch_reward": 0.9118038647174835, "critic_loss": 0.20422954338043928, "actor_loss": -93.38656471252442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.043317079544067, "step": 148000}
{"episode_reward": 901.0002856728235, "episode": 149.0, "batch_reward": 0.9129814680218696, "critic_loss": 0.19582211097702384, "actor_loss": -93.72857752990723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.512054681777954, "step": 149000}
{"episode_reward": 935.6032647753415, "episode": 150.0, "batch_reward": 0.9129387654662132, "critic_loss": 0.1964816107712686, "actor_loss": -93.44166180419921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
