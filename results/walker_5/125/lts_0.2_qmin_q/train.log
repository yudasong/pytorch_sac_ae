{"episode_reward": 0.0, "episode": 1.0, "duration": 22.141226768493652, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.872619390487671, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.45507513925249315, "critic_loss": 0.5805582624200822, "actor_loss": -84.83951729190211, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 63.51310682296753, "step": 3000}
{"episode_reward": 269.74142741551157, "episode": 4.0, "batch_reward": 0.3577089017778635, "critic_loss": 0.603311760365963, "actor_loss": -85.99327743530273, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.263681650161743, "step": 4000}
{"episode_reward": 33.06161732865127, "episode": 5.0, "batch_reward": 0.3626277386248112, "critic_loss": 0.5782330675721169, "actor_loss": -87.00543243408202, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.45931577682495, "step": 5000}
{"episode_reward": 721.1343988642607, "episode": 6.0, "batch_reward": 0.4416819064021111, "critic_loss": 0.5000896878838539, "actor_loss": -88.27810414123535, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.793458223342896, "step": 6000}
{"episode_reward": 960.8422894139122, "episode": 7.0, "batch_reward": 0.5167476098537445, "critic_loss": 0.40345356114208697, "actor_loss": -89.51279296875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.416270971298218, "step": 7000}
{"episode_reward": 914.139492559954, "episode": 8.0, "batch_reward": 0.5353318545520306, "critic_loss": 0.4372149466574192, "actor_loss": -90.0619570465088, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.49431085586548, "step": 8000}
{"episode_reward": 545.3269547434522, "episode": 9.0, "batch_reward": 0.5334352813065052, "critic_loss": 0.4259928367137909, "actor_loss": -90.10241799926757, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.848881721496582, "step": 9000}
{"episode_reward": 183.70103496959308, "episode": 10.0, "batch_reward": 0.527090621560812, "critic_loss": 0.4238986357748508, "actor_loss": -89.50636767578125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.828484773635864, "step": 10000}
{"episode_reward": 914.2088318572147, "episode": 11.0, "batch_reward": 0.5632279752194882, "critic_loss": 0.4225951307266951, "actor_loss": -89.66897857666015, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.58756613731384, "step": 11000}
{"episode_reward": 935.9050675471001, "episode": 12.0, "batch_reward": 0.5962365201711655, "critic_loss": 0.4478532344698906, "actor_loss": -90.31739520263672, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.73575520515442, "step": 12000}
{"episode_reward": 920.3367865033463, "episode": 13.0, "batch_reward": 0.6197297463417053, "critic_loss": 0.43324595879018307, "actor_loss": -90.72989175415039, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.81097650527954, "step": 13000}
{"episode_reward": 910.6205097186568, "episode": 14.0, "batch_reward": 0.648222886621952, "critic_loss": 0.42156656813621524, "actor_loss": -91.19820431518555, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.833346843719482, "step": 14000}
{"episode_reward": 980.2821660546051, "episode": 15.0, "batch_reward": 0.6655596142411232, "critic_loss": 0.586272858440876, "actor_loss": -91.30451593017578, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.848783016204834, "step": 15000}
{"episode_reward": 874.9271189372668, "episode": 16.0, "batch_reward": 0.6592095103859902, "critic_loss": 0.5108137866556645, "actor_loss": -90.9595004119873, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.664401531219482, "step": 16000}
{"episode_reward": 362.3060719819514, "episode": 17.0, "batch_reward": 0.6590730087161064, "critic_loss": 0.4990862625539303, "actor_loss": -90.8737660522461, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.107446908950806, "step": 17000}
{"episode_reward": 919.0401531452268, "episode": 18.0, "batch_reward": 0.67616699051857, "critic_loss": 0.4830038487017155, "actor_loss": -91.17310876464843, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.828298091888428, "step": 18000}
{"episode_reward": 774.0609841873099, "episode": 19.0, "batch_reward": 0.6834689125418663, "critic_loss": 0.564438458532095, "actor_loss": -90.9216425933838, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.732996225357056, "step": 19000}
{"episode_reward": 968.2026781217138, "episode": 20.0, "batch_reward": 0.6958948344588279, "critic_loss": 0.4965222125649452, "actor_loss": -91.17473260498046, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.67200517654419, "step": 20000}
{"episode_reward": 894.1532128813259, "episode": 21.0, "batch_reward": 0.7013662314414978, "critic_loss": 0.5391941492557526, "actor_loss": -91.14860342407226, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.87274742126465, "step": 21000}
{"episode_reward": 831.1969124872146, "episode": 22.0, "batch_reward": 0.7125550666451455, "critic_loss": 0.5463007508814335, "actor_loss": -91.28666770935058, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.425738096237183, "step": 22000}
{"episode_reward": 870.7605197820255, "episode": 23.0, "batch_reward": 0.7162317610383033, "critic_loss": 0.5705245372354985, "actor_loss": -91.34320455932617, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.778128147125244, "step": 23000}
{"episode_reward": 855.8203173029582, "episode": 24.0, "batch_reward": 0.7267237777709961, "critic_loss": 0.6732014899253845, "actor_loss": -91.60506253051757, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.955293655395508, "step": 24000}
{"episode_reward": 969.475468228846, "episode": 25.0, "batch_reward": 0.7166885563731193, "critic_loss": 0.6425354676246643, "actor_loss": -91.3637434387207, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44737982749939, "step": 25000}
{"episode_reward": 183.3652345656661, "episode": 26.0, "batch_reward": 0.711608478486538, "critic_loss": 0.6999610069692135, "actor_loss": -91.17819934082031, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.22221088409424, "step": 26000}
{"episode_reward": 774.6953546800102, "episode": 27.0, "batch_reward": 0.7178928146362304, "critic_loss": 0.6347782618105412, "actor_loss": -91.31122010803223, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.63924551010132, "step": 27000}
{"episode_reward": 963.97932126987, "episode": 28.0, "batch_reward": 0.7262222543358803, "critic_loss": 0.5951232063472272, "actor_loss": -91.44295109558105, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.448647022247314, "step": 28000}
{"episode_reward": 944.9435872510209, "episode": 29.0, "batch_reward": 0.731676361143589, "critic_loss": 0.5726298623681069, "actor_loss": -91.53621328735352, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.11681318283081, "step": 29000}
{"episode_reward": 924.3918193623151, "episode": 30.0, "batch_reward": 0.7370925128459931, "critic_loss": 0.6676929456293583, "actor_loss": -91.63997306823731, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.806553840637207, "step": 30000}
{"episode_reward": 825.5809787886933, "episode": 31.0, "batch_reward": 0.7403249671459198, "critic_loss": 0.5651609721481801, "actor_loss": -91.67451499938964, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.462566614151, "step": 31000}
{"episode_reward": 946.5201417940494, "episode": 32.0, "batch_reward": 0.7440348234772682, "critic_loss": 0.6017806207239628, "actor_loss": -91.62758706665039, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.87648367881775, "step": 32000}
{"episode_reward": 820.3972763928409, "episode": 33.0, "batch_reward": 0.7477953036427498, "critic_loss": 0.7318772361576558, "actor_loss": -91.60566122436524, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.229108572006226, "step": 33000}
{"episode_reward": 793.9537116426645, "episode": 34.0, "batch_reward": 0.7443111085295677, "critic_loss": 0.7573959378302098, "actor_loss": -91.54252062988282, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.444246768951416, "step": 34000}
{"episode_reward": 667.5379027432616, "episode": 35.0, "batch_reward": 0.7374461528658867, "critic_loss": 0.6571762953698636, "actor_loss": -91.43535734558105, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.68219757080078, "step": 35000}
{"episode_reward": 77.07927223455462, "episode": 36.0, "batch_reward": 0.731526469886303, "critic_loss": 0.6575363888442516, "actor_loss": -91.27764973449707, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.333878755569458, "step": 36000}
{"episode_reward": 935.8318368611629, "episode": 37.0, "batch_reward": 0.7338322092294693, "critic_loss": 0.5941595230996609, "actor_loss": -91.23581567382813, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.499619483947754, "step": 37000}
{"episode_reward": 948.6899215237402, "episode": 38.0, "batch_reward": 0.7411164219975471, "critic_loss": 0.5309511731863021, "actor_loss": -91.29511851501465, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.325628519058228, "step": 38000}
{"episode_reward": 986.415607926185, "episode": 39.0, "batch_reward": 0.7390547333359718, "critic_loss": 0.5271317871063947, "actor_loss": -91.21644088745117, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.524150371551514, "step": 39000}
{"episode_reward": 467.234199309969, "episode": 40.0, "batch_reward": 0.7383381283283234, "critic_loss": 0.4713704670518637, "actor_loss": -91.05044599914551, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.472054481506348, "step": 40000}
{"episode_reward": 936.7361936704874, "episode": 41.0, "batch_reward": 0.746351209461689, "critic_loss": 0.4555341453254223, "actor_loss": -91.02900163269042, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.09629511833191, "step": 41000}
{"episode_reward": 900.2472073708548, "episode": 42.0, "batch_reward": 0.7500445433855056, "critic_loss": 0.4950994397103786, "actor_loss": -90.82319483947754, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.114234447479248, "step": 42000}
{"episode_reward": 883.5081300251333, "episode": 43.0, "batch_reward": 0.7514821592569351, "critic_loss": 0.46044957379996776, "actor_loss": -90.7189130859375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.463603973388672, "step": 43000}
{"episode_reward": 875.0816401972696, "episode": 44.0, "batch_reward": 0.7530213928818703, "critic_loss": 0.47834706458449366, "actor_loss": -90.55121855163574, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.928767442703247, "step": 44000}
{"episode_reward": 901.6569864676278, "episode": 45.0, "batch_reward": 0.7576248707771301, "critic_loss": 0.48374429349601267, "actor_loss": -90.50020010375977, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.514968633651733, "step": 45000}
{"episode_reward": 889.6490234864283, "episode": 46.0, "batch_reward": 0.7611138218641281, "critic_loss": 0.5086108063459396, "actor_loss": -90.51960935974121, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44757103919983, "step": 46000}
{"episode_reward": 949.8699696640587, "episode": 47.0, "batch_reward": 0.7663116202354431, "critic_loss": 0.5140343462228775, "actor_loss": -90.4726323852539, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.891891479492188, "step": 47000}
{"episode_reward": 947.3628814939467, "episode": 48.0, "batch_reward": 0.7685572802424431, "critic_loss": 0.4939301992505789, "actor_loss": -90.45847369384765, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.026473999023438, "step": 48000}
{"episode_reward": 921.0045062469655, "episode": 49.0, "batch_reward": 0.7721613620519638, "critic_loss": 0.5109300171732902, "actor_loss": -90.6162169494629, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.53078603744507, "step": 49000}
{"episode_reward": 871.6995134785371, "episode": 50.0, "batch_reward": 0.776692274093628, "critic_loss": 0.48362545181810856, "actor_loss": -90.66570166015624, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.791316509246826, "step": 50000}
{"episode_reward": 976.2768040336231, "episode": 51.0, "batch_reward": 0.779034889280796, "critic_loss": 0.4597882900238037, "actor_loss": -90.68382669067383, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.83924198150635, "step": 51000}
{"episode_reward": 983.9648352721958, "episode": 52.0, "batch_reward": 0.7833377855420113, "critic_loss": 0.4632378883957863, "actor_loss": -90.82158139038086, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.53399634361267, "step": 52000}
{"episode_reward": 951.4501448614543, "episode": 53.0, "batch_reward": 0.785735469698906, "critic_loss": 0.4470510400980711, "actor_loss": -90.80312319946289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.713908910751343, "step": 53000}
{"episode_reward": 963.2676924030181, "episode": 54.0, "batch_reward": 0.7888480725288392, "critic_loss": 0.44892552101612093, "actor_loss": -90.86811381530762, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.935980081558228, "step": 54000}
{"episode_reward": 942.6369906767037, "episode": 55.0, "batch_reward": 0.7913315795063972, "critic_loss": 0.45242566561698916, "actor_loss": -90.9980657043457, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.56702995300293, "step": 55000}
{"episode_reward": 969.4566573035086, "episode": 56.0, "batch_reward": 0.7965800321698189, "critic_loss": 0.45661361515522003, "actor_loss": -91.17892811584473, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.06650471687317, "step": 56000}
{"episode_reward": 984.3573134584791, "episode": 57.0, "batch_reward": 0.7987893623709679, "critic_loss": 0.47091161137819293, "actor_loss": -91.28041529846192, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.9435977935791, "step": 57000}
{"episode_reward": 951.541921735186, "episode": 58.0, "batch_reward": 0.8021514284014701, "critic_loss": 0.4436420102864504, "actor_loss": -91.39586911010743, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.471876859664917, "step": 58000}
{"episode_reward": 982.9750650680027, "episode": 59.0, "batch_reward": 0.8050860332250596, "critic_loss": 0.46813249622285363, "actor_loss": -91.65833396911621, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.456990003585815, "step": 59000}
{"episode_reward": 941.3355312799105, "episode": 60.0, "batch_reward": 0.8071519751548767, "critic_loss": 0.4671291574984789, "actor_loss": -91.81323962402344, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.703617095947266, "step": 60000}
{"episode_reward": 969.5888384783347, "episode": 61.0, "batch_reward": 0.8098951402902603, "critic_loss": 0.44552493323385717, "actor_loss": -91.80533351135254, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.698413372039795, "step": 61000}
{"episode_reward": 959.3701943116381, "episode": 62.0, "batch_reward": 0.8117740237116814, "critic_loss": 0.447320064842701, "actor_loss": -91.93299453735352, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.27773952484131, "step": 62000}
{"episode_reward": 934.1284820406398, "episode": 63.0, "batch_reward": 0.8119850748181343, "critic_loss": 0.4480435583293438, "actor_loss": -92.05779158020019, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.93583583831787, "step": 63000}
{"episode_reward": 906.0899394799749, "episode": 64.0, "batch_reward": 0.8151916062235832, "critic_loss": 0.41291899846494196, "actor_loss": -92.19184803771972, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.76022696495056, "step": 64000}
{"episode_reward": 984.6453040419091, "episode": 65.0, "batch_reward": 0.8194088350534439, "critic_loss": 0.41098151525855064, "actor_loss": -92.2687257232666, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.83475351333618, "step": 65000}
{"episode_reward": 981.6375072869289, "episode": 66.0, "batch_reward": 0.8196688653826714, "critic_loss": 0.43828566616773607, "actor_loss": -92.37105166625976, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.012758016586304, "step": 66000}
{"episode_reward": 900.4903710750126, "episode": 67.0, "batch_reward": 0.8197940273284912, "critic_loss": 0.4485044244080782, "actor_loss": -92.39010314941406, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.81618618965149, "step": 67000}
{"episode_reward": 831.7411398121766, "episode": 68.0, "batch_reward": 0.8221666894555092, "critic_loss": 0.42310556541383265, "actor_loss": -92.37321920776367, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.677347421646118, "step": 68000}
{"episode_reward": 947.5294051231855, "episode": 69.0, "batch_reward": 0.8226886588335037, "critic_loss": 0.4373884471803904, "actor_loss": -92.4705711364746, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.88436484336853, "step": 69000}
{"episode_reward": 977.5822963354194, "episode": 70.0, "batch_reward": 0.8261320261955262, "critic_loss": 0.3998309779167175, "actor_loss": -92.44555007934571, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.112088680267334, "step": 70000}
{"episode_reward": 949.5891108842956, "episode": 71.0, "batch_reward": 0.8271048139333725, "critic_loss": 0.38700821454823015, "actor_loss": -92.40526823425293, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.44367074966431, "step": 71000}
{"episode_reward": 933.913334975384, "episode": 72.0, "batch_reward": 0.8293911301493645, "critic_loss": 0.37383058926463125, "actor_loss": -92.39295889282226, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.137024879455566, "step": 72000}
{"episode_reward": 972.6263659054791, "episode": 73.0, "batch_reward": 0.830823279440403, "critic_loss": 0.38181231866776943, "actor_loss": -92.35794793701172, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.473037004470825, "step": 73000}
{"episode_reward": 906.6741677226744, "episode": 74.0, "batch_reward": 0.8327097406983376, "critic_loss": 0.42420077650249005, "actor_loss": -92.35578981018067, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.921631813049316, "step": 74000}
{"episode_reward": 929.7905111652077, "episode": 75.0, "batch_reward": 0.8349933351874351, "critic_loss": 0.3670960377305746, "actor_loss": -92.38184252929688, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.848777532577515, "step": 75000}
{"episode_reward": 965.5042127622169, "episode": 76.0, "batch_reward": 0.8356628797650337, "critic_loss": 0.39060754811763765, "actor_loss": -92.3696837310791, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.612828016281128, "step": 76000}
{"episode_reward": 981.4261177457389, "episode": 77.0, "batch_reward": 0.8356665384173393, "critic_loss": 0.3850828357487917, "actor_loss": -92.4638432006836, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.48501443862915, "step": 77000}
{"episode_reward": 938.7158955757839, "episode": 78.0, "batch_reward": 0.8337321136593818, "critic_loss": 0.3623176255822182, "actor_loss": -92.48291012573242, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.720777988433838, "step": 78000}
{"episode_reward": 19.805367312389045, "episode": 79.0, "batch_reward": 0.8294957991242409, "critic_loss": 0.38075340329110624, "actor_loss": -92.3533331604004, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.59324312210083, "step": 79000}
{"episode_reward": 950.4889240098438, "episode": 80.0, "batch_reward": 0.8290131407380104, "critic_loss": 0.39040704967081546, "actor_loss": -92.33052850341797, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.45835590362549, "step": 80000}
{"episode_reward": 951.6620126524299, "episode": 81.0, "batch_reward": 0.8312946314811707, "critic_loss": 0.329943601578474, "actor_loss": -92.47368536376953, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.97004723548889, "step": 81000}
{"episode_reward": 926.7619280762244, "episode": 82.0, "batch_reward": 0.8328001620173454, "critic_loss": 0.3872828343957663, "actor_loss": -92.39975831604004, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.68621301651001, "step": 82000}
{"episode_reward": 956.8735427300736, "episode": 83.0, "batch_reward": 0.8326755619049072, "critic_loss": 0.3581397346407175, "actor_loss": -92.50920655822753, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.74017834663391, "step": 83000}
{"episode_reward": 910.5896323003026, "episode": 84.0, "batch_reward": 0.836309890806675, "critic_loss": 0.36452399112284184, "actor_loss": -92.55174528503417, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.991419792175293, "step": 84000}
{"episode_reward": 984.7350241808236, "episode": 85.0, "batch_reward": 0.8350812119841575, "critic_loss": 0.3618026978224516, "actor_loss": -92.44854545593262, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.003910064697266, "step": 85000}
{"episode_reward": 949.3933848564421, "episode": 86.0, "batch_reward": 0.8371899046301842, "critic_loss": 0.35291428758203985, "actor_loss": -92.48179356384277, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.485754251480103, "step": 86000}
{"episode_reward": 948.5211843445862, "episode": 87.0, "batch_reward": 0.8384521443843842, "critic_loss": 0.3522344495654106, "actor_loss": -92.54375819396972, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.26397132873535, "step": 87000}
{"episode_reward": 963.2544260406822, "episode": 88.0, "batch_reward": 0.8399065881371498, "critic_loss": 0.3438945750743151, "actor_loss": -92.5626217803955, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.964149951934814, "step": 88000}
{"episode_reward": 972.2442197206772, "episode": 89.0, "batch_reward": 0.840391034245491, "critic_loss": 0.36504461485147477, "actor_loss": -92.56154472351074, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.846975088119507, "step": 89000}
{"episode_reward": 988.3028119635474, "episode": 90.0, "batch_reward": 0.8434713461399078, "critic_loss": 0.3411058878079057, "actor_loss": -92.61786686706543, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.885664224624634, "step": 90000}
{"episode_reward": 925.4850075167216, "episode": 91.0, "batch_reward": 0.8446596654653549, "critic_loss": 0.3160635985136032, "actor_loss": -92.66047035217285, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.588263750076294, "step": 91000}
{"episode_reward": 980.8573925450198, "episode": 92.0, "batch_reward": 0.8476084005236626, "critic_loss": 0.3330578269958496, "actor_loss": -92.77179899597168, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.477461576461792, "step": 92000}
{"episode_reward": 957.8165827364173, "episode": 93.0, "batch_reward": 0.8445652980804443, "critic_loss": 0.3187444711327553, "actor_loss": -92.65450344848632, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.384267330169678, "step": 93000}
{"episode_reward": 981.2188663535999, "episode": 94.0, "batch_reward": 0.8492127437591552, "critic_loss": 0.3209850540831685, "actor_loss": -92.79636111450195, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.885988235473633, "step": 94000}
{"episode_reward": 931.4024668111268, "episode": 95.0, "batch_reward": 0.8490385172367096, "critic_loss": 0.31663153184205295, "actor_loss": -92.77400535583496, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.693843364715576, "step": 95000}
{"episode_reward": 953.9935978472937, "episode": 96.0, "batch_reward": 0.8516260238289833, "critic_loss": 0.3120735891908407, "actor_loss": -92.8348660583496, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.60473394393921, "step": 96000}
{"episode_reward": 962.1952026993383, "episode": 97.0, "batch_reward": 0.8524140995740891, "critic_loss": 0.31759489871561525, "actor_loss": -92.84882821655273, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.9271719455719, "step": 97000}
{"episode_reward": 930.2743160143594, "episode": 98.0, "batch_reward": 0.8539993805289269, "critic_loss": 0.3118972706347704, "actor_loss": -92.92140197753906, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.854292154312134, "step": 98000}
{"episode_reward": 968.2171861700355, "episode": 99.0, "batch_reward": 0.8541457154154778, "critic_loss": 0.3365148387476802, "actor_loss": -92.9695302734375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.468645572662354, "step": 99000}
{"episode_reward": 982.8834576099362, "episode": 100.0, "batch_reward": 0.855439134299755, "critic_loss": 0.316423081189394, "actor_loss": -93.03931796264648, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.219266891479492, "step": 100000}
{"episode_reward": 929.7424230423886, "episode": 101.0, "batch_reward": 0.8562855029702187, "critic_loss": 0.3172180533632636, "actor_loss": -93.05989807128907, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.79399061203003, "step": 101000}
{"episode_reward": 987.8284302269609, "episode": 102.0, "batch_reward": 0.8555801948308944, "critic_loss": 0.3148405186384916, "actor_loss": -93.10951734924316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.898232460021973, "step": 102000}
{"episode_reward": 982.6904473843699, "episode": 103.0, "batch_reward": 0.8575231083035469, "critic_loss": 0.3335391561836004, "actor_loss": -93.1450288696289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.983031511306763, "step": 103000}
{"episode_reward": 960.7235359525234, "episode": 104.0, "batch_reward": 0.8603079739809036, "critic_loss": 0.3195073177963495, "actor_loss": -93.23176585388184, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.843528747558594, "step": 104000}
{"episode_reward": 960.3344687175073, "episode": 105.0, "batch_reward": 0.8607960859537125, "critic_loss": 0.31026593009382486, "actor_loss": -93.3283062286377, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.50371789932251, "step": 105000}
{"episode_reward": 901.2806889667028, "episode": 106.0, "batch_reward": 0.8599380977749824, "critic_loss": 0.3549098817408085, "actor_loss": -93.26208116149903, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.58893394470215, "step": 106000}
{"episode_reward": 880.3287061445951, "episode": 107.0, "batch_reward": 0.8607648885250092, "critic_loss": 0.3073749807775021, "actor_loss": -93.28096627807618, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.962852716445923, "step": 107000}
{"episode_reward": 962.2815547200261, "episode": 108.0, "batch_reward": 0.8632526251077652, "critic_loss": 0.30537547709047796, "actor_loss": -93.40943795776367, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.544687509536743, "step": 108000}
{"episode_reward": 938.6090194737691, "episode": 109.0, "batch_reward": 0.8631047817468643, "critic_loss": 0.31568398427218197, "actor_loss": -93.3766714477539, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.638411283493042, "step": 109000}
{"episode_reward": 977.4279738223205, "episode": 110.0, "batch_reward": 0.8636652664542198, "critic_loss": 0.3070295975357294, "actor_loss": -93.37277708435059, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.967318058013916, "step": 110000}
{"episode_reward": 976.570957017442, "episode": 111.0, "batch_reward": 0.8641390562653541, "critic_loss": 0.32304033017903566, "actor_loss": -93.3954864654541, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.324362993240356, "step": 111000}
{"episode_reward": 951.963492780636, "episode": 112.0, "batch_reward": 0.8656639988422394, "critic_loss": 0.35327707314491275, "actor_loss": -93.45934944152832, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.961355924606323, "step": 112000}
{"episode_reward": 935.1270561132661, "episode": 113.0, "batch_reward": 0.8667145434617997, "critic_loss": 0.33888786235451696, "actor_loss": -93.52597230529786, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.876814603805542, "step": 113000}
{"episode_reward": 954.8028713767366, "episode": 114.0, "batch_reward": 0.8669669402241706, "critic_loss": 0.35068738705664876, "actor_loss": -93.55195375061035, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.485743284225464, "step": 114000}
{"episode_reward": 979.2007323304323, "episode": 115.0, "batch_reward": 0.8683096430301667, "critic_loss": 0.3169451911598444, "actor_loss": -93.52278689575195, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.802446126937866, "step": 115000}
{"episode_reward": 959.7739953152408, "episode": 116.0, "batch_reward": 0.8678103804588317, "critic_loss": 0.32924352686852215, "actor_loss": -93.55439356994628, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.01543116569519, "step": 116000}
{"episode_reward": 959.0324565852859, "episode": 117.0, "batch_reward": 0.869025853216648, "critic_loss": 0.30721204011142256, "actor_loss": -93.59382833862304, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.515220165252686, "step": 117000}
{"episode_reward": 921.8497756956723, "episode": 118.0, "batch_reward": 0.8702385123372078, "critic_loss": 0.31514085406810044, "actor_loss": -93.64645581054687, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.8792245388031, "step": 118000}
{"episode_reward": 986.7861103500555, "episode": 119.0, "batch_reward": 0.8706961359381675, "critic_loss": 0.31547561091929677, "actor_loss": -93.69455633544922, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.360150575637817, "step": 119000}
{"episode_reward": 953.4606271465434, "episode": 120.0, "batch_reward": 0.870490269601345, "critic_loss": 0.3236750368922949, "actor_loss": -93.65627439880372, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.449822902679443, "step": 120000}
{"episode_reward": 959.6263403384085, "episode": 121.0, "batch_reward": 0.8727432371377944, "critic_loss": 0.32611525715142486, "actor_loss": -93.75990747070313, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.34519910812378, "step": 121000}
{"episode_reward": 962.992831818599, "episode": 122.0, "batch_reward": 0.8731013773679733, "critic_loss": 0.30894817928224805, "actor_loss": -93.76726306152344, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.45876383781433, "step": 122000}
{"episode_reward": 955.9870033938015, "episode": 123.0, "batch_reward": 0.8751280417442322, "critic_loss": 0.29478786619752645, "actor_loss": -93.84954109191895, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.41644835472107, "step": 123000}
{"episode_reward": 950.9264569630943, "episode": 124.0, "batch_reward": 0.8739824109077453, "critic_loss": 0.31734837307780983, "actor_loss": -93.76917163085938, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.416592597961426, "step": 124000}
{"episode_reward": 981.8944545563454, "episode": 125.0, "batch_reward": 0.874799765944481, "critic_loss": 0.325481620490551, "actor_loss": -93.87855026245117, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.496896266937256, "step": 125000}
{"episode_reward": 981.4900785324343, "episode": 126.0, "batch_reward": 0.8763281462788581, "critic_loss": 0.31843170849233865, "actor_loss": -93.98967111206055, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.444852352142334, "step": 126000}
{"episode_reward": 989.8994447493826, "episode": 127.0, "batch_reward": 0.8748945886492729, "critic_loss": 0.32044807977974415, "actor_loss": -93.90269596862792, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.834862232208252, "step": 127000}
{"episode_reward": 970.760574890839, "episode": 128.0, "batch_reward": 0.8776456934809684, "critic_loss": 0.3098370010703802, "actor_loss": -94.01692976379394, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.186179637908936, "step": 128000}
{"episode_reward": 962.682684984574, "episode": 129.0, "batch_reward": 0.8786362258195877, "critic_loss": 0.2978440112024546, "actor_loss": -94.08106631469727, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.48149871826172, "step": 129000}
{"episode_reward": 985.0371261708763, "episode": 130.0, "batch_reward": 0.8791231445074081, "critic_loss": 0.2814752343818545, "actor_loss": -94.04624519348144, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.679755210876465, "step": 130000}
{"episode_reward": 987.0252241260996, "episode": 131.0, "batch_reward": 0.880872857093811, "critic_loss": 0.31782355055212974, "actor_loss": -94.06515690612792, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.665977001190186, "step": 131000}
{"episode_reward": 987.0990063331499, "episode": 132.0, "batch_reward": 0.8809102006554603, "critic_loss": 0.2885869201272726, "actor_loss": -94.08627639770508, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.635579109191895, "step": 132000}
{"episode_reward": 977.8735139731267, "episode": 133.0, "batch_reward": 0.8822695004940033, "critic_loss": 0.258939845405519, "actor_loss": -94.19545834350586, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.45785403251648, "step": 133000}
{"episode_reward": 961.6105482308787, "episode": 134.0, "batch_reward": 0.8821197679638862, "critic_loss": 0.27881565620005133, "actor_loss": -94.17057734680176, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.463414192199707, "step": 134000}
{"episode_reward": 946.9320334328091, "episode": 135.0, "batch_reward": 0.8837695968151092, "critic_loss": 0.29733946653455495, "actor_loss": -94.19033238220214, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.040863752365112, "step": 135000}
{"episode_reward": 991.0923202787872, "episode": 136.0, "batch_reward": 0.8841190683245659, "critic_loss": 0.2846318130940199, "actor_loss": -94.21964498901367, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.85891056060791, "step": 136000}
{"episode_reward": 988.7438770064514, "episode": 137.0, "batch_reward": 0.8840400315523148, "critic_loss": 0.2858536161854863, "actor_loss": -94.21523957824706, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.94437003135681, "step": 137000}
{"episode_reward": 988.6205863235635, "episode": 138.0, "batch_reward": 0.8851494205594063, "critic_loss": 0.28768992944061755, "actor_loss": -94.28593646240235, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.558469533920288, "step": 138000}
{"episode_reward": 958.4005319568101, "episode": 139.0, "batch_reward": 0.8846221255064011, "critic_loss": 0.3044314662218094, "actor_loss": -94.29633660888672, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.995798349380493, "step": 139000}
{"episode_reward": 989.2771719065554, "episode": 140.0, "batch_reward": 0.8852375451922416, "critic_loss": 0.29120105116814377, "actor_loss": -94.30196459960938, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.655006647109985, "step": 140000}
{"episode_reward": 952.6485923966795, "episode": 141.0, "batch_reward": 0.8871043791174889, "critic_loss": 0.2879062095358968, "actor_loss": -94.36953636169433, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.208134174346924, "step": 141000}
{"episode_reward": 963.1376324838284, "episode": 142.0, "batch_reward": 0.8876232445240021, "critic_loss": 0.2861102296486497, "actor_loss": -94.34355690002441, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.721441507339478, "step": 142000}
{"episode_reward": 988.6399961237522, "episode": 143.0, "batch_reward": 0.8874353841543198, "critic_loss": 0.2918562335669994, "actor_loss": -94.36650219726563, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.463615894317627, "step": 143000}
{"episode_reward": 934.9424655004293, "episode": 144.0, "batch_reward": 0.887966011762619, "critic_loss": 0.3010039425417781, "actor_loss": -94.45815570068359, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.338597774505615, "step": 144000}
{"episode_reward": 909.3804929270132, "episode": 145.0, "batch_reward": 0.8891088112592697, "critic_loss": 0.31919651374965907, "actor_loss": -94.46825108337403, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.327657461166382, "step": 145000}
{"episode_reward": 987.7752447527365, "episode": 146.0, "batch_reward": 0.8888152442574501, "critic_loss": 0.2964488542228937, "actor_loss": -94.49491763305664, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.867698192596436, "step": 146000}
{"episode_reward": 969.3166833056589, "episode": 147.0, "batch_reward": 0.889197202026844, "critic_loss": 0.28971690678596496, "actor_loss": -94.50777421569825, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.20970106124878, "step": 147000}
{"episode_reward": 907.4135463316718, "episode": 148.0, "batch_reward": 0.8901647641658783, "critic_loss": 0.3032184861674905, "actor_loss": -94.54750904846192, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.735320568084717, "step": 148000}
{"episode_reward": 989.3326496346986, "episode": 149.0, "batch_reward": 0.8896475469470024, "critic_loss": 0.2596321204230189, "actor_loss": -94.43431158447265, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.649972438812256, "step": 149000}
{"episode_reward": 955.3061606395186, "episode": 150.0, "batch_reward": 0.8910683079957962, "critic_loss": 0.2751579048931599, "actor_loss": -94.49661151123047, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
