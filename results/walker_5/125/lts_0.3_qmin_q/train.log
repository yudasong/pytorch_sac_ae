{"episode_reward": 0.0, "episode": 1.0, "duration": 21.38796615600586, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.8159096240997314, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.46183196654237085, "critic_loss": 0.44120110556975173, "actor_loss": -84.58263119701006, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 63.729965925216675, "step": 3000}
{"episode_reward": 192.72812405911742, "episode": 4.0, "batch_reward": 0.4014277944266796, "critic_loss": 0.6037649292349815, "actor_loss": -84.57419290161133, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.407501935958862, "step": 4000}
{"episode_reward": 541.2687660519306, "episode": 5.0, "batch_reward": 0.4699136610627174, "critic_loss": 0.6481448227167129, "actor_loss": -86.59860591125488, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.847060680389404, "step": 5000}
{"episode_reward": 862.6737170718739, "episode": 6.0, "batch_reward": 0.5472826444804668, "critic_loss": 0.6314619804024696, "actor_loss": -88.54191868591309, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.512393951416016, "step": 6000}
{"episode_reward": 943.9070300769986, "episode": 7.0, "batch_reward": 0.5981811607778073, "critic_loss": 0.6403128613233566, "actor_loss": -89.82790228271485, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.175368785858154, "step": 7000}
{"episode_reward": 869.2319165966709, "episode": 8.0, "batch_reward": 0.6388479403853417, "critic_loss": 0.6388103768527508, "actor_loss": -90.92323440551758, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.914334297180176, "step": 8000}
{"episode_reward": 894.8275831813028, "episode": 9.0, "batch_reward": 0.640984445989132, "critic_loss": 0.6857193787395954, "actor_loss": -91.01921922302246, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.549073934555054, "step": 9000}
{"episode_reward": 557.2210170595766, "episode": 10.0, "batch_reward": 0.6137622481882572, "critic_loss": 0.5769497664570808, "actor_loss": -90.97853660583496, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.059828996658325, "step": 10000}
{"episode_reward": 25.938791730506132, "episode": 11.0, "batch_reward": 0.5756613698899746, "critic_loss": 0.5318310015499592, "actor_loss": -90.1833031616211, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.258496046066284, "step": 11000}
{"episode_reward": 691.1306988163789, "episode": 12.0, "batch_reward": 0.6053110404014588, "critic_loss": 0.5460389496982098, "actor_loss": -90.91555995178223, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.4902184009552, "step": 12000}
{"episode_reward": 940.3605879310361, "episode": 13.0, "batch_reward": 0.6274796139597892, "critic_loss": 0.5976827888488769, "actor_loss": -91.62649177551269, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.42129421234131, "step": 13000}
{"episode_reward": 854.4694062323547, "episode": 14.0, "batch_reward": 0.6503308480381965, "critic_loss": 0.5555319750010967, "actor_loss": -92.17849765014648, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.794281244277954, "step": 14000}
{"episode_reward": 909.0023738988684, "episode": 15.0, "batch_reward": 0.6693809168338776, "critic_loss": 0.5585577728152276, "actor_loss": -92.05681452941894, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.55060338973999, "step": 15000}
{"episode_reward": 973.7000883972523, "episode": 16.0, "batch_reward": 0.6839382535815239, "critic_loss": 0.5961712048947811, "actor_loss": -92.21487973022461, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.050588846206665, "step": 16000}
{"episode_reward": 845.1155119214612, "episode": 17.0, "batch_reward": 0.6942783512473106, "critic_loss": 0.5856988340020179, "actor_loss": -92.42177214050292, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.984828233718872, "step": 17000}
{"episode_reward": 864.6324896688974, "episode": 18.0, "batch_reward": 0.7036303223967553, "critic_loss": 0.5998465602993965, "actor_loss": -92.61384303283691, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.920097589492798, "step": 18000}
{"episode_reward": 833.7667165851896, "episode": 19.0, "batch_reward": 0.7128023921847343, "critic_loss": 0.6159434738457203, "actor_loss": -92.46449841308593, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.540209770202637, "step": 19000}
{"episode_reward": 922.8286917245903, "episode": 20.0, "batch_reward": 0.724450580060482, "critic_loss": 0.6530822523832321, "actor_loss": -92.61295959472656, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.06548523902893, "step": 20000}
{"episode_reward": 938.7278022204936, "episode": 21.0, "batch_reward": 0.7360917441248894, "critic_loss": 0.6663778764009476, "actor_loss": -92.76560919189453, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.59075450897217, "step": 21000}
{"episode_reward": 949.9633398956707, "episode": 22.0, "batch_reward": 0.7258452778458595, "critic_loss": 0.6865565356314183, "actor_loss": -93.0774038848877, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.64822554588318, "step": 22000}
{"episode_reward": 93.23197239220134, "episode": 23.0, "batch_reward": 0.7154263783097267, "critic_loss": 0.6290453685820103, "actor_loss": -93.30835897827149, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.455977201461792, "step": 23000}
{"episode_reward": 945.8898898479009, "episode": 24.0, "batch_reward": 0.7257284716367721, "critic_loss": 0.5584237712323665, "actor_loss": -93.18128921508789, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.522149562835693, "step": 24000}
{"episode_reward": 984.7495467905532, "episode": 25.0, "batch_reward": 0.7365744978785514, "critic_loss": 0.5090144999027252, "actor_loss": -93.18078231811523, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.63774609565735, "step": 25000}
{"episode_reward": 961.0524031081992, "episode": 26.0, "batch_reward": 0.7465350602269173, "critic_loss": 0.48936861418187616, "actor_loss": -93.22179618835449, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.65090584754944, "step": 26000}
{"episode_reward": 982.7461797189567, "episode": 27.0, "batch_reward": 0.7554095461964607, "critic_loss": 0.4718429795056581, "actor_loss": -93.32441798400879, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.5372097492218, "step": 27000}
{"episode_reward": 979.3598488810801, "episode": 28.0, "batch_reward": 0.7618386192917824, "critic_loss": 0.5058069508224726, "actor_loss": -93.4259211883545, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.256433963775635, "step": 28000}
{"episode_reward": 906.8327895662757, "episode": 29.0, "batch_reward": 0.754631323993206, "critic_loss": 0.5757251768112183, "actor_loss": -93.39384754943848, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.739762544631958, "step": 29000}
{"episode_reward": 79.1958773370604, "episode": 30.0, "batch_reward": 0.7445449619293213, "critic_loss": 0.6055801630318165, "actor_loss": -93.17784719848633, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.700162410736084, "step": 30000}
{"episode_reward": 885.6862804409524, "episode": 31.0, "batch_reward": 0.7460544438958168, "critic_loss": 0.5512037963271141, "actor_loss": -93.03887109375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.68780493736267, "step": 31000}
{"episode_reward": 854.041827985763, "episode": 32.0, "batch_reward": 0.7540070182085037, "critic_loss": 0.49606719002127647, "actor_loss": -92.76221353149414, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.68276858329773, "step": 32000}
{"episode_reward": 955.9068591587662, "episode": 33.0, "batch_reward": 0.7458309742808342, "critic_loss": 0.5098467762470246, "actor_loss": -92.38397003173829, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.60859227180481, "step": 33000}
{"episode_reward": 36.013625012654806, "episode": 34.0, "batch_reward": 0.7334705560803413, "critic_loss": 0.4977365497946739, "actor_loss": -92.01710566711425, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.022939443588257, "step": 34000}
{"episode_reward": 887.8598270947116, "episode": 35.0, "batch_reward": 0.7380055902600289, "critic_loss": 0.5283844474554061, "actor_loss": -91.83261083984375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.041826963424683, "step": 35000}
{"episode_reward": 896.986474487062, "episode": 36.0, "batch_reward": 0.7402084888219833, "critic_loss": 0.5928163869082927, "actor_loss": -91.72240663146972, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.527891397476196, "step": 36000}
{"episode_reward": 706.4623787955527, "episode": 37.0, "batch_reward": 0.7452946479320526, "critic_loss": 0.5395074127912521, "actor_loss": -91.70964019775391, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.99839472770691, "step": 37000}
{"episode_reward": 960.7239710371678, "episode": 38.0, "batch_reward": 0.7401873016357422, "critic_loss": 0.6137510086297989, "actor_loss": -91.70480630493164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.56768298149109, "step": 38000}
{"episode_reward": 153.33115501668317, "episode": 39.0, "batch_reward": 0.7280146098136902, "critic_loss": 0.6405432474315167, "actor_loss": -91.53485710144042, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.49342155456543, "step": 39000}
{"episode_reward": 455.65829881485007, "episode": 40.0, "batch_reward": 0.7263219812512398, "critic_loss": 0.5874294102191925, "actor_loss": -91.40178355407714, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.79968500137329, "step": 40000}
{"episode_reward": 984.9342405777938, "episode": 41.0, "batch_reward": 0.7243827794194222, "critic_loss": 0.6064299874901772, "actor_loss": -91.37370381164551, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.94932198524475, "step": 41000}
{"episode_reward": 87.30626360793417, "episode": 42.0, "batch_reward": 0.72130612128973, "critic_loss": 0.6300572509169579, "actor_loss": -91.33379925537109, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.197837114334106, "step": 42000}
{"episode_reward": 944.8775258281275, "episode": 43.0, "batch_reward": 0.724724456012249, "critic_loss": 0.6227704188525677, "actor_loss": -91.26558576965331, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.91295027732849, "step": 43000}
{"episode_reward": 928.0761177277001, "episode": 44.0, "batch_reward": 0.7291983340978623, "critic_loss": 0.5925863676667213, "actor_loss": -91.28509680175782, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.57048773765564, "step": 44000}
{"episode_reward": 971.7631803418171, "episode": 45.0, "batch_reward": 0.735861951828003, "critic_loss": 0.573711238116026, "actor_loss": -91.28063810729981, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.58249068260193, "step": 45000}
{"episode_reward": 945.9168300114417, "episode": 46.0, "batch_reward": 0.7367423665523529, "critic_loss": 0.5433031564652919, "actor_loss": -91.09140884399415, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.820398807525635, "step": 46000}
{"episode_reward": 944.9931882903322, "episode": 47.0, "batch_reward": 0.7436503977179527, "critic_loss": 0.5249179363548756, "actor_loss": -91.13045614624023, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.445682525634766, "step": 47000}
{"episode_reward": 966.5688783630094, "episode": 48.0, "batch_reward": 0.7470685474872589, "critic_loss": 0.48654313425719736, "actor_loss": -91.11585812377929, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.520095586776733, "step": 48000}
{"episode_reward": 916.6853353391024, "episode": 49.0, "batch_reward": 0.7517085873484611, "critic_loss": 0.454425930082798, "actor_loss": -91.16615190124512, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.826552867889404, "step": 49000}
{"episode_reward": 949.971109762184, "episode": 50.0, "batch_reward": 0.7564803076386452, "critic_loss": 0.4472137905806303, "actor_loss": -91.19991361999512, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.261512279510498, "step": 50000}
{"episode_reward": 979.9642815830874, "episode": 51.0, "batch_reward": 0.7606303068995476, "critic_loss": 0.45527224692702295, "actor_loss": -91.21119572448731, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.54552674293518, "step": 51000}
{"episode_reward": 980.4670473106289, "episode": 52.0, "batch_reward": 0.7610085288882256, "critic_loss": 0.4652670608907938, "actor_loss": -91.23256323242188, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.947340965270996, "step": 52000}
{"episode_reward": 846.7656760016079, "episode": 53.0, "batch_reward": 0.76538717263937, "critic_loss": 0.4776898510307074, "actor_loss": -91.32052453613281, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.780343770980835, "step": 53000}
{"episode_reward": 950.5166764194335, "episode": 54.0, "batch_reward": 0.7674326005578042, "critic_loss": 0.4764941469579935, "actor_loss": -91.35021784973145, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.102514028549194, "step": 54000}
{"episode_reward": 897.5829468265695, "episode": 55.0, "batch_reward": 0.7705233595967292, "critic_loss": 0.4776287367194891, "actor_loss": -91.34709338378906, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.968904972076416, "step": 55000}
{"episode_reward": 856.8352456578531, "episode": 56.0, "batch_reward": 0.7748612802028656, "critic_loss": 0.49009417091310026, "actor_loss": -91.51740237426758, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.720914363861084, "step": 56000}
{"episode_reward": 978.4726792182171, "episode": 57.0, "batch_reward": 0.7769825443029403, "critic_loss": 0.5064710864424705, "actor_loss": -91.5908031463623, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.73266911506653, "step": 57000}
{"episode_reward": 947.8635761344237, "episode": 58.0, "batch_reward": 0.7810272408127785, "critic_loss": 0.5329805786609649, "actor_loss": -91.59938374328614, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.93992257118225, "step": 58000}
{"episode_reward": 969.5282064762981, "episode": 59.0, "batch_reward": 0.7831334263086319, "critic_loss": 0.6701073572486639, "actor_loss": -91.89699235534668, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.26142144203186, "step": 59000}
{"episode_reward": 955.0847498569862, "episode": 60.0, "batch_reward": 0.7859793646335602, "critic_loss": 0.9324152080416679, "actor_loss": -92.1004635925293, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.507259845733643, "step": 60000}
{"episode_reward": 945.4489575234998, "episode": 61.0, "batch_reward": 0.7822472451329231, "critic_loss": 1.140258702725172, "actor_loss": -92.3256011505127, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.97681403160095, "step": 61000}
{"episode_reward": 74.26129314726316, "episode": 62.0, "batch_reward": 0.7746705580949783, "critic_loss": 1.4382799916267395, "actor_loss": -92.97218493652343, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.55066704750061, "step": 62000}
{"episode_reward": 458.94188513945033, "episode": 63.0, "batch_reward": 0.7643263655304908, "critic_loss": 2.486212425947189, "actor_loss": -95.9902116394043, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.300511360168457, "step": 63000}
{"episode_reward": 70.57644595120546, "episode": 64.0, "batch_reward": 0.7551927453279496, "critic_loss": 3.552597062706947, "actor_loss": -102.49788265991211, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.982101678848267, "step": 64000}
{"episode_reward": 87.31020226531761, "episode": 65.0, "batch_reward": 0.7446032212972641, "critic_loss": 4.613705042600632, "actor_loss": -109.14057006835938, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.59116768836975, "step": 65000}
{"episode_reward": 89.93103329926315, "episode": 66.0, "batch_reward": 0.7329424269199372, "critic_loss": 5.638927675247192, "actor_loss": -115.13330857849121, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.55031442642212, "step": 66000}
{"episode_reward": 64.74402812915761, "episode": 67.0, "batch_reward": 0.7224188022613526, "critic_loss": 6.057719615221024, "actor_loss": -118.80252383422851, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.82187533378601, "step": 67000}
{"episode_reward": 69.37993556157926, "episode": 68.0, "batch_reward": 0.7161835595369339, "critic_loss": 5.89560716342926, "actor_loss": -125.1002505493164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.094133138656616, "step": 68000}
{"episode_reward": 153.85630273086082, "episode": 69.0, "batch_reward": 0.7049594151973725, "critic_loss": 5.79771251988411, "actor_loss": -127.79035186767578, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.553666830062866, "step": 69000}
{"episode_reward": 297.16635813658957, "episode": 70.0, "batch_reward": 0.7030319107770919, "critic_loss": 5.454043141365052, "actor_loss": -127.24630226135254, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.484161138534546, "step": 70000}
{"episode_reward": 620.0589116461066, "episode": 71.0, "batch_reward": 0.7045091814994812, "critic_loss": 4.764633789777756, "actor_loss": -128.56357774353026, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.77817440032959, "step": 71000}
{"episode_reward": 739.3953933891593, "episode": 72.0, "batch_reward": 0.7067217430472374, "critic_loss": 4.127572433829307, "actor_loss": -127.52528584289551, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.728708028793335, "step": 72000}
{"episode_reward": 960.7741845538962, "episode": 73.0, "batch_reward": 0.7082667704224587, "critic_loss": 3.42018039393425, "actor_loss": -126.49079322814941, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.672037839889526, "step": 73000}
{"episode_reward": 916.4506221318043, "episode": 74.0, "batch_reward": 0.710465492606163, "critic_loss": 2.8818795174360274, "actor_loss": -125.37962055969238, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.52047109603882, "step": 74000}
{"episode_reward": 867.661403447428, "episode": 75.0, "batch_reward": 0.7130892166495323, "critic_loss": 2.45005056977272, "actor_loss": -125.46893273925781, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.460198402404785, "step": 75000}
{"episode_reward": 959.3438449922897, "episode": 76.0, "batch_reward": 0.7173221140503884, "critic_loss": 2.1176138907670974, "actor_loss": -124.55877775573731, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.781323432922363, "step": 76000}
{"episode_reward": 965.2317526987032, "episode": 77.0, "batch_reward": 0.7194167777895928, "critic_loss": 1.9140375918149948, "actor_loss": -123.71448512268067, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.8817458152771, "step": 77000}
{"episode_reward": 964.6855141337005, "episode": 78.0, "batch_reward": 0.7210766981244088, "critic_loss": 1.6814453824162483, "actor_loss": -122.46856628417969, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.81513500213623, "step": 78000}
{"episode_reward": 948.2723927925852, "episode": 79.0, "batch_reward": 0.7240263864398002, "critic_loss": 1.4789407470822333, "actor_loss": -122.16794665527344, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.94609808921814, "step": 79000}
{"episode_reward": 964.0933038573398, "episode": 80.0, "batch_reward": 0.7276790913343429, "critic_loss": 1.2771075615882874, "actor_loss": -121.29689300537109, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.702746629714966, "step": 80000}
{"episode_reward": 977.7319689175861, "episode": 81.0, "batch_reward": 0.7326965369582176, "critic_loss": 1.06984152379632, "actor_loss": -119.0238165435791, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.85410261154175, "step": 81000}
{"episode_reward": 917.2218964832609, "episode": 82.0, "batch_reward": 0.7347088412642478, "critic_loss": 0.976011343151331, "actor_loss": -118.09571586608887, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.889353275299072, "step": 82000}
{"episode_reward": 956.3144087516235, "episode": 83.0, "batch_reward": 0.7386473260521889, "critic_loss": 0.907090764850378, "actor_loss": -116.6861199798584, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.494077444076538, "step": 83000}
{"episode_reward": 951.2287799340988, "episode": 84.0, "batch_reward": 0.7410875694155693, "critic_loss": 0.8358943457007408, "actor_loss": -116.03333071899414, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.780771017074585, "step": 84000}
{"episode_reward": 971.7572805143778, "episode": 85.0, "batch_reward": 0.7409896717071534, "critic_loss": 0.8089585273563862, "actor_loss": -115.57563029479981, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.68544363975525, "step": 85000}
{"episode_reward": 921.3882797039419, "episode": 86.0, "batch_reward": 0.7430227636694908, "critic_loss": 0.7467110018134118, "actor_loss": -114.14635511779785, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.59829354286194, "step": 86000}
{"episode_reward": 954.7957543975596, "episode": 87.0, "batch_reward": 0.7470821963548661, "critic_loss": 0.6701069847643375, "actor_loss": -113.41744502258301, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.224355697631836, "step": 87000}
{"episode_reward": 947.0038763309472, "episode": 88.0, "batch_reward": 0.7499440768361092, "critic_loss": 0.6868956815004349, "actor_loss": -112.45734066772461, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.959081411361694, "step": 88000}
{"episode_reward": 847.3324564780022, "episode": 89.0, "batch_reward": 0.7501028124690056, "critic_loss": 0.6387873721122742, "actor_loss": -112.14428437805176, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.860092878341675, "step": 89000}
{"episode_reward": 986.8957181227148, "episode": 90.0, "batch_reward": 0.7533691065311432, "critic_loss": 0.6270576046705246, "actor_loss": -110.16623120117187, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.523324251174927, "step": 90000}
{"episode_reward": 934.9347792358928, "episode": 91.0, "batch_reward": 0.7548672449588776, "critic_loss": 0.6084049439430237, "actor_loss": -110.07298023986816, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.8719379901886, "step": 91000}
{"episode_reward": 957.3071121541458, "episode": 92.0, "batch_reward": 0.7580926307439804, "critic_loss": 0.5982851497381926, "actor_loss": -108.10089126586914, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.525307655334473, "step": 92000}
{"episode_reward": 969.1400706901832, "episode": 93.0, "batch_reward": 0.7574257914423943, "critic_loss": 0.5872637873888016, "actor_loss": -108.1273809967041, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.321478605270386, "step": 93000}
{"episode_reward": 985.533521483128, "episode": 94.0, "batch_reward": 0.7619310692548752, "critic_loss": 0.6037672933340072, "actor_loss": -106.67320111083984, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.03290820121765, "step": 94000}
{"episode_reward": 896.1392817450458, "episode": 95.0, "batch_reward": 0.7636694531440735, "critic_loss": 0.5521848329156637, "actor_loss": -106.02126922607422, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.120306491851807, "step": 95000}
{"episode_reward": 934.0451833855652, "episode": 96.0, "batch_reward": 0.7640062684416771, "critic_loss": 0.5321452463418246, "actor_loss": -105.44515368652344, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.561915159225464, "step": 96000}
{"episode_reward": 925.1389672358855, "episode": 97.0, "batch_reward": 0.7658869027495384, "critic_loss": 0.5536124478578568, "actor_loss": -104.85396546936035, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.95545530319214, "step": 97000}
{"episode_reward": 897.5713233192952, "episode": 98.0, "batch_reward": 0.7692091732025147, "critic_loss": 0.533328407227993, "actor_loss": -103.9361517791748, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.609514236450195, "step": 98000}
{"episode_reward": 929.1577490231933, "episode": 99.0, "batch_reward": 0.7687096428871155, "critic_loss": 0.5740043333619833, "actor_loss": -103.50195010375977, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.8976469039917, "step": 99000}
{"episode_reward": 952.2351112484575, "episode": 100.0, "batch_reward": 0.771313267827034, "critic_loss": 0.568399396315217, "actor_loss": -103.0880168914795, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.962599277496338, "step": 100000}
{"episode_reward": 905.9426893954384, "episode": 101.0, "batch_reward": 0.7740166200995445, "critic_loss": 0.5660634135305882, "actor_loss": -102.14605828857422, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.10228395462036, "step": 101000}
{"episode_reward": 990.7503236649055, "episode": 102.0, "batch_reward": 0.7742879031300545, "critic_loss": 0.537378650829196, "actor_loss": -101.78168521118164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.530805110931396, "step": 102000}
{"episode_reward": 963.9396363516524, "episode": 103.0, "batch_reward": 0.7769014938473702, "critic_loss": 0.5278447152674198, "actor_loss": -101.39054895019531, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.28745174407959, "step": 103000}
{"episode_reward": 960.5198778529475, "episode": 104.0, "batch_reward": 0.7802343438267708, "critic_loss": 0.5147697467803956, "actor_loss": -100.99767953491211, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.83511972427368, "step": 104000}
{"episode_reward": 959.4086765718871, "episode": 105.0, "batch_reward": 0.7804790107011795, "critic_loss": 0.5669251739531755, "actor_loss": -100.96388940429688, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.52347707748413, "step": 105000}
{"episode_reward": 897.0564236598811, "episode": 106.0, "batch_reward": 0.7813297088146209, "critic_loss": 0.5738181626349688, "actor_loss": -100.68818910217286, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.928302526474, "step": 106000}
{"episode_reward": 942.7411408873395, "episode": 107.0, "batch_reward": 0.7832164179682731, "critic_loss": 0.565069152072072, "actor_loss": -99.93658819580078, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.97846555709839, "step": 107000}
{"episode_reward": 921.84328922319, "episode": 108.0, "batch_reward": 0.7832759895920753, "critic_loss": 0.5404175717681646, "actor_loss": -99.38175032043458, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.303722381591797, "step": 108000}
{"episode_reward": 912.5989811479261, "episode": 109.0, "batch_reward": 0.7876321585774422, "critic_loss": 0.5266156871020794, "actor_loss": -99.09550372314453, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.535236358642578, "step": 109000}
{"episode_reward": 980.181276186359, "episode": 110.0, "batch_reward": 0.7881708335280418, "critic_loss": 0.5445566830039025, "actor_loss": -98.74041938781738, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.97371554374695, "step": 110000}
{"episode_reward": 940.0333729715613, "episode": 111.0, "batch_reward": 0.7877368025779724, "critic_loss": 0.5238916859179735, "actor_loss": -98.3406964263916, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.474403858184814, "step": 111000}
{"episode_reward": 948.5786647853095, "episode": 112.0, "batch_reward": 0.7900940378308297, "critic_loss": 0.5227182509005069, "actor_loss": -98.04999560546875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.85521411895752, "step": 112000}
{"episode_reward": 942.4190011212739, "episode": 113.0, "batch_reward": 0.7925128623247146, "critic_loss": 0.5610778468698263, "actor_loss": -97.77646640014649, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.31458282470703, "step": 113000}
{"episode_reward": 955.7814322917212, "episode": 114.0, "batch_reward": 0.7924063214659691, "critic_loss": 0.5320486196875572, "actor_loss": -97.4443345489502, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.51331377029419, "step": 114000}
{"episode_reward": 972.5472073747696, "episode": 115.0, "batch_reward": 0.7942938242554665, "critic_loss": 0.5120497360229492, "actor_loss": -97.4271098022461, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.85147261619568, "step": 115000}
{"episode_reward": 929.6850189614331, "episode": 116.0, "batch_reward": 0.7975755441784859, "critic_loss": 0.5396398215293884, "actor_loss": -97.12685751342774, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.406083822250366, "step": 116000}
{"episode_reward": 905.8994359427675, "episode": 117.0, "batch_reward": 0.7961939185857773, "critic_loss": 0.5387941201031208, "actor_loss": -96.7815979309082, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.522233247756958, "step": 117000}
{"episode_reward": 928.1980087673327, "episode": 118.0, "batch_reward": 0.7985712760686874, "critic_loss": 0.5490825602263212, "actor_loss": -96.51309400939941, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.72160053253174, "step": 118000}
{"episode_reward": 987.6925012528274, "episode": 119.0, "batch_reward": 0.7986719524860382, "critic_loss": 0.5206799392253161, "actor_loss": -96.57657743835449, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.031661987304688, "step": 119000}
{"episode_reward": 938.0377763545816, "episode": 120.0, "batch_reward": 0.7991227084994316, "critic_loss": 0.5168261064141989, "actor_loss": -96.39079745483399, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.950790405273438, "step": 120000}
{"episode_reward": 925.9563133526419, "episode": 121.0, "batch_reward": 0.8031252522468567, "critic_loss": 0.5333338463753462, "actor_loss": -96.4003607635498, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.26487445831299, "step": 121000}
{"episode_reward": 984.3186542861997, "episode": 122.0, "batch_reward": 0.8022655705809594, "critic_loss": 0.5517907909750939, "actor_loss": -96.13561875915528, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.903296947479248, "step": 122000}
{"episode_reward": 946.662116320694, "episode": 123.0, "batch_reward": 0.8031167796850205, "critic_loss": 0.515010324075818, "actor_loss": -95.926625, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.651538372039795, "step": 123000}
{"episode_reward": 953.4753708328806, "episode": 124.0, "batch_reward": 0.8058112466335297, "critic_loss": 0.5417559234648943, "actor_loss": -95.70964653015136, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.251930236816406, "step": 124000}
{"episode_reward": 987.9980323689425, "episode": 125.0, "batch_reward": 0.807664687693119, "critic_loss": 0.5008339081704617, "actor_loss": -95.72157719421386, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.75277590751648, "step": 125000}
{"episode_reward": 988.0651067058142, "episode": 126.0, "batch_reward": 0.8086629455685616, "critic_loss": 0.49724377797544, "actor_loss": -95.6341996307373, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.529355764389038, "step": 126000}
{"episode_reward": 990.1541980130053, "episode": 127.0, "batch_reward": 0.8094268451929092, "critic_loss": 0.4961555809378624, "actor_loss": -95.46810954284668, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.865871906280518, "step": 127000}
{"episode_reward": 952.0089993406772, "episode": 128.0, "batch_reward": 0.8105472471117974, "critic_loss": 0.4764105996340513, "actor_loss": -95.3687020111084, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.0710232257843, "step": 128000}
{"episode_reward": 962.3990689213629, "episode": 129.0, "batch_reward": 0.8114836241006851, "critic_loss": 0.5133045812547207, "actor_loss": -95.13057984924316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.032251834869385, "step": 129000}
{"episode_reward": 979.1813219700158, "episode": 130.0, "batch_reward": 0.8150883819460869, "critic_loss": 0.4629044601768255, "actor_loss": -95.1607818145752, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.53962206840515, "step": 130000}
{"episode_reward": 985.6367667821852, "episode": 131.0, "batch_reward": 0.8165095186233521, "critic_loss": 0.490214158385992, "actor_loss": -95.00044340515137, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.89368557929993, "step": 131000}
{"episode_reward": 986.1448862102735, "episode": 132.0, "batch_reward": 0.8160152220726014, "critic_loss": 0.4582604792714119, "actor_loss": -95.07377323913575, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.529155731201172, "step": 132000}
{"episode_reward": 976.8951801903031, "episode": 133.0, "batch_reward": 0.8185504453778267, "critic_loss": 0.42882948461174963, "actor_loss": -94.9081930847168, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.92307186126709, "step": 133000}
{"episode_reward": 959.8246642382701, "episode": 134.0, "batch_reward": 0.8165783036351204, "critic_loss": 0.43197470119595527, "actor_loss": -94.74734197998046, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.973144054412842, "step": 134000}
{"episode_reward": 948.48200835992, "episode": 135.0, "batch_reward": 0.8189995791316033, "critic_loss": 0.4307942073494196, "actor_loss": -94.79257162475587, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.75732421875, "step": 135000}
{"episode_reward": 991.254177195527, "episode": 136.0, "batch_reward": 0.8215059091448784, "critic_loss": 0.4410275022983551, "actor_loss": -94.75930966186523, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.555882692337036, "step": 136000}
{"episode_reward": 989.3295192427994, "episode": 137.0, "batch_reward": 0.8233913224935532, "critic_loss": 0.4422106875628233, "actor_loss": -94.79636180114746, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.68225598335266, "step": 137000}
{"episode_reward": 987.3518415169875, "episode": 138.0, "batch_reward": 0.824175045967102, "critic_loss": 0.4235393360555172, "actor_loss": -94.89075755310058, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.450484037399292, "step": 138000}
{"episode_reward": 961.6667075420565, "episode": 139.0, "batch_reward": 0.8252245959639549, "critic_loss": 0.40564401289820673, "actor_loss": -94.74028311157227, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.76838994026184, "step": 139000}
{"episode_reward": 983.9317477256916, "episode": 140.0, "batch_reward": 0.8245107322335243, "critic_loss": 0.4037743700519204, "actor_loss": -94.68673950195313, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.76774764060974, "step": 140000}
{"episode_reward": 939.956873000648, "episode": 141.0, "batch_reward": 0.8263140432834625, "critic_loss": 0.3849672564715147, "actor_loss": -94.62776641845703, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.93104529380798, "step": 141000}
{"episode_reward": 945.7766819759969, "episode": 142.0, "batch_reward": 0.8251879018545151, "critic_loss": 0.4219376069754362, "actor_loss": -94.52655073547363, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.944297075271606, "step": 142000}
{"episode_reward": 989.542558022131, "episode": 143.0, "batch_reward": 0.8272842220067977, "critic_loss": 0.4178642469793558, "actor_loss": -94.53988977050781, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.94001007080078, "step": 143000}
{"episode_reward": 941.4386160642076, "episode": 144.0, "batch_reward": 0.8285897600054741, "critic_loss": 0.38773818729817866, "actor_loss": -94.51026963806153, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.682053089141846, "step": 144000}
{"episode_reward": 961.2597549341801, "episode": 145.0, "batch_reward": 0.8311454234719277, "critic_loss": 0.37500024135410787, "actor_loss": -94.54729193115234, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.545256853103638, "step": 145000}
{"episode_reward": 987.1719995683867, "episode": 146.0, "batch_reward": 0.829981629550457, "critic_loss": 0.37089386105537414, "actor_loss": -94.44635990905762, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.868155241012573, "step": 146000}
{"episode_reward": 923.6781056335186, "episode": 147.0, "batch_reward": 0.8306450716257096, "critic_loss": 0.3910303086936474, "actor_loss": -94.40560357666016, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.410789489746094, "step": 147000}
{"episode_reward": 947.6973930968094, "episode": 148.0, "batch_reward": 0.8331514641046524, "critic_loss": 0.3691732165515423, "actor_loss": -94.44685528564453, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.55704164505005, "step": 148000}
{"episode_reward": 989.0420344281148, "episode": 149.0, "batch_reward": 0.8324941779375077, "critic_loss": 0.3829271081015468, "actor_loss": -94.40953253173828, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.714492559432983, "step": 149000}
{"episode_reward": 929.3192718374095, "episode": 150.0, "batch_reward": 0.8335508967041969, "critic_loss": 0.3756586517393589, "actor_loss": -94.39870010375977, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
