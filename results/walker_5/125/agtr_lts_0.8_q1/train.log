{"episode_reward": 0.0, "episode": 1.0, "duration": 21.21567702293396, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.833045244216919, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.4562934650385845, "critic_loss": 0.1742084226221661, "actor_loss": -70.07992636541292, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 63.16117715835571, "step": 3000}
{"episode_reward": 175.42846305423762, "episode": 4.0, "batch_reward": 0.3549927507191896, "critic_loss": 0.4040128241479397, "actor_loss": -67.92714728927612, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.687960147857666, "step": 4000}
{"episode_reward": 139.4265424060292, "episode": 5.0, "batch_reward": 0.32385662297904494, "critic_loss": 0.6191802496761084, "actor_loss": -63.67837387275696, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.15497899055481, "step": 5000}
{"episode_reward": 308.28612964605605, "episode": 6.0, "batch_reward": 0.3160771242380142, "critic_loss": 0.8950003231465816, "actor_loss": -65.2814904870987, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.481932401657104, "step": 6000}
{"episode_reward": 331.8037228007737, "episode": 7.0, "batch_reward": 0.306482828348875, "critic_loss": 1.2247684257626534, "actor_loss": -66.35287697410584, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.885690689086914, "step": 7000}
{"episode_reward": 168.95714169361656, "episode": 8.0, "batch_reward": 0.3062009470164776, "critic_loss": 1.61847350949049, "actor_loss": -65.770273686409, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.930025339126587, "step": 8000}
{"episode_reward": 408.89883214007915, "episode": 9.0, "batch_reward": 0.3230712088942528, "critic_loss": 2.023471565723419, "actor_loss": -66.71759224510193, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.589650630950928, "step": 9000}
{"episode_reward": 629.1794037906617, "episode": 10.0, "batch_reward": 0.3513012883067131, "critic_loss": 2.2617539188861846, "actor_loss": -68.08653010177612, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.85760760307312, "step": 10000}
{"episode_reward": 512.8830997088708, "episode": 11.0, "batch_reward": 0.37740131017565726, "critic_loss": 2.1977143957614897, "actor_loss": -68.97336238098144, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.21980285644531, "step": 11000}
{"episode_reward": 683.1243718734166, "episode": 12.0, "batch_reward": 0.39669256123900415, "critic_loss": 2.3297304542064667, "actor_loss": -68.45574126815796, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.621030569076538, "step": 12000}
{"episode_reward": 582.3583709359937, "episode": 13.0, "batch_reward": 0.4203886949121952, "critic_loss": 2.376856479406357, "actor_loss": -70.06498230743408, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.414153575897217, "step": 13000}
{"episode_reward": 757.1690235883374, "episode": 14.0, "batch_reward": 0.45154648396372793, "critic_loss": 2.3817073892354967, "actor_loss": -69.4214341583252, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.484859943389893, "step": 14000}
{"episode_reward": 888.2086805419262, "episode": 15.0, "batch_reward": 0.4746702024936676, "critic_loss": 2.369996583342552, "actor_loss": -75.42050031661988, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.252655506134033, "step": 15000}
{"episode_reward": 786.4513246893329, "episode": 16.0, "batch_reward": 0.49782080152630803, "critic_loss": 2.1875236583948134, "actor_loss": -73.36343490219116, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.635032653808594, "step": 16000}
{"episode_reward": 833.5908910096706, "episode": 17.0, "batch_reward": 0.5122079803049564, "critic_loss": 2.1559643239974977, "actor_loss": -75.41841223526, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.78332829475403, "step": 17000}
{"episode_reward": 773.624918732886, "episode": 18.0, "batch_reward": 0.5326264206767082, "critic_loss": 2.2222936602830887, "actor_loss": -75.29497143173218, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.6060471534729, "step": 18000}
{"episode_reward": 867.6835334754503, "episode": 19.0, "batch_reward": 0.5524275386333466, "critic_loss": 2.23554046690464, "actor_loss": -74.70095834350586, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.688302040100098, "step": 19000}
{"episode_reward": 901.3672647441886, "episode": 20.0, "batch_reward": 0.570469118386507, "critic_loss": 2.229724838733673, "actor_loss": -77.47161013031005, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.865328550338745, "step": 20000}
{"episode_reward": 861.875877695, "episode": 21.0, "batch_reward": 0.5845390709638596, "critic_loss": 2.173629675865173, "actor_loss": -78.05524645996094, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.56513953208923, "step": 21000}
{"episode_reward": 913.0466857971941, "episode": 22.0, "batch_reward": 0.6026941568255425, "critic_loss": 2.229809157371521, "actor_loss": -78.53575690460205, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.821341514587402, "step": 22000}
{"episode_reward": 890.7017391683937, "episode": 23.0, "batch_reward": 0.6080592966377735, "critic_loss": 2.2445060032606126, "actor_loss": -80.26949310302734, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.16709613800049, "step": 23000}
{"episode_reward": 706.5260975833372, "episode": 24.0, "batch_reward": 0.6188921906352043, "critic_loss": 2.101292981028557, "actor_loss": -79.73091807556152, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.812591791152954, "step": 24000}
{"episode_reward": 976.2947008859118, "episode": 25.0, "batch_reward": 0.6317435336112976, "critic_loss": 1.8863147720694542, "actor_loss": -79.55643840789794, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.842318296432495, "step": 25000}
{"episode_reward": 943.4598950197518, "episode": 26.0, "batch_reward": 0.644213521540165, "critic_loss": 1.7736078997850417, "actor_loss": -81.3992592086792, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.426246643066406, "step": 26000}
{"episode_reward": 982.7926802770226, "episode": 27.0, "batch_reward": 0.6602875124812126, "critic_loss": 1.7050131947398186, "actor_loss": -80.99704047393799, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43920636177063, "step": 27000}
{"episode_reward": 978.8408257147853, "episode": 28.0, "batch_reward": 0.6665537688732147, "critic_loss": 1.8579456049203873, "actor_loss": -80.93031846618652, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.831650257110596, "step": 28000}
{"episode_reward": 781.6063742217842, "episode": 29.0, "batch_reward": 0.6719115483164787, "critic_loss": 1.8647210853099823, "actor_loss": -81.98488390350342, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.732112884521484, "step": 29000}
{"episode_reward": 858.8761580341434, "episode": 30.0, "batch_reward": 0.6785684532523155, "critic_loss": 1.9673497307300567, "actor_loss": -81.71148295593262, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.911149978637695, "step": 30000}
{"episode_reward": 878.9888465139799, "episode": 31.0, "batch_reward": 0.6861207035779953, "critic_loss": 1.9967731231451034, "actor_loss": -82.28821559143067, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.988333225250244, "step": 31000}
{"episode_reward": 942.6940502381257, "episode": 32.0, "batch_reward": 0.6941370818614959, "critic_loss": 2.052459466934204, "actor_loss": -82.0600039138794, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.536170482635498, "step": 32000}
{"episode_reward": 894.5557858458736, "episode": 33.0, "batch_reward": 0.6950862413048744, "critic_loss": 2.103156612634659, "actor_loss": -83.44924987792969, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.655773162841797, "step": 33000}
{"episode_reward": 757.353639234957, "episode": 34.0, "batch_reward": 0.7028380700349808, "critic_loss": 2.141275063633919, "actor_loss": -82.6573936843872, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.47746181488037, "step": 34000}
{"episode_reward": 983.3249723998798, "episode": 35.0, "batch_reward": 0.710162789940834, "critic_loss": 2.087054195821285, "actor_loss": -84.57151197814942, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.76058268547058, "step": 35000}
{"episode_reward": 914.1554888093852, "episode": 36.0, "batch_reward": 0.7140195717215538, "critic_loss": 2.127614041566849, "actor_loss": -83.24740129089355, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.90489888191223, "step": 36000}
{"episode_reward": 924.6395159033676, "episode": 37.0, "batch_reward": 0.7184169404506683, "critic_loss": 2.1810414972305296, "actor_loss": -84.87081522369385, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.85571575164795, "step": 37000}
{"episode_reward": 839.1501122067882, "episode": 38.0, "batch_reward": 0.725721741259098, "critic_loss": 2.0104340843558313, "actor_loss": -85.1177208480835, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.73587918281555, "step": 38000}
{"episode_reward": 955.5724676955726, "episode": 39.0, "batch_reward": 0.7296083924770356, "critic_loss": 2.1393913598060608, "actor_loss": -85.3226678314209, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.086657762527466, "step": 39000}
{"episode_reward": 869.3057377581382, "episode": 40.0, "batch_reward": 0.7344798287153244, "critic_loss": 2.119154957413673, "actor_loss": -85.76846159362793, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.057674169540405, "step": 40000}
{"episode_reward": 960.3701267164624, "episode": 41.0, "batch_reward": 0.7368338396549224, "critic_loss": 2.1202360887527467, "actor_loss": -86.1155117111206, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.81741499900818, "step": 41000}
{"episode_reward": 851.124489285943, "episode": 42.0, "batch_reward": 0.7430087327957153, "critic_loss": 2.146160999417305, "actor_loss": -85.47607605743408, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.734266757965088, "step": 42000}
{"episode_reward": 955.2742751193769, "episode": 43.0, "batch_reward": 0.7479037092328071, "critic_loss": 2.0731545774936677, "actor_loss": -85.94767189025879, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.8551504611969, "step": 43000}
{"episode_reward": 950.2966266340936, "episode": 44.0, "batch_reward": 0.7521302520632743, "critic_loss": 2.1116331105232238, "actor_loss": -86.10727619934082, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.656323194503784, "step": 44000}
{"episode_reward": 987.0406806191749, "episode": 45.0, "batch_reward": 0.7580954354405404, "critic_loss": 2.074107083916664, "actor_loss": -86.49622955322266, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.030261278152466, "step": 45000}
{"episode_reward": 958.7731768116299, "episode": 46.0, "batch_reward": 0.7580371834039689, "critic_loss": 2.1347901476621627, "actor_loss": -86.53203770446777, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.662842750549316, "step": 46000}
{"episode_reward": 886.4545106812507, "episode": 47.0, "batch_reward": 0.7636800038814545, "critic_loss": 2.0674275288581847, "actor_loss": -87.25561680603028, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.448842763900757, "step": 47000}
{"episode_reward": 836.044484199832, "episode": 48.0, "batch_reward": 0.765056007027626, "critic_loss": 2.0620033833980562, "actor_loss": -87.03953132629394, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.295987606048584, "step": 48000}
{"episode_reward": 933.6469281082825, "episode": 49.0, "batch_reward": 0.7689975722432136, "critic_loss": 2.120240949511528, "actor_loss": -87.91162644958496, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.258623123168945, "step": 49000}
{"episode_reward": 925.7417170663109, "episode": 50.0, "batch_reward": 0.7708902552723884, "critic_loss": 2.0523590588569642, "actor_loss": -87.32837660217285, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.407598972320557, "step": 50000}
{"episode_reward": 954.448084216072, "episode": 51.0, "batch_reward": 0.7773007499575615, "critic_loss": 2.045507000744343, "actor_loss": -87.68193515014649, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.807469606399536, "step": 51000}
{"episode_reward": 983.9026911766066, "episode": 52.0, "batch_reward": 0.7798502138257026, "critic_loss": 2.0707673498988153, "actor_loss": -87.72426449584961, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.560882806777954, "step": 52000}
{"episode_reward": 952.5845377883795, "episode": 53.0, "batch_reward": 0.7839272898435593, "critic_loss": 2.0331332768797874, "actor_loss": -88.10825897216797, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.87644076347351, "step": 53000}
{"episode_reward": 947.4171550677551, "episode": 54.0, "batch_reward": 0.7854964733123779, "critic_loss": 1.9630522800683976, "actor_loss": -87.97475263977051, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.651658296585083, "step": 54000}
{"episode_reward": 915.7912529251603, "episode": 55.0, "batch_reward": 0.7889547370672226, "critic_loss": 1.916236000418663, "actor_loss": -88.90190977478028, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.402214765548706, "step": 55000}
{"episode_reward": 967.9777169931667, "episode": 56.0, "batch_reward": 0.7935959087610245, "critic_loss": 2.0366352882385255, "actor_loss": -88.79840043640137, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.128900051116943, "step": 56000}
{"episode_reward": 985.7014041246472, "episode": 57.0, "batch_reward": 0.7956729110479355, "critic_loss": 1.8717685932517052, "actor_loss": -88.36834719848633, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43620777130127, "step": 57000}
{"episode_reward": 893.9448470411772, "episode": 58.0, "batch_reward": 0.7991533406972885, "critic_loss": 1.8231173717975617, "actor_loss": -88.71445471191406, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.68093180656433, "step": 58000}
{"episode_reward": 983.1003949442767, "episode": 59.0, "batch_reward": 0.8010089238286018, "critic_loss": 1.936427305459976, "actor_loss": -88.69638330078125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.003870725631714, "step": 59000}
{"episode_reward": 954.4815754211013, "episode": 60.0, "batch_reward": 0.8037802809476853, "critic_loss": 1.8425196402668953, "actor_loss": -88.97274252319336, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.695480585098267, "step": 60000}
{"episode_reward": 943.8068254992736, "episode": 61.0, "batch_reward": 0.8052218719720841, "critic_loss": 1.8106367006897925, "actor_loss": -88.80746212768555, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.56007671356201, "step": 61000}
{"episode_reward": 905.350770631281, "episode": 62.0, "batch_reward": 0.8070085572600365, "critic_loss": 1.8736486350297927, "actor_loss": -89.54548452758789, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.891044855117798, "step": 62000}
{"episode_reward": 950.874146466097, "episode": 63.0, "batch_reward": 0.8074445842504502, "critic_loss": 1.9046933758854867, "actor_loss": -89.1893793182373, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.698785543441772, "step": 63000}
{"episode_reward": 904.7251295932793, "episode": 64.0, "batch_reward": 0.8104160457253456, "critic_loss": 1.9292426458597183, "actor_loss": -89.43210404968262, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.898241996765137, "step": 64000}
{"episode_reward": 913.6032077258417, "episode": 65.0, "batch_reward": 0.8123294317126274, "critic_loss": 1.8470675385594368, "actor_loss": -89.27903117370606, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.258387804031372, "step": 65000}
{"episode_reward": 953.1202008824317, "episode": 66.0, "batch_reward": 0.8132321484088898, "critic_loss": 1.9153631770014763, "actor_loss": -89.4724825592041, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.712793588638306, "step": 66000}
{"episode_reward": 883.1380954772845, "episode": 67.0, "batch_reward": 0.8144990042448044, "critic_loss": 1.8206202461123466, "actor_loss": -89.63920687866211, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.424636363983154, "step": 67000}
{"episode_reward": 918.742164659568, "episode": 68.0, "batch_reward": 0.8172906289100647, "critic_loss": 1.7773634992837906, "actor_loss": -89.55886404418945, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.71168875694275, "step": 68000}
{"episode_reward": 947.7662451895806, "episode": 69.0, "batch_reward": 0.8179085118770599, "critic_loss": 1.7095378690958023, "actor_loss": -89.82756182861328, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.00679039955139, "step": 69000}
{"episode_reward": 984.2575624604677, "episode": 70.0, "batch_reward": 0.8213371453285218, "critic_loss": 1.7723912087082863, "actor_loss": -89.98798893737793, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.075790405273438, "step": 70000}
{"episode_reward": 928.7133066865634, "episode": 71.0, "batch_reward": 0.8227632581591606, "critic_loss": 1.818039733529091, "actor_loss": -90.20919253540039, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.220698833465576, "step": 71000}
{"episode_reward": 945.4024526894733, "episode": 72.0, "batch_reward": 0.8257649163007736, "critic_loss": 1.7409837398529053, "actor_loss": -90.32241232299805, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.533859968185425, "step": 72000}
{"episode_reward": 973.0439064838944, "episode": 73.0, "batch_reward": 0.8252554942369461, "critic_loss": 1.7725246428847312, "actor_loss": -90.11948695373535, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.74845314025879, "step": 73000}
{"episode_reward": 905.3583344589753, "episode": 74.0, "batch_reward": 0.8288322059512139, "critic_loss": 1.7348772636651992, "actor_loss": -90.53786511230469, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.19888424873352, "step": 74000}
{"episode_reward": 928.4484243524433, "episode": 75.0, "batch_reward": 0.8309576900601388, "critic_loss": 1.6273150198459625, "actor_loss": -90.25831797790528, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.653900146484375, "step": 75000}
{"episode_reward": 957.1431630837876, "episode": 76.0, "batch_reward": 0.8305834528803825, "critic_loss": 1.7173499670624732, "actor_loss": -90.35269192504883, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.812694549560547, "step": 76000}
{"episode_reward": 918.685595178182, "episode": 77.0, "batch_reward": 0.8329043760299683, "critic_loss": 1.6773356502056123, "actor_loss": -90.14210974121093, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.551239013671875, "step": 77000}
{"episode_reward": 958.7719380923387, "episode": 78.0, "batch_reward": 0.8337179987430573, "critic_loss": 1.6694509700536728, "actor_loss": -90.57826733398437, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.098149299621582, "step": 78000}
{"episode_reward": 925.5957807739868, "episode": 79.0, "batch_reward": 0.8352417702674866, "critic_loss": 1.6379447205662727, "actor_loss": -89.95955767822265, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.727787494659424, "step": 79000}
{"episode_reward": 911.2420555042088, "episode": 80.0, "batch_reward": 0.8336981302499771, "critic_loss": 1.6306276730298996, "actor_loss": -90.3735454864502, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.963961601257324, "step": 80000}
{"episode_reward": 960.8496777982598, "episode": 81.0, "batch_reward": 0.8365000375509262, "critic_loss": 1.6450846571326256, "actor_loss": -90.43752861022949, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.95778679847717, "step": 81000}
{"episode_reward": 943.0346799147751, "episode": 82.0, "batch_reward": 0.8371703812479973, "critic_loss": 1.7021788730025291, "actor_loss": -91.04636721801758, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.537911891937256, "step": 82000}
{"episode_reward": 769.4320815560336, "episode": 83.0, "batch_reward": 0.8390638846755027, "critic_loss": 1.7376603881120682, "actor_loss": -90.60512715148926, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.046940565109253, "step": 83000}
{"episode_reward": 912.7231197593378, "episode": 84.0, "batch_reward": 0.8398099413514137, "critic_loss": 1.6830530706644058, "actor_loss": -91.4042583770752, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.774345636367798, "step": 84000}
{"episode_reward": 973.0686594441376, "episode": 85.0, "batch_reward": 0.8377631958723069, "critic_loss": 1.8455078553557396, "actor_loss": -90.83598443603516, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.61495089530945, "step": 85000}
{"episode_reward": 864.1900203370068, "episode": 86.0, "batch_reward": 0.8409199222922326, "critic_loss": 1.7832582514882087, "actor_loss": -90.84896096801758, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.863734245300293, "step": 86000}
{"episode_reward": 944.8242315595526, "episode": 87.0, "batch_reward": 0.8421347594857216, "critic_loss": 1.7762409689426422, "actor_loss": -90.93435198974609, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.13642406463623, "step": 87000}
{"episode_reward": 935.4500462380572, "episode": 88.0, "batch_reward": 0.8431906025409699, "critic_loss": 1.7489861423373223, "actor_loss": -90.6518950805664, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.25164294242859, "step": 88000}
{"episode_reward": 936.6825071236834, "episode": 89.0, "batch_reward": 0.8419266378879547, "critic_loss": 1.7602181265354155, "actor_loss": -91.0237205657959, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.15043044090271, "step": 89000}
{"episode_reward": 899.5132555961085, "episode": 90.0, "batch_reward": 0.8442432054877281, "critic_loss": 1.7949516962766647, "actor_loss": -91.23092991638184, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.521186590194702, "step": 90000}
{"episode_reward": 916.9000800862416, "episode": 91.0, "batch_reward": 0.8463108763098717, "critic_loss": 1.7112450827360153, "actor_loss": -91.08302229309082, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.71577286720276, "step": 91000}
{"episode_reward": 925.8059296978188, "episode": 92.0, "batch_reward": 0.8489245470166207, "critic_loss": 1.641768250465393, "actor_loss": -91.18810249328614, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.456266164779663, "step": 92000}
{"episode_reward": 937.3530709782937, "episode": 93.0, "batch_reward": 0.8465046854615211, "critic_loss": 1.683220835149288, "actor_loss": -90.90696662902832, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.82403802871704, "step": 93000}
{"episode_reward": 971.3550236545592, "episode": 94.0, "batch_reward": 0.8474404582977295, "critic_loss": 1.729153294980526, "actor_loss": -91.1988094177246, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.931607484817505, "step": 94000}
{"episode_reward": 821.2101040196138, "episode": 95.0, "batch_reward": 0.8467422392368317, "critic_loss": 1.6759860385656358, "actor_loss": -91.2933589630127, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.21946907043457, "step": 95000}
{"episode_reward": 909.8947020108327, "episode": 96.0, "batch_reward": 0.8474355272650719, "critic_loss": 1.8376331200599672, "actor_loss": -91.39679267883301, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.741023540496826, "step": 96000}
{"episode_reward": 929.2551009573417, "episode": 97.0, "batch_reward": 0.8495705053806305, "critic_loss": 1.719144387960434, "actor_loss": -91.61648878479004, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.985715627670288, "step": 97000}
{"episode_reward": 936.6976202464192, "episode": 98.0, "batch_reward": 0.8509749608039856, "critic_loss": 1.6433727698922158, "actor_loss": -91.47364730834961, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.88571071624756, "step": 98000}
{"episode_reward": 927.6544726107327, "episode": 99.0, "batch_reward": 0.8497803688049317, "critic_loss": 1.592601501762867, "actor_loss": -91.09541458129883, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.668331384658813, "step": 99000}
{"episode_reward": 894.232549154708, "episode": 100.0, "batch_reward": 0.8529265106916427, "critic_loss": 1.7489212637543678, "actor_loss": -91.47084387207032, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.484692573547363, "step": 100000}
{"episode_reward": 922.9301063255882, "episode": 101.0, "batch_reward": 0.8535990306735038, "critic_loss": 1.5994510957598687, "actor_loss": -91.57412631225586, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.012648582458496, "step": 101000}
{"episode_reward": 965.51204013209, "episode": 102.0, "batch_reward": 0.853488938331604, "critic_loss": 1.7719532373547553, "actor_loss": -91.39126582336426, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44019365310669, "step": 102000}
{"episode_reward": 969.0920462547583, "episode": 103.0, "batch_reward": 0.8533756458163262, "critic_loss": 1.6730901320576668, "actor_loss": -91.65969340515137, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.810970783233643, "step": 103000}
{"episode_reward": 923.7980629508645, "episode": 104.0, "batch_reward": 0.8554083113670349, "critic_loss": 1.7153101470470429, "actor_loss": -91.7901830291748, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.096025705337524, "step": 104000}
{"episode_reward": 907.4503280702136, "episode": 105.0, "batch_reward": 0.8573946458697319, "critic_loss": 1.7366638471484184, "actor_loss": -91.85165339660645, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.445945978164673, "step": 105000}
{"episode_reward": 943.7066017454011, "episode": 106.0, "batch_reward": 0.8558623754382133, "critic_loss": 1.7883766775727272, "actor_loss": -91.68416003417968, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.138542652130127, "step": 106000}
{"episode_reward": 912.1283007202037, "episode": 107.0, "batch_reward": 0.8574019105434417, "critic_loss": 1.8423064513802527, "actor_loss": -91.8627230682373, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.86414670944214, "step": 107000}
{"episode_reward": 959.5198732939546, "episode": 108.0, "batch_reward": 0.8586409350633621, "critic_loss": 1.7087862280607224, "actor_loss": -91.86955456542968, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.280489206314087, "step": 108000}
{"episode_reward": 797.7736710648313, "episode": 109.0, "batch_reward": 0.8574860627651215, "critic_loss": 1.7971801221966743, "actor_loss": -92.23612925720215, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.617024183273315, "step": 109000}
{"episode_reward": 915.3090615766464, "episode": 110.0, "batch_reward": 0.8579640442728996, "critic_loss": 1.622967516720295, "actor_loss": -92.01553692626953, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.631078004837036, "step": 110000}
{"episode_reward": 943.9657264527136, "episode": 111.0, "batch_reward": 0.8582576893568039, "critic_loss": 1.5830705629587174, "actor_loss": -92.03282026672363, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.04472088813782, "step": 111000}
{"episode_reward": 945.6745571341987, "episode": 112.0, "batch_reward": 0.8590782140493393, "critic_loss": 1.6777619203329086, "actor_loss": -91.75527372741699, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.587453365325928, "step": 112000}
{"episode_reward": 913.8814021903622, "episode": 113.0, "batch_reward": 0.8606803886294365, "critic_loss": 1.6305742798447609, "actor_loss": -92.06060188293458, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.46792507171631, "step": 113000}
{"episode_reward": 958.4392314041717, "episode": 114.0, "batch_reward": 0.8615466359257699, "critic_loss": 1.6829834632873535, "actor_loss": -92.32181616210937, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.72301149368286, "step": 114000}
{"episode_reward": 975.2560179314299, "episode": 115.0, "batch_reward": 0.8614888035655022, "critic_loss": 1.655739402681589, "actor_loss": -92.00463079833985, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.018664360046387, "step": 115000}
{"episode_reward": 899.9551835910873, "episode": 116.0, "batch_reward": 0.8629948362112045, "critic_loss": 1.6602456243634225, "actor_loss": -92.04958200073243, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.117032051086426, "step": 116000}
{"episode_reward": 951.537105775533, "episode": 117.0, "batch_reward": 0.8623456936478615, "critic_loss": 1.6800845167040825, "actor_loss": -91.9291881866455, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.502142906188965, "step": 117000}
{"episode_reward": 910.7506344714205, "episode": 118.0, "batch_reward": 0.8633077914714813, "critic_loss": 1.6770685814619064, "actor_loss": -92.17681874084472, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.4455885887146, "step": 118000}
{"episode_reward": 877.9707076976626, "episode": 119.0, "batch_reward": 0.8635274965167046, "critic_loss": 1.6548815457224846, "actor_loss": -92.27530407714843, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.53102684020996, "step": 119000}
{"episode_reward": 936.429974906604, "episode": 120.0, "batch_reward": 0.8613644225001336, "critic_loss": 1.6741815120577812, "actor_loss": -92.11621369934082, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.999969959259033, "step": 120000}
{"episode_reward": 935.0696590894258, "episode": 121.0, "batch_reward": 0.8653277681469917, "critic_loss": 1.5628317430019378, "actor_loss": -91.9978024597168, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.40010857582092, "step": 121000}
{"episode_reward": 966.4122894398377, "episode": 122.0, "batch_reward": 0.8645871722102165, "critic_loss": 1.598250486910343, "actor_loss": -92.12477154541016, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.43728470802307, "step": 122000}
{"episode_reward": 942.6308995433732, "episode": 123.0, "batch_reward": 0.8669875710606575, "critic_loss": 1.6047331101894378, "actor_loss": -91.89281729125976, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.639310836791992, "step": 123000}
{"episode_reward": 855.4861879291263, "episode": 124.0, "batch_reward": 0.8665773183107376, "critic_loss": 1.5666088173389434, "actor_loss": -92.17658961486816, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.884683847427368, "step": 124000}
{"episode_reward": 960.1182534340635, "episode": 125.0, "batch_reward": 0.8681760365962983, "critic_loss": 1.520694817662239, "actor_loss": -92.17233898925781, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.770230293273926, "step": 125000}
{"episode_reward": 986.0975764325207, "episode": 126.0, "batch_reward": 0.8679992194771766, "critic_loss": 1.4617717814445497, "actor_loss": -92.03286543273926, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.20908808708191, "step": 126000}
{"episode_reward": 979.256777919469, "episode": 127.0, "batch_reward": 0.8681255033612252, "critic_loss": 1.4866224715709686, "actor_loss": -92.41310813903809, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.60028314590454, "step": 127000}
{"episode_reward": 766.6486430635802, "episode": 128.0, "batch_reward": 0.8666445932984352, "critic_loss": 1.6601012491583824, "actor_loss": -92.63860810852051, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.859970331192017, "step": 128000}
{"episode_reward": 878.5029414226877, "episode": 129.0, "batch_reward": 0.8683039796352386, "critic_loss": 1.5638868162035942, "actor_loss": -92.44715673828125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.27510118484497, "step": 129000}
{"episode_reward": 983.1677032767394, "episode": 130.0, "batch_reward": 0.8696376963257789, "critic_loss": 1.5604949404597281, "actor_loss": -92.49219728088379, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.523852825164795, "step": 130000}
{"episode_reward": 981.6158582918368, "episode": 131.0, "batch_reward": 0.8717738453745842, "critic_loss": 1.5861631485521794, "actor_loss": -92.67741065979004, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.27522110939026, "step": 131000}
{"episode_reward": 937.7896720148331, "episode": 132.0, "batch_reward": 0.8710110139250755, "critic_loss": 1.5794820714592934, "actor_loss": -92.63281158447266, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.45223307609558, "step": 132000}
{"episode_reward": 960.8097490062278, "episode": 133.0, "batch_reward": 0.870020012319088, "critic_loss": 1.6328618581295014, "actor_loss": -92.53160864257812, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.7404203414917, "step": 133000}
{"episode_reward": 883.0203718643106, "episode": 134.0, "batch_reward": 0.8715635414719581, "critic_loss": 1.5949321281313895, "actor_loss": -92.69181806945801, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.75059986114502, "step": 134000}
{"episode_reward": 957.7332107110932, "episode": 135.0, "batch_reward": 0.8729806396961212, "critic_loss": 1.5566234986186027, "actor_loss": -92.65689511108398, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.563036680221558, "step": 135000}
{"episode_reward": 986.199161846232, "episode": 136.0, "batch_reward": 0.8735354687571526, "critic_loss": 1.5389965574741364, "actor_loss": -92.97411071777344, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.849152088165283, "step": 136000}
{"episode_reward": 988.5601583486317, "episode": 137.0, "batch_reward": 0.8737008838057518, "critic_loss": 1.571648085772991, "actor_loss": -92.71669473266601, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.788299083709717, "step": 137000}
{"episode_reward": 987.6378321862117, "episode": 138.0, "batch_reward": 0.8751334462165833, "critic_loss": 1.5921114830970764, "actor_loss": -92.33757640075683, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.45646047592163, "step": 138000}
{"episode_reward": 915.5100459111788, "episode": 139.0, "batch_reward": 0.8748276619911194, "critic_loss": 1.5314956958293915, "actor_loss": -92.48147248840333, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.29092025756836, "step": 139000}
{"episode_reward": 975.257662182319, "episode": 140.0, "batch_reward": 0.8761795696020126, "critic_loss": 1.541523883342743, "actor_loss": -92.33367041015624, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.558818340301514, "step": 140000}
{"episode_reward": 945.9611383496017, "episode": 141.0, "batch_reward": 0.8761751660704613, "critic_loss": 1.4876259332895279, "actor_loss": -92.52697529602051, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.40331268310547, "step": 141000}
{"episode_reward": 964.2293057045255, "episode": 142.0, "batch_reward": 0.8757266376614571, "critic_loss": 1.5027071471512317, "actor_loss": -92.55193530273438, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.15933394432068, "step": 142000}
{"episode_reward": 988.3669377363512, "episode": 143.0, "batch_reward": 0.8770494985580445, "critic_loss": 1.5169195193052292, "actor_loss": -92.79405438232422, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.679585695266724, "step": 143000}
{"episode_reward": 962.1835515673018, "episode": 144.0, "batch_reward": 0.8774819021224975, "critic_loss": 1.525088642001152, "actor_loss": -92.74962265014648, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.858051776885986, "step": 144000}
{"episode_reward": 956.4078806488873, "episode": 145.0, "batch_reward": 0.8788695631623268, "critic_loss": 1.5466515391469002, "actor_loss": -92.7851240234375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.91381287574768, "step": 145000}
{"episode_reward": 986.9934713129402, "episode": 146.0, "batch_reward": 0.8780320724248886, "critic_loss": 1.5294220771193505, "actor_loss": -92.68087533569336, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.320587635040283, "step": 146000}
{"episode_reward": 965.0824162183691, "episode": 147.0, "batch_reward": 0.8793074327111244, "critic_loss": 1.5020449691414832, "actor_loss": -92.98130252075195, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.510265350341797, "step": 147000}
{"episode_reward": 898.2968736119697, "episode": 148.0, "batch_reward": 0.8812372400164604, "critic_loss": 1.4914254871010781, "actor_loss": -92.7827933807373, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.639228105545044, "step": 148000}
{"episode_reward": 981.4683672999279, "episode": 149.0, "batch_reward": 0.8802227370738983, "critic_loss": 1.4717731168866157, "actor_loss": -92.89484117126464, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.862863063812256, "step": 149000}
{"episode_reward": 963.0023923784064, "episode": 150.0, "batch_reward": 0.8810837529301644, "critic_loss": 1.5369822647571563, "actor_loss": -92.75663497924805, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
