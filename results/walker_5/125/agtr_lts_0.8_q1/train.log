{"episode_reward": 0.0, "episode": 1.0, "duration": 22.60664677619934, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.9177632331848145, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.500907701188304, "critic_loss": 1.1778334596229418, "actor_loss": -85.95583110258264, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 67.37474226951599, "step": 3000}
{"episode_reward": 831.2861701804358, "episode": 4.0, "batch_reward": 0.6048571708500385, "critic_loss": 1.493444972395897, "actor_loss": -87.92730194091797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.405889749526978, "step": 4000}
{"episode_reward": 687.5040055376796, "episode": 5.0, "batch_reward": 0.6407452561855316, "critic_loss": 1.4222089771032334, "actor_loss": -88.09645352172852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.611770153045654, "step": 5000}
{"episode_reward": 862.826409279579, "episode": 6.0, "batch_reward": 0.6915118871927262, "critic_loss": 1.4572746601104736, "actor_loss": -88.8261612701416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.921953439712524, "step": 6000}
{"episode_reward": 968.8854641526489, "episode": 7.0, "batch_reward": 0.724223060965538, "critic_loss": 1.4794348975419997, "actor_loss": -89.42861543273926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.40708017349243, "step": 7000}
{"episode_reward": 865.761390349896, "episode": 8.0, "batch_reward": 0.7514561853408813, "critic_loss": 1.3625825061798096, "actor_loss": -89.91749920654297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97974395751953, "step": 8000}
{"episode_reward": 958.0021889263562, "episode": 9.0, "batch_reward": 0.7712156300544739, "critic_loss": 1.4323148285150529, "actor_loss": -90.45432441711426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.22466516494751, "step": 9000}
{"episode_reward": 945.2616751559898, "episode": 10.0, "batch_reward": 0.7890847370624542, "critic_loss": 1.3218908086419106, "actor_loss": -90.93802133178711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.027661561965942, "step": 10000}
{"episode_reward": 932.303544384937, "episode": 11.0, "batch_reward": 0.805112536072731, "critic_loss": 1.1359518040418626, "actor_loss": -91.41526856994629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.46379590034485, "step": 11000}
{"episode_reward": 960.9950612860234, "episode": 12.0, "batch_reward": 0.8093559925556183, "critic_loss": 1.1792839327454567, "actor_loss": -91.35590646362304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.80596423149109, "step": 12000}
{"episode_reward": 862.9531908669354, "episode": 13.0, "batch_reward": 0.8187011695504188, "critic_loss": 1.1143200660347938, "actor_loss": -91.70776307678223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.466348886489868, "step": 13000}
{"episode_reward": 913.0516508250838, "episode": 14.0, "batch_reward": 0.8314139714241028, "critic_loss": 1.1084471680521966, "actor_loss": -91.85151368713379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.929361581802368, "step": 14000}
{"episode_reward": 966.7678926079766, "episode": 15.0, "batch_reward": 0.8411008271574975, "critic_loss": 0.9526583095192909, "actor_loss": -92.67743919372559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.742877960205078, "step": 15000}
{"episode_reward": 987.7837352914884, "episode": 16.0, "batch_reward": 0.8487282151579857, "critic_loss": 0.9212084428668023, "actor_loss": -92.56317497253418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.491066694259644, "step": 16000}
{"episode_reward": 932.2501464100692, "episode": 17.0, "batch_reward": 0.8515211116671563, "critic_loss": 0.8845343406498433, "actor_loss": -92.81132817077636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.73452115058899, "step": 17000}
{"episode_reward": 893.3188065614543, "episode": 18.0, "batch_reward": 0.8558915392160416, "critic_loss": 0.9009867300987243, "actor_loss": -92.77120829772949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.933831214904785, "step": 18000}
{"episode_reward": 934.9638131041695, "episode": 19.0, "batch_reward": 0.8616755341887474, "critic_loss": 0.9652109176516533, "actor_loss": -92.65242346191407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.8838210105896, "step": 19000}
{"episode_reward": 983.793562803665, "episode": 20.0, "batch_reward": 0.8670178467035293, "critic_loss": 0.9084410633146763, "actor_loss": -93.05493977355957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.20898413658142, "step": 20000}
{"episode_reward": 962.2078687560411, "episode": 21.0, "batch_reward": 0.8681615073084831, "critic_loss": 0.9237488331794739, "actor_loss": -93.07968324279786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.5606746673584, "step": 21000}
{"episode_reward": 902.8215590378185, "episode": 22.0, "batch_reward": 0.8747342954874039, "critic_loss": 0.8943028211891652, "actor_loss": -93.15208441162109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.043908834457397, "step": 22000}
{"episode_reward": 968.4266734836018, "episode": 23.0, "batch_reward": 0.874387627184391, "critic_loss": 0.8939164083600044, "actor_loss": -93.35959956359864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.223963260650635, "step": 23000}
{"episode_reward": 885.6054445088411, "episode": 24.0, "batch_reward": 0.8770941816568375, "critic_loss": 0.844218634724617, "actor_loss": -93.29399955749511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.635733127593994, "step": 24000}
{"episode_reward": 921.9513451376818, "episode": 25.0, "batch_reward": 0.8784032016396522, "critic_loss": 0.9323537767529487, "actor_loss": -93.19095108032226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.81511950492859, "step": 25000}
{"episode_reward": 947.4154275323231, "episode": 26.0, "batch_reward": 0.8809921842813492, "critic_loss": 0.8870464189946652, "actor_loss": -93.51339942932128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.658895254135132, "step": 26000}
{"episode_reward": 975.6355866341252, "episode": 27.0, "batch_reward": 0.8867949888706207, "critic_loss": 0.9427685656547546, "actor_loss": -93.39965322875976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.808558464050293, "step": 27000}
{"episode_reward": 972.4726752421547, "episode": 28.0, "batch_reward": 0.8889184613823891, "critic_loss": 0.8996415882110596, "actor_loss": -93.388392578125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.386398315429688, "step": 28000}
{"episode_reward": 929.7052457282085, "episode": 29.0, "batch_reward": 0.8889503815770149, "critic_loss": 0.9380748701393604, "actor_loss": -93.48792077636719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.056630849838257, "step": 29000}
{"episode_reward": 912.4777086399616, "episode": 30.0, "batch_reward": 0.8900321353673935, "critic_loss": 0.9918783963322639, "actor_loss": -93.39746257019043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.633889198303223, "step": 30000}
{"episode_reward": 917.0219354802388, "episode": 31.0, "batch_reward": 0.8921175957918167, "critic_loss": 0.9814495114088059, "actor_loss": -93.55331399536132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.58972954750061, "step": 31000}
{"episode_reward": 956.0096940590793, "episode": 32.0, "batch_reward": 0.8940698196291923, "critic_loss": 0.9580356430113316, "actor_loss": -93.44253741455078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.04018473625183, "step": 32000}
{"episode_reward": 969.6594518882667, "episode": 33.0, "batch_reward": 0.8948222807049752, "critic_loss": 0.9687704078555107, "actor_loss": -93.74806140136718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.490278244018555, "step": 33000}
{"episode_reward": 923.4430393281442, "episode": 34.0, "batch_reward": 0.8963392385840416, "critic_loss": 0.9768161354362964, "actor_loss": -93.59184809875488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.30285143852234, "step": 34000}
{"episode_reward": 956.9452799533685, "episode": 35.0, "batch_reward": 0.8957189472317696, "critic_loss": 1.1407366298437118, "actor_loss": -93.90842448425293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.299590349197388, "step": 35000}
{"episode_reward": 872.4205356087476, "episode": 36.0, "batch_reward": 0.8963739411830902, "critic_loss": 1.1081125893592834, "actor_loss": -93.56007518005372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.962321281433105, "step": 36000}
{"episode_reward": 916.8499288865705, "episode": 37.0, "batch_reward": 0.8971204324960709, "critic_loss": 1.1397309520244598, "actor_loss": -93.8231432800293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.873900651931763, "step": 37000}
{"episode_reward": 952.4607654457154, "episode": 38.0, "batch_reward": 0.9010506258606911, "critic_loss": 1.1076979462504386, "actor_loss": -93.85143852233887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.810025691986084, "step": 38000}
{"episode_reward": 985.6071994639738, "episode": 39.0, "batch_reward": 0.901063715517521, "critic_loss": 1.231700930774212, "actor_loss": -93.9391483001709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.067918062210083, "step": 39000}
{"episode_reward": 914.5490229728523, "episode": 40.0, "batch_reward": 0.9018972281217575, "critic_loss": 1.254054822564125, "actor_loss": -94.02124873352051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.384201288223267, "step": 40000}
{"episode_reward": 964.1074626243775, "episode": 41.0, "batch_reward": 0.9026326012015343, "critic_loss": 1.388388651549816, "actor_loss": -94.05077029418945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.699870586395264, "step": 41000}
{"episode_reward": 870.7857903423554, "episode": 42.0, "batch_reward": 0.9039268090128899, "critic_loss": 1.3845965009331702, "actor_loss": -93.80463746643066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.169856309890747, "step": 42000}
{"episode_reward": 945.021384775701, "episode": 43.0, "batch_reward": 0.9027996146082878, "critic_loss": 1.4040007945299149, "actor_loss": -93.90068649291992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.87252140045166, "step": 43000}
{"episode_reward": 922.4945352583956, "episode": 44.0, "batch_reward": 0.9050572111010552, "critic_loss": 1.324786394059658, "actor_loss": -93.90662014770508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.646329402923584, "step": 44000}
{"episode_reward": 978.3185516117085, "episode": 45.0, "batch_reward": 0.9060815781354904, "critic_loss": 1.2225976406037808, "actor_loss": -93.97603015136718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.809958457946777, "step": 45000}
{"episode_reward": 942.2098573216114, "episode": 46.0, "batch_reward": 0.9057371933460235, "critic_loss": 1.2499932110905647, "actor_loss": -93.97604042053223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.706270694732666, "step": 46000}
{"episode_reward": 938.1234394277434, "episode": 47.0, "batch_reward": 0.908122620344162, "critic_loss": 1.1879971058368684, "actor_loss": -94.19528526306152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.802740335464478, "step": 47000}
{"episode_reward": 959.2889728435174, "episode": 48.0, "batch_reward": 0.9056978939771653, "critic_loss": 1.207700035095215, "actor_loss": -94.02474978637696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.63675594329834, "step": 48000}
{"episode_reward": 834.1592844515212, "episode": 49.0, "batch_reward": 0.9077135651111603, "critic_loss": 1.1959081837236882, "actor_loss": -94.30973857116699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.399998903274536, "step": 49000}
{"episode_reward": 955.1124754192983, "episode": 50.0, "batch_reward": 0.9086936590075493, "critic_loss": 1.1561063937842846, "actor_loss": -94.13268270874023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.345453023910522, "step": 50000}
{"episode_reward": 986.812288987175, "episode": 51.0, "batch_reward": 0.9099409757256508, "critic_loss": 1.1646523445546626, "actor_loss": -94.21103782653809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.59590148925781, "step": 51000}
{"episode_reward": 975.7631500327288, "episode": 52.0, "batch_reward": 0.9100523054003715, "critic_loss": 1.1049797039031983, "actor_loss": -94.20866918945312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.75646662712097, "step": 52000}
{"episode_reward": 922.4835287224666, "episode": 53.0, "batch_reward": 0.9111477838754654, "critic_loss": 1.0513760628700257, "actor_loss": -94.33147555541993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.72938299179077, "step": 53000}
{"episode_reward": 933.749954812941, "episode": 54.0, "batch_reward": 0.9103808005452156, "critic_loss": 1.1593087575435639, "actor_loss": -94.18349472045898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.672872066497803, "step": 54000}
{"episode_reward": 902.8564224424574, "episode": 55.0, "batch_reward": 0.9116422706246377, "critic_loss": 1.1634480491578578, "actor_loss": -94.51062165832519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.8866605758667, "step": 55000}
{"episode_reward": 951.3899790183141, "episode": 56.0, "batch_reward": 0.9127614192962646, "critic_loss": 1.1996287989020347, "actor_loss": -94.4449478149414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60985517501831, "step": 56000}
{"episode_reward": 988.4023874685337, "episode": 57.0, "batch_reward": 0.9129093722105026, "critic_loss": 1.1127071115374565, "actor_loss": -94.21344621276856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.540851354599, "step": 57000}
{"episode_reward": 913.8405281690909, "episode": 58.0, "batch_reward": 0.9136678226590157, "critic_loss": 1.1014684033691884, "actor_loss": -94.3319377746582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.653264045715332, "step": 58000}
{"episode_reward": 974.3394555969563, "episode": 59.0, "batch_reward": 0.9151481454968452, "critic_loss": 1.1505221855938434, "actor_loss": -94.33565991210938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.758815050125122, "step": 59000}
{"episode_reward": 958.7575885553157, "episode": 60.0, "batch_reward": 0.9155535163283348, "critic_loss": 1.22179782345891, "actor_loss": -94.40902394104003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.065866947174072, "step": 60000}
{"episode_reward": 923.4146339584248, "episode": 61.0, "batch_reward": 0.9162781674861908, "critic_loss": 1.078862737774849, "actor_loss": -94.31120562744141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.07154655456543, "step": 61000}
{"episode_reward": 957.7236626174622, "episode": 62.0, "batch_reward": 0.915264976799488, "critic_loss": 1.0833844650685787, "actor_loss": -94.59637307739258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.58100199699402, "step": 62000}
{"episode_reward": 933.9171418546136, "episode": 63.0, "batch_reward": 0.9137730394601822, "critic_loss": 1.1747246623635292, "actor_loss": -94.35308908081055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.92432689666748, "step": 63000}
{"episode_reward": 810.5487179591573, "episode": 64.0, "batch_reward": 0.9143755043148994, "critic_loss": 1.1075870516002178, "actor_loss": -94.43079425048828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.494200468063354, "step": 64000}
{"episode_reward": 987.1365799445622, "episode": 65.0, "batch_reward": 0.9164902438521385, "critic_loss": 1.0898077082633972, "actor_loss": -94.40180046081542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.84654474258423, "step": 65000}
{"episode_reward": 982.0720316186911, "episode": 66.0, "batch_reward": 0.9157120541930198, "critic_loss": 1.1095896496474742, "actor_loss": -94.46106326293945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.7900869846344, "step": 66000}
{"episode_reward": 929.1577226305235, "episode": 67.0, "batch_reward": 0.9154700136184692, "critic_loss": 1.1431523578763008, "actor_loss": -94.49025177001953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.541093111038208, "step": 67000}
{"episode_reward": 914.6337987582241, "episode": 68.0, "batch_reward": 0.916573526263237, "critic_loss": 1.1172987295985222, "actor_loss": -94.41058407592773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.971115350723267, "step": 68000}
{"episode_reward": 944.759608866552, "episode": 69.0, "batch_reward": 0.9169089516401291, "critic_loss": 1.1132949512302877, "actor_loss": -94.53682223510742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.24036455154419, "step": 69000}
{"episode_reward": 928.3589130419138, "episode": 70.0, "batch_reward": 0.916945349752903, "critic_loss": 1.0761874663233757, "actor_loss": -94.51503440856933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.600870370864868, "step": 70000}
{"episode_reward": 918.0732836119338, "episode": 71.0, "batch_reward": 0.9172619439959526, "critic_loss": 1.1221297398507595, "actor_loss": -94.64722904968262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.76834726333618, "step": 71000}
{"episode_reward": 943.1904895665925, "episode": 72.0, "batch_reward": 0.9177156592011452, "critic_loss": 1.126489079207182, "actor_loss": -94.6449493560791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.131744623184204, "step": 72000}
{"episode_reward": 971.3707216155491, "episode": 73.0, "batch_reward": 0.916316404402256, "critic_loss": 1.21535719704628, "actor_loss": -94.52206274414063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.07046914100647, "step": 73000}
{"episode_reward": 769.2299696755466, "episode": 74.0, "batch_reward": 0.9166664375662804, "critic_loss": 1.33482079616189, "actor_loss": -94.66296932983398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.62954092025757, "step": 74000}
{"episode_reward": 853.4729643732602, "episode": 75.0, "batch_reward": 0.915364679634571, "critic_loss": 1.2219877972900868, "actor_loss": -94.45458416748046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.73470377922058, "step": 75000}
{"episode_reward": 950.5946418442776, "episode": 76.0, "batch_reward": 0.9155514197349548, "critic_loss": 1.3096575787067413, "actor_loss": -94.47075323486328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.037647008895874, "step": 76000}
{"episode_reward": 960.6424143965894, "episode": 77.0, "batch_reward": 0.9166761685013771, "critic_loss": 1.281570280969143, "actor_loss": -94.39293815612793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.112200021743774, "step": 77000}
{"episode_reward": 959.946988178792, "episode": 78.0, "batch_reward": 0.9175731518268585, "critic_loss": 1.2430962710678577, "actor_loss": -94.59540344238282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.782479763031006, "step": 78000}
{"episode_reward": 954.5580997368012, "episode": 79.0, "batch_reward": 0.9187317762970925, "critic_loss": 1.2921499927937985, "actor_loss": -94.31818408203125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.075149297714233, "step": 79000}
{"episode_reward": 963.5701343432773, "episode": 80.0, "batch_reward": 0.9178141885995865, "critic_loss": 1.2663469059169292, "actor_loss": -94.47582893371582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.75618886947632, "step": 80000}
{"episode_reward": 970.8278837169323, "episode": 81.0, "batch_reward": 0.9180678948163986, "critic_loss": 1.2659182081520557, "actor_loss": -94.46410255432129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.565998792648315, "step": 81000}
{"episode_reward": 837.5832266695814, "episode": 82.0, "batch_reward": 0.9184990603327751, "critic_loss": 1.253168132185936, "actor_loss": -94.67630877685546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.611979007720947, "step": 82000}
{"episode_reward": 961.1588913815581, "episode": 83.0, "batch_reward": 0.9176210163235664, "critic_loss": 1.2647974293231965, "actor_loss": -94.44377822875977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.333231687545776, "step": 83000}
{"episode_reward": 886.5438946074673, "episode": 84.0, "batch_reward": 0.9193495659232139, "critic_loss": 1.21699360743165, "actor_loss": -94.89778985595703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.133069276809692, "step": 84000}
{"episode_reward": 989.6636615663161, "episode": 85.0, "batch_reward": 0.9184395119547843, "critic_loss": 1.227316148608923, "actor_loss": -94.55418519592286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.055182933807373, "step": 85000}
{"episode_reward": 944.275354484242, "episode": 86.0, "batch_reward": 0.9190216551423073, "critic_loss": 1.3372945646345615, "actor_loss": -94.58460992431641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.634427785873413, "step": 86000}
{"episode_reward": 913.53252950743, "episode": 87.0, "batch_reward": 0.9185285876989364, "critic_loss": 1.300558273255825, "actor_loss": -94.58027673339843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.944113969802856, "step": 87000}
{"episode_reward": 897.4033008510864, "episode": 88.0, "batch_reward": 0.9195440236330032, "critic_loss": 1.3644346927404403, "actor_loss": -94.41091957092286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.837863445281982, "step": 88000}
{"episode_reward": 912.1515104374762, "episode": 89.0, "batch_reward": 0.91828314691782, "critic_loss": 1.3040413412153722, "actor_loss": -94.58517015075684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.92734980583191, "step": 89000}
{"episode_reward": 954.3954858188042, "episode": 90.0, "batch_reward": 0.9192607980370522, "critic_loss": 1.3683673904538154, "actor_loss": -94.70739651489258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.432541847229004, "step": 90000}
{"episode_reward": 906.8850164098235, "episode": 91.0, "batch_reward": 0.91893673235178, "critic_loss": 1.3377843542695045, "actor_loss": -94.53606632995606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.64899396896362, "step": 91000}
{"episode_reward": 941.660642532821, "episode": 92.0, "batch_reward": 0.9205657801032067, "critic_loss": 1.34625061121583, "actor_loss": -94.62174386596679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.443437099456787, "step": 92000}
{"episode_reward": 954.5018798907889, "episode": 93.0, "batch_reward": 0.9190976583361625, "critic_loss": 1.3494591678380967, "actor_loss": -94.50329457092285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.70173978805542, "step": 93000}
{"episode_reward": 965.3832231748854, "episode": 94.0, "batch_reward": 0.9201157476902008, "critic_loss": 1.3919618084430694, "actor_loss": -94.60444538879395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.59266471862793, "step": 94000}
{"episode_reward": 930.5391242666599, "episode": 95.0, "batch_reward": 0.9193020184636116, "critic_loss": 1.4490295138061047, "actor_loss": -94.59955253601075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.223848819732666, "step": 95000}
{"episode_reward": 908.5623940949431, "episode": 96.0, "batch_reward": 0.9198997307419777, "critic_loss": 1.514066715270281, "actor_loss": -94.66735499572754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.573737621307373, "step": 96000}
{"episode_reward": 947.6933708597363, "episode": 97.0, "batch_reward": 0.9203915840983391, "critic_loss": 1.5153500398099422, "actor_loss": -94.66892684936523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.66581892967224, "step": 97000}
{"episode_reward": 928.2886319583978, "episode": 98.0, "batch_reward": 0.9204477519392967, "critic_loss": 1.5332048476338387, "actor_loss": -94.55396841430664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.62467074394226, "step": 98000}
{"episode_reward": 903.3726346659166, "episode": 99.0, "batch_reward": 0.9190715747475624, "critic_loss": 1.594975272476673, "actor_loss": -94.31803248596191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.62487006187439, "step": 99000}
{"episode_reward": 923.5382214946821, "episode": 100.0, "batch_reward": 0.9214081280231475, "critic_loss": 1.5338634923100471, "actor_loss": -94.55523609924316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.696439266204834, "step": 100000}
{"episode_reward": 922.477929093974, "episode": 101.0, "batch_reward": 0.9219317435622215, "critic_loss": 1.547074843943119, "actor_loss": -94.55358274841309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.477126598358154, "step": 101000}
{"episode_reward": 979.9023994537544, "episode": 102.0, "batch_reward": 0.920138423860073, "critic_loss": 1.5295798235535623, "actor_loss": -94.43612591552734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.468679428100586, "step": 102000}
{"episode_reward": 968.1026366644473, "episode": 103.0, "batch_reward": 0.9211308072209359, "critic_loss": 1.4977410967350007, "actor_loss": -94.5618623046875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.64039707183838, "step": 103000}
{"episode_reward": 958.7704937019728, "episode": 104.0, "batch_reward": 0.9224747628569603, "critic_loss": 1.4607732839882375, "actor_loss": -94.65605299377441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.43895721435547, "step": 104000}
{"episode_reward": 956.139020830021, "episode": 105.0, "batch_reward": 0.9231504569649697, "critic_loss": 1.5157315744757651, "actor_loss": -94.69264956665039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.79848074913025, "step": 105000}
{"episode_reward": 919.7855379812003, "episode": 106.0, "batch_reward": 0.9217995032668114, "critic_loss": 1.5377832312583923, "actor_loss": -94.57766717529297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.063570261001587, "step": 106000}
{"episode_reward": 849.4960375844636, "episode": 107.0, "batch_reward": 0.9211334030032158, "critic_loss": 1.4870842496156693, "actor_loss": -94.62816102600098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.842203378677368, "step": 107000}
{"episode_reward": 952.168114282059, "episode": 108.0, "batch_reward": 0.9221157448291779, "critic_loss": 1.4939155034720897, "actor_loss": -94.63824742126465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.85408091545105, "step": 108000}
{"episode_reward": 946.386972031575, "episode": 109.0, "batch_reward": 0.9223463754057885, "critic_loss": 1.4440021049380303, "actor_loss": -94.87839482116699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.615902185440063, "step": 109000}
{"episode_reward": 952.7466563821941, "episode": 110.0, "batch_reward": 0.9220712682008744, "critic_loss": 1.544174568593502, "actor_loss": -94.75658721923828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.665284156799316, "step": 110000}
{"episode_reward": 939.1515473173772, "episode": 111.0, "batch_reward": 0.921816597700119, "critic_loss": 1.5246664788424968, "actor_loss": -94.68369047546386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.87700176239014, "step": 111000}
{"episode_reward": 911.512853540843, "episode": 112.0, "batch_reward": 0.9218515304327011, "critic_loss": 1.5754915677309036, "actor_loss": -94.45343949890136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.41469097137451, "step": 112000}
{"episode_reward": 939.9436678931045, "episode": 113.0, "batch_reward": 0.9237508088350296, "critic_loss": 1.5286728808879853, "actor_loss": -94.73218225097656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16572880744934, "step": 113000}
{"episode_reward": 959.1764449127932, "episode": 114.0, "batch_reward": 0.9225396918654442, "critic_loss": 1.5595285457372665, "actor_loss": -94.8083452758789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.991934061050415, "step": 114000}
{"episode_reward": 936.4131792338709, "episode": 115.0, "batch_reward": 0.9235601256489754, "critic_loss": 1.700638698577881, "actor_loss": -94.58999183654785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.6291081905365, "step": 115000}
{"episode_reward": 923.0441718464167, "episode": 116.0, "batch_reward": 0.9224153831601143, "critic_loss": 1.7163591460883618, "actor_loss": -94.5971473083496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.333164930343628, "step": 116000}
{"episode_reward": 898.8528065510365, "episode": 117.0, "batch_reward": 0.9219462664723397, "critic_loss": 1.8047209748625754, "actor_loss": -94.5038249053955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.562880277633667, "step": 117000}
{"episode_reward": 868.1518557488838, "episode": 118.0, "batch_reward": 0.9226731864213944, "critic_loss": 1.872264680147171, "actor_loss": -94.67024935913086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.428706884384155, "step": 118000}
{"episode_reward": 982.0028565726159, "episode": 119.0, "batch_reward": 0.9225446531772613, "critic_loss": 1.7208396865725517, "actor_loss": -94.70085646057129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.440276622772217, "step": 119000}
{"episode_reward": 946.5261371840775, "episode": 120.0, "batch_reward": 0.9224639258384705, "critic_loss": 1.747698793143034, "actor_loss": -94.59874411010742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.328092098236084, "step": 120000}
{"episode_reward": 923.4073962838004, "episode": 121.0, "batch_reward": 0.9233687705397606, "critic_loss": 1.6779177089333535, "actor_loss": -94.52065107727051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.65359807014465, "step": 121000}
{"episode_reward": 980.1671996002311, "episode": 122.0, "batch_reward": 0.9230780693888664, "critic_loss": 1.6629845927357674, "actor_loss": -94.56389723205567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.12358570098877, "step": 122000}
{"episode_reward": 945.7165607302205, "episode": 123.0, "batch_reward": 0.9237856829762459, "critic_loss": 1.660612648844719, "actor_loss": -94.42124348449707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.753509044647217, "step": 123000}
{"episode_reward": 935.9693934933457, "episode": 124.0, "batch_reward": 0.9233035101294518, "critic_loss": 1.6566768238544465, "actor_loss": -94.57003907775879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.14391040802002, "step": 124000}
{"episode_reward": 947.5691486019836, "episode": 125.0, "batch_reward": 0.9241665753722191, "critic_loss": 1.6446025819480419, "actor_loss": -94.59189912414551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.052608251571655, "step": 125000}
{"episode_reward": 985.3419934936613, "episode": 126.0, "batch_reward": 0.925409733235836, "critic_loss": 1.6483489181399344, "actor_loss": -94.57637672424316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.83203363418579, "step": 126000}
{"episode_reward": 988.8998775680648, "episode": 127.0, "batch_reward": 0.9238707413077354, "critic_loss": 1.710472054541111, "actor_loss": -94.70740901184082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.722975254058838, "step": 127000}
{"episode_reward": 911.5977447448045, "episode": 128.0, "batch_reward": 0.9244314176440239, "critic_loss": 1.6742086911797522, "actor_loss": -95.00253561401367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.319931507110596, "step": 128000}
{"episode_reward": 964.6783282253657, "episode": 129.0, "batch_reward": 0.9250033194422722, "critic_loss": 1.5840122101902963, "actor_loss": -94.85046488952636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.926226377487183, "step": 129000}
{"episode_reward": 958.470112192084, "episode": 130.0, "batch_reward": 0.9263235445618629, "critic_loss": 1.6572133051753044, "actor_loss": -94.87389408874512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.250119924545288, "step": 130000}
{"episode_reward": 990.7884230093063, "episode": 131.0, "batch_reward": 0.9262928177714348, "critic_loss": 1.5671154255867004, "actor_loss": -94.92272096252441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.494298219680786, "step": 131000}
{"episode_reward": 915.2077545170167, "episode": 132.0, "batch_reward": 0.9262611091136932, "critic_loss": 1.6055373391211032, "actor_loss": -94.94343922424316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.977198123931885, "step": 132000}
{"episode_reward": 983.2886052352537, "episode": 133.0, "batch_reward": 0.9260522760152817, "critic_loss": 1.6628999718129636, "actor_loss": -94.92452198791504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.722330570220947, "step": 133000}
{"episode_reward": 956.093788346258, "episode": 134.0, "batch_reward": 0.9258813951611519, "critic_loss": 1.6276025341749192, "actor_loss": -94.96772187805176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.34034752845764, "step": 134000}
{"episode_reward": 941.369506422084, "episode": 135.0, "batch_reward": 0.9282745261192322, "critic_loss": 1.7235770295262336, "actor_loss": -94.99341764831543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.643823385238647, "step": 135000}
{"episode_reward": 979.1402770654898, "episode": 136.0, "batch_reward": 0.9266870778799057, "critic_loss": 1.6519726581275462, "actor_loss": -95.13784181213379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.7350013256073, "step": 136000}
{"episode_reward": 989.3476732348971, "episode": 137.0, "batch_reward": 0.9266777023077011, "critic_loss": 1.719097583204508, "actor_loss": -95.01025357055664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.756349086761475, "step": 137000}
{"episode_reward": 943.2183749124245, "episode": 138.0, "batch_reward": 0.9279468851685524, "critic_loss": 1.8249675392508506, "actor_loss": -94.79266203308106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.34423828125, "step": 138000}
{"episode_reward": 958.2124344691647, "episode": 139.0, "batch_reward": 0.9274943832755089, "critic_loss": 1.8063668116629124, "actor_loss": -94.88816491699218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.889312982559204, "step": 139000}
{"episode_reward": 966.4950217745401, "episode": 140.0, "batch_reward": 0.9279130405187607, "critic_loss": 1.6797093759179116, "actor_loss": -94.81714045715331, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.862679958343506, "step": 140000}
{"episode_reward": 942.3414238362317, "episode": 141.0, "batch_reward": 0.9287316710352898, "critic_loss": 1.6629199693202972, "actor_loss": -94.96696771240235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.542073488235474, "step": 141000}
{"episode_reward": 964.0901208761777, "episode": 142.0, "batch_reward": 0.9293128591179848, "critic_loss": 1.6083379461169243, "actor_loss": -94.97772270202637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.094037294387817, "step": 142000}
{"episode_reward": 986.6271807731629, "episode": 143.0, "batch_reward": 0.9295024335384369, "critic_loss": 1.5826330062747003, "actor_loss": -95.08608935546874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.135642290115356, "step": 143000}
{"episode_reward": 949.9465430884323, "episode": 144.0, "batch_reward": 0.9286370616555214, "critic_loss": 1.5875893393158913, "actor_loss": -95.04239295959472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.936022996902466, "step": 144000}
{"episode_reward": 905.6589326719378, "episode": 145.0, "batch_reward": 0.9295506296157837, "critic_loss": 1.6062294819056988, "actor_loss": -95.05398989868164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.339158296585083, "step": 145000}
{"episode_reward": 985.900252130498, "episode": 146.0, "batch_reward": 0.9297297538518906, "critic_loss": 1.6799054212868214, "actor_loss": -95.0353405456543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.878328561782837, "step": 146000}
{"episode_reward": 913.6053668302883, "episode": 147.0, "batch_reward": 0.9282415124177933, "critic_loss": 1.6358932549357414, "actor_loss": -95.13057200622559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.071961641311646, "step": 147000}
{"episode_reward": 870.9367041205417, "episode": 148.0, "batch_reward": 0.9296064901351929, "critic_loss": 1.73417565664649, "actor_loss": -95.02210639953613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.76314902305603, "step": 148000}
{"episode_reward": 990.2058705520413, "episode": 149.0, "batch_reward": 0.9290273470878601, "critic_loss": 1.7199792153835296, "actor_loss": -95.08202578735352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.83756136894226, "step": 149000}
{"episode_reward": 943.3885332396101, "episode": 150.0, "batch_reward": 0.928340679705143, "critic_loss": 1.6589010967314244, "actor_loss": -94.98121432495117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
