{"episode_reward": 0.0, "episode": 1.0, "duration": 20.468910217285156, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.780463695526123, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.4942186936393266, "critic_loss": 1.0450776847512295, "actor_loss": -87.86708801257319, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.42187690734863, "step": 3000}
{"episode_reward": 572.1215733937877, "episode": 4.0, "batch_reward": 0.5442222116589546, "critic_loss": 1.188545151412487, "actor_loss": -91.74470002746583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.187889575958252, "step": 4000}
{"episode_reward": 555.3802689218952, "episode": 5.0, "batch_reward": 0.5655681604743004, "critic_loss": 1.0348922674655914, "actor_loss": -92.88591447448731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20645833015442, "step": 5000}
{"episode_reward": 966.8791667129572, "episode": 6.0, "batch_reward": 0.6343718983530998, "critic_loss": 0.8779554649889469, "actor_loss": -93.11609735107422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.192436456680298, "step": 6000}
{"episode_reward": 931.2338725987429, "episode": 7.0, "batch_reward": 0.6703028589487076, "critic_loss": 1.40953610175848, "actor_loss": -92.68576489257812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.194983959197998, "step": 7000}
{"episode_reward": 834.350767014624, "episode": 8.0, "batch_reward": 0.6805919080376625, "critic_loss": 1.217678553134203, "actor_loss": -92.66159860229492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18868350982666, "step": 8000}
{"episode_reward": 626.3781791140768, "episode": 9.0, "batch_reward": 0.6776514232158661, "critic_loss": 1.129252156972885, "actor_loss": -92.38687632751464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.179391860961914, "step": 9000}
{"episode_reward": 771.573332022521, "episode": 10.0, "batch_reward": 0.6665233229398727, "critic_loss": 1.1272147590517998, "actor_loss": -91.82281283569336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19371008872986, "step": 10000}
{"episode_reward": 180.4698259952835, "episode": 11.0, "batch_reward": 0.6518872725367546, "critic_loss": 1.0324260351657868, "actor_loss": -90.99862351989746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.43395447731018, "step": 11000}
{"episode_reward": 964.2355655530307, "episode": 12.0, "batch_reward": 0.6685608018636704, "critic_loss": 0.9544250307679176, "actor_loss": -90.85728218078613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21001362800598, "step": 12000}
{"episode_reward": 690.625752907329, "episode": 13.0, "batch_reward": 0.6619249739646912, "critic_loss": 1.0607244536280631, "actor_loss": -90.24931095886231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.202834129333496, "step": 13000}
{"episode_reward": 647.5637710634994, "episode": 14.0, "batch_reward": 0.6615239634513855, "critic_loss": 0.9582482320070267, "actor_loss": -89.92094607543946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.22258424758911, "step": 14000}
{"episode_reward": 576.0562726360315, "episode": 15.0, "batch_reward": 0.6654871000647545, "critic_loss": 1.1027658490538597, "actor_loss": -89.49405528259277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.181845664978027, "step": 15000}
{"episode_reward": 811.7537724708843, "episode": 16.0, "batch_reward": 0.6766865903139114, "critic_loss": 1.2579311868548393, "actor_loss": -89.59955477905274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.158631563186646, "step": 16000}
{"episode_reward": 836.2071102829079, "episode": 17.0, "batch_reward": 0.68693871062994, "critic_loss": 1.2553159192800523, "actor_loss": -89.70733401489258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21104407310486, "step": 17000}
{"episode_reward": 904.9340061021143, "episode": 18.0, "batch_reward": 0.6998817937970161, "critic_loss": 1.0662806059718133, "actor_loss": -89.84729429626465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15533185005188, "step": 18000}
{"episode_reward": 900.1008109649414, "episode": 19.0, "batch_reward": 0.7144663076996803, "critic_loss": 0.9988527125716209, "actor_loss": -89.88750595092773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.13813281059265, "step": 19000}
{"episode_reward": 978.2501066342185, "episode": 20.0, "batch_reward": 0.7255864715576172, "critic_loss": 0.9755773728489876, "actor_loss": -90.18490881347657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.13387155532837, "step": 20000}
{"episode_reward": 923.6133770233093, "episode": 21.0, "batch_reward": 0.7362131624221802, "critic_loss": 0.9737209921479225, "actor_loss": -90.23257524108887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.29556965827942, "step": 21000}
{"episode_reward": 939.7616519916959, "episode": 22.0, "batch_reward": 0.7470445742607117, "critic_loss": 0.9766469784975051, "actor_loss": -90.03412438964844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.169678688049316, "step": 22000}
{"episode_reward": 972.2229699066061, "episode": 23.0, "batch_reward": 0.7553563569784164, "critic_loss": 0.9479293897151947, "actor_loss": -90.11770550537109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.184643983840942, "step": 23000}
{"episode_reward": 925.8589166599453, "episode": 24.0, "batch_reward": 0.7629955774545669, "critic_loss": 0.9434880042374134, "actor_loss": -90.4531895904541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.167295455932617, "step": 24000}
{"episode_reward": 958.3076096772927, "episode": 25.0, "batch_reward": 0.770214810013771, "critic_loss": 0.974458159506321, "actor_loss": -90.46157116699219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20354723930359, "step": 25000}
{"episode_reward": 950.855254259723, "episode": 26.0, "batch_reward": 0.7775670852065086, "critic_loss": 0.9452829522192479, "actor_loss": -90.69900108337403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.168262481689453, "step": 26000}
{"episode_reward": 974.4080327617578, "episode": 27.0, "batch_reward": 0.7864083940386772, "critic_loss": 0.9350731344521046, "actor_loss": -91.02890615844727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17539143562317, "step": 27000}
{"episode_reward": 984.6543000657708, "episode": 28.0, "batch_reward": 0.7941175653934479, "critic_loss": 0.9137716370522976, "actor_loss": -91.07734407043458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.195841312408447, "step": 28000}
{"episode_reward": 929.3134793221079, "episode": 29.0, "batch_reward": 0.7943315316438675, "critic_loss": 1.0277484799027443, "actor_loss": -91.18845753479003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.149898529052734, "step": 29000}
{"episode_reward": 841.1691053680707, "episode": 30.0, "batch_reward": 0.7958700405955315, "critic_loss": 0.9877889811694622, "actor_loss": -91.10595135498046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.141387939453125, "step": 30000}
{"episode_reward": 815.6453867462519, "episode": 31.0, "batch_reward": 0.79828215944767, "critic_loss": 0.9581980411112309, "actor_loss": -91.19918106079102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.356324911117554, "step": 31000}
{"episode_reward": 949.5592047962084, "episode": 32.0, "batch_reward": 0.8017323903441429, "critic_loss": 0.9900589989423751, "actor_loss": -91.25678826904297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.192845821380615, "step": 32000}
{"episode_reward": 850.0271011297207, "episode": 33.0, "batch_reward": 0.8036629699468613, "critic_loss": 0.9606577835679054, "actor_loss": -91.2946944732666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20046305656433, "step": 33000}
{"episode_reward": 929.2858957695286, "episode": 34.0, "batch_reward": 0.8073716470003128, "critic_loss": 0.9279845854640008, "actor_loss": -91.09619941711426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.198166131973267, "step": 34000}
{"episode_reward": 927.8610714669683, "episode": 35.0, "batch_reward": 0.8115964320302009, "critic_loss": 0.8795907536745071, "actor_loss": -91.39755223083496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19339895248413, "step": 35000}
{"episode_reward": 934.8448233467136, "episode": 36.0, "batch_reward": 0.8132172489762306, "critic_loss": 0.8660687055885792, "actor_loss": -91.17517831420898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.128530979156494, "step": 36000}
{"episode_reward": 918.0657739764978, "episode": 37.0, "batch_reward": 0.8175454671382905, "critic_loss": 0.8218640505075455, "actor_loss": -91.30143719482422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15606951713562, "step": 37000}
{"episode_reward": 960.3306836297909, "episode": 38.0, "batch_reward": 0.8235838983654976, "critic_loss": 0.8035722469985485, "actor_loss": -91.47770738220215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.197304248809814, "step": 38000}
{"episode_reward": 985.4303017644327, "episode": 39.0, "batch_reward": 0.8258812393546104, "critic_loss": 0.8064941591620445, "actor_loss": -91.73366304016113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.160179138183594, "step": 39000}
{"episode_reward": 966.1748455970472, "episode": 40.0, "batch_reward": 0.8310771683454513, "critic_loss": 0.8297379767596722, "actor_loss": -91.83963619995117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.165097951889038, "step": 40000}
{"episode_reward": 981.0412814786162, "episode": 41.0, "batch_reward": 0.8325582754611969, "critic_loss": 0.8243690924346447, "actor_loss": -91.87462173461914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.39049410820007, "step": 41000}
{"episode_reward": 916.5166500341196, "episode": 42.0, "batch_reward": 0.8376076582670212, "critic_loss": 0.8025224254429341, "actor_loss": -91.96308265686035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.113763570785522, "step": 42000}
{"episode_reward": 966.8305490691077, "episode": 43.0, "batch_reward": 0.8387926065921784, "critic_loss": 0.7851766161322594, "actor_loss": -92.06845948791504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.179660320281982, "step": 43000}
{"episode_reward": 927.166520813159, "episode": 44.0, "batch_reward": 0.8412396050691605, "critic_loss": 0.7725220826268197, "actor_loss": -91.99695448303223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.208834886550903, "step": 44000}
{"episode_reward": 976.7431194033823, "episode": 45.0, "batch_reward": 0.8437856740355492, "critic_loss": 0.6985380330979825, "actor_loss": -92.31095011901856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.187653064727783, "step": 45000}
{"episode_reward": 946.819765923951, "episode": 46.0, "batch_reward": 0.8451041721701622, "critic_loss": 0.7319170226156712, "actor_loss": -92.29716200256348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.187150955200195, "step": 46000}
{"episode_reward": 964.6250898907725, "episode": 47.0, "batch_reward": 0.8501971531510353, "critic_loss": 0.7021813440620899, "actor_loss": -92.36319313049316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.189049243927002, "step": 47000}
{"episode_reward": 969.8558763447829, "episode": 48.0, "batch_reward": 0.8504598416090011, "critic_loss": 0.7018447294235229, "actor_loss": -92.42664212036132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.219929218292236, "step": 48000}
{"episode_reward": 939.0540481424573, "episode": 49.0, "batch_reward": 0.8538486193418503, "critic_loss": 0.6886661639213562, "actor_loss": -92.66748217773437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19840097427368, "step": 49000}
{"episode_reward": 948.4345810329698, "episode": 50.0, "batch_reward": 0.8568243378996849, "critic_loss": 0.6262092545330524, "actor_loss": -92.63807717895507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.203162670135498, "step": 50000}
{"episode_reward": 979.6317598702701, "episode": 51.0, "batch_reward": 0.8586066004633903, "critic_loss": 0.662071172684431, "actor_loss": -92.60853421020508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.44437575340271, "step": 51000}
{"episode_reward": 947.8661100537863, "episode": 52.0, "batch_reward": 0.8580406952500343, "critic_loss": 0.6768027327060699, "actor_loss": -92.82361602783203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.146536827087402, "step": 52000}
{"episode_reward": 913.6556424811031, "episode": 53.0, "batch_reward": 0.8597298270463943, "critic_loss": 0.7331051971018314, "actor_loss": -92.7480511932373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15700078010559, "step": 53000}
{"episode_reward": 880.8756934142613, "episode": 54.0, "batch_reward": 0.8588653664588928, "critic_loss": 0.7416013386249543, "actor_loss": -92.85533430480957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18363642692566, "step": 54000}
{"episode_reward": 883.2906923374073, "episode": 55.0, "batch_reward": 0.8600480041503906, "critic_loss": 0.7509986923038959, "actor_loss": -92.76263528442382, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17608618736267, "step": 55000}
{"episode_reward": 944.6816347256074, "episode": 56.0, "batch_reward": 0.8628906903862953, "critic_loss": 0.7643215382397175, "actor_loss": -93.0038938293457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19705295562744, "step": 56000}
{"episode_reward": 975.6686789502132, "episode": 57.0, "batch_reward": 0.8652602130174637, "critic_loss": 0.7463058900237084, "actor_loss": -92.87662063598633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20704197883606, "step": 57000}
{"episode_reward": 962.145285048288, "episode": 58.0, "batch_reward": 0.866677965760231, "critic_loss": 0.7672239196598529, "actor_loss": -92.88437480163574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21124029159546, "step": 58000}
{"episode_reward": 983.0453613115288, "episode": 59.0, "batch_reward": 0.8699670050144196, "critic_loss": 0.7808900900483131, "actor_loss": -92.96434672546387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20000910758972, "step": 59000}
{"episode_reward": 960.3204711985436, "episode": 60.0, "batch_reward": 0.8699756289720535, "critic_loss": 0.7926074329316616, "actor_loss": -93.143174118042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18688416481018, "step": 60000}
{"episode_reward": 945.416985976187, "episode": 61.0, "batch_reward": 0.871544887304306, "critic_loss": 0.735924930036068, "actor_loss": -93.03865823364258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.4216582775116, "step": 61000}
{"episode_reward": 953.2765923258073, "episode": 62.0, "batch_reward": 0.8719753934144974, "critic_loss": 0.7177844536751509, "actor_loss": -93.04283396911622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.150442838668823, "step": 62000}
{"episode_reward": 968.5467119207565, "episode": 63.0, "batch_reward": 0.8730520613193512, "critic_loss": 0.7325010385960341, "actor_loss": -93.06292854309082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.198139190673828, "step": 63000}
{"episode_reward": 919.0762076378479, "episode": 64.0, "batch_reward": 0.8750052258372307, "critic_loss": 0.7108667487204074, "actor_loss": -93.22117251586914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.191489219665527, "step": 64000}
{"episode_reward": 987.626191184676, "episode": 65.0, "batch_reward": 0.8777054821252823, "critic_loss": 0.70564609888196, "actor_loss": -93.25481336975098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20985245704651, "step": 65000}
{"episode_reward": 966.3041578068346, "episode": 66.0, "batch_reward": 0.8770760930776597, "critic_loss": 0.7327089249789714, "actor_loss": -93.37629913330078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.215928077697754, "step": 66000}
{"episode_reward": 950.4832086579917, "episode": 67.0, "batch_reward": 0.8782640889883041, "critic_loss": 0.7251065055429935, "actor_loss": -93.4950853881836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.204129934310913, "step": 67000}
{"episode_reward": 927.1537373529715, "episode": 68.0, "batch_reward": 0.8789635223746299, "critic_loss": 0.6760271659195423, "actor_loss": -93.33678970336913, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.240483283996582, "step": 68000}
{"episode_reward": 955.1612499648342, "episode": 69.0, "batch_reward": 0.88178001755476, "critic_loss": 0.6591741209924221, "actor_loss": -93.54766543579102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.22040867805481, "step": 69000}
{"episode_reward": 983.5624589189207, "episode": 70.0, "batch_reward": 0.8820649121403694, "critic_loss": 0.6831334833949805, "actor_loss": -93.61287915039063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.207095861434937, "step": 70000}
{"episode_reward": 930.3456214646543, "episode": 71.0, "batch_reward": 0.8828804063796997, "critic_loss": 0.6145526306629181, "actor_loss": -93.52945596313477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.398070335388184, "step": 71000}
{"episode_reward": 927.3091889653896, "episode": 72.0, "batch_reward": 0.8837312435507775, "critic_loss": 0.5642398018240928, "actor_loss": -93.6145168914795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.157232999801636, "step": 72000}
{"episode_reward": 970.8210963107545, "episode": 73.0, "batch_reward": 0.8831585797071457, "critic_loss": 0.6030867031514645, "actor_loss": -93.67762638854981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.178913116455078, "step": 73000}
{"episode_reward": 928.3399934594429, "episode": 74.0, "batch_reward": 0.8870638112425804, "critic_loss": 0.5991138449758291, "actor_loss": -93.8864659576416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.169137716293335, "step": 74000}
{"episode_reward": 951.5738990532316, "episode": 75.0, "batch_reward": 0.8862218601107598, "critic_loss": 0.6380824445784092, "actor_loss": -93.85263731384278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18772840499878, "step": 75000}
{"episode_reward": 969.9378815171474, "episode": 76.0, "batch_reward": 0.8878072671890259, "critic_loss": 0.6023292513489723, "actor_loss": -93.85385852050781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14582371711731, "step": 76000}
{"episode_reward": 958.0027607514194, "episode": 77.0, "batch_reward": 0.8875863772630691, "critic_loss": 0.5823836263865233, "actor_loss": -93.83319596862793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.161388635635376, "step": 77000}
{"episode_reward": 969.8366960770387, "episode": 78.0, "batch_reward": 0.8893227813839912, "critic_loss": 0.5586225820183754, "actor_loss": -93.95650077819825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.181783437728882, "step": 78000}
{"episode_reward": 922.2229825168895, "episode": 79.0, "batch_reward": 0.889273920238018, "critic_loss": 0.5588277519345284, "actor_loss": -93.82166192626953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21589493751526, "step": 79000}
{"episode_reward": 962.4694145941246, "episode": 80.0, "batch_reward": 0.8897172815203667, "critic_loss": 0.568374803930521, "actor_loss": -93.90916424560547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19717836380005, "step": 80000}
{"episode_reward": 962.9267765195171, "episode": 81.0, "batch_reward": 0.8905257960557937, "critic_loss": 0.5813603667020798, "actor_loss": -94.00736671447754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.40425443649292, "step": 81000}
{"episode_reward": 904.9083259488665, "episode": 82.0, "batch_reward": 0.8918938770294189, "critic_loss": 0.600739337772131, "actor_loss": -94.13382925415038, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.189584255218506, "step": 82000}
{"episode_reward": 948.6601103704303, "episode": 83.0, "batch_reward": 0.8923710125088692, "critic_loss": 0.578267944931984, "actor_loss": -94.06690542602539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.212260961532593, "step": 83000}
{"episode_reward": 896.0985442670342, "episode": 84.0, "batch_reward": 0.8933678110241889, "critic_loss": 0.6296668898761273, "actor_loss": -94.21691407775879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.174840927124023, "step": 84000}
{"episode_reward": 987.4622128880964, "episode": 85.0, "batch_reward": 0.8922835496068001, "critic_loss": 0.5584261824786663, "actor_loss": -94.10380636596679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.190467596054077, "step": 85000}
{"episode_reward": 959.694125200092, "episode": 86.0, "batch_reward": 0.8945089631080627, "critic_loss": 0.5812480401098729, "actor_loss": -94.04462428283692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.185202836990356, "step": 86000}
{"episode_reward": 955.9623520529358, "episode": 87.0, "batch_reward": 0.8950225595235825, "critic_loss": 0.622629070803523, "actor_loss": -94.19596243286132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20736265182495, "step": 87000}
{"episode_reward": 938.8300512355215, "episode": 88.0, "batch_reward": 0.8949538558125496, "critic_loss": 0.5923040050417184, "actor_loss": -94.12781394958496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20332622528076, "step": 88000}
{"episode_reward": 909.8399978933226, "episode": 89.0, "batch_reward": 0.8952080843448639, "critic_loss": 0.537422160372138, "actor_loss": -94.1299648590088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.198471307754517, "step": 89000}
{"episode_reward": 988.7261496829947, "episode": 90.0, "batch_reward": 0.8964822505712509, "critic_loss": 0.5935635998547077, "actor_loss": -94.29358763122559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.215060234069824, "step": 90000}
{"episode_reward": 950.4753626273866, "episode": 91.0, "batch_reward": 0.8974481332302093, "critic_loss": 0.5466167930215597, "actor_loss": -94.134939163208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.40377235412598, "step": 91000}
{"episode_reward": 950.3064941580736, "episode": 92.0, "batch_reward": 0.8996977229714394, "critic_loss": 0.5447851399183273, "actor_loss": -94.35472465515137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.161789894104004, "step": 92000}
{"episode_reward": 947.509670450297, "episode": 93.0, "batch_reward": 0.8976716320514679, "critic_loss": 0.5838089285045862, "actor_loss": -94.27837510681152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14592933654785, "step": 93000}
{"episode_reward": 979.374914229581, "episode": 94.0, "batch_reward": 0.898543363571167, "critic_loss": 0.5785486401468516, "actor_loss": -94.37804214477539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.162372589111328, "step": 94000}
{"episode_reward": 947.654784770329, "episode": 95.0, "batch_reward": 0.8998484950065613, "critic_loss": 0.5397646034657955, "actor_loss": -94.40955978393555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.11907720565796, "step": 95000}
{"episode_reward": 958.0879536721618, "episode": 96.0, "batch_reward": 0.8997122339010238, "critic_loss": 0.5482579348534345, "actor_loss": -94.42972477722168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.165740728378296, "step": 96000}
{"episode_reward": 951.2272669625405, "episode": 97.0, "batch_reward": 0.9002419456243514, "critic_loss": 0.548372112467885, "actor_loss": -94.4584376220703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.12596368789673, "step": 97000}
{"episode_reward": 912.4293042406646, "episode": 98.0, "batch_reward": 0.9014832949042321, "critic_loss": 0.5731350969076157, "actor_loss": -94.42758149719238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17398166656494, "step": 98000}
{"episode_reward": 907.5220735751693, "episode": 99.0, "batch_reward": 0.9008050534129143, "critic_loss": 0.5515380766838789, "actor_loss": -94.43472451782226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19583296775818, "step": 99000}
{"episode_reward": 926.168672254968, "episode": 100.0, "batch_reward": 0.9026575903892518, "critic_loss": 0.5843053758293391, "actor_loss": -94.47799696350097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.198607444763184, "step": 100000}
{"episode_reward": 908.8723544918182, "episode": 101.0, "batch_reward": 0.9024765110611915, "critic_loss": 0.5943754627108574, "actor_loss": -94.4954156036377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.42877912521362, "step": 101000}
{"episode_reward": 990.3397023120932, "episode": 102.0, "batch_reward": 0.9003915299773216, "critic_loss": 0.6268945149630308, "actor_loss": -94.43193159484863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.205899715423584, "step": 102000}
{"episode_reward": 942.6807540972048, "episode": 103.0, "batch_reward": 0.9017621564865113, "critic_loss": 0.545102308690548, "actor_loss": -94.45520127868653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21116304397583, "step": 103000}
{"episode_reward": 961.4718744457698, "episode": 104.0, "batch_reward": 0.9049194228053093, "critic_loss": 0.5583732045292854, "actor_loss": -94.57953665161133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.210843563079834, "step": 104000}
{"episode_reward": 959.1812788369045, "episode": 105.0, "batch_reward": 0.9051253478527069, "critic_loss": 0.5476784708797932, "actor_loss": -94.60878048706054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18479299545288, "step": 105000}
{"episode_reward": 934.3695410896189, "episode": 106.0, "batch_reward": 0.9047450460195542, "critic_loss": 0.587157525062561, "actor_loss": -94.59231477355956, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.168216705322266, "step": 106000}
{"episode_reward": 929.5324501920777, "episode": 107.0, "batch_reward": 0.9046120741963386, "critic_loss": 0.5541468079537153, "actor_loss": -94.51227435302734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.186251401901245, "step": 107000}
{"episode_reward": 955.8255936801505, "episode": 108.0, "batch_reward": 0.9056049165129662, "critic_loss": 0.5659661073833704, "actor_loss": -94.66647068786621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.216289281845093, "step": 108000}
{"episode_reward": 928.3335050941539, "episode": 109.0, "batch_reward": 0.9044009938836097, "critic_loss": 0.6024794250875711, "actor_loss": -94.69060577392578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.201959133148193, "step": 109000}
{"episode_reward": 922.2650626071224, "episode": 110.0, "batch_reward": 0.9059389929175377, "critic_loss": 0.6132263787537813, "actor_loss": -94.62497557067871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18739342689514, "step": 110000}
{"episode_reward": 970.2879445905664, "episode": 111.0, "batch_reward": 0.9054073486328125, "critic_loss": 0.619667365461588, "actor_loss": -94.71722735595704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.3985857963562, "step": 111000}
{"episode_reward": 952.6586817720232, "episode": 112.0, "batch_reward": 0.905714722931385, "critic_loss": 0.6147418193370103, "actor_loss": -94.68061735534668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.165396690368652, "step": 112000}
{"episode_reward": 935.7528628671338, "episode": 113.0, "batch_reward": 0.9077597665786743, "critic_loss": 0.5989921085983515, "actor_loss": -94.68804301452637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20899224281311, "step": 113000}
{"episode_reward": 962.4562786865965, "episode": 114.0, "batch_reward": 0.9069935712218284, "critic_loss": 0.5783963528871536, "actor_loss": -94.79781687927246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.185797691345215, "step": 114000}
{"episode_reward": 978.1401977517733, "episode": 115.0, "batch_reward": 0.9074883086681366, "critic_loss": 0.6341997817307711, "actor_loss": -94.73929684448242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.152508974075317, "step": 115000}
{"episode_reward": 900.9617838869651, "episode": 116.0, "batch_reward": 0.9079104412198067, "critic_loss": 0.6098834366798401, "actor_loss": -94.87759390258789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19596529006958, "step": 116000}
{"episode_reward": 958.7933836453668, "episode": 117.0, "batch_reward": 0.9072905298471451, "critic_loss": 0.6273376813232898, "actor_loss": -94.72855059814454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.196885585784912, "step": 117000}
{"episode_reward": 936.1359806175163, "episode": 118.0, "batch_reward": 0.9079678531885147, "critic_loss": 0.5882872063219547, "actor_loss": -94.84225679016113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.212462902069092, "step": 118000}
{"episode_reward": 982.9485223750322, "episode": 119.0, "batch_reward": 0.908802325129509, "critic_loss": 0.6071743712127209, "actor_loss": -94.90203486633301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20753788948059, "step": 119000}
{"episode_reward": 920.7925269146815, "episode": 120.0, "batch_reward": 0.9086147609353066, "critic_loss": 0.5928445932865143, "actor_loss": -94.77365592956544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.187989950180054, "step": 120000}
{"episode_reward": 954.5477586741266, "episode": 121.0, "batch_reward": 0.9094641178846359, "critic_loss": 0.6140955276489258, "actor_loss": -94.79753875732422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.37739372253418, "step": 121000}
{"episode_reward": 971.9925866347501, "episode": 122.0, "batch_reward": 0.9096830229759216, "critic_loss": 0.6405032130181789, "actor_loss": -94.83987135314942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18570375442505, "step": 122000}
{"episode_reward": 885.8055817518529, "episode": 123.0, "batch_reward": 0.9102182046175004, "critic_loss": 0.6043328583240509, "actor_loss": -94.7236713104248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17676591873169, "step": 123000}
{"episode_reward": 952.2897903062346, "episode": 124.0, "batch_reward": 0.9109444161057472, "critic_loss": 0.6080462938994169, "actor_loss": -94.82404989624024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.162912130355835, "step": 124000}
{"episode_reward": 988.6100705166475, "episode": 125.0, "batch_reward": 0.9110467795133591, "critic_loss": 0.6032683620601893, "actor_loss": -94.85422653198242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.187912464141846, "step": 125000}
{"episode_reward": 988.8414139086887, "episode": 126.0, "batch_reward": 0.9117931951284408, "critic_loss": 0.6490510539710521, "actor_loss": -94.97899240112305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21224284172058, "step": 126000}
{"episode_reward": 991.8503898101909, "episode": 127.0, "batch_reward": 0.9109513577818871, "critic_loss": 0.625948347941041, "actor_loss": -94.9007587890625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21766471862793, "step": 127000}
{"episode_reward": 896.2438973829187, "episode": 128.0, "batch_reward": 0.9108036476969719, "critic_loss": 0.5840197286456823, "actor_loss": -94.9455756225586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.201002836227417, "step": 128000}
{"episode_reward": 971.6621067535921, "episode": 129.0, "batch_reward": 0.9121925554871559, "critic_loss": 0.611161905542016, "actor_loss": -95.01804023742676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.409932851791382, "step": 129000}
{"episode_reward": 985.102977976265, "episode": 130.0, "batch_reward": 0.9138725994825363, "critic_loss": 0.5955483859181404, "actor_loss": -95.05634153747559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30235528945923, "step": 130000}
{"episode_reward": 990.7164566528196, "episode": 131.0, "batch_reward": 0.9142377920746804, "critic_loss": 0.5986955799162388, "actor_loss": -95.044193359375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.37162637710571, "step": 131000}
{"episode_reward": 910.1458571112126, "episode": 132.0, "batch_reward": 0.913235246360302, "critic_loss": 0.5763017744272947, "actor_loss": -95.01230982971191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.200048208236694, "step": 132000}
{"episode_reward": 980.7862256600276, "episode": 133.0, "batch_reward": 0.9129100520610809, "critic_loss": 0.5999056647121906, "actor_loss": -95.00422937011719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.213767766952515, "step": 133000}
{"episode_reward": 958.9821776031074, "episode": 134.0, "batch_reward": 0.913505990922451, "critic_loss": 0.5740436276495456, "actor_loss": -95.0459695739746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.497775554656982, "step": 134000}
{"episode_reward": 940.9484876421725, "episode": 135.0, "batch_reward": 0.9158475629687309, "critic_loss": 0.5704876890182495, "actor_loss": -95.09806169128419, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.22055721282959, "step": 135000}
{"episode_reward": 991.2979560246011, "episode": 136.0, "batch_reward": 0.9156788346767426, "critic_loss": 0.621815581008792, "actor_loss": -95.16950813293457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.162110328674316, "step": 136000}
{"episode_reward": 986.55089456255, "episode": 137.0, "batch_reward": 0.915624377131462, "critic_loss": 0.6546808132231235, "actor_loss": -95.0926095123291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.193959951400757, "step": 137000}
{"episode_reward": 975.0120725814797, "episode": 138.0, "batch_reward": 0.916454089820385, "critic_loss": 0.644841257378459, "actor_loss": -95.0522921295166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.236092805862427, "step": 138000}
{"episode_reward": 957.0638843446178, "episode": 139.0, "batch_reward": 0.9164199746251106, "critic_loss": 0.6314988308399916, "actor_loss": -95.10226742553711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.207212448120117, "step": 139000}
{"episode_reward": 989.1248590499861, "episode": 140.0, "batch_reward": 0.9167017335295677, "critic_loss": 0.6023822706788778, "actor_loss": -95.09540316772461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.217411041259766, "step": 140000}
{"episode_reward": 956.4539578028987, "episode": 141.0, "batch_reward": 0.9169957611560822, "critic_loss": 0.6090340477377176, "actor_loss": -95.11543640136719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.42862057685852, "step": 141000}
{"episode_reward": 963.7412246753829, "episode": 142.0, "batch_reward": 0.9173328449726105, "critic_loss": 0.6134054156243801, "actor_loss": -95.17191513061523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.213046550750732, "step": 142000}
{"episode_reward": 988.8156606043004, "episode": 143.0, "batch_reward": 0.9179241608977318, "critic_loss": 0.6015633157640695, "actor_loss": -95.19909428405762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18617820739746, "step": 143000}
{"episode_reward": 945.8285495739115, "episode": 144.0, "batch_reward": 0.9179609231352807, "critic_loss": 0.5927733809351922, "actor_loss": -95.24886158752442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.202528476715088, "step": 144000}
{"episode_reward": 956.482849702611, "episode": 145.0, "batch_reward": 0.9194040544033051, "critic_loss": 0.5725782108902931, "actor_loss": -95.26649539184571, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.230786323547363, "step": 145000}
{"episode_reward": 988.468822332453, "episode": 146.0, "batch_reward": 0.9189479902982712, "critic_loss": 0.5730989943593741, "actor_loss": -95.34931761169433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.202649354934692, "step": 146000}
{"episode_reward": 963.4668456034822, "episode": 147.0, "batch_reward": 0.9195804815888405, "critic_loss": 0.5834269150644541, "actor_loss": -95.33975172424316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.193211793899536, "step": 147000}
{"episode_reward": 957.0062302238177, "episode": 148.0, "batch_reward": 0.920185451745987, "critic_loss": 0.5557432633936406, "actor_loss": -95.34300689697265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.517056703567505, "step": 148000}
{"episode_reward": 983.1987565901859, "episode": 149.0, "batch_reward": 0.9192474744915963, "critic_loss": 0.5788487809300422, "actor_loss": -95.30767315673828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20615029335022, "step": 149000}
{"episode_reward": 906.4009627630303, "episode": 150.0, "batch_reward": 0.9199182773828507, "critic_loss": 0.5861546241343022, "actor_loss": -95.39394354248047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
