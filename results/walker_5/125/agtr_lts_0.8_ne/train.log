{"episode_reward": 0.0, "episode": 1.0, "duration": 20.421339511871338, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.7766516208648682, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.4972461937625792, "critic_loss": 1.0644300663896544, "actor_loss": -85.93538789417134, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.61402487754822, "step": 3000}
{"episode_reward": 816.8997523141409, "episode": 4.0, "batch_reward": 0.6225610699653625, "critic_loss": 1.2930970248579978, "actor_loss": -88.89321739196777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.975531578063965, "step": 4000}
{"episode_reward": 837.1136074897521, "episode": 5.0, "batch_reward": 0.6791797521710395, "critic_loss": 0.929959599673748, "actor_loss": -90.04122326660156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.998998165130615, "step": 5000}
{"episode_reward": 951.6732549101441, "episode": 6.0, "batch_reward": 0.7308381243944168, "critic_loss": 0.9328663727045059, "actor_loss": -91.06720072937011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.998320817947388, "step": 6000}
{"episode_reward": 974.5477008666744, "episode": 7.0, "batch_reward": 0.7656002539992333, "critic_loss": 0.9012630044221878, "actor_loss": -91.79173301696777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.962870121002197, "step": 7000}
{"episode_reward": 948.8065497559397, "episode": 8.0, "batch_reward": 0.7924358343482018, "critic_loss": 0.8664725054800511, "actor_loss": -92.35711369323731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.966195106506348, "step": 8000}
{"episode_reward": 958.1373610931165, "episode": 9.0, "batch_reward": 0.8079530294537545, "critic_loss": 0.7459331134557724, "actor_loss": -92.72244674682617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92338514328003, "step": 9000}
{"episode_reward": 942.2105786188168, "episode": 10.0, "batch_reward": 0.8206231164336204, "critic_loss": 0.6679410016536713, "actor_loss": -92.95103799438476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.954293489456177, "step": 10000}
{"episode_reward": 896.8598317498323, "episode": 11.0, "batch_reward": 0.8302215337157249, "critic_loss": 0.6021920521855354, "actor_loss": -93.05282678222656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.20335268974304, "step": 11000}
{"episode_reward": 950.5315208795496, "episode": 12.0, "batch_reward": 0.8335968779325486, "critic_loss": 0.5908039426207542, "actor_loss": -93.06064347839356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.992618560791016, "step": 12000}
{"episode_reward": 880.0218475780723, "episode": 13.0, "batch_reward": 0.8387369498610496, "critic_loss": 0.6425458990037441, "actor_loss": -93.20268222045898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00381565093994, "step": 13000}
{"episode_reward": 810.441111103147, "episode": 14.0, "batch_reward": 0.8444039530158043, "critic_loss": 0.63532365077734, "actor_loss": -93.13104930114746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00749158859253, "step": 14000}
{"episode_reward": 985.4588644374452, "episode": 15.0, "batch_reward": 0.854948060452938, "critic_loss": 0.7136787623763085, "actor_loss": -93.47271778869629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993959665298462, "step": 15000}
{"episode_reward": 984.3220675407514, "episode": 16.0, "batch_reward": 0.8604291341900826, "critic_loss": 0.8077266739308834, "actor_loss": -93.3584171295166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9878191947937, "step": 16000}
{"episode_reward": 898.516140081499, "episode": 17.0, "batch_reward": 0.8586409721970558, "critic_loss": 0.9249420450031758, "actor_loss": -93.34101647949218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.975765228271484, "step": 17000}
{"episode_reward": 871.9268678748184, "episode": 18.0, "batch_reward": 0.857216327548027, "critic_loss": 1.134902487397194, "actor_loss": -93.15626048278808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.973380088806152, "step": 18000}
{"episode_reward": 764.9859655682928, "episode": 19.0, "batch_reward": 0.8600338333845139, "critic_loss": 1.0842534925341607, "actor_loss": -93.01580354309083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.978142023086548, "step": 19000}
{"episode_reward": 973.3954985104723, "episode": 20.0, "batch_reward": 0.8653944506049156, "critic_loss": 0.9965788698792457, "actor_loss": -93.29217919921875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002477169036865, "step": 20000}
{"episode_reward": 962.0676149663138, "episode": 21.0, "batch_reward": 0.8685134765505791, "critic_loss": 0.9724157256484032, "actor_loss": -93.33398558044433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.202635765075684, "step": 21000}
{"episode_reward": 876.2394608819087, "episode": 22.0, "batch_reward": 0.8714329941868783, "critic_loss": 0.9258937831223011, "actor_loss": -93.34320741271972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01098608970642, "step": 22000}
{"episode_reward": 986.592613194132, "episode": 23.0, "batch_reward": 0.8725348801016808, "critic_loss": 0.8893373515307903, "actor_loss": -93.50766914367676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.021402835845947, "step": 23000}
{"episode_reward": 895.4030166049865, "episode": 24.0, "batch_reward": 0.8763500289320946, "critic_loss": 0.8518369852900505, "actor_loss": -93.53332124328614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00260281562805, "step": 24000}
{"episode_reward": 983.3693109536885, "episode": 25.0, "batch_reward": 0.874011991739273, "critic_loss": 1.011449854671955, "actor_loss": -93.27698155212403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999248027801514, "step": 25000}
{"episode_reward": 792.2041981886703, "episode": 26.0, "batch_reward": 0.8758738512992859, "critic_loss": 0.9565053450465202, "actor_loss": -93.51664781188965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.975348711013794, "step": 26000}
{"episode_reward": 974.1230805104648, "episode": 27.0, "batch_reward": 0.8819636318087578, "critic_loss": 0.9339541308283806, "actor_loss": -93.51604774475098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.971553564071655, "step": 27000}
{"episode_reward": 984.3351095712447, "episode": 28.0, "batch_reward": 0.8841609791517258, "critic_loss": 1.0003576532006264, "actor_loss": -93.48349812316894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990779161453247, "step": 28000}
{"episode_reward": 949.3511245089305, "episode": 29.0, "batch_reward": 0.8831089932918549, "critic_loss": 1.026387668788433, "actor_loss": -93.48129629516602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99239492416382, "step": 29000}
{"episode_reward": 828.6130286461421, "episode": 30.0, "batch_reward": 0.8848708905577659, "critic_loss": 1.0041499312222004, "actor_loss": -93.4775883026123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.016332387924194, "step": 30000}
{"episode_reward": 936.8945583181282, "episode": 31.0, "batch_reward": 0.8864102016687393, "critic_loss": 1.0877525995969772, "actor_loss": -93.5189054107666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.24061346054077, "step": 31000}
{"episode_reward": 954.8729181580865, "episode": 32.0, "batch_reward": 0.8885022935867309, "critic_loss": 1.007277739316225, "actor_loss": -93.45190968322754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999951124191284, "step": 32000}
{"episode_reward": 944.7016551334243, "episode": 33.0, "batch_reward": 0.8871082156300545, "critic_loss": 1.1335174949467182, "actor_loss": -93.61954342651367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01130986213684, "step": 33000}
{"episode_reward": 883.6099644911328, "episode": 34.0, "batch_reward": 0.8896958957314491, "critic_loss": 1.0126794793605804, "actor_loss": -93.47094958496093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02207851409912, "step": 34000}
{"episode_reward": 985.6659880277925, "episode": 35.0, "batch_reward": 0.8903863547444344, "critic_loss": 1.174343672990799, "actor_loss": -93.79914126586914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.012705326080322, "step": 35000}
{"episode_reward": 861.2244054992833, "episode": 36.0, "batch_reward": 0.8910082889795303, "critic_loss": 1.0686833764910697, "actor_loss": -93.5192271118164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99298095703125, "step": 36000}
{"episode_reward": 951.5265930618287, "episode": 37.0, "batch_reward": 0.8914549607038498, "critic_loss": 1.1218272947072983, "actor_loss": -93.75750595092774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.992716312408447, "step": 37000}
{"episode_reward": 956.6673651972192, "episode": 38.0, "batch_reward": 0.8950601692795753, "critic_loss": 1.134456409662962, "actor_loss": -93.78491268920898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988550662994385, "step": 38000}
{"episode_reward": 930.4778241432804, "episode": 39.0, "batch_reward": 0.894839106798172, "critic_loss": 1.1150748570561408, "actor_loss": -93.87323167419433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993855237960815, "step": 39000}
{"episode_reward": 958.5653624570797, "episode": 40.0, "batch_reward": 0.897894452571869, "critic_loss": 1.136568885475397, "actor_loss": -93.95503323364258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98727822303772, "step": 40000}
{"episode_reward": 987.5445356383004, "episode": 41.0, "batch_reward": 0.8981077795028687, "critic_loss": 1.1789402388632297, "actor_loss": -94.02070614624023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.23324775695801, "step": 41000}
{"episode_reward": 853.4450882637016, "episode": 42.0, "batch_reward": 0.8989843955039978, "critic_loss": 1.1207674997150898, "actor_loss": -93.83362478637696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.012595891952515, "step": 42000}
{"episode_reward": 962.9907834453553, "episode": 43.0, "batch_reward": 0.9006746839284897, "critic_loss": 1.1084682184755803, "actor_loss": -93.98583685302734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.991597175598145, "step": 43000}
{"episode_reward": 964.3575602958574, "episode": 44.0, "batch_reward": 0.901990361213684, "critic_loss": 1.0613888222277164, "actor_loss": -94.00135954284669, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.017534494400024, "step": 44000}
{"episode_reward": 955.7322392359233, "episode": 45.0, "batch_reward": 0.9027843863964081, "critic_loss": 1.0748828141391278, "actor_loss": -94.08529182434081, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00434160232544, "step": 45000}
{"episode_reward": 942.6644493054614, "episode": 46.0, "batch_reward": 0.9013076560497284, "critic_loss": 1.0440127052664756, "actor_loss": -94.05193647766113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.980957746505737, "step": 46000}
{"episode_reward": 868.0109863807693, "episode": 47.0, "batch_reward": 0.9034822206497193, "critic_loss": 0.9820509856343269, "actor_loss": -94.23857585144043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.972480535507202, "step": 47000}
{"episode_reward": 941.5055558049881, "episode": 48.0, "batch_reward": 0.9033339576721191, "critic_loss": 1.0065951447486878, "actor_loss": -94.19434994506835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.989519596099854, "step": 48000}
{"episode_reward": 947.186829564869, "episode": 49.0, "batch_reward": 0.9056562601327897, "critic_loss": 0.9321556527018547, "actor_loss": -94.43184320068359, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00376582145691, "step": 49000}
{"episode_reward": 951.7891904518855, "episode": 50.0, "batch_reward": 0.9065512432456017, "critic_loss": 0.8828672133386135, "actor_loss": -94.29555314636231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006919860839844, "step": 50000}
{"episode_reward": 971.0377086936498, "episode": 51.0, "batch_reward": 0.9072391368150711, "critic_loss": 0.8832525972127915, "actor_loss": -94.3076044921875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.22378945350647, "step": 51000}
{"episode_reward": 977.5724898472207, "episode": 52.0, "batch_reward": 0.9076731230616569, "critic_loss": 0.8501721133589745, "actor_loss": -94.33733468627929, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99095368385315, "step": 52000}
{"episode_reward": 941.3678128761227, "episode": 53.0, "batch_reward": 0.9090570403933526, "critic_loss": 0.856693784236908, "actor_loss": -94.45280137634278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.980156660079956, "step": 53000}
{"episode_reward": 935.9358970858207, "episode": 54.0, "batch_reward": 0.908363946378231, "critic_loss": 0.899918091326952, "actor_loss": -94.35374418640137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01200532913208, "step": 54000}
{"episode_reward": 881.9169086392023, "episode": 55.0, "batch_reward": 0.9094809917807579, "critic_loss": 0.8599624375402928, "actor_loss": -94.60770359802247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999097108840942, "step": 55000}
{"episode_reward": 974.5507897571595, "episode": 56.0, "batch_reward": 0.9112827909588814, "critic_loss": 0.8220805571079254, "actor_loss": -94.63866384887696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98096466064453, "step": 56000}
{"episode_reward": 984.6059820427547, "episode": 57.0, "batch_reward": 0.9126600639820099, "critic_loss": 0.86016477227211, "actor_loss": -94.47266952514649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.991777181625366, "step": 57000}
{"episode_reward": 958.7858564505584, "episode": 58.0, "batch_reward": 0.9126252704262734, "critic_loss": 0.8324409264326096, "actor_loss": -94.5305064239502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98554754257202, "step": 58000}
{"episode_reward": 981.2677281931204, "episode": 59.0, "batch_reward": 0.914755175113678, "critic_loss": 0.8130657211840153, "actor_loss": -94.6104778289795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99687910079956, "step": 59000}
{"episode_reward": 961.2009602236063, "episode": 60.0, "batch_reward": 0.9128716936111451, "critic_loss": 0.8833503632843495, "actor_loss": -94.60307601928712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.996222257614136, "step": 60000}
{"episode_reward": 888.8772239966607, "episode": 61.0, "batch_reward": 0.9132840912342072, "critic_loss": 0.8503035139739513, "actor_loss": -94.51478500366211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.21247124671936, "step": 61000}
{"episode_reward": 911.9198654434541, "episode": 62.0, "batch_reward": 0.9136592710614204, "critic_loss": 0.8312770544588566, "actor_loss": -94.77426878356934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98200559616089, "step": 62000}
{"episode_reward": 965.5821986697844, "episode": 63.0, "batch_reward": 0.9116902709007263, "critic_loss": 0.9093957468569279, "actor_loss": -94.61570191955566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.012802839279175, "step": 63000}
{"episode_reward": 836.478332412552, "episode": 64.0, "batch_reward": 0.9130462655425071, "critic_loss": 0.875315996825695, "actor_loss": -94.6962645111084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.035903692245483, "step": 64000}
{"episode_reward": 989.4449062456807, "episode": 65.0, "batch_reward": 0.9144094742536545, "critic_loss": 0.8520876016616822, "actor_loss": -94.69528326416015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99456214904785, "step": 65000}
{"episode_reward": 940.5811766195488, "episode": 66.0, "batch_reward": 0.9140245277881622, "critic_loss": 0.8889365776628256, "actor_loss": -94.7219457244873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.994848489761353, "step": 66000}
{"episode_reward": 914.9119525693264, "episode": 67.0, "batch_reward": 0.9124342608451843, "critic_loss": 0.8875676466673612, "actor_loss": -94.7276847076416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98429250717163, "step": 67000}
{"episode_reward": 861.4387021428755, "episode": 68.0, "batch_reward": 0.9134062027335167, "critic_loss": 0.8869302017688752, "actor_loss": -94.66429072570801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.008912086486816, "step": 68000}
{"episode_reward": 947.0850395754638, "episode": 69.0, "batch_reward": 0.9148295809626579, "critic_loss": 0.8801602041423321, "actor_loss": -94.83062284851074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.987428188323975, "step": 69000}
{"episode_reward": 986.8366711859659, "episode": 70.0, "batch_reward": 0.9151963989734649, "critic_loss": 0.8355861811637878, "actor_loss": -94.81819999694824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002214908599854, "step": 70000}
{"episode_reward": 915.756673195769, "episode": 71.0, "batch_reward": 0.9150139092206955, "critic_loss": 0.8114891955852509, "actor_loss": -94.90059574890137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.20713543891907, "step": 71000}
{"episode_reward": 936.5228656603756, "episode": 72.0, "batch_reward": 0.9148684169650078, "critic_loss": 0.8604691758602857, "actor_loss": -94.86922807312011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999363660812378, "step": 72000}
{"episode_reward": 784.0173446197465, "episode": 73.0, "batch_reward": 0.9141709908246994, "critic_loss": 0.820391821116209, "actor_loss": -94.82098899841309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.983442544937134, "step": 73000}
{"episode_reward": 956.5698740750879, "episode": 74.0, "batch_reward": 0.9148358327746391, "critic_loss": 0.8232006162106991, "actor_loss": -94.92226908874511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.996713638305664, "step": 74000}
{"episode_reward": 934.8738407694934, "episode": 75.0, "batch_reward": 0.9152195129394531, "critic_loss": 0.8370039884746074, "actor_loss": -94.82059643554688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98866629600525, "step": 75000}
{"episode_reward": 955.7619971871984, "episode": 76.0, "batch_reward": 0.9160525614023208, "critic_loss": 0.8053821808099747, "actor_loss": -94.88140087890625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.994736194610596, "step": 76000}
{"episode_reward": 971.8518888740557, "episode": 77.0, "batch_reward": 0.9159195768237114, "critic_loss": 0.7595900491476059, "actor_loss": -94.79177937316895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97564697265625, "step": 77000}
{"episode_reward": 959.3955778926958, "episode": 78.0, "batch_reward": 0.91632683801651, "critic_loss": 0.8190009874403477, "actor_loss": -94.92007144165039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9793803691864, "step": 78000}
{"episode_reward": 916.2765233855234, "episode": 79.0, "batch_reward": 0.9175816752910614, "critic_loss": 0.7766868322640658, "actor_loss": -94.76590621948242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.001429319381714, "step": 79000}
{"episode_reward": 966.6349228698323, "episode": 80.0, "batch_reward": 0.9173455298542976, "critic_loss": 0.7681449799239636, "actor_loss": -94.8792618560791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98994493484497, "step": 80000}
{"episode_reward": 984.0260688400898, "episode": 81.0, "batch_reward": 0.9173378800749779, "critic_loss": 0.7827814589589834, "actor_loss": -94.89754386901855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.17232632637024, "step": 81000}
{"episode_reward": 921.6466660338032, "episode": 82.0, "batch_reward": 0.9179208416938782, "critic_loss": 0.774771495461464, "actor_loss": -95.05284075927734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.992409467697144, "step": 82000}
{"episode_reward": 926.1651536826904, "episode": 83.0, "batch_reward": 0.9184459582567215, "critic_loss": 0.7940559146106243, "actor_loss": -94.94876820373536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.995445489883423, "step": 83000}
{"episode_reward": 898.421342130648, "episode": 84.0, "batch_reward": 0.9194991988539696, "critic_loss": 0.75913741594553, "actor_loss": -95.25239756774903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00324320793152, "step": 84000}
{"episode_reward": 988.9935440625827, "episode": 85.0, "batch_reward": 0.9178547310233116, "critic_loss": 0.7663892614692449, "actor_loss": -95.03110177612305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00283932685852, "step": 85000}
{"episode_reward": 916.0229455070723, "episode": 86.0, "batch_reward": 0.9185649692416191, "critic_loss": 0.7701278310120105, "actor_loss": -95.02806640625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997581005096436, "step": 86000}
{"episode_reward": 959.2651525304553, "episode": 87.0, "batch_reward": 0.9191701301932335, "critic_loss": 0.7791766140460968, "actor_loss": -95.032916015625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99700665473938, "step": 87000}
{"episode_reward": 927.5225684594894, "episode": 88.0, "batch_reward": 0.9196132007241249, "critic_loss": 0.7857591721713543, "actor_loss": -94.95793553161622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997145891189575, "step": 88000}
{"episode_reward": 946.4156892797065, "episode": 89.0, "batch_reward": 0.918363127052784, "critic_loss": 0.8171566286236047, "actor_loss": -95.05740090942383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01034450531006, "step": 89000}
{"episode_reward": 939.6030091079281, "episode": 90.0, "batch_reward": 0.9196662893891334, "critic_loss": 0.7084225921332836, "actor_loss": -95.15218603515625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003129720687866, "step": 90000}
{"episode_reward": 955.6719855486411, "episode": 91.0, "batch_reward": 0.9199068131446838, "critic_loss": 0.761321885600686, "actor_loss": -95.04362532043457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.17713141441345, "step": 91000}
{"episode_reward": 902.5857922429002, "episode": 92.0, "batch_reward": 0.9216926471590996, "critic_loss": 0.7342533839643002, "actor_loss": -95.1276328125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981966018676758, "step": 92000}
{"episode_reward": 960.8747179100166, "episode": 93.0, "batch_reward": 0.9187888535261154, "critic_loss": 0.7300721646696329, "actor_loss": -95.0347875366211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.974397659301758, "step": 93000}
{"episode_reward": 981.1615966609279, "episode": 94.0, "batch_reward": 0.9205938203930855, "critic_loss": 0.7186469609737396, "actor_loss": -95.13618737792969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00432825088501, "step": 94000}
{"episode_reward": 955.4005656234327, "episode": 95.0, "batch_reward": 0.9205990209579468, "critic_loss": 0.7464043061882257, "actor_loss": -95.13990734863282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99318027496338, "step": 95000}
{"episode_reward": 947.0339708399162, "episode": 96.0, "batch_reward": 0.9217430681586266, "critic_loss": 0.7694665161073208, "actor_loss": -95.1949747467041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.976959943771362, "step": 96000}
{"episode_reward": 962.4174576037169, "episode": 97.0, "batch_reward": 0.921114759504795, "critic_loss": 0.7896495644152165, "actor_loss": -95.21311711120606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99351692199707, "step": 97000}
{"episode_reward": 825.7984486378513, "episode": 98.0, "batch_reward": 0.9211240925192833, "critic_loss": 0.7880338321477175, "actor_loss": -95.14636791992187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00171208381653, "step": 98000}
{"episode_reward": 850.8553094904212, "episode": 99.0, "batch_reward": 0.9196871921420098, "critic_loss": 0.7956922892332077, "actor_loss": -94.98814616394043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9971981048584, "step": 99000}
{"episode_reward": 926.320798500331, "episode": 100.0, "batch_reward": 0.9216375672221184, "critic_loss": 0.8023550158441066, "actor_loss": -95.16222663879394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988734006881714, "step": 100000}
{"episode_reward": 931.9300430383325, "episode": 101.0, "batch_reward": 0.9216714852452278, "critic_loss": 0.807849522203207, "actor_loss": -95.15612705993652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.184582471847534, "step": 101000}
{"episode_reward": 987.9203138377245, "episode": 102.0, "batch_reward": 0.9203763226866722, "critic_loss": 0.804075618982315, "actor_loss": -95.10074382019043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.948211669921875, "step": 102000}
{"episode_reward": 945.2233789376633, "episode": 103.0, "batch_reward": 0.9208145911097526, "critic_loss": 0.7883579590022564, "actor_loss": -95.1258277130127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96181011199951, "step": 103000}
{"episode_reward": 959.7851125508487, "episode": 104.0, "batch_reward": 0.9231229668855667, "critic_loss": 0.8241854200065136, "actor_loss": -95.23142045593262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.973373413085938, "step": 104000}
{"episode_reward": 958.3420380161094, "episode": 105.0, "batch_reward": 0.9229242408275604, "critic_loss": 0.8695322757065296, "actor_loss": -95.24601266479492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.978164196014404, "step": 105000}
{"episode_reward": 893.9816313911098, "episode": 106.0, "batch_reward": 0.9225777260065079, "critic_loss": 0.8643562787473201, "actor_loss": -95.17759535217286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98284149169922, "step": 106000}
{"episode_reward": 921.1446441002141, "episode": 107.0, "batch_reward": 0.9210721007585525, "critic_loss": 0.8967168251127005, "actor_loss": -95.11437361145019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99705743789673, "step": 107000}
{"episode_reward": 959.8621435401128, "episode": 108.0, "batch_reward": 0.9231694052219391, "critic_loss": 0.8621030868887901, "actor_loss": -95.19465563964843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.965407609939575, "step": 108000}
{"episode_reward": 956.7181864896174, "episode": 109.0, "batch_reward": 0.9230361557602882, "critic_loss": 0.8262107640951872, "actor_loss": -95.32724143981933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993692874908447, "step": 109000}
{"episode_reward": 978.1925231991293, "episode": 110.0, "batch_reward": 0.923611485004425, "critic_loss": 0.8839890228509903, "actor_loss": -95.28887698364258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95949149131775, "step": 110000}
{"episode_reward": 918.407728539195, "episode": 111.0, "batch_reward": 0.9227380982637405, "critic_loss": 0.8647605597823859, "actor_loss": -95.21531974792481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.208553314208984, "step": 111000}
{"episode_reward": 941.3390384063415, "episode": 112.0, "batch_reward": 0.9229705510139465, "critic_loss": 0.8733269252032042, "actor_loss": -95.08686070251464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00599718093872, "step": 112000}
{"episode_reward": 958.1667009793149, "episode": 113.0, "batch_reward": 0.9240947508811951, "critic_loss": 0.8811052996516228, "actor_loss": -95.21765199279785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007211446762085, "step": 113000}
{"episode_reward": 913.6771352702076, "episode": 114.0, "batch_reward": 0.9235671327114106, "critic_loss": 0.9272719662189484, "actor_loss": -95.26384164428711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.966643810272217, "step": 114000}
{"episode_reward": 972.3473381580757, "episode": 115.0, "batch_reward": 0.9235879264473915, "critic_loss": 0.936199414819479, "actor_loss": -95.15129832458496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00696873664856, "step": 115000}
{"episode_reward": 896.1079603631302, "episode": 116.0, "batch_reward": 0.9243478508591652, "critic_loss": 0.8978429838567972, "actor_loss": -95.17981469726563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990083932876587, "step": 116000}
{"episode_reward": 951.9174467028897, "episode": 117.0, "batch_reward": 0.9237282484173774, "critic_loss": 0.9543840517699719, "actor_loss": -95.11019316101074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004775762557983, "step": 117000}
{"episode_reward": 938.3272053444912, "episode": 118.0, "batch_reward": 0.924557979285717, "critic_loss": 0.9669682972729207, "actor_loss": -95.24927728271484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00671362876892, "step": 118000}
{"episode_reward": 985.7754296801282, "episode": 119.0, "batch_reward": 0.9247267126441002, "critic_loss": 0.9430657929480076, "actor_loss": -95.26530236816406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99831199645996, "step": 119000}
{"episode_reward": 933.836680673715, "episode": 120.0, "batch_reward": 0.9238001950383187, "critic_loss": 0.9829158663451671, "actor_loss": -95.19119732666016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005897521972656, "step": 120000}
{"episode_reward": 901.9593425783315, "episode": 121.0, "batch_reward": 0.924613100707531, "critic_loss": 0.9458651097416878, "actor_loss": -95.11986822509766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.197651863098145, "step": 121000}
{"episode_reward": 983.6086126075395, "episode": 122.0, "batch_reward": 0.9241690279245377, "critic_loss": 0.967391977339983, "actor_loss": -95.15334823608399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97163677215576, "step": 122000}
{"episode_reward": 913.754296021517, "episode": 123.0, "batch_reward": 0.9247707090973855, "critic_loss": 0.8947743464559317, "actor_loss": -95.05074526977539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99213671684265, "step": 123000}
{"episode_reward": 952.8324303217669, "episode": 124.0, "batch_reward": 0.9244324105381966, "critic_loss": 0.8870777557492256, "actor_loss": -95.12836694335938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002503395080566, "step": 124000}
{"episode_reward": 955.640808755713, "episode": 125.0, "batch_reward": 0.9255581011176109, "critic_loss": 0.8448755439221859, "actor_loss": -95.19489764404297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997127294540405, "step": 125000}
{"episode_reward": 987.8563129682163, "episode": 126.0, "batch_reward": 0.9268778312206268, "critic_loss": 0.8281593375205993, "actor_loss": -95.17809817504883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97314453125, "step": 126000}
{"episode_reward": 987.4433047259125, "episode": 127.0, "batch_reward": 0.9259599522352219, "critic_loss": 0.8880178127288818, "actor_loss": -95.30016209411622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.983407974243164, "step": 127000}
{"episode_reward": 938.7601374784648, "episode": 128.0, "batch_reward": 0.9257895058989525, "critic_loss": 0.900625878483057, "actor_loss": -95.43837495422363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999241828918457, "step": 128000}
{"episode_reward": 965.3802213438731, "episode": 129.0, "batch_reward": 0.9263900758624077, "critic_loss": 0.8690229265689849, "actor_loss": -95.32863162231445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00013303756714, "step": 129000}
{"episode_reward": 939.5045365769844, "episode": 130.0, "batch_reward": 0.9278173498511314, "critic_loss": 0.8651097862720489, "actor_loss": -95.34129922485351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.978090286254883, "step": 130000}
{"episode_reward": 988.374557410845, "episode": 131.0, "batch_reward": 0.9282166428565979, "critic_loss": 0.8467325314581394, "actor_loss": -95.41126016235351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.56460762023926, "step": 131000}
{"episode_reward": 955.3607167496695, "episode": 132.0, "batch_reward": 0.9278572681546211, "critic_loss": 0.8754381507635116, "actor_loss": -95.40993222045898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98641347885132, "step": 132000}
{"episode_reward": 973.7479513918558, "episode": 133.0, "batch_reward": 0.9269211537837982, "critic_loss": 0.8447399201095104, "actor_loss": -95.3722740020752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.306254863739014, "step": 133000}
{"episode_reward": 902.1775245549024, "episode": 134.0, "batch_reward": 0.9272751300930977, "critic_loss": 0.8655864101350308, "actor_loss": -95.39896908569337, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.001705646514893, "step": 134000}
{"episode_reward": 960.1191510163103, "episode": 135.0, "batch_reward": 0.9298079723715782, "critic_loss": 0.8557944320440293, "actor_loss": -95.45971925354004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97358012199402, "step": 135000}
{"episode_reward": 992.118613888075, "episode": 136.0, "batch_reward": 0.9288724365830422, "critic_loss": 0.903127811551094, "actor_loss": -95.56712913513184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99812960624695, "step": 136000}
{"episode_reward": 982.890803185809, "episode": 137.0, "batch_reward": 0.9277068934440613, "critic_loss": 0.9035779987573623, "actor_loss": -95.41752186584473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.001731395721436, "step": 137000}
{"episode_reward": 980.8185956414889, "episode": 138.0, "batch_reward": 0.9297922940254212, "critic_loss": 0.9039245658218861, "actor_loss": -95.3007030029297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00996470451355, "step": 138000}
{"episode_reward": 880.2575206550088, "episode": 139.0, "batch_reward": 0.9279682743549347, "critic_loss": 0.9165551588684321, "actor_loss": -95.31147761535645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02572774887085, "step": 139000}
{"episode_reward": 989.023542340315, "episode": 140.0, "batch_reward": 0.929535944879055, "critic_loss": 0.9033956754356622, "actor_loss": -95.27240785217285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.992554664611816, "step": 140000}
{"episode_reward": 933.5033517124571, "episode": 141.0, "batch_reward": 0.9297578766345977, "critic_loss": 0.9244791489839553, "actor_loss": -95.37305014038085, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.20778727531433, "step": 141000}
{"episode_reward": 967.0699338794287, "episode": 142.0, "batch_reward": 0.930184452176094, "critic_loss": 0.9080352024585009, "actor_loss": -95.36730917358399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.995064735412598, "step": 142000}
{"episode_reward": 988.9267493263828, "episode": 143.0, "batch_reward": 0.9301655088663101, "critic_loss": 0.9380104638338089, "actor_loss": -95.48458059692383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993685007095337, "step": 143000}
{"episode_reward": 922.7967575257094, "episode": 144.0, "batch_reward": 0.9290614296197891, "critic_loss": 0.9666718577444553, "actor_loss": -95.44696076965332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999131441116333, "step": 144000}
{"episode_reward": 920.0536787261032, "episode": 145.0, "batch_reward": 0.9301765770316124, "critic_loss": 0.8828979929387569, "actor_loss": -95.4345129699707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.014003038406372, "step": 145000}
{"episode_reward": 986.6250246444115, "episode": 146.0, "batch_reward": 0.9298533353805541, "critic_loss": 0.8653334664106369, "actor_loss": -95.46867280578613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990589141845703, "step": 146000}
{"episode_reward": 950.6411353565278, "episode": 147.0, "batch_reward": 0.9301408511400223, "critic_loss": 0.8822933348864317, "actor_loss": -95.52276469421386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005696773529053, "step": 147000}
{"episode_reward": 944.6374590945534, "episode": 148.0, "batch_reward": 0.9311095086336136, "critic_loss": 0.8605492826849223, "actor_loss": -95.49164903259278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.994590759277344, "step": 148000}
{"episode_reward": 975.348574002211, "episode": 149.0, "batch_reward": 0.9299121131300926, "critic_loss": 0.9230505984723568, "actor_loss": -95.50215447998048, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99903392791748, "step": 149000}
{"episode_reward": 924.4031537253259, "episode": 150.0, "batch_reward": 0.9297563243508339, "critic_loss": 0.9440512950122356, "actor_loss": -95.46354107666015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
