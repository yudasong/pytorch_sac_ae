{"episode_reward": 0.0, "episode": 1.0, "duration": 20.561662197113037, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.7780933380126953, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.5048700651056411, "critic_loss": 1.0086568161999236, "actor_loss": -86.05198954581833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.850056171417236, "step": 3000}
{"episode_reward": 947.3389438797196, "episode": 4.0, "batch_reward": 0.6753284663558007, "critic_loss": 0.8514507311284543, "actor_loss": -89.72028427124023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03901243209839, "step": 4000}
{"episode_reward": 967.2491554792665, "episode": 5.0, "batch_reward": 0.7450501238107681, "critic_loss": 0.8789576087296009, "actor_loss": -90.89905293273925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05378031730652, "step": 5000}
{"episode_reward": 989.2032224211837, "episode": 6.0, "batch_reward": 0.7794577478170395, "critic_loss": 0.8293505042791367, "actor_loss": -91.51368650817871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.044394731521606, "step": 6000}
{"episode_reward": 927.1163947850849, "episode": 7.0, "batch_reward": 0.8073819309473038, "critic_loss": 0.6303762746155261, "actor_loss": -92.05951963806152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.01338768005371, "step": 7000}
{"episode_reward": 969.5973844973463, "episode": 8.0, "batch_reward": 0.8280365600585937, "critic_loss": 0.5467578045725823, "actor_loss": -92.29314744567871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03024387359619, "step": 8000}
{"episode_reward": 926.2776663234399, "episode": 9.0, "batch_reward": 0.8379511561393738, "critic_loss": 0.6314463798701763, "actor_loss": -92.39544760131835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.031152963638306, "step": 9000}
{"episode_reward": 953.4547922572062, "episode": 10.0, "batch_reward": 0.8485174713134765, "critic_loss": 0.717899280577898, "actor_loss": -92.61748139953613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.00752830505371, "step": 10000}
{"episode_reward": 921.2372229439053, "episode": 11.0, "batch_reward": 0.8553219544887543, "critic_loss": 0.715875263184309, "actor_loss": -92.80854103088379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.36371874809265, "step": 11000}
{"episode_reward": 882.2294767637949, "episode": 12.0, "batch_reward": 0.8546861672997474, "critic_loss": 0.6743013642132282, "actor_loss": -92.68218832397461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.027589321136475, "step": 12000}
{"episode_reward": 899.4819645011714, "episode": 13.0, "batch_reward": 0.858930983543396, "critic_loss": 0.622420370310545, "actor_loss": -92.89585299682618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03418207168579, "step": 13000}
{"episode_reward": 905.3742422695507, "episode": 14.0, "batch_reward": 0.8682358837723732, "critic_loss": 0.5710642543435097, "actor_loss": -92.95907618713379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.033633708953857, "step": 14000}
{"episode_reward": 979.2524884640574, "episode": 15.0, "batch_reward": 0.8768844124674797, "critic_loss": 0.5019628897607327, "actor_loss": -93.6554515838623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.035585165023804, "step": 15000}
{"episode_reward": 989.9169375587238, "episode": 16.0, "batch_reward": 0.8813309479355812, "critic_loss": 0.5342353852689267, "actor_loss": -93.5268136138916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.068073272705078, "step": 16000}
{"episode_reward": 913.4108038953304, "episode": 17.0, "batch_reward": 0.8824878078103066, "critic_loss": 0.6037888045608998, "actor_loss": -93.67101708984374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.049058198928833, "step": 17000}
{"episode_reward": 935.5117308327212, "episode": 18.0, "batch_reward": 0.886256973862648, "critic_loss": 0.6395819640159607, "actor_loss": -93.61704736328124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.038889169692993, "step": 18000}
{"episode_reward": 932.6500467360099, "episode": 19.0, "batch_reward": 0.888965349137783, "critic_loss": 0.597696783542633, "actor_loss": -93.50852322387695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03025245666504, "step": 19000}
{"episode_reward": 951.3643477932566, "episode": 20.0, "batch_reward": 0.8912652663588524, "critic_loss": 0.6250603404939175, "actor_loss": -93.79035545349122, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.054603576660156, "step": 20000}
{"episode_reward": 891.8479751141161, "episode": 21.0, "batch_reward": 0.892058672606945, "critic_loss": 0.6739723236560822, "actor_loss": -93.829564453125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.328157901763916, "step": 21000}
{"episode_reward": 951.6403467848926, "episode": 22.0, "batch_reward": 0.8954609906077385, "critic_loss": 0.716493324071169, "actor_loss": -93.77368057250976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04936122894287, "step": 22000}
{"episode_reward": 946.465828055829, "episode": 23.0, "batch_reward": 0.8965914661288261, "critic_loss": 0.7689151329100132, "actor_loss": -93.99269822692871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.032076835632324, "step": 23000}
{"episode_reward": 918.368127524717, "episode": 24.0, "batch_reward": 0.8989221090078354, "critic_loss": 0.6924493571221828, "actor_loss": -93.91434387207032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.004343032836914, "step": 24000}
{"episode_reward": 984.334538401426, "episode": 25.0, "batch_reward": 0.89959056609869, "critic_loss": 0.7725906459391118, "actor_loss": -93.79779714965821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.033758878707886, "step": 25000}
{"episode_reward": 924.0985958258249, "episode": 26.0, "batch_reward": 0.9004052953124047, "critic_loss": 0.7770167455375194, "actor_loss": -94.01422593688964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.00868272781372, "step": 26000}
{"episode_reward": 942.081482178074, "episode": 27.0, "batch_reward": 0.9054322226047515, "critic_loss": 0.7281473933458328, "actor_loss": -93.9964564666748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03831124305725, "step": 27000}
{"episode_reward": 984.3080987563133, "episode": 28.0, "batch_reward": 0.9081506778597832, "critic_loss": 0.7480041241943837, "actor_loss": -94.00741018676757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04058027267456, "step": 28000}
{"episode_reward": 946.2543522907016, "episode": 29.0, "batch_reward": 0.9054580597281456, "critic_loss": 0.7909950863718986, "actor_loss": -94.0507869720459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03978157043457, "step": 29000}
{"episode_reward": 872.8779975712325, "episode": 30.0, "batch_reward": 0.907843601167202, "critic_loss": 0.7634752659499645, "actor_loss": -93.99725946044921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05183458328247, "step": 30000}
{"episode_reward": 933.9210855318536, "episode": 31.0, "batch_reward": 0.9086894507408142, "critic_loss": 0.7386294374167919, "actor_loss": -94.09697647094727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.35202169418335, "step": 31000}
{"episode_reward": 955.4660482678438, "episode": 32.0, "batch_reward": 0.9107205985188485, "critic_loss": 0.7296706849634648, "actor_loss": -93.984064743042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03976011276245, "step": 32000}
{"episode_reward": 937.9468853726981, "episode": 33.0, "batch_reward": 0.9084658998847007, "critic_loss": 0.7902491343915462, "actor_loss": -94.15845860290527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03759264945984, "step": 33000}
{"episode_reward": 894.9452768803442, "episode": 34.0, "batch_reward": 0.9098122971057891, "critic_loss": 0.6906188912987709, "actor_loss": -93.99284967041015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.058412790298462, "step": 34000}
{"episode_reward": 981.116644048092, "episode": 35.0, "batch_reward": 0.9098354382514954, "critic_loss": 0.7180533846020698, "actor_loss": -94.3553392791748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.02159309387207, "step": 35000}
{"episode_reward": 878.0876453934513, "episode": 36.0, "batch_reward": 0.9100730040669441, "critic_loss": 0.6755098657310009, "actor_loss": -94.00879336547851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.029848337173462, "step": 36000}
{"episode_reward": 933.5715157170303, "episode": 37.0, "batch_reward": 0.9104448658823967, "critic_loss": 0.6788990406095982, "actor_loss": -94.32734423828126, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.031963348388672, "step": 37000}
{"episode_reward": 960.7579153587394, "episode": 38.0, "batch_reward": 0.9138251347541809, "critic_loss": 0.6915837341248989, "actor_loss": -94.32478433227539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.024315357208252, "step": 38000}
{"episode_reward": 984.1808582672646, "episode": 39.0, "batch_reward": 0.9141578568816185, "critic_loss": 0.693333823621273, "actor_loss": -94.39315124511718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.01255989074707, "step": 39000}
{"episode_reward": 957.6501814886984, "episode": 40.0, "batch_reward": 0.9157150185704231, "critic_loss": 0.7127165082097053, "actor_loss": -94.47100311279297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.00028157234192, "step": 40000}
{"episode_reward": 979.8888365490637, "episode": 41.0, "batch_reward": 0.9160714579224587, "critic_loss": 0.7602297531068325, "actor_loss": -94.51560200500488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.3117036819458, "step": 41000}
{"episode_reward": 869.0074192780054, "episode": 42.0, "batch_reward": 0.9174148765206337, "critic_loss": 0.8250792327523232, "actor_loss": -94.28748007202148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.041327476501465, "step": 42000}
{"episode_reward": 959.6083597779333, "episode": 43.0, "batch_reward": 0.9169429090023041, "critic_loss": 0.804772117882967, "actor_loss": -94.36604125976562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.041097164154053, "step": 43000}
{"episode_reward": 940.9095223020769, "episode": 44.0, "batch_reward": 0.9177420980334282, "critic_loss": 0.7744021629989147, "actor_loss": -94.37305155944824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03836441040039, "step": 44000}
{"episode_reward": 966.4830376952968, "episode": 45.0, "batch_reward": 0.9181836119294167, "critic_loss": 0.8176988692879676, "actor_loss": -94.42813568115234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.047924041748047, "step": 45000}
{"episode_reward": 923.8831685499063, "episode": 46.0, "batch_reward": 0.918640946149826, "critic_loss": 0.7499783457219601, "actor_loss": -94.42458320617676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.037025213241577, "step": 46000}
{"episode_reward": 964.3142009644547, "episode": 47.0, "batch_reward": 0.9201849498152733, "critic_loss": 0.7545618009567261, "actor_loss": -94.65382106018066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.028066873550415, "step": 47000}
{"episode_reward": 967.2633794995853, "episode": 48.0, "batch_reward": 0.920282090485096, "critic_loss": 0.7481283357739449, "actor_loss": -94.58775314331055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.052663803100586, "step": 48000}
{"episode_reward": 901.3687390583113, "episode": 49.0, "batch_reward": 0.9197311963438988, "critic_loss": 0.7740559335947037, "actor_loss": -94.77133477783204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.043858766555786, "step": 49000}
{"episode_reward": 888.8419170084929, "episode": 50.0, "batch_reward": 0.920719605743885, "critic_loss": 0.7579198612570762, "actor_loss": -94.6014846496582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.046464443206787, "step": 50000}
{"episode_reward": 987.3297124440687, "episode": 51.0, "batch_reward": 0.922026357471943, "critic_loss": 0.7534660959541798, "actor_loss": -94.67762649536132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.364296436309814, "step": 51000}
{"episode_reward": 984.4583957787543, "episode": 52.0, "batch_reward": 0.9219675109386444, "critic_loss": 0.7588126159310341, "actor_loss": -94.66969285583497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03503942489624, "step": 52000}
{"episode_reward": 945.1183325556606, "episode": 53.0, "batch_reward": 0.9231136392354965, "critic_loss": 0.7827411257624626, "actor_loss": -94.76805711364746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.02460551261902, "step": 53000}
{"episode_reward": 955.0124235394212, "episode": 54.0, "batch_reward": 0.9228514548540115, "critic_loss": 0.7894927476644515, "actor_loss": -94.71191506958007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.038676500320435, "step": 54000}
{"episode_reward": 923.2680044039597, "episode": 55.0, "batch_reward": 0.9239376558661461, "critic_loss": 0.6770708238184452, "actor_loss": -95.01015180969239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.031779766082764, "step": 55000}
{"episode_reward": 974.9707109432005, "episode": 56.0, "batch_reward": 0.9251985220313073, "critic_loss": 0.6901119129359722, "actor_loss": -94.97383912658691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.031801223754883, "step": 56000}
{"episode_reward": 982.2050411931865, "episode": 57.0, "batch_reward": 0.926057456612587, "critic_loss": 0.6318822839558125, "actor_loss": -94.84321092224121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.057682514190674, "step": 57000}
{"episode_reward": 956.9356067467348, "episode": 58.0, "batch_reward": 0.9265384768247604, "critic_loss": 0.6453504302054643, "actor_loss": -94.92268237304687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.036476612091064, "step": 58000}
{"episode_reward": 982.1074650073724, "episode": 59.0, "batch_reward": 0.9280371294617653, "critic_loss": 0.6152354015558958, "actor_loss": -95.0008770904541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.051988124847412, "step": 59000}
{"episode_reward": 956.0659641650577, "episode": 60.0, "batch_reward": 0.9263448814749717, "critic_loss": 0.6867061275541783, "actor_loss": -95.0226022644043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05773901939392, "step": 60000}
{"episode_reward": 877.8592442400633, "episode": 61.0, "batch_reward": 0.9271758916378021, "critic_loss": 0.6552432422637939, "actor_loss": -94.9281008758545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.386279821395874, "step": 61000}
{"episode_reward": 955.092186504475, "episode": 62.0, "batch_reward": 0.9268995878696442, "critic_loss": 0.6604751156568527, "actor_loss": -95.13109075927734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04961109161377, "step": 62000}
{"episode_reward": 966.6081830398841, "episode": 63.0, "batch_reward": 0.9264232935905456, "critic_loss": 0.6315039783120155, "actor_loss": -95.0021205444336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.066431045532227, "step": 63000}
{"episode_reward": 942.1152736983073, "episode": 64.0, "batch_reward": 0.9282398237586021, "critic_loss": 0.617287515744567, "actor_loss": -95.095551071167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04910111427307, "step": 64000}
{"episode_reward": 976.0195525287743, "episode": 65.0, "batch_reward": 0.9297703168392182, "critic_loss": 0.622387709364295, "actor_loss": -95.07358903503417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05059814453125, "step": 65000}
{"episode_reward": 976.1857035974871, "episode": 66.0, "batch_reward": 0.9283208786845207, "critic_loss": 0.6259946700036526, "actor_loss": -95.10077070617676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05264902114868, "step": 66000}
{"episode_reward": 911.5346754833316, "episode": 67.0, "batch_reward": 0.927838240146637, "critic_loss": 0.6077322900742292, "actor_loss": -95.13131227111816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.028341054916382, "step": 67000}
{"episode_reward": 925.1010635156365, "episode": 68.0, "batch_reward": 0.9288669865727425, "critic_loss": 0.6078831373155117, "actor_loss": -95.0480477142334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.046942710876465, "step": 68000}
{"episode_reward": 958.8753562386368, "episode": 69.0, "batch_reward": 0.9294393707513809, "critic_loss": 0.5998388913571835, "actor_loss": -95.1728039855957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.041613340377808, "step": 69000}
{"episode_reward": 963.8437254862965, "episode": 70.0, "batch_reward": 0.9295143142938614, "critic_loss": 0.5960227464437484, "actor_loss": -95.14883267211914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.031476974487305, "step": 70000}
{"episode_reward": 929.1752956974034, "episode": 71.0, "batch_reward": 0.9295401713848114, "critic_loss": 0.570742576777935, "actor_loss": -95.23687519836426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.40088987350464, "step": 71000}
{"episode_reward": 942.17193832395, "episode": 72.0, "batch_reward": 0.9305014538168908, "critic_loss": 0.5554173367917538, "actor_loss": -95.26375856018066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.018489360809326, "step": 72000}
{"episode_reward": 975.8417227858279, "episode": 73.0, "batch_reward": 0.9295061106681823, "critic_loss": 0.591913425117731, "actor_loss": -95.19154763793945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.066256761550903, "step": 73000}
{"episode_reward": 931.0638053287793, "episode": 74.0, "batch_reward": 0.9310985699295997, "critic_loss": 0.5607056477069855, "actor_loss": -95.30576596069336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.053011178970337, "step": 74000}
{"episode_reward": 926.231885878426, "episode": 75.0, "batch_reward": 0.9311901866793633, "critic_loss": 0.5660820352435112, "actor_loss": -95.19499981689454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.048941135406494, "step": 75000}
{"episode_reward": 960.2661047842819, "episode": 76.0, "batch_reward": 0.9317061095833779, "critic_loss": 0.5704893513768912, "actor_loss": -95.26489888000488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.048306703567505, "step": 76000}
{"episode_reward": 967.0803487492957, "episode": 77.0, "batch_reward": 0.9311340081095696, "critic_loss": 0.5827766674011946, "actor_loss": -95.15775227355957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.056246995925903, "step": 77000}
{"episode_reward": 969.8475494687913, "episode": 78.0, "batch_reward": 0.9321652991771698, "critic_loss": 0.6261402291059494, "actor_loss": -95.29661297607421, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.023264408111572, "step": 78000}
{"episode_reward": 952.695650300948, "episode": 79.0, "batch_reward": 0.9324046615958214, "critic_loss": 0.5848760529011487, "actor_loss": -95.12391970825195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05696940422058, "step": 79000}
{"episode_reward": 950.9969279644349, "episode": 80.0, "batch_reward": 0.9324130646586418, "critic_loss": 0.552869317650795, "actor_loss": -95.22935763549805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.064629793167114, "step": 80000}
{"episode_reward": 973.1523664822281, "episode": 81.0, "batch_reward": 0.9321879814267159, "critic_loss": 0.5756208115667105, "actor_loss": -95.20544598388672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.37844276428223, "step": 81000}
{"episode_reward": 928.058699869257, "episode": 82.0, "batch_reward": 0.9331837322115898, "critic_loss": 0.5541761577427388, "actor_loss": -95.3759806060791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05303382873535, "step": 82000}
{"episode_reward": 962.8090188711807, "episode": 83.0, "batch_reward": 0.9331025245189667, "critic_loss": 0.5616217010319233, "actor_loss": -95.25303175354004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.062431573867798, "step": 83000}
{"episode_reward": 926.3017722621983, "episode": 84.0, "batch_reward": 0.9345213510990142, "critic_loss": 0.5686439865380526, "actor_loss": -95.56058923339843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.02710723876953, "step": 84000}
{"episode_reward": 990.6636063008457, "episode": 85.0, "batch_reward": 0.9337375888228416, "critic_loss": 0.552707266151905, "actor_loss": -95.34842791748046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.029772520065308, "step": 85000}
{"episode_reward": 952.4805156394325, "episode": 86.0, "batch_reward": 0.9343340618610382, "critic_loss": 0.5487408932000398, "actor_loss": -95.31092578125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.025526523590088, "step": 86000}
{"episode_reward": 947.9490538725637, "episode": 87.0, "batch_reward": 0.9347078258395195, "critic_loss": 0.5613690912425519, "actor_loss": -95.35667561340333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.039416313171387, "step": 87000}
{"episode_reward": 936.3517212431789, "episode": 88.0, "batch_reward": 0.9340777580738068, "critic_loss": 0.5175737724751234, "actor_loss": -95.24235662841797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.044477462768555, "step": 88000}
{"episode_reward": 913.566291968157, "episode": 89.0, "batch_reward": 0.9336423169970512, "critic_loss": 0.5234361023306847, "actor_loss": -95.35640325927734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04656958580017, "step": 89000}
{"episode_reward": 983.0249488106804, "episode": 90.0, "batch_reward": 0.9349210124015808, "critic_loss": 0.4898405319303274, "actor_loss": -95.45845875549317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03306007385254, "step": 90000}
{"episode_reward": 962.8257483007579, "episode": 91.0, "batch_reward": 0.9345335229039192, "critic_loss": 0.532636210501194, "actor_loss": -95.35965798950195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.39056086540222, "step": 91000}
{"episode_reward": 951.9647811982725, "episode": 92.0, "batch_reward": 0.935466847717762, "critic_loss": 0.5059645626395941, "actor_loss": -95.395363571167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.0546612739563, "step": 92000}
{"episode_reward": 955.9773292121499, "episode": 93.0, "batch_reward": 0.9340292111039161, "critic_loss": 0.5434763725996018, "actor_loss": -95.31204571533203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.061152935028076, "step": 93000}
{"episode_reward": 986.1742511586729, "episode": 94.0, "batch_reward": 0.9357025201320648, "critic_loss": 0.5110254710763693, "actor_loss": -95.45268116760253, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.055097341537476, "step": 94000}
{"episode_reward": 938.6994173373571, "episode": 95.0, "batch_reward": 0.9356719745993615, "critic_loss": 0.5264128867834806, "actor_loss": -95.42427763366699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.026846408843994, "step": 95000}
{"episode_reward": 960.7750575181509, "episode": 96.0, "batch_reward": 0.9363453363180161, "critic_loss": 0.5073278289735317, "actor_loss": -95.50106448364258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.033676385879517, "step": 96000}
{"episode_reward": 957.1884238712987, "episode": 97.0, "batch_reward": 0.9362334470152855, "critic_loss": 0.5187262608259916, "actor_loss": -95.5154969177246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.01282525062561, "step": 97000}
{"episode_reward": 919.1042529613069, "episode": 98.0, "batch_reward": 0.9367447344064712, "critic_loss": 0.525997440546751, "actor_loss": -95.46348741149902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05800986289978, "step": 98000}
{"episode_reward": 936.1573176979385, "episode": 99.0, "batch_reward": 0.9354878610372543, "critic_loss": 0.5184280346781015, "actor_loss": -95.35175819396973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04619288444519, "step": 99000}
{"episode_reward": 965.9947818232865, "episode": 100.0, "batch_reward": 0.9360277410149574, "critic_loss": 0.5926146792471408, "actor_loss": -95.47206723022461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.023622274398804, "step": 100000}
{"episode_reward": 743.1911033618596, "episode": 101.0, "batch_reward": 0.9354951157569885, "critic_loss": 0.5890020558685064, "actor_loss": -95.43247344970703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.35662865638733, "step": 101000}
{"episode_reward": 990.0278610479045, "episode": 102.0, "batch_reward": 0.9347324015498162, "critic_loss": 0.5748101436197758, "actor_loss": -95.36990393066407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.053860902786255, "step": 102000}
{"episode_reward": 983.4718933659192, "episode": 103.0, "batch_reward": 0.9346789216399193, "critic_loss": 0.5691219495534897, "actor_loss": -95.42571940612793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.046971082687378, "step": 103000}
{"episode_reward": 950.4497311792361, "episode": 104.0, "batch_reward": 0.9372019126415253, "critic_loss": 0.5856966819763184, "actor_loss": -95.51128500366211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05261206626892, "step": 104000}
{"episode_reward": 956.0513198839645, "episode": 105.0, "batch_reward": 0.936828265607357, "critic_loss": 0.5547370943278074, "actor_loss": -95.53402233886719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05071473121643, "step": 105000}
{"episode_reward": 946.4258453128235, "episode": 106.0, "batch_reward": 0.9365485595464706, "critic_loss": 0.5598716124743223, "actor_loss": -95.48302328491211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3725004196167, "step": 106000}
{"episode_reward": 922.7393982281608, "episode": 107.0, "batch_reward": 0.9350496038198471, "critic_loss": 0.5587542382031679, "actor_loss": -95.43991464233399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.219905376434326, "step": 107000}
{"episode_reward": 959.1345540037738, "episode": 108.0, "batch_reward": 0.9366249523758888, "critic_loss": 0.5473595607280731, "actor_loss": -95.51762503051758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.11015772819519, "step": 108000}
{"episode_reward": 950.6337516314236, "episode": 109.0, "batch_reward": 0.936934229850769, "critic_loss": 0.5379464108645916, "actor_loss": -95.6464150543213, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.11298179626465, "step": 109000}
{"episode_reward": 962.8524580074969, "episode": 110.0, "batch_reward": 0.9365388107299805, "critic_loss": 0.5503333127349616, "actor_loss": -95.58723318481445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.07032012939453, "step": 110000}
{"episode_reward": 935.5629793170185, "episode": 111.0, "batch_reward": 0.9365641078352929, "critic_loss": 0.548337703704834, "actor_loss": -95.56676377868652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.38020324707031, "step": 111000}
{"episode_reward": 929.6480020316104, "episode": 112.0, "batch_reward": 0.935833255648613, "critic_loss": 0.5738987789005041, "actor_loss": -95.43536700439454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.356328010559082, "step": 112000}
{"episode_reward": 911.3794150396974, "episode": 113.0, "batch_reward": 0.9371769717335701, "critic_loss": 0.5273913566917181, "actor_loss": -95.56482594299317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.035297393798828, "step": 113000}
{"episode_reward": 948.8866923748989, "episode": 114.0, "batch_reward": 0.9366578385829926, "critic_loss": 0.5322791615873576, "actor_loss": -95.60657955932618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.990571975708008, "step": 114000}
{"episode_reward": 972.0892756038941, "episode": 115.0, "batch_reward": 0.93725686866045, "critic_loss": 0.5456305043995381, "actor_loss": -95.50803160095215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.98684787750244, "step": 115000}
{"episode_reward": 903.2309537638349, "episode": 116.0, "batch_reward": 0.9365764192342758, "critic_loss": 0.5671317355632782, "actor_loss": -95.51682627868652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03382706642151, "step": 116000}
{"episode_reward": 955.0728229365596, "episode": 117.0, "batch_reward": 0.9359693994522095, "critic_loss": 0.5904011697471142, "actor_loss": -95.45951329040527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.01150155067444, "step": 117000}
{"episode_reward": 909.8095248791313, "episode": 118.0, "batch_reward": 0.9361686831116677, "critic_loss": 0.5723417409658432, "actor_loss": -95.55393067932128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.026703357696533, "step": 118000}
{"episode_reward": 968.2552926372174, "episode": 119.0, "batch_reward": 0.9365938618183136, "critic_loss": 0.5922598751187325, "actor_loss": -95.57842422485352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04717779159546, "step": 119000}
{"episode_reward": 947.1056652202672, "episode": 120.0, "batch_reward": 0.9361371484994888, "critic_loss": 0.5724644952565432, "actor_loss": -95.515142578125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05212903022766, "step": 120000}
{"episode_reward": 921.6620333193943, "episode": 121.0, "batch_reward": 0.9371488357186317, "critic_loss": 0.5798751946687698, "actor_loss": -95.47328120422364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.35929989814758, "step": 121000}
{"episode_reward": 980.2121103913667, "episode": 122.0, "batch_reward": 0.9364336095452309, "critic_loss": 0.6160194547772407, "actor_loss": -95.50966325378418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.034342765808105, "step": 122000}
{"episode_reward": 946.1754972652814, "episode": 123.0, "batch_reward": 0.9364418268203736, "critic_loss": 0.6362904342412948, "actor_loss": -95.39368421936035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.033556938171387, "step": 123000}
{"episode_reward": 841.4408787059187, "episode": 124.0, "batch_reward": 0.9360009249448776, "critic_loss": 0.6301234702914953, "actor_loss": -95.43305033874512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.02961564064026, "step": 124000}
{"episode_reward": 988.6541910439452, "episode": 125.0, "batch_reward": 0.9370311696529389, "critic_loss": 0.6333581534773112, "actor_loss": -95.46962879943848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05843234062195, "step": 125000}
{"episode_reward": 986.5601913604808, "episode": 126.0, "batch_reward": 0.9375285684466362, "critic_loss": 0.5985602143481373, "actor_loss": -95.48752601623535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.071799278259277, "step": 126000}
{"episode_reward": 989.4004509609281, "episode": 127.0, "batch_reward": 0.936420040011406, "critic_loss": 0.6218926555365324, "actor_loss": -95.53672615051269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.050260305404663, "step": 127000}
{"episode_reward": 929.3468647496552, "episode": 128.0, "batch_reward": 0.9370301431417465, "critic_loss": 0.6158244027644396, "actor_loss": -95.68675187683105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03878879547119, "step": 128000}
{"episode_reward": 956.1415397698541, "episode": 129.0, "batch_reward": 0.9377848539948463, "critic_loss": 0.6010219394862651, "actor_loss": -95.62942601013184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.075711250305176, "step": 129000}
{"episode_reward": 959.9068640604858, "episode": 130.0, "batch_reward": 0.9382271820902824, "critic_loss": 0.6751825318336487, "actor_loss": -95.63979858398437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.019278049468994, "step": 130000}
{"episode_reward": 990.461964894239, "episode": 131.0, "batch_reward": 0.9389208614826202, "critic_loss": 0.6311775071769953, "actor_loss": -95.66709147644043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.32072353363037, "step": 131000}
{"episode_reward": 974.3391300824516, "episode": 132.0, "batch_reward": 0.9384820917844773, "critic_loss": 0.589078568726778, "actor_loss": -95.65318151855469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.044986724853516, "step": 132000}
{"episode_reward": 962.8253828774855, "episode": 133.0, "batch_reward": 0.9383549815416337, "critic_loss": 0.641607486128807, "actor_loss": -95.65187866210937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.068610191345215, "step": 133000}
{"episode_reward": 959.9475875598966, "episode": 134.0, "batch_reward": 0.9384168301224709, "critic_loss": 0.609958795979619, "actor_loss": -95.67386492919921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.011454105377197, "step": 134000}
{"episode_reward": 965.620508654213, "episode": 135.0, "batch_reward": 0.9402482925057412, "critic_loss": 0.5993006433099508, "actor_loss": -95.71652308654785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.023162603378296, "step": 135000}
{"episode_reward": 993.1610870863531, "episode": 136.0, "batch_reward": 0.9398636030554771, "critic_loss": 0.590075233027339, "actor_loss": -95.78171936035156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.044745206832886, "step": 136000}
{"episode_reward": 985.4897526123265, "episode": 137.0, "batch_reward": 0.9388213591575623, "critic_loss": 0.5966036660820245, "actor_loss": -95.70180665588379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.02478265762329, "step": 137000}
{"episode_reward": 947.9346467571809, "episode": 138.0, "batch_reward": 0.9408144094347953, "critic_loss": 0.5942369995713234, "actor_loss": -95.6149799194336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04914879798889, "step": 138000}
{"episode_reward": 954.4326076404262, "episode": 139.0, "batch_reward": 0.9391968838572502, "critic_loss": 0.62462651078403, "actor_loss": -95.63440264892579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.271016597747803, "step": 139000}
{"episode_reward": 986.5193878346312, "episode": 140.0, "batch_reward": 0.9404321801066399, "critic_loss": 0.6003465416580439, "actor_loss": -95.63032051086425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.210777044296265, "step": 140000}
{"episode_reward": 913.8339122153257, "episode": 141.0, "batch_reward": 0.9408962935209274, "critic_loss": 0.6148363551348448, "actor_loss": -95.69851123046875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.35876488685608, "step": 141000}
{"episode_reward": 959.155259988318, "episode": 142.0, "batch_reward": 0.9406083471775055, "critic_loss": 0.6378082358986139, "actor_loss": -95.71118676757813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.048438787460327, "step": 142000}
{"episode_reward": 989.5943941035857, "episode": 143.0, "batch_reward": 0.9408783619999885, "critic_loss": 0.5877020044624806, "actor_loss": -95.76229866027832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.064552545547485, "step": 143000}
{"episode_reward": 940.2444579411089, "episode": 144.0, "batch_reward": 0.9405174059867859, "critic_loss": 0.6308680566698313, "actor_loss": -95.73814016723632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06997513771057, "step": 144000}
{"episode_reward": 903.2355219279025, "episode": 145.0, "batch_reward": 0.9408954415917397, "critic_loss": 0.6427380091398954, "actor_loss": -95.75070236206055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.079190015792847, "step": 145000}
{"episode_reward": 987.5756024313808, "episode": 146.0, "batch_reward": 0.9404402660131455, "critic_loss": 0.6410680417343975, "actor_loss": -95.72743603515624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05084466934204, "step": 146000}
{"episode_reward": 947.5202533916163, "episode": 147.0, "batch_reward": 0.9401573670506478, "critic_loss": 0.6606120355278253, "actor_loss": -95.79391091918946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.0535626411438, "step": 147000}
{"episode_reward": 925.5916524261968, "episode": 148.0, "batch_reward": 0.9413534708023071, "critic_loss": 0.664982970520854, "actor_loss": -95.77460633850097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.071142196655273, "step": 148000}
{"episode_reward": 976.9405250526532, "episode": 149.0, "batch_reward": 0.9397758689522743, "critic_loss": 0.6829359127879143, "actor_loss": -95.7644310760498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05974817276001, "step": 149000}
{"episode_reward": 919.4008339247936, "episode": 150.0, "batch_reward": 0.9392689406275749, "critic_loss": 0.6826250949949026, "actor_loss": -95.69537832641602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
