{"episode": 1.0, "duration": 20.348299264907837, "episode_reward": 59.660092495208936, "step": 1000}
{"episode": 2.0, "duration": 1.778794288635254, "episode_reward": 890.1817750618746, "step": 2000}
{"episode": 3.0, "batch_reward": 0.4933139555610868, "critic_loss": 1.1201134830584085, "actor_loss": -84.94022911593837, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 74.57250308990479, "episode_reward": 676.4688274013813, "step": 3000}
{"episode": 4.0, "batch_reward": 0.5719050363898277, "critic_loss": 1.645827233672142, "actor_loss": -87.04239308166504, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 24.772259950637817, "episode_reward": 864.3144357151091, "step": 4000}
{"episode": 5.0, "batch_reward": 0.6568608043193818, "critic_loss": 1.6439009915590286, "actor_loss": -89.06652439880371, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 24.84370231628418, "episode_reward": 956.8895214236966, "step": 5000}
{"episode": 6.0, "batch_reward": 0.7073852464556694, "critic_loss": 1.597224671661854, "actor_loss": -90.32439131164551, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 24.74942684173584, "episode_reward": 888.6911836229517, "step": 6000}
{"episode": 7.0, "batch_reward": 0.7201772028207779, "critic_loss": 1.7987893334627152, "actor_loss": -90.6110249786377, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 24.737328052520752, "episode_reward": 738.0413120923216, "step": 7000}
{"episode": 8.0, "batch_reward": 0.7278408574461936, "critic_loss": 2.3109303306341173, "actor_loss": -90.70790446472168, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.166107892990112, "episode_reward": 780.8970325954649, "step": 8000}
{"episode": 9.0, "batch_reward": 0.7397807899713517, "critic_loss": 2.4518927257061005, "actor_loss": -90.95051455688477, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.04970669746399, "episode_reward": 937.6048430127154, "step": 9000}
{"episode": 10.0, "batch_reward": 0.759775353372097, "critic_loss": 2.8554746874570847, "actor_loss": -86.76662139892578, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 4542.806009054184, "episode_reward": 920.5600666975251, "step": 10000}
{"episode": 11.0, "batch_reward": 0.7747957220673561, "critic_loss": 2.9864152987003325, "actor_loss": -87.50599722290039, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 45.05436635017395, "episode_reward": 840.1703204553362, "step": 11000}
{"episode": 12.0, "batch_reward": 0.7588968384861946, "critic_loss": 3.686626987695694, "actor_loss": -85.47315406799316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 533.0505142211914, "episode_reward": 448.6404412358075, "step": 12000}
{"episode": 13.0, "batch_reward": 0.7445351244807243, "critic_loss": 3.9379595165252685, "actor_loss": -85.12123054504394, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.482346773147583, "episode_reward": 651.6388406540971, "step": 13000}
{"episode": 14.0, "batch_reward": 0.743461971461773, "critic_loss": 4.506319513559341, "actor_loss": -83.07476005554199, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 533.7286837100983, "episode_reward": 751.9819080015955, "step": 14000}
{"episode": 15.0, "batch_reward": 0.7410452671051025, "critic_loss": 4.82601285815239, "actor_loss": -82.96676495361328, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.547656059265137, "episode_reward": 708.0794551894011, "step": 15000}
{"episode": 16.0, "batch_reward": 0.7368954244852066, "critic_loss": 5.000286182641983, "actor_loss": -80.74895484924316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 529.3353736400604, "episode_reward": 745.6678598599605, "step": 16000}
{"episode": 17.0, "batch_reward": 0.7390333223938942, "critic_loss": 5.095569422960281, "actor_loss": -80.89515390014648, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.433160543441772, "episode_reward": 678.8127541148519, "step": 17000}
{"episode": 18.0, "batch_reward": 0.7362205007076263, "critic_loss": 5.307289504289627, "actor_loss": -79.77417294311523, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 507.8394250869751, "episode_reward": 783.0113621925447, "step": 18000}
{"episode": 19.0, "batch_reward": 0.7402253078222275, "critic_loss": 5.475882684230805, "actor_loss": -79.99939311218262, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.52571153640747, "episode_reward": 687.0283647916555, "step": 19000}
{"episode": 20.0, "batch_reward": 0.7353908812403679, "critic_loss": 5.8287329161167145, "actor_loss": -78.97987727355957, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 523.9639899730682, "episode_reward": 720.5303623159111, "step": 20000}
{"episode": 21.0, "batch_reward": 0.7380552006959915, "critic_loss": 5.816971803665161, "actor_loss": -79.13408168029785, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 44.195544719696045, "episode_reward": 744.3102629772367, "step": 21000}
{"episode": 22.0, "batch_reward": 0.7389772698879242, "critic_loss": 5.707088941574097, "actor_loss": -79.06179859924316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 523.0806307792664, "episode_reward": 880.9492905572696, "step": 22000}
{"episode": 23.0, "batch_reward": 0.745838927090168, "critic_loss": 5.147689811229705, "actor_loss": -79.42800291442872, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.47518801689148, "episode_reward": 885.1434226387279, "step": 23000}
{"episode": 24.0, "batch_reward": 0.750656860589981, "critic_loss": 4.644330499887467, "actor_loss": -78.95232766723633, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 523.9754951000214, "episode_reward": 856.862463005819, "step": 24000}
{"episode": 25.0, "batch_reward": 0.755445756316185, "critic_loss": 4.2338360171318055, "actor_loss": -79.23914433288574, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.33747100830078, "episode_reward": 823.9382676841964, "step": 25000}
{"episode": 26.0, "batch_reward": 0.7570189005732536, "critic_loss": 3.966552614927292, "actor_loss": -78.58639265441894, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 499.6929862499237, "episode_reward": 773.2748228213537, "step": 26000}
{"episode": 27.0, "batch_reward": 0.759201163828373, "critic_loss": 3.834774574756622, "actor_loss": -78.72688938903809, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 24.426393032073975, "episode_reward": 870.7993021630441, "step": 27000}
{"episode": 28.0, "batch_reward": 0.7595413138866425, "critic_loss": 3.7210069103240966, "actor_loss": -78.4535493774414, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 461.4967565536499, "episode_reward": 837.1789762562817, "step": 28000}
{"episode": 29.0, "batch_reward": 0.7679184074997902, "critic_loss": 3.641321160197258, "actor_loss": -78.7380166015625, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.256710052490234, "episode_reward": 916.3028662718452, "step": 29000}
{"episode": 30.0, "batch_reward": 0.7698064860105515, "critic_loss": 3.9317670285701753, "actor_loss": -77.89983810424805, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 487.4504358768463, "episode_reward": 872.0408195459191, "step": 30000}
{"episode": 31.0, "batch_reward": 0.7759074670672417, "critic_loss": 3.894247726917267, "actor_loss": -78.21809858703614, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 44.91738247871399, "episode_reward": 931.9837072764764, "step": 31000}
{"episode": 32.0, "batch_reward": 0.7795125756263733, "critic_loss": 3.956197571516037, "actor_loss": -77.02661157226562, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 457.55094623565674, "episode_reward": 881.3543563686889, "step": 32000}
{"episode": 33.0, "batch_reward": 0.782042088329792, "critic_loss": 4.213400120019913, "actor_loss": -77.17290296936035, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.226473808288574, "episode_reward": 920.5734107128919, "step": 33000}
{"episode": 34.0, "batch_reward": 0.7889298999905586, "critic_loss": 4.500981175661087, "actor_loss": -76.92503907775878, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 481.61695432662964, "episode_reward": 972.4186688029708, "step": 34000}
{"episode": 35.0, "batch_reward": 0.7913828635811806, "critic_loss": 4.846511472940445, "actor_loss": -77.08234568786621, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.862004041671753, "episode_reward": 865.5123509261814, "step": 35000}
{"episode": 36.0, "batch_reward": 0.7933061965107918, "critic_loss": 4.660443357467651, "actor_loss": -76.09015390014649, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 496.93046712875366, "episode_reward": 922.6167040322105, "step": 36000}
{"episode": 37.0, "batch_reward": 0.7968717460632324, "critic_loss": 4.529367398977279, "actor_loss": -76.37477209472657, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.21519660949707, "episode_reward": 871.6358825086849, "step": 37000}
{"episode": 38.0, "batch_reward": 0.8001087709665299, "critic_loss": 4.701799988031388, "actor_loss": -75.06014451599121, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 474.15348386764526, "episode_reward": 909.9442489967107, "step": 38000}
{"episode": 39.0, "batch_reward": 0.8030823682546615, "critic_loss": 4.806371891260147, "actor_loss": -75.41609747314453, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.644153594970703, "episode_reward": 939.0513441756956, "step": 39000}
{"episode": 40.0, "batch_reward": 0.8062183819413186, "critic_loss": 4.75543416762352, "actor_loss": -74.87222540283203, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 504.6216857433319, "episode_reward": 852.5823265066259, "step": 40000}
{"episode": 41.0, "batch_reward": 0.8040831453204155, "critic_loss": 5.118668967485428, "actor_loss": -74.9307283630371, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.97781157493591, "episode_reward": 837.1629461206662, "step": 41000}
{"episode": 42.0, "batch_reward": 0.8074893640875817, "critic_loss": 4.973677899599076, "actor_loss": -74.30847193908691, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 456.7840521335602, "episode_reward": 919.3933168196719, "step": 42000}
{"episode": 43.0, "batch_reward": 0.8106502103805542, "critic_loss": 5.028152683258057, "actor_loss": -74.53049267578125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.658656358718872, "episode_reward": 917.3908542517885, "step": 43000}
{"episode": 44.0, "batch_reward": 0.8146775462031365, "critic_loss": 4.903178091287613, "actor_loss": -74.97684217834473, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 445.39523792266846, "episode_reward": 938.8202497677111, "step": 44000}
{"episode": 45.0, "batch_reward": 0.815507909655571, "critic_loss": 4.698094176292419, "actor_loss": -75.12735093688966, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.471670150756836, "episode_reward": 952.3490824234159, "step": 45000}
{"episode": 46.0, "batch_reward": 0.8191374069452286, "critic_loss": 4.7827250959873195, "actor_loss": -75.3529073638916, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 465.38244557380676, "episode_reward": 966.9982804502507, "step": 46000}
{"episode": 47.0, "batch_reward": 0.8223604085445404, "critic_loss": 4.837909764766693, "actor_loss": -75.50223649597169, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.811269283294678, "episode_reward": 939.7447205419188, "step": 47000}
{"episode": 48.0, "batch_reward": 0.8254367345571518, "critic_loss": 5.249297239542008, "actor_loss": -75.41644061279297, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 443.98610258102417, "episode_reward": 908.059720450427, "step": 48000}
{"episode": 49.0, "batch_reward": 0.8249103408455849, "critic_loss": 5.318744645595551, "actor_loss": -75.57742518615723, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.079256772994995, "episode_reward": 921.6511231528843, "step": 49000}
{"episode": 50.0, "batch_reward": 0.8304902656078339, "critic_loss": 5.315276991128922, "actor_loss": -75.92363668823242, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 466.17312240600586, "episode_reward": 952.1379980946951, "step": 50000}
{"episode": 51.0, "batch_reward": 0.830847663462162, "critic_loss": 5.656945411920548, "actor_loss": -76.00081297302246, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 39.28366947174072, "episode_reward": 923.9424960319111, "step": 51000}
{"episode": 52.0, "batch_reward": 0.8310258502960205, "critic_loss": 5.518897249698639, "actor_loss": -76.50902062988281, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 460.8959457874298, "episode_reward": 830.8711668312527, "step": 52000}
{"episode": 53.0, "batch_reward": 0.8321186243891716, "critic_loss": 5.7961698505878445, "actor_loss": -76.58270050048829, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.87781548500061, "episode_reward": 918.7282326975904, "step": 53000}
{"episode": 54.0, "batch_reward": 0.833193321287632, "critic_loss": 6.0197567541599275, "actor_loss": -76.21330319213867, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 460.6775288581848, "episode_reward": 923.4217457970136, "step": 54000}
{"episode": 55.0, "batch_reward": 0.8356001690030098, "critic_loss": 6.071777794837952, "actor_loss": -76.30229638671875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.8317711353302, "episode_reward": 920.6674139716847, "step": 55000}
{"episode": 56.0, "batch_reward": 0.8374306589961052, "critic_loss": 5.989112770795822, "actor_loss": -76.5576552734375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 467.9799883365631, "episode_reward": 964.6295878126888, "step": 56000}
{"episode": 57.0, "batch_reward": 0.8388287517428398, "critic_loss": 6.082742423534393, "actor_loss": -76.69489179992675, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.2075617313385, "episode_reward": 944.8500261245213, "step": 57000}
{"episode": 58.0, "batch_reward": 0.8417528158426285, "critic_loss": 5.841581393241882, "actor_loss": -76.80348851013184, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 463.4340970516205, "episode_reward": 956.916137277248, "step": 58000}
{"episode": 59.0, "batch_reward": 0.8439274439811707, "critic_loss": 5.583739655971527, "actor_loss": -76.94981126403809, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 19.979225635528564, "episode_reward": 900.1683358976995, "step": 59000}
{"episode": 60.0, "batch_reward": 0.8455861836075783, "critic_loss": 5.601782331228256, "actor_loss": -76.87129135131836, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 453.6966242790222, "episode_reward": 949.8464829174644, "step": 60000}
{"episode": 61.0, "batch_reward": 0.84705751901865, "critic_loss": 5.555055421113968, "actor_loss": -77.02881600952148, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.22557830810547, "episode_reward": 956.4120913701286, "step": 61000}
{"episode": 62.0, "batch_reward": 0.8474408126473427, "critic_loss": 5.429646642446518, "actor_loss": -76.55737062072754, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 472.00524497032166, "episode_reward": 967.0936544902953, "step": 62000}
{"episode": 63.0, "batch_reward": 0.8501708263158798, "critic_loss": 5.564670053482056, "actor_loss": -76.67233634948731, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.652596712112427, "episode_reward": 944.6297706498337, "step": 63000}
{"episode": 64.0, "batch_reward": 0.851693450331688, "critic_loss": 5.36152139043808, "actor_loss": -76.45241297912598, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 453.6543562412262, "episode_reward": 978.577218733868, "step": 64000}
{"episode": 65.0, "batch_reward": 0.8543384469747544, "critic_loss": 5.438201317071915, "actor_loss": -76.46692417907715, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 24.98836612701416, "episode_reward": 968.9979620605386, "step": 65000}
{"episode": 66.0, "batch_reward": 0.8549827366471291, "critic_loss": 5.4431645724773405, "actor_loss": -76.03805809020996, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 475.34826588630676, "episode_reward": 919.0509195321004, "step": 66000}
{"episode": 67.0, "batch_reward": 0.8551508738994599, "critic_loss": 5.734163918018341, "actor_loss": -76.09946678161621, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.667826175689697, "episode_reward": 881.0243028263028, "step": 67000}
{"episode": 68.0, "batch_reward": 0.8570482993721962, "critic_loss": 5.922862339258194, "actor_loss": -76.10753265380859, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 445.66754603385925, "episode_reward": 919.8383622680353, "step": 68000}
{"episode": 69.0, "batch_reward": 0.8572984374165535, "critic_loss": 5.842055048942566, "actor_loss": -76.18670767211914, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.800374507904053, "episode_reward": 988.9785084977434, "step": 69000}
{"episode": 70.0, "batch_reward": 0.8560350258946419, "critic_loss": 6.275498853206635, "actor_loss": -76.40004713439941, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 432.08668637275696, "episode_reward": 592.2350416324769, "step": 70000}
{"episode": 71.0, "batch_reward": 0.8557172850370407, "critic_loss": 6.1315208270549775, "actor_loss": -76.54416415405274, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 39.90032982826233, "episode_reward": 935.170408113696, "step": 71000}
{"episode": 72.0, "batch_reward": 0.8562652062773705, "critic_loss": 6.327794584035874, "actor_loss": -76.9821312713623, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 479.6977889537811, "episode_reward": 956.9468834765034, "step": 72000}
{"episode": 73.0, "batch_reward": 0.8594535464644432, "critic_loss": 6.487186758756637, "actor_loss": -77.03267811584473, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.22765302658081, "episode_reward": 962.7267476111206, "step": 73000}
{"episode": 74.0, "batch_reward": 0.8571985257267952, "critic_loss": 7.073900610923767, "actor_loss": -77.15415451049805, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 465.24991035461426, "episode_reward": 740.2787861781695, "step": 74000}
{"episode": 75.0, "batch_reward": 0.8576343503594398, "critic_loss": 7.016560629367828, "actor_loss": -77.23819334411621, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.270045042037964, "episode_reward": 959.0290338813365, "step": 75000}
{"episode": 76.0, "batch_reward": 0.859259790122509, "critic_loss": 6.911523346185684, "actor_loss": -77.61026606750488, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 482.18117451667786, "episode_reward": 890.399633552272, "step": 76000}
{"episode": 77.0, "batch_reward": 0.8596086651682854, "critic_loss": 6.633637821435928, "actor_loss": -77.60942198181152, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.305947303771973, "episode_reward": 960.546975183239, "step": 77000}
{"episode": 78.0, "batch_reward": 0.8617431382536889, "critic_loss": 6.679898634195328, "actor_loss": -78.09234759521485, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 496.3856346607208, "episode_reward": 932.321265156836, "step": 78000}
{"episode": 79.0, "batch_reward": 0.862640331029892, "critic_loss": 6.239719532489777, "actor_loss": -78.1427551574707, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.256961584091187, "episode_reward": 968.6134184698942, "step": 79000}
{"episode": 80.0, "batch_reward": 0.8620512331724167, "critic_loss": 6.119647674083709, "actor_loss": -78.71765650939942, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 467.39338302612305, "episode_reward": 955.3080571936897, "step": 80000}
{"episode": 81.0, "batch_reward": 0.8644370610117912, "critic_loss": 6.212635919332504, "actor_loss": -78.81887083435059, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 44.10742735862732, "episode_reward": 934.0582090532469, "step": 81000}
{"episode": 82.0, "batch_reward": 0.8660025060772896, "critic_loss": 6.121988169193267, "actor_loss": -79.52548724365235, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 472.3351902961731, "episode_reward": 951.1377084427547, "step": 82000}
{"episode": 83.0, "batch_reward": 0.8659879457950592, "critic_loss": 6.025589456796646, "actor_loss": -79.59063890075683, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.522299766540527, "episode_reward": 903.895111072282, "step": 83000}
{"episode": 84.0, "batch_reward": 0.8662765915989876, "critic_loss": 6.071548233509064, "actor_loss": -80.46747396850586, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 492.16807413101196, "episode_reward": 990.699838317868, "step": 84000}
{"episode": 85.0, "batch_reward": 0.8707415436506272, "critic_loss": 6.119764875411987, "actor_loss": -80.57020960998535, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.79267144203186, "episode_reward": 961.5701322482436, "step": 85000}
{"episode": 86.0, "batch_reward": 0.8685667254328727, "critic_loss": 6.441597776412964, "actor_loss": -80.86497192382812, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 474.55751276016235, "episode_reward": 867.4844896606238, "step": 86000}
{"episode": 87.0, "batch_reward": 0.8680010194182396, "critic_loss": 6.635621523618698, "actor_loss": -80.83115731811523, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.22443437576294, "episode_reward": 946.4914317605338, "step": 87000}
{"episode": 88.0, "batch_reward": 0.870093147277832, "critic_loss": 6.535244060993195, "actor_loss": -81.15470477294922, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 442.41005516052246, "episode_reward": 898.7513666473538, "step": 88000}
{"episode": 89.0, "batch_reward": 0.8714315022230148, "critic_loss": 6.571839730262757, "actor_loss": -81.22552334594727, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.336426258087158, "episode_reward": 948.301730370862, "step": 89000}
{"episode": 90.0, "batch_reward": 0.8719390718340874, "critic_loss": 6.831898424863815, "actor_loss": -81.4996729888916, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 467.1731004714966, "episode_reward": 960.1757810020764, "step": 90000}
{"episode": 91.0, "batch_reward": 0.8721962125301361, "critic_loss": 6.645755688428879, "actor_loss": -81.46573020935058, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.87254762649536, "episode_reward": 928.823772367925, "step": 91000}
{"episode": 92.0, "batch_reward": 0.8724935044646263, "critic_loss": 6.4492438786029815, "actor_loss": -81.8587540435791, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.2975652217865, "episode_reward": 955.9936960258038, "step": 92000}
{"episode": 93.0, "batch_reward": 0.8737557502985001, "critic_loss": 6.535383506536483, "actor_loss": -81.89046040344239, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.302960634231567, "episode_reward": 961.5205042232603, "step": 93000}
{"episode": 94.0, "batch_reward": 0.8741159506440163, "critic_loss": 6.977429604530334, "actor_loss": -82.36678926086425, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 426.3943204879761, "episode_reward": 952.4301697734718, "step": 94000}
{"episode": 95.0, "batch_reward": 0.8743459571599961, "critic_loss": 6.901240300178528, "actor_loss": -82.50165434265136, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.028870820999146, "episode_reward": 957.741325918085, "step": 95000}
{"episode": 96.0, "batch_reward": 0.8756884889006614, "critic_loss": 7.00590723657608, "actor_loss": -82.88197779846192, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 463.12885308265686, "episode_reward": 958.2241587312394, "step": 96000}
{"episode": 97.0, "batch_reward": 0.8769098865389824, "critic_loss": 6.919381531000138, "actor_loss": -82.94928718566895, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.232566118240356, "episode_reward": 912.2319637886201, "step": 97000}
{"episode": 98.0, "batch_reward": 0.8775047583580017, "critic_loss": 6.873961828231812, "actor_loss": -82.95238438415528, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 418.8491542339325, "episode_reward": 929.6318409396657, "step": 98000}
{"episode": 99.0, "batch_reward": 0.8789639293551444, "critic_loss": 6.602902858972549, "actor_loss": -83.0482258758545, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.067785263061523, "episode_reward": 944.9165055714695, "step": 99000}
{"episode": 100.0, "batch_reward": 0.8782545218467712, "critic_loss": 6.851849599838257, "actor_loss": -82.74136151123047, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 460.6475577354431, "episode_reward": 937.1698756945432, "step": 100000}
{"episode": 101.0, "batch_reward": 0.8797986723780632, "critic_loss": 6.357591666460038, "actor_loss": -82.81412072753906, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 39.52253007888794, "episode_reward": 985.2850650405628, "step": 101000}
{"episode": 102.0, "batch_reward": 0.8788513459563255, "critic_loss": 6.76110596370697, "actor_loss": -82.59624862670898, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 471.10560417175293, "episode_reward": 830.8229221652441, "step": 102000}
{"episode": 103.0, "batch_reward": 0.8795801442861557, "critic_loss": 6.8128881011009215, "actor_loss": -82.69582160949707, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.45378351211548, "episode_reward": 903.1359295386941, "step": 103000}
{"episode": 104.0, "batch_reward": 0.8804485122561455, "critic_loss": 6.845580820798874, "actor_loss": -82.33650286865235, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 464.1833236217499, "episode_reward": 954.5781929825574, "step": 104000}
{"episode": 105.0, "batch_reward": 0.8804611207246781, "critic_loss": 6.861029134750366, "actor_loss": -82.37344956970215, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 24.617525339126587, "episode_reward": 895.4753303591096, "step": 105000}
{"episode": 106.0, "batch_reward": 0.8803838517665863, "critic_loss": 7.03699919462204, "actor_loss": -81.61524897766114, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 458.3477346897125, "episode_reward": 856.9816630031237, "step": 106000}
{"episode": 107.0, "batch_reward": 0.8813774389624596, "critic_loss": 7.382058683156967, "actor_loss": -81.73365663146973, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.40759825706482, "episode_reward": 956.4792902638687, "step": 107000}
{"episode": 108.0, "batch_reward": 0.8809386023879051, "critic_loss": 7.47052507853508, "actor_loss": -81.6149580230713, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 451.412992477417, "episode_reward": 951.1344245818158, "step": 108000}
{"episode": 109.0, "batch_reward": 0.881616216301918, "critic_loss": 7.607350551366806, "actor_loss": -81.69792013549805, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 24.67471218109131, "episode_reward": 965.9957262648529, "step": 109000}
{"episode": 110.0, "batch_reward": 0.8817752711176873, "critic_loss": 7.801934638500214, "actor_loss": -81.39858078002929, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 444.1667368412018, "episode_reward": 922.4428577738552, "step": 110000}
{"episode": 111.0, "batch_reward": 0.8829713487625122, "critic_loss": 8.006387522220612, "actor_loss": -81.44173669433594, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.570234060287476, "episode_reward": 951.8647429824883, "step": 111000}
{"episode": 112.0, "batch_reward": 0.8848502564430237, "critic_loss": 8.01127551817894, "actor_loss": -81.71569700622558, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 433.10223174095154, "episode_reward": 922.9966551320816, "step": 112000}
{"episode": 113.0, "batch_reward": 0.8813520370721817, "critic_loss": 8.459182201862335, "actor_loss": -81.61797943115235, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.34417724609375, "episode_reward": 885.6755620684147, "step": 113000}
{"episode": 114.0, "batch_reward": 0.8842256705760956, "critic_loss": 8.108989458322524, "actor_loss": -81.7990798034668, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 466.84504652023315, "episode_reward": 977.342854532305, "step": 114000}
{"episode": 115.0, "batch_reward": 0.8856518961191178, "critic_loss": 8.120351934671403, "actor_loss": -81.90184141540527, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.349688291549683, "episode_reward": 910.5584890444193, "step": 115000}
{"episode": 116.0, "batch_reward": 0.8842347364425659, "critic_loss": 8.250832567214966, "actor_loss": -82.42328865051269, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 469.5623896121979, "episode_reward": 955.0568574324335, "step": 116000}
{"episode": 117.0, "batch_reward": 0.8851571750044823, "critic_loss": 8.479811601161957, "actor_loss": -82.52463446044922, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 24.462196350097656, "episode_reward": 889.355951083142, "step": 117000}
{"episode": 118.0, "batch_reward": 0.8864464883208275, "critic_loss": 8.447297269582748, "actor_loss": -82.80758215332031, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 428.82676815986633, "episode_reward": 941.4671979960195, "step": 118000}
{"episode": 119.0, "batch_reward": 0.8868369635939598, "critic_loss": 8.453100688934326, "actor_loss": -82.88805001831055, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.260738372802734, "episode_reward": 945.2730857914964, "step": 119000}
{"episode": 120.0, "batch_reward": 0.8866540281176567, "critic_loss": 9.045430583477021, "actor_loss": -82.90164015197755, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 467.18952536582947, "episode_reward": 887.6742418074004, "step": 120000}
{"episode": 121.0, "batch_reward": 0.8863494091033935, "critic_loss": 8.842100534677506, "actor_loss": -82.93822303771972, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 39.17889189720154, "episode_reward": 973.388194794793, "step": 121000}
{"episode": 122.0, "batch_reward": 0.887488193333149, "critic_loss": 8.821028092622758, "actor_loss": -82.85605708312988, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 437.73801708221436, "episode_reward": 918.5816291140985, "step": 122000}
{"episode": 123.0, "batch_reward": 0.8883957541584968, "critic_loss": 8.767231488227845, "actor_loss": -82.83832579040528, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.47561025619507, "episode_reward": 963.3141899223937, "step": 123000}
{"episode": 124.0, "batch_reward": 0.8879135003089905, "critic_loss": 9.001006960391999, "actor_loss": -82.78469233703613, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.86642575263977, "episode_reward": 954.0071145479874, "step": 124000}
{"episode": 125.0, "batch_reward": 0.8890607198476791, "critic_loss": 9.031471625804901, "actor_loss": -82.96507531738281, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.77376651763916, "episode_reward": 975.9522310286053, "step": 125000}
{"episode": 126.0, "batch_reward": 0.8900692068338394, "critic_loss": 9.147712590694427, "actor_loss": -82.70149288940429, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 451.6213176250458, "episode_reward": 944.5482924554202, "step": 126000}
{"episode": 127.0, "batch_reward": 0.8887314914464951, "critic_loss": 9.19030813217163, "actor_loss": -82.70635487365723, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.12461256980896, "episode_reward": 936.002966973035, "step": 127000}
{"episode": 128.0, "batch_reward": 0.8905221509933472, "critic_loss": 9.211015159606934, "actor_loss": -82.62959715270996, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 438.6856310367584, "episode_reward": 970.2984635380544, "step": 128000}
{"episode": 129.0, "batch_reward": 0.8910809872746468, "critic_loss": 9.763559404373169, "actor_loss": -82.64545158386231, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.408467292785645, "episode_reward": 985.4351745106422, "step": 129000}
{"episode": 130.0, "batch_reward": 0.8922151082158088, "critic_loss": 9.806656635046005, "actor_loss": -82.89667782592774, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 497.5121898651123, "episode_reward": 988.1241380053171, "step": 130000}
{"episode": 131.0, "batch_reward": 0.8926554110646248, "critic_loss": 9.716022327423095, "actor_loss": -82.95800155639648, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 43.413373947143555, "episode_reward": 917.5243498774806, "step": 131000}
{"episode": 132.0, "batch_reward": 0.8931829991936684, "critic_loss": 9.733731971025467, "actor_loss": -83.38918057250977, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 477.4311077594757, "episode_reward": 974.3439945802608, "step": 132000}
{"episode": 133.0, "batch_reward": 0.8926368243098259, "critic_loss": 10.066130610227585, "actor_loss": -83.38518898010254, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.44500470161438, "episode_reward": 959.637255662821, "step": 133000}
{"episode": 134.0, "batch_reward": 0.8915621432065963, "critic_loss": 10.18960583615303, "actor_loss": -83.6849490661621, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 478.21261167526245, "episode_reward": 972.8318538127288, "step": 134000}
{"episode": 135.0, "batch_reward": 0.8952033795118332, "critic_loss": 10.237147407054902, "actor_loss": -83.81251051330567, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.539905548095703, "episode_reward": 991.3036320229529, "step": 135000}
{"episode": 136.0, "batch_reward": 0.8962120973467826, "critic_loss": 10.319151239395142, "actor_loss": -83.69813879394532, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 445.02504444122314, "episode_reward": 988.5293797999354, "step": 136000}
{"episode": 137.0, "batch_reward": 0.8960277255773544, "critic_loss": 10.524906598567963, "actor_loss": -83.77360119628906, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.193490982055664, "episode_reward": 971.5592536769515, "step": 137000}
{"episode": 138.0, "batch_reward": 0.8950302008986473, "critic_loss": 11.131543579816817, "actor_loss": -83.39269595336914, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 446.8973243236542, "episode_reward": 914.657592059145, "step": 138000}
{"episode": 139.0, "batch_reward": 0.8972368902564049, "critic_loss": 11.436280085802078, "actor_loss": -83.61592910766602, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.6029953956604, "episode_reward": 981.403084361738, "step": 139000}
{"episode": 140.0, "batch_reward": 0.8973078641295433, "critic_loss": 11.024566705942155, "actor_loss": -83.4347749633789, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 504.8007619380951, "episode_reward": 959.4650749414955, "step": 140000}
{"episode": 141.0, "batch_reward": 0.8971333464384079, "critic_loss": 11.02110437822342, "actor_loss": -83.42044601440429, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 43.23393750190735, "episode_reward": 961.4365393223055, "step": 141000}
{"episode": 142.0, "batch_reward": 0.8979522967934609, "critic_loss": 11.235609090805054, "actor_loss": -83.62028038024903, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 448.5469844341278, "episode_reward": 984.7127232168053, "step": 142000}
{"episode": 143.0, "batch_reward": 0.8990929859280586, "critic_loss": 11.271567500829697, "actor_loss": -83.72185792541504, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.211512804031372, "episode_reward": 948.1216799901915, "step": 143000}
{"episode": 144.0, "batch_reward": 0.8986991773247719, "critic_loss": 11.65930048441887, "actor_loss": -83.70667221069336, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 414.5465042591095, "episode_reward": 955.438949521642, "step": 144000}
{"episode": 145.0, "batch_reward": 0.898049905538559, "critic_loss": 11.14003946709633, "actor_loss": -83.7302839050293, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.765092849731445, "episode_reward": 982.7900138478661, "step": 145000}
{"episode": 146.0, "batch_reward": 0.8995450482368469, "critic_loss": 11.317786386489868, "actor_loss": -83.78266314697265, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 448.81804513931274, "episode_reward": 959.9565916669895, "step": 146000}
{"episode": 147.0, "batch_reward": 0.900069586455822, "critic_loss": 11.797889785051346, "actor_loss": -83.76864083862304, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.78546643257141, "episode_reward": 933.8308711720279, "step": 147000}
{"episode": 148.0, "batch_reward": 0.9004108966588974, "critic_loss": 11.767815333366395, "actor_loss": -83.77219435119629, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 448.5388181209564, "episode_reward": 910.3197412143096, "step": 148000}
{"episode": 149.0, "batch_reward": 0.9001751940846443, "critic_loss": 12.326453567028045, "actor_loss": -83.77861221313476, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.119093656539917, "episode_reward": 924.109237041752, "step": 149000}
{"episode": 150.0, "batch_reward": 0.9000048179626465, "critic_loss": 12.671145916461944, "actor_loss": -84.05827755737305, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
