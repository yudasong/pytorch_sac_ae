{"episode": 1.0, "duration": 19.632585763931274, "episode_reward": 59.660092495208936, "step": 1000}
{"episode": 2.0, "duration": 1.6959037780761719, "episode_reward": 890.1817750618746, "step": 2000}
{"episode": 3.0, "batch_reward": 0.49512501567274225, "critic_loss": 0.9718546934547564, "actor_loss": -84.90672355978525, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 82.42407488822937, "episode_reward": 857.1185210789808, "step": 3000}
{"episode": 4.0, "batch_reward": 0.6255850393176079, "critic_loss": 1.5773217984437942, "actor_loss": -87.8445234375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 26.00239658355713, "episode_reward": 795.6842616461573, "step": 4000}
{"episode": 5.0, "batch_reward": 0.6758782247900963, "critic_loss": 2.0171300369501113, "actor_loss": -88.88933317565917, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.954396963119507, "episode_reward": 882.1606657758826, "step": 5000}
{"episode": 6.0, "batch_reward": 0.6897267681956292, "critic_loss": 2.2358456466197967, "actor_loss": -89.4496460571289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 26.038066625595093, "episode_reward": 752.1286956450334, "step": 6000}
{"episode": 7.0, "batch_reward": 0.7128679433465004, "critic_loss": 2.502235497713089, "actor_loss": -89.99102618408203, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 26.018954753875732, "episode_reward": 845.2521727756391, "step": 7000}
{"episode": 8.0, "batch_reward": 0.7319199020266532, "critic_loss": 2.709119848370552, "actor_loss": -90.19252976989746, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.996865272521973, "episode_reward": 840.6648367708937, "step": 8000}
{"episode": 9.0, "batch_reward": 0.7374888517260552, "critic_loss": 3.309384244084358, "actor_loss": -90.0422660369873, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.9032039642334, "episode_reward": 770.3890912764987, "step": 9000}
{"episode": 10.0, "batch_reward": 0.7441325505971909, "critic_loss": 3.683967422246933, "actor_loss": -87.08100381469727, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 4370.713536262512, "episode_reward": 847.169368732971, "step": 10000}
{"episode": 11.0, "batch_reward": 0.7622449322342872, "critic_loss": 3.4637497019767762, "actor_loss": -87.53519386291504, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.02809715270996, "episode_reward": 964.9452795409304, "step": 11000}
{"episode": 12.0, "batch_reward": 0.7781975411772728, "critic_loss": 3.262464557170868, "actor_loss": -86.07695727539063, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 488.8237042427063, "episode_reward": 920.9958044190904, "step": 12000}
{"episode": 13.0, "batch_reward": 0.7882668342590332, "critic_loss": 3.1002146490812303, "actor_loss": -86.50536058044433, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.34479069709778, "episode_reward": 933.3912680036503, "step": 13000}
{"episode": 14.0, "batch_reward": 0.80321364402771, "critic_loss": 2.96692163169384, "actor_loss": -86.04108151245117, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 461.09917736053467, "episode_reward": 981.3278318862446, "step": 14000}
{"episode": 15.0, "batch_reward": 0.8143708614706993, "critic_loss": 3.1065076264142992, "actor_loss": -86.49517457580566, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.20650625228882, "episode_reward": 976.8244689405456, "step": 15000}
{"episode": 16.0, "batch_reward": 0.8202286583781242, "critic_loss": 3.2282953630685807, "actor_loss": -86.11040603637696, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 461.0378439426422, "episode_reward": 900.1338305967603, "step": 16000}
{"episode": 17.0, "batch_reward": 0.8282311996221542, "critic_loss": 3.5606376352310183, "actor_loss": -86.49933055114747, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.2172634601593, "episode_reward": 927.597720040433, "step": 17000}
{"episode": 18.0, "batch_reward": 0.8327868965864181, "critic_loss": 3.7883469390869142, "actor_loss": -86.41645162963867, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 423.98602414131165, "episode_reward": 938.067837294689, "step": 18000}
{"episode": 19.0, "batch_reward": 0.8407090354561806, "critic_loss": 4.124764104604721, "actor_loss": -86.68277255249023, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.19064998626709, "episode_reward": 972.2896564151451, "step": 19000}
{"episode": 20.0, "batch_reward": 0.847666051030159, "critic_loss": 5.601178800344467, "actor_loss": -86.84556280517577, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 446.31468057632446, "episode_reward": 960.2715324580481, "step": 20000}
{"episode": 21.0, "batch_reward": 0.853100167632103, "critic_loss": 8.906420857667923, "actor_loss": -87.10849017333985, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.368528842926025, "episode_reward": 954.5050783684244, "step": 21000}
{"episode": 22.0, "batch_reward": 0.8561223923563958, "critic_loss": 22.845934027671813, "actor_loss": -87.42660705566406, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 428.7888913154602, "episode_reward": 915.1996805287097, "step": 22000}
{"episode": 23.0, "batch_reward": 0.8572265664339066, "critic_loss": 58.05275807857513, "actor_loss": -88.56468473815917, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.173784255981445, "episode_reward": 685.1725292591091, "step": 23000}
{"episode": 24.0, "batch_reward": 0.8403712902665138, "critic_loss": 112.93703072738647, "actor_loss": -89.62771243286133, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 447.6782100200653, "episode_reward": 355.14794175996764, "step": 24000}
{"episode": 25.0, "batch_reward": 0.8200655190348625, "critic_loss": 160.93412621307374, "actor_loss": -93.36190577697754, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.841893196105957, "episode_reward": 274.6152147524995, "step": 25000}
{"episode": 26.0, "batch_reward": 0.7942837457656861, "critic_loss": 239.9875393676758, "actor_loss": -98.75919274902344, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 431.12877011299133, "episode_reward": 114.83038922839921, "step": 26000}
{"episode": 27.0, "batch_reward": 0.7698382628560066, "critic_loss": 326.9651446685791, "actor_loss": -107.20683070373535, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.504543781280518, "episode_reward": 208.4440460823184, "step": 27000}
{"episode": 28.0, "batch_reward": 0.751890629529953, "critic_loss": 376.02083882141113, "actor_loss": -117.34006214904785, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 479.74324321746826, "episode_reward": 198.98624759388022, "step": 28000}
{"episode": 29.0, "batch_reward": 0.7329736738801003, "critic_loss": 385.8232600250244, "actor_loss": -127.07714833068847, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.631549835205078, "episode_reward": 158.56988009770703, "step": 29000}
{"episode": 30.0, "batch_reward": 0.7094220489859581, "critic_loss": 372.3009276123047, "actor_loss": -135.7062032775879, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 443.1729645729065, "episode_reward": 149.82228858170825, "step": 30000}
{"episode": 31.0, "batch_reward": 0.6912813491821289, "critic_loss": 335.93093118286134, "actor_loss": -143.5671628417969, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.9963219165802, "episode_reward": 108.55656029494291, "step": 31000}
{"episode": 32.0, "batch_reward": 0.6706147525906563, "critic_loss": 274.44552804565427, "actor_loss": -150.3229781188965, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 419.225958108902, "episode_reward": 258.20723600500764, "step": 32000}
{"episode": 33.0, "batch_reward": 0.6717126871943474, "critic_loss": 230.24689701080322, "actor_loss": -155.65956869506837, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.52636456489563, "episode_reward": 880.5893625675797, "step": 33000}
{"episode": 34.0, "batch_reward": 0.6802260252833366, "critic_loss": 200.11642307281494, "actor_loss": -159.396393951416, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 440.99298334121704, "episode_reward": 864.7305852146237, "step": 34000}
{"episode": 35.0, "batch_reward": 0.6836420965194702, "critic_loss": 188.7002618637085, "actor_loss": -162.32388662719725, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.40773606300354, "episode_reward": 891.2470896958308, "step": 35000}
{"episode": 36.0, "batch_reward": 0.6899038350582123, "critic_loss": 172.47018208312988, "actor_loss": -165.12099380493163, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 423.912086725235, "episode_reward": 861.1606490928625, "step": 36000}
{"episode": 37.0, "batch_reward": 0.692567599594593, "critic_loss": 150.5497898712158, "actor_loss": -167.34834881591797, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.443689107894897, "episode_reward": 924.9286422008081, "step": 37000}
{"episode": 38.0, "batch_reward": 0.6997024642825127, "critic_loss": 134.02058097076417, "actor_loss": -169.43397521972656, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 450.0486915111542, "episode_reward": 953.0774033286511, "step": 38000}
{"episode": 39.0, "batch_reward": 0.707641795873642, "critic_loss": 117.50091486358643, "actor_loss": -172.00150192260742, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.532991886138916, "episode_reward": 940.6631857327312, "step": 39000}
{"episode": 40.0, "batch_reward": 0.7165253261327743, "critic_loss": 102.45338949203492, "actor_loss": -173.65613958740235, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 476.80726313591003, "episode_reward": 986.2232782806218, "step": 40000}
{"episode": 41.0, "batch_reward": 0.7141931410431862, "critic_loss": 93.22914256286622, "actor_loss": -175.27591220092773, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.84686326980591, "episode_reward": 617.8182004868838, "step": 41000}
{"episode": 42.0, "batch_reward": 0.7172873572707176, "critic_loss": 87.56656841278077, "actor_loss": -177.20274978637696, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 433.3003890514374, "episode_reward": 935.731882452106, "step": 42000}
{"episode": 43.0, "batch_reward": 0.7182856660485267, "critic_loss": 86.69672757339478, "actor_loss": -178.58117449951172, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.50557518005371, "episode_reward": 674.1876050594362, "step": 43000}
{"episode": 44.0, "batch_reward": 0.7207455217242241, "critic_loss": 85.88097317886353, "actor_loss": -179.3560389404297, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 447.62842202186584, "episode_reward": 893.5400340637933, "step": 44000}
{"episode": 45.0, "batch_reward": 0.7141640442609787, "critic_loss": 85.9565865097046, "actor_loss": -180.43004409790038, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.674979209899902, "episode_reward": 25.04731081018013, "step": 45000}
{"episode": 46.0, "batch_reward": 0.700913560450077, "critic_loss": 82.09782225227356, "actor_loss": -181.30905084228516, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 424.037579536438, "episode_reward": 34.615703827813746, "step": 46000}
{"episode": 47.0, "batch_reward": 0.6858635113835335, "critic_loss": 84.28404187011719, "actor_loss": -182.5279591064453, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.321460485458374, "episode_reward": 37.743799366512995, "step": 47000}
{"episode": 48.0, "batch_reward": 0.6734868523478508, "critic_loss": 85.67408555984497, "actor_loss": -183.68666586303712, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 449.49880194664, "episode_reward": 85.12558708415416, "step": 48000}
{"episode": 49.0, "batch_reward": 0.6608680147528648, "critic_loss": 86.18444940185547, "actor_loss": -186.0492551574707, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.59705948829651, "episode_reward": 97.04002177026157, "step": 49000}
{"episode": 50.0, "batch_reward": 0.649174529671669, "critic_loss": 85.83152070617676, "actor_loss": -188.58621276855467, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 465.9190413951874, "episode_reward": 81.71638289876499, "step": 50000}
{"episode": 51.0, "batch_reward": 0.6388338589072228, "critic_loss": 91.24487324142456, "actor_loss": -191.94920504760742, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.578840494155884, "episode_reward": 86.86893513604564, "step": 51000}
{"episode": 52.0, "batch_reward": 0.6265552108883857, "critic_loss": 109.8487785949707, "actor_loss": -197.32832507324218, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 442.39084482192993, "episode_reward": 79.95600195712329, "step": 52000}
{"episode": 53.0, "batch_reward": 0.6170660850405693, "critic_loss": 132.3856887512207, "actor_loss": -206.33975192260743, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.760098695755005, "episode_reward": 56.487544085197975, "step": 53000}
{"episode": 54.0, "batch_reward": 0.6067216527760029, "critic_loss": 162.85695288085938, "actor_loss": -217.6528158569336, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 446.276957988739, "episode_reward": 42.29503679889856, "step": 54000}
{"episode": 55.0, "batch_reward": 0.5956668271422386, "critic_loss": 197.9044888458252, "actor_loss": -231.47773379516602, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.92877697944641, "episode_reward": 129.30614727112834, "step": 55000}
{"episode": 56.0, "batch_reward": 0.5871124344468117, "critic_loss": 211.66416073608397, "actor_loss": -245.4144317626953, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 455.94333267211914, "episode_reward": 59.48083922456429, "step": 56000}
{"episode": 57.0, "batch_reward": 0.5802688957452774, "critic_loss": 225.23835748291015, "actor_loss": -259.12393740844726, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.763221502304077, "episode_reward": 290.58107601845745, "step": 57000}
{"episode": 58.0, "batch_reward": 0.5762394183278083, "critic_loss": 217.06030319976807, "actor_loss": -271.6093558959961, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 435.87715005874634, "episode_reward": 290.28144127013115, "step": 58000}
{"episode": 59.0, "batch_reward": 0.5712786112725735, "critic_loss": 205.5059467086792, "actor_loss": -280.40633953857423, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.38335871696472, "episode_reward": 241.79114087143486, "step": 59000}
{"episode": 60.0, "batch_reward": 0.5637352750003338, "critic_loss": 190.68936923217774, "actor_loss": -285.540685546875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 472.87493801116943, "episode_reward": 75.08456348321177, "step": 60000}
{"episode": 61.0, "batch_reward": 0.5571978880167008, "critic_loss": 173.07761283874513, "actor_loss": -287.393486328125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.57206749916077, "episode_reward": 377.69071408931404, "step": 61000}
{"episode": 62.0, "batch_reward": 0.5576693203747273, "critic_loss": 148.02643082427977, "actor_loss": -288.01467028808594, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 463.34477162361145, "episode_reward": 965.5069205558043, "step": 62000}
{"episode": 63.0, "batch_reward": 0.564762099057436, "critic_loss": 121.3128525543213, "actor_loss": -288.5688895263672, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.527657747268677, "episode_reward": 922.1184526529264, "step": 63000}
{"episode": 64.0, "batch_reward": 0.5741042313575745, "critic_loss": 96.30271411132813, "actor_loss": -287.9874528198242, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.17954564094543, "episode_reward": 983.4017853527889, "step": 64000}
{"episode": 65.0, "batch_reward": 0.5738909607231617, "critic_loss": 78.69057783126831, "actor_loss": -285.35635955810545, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.48578119277954, "episode_reward": 950.164232004954, "step": 65000}
{"episode": 66.0, "batch_reward": 0.5822978883087635, "critic_loss": 64.95675267410279, "actor_loss": -282.5565995483398, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 447.0762565135956, "episode_reward": 934.368629268529, "step": 66000}
{"episode": 67.0, "batch_reward": 0.5846602573096752, "critic_loss": 52.489321285247804, "actor_loss": -278.8545227661133, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.762443780899048, "episode_reward": 846.2907627478853, "step": 67000}
{"episode": 68.0, "batch_reward": 0.5928563109934329, "critic_loss": 39.59988118362427, "actor_loss": -275.0337708129883, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 498.405287027359, "episode_reward": 942.4915758761996, "step": 68000}
{"episode": 69.0, "batch_reward": 0.5969345920681953, "critic_loss": 30.418063666343688, "actor_loss": -271.5327141723633, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.44889545440674, "episode_reward": 973.1851353353849, "step": 69000}
{"episode": 70.0, "batch_reward": 0.6006931073367595, "critic_loss": 25.050738063812254, "actor_loss": -267.646878112793, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 442.62251472473145, "episode_reward": 878.4731718965905, "step": 70000}
{"episode": 71.0, "batch_reward": 0.6047162245512009, "critic_loss": 19.84658037662506, "actor_loss": -263.51230889892577, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.309621810913086, "episode_reward": 904.5171278690864, "step": 71000}
{"episode": 72.0, "batch_reward": 0.6112548207938671, "critic_loss": 16.436621481895447, "actor_loss": -259.5019405822754, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 479.0937850475311, "episode_reward": 965.1279207295825, "step": 72000}
{"episode": 73.0, "batch_reward": 0.6178725345730781, "critic_loss": 14.32982855463028, "actor_loss": -255.25176022338866, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.60105586051941, "episode_reward": 939.9456180256246, "step": 73000}
{"episode": 74.0, "batch_reward": 0.6210153540074825, "critic_loss": 12.594268705368043, "actor_loss": -250.9614077758789, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 442.26415061950684, "episode_reward": 890.6868009772011, "step": 74000}
{"episode": 75.0, "batch_reward": 0.6227304941117764, "critic_loss": 10.983549988746644, "actor_loss": -246.2460023803711, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.313941955566406, "episode_reward": 966.3100269064319, "step": 75000}
{"episode": 76.0, "batch_reward": 0.6273217291235924, "critic_loss": 9.6432586684227, "actor_loss": -241.81060220336914, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 420.7598021030426, "episode_reward": 929.6529197510383, "step": 76000}
{"episode": 77.0, "batch_reward": 0.631770085811615, "critic_loss": 8.179757077455521, "actor_loss": -236.95410095214845, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.24081540107727, "episode_reward": 966.4701390603232, "step": 77000}
{"episode": 78.0, "batch_reward": 0.6385881870388984, "critic_loss": 6.672287091255188, "actor_loss": -232.12808325195311, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 427.2155854701996, "episode_reward": 959.5234739774565, "step": 78000}
{"episode": 79.0, "batch_reward": 0.6399470416903495, "critic_loss": 5.886115403652191, "actor_loss": -227.0840544128418, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.710516452789307, "episode_reward": 958.9412752358887, "step": 79000}
{"episode": 80.0, "batch_reward": 0.6441392467021942, "critic_loss": 4.995521164894104, "actor_loss": -222.39926495361328, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 427.7376425266266, "episode_reward": 976.0478192494695, "step": 80000}
{"episode": 81.0, "batch_reward": 0.6461575367450714, "critic_loss": 4.547915137529373, "actor_loss": -217.45155963134766, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.80838203430176, "episode_reward": 917.6018587091567, "step": 81000}
{"episode": 82.0, "batch_reward": 0.6500394706130028, "critic_loss": 4.045864786863327, "actor_loss": -212.70244567871094, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 430.65688729286194, "episode_reward": 918.5159811261283, "step": 82000}
{"episode": 83.0, "batch_reward": 0.6565040136575699, "critic_loss": 3.6172565438747406, "actor_loss": -208.2642232055664, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.714897394180298, "episode_reward": 919.2942785383258, "step": 83000}
{"episode": 84.0, "batch_reward": 0.6576912876367569, "critic_loss": 3.224568942785263, "actor_loss": -203.81763900756835, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 449.98009419441223, "episode_reward": 985.5909855449071, "step": 84000}
{"episode": 85.0, "batch_reward": 0.6633297842144966, "critic_loss": 2.9129131861925126, "actor_loss": -199.58425579833985, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.42447257041931, "episode_reward": 945.0066091003309, "step": 85000}
{"episode": 86.0, "batch_reward": 0.6675314341783524, "critic_loss": 2.691613018155098, "actor_loss": -195.3965880126953, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 427.91549015045166, "episode_reward": 881.0293687571562, "step": 86000}
{"episode": 87.0, "batch_reward": 0.6703804508447647, "critic_loss": 2.5679032361507415, "actor_loss": -191.29192199707032, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.160922527313232, "episode_reward": 944.4801805229947, "step": 87000}
{"episode": 88.0, "batch_reward": 0.6710600208640098, "critic_loss": 2.060068738758564, "actor_loss": -187.627931640625, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 441.5338897705078, "episode_reward": 937.3696333594878, "step": 88000}
{"episode": 89.0, "batch_reward": 0.6758113790750504, "critic_loss": 1.9612645945549012, "actor_loss": -183.7620641784668, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.64010739326477, "episode_reward": 955.2227457735668, "step": 89000}
{"episode": 90.0, "batch_reward": 0.6793276914954185, "critic_loss": 1.938967402637005, "actor_loss": -180.31823727416992, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 458.4910192489624, "episode_reward": 962.3675290430799, "step": 90000}
{"episode": 91.0, "batch_reward": 0.6803977663516998, "critic_loss": 1.698533378958702, "actor_loss": -176.71410739135743, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.36356854438782, "episode_reward": 947.8786091661842, "step": 91000}
{"episode": 92.0, "batch_reward": 0.6835688232779503, "critic_loss": 1.6902595673799514, "actor_loss": -173.236138671875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 426.2798056602478, "episode_reward": 923.2220187300567, "step": 92000}
{"episode": 93.0, "batch_reward": 0.6838673216700554, "critic_loss": 1.5171983188390732, "actor_loss": -169.9681654663086, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.80047345161438, "episode_reward": 983.5050969831044, "step": 93000}
{"episode": 94.0, "batch_reward": 0.6880527271628379, "critic_loss": 1.445038631439209, "actor_loss": -166.72229833984375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 433.5217730998993, "episode_reward": 933.5940108420778, "step": 94000}
{"episode": 95.0, "batch_reward": 0.6902091856598854, "critic_loss": 1.3675117213726045, "actor_loss": -163.77806408691407, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.802857637405396, "episode_reward": 951.9420180059672, "step": 95000}
{"episode": 96.0, "batch_reward": 0.6935222282409668, "critic_loss": 1.3654695888757706, "actor_loss": -160.93636679077147, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 453.2030885219574, "episode_reward": 880.1029052101385, "step": 96000}
{"episode": 97.0, "batch_reward": 0.6962956610918045, "critic_loss": 1.1729112362861633, "actor_loss": -158.12199923706055, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.516395807266235, "episode_reward": 919.5496439265779, "step": 97000}
{"episode": 98.0, "batch_reward": 0.6980615908503532, "critic_loss": 1.19435500061512, "actor_loss": -155.24649645996095, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 460.53849363327026, "episode_reward": 901.6414964519558, "step": 98000}
{"episode": 99.0, "batch_reward": 0.6991694564819336, "critic_loss": 1.1727689828574657, "actor_loss": -152.7161231689453, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.676413536071777, "episode_reward": 910.7034597084796, "step": 99000}
{"episode": 100.0, "batch_reward": 0.7026490550041199, "critic_loss": 1.203643760561943, "actor_loss": -149.98000061035157, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 414.92644476890564, "episode_reward": 887.7525433462349, "step": 100000}
{"episode": 101.0, "batch_reward": 0.7043471473455429, "critic_loss": 1.08654502800107, "actor_loss": -147.45904891967774, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.12645435333252, "episode_reward": 981.4174069371562, "step": 101000}
{"episode": 102.0, "batch_reward": 0.7074946525096893, "critic_loss": 1.0228067132532597, "actor_loss": -144.9237728881836, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 467.4308590888977, "episode_reward": 941.2750389227826, "step": 102000}
{"episode": 103.0, "batch_reward": 0.7086805460453034, "critic_loss": 1.0026894011199474, "actor_loss": -142.61645526123047, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.42410635948181, "episode_reward": 948.8439193148258, "step": 103000}
{"episode": 104.0, "batch_reward": 0.7130489989519119, "critic_loss": 0.9706731125712394, "actor_loss": -140.4850245361328, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 473.45090436935425, "episode_reward": 936.0123872951544, "step": 104000}
{"episode": 105.0, "batch_reward": 0.7142968747615814, "critic_loss": 0.9839755660891533, "actor_loss": -138.37420343017578, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.902798652648926, "episode_reward": 843.3220952698842, "step": 105000}
{"episode": 106.0, "batch_reward": 0.7181557747721672, "critic_loss": 0.8959671101868153, "actor_loss": -136.3945392150879, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 484.5166440010071, "episode_reward": 941.9228928864624, "step": 106000}
{"episode": 107.0, "batch_reward": 0.7181104458570481, "critic_loss": 0.8860844036638736, "actor_loss": -134.55717834472657, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.47284960746765, "episode_reward": 954.8769815330269, "step": 107000}
{"episode": 108.0, "batch_reward": 0.7201733175516128, "critic_loss": 0.8470733935832977, "actor_loss": -132.7270938720703, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 451.1632401943207, "episode_reward": 944.435775467616, "step": 108000}
{"episode": 109.0, "batch_reward": 0.7220137106180191, "critic_loss": 0.7786206160485745, "actor_loss": -130.89811798095704, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.6015727519989, "episode_reward": 971.2327071998259, "step": 109000}
{"episode": 110.0, "batch_reward": 0.7245984370112419, "critic_loss": 0.7540292268693447, "actor_loss": -129.13203036499024, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 434.74075722694397, "episode_reward": 921.6419144249535, "step": 110000}
{"episode": 111.0, "batch_reward": 0.7254281054139138, "critic_loss": 0.71626951572299, "actor_loss": -127.29454638671875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.78806948661804, "episode_reward": 890.6466184632739, "step": 111000}
{"episode": 112.0, "batch_reward": 0.7300664094686509, "critic_loss": 0.7024672420620919, "actor_loss": -125.67696878051758, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 460.1590552330017, "episode_reward": 920.549985268971, "step": 112000}
{"episode": 113.0, "batch_reward": 0.7300160039067268, "critic_loss": 0.7377116247117519, "actor_loss": -124.05152528381348, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.299752473831177, "episode_reward": 954.2724018982002, "step": 113000}
{"episode": 114.0, "batch_reward": 0.7307281357645988, "critic_loss": 0.764369243323803, "actor_loss": -122.58019627380371, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 443.8564119338989, "episode_reward": 965.8166195186373, "step": 114000}
{"episode": 115.0, "batch_reward": 0.7348584557771682, "critic_loss": 0.7441604986786843, "actor_loss": -121.29443507385254, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.779759645462036, "episode_reward": 939.6216139911755, "step": 115000}
{"episode": 116.0, "batch_reward": 0.7357502961158753, "critic_loss": 0.6749227013587952, "actor_loss": -120.03989924621582, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 463.84858894348145, "episode_reward": 952.1216823303183, "step": 116000}
{"episode": 117.0, "batch_reward": 0.736943685054779, "critic_loss": 0.7487207982242108, "actor_loss": -118.83848616027832, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.318718194961548, "episode_reward": 798.2833010246824, "step": 117000}
{"episode": 118.0, "batch_reward": 0.7379738040566445, "critic_loss": 0.7231550480425358, "actor_loss": -117.6597455291748, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 501.4401352405548, "episode_reward": 984.0164810272071, "step": 118000}
{"episode": 119.0, "batch_reward": 0.7412741231322288, "critic_loss": 0.7008404047787189, "actor_loss": -116.58453425598144, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 24.421189308166504, "episode_reward": 955.9512493943176, "step": 119000}
{"episode": 120.0, "batch_reward": 0.7415725709795952, "critic_loss": 0.6911447809636593, "actor_loss": -115.42740032958984, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 499.85979199409485, "episode_reward": 901.1167200577765, "step": 120000}
{"episode": 121.0, "batch_reward": 0.7436451922655105, "critic_loss": 0.6552367664277553, "actor_loss": -114.3378475189209, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.60231018066406, "episode_reward": 981.6661246018992, "step": 121000}
{"episode": 122.0, "batch_reward": 0.7451365739703179, "critic_loss": 0.6249028345346451, "actor_loss": -113.27861614990235, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 433.9161579608917, "episode_reward": 947.9205241610697, "step": 122000}
{"episode": 123.0, "batch_reward": 0.746447762787342, "critic_loss": 0.6276199035048485, "actor_loss": -112.29957962036133, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.277559518814087, "episode_reward": 942.0886398026221, "step": 123000}
{"episode": 124.0, "batch_reward": 0.7467695451378822, "critic_loss": 0.6330521990656852, "actor_loss": -111.39854342651367, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 477.17320346832275, "episode_reward": 985.7334341647686, "step": 124000}
{"episode": 125.0, "batch_reward": 0.7482658624649048, "critic_loss": 0.6676395669281483, "actor_loss": -110.69334851074218, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.688637256622314, "episode_reward": 982.6330973473072, "step": 125000}
{"episode": 126.0, "batch_reward": 0.7536268679499626, "critic_loss": 0.6521497548222542, "actor_loss": -109.95092497253418, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 463.84190464019775, "episode_reward": 978.1830847551774, "step": 126000}
{"episode": 127.0, "batch_reward": 0.7520861260294914, "critic_loss": 0.6285096786767245, "actor_loss": -109.23294844055175, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.24440097808838, "episode_reward": 916.2532628868455, "step": 127000}
{"episode": 128.0, "batch_reward": 0.7536389744877815, "critic_loss": 0.6060436386615038, "actor_loss": -108.52353631591797, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 455.63442945480347, "episode_reward": 959.4642935244018, "step": 128000}
{"episode": 129.0, "batch_reward": 0.7582301588058472, "critic_loss": 0.5602203387022019, "actor_loss": -108.03911740112305, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.648648738861084, "episode_reward": 984.4010844644009, "step": 129000}
{"episode": 130.0, "batch_reward": 0.7584227974414826, "critic_loss": 0.5553457081466914, "actor_loss": -107.39082481384277, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 430.33744049072266, "episode_reward": 987.1403243951348, "step": 130000}
{"episode": 131.0, "batch_reward": 0.7606671329140663, "critic_loss": 0.5591218158602714, "actor_loss": -106.86676983642577, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.85451412200928, "episode_reward": 957.4243119099189, "step": 131000}
{"episode": 132.0, "batch_reward": 0.7634969348311424, "critic_loss": 0.5575484400242567, "actor_loss": -106.38797883605957, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.8673233985901, "episode_reward": 971.8103688390212, "step": 132000}
{"episode": 133.0, "batch_reward": 0.7630993118286132, "critic_loss": 0.5376339966654777, "actor_loss": -105.71941136169434, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.486586332321167, "episode_reward": 958.7502896610353, "step": 133000}
{"episode": 134.0, "batch_reward": 0.7642064424157142, "critic_loss": 0.5373856163918972, "actor_loss": -105.17972758483887, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 455.9751319885254, "episode_reward": 928.3487133062138, "step": 134000}
{"episode": 135.0, "batch_reward": 0.7648337005376816, "critic_loss": 0.505765930339694, "actor_loss": -104.6380521697998, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.90358018875122, "episode_reward": 990.6798094384087, "step": 135000}
{"episode": 136.0, "batch_reward": 0.7688412190079689, "critic_loss": 0.4751695470809936, "actor_loss": -104.21461958312989, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 447.0773084163666, "episode_reward": 987.0681025741944, "step": 136000}
{"episode": 137.0, "batch_reward": 0.7703151091337204, "critic_loss": 0.4691391964405775, "actor_loss": -103.76600466918946, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.458632946014404, "episode_reward": 981.4399822960027, "step": 137000}
{"episode": 138.0, "batch_reward": 0.7706025124192238, "critic_loss": 0.4818913071453571, "actor_loss": -103.3289829864502, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 458.62272596359253, "episode_reward": 925.7696028751043, "step": 138000}
{"episode": 139.0, "batch_reward": 0.7712641263008118, "critic_loss": 0.4907830009907484, "actor_loss": -102.91167539978028, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.351508378982544, "episode_reward": 970.0019441938873, "step": 139000}
{"episode": 140.0, "batch_reward": 0.7732963970899582, "critic_loss": 0.5144910938441754, "actor_loss": -102.5827015991211, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 431.0985083580017, "episode_reward": 917.6769749700828, "step": 140000}
{"episode": 141.0, "batch_reward": 0.775040678203106, "critic_loss": 0.48621798276901246, "actor_loss": -102.27037606811524, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.76746916770935, "episode_reward": 961.0983952337845, "step": 141000}
{"episode": 142.0, "batch_reward": 0.7747183995842933, "critic_loss": 0.46121616727113723, "actor_loss": -101.83243879699707, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 449.0708472728729, "episode_reward": 988.3765079819987, "step": 142000}
{"episode": 143.0, "batch_reward": 0.7759930120110512, "critic_loss": 0.46437813909351827, "actor_loss": -101.60243159484864, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.4654598236084, "episode_reward": 915.3245421667192, "step": 143000}
{"episode": 144.0, "batch_reward": 0.7777110337615013, "critic_loss": 0.49724176558852196, "actor_loss": -101.24555264282226, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 451.7499225139618, "episode_reward": 928.0940275365979, "step": 144000}
{"episode": 145.0, "batch_reward": 0.7791041511893272, "critic_loss": 0.44221561524271963, "actor_loss": -101.01608460998536, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.534339904785156, "episode_reward": 983.338387058186, "step": 145000}
{"episode": 146.0, "batch_reward": 0.7796942992210388, "critic_loss": 0.4765007056444883, "actor_loss": -100.73950280761719, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 444.26216173171997, "episode_reward": 929.8143972646844, "step": 146000}
{"episode": 147.0, "batch_reward": 0.782235542833805, "critic_loss": 0.4777171399742365, "actor_loss": -100.57128483581543, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.58377432823181, "episode_reward": 956.5055380614139, "step": 147000}
{"episode": 148.0, "batch_reward": 0.7819422179460526, "critic_loss": 0.45301418544352057, "actor_loss": -100.2405085144043, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 450.9151301383972, "episode_reward": 973.8742219582037, "step": 148000}
{"episode": 149.0, "batch_reward": 0.7825228605270386, "critic_loss": 0.4391320369839668, "actor_loss": -99.98764765930176, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 26.624963998794556, "episode_reward": 917.9778478264899, "step": 149000}
{"episode": 150.0, "batch_reward": 0.7852575470209122, "critic_loss": 0.4586739834547043, "actor_loss": -99.83071481323242, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
