{"episode": 1.0, "duration": 20.235525846481323, "episode_reward": 59.660092495208936, "step": 1000}
{"episode": 2.0, "duration": 1.762164831161499, "episode_reward": 890.1817750618746, "step": 2000}
{"episode": 3.0, "batch_reward": 0.49512501567274225, "critic_loss": 0.9718546934547564, "actor_loss": -84.90672355978525, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 87.51540875434875, "episode_reward": 857.1185210789808, "step": 3000}
{"episode": 4.0, "batch_reward": 0.6255850393176079, "critic_loss": 1.5773217984437942, "actor_loss": -87.8445234375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 26.26469922065735, "episode_reward": 795.6842616461573, "step": 4000}
{"episode": 5.0, "batch_reward": 0.6758782247900963, "critic_loss": 2.0171300369501113, "actor_loss": -88.88933317565917, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 26.713731288909912, "episode_reward": 882.1606657758826, "step": 5000}
{"episode": 6.0, "batch_reward": 0.6897267681956292, "critic_loss": 2.2358456466197967, "actor_loss": -89.4496460571289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.888951539993286, "episode_reward": 752.1286956450334, "step": 6000}
{"episode": 7.0, "batch_reward": 0.7128679433465004, "critic_loss": 2.502235497713089, "actor_loss": -89.99102618408203, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.320094347000122, "episode_reward": 845.2521727756391, "step": 7000}
{"episode": 8.0, "batch_reward": 0.7319199020266532, "critic_loss": 2.709119848370552, "actor_loss": -90.19252976989746, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 26.21145462989807, "episode_reward": 840.6648367708937, "step": 8000}
{"episode": 9.0, "batch_reward": 0.7374888517260552, "critic_loss": 3.309384244084358, "actor_loss": -90.0422660369873, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 26.682337522506714, "episode_reward": 770.3890912764987, "step": 9000}
{"episode": 10.0, "batch_reward": 0.7441325505971909, "critic_loss": 3.683967422246933, "actor_loss": -87.08100381469727, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 4061.5873036384583, "episode_reward": 847.169368732971, "step": 10000}
{"episode": 11.0, "batch_reward": 0.7622449322342872, "critic_loss": 3.4637497019767762, "actor_loss": -87.53519386291504, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.14795660972595, "episode_reward": 964.9452795409304, "step": 11000}
{"episode": 12.0, "batch_reward": 0.7781975411772728, "critic_loss": 3.262464557170868, "actor_loss": -86.07695727539063, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 462.0557236671448, "episode_reward": 920.9958044190904, "step": 12000}
{"episode": 13.0, "batch_reward": 0.7882668342590332, "critic_loss": 3.1002146490812303, "actor_loss": -86.50536058044433, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.852524757385254, "episode_reward": 933.3912680036503, "step": 13000}
{"episode": 14.0, "batch_reward": 0.80321364402771, "critic_loss": 2.96692163169384, "actor_loss": -86.04108151245117, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 492.4837374687195, "episode_reward": 981.3278318862446, "step": 14000}
{"episode": 15.0, "batch_reward": 0.8143708614706993, "critic_loss": 3.1065076264142992, "actor_loss": -86.49517457580566, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 26.148844957351685, "episode_reward": 976.8244689405456, "step": 15000}
{"episode": 16.0, "batch_reward": 0.821338917016983, "critic_loss": 3.2850372924804687, "actor_loss": -86.1016037902832, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 442.62666416168213, "episode_reward": 917.0192876445219, "step": 16000}
{"episode": 17.0, "batch_reward": 0.8283260546922684, "critic_loss": 3.6827656877040864, "actor_loss": -86.49321229553223, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.351137399673462, "episode_reward": 887.8746907667065, "step": 17000}
{"episode": 18.0, "batch_reward": 0.8316689198613166, "critic_loss": 4.307797462701798, "actor_loss": -85.98145928955078, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 446.11088037490845, "episode_reward": 939.7991002951755, "step": 18000}
{"episode": 19.0, "batch_reward": 0.8380177079439163, "critic_loss": 4.726154079914093, "actor_loss": -86.23494129943847, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.227632999420166, "episode_reward": 928.9026092608002, "step": 19000}
{"episode": 20.0, "batch_reward": 0.8444915135502815, "critic_loss": 6.318884026765823, "actor_loss": -86.3395225982666, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 443.80712509155273, "episode_reward": 960.4890205241932, "step": 20000}
{"episode": 21.0, "batch_reward": 0.8500487152338028, "critic_loss": 10.477579178571702, "actor_loss": -86.6861806640625, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.4130380153656, "episode_reward": 958.9778557533208, "step": 21000}
{"episode": 22.0, "batch_reward": 0.85336952906847, "critic_loss": 25.173639711380005, "actor_loss": -86.9267325439453, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 443.3965516090393, "episode_reward": 906.9151440928437, "step": 22000}
{"episode": 23.0, "batch_reward": 0.8551093473434448, "critic_loss": 59.21830195617676, "actor_loss": -88.15132542419434, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.9032244682312, "episode_reward": 890.7233226629928, "step": 23000}
{"episode": 24.0, "batch_reward": 0.8551418259143829, "critic_loss": 110.10626665115356, "actor_loss": -89.68105262756347, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.2603883743286, "episode_reward": 717.5702635558509, "step": 24000}
{"episode": 25.0, "batch_reward": 0.8386639012098313, "critic_loss": 156.29135208511352, "actor_loss": -92.92324597167969, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.260327100753784, "episode_reward": 152.47006989349788, "step": 25000}
{"episode": 26.0, "batch_reward": 0.8084814839959145, "critic_loss": 215.73307694244386, "actor_loss": -97.15136042785645, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 428.33514642715454, "episode_reward": 28.078422891412586, "step": 26000}
{"episode": 27.0, "batch_reward": 0.777505711376667, "critic_loss": 281.44046910095216, "actor_loss": -104.19097212219238, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.11175036430359, "episode_reward": 42.160344028044264, "step": 27000}
{"episode": 28.0, "batch_reward": 0.7529328382015228, "critic_loss": 326.65317404174806, "actor_loss": -112.70667178344726, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 452.2117323875427, "episode_reward": 68.75697297884714, "step": 28000}
{"episode": 29.0, "batch_reward": 0.7316529462933541, "critic_loss": 356.2369467315674, "actor_loss": -122.77741119384766, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.95000696182251, "episode_reward": 129.59955314522668, "step": 29000}
{"episode": 30.0, "batch_reward": 0.7073898669481278, "critic_loss": 386.0594652709961, "actor_loss": -133.212342376709, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 449.76607275009155, "episode_reward": 120.9612274670398, "step": 30000}
{"episode": 31.0, "batch_reward": 0.6906449888944626, "critic_loss": 384.5421316986084, "actor_loss": -144.3668956604004, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.85988807678223, "episode_reward": 148.7847135775241, "step": 31000}
{"episode": 32.0, "batch_reward": 0.6722777425050736, "critic_loss": 356.99807344055176, "actor_loss": -154.8046597290039, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 444.1635808944702, "episode_reward": 268.3470203952898, "step": 32000}
{"episode": 33.0, "batch_reward": 0.6648356896042824, "critic_loss": 343.2161569519043, "actor_loss": -163.87933724975585, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.78359580039978, "episode_reward": 562.7704802242083, "step": 33000}
{"episode": 34.0, "batch_reward": 0.6703733520507813, "critic_loss": 337.19447518920896, "actor_loss": -171.37357699584962, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 440.8346462249756, "episode_reward": 926.2243393162273, "step": 34000}
{"episode": 35.0, "batch_reward": 0.6762628201246261, "critic_loss": 287.3912276306152, "actor_loss": -176.41247802734375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.2872314453125, "episode_reward": 865.7979463282076, "step": 35000}
{"episode": 36.0, "batch_reward": 0.678118179321289, "critic_loss": 263.3950691986084, "actor_loss": -180.5001378173828, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 450.8052463531494, "episode_reward": 639.1336599964332, "step": 36000}
{"episode": 37.0, "batch_reward": 0.675956348657608, "critic_loss": 250.787993270874, "actor_loss": -183.3857984008789, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.128021955490112, "episode_reward": 735.2445806046195, "step": 37000}
{"episode": 38.0, "batch_reward": 0.6798588673472404, "critic_loss": 223.33837703704833, "actor_loss": -187.21544595336914, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 465.60472083091736, "episode_reward": 822.2750747364657, "step": 38000}
{"episode": 39.0, "batch_reward": 0.6752594270706177, "critic_loss": 213.45171791839599, "actor_loss": -192.10662509155273, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.425628185272217, "episode_reward": 61.84454966616011, "step": 39000}
{"episode": 40.0, "batch_reward": 0.6711440643072129, "critic_loss": 177.00941362762453, "actor_loss": -193.63984506225586, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 432.62750148773193, "episode_reward": 973.693505234506, "step": 40000}
{"episode": 41.0, "batch_reward": 0.6765974566340447, "critic_loss": 145.35058853912352, "actor_loss": -195.00512857055665, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.535104274749756, "episode_reward": 893.4971642020698, "step": 41000}
{"episode": 42.0, "batch_reward": 0.6792274200320244, "critic_loss": 119.40556942367553, "actor_loss": -196.39167248535156, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 455.2449493408203, "episode_reward": 801.8865515324146, "step": 42000}
{"episode": 43.0, "batch_reward": 0.685184379696846, "critic_loss": 93.9800608253479, "actor_loss": -196.32046493530274, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.115548372268677, "episode_reward": 890.5607776286563, "step": 43000}
{"episode": 44.0, "batch_reward": 0.6903476856350899, "critic_loss": 69.83391077041625, "actor_loss": -195.77357958984376, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 470.1357774734497, "episode_reward": 979.9385455480923, "step": 44000}
{"episode": 45.0, "batch_reward": 0.6964751107692718, "critic_loss": 54.79596584701538, "actor_loss": -194.56996423339845, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.001561880111694, "episode_reward": 950.6246657556304, "step": 45000}
{"episode": 46.0, "batch_reward": 0.7021890694499016, "critic_loss": 44.741212930679325, "actor_loss": -192.94786923217774, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.22209191322327, "episode_reward": 945.5666815711412, "step": 46000}
{"episode": 47.0, "batch_reward": 0.70686287266016, "critic_loss": 39.009366662979126, "actor_loss": -191.34570013427734, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.416001558303833, "episode_reward": 930.2948352117228, "step": 47000}
{"episode": 48.0, "batch_reward": 0.7071334564685822, "critic_loss": 35.075408104896546, "actor_loss": -189.53695391845704, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 452.328809261322, "episode_reward": 285.2534419971685, "step": 48000}
{"episode": 49.0, "batch_reward": 0.6946318563818932, "critic_loss": 32.243825317382814, "actor_loss": -187.89082495117188, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.18948221206665, "episode_reward": 45.03657287361322, "step": 49000}
{"episode": 50.0, "batch_reward": 0.6861323360204696, "critic_loss": 31.37528527736664, "actor_loss": -186.0533876647949, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 455.3225255012512, "episode_reward": 287.38385645085555, "step": 50000}
{"episode": 51.0, "batch_reward": 0.6748493742346764, "critic_loss": 31.134878909111023, "actor_loss": -184.44638751220702, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.986923933029175, "episode_reward": 53.74072335259376, "step": 51000}
{"episode": 52.0, "batch_reward": 0.6621237101554871, "critic_loss": 38.960936111450195, "actor_loss": -183.42016229248046, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 474.48304438591003, "episode_reward": 124.33769351208386, "step": 52000}
{"episode": 53.0, "batch_reward": 0.6520620377063752, "critic_loss": 48.7703325920105, "actor_loss": -183.66575692749024, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.746145248413086, "episode_reward": 112.33161711422652, "step": 53000}
{"episode": 54.0, "batch_reward": 0.6413782522082329, "critic_loss": 64.69199308395386, "actor_loss": -186.7484751586914, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 438.4271008968353, "episode_reward": 55.20231430198874, "step": 54000}
{"episode": 55.0, "batch_reward": 0.6299829088151455, "critic_loss": 82.25598558044433, "actor_loss": -192.3159449157715, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.547526121139526, "episode_reward": 84.19825596668156, "step": 55000}
{"episode": 56.0, "batch_reward": 0.6197653751373291, "critic_loss": 91.13126100540161, "actor_loss": -199.3133151550293, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 457.3013639450073, "episode_reward": 113.06917458177116, "step": 56000}
{"episode": 57.0, "batch_reward": 0.6133150707483291, "critic_loss": 94.93805325317383, "actor_loss": -206.04562200927734, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.610360622406006, "episode_reward": 121.67137347272393, "step": 57000}
{"episode": 58.0, "batch_reward": 0.6043433376252652, "critic_loss": 99.5868123474121, "actor_loss": -213.10129733276366, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 460.19032645225525, "episode_reward": 306.19861749568287, "step": 58000}
{"episode": 59.0, "batch_reward": 0.6014310503304005, "critic_loss": 109.94187236404419, "actor_loss": -218.60800521850587, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.722049474716187, "episode_reward": 557.7995261287576, "step": 59000}
{"episode": 60.0, "batch_reward": 0.6030775471329689, "critic_loss": 124.19695808029175, "actor_loss": -224.99831274414063, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 461.5132329463959, "episode_reward": 871.6929577807076, "step": 60000}
{"episode": 61.0, "batch_reward": 0.6094228274226189, "critic_loss": 121.69756758880615, "actor_loss": -229.7474663696289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 45.919477462768555, "episode_reward": 919.6826685059183, "step": 61000}
{"episode": 62.0, "batch_reward": 0.6090493906438351, "critic_loss": 106.82024355697632, "actor_loss": -230.9893475341797, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 436.41028022766113, "episode_reward": 642.7486477744033, "step": 62000}
{"episode": 63.0, "batch_reward": 0.6134209858179093, "critic_loss": 93.4643408126831, "actor_loss": -231.8824147644043, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.184803009033203, "episode_reward": 881.6884082655763, "step": 63000}
{"episode": 64.0, "batch_reward": 0.6198992369771004, "critic_loss": 82.29112182998657, "actor_loss": -233.09348712158203, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 459.54041957855225, "episode_reward": 979.2832133247673, "step": 64000}
{"episode": 65.0, "batch_reward": 0.6211252515912056, "critic_loss": 73.57872093963623, "actor_loss": -234.71435296630858, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.698378801345825, "episode_reward": 948.5358570034005, "step": 65000}
{"episode": 66.0, "batch_reward": 0.6210419321060181, "critic_loss": 67.31595757293701, "actor_loss": -237.01242248535155, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 497.16143465042114, "episode_reward": 9.491620571544551, "step": 66000}
{"episode": 67.0, "batch_reward": 0.6184499458670616, "critic_loss": 56.820423698425294, "actor_loss": -236.07112548828124, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.231300592422485, "episode_reward": 911.3428733370395, "step": 67000}
{"episode": 68.0, "batch_reward": 0.623799260109663, "critic_loss": 48.41883419418335, "actor_loss": -235.06635690307618, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 453.0995352268219, "episode_reward": 951.1374723025449, "step": 68000}
{"episode": 69.0, "batch_reward": 0.6295040979385376, "critic_loss": 41.7886436252594, "actor_loss": -233.6366385498047, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.57476782798767, "episode_reward": 985.2713751266996, "step": 69000}
{"episode": 70.0, "batch_reward": 0.6335203188061714, "critic_loss": 33.96285000991821, "actor_loss": -231.56285134887696, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 437.6615126132965, "episode_reward": 914.0590365644113, "step": 70000}
{"episode": 71.0, "batch_reward": 0.6370653756856919, "critic_loss": 27.83936356639862, "actor_loss": -229.1099521484375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.34437108039856, "episode_reward": 922.527344268995, "step": 71000}
{"episode": 72.0, "batch_reward": 0.6427297007143498, "critic_loss": 21.915100224494935, "actor_loss": -226.40023754882813, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 455.5947320461273, "episode_reward": 969.187767370277, "step": 72000}
{"episode": 73.0, "batch_reward": 0.6432277318239212, "critic_loss": 17.565713638305663, "actor_loss": -222.91303057861327, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.689915895462036, "episode_reward": 708.7777722781113, "step": 73000}
{"episode": 74.0, "batch_reward": 0.6468080985546112, "critic_loss": 14.61214546728134, "actor_loss": -218.94091036987305, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 457.5764350891113, "episode_reward": 899.2541380346106, "step": 74000}
{"episode": 75.0, "batch_reward": 0.6506620336174965, "critic_loss": 12.300338784217834, "actor_loss": -215.1832597351074, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 24.864262104034424, "episode_reward": 951.1353781007086, "step": 75000}
{"episode": 76.0, "batch_reward": 0.6489450760483741, "critic_loss": 13.779248570919037, "actor_loss": -212.10980227661133, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 450.6366300582886, "episode_reward": 55.15597435104534, "step": 76000}
{"episode": 77.0, "batch_reward": 0.6411288129091263, "critic_loss": 17.768592504501342, "actor_loss": -211.29277182006837, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.409950733184814, "episode_reward": 62.633304167500064, "step": 77000}
{"episode": 78.0, "batch_reward": 0.640041810810566, "critic_loss": 18.530835461616515, "actor_loss": -209.62050668334962, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 455.7673580646515, "episode_reward": 961.8922717651878, "step": 78000}
{"episode": 79.0, "batch_reward": 0.6390550388097763, "critic_loss": 15.830989025592803, "actor_loss": -207.04246746826172, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.26354718208313, "episode_reward": 78.71393578517937, "step": 79000}
{"episode": 80.0, "batch_reward": 0.6303399558067322, "critic_loss": 13.352302250385284, "actor_loss": -203.8719910583496, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 433.06373929977417, "episode_reward": 68.95149288031091, "step": 80000}
{"episode": 81.0, "batch_reward": 0.6236692011356354, "critic_loss": 10.731054461956024, "actor_loss": -201.3296381225586, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.291866302490234, "episode_reward": 91.33644346313756, "step": 81000}
{"episode": 82.0, "batch_reward": 0.617464224934578, "critic_loss": 9.39281103849411, "actor_loss": -199.39546740722656, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 469.2849700450897, "episode_reward": 168.84320919430618, "step": 82000}
{"episode": 83.0, "batch_reward": 0.6142190582156182, "critic_loss": 8.846882537841797, "actor_loss": -198.00114694213866, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.565143585205078, "episode_reward": 133.84299969299198, "step": 83000}
{"episode": 84.0, "batch_reward": 0.6050105062425136, "critic_loss": 9.225441517353058, "actor_loss": -197.3843271789551, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 425.8251178264618, "episode_reward": 166.6911786750562, "step": 84000}
{"episode": 85.0, "batch_reward": 0.6031336422860623, "critic_loss": 9.6720628824234, "actor_loss": -197.0979330749512, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.43720316886902, "episode_reward": 249.4156486939793, "step": 85000}
{"episode": 86.0, "batch_reward": 0.6015462256669998, "critic_loss": 9.345612015724182, "actor_loss": -196.29514276123047, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 449.6231656074524, "episode_reward": 437.8046905259342, "step": 86000}
{"episode": 87.0, "batch_reward": 0.5987956877350807, "critic_loss": 8.77674641418457, "actor_loss": -194.63995455932618, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.343883514404297, "episode_reward": 737.781023701176, "step": 87000}
{"episode": 88.0, "batch_reward": 0.5962360731661319, "critic_loss": 8.294577988147736, "actor_loss": -193.02674420166016, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 472.11734771728516, "episode_reward": 120.50032161019135, "step": 88000}
{"episode": 89.0, "batch_reward": 0.5914629830420017, "critic_loss": 7.333352163791656, "actor_loss": -190.57805667114258, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.33125066757202, "episode_reward": 339.39232517455486, "step": 89000}
{"episode": 90.0, "batch_reward": 0.5941341915130616, "critic_loss": 6.839062659263611, "actor_loss": -187.9233199157715, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 480.3838667869568, "episode_reward": 946.6624925531228, "step": 90000}
{"episode": 91.0, "batch_reward": 0.596891382575035, "critic_loss": 6.493126678705216, "actor_loss": -184.78107705688475, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 43.27491283416748, "episode_reward": 910.7483240545695, "step": 91000}
{"episode": 92.0, "batch_reward": 0.5996810781657695, "critic_loss": 5.877222718954086, "actor_loss": -181.8249748840332, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 490.87826776504517, "episode_reward": 954.0906010332333, "step": 92000}
{"episode": 93.0, "batch_reward": 0.602652639478445, "critic_loss": 5.09583442234993, "actor_loss": -179.15989434814452, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.50892686843872, "episode_reward": 979.2901325602624, "step": 93000}
{"episode": 94.0, "batch_reward": 0.6087245962917804, "critic_loss": 4.797534662246704, "actor_loss": -176.75802673339842, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 444.9622094631195, "episode_reward": 953.0151951138905, "step": 94000}
{"episode": 95.0, "batch_reward": 0.611403187841177, "critic_loss": 4.26444202041626, "actor_loss": -174.43545614624023, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.22361993789673, "episode_reward": 959.2012450206515, "step": 95000}
{"episode": 96.0, "batch_reward": 0.6158949155211448, "critic_loss": 3.61991093146801, "actor_loss": -171.86848989868164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 460.9711124897003, "episode_reward": 958.2856043599162, "step": 96000}
{"episode": 97.0, "batch_reward": 0.6189483104348182, "critic_loss": 3.221074172377586, "actor_loss": -169.19203927612304, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.194826126098633, "episode_reward": 928.880387660508, "step": 97000}
{"episode": 98.0, "batch_reward": 0.6230884844660759, "critic_loss": 3.1177802798748018, "actor_loss": -166.42502212524414, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 423.76923871040344, "episode_reward": 935.6489635568332, "step": 98000}
{"episode": 99.0, "batch_reward": 0.6224944735467434, "critic_loss": 2.565972954750061, "actor_loss": -163.71348611450196, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.54193353652954, "episode_reward": 941.0137018420348, "step": 99000}
{"episode": 100.0, "batch_reward": 0.6309112704992295, "critic_loss": 2.3755832320451735, "actor_loss": -161.60661544799805, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 436.3585729598999, "episode_reward": 928.3474773936181, "step": 100000}
{"episode": 101.0, "batch_reward": 0.6319463250637054, "critic_loss": 2.372551744580269, "actor_loss": -159.46116232299804, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.78873014450073, "episode_reward": 985.9043709893954, "step": 101000}
{"episode": 102.0, "batch_reward": 0.6359916589856148, "critic_loss": 2.03891484105587, "actor_loss": -157.1310828552246, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 485.3821933269501, "episode_reward": 982.6417046454601, "step": 102000}
{"episode": 103.0, "batch_reward": 0.6405693169236183, "critic_loss": 1.8009634491801263, "actor_loss": -155.066266998291, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.14086627960205, "episode_reward": 955.3524983197568, "step": 103000}
{"episode": 104.0, "batch_reward": 0.6426871458888054, "critic_loss": 1.6454043017625808, "actor_loss": -152.9084016418457, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 470.1143252849579, "episode_reward": 931.642344026298, "step": 104000}
{"episode": 105.0, "batch_reward": 0.6433736868500709, "critic_loss": 1.66188145506382, "actor_loss": -150.61426611328125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.435567378997803, "episode_reward": 856.37016787702, "step": 105000}
{"episode": 106.0, "batch_reward": 0.6460588874816895, "critic_loss": 1.5773365330696105, "actor_loss": -148.70437948608398, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 464.2624092102051, "episode_reward": 829.7209478151043, "step": 106000}
{"episode": 107.0, "batch_reward": 0.6487959862351418, "critic_loss": 1.407885243177414, "actor_loss": -146.57617083740234, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.061652660369873, "episode_reward": 961.1143060926347, "step": 107000}
{"episode": 108.0, "batch_reward": 0.6538555275201797, "critic_loss": 1.2972981773614884, "actor_loss": -144.45264517211913, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 489.73384523391724, "episode_reward": 948.363065412452, "step": 108000}
{"episode": 109.0, "batch_reward": 0.6556013138890266, "critic_loss": 1.2124257645606995, "actor_loss": -142.3971883544922, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.142093420028687, "episode_reward": 978.2125195279654, "step": 109000}
{"episode": 110.0, "batch_reward": 0.6555451734662056, "critic_loss": 1.1719416754841805, "actor_loss": -140.49479821777345, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 440.64182710647583, "episode_reward": 878.9207371735042, "step": 110000}
{"episode": 111.0, "batch_reward": 0.6578676720261574, "critic_loss": 1.0689544892907143, "actor_loss": -138.27242385864258, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 43.276519775390625, "episode_reward": 927.384066347487, "step": 111000}
{"episode": 112.0, "batch_reward": 0.6628726887702941, "critic_loss": 1.0138043951392173, "actor_loss": -136.36607180786132, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 463.4731960296631, "episode_reward": 964.1876659441957, "step": 112000}
{"episode": 113.0, "batch_reward": 0.66344319409132, "critic_loss": 1.0028717339932918, "actor_loss": -134.317470123291, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.478773832321167, "episode_reward": 957.9780170964915, "step": 113000}
{"episode": 114.0, "batch_reward": 0.667232074201107, "critic_loss": 0.9369534272253514, "actor_loss": -132.51600341796876, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 440.9080386161804, "episode_reward": 961.9366298624102, "step": 114000}
{"episode": 115.0, "batch_reward": 0.6686983379125595, "critic_loss": 0.8684370430707932, "actor_loss": -130.7307663116455, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.15463376045227, "episode_reward": 911.7725571737186, "step": 115000}
{"episode": 116.0, "batch_reward": 0.6700707616209984, "critic_loss": 0.8568217222094536, "actor_loss": -129.19375306701662, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 448.98560881614685, "episode_reward": 938.369881323136, "step": 116000}
{"episode": 117.0, "batch_reward": 0.6743011491298676, "critic_loss": 0.9091803993880748, "actor_loss": -127.62824382019043, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 26.34080410003662, "episode_reward": 893.6591653920094, "step": 117000}
{"episode": 118.0, "batch_reward": 0.6768963701725006, "critic_loss": 0.8633214541077614, "actor_loss": -126.24086058044433, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 448.7987940311432, "episode_reward": 987.854184157551, "step": 118000}
{"episode": 119.0, "batch_reward": 0.6795936464071274, "critic_loss": 0.796749307513237, "actor_loss": -124.84086004638672, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.255399227142334, "episode_reward": 951.2317757791188, "step": 119000}
{"episode": 120.0, "batch_reward": 0.6800023454427719, "critic_loss": 0.780428798288107, "actor_loss": -123.54753128051757, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 498.78972029685974, "episode_reward": 954.3992158512727, "step": 120000}
{"episode": 121.0, "batch_reward": 0.6841990315914154, "critic_loss": 0.7477836138606071, "actor_loss": -122.34548637390137, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.5844407081604, "episode_reward": 985.6576630672636, "step": 121000}
{"episode": 122.0, "batch_reward": 0.6855265055894851, "critic_loss": 0.7388503388464451, "actor_loss": -121.06263208007813, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 447.8637607097626, "episode_reward": 962.8745732024394, "step": 122000}
{"episode": 123.0, "batch_reward": 0.6880491365194321, "critic_loss": 0.7134448875188828, "actor_loss": -119.7945910949707, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.368674516677856, "episode_reward": 950.6431179621994, "step": 123000}
{"episode": 124.0, "batch_reward": 0.6904100633263588, "critic_loss": 0.6549519691765309, "actor_loss": -118.66603021240235, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 451.97990131378174, "episode_reward": 983.491155245665, "step": 124000}
{"episode": 125.0, "batch_reward": 0.6919253525733948, "critic_loss": 0.663623859256506, "actor_loss": -117.71522392272949, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 26.17773199081421, "episode_reward": 977.9488797377925, "step": 125000}
{"episode": 126.0, "batch_reward": 0.6941889500021935, "critic_loss": 0.6511087829470634, "actor_loss": -116.71634304809571, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 446.5388448238373, "episode_reward": 984.3228209089339, "step": 126000}
{"episode": 127.0, "batch_reward": 0.6967322276830673, "critic_loss": 0.5965734241306782, "actor_loss": -115.78889028930664, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.294254302978516, "episode_reward": 871.5827174691099, "step": 127000}
{"episode": 128.0, "batch_reward": 0.6961083604693413, "critic_loss": 0.6346229724884033, "actor_loss": -114.86481289672851, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 447.3187439441681, "episode_reward": 967.8433707760213, "step": 128000}
{"episode": 129.0, "batch_reward": 0.7001517754793167, "critic_loss": 0.6135718767493963, "actor_loss": -114.109988571167, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.338939905166626, "episode_reward": 982.1131178370948, "step": 129000}
{"episode": 130.0, "batch_reward": 0.7045780118703843, "critic_loss": 0.5800915077626705, "actor_loss": -113.13984043884277, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 458.94621086120605, "episode_reward": 986.5123619153821, "step": 130000}
{"episode": 131.0, "batch_reward": 0.7059738799929619, "critic_loss": 0.5771765528917313, "actor_loss": -112.1928364868164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.24645757675171, "episode_reward": 983.6347670555041, "step": 131000}
{"episode": 132.0, "batch_reward": 0.7086802309751511, "critic_loss": 0.5599031316190958, "actor_loss": -111.46745004272461, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 460.8604009151459, "episode_reward": 985.1862151602952, "step": 132000}
{"episode": 133.0, "batch_reward": 0.709289844751358, "critic_loss": 0.5463946546018124, "actor_loss": -110.58480404663086, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.525818347930908, "episode_reward": 946.5886188479649, "step": 133000}
{"episode": 134.0, "batch_reward": 0.7089440190792083, "critic_loss": 0.5505856313109397, "actor_loss": -109.69020835876465, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 443.28580713272095, "episode_reward": 959.1373631525013, "step": 134000}
{"episode": 135.0, "batch_reward": 0.7119632893800736, "critic_loss": 0.5056844839304686, "actor_loss": -109.14329080200196, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.469659328460693, "episode_reward": 986.2657874975872, "step": 135000}
{"episode": 136.0, "batch_reward": 0.7171260872483254, "critic_loss": 0.5212893627285957, "actor_loss": -108.73067462158203, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 459.7632131576538, "episode_reward": 990.9309891226854, "step": 136000}
{"episode": 137.0, "batch_reward": 0.717767032802105, "critic_loss": 0.508935418099165, "actor_loss": -108.23409565734863, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.98390030860901, "episode_reward": 979.6124905780301, "step": 137000}
{"episode": 138.0, "batch_reward": 0.7164268089532853, "critic_loss": 0.49385414204001427, "actor_loss": -107.70836993408203, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 455.32097458839417, "episode_reward": 953.1572410190241, "step": 138000}
{"episode": 139.0, "batch_reward": 0.7207389039993286, "critic_loss": 0.4836726713180542, "actor_loss": -107.13472799682617, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.649795532226562, "episode_reward": 946.6826040035758, "step": 139000}
{"episode": 140.0, "batch_reward": 0.7214914664030075, "critic_loss": 0.500917245849967, "actor_loss": -106.55075938415527, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 451.2657890319824, "episode_reward": 937.9327869296669, "step": 140000}
{"episode": 141.0, "batch_reward": 0.7229425537586213, "critic_loss": 0.4724279189258814, "actor_loss": -105.98859661865234, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.781208992004395, "episode_reward": 957.9463532404499, "step": 141000}
{"episode": 142.0, "batch_reward": 0.7244888262152672, "critic_loss": 0.46483840748667715, "actor_loss": -105.5494568939209, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 440.7571303844452, "episode_reward": 981.3431505216054, "step": 142000}
{"episode": 143.0, "batch_reward": 0.7265574651360511, "critic_loss": 0.4553679032474756, "actor_loss": -105.0583138885498, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.48461604118347, "episode_reward": 948.3441919014194, "step": 143000}
{"episode": 144.0, "batch_reward": 0.7284808855652809, "critic_loss": 0.4627899765968323, "actor_loss": -104.56575283813477, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 436.6949119567871, "episode_reward": 960.4862791685107, "step": 144000}
{"episode": 145.0, "batch_reward": 0.7280109716653824, "critic_loss": 0.4561506928354502, "actor_loss": -104.13922811889648, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 25.96895980834961, "episode_reward": 985.4570003985347, "step": 145000}
{"episode": 146.0, "batch_reward": 0.7311815140247345, "critic_loss": 0.4598553249835968, "actor_loss": -103.74199990844727, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 451.19193410873413, "episode_reward": 947.3726004330412, "step": 146000}
{"episode": 147.0, "batch_reward": 0.7334378619790077, "critic_loss": 0.44720582957565785, "actor_loss": -103.38242446899415, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.40914249420166, "episode_reward": 898.832355717935, "step": 147000}
{"episode": 148.0, "batch_reward": 0.7323213028907776, "critic_loss": 0.4512945251613855, "actor_loss": -102.92108413696289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 460.2462668418884, "episode_reward": 962.5665455154349, "step": 148000}
{"episode": 149.0, "batch_reward": 0.735385721206665, "critic_loss": 0.45209090240299704, "actor_loss": -102.55703387451172, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.271501064300537, "episode_reward": 931.8184518635588, "step": 149000}
{"episode": 150.0, "batch_reward": 0.7382071655392647, "critic_loss": 0.4443085675686598, "actor_loss": -102.21632838439942, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
