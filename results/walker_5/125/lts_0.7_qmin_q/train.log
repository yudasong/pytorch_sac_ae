{"episode_reward": 0.0, "episode": 1.0, "duration": 22.734483242034912, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.8703172206878662, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.4772197054143189, "critic_loss": 1.0333550345225906, "actor_loss": -84.82160221266241, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 64.01015877723694, "step": 3000}
{"episode_reward": 595.4235995752357, "episode": 4.0, "batch_reward": 0.47912763118743895, "critic_loss": 1.9894745777249336, "actor_loss": -85.70940246582032, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.288292169570923, "step": 4000}
{"episode_reward": 159.39111959058667, "episode": 5.0, "batch_reward": 0.4090890405476093, "critic_loss": 1.7430883872509002, "actor_loss": -85.34123538208007, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.156304836273193, "step": 5000}
{"episode_reward": 270.55618019047546, "episode": 6.0, "batch_reward": 0.4304834584891796, "critic_loss": 1.571760762989521, "actor_loss": -85.21525442504883, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.73456645011902, "step": 6000}
{"episode_reward": 758.6934439726922, "episode": 7.0, "batch_reward": 0.4775748377740383, "critic_loss": 1.6776755567193031, "actor_loss": -85.21584519958496, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.954919576644897, "step": 7000}
{"episode_reward": 866.697722419526, "episode": 8.0, "batch_reward": 0.524525636613369, "critic_loss": 1.5285875272154807, "actor_loss": -85.7174786529541, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.148903608322144, "step": 8000}
{"episode_reward": 740.3438976178863, "episode": 9.0, "batch_reward": 0.5463441798090934, "critic_loss": 1.5781003457307816, "actor_loss": -85.71342980957031, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.15716314315796, "step": 9000}
{"episode_reward": 733.3100180254182, "episode": 10.0, "batch_reward": 0.5676009455025196, "critic_loss": 1.5116907744407653, "actor_loss": -85.81624244689941, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.740925312042236, "step": 10000}
{"episode_reward": 696.3828600533558, "episode": 11.0, "batch_reward": 0.5752961303293705, "critic_loss": 1.489286699652672, "actor_loss": -85.83630960083008, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.7236430644989, "step": 11000}
{"episode_reward": 748.7725952087297, "episode": 12.0, "batch_reward": 0.594990661740303, "critic_loss": 1.3851942323446274, "actor_loss": -85.89760301208496, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.65152883529663, "step": 12000}
{"episode_reward": 793.1484812155727, "episode": 13.0, "batch_reward": 0.612822373688221, "critic_loss": 1.307843372285366, "actor_loss": -86.20225770568848, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.18502688407898, "step": 13000}
{"episode_reward": 816.191434644579, "episode": 14.0, "batch_reward": 0.6357328559756279, "critic_loss": 1.196497240126133, "actor_loss": -86.40992727661133, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.166987895965576, "step": 14000}
{"episode_reward": 943.4395906496404, "episode": 15.0, "batch_reward": 0.6576916400194168, "critic_loss": 1.2166954908370973, "actor_loss": -87.44606135559081, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.134887218475342, "step": 15000}
{"episode_reward": 986.5449560816447, "episode": 16.0, "batch_reward": 0.6791622141599655, "critic_loss": 1.2317715473771096, "actor_loss": -87.5797176208496, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.167832851409912, "step": 16000}
{"episode_reward": 941.1716873227343, "episode": 17.0, "batch_reward": 0.6879100449681282, "critic_loss": 1.3298563442230225, "actor_loss": -87.39100927734376, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.223055601119995, "step": 17000}
{"episode_reward": 720.665142852437, "episode": 18.0, "batch_reward": 0.6956645064949989, "critic_loss": 1.287592360317707, "actor_loss": -87.58213137817383, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.20376944541931, "step": 18000}
{"episode_reward": 911.3449519566246, "episode": 19.0, "batch_reward": 0.7095165938735009, "critic_loss": 1.233717141032219, "actor_loss": -87.80436254882812, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.319517612457275, "step": 19000}
{"episode_reward": 975.1765278806183, "episode": 20.0, "batch_reward": 0.7209989759325981, "critic_loss": 1.2139440775513648, "actor_loss": -88.35446664428711, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.171282529830933, "step": 20000}
{"episode_reward": 958.5428932996905, "episode": 21.0, "batch_reward": 0.7298225572705269, "critic_loss": 1.31632620292902, "actor_loss": -88.53880253601075, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.390116930007935, "step": 21000}
{"episode_reward": 812.7807812775548, "episode": 22.0, "batch_reward": 0.7386673680543899, "critic_loss": 1.307276271045208, "actor_loss": -88.451486038208, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.308979749679565, "step": 22000}
{"episode_reward": 964.2476649085295, "episode": 23.0, "batch_reward": 0.7482174448370934, "critic_loss": 1.1914935556054116, "actor_loss": -89.00568479919434, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.213027715682983, "step": 23000}
{"episode_reward": 943.2515390361534, "episode": 24.0, "batch_reward": 0.7547201582789421, "critic_loss": 1.1137263550758363, "actor_loss": -89.1614584197998, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.44134545326233, "step": 24000}
{"episode_reward": 980.9628361263724, "episode": 25.0, "batch_reward": 0.7616349533200264, "critic_loss": 1.0477064972519874, "actor_loss": -89.01928884887695, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.137032508850098, "step": 25000}
{"episode_reward": 906.932745069484, "episode": 26.0, "batch_reward": 0.7687874106168747, "critic_loss": 1.000761082023382, "actor_loss": -89.37062812805176, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.830989599227905, "step": 26000}
{"episode_reward": 968.1668885689328, "episode": 27.0, "batch_reward": 0.7787426334619522, "critic_loss": 0.8982105230689049, "actor_loss": -89.67127810668946, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.87534475326538, "step": 27000}
{"episode_reward": 976.1851489079118, "episode": 28.0, "batch_reward": 0.7818028724193573, "critic_loss": 0.9560260304808617, "actor_loss": -89.56461808776855, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.102161407470703, "step": 28000}
{"episode_reward": 837.4461080258544, "episode": 29.0, "batch_reward": 0.7877954338788986, "critic_loss": 0.920545321047306, "actor_loss": -89.93938063049316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.27674126625061, "step": 29000}
{"episode_reward": 942.5911205240636, "episode": 30.0, "batch_reward": 0.792326490342617, "critic_loss": 0.911022190630436, "actor_loss": -89.77426937866211, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.174642086029053, "step": 30000}
{"episode_reward": 919.6915808342997, "episode": 31.0, "batch_reward": 0.7906138949394226, "critic_loss": 0.9182382045686245, "actor_loss": -90.0487456665039, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.33688569068909, "step": 31000}
{"episode_reward": 718.0993464046609, "episode": 32.0, "batch_reward": 0.7904776957631111, "critic_loss": 0.9774097035527229, "actor_loss": -89.74485513305665, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.076232433319092, "step": 32000}
{"episode_reward": 852.9685148252989, "episode": 33.0, "batch_reward": 0.7919748136401177, "critic_loss": 0.9686245281398297, "actor_loss": -90.10289135742188, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.88352942466736, "step": 33000}
{"episode_reward": 822.0030528563221, "episode": 34.0, "batch_reward": 0.7950192802548408, "critic_loss": 0.9912611728310585, "actor_loss": -89.77144032287597, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.09986186027527, "step": 34000}
{"episode_reward": 974.3377959355735, "episode": 35.0, "batch_reward": 0.8001134368181229, "critic_loss": 1.0526290498673916, "actor_loss": -90.20160055541992, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.741774082183838, "step": 35000}
{"episode_reward": 894.4463095369694, "episode": 36.0, "batch_reward": 0.8025704421997071, "critic_loss": 1.0304754121601583, "actor_loss": -89.72735180664063, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.1499605178833, "step": 36000}
{"episode_reward": 925.8206264973917, "episode": 37.0, "batch_reward": 0.8024856390357018, "critic_loss": 1.0394653576612471, "actor_loss": -89.96770140075684, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.189767122268677, "step": 37000}
{"episode_reward": 838.6209374764926, "episode": 38.0, "batch_reward": 0.8081789914965629, "critic_loss": 0.9973998608291149, "actor_loss": -90.2386567993164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.470638513565063, "step": 38000}
{"episode_reward": 967.9008360401924, "episode": 39.0, "batch_reward": 0.8125865239500999, "critic_loss": 1.0381836193203926, "actor_loss": -90.45508868408203, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.19213056564331, "step": 39000}
{"episode_reward": 961.7195901474508, "episode": 40.0, "batch_reward": 0.8151567036509514, "critic_loss": 1.0194108264148236, "actor_loss": -90.53152694702149, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.285441637039185, "step": 40000}
{"episode_reward": 963.5726501552007, "episode": 41.0, "batch_reward": 0.820529898583889, "critic_loss": 1.0883816286325454, "actor_loss": -90.59242127990723, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.45893979072571, "step": 41000}
{"episode_reward": 945.99378176643, "episode": 42.0, "batch_reward": 0.8249796674251556, "critic_loss": 1.0603052461743354, "actor_loss": -90.44648924255371, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.395358324050903, "step": 42000}
{"episode_reward": 954.6816916072074, "episode": 43.0, "batch_reward": 0.8263432089686393, "critic_loss": 1.114869467496872, "actor_loss": -90.58519892883301, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.111441373825073, "step": 43000}
{"episode_reward": 957.3302733762464, "episode": 44.0, "batch_reward": 0.8271310533881188, "critic_loss": 1.166797051757574, "actor_loss": -90.49115766906738, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.505089282989502, "step": 44000}
{"episode_reward": 916.8652975062582, "episode": 45.0, "batch_reward": 0.8289046511650086, "critic_loss": 1.1207503264546395, "actor_loss": -90.81647151184082, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.0041983127594, "step": 45000}
{"episode_reward": 858.3876245234295, "episode": 46.0, "batch_reward": 0.8306671541333198, "critic_loss": 1.113968033850193, "actor_loss": -90.78766911315918, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.268683433532715, "step": 46000}
{"episode_reward": 966.8041303895154, "episode": 47.0, "batch_reward": 0.8353292846679687, "critic_loss": 1.1141161125898362, "actor_loss": -91.07016812133789, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.098581075668335, "step": 47000}
{"episode_reward": 963.36769411739, "episode": 48.0, "batch_reward": 0.8341164142489433, "critic_loss": 1.1727060916423797, "actor_loss": -90.62560466003418, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.874300003051758, "step": 48000}
{"episode_reward": 751.8428041105093, "episode": 49.0, "batch_reward": 0.8346654133796692, "critic_loss": 1.1291595026254655, "actor_loss": -91.13914573669433, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.982895135879517, "step": 49000}
{"episode_reward": 905.8134115948222, "episode": 50.0, "batch_reward": 0.8376548246145249, "critic_loss": 1.0853835991322993, "actor_loss": -91.1554037322998, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.995012760162354, "step": 50000}
{"episode_reward": 984.3107032866949, "episode": 51.0, "batch_reward": 0.8388680711388588, "critic_loss": 1.080972352951765, "actor_loss": -91.16296073913574, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.18384552001953, "step": 51000}
{"episode_reward": 965.9155247231852, "episode": 52.0, "batch_reward": 0.8409711169600487, "critic_loss": 1.0264231891930102, "actor_loss": -91.3265338897705, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.30835461616516, "step": 52000}
{"episode_reward": 916.1874327208411, "episode": 53.0, "batch_reward": 0.843125468313694, "critic_loss": 0.9922647458612919, "actor_loss": -91.33061373901367, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.147605895996094, "step": 53000}
{"episode_reward": 942.5316923861567, "episode": 54.0, "batch_reward": 0.8457889868021011, "critic_loss": 0.9555601128339768, "actor_loss": -91.50842782592774, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.474663257598877, "step": 54000}
{"episode_reward": 879.8258149836863, "episode": 55.0, "batch_reward": 0.8456820487380028, "critic_loss": 0.9289017730355262, "actor_loss": -91.49402375793457, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.92315673828125, "step": 55000}
{"episode_reward": 956.3946388882136, "episode": 56.0, "batch_reward": 0.8483551131486893, "critic_loss": 0.9508767158389092, "actor_loss": -91.6453738861084, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.387285709381104, "step": 56000}
{"episode_reward": 965.0364066788177, "episode": 57.0, "batch_reward": 0.8508178160190583, "critic_loss": 0.9838123508393765, "actor_loss": -91.55288148498535, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.055914163589478, "step": 57000}
{"episode_reward": 877.9933090348211, "episode": 58.0, "batch_reward": 0.8516625763177872, "critic_loss": 0.9549332052469254, "actor_loss": -91.47105116271973, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.06988215446472, "step": 58000}
{"episode_reward": 973.7425069532356, "episode": 59.0, "batch_reward": 0.8526898086071014, "critic_loss": 0.9875028249621391, "actor_loss": -91.46700598144531, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.19730520248413, "step": 59000}
{"episode_reward": 887.6938414262019, "episode": 60.0, "batch_reward": 0.8528346896767617, "critic_loss": 1.043084897786379, "actor_loss": -91.72803788757324, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.269789695739746, "step": 60000}
{"episode_reward": 896.0579196828076, "episode": 61.0, "batch_reward": 0.8542057605981827, "critic_loss": 1.089152861982584, "actor_loss": -91.5435827178955, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.58523201942444, "step": 61000}
{"episode_reward": 901.74637320187, "episode": 62.0, "batch_reward": 0.8539590837359429, "critic_loss": 1.0980582907497882, "actor_loss": -91.7256150970459, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.238929986953735, "step": 62000}
{"episode_reward": 962.79703493273, "episode": 63.0, "batch_reward": 0.8557237663865089, "critic_loss": 1.0975357347428798, "actor_loss": -91.53334426879883, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.14699912071228, "step": 63000}
{"episode_reward": 926.7038872170443, "episode": 64.0, "batch_reward": 0.857459659397602, "critic_loss": 1.0709236309230328, "actor_loss": -91.75132739257812, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.99614644050598, "step": 64000}
{"episode_reward": 987.6664029555442, "episode": 65.0, "batch_reward": 0.8593208612799644, "critic_loss": 1.0862952499389649, "actor_loss": -91.768625289917, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.597856283187866, "step": 65000}
{"episode_reward": 963.3854448838069, "episode": 66.0, "batch_reward": 0.860782076060772, "critic_loss": 1.1031552011966705, "actor_loss": -91.87651216125488, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.011625289916992, "step": 66000}
{"episode_reward": 939.9296190972196, "episode": 67.0, "batch_reward": 0.860884308040142, "critic_loss": 1.1527210188508035, "actor_loss": -91.95388568115234, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.352178812026978, "step": 67000}
{"episode_reward": 914.2557317428034, "episode": 68.0, "batch_reward": 0.8625057505369187, "critic_loss": 1.0306555685698986, "actor_loss": -91.67695642089843, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.024433851242065, "step": 68000}
{"episode_reward": 940.2476903771557, "episode": 69.0, "batch_reward": 0.8626358341574669, "critic_loss": 1.0027698959708213, "actor_loss": -91.7528272857666, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.104430198669434, "step": 69000}
{"episode_reward": 962.4357244467767, "episode": 70.0, "batch_reward": 0.8659251042604447, "critic_loss": 0.9876695736944675, "actor_loss": -92.17898875427247, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.272183179855347, "step": 70000}
{"episode_reward": 934.406621206131, "episode": 71.0, "batch_reward": 0.866409348487854, "critic_loss": 1.0346855952441691, "actor_loss": -92.12636256408692, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.58666443824768, "step": 71000}
{"episode_reward": 941.8886358580277, "episode": 72.0, "batch_reward": 0.867875417470932, "critic_loss": 1.0081887906193734, "actor_loss": -92.11987892150879, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.099493980407715, "step": 72000}
{"episode_reward": 980.5169308800639, "episode": 73.0, "batch_reward": 0.8670407704710961, "critic_loss": 1.0651625510454177, "actor_loss": -92.20140673828125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.567487955093384, "step": 73000}
{"episode_reward": 938.9843511661065, "episode": 74.0, "batch_reward": 0.8702736387848854, "critic_loss": 0.9972944537401199, "actor_loss": -92.49597468566894, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.178539991378784, "step": 74000}
{"episode_reward": 930.4602221882078, "episode": 75.0, "batch_reward": 0.8695785979032516, "critic_loss": 0.9359834862053394, "actor_loss": -92.382157913208, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.999516010284424, "step": 75000}
{"episode_reward": 903.5852739740941, "episode": 76.0, "batch_reward": 0.871399376988411, "critic_loss": 0.9597232249677181, "actor_loss": -92.5837169494629, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.129985570907593, "step": 76000}
{"episode_reward": 925.477516305061, "episode": 77.0, "batch_reward": 0.8722627802491189, "critic_loss": 1.0072148843407631, "actor_loss": -92.29547702026368, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.341915369033813, "step": 77000}
{"episode_reward": 964.8938044157775, "episode": 78.0, "batch_reward": 0.8744614263772964, "critic_loss": 0.9253327977061272, "actor_loss": -92.49050706481934, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.81343126296997, "step": 78000}
{"episode_reward": 957.4149669585886, "episode": 79.0, "batch_reward": 0.8744214907288551, "critic_loss": 0.9584930402338505, "actor_loss": -92.21059790039062, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.125200748443604, "step": 79000}
{"episode_reward": 956.691152554568, "episode": 80.0, "batch_reward": 0.8750564499497414, "critic_loss": 0.957249736726284, "actor_loss": -92.39127261352539, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.769383668899536, "step": 80000}
{"episode_reward": 963.8739262309115, "episode": 81.0, "batch_reward": 0.8758972905278206, "critic_loss": 0.9389993043541909, "actor_loss": -92.53141998291015, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.64143443107605, "step": 81000}
{"episode_reward": 903.2930452880044, "episode": 82.0, "batch_reward": 0.8765730984210968, "critic_loss": 0.964087898850441, "actor_loss": -92.7650724029541, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.18375039100647, "step": 82000}
{"episode_reward": 949.8342901111732, "episode": 83.0, "batch_reward": 0.8778850081562996, "critic_loss": 0.9395900519788265, "actor_loss": -92.41346855163575, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.31723690032959, "step": 83000}
{"episode_reward": 910.1389453868262, "episode": 84.0, "batch_reward": 0.8795341618061066, "critic_loss": 0.9394752923846245, "actor_loss": -92.80766410827637, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.72306728363037, "step": 84000}
{"episode_reward": 985.0145293899373, "episode": 85.0, "batch_reward": 0.8778416134119034, "critic_loss": 0.9642550248503685, "actor_loss": -92.68947966003418, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.13774347305298, "step": 85000}
{"episode_reward": 949.0379461007449, "episode": 86.0, "batch_reward": 0.8795628443956375, "critic_loss": 0.9479859271645545, "actor_loss": -92.57718530273438, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.765408277511597, "step": 86000}
{"episode_reward": 952.202368327935, "episode": 87.0, "batch_reward": 0.8806235765814782, "critic_loss": 0.9249639338850975, "actor_loss": -92.58773805236817, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.59794545173645, "step": 87000}
{"episode_reward": 953.8401168607817, "episode": 88.0, "batch_reward": 0.881033584177494, "critic_loss": 0.8846840391755104, "actor_loss": -92.45106172180176, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.100225687026978, "step": 88000}
{"episode_reward": 875.6433126136166, "episode": 89.0, "batch_reward": 0.8815979859232903, "critic_loss": 0.9364572762548924, "actor_loss": -92.8668530883789, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.305803537368774, "step": 89000}
{"episode_reward": 972.9913229725978, "episode": 90.0, "batch_reward": 0.8823987262845039, "critic_loss": 0.9252183747291565, "actor_loss": -93.09235586547851, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.09648060798645, "step": 90000}
{"episode_reward": 946.0732336795774, "episode": 91.0, "batch_reward": 0.8840855353474617, "critic_loss": 0.8990311250388622, "actor_loss": -92.84223146057128, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.210695028305054, "step": 91000}
{"episode_reward": 934.121725571497, "episode": 92.0, "batch_reward": 0.8855072525143624, "critic_loss": 0.8824372228085995, "actor_loss": -92.8337505493164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.780853509902954, "step": 92000}
{"episode_reward": 958.6788418480123, "episode": 93.0, "batch_reward": 0.8835399421453476, "critic_loss": 0.8608440957665443, "actor_loss": -92.8038504486084, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.060163021087646, "step": 93000}
{"episode_reward": 980.8876950728549, "episode": 94.0, "batch_reward": 0.8850080847740174, "critic_loss": 0.8592560854554177, "actor_loss": -92.94833351135254, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.097177982330322, "step": 94000}
{"episode_reward": 955.0235875232972, "episode": 95.0, "batch_reward": 0.8858019142746926, "critic_loss": 0.9075258767902851, "actor_loss": -93.21642559814453, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.348379373550415, "step": 95000}
{"episode_reward": 927.0025076987263, "episode": 96.0, "batch_reward": 0.8862645327448845, "critic_loss": 0.8339808675348759, "actor_loss": -93.23469891357422, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.15968370437622, "step": 96000}
{"episode_reward": 929.6676165574443, "episode": 97.0, "batch_reward": 0.8865988925099373, "critic_loss": 0.8321051485389471, "actor_loss": -93.28270031738282, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.304491758346558, "step": 97000}
{"episode_reward": 920.7055841407744, "episode": 98.0, "batch_reward": 0.8881937189102173, "critic_loss": 0.8396149696707725, "actor_loss": -93.00948150634765, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.035138368606567, "step": 98000}
{"episode_reward": 922.3761503953282, "episode": 99.0, "batch_reward": 0.8879491931200028, "critic_loss": 0.8792772477567196, "actor_loss": -93.00347721862794, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.537717819213867, "step": 99000}
{"episode_reward": 959.3613788354172, "episode": 100.0, "batch_reward": 0.8897846472859383, "critic_loss": 0.8347595359385014, "actor_loss": -93.19291920471191, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.950584650039673, "step": 100000}
{"episode_reward": 922.3101331694072, "episode": 101.0, "batch_reward": 0.8909234622120857, "critic_loss": 0.841981057047844, "actor_loss": -93.29661225891114, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.101239919662476, "step": 101000}
{"episode_reward": 990.7890843766168, "episode": 102.0, "batch_reward": 0.889489857673645, "critic_loss": 0.8392010462284089, "actor_loss": -93.2658452758789, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.6800274848938, "step": 102000}
{"episode_reward": 971.845307605014, "episode": 103.0, "batch_reward": 0.8892670413255691, "critic_loss": 0.9115143649280071, "actor_loss": -93.22539694213867, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.776301622390747, "step": 103000}
{"episode_reward": 917.2339675357491, "episode": 104.0, "batch_reward": 0.8918862277269364, "critic_loss": 0.8202925105541945, "actor_loss": -93.32631489562988, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.106037616729736, "step": 104000}
{"episode_reward": 949.5721486165677, "episode": 105.0, "batch_reward": 0.8927636032104492, "critic_loss": 0.8109130837917328, "actor_loss": -93.39732911682128, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.12423276901245, "step": 105000}
{"episode_reward": 935.0765373892683, "episode": 106.0, "batch_reward": 0.8924182153940201, "critic_loss": 0.8059140724092722, "actor_loss": -93.23933773803711, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.21295428276062, "step": 106000}
{"episode_reward": 903.0144504664676, "episode": 107.0, "batch_reward": 0.8923412022590638, "critic_loss": 0.8276469507217408, "actor_loss": -93.31808859252929, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.884833574295044, "step": 107000}
{"episode_reward": 953.2564462340551, "episode": 108.0, "batch_reward": 0.8937861305475235, "critic_loss": 0.8140907428115607, "actor_loss": -93.43647454833985, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.090790033340454, "step": 108000}
{"episode_reward": 936.0804757505266, "episode": 109.0, "batch_reward": 0.8937112361788749, "critic_loss": 0.78115938167274, "actor_loss": -93.58271286010742, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.388931035995483, "step": 109000}
{"episode_reward": 977.2870032870561, "episode": 110.0, "batch_reward": 0.894518674492836, "critic_loss": 0.7952299249172211, "actor_loss": -93.47145024108887, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.230982542037964, "step": 110000}
{"episode_reward": 949.3652634525049, "episode": 111.0, "batch_reward": 0.8933046180605888, "critic_loss": 0.8135924703776837, "actor_loss": -93.69675511169433, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.45321297645569, "step": 111000}
{"episode_reward": 944.1725599816149, "episode": 112.0, "batch_reward": 0.8952063816189766, "critic_loss": 0.7827804231643677, "actor_loss": -93.54449063110351, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.14377474784851, "step": 112000}
{"episode_reward": 946.5085992183928, "episode": 113.0, "batch_reward": 0.8950473517775536, "critic_loss": 0.7305500747412443, "actor_loss": -93.56996827697753, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.01893377304077, "step": 113000}
{"episode_reward": 954.7831475026933, "episode": 114.0, "batch_reward": 0.8966947980523109, "critic_loss": 0.6970239838063716, "actor_loss": -93.75909107971191, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.082968711853027, "step": 114000}
{"episode_reward": 974.1651800499068, "episode": 115.0, "batch_reward": 0.8964052027463913, "critic_loss": 0.7345889732688665, "actor_loss": -93.6164503479004, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.420793294906616, "step": 115000}
{"episode_reward": 904.8831333641928, "episode": 116.0, "batch_reward": 0.896766358435154, "critic_loss": 0.7505176267623901, "actor_loss": -93.66694067382812, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.132420778274536, "step": 116000}
{"episode_reward": 895.6975234347018, "episode": 117.0, "batch_reward": 0.8965827729701996, "critic_loss": 0.7304421927034855, "actor_loss": -93.6519803466797, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.37149143218994, "step": 117000}
{"episode_reward": 932.4139421135255, "episode": 118.0, "batch_reward": 0.8971076617240906, "critic_loss": 0.7489596899151802, "actor_loss": -93.74859689331055, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.097123622894287, "step": 118000}
{"episode_reward": 978.0291200660282, "episode": 119.0, "batch_reward": 0.898200498342514, "critic_loss": 0.7403406741321087, "actor_loss": -93.8437352142334, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.609802961349487, "step": 119000}
{"episode_reward": 943.7961468016548, "episode": 120.0, "batch_reward": 0.8968654277920723, "critic_loss": 0.7310801653563976, "actor_loss": -93.62949589538574, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.02843451499939, "step": 120000}
{"episode_reward": 948.582090783388, "episode": 121.0, "batch_reward": 0.8984233860373497, "critic_loss": 0.7370434823930263, "actor_loss": -93.71998654174804, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.44938945770264, "step": 121000}
{"episode_reward": 983.1580329237543, "episode": 122.0, "batch_reward": 0.8995809050798416, "critic_loss": 0.7096336886882783, "actor_loss": -93.70288446044921, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.708531618118286, "step": 122000}
{"episode_reward": 931.3778197382222, "episode": 123.0, "batch_reward": 0.8994738138318061, "critic_loss": 0.7135049942433834, "actor_loss": -93.48391007995606, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.236305236816406, "step": 123000}
{"episode_reward": 947.7217674685046, "episode": 124.0, "batch_reward": 0.8991893101930618, "critic_loss": 0.7151299182027578, "actor_loss": -93.76092095947266, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.30306100845337, "step": 124000}
{"episode_reward": 974.7005927831841, "episode": 125.0, "batch_reward": 0.9007968377470971, "critic_loss": 0.734130999520421, "actor_loss": -93.82244522094726, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.40245819091797, "step": 125000}
{"episode_reward": 982.3148132273775, "episode": 126.0, "batch_reward": 0.901832228899002, "critic_loss": 0.7193309298455716, "actor_loss": -93.89559114074707, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.4799325466156, "step": 126000}
{"episode_reward": 980.9112987984021, "episode": 127.0, "batch_reward": 0.9020027890205383, "critic_loss": 0.6845630892515182, "actor_loss": -93.8461872253418, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.382155895233154, "step": 127000}
{"episode_reward": 944.9488605545872, "episode": 128.0, "batch_reward": 0.9012754470109939, "critic_loss": 0.700720537558198, "actor_loss": -94.08076313781739, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.980392694473267, "step": 128000}
{"episode_reward": 969.0615713322705, "episode": 129.0, "batch_reward": 0.9025587528347969, "critic_loss": 0.6472324564009905, "actor_loss": -94.12434906005859, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.87497878074646, "step": 129000}
{"episode_reward": 981.0468826293736, "episode": 130.0, "batch_reward": 0.9039234851002693, "critic_loss": 0.6860486420542001, "actor_loss": -94.01517422485351, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.85583758354187, "step": 130000}
{"episode_reward": 987.919886507339, "episode": 131.0, "batch_reward": 0.9047484735846519, "critic_loss": 0.6363669813126326, "actor_loss": -94.16466432189941, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.31106781959534, "step": 131000}
{"episode_reward": 983.8174667779323, "episode": 132.0, "batch_reward": 0.9048375849723815, "critic_loss": 0.6160228832364082, "actor_loss": -94.04093214416504, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.03871464729309, "step": 132000}
{"episode_reward": 983.9079623182679, "episode": 133.0, "batch_reward": 0.9041475032567978, "critic_loss": 0.6313885714411736, "actor_loss": -94.09523428344727, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.50418710708618, "step": 133000}
{"episode_reward": 955.8258723510056, "episode": 134.0, "batch_reward": 0.9055488284826279, "critic_loss": 0.6007216306477785, "actor_loss": -94.14805242919923, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.092509031295776, "step": 134000}
{"episode_reward": 958.6233557868701, "episode": 135.0, "batch_reward": 0.907259850680828, "critic_loss": 0.610144623324275, "actor_loss": -94.23394482421875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.057796239852905, "step": 135000}
{"episode_reward": 992.5523142438441, "episode": 136.0, "batch_reward": 0.907367168366909, "critic_loss": 0.6026408738791943, "actor_loss": -94.36061839294433, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.402026653289795, "step": 136000}
{"episode_reward": 985.3615754497167, "episode": 137.0, "batch_reward": 0.9065355692505837, "critic_loss": 0.6113616567552089, "actor_loss": -94.10021601867676, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.012667655944824, "step": 137000}
{"episode_reward": 984.0474224035067, "episode": 138.0, "batch_reward": 0.9079627829790116, "critic_loss": 0.6020810872018337, "actor_loss": -94.14385652160645, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.643831968307495, "step": 138000}
{"episode_reward": 954.8877315277634, "episode": 139.0, "batch_reward": 0.9074062352776527, "critic_loss": 0.5971633099764585, "actor_loss": -94.1354591369629, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.884363889694214, "step": 139000}
{"episode_reward": 985.1255849010506, "episode": 140.0, "batch_reward": 0.9086007386445999, "critic_loss": 0.6048632284104825, "actor_loss": -94.13601927185059, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.10374641418457, "step": 140000}
{"episode_reward": 949.8012535199563, "episode": 141.0, "batch_reward": 0.9093568604588509, "critic_loss": 0.5916976549178362, "actor_loss": -94.13740466308593, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.98574209213257, "step": 141000}
{"episode_reward": 963.2564188429546, "episode": 142.0, "batch_reward": 0.9092131286859513, "critic_loss": 0.5756960581243038, "actor_loss": -94.23663537597656, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.3130784034729, "step": 142000}
{"episode_reward": 988.50792191604, "episode": 143.0, "batch_reward": 0.9095214197039604, "critic_loss": 0.6109624301046133, "actor_loss": -94.30733267211914, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.13438320159912, "step": 143000}
{"episode_reward": 927.1252680411073, "episode": 144.0, "batch_reward": 0.9099111430644989, "critic_loss": 0.6024852704256773, "actor_loss": -94.35767755126953, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.298630714416504, "step": 144000}
{"episode_reward": 931.1704612103862, "episode": 145.0, "batch_reward": 0.9110410990715027, "critic_loss": 0.5787209488451481, "actor_loss": -94.33717852783204, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.09092664718628, "step": 145000}
{"episode_reward": 985.0581289313562, "episode": 146.0, "batch_reward": 0.9101868539452552, "critic_loss": 0.5881048049628734, "actor_loss": -94.25737327575683, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.103062629699707, "step": 146000}
{"episode_reward": 960.9267783929239, "episode": 147.0, "batch_reward": 0.911050899207592, "critic_loss": 0.5843737843930721, "actor_loss": -94.36733836364746, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.0377779006958, "step": 147000}
{"episode_reward": 906.6232119339634, "episode": 148.0, "batch_reward": 0.9115218538641929, "critic_loss": 0.5762882389873266, "actor_loss": -94.25421138000489, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.710650205612183, "step": 148000}
{"episode_reward": 984.4957193258952, "episode": 149.0, "batch_reward": 0.9112514823675155, "critic_loss": 0.5679192131012678, "actor_loss": -94.31622116088867, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.49042844772339, "step": 149000}
{"episode_reward": 961.1598081965329, "episode": 150.0, "batch_reward": 0.9115490538477897, "critic_loss": 0.5705499104559422, "actor_loss": -94.37721147155762, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
