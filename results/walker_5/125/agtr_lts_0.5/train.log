{"episode_reward": 0.0, "episode": 1.0, "duration": 24.660634994506836, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 2.1802380084991455, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.5038047313948558, "critic_loss": 0.6887166347055286, "actor_loss": -88.4387728022117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 95.47062373161316, "step": 3000}
{"episode_reward": 944.7285040781328, "episode": 4.0, "batch_reward": 0.6763838844895362, "critic_loss": 0.6542844781577587, "actor_loss": -94.97819750976562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.658138036727905, "step": 4000}
{"episode_reward": 974.7589899677871, "episode": 5.0, "batch_reward": 0.7378124566674232, "critic_loss": 0.7870476998984813, "actor_loss": -97.33938288879395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.54942321777344, "step": 5000}
{"episode_reward": 935.6906257641186, "episode": 6.0, "batch_reward": 0.7592171146273613, "critic_loss": 1.1122895712852479, "actor_loss": -98.00134982299805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.05073809623718, "step": 6000}
{"episode_reward": 570.6796609577048, "episode": 7.0, "batch_reward": 0.6740388748645783, "critic_loss": 2.3588393009305, "actor_loss": -99.64823359680176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.56262421607971, "step": 7000}
{"episode_reward": 33.679984507843095, "episode": 8.0, "batch_reward": 0.5948441572487354, "critic_loss": 2.5375711238384246, "actor_loss": -102.02987524414063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.60405945777893, "step": 8000}
{"episode_reward": 75.95089741031245, "episode": 9.0, "batch_reward": 0.5302129681408405, "critic_loss": 2.6470997116565704, "actor_loss": -103.49250135803223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.063170671463013, "step": 9000}
{"episode_reward": 40.960784267833915, "episode": 10.0, "batch_reward": 0.48470395675301553, "critic_loss": 2.83683274435997, "actor_loss": -104.72689567565918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.65253949165344, "step": 10000}
{"episode_reward": 74.7015159870133, "episode": 11.0, "batch_reward": 0.45327352100610735, "critic_loss": 3.3862509292364122, "actor_loss": -102.89766194152833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 57.27571177482605, "step": 11000}
{"episode_reward": 256.14782189711957, "episode": 12.0, "batch_reward": 0.4247977606654167, "critic_loss": 3.276159803986549, "actor_loss": -103.40076907348633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.34174680709839, "step": 12000}
{"episode_reward": 36.25904826188892, "episode": 13.0, "batch_reward": 0.39210669818520544, "critic_loss": 2.627334988832474, "actor_loss": -103.60161653137207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.27527737617493, "step": 13000}
{"episode_reward": 30.20821762946933, "episode": 14.0, "batch_reward": 0.36874997919797897, "critic_loss": 2.2660086125135424, "actor_loss": -104.20113320922852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.69640326499939, "step": 14000}
{"episode_reward": 45.99644956345509, "episode": 15.0, "batch_reward": 0.34806937527656556, "critic_loss": 2.2140463523864744, "actor_loss": -100.24550349426269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.26513695716858, "step": 15000}
{"episode_reward": 58.608134598410096, "episode": 16.0, "batch_reward": 0.3270009078979492, "critic_loss": 2.115299842953682, "actor_loss": -99.54835227966309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.000345945358276, "step": 16000}
{"episode_reward": 26.61778477090378, "episode": 17.0, "batch_reward": 0.30694071112573146, "critic_loss": 1.9524751156568527, "actor_loss": -100.31998359680176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.62638545036316, "step": 17000}
{"episode_reward": 33.10620044713766, "episode": 18.0, "batch_reward": 0.2911242753267288, "critic_loss": 1.8469718420505523, "actor_loss": -100.2429681854248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.161377906799316, "step": 18000}
{"episode_reward": 31.142786862019424, "episode": 19.0, "batch_reward": 0.2771357294172049, "critic_loss": 1.654152805030346, "actor_loss": -98.32309719848632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.638129234313965, "step": 19000}
{"episode_reward": 34.593021085538474, "episode": 20.0, "batch_reward": 0.2732765952795744, "critic_loss": 1.9929142473936081, "actor_loss": -96.55080743408203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.87468433380127, "step": 20000}
{"episode_reward": 302.85986153881674, "episode": 21.0, "batch_reward": 0.2736022899597883, "critic_loss": 2.2276818752884866, "actor_loss": -94.88664323425293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.32979202270508, "step": 21000}
{"episode_reward": 233.4793342885855, "episode": 22.0, "batch_reward": 0.269265011921525, "critic_loss": 2.1904322862625123, "actor_loss": -94.54959394836426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.3666672706604, "step": 22000}
{"episode_reward": 177.73078724579946, "episode": 23.0, "batch_reward": 0.2678591500222683, "critic_loss": 1.967105737030506, "actor_loss": -93.63429322814942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.775978088378906, "step": 23000}
{"episode_reward": 195.46403090859377, "episode": 24.0, "batch_reward": 0.27382309472560884, "critic_loss": 2.055257083058357, "actor_loss": -91.79831619262696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.45357632637024, "step": 24000}
{"episode_reward": 626.9134779707615, "episode": 25.0, "batch_reward": 0.29223230309784415, "critic_loss": 2.3643797700405123, "actor_loss": -93.75118737792968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.774402379989624, "step": 25000}
{"episode_reward": 891.6097822052278, "episode": 26.0, "batch_reward": 0.3127795989215374, "critic_loss": 2.1069101721048353, "actor_loss": -94.19355319213867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.53936958312988, "step": 26000}
{"episode_reward": 859.115649897297, "episode": 27.0, "batch_reward": 0.333899187207222, "critic_loss": 2.1044213811159134, "actor_loss": -93.74986674499512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.535595417022705, "step": 27000}
{"episode_reward": 791.5677638545782, "episode": 28.0, "batch_reward": 0.3507814134657383, "critic_loss": 2.0502675235271455, "actor_loss": -93.24588249206543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.835293531417847, "step": 28000}
{"episode_reward": 927.7879329247015, "episode": 29.0, "batch_reward": 0.3686964620798826, "critic_loss": 2.155870481610298, "actor_loss": -91.79062603759766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.76365852355957, "step": 29000}
{"episode_reward": 775.2599543470305, "episode": 30.0, "batch_reward": 0.38171860015392306, "critic_loss": 2.1020886142253876, "actor_loss": -92.5583225402832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.26068997383118, "step": 30000}
{"episode_reward": 800.9713244094653, "episode": 31.0, "batch_reward": 0.3980649201273918, "critic_loss": 1.900883611679077, "actor_loss": -92.56868795776367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.888211250305176, "step": 31000}
{"episode_reward": 913.2180613697014, "episode": 32.0, "batch_reward": 0.41242558673024177, "critic_loss": 1.9464243814945221, "actor_loss": -92.08343048095703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.75321865081787, "step": 32000}
{"episode_reward": 750.2086844723941, "episode": 33.0, "batch_reward": 0.4268219677209854, "critic_loss": 1.976583501935005, "actor_loss": -91.99335458374023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.0573627948761, "step": 33000}
{"episode_reward": 903.1594621348553, "episode": 34.0, "batch_reward": 0.44275596243143084, "critic_loss": 1.929948392868042, "actor_loss": -93.11865643310547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.81226372718811, "step": 34000}
{"episode_reward": 972.7659863446113, "episode": 35.0, "batch_reward": 0.4553961095511913, "critic_loss": 1.8932027263641358, "actor_loss": -92.4578355102539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.32868194580078, "step": 35000}
{"episode_reward": 927.1286484020643, "episode": 36.0, "batch_reward": 0.46610351794958116, "critic_loss": 1.998426464319229, "actor_loss": -93.40450778198242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.32807230949402, "step": 36000}
{"episode_reward": 891.134129139783, "episode": 37.0, "batch_reward": 0.47722569727897646, "critic_loss": 1.713409490942955, "actor_loss": -93.81878303527832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.51594924926758, "step": 37000}
{"episode_reward": 901.7690472129725, "episode": 38.0, "batch_reward": 0.49305777296423914, "critic_loss": 1.5430507209300994, "actor_loss": -93.43741738891602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.907201051712036, "step": 38000}
{"episode_reward": 912.1631461045467, "episode": 39.0, "batch_reward": 0.5012826352715493, "critic_loss": 1.5603179793953896, "actor_loss": -92.85850350952148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.06769871711731, "step": 39000}
{"episode_reward": 955.6005284257353, "episode": 40.0, "batch_reward": 0.5147131110727787, "critic_loss": 1.6332659032940864, "actor_loss": -93.01820927429199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.98752737045288, "step": 40000}
{"episode_reward": 806.099638345191, "episode": 41.0, "batch_reward": 0.5190366076231003, "critic_loss": 1.5296807253956795, "actor_loss": -92.80608766174316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 58.248523473739624, "step": 41000}
{"episode_reward": 814.6462566536222, "episode": 42.0, "batch_reward": 0.528025265276432, "critic_loss": 1.4804032227396966, "actor_loss": -93.1390811920166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.516912698745728, "step": 42000}
{"episode_reward": 958.4037686727979, "episode": 43.0, "batch_reward": 0.5399179047346115, "critic_loss": 1.39359638017416, "actor_loss": -92.776279006958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.33860468864441, "step": 43000}
{"episode_reward": 889.7810644706651, "episode": 44.0, "batch_reward": 0.5481890913248062, "critic_loss": 1.2618028877973557, "actor_loss": -92.43381163024902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.86728549003601, "step": 44000}
{"episode_reward": 984.9430396227964, "episode": 45.0, "batch_reward": 0.5561661256551742, "critic_loss": 1.1563247446417808, "actor_loss": -91.98977439880372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.761921644210815, "step": 45000}
{"episode_reward": 946.2341248637753, "episode": 46.0, "batch_reward": 0.5650936278104782, "critic_loss": 1.0738233419060708, "actor_loss": -92.2634356842041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.405670166015625, "step": 46000}
{"episode_reward": 963.4961903033906, "episode": 47.0, "batch_reward": 0.5754704387187958, "critic_loss": 0.9829703230261803, "actor_loss": -92.1522774810791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.4014458656311, "step": 47000}
{"episode_reward": 975.8934258838906, "episode": 48.0, "batch_reward": 0.5794118975102901, "critic_loss": 0.9879971920251847, "actor_loss": -91.8684959564209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.741785764694214, "step": 48000}
{"episode_reward": 798.4263850900675, "episode": 49.0, "batch_reward": 0.5866738509833813, "critic_loss": 0.9811108791232109, "actor_loss": -91.47737910461426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.86532711982727, "step": 49000}
{"episode_reward": 899.2515180103388, "episode": 50.0, "batch_reward": 0.59295483481884, "critic_loss": 0.9047974928915501, "actor_loss": -91.17506761169433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.559252738952637, "step": 50000}
{"episode_reward": 983.9868137694579, "episode": 51.0, "batch_reward": 0.6032043892145157, "critic_loss": 0.9083800216317177, "actor_loss": -91.28630297851562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.179776668548584, "step": 51000}
{"episode_reward": 982.8000890236437, "episode": 52.0, "batch_reward": 0.6060219310820103, "critic_loss": 0.9105405048727989, "actor_loss": -90.96164900207519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.42011570930481, "step": 52000}
{"episode_reward": 944.7614601301727, "episode": 53.0, "batch_reward": 0.616172195315361, "critic_loss": 0.8722832697927951, "actor_loss": -90.95842910766602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.574440479278564, "step": 53000}
{"episode_reward": 950.2441905744085, "episode": 54.0, "batch_reward": 0.6206188064813614, "critic_loss": 0.855303401350975, "actor_loss": -90.74182632446289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.807876110076904, "step": 54000}
{"episode_reward": 933.6173345253535, "episode": 55.0, "batch_reward": 0.6285942108631134, "critic_loss": 0.8913928183615207, "actor_loss": -90.92675108337403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.90901446342468, "step": 55000}
{"episode_reward": 969.002424371429, "episode": 56.0, "batch_reward": 0.6326871038079261, "critic_loss": 0.8861604248285293, "actor_loss": -90.8061958770752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.693164587020874, "step": 56000}
{"episode_reward": 987.9494033005984, "episode": 57.0, "batch_reward": 0.6405055157542229, "critic_loss": 0.8609037746787072, "actor_loss": -90.84773970031738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.332927703857422, "step": 57000}
{"episode_reward": 944.5391659073131, "episode": 58.0, "batch_reward": 0.6461985604763031, "critic_loss": 0.7979567277729511, "actor_loss": -91.05778028869629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.903791666030884, "step": 58000}
{"episode_reward": 966.8116477156155, "episode": 59.0, "batch_reward": 0.6508078283071518, "critic_loss": 0.803192339926958, "actor_loss": -90.92428707885742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.301584720611572, "step": 59000}
{"episode_reward": 892.9585402368808, "episode": 60.0, "batch_reward": 0.6526130656003952, "critic_loss": 0.7830425353348255, "actor_loss": -90.64771632385253, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.155445337295532, "step": 60000}
{"episode_reward": 909.6620586782625, "episode": 61.0, "batch_reward": 0.6565492178797722, "critic_loss": 0.8095674051344395, "actor_loss": -90.70462132263184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.08998417854309, "step": 61000}
{"episode_reward": 911.1110637227919, "episode": 62.0, "batch_reward": 0.6623856317400932, "critic_loss": 0.7805161968171597, "actor_loss": -90.80414457702636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.03123927116394, "step": 62000}
{"episode_reward": 952.9039761333269, "episode": 63.0, "batch_reward": 0.6663791202306747, "critic_loss": 0.7481571158468723, "actor_loss": -90.7574779663086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.56223964691162, "step": 63000}
{"episode_reward": 922.2795484604111, "episode": 64.0, "batch_reward": 0.6703637399673462, "critic_loss": 0.7398895343244076, "actor_loss": -90.93881729125977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.92232942581177, "step": 64000}
{"episode_reward": 983.422280933184, "episode": 65.0, "batch_reward": 0.6750751789808274, "critic_loss": 0.7193660189807415, "actor_loss": -90.90290142822266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.11575508117676, "step": 65000}
{"episode_reward": 976.1222480962318, "episode": 66.0, "batch_reward": 0.6803908287882805, "critic_loss": 0.7092081066966057, "actor_loss": -90.86478398132324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.851205587387085, "step": 66000}
{"episode_reward": 927.2173520686468, "episode": 67.0, "batch_reward": 0.6832281699180603, "critic_loss": 0.7322141456902027, "actor_loss": -90.84022714233399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.507984399795532, "step": 67000}
{"episode_reward": 905.825775381876, "episode": 68.0, "batch_reward": 0.6864425610899926, "critic_loss": 0.6989640623927117, "actor_loss": -90.88188487243653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.98610281944275, "step": 68000}
{"episode_reward": 937.585704149483, "episode": 69.0, "batch_reward": 0.6910275554656983, "critic_loss": 0.6838453451693058, "actor_loss": -90.86872439575195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.01200222969055, "step": 69000}
{"episode_reward": 987.0268695767102, "episode": 70.0, "batch_reward": 0.6933818193078041, "critic_loss": 0.7191656413972378, "actor_loss": -90.91153259277344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.375170707702637, "step": 70000}
{"episode_reward": 896.3783771885871, "episode": 71.0, "batch_reward": 0.6991431757807731, "critic_loss": 0.7320648794174194, "actor_loss": -91.04942576599122, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.17267060279846, "step": 71000}
{"episode_reward": 928.3195244217122, "episode": 72.0, "batch_reward": 0.7008953540325165, "critic_loss": 0.7221235278844833, "actor_loss": -90.95169230651855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.722622871398926, "step": 72000}
{"episode_reward": 976.6302961392713, "episode": 73.0, "batch_reward": 0.7047041043639183, "critic_loss": 0.7139678077697754, "actor_loss": -90.82221159362793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.23652005195618, "step": 73000}
{"episode_reward": 957.3117522616119, "episode": 74.0, "batch_reward": 0.7087457903623581, "critic_loss": 0.7232563490271569, "actor_loss": -90.86383416748046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.475157499313354, "step": 74000}
{"episode_reward": 899.7875456921821, "episode": 75.0, "batch_reward": 0.7097058205008506, "critic_loss": 0.7185360601246357, "actor_loss": -90.78956741333008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.448018074035645, "step": 75000}
{"episode_reward": 941.7368759515483, "episode": 76.0, "batch_reward": 0.713407335460186, "critic_loss": 0.7373227525353432, "actor_loss": -90.79221075439453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.725019454956055, "step": 76000}
{"episode_reward": 928.6556459404752, "episode": 77.0, "batch_reward": 0.7136457667946815, "critic_loss": 0.7425559862852097, "actor_loss": -90.71505889892578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.681450843811035, "step": 77000}
{"episode_reward": 907.2600665085492, "episode": 78.0, "batch_reward": 0.7190659006237984, "critic_loss": 0.7406193189918995, "actor_loss": -90.83269717407227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.325759649276733, "step": 78000}
{"episode_reward": 930.6920729037869, "episode": 79.0, "batch_reward": 0.7222960019707679, "critic_loss": 0.7662038035988807, "actor_loss": -90.85774844360351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.308269739151, "step": 79000}
{"episode_reward": 961.4662418599837, "episode": 80.0, "batch_reward": 0.7263076823353768, "critic_loss": 0.7239498689770698, "actor_loss": -90.87093591308594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.76666879653931, "step": 80000}
{"episode_reward": 982.3130707892293, "episode": 81.0, "batch_reward": 0.7295161271691323, "critic_loss": 0.7078325995802879, "actor_loss": -91.0468702697754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.681620359420776, "step": 81000}
{"episode_reward": 948.0832817727896, "episode": 82.0, "batch_reward": 0.7324413051009178, "critic_loss": 0.688795687675476, "actor_loss": -91.07554429626465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.104423999786377, "step": 82000}
{"episode_reward": 954.8548937172825, "episode": 83.0, "batch_reward": 0.7340502380728722, "critic_loss": 0.6911032107174396, "actor_loss": -91.03908712768555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.823551177978516, "step": 83000}
{"episode_reward": 932.9783005802901, "episode": 84.0, "batch_reward": 0.7372936955094338, "critic_loss": 0.6829549840390682, "actor_loss": -91.11885862731934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.335548639297485, "step": 84000}
{"episode_reward": 989.3755066489769, "episode": 85.0, "batch_reward": 0.7360906068682671, "critic_loss": 0.716660650074482, "actor_loss": -90.92955645751952, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.93350124359131, "step": 85000}
{"episode_reward": 800.0314614706799, "episode": 86.0, "batch_reward": 0.7387136942148209, "critic_loss": 0.7001578234732151, "actor_loss": -90.84219181823731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.80732297897339, "step": 86000}
{"episode_reward": 955.8427585295, "episode": 87.0, "batch_reward": 0.7414515793323517, "critic_loss": 0.69425548017025, "actor_loss": -91.05345959472656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.66628098487854, "step": 87000}
{"episode_reward": 952.7026306873098, "episode": 88.0, "batch_reward": 0.743406068444252, "critic_loss": 0.7221362430453301, "actor_loss": -91.04581159973145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.834762811660767, "step": 88000}
{"episode_reward": 886.36988252484, "episode": 89.0, "batch_reward": 0.7438460908532143, "critic_loss": 0.7135086108148098, "actor_loss": -90.98244380187988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.354957103729248, "step": 89000}
{"episode_reward": 948.558416208258, "episode": 90.0, "batch_reward": 0.7484851814508439, "critic_loss": 0.6532078948020935, "actor_loss": -91.16948034667969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.44383978843689, "step": 90000}
{"episode_reward": 929.3333572508368, "episode": 91.0, "batch_reward": 0.7511641280651092, "critic_loss": 0.6525461040139199, "actor_loss": -91.09501153564453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.00389122962952, "step": 91000}
{"episode_reward": 962.82556905, "episode": 92.0, "batch_reward": 0.7543025268912316, "critic_loss": 0.6415604098141193, "actor_loss": -91.24337673950195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.80975031852722, "step": 92000}
{"episode_reward": 968.9686664548601, "episode": 93.0, "batch_reward": 0.7547549883723259, "critic_loss": 0.6509744271934033, "actor_loss": -91.22914576721192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.46035194396973, "step": 93000}
{"episode_reward": 983.1679284154326, "episode": 94.0, "batch_reward": 0.7581577551364899, "critic_loss": 0.6504856110811233, "actor_loss": -91.33456848144532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.10346436500549, "step": 94000}
{"episode_reward": 959.896646052534, "episode": 95.0, "batch_reward": 0.7595529261231423, "critic_loss": 0.662566747277975, "actor_loss": -91.34864848327636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.06132674217224, "step": 95000}
{"episode_reward": 898.1568087502548, "episode": 96.0, "batch_reward": 0.7607325096726417, "critic_loss": 0.7119842811971903, "actor_loss": -91.41087409973144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.736643075942993, "step": 96000}
{"episode_reward": 959.5092702711983, "episode": 97.0, "batch_reward": 0.76152941685915, "critic_loss": 0.6609324728101492, "actor_loss": -91.31388963317872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.553781747817993, "step": 97000}
{"episode_reward": 928.7476317610426, "episode": 98.0, "batch_reward": 0.7642544452548027, "critic_loss": 0.648583193436265, "actor_loss": -91.41935018920898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.687943696975708, "step": 98000}
{"episode_reward": 928.0141050403607, "episode": 99.0, "batch_reward": 0.766675142288208, "critic_loss": 0.6648070137798786, "actor_loss": -91.4668397064209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.722689151763916, "step": 99000}
{"episode_reward": 946.9612956132187, "episode": 100.0, "batch_reward": 0.770918951690197, "critic_loss": 0.6789236158132553, "actor_loss": -91.46650561523437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.6478853225708, "step": 100000}
{"episode_reward": 762.6569484530285, "episode": 101.0, "batch_reward": 0.769796860218048, "critic_loss": 0.6899959123730659, "actor_loss": -91.51937460327149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.339640617370605, "step": 101000}
{"episode_reward": 985.4796813138213, "episode": 102.0, "batch_reward": 0.7683877254128456, "critic_loss": 0.6793209991157055, "actor_loss": -91.4659434967041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.50557589530945, "step": 102000}
{"episode_reward": 929.0039543670296, "episode": 103.0, "batch_reward": 0.7704298988580703, "critic_loss": 0.686673106059432, "actor_loss": -91.37252648925781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.14195990562439, "step": 103000}
{"episode_reward": 943.1342577182494, "episode": 104.0, "batch_reward": 0.7757158135771751, "critic_loss": 0.7022954299449921, "actor_loss": -91.49303189086915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.158462047576904, "step": 104000}
{"episode_reward": 959.6831088638972, "episode": 105.0, "batch_reward": 0.774970325767994, "critic_loss": 0.69312592035532, "actor_loss": -91.47376219177247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.69536781311035, "step": 105000}
{"episode_reward": 883.0436144072764, "episode": 106.0, "batch_reward": 0.77517956250906, "critic_loss": 0.7135442733764649, "actor_loss": -91.3610626220703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.819112062454224, "step": 106000}
{"episode_reward": 907.6049597790333, "episode": 107.0, "batch_reward": 0.7773454961776733, "critic_loss": 0.6631056959629059, "actor_loss": -91.32094857788086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.724292755126953, "step": 107000}
{"episode_reward": 961.5017947980679, "episode": 108.0, "batch_reward": 0.7804207573533058, "critic_loss": 0.6656781103461981, "actor_loss": -91.50444033813477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.216510772705078, "step": 108000}
{"episode_reward": 908.1590304079007, "episode": 109.0, "batch_reward": 0.7801692167520523, "critic_loss": 0.63083897562325, "actor_loss": -91.3901106414795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.57222938537598, "step": 109000}
{"episode_reward": 973.3866988985192, "episode": 110.0, "batch_reward": 0.7818324130177497, "critic_loss": 0.6716051252633333, "actor_loss": -91.5449458618164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.91392517089844, "step": 110000}
{"episode_reward": 894.1552374334772, "episode": 111.0, "batch_reward": 0.7853651642203331, "critic_loss": 0.6661883256882429, "actor_loss": -91.58425259399414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.303202867507935, "step": 111000}
{"episode_reward": 939.2985226564094, "episode": 112.0, "batch_reward": 0.7859432637095451, "critic_loss": 0.6376638132333755, "actor_loss": -91.55086376953125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.556363821029663, "step": 112000}
{"episode_reward": 935.9267174827684, "episode": 113.0, "batch_reward": 0.7867124574780464, "critic_loss": 0.6878053019195796, "actor_loss": -91.56141485595703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.43591833114624, "step": 113000}
{"episode_reward": 960.947192425098, "episode": 114.0, "batch_reward": 0.7860190271139145, "critic_loss": 0.6361838905364275, "actor_loss": -91.65884182739258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.840461015701294, "step": 114000}
{"episode_reward": 976.1370322803532, "episode": 115.0, "batch_reward": 0.789913807630539, "critic_loss": 0.6275695793181658, "actor_loss": -91.6144454498291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.91515612602234, "step": 115000}
{"episode_reward": 920.1432418431921, "episode": 116.0, "batch_reward": 0.79069792085886, "critic_loss": 0.6456416943967342, "actor_loss": -91.75281355285645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.245675325393677, "step": 116000}
{"episode_reward": 945.7642103834132, "episode": 117.0, "batch_reward": 0.7922445866465568, "critic_loss": 0.650286975428462, "actor_loss": -91.71590905761718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.559813976287842, "step": 117000}
{"episode_reward": 934.9775049104281, "episode": 118.0, "batch_reward": 0.7921909279227257, "critic_loss": 0.6513650809228421, "actor_loss": -91.74741812133789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.756086349487305, "step": 118000}
{"episode_reward": 989.1613548017853, "episode": 119.0, "batch_reward": 0.7952675784230232, "critic_loss": 0.6508412000089884, "actor_loss": -91.97390092468262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.53653526306152, "step": 119000}
{"episode_reward": 952.2907023543231, "episode": 120.0, "batch_reward": 0.7903660524487496, "critic_loss": 0.6866314682662487, "actor_loss": -91.72311044311523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.72475337982178, "step": 120000}
{"episode_reward": 55.39433616912418, "episode": 121.0, "batch_reward": 0.7898760034441948, "critic_loss": 0.6616714996695519, "actor_loss": -91.7251773223877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.55216884613037, "step": 121000}
{"episode_reward": 985.1665470757905, "episode": 122.0, "batch_reward": 0.7915487164855003, "critic_loss": 0.6833617448359728, "actor_loss": -91.77308238220215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.055432319641113, "step": 122000}
{"episode_reward": 945.3228616576536, "episode": 123.0, "batch_reward": 0.7953829995393753, "critic_loss": 0.6351941472589969, "actor_loss": -91.78647897338867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.52755570411682, "step": 123000}
{"episode_reward": 963.5424033550913, "episode": 124.0, "batch_reward": 0.7938969325423241, "critic_loss": 0.6600916478931904, "actor_loss": -91.89082096862793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.549856185913086, "step": 124000}
{"episode_reward": 987.2172675105298, "episode": 125.0, "batch_reward": 0.7969875905513764, "critic_loss": 0.6476778581142425, "actor_loss": -91.91539463806153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.5230598449707, "step": 125000}
{"episode_reward": 985.7204115906181, "episode": 126.0, "batch_reward": 0.7971956042647361, "critic_loss": 0.6194380253702402, "actor_loss": -92.04200172424316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.24428939819336, "step": 126000}
{"episode_reward": 985.5219993064553, "episode": 127.0, "batch_reward": 0.7997388347387314, "critic_loss": 0.6219692010730505, "actor_loss": -92.0300767211914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.61453938484192, "step": 127000}
{"episode_reward": 943.1865355080963, "episode": 128.0, "batch_reward": 0.8004411805272102, "critic_loss": 0.6228071320354939, "actor_loss": -92.05626959228516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.00675702095032, "step": 128000}
{"episode_reward": 964.154187211838, "episode": 129.0, "batch_reward": 0.8014392924308776, "critic_loss": 0.6039900248795748, "actor_loss": -92.12439894104004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.37728476524353, "step": 129000}
{"episode_reward": 980.7148114179746, "episode": 130.0, "batch_reward": 0.8041447630524635, "critic_loss": 0.6031698900014162, "actor_loss": -92.21752729797363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.960793018341064, "step": 130000}
{"episode_reward": 989.9843923580191, "episode": 131.0, "batch_reward": 0.8049904273152352, "critic_loss": 0.6485841498076915, "actor_loss": -92.13464825439453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.07268524169922, "step": 131000}
{"episode_reward": 901.794370119556, "episode": 132.0, "batch_reward": 0.8051296377778053, "critic_loss": 0.6171167716979981, "actor_loss": -92.17320077514648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.89161252975464, "step": 132000}
{"episode_reward": 982.2702896753507, "episode": 133.0, "batch_reward": 0.8045971928834915, "critic_loss": 0.6008988048285245, "actor_loss": -92.25836456298828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.92358756065369, "step": 133000}
{"episode_reward": 961.5559918799786, "episode": 134.0, "batch_reward": 0.8059287139773369, "critic_loss": 0.6018351314663887, "actor_loss": -92.27397505187989, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.67184090614319, "step": 134000}
{"episode_reward": 966.0764687700415, "episode": 135.0, "batch_reward": 0.809299584031105, "critic_loss": 0.5789907054007053, "actor_loss": -92.27451420593262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.83140707015991, "step": 135000}
{"episode_reward": 990.5873013392971, "episode": 136.0, "batch_reward": 0.8106390200853347, "critic_loss": 0.5794259043633938, "actor_loss": -92.39329933166503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.596577882766724, "step": 136000}
{"episode_reward": 988.014415032852, "episode": 137.0, "batch_reward": 0.8114373429417611, "critic_loss": 0.5924441591799259, "actor_loss": -92.39077331542968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.406091690063477, "step": 137000}
{"episode_reward": 985.7579026676376, "episode": 138.0, "batch_reward": 0.813929988026619, "critic_loss": 0.5681638041287661, "actor_loss": -92.45580982971191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.84127855300903, "step": 138000}
{"episode_reward": 953.0928220703994, "episode": 139.0, "batch_reward": 0.8131182770729065, "critic_loss": 0.5982452805191278, "actor_loss": -92.42349365234375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.57822775840759, "step": 139000}
{"episode_reward": 987.4877735950357, "episode": 140.0, "batch_reward": 0.8126614508628845, "critic_loss": 0.5720260367691516, "actor_loss": -92.42349774169922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.512558698654175, "step": 140000}
{"episode_reward": 807.6127744111686, "episode": 141.0, "batch_reward": 0.8156818553805352, "critic_loss": 0.5458987694084644, "actor_loss": -92.46662541198731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.15959548950195, "step": 141000}
{"episode_reward": 954.341791586945, "episode": 142.0, "batch_reward": 0.8168811393380165, "critic_loss": 0.5593775560110807, "actor_loss": -92.4758250579834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.783843278884888, "step": 142000}
{"episode_reward": 989.7213998150106, "episode": 143.0, "batch_reward": 0.8170715338587761, "critic_loss": 0.5690856812149286, "actor_loss": -92.4820728149414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.59695553779602, "step": 143000}
{"episode_reward": 949.4478537860053, "episode": 144.0, "batch_reward": 0.8177816634774208, "critic_loss": 0.5661176328659058, "actor_loss": -92.52963102722168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.543975830078125, "step": 144000}
{"episode_reward": 959.8521391717214, "episode": 145.0, "batch_reward": 0.8194688229560853, "critic_loss": 0.5797332867085934, "actor_loss": -92.60847248840332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.479397535324097, "step": 145000}
{"episode_reward": 986.7450888485279, "episode": 146.0, "batch_reward": 0.820073314666748, "critic_loss": 0.552250970646739, "actor_loss": -92.69018382263184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.813013315200806, "step": 146000}
{"episode_reward": 970.988925259429, "episode": 147.0, "batch_reward": 0.819484152495861, "critic_loss": 0.5589120978116989, "actor_loss": -92.60890290832519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.85033392906189, "step": 147000}
{"episode_reward": 962.1409370121501, "episode": 148.0, "batch_reward": 0.8225358173251152, "critic_loss": 0.5311354892402887, "actor_loss": -92.74618045043945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.20940065383911, "step": 148000}
{"episode_reward": 986.8953037388238, "episode": 149.0, "batch_reward": 0.8226081418395043, "critic_loss": 0.5386012543737888, "actor_loss": -92.77321345520019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.43942666053772, "step": 149000}
{"episode_reward": 937.6932326257665, "episode": 150.0, "batch_reward": 0.8241287118792534, "critic_loss": 0.5662578411102295, "actor_loss": -92.87018838500977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
