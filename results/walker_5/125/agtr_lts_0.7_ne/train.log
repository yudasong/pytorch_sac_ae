{"episode_reward": 0.0, "episode": 1.0, "duration": 20.691490173339844, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.8020269870758057, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.49367921709736096, "critic_loss": 1.3458947266149854, "actor_loss": -86.81449496302427, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.37952971458435, "step": 3000}
{"episode_reward": 781.292175665996, "episode": 4.0, "batch_reward": 0.6119910664260387, "critic_loss": 1.6171350566148759, "actor_loss": -89.6582233581543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.501769542694092, "step": 4000}
{"episode_reward": 841.2030411355023, "episode": 5.0, "batch_reward": 0.6760788151025772, "critic_loss": 1.3791850546598434, "actor_loss": -90.96881416320801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.554206132888794, "step": 5000}
{"episode_reward": 894.6436766212231, "episode": 6.0, "batch_reward": 0.7126840580105781, "critic_loss": 1.1142616719007492, "actor_loss": -91.3222663269043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.529292821884155, "step": 6000}
{"episode_reward": 951.3364254336668, "episode": 7.0, "batch_reward": 0.7401351993083953, "critic_loss": 1.246119172334671, "actor_loss": -91.55713230895996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.539584398269653, "step": 7000}
{"episode_reward": 802.8350506066424, "episode": 8.0, "batch_reward": 0.7512726396918297, "critic_loss": 1.290124351799488, "actor_loss": -91.42367695617676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.538856983184814, "step": 8000}
{"episode_reward": 847.5899648081178, "episode": 9.0, "batch_reward": 0.7611604563593865, "critic_loss": 1.2620830846428872, "actor_loss": -91.43896565246582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.538022994995117, "step": 9000}
{"episode_reward": 892.6407598770421, "episode": 10.0, "batch_reward": 0.7708993346095085, "critic_loss": 1.1828203437924385, "actor_loss": -91.40959574890137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.536619186401367, "step": 10000}
{"episode_reward": 815.4541742927896, "episode": 11.0, "batch_reward": 0.7778544813394547, "critic_loss": 1.1297733597755433, "actor_loss": -91.38087829589844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.93891620635986, "step": 11000}
{"episode_reward": 880.0902399449109, "episode": 12.0, "batch_reward": 0.7844446198940277, "critic_loss": 1.141027461707592, "actor_loss": -91.18339501953125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.54572296142578, "step": 12000}
{"episode_reward": 854.9323141746202, "episode": 13.0, "batch_reward": 0.7924169780611992, "critic_loss": 1.1042210346460342, "actor_loss": -91.36452816772461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.537614583969116, "step": 13000}
{"episode_reward": 917.2158267183039, "episode": 14.0, "batch_reward": 0.8074627463817596, "critic_loss": 1.0142191382050514, "actor_loss": -91.47951629638672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.54935574531555, "step": 14000}
{"episode_reward": 973.3947581044404, "episode": 15.0, "batch_reward": 0.8168717961907387, "critic_loss": 1.076169332742691, "actor_loss": -92.05947204589843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.517107009887695, "step": 15000}
{"episode_reward": 833.4428575193931, "episode": 16.0, "batch_reward": 0.8186346887946129, "critic_loss": 1.0088788361549377, "actor_loss": -91.81464682006836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.49820876121521, "step": 16000}
{"episode_reward": 901.827899145277, "episode": 17.0, "batch_reward": 0.8203118572831154, "critic_loss": 0.9319189249575138, "actor_loss": -91.6587374572754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51775026321411, "step": 17000}
{"episode_reward": 875.7175403030644, "episode": 18.0, "batch_reward": 0.8257731790542603, "critic_loss": 0.9716557577252388, "actor_loss": -91.77933372497559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.510174989700317, "step": 18000}
{"episode_reward": 914.8247176771697, "episode": 19.0, "batch_reward": 0.8319423624873161, "critic_loss": 0.9850362091064453, "actor_loss": -91.83936264038086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.534191131591797, "step": 19000}
{"episode_reward": 959.2853671676999, "episode": 20.0, "batch_reward": 0.8394772284626961, "critic_loss": 0.901211787879467, "actor_loss": -92.14737591552735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.49492573738098, "step": 20000}
{"episode_reward": 958.9664672181942, "episode": 21.0, "batch_reward": 0.8400268194675445, "critic_loss": 0.9403490175008774, "actor_loss": -92.15354983520508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.93390870094299, "step": 21000}
{"episode_reward": 863.684209833686, "episode": 22.0, "batch_reward": 0.8471775383353234, "critic_loss": 0.9403856768012047, "actor_loss": -92.14252056884766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.540459394454956, "step": 22000}
{"episode_reward": 965.9550498621504, "episode": 23.0, "batch_reward": 0.8514083687067032, "critic_loss": 0.8717120218276978, "actor_loss": -92.39902404785157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.552268028259277, "step": 23000}
{"episode_reward": 952.1741815269196, "episode": 24.0, "batch_reward": 0.8536903596520424, "critic_loss": 0.8565713340938091, "actor_loss": -92.50807293701172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.507889986038208, "step": 24000}
{"episode_reward": 978.950594679366, "episode": 25.0, "batch_reward": 0.8588448664546013, "critic_loss": 0.8241665436923504, "actor_loss": -92.41898323059083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.55715560913086, "step": 25000}
{"episode_reward": 910.6653284212197, "episode": 26.0, "batch_reward": 0.8613283066749573, "critic_loss": 0.778080854088068, "actor_loss": -92.64538591003418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.567079305648804, "step": 26000}
{"episode_reward": 983.0682695069403, "episode": 27.0, "batch_reward": 0.8688903298377991, "critic_loss": 0.7324995850622654, "actor_loss": -92.89729624938965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.550349950790405, "step": 27000}
{"episode_reward": 978.8977405210039, "episode": 28.0, "batch_reward": 0.8708343809247017, "critic_loss": 0.7462717752158642, "actor_loss": -92.83772903442383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.54088592529297, "step": 28000}
{"episode_reward": 944.5533399633149, "episode": 29.0, "batch_reward": 0.8727535746693611, "critic_loss": 0.731807797074318, "actor_loss": -93.06143939208984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.544721603393555, "step": 29000}
{"episode_reward": 939.4758842521674, "episode": 30.0, "batch_reward": 0.8754494997859001, "critic_loss": 0.6970512478947639, "actor_loss": -93.01684118652344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.553085803985596, "step": 30000}
{"episode_reward": 904.6197078480286, "episode": 31.0, "batch_reward": 0.8767981410026551, "critic_loss": 0.651099564254284, "actor_loss": -93.24214778137207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.01880383491516, "step": 31000}
{"episode_reward": 959.5349307466923, "episode": 32.0, "batch_reward": 0.879787720143795, "critic_loss": 0.5880316877961159, "actor_loss": -93.178953125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.548391103744507, "step": 32000}
{"episode_reward": 941.5826114042461, "episode": 33.0, "batch_reward": 0.878555636048317, "critic_loss": 0.6434469166994095, "actor_loss": -93.36945756530761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.549266576766968, "step": 33000}
{"episode_reward": 897.192081267886, "episode": 34.0, "batch_reward": 0.8817836233973503, "critic_loss": 0.6189745270609855, "actor_loss": -93.24249993896484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.54204297065735, "step": 34000}
{"episode_reward": 982.1859107731391, "episode": 35.0, "batch_reward": 0.8834826490283012, "critic_loss": 0.6135138549208641, "actor_loss": -93.48689379882812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.546852111816406, "step": 35000}
{"episode_reward": 884.9918950975632, "episode": 36.0, "batch_reward": 0.8824191851615906, "critic_loss": 0.6608056864142418, "actor_loss": -93.2391647491455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.565497159957886, "step": 36000}
{"episode_reward": 952.4630265298883, "episode": 37.0, "batch_reward": 0.8855077837109566, "critic_loss": 0.6575707420408726, "actor_loss": -93.45231314086914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.552255630493164, "step": 37000}
{"episode_reward": 959.5743183674258, "episode": 38.0, "batch_reward": 0.8870562008023262, "critic_loss": 0.6244933488965034, "actor_loss": -93.53222387695313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.553154230117798, "step": 38000}
{"episode_reward": 937.9873843623683, "episode": 39.0, "batch_reward": 0.8897915195226669, "critic_loss": 0.6190292443186045, "actor_loss": -93.70140765380859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.53256845474243, "step": 39000}
{"episode_reward": 952.951681170121, "episode": 40.0, "batch_reward": 0.891422824382782, "critic_loss": 0.6398888922929764, "actor_loss": -93.77489903259277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.53500008583069, "step": 40000}
{"episode_reward": 969.8957119853029, "episode": 41.0, "batch_reward": 0.8916541479825973, "critic_loss": 0.6335441789329052, "actor_loss": -93.73354119873046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.9918851852417, "step": 41000}
{"episode_reward": 892.2347718176006, "episode": 42.0, "batch_reward": 0.894075923204422, "critic_loss": 0.613712180763483, "actor_loss": -93.63890394592285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.576666831970215, "step": 42000}
{"episode_reward": 965.5279356917724, "episode": 43.0, "batch_reward": 0.8945315582752228, "critic_loss": 0.6192939732968807, "actor_loss": -93.670775390625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.544730186462402, "step": 43000}
{"episode_reward": 926.4545708859938, "episode": 44.0, "batch_reward": 0.8959688072800637, "critic_loss": 0.5783058407902718, "actor_loss": -93.68543161010743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.527421236038208, "step": 44000}
{"episode_reward": 960.8584524940468, "episode": 45.0, "batch_reward": 0.8968346706628799, "critic_loss": 0.5509619520306587, "actor_loss": -93.87675831604004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51349139213562, "step": 45000}
{"episode_reward": 953.6190163572477, "episode": 46.0, "batch_reward": 0.8973840273022652, "critic_loss": 0.5566099838465453, "actor_loss": -93.82518765258789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.513741970062256, "step": 46000}
{"episode_reward": 967.6005255956221, "episode": 47.0, "batch_reward": 0.8997601981759071, "critic_loss": 0.5373264464437961, "actor_loss": -94.01047621154785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.537597179412842, "step": 47000}
{"episode_reward": 944.1007172429202, "episode": 48.0, "batch_reward": 0.9009337342381477, "critic_loss": 0.515148885846138, "actor_loss": -93.83102897644044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.547199964523315, "step": 48000}
{"episode_reward": 945.253768282679, "episode": 49.0, "batch_reward": 0.9003035156726837, "critic_loss": 0.5534149896502495, "actor_loss": -94.16138203430175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.529244422912598, "step": 49000}
{"episode_reward": 891.6113273577987, "episode": 50.0, "batch_reward": 0.9024547832608223, "critic_loss": 0.5378408897817135, "actor_loss": -94.14347608947755, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.510201454162598, "step": 50000}
{"episode_reward": 974.9942158518114, "episode": 51.0, "batch_reward": 0.9036390555500984, "critic_loss": 0.5534088113605976, "actor_loss": -94.1538247680664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.96256375312805, "step": 51000}
{"episode_reward": 972.7415600621408, "episode": 52.0, "batch_reward": 0.9035030484199524, "critic_loss": 0.5569127819687129, "actor_loss": -94.23098738098145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52920937538147, "step": 52000}
{"episode_reward": 951.0692759440439, "episode": 53.0, "batch_reward": 0.9046854832172394, "critic_loss": 0.5499620065391063, "actor_loss": -94.23384538269043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.534148931503296, "step": 53000}
{"episode_reward": 956.4258385102605, "episode": 54.0, "batch_reward": 0.9057232043743133, "critic_loss": 0.5407237997949124, "actor_loss": -94.27323104858398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.49651861190796, "step": 54000}
{"episode_reward": 926.3400500732571, "episode": 55.0, "batch_reward": 0.9072778161168098, "critic_loss": 0.557520976960659, "actor_loss": -94.3879916229248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.482409954071045, "step": 55000}
{"episode_reward": 978.4434314367527, "episode": 56.0, "batch_reward": 0.9075141667723655, "critic_loss": 0.5315968972295523, "actor_loss": -94.45409992980957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.50253200531006, "step": 56000}
{"episode_reward": 985.9352178980174, "episode": 57.0, "batch_reward": 0.9088799456954002, "critic_loss": 0.5199626024067402, "actor_loss": -94.41142597961426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.514371156692505, "step": 57000}
{"episode_reward": 920.2291486604861, "episode": 58.0, "batch_reward": 0.9098197466731072, "critic_loss": 0.5049728884249925, "actor_loss": -94.39636585998535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51958918571472, "step": 58000}
{"episode_reward": 980.4949439856906, "episode": 59.0, "batch_reward": 0.910320712864399, "critic_loss": 0.5145694198161364, "actor_loss": -94.47110075378419, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52838158607483, "step": 59000}
{"episode_reward": 919.7372202338614, "episode": 60.0, "batch_reward": 0.9105445981025696, "critic_loss": 0.4956923435628414, "actor_loss": -94.60939755249024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51773428916931, "step": 60000}
{"episode_reward": 951.3042413123442, "episode": 61.0, "batch_reward": 0.9116304721832276, "critic_loss": 0.4905741700679064, "actor_loss": -94.53679374694825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.996060609817505, "step": 61000}
{"episode_reward": 959.865139799464, "episode": 62.0, "batch_reward": 0.9121130514740944, "critic_loss": 0.46970715586841105, "actor_loss": -94.61713204956055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.538143157958984, "step": 62000}
{"episode_reward": 929.5797501846616, "episode": 63.0, "batch_reward": 0.9105521632432938, "critic_loss": 0.47481577028334143, "actor_loss": -94.50068875122071, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.541998863220215, "step": 63000}
{"episode_reward": 920.5709684761366, "episode": 64.0, "batch_reward": 0.9125506452322006, "critic_loss": 0.4671048447936773, "actor_loss": -94.64670506286622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.55993151664734, "step": 64000}
{"episode_reward": 981.6128809913366, "episode": 65.0, "batch_reward": 0.9138217180967331, "critic_loss": 0.48083612516522406, "actor_loss": -94.68126081848145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.525370359420776, "step": 65000}
{"episode_reward": 946.7117274120031, "episode": 66.0, "batch_reward": 0.9128475804328918, "critic_loss": 0.49839506222307683, "actor_loss": -94.66181758117676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.532938957214355, "step": 66000}
{"episode_reward": 874.6606061224728, "episode": 67.0, "batch_reward": 0.912095671415329, "critic_loss": 0.5045648735314607, "actor_loss": -94.66394943237304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.534103393554688, "step": 67000}
{"episode_reward": 910.4176322620272, "episode": 68.0, "batch_reward": 0.9126259412169456, "critic_loss": 0.4905990845263004, "actor_loss": -94.50272624206544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.516515016555786, "step": 68000}
{"episode_reward": 951.3124450150634, "episode": 69.0, "batch_reward": 0.9137578203082085, "critic_loss": 0.5029777248054743, "actor_loss": -94.56763043212891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.55912208557129, "step": 69000}
{"episode_reward": 986.2263662357109, "episode": 70.0, "batch_reward": 0.9136446285247802, "critic_loss": 0.4940336319208145, "actor_loss": -94.72643476867675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.557530164718628, "step": 70000}
{"episode_reward": 865.6277322682123, "episode": 71.0, "batch_reward": 0.9136057476997376, "critic_loss": 0.5213023589849473, "actor_loss": -94.7129793548584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.96732258796692, "step": 71000}
{"episode_reward": 924.582933204379, "episode": 72.0, "batch_reward": 0.9148960294127464, "critic_loss": 0.48485445065796373, "actor_loss": -94.68272706604004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.529035091400146, "step": 72000}
{"episode_reward": 971.6864195720635, "episode": 73.0, "batch_reward": 0.9147209654450417, "critic_loss": 0.49967417135834696, "actor_loss": -94.73180206298828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.528050184249878, "step": 73000}
{"episode_reward": 954.327030380919, "episode": 74.0, "batch_reward": 0.9170241415500641, "critic_loss": 0.5250719536840915, "actor_loss": -94.83253839111327, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.538665533065796, "step": 74000}
{"episode_reward": 955.2892074577369, "episode": 75.0, "batch_reward": 0.9160832971334457, "critic_loss": 0.5252087568044662, "actor_loss": -94.76470863342286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.522059679031372, "step": 75000}
{"episode_reward": 968.1306493900697, "episode": 76.0, "batch_reward": 0.9167189360260963, "critic_loss": 0.5520012570023537, "actor_loss": -94.84045024108887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.541794538497925, "step": 76000}
{"episode_reward": 945.8604088218863, "episode": 77.0, "batch_reward": 0.916708758354187, "critic_loss": 0.6065340906977653, "actor_loss": -94.7025373840332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.534945487976074, "step": 77000}
{"episode_reward": 957.117809655066, "episode": 78.0, "batch_reward": 0.9180158233642578, "critic_loss": 0.5981763489246369, "actor_loss": -94.81841752624511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.544905424118042, "step": 78000}
{"episode_reward": 959.7031659910922, "episode": 79.0, "batch_reward": 0.9180217007398606, "critic_loss": 0.5737941088825464, "actor_loss": -94.6907534790039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.56572437286377, "step": 79000}
{"episode_reward": 971.1894235924406, "episode": 80.0, "batch_reward": 0.9178347825407982, "critic_loss": 0.5579481476098299, "actor_loss": -94.79423735046387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.547765970230103, "step": 80000}
{"episode_reward": 947.497066456232, "episode": 81.0, "batch_reward": 0.9188092209100723, "critic_loss": 0.5374100920706988, "actor_loss": -94.8688067932129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.98675227165222, "step": 81000}
{"episode_reward": 952.3904277471191, "episode": 82.0, "batch_reward": 0.9201873789429664, "critic_loss": 0.5349548493623734, "actor_loss": -94.98665777587891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52915668487549, "step": 82000}
{"episode_reward": 954.9755031561261, "episode": 83.0, "batch_reward": 0.9201453695297241, "critic_loss": 0.5386492227166891, "actor_loss": -94.8314951171875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.560456037521362, "step": 83000}
{"episode_reward": 924.3018372008959, "episode": 84.0, "batch_reward": 0.9212114263176918, "critic_loss": 0.5668678131848573, "actor_loss": -95.05504719543457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.53487253189087, "step": 84000}
{"episode_reward": 988.1683882245229, "episode": 85.0, "batch_reward": 0.9196017808914184, "critic_loss": 0.5077199123203754, "actor_loss": -94.96213821411133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.53779935836792, "step": 85000}
{"episode_reward": 960.2815742654492, "episode": 86.0, "batch_reward": 0.9217664011120796, "critic_loss": 0.5070143259987235, "actor_loss": -94.94719882202149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51142692565918, "step": 86000}
{"episode_reward": 957.837194960898, "episode": 87.0, "batch_reward": 0.9219674236774444, "critic_loss": 0.5317376338690519, "actor_loss": -94.98128427124024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.49938464164734, "step": 87000}
{"episode_reward": 948.4725810594689, "episode": 88.0, "batch_reward": 0.921478735268116, "critic_loss": 0.5375524699985981, "actor_loss": -94.89307431030274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.524429082870483, "step": 88000}
{"episode_reward": 933.8863784432707, "episode": 89.0, "batch_reward": 0.9214362461566925, "critic_loss": 0.4873730444908142, "actor_loss": -95.06005084228515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.54099726676941, "step": 89000}
{"episode_reward": 949.7396608165495, "episode": 90.0, "batch_reward": 0.9230327122211456, "critic_loss": 0.475644942432642, "actor_loss": -95.21001251220703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.539085865020752, "step": 90000}
{"episode_reward": 960.8202221681721, "episode": 91.0, "batch_reward": 0.9229189605712891, "critic_loss": 0.47394104208052157, "actor_loss": -95.03491282653809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.9770143032074, "step": 91000}
{"episode_reward": 935.8398846961428, "episode": 92.0, "batch_reward": 0.9233495815992355, "critic_loss": 0.47110615038871767, "actor_loss": -95.07461689758301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52983546257019, "step": 92000}
{"episode_reward": 962.1797599789577, "episode": 93.0, "batch_reward": 0.9229076882004738, "critic_loss": 0.470757188141346, "actor_loss": -95.03020582580567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51590633392334, "step": 93000}
{"episode_reward": 984.7671784476979, "episode": 94.0, "batch_reward": 0.9242006720304489, "critic_loss": 0.43402969796955587, "actor_loss": -95.09519819641113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.525501012802124, "step": 94000}
{"episode_reward": 956.0729768164065, "episode": 95.0, "batch_reward": 0.9241935582756996, "critic_loss": 0.47248161843419073, "actor_loss": -95.19445156860351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.507190465927124, "step": 95000}
{"episode_reward": 961.0328203341368, "episode": 96.0, "batch_reward": 0.9245883717536926, "critic_loss": 0.4652855985164642, "actor_loss": -95.25607711791992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.497385263442993, "step": 96000}
{"episode_reward": 963.1101470603353, "episode": 97.0, "batch_reward": 0.924411072254181, "critic_loss": 0.4634449589699507, "actor_loss": -95.2383818359375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.530307292938232, "step": 97000}
{"episode_reward": 819.5660543600746, "episode": 98.0, "batch_reward": 0.9238437194824218, "critic_loss": 0.46722900529205796, "actor_loss": -95.07230601501465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.56289577484131, "step": 98000}
{"episode_reward": 892.5832439996723, "episode": 99.0, "batch_reward": 0.9234608412384987, "critic_loss": 0.48728449146449565, "actor_loss": -95.04747985839843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.561983346939087, "step": 99000}
{"episode_reward": 957.2507389576419, "episode": 100.0, "batch_reward": 0.9256772124171257, "critic_loss": 0.49157444410026074, "actor_loss": -95.17041757202148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.559812545776367, "step": 100000}
{"episode_reward": 923.2202948678124, "episode": 101.0, "batch_reward": 0.9257227158546448, "critic_loss": 0.468434790045023, "actor_loss": -95.20051295471191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.91793751716614, "step": 101000}
{"episode_reward": 977.0547830762612, "episode": 102.0, "batch_reward": 0.9240796055793762, "critic_loss": 0.48768235801160337, "actor_loss": -95.1590350189209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52682662010193, "step": 102000}
{"episode_reward": 983.6742779562079, "episode": 103.0, "batch_reward": 0.9246639255285263, "critic_loss": 0.4746000518500805, "actor_loss": -95.14111582946778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.49521231651306, "step": 103000}
{"episode_reward": 959.216319133089, "episode": 104.0, "batch_reward": 0.9262846921682357, "critic_loss": 0.5045453628897667, "actor_loss": -95.17433586120606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.53335928916931, "step": 104000}
{"episode_reward": 915.4613154363636, "episode": 105.0, "batch_reward": 0.9262616965770721, "critic_loss": 0.5244377516359091, "actor_loss": -95.21044155883789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.534603118896484, "step": 105000}
{"episode_reward": 917.200030077568, "episode": 106.0, "batch_reward": 0.92626600253582, "critic_loss": 0.5258366074711084, "actor_loss": -95.15366026306152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.547102451324463, "step": 106000}
{"episode_reward": 922.7799752259798, "episode": 107.0, "batch_reward": 0.9243564441800117, "critic_loss": 0.5241546321213245, "actor_loss": -95.12222039794922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52490210533142, "step": 107000}
{"episode_reward": 918.1084815631995, "episode": 108.0, "batch_reward": 0.9261928445696831, "critic_loss": 0.5155721813440323, "actor_loss": -95.24767437744141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.533940076828003, "step": 108000}
{"episode_reward": 947.9539307808665, "episode": 109.0, "batch_reward": 0.9263071830868721, "critic_loss": 0.5013178293853998, "actor_loss": -95.29247290039062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.532532453536987, "step": 109000}
{"episode_reward": 981.584465762411, "episode": 110.0, "batch_reward": 0.9259952054619789, "critic_loss": 0.5365955877006054, "actor_loss": -95.21669609069824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52350616455078, "step": 110000}
{"episode_reward": 864.3171937257607, "episode": 111.0, "batch_reward": 0.9257035447955132, "critic_loss": 0.5434586320966482, "actor_loss": -95.30251100158691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.9706244468689, "step": 111000}
{"episode_reward": 928.1136608549845, "episode": 112.0, "batch_reward": 0.9254554404616356, "critic_loss": 0.541207012847066, "actor_loss": -95.22459295654296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8742995262146, "step": 112000}
{"episode_reward": 926.929411644043, "episode": 113.0, "batch_reward": 0.9261596223115921, "critic_loss": 0.5140906660109759, "actor_loss": -95.23229502868652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.56167960166931, "step": 113000}
{"episode_reward": 963.2921635400982, "episode": 114.0, "batch_reward": 0.9263536322712899, "critic_loss": 0.5397022192031146, "actor_loss": -95.2968321685791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51144790649414, "step": 114000}
{"episode_reward": 979.0362723614184, "episode": 115.0, "batch_reward": 0.9269374500513077, "critic_loss": 0.5621370317488908, "actor_loss": -95.22403324890136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.507801055908203, "step": 115000}
{"episode_reward": 898.043474524798, "episode": 116.0, "batch_reward": 0.9265930829644203, "critic_loss": 0.5840220076739788, "actor_loss": -95.24543730163575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.559314489364624, "step": 116000}
{"episode_reward": 954.0944824091852, "episode": 117.0, "batch_reward": 0.925730543076992, "critic_loss": 0.5958799540698528, "actor_loss": -95.2224096069336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51247525215149, "step": 117000}
{"episode_reward": 903.4066122632693, "episode": 118.0, "batch_reward": 0.926526030600071, "critic_loss": 0.5519968599975109, "actor_loss": -95.2626529083252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.557761907577515, "step": 118000}
{"episode_reward": 983.7003546077852, "episode": 119.0, "batch_reward": 0.9261073201298714, "critic_loss": 0.5689996600449085, "actor_loss": -95.30903536987304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8291757106781, "step": 119000}
{"episode_reward": 899.2919764932686, "episode": 120.0, "batch_reward": 0.9259470258951187, "critic_loss": 0.6246509723365307, "actor_loss": -95.1763402557373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.495234489440918, "step": 120000}
{"episode_reward": 929.9382715293674, "episode": 121.0, "batch_reward": 0.9272587315440178, "critic_loss": 0.597221154153347, "actor_loss": -95.2603384552002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.95767378807068, "step": 121000}
{"episode_reward": 985.2237811853464, "episode": 122.0, "batch_reward": 0.9261656447649002, "critic_loss": 0.6107262457013131, "actor_loss": -95.24654280090331, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.554537057876587, "step": 122000}
{"episode_reward": 935.9886646175049, "episode": 123.0, "batch_reward": 0.9266369200944901, "critic_loss": 0.5633822051435708, "actor_loss": -95.1352108001709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.535348415374756, "step": 123000}
{"episode_reward": 946.0977765578642, "episode": 124.0, "batch_reward": 0.926277537047863, "critic_loss": 0.620845199406147, "actor_loss": -95.23792509460449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.535890102386475, "step": 124000}
{"episode_reward": 967.9326681035608, "episode": 125.0, "batch_reward": 0.927735267341137, "critic_loss": 0.5648858316391706, "actor_loss": -95.32396110534668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.539616107940674, "step": 125000}
{"episode_reward": 988.4021982923603, "episode": 126.0, "batch_reward": 0.9286711428761483, "critic_loss": 0.6037536000311374, "actor_loss": -95.40034657287597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.530643939971924, "step": 126000}
{"episode_reward": 990.6153907309351, "episode": 127.0, "batch_reward": 0.9273760948777199, "critic_loss": 0.5681102505624295, "actor_loss": -95.35492810058594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.541078329086304, "step": 127000}
{"episode_reward": 928.9204922641972, "episode": 128.0, "batch_reward": 0.9280944682955742, "critic_loss": 0.5633060473650694, "actor_loss": -95.45655126953125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51388645172119, "step": 128000}
{"episode_reward": 963.3476857320168, "episode": 129.0, "batch_reward": 0.9294074692130089, "critic_loss": 0.5631669804304839, "actor_loss": -95.50704014587403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52939748764038, "step": 129000}
{"episode_reward": 984.3924245392901, "episode": 130.0, "batch_reward": 0.930101940214634, "critic_loss": 0.5851061920374632, "actor_loss": -95.45700567626953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.531272172927856, "step": 130000}
{"episode_reward": 989.3502891289854, "episode": 131.0, "batch_reward": 0.9301736962199211, "critic_loss": 0.5630405739843846, "actor_loss": -95.51365100097657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.978320598602295, "step": 131000}
{"episode_reward": 959.5190075970726, "episode": 132.0, "batch_reward": 0.930693368434906, "critic_loss": 0.5609509889632464, "actor_loss": -95.47880416870117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.55334448814392, "step": 132000}
{"episode_reward": 978.7965370843891, "episode": 133.0, "batch_reward": 0.929333601474762, "critic_loss": 0.5622824190258979, "actor_loss": -95.52760653686524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.538935661315918, "step": 133000}
{"episode_reward": 961.3157908158713, "episode": 134.0, "batch_reward": 0.9303488659262658, "critic_loss": 0.554832378461957, "actor_loss": -95.53097322082519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.528607845306396, "step": 134000}
{"episode_reward": 966.9505242381928, "episode": 135.0, "batch_reward": 0.9319647975564003, "critic_loss": 0.5517005798220634, "actor_loss": -95.58980442810059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.536163330078125, "step": 135000}
{"episode_reward": 991.9896871719938, "episode": 136.0, "batch_reward": 0.9317026481628418, "critic_loss": 0.5349068350642919, "actor_loss": -95.67501531982421, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.536780834197998, "step": 136000}
{"episode_reward": 988.8291065552529, "episode": 137.0, "batch_reward": 0.9307223073244095, "critic_loss": 0.5178920851945877, "actor_loss": -95.52242567443848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.533971071243286, "step": 137000}
{"episode_reward": 985.8015523750635, "episode": 138.0, "batch_reward": 0.9316775197386742, "critic_loss": 0.59906431363523, "actor_loss": -95.5065486755371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.508952856063843, "step": 138000}
{"episode_reward": 864.4886377947003, "episode": 139.0, "batch_reward": 0.9303591024279595, "critic_loss": 0.5611126340478658, "actor_loss": -95.52039413452148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.54523515701294, "step": 139000}
{"episode_reward": 986.3099858116929, "episode": 140.0, "batch_reward": 0.9320157946944236, "critic_loss": 0.555877710595727, "actor_loss": -95.56721655273438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.555018663406372, "step": 140000}
{"episode_reward": 944.9606850984103, "episode": 141.0, "batch_reward": 0.9323449862003327, "critic_loss": 0.5391911031454801, "actor_loss": -95.56099928283692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.095919370651245, "step": 141000}
{"episode_reward": 953.7765273118526, "episode": 142.0, "batch_reward": 0.9331232177615165, "critic_loss": 0.548106379494071, "actor_loss": -95.62455836486816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.514251232147217, "step": 142000}
{"episode_reward": 988.9802636945338, "episode": 143.0, "batch_reward": 0.9327008218169213, "critic_loss": 0.5433304142802954, "actor_loss": -95.64697793579101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.526118516921997, "step": 143000}
{"episode_reward": 942.7641781900954, "episode": 144.0, "batch_reward": 0.9321721851229667, "critic_loss": 0.5889261531531811, "actor_loss": -95.65373629760742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.526471376419067, "step": 144000}
{"episode_reward": 909.5057023458985, "episode": 145.0, "batch_reward": 0.9328496356606484, "critic_loss": 0.5560047121644021, "actor_loss": -95.6808733215332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.54997682571411, "step": 145000}
{"episode_reward": 988.0438837175869, "episode": 146.0, "batch_reward": 0.9327978925704956, "critic_loss": 0.5633964265286923, "actor_loss": -95.68078553771973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.549591064453125, "step": 146000}
{"episode_reward": 970.4917032757828, "episode": 147.0, "batch_reward": 0.9326780998706817, "critic_loss": 0.5679148623496294, "actor_loss": -95.67804061889649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.53637385368347, "step": 147000}
{"episode_reward": 936.543379347973, "episode": 148.0, "batch_reward": 0.9342181045413017, "critic_loss": 0.5369990235865116, "actor_loss": -95.67390019226075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.55444622039795, "step": 148000}
{"episode_reward": 984.3716740963754, "episode": 149.0, "batch_reward": 0.932440566778183, "critic_loss": 0.5754903242141008, "actor_loss": -95.64638891601562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.534027338027954, "step": 149000}
{"episode_reward": 884.8859303845752, "episode": 150.0, "batch_reward": 0.9329620034694671, "critic_loss": 0.5990569521486759, "actor_loss": -95.70901626586914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
