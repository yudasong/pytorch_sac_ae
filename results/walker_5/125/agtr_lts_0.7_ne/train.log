{"episode_reward": 0.0, "episode": 1.0, "duration": 20.660080909729004, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.7953824996948242, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.49028515224458374, "critic_loss": 0.8760321139593688, "actor_loss": -86.42133161858493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.72393274307251, "step": 3000}
{"episode_reward": 812.0431246075307, "episode": 4.0, "batch_reward": 0.6065004025399685, "critic_loss": 1.2652797976136207, "actor_loss": -89.65914598083496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12798285484314, "step": 4000}
{"episode_reward": 832.1214265163918, "episode": 5.0, "batch_reward": 0.6825513980388641, "critic_loss": 1.494133405506611, "actor_loss": -92.04410124206542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.119184970855713, "step": 5000}
{"episode_reward": 977.6075161828743, "episode": 6.0, "batch_reward": 0.6879710268378257, "critic_loss": 1.8627222907543182, "actor_loss": -92.40538873291015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.141388177871704, "step": 6000}
{"episode_reward": 261.63615190634783, "episode": 7.0, "batch_reward": 0.6457675042152404, "critic_loss": 3.089466551542282, "actor_loss": -91.55243663024902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.133930206298828, "step": 7000}
{"episode_reward": 831.8736972865009, "episode": 8.0, "batch_reward": 0.631161333501339, "critic_loss": 4.44606519150734, "actor_loss": -92.75121383666992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12249231338501, "step": 8000}
{"episode_reward": 263.33460869758636, "episode": 9.0, "batch_reward": 0.6278387419581414, "critic_loss": 3.7990755001306535, "actor_loss": -93.03184936523438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.130614042282104, "step": 9000}
{"episode_reward": 890.0252269824591, "episode": 10.0, "batch_reward": 0.6608244391679764, "critic_loss": 3.0811117218732833, "actor_loss": -93.5180240020752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.145228385925293, "step": 10000}
{"episode_reward": 953.4915757274579, "episode": 11.0, "batch_reward": 0.6862809487581253, "critic_loss": 2.5073948802948, "actor_loss": -93.65383271789551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.637837648391724, "step": 11000}
{"episode_reward": 948.9533597740359, "episode": 12.0, "batch_reward": 0.671579336643219, "critic_loss": 2.337671809434891, "actor_loss": -94.3742970123291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.169053077697754, "step": 12000}
{"episode_reward": 28.599704803485004, "episode": 13.0, "batch_reward": 0.6211164106428623, "critic_loss": 2.150657516717911, "actor_loss": -94.26875534057618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.173131942749023, "step": 13000}
{"episode_reward": 28.473236809937635, "episode": 14.0, "batch_reward": 0.5943379961848259, "critic_loss": 2.4197943032979965, "actor_loss": -94.30716796875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15499210357666, "step": 14000}
{"episode_reward": 298.6303882135303, "episode": 15.0, "batch_reward": 0.586104048371315, "critic_loss": 2.545457773447037, "actor_loss": -91.99841184997558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13815951347351, "step": 15000}
{"episode_reward": 708.1133311737816, "episode": 16.0, "batch_reward": 0.5900657277405262, "critic_loss": 2.7847932817935943, "actor_loss": -91.9089122619629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.152820587158203, "step": 16000}
{"episode_reward": 764.8822671075828, "episode": 17.0, "batch_reward": 0.600500172317028, "critic_loss": 2.733018373847008, "actor_loss": -91.67325723266602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14208698272705, "step": 17000}
{"episode_reward": 854.1735332740424, "episode": 18.0, "batch_reward": 0.6140625294446945, "critic_loss": 2.2368433277606963, "actor_loss": -91.12341680908203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.107683420181274, "step": 18000}
{"episode_reward": 821.9315898774438, "episode": 19.0, "batch_reward": 0.6297101954817772, "critic_loss": 1.9046569751501083, "actor_loss": -90.81264183044433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13380527496338, "step": 19000}
{"episode_reward": 833.1905437453796, "episode": 20.0, "batch_reward": 0.6394683682322502, "critic_loss": 1.7332562434077263, "actor_loss": -90.39862495422364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.140333890914917, "step": 20000}
{"episode_reward": 850.3721150336736, "episode": 21.0, "batch_reward": 0.6506883344650268, "critic_loss": 1.5896079374551773, "actor_loss": -90.02990869140625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.64526152610779, "step": 21000}
{"episode_reward": 860.7556877351651, "episode": 22.0, "batch_reward": 0.6552511014938355, "critic_loss": 1.6077717989683151, "actor_loss": -89.56536247253418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.161234378814697, "step": 22000}
{"episode_reward": 565.0850042915034, "episode": 23.0, "batch_reward": 0.6584161056280136, "critic_loss": 1.5602246745824815, "actor_loss": -89.24993528747558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.164490938186646, "step": 23000}
{"episode_reward": 956.6306315179381, "episode": 24.0, "batch_reward": 0.6699682691693306, "critic_loss": 1.598029578268528, "actor_loss": -89.21492874145508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.145525217056274, "step": 24000}
{"episode_reward": 915.2067113089983, "episode": 25.0, "batch_reward": 0.6774014563560485, "critic_loss": 1.8030174124836922, "actor_loss": -89.0025009765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.138864278793335, "step": 25000}
{"episode_reward": 854.100531608998, "episode": 26.0, "batch_reward": 0.6750528610348702, "critic_loss": 1.934493523478508, "actor_loss": -89.19525155639649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.168545246124268, "step": 26000}
{"episode_reward": 189.58756662767195, "episode": 27.0, "batch_reward": 0.6691065910458565, "critic_loss": 2.0773335916996003, "actor_loss": -89.25738891601563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.154569149017334, "step": 27000}
{"episode_reward": 927.3784513407587, "episode": 28.0, "batch_reward": 0.6632389961481094, "critic_loss": 1.9339998181462288, "actor_loss": -89.15274620056152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.173389673233032, "step": 28000}
{"episode_reward": 50.51869428403674, "episode": 29.0, "batch_reward": 0.6522776638865471, "critic_loss": 1.8015364643931389, "actor_loss": -88.99121406555176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.139845371246338, "step": 29000}
{"episode_reward": 775.6038561773076, "episode": 30.0, "batch_reward": 0.6508706205487251, "critic_loss": 1.7197418275475502, "actor_loss": -88.64934132385254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.122605085372925, "step": 30000}
{"episode_reward": 605.6556439376986, "episode": 31.0, "batch_reward": 0.6592647228240966, "critic_loss": 1.607647424519062, "actor_loss": -88.78874609375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.59837794303894, "step": 31000}
{"episode_reward": 953.3233759396992, "episode": 32.0, "batch_reward": 0.6650682885050774, "critic_loss": 1.4479224383234979, "actor_loss": -88.5518765411377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.134645462036133, "step": 32000}
{"episode_reward": 864.5049567089525, "episode": 33.0, "batch_reward": 0.6686460404992104, "critic_loss": 1.794389611840248, "actor_loss": -88.64589065551758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.143866777420044, "step": 33000}
{"episode_reward": 806.4142135292732, "episode": 34.0, "batch_reward": 0.6772579621672631, "critic_loss": 1.593876180112362, "actor_loss": -88.51300469970703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14664626121521, "step": 34000}
{"episode_reward": 940.0622953107008, "episode": 35.0, "batch_reward": 0.6834361988902092, "critic_loss": 1.4551862626075744, "actor_loss": -88.65868334960938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.161365270614624, "step": 35000}
{"episode_reward": 927.9464803786386, "episode": 36.0, "batch_reward": 0.6898927003741264, "critic_loss": 1.31921867030859, "actor_loss": -88.3512689819336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.150227308273315, "step": 36000}
{"episode_reward": 931.5342662602264, "episode": 37.0, "batch_reward": 0.6954361490011215, "critic_loss": 1.258618948817253, "actor_loss": -88.59181076049805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.136693239212036, "step": 37000}
{"episode_reward": 961.1880255117331, "episode": 38.0, "batch_reward": 0.7048906325101852, "critic_loss": 1.224163359284401, "actor_loss": -88.86993630981445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14043378829956, "step": 38000}
{"episode_reward": 913.8671821089172, "episode": 39.0, "batch_reward": 0.7101287558674813, "critic_loss": 1.174089495718479, "actor_loss": -89.17031713867188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.143840074539185, "step": 39000}
{"episode_reward": 927.8925427730981, "episode": 40.0, "batch_reward": 0.7187007310390472, "critic_loss": 1.1258200144171715, "actor_loss": -89.50997981262206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13227891921997, "step": 40000}
{"episode_reward": 984.5097779511542, "episode": 41.0, "batch_reward": 0.7232299895882607, "critic_loss": 1.0539117725491525, "actor_loss": -89.57518617248535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.51302528381348, "step": 41000}
{"episode_reward": 946.742632811336, "episode": 42.0, "batch_reward": 0.7297801555991172, "critic_loss": 1.0051798121631146, "actor_loss": -89.52795237731934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.099778652191162, "step": 42000}
{"episode_reward": 962.8736037646744, "episode": 43.0, "batch_reward": 0.7343347035646438, "critic_loss": 0.9386303507089615, "actor_loss": -89.65694906616211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11771845817566, "step": 43000}
{"episode_reward": 906.2149275157967, "episode": 44.0, "batch_reward": 0.7378133391737938, "critic_loss": 0.933197938978672, "actor_loss": -89.69812773132324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1209077835083, "step": 44000}
{"episode_reward": 944.0554745568205, "episode": 45.0, "batch_reward": 0.7435630453228951, "critic_loss": 0.9120721551477909, "actor_loss": -90.0168207244873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11030888557434, "step": 45000}
{"episode_reward": 947.6756276646522, "episode": 46.0, "batch_reward": 0.7461984066367149, "critic_loss": 0.8714267240166664, "actor_loss": -90.05198977661132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.127865314483643, "step": 46000}
{"episode_reward": 965.3752738864681, "episode": 47.0, "batch_reward": 0.7507933791279793, "critic_loss": 0.8377722658812999, "actor_loss": -90.29974044799805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.125664710998535, "step": 47000}
{"episode_reward": 965.9193629003142, "episode": 48.0, "batch_reward": 0.7562306244969368, "critic_loss": 0.8946952869594097, "actor_loss": -90.07700416564941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.131789922714233, "step": 48000}
{"episode_reward": 914.7219152550324, "episode": 49.0, "batch_reward": 0.7594666450023652, "critic_loss": 0.8131533786952495, "actor_loss": -90.51651849365234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.136597633361816, "step": 49000}
{"episode_reward": 954.814271331629, "episode": 50.0, "batch_reward": 0.7632115713357925, "critic_loss": 0.8569177042841911, "actor_loss": -90.59263803100586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.114952087402344, "step": 50000}
{"episode_reward": 985.3395907365132, "episode": 51.0, "batch_reward": 0.7684662677049637, "critic_loss": 0.772157667696476, "actor_loss": -90.75985244750977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.490394592285156, "step": 51000}
{"episode_reward": 987.1870514273137, "episode": 52.0, "batch_reward": 0.7717215422987938, "critic_loss": 0.7994088733792305, "actor_loss": -90.81742370605468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12757921218872, "step": 52000}
{"episode_reward": 959.3192902278864, "episode": 53.0, "batch_reward": 0.7766809005141259, "critic_loss": 0.7608158419728279, "actor_loss": -90.88268502807617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.158876180648804, "step": 53000}
{"episode_reward": 958.5224049628895, "episode": 54.0, "batch_reward": 0.7781519011259079, "critic_loss": 0.7540905231833458, "actor_loss": -91.01051080322266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.154925107955933, "step": 54000}
{"episode_reward": 923.1297956767763, "episode": 55.0, "batch_reward": 0.7816942985653877, "critic_loss": 0.7594025950729847, "actor_loss": -91.12460820007324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15723967552185, "step": 55000}
{"episode_reward": 938.2371221088924, "episode": 56.0, "batch_reward": 0.7858778066635131, "critic_loss": 0.7216590655446052, "actor_loss": -91.24077236938477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.150500297546387, "step": 56000}
{"episode_reward": 988.4657915942571, "episode": 57.0, "batch_reward": 0.7898345370292663, "critic_loss": 0.7659349901974202, "actor_loss": -91.29417372131347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.176225423812866, "step": 57000}
{"episode_reward": 898.4576995760453, "episode": 58.0, "batch_reward": 0.7887807900309562, "critic_loss": 0.7283872083127498, "actor_loss": -91.19558645629883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.157594680786133, "step": 58000}
{"episode_reward": 977.028076554046, "episode": 59.0, "batch_reward": 0.7926408142447472, "critic_loss": 0.698981639444828, "actor_loss": -91.34749946594238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15849471092224, "step": 59000}
{"episode_reward": 962.0141342161146, "episode": 60.0, "batch_reward": 0.7963710299730301, "critic_loss": 0.684227435439825, "actor_loss": -91.62648149108887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15172028541565, "step": 60000}
{"episode_reward": 957.8041925382292, "episode": 61.0, "batch_reward": 0.7988428231477738, "critic_loss": 0.688371805548668, "actor_loss": -91.56586334228516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.56384253501892, "step": 61000}
{"episode_reward": 914.4311057561409, "episode": 62.0, "batch_reward": 0.8008386579155922, "critic_loss": 0.7051428945362568, "actor_loss": -91.72723330688477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.165098428726196, "step": 62000}
{"episode_reward": 969.6317381169592, "episode": 63.0, "batch_reward": 0.8032223057746887, "critic_loss": 0.6718386123776436, "actor_loss": -91.62396388244629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1436185836792, "step": 63000}
{"episode_reward": 915.0051057175347, "episode": 64.0, "batch_reward": 0.8037380459308624, "critic_loss": 0.6502535637617112, "actor_loss": -91.73985919189452, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17296028137207, "step": 64000}
{"episode_reward": 988.3509959207823, "episode": 65.0, "batch_reward": 0.8068365798592567, "critic_loss": 0.6421995390355587, "actor_loss": -91.78521006774902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.147810697555542, "step": 65000}
{"episode_reward": 981.3532990941906, "episode": 66.0, "batch_reward": 0.8097615104913711, "critic_loss": 0.6310265321135521, "actor_loss": -91.92144621276856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1586811542511, "step": 66000}
{"episode_reward": 929.6089109096594, "episode": 67.0, "batch_reward": 0.811674636542797, "critic_loss": 0.6693003387749195, "actor_loss": -92.03108135986328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16798710823059, "step": 67000}
{"episode_reward": 879.8820486681029, "episode": 68.0, "batch_reward": 0.8120295952558517, "critic_loss": 0.6292111814916134, "actor_loss": -91.85071620178222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16160750389099, "step": 68000}
{"episode_reward": 964.0434879838517, "episode": 69.0, "batch_reward": 0.8157516040802002, "critic_loss": 0.5759090418964624, "actor_loss": -91.98410144042968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.175206184387207, "step": 69000}
{"episode_reward": 945.3307788071809, "episode": 70.0, "batch_reward": 0.817673470377922, "critic_loss": 0.6994036759436131, "actor_loss": -92.18189344787598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.151692867279053, "step": 70000}
{"episode_reward": 926.550202042294, "episode": 71.0, "batch_reward": 0.8177274386286736, "critic_loss": 0.7240353729724884, "actor_loss": -92.19211427307128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.54690432548523, "step": 71000}
{"episode_reward": 946.3029197341692, "episode": 72.0, "batch_reward": 0.822292264521122, "critic_loss": 0.674992201179266, "actor_loss": -92.23253913879394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.140475749969482, "step": 72000}
{"episode_reward": 977.8521681989855, "episode": 73.0, "batch_reward": 0.8233955364227294, "critic_loss": 0.6998072693943977, "actor_loss": -92.28195530700684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.137404441833496, "step": 73000}
{"episode_reward": 930.7386957757597, "episode": 74.0, "batch_reward": 0.8242698286175728, "critic_loss": 0.6006722214519977, "actor_loss": -92.4154874267578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.128729104995728, "step": 74000}
{"episode_reward": 931.7190414933847, "episode": 75.0, "batch_reward": 0.8259758690595627, "critic_loss": 0.6866743065565825, "actor_loss": -92.33664199829101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.165021896362305, "step": 75000}
{"episode_reward": 951.7873394023526, "episode": 76.0, "batch_reward": 0.8280878779888153, "critic_loss": 0.7010879778265953, "actor_loss": -92.42828356933593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.121805906295776, "step": 76000}
{"episode_reward": 949.4984049031582, "episode": 77.0, "batch_reward": 0.8283139855861664, "critic_loss": 0.6557179717123508, "actor_loss": -92.25387414550781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.118188858032227, "step": 77000}
{"episode_reward": 955.303830191678, "episode": 78.0, "batch_reward": 0.8328311177492141, "critic_loss": 0.6208710571825504, "actor_loss": -92.4419049987793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09448218345642, "step": 78000}
{"episode_reward": 958.5108512548367, "episode": 79.0, "batch_reward": 0.8323654655218125, "critic_loss": 0.7316021244972944, "actor_loss": -92.32777304077149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.125420331954956, "step": 79000}
{"episode_reward": 961.2502802625759, "episode": 80.0, "batch_reward": 0.8350074119567871, "critic_loss": 0.6839516664296389, "actor_loss": -92.561172164917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14536142349243, "step": 80000}
{"episode_reward": 979.8660074737427, "episode": 81.0, "batch_reward": 0.8352602382898331, "critic_loss": 0.7435274959653616, "actor_loss": -92.63073373413086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.54488182067871, "step": 81000}
{"episode_reward": 856.9290208613029, "episode": 82.0, "batch_reward": 0.835557179570198, "critic_loss": 0.6934766581654549, "actor_loss": -92.75626832580566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.140005111694336, "step": 82000}
{"episode_reward": 961.7370852937091, "episode": 83.0, "batch_reward": 0.8372957351207733, "critic_loss": 0.6985319999158383, "actor_loss": -92.61611097717285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10828685760498, "step": 83000}
{"episode_reward": 949.8788025176872, "episode": 84.0, "batch_reward": 0.840968311548233, "critic_loss": 0.6359012292921543, "actor_loss": -92.9330322265625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.120817184448242, "step": 84000}
{"episode_reward": 986.8797711532985, "episode": 85.0, "batch_reward": 0.8394911689162254, "critic_loss": 0.6206463326364756, "actor_loss": -92.80536712646484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.152811288833618, "step": 85000}
{"episode_reward": 958.583728705746, "episode": 86.0, "batch_reward": 0.8411715350747109, "critic_loss": 0.6426836980879307, "actor_loss": -92.79958981323242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.145881175994873, "step": 86000}
{"episode_reward": 933.1971408503434, "episode": 87.0, "batch_reward": 0.8417926052808762, "critic_loss": 0.6503101776838303, "actor_loss": -92.80667236328125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16249918937683, "step": 87000}
{"episode_reward": 956.3532109779405, "episode": 88.0, "batch_reward": 0.8426381730437279, "critic_loss": 0.6320523955076933, "actor_loss": -92.78104470825195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.142399549484253, "step": 88000}
{"episode_reward": 919.9523888731468, "episode": 89.0, "batch_reward": 0.8429310767054558, "critic_loss": 0.6719961603283882, "actor_loss": -92.99016262817383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.166835069656372, "step": 89000}
{"episode_reward": 904.9177355271167, "episode": 90.0, "batch_reward": 0.8457765691876411, "critic_loss": 0.674259127870202, "actor_loss": -93.16844143676758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15200448036194, "step": 90000}
{"episode_reward": 962.1391812019872, "episode": 91.0, "batch_reward": 0.8469974028468132, "critic_loss": 0.6350918232798576, "actor_loss": -92.98464427185058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.59158945083618, "step": 91000}
{"episode_reward": 941.7988439876763, "episode": 92.0, "batch_reward": 0.8490985862016678, "critic_loss": 0.6222330522239208, "actor_loss": -93.08116136169434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15452265739441, "step": 92000}
{"episode_reward": 963.2717195766415, "episode": 93.0, "batch_reward": 0.8498266473412514, "critic_loss": 0.6350541201680898, "actor_loss": -93.07707330322266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14293074607849, "step": 93000}
{"episode_reward": 984.7895026988849, "episode": 94.0, "batch_reward": 0.85098113656044, "critic_loss": 0.6581816301643848, "actor_loss": -93.19003472900391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14947819709778, "step": 94000}
{"episode_reward": 876.4194609789478, "episode": 95.0, "batch_reward": 0.8490395152568817, "critic_loss": 0.5851537164747715, "actor_loss": -93.26572959899903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.163248300552368, "step": 95000}
{"episode_reward": 958.953296263484, "episode": 96.0, "batch_reward": 0.8520094124078751, "critic_loss": 0.614855868846178, "actor_loss": -93.36885400390625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.140475749969482, "step": 96000}
{"episode_reward": 960.7185523312247, "episode": 97.0, "batch_reward": 0.8520627560019494, "critic_loss": 0.6661511538922786, "actor_loss": -93.35997093200683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.140506982803345, "step": 97000}
{"episode_reward": 895.6984346382789, "episode": 98.0, "batch_reward": 0.8544120234847069, "critic_loss": 0.6070520922243595, "actor_loss": -93.28155833435059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.164220333099365, "step": 98000}
{"episode_reward": 938.0933558773671, "episode": 99.0, "batch_reward": 0.8527300934195519, "critic_loss": 0.6241510094255209, "actor_loss": -93.21004232788086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.167288780212402, "step": 99000}
{"episode_reward": 947.7680649565442, "episode": 100.0, "batch_reward": 0.8565862387418747, "critic_loss": 0.5939162050634622, "actor_loss": -93.33408348083496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10210108757019, "step": 100000}
{"episode_reward": 925.9218854046312, "episode": 101.0, "batch_reward": 0.8568174141645432, "critic_loss": 0.5812301130592823, "actor_loss": -93.40945413208007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.58162832260132, "step": 101000}
{"episode_reward": 988.5635564623826, "episode": 102.0, "batch_reward": 0.8559745336174965, "critic_loss": 0.604960912078619, "actor_loss": -93.35029393005371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.157933950424194, "step": 102000}
{"episode_reward": 982.7541585810344, "episode": 103.0, "batch_reward": 0.8576637116074562, "critic_loss": 0.5671737067103386, "actor_loss": -93.36661769104003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.133859395980835, "step": 103000}
{"episode_reward": 955.8966785281275, "episode": 104.0, "batch_reward": 0.8614710537791253, "critic_loss": 0.5799917296916246, "actor_loss": -93.5050952758789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.155668020248413, "step": 104000}
{"episode_reward": 959.5617240846778, "episode": 105.0, "batch_reward": 0.8607760455608368, "critic_loss": 0.5836583373099565, "actor_loss": -93.55729078674317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.124369144439697, "step": 105000}
{"episode_reward": 865.8942492080163, "episode": 106.0, "batch_reward": 0.8587410083413124, "critic_loss": 0.6218880059719085, "actor_loss": -93.36405815124512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.134880304336548, "step": 106000}
{"episode_reward": 848.6780249850704, "episode": 107.0, "batch_reward": 0.8596856618523597, "critic_loss": 0.7031550569981336, "actor_loss": -93.4558268737793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.152915477752686, "step": 107000}
{"episode_reward": 934.7742062088278, "episode": 108.0, "batch_reward": 0.8621704804897309, "critic_loss": 0.6592436230182648, "actor_loss": -93.5652964630127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.139466047286987, "step": 108000}
{"episode_reward": 950.631899787663, "episode": 109.0, "batch_reward": 0.8617890357375145, "critic_loss": 0.6080297645926476, "actor_loss": -93.63559358215332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14858627319336, "step": 109000}
{"episode_reward": 977.4982021913568, "episode": 110.0, "batch_reward": 0.8642109542489051, "critic_loss": 0.5987540169209242, "actor_loss": -93.54002745056152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14185619354248, "step": 110000}
{"episode_reward": 920.6435337285711, "episode": 111.0, "batch_reward": 0.8641105820536613, "critic_loss": 0.6378108814060688, "actor_loss": -93.71825904846192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.5342059135437, "step": 111000}
{"episode_reward": 923.7207133215014, "episode": 112.0, "batch_reward": 0.8647319345474244, "critic_loss": 0.6575198097079993, "actor_loss": -93.62653727722169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16421627998352, "step": 112000}
{"episode_reward": 946.6593369689429, "episode": 113.0, "batch_reward": 0.8657848739624023, "critic_loss": 0.6662938015013933, "actor_loss": -93.66839613342285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.179836750030518, "step": 113000}
{"episode_reward": 960.7237198979319, "episode": 114.0, "batch_reward": 0.8656295627355576, "critic_loss": 0.646920248836279, "actor_loss": -93.73229132080078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16244888305664, "step": 114000}
{"episode_reward": 971.2507554131263, "episode": 115.0, "batch_reward": 0.868175133049488, "critic_loss": 0.6302487084567547, "actor_loss": -93.68075299072265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.153862714767456, "step": 115000}
{"episode_reward": 962.7091642947291, "episode": 116.0, "batch_reward": 0.8681558896899223, "critic_loss": 0.6393153017014265, "actor_loss": -93.70721656799316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.149396181106567, "step": 116000}
{"episode_reward": 953.3230992927689, "episode": 117.0, "batch_reward": 0.8692757044434547, "critic_loss": 0.6169768304675818, "actor_loss": -93.71705442810058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12843084335327, "step": 117000}
{"episode_reward": 931.255196311469, "episode": 118.0, "batch_reward": 0.8685392252206803, "critic_loss": 0.6668527973294258, "actor_loss": -93.75649465942382, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.153186321258545, "step": 118000}
{"episode_reward": 976.5658017819122, "episode": 119.0, "batch_reward": 0.8692887271046639, "critic_loss": 0.6630636810213327, "actor_loss": -93.8425989074707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16971778869629, "step": 119000}
{"episode_reward": 906.2264969685197, "episode": 120.0, "batch_reward": 0.8692768102884293, "critic_loss": 0.6316882867217064, "actor_loss": -93.75408111572266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.167739391326904, "step": 120000}
{"episode_reward": 933.6179061458563, "episode": 121.0, "batch_reward": 0.870474377989769, "critic_loss": 0.5741126528829337, "actor_loss": -93.80737245178223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.58916091918945, "step": 121000}
{"episode_reward": 828.2800011356713, "episode": 122.0, "batch_reward": 0.8696370141506196, "critic_loss": 0.6135148155838251, "actor_loss": -93.75026341247559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.183643341064453, "step": 122000}
{"episode_reward": 953.5742986179619, "episode": 123.0, "batch_reward": 0.872369611799717, "critic_loss": 0.5702744092941284, "actor_loss": -93.70886862182617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.163009643554688, "step": 123000}
{"episode_reward": 960.8523285540433, "episode": 124.0, "batch_reward": 0.8720272691249847, "critic_loss": 0.5593099201470614, "actor_loss": -93.88009037780762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.174480676651, "step": 124000}
{"episode_reward": 986.8248848884587, "episode": 125.0, "batch_reward": 0.8728839997649193, "critic_loss": 0.5874411934316158, "actor_loss": -93.94882954406738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15793776512146, "step": 125000}
{"episode_reward": 983.7332002953457, "episode": 126.0, "batch_reward": 0.8748635144233704, "critic_loss": 0.5831746630072594, "actor_loss": -94.04111030578613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.146583795547485, "step": 126000}
{"episode_reward": 991.1479255795481, "episode": 127.0, "batch_reward": 0.8741117210984231, "critic_loss": 0.5458791388273239, "actor_loss": -93.98201071166991, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16840696334839, "step": 127000}
{"episode_reward": 933.0609344992322, "episode": 128.0, "batch_reward": 0.8738805023431778, "critic_loss": 0.5973865098059178, "actor_loss": -94.1035877380371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17643165588379, "step": 128000}
{"episode_reward": 952.0883200407586, "episode": 129.0, "batch_reward": 0.8758249342441559, "critic_loss": 0.6080422625094652, "actor_loss": -94.13000918579101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13933825492859, "step": 129000}
{"episode_reward": 984.5450155899382, "episode": 130.0, "batch_reward": 0.8776299989819527, "critic_loss": 0.6098275520354509, "actor_loss": -94.14535874938964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1677725315094, "step": 130000}
{"episode_reward": 985.8307077559386, "episode": 131.0, "batch_reward": 0.8774603620171547, "critic_loss": 0.5830849444270134, "actor_loss": -94.18451481628418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.55294847488403, "step": 131000}
{"episode_reward": 976.8301119831415, "episode": 132.0, "batch_reward": 0.8788399286270142, "critic_loss": 0.5476602768599987, "actor_loss": -94.18817227172852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.114362716674805, "step": 132000}
{"episode_reward": 988.734485740651, "episode": 133.0, "batch_reward": 0.8779740597605705, "critic_loss": 0.6174724017977714, "actor_loss": -94.21398878479003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.24422574043274, "step": 133000}
{"episode_reward": 951.3298894158934, "episode": 134.0, "batch_reward": 0.8789654111266136, "critic_loss": 0.574400189101696, "actor_loss": -94.20054815673828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.40820813179016, "step": 134000}
{"episode_reward": 966.6661933178132, "episode": 135.0, "batch_reward": 0.8803428164720535, "critic_loss": 0.5731494812220335, "actor_loss": -94.26838531494141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1672625541687, "step": 135000}
{"episode_reward": 988.4147039008592, "episode": 136.0, "batch_reward": 0.8823397326469421, "critic_loss": 0.5830502707958222, "actor_loss": -94.41406684875489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.39890480041504, "step": 136000}
{"episode_reward": 966.9472384521853, "episode": 137.0, "batch_reward": 0.8808825789690018, "critic_loss": 0.577063838750124, "actor_loss": -94.2404485168457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.155207633972168, "step": 137000}
{"episode_reward": 982.8524259134518, "episode": 138.0, "batch_reward": 0.8825810936689377, "critic_loss": 0.5909570570290089, "actor_loss": -94.31240055847168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.145378828048706, "step": 138000}
{"episode_reward": 959.6252199935197, "episode": 139.0, "batch_reward": 0.8812365564703941, "critic_loss": 0.6031503680348397, "actor_loss": -94.24995237731933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18161177635193, "step": 139000}
{"episode_reward": 928.1884977326001, "episode": 140.0, "batch_reward": 0.883187950015068, "critic_loss": 0.5630362735688687, "actor_loss": -94.28694325256347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.145507097244263, "step": 140000}
{"episode_reward": 952.2118872561196, "episode": 141.0, "batch_reward": 0.8846319052577019, "critic_loss": 0.5716799826174974, "actor_loss": -94.30312173461914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.61817693710327, "step": 141000}
{"episode_reward": 956.9914348100832, "episode": 142.0, "batch_reward": 0.8849273838996887, "critic_loss": 0.5828279301971198, "actor_loss": -94.4120108795166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.164969444274902, "step": 142000}
{"episode_reward": 989.3467958281319, "episode": 143.0, "batch_reward": 0.8857555394768715, "critic_loss": 0.5696946762800217, "actor_loss": -94.45876809692383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17980694770813, "step": 143000}
{"episode_reward": 955.7142605243641, "episode": 144.0, "batch_reward": 0.8847994509935379, "critic_loss": 0.5703515623658896, "actor_loss": -94.46752822875976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.173509120941162, "step": 144000}
{"episode_reward": 957.8203170829286, "episode": 145.0, "batch_reward": 0.8861456260085105, "critic_loss": 0.5972545301765203, "actor_loss": -94.48115553283691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.189818859100342, "step": 145000}
{"episode_reward": 986.2006192449834, "episode": 146.0, "batch_reward": 0.8856682872772217, "critic_loss": 0.5847850156724453, "actor_loss": -94.47879530334473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.194844961166382, "step": 146000}
{"episode_reward": 954.2869043616353, "episode": 147.0, "batch_reward": 0.8874030404090881, "critic_loss": 0.5703694566637277, "actor_loss": -94.52256742858887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.162994623184204, "step": 147000}
{"episode_reward": 962.8200290184175, "episode": 148.0, "batch_reward": 0.8881896606683731, "critic_loss": 0.5443741974681616, "actor_loss": -94.49818098449707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.141947269439697, "step": 148000}
{"episode_reward": 984.2835220283131, "episode": 149.0, "batch_reward": 0.8881479054689407, "critic_loss": 0.5270152448266745, "actor_loss": -94.47653932189941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18552303314209, "step": 149000}
{"episode_reward": 954.4152125771943, "episode": 150.0, "batch_reward": 0.8872406588196754, "critic_loss": 0.5722735339999199, "actor_loss": -94.49777334594727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
