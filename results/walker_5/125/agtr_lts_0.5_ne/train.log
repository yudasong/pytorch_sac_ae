{"episode_reward": 0.0, "episode": 1.0, "duration": 20.587355136871338, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.7786345481872559, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.5054868043423016, "critic_loss": 0.6948399066865424, "actor_loss": -88.39129573643422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.003116607666016, "step": 3000}
{"episode_reward": 954.5676193563904, "episode": 4.0, "batch_reward": 0.6638727406263352, "critic_loss": 0.6485294619202614, "actor_loss": -93.91253594970703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.965128421783447, "step": 4000}
{"episode_reward": 884.6234012470431, "episode": 5.0, "batch_reward": 0.723218418598175, "critic_loss": 0.5675780804157257, "actor_loss": -95.6448083190918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.974198818206787, "step": 5000}
{"episode_reward": 947.5267131864294, "episode": 6.0, "batch_reward": 0.7638412248492241, "critic_loss": 0.6305348216891289, "actor_loss": -96.13972552490235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.925902843475342, "step": 6000}
{"episode_reward": 948.9862751282961, "episode": 7.0, "batch_reward": 0.723534077167511, "critic_loss": 1.0572640994489193, "actor_loss": -96.14305940246582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95876145362854, "step": 7000}
{"episode_reward": 30.403477220979358, "episode": 8.0, "batch_reward": 0.6787963896393776, "critic_loss": 0.9418498739004135, "actor_loss": -95.98914596557617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.953561305999756, "step": 8000}
{"episode_reward": 871.1932471925204, "episode": 9.0, "batch_reward": 0.7023611000180244, "critic_loss": 0.7499038503170014, "actor_loss": -95.9229397277832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97590923309326, "step": 9000}
{"episode_reward": 845.4295680715799, "episode": 10.0, "batch_reward": 0.7186786522865295, "critic_loss": 0.7730666317045689, "actor_loss": -95.85906393432617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97391414642334, "step": 10000}
{"episode_reward": 875.630329081851, "episode": 11.0, "batch_reward": 0.7011256091594696, "critic_loss": 0.6731835190653801, "actor_loss": -95.10889088439941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.4779999256134, "step": 11000}
{"episode_reward": 62.049595984606356, "episode": 12.0, "batch_reward": 0.6414181486964226, "critic_loss": 0.707674642086029, "actor_loss": -94.42207969665527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.969738006591797, "step": 12000}
{"episode_reward": 28.442200942047066, "episode": 13.0, "batch_reward": 0.592577477067709, "critic_loss": 0.6027941466867923, "actor_loss": -93.48393090820312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.996049404144287, "step": 13000}
{"episode_reward": 23.177283806514343, "episode": 14.0, "batch_reward": 0.5538491559922695, "critic_loss": 0.5917647396922111, "actor_loss": -92.5630382232666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.983887195587158, "step": 14000}
{"episode_reward": 85.08023045106094, "episode": 15.0, "batch_reward": 0.5502027245163917, "critic_loss": 0.5818339252471924, "actor_loss": -91.0364829711914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.957009077072144, "step": 15000}
{"episode_reward": 924.3349933696257, "episode": 16.0, "batch_reward": 0.5695305066108703, "critic_loss": 0.5361446108669042, "actor_loss": -90.72132969665527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.960607290267944, "step": 16000}
{"episode_reward": 860.256027752552, "episode": 17.0, "batch_reward": 0.5798191397488117, "critic_loss": 0.5674651218056679, "actor_loss": -90.52329238891602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.951459646224976, "step": 17000}
{"episode_reward": 774.9953714348873, "episode": 18.0, "batch_reward": 0.5956401220262051, "critic_loss": 0.6549729317724705, "actor_loss": -90.77040142822266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96548628807068, "step": 18000}
{"episode_reward": 850.3848593863374, "episode": 19.0, "batch_reward": 0.614719873547554, "critic_loss": 0.6318319146335125, "actor_loss": -90.71140739440918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9472873210907, "step": 19000}
{"episode_reward": 970.1372104325998, "episode": 20.0, "batch_reward": 0.6229631576836109, "critic_loss": 0.6053570976257324, "actor_loss": -90.2658777923584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.957160234451294, "step": 20000}
{"episode_reward": 577.9425430850551, "episode": 21.0, "batch_reward": 0.6270891957879067, "critic_loss": 0.5249918230175972, "actor_loss": -89.54795552062988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.30176877975464, "step": 21000}
{"episode_reward": 870.0412635604181, "episode": 22.0, "batch_reward": 0.6429035311937332, "critic_loss": 0.5462988235056401, "actor_loss": -89.3088582458496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94686245918274, "step": 22000}
{"episode_reward": 942.2142432859246, "episode": 23.0, "batch_reward": 0.6534068539738656, "critic_loss": 0.6474835555851459, "actor_loss": -89.58789219665528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.949394941329956, "step": 23000}
{"episode_reward": 932.136592490837, "episode": 24.0, "batch_reward": 0.6667961964011192, "critic_loss": 0.6080129017531872, "actor_loss": -90.01693809509277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.939025402069092, "step": 24000}
{"episode_reward": 969.2435671056649, "episode": 25.0, "batch_reward": 0.6770204981565475, "critic_loss": 0.6463880613744258, "actor_loss": -89.70572448730469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9334614276886, "step": 25000}
{"episode_reward": 897.2544242849366, "episode": 26.0, "batch_reward": 0.683944636464119, "critic_loss": 0.6196549507379532, "actor_loss": -89.50878321838378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.928455114364624, "step": 26000}
{"episode_reward": 914.9669337925542, "episode": 27.0, "batch_reward": 0.6964423582553864, "critic_loss": 0.6141913043558598, "actor_loss": -89.96048275756836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.942145586013794, "step": 27000}
{"episode_reward": 985.3516490223019, "episode": 28.0, "batch_reward": 0.7042790682315826, "critic_loss": 0.6593909808397294, "actor_loss": -90.14550311279297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.930011510849, "step": 28000}
{"episode_reward": 847.7642257161878, "episode": 29.0, "batch_reward": 0.714330108821392, "critic_loss": 0.6431728296875954, "actor_loss": -90.22403381347657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91377353668213, "step": 29000}
{"episode_reward": 949.6692160391505, "episode": 30.0, "batch_reward": 0.7164528485536575, "critic_loss": 0.6853616037666798, "actor_loss": -90.26008351135253, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.926961421966553, "step": 30000}
{"episode_reward": 831.5316010883283, "episode": 31.0, "batch_reward": 0.7223543703556061, "critic_loss": 0.710882693529129, "actor_loss": -90.53080720520019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.17881917953491, "step": 31000}
{"episode_reward": 887.6266748116833, "episode": 32.0, "batch_reward": 0.7290191822648049, "critic_loss": 0.7219708677828311, "actor_loss": -90.63064390563964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.945382118225098, "step": 32000}
{"episode_reward": 860.7650506254828, "episode": 33.0, "batch_reward": 0.7318026783466339, "critic_loss": 0.7137266773581504, "actor_loss": -90.46414358520508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91493535041809, "step": 33000}
{"episode_reward": 936.1902195501259, "episode": 34.0, "batch_reward": 0.7405681725740433, "critic_loss": 0.7140702967643737, "actor_loss": -90.52359062194824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.915336847305298, "step": 34000}
{"episode_reward": 917.3271726615166, "episode": 35.0, "batch_reward": 0.7438899972438813, "critic_loss": 0.7219359752833843, "actor_loss": -90.77783793640137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.907500505447388, "step": 35000}
{"episode_reward": 880.2793151870617, "episode": 36.0, "batch_reward": 0.7461143491864204, "critic_loss": 0.7043557096123695, "actor_loss": -90.57809495544434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91253137588501, "step": 36000}
{"episode_reward": 951.3034707668547, "episode": 37.0, "batch_reward": 0.7489951609373092, "critic_loss": 0.722822057902813, "actor_loss": -90.51575012207032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.922464847564697, "step": 37000}
{"episode_reward": 850.4902905088894, "episode": 38.0, "batch_reward": 0.7561267115473748, "critic_loss": 0.7427600665986538, "actor_loss": -90.84497019958496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.927876710891724, "step": 38000}
{"episode_reward": 982.1941234148538, "episode": 39.0, "batch_reward": 0.7607222234010697, "critic_loss": 0.7916622574329376, "actor_loss": -91.09499894714355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.960935354232788, "step": 39000}
{"episode_reward": 917.8358573280377, "episode": 40.0, "batch_reward": 0.76654360049963, "critic_loss": 0.7818877342045307, "actor_loss": -91.22214791870117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.944836616516113, "step": 40000}
{"episode_reward": 974.0407790020903, "episode": 41.0, "batch_reward": 0.7684955013990402, "critic_loss": 0.7982340702712536, "actor_loss": -91.22074240112305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.300183057785034, "step": 41000}
{"episode_reward": 863.6639800167108, "episode": 42.0, "batch_reward": 0.7737560292482376, "critic_loss": 0.7641668702960014, "actor_loss": -91.19421151733398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97811007499695, "step": 42000}
{"episode_reward": 958.3298898636397, "episode": 43.0, "batch_reward": 0.775911669254303, "critic_loss": 0.7502103735208512, "actor_loss": -91.1654083404541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.946101903915405, "step": 43000}
{"episode_reward": 894.5988838805795, "episode": 44.0, "batch_reward": 0.7798542015552521, "critic_loss": 0.7869080758988857, "actor_loss": -91.17525090026855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.932223796844482, "step": 44000}
{"episode_reward": 985.0552674143215, "episode": 45.0, "batch_reward": 0.7832166084647179, "critic_loss": 0.795728089094162, "actor_loss": -91.42432287597656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95080327987671, "step": 45000}
{"episode_reward": 938.10206038076, "episode": 46.0, "batch_reward": 0.7868028278946877, "critic_loss": 0.798179217159748, "actor_loss": -91.50609436035157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96220898628235, "step": 46000}
{"episode_reward": 958.9558697903373, "episode": 47.0, "batch_reward": 0.7929597052931786, "critic_loss": 0.789453299343586, "actor_loss": -91.47680432128907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.929133415222168, "step": 47000}
{"episode_reward": 972.7729364385791, "episode": 48.0, "batch_reward": 0.7946890305876732, "critic_loss": 0.7817521077990532, "actor_loss": -91.56916078186035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.936709880828857, "step": 48000}
{"episode_reward": 896.0610162575256, "episode": 49.0, "batch_reward": 0.798020708501339, "critic_loss": 0.8111330048143863, "actor_loss": -91.74119876098632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95704174041748, "step": 49000}
{"episode_reward": 920.7995372152681, "episode": 50.0, "batch_reward": 0.7994868381619453, "critic_loss": 0.79002871966362, "actor_loss": -91.91168760681153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.953485250473022, "step": 50000}
{"episode_reward": 986.2640837991779, "episode": 51.0, "batch_reward": 0.8060834461450577, "critic_loss": 0.721095557063818, "actor_loss": -92.02541844177246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.2988018989563, "step": 51000}
{"episode_reward": 974.4428355533032, "episode": 52.0, "batch_reward": 0.8071861216425895, "critic_loss": 0.7008985247313976, "actor_loss": -92.21737394714356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94897770881653, "step": 52000}
{"episode_reward": 957.3933329122482, "episode": 53.0, "batch_reward": 0.8114487223029136, "critic_loss": 0.6759593518972397, "actor_loss": -92.34501860046387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.950376987457275, "step": 53000}
{"episode_reward": 952.7264826287426, "episode": 54.0, "batch_reward": 0.8125072324872017, "critic_loss": 0.6543791061639785, "actor_loss": -92.51997738647461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.955081939697266, "step": 54000}
{"episode_reward": 939.3472416267925, "episode": 55.0, "batch_reward": 0.8165023976564407, "critic_loss": 0.6151657249033451, "actor_loss": -92.59085177612305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94728422164917, "step": 55000}
{"episode_reward": 978.0926431241189, "episode": 56.0, "batch_reward": 0.820309927046299, "critic_loss": 0.5684621385484934, "actor_loss": -92.72460258483886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.920077085494995, "step": 56000}
{"episode_reward": 989.0890106990059, "episode": 57.0, "batch_reward": 0.8213348277807235, "critic_loss": 0.5583354437947273, "actor_loss": -92.7903614654541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95762872695923, "step": 57000}
{"episode_reward": 961.2894528940126, "episode": 58.0, "batch_reward": 0.8243472337722778, "critic_loss": 0.5491922381222248, "actor_loss": -92.86093267822265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.925137281417847, "step": 58000}
{"episode_reward": 980.1883336189646, "episode": 59.0, "batch_reward": 0.8259250866174698, "critic_loss": 0.5705614027678967, "actor_loss": -93.00099407958984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.972748041152954, "step": 59000}
{"episode_reward": 874.9085233152734, "episode": 60.0, "batch_reward": 0.8273254483342171, "critic_loss": 0.5316534168571234, "actor_loss": -93.07899798583985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.977107048034668, "step": 60000}
{"episode_reward": 947.181291735922, "episode": 61.0, "batch_reward": 0.8281963304877281, "critic_loss": 0.507310476064682, "actor_loss": -92.9013016052246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.32312297821045, "step": 61000}
{"episode_reward": 957.8305696106277, "episode": 62.0, "batch_reward": 0.8299029070138931, "critic_loss": 0.47069190537929534, "actor_loss": -92.86188088989257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94525408744812, "step": 62000}
{"episode_reward": 970.3862555612153, "episode": 63.0, "batch_reward": 0.8310580059289933, "critic_loss": 0.47061254528164864, "actor_loss": -92.90594128417969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.909680366516113, "step": 63000}
{"episode_reward": 937.1296976031267, "episode": 64.0, "batch_reward": 0.8353132655620575, "critic_loss": 0.46218684946000577, "actor_loss": -93.03445774841309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.920949697494507, "step": 64000}
{"episode_reward": 986.6959777549216, "episode": 65.0, "batch_reward": 0.8375147444009781, "critic_loss": 0.4452891995459795, "actor_loss": -93.07442523193359, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.930850982666016, "step": 65000}
{"episode_reward": 979.9515236805246, "episode": 66.0, "batch_reward": 0.8394995328783988, "critic_loss": 0.4717721163928509, "actor_loss": -93.17098440551757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93218207359314, "step": 66000}
{"episode_reward": 962.5887974770677, "episode": 67.0, "batch_reward": 0.8405294743180275, "critic_loss": 0.47829256117343905, "actor_loss": -93.29220703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93429732322693, "step": 67000}
{"episode_reward": 925.3188663107773, "episode": 68.0, "batch_reward": 0.8430172961950302, "critic_loss": 0.46602801571786406, "actor_loss": -93.32300956726074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.966068506240845, "step": 68000}
{"episode_reward": 959.946697878907, "episode": 69.0, "batch_reward": 0.8436972377896309, "critic_loss": 0.45481657235324385, "actor_loss": -93.44601786804199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97799849510193, "step": 69000}
{"episode_reward": 981.219279896236, "episode": 70.0, "batch_reward": 0.8458823799490929, "critic_loss": 0.43748191648721696, "actor_loss": -93.47044064331055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.952040910720825, "step": 70000}
{"episode_reward": 955.4289572413003, "episode": 71.0, "batch_reward": 0.8486357213258743, "critic_loss": 0.4435370640605688, "actor_loss": -93.51630574035644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.27938199043274, "step": 71000}
{"episode_reward": 893.265193472952, "episode": 72.0, "batch_reward": 0.8492625075578689, "critic_loss": 0.4416157363206148, "actor_loss": -93.55274899291992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.941609382629395, "step": 72000}
{"episode_reward": 972.778902384966, "episode": 73.0, "batch_reward": 0.8492675994038582, "critic_loss": 0.4556585458219051, "actor_loss": -93.53993812561035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.936859846115112, "step": 73000}
{"episode_reward": 919.9055053825552, "episode": 74.0, "batch_reward": 0.8518586918711663, "critic_loss": 0.423028042063117, "actor_loss": -93.62291720581055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.936728954315186, "step": 74000}
{"episode_reward": 940.7839219987109, "episode": 75.0, "batch_reward": 0.851847512125969, "critic_loss": 0.4357657862007618, "actor_loss": -93.5210167541504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94063377380371, "step": 75000}
{"episode_reward": 964.1866159237766, "episode": 76.0, "batch_reward": 0.8520769056081772, "critic_loss": 0.4738485574871302, "actor_loss": -93.50243089294433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9334077835083, "step": 76000}
{"episode_reward": 897.7249827452865, "episode": 77.0, "batch_reward": 0.8538600015640259, "critic_loss": 0.4874471787214279, "actor_loss": -93.5840343170166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97401475906372, "step": 77000}
{"episode_reward": 961.9187398020946, "episode": 78.0, "batch_reward": 0.8556983343958855, "critic_loss": 0.46889412979781625, "actor_loss": -93.63678704833984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96883988380432, "step": 78000}
{"episode_reward": 911.1156637628901, "episode": 79.0, "batch_reward": 0.856234909772873, "critic_loss": 0.4612704765498638, "actor_loss": -93.5092063446045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.977392196655273, "step": 79000}
{"episode_reward": 968.4316138267881, "episode": 80.0, "batch_reward": 0.8567109205126763, "critic_loss": 0.458223266556859, "actor_loss": -93.51424864196777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95045757293701, "step": 80000}
{"episode_reward": 956.5998019539609, "episode": 81.0, "batch_reward": 0.8580534418225289, "critic_loss": 0.464983861848712, "actor_loss": -93.66538429260254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.272756576538086, "step": 81000}
{"episode_reward": 913.6694214005382, "episode": 82.0, "batch_reward": 0.859969446003437, "critic_loss": 0.47318272151052954, "actor_loss": -93.68198065185547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.939366579055786, "step": 82000}
{"episode_reward": 960.5924913056149, "episode": 83.0, "batch_reward": 0.8609012404084205, "critic_loss": 0.48902229526638985, "actor_loss": -93.67741850280761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.945646286010742, "step": 83000}
{"episode_reward": 947.7245859960573, "episode": 84.0, "batch_reward": 0.8626771294474602, "critic_loss": 0.48790393508970736, "actor_loss": -93.77631466674805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.956512451171875, "step": 84000}
{"episode_reward": 986.3208965114859, "episode": 85.0, "batch_reward": 0.8623933505415916, "critic_loss": 0.46948810973763466, "actor_loss": -93.77569895935059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.898948192596436, "step": 85000}
{"episode_reward": 957.0721602468566, "episode": 86.0, "batch_reward": 0.8653893681764603, "critic_loss": 0.47759858472645284, "actor_loss": -93.7862889251709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.906184911727905, "step": 86000}
{"episode_reward": 952.5424605318954, "episode": 87.0, "batch_reward": 0.8658532365560532, "critic_loss": 0.4424949712306261, "actor_loss": -93.83504225158691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97232413291931, "step": 87000}
{"episode_reward": 930.3939728931038, "episode": 88.0, "batch_reward": 0.8660844867229461, "critic_loss": 0.44222981835901737, "actor_loss": -93.79546580505371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.965094327926636, "step": 88000}
{"episode_reward": 937.8934423964665, "episode": 89.0, "batch_reward": 0.8651408162117005, "critic_loss": 0.44217415221035483, "actor_loss": -93.84639939880371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.974079132080078, "step": 89000}
{"episode_reward": 954.051770145752, "episode": 90.0, "batch_reward": 0.868823272228241, "critic_loss": 0.42765548028051853, "actor_loss": -94.01681698608398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.957523822784424, "step": 90000}
{"episode_reward": 948.9172089442816, "episode": 91.0, "batch_reward": 0.868134456217289, "critic_loss": 0.44813071356713774, "actor_loss": -93.87944966125488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.28165602684021, "step": 91000}
{"episode_reward": 938.0938765381806, "episode": 92.0, "batch_reward": 0.8720213136672974, "critic_loss": 0.43343611209094524, "actor_loss": -94.0049119720459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.955069303512573, "step": 92000}
{"episode_reward": 968.92669724215, "episode": 93.0, "batch_reward": 0.870036639213562, "critic_loss": 0.42072709946334363, "actor_loss": -93.92378967285157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94829750061035, "step": 93000}
{"episode_reward": 982.092504567845, "episode": 94.0, "batch_reward": 0.8704389521479606, "critic_loss": 0.4493978115618229, "actor_loss": -93.9842264251709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.941407918930054, "step": 94000}
{"episode_reward": 840.2902353195486, "episode": 95.0, "batch_reward": 0.8715981922149658, "critic_loss": 0.4710571027249098, "actor_loss": -94.01183769226074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91726040840149, "step": 95000}
{"episode_reward": 944.6677493623724, "episode": 96.0, "batch_reward": 0.872532889187336, "critic_loss": 0.4552451341152191, "actor_loss": -94.03038734436035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.921573638916016, "step": 96000}
{"episode_reward": 930.2079499442132, "episode": 97.0, "batch_reward": 0.8714935555458069, "critic_loss": 0.47020694278180597, "actor_loss": -93.99016030883789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.905719757080078, "step": 97000}
{"episode_reward": 932.0085739225264, "episode": 98.0, "batch_reward": 0.8735051167607307, "critic_loss": 0.46072800575196743, "actor_loss": -94.08988929748536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.910244941711426, "step": 98000}
{"episode_reward": 903.7677183858825, "episode": 99.0, "batch_reward": 0.8723004650473595, "critic_loss": 0.47608707472682, "actor_loss": -94.0387668914795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.941914558410645, "step": 99000}
{"episode_reward": 837.3706904015805, "episode": 100.0, "batch_reward": 0.8746841250658035, "critic_loss": 0.4967829876095057, "actor_loss": -93.9985550994873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.962552547454834, "step": 100000}
{"episode_reward": 914.8551991597635, "episode": 101.0, "batch_reward": 0.8740938194990158, "critic_loss": 0.49820380909740924, "actor_loss": -94.03983258056641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.33271765708923, "step": 101000}
{"episode_reward": 982.9427095457385, "episode": 102.0, "batch_reward": 0.8738394055962563, "critic_loss": 0.4555466088652611, "actor_loss": -93.96280641174316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.957578420639038, "step": 102000}
{"episode_reward": 953.3872525247884, "episode": 103.0, "batch_reward": 0.8742523134946824, "critic_loss": 0.48716936647892, "actor_loss": -93.93192610168457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.964374542236328, "step": 103000}
{"episode_reward": 956.6033363484479, "episode": 104.0, "batch_reward": 0.8768157932758331, "critic_loss": 0.5055972125828266, "actor_loss": -94.00034541320801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.955059051513672, "step": 104000}
{"episode_reward": 946.1310797328293, "episode": 105.0, "batch_reward": 0.8777974930405616, "critic_loss": 0.5358882288336754, "actor_loss": -94.10635781860351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.943665504455566, "step": 105000}
{"episode_reward": 899.0798007436168, "episode": 106.0, "batch_reward": 0.8772545472979546, "critic_loss": 0.5486698445826769, "actor_loss": -94.0550110168457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.952428340911865, "step": 106000}
{"episode_reward": 938.8773314988591, "episode": 107.0, "batch_reward": 0.8768240883350372, "critic_loss": 0.5095945785045624, "actor_loss": -93.96855680847167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.941452026367188, "step": 107000}
{"episode_reward": 960.9408055279985, "episode": 108.0, "batch_reward": 0.8786722025871276, "critic_loss": 0.529082114085555, "actor_loss": -94.06969525146485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.946454763412476, "step": 108000}
{"episode_reward": 902.7153486907384, "episode": 109.0, "batch_reward": 0.8784137929081917, "critic_loss": 0.5115388234704733, "actor_loss": -94.0257560119629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.955740690231323, "step": 109000}
{"episode_reward": 977.7621499262632, "episode": 110.0, "batch_reward": 0.8801217616200447, "critic_loss": 0.5477593448609114, "actor_loss": -94.07135325622559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94718074798584, "step": 110000}
{"episode_reward": 929.4341486062057, "episode": 111.0, "batch_reward": 0.8780247410535812, "critic_loss": 0.6001581777930259, "actor_loss": -94.03440190124512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.279319047927856, "step": 111000}
{"episode_reward": 822.8371870098047, "episode": 112.0, "batch_reward": 0.8806646183729172, "critic_loss": 0.5699320416897535, "actor_loss": -94.06921423339844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96139430999756, "step": 112000}
{"episode_reward": 947.6456009245243, "episode": 113.0, "batch_reward": 0.8805852630138398, "critic_loss": 0.5574876148700714, "actor_loss": -94.03537925720215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.962162494659424, "step": 113000}
{"episode_reward": 959.4315052891245, "episode": 114.0, "batch_reward": 0.8805450403690338, "critic_loss": 0.5517909627705813, "actor_loss": -94.0460605316162, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.961787462234497, "step": 114000}
{"episode_reward": 980.0349575128852, "episode": 115.0, "batch_reward": 0.8814953180551529, "critic_loss": 0.5985503782182932, "actor_loss": -94.00904553222657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94131851196289, "step": 115000}
{"episode_reward": 826.0807423561007, "episode": 116.0, "batch_reward": 0.881820715546608, "critic_loss": 0.5909530856162309, "actor_loss": -94.07614659118653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.949130058288574, "step": 116000}
{"episode_reward": 944.7506249046089, "episode": 117.0, "batch_reward": 0.8814858205914498, "critic_loss": 0.6174997024387121, "actor_loss": -93.97868247985839, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.979984521865845, "step": 117000}
{"episode_reward": 865.9117085392669, "episode": 118.0, "batch_reward": 0.8817470878958702, "critic_loss": 0.5791982373893261, "actor_loss": -94.07589752197265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96786403656006, "step": 118000}
{"episode_reward": 978.3576241577548, "episode": 119.0, "batch_reward": 0.8822705874443054, "critic_loss": 0.6017744685560464, "actor_loss": -94.11315472412109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98245930671692, "step": 119000}
{"episode_reward": 910.3634706628333, "episode": 120.0, "batch_reward": 0.8822810389995575, "critic_loss": 0.6130482946932316, "actor_loss": -93.97493380737305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97964358329773, "step": 120000}
{"episode_reward": 905.6709043915339, "episode": 121.0, "batch_reward": 0.8831536322236061, "critic_loss": 0.6070105833187699, "actor_loss": -94.13383442687989, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.2894344329834, "step": 121000}
{"episode_reward": 985.2948753958291, "episode": 122.0, "batch_reward": 0.8830833278298378, "critic_loss": 0.5886336758285761, "actor_loss": -94.14991033935547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95769214630127, "step": 122000}
{"episode_reward": 957.9658402833148, "episode": 123.0, "batch_reward": 0.8855408182740212, "critic_loss": 0.6044835231900215, "actor_loss": -94.07114726257325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.963162899017334, "step": 123000}
{"episode_reward": 953.5948004342916, "episode": 124.0, "batch_reward": 0.8851749784350396, "critic_loss": 0.6303469546884298, "actor_loss": -94.13008554077149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.968481302261353, "step": 124000}
{"episode_reward": 986.7104149504207, "episode": 125.0, "batch_reward": 0.8865662115216255, "critic_loss": 0.6484761333912611, "actor_loss": -94.08625389099122, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.963776350021362, "step": 125000}
{"episode_reward": 983.2253299196637, "episode": 126.0, "batch_reward": 0.887905573785305, "critic_loss": 0.6023986917585135, "actor_loss": -94.30692864990235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.957191944122314, "step": 126000}
{"episode_reward": 988.2559142444617, "episode": 127.0, "batch_reward": 0.8874134522080421, "critic_loss": 0.6275556043535471, "actor_loss": -94.24926837158203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.914535522460938, "step": 127000}
{"episode_reward": 941.1279671726633, "episode": 128.0, "batch_reward": 0.8870417870879174, "critic_loss": 0.6044669627249241, "actor_loss": -94.33332925415039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.912524461746216, "step": 128000}
{"episode_reward": 962.2856610714568, "episode": 129.0, "batch_reward": 0.8894364700317383, "critic_loss": 0.5566383048892021, "actor_loss": -94.39444630432129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.960296154022217, "step": 129000}
{"episode_reward": 978.5681965497272, "episode": 130.0, "batch_reward": 0.8899195154309273, "critic_loss": 0.5759215648174286, "actor_loss": -94.42334170532227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.967605590820312, "step": 130000}
{"episode_reward": 988.8455401341961, "episode": 131.0, "batch_reward": 0.8910555332303047, "critic_loss": 0.5717621884346008, "actor_loss": -94.35901338195801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.39526176452637, "step": 131000}
{"episode_reward": 974.4609169134775, "episode": 132.0, "batch_reward": 0.8917521568536758, "critic_loss": 0.5793097775578498, "actor_loss": -94.49532484436035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.940415859222412, "step": 132000}
{"episode_reward": 977.7168106454536, "episode": 133.0, "batch_reward": 0.8900643810033798, "critic_loss": 0.5885842163413763, "actor_loss": -94.52007954406739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96566939353943, "step": 133000}
{"episode_reward": 894.0707951631956, "episode": 134.0, "batch_reward": 0.8902177356481552, "critic_loss": 0.5500170089304447, "actor_loss": -94.50399143981933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.967609643936157, "step": 134000}
{"episode_reward": 944.1529714138809, "episode": 135.0, "batch_reward": 0.8928527454733849, "critic_loss": 0.5228092643171549, "actor_loss": -94.57039459228515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96243929862976, "step": 135000}
{"episode_reward": 992.1376168453029, "episode": 136.0, "batch_reward": 0.8926201719045639, "critic_loss": 0.541678861245513, "actor_loss": -94.58091075134277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.972050666809082, "step": 136000}
{"episode_reward": 989.0839767845271, "episode": 137.0, "batch_reward": 0.8923125550746918, "critic_loss": 0.5389716262221337, "actor_loss": -94.5757200012207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.966387510299683, "step": 137000}
{"episode_reward": 983.7384604919413, "episode": 138.0, "batch_reward": 0.8937212920188904, "critic_loss": 0.5561916187107563, "actor_loss": -94.63372521972656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96985173225403, "step": 138000}
{"episode_reward": 769.8254092755486, "episode": 139.0, "batch_reward": 0.892236334502697, "critic_loss": 0.5509216147214174, "actor_loss": -94.64803929138183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34181523323059, "step": 139000}
{"episode_reward": 988.4815100221465, "episode": 140.0, "batch_reward": 0.8938748165369034, "critic_loss": 0.551647036537528, "actor_loss": -94.68526429748535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.309240102767944, "step": 140000}
{"episode_reward": 925.1844974063613, "episode": 141.0, "batch_reward": 0.8936254143714905, "critic_loss": 0.5088242900669575, "actor_loss": -94.70882020568848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.28074645996094, "step": 141000}
{"episode_reward": 966.1485742259634, "episode": 142.0, "batch_reward": 0.8943981121778488, "critic_loss": 0.5019221579134464, "actor_loss": -94.77446418762207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.957258462905884, "step": 142000}
{"episode_reward": 986.0766684775498, "episode": 143.0, "batch_reward": 0.8946655189990997, "critic_loss": 0.4771334997713566, "actor_loss": -94.76969361877441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.974830389022827, "step": 143000}
{"episode_reward": 914.6245496742456, "episode": 144.0, "batch_reward": 0.8954055770039558, "critic_loss": 0.47930638507008555, "actor_loss": -94.8104058380127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.975646018981934, "step": 144000}
{"episode_reward": 948.7824692850146, "episode": 145.0, "batch_reward": 0.8962029767036438, "critic_loss": 0.4703016754090786, "actor_loss": -94.8284398651123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.955094575881958, "step": 145000}
{"episode_reward": 983.7033064416138, "episode": 146.0, "batch_reward": 0.8955390033125877, "critic_loss": 0.501270912155509, "actor_loss": -94.85289248657226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.967387914657593, "step": 146000}
{"episode_reward": 968.5373987867409, "episode": 147.0, "batch_reward": 0.896171035528183, "critic_loss": 0.4640132206082344, "actor_loss": -94.85445361328125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.938312768936157, "step": 147000}
{"episode_reward": 958.5807792043033, "episode": 148.0, "batch_reward": 0.8984340416789055, "critic_loss": 0.45150465989112853, "actor_loss": -94.92926112365723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94382119178772, "step": 148000}
{"episode_reward": 988.0022347463862, "episode": 149.0, "batch_reward": 0.8971781170368195, "critic_loss": 0.4507252821549773, "actor_loss": -94.92936012268066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95703434944153, "step": 149000}
{"episode_reward": 928.2465958460406, "episode": 150.0, "batch_reward": 0.8968751281499863, "critic_loss": 0.4626341161131859, "actor_loss": -94.95738307189941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
