{"episode_reward": 0.0, "episode": 1.0, "duration": 20.58410120010376, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.790086269378662, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.4867487233274974, "critic_loss": 0.8230921888140768, "actor_loss": -88.34275649041355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.894941329956055, "step": 3000}
{"episode_reward": 588.6456610580689, "episode": 4.0, "batch_reward": 0.5610190396606922, "critic_loss": 1.0315018615722655, "actor_loss": -92.45517645263672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33814525604248, "step": 4000}
{"episode_reward": 931.065778369097, "episode": 5.0, "batch_reward": 0.6547633184790611, "critic_loss": 0.9901420968174934, "actor_loss": -95.2111887512207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.349085330963135, "step": 5000}
{"episode_reward": 983.3007936958279, "episode": 6.0, "batch_reward": 0.6973996443152428, "critic_loss": 1.151166949659586, "actor_loss": -96.2931870880127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.339911699295044, "step": 6000}
{"episode_reward": 551.4050660530067, "episode": 7.0, "batch_reward": 0.616459877282381, "critic_loss": 1.566699450790882, "actor_loss": -96.87439102172851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39874839782715, "step": 7000}
{"episode_reward": 35.33105529105086, "episode": 8.0, "batch_reward": 0.5979897136688233, "critic_loss": 1.3719713245630265, "actor_loss": -97.25256776428223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36356520652771, "step": 8000}
{"episode_reward": 895.037063057449, "episode": 9.0, "batch_reward": 0.5837340954840183, "critic_loss": 1.5190098623037338, "actor_loss": -97.07004051208496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35207438468933, "step": 9000}
{"episode_reward": 36.388359613118645, "episode": 10.0, "batch_reward": 0.5668512766063213, "critic_loss": 1.3439613519310951, "actor_loss": -96.80112197875977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.342991828918457, "step": 10000}
{"episode_reward": 630.0216744228652, "episode": 11.0, "batch_reward": 0.5747097122073174, "critic_loss": 1.1061524544358254, "actor_loss": -95.57330143737794, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.801331758499146, "step": 11000}
{"episode_reward": 938.5129054753115, "episode": 12.0, "batch_reward": 0.5709612674713135, "critic_loss": 1.0983641054034232, "actor_loss": -95.16280737304687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.364914655685425, "step": 12000}
{"episode_reward": 161.11510744293088, "episode": 13.0, "batch_reward": 0.537015456110239, "critic_loss": 1.3533647513389588, "actor_loss": -94.17124055480957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.406975269317627, "step": 13000}
{"episode_reward": 40.97374216809562, "episode": 14.0, "batch_reward": 0.5328126810491085, "critic_loss": 1.4438898066878318, "actor_loss": -93.8550651397705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.383761644363403, "step": 14000}
{"episode_reward": 944.6435607950251, "episode": 15.0, "batch_reward": 0.5449927164912224, "critic_loss": 1.6443054071068763, "actor_loss": -92.51085745239257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.389474391937256, "step": 15000}
{"episode_reward": 251.59306528164683, "episode": 16.0, "batch_reward": 0.5221888331174851, "critic_loss": 1.4584541459679603, "actor_loss": -91.62503587341308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.367751598358154, "step": 16000}
{"episode_reward": 304.22412473081937, "episode": 17.0, "batch_reward": 0.5118507591485977, "critic_loss": 1.1870877613425255, "actor_loss": -90.99063526916504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3592312335968, "step": 17000}
{"episode_reward": 491.2921867592813, "episode": 18.0, "batch_reward": 0.518187775760889, "critic_loss": 0.9691060264706611, "actor_loss": -90.29203625488282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.354763984680176, "step": 18000}
{"episode_reward": 652.5082611682743, "episode": 19.0, "batch_reward": 0.531216398447752, "critic_loss": 0.8640774287581444, "actor_loss": -89.50788542175293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.392600297927856, "step": 19000}
{"episode_reward": 894.7935713486287, "episode": 20.0, "batch_reward": 0.5483603216409684, "critic_loss": 0.8231169742643833, "actor_loss": -88.79324772644043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3644437789917, "step": 20000}
{"episode_reward": 869.5586891596009, "episode": 21.0, "batch_reward": 0.5626805211305619, "critic_loss": 0.9229938092231751, "actor_loss": -88.36677952575684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.61843729019165, "step": 21000}
{"episode_reward": 877.6954020562163, "episode": 22.0, "batch_reward": 0.580320125579834, "critic_loss": 1.0721480922102928, "actor_loss": -88.67175340270997, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36860752105713, "step": 22000}
{"episode_reward": 891.2043877017254, "episode": 23.0, "batch_reward": 0.5853302420079708, "critic_loss": 1.1596047559976577, "actor_loss": -88.36771647644044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.378082513809204, "step": 23000}
{"episode_reward": 743.1197997268968, "episode": 24.0, "batch_reward": 0.6019466135203838, "critic_loss": 1.064162350833416, "actor_loss": -88.50357119750977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37194538116455, "step": 24000}
{"episode_reward": 981.9413571091707, "episode": 25.0, "batch_reward": 0.6142251814603805, "critic_loss": 1.0719692556262017, "actor_loss": -88.65365354919433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.352591276168823, "step": 25000}
{"episode_reward": 935.4957881860452, "episode": 26.0, "batch_reward": 0.625186205893755, "critic_loss": 1.0606754618883132, "actor_loss": -88.48186776733398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36111068725586, "step": 26000}
{"episode_reward": 942.5098925424679, "episode": 27.0, "batch_reward": 0.6417209783792496, "critic_loss": 1.0298713267445565, "actor_loss": -88.74319818115234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.344719886779785, "step": 27000}
{"episode_reward": 981.9879686962876, "episode": 28.0, "batch_reward": 0.6532418591380119, "critic_loss": 1.0185314170122146, "actor_loss": -88.92799531555175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.350745916366577, "step": 28000}
{"episode_reward": 952.4919510528199, "episode": 29.0, "batch_reward": 0.662564675450325, "critic_loss": 1.027803750038147, "actor_loss": -88.82097103881836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.365126609802246, "step": 29000}
{"episode_reward": 896.5149409442619, "episode": 30.0, "batch_reward": 0.6728720008730888, "critic_loss": 0.9634629704654217, "actor_loss": -88.94184362792969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.374207735061646, "step": 30000}
{"episode_reward": 931.9640289753445, "episode": 31.0, "batch_reward": 0.6774737269282342, "critic_loss": 1.0083809169530868, "actor_loss": -89.1865274810791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.69702625274658, "step": 31000}
{"episode_reward": 865.3602612335138, "episode": 32.0, "batch_reward": 0.6825339463949204, "critic_loss": 1.0907221669256688, "actor_loss": -89.04441310119628, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.366610288619995, "step": 32000}
{"episode_reward": 685.8270431247473, "episode": 33.0, "batch_reward": 0.6820351665019989, "critic_loss": 1.0618132343888282, "actor_loss": -88.72248776245117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.398038387298584, "step": 33000}
{"episode_reward": 831.6154832573696, "episode": 34.0, "batch_reward": 0.6918640965819359, "critic_loss": 0.9758251485228538, "actor_loss": -88.83241384887695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.389787435531616, "step": 34000}
{"episode_reward": 966.3999233148454, "episode": 35.0, "batch_reward": 0.6975036489963532, "critic_loss": 0.9511809278428555, "actor_loss": -88.99728900146485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.378787517547607, "step": 35000}
{"episode_reward": 921.7378235618962, "episode": 36.0, "batch_reward": 0.7028593940734863, "critic_loss": 0.9668716244399548, "actor_loss": -88.85851351928711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.362979888916016, "step": 36000}
{"episode_reward": 923.0165896075031, "episode": 37.0, "batch_reward": 0.7077462965250015, "critic_loss": 1.0511285561919212, "actor_loss": -89.07882205200195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37068247795105, "step": 37000}
{"episode_reward": 872.4175075662076, "episode": 38.0, "batch_reward": 0.7156181251406669, "critic_loss": 0.9904557635188103, "actor_loss": -89.24740989685058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35539412498474, "step": 38000}
{"episode_reward": 985.2925412130339, "episode": 39.0, "batch_reward": 0.7194216365814209, "critic_loss": 1.0142352132201196, "actor_loss": -89.45367541503906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.385873317718506, "step": 39000}
{"episode_reward": 952.6707543080424, "episode": 40.0, "batch_reward": 0.7292016872763634, "critic_loss": 0.9984683618247508, "actor_loss": -89.57637113952637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.380484342575073, "step": 40000}
{"episode_reward": 935.7583075493028, "episode": 41.0, "batch_reward": 0.7317360895276069, "critic_loss": 0.9669691501557827, "actor_loss": -89.52520552062988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.70832896232605, "step": 41000}
{"episode_reward": 902.6367947656507, "episode": 42.0, "batch_reward": 0.7373793650865554, "critic_loss": 0.9696478372216225, "actor_loss": -89.68546112060547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37923002243042, "step": 42000}
{"episode_reward": 971.2457018706947, "episode": 43.0, "batch_reward": 0.7430833994150162, "critic_loss": 1.012770553290844, "actor_loss": -89.90206997680664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34341073036194, "step": 43000}
{"episode_reward": 932.1581100772669, "episode": 44.0, "batch_reward": 0.7475229133963585, "critic_loss": 0.9225942361652851, "actor_loss": -90.11003085327148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.343209266662598, "step": 44000}
{"episode_reward": 974.5864828935654, "episode": 45.0, "batch_reward": 0.7519192892313004, "critic_loss": 0.8471558609604836, "actor_loss": -90.4495442199707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35895085334778, "step": 45000}
{"episode_reward": 955.2535914344923, "episode": 46.0, "batch_reward": 0.7582504225969314, "critic_loss": 0.856897904574871, "actor_loss": -90.72531076049805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.358689785003662, "step": 46000}
{"episode_reward": 968.9982074348167, "episode": 47.0, "batch_reward": 0.7626500072479248, "critic_loss": 0.7883147097826004, "actor_loss": -90.77429640197754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38615918159485, "step": 47000}
{"episode_reward": 956.108331171949, "episode": 48.0, "batch_reward": 0.764946054816246, "critic_loss": 0.8393444742560386, "actor_loss": -90.85224594116211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.375563144683838, "step": 48000}
{"episode_reward": 890.8548292932979, "episode": 49.0, "batch_reward": 0.768007273375988, "critic_loss": 0.7580699056982995, "actor_loss": -90.98099263000488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.369720458984375, "step": 49000}
{"episode_reward": 945.010509442494, "episode": 50.0, "batch_reward": 0.7712661076784134, "critic_loss": 0.7037124275267124, "actor_loss": -91.02014154052735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.333953380584717, "step": 50000}
{"episode_reward": 987.7928600113635, "episode": 51.0, "batch_reward": 0.7787832901477814, "critic_loss": 0.6696643536686897, "actor_loss": -90.94240391540528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.6826548576355, "step": 51000}
{"episode_reward": 981.1725347742006, "episode": 52.0, "batch_reward": 0.778705870270729, "critic_loss": 0.6659239599704743, "actor_loss": -91.1024274597168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37239670753479, "step": 52000}
{"episode_reward": 931.5940517196597, "episode": 53.0, "batch_reward": 0.7839632042646408, "critic_loss": 0.6709903579950333, "actor_loss": -91.2656425628662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39357566833496, "step": 53000}
{"episode_reward": 957.9316973255516, "episode": 54.0, "batch_reward": 0.7841614899635315, "critic_loss": 0.6497523748278617, "actor_loss": -91.32086054992676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.352765560150146, "step": 54000}
{"episode_reward": 924.3517949392952, "episode": 55.0, "batch_reward": 0.7898105577230453, "critic_loss": 0.6812256142199039, "actor_loss": -91.32324546813965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.399645566940308, "step": 55000}
{"episode_reward": 973.7825619422921, "episode": 56.0, "batch_reward": 0.7914849701523781, "critic_loss": 0.6150827971249819, "actor_loss": -91.52267112731934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.364378213882446, "step": 56000}
{"episode_reward": 980.8566247968535, "episode": 57.0, "batch_reward": 0.7904375783801079, "critic_loss": 0.6405296236276626, "actor_loss": -91.66520364379883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.337190866470337, "step": 57000}
{"episode_reward": 488.19696782135054, "episode": 58.0, "batch_reward": 0.7895953024625778, "critic_loss": 0.5908954926431179, "actor_loss": -91.55878378295898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.365798234939575, "step": 58000}
{"episode_reward": 959.5626278637603, "episode": 59.0, "batch_reward": 0.7919972795248031, "critic_loss": 0.6186334645152092, "actor_loss": -91.69620095825195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.406819105148315, "step": 59000}
{"episode_reward": 860.6827148255514, "episode": 60.0, "batch_reward": 0.7926011849045753, "critic_loss": 0.593668762370944, "actor_loss": -91.88046939086914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38154935836792, "step": 60000}
{"episode_reward": 976.2218027541649, "episode": 61.0, "batch_reward": 0.7953949847817421, "critic_loss": 0.6659744562506675, "actor_loss": -91.62772158813476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.74154710769653, "step": 61000}
{"episode_reward": 877.9543193057572, "episode": 62.0, "batch_reward": 0.7972936551570893, "critic_loss": 0.6514762345850468, "actor_loss": -91.57781288146973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.379119157791138, "step": 62000}
{"episode_reward": 960.1803363097205, "episode": 63.0, "batch_reward": 0.7996616790294647, "critic_loss": 0.6293624463379384, "actor_loss": -91.74121746826172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.4093976020813, "step": 63000}
{"episode_reward": 936.2515327984951, "episode": 64.0, "batch_reward": 0.8030596644878387, "critic_loss": 0.6665561508387328, "actor_loss": -91.7908521118164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.365330457687378, "step": 64000}
{"episode_reward": 988.659093809947, "episode": 65.0, "batch_reward": 0.8048712949156761, "critic_loss": 0.6340217220634222, "actor_loss": -91.85303501892089, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.343334197998047, "step": 65000}
{"episode_reward": 961.3153167958907, "episode": 66.0, "batch_reward": 0.8068598122596741, "critic_loss": 0.6388108876943588, "actor_loss": -91.97488095092774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.332885026931763, "step": 66000}
{"episode_reward": 913.7960200172382, "episode": 67.0, "batch_reward": 0.8086794441938401, "critic_loss": 0.6500451742708683, "actor_loss": -92.08808818054199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.341662883758545, "step": 67000}
{"episode_reward": 874.1025590465713, "episode": 68.0, "batch_reward": 0.8108509819507599, "critic_loss": 0.6421258381605148, "actor_loss": -91.93716812133789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3908531665802, "step": 68000}
{"episode_reward": 955.2575718207831, "episode": 69.0, "batch_reward": 0.8132383018732071, "critic_loss": 0.6272571736723185, "actor_loss": -92.17354113769531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.390915155410767, "step": 69000}
{"episode_reward": 983.9593019877778, "episode": 70.0, "batch_reward": 0.8141729130148888, "critic_loss": 0.6360881748795509, "actor_loss": -92.13864096069337, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35614824295044, "step": 70000}
{"episode_reward": 932.5415369042887, "episode": 71.0, "batch_reward": 0.8186583250164986, "critic_loss": 0.6062175630629063, "actor_loss": -92.09264981079102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.67577075958252, "step": 71000}
{"episode_reward": 946.13132332006, "episode": 72.0, "batch_reward": 0.8189150361418724, "critic_loss": 0.6285953834950924, "actor_loss": -92.25154360961913, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33067774772644, "step": 72000}
{"episode_reward": 978.8551024355976, "episode": 73.0, "batch_reward": 0.8206617529988289, "critic_loss": 0.6093690034747123, "actor_loss": -92.32581285095215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.386427640914917, "step": 73000}
{"episode_reward": 985.7490903078011, "episode": 74.0, "batch_reward": 0.8250150316953659, "critic_loss": 0.6097145524919033, "actor_loss": -92.50467045593261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.365347146987915, "step": 74000}
{"episode_reward": 914.6069227560057, "episode": 75.0, "batch_reward": 0.8256513121128082, "critic_loss": 0.6120287125855685, "actor_loss": -92.47987785339356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.360708951950073, "step": 75000}
{"episode_reward": 966.6936675839625, "episode": 76.0, "batch_reward": 0.8254195943474769, "critic_loss": 0.5944983546882868, "actor_loss": -92.4605458984375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33541202545166, "step": 76000}
{"episode_reward": 946.8774503419785, "episode": 77.0, "batch_reward": 0.8265150063633919, "critic_loss": 0.6516618594229221, "actor_loss": -92.46038270568847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3456711769104, "step": 77000}
{"episode_reward": 962.3320678389618, "episode": 78.0, "batch_reward": 0.829188374042511, "critic_loss": 0.7218828331828118, "actor_loss": -92.6910263671875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.393877744674683, "step": 78000}
{"episode_reward": 952.042501999267, "episode": 79.0, "batch_reward": 0.8313639517426491, "critic_loss": 0.8321418443620205, "actor_loss": -92.69585850524902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.390700101852417, "step": 79000}
{"episode_reward": 945.4124164631867, "episode": 80.0, "batch_reward": 0.8317842569947242, "critic_loss": 0.8942691072821617, "actor_loss": -92.74257922363282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.391427993774414, "step": 80000}
{"episode_reward": 979.8829633603609, "episode": 81.0, "batch_reward": 0.8347233364582062, "critic_loss": 1.0334917583167553, "actor_loss": -93.02046121215821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.702654123306274, "step": 81000}
{"episode_reward": 894.3732616357914, "episode": 82.0, "batch_reward": 0.8357627026438713, "critic_loss": 1.1638718630373477, "actor_loss": -93.13278437805175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35250425338745, "step": 82000}
{"episode_reward": 961.6361156888667, "episode": 83.0, "batch_reward": 0.8375302234888077, "critic_loss": 1.366677707672119, "actor_loss": -93.21885681152344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.379435777664185, "step": 83000}
{"episode_reward": 906.3984099400627, "episode": 84.0, "batch_reward": 0.839555951833725, "critic_loss": 1.8045265942811965, "actor_loss": -93.39983070373535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.370139598846436, "step": 84000}
{"episode_reward": 977.6205328832511, "episode": 85.0, "batch_reward": 0.8379375885128975, "critic_loss": 2.2580976762771607, "actor_loss": -93.58423365783692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.355420351028442, "step": 85000}
{"episode_reward": 958.8586342288899, "episode": 86.0, "batch_reward": 0.8408511818647385, "critic_loss": 2.7697179032564163, "actor_loss": -93.97371659851075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.383416891098022, "step": 86000}
{"episode_reward": 954.9284432622075, "episode": 87.0, "batch_reward": 0.8361817201375962, "critic_loss": 3.1943615419864653, "actor_loss": -94.77120256042481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.394089460372925, "step": 87000}
{"episode_reward": 78.65538340408857, "episode": 88.0, "batch_reward": 0.8293180882334709, "critic_loss": 2.7612282138466835, "actor_loss": -95.7250662536621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39144778251648, "step": 88000}
{"episode_reward": 71.53197987874366, "episode": 89.0, "batch_reward": 0.8188474873304367, "critic_loss": 2.644936292052269, "actor_loss": -96.21863981628418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.417116165161133, "step": 89000}
{"episode_reward": 68.46528804710736, "episode": 90.0, "batch_reward": 0.8166628710627556, "critic_loss": 2.246646142601967, "actor_loss": -96.31397111511231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38259983062744, "step": 90000}
{"episode_reward": 963.0296939420431, "episode": 91.0, "batch_reward": 0.813364036142826, "critic_loss": 2.1541934435367582, "actor_loss": -96.58682666015625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.0774028301239, "step": 91000}
{"episode_reward": 53.220570530387704, "episode": 92.0, "batch_reward": 0.8111480786800385, "critic_loss": 1.8973377620875835, "actor_loss": -96.70900914001464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.364630222320557, "step": 92000}
{"episode_reward": 961.3707822628062, "episode": 93.0, "batch_reward": 0.8056979203820228, "critic_loss": 1.7014200859367847, "actor_loss": -96.5717667236328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.402597427368164, "step": 93000}
{"episode_reward": 44.09118594135899, "episode": 94.0, "batch_reward": 0.7997676861286164, "critic_loss": 1.4738372398018837, "actor_loss": -96.53154493713379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38237166404724, "step": 94000}
{"episode_reward": 34.51121195799948, "episode": 95.0, "batch_reward": 0.7941848213672638, "critic_loss": 1.3817327712476253, "actor_loss": -95.9771488494873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.374855756759644, "step": 95000}
{"episode_reward": 959.2787426185014, "episode": 96.0, "batch_reward": 0.7960969550013542, "critic_loss": 1.2137242495119571, "actor_loss": -95.79926881408691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.387404918670654, "step": 96000}
{"episode_reward": 929.5618047870263, "episode": 97.0, "batch_reward": 0.7952793840169906, "critic_loss": 1.1323805519044399, "actor_loss": -95.424497756958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.361724615097046, "step": 97000}
{"episode_reward": 692.0717856395307, "episode": 98.0, "batch_reward": 0.7918533920049667, "critic_loss": 1.0656430338025094, "actor_loss": -95.11483995056152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.423972845077515, "step": 98000}
{"episode_reward": 64.80231509161094, "episode": 99.0, "batch_reward": 0.7872354059219361, "critic_loss": 1.1956697575747968, "actor_loss": -95.02344032287597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.413912296295166, "step": 99000}
{"episode_reward": 258.90425828009404, "episode": 100.0, "batch_reward": 0.7815634635686874, "critic_loss": 1.0530515801310538, "actor_loss": -95.02534335327148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38540530204773, "step": 100000}
{"episode_reward": 46.801918179860245, "episode": 101.0, "batch_reward": 0.7718066673874855, "critic_loss": 1.0566162234544754, "actor_loss": -94.7217790222168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.77977466583252, "step": 101000}
{"episode_reward": 228.43633773469983, "episode": 102.0, "batch_reward": 0.7698758475184441, "critic_loss": 0.9987844654023648, "actor_loss": -94.78851231384277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38371777534485, "step": 102000}
{"episode_reward": 445.55590382061115, "episode": 103.0, "batch_reward": 0.7660906029343605, "critic_loss": 1.0164902040064334, "actor_loss": -94.71427661132813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.370980978012085, "step": 103000}
{"episode_reward": 541.9203040829918, "episode": 104.0, "batch_reward": 0.7651088917851449, "critic_loss": 1.028973125964403, "actor_loss": -94.82248725891114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.395931243896484, "step": 104000}
{"episode_reward": 909.8290618729221, "episode": 105.0, "batch_reward": 0.7668878285884857, "critic_loss": 1.0800382370948791, "actor_loss": -95.01860502624511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37677502632141, "step": 105000}
{"episode_reward": 904.4370325780865, "episode": 106.0, "batch_reward": 0.7679492769241333, "critic_loss": 1.0978186557888985, "actor_loss": -95.13362593078614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.391295433044434, "step": 106000}
{"episode_reward": 864.2131848091087, "episode": 107.0, "batch_reward": 0.7686319735050201, "critic_loss": 1.0954585662782192, "actor_loss": -94.84625294494629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.386756658554077, "step": 107000}
{"episode_reward": 930.9345470805105, "episode": 108.0, "batch_reward": 0.7717348667383194, "critic_loss": 1.091621130079031, "actor_loss": -94.89413182067871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.390931129455566, "step": 108000}
{"episode_reward": 953.9425860720866, "episode": 109.0, "batch_reward": 0.7718364769220352, "critic_loss": 1.1301754968762399, "actor_loss": -94.82473281860352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35900115966797, "step": 109000}
{"episode_reward": 925.0982561293766, "episode": 110.0, "batch_reward": 0.7732078873515129, "critic_loss": 1.1686524817049504, "actor_loss": -94.67234916687012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.344566345214844, "step": 110000}
{"episode_reward": 827.6589776589567, "episode": 111.0, "batch_reward": 0.7744580573439598, "critic_loss": 1.2054862752854825, "actor_loss": -94.58684288024902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.63062787055969, "step": 111000}
{"episode_reward": 942.8072684292141, "episode": 112.0, "batch_reward": 0.7757796288728714, "critic_loss": 1.1699619644880295, "actor_loss": -94.57870803833008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.334398984909058, "step": 112000}
{"episode_reward": 946.2326177169169, "episode": 113.0, "batch_reward": 0.7787778650522232, "critic_loss": 1.1819902802407742, "actor_loss": -94.6271176147461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.350394248962402, "step": 113000}
{"episode_reward": 959.910756884756, "episode": 114.0, "batch_reward": 0.7797265399694443, "critic_loss": 1.1570532581210136, "actor_loss": -94.3876981201172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.347710371017456, "step": 114000}
{"episode_reward": 969.2321089894418, "episode": 115.0, "batch_reward": 0.7811801398992538, "critic_loss": 1.136326180756092, "actor_loss": -94.40612133789062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.394834995269775, "step": 115000}
{"episode_reward": 953.0138022427848, "episode": 116.0, "batch_reward": 0.7821024402379989, "critic_loss": 1.1547512407302856, "actor_loss": -94.36275804138184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.376311779022217, "step": 116000}
{"episode_reward": 937.6684587037439, "episode": 117.0, "batch_reward": 0.7826541392207146, "critic_loss": 1.0681870788633823, "actor_loss": -94.4371983947754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.392935037612915, "step": 117000}
{"episode_reward": 941.9513797508924, "episode": 118.0, "batch_reward": 0.7819376683235169, "critic_loss": 1.0407779690921306, "actor_loss": -94.30845289611817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.380426168441772, "step": 118000}
{"episode_reward": 987.8248716931791, "episode": 119.0, "batch_reward": 0.7865632607936859, "critic_loss": 0.9551713778078557, "actor_loss": -94.19685850524903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.40103316307068, "step": 119000}
{"episode_reward": 941.1166763239335, "episode": 120.0, "batch_reward": 0.7867382164001465, "critic_loss": 0.9227186492085457, "actor_loss": -94.17698666381835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.380078315734863, "step": 120000}
{"episode_reward": 925.490554110548, "episode": 121.0, "batch_reward": 0.787409815132618, "critic_loss": 0.8809337198734284, "actor_loss": -94.10062130737305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.69575214385986, "step": 121000}
{"episode_reward": 956.5385946674002, "episode": 122.0, "batch_reward": 0.7891316714286805, "critic_loss": 0.857737845748663, "actor_loss": -94.05395249938965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.365174531936646, "step": 122000}
{"episode_reward": 939.7790026629917, "episode": 123.0, "batch_reward": 0.791962601006031, "critic_loss": 0.8519145459234715, "actor_loss": -94.06685516357422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34173035621643, "step": 123000}
{"episode_reward": 954.0553446695228, "episode": 124.0, "batch_reward": 0.7931956990361214, "critic_loss": 0.8609408416152, "actor_loss": -93.93915928649902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.351742029190063, "step": 124000}
{"episode_reward": 988.0195501069499, "episode": 125.0, "batch_reward": 0.7965678966641426, "critic_loss": 0.8027930508852005, "actor_loss": -94.04523295593262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.388594388961792, "step": 125000}
{"episode_reward": 980.7688854874341, "episode": 126.0, "batch_reward": 0.7970621236562729, "critic_loss": 0.8076078394949436, "actor_loss": -93.97237442016602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.375277519226074, "step": 126000}
{"episode_reward": 988.8119636948504, "episode": 127.0, "batch_reward": 0.7974458945989609, "critic_loss": 0.7691794770061969, "actor_loss": -93.91103868103028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36211133003235, "step": 127000}
{"episode_reward": 951.4963598629396, "episode": 128.0, "batch_reward": 0.7982346317172051, "critic_loss": 0.7496316740512848, "actor_loss": -93.94141014099121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39356780052185, "step": 128000}
{"episode_reward": 961.7414731723466, "episode": 129.0, "batch_reward": 0.8002433288693428, "critic_loss": 0.7196793675869704, "actor_loss": -93.89456158447265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.377286195755005, "step": 129000}
{"episode_reward": 982.6738513427117, "episode": 130.0, "batch_reward": 0.8043690727949142, "critic_loss": 0.689874644100666, "actor_loss": -93.93052169799805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38770294189453, "step": 130000}
{"episode_reward": 984.3995356272753, "episode": 131.0, "batch_reward": 0.8038718797564507, "critic_loss": 0.6569181286990643, "actor_loss": -93.83423002624512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.74795317649841, "step": 131000}
{"episode_reward": 983.676418602448, "episode": 132.0, "batch_reward": 0.8050250918865204, "critic_loss": 0.6296823370009661, "actor_loss": -93.89261616516113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36410617828369, "step": 132000}
{"episode_reward": 978.633810847042, "episode": 133.0, "batch_reward": 0.806625795185566, "critic_loss": 0.6278282675594091, "actor_loss": -93.89796627807617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.659340381622314, "step": 133000}
{"episode_reward": 961.3491347041806, "episode": 134.0, "batch_reward": 0.8061670210957527, "critic_loss": 0.6079990192651749, "actor_loss": -93.82136570739746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.322021007537842, "step": 134000}
{"episode_reward": 960.9180890679885, "episode": 135.0, "batch_reward": 0.8078287096619606, "critic_loss": 0.5990816092789173, "actor_loss": -93.87098063659668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.331138849258423, "step": 135000}
{"episode_reward": 991.0254859097532, "episode": 136.0, "batch_reward": 0.8086582419276237, "critic_loss": 0.5657054950296879, "actor_loss": -93.78870520019531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.636836767196655, "step": 136000}
{"episode_reward": 989.4405523643621, "episode": 137.0, "batch_reward": 0.8103845063447952, "critic_loss": 0.5672704043984413, "actor_loss": -93.83251522827149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38229012489319, "step": 137000}
{"episode_reward": 966.5319544794122, "episode": 138.0, "batch_reward": 0.8129429104328155, "critic_loss": 0.556246758878231, "actor_loss": -93.91334362792969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36509394645691, "step": 138000}
{"episode_reward": 960.0064947380707, "episode": 139.0, "batch_reward": 0.8114623965024949, "critic_loss": 0.5792902555316687, "actor_loss": -93.86258982849121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.357283353805542, "step": 139000}
{"episode_reward": 988.2861769581677, "episode": 140.0, "batch_reward": 0.8145221753716468, "critic_loss": 0.5290041379034519, "actor_loss": -93.84513890075684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.406152486801147, "step": 140000}
{"episode_reward": 952.5379362781272, "episode": 141.0, "batch_reward": 0.8168401556611061, "critic_loss": 0.5372017570137978, "actor_loss": -93.91330595397949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.76309633255005, "step": 141000}
{"episode_reward": 967.6152959318407, "episode": 142.0, "batch_reward": 0.8150672534108162, "critic_loss": 0.5560152575522661, "actor_loss": -93.7985498046875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.355449199676514, "step": 142000}
{"episode_reward": 989.2747683069593, "episode": 143.0, "batch_reward": 0.8176430335640907, "critic_loss": 0.5462484019845724, "actor_loss": -93.8444985961914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.373496055603027, "step": 143000}
{"episode_reward": 949.0981076122731, "episode": 144.0, "batch_reward": 0.8173661037087441, "critic_loss": 0.5326705888062716, "actor_loss": -93.8172996520996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39053225517273, "step": 144000}
{"episode_reward": 957.4682148392209, "episode": 145.0, "batch_reward": 0.8201188235878945, "critic_loss": 0.5259584876000881, "actor_loss": -93.81528703308105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.389030694961548, "step": 145000}
{"episode_reward": 988.5290784968095, "episode": 146.0, "batch_reward": 0.8195532349944115, "critic_loss": 0.5367786694914103, "actor_loss": -93.76940423583984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37358045578003, "step": 146000}
{"episode_reward": 965.7882256252748, "episode": 147.0, "batch_reward": 0.8203211268782615, "critic_loss": 0.5164417550116778, "actor_loss": -93.74554365539551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38276195526123, "step": 147000}
{"episode_reward": 951.6011259268317, "episode": 148.0, "batch_reward": 0.8229640432596207, "critic_loss": 0.5065872924774886, "actor_loss": -93.83450730895996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.639117002487183, "step": 148000}
{"episode_reward": 988.7624882251307, "episode": 149.0, "batch_reward": 0.821984947025776, "critic_loss": 0.4802315770834684, "actor_loss": -93.73207218933105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.429776668548584, "step": 149000}
{"episode_reward": 942.9921028826764, "episode": 150.0, "batch_reward": 0.8228585278391838, "critic_loss": 0.4813142785280943, "actor_loss": -93.77567196655274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
