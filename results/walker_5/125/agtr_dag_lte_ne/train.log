{"episode": 1.0, "duration": 17.738523960113525, "episode_reward": 59.660092495208936, "step": 1000}
{"episode": 2.0, "duration": 1.4989030361175537, "episode_reward": 890.1817750618746, "step": 2000}
{"episode": 3.0, "batch_reward": 0.49748840791935045, "critic_loss": 0.6953414492694169, "actor_loss": -87.6525359502932, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 80.78414463996887, "episode_reward": 762.1410582394764, "step": 3000}
{"episode": 4.0, "batch_reward": 0.6042919673025609, "critic_loss": 1.2941473517417907, "actor_loss": -93.73613195800782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.807570457458496, "episode_reward": 886.941852128267, "step": 4000}
{"episode": 5.0, "batch_reward": 0.6821268948316574, "critic_loss": 1.2088516823649407, "actor_loss": -95.31265074157714, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.115670680999756, "episode_reward": 916.7045404268207, "step": 5000}
{"episode": 6.0, "batch_reward": 0.7219056286811829, "critic_loss": 1.1827372045516968, "actor_loss": -96.80337341308594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.026156187057495, "episode_reward": 934.6946176912439, "step": 6000}
{"episode": 7.0, "batch_reward": 0.7425612226724625, "critic_loss": 1.1022227345705031, "actor_loss": -97.77608447265625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.304073095321655, "episode_reward": 815.7597764731161, "step": 7000}
{"episode": 8.0, "batch_reward": 0.7597772728800773, "critic_loss": 1.1121851536035539, "actor_loss": -97.91509075927735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.25508213043213, "episode_reward": 900.3535971313752, "step": 8000}
{"episode": 9.0, "batch_reward": 0.7659616549015045, "critic_loss": 1.0081804743409157, "actor_loss": -97.924759475708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.433855533599854, "episode_reward": 839.0920980414141, "step": 9000}
{"episode": 10.0, "batch_reward": 0.7821175267100334, "critic_loss": 0.8506733457446098, "actor_loss": -96.79171328735352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 4828.9286143779755, "episode_reward": 917.8062445644995, "step": 10000}
{"episode": 11.0, "batch_reward": 0.7993702393174171, "critic_loss": 0.686754816353321, "actor_loss": -96.78500584411621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.07534217834473, "episode_reward": 924.4877658056635, "step": 11000}
{"episode": 12.0, "batch_reward": 0.8054624552130699, "critic_loss": 0.6297938562631608, "actor_loss": -95.78036793518066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 539.0539903640747, "episode_reward": 875.7479943173067, "step": 12000}
{"episode": 13.0, "batch_reward": 0.8129463323950767, "critic_loss": 0.655192509829998, "actor_loss": -95.6382042541504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.707864999771118, "episode_reward": 919.6299881460747, "step": 13000}
{"episode": 14.0, "batch_reward": 0.8253177500367165, "critic_loss": 0.5616559876799584, "actor_loss": -95.42593072509766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 561.847642660141, "episode_reward": 974.0856381728912, "step": 14000}
{"episode": 15.0, "batch_reward": 0.8345855149030685, "critic_loss": 0.5219375665485859, "actor_loss": -94.66361849975586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.24304962158203, "episode_reward": 974.2729603281089, "step": 15000}
{"episode": 16.0, "batch_reward": 0.8383609384894372, "critic_loss": 0.6049785555303097, "actor_loss": -94.0160802154541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 556.5117485523224, "episode_reward": 895.2318746307992, "step": 16000}
{"episode": 17.0, "batch_reward": 0.8433782648444176, "critic_loss": 0.5548470251560211, "actor_loss": -93.8410279083252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.639870405197144, "episode_reward": 901.5727074567046, "step": 17000}
{"episode": 18.0, "batch_reward": 0.8462780124545097, "critic_loss": 0.6133121575415135, "actor_loss": -93.45989953613281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 557.0182049274445, "episode_reward": 925.338629259115, "step": 18000}
{"episode": 19.0, "batch_reward": 0.8540785244703293, "critic_loss": 0.6070602964758873, "actor_loss": -93.65790725708008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.493175745010376, "episode_reward": 973.0969523596228, "step": 19000}
{"episode": 20.0, "batch_reward": 0.8588209269046784, "critic_loss": 0.5654860477745532, "actor_loss": -92.79087754821778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 559.0836918354034, "episode_reward": 929.9330671573341, "step": 20000}
{"episode": 21.0, "batch_reward": 0.8572512600421905, "critic_loss": 0.6164176678657531, "actor_loss": -92.50420724487304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.70753812789917, "episode_reward": 863.0665587889675, "step": 21000}
{"episode": 22.0, "batch_reward": 0.8596641414165497, "critic_loss": 0.5668881757855415, "actor_loss": -92.17092678833008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 556.3665888309479, "episode_reward": 856.3483482305833, "step": 22000}
{"episode": 23.0, "batch_reward": 0.8605197364091873, "critic_loss": 0.5743973875939846, "actor_loss": -92.07382958984375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.346903085708618, "episode_reward": 921.5337257807618, "step": 23000}
{"episode": 24.0, "batch_reward": 0.8652270585894585, "critic_loss": 0.5206721950769424, "actor_loss": -91.34026881408691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 557.3544487953186, "episode_reward": 940.2113719275053, "step": 24000}
{"episode": 25.0, "batch_reward": 0.8667073872685432, "critic_loss": 0.533365947663784, "actor_loss": -91.58137910461426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.440313816070557, "episode_reward": 939.8227367988868, "step": 25000}
{"episode": 26.0, "batch_reward": 0.8714243000149727, "critic_loss": 0.5037033482939005, "actor_loss": -90.78858283996583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 555.7766513824463, "episode_reward": 969.5878063334587, "step": 26000}
{"episode": 27.0, "batch_reward": 0.8724780973792076, "critic_loss": 0.5244002923220396, "actor_loss": -90.75038468933106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.33257031440735, "episode_reward": 940.0922193826193, "step": 27000}
{"episode": 28.0, "batch_reward": 0.8759962228536606, "critic_loss": 0.5404886420071126, "actor_loss": -90.51041493225098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 555.0596044063568, "episode_reward": 938.2140510379568, "step": 28000}
{"episode": 29.0, "batch_reward": 0.8746754816174507, "critic_loss": 0.5705083806216716, "actor_loss": -90.05254498291016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.134888410568237, "episode_reward": 830.7767785414097, "step": 29000}
{"episode": 30.0, "batch_reward": 0.8741798055171967, "critic_loss": 0.5781369018852711, "actor_loss": -90.15093060302735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 558.6443498134613, "episode_reward": 885.1547980916321, "step": 30000}
{"episode": 31.0, "batch_reward": 0.877348539352417, "critic_loss": 0.5555724139809608, "actor_loss": -90.37197686767578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.73516893386841, "episode_reward": 949.3304566320498, "step": 31000}
{"episode": 32.0, "batch_reward": 0.8797926244735718, "critic_loss": 0.5095628761649131, "actor_loss": -89.74577941894532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 555.8070118427277, "episode_reward": 967.1605257854063, "step": 32000}
{"episode": 33.0, "batch_reward": 0.8821044607758523, "critic_loss": 0.48550326177477837, "actor_loss": -89.62503732299805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.43776249885559, "episode_reward": 948.7029635505394, "step": 33000}
{"episode": 34.0, "batch_reward": 0.8839767141342163, "critic_loss": 0.4896510922312737, "actor_loss": -89.65664739990234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 558.2971210479736, "episode_reward": 976.4289118479899, "step": 34000}
{"episode": 35.0, "batch_reward": 0.88648786008358, "critic_loss": 0.4960312193483114, "actor_loss": -89.53321961975098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.30183744430542, "episode_reward": 940.8022708449487, "step": 35000}
{"episode": 36.0, "batch_reward": 0.8878888874650002, "critic_loss": 0.5001144195348024, "actor_loss": -89.17754197692871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 556.7478363513947, "episode_reward": 925.0903137124022, "step": 36000}
{"episode": 37.0, "batch_reward": 0.8888074083924293, "critic_loss": 0.505020110681653, "actor_loss": -89.25202264404297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.350165367126465, "episode_reward": 959.9241534095609, "step": 37000}
{"episode": 38.0, "batch_reward": 0.8934368924498558, "critic_loss": 0.4887410276532173, "actor_loss": -89.22156469726562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 557.8278360366821, "episode_reward": 978.4835279331536, "step": 38000}
{"episode": 39.0, "batch_reward": 0.8923094364404678, "critic_loss": 0.518384852513671, "actor_loss": -88.82168830871582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.470728874206543, "episode_reward": 928.6361609250813, "step": 39000}
{"episode": 40.0, "batch_reward": 0.8970485663414002, "critic_loss": 0.4845070386230946, "actor_loss": -88.85865835571289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 554.5971012115479, "episode_reward": 978.1877897442357, "step": 40000}
{"episode": 41.0, "batch_reward": 0.89507870221138, "critic_loss": 0.5101379545629025, "actor_loss": -88.94537129211426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.06178832054138, "episode_reward": 910.7269354322289, "step": 41000}
{"episode": 42.0, "batch_reward": 0.8976442003250122, "critic_loss": 0.46515114237368105, "actor_loss": -89.11607485961915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 541.0109515190125, "episode_reward": 965.897100665687, "step": 42000}
{"episode": 43.0, "batch_reward": 0.8968537339568138, "critic_loss": 0.5018884991705418, "actor_loss": -88.87208990478516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.404744386672974, "episode_reward": 893.5123363910698, "step": 43000}
{"episode": 44.0, "batch_reward": 0.8986629826426507, "critic_loss": 0.4488019907325506, "actor_loss": -88.44959130859375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 556.2985692024231, "episode_reward": 966.4881701931026, "step": 44000}
{"episode": 45.0, "batch_reward": 0.8987463304400444, "critic_loss": 0.458242525473237, "actor_loss": -88.0885559387207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.410151958465576, "episode_reward": 862.1146337738138, "step": 45000}
{"episode": 46.0, "batch_reward": 0.8985231091380119, "critic_loss": 0.4790597233623266, "actor_loss": -88.28205381774902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 554.7040641307831, "episode_reward": 885.6433561169371, "step": 46000}
{"episode": 47.0, "batch_reward": 0.9004034103155136, "critic_loss": 0.4771559995263815, "actor_loss": -87.8524533996582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.475544214248657, "episode_reward": 963.0699593119211, "step": 47000}
{"episode": 48.0, "batch_reward": 0.9007050707340241, "critic_loss": 0.4885500891059637, "actor_loss": -88.10009765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 555.1000547409058, "episode_reward": 941.3845604474988, "step": 48000}
{"episode": 49.0, "batch_reward": 0.901651256620884, "critic_loss": 0.5154216240644455, "actor_loss": -88.129740234375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.974915981292725, "episode_reward": 922.2409371127707, "step": 49000}
{"episode": 50.0, "batch_reward": 0.9011191594600677, "critic_loss": 0.4990806543678045, "actor_loss": -87.6101562652588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 554.3568420410156, "episode_reward": 986.9846727258085, "step": 50000}
{"episode": 51.0, "batch_reward": 0.9035340738296509, "critic_loss": 0.47342076219618323, "actor_loss": -88.21958624267577, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.379735231399536, "episode_reward": 980.9299309496959, "step": 51000}
{"episode": 52.0, "batch_reward": 0.9043597424626351, "critic_loss": 0.481766223102808, "actor_loss": -88.06370416259766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 554.1726803779602, "episode_reward": 962.1827538884999, "step": 52000}
{"episode": 53.0, "batch_reward": 0.905562290430069, "critic_loss": 0.47587469044327735, "actor_loss": -87.60478157043457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.884138584136963, "episode_reward": 960.2802894538847, "step": 53000}
{"episode": 54.0, "batch_reward": 0.9059431077241897, "critic_loss": 0.4944401247948408, "actor_loss": -87.91777243041992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 557.2903642654419, "episode_reward": 892.2598313827231, "step": 54000}
{"episode": 55.0, "batch_reward": 0.905678188085556, "critic_loss": 0.48333518898487093, "actor_loss": -87.581269241333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.467074155807495, "episode_reward": 946.3629545597149, "step": 55000}
{"episode": 56.0, "batch_reward": 0.9085524104237557, "critic_loss": 0.4569318051487207, "actor_loss": -87.6675528717041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 559.0904910564423, "episode_reward": 981.0246342865744, "step": 56000}
{"episode": 57.0, "batch_reward": 0.9078597965836525, "critic_loss": 0.4819292193800211, "actor_loss": -87.88529753112793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.23573589324951, "episode_reward": 925.1994220687171, "step": 57000}
{"episode": 58.0, "batch_reward": 0.9078112593889236, "critic_loss": 0.46058564837276933, "actor_loss": -87.4417197265625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 554.0066843032837, "episode_reward": 964.7936770779493, "step": 58000}
{"episode": 59.0, "batch_reward": 0.9092297735214233, "critic_loss": 0.47738225644826887, "actor_loss": -87.24221681213379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.55899691581726, "episode_reward": 912.4875524362903, "step": 59000}
{"episode": 60.0, "batch_reward": 0.9096532069444656, "critic_loss": 0.48112489615380766, "actor_loss": -87.67255613708497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 558.6927785873413, "episode_reward": 942.0781203412776, "step": 60000}
{"episode": 61.0, "batch_reward": 0.9095202470421792, "critic_loss": 0.5096952195465565, "actor_loss": -87.78790580749512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.55768966674805, "episode_reward": 953.2917366406408, "step": 61000}
{"episode": 62.0, "batch_reward": 0.9104184532165527, "critic_loss": 0.49519670590758325, "actor_loss": -87.37758595275879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 557.0943291187286, "episode_reward": 955.4004989225676, "step": 62000}
{"episode": 63.0, "batch_reward": 0.9103482061028481, "critic_loss": 0.49525207582116126, "actor_loss": -87.9167527923584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.440632104873657, "episode_reward": 919.2631523743772, "step": 63000}
{"episode": 64.0, "batch_reward": 0.9114236930608749, "critic_loss": 0.4875837972611189, "actor_loss": -87.75795274353027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 557.0322811603546, "episode_reward": 985.1324980486061, "step": 64000}
{"episode": 65.0, "batch_reward": 0.9122641645073891, "critic_loss": 0.49240822726488115, "actor_loss": -87.54223362731933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.375380277633667, "episode_reward": 983.7891514921959, "step": 65000}
{"episode": 66.0, "batch_reward": 0.9129287417531013, "critic_loss": 0.519017546504736, "actor_loss": -87.6819128112793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 557.7043435573578, "episode_reward": 926.7085699020456, "step": 66000}
{"episode": 67.0, "batch_reward": 0.9147291833758354, "critic_loss": 0.5131064742058515, "actor_loss": -87.4444679260254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.033432245254517, "episode_reward": 962.9593466751957, "step": 67000}
{"episode": 68.0, "batch_reward": 0.9161247875094414, "critic_loss": 0.5004890104085207, "actor_loss": -87.86950775146484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 554.1648879051208, "episode_reward": 958.4973424301213, "step": 68000}
{"episode": 69.0, "batch_reward": 0.9167900080680847, "critic_loss": 0.5213115373104811, "actor_loss": -87.48186277770996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.795771598815918, "episode_reward": 987.3616098493, "step": 69000}
{"episode": 70.0, "batch_reward": 0.915300441622734, "critic_loss": 0.5590241656750441, "actor_loss": -87.55934939575195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 557.9668838977814, "episode_reward": 922.6706268934335, "step": 70000}
{"episode": 71.0, "batch_reward": 0.9151577050685883, "critic_loss": 0.524792484074831, "actor_loss": -87.48612362670899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.52254605293274, "episode_reward": 867.9745935540922, "step": 71000}
{"episode": 72.0, "batch_reward": 0.9169908531308174, "critic_loss": 0.500587696403265, "actor_loss": -88.0259521484375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 558.9464638233185, "episode_reward": 977.7888778403653, "step": 72000}
{"episode": 73.0, "batch_reward": 0.9158609588146209, "critic_loss": 0.5377315320372581, "actor_loss": -87.50175885009766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.998403549194336, "episode_reward": 894.4341579011925, "step": 73000}
{"episode": 74.0, "batch_reward": 0.9153597993850708, "critic_loss": 0.5586948908120394, "actor_loss": -88.13981381225587, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 556.0586698055267, "episode_reward": 929.9928367217765, "step": 74000}
{"episode": 75.0, "batch_reward": 0.9169996345639229, "critic_loss": 0.5668005802184344, "actor_loss": -87.89535438537598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.436431169509888, "episode_reward": 965.0633760471723, "step": 75000}
{"episode": 76.0, "batch_reward": 0.9163382281064987, "critic_loss": 0.571070280790329, "actor_loss": -87.86470458984375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 557.0298290252686, "episode_reward": 884.0578479249062, "step": 76000}
{"episode": 77.0, "batch_reward": 0.9174316318631173, "critic_loss": 0.5366715411096812, "actor_loss": -87.71786692810059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.072181224822998, "episode_reward": 965.6422916623661, "step": 77000}
{"episode": 78.0, "batch_reward": 0.9185806235671043, "critic_loss": 0.5299436994194985, "actor_loss": -87.80849879455566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 555.5531649589539, "episode_reward": 961.8399654939585, "step": 78000}
{"episode": 79.0, "batch_reward": 0.9188212406039238, "critic_loss": 0.5334901506602764, "actor_loss": -87.5806909790039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.17680335044861, "episode_reward": 961.5883546715517, "step": 79000}
{"episode": 80.0, "batch_reward": 0.919265945494175, "critic_loss": 0.5412846898436546, "actor_loss": -88.19127603149414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 553.6351494789124, "episode_reward": 953.0581629551587, "step": 80000}
{"episode": 81.0, "batch_reward": 0.9188489251732826, "critic_loss": 0.518298586666584, "actor_loss": -88.06625369262696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.02350664138794, "episode_reward": 922.7370235202072, "step": 81000}
{"episode": 82.0, "batch_reward": 0.9193184757828713, "critic_loss": 0.5113570898771286, "actor_loss": -88.00884211730957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 555.4456496238708, "episode_reward": 960.4574873821201, "step": 82000}
{"episode": 83.0, "batch_reward": 0.9199417760968208, "critic_loss": 0.5506658398211003, "actor_loss": -88.18549867248535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.91312861442566, "episode_reward": 895.867215692723, "step": 83000}
{"episode": 84.0, "batch_reward": 0.9200993659496307, "critic_loss": 0.5353135211020708, "actor_loss": -88.02558963012696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 558.3629102706909, "episode_reward": 989.4204867304431, "step": 84000}
{"episode": 85.0, "batch_reward": 0.9190561398863792, "critic_loss": 0.5228781027495861, "actor_loss": -88.15690559387207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.992445468902588, "episode_reward": 949.6704337834667, "step": 85000}
{"episode": 86.0, "batch_reward": 0.9215014048814774, "critic_loss": 0.5209578646868467, "actor_loss": -88.13789302062989, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 556.9997968673706, "episode_reward": 926.6215243812851, "step": 86000}
{"episode": 87.0, "batch_reward": 0.9206939895749092, "critic_loss": 0.5010870537757873, "actor_loss": -88.55692172241211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.478429555892944, "episode_reward": 951.8716194960488, "step": 87000}
{"episode": 88.0, "batch_reward": 0.920663307249546, "critic_loss": 0.5425527778863907, "actor_loss": -88.15196986389161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 555.9138021469116, "episode_reward": 910.6542731737408, "step": 88000}
{"episode": 89.0, "batch_reward": 0.9206343402862549, "critic_loss": 0.5316752314120531, "actor_loss": -88.36401959228516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.19339346885681, "episode_reward": 972.0075225081747, "step": 89000}
{"episode": 90.0, "batch_reward": 0.9217402744889259, "critic_loss": 0.5114582226723432, "actor_loss": -88.67343499755859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 558.8116507530212, "episode_reward": 858.4200998163084, "step": 90000}
{"episode": 91.0, "batch_reward": 0.9224064123034478, "critic_loss": 0.493301038429141, "actor_loss": -88.29834034729004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.22604465484619, "episode_reward": 949.964364404032, "step": 91000}
{"episode": 92.0, "batch_reward": 0.9216909493803978, "critic_loss": 0.5149227715432644, "actor_loss": -88.73439436340333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 544.7527635097504, "episode_reward": 959.7335174902277, "step": 92000}
{"episode": 93.0, "batch_reward": 0.9220511551499366, "critic_loss": 0.5350008383393288, "actor_loss": -88.60733888244629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.41300368309021, "episode_reward": 986.0645349828712, "step": 93000}
{"episode": 94.0, "batch_reward": 0.921530194401741, "critic_loss": 0.5328901209831238, "actor_loss": -88.84085446166992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 553.9026019573212, "episode_reward": 880.8378516787942, "step": 94000}
{"episode": 95.0, "batch_reward": 0.9224325448274613, "critic_loss": 0.5563387628793717, "actor_loss": -88.40668724060059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.057475805282593, "episode_reward": 958.3724295986887, "step": 95000}
{"episode": 96.0, "batch_reward": 0.9219809747338295, "critic_loss": 0.5502401225566864, "actor_loss": -89.09501202392578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 558.3025586605072, "episode_reward": 861.6239441760498, "step": 96000}
{"episode": 97.0, "batch_reward": 0.9216289886832237, "critic_loss": 0.5916475717276335, "actor_loss": -88.66149246215821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.030634880065918, "episode_reward": 870.448190368234, "step": 97000}
{"episode": 98.0, "batch_reward": 0.9209091619253159, "critic_loss": 0.5857784281820059, "actor_loss": -88.63834432983398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 556.2123379707336, "episode_reward": 918.0391799007472, "step": 98000}
{"episode": 99.0, "batch_reward": 0.9208999163508416, "critic_loss": 0.5989624613523483, "actor_loss": -88.55882020568848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.033144235610962, "episode_reward": 925.0402660792321, "step": 99000}
{"episode": 100.0, "batch_reward": 0.9211321220397949, "critic_loss": 0.6169491716176272, "actor_loss": -89.15740618896484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 555.2639684677124, "episode_reward": 926.3038790738037, "step": 100000}
{"episode": 101.0, "batch_reward": 0.9210260843634606, "critic_loss": 0.5893368990570307, "actor_loss": -88.77186701965331, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.3611044883728, "episode_reward": 989.2427900711152, "step": 101000}
{"episode": 102.0, "batch_reward": 0.9219208447933197, "critic_loss": 0.589865555986762, "actor_loss": -88.7964810180664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 554.6917488574982, "episode_reward": 982.6400831653546, "step": 102000}
{"episode": 103.0, "batch_reward": 0.9211667875647545, "critic_loss": 0.5982490752786398, "actor_loss": -88.99360200500489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.12744140625, "episode_reward": 940.851803485079, "step": 103000}
{"episode": 104.0, "batch_reward": 0.9218419961929322, "critic_loss": 0.578661984115839, "actor_loss": -89.31584373474121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 553.6893172264099, "episode_reward": 958.4947455100402, "step": 104000}
{"episode": 105.0, "batch_reward": 0.9228686876893043, "critic_loss": 0.5716689693927764, "actor_loss": -89.13762254333496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.60016632080078, "episode_reward": 941.346218797835, "step": 105000}
{"episode": 106.0, "batch_reward": 0.9221969860196113, "critic_loss": 0.5942254758477211, "actor_loss": -89.25356195068359, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 555.8040499687195, "episode_reward": 887.5497031932377, "step": 106000}
{"episode": 107.0, "batch_reward": 0.9221637109518052, "critic_loss": 0.5688592784851789, "actor_loss": -89.1266505279541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.25679588317871, "episode_reward": 945.3864469405424, "step": 107000}
{"episode": 108.0, "batch_reward": 0.9229588359594345, "critic_loss": 0.5659346534758807, "actor_loss": -89.28701708984374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 557.8749961853027, "episode_reward": 904.9528264558852, "step": 108000}
{"episode": 109.0, "batch_reward": 0.9230552666783333, "critic_loss": 0.5851140219867229, "actor_loss": -89.59271186828613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.358768939971924, "episode_reward": 957.8302500373776, "step": 109000}
{"episode": 110.0, "batch_reward": 0.9236947876214981, "critic_loss": 0.5892124141603708, "actor_loss": -89.14294566345215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 559.4427285194397, "episode_reward": 929.9992654948537, "step": 110000}
{"episode": 111.0, "batch_reward": 0.922960810482502, "critic_loss": 0.5807944588959217, "actor_loss": -89.52593650817872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.56348776817322, "episode_reward": 935.4174790595712, "step": 111000}
{"episode": 112.0, "batch_reward": 0.9234596812129021, "critic_loss": 0.5844779611080885, "actor_loss": -89.33531986999512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 559.3963053226471, "episode_reward": 949.1573320399262, "step": 112000}
{"episode": 113.0, "batch_reward": 0.9227754164934159, "critic_loss": 0.5977218665182591, "actor_loss": -89.51245442199708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.544314861297607, "episode_reward": 898.3882368930483, "step": 113000}
{"episode": 114.0, "batch_reward": 0.9238956372737884, "critic_loss": 0.5936729542016983, "actor_loss": -89.56660029602051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 555.5121021270752, "episode_reward": 962.3454294837858, "step": 114000}
{"episode": 115.0, "batch_reward": 0.9231089211702347, "critic_loss": 0.5921450874060392, "actor_loss": -89.56355558776855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.542502880096436, "episode_reward": 955.8894990546768, "step": 115000}
{"episode": 116.0, "batch_reward": 0.9236043991446495, "critic_loss": 0.5783952601999044, "actor_loss": -89.83545379638672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 556.9115765094757, "episode_reward": 918.2587968771383, "step": 116000}
{"episode": 117.0, "batch_reward": 0.9230448143482208, "critic_loss": 0.5824205984771251, "actor_loss": -89.7179278717041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.666841983795166, "episode_reward": 870.5622456985757, "step": 117000}
{"episode": 118.0, "batch_reward": 0.9230859334468842, "critic_loss": 0.5925741882324219, "actor_loss": -89.5001171875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 553.7690932750702, "episode_reward": 986.705035528627, "step": 118000}
{"episode": 119.0, "batch_reward": 0.9228040071129799, "critic_loss": 0.5952819657176733, "actor_loss": -89.69171926879883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.114343404769897, "episode_reward": 920.6973087366997, "step": 119000}
{"episode": 120.0, "batch_reward": 0.9225567340254783, "critic_loss": 0.5828172564208508, "actor_loss": -89.79067364501954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 555.3726289272308, "episode_reward": 887.6430615159583, "step": 120000}
{"episode": 121.0, "batch_reward": 0.9240002621412278, "critic_loss": 0.5888394196033477, "actor_loss": -89.63981518554688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.748313665390015, "episode_reward": 980.7463527073938, "step": 121000}
{"episode": 122.0, "batch_reward": 0.9239307705163956, "critic_loss": 0.5908661951422691, "actor_loss": -89.81008201599121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 555.3084526062012, "episode_reward": 940.0024503869191, "step": 122000}
{"episode": 123.0, "batch_reward": 0.9247464609146118, "critic_loss": 0.5967760556489229, "actor_loss": -89.6839105834961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.86090350151062, "episode_reward": 939.1959465333612, "step": 123000}
{"episode": 124.0, "batch_reward": 0.9237701514959336, "critic_loss": 0.6095328838229179, "actor_loss": -89.7447274017334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 553.1552956104279, "episode_reward": 978.951728720095, "step": 124000}
{"episode": 125.0, "batch_reward": 0.9255678883194923, "critic_loss": 0.6068782377690077, "actor_loss": -90.06059941101074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.906989097595215, "episode_reward": 980.2644829464688, "step": 125000}
{"episode": 126.0, "batch_reward": 0.9272462671399117, "critic_loss": 0.591940945237875, "actor_loss": -90.16727714538574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 553.2283549308777, "episode_reward": 982.9353947507194, "step": 126000}
{"episode": 127.0, "batch_reward": 0.924486087679863, "critic_loss": 0.5779532981663942, "actor_loss": -89.81472300720215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.297274351119995, "episode_reward": 934.9668607582489, "step": 127000}
{"episode": 128.0, "batch_reward": 0.9264240377545356, "critic_loss": 0.5515411570072174, "actor_loss": -90.14812432861328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 553.4759571552277, "episode_reward": 962.0618306687463, "step": 128000}
{"episode": 129.0, "batch_reward": 0.92432307523489, "critic_loss": 0.5718868500888348, "actor_loss": -90.22068902587891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.617952823638916, "episode_reward": 980.2251330111336, "step": 129000}
{"episode": 130.0, "batch_reward": 0.9271065033078194, "critic_loss": 0.5649112049490214, "actor_loss": -90.13175988769531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 552.6238861083984, "episode_reward": 986.3187385845458, "step": 130000}
{"episode": 131.0, "batch_reward": 0.9278140618801117, "critic_loss": 0.5237209261655807, "actor_loss": -89.86048945617675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.31436276435852, "episode_reward": 975.6236665467611, "step": 131000}
{"episode": 132.0, "batch_reward": 0.9271371218562127, "critic_loss": 0.4911123576164246, "actor_loss": -90.21290065002441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 552.3135406970978, "episode_reward": 949.1251012757957, "step": 132000}
{"episode": 133.0, "batch_reward": 0.9272868730425835, "critic_loss": 0.5316342077702284, "actor_loss": -90.13034385681152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.386972427368164, "episode_reward": 960.0678194785975, "step": 133000}
{"episode": 134.0, "batch_reward": 0.927747913658619, "critic_loss": 0.5208740298300981, "actor_loss": -90.64072760009766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 557.8224880695343, "episode_reward": 966.6393990134655, "step": 134000}
{"episode": 135.0, "batch_reward": 0.927789577126503, "critic_loss": 0.5459257328957319, "actor_loss": -90.61314935302734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.956681489944458, "episode_reward": 991.7191958005025, "step": 135000}
{"episode": 136.0, "batch_reward": 0.9287262696027756, "critic_loss": 0.5239961258918047, "actor_loss": -90.3334892730713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 590.8490030765533, "episode_reward": 986.5285324504049, "step": 136000}
{"episode": 137.0, "batch_reward": 0.9284837077260018, "critic_loss": 0.49391092073917386, "actor_loss": -90.56037635803223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.428157091140747, "episode_reward": 978.764506260786, "step": 137000}
{"episode": 138.0, "batch_reward": 0.9296229643821716, "critic_loss": 0.4664190185889602, "actor_loss": -90.40423628234863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 564.4050004482269, "episode_reward": 951.710459711949, "step": 138000}
{"episode": 139.0, "batch_reward": 0.9295448954105378, "critic_loss": 0.4886276810020208, "actor_loss": -90.5863000793457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.639238119125366, "episode_reward": 962.0194157076963, "step": 139000}
{"episode": 140.0, "batch_reward": 0.9296475654244423, "critic_loss": 0.48280577608942987, "actor_loss": -90.54065664672852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 534.5525803565979, "episode_reward": 953.6382203672862, "step": 140000}
{"episode": 141.0, "batch_reward": 0.9294370288848877, "critic_loss": 0.5042397267073393, "actor_loss": -90.61249627685547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.78185248374939, "episode_reward": 967.8504484160206, "step": 141000}
{"episode": 142.0, "batch_reward": 0.9296286405324936, "critic_loss": 0.5103434575200081, "actor_loss": -90.84179710388183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 526.1616127490997, "episode_reward": 986.6985067425694, "step": 142000}
{"episode": 143.0, "batch_reward": 0.930743971824646, "critic_loss": 0.47902110914886, "actor_loss": -90.61675262451172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.619715690612793, "episode_reward": 948.7824209637471, "step": 143000}
{"episode": 144.0, "batch_reward": 0.929891811490059, "critic_loss": 0.4574137875288725, "actor_loss": -90.81630921936035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 531.9568562507629, "episode_reward": 959.710687164308, "step": 144000}
{"episode": 145.0, "batch_reward": 0.9317227699756623, "critic_loss": 0.4564004588648677, "actor_loss": -90.79764932250977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.156936645507812, "episode_reward": 986.7133109291753, "step": 145000}
{"episode": 146.0, "batch_reward": 0.9321652932167053, "critic_loss": 0.4809816449061036, "actor_loss": -90.55446264648438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 529.5477070808411, "episode_reward": 966.8187072357517, "step": 146000}
{"episode": 147.0, "batch_reward": 0.931007497727871, "critic_loss": 0.45678141550719736, "actor_loss": -90.92936073303223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.107959747314453, "episode_reward": 958.3559478858881, "step": 147000}
{"episode": 148.0, "batch_reward": 0.9311033383607864, "critic_loss": 0.45836973188817504, "actor_loss": -90.52603834533691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 530.2316219806671, "episode_reward": 985.9556350113636, "step": 148000}
{"episode": 149.0, "batch_reward": 0.9314375756978989, "critic_loss": 0.44573407018184663, "actor_loss": -90.86224826049805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.40802836418152, "episode_reward": 921.5616752148068, "step": 149000}
{"episode": 150.0, "batch_reward": 0.9313510660529136, "critic_loss": 0.4455443466156721, "actor_loss": -90.45179832458496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
