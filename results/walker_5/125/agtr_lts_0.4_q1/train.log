{"episode_reward": 0.0, "episode": 1.0, "duration": 21.02058744430542, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.9001514911651611, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.5038969838030937, "critic_loss": 0.9299075064081953, "actor_loss": -89.22468634975964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.30714416503906, "step": 3000}
{"episode_reward": 938.5596808937056, "episode": 4.0, "batch_reward": 0.6369528072178364, "critic_loss": 1.4119712511897087, "actor_loss": -94.06368113708496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.614396810531616, "step": 4000}
{"episode_reward": 449.1111748255557, "episode": 5.0, "batch_reward": 0.5569489651024342, "critic_loss": 1.7228501647114753, "actor_loss": -95.93818650817872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.715630531311035, "step": 5000}
{"episode_reward": 190.86519776455958, "episode": 6.0, "batch_reward": 0.5392492022514344, "critic_loss": 1.5381709718108176, "actor_loss": -95.51767074584961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990650177001953, "step": 6000}
{"episode_reward": 943.5945989541038, "episode": 7.0, "batch_reward": 0.5361873331964015, "critic_loss": 1.1527649546265601, "actor_loss": -94.97441896057128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.155097723007202, "step": 7000}
{"episode_reward": 29.20279376079806, "episode": 8.0, "batch_reward": 0.49705547180771825, "critic_loss": 1.2282643325328826, "actor_loss": -94.09995300292968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.171120166778564, "step": 8000}
{"episode_reward": 375.3292321677449, "episode": 9.0, "batch_reward": 0.4592886261343956, "critic_loss": 1.2053398833274842, "actor_loss": -91.69412663269043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.4668071269989, "step": 9000}
{"episode_reward": 51.409474916144674, "episode": 10.0, "batch_reward": 0.4185503072738647, "critic_loss": 1.0504620996713638, "actor_loss": -89.9211229095459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.335683822631836, "step": 10000}
{"episode_reward": 48.089546015770054, "episode": 11.0, "batch_reward": 0.38693715146183966, "critic_loss": 0.9048788730502129, "actor_loss": -88.09103254699707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.72519779205322, "step": 11000}
{"episode_reward": 70.42387490727087, "episode": 12.0, "batch_reward": 0.3515028800815344, "critic_loss": 0.7387337224185466, "actor_loss": -86.3119838104248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.45943784713745, "step": 12000}
{"episode_reward": 29.179366239783633, "episode": 13.0, "batch_reward": 0.3487057520747185, "critic_loss": 0.7223485746979713, "actor_loss": -85.13478807067871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.958298444747925, "step": 13000}
{"episode_reward": 752.9585327389095, "episode": 14.0, "batch_reward": 0.39221777188777923, "critic_loss": 0.6514587543010711, "actor_loss": -84.71913346862793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.501671075820923, "step": 14000}
{"episode_reward": 801.3430399493519, "episode": 15.0, "batch_reward": 0.42262490594387053, "critic_loss": 0.6065636900961399, "actor_loss": -83.96848205566407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.861283779144287, "step": 15000}
{"episode_reward": 942.2104426996648, "episode": 16.0, "batch_reward": 0.450568572729826, "critic_loss": 0.5779982772171497, "actor_loss": -83.4300690460205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.742501735687256, "step": 16000}
{"episode_reward": 765.2624765100035, "episode": 17.0, "batch_reward": 0.4680387831032276, "critic_loss": 0.9347193434536457, "actor_loss": -82.88615379333496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.533541679382324, "step": 17000}
{"episode_reward": 846.5435574721712, "episode": 18.0, "batch_reward": 0.4707840030193329, "critic_loss": 0.974515594124794, "actor_loss": -83.63413377380371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.872955560684204, "step": 18000}
{"episode_reward": 211.01602135392724, "episode": 19.0, "batch_reward": 0.47869023635983465, "critic_loss": 0.8213162990510464, "actor_loss": -83.12002403259277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.791768789291382, "step": 19000}
{"episode_reward": 964.274263640662, "episode": 20.0, "batch_reward": 0.5001493278443814, "critic_loss": 0.9005145608782769, "actor_loss": -83.15184466552735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.671022415161133, "step": 20000}
{"episode_reward": 959.6893168071806, "episode": 21.0, "batch_reward": 0.5243623063862324, "critic_loss": 0.939174980044365, "actor_loss": -84.1113013305664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.20144534111023, "step": 21000}
{"episode_reward": 819.871711373849, "episode": 22.0, "batch_reward": 0.5410335389673709, "critic_loss": 0.8676308216154576, "actor_loss": -84.03630718994141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.474277019500732, "step": 22000}
{"episode_reward": 951.758718296353, "episode": 23.0, "batch_reward": 0.5578825952410698, "critic_loss": 0.8553394932150841, "actor_loss": -84.096890335083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.795738697052002, "step": 23000}
{"episode_reward": 899.4099590018768, "episode": 24.0, "batch_reward": 0.5723632845282555, "critic_loss": 0.8264922439754009, "actor_loss": -84.63361906433106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.617892503738403, "step": 24000}
{"episode_reward": 969.6337929951843, "episode": 25.0, "batch_reward": 0.5848993290960789, "critic_loss": 0.890845714211464, "actor_loss": -84.3136582183838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8232421875, "step": 25000}
{"episode_reward": 852.4937891138048, "episode": 26.0, "batch_reward": 0.5988879725933075, "critic_loss": 0.7980052419304847, "actor_loss": -84.65925132751465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.113950490951538, "step": 26000}
{"episode_reward": 965.2543110027799, "episode": 27.0, "batch_reward": 0.6149140928983688, "critic_loss": 0.7891668764650822, "actor_loss": -85.23394229125977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.639182806015015, "step": 27000}
{"episode_reward": 983.8711953910522, "episode": 28.0, "batch_reward": 0.6242305098176002, "critic_loss": 0.766390450656414, "actor_loss": -85.18448645019531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.804790019989014, "step": 28000}
{"episode_reward": 892.8315737147528, "episode": 29.0, "batch_reward": 0.6337945185303688, "critic_loss": 0.7547896665036679, "actor_loss": -85.58230493164062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.67353844642639, "step": 29000}
{"episode_reward": 893.452671760597, "episode": 30.0, "batch_reward": 0.6440753340125084, "critic_loss": 0.8129801325500011, "actor_loss": -85.57854943847656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.400405168533325, "step": 30000}
{"episode_reward": 871.7369165662511, "episode": 31.0, "batch_reward": 0.6520797919034957, "critic_loss": 0.7521756729781628, "actor_loss": -85.6621975402832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.27612042427063, "step": 31000}
{"episode_reward": 961.1503590123398, "episode": 32.0, "batch_reward": 0.6641697356700897, "critic_loss": 0.7365364733934402, "actor_loss": -86.168630859375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.529541015625, "step": 32000}
{"episode_reward": 984.7994793066944, "episode": 33.0, "batch_reward": 0.6726189593672752, "critic_loss": 0.7445997848212719, "actor_loss": -86.22108070373535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23340392112732, "step": 33000}
{"episode_reward": 937.3270597829683, "episode": 34.0, "batch_reward": 0.6810177894234657, "critic_loss": 0.7591227383315563, "actor_loss": -85.71268312072753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.737797737121582, "step": 34000}
{"episode_reward": 981.267880050104, "episode": 35.0, "batch_reward": 0.6885516293644905, "critic_loss": 0.8071169613897801, "actor_loss": -86.38618173217773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.825082302093506, "step": 35000}
{"episode_reward": 938.40772889133, "episode": 36.0, "batch_reward": 0.6932300953865052, "critic_loss": 0.7974761979877949, "actor_loss": -86.40340560913086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.439820051193237, "step": 36000}
{"episode_reward": 909.7539649358594, "episode": 37.0, "batch_reward": 0.692090727031231, "critic_loss": 0.7545087398588657, "actor_loss": -86.28065490722656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.96212387084961, "step": 37000}
{"episode_reward": 597.8641525284054, "episode": 38.0, "batch_reward": 0.7001853814721107, "critic_loss": 0.7034429658651352, "actor_loss": -86.56122238159179, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.574062824249268, "step": 38000}
{"episode_reward": 983.7359737658104, "episode": 39.0, "batch_reward": 0.7056128979325295, "critic_loss": 0.6703754518032073, "actor_loss": -87.18085334777832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.846585512161255, "step": 39000}
{"episode_reward": 949.2265733085561, "episode": 40.0, "batch_reward": 0.7129572269916534, "critic_loss": 0.6768759132921696, "actor_loss": -87.20796040344239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.714387893676758, "step": 40000}
{"episode_reward": 987.3678163094265, "episode": 41.0, "batch_reward": 0.7166625998020172, "critic_loss": 0.6242964175343514, "actor_loss": -87.37405242919922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.66998028755188, "step": 41000}
{"episode_reward": 922.8352965987178, "episode": 42.0, "batch_reward": 0.7259633049368859, "critic_loss": 0.5887895675301552, "actor_loss": -87.7086589050293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.8346004486084, "step": 42000}
{"episode_reward": 953.0523455087381, "episode": 43.0, "batch_reward": 0.7280960634946824, "critic_loss": 0.5677387166172266, "actor_loss": -87.85355151367187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.48116898536682, "step": 43000}
{"episode_reward": 921.589644147579, "episode": 44.0, "batch_reward": 0.7343190543651581, "critic_loss": 0.5348727847337723, "actor_loss": -87.88467259216308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.880184412002563, "step": 44000}
{"episode_reward": 981.2208064239713, "episode": 45.0, "batch_reward": 0.7383886274695396, "critic_loss": 0.530802442252636, "actor_loss": -88.4024833831787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.525708436965942, "step": 45000}
{"episode_reward": 940.8889609039492, "episode": 46.0, "batch_reward": 0.7421375978589058, "critic_loss": 0.5336452157497406, "actor_loss": -88.50754986572265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.918131351470947, "step": 46000}
{"episode_reward": 936.0681723600334, "episode": 47.0, "batch_reward": 0.7499713096618652, "critic_loss": 0.5356471301913261, "actor_loss": -88.6910899963379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17302393913269, "step": 47000}
{"episode_reward": 966.2184008109865, "episode": 48.0, "batch_reward": 0.7497063544988632, "critic_loss": 0.5510750632584095, "actor_loss": -88.7581633758545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0063054561615, "step": 48000}
{"episode_reward": 868.7430951053788, "episode": 49.0, "batch_reward": 0.7547831043601037, "critic_loss": 0.5577831055819988, "actor_loss": -89.04578547668457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.492698192596436, "step": 49000}
{"episode_reward": 944.8769558232456, "episode": 50.0, "batch_reward": 0.7579135082364082, "critic_loss": 0.537548972159624, "actor_loss": -89.09328916931152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.76923179626465, "step": 50000}
{"episode_reward": 986.9066985869689, "episode": 51.0, "batch_reward": 0.7637844910025596, "critic_loss": 0.5328600893169642, "actor_loss": -88.97796757507324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.78717565536499, "step": 51000}
{"episode_reward": 985.9183424478397, "episode": 52.0, "batch_reward": 0.7674825926423072, "critic_loss": 0.5265903112590313, "actor_loss": -89.53089256286621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.66020917892456, "step": 52000}
{"episode_reward": 966.1610258990243, "episode": 53.0, "batch_reward": 0.7717251667380333, "critic_loss": 0.5138629991859197, "actor_loss": -89.6359488067627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.74319076538086, "step": 53000}
{"episode_reward": 911.8707279475658, "episode": 54.0, "batch_reward": 0.7730547297000885, "critic_loss": 0.5247251833230258, "actor_loss": -89.58672105407715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.71883487701416, "step": 54000}
{"episode_reward": 916.7982747105201, "episode": 55.0, "batch_reward": 0.7774029196500778, "critic_loss": 0.495263903170824, "actor_loss": -89.48408320617676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.520397424697876, "step": 55000}
{"episode_reward": 978.6763350811361, "episode": 56.0, "batch_reward": 0.7824562145471573, "critic_loss": 0.49785051798820495, "actor_loss": -89.7730876159668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.810567617416382, "step": 56000}
{"episode_reward": 981.7704899834731, "episode": 57.0, "batch_reward": 0.7851329819560051, "critic_loss": 0.46840244449675084, "actor_loss": -89.83554151916503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.622703790664673, "step": 57000}
{"episode_reward": 962.6111136352976, "episode": 58.0, "batch_reward": 0.7877847718596458, "critic_loss": 0.4779297349452972, "actor_loss": -89.65485220336915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.907809019088745, "step": 58000}
{"episode_reward": 984.9424411941561, "episode": 59.0, "batch_reward": 0.79175517141819, "critic_loss": 0.5350881684273482, "actor_loss": -90.01129977416993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.406671285629272, "step": 59000}
{"episode_reward": 904.8213577741444, "episode": 60.0, "batch_reward": 0.7925500794649124, "critic_loss": 0.5317909425646067, "actor_loss": -90.19120359802245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.006437301635742, "step": 60000}
{"episode_reward": 936.6864244606294, "episode": 61.0, "batch_reward": 0.7945197793245315, "critic_loss": 0.5092141532748937, "actor_loss": -90.06136236572266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.64167046546936, "step": 61000}
{"episode_reward": 952.7532690715161, "episode": 62.0, "batch_reward": 0.7967364050149918, "critic_loss": 0.5209144360423088, "actor_loss": -90.1191474456787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.701424837112427, "step": 62000}
{"episode_reward": 964.9035649993739, "episode": 63.0, "batch_reward": 0.7979843306541443, "critic_loss": 0.5023711646646262, "actor_loss": -90.25919625854492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.679771423339844, "step": 63000}
{"episode_reward": 943.2633071502665, "episode": 64.0, "batch_reward": 0.800962730050087, "critic_loss": 0.4935633761435747, "actor_loss": -90.52974116516113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.922810792922974, "step": 64000}
{"episode_reward": 982.7969562179806, "episode": 65.0, "batch_reward": 0.8059536263346672, "critic_loss": 0.4901970685124397, "actor_loss": -90.76486016845703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.423551559448242, "step": 65000}
{"episode_reward": 976.9455167328705, "episode": 66.0, "batch_reward": 0.8076842365264892, "critic_loss": 0.45568996050953864, "actor_loss": -90.87726649475097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.928370714187622, "step": 66000}
{"episode_reward": 949.4657957151667, "episode": 67.0, "batch_reward": 0.8084395743012428, "critic_loss": 0.45144392909109593, "actor_loss": -91.02495530700683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.466251373291016, "step": 67000}
{"episode_reward": 935.6167851421023, "episode": 68.0, "batch_reward": 0.8107085518836975, "critic_loss": 0.44497182646393774, "actor_loss": -90.8383957824707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.872031450271606, "step": 68000}
{"episode_reward": 960.1808086834902, "episode": 69.0, "batch_reward": 0.8126734691858292, "critic_loss": 0.4322385211735964, "actor_loss": -91.11646310424804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.451274633407593, "step": 69000}
{"episode_reward": 986.8548558188525, "episode": 70.0, "batch_reward": 0.8146253158450126, "critic_loss": 0.4238644239604473, "actor_loss": -91.25244897460938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.850866317749023, "step": 70000}
{"episode_reward": 938.4060056270404, "episode": 71.0, "batch_reward": 0.8177974662780761, "critic_loss": 0.42867859137058256, "actor_loss": -91.24317401123047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.220773458480835, "step": 71000}
{"episode_reward": 938.8224122533362, "episode": 72.0, "batch_reward": 0.8201015183329582, "critic_loss": 0.4274449874162674, "actor_loss": -91.4257926940918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.570815801620483, "step": 72000}
{"episode_reward": 963.3445354038626, "episode": 73.0, "batch_reward": 0.8209730423092843, "critic_loss": 0.4216728702783585, "actor_loss": -91.61271403503417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.930924892425537, "step": 73000}
{"episode_reward": 927.2006724043015, "episode": 74.0, "batch_reward": 0.8242466385364533, "critic_loss": 0.4165164663046598, "actor_loss": -91.83007669067383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37662172317505, "step": 74000}
{"episode_reward": 929.0888905882096, "episode": 75.0, "batch_reward": 0.823180594086647, "critic_loss": 0.41569067841768265, "actor_loss": -91.82584112548828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.025530099868774, "step": 75000}
{"episode_reward": 963.7614266631432, "episode": 76.0, "batch_reward": 0.8252808015346527, "critic_loss": 0.4008684034049511, "actor_loss": -91.82182427978516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.556354761123657, "step": 76000}
{"episode_reward": 952.0033905075601, "episode": 77.0, "batch_reward": 0.8277516217231751, "critic_loss": 0.4234968222230673, "actor_loss": -91.89333245849609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.934311151504517, "step": 77000}
{"episode_reward": 933.3050031287542, "episode": 78.0, "batch_reward": 0.829388888835907, "critic_loss": 0.42112075893580914, "actor_loss": -92.06459379577636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.639235496520996, "step": 78000}
{"episode_reward": 955.2491658996119, "episode": 79.0, "batch_reward": 0.8302045538425445, "critic_loss": 0.3948688538521528, "actor_loss": -92.10491822814942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.72031879425049, "step": 79000}
{"episode_reward": 961.011521992689, "episode": 80.0, "batch_reward": 0.8319346399307251, "critic_loss": 0.38463467280566693, "actor_loss": -92.10426182556152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.035819053649902, "step": 80000}
{"episode_reward": 986.6760636436157, "episode": 81.0, "batch_reward": 0.8334842423200607, "critic_loss": 0.4157218032479286, "actor_loss": -92.358638381958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.48229432106018, "step": 81000}
{"episode_reward": 916.8734250097076, "episode": 82.0, "batch_reward": 0.8357322471141815, "critic_loss": 0.39191456206142905, "actor_loss": -92.37352503967286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37193512916565, "step": 82000}
{"episode_reward": 938.26067733619, "episode": 83.0, "batch_reward": 0.8371576352715492, "critic_loss": 0.3816110415011644, "actor_loss": -92.38618667602539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.123805284500122, "step": 83000}
{"episode_reward": 930.027285016432, "episode": 84.0, "batch_reward": 0.8387203207612037, "critic_loss": 0.3643974283784628, "actor_loss": -92.43946530151368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.657474756240845, "step": 84000}
{"episode_reward": 985.8876876039252, "episode": 85.0, "batch_reward": 0.8367742593288422, "critic_loss": 0.4009453969150782, "actor_loss": -92.36066156005859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.438425302505493, "step": 85000}
{"episode_reward": 917.8651171372695, "episode": 86.0, "batch_reward": 0.8391768561601639, "critic_loss": 0.4394843686670065, "actor_loss": -92.37483915710449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.259784936904907, "step": 86000}
{"episode_reward": 826.1912162859512, "episode": 87.0, "batch_reward": 0.8400218014121056, "critic_loss": 0.41501831366121766, "actor_loss": -92.32903164672851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.686969757080078, "step": 87000}
{"episode_reward": 959.1668789305816, "episode": 88.0, "batch_reward": 0.8427900469303131, "critic_loss": 0.4386620362251997, "actor_loss": -92.37859391784669, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.79629874229431, "step": 88000}
{"episode_reward": 923.1820407753697, "episode": 89.0, "batch_reward": 0.8417834202051163, "critic_loss": 0.45181484131515026, "actor_loss": -92.34925267028808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.506620168685913, "step": 89000}
{"episode_reward": 967.1075101272229, "episode": 90.0, "batch_reward": 0.845022362112999, "critic_loss": 0.42906873659789563, "actor_loss": -92.44681460571289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.480613708496094, "step": 90000}
{"episode_reward": 961.0567128385176, "episode": 91.0, "batch_reward": 0.8457262839078903, "critic_loss": 0.4134771989583969, "actor_loss": -92.34928169250489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.18136143684387, "step": 91000}
{"episode_reward": 937.6350289648622, "episode": 92.0, "batch_reward": 0.8483380417823791, "critic_loss": 0.41920570746064184, "actor_loss": -92.51518515014648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.86259913444519, "step": 92000}
{"episode_reward": 963.0341575714206, "episode": 93.0, "batch_reward": 0.8463219808936119, "critic_loss": 0.4599837819635868, "actor_loss": -92.30545658874512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3523428440094, "step": 93000}
{"episode_reward": 985.597455799481, "episode": 94.0, "batch_reward": 0.8489074763059616, "critic_loss": 0.45063222795724867, "actor_loss": -92.4710683441162, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0709331035614, "step": 94000}
{"episode_reward": 958.6771262747496, "episode": 95.0, "batch_reward": 0.8506016182303429, "critic_loss": 0.44952001418173315, "actor_loss": -92.57020629882813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23692536354065, "step": 95000}
{"episode_reward": 933.9439416106709, "episode": 96.0, "batch_reward": 0.8505448291301727, "critic_loss": 0.43515487532317637, "actor_loss": -92.58896020507812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00952935218811, "step": 96000}
{"episode_reward": 962.619392776258, "episode": 97.0, "batch_reward": 0.851117470741272, "critic_loss": 0.4274273856431246, "actor_loss": -92.6856932220459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.5235435962677, "step": 97000}
{"episode_reward": 925.5137249763524, "episode": 98.0, "batch_reward": 0.8526280701160431, "critic_loss": 0.43471764741837976, "actor_loss": -92.68005838012695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.884209394454956, "step": 98000}
{"episode_reward": 949.6026317235301, "episode": 99.0, "batch_reward": 0.8540658718943596, "critic_loss": 0.42566440819203855, "actor_loss": -92.71614991760254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.463682651519775, "step": 99000}
{"episode_reward": 980.8018290075956, "episode": 100.0, "batch_reward": 0.8564479147195816, "critic_loss": 0.43058910508453846, "actor_loss": -92.78940324401856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.943294525146484, "step": 100000}
{"episode_reward": 941.4771443898043, "episode": 101.0, "batch_reward": 0.8570357986092567, "critic_loss": 0.43857054197788237, "actor_loss": -92.99956326293945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.15479493141174, "step": 101000}
{"episode_reward": 980.2157512574283, "episode": 102.0, "batch_reward": 0.8563090324997902, "critic_loss": 0.41704824644327165, "actor_loss": -93.01548953247071, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.293048858642578, "step": 102000}
{"episode_reward": 972.6012242216015, "episode": 103.0, "batch_reward": 0.8581589183807373, "critic_loss": 0.4076520579010248, "actor_loss": -93.03371179199219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20218539237976, "step": 103000}
{"episode_reward": 962.7735991331361, "episode": 104.0, "batch_reward": 0.8605855241417885, "critic_loss": 0.39483224850893023, "actor_loss": -93.12957818603516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.333860874176025, "step": 104000}
{"episode_reward": 955.8054351213427, "episode": 105.0, "batch_reward": 0.8617019526362419, "critic_loss": 0.3887771054506302, "actor_loss": -93.09264923095704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.73338508605957, "step": 105000}
{"episode_reward": 941.058648821307, "episode": 106.0, "batch_reward": 0.8615564830303192, "critic_loss": 0.3860631742179394, "actor_loss": -93.0348796081543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.85917019844055, "step": 106000}
{"episode_reward": 903.2069631801124, "episode": 107.0, "batch_reward": 0.860497048676014, "critic_loss": 0.3938232780843973, "actor_loss": -93.10994807434082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.46669840812683, "step": 107000}
{"episode_reward": 961.4448213072948, "episode": 108.0, "batch_reward": 0.8634540858268738, "critic_loss": 0.37120688539743424, "actor_loss": -93.31410688781739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.13198232650757, "step": 108000}
{"episode_reward": 943.6074956373583, "episode": 109.0, "batch_reward": 0.8622757522463799, "critic_loss": 0.36703822830319405, "actor_loss": -93.26750035095215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.801937341690063, "step": 109000}
{"episode_reward": 975.8637207683666, "episode": 110.0, "batch_reward": 0.8639194289445877, "critic_loss": 0.36650299801677466, "actor_loss": -93.31119097900391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.423455715179443, "step": 110000}
{"episode_reward": 912.0923817733217, "episode": 111.0, "batch_reward": 0.8634678195714951, "critic_loss": 0.387330921664834, "actor_loss": -93.29432252502441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.01840853691101, "step": 111000}
{"episode_reward": 930.5734371661473, "episode": 112.0, "batch_reward": 0.8654318441748619, "critic_loss": 0.38135141782462595, "actor_loss": -93.34110481262206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.116719722747803, "step": 112000}
{"episode_reward": 953.3000098809828, "episode": 113.0, "batch_reward": 0.8663465486168861, "critic_loss": 0.38693613174557684, "actor_loss": -93.38057977294922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3325138092041, "step": 113000}
{"episode_reward": 959.8914262430433, "episode": 114.0, "batch_reward": 0.8671913420557976, "critic_loss": 0.39572261603176595, "actor_loss": -93.4324748840332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.32220697402954, "step": 114000}
{"episode_reward": 980.7791786129865, "episode": 115.0, "batch_reward": 0.8671352733969688, "critic_loss": 0.37996397986263036, "actor_loss": -93.42336416625976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1458740234375, "step": 115000}
{"episode_reward": 953.8487564380828, "episode": 116.0, "batch_reward": 0.8695132768750191, "critic_loss": 0.36695438823103904, "actor_loss": -93.66269039916992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.568524837493896, "step": 116000}
{"episode_reward": 962.0204273383881, "episode": 117.0, "batch_reward": 0.8688222505450248, "critic_loss": 0.369718406111002, "actor_loss": -93.53675410461426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.80993390083313, "step": 117000}
{"episode_reward": 912.2122765268128, "episode": 118.0, "batch_reward": 0.8691548078656196, "critic_loss": 0.3693725504502654, "actor_loss": -93.66268113708496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.562360763549805, "step": 118000}
{"episode_reward": 985.1956254952403, "episode": 119.0, "batch_reward": 0.8715939691662788, "critic_loss": 0.3627031280696392, "actor_loss": -93.64484231567383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.170368194580078, "step": 119000}
{"episode_reward": 943.0106955867035, "episode": 120.0, "batch_reward": 0.8693868569731712, "critic_loss": 0.37954939928650855, "actor_loss": -93.48207861328125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.059282302856445, "step": 120000}
{"episode_reward": 956.0323092498701, "episode": 121.0, "batch_reward": 0.8720014198422432, "critic_loss": 0.37102227368205787, "actor_loss": -93.7222765045166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.52581238746643, "step": 121000}
{"episode_reward": 978.9902907261668, "episode": 122.0, "batch_reward": 0.8730068373680114, "critic_loss": 0.35437778348475696, "actor_loss": -93.84206387329101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.469157457351685, "step": 122000}
{"episode_reward": 945.6868532200808, "episode": 123.0, "batch_reward": 0.8744376646876335, "critic_loss": 0.36057873502373694, "actor_loss": -93.84179031372071, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.982380390167236, "step": 123000}
{"episode_reward": 944.797315993739, "episode": 124.0, "batch_reward": 0.8744514617323875, "critic_loss": 0.34640435920655727, "actor_loss": -93.87779969787597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.64412546157837, "step": 124000}
{"episode_reward": 986.7914268314473, "episode": 125.0, "batch_reward": 0.8756293192505836, "critic_loss": 0.33281555307656524, "actor_loss": -93.8804539489746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.55848217010498, "step": 125000}
{"episode_reward": 986.5278597598676, "episode": 126.0, "batch_reward": 0.8755815174579621, "critic_loss": 0.33324161686003206, "actor_loss": -94.04713023376465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.64586615562439, "step": 126000}
{"episode_reward": 990.5039226825256, "episode": 127.0, "batch_reward": 0.8764184905886651, "critic_loss": 0.34274003917723894, "actor_loss": -94.04950024414063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.813470125198364, "step": 127000}
{"episode_reward": 920.1608208079705, "episode": 128.0, "batch_reward": 0.8764263513088226, "critic_loss": 0.35481475068628787, "actor_loss": -94.09359934997559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10153317451477, "step": 128000}
{"episode_reward": 921.2404165214092, "episode": 129.0, "batch_reward": 0.8778512066006661, "critic_loss": 0.3466285793781281, "actor_loss": -94.16250733947754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.405882835388184, "step": 129000}
{"episode_reward": 983.7367788874946, "episode": 130.0, "batch_reward": 0.8796525017619133, "critic_loss": 0.36017150327563285, "actor_loss": -94.13631878662109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.97872281074524, "step": 130000}
{"episode_reward": 989.0952381675322, "episode": 131.0, "batch_reward": 0.8806735236048698, "critic_loss": 0.35911051342636346, "actor_loss": -94.12405081176757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.95754098892212, "step": 131000}
{"episode_reward": 954.114187349047, "episode": 132.0, "batch_reward": 0.8802937979102134, "critic_loss": 0.36239826963841915, "actor_loss": -94.08200546264648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.317416667938232, "step": 132000}
{"episode_reward": 926.6954735175855, "episode": 133.0, "batch_reward": 0.8789046576023102, "critic_loss": 0.34959116857498884, "actor_loss": -94.20569885253906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.001346111297607, "step": 133000}
{"episode_reward": 962.2649925876032, "episode": 134.0, "batch_reward": 0.8797716348171234, "critic_loss": 0.36005417853593824, "actor_loss": -94.2839573059082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.449331760406494, "step": 134000}
{"episode_reward": 948.951900781132, "episode": 135.0, "batch_reward": 0.8821559913158417, "critic_loss": 0.37684809213131665, "actor_loss": -94.29379975891113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.86787176132202, "step": 135000}
{"episode_reward": 992.8103181909959, "episode": 136.0, "batch_reward": 0.8833103893995286, "critic_loss": 0.3891428878903389, "actor_loss": -94.32181127929688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.477986812591553, "step": 136000}
{"episode_reward": 987.9402797874766, "episode": 137.0, "batch_reward": 0.8823524938821793, "critic_loss": 0.3742804017066956, "actor_loss": -94.2490848236084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00140929222107, "step": 137000}
{"episode_reward": 979.1990307612239, "episode": 138.0, "batch_reward": 0.8834492676854133, "critic_loss": 0.3527463098540902, "actor_loss": -94.290130859375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.99496102333069, "step": 138000}
{"episode_reward": 952.7257814685689, "episode": 139.0, "batch_reward": 0.8830056628584861, "critic_loss": 0.3575923301354051, "actor_loss": -94.27915811157227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.531696557998657, "step": 139000}
{"episode_reward": 985.301589324855, "episode": 140.0, "batch_reward": 0.8838144236207008, "critic_loss": 0.33823428402096034, "actor_loss": -94.33714401245118, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.786026000976562, "step": 140000}
{"episode_reward": 935.884663562095, "episode": 141.0, "batch_reward": 0.8853121634125709, "critic_loss": 0.35946943564713, "actor_loss": -94.347900390625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.37414836883545, "step": 141000}
{"episode_reward": 965.4281332364261, "episode": 142.0, "batch_reward": 0.8848774202466011, "critic_loss": 0.3530055517554283, "actor_loss": -94.3233771057129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.775845766067505, "step": 142000}
{"episode_reward": 988.332548218986, "episode": 143.0, "batch_reward": 0.8861876343488693, "critic_loss": 0.3546962900236249, "actor_loss": -94.4280670928955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.560877084732056, "step": 143000}
{"episode_reward": 946.1981940729141, "episode": 144.0, "batch_reward": 0.8866044392585755, "critic_loss": 0.3520751905441284, "actor_loss": -94.50346354675293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.169203996658325, "step": 144000}
{"episode_reward": 961.825579779506, "episode": 145.0, "batch_reward": 0.888939415037632, "critic_loss": 0.33675439201295376, "actor_loss": -94.56379299926758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.330238819122314, "step": 145000}
{"episode_reward": 980.4729874815098, "episode": 146.0, "batch_reward": 0.8868403911590577, "critic_loss": 0.33666447810828687, "actor_loss": -94.5219615020752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.171488761901855, "step": 146000}
{"episode_reward": 965.456534307566, "episode": 147.0, "batch_reward": 0.8876114881634712, "critic_loss": 0.33570914904773236, "actor_loss": -94.58022732543945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.568923234939575, "step": 147000}
{"episode_reward": 942.0884041724497, "episode": 148.0, "batch_reward": 0.8894773828983307, "critic_loss": 0.32104659876972436, "actor_loss": -94.64638102722168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.246840238571167, "step": 148000}
{"episode_reward": 989.3104184679635, "episode": 149.0, "batch_reward": 0.8889215179085731, "critic_loss": 0.3202810368016362, "actor_loss": -94.64702716064453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.226250648498535, "step": 149000}
{"episode_reward": 947.3884400567601, "episode": 150.0, "batch_reward": 0.8896093680858612, "critic_loss": 0.34408313869684937, "actor_loss": -94.69308374023437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
