{"episode_reward": 0.0, "episode": 1.0, "duration": 20.998746156692505, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.8277080059051514, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.454509816017895, "critic_loss": 0.14685323747901588, "actor_loss": -37.02227585514163, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 61.065404653549194, "step": 3000}
{"episode_reward": 81.10692517463862, "episode": 4.0, "batch_reward": 0.30578536696732045, "critic_loss": 0.22869193648546934, "actor_loss": -41.68937331867218, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.331008434295654, "step": 4000}
{"episode_reward": 56.63478995450962, "episode": 5.0, "batch_reward": 0.280802527859807, "critic_loss": 0.4675505269318819, "actor_loss": -35.801845361709596, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.309289932250977, "step": 5000}
{"episode_reward": 301.3648885522571, "episode": 6.0, "batch_reward": 0.2811729808449745, "critic_loss": 0.7170304261744023, "actor_loss": -40.28090203666687, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.398298978805542, "step": 6000}
{"episode_reward": 232.7449992392263, "episode": 7.0, "batch_reward": 0.268281979650259, "critic_loss": 1.0776914759278298, "actor_loss": -42.43943688583374, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.33477544784546, "step": 7000}
{"episode_reward": 222.77659003489305, "episode": 8.0, "batch_reward": 0.2713505510538817, "critic_loss": 1.3739386240243912, "actor_loss": -42.99698050308228, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.340545177459717, "step": 8000}
{"episode_reward": 361.73774177994335, "episode": 9.0, "batch_reward": 0.27760530833899977, "critic_loss": 1.5478925879001617, "actor_loss": -47.6229857711792, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.374407529830933, "step": 9000}
{"episode_reward": 356.01135564318383, "episode": 10.0, "batch_reward": 0.3055651310682297, "critic_loss": 1.9372110397815705, "actor_loss": -47.928913330078124, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.328479051589966, "step": 10000}
{"episode_reward": 724.2655168734111, "episode": 11.0, "batch_reward": 0.35048264545202257, "critic_loss": 1.7933822388648988, "actor_loss": -50.742374687194825, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.1568648815155, "step": 11000}
{"episode_reward": 854.2475750738139, "episode": 12.0, "batch_reward": 0.39385158029198647, "critic_loss": 1.9338558105826378, "actor_loss": -53.88963969802857, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.345382928848267, "step": 12000}
{"episode_reward": 765.0005034864204, "episode": 13.0, "batch_reward": 0.4257259371578693, "critic_loss": 1.7543564622998238, "actor_loss": -56.41425044250488, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.377966165542603, "step": 13000}
{"episode_reward": 883.6838417905886, "episode": 14.0, "batch_reward": 0.46035794442892075, "critic_loss": 1.6271729759573936, "actor_loss": -56.31976709747315, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.3730947971344, "step": 14000}
{"episode_reward": 915.7402735572565, "episode": 15.0, "batch_reward": 0.492538843780756, "critic_loss": 1.6373427146673203, "actor_loss": -61.427412956237795, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.319737434387207, "step": 15000}
{"episode_reward": 797.5251697571259, "episode": 16.0, "batch_reward": 0.5064502362310886, "critic_loss": 1.9180099277496339, "actor_loss": -63.11844274139404, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.358969688415527, "step": 16000}
{"episode_reward": 804.9536732563818, "episode": 17.0, "batch_reward": 0.5192693317234516, "critic_loss": 1.7726198389530181, "actor_loss": -62.80686262512207, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.39957070350647, "step": 17000}
{"episode_reward": 696.6955758633891, "episode": 18.0, "batch_reward": 0.540215969145298, "critic_loss": 1.6972968710064888, "actor_loss": -64.74885945129394, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.335294485092163, "step": 18000}
{"episode_reward": 848.4542322927377, "episode": 19.0, "batch_reward": 0.5536781996786594, "critic_loss": 1.7543710714578629, "actor_loss": -67.19266641235352, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.357994079589844, "step": 19000}
{"episode_reward": 824.5846303091655, "episode": 20.0, "batch_reward": 0.572196773827076, "critic_loss": 1.51344894438982, "actor_loss": -68.82551533508301, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.3686420917511, "step": 20000}
{"episode_reward": 963.3375756124277, "episode": 21.0, "batch_reward": 0.5895690031349659, "critic_loss": 1.4732841922044755, "actor_loss": -70.2168599472046, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.14498281478882, "step": 21000}
{"episode_reward": 956.2166273096178, "episode": 22.0, "batch_reward": 0.6112620064616203, "critic_loss": 1.4313373384475707, "actor_loss": -70.97410350036621, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.373881578445435, "step": 22000}
{"episode_reward": 982.7852413283779, "episode": 23.0, "batch_reward": 0.6240749149918556, "critic_loss": 1.5154344084262847, "actor_loss": -70.85308235931396, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35301113128662, "step": 23000}
{"episode_reward": 893.8954166301235, "episode": 24.0, "batch_reward": 0.6311252474188804, "critic_loss": 1.5850483507514, "actor_loss": -72.86232619476318, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.3584463596344, "step": 24000}
{"episode_reward": 848.5854779964268, "episode": 25.0, "batch_reward": 0.6430121192336082, "critic_loss": 1.6713833497166635, "actor_loss": -72.84923860931397, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.387763738632202, "step": 25000}
{"episode_reward": 842.934097673197, "episode": 26.0, "batch_reward": 0.6497725076675415, "critic_loss": 1.728306277990341, "actor_loss": -74.15515809631347, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.34523320198059, "step": 26000}
{"episode_reward": 963.4916972395943, "episode": 27.0, "batch_reward": 0.6655299973487854, "critic_loss": 1.569891327917576, "actor_loss": -75.277056640625, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.334588527679443, "step": 27000}
{"episode_reward": 961.2510374895832, "episode": 28.0, "batch_reward": 0.6750106736421585, "critic_loss": 1.5313229153752328, "actor_loss": -75.84946899414062, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.37033200263977, "step": 28000}
{"episode_reward": 948.0937870087107, "episode": 29.0, "batch_reward": 0.6841725303530694, "critic_loss": 1.3489923470020295, "actor_loss": -77.28476588439942, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.31654930114746, "step": 29000}
{"episode_reward": 919.052768233371, "episode": 30.0, "batch_reward": 0.6916717885136604, "critic_loss": 1.3388240227103234, "actor_loss": -77.55558937072755, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.365930557250977, "step": 30000}
{"episode_reward": 890.418977904819, "episode": 31.0, "batch_reward": 0.6972414024472237, "critic_loss": 1.3364127360582352, "actor_loss": -78.19333102416992, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.09009838104248, "step": 31000}
{"episode_reward": 937.5282648869998, "episode": 32.0, "batch_reward": 0.7050214558243751, "critic_loss": 1.3840599635839461, "actor_loss": -79.55975938415527, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.36792230606079, "step": 32000}
{"episode_reward": 899.0425230954914, "episode": 33.0, "batch_reward": 0.7109844006299972, "critic_loss": 1.405649335205555, "actor_loss": -79.81287957763672, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.36214518547058, "step": 33000}
{"episode_reward": 892.4907037381344, "episode": 34.0, "batch_reward": 0.7168871166110039, "critic_loss": 1.2586401298046113, "actor_loss": -78.90348860168457, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.382994413375854, "step": 34000}
{"episode_reward": 971.5598449009675, "episode": 35.0, "batch_reward": 0.7236132444143295, "critic_loss": 1.307736316382885, "actor_loss": -80.48707009887696, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35995125770569, "step": 35000}
{"episode_reward": 900.9755619954952, "episode": 36.0, "batch_reward": 0.7272770428061486, "critic_loss": 1.2327307510375975, "actor_loss": -80.62781524658203, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.358770847320557, "step": 36000}
{"episode_reward": 919.519411243221, "episode": 37.0, "batch_reward": 0.7324602037072182, "critic_loss": 1.2128952347040176, "actor_loss": -80.82731475830079, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.356698036193848, "step": 37000}
{"episode_reward": 958.0136987025926, "episode": 38.0, "batch_reward": 0.7415033921003341, "critic_loss": 1.105810671031475, "actor_loss": -81.44845457458496, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.329227209091187, "step": 38000}
{"episode_reward": 966.4764907334535, "episode": 39.0, "batch_reward": 0.7478474501371384, "critic_loss": 1.13406439691782, "actor_loss": -82.80062519836426, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.34253168106079, "step": 39000}
{"episode_reward": 979.722357197633, "episode": 40.0, "batch_reward": 0.7535867130160332, "critic_loss": 1.0619429498910904, "actor_loss": -82.54163298034668, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.349952459335327, "step": 40000}
{"episode_reward": 977.3101434505037, "episode": 41.0, "batch_reward": 0.7561561549305916, "critic_loss": 1.1095465864539147, "actor_loss": -82.99435012817383, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.119486808776855, "step": 41000}
{"episode_reward": 842.2575591621558, "episode": 42.0, "batch_reward": 0.7606262630224228, "critic_loss": 1.0921654940843581, "actor_loss": -83.21663790893555, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.364798545837402, "step": 42000}
{"episode_reward": 921.947256660185, "episode": 43.0, "batch_reward": 0.7629108186960221, "critic_loss": 1.1482409523129464, "actor_loss": -83.51322213745117, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.353384494781494, "step": 43000}
{"episode_reward": 913.4897796919948, "episode": 44.0, "batch_reward": 0.7683913708925247, "critic_loss": 1.0996324862241744, "actor_loss": -83.60014167785644, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.372987270355225, "step": 44000}
{"episode_reward": 982.2080886423194, "episode": 45.0, "batch_reward": 0.7688062845468521, "critic_loss": 1.1655929197072983, "actor_loss": -84.37245193481445, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.384336709976196, "step": 45000}
{"episode_reward": 786.7616682323113, "episode": 46.0, "batch_reward": 0.7718152649402619, "critic_loss": 1.1066197526454926, "actor_loss": -84.42222717285156, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.33399271965027, "step": 46000}
{"episode_reward": 937.2424633678661, "episode": 47.0, "batch_reward": 0.7764500552415847, "critic_loss": 1.066474418759346, "actor_loss": -84.5469991607666, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.342092990875244, "step": 47000}
{"episode_reward": 898.8807940023501, "episode": 48.0, "batch_reward": 0.7784688475131989, "critic_loss": 1.1173794672489166, "actor_loss": -84.51924504089355, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.370070934295654, "step": 48000}
{"episode_reward": 927.0634912939001, "episode": 49.0, "batch_reward": 0.782199782550335, "critic_loss": 1.072241543352604, "actor_loss": -85.06587889099121, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.356284379959106, "step": 49000}
{"episode_reward": 973.8797819114532, "episode": 50.0, "batch_reward": 0.785486305296421, "critic_loss": 1.0641554463505745, "actor_loss": -85.07754788208008, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.372640132904053, "step": 50000}
{"episode_reward": 980.6339580348385, "episode": 51.0, "batch_reward": 0.7909274570941925, "critic_loss": 1.1179356256723403, "actor_loss": -85.03741508483887, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.079598903656006, "step": 51000}
{"episode_reward": 916.6036518373239, "episode": 52.0, "batch_reward": 0.7911957013010978, "critic_loss": 1.1460249680280685, "actor_loss": -85.76302169799804, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.302544116973877, "step": 52000}
{"episode_reward": 935.5437675412155, "episode": 53.0, "batch_reward": 0.7935369606614113, "critic_loss": 1.116283252954483, "actor_loss": -85.91595013427734, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.317649364471436, "step": 53000}
{"episode_reward": 934.0404114688317, "episode": 54.0, "batch_reward": 0.7964913408756256, "critic_loss": 1.116795158445835, "actor_loss": -85.97611259460449, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.34724736213684, "step": 54000}
{"episode_reward": 878.2399021156293, "episode": 55.0, "batch_reward": 0.7988271298408508, "critic_loss": 1.1208650572299956, "actor_loss": -85.80581042480469, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.33492946624756, "step": 55000}
{"episode_reward": 960.6255337774799, "episode": 56.0, "batch_reward": 0.8027068029046058, "critic_loss": 1.0763031269609928, "actor_loss": -86.47521142578125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.371646404266357, "step": 56000}
{"episode_reward": 968.1590404836107, "episode": 57.0, "batch_reward": 0.8061162891983986, "critic_loss": 1.0520861815214158, "actor_loss": -86.62951794433594, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.378763914108276, "step": 57000}
{"episode_reward": 948.6277618311533, "episode": 58.0, "batch_reward": 0.8076175327897072, "critic_loss": 1.024576498031616, "actor_loss": -86.35305316162109, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.382725954055786, "step": 58000}
{"episode_reward": 964.1685318619242, "episode": 59.0, "batch_reward": 0.810926477432251, "critic_loss": 0.9805962936580181, "actor_loss": -86.99930712890625, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.384804010391235, "step": 59000}
{"episode_reward": 955.16312534498, "episode": 60.0, "batch_reward": 0.8121529910564422, "critic_loss": 1.0072917396724224, "actor_loss": -87.25776608276367, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35964822769165, "step": 60000}
{"episode_reward": 926.4976975105142, "episode": 61.0, "batch_reward": 0.8150370628833771, "critic_loss": 1.004111565887928, "actor_loss": -87.07000579833985, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.18671250343323, "step": 61000}
{"episode_reward": 957.9065446861765, "episode": 62.0, "batch_reward": 0.8162231457233429, "critic_loss": 0.9896780143082142, "actor_loss": -87.11685556030274, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.358885526657104, "step": 62000}
{"episode_reward": 960.9248134610367, "episode": 63.0, "batch_reward": 0.8166702014803886, "critic_loss": 0.9423237435817718, "actor_loss": -87.3546460571289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.365235328674316, "step": 63000}
{"episode_reward": 923.5852615604364, "episode": 64.0, "batch_reward": 0.8197622081637382, "critic_loss": 0.9205895200371742, "actor_loss": -87.59929081726074, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.382215976715088, "step": 64000}
{"episode_reward": 960.9072483492897, "episode": 65.0, "batch_reward": 0.8222063307762146, "critic_loss": 0.9369330010712147, "actor_loss": -87.84935284423828, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.346118927001953, "step": 65000}
{"episode_reward": 976.5317687287012, "episode": 66.0, "batch_reward": 0.8237798408865928, "critic_loss": 0.9149031307697296, "actor_loss": -87.98560977172852, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.36600661277771, "step": 66000}
{"episode_reward": 924.830111210866, "episode": 67.0, "batch_reward": 0.825181547343731, "critic_loss": 0.8971477964520455, "actor_loss": -88.33188160705566, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35569930076599, "step": 67000}
{"episode_reward": 890.5169111762422, "episode": 68.0, "batch_reward": 0.8276030228734016, "critic_loss": 0.9094384207427502, "actor_loss": -87.88905036926269, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.340908527374268, "step": 68000}
{"episode_reward": 942.3637705719013, "episode": 69.0, "batch_reward": 0.8284279360175133, "critic_loss": 0.9558657043874264, "actor_loss": -88.39283244323731, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.368541955947876, "step": 69000}
{"episode_reward": 979.6920424630487, "episode": 70.0, "batch_reward": 0.8314671346545219, "critic_loss": 0.9702437667250633, "actor_loss": -88.54106394958497, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.373834133148193, "step": 70000}
{"episode_reward": 926.1459714656888, "episode": 71.0, "batch_reward": 0.832257252395153, "critic_loss": 0.8786269432902336, "actor_loss": -88.3149513092041, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.118805170059204, "step": 71000}
{"episode_reward": 935.3773504612233, "episode": 72.0, "batch_reward": 0.8351668143272399, "critic_loss": 0.8534349880814552, "actor_loss": -88.5211051940918, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.370886087417603, "step": 72000}
{"episode_reward": 943.4931201874922, "episode": 73.0, "batch_reward": 0.8356004773974418, "critic_loss": 0.8765032626390458, "actor_loss": -88.74546127319336, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.341909885406494, "step": 73000}
{"episode_reward": 977.8410849532031, "episode": 74.0, "batch_reward": 0.8394176342487335, "critic_loss": 0.8761388944387436, "actor_loss": -89.00695854187012, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35271406173706, "step": 74000}
{"episode_reward": 978.507787071197, "episode": 75.0, "batch_reward": 0.8398366988897323, "critic_loss": 0.8521529921591282, "actor_loss": -88.93918342590332, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.37011170387268, "step": 75000}
{"episode_reward": 954.7181749518869, "episode": 76.0, "batch_reward": 0.8410029544830322, "critic_loss": 0.8410304597318172, "actor_loss": -88.98743141174316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.345746994018555, "step": 76000}
{"episode_reward": 983.5094234333309, "episode": 77.0, "batch_reward": 0.8427284007668495, "critic_loss": 0.8441803685128689, "actor_loss": -89.12491661071778, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.38220977783203, "step": 77000}
{"episode_reward": 960.228436454483, "episode": 78.0, "batch_reward": 0.8446900836825371, "critic_loss": 0.8366696194112301, "actor_loss": -89.35385513305664, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.364722967147827, "step": 78000}
{"episode_reward": 956.2375226118985, "episode": 79.0, "batch_reward": 0.8457434906363487, "critic_loss": 0.8195717028081417, "actor_loss": -89.29402259826661, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.352547883987427, "step": 79000}
{"episode_reward": 962.6632768665917, "episode": 80.0, "batch_reward": 0.8459737238883972, "critic_loss": 0.845055066794157, "actor_loss": -89.33259495544434, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.375003814697266, "step": 80000}
{"episode_reward": 955.3506023416569, "episode": 81.0, "batch_reward": 0.8488629376292228, "critic_loss": 0.7916707293689251, "actor_loss": -89.73783026123047, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.132312059402466, "step": 81000}
{"episode_reward": 973.9361464859188, "episode": 82.0, "batch_reward": 0.850546988427639, "critic_loss": 0.8051093511283398, "actor_loss": -89.77245028686524, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.370922327041626, "step": 82000}
{"episode_reward": 921.2290148814075, "episode": 83.0, "batch_reward": 0.8527785618901252, "critic_loss": 0.8481364083588123, "actor_loss": -89.89182379150391, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.376453638076782, "step": 83000}
{"episode_reward": 955.8207088960354, "episode": 84.0, "batch_reward": 0.8535571870803833, "critic_loss": 0.8075536696016788, "actor_loss": -90.05706546020508, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.361836671829224, "step": 84000}
{"episode_reward": 988.4271060479089, "episode": 85.0, "batch_reward": 0.8518269023895264, "critic_loss": 0.7708900594711303, "actor_loss": -90.05195475769042, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.385154962539673, "step": 85000}
{"episode_reward": 945.7627991696032, "episode": 86.0, "batch_reward": 0.8546195437908173, "critic_loss": 0.7882622840702533, "actor_loss": -90.04953274536133, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.39381766319275, "step": 86000}
{"episode_reward": 953.3766713661553, "episode": 87.0, "batch_reward": 0.8567537790536881, "critic_loss": 0.8196604391336441, "actor_loss": -90.07294998168945, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.37248396873474, "step": 87000}
{"episode_reward": 955.8879038143866, "episode": 88.0, "batch_reward": 0.8570694711208343, "critic_loss": 0.7793792261481285, "actor_loss": -90.06533782958985, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.39537215232849, "step": 88000}
{"episode_reward": 945.3626130064163, "episode": 89.0, "batch_reward": 0.8576444740891457, "critic_loss": 0.7518141687512397, "actor_loss": -90.26730754089355, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.388640880584717, "step": 89000}
{"episode_reward": 978.9535074775343, "episode": 90.0, "batch_reward": 0.860256141424179, "critic_loss": 0.7474677628278732, "actor_loss": -90.44491212463379, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.371114015579224, "step": 90000}
{"episode_reward": 905.922898191849, "episode": 91.0, "batch_reward": 0.8608109142184257, "critic_loss": 0.7545640137791634, "actor_loss": -90.35606143188477, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.14815068244934, "step": 91000}
{"episode_reward": 981.5581644011397, "episode": 92.0, "batch_reward": 0.8628255698680878, "critic_loss": 0.783541266053915, "actor_loss": -90.62256762695313, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.366997480392456, "step": 92000}
{"episode_reward": 963.3447286052119, "episode": 93.0, "batch_reward": 0.860804689347744, "critic_loss": 0.8072723905444146, "actor_loss": -90.44996868896484, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.341201543807983, "step": 93000}
{"episode_reward": 934.4908627984265, "episode": 94.0, "batch_reward": 0.863198560833931, "critic_loss": 0.7811789259910583, "actor_loss": -90.69083337402344, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35480523109436, "step": 94000}
{"episode_reward": 953.1568060927857, "episode": 95.0, "batch_reward": 0.862852378487587, "critic_loss": 0.7837148573696613, "actor_loss": -90.79966589355469, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35037899017334, "step": 95000}
{"episode_reward": 940.0606947633429, "episode": 96.0, "batch_reward": 0.8639174211025238, "critic_loss": 0.7802692924439907, "actor_loss": -90.76895362854003, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.327479124069214, "step": 96000}
{"episode_reward": 938.053947156026, "episode": 97.0, "batch_reward": 0.8655153670907021, "critic_loss": 0.7519057696759701, "actor_loss": -90.93816368103028, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.369999170303345, "step": 97000}
{"episode_reward": 915.1053569173914, "episode": 98.0, "batch_reward": 0.8652633933424949, "critic_loss": 0.8201739703714848, "actor_loss": -90.83796662902832, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.374067068099976, "step": 98000}
{"episode_reward": 800.0710424175477, "episode": 99.0, "batch_reward": 0.8655372241735458, "critic_loss": 0.8091119222640991, "actor_loss": -90.89685690307617, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35508108139038, "step": 99000}
{"episode_reward": 904.1285193886855, "episode": 100.0, "batch_reward": 0.8673985202908516, "critic_loss": 0.7935138357579709, "actor_loss": -90.8549140625, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.345141410827637, "step": 100000}
{"episode_reward": 965.9181998765174, "episode": 101.0, "batch_reward": 0.8682416281700134, "critic_loss": 0.8223914794921875, "actor_loss": -91.04423168945313, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.17540407180786, "step": 101000}
{"episode_reward": 989.4172032231448, "episode": 102.0, "batch_reward": 0.8685050679445266, "critic_loss": 0.9260303788781166, "actor_loss": -91.02156912231445, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.364708185195923, "step": 102000}
{"episode_reward": 981.5161755620977, "episode": 103.0, "batch_reward": 0.8680527268052101, "critic_loss": 0.8472673816382885, "actor_loss": -91.0174264831543, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.386163473129272, "step": 103000}
{"episode_reward": 951.7777820120153, "episode": 104.0, "batch_reward": 0.8704580008387566, "critic_loss": 0.8741094011068344, "actor_loss": -91.15574240112305, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.376840829849243, "step": 104000}
{"episode_reward": 874.1000384240311, "episode": 105.0, "batch_reward": 0.8710876724123955, "critic_loss": 0.8936130209267139, "actor_loss": -91.0017771911621, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.379767417907715, "step": 105000}
{"episode_reward": 849.2095350050813, "episode": 106.0, "batch_reward": 0.8700347013473511, "critic_loss": 0.9425414235293865, "actor_loss": -90.94367767333985, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.351656436920166, "step": 106000}
{"episode_reward": 899.0741124873189, "episode": 107.0, "batch_reward": 0.869758424282074, "critic_loss": 0.8865459558665753, "actor_loss": -91.17606318664551, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35680603981018, "step": 107000}
{"episode_reward": 948.1813422401157, "episode": 108.0, "batch_reward": 0.8727233365178109, "critic_loss": 0.8656485303640366, "actor_loss": -91.4087237701416, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.360873460769653, "step": 108000}
{"episode_reward": 952.7219916885479, "episode": 109.0, "batch_reward": 0.8722684175372124, "critic_loss": 0.8817653546929359, "actor_loss": -91.32869227600098, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.409124612808228, "step": 109000}
{"episode_reward": 973.1801061816656, "episode": 110.0, "batch_reward": 0.8716736231446266, "critic_loss": 0.8755387989878655, "actor_loss": -91.43077413940429, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35504460334778, "step": 110000}
{"episode_reward": 959.3319852953629, "episode": 111.0, "batch_reward": 0.8736577149033546, "critic_loss": 0.8901356662213802, "actor_loss": -91.42059620666504, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.20230531692505, "step": 111000}
{"episode_reward": 896.0803063638264, "episode": 112.0, "batch_reward": 0.874030652821064, "critic_loss": 0.8533523370027543, "actor_loss": -91.45788320922851, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.353827953338623, "step": 112000}
{"episode_reward": 981.4164870225983, "episode": 113.0, "batch_reward": 0.8749457942247391, "critic_loss": 0.8700514838993549, "actor_loss": -91.50841679382324, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.384739875793457, "step": 113000}
{"episode_reward": 959.5016412067348, "episode": 114.0, "batch_reward": 0.8763900760412217, "critic_loss": 0.831285798817873, "actor_loss": -91.66667854309082, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.414909601211548, "step": 114000}
{"episode_reward": 965.2864297266523, "episode": 115.0, "batch_reward": 0.8759494849443435, "critic_loss": 0.8627189001739025, "actor_loss": -91.53273373413086, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35871434211731, "step": 115000}
{"episode_reward": 925.7451006483648, "episode": 116.0, "batch_reward": 0.8769834825396537, "critic_loss": 0.8411394683420658, "actor_loss": -91.6653874206543, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35903549194336, "step": 116000}
{"episode_reward": 941.6700772496123, "episode": 117.0, "batch_reward": 0.8765785158872604, "critic_loss": 0.7950746458172798, "actor_loss": -91.55383033752442, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.370485544204712, "step": 117000}
{"episode_reward": 944.8109495410605, "episode": 118.0, "batch_reward": 0.877518211722374, "critic_loss": 0.8454034262895584, "actor_loss": -91.76503994750976, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.366613149642944, "step": 118000}
{"episode_reward": 988.0367960395394, "episode": 119.0, "batch_reward": 0.8787898334860802, "critic_loss": 0.7824288844764232, "actor_loss": -91.62196296691894, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.36643671989441, "step": 119000}
{"episode_reward": 945.3691155368599, "episode": 120.0, "batch_reward": 0.8773361209630967, "critic_loss": 0.7636348923444748, "actor_loss": -91.49807620239258, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.401363849639893, "step": 120000}
{"episode_reward": 981.410810889849, "episode": 121.0, "batch_reward": 0.8803309802412986, "critic_loss": 0.7226631000339985, "actor_loss": -91.71265022277832, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.128326654434204, "step": 121000}
{"episode_reward": 976.4605991288919, "episode": 122.0, "batch_reward": 0.8806438580155372, "critic_loss": 0.7434343160837888, "actor_loss": -91.78094865417481, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.36525297164917, "step": 122000}
{"episode_reward": 951.1790945701099, "episode": 123.0, "batch_reward": 0.8826774697899819, "critic_loss": 0.7718666495084763, "actor_loss": -91.79231665039063, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.326462745666504, "step": 123000}
{"episode_reward": 929.6653798546088, "episode": 124.0, "batch_reward": 0.8820474609732628, "critic_loss": 0.7353567529022693, "actor_loss": -91.9455915222168, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.353373765945435, "step": 124000}
{"episode_reward": 983.6470610537534, "episode": 125.0, "batch_reward": 0.8834439804553985, "critic_loss": 0.705792707145214, "actor_loss": -91.90258659362793, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.373990297317505, "step": 125000}
{"episode_reward": 978.8081025034262, "episode": 126.0, "batch_reward": 0.8838364183306694, "critic_loss": 0.6852583995461464, "actor_loss": -92.15035687255859, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.363938093185425, "step": 126000}
{"episode_reward": 988.9992674308633, "episode": 127.0, "batch_reward": 0.8840325282216072, "critic_loss": 0.7147147063314915, "actor_loss": -92.09386793518067, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.37961745262146, "step": 127000}
{"episode_reward": 981.2051042858927, "episode": 128.0, "batch_reward": 0.8846148258447647, "critic_loss": 0.7438408041894435, "actor_loss": -92.18715348815918, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.408644437789917, "step": 128000}
{"episode_reward": 965.723421725382, "episode": 129.0, "batch_reward": 0.8850980259180069, "critic_loss": 0.7209043646454811, "actor_loss": -92.23893252563477, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.353548526763916, "step": 129000}
{"episode_reward": 983.7929336872165, "episode": 130.0, "batch_reward": 0.8875393683314323, "critic_loss": 0.7187794279456139, "actor_loss": -92.10950372314453, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.376232624053955, "step": 130000}
{"episode_reward": 985.3794093745345, "episode": 131.0, "batch_reward": 0.8881297783255577, "critic_loss": 0.7493618364930152, "actor_loss": -92.17541159057618, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.17719864845276, "step": 131000}
{"episode_reward": 958.2987546293031, "episode": 132.0, "batch_reward": 0.8882086797952652, "critic_loss": 0.6823498860001564, "actor_loss": -92.21106658935547, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.41217064857483, "step": 132000}
{"episode_reward": 955.7803366165465, "episode": 133.0, "batch_reward": 0.887914641559124, "critic_loss": 0.7248487935960293, "actor_loss": -92.40272441101074, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.39990735054016, "step": 133000}
{"episode_reward": 954.236329854983, "episode": 134.0, "batch_reward": 0.8883709372282028, "critic_loss": 0.688883443236351, "actor_loss": -92.47172619628907, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35031509399414, "step": 134000}
{"episode_reward": 959.7158469354109, "episode": 135.0, "batch_reward": 0.8908476925492287, "critic_loss": 0.666407543182373, "actor_loss": -92.33440324401856, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.39204430580139, "step": 135000}
{"episode_reward": 985.2090712534757, "episode": 136.0, "batch_reward": 0.8902695136666298, "critic_loss": 0.6777410633862019, "actor_loss": -92.35899295043946, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.61257243156433, "step": 136000}
{"episode_reward": 980.9829056438654, "episode": 137.0, "batch_reward": 0.8900935426354408, "critic_loss": 0.7098230332881212, "actor_loss": -92.3035935974121, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.456061363220215, "step": 137000}
{"episode_reward": 984.7823808233994, "episode": 138.0, "batch_reward": 0.8919763352870941, "critic_loss": 0.6876599597930908, "actor_loss": -92.35411402893067, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.55254101753235, "step": 138000}
{"episode_reward": 950.4142131915962, "episode": 139.0, "batch_reward": 0.8920020886063575, "critic_loss": 0.6896996575295925, "actor_loss": -92.42414613342285, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.475291967391968, "step": 139000}
{"episode_reward": 975.1173222854761, "episode": 140.0, "batch_reward": 0.8931188083291054, "critic_loss": 0.7052097047865391, "actor_loss": -92.4291371459961, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.324512481689453, "step": 140000}
{"episode_reward": 958.4256108613533, "episode": 141.0, "batch_reward": 0.892828457057476, "critic_loss": 0.6632592824101448, "actor_loss": -92.39989280700684, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.16933870315552, "step": 141000}
{"episode_reward": 963.621391954872, "episode": 142.0, "batch_reward": 0.8925979661345482, "critic_loss": 0.6606603209674359, "actor_loss": -92.47686366271972, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.39076328277588, "step": 142000}
{"episode_reward": 986.2830163137032, "episode": 143.0, "batch_reward": 0.8946300904750824, "critic_loss": 0.7280484111905098, "actor_loss": -92.5145050201416, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.379924774169922, "step": 143000}
{"episode_reward": 951.9709231587796, "episode": 144.0, "batch_reward": 0.8940278040766716, "critic_loss": 0.6977665316015482, "actor_loss": -92.5180655822754, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.383718013763428, "step": 144000}
{"episode_reward": 961.429868843413, "episode": 145.0, "batch_reward": 0.8955344685912132, "critic_loss": 0.6765577081888914, "actor_loss": -92.62959980773925, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.3943932056427, "step": 145000}
{"episode_reward": 985.709617416268, "episode": 146.0, "batch_reward": 0.8943591496348381, "critic_loss": 0.6568149942308664, "actor_loss": -92.73298539733887, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.363741636276245, "step": 146000}
{"episode_reward": 967.9725286657471, "episode": 147.0, "batch_reward": 0.8941673128604889, "critic_loss": 0.7011234816908837, "actor_loss": -92.62348309326173, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.36697793006897, "step": 147000}
{"episode_reward": 867.8343410941206, "episode": 148.0, "batch_reward": 0.89663549888134, "critic_loss": 0.641651682689786, "actor_loss": -92.68050793457031, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.395498752593994, "step": 148000}
{"episode_reward": 977.2831868897731, "episode": 149.0, "batch_reward": 0.8963323010802269, "critic_loss": 0.7038353605419397, "actor_loss": -92.69941751098632, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.381569862365723, "step": 149000}
{"episode_reward": 969.4648852238824, "episode": 150.0, "batch_reward": 0.8971843379735946, "critic_loss": 0.7175021888911725, "actor_loss": -92.77805767822265, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
