{"episode": 4.0, "batch_reward": 0.49857808607816695, "actor_loss": -85.00785427856445, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.885842084884644, "episode_reward": 669.1340603460055, "step": 4000}
{"episode": 1.0, "duration": 24.80732822418213, "episode_reward": 59.660092495208936, "step": 1000}
{"episode": 2.0, "duration": 1.995786428451538, "episode_reward": 890.1817750618746, "step": 2000}
{"episode": 5.0, "batch_reward": 0.552901408791542, "actor_loss": -86.2398821105957, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.441901445388794, "episode_reward": 779.9444665975454, "step": 5000}
{"episode": 6.0, "batch_reward": 0.5740360031425953, "actor_loss": -86.53721333312988, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.656789302825928, "episode_reward": 687.3919447527866, "step": 6000}
{"episode": 7.0, "batch_reward": 0.602742609500885, "actor_loss": -87.24006782531738, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.55654764175415, "episode_reward": 853.7715025889644, "step": 7000}
{"episode": 3.0, "batch_reward": 0.47940904560904773, "actor_loss": -84.92750646706436, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 49.497828006744385, "episode_reward": 450.6024003723654, "step": 3000}
{"episode": 8.0, "batch_reward": 0.6322549127936363, "actor_loss": -87.82521775817871, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.642136335372925, "episode_reward": 770.5472065039779, "step": 8000}
{"episode": 4.0, "batch_reward": 0.49857808607816695, "actor_loss": -85.00785427856445, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.191690921783447, "episode_reward": 669.1340603460055, "step": 4000}
{"episode": 9.0, "batch_reward": 0.6384174175858498, "actor_loss": -87.77158125305176, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.0281343460083, "episode_reward": 645.0532939258136, "step": 9000}
{"episode": 5.0, "batch_reward": 0.552901408791542, "actor_loss": -86.2398821105957, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.21033215522766, "episode_reward": 779.9444665975454, "step": 5000}
{"episode": 6.0, "batch_reward": 0.5740360031425953, "actor_loss": -86.53721333312988, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 19.26835346221924, "episode_reward": 687.3919447527866, "step": 6000}
{"episode": 7.0, "batch_reward": 0.602742609500885, "actor_loss": -87.24006782531738, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.78061079978943, "episode_reward": 853.7715025889644, "step": 7000}
{"episode": 8.0, "batch_reward": 0.6322549127936363, "actor_loss": -87.82521775817871, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.551802158355713, "episode_reward": 770.5472065039779, "step": 8000}
{"episode": 9.0, "batch_reward": 0.6384174175858498, "actor_loss": -87.77158125305176, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.667256355285645, "episode_reward": 645.0532939258136, "step": 9000}
{"episode": 10.0, "batch_reward": 0.6473716421127319, "actor_loss": -83.36284135437012, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 4041.2975509166718, "episode_reward": 696.2298072514182, "step": 10000}
{"episode": 11.0, "batch_reward": 0.6501634224653244, "actor_loss": -83.61039276123047, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.751723289489746, "episode_reward": 712.9591447519543, "step": 11000}
{"episode": 10.0, "batch_reward": 0.6473716421127319, "actor_loss": -83.36284135437012, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 4025.5343205928802, "episode_reward": 696.2298072514182, "step": 10000}
{"episode": 11.0, "batch_reward": 0.6501634224653244, "actor_loss": -83.61039276123047, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 36.85658669471741, "episode_reward": 712.9591447519543, "step": 11000}
{"episode": 12.0, "batch_reward": 0.655408441901207, "actor_loss": -80.12148518371582, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 443.8702743053436, "episode_reward": 697.4011398102115, "step": 12000}
{"episode": 13.0, "batch_reward": 0.6559400917887688, "actor_loss": -80.31928816223144, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.648775339126587, "episode_reward": 627.3883054793421, "step": 13000}
{"episode": 12.0, "batch_reward": 0.655408441901207, "actor_loss": -80.12148518371582, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 441.8355121612549, "episode_reward": 697.4011398102115, "step": 12000}
{"episode": 13.0, "batch_reward": 0.6559400917887688, "actor_loss": -80.31928816223144, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.381840705871582, "episode_reward": 627.3883054793421, "step": 13000}
{"episode": 14.0, "batch_reward": 0.6521235467791557, "actor_loss": -78.04940814208985, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 441.14827132225037, "episode_reward": 517.4962893239805, "step": 14000}
{"episode": 15.0, "batch_reward": 0.6534705746769905, "actor_loss": -78.29067863464356, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.821553230285645, "episode_reward": 804.466464125069, "step": 15000}
{"episode": 14.0, "batch_reward": 0.6521235467791557, "actor_loss": -78.04940814208985, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 441.7894060611725, "episode_reward": 517.4962893239805, "step": 14000}
{"episode": 15.0, "batch_reward": 0.6534705746769905, "actor_loss": -78.29067863464356, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.40319800376892, "episode_reward": 804.466464125069, "step": 15000}
{"episode": 16.0, "batch_reward": 0.6561680027246475, "actor_loss": -76.87801489257812, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 431.5340533256531, "episode_reward": 717.6179157144425, "step": 16000}
{"episode": 17.0, "batch_reward": 0.6657665495872498, "actor_loss": -77.33481413269043, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 19.251551628112793, "episode_reward": 866.5640534058751, "step": 17000}
{"episode": 16.0, "batch_reward": 0.6561680027246475, "actor_loss": -76.87801489257812, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 436.74761629104614, "episode_reward": 717.6179157144425, "step": 16000}
{"episode": 17.0, "batch_reward": 0.6657665495872498, "actor_loss": -77.33481413269043, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.087472915649414, "episode_reward": 866.5640534058751, "step": 17000}
{"episode": 18.0, "batch_reward": 0.6756494032144547, "actor_loss": -76.7891312866211, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 441.27828097343445, "episode_reward": 804.6205623604393, "step": 18000}
{"episode": 19.0, "batch_reward": 0.6876115192770957, "actor_loss": -77.26069274902343, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.8651340007782, "episode_reward": 939.7563579141366, "step": 19000}
{"episode": 18.0, "batch_reward": 0.6756494032144547, "actor_loss": -76.7891312866211, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 436.54939126968384, "episode_reward": 804.6205623604393, "step": 18000}
{"episode": 19.0, "batch_reward": 0.6876115192770957, "actor_loss": -77.26069274902343, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.754937887191772, "episode_reward": 939.7563579141366, "step": 19000}
{"episode": 20.0, "batch_reward": 0.6987606857419014, "actor_loss": -76.97094390869141, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 437.55703997612, "episode_reward": 931.9212032727594, "step": 20000}
{"episode": 21.0, "batch_reward": 0.7039478513002395, "actor_loss": -77.28280426025391, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 44.89608407020569, "episode_reward": 689.9192774016464, "step": 21000}
{"episode": 20.0, "batch_reward": 0.6987606857419014, "actor_loss": -76.97094390869141, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 449.7823176383972, "episode_reward": 931.9212032727594, "step": 20000}
{"episode": 21.0, "batch_reward": 0.7039478513002395, "actor_loss": -77.28280426025391, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 38.71571350097656, "episode_reward": 689.9192774016464, "step": 21000}
{"episode": 22.0, "batch_reward": 0.7090443113446235, "actor_loss": -77.04069731140137, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 450.87439155578613, "episode_reward": 862.6872553833081, "step": 22000}
{"episode": 23.0, "batch_reward": 0.7131279646158218, "actor_loss": -77.31809895324707, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.65878129005432, "episode_reward": 782.6489118084799, "step": 23000}
{"episode": 22.0, "batch_reward": 0.7090443113446235, "actor_loss": -77.04069731140137, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 445.5397832393646, "episode_reward": 862.6872553833081, "step": 22000}
{"episode": 23.0, "batch_reward": 0.7131279646158218, "actor_loss": -77.31809895324707, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.355907201766968, "episode_reward": 782.6489118084799, "step": 23000}
{"episode": 24.0, "batch_reward": 0.718597556591034, "actor_loss": -76.63269889831543, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 450.6951894760132, "episode_reward": 857.6057897645109, "step": 24000}
{"episode": 25.0, "batch_reward": 0.7216252176761627, "actor_loss": -76.93544006347656, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.98685312271118, "episode_reward": 872.9751531071278, "step": 25000}
{"episode": 24.0, "batch_reward": 0.718597556591034, "actor_loss": -76.63269889831543, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 453.80724143981934, "episode_reward": 857.6057897645109, "step": 24000}
{"episode": 25.0, "batch_reward": 0.7216252176761627, "actor_loss": -76.93544006347656, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 19.250811338424683, "episode_reward": 872.9751531071278, "step": 25000}
{"episode": 26.0, "batch_reward": 0.7308555104732514, "actor_loss": -76.82345399475098, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.4416630268097, "episode_reward": 957.5926151654534, "step": 26000}
{"episode": 27.0, "batch_reward": 0.7357218525409699, "actor_loss": -77.0574287109375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 15.956700086593628, "episode_reward": 822.8239817675791, "step": 27000}
{"episode": 26.0, "batch_reward": 0.7308555104732514, "actor_loss": -76.82345399475098, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 429.0208327770233, "episode_reward": 957.5926151654534, "step": 26000}
{"episode": 27.0, "batch_reward": 0.7357218525409699, "actor_loss": -77.0574287109375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.72210669517517, "episode_reward": 822.8239817675791, "step": 27000}
{"episode": 28.0, "batch_reward": 0.739395770072937, "actor_loss": -76.33489234924316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 423.79008650779724, "episode_reward": 806.4426578645499, "step": 28000}
{"episode": 29.0, "batch_reward": 0.743429846405983, "actor_loss": -76.6585772705078, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.6185359954834, "episode_reward": 811.9857435783973, "step": 29000}
{"episode": 28.0, "batch_reward": 0.739395770072937, "actor_loss": -76.33489234924316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 425.89281010627747, "episode_reward": 806.4426578645499, "step": 28000}
{"episode": 29.0, "batch_reward": 0.743429846405983, "actor_loss": -76.6585772705078, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.620197772979736, "episode_reward": 811.9857435783973, "step": 29000}
{"episode": 30.0, "batch_reward": 0.7447241947054863, "actor_loss": -76.6817063293457, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 421.7584686279297, "episode_reward": 886.3039336828762, "step": 30000}
{"episode": 31.0, "batch_reward": 0.7508015620112419, "actor_loss": -76.92045750427246, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 38.54057860374451, "episode_reward": 918.2064838122864, "step": 31000}
{"episode": 30.0, "batch_reward": 0.7447241947054863, "actor_loss": -76.6817063293457, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 423.209734916687, "episode_reward": 886.3039336828762, "step": 30000}
{"episode": 31.0, "batch_reward": 0.7508015620112419, "actor_loss": -76.92045750427246, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 38.32946753501892, "episode_reward": 918.2064838122864, "step": 31000}
{"episode": 32.0, "batch_reward": 0.7534557716846466, "actor_loss": -76.99672889709473, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.2800302505493, "episode_reward": 838.8407695665928, "step": 32000}
{"episode": 33.0, "batch_reward": 0.7594052381515503, "actor_loss": -77.35828143310547, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.944808959960938, "episode_reward": 902.4150904777442, "step": 33000}
{"episode": 32.0, "batch_reward": 0.7534557716846466, "actor_loss": -76.99672889709473, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 436.41876435279846, "episode_reward": 838.8407695665928, "step": 32000}
{"episode": 33.0, "batch_reward": 0.7594052381515503, "actor_loss": -77.35828143310547, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.764602184295654, "episode_reward": 902.4150904777442, "step": 33000}
{"episode": 34.0, "batch_reward": 0.7628413949608803, "actor_loss": -77.7603193206787, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 431.44725465774536, "episode_reward": 942.716645345226, "step": 34000}
{"episode": 35.0, "batch_reward": 0.7661103932261467, "actor_loss": -77.96219445800782, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.699758291244507, "episode_reward": 857.9070366511821, "step": 35000}
{"episode": 34.0, "batch_reward": 0.7628413949608803, "actor_loss": -77.7603193206787, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 428.27410221099854, "episode_reward": 942.716645345226, "step": 34000}
{"episode": 35.0, "batch_reward": 0.7661103932261467, "actor_loss": -77.96219445800782, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.76095414161682, "episode_reward": 857.9070366511821, "step": 35000}
{"episode": 36.0, "batch_reward": 0.7692536215782165, "actor_loss": -77.83790368652343, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 432.74730253219604, "episode_reward": 873.1366694492378, "step": 36000}
{"episode": 37.0, "batch_reward": 0.7736323084831238, "actor_loss": -78.05621684265137, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.424269199371338, "episode_reward": 918.6733627269037, "step": 37000}
{"episode": 36.0, "batch_reward": 0.7692536215782165, "actor_loss": -77.83790368652343, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 435.64374804496765, "episode_reward": 873.1366694492378, "step": 36000}
{"episode": 37.0, "batch_reward": 0.7736323084831238, "actor_loss": -78.05621684265137, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.997910022735596, "episode_reward": 918.6733627269037, "step": 37000}
{"episode": 38.0, "batch_reward": 0.780295302271843, "actor_loss": -78.41462994384766, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 433.37137842178345, "episode_reward": 959.5721996704483, "step": 38000}
{"episode": 39.0, "batch_reward": 0.780791328549385, "actor_loss": -78.59143598937989, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.73045778274536, "episode_reward": 906.998734602799, "step": 39000}
{"episode": 38.0, "batch_reward": 0.780295302271843, "actor_loss": -78.41462994384766, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 428.0311498641968, "episode_reward": 959.5721996704483, "step": 38000}
{"episode": 39.0, "batch_reward": 0.780791328549385, "actor_loss": -78.59143598937989, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.751888751983643, "episode_reward": 906.998734602799, "step": 39000}
{"episode": 40.0, "batch_reward": 0.7869078209996223, "actor_loss": -79.11292271423339, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 422.6488893032074, "episode_reward": 922.8136591290897, "step": 40000}
{"episode": 41.0, "batch_reward": 0.786110680103302, "actor_loss": -79.1825892944336, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 37.30217146873474, "episode_reward": 709.6919634180887, "step": 41000}
{"episode": 40.0, "batch_reward": 0.7869078209996223, "actor_loss": -79.11292271423339, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 421.73042488098145, "episode_reward": 922.8136591290897, "step": 40000}
{"episode": 41.0, "batch_reward": 0.786110680103302, "actor_loss": -79.1825892944336, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 37.887675285339355, "episode_reward": 709.6919634180887, "step": 41000}
{"episode": 42.0, "batch_reward": 0.788354204595089, "actor_loss": -79.12299282836914, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 419.323725938797, "episode_reward": 929.2601942043291, "step": 42000}
{"episode": 43.0, "batch_reward": 0.7876741777062416, "actor_loss": -79.31882627868653, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.917137145996094, "episode_reward": 830.9090163555505, "step": 43000}
{"episode": 42.0, "batch_reward": 0.788354204595089, "actor_loss": -79.12299282836914, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 421.8379817008972, "episode_reward": 929.2601942043291, "step": 42000}
{"episode": 43.0, "batch_reward": 0.7876741777062416, "actor_loss": -79.31882627868653, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.466995239257812, "episode_reward": 830.9090163555505, "step": 43000}
{"episode": 44.0, "batch_reward": 0.7899868099689483, "actor_loss": -79.09126460266113, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 420.87818241119385, "episode_reward": 828.8467245400508, "step": 44000}
{"episode": 45.0, "batch_reward": 0.7902546774744987, "actor_loss": -79.19783381652832, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.782557487487793, "episode_reward": 792.3883714881539, "step": 45000}
{"episode": 44.0, "batch_reward": 0.7899868099689483, "actor_loss": -79.09126460266113, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 418.14827728271484, "episode_reward": 828.8467245400508, "step": 44000}
{"episode": 45.0, "batch_reward": 0.7902546774744987, "actor_loss": -79.19783381652832, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.49188494682312, "episode_reward": 792.3883714881539, "step": 45000}
{"episode": 46.0, "batch_reward": 0.7892581268548965, "actor_loss": -79.50264718627929, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 423.3374328613281, "episode_reward": 684.042653231837, "step": 46000}
{"episode": 47.0, "batch_reward": 0.7893136004209519, "actor_loss": -79.50858586120606, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.187841415405273, "episode_reward": 792.1669426649569, "step": 47000}
{"episode": 46.0, "batch_reward": 0.7892581268548965, "actor_loss": -79.50264718627929, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 421.53752398490906, "episode_reward": 684.042653231837, "step": 46000}
{"episode": 47.0, "batch_reward": 0.7893136004209519, "actor_loss": -79.50858586120606, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.733395099639893, "episode_reward": 792.1669426649569, "step": 47000}
{"episode": 48.0, "batch_reward": 0.7903130905032157, "actor_loss": -79.81372996520996, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 430.1386194229126, "episode_reward": 919.6587189668252, "step": 48000}
{"episode": 49.0, "batch_reward": 0.794207444190979, "actor_loss": -79.90656163024903, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.387582540512085, "episode_reward": 899.3049254254322, "step": 49000}
{"episode": 48.0, "batch_reward": 0.7903130905032157, "actor_loss": -79.81372996520996, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 430.2905855178833, "episode_reward": 919.6587189668252, "step": 48000}
{"episode": 49.0, "batch_reward": 0.794207444190979, "actor_loss": -79.90656163024903, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.94592523574829, "episode_reward": 899.3049254254322, "step": 49000}
{"episode": 50.0, "batch_reward": 0.7937336589694023, "actor_loss": -80.05484448242187, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 436.8252055644989, "episode_reward": 965.7115706263188, "step": 50000}
{"episode": 51.0, "batch_reward": 0.7969579474925995, "actor_loss": -80.16937884521484, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.472764015197754, "episode_reward": 855.4326567469119, "step": 51000}
{"episode": 50.0, "batch_reward": 0.7937336589694023, "actor_loss": -80.05484448242187, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.0062835216522, "episode_reward": 965.7115706263188, "step": 50000}
{"episode": 51.0, "batch_reward": 0.7969579474925995, "actor_loss": -80.16937884521484, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 37.98915910720825, "episode_reward": 855.4326567469119, "step": 51000}
{"episode": 52.0, "batch_reward": 0.7987597022652626, "actor_loss": -80.79011138916016, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 440.98601722717285, "episode_reward": 917.4207997532933, "step": 52000}
{"episode": 53.0, "batch_reward": 0.7997415206432342, "actor_loss": -80.81434675598145, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.37320303916931, "episode_reward": 818.462652497213, "step": 53000}
{"episode": 52.0, "batch_reward": 0.7987597022652626, "actor_loss": -80.79011138916016, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 435.94408893585205, "episode_reward": 917.4207997532933, "step": 52000}
{"episode": 53.0, "batch_reward": 0.7997415206432342, "actor_loss": -80.81434675598145, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.113593101501465, "episode_reward": 818.462652497213, "step": 53000}
{"episode": 54.0, "batch_reward": 0.8015517199039459, "actor_loss": -80.96653576660157, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 437.6541028022766, "episode_reward": 900.527383163374, "step": 54000}
{"episode": 55.0, "batch_reward": 0.8026240877509118, "actor_loss": -81.03561439514161, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.667033433914185, "episode_reward": 946.489881191071, "step": 55000}
{"episode": 54.0, "batch_reward": 0.8015517199039459, "actor_loss": -80.96653576660157, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 438.5288174152374, "episode_reward": 900.527383163374, "step": 54000}
{"episode": 55.0, "batch_reward": 0.8026240877509118, "actor_loss": -81.03561439514161, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.97863006591797, "episode_reward": 946.489881191071, "step": 55000}
{"episode": 56.0, "batch_reward": 0.8063175604939461, "actor_loss": -81.76676095581055, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 440.5408766269684, "episode_reward": 922.8505081034076, "step": 56000}
{"episode": 57.0, "batch_reward": 0.8071824465990066, "actor_loss": -81.86139778137208, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.517579078674316, "episode_reward": 866.7197134223527, "step": 57000}
{"episode": 56.0, "batch_reward": 0.8063175604939461, "actor_loss": -81.76676095581055, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 437.4146020412445, "episode_reward": 922.8505081034076, "step": 56000}
{"episode": 57.0, "batch_reward": 0.8071824465990066, "actor_loss": -81.86139778137208, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.24545454978943, "episode_reward": 866.7197134223527, "step": 57000}
{"episode": 58.0, "batch_reward": 0.8086728684306145, "actor_loss": -81.90263589477539, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 436.0111322402954, "episode_reward": 954.5878676949607, "step": 58000}
{"episode": 59.0, "batch_reward": 0.8111691623926163, "actor_loss": -82.02472178649903, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.976505517959595, "episode_reward": 869.8510098813299, "step": 59000}
{"episode": 58.0, "batch_reward": 0.8086728684306145, "actor_loss": -81.90263589477539, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 441.01625776290894, "episode_reward": 954.5878676949607, "step": 58000}
{"episode": 59.0, "batch_reward": 0.8111691623926163, "actor_loss": -82.02472178649903, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.479430198669434, "episode_reward": 869.8510098813299, "step": 59000}
{"episode": 60.0, "batch_reward": 0.8140701802372933, "actor_loss": -81.633064453125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 434.7319483757019, "episode_reward": 858.1744307171965, "step": 60000}
{"episode": 61.0, "batch_reward": 0.8123374552130699, "actor_loss": -81.5168345489502, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 39.95409321784973, "episode_reward": 829.0085960834426, "step": 61000}
{"episode": 60.0, "batch_reward": 0.8140701802372933, "actor_loss": -81.633064453125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 431.64910411834717, "episode_reward": 858.1744307171965, "step": 60000}
{"episode": 61.0, "batch_reward": 0.8123374552130699, "actor_loss": -81.5168345489502, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.78540372848511, "episode_reward": 829.0085960834426, "step": 61000}
{"episode": 62.0, "batch_reward": 0.8133235540986061, "actor_loss": -81.45011103820801, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 441.646644115448, "episode_reward": 709.601976680719, "step": 62000}
{"episode": 63.0, "batch_reward": 0.810224526822567, "actor_loss": -81.42185984802246, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.50353741645813, "episode_reward": 822.0351184110561, "step": 63000}
{"episode": 62.0, "batch_reward": 0.8133235540986061, "actor_loss": -81.45011103820801, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 436.07489228248596, "episode_reward": 709.601976680719, "step": 62000}
{"episode": 63.0, "batch_reward": 0.810224526822567, "actor_loss": -81.42185984802246, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.744499444961548, "episode_reward": 822.0351184110561, "step": 63000}
{"episode": 64.0, "batch_reward": 0.8113243022561073, "actor_loss": -81.24056285095214, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.04977798461914, "episode_reward": 817.7277530903476, "step": 64000}
{"episode": 65.0, "batch_reward": 0.8109272185564042, "actor_loss": -81.29092051696777, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.197332620620728, "episode_reward": 858.0718275895437, "step": 65000}
{"episode": 64.0, "batch_reward": 0.8113243022561073, "actor_loss": -81.24056285095214, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 437.26084637641907, "episode_reward": 817.7277530903476, "step": 64000}
{"episode": 65.0, "batch_reward": 0.8109272185564042, "actor_loss": -81.29092051696777, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.83581018447876, "episode_reward": 858.0718275895437, "step": 65000}
{"episode": 66.0, "batch_reward": 0.810576520383358, "actor_loss": -80.68212875366211, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 438.4096624851227, "episode_reward": 680.1487440783721, "step": 66000}
{"episode": 67.0, "batch_reward": 0.8086406291723252, "actor_loss": -80.65713380432129, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.769316911697388, "episode_reward": 779.5169865854258, "step": 67000}
{"episode": 66.0, "batch_reward": 0.810576520383358, "actor_loss": -80.68212875366211, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 438.6086118221283, "episode_reward": 680.1487440783721, "step": 66000}
{"episode": 67.0, "batch_reward": 0.8086406291723252, "actor_loss": -80.65713380432129, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.254226684570312, "episode_reward": 779.5169865854258, "step": 67000}
{"episode": 68.0, "batch_reward": 0.8119900333881378, "actor_loss": -80.016875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 438.5537157058716, "episode_reward": 888.5788081065622, "step": 68000}
{"episode": 69.0, "batch_reward": 0.8134616083502769, "actor_loss": -80.05125550842286, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.59357476234436, "episode_reward": 959.2717368305675, "step": 69000}
{"episode": 68.0, "batch_reward": 0.8119900333881378, "actor_loss": -80.016875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 437.4794731140137, "episode_reward": 888.5788081065622, "step": 68000}
{"episode": 69.0, "batch_reward": 0.8134616083502769, "actor_loss": -80.05125550842286, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.462462425231934, "episode_reward": 959.2717368305675, "step": 69000}
{"episode": 70.0, "batch_reward": 0.8113629015088082, "actor_loss": -79.5140058746338, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 435.4926600456238, "episode_reward": 914.4744814981691, "step": 70000}
{"episode": 70.0, "batch_reward": 0.8113629015088082, "actor_loss": -79.5140058746338, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 434.22953248023987, "episode_reward": 914.4744814981691, "step": 70000}
{"episode": 71.0, "batch_reward": 0.814600082218647, "actor_loss": -79.63457431030274, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 38.621410608291626, "episode_reward": 908.538843140388, "step": 71000}
{"episode": 71.0, "batch_reward": 0.814600082218647, "actor_loss": -79.63457431030274, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 37.397751331329346, "episode_reward": 908.538843140388, "step": 71000}
{"episode": 72.0, "batch_reward": 0.8154702659249305, "actor_loss": -79.91596127319336, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 438.9359817504883, "episode_reward": 885.5287645608288, "step": 72000}
{"episode": 73.0, "batch_reward": 0.8172408298850059, "actor_loss": -79.95995666503906, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.506534576416016, "episode_reward": 897.2299681330938, "step": 73000}
{"episode": 72.0, "batch_reward": 0.8154702659249305, "actor_loss": -79.91596127319336, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.80382013320923, "episode_reward": 885.5287645608288, "step": 72000}
{"episode": 73.0, "batch_reward": 0.8172408298850059, "actor_loss": -79.95995666503906, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.748197078704834, "episode_reward": 897.2299681330938, "step": 73000}
{"episode": 74.0, "batch_reward": 0.816357775747776, "actor_loss": -80.05964022827149, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 433.61253452301025, "episode_reward": 877.0295156546495, "step": 74000}
{"episode": 75.0, "batch_reward": 0.8202021233439446, "actor_loss": -80.28660289001465, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.374180555343628, "episode_reward": 940.5343430274628, "step": 75000}
{"episode": 74.0, "batch_reward": 0.816357775747776, "actor_loss": -80.05964022827149, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 435.39673113822937, "episode_reward": 877.0295156546495, "step": 74000}
{"episode": 75.0, "batch_reward": 0.8202021233439446, "actor_loss": -80.28660289001465, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.56576943397522, "episode_reward": 940.5343430274628, "step": 75000}
{"episode": 76.0, "batch_reward": 0.8187610436081886, "actor_loss": -79.33268060302734, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 442.1854271888733, "episode_reward": 765.6036875050642, "step": 76000}
{"episode": 77.0, "batch_reward": 0.8200871852636338, "actor_loss": -79.56049211120606, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 15.694710731506348, "episode_reward": 855.2013387698296, "step": 77000}
{"episode": 76.0, "batch_reward": 0.8187610436081886, "actor_loss": -79.33268060302734, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 436.2063457965851, "episode_reward": 765.6036875050642, "step": 76000}
{"episode": 77.0, "batch_reward": 0.8200871852636338, "actor_loss": -79.56049211120606, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.017035722732544, "episode_reward": 855.2013387698296, "step": 77000}
{"episode": 78.0, "batch_reward": 0.8199791626334191, "actor_loss": -79.60148895263671, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 440.83223819732666, "episode_reward": 803.2577165593232, "step": 78000}
{"episode": 79.0, "batch_reward": 0.8214543304443359, "actor_loss": -79.64779579162598, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.94689679145813, "episode_reward": 883.928768097982, "step": 79000}
{"episode": 78.0, "batch_reward": 0.8199791626334191, "actor_loss": -79.60148895263671, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 443.0108759403229, "episode_reward": 803.2577165593232, "step": 78000}
{"episode": 79.0, "batch_reward": 0.8214543304443359, "actor_loss": -79.64779579162598, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.394242525100708, "episode_reward": 883.928768097982, "step": 79000}
{"episode": 80.0, "batch_reward": 0.8211355248689651, "actor_loss": -79.47540943908692, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 432.353675365448, "episode_reward": 883.8786765656873, "step": 80000}
{"episode": 80.0, "batch_reward": 0.8211355248689651, "actor_loss": -79.47540943908692, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 432.12827706336975, "episode_reward": 883.8786765656873, "step": 80000}
{"episode": 81.0, "batch_reward": 0.821829099714756, "actor_loss": -79.47073133850098, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.161571741104126, "episode_reward": 884.4085644711213, "step": 81000}
{"episode": 81.0, "batch_reward": 0.821829099714756, "actor_loss": -79.47073133850098, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.936601638793945, "episode_reward": 884.4085644711213, "step": 81000}
{"episode": 82.0, "batch_reward": 0.8220066925883294, "actor_loss": -79.75414707946777, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 442.5821166038513, "episode_reward": 824.5795094625108, "step": 82000}
{"episode": 83.0, "batch_reward": 0.824142700791359, "actor_loss": -79.8779815826416, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.510978937149048, "episode_reward": 873.9861213037034, "step": 83000}
{"episode": 82.0, "batch_reward": 0.8220066925883294, "actor_loss": -79.75414707946777, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 435.65899562835693, "episode_reward": 824.5795094625108, "step": 82000}
{"episode": 83.0, "batch_reward": 0.824142700791359, "actor_loss": -79.8779815826416, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.990604162216187, "episode_reward": 873.9861213037034, "step": 83000}
{"episode": 84.0, "batch_reward": 0.8246428423523903, "actor_loss": -80.1698123474121, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.717919588089, "episode_reward": 969.9435665972642, "step": 84000}
{"episode": 85.0, "batch_reward": 0.8250570310354233, "actor_loss": -80.23119651794434, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.660844802856445, "episode_reward": 933.2303630692336, "step": 85000}
{"episode": 84.0, "batch_reward": 0.8246428423523903, "actor_loss": -80.1698123474121, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 440.4103353023529, "episode_reward": 969.9435665972642, "step": 84000}
{"episode": 85.0, "batch_reward": 0.8250570310354233, "actor_loss": -80.23119651794434, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.44020390510559, "episode_reward": 933.2303630692336, "step": 85000}
{"episode": 86.0, "batch_reward": 0.8261386172771454, "actor_loss": -80.39627810668945, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 437.27780985832214, "episode_reward": 856.0739125425706, "step": 86000}
{"episode": 87.0, "batch_reward": 0.8262371564507485, "actor_loss": -80.43904981994629, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.272417783737183, "episode_reward": 923.8935383413525, "step": 87000}
{"episode": 86.0, "batch_reward": 0.8261386172771454, "actor_loss": -80.39627810668945, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 438.4721927642822, "episode_reward": 856.0739125425706, "step": 86000}
{"episode": 87.0, "batch_reward": 0.8262371564507485, "actor_loss": -80.43904981994629, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.249304056167603, "episode_reward": 923.8935383413525, "step": 87000}
{"episode": 88.0, "batch_reward": 0.8279278582334518, "actor_loss": -80.28434294128418, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 434.4458374977112, "episode_reward": 871.4609892346713, "step": 88000}
{"episode": 89.0, "batch_reward": 0.826117225766182, "actor_loss": -80.25134443664551, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.804565906524658, "episode_reward": 806.6135793122427, "step": 89000}
{"episode": 88.0, "batch_reward": 0.8279278582334518, "actor_loss": -80.28434294128418, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 433.4848177433014, "episode_reward": 871.4609892346713, "step": 88000}
{"episode": 89.0, "batch_reward": 0.826117225766182, "actor_loss": -80.25134443664551, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.317777156829834, "episode_reward": 806.6135793122427, "step": 89000}
{"episode": 90.0, "batch_reward": 0.828753599703312, "actor_loss": -80.22639848327637, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 433.55474948883057, "episode_reward": 853.4943236125256, "step": 90000}
{"episode": 90.0, "batch_reward": 0.828753599703312, "actor_loss": -80.22639848327637, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 432.97150778770447, "episode_reward": 853.4943236125256, "step": 90000}
{"episode": 91.0, "batch_reward": 0.8279101248979569, "actor_loss": -80.1926979522705, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 38.14740467071533, "episode_reward": 533.0165638481286, "step": 91000}
{"episode": 91.0, "batch_reward": 0.8279101248979569, "actor_loss": -80.1926979522705, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 38.204689025878906, "episode_reward": 533.0165638481286, "step": 91000}
{"episode": 92.0, "batch_reward": 0.824917218208313, "actor_loss": -79.95453480529785, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 434.80149006843567, "episode_reward": 901.6794191237063, "step": 92000}
{"episode": 93.0, "batch_reward": 0.824563151717186, "actor_loss": -80.00597012329102, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.744218826293945, "episode_reward": 787.4526804805952, "step": 93000}
{"episode": 92.0, "batch_reward": 0.824917218208313, "actor_loss": -79.95453480529785, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 433.5468063354492, "episode_reward": 901.6794191237063, "step": 92000}
{"episode": 93.0, "batch_reward": 0.824563151717186, "actor_loss": -80.00597012329102, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.806665182113647, "episode_reward": 787.4526804805952, "step": 93000}
{"episode": 94.0, "batch_reward": 0.8259136800169945, "actor_loss": -79.12818634033204, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.6633553504944, "episode_reward": 922.8881714489572, "step": 94000}
{"episode": 95.0, "batch_reward": 0.8256599894762039, "actor_loss": -79.10692630004883, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.871817350387573, "episode_reward": 883.7959590012388, "step": 95000}
{"episode": 94.0, "batch_reward": 0.8259136800169945, "actor_loss": -79.12818634033204, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.98739886283875, "episode_reward": 922.8881714489572, "step": 94000}
{"episode": 95.0, "batch_reward": 0.8256599894762039, "actor_loss": -79.10692630004883, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.027769327163696, "episode_reward": 883.7959590012388, "step": 95000}
{"episode": 96.0, "batch_reward": 0.8265746270418167, "actor_loss": -79.13745948791504, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 437.01748847961426, "episode_reward": 808.7773807821765, "step": 96000}
{"episode": 97.0, "batch_reward": 0.8259801396131515, "actor_loss": -79.16909243774414, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.76741361618042, "episode_reward": 785.5310508701552, "step": 97000}
{"episode": 96.0, "batch_reward": 0.8265746270418167, "actor_loss": -79.13745948791504, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 435.3076801300049, "episode_reward": 808.7773807821765, "step": 96000}
{"episode": 97.0, "batch_reward": 0.8259801396131515, "actor_loss": -79.16909243774414, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.556418418884277, "episode_reward": 785.5310508701552, "step": 97000}
{"episode": 98.0, "batch_reward": 0.8259107329845429, "actor_loss": -78.7116011352539, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.55496287345886, "episode_reward": 883.818146618654, "step": 98000}
{"episode": 99.0, "batch_reward": 0.8280434326529503, "actor_loss": -78.8006983947754, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.140342235565186, "episode_reward": 848.5127061174969, "step": 99000}
{"episode": 98.0, "batch_reward": 0.8259107329845429, "actor_loss": -78.7116011352539, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 435.7636811733246, "episode_reward": 883.818146618654, "step": 98000}
{"episode": 99.0, "batch_reward": 0.8280434326529503, "actor_loss": -78.8006983947754, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 15.87839674949646, "episode_reward": 848.5127061174969, "step": 99000}
{"episode": 100.0, "batch_reward": 0.8267005194425583, "actor_loss": -78.66402644348145, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 435.02603363990784, "episode_reward": 818.2491276368339, "step": 100000}
{"episode": 100.0, "batch_reward": 0.8267005194425583, "actor_loss": -78.66402644348145, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 439.0095901489258, "episode_reward": 818.2491276368339, "step": 100000}
{"episode": 101.0, "batch_reward": 0.8276296070814133, "actor_loss": -78.73250942993164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.62461018562317, "episode_reward": 913.3353129254341, "step": 101000}
{"episode": 101.0, "batch_reward": 0.8276296070814133, "actor_loss": -78.73250942993164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.197922229766846, "episode_reward": 913.3353129254341, "step": 101000}
{"episode": 102.0, "batch_reward": 0.8283594930171967, "actor_loss": -78.30676475524902, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 435.8045313358307, "episode_reward": 918.695377867264, "step": 102000}
{"episode": 103.0, "batch_reward": 0.8285495871901513, "actor_loss": -78.35935020446777, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.33548092842102, "episode_reward": 837.5351775557738, "step": 103000}
{"episode": 102.0, "batch_reward": 0.8283594930171967, "actor_loss": -78.30676475524902, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 434.428524017334, "episode_reward": 918.695377867264, "step": 102000}
{"episode": 103.0, "batch_reward": 0.8285495871901513, "actor_loss": -78.35935020446777, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.682209253311157, "episode_reward": 837.5351775557738, "step": 103000}
{"episode": 104.0, "batch_reward": 0.8285772011876106, "actor_loss": -78.33943521118164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 442.4645290374756, "episode_reward": 854.1682554753686, "step": 104000}
{"episode": 105.0, "batch_reward": 0.8280681553483009, "actor_loss": -78.27092858886719, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.089650630950928, "episode_reward": 883.4116284714314, "step": 105000}
{"episode": 104.0, "batch_reward": 0.8285772011876106, "actor_loss": -78.33943521118164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 438.39028549194336, "episode_reward": 854.1682554753686, "step": 104000}
{"episode": 105.0, "batch_reward": 0.8280681553483009, "actor_loss": -78.27092858886719, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.343081951141357, "episode_reward": 883.4116284714314, "step": 105000}
{"episode": 106.0, "batch_reward": 0.8295862122178078, "actor_loss": -78.77987174987793, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 427.13921308517456, "episode_reward": 925.1612078850907, "step": 106000}
{"episode": 107.0, "batch_reward": 0.8296550832390786, "actor_loss": -78.69553501892089, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.44381022453308, "episode_reward": 869.3456668404687, "step": 107000}
{"episode": 106.0, "batch_reward": 0.8295862122178078, "actor_loss": -78.77987174987793, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 429.24536991119385, "episode_reward": 925.1612078850907, "step": 106000}
{"episode": 107.0, "batch_reward": 0.8296550832390786, "actor_loss": -78.69553501892089, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.891819715499878, "episode_reward": 869.3456668404687, "step": 107000}
{"episode": 108.0, "batch_reward": 0.831134306550026, "actor_loss": -78.63725177001953, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 424.0629940032959, "episode_reward": 928.5500390316678, "step": 108000}
{"episode": 109.0, "batch_reward": 0.8314462723135948, "actor_loss": -78.61225451660157, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.33801770210266, "episode_reward": 945.7487244672344, "step": 109000}
{"episode": 108.0, "batch_reward": 0.831134306550026, "actor_loss": -78.63725177001953, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 420.2849760055542, "episode_reward": 928.5500390316678, "step": 108000}
{"episode": 109.0, "batch_reward": 0.8314462723135948, "actor_loss": -78.61225451660157, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.752788543701172, "episode_reward": 945.7487244672344, "step": 109000}
{"episode": 110.0, "batch_reward": 0.8333283521533013, "actor_loss": -79.21247758483887, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 433.017324924469, "episode_reward": 897.3934000229084, "step": 110000}
{"episode": 110.0, "batch_reward": 0.8333283521533013, "actor_loss": -79.21247758483887, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 431.6322121620178, "episode_reward": 897.3934000229084, "step": 110000}
{"episode": 111.0, "batch_reward": 0.832635052204132, "actor_loss": -79.20172904968261, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 37.91931366920471, "episode_reward": 890.4285263240555, "step": 111000}
{"episode": 111.0, "batch_reward": 0.832635052204132, "actor_loss": -79.20172904968261, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 36.934226751327515, "episode_reward": 890.4285263240555, "step": 111000}
{"episode": 112.0, "batch_reward": 0.8321331228017808, "actor_loss": -79.2298316192627, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 433.0241277217865, "episode_reward": 747.9098759117862, "step": 112000}
{"episode": 113.0, "batch_reward": 0.8333539046645164, "actor_loss": -79.30454852294922, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.771331310272217, "episode_reward": 803.3242610605464, "step": 113000}
{"episode": 112.0, "batch_reward": 0.8321331228017808, "actor_loss": -79.2298316192627, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 435.0575921535492, "episode_reward": 747.9098759117862, "step": 112000}
{"episode": 113.0, "batch_reward": 0.8333539046645164, "actor_loss": -79.30454852294922, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.386260271072388, "episode_reward": 803.3242610605464, "step": 113000}
{"episode": 114.0, "batch_reward": 0.8336732806563377, "actor_loss": -79.49155307006836, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 441.82841420173645, "episode_reward": 944.6241484151061, "step": 114000}
{"episode": 115.0, "batch_reward": 0.8348562719225884, "actor_loss": -79.53079667663575, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.15279483795166, "episode_reward": 876.4342191127015, "step": 115000}
{"episode": 114.0, "batch_reward": 0.8336732806563377, "actor_loss": -79.49155307006836, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 437.96060252189636, "episode_reward": 944.6241484151061, "step": 114000}
{"episode": 115.0, "batch_reward": 0.8348562719225884, "actor_loss": -79.53079667663575, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.080660581588745, "episode_reward": 876.4342191127015, "step": 115000}
{"episode": 116.0, "batch_reward": 0.8337588135004044, "actor_loss": -79.23967750549316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 436.2705326080322, "episode_reward": 804.6732638188843, "step": 116000}
{"episode": 117.0, "batch_reward": 0.8339893767237663, "actor_loss": -79.30206349182129, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.565014600753784, "episode_reward": 823.0201578227039, "step": 117000}
{"episode": 116.0, "batch_reward": 0.8337588135004044, "actor_loss": -79.23967750549316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 438.5298728942871, "episode_reward": 804.6732638188843, "step": 116000}
{"episode": 117.0, "batch_reward": 0.8339893767237663, "actor_loss": -79.30206349182129, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.8698832988739, "episode_reward": 823.0201578227039, "step": 117000}
{"episode": 118.0, "batch_reward": 0.8339532374739647, "actor_loss": -79.33249475097657, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 436.56922030448914, "episode_reward": 785.3696083887526, "step": 118000}
{"episode": 119.0, "batch_reward": 0.8319875590801239, "actor_loss": -79.38273574829101, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.98687481880188, "episode_reward": 673.9929088691943, "step": 119000}
{"episode": 118.0, "batch_reward": 0.8339532374739647, "actor_loss": -79.33249475097657, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 435.4799733161926, "episode_reward": 785.3696083887526, "step": 118000}
{"episode": 119.0, "batch_reward": 0.8319875590801239, "actor_loss": -79.38273574829101, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.909722566604614, "episode_reward": 673.9929088691943, "step": 119000}
{"episode": 120.0, "batch_reward": 0.8324609534740448, "actor_loss": -79.68670672607422, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 443.7946982383728, "episode_reward": 752.9373120024493, "step": 120000}
{"episode": 120.0, "batch_reward": 0.8324609534740448, "actor_loss": -79.68670672607422, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 442.31634306907654, "episode_reward": 752.9373120024493, "step": 120000}
{"episode": 121.0, "batch_reward": 0.8302344646453858, "actor_loss": -79.64098365783691, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 38.762094259262085, "episode_reward": 835.4862869022119, "step": 121000}
{"episode": 121.0, "batch_reward": 0.8302344646453858, "actor_loss": -79.64098365783691, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 38.412556409835815, "episode_reward": 835.4862869022119, "step": 121000}
{"episode": 122.0, "batch_reward": 0.8313397707939147, "actor_loss": -79.19851683044433, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 440.41908025741577, "episode_reward": 801.1901410720538, "step": 122000}
{"episode": 123.0, "batch_reward": 0.8302442667484283, "actor_loss": -79.1458397064209, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.275113105773926, "episode_reward": 754.1660508752935, "step": 123000}
{"episode": 122.0, "batch_reward": 0.8313397707939147, "actor_loss": -79.19851683044433, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 440.57661986351013, "episode_reward": 801.1901410720538, "step": 122000}
{"episode": 123.0, "batch_reward": 0.8302442667484283, "actor_loss": -79.1458397064209, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.841827392578125, "episode_reward": 754.1660508752935, "step": 123000}
{"episode": 124.0, "batch_reward": 0.8301734277009964, "actor_loss": -79.15962910461425, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 424.35813546180725, "episode_reward": 874.7694753920345, "step": 124000}
{"episode": 125.0, "batch_reward": 0.829416576385498, "actor_loss": -79.15134898376465, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.450851917266846, "episode_reward": 892.1871763713532, "step": 125000}
{"episode": 124.0, "batch_reward": 0.8301734277009964, "actor_loss": -79.15962910461425, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 423.49268412590027, "episode_reward": 874.7694753920345, "step": 124000}
{"episode": 125.0, "batch_reward": 0.829416576385498, "actor_loss": -79.15134898376465, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 15.893994808197021, "episode_reward": 892.1871763713532, "step": 125000}
{"episode": 126.0, "batch_reward": 0.8329960380196572, "actor_loss": -79.3437349395752, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 418.8796660900116, "episode_reward": 885.2635049895413, "step": 126000}
{"episode": 126.0, "batch_reward": 0.8329960380196572, "actor_loss": -79.3437349395752, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 421.19126892089844, "episode_reward": 885.2635049895413, "step": 126000}
{"episode": 127.0, "batch_reward": 0.8313386861085892, "actor_loss": -79.37416780090332, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.83809542655945, "episode_reward": 822.5972443456087, "step": 127000}
{"episode": 127.0, "batch_reward": 0.8313386861085892, "actor_loss": -79.37416780090332, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.88306164741516, "episode_reward": 822.5972443456087, "step": 127000}
{"episode": 128.0, "batch_reward": 0.8320589974522591, "actor_loss": -79.38487226867676, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 424.9745135307312, "episode_reward": 652.4376853820056, "step": 128000}
{"episode": 128.0, "batch_reward": 0.8320589974522591, "actor_loss": -79.38487226867676, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 421.78078031539917, "episode_reward": 652.4376853820056, "step": 128000}
{"episode": 129.0, "batch_reward": 0.8312221533060073, "actor_loss": -79.36496974182128, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.67368483543396, "episode_reward": 645.2973258491166, "step": 129000}
{"episode": 129.0, "batch_reward": 0.8312221533060073, "actor_loss": -79.36496974182128, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.812973976135254, "episode_reward": 645.2973258491166, "step": 129000}
{"episode": 130.0, "batch_reward": 0.8293602751493454, "actor_loss": -79.18975692749024, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 421.85389614105225, "episode_reward": 819.0653885839188, "step": 130000}
{"episode": 130.0, "batch_reward": 0.8293602751493454, "actor_loss": -79.18975692749024, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 420.701664686203, "episode_reward": 819.0653885839188, "step": 130000}
{"episode": 131.0, "batch_reward": 0.8280767585635185, "actor_loss": -79.17736541748047, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 37.8996479511261, "episode_reward": 914.9088003606837, "step": 131000}
{"episode": 131.0, "batch_reward": 0.8280767585635185, "actor_loss": -79.17736541748047, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 38.958709955215454, "episode_reward": 914.9088003606837, "step": 131000}
{"episode": 132.0, "batch_reward": 0.82876220870018, "actor_loss": -79.25104013061524, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 424.09440755844116, "episode_reward": 739.6693512133353, "step": 132000}
{"episode": 132.0, "batch_reward": 0.82876220870018, "actor_loss": -79.25104013061524, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 421.87008595466614, "episode_reward": 739.6693512133353, "step": 132000}
{"episode": 133.0, "batch_reward": 0.8288953613638878, "actor_loss": -79.28819326782227, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.844083547592163, "episode_reward": 818.2981935260659, "step": 133000}
{"episode": 133.0, "batch_reward": 0.8288953613638878, "actor_loss": -79.28819326782227, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.86384654045105, "episode_reward": 818.2981935260659, "step": 133000}
{"episode": 134.0, "batch_reward": 0.8304533061385154, "actor_loss": -79.26109568786622, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 440.3698239326477, "episode_reward": 866.429809126942, "step": 134000}
{"episode": 134.0, "batch_reward": 0.8304533061385154, "actor_loss": -79.26109568786622, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 440.07799673080444, "episode_reward": 866.429809126942, "step": 134000}
{"episode": 135.0, "batch_reward": 0.8295298691987991, "actor_loss": -79.23438487243652, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.50970697402954, "episode_reward": 936.231254519207, "step": 135000}
{"episode": 135.0, "batch_reward": 0.8295298691987991, "actor_loss": -79.23438487243652, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.906854391098022, "episode_reward": 936.231254519207, "step": 135000}
{"episode": 136.0, "batch_reward": 0.8307783377766609, "actor_loss": -79.08049024963378, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 425.8583674430847, "episode_reward": 862.0590361468473, "step": 136000}
{"episode": 136.0, "batch_reward": 0.8307783377766609, "actor_loss": -79.08049024963378, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 424.83169770240784, "episode_reward": 862.0590361468473, "step": 136000}
{"episode": 137.0, "batch_reward": 0.8312366591095924, "actor_loss": -79.08122155761718, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.99477481842041, "episode_reward": 921.734533202065, "step": 137000}
{"episode": 137.0, "batch_reward": 0.8312366591095924, "actor_loss": -79.08122155761718, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.826725482940674, "episode_reward": 921.734533202065, "step": 137000}
{"episode": 138.0, "batch_reward": 0.831397124171257, "actor_loss": -79.78426327514649, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 422.8774905204773, "episode_reward": 856.5891524623868, "step": 138000}
{"episode": 138.0, "batch_reward": 0.831397124171257, "actor_loss": -79.78426327514649, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 421.6225781440735, "episode_reward": 856.5891524623868, "step": 138000}
{"episode": 139.0, "batch_reward": 0.8307289626002312, "actor_loss": -79.77903483581542, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 15.688797235488892, "episode_reward": 852.9547146850622, "step": 139000}
{"episode": 139.0, "batch_reward": 0.8307289626002312, "actor_loss": -79.77903483581542, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 15.761666297912598, "episode_reward": 852.9547146850622, "step": 139000}
{"episode": 140.0, "batch_reward": 0.8329371429681778, "actor_loss": -79.73759255981446, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 420.40349817276, "episode_reward": 873.6097944961887, "step": 140000}
{"episode": 140.0, "batch_reward": 0.8329371429681778, "actor_loss": -79.73759255981446, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 422.0807104110718, "episode_reward": 873.6097944961887, "step": 140000}
{"episode": 141.0, "batch_reward": 0.8303552459478378, "actor_loss": -79.73563645935059, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.75477623939514, "episode_reward": 928.3127066983559, "step": 141000}
{"episode": 141.0, "batch_reward": 0.8303552459478378, "actor_loss": -79.73563645935059, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.294549226760864, "episode_reward": 928.3127066983559, "step": 141000}
{"episode": 142.0, "batch_reward": 0.8320298379063606, "actor_loss": -79.67853605651855, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 411.15723037719727, "episode_reward": 937.15415336555, "step": 142000}
{"episode": 142.0, "batch_reward": 0.8320298379063606, "actor_loss": -79.67853605651855, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 409.28173828125, "episode_reward": 937.15415336555, "step": 142000}
{"episode": 143.0, "batch_reward": 0.8323895053267479, "actor_loss": -79.69489625549316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.50774073600769, "episode_reward": 803.0551521136671, "step": 143000}
{"episode": 143.0, "batch_reward": 0.8323895053267479, "actor_loss": -79.69489625549316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.89797806739807, "episode_reward": 803.0551521136671, "step": 143000}
{"episode": 144.0, "batch_reward": 0.8316535586714745, "actor_loss": -79.86675225830078, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 424.8819146156311, "episode_reward": 897.0637632975037, "step": 144000}
{"episode": 144.0, "batch_reward": 0.8316535586714745, "actor_loss": -79.86675225830078, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 424.40782499313354, "episode_reward": 897.0637632975037, "step": 144000}
{"episode": 145.0, "batch_reward": 0.833993457198143, "actor_loss": -79.90572850036621, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.852888822555542, "episode_reward": 957.1725459255052, "step": 145000}
{"episode": 145.0, "batch_reward": 0.833993457198143, "actor_loss": -79.90572850036621, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 17.244889736175537, "episode_reward": 957.1725459255052, "step": 145000}
{"episode": 146.0, "batch_reward": 0.8334220615625382, "actor_loss": -79.69189286804199, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 422.07511281967163, "episode_reward": 925.0952385640787, "step": 146000}
{"episode": 146.0, "batch_reward": 0.8334220615625382, "actor_loss": -79.69189286804199, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 421.51505994796753, "episode_reward": 925.0952385640787, "step": 146000}
{"episode": 147.0, "batch_reward": 0.8338200253844261, "actor_loss": -79.7138258972168, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.629926204681396, "episode_reward": 835.5083177319674, "step": 147000}
{"episode": 147.0, "batch_reward": 0.8338200253844261, "actor_loss": -79.7138258972168, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 18.83348798751831, "episode_reward": 835.5083177319674, "step": 147000}
{"episode": 148.0, "batch_reward": 0.834842054605484, "actor_loss": -80.12737335205078, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 447.9607141017914, "episode_reward": 952.8429527547945, "step": 148000}
{"episode": 148.0, "batch_reward": 0.834842054605484, "actor_loss": -80.12737335205078, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 445.1038534641266, "episode_reward": 952.8429527547945, "step": 148000}
{"episode": 149.0, "batch_reward": 0.8352590630054474, "actor_loss": -80.21878637695312, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.905956268310547, "episode_reward": 898.5505015551114, "step": 149000}
{"episode": 149.0, "batch_reward": 0.8352590630054474, "actor_loss": -80.21878637695312, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 16.607213497161865, "episode_reward": 898.5505015551114, "step": 149000}
{"episode": 150.0, "batch_reward": 0.8344520528316498, "actor_loss": -80.19864680480957, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
{"episode": 150.0, "batch_reward": 0.8344520528316498, "actor_loss": -80.19864680480957, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
