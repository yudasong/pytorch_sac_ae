{"episode_reward": 0.0, "episode": 1.0, "duration": 20.5164213180542, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.7850031852722168, "step": 2000}
{"episode_reward": 981.6628711771527, "episode": 3.0, "batch_reward": 0.5479056311770653, "critic_loss": 0.21596461072534312, "actor_loss": -90.0887231601625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.116331338882446, "step": 3000}
{"episode_reward": 958.6272203709119, "episode": 4.0, "batch_reward": 0.6939445067048072, "critic_loss": 0.21107903920859097, "actor_loss": -95.45747483825684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92543935775757, "step": 4000}
{"episode_reward": 933.4439650013809, "episode": 5.0, "batch_reward": 0.7543764742016792, "critic_loss": 0.22554874151200055, "actor_loss": -96.8396787109375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91265606880188, "step": 5000}
{"episode_reward": 954.8400360195193, "episode": 6.0, "batch_reward": 0.7910291537642479, "critic_loss": 0.2169308932647109, "actor_loss": -97.28294155883789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.914416551589966, "step": 6000}
{"episode_reward": 968.0077771666166, "episode": 7.0, "batch_reward": 0.7984792749881744, "critic_loss": 0.2418182458281517, "actor_loss": -97.23842384338379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.921133279800415, "step": 7000}
{"episode_reward": 827.040935503161, "episode": 8.0, "batch_reward": 0.8190261731147767, "critic_loss": 0.20249801345914603, "actor_loss": -97.54379318237305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.930018186569214, "step": 8000}
{"episode_reward": 951.0636798176957, "episode": 9.0, "batch_reward": 0.7827772469520569, "critic_loss": 0.2077109131515026, "actor_loss": -96.86371842956542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.973342657089233, "step": 9000}
{"episode_reward": 27.703957630844176, "episode": 10.0, "batch_reward": 0.7486772162914276, "critic_loss": 0.2350492016747594, "actor_loss": -96.56533340454102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.940980672836304, "step": 10000}
{"episode_reward": 923.1531501761067, "episode": 11.0, "batch_reward": 0.7654217128157615, "critic_loss": 0.3341033766269684, "actor_loss": -96.32405110168457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.23660111427307, "step": 11000}
{"episode_reward": 949.9474411474646, "episode": 12.0, "batch_reward": 0.7737812809944152, "critic_loss": 0.4564788509011269, "actor_loss": -96.71736563110352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.922709226608276, "step": 12000}
{"episode_reward": 859.4283754394913, "episode": 13.0, "batch_reward": 0.7853989522457123, "critic_loss": 0.34500520379841326, "actor_loss": -96.89009829711914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.917714834213257, "step": 13000}
{"episode_reward": 924.1377817867799, "episode": 14.0, "batch_reward": 0.7988803294301033, "critic_loss": 0.2775798381716013, "actor_loss": -97.51014646911621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92544674873352, "step": 14000}
{"episode_reward": 926.6544317797865, "episode": 15.0, "batch_reward": 0.8077462178468704, "critic_loss": 0.2688063814342022, "actor_loss": -97.6323103942871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92660665512085, "step": 15000}
{"episode_reward": 953.072753662637, "episode": 16.0, "batch_reward": 0.8159555068612099, "critic_loss": 0.25905686013400553, "actor_loss": -98.03648092651368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.920950174331665, "step": 16000}
{"episode_reward": 912.3529885169697, "episode": 17.0, "batch_reward": 0.8186663622856141, "critic_loss": 0.2789153972864151, "actor_loss": -98.23760755920411, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.933169841766357, "step": 17000}
{"episode_reward": 912.878891923308, "episode": 18.0, "batch_reward": 0.8276186081767082, "critic_loss": 0.2623306823819876, "actor_loss": -98.6233235321045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.915221214294434, "step": 18000}
{"episode_reward": 950.4372442210647, "episode": 19.0, "batch_reward": 0.835804470539093, "critic_loss": 0.23148361506313087, "actor_loss": -98.33505680847168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.923738479614258, "step": 19000}
{"episode_reward": 986.3563070470569, "episode": 20.0, "batch_reward": 0.8433683683276176, "critic_loss": 0.26978977684676647, "actor_loss": -98.63661386108399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92375111579895, "step": 20000}
{"episode_reward": 970.9535117168397, "episode": 21.0, "batch_reward": 0.8481469515562058, "critic_loss": 0.30409073588997126, "actor_loss": -98.63296296691894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.20423889160156, "step": 21000}
{"episode_reward": 937.5425618651274, "episode": 22.0, "batch_reward": 0.8545855766534806, "critic_loss": 0.2725027330219746, "actor_loss": -99.08332673645019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.950167179107666, "step": 22000}
{"episode_reward": 977.7491726724311, "episode": 23.0, "batch_reward": 0.8568206053376198, "critic_loss": 0.2958343777284026, "actor_loss": -99.38542425537109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.950256824493408, "step": 23000}
{"episode_reward": 923.560410899554, "episode": 24.0, "batch_reward": 0.8615952592492103, "critic_loss": 0.26263128595054147, "actor_loss": -99.10555206298828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.938883304595947, "step": 24000}
{"episode_reward": 974.9181893955716, "episode": 25.0, "batch_reward": 0.8646307358145714, "critic_loss": 0.2299507302120328, "actor_loss": -99.02391873168945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.927894115447998, "step": 25000}
{"episode_reward": 960.3340001775305, "episode": 26.0, "batch_reward": 0.8683012448549271, "critic_loss": 0.17317340954393148, "actor_loss": -98.88188204956055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.914912223815918, "step": 26000}
{"episode_reward": 978.0903225242578, "episode": 27.0, "batch_reward": 0.8749697313904762, "critic_loss": 0.16789252242073416, "actor_loss": -98.90570622253418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93539834022522, "step": 27000}
{"episode_reward": 978.704044461143, "episode": 28.0, "batch_reward": 0.8785883188247681, "critic_loss": 0.1726917585581541, "actor_loss": -98.89666775512696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.918013334274292, "step": 28000}
{"episode_reward": 962.8915061529123, "episode": 29.0, "batch_reward": 0.8789308840632438, "critic_loss": 0.19409532402455806, "actor_loss": -98.82404690551758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.919720888137817, "step": 29000}
{"episode_reward": 921.0386215020206, "episode": 30.0, "batch_reward": 0.8802586770653724, "critic_loss": 0.20897679979354142, "actor_loss": -98.60385195922852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.915677070617676, "step": 30000}
{"episode_reward": 865.5489789410949, "episode": 31.0, "batch_reward": 0.8811923378705978, "critic_loss": 0.17285319408029318, "actor_loss": -98.5454204711914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.17741870880127, "step": 31000}
{"episode_reward": 964.8548612915732, "episode": 32.0, "batch_reward": 0.8847158333659172, "critic_loss": 0.15737382234632968, "actor_loss": -98.22546401977539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.932766675949097, "step": 32000}
{"episode_reward": 969.2085218406553, "episode": 33.0, "batch_reward": 0.8855949087738991, "critic_loss": 0.17409703206270932, "actor_loss": -98.15934114074707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.933021068572998, "step": 33000}
{"episode_reward": 934.0380437882457, "episode": 34.0, "batch_reward": 0.8876542353630066, "critic_loss": 0.1662266561239958, "actor_loss": -98.34604841613769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.950095176696777, "step": 34000}
{"episode_reward": 978.3648498893654, "episode": 35.0, "batch_reward": 0.8885630553364754, "critic_loss": 0.16532108795642853, "actor_loss": -98.12184063720703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.937774896621704, "step": 35000}
{"episode_reward": 930.9334457271543, "episode": 36.0, "batch_reward": 0.8913091080784797, "critic_loss": 0.15751831007003783, "actor_loss": -98.10564511108399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93689250946045, "step": 36000}
{"episode_reward": 962.0074881551864, "episode": 37.0, "batch_reward": 0.8918863608837128, "critic_loss": 0.151889417052269, "actor_loss": -98.05955859375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.933748245239258, "step": 37000}
{"episode_reward": 950.2317195350688, "episode": 38.0, "batch_reward": 0.894888157248497, "critic_loss": 0.14636496206372976, "actor_loss": -98.03634573364258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.909749507904053, "step": 38000}
{"episode_reward": 971.5302746037072, "episode": 39.0, "batch_reward": 0.8964690491557121, "critic_loss": 0.1384575702883303, "actor_loss": -97.74734355163574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.923887491226196, "step": 39000}
{"episode_reward": 985.5998999443702, "episode": 40.0, "batch_reward": 0.8986198407411575, "critic_loss": 0.14983883921802044, "actor_loss": -97.72576176452637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.915834188461304, "step": 40000}
{"episode_reward": 964.646871001913, "episode": 41.0, "batch_reward": 0.9012873255610466, "critic_loss": 0.17254605109989643, "actor_loss": -97.6987978515625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.239280700683594, "step": 41000}
{"episode_reward": 931.3722310298548, "episode": 42.0, "batch_reward": 0.903108136177063, "critic_loss": 0.13921424190700055, "actor_loss": -97.86699534606933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93056583404541, "step": 42000}
{"episode_reward": 976.9163850813397, "episode": 43.0, "batch_reward": 0.9029951911568642, "critic_loss": 0.1574769487865269, "actor_loss": -97.71363124084472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.921850204467773, "step": 43000}
{"episode_reward": 894.8384030916436, "episode": 44.0, "batch_reward": 0.9036828761100769, "critic_loss": 0.15638786166906357, "actor_loss": -97.58551113891602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92625403404236, "step": 44000}
{"episode_reward": 969.982531068699, "episode": 45.0, "batch_reward": 0.9041507711410522, "critic_loss": 0.15162464878335596, "actor_loss": -97.44682032775879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.926697492599487, "step": 45000}
{"episode_reward": 956.1990547611828, "episode": 46.0, "batch_reward": 0.9059356899261475, "critic_loss": 0.16033381823822856, "actor_loss": -97.43102793884277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.917686939239502, "step": 46000}
{"episode_reward": 965.41990507893, "episode": 47.0, "batch_reward": 0.908741914331913, "critic_loss": 0.14591032423451541, "actor_loss": -97.5256072845459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.921364307403564, "step": 47000}
{"episode_reward": 976.5987305534808, "episode": 48.0, "batch_reward": 0.9064657332897186, "critic_loss": 0.17652940919995308, "actor_loss": -97.44984596252442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.944287061691284, "step": 48000}
{"episode_reward": 844.6593837694794, "episode": 49.0, "batch_reward": 0.9073123052716255, "critic_loss": 0.19748956398665904, "actor_loss": -97.36079821777344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95083999633789, "step": 49000}
{"episode_reward": 958.64555178471, "episode": 50.0, "batch_reward": 0.9088926184773445, "critic_loss": 0.15664456836134194, "actor_loss": -97.32324604797363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.927101850509644, "step": 50000}
{"episode_reward": 986.8595116439408, "episode": 51.0, "batch_reward": 0.9099186425209045, "critic_loss": 0.15558420449867844, "actor_loss": -97.37692942810058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.223304271698, "step": 51000}
{"episode_reward": 975.5133101538437, "episode": 52.0, "batch_reward": 0.9108912853598594, "critic_loss": 0.16448013420775534, "actor_loss": -97.2125149230957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.923535108566284, "step": 52000}
{"episode_reward": 963.0377189668646, "episode": 53.0, "batch_reward": 0.912180848300457, "critic_loss": 0.16627564235404133, "actor_loss": -97.21792622375489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.928449869155884, "step": 53000}
{"episode_reward": 923.2778513371663, "episode": 54.0, "batch_reward": 0.9104861296415329, "critic_loss": 0.20018272346630692, "actor_loss": -97.17093276977539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9209041595459, "step": 54000}
{"episode_reward": 874.4753273862372, "episode": 55.0, "batch_reward": 0.9117117760777473, "critic_loss": 0.16711622171476484, "actor_loss": -97.22590284729004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.922396421432495, "step": 55000}
{"episode_reward": 980.1387107800738, "episode": 56.0, "batch_reward": 0.9132043970227242, "critic_loss": 0.16852196673303843, "actor_loss": -97.1883824005127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.952451705932617, "step": 56000}
{"episode_reward": 990.101348022096, "episode": 57.0, "batch_reward": 0.9136924915313721, "critic_loss": 0.19810867477580904, "actor_loss": -97.0571731414795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94841718673706, "step": 57000}
{"episode_reward": 918.7391012268891, "episode": 58.0, "batch_reward": 0.9156124349832535, "critic_loss": 0.1746746112331748, "actor_loss": -97.15394903564453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.937893390655518, "step": 58000}
{"episode_reward": 984.6469053647087, "episode": 59.0, "batch_reward": 0.9166399161219597, "critic_loss": 0.1731614546738565, "actor_loss": -97.05923675537109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93260359764099, "step": 59000}
{"episode_reward": 962.3883895033629, "episode": 60.0, "batch_reward": 0.9165670630335808, "critic_loss": 0.17051376527175308, "actor_loss": -97.07729914855958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92639446258545, "step": 60000}
{"episode_reward": 965.7290774363163, "episode": 61.0, "batch_reward": 0.9161109240651131, "critic_loss": 0.19799472802877427, "actor_loss": -96.98423170471192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.20011019706726, "step": 61000}
{"episode_reward": 888.6605734052357, "episode": 62.0, "batch_reward": 0.9158284150958061, "critic_loss": 0.2013420266211033, "actor_loss": -97.00811352539063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95167875289917, "step": 62000}
{"episode_reward": 976.4353940669172, "episode": 63.0, "batch_reward": 0.9160202597379684, "critic_loss": 0.1881812567152083, "actor_loss": -96.8865842590332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.944213151931763, "step": 63000}
{"episode_reward": 920.9647803726967, "episode": 64.0, "batch_reward": 0.9173470479249954, "critic_loss": 0.1887184815518558, "actor_loss": -96.94707118225098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.955073356628418, "step": 64000}
{"episode_reward": 988.6591385306633, "episode": 65.0, "batch_reward": 0.9187115703821183, "critic_loss": 0.1993020700737834, "actor_loss": -96.94969010925293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98076629638672, "step": 65000}
{"episode_reward": 975.6548884778466, "episode": 66.0, "batch_reward": 0.9179152007102966, "critic_loss": 0.22841159686818718, "actor_loss": -96.88334690856934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95582365989685, "step": 66000}
{"episode_reward": 900.1462152112261, "episode": 67.0, "batch_reward": 0.9178085799217224, "critic_loss": 0.2288317604586482, "actor_loss": -96.7863208618164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.955267429351807, "step": 67000}
{"episode_reward": 889.1961946733686, "episode": 68.0, "batch_reward": 0.9183855159878731, "critic_loss": 0.21573982628434896, "actor_loss": -96.84882048034667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96024227142334, "step": 68000}
{"episode_reward": 964.6182257546461, "episode": 69.0, "batch_reward": 0.9194890966415405, "critic_loss": 0.1961843690685928, "actor_loss": -96.88258815002442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94585156440735, "step": 69000}
{"episode_reward": 987.6977289420838, "episode": 70.0, "batch_reward": 0.9202828145027161, "critic_loss": 0.23700017166882753, "actor_loss": -96.82000498962402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.956942081451416, "step": 70000}
{"episode_reward": 945.2432113448004, "episode": 71.0, "batch_reward": 0.9206004636287689, "critic_loss": 0.22324575178697706, "actor_loss": -96.84088342285156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.252821922302246, "step": 71000}
{"episode_reward": 953.9893845152866, "episode": 72.0, "batch_reward": 0.9212491341233253, "critic_loss": 0.22319994870573281, "actor_loss": -96.82234208679199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.021044731140137, "step": 72000}
{"episode_reward": 966.9748705120537, "episode": 73.0, "batch_reward": 0.9219758140444756, "critic_loss": 0.2331422811411321, "actor_loss": -96.83599606323243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.016664028167725, "step": 73000}
{"episode_reward": 959.5741273506619, "episode": 74.0, "batch_reward": 0.9237597956061363, "critic_loss": 0.2565653076171875, "actor_loss": -96.85056900024414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.009197235107422, "step": 74000}
{"episode_reward": 943.5886103880863, "episode": 75.0, "batch_reward": 0.9231969659924507, "critic_loss": 0.23695944963395596, "actor_loss": -96.79198554992676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94842767715454, "step": 75000}
{"episode_reward": 979.0067302033649, "episode": 76.0, "batch_reward": 0.9239890660047532, "critic_loss": 0.2904979719892144, "actor_loss": -96.78467178344727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.926517724990845, "step": 76000}
{"episode_reward": 983.9435231852852, "episode": 77.0, "batch_reward": 0.9241287994384766, "critic_loss": 0.24325305129215122, "actor_loss": -96.78487817382812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.925610303878784, "step": 77000}
{"episode_reward": 982.4816469484907, "episode": 78.0, "batch_reward": 0.9252395151257515, "critic_loss": 0.2403535860776901, "actor_loss": -96.83045269775391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93413281440735, "step": 78000}
{"episode_reward": 945.9859758055279, "episode": 79.0, "batch_reward": 0.9254497299790383, "critic_loss": 0.2508151913397014, "actor_loss": -96.89272163391114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92682147026062, "step": 79000}
{"episode_reward": 953.7606434982941, "episode": 80.0, "batch_reward": 0.9258700135946274, "critic_loss": 0.22520142183825373, "actor_loss": -96.92273472595215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93136191368103, "step": 80000}
{"episode_reward": 985.1901899531965, "episode": 81.0, "batch_reward": 0.9249770148396492, "critic_loss": 0.24681830913573505, "actor_loss": -96.88032527160645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.23218774795532, "step": 81000}
{"episode_reward": 825.5320342424122, "episode": 82.0, "batch_reward": 0.925292040348053, "critic_loss": 0.24029377396404744, "actor_loss": -96.85537588500976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92474913597107, "step": 82000}
{"episode_reward": 940.4996404263045, "episode": 83.0, "batch_reward": 0.9255705088973045, "critic_loss": 0.2395203258767724, "actor_loss": -96.89716989135742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.932154655456543, "step": 83000}
{"episode_reward": 932.6794671771631, "episode": 84.0, "batch_reward": 0.9260859095454216, "critic_loss": 0.22142354443669318, "actor_loss": -96.9399367980957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.975494384765625, "step": 84000}
{"episode_reward": 988.4846406245853, "episode": 85.0, "batch_reward": 0.9243090239167213, "critic_loss": 0.25484589334577323, "actor_loss": -96.86676565551758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.986027002334595, "step": 85000}
{"episode_reward": 926.9210923993232, "episode": 86.0, "batch_reward": 0.9263675029277801, "critic_loss": 0.23825853224098684, "actor_loss": -96.89631643676758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.967849254608154, "step": 86000}
{"episode_reward": 954.2068679691865, "episode": 87.0, "batch_reward": 0.9262412523627281, "critic_loss": 0.22699400933459402, "actor_loss": -96.90651399230957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.925111293792725, "step": 87000}
{"episode_reward": 967.2624302035173, "episode": 88.0, "batch_reward": 0.9275181984901428, "critic_loss": 0.24829393258690835, "actor_loss": -96.92329504394532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.936238765716553, "step": 88000}
{"episode_reward": 924.640983878691, "episode": 89.0, "batch_reward": 0.9260655393004418, "critic_loss": 0.2180200413800776, "actor_loss": -96.92467631530762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.931175708770752, "step": 89000}
{"episode_reward": 952.1459338275502, "episode": 90.0, "batch_reward": 0.9277195727229118, "critic_loss": 0.24962604470551014, "actor_loss": -96.91662535095215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.932674646377563, "step": 90000}
{"episode_reward": 947.893396404547, "episode": 91.0, "batch_reward": 0.927748123049736, "critic_loss": 0.23154028279334307, "actor_loss": -96.92573579406738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.22825002670288, "step": 91000}
{"episode_reward": 958.3652566714147, "episode": 92.0, "batch_reward": 0.9294371957778931, "critic_loss": 0.22351814647018908, "actor_loss": -96.94339624023438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.942692518234253, "step": 92000}
{"episode_reward": 969.4577101019325, "episode": 93.0, "batch_reward": 0.9271513614058494, "critic_loss": 0.22663953552395105, "actor_loss": -96.9018101348877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96543049812317, "step": 93000}
{"episode_reward": 984.5411075745637, "episode": 94.0, "batch_reward": 0.9278923034667969, "critic_loss": 0.2111915109939873, "actor_loss": -96.90325630187988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.944318056106567, "step": 94000}
{"episode_reward": 942.5714670854039, "episode": 95.0, "batch_reward": 0.9281937749385833, "critic_loss": 0.21088997274264693, "actor_loss": -96.88418338012696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.935930728912354, "step": 95000}
{"episode_reward": 959.0863114102349, "episode": 96.0, "batch_reward": 0.9291810575127601, "critic_loss": 0.195050127428025, "actor_loss": -96.94149908447265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.936858415603638, "step": 96000}
{"episode_reward": 951.614648946727, "episode": 97.0, "batch_reward": 0.929143310546875, "critic_loss": 0.21051963752508163, "actor_loss": -96.91949874877929, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92597532272339, "step": 97000}
{"episode_reward": 956.746874929759, "episode": 98.0, "batch_reward": 0.9296528858542442, "critic_loss": 0.22333398465439677, "actor_loss": -96.92573768615722, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93402862548828, "step": 98000}
{"episode_reward": 955.7173754701902, "episode": 99.0, "batch_reward": 0.9291482244729996, "critic_loss": 0.21694240198284387, "actor_loss": -96.96877372741699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.931180000305176, "step": 99000}
{"episode_reward": 953.8119926740368, "episode": 100.0, "batch_reward": 0.9308266493678093, "critic_loss": 0.19881037329882384, "actor_loss": -97.02636724853515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.944925546646118, "step": 100000}
{"episode_reward": 902.1310234229288, "episode": 101.0, "batch_reward": 0.9307342786192894, "critic_loss": 0.2035427973791957, "actor_loss": -96.97956074523925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.262171506881714, "step": 101000}
{"episode_reward": 975.3499602008484, "episode": 102.0, "batch_reward": 0.9310990613102913, "critic_loss": 0.22183202136680483, "actor_loss": -96.99967324829102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.937830209732056, "step": 102000}
{"episode_reward": 985.7166501195668, "episode": 103.0, "batch_reward": 0.9305390635728836, "critic_loss": 0.21784781070053577, "actor_loss": -96.947794631958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93274211883545, "step": 103000}
{"episode_reward": 962.3205744372435, "episode": 104.0, "batch_reward": 0.9319811609983444, "critic_loss": 0.20448341207951307, "actor_loss": -97.01409411621094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92518424987793, "step": 104000}
{"episode_reward": 925.7117882332337, "episode": 105.0, "batch_reward": 0.9324065536856652, "critic_loss": 0.22475107066333294, "actor_loss": -97.02869284057617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92756175994873, "step": 105000}
{"episode_reward": 930.9607630711514, "episode": 106.0, "batch_reward": 0.9317686356306076, "critic_loss": 0.2124559432975948, "actor_loss": -97.08253916931152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.916646003723145, "step": 106000}
{"episode_reward": 935.0773187081121, "episode": 107.0, "batch_reward": 0.9296640311479568, "critic_loss": 0.22385497491061687, "actor_loss": -96.95589825439453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.931513786315918, "step": 107000}
{"episode_reward": 930.0711850871015, "episode": 108.0, "batch_reward": 0.9322262315154075, "critic_loss": 0.2005073352381587, "actor_loss": -96.99864916992188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.926698923110962, "step": 108000}
{"episode_reward": 971.0040476121483, "episode": 109.0, "batch_reward": 0.9320540578365326, "critic_loss": 0.1955667188875377, "actor_loss": -96.95755815124512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.924067735671997, "step": 109000}
{"episode_reward": 982.6280093633193, "episode": 110.0, "batch_reward": 0.9322964485287666, "critic_loss": 0.19981249345466495, "actor_loss": -96.97782792663574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.930539846420288, "step": 110000}
{"episode_reward": 927.9507844498464, "episode": 111.0, "batch_reward": 0.9311445509791374, "critic_loss": 0.205457962308079, "actor_loss": -96.9660990447998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.28012013435364, "step": 111000}
{"episode_reward": 906.3211408610467, "episode": 112.0, "batch_reward": 0.931375327706337, "critic_loss": 0.23466072551161052, "actor_loss": -96.9585846862793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9497332572937, "step": 112000}
{"episode_reward": 904.2760638438745, "episode": 113.0, "batch_reward": 0.9327607902288437, "critic_loss": 0.22547804217785597, "actor_loss": -97.0003211669922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.588531017303467, "step": 113000}
{"episode_reward": 961.1133039117972, "episode": 114.0, "batch_reward": 0.9321827219128609, "critic_loss": 0.21448759266734124, "actor_loss": -96.96654989624024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.938485860824585, "step": 114000}
{"episode_reward": 978.36496034932, "episode": 115.0, "batch_reward": 0.9321205618381501, "critic_loss": 0.21755607261881232, "actor_loss": -96.94749389648437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.911303281784058, "step": 115000}
{"episode_reward": 928.9431628740823, "episode": 116.0, "batch_reward": 0.9309254920482636, "critic_loss": 0.228005928337574, "actor_loss": -96.94137776184083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.908625841140747, "step": 116000}
{"episode_reward": 956.2289009839717, "episode": 117.0, "batch_reward": 0.9326741951704025, "critic_loss": 0.23627813914045692, "actor_loss": -96.96854957580567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.936240196228027, "step": 117000}
{"episode_reward": 854.5606869821661, "episode": 118.0, "batch_reward": 0.9312266466617585, "critic_loss": 0.2403441851362586, "actor_loss": -96.934566116333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.935043573379517, "step": 118000}
{"episode_reward": 986.0190558797531, "episode": 119.0, "batch_reward": 0.9324094762206078, "critic_loss": 0.2105165031515062, "actor_loss": -96.99153706359863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.935402631759644, "step": 119000}
{"episode_reward": 906.8557850137404, "episode": 120.0, "batch_reward": 0.9306813648343086, "critic_loss": 0.20966061567887664, "actor_loss": -96.94274977111816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.929890155792236, "step": 120000}
{"episode_reward": 923.5549627692106, "episode": 121.0, "batch_reward": 0.9323503279089927, "critic_loss": 0.21752775260806084, "actor_loss": -96.98350930786133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.23537540435791, "step": 121000}
{"episode_reward": 982.2901376982795, "episode": 122.0, "batch_reward": 0.9314715750217438, "critic_loss": 0.23574357687309383, "actor_loss": -96.93285473632812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92945957183838, "step": 122000}
{"episode_reward": 955.5407306050311, "episode": 123.0, "batch_reward": 0.9330601322054863, "critic_loss": 0.2483099068775773, "actor_loss": -96.89485627746582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93235683441162, "step": 123000}
{"episode_reward": 971.0664275495091, "episode": 124.0, "batch_reward": 0.9318356884121894, "critic_loss": 0.23021084646508097, "actor_loss": -96.85359239196778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.040698051452637, "step": 124000}
{"episode_reward": 980.109320446432, "episode": 125.0, "batch_reward": 0.9338268623352051, "critic_loss": 0.23982791068404913, "actor_loss": -96.97709230041504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.143074989318848, "step": 125000}
{"episode_reward": 987.993777368984, "episode": 126.0, "batch_reward": 0.9340849853157998, "critic_loss": 0.2332228721641004, "actor_loss": -96.9621668395996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.899780988693237, "step": 126000}
{"episode_reward": 983.7003457102256, "episode": 127.0, "batch_reward": 0.9332490499019623, "critic_loss": 0.2364204660281539, "actor_loss": -96.88210638427735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92526078224182, "step": 127000}
{"episode_reward": 950.3911043570249, "episode": 128.0, "batch_reward": 0.9342882203459739, "critic_loss": 0.2480117994584143, "actor_loss": -96.94310816955566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.940681219100952, "step": 128000}
{"episode_reward": 957.5445856032532, "episode": 129.0, "batch_reward": 0.9346029912829399, "critic_loss": 0.243587061136961, "actor_loss": -96.89355508422851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.946343421936035, "step": 129000}
{"episode_reward": 980.9266346238935, "episode": 130.0, "batch_reward": 0.9352084172368049, "critic_loss": 0.22154154049605132, "actor_loss": -96.98653703308105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.919960260391235, "step": 130000}
{"episode_reward": 983.7310470832299, "episode": 131.0, "batch_reward": 0.9357713718414307, "critic_loss": 0.23245722528919577, "actor_loss": -96.92776303100585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.23826622962952, "step": 131000}
{"episode_reward": 971.1457180233521, "episode": 132.0, "batch_reward": 0.936577485203743, "critic_loss": 0.22438390037044884, "actor_loss": -97.0161978149414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.921660661697388, "step": 132000}
{"episode_reward": 985.8987822222145, "episode": 133.0, "batch_reward": 0.9354158512353897, "critic_loss": 0.2505234069302678, "actor_loss": -96.95617008972168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.930479288101196, "step": 133000}
{"episode_reward": 938.2698196810103, "episode": 134.0, "batch_reward": 0.9357867879271508, "critic_loss": 0.22914258946105837, "actor_loss": -96.9281923675537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.922287940979004, "step": 134000}
{"episode_reward": 986.5292697676155, "episode": 135.0, "batch_reward": 0.93717594653368, "critic_loss": 0.22252996440976858, "actor_loss": -97.00209034729004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.930087327957153, "step": 135000}
{"episode_reward": 991.3746241745218, "episode": 136.0, "batch_reward": 0.936668795287609, "critic_loss": 0.2356161879375577, "actor_loss": -97.00441761779786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93216371536255, "step": 136000}
{"episode_reward": 989.4967976011462, "episode": 137.0, "batch_reward": 0.9361549565792083, "critic_loss": 0.23163515383377672, "actor_loss": -97.03244206237792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.927667379379272, "step": 137000}
{"episode_reward": 968.9654080015515, "episode": 138.0, "batch_reward": 0.9379118049740791, "critic_loss": 0.22863862134516239, "actor_loss": -97.13878926086426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.96129298210144, "step": 138000}
{"episode_reward": 961.9045310654701, "episode": 139.0, "batch_reward": 0.936209959089756, "critic_loss": 0.23257820250466466, "actor_loss": -97.07527561950684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.922846794128418, "step": 139000}
{"episode_reward": 978.1286219320156, "episode": 140.0, "batch_reward": 0.9378765789270401, "critic_loss": 0.22913281088322401, "actor_loss": -97.14695140075683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92531943321228, "step": 140000}
{"episode_reward": 957.3839798865775, "episode": 141.0, "batch_reward": 0.9381918128728867, "critic_loss": 0.21045988453552128, "actor_loss": -97.16876094055176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.293317794799805, "step": 141000}
{"episode_reward": 969.9310878696567, "episode": 142.0, "batch_reward": 0.9382921661138535, "critic_loss": 0.20981899082660674, "actor_loss": -97.17544752502441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.944090843200684, "step": 142000}
{"episode_reward": 990.2813410688921, "episode": 143.0, "batch_reward": 0.938691472530365, "critic_loss": 0.21776412318646907, "actor_loss": -97.186501663208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.933032989501953, "step": 143000}
{"episode_reward": 950.751813407784, "episode": 144.0, "batch_reward": 0.938595912694931, "critic_loss": 0.22368870001286267, "actor_loss": -97.22517266845703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.919458389282227, "step": 144000}
{"episode_reward": 943.5419883568668, "episode": 145.0, "batch_reward": 0.938782550573349, "critic_loss": 0.21853589751943947, "actor_loss": -97.229986328125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.930689811706543, "step": 145000}
{"episode_reward": 984.6895048683643, "episode": 146.0, "batch_reward": 0.9389243006110192, "critic_loss": 0.19717038521915675, "actor_loss": -97.2203027191162, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9572970867157, "step": 146000}
{"episode_reward": 972.3512419587572, "episode": 147.0, "batch_reward": 0.9383760593533516, "critic_loss": 0.21462308040633798, "actor_loss": -97.18756051635742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.927836894989014, "step": 147000}
{"episode_reward": 949.5094219213088, "episode": 148.0, "batch_reward": 0.9403268436789513, "critic_loss": 0.20106156311742962, "actor_loss": -97.24959237670899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.934550285339355, "step": 148000}
{"episode_reward": 987.4050572764361, "episode": 149.0, "batch_reward": 0.9383218993544579, "critic_loss": 0.22507087109237908, "actor_loss": -97.22332862854005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93026900291443, "step": 149000}
{"episode_reward": 908.2252658167009, "episode": 150.0, "batch_reward": 0.9387664610743522, "critic_loss": 0.22218123702332376, "actor_loss": -97.25317419433594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
