{"episode_reward": 0.0, "episode": 1.0, "duration": 21.200594663619995, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.8021061420440674, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.48896008478517966, "critic_loss": 1.0014816106717241, "actor_loss": -87.10812415786627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.495540618896484, "step": 3000}
{"episode_reward": 576.6976005248741, "episode": 4.0, "batch_reward": 0.5225557057261467, "critic_loss": 1.3569345584511756, "actor_loss": -89.06645353698731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.449968814849854, "step": 4000}
{"episode_reward": 391.1068701461711, "episode": 5.0, "batch_reward": 0.5169901801645755, "critic_loss": 1.1017062619924545, "actor_loss": -89.46254446411133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.280505895614624, "step": 5000}
{"episode_reward": 876.4279606264223, "episode": 6.0, "batch_reward": 0.5656869200766087, "critic_loss": 0.9523601927161217, "actor_loss": -89.35495399475097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.69017457962036, "step": 6000}
{"episode_reward": 570.1435254173487, "episode": 7.0, "batch_reward": 0.5711696498990059, "critic_loss": 0.9517714952230454, "actor_loss": -88.52408767700196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.72175097465515, "step": 7000}
{"episode_reward": 723.7491148538145, "episode": 8.0, "batch_reward": 0.5865433368384838, "critic_loss": 1.004746334552765, "actor_loss": -88.23435215759277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.562421083450317, "step": 8000}
{"episode_reward": 776.8653041886217, "episode": 9.0, "batch_reward": 0.6140474114716054, "critic_loss": 0.9508587135076523, "actor_loss": -88.04163958740234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.839815616607666, "step": 9000}
{"episode_reward": 860.9874838398334, "episode": 10.0, "batch_reward": 0.6500867890715599, "critic_loss": 1.0253072402477263, "actor_loss": -88.38616661071778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.537583112716675, "step": 10000}
{"episode_reward": 951.8223438911202, "episode": 11.0, "batch_reward": 0.6767050101161003, "critic_loss": 1.227087317943573, "actor_loss": -89.3825643157959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.31599974632263, "step": 11000}
{"episode_reward": 939.576653005634, "episode": 12.0, "batch_reward": 0.6971154542565345, "critic_loss": 0.963289892077446, "actor_loss": -89.43909461975097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.299508810043335, "step": 12000}
{"episode_reward": 923.0254522401193, "episode": 13.0, "batch_reward": 0.7164575388431549, "critic_loss": 0.8577892509102821, "actor_loss": -89.48798556518555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02394700050354, "step": 13000}
{"episode_reward": 893.2233742763942, "episode": 14.0, "batch_reward": 0.7360471591949463, "critic_loss": 0.7979461223483085, "actor_loss": -89.78191430664063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.269505739212036, "step": 14000}
{"episode_reward": 976.2790078687075, "episode": 15.0, "batch_reward": 0.7510219780206681, "critic_loss": 0.7333266076445579, "actor_loss": -90.38048207092285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.113029718399048, "step": 15000}
{"episode_reward": 988.9059196854981, "episode": 16.0, "batch_reward": 0.7660899769067764, "critic_loss": 0.7346071405410767, "actor_loss": -90.54334033203125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05907106399536, "step": 16000}
{"episode_reward": 936.7610930519568, "episode": 17.0, "batch_reward": 0.7712279595732688, "critic_loss": 0.8044815215468407, "actor_loss": -90.47956144714355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04723286628723, "step": 17000}
{"episode_reward": 844.206171541671, "episode": 18.0, "batch_reward": 0.7795621011257171, "critic_loss": 0.7372980761528015, "actor_loss": -90.72419139099121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.062728881835938, "step": 18000}
{"episode_reward": 944.5688439659981, "episode": 19.0, "batch_reward": 0.7913170167207718, "critic_loss": 0.708554911673069, "actor_loss": -90.8089321899414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.26586151123047, "step": 19000}
{"episode_reward": 976.497540158144, "episode": 20.0, "batch_reward": 0.7986094635128975, "critic_loss": 0.6726635774970054, "actor_loss": -91.22014790344238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.046993494033813, "step": 20000}
{"episode_reward": 962.1077978934868, "episode": 21.0, "batch_reward": 0.8023533716797828, "critic_loss": 0.6944341297745704, "actor_loss": -91.25390097045899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.545881509780884, "step": 21000}
{"episode_reward": 853.5222014966466, "episode": 22.0, "batch_reward": 0.8098518545627594, "critic_loss": 0.626256338596344, "actor_loss": -91.04812854003906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.877022743225098, "step": 22000}
{"episode_reward": 950.9379477453816, "episode": 23.0, "batch_reward": 0.8138329402208329, "critic_loss": 0.652171419620514, "actor_loss": -90.98171714782715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.514255046844482, "step": 23000}
{"episode_reward": 901.4141460066439, "episode": 24.0, "batch_reward": 0.8178385733366013, "critic_loss": 0.6391801878213882, "actor_loss": -91.2170216369629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.29360270500183, "step": 24000}
{"episode_reward": 981.7288543359624, "episode": 25.0, "batch_reward": 0.8213333685994149, "critic_loss": 0.6784306746423244, "actor_loss": -91.07004870605469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03141474723816, "step": 25000}
{"episode_reward": 892.4382025533454, "episode": 26.0, "batch_reward": 0.824599694609642, "critic_loss": 0.7334461709260941, "actor_loss": -91.07249136352539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.852858066558838, "step": 26000}
{"episode_reward": 943.1069671600723, "episode": 27.0, "batch_reward": 0.8341300152540206, "critic_loss": 0.7243469837903976, "actor_loss": -91.44929513549805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.368733882904053, "step": 27000}
{"episode_reward": 959.5897666598548, "episode": 28.0, "batch_reward": 0.8362909218668938, "critic_loss": 0.8034506405293942, "actor_loss": -91.31915161132812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36266779899597, "step": 28000}
{"episode_reward": 877.0516894930066, "episode": 29.0, "batch_reward": 0.8339323176145553, "critic_loss": 0.9304891197085381, "actor_loss": -91.28884191894531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.05007839202881, "step": 29000}
{"episode_reward": 762.75854095138, "episode": 30.0, "batch_reward": 0.835095895588398, "critic_loss": 1.043452809214592, "actor_loss": -91.22467456054687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.773897886276245, "step": 30000}
{"episode_reward": 895.4006505508721, "episode": 31.0, "batch_reward": 0.8362101652026176, "critic_loss": 1.0942037905454636, "actor_loss": -91.30784353637695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.71736288070679, "step": 31000}
{"episode_reward": 891.9949775816921, "episode": 32.0, "batch_reward": 0.8396485634446144, "critic_loss": 1.1093056318163872, "actor_loss": -91.4254264831543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.413620948791504, "step": 32000}
{"episode_reward": 957.999292240108, "episode": 33.0, "batch_reward": 0.8403392082452774, "critic_loss": 1.1644067317843436, "actor_loss": -91.45055386352539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.832807302474976, "step": 33000}
{"episode_reward": 918.8871486080435, "episode": 34.0, "batch_reward": 0.8442474021315575, "critic_loss": 1.176338607788086, "actor_loss": -91.17355053710938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.657782077789307, "step": 34000}
{"episode_reward": 979.6150253023351, "episode": 35.0, "batch_reward": 0.8471109805703163, "critic_loss": 1.3105031432509422, "actor_loss": -91.60143151855469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.460185766220093, "step": 35000}
{"episode_reward": 876.1496422402394, "episode": 36.0, "batch_reward": 0.847011008143425, "critic_loss": 1.2457911306023597, "actor_loss": -91.25750009155273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.012944221496582, "step": 36000}
{"episode_reward": 816.2672497734638, "episode": 37.0, "batch_reward": 0.8468543915748596, "critic_loss": 1.091767516374588, "actor_loss": -91.37336968994141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66551160812378, "step": 37000}
{"episode_reward": 934.9057570029639, "episode": 38.0, "batch_reward": 0.8513673722147942, "critic_loss": 0.9632998267114162, "actor_loss": -91.44124771118165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.947819232940674, "step": 38000}
{"episode_reward": 982.5578905805004, "episode": 39.0, "batch_reward": 0.8542169210314751, "critic_loss": 0.9018638506233693, "actor_loss": -91.72049771118164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.40301775932312, "step": 39000}
{"episode_reward": 958.2702416086526, "episode": 40.0, "batch_reward": 0.8575079265832901, "critic_loss": 0.9226397380530834, "actor_loss": -91.71877830505372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.84250283241272, "step": 40000}
{"episode_reward": 976.6895099466689, "episode": 41.0, "batch_reward": 0.8587495745420456, "critic_loss": 0.9886647433042526, "actor_loss": -91.79269319152831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.306177854537964, "step": 41000}
{"episode_reward": 875.7672114292658, "episode": 42.0, "batch_reward": 0.8602326471209526, "critic_loss": 0.9472695871889592, "actor_loss": -91.72207743835449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.812416553497314, "step": 42000}
{"episode_reward": 942.6008359295547, "episode": 43.0, "batch_reward": 0.8590279639363289, "critic_loss": 1.0516170211136342, "actor_loss": -91.77138557434083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.396374464035034, "step": 43000}
{"episode_reward": 846.042446976143, "episode": 44.0, "batch_reward": 0.8613092615604401, "critic_loss": 1.0054501985311508, "actor_loss": -91.6097933807373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.497339487075806, "step": 44000}
{"episode_reward": 977.1340383677127, "episode": 45.0, "batch_reward": 0.8649557740092277, "critic_loss": 0.9593842814862729, "actor_loss": -92.01819180297852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.89229130744934, "step": 45000}
{"episode_reward": 940.8412985408593, "episode": 46.0, "batch_reward": 0.8653822497725486, "critic_loss": 0.9850269257128239, "actor_loss": -91.89107472229004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.67083716392517, "step": 46000}
{"episode_reward": 957.3035036572663, "episode": 47.0, "batch_reward": 0.8687980113625526, "critic_loss": 0.9222375661730766, "actor_loss": -91.94841535949708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.5043888092041, "step": 47000}
{"episode_reward": 962.1612723630932, "episode": 48.0, "batch_reward": 0.8696214984059334, "critic_loss": 0.9204571019411087, "actor_loss": -91.87005863952636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.190666675567627, "step": 48000}
{"episode_reward": 909.9093164535702, "episode": 49.0, "batch_reward": 0.8717924517989158, "critic_loss": 0.9505140945017337, "actor_loss": -92.19187660217285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.403971195220947, "step": 49000}
{"episode_reward": 952.6818661484821, "episode": 50.0, "batch_reward": 0.8734178550839424, "critic_loss": 0.867825000166893, "actor_loss": -92.14027073669433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.783556938171387, "step": 50000}
{"episode_reward": 986.3547141706752, "episode": 51.0, "batch_reward": 0.8756086413860321, "critic_loss": 0.8664698695540428, "actor_loss": -92.12489726257324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.419596910476685, "step": 51000}
{"episode_reward": 928.4435454426815, "episode": 52.0, "batch_reward": 0.8742107805013657, "critic_loss": 0.8960112839639187, "actor_loss": -92.4238998413086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.433984756469727, "step": 52000}
{"episode_reward": 886.0322815386459, "episode": 53.0, "batch_reward": 0.8760726536512375, "critic_loss": 0.8473857725262642, "actor_loss": -92.35920428466797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.625304698944092, "step": 53000}
{"episode_reward": 949.3224505511037, "episode": 54.0, "batch_reward": 0.876518448650837, "critic_loss": 0.8608926341533661, "actor_loss": -92.54806745910645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.812373161315918, "step": 54000}
{"episode_reward": 925.0256790721758, "episode": 55.0, "batch_reward": 0.8784988615512848, "critic_loss": 0.8381180624365807, "actor_loss": -92.49772375488281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.246468544006348, "step": 55000}
{"episode_reward": 983.3076251518337, "episode": 56.0, "batch_reward": 0.8817787014245987, "critic_loss": 0.7926183436214924, "actor_loss": -92.86456344604493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.852453231811523, "step": 56000}
{"episode_reward": 982.4484667037741, "episode": 57.0, "batch_reward": 0.8827711775898933, "critic_loss": 0.7663512054383754, "actor_loss": -92.74875959777832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.474982738494873, "step": 57000}
{"episode_reward": 960.4320285374903, "episode": 58.0, "batch_reward": 0.8836707381606101, "critic_loss": 0.7760300294756889, "actor_loss": -92.68396203613281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.93489694595337, "step": 58000}
{"episode_reward": 966.3549000352841, "episode": 59.0, "batch_reward": 0.8859231066703797, "critic_loss": 0.7467474449872971, "actor_loss": -92.83613119506836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16221284866333, "step": 59000}
{"episode_reward": 961.0256134740905, "episode": 60.0, "batch_reward": 0.8866826093196869, "critic_loss": 0.7133406177461147, "actor_loss": -93.15839820861817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.275440454483032, "step": 60000}
{"episode_reward": 937.738659533222, "episode": 61.0, "batch_reward": 0.8873243224620819, "critic_loss": 0.694835369259119, "actor_loss": -93.06823541259766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.45497941970825, "step": 61000}
{"episode_reward": 931.433268441425, "episode": 62.0, "batch_reward": 0.8870474306941032, "critic_loss": 0.6848216659128666, "actor_loss": -93.05726669311524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.767389059066772, "step": 62000}
{"episode_reward": 956.1609971908499, "episode": 63.0, "batch_reward": 0.8873215771317482, "critic_loss": 0.6711419526338577, "actor_loss": -93.05170571899414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.51095199584961, "step": 63000}
{"episode_reward": 909.0591734306041, "episode": 64.0, "batch_reward": 0.8888721405863762, "critic_loss": 0.621660886645317, "actor_loss": -93.17055525207519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.60385274887085, "step": 64000}
{"episode_reward": 978.9613929711167, "episode": 65.0, "batch_reward": 0.8907634589076042, "critic_loss": 0.6217614383995533, "actor_loss": -93.23827726745606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.552435636520386, "step": 65000}
{"episode_reward": 977.6834406649164, "episode": 66.0, "batch_reward": 0.8885066413879394, "critic_loss": 0.6673421721756458, "actor_loss": -93.28237342834473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.685327291488647, "step": 66000}
{"episode_reward": 669.5108812501578, "episode": 67.0, "batch_reward": 0.8861435258984566, "critic_loss": 0.7088037884235382, "actor_loss": -93.40419711303711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.570753812789917, "step": 67000}
{"episode_reward": 921.3130855555694, "episode": 68.0, "batch_reward": 0.8889896716475487, "critic_loss": 0.7246834598779678, "actor_loss": -93.21955029296875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89348602294922, "step": 68000}
{"episode_reward": 953.7198689812388, "episode": 69.0, "batch_reward": 0.8899178426265717, "critic_loss": 0.6785808046907187, "actor_loss": -93.4340948791504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.518141984939575, "step": 69000}
{"episode_reward": 965.5057348251887, "episode": 70.0, "batch_reward": 0.8914253757596016, "critic_loss": 0.688772803068161, "actor_loss": -93.45759545898437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.77852773666382, "step": 70000}
{"episode_reward": 911.0308969274168, "episode": 71.0, "batch_reward": 0.8912085286974907, "critic_loss": 0.684063658118248, "actor_loss": -93.3760933380127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.76062345504761, "step": 71000}
{"episode_reward": 927.0474341076559, "episode": 72.0, "batch_reward": 0.8927980872988701, "critic_loss": 0.660770310729742, "actor_loss": -93.4863780670166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.83397936820984, "step": 72000}
{"episode_reward": 967.6056141432898, "episode": 73.0, "batch_reward": 0.8911354658603668, "critic_loss": 0.6708896193504333, "actor_loss": -93.45610427856445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.853095769882202, "step": 73000}
{"episode_reward": 945.870308332947, "episode": 74.0, "batch_reward": 0.8930409313440323, "critic_loss": 0.730125764220953, "actor_loss": -93.6126398010254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07095241546631, "step": 74000}
{"episode_reward": 863.1025559640401, "episode": 75.0, "batch_reward": 0.8932588837742805, "critic_loss": 0.7177901799380779, "actor_loss": -93.66353440856933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0128333568573, "step": 75000}
{"episode_reward": 956.594056059546, "episode": 76.0, "batch_reward": 0.8933760230541229, "critic_loss": 0.7600046786665916, "actor_loss": -93.54730570983887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.267292261123657, "step": 76000}
{"episode_reward": 909.3462885965614, "episode": 77.0, "batch_reward": 0.8943146589398384, "critic_loss": 0.7204847301840782, "actor_loss": -93.57628204345703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15579891204834, "step": 77000}
{"episode_reward": 961.150860477186, "episode": 78.0, "batch_reward": 0.8950971328616142, "critic_loss": 0.7260632210373879, "actor_loss": -93.64692832946777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.551559925079346, "step": 78000}
{"episode_reward": 958.2630290526698, "episode": 79.0, "batch_reward": 0.8963125172257423, "critic_loss": 0.7802247406244278, "actor_loss": -93.45561291503907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.84306025505066, "step": 79000}
{"episode_reward": 965.4136952366339, "episode": 80.0, "batch_reward": 0.8962318282723427, "critic_loss": 0.7840981474220753, "actor_loss": -93.5857254486084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.519821643829346, "step": 80000}
{"episode_reward": 963.9430212193578, "episode": 81.0, "batch_reward": 0.8974733429551125, "critic_loss": 0.7550024757683277, "actor_loss": -93.73774008178711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.92700481414795, "step": 81000}
{"episode_reward": 934.5875899667844, "episode": 82.0, "batch_reward": 0.8978875332474708, "critic_loss": 0.7796339339911937, "actor_loss": -93.88408848571777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.507861137390137, "step": 82000}
{"episode_reward": 956.3523119403699, "episode": 83.0, "batch_reward": 0.897183418571949, "critic_loss": 0.7696986413896084, "actor_loss": -93.71179872131347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.71777844429016, "step": 83000}
{"episode_reward": 823.288316645174, "episode": 84.0, "batch_reward": 0.8993396085500717, "critic_loss": 0.7866825815588235, "actor_loss": -93.9723275756836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.493321418762207, "step": 84000}
{"episode_reward": 990.6737014226732, "episode": 85.0, "batch_reward": 0.896773318707943, "critic_loss": 0.7722254732549191, "actor_loss": -93.86390914916993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21105408668518, "step": 85000}
{"episode_reward": 916.4170184900474, "episode": 86.0, "batch_reward": 0.8989194793701172, "critic_loss": 0.7335987640321254, "actor_loss": -93.78121855163575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.72642183303833, "step": 86000}
{"episode_reward": 957.4159088242235, "episode": 87.0, "batch_reward": 0.8984293252825737, "critic_loss": 0.7912129640430212, "actor_loss": -93.92941049194336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.615808486938477, "step": 87000}
{"episode_reward": 855.4785277795277, "episode": 88.0, "batch_reward": 0.8999323223233223, "critic_loss": 0.7491971716284752, "actor_loss": -93.8877218017578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.471670389175415, "step": 88000}
{"episode_reward": 915.2740270637843, "episode": 89.0, "batch_reward": 0.8975756482481957, "critic_loss": 0.7764300861656666, "actor_loss": -93.91308633422851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.894574403762817, "step": 89000}
{"episode_reward": 906.1157038349991, "episode": 90.0, "batch_reward": 0.899530733525753, "critic_loss": 0.7403751541525125, "actor_loss": -94.08296159362793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.350963354110718, "step": 90000}
{"episode_reward": 957.987388565588, "episode": 91.0, "batch_reward": 0.9001532165408135, "critic_loss": 0.7717772049307823, "actor_loss": -93.89721803283692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.90318584442139, "step": 91000}
{"episode_reward": 927.9828349103404, "episode": 92.0, "batch_reward": 0.9017342357635498, "critic_loss": 0.7362706427574157, "actor_loss": -94.02615454101563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.85142731666565, "step": 92000}
{"episode_reward": 951.2683539484957, "episode": 93.0, "batch_reward": 0.8996976146697998, "critic_loss": 0.7041023716330528, "actor_loss": -94.02749633789062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.40043067932129, "step": 93000}
{"episode_reward": 987.545690644888, "episode": 94.0, "batch_reward": 0.901087427675724, "critic_loss": 0.7530901797115803, "actor_loss": -94.06323538208008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.0350022315979, "step": 94000}
{"episode_reward": 910.2613609255551, "episode": 95.0, "batch_reward": 0.9017390111088752, "critic_loss": 0.771339476287365, "actor_loss": -94.15383862304688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087093830108643, "step": 95000}
{"episode_reward": 960.7318895030902, "episode": 96.0, "batch_reward": 0.9018775389194489, "critic_loss": 0.7836673278808594, "actor_loss": -94.12170161437989, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.895002365112305, "step": 96000}
{"episode_reward": 961.1767657797874, "episode": 97.0, "batch_reward": 0.9025511728525162, "critic_loss": 0.7494598266929388, "actor_loss": -94.13615277099609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.524653434753418, "step": 97000}
{"episode_reward": 902.6027462533558, "episode": 98.0, "batch_reward": 0.903503426015377, "critic_loss": 0.8113831363022327, "actor_loss": -94.10309648132325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.457528352737427, "step": 98000}
{"episode_reward": 891.6182695293267, "episode": 99.0, "batch_reward": 0.9016916157603264, "critic_loss": 0.828022168725729, "actor_loss": -94.08392054748535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.02746319770813, "step": 99000}
{"episode_reward": 952.403533980983, "episode": 100.0, "batch_reward": 0.9041052972674369, "critic_loss": 0.8142320630997419, "actor_loss": -94.09386712646484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.359607934951782, "step": 100000}
{"episode_reward": 922.5077490290286, "episode": 101.0, "batch_reward": 0.9045364984869957, "critic_loss": 0.8070105310380459, "actor_loss": -94.15187194824219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.1098849773407, "step": 101000}
{"episode_reward": 990.3419190555679, "episode": 102.0, "batch_reward": 0.9037320979237556, "critic_loss": 0.8874520428776741, "actor_loss": -94.16400306701661, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.826289415359497, "step": 102000}
{"episode_reward": 934.334429931704, "episode": 103.0, "batch_reward": 0.9040746818184853, "critic_loss": 0.8525278349518776, "actor_loss": -94.08140650939941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.505160331726074, "step": 103000}
{"episode_reward": 959.4135092314193, "episode": 104.0, "batch_reward": 0.9055243402123451, "critic_loss": 0.8271915176212787, "actor_loss": -94.1836726989746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.767417907714844, "step": 104000}
{"episode_reward": 897.8751327526099, "episode": 105.0, "batch_reward": 0.9058479055762291, "critic_loss": 0.8424375850707293, "actor_loss": -94.23765779113769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.546029329299927, "step": 105000}
{"episode_reward": 920.5284210206407, "episode": 106.0, "batch_reward": 0.9063693417906761, "critic_loss": 0.7952974088490009, "actor_loss": -94.22831927490235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.561813592910767, "step": 106000}
{"episode_reward": 916.922504812379, "episode": 107.0, "batch_reward": 0.9060159722566604, "critic_loss": 0.7799826256632805, "actor_loss": -94.18003540039062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.73133087158203, "step": 107000}
{"episode_reward": 961.0084604421535, "episode": 108.0, "batch_reward": 0.9072800367474556, "critic_loss": 0.7766620264649391, "actor_loss": -94.30092887878418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.2162606716156, "step": 108000}
{"episode_reward": 958.9125824659437, "episode": 109.0, "batch_reward": 0.9067880491018295, "critic_loss": 0.8236956178247928, "actor_loss": -94.37029498291015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.180023193359375, "step": 109000}
{"episode_reward": 963.5501378033832, "episode": 110.0, "batch_reward": 0.9070030114650727, "critic_loss": 0.855921975851059, "actor_loss": -94.33077713012695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.147926568984985, "step": 110000}
{"episode_reward": 890.726224824284, "episode": 111.0, "batch_reward": 0.9061546989679337, "critic_loss": 0.9001430436372757, "actor_loss": -94.33458314514161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.667444467544556, "step": 111000}
{"episode_reward": 951.1711231151304, "episode": 112.0, "batch_reward": 0.9065763211846352, "critic_loss": 0.8948252266943455, "actor_loss": -94.23239381408692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.70863938331604, "step": 112000}
{"episode_reward": 960.1116547113357, "episode": 113.0, "batch_reward": 0.9084428804516792, "critic_loss": 0.8265828226804733, "actor_loss": -94.24728771972656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.720993041992188, "step": 113000}
{"episode_reward": 957.2282250855841, "episode": 114.0, "batch_reward": 0.9095150428414345, "critic_loss": 0.8181818369925022, "actor_loss": -94.44594131469727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.49076247215271, "step": 114000}
{"episode_reward": 980.4048856782249, "episode": 115.0, "batch_reward": 0.9093215463757515, "critic_loss": 0.8768412343263626, "actor_loss": -94.32111029052734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9141902923584, "step": 115000}
{"episode_reward": 897.1023139736379, "episode": 116.0, "batch_reward": 0.9090699291229248, "critic_loss": 0.8451078063845634, "actor_loss": -94.405083984375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.36144995689392, "step": 116000}
{"episode_reward": 953.7969233787352, "episode": 117.0, "batch_reward": 0.9086902548670769, "critic_loss": 0.8593693449497223, "actor_loss": -94.22076425170899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.957778930664062, "step": 117000}
{"episode_reward": 926.2581227020464, "episode": 118.0, "batch_reward": 0.9092812590003013, "critic_loss": 0.9241335978209972, "actor_loss": -94.39351901245116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.130388259887695, "step": 118000}
{"episode_reward": 988.8493829065991, "episode": 119.0, "batch_reward": 0.9090240009427071, "critic_loss": 0.8639144836962223, "actor_loss": -94.36816387939453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.328392505645752, "step": 119000}
{"episode_reward": 926.6874654896548, "episode": 120.0, "batch_reward": 0.9092758143544197, "critic_loss": 0.8132032354623079, "actor_loss": -94.30667370605468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12763214111328, "step": 120000}
{"episode_reward": 924.6017101179508, "episode": 121.0, "batch_reward": 0.9109541385769844, "critic_loss": 0.8215541444420814, "actor_loss": -94.41251173400879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.6467080116272, "step": 121000}
{"episode_reward": 984.1135307279548, "episode": 122.0, "batch_reward": 0.9106083900332451, "critic_loss": 0.8553318462818861, "actor_loss": -94.37732679748535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.000301361083984, "step": 122000}
{"episode_reward": 938.2930352122727, "episode": 123.0, "batch_reward": 0.9109928266406059, "critic_loss": 0.8104519690275193, "actor_loss": -94.26102606201172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.55191445350647, "step": 123000}
{"episode_reward": 946.9778947146842, "episode": 124.0, "batch_reward": 0.911640074968338, "critic_loss": 0.7981572022736072, "actor_loss": -94.41964779663085, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.772547721862793, "step": 124000}
{"episode_reward": 975.8463603650177, "episode": 125.0, "batch_reward": 0.9124430014491082, "critic_loss": 0.7999887838065625, "actor_loss": -94.50131523132325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.921379804611206, "step": 125000}
{"episode_reward": 980.2022449219904, "episode": 126.0, "batch_reward": 0.9131355659961701, "critic_loss": 0.8338797149658204, "actor_loss": -94.62160667419434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.330405473709106, "step": 126000}
{"episode_reward": 940.2581196785062, "episode": 127.0, "batch_reward": 0.9118734222054482, "critic_loss": 0.8243374313861132, "actor_loss": -94.48964723205566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.221583127975464, "step": 127000}
{"episode_reward": 924.6783727779332, "episode": 128.0, "batch_reward": 0.911848063826561, "critic_loss": 0.8633911072909832, "actor_loss": -94.55075575256348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.84684729576111, "step": 128000}
{"episode_reward": 970.2638403211658, "episode": 129.0, "batch_reward": 0.9131513521671295, "critic_loss": 0.859503093034029, "actor_loss": -94.58413488769531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.600496292114258, "step": 129000}
{"episode_reward": 984.6262974948266, "episode": 130.0, "batch_reward": 0.9152566701173782, "critic_loss": 0.8335006795227528, "actor_loss": -94.65873236083985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.883649826049805, "step": 130000}
{"episode_reward": 985.7672293424115, "episode": 131.0, "batch_reward": 0.9151553329229355, "critic_loss": 0.8494688910245896, "actor_loss": -94.61923553466796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.80781817436218, "step": 131000}
{"episode_reward": 959.5128908375973, "episode": 132.0, "batch_reward": 0.9146271296739579, "critic_loss": 0.8475523468106985, "actor_loss": -94.65559580993653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.9690945148468, "step": 132000}
{"episode_reward": 947.2626000859917, "episode": 133.0, "batch_reward": 0.9154337472915649, "critic_loss": 0.8790150116086006, "actor_loss": -94.6173059539795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.559841632843018, "step": 133000}
{"episode_reward": 951.4746219511953, "episode": 134.0, "batch_reward": 0.9151412345170975, "critic_loss": 0.9509426786899566, "actor_loss": -94.66553652954101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.60456943511963, "step": 134000}
{"episode_reward": 924.3062841792859, "episode": 135.0, "batch_reward": 0.9146532660126686, "critic_loss": 1.692584595501423, "actor_loss": -95.12908207702637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.160122871398926, "step": 135000}
{"episode_reward": 550.613318184073, "episode": 136.0, "batch_reward": 0.9122514150738716, "critic_loss": 2.158166643798351, "actor_loss": -96.25257223510742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.211897373199463, "step": 136000}
{"episode_reward": 973.3587679873073, "episode": 137.0, "batch_reward": 0.9124551004767418, "critic_loss": 2.404366100549698, "actor_loss": -97.22307235717773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.478713512420654, "step": 137000}
{"episode_reward": 930.994371955789, "episode": 138.0, "batch_reward": 0.9131261984109879, "critic_loss": 2.431768137693405, "actor_loss": -98.0208239440918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.398184299468994, "step": 138000}
{"episode_reward": 897.7083564959579, "episode": 139.0, "batch_reward": 0.9128700196146965, "critic_loss": 2.458041117429733, "actor_loss": -98.39736863708497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.900365352630615, "step": 139000}
{"episode_reward": 883.8252467046931, "episode": 140.0, "batch_reward": 0.91331970256567, "critic_loss": 2.2586080359220504, "actor_loss": -98.66759315490722, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.44799494743347, "step": 140000}
{"episode_reward": 932.4093528544153, "episode": 141.0, "batch_reward": 0.9130345408320427, "critic_loss": 2.023676755607128, "actor_loss": -98.94104776000977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.3623948097229, "step": 141000}
{"episode_reward": 904.6361909482202, "episode": 142.0, "batch_reward": 0.91308774548769, "critic_loss": 1.8333207238912583, "actor_loss": -98.83146569824218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1449773311615, "step": 142000}
{"episode_reward": 986.6174992093659, "episode": 143.0, "batch_reward": 0.9133340794444084, "critic_loss": 1.7303238976597786, "actor_loss": -98.90295101928712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.096803903579712, "step": 143000}
{"episode_reward": 946.4929104216873, "episode": 144.0, "batch_reward": 0.9138255108594895, "critic_loss": 1.6310903222560882, "actor_loss": -98.62710803222656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.185058116912842, "step": 144000}
{"episode_reward": 962.1721276693196, "episode": 145.0, "batch_reward": 0.9143720632791519, "critic_loss": 1.4905792036652565, "actor_loss": -98.83293403625488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.435203075408936, "step": 145000}
{"episode_reward": 986.6490763981192, "episode": 146.0, "batch_reward": 0.9143389285802841, "critic_loss": 1.4001644716858863, "actor_loss": -98.66709439086914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.75973105430603, "step": 146000}
{"episode_reward": 971.7110015892026, "episode": 147.0, "batch_reward": 0.9142713297605515, "critic_loss": 1.3665733850896358, "actor_loss": -98.41079083251954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.674650192260742, "step": 147000}
{"episode_reward": 924.641194329096, "episode": 148.0, "batch_reward": 0.9160154517889023, "critic_loss": 1.200661064118147, "actor_loss": -98.5495112915039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.624836444854736, "step": 148000}
{"episode_reward": 984.329073838338, "episode": 149.0, "batch_reward": 0.9149575335979462, "critic_loss": 1.1942699958086014, "actor_loss": -98.43222166442871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.691168785095215, "step": 149000}
{"episode_reward": 950.4833173766759, "episode": 150.0, "batch_reward": 0.9152153720259666, "critic_loss": 1.1347506618201733, "actor_loss": -98.26582511901856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
