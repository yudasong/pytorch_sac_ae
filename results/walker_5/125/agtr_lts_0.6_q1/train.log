{"episode_reward": 0.0, "episode": 1.0, "duration": 22.121681690216064, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.8635478019714355, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.45180013140824365, "critic_loss": 0.15750914221556833, "actor_loss": -54.18995389835883, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 64.45628690719604, "step": 3000}
{"episode_reward": 100.14542548467949, "episode": 4.0, "batch_reward": 0.3299094150513411, "critic_loss": 0.3543826965242624, "actor_loss": -54.53280455112457, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.061577558517456, "step": 4000}
{"episode_reward": 253.19447165909764, "episode": 5.0, "batch_reward": 0.3342303377240896, "critic_loss": 0.6629967262744904, "actor_loss": -49.66687896251678, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.17567777633667, "step": 5000}
{"episode_reward": 374.13036781742665, "episode": 6.0, "batch_reward": 0.30958302348852157, "critic_loss": 0.7397720296084881, "actor_loss": -51.01318574142456, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.94768238067627, "step": 6000}
{"episode_reward": 33.725546749885616, "episode": 7.0, "batch_reward": 0.2743170839548111, "critic_loss": 1.1587573377490044, "actor_loss": -55.23817055511475, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.96100091934204, "step": 7000}
{"episode_reward": 142.86818157088447, "episode": 8.0, "batch_reward": 0.2715992492288351, "critic_loss": 1.7621948733329773, "actor_loss": -53.61392372703552, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.48845648765564, "step": 8000}
{"episode_reward": 340.2750698252983, "episode": 9.0, "batch_reward": 0.2797949743270874, "critic_loss": 2.1160582448244094, "actor_loss": -53.22936547660828, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.91144347190857, "step": 9000}
{"episode_reward": 408.1732460251192, "episode": 10.0, "batch_reward": 0.2885544078499079, "critic_loss": 2.3719755115509034, "actor_loss": -55.19425216293335, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.279903650283813, "step": 10000}
{"episode_reward": 277.8139162663187, "episode": 11.0, "batch_reward": 0.2942156184017658, "critic_loss": 2.784625113368034, "actor_loss": -56.92450953865051, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.412909746170044, "step": 11000}
{"episode_reward": 475.43168449050836, "episode": 12.0, "batch_reward": 0.3075702509582043, "critic_loss": 2.855315185189247, "actor_loss": -55.523269157409665, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.26821541786194, "step": 12000}
{"episode_reward": 239.97758629755512, "episode": 13.0, "batch_reward": 0.3046413119733334, "critic_loss": 2.921075319647789, "actor_loss": -57.46421361541748, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.02787971496582, "step": 13000}
{"episode_reward": 325.76205488956384, "episode": 14.0, "batch_reward": 0.2915394097864628, "critic_loss": 2.684184107065201, "actor_loss": -55.935080982208255, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.99349331855774, "step": 14000}
{"episode_reward": 36.53351770755163, "episode": 15.0, "batch_reward": 0.29818691766262057, "critic_loss": 2.931185588002205, "actor_loss": -62.10314398193359, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.968883275985718, "step": 15000}
{"episode_reward": 717.4220458581041, "episode": 16.0, "batch_reward": 0.3179793227612972, "critic_loss": 3.6118549324274065, "actor_loss": -63.415403079986575, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.215286016464233, "step": 16000}
{"episode_reward": 704.3626037137082, "episode": 17.0, "batch_reward": 0.3461167309582233, "critic_loss": 3.3459524002075196, "actor_loss": -63.53591833496094, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.322053909301758, "step": 17000}
{"episode_reward": 793.139806370594, "episode": 18.0, "batch_reward": 0.3747422901391983, "critic_loss": 2.768359569311142, "actor_loss": -65.10873519134522, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.902190446853638, "step": 18000}
{"episode_reward": 843.9758120876676, "episode": 19.0, "batch_reward": 0.405631288677454, "critic_loss": 2.476377119898796, "actor_loss": -65.70391366577148, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.16662359237671, "step": 19000}
{"episode_reward": 962.9899362814668, "episode": 20.0, "batch_reward": 0.4338801523447037, "critic_loss": 2.3413655112981795, "actor_loss": -69.36028966522217, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.164442777633667, "step": 20000}
{"episode_reward": 935.4325014461731, "episode": 21.0, "batch_reward": 0.4527698239088058, "critic_loss": 2.3276339888572695, "actor_loss": -70.48232144927978, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.37446427345276, "step": 21000}
{"episode_reward": 802.0144625531436, "episode": 22.0, "batch_reward": 0.47305824667215346, "critic_loss": 2.2456505875587465, "actor_loss": -70.0939719696045, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.38321352005005, "step": 22000}
{"episode_reward": 873.8735530218071, "episode": 23.0, "batch_reward": 0.49264877662062645, "critic_loss": 1.9716382312774658, "actor_loss": -70.57219184875488, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.02880072593689, "step": 23000}
{"episode_reward": 936.5015488016556, "episode": 24.0, "batch_reward": 0.502196288049221, "critic_loss": 2.0721674077510834, "actor_loss": -72.37966609191895, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.14227318763733, "step": 24000}
{"episode_reward": 667.1632459785876, "episode": 25.0, "batch_reward": 0.5154642891287804, "critic_loss": 2.1144703562259672, "actor_loss": -72.30659753417969, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.91465950012207, "step": 25000}
{"episode_reward": 902.3727163485287, "episode": 26.0, "batch_reward": 0.5266230629384517, "critic_loss": 2.167875058531761, "actor_loss": -72.78453957366943, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.715621948242188, "step": 26000}
{"episode_reward": 850.3050012580259, "episode": 27.0, "batch_reward": 0.5446368998289108, "critic_loss": 2.0321451441049576, "actor_loss": -74.59401347351074, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.095988750457764, "step": 27000}
{"episode_reward": 984.14004811144, "episode": 28.0, "batch_reward": 0.5593250207006931, "critic_loss": 2.211323973417282, "actor_loss": -74.54778053283691, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.293079376220703, "step": 28000}
{"episode_reward": 884.2180548812743, "episode": 29.0, "batch_reward": 0.5738432315289974, "critic_loss": 2.028292699098587, "actor_loss": -76.1420023727417, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.050243139266968, "step": 29000}
{"episode_reward": 947.9387956820665, "episode": 30.0, "batch_reward": 0.582445621907711, "critic_loss": 2.1173638726472856, "actor_loss": -76.26957850646973, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.963545083999634, "step": 30000}
{"episode_reward": 790.0364752979361, "episode": 31.0, "batch_reward": 0.5884775321185589, "critic_loss": 2.1836635582447053, "actor_loss": -77.15563527679443, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.73764896392822, "step": 31000}
{"episode_reward": 878.6319508680385, "episode": 32.0, "batch_reward": 0.6011598359942436, "critic_loss": 1.9645034968852997, "actor_loss": -78.1554489364624, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.326610326766968, "step": 32000}
{"episode_reward": 950.6689649646248, "episode": 33.0, "batch_reward": 0.6088931750953197, "critic_loss": 2.005755196094513, "actor_loss": -78.87837371063232, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.029770612716675, "step": 33000}
{"episode_reward": 924.7358573753356, "episode": 34.0, "batch_reward": 0.6186841003894806, "critic_loss": 1.955533106327057, "actor_loss": -77.95694137573243, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.23700499534607, "step": 34000}
{"episode_reward": 909.5982274597862, "episode": 35.0, "batch_reward": 0.6276242272257805, "critic_loss": 1.9017503853440285, "actor_loss": -79.9412971496582, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.113505125045776, "step": 35000}
{"episode_reward": 848.7085478064502, "episode": 36.0, "batch_reward": 0.6318881329894066, "critic_loss": 1.8743686144351959, "actor_loss": -79.09004857635497, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.888525247573853, "step": 36000}
{"episode_reward": 943.1122683398335, "episode": 37.0, "batch_reward": 0.6409681203961373, "critic_loss": 1.9042668058872223, "actor_loss": -79.95400671386719, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.18721914291382, "step": 37000}
{"episode_reward": 935.2356703252082, "episode": 38.0, "batch_reward": 0.6528427265882492, "critic_loss": 1.7529029470682145, "actor_loss": -80.76867218017578, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.522094011306763, "step": 38000}
{"episode_reward": 943.6311758904106, "episode": 39.0, "batch_reward": 0.6574765004515648, "critic_loss": 1.8915487946271896, "actor_loss": -81.79949954223633, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.425983905792236, "step": 39000}
{"episode_reward": 946.9304774440201, "episode": 40.0, "batch_reward": 0.6672405552268028, "critic_loss": 1.7123597292900086, "actor_loss": -82.0461443786621, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.312124967575073, "step": 40000}
{"episode_reward": 976.2224441221451, "episode": 41.0, "batch_reward": 0.6741613229513168, "critic_loss": 1.7060289217233657, "actor_loss": -82.35775048828125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.319379806518555, "step": 41000}
{"episode_reward": 870.031529380211, "episode": 42.0, "batch_reward": 0.6795533188581466, "critic_loss": 1.6668194089531898, "actor_loss": -82.37437171936035, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.374089002609253, "step": 42000}
{"episode_reward": 939.8013926569033, "episode": 43.0, "batch_reward": 0.6831500999331475, "critic_loss": 1.675101995408535, "actor_loss": -82.75118911743164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.387031078338623, "step": 43000}
{"episode_reward": 893.3622366211405, "episode": 44.0, "batch_reward": 0.6880510526299477, "critic_loss": 1.6253730973005296, "actor_loss": -82.58571740722657, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.838299036026, "step": 44000}
{"episode_reward": 976.0578553971571, "episode": 45.0, "batch_reward": 0.6932797439098358, "critic_loss": 1.6522598550319672, "actor_loss": -83.64734986877441, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.265445470809937, "step": 45000}
{"episode_reward": 805.9606267484878, "episode": 46.0, "batch_reward": 0.6951200318336487, "critic_loss": 1.6753990755081176, "actor_loss": -83.36500114440918, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.377586841583252, "step": 46000}
{"episode_reward": 920.8030324756133, "episode": 47.0, "batch_reward": 0.7056901829838753, "critic_loss": 1.6229356445074081, "actor_loss": -83.70301892089844, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.80145573616028, "step": 47000}
{"episode_reward": 971.0864562550532, "episode": 48.0, "batch_reward": 0.7080361313819885, "critic_loss": 1.5697590938806534, "actor_loss": -83.57265379333496, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.802386045455933, "step": 48000}
{"episode_reward": 923.7533078070234, "episode": 49.0, "batch_reward": 0.7127664884328843, "critic_loss": 1.5932184345722198, "actor_loss": -84.46626300048828, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.03825283050537, "step": 49000}
{"episode_reward": 950.6578558693777, "episode": 50.0, "batch_reward": 0.7159228799343109, "critic_loss": 1.4801843404769897, "actor_loss": -84.47728981018066, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.426236391067505, "step": 50000}
{"episode_reward": 984.890976875319, "episode": 51.0, "batch_reward": 0.7258375189304351, "critic_loss": 1.5473536351323127, "actor_loss": -84.57400366210938, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.83068108558655, "step": 51000}
{"episode_reward": 975.0941330463346, "episode": 52.0, "batch_reward": 0.7268147928714752, "critic_loss": 1.4382714172005653, "actor_loss": -85.41662126159667, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.06012535095215, "step": 52000}
{"episode_reward": 943.8891024214521, "episode": 53.0, "batch_reward": 0.7306395643353463, "critic_loss": 1.4325801212191582, "actor_loss": -85.2460687866211, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.235921144485474, "step": 53000}
{"episode_reward": 874.814947190303, "episode": 54.0, "batch_reward": 0.7348777251243591, "critic_loss": 1.37646541172266, "actor_loss": -85.65491371154785, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.204426050186157, "step": 54000}
{"episode_reward": 902.2384519668107, "episode": 55.0, "batch_reward": 0.738314777135849, "critic_loss": 1.324247719168663, "actor_loss": -85.52481219482422, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.996357440948486, "step": 55000}
{"episode_reward": 962.6920301801022, "episode": 56.0, "batch_reward": 0.7429533460736275, "critic_loss": 1.2667255787849425, "actor_loss": -86.29119032287598, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.596287965774536, "step": 56000}
{"episode_reward": 978.3128738607105, "episode": 57.0, "batch_reward": 0.746196635723114, "critic_loss": 1.2452370290756225, "actor_loss": -86.12070771789551, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.788581371307373, "step": 57000}
{"episode_reward": 907.5658348444143, "episode": 58.0, "batch_reward": 0.7487487572431565, "critic_loss": 1.2242469665408136, "actor_loss": -86.07234655761718, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.990162134170532, "step": 58000}
{"episode_reward": 965.5915663408073, "episode": 59.0, "batch_reward": 0.7522197046875954, "critic_loss": 1.2967598387002945, "actor_loss": -86.28872756958008, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.370900869369507, "step": 59000}
{"episode_reward": 892.8610920985489, "episode": 60.0, "batch_reward": 0.7537675440311432, "critic_loss": 1.2547681559324264, "actor_loss": -86.7402886505127, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.283350467681885, "step": 60000}
{"episode_reward": 886.6610011177174, "episode": 61.0, "batch_reward": 0.7572747429609299, "critic_loss": 1.2383425410985947, "actor_loss": -86.76577569580078, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.293275117874146, "step": 61000}
{"episode_reward": 952.8756940216979, "episode": 62.0, "batch_reward": 0.7593105856776238, "critic_loss": 1.2309359045028687, "actor_loss": -86.66969763183593, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.92025923728943, "step": 62000}
{"episode_reward": 958.0526588852515, "episode": 63.0, "batch_reward": 0.7594629182815552, "critic_loss": 1.263239530712366, "actor_loss": -86.6919548034668, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.119537830352783, "step": 63000}
{"episode_reward": 708.4689442328217, "episode": 64.0, "batch_reward": 0.7604592319130897, "critic_loss": 1.274799879014492, "actor_loss": -86.95459600830078, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.347282886505127, "step": 64000}
{"episode_reward": 882.9996970259452, "episode": 65.0, "batch_reward": 0.7649884901046753, "critic_loss": 1.3128374329209327, "actor_loss": -86.9755470123291, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.909575939178467, "step": 65000}
{"episode_reward": 965.8128671620807, "episode": 66.0, "batch_reward": 0.7660688873529434, "critic_loss": 1.3503771908283233, "actor_loss": -87.27724342346191, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.214709043502808, "step": 66000}
{"episode_reward": 918.7521137460741, "episode": 67.0, "batch_reward": 0.769036236345768, "critic_loss": 1.4133765701055527, "actor_loss": -87.77937210083007, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.1493239402771, "step": 67000}
{"episode_reward": 920.2193932500228, "episode": 68.0, "batch_reward": 0.7706248596906662, "critic_loss": 1.3759995935559273, "actor_loss": -87.25427293395997, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.57203435897827, "step": 68000}
{"episode_reward": 941.3861916084996, "episode": 69.0, "batch_reward": 0.7736088573336601, "critic_loss": 1.3173421993851662, "actor_loss": -87.64666032409669, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.045414686203003, "step": 69000}
{"episode_reward": 981.0009879525848, "episode": 70.0, "batch_reward": 0.7775680543780327, "critic_loss": 1.3269324693083764, "actor_loss": -87.95129284667969, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.898194789886475, "step": 70000}
{"episode_reward": 950.1777462189111, "episode": 71.0, "batch_reward": 0.7804765777587891, "critic_loss": 1.329341770529747, "actor_loss": -87.73192390441895, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.315115213394165, "step": 71000}
{"episode_reward": 940.1237318854112, "episode": 72.0, "batch_reward": 0.7831822967529297, "critic_loss": 1.238639182448387, "actor_loss": -87.98388873291016, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.90415334701538, "step": 72000}
{"episode_reward": 973.8235891996432, "episode": 73.0, "batch_reward": 0.7837715537548066, "critic_loss": 1.2203779845833778, "actor_loss": -88.05204077148437, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.155033111572266, "step": 73000}
{"episode_reward": 957.1365672017805, "episode": 74.0, "batch_reward": 0.787973197877407, "critic_loss": 1.285102630198002, "actor_loss": -88.58719348144531, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.27788805961609, "step": 74000}
{"episode_reward": 932.5545992143223, "episode": 75.0, "batch_reward": 0.7892058053612709, "critic_loss": 1.2054267300665378, "actor_loss": -88.70738752746583, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.906090021133423, "step": 75000}
{"episode_reward": 925.8964188411115, "episode": 76.0, "batch_reward": 0.7898882070183754, "critic_loss": 1.2370426506996155, "actor_loss": -88.65541232299805, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.258809804916382, "step": 76000}
{"episode_reward": 946.7661844394089, "episode": 77.0, "batch_reward": 0.7930753693580628, "critic_loss": 1.1915675162672996, "actor_loss": -88.72342115783691, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.30639100074768, "step": 77000}
{"episode_reward": 963.3876521273912, "episode": 78.0, "batch_reward": 0.794297366142273, "critic_loss": 1.2311077181100845, "actor_loss": -89.02475720214844, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.781963109970093, "step": 78000}
{"episode_reward": 956.5393958011099, "episode": 79.0, "batch_reward": 0.797509465098381, "critic_loss": 1.1690608947873116, "actor_loss": -88.50255725097657, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.066461324691772, "step": 79000}
{"episode_reward": 965.7239368368943, "episode": 80.0, "batch_reward": 0.7985313503146172, "critic_loss": 1.192469387292862, "actor_loss": -88.95205090332031, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.140122890472412, "step": 80000}
{"episode_reward": 971.4235361609489, "episode": 81.0, "batch_reward": 0.8012427070140838, "critic_loss": 1.1279211853146554, "actor_loss": -89.156760055542, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.50791907310486, "step": 81000}
{"episode_reward": 915.5549808168571, "episode": 82.0, "batch_reward": 0.8028964983224869, "critic_loss": 1.0845861850678922, "actor_loss": -89.68454429626465, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.092285871505737, "step": 82000}
{"episode_reward": 934.2564161119948, "episode": 83.0, "batch_reward": 0.8043622300624848, "critic_loss": 1.151741648644209, "actor_loss": -89.26201110839844, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.686936855316162, "step": 83000}
{"episode_reward": 854.2223692287008, "episode": 84.0, "batch_reward": 0.8062131721973419, "critic_loss": 1.093519647538662, "actor_loss": -89.72072682189942, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.744747638702393, "step": 84000}
{"episode_reward": 977.5494131958914, "episode": 85.0, "batch_reward": 0.8060792604088783, "critic_loss": 1.1398037326931953, "actor_loss": -89.62163397216797, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.95850706100464, "step": 85000}
{"episode_reward": 955.5761619939959, "episode": 86.0, "batch_reward": 0.8100823231339455, "critic_loss": 1.127896041661501, "actor_loss": -89.36406278991699, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.372747659683228, "step": 86000}
{"episode_reward": 952.4906012897416, "episode": 87.0, "batch_reward": 0.810092144727707, "critic_loss": 1.1614764345884323, "actor_loss": -89.73083448791503, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.29860019683838, "step": 87000}
{"episode_reward": 937.8747916942837, "episode": 88.0, "batch_reward": 0.811164091527462, "critic_loss": 1.085190546631813, "actor_loss": -89.6281339111328, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.672674655914307, "step": 88000}
{"episode_reward": 928.5943803780764, "episode": 89.0, "batch_reward": 0.8122557354569435, "critic_loss": 1.0826859729588032, "actor_loss": -89.76586346435546, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.85651469230652, "step": 89000}
{"episode_reward": 965.280947181126, "episode": 90.0, "batch_reward": 0.8141507887840271, "critic_loss": 1.1409723984599114, "actor_loss": -90.08568041992187, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.189406394958496, "step": 90000}
{"episode_reward": 902.7224798577417, "episode": 91.0, "batch_reward": 0.8159902504086495, "critic_loss": 1.1359192112684249, "actor_loss": -89.75196128845215, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.86239004135132, "step": 91000}
{"episode_reward": 949.0318497340892, "episode": 92.0, "batch_reward": 0.8205648211836815, "critic_loss": 1.0560108207762242, "actor_loss": -90.11850875854492, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.023879289627075, "step": 92000}
{"episode_reward": 956.2014362561019, "episode": 93.0, "batch_reward": 0.8169259150028229, "critic_loss": 1.0916098593771457, "actor_loss": -90.00591273498536, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.039985179901123, "step": 93000}
{"episode_reward": 981.9086716261057, "episode": 94.0, "batch_reward": 0.8200779223442077, "critic_loss": 1.0695488742589951, "actor_loss": -90.25527499389648, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.104833841323853, "step": 94000}
{"episode_reward": 930.0062378267385, "episode": 95.0, "batch_reward": 0.8203902701735497, "critic_loss": 1.05680648162961, "actor_loss": -90.46962289428711, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.396538972854614, "step": 95000}
{"episode_reward": 954.3513998208911, "episode": 96.0, "batch_reward": 0.8207251315116882, "critic_loss": 1.1083815633952618, "actor_loss": -90.47340879821778, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.060142278671265, "step": 96000}
{"episode_reward": 903.0398589223967, "episode": 97.0, "batch_reward": 0.8224092154502869, "critic_loss": 1.1076317862570286, "actor_loss": -90.54886375427246, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.002634525299072, "step": 97000}
{"episode_reward": 884.8436937274852, "episode": 98.0, "batch_reward": 0.824692385494709, "critic_loss": 1.0562606171369553, "actor_loss": -90.42366770935058, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.648422479629517, "step": 98000}
{"episode_reward": 881.5592973236679, "episode": 99.0, "batch_reward": 0.8247215260267258, "critic_loss": 1.073490723490715, "actor_loss": -90.48640545654297, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.0792179107666, "step": 99000}
{"episode_reward": 942.7316927518339, "episode": 100.0, "batch_reward": 0.826851191163063, "critic_loss": 1.0745671831965447, "actor_loss": -90.48574549865722, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.325278997421265, "step": 100000}
{"episode_reward": 911.7238374326043, "episode": 101.0, "batch_reward": 0.8278219149112701, "critic_loss": 1.0370560631752015, "actor_loss": -90.68026405334473, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.18093919754028, "step": 101000}
{"episode_reward": 978.1048614514842, "episode": 102.0, "batch_reward": 0.8267425179481507, "critic_loss": 1.062277762591839, "actor_loss": -90.59551959228516, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.774436712265015, "step": 102000}
{"episode_reward": 902.5474487173192, "episode": 103.0, "batch_reward": 0.8284662019610405, "critic_loss": 1.0900825442373752, "actor_loss": -90.61459413146973, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.140702486038208, "step": 103000}
{"episode_reward": 917.9650012939376, "episode": 104.0, "batch_reward": 0.8304986103177071, "critic_loss": 1.077408781439066, "actor_loss": -90.77847822570801, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.37134552001953, "step": 104000}
{"episode_reward": 940.8691276549121, "episode": 105.0, "batch_reward": 0.8318309732079506, "critic_loss": 1.0580321681797504, "actor_loss": -90.8586068725586, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.88103413581848, "step": 105000}
{"episode_reward": 920.877794349988, "episode": 106.0, "batch_reward": 0.8308584156632424, "critic_loss": 1.111603709578514, "actor_loss": -90.67354049682618, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.817087173461914, "step": 106000}
{"episode_reward": 915.1672829002678, "episode": 107.0, "batch_reward": 0.8325684416294098, "critic_loss": 1.0715053777992725, "actor_loss": -90.72142086791992, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.206992149353027, "step": 107000}
{"episode_reward": 960.263275918357, "episode": 108.0, "batch_reward": 0.8343256726264954, "critic_loss": 1.0795708086490632, "actor_loss": -90.95148095703125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.012906312942505, "step": 108000}
{"episode_reward": 943.5201603626524, "episode": 109.0, "batch_reward": 0.8342459996938706, "critic_loss": 1.1044535008966923, "actor_loss": -91.14801948547364, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.11421847343445, "step": 109000}
{"episode_reward": 967.3631219944695, "episode": 110.0, "batch_reward": 0.836299087703228, "critic_loss": 1.0974569980204105, "actor_loss": -90.98697332763672, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.3530912399292, "step": 110000}
{"episode_reward": 951.5733102705664, "episode": 111.0, "batch_reward": 0.8372237891554832, "critic_loss": 1.121540040910244, "actor_loss": -91.18418098449708, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.3864688873291, "step": 111000}
{"episode_reward": 873.8799221890308, "episode": 112.0, "batch_reward": 0.836606985449791, "critic_loss": 1.077464557826519, "actor_loss": -91.01854470825195, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.89462924003601, "step": 112000}
{"episode_reward": 821.5732575608467, "episode": 113.0, "batch_reward": 0.8379549499750137, "critic_loss": 1.138000267624855, "actor_loss": -91.00686225891113, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.726259469985962, "step": 113000}
{"episode_reward": 951.641350312965, "episode": 114.0, "batch_reward": 0.8382464000582694, "critic_loss": 1.219162506133318, "actor_loss": -91.44480421447754, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.781890869140625, "step": 114000}
{"episode_reward": 971.3344516305823, "episode": 115.0, "batch_reward": 0.839647255718708, "critic_loss": 1.163805070132017, "actor_loss": -91.26774250793457, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.909061193466187, "step": 115000}
{"episode_reward": 857.5586718357886, "episode": 116.0, "batch_reward": 0.8407568596601486, "critic_loss": 1.1918408970534802, "actor_loss": -91.4840163116455, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.92967653274536, "step": 116000}
{"episode_reward": 958.5435788665262, "episode": 117.0, "batch_reward": 0.8400436671972275, "critic_loss": 1.130272508740425, "actor_loss": -91.0719302368164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.145517349243164, "step": 117000}
{"episode_reward": 918.8895219044422, "episode": 118.0, "batch_reward": 0.8393786378502845, "critic_loss": 1.1375549513101577, "actor_loss": -91.38622241210938, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.956761360168457, "step": 118000}
{"episode_reward": 822.1975322074491, "episode": 119.0, "batch_reward": 0.8405059101581573, "critic_loss": 1.196180493503809, "actor_loss": -91.46149462890625, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.408130407333374, "step": 119000}
{"episode_reward": 948.7536295452743, "episode": 120.0, "batch_reward": 0.840300266623497, "critic_loss": 1.2216275402903556, "actor_loss": -91.26819998168945, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.737786531448364, "step": 120000}
{"episode_reward": 944.804813724863, "episode": 121.0, "batch_reward": 0.8439562161564826, "critic_loss": 1.1871297045052052, "actor_loss": -91.40512016296387, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.91594576835632, "step": 121000}
{"episode_reward": 966.3520346620683, "episode": 122.0, "batch_reward": 0.8429383338689804, "critic_loss": 1.1517470906376839, "actor_loss": -91.37116007995606, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.172268390655518, "step": 122000}
{"episode_reward": 937.8957468258574, "episode": 123.0, "batch_reward": 0.8450830893516541, "critic_loss": 1.1072959931194781, "actor_loss": -91.08682922363282, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.792810201644897, "step": 123000}
{"episode_reward": 950.2590042408851, "episode": 124.0, "batch_reward": 0.8461693288683891, "critic_loss": 1.1059802864789963, "actor_loss": -91.49796244812012, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.869630575180054, "step": 124000}
{"episode_reward": 961.4090725314796, "episode": 125.0, "batch_reward": 0.8478850678205491, "critic_loss": 1.1127991496622562, "actor_loss": -91.50022242736816, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.3613600730896, "step": 125000}
{"episode_reward": 986.8572111777311, "episode": 126.0, "batch_reward": 0.8482019169330597, "critic_loss": 1.1100247329175472, "actor_loss": -91.72443562316894, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.25894808769226, "step": 126000}
{"episode_reward": 968.2295034400103, "episode": 127.0, "batch_reward": 0.8491150013804436, "critic_loss": 1.099172298103571, "actor_loss": -91.62500956726075, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.90614080429077, "step": 127000}
{"episode_reward": 943.7189455822818, "episode": 128.0, "batch_reward": 0.8494964879751206, "critic_loss": 1.104310443520546, "actor_loss": -91.67051570129395, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.745054721832275, "step": 128000}
{"episode_reward": 965.1796390291954, "episode": 129.0, "batch_reward": 0.8502526931166648, "critic_loss": 1.0328904424011707, "actor_loss": -91.85086291503906, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.82274842262268, "step": 129000}
{"episode_reward": 977.855325796392, "episode": 130.0, "batch_reward": 0.8519664444327354, "critic_loss": 1.090801314562559, "actor_loss": -91.87405079650878, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.922698259353638, "step": 130000}
{"episode_reward": 983.6718947436492, "episode": 131.0, "batch_reward": 0.8530448995232582, "critic_loss": 1.0796179842352867, "actor_loss": -91.9094723815918, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.22415781021118, "step": 131000}
{"episode_reward": 931.8077908678265, "episode": 132.0, "batch_reward": 0.8532185572385788, "critic_loss": 1.0806043377816676, "actor_loss": -91.95036976623535, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.49473547935486, "step": 132000}
{"episode_reward": 974.7651871697938, "episode": 133.0, "batch_reward": 0.8533549313545227, "critic_loss": 0.9885786716938019, "actor_loss": -91.84123435974121, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.362908363342285, "step": 133000}
{"episode_reward": 928.0357172035356, "episode": 134.0, "batch_reward": 0.853055666565895, "critic_loss": 1.0218834379017354, "actor_loss": -91.94873918151856, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.313082218170166, "step": 134000}
{"episode_reward": 958.9310038861607, "episode": 135.0, "batch_reward": 0.8567869293689728, "critic_loss": 0.9796108845472336, "actor_loss": -92.06065310668946, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.943762063980103, "step": 135000}
{"episode_reward": 991.5687321262847, "episode": 136.0, "batch_reward": 0.857412514925003, "critic_loss": 0.9773098663687706, "actor_loss": -92.22265531921387, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.335042238235474, "step": 136000}
{"episode_reward": 989.1893075711065, "episode": 137.0, "batch_reward": 0.8564827152490616, "critic_loss": 0.9817158012390137, "actor_loss": -92.07891108703613, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.883691549301147, "step": 137000}
{"episode_reward": 986.0422999237376, "episode": 138.0, "batch_reward": 0.8586666374206543, "critic_loss": 0.9841999371945858, "actor_loss": -91.93538641357422, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.163209199905396, "step": 138000}
{"episode_reward": 880.5162448662417, "episode": 139.0, "batch_reward": 0.856648729622364, "critic_loss": 0.9654597768187523, "actor_loss": -91.95615513610839, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.28383231163025, "step": 139000}
{"episode_reward": 981.7406174133681, "episode": 140.0, "batch_reward": 0.8588019595146179, "critic_loss": 0.9979788403511047, "actor_loss": -91.99551467895508, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.723207712173462, "step": 140000}
{"episode_reward": 900.9241275557399, "episode": 141.0, "batch_reward": 0.8601271430850029, "critic_loss": 1.0029766915440559, "actor_loss": -91.97411135864257, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.790690660476685, "step": 141000}
{"episode_reward": 957.0715745151316, "episode": 142.0, "batch_reward": 0.8596481283903122, "critic_loss": 1.0007415746450423, "actor_loss": -92.09188861083985, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.995918035507202, "step": 142000}
{"episode_reward": 989.1768456931452, "episode": 143.0, "batch_reward": 0.861036557674408, "critic_loss": 0.9827892900705337, "actor_loss": -92.14750462341308, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.892311096191406, "step": 143000}
{"episode_reward": 940.2584892098082, "episode": 144.0, "batch_reward": 0.8615481405854225, "critic_loss": 0.9223915314078331, "actor_loss": -92.3126672821045, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.265105485916138, "step": 144000}
{"episode_reward": 959.973001651665, "episode": 145.0, "batch_reward": 0.862893895149231, "critic_loss": 0.946479920387268, "actor_loss": -92.24282255554199, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.29088521003723, "step": 145000}
{"episode_reward": 986.6647584982179, "episode": 146.0, "batch_reward": 0.8629893783926964, "critic_loss": 0.9427443862855435, "actor_loss": -92.23955262756348, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.930315017700195, "step": 146000}
{"episode_reward": 964.2004928610213, "episode": 147.0, "batch_reward": 0.8625912731289863, "critic_loss": 0.9386951505243778, "actor_loss": -92.35024382019043, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.714512586593628, "step": 147000}
{"episode_reward": 893.0344640841048, "episode": 148.0, "batch_reward": 0.8651919047236443, "critic_loss": 0.9603394087851047, "actor_loss": -92.23309202575683, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.722338914871216, "step": 148000}
{"episode_reward": 966.8739932834593, "episode": 149.0, "batch_reward": 0.864588230073452, "critic_loss": 0.9512872691750527, "actor_loss": -92.24181858825683, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.06555938720703, "step": 149000}
{"episode_reward": 932.1985363255442, "episode": 150.0, "batch_reward": 0.8654852281808854, "critic_loss": 0.9936841278076172, "actor_loss": -92.42419209289551, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
