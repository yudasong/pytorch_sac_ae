{"episode_reward": 0.0, "episode": 1.0, "duration": 21.603395700454712, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.8323485851287842, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.46618779810041777, "critic_loss": 0.6091003744860178, "actor_loss": -84.45734402464599, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 64.43771553039551, "step": 3000}
{"episode_reward": 483.6531914240389, "episode": 4.0, "batch_reward": 0.4236881160736084, "critic_loss": 0.8998741988539696, "actor_loss": -84.86238203430176, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.66049599647522, "step": 4000}
{"episode_reward": 88.64959734175434, "episode": 5.0, "batch_reward": 0.41780229145288467, "critic_loss": 0.9778404579758644, "actor_loss": -84.99561006164551, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.11311912536621, "step": 5000}
{"episode_reward": 809.7279296197601, "episode": 6.0, "batch_reward": 0.4706306360960007, "critic_loss": 0.9946030946969986, "actor_loss": -85.94786036682129, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.03070092201233, "step": 6000}
{"episode_reward": 511.6404847505282, "episode": 7.0, "batch_reward": 0.49799762800335884, "critic_loss": 1.0112231977581978, "actor_loss": -86.09081967163085, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.94254493713379, "step": 7000}
{"episode_reward": 841.6316092890926, "episode": 8.0, "batch_reward": 0.5402731825113296, "critic_loss": 1.122204526424408, "actor_loss": -86.62026390075684, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.017149448394775, "step": 8000}
{"episode_reward": 794.1664850006587, "episode": 9.0, "batch_reward": 0.5722758924067021, "critic_loss": 1.012472643971443, "actor_loss": -87.08558856201172, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.12602186203003, "step": 9000}
{"episode_reward": 837.0836931314384, "episode": 10.0, "batch_reward": 0.6062924570441246, "critic_loss": 1.023386258661747, "actor_loss": -87.65880207824706, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.731013774871826, "step": 10000}
{"episode_reward": 942.9411415604458, "episode": 11.0, "batch_reward": 0.6306142238378525, "critic_loss": 0.9838309460878372, "actor_loss": -88.06137554931641, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.938072204589844, "step": 11000}
{"episode_reward": 722.6131781774886, "episode": 12.0, "batch_reward": 0.641015392780304, "critic_loss": 1.1596155435442925, "actor_loss": -88.03747778320313, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.162513494491577, "step": 12000}
{"episode_reward": 860.5428008846842, "episode": 13.0, "batch_reward": 0.6578945859074593, "critic_loss": 1.248063016116619, "actor_loss": -88.41537348937989, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.73145294189453, "step": 13000}
{"episode_reward": 867.4907493228358, "episode": 14.0, "batch_reward": 0.668367779970169, "critic_loss": 1.3984226928949357, "actor_loss": -88.38819430541992, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.7834529876709, "step": 14000}
{"episode_reward": 711.2601867216249, "episode": 15.0, "batch_reward": 0.6828359401226044, "critic_loss": 1.3269367945790291, "actor_loss": -88.87386297607422, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.835642337799072, "step": 15000}
{"episode_reward": 982.5750196279263, "episode": 16.0, "batch_reward": 0.6989021662473679, "critic_loss": 1.2523297970294953, "actor_loss": -89.13234831237793, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.70600461959839, "step": 16000}
{"episode_reward": 940.6197337799033, "episode": 17.0, "batch_reward": 0.7156026258468627, "critic_loss": 1.180745231807232, "actor_loss": -89.35630731201172, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.053730964660645, "step": 17000}
{"episode_reward": 946.6227343908527, "episode": 18.0, "batch_reward": 0.72929707467556, "critic_loss": 1.1426356993317603, "actor_loss": -89.69170582580567, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.152926683425903, "step": 18000}
{"episode_reward": 960.739526834674, "episode": 19.0, "batch_reward": 0.7416533631682396, "critic_loss": 1.0289846393465996, "actor_loss": -89.91700872802734, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.036926984786987, "step": 19000}
{"episode_reward": 936.9411864826588, "episode": 20.0, "batch_reward": 0.742787148475647, "critic_loss": 0.8709324488639831, "actor_loss": -90.30629191589355, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.693774223327637, "step": 20000}
{"episode_reward": 732.6872178319556, "episode": 21.0, "batch_reward": 0.7453305012583733, "critic_loss": 0.8045437938570976, "actor_loss": -90.3331986694336, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.064586877822876, "step": 21000}
{"episode_reward": 854.2902509707804, "episode": 22.0, "batch_reward": 0.7554997058510781, "critic_loss": 0.7690791016221047, "actor_loss": -90.19151812744141, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.72212505340576, "step": 22000}
{"episode_reward": 905.3739193538062, "episode": 23.0, "batch_reward": 0.7602833698987961, "critic_loss": 0.7002615264356137, "actor_loss": -90.17949432373047, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.40861678123474, "step": 23000}
{"episode_reward": 912.7945750224886, "episode": 24.0, "batch_reward": 0.7698618313670158, "critic_loss": 0.6184572714269161, "actor_loss": -90.40534031677247, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.796780347824097, "step": 24000}
{"episode_reward": 979.4891501079768, "episode": 25.0, "batch_reward": 0.7737876987457275, "critic_loss": 0.5814590943157673, "actor_loss": -90.28867044067383, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.775267839431763, "step": 25000}
{"episode_reward": 893.3808529689666, "episode": 26.0, "batch_reward": 0.7802640305757522, "critic_loss": 0.5434124723672867, "actor_loss": -90.32088922119141, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.13058590888977, "step": 26000}
{"episode_reward": 975.8341588034709, "episode": 27.0, "batch_reward": 0.789939458668232, "critic_loss": 0.5726348315924406, "actor_loss": -90.64464665222168, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.17825150489807, "step": 27000}
{"episode_reward": 979.4826512103679, "episode": 28.0, "batch_reward": 0.7969296730160713, "critic_loss": 0.5632340863645077, "actor_loss": -90.63552777099609, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.93090033531189, "step": 28000}
{"episode_reward": 950.5794206923222, "episode": 29.0, "batch_reward": 0.8024690570831299, "critic_loss": 0.5885369052290916, "actor_loss": -90.83823643493652, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.746782064437866, "step": 29000}
{"episode_reward": 944.2100846356315, "episode": 30.0, "batch_reward": 0.8040431456565857, "critic_loss": 0.597543523222208, "actor_loss": -90.77903977966308, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.847166538238525, "step": 30000}
{"episode_reward": 898.8155855378565, "episode": 31.0, "batch_reward": 0.8080251002311707, "critic_loss": 0.6110427441895008, "actor_loss": -90.9322577972412, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.894420862197876, "step": 31000}
{"episode_reward": 944.4046915680752, "episode": 32.0, "batch_reward": 0.8136220704317093, "critic_loss": 0.5989493461549282, "actor_loss": -91.1057813873291, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.723708391189575, "step": 32000}
{"episode_reward": 956.5456301273082, "episode": 33.0, "batch_reward": 0.8159840192198753, "critic_loss": 0.6209265537559986, "actor_loss": -91.15806240844726, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.157047033309937, "step": 33000}
{"episode_reward": 927.2905989622565, "episode": 34.0, "batch_reward": 0.8214150336384773, "critic_loss": 0.5897954244315624, "actor_loss": -90.880208694458, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.322295427322388, "step": 34000}
{"episode_reward": 980.9325458214695, "episode": 35.0, "batch_reward": 0.8230063776969909, "critic_loss": 0.6148062146902085, "actor_loss": -91.33518426513672, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.715641260147095, "step": 35000}
{"episode_reward": 836.2362552097925, "episode": 36.0, "batch_reward": 0.8251648553609848, "critic_loss": 0.5770392934530973, "actor_loss": -91.07365631103515, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.969902515411377, "step": 36000}
{"episode_reward": 940.3034199586946, "episode": 37.0, "batch_reward": 0.8259540955424309, "critic_loss": 0.5852588505148888, "actor_loss": -91.1784868774414, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.887303829193115, "step": 37000}
{"episode_reward": 951.7977643869823, "episode": 38.0, "batch_reward": 0.8330442289113998, "critic_loss": 0.5455840614438057, "actor_loss": -91.3744072265625, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.72236156463623, "step": 38000}
{"episode_reward": 982.4185331129056, "episode": 39.0, "batch_reward": 0.8339054532647133, "critic_loss": 0.5873574442863464, "actor_loss": -91.63585978698731, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.396478176116943, "step": 39000}
{"episode_reward": 901.4182110036189, "episode": 40.0, "batch_reward": 0.8381317822337151, "critic_loss": 0.560865178912878, "actor_loss": -91.64085383605958, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.090256214141846, "step": 40000}
{"episode_reward": 982.938014722178, "episode": 41.0, "batch_reward": 0.8428115696310997, "critic_loss": 0.5809996701776982, "actor_loss": -91.80051261901855, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.949090242385864, "step": 41000}
{"episode_reward": 933.0552747324703, "episode": 42.0, "batch_reward": 0.8452085398435593, "critic_loss": 0.5581713947951794, "actor_loss": -91.70739068603515, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.19107747077942, "step": 42000}
{"episode_reward": 961.0631597675447, "episode": 43.0, "batch_reward": 0.8435995037555695, "critic_loss": 0.6032812236845493, "actor_loss": -91.69143118286132, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.901684761047363, "step": 43000}
{"episode_reward": 855.2482817967278, "episode": 44.0, "batch_reward": 0.8464925694465637, "critic_loss": 0.5815489589869977, "actor_loss": -91.59858869934082, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.733463525772095, "step": 44000}
{"episode_reward": 981.09052160749, "episode": 45.0, "batch_reward": 0.8496656726598739, "critic_loss": 0.5506753641813994, "actor_loss": -91.92184988403321, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.544477939605713, "step": 45000}
{"episode_reward": 962.0697937381099, "episode": 46.0, "batch_reward": 0.8503063327074051, "critic_loss": 0.5425829770863057, "actor_loss": -91.8458849029541, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.095041275024414, "step": 46000}
{"episode_reward": 966.8660330304049, "episode": 47.0, "batch_reward": 0.854406287252903, "critic_loss": 0.5191028484553099, "actor_loss": -91.9143006439209, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.91338539123535, "step": 47000}
{"episode_reward": 972.8247944521048, "episode": 48.0, "batch_reward": 0.8557177615761757, "critic_loss": 0.5424846061021089, "actor_loss": -91.86132554626465, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.014353275299072, "step": 48000}
{"episode_reward": 893.9921485504872, "episode": 49.0, "batch_reward": 0.8588262317180634, "critic_loss": 0.5379212696403265, "actor_loss": -92.16822286987305, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.064269542694092, "step": 49000}
{"episode_reward": 929.3952344109715, "episode": 50.0, "batch_reward": 0.8586399224996567, "critic_loss": 0.49648013977706434, "actor_loss": -92.05729997253418, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.754957914352417, "step": 50000}
{"episode_reward": 983.3570841366725, "episode": 51.0, "batch_reward": 0.8627118389606476, "critic_loss": 0.5274968954920769, "actor_loss": -92.0854102935791, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.80000901222229, "step": 51000}
{"episode_reward": 981.422842799373, "episode": 52.0, "batch_reward": 0.8632511849403381, "critic_loss": 0.5529508740603923, "actor_loss": -92.35206648254395, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.115411520004272, "step": 52000}
{"episode_reward": 921.1393002438783, "episode": 53.0, "batch_reward": 0.8642270783185959, "critic_loss": 0.5230345779657364, "actor_loss": -92.23116055297852, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.182915449142456, "step": 53000}
{"episode_reward": 946.8232879092108, "episode": 54.0, "batch_reward": 0.8674421961903572, "critic_loss": 0.5106625645160675, "actor_loss": -92.40590257263183, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.731425523757935, "step": 54000}
{"episode_reward": 921.5396789933006, "episode": 55.0, "batch_reward": 0.8675642704963684, "critic_loss": 0.515777279868722, "actor_loss": -92.31627030944824, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.73497748374939, "step": 55000}
{"episode_reward": 981.6418392138347, "episode": 56.0, "batch_reward": 0.8696622945666314, "critic_loss": 0.49760540030896666, "actor_loss": -92.66700346374512, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.109719038009644, "step": 56000}
{"episode_reward": 980.6484915043719, "episode": 57.0, "batch_reward": 0.8723791071772575, "critic_loss": 0.47999797759950164, "actor_loss": -92.52386488342285, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.18107771873474, "step": 57000}
{"episode_reward": 951.698297963327, "episode": 58.0, "batch_reward": 0.872595477938652, "critic_loss": 0.47529477380216123, "actor_loss": -92.40797265625, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.593737840652466, "step": 58000}
{"episode_reward": 974.6649413142886, "episode": 59.0, "batch_reward": 0.8753509908914566, "critic_loss": 0.44696251447498797, "actor_loss": -92.56761026000977, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.35477638244629, "step": 59000}
{"episode_reward": 940.1612069376786, "episode": 60.0, "batch_reward": 0.8772391592264175, "critic_loss": 0.45771871097385886, "actor_loss": -92.8324559326172, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.73069405555725, "step": 60000}
{"episode_reward": 928.1176997093825, "episode": 61.0, "batch_reward": 0.8772248175144196, "critic_loss": 0.4601149936467409, "actor_loss": -92.69014399719238, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.67126250267029, "step": 61000}
{"episode_reward": 939.9899607004215, "episode": 62.0, "batch_reward": 0.8780609954595566, "critic_loss": 0.4561565236002207, "actor_loss": -92.65336116027832, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.221538543701172, "step": 62000}
{"episode_reward": 957.8956001455165, "episode": 63.0, "batch_reward": 0.876669418156147, "critic_loss": 0.4592698505520821, "actor_loss": -92.54582707214355, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.976929664611816, "step": 63000}
{"episode_reward": 875.851896515245, "episode": 64.0, "batch_reward": 0.8793216896057129, "critic_loss": 0.43945500886440275, "actor_loss": -92.73307151794434, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.135047912597656, "step": 64000}
{"episode_reward": 979.8665387524707, "episode": 65.0, "batch_reward": 0.8814685757160187, "critic_loss": 0.4489443699866533, "actor_loss": -92.74547431945801, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.533857822418213, "step": 65000}
{"episode_reward": 982.1057267088283, "episode": 66.0, "batch_reward": 0.8820653667449951, "critic_loss": 0.4352592454403639, "actor_loss": -92.90900883483887, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.138344526290894, "step": 66000}
{"episode_reward": 954.5829185702115, "episode": 67.0, "batch_reward": 0.8811775034666062, "critic_loss": 0.49412784847617147, "actor_loss": -93.04382077026368, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.04805040359497, "step": 67000}
{"episode_reward": 860.5216791902664, "episode": 68.0, "batch_reward": 0.8820732641816139, "critic_loss": 0.47618780517578124, "actor_loss": -92.78790426635742, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.7352294921875, "step": 68000}
{"episode_reward": 942.7992839776413, "episode": 69.0, "batch_reward": 0.8833291378617286, "critic_loss": 0.4434100217372179, "actor_loss": -92.97484324645995, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.44162392616272, "step": 69000}
{"episode_reward": 986.8395372214609, "episode": 70.0, "batch_reward": 0.8860189120173454, "critic_loss": 0.4597694010287523, "actor_loss": -93.08394215393066, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.61069393157959, "step": 70000}
{"episode_reward": 949.3111497907838, "episode": 71.0, "batch_reward": 0.8855617274045944, "critic_loss": 0.514612095683813, "actor_loss": -92.97162754821777, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 43.34843158721924, "step": 71000}
{"episode_reward": 924.5479982293105, "episode": 72.0, "batch_reward": 0.8871682856678963, "critic_loss": 0.48584885312616827, "actor_loss": -93.06507322692872, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.59347105026245, "step": 72000}
{"episode_reward": 972.0040672903814, "episode": 73.0, "batch_reward": 0.8876075701713562, "critic_loss": 0.5339568847864866, "actor_loss": -93.05503681945801, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.756205081939697, "step": 73000}
{"episode_reward": 908.6615022627292, "episode": 74.0, "batch_reward": 0.8893809955716133, "critic_loss": 0.5443475883752108, "actor_loss": -93.26500587463379, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.551517009735107, "step": 74000}
{"episode_reward": 929.3470147907005, "episode": 75.0, "batch_reward": 0.8900961062908173, "critic_loss": 0.5478204324096442, "actor_loss": -93.30641246032715, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.93792986869812, "step": 75000}
{"episode_reward": 953.6991817788288, "episode": 76.0, "batch_reward": 0.8902040281891823, "critic_loss": 0.5051720189303159, "actor_loss": -93.23437104797364, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.766090631484985, "step": 76000}
{"episode_reward": 953.8492296485816, "episode": 77.0, "batch_reward": 0.8897370779514313, "critic_loss": 0.515763488277793, "actor_loss": -93.21524319458008, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.616499423980713, "step": 77000}
{"episode_reward": 957.9192864311507, "episode": 78.0, "batch_reward": 0.8914829788804054, "critic_loss": 0.5133510341197253, "actor_loss": -93.38290867614747, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.053574085235596, "step": 78000}
{"episode_reward": 938.3078882730274, "episode": 79.0, "batch_reward": 0.8923342052698136, "critic_loss": 0.5068154677897692, "actor_loss": -93.11848159790038, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.561079025268555, "step": 79000}
{"episode_reward": 963.6168985068483, "episode": 80.0, "batch_reward": 0.892817794084549, "critic_loss": 0.5170944201499224, "actor_loss": -93.31957368469239, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.371842861175537, "step": 80000}
{"episode_reward": 969.3084530606675, "episode": 81.0, "batch_reward": 0.89397142547369, "critic_loss": 0.5277936873584985, "actor_loss": -93.41471394348144, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.07754898071289, "step": 81000}
{"episode_reward": 927.1332285373202, "episode": 82.0, "batch_reward": 0.8945707290172576, "critic_loss": 0.5062281838804483, "actor_loss": -93.5935108795166, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.25814652442932, "step": 82000}
{"episode_reward": 934.7689966256453, "episode": 83.0, "batch_reward": 0.8930848435163498, "critic_loss": 0.5271071367710829, "actor_loss": -93.3817876739502, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.675373554229736, "step": 83000}
{"episode_reward": 861.2490717010827, "episode": 84.0, "batch_reward": 0.8959166756272317, "critic_loss": 0.5420581477433443, "actor_loss": -93.67362222290039, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.632617473602295, "step": 84000}
{"episode_reward": 986.677756525186, "episode": 85.0, "batch_reward": 0.8948857130408288, "critic_loss": 0.5677603419572115, "actor_loss": -93.5580597076416, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.539923667907715, "step": 85000}
{"episode_reward": 953.0230129966519, "episode": 86.0, "batch_reward": 0.8950911395549774, "critic_loss": 0.6192433077394962, "actor_loss": -93.39135153198242, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.41600465774536, "step": 86000}
{"episode_reward": 883.3016703504537, "episode": 87.0, "batch_reward": 0.8956534621715546, "critic_loss": 0.5756854436248541, "actor_loss": -93.56910543823243, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.39507746696472, "step": 87000}
{"episode_reward": 940.1840214254204, "episode": 88.0, "batch_reward": 0.895621352493763, "critic_loss": 0.5776433422714472, "actor_loss": -93.48664553833008, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.648432731628418, "step": 88000}
{"episode_reward": 879.9276627777681, "episode": 89.0, "batch_reward": 0.8956449141502381, "critic_loss": 0.6251155346632004, "actor_loss": -93.50972454833985, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.00591254234314, "step": 89000}
{"episode_reward": 981.3549664336971, "episode": 90.0, "batch_reward": 0.8963012634515762, "critic_loss": 0.5879626331478357, "actor_loss": -93.62880798339843, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.364490747451782, "step": 90000}
{"episode_reward": 936.4941865800739, "episode": 91.0, "batch_reward": 0.8967130895256996, "critic_loss": 0.5895534770041704, "actor_loss": -93.44713090515137, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.86037278175354, "step": 91000}
{"episode_reward": 892.0456830152712, "episode": 92.0, "batch_reward": 0.8999264081716537, "critic_loss": 0.562486585572362, "actor_loss": -93.69114562988281, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.35154676437378, "step": 92000}
{"episode_reward": 956.5925895205763, "episode": 93.0, "batch_reward": 0.8971173516511917, "critic_loss": 0.5833342985212803, "actor_loss": -93.58910957336425, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.38560676574707, "step": 93000}
{"episode_reward": 984.9357043565119, "episode": 94.0, "batch_reward": 0.89839513194561, "critic_loss": 0.6100592219829559, "actor_loss": -93.65479159545899, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.92807650566101, "step": 94000}
{"episode_reward": 923.4052664637949, "episode": 95.0, "batch_reward": 0.8974724310040474, "critic_loss": 0.5743718285560608, "actor_loss": -93.71245283508301, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.762044429779053, "step": 95000}
{"episode_reward": 938.1057357759053, "episode": 96.0, "batch_reward": 0.8993949844837189, "critic_loss": 0.5835113007128239, "actor_loss": -93.75570552062989, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.664132833480835, "step": 96000}
{"episode_reward": 948.4600173593617, "episode": 97.0, "batch_reward": 0.9008604068756103, "critic_loss": 0.5787341203242541, "actor_loss": -93.78895518493653, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.236411094665527, "step": 97000}
{"episode_reward": 957.1275789352833, "episode": 98.0, "batch_reward": 0.9009636905193329, "critic_loss": 0.5606379896551371, "actor_loss": -93.69218144226075, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.642223358154297, "step": 98000}
{"episode_reward": 939.9847477231727, "episode": 99.0, "batch_reward": 0.900599573135376, "critic_loss": 0.5364215038865805, "actor_loss": -93.74224948120117, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.530343770980835, "step": 99000}
{"episode_reward": 955.1933076446871, "episode": 100.0, "batch_reward": 0.9016890054941178, "critic_loss": 0.5521612598001957, "actor_loss": -93.71417985534669, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.60050868988037, "step": 100000}
{"episode_reward": 922.711594962527, "episode": 101.0, "batch_reward": 0.9034517195224762, "critic_loss": 0.5460645000040532, "actor_loss": -93.85295469665527, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.03799605369568, "step": 101000}
{"episode_reward": 987.5551674497497, "episode": 102.0, "batch_reward": 0.902056987464428, "critic_loss": 0.5683708190917969, "actor_loss": -93.82319886779786, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.487359523773193, "step": 102000}
{"episode_reward": 943.8512888225058, "episode": 103.0, "batch_reward": 0.9024965347647667, "critic_loss": 0.5633155884444714, "actor_loss": -93.79705513000488, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.5865216255188, "step": 103000}
{"episode_reward": 961.5941470173209, "episode": 104.0, "batch_reward": 0.9045373967289925, "critic_loss": 0.5824896585941315, "actor_loss": -93.90648880004883, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.69566559791565, "step": 104000}
{"episode_reward": 958.3913569584835, "episode": 105.0, "batch_reward": 0.9040577902793884, "critic_loss": 0.565923068150878, "actor_loss": -93.9342281036377, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.445083379745483, "step": 105000}
{"episode_reward": 874.146653757628, "episode": 106.0, "batch_reward": 0.9037334225773811, "critic_loss": 0.5429138676971197, "actor_loss": -93.83596006774903, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.89471197128296, "step": 106000}
{"episode_reward": 898.9038044098695, "episode": 107.0, "batch_reward": 0.9037334660887718, "critic_loss": 0.5358634746670723, "actor_loss": -93.76222540283203, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.834980487823486, "step": 107000}
{"episode_reward": 959.1044104679096, "episode": 108.0, "batch_reward": 0.9056469441056252, "critic_loss": 0.5229021991342306, "actor_loss": -93.94860675048828, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.74004054069519, "step": 108000}
{"episode_reward": 945.7266848869381, "episode": 109.0, "batch_reward": 0.9046647159457206, "critic_loss": 0.5303796841651202, "actor_loss": -93.9912023010254, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.08376121520996, "step": 109000}
{"episode_reward": 973.7366663312595, "episode": 110.0, "batch_reward": 0.9053131713271141, "critic_loss": 0.505812146037817, "actor_loss": -93.95756433105468, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.627495050430298, "step": 110000}
{"episode_reward": 931.5518195144106, "episode": 111.0, "batch_reward": 0.9044285049438476, "critic_loss": 0.5042704371362925, "actor_loss": -94.00416737365722, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 43.15890192985535, "step": 111000}
{"episode_reward": 853.6606546609047, "episode": 112.0, "batch_reward": 0.9041514557003975, "critic_loss": 0.507260492309928, "actor_loss": -93.88012960815429, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.772597789764404, "step": 112000}
{"episode_reward": 929.5660783177822, "episode": 113.0, "batch_reward": 0.9057409447431565, "critic_loss": 0.5115797492414713, "actor_loss": -93.91129579162597, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.51109552383423, "step": 113000}
{"episode_reward": 959.7086749942126, "episode": 114.0, "batch_reward": 0.9058983910679818, "critic_loss": 0.5054782359302044, "actor_loss": -94.13989018249512, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.38542366027832, "step": 114000}
{"episode_reward": 971.519081014884, "episode": 115.0, "batch_reward": 0.9063930318355561, "critic_loss": 0.5252487526237964, "actor_loss": -94.0008758544922, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.820247411727905, "step": 115000}
{"episode_reward": 921.9788367093721, "episode": 116.0, "batch_reward": 0.9062623329162598, "critic_loss": 0.5728290415257216, "actor_loss": -94.10263693237304, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.563771724700928, "step": 116000}
{"episode_reward": 955.4143105878861, "episode": 117.0, "batch_reward": 0.9066838299036026, "critic_loss": 0.5723285921514034, "actor_loss": -93.88163156127929, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.010844945907593, "step": 117000}
{"episode_reward": 929.3581317882185, "episode": 118.0, "batch_reward": 0.9077322649359703, "critic_loss": 0.5637717808336019, "actor_loss": -94.08990335083008, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.367385387420654, "step": 118000}
{"episode_reward": 986.1234241433717, "episode": 119.0, "batch_reward": 0.9070486711859703, "critic_loss": 0.5601250264942647, "actor_loss": -94.10699482727051, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.829193353652954, "step": 119000}
{"episode_reward": 928.0150852716765, "episode": 120.0, "batch_reward": 0.9068782286643982, "critic_loss": 0.5894886018037796, "actor_loss": -93.96089993286132, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.450050115585327, "step": 120000}
{"episode_reward": 876.1164661005763, "episode": 121.0, "batch_reward": 0.9081111054420471, "critic_loss": 0.6082609688490629, "actor_loss": -93.99882243347167, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 43.250136613845825, "step": 121000}
{"episode_reward": 986.797495403574, "episode": 122.0, "batch_reward": 0.9069912070035935, "critic_loss": 0.6372681569308043, "actor_loss": -93.99813432312011, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.56913948059082, "step": 122000}
{"episode_reward": 835.7558719419741, "episode": 123.0, "batch_reward": 0.9077241637706757, "critic_loss": 0.5789550851285458, "actor_loss": -93.78349453735352, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.53400182723999, "step": 123000}
{"episode_reward": 949.5777916223317, "episode": 124.0, "batch_reward": 0.9079219620227814, "critic_loss": 0.590492223829031, "actor_loss": -93.98383825683594, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.035858392715454, "step": 124000}
{"episode_reward": 951.2762842703022, "episode": 125.0, "batch_reward": 0.9092484102249145, "critic_loss": 0.5818038370832801, "actor_loss": -94.03515913391114, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.55709195137024, "step": 125000}
{"episode_reward": 987.7236887885148, "episode": 126.0, "batch_reward": 0.9100739708542824, "critic_loss": 0.5412068883925676, "actor_loss": -94.20696942138672, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.38119649887085, "step": 126000}
{"episode_reward": 979.1742107588859, "episode": 127.0, "batch_reward": 0.9082848750948906, "critic_loss": 0.5752891522794962, "actor_loss": -94.03916737365722, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.228604555130005, "step": 127000}
{"episode_reward": 852.2852037175572, "episode": 128.0, "batch_reward": 0.9078379911780358, "critic_loss": 0.5845098049193621, "actor_loss": -94.06239865112305, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.535441398620605, "step": 128000}
{"episode_reward": 967.4091663845054, "episode": 129.0, "batch_reward": 0.9099601686000824, "critic_loss": 0.5661467153578996, "actor_loss": -94.18105049133301, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.838761806488037, "step": 129000}
{"episode_reward": 983.1190359236496, "episode": 130.0, "batch_reward": 0.9106519414186478, "critic_loss": 0.5482741288989782, "actor_loss": -94.19332423400878, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.40704846382141, "step": 130000}
{"episode_reward": 990.2757180257097, "episode": 131.0, "batch_reward": 0.9122988389730453, "critic_loss": 0.5476671944260597, "actor_loss": -94.20024276733399, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.23341417312622, "step": 131000}
{"episode_reward": 985.2672086369565, "episode": 132.0, "batch_reward": 0.9120934534072876, "critic_loss": 0.5394699126631022, "actor_loss": -94.26912623596192, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.508631467819214, "step": 132000}
{"episode_reward": 985.146252814167, "episode": 133.0, "batch_reward": 0.9122234487533569, "critic_loss": 0.5438502803593874, "actor_loss": -94.17246226501464, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.087629318237305, "step": 133000}
{"episode_reward": 961.9880143387535, "episode": 134.0, "batch_reward": 0.9117399492263794, "critic_loss": 0.5724898160994053, "actor_loss": -94.22448873901367, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.52517867088318, "step": 134000}
{"episode_reward": 932.5527353325482, "episode": 135.0, "batch_reward": 0.9143943750858307, "critic_loss": 0.5643974455147982, "actor_loss": -94.3606495513916, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.014302968978882, "step": 135000}
{"episode_reward": 991.2859438472176, "episode": 136.0, "batch_reward": 0.9127617178559303, "critic_loss": 0.564737414047122, "actor_loss": -94.35875386047363, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.526488542556763, "step": 136000}
{"episode_reward": 986.2569103069014, "episode": 137.0, "batch_reward": 0.9124178739786148, "critic_loss": 0.5698473842144013, "actor_loss": -94.26150959777831, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.666486978530884, "step": 137000}
{"episode_reward": 969.855255239998, "episode": 138.0, "batch_reward": 0.9139428461194038, "critic_loss": 0.5603639967292547, "actor_loss": -94.20804751586914, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.590412616729736, "step": 138000}
{"episode_reward": 955.404653227152, "episode": 139.0, "batch_reward": 0.9138527467846871, "critic_loss": 0.5791782118231058, "actor_loss": -94.31147477722168, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.598371744155884, "step": 139000}
{"episode_reward": 989.9287557113852, "episode": 140.0, "batch_reward": 0.9153529218435288, "critic_loss": 0.5682100592851639, "actor_loss": -94.30928102111817, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.1154944896698, "step": 140000}
{"episode_reward": 942.0967619076221, "episode": 141.0, "batch_reward": 0.9155288856029511, "critic_loss": 0.5636078513264656, "actor_loss": -94.28808389282227, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.48223829269409, "step": 141000}
{"episode_reward": 965.4479258005339, "episode": 142.0, "batch_reward": 0.9155070955753326, "critic_loss": 0.525663886025548, "actor_loss": -94.37111141967773, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.11568307876587, "step": 142000}
{"episode_reward": 985.9548503632735, "episode": 143.0, "batch_reward": 0.9173589704632759, "critic_loss": 0.5227597536891699, "actor_loss": -94.42543702697753, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.579243898391724, "step": 143000}
{"episode_reward": 933.7467062187193, "episode": 144.0, "batch_reward": 0.9157599750161171, "critic_loss": 0.5711826808005571, "actor_loss": -94.45575666809081, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.573497533798218, "step": 144000}
{"episode_reward": 921.0233319890733, "episode": 145.0, "batch_reward": 0.9163528178930282, "critic_loss": 0.5381235892027616, "actor_loss": -94.42479400634765, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.7095730304718, "step": 145000}
{"episode_reward": 987.5773056597639, "episode": 146.0, "batch_reward": 0.9158734298944473, "critic_loss": 0.5504704439714551, "actor_loss": -94.47539900207519, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.608062744140625, "step": 146000}
{"episode_reward": 968.690087109475, "episode": 147.0, "batch_reward": 0.9168996101617813, "critic_loss": 0.5189695152491332, "actor_loss": -94.51750064086914, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.56449556350708, "step": 147000}
{"episode_reward": 953.8722193627472, "episode": 148.0, "batch_reward": 0.918074724316597, "critic_loss": 0.5281654161512852, "actor_loss": -94.51357389831543, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.958057641983032, "step": 148000}
{"episode_reward": 990.014782985692, "episode": 149.0, "batch_reward": 0.9168071339726448, "critic_loss": 0.5306044200062752, "actor_loss": -94.47095838928223, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.52677273750305, "step": 149000}
{"episode_reward": 953.6239030622754, "episode": 150.0, "batch_reward": 0.9175807107686996, "critic_loss": 0.5514191625267267, "actor_loss": -94.61434907531738, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
