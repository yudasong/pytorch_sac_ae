{"episode_reward": 0.0, "episode": 1.0, "duration": 22.278773069381714, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.8481922149658203, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.4665808878607971, "critic_loss": 0.5897487700084878, "actor_loss": -84.87757447339287, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 62.2845561504364, "step": 3000}
{"episode_reward": 298.3292484295521, "episode": 4.0, "batch_reward": 0.37489586985111234, "critic_loss": 0.7861550275385379, "actor_loss": -84.62778077697754, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.572057008743286, "step": 4000}
{"episode_reward": 72.00413154251609, "episode": 5.0, "batch_reward": 0.36767868542671206, "critic_loss": 0.7604519389271737, "actor_loss": -85.06126916503906, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.224452018737793, "step": 5000}
{"episode_reward": 521.5161685599935, "episode": 6.0, "batch_reward": 0.3904105051457882, "critic_loss": 0.739890912026167, "actor_loss": -84.9119037475586, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.31716823577881, "step": 6000}
{"episode_reward": 617.1630806093896, "episode": 7.0, "batch_reward": 0.4391449421942234, "critic_loss": 0.7652728834748268, "actor_loss": -85.15148724365234, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.81932282447815, "step": 7000}
{"episode_reward": 786.0597879972091, "episode": 8.0, "batch_reward": 0.4653354477286339, "critic_loss": 0.8752024187743663, "actor_loss": -85.03068579101563, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.20323896408081, "step": 8000}
{"episode_reward": 521.6512647863686, "episode": 9.0, "batch_reward": 0.46871864548325537, "critic_loss": 1.1996257165074349, "actor_loss": -84.73826875305176, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.647663354873657, "step": 9000}
{"episode_reward": 608.461210028152, "episode": 10.0, "batch_reward": 0.49362116104364395, "critic_loss": 1.0776360362768174, "actor_loss": -85.39297848510742, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.562628984451294, "step": 10000}
{"episode_reward": 764.3330648788987, "episode": 11.0, "batch_reward": 0.5252452412843704, "critic_loss": 0.9154385915994644, "actor_loss": -85.8899324798584, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.112990856170654, "step": 11000}
{"episode_reward": 880.5568947916825, "episode": 12.0, "batch_reward": 0.5552793331444263, "critic_loss": 0.8650533039271832, "actor_loss": -85.99971720886231, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.27993893623352, "step": 12000}
{"episode_reward": 828.7633293994394, "episode": 13.0, "batch_reward": 0.5769685553312301, "critic_loss": 0.8991236011981965, "actor_loss": -86.09357380676269, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.280083656311035, "step": 13000}
{"episode_reward": 837.8366805111687, "episode": 14.0, "batch_reward": 0.596702467918396, "critic_loss": 0.9770538715720176, "actor_loss": -86.27119953918456, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.20768928527832, "step": 14000}
{"episode_reward": 787.7224499033607, "episode": 15.0, "batch_reward": 0.6158239631950855, "critic_loss": 1.0155947330594062, "actor_loss": -86.63929313659668, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.921552658081055, "step": 15000}
{"episode_reward": 933.8418385595293, "episode": 16.0, "batch_reward": 0.630060842514038, "critic_loss": 1.1250005632042885, "actor_loss": -86.73234365844726, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.305261850357056, "step": 16000}
{"episode_reward": 809.5001582246348, "episode": 17.0, "batch_reward": 0.6396564403176308, "critic_loss": 1.1623988631367683, "actor_loss": -86.72452186584472, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.224205493927002, "step": 17000}
{"episode_reward": 796.7280484081666, "episode": 18.0, "batch_reward": 0.6558067255616188, "critic_loss": 1.073399284183979, "actor_loss": -87.01343220520019, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.763131856918335, "step": 18000}
{"episode_reward": 931.7663566260684, "episode": 19.0, "batch_reward": 0.6718833179473876, "critic_loss": 1.097800755381584, "actor_loss": -87.60706025695801, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.519462823867798, "step": 19000}
{"episode_reward": 980.1923141080637, "episode": 20.0, "batch_reward": 0.6856643590331077, "critic_loss": 1.098359513282776, "actor_loss": -88.03085508728027, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.504675149917603, "step": 20000}
{"episode_reward": 923.7608085932005, "episode": 21.0, "batch_reward": 0.6950943009853363, "critic_loss": 1.0642834854722023, "actor_loss": -88.34938377380371, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.878230571746826, "step": 21000}
{"episode_reward": 873.7894452691826, "episode": 22.0, "batch_reward": 0.7102859743237495, "critic_loss": 0.8731542602777481, "actor_loss": -88.55462757873535, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.173523426055908, "step": 22000}
{"episode_reward": 982.9292352557485, "episode": 23.0, "batch_reward": 0.70517912119627, "critic_loss": 0.8514411351382732, "actor_loss": -88.44428825378418, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.24028992652893, "step": 23000}
{"episode_reward": 524.0963092257426, "episode": 24.0, "batch_reward": 0.711024536550045, "critic_loss": 0.7649200178086758, "actor_loss": -88.80927116394042, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.895153522491455, "step": 24000}
{"episode_reward": 983.7858818295377, "episode": 25.0, "batch_reward": 0.719697714149952, "critic_loss": 0.7067163014113903, "actor_loss": -88.86801820373535, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.520575284957886, "step": 25000}
{"episode_reward": 954.7752192253146, "episode": 26.0, "batch_reward": 0.7289659232497215, "critic_loss": 0.6852035239636898, "actor_loss": -89.05963105773925, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.655789613723755, "step": 26000}
{"episode_reward": 970.0947452178265, "episode": 27.0, "batch_reward": 0.7415646106004715, "critic_loss": 0.5909257870018482, "actor_loss": -89.42987022399902, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.21811079978943, "step": 27000}
{"episode_reward": 976.8676779411343, "episode": 28.0, "batch_reward": 0.7481769803166389, "critic_loss": 0.5665012449622154, "actor_loss": -89.57932389831544, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.50493884086609, "step": 28000}
{"episode_reward": 938.2809752931838, "episode": 29.0, "batch_reward": 0.7539486058354378, "critic_loss": 0.5739725521802902, "actor_loss": -89.75903747558594, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.929115056991577, "step": 29000}
{"episode_reward": 907.2443535648159, "episode": 30.0, "batch_reward": 0.7604406045675278, "critic_loss": 0.5477623295783997, "actor_loss": -89.85383221435546, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.234163761138916, "step": 30000}
{"episode_reward": 927.2174451705965, "episode": 31.0, "batch_reward": 0.7640315511226654, "critic_loss": 0.5325392157733441, "actor_loss": -90.00773223876953, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.59241080284119, "step": 31000}
{"episode_reward": 897.6164809337565, "episode": 32.0, "batch_reward": 0.7670547449588776, "critic_loss": 0.5507742809951306, "actor_loss": -89.93467390441894, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.232597589492798, "step": 32000}
{"episode_reward": 837.2884462855086, "episode": 33.0, "batch_reward": 0.7716948673725128, "critic_loss": 0.5545742972046137, "actor_loss": -89.90376699829102, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.18949580192566, "step": 33000}
{"episode_reward": 928.5134421698392, "episode": 34.0, "batch_reward": 0.7735769557356834, "critic_loss": 0.5538458962738514, "actor_loss": -89.65773951721191, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.477943181991577, "step": 34000}
{"episode_reward": 893.7488939494675, "episode": 35.0, "batch_reward": 0.7800929614305496, "critic_loss": 0.5770722165107727, "actor_loss": -90.02323973083496, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.435582637786865, "step": 35000}
{"episode_reward": 933.818687893283, "episode": 36.0, "batch_reward": 0.782703471004963, "critic_loss": 0.5802834051698447, "actor_loss": -89.86350486755371, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.208770513534546, "step": 36000}
{"episode_reward": 917.8256044471045, "episode": 37.0, "batch_reward": 0.7859515318870545, "critic_loss": 0.5984366129636765, "actor_loss": -89.90357406616211, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.852813243865967, "step": 37000}
{"episode_reward": 955.4694716435677, "episode": 38.0, "batch_reward": 0.7919095240831375, "critic_loss": 0.5978087293207646, "actor_loss": -90.16923565673828, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.564914226531982, "step": 38000}
{"episode_reward": 979.1010985480475, "episode": 39.0, "batch_reward": 0.7963252930045128, "critic_loss": 0.5890417216420174, "actor_loss": -90.49981318664551, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35353970527649, "step": 39000}
{"episode_reward": 951.3737834001897, "episode": 40.0, "batch_reward": 0.7995589142441749, "critic_loss": 0.5851060210764408, "actor_loss": -90.59150563049316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.22289729118347, "step": 40000}
{"episode_reward": 967.9939025833878, "episode": 41.0, "batch_reward": 0.8060342981219292, "critic_loss": 0.595810896590352, "actor_loss": -90.74818580627442, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.514556646347046, "step": 41000}
{"episode_reward": 935.1283307156092, "episode": 42.0, "batch_reward": 0.8099607187509537, "critic_loss": 0.5328424505293369, "actor_loss": -90.75505633544923, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.2033953666687, "step": 42000}
{"episode_reward": 957.7341539098227, "episode": 43.0, "batch_reward": 0.8115291599035263, "critic_loss": 0.5151040579378605, "actor_loss": -90.87140072631836, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.45835304260254, "step": 43000}
{"episode_reward": 961.6467378145372, "episode": 44.0, "batch_reward": 0.8153299906849861, "critic_loss": 0.4818632193952799, "actor_loss": -90.89728587341308, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.20004963874817, "step": 44000}
{"episode_reward": 979.3846896782802, "episode": 45.0, "batch_reward": 0.8182618258595467, "critic_loss": 0.5254733440130949, "actor_loss": -91.1401651916504, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.362730979919434, "step": 45000}
{"episode_reward": 887.1478069262612, "episode": 46.0, "batch_reward": 0.8195170390605927, "critic_loss": 0.5124402013868093, "actor_loss": -91.20201075744629, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.75829792022705, "step": 46000}
{"episode_reward": 962.7427604895553, "episode": 47.0, "batch_reward": 0.8238397374749183, "critic_loss": 0.496623470261693, "actor_loss": -91.14819438171386, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.63851308822632, "step": 47000}
{"episode_reward": 979.0241451065957, "episode": 48.0, "batch_reward": 0.8251167495846748, "critic_loss": 0.5032184820622205, "actor_loss": -91.20155924987793, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.15809965133667, "step": 48000}
{"episode_reward": 931.7724683986065, "episode": 49.0, "batch_reward": 0.8282278735637665, "critic_loss": 0.5312855876684189, "actor_loss": -91.40958226013184, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.212055921554565, "step": 49000}
{"episode_reward": 917.2509005762681, "episode": 50.0, "batch_reward": 0.8299208262562752, "critic_loss": 0.5092821235507726, "actor_loss": -91.41091862487794, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.115869522094727, "step": 50000}
{"episode_reward": 988.655799736004, "episode": 51.0, "batch_reward": 0.8345750796794892, "critic_loss": 0.48884609565138815, "actor_loss": -91.49098895263671, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.871267795562744, "step": 51000}
{"episode_reward": 982.9330449584061, "episode": 52.0, "batch_reward": 0.8367251453995704, "critic_loss": 0.49934068366885187, "actor_loss": -91.80128834533691, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.214782238006592, "step": 52000}
{"episode_reward": 959.8355168720008, "episode": 53.0, "batch_reward": 0.8381949427127838, "critic_loss": 0.5402264845967293, "actor_loss": -91.74076602172852, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.502920150756836, "step": 53000}
{"episode_reward": 929.9317352582393, "episode": 54.0, "batch_reward": 0.8402909109592438, "critic_loss": 0.5471705153137445, "actor_loss": -91.80883883666992, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.3283371925354, "step": 54000}
{"episode_reward": 929.939933674661, "episode": 55.0, "batch_reward": 0.8419825573563575, "critic_loss": 0.5562890121787787, "actor_loss": -91.77347166442871, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.190073013305664, "step": 55000}
{"episode_reward": 969.2310967529011, "episode": 56.0, "batch_reward": 0.8452170462012291, "critic_loss": 0.561613877132535, "actor_loss": -92.0719794921875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.94359803199768, "step": 56000}
{"episode_reward": 973.5424215132435, "episode": 57.0, "batch_reward": 0.8475573764443397, "critic_loss": 0.5551965972185134, "actor_loss": -92.14477490234376, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.33933115005493, "step": 57000}
{"episode_reward": 940.7884561475929, "episode": 58.0, "batch_reward": 0.8497470427751541, "critic_loss": 0.5284884263575077, "actor_loss": -92.02782858276368, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.20353674888611, "step": 58000}
{"episode_reward": 974.4332862023226, "episode": 59.0, "batch_reward": 0.8528249804973602, "critic_loss": 0.530030443161726, "actor_loss": -92.27810516357422, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.580653429031372, "step": 59000}
{"episode_reward": 945.5386411016683, "episode": 60.0, "batch_reward": 0.8527359132170678, "critic_loss": 0.5450336325913667, "actor_loss": -92.49049009704589, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.60454821586609, "step": 60000}
{"episode_reward": 932.0298994642737, "episode": 61.0, "batch_reward": 0.8544197221398353, "critic_loss": 0.5573421305716038, "actor_loss": -92.21453346252441, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.289066553115845, "step": 61000}
{"episode_reward": 917.5075984643004, "episode": 62.0, "batch_reward": 0.8537700700759888, "critic_loss": 0.5486953515857458, "actor_loss": -92.17800190734863, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.2664897441864, "step": 62000}
{"episode_reward": 946.7731213556316, "episode": 63.0, "batch_reward": 0.8539408584237098, "critic_loss": 0.5216782828867436, "actor_loss": -92.38500143432617, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.34909677505493, "step": 63000}
{"episode_reward": 913.7451433747552, "episode": 64.0, "batch_reward": 0.8571959181427956, "critic_loss": 0.5127641613483429, "actor_loss": -92.45588453674317, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.23548913002014, "step": 64000}
{"episode_reward": 980.8764356515771, "episode": 65.0, "batch_reward": 0.8595856768488884, "critic_loss": 0.5305960927605629, "actor_loss": -92.53811599731445, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.194255590438843, "step": 65000}
{"episode_reward": 975.673939774166, "episode": 66.0, "batch_reward": 0.860220775783062, "critic_loss": 0.538190114825964, "actor_loss": -92.55547946166992, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.583876132965088, "step": 66000}
{"episode_reward": 948.2549833535923, "episode": 67.0, "batch_reward": 0.8585814488530159, "critic_loss": 0.5993989581614733, "actor_loss": -92.62025338745117, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.912245750427246, "step": 67000}
{"episode_reward": 734.7676925414659, "episode": 68.0, "batch_reward": 0.8600235838890076, "critic_loss": 0.6056111500263214, "actor_loss": -92.3816912689209, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.21823501586914, "step": 68000}
{"episode_reward": 949.5789813850284, "episode": 69.0, "batch_reward": 0.862242386341095, "critic_loss": 0.5757564742863178, "actor_loss": -92.66946524047852, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.21868658065796, "step": 69000}
{"episode_reward": 989.2080951580518, "episode": 70.0, "batch_reward": 0.863856884419918, "critic_loss": 0.5618820664584636, "actor_loss": -92.68340007019043, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.215001106262207, "step": 70000}
{"episode_reward": 941.529844761808, "episode": 71.0, "batch_reward": 0.8639323234558105, "critic_loss": 0.5469407512396574, "actor_loss": -92.58337519836425, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.634992599487305, "step": 71000}
{"episode_reward": 948.9391283508623, "episode": 72.0, "batch_reward": 0.866501551926136, "critic_loss": 0.5476003809720278, "actor_loss": -92.69092176818847, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.59261441230774, "step": 72000}
{"episode_reward": 974.574279392081, "episode": 73.0, "batch_reward": 0.8662266725301743, "critic_loss": 0.5433232570439577, "actor_loss": -92.77268661499023, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.723886013031006, "step": 73000}
{"episode_reward": 922.878433065252, "episode": 74.0, "batch_reward": 0.8690112794041633, "critic_loss": 0.5163388494849205, "actor_loss": -92.91670167541504, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.208190441131592, "step": 74000}
{"episode_reward": 936.9235076596492, "episode": 75.0, "batch_reward": 0.8691195110678673, "critic_loss": 0.5061328858882189, "actor_loss": -92.92516787719727, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.58278727531433, "step": 75000}
{"episode_reward": 956.6656575955564, "episode": 76.0, "batch_reward": 0.8706347437500954, "critic_loss": 0.48717058169841765, "actor_loss": -92.88101625061036, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.004058599472046, "step": 76000}
{"episode_reward": 928.8382127568598, "episode": 77.0, "batch_reward": 0.8704608677029609, "critic_loss": 0.4906475408375263, "actor_loss": -92.86093049621581, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.191829442977905, "step": 77000}
{"episode_reward": 963.4989824556484, "episode": 78.0, "batch_reward": 0.8723640142679214, "critic_loss": 0.4755498195588589, "actor_loss": -93.04715235900879, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.05737042427063, "step": 78000}
{"episode_reward": 911.6734836354109, "episode": 79.0, "batch_reward": 0.8721382776498795, "critic_loss": 0.462772155418992, "actor_loss": -92.89247294616699, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.53989338874817, "step": 79000}
{"episode_reward": 961.7474766260125, "episode": 80.0, "batch_reward": 0.8733999513983727, "critic_loss": 0.48481582617759705, "actor_loss": -92.93640914916992, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.385987281799316, "step": 80000}
{"episode_reward": 972.1096519260905, "episode": 81.0, "batch_reward": 0.8746710735559463, "critic_loss": 0.48553964449465276, "actor_loss": -93.10796437072754, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.26531624794006, "step": 81000}
{"episode_reward": 917.7135781286534, "episode": 82.0, "batch_reward": 0.8760804901719094, "critic_loss": 0.4693342810720205, "actor_loss": -93.14522041320801, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.881694316864014, "step": 82000}
{"episode_reward": 960.856656649124, "episode": 83.0, "batch_reward": 0.8769784487485885, "critic_loss": 0.46125504940748213, "actor_loss": -93.1329404296875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.199831008911133, "step": 83000}
{"episode_reward": 929.7271270473524, "episode": 84.0, "batch_reward": 0.8786593560576439, "critic_loss": 0.47621525022387506, "actor_loss": -93.24551423645019, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.74954056739807, "step": 84000}
{"episode_reward": 989.1052453798418, "episode": 85.0, "batch_reward": 0.8769708542227745, "critic_loss": 0.45371728093922137, "actor_loss": -93.209701171875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.56630253791809, "step": 85000}
{"episode_reward": 947.6649376071285, "episode": 86.0, "batch_reward": 0.8778950163125991, "critic_loss": 0.4649864448904991, "actor_loss": -93.05485479736328, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.526655435562134, "step": 86000}
{"episode_reward": 888.1502889805129, "episode": 87.0, "batch_reward": 0.8799155052900315, "critic_loss": 0.4741988366395235, "actor_loss": -93.15939402770996, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.183436393737793, "step": 87000}
{"episode_reward": 955.1828725445175, "episode": 88.0, "batch_reward": 0.880501673579216, "critic_loss": 0.4684804071933031, "actor_loss": -93.09400021362305, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.2036612033844, "step": 88000}
{"episode_reward": 935.1502178258669, "episode": 89.0, "batch_reward": 0.8789962558150292, "critic_loss": 0.48793488766252996, "actor_loss": -93.18703601074219, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.087055683135986, "step": 89000}
{"episode_reward": 970.9980637874494, "episode": 90.0, "batch_reward": 0.8816404303312302, "critic_loss": 0.4711588201522827, "actor_loss": -93.37133686828614, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.214358806610107, "step": 90000}
{"episode_reward": 955.6884384207482, "episode": 91.0, "batch_reward": 0.8825701187849044, "critic_loss": 0.46574778321385385, "actor_loss": -93.27522872924804, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.539976596832275, "step": 91000}
{"episode_reward": 936.0011078475372, "episode": 92.0, "batch_reward": 0.8851964733600617, "critic_loss": 0.4346531212031841, "actor_loss": -93.46518936157227, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.236687183380127, "step": 92000}
{"episode_reward": 960.5720069890659, "episode": 93.0, "batch_reward": 0.8833621357679367, "critic_loss": 0.4470336379557848, "actor_loss": -93.40641163635254, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.202306032180786, "step": 93000}
{"episode_reward": 986.8362489469605, "episode": 94.0, "batch_reward": 0.8845337233543396, "critic_loss": 0.43726923026144504, "actor_loss": -93.42525019836425, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.460512161254883, "step": 94000}
{"episode_reward": 925.1626233406615, "episode": 95.0, "batch_reward": 0.8837796458601952, "critic_loss": 0.43494601412117484, "actor_loss": -93.53141656494141, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.215627193450928, "step": 95000}
{"episode_reward": 934.6181976055266, "episode": 96.0, "batch_reward": 0.8862446120977402, "critic_loss": 0.39792080041766165, "actor_loss": -93.5076953277588, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.24189567565918, "step": 96000}
{"episode_reward": 958.4489513053722, "episode": 97.0, "batch_reward": 0.8866804297566414, "critic_loss": 0.4166737657263875, "actor_loss": -93.55358010864258, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.80105972290039, "step": 97000}
{"episode_reward": 917.2512743870653, "episode": 98.0, "batch_reward": 0.8879188736081123, "critic_loss": 0.40150185066461563, "actor_loss": -93.58488861083984, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.518454790115356, "step": 98000}
{"episode_reward": 955.9973297092254, "episode": 99.0, "batch_reward": 0.8869135377407074, "critic_loss": 0.42127556997537613, "actor_loss": -93.57729595947265, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.696082830429077, "step": 99000}
{"episode_reward": 912.780655719528, "episode": 100.0, "batch_reward": 0.8881701244115829, "critic_loss": 0.4337689616829157, "actor_loss": -93.59900422668457, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.179959058761597, "step": 100000}
{"episode_reward": 880.8297929898687, "episode": 101.0, "batch_reward": 0.8890036146044731, "critic_loss": 0.43860062111914155, "actor_loss": -93.72080541992187, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.6429762840271, "step": 101000}
{"episode_reward": 985.7927493456353, "episode": 102.0, "batch_reward": 0.8879403899908066, "critic_loss": 0.4342389055415988, "actor_loss": -93.59629736328125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.240002155303955, "step": 102000}
{"episode_reward": 981.2263599672065, "episode": 103.0, "batch_reward": 0.8885664790272713, "critic_loss": 0.4224168374463916, "actor_loss": -93.61553617858887, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.814558267593384, "step": 103000}
{"episode_reward": 960.9274218414977, "episode": 104.0, "batch_reward": 0.8916644158959389, "critic_loss": 0.42256816433370115, "actor_loss": -93.708787109375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.308736085891724, "step": 104000}
{"episode_reward": 949.9755482016726, "episode": 105.0, "batch_reward": 0.8919639813303948, "critic_loss": 0.41315369319915773, "actor_loss": -93.81636901855468, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.240036010742188, "step": 105000}
{"episode_reward": 904.61450039425, "episode": 106.0, "batch_reward": 0.8915736309885979, "critic_loss": 0.4126485447138548, "actor_loss": -93.6932894744873, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.432272911071777, "step": 106000}
{"episode_reward": 882.8314985540959, "episode": 107.0, "batch_reward": 0.8913599996566772, "critic_loss": 0.427044457398355, "actor_loss": -93.70515090942382, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.57954168319702, "step": 107000}
{"episode_reward": 957.7374520488165, "episode": 108.0, "batch_reward": 0.8929201445579529, "critic_loss": 0.40892999060451984, "actor_loss": -93.8531294555664, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.913095235824585, "step": 108000}
{"episode_reward": 913.2865153156907, "episode": 109.0, "batch_reward": 0.8921005702614784, "critic_loss": 0.4278920182287693, "actor_loss": -93.81995967102051, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.212033987045288, "step": 109000}
{"episode_reward": 955.8176797823012, "episode": 110.0, "batch_reward": 0.8928970831036568, "critic_loss": 0.4127200945317745, "actor_loss": -93.89356854248047, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.44017195701599, "step": 110000}
{"episode_reward": 942.6406321976224, "episode": 111.0, "batch_reward": 0.8924873594045639, "critic_loss": 0.42067020665109156, "actor_loss": -93.92994128417969, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.40443515777588, "step": 111000}
{"episode_reward": 931.7783710537833, "episode": 112.0, "batch_reward": 0.8932303821444512, "critic_loss": 0.41099663671851155, "actor_loss": -93.88816947937012, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.069246768951416, "step": 112000}
{"episode_reward": 941.2208190562494, "episode": 113.0, "batch_reward": 0.8937931812405586, "critic_loss": 0.4198778119534254, "actor_loss": -93.84880554199219, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.595009803771973, "step": 113000}
{"episode_reward": 927.7351727298559, "episode": 114.0, "batch_reward": 0.8945782577395439, "critic_loss": 0.3946829060316086, "actor_loss": -93.98769357299804, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.401551485061646, "step": 114000}
{"episode_reward": 964.4403009476684, "episode": 115.0, "batch_reward": 0.894517907679081, "critic_loss": 0.40432523065805437, "actor_loss": -93.89271569824218, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.17450785636902, "step": 115000}
{"episode_reward": 937.8514151424563, "episode": 116.0, "batch_reward": 0.8946581089496612, "critic_loss": 0.41104845255613326, "actor_loss": -93.97310749816894, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35278081893921, "step": 116000}
{"episode_reward": 943.3477502343464, "episode": 117.0, "batch_reward": 0.8953117603659629, "critic_loss": 0.4317669634371996, "actor_loss": -93.90601531982422, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.58293914794922, "step": 117000}
{"episode_reward": 912.8724529559471, "episode": 118.0, "batch_reward": 0.8957335922122002, "critic_loss": 0.4055117038786411, "actor_loss": -93.99122772216796, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.91371989250183, "step": 118000}
{"episode_reward": 985.0001339751195, "episode": 119.0, "batch_reward": 0.8962393380403518, "critic_loss": 0.37788881050795314, "actor_loss": -93.99149169921876, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.23560619354248, "step": 119000}
{"episode_reward": 954.0563612429308, "episode": 120.0, "batch_reward": 0.8953792165517807, "critic_loss": 0.3833278304561973, "actor_loss": -93.90172514343261, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.46844744682312, "step": 120000}
{"episode_reward": 935.7855179616942, "episode": 121.0, "batch_reward": 0.8974835572838783, "critic_loss": 0.3744203827530146, "actor_loss": -94.06379304504395, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.336111068725586, "step": 121000}
{"episode_reward": 982.8614005361635, "episode": 122.0, "batch_reward": 0.8968472631573677, "critic_loss": 0.38240263406932357, "actor_loss": -94.07776052856445, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.193740844726562, "step": 122000}
{"episode_reward": 936.2027479811868, "episode": 123.0, "batch_reward": 0.8980848650932312, "critic_loss": 0.400092514693737, "actor_loss": -93.98838363647461, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.175604343414307, "step": 123000}
{"episode_reward": 950.3209899493539, "episode": 124.0, "batch_reward": 0.8994409354925156, "critic_loss": 0.39451800245046614, "actor_loss": -94.09642506408692, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.2286376953125, "step": 124000}
{"episode_reward": 987.9268948923535, "episode": 125.0, "batch_reward": 0.900202735543251, "critic_loss": 0.3668420743495226, "actor_loss": -94.06026502990723, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.378286600112915, "step": 125000}
{"episode_reward": 988.507633233775, "episode": 126.0, "batch_reward": 0.9001173405647278, "critic_loss": 0.39538768085837367, "actor_loss": -94.17663748168945, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.559478282928467, "step": 126000}
{"episode_reward": 989.9185669843756, "episode": 127.0, "batch_reward": 0.9007068923711776, "critic_loss": 0.37038359116017816, "actor_loss": -94.18399340820312, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.163375854492188, "step": 127000}
{"episode_reward": 931.7188027126965, "episode": 128.0, "batch_reward": 0.900042800962925, "critic_loss": 0.38216295976936815, "actor_loss": -94.14382559204101, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.231172561645508, "step": 128000}
{"episode_reward": 965.1301177745079, "episode": 129.0, "batch_reward": 0.9012088531255722, "critic_loss": 0.38231100872159, "actor_loss": -94.24758909606933, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.143359184265137, "step": 129000}
{"episode_reward": 982.0160380953665, "episode": 130.0, "batch_reward": 0.9017703248858452, "critic_loss": 0.364164680570364, "actor_loss": -94.24720091247559, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.136858701705933, "step": 130000}
{"episode_reward": 990.3340015756269, "episode": 131.0, "batch_reward": 0.9037124161720276, "critic_loss": 0.366319063320756, "actor_loss": -94.19965263366699, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.18874454498291, "step": 131000}
{"episode_reward": 973.8725999544724, "episode": 132.0, "batch_reward": 0.9035153480172158, "critic_loss": 0.3710512246191502, "actor_loss": -94.18053440856933, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.647156715393066, "step": 132000}
{"episode_reward": 972.686589892426, "episode": 133.0, "batch_reward": 0.9034844341874123, "critic_loss": 0.3814039996042848, "actor_loss": -94.24542544555663, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.054187297821045, "step": 133000}
{"episode_reward": 909.722481666089, "episode": 134.0, "batch_reward": 0.9039745435118676, "critic_loss": 0.395156621620059, "actor_loss": -94.28622149658203, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.206671714782715, "step": 134000}
{"episode_reward": 953.6277099536916, "episode": 135.0, "batch_reward": 0.9054106658697129, "critic_loss": 0.3891001145020127, "actor_loss": -94.29010105895996, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.73417568206787, "step": 135000}
{"episode_reward": 993.4666271666835, "episode": 136.0, "batch_reward": 0.9060506582856178, "critic_loss": 0.39567108880728485, "actor_loss": -94.34735200500488, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.984426021575928, "step": 136000}
{"episode_reward": 988.5719496691858, "episode": 137.0, "batch_reward": 0.9050738316774368, "critic_loss": 0.398695655554533, "actor_loss": -94.276396194458, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.431341409683228, "step": 137000}
{"episode_reward": 982.4222704235684, "episode": 138.0, "batch_reward": 0.9062449181079865, "critic_loss": 0.37392184922844174, "actor_loss": -94.29257833862304, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.15938377380371, "step": 138000}
{"episode_reward": 942.4338457250537, "episode": 139.0, "batch_reward": 0.9062634443640709, "critic_loss": 0.3804270100668073, "actor_loss": -94.35128912353515, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.348119020462036, "step": 139000}
{"episode_reward": 972.5616606865442, "episode": 140.0, "batch_reward": 0.9066435936689377, "critic_loss": 0.374239827029407, "actor_loss": -94.2952218170166, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.713411331176758, "step": 140000}
{"episode_reward": 940.5023316788468, "episode": 141.0, "batch_reward": 0.9076226717829704, "critic_loss": 0.3762803962677717, "actor_loss": -94.30888380432128, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.14357829093933, "step": 141000}
{"episode_reward": 968.6554921316872, "episode": 142.0, "batch_reward": 0.9070002242326737, "critic_loss": 0.40532264998555184, "actor_loss": -94.37883474731446, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.55794930458069, "step": 142000}
{"episode_reward": 989.3697619200365, "episode": 143.0, "batch_reward": 0.9081169870495797, "critic_loss": 0.3668584804981947, "actor_loss": -94.39380229187012, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.314375400543213, "step": 143000}
{"episode_reward": 946.8264910255748, "episode": 144.0, "batch_reward": 0.9082762187123299, "critic_loss": 0.39309123282879593, "actor_loss": -94.44196362304687, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.803243160247803, "step": 144000}
{"episode_reward": 952.3222030592441, "episode": 145.0, "batch_reward": 0.9088706970214844, "critic_loss": 0.3515540596544743, "actor_loss": -94.42988586425781, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.49876356124878, "step": 145000}
{"episode_reward": 988.3297594129599, "episode": 146.0, "batch_reward": 0.9093939459323883, "critic_loss": 0.37464679150283337, "actor_loss": -94.54156420898437, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.352678537368774, "step": 146000}
{"episode_reward": 949.3209481089974, "episode": 147.0, "batch_reward": 0.908615007340908, "critic_loss": 0.36418998064100744, "actor_loss": -94.44965269470215, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.630093574523926, "step": 147000}
{"episode_reward": 944.729458465293, "episode": 148.0, "batch_reward": 0.9108830162882805, "critic_loss": 0.3576707324534655, "actor_loss": -94.55937893676757, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.60527205467224, "step": 148000}
{"episode_reward": 985.9709324883454, "episode": 149.0, "batch_reward": 0.9099875531196594, "critic_loss": 0.35966822466254234, "actor_loss": -94.53499867248536, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.908916473388672, "step": 149000}
{"episode_reward": 939.14054237412, "episode": 150.0, "batch_reward": 0.9106344094276428, "critic_loss": 0.3613092519417405, "actor_loss": -94.62878968811034, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
