{"episode_reward": 0.0, "episode": 1.0, "duration": 22.29210066795349, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.8810977935791016, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.46905009131027725, "critic_loss": 0.7181136136493829, "actor_loss": -84.31049332574827, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 65.83911347389221, "step": 3000}
{"episode_reward": 438.8633048659979, "episode": 4.0, "batch_reward": 0.49262590247392657, "critic_loss": 1.2660915810465814, "actor_loss": -83.65740087890624, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.551666259765625, "step": 4000}
{"episode_reward": 611.7167086491255, "episode": 5.0, "batch_reward": 0.5260116118192673, "critic_loss": 1.3788560952544213, "actor_loss": -83.68014613342285, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.594154119491577, "step": 5000}
{"episode_reward": 741.0681379692048, "episode": 6.0, "batch_reward": 0.565529510140419, "critic_loss": 1.584456258893013, "actor_loss": -84.62146231079102, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.75813603401184, "step": 6000}
{"episode_reward": 783.5788606327839, "episode": 7.0, "batch_reward": 0.6040978416502476, "critic_loss": 1.6521013283729553, "actor_loss": -85.35075761413574, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.512791395187378, "step": 7000}
{"episode_reward": 864.672358506213, "episode": 8.0, "batch_reward": 0.6405706807971001, "critic_loss": 1.6833426728248597, "actor_loss": -86.09488459777832, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.601366758346558, "step": 8000}
{"episode_reward": 888.3330485995365, "episode": 9.0, "batch_reward": 0.6574958221316337, "critic_loss": 1.8785419456958772, "actor_loss": -86.5617225341797, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.042194366455078, "step": 9000}
{"episode_reward": 770.4022588730858, "episode": 10.0, "batch_reward": 0.6774675571322442, "critic_loss": 1.7258337181806565, "actor_loss": -87.10091479492188, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.443033456802368, "step": 10000}
{"episode_reward": 802.9241631046076, "episode": 11.0, "batch_reward": 0.6886186144948006, "critic_loss": 1.6269219906330108, "actor_loss": -87.37282177734374, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.18243384361267, "step": 11000}
{"episode_reward": 858.7925043288421, "episode": 12.0, "batch_reward": 0.704998514354229, "critic_loss": 1.6143996948599815, "actor_loss": -87.49422351074219, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.616337060928345, "step": 12000}
{"episode_reward": 861.7913464852154, "episode": 13.0, "batch_reward": 0.7193249341845512, "critic_loss": 1.5011172256469727, "actor_loss": -87.92963063049316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.193676233291626, "step": 13000}
{"episode_reward": 922.5507207340382, "episode": 14.0, "batch_reward": 0.7370291040539741, "critic_loss": 1.3620595238804818, "actor_loss": -88.10021270751953, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.659451961517334, "step": 14000}
{"episode_reward": 962.363923890759, "episode": 15.0, "batch_reward": 0.7529384244680405, "critic_loss": 1.3607954320907594, "actor_loss": -89.38752627563477, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.1500883102417, "step": 15000}
{"episode_reward": 972.028015777105, "episode": 16.0, "batch_reward": 0.7652914999723435, "critic_loss": 1.3109181637763978, "actor_loss": -89.08166165161133, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.675595998764038, "step": 16000}
{"episode_reward": 903.6708020017016, "episode": 17.0, "batch_reward": 0.7692722750306129, "critic_loss": 1.3634243351221085, "actor_loss": -89.30819346618652, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.645069122314453, "step": 17000}
{"episode_reward": 873.0001619915781, "episode": 18.0, "batch_reward": 0.781956077337265, "critic_loss": 1.2989515991210938, "actor_loss": -89.45114472961426, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.600651502609253, "step": 18000}
{"episode_reward": 940.7303000896671, "episode": 19.0, "batch_reward": 0.7899141402244568, "critic_loss": 1.244185466170311, "actor_loss": -89.30825090026856, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.766509532928467, "step": 19000}
{"episode_reward": 947.6548065078158, "episode": 20.0, "batch_reward": 0.7993283530473709, "critic_loss": 1.1863825892806052, "actor_loss": -89.99341102600097, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.05073857307434, "step": 20000}
{"episode_reward": 946.5993523094081, "episode": 21.0, "batch_reward": 0.8034228986501694, "critic_loss": 1.2535881820321082, "actor_loss": -90.16220771789551, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 43.04332613945007, "step": 21000}
{"episode_reward": 891.3176133900453, "episode": 22.0, "batch_reward": 0.8065766784548759, "critic_loss": 1.3769261990189552, "actor_loss": -90.00975067138671, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.10288715362549, "step": 22000}
{"episode_reward": 901.1933499424644, "episode": 23.0, "batch_reward": 0.8127079011797905, "critic_loss": 1.3343526490926743, "actor_loss": -90.53715934753419, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.52674889564514, "step": 23000}
{"episode_reward": 939.8739706604098, "episode": 24.0, "batch_reward": 0.8187728925347328, "critic_loss": 1.3122150468826295, "actor_loss": -90.46763764953613, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.012272357940674, "step": 24000}
{"episode_reward": 983.9283078440811, "episode": 25.0, "batch_reward": 0.8214204296469688, "critic_loss": 1.4715970186591147, "actor_loss": -90.25294175720215, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.228900909423828, "step": 25000}
{"episode_reward": 885.2304339586985, "episode": 26.0, "batch_reward": 0.8257901525497436, "critic_loss": 1.4420749709010123, "actor_loss": -90.72410945129394, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.528563261032104, "step": 26000}
{"episode_reward": 972.0220394018235, "episode": 27.0, "batch_reward": 0.8331798911094666, "critic_loss": 1.4431503153443337, "actor_loss": -90.58850659179687, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.63677477836609, "step": 27000}
{"episode_reward": 970.6152742319657, "episode": 28.0, "batch_reward": 0.8386511335968971, "critic_loss": 1.430430841267109, "actor_loss": -90.66116616821289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.325989484786987, "step": 28000}
{"episode_reward": 945.3223223300279, "episode": 29.0, "batch_reward": 0.8385542529821396, "critic_loss": 1.4536681289076805, "actor_loss": -90.8724358215332, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.66787576675415, "step": 29000}
{"episode_reward": 836.927588556155, "episode": 30.0, "batch_reward": 0.8421808504462243, "critic_loss": 1.3671771131753923, "actor_loss": -90.79171961975098, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.906272172927856, "step": 30000}
{"episode_reward": 927.3864836592452, "episode": 31.0, "batch_reward": 0.8431077001094818, "critic_loss": 1.354892436146736, "actor_loss": -90.89765924072266, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 43.17675852775574, "step": 31000}
{"episode_reward": 920.2152928695529, "episode": 32.0, "batch_reward": 0.846058230817318, "critic_loss": 1.388109612762928, "actor_loss": -90.78707063293457, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.905270099639893, "step": 32000}
{"episode_reward": 866.0868008916221, "episode": 33.0, "batch_reward": 0.846977412045002, "critic_loss": 1.3938030181527137, "actor_loss": -91.18809567260742, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.464575052261353, "step": 33000}
{"episode_reward": 929.5723173157776, "episode": 34.0, "batch_reward": 0.8481622021198273, "critic_loss": 1.3672235631942748, "actor_loss": -90.90333448791503, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.33568024635315, "step": 34000}
{"episode_reward": 938.4712600208261, "episode": 35.0, "batch_reward": 0.8504120495319366, "critic_loss": 1.3773076286911965, "actor_loss": -91.58586614990234, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.275338172912598, "step": 35000}
{"episode_reward": 914.5795887938979, "episode": 36.0, "batch_reward": 0.8525650089383126, "critic_loss": 1.3890530375242234, "actor_loss": -90.98836033630371, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.66286063194275, "step": 36000}
{"episode_reward": 930.1902974655461, "episode": 37.0, "batch_reward": 0.8530454224348069, "critic_loss": 1.5301344153881073, "actor_loss": -91.52653083801269, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.264363527297974, "step": 37000}
{"episode_reward": 880.7589105004671, "episode": 38.0, "batch_reward": 0.857040003657341, "critic_loss": 1.5250269344449043, "actor_loss": -91.57952003479004, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.61227822303772, "step": 38000}
{"episode_reward": 970.7359174582454, "episode": 39.0, "batch_reward": 0.8582811630964279, "critic_loss": 1.5261628565192222, "actor_loss": -91.60831507873534, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.633500337600708, "step": 39000}
{"episode_reward": 906.8765029923426, "episode": 40.0, "batch_reward": 0.8602306877374649, "critic_loss": 1.4768031687140464, "actor_loss": -91.7164220123291, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.619031190872192, "step": 40000}
{"episode_reward": 960.6347061475383, "episode": 41.0, "batch_reward": 0.8619944913983345, "critic_loss": 1.528131621003151, "actor_loss": -91.86635076904297, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 43.25755500793457, "step": 41000}
{"episode_reward": 881.8805401621038, "episode": 42.0, "batch_reward": 0.8656685833930969, "critic_loss": 1.5342398920655251, "actor_loss": -91.52483613586426, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.690547704696655, "step": 42000}
{"episode_reward": 964.3310639263904, "episode": 43.0, "batch_reward": 0.8638814839720727, "critic_loss": 1.5844065304398536, "actor_loss": -91.62723248291016, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.683390617370605, "step": 43000}
{"episode_reward": 849.0849325025898, "episode": 44.0, "batch_reward": 0.8661797962784767, "critic_loss": 1.531918149113655, "actor_loss": -91.6178978729248, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.460785388946533, "step": 44000}
{"episode_reward": 983.0540391658783, "episode": 45.0, "batch_reward": 0.8663190199136734, "critic_loss": 1.5503175087571144, "actor_loss": -91.68363780212403, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.996883869171143, "step": 45000}
{"episode_reward": 906.1786390034218, "episode": 46.0, "batch_reward": 0.8685333841443061, "critic_loss": 1.4788931288719178, "actor_loss": -91.76902998352051, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.633172035217285, "step": 46000}
{"episode_reward": 927.3578911938569, "episode": 47.0, "batch_reward": 0.8701259739995003, "critic_loss": 1.5517263796925544, "actor_loss": -92.03698791503906, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.375205039978027, "step": 47000}
{"episode_reward": 945.3610764601874, "episode": 48.0, "batch_reward": 0.8720337258577346, "critic_loss": 1.4482234935760498, "actor_loss": -91.97665208435059, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.31263756752014, "step": 48000}
{"episode_reward": 928.9172974421394, "episode": 49.0, "batch_reward": 0.8743283421397209, "critic_loss": 1.3927573002576827, "actor_loss": -92.38724539184571, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.706522226333618, "step": 49000}
{"episode_reward": 956.6928068057651, "episode": 50.0, "batch_reward": 0.8751469905972481, "critic_loss": 1.341763752937317, "actor_loss": -92.04805133056641, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.888267278671265, "step": 50000}
{"episode_reward": 983.9439243751935, "episode": 51.0, "batch_reward": 0.8778860484957695, "critic_loss": 1.364129210472107, "actor_loss": -92.20263902282714, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.980989933013916, "step": 51000}
{"episode_reward": 967.180250980456, "episode": 52.0, "batch_reward": 0.8789702841043472, "critic_loss": 1.375429099559784, "actor_loss": -92.23437155151368, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.698683977127075, "step": 52000}
{"episode_reward": 947.8894378197541, "episode": 53.0, "batch_reward": 0.8803066243529319, "critic_loss": 1.3106226978302002, "actor_loss": -92.37844407653809, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.658812046051025, "step": 53000}
{"episode_reward": 914.7850778832945, "episode": 54.0, "batch_reward": 0.8795635668039322, "critic_loss": 1.414414942920208, "actor_loss": -92.22525045776368, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.29391360282898, "step": 54000}
{"episode_reward": 865.0802057549311, "episode": 55.0, "batch_reward": 0.8799270110130311, "critic_loss": 1.4030359356999398, "actor_loss": -92.6904472503662, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.644160509109497, "step": 55000}
{"episode_reward": 970.3510602134761, "episode": 56.0, "batch_reward": 0.8831113711595535, "critic_loss": 1.3809179323315621, "actor_loss": -92.62841088867188, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.07986044883728, "step": 56000}
{"episode_reward": 982.6134735871949, "episode": 57.0, "batch_reward": 0.8836424800157547, "critic_loss": 1.3559636637568473, "actor_loss": -92.28439625549316, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.62586760520935, "step": 57000}
{"episode_reward": 872.4797289008555, "episode": 58.0, "batch_reward": 0.8847377892732621, "critic_loss": 1.2962642527222634, "actor_loss": -92.46332875061036, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.744215965270996, "step": 58000}
{"episode_reward": 980.0279414230171, "episode": 59.0, "batch_reward": 0.8858997688293457, "critic_loss": 1.3797042668461799, "actor_loss": -92.4154799041748, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.601147651672363, "step": 59000}
{"episode_reward": 937.397801735336, "episode": 60.0, "batch_reward": 0.884169513463974, "critic_loss": 1.3251408290863038, "actor_loss": -92.47823443603515, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.66546058654785, "step": 60000}
{"episode_reward": 853.5889392003901, "episode": 61.0, "batch_reward": 0.8867331779003144, "critic_loss": 1.3225320685505868, "actor_loss": -92.33003451538086, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.26078939437866, "step": 61000}
{"episode_reward": 940.1510893261336, "episode": 62.0, "batch_reward": 0.8851394076943397, "critic_loss": 1.2967408488988876, "actor_loss": -92.77910777282715, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.125068426132202, "step": 62000}
{"episode_reward": 957.6992951631067, "episode": 63.0, "batch_reward": 0.8861743540167809, "critic_loss": 1.2778207839131355, "actor_loss": -92.54668226623535, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.44985818862915, "step": 63000}
{"episode_reward": 933.2379823261684, "episode": 64.0, "batch_reward": 0.8881325177550315, "critic_loss": 1.2763174825310708, "actor_loss": -92.6914174041748, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.710036039352417, "step": 64000}
{"episode_reward": 986.0836927011868, "episode": 65.0, "batch_reward": 0.8898229639530182, "critic_loss": 1.255140335857868, "actor_loss": -92.59004832458496, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.06000328063965, "step": 65000}
{"episode_reward": 976.4678812224067, "episode": 66.0, "batch_reward": 0.8888455930948257, "critic_loss": 1.2961915933191777, "actor_loss": -92.62917492675781, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.91240644454956, "step": 66000}
{"episode_reward": 818.7168979310104, "episode": 67.0, "batch_reward": 0.8881094623804092, "critic_loss": 1.2810693390369414, "actor_loss": -92.694322265625, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.634154796600342, "step": 67000}
{"episode_reward": 905.4223367313806, "episode": 68.0, "batch_reward": 0.8904504804611206, "critic_loss": 1.2739428017735481, "actor_loss": -92.59715817260742, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.590598821640015, "step": 68000}
{"episode_reward": 939.2606389310043, "episode": 69.0, "batch_reward": 0.8909190556406975, "critic_loss": 1.3094326089024544, "actor_loss": -92.78086433410644, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.318921089172363, "step": 69000}
{"episode_reward": 986.2051145141568, "episode": 70.0, "batch_reward": 0.8920756205320358, "critic_loss": 1.3273048700392247, "actor_loss": -92.89204483032226, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.15253734588623, "step": 70000}
{"episode_reward": 895.223244516276, "episode": 71.0, "batch_reward": 0.8908798323273659, "critic_loss": 1.416526639610529, "actor_loss": -92.9780630645752, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.986162424087524, "step": 71000}
{"episode_reward": 904.0137901417606, "episode": 72.0, "batch_reward": 0.8924772194027901, "critic_loss": 1.3698717885911464, "actor_loss": -93.03588049316406, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.657978534698486, "step": 72000}
{"episode_reward": 983.4069491847843, "episode": 73.0, "batch_reward": 0.8929034611582756, "critic_loss": 1.364753641307354, "actor_loss": -92.89827667236328, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.686030387878418, "step": 73000}
{"episode_reward": 934.6955438685111, "episode": 74.0, "batch_reward": 0.8942723007798195, "critic_loss": 1.4389437286257745, "actor_loss": -93.19095286560058, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.500496864318848, "step": 74000}
{"episode_reward": 852.6496716310754, "episode": 75.0, "batch_reward": 0.8946933914422989, "critic_loss": 1.4693411224484443, "actor_loss": -92.89325328063966, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.35256004333496, "step": 75000}
{"episode_reward": 964.47565980364, "episode": 76.0, "batch_reward": 0.8945253147482872, "critic_loss": 1.4826253339648248, "actor_loss": -92.99903637695313, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.314642906188965, "step": 76000}
{"episode_reward": 905.8468080781807, "episode": 77.0, "batch_reward": 0.8946615003347397, "critic_loss": 1.441055809557438, "actor_loss": -92.79026858520508, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.578476428985596, "step": 77000}
{"episode_reward": 951.6112311880726, "episode": 78.0, "batch_reward": 0.894987013220787, "critic_loss": 1.5631392970085145, "actor_loss": -93.10826840209961, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.692147970199585, "step": 78000}
{"episode_reward": 923.5820440705327, "episode": 79.0, "batch_reward": 0.8955173840522767, "critic_loss": 1.4971604635715485, "actor_loss": -92.59794863891601, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.676677942276, "step": 79000}
{"episode_reward": 963.7527531789585, "episode": 80.0, "batch_reward": 0.8964659338593483, "critic_loss": 1.4615877384543419, "actor_loss": -92.93140641784667, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.851312398910522, "step": 80000}
{"episode_reward": 971.599072923129, "episode": 81.0, "batch_reward": 0.8979372825622559, "critic_loss": 1.4630763141214849, "actor_loss": -92.97201039123536, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.43930530548096, "step": 81000}
{"episode_reward": 909.3682790092286, "episode": 82.0, "batch_reward": 0.8984636751413345, "critic_loss": 1.3893481341004372, "actor_loss": -93.44562254333496, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.286048650741577, "step": 82000}
{"episode_reward": 961.7445952001248, "episode": 83.0, "batch_reward": 0.8988307545781136, "critic_loss": 1.3995328916609286, "actor_loss": -93.08733181762695, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.470969438552856, "step": 83000}
{"episode_reward": 945.2860597396675, "episode": 84.0, "batch_reward": 0.9006770868897438, "critic_loss": 1.3346555450856685, "actor_loss": -93.7329036102295, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.74413824081421, "step": 84000}
{"episode_reward": 986.8664788157837, "episode": 85.0, "batch_reward": 0.8998142111897468, "critic_loss": 1.4151812841296196, "actor_loss": -93.32838917541504, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.719033241271973, "step": 85000}
{"episode_reward": 946.1150303774568, "episode": 86.0, "batch_reward": 0.9009383372068405, "critic_loss": 1.3810444463193416, "actor_loss": -93.30444241333008, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.77160382270813, "step": 86000}
{"episode_reward": 954.1094063986841, "episode": 87.0, "batch_reward": 0.9016332199573517, "critic_loss": 1.3687059560120105, "actor_loss": -93.35190628051758, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.64099931716919, "step": 87000}
{"episode_reward": 944.8106409568728, "episode": 88.0, "batch_reward": 0.9014258373975754, "critic_loss": 1.2936542870700358, "actor_loss": -93.13601254272461, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.374433279037476, "step": 88000}
{"episode_reward": 929.8453871319632, "episode": 89.0, "batch_reward": 0.9008773885965348, "critic_loss": 1.4014842841029167, "actor_loss": -93.43678121948243, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.38606548309326, "step": 89000}
{"episode_reward": 926.5622647634987, "episode": 90.0, "batch_reward": 0.9022156484127045, "critic_loss": 1.3234875067770482, "actor_loss": -93.63101812744141, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.598498344421387, "step": 90000}
{"episode_reward": 957.3121755383156, "episode": 91.0, "batch_reward": 0.9032005068659782, "critic_loss": 1.2823179553151132, "actor_loss": -93.49395678710937, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.632744789123535, "step": 91000}
{"episode_reward": 949.7761732914103, "episode": 92.0, "batch_reward": 0.9051878870725631, "critic_loss": 1.2936360920369625, "actor_loss": -93.57449490356446, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.133680820465088, "step": 92000}
{"episode_reward": 954.4288387072291, "episode": 93.0, "batch_reward": 0.9036347510218621, "critic_loss": 1.238780769377947, "actor_loss": -93.37691632080079, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.599467515945435, "step": 93000}
{"episode_reward": 977.4100330410344, "episode": 94.0, "batch_reward": 0.9047837083935738, "critic_loss": 1.1820996554195882, "actor_loss": -93.65478408813476, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.897613286972046, "step": 94000}
{"episode_reward": 949.8728279889268, "episode": 95.0, "batch_reward": 0.9052619547843933, "critic_loss": 1.1210180445909501, "actor_loss": -93.66994204711914, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.42346978187561, "step": 95000}
{"episode_reward": 954.3885572340449, "episode": 96.0, "batch_reward": 0.9059037055969238, "critic_loss": 1.1353304787278176, "actor_loss": -93.78987370300293, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.807020664215088, "step": 96000}
{"episode_reward": 957.671108715466, "episode": 97.0, "batch_reward": 0.9061804659962654, "critic_loss": 1.171192257732153, "actor_loss": -93.88236563110351, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.946643352508545, "step": 97000}
{"episode_reward": 898.0048571674844, "episode": 98.0, "batch_reward": 0.9065306543707847, "critic_loss": 1.1582775788009168, "actor_loss": -93.77607720947266, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.914849281311035, "step": 98000}
{"episode_reward": 913.3448236176018, "episode": 99.0, "batch_reward": 0.9056660331487656, "critic_loss": 1.1780679878294469, "actor_loss": -93.46402313232421, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.696913242340088, "step": 99000}
{"episode_reward": 939.6268185737063, "episode": 100.0, "batch_reward": 0.9070330021381379, "critic_loss": 1.2074528212845326, "actor_loss": -93.72827769470214, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.549332857131958, "step": 100000}
{"episode_reward": 818.7122953436049, "episode": 101.0, "batch_reward": 0.9072923067212105, "critic_loss": 1.1958304907679558, "actor_loss": -93.73253855895996, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 43.39400243759155, "step": 101000}
{"episode_reward": 978.4047288319194, "episode": 102.0, "batch_reward": 0.9055605236291885, "critic_loss": 1.2407610330581664, "actor_loss": -93.57246290588378, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.631240129470825, "step": 102000}
{"episode_reward": 974.5259947098168, "episode": 103.0, "batch_reward": 0.9060240941643715, "critic_loss": 1.2112816987335682, "actor_loss": -93.77207987976074, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.86438512802124, "step": 103000}
{"episode_reward": 956.7640009429947, "episode": 104.0, "batch_reward": 0.908305674135685, "critic_loss": 1.1782492780089378, "actor_loss": -93.85369766235351, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.692607641220093, "step": 104000}
{"episode_reward": 952.0337447003714, "episode": 105.0, "batch_reward": 0.9096676175594329, "critic_loss": 1.2077536815106868, "actor_loss": -93.93637594604492, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.982122659683228, "step": 105000}
{"episode_reward": 914.9207757486747, "episode": 106.0, "batch_reward": 0.9088874959349632, "critic_loss": 1.170537342607975, "actor_loss": -93.81640660095215, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.866472482681274, "step": 106000}
{"episode_reward": 934.9774829252686, "episode": 107.0, "batch_reward": 0.9079137400388718, "critic_loss": 1.2499177308678626, "actor_loss": -93.8511876373291, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.738431930541992, "step": 107000}
{"episode_reward": 962.7954673937747, "episode": 108.0, "batch_reward": 0.9098662437796593, "critic_loss": 1.1411052367389203, "actor_loss": -93.86576051330566, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.893385410308838, "step": 108000}
{"episode_reward": 941.6711628970608, "episode": 109.0, "batch_reward": 0.9092395129799843, "critic_loss": 1.159866906762123, "actor_loss": -94.17186474609375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.62505006790161, "step": 109000}
{"episode_reward": 970.9198705058518, "episode": 110.0, "batch_reward": 0.9098013767004013, "critic_loss": 1.1569892212152482, "actor_loss": -94.05209323120117, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.212673664093018, "step": 110000}
{"episode_reward": 932.2766341803014, "episode": 111.0, "batch_reward": 0.9093006257414817, "critic_loss": 1.1745841566324233, "actor_loss": -94.00227755737305, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.87291479110718, "step": 111000}
{"episode_reward": 882.779481328939, "episode": 112.0, "batch_reward": 0.9102462481856346, "critic_loss": 1.1952102173864843, "actor_loss": -93.74511407470703, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.90243148803711, "step": 112000}
{"episode_reward": 945.341597089317, "episode": 113.0, "batch_reward": 0.9107397173047066, "critic_loss": 1.1906191494762897, "actor_loss": -93.97211293029785, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.776180505752563, "step": 113000}
{"episode_reward": 922.6234478566133, "episode": 114.0, "batch_reward": 0.910888279914856, "critic_loss": 1.164715832591057, "actor_loss": -94.1259919128418, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.11013150215149, "step": 114000}
{"episode_reward": 976.5285124909979, "episode": 115.0, "batch_reward": 0.9100411863327026, "critic_loss": 1.214911142706871, "actor_loss": -93.87129011535644, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.62252378463745, "step": 115000}
{"episode_reward": 783.514174020257, "episode": 116.0, "batch_reward": 0.9086900940537452, "critic_loss": 1.2715979125499726, "actor_loss": -93.85566659545898, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.083869218826294, "step": 116000}
{"episode_reward": 816.5189053426361, "episode": 117.0, "batch_reward": 0.9076465742588044, "critic_loss": 1.3099348022341728, "actor_loss": -93.70969761657715, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.46133065223694, "step": 117000}
{"episode_reward": 836.6798385720625, "episode": 118.0, "batch_reward": 0.9084186685681344, "critic_loss": 1.3135701010227203, "actor_loss": -93.87026901245117, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.591428995132446, "step": 118000}
{"episode_reward": 980.213895698777, "episode": 119.0, "batch_reward": 0.9091983091235161, "critic_loss": 1.202365219026804, "actor_loss": -93.94705342102051, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.810673713684082, "step": 119000}
{"episode_reward": 958.0676795720902, "episode": 120.0, "batch_reward": 0.9082702448368073, "critic_loss": 1.2675266301035881, "actor_loss": -93.84563868713379, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 23.013303756713867, "step": 120000}
{"episode_reward": 910.9684615816876, "episode": 121.0, "batch_reward": 0.9099772171974182, "critic_loss": 1.296865620702505, "actor_loss": -93.67676361083984, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.96335697174072, "step": 121000}
{"episode_reward": 981.6867250914407, "episode": 122.0, "batch_reward": 0.9096636437773704, "critic_loss": 1.3268800412416457, "actor_loss": -93.7949776763916, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.27344250679016, "step": 122000}
{"episode_reward": 892.7093005476811, "episode": 123.0, "batch_reward": 0.91005077201128, "critic_loss": 1.3080603737533092, "actor_loss": -93.56473132324219, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.487823724746704, "step": 123000}
{"episode_reward": 952.5716865875295, "episode": 124.0, "batch_reward": 0.9098520810604096, "critic_loss": 1.2967998354136945, "actor_loss": -93.78581994628907, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.638995885849, "step": 124000}
{"episode_reward": 923.6926422215859, "episode": 125.0, "batch_reward": 0.9105179026722908, "critic_loss": 1.2979930485486983, "actor_loss": -93.78214561462403, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.667752504348755, "step": 125000}
{"episode_reward": 985.4075658143967, "episode": 126.0, "batch_reward": 0.9110181840062141, "critic_loss": 1.35743156427145, "actor_loss": -93.67525312805176, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.41388702392578, "step": 126000}
{"episode_reward": 989.3846658406825, "episode": 127.0, "batch_reward": 0.9109374744296074, "critic_loss": 1.3220501301288605, "actor_loss": -93.95642608642578, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.185094118118286, "step": 127000}
{"episode_reward": 930.9508767374208, "episode": 128.0, "batch_reward": 0.9122842754125595, "critic_loss": 1.2939981715977191, "actor_loss": -94.25272776794434, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.5233154296875, "step": 128000}
{"episode_reward": 957.1772697585778, "episode": 129.0, "batch_reward": 0.9123809757232666, "critic_loss": 1.2747442907691002, "actor_loss": -94.06032795715332, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.88576102256775, "step": 129000}
{"episode_reward": 981.5420418378577, "episode": 130.0, "batch_reward": 0.9131321479678154, "critic_loss": 1.291526165574789, "actor_loss": -94.0642465209961, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.739951610565186, "step": 130000}
{"episode_reward": 988.3475737644504, "episode": 131.0, "batch_reward": 0.9138586170673371, "critic_loss": 1.2218700433969498, "actor_loss": -94.1719010772705, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.06539511680603, "step": 131000}
{"episode_reward": 985.319541671407, "episode": 132.0, "batch_reward": 0.9142797960639, "critic_loss": 1.277299115240574, "actor_loss": -94.19557569885254, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.22837471961975, "step": 132000}
{"episode_reward": 975.0921188735215, "episode": 133.0, "batch_reward": 0.9137320666909218, "critic_loss": 1.3163287625610829, "actor_loss": -94.08926095581054, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.491068363189697, "step": 133000}
{"episode_reward": 961.5723913444796, "episode": 134.0, "batch_reward": 0.914801930308342, "critic_loss": 1.3052646187841892, "actor_loss": -94.19849014282227, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.594869375228882, "step": 134000}
{"episode_reward": 956.8185387163965, "episode": 135.0, "batch_reward": 0.9161599690914154, "critic_loss": 1.272216209948063, "actor_loss": -94.20228039550781, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.567563772201538, "step": 135000}
{"episode_reward": 973.6672871942561, "episode": 136.0, "batch_reward": 0.9151682312488556, "critic_loss": 1.2641046016216277, "actor_loss": -94.45907484436034, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.384642124176025, "step": 136000}
{"episode_reward": 982.8496955754187, "episode": 137.0, "batch_reward": 0.9145722763538361, "critic_loss": 1.292521945565939, "actor_loss": -94.22884628295898, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.16467833518982, "step": 137000}
{"episode_reward": 975.0860532244541, "episode": 138.0, "batch_reward": 0.9170928239822388, "critic_loss": 1.2944311839044094, "actor_loss": -93.9722017364502, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.613694667816162, "step": 138000}
{"episode_reward": 951.5939029145343, "episode": 139.0, "batch_reward": 0.9163745093345642, "critic_loss": 1.262308889478445, "actor_loss": -94.02704718017579, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.87937307357788, "step": 139000}
{"episode_reward": 978.805610086965, "episode": 140.0, "batch_reward": 0.9175383486747741, "critic_loss": 1.2444544859230517, "actor_loss": -93.95835641479492, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.54021906852722, "step": 140000}
{"episode_reward": 927.7168996532318, "episode": 141.0, "batch_reward": 0.9178256189823151, "critic_loss": 1.2730695898234845, "actor_loss": -94.09734950256347, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.82294487953186, "step": 141000}
{"episode_reward": 957.8519352113885, "episode": 142.0, "batch_reward": 0.9173695024847984, "critic_loss": 1.32105795571208, "actor_loss": -94.14165444946289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.36946415901184, "step": 142000}
{"episode_reward": 987.8458231572799, "episode": 143.0, "batch_reward": 0.9176671651601791, "critic_loss": 1.2738817254006862, "actor_loss": -94.32890585327148, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.11646580696106, "step": 143000}
{"episode_reward": 940.6403682087098, "episode": 144.0, "batch_reward": 0.9176790734529495, "critic_loss": 1.3059424560964108, "actor_loss": -94.27413938903808, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.62827491760254, "step": 144000}
{"episode_reward": 928.6626044833992, "episode": 145.0, "batch_reward": 0.918227379143238, "critic_loss": 1.2808271690607071, "actor_loss": -94.27567268371583, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.339144945144653, "step": 145000}
{"episode_reward": 985.7635666733938, "episode": 146.0, "batch_reward": 0.9192677423357963, "critic_loss": 1.2795708507597447, "actor_loss": -94.23986087036133, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.515395164489746, "step": 146000}
{"episode_reward": 975.7665852499337, "episode": 147.0, "batch_reward": 0.9182996222376824, "critic_loss": 1.2724077051877976, "actor_loss": -94.4195375213623, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.62264919281006, "step": 147000}
{"episode_reward": 892.8993795839749, "episode": 148.0, "batch_reward": 0.9192131044268608, "critic_loss": 1.2079801049530505, "actor_loss": -94.23551565551757, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.034128665924072, "step": 148000}
{"episode_reward": 982.0284570743084, "episode": 149.0, "batch_reward": 0.9185280279517174, "critic_loss": 1.2521414867937566, "actor_loss": -94.35234428405762, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.53597140312195, "step": 149000}
{"episode_reward": 874.1388635074305, "episode": 150.0, "batch_reward": 0.9186033570170402, "critic_loss": 1.340534236073494, "actor_loss": -94.17801892089844, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
