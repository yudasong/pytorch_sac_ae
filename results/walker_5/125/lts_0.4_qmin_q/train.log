{"episode_reward": 0.0, "episode": 1.0, "duration": 22.399697303771973, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.909940242767334, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.45812200480359677, "critic_loss": 0.6554813506693473, "actor_loss": -84.93324383586442, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 62.4825873374939, "step": 3000}
{"episode_reward": 307.02064831453765, "episode": 4.0, "batch_reward": 0.4191532405912876, "critic_loss": 1.3064813126325607, "actor_loss": -87.23703382873535, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.12445592880249, "step": 4000}
{"episode_reward": 281.7712446905897, "episode": 5.0, "batch_reward": 0.35991520000994204, "critic_loss": 0.9401252177357674, "actor_loss": -88.89629153442382, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.35675883293152, "step": 5000}
{"episode_reward": 99.39286987662452, "episode": 6.0, "batch_reward": 0.31757104471325875, "critic_loss": 0.9282784944474697, "actor_loss": -88.52132792663575, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.558890104293823, "step": 6000}
{"episode_reward": 181.65043055434143, "episode": 7.0, "batch_reward": 0.33681521654129026, "critic_loss": 1.0334125403165817, "actor_loss": -88.37736140441895, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.735760927200317, "step": 7000}
{"episode_reward": 776.6471631562038, "episode": 8.0, "batch_reward": 0.3730334057211876, "critic_loss": 0.9572912706136704, "actor_loss": -88.93025726318359, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.19786548614502, "step": 8000}
{"episode_reward": 245.43846326447152, "episode": 9.0, "batch_reward": 0.34189575278759005, "critic_loss": 0.999158205151558, "actor_loss": -87.64149829101562, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.324702739715576, "step": 9000}
{"episode_reward": 350.8130458290216, "episode": 10.0, "batch_reward": 0.3808990466296673, "critic_loss": 1.504579136431217, "actor_loss": -88.33193812561035, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.82882022857666, "step": 10000}
{"episode_reward": 879.5340288292591, "episode": 11.0, "batch_reward": 0.41930921041965485, "critic_loss": 2.68402309179306, "actor_loss": -89.47551669311524, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.847307205200195, "step": 11000}
{"episode_reward": 488.7367683869204, "episode": 12.0, "batch_reward": 0.4095108143091202, "critic_loss": 3.5853714402914045, "actor_loss": -90.24830152893067, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.306874990463257, "step": 12000}
{"episode_reward": 292.31238858280494, "episode": 13.0, "batch_reward": 0.3973165315687656, "critic_loss": 4.198506727576256, "actor_loss": -91.9272028503418, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.65061664581299, "step": 13000}
{"episode_reward": 106.51488067802036, "episode": 14.0, "batch_reward": 0.3731371601819992, "critic_loss": 4.791146033287048, "actor_loss": -95.86907797241211, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.91173005104065, "step": 14000}
{"episode_reward": 221.85333615106126, "episode": 15.0, "batch_reward": 0.36434490197896957, "critic_loss": 4.5318748569488525, "actor_loss": -95.97657791137695, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.33857750892639, "step": 15000}
{"episode_reward": 207.2432855126249, "episode": 16.0, "batch_reward": 0.3537830080091953, "critic_loss": 4.206923814058304, "actor_loss": -96.42536892700195, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.474924087524414, "step": 16000}
{"episode_reward": 134.77589353537053, "episode": 17.0, "batch_reward": 0.34376625414192674, "critic_loss": 4.331676013469696, "actor_loss": -97.95507604980469, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.70237135887146, "step": 17000}
{"episode_reward": 232.55149891750594, "episode": 18.0, "batch_reward": 0.3337603869736195, "critic_loss": 4.214108879327774, "actor_loss": -97.78778091430664, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.019679069519043, "step": 18000}
{"episode_reward": 260.11314750781355, "episode": 19.0, "batch_reward": 0.33692162761092187, "critic_loss": 4.153457410335541, "actor_loss": -96.83491616821289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.31451940536499, "step": 19000}
{"episode_reward": 314.74731662491047, "episode": 20.0, "batch_reward": 0.33294488160312175, "critic_loss": 3.8870562980175016, "actor_loss": -95.95341384887695, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.318162441253662, "step": 20000}
{"episode_reward": 172.12543060820914, "episode": 21.0, "batch_reward": 0.33267565055191517, "critic_loss": 3.742045327425003, "actor_loss": -95.2263501586914, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.70513677597046, "step": 21000}
{"episode_reward": 694.6513631555873, "episode": 22.0, "batch_reward": 0.35401226541399955, "critic_loss": 3.563199103832245, "actor_loss": -96.09117126464844, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.302969217300415, "step": 22000}
{"episode_reward": 820.4399012795495, "episode": 23.0, "batch_reward": 0.37408760875463487, "critic_loss": 3.5009815224409104, "actor_loss": -97.86179202270507, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.710333108901978, "step": 23000}
{"episode_reward": 899.7938850781227, "episode": 24.0, "batch_reward": 0.3960937373638153, "critic_loss": 3.555815253853798, "actor_loss": -98.33706393432617, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.294028997421265, "step": 24000}
{"episode_reward": 867.0187532125036, "episode": 25.0, "batch_reward": 0.41563667356967926, "critic_loss": 3.394179156064987, "actor_loss": -100.42469828796386, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.30958080291748, "step": 25000}
{"episode_reward": 926.2942376821363, "episode": 26.0, "batch_reward": 0.4349922412633896, "critic_loss": 3.202348984837532, "actor_loss": -100.80176860046387, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.402847051620483, "step": 26000}
{"episode_reward": 761.1858667790248, "episode": 27.0, "batch_reward": 0.45149330362677575, "critic_loss": 2.8380574370622633, "actor_loss": -100.96215591430663, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.457207918167114, "step": 27000}
{"episode_reward": 974.8376554093983, "episode": 28.0, "batch_reward": 0.4694375629723072, "critic_loss": 2.4656157546043396, "actor_loss": -101.18065071105957, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.882502555847168, "step": 28000}
{"episode_reward": 862.132034669659, "episode": 29.0, "batch_reward": 0.4839203154146671, "critic_loss": 2.2063749442100526, "actor_loss": -100.21446865844726, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.390105724334717, "step": 29000}
{"episode_reward": 940.9645130373345, "episode": 30.0, "batch_reward": 0.49715017145872115, "critic_loss": 1.9848119502067565, "actor_loss": -100.32160908508301, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.70837092399597, "step": 30000}
{"episode_reward": 885.2553059533092, "episode": 31.0, "batch_reward": 0.5090719921290875, "critic_loss": 1.8051176941394806, "actor_loss": -99.76123329162597, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.46043848991394, "step": 31000}
{"episode_reward": 898.6339305884752, "episode": 32.0, "batch_reward": 0.5230402857959271, "critic_loss": 1.6848796387314797, "actor_loss": -98.31681311035156, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.5931499004364, "step": 32000}
{"episode_reward": 904.562166865036, "episode": 33.0, "batch_reward": 0.5362115649580955, "critic_loss": 1.5783145270943642, "actor_loss": -98.06113806152344, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.33684277534485, "step": 33000}
{"episode_reward": 952.4174570099225, "episode": 34.0, "batch_reward": 0.5462610094547272, "critic_loss": 1.4152626550793648, "actor_loss": -99.31526794433594, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.309451580047607, "step": 34000}
{"episode_reward": 983.0779680931385, "episode": 35.0, "batch_reward": 0.560288078814745, "critic_loss": 1.3370092274546623, "actor_loss": -98.02521464538574, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.330472469329834, "step": 35000}
{"episode_reward": 926.4176626814794, "episode": 36.0, "batch_reward": 0.5680884619951249, "critic_loss": 1.210009137094021, "actor_loss": -98.00420841979981, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.690987586975098, "step": 36000}
{"episode_reward": 944.7256889224202, "episode": 37.0, "batch_reward": 0.5762321099936962, "critic_loss": 1.1072455977797508, "actor_loss": -97.97236741638184, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.432540893554688, "step": 37000}
{"episode_reward": 950.261387011941, "episode": 38.0, "batch_reward": 0.5929079976379872, "critic_loss": 0.945347048997879, "actor_loss": -97.68968759155274, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.942856311798096, "step": 38000}
{"episode_reward": 971.9736247151384, "episode": 39.0, "batch_reward": 0.6000986286103726, "critic_loss": 0.894956267029047, "actor_loss": -96.45102841186524, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.760265350341797, "step": 39000}
{"episode_reward": 940.0146575188779, "episode": 40.0, "batch_reward": 0.6105368508696556, "critic_loss": 0.8488829448521137, "actor_loss": -96.71352218627929, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.611814737319946, "step": 40000}
{"episode_reward": 970.9289882294231, "episode": 41.0, "batch_reward": 0.617047478377819, "critic_loss": 0.8573140178918839, "actor_loss": -96.23650622558594, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.51236176490784, "step": 41000}
{"episode_reward": 845.0105515556772, "episode": 42.0, "batch_reward": 0.6231976246237755, "critic_loss": 0.8341949197649956, "actor_loss": -95.95998585510254, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.157578706741333, "step": 42000}
{"episode_reward": 953.832485726796, "episode": 43.0, "batch_reward": 0.6322027583718299, "critic_loss": 0.8264859533905983, "actor_loss": -95.65821630859375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.29895329475403, "step": 43000}
{"episode_reward": 950.765354659832, "episode": 44.0, "batch_reward": 0.6382771981954575, "critic_loss": 0.786130072683096, "actor_loss": -95.52050094604492, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.437177896499634, "step": 44000}
{"episode_reward": 965.441459853684, "episode": 45.0, "batch_reward": 0.6447208282351494, "critic_loss": 0.7914432897567749, "actor_loss": -94.6756117401123, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.287769317626953, "step": 45000}
{"episode_reward": 926.1790808261153, "episode": 46.0, "batch_reward": 0.6478249897360802, "critic_loss": 0.7708459625542163, "actor_loss": -94.47094276428223, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.30204701423645, "step": 46000}
{"episode_reward": 686.4961033245874, "episode": 47.0, "batch_reward": 0.6534006400704384, "critic_loss": 0.7761128870248795, "actor_loss": -94.25919323730469, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.199480772018433, "step": 47000}
{"episode_reward": 951.7720019029839, "episode": 48.0, "batch_reward": 0.6572878013849258, "critic_loss": 0.7618974920809269, "actor_loss": -94.1286342010498, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.530967235565186, "step": 48000}
{"episode_reward": 847.2494497722442, "episode": 49.0, "batch_reward": 0.6654623112082482, "critic_loss": 0.7785900596976281, "actor_loss": -93.73119357299805, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.444856882095337, "step": 49000}
{"episode_reward": 928.4697390545808, "episode": 50.0, "batch_reward": 0.6667854107022285, "critic_loss": 0.7613169892430306, "actor_loss": -93.4707903137207, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.564231634140015, "step": 50000}
{"episode_reward": 987.2936901035632, "episode": 51.0, "batch_reward": 0.6754049799442291, "critic_loss": 0.7398331893384457, "actor_loss": -93.63283433532715, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.09377574920654, "step": 51000}
{"episode_reward": 982.0135756970176, "episode": 52.0, "batch_reward": 0.6783804998397828, "critic_loss": 0.7447148424088955, "actor_loss": -93.15187619018555, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.298847913742065, "step": 52000}
{"episode_reward": 884.5547237059556, "episode": 53.0, "batch_reward": 0.6849129171967506, "critic_loss": 0.7818211524784565, "actor_loss": -92.9991771850586, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.277382850646973, "step": 53000}
{"episode_reward": 916.5306538074494, "episode": 54.0, "batch_reward": 0.6892193647027016, "critic_loss": 0.7662276683151722, "actor_loss": -92.87003804016113, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.5845468044281, "step": 54000}
{"episode_reward": 946.1643283170279, "episode": 55.0, "batch_reward": 0.6943603275418282, "critic_loss": 0.7465855882167817, "actor_loss": -92.8526569519043, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.51710081100464, "step": 55000}
{"episode_reward": 976.4070809719262, "episode": 56.0, "batch_reward": 0.698774209678173, "critic_loss": 0.737030069977045, "actor_loss": -92.55549200439454, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.869138479232788, "step": 56000}
{"episode_reward": 980.7211882707363, "episode": 57.0, "batch_reward": 0.7067020161747932, "critic_loss": 0.729362265765667, "actor_loss": -92.38737503051757, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.654016494750977, "step": 57000}
{"episode_reward": 951.0402410901553, "episode": 58.0, "batch_reward": 0.7087118690013885, "critic_loss": 0.7118381906151772, "actor_loss": -92.36179446411133, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.771411657333374, "step": 58000}
{"episode_reward": 960.886629552162, "episode": 59.0, "batch_reward": 0.7128579119443893, "critic_loss": 0.7006312061548233, "actor_loss": -92.26127131652832, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.5713472366333, "step": 59000}
{"episode_reward": 938.4945013857163, "episode": 60.0, "batch_reward": 0.7164151476025581, "critic_loss": 0.7107560293972492, "actor_loss": -92.08473287963866, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.775176286697388, "step": 60000}
{"episode_reward": 922.1191147123064, "episode": 61.0, "batch_reward": 0.720331213593483, "critic_loss": 0.6895640590488911, "actor_loss": -91.95751347351074, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.58332872390747, "step": 61000}
{"episode_reward": 941.9336589560951, "episode": 62.0, "batch_reward": 0.7235415027737617, "critic_loss": 0.6834241084456444, "actor_loss": -91.91543980407715, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.18149209022522, "step": 62000}
{"episode_reward": 967.4280103732069, "episode": 63.0, "batch_reward": 0.7262295182943345, "critic_loss": 0.7060014183819294, "actor_loss": -91.82821838378906, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.460814952850342, "step": 63000}
{"episode_reward": 943.8472157431468, "episode": 64.0, "batch_reward": 0.7307456809878349, "critic_loss": 0.682528132468462, "actor_loss": -91.84819258117676, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.32884120941162, "step": 64000}
{"episode_reward": 986.0332328396009, "episode": 65.0, "batch_reward": 0.7289504379034042, "critic_loss": 0.6520849241316319, "actor_loss": -91.7830132446289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.810391426086426, "step": 65000}
{"episode_reward": 272.613874054533, "episode": 66.0, "batch_reward": 0.7275546036362648, "critic_loss": 0.6408757518231869, "actor_loss": -91.67731674194336, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.674589157104492, "step": 66000}
{"episode_reward": 935.1227473606327, "episode": 67.0, "batch_reward": 0.7302604294419288, "critic_loss": 0.6183933228254318, "actor_loss": -91.58126078796387, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.65583562850952, "step": 67000}
{"episode_reward": 907.1591645820995, "episode": 68.0, "batch_reward": 0.7316689414978027, "critic_loss": 0.6209787867069244, "actor_loss": -91.527298828125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.288158655166626, "step": 68000}
{"episode_reward": 949.5331108229458, "episode": 69.0, "batch_reward": 0.7356950677633286, "critic_loss": 0.5946591310203075, "actor_loss": -91.49379533386231, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.495310306549072, "step": 69000}
{"episode_reward": 984.478997792092, "episode": 70.0, "batch_reward": 0.7392180572152138, "critic_loss": 0.5843969659805298, "actor_loss": -91.26576132202149, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.359646558761597, "step": 70000}
{"episode_reward": 939.1499766286097, "episode": 71.0, "batch_reward": 0.7407875074744225, "critic_loss": 0.5868229798972606, "actor_loss": -90.99560215759277, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.078593730926514, "step": 71000}
{"episode_reward": 957.0513831583438, "episode": 72.0, "batch_reward": 0.7477518558502197, "critic_loss": 0.5792250539064407, "actor_loss": -91.02537319946289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.668909311294556, "step": 72000}
{"episode_reward": 970.226549641728, "episode": 73.0, "batch_reward": 0.7485664959549904, "critic_loss": 0.585806272238493, "actor_loss": -90.92126924133301, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.40532422065735, "step": 73000}
{"episode_reward": 957.176551774747, "episode": 74.0, "batch_reward": 0.7527675453424454, "critic_loss": 0.5585809202492237, "actor_loss": -91.01003814697266, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.324438333511353, "step": 74000}
{"episode_reward": 939.9171004334285, "episode": 75.0, "batch_reward": 0.7551057861447334, "critic_loss": 0.5555580665171146, "actor_loss": -90.98448069763184, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.2142276763916, "step": 75000}
{"episode_reward": 968.9900311687948, "episode": 76.0, "batch_reward": 0.7564325024485588, "critic_loss": 0.5529461840093136, "actor_loss": -90.95668688964844, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.56838321685791, "step": 76000}
{"episode_reward": 947.6758616472534, "episode": 77.0, "batch_reward": 0.7579318966269493, "critic_loss": 0.554392215937376, "actor_loss": -90.91833406066894, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.330326080322266, "step": 77000}
{"episode_reward": 965.4815996191155, "episode": 78.0, "batch_reward": 0.7633879415392876, "critic_loss": 0.5467341886013746, "actor_loss": -91.03759065246582, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.74929189682007, "step": 78000}
{"episode_reward": 954.3640424270101, "episode": 79.0, "batch_reward": 0.7661430559754372, "critic_loss": 0.5410182099342347, "actor_loss": -91.03306533813476, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.65401816368103, "step": 79000}
{"episode_reward": 966.8962111028324, "episode": 80.0, "batch_reward": 0.7678038536906242, "critic_loss": 0.5294250775426627, "actor_loss": -90.9792593536377, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.85938310623169, "step": 80000}
{"episode_reward": 978.7679466597227, "episode": 81.0, "batch_reward": 0.7703190979361534, "critic_loss": 0.5155046952962875, "actor_loss": -91.1415601196289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.048041343688965, "step": 81000}
{"episode_reward": 936.9516056156276, "episode": 82.0, "batch_reward": 0.7735162301063537, "critic_loss": 0.4959875135719776, "actor_loss": -91.10163752746583, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.668798208236694, "step": 82000}
{"episode_reward": 957.1139920340496, "episode": 83.0, "batch_reward": 0.773878581225872, "critic_loss": 0.48994407603144646, "actor_loss": -91.12365815734863, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.700676679611206, "step": 83000}
{"episode_reward": 940.0340039142728, "episode": 84.0, "batch_reward": 0.7776217374801636, "critic_loss": 0.48200989997386934, "actor_loss": -91.11595077514649, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.385161638259888, "step": 84000}
{"episode_reward": 990.4425850098935, "episode": 85.0, "batch_reward": 0.7772880619168282, "critic_loss": 0.4874366384446621, "actor_loss": -91.04117758178711, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.626033067703247, "step": 85000}
{"episode_reward": 950.5887738195163, "episode": 86.0, "batch_reward": 0.7791474984288216, "critic_loss": 0.4805302610397339, "actor_loss": -90.95868972778321, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.60246706008911, "step": 86000}
{"episode_reward": 955.2164118379569, "episode": 87.0, "batch_reward": 0.7815890295505523, "critic_loss": 0.5131233672052622, "actor_loss": -90.9516826171875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.304640293121338, "step": 87000}
{"episode_reward": 935.2496479834393, "episode": 88.0, "batch_reward": 0.7830551726818085, "critic_loss": 0.49176018753647804, "actor_loss": -91.00008615112304, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.944791793823242, "step": 88000}
{"episode_reward": 941.9798302395843, "episode": 89.0, "batch_reward": 0.7841858029365539, "critic_loss": 0.47751832830905916, "actor_loss": -91.05954522705078, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.581377744674683, "step": 89000}
{"episode_reward": 951.9292358196009, "episode": 90.0, "batch_reward": 0.7875882151126862, "critic_loss": 0.4793778758496046, "actor_loss": -91.25802926635743, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.30408024787903, "step": 90000}
{"episode_reward": 962.1788107073178, "episode": 91.0, "batch_reward": 0.7896134313941002, "critic_loss": 0.4756398745030165, "actor_loss": -91.08804856872558, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.510613441467285, "step": 91000}
{"episode_reward": 882.5157003158847, "episode": 92.0, "batch_reward": 0.7917139434814453, "critic_loss": 0.4669923928529024, "actor_loss": -91.2586501159668, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.859565258026123, "step": 92000}
{"episode_reward": 937.698322252409, "episode": 93.0, "batch_reward": 0.7921591718196869, "critic_loss": 0.47447472354769704, "actor_loss": -91.23588117980957, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.312787771224976, "step": 93000}
{"episode_reward": 984.3084454775698, "episode": 94.0, "batch_reward": 0.7934554436206818, "critic_loss": 0.48542331653833387, "actor_loss": -91.31254388427735, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.65712022781372, "step": 94000}
{"episode_reward": 957.8552305331301, "episode": 95.0, "batch_reward": 0.7949800295233727, "critic_loss": 0.507100634008646, "actor_loss": -91.35970454406738, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.64543914794922, "step": 95000}
{"episode_reward": 859.6873642773966, "episode": 96.0, "batch_reward": 0.7968111242055893, "critic_loss": 0.4944764485955238, "actor_loss": -91.34430894470215, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.3170382976532, "step": 96000}
{"episode_reward": 958.432759048073, "episode": 97.0, "batch_reward": 0.7975454031229019, "critic_loss": 0.5149209368228912, "actor_loss": -91.35351402282714, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.3692569732666, "step": 97000}
{"episode_reward": 917.4108851034687, "episode": 98.0, "batch_reward": 0.7993450260162354, "critic_loss": 0.5070181827694178, "actor_loss": -91.40786029052734, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.557947397232056, "step": 98000}
{"episode_reward": 927.9391603814055, "episode": 99.0, "batch_reward": 0.8011122494935989, "critic_loss": 0.5258119987547397, "actor_loss": -91.44481216430664, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.302000999450684, "step": 99000}
{"episode_reward": 908.7575132397595, "episode": 100.0, "batch_reward": 0.8040272736549378, "critic_loss": 0.5244563772976398, "actor_loss": -91.4188109741211, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.02621078491211, "step": 100000}
{"episode_reward": 909.1851603046628, "episode": 101.0, "batch_reward": 0.8034712460041046, "critic_loss": 0.4847845980674028, "actor_loss": -91.51349674987793, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.19206643104553, "step": 101000}
{"episode_reward": 961.0535778921744, "episode": 102.0, "batch_reward": 0.8029443916082383, "critic_loss": 0.4839458977878094, "actor_loss": -91.45589811706543, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.585978269577026, "step": 102000}
{"episode_reward": 978.3229455380649, "episode": 103.0, "batch_reward": 0.8046794895529747, "critic_loss": 0.4799022042155266, "actor_loss": -91.41470970153809, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.8520724773407, "step": 103000}
{"episode_reward": 929.7728956056105, "episode": 104.0, "batch_reward": 0.8102526162862778, "critic_loss": 0.48803208246827123, "actor_loss": -91.60620175170898, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.161354064941406, "step": 104000}
{"episode_reward": 944.3967376663954, "episode": 105.0, "batch_reward": 0.8098307639956475, "critic_loss": 0.497981203481555, "actor_loss": -91.48762872314452, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.316107273101807, "step": 105000}
{"episode_reward": 944.6114220134217, "episode": 106.0, "batch_reward": 0.809798153758049, "critic_loss": 0.4846266180425882, "actor_loss": -91.43410598754883, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.847694635391235, "step": 106000}
{"episode_reward": 936.7773727715851, "episode": 107.0, "batch_reward": 0.8115912853479386, "critic_loss": 0.4530161134451628, "actor_loss": -91.63810099792481, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.667733669281006, "step": 107000}
{"episode_reward": 949.9557042833999, "episode": 108.0, "batch_reward": 0.8134474414587021, "critic_loss": 0.4553142475783825, "actor_loss": -91.8049009552002, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.84529447555542, "step": 108000}
{"episode_reward": 950.7676909401235, "episode": 109.0, "batch_reward": 0.814387283205986, "critic_loss": 0.4715476358383894, "actor_loss": -91.74499476623535, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.32721972465515, "step": 109000}
{"episode_reward": 972.8016024992954, "episode": 110.0, "batch_reward": 0.8156953961253166, "critic_loss": 0.4787736349105835, "actor_loss": -91.82128329467774, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.377803087234497, "step": 110000}
{"episode_reward": 926.9035508294272, "episode": 111.0, "batch_reward": 0.817062005341053, "critic_loss": 0.4713522130548954, "actor_loss": -91.81607719421386, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.65857672691345, "step": 111000}
{"episode_reward": 932.0684230972705, "episode": 112.0, "batch_reward": 0.8178204237818718, "critic_loss": 0.44544341030716894, "actor_loss": -91.79282197570801, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.71873116493225, "step": 112000}
{"episode_reward": 945.0365904620033, "episode": 113.0, "batch_reward": 0.8197586421370506, "critic_loss": 0.4586138318628073, "actor_loss": -91.76007940673829, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.744402170181274, "step": 113000}
{"episode_reward": 938.5967889857269, "episode": 114.0, "batch_reward": 0.8199630981683731, "critic_loss": 0.44660465766489504, "actor_loss": -91.8561626739502, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.887030363082886, "step": 114000}
{"episode_reward": 980.1348112035928, "episode": 115.0, "batch_reward": 0.820372143983841, "critic_loss": 0.4718635434657335, "actor_loss": -91.75472698974609, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.32193422317505, "step": 115000}
{"episode_reward": 874.9798059217085, "episode": 116.0, "batch_reward": 0.8209073793292045, "critic_loss": 0.49238099010288716, "actor_loss": -91.79116989135743, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.103549480438232, "step": 116000}
{"episode_reward": 936.0400248131377, "episode": 117.0, "batch_reward": 0.8216939142346382, "critic_loss": 0.49381342424452307, "actor_loss": -91.70603965759277, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.67834782600403, "step": 117000}
{"episode_reward": 908.3958262743063, "episode": 118.0, "batch_reward": 0.8232805623412133, "critic_loss": 0.49131818751990797, "actor_loss": -91.86355879211426, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.604601860046387, "step": 118000}
{"episode_reward": 972.1683940210925, "episode": 119.0, "batch_reward": 0.8245238302946091, "critic_loss": 0.4794117193073034, "actor_loss": -91.75554978942871, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.336891651153564, "step": 119000}
{"episode_reward": 961.2423273039216, "episode": 120.0, "batch_reward": 0.8237916550040245, "critic_loss": 0.48053397332131864, "actor_loss": -91.57283949279785, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.71368980407715, "step": 120000}
{"episode_reward": 921.3726926287375, "episode": 121.0, "batch_reward": 0.8266744382977486, "critic_loss": 0.47472793225944043, "actor_loss": -91.77594827270508, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.49305987358093, "step": 121000}
{"episode_reward": 986.3736126884437, "episode": 122.0, "batch_reward": 0.8275983324050903, "critic_loss": 0.4931392856836319, "actor_loss": -91.85379847717284, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.66127038002014, "step": 122000}
{"episode_reward": 940.4536329542699, "episode": 123.0, "batch_reward": 0.8299490203857421, "critic_loss": 0.4760312819480896, "actor_loss": -91.81389186096192, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.41654896736145, "step": 123000}
{"episode_reward": 927.2515677815632, "episode": 124.0, "batch_reward": 0.8294707746505737, "critic_loss": 0.495517238676548, "actor_loss": -91.90280857849122, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.338489055633545, "step": 124000}
{"episode_reward": 982.7672220306241, "episode": 125.0, "batch_reward": 0.8320022259950638, "critic_loss": 0.4856870376318693, "actor_loss": -91.87549774169922, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.772476196289062, "step": 125000}
{"episode_reward": 982.1261344782345, "episode": 126.0, "batch_reward": 0.8327036741971969, "critic_loss": 0.48026114608347414, "actor_loss": -92.08949554443359, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.71408224105835, "step": 126000}
{"episode_reward": 987.423501024346, "episode": 127.0, "batch_reward": 0.8330443168282509, "critic_loss": 0.48835580398142336, "actor_loss": -92.05590924072266, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.610538721084595, "step": 127000}
{"episode_reward": 926.0420685805958, "episode": 128.0, "batch_reward": 0.8330667637586594, "critic_loss": 0.5034001421779394, "actor_loss": -92.08092425537109, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.307839393615723, "step": 128000}
{"episode_reward": 969.6393754600499, "episode": 129.0, "batch_reward": 0.8352048816680908, "critic_loss": 0.5042162710577249, "actor_loss": -92.17116806030273, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.591427087783813, "step": 129000}
{"episode_reward": 984.2846091028197, "episode": 130.0, "batch_reward": 0.8379963490366936, "critic_loss": 0.4903100206106901, "actor_loss": -92.16461480712891, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.44646430015564, "step": 130000}
{"episode_reward": 988.5423979908337, "episode": 131.0, "batch_reward": 0.8379015220403672, "critic_loss": 0.5057594287544489, "actor_loss": -92.11189077758789, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.84995889663696, "step": 131000}
{"episode_reward": 986.100499688933, "episode": 132.0, "batch_reward": 0.8382572587132454, "critic_loss": 0.5111006395816803, "actor_loss": -92.18732084655761, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.509428024291992, "step": 132000}
{"episode_reward": 962.2114037830951, "episode": 133.0, "batch_reward": 0.8383418274521828, "critic_loss": 0.5057409002035856, "actor_loss": -92.31897172546387, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.63824772834778, "step": 133000}
{"episode_reward": 962.0332387963532, "episode": 134.0, "batch_reward": 0.8398502023220062, "critic_loss": 0.47317555065453054, "actor_loss": -92.39017028808594, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.26876425743103, "step": 134000}
{"episode_reward": 964.3100032372231, "episode": 135.0, "batch_reward": 0.841907633125782, "critic_loss": 0.46180374440550803, "actor_loss": -92.26552893066406, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.361122608184814, "step": 135000}
{"episode_reward": 994.6512379781561, "episode": 136.0, "batch_reward": 0.8444453852176667, "critic_loss": 0.44773241733014585, "actor_loss": -92.33016087341309, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.635570526123047, "step": 136000}
{"episode_reward": 986.203128964148, "episode": 137.0, "batch_reward": 0.8425648336410523, "critic_loss": 0.4716496543288231, "actor_loss": -92.27356791687012, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.850985288619995, "step": 137000}
{"episode_reward": 875.8757938050569, "episode": 138.0, "batch_reward": 0.844276767551899, "critic_loss": 0.47413786762952803, "actor_loss": -92.34429362487793, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.345919370651245, "step": 138000}
{"episode_reward": 959.3492124103939, "episode": 139.0, "batch_reward": 0.8450722868442535, "critic_loss": 0.4702027703821659, "actor_loss": -92.38874089050293, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.786946535110474, "step": 139000}
{"episode_reward": 988.174825387316, "episode": 140.0, "batch_reward": 0.8445384365320205, "critic_loss": 0.4558565089404583, "actor_loss": -92.42669610595703, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.92801547050476, "step": 140000}
{"episode_reward": 956.435304894459, "episode": 141.0, "batch_reward": 0.8466808052062988, "critic_loss": 0.4700501141101122, "actor_loss": -92.44187983703613, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.59459161758423, "step": 141000}
{"episode_reward": 968.5263612780441, "episode": 142.0, "batch_reward": 0.8472614102959632, "critic_loss": 0.439161551207304, "actor_loss": -92.48981802368164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.65543293952942, "step": 142000}
{"episode_reward": 987.5425506609439, "episode": 143.0, "batch_reward": 0.8491983097195626, "critic_loss": 0.44600938887894154, "actor_loss": -92.59658389282227, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.699875354766846, "step": 143000}
{"episode_reward": 879.9213542901161, "episode": 144.0, "batch_reward": 0.8479977278113365, "critic_loss": 0.4693121448606253, "actor_loss": -92.58297277832031, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.5158109664917, "step": 144000}
{"episode_reward": 957.435890172806, "episode": 145.0, "batch_reward": 0.8498629829883575, "critic_loss": 0.45287160570919516, "actor_loss": -92.66819619750977, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.72611355781555, "step": 145000}
{"episode_reward": 987.3150792311676, "episode": 146.0, "batch_reward": 0.8492837076783181, "critic_loss": 0.4707481225728989, "actor_loss": -92.70745899963379, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.974651098251343, "step": 146000}
{"episode_reward": 954.0406852885502, "episode": 147.0, "batch_reward": 0.8503213734030723, "critic_loss": 0.47868424679338933, "actor_loss": -92.67713008117676, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.32460904121399, "step": 147000}
{"episode_reward": 917.1638090917687, "episode": 148.0, "batch_reward": 0.8528670187592506, "critic_loss": 0.450040161266923, "actor_loss": -92.76818157958985, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.175264596939087, "step": 148000}
{"episode_reward": 983.8353680395493, "episode": 149.0, "batch_reward": 0.8522941883206367, "critic_loss": 0.45173737573623657, "actor_loss": -92.69919274902344, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.701356410980225, "step": 149000}
{"episode_reward": 923.9839007792774, "episode": 150.0, "batch_reward": 0.8529215633869172, "critic_loss": 0.4586098078787327, "actor_loss": -92.77202496337891, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
