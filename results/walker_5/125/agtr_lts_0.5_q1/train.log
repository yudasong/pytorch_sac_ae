{"episode_reward": 0.0, "episode": 1.0, "duration": 20.990353107452393, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.8220458030700684, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.45745399554557264, "critic_loss": 0.21447689714864834, "actor_loss": -45.424219616425304, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 61.31851315498352, "step": 3000}
{"episode_reward": 209.70529882440107, "episode": 4.0, "batch_reward": 0.36493593207001684, "critic_loss": 0.5343182162642479, "actor_loss": -47.767168910980224, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.479729413986206, "step": 4000}
{"episode_reward": 159.40698806327782, "episode": 5.0, "batch_reward": 0.3246941037923098, "critic_loss": 0.5809844259023667, "actor_loss": -43.81554577255249, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.445377111434937, "step": 5000}
{"episode_reward": 183.4238014100544, "episode": 6.0, "batch_reward": 0.27696926037967207, "critic_loss": 0.5837841928303241, "actor_loss": -46.29956599235535, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.48507809638977, "step": 6000}
{"episode_reward": 33.158723162019115, "episode": 7.0, "batch_reward": 0.2557192001640797, "critic_loss": 0.968350531488657, "actor_loss": -49.23967482948303, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.461435556411743, "step": 7000}
{"episode_reward": 405.2026298673317, "episode": 8.0, "batch_reward": 0.28740651907026765, "critic_loss": 1.3394255750179291, "actor_loss": -50.25573586273193, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.455065488815308, "step": 8000}
{"episode_reward": 475.80600677398144, "episode": 9.0, "batch_reward": 0.31439172619581224, "critic_loss": 1.6284275770187377, "actor_loss": -51.77307474136352, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.485723733901978, "step": 9000}
{"episode_reward": 604.9038494436782, "episode": 10.0, "batch_reward": 0.34082247054576875, "critic_loss": 1.8336243778467178, "actor_loss": -52.21183255386352, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43489718437195, "step": 10000}
{"episode_reward": 608.6347894284152, "episode": 11.0, "batch_reward": 0.37365295344591143, "critic_loss": 1.9485033664703368, "actor_loss": -56.43783995819092, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.20876097679138, "step": 11000}
{"episode_reward": 672.630473883142, "episode": 12.0, "batch_reward": 0.40414140769839285, "critic_loss": 2.15061264193058, "actor_loss": -56.618362480163576, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.38757348060608, "step": 12000}
{"episode_reward": 773.5003271880415, "episode": 13.0, "batch_reward": 0.4249948240220547, "critic_loss": 2.0505116398334504, "actor_loss": -57.59384369659424, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.430892944335938, "step": 13000}
{"episode_reward": 549.7583081814339, "episode": 14.0, "batch_reward": 0.4461346746683121, "critic_loss": 1.892310839653015, "actor_loss": -58.12235417938233, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.493165731430054, "step": 14000}
{"episode_reward": 884.1204006317074, "episode": 15.0, "batch_reward": 0.4772588263750076, "critic_loss": 1.8424567146897315, "actor_loss": -63.733745651245115, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43584132194519, "step": 15000}
{"episode_reward": 921.1643095204131, "episode": 16.0, "batch_reward": 0.5004753533303737, "critic_loss": 1.7439904075860977, "actor_loss": -64.91585796356202, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43609595298767, "step": 16000}
{"episode_reward": 812.7064369282919, "episode": 17.0, "batch_reward": 0.5227264482975006, "critic_loss": 1.739341437280178, "actor_loss": -64.62994304656982, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.443862915039062, "step": 17000}
{"episode_reward": 779.9004625140744, "episode": 18.0, "batch_reward": 0.5402163859009743, "critic_loss": 1.8241169764995575, "actor_loss": -65.17850896453858, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.400004148483276, "step": 18000}
{"episode_reward": 884.214630268252, "episode": 19.0, "batch_reward": 0.5619237618744374, "critic_loss": 1.7575798188447953, "actor_loss": -67.39090511322021, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44819474220276, "step": 19000}
{"episode_reward": 982.2936452033302, "episode": 20.0, "batch_reward": 0.577646809309721, "critic_loss": 1.8234861214756966, "actor_loss": -69.10666460418702, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.45296049118042, "step": 20000}
{"episode_reward": 783.343978720909, "episode": 21.0, "batch_reward": 0.5863299937844276, "critic_loss": 1.8774221103191375, "actor_loss": -70.55228527832031, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.113298177719116, "step": 21000}
{"episode_reward": 807.5239369897447, "episode": 22.0, "batch_reward": 0.6050280482470989, "critic_loss": 1.810023772239685, "actor_loss": -70.57009331512451, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.46993637084961, "step": 22000}
{"episode_reward": 962.4547865325526, "episode": 23.0, "batch_reward": 0.62038672798872, "critic_loss": 1.7331326344013214, "actor_loss": -71.25327970123291, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.41135001182556, "step": 23000}
{"episode_reward": 946.9670019520466, "episode": 24.0, "batch_reward": 0.6304595069289207, "critic_loss": 1.7892289608716965, "actor_loss": -73.34226773834229, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.452596426010132, "step": 24000}
{"episode_reward": 923.6036611406581, "episode": 25.0, "batch_reward": 0.6411844856142997, "critic_loss": 1.871592114508152, "actor_loss": -73.12248892211915, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.418755531311035, "step": 25000}
{"episode_reward": 873.7603416525585, "episode": 26.0, "batch_reward": 0.6497182004451751, "critic_loss": 1.8661420464515686, "actor_loss": -73.69343687438965, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.443241357803345, "step": 26000}
{"episode_reward": 917.0736032931616, "episode": 27.0, "batch_reward": 0.6609376571178436, "critic_loss": 1.8663639991283416, "actor_loss": -74.65964794158936, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.466527223587036, "step": 27000}
{"episode_reward": 858.9833760523821, "episode": 28.0, "batch_reward": 0.6724039760828018, "critic_loss": 1.7836470001935958, "actor_loss": -75.29082929992676, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.45184826850891, "step": 28000}
{"episode_reward": 955.4102825476488, "episode": 29.0, "batch_reward": 0.6787082946896553, "critic_loss": 1.7129123896360396, "actor_loss": -76.8499409942627, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.440732955932617, "step": 29000}
{"episode_reward": 891.2738986367037, "episode": 30.0, "batch_reward": 0.688156334578991, "critic_loss": 1.6559949060678483, "actor_loss": -77.2874292755127, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44429087638855, "step": 30000}
{"episode_reward": 840.2697025060332, "episode": 31.0, "batch_reward": 0.6908541669249535, "critic_loss": 1.8011259468197822, "actor_loss": -78.05956893157959, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.1806526184082, "step": 31000}
{"episode_reward": 926.929656565629, "episode": 32.0, "batch_reward": 0.7015589366555214, "critic_loss": 1.7297624745368958, "actor_loss": -78.6403897857666, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.435821056365967, "step": 32000}
{"episode_reward": 945.9894596384943, "episode": 33.0, "batch_reward": 0.7069712089300155, "critic_loss": 1.7404415721297264, "actor_loss": -79.07251963806152, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.452362060546875, "step": 33000}
{"episode_reward": 954.9266107763449, "episode": 34.0, "batch_reward": 0.7142416141033172, "critic_loss": 1.7180509865880011, "actor_loss": -78.53356808471679, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.465269327163696, "step": 34000}
{"episode_reward": 898.7096588488203, "episode": 35.0, "batch_reward": 0.7194326882362365, "critic_loss": 1.8397928755879402, "actor_loss": -80.29208200073242, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44323420524597, "step": 35000}
{"episode_reward": 859.0442829101638, "episode": 36.0, "batch_reward": 0.7213974784016609, "critic_loss": 1.8627733291983604, "actor_loss": -80.05654753112793, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.459232568740845, "step": 36000}
{"episode_reward": 923.1222780673079, "episode": 37.0, "batch_reward": 0.7153863012194633, "critic_loss": 1.8603602221608162, "actor_loss": -80.16500506591797, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.484678268432617, "step": 37000}
{"episode_reward": 321.02935345177656, "episode": 38.0, "batch_reward": 0.7199338364005089, "critic_loss": 1.654885170340538, "actor_loss": -81.06638708496094, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44727110862732, "step": 38000}
{"episode_reward": 971.4646530737134, "episode": 39.0, "batch_reward": 0.7251138273477554, "critic_loss": 1.5550839450955392, "actor_loss": -82.03762225341796, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.455568552017212, "step": 39000}
{"episode_reward": 950.2799615326298, "episode": 40.0, "batch_reward": 0.7296732471585273, "critic_loss": 1.5531374451518059, "actor_loss": -82.14634899902343, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.45952606201172, "step": 40000}
{"episode_reward": 909.984952675598, "episode": 41.0, "batch_reward": 0.7339655781984329, "critic_loss": 1.6374291199445725, "actor_loss": -82.30440728759766, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.149893045425415, "step": 41000}
{"episode_reward": 874.5417843732823, "episode": 42.0, "batch_reward": 0.7405750298500061, "critic_loss": 1.567569059252739, "actor_loss": -82.26619775390625, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.454525232315063, "step": 42000}
{"episode_reward": 966.7581995220804, "episode": 43.0, "batch_reward": 0.7435876926779748, "critic_loss": 1.5695212443470954, "actor_loss": -82.70412893676757, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.41446566581726, "step": 43000}
{"episode_reward": 951.0265432189354, "episode": 44.0, "batch_reward": 0.7477034993171692, "critic_loss": 1.3437012066841125, "actor_loss": -82.7738569946289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.41830825805664, "step": 44000}
{"episode_reward": 975.3651735087227, "episode": 45.0, "batch_reward": 0.7541264900565148, "critic_loss": 1.332304819583893, "actor_loss": -83.58111322021485, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.465437412261963, "step": 45000}
{"episode_reward": 967.2308476706113, "episode": 46.0, "batch_reward": 0.7572444501519203, "critic_loss": 1.196651471555233, "actor_loss": -83.82340937805176, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.416002988815308, "step": 46000}
{"episode_reward": 971.8848618775025, "episode": 47.0, "batch_reward": 0.7636748604774475, "critic_loss": 1.2625612030029296, "actor_loss": -83.7743070526123, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44830846786499, "step": 47000}
{"episode_reward": 958.2408951307166, "episode": 48.0, "batch_reward": 0.7661820887327194, "critic_loss": 1.1909815142154694, "actor_loss": -83.75818818664551, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44752526283264, "step": 48000}
{"episode_reward": 934.6079569915452, "episode": 49.0, "batch_reward": 0.7725805746912956, "critic_loss": 1.1515176513195038, "actor_loss": -84.42252096557617, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.424375534057617, "step": 49000}
{"episode_reward": 981.432099688282, "episode": 50.0, "batch_reward": 0.7745731962919236, "critic_loss": 1.1576638597249984, "actor_loss": -84.67043243408203, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.450697422027588, "step": 50000}
{"episode_reward": 987.7436692138883, "episode": 51.0, "batch_reward": 0.7808664044737816, "critic_loss": 1.1747203586697579, "actor_loss": -84.46633279418946, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.172781229019165, "step": 51000}
{"episode_reward": 982.4773246064707, "episode": 52.0, "batch_reward": 0.7830556816458702, "critic_loss": 1.1139396224021911, "actor_loss": -85.45988131713867, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43431544303894, "step": 52000}
{"episode_reward": 957.7159138965983, "episode": 53.0, "batch_reward": 0.7859605378508567, "critic_loss": 1.127350276052952, "actor_loss": -85.40638874816895, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.460084438323975, "step": 53000}
{"episode_reward": 911.6300506522491, "episode": 54.0, "batch_reward": 0.7889598057866096, "critic_loss": 1.1042940581440925, "actor_loss": -85.69496008300781, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.41512155532837, "step": 54000}
{"episode_reward": 939.9658250760732, "episode": 55.0, "batch_reward": 0.7922748504877091, "critic_loss": 1.0538281191587449, "actor_loss": -85.6154621887207, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.401859521865845, "step": 55000}
{"episode_reward": 976.597456691062, "episode": 56.0, "batch_reward": 0.7966836177706719, "critic_loss": 1.0350584545731545, "actor_loss": -86.32110174560547, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.45409369468689, "step": 56000}
{"episode_reward": 985.3996142749019, "episode": 57.0, "batch_reward": 0.7990845273137093, "critic_loss": 1.0113629546165466, "actor_loss": -86.53166900634766, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.42975616455078, "step": 57000}
{"episode_reward": 949.1215893017837, "episode": 58.0, "batch_reward": 0.8012821053862572, "critic_loss": 0.9624919163286686, "actor_loss": -86.14137518310547, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.440534591674805, "step": 58000}
{"episode_reward": 965.4756862868626, "episode": 59.0, "batch_reward": 0.8046170654296875, "critic_loss": 0.9628850665688514, "actor_loss": -86.60436892700196, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.433237314224243, "step": 59000}
{"episode_reward": 951.9800615472635, "episode": 60.0, "batch_reward": 0.8071349370479584, "critic_loss": 0.9561529298722744, "actor_loss": -87.48492720031739, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.3915696144104, "step": 60000}
{"episode_reward": 959.5856996351267, "episode": 61.0, "batch_reward": 0.808409061908722, "critic_loss": 1.011099758952856, "actor_loss": -86.82565184020996, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.157597064971924, "step": 61000}
{"episode_reward": 900.8335982912416, "episode": 62.0, "batch_reward": 0.8085459731817245, "critic_loss": 0.94448531883955, "actor_loss": -86.88715823364258, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.393769025802612, "step": 62000}
{"episode_reward": 961.8815643373242, "episode": 63.0, "batch_reward": 0.8102527905702591, "critic_loss": 0.9743648141026496, "actor_loss": -87.37649583435059, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.46584177017212, "step": 63000}
{"episode_reward": 899.9084021027143, "episode": 64.0, "batch_reward": 0.8130291985869408, "critic_loss": 0.9459521629810334, "actor_loss": -87.46927032470703, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.443116188049316, "step": 64000}
{"episode_reward": 988.8251119517929, "episode": 65.0, "batch_reward": 0.816828588783741, "critic_loss": 0.9578558733761311, "actor_loss": -87.75940629577637, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.425951719284058, "step": 65000}
{"episode_reward": 946.6449808686452, "episode": 66.0, "batch_reward": 0.8169401739239692, "critic_loss": 0.975493760973215, "actor_loss": -87.91640911865234, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.462405681610107, "step": 66000}
{"episode_reward": 847.5133483426285, "episode": 67.0, "batch_reward": 0.817791531264782, "critic_loss": 0.9837909916639328, "actor_loss": -88.32057815551758, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.454704999923706, "step": 67000}
{"episode_reward": 932.86575546016, "episode": 68.0, "batch_reward": 0.8208933927416802, "critic_loss": 0.9607414112985134, "actor_loss": -87.78336033630372, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.45128631591797, "step": 68000}
{"episode_reward": 944.15205983795, "episode": 69.0, "batch_reward": 0.820262510240078, "critic_loss": 0.9408973968327046, "actor_loss": -88.3259109802246, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.45591688156128, "step": 69000}
{"episode_reward": 988.3376300113547, "episode": 70.0, "batch_reward": 0.8242091290354728, "critic_loss": 0.9591797797679901, "actor_loss": -88.54428576660156, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.434868335723877, "step": 70000}
{"episode_reward": 904.5019876506466, "episode": 71.0, "batch_reward": 0.8248456538915634, "critic_loss": 0.9937886958420277, "actor_loss": -88.26417698669434, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.1706109046936, "step": 71000}
{"episode_reward": 964.045617257037, "episode": 72.0, "batch_reward": 0.8292796550393104, "critic_loss": 0.9314021652340889, "actor_loss": -88.56867887878418, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44205594062805, "step": 72000}
{"episode_reward": 982.8227587887982, "episode": 73.0, "batch_reward": 0.82939281219244, "critic_loss": 0.9280184154510498, "actor_loss": -88.65459898376464, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.452495098114014, "step": 73000}
{"episode_reward": 986.2139983393182, "episode": 74.0, "batch_reward": 0.8335611153841018, "critic_loss": 0.9503467321991921, "actor_loss": -89.02084060668945, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.460397720336914, "step": 74000}
{"episode_reward": 851.1622324530174, "episode": 75.0, "batch_reward": 0.8331165432929992, "critic_loss": 0.921211201608181, "actor_loss": -88.97470072937011, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.473316431045532, "step": 75000}
{"episode_reward": 968.4530351894683, "episode": 76.0, "batch_reward": 0.8336664596796036, "critic_loss": 0.94427081990242, "actor_loss": -88.92740103149414, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43741536140442, "step": 76000}
{"episode_reward": 925.3404079085001, "episode": 77.0, "batch_reward": 0.8355479538440704, "critic_loss": 0.9763012601137161, "actor_loss": -89.10005990600585, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.454251289367676, "step": 77000}
{"episode_reward": 956.7277094649356, "episode": 78.0, "batch_reward": 0.8374848999977111, "critic_loss": 0.9434105113744736, "actor_loss": -89.47227333068848, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.46107006072998, "step": 78000}
{"episode_reward": 958.8500361917302, "episode": 79.0, "batch_reward": 0.8394202209711075, "critic_loss": 0.9249166628420353, "actor_loss": -89.14431356811524, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.462673664093018, "step": 79000}
{"episode_reward": 969.0079648695298, "episode": 80.0, "batch_reward": 0.8391338375806808, "critic_loss": 0.9297380208671093, "actor_loss": -89.28131210327149, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43170475959778, "step": 80000}
{"episode_reward": 978.74512987848, "episode": 81.0, "batch_reward": 0.842083831012249, "critic_loss": 0.8997736774682998, "actor_loss": -89.6019037322998, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.16482949256897, "step": 81000}
{"episode_reward": 927.4194233351499, "episode": 82.0, "batch_reward": 0.8428919141292572, "critic_loss": 0.8724621108770371, "actor_loss": -89.88159254455566, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.442476272583008, "step": 82000}
{"episode_reward": 922.5439843937241, "episode": 83.0, "batch_reward": 0.8447168089151382, "critic_loss": 0.8611968328356743, "actor_loss": -89.79074151611329, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.448503971099854, "step": 83000}
{"episode_reward": 945.7610165529954, "episode": 84.0, "batch_reward": 0.8459331731200218, "critic_loss": 0.880403020054102, "actor_loss": -89.89436592102051, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.476627111434937, "step": 84000}
{"episode_reward": 987.8035207766102, "episode": 85.0, "batch_reward": 0.8451763113737106, "critic_loss": 0.8812354641258716, "actor_loss": -90.03749856567383, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.427491903305054, "step": 85000}
{"episode_reward": 916.0898864541351, "episode": 86.0, "batch_reward": 0.8477775328159333, "critic_loss": 0.8744196145236492, "actor_loss": -89.87142323303223, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.441396951675415, "step": 86000}
{"episode_reward": 932.9015502887142, "episode": 87.0, "batch_reward": 0.8486057314276695, "critic_loss": 0.9206248330175877, "actor_loss": -89.98137857055664, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.474329948425293, "step": 87000}
{"episode_reward": 958.3440005094733, "episode": 88.0, "batch_reward": 0.8505635413527489, "critic_loss": 0.8838532628118991, "actor_loss": -89.84733126831054, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.453795909881592, "step": 88000}
{"episode_reward": 930.7986230111993, "episode": 89.0, "batch_reward": 0.8505749815106391, "critic_loss": 0.8848123762309551, "actor_loss": -90.14876803588866, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.454692840576172, "step": 89000}
{"episode_reward": 986.4109176751382, "episode": 90.0, "batch_reward": 0.8519105719923973, "critic_loss": 0.8491395400464534, "actor_loss": -90.37859944152832, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.47147512435913, "step": 90000}
{"episode_reward": 940.7847123884311, "episode": 91.0, "batch_reward": 0.8538247495293617, "critic_loss": 0.8733840639293193, "actor_loss": -90.23243650817871, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.20024275779724, "step": 91000}
{"episode_reward": 963.76137203382, "episode": 92.0, "batch_reward": 0.8560463507771492, "critic_loss": 0.8518624522536993, "actor_loss": -90.4015299987793, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.477325439453125, "step": 92000}
{"episode_reward": 972.6968490267055, "episode": 93.0, "batch_reward": 0.8540491132736207, "critic_loss": 0.8534105665385723, "actor_loss": -90.33934629821778, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.458849906921387, "step": 93000}
{"episode_reward": 984.2602358399914, "episode": 94.0, "batch_reward": 0.8559986752271652, "critic_loss": 0.8292364328503609, "actor_loss": -90.42275688171387, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.428131580352783, "step": 94000}
{"episode_reward": 944.0917275817351, "episode": 95.0, "batch_reward": 0.8561377353072166, "critic_loss": 0.8146072663664817, "actor_loss": -90.76520442199707, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.434971809387207, "step": 95000}
{"episode_reward": 929.3150188695172, "episode": 96.0, "batch_reward": 0.8590388175845146, "critic_loss": 0.8132882120013237, "actor_loss": -90.72118862915039, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43556571006775, "step": 96000}
{"episode_reward": 944.6786634420993, "episode": 97.0, "batch_reward": 0.86031382137537, "critic_loss": 0.78226217892766, "actor_loss": -90.82036567687989, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.4582679271698, "step": 97000}
{"episode_reward": 919.6791411611531, "episode": 98.0, "batch_reward": 0.8606149668097496, "critic_loss": 0.8047135373651981, "actor_loss": -90.82184544372559, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43793535232544, "step": 98000}
{"episode_reward": 913.1666792832388, "episode": 99.0, "batch_reward": 0.861004160284996, "critic_loss": 0.8410660132467747, "actor_loss": -90.858941696167, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.437391757965088, "step": 99000}
{"episode_reward": 985.0592158519285, "episode": 100.0, "batch_reward": 0.8622364321351051, "critic_loss": 0.7811411952376366, "actor_loss": -90.83097848510742, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.462661027908325, "step": 100000}
{"episode_reward": 917.0694952883476, "episode": 101.0, "batch_reward": 0.8629341090321541, "critic_loss": 0.8184233846962452, "actor_loss": -91.08011235046386, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.21135354042053, "step": 101000}
{"episode_reward": 958.66649684717, "episode": 102.0, "batch_reward": 0.8646381102800369, "critic_loss": 0.7958896659016609, "actor_loss": -91.11407243347168, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.47036075592041, "step": 102000}
{"episode_reward": 984.1862395089898, "episode": 103.0, "batch_reward": 0.8626839268803597, "critic_loss": 0.8364942777752876, "actor_loss": -91.02585249328614, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.48081111907959, "step": 103000}
{"episode_reward": 867.3078201769697, "episode": 104.0, "batch_reward": 0.8650765781402587, "critic_loss": 0.7769841227829456, "actor_loss": -91.05001847839355, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44148302078247, "step": 104000}
{"episode_reward": 957.5961610222467, "episode": 105.0, "batch_reward": 0.8669167617559433, "critic_loss": 0.7763580806851387, "actor_loss": -91.27740783691407, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.46701455116272, "step": 105000}
{"episode_reward": 934.3071873810345, "episode": 106.0, "batch_reward": 0.8664101303815842, "critic_loss": 0.793490981400013, "actor_loss": -91.06585409545899, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.456085205078125, "step": 106000}
{"episode_reward": 937.3079769071763, "episode": 107.0, "batch_reward": 0.8658718418478966, "critic_loss": 0.7598678014576435, "actor_loss": -91.18413452148438, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.427462100982666, "step": 107000}
{"episode_reward": 948.0636687391623, "episode": 108.0, "batch_reward": 0.8685982691645622, "critic_loss": 0.72945066472888, "actor_loss": -91.39343711853027, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.482155561447144, "step": 108000}
{"episode_reward": 964.0045709213533, "episode": 109.0, "batch_reward": 0.868629233777523, "critic_loss": 0.7830215413570404, "actor_loss": -91.39318312072754, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.440123796463013, "step": 109000}
{"episode_reward": 973.7789550698831, "episode": 110.0, "batch_reward": 0.8699147788882255, "critic_loss": 0.7905296658277512, "actor_loss": -91.54984066772461, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.458643198013306, "step": 110000}
{"episode_reward": 952.6374040831025, "episode": 111.0, "batch_reward": 0.8700482465028763, "critic_loss": 0.8025006911456585, "actor_loss": -91.56979054260253, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.19583177566528, "step": 111000}
{"episode_reward": 910.1884229982513, "episode": 112.0, "batch_reward": 0.8701109253764152, "critic_loss": 0.8130234372615814, "actor_loss": -91.46507943725587, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.489379167556763, "step": 112000}
{"episode_reward": 972.7890784747726, "episode": 113.0, "batch_reward": 0.8714819719195366, "critic_loss": 0.8069428073465824, "actor_loss": -91.52114437866211, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.441253423690796, "step": 113000}
{"episode_reward": 921.4320092719988, "episode": 114.0, "batch_reward": 0.8733929570913315, "critic_loss": 0.7869251307845115, "actor_loss": -91.77551698303223, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.485307693481445, "step": 114000}
{"episode_reward": 971.7934940899568, "episode": 115.0, "batch_reward": 0.8734574089050293, "critic_loss": 0.7679291307032108, "actor_loss": -91.72841412353516, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.98378825187683, "step": 115000}
{"episode_reward": 910.4531611582768, "episode": 116.0, "batch_reward": 0.8734935371875763, "critic_loss": 0.7735689967274666, "actor_loss": -91.78838374328613, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.625816106796265, "step": 116000}
{"episode_reward": 954.6144195609156, "episode": 117.0, "batch_reward": 0.8737324177622795, "critic_loss": 0.7949783118963242, "actor_loss": -91.62340867614746, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.45840334892273, "step": 117000}
{"episode_reward": 854.1994827769273, "episode": 118.0, "batch_reward": 0.8743858417272568, "critic_loss": 0.7893860754072666, "actor_loss": -91.7909482421875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.597236394882202, "step": 118000}
{"episode_reward": 949.9446626604882, "episode": 119.0, "batch_reward": 0.8741245778203011, "critic_loss": 0.7762887490093708, "actor_loss": -91.77702024841308, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.476545095443726, "step": 119000}
{"episode_reward": 962.7055885963938, "episode": 120.0, "batch_reward": 0.8742638736963272, "critic_loss": 0.7963246468901635, "actor_loss": -91.63867378234863, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.461062908172607, "step": 120000}
{"episode_reward": 948.6617239980436, "episode": 121.0, "batch_reward": 0.8757002100348472, "critic_loss": 0.7614671897292137, "actor_loss": -91.83491320800782, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.52104949951172, "step": 121000}
{"episode_reward": 943.4711764943536, "episode": 122.0, "batch_reward": 0.8768185719847679, "critic_loss": 0.7587356493175029, "actor_loss": -91.95700189208985, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.225979328155518, "step": 122000}
{"episode_reward": 954.449569561552, "episode": 123.0, "batch_reward": 0.8762224754691124, "critic_loss": 0.7604981001019477, "actor_loss": -91.76922746276855, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.13235306739807, "step": 123000}
{"episode_reward": 958.1206980750927, "episode": 124.0, "batch_reward": 0.877801786005497, "critic_loss": 0.7760813371837139, "actor_loss": -92.01990907287598, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.41985845565796, "step": 124000}
{"episode_reward": 905.6164817469712, "episode": 125.0, "batch_reward": 0.8797690972089768, "critic_loss": 0.7414439277350903, "actor_loss": -91.86318272399902, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.610483646392822, "step": 125000}
{"episode_reward": 981.7396044898612, "episode": 126.0, "batch_reward": 0.8789750443100929, "critic_loss": 0.738819201529026, "actor_loss": -92.11088024902344, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.850553274154663, "step": 126000}
{"episode_reward": 979.6335922970216, "episode": 127.0, "batch_reward": 0.8795207329988479, "critic_loss": 0.7420154150724411, "actor_loss": -92.10785084533691, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.708618640899658, "step": 127000}
{"episode_reward": 928.9176648079155, "episode": 128.0, "batch_reward": 0.8797436300516128, "critic_loss": 0.7480662464499473, "actor_loss": -92.10925607299805, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.571690559387207, "step": 128000}
{"episode_reward": 971.8504401621141, "episode": 129.0, "batch_reward": 0.8814075846672058, "critic_loss": 0.7660980637371541, "actor_loss": -92.23033459472656, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.061195611953735, "step": 129000}
{"episode_reward": 973.2527357779278, "episode": 130.0, "batch_reward": 0.8818657192587852, "critic_loss": 0.7722349874675274, "actor_loss": -92.19254713439942, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.65181851387024, "step": 130000}
{"episode_reward": 948.8623976650567, "episode": 131.0, "batch_reward": 0.8825838025212288, "critic_loss": 0.823970088750124, "actor_loss": -92.18700453186035, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.414608001708984, "step": 131000}
{"episode_reward": 951.7328583164422, "episode": 132.0, "batch_reward": 0.883342347741127, "critic_loss": 0.8010437968373298, "actor_loss": -92.08631750488281, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.170249223709106, "step": 132000}
{"episode_reward": 979.1017966607021, "episode": 133.0, "batch_reward": 0.8819975098371505, "critic_loss": 0.8255430876612663, "actor_loss": -92.2167380065918, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.938936233520508, "step": 133000}
{"episode_reward": 958.4723341675598, "episode": 134.0, "batch_reward": 0.8834183181524277, "critic_loss": 0.7757594656050205, "actor_loss": -92.31199447631836, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.752257823944092, "step": 134000}
{"episode_reward": 959.9880119016455, "episode": 135.0, "batch_reward": 0.8858303751945495, "critic_loss": 0.7857738537192345, "actor_loss": -92.29928277587891, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.600271224975586, "step": 135000}
{"episode_reward": 991.4332991735661, "episode": 136.0, "batch_reward": 0.8860356951355934, "critic_loss": 0.7890552385747432, "actor_loss": -92.39714453125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.114503622055054, "step": 136000}
{"episode_reward": 988.7383777608561, "episode": 137.0, "batch_reward": 0.8859233838319779, "critic_loss": 0.7566007615625858, "actor_loss": -92.27036018371582, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.806791305541992, "step": 137000}
{"episode_reward": 975.4024595007805, "episode": 138.0, "batch_reward": 0.8871694508790969, "critic_loss": 0.7549684961438179, "actor_loss": -92.24652336120606, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.875916242599487, "step": 138000}
{"episode_reward": 958.9951463794221, "episode": 139.0, "batch_reward": 0.8870438923835754, "critic_loss": 0.7611033388972283, "actor_loss": -92.3155899810791, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.926383018493652, "step": 139000}
{"episode_reward": 950.0411695490154, "episode": 140.0, "batch_reward": 0.8872124329209328, "critic_loss": 0.797286546498537, "actor_loss": -92.23899353027343, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.14152216911316, "step": 140000}
{"episode_reward": 930.2960468299536, "episode": 141.0, "batch_reward": 0.8887905890345573, "critic_loss": 0.7251594101786614, "actor_loss": -92.21453392028809, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.24260425567627, "step": 141000}
{"episode_reward": 957.6923623231454, "episode": 142.0, "batch_reward": 0.8871512950062752, "critic_loss": 0.7069217355549335, "actor_loss": -92.36950221252441, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.2689368724823, "step": 142000}
{"episode_reward": 984.34828548332, "episode": 143.0, "batch_reward": 0.8883817639350892, "critic_loss": 0.718963225364685, "actor_loss": -92.33059677124024, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.861771821975708, "step": 143000}
{"episode_reward": 914.7319133037972, "episode": 144.0, "batch_reward": 0.8885610004663468, "critic_loss": 0.7466863676011563, "actor_loss": -92.47914463806153, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.460055589675903, "step": 144000}
{"episode_reward": 903.6317081744365, "episode": 145.0, "batch_reward": 0.8895698367953301, "critic_loss": 0.7318409814834594, "actor_loss": -92.45794839477539, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.70064425468445, "step": 145000}
{"episode_reward": 982.1385984915927, "episode": 146.0, "batch_reward": 0.8894128272533417, "critic_loss": 0.7204865825474263, "actor_loss": -92.59035041809082, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.005536317825317, "step": 146000}
{"episode_reward": 974.0976807161906, "episode": 147.0, "batch_reward": 0.8895680549144744, "critic_loss": 0.7434649118483067, "actor_loss": -92.52141493225098, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.73462176322937, "step": 147000}
{"episode_reward": 958.4253253390722, "episode": 148.0, "batch_reward": 0.8914632964134216, "critic_loss": 0.7010955824255943, "actor_loss": -92.60824461364746, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.865339279174805, "step": 148000}
{"episode_reward": 984.6606880326146, "episode": 149.0, "batch_reward": 0.8916679219007492, "critic_loss": 0.7319109695255757, "actor_loss": -92.62520765686035, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.459574222564697, "step": 149000}
{"episode_reward": 929.0783629597372, "episode": 150.0, "batch_reward": 0.8913373527526856, "critic_loss": 0.7061201299726964, "actor_loss": -92.69336045837403, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
