{"episode_reward": 0.0, "episode": 1.0, "duration": 21.617671966552734, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.8072149753570557, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.48868939372927955, "critic_loss": 1.1993768343869031, "actor_loss": -88.51440734374805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.10174584388733, "step": 3000}
{"episode_reward": 643.9041183428839, "episode": 4.0, "batch_reward": 0.5867547051906585, "critic_loss": 1.7865551407337188, "actor_loss": -92.93978895568847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.74033784866333, "step": 4000}
{"episode_reward": 966.8933579589582, "episode": 5.0, "batch_reward": 0.6723206849098206, "critic_loss": 1.5042440772652625, "actor_loss": -94.55916236877441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.53582215309143, "step": 5000}
{"episode_reward": 966.7130101978269, "episode": 6.0, "batch_reward": 0.7188234028220176, "critic_loss": 1.4253950778245925, "actor_loss": -94.72200086975097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.70964002609253, "step": 6000}
{"episode_reward": 818.1687017362001, "episode": 7.0, "batch_reward": 0.6703860958218575, "critic_loss": 1.8106311206817627, "actor_loss": -95.17381080627442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.772249460220337, "step": 7000}
{"episode_reward": 31.924386011454025, "episode": 8.0, "batch_reward": 0.5908666725456715, "critic_loss": 1.8588522768616675, "actor_loss": -95.5628480682373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23183560371399, "step": 8000}
{"episode_reward": 212.30997924723087, "episode": 9.0, "batch_reward": 0.5423815802931785, "critic_loss": 2.4505334379673003, "actor_loss": -95.19729710388184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.170969247817993, "step": 9000}
{"episode_reward": 30.429999826890644, "episode": 10.0, "batch_reward": 0.5001544850468636, "critic_loss": 3.8877819304466246, "actor_loss": -94.83987727355957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.110862493515015, "step": 10000}
{"episode_reward": 224.07386650663452, "episode": 11.0, "batch_reward": 0.4662198242247105, "critic_loss": 5.024232676506043, "actor_loss": -94.09005924987792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.227842569351196, "step": 11000}
{"episode_reward": 75.87991269988501, "episode": 12.0, "batch_reward": 0.43043237975239756, "critic_loss": 5.258833032369614, "actor_loss": -94.11588612365723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.54733157157898, "step": 12000}
{"episode_reward": 44.251239838447255, "episode": 13.0, "batch_reward": 0.4008974845409393, "critic_loss": 5.012413500070572, "actor_loss": -93.14657194519043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.81886601448059, "step": 13000}
{"episode_reward": 141.1796702729224, "episode": 14.0, "batch_reward": 0.38120130702853205, "critic_loss": 4.4537656843662266, "actor_loss": -91.76981474304199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.386043071746826, "step": 14000}
{"episode_reward": 49.738898956327745, "episode": 15.0, "batch_reward": 0.3608924136310816, "critic_loss": 4.56281179356575, "actor_loss": -88.73808615112304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.055676698684692, "step": 15000}
{"episode_reward": 42.60224934464076, "episode": 16.0, "batch_reward": 0.3385819912552834, "critic_loss": 4.442918970704079, "actor_loss": -87.32928004455566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.316800355911255, "step": 16000}
{"episode_reward": 41.396990710338855, "episode": 17.0, "batch_reward": 0.3224310937523842, "critic_loss": 4.467665561199189, "actor_loss": -86.06741545104981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01614761352539, "step": 17000}
{"episode_reward": 237.62041552870375, "episode": 18.0, "batch_reward": 0.3182773063182831, "critic_loss": 4.438187151908875, "actor_loss": -84.3812416229248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.8377046585083, "step": 18000}
{"episode_reward": 138.09153517240333, "episode": 19.0, "batch_reward": 0.3136537906825542, "critic_loss": 3.925345860362053, "actor_loss": -82.88096160888672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.525700569152832, "step": 19000}
{"episode_reward": 238.26110161532372, "episode": 20.0, "batch_reward": 0.30334472298622134, "critic_loss": 4.010924405217171, "actor_loss": -82.03824551391601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.756083488464355, "step": 20000}
{"episode_reward": 43.28294815731092, "episode": 21.0, "batch_reward": 0.29583075547218324, "critic_loss": 4.321803371667862, "actor_loss": -81.27494909667969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.19662380218506, "step": 21000}
{"episode_reward": 244.16328142998523, "episode": 22.0, "batch_reward": 0.3045896307826042, "critic_loss": 6.047873940229416, "actor_loss": -80.90695228576661, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.661269903182983, "step": 22000}
{"episode_reward": 779.4171300470397, "episode": 23.0, "batch_reward": 0.3240859312415123, "critic_loss": 6.894100083827972, "actor_loss": -80.70166397094727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.392093658447266, "step": 23000}
{"episode_reward": 795.1671293979851, "episode": 24.0, "batch_reward": 0.3447760558575392, "critic_loss": 6.277767282724381, "actor_loss": -80.44810983276368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.997608184814453, "step": 24000}
{"episode_reward": 815.7821332454819, "episode": 25.0, "batch_reward": 0.3666163172721863, "critic_loss": 5.250488969087601, "actor_loss": -80.32115475463867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.57302188873291, "step": 25000}
{"episode_reward": 957.1764547329603, "episode": 26.0, "batch_reward": 0.3891177887022495, "critic_loss": 4.438015153884888, "actor_loss": -81.04497367858886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.78960657119751, "step": 26000}
{"episode_reward": 975.0208178892958, "episode": 27.0, "batch_reward": 0.41394480761885644, "critic_loss": 4.05943159031868, "actor_loss": -82.35599476623536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.419135570526123, "step": 27000}
{"episode_reward": 984.1174398529715, "episode": 28.0, "batch_reward": 0.43167393109202384, "critic_loss": 3.726789839029312, "actor_loss": -83.72805824279786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37381410598755, "step": 28000}
{"episode_reward": 858.8318368287368, "episode": 29.0, "batch_reward": 0.442838841766119, "critic_loss": 3.675885635614395, "actor_loss": -84.81199984741211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.870831727981567, "step": 29000}
{"episode_reward": 722.0739181895917, "episode": 30.0, "batch_reward": 0.4538102927803993, "critic_loss": 3.511063006877899, "actor_loss": -85.72670199584961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.49547266960144, "step": 30000}
{"episode_reward": 811.9139422261759, "episode": 31.0, "batch_reward": 0.46382763162255286, "critic_loss": 3.221570654153824, "actor_loss": -86.38321110534667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.05093312263489, "step": 31000}
{"episode_reward": 799.217663644862, "episode": 32.0, "batch_reward": 0.4789475389122963, "critic_loss": 2.7649645836353303, "actor_loss": -86.66305418395996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.61940908432007, "step": 32000}
{"episode_reward": 914.1261356946312, "episode": 33.0, "batch_reward": 0.49318290954828264, "critic_loss": 2.4507750710248946, "actor_loss": -86.3924135131836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.665711879730225, "step": 33000}
{"episode_reward": 919.749538493439, "episode": 34.0, "batch_reward": 0.5071095088422298, "critic_loss": 2.095498009800911, "actor_loss": -85.76719671630859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.583247423171997, "step": 34000}
{"episode_reward": 982.2883211966578, "episode": 35.0, "batch_reward": 0.5183892518281936, "critic_loss": 1.879474593102932, "actor_loss": -85.46007775878907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.974886417388916, "step": 35000}
{"episode_reward": 923.7260612028797, "episode": 36.0, "batch_reward": 0.5283988900482655, "critic_loss": 1.6767008715867997, "actor_loss": -85.13441818237305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.957929849624634, "step": 36000}
{"episode_reward": 934.4340321377592, "episode": 37.0, "batch_reward": 0.5397332455813885, "critic_loss": 1.600339074075222, "actor_loss": -84.98460815429688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.768646001815796, "step": 37000}
{"episode_reward": 958.2363654476962, "episode": 38.0, "batch_reward": 0.5552088658511639, "critic_loss": 1.481845303595066, "actor_loss": -84.94357447814942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.378933906555176, "step": 38000}
{"episode_reward": 980.9347780005955, "episode": 39.0, "batch_reward": 0.5630666052401065, "critic_loss": 1.4194512804746628, "actor_loss": -85.11167527770996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.797467708587646, "step": 39000}
{"episode_reward": 975.8439114769559, "episode": 40.0, "batch_reward": 0.5771454364657402, "critic_loss": 1.4117027742266655, "actor_loss": -85.36955895996094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.65956711769104, "step": 40000}
{"episode_reward": 972.6499407509475, "episode": 41.0, "batch_reward": 0.5813490433096886, "critic_loss": 1.4370980045199395, "actor_loss": -85.48980149841309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.88916254043579, "step": 41000}
{"episode_reward": 888.6115592624976, "episode": 42.0, "batch_reward": 0.5917351239621639, "critic_loss": 1.3530603377819062, "actor_loss": -85.80347003173829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.385307550430298, "step": 42000}
{"episode_reward": 965.114423210311, "episode": 43.0, "batch_reward": 0.6006458058059215, "critic_loss": 1.3160615939497948, "actor_loss": -86.1479439239502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.02695631980896, "step": 43000}
{"episode_reward": 920.171241441848, "episode": 44.0, "batch_reward": 0.6093131393492222, "critic_loss": 1.2734620313048364, "actor_loss": -86.29973707580567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.339508771896362, "step": 44000}
{"episode_reward": 983.4050717105971, "episode": 45.0, "batch_reward": 0.6141480554938317, "critic_loss": 1.2258317149281501, "actor_loss": -86.52741062927247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.063769102096558, "step": 45000}
{"episode_reward": 941.2987140945032, "episode": 46.0, "batch_reward": 0.6238767821192741, "critic_loss": 1.1735377734899521, "actor_loss": -86.7811265258789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.434858798980713, "step": 46000}
{"episode_reward": 945.0762448983572, "episode": 47.0, "batch_reward": 0.6317859840393066, "critic_loss": 1.0874561356306076, "actor_loss": -86.78000462341309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.759772539138794, "step": 47000}
{"episode_reward": 965.4717730947646, "episode": 48.0, "batch_reward": 0.6339897419214249, "critic_loss": 1.0803092287182807, "actor_loss": -86.73835380554199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37510633468628, "step": 48000}
{"episode_reward": 834.1669568592866, "episode": 49.0, "batch_reward": 0.6419355537891388, "critic_loss": 1.0481063495278358, "actor_loss": -86.90367060852051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.77606987953186, "step": 49000}
{"episode_reward": 913.7752928084166, "episode": 50.0, "batch_reward": 0.6473887276649475, "critic_loss": 1.0173773681819438, "actor_loss": -86.99544438171387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.496179342269897, "step": 50000}
{"episode_reward": 985.6521210738887, "episode": 51.0, "batch_reward": 0.6550292390584945, "critic_loss": 0.9872567917108536, "actor_loss": -86.8978081817627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.291853189468384, "step": 51000}
{"episode_reward": 925.4719123923605, "episode": 52.0, "batch_reward": 0.6572298142313957, "critic_loss": 1.0179805265665054, "actor_loss": -87.25432914733886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23670792579651, "step": 52000}
{"episode_reward": 923.2497409368127, "episode": 53.0, "batch_reward": 0.6657004784941674, "critic_loss": 0.9425264975428581, "actor_loss": -87.40523461914063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.31705951690674, "step": 53000}
{"episode_reward": 936.9344982871565, "episode": 54.0, "batch_reward": 0.6675879950523377, "critic_loss": 0.9816803004741669, "actor_loss": -87.28228768920899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.916969060897827, "step": 54000}
{"episode_reward": 909.7906088777938, "episode": 55.0, "batch_reward": 0.674146468281746, "critic_loss": 0.9670652336478234, "actor_loss": -87.02349502563476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.700196504592896, "step": 55000}
{"episode_reward": 946.9034246643002, "episode": 56.0, "batch_reward": 0.6785377410054206, "critic_loss": 0.9014142407774925, "actor_loss": -87.34021336364746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.877171516418457, "step": 56000}
{"episode_reward": 986.4694611540008, "episode": 57.0, "batch_reward": 0.6857398933172226, "critic_loss": 0.8883525594174861, "actor_loss": -87.49805204772949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.27455711364746, "step": 57000}
{"episode_reward": 955.2535443974368, "episode": 58.0, "batch_reward": 0.6903905875086784, "critic_loss": 0.8994221751987934, "actor_loss": -87.18420631408691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02210259437561, "step": 58000}
{"episode_reward": 964.003128371097, "episode": 59.0, "batch_reward": 0.6916069586873055, "critic_loss": 0.8899228288829326, "actor_loss": -87.28495323181153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3416428565979, "step": 59000}
{"episode_reward": 848.2437160591039, "episode": 60.0, "batch_reward": 0.6956153553128243, "critic_loss": 0.923698407381773, "actor_loss": -87.8164386291504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.989543437957764, "step": 60000}
{"episode_reward": 909.5507613691669, "episode": 61.0, "batch_reward": 0.6986660997271538, "critic_loss": 0.9001987029612064, "actor_loss": -87.31296459960937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.74866843223572, "step": 61000}
{"episode_reward": 888.3756092315831, "episode": 62.0, "batch_reward": 0.7024915764331817, "critic_loss": 0.9338927084207534, "actor_loss": -87.29366291809082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.912694692611694, "step": 62000}
{"episode_reward": 962.052956465824, "episode": 63.0, "batch_reward": 0.7041559590697288, "critic_loss": 0.9840498717427254, "actor_loss": -87.64797853088379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.377509355545044, "step": 63000}
{"episode_reward": 904.4245834748928, "episode": 64.0, "batch_reward": 0.7087823632955551, "critic_loss": 0.8904858592152596, "actor_loss": -87.70170045471191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.937973976135254, "step": 64000}
{"episode_reward": 983.9628707331646, "episode": 65.0, "batch_reward": 0.7135762338638305, "critic_loss": 0.8972634933888912, "actor_loss": -87.86631015014649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.582067489624023, "step": 65000}
{"episode_reward": 962.8780555521998, "episode": 66.0, "batch_reward": 0.7167490718960762, "critic_loss": 0.9003575492203235, "actor_loss": -87.83936183166504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.623979091644287, "step": 66000}
{"episode_reward": 926.9965574937501, "episode": 67.0, "batch_reward": 0.7193968327641487, "critic_loss": 0.8577034139931202, "actor_loss": -88.0958162689209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.76454734802246, "step": 67000}
{"episode_reward": 911.5656616897709, "episode": 68.0, "batch_reward": 0.7223542254567147, "critic_loss": 0.8672707447111606, "actor_loss": -87.6698643951416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.64241862297058, "step": 68000}
{"episode_reward": 949.2254026458737, "episode": 69.0, "batch_reward": 0.726897908270359, "critic_loss": 0.881280380755663, "actor_loss": -88.1206971282959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.486722707748413, "step": 69000}
{"episode_reward": 985.7407307358612, "episode": 70.0, "batch_reward": 0.7296930800080299, "critic_loss": 0.9292581533789634, "actor_loss": -88.23090698242187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.032520294189453, "step": 70000}
{"episode_reward": 904.7383817602154, "episode": 71.0, "batch_reward": 0.7334347403049469, "critic_loss": 0.9217694699466229, "actor_loss": -88.10314785766602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.22466564178467, "step": 71000}
{"episode_reward": 901.38191087835, "episode": 72.0, "batch_reward": 0.73507091152668, "critic_loss": 0.9451717819869518, "actor_loss": -88.38626826477051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.058198928833008, "step": 72000}
{"episode_reward": 971.75153147126, "episode": 73.0, "batch_reward": 0.7369082478880882, "critic_loss": 0.9134000895619392, "actor_loss": -88.51507621765137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07551908493042, "step": 73000}
{"episode_reward": 933.4187423539516, "episode": 74.0, "batch_reward": 0.7426003638505936, "critic_loss": 0.8986400207281112, "actor_loss": -88.79430355834961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.59816598892212, "step": 74000}
{"episode_reward": 948.0313081661684, "episode": 75.0, "batch_reward": 0.7429553814530373, "critic_loss": 0.8812283835709095, "actor_loss": -88.69689309692383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.45504903793335, "step": 75000}
{"episode_reward": 958.174969255532, "episode": 76.0, "batch_reward": 0.7459209187030792, "critic_loss": 0.8978621621131897, "actor_loss": -88.67668852233886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.765437126159668, "step": 76000}
{"episode_reward": 925.9568225806843, "episode": 77.0, "batch_reward": 0.7480587288737297, "critic_loss": 0.875426236629486, "actor_loss": -88.86088002014161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.340317487716675, "step": 77000}
{"episode_reward": 966.7969480353134, "episode": 78.0, "batch_reward": 0.7517954438328743, "critic_loss": 0.8473484950363636, "actor_loss": -89.14454696655274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.030598163604736, "step": 78000}
{"episode_reward": 954.0702657837345, "episode": 79.0, "batch_reward": 0.7553324666619301, "critic_loss": 0.8313346512019634, "actor_loss": -88.9181884765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.426681518554688, "step": 79000}
{"episode_reward": 967.8251191743606, "episode": 80.0, "batch_reward": 0.7585448192954063, "critic_loss": 0.8247168421149254, "actor_loss": -89.00354655456543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.082791805267334, "step": 80000}
{"episode_reward": 978.9949806489956, "episode": 81.0, "batch_reward": 0.7616857336759567, "critic_loss": 0.7990802402794361, "actor_loss": -89.38379254150391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.17986798286438, "step": 81000}
{"episode_reward": 931.5743403905077, "episode": 82.0, "batch_reward": 0.763420620083809, "critic_loss": 0.8115821648836136, "actor_loss": -89.49030299377442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.194032669067383, "step": 82000}
{"episode_reward": 907.7071992039681, "episode": 83.0, "batch_reward": 0.7638594179153443, "critic_loss": 0.8222341924011707, "actor_loss": -89.27794561767578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.812705039978027, "step": 83000}
{"episode_reward": 883.6255079839719, "episode": 84.0, "batch_reward": 0.7664134640097618, "critic_loss": 0.8418544611036778, "actor_loss": -89.43381680297851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.38762664794922, "step": 84000}
{"episode_reward": 986.1839068372158, "episode": 85.0, "batch_reward": 0.7666454223394394, "critic_loss": 0.7932844085991383, "actor_loss": -89.41407568359375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.636560678482056, "step": 85000}
{"episode_reward": 954.042468518031, "episode": 86.0, "batch_reward": 0.7703435553908348, "critic_loss": 0.8024697692990304, "actor_loss": -89.21801498413086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.726317167282104, "step": 86000}
{"episode_reward": 947.2461485204964, "episode": 87.0, "batch_reward": 0.7714558987617492, "critic_loss": 0.7653275528848171, "actor_loss": -89.30402978515625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.473965883255005, "step": 87000}
{"episode_reward": 950.5520101486924, "episode": 88.0, "batch_reward": 0.7739095027446747, "critic_loss": 0.7763963170349598, "actor_loss": -89.20546391296386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.630556106567383, "step": 88000}
{"episode_reward": 922.7922641269693, "episode": 89.0, "batch_reward": 0.773703949213028, "critic_loss": 0.7993205029666424, "actor_loss": -89.31035708618164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.829785585403442, "step": 89000}
{"episode_reward": 911.66316528003, "episode": 90.0, "batch_reward": 0.778216335117817, "critic_loss": 0.7526121943295002, "actor_loss": -89.72111268615723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.67792582511902, "step": 90000}
{"episode_reward": 951.1156366317714, "episode": 91.0, "batch_reward": 0.779247009575367, "critic_loss": 0.7642934803366661, "actor_loss": -89.40459170532226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.538116455078125, "step": 91000}
{"episode_reward": 947.6133079446089, "episode": 92.0, "batch_reward": 0.7832732350826264, "critic_loss": 0.7738862943351269, "actor_loss": -89.51980424499511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.683939218521118, "step": 92000}
{"episode_reward": 963.631592756497, "episode": 93.0, "batch_reward": 0.7828459495306015, "critic_loss": 0.8040587579011917, "actor_loss": -89.42451951599121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.49276089668274, "step": 93000}
{"episode_reward": 981.4633940323224, "episode": 94.0, "batch_reward": 0.7839446170330048, "critic_loss": 0.7891829687058926, "actor_loss": -89.49178269958496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.363007068634033, "step": 94000}
{"episode_reward": 898.8253712797489, "episode": 95.0, "batch_reward": 0.7868714147806167, "critic_loss": 0.8070459102988243, "actor_loss": -89.7982335357666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.75169038772583, "step": 95000}
{"episode_reward": 959.414203421561, "episode": 96.0, "batch_reward": 0.7883383743166924, "critic_loss": 0.8009976364970207, "actor_loss": -89.81385279846191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.55339765548706, "step": 96000}
{"episode_reward": 959.5575585056672, "episode": 97.0, "batch_reward": 0.7883102206587791, "critic_loss": 0.8251950119733811, "actor_loss": -89.84209246826173, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.777270078659058, "step": 97000}
{"episode_reward": 925.3112476905236, "episode": 98.0, "batch_reward": 0.7905234068632125, "critic_loss": 0.8342921456396579, "actor_loss": -89.94258207702637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.285670042037964, "step": 98000}
{"episode_reward": 920.5583100946137, "episode": 99.0, "batch_reward": 0.792161818921566, "critic_loss": 0.8826735064983368, "actor_loss": -90.06186451721192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.761304140090942, "step": 99000}
{"episode_reward": 868.8330876828968, "episode": 100.0, "batch_reward": 0.7956345983743668, "critic_loss": 0.8297380558848381, "actor_loss": -90.14001416015626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.674479246139526, "step": 100000}
{"episode_reward": 930.6780927417709, "episode": 101.0, "batch_reward": 0.7949975301027298, "critic_loss": 0.8119514848291874, "actor_loss": -90.29934803771972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.280163288116455, "step": 101000}
{"episode_reward": 970.1982214619868, "episode": 102.0, "batch_reward": 0.7946388502120971, "critic_loss": 0.8197195142507553, "actor_loss": -90.2289728088379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.682912588119507, "step": 102000}
{"episode_reward": 969.6380002908957, "episode": 103.0, "batch_reward": 0.7967335058450699, "critic_loss": 0.8195682368278503, "actor_loss": -90.32113038635254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.2139630317688, "step": 103000}
{"episode_reward": 959.6444897204951, "episode": 104.0, "batch_reward": 0.8007643548846245, "critic_loss": 0.83333121073246, "actor_loss": -90.44102848815918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.26322913169861, "step": 104000}
{"episode_reward": 948.8260358475753, "episode": 105.0, "batch_reward": 0.8023690072894096, "critic_loss": 0.8296799582540989, "actor_loss": -90.45003227233887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.069993495941162, "step": 105000}
{"episode_reward": 928.1757729835575, "episode": 106.0, "batch_reward": 0.8012931925058365, "critic_loss": 0.8504218291044235, "actor_loss": -90.20934460449219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108331203460693, "step": 106000}
{"episode_reward": 868.9497021073556, "episode": 107.0, "batch_reward": 0.8024381220936775, "critic_loss": 0.8387638700604438, "actor_loss": -90.35031295776368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.027130842208862, "step": 107000}
{"episode_reward": 948.4391332045507, "episode": 108.0, "batch_reward": 0.804887103497982, "critic_loss": 0.8290327939689159, "actor_loss": -90.65979968261719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.618554830551147, "step": 108000}
{"episode_reward": 942.2116568912121, "episode": 109.0, "batch_reward": 0.8053135504722595, "critic_loss": 0.8297000078856945, "actor_loss": -90.73748538208008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.425310373306274, "step": 109000}
{"episode_reward": 980.2296405208742, "episode": 110.0, "batch_reward": 0.8072889734506608, "critic_loss": 0.8322309499979019, "actor_loss": -90.94536614990234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.975884199142456, "step": 110000}
{"episode_reward": 927.6184738434425, "episode": 111.0, "batch_reward": 0.80897761541605, "critic_loss": 0.8574223189353943, "actor_loss": -91.08319326782227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.1196494102478, "step": 111000}
{"episode_reward": 923.0795487197836, "episode": 112.0, "batch_reward": 0.8100429711937904, "critic_loss": 0.8414454635381698, "actor_loss": -90.99067532348633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95642924308777, "step": 112000}
{"episode_reward": 926.3680024845365, "episode": 113.0, "batch_reward": 0.8114457851052285, "critic_loss": 0.8082673316001892, "actor_loss": -90.87015798950195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15789794921875, "step": 113000}
{"episode_reward": 960.6845664918472, "episode": 114.0, "batch_reward": 0.8114295138716697, "critic_loss": 0.8237336564660073, "actor_loss": -91.08403172302246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.301290035247803, "step": 114000}
{"episode_reward": 971.235822272956, "episode": 115.0, "batch_reward": 0.8141742191314697, "critic_loss": 0.7724750832915306, "actor_loss": -91.03503327941894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.117894887924194, "step": 115000}
{"episode_reward": 919.9728719620471, "episode": 116.0, "batch_reward": 0.8138572723269463, "critic_loss": 0.8151078263819218, "actor_loss": -91.19970338439941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07838273048401, "step": 116000}
{"episode_reward": 951.8122498837863, "episode": 117.0, "batch_reward": 0.8150960692763328, "critic_loss": 0.8163452907502651, "actor_loss": -91.07007984924316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10569143295288, "step": 117000}
{"episode_reward": 822.2017848468934, "episode": 118.0, "batch_reward": 0.814800430893898, "critic_loss": 0.8098490016758442, "actor_loss": -91.17691021728515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.57767415046692, "step": 118000}
{"episode_reward": 964.8859509169023, "episode": 119.0, "batch_reward": 0.8171260130405426, "critic_loss": 0.8008367920219899, "actor_loss": -91.26528088378906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.683531284332275, "step": 119000}
{"episode_reward": 948.0824505651291, "episode": 120.0, "batch_reward": 0.816408917427063, "critic_loss": 0.8238031165897847, "actor_loss": -91.02222068786621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.576694011688232, "step": 120000}
{"episode_reward": 924.2485478283178, "episode": 121.0, "batch_reward": 0.819271637737751, "critic_loss": 0.7762484923005104, "actor_loss": -91.20583560180664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.42519474029541, "step": 121000}
{"episode_reward": 984.577967614649, "episode": 122.0, "batch_reward": 0.8200495291352272, "critic_loss": 0.8053947550058365, "actor_loss": -91.40915484619141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.672334671020508, "step": 122000}
{"episode_reward": 935.6976589990556, "episode": 123.0, "batch_reward": 0.8224728746414185, "critic_loss": 0.7655734661519528, "actor_loss": -91.30893444824218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.70233917236328, "step": 123000}
{"episode_reward": 948.2118361191827, "episode": 124.0, "batch_reward": 0.8214645400643349, "critic_loss": 0.7845476615726947, "actor_loss": -91.45103456115723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.418221950531006, "step": 124000}
{"episode_reward": 927.1006603102813, "episode": 125.0, "batch_reward": 0.8236463813185692, "critic_loss": 0.761533773869276, "actor_loss": -91.26643815612793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.93919277191162, "step": 125000}
{"episode_reward": 984.3574813024293, "episode": 126.0, "batch_reward": 0.8245830622315407, "critic_loss": 0.7824641099572182, "actor_loss": -91.51306188964844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.525212287902832, "step": 126000}
{"episode_reward": 988.0367013009391, "episode": 127.0, "batch_reward": 0.8247000299096108, "critic_loss": 0.8605169222205877, "actor_loss": -91.49844253540039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.550614595413208, "step": 127000}
{"episode_reward": 884.3081817398504, "episode": 128.0, "batch_reward": 0.8253655717968941, "critic_loss": 0.7603118973076344, "actor_loss": -91.49547966003418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.725191116333008, "step": 128000}
{"episode_reward": 968.492449609278, "episode": 129.0, "batch_reward": 0.8279746211171151, "critic_loss": 0.7820095665454865, "actor_loss": -91.61308639526368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.93650245666504, "step": 129000}
{"episode_reward": 984.0922783252736, "episode": 130.0, "batch_reward": 0.8305268198847771, "critic_loss": 0.7689503594040871, "actor_loss": -91.74774649047852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.300252676010132, "step": 130000}
{"episode_reward": 977.7224893549156, "episode": 131.0, "batch_reward": 0.8301795220971108, "critic_loss": 0.8580316490978003, "actor_loss": -91.65986535644531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.894052505493164, "step": 131000}
{"episode_reward": 960.5758105001137, "episode": 132.0, "batch_reward": 0.8311800832748413, "critic_loss": 0.7935991787910461, "actor_loss": -91.68602252197266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.746706247329712, "step": 132000}
{"episode_reward": 972.3182967266858, "episode": 133.0, "batch_reward": 0.82991724973917, "critic_loss": 0.8430684224963189, "actor_loss": -91.72571200561524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.417359352111816, "step": 133000}
{"episode_reward": 919.508876039867, "episode": 134.0, "batch_reward": 0.8310196561813354, "critic_loss": 0.8134052825272083, "actor_loss": -91.78948042297364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.322112798690796, "step": 134000}
{"episode_reward": 965.878837181949, "episode": 135.0, "batch_reward": 0.8340037198066711, "critic_loss": 0.7793500407040119, "actor_loss": -91.71353169250489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.316450357437134, "step": 135000}
{"episode_reward": 992.3874481024303, "episode": 136.0, "batch_reward": 0.8353761971592903, "critic_loss": 0.7862626028358937, "actor_loss": -91.82312861633301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.695401430130005, "step": 136000}
{"episode_reward": 988.045010570879, "episode": 137.0, "batch_reward": 0.8351407681107521, "critic_loss": 0.7743951463997364, "actor_loss": -91.77593273925781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.55991816520691, "step": 137000}
{"episode_reward": 975.0153234259973, "episode": 138.0, "batch_reward": 0.8377453855872155, "critic_loss": 0.829018912166357, "actor_loss": -91.7094351196289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.91504454612732, "step": 138000}
{"episode_reward": 930.2050154208706, "episode": 139.0, "batch_reward": 0.8377112894654274, "critic_loss": 0.800921839505434, "actor_loss": -91.71189663696289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.479896306991577, "step": 139000}
{"episode_reward": 967.0601531013848, "episode": 140.0, "batch_reward": 0.8370832875370979, "critic_loss": 0.8419190472662449, "actor_loss": -91.64943556213379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.901771545410156, "step": 140000}
{"episode_reward": 920.3215476459173, "episode": 141.0, "batch_reward": 0.8391990600824356, "critic_loss": 0.8633823159635067, "actor_loss": -91.72748637390137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.28793525695801, "step": 141000}
{"episode_reward": 955.1033813684644, "episode": 142.0, "batch_reward": 0.8394753547310829, "critic_loss": 0.8625619469732047, "actor_loss": -91.95052764892579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04940128326416, "step": 142000}
{"episode_reward": 990.0125413476163, "episode": 143.0, "batch_reward": 0.8410253986716271, "critic_loss": 0.8369133878946304, "actor_loss": -91.91264588928223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.715503454208374, "step": 143000}
{"episode_reward": 949.3305360550335, "episode": 144.0, "batch_reward": 0.8408257339000702, "critic_loss": 0.8454069277942181, "actor_loss": -91.9294030456543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.633827209472656, "step": 144000}
{"episode_reward": 957.0826614198988, "episode": 145.0, "batch_reward": 0.8436321923732758, "critic_loss": 0.8204224215447903, "actor_loss": -91.94181861877442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.73808217048645, "step": 145000}
{"episode_reward": 985.4531450101998, "episode": 146.0, "batch_reward": 0.8425077288746834, "critic_loss": 0.8395000336170196, "actor_loss": -92.08983122253417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.486337661743164, "step": 146000}
{"episode_reward": 953.915976750874, "episode": 147.0, "batch_reward": 0.8426957145929337, "critic_loss": 0.808273684039712, "actor_loss": -92.00642633056641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981029510498047, "step": 147000}
{"episode_reward": 952.0528546954228, "episode": 148.0, "batch_reward": 0.8455127212405205, "critic_loss": 0.8221450199782848, "actor_loss": -92.20705311584473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.685556411743164, "step": 148000}
{"episode_reward": 988.1552521650829, "episode": 149.0, "batch_reward": 0.8461245058774948, "critic_loss": 0.8514567967355251, "actor_loss": -92.23623765563966, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.649230480194092, "step": 149000}
{"episode_reward": 909.3846158265627, "episode": 150.0, "batch_reward": 0.8465164377093315, "critic_loss": 0.8353140886127949, "actor_loss": -92.32874844360352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
