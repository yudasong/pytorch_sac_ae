{"episode_reward": 0.0, "episode": 1.0, "duration": 20.490126371383667, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.7816431522369385, "step": 2000}
{"episode_reward": 981.6628711771527, "episode": 3.0, "batch_reward": 0.5449063431405751, "critic_loss": 0.19986639471203535, "actor_loss": -87.80258984086798, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.995885610580444, "step": 3000}
{"episode_reward": 937.5188921907479, "episode": 4.0, "batch_reward": 0.6919346876144409, "critic_loss": 0.28734847808629277, "actor_loss": -92.43983586120605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.896324396133423, "step": 4000}
{"episode_reward": 939.0172341309353, "episode": 5.0, "batch_reward": 0.7545798378586769, "critic_loss": 0.3054907076656818, "actor_loss": -94.2038974609375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.927619695663452, "step": 5000}
{"episode_reward": 981.7128321758481, "episode": 6.0, "batch_reward": 0.7906025320291519, "critic_loss": 0.3199029482975602, "actor_loss": -94.47719128417968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91103744506836, "step": 6000}
{"episode_reward": 952.3501938377093, "episode": 7.0, "batch_reward": 0.8193779708147049, "critic_loss": 0.38261464034020903, "actor_loss": -94.49183837890625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.87797474861145, "step": 7000}
{"episode_reward": 980.041938919764, "episode": 8.0, "batch_reward": 0.8391528329253197, "critic_loss": 0.3318708590492606, "actor_loss": -94.97602268981933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.86593508720398, "step": 8000}
{"episode_reward": 954.5110255089829, "episode": 9.0, "batch_reward": 0.8502231435775757, "critic_loss": 0.27550087501108644, "actor_loss": -95.13034727478028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89721918106079, "step": 9000}
{"episode_reward": 944.246239190207, "episode": 10.0, "batch_reward": 0.8571691376566887, "critic_loss": 0.2858504571914673, "actor_loss": -95.16248458862304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.883575439453125, "step": 10000}
{"episode_reward": 902.1230530953919, "episode": 11.0, "batch_reward": 0.8666151299476623, "critic_loss": 0.23853474525362253, "actor_loss": -95.20527688598632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.122883319854736, "step": 11000}
{"episode_reward": 979.0297500883902, "episode": 12.0, "batch_reward": 0.8712467994689942, "critic_loss": 0.3308876381665468, "actor_loss": -95.23046040344238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.874003648757935, "step": 12000}
{"episode_reward": 931.8883942210625, "episode": 13.0, "batch_reward": 0.8778884161710739, "critic_loss": 0.21917953325062992, "actor_loss": -95.28807965087891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.878767490386963, "step": 13000}
{"episode_reward": 937.1946684257033, "episode": 14.0, "batch_reward": 0.8840832470059394, "critic_loss": 0.23120879115909337, "actor_loss": -95.36163929748535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.874813556671143, "step": 14000}
{"episode_reward": 953.6901181606448, "episode": 15.0, "batch_reward": 0.8902172334194184, "critic_loss": 0.2138620551377535, "actor_loss": -95.43925944519043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.872817993164062, "step": 15000}
{"episode_reward": 978.0755719158562, "episode": 16.0, "batch_reward": 0.8936414299607277, "critic_loss": 0.2351744157373905, "actor_loss": -95.4711538848877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.87711453437805, "step": 16000}
{"episode_reward": 909.5842633148608, "episode": 17.0, "batch_reward": 0.8887693817019463, "critic_loss": 0.30364113007485866, "actor_loss": -95.30492970275878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.876884937286377, "step": 17000}
{"episode_reward": 834.130395653949, "episode": 18.0, "batch_reward": 0.8930287057757378, "critic_loss": 0.28984676486998795, "actor_loss": -95.38094898986816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.889813661575317, "step": 18000}
{"episode_reward": 941.3989423247259, "episode": 19.0, "batch_reward": 0.8951392265558242, "critic_loss": 0.28682350623607633, "actor_loss": -95.39333700561524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.896947860717773, "step": 19000}
{"episode_reward": 963.1684142083539, "episode": 20.0, "batch_reward": 0.8997910925745964, "critic_loss": 0.25983402408659456, "actor_loss": -95.47876992797852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.87332797050476, "step": 20000}
{"episode_reward": 973.9698210796448, "episode": 21.0, "batch_reward": 0.9012375953793526, "critic_loss": 0.28876721888780593, "actor_loss": -95.49366117858887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.107826948165894, "step": 21000}
{"episode_reward": 925.4669878463908, "episode": 22.0, "batch_reward": 0.9034257348775864, "critic_loss": 0.2971638850644231, "actor_loss": -95.40874200439453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.870503902435303, "step": 22000}
{"episode_reward": 944.2867015788338, "episode": 23.0, "batch_reward": 0.9038464065790176, "critic_loss": 0.288526679225266, "actor_loss": -95.39144236755371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.880170583724976, "step": 23000}
{"episode_reward": 904.918220585192, "episode": 24.0, "batch_reward": 0.9051528886556626, "critic_loss": 0.2573233576640487, "actor_loss": -95.44328160095215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8705632686615, "step": 24000}
{"episode_reward": 979.569141592008, "episode": 25.0, "batch_reward": 0.9060445055961609, "critic_loss": 0.2832631654068828, "actor_loss": -95.41332543945313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.875617504119873, "step": 25000}
{"episode_reward": 918.2867505678, "episode": 26.0, "batch_reward": 0.9085396083593369, "critic_loss": 0.2613686230108142, "actor_loss": -95.43546502685547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.87242603302002, "step": 26000}
{"episode_reward": 979.4632463159847, "episode": 27.0, "batch_reward": 0.9108434454798698, "critic_loss": 0.2796722603514791, "actor_loss": -95.54234202575684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8790442943573, "step": 27000}
{"episode_reward": 940.1436294215474, "episode": 28.0, "batch_reward": 0.9135454636216164, "critic_loss": 0.2491640355885029, "actor_loss": -95.60955247497559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.878880262374878, "step": 28000}
{"episode_reward": 962.694015121232, "episode": 29.0, "batch_reward": 0.9116969898939132, "critic_loss": 0.2704458986669779, "actor_loss": -95.4906301574707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.87891674041748, "step": 29000}
{"episode_reward": 869.9657979345038, "episode": 30.0, "batch_reward": 0.9128280062079429, "critic_loss": 0.28208823113888504, "actor_loss": -95.51755078125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.900068283081055, "step": 30000}
{"episode_reward": 933.7055440052359, "episode": 31.0, "batch_reward": 0.9131127743124962, "critic_loss": 0.29081769575178623, "actor_loss": -95.58608695983887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.22443199157715, "step": 31000}
{"episode_reward": 934.660962371974, "episode": 32.0, "batch_reward": 0.9136953353285789, "critic_loss": 0.30009274230897426, "actor_loss": -95.54706408691406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89265727996826, "step": 32000}
{"episode_reward": 910.7390527741218, "episode": 33.0, "batch_reward": 0.912722287118435, "critic_loss": 0.3266473046168685, "actor_loss": -95.51563859558105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.87424874305725, "step": 33000}
{"episode_reward": 921.1478352689682, "episode": 34.0, "batch_reward": 0.9138859678506851, "critic_loss": 0.25579063076525926, "actor_loss": -95.57739784240722, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.882227182388306, "step": 34000}
{"episode_reward": 971.8071980442776, "episode": 35.0, "batch_reward": 0.9152221773862839, "critic_loss": 0.29069270811975, "actor_loss": -95.64805490112305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.878687143325806, "step": 35000}
{"episode_reward": 950.1094583893461, "episode": 36.0, "batch_reward": 0.9159448819160462, "critic_loss": 0.23542107599973677, "actor_loss": -95.6438560180664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88998055458069, "step": 36000}
{"episode_reward": 967.5524931726492, "episode": 37.0, "batch_reward": 0.9162745785117149, "critic_loss": 0.25379638881236316, "actor_loss": -95.63669551086426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.878381729125977, "step": 37000}
{"episode_reward": 917.5176523893186, "episode": 38.0, "batch_reward": 0.9183927420973778, "critic_loss": 0.26373218014091254, "actor_loss": -95.67702090454101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.870267868041992, "step": 38000}
{"episode_reward": 983.2181680654287, "episode": 39.0, "batch_reward": 0.9184342442750931, "critic_loss": 0.302287667170167, "actor_loss": -95.70076480102539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.873363733291626, "step": 39000}
{"episode_reward": 911.8803650131457, "episode": 40.0, "batch_reward": 0.9179822013974189, "critic_loss": 0.2990559595376253, "actor_loss": -95.66900657653808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.87416982650757, "step": 40000}
{"episode_reward": 936.9911325038818, "episode": 41.0, "batch_reward": 0.9207428659796715, "critic_loss": 0.3024807931482792, "actor_loss": -95.75026921081543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.18723130226135, "step": 41000}
{"episode_reward": 949.0374016816157, "episode": 42.0, "batch_reward": 0.9219510062336922, "critic_loss": 0.29707358723878863, "actor_loss": -95.70364332580566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8854079246521, "step": 42000}
{"episode_reward": 980.4903407624562, "episode": 43.0, "batch_reward": 0.9214984200000763, "critic_loss": 0.34847173012793065, "actor_loss": -95.69147180175781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.87320590019226, "step": 43000}
{"episode_reward": 919.6776534016434, "episode": 44.0, "batch_reward": 0.9219920910000801, "critic_loss": 0.3107307829782367, "actor_loss": -95.71606909179687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.883418321609497, "step": 44000}
{"episode_reward": 981.5633294403228, "episode": 45.0, "batch_reward": 0.9223082669973374, "critic_loss": 0.2853048211038113, "actor_loss": -95.76323176574707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88569164276123, "step": 45000}
{"episode_reward": 931.1918333635443, "episode": 46.0, "batch_reward": 0.9233441025614738, "critic_loss": 0.32349183202534915, "actor_loss": -95.7666062927246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.87468647956848, "step": 46000}
{"episode_reward": 972.4915863870054, "episode": 47.0, "batch_reward": 0.9255092262625694, "critic_loss": 0.2664165669232607, "actor_loss": -95.83777226257324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.894584894180298, "step": 47000}
{"episode_reward": 971.826012781753, "episode": 48.0, "batch_reward": 0.9258420274853706, "critic_loss": 0.25170940651372076, "actor_loss": -95.82023030090332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.886999368667603, "step": 48000}
{"episode_reward": 954.2226233014267, "episode": 49.0, "batch_reward": 0.9266120316982269, "critic_loss": 0.29840285242721437, "actor_loss": -95.90051515197754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.879040956497192, "step": 49000}
{"episode_reward": 933.8754045395317, "episode": 50.0, "batch_reward": 0.9268869543671608, "critic_loss": 0.26315146412327883, "actor_loss": -95.88917427062988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.889637231826782, "step": 50000}
{"episode_reward": 983.2803701555058, "episode": 51.0, "batch_reward": 0.9281819725632667, "critic_loss": 0.2566562746949494, "actor_loss": -95.90818406677246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.161648988723755, "step": 51000}
{"episode_reward": 985.8682133214696, "episode": 52.0, "batch_reward": 0.9285638610720635, "critic_loss": 0.25311993756890294, "actor_loss": -95.91527410888672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88502287864685, "step": 52000}
{"episode_reward": 968.7234625796746, "episode": 53.0, "batch_reward": 0.9291002981066704, "critic_loss": 0.33002006413042545, "actor_loss": -95.91621113586426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.880202770233154, "step": 53000}
{"episode_reward": 922.0163016966434, "episode": 54.0, "batch_reward": 0.9280989626646042, "critic_loss": 0.3139339230060577, "actor_loss": -95.90257905578613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.880396842956543, "step": 54000}
{"episode_reward": 923.1616257800745, "episode": 55.0, "batch_reward": 0.9295838769674302, "critic_loss": 0.27643003203719857, "actor_loss": -95.99353514099121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.878591537475586, "step": 55000}
{"episode_reward": 984.3102084602532, "episode": 56.0, "batch_reward": 0.9305971958041191, "critic_loss": 0.2976198848038912, "actor_loss": -96.0018777923584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.914053678512573, "step": 56000}
{"episode_reward": 958.7010810468685, "episode": 57.0, "batch_reward": 0.9304894924759864, "critic_loss": 0.29031832225620746, "actor_loss": -95.93864329528809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91719388961792, "step": 57000}
{"episode_reward": 962.3268930207845, "episode": 58.0, "batch_reward": 0.9319231323003769, "critic_loss": 0.27071288402378557, "actor_loss": -96.00226634216308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.907108783721924, "step": 58000}
{"episode_reward": 979.606871711884, "episode": 59.0, "batch_reward": 0.9328418418765068, "critic_loss": 0.2921503397449851, "actor_loss": -96.09832414245605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.890637397766113, "step": 59000}
{"episode_reward": 963.4207703530083, "episode": 60.0, "batch_reward": 0.9324924679398536, "critic_loss": 0.3209187475964427, "actor_loss": -96.11809523010254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89810085296631, "step": 60000}
{"episode_reward": 946.1668546353029, "episode": 61.0, "batch_reward": 0.9326451434493065, "critic_loss": 0.2981915567442775, "actor_loss": -96.05371859741211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.15946102142334, "step": 61000}
{"episode_reward": 957.1831596344118, "episode": 62.0, "batch_reward": 0.9324383881092072, "critic_loss": 0.33801464608311654, "actor_loss": -96.07500123596192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.888076782226562, "step": 62000}
{"episode_reward": 970.2475611491404, "episode": 63.0, "batch_reward": 0.9322704362869263, "critic_loss": 0.33468549166619777, "actor_loss": -96.04928225708008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88075876235962, "step": 63000}
{"episode_reward": 940.6630874204365, "episode": 64.0, "batch_reward": 0.9337472639083862, "critic_loss": 0.2961394702196121, "actor_loss": -96.12598881530762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.888284921646118, "step": 64000}
{"episode_reward": 988.3075272991182, "episode": 65.0, "batch_reward": 0.9352898067831993, "critic_loss": 0.2767762451134622, "actor_loss": -96.18176274108886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.888379335403442, "step": 65000}
{"episode_reward": 978.6362571920529, "episode": 66.0, "batch_reward": 0.9350879570841789, "critic_loss": 0.28464194605499504, "actor_loss": -96.16693161010743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.886149406433105, "step": 66000}
{"episode_reward": 969.0672998698997, "episode": 67.0, "batch_reward": 0.9347260550260544, "critic_loss": 0.3197414731010795, "actor_loss": -96.17726307678222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.884369611740112, "step": 67000}
{"episode_reward": 919.2039280374121, "episode": 68.0, "batch_reward": 0.9354123025536537, "critic_loss": 0.2819768010303378, "actor_loss": -96.17797996520996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.889112949371338, "step": 68000}
{"episode_reward": 968.825810853494, "episode": 69.0, "batch_reward": 0.936177719950676, "critic_loss": 0.264077305611223, "actor_loss": -96.25133149719238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88865566253662, "step": 69000}
{"episode_reward": 982.8417874793913, "episode": 70.0, "batch_reward": 0.9371143093705178, "critic_loss": 0.2883468008749187, "actor_loss": -96.24426022338868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.905678033828735, "step": 70000}
{"episode_reward": 938.1403830701574, "episode": 71.0, "batch_reward": 0.9367692717313767, "critic_loss": 0.30655273266509175, "actor_loss": -96.25597085571289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.21718907356262, "step": 71000}
{"episode_reward": 963.4398307147965, "episode": 72.0, "batch_reward": 0.9373035922050476, "critic_loss": 0.2554002334177494, "actor_loss": -96.27141816711426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.891029119491577, "step": 72000}
{"episode_reward": 964.1713792274147, "episode": 73.0, "batch_reward": 0.9370615469813347, "critic_loss": 0.2879357315972447, "actor_loss": -96.29791168212891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.885554790496826, "step": 73000}
{"episode_reward": 955.414868089468, "episode": 74.0, "batch_reward": 0.9387956819534302, "critic_loss": 0.2679807734228671, "actor_loss": -96.35025093078613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.880812406539917, "step": 74000}
{"episode_reward": 938.6368224187606, "episode": 75.0, "batch_reward": 0.9377276142835617, "critic_loss": 0.27456570479273795, "actor_loss": -96.28436061096191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.892130374908447, "step": 75000}
{"episode_reward": 979.9838939300497, "episode": 76.0, "batch_reward": 0.9383873916864395, "critic_loss": 0.3030156596451998, "actor_loss": -96.30086422729492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.883116960525513, "step": 76000}
{"episode_reward": 926.6675709831853, "episode": 77.0, "batch_reward": 0.9375767987370491, "critic_loss": 0.2945407358184457, "actor_loss": -96.27217964172364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.894662380218506, "step": 77000}
{"episode_reward": 980.713237709435, "episode": 78.0, "batch_reward": 0.9387235684394837, "critic_loss": 0.3000322683826089, "actor_loss": -96.29405198669434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.887998580932617, "step": 78000}
{"episode_reward": 955.9621498169316, "episode": 79.0, "batch_reward": 0.9384495038986206, "critic_loss": 0.2720291736274958, "actor_loss": -96.30867248535156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.883325576782227, "step": 79000}
{"episode_reward": 965.1463706223327, "episode": 80.0, "batch_reward": 0.9391376115083695, "critic_loss": 0.2868332808613777, "actor_loss": -96.31551158142089, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.895637273788452, "step": 80000}
{"episode_reward": 965.2301897864562, "episode": 81.0, "batch_reward": 0.9387723551392555, "critic_loss": 0.330627406463027, "actor_loss": -96.31101353454589, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.16907525062561, "step": 81000}
{"episode_reward": 925.9511807895941, "episode": 82.0, "batch_reward": 0.9396110978722573, "critic_loss": 0.2909443282559514, "actor_loss": -96.29305638122558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.90814447402954, "step": 82000}
{"episode_reward": 963.5152877723314, "episode": 83.0, "batch_reward": 0.9385027444958687, "critic_loss": 0.3372749255746603, "actor_loss": -96.29565432739258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.918115615844727, "step": 83000}
{"episode_reward": 863.8812175718017, "episode": 84.0, "batch_reward": 0.9396520404219627, "critic_loss": 0.3068845967575908, "actor_loss": -96.35349362182617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.910117864608765, "step": 84000}
{"episode_reward": 982.8350841002422, "episode": 85.0, "batch_reward": 0.9385818229913712, "critic_loss": 0.307155891276896, "actor_loss": -96.28696647644043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.900311946868896, "step": 85000}
{"episode_reward": 915.5137683833027, "episode": 86.0, "batch_reward": 0.9387458767294884, "critic_loss": 0.31474781142175196, "actor_loss": -96.23393774414062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89310121536255, "step": 86000}
{"episode_reward": 949.6393313654571, "episode": 87.0, "batch_reward": 0.9386004548072815, "critic_loss": 0.30794532361999155, "actor_loss": -96.26159114074707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.877954959869385, "step": 87000}
{"episode_reward": 899.2118527593852, "episode": 88.0, "batch_reward": 0.9382025275826454, "critic_loss": 0.36048665855824946, "actor_loss": -96.20210566711425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.893778324127197, "step": 88000}
{"episode_reward": 825.2141078847379, "episode": 89.0, "batch_reward": 0.9368726590871811, "critic_loss": 0.39569277615845205, "actor_loss": -96.17820596313477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.888643503189087, "step": 89000}
{"episode_reward": 952.4180993806569, "episode": 90.0, "batch_reward": 0.9370751490592957, "critic_loss": 0.3680564563944936, "actor_loss": -96.21426110839843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88594937324524, "step": 90000}
{"episode_reward": 946.6706951638862, "episode": 91.0, "batch_reward": 0.9377007229328156, "critic_loss": 0.43563487999886275, "actor_loss": -96.12568542480469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.1440806388855, "step": 91000}
{"episode_reward": 950.9748308747221, "episode": 92.0, "batch_reward": 0.9386759485602378, "critic_loss": 0.40222695405781267, "actor_loss": -96.20283285522461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.896352767944336, "step": 92000}
{"episode_reward": 965.3995498799102, "episode": 93.0, "batch_reward": 0.9373843575716019, "critic_loss": 0.3892582368850708, "actor_loss": -96.13647589111328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.890453815460205, "step": 93000}
{"episode_reward": 980.7499163013193, "episode": 94.0, "batch_reward": 0.9376817222833633, "critic_loss": 0.40630151162296535, "actor_loss": -96.16354640197754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89148712158203, "step": 94000}
{"episode_reward": 934.8499777427278, "episode": 95.0, "batch_reward": 0.9382015799283981, "critic_loss": 0.4211889719069004, "actor_loss": -96.14095262145996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.47490692138672, "step": 95000}
{"episode_reward": 960.8966976338631, "episode": 96.0, "batch_reward": 0.9388265396952629, "critic_loss": 0.3989736118167639, "actor_loss": -96.18698059082031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.873695373535156, "step": 96000}
{"episode_reward": 950.1768925431679, "episode": 97.0, "batch_reward": 0.9376466307044029, "critic_loss": 0.4388394233807921, "actor_loss": -96.11309762573242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.839024782180786, "step": 97000}
{"episode_reward": 835.7138965286615, "episode": 98.0, "batch_reward": 0.93818609136343, "critic_loss": 0.4049200638011098, "actor_loss": -96.08822640991211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.830730676651, "step": 98000}
{"episode_reward": 933.7411302201152, "episode": 99.0, "batch_reward": 0.9363814022541046, "critic_loss": 0.43278938487172125, "actor_loss": -96.05929264831543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88106417655945, "step": 99000}
{"episode_reward": 947.164007045661, "episode": 100.0, "batch_reward": 0.9381569564938546, "critic_loss": 0.40300167679041626, "actor_loss": -96.12055033874512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.867109537124634, "step": 100000}
{"episode_reward": 892.9223444850251, "episode": 101.0, "batch_reward": 0.9380539831519127, "critic_loss": 0.4288560372814536, "actor_loss": -96.09640576171876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.13420128822327, "step": 101000}
{"episode_reward": 984.3749474162563, "episode": 102.0, "batch_reward": 0.9380270679593086, "critic_loss": 0.41593421637266875, "actor_loss": -96.13313725280761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.881672859191895, "step": 102000}
{"episode_reward": 972.3084550927372, "episode": 103.0, "batch_reward": 0.9375098057985306, "critic_loss": 0.4086840515509248, "actor_loss": -96.07950872802735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.880171060562134, "step": 103000}
{"episode_reward": 956.9909997990072, "episode": 104.0, "batch_reward": 0.9386549828052521, "critic_loss": 0.4213600551113486, "actor_loss": -96.13598669433594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.875107049942017, "step": 104000}
{"episode_reward": 935.8136516614046, "episode": 105.0, "batch_reward": 0.9395799700617791, "critic_loss": 0.42167156191170213, "actor_loss": -96.18791069030762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.878069162368774, "step": 105000}
{"episode_reward": 939.2177480753231, "episode": 106.0, "batch_reward": 0.9391817452907563, "critic_loss": 0.4276179251074791, "actor_loss": -96.16033297729493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.871495723724365, "step": 106000}
{"episode_reward": 922.8847187006103, "episode": 107.0, "batch_reward": 0.9370800470113754, "critic_loss": 0.4254770884439349, "actor_loss": -96.03617346191406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.888832807540894, "step": 107000}
{"episode_reward": 906.1901172881254, "episode": 108.0, "batch_reward": 0.9385247694849967, "critic_loss": 0.41202163527160884, "actor_loss": -96.15999403381348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.886624574661255, "step": 108000}
{"episode_reward": 942.3750008791684, "episode": 109.0, "batch_reward": 0.9379820638298988, "critic_loss": 0.42849258639663457, "actor_loss": -96.13843701171875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.894803285598755, "step": 109000}
{"episode_reward": 968.3570437272912, "episode": 110.0, "batch_reward": 0.9383182110190391, "critic_loss": 0.42727902076393365, "actor_loss": -96.14889234924317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89833927154541, "step": 110000}
{"episode_reward": 922.9179481705936, "episode": 111.0, "batch_reward": 0.937857873737812, "critic_loss": 0.46995191878825426, "actor_loss": -96.15694270324707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.17270374298096, "step": 111000}
{"episode_reward": 953.3564566580816, "episode": 112.0, "batch_reward": 0.9378473610281944, "critic_loss": 0.4872911376953125, "actor_loss": -96.11905902099609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88626503944397, "step": 112000}
{"episode_reward": 945.9596930754143, "episode": 113.0, "batch_reward": 0.9392250242233277, "critic_loss": 0.45896840519085524, "actor_loss": -96.17941983032226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.888209581375122, "step": 113000}
{"episode_reward": 965.8356818467242, "episode": 114.0, "batch_reward": 0.9392738778591156, "critic_loss": 0.40264530972391366, "actor_loss": -96.17185041809083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.87898349761963, "step": 114000}
{"episode_reward": 976.4415564489335, "episode": 115.0, "batch_reward": 0.9396840134859085, "critic_loss": 0.4647200442031026, "actor_loss": -96.15926017761231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.885695934295654, "step": 115000}
{"episode_reward": 921.6775776215061, "episode": 116.0, "batch_reward": 0.9386407890915871, "critic_loss": 0.43226126780360935, "actor_loss": -96.1381603088379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89203119277954, "step": 116000}
{"episode_reward": 960.9206647764154, "episode": 117.0, "batch_reward": 0.9386005721688271, "critic_loss": 0.4478410175293684, "actor_loss": -96.14237826538086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.87514877319336, "step": 117000}
{"episode_reward": 914.022745048694, "episode": 118.0, "batch_reward": 0.9389354428648948, "critic_loss": 0.42776453325897457, "actor_loss": -96.18573431396484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.889382362365723, "step": 118000}
{"episode_reward": 982.1519259986858, "episode": 119.0, "batch_reward": 0.9382028680443764, "critic_loss": 0.5337333645373583, "actor_loss": -96.14061540222168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88286781311035, "step": 119000}
{"episode_reward": 850.6348125628717, "episode": 120.0, "batch_reward": 0.9370027370452881, "critic_loss": 0.5316680734157562, "actor_loss": -96.03839804077148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.881192445755005, "step": 120000}
{"episode_reward": 879.7917429023126, "episode": 121.0, "batch_reward": 0.9383187675476075, "critic_loss": 0.5123457872048021, "actor_loss": -96.10982513427734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.14348077774048, "step": 121000}
{"episode_reward": 972.1797694059535, "episode": 122.0, "batch_reward": 0.9373069847226143, "critic_loss": 0.5289587575420738, "actor_loss": -96.07141889953613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.903130769729614, "step": 122000}
{"episode_reward": 917.0697519734186, "episode": 123.0, "batch_reward": 0.9379914082884788, "critic_loss": 0.5632439584806561, "actor_loss": -96.03810229492187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89921522140503, "step": 123000}
{"episode_reward": 961.0029672417584, "episode": 124.0, "batch_reward": 0.9371652709841728, "critic_loss": 0.551783394433558, "actor_loss": -96.04243180847168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89278769493103, "step": 124000}
{"episode_reward": 955.1117408073126, "episode": 125.0, "batch_reward": 0.9387619027495384, "critic_loss": 0.5200296334698796, "actor_loss": -96.14035072326661, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88682794570923, "step": 125000}
{"episode_reward": 983.0878679853936, "episode": 126.0, "batch_reward": 0.9388895178437233, "critic_loss": 0.5208338845968247, "actor_loss": -96.16807286071777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.883867740631104, "step": 126000}
{"episode_reward": 983.5996955009105, "episode": 127.0, "batch_reward": 0.9386459791660309, "critic_loss": 0.4788683430030942, "actor_loss": -96.11825045776366, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88601541519165, "step": 127000}
{"episode_reward": 932.2149721805907, "episode": 128.0, "batch_reward": 0.938833973288536, "critic_loss": 0.514115536980331, "actor_loss": -96.18477035522461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.884854555130005, "step": 128000}
{"episode_reward": 969.024409615476, "episode": 129.0, "batch_reward": 0.9395016492009163, "critic_loss": 0.5476242152750492, "actor_loss": -96.20404264831544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.882052421569824, "step": 129000}
{"episode_reward": 952.3930891256704, "episode": 130.0, "batch_reward": 0.9392656654715538, "critic_loss": 0.5513311694413423, "actor_loss": -96.2074355621338, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.876375913619995, "step": 130000}
{"episode_reward": 980.3851283990265, "episode": 131.0, "batch_reward": 0.9399047897458076, "critic_loss": 0.5887407907173038, "actor_loss": -96.17325424194335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.1685676574707, "step": 131000}
{"episode_reward": 942.5936203465914, "episode": 132.0, "batch_reward": 0.9401182556152343, "critic_loss": 0.5890407424941659, "actor_loss": -96.19379856872558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.882396459579468, "step": 132000}
{"episode_reward": 981.0590048768534, "episode": 133.0, "batch_reward": 0.9398813391327858, "critic_loss": 0.6723128380775452, "actor_loss": -96.24231214904785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.2022602558136, "step": 133000}
{"episode_reward": 962.3418761595887, "episode": 134.0, "batch_reward": 0.9403138751387596, "critic_loss": 0.6416128623113037, "actor_loss": -96.2265496673584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.86464786529541, "step": 134000}
{"episode_reward": 983.9474478386812, "episode": 135.0, "batch_reward": 0.9419282256364823, "critic_loss": 0.6344838089048862, "actor_loss": -96.25715490722656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.891398429870605, "step": 135000}
{"episode_reward": 984.9532363193981, "episode": 136.0, "batch_reward": 0.9409392322301865, "critic_loss": 0.6137876096367836, "actor_loss": -96.27258528137207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89446473121643, "step": 136000}
{"episode_reward": 984.3673817458233, "episode": 137.0, "batch_reward": 0.9402350803613663, "critic_loss": 0.5727276091128588, "actor_loss": -96.21750372314453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.914753198623657, "step": 137000}
{"episode_reward": 972.3090530556009, "episode": 138.0, "batch_reward": 0.9417159986495972, "critic_loss": 0.6114403886944055, "actor_loss": -96.30296517944336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.884350538253784, "step": 138000}
{"episode_reward": 964.4005786684684, "episode": 139.0, "batch_reward": 0.940831716299057, "critic_loss": 0.6235897764787078, "actor_loss": -96.27878965759277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.886034965515137, "step": 139000}
{"episode_reward": 963.7151014146981, "episode": 140.0, "batch_reward": 0.9416055364608764, "critic_loss": 0.5396991567537188, "actor_loss": -96.29598991394043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8899827003479, "step": 140000}
{"episode_reward": 954.6439708486644, "episode": 141.0, "batch_reward": 0.9417600734829903, "critic_loss": 0.4668654661178589, "actor_loss": -96.292757522583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.20960450172424, "step": 141000}
{"episode_reward": 969.7110532194949, "episode": 142.0, "batch_reward": 0.9422484501004219, "critic_loss": 0.4576002551689744, "actor_loss": -96.3164154663086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.881587505340576, "step": 142000}
{"episode_reward": 986.3251485843366, "episode": 143.0, "batch_reward": 0.9428400671482087, "critic_loss": 0.5437039857804775, "actor_loss": -96.32098240661621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.89143133163452, "step": 143000}
{"episode_reward": 954.3505247406174, "episode": 144.0, "batch_reward": 0.9424039633870125, "critic_loss": 0.4394372285678983, "actor_loss": -96.31286897277832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.889851093292236, "step": 144000}
{"episode_reward": 936.6455067367474, "episode": 145.0, "batch_reward": 0.9425517627000809, "critic_loss": 0.4481088967695832, "actor_loss": -96.33761141967773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.892990589141846, "step": 145000}
{"episode_reward": 977.3410731565585, "episode": 146.0, "batch_reward": 0.9425717315077782, "critic_loss": 0.48123027590662243, "actor_loss": -96.33335469055176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88899064064026, "step": 146000}
{"episode_reward": 974.5291952877427, "episode": 147.0, "batch_reward": 0.9430087244510651, "critic_loss": 0.47342113391309976, "actor_loss": -96.30298927307129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88664174079895, "step": 147000}
{"episode_reward": 953.5419430797723, "episode": 148.0, "batch_reward": 0.943414343893528, "critic_loss": 0.42992462404072285, "actor_loss": -96.33831137084961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.899933099746704, "step": 148000}
{"episode_reward": 964.9683996469402, "episode": 149.0, "batch_reward": 0.9419196147322655, "critic_loss": 0.45821833600103856, "actor_loss": -96.3056929321289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88006043434143, "step": 149000}
{"episode_reward": 903.092719241958, "episode": 150.0, "batch_reward": 0.9418316873311996, "critic_loss": 0.45726270335167646, "actor_loss": -96.30857958984375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
