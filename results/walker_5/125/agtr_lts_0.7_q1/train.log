{"episode_reward": 0.0, "episode": 1.0, "duration": 20.83235239982605, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.9069013595581055, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.502394643574009, "critic_loss": 1.335944159512283, "actor_loss": -86.62431467337912, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.21086931228638, "step": 3000}
{"episode_reward": 846.4456278740256, "episode": 4.0, "batch_reward": 0.639829519033432, "critic_loss": 1.8903523322343827, "actor_loss": -89.53810850524903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.366018295288086, "step": 4000}
{"episode_reward": 940.2754050810767, "episode": 5.0, "batch_reward": 0.7056048684120179, "critic_loss": 1.8326425822377206, "actor_loss": -91.19075427246094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.856393575668335, "step": 5000}
{"episode_reward": 748.4950228811142, "episode": 6.0, "batch_reward": 0.7118465603590012, "critic_loss": 2.0020386172533033, "actor_loss": -91.17974372863769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.530577182769775, "step": 6000}
{"episode_reward": 924.7668300594066, "episode": 7.0, "batch_reward": 0.7347379540205001, "critic_loss": 1.757111274421215, "actor_loss": -91.25121702575683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.400310516357422, "step": 7000}
{"episode_reward": 858.6150961860938, "episode": 8.0, "batch_reward": 0.7622730045318603, "critic_loss": 1.4064639870524407, "actor_loss": -91.70133473205567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.125843048095703, "step": 8000}
{"episode_reward": 941.4094961284317, "episode": 9.0, "batch_reward": 0.7448078098893166, "critic_loss": 1.5719705373644828, "actor_loss": -91.12609555053712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.845714807510376, "step": 9000}
{"episode_reward": 483.48841168126813, "episode": 10.0, "batch_reward": 0.7400754405856133, "critic_loss": 1.462205939054489, "actor_loss": -90.57181658935546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.44812774658203, "step": 10000}
{"episode_reward": 808.6162109678513, "episode": 11.0, "batch_reward": 0.7453820588588714, "critic_loss": 1.3284586715102196, "actor_loss": -90.42940199279785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.33529448509216, "step": 11000}
{"episode_reward": 815.2514158134965, "episode": 12.0, "batch_reward": 0.7551549824476242, "critic_loss": 1.3796819803714753, "actor_loss": -90.04295092773438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.3244948387146, "step": 12000}
{"episode_reward": 857.11991520527, "episode": 13.0, "batch_reward": 0.7608647431135178, "critic_loss": 1.4058239580988885, "actor_loss": -89.84956771850585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.861886978149414, "step": 13000}
{"episode_reward": 833.293989625592, "episode": 14.0, "batch_reward": 0.7764072313308715, "critic_loss": 1.3407096155285836, "actor_loss": -89.67471543884277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.414139986038208, "step": 14000}
{"episode_reward": 966.2186922488029, "episode": 15.0, "batch_reward": 0.7903978801369667, "critic_loss": 1.3330031654834746, "actor_loss": -90.44092608642578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.91509985923767, "step": 15000}
{"episode_reward": 986.7615186358773, "episode": 16.0, "batch_reward": 0.8002166090011597, "critic_loss": 1.503789339363575, "actor_loss": -90.16106860351563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.791800498962402, "step": 16000}
{"episode_reward": 887.9191852496105, "episode": 17.0, "batch_reward": 0.8015370907783508, "critic_loss": 1.5896503457427025, "actor_loss": -89.78610934448243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.411085844039917, "step": 17000}
{"episode_reward": 869.4223917574908, "episode": 18.0, "batch_reward": 0.8097118265628814, "critic_loss": 1.7020786420702934, "actor_loss": -89.92711886596679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.148892164230347, "step": 18000}
{"episode_reward": 930.0787748161957, "episode": 19.0, "batch_reward": 0.8096240788698197, "critic_loss": 1.7200752710103988, "actor_loss": -89.68297882080078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9542076587677, "step": 19000}
{"episode_reward": 781.7463388981473, "episode": 20.0, "batch_reward": 0.8151070975661278, "critic_loss": 1.6307863218784333, "actor_loss": -90.03906744384766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.750997304916382, "step": 20000}
{"episode_reward": 959.0120362481265, "episode": 21.0, "batch_reward": 0.8164506348371505, "critic_loss": 1.826322990655899, "actor_loss": -89.9579464263916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.46374559402466, "step": 21000}
{"episode_reward": 804.4204343708387, "episode": 22.0, "batch_reward": 0.8229579051733017, "critic_loss": 1.7982168467640878, "actor_loss": -89.68886337280273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36325168609619, "step": 22000}
{"episode_reward": 976.3975595989651, "episode": 23.0, "batch_reward": 0.8287592458724976, "critic_loss": 1.774731581568718, "actor_loss": -90.10119757080078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.38043522834778, "step": 23000}
{"episode_reward": 950.991513418154, "episode": 24.0, "batch_reward": 0.8331872339844704, "critic_loss": 1.6370191113352777, "actor_loss": -90.2398553161621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.27089524269104, "step": 24000}
{"episode_reward": 982.5353947222633, "episode": 25.0, "batch_reward": 0.8383595007658005, "critic_loss": 1.6252228847146035, "actor_loss": -90.01036344909667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.783231258392334, "step": 25000}
{"episode_reward": 951.3993573677923, "episode": 26.0, "batch_reward": 0.8428591994643211, "critic_loss": 1.5482029481530188, "actor_loss": -90.40089122009277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.19734501838684, "step": 26000}
{"episode_reward": 975.3546900269716, "episode": 27.0, "batch_reward": 0.8512480806708336, "critic_loss": 1.42325669413805, "actor_loss": -90.77860208129883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.928229570388794, "step": 27000}
{"episode_reward": 980.4806832150042, "episode": 28.0, "batch_reward": 0.8538774555921554, "critic_loss": 1.4520853012800217, "actor_loss": -90.74294686889648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.536467790603638, "step": 28000}
{"episode_reward": 951.4767257571556, "episode": 29.0, "batch_reward": 0.8555475164651871, "critic_loss": 1.4575177769064904, "actor_loss": -91.06212930297852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.72120475769043, "step": 29000}
{"episode_reward": 898.342803444488, "episode": 30.0, "batch_reward": 0.8576653268933296, "critic_loss": 1.2711500779986382, "actor_loss": -90.91385200500488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.37413191795349, "step": 30000}
{"episode_reward": 925.9241988885382, "episode": 31.0, "batch_reward": 0.8608194453716278, "critic_loss": 1.2598078424930572, "actor_loss": -91.30638876342773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.600860357284546, "step": 31000}
{"episode_reward": 945.7859368007566, "episode": 32.0, "batch_reward": 0.8627167027592659, "critic_loss": 1.1753215076923371, "actor_loss": -91.0838059387207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.71365213394165, "step": 32000}
{"episode_reward": 879.6455333397354, "episode": 33.0, "batch_reward": 0.8644570671916008, "critic_loss": 1.1405579372644425, "actor_loss": -91.56295617675781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.26839017868042, "step": 33000}
{"episode_reward": 918.4036768062867, "episode": 34.0, "batch_reward": 0.8648663336038589, "critic_loss": 1.147206658065319, "actor_loss": -91.20169071960449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.41355061531067, "step": 34000}
{"episode_reward": 935.9407679060232, "episode": 35.0, "batch_reward": 0.8670719621777534, "critic_loss": 1.0308954711556435, "actor_loss": -91.64789823913574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.563051223754883, "step": 35000}
{"episode_reward": 931.6874375778119, "episode": 36.0, "batch_reward": 0.8679959466457366, "critic_loss": 1.0124359134435654, "actor_loss": -91.23143637084961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.38075613975525, "step": 36000}
{"episode_reward": 936.8844731528742, "episode": 37.0, "batch_reward": 0.8687337915301323, "critic_loss": 1.0193555366396905, "actor_loss": -91.53144366455078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.06580877304077, "step": 37000}
{"episode_reward": 895.4389997696721, "episode": 38.0, "batch_reward": 0.8709941326379776, "critic_loss": 0.9892532684206963, "actor_loss": -91.76212705993652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.87152624130249, "step": 38000}
{"episode_reward": 932.5144873375349, "episode": 39.0, "batch_reward": 0.8725253573656082, "critic_loss": 0.9917917416095734, "actor_loss": -91.92599722290039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.715702533721924, "step": 39000}
{"episode_reward": 951.0082252844765, "episode": 40.0, "batch_reward": 0.8745299908518791, "critic_loss": 0.9902810883522034, "actor_loss": -92.06691078186036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.717053174972534, "step": 40000}
{"episode_reward": 977.4049151030495, "episode": 41.0, "batch_reward": 0.876250256717205, "critic_loss": 1.0988381712734698, "actor_loss": -92.05194067382813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.885003328323364, "step": 41000}
{"episode_reward": 861.9367624811888, "episode": 42.0, "batch_reward": 0.8795682240128517, "critic_loss": 1.0306893389821052, "actor_loss": -91.89645916748047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.23027467727661, "step": 42000}
{"episode_reward": 967.6594829848374, "episode": 43.0, "batch_reward": 0.8789523651599884, "critic_loss": 1.0393279520571232, "actor_loss": -91.97063005065918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.45750093460083, "step": 43000}
{"episode_reward": 929.3788042058575, "episode": 44.0, "batch_reward": 0.8819539489746093, "critic_loss": 0.9969855012893677, "actor_loss": -91.95992352294923, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.3305926322937, "step": 44000}
{"episode_reward": 979.8125040386979, "episode": 45.0, "batch_reward": 0.8786403337717056, "critic_loss": 1.1882145097255707, "actor_loss": -92.14055545043945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.998008728027344, "step": 45000}
{"episode_reward": 759.6041880347154, "episode": 46.0, "batch_reward": 0.8805931957960129, "critic_loss": 1.0876856401264667, "actor_loss": -92.03866806030274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.485986948013306, "step": 46000}
{"episode_reward": 962.6407062045165, "episode": 47.0, "batch_reward": 0.881770951628685, "critic_loss": 1.0859783063828945, "actor_loss": -92.24870208740235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.767085075378418, "step": 47000}
{"episode_reward": 932.1683169287937, "episode": 48.0, "batch_reward": 0.8830202922224999, "critic_loss": 1.0734357462227344, "actor_loss": -91.948849319458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.9996395111084, "step": 48000}
{"episode_reward": 904.7557524249711, "episode": 49.0, "batch_reward": 0.8843306583762169, "critic_loss": 1.1333708304166794, "actor_loss": -92.51474359130859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.079570531845093, "step": 49000}
{"episode_reward": 964.301731992257, "episode": 50.0, "batch_reward": 0.8862174698114396, "critic_loss": 1.08644239538908, "actor_loss": -92.53097537231446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.460068464279175, "step": 50000}
{"episode_reward": 985.1982848407737, "episode": 51.0, "batch_reward": 0.8862040481567383, "critic_loss": 1.0937730173170566, "actor_loss": -92.52574328613281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.9896559715271, "step": 51000}
{"episode_reward": 909.6089293376988, "episode": 52.0, "batch_reward": 0.886761033475399, "critic_loss": 1.1196266167163849, "actor_loss": -92.6575306854248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.19934916496277, "step": 52000}
{"episode_reward": 927.7563776870128, "episode": 53.0, "batch_reward": 0.8876401370763779, "critic_loss": 1.1120967018604277, "actor_loss": -92.67128984069824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.283153295516968, "step": 53000}
{"episode_reward": 937.5079826834133, "episode": 54.0, "batch_reward": 0.8889666164517402, "critic_loss": 1.1483663443028926, "actor_loss": -92.80916542053222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.718695402145386, "step": 54000}
{"episode_reward": 898.0513095652202, "episode": 55.0, "batch_reward": 0.889749967455864, "critic_loss": 1.1216686587929725, "actor_loss": -92.91680978393555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.43486738204956, "step": 55000}
{"episode_reward": 976.3937306866179, "episode": 56.0, "batch_reward": 0.8928036199212074, "critic_loss": 1.034627671033144, "actor_loss": -93.10954693603516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.37195110321045, "step": 56000}
{"episode_reward": 987.4934659207482, "episode": 57.0, "batch_reward": 0.8934645700454712, "critic_loss": 1.031813247412443, "actor_loss": -93.04848652648926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.263221502304077, "step": 57000}
{"episode_reward": 960.6737300112312, "episode": 58.0, "batch_reward": 0.8951424541473388, "critic_loss": 1.019714744925499, "actor_loss": -93.00755015563965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.499440670013428, "step": 58000}
{"episode_reward": 972.5649926156716, "episode": 59.0, "batch_reward": 0.8963125313520431, "critic_loss": 1.022888446509838, "actor_loss": -93.11216781616211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.05161452293396, "step": 59000}
{"episode_reward": 952.7932325114417, "episode": 60.0, "batch_reward": 0.8946002507209778, "critic_loss": 1.0589483645558357, "actor_loss": -93.30452819824218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.159615755081177, "step": 60000}
{"episode_reward": 879.627686549841, "episode": 61.0, "batch_reward": 0.8949291654229165, "critic_loss": 0.969948733061552, "actor_loss": -93.09508322143554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.97477984428406, "step": 61000}
{"episode_reward": 962.3089055025763, "episode": 62.0, "batch_reward": 0.8963045850992203, "critic_loss": 0.9723221156299114, "actor_loss": -93.34570054626465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.46208620071411, "step": 62000}
{"episode_reward": 967.1883776333491, "episode": 63.0, "batch_reward": 0.8964701739549636, "critic_loss": 1.0072291221320628, "actor_loss": -93.19788916015625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.839730739593506, "step": 63000}
{"episode_reward": 903.2581020708883, "episode": 64.0, "batch_reward": 0.8980651984810829, "critic_loss": 0.9710305576622487, "actor_loss": -93.40638328552247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.68891429901123, "step": 64000}
{"episode_reward": 987.014847826165, "episode": 65.0, "batch_reward": 0.899001235127449, "critic_loss": 0.9400063799023628, "actor_loss": -93.42345001220703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.703216075897217, "step": 65000}
{"episode_reward": 912.1730412912719, "episode": 66.0, "batch_reward": 0.8986316146254539, "critic_loss": 0.9376095214188099, "actor_loss": -93.47877294921875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.514466047286987, "step": 66000}
{"episode_reward": 948.6205431671494, "episode": 67.0, "batch_reward": 0.8985153563022613, "critic_loss": 1.0094099451899528, "actor_loss": -93.52354959106445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.629130125045776, "step": 67000}
{"episode_reward": 888.1523345727315, "episode": 68.0, "batch_reward": 0.899025684773922, "critic_loss": 0.9383980317115783, "actor_loss": -93.3182758178711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.92450785636902, "step": 68000}
{"episode_reward": 957.0340009347366, "episode": 69.0, "batch_reward": 0.9008956816792488, "critic_loss": 0.9297890655398369, "actor_loss": -93.40769613647461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.80911922454834, "step": 69000}
{"episode_reward": 986.2579206200571, "episode": 70.0, "batch_reward": 0.9020772323608398, "critic_loss": 0.9880972974300385, "actor_loss": -93.65815792846679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.567609071731567, "step": 70000}
{"episode_reward": 934.1652419481447, "episode": 71.0, "batch_reward": 0.9023983986973763, "critic_loss": 0.9034391301572323, "actor_loss": -93.63000300598145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.369760036468506, "step": 71000}
{"episode_reward": 959.618234720379, "episode": 72.0, "batch_reward": 0.9030221009850502, "critic_loss": 0.924636967420578, "actor_loss": -93.6097420501709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.506222009658813, "step": 72000}
{"episode_reward": 975.5909611132251, "episode": 73.0, "batch_reward": 0.9049878840446473, "critic_loss": 0.9177951231598854, "actor_loss": -93.69282916259766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.254589557647705, "step": 73000}
{"episode_reward": 950.6586588035456, "episode": 74.0, "batch_reward": 0.9056845347881317, "critic_loss": 0.8983807009160518, "actor_loss": -93.86046926879882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.386849403381348, "step": 74000}
{"episode_reward": 906.9161664538067, "episode": 75.0, "batch_reward": 0.9038473199605942, "critic_loss": 0.9901019822955132, "actor_loss": -93.72760723876954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.75593113899231, "step": 75000}
{"episode_reward": 851.3916937632235, "episode": 76.0, "batch_reward": 0.9050975832343101, "critic_loss": 0.9237206204831601, "actor_loss": -93.8296137084961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.57338809967041, "step": 76000}
{"episode_reward": 959.1104504224394, "episode": 77.0, "batch_reward": 0.904009073138237, "critic_loss": 0.8939755002558232, "actor_loss": -93.60278536987305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.85947847366333, "step": 77000}
{"episode_reward": 942.5923155970088, "episode": 78.0, "batch_reward": 0.9062497019767761, "critic_loss": 0.9375469671487808, "actor_loss": -93.77296696472168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.865007877349854, "step": 78000}
{"episode_reward": 958.4714636496572, "episode": 79.0, "batch_reward": 0.9067246246337891, "critic_loss": 0.9052113881409168, "actor_loss": -93.55627545166016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.426947116851807, "step": 79000}
{"episode_reward": 954.4070997432689, "episode": 80.0, "batch_reward": 0.9058942543268204, "critic_loss": 0.9288175248503685, "actor_loss": -93.71293653869628, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.78901958465576, "step": 80000}
{"episode_reward": 958.8848958115703, "episode": 81.0, "batch_reward": 0.9073689596056939, "critic_loss": 0.9247331417798996, "actor_loss": -93.86467309570313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.96435070037842, "step": 81000}
{"episode_reward": 941.4152585497461, "episode": 82.0, "batch_reward": 0.9085628755688667, "critic_loss": 0.9427070207297802, "actor_loss": -93.99371145629883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.588003396987915, "step": 82000}
{"episode_reward": 911.0804386530904, "episode": 83.0, "batch_reward": 0.9080286076068879, "critic_loss": 0.9545422325730324, "actor_loss": -93.73188215637207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.139399528503418, "step": 83000}
{"episode_reward": 920.1625323917071, "episode": 84.0, "batch_reward": 0.9082129172682762, "critic_loss": 0.9586474044024944, "actor_loss": -94.02294752502442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.439300060272217, "step": 84000}
{"episode_reward": 975.5748472469859, "episode": 85.0, "batch_reward": 0.9074901277422905, "critic_loss": 0.9678767927289009, "actor_loss": -93.89474063110352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.852753400802612, "step": 85000}
{"episode_reward": 951.1723133291576, "episode": 86.0, "batch_reward": 0.9086310575604439, "critic_loss": 0.9750579258501529, "actor_loss": -93.84565858459473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.46190357208252, "step": 86000}
{"episode_reward": 959.7574473714385, "episode": 87.0, "batch_reward": 0.9101001647114754, "critic_loss": 0.9790706116557121, "actor_loss": -93.92797566223145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.756548643112183, "step": 87000}
{"episode_reward": 949.5027028042448, "episode": 88.0, "batch_reward": 0.9105943139791489, "critic_loss": 0.9606675284504891, "actor_loss": -93.80563697814941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.628087282180786, "step": 88000}
{"episode_reward": 873.3051731438458, "episode": 89.0, "batch_reward": 0.9084760694503784, "critic_loss": 1.0016412183642387, "actor_loss": -94.02221887207031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.82113814353943, "step": 89000}
{"episode_reward": 972.1652873183051, "episode": 90.0, "batch_reward": 0.9108493776917458, "critic_loss": 1.024821981102228, "actor_loss": -94.22337049865723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.86525321006775, "step": 90000}
{"episode_reward": 962.8537995541133, "episode": 91.0, "batch_reward": 0.9110000712871551, "critic_loss": 0.9553152572214604, "actor_loss": -93.96069923400879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.915969371795654, "step": 91000}
{"episode_reward": 948.6732074034029, "episode": 92.0, "batch_reward": 0.9121878175139427, "critic_loss": 1.028620817065239, "actor_loss": -93.9785209350586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.742717027664185, "step": 92000}
{"episode_reward": 968.9900178132083, "episode": 93.0, "batch_reward": 0.911325136065483, "critic_loss": 0.9918108132481575, "actor_loss": -93.96160429382324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.855266571044922, "step": 93000}
{"episode_reward": 977.0619574013548, "episode": 94.0, "batch_reward": 0.9128364270925522, "critic_loss": 0.9176510716378689, "actor_loss": -94.04217150878907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.864901065826416, "step": 94000}
{"episode_reward": 952.6726144510134, "episode": 95.0, "batch_reward": 0.9121756118535995, "critic_loss": 0.9665418373942375, "actor_loss": -94.21190637207032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.019492149353027, "step": 95000}
{"episode_reward": 849.933034620815, "episode": 96.0, "batch_reward": 0.9128050673604011, "critic_loss": 0.9932622236013412, "actor_loss": -94.24401477050782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.13498568534851, "step": 96000}
{"episode_reward": 940.6496555099521, "episode": 97.0, "batch_reward": 0.9128414072394371, "critic_loss": 1.0036671689152719, "actor_loss": -94.22141040039062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.52171802520752, "step": 97000}
{"episode_reward": 955.6634204696055, "episode": 98.0, "batch_reward": 0.9133443691134453, "critic_loss": 1.0081949119865894, "actor_loss": -94.01615940856934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.914385318756104, "step": 98000}
{"episode_reward": 928.9081116401161, "episode": 99.0, "batch_reward": 0.9129827072024346, "critic_loss": 1.0443486550450325, "actor_loss": -93.96698240661621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.12049651145935, "step": 99000}
{"episode_reward": 946.0785383020938, "episode": 100.0, "batch_reward": 0.9143171855807304, "critic_loss": 0.9845546778142452, "actor_loss": -94.05932066345216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.145415544509888, "step": 100000}
{"episode_reward": 881.6839610211601, "episode": 101.0, "batch_reward": 0.9139081973433495, "critic_loss": 0.9917869845926761, "actor_loss": -94.1289476928711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.49398732185364, "step": 101000}
{"episode_reward": 990.3267413806889, "episode": 102.0, "batch_reward": 0.9134804930090904, "critic_loss": 1.0472366397082806, "actor_loss": -94.07802619934083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.367639541625977, "step": 102000}
{"episode_reward": 899.0053205141785, "episode": 103.0, "batch_reward": 0.9135571334958077, "critic_loss": 1.050762515515089, "actor_loss": -94.06647444152831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.594764709472656, "step": 103000}
{"episode_reward": 934.2407401825427, "episode": 104.0, "batch_reward": 0.915666355729103, "critic_loss": 1.0357120057046414, "actor_loss": -94.13733149719238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.095575094223022, "step": 104000}
{"episode_reward": 961.9675952282338, "episode": 105.0, "batch_reward": 0.9156767845153808, "critic_loss": 1.0457698837816716, "actor_loss": -94.15573461914063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.1079204082489, "step": 105000}
{"episode_reward": 936.7556965922726, "episode": 106.0, "batch_reward": 0.9158693625926971, "critic_loss": 1.0916206883788109, "actor_loss": -94.06566807556152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.996299266815186, "step": 106000}
{"episode_reward": 929.108382730162, "episode": 107.0, "batch_reward": 0.9156033882498741, "critic_loss": 1.0859690282046794, "actor_loss": -94.07432884216308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.46744441986084, "step": 107000}
{"episode_reward": 960.8798337951386, "episode": 108.0, "batch_reward": 0.9157446265220642, "critic_loss": 1.0652695697844028, "actor_loss": -94.22627827453613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.181273221969604, "step": 108000}
{"episode_reward": 889.9985911557196, "episode": 109.0, "batch_reward": 0.9160963383316993, "critic_loss": 1.1208168733417987, "actor_loss": -94.31504414367676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.844921588897705, "step": 109000}
{"episode_reward": 973.8047253047389, "episode": 110.0, "batch_reward": 0.917076073884964, "critic_loss": 1.0723108840286733, "actor_loss": -94.20242361450195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.77848243713379, "step": 110000}
{"episode_reward": 954.8797057092295, "episode": 111.0, "batch_reward": 0.9155105412602424, "critic_loss": 1.0884647629261017, "actor_loss": -94.35965740966797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.940035581588745, "step": 111000}
{"episode_reward": 910.5392593839304, "episode": 112.0, "batch_reward": 0.916197968840599, "critic_loss": 1.1470253796577454, "actor_loss": -94.20830754089356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.574493646621704, "step": 112000}
{"episode_reward": 938.4196475367216, "episode": 113.0, "batch_reward": 0.9167839605212211, "critic_loss": 1.1164294711649418, "actor_loss": -94.23695945739746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10318875312805, "step": 113000}
{"episode_reward": 963.6515575575371, "episode": 114.0, "batch_reward": 0.9169849544763565, "critic_loss": 1.1220980685949327, "actor_loss": -94.34057698059082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.602047443389893, "step": 114000}
{"episode_reward": 980.6717298336484, "episode": 115.0, "batch_reward": 0.9174632925391197, "critic_loss": 1.1231083990335464, "actor_loss": -94.25339065551758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.231837272644043, "step": 115000}
{"episode_reward": 932.7298620267277, "episode": 116.0, "batch_reward": 0.9172320533394813, "critic_loss": 1.079558441698551, "actor_loss": -94.36170686340333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.31600022315979, "step": 116000}
{"episode_reward": 952.6856397546168, "episode": 117.0, "batch_reward": 0.9172347831726074, "critic_loss": 1.0782339636683465, "actor_loss": -94.33617294311523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.85175585746765, "step": 117000}
{"episode_reward": 891.1229424504218, "episode": 118.0, "batch_reward": 0.9180476943254471, "critic_loss": 1.0405195327401162, "actor_loss": -94.43633944702148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.89353060722351, "step": 118000}
{"episode_reward": 986.0003500870729, "episode": 119.0, "batch_reward": 0.9182467755675315, "critic_loss": 1.0547516450285912, "actor_loss": -94.43226167297364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.818644285202026, "step": 119000}
{"episode_reward": 934.2225546026702, "episode": 120.0, "batch_reward": 0.9164338839054108, "critic_loss": 1.0236395968198777, "actor_loss": -94.22253479003906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.09957718849182, "step": 120000}
{"episode_reward": 921.6235213771215, "episode": 121.0, "batch_reward": 0.9192119328379631, "critic_loss": 1.0690263259112835, "actor_loss": -94.36259107971192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.00302028656006, "step": 121000}
{"episode_reward": 934.9687087206413, "episode": 122.0, "batch_reward": 0.9184111884236336, "critic_loss": 1.0454523358643055, "actor_loss": -94.34271411132812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.80659317970276, "step": 122000}
{"episode_reward": 942.7685993172213, "episode": 123.0, "batch_reward": 0.9191394249796867, "critic_loss": 1.0497988629043102, "actor_loss": -94.14972427368164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.008931636810303, "step": 123000}
{"episode_reward": 952.149561322843, "episode": 124.0, "batch_reward": 0.9192957924604416, "critic_loss": 1.0346354894042016, "actor_loss": -94.35887637329101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.33140993118286, "step": 124000}
{"episode_reward": 979.3123394478528, "episode": 125.0, "batch_reward": 0.9190382277965545, "critic_loss": 0.9831284643709659, "actor_loss": -94.4358712463379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.440226793289185, "step": 125000}
{"episode_reward": 986.7075987459855, "episode": 126.0, "batch_reward": 0.9198875545859336, "critic_loss": 1.010311241298914, "actor_loss": -94.49519689941407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.85715937614441, "step": 126000}
{"episode_reward": 987.3398017265221, "episode": 127.0, "batch_reward": 0.919946493268013, "critic_loss": 1.0164170560538768, "actor_loss": -94.47467561340332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.194030046463013, "step": 127000}
{"episode_reward": 958.7771136652729, "episode": 128.0, "batch_reward": 0.9204306799769402, "critic_loss": 0.9705089586079121, "actor_loss": -94.66419055175781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.676811933517456, "step": 128000}
{"episode_reward": 967.1552359276217, "episode": 129.0, "batch_reward": 0.9212748085260392, "critic_loss": 0.9859255591034889, "actor_loss": -94.70831268310548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.399248361587524, "step": 129000}
{"episode_reward": 981.2638344023345, "episode": 130.0, "batch_reward": 0.9227617945671082, "critic_loss": 1.0013610365390777, "actor_loss": -94.62321730041504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.261411905288696, "step": 130000}
{"episode_reward": 983.6351973225513, "episode": 131.0, "batch_reward": 0.9222682476043701, "critic_loss": 0.9524070949554443, "actor_loss": -94.74384552001953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.69446134567261, "step": 131000}
{"episode_reward": 966.2554995778567, "episode": 132.0, "batch_reward": 0.9238736582398415, "critic_loss": 0.965759460657835, "actor_loss": -94.67204127502441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.988466024398804, "step": 132000}
{"episode_reward": 982.5931344656029, "episode": 133.0, "batch_reward": 0.9222855766415596, "critic_loss": 0.9554677682965994, "actor_loss": -94.73643305969239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.268812656402588, "step": 133000}
{"episode_reward": 958.4799867602134, "episode": 134.0, "batch_reward": 0.9226986302137374, "critic_loss": 0.9707475326359272, "actor_loss": -94.74650804138183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.55571484565735, "step": 134000}
{"episode_reward": 957.3793747029913, "episode": 135.0, "batch_reward": 0.9247218402028083, "critic_loss": 0.9309871564209461, "actor_loss": -94.81808401489258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.717541456222534, "step": 135000}
{"episode_reward": 992.9839548145344, "episode": 136.0, "batch_reward": 0.9245039868354797, "critic_loss": 0.8914248707592487, "actor_loss": -94.9146605834961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.933681964874268, "step": 136000}
{"episode_reward": 989.6700003749218, "episode": 137.0, "batch_reward": 0.9235539330840111, "critic_loss": 0.9231330958902836, "actor_loss": -94.71225115966797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.978612184524536, "step": 137000}
{"episode_reward": 981.9378323673573, "episode": 138.0, "batch_reward": 0.9246679617166519, "critic_loss": 0.9370036863684654, "actor_loss": -94.70200694274902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.88633370399475, "step": 138000}
{"episode_reward": 771.1217759692598, "episode": 139.0, "batch_reward": 0.9227521671652794, "critic_loss": 0.9462744526565074, "actor_loss": -94.67555554199218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.843059301376343, "step": 139000}
{"episode_reward": 989.4168005550179, "episode": 140.0, "batch_reward": 0.9244745494127273, "critic_loss": 0.9106415538489818, "actor_loss": -94.73053288269043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.73999857902527, "step": 140000}
{"episode_reward": 928.526985157814, "episode": 141.0, "batch_reward": 0.9245350705981255, "critic_loss": 0.9540744087696076, "actor_loss": -94.68248802185059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.644986629486084, "step": 141000}
{"episode_reward": 964.4839489228551, "episode": 142.0, "batch_reward": 0.9250740688443184, "critic_loss": 0.9582817710340022, "actor_loss": -94.762052734375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.70376181602478, "step": 142000}
{"episode_reward": 983.3113383083405, "episode": 143.0, "batch_reward": 0.9242344584465026, "critic_loss": 0.9634562689363957, "actor_loss": -94.80798722839356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.76994252204895, "step": 143000}
{"episode_reward": 844.9023522451297, "episode": 144.0, "batch_reward": 0.9243263181447983, "critic_loss": 0.9858260395228863, "actor_loss": -94.7934252319336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.619526147842407, "step": 144000}
{"episode_reward": 962.4196800211041, "episode": 145.0, "batch_reward": 0.9241865047216415, "critic_loss": 0.9757065345048904, "actor_loss": -94.7719507598877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.58178949356079, "step": 145000}
{"episode_reward": 983.8795426128547, "episode": 146.0, "batch_reward": 0.9245138634443283, "critic_loss": 0.9754389126300812, "actor_loss": -94.75719079589844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.018681049346924, "step": 146000}
{"episode_reward": 968.3840437075687, "episode": 147.0, "batch_reward": 0.9249095172286034, "critic_loss": 1.0146709734797477, "actor_loss": -94.81035575866699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.329508304595947, "step": 147000}
{"episode_reward": 923.7422581740956, "episode": 148.0, "batch_reward": 0.9261883791089058, "critic_loss": 0.9930934811532497, "actor_loss": -94.7407469177246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.88168478012085, "step": 148000}
{"episode_reward": 986.2686237282054, "episode": 149.0, "batch_reward": 0.925549387037754, "critic_loss": 1.021312821418047, "actor_loss": -94.78656901550293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.344759464263916, "step": 149000}
{"episode_reward": 932.0274936170174, "episode": 150.0, "batch_reward": 0.9255349668264389, "critic_loss": 1.010292623385787, "actor_loss": -94.80077537536621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
