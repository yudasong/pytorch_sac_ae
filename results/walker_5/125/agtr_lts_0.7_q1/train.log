{"episode_reward": 0.0, "episode": 1.0, "duration": 21.603351354599, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.8308336734771729, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.46098663806219664, "critic_loss": 0.15907733830542276, "actor_loss": -61.86689078483154, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 62.85181975364685, "step": 3000}
{"episode_reward": 132.37538708215737, "episode": 4.0, "batch_reward": 0.34758341643214224, "critic_loss": 0.3921928743422031, "actor_loss": -60.312102486610414, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.18753957748413, "step": 4000}
{"episode_reward": 266.9994346800964, "episode": 5.0, "batch_reward": 0.3277883598655462, "critic_loss": 0.4591337572932243, "actor_loss": -54.764811499595645, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.77241587638855, "step": 5000}
{"episode_reward": 228.34830496913924, "episode": 6.0, "batch_reward": 0.30891031970083715, "critic_loss": 0.6531629348695278, "actor_loss": -57.84672029876709, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.431473970413208, "step": 6000}
{"episode_reward": 245.7133598372027, "episode": 7.0, "batch_reward": 0.3078655741214752, "critic_loss": 0.9788545531630516, "actor_loss": -62.85790892982483, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.64121651649475, "step": 7000}
{"episode_reward": 460.84026290403744, "episode": 8.0, "batch_reward": 0.32883713464438913, "critic_loss": 1.4731402300596237, "actor_loss": -60.24703760719299, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.917213201522827, "step": 8000}
{"episode_reward": 366.847868467251, "episode": 9.0, "batch_reward": 0.32370963633060457, "critic_loss": 1.7169676418304443, "actor_loss": -60.09271857452393, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.458320379257202, "step": 9000}
{"episode_reward": 182.15252524303315, "episode": 10.0, "batch_reward": 0.30139002507925033, "critic_loss": 1.5999555862545967, "actor_loss": -60.48824291038513, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.16191005706787, "step": 10000}
{"episode_reward": 99.86647678860224, "episode": 11.0, "batch_reward": 0.30543680292367936, "critic_loss": 2.109508684515953, "actor_loss": -62.556415565490724, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.5139844417572, "step": 11000}
{"episode_reward": 536.7144349979706, "episode": 12.0, "batch_reward": 0.32923008596897124, "critic_loss": 2.404576219201088, "actor_loss": -61.78499597358704, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.68032479286194, "step": 12000}
{"episode_reward": 676.6934650171438, "episode": 13.0, "batch_reward": 0.36112284237146375, "critic_loss": 2.5505527763366698, "actor_loss": -64.01015032577514, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.96070170402527, "step": 13000}
{"episode_reward": 804.9366322287337, "episode": 14.0, "batch_reward": 0.39266482478380205, "critic_loss": 2.692697779297829, "actor_loss": -63.86620497512818, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.519902229309082, "step": 14000}
{"episode_reward": 715.8488512847226, "episode": 15.0, "batch_reward": 0.41585257041454315, "critic_loss": 2.67316406083107, "actor_loss": -70.17129197311401, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.452171564102173, "step": 15000}
{"episode_reward": 701.0118843249148, "episode": 16.0, "batch_reward": 0.4240876136124134, "critic_loss": 2.7895771666765214, "actor_loss": -68.47665581512452, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.70737624168396, "step": 16000}
{"episode_reward": 598.6107244660379, "episode": 17.0, "batch_reward": 0.44868413016200065, "critic_loss": 2.569320817351341, "actor_loss": -67.8395309638977, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.593805074691772, "step": 17000}
{"episode_reward": 909.2843513590915, "episode": 18.0, "batch_reward": 0.4721350814402103, "critic_loss": 2.5060994695425034, "actor_loss": -69.42602537155152, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.14700937271118, "step": 18000}
{"episode_reward": 829.1237844483048, "episode": 19.0, "batch_reward": 0.4930650790929794, "critic_loss": 2.54995231282711, "actor_loss": -70.07931661605835, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.30614185333252, "step": 19000}
{"episode_reward": 843.0918468638084, "episode": 20.0, "batch_reward": 0.5096417954266071, "critic_loss": 2.4799951325654983, "actor_loss": -72.25443207550049, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.417590618133545, "step": 20000}
{"episode_reward": 820.2936347398777, "episode": 21.0, "batch_reward": 0.5266839904487133, "critic_loss": 2.436257443666458, "actor_loss": -73.32522507476807, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.235315561294556, "step": 21000}
{"episode_reward": 831.7501354927145, "episode": 22.0, "batch_reward": 0.5424848502874374, "critic_loss": 2.4324822095632554, "actor_loss": -73.11775193023682, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.581486701965332, "step": 22000}
{"episode_reward": 903.7672360422907, "episode": 23.0, "batch_reward": 0.5527363324463368, "critic_loss": 2.2577481327056885, "actor_loss": -74.68187342071533, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.879311561584473, "step": 23000}
{"episode_reward": 770.9715504596969, "episode": 24.0, "batch_reward": 0.5699733427166939, "critic_loss": 2.168789296746254, "actor_loss": -75.4700414276123, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.62602424621582, "step": 24000}
{"episode_reward": 985.2675028341334, "episode": 25.0, "batch_reward": 0.581882341504097, "critic_loss": 2.2940968359708784, "actor_loss": -74.5408793258667, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.94435214996338, "step": 25000}
{"episode_reward": 885.4003349076984, "episode": 26.0, "batch_reward": 0.595022328287363, "critic_loss": 2.099061088323593, "actor_loss": -75.84606898498535, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.231096267700195, "step": 26000}
{"episode_reward": 975.3354445984206, "episode": 27.0, "batch_reward": 0.6114034988880157, "critic_loss": 1.9791751841306686, "actor_loss": -76.94406993865967, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.41986846923828, "step": 27000}
{"episode_reward": 963.1555944515333, "episode": 28.0, "batch_reward": 0.6184792656302452, "critic_loss": 2.066550363242626, "actor_loss": -76.65142059326172, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.349340438842773, "step": 28000}
{"episode_reward": 729.3058178902537, "episode": 29.0, "batch_reward": 0.6243454644382, "critic_loss": 2.067083534359932, "actor_loss": -78.04680632019043, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.289734363555908, "step": 29000}
{"episode_reward": 795.1590468536637, "episode": 30.0, "batch_reward": 0.631313574552536, "critic_loss": 2.0114675654172895, "actor_loss": -77.56865512847901, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.51266646385193, "step": 30000}
{"episode_reward": 881.533973964363, "episode": 31.0, "batch_reward": 0.6398247378468513, "critic_loss": 2.2337881662845613, "actor_loss": -79.15029528045655, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.33841943740845, "step": 31000}
{"episode_reward": 860.919234669577, "episode": 32.0, "batch_reward": 0.6467210695147514, "critic_loss": 2.2016515583992002, "actor_loss": -78.77037808227539, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.460173845291138, "step": 32000}
{"episode_reward": 884.7624736137129, "episode": 33.0, "batch_reward": 0.6504923961758614, "critic_loss": 2.29159053170681, "actor_loss": -80.29470111083984, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.885811805725098, "step": 33000}
{"episode_reward": 768.5408797674677, "episode": 34.0, "batch_reward": 0.6573685984015465, "critic_loss": 2.1968185799121858, "actor_loss": -79.35816487121582, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.52485704421997, "step": 34000}
{"episode_reward": 972.568330424099, "episode": 35.0, "batch_reward": 0.6668315277695656, "critic_loss": 2.228998164534569, "actor_loss": -80.92227812957763, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.94904375076294, "step": 35000}
{"episode_reward": 903.8208833789196, "episode": 36.0, "batch_reward": 0.6721179907917977, "critic_loss": 2.214839359045029, "actor_loss": -79.81024808502197, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.796005964279175, "step": 36000}
{"episode_reward": 882.4951371384179, "episode": 37.0, "batch_reward": 0.6781392893791198, "critic_loss": 2.127445153236389, "actor_loss": -81.18402277374267, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.473064184188843, "step": 37000}
{"episode_reward": 960.1617458144264, "episode": 38.0, "batch_reward": 0.6877072151899338, "critic_loss": 1.9784017571210861, "actor_loss": -82.08424700164795, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.82489800453186, "step": 38000}
{"episode_reward": 977.604840735593, "episode": 39.0, "batch_reward": 0.6957780297398567, "critic_loss": 1.8728444120883943, "actor_loss": -82.69945314025878, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.773181915283203, "step": 39000}
{"episode_reward": 965.3418323023018, "episode": 40.0, "batch_reward": 0.7020671197772026, "critic_loss": 1.8357721990942955, "actor_loss": -83.19477121734619, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.50805640220642, "step": 40000}
{"episode_reward": 977.935718528301, "episode": 41.0, "batch_reward": 0.7053917894363403, "critic_loss": 1.910031443119049, "actor_loss": -83.14173315429687, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.513967514038086, "step": 41000}
{"episode_reward": 771.0942951169106, "episode": 42.0, "batch_reward": 0.7100045583248138, "critic_loss": 1.9034921987056732, "actor_loss": -82.7210586013794, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.38114595413208, "step": 42000}
{"episode_reward": 860.2560016151757, "episode": 43.0, "batch_reward": 0.7125509765148162, "critic_loss": 2.0516130598783495, "actor_loss": -83.04240018463135, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.490277767181396, "step": 43000}
{"episode_reward": 874.959643151327, "episode": 44.0, "batch_reward": 0.7171316066980362, "critic_loss": 1.975646525144577, "actor_loss": -83.047997215271, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.176528692245483, "step": 44000}
{"episode_reward": 854.4369682374565, "episode": 45.0, "batch_reward": 0.7198045634627342, "critic_loss": 2.07411242723465, "actor_loss": -83.85146842956543, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.407509326934814, "step": 45000}
{"episode_reward": 889.8063145526856, "episode": 46.0, "batch_reward": 0.7226313440799713, "critic_loss": 2.0418047438263893, "actor_loss": -83.73382608032226, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.462013721466064, "step": 46000}
{"episode_reward": 918.0555621851398, "episode": 47.0, "batch_reward": 0.7302656180262566, "critic_loss": 2.184780673146248, "actor_loss": -84.53580101013183, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.096209049224854, "step": 47000}
{"episode_reward": 974.8447918250179, "episode": 48.0, "batch_reward": 0.7325304982066154, "critic_loss": 2.1423534939289093, "actor_loss": -83.76218798828126, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.81952929496765, "step": 48000}
{"episode_reward": 938.5531391497451, "episode": 49.0, "batch_reward": 0.73721122777462, "critic_loss": 2.11540671646595, "actor_loss": -85.12080523681641, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.865015506744385, "step": 49000}
{"episode_reward": 945.7538288676376, "episode": 50.0, "batch_reward": 0.7408401861786842, "critic_loss": 2.189248350739479, "actor_loss": -85.2350717163086, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.939756870269775, "step": 50000}
{"episode_reward": 937.9107734027981, "episode": 51.0, "batch_reward": 0.7465331227183342, "critic_loss": 2.1530016806125643, "actor_loss": -85.50271243286133, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.73195004463196, "step": 51000}
{"episode_reward": 986.0262815683645, "episode": 52.0, "batch_reward": 0.7493871222138405, "critic_loss": 2.0646989287137987, "actor_loss": -85.80033769226074, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.415717840194702, "step": 52000}
{"episode_reward": 940.9816380663585, "episode": 53.0, "batch_reward": 0.7545127073526382, "critic_loss": 2.105187606692314, "actor_loss": -85.83012896728516, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.970811367034912, "step": 53000}
{"episode_reward": 930.329914015995, "episode": 54.0, "batch_reward": 0.7566443774700164, "critic_loss": 2.082827565073967, "actor_loss": -86.20289305114746, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.616241216659546, "step": 54000}
{"episode_reward": 919.339795718103, "episode": 55.0, "batch_reward": 0.760187067270279, "critic_loss": 2.0158979204893113, "actor_loss": -86.35476945495606, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.352173566818237, "step": 55000}
{"episode_reward": 949.5257481226383, "episode": 56.0, "batch_reward": 0.7630959168076515, "critic_loss": 1.895059605360031, "actor_loss": -86.66942709350586, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.481963396072388, "step": 56000}
{"episode_reward": 970.6573403783365, "episode": 57.0, "batch_reward": 0.7683176082968712, "critic_loss": 1.8639327411055564, "actor_loss": -86.65849252319336, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.279083251953125, "step": 57000}
{"episode_reward": 918.5184093611965, "episode": 58.0, "batch_reward": 0.7727901239991188, "critic_loss": 1.8439440752863885, "actor_loss": -86.52051446533203, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.399287462234497, "step": 58000}
{"episode_reward": 972.6562478692247, "episode": 59.0, "batch_reward": 0.7737823665738106, "critic_loss": 1.8812914780378343, "actor_loss": -86.68282075500488, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.670802354812622, "step": 59000}
{"episode_reward": 940.2979739154381, "episode": 60.0, "batch_reward": 0.7772053889036179, "critic_loss": 1.80158652561903, "actor_loss": -87.2904294128418, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.35531449317932, "step": 60000}
{"episode_reward": 954.9527438866994, "episode": 61.0, "batch_reward": 0.7796448101401329, "critic_loss": 1.7701755308508873, "actor_loss": -87.13224273681641, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.64312195777893, "step": 61000}
{"episode_reward": 909.1910123347983, "episode": 62.0, "batch_reward": 0.780743212044239, "critic_loss": 1.775102415382862, "actor_loss": -87.63414602661133, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.239128589630127, "step": 62000}
{"episode_reward": 951.174110919871, "episode": 63.0, "batch_reward": 0.7823266934752464, "critic_loss": 1.7323094623684883, "actor_loss": -87.28095173645019, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.471146821975708, "step": 63000}
{"episode_reward": 929.826557514678, "episode": 64.0, "batch_reward": 0.7859826744794846, "critic_loss": 1.7075540179014206, "actor_loss": -87.77928622436524, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.763153553009033, "step": 64000}
{"episode_reward": 985.854227008608, "episode": 65.0, "batch_reward": 0.7874231199026108, "critic_loss": 1.720021781384945, "actor_loss": -87.84023387145996, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44845199584961, "step": 65000}
{"episode_reward": 879.812419104251, "episode": 66.0, "batch_reward": 0.7908125909566879, "critic_loss": 1.6820404173135757, "actor_loss": -88.10628047180175, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.88668441772461, "step": 66000}
{"episode_reward": 920.14869289828, "episode": 67.0, "batch_reward": 0.7920146850943566, "critic_loss": 1.6081680697202683, "actor_loss": -88.2958645324707, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.595836639404297, "step": 67000}
{"episode_reward": 962.6286451482935, "episode": 68.0, "batch_reward": 0.7943159301280975, "critic_loss": 1.6940828364491463, "actor_loss": -87.76652467346192, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.443679809570312, "step": 68000}
{"episode_reward": 854.7843225318504, "episode": 69.0, "batch_reward": 0.7962614054679871, "critic_loss": 1.594115264236927, "actor_loss": -87.97708773803711, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.429337978363037, "step": 69000}
{"episode_reward": 983.6440370132092, "episode": 70.0, "batch_reward": 0.7979842168092728, "critic_loss": 1.6161358354091644, "actor_loss": -88.5673755645752, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.10489296913147, "step": 70000}
{"episode_reward": 896.4388141133435, "episode": 71.0, "batch_reward": 0.8001138665676117, "critic_loss": 1.620555078983307, "actor_loss": -88.5581909942627, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.68592929840088, "step": 71000}
{"episode_reward": 913.3955264856021, "episode": 72.0, "batch_reward": 0.8028888319730758, "critic_loss": 1.567862988948822, "actor_loss": -88.57551628112793, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.19954490661621, "step": 72000}
{"episode_reward": 980.5064780698884, "episode": 73.0, "batch_reward": 0.8025168226361274, "critic_loss": 1.5306746411323546, "actor_loss": -88.65633773803711, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.926228523254395, "step": 73000}
{"episode_reward": 946.2472735773805, "episode": 74.0, "batch_reward": 0.8072590098977089, "critic_loss": 1.5396060488820076, "actor_loss": -89.0495410003662, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.765018939971924, "step": 74000}
{"episode_reward": 950.5808314886658, "episode": 75.0, "batch_reward": 0.807589295566082, "critic_loss": 1.6331091589331628, "actor_loss": -89.05278518676758, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.45098304748535, "step": 75000}
{"episode_reward": 793.2509255526911, "episode": 76.0, "batch_reward": 0.8080120067596436, "critic_loss": 1.635167468190193, "actor_loss": -89.23750227355957, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.0074565410614, "step": 76000}
{"episode_reward": 966.4946766797325, "episode": 77.0, "batch_reward": 0.8087697819471359, "critic_loss": 1.6265655075907708, "actor_loss": -88.83539367675782, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.851895093917847, "step": 77000}
{"episode_reward": 902.3526470645418, "episode": 78.0, "batch_reward": 0.8112532125711441, "critic_loss": 1.6628418037891388, "actor_loss": -89.13372917175293, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.776935338974, "step": 78000}
{"episode_reward": 916.9890727073404, "episode": 79.0, "batch_reward": 0.8137262658476829, "critic_loss": 1.6629307411313057, "actor_loss": -88.72657339477539, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.373252153396606, "step": 79000}
{"episode_reward": 951.6596655320002, "episode": 80.0, "batch_reward": 0.8126982863545418, "critic_loss": 1.6568082006573677, "actor_loss": -89.10930821228027, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.839834451675415, "step": 80000}
{"episode_reward": 914.6236280653011, "episode": 81.0, "batch_reward": 0.8146813278198242, "critic_loss": 1.7730964463353156, "actor_loss": -89.33173442077637, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.763036012649536, "step": 81000}
{"episode_reward": 853.2284082679452, "episode": 82.0, "batch_reward": 0.8175436769127846, "critic_loss": 1.7424478797912597, "actor_loss": -89.72370864868164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.66571283340454, "step": 82000}
{"episode_reward": 951.9124189906937, "episode": 83.0, "batch_reward": 0.8192730564475059, "critic_loss": 1.716176975786686, "actor_loss": -89.14102947998047, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.25617241859436, "step": 83000}
{"episode_reward": 926.7343097382428, "episode": 84.0, "batch_reward": 0.8195184692144394, "critic_loss": 1.6862767015099525, "actor_loss": -89.82325268554688, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.97090458869934, "step": 84000}
{"episode_reward": 988.5575653960382, "episode": 85.0, "batch_reward": 0.8186066800951958, "critic_loss": 1.7246163791418077, "actor_loss": -89.55420903015137, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.674221992492676, "step": 85000}
{"episode_reward": 948.3188355488827, "episode": 86.0, "batch_reward": 0.8224152300953865, "critic_loss": 1.719798207640648, "actor_loss": -89.57249368286134, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.57785129547119, "step": 86000}
{"episode_reward": 928.1847578990119, "episode": 87.0, "batch_reward": 0.8229627892971039, "critic_loss": 1.6242316684126854, "actor_loss": -89.57050695800781, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.138219594955444, "step": 87000}
{"episode_reward": 938.598631773579, "episode": 88.0, "batch_reward": 0.8255135920643807, "critic_loss": 1.5954128367304803, "actor_loss": -89.43148973083495, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.840919017791748, "step": 88000}
{"episode_reward": 934.4187838515417, "episode": 89.0, "batch_reward": 0.8255957306623459, "critic_loss": 1.5627325409054755, "actor_loss": -89.99566731262207, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.948511123657227, "step": 89000}
{"episode_reward": 949.8351167581345, "episode": 90.0, "batch_reward": 0.8281173555850982, "critic_loss": 1.6735928144454957, "actor_loss": -90.36775999450684, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.162694931030273, "step": 90000}
{"episode_reward": 916.2078860717645, "episode": 91.0, "batch_reward": 0.8282623419165611, "critic_loss": 1.6111431397199631, "actor_loss": -89.93108111572266, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.586427450180054, "step": 91000}
{"episode_reward": 916.8584392398111, "episode": 92.0, "batch_reward": 0.8314710888266563, "critic_loss": 1.5775501666069032, "actor_loss": -89.96699734497071, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43820285797119, "step": 92000}
{"episode_reward": 956.1572920958048, "episode": 93.0, "batch_reward": 0.8305337032079697, "critic_loss": 1.6487715436816215, "actor_loss": -89.94974977111816, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.543461799621582, "step": 93000}
{"episode_reward": 971.2843898372377, "episode": 94.0, "batch_reward": 0.831285930454731, "critic_loss": 1.6021894876360894, "actor_loss": -90.03260932922363, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.761066198349, "step": 94000}
{"episode_reward": 881.9853349648712, "episode": 95.0, "batch_reward": 0.832003285586834, "critic_loss": 1.5896953885555267, "actor_loss": -90.52268920898437, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.453907251358032, "step": 95000}
{"episode_reward": 955.375387236768, "episode": 96.0, "batch_reward": 0.8337881126403809, "critic_loss": 1.589369301378727, "actor_loss": -90.55313458251953, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.615865468978882, "step": 96000}
{"episode_reward": 954.9948467465229, "episode": 97.0, "batch_reward": 0.8344919147491455, "critic_loss": 1.6263759789466858, "actor_loss": -90.7199246520996, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.510098934173584, "step": 97000}
{"episode_reward": 894.453146059581, "episode": 98.0, "batch_reward": 0.8362606325745583, "critic_loss": 1.640172735631466, "actor_loss": -90.16821279907226, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.81586980819702, "step": 98000}
{"episode_reward": 854.9876626804155, "episode": 99.0, "batch_reward": 0.8359885889291764, "critic_loss": 1.592645944595337, "actor_loss": -90.19594956970215, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.277519702911377, "step": 99000}
{"episode_reward": 893.9322769779801, "episode": 100.0, "batch_reward": 0.8388972843289375, "critic_loss": 1.6033708187937736, "actor_loss": -90.41011988830566, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.363574266433716, "step": 100000}
{"episode_reward": 933.6554389707164, "episode": 101.0, "batch_reward": 0.8388742901682854, "critic_loss": 1.6085846526622771, "actor_loss": -90.6253073425293, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.69772911071777, "step": 101000}
{"episode_reward": 988.8675247335304, "episode": 102.0, "batch_reward": 0.8388837508559227, "critic_loss": 1.6055066449046136, "actor_loss": -90.55339289855957, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.59020161628723, "step": 102000}
{"episode_reward": 968.535264836469, "episode": 103.0, "batch_reward": 0.8386052086353302, "critic_loss": 1.5672483971714974, "actor_loss": -90.57788818359376, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.434847831726074, "step": 103000}
{"episode_reward": 927.2230209881184, "episode": 104.0, "batch_reward": 0.8420520214438438, "critic_loss": 1.5052265477180482, "actor_loss": -90.68791424560547, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.767677307128906, "step": 104000}
{"episode_reward": 951.1387314133527, "episode": 105.0, "batch_reward": 0.8445591232180596, "critic_loss": 1.6034628373384476, "actor_loss": -90.85891386413574, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.26900339126587, "step": 105000}
{"episode_reward": 925.5820176912423, "episode": 106.0, "batch_reward": 0.8423902509212494, "critic_loss": 1.5693624807596207, "actor_loss": -90.48433882141113, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.78793978691101, "step": 106000}
{"episode_reward": 920.9959639529317, "episode": 107.0, "batch_reward": 0.8430892624258995, "critic_loss": 1.6100423181653023, "actor_loss": -90.70510710144043, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.340784072875977, "step": 107000}
{"episode_reward": 917.983190938571, "episode": 108.0, "batch_reward": 0.8461476578116417, "critic_loss": 1.507154303431511, "actor_loss": -90.85750318908691, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.455824851989746, "step": 108000}
{"episode_reward": 950.4996348749305, "episode": 109.0, "batch_reward": 0.8467587577700615, "critic_loss": 1.5686938920021056, "actor_loss": -91.10728742980957, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.361060857772827, "step": 109000}
{"episode_reward": 971.5707982762358, "episode": 110.0, "batch_reward": 0.8470184661746025, "critic_loss": 1.496811527132988, "actor_loss": -90.8965818786621, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.18680739402771, "step": 110000}
{"episode_reward": 931.767506052889, "episode": 111.0, "batch_reward": 0.8477288703918457, "critic_loss": 1.4509040098190307, "actor_loss": -91.32109149169922, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.10201716423035, "step": 111000}
{"episode_reward": 921.5405556242652, "episode": 112.0, "batch_reward": 0.8480306478142738, "critic_loss": 1.4207387462258338, "actor_loss": -91.01468096923828, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.917564153671265, "step": 112000}
{"episode_reward": 931.558012229757, "episode": 113.0, "batch_reward": 0.8494184812307358, "critic_loss": 1.4483208999037742, "actor_loss": -91.09195629882812, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.75402021408081, "step": 113000}
{"episode_reward": 930.1290353429863, "episode": 114.0, "batch_reward": 0.8501573536396027, "critic_loss": 1.4719814999103547, "actor_loss": -91.29878224182129, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.763543844223022, "step": 114000}
{"episode_reward": 972.4841963184147, "episode": 115.0, "batch_reward": 0.8503970994353295, "critic_loss": 1.4876965872049333, "actor_loss": -91.10760781860351, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.39099931716919, "step": 115000}
{"episode_reward": 918.5033101052419, "episode": 116.0, "batch_reward": 0.8510768900513649, "critic_loss": 1.4198801750540733, "actor_loss": -91.23450422668456, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.724721431732178, "step": 116000}
{"episode_reward": 947.7122622156472, "episode": 117.0, "batch_reward": 0.8530351542830468, "critic_loss": 1.4188662642240524, "actor_loss": -91.19335888671876, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 22.041242599487305, "step": 117000}
{"episode_reward": 932.546206237592, "episode": 118.0, "batch_reward": 0.8529474251270294, "critic_loss": 1.466960032105446, "actor_loss": -91.34963882446289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.918514251708984, "step": 118000}
{"episode_reward": 978.403181115422, "episode": 119.0, "batch_reward": 0.8545570538640023, "critic_loss": 1.434681814968586, "actor_loss": -91.44396459960937, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.709489583969116, "step": 119000}
{"episode_reward": 949.3740454033368, "episode": 120.0, "batch_reward": 0.8523955273628235, "critic_loss": 1.4175597280561925, "actor_loss": -91.04361277770997, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.7503182888031, "step": 120000}
{"episode_reward": 821.5540812061437, "episode": 121.0, "batch_reward": 0.8544186756610871, "critic_loss": 1.4176968890428543, "actor_loss": -91.28347210693359, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.91449236869812, "step": 121000}
{"episode_reward": 981.942903335279, "episode": 122.0, "batch_reward": 0.855017450094223, "critic_loss": 1.3956946955919265, "actor_loss": -91.25266540527343, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.38874578475952, "step": 122000}
{"episode_reward": 878.9394553232623, "episode": 123.0, "batch_reward": 0.8560127968788147, "critic_loss": 1.4047627891898156, "actor_loss": -90.81368829345703, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.467375993728638, "step": 123000}
{"episode_reward": 939.5159195842185, "episode": 124.0, "batch_reward": 0.8577165905237197, "critic_loss": 1.3735699394345284, "actor_loss": -91.33084873962402, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.651690006256104, "step": 124000}
{"episode_reward": 959.8014178299796, "episode": 125.0, "batch_reward": 0.859020802795887, "critic_loss": 1.4138292443156242, "actor_loss": -91.43134600830078, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.096052646636963, "step": 125000}
{"episode_reward": 982.4282650019911, "episode": 126.0, "batch_reward": 0.8580251009464264, "critic_loss": 1.3453586331605911, "actor_loss": -91.49279957580566, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.99938678741455, "step": 126000}
{"episode_reward": 971.4427820012819, "episode": 127.0, "batch_reward": 0.8585880828499795, "critic_loss": 1.3546158331036569, "actor_loss": -91.4491808013916, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.794860124588013, "step": 127000}
{"episode_reward": 937.5788629731968, "episode": 128.0, "batch_reward": 0.8595637364983558, "critic_loss": 1.3343505299091338, "actor_loss": -91.76373243713378, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.842153787612915, "step": 128000}
{"episode_reward": 980.4472877565308, "episode": 129.0, "batch_reward": 0.8602919237017631, "critic_loss": 1.3059979661107064, "actor_loss": -91.84062118530274, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.25406002998352, "step": 129000}
{"episode_reward": 981.5369693577237, "episode": 130.0, "batch_reward": 0.8621662825942039, "critic_loss": 1.2615397983789445, "actor_loss": -91.63669563293458, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.517457723617554, "step": 130000}
{"episode_reward": 989.5908911941787, "episode": 131.0, "batch_reward": 0.8643908121585846, "critic_loss": 1.301916658759117, "actor_loss": -92.03501162719726, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 41.447590351104736, "step": 131000}
{"episode_reward": 954.8135835517385, "episode": 132.0, "batch_reward": 0.8649869574904442, "critic_loss": 1.2656656492352485, "actor_loss": -91.7319789428711, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.57942533493042, "step": 132000}
{"episode_reward": 984.4403999274673, "episode": 133.0, "batch_reward": 0.8625895600914956, "critic_loss": 1.3099703515470027, "actor_loss": -91.79597076416016, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.504448175430298, "step": 133000}
{"episode_reward": 959.1207721675719, "episode": 134.0, "batch_reward": 0.8651236558556556, "critic_loss": 1.2594719400405885, "actor_loss": -91.90137406921387, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.255258321762085, "step": 134000}
{"episode_reward": 955.0644868031621, "episode": 135.0, "batch_reward": 0.8667282611131668, "critic_loss": 1.2312748408317566, "actor_loss": -91.95114093017578, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.4554226398468, "step": 135000}
{"episode_reward": 989.8024554772029, "episode": 136.0, "batch_reward": 0.8677886322140693, "critic_loss": 1.2193098933100701, "actor_loss": -92.27355766296387, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.897217988967896, "step": 136000}
{"episode_reward": 989.7041244416986, "episode": 137.0, "batch_reward": 0.8668600513339043, "critic_loss": 1.241930883616209, "actor_loss": -91.79726194763184, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.13943076133728, "step": 137000}
{"episode_reward": 978.3002379005356, "episode": 138.0, "batch_reward": 0.8688569682836532, "critic_loss": 1.2801009542942048, "actor_loss": -91.73764491271973, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.831672191619873, "step": 138000}
{"episode_reward": 949.7571224459592, "episode": 139.0, "batch_reward": 0.8688074200749397, "critic_loss": 1.2795128433704377, "actor_loss": -91.82066227722169, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.24894666671753, "step": 139000}
{"episode_reward": 989.7621949756192, "episode": 140.0, "batch_reward": 0.8702658412456512, "critic_loss": 1.2548594259023667, "actor_loss": -91.79311415100098, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.530553102493286, "step": 140000}
{"episode_reward": 940.953631594249, "episode": 141.0, "batch_reward": 0.8703523679971695, "critic_loss": 1.3073302379846572, "actor_loss": -91.71536099243164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 42.20877742767334, "step": 141000}
{"episode_reward": 948.8102190290435, "episode": 142.0, "batch_reward": 0.8706680173277855, "critic_loss": 1.3409929826557636, "actor_loss": -91.95234393310547, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.40492033958435, "step": 142000}
{"episode_reward": 989.737969121197, "episode": 143.0, "batch_reward": 0.8715154840350151, "critic_loss": 1.3509593008756637, "actor_loss": -92.03933642578124, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.583308458328247, "step": 143000}
{"episode_reward": 948.9662162804244, "episode": 144.0, "batch_reward": 0.8722321296334267, "critic_loss": 1.3601846717000008, "actor_loss": -92.12348170471192, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.14183783531189, "step": 144000}
{"episode_reward": 959.7277939942014, "episode": 145.0, "batch_reward": 0.8734395080208779, "critic_loss": 1.2665512352883816, "actor_loss": -92.10196345520019, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.41349220275879, "step": 145000}
{"episode_reward": 977.5474947879665, "episode": 146.0, "batch_reward": 0.8728366347551346, "critic_loss": 1.2791723740696908, "actor_loss": -92.03378448486328, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.848323345184326, "step": 146000}
{"episode_reward": 947.3715730663756, "episode": 147.0, "batch_reward": 0.8731861900687218, "critic_loss": 1.2204482626914979, "actor_loss": -92.1681297302246, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.006396055221558, "step": 147000}
{"episode_reward": 945.980751511815, "episode": 148.0, "batch_reward": 0.8759200562238694, "critic_loss": 1.18383023712039, "actor_loss": -92.02563278198242, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.488060474395752, "step": 148000}
{"episode_reward": 977.7002153818491, "episode": 149.0, "batch_reward": 0.8745394133925438, "critic_loss": 1.2594290591180324, "actor_loss": -92.1091363067627, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 21.767937183380127, "step": 149000}
{"episode_reward": 934.2261830487391, "episode": 150.0, "batch_reward": 0.8762323349714279, "critic_loss": 1.1820776354074478, "actor_loss": -92.2450961303711, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
