{"episode_reward": 0.0, "episode": 1.0, "duration": 20.43300700187683, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.7639830112457275, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.5002037471594434, "critic_loss": 0.7613912025723071, "actor_loss": -89.56322930173046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.34618806838989, "step": 3000}
{"episode_reward": 894.0754396412568, "episode": 4.0, "batch_reward": 0.6155884991586208, "critic_loss": 0.9196717742085457, "actor_loss": -95.43476423645019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.158119678497314, "step": 4000}
{"episode_reward": 558.2080417045917, "episode": 5.0, "batch_reward": 0.6389202953577041, "critic_loss": 1.1176470273137094, "actor_loss": -97.795728805542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.161380529403687, "step": 5000}
{"episode_reward": 963.1717974627365, "episode": 6.0, "batch_reward": 0.6909006826877594, "critic_loss": 1.6639119622707368, "actor_loss": -99.09846621704102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15470051765442, "step": 6000}
{"episode_reward": 883.3275932189089, "episode": 7.0, "batch_reward": 0.6555082920491695, "critic_loss": 3.4030921827554703, "actor_loss": -103.95942837524414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16177988052368, "step": 7000}
{"episode_reward": 31.83221684595203, "episode": 8.0, "batch_reward": 0.580583642989397, "critic_loss": 3.5046395840644835, "actor_loss": -110.07280380249023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.202357053756714, "step": 8000}
{"episode_reward": 85.74435678366068, "episode": 9.0, "batch_reward": 0.5152124291956425, "critic_loss": 4.357474488735199, "actor_loss": -112.55522937011719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21875, "step": 9000}
{"episode_reward": 27.982813759524564, "episode": 10.0, "batch_reward": 0.4750185134112835, "critic_loss": 5.424198319673538, "actor_loss": -116.6944934387207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.210448026657104, "step": 10000}
{"episode_reward": 122.82098016452355, "episode": 11.0, "batch_reward": 0.43895469525456426, "critic_loss": 5.669002094030381, "actor_loss": -118.74989250183106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.76441693305969, "step": 11000}
{"episode_reward": 102.61668368493352, "episode": 12.0, "batch_reward": 0.40282270711660384, "critic_loss": 6.235282942056656, "actor_loss": -120.93982749938965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16286039352417, "step": 12000}
{"episode_reward": 27.77659583290979, "episode": 13.0, "batch_reward": 0.37344561928510667, "critic_loss": 7.085588165521622, "actor_loss": -122.16314228820801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16963505744934, "step": 13000}
{"episode_reward": 31.040560172920642, "episode": 14.0, "batch_reward": 0.3534781678915024, "critic_loss": 7.321157388210296, "actor_loss": -126.13331306457519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.200817584991455, "step": 14000}
{"episode_reward": 99.3607023259521, "episode": 15.0, "batch_reward": 0.33527996915578845, "critic_loss": 6.023059854269028, "actor_loss": -121.43793206787109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15258479118347, "step": 15000}
{"episode_reward": 37.82608141156244, "episode": 16.0, "batch_reward": 0.3134588945060968, "critic_loss": 5.779833871126175, "actor_loss": -120.94499337768555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.205872774124146, "step": 16000}
{"episode_reward": 29.093067683599795, "episode": 17.0, "batch_reward": 0.29396313525736334, "critic_loss": 6.716836351156235, "actor_loss": -123.93175543212891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.22333288192749, "step": 17000}
{"episode_reward": 31.315968498229186, "episode": 18.0, "batch_reward": 0.2840983029305935, "critic_loss": 8.444562012672424, "actor_loss": -124.31891931152344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.184250116348267, "step": 18000}
{"episode_reward": 363.1097456371333, "episode": 19.0, "batch_reward": 0.2827265973985195, "critic_loss": 7.842360798358917, "actor_loss": -122.76792691040039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.195765733718872, "step": 19000}
{"episode_reward": 9.696823567075175, "episode": 20.0, "batch_reward": 0.27153093068301676, "critic_loss": 7.1258856749534605, "actor_loss": -123.26857765197754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.180771350860596, "step": 20000}
{"episode_reward": 118.63011024445723, "episode": 21.0, "batch_reward": 0.2696822948306799, "critic_loss": 6.15524161195755, "actor_loss": -123.29886778259278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.75165295600891, "step": 21000}
{"episode_reward": 159.91698287538748, "episode": 22.0, "batch_reward": 0.2565133469551802, "critic_loss": 4.523594203948974, "actor_loss": -124.19261334228516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.198527336120605, "step": 22000}
{"episode_reward": 18.141265121384865, "episode": 23.0, "batch_reward": 0.24968425814807416, "critic_loss": 3.771062514424324, "actor_loss": -126.37710032653808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.194498538970947, "step": 23000}
{"episode_reward": 105.56153203749156, "episode": 24.0, "batch_reward": 0.24169081957638264, "critic_loss": 2.8802548801898955, "actor_loss": -122.60435081481934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.196021795272827, "step": 24000}
{"episode_reward": 71.37173346244928, "episode": 25.0, "batch_reward": 0.23554373709857465, "critic_loss": 2.576710942745209, "actor_loss": -124.42218215942383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.175611972808838, "step": 25000}
{"episode_reward": 36.015310294135965, "episode": 26.0, "batch_reward": 0.2280030341744423, "critic_loss": 2.2652516695261, "actor_loss": -121.4271251373291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1973557472229, "step": 26000}
{"episode_reward": 39.775293953786914, "episode": 27.0, "batch_reward": 0.2212424635887146, "critic_loss": 1.945741574048996, "actor_loss": -119.33451283264161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23401117324829, "step": 27000}
{"episode_reward": 61.9064517751275, "episode": 28.0, "batch_reward": 0.21398616257309913, "critic_loss": 1.8081929712295532, "actor_loss": -117.55552186584472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.222333431243896, "step": 28000}
{"episode_reward": 84.4508884919397, "episode": 29.0, "batch_reward": 0.2171367055028677, "critic_loss": 1.8608423912525176, "actor_loss": -113.09671069335937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.172075271606445, "step": 29000}
{"episode_reward": 570.5561550079295, "episode": 30.0, "batch_reward": 0.23354080675542355, "critic_loss": 1.7683536051511763, "actor_loss": -111.63586460876465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.158718585968018, "step": 30000}
{"episode_reward": 846.3902108264472, "episode": 31.0, "batch_reward": 0.2489688138961792, "critic_loss": 1.691023257315159, "actor_loss": -109.51194508361816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.53410029411316, "step": 31000}
{"episode_reward": 408.8622626561841, "episode": 32.0, "batch_reward": 0.24889769162237643, "critic_loss": 1.5426537808775902, "actor_loss": -104.90474742126464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.162280082702637, "step": 32000}
{"episode_reward": 194.7188548812558, "episode": 33.0, "batch_reward": 0.2594200997799635, "critic_loss": 1.4773791677951813, "actor_loss": -103.19366018676757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16425585746765, "step": 33000}
{"episode_reward": 920.765099228876, "episode": 34.0, "batch_reward": 0.2804353365600109, "critic_loss": 1.5485935294032096, "actor_loss": -104.82030047607422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19485878944397, "step": 34000}
{"episode_reward": 956.9847858498504, "episode": 35.0, "batch_reward": 0.2969002887159586, "critic_loss": 1.5720845631361007, "actor_loss": -101.25518032836914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14673900604248, "step": 35000}
{"episode_reward": 902.7070109720843, "episode": 36.0, "batch_reward": 0.31291924104094504, "critic_loss": 1.6929090744256974, "actor_loss": -100.62700283813477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.148104429244995, "step": 36000}
{"episode_reward": 856.7998953654487, "episode": 37.0, "batch_reward": 0.3298331610560417, "critic_loss": 1.7826738448143005, "actor_loss": -100.36885932922364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.195096492767334, "step": 37000}
{"episode_reward": 852.2762389495576, "episode": 38.0, "batch_reward": 0.34442475524544713, "critic_loss": 1.7931295867562294, "actor_loss": -99.66682708740234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19731831550598, "step": 38000}
{"episode_reward": 985.2039788660877, "episode": 39.0, "batch_reward": 0.3604463122934103, "critic_loss": 1.6962211285233497, "actor_loss": -98.10345166015625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.181004524230957, "step": 39000}
{"episode_reward": 942.2678385315705, "episode": 40.0, "batch_reward": 0.3772200608849525, "critic_loss": 1.4814835100769996, "actor_loss": -99.30767213439941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14254903793335, "step": 40000}
{"episode_reward": 981.786742360925, "episode": 41.0, "batch_reward": 0.388000431984663, "critic_loss": 1.294381287932396, "actor_loss": -98.68646383666992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.35822010040283, "step": 41000}
{"episode_reward": 918.3644261116825, "episode": 42.0, "batch_reward": 0.4016737715303898, "critic_loss": 1.2292749859690666, "actor_loss": -98.68580033874511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.178502798080444, "step": 42000}
{"episode_reward": 880.5839480625815, "episode": 43.0, "batch_reward": 0.4152471233308315, "critic_loss": 1.178854043364525, "actor_loss": -98.38245703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17642831802368, "step": 43000}
{"episode_reward": 951.0081551186705, "episode": 44.0, "batch_reward": 0.4284405914247036, "critic_loss": 1.137254742383957, "actor_loss": -98.88553410339355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.185725450515747, "step": 44000}
{"episode_reward": 986.2358339817112, "episode": 45.0, "batch_reward": 0.4388190471529961, "critic_loss": 1.02747058904171, "actor_loss": -97.20678538513184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.151504278182983, "step": 45000}
{"episode_reward": 887.6382200948703, "episode": 46.0, "batch_reward": 0.4476696141958237, "critic_loss": 0.95368624573946, "actor_loss": -96.88595297241211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17208504676819, "step": 46000}
{"episode_reward": 944.4288238211386, "episode": 47.0, "batch_reward": 0.4606170538663864, "critic_loss": 0.9376011660695076, "actor_loss": -96.64053109741211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.152432441711426, "step": 47000}
{"episode_reward": 956.2135700514768, "episode": 48.0, "batch_reward": 0.4712122320830822, "critic_loss": 0.8484439486563206, "actor_loss": -96.32986145019531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18196988105774, "step": 48000}
{"episode_reward": 934.1882738500308, "episode": 49.0, "batch_reward": 0.48094285881519316, "critic_loss": 0.8412352148592472, "actor_loss": -95.18379829406739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.187055110931396, "step": 49000}
{"episode_reward": 906.4675542139393, "episode": 50.0, "batch_reward": 0.4867707082331181, "critic_loss": 0.8492127822935581, "actor_loss": -94.8250364227295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18176770210266, "step": 50000}
{"episode_reward": 985.3691517290263, "episode": 51.0, "batch_reward": 0.498952651232481, "critic_loss": 0.9035304233431816, "actor_loss": -95.12669813537597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.44036078453064, "step": 51000}
{"episode_reward": 983.9340044490967, "episode": 52.0, "batch_reward": 0.5061800826191902, "critic_loss": 0.9505621410906315, "actor_loss": -94.0782261352539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1930513381958, "step": 52000}
{"episode_reward": 931.2259818733481, "episode": 53.0, "batch_reward": 0.5174368851482868, "critic_loss": 0.9372090058326721, "actor_loss": -94.10091958618165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16964864730835, "step": 53000}
{"episode_reward": 950.5623516105896, "episode": 54.0, "batch_reward": 0.5214196327328682, "critic_loss": 0.8324158704280853, "actor_loss": -93.97132354736328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18722939491272, "step": 54000}
{"episode_reward": 908.2348008761485, "episode": 55.0, "batch_reward": 0.5330514322817326, "critic_loss": 0.7250921514034271, "actor_loss": -94.27176568603515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.145017862319946, "step": 55000}
{"episode_reward": 972.1606047216743, "episode": 56.0, "batch_reward": 0.5409001537561416, "critic_loss": 0.6850686227977276, "actor_loss": -93.36627717590332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1746187210083, "step": 56000}
{"episode_reward": 983.6888798240991, "episode": 57.0, "batch_reward": 0.5477824752628804, "critic_loss": 0.6381214693188667, "actor_loss": -92.96267790222169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.188417673110962, "step": 57000}
{"episode_reward": 961.7585809790824, "episode": 58.0, "batch_reward": 0.555332364588976, "critic_loss": 0.6279564865231514, "actor_loss": -93.19844523620606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20564556121826, "step": 58000}
{"episode_reward": 970.6400775838214, "episode": 59.0, "batch_reward": 0.5620150555372239, "critic_loss": 0.6678145079910756, "actor_loss": -92.59485455322266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19292140007019, "step": 59000}
{"episode_reward": 935.2377489357176, "episode": 60.0, "batch_reward": 0.5669282711446285, "critic_loss": 0.674185692936182, "actor_loss": -92.29402772521972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18117904663086, "step": 60000}
{"episode_reward": 942.2057653202951, "episode": 61.0, "batch_reward": 0.574134950876236, "critic_loss": 0.6679329580962657, "actor_loss": -92.20413584899903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.415467500686646, "step": 61000}
{"episode_reward": 940.743292080653, "episode": 62.0, "batch_reward": 0.5796969165802002, "critic_loss": 0.6620050953924655, "actor_loss": -92.12151651000977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.147223472595215, "step": 62000}
{"episode_reward": 965.1085676430849, "episode": 63.0, "batch_reward": 0.585183146417141, "critic_loss": 0.6421315421462059, "actor_loss": -91.88912829589843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.149896144866943, "step": 63000}
{"episode_reward": 923.8793696888661, "episode": 64.0, "batch_reward": 0.5896603469848632, "critic_loss": 0.6588770656883717, "actor_loss": -91.78313502502441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18249535560608, "step": 64000}
{"episode_reward": 962.7643937981998, "episode": 65.0, "batch_reward": 0.5953666832745075, "critic_loss": 0.6810653072297573, "actor_loss": -91.57177825927734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.160359382629395, "step": 65000}
{"episode_reward": 955.2652787130149, "episode": 66.0, "batch_reward": 0.6036824487745762, "critic_loss": 0.6751863158643245, "actor_loss": -91.4703304901123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.171452283859253, "step": 66000}
{"episode_reward": 918.2516117838139, "episode": 67.0, "batch_reward": 0.6082056436836719, "critic_loss": 0.6750587816238404, "actor_loss": -91.1878699798584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17164134979248, "step": 67000}
{"episode_reward": 929.9243302216712, "episode": 68.0, "batch_reward": 0.610790304839611, "critic_loss": 0.6902989844530821, "actor_loss": -91.34936463928223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20706081390381, "step": 68000}
{"episode_reward": 955.6534449073719, "episode": 69.0, "batch_reward": 0.6165037634968757, "critic_loss": 0.6936072957515717, "actor_loss": -91.11801290893554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.212024927139282, "step": 69000}
{"episode_reward": 984.0216130901375, "episode": 70.0, "batch_reward": 0.6211432576179504, "critic_loss": 0.7472337047457696, "actor_loss": -90.93712335205078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.198028802871704, "step": 70000}
{"episode_reward": 908.409430651439, "episode": 71.0, "batch_reward": 0.6264912373423577, "critic_loss": 0.8201682774722576, "actor_loss": -91.08059614562988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.415228605270386, "step": 71000}
{"episode_reward": 905.6906793149518, "episode": 72.0, "batch_reward": 0.6316060431003571, "critic_loss": 0.8478517206013203, "actor_loss": -90.95679014587402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.156174898147583, "step": 72000}
{"episode_reward": 950.5488769059231, "episode": 73.0, "batch_reward": 0.6343289753198623, "critic_loss": 1.1316483636796475, "actor_loss": -90.81802006530762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14392924308777, "step": 73000}
{"episode_reward": 936.8711456866819, "episode": 74.0, "batch_reward": 0.6397549840807915, "critic_loss": 1.3141673651337624, "actor_loss": -90.73599583435059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.161288261413574, "step": 74000}
{"episode_reward": 944.2420932863583, "episode": 75.0, "batch_reward": 0.6425068159997464, "critic_loss": 1.4425448739528657, "actor_loss": -90.61512455749512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.165480613708496, "step": 75000}
{"episode_reward": 956.7505512023195, "episode": 76.0, "batch_reward": 0.6456089789271354, "critic_loss": 2.0822566244602205, "actor_loss": -90.53677754211425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.169623851776123, "step": 76000}
{"episode_reward": 939.2734045811018, "episode": 77.0, "batch_reward": 0.6462623081803321, "critic_loss": 2.6393953600525855, "actor_loss": -90.63363771057129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.181968450546265, "step": 77000}
{"episode_reward": 647.8245579121436, "episode": 78.0, "batch_reward": 0.6509096128344536, "critic_loss": 4.0982002581954005, "actor_loss": -90.95164024353028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14589238166809, "step": 78000}
{"episode_reward": 861.7538532513092, "episode": 79.0, "batch_reward": 0.6467536981701851, "critic_loss": 5.811797837972641, "actor_loss": -92.0383758392334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.210163116455078, "step": 79000}
{"episode_reward": 34.18930548631742, "episode": 80.0, "batch_reward": 0.641756526529789, "critic_loss": 7.549363114118576, "actor_loss": -94.1792571105957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.222809076309204, "step": 80000}
{"episode_reward": 18.70238161123243, "episode": 81.0, "batch_reward": 0.6328166593313217, "critic_loss": 9.631306635856628, "actor_loss": -95.73991444396972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.732431173324585, "step": 81000}
{"episode_reward": 92.21730131565803, "episode": 82.0, "batch_reward": 0.6262293051481247, "critic_loss": 10.695878606557846, "actor_loss": -98.84685780334473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.195768117904663, "step": 82000}
{"episode_reward": 17.06941225335476, "episode": 83.0, "batch_reward": 0.6180967934727669, "critic_loss": 10.623886936187745, "actor_loss": -101.49108934020997, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17126178741455, "step": 83000}
{"episode_reward": 61.02220885255872, "episode": 84.0, "batch_reward": 0.6129966583848, "critic_loss": 9.140147550582885, "actor_loss": -102.54285708618164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20019245147705, "step": 84000}
{"episode_reward": 74.83283918117453, "episode": 85.0, "batch_reward": 0.602722407490015, "critic_loss": 7.736845332145691, "actor_loss": -102.82605610656738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.202648162841797, "step": 85000}
{"episode_reward": 42.27442411592488, "episode": 86.0, "batch_reward": 0.5978557434082031, "critic_loss": 7.630987648010254, "actor_loss": -103.82582725524902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23155689239502, "step": 86000}
{"episode_reward": 53.88209951802757, "episode": 87.0, "batch_reward": 0.5922047995626927, "critic_loss": 7.17876611161232, "actor_loss": -105.42454077148437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21569585800171, "step": 87000}
{"episode_reward": 156.25184720111483, "episode": 88.0, "batch_reward": 0.5873284970223903, "critic_loss": 7.729488658905029, "actor_loss": -105.77533049011231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.221867084503174, "step": 88000}
{"episode_reward": 95.91859454275138, "episode": 89.0, "batch_reward": 0.5807117247283459, "critic_loss": 5.850527122497558, "actor_loss": -104.73509593200684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19232678413391, "step": 89000}
{"episode_reward": 119.87155309189932, "episode": 90.0, "batch_reward": 0.5814106730818749, "critic_loss": 5.844442032337189, "actor_loss": -104.9133472442627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.203386545181274, "step": 90000}
{"episode_reward": 915.8417381343814, "episode": 91.0, "batch_reward": 0.5862181048989296, "critic_loss": 5.415223300218583, "actor_loss": -105.90890548706055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.5267653465271, "step": 91000}
{"episode_reward": 950.7834627982147, "episode": 92.0, "batch_reward": 0.585916505932808, "critic_loss": 5.605932296514511, "actor_loss": -105.56040118408202, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.169652223587036, "step": 92000}
{"episode_reward": 35.93721325690687, "episode": 93.0, "batch_reward": 0.5812050352692604, "critic_loss": 5.249869639635086, "actor_loss": -106.43242790222168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.140878200531006, "step": 93000}
{"episode_reward": 983.5288960986143, "episode": 94.0, "batch_reward": 0.586958665907383, "critic_loss": 4.9221455764770505, "actor_loss": -106.07144860839844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14243984222412, "step": 94000}
{"episode_reward": 951.3550569177575, "episode": 95.0, "batch_reward": 0.5919634998738765, "critic_loss": 4.867420048475266, "actor_loss": -104.92777795410156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.145533800125122, "step": 95000}
{"episode_reward": 955.4953373302061, "episode": 96.0, "batch_reward": 0.5949881884157657, "critic_loss": 5.293417722702026, "actor_loss": -105.45472729492188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.13015627861023, "step": 96000}
{"episode_reward": 954.1566099884058, "episode": 97.0, "batch_reward": 0.601074835896492, "critic_loss": 4.879888244390488, "actor_loss": -104.60763154602051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.149977207183838, "step": 97000}
{"episode_reward": 937.4302457908465, "episode": 98.0, "batch_reward": 0.6022911422848701, "critic_loss": 5.428618395328522, "actor_loss": -105.01544160461425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19275403022766, "step": 98000}
{"episode_reward": 892.6285310542202, "episode": 99.0, "batch_reward": 0.6043232444226742, "critic_loss": 5.753995874881745, "actor_loss": -104.84843341064453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16824221611023, "step": 99000}
{"episode_reward": 973.7685925071223, "episode": 100.0, "batch_reward": 0.610669041544199, "critic_loss": 5.8668397917747495, "actor_loss": -104.91601501464844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16699719429016, "step": 100000}
{"episode_reward": 933.2877215526236, "episode": 101.0, "batch_reward": 0.6107272022366523, "critic_loss": 5.874962112307548, "actor_loss": -103.44394689941406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.4240300655365, "step": 101000}
{"episode_reward": 990.3889939972673, "episode": 102.0, "batch_reward": 0.613465977281332, "critic_loss": 5.999685120463371, "actor_loss": -103.43129562377929, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15086555480957, "step": 102000}
{"episode_reward": 945.9465516433626, "episode": 103.0, "batch_reward": 0.6149544936418533, "critic_loss": 6.779069446802139, "actor_loss": -103.80953927612305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16500234603882, "step": 103000}
{"episode_reward": 25.37636902409997, "episode": 104.0, "batch_reward": 0.6113577940165996, "critic_loss": 9.03340688931942, "actor_loss": -104.42116091918945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.163249731063843, "step": 104000}
{"episode_reward": 500.5966622827116, "episode": 105.0, "batch_reward": 0.6115570148229599, "critic_loss": 8.672155183196068, "actor_loss": -105.5196420135498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.167572021484375, "step": 105000}
{"episode_reward": 388.9880944293528, "episode": 106.0, "batch_reward": 0.6087495414018631, "critic_loss": 8.969563354492188, "actor_loss": -105.62582020568847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.157844066619873, "step": 106000}
{"episode_reward": 925.3004155249356, "episode": 107.0, "batch_reward": 0.609045514523983, "critic_loss": 9.568071244835853, "actor_loss": -104.64297665405273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.197036027908325, "step": 107000}
{"episode_reward": 24.006341265772388, "episode": 108.0, "batch_reward": 0.6065976385474205, "critic_loss": 9.699778944015502, "actor_loss": -104.64082604980469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15451693534851, "step": 108000}
{"episode_reward": 38.19016733376995, "episode": 109.0, "batch_reward": 0.6039548349678516, "critic_loss": 9.436390412092209, "actor_loss": -104.55134031677247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.166141271591187, "step": 109000}
{"episode_reward": 953.4849010638732, "episode": 110.0, "batch_reward": 0.6050265069901943, "critic_loss": 11.156245697975159, "actor_loss": -103.66719508361817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15967893600464, "step": 110000}
{"episode_reward": 942.8144527287214, "episode": 111.0, "batch_reward": 0.6115636669099331, "critic_loss": 15.41433378481865, "actor_loss": -104.28073519897461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.47252035140991, "step": 111000}
{"episode_reward": 948.1662696999908, "episode": 112.0, "batch_reward": 0.6140330399274826, "critic_loss": 20.64099982213974, "actor_loss": -105.9079761505127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16092085838318, "step": 112000}
{"episode_reward": 727.1323617594412, "episode": 113.0, "batch_reward": 0.609570377856493, "critic_loss": 24.372826892375947, "actor_loss": -107.73827015686035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.153334856033325, "step": 113000}
{"episode_reward": 36.03273655376324, "episode": 114.0, "batch_reward": 0.6067559740841388, "critic_loss": 23.798018239974976, "actor_loss": -107.5779559173584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.147492170333862, "step": 114000}
{"episode_reward": 708.9692741631975, "episode": 115.0, "batch_reward": 0.6050459490716458, "critic_loss": 22.65790342473984, "actor_loss": -111.04572225952148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.189956188201904, "step": 115000}
{"episode_reward": 5.368705736967744, "episode": 116.0, "batch_reward": 0.6002761035859585, "critic_loss": 23.39115719652176, "actor_loss": -113.50408950805664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.195462942123413, "step": 116000}
{"episode_reward": 15.295128954494926, "episode": 117.0, "batch_reward": 0.5931293384730816, "critic_loss": 24.323283177375792, "actor_loss": -118.86119989013672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.212785005569458, "step": 117000}
{"episode_reward": 7.39921716535953, "episode": 118.0, "batch_reward": 0.589283287703991, "critic_loss": 23.672420372486116, "actor_loss": -119.85037506103515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18826937675476, "step": 118000}
{"episode_reward": 42.11190685842525, "episode": 119.0, "batch_reward": 0.5843272699415684, "critic_loss": 21.81454117679596, "actor_loss": -126.58140600585938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.232787609100342, "step": 119000}
{"episode_reward": 17.21951703056243, "episode": 120.0, "batch_reward": 0.5798780362010002, "critic_loss": 20.674210186958312, "actor_loss": -131.64450006103516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19377636909485, "step": 120000}
{"episode_reward": 13.693083145773647, "episode": 121.0, "batch_reward": 0.5779596679210662, "critic_loss": 20.20216750431061, "actor_loss": -132.97645977783202, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.780460596084595, "step": 121000}
{"episode_reward": 70.85326792936996, "episode": 122.0, "batch_reward": 0.5716641749143601, "critic_loss": 23.78037650871277, "actor_loss": -134.487423248291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.211357831954956, "step": 122000}
{"episode_reward": 10.082319938230802, "episode": 123.0, "batch_reward": 0.5668551883399486, "critic_loss": 32.735626478195194, "actor_loss": -139.33526477050782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.220735549926758, "step": 123000}
{"episode_reward": 15.801296482008597, "episode": 124.0, "batch_reward": 0.563504830867052, "critic_loss": 43.69730677986145, "actor_loss": -139.74866275024414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.215094566345215, "step": 124000}
{"episode_reward": 94.36980398818565, "episode": 125.0, "batch_reward": 0.5584832371175289, "critic_loss": 75.01149452781678, "actor_loss": -152.8710835723877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.181236743927002, "step": 125000}
{"episode_reward": 92.73079020237564, "episode": 126.0, "batch_reward": 0.5538614361286164, "critic_loss": 84.03149230957031, "actor_loss": -157.8506132507324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.218767404556274, "step": 126000}
{"episode_reward": 45.06180059053725, "episode": 127.0, "batch_reward": 0.5518549025356769, "critic_loss": 71.80179391098022, "actor_loss": -167.78910713195802, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.187185764312744, "step": 127000}
{"episode_reward": 76.97044624256712, "episode": 128.0, "batch_reward": 0.5469753763377666, "critic_loss": 56.058615837097165, "actor_loss": -172.75588360595702, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.220115661621094, "step": 128000}
{"episode_reward": 19.95063045144904, "episode": 129.0, "batch_reward": 0.5459317923486233, "critic_loss": 52.84726603317261, "actor_loss": -174.8720055541992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21428656578064, "step": 129000}
{"episode_reward": 22.39626712473855, "episode": 130.0, "batch_reward": 0.5385852693915367, "critic_loss": 51.64941978263855, "actor_loss": -183.7053441772461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.223429203033447, "step": 130000}
{"episode_reward": 28.640512508184376, "episode": 131.0, "batch_reward": 0.5351980123817921, "critic_loss": 49.28602913665772, "actor_loss": -184.73802041625976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.730422496795654, "step": 131000}
{"episode_reward": 28.35469535236813, "episode": 132.0, "batch_reward": 0.5308944931924343, "critic_loss": 42.80838424491883, "actor_loss": -190.1297381286621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.209139108657837, "step": 132000}
{"episode_reward": 25.314977697338787, "episode": 133.0, "batch_reward": 0.5249986158013343, "critic_loss": 41.155924577713016, "actor_loss": -185.42131619262696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21952795982361, "step": 133000}
{"episode_reward": 23.723242090882295, "episode": 134.0, "batch_reward": 0.5235508208870888, "critic_loss": 36.67680429267883, "actor_loss": -183.43468112182617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1959810256958, "step": 134000}
{"episode_reward": 26.04420994616943, "episode": 135.0, "batch_reward": 0.521501580119133, "critic_loss": 31.367248237609864, "actor_loss": -191.71488883972168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.234883546829224, "step": 135000}
{"episode_reward": 118.40058927953952, "episode": 136.0, "batch_reward": 0.5184512878358364, "critic_loss": 27.052482201576233, "actor_loss": -188.08516616821288, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16754961013794, "step": 136000}
{"episode_reward": 187.16433258123024, "episode": 137.0, "batch_reward": 0.5153139294683933, "critic_loss": 25.35540584564209, "actor_loss": -188.36701640319825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.170985460281372, "step": 137000}
{"episode_reward": 472.9729177236869, "episode": 138.0, "batch_reward": 0.5162499662339687, "critic_loss": 23.481553442001342, "actor_loss": -189.74178532409667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.187385082244873, "step": 138000}
{"episode_reward": 535.3275092772922, "episode": 139.0, "batch_reward": 0.514191664069891, "critic_loss": 19.501363357543944, "actor_loss": -185.76052494812012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.507702350616455, "step": 139000}
{"episode_reward": 780.5695278237179, "episode": 140.0, "batch_reward": 0.5186584079265595, "critic_loss": 15.33359940481186, "actor_loss": -184.80144076538085, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23694133758545, "step": 140000}
{"episode_reward": 767.9780980689559, "episode": 141.0, "batch_reward": 0.5224096605479718, "critic_loss": 12.857390013694763, "actor_loss": -182.90086193847657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.472832441329956, "step": 141000}
{"episode_reward": 941.7382026096363, "episode": 142.0, "batch_reward": 0.5262338776290417, "critic_loss": 10.494457345485687, "actor_loss": -178.40806384277343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52526330947876, "step": 142000}
{"episode_reward": 979.8318667215569, "episode": 143.0, "batch_reward": 0.527235702842474, "critic_loss": 8.978784426689147, "actor_loss": -175.7883486328125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17607879638672, "step": 143000}
{"episode_reward": 69.26906713681657, "episode": 144.0, "batch_reward": 0.5222895243167878, "critic_loss": 8.103745541810989, "actor_loss": -173.05728350830077, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15794539451599, "step": 144000}
{"episode_reward": 676.1303467714038, "episode": 145.0, "batch_reward": 0.5261925319731235, "critic_loss": 6.827899504423142, "actor_loss": -168.29014649963378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.195263147354126, "step": 145000}
{"episode_reward": 953.6108950975868, "episode": 146.0, "batch_reward": 0.5278405272066593, "critic_loss": 6.510117974758148, "actor_loss": -161.03697302246093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.202388525009155, "step": 146000}
{"episode_reward": 958.821900076356, "episode": 147.0, "batch_reward": 0.5331550141870975, "critic_loss": 5.839866755485534, "actor_loss": -161.39221646118165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.218175411224365, "step": 147000}
{"episode_reward": 934.1491163945927, "episode": 148.0, "batch_reward": 0.5365020861923695, "critic_loss": 5.035962714910507, "actor_loss": -159.67924919128419, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20895504951477, "step": 148000}
{"episode_reward": 984.563323985716, "episode": 149.0, "batch_reward": 0.5338918980956078, "critic_loss": 4.507053115129471, "actor_loss": -157.01391368103026, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.220956087112427, "step": 149000}
{"episode_reward": 28.129553073222144, "episode": 150.0, "batch_reward": 0.5315651788413525, "critic_loss": 3.8841800775527955, "actor_loss": -153.3900203552246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
