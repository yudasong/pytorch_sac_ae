{"episode_reward": 0.0, "episode": 1.0, "duration": 21.167859077453613, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.8347558975219727, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.4578735365117141, "critic_loss": 0.16007616216327378, "actor_loss": -21.01044844173375, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 60.44032406806946, "step": 3000}
{"episode_reward": 158.12743993289828, "episode": 4.0, "batch_reward": 0.34528699550032615, "critic_loss": 0.32752963867783547, "actor_loss": -27.80791987991333, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.277724504470825, "step": 4000}
{"episode_reward": 237.8355683528358, "episode": 5.0, "batch_reward": 0.3628486609905958, "critic_loss": 0.6136491171866655, "actor_loss": -28.34010036277771, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.299434900283813, "step": 5000}
{"episode_reward": 576.8692217550566, "episode": 6.0, "batch_reward": 0.3589084630608559, "critic_loss": 0.7987950809001922, "actor_loss": -30.3070324382782, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.337825298309326, "step": 6000}
{"episode_reward": 219.6423911946793, "episode": 7.0, "batch_reward": 0.37470470303297043, "critic_loss": 0.9706519708931446, "actor_loss": -34.601341018676756, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.29130268096924, "step": 7000}
{"episode_reward": 556.5057301391216, "episode": 8.0, "batch_reward": 0.40088174000382426, "critic_loss": 1.231938470005989, "actor_loss": -36.83325261306763, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.291824340820312, "step": 8000}
{"episode_reward": 656.915222492434, "episode": 9.0, "batch_reward": 0.4225317375063896, "critic_loss": 1.5001352317929268, "actor_loss": -41.2836496925354, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.29350519180298, "step": 9000}
{"episode_reward": 505.0257351385034, "episode": 10.0, "batch_reward": 0.4410200914144516, "critic_loss": 1.521957223057747, "actor_loss": -43.41541188430786, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.285314321517944, "step": 10000}
{"episode_reward": 685.2164841753635, "episode": 11.0, "batch_reward": 0.4488041878640652, "critic_loss": 1.4505030453205108, "actor_loss": -47.908613594055176, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.2575159072876, "step": 11000}
{"episode_reward": 312.1277469069693, "episode": 12.0, "batch_reward": 0.43530334743857385, "critic_loss": 1.3135405330657959, "actor_loss": -48.42413857269287, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.30350923538208, "step": 12000}
{"episode_reward": 237.9165017662469, "episode": 13.0, "batch_reward": 0.4124440070986748, "critic_loss": 1.2767486487030983, "actor_loss": -50.6633992843628, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.331111431121826, "step": 13000}
{"episode_reward": 54.72028952247853, "episode": 14.0, "batch_reward": 0.40163876083493233, "critic_loss": 1.4195229198932648, "actor_loss": -51.45019772338867, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.320648431777954, "step": 14000}
{"episode_reward": 579.5471736037208, "episode": 15.0, "batch_reward": 0.4241725055873394, "critic_loss": 1.517550232231617, "actor_loss": -53.402377059936526, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.28499436378479, "step": 15000}
{"episode_reward": 778.6788508623974, "episode": 16.0, "batch_reward": 0.44011346581578253, "critic_loss": 1.6385551017522813, "actor_loss": -55.18930554199219, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.293204307556152, "step": 16000}
{"episode_reward": 760.7602338048927, "episode": 17.0, "batch_reward": 0.4599425059556961, "critic_loss": 1.7176600912809372, "actor_loss": -55.781215698242185, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.305908918380737, "step": 17000}
{"episode_reward": 685.8728247511334, "episode": 18.0, "batch_reward": 0.48221004667878153, "critic_loss": 1.7562964906692504, "actor_loss": -57.24590916442871, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.284297704696655, "step": 18000}
{"episode_reward": 944.1921490167845, "episode": 19.0, "batch_reward": 0.5028333063125611, "critic_loss": 1.760899109840393, "actor_loss": -60.913703788757324, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.274129629135132, "step": 19000}
{"episode_reward": 919.7491109242778, "episode": 20.0, "batch_reward": 0.5222358813583851, "critic_loss": 1.970566668868065, "actor_loss": -62.1380785446167, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.334916591644287, "step": 20000}
{"episode_reward": 808.7968408296874, "episode": 21.0, "batch_reward": 0.5315441142618657, "critic_loss": 2.0874584468603135, "actor_loss": -64.19282139587402, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.23326134681702, "step": 21000}
{"episode_reward": 761.4066120450757, "episode": 22.0, "batch_reward": 0.5486758033335208, "critic_loss": 2.0148005931377413, "actor_loss": -65.36576277923584, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.29943871498108, "step": 22000}
{"episode_reward": 789.5606187332892, "episode": 23.0, "batch_reward": 0.5557923440337181, "critic_loss": 2.1487946103811266, "actor_loss": -65.72671685028077, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.2762668132782, "step": 23000}
{"episode_reward": 725.8160859563238, "episode": 24.0, "batch_reward": 0.5667093763351441, "critic_loss": 2.0730189625024797, "actor_loss": -67.30086022949219, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.3029522895813, "step": 24000}
{"episode_reward": 900.6950892297585, "episode": 25.0, "batch_reward": 0.5794629086852073, "critic_loss": 1.9512848845720292, "actor_loss": -69.0547788848877, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.32097816467285, "step": 25000}
{"episode_reward": 860.7130839542137, "episode": 26.0, "batch_reward": 0.5903947381973267, "critic_loss": 1.7229037971496581, "actor_loss": -70.05327890777588, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.277029275894165, "step": 26000}
{"episode_reward": 951.5737203487605, "episode": 27.0, "batch_reward": 0.6046519370675087, "critic_loss": 1.714490594625473, "actor_loss": -71.07978964233398, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.283210515975952, "step": 27000}
{"episode_reward": 812.8824502322337, "episode": 28.0, "batch_reward": 0.6096878501176834, "critic_loss": 1.8693890645503999, "actor_loss": -71.83115454101562, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.3034987449646, "step": 28000}
{"episode_reward": 715.1790830766097, "episode": 29.0, "batch_reward": 0.6179167222976685, "critic_loss": 1.7692398619651795, "actor_loss": -72.72176208496094, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.255801916122437, "step": 29000}
{"episode_reward": 881.8778347806453, "episode": 30.0, "batch_reward": 0.6267429893910885, "critic_loss": 1.763435952425003, "actor_loss": -73.64387139892578, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.27162218093872, "step": 30000}
{"episode_reward": 817.3703980519149, "episode": 31.0, "batch_reward": 0.6308538849353791, "critic_loss": 1.6649341943860054, "actor_loss": -74.27784950256347, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.060967445373535, "step": 31000}
{"episode_reward": 860.0241803993325, "episode": 32.0, "batch_reward": 0.6426382169723511, "critic_loss": 1.647066059231758, "actor_loss": -75.15225611877442, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.279462814331055, "step": 32000}
{"episode_reward": 959.2618843823102, "episode": 33.0, "batch_reward": 0.6461147791147233, "critic_loss": 1.6409801749587059, "actor_loss": -75.66019961547852, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.3200740814209, "step": 33000}
{"episode_reward": 861.8705000946427, "episode": 34.0, "batch_reward": 0.6571178244948387, "critic_loss": 1.5373273191452026, "actor_loss": -75.831336227417, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.27364706993103, "step": 34000}
{"episode_reward": 972.5548713127572, "episode": 35.0, "batch_reward": 0.6647221900820732, "critic_loss": 1.5427266429662705, "actor_loss": -76.94296701049805, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.300352096557617, "step": 35000}
{"episode_reward": 880.1198797868053, "episode": 36.0, "batch_reward": 0.6700746572613716, "critic_loss": 1.4399226487874985, "actor_loss": -77.6402449645996, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.291152000427246, "step": 36000}
{"episode_reward": 923.6007084421453, "episode": 37.0, "batch_reward": 0.6759818241000175, "critic_loss": 1.4719671754837036, "actor_loss": -77.75455023193359, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.28797483444214, "step": 37000}
{"episode_reward": 927.526172335834, "episode": 38.0, "batch_reward": 0.6859279343485832, "critic_loss": 1.365908800840378, "actor_loss": -78.42287721252441, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.289295434951782, "step": 38000}
{"episode_reward": 962.0822557185278, "episode": 39.0, "batch_reward": 0.6920680812001229, "critic_loss": 1.4040717149972917, "actor_loss": -79.38274263000488, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.317172288894653, "step": 39000}
{"episode_reward": 928.3473116458817, "episode": 40.0, "batch_reward": 0.6994143560528755, "critic_loss": 1.418236995279789, "actor_loss": -79.81632255554199, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.269568920135498, "step": 40000}
{"episode_reward": 959.379262694271, "episode": 41.0, "batch_reward": 0.7049373785257339, "critic_loss": 1.4147275894284248, "actor_loss": -80.3290679473877, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.146629333496094, "step": 41000}
{"episode_reward": 934.369211842795, "episode": 42.0, "batch_reward": 0.7056176133751869, "critic_loss": 1.3396856669187547, "actor_loss": -80.0715438232422, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.277912855148315, "step": 42000}
{"episode_reward": 552.9697635693557, "episode": 43.0, "batch_reward": 0.7051330046057701, "critic_loss": 1.4082983521819115, "actor_loss": -80.43453535461425, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.28364896774292, "step": 43000}
{"episode_reward": 888.3370676601047, "episode": 44.0, "batch_reward": 0.7103869945406914, "critic_loss": 1.2612608333826065, "actor_loss": -80.8339458618164, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.290541648864746, "step": 44000}
{"episode_reward": 980.9008984807602, "episode": 45.0, "batch_reward": 0.7165743162035942, "critic_loss": 1.3113016124963761, "actor_loss": -81.3808904876709, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.274863719940186, "step": 45000}
{"episode_reward": 922.956868887349, "episode": 46.0, "batch_reward": 0.7181036140918732, "critic_loss": 1.2397217049598694, "actor_loss": -81.78349047851563, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.314149856567383, "step": 46000}
{"episode_reward": 869.1720294189118, "episode": 47.0, "batch_reward": 0.7248760523796082, "critic_loss": 1.1862938246130943, "actor_loss": -81.76597273254394, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.322539806365967, "step": 47000}
{"episode_reward": 953.1240004706262, "episode": 48.0, "batch_reward": 0.7285698094964027, "critic_loss": 1.2010476549863816, "actor_loss": -81.76437670898437, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.29977297782898, "step": 48000}
{"episode_reward": 923.6638794872031, "episode": 49.0, "batch_reward": 0.7337944728136062, "critic_loss": 1.1363099921941757, "actor_loss": -82.4456632232666, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.297422409057617, "step": 49000}
{"episode_reward": 931.7563617993844, "episode": 50.0, "batch_reward": 0.7366368529796601, "critic_loss": 1.1400698580741881, "actor_loss": -82.6086552734375, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.31903314590454, "step": 50000}
{"episode_reward": 958.5748054373068, "episode": 51.0, "batch_reward": 0.7413248450160027, "critic_loss": 1.1138377911448478, "actor_loss": -82.67456350708008, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.13563108444214, "step": 51000}
{"episode_reward": 925.3300769738562, "episode": 52.0, "batch_reward": 0.7419280627369881, "critic_loss": 1.2481890591979026, "actor_loss": -83.27012149047852, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.314284801483154, "step": 52000}
{"episode_reward": 645.657196823053, "episode": 53.0, "batch_reward": 0.7424932438731193, "critic_loss": 1.133952241420746, "actor_loss": -83.14774420166016, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.277039527893066, "step": 53000}
{"episode_reward": 855.1672933949378, "episode": 54.0, "batch_reward": 0.7444425948858261, "critic_loss": 1.1317599123120308, "actor_loss": -82.91342553710938, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.309778451919556, "step": 54000}
{"episode_reward": 902.1085133702919, "episode": 55.0, "batch_reward": 0.7493601929545403, "critic_loss": 1.1501008120775222, "actor_loss": -83.21950993347168, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.313156843185425, "step": 55000}
{"episode_reward": 971.7947500652368, "episode": 56.0, "batch_reward": 0.7516217495799065, "critic_loss": 1.110594622194767, "actor_loss": -83.49228034973144, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.265044927597046, "step": 56000}
{"episode_reward": 899.605674803628, "episode": 57.0, "batch_reward": 0.7556309953331948, "critic_loss": 1.1835192400813104, "actor_loss": -83.9366116027832, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.291873931884766, "step": 57000}
{"episode_reward": 918.8796202801977, "episode": 58.0, "batch_reward": 0.7584242698550224, "critic_loss": 1.084568790078163, "actor_loss": -83.75686251831054, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.284659385681152, "step": 58000}
{"episode_reward": 962.5052618443195, "episode": 59.0, "batch_reward": 0.7613122078180313, "critic_loss": 1.1569882960915565, "actor_loss": -84.53901512145995, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.291221618652344, "step": 59000}
{"episode_reward": 958.9886921153861, "episode": 60.0, "batch_reward": 0.7660556501746177, "critic_loss": 1.1283051052093507, "actor_loss": -84.76750445556641, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.31120252609253, "step": 60000}
{"episode_reward": 970.0314871633663, "episode": 61.0, "batch_reward": 0.768604336977005, "critic_loss": 1.0635277524888516, "actor_loss": -84.49052871704102, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.136547565460205, "step": 61000}
{"episode_reward": 923.5612096870573, "episode": 62.0, "batch_reward": 0.7704040260910988, "critic_loss": 1.1305228479504585, "actor_loss": -84.55541459655761, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.285815000534058, "step": 62000}
{"episode_reward": 964.1681954790237, "episode": 63.0, "batch_reward": 0.7704368062615394, "critic_loss": 1.1186750122904778, "actor_loss": -84.94068238830566, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.287651538848877, "step": 63000}
{"episode_reward": 812.4459403107364, "episode": 64.0, "batch_reward": 0.7719713647961617, "critic_loss": 1.206407975077629, "actor_loss": -84.92945335388184, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.296518564224243, "step": 64000}
{"episode_reward": 893.755690665339, "episode": 65.0, "batch_reward": 0.7766368165016174, "critic_loss": 1.1706091470718383, "actor_loss": -85.05581694030762, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.310940980911255, "step": 65000}
{"episode_reward": 965.1086831799327, "episode": 66.0, "batch_reward": 0.7790217300653458, "critic_loss": 1.1651090421676635, "actor_loss": -85.32166081237793, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.325540781021118, "step": 66000}
{"episode_reward": 931.9969062504429, "episode": 67.0, "batch_reward": 0.7801809639334679, "critic_loss": 1.1236242555975915, "actor_loss": -85.48928680419922, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.291910409927368, "step": 67000}
{"episode_reward": 850.9367641814777, "episode": 68.0, "batch_reward": 0.7815762436985969, "critic_loss": 1.1136174934506415, "actor_loss": -85.45708723449707, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.291489839553833, "step": 68000}
{"episode_reward": 941.5029816556906, "episode": 69.0, "batch_reward": 0.783581542313099, "critic_loss": 1.162676269888878, "actor_loss": -85.67845269775391, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.297794818878174, "step": 69000}
{"episode_reward": 929.6844664433056, "episode": 70.0, "batch_reward": 0.7851153549551964, "critic_loss": 1.125527882605791, "actor_loss": -85.74489797973632, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.326467752456665, "step": 70000}
{"episode_reward": 919.5846959254692, "episode": 71.0, "batch_reward": 0.7887589785456658, "critic_loss": 1.1138797107934952, "actor_loss": -85.80462026977538, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.21598958969116, "step": 71000}
{"episode_reward": 950.221668121386, "episode": 72.0, "batch_reward": 0.7917726573348045, "critic_loss": 1.0591016085743905, "actor_loss": -86.09910765075684, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.310670375823975, "step": 72000}
{"episode_reward": 975.261468238006, "episode": 73.0, "batch_reward": 0.7937699384689331, "critic_loss": 1.087008399873972, "actor_loss": -86.30563369750976, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.28066325187683, "step": 73000}
{"episode_reward": 965.1890242333717, "episode": 74.0, "batch_reward": 0.7970870385766029, "critic_loss": 1.069470909357071, "actor_loss": -86.54909027099609, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.28747034072876, "step": 74000}
{"episode_reward": 953.285093423248, "episode": 75.0, "batch_reward": 0.7994292301535606, "critic_loss": 1.0864291594028472, "actor_loss": -86.5466497039795, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.335659980773926, "step": 75000}
{"episode_reward": 950.1354226299734, "episode": 76.0, "batch_reward": 0.7988726069927216, "critic_loss": 1.0676456102728844, "actor_loss": -86.54666543579101, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.30616021156311, "step": 76000}
{"episode_reward": 979.0099169160203, "episode": 77.0, "batch_reward": 0.8017193999886513, "critic_loss": 1.031134120464325, "actor_loss": -86.86709841918945, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.328868627548218, "step": 77000}
{"episode_reward": 873.1466675258464, "episode": 78.0, "batch_reward": 0.8031220595836639, "critic_loss": 1.0255429971218109, "actor_loss": -87.08279615783691, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.316367149353027, "step": 78000}
{"episode_reward": 899.0584757256272, "episode": 79.0, "batch_reward": 0.8037074152231216, "critic_loss": 1.0747956749796868, "actor_loss": -87.04688468933105, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.260862588882446, "step": 79000}
{"episode_reward": 919.8602452180617, "episode": 80.0, "batch_reward": 0.8063955302834511, "critic_loss": 1.0333319329321384, "actor_loss": -87.08874516296386, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.311164617538452, "step": 80000}
{"episode_reward": 970.8675046035452, "episode": 81.0, "batch_reward": 0.8075648393034935, "critic_loss": 1.1231253231465816, "actor_loss": -87.45466632080078, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.24545192718506, "step": 81000}
{"episode_reward": 920.3098442274195, "episode": 82.0, "batch_reward": 0.8093001091480255, "critic_loss": 1.0236715773940086, "actor_loss": -87.3155513458252, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.313997983932495, "step": 82000}
{"episode_reward": 939.8353780095664, "episode": 83.0, "batch_reward": 0.8099214904904366, "critic_loss": 1.1089985303878784, "actor_loss": -87.55157847595216, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.32611346244812, "step": 83000}
{"episode_reward": 864.2758931287157, "episode": 84.0, "batch_reward": 0.8120172654390335, "critic_loss": 1.0068766990303992, "actor_loss": -87.67149374389649, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.284348249435425, "step": 84000}
{"episode_reward": 989.7733887207801, "episode": 85.0, "batch_reward": 0.8109774883389473, "critic_loss": 1.0647906981110573, "actor_loss": -87.56161059570313, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.29797673225403, "step": 85000}
{"episode_reward": 838.9944055652786, "episode": 86.0, "batch_reward": 0.8133067194223403, "critic_loss": 1.0215889782905578, "actor_loss": -87.65057150268555, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.297311544418335, "step": 86000}
{"episode_reward": 957.3071684898365, "episode": 87.0, "batch_reward": 0.815970178604126, "critic_loss": 1.0255192404687405, "actor_loss": -87.75692114257812, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.26904058456421, "step": 87000}
{"episode_reward": 958.066568087726, "episode": 88.0, "batch_reward": 0.8171855817437172, "critic_loss": 1.0263323048353195, "actor_loss": -87.8250281982422, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.31497836112976, "step": 88000}
{"episode_reward": 856.2105413006541, "episode": 89.0, "batch_reward": 0.8163201178908348, "critic_loss": 1.0504599149525164, "actor_loss": -87.97389559936524, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.33003330230713, "step": 89000}
{"episode_reward": 948.6756796310519, "episode": 90.0, "batch_reward": 0.8169934549927711, "critic_loss": 1.0739352979063987, "actor_loss": -88.19244438171387, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.30953621864319, "step": 90000}
{"episode_reward": 956.5754748106424, "episode": 91.0, "batch_reward": 0.820956838786602, "critic_loss": 0.9900844627022743, "actor_loss": -88.14256495666504, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.18864703178406, "step": 91000}
{"episode_reward": 957.0747344441751, "episode": 92.0, "batch_reward": 0.822779497563839, "critic_loss": 1.0343905004262923, "actor_loss": -88.42757231140136, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.242708206176758, "step": 92000}
{"episode_reward": 937.098638743123, "episode": 93.0, "batch_reward": 0.8225862832665444, "critic_loss": 1.0632767901718616, "actor_loss": -88.32466235351562, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.32374668121338, "step": 93000}
{"episode_reward": 962.9846524991729, "episode": 94.0, "batch_reward": 0.8253914071321488, "critic_loss": 1.0733135348856448, "actor_loss": -88.59215864562988, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.335588455200195, "step": 94000}
{"episode_reward": 903.9503506596118, "episode": 95.0, "batch_reward": 0.823488418340683, "critic_loss": 1.0935255124568939, "actor_loss": -88.64027606201172, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.293442726135254, "step": 95000}
{"episode_reward": 874.0812003723383, "episode": 96.0, "batch_reward": 0.8254375929832458, "critic_loss": 1.038614997804165, "actor_loss": -88.70210920715331, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.28086757659912, "step": 96000}
{"episode_reward": 923.1302684565103, "episode": 97.0, "batch_reward": 0.8269291940927506, "critic_loss": 1.024841655164957, "actor_loss": -88.77871566772461, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.304426670074463, "step": 97000}
{"episode_reward": 921.3014659109128, "episode": 98.0, "batch_reward": 0.8282712641954422, "critic_loss": 1.042896489828825, "actor_loss": -88.89813612365722, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.297282695770264, "step": 98000}
{"episode_reward": 928.454482891983, "episode": 99.0, "batch_reward": 0.8302348096370697, "critic_loss": 1.031083504766226, "actor_loss": -88.9229711151123, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.31490445137024, "step": 99000}
{"episode_reward": 966.6028479775897, "episode": 100.0, "batch_reward": 0.830988430261612, "critic_loss": 1.0608515418469906, "actor_loss": -88.96478933715821, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.322885751724243, "step": 100000}
{"episode_reward": 930.0782803941682, "episode": 101.0, "batch_reward": 0.8328341118693352, "critic_loss": 1.0425242324471473, "actor_loss": -89.16325608825683, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.17926001548767, "step": 101000}
{"episode_reward": 971.2426447430523, "episode": 102.0, "batch_reward": 0.8305827032327652, "critic_loss": 1.076739078581333, "actor_loss": -89.2010291442871, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.324591875076294, "step": 102000}
{"episode_reward": 809.0157877989635, "episode": 103.0, "batch_reward": 0.8299665871858597, "critic_loss": 1.1361632557213306, "actor_loss": -89.12818475341797, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.279003858566284, "step": 103000}
{"episode_reward": 895.9717667406045, "episode": 104.0, "batch_reward": 0.8322026794552803, "critic_loss": 1.085908168822527, "actor_loss": -89.17076246643066, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.3063325881958, "step": 104000}
{"episode_reward": 931.3234711166305, "episode": 105.0, "batch_reward": 0.8353135629892349, "critic_loss": 1.0097150391936303, "actor_loss": -89.24460250854492, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.283982753753662, "step": 105000}
{"episode_reward": 937.4976270806333, "episode": 106.0, "batch_reward": 0.8335361945033073, "critic_loss": 1.055651061832905, "actor_loss": -89.10335168457031, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.267247438430786, "step": 106000}
{"episode_reward": 918.1035002317607, "episode": 107.0, "batch_reward": 0.8357280336618423, "critic_loss": 1.01824167445302, "actor_loss": -89.27193594360351, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.281534671783447, "step": 107000}
{"episode_reward": 956.8578874561397, "episode": 108.0, "batch_reward": 0.8379200224876404, "critic_loss": 1.0471438872814178, "actor_loss": -89.59698745727539, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.3259756565094, "step": 108000}
{"episode_reward": 948.2176487016978, "episode": 109.0, "batch_reward": 0.8369607133865357, "critic_loss": 0.9847753502726555, "actor_loss": -89.51489057922363, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.28812265396118, "step": 109000}
{"episode_reward": 978.672051996918, "episode": 110.0, "batch_reward": 0.8408984041810036, "critic_loss": 1.0304670081138612, "actor_loss": -89.63658662414551, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.317670822143555, "step": 110000}
{"episode_reward": 907.9893630045603, "episode": 111.0, "batch_reward": 0.8392638741135597, "critic_loss": 1.0180368967950344, "actor_loss": -89.69514233398438, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.086721420288086, "step": 111000}
{"episode_reward": 921.8141428460657, "episode": 112.0, "batch_reward": 0.8403357248306275, "critic_loss": 1.0688417810201645, "actor_loss": -89.64583244323731, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.327093601226807, "step": 112000}
{"episode_reward": 944.3276774982953, "episode": 113.0, "batch_reward": 0.8419512020349502, "critic_loss": 1.06387705886364, "actor_loss": -89.7223624420166, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.309535264968872, "step": 113000}
{"episode_reward": 953.2620105675891, "episode": 114.0, "batch_reward": 0.842431800365448, "critic_loss": 1.0481250381171703, "actor_loss": -89.86767388916016, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.270444869995117, "step": 114000}
{"episode_reward": 972.6687623155773, "episode": 115.0, "batch_reward": 0.8404312382340431, "critic_loss": 0.9940787901282311, "actor_loss": -89.80464723205566, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.31306552886963, "step": 115000}
{"episode_reward": 71.778896285448, "episode": 116.0, "batch_reward": 0.8376181291937828, "critic_loss": 0.9888138600289822, "actor_loss": -89.78283656311035, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.295534133911133, "step": 116000}
{"episode_reward": 924.1722303193103, "episode": 117.0, "batch_reward": 0.8372693408727646, "critic_loss": 0.9608552382290363, "actor_loss": -89.8007310180664, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.285154819488525, "step": 117000}
{"episode_reward": 936.7460275744396, "episode": 118.0, "batch_reward": 0.8373517072796821, "critic_loss": 1.0223455677032471, "actor_loss": -89.78694873046875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.32750177383423, "step": 118000}
{"episode_reward": 985.6525978941294, "episode": 119.0, "batch_reward": 0.8389052423238754, "critic_loss": 1.0059756797850132, "actor_loss": -89.84828031921387, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.322330236434937, "step": 119000}
{"episode_reward": 942.1070448184562, "episode": 120.0, "batch_reward": 0.8403430913090706, "critic_loss": 1.039484427690506, "actor_loss": -89.81654510498046, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.289886713027954, "step": 120000}
{"episode_reward": 957.8897346000684, "episode": 121.0, "batch_reward": 0.8415253467559815, "critic_loss": 1.1209759278595448, "actor_loss": -89.95142126464843, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.15057921409607, "step": 121000}
{"episode_reward": 958.8812956211507, "episode": 122.0, "batch_reward": 0.8428506019711495, "critic_loss": 1.0447434103190898, "actor_loss": -90.02662840270996, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.26918315887451, "step": 122000}
{"episode_reward": 944.4933724287898, "episode": 123.0, "batch_reward": 0.8426066074371338, "critic_loss": 1.0172158188819884, "actor_loss": -90.00068716430664, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.322685480117798, "step": 123000}
{"episode_reward": 850.0619846567395, "episode": 124.0, "batch_reward": 0.8436771171092987, "critic_loss": 0.999548064917326, "actor_loss": -90.05283097839356, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.323616981506348, "step": 124000}
{"episode_reward": 970.0033493147101, "episode": 125.0, "batch_reward": 0.845524240553379, "critic_loss": 0.9200962678790092, "actor_loss": -90.22208920288087, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.28727626800537, "step": 125000}
{"episode_reward": 987.9551117654563, "episode": 126.0, "batch_reward": 0.8465709108114242, "critic_loss": 0.9625628103911876, "actor_loss": -90.34815089416504, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.31941318511963, "step": 126000}
{"episode_reward": 981.469796991121, "episode": 127.0, "batch_reward": 0.8471689893603325, "critic_loss": 0.9969379155337811, "actor_loss": -90.38751904296875, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.316223621368408, "step": 127000}
{"episode_reward": 950.8136456761407, "episode": 128.0, "batch_reward": 0.847194363951683, "critic_loss": 0.9774133373796939, "actor_loss": -90.4686983795166, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.29926323890686, "step": 128000}
{"episode_reward": 978.0455148356921, "episode": 129.0, "batch_reward": 0.8492000363469124, "critic_loss": 0.9961928022503853, "actor_loss": -90.51802754211425, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.308393716812134, "step": 129000}
{"episode_reward": 985.0157131406893, "episode": 130.0, "batch_reward": 0.851446447789669, "critic_loss": 1.0179328550696374, "actor_loss": -90.52296522521972, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.30323886871338, "step": 130000}
{"episode_reward": 988.2099796512013, "episode": 131.0, "batch_reward": 0.8514981006979943, "critic_loss": 0.9802748490273953, "actor_loss": -90.43769100952149, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.12421154975891, "step": 131000}
{"episode_reward": 969.4801070686073, "episode": 132.0, "batch_reward": 0.8529887192249298, "critic_loss": 0.9421253788471222, "actor_loss": -90.52106640625, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.279760599136353, "step": 132000}
{"episode_reward": 973.2494268036899, "episode": 133.0, "batch_reward": 0.8512908571362495, "critic_loss": 0.9882526338398456, "actor_loss": -90.53652484130859, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.285842180252075, "step": 133000}
{"episode_reward": 960.8677698586115, "episode": 134.0, "batch_reward": 0.85378736358881, "critic_loss": 0.9375800443291664, "actor_loss": -90.63756489562988, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.290817260742188, "step": 134000}
{"episode_reward": 961.684825821534, "episode": 135.0, "batch_reward": 0.8559910743832588, "critic_loss": 0.9291786496937275, "actor_loss": -90.62901480102539, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.328360557556152, "step": 135000}
{"episode_reward": 993.6193356046833, "episode": 136.0, "batch_reward": 0.8562700520157814, "critic_loss": 0.9351270315647126, "actor_loss": -90.75682133483886, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.317375421524048, "step": 136000}
{"episode_reward": 986.341663151379, "episode": 137.0, "batch_reward": 0.8555519512891769, "critic_loss": 0.9414303509891033, "actor_loss": -90.60663258361816, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.31718397140503, "step": 137000}
{"episode_reward": 967.8334299126577, "episode": 138.0, "batch_reward": 0.8573518265485763, "critic_loss": 0.8723879840373993, "actor_loss": -90.73876560974121, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.292259216308594, "step": 138000}
{"episode_reward": 958.909391238347, "episode": 139.0, "batch_reward": 0.857595880150795, "critic_loss": 0.9168849621117116, "actor_loss": -90.84508934020997, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.298429012298584, "step": 139000}
{"episode_reward": 975.1553408505308, "episode": 140.0, "batch_reward": 0.8591037564277649, "critic_loss": 0.9364633572697639, "actor_loss": -90.95898893737792, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.299580335617065, "step": 140000}
{"episode_reward": 953.0563368554577, "episode": 141.0, "batch_reward": 0.8595682516694069, "critic_loss": 0.9214410302639008, "actor_loss": -90.99674198913574, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.225117921829224, "step": 141000}
{"episode_reward": 971.5069357847643, "episode": 142.0, "batch_reward": 0.8595071315765381, "critic_loss": 0.9250269056260586, "actor_loss": -90.85676249694824, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.28443717956543, "step": 142000}
{"episode_reward": 990.7773723573672, "episode": 143.0, "batch_reward": 0.8608321001529694, "critic_loss": 0.9428990523517132, "actor_loss": -91.07322813415527, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.317334413528442, "step": 143000}
{"episode_reward": 944.0236769791894, "episode": 144.0, "batch_reward": 0.8601541917324066, "critic_loss": 0.8927321173548698, "actor_loss": -91.07985165405273, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.333862781524658, "step": 144000}
{"episode_reward": 930.7921464148902, "episode": 145.0, "batch_reward": 0.8623922806382179, "critic_loss": 0.8404250968694686, "actor_loss": -91.07755522155762, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.31692099571228, "step": 145000}
{"episode_reward": 988.2758420950656, "episode": 146.0, "batch_reward": 0.8627253514528275, "critic_loss": 0.8957810319364071, "actor_loss": -91.18093768310547, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.36215353012085, "step": 146000}
{"episode_reward": 971.2364838092377, "episode": 147.0, "batch_reward": 0.8626987872719765, "critic_loss": 0.8398349070847034, "actor_loss": -91.19262382507324, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.59177303314209, "step": 147000}
{"episode_reward": 920.4500094620024, "episode": 148.0, "batch_reward": 0.8646968575716019, "critic_loss": 0.8521284466981888, "actor_loss": -91.29856588745118, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.279446363449097, "step": 148000}
{"episode_reward": 984.0202247982648, "episode": 149.0, "batch_reward": 0.8648810919523239, "critic_loss": 0.8161772903800011, "actor_loss": -91.19880039978027, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.30141830444336, "step": 149000}
{"episode_reward": 927.4863020195021, "episode": 150.0, "batch_reward": 0.8654326599240303, "critic_loss": 0.8555885666012764, "actor_loss": -91.3287682647705, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
