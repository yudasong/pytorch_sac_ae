{"episode_reward": 0.0, "episode": 1.0, "duration": 20.570575952529907, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.7912321090698242, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.4971782778771411, "critic_loss": 0.8964197740987286, "actor_loss": -89.87813909132988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.5621383190155, "step": 3000}
{"episode_reward": 887.258285326623, "episode": 4.0, "batch_reward": 0.5626931737363339, "critic_loss": 1.6586346311569213, "actor_loss": -95.1116230316162, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94134831428528, "step": 4000}
{"episode_reward": 138.208237036622, "episode": 5.0, "batch_reward": 0.4949085223674774, "critic_loss": 1.4031440154910089, "actor_loss": -97.34052682495117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.943720817565918, "step": 5000}
{"episode_reward": 311.8003776232272, "episode": 6.0, "batch_reward": 0.43319952315092086, "critic_loss": 1.1592208300232887, "actor_loss": -97.31658271789551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.973358392715454, "step": 6000}
{"episode_reward": 107.37777126885955, "episode": 7.0, "batch_reward": 0.3697495652735233, "critic_loss": 1.0900486249327659, "actor_loss": -95.8600016937256, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.950060606002808, "step": 7000}
{"episode_reward": 33.283094045389426, "episode": 8.0, "batch_reward": 0.3403116342127323, "critic_loss": 1.0876364350318908, "actor_loss": -94.83498738098145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.969358444213867, "step": 8000}
{"episode_reward": 160.1453216628386, "episode": 9.0, "batch_reward": 0.30593445006012915, "critic_loss": 0.9208069345355034, "actor_loss": -92.73186268615723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.964024543762207, "step": 9000}
{"episode_reward": 30.27154486954962, "episode": 10.0, "batch_reward": 0.28106919741630554, "critic_loss": 0.9278740780949593, "actor_loss": -91.75463865661621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.961551189422607, "step": 10000}
{"episode_reward": 61.245104861423535, "episode": 11.0, "batch_reward": 0.26147126354277134, "critic_loss": 0.7375380023419857, "actor_loss": -89.18853919982911, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.38720989227295, "step": 11000}
{"episode_reward": 67.55679457976099, "episode": 12.0, "batch_reward": 0.23902766413986684, "critic_loss": 0.6239117924869061, "actor_loss": -87.18265280151367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.982786178588867, "step": 12000}
{"episode_reward": 29.44696305512621, "episode": 13.0, "batch_reward": 0.22337337478250266, "critic_loss": 0.636394539654255, "actor_loss": -85.05621955871582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.95716094970703, "step": 13000}
{"episode_reward": 30.248224392597674, "episode": 14.0, "batch_reward": 0.21190171752870082, "critic_loss": 0.6833185301721096, "actor_loss": -83.1428759765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.974782943725586, "step": 14000}
{"episode_reward": 80.87126483625816, "episode": 15.0, "batch_reward": 0.22547247373312712, "critic_loss": 0.793475169122219, "actor_loss": -81.31134848022461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.948642253875732, "step": 15000}
{"episode_reward": 502.4699097258754, "episode": 16.0, "batch_reward": 0.2310220189243555, "critic_loss": 0.8145902003347874, "actor_loss": -79.5466759185791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.96259045600891, "step": 16000}
{"episode_reward": 568.6368966333562, "episode": 17.0, "batch_reward": 0.2666867155432701, "critic_loss": 0.8635612225234508, "actor_loss": -78.64175399780274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.966786861419678, "step": 17000}
{"episode_reward": 930.8540839528459, "episode": 18.0, "batch_reward": 0.29847796882689, "critic_loss": 1.0231329285502433, "actor_loss": -78.89962350463867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.951699018478394, "step": 18000}
{"episode_reward": 709.3990049032656, "episode": 19.0, "batch_reward": 0.3272767282873392, "critic_loss": 1.091661898612976, "actor_loss": -79.90255752563476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92725920677185, "step": 19000}
{"episode_reward": 941.5592289151793, "episode": 20.0, "batch_reward": 0.3521575732827187, "critic_loss": 1.1348895114660262, "actor_loss": -79.96711985778809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.953920125961304, "step": 20000}
{"episode_reward": 785.3950433099026, "episode": 21.0, "batch_reward": 0.37531326432526113, "critic_loss": 1.113942587584257, "actor_loss": -80.01684426879883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.29548788070679, "step": 21000}
{"episode_reward": 800.7170340828816, "episode": 22.0, "batch_reward": 0.3914119453728199, "critic_loss": 1.0678461723327637, "actor_loss": -79.49610842895508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.927385330200195, "step": 22000}
{"episode_reward": 603.7635588487694, "episode": 23.0, "batch_reward": 0.4074320422708988, "critic_loss": 1.101461688220501, "actor_loss": -78.99887245178223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93333888053894, "step": 23000}
{"episode_reward": 893.8300326230996, "episode": 24.0, "batch_reward": 0.4310932403206825, "critic_loss": 1.052392207980156, "actor_loss": -79.81303419494628, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94974160194397, "step": 24000}
{"episode_reward": 980.2045550653288, "episode": 25.0, "batch_reward": 0.44727510622143746, "critic_loss": 1.2632642098069191, "actor_loss": -80.72283964538575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93158483505249, "step": 25000}
{"episode_reward": 775.8445164226356, "episode": 26.0, "batch_reward": 0.4643614005148411, "critic_loss": 1.2830590717792512, "actor_loss": -81.76579858398438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.932032823562622, "step": 26000}
{"episode_reward": 981.0562956662964, "episode": 27.0, "batch_reward": 0.4841459052562714, "critic_loss": 1.3509427567124366, "actor_loss": -82.0810089263916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.948853731155396, "step": 27000}
{"episode_reward": 975.9920834005028, "episode": 28.0, "batch_reward": 0.4971037963628769, "critic_loss": 1.5079072652459145, "actor_loss": -82.03041543579101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.964130401611328, "step": 28000}
{"episode_reward": 753.6407193755192, "episode": 29.0, "batch_reward": 0.5074896415770054, "critic_loss": 1.5304951637387276, "actor_loss": -82.8735234375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.936985969543457, "step": 29000}
{"episode_reward": 738.662579853911, "episode": 30.0, "batch_reward": 0.5180091786682606, "critic_loss": 1.4267108684778214, "actor_loss": -83.18636293029785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.950873613357544, "step": 30000}
{"episode_reward": 907.8576883399094, "episode": 31.0, "batch_reward": 0.5273497047424316, "critic_loss": 1.3026656888723374, "actor_loss": -83.17188404846192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.27365803718567, "step": 31000}
{"episode_reward": 864.1584043338441, "episode": 32.0, "batch_reward": 0.5336502626240254, "critic_loss": 1.271394287288189, "actor_loss": -83.23890983581543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.952221393585205, "step": 32000}
{"episode_reward": 538.9488827898924, "episode": 33.0, "batch_reward": 0.5390308147668839, "critic_loss": 1.2121129604578018, "actor_loss": -82.86327055358886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92124080657959, "step": 33000}
{"episode_reward": 886.372562497203, "episode": 34.0, "batch_reward": 0.5531508222818374, "critic_loss": 1.0882946820557118, "actor_loss": -82.60600134277344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.908042192459106, "step": 34000}
{"episode_reward": 980.9776519166372, "episode": 35.0, "batch_reward": 0.565121317088604, "critic_loss": 1.0862153860330581, "actor_loss": -83.0474906463623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.929030418395996, "step": 35000}
{"episode_reward": 901.6082559772111, "episode": 36.0, "batch_reward": 0.570063162535429, "critic_loss": 1.1214246084094048, "actor_loss": -83.0226378326416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93674635887146, "step": 36000}
{"episode_reward": 858.5672143510028, "episode": 37.0, "batch_reward": 0.5771890768408775, "critic_loss": 1.0834690234065056, "actor_loss": -83.04810105895996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.90877652168274, "step": 37000}
{"episode_reward": 870.3378725271891, "episode": 38.0, "batch_reward": 0.5903184498250484, "critic_loss": 1.064334324836731, "actor_loss": -83.24020678710937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.951513528823853, "step": 38000}
{"episode_reward": 982.8414539400211, "episode": 39.0, "batch_reward": 0.5989197133481503, "critic_loss": 1.0881570660471915, "actor_loss": -83.85612176513672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94351577758789, "step": 39000}
{"episode_reward": 915.8906985354624, "episode": 40.0, "batch_reward": 0.6093546490967273, "critic_loss": 1.1269173183739185, "actor_loss": -84.02677551269531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.947874784469604, "step": 40000}
{"episode_reward": 911.4866898307496, "episode": 41.0, "batch_reward": 0.6126094265282154, "critic_loss": 1.1781461973190308, "actor_loss": -84.06518548583985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.305275678634644, "step": 41000}
{"episode_reward": 853.3551075345562, "episode": 42.0, "batch_reward": 0.6221969828605652, "critic_loss": 1.1775903838276862, "actor_loss": -83.94359338378906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93359398841858, "step": 42000}
{"episode_reward": 942.9279265145439, "episode": 43.0, "batch_reward": 0.6272279557585716, "critic_loss": 1.1958677985668182, "actor_loss": -84.13298815917969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.939229249954224, "step": 43000}
{"episode_reward": 926.6714254311805, "episode": 44.0, "batch_reward": 0.6358150072097778, "critic_loss": 1.1754436348080635, "actor_loss": -84.36052659606933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.956907033920288, "step": 44000}
{"episode_reward": 978.7402102073087, "episode": 45.0, "batch_reward": 0.6431671643555165, "critic_loss": 1.205251156270504, "actor_loss": -84.62304837036133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.954575300216675, "step": 45000}
{"episode_reward": 916.3639087349737, "episode": 46.0, "batch_reward": 0.6471745888590813, "critic_loss": 1.200094054698944, "actor_loss": -84.72063667297363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.958862781524658, "step": 46000}
{"episode_reward": 939.9553891523192, "episode": 47.0, "batch_reward": 0.6555607198476792, "critic_loss": 1.1838049328327178, "actor_loss": -84.60501945495605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.97597360610962, "step": 47000}
{"episode_reward": 939.7711402447711, "episode": 48.0, "batch_reward": 0.6598652314543724, "critic_loss": 1.1046019958257676, "actor_loss": -84.73468389892578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.981439113616943, "step": 48000}
{"episode_reward": 927.1127951983522, "episode": 49.0, "batch_reward": 0.6663336048722267, "critic_loss": 1.0033120687901973, "actor_loss": -85.25701933288575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.917081117630005, "step": 49000}
{"episode_reward": 933.6971595584924, "episode": 50.0, "batch_reward": 0.6711502814292908, "critic_loss": 0.9670370763838291, "actor_loss": -85.2404267578125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93609356880188, "step": 50000}
{"episode_reward": 988.4967544815469, "episode": 51.0, "batch_reward": 0.680079674422741, "critic_loss": 0.9526471506655216, "actor_loss": -85.34876580810547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.230982303619385, "step": 51000}
{"episode_reward": 954.7175692197641, "episode": 52.0, "batch_reward": 0.6824667481780052, "critic_loss": 0.9666435739398003, "actor_loss": -85.93731813049317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.889187574386597, "step": 52000}
{"episode_reward": 881.6259912163669, "episode": 53.0, "batch_reward": 0.6883643528223038, "critic_loss": 0.9272102136015892, "actor_loss": -86.1417233581543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.969372987747192, "step": 53000}
{"episode_reward": 934.150470816573, "episode": 54.0, "batch_reward": 0.6919477316737175, "critic_loss": 0.910188040792942, "actor_loss": -86.152359085083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93304944038391, "step": 54000}
{"episode_reward": 929.9217983977469, "episode": 55.0, "batch_reward": 0.6971037821173668, "critic_loss": 0.9027822127342224, "actor_loss": -86.20881892395019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.923710346221924, "step": 55000}
{"episode_reward": 970.5531903436485, "episode": 56.0, "batch_reward": 0.7024658976793289, "critic_loss": 0.8470839301645756, "actor_loss": -86.6153670654297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.942566633224487, "step": 56000}
{"episode_reward": 982.6691794150081, "episode": 57.0, "batch_reward": 0.7083440786600113, "critic_loss": 0.8932582803666592, "actor_loss": -86.90542098999023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94279980659485, "step": 57000}
{"episode_reward": 924.0722171883178, "episode": 58.0, "batch_reward": 0.710959858417511, "critic_loss": 0.8461468394696713, "actor_loss": -86.59813235473632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.979579210281372, "step": 58000}
{"episode_reward": 984.4190359331172, "episode": 59.0, "batch_reward": 0.716806613445282, "critic_loss": 0.8338873850703239, "actor_loss": -87.21601919555664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.973814249038696, "step": 59000}
{"episode_reward": 953.7474606849456, "episode": 60.0, "batch_reward": 0.7193849921226502, "critic_loss": 0.7709980090260505, "actor_loss": -87.32929359436035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.970922470092773, "step": 60000}
{"episode_reward": 940.6822766844042, "episode": 61.0, "batch_reward": 0.7207102415561676, "critic_loss": 0.7461041386127472, "actor_loss": -87.27320039367676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.29518508911133, "step": 61000}
{"episode_reward": 919.5766280112479, "episode": 62.0, "batch_reward": 0.7257465413808822, "critic_loss": 0.7832923034131527, "actor_loss": -87.18625230407714, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.96601891517639, "step": 62000}
{"episode_reward": 968.0158531631773, "episode": 63.0, "batch_reward": 0.726434086382389, "critic_loss": 0.7912417034804821, "actor_loss": -87.31467497253418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92399001121521, "step": 63000}
{"episode_reward": 877.7075878814908, "episode": 64.0, "batch_reward": 0.7312623525261879, "critic_loss": 0.7717386642694474, "actor_loss": -87.57368055725098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.936408758163452, "step": 64000}
{"episode_reward": 987.4536420064811, "episode": 65.0, "batch_reward": 0.7356823760867118, "critic_loss": 0.7338755378425121, "actor_loss": -87.84105781555176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.932929515838623, "step": 65000}
{"episode_reward": 960.1175802947857, "episode": 66.0, "batch_reward": 0.7402676941156388, "critic_loss": 0.7288226832151413, "actor_loss": -88.11707049560547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.908769369125366, "step": 66000}
{"episode_reward": 933.3867250316798, "episode": 67.0, "batch_reward": 0.7420299906134605, "critic_loss": 0.7337091701626778, "actor_loss": -88.32735200500488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.919546604156494, "step": 67000}
{"episode_reward": 932.725340150713, "episode": 68.0, "batch_reward": 0.744221174120903, "critic_loss": 0.7090259411931038, "actor_loss": -88.02570933532715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.930902004241943, "step": 68000}
{"episode_reward": 953.9923371044674, "episode": 69.0, "batch_reward": 0.747653661608696, "critic_loss": 0.6838207210302353, "actor_loss": -88.15599363708496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.961475610733032, "step": 69000}
{"episode_reward": 987.7144135681406, "episode": 70.0, "batch_reward": 0.7501304257512093, "critic_loss": 0.6735024507641793, "actor_loss": -88.39311082458497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.962672472000122, "step": 70000}
{"episode_reward": 884.2617756867415, "episode": 71.0, "batch_reward": 0.7533820009827614, "critic_loss": 0.7366492369174957, "actor_loss": -88.52516700744629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.329978227615356, "step": 71000}
{"episode_reward": 929.8128296917716, "episode": 72.0, "batch_reward": 0.7571384870409965, "critic_loss": 0.6995423040091991, "actor_loss": -88.75429067993164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93853521347046, "step": 72000}
{"episode_reward": 982.3485737198819, "episode": 73.0, "batch_reward": 0.7579637907743454, "critic_loss": 0.6919353416860103, "actor_loss": -88.90026037597656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.906792640686035, "step": 73000}
{"episode_reward": 944.5887560541032, "episode": 74.0, "batch_reward": 0.7629992004036903, "critic_loss": 0.7029982637763024, "actor_loss": -89.08903089904786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.91041612625122, "step": 74000}
{"episode_reward": 937.5762783904516, "episode": 75.0, "batch_reward": 0.7628911589980125, "critic_loss": 0.6891931535899639, "actor_loss": -88.94794499206543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93981909751892, "step": 75000}
{"episode_reward": 967.5106763034247, "episode": 76.0, "batch_reward": 0.764824155151844, "critic_loss": 0.7149104191958904, "actor_loss": -88.85867544555664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.914860010147095, "step": 76000}
{"episode_reward": 891.2185872149936, "episode": 77.0, "batch_reward": 0.7678836045265198, "critic_loss": 0.6629307813942432, "actor_loss": -88.89059135437012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93641948699951, "step": 77000}
{"episode_reward": 951.5682287843316, "episode": 78.0, "batch_reward": 0.7705579344630241, "critic_loss": 0.7043766512572766, "actor_loss": -89.06257214355469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.916043996810913, "step": 78000}
{"episode_reward": 913.4133741011437, "episode": 79.0, "batch_reward": 0.7731041535139084, "critic_loss": 0.7095948833525181, "actor_loss": -89.10375430297852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.91135287284851, "step": 79000}
{"episode_reward": 966.3066059541949, "episode": 80.0, "batch_reward": 0.7746449440121651, "critic_loss": 0.6944662373065948, "actor_loss": -89.139423828125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.957390069961548, "step": 80000}
{"episode_reward": 979.7422672608418, "episode": 81.0, "batch_reward": 0.7769240273833274, "critic_loss": 0.6753168275356293, "actor_loss": -89.45525028991699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.325093507766724, "step": 81000}
{"episode_reward": 934.0582536008242, "episode": 82.0, "batch_reward": 0.7797034785151482, "critic_loss": 0.6972861014604569, "actor_loss": -89.47871568298339, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.951869010925293, "step": 82000}
{"episode_reward": 959.7348372865121, "episode": 83.0, "batch_reward": 0.7824410681724548, "critic_loss": 0.6932987903058528, "actor_loss": -89.6069796295166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94809651374817, "step": 83000}
{"episode_reward": 932.440831575897, "episode": 84.0, "batch_reward": 0.7852459648251533, "critic_loss": 0.6346886125802994, "actor_loss": -89.66387648010254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.95498538017273, "step": 84000}
{"episode_reward": 989.0197374000813, "episode": 85.0, "batch_reward": 0.7835013257861138, "critic_loss": 0.6630688421130181, "actor_loss": -89.55431645202637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.9238121509552, "step": 85000}
{"episode_reward": 916.831623132398, "episode": 86.0, "batch_reward": 0.78736186337471, "critic_loss": 0.726886351287365, "actor_loss": -89.72349130249023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.953691244125366, "step": 86000}
{"episode_reward": 946.6411860410195, "episode": 87.0, "batch_reward": 0.7895389843583107, "critic_loss": 0.614045212239027, "actor_loss": -89.77692585754394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.89873456954956, "step": 87000}
{"episode_reward": 956.9056985165674, "episode": 88.0, "batch_reward": 0.7909262179732323, "critic_loss": 0.5972854613363743, "actor_loss": -89.86729211425781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.983312129974365, "step": 88000}
{"episode_reward": 871.034548812687, "episode": 89.0, "batch_reward": 0.7915925123691558, "critic_loss": 0.6513238718956709, "actor_loss": -89.73254591369628, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.895744562149048, "step": 89000}
{"episode_reward": 969.1292066337253, "episode": 90.0, "batch_reward": 0.7938686872720718, "critic_loss": 0.6116065799891949, "actor_loss": -90.13800352478027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.90443205833435, "step": 90000}
{"episode_reward": 941.6578412243922, "episode": 91.0, "batch_reward": 0.7958629267215729, "critic_loss": 0.6252960157841444, "actor_loss": -90.09493626403808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.2484176158905, "step": 91000}
{"episode_reward": 959.5556989460372, "episode": 92.0, "batch_reward": 0.7998846116662025, "critic_loss": 0.6313244090229273, "actor_loss": -90.6279097290039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.88294005393982, "step": 92000}
{"episode_reward": 960.632427495955, "episode": 93.0, "batch_reward": 0.7981065077781677, "critic_loss": 0.6488103052973747, "actor_loss": -90.40522009277343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.91387939453125, "step": 93000}
{"episode_reward": 981.7331172069287, "episode": 94.0, "batch_reward": 0.8015765328407287, "critic_loss": 0.6395170547068119, "actor_loss": -90.73157412719726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93490719795227, "step": 94000}
{"episode_reward": 934.3946149499235, "episode": 95.0, "batch_reward": 0.8029495234489441, "critic_loss": 0.6181411925703287, "actor_loss": -90.65531181335449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.91946315765381, "step": 95000}
{"episode_reward": 954.3721027569009, "episode": 96.0, "batch_reward": 0.8030960654020309, "critic_loss": 0.6518217179924249, "actor_loss": -90.68190364074707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94951820373535, "step": 96000}
{"episode_reward": 915.4211151471198, "episode": 97.0, "batch_reward": 0.8030314759016037, "critic_loss": 0.6318986779302359, "actor_loss": -90.61553547668457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.948133945465088, "step": 97000}
{"episode_reward": 933.5626148469756, "episode": 98.0, "batch_reward": 0.8053450216054916, "critic_loss": 0.6132408397793769, "actor_loss": -90.83927606201172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.97017812728882, "step": 98000}
{"episode_reward": 953.7399067062256, "episode": 99.0, "batch_reward": 0.8086420277357101, "critic_loss": 0.5685823774039745, "actor_loss": -90.85927595520019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.957647562026978, "step": 99000}
{"episode_reward": 957.9836782488314, "episode": 100.0, "batch_reward": 0.8096929420828819, "critic_loss": 0.5838331330120563, "actor_loss": -90.84020777893066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94235610961914, "step": 100000}
{"episode_reward": 939.5777294331956, "episode": 101.0, "batch_reward": 0.8120726572275162, "critic_loss": 0.5793561822474003, "actor_loss": -91.03303717041015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.25795841217041, "step": 101000}
{"episode_reward": 989.4000543038542, "episode": 102.0, "batch_reward": 0.8107393320202827, "critic_loss": 0.5781477475166321, "actor_loss": -91.08929147338867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.9840190410614, "step": 102000}
{"episode_reward": 955.9246203209113, "episode": 103.0, "batch_reward": 0.8128584614396095, "critic_loss": 0.6090221349895001, "actor_loss": -91.13219563293457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.971062183380127, "step": 103000}
{"episode_reward": 959.0739721031753, "episode": 104.0, "batch_reward": 0.8158297482728958, "critic_loss": 0.5586624608635903, "actor_loss": -91.33698631286622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.962882041931152, "step": 104000}
{"episode_reward": 907.3898249895423, "episode": 105.0, "batch_reward": 0.81670844912529, "critic_loss": 0.5954502547383308, "actor_loss": -91.31070245361329, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.951601266860962, "step": 105000}
{"episode_reward": 875.410364235998, "episode": 106.0, "batch_reward": 0.8158732621073723, "critic_loss": 0.5773219108283519, "actor_loss": -91.19969956970215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92313241958618, "step": 106000}
{"episode_reward": 876.0898624607047, "episode": 107.0, "batch_reward": 0.8163353803753853, "critic_loss": 0.6372165026217699, "actor_loss": -91.33121876525878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.948108911514282, "step": 107000}
{"episode_reward": 905.3089564105189, "episode": 108.0, "batch_reward": 0.8186051052808762, "critic_loss": 0.6150873500853777, "actor_loss": -91.5028168182373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92424964904785, "step": 108000}
{"episode_reward": 923.2856696206043, "episode": 109.0, "batch_reward": 0.8188880535364151, "critic_loss": 0.6118187698721885, "actor_loss": -91.45455142211914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.924063205718994, "step": 109000}
{"episode_reward": 952.9543338189015, "episode": 110.0, "batch_reward": 0.8199764694571495, "critic_loss": 0.6512651153206825, "actor_loss": -91.42406924438477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.924647569656372, "step": 110000}
{"episode_reward": 913.9929917452845, "episode": 111.0, "batch_reward": 0.8209453419446945, "critic_loss": 0.6433647406995296, "actor_loss": -91.42964953613281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.21241545677185, "step": 111000}
{"episode_reward": 947.2487126329556, "episode": 112.0, "batch_reward": 0.8221656988859176, "critic_loss": 0.6892557689845562, "actor_loss": -91.47009658813477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.931153535842896, "step": 112000}
{"episode_reward": 936.96489784562, "episode": 113.0, "batch_reward": 0.8232329333424568, "critic_loss": 0.7082835169434547, "actor_loss": -91.50163356018066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.895642518997192, "step": 113000}
{"episode_reward": 892.6368625776382, "episode": 114.0, "batch_reward": 0.8244799861311912, "critic_loss": 0.6634535286575556, "actor_loss": -91.45378883361816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.935292959213257, "step": 114000}
{"episode_reward": 979.0001277273842, "episode": 115.0, "batch_reward": 0.8249662463068962, "critic_loss": 0.6684567523151637, "actor_loss": -91.35472583007812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.9820876121521, "step": 115000}
{"episode_reward": 926.2391785866395, "episode": 116.0, "batch_reward": 0.8264237505793571, "critic_loss": 0.6896237113475799, "actor_loss": -91.45127642822266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.955910682678223, "step": 116000}
{"episode_reward": 932.4608536122246, "episode": 117.0, "batch_reward": 0.8268169888854027, "critic_loss": 0.734453983798623, "actor_loss": -91.44080195617676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.962708234786987, "step": 117000}
{"episode_reward": 876.742303887199, "episode": 118.0, "batch_reward": 0.8264622743725777, "critic_loss": 0.7110832709521056, "actor_loss": -91.51626388549805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.982710123062134, "step": 118000}
{"episode_reward": 985.543279201884, "episode": 119.0, "batch_reward": 0.8289835135340691, "critic_loss": 0.7490637106597423, "actor_loss": -91.43913348388672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.962707042694092, "step": 119000}
{"episode_reward": 902.859130293214, "episode": 120.0, "batch_reward": 0.8271768372654915, "critic_loss": 0.808434721916914, "actor_loss": -91.26499760437012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.960512399673462, "step": 120000}
{"episode_reward": 901.6497843857181, "episode": 121.0, "batch_reward": 0.8300867253541946, "critic_loss": 0.8007501547783613, "actor_loss": -91.36861924743653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.34554672241211, "step": 121000}
{"episode_reward": 985.2397437332843, "episode": 122.0, "batch_reward": 0.8309449393749238, "critic_loss": 0.8100298347473145, "actor_loss": -91.36240222167969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.957948207855225, "step": 122000}
{"episode_reward": 938.0933825181079, "episode": 123.0, "batch_reward": 0.8332950020432472, "critic_loss": 0.8230875356495381, "actor_loss": -91.41396166992187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92778491973877, "step": 123000}
{"episode_reward": 897.7151449377094, "episode": 124.0, "batch_reward": 0.834165061533451, "critic_loss": 0.8186725662648677, "actor_loss": -91.49344493103027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92312455177307, "step": 124000}
{"episode_reward": 978.5898430076987, "episode": 125.0, "batch_reward": 0.834882462978363, "critic_loss": 0.8058352336585521, "actor_loss": -91.56647373962403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.909058094024658, "step": 125000}
{"episode_reward": 981.2014090059898, "episode": 126.0, "batch_reward": 0.835077980518341, "critic_loss": 0.799288118571043, "actor_loss": -91.72913044738769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.91472554206848, "step": 126000}
{"episode_reward": 985.4649017191856, "episode": 127.0, "batch_reward": 0.8363141863942146, "critic_loss": 0.8253766287863255, "actor_loss": -91.77446063232422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.933141946792603, "step": 127000}
{"episode_reward": 934.5294736470281, "episode": 128.0, "batch_reward": 0.836237931907177, "critic_loss": 0.7974546705037355, "actor_loss": -91.83899128723145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.956713676452637, "step": 128000}
{"episode_reward": 966.3073276311749, "episode": 129.0, "batch_reward": 0.8377673509716987, "critic_loss": 0.796452917844057, "actor_loss": -91.88873202514648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94800090789795, "step": 129000}
{"episode_reward": 983.0683757031497, "episode": 130.0, "batch_reward": 0.839963607609272, "critic_loss": 0.8021166515052318, "actor_loss": -91.66213458251953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.962712049484253, "step": 130000}
{"episode_reward": 990.7599925333924, "episode": 131.0, "batch_reward": 0.8413388167023659, "critic_loss": 0.7574189764410257, "actor_loss": -91.74141256713867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.24660396575928, "step": 131000}
{"episode_reward": 978.105150020986, "episode": 132.0, "batch_reward": 0.8420688631534576, "critic_loss": 0.7445856536328792, "actor_loss": -91.66389399719239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.913410186767578, "step": 132000}
{"episode_reward": 978.1529961374657, "episode": 133.0, "batch_reward": 0.8402000969648361, "critic_loss": 0.7978218867182731, "actor_loss": -91.74938534545899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92721176147461, "step": 133000}
{"episode_reward": 952.6194553356045, "episode": 134.0, "batch_reward": 0.841829280614853, "critic_loss": 0.7646555995047093, "actor_loss": -91.85000491333008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.935816049575806, "step": 134000}
{"episode_reward": 965.3054079764421, "episode": 135.0, "batch_reward": 0.8448000211715698, "critic_loss": 0.7579325229972601, "actor_loss": -91.82641906738282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94561791419983, "step": 135000}
{"episode_reward": 989.5414543846254, "episode": 136.0, "batch_reward": 0.8465074650049209, "critic_loss": 0.7549727041125297, "actor_loss": -91.84431204223633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93816041946411, "step": 136000}
{"episode_reward": 990.5681870256343, "episode": 137.0, "batch_reward": 0.8461405744552613, "critic_loss": 0.7487534515857697, "actor_loss": -91.88081158447265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.231120347976685, "step": 137000}
{"episode_reward": 956.9147739460968, "episode": 138.0, "batch_reward": 0.8475759089589119, "critic_loss": 0.721685217231512, "actor_loss": -91.92219987487793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.964072227478027, "step": 138000}
{"episode_reward": 965.989250114121, "episode": 139.0, "batch_reward": 0.8476131418943406, "critic_loss": 0.7384634122550487, "actor_loss": -92.08840536499024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.89571499824524, "step": 139000}
{"episode_reward": 984.7639205954114, "episode": 140.0, "batch_reward": 0.8483186202645302, "critic_loss": 0.6749862153083086, "actor_loss": -92.08365977478027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24017095565796, "step": 140000}
{"episode_reward": 936.0252286354291, "episode": 141.0, "batch_reward": 0.8500835849642754, "critic_loss": 0.672190919175744, "actor_loss": -92.09472790527344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.59763216972351, "step": 141000}
{"episode_reward": 968.9773053836806, "episode": 142.0, "batch_reward": 0.8499794718027115, "critic_loss": 0.6664786838293075, "actor_loss": -92.028254196167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.098496675491333, "step": 142000}
{"episode_reward": 989.7502654086201, "episode": 143.0, "batch_reward": 0.8516924071311951, "critic_loss": 0.6824645146578551, "actor_loss": -92.27505654907226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.583380222320557, "step": 143000}
{"episode_reward": 931.7490428286358, "episode": 144.0, "batch_reward": 0.851936552643776, "critic_loss": 0.6921921102851629, "actor_loss": -92.13746612548829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.41984534263611, "step": 144000}
{"episode_reward": 961.4136822550859, "episode": 145.0, "batch_reward": 0.8540095379352569, "critic_loss": 0.6759791600704194, "actor_loss": -92.26983938598633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.549680709838867, "step": 145000}
{"episode_reward": 987.3473979703566, "episode": 146.0, "batch_reward": 0.8525050478577614, "critic_loss": 0.6398967164903879, "actor_loss": -92.37468342590331, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109275579452515, "step": 146000}
{"episode_reward": 960.5303716031185, "episode": 147.0, "batch_reward": 0.8530540123581887, "critic_loss": 0.6352448924034834, "actor_loss": -92.37002165222168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.46947169303894, "step": 147000}
{"episode_reward": 951.7079019349349, "episode": 148.0, "batch_reward": 0.8558543489575386, "critic_loss": 0.6193048220723868, "actor_loss": -92.48958383178712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.802082061767578, "step": 148000}
{"episode_reward": 974.2707809306197, "episode": 149.0, "batch_reward": 0.8552279802560806, "critic_loss": 0.6134635754674673, "actor_loss": -92.41127333068847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.14543652534485, "step": 149000}
{"episode_reward": 941.0051138272494, "episode": 150.0, "batch_reward": 0.85703179615736, "critic_loss": 0.6232871946841478, "actor_loss": -92.62182971191406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
