{"episode_reward": 0.0, "episode": 1.0, "duration": 20.937169313430786, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.8383746147155762, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.45193531123965375, "critic_loss": 0.1533097159732338, "actor_loss": -28.7714094113642, "actor_target_entropy": -6.0, "alpha_value": 0.0033185846155115383, "duration": 61.09509801864624, "step": 3000}
{"episode_reward": 98.0840113620523, "episode": 4.0, "batch_reward": 0.33001796214282514, "critic_loss": 0.4156122718304396, "actor_loss": -35.27969544219971, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.423426628112793, "step": 4000}
{"episode_reward": 193.28487686053487, "episode": 5.0, "batch_reward": 0.32642828024923803, "critic_loss": 0.6847921523749828, "actor_loss": -32.33263927268982, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.382033348083496, "step": 5000}
{"episode_reward": 482.5303348364024, "episode": 6.0, "batch_reward": 0.35896436193585396, "critic_loss": 0.9628618654608726, "actor_loss": -35.979326190948484, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.413413763046265, "step": 6000}
{"episode_reward": 488.93043102192405, "episode": 7.0, "batch_reward": 0.36127144780755044, "critic_loss": 0.9963152601122857, "actor_loss": -39.291326694488525, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.390841960906982, "step": 7000}
{"episode_reward": 297.90362377708135, "episode": 8.0, "batch_reward": 0.3595269170701504, "critic_loss": 1.3646912463903427, "actor_loss": -40.57689460754395, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.42295742034912, "step": 8000}
{"episode_reward": 402.0154449644319, "episode": 9.0, "batch_reward": 0.35194513806700706, "critic_loss": 1.2341634576916696, "actor_loss": -45.12719477081299, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.443852186203003, "step": 9000}
{"episode_reward": 267.97983147753945, "episode": 10.0, "batch_reward": 0.37561916652321814, "critic_loss": 1.2255266340970994, "actor_loss": -45.23397476196289, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.408918619155884, "step": 10000}
{"episode_reward": 767.7798790037976, "episode": 11.0, "batch_reward": 0.4077861045598984, "critic_loss": 1.3609767595529556, "actor_loss": -50.638439632415775, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.22352910041809, "step": 11000}
{"episode_reward": 726.6475964322198, "episode": 12.0, "batch_reward": 0.43881822082400324, "critic_loss": 1.668027482688427, "actor_loss": -52.44265287780762, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.419525861740112, "step": 12000}
{"episode_reward": 803.2464409927466, "episode": 13.0, "batch_reward": 0.4637268615961075, "critic_loss": 1.5873727092146874, "actor_loss": -54.73518168640137, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.445852518081665, "step": 13000}
{"episode_reward": 759.6320136023113, "episode": 14.0, "batch_reward": 0.48852538162469866, "critic_loss": 1.7142695432901383, "actor_loss": -55.27339996337891, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.432934761047363, "step": 14000}
{"episode_reward": 822.0464027656677, "episode": 15.0, "batch_reward": 0.5156597865521908, "critic_loss": 1.7622302615046501, "actor_loss": -59.94361417388916, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.39569616317749, "step": 15000}
{"episode_reward": 886.4667206333286, "episode": 16.0, "batch_reward": 0.5363763088285923, "critic_loss": 1.7958159945011138, "actor_loss": -61.86279837799072, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.4285089969635, "step": 16000}
{"episode_reward": 818.3315117321068, "episode": 17.0, "batch_reward": 0.5530139169692994, "critic_loss": 1.7146461599469185, "actor_loss": -62.90190801239014, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.450931310653687, "step": 17000}
{"episode_reward": 796.9740667561568, "episode": 18.0, "batch_reward": 0.5681696915626526, "critic_loss": 1.7607860771417618, "actor_loss": -63.69221450042725, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.41709065437317, "step": 18000}
{"episode_reward": 749.1866165785553, "episode": 19.0, "batch_reward": 0.5839285843968391, "critic_loss": 1.691725998878479, "actor_loss": -67.36314456176758, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.4151930809021, "step": 19000}
{"episode_reward": 970.5673222743605, "episode": 20.0, "batch_reward": 0.595258641988039, "critic_loss": 1.8214097013473511, "actor_loss": -68.26864493560791, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.444312810897827, "step": 20000}
{"episode_reward": 673.6700948971057, "episode": 21.0, "batch_reward": 0.5979399719834327, "critic_loss": 1.992350991845131, "actor_loss": -70.00546423339844, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.15795278549194, "step": 21000}
{"episode_reward": 666.5103504505014, "episode": 22.0, "batch_reward": 0.6080736761689186, "critic_loss": 1.8751371169090272, "actor_loss": -69.82516316223145, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.444138288497925, "step": 22000}
{"episode_reward": 796.9594134925972, "episode": 23.0, "batch_reward": 0.6158261364400387, "critic_loss": 2.0332259060144424, "actor_loss": -69.6758549041748, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.3928861618042, "step": 23000}
{"episode_reward": 877.2449911322119, "episode": 24.0, "batch_reward": 0.626420209646225, "critic_loss": 1.8960116740465165, "actor_loss": -71.60990545654298, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.4358012676239, "step": 24000}
{"episode_reward": 856.1921850723157, "episode": 25.0, "batch_reward": 0.6328114832043648, "critic_loss": 1.8916333711743354, "actor_loss": -72.25700396728516, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44469976425171, "step": 25000}
{"episode_reward": 830.8170684757575, "episode": 26.0, "batch_reward": 0.6398221195936203, "critic_loss": 1.9309064863920211, "actor_loss": -73.01166227722167, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.399043798446655, "step": 26000}
{"episode_reward": 837.157464709909, "episode": 27.0, "batch_reward": 0.6533587073683739, "critic_loss": 1.9261099247932434, "actor_loss": -73.97112908935547, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.443111896514893, "step": 27000}
{"episode_reward": 874.0352708274224, "episode": 28.0, "batch_reward": 0.6599691765904426, "critic_loss": 1.9233564599752426, "actor_loss": -74.80353860473633, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.416927814483643, "step": 28000}
{"episode_reward": 902.6387263076497, "episode": 29.0, "batch_reward": 0.6658426811099052, "critic_loss": 1.8302100083827972, "actor_loss": -75.5339294128418, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.388201475143433, "step": 29000}
{"episode_reward": 846.8996496167379, "episode": 30.0, "batch_reward": 0.6754850575327873, "critic_loss": 1.7688428968191148, "actor_loss": -76.19802127075195, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.423572301864624, "step": 30000}
{"episode_reward": 913.8663056831493, "episode": 31.0, "batch_reward": 0.6801956315636635, "critic_loss": 1.7776949279308318, "actor_loss": -76.62021513366699, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.144797563552856, "step": 31000}
{"episode_reward": 902.1657342041639, "episode": 32.0, "batch_reward": 0.6897350749969482, "critic_loss": 1.6688937330245972, "actor_loss": -77.9681890258789, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.437424659729004, "step": 32000}
{"episode_reward": 905.4455917504131, "episode": 33.0, "batch_reward": 0.6960815424919129, "critic_loss": 1.4962761553525925, "actor_loss": -78.1818748626709, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.409057140350342, "step": 33000}
{"episode_reward": 941.9508905880521, "episode": 34.0, "batch_reward": 0.7046050580739975, "critic_loss": 1.4236241119503974, "actor_loss": -77.86544085693359, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.42005729675293, "step": 34000}
{"episode_reward": 985.6566524542554, "episode": 35.0, "batch_reward": 0.710275444328785, "critic_loss": 1.3873131385445594, "actor_loss": -79.16056636047364, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.41546130180359, "step": 35000}
{"episode_reward": 900.2257965522805, "episode": 36.0, "batch_reward": 0.7153540790677071, "critic_loss": 1.3424236194491386, "actor_loss": -79.6844721069336, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.434330463409424, "step": 36000}
{"episode_reward": 943.3726795209737, "episode": 37.0, "batch_reward": 0.7211315249800682, "critic_loss": 1.2142286447286605, "actor_loss": -79.89214065551758, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.426263093948364, "step": 37000}
{"episode_reward": 954.9827831520472, "episode": 38.0, "batch_reward": 0.7293689600825309, "critic_loss": 1.1389571941494943, "actor_loss": -80.28416622924804, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.42201852798462, "step": 38000}
{"episode_reward": 980.7349637176779, "episode": 39.0, "batch_reward": 0.736063801586628, "critic_loss": 1.177602933704853, "actor_loss": -81.5701443939209, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.40939211845398, "step": 39000}
{"episode_reward": 978.3217029049221, "episode": 40.0, "batch_reward": 0.7426494704484939, "critic_loss": 1.0403104080557823, "actor_loss": -81.97278529357911, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.38316559791565, "step": 40000}
{"episode_reward": 965.2542687795396, "episode": 41.0, "batch_reward": 0.745332587659359, "critic_loss": 1.1394829529523849, "actor_loss": -82.3364782409668, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.13160586357117, "step": 41000}
{"episode_reward": 889.4189244764214, "episode": 42.0, "batch_reward": 0.7522153735160828, "critic_loss": 1.0526073864102363, "actor_loss": -82.10340863037109, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43272590637207, "step": 42000}
{"episode_reward": 961.1905850808471, "episode": 43.0, "batch_reward": 0.7547018572092056, "critic_loss": 1.0430050613284112, "actor_loss": -82.62826524353028, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.404581308364868, "step": 43000}
{"episode_reward": 913.2244807198322, "episode": 44.0, "batch_reward": 0.7587859237194061, "critic_loss": 1.0260957956910133, "actor_loss": -83.03637274169922, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.389989137649536, "step": 44000}
{"episode_reward": 979.6405977913721, "episode": 45.0, "batch_reward": 0.7633959090709687, "critic_loss": 0.9713166877627373, "actor_loss": -83.62356303405761, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.438612699508667, "step": 45000}
{"episode_reward": 939.7117588195034, "episode": 46.0, "batch_reward": 0.7660903497338295, "critic_loss": 0.9715885983109475, "actor_loss": -83.9714012298584, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.383920669555664, "step": 46000}
{"episode_reward": 909.6182873996421, "episode": 47.0, "batch_reward": 0.7717894522547721, "critic_loss": 0.9466476236879826, "actor_loss": -84.01638189697266, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.434932947158813, "step": 47000}
{"episode_reward": 931.8116809530802, "episode": 48.0, "batch_reward": 0.7744989026784896, "critic_loss": 0.9518912539482117, "actor_loss": -84.13015446472168, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.435659885406494, "step": 48000}
{"episode_reward": 938.0804284843191, "episode": 49.0, "batch_reward": 0.7786965514421463, "critic_loss": 0.9977570422291756, "actor_loss": -84.75535237121582, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.42003345489502, "step": 49000}
{"episode_reward": 934.1684235441454, "episode": 50.0, "batch_reward": 0.7811218294501304, "critic_loss": 0.9440741710066796, "actor_loss": -84.697673828125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.41481304168701, "step": 50000}
{"episode_reward": 987.5208057124433, "episode": 51.0, "batch_reward": 0.7872500504255295, "critic_loss": 0.9459574275612831, "actor_loss": -84.87905320739746, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.20747089385986, "step": 51000}
{"episode_reward": 976.9300058048253, "episode": 52.0, "batch_reward": 0.7891414132118225, "critic_loss": 0.9228399333357811, "actor_loss": -85.65876625061036, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.46384572982788, "step": 52000}
{"episode_reward": 955.9617446272471, "episode": 53.0, "batch_reward": 0.7909667358994484, "critic_loss": 0.9070769696235657, "actor_loss": -85.81661044311524, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.450709342956543, "step": 53000}
{"episode_reward": 817.3731536949322, "episode": 54.0, "batch_reward": 0.7931073526144028, "critic_loss": 0.928784470051527, "actor_loss": -85.70109803771973, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.395913124084473, "step": 54000}
{"episode_reward": 943.8357525215661, "episode": 55.0, "batch_reward": 0.7947565025091171, "critic_loss": 0.9008335920274257, "actor_loss": -85.76213494873046, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.402161598205566, "step": 55000}
{"episode_reward": 963.4073147721796, "episode": 56.0, "batch_reward": 0.7985585898160934, "critic_loss": 0.8899139903485775, "actor_loss": -86.1650254058838, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.451005935668945, "step": 56000}
{"episode_reward": 979.2333832126793, "episode": 57.0, "batch_reward": 0.8015604364275932, "critic_loss": 0.9355239494144917, "actor_loss": -86.53516368103027, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.416774034500122, "step": 57000}
{"episode_reward": 921.3713113374229, "episode": 58.0, "batch_reward": 0.8051232507824898, "critic_loss": 0.8672229376137257, "actor_loss": -86.31538891601562, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.4043231010437, "step": 58000}
{"episode_reward": 975.8117390035321, "episode": 59.0, "batch_reward": 0.8065634273290634, "critic_loss": 0.8927128821611404, "actor_loss": -87.15097828674317, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.444570064544678, "step": 59000}
{"episode_reward": 857.9245628065454, "episode": 60.0, "batch_reward": 0.8076275048851966, "critic_loss": 0.8711158341765404, "actor_loss": -87.20580201721191, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.401949644088745, "step": 60000}
{"episode_reward": 946.6042216832604, "episode": 61.0, "batch_reward": 0.8112054423689842, "critic_loss": 0.9139628404676914, "actor_loss": -87.16769203186035, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.224833965301514, "step": 61000}
{"episode_reward": 953.7808473410395, "episode": 62.0, "batch_reward": 0.811437084376812, "critic_loss": 0.8715325002074241, "actor_loss": -87.03175947570801, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.434598207473755, "step": 62000}
{"episode_reward": 943.1540006335888, "episode": 63.0, "batch_reward": 0.812647466301918, "critic_loss": 0.8852801215350627, "actor_loss": -87.49256436157226, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.428630590438843, "step": 63000}
{"episode_reward": 907.3558465977551, "episode": 64.0, "batch_reward": 0.8155787935853005, "critic_loss": 0.881662230938673, "actor_loss": -87.67749407958985, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.407883167266846, "step": 64000}
{"episode_reward": 974.3747410035594, "episode": 65.0, "batch_reward": 0.8174745318889618, "critic_loss": 0.8970301983356476, "actor_loss": -87.88408329772949, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.404921770095825, "step": 65000}
{"episode_reward": 863.3405751438834, "episode": 66.0, "batch_reward": 0.8181879443526268, "critic_loss": 0.8539154915809631, "actor_loss": -87.98432614135743, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.451998472213745, "step": 66000}
{"episode_reward": 945.0589659039337, "episode": 67.0, "batch_reward": 0.818996259868145, "critic_loss": 0.8620307671129703, "actor_loss": -88.30455923461913, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43443775177002, "step": 67000}
{"episode_reward": 917.9623770075597, "episode": 68.0, "batch_reward": 0.8224054005742073, "critic_loss": 0.847051756709814, "actor_loss": -88.07248176574707, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.435672283172607, "step": 68000}
{"episode_reward": 948.2731428323526, "episode": 69.0, "batch_reward": 0.823500906765461, "critic_loss": 0.8499626870453357, "actor_loss": -88.30821867370605, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.436631202697754, "step": 69000}
{"episode_reward": 983.0602724375304, "episode": 70.0, "batch_reward": 0.8262696906924247, "critic_loss": 0.8467969335317612, "actor_loss": -88.61260905456543, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.454236268997192, "step": 70000}
{"episode_reward": 964.5155735938051, "episode": 71.0, "batch_reward": 0.829249924659729, "critic_loss": 0.8472130378186703, "actor_loss": -88.60263987731933, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.187310457229614, "step": 71000}
{"episode_reward": 937.8931949291779, "episode": 72.0, "batch_reward": 0.8312863745689392, "critic_loss": 0.7886281223297119, "actor_loss": -88.85252359008788, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.46703863143921, "step": 72000}
{"episode_reward": 975.7814678782095, "episode": 73.0, "batch_reward": 0.8316387653946876, "critic_loss": 0.8294840493798256, "actor_loss": -89.0364047088623, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.40114665031433, "step": 73000}
{"episode_reward": 956.0418046704842, "episode": 74.0, "batch_reward": 0.8334859545826911, "critic_loss": 0.9223837651908398, "actor_loss": -89.23993663024902, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.4479558467865, "step": 74000}
{"episode_reward": 864.1812539808027, "episode": 75.0, "batch_reward": 0.8345474932789803, "critic_loss": 0.9398168060481549, "actor_loss": -89.21135578918457, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.443177223205566, "step": 75000}
{"episode_reward": 957.8598141499383, "episode": 76.0, "batch_reward": 0.8367488100528717, "critic_loss": 0.8302779832184315, "actor_loss": -89.3014044494629, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44972014427185, "step": 76000}
{"episode_reward": 980.743388096163, "episode": 77.0, "batch_reward": 0.8371245762705803, "critic_loss": 0.790020732730627, "actor_loss": -89.40332759094238, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.430434942245483, "step": 77000}
{"episode_reward": 963.0112210194242, "episode": 78.0, "batch_reward": 0.8395150572657585, "critic_loss": 0.7737756028175354, "actor_loss": -89.63198985290528, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.42438268661499, "step": 78000}
{"episode_reward": 958.2092299532343, "episode": 79.0, "batch_reward": 0.8409431327581406, "critic_loss": 0.7803406226038933, "actor_loss": -89.654425491333, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.430837154388428, "step": 79000}
{"episode_reward": 955.8374220365298, "episode": 80.0, "batch_reward": 0.8406629338860512, "critic_loss": 0.798242781728506, "actor_loss": -89.66843229675293, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.408654928207397, "step": 80000}
{"episode_reward": 975.7596489976374, "episode": 81.0, "batch_reward": 0.8445690680146217, "critic_loss": 0.7716598340272903, "actor_loss": -90.03736480712891, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.14505314826965, "step": 81000}
{"episode_reward": 938.2296145987102, "episode": 82.0, "batch_reward": 0.8452887744903564, "critic_loss": 0.7209444978833198, "actor_loss": -90.00543955993652, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44529938697815, "step": 82000}
{"episode_reward": 961.95326372607, "episode": 83.0, "batch_reward": 0.8459531511664391, "critic_loss": 0.7682276802361011, "actor_loss": -90.18789813232422, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43261194229126, "step": 83000}
{"episode_reward": 910.0284013435212, "episode": 84.0, "batch_reward": 0.8476202290654182, "critic_loss": 0.7564168912172318, "actor_loss": -90.2239655456543, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.439656972885132, "step": 84000}
{"episode_reward": 986.217794445629, "episode": 85.0, "batch_reward": 0.847351090669632, "critic_loss": 0.7522920069992542, "actor_loss": -90.18221220397949, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.411969900131226, "step": 85000}
{"episode_reward": 942.1006596902541, "episode": 86.0, "batch_reward": 0.8486200807094574, "critic_loss": 0.7345739346146584, "actor_loss": -90.30415191650391, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.421201944351196, "step": 86000}
{"episode_reward": 956.4239085093775, "episode": 87.0, "batch_reward": 0.8508087572455406, "critic_loss": 0.748313809812069, "actor_loss": -90.43308433532715, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.431934118270874, "step": 87000}
{"episode_reward": 930.1236597817416, "episode": 88.0, "batch_reward": 0.8523609602451324, "critic_loss": 0.6801437160670757, "actor_loss": -90.47578178405762, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.384674072265625, "step": 88000}
{"episode_reward": 951.929864480172, "episode": 89.0, "batch_reward": 0.8504691793322563, "critic_loss": 0.7157906142771244, "actor_loss": -90.35799555969238, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.41500186920166, "step": 89000}
{"episode_reward": 941.991626297283, "episode": 90.0, "batch_reward": 0.8544631740450859, "critic_loss": 0.7136205044090748, "actor_loss": -90.64947520446778, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.419044733047485, "step": 90000}
{"episode_reward": 959.8658293790419, "episode": 91.0, "batch_reward": 0.8558883469104767, "critic_loss": 0.7041688490658998, "actor_loss": -90.467377243042, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.13178539276123, "step": 91000}
{"episode_reward": 917.5616432119174, "episode": 92.0, "batch_reward": 0.8577643074393272, "critic_loss": 0.6996551330983639, "actor_loss": -90.85713710021973, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.418187379837036, "step": 92000}
{"episode_reward": 961.793774346922, "episode": 93.0, "batch_reward": 0.8557636157274247, "critic_loss": 0.7069682514369487, "actor_loss": -90.66570469665527, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.413686513900757, "step": 93000}
{"episode_reward": 918.8097624159185, "episode": 94.0, "batch_reward": 0.8571162956357002, "critic_loss": 0.7158014786839485, "actor_loss": -90.90989988708496, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.432488679885864, "step": 94000}
{"episode_reward": 924.58937359397, "episode": 95.0, "batch_reward": 0.8575285558700562, "critic_loss": 0.7215217610001564, "actor_loss": -90.84700543212891, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43849468231201, "step": 95000}
{"episode_reward": 957.6896472208888, "episode": 96.0, "batch_reward": 0.8584241608977318, "critic_loss": 0.6919675553441048, "actor_loss": -90.89173640441895, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.4031822681427, "step": 96000}
{"episode_reward": 929.7135503002322, "episode": 97.0, "batch_reward": 0.8596994566321373, "critic_loss": 0.725453431636095, "actor_loss": -90.91091986083984, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.400357007980347, "step": 97000}
{"episode_reward": 880.7462660712349, "episode": 98.0, "batch_reward": 0.8601245436668395, "critic_loss": 0.706115238904953, "actor_loss": -91.03430548095703, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.434022665023804, "step": 98000}
{"episode_reward": 908.3488627781754, "episode": 99.0, "batch_reward": 0.8609506300091744, "critic_loss": 0.7040443373322487, "actor_loss": -91.01361387634277, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.39800453186035, "step": 99000}
{"episode_reward": 946.425614664053, "episode": 100.0, "batch_reward": 0.8627717000842094, "critic_loss": 0.6889014150202274, "actor_loss": -91.0541742401123, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.42051649093628, "step": 100000}
{"episode_reward": 875.2365800668482, "episode": 101.0, "batch_reward": 0.8634834688305855, "critic_loss": 0.6907299237549305, "actor_loss": -91.19581401062011, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.16317677497864, "step": 101000}
{"episode_reward": 983.5421394677234, "episode": 102.0, "batch_reward": 0.8632195425629616, "critic_loss": 0.6954986267536879, "actor_loss": -91.26261569213867, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.412697792053223, "step": 102000}
{"episode_reward": 986.3834708558187, "episode": 103.0, "batch_reward": 0.8625700659155846, "critic_loss": 0.7016810567080974, "actor_loss": -91.16850202941895, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.418662071228027, "step": 103000}
{"episode_reward": 960.6714764906479, "episode": 104.0, "batch_reward": 0.8655911182165146, "critic_loss": 0.678896733045578, "actor_loss": -91.32825119018554, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.40008282661438, "step": 104000}
{"episode_reward": 960.2844351983573, "episode": 105.0, "batch_reward": 0.8674573578238487, "critic_loss": 0.6924679630547762, "actor_loss": -91.34778578186035, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.451016664505005, "step": 105000}
{"episode_reward": 905.9255869403817, "episode": 106.0, "batch_reward": 0.8657521728873253, "critic_loss": 0.6501377485692501, "actor_loss": -91.25241595458985, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.402897357940674, "step": 106000}
{"episode_reward": 922.0271705304917, "episode": 107.0, "batch_reward": 0.8661924434304238, "critic_loss": 0.7138473681211471, "actor_loss": -91.35841445922851, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.403977394104004, "step": 107000}
{"episode_reward": 941.4055133759418, "episode": 108.0, "batch_reward": 0.8686691039204597, "critic_loss": 0.6989254610836506, "actor_loss": -91.59868463134765, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.439072608947754, "step": 108000}
{"episode_reward": 951.4867516855147, "episode": 109.0, "batch_reward": 0.8690609622001648, "critic_loss": 0.6655351771116257, "actor_loss": -91.60560884094238, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.439769506454468, "step": 109000}
{"episode_reward": 967.6965916304868, "episode": 110.0, "batch_reward": 0.868602035164833, "critic_loss": 0.6531997961848974, "actor_loss": -91.60834474182128, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.41622829437256, "step": 110000}
{"episode_reward": 918.2212096167898, "episode": 111.0, "batch_reward": 0.8694209542274475, "critic_loss": 0.6557120703458786, "actor_loss": -91.60486163330079, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.23311710357666, "step": 111000}
{"episode_reward": 941.1445125045424, "episode": 112.0, "batch_reward": 0.8705600368380546, "critic_loss": 0.6789681718051434, "actor_loss": -91.62627778625489, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.38195037841797, "step": 112000}
{"episode_reward": 944.6098908792871, "episode": 113.0, "batch_reward": 0.872399219095707, "critic_loss": 0.6798165475428104, "actor_loss": -91.71758738708496, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.444059133529663, "step": 113000}
{"episode_reward": 961.1267768247164, "episode": 114.0, "batch_reward": 0.8725470191240311, "critic_loss": 0.6478293558657169, "actor_loss": -91.7522819366455, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.440378189086914, "step": 114000}
{"episode_reward": 973.5241615466879, "episode": 115.0, "batch_reward": 0.8726582394838334, "critic_loss": 0.6555237870514393, "actor_loss": -91.67139433288574, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.415276765823364, "step": 115000}
{"episode_reward": 943.2343871640039, "episode": 116.0, "batch_reward": 0.8739664607048034, "critic_loss": 0.6330108393728733, "actor_loss": -91.7954372253418, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.420931577682495, "step": 116000}
{"episode_reward": 953.5550206425631, "episode": 117.0, "batch_reward": 0.8737307758331299, "critic_loss": 0.6792880481779575, "actor_loss": -91.81289395141602, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.427773237228394, "step": 117000}
{"episode_reward": 869.4348591852432, "episode": 118.0, "batch_reward": 0.8737319937944412, "critic_loss": 0.6326415516734123, "actor_loss": -91.90091418457031, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.419811248779297, "step": 118000}
{"episode_reward": 979.2817956178463, "episode": 119.0, "batch_reward": 0.8751697684526444, "critic_loss": 0.6563635272085666, "actor_loss": -91.73834838867188, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.416272401809692, "step": 119000}
{"episode_reward": 901.4727326691577, "episode": 120.0, "batch_reward": 0.8735316204428673, "critic_loss": 0.6515960977971553, "actor_loss": -91.60357836914062, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.437222957611084, "step": 120000}
{"episode_reward": 922.4193307221042, "episode": 121.0, "batch_reward": 0.8759431920647621, "critic_loss": 0.6394378066062927, "actor_loss": -91.70018623352051, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.18498969078064, "step": 121000}
{"episode_reward": 983.903681508299, "episode": 122.0, "batch_reward": 0.8757648496627808, "critic_loss": 0.6931736587285996, "actor_loss": -91.70112107849121, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.442951917648315, "step": 122000}
{"episode_reward": 947.7059839020006, "episode": 123.0, "batch_reward": 0.877442900776863, "critic_loss": 0.6677317943274975, "actor_loss": -91.8779658203125, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.466003894805908, "step": 123000}
{"episode_reward": 938.197846200849, "episode": 124.0, "batch_reward": 0.8771425991654396, "critic_loss": 0.6956629884690047, "actor_loss": -91.89456861877441, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.417705535888672, "step": 124000}
{"episode_reward": 978.4380480976325, "episode": 125.0, "batch_reward": 0.8792433617711067, "critic_loss": 0.647895492374897, "actor_loss": -91.96480107116699, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.423800945281982, "step": 125000}
{"episode_reward": 982.2966476584622, "episode": 126.0, "batch_reward": 0.8794711654186249, "critic_loss": 0.6408202686011791, "actor_loss": -92.1162804107666, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43039846420288, "step": 126000}
{"episode_reward": 977.1352143865682, "episode": 127.0, "batch_reward": 0.8788102957010269, "critic_loss": 0.6767114741206169, "actor_loss": -92.09268402099609, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.40028476715088, "step": 127000}
{"episode_reward": 944.6409037383615, "episode": 128.0, "batch_reward": 0.880343661904335, "critic_loss": 0.6055162578374147, "actor_loss": -92.1918020324707, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43143057823181, "step": 128000}
{"episode_reward": 963.2538299180696, "episode": 129.0, "batch_reward": 0.8809371030926705, "critic_loss": 0.6262580880075693, "actor_loss": -92.33620162963867, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.425983667373657, "step": 129000}
{"episode_reward": 976.2761406708619, "episode": 130.0, "batch_reward": 0.8835028901100158, "critic_loss": 0.6084693718999624, "actor_loss": -92.23783639526367, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.403173208236694, "step": 130000}
{"episode_reward": 990.24134588491, "episode": 131.0, "batch_reward": 0.883285247862339, "critic_loss": 0.62782217502594, "actor_loss": -92.24468542480469, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.17560029029846, "step": 131000}
{"episode_reward": 959.103870303787, "episode": 132.0, "batch_reward": 0.8839290611147881, "critic_loss": 0.5920236298441887, "actor_loss": -92.23614459228516, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.42535662651062, "step": 132000}
{"episode_reward": 986.7931780553256, "episode": 133.0, "batch_reward": 0.8840397526621818, "critic_loss": 0.6044055311828852, "actor_loss": -92.45153675842285, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.436954021453857, "step": 133000}
{"episode_reward": 932.7186320199202, "episode": 134.0, "batch_reward": 0.8848714228272438, "critic_loss": 0.5871494051367044, "actor_loss": -92.48655899047851, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.42786431312561, "step": 134000}
{"episode_reward": 953.0036046776271, "episode": 135.0, "batch_reward": 0.8865020026564598, "critic_loss": 0.5900782690793276, "actor_loss": -92.45115783691406, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.41500449180603, "step": 135000}
{"episode_reward": 991.9248774770538, "episode": 136.0, "batch_reward": 0.886436488211155, "critic_loss": 0.6028566345274449, "actor_loss": -92.39392785644532, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.425179958343506, "step": 136000}
{"episode_reward": 982.5455397629004, "episode": 137.0, "batch_reward": 0.8856489645242691, "critic_loss": 0.6045868941098451, "actor_loss": -92.36482426452636, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.42967677116394, "step": 137000}
{"episode_reward": 975.0329453502701, "episode": 138.0, "batch_reward": 0.8882990707159042, "critic_loss": 0.6125361310243607, "actor_loss": -92.45381800842286, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.370630502700806, "step": 138000}
{"episode_reward": 916.8686101968196, "episode": 139.0, "batch_reward": 0.887581536591053, "critic_loss": 0.5787615359276533, "actor_loss": -92.5296506652832, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.429139614105225, "step": 139000}
{"episode_reward": 968.4435077765808, "episode": 140.0, "batch_reward": 0.88747995865345, "critic_loss": 0.596474698111415, "actor_loss": -92.54137107849121, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.426066160202026, "step": 140000}
{"episode_reward": 923.6074595309432, "episode": 141.0, "batch_reward": 0.8884696567058563, "critic_loss": 0.5877571595907212, "actor_loss": -92.54004200744629, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 40.25882649421692, "step": 141000}
{"episode_reward": 947.4932721879098, "episode": 142.0, "batch_reward": 0.8878909581303597, "critic_loss": 0.5573486891388894, "actor_loss": -92.44930450439453, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.3929443359375, "step": 142000}
{"episode_reward": 989.0220093443588, "episode": 143.0, "batch_reward": 0.8899369226098061, "critic_loss": 0.6095512164980174, "actor_loss": -92.61552598571777, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.36683678627014, "step": 143000}
{"episode_reward": 898.3453036471057, "episode": 144.0, "batch_reward": 0.8889632883667946, "critic_loss": 0.5825290904790164, "actor_loss": -92.56890856933593, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.793745756149292, "step": 144000}
{"episode_reward": 947.6364233562667, "episode": 145.0, "batch_reward": 0.8902008203268051, "critic_loss": 0.5768458701521159, "actor_loss": -92.58554830932617, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.418368339538574, "step": 145000}
{"episode_reward": 987.3067886401183, "episode": 146.0, "batch_reward": 0.8899389906525612, "critic_loss": 0.6067983026057482, "actor_loss": -92.72377200317383, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.397475957870483, "step": 146000}
{"episode_reward": 963.209806098372, "episode": 147.0, "batch_reward": 0.8896949800848961, "critic_loss": 0.569366900920868, "actor_loss": -92.68799504089355, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.44282364845276, "step": 147000}
{"episode_reward": 952.3182840445481, "episode": 148.0, "batch_reward": 0.8919029494524002, "critic_loss": 0.556203065738082, "actor_loss": -92.77668101501465, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43376922607422, "step": 148000}
{"episode_reward": 986.0168847748564, "episode": 149.0, "batch_reward": 0.8918400775194169, "critic_loss": 0.5690852363854647, "actor_loss": -92.7031364440918, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "duration": 20.43537664413452, "step": 149000}
{"episode_reward": 944.6688764838703, "episode": 150.0, "batch_reward": 0.8921324440836906, "critic_loss": 0.5738841564506292, "actor_loss": -92.8395986175537, "actor_target_entropy": -6.0, "alpha_value": 0.003318584615511434, "step": 150000}
