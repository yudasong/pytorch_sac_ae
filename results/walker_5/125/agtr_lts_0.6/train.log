{"episode_reward": 0.0, "episode": 1.0, "duration": 20.56671118736267, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.7868282794952393, "step": 2000}
{"episode_reward": 981.6628711771527, "episode": 3.0, "batch_reward": 0.5468083255964344, "critic_loss": 0.1886124300580098, "actor_loss": -88.28068521414913, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.4449245929718, "step": 3000}
{"episode_reward": 956.9145285499727, "episode": 4.0, "batch_reward": 0.6994201522469521, "critic_loss": 0.23991470063477754, "actor_loss": -93.40185906982421, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.066887140274048, "step": 4000}
{"episode_reward": 955.4331685347319, "episode": 5.0, "batch_reward": 0.7582596018910408, "critic_loss": 0.2857056560367346, "actor_loss": -94.92349958801269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03497004508972, "step": 5000}
{"episode_reward": 961.6776445029643, "episode": 6.0, "batch_reward": 0.7966517850160598, "critic_loss": 0.18488270325958728, "actor_loss": -95.27358180236817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.035022258758545, "step": 6000}
{"episode_reward": 975.957197736634, "episode": 7.0, "batch_reward": 0.8146332066059112, "critic_loss": 0.2487626010403037, "actor_loss": -95.04385438537598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03583002090454, "step": 7000}
{"episode_reward": 904.6242233438828, "episode": 8.0, "batch_reward": 0.8302120932340622, "critic_loss": 0.24851679839938878, "actor_loss": -95.14781504821778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.028241395950317, "step": 8000}
{"episode_reward": 894.8579176945785, "episode": 9.0, "batch_reward": 0.8353645437955857, "critic_loss": 0.2373847695067525, "actor_loss": -95.03247583007813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04441237449646, "step": 9000}
{"episode_reward": 909.1049090921202, "episode": 10.0, "batch_reward": 0.8430975413322449, "critic_loss": 0.24254254622757435, "actor_loss": -94.90923027038575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03903841972351, "step": 10000}
{"episode_reward": 898.5177636912402, "episode": 11.0, "batch_reward": 0.8530245314836502, "critic_loss": 0.20914254204928875, "actor_loss": -94.9741339263916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.354132652282715, "step": 11000}
{"episode_reward": 978.28411391932, "episode": 12.0, "batch_reward": 0.8601921729445458, "critic_loss": 0.20533525646477938, "actor_loss": -95.11874240112304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.036209106445312, "step": 12000}
{"episode_reward": 943.3063527343618, "episode": 13.0, "batch_reward": 0.8652031740546227, "critic_loss": 0.23505346740037203, "actor_loss": -95.12505369567872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.053548097610474, "step": 13000}
{"episode_reward": 896.015614890464, "episode": 14.0, "batch_reward": 0.873910684466362, "critic_loss": 0.20153769064694643, "actor_loss": -95.32228218078613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.046031713485718, "step": 14000}
{"episode_reward": 978.2562692282193, "episode": 15.0, "batch_reward": 0.8814900398850442, "critic_loss": 0.19619475112110377, "actor_loss": -95.33756916809082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03516912460327, "step": 15000}
{"episode_reward": 985.236794413411, "episode": 16.0, "batch_reward": 0.8800529782176018, "critic_loss": 0.34870849216729405, "actor_loss": -95.19092337036133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.032675743103027, "step": 16000}
{"episode_reward": 824.601652446395, "episode": 17.0, "batch_reward": 0.8802359511256218, "critic_loss": 0.3118400555849075, "actor_loss": -95.13484996032714, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.045753240585327, "step": 17000}
{"episode_reward": 920.9014685533805, "episode": 18.0, "batch_reward": 0.8824357314109802, "critic_loss": 0.3260725766420364, "actor_loss": -95.1227908782959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03716731071472, "step": 18000}
{"episode_reward": 889.1632596655637, "episode": 19.0, "batch_reward": 0.8857853580117225, "critic_loss": 0.284763897947967, "actor_loss": -95.20664668273926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03667163848877, "step": 19000}
{"episode_reward": 968.7090346503645, "episode": 20.0, "batch_reward": 0.8912624542117119, "critic_loss": 0.29945122688263653, "actor_loss": -95.28430363464355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04567790031433, "step": 20000}
{"episode_reward": 978.1975400973815, "episode": 21.0, "batch_reward": 0.8898512024283409, "critic_loss": 0.3442117933481932, "actor_loss": -95.23488752746582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.33036398887634, "step": 21000}
{"episode_reward": 843.9118812461475, "episode": 22.0, "batch_reward": 0.8933171091675758, "critic_loss": 0.35341550697386265, "actor_loss": -95.27690364074707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.049044847488403, "step": 22000}
{"episode_reward": 969.332725083136, "episode": 23.0, "batch_reward": 0.8919572569131852, "critic_loss": 0.3494213281273842, "actor_loss": -95.20263833618164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05829691886902, "step": 23000}
{"episode_reward": 869.2136481539073, "episode": 24.0, "batch_reward": 0.8949479939341545, "critic_loss": 0.32529499075561763, "actor_loss": -95.28649134826661, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.056108236312866, "step": 24000}
{"episode_reward": 981.2991221439341, "episode": 25.0, "batch_reward": 0.8950654224157334, "critic_loss": 0.35491840572655203, "actor_loss": -95.3131958770752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06419610977173, "step": 25000}
{"episode_reward": 917.0961322042201, "episode": 26.0, "batch_reward": 0.8975604956746102, "critic_loss": 0.3023290035575628, "actor_loss": -95.35836187744141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.056430339813232, "step": 26000}
{"episode_reward": 981.3660568420948, "episode": 27.0, "batch_reward": 0.9029311156272888, "critic_loss": 0.3089941296726465, "actor_loss": -95.46181959533692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04675054550171, "step": 27000}
{"episode_reward": 972.1307164612365, "episode": 28.0, "batch_reward": 0.9044643740057945, "critic_loss": 0.27331846523284914, "actor_loss": -95.55694770812988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0364727973938, "step": 28000}
{"episode_reward": 956.1171350974166, "episode": 29.0, "batch_reward": 0.9043709861636162, "critic_loss": 0.315585364818573, "actor_loss": -95.47299702453613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.041511058807373, "step": 29000}
{"episode_reward": 917.7085514350498, "episode": 30.0, "batch_reward": 0.9060102801918983, "critic_loss": 0.3217683396041393, "actor_loss": -95.5282975616455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.038553476333618, "step": 30000}
{"episode_reward": 925.2383967779753, "episode": 31.0, "batch_reward": 0.9063535779118538, "critic_loss": 0.2953306397870183, "actor_loss": -95.56667527770996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.36272573471069, "step": 31000}
{"episode_reward": 943.4145599475302, "episode": 32.0, "batch_reward": 0.9091653382778168, "critic_loss": 0.2904970354437828, "actor_loss": -95.59854835510254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.030384063720703, "step": 32000}
{"episode_reward": 956.1717086178991, "episode": 33.0, "batch_reward": 0.9092607924342155, "critic_loss": 0.27087117987126114, "actor_loss": -95.62625541687012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.030766487121582, "step": 33000}
{"episode_reward": 949.5282810373263, "episode": 34.0, "batch_reward": 0.9105697718858718, "critic_loss": 0.2361675627157092, "actor_loss": -95.66787222290039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04077982902527, "step": 34000}
{"episode_reward": 971.3151850348555, "episode": 35.0, "batch_reward": 0.9118706164956093, "critic_loss": 0.29075165244936946, "actor_loss": -95.7034069519043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03792142868042, "step": 35000}
{"episode_reward": 932.8692199717239, "episode": 36.0, "batch_reward": 0.9117943912744522, "critic_loss": 0.24579685983061791, "actor_loss": -95.72852122497558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03374457359314, "step": 36000}
{"episode_reward": 948.215258440813, "episode": 37.0, "batch_reward": 0.9125347161889076, "critic_loss": 0.25118347647041084, "actor_loss": -95.73047766113281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05626082420349, "step": 37000}
{"episode_reward": 961.2125790204268, "episode": 38.0, "batch_reward": 0.9155514729619026, "critic_loss": 0.25672482106089595, "actor_loss": -95.75374504089355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.070499658584595, "step": 38000}
{"episode_reward": 982.6583911453438, "episode": 39.0, "batch_reward": 0.917127468585968, "critic_loss": 0.24446502806991338, "actor_loss": -95.79970916748047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.066534280776978, "step": 39000}
{"episode_reward": 976.03750241081, "episode": 40.0, "batch_reward": 0.9174334312081337, "critic_loss": 0.24574044267833234, "actor_loss": -95.81405210876464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.040486574172974, "step": 40000}
{"episode_reward": 974.7161774761054, "episode": 41.0, "batch_reward": 0.9182485741972923, "critic_loss": 0.2905674934759736, "actor_loss": -95.79897746276855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.35379457473755, "step": 41000}
{"episode_reward": 874.5211194102368, "episode": 42.0, "batch_reward": 0.9200250732898713, "critic_loss": 0.2602174754589796, "actor_loss": -95.8330481262207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04493546485901, "step": 42000}
{"episode_reward": 982.9616069304899, "episode": 43.0, "batch_reward": 0.9175659846663475, "critic_loss": 0.3450119376182556, "actor_loss": -95.72533419799805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03491187095642, "step": 43000}
{"episode_reward": 818.999370634215, "episode": 44.0, "batch_reward": 0.918574626147747, "critic_loss": 0.32764362306147815, "actor_loss": -95.72004026794434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.041311502456665, "step": 44000}
{"episode_reward": 966.6032880330946, "episode": 45.0, "batch_reward": 0.9186855527758598, "critic_loss": 0.3420959581956267, "actor_loss": -95.69444400024415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.039121627807617, "step": 45000}
{"episode_reward": 922.3406039299833, "episode": 46.0, "batch_reward": 0.9191992155313492, "critic_loss": 0.363116380520165, "actor_loss": -95.71384503173829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.034241914749146, "step": 46000}
{"episode_reward": 966.3725847826427, "episode": 47.0, "batch_reward": 0.9206233204007149, "critic_loss": 0.35391028549522163, "actor_loss": -95.70474865722656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.044310331344604, "step": 47000}
{"episode_reward": 972.3185195728329, "episode": 48.0, "batch_reward": 0.9186190351843834, "critic_loss": 0.4255079069212079, "actor_loss": -95.67005740356446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.038660526275635, "step": 48000}
{"episode_reward": 785.6503417604438, "episode": 49.0, "batch_reward": 0.9191438127756119, "critic_loss": 0.43625858454406263, "actor_loss": -95.65554518127442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03846836090088, "step": 49000}
{"episode_reward": 958.3608769502291, "episode": 50.0, "batch_reward": 0.9176508774757385, "critic_loss": 0.43338246428221466, "actor_loss": -95.53417294311524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.048913955688477, "step": 50000}
{"episode_reward": 882.0405258024192, "episode": 51.0, "batch_reward": 0.9181139216423034, "critic_loss": 0.46315996992588043, "actor_loss": -95.53419465637207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.40512561798096, "step": 51000}
{"episode_reward": 969.3569583457945, "episode": 52.0, "batch_reward": 0.9182593628168106, "critic_loss": 0.45610496661067007, "actor_loss": -95.52192395019532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.060924768447876, "step": 52000}
{"episode_reward": 920.1158866866133, "episode": 53.0, "batch_reward": 0.9190376406311989, "critic_loss": 0.5102556696534157, "actor_loss": -95.51265946960449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.033140897750854, "step": 53000}
{"episode_reward": 898.7204279082307, "episode": 54.0, "batch_reward": 0.9188917365670204, "critic_loss": 0.48614683663100006, "actor_loss": -95.50352723693848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04475498199463, "step": 54000}
{"episode_reward": 941.9485113186196, "episode": 55.0, "batch_reward": 0.9201755198836327, "critic_loss": 0.49987794771045446, "actor_loss": -95.52357681274414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.037901878356934, "step": 55000}
{"episode_reward": 985.3819254180025, "episode": 56.0, "batch_reward": 0.9207911297082901, "critic_loss": 0.45238186871260405, "actor_loss": -95.6170400390625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04329514503479, "step": 56000}
{"episode_reward": 969.6802340119689, "episode": 57.0, "batch_reward": 0.9212368633747101, "critic_loss": 0.44932557046413424, "actor_loss": -95.58128234863281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.050275802612305, "step": 57000}
{"episode_reward": 961.1573363059849, "episode": 58.0, "batch_reward": 0.9228072724938393, "critic_loss": 0.4333529791384935, "actor_loss": -95.6401134185791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04407548904419, "step": 58000}
{"episode_reward": 984.0406903310828, "episode": 59.0, "batch_reward": 0.9239907951354981, "critic_loss": 0.43244707433134316, "actor_loss": -95.7509193725586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04410743713379, "step": 59000}
{"episode_reward": 958.8922968485916, "episode": 60.0, "batch_reward": 0.9248219872117043, "critic_loss": 0.4380322412475944, "actor_loss": -95.82125459289551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.051350593566895, "step": 60000}
{"episode_reward": 965.6277562635618, "episode": 61.0, "batch_reward": 0.924604052901268, "critic_loss": 0.4293282350897789, "actor_loss": -95.77538768005371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.40113115310669, "step": 61000}
{"episode_reward": 947.902226079115, "episode": 62.0, "batch_reward": 0.9245489916205406, "critic_loss": 0.4268131305128336, "actor_loss": -95.78044927978516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04699730873108, "step": 62000}
{"episode_reward": 942.6942527382656, "episode": 63.0, "batch_reward": 0.9242589085102081, "critic_loss": 0.38847939693927763, "actor_loss": -95.82274644470215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04751181602478, "step": 63000}
{"episode_reward": 944.4840477017245, "episode": 64.0, "batch_reward": 0.9253824989199638, "critic_loss": 0.38255123518407347, "actor_loss": -95.88695268249512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.071267127990723, "step": 64000}
{"episode_reward": 983.0395481611902, "episode": 65.0, "batch_reward": 0.9272571845650673, "critic_loss": 0.34043126001209023, "actor_loss": -95.95574893188477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.061434268951416, "step": 65000}
{"episode_reward": 979.7051398479596, "episode": 66.0, "batch_reward": 0.9244032341241837, "critic_loss": 0.3851950847953558, "actor_loss": -95.85785313415528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.051676988601685, "step": 66000}
{"episode_reward": 837.508249738246, "episode": 67.0, "batch_reward": 0.9240745174288749, "critic_loss": 0.38491632100194695, "actor_loss": -95.85040812683106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.041393041610718, "step": 67000}
{"episode_reward": 912.5895335022108, "episode": 68.0, "batch_reward": 0.9255180240273476, "critic_loss": 0.3364397656023502, "actor_loss": -95.86336540222167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.044437885284424, "step": 68000}
{"episode_reward": 958.4232103470932, "episode": 69.0, "batch_reward": 0.9261592180728913, "critic_loss": 0.35096145456284283, "actor_loss": -95.87671214294434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04590392112732, "step": 69000}
{"episode_reward": 987.8268546486881, "episode": 70.0, "batch_reward": 0.9259311522245407, "critic_loss": 0.37159646294265986, "actor_loss": -95.86980068969727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.043071508407593, "step": 70000}
{"episode_reward": 847.6766047843703, "episode": 71.0, "batch_reward": 0.9248810232877731, "critic_loss": 0.4186233985945582, "actor_loss": -95.79851824951172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.42787837982178, "step": 71000}
{"episode_reward": 851.4227265798762, "episode": 72.0, "batch_reward": 0.9256909431815148, "critic_loss": 0.4139093084707856, "actor_loss": -95.78261854553223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04588484764099, "step": 72000}
{"episode_reward": 977.20282284564, "episode": 73.0, "batch_reward": 0.9252704813480377, "critic_loss": 0.4237374142333865, "actor_loss": -95.77806027221679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.042524099349976, "step": 73000}
{"episode_reward": 968.0998432574055, "episode": 74.0, "batch_reward": 0.9270653299689293, "critic_loss": 0.4228646216765046, "actor_loss": -95.87423899841309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.037176370620728, "step": 74000}
{"episode_reward": 943.7007204652842, "episode": 75.0, "batch_reward": 0.9261148937344551, "critic_loss": 0.41836937218159437, "actor_loss": -95.78877584838867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.051119327545166, "step": 75000}
{"episode_reward": 974.0095428782118, "episode": 76.0, "batch_reward": 0.9265145825743675, "critic_loss": 0.43691828671842814, "actor_loss": -95.77973103332519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.065234661102295, "step": 76000}
{"episode_reward": 940.1917798563181, "episode": 77.0, "batch_reward": 0.9266619849205017, "critic_loss": 0.45420491144806147, "actor_loss": -95.7952173614502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0689115524292, "step": 77000}
{"episode_reward": 982.4908066152265, "episode": 78.0, "batch_reward": 0.9278910560011864, "critic_loss": 0.4109297271966934, "actor_loss": -95.80543399047852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.066068172454834, "step": 78000}
{"episode_reward": 952.0618763845382, "episode": 79.0, "batch_reward": 0.9281377011537552, "critic_loss": 0.3993224717304111, "actor_loss": -95.87628286743164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08000636100769, "step": 79000}
{"episode_reward": 968.4974327621733, "episode": 80.0, "batch_reward": 0.9291071846485138, "critic_loss": 0.4023255642428994, "actor_loss": -95.89904786682129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.067083597183228, "step": 80000}
{"episode_reward": 984.1878828319602, "episode": 81.0, "batch_reward": 0.9291436716914176, "critic_loss": 0.38444621247798205, "actor_loss": -95.92838916015624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.45387268066406, "step": 81000}
{"episode_reward": 950.7198056546358, "episode": 82.0, "batch_reward": 0.9302516242265702, "critic_loss": 0.3875681270509958, "actor_loss": -95.898685836792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05850839614868, "step": 82000}
{"episode_reward": 954.9593369905458, "episode": 83.0, "batch_reward": 0.9288831160068513, "critic_loss": 0.4022146010324359, "actor_loss": -95.9152903289795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08465576171875, "step": 83000}
{"episode_reward": 840.1226097169005, "episode": 84.0, "batch_reward": 0.929384518623352, "critic_loss": 0.41541019708663224, "actor_loss": -95.95925184631348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.084193468093872, "step": 84000}
{"episode_reward": 987.392415590824, "episode": 85.0, "batch_reward": 0.9285019661784172, "critic_loss": 0.42119079760462047, "actor_loss": -95.82693598937988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.066838264465332, "step": 85000}
{"episode_reward": 878.3354925164061, "episode": 86.0, "batch_reward": 0.9286448146104813, "critic_loss": 0.40891450954973696, "actor_loss": -95.79715325927734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.060941457748413, "step": 86000}
{"episode_reward": 936.186607401152, "episode": 87.0, "batch_reward": 0.9294290286302567, "critic_loss": 0.3990885837078095, "actor_loss": -95.86101002502441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.064255714416504, "step": 87000}
{"episode_reward": 954.5516440384206, "episode": 88.0, "batch_reward": 0.9285763222575187, "critic_loss": 0.4503974633440375, "actor_loss": -95.81053829956055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.074565649032593, "step": 88000}
{"episode_reward": 920.6806590465545, "episode": 89.0, "batch_reward": 0.929025219142437, "critic_loss": 0.45178053591400386, "actor_loss": -95.81891398620606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07023787498474, "step": 89000}
{"episode_reward": 961.3182452461247, "episode": 90.0, "batch_reward": 0.9294489024877548, "critic_loss": 0.43037265227735044, "actor_loss": -95.87189088439942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077515363693237, "step": 90000}
{"episode_reward": 956.0760657257766, "episode": 91.0, "batch_reward": 0.9299360582828522, "critic_loss": 0.43444672600924966, "actor_loss": -95.82088000488281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.49373435974121, "step": 91000}
{"episode_reward": 957.2694841627799, "episode": 92.0, "batch_reward": 0.9310989525914192, "critic_loss": 0.44726334600150586, "actor_loss": -95.9180152130127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.095900058746338, "step": 92000}
{"episode_reward": 960.0116423109737, "episode": 93.0, "batch_reward": 0.9299002102017403, "critic_loss": 0.4377247499153018, "actor_loss": -95.88339411926269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07132315635681, "step": 93000}
{"episode_reward": 981.825785641856, "episode": 94.0, "batch_reward": 0.9304421109557152, "critic_loss": 0.41743944290280344, "actor_loss": -95.91074856567383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.074326276779175, "step": 94000}
{"episode_reward": 926.1415411298748, "episode": 95.0, "batch_reward": 0.9301889519095421, "critic_loss": 0.43697716333717107, "actor_loss": -95.90358842468262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.071388483047485, "step": 95000}
{"episode_reward": 960.8251287113794, "episode": 96.0, "batch_reward": 0.9310000324249268, "critic_loss": 0.4350525101348758, "actor_loss": -95.93957955932618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07579278945923, "step": 96000}
{"episode_reward": 944.4271274282008, "episode": 97.0, "batch_reward": 0.9311028484106064, "critic_loss": 0.4183419556170702, "actor_loss": -95.89279321289062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.066123247146606, "step": 97000}
{"episode_reward": 918.8124286163338, "episode": 98.0, "batch_reward": 0.93117479377985, "critic_loss": 0.41400702749192714, "actor_loss": -95.87910768127442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.387314558029175, "step": 98000}
{"episode_reward": 887.42228133995, "episode": 99.0, "batch_reward": 0.9299904395341874, "critic_loss": 0.42839649275690317, "actor_loss": -95.89885108947755, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.070733785629272, "step": 99000}
{"episode_reward": 951.4646917225118, "episode": 100.0, "batch_reward": 0.9321676538586616, "critic_loss": 0.4107429365590215, "actor_loss": -96.00847956848145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.356289625167847, "step": 100000}
{"episode_reward": 939.5603055490633, "episode": 101.0, "batch_reward": 0.9325203478932381, "critic_loss": 0.404773726478219, "actor_loss": -95.96773620605468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.46832895278931, "step": 101000}
{"episode_reward": 980.7052265385549, "episode": 102.0, "batch_reward": 0.9312567347288132, "critic_loss": 0.4302760952115059, "actor_loss": -95.96557783508301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07816767692566, "step": 102000}
{"episode_reward": 981.5570626209504, "episode": 103.0, "batch_reward": 0.9317547628879547, "critic_loss": 0.3745165890678763, "actor_loss": -95.93900424194337, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09041976928711, "step": 103000}
{"episode_reward": 956.6477924870744, "episode": 104.0, "batch_reward": 0.9325466085076332, "critic_loss": 0.37979485497623683, "actor_loss": -96.01613687133789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09221315383911, "step": 104000}
{"episode_reward": 902.3270983008605, "episode": 105.0, "batch_reward": 0.9327244540452957, "critic_loss": 0.4126569396331906, "actor_loss": -96.02862756347656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.080146551132202, "step": 105000}
{"episode_reward": 945.2190487339886, "episode": 106.0, "batch_reward": 0.9320965117812157, "critic_loss": 0.378048255994916, "actor_loss": -96.03079460144043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.070666313171387, "step": 106000}
{"episode_reward": 876.3517880130498, "episode": 107.0, "batch_reward": 0.9309912326335907, "critic_loss": 0.391633974917233, "actor_loss": -95.92731492614746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08239984512329, "step": 107000}
{"episode_reward": 896.8631838572344, "episode": 108.0, "batch_reward": 0.9321778382062912, "critic_loss": 0.37699813123047354, "actor_loss": -96.02288404846192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08182120323181, "step": 108000}
{"episode_reward": 976.1775406840829, "episode": 109.0, "batch_reward": 0.9318535793423652, "critic_loss": 0.3976410313397646, "actor_loss": -96.01589227294922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.083632469177246, "step": 109000}
{"episode_reward": 963.8417667451624, "episode": 110.0, "batch_reward": 0.9318771089315414, "critic_loss": 0.37146262354403736, "actor_loss": -96.0224670715332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07214093208313, "step": 110000}
{"episode_reward": 957.2133305988815, "episode": 111.0, "batch_reward": 0.931886471092701, "critic_loss": 0.3954451115950942, "actor_loss": -96.01903128051758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.45537614822388, "step": 111000}
{"episode_reward": 955.9850198099215, "episode": 112.0, "batch_reward": 0.9313976939916611, "critic_loss": 0.4161343526765704, "actor_loss": -96.00682739257813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07419466972351, "step": 112000}
{"episode_reward": 910.8605785198606, "episode": 113.0, "batch_reward": 0.9327778279781341, "critic_loss": 0.3727768558636308, "actor_loss": -96.05297413635255, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08388113975525, "step": 113000}
{"episode_reward": 962.7960126891898, "episode": 114.0, "batch_reward": 0.9327396584749221, "critic_loss": 0.38304644616693256, "actor_loss": -96.06463610839843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.071627140045166, "step": 114000}
{"episode_reward": 975.9528869435694, "episode": 115.0, "batch_reward": 0.9334528178572655, "critic_loss": 0.37746775861084464, "actor_loss": -96.06440615844727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07791495323181, "step": 115000}
{"episode_reward": 939.4199780750054, "episode": 116.0, "batch_reward": 0.9328461176156998, "critic_loss": 0.4069215849861503, "actor_loss": -96.00424308776856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.107712268829346, "step": 116000}
{"episode_reward": 963.6821433039163, "episode": 117.0, "batch_reward": 0.9327225515246391, "critic_loss": 0.4368398993164301, "actor_loss": -96.02549359130859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.104093074798584, "step": 117000}
{"episode_reward": 921.2451531555698, "episode": 118.0, "batch_reward": 0.9334488685727119, "critic_loss": 0.3560431798249483, "actor_loss": -96.06538423156738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09839653968811, "step": 118000}
{"episode_reward": 986.740103052293, "episode": 119.0, "batch_reward": 0.9333407044410705, "critic_loss": 0.39852596624940634, "actor_loss": -96.04709544372558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.073538780212402, "step": 119000}
{"episode_reward": 971.5618671240913, "episode": 120.0, "batch_reward": 0.9336824207901955, "critic_loss": 0.38882154746353625, "actor_loss": -96.05690618896485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085769176483154, "step": 120000}
{"episode_reward": 947.1721108156017, "episode": 121.0, "batch_reward": 0.9346523115634918, "critic_loss": 0.34164458368718625, "actor_loss": -96.10215823364258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.47002100944519, "step": 121000}
{"episode_reward": 981.6328790567201, "episode": 122.0, "batch_reward": 0.9337239879965782, "critic_loss": 0.38186423742026093, "actor_loss": -96.05445796203614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.080928087234497, "step": 122000}
{"episode_reward": 893.6661729293681, "episode": 123.0, "batch_reward": 0.9349360523819923, "critic_loss": 0.4090527437366545, "actor_loss": -96.09591632080078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.076706647872925, "step": 123000}
{"episode_reward": 973.3303720932548, "episode": 124.0, "batch_reward": 0.9339619877934456, "critic_loss": 0.36925792139023544, "actor_loss": -96.07063842773438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.079838275909424, "step": 124000}
{"episode_reward": 972.8042190538116, "episode": 125.0, "batch_reward": 0.9351528369188309, "critic_loss": 0.3756892621740699, "actor_loss": -96.14164810180664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.081005573272705, "step": 125000}
{"episode_reward": 985.5763027287207, "episode": 126.0, "batch_reward": 0.9351874253749848, "critic_loss": 0.3750385953709483, "actor_loss": -96.17065676879882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085110664367676, "step": 126000}
{"episode_reward": 926.346333323951, "episode": 127.0, "batch_reward": 0.9342417370676994, "critic_loss": 0.4143548436164856, "actor_loss": -96.0962281036377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07594347000122, "step": 127000}
{"episode_reward": 956.2895474819501, "episode": 128.0, "batch_reward": 0.9353463933467865, "critic_loss": 0.3822926296889782, "actor_loss": -96.1506333770752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.079305410385132, "step": 128000}
{"episode_reward": 968.3493122623911, "episode": 129.0, "batch_reward": 0.935069302558899, "critic_loss": 0.4006911308802664, "actor_loss": -96.15301641845703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.090771675109863, "step": 129000}
{"episode_reward": 979.2580741765779, "episode": 130.0, "batch_reward": 0.9360992560386657, "critic_loss": 0.37657927203178404, "actor_loss": -96.20251309204102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.102700233459473, "step": 130000}
{"episode_reward": 982.9010107078323, "episode": 131.0, "batch_reward": 0.9361123423576355, "critic_loss": 0.40367185804992917, "actor_loss": -96.13763037109375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.56535983085632, "step": 131000}
{"episode_reward": 962.0448850966666, "episode": 132.0, "batch_reward": 0.9369629523754119, "critic_loss": 0.39235595703125, "actor_loss": -96.21033103942871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06383228302002, "step": 132000}
{"episode_reward": 986.8617307173681, "episode": 133.0, "batch_reward": 0.936819047152996, "critic_loss": 0.37890527515858413, "actor_loss": -96.20639179992676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.049407958984375, "step": 133000}
{"episode_reward": 960.2652976112705, "episode": 134.0, "batch_reward": 0.9370872565507888, "critic_loss": 0.4191120593175292, "actor_loss": -96.22002590942382, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07990288734436, "step": 134000}
{"episode_reward": 960.8771540585662, "episode": 135.0, "batch_reward": 0.9386188388466835, "critic_loss": 0.3964436694085598, "actor_loss": -96.23893685913086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10267949104309, "step": 135000}
{"episode_reward": 990.6683885678477, "episode": 136.0, "batch_reward": 0.9376753561496735, "critic_loss": 0.3910660100504756, "actor_loss": -96.25272390747071, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.080259323120117, "step": 136000}
{"episode_reward": 989.2942625983819, "episode": 137.0, "batch_reward": 0.9370510845184327, "critic_loss": 0.37635419937968256, "actor_loss": -96.19784841918946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.078222274780273, "step": 137000}
{"episode_reward": 980.1267741312291, "episode": 138.0, "batch_reward": 0.9388450277447701, "critic_loss": 0.4085079710930586, "actor_loss": -96.32626818847656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.070963382720947, "step": 138000}
{"episode_reward": 964.2794317951251, "episode": 139.0, "batch_reward": 0.9375089218616486, "critic_loss": 0.3908446571752429, "actor_loss": -96.26465646362304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07761025428772, "step": 139000}
{"episode_reward": 955.5791546237015, "episode": 140.0, "batch_reward": 0.9386727350354195, "critic_loss": 0.39787369380146265, "actor_loss": -96.29223617553711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.075193643569946, "step": 140000}
{"episode_reward": 975.4264660060444, "episode": 141.0, "batch_reward": 0.9393037249445915, "critic_loss": 0.35163791166990993, "actor_loss": -96.30597901916504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.47936129570007, "step": 141000}
{"episode_reward": 978.8953327963721, "episode": 142.0, "batch_reward": 0.9395389018058777, "critic_loss": 0.34762771327793596, "actor_loss": -96.32386337280273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10485076904297, "step": 142000}
{"episode_reward": 986.6868315434464, "episode": 143.0, "batch_reward": 0.939451591193676, "critic_loss": 0.3608340740352869, "actor_loss": -96.31688572692872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097447156906128, "step": 143000}
{"episode_reward": 976.9239983045977, "episode": 144.0, "batch_reward": 0.9398247488737106, "critic_loss": 0.35898510190844535, "actor_loss": -96.31810192871093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07547354698181, "step": 144000}
{"episode_reward": 920.4320235733736, "episode": 145.0, "batch_reward": 0.9403649799823761, "critic_loss": 0.35841561075299977, "actor_loss": -96.33765171813965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.074936628341675, "step": 145000}
{"episode_reward": 980.9773774713584, "episode": 146.0, "batch_reward": 0.940427362024784, "critic_loss": 0.39090137142688036, "actor_loss": -96.34839653015136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0730402469635, "step": 146000}
{"episode_reward": 968.8168104470067, "episode": 147.0, "batch_reward": 0.9399822474122047, "critic_loss": 0.3551819195523858, "actor_loss": -96.33707322692871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.070489645004272, "step": 147000}
{"episode_reward": 957.8526340823607, "episode": 148.0, "batch_reward": 0.9410671478509903, "critic_loss": 0.34575366358459, "actor_loss": -96.37233363342285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.068955183029175, "step": 148000}
{"episode_reward": 978.4607924311812, "episode": 149.0, "batch_reward": 0.9398646544218063, "critic_loss": 0.35722311938554047, "actor_loss": -96.3352918548584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07191777229309, "step": 149000}
{"episode_reward": 914.0405842398997, "episode": 150.0, "batch_reward": 0.9398179507255554, "critic_loss": 0.37918638488650325, "actor_loss": -96.3638106842041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
