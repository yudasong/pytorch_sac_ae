{"episode_reward": 0.0, "episode": 1.0, "duration": 21.062249660491943, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.8316075801849365, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.47684625439065104, "critic_loss": 0.9162740291516437, "actor_loss": -90.89259865017785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.11660170555115, "step": 3000}
{"episode_reward": 385.0995583748599, "episode": 4.0, "batch_reward": 0.44520315730571747, "critic_loss": 1.1822705212235451, "actor_loss": -97.36608404541016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.523014307022095, "step": 4000}
{"episode_reward": 262.96065406062644, "episode": 5.0, "batch_reward": 0.45667115691304205, "critic_loss": 0.9643380767703056, "actor_loss": -99.4884705657959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.569393157958984, "step": 5000}
{"episode_reward": 932.1167914144681, "episode": 6.0, "batch_reward": 0.5357902894318104, "critic_loss": 0.7893173384964466, "actor_loss": -99.39919802856446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.313902139663696, "step": 6000}
{"episode_reward": 742.7838867092452, "episode": 7.0, "batch_reward": 0.5053147104978561, "critic_loss": 0.851645371645689, "actor_loss": -98.84982090759277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26683235168457, "step": 7000}
{"episode_reward": 31.13987206994322, "episode": 8.0, "batch_reward": 0.4483224108815193, "critic_loss": 0.7512633140087128, "actor_loss": -98.61163632202148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.298887252807617, "step": 8000}
{"episode_reward": 59.99722168103182, "episode": 9.0, "batch_reward": 0.39769027760624887, "critic_loss": 0.7439913883209228, "actor_loss": -96.46216128540038, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.302432775497437, "step": 9000}
{"episode_reward": 32.669475522138, "episode": 10.0, "batch_reward": 0.3629190055727959, "critic_loss": 0.7982079838216305, "actor_loss": -96.04371867370605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30080485343933, "step": 10000}
{"episode_reward": 50.438224811560055, "episode": 11.0, "batch_reward": 0.33216856414079665, "critic_loss": 0.817660239636898, "actor_loss": -94.35540368652343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.00221514701843, "step": 11000}
{"episode_reward": 46.8613131870666, "episode": 12.0, "batch_reward": 0.30554186390340327, "critic_loss": 0.8820771898627281, "actor_loss": -93.93411256408692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30558967590332, "step": 12000}
{"episode_reward": 32.57988197760514, "episode": 13.0, "batch_reward": 0.2836580090969801, "critic_loss": 0.8871433964371681, "actor_loss": -93.76607901000976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34834885597229, "step": 13000}
{"episode_reward": 29.35467193619782, "episode": 14.0, "batch_reward": 0.26702490767836573, "critic_loss": 0.9072538711428643, "actor_loss": -94.8082815246582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.345881462097168, "step": 14000}
{"episode_reward": 37.27323600018186, "episode": 15.0, "batch_reward": 0.254508959710598, "critic_loss": 0.8185944511592388, "actor_loss": -93.25012361145019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26452875137329, "step": 15000}
{"episode_reward": 75.94504312920009, "episode": 16.0, "batch_reward": 0.2391744892001152, "critic_loss": 0.7114960997402668, "actor_loss": -92.25584017944335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.258668899536133, "step": 16000}
{"episode_reward": 27.40228345841232, "episode": 17.0, "batch_reward": 0.2241872419565916, "critic_loss": 0.6589668978452683, "actor_loss": -91.08736485290527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.290220737457275, "step": 17000}
{"episode_reward": 26.036044385131174, "episode": 18.0, "batch_reward": 0.2150287136286497, "critic_loss": 0.6770872167050839, "actor_loss": -90.20644458007813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.256937265396118, "step": 18000}
{"episode_reward": 289.06329673292265, "episode": 19.0, "batch_reward": 0.2230395565479994, "critic_loss": 0.9698795677423477, "actor_loss": -88.69917877197265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.215814352035522, "step": 19000}
{"episode_reward": 252.66520309361448, "episode": 20.0, "batch_reward": 0.23302081313729286, "critic_loss": 0.9515206538438797, "actor_loss": -90.35356350708008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23759651184082, "step": 20000}
{"episode_reward": 677.8017845844399, "episode": 21.0, "batch_reward": 0.26099531491100786, "critic_loss": 0.8709009900689125, "actor_loss": -90.26678393554687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.687610149383545, "step": 21000}
{"episode_reward": 860.2321015898409, "episode": 22.0, "batch_reward": 0.2907539952248335, "critic_loss": 0.7366746976077556, "actor_loss": -89.95290704345703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25401544570923, "step": 22000}
{"episode_reward": 878.1268675188481, "episode": 23.0, "batch_reward": 0.3127900565713644, "critic_loss": 0.7117822964191437, "actor_loss": -89.39363597106933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27946710586548, "step": 23000}
{"episode_reward": 835.4446476014281, "episode": 24.0, "batch_reward": 0.337938991472125, "critic_loss": 0.7158012585043907, "actor_loss": -89.51617472839355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.258000373840332, "step": 24000}
{"episode_reward": 959.9890828891846, "episode": 25.0, "batch_reward": 0.36148045128583906, "critic_loss": 0.7618393850922585, "actor_loss": -90.14805935668946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.244561195373535, "step": 25000}
{"episode_reward": 884.5153881008614, "episode": 26.0, "batch_reward": 0.38342012992501256, "critic_loss": 0.741927476555109, "actor_loss": -90.15648358154297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.267300367355347, "step": 26000}
{"episode_reward": 939.6296687673329, "episode": 27.0, "batch_reward": 0.4069931427240372, "critic_loss": 0.625921155244112, "actor_loss": -89.88158787536621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.242591381072998, "step": 27000}
{"episode_reward": 978.3673880139694, "episode": 28.0, "batch_reward": 0.42279387375712396, "critic_loss": 0.6049994967877865, "actor_loss": -89.28249896240234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.272804975509644, "step": 28000}
{"episode_reward": 858.1573701139904, "episode": 29.0, "batch_reward": 0.4438329119682312, "critic_loss": 0.5823526427447796, "actor_loss": -89.66259310913085, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.276968240737915, "step": 29000}
{"episode_reward": 936.1275866049426, "episode": 30.0, "batch_reward": 0.4572802618741989, "critic_loss": 0.55560858720541, "actor_loss": -89.42759861755371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.282636404037476, "step": 30000}
{"episode_reward": 912.3827747064408, "episode": 31.0, "batch_reward": 0.4726157854795456, "critic_loss": 0.5720584076941013, "actor_loss": -88.72732643127442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.713801860809326, "step": 31000}
{"episode_reward": 916.7482686036707, "episode": 32.0, "batch_reward": 0.4876455171406269, "critic_loss": 0.6083083654344081, "actor_loss": -88.31951599121093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.273853540420532, "step": 32000}
{"episode_reward": 877.7809307293345, "episode": 33.0, "batch_reward": 0.5023801371455192, "critic_loss": 0.6528103645145893, "actor_loss": -88.57333918762207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26205277442932, "step": 33000}
{"episode_reward": 949.4676858690237, "episode": 34.0, "batch_reward": 0.5144702764451504, "critic_loss": 0.6167562112808228, "actor_loss": -88.93036027526855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.249587774276733, "step": 34000}
{"episode_reward": 956.663181263991, "episode": 35.0, "batch_reward": 0.5258023304641247, "critic_loss": 0.6323753433525562, "actor_loss": -88.8737110900879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23017954826355, "step": 35000}
{"episode_reward": 916.6529145227198, "episode": 36.0, "batch_reward": 0.5332743035554885, "critic_loss": 0.7102354992926121, "actor_loss": -88.45715716552735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.238528728485107, "step": 36000}
{"episode_reward": 912.7289577141127, "episode": 37.0, "batch_reward": 0.5449792555272579, "critic_loss": 0.7720628794729709, "actor_loss": -88.25521493530273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.230759382247925, "step": 37000}
{"episode_reward": 948.3910276402572, "episode": 38.0, "batch_reward": 0.5600764131546021, "critic_loss": 0.9534715555012226, "actor_loss": -88.85316355895996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24535083770752, "step": 38000}
{"episode_reward": 983.7164763313436, "episode": 39.0, "batch_reward": 0.5604104376137257, "critic_loss": 1.3309312554001809, "actor_loss": -90.03962222290039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.225295543670654, "step": 39000}
{"episode_reward": 169.06980115133786, "episode": 40.0, "batch_reward": 0.5607330274581909, "critic_loss": 1.430457868218422, "actor_loss": -90.9179228515625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.231564044952393, "step": 40000}
{"episode_reward": 983.7185297204452, "episode": 41.0, "batch_reward": 0.5625377792716026, "critic_loss": 1.8404367551207543, "actor_loss": -91.20889178466797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.67011833190918, "step": 41000}
{"episode_reward": 192.92748319510616, "episode": 42.0, "batch_reward": 0.5570798643529415, "critic_loss": 2.6531883469820023, "actor_loss": -92.4572122039795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23644733428955, "step": 42000}
{"episode_reward": 630.2017439124318, "episode": 43.0, "batch_reward": 0.556865725159645, "critic_loss": 3.439971267580986, "actor_loss": -94.25414636230468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.238056421279907, "step": 43000}
{"episode_reward": 405.65832490899516, "episode": 44.0, "batch_reward": 0.5494912036359311, "critic_loss": 3.8679619152545928, "actor_loss": -95.20655575561524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23891305923462, "step": 44000}
{"episode_reward": 98.93162065777221, "episode": 45.0, "batch_reward": 0.5386140805780888, "critic_loss": 4.237270828485489, "actor_loss": -96.28511737060546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25058650970459, "step": 45000}
{"episode_reward": 40.61874496242034, "episode": 46.0, "batch_reward": 0.5276471298336983, "critic_loss": 4.675762391805649, "actor_loss": -97.40103530883789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27091383934021, "step": 46000}
{"episode_reward": 69.08552710165931, "episode": 47.0, "batch_reward": 0.5197549372017384, "critic_loss": 4.809116323232651, "actor_loss": -98.48477767944335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.306015968322754, "step": 47000}
{"episode_reward": 37.61220520366833, "episode": 48.0, "batch_reward": 0.5051317829191685, "critic_loss": 4.425104010820389, "actor_loss": -99.33354545593262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.309600591659546, "step": 48000}
{"episode_reward": 87.70948861961733, "episode": 49.0, "batch_reward": 0.4982188614308834, "critic_loss": 3.9134737771749495, "actor_loss": -100.35482260131836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.269490957260132, "step": 49000}
{"episode_reward": 58.005851979562934, "episode": 50.0, "batch_reward": 0.4883724744617939, "critic_loss": 3.640822064042091, "actor_loss": -102.36793688964843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.275643825531006, "step": 50000}
{"episode_reward": 47.71440773712487, "episode": 51.0, "batch_reward": 0.4815961686074734, "critic_loss": 3.418344936966896, "actor_loss": -104.19414982604981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.014482259750366, "step": 51000}
{"episode_reward": 31.065405727904384, "episode": 52.0, "batch_reward": 0.47057478326559066, "critic_loss": 2.9741309806108474, "actor_loss": -103.72977868652343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29582118988037, "step": 52000}
{"episode_reward": 34.79713925946184, "episode": 53.0, "batch_reward": 0.46557703986763954, "critic_loss": 2.8217929936647415, "actor_loss": -104.65921290588379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27884840965271, "step": 53000}
{"episode_reward": 60.06192661325071, "episode": 54.0, "batch_reward": 0.45659870067238806, "critic_loss": 2.800114307165146, "actor_loss": -105.34130213928222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.258605480194092, "step": 54000}
{"episode_reward": 218.94464597693187, "episode": 55.0, "batch_reward": 0.45838335260748864, "critic_loss": 2.705828387737274, "actor_loss": -105.81902883911133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2741858959198, "step": 55000}
{"episode_reward": 780.7208464552223, "episode": 56.0, "batch_reward": 0.46550950697064397, "critic_loss": 2.6212130296230316, "actor_loss": -105.76685157775879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2814621925354, "step": 56000}
{"episode_reward": 939.8324212539861, "episode": 57.0, "batch_reward": 0.4732356497645378, "critic_loss": 2.541963556289673, "actor_loss": -105.377095703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29369807243347, "step": 57000}
{"episode_reward": 742.6262958254615, "episode": 58.0, "batch_reward": 0.47926947855949403, "critic_loss": 2.5386561747789385, "actor_loss": -107.31047080993652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.270246267318726, "step": 58000}
{"episode_reward": 975.2520521412978, "episode": 59.0, "batch_reward": 0.49014906415343285, "critic_loss": 2.304951027274132, "actor_loss": -105.49553128051758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25678539276123, "step": 59000}
{"episode_reward": 943.5137138926282, "episode": 60.0, "batch_reward": 0.4943894263803959, "critic_loss": 2.0031656523942947, "actor_loss": -106.00652500915527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25765562057495, "step": 60000}
{"episode_reward": 957.2971479326229, "episode": 61.0, "batch_reward": 0.502025469481945, "critic_loss": 1.876177698433399, "actor_loss": -106.41312240600585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.725125312805176, "step": 61000}
{"episode_reward": 878.710571039395, "episode": 62.0, "batch_reward": 0.5100956411361695, "critic_loss": 1.7425287593603134, "actor_loss": -107.24604864501953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.258918523788452, "step": 62000}
{"episode_reward": 968.7801310412607, "episode": 63.0, "batch_reward": 0.5151999577581883, "critic_loss": 1.5936764413118363, "actor_loss": -105.64989724731446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29042077064514, "step": 63000}
{"episode_reward": 939.4457022446645, "episode": 64.0, "batch_reward": 0.5224087029695511, "critic_loss": 1.370320795416832, "actor_loss": -105.3990638885498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.265528917312622, "step": 64000}
{"episode_reward": 989.5367146169172, "episode": 65.0, "batch_reward": 0.5299029158949852, "critic_loss": 1.1928798016905784, "actor_loss": -104.48741670227051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25893783569336, "step": 65000}
{"episode_reward": 972.9892610701241, "episode": 66.0, "batch_reward": 0.5363074993491173, "critic_loss": 1.0813205469846725, "actor_loss": -103.88345852661134, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27421736717224, "step": 66000}
{"episode_reward": 946.6077702724276, "episode": 67.0, "batch_reward": 0.5410427705347538, "critic_loss": 0.9457382258176804, "actor_loss": -102.17874848937988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.278210163116455, "step": 67000}
{"episode_reward": 865.9460815963286, "episode": 68.0, "batch_reward": 0.5496885410249234, "critic_loss": 0.8683483003973961, "actor_loss": -102.44373808288574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.298423290252686, "step": 68000}
{"episode_reward": 962.9029241949145, "episode": 69.0, "batch_reward": 0.553500698775053, "critic_loss": 0.789238189548254, "actor_loss": -101.38419287109375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.281641006469727, "step": 69000}
{"episode_reward": 984.482975463024, "episode": 70.0, "batch_reward": 0.557809900701046, "critic_loss": 0.7839699356257915, "actor_loss": -100.00629127502441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.287780046463013, "step": 70000}
{"episode_reward": 665.9420196906035, "episode": 71.0, "batch_reward": 0.5601110028028489, "critic_loss": 0.8064447803199292, "actor_loss": -99.71437405395508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.78446316719055, "step": 71000}
{"episode_reward": 689.1068542049662, "episode": 72.0, "batch_reward": 0.5627342228293419, "critic_loss": 0.753165666282177, "actor_loss": -99.0592391052246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2910418510437, "step": 72000}
{"episode_reward": 974.8756799183914, "episode": 73.0, "batch_reward": 0.568060334533453, "critic_loss": 0.7276530365943908, "actor_loss": -98.61721263122558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28821349143982, "step": 73000}
{"episode_reward": 962.617336059706, "episode": 74.0, "batch_reward": 0.5761705794930458, "critic_loss": 0.7126954502761363, "actor_loss": -98.52658045959473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29185438156128, "step": 74000}
{"episode_reward": 943.3108067745086, "episode": 75.0, "batch_reward": 0.5791420870125293, "critic_loss": 0.7339016886055469, "actor_loss": -98.56552954101562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.262096881866455, "step": 75000}
{"episode_reward": 964.6778168597817, "episode": 76.0, "batch_reward": 0.5839715636670589, "critic_loss": 0.7160644477307796, "actor_loss": -98.17001612854004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.246841430664062, "step": 76000}
{"episode_reward": 962.0309222715049, "episode": 77.0, "batch_reward": 0.5868348738849163, "critic_loss": 0.7010455832779408, "actor_loss": -97.9067809753418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24211359024048, "step": 77000}
{"episode_reward": 966.0956661713731, "episode": 78.0, "batch_reward": 0.5925330012142658, "critic_loss": 0.6918833310008049, "actor_loss": -97.6229912109375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.220072269439697, "step": 78000}
{"episode_reward": 925.705046615519, "episode": 79.0, "batch_reward": 0.5989428835809231, "critic_loss": 0.7059995465576648, "actor_loss": -97.62866212463379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.252199172973633, "step": 79000}
{"episode_reward": 963.3947907298727, "episode": 80.0, "batch_reward": 0.6039368533790112, "critic_loss": 0.6629171560406685, "actor_loss": -97.3099993133545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.260186433792114, "step": 80000}
{"episode_reward": 984.1385872327165, "episode": 81.0, "batch_reward": 0.6071654188632966, "critic_loss": 0.6594365243017674, "actor_loss": -96.80592350769042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.67159986495972, "step": 81000}
{"episode_reward": 932.3056649937911, "episode": 82.0, "batch_reward": 0.6125002035796643, "critic_loss": 0.6592313401699066, "actor_loss": -96.50509620666504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.280898809432983, "step": 82000}
{"episode_reward": 925.6839157019022, "episode": 83.0, "batch_reward": 0.6148393059670925, "critic_loss": 0.6944963717758655, "actor_loss": -95.90360256958007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27675485610962, "step": 83000}
{"episode_reward": 721.1614178687643, "episode": 84.0, "batch_reward": 0.6175753548145294, "critic_loss": 0.6344146736115217, "actor_loss": -95.61125604248046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.286296844482422, "step": 84000}
{"episode_reward": 991.6547111485963, "episode": 85.0, "batch_reward": 0.6170066260993481, "critic_loss": 0.6396924898922444, "actor_loss": -95.290029296875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29270315170288, "step": 85000}
{"episode_reward": 549.9246513700526, "episode": 86.0, "batch_reward": 0.6199484683573246, "critic_loss": 0.5842960779964924, "actor_loss": -94.78198219299317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.261872053146362, "step": 86000}
{"episode_reward": 958.1709223646563, "episode": 87.0, "batch_reward": 0.6237087429165841, "critic_loss": 0.5892019153535366, "actor_loss": -94.60977569580078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26057505607605, "step": 87000}
{"episode_reward": 958.3628993334689, "episode": 88.0, "batch_reward": 0.6257072495818138, "critic_loss": 0.5704437186717987, "actor_loss": -94.4091901550293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29474449157715, "step": 88000}
{"episode_reward": 639.9144959386736, "episode": 89.0, "batch_reward": 0.6270249953866005, "critic_loss": 0.5587999813407659, "actor_loss": -94.18706173706055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.232847690582275, "step": 89000}
{"episode_reward": 930.0668081729025, "episode": 90.0, "batch_reward": 0.6316079120635987, "critic_loss": 0.5549429208785296, "actor_loss": -93.6758203125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.22757887840271, "step": 90000}
{"episode_reward": 914.6910563080594, "episode": 91.0, "batch_reward": 0.6343862869143486, "critic_loss": 0.5646942553818226, "actor_loss": -93.64818724060059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.64511704444885, "step": 91000}
{"episode_reward": 957.0289084588376, "episode": 92.0, "batch_reward": 0.6409684657752514, "critic_loss": 0.5512090107500554, "actor_loss": -93.45192199707031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26172947883606, "step": 92000}
{"episode_reward": 960.7081426002289, "episode": 93.0, "batch_reward": 0.6441013923287392, "critic_loss": 0.56328504088521, "actor_loss": -93.39349475097656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.286585569381714, "step": 93000}
{"episode_reward": 984.0671290943643, "episode": 94.0, "batch_reward": 0.6456905408501625, "critic_loss": 0.5648728749155998, "actor_loss": -93.0420802154541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.266902208328247, "step": 94000}
{"episode_reward": 943.4553095698632, "episode": 95.0, "batch_reward": 0.6479730622172356, "critic_loss": 0.5653172008544206, "actor_loss": -92.79674111938476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26429057121277, "step": 95000}
{"episode_reward": 937.9723085535574, "episode": 96.0, "batch_reward": 0.6501249405145645, "critic_loss": 0.5551373279988766, "actor_loss": -92.785515625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25623917579651, "step": 96000}
{"episode_reward": 929.9452758105205, "episode": 97.0, "batch_reward": 0.6517529700398446, "critic_loss": 0.5493135795593261, "actor_loss": -92.39471575927735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.248804330825806, "step": 97000}
{"episode_reward": 913.1866082686535, "episode": 98.0, "batch_reward": 0.6554631906747818, "critic_loss": 0.5412480443716049, "actor_loss": -92.07316227722168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23913836479187, "step": 98000}
{"episode_reward": 879.1729321230048, "episode": 99.0, "batch_reward": 0.6610331500768661, "critic_loss": 0.5196153271794319, "actor_loss": -92.04144340515137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.268280506134033, "step": 99000}
{"episode_reward": 981.7535095682185, "episode": 100.0, "batch_reward": 0.662954315662384, "critic_loss": 0.5287084305435419, "actor_loss": -91.93448960876465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25913953781128, "step": 100000}
{"episode_reward": 918.323329379889, "episode": 101.0, "batch_reward": 0.6642872549891472, "critic_loss": 0.5359066676050425, "actor_loss": -91.73117320251465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.71454095840454, "step": 101000}
{"episode_reward": 940.589447222911, "episode": 102.0, "batch_reward": 0.6645022109746933, "critic_loss": 0.5062864135354758, "actor_loss": -91.56718525695801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.241655588150024, "step": 102000}
{"episode_reward": 948.8785456824687, "episode": 103.0, "batch_reward": 0.6705584234595299, "critic_loss": 0.5127855458557605, "actor_loss": -91.41241627502441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.235311031341553, "step": 103000}
{"episode_reward": 958.627199531647, "episode": 104.0, "batch_reward": 0.6741006196141243, "critic_loss": 0.5324953566789628, "actor_loss": -91.44331227111816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.243966341018677, "step": 104000}
{"episode_reward": 955.5567006824938, "episode": 105.0, "batch_reward": 0.6742965105772019, "critic_loss": 0.5790101863741874, "actor_loss": -91.60903181457519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.248744010925293, "step": 105000}
{"episode_reward": 902.9027819530604, "episode": 106.0, "batch_reward": 0.6779603803157807, "critic_loss": 0.5694154119789601, "actor_loss": -91.68786543273926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.369521141052246, "step": 106000}
{"episode_reward": 949.2208944085623, "episode": 107.0, "batch_reward": 0.6810832846164704, "critic_loss": 0.5626398474276065, "actor_loss": -91.70315031433105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.672543048858643, "step": 107000}
{"episode_reward": 946.8034562548024, "episode": 108.0, "batch_reward": 0.6844023377299309, "critic_loss": 0.5487363061308861, "actor_loss": -91.81861599731445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.70717144012451, "step": 108000}
{"episode_reward": 963.04926908596, "episode": 109.0, "batch_reward": 0.6855254823565483, "critic_loss": 0.5965760372877121, "actor_loss": -91.77967390441894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.256133794784546, "step": 109000}
{"episode_reward": 970.0131121451225, "episode": 110.0, "batch_reward": 0.6902475606203079, "critic_loss": 0.5380671128034592, "actor_loss": -91.76557368469238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.137888193130493, "step": 110000}
{"episode_reward": 941.4296384441734, "episode": 111.0, "batch_reward": 0.6908348218798638, "critic_loss": 0.497000311627984, "actor_loss": -91.60599018859864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.01251745223999, "step": 111000}
{"episode_reward": 942.4848227556969, "episode": 112.0, "batch_reward": 0.6933913416266442, "critic_loss": 0.5081862532198429, "actor_loss": -91.55729464721679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.244983196258545, "step": 112000}
{"episode_reward": 943.7456006688452, "episode": 113.0, "batch_reward": 0.6949625269770622, "critic_loss": 0.48837220162153244, "actor_loss": -91.42873020935059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.25587749481201, "step": 113000}
{"episode_reward": 953.7717437697634, "episode": 114.0, "batch_reward": 0.6968811836838722, "critic_loss": 0.47616265746951103, "actor_loss": -91.30256781005859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.236266136169434, "step": 114000}
{"episode_reward": 964.4535772221645, "episode": 115.0, "batch_reward": 0.6978514691591263, "critic_loss": 0.4744415681362152, "actor_loss": -91.22543142700195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.24526309967041, "step": 115000}
{"episode_reward": 943.029105890998, "episode": 116.0, "batch_reward": 0.7016632879376411, "critic_loss": 0.4529020251482725, "actor_loss": -91.2210125579834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.470842361450195, "step": 116000}
{"episode_reward": 951.8754413027115, "episode": 117.0, "batch_reward": 0.7037210487127304, "critic_loss": 0.44499454843997954, "actor_loss": -91.20949362182617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.46460223197937, "step": 117000}
{"episode_reward": 935.4838469877005, "episode": 118.0, "batch_reward": 0.7051709647774697, "critic_loss": 0.43007106421887875, "actor_loss": -91.14117317199707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.405120372772217, "step": 118000}
{"episode_reward": 976.9050289667498, "episode": 119.0, "batch_reward": 0.7091515895724296, "critic_loss": 0.4645378380268812, "actor_loss": -91.10171229553222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.448846340179443, "step": 119000}
{"episode_reward": 925.2616376671234, "episode": 120.0, "batch_reward": 0.7091660925149917, "critic_loss": 0.4313604142069817, "actor_loss": -91.02109234619141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.504348039627075, "step": 120000}
{"episode_reward": 924.6140158665697, "episode": 121.0, "batch_reward": 0.7129077312350273, "critic_loss": 0.42430562710762026, "actor_loss": -91.20204693603516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.81550407409668, "step": 121000}
{"episode_reward": 988.3281959423084, "episode": 122.0, "batch_reward": 0.713271720290184, "critic_loss": 0.4377060359418392, "actor_loss": -91.15504235839843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28160548210144, "step": 122000}
{"episode_reward": 956.3370368311944, "episode": 123.0, "batch_reward": 0.7192602437138558, "critic_loss": 0.418359869197011, "actor_loss": -91.17887750244141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.269373178482056, "step": 123000}
{"episode_reward": 954.3431126919468, "episode": 124.0, "batch_reward": 0.7192073730230332, "critic_loss": 0.4305463037490845, "actor_loss": -91.16696325683594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27082872390747, "step": 124000}
{"episode_reward": 983.3225523565095, "episode": 125.0, "batch_reward": 0.7198830803632736, "critic_loss": 0.42531355360150336, "actor_loss": -91.16674452209473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.276400327682495, "step": 125000}
{"episode_reward": 985.3018221899662, "episode": 126.0, "batch_reward": 0.7217613280415535, "critic_loss": 0.42325886300206184, "actor_loss": -91.23969622802734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.252665519714355, "step": 126000}
{"episode_reward": 984.5863842184921, "episode": 127.0, "batch_reward": 0.7224486560225487, "critic_loss": 0.4139984912723303, "actor_loss": -91.19890802001953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.218935012817383, "step": 127000}
{"episode_reward": 951.6703405683322, "episode": 128.0, "batch_reward": 0.7254757001996041, "critic_loss": 0.4152774685919285, "actor_loss": -91.20407353210449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.239571809768677, "step": 128000}
{"episode_reward": 895.3498590997473, "episode": 129.0, "batch_reward": 0.7278701714873314, "critic_loss": 0.45173582454025746, "actor_loss": -91.17258772277832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.234190225601196, "step": 129000}
{"episode_reward": 913.0939399167357, "episode": 130.0, "batch_reward": 0.7306344568133354, "critic_loss": 0.4547577695548534, "actor_loss": -91.313833984375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27213168144226, "step": 130000}
{"episode_reward": 991.6553233772428, "episode": 131.0, "batch_reward": 0.7309066988825798, "critic_loss": 0.43839027132093905, "actor_loss": -91.29414266967774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.68912410736084, "step": 131000}
{"episode_reward": 986.7856632693318, "episode": 132.0, "batch_reward": 0.7333232855200768, "critic_loss": 0.4451996085047722, "actor_loss": -91.29466259765626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2589693069458, "step": 132000}
{"episode_reward": 884.4079112072623, "episode": 133.0, "batch_reward": 0.7330639054775238, "critic_loss": 0.44544896383583543, "actor_loss": -91.15970556640625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2838773727417, "step": 133000}
{"episode_reward": 961.514431691245, "episode": 134.0, "batch_reward": 0.7356848549842835, "critic_loss": 0.458117487475276, "actor_loss": -91.22639671325683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27158546447754, "step": 134000}
{"episode_reward": 951.7688332998083, "episode": 135.0, "batch_reward": 0.7379317389726638, "critic_loss": 0.4670840104073286, "actor_loss": -91.22126947021485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.283874988555908, "step": 135000}
{"episode_reward": 991.2136557093434, "episode": 136.0, "batch_reward": 0.7411648994684219, "critic_loss": 0.4639775766134262, "actor_loss": -91.2604415435791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.291845560073853, "step": 136000}
{"episode_reward": 990.3785351449446, "episode": 137.0, "batch_reward": 0.7415167297720909, "critic_loss": 0.46050653675198555, "actor_loss": -91.32471096801758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29513168334961, "step": 137000}
{"episode_reward": 986.9963178029, "episode": 138.0, "batch_reward": 0.7440768893957138, "critic_loss": 0.4464426075220108, "actor_loss": -91.38618821716308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.295759677886963, "step": 138000}
{"episode_reward": 940.1439305369411, "episode": 139.0, "batch_reward": 0.742732664167881, "critic_loss": 0.45888555446267126, "actor_loss": -91.43486131286622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.265794277191162, "step": 139000}
{"episode_reward": 959.0723591671057, "episode": 140.0, "batch_reward": 0.7451760478019714, "critic_loss": 0.4431801469475031, "actor_loss": -91.50754432678222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.61836528778076, "step": 140000}
{"episode_reward": 929.903842718046, "episode": 141.0, "batch_reward": 0.7463043984770775, "critic_loss": 0.4448598492443562, "actor_loss": -91.47755473327636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.78320932388306, "step": 141000}
{"episode_reward": 968.3658711466084, "episode": 142.0, "batch_reward": 0.7490669567584991, "critic_loss": 0.4259256683588028, "actor_loss": -91.50166355895996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.589375019073486, "step": 142000}
{"episode_reward": 991.1363758095965, "episode": 143.0, "batch_reward": 0.7504430908560753, "critic_loss": 0.4201358783841133, "actor_loss": -91.52887942504883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26496982574463, "step": 143000}
{"episode_reward": 933.5821822945007, "episode": 144.0, "batch_reward": 0.7522898825407028, "critic_loss": 0.44157751616835594, "actor_loss": -91.60040353393555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.223204374313354, "step": 144000}
{"episode_reward": 957.9855267968317, "episode": 145.0, "batch_reward": 0.7540134271383285, "critic_loss": 0.4454367004111409, "actor_loss": -91.685265914917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23563003540039, "step": 145000}
{"episode_reward": 988.4042346286997, "episode": 146.0, "batch_reward": 0.7536717865467072, "critic_loss": 0.4270865917801857, "actor_loss": -91.78168452453613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.254137754440308, "step": 146000}
{"episode_reward": 967.7246279568527, "episode": 147.0, "batch_reward": 0.7552874221205711, "critic_loss": 0.4193220075517893, "actor_loss": -91.8048977508545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.28221869468689, "step": 147000}
{"episode_reward": 950.3554793828735, "episode": 148.0, "batch_reward": 0.7586785212159157, "critic_loss": 0.4181753267049789, "actor_loss": -91.95135661315918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29084348678589, "step": 148000}
{"episode_reward": 988.2224564938263, "episode": 149.0, "batch_reward": 0.7595044455528259, "critic_loss": 0.41700013454258444, "actor_loss": -91.95844409179688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.291205167770386, "step": 149000}
{"episode_reward": 960.1117658255552, "episode": 150.0, "batch_reward": 0.761546857893467, "critic_loss": 0.403413565017283, "actor_loss": -92.07277165222168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
