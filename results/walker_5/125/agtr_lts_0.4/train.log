{"episode_reward": 0.0, "episode": 1.0, "duration": 30.330771446228027, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 2.3880341053009033, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.49503072981995, "critic_loss": 0.7376210754137907, "actor_loss": -89.19550854399377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 90.16417288780212, "step": 3000}
{"episode_reward": 840.3121597184484, "episode": 4.0, "batch_reward": 0.6348620761632919, "critic_loss": 0.8481840822100639, "actor_loss": -94.9963317565918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.627418518066406, "step": 4000}
{"episode_reward": 813.8708708965602, "episode": 5.0, "batch_reward": 0.6700534412264824, "critic_loss": 0.966649847626686, "actor_loss": -97.14775672912597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.613389492034912, "step": 5000}
{"episode_reward": 868.5585931220726, "episode": 6.0, "batch_reward": 0.7108015329837799, "critic_loss": 0.9776373817324638, "actor_loss": -97.79115711975098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.483510971069336, "step": 6000}
{"episode_reward": 851.2662755358554, "episode": 7.0, "batch_reward": 0.6683423576951026, "critic_loss": 1.9034314495325089, "actor_loss": -99.57040588378906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.054564476013184, "step": 7000}
{"episode_reward": 35.48696215131955, "episode": 8.0, "batch_reward": 0.5902092518806458, "critic_loss": 2.025014726281166, "actor_loss": -102.64668811035156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.717564582824707, "step": 8000}
{"episode_reward": 83.31656752558168, "episode": 9.0, "batch_reward": 0.5275837835073471, "critic_loss": 2.527555948495865, "actor_loss": -103.07336599731445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.74924945831299, "step": 9000}
{"episode_reward": 125.86008643119294, "episode": 10.0, "batch_reward": 0.4894913610816002, "critic_loss": 2.7454491435289383, "actor_loss": -104.97239683532715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.784189462661743, "step": 10000}
{"episode_reward": 81.97286811340288, "episode": 11.0, "batch_reward": 0.4464733181297779, "critic_loss": 2.5106840884685515, "actor_loss": -105.22115632629395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.34689664840698, "step": 11000}
{"episode_reward": 50.06076214512032, "episode": 12.0, "batch_reward": 0.41025258383154867, "critic_loss": 2.4324911139011385, "actor_loss": -104.65551083374024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.990641832351685, "step": 12000}
{"episode_reward": 31.326722810591566, "episode": 13.0, "batch_reward": 0.3912438906133175, "critic_loss": 2.423338922739029, "actor_loss": -103.60649436950683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.42323613166809, "step": 13000}
{"episode_reward": 314.9661203597324, "episode": 14.0, "batch_reward": 0.3852197300493717, "critic_loss": 2.1194260020256044, "actor_loss": -104.1047332611084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.858949899673462, "step": 14000}
{"episode_reward": 184.66451038018633, "episode": 15.0, "batch_reward": 0.3822592380940914, "critic_loss": 1.859788269162178, "actor_loss": -100.79984248352051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.619524478912354, "step": 15000}
{"episode_reward": 339.9199398213054, "episode": 16.0, "batch_reward": 0.3625772680938244, "critic_loss": 1.8186005157232286, "actor_loss": -99.03781690979004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.280264377593994, "step": 16000}
{"episode_reward": 193.27418074946095, "episode": 17.0, "batch_reward": 0.3734037687629461, "critic_loss": 2.00849920296669, "actor_loss": -99.43474940490722, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.948171854019165, "step": 17000}
{"episode_reward": 869.1422723657398, "episode": 18.0, "batch_reward": 0.40086025965213773, "critic_loss": 2.200652291417122, "actor_loss": -99.11178637695312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.67377471923828, "step": 18000}
{"episode_reward": 817.3562081073126, "episode": 19.0, "batch_reward": 0.4279826742708683, "critic_loss": 2.2979174407720566, "actor_loss": -98.36574992370605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.467232942581177, "step": 19000}
{"episode_reward": 962.4856614461867, "episode": 20.0, "batch_reward": 0.44613544043898584, "critic_loss": 2.4124139086008074, "actor_loss": -98.13065098571778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.819998264312744, "step": 20000}
{"episode_reward": 739.2353453971795, "episode": 21.0, "batch_reward": 0.44700940161943437, "critic_loss": 2.2081551387310028, "actor_loss": -97.72036256408691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.823548555374146, "step": 21000}
{"episode_reward": 28.19348775674943, "episode": 22.0, "batch_reward": 0.4486338412463665, "critic_loss": 2.112016365766525, "actor_loss": -97.82797804260254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.727452278137207, "step": 22000}
{"episode_reward": 971.2113624403972, "episode": 23.0, "batch_reward": 0.4509584822356701, "critic_loss": 1.8592275869250297, "actor_loss": -98.43419189453125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.7659330368042, "step": 23000}
{"episode_reward": 26.29003560749962, "episode": 24.0, "batch_reward": 0.4531781345009804, "critic_loss": 1.6835007860660554, "actor_loss": -97.8673598022461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.639763832092285, "step": 24000}
{"episode_reward": 907.4880891443044, "episode": 25.0, "batch_reward": 0.47299567151069644, "critic_loss": 1.527349253177643, "actor_loss": -99.06140414428711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.51335048675537, "step": 25000}
{"episode_reward": 916.9868584460289, "episode": 26.0, "batch_reward": 0.48488457542657853, "critic_loss": 1.4141596205234528, "actor_loss": -98.28769694519043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.68039321899414, "step": 26000}
{"episode_reward": 821.4293688800667, "episode": 27.0, "batch_reward": 0.5020668473541736, "critic_loss": 1.151104404449463, "actor_loss": -97.93487768554688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.402461528778076, "step": 27000}
{"episode_reward": 931.0241685136546, "episode": 28.0, "batch_reward": 0.5154203144311905, "critic_loss": 0.9771554658412933, "actor_loss": -98.03692129516601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.580617427825928, "step": 28000}
{"episode_reward": 890.1943355096349, "episode": 29.0, "batch_reward": 0.5266346889734268, "critic_loss": 0.9543373686671257, "actor_loss": -97.26734855651856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.485222101211548, "step": 29000}
{"episode_reward": 706.1824010957037, "episode": 30.0, "batch_reward": 0.535549012452364, "critic_loss": 1.0044998625516892, "actor_loss": -97.10006903076172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.274572610855103, "step": 30000}
{"episode_reward": 901.5211134043013, "episode": 31.0, "batch_reward": 0.5455599828362465, "critic_loss": 0.985837374150753, "actor_loss": -96.66995956420898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.43964219093323, "step": 31000}
{"episode_reward": 819.5406398407939, "episode": 32.0, "batch_reward": 0.5536314572095871, "critic_loss": 0.9734460847377777, "actor_loss": -95.4408983001709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.587085962295532, "step": 32000}
{"episode_reward": 799.0809487441107, "episode": 33.0, "batch_reward": 0.5630642831027508, "critic_loss": 0.9831392868161202, "actor_loss": -95.10250184631347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.78324031829834, "step": 33000}
{"episode_reward": 930.0506557953752, "episode": 34.0, "batch_reward": 0.5778986670970917, "critic_loss": 0.9724805656671524, "actor_loss": -95.89378495788574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.472153425216675, "step": 34000}
{"episode_reward": 982.1308349006267, "episode": 35.0, "batch_reward": 0.5832910993397236, "critic_loss": 1.0552424320578575, "actor_loss": -94.49948707580566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.606833696365356, "step": 35000}
{"episode_reward": 773.1896256561857, "episode": 36.0, "batch_reward": 0.5887111507356166, "critic_loss": 1.043387319087982, "actor_loss": -94.13195397949218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.699162006378174, "step": 36000}
{"episode_reward": 886.869643755816, "episode": 37.0, "batch_reward": 0.5984412741363049, "critic_loss": 1.0183483451008797, "actor_loss": -93.94286473083496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.36520767211914, "step": 37000}
{"episode_reward": 937.4641150123923, "episode": 38.0, "batch_reward": 0.6090213094651699, "critic_loss": 1.0050658717155456, "actor_loss": -93.55816893005371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.721191883087158, "step": 38000}
{"episode_reward": 978.3218524344563, "episode": 39.0, "batch_reward": 0.6168868876099587, "critic_loss": 0.9833179669380188, "actor_loss": -92.90957002258301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.578956842422485, "step": 39000}
{"episode_reward": 951.2986480162356, "episode": 40.0, "batch_reward": 0.6281871998906136, "critic_loss": 0.9390904703736305, "actor_loss": -93.13680401611329, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.431459188461304, "step": 40000}
{"episode_reward": 947.7612510210649, "episode": 41.0, "batch_reward": 0.6338868623375893, "critic_loss": 0.9152307487130165, "actor_loss": -93.00745272827149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.83242726325989, "step": 41000}
{"episode_reward": 959.9493178354809, "episode": 42.0, "batch_reward": 0.6447939606904983, "critic_loss": 0.8143078393042088, "actor_loss": -93.1514028930664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.07849431037903, "step": 42000}
{"episode_reward": 963.0803017767829, "episode": 43.0, "batch_reward": 0.6505546843409539, "critic_loss": 0.813847787708044, "actor_loss": -93.0796520690918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.48633360862732, "step": 43000}
{"episode_reward": 937.1173681409964, "episode": 44.0, "batch_reward": 0.658712460398674, "critic_loss": 0.7773365714251995, "actor_loss": -93.14666311645507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.952722311019897, "step": 44000}
{"episode_reward": 902.85263921324, "episode": 45.0, "batch_reward": 0.6608313284516335, "critic_loss": 0.801531544238329, "actor_loss": -92.64311720275879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.00326466560364, "step": 45000}
{"episode_reward": 871.9987877695296, "episode": 46.0, "batch_reward": 0.6644174352884292, "critic_loss": 0.7706766196489334, "actor_loss": -92.55788681030273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.12269353866577, "step": 46000}
{"episode_reward": 857.5828860823977, "episode": 47.0, "batch_reward": 0.6722149868607521, "critic_loss": 0.7694998193681241, "actor_loss": -92.51762788391113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.884748458862305, "step": 47000}
{"episode_reward": 976.0000176063301, "episode": 48.0, "batch_reward": 0.6746374444961548, "critic_loss": 0.7852180251479148, "actor_loss": -92.34062841796874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.960511207580566, "step": 48000}
{"episode_reward": 810.5143338911765, "episode": 49.0, "batch_reward": 0.6785222075581551, "critic_loss": 0.7904616069793701, "actor_loss": -92.08033926391602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.501670837402344, "step": 49000}
{"episode_reward": 795.6903079115145, "episode": 50.0, "batch_reward": 0.682085431933403, "critic_loss": 0.7681737257242203, "actor_loss": -91.94602995300293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.65617847442627, "step": 50000}
{"episode_reward": 982.7666227817385, "episode": 51.0, "batch_reward": 0.6912641626000404, "critic_loss": 0.7718373458981515, "actor_loss": -92.11567481994629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.90464425086975, "step": 51000}
{"episode_reward": 983.2597322396992, "episode": 52.0, "batch_reward": 0.6935015411376954, "critic_loss": 0.776606289178133, "actor_loss": -91.9824496307373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.41831088066101, "step": 52000}
{"episode_reward": 947.1152826889735, "episode": 53.0, "batch_reward": 0.7010181706547737, "critic_loss": 0.7633720890581608, "actor_loss": -91.92373913574218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.953662872314453, "step": 53000}
{"episode_reward": 960.554964145368, "episode": 54.0, "batch_reward": 0.7042553873062134, "critic_loss": 0.7189461123943329, "actor_loss": -91.79861950683593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.237009286880493, "step": 54000}
{"episode_reward": 933.4074403118423, "episode": 55.0, "batch_reward": 0.7091137961745262, "critic_loss": 0.6786091846227645, "actor_loss": -91.81313554382324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.584893226623535, "step": 55000}
{"episode_reward": 974.6198901619964, "episode": 56.0, "batch_reward": 0.713067131459713, "critic_loss": 0.714570400595665, "actor_loss": -91.7272631072998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.808531284332275, "step": 56000}
{"episode_reward": 989.0870639388635, "episode": 57.0, "batch_reward": 0.7189243896603584, "critic_loss": 0.6800640698969365, "actor_loss": -91.6796189880371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.338129997253418, "step": 57000}
{"episode_reward": 953.015639839878, "episode": 58.0, "batch_reward": 0.72237025141716, "critic_loss": 0.682947544246912, "actor_loss": -91.70427937316894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.445669174194336, "step": 58000}
{"episode_reward": 949.1625846913603, "episode": 59.0, "batch_reward": 0.7295298414826393, "critic_loss": 0.6511380185782909, "actor_loss": -91.7368860168457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.73426055908203, "step": 59000}
{"episode_reward": 957.4726543815871, "episode": 60.0, "batch_reward": 0.7297143226265908, "critic_loss": 0.6563565707206727, "actor_loss": -91.71323350524902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.607078552246094, "step": 60000}
{"episode_reward": 951.1645741797707, "episode": 61.0, "batch_reward": 0.7335967711210251, "critic_loss": 0.6373680947124958, "actor_loss": -91.71919812011718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.918376207351685, "step": 61000}
{"episode_reward": 958.3990387542717, "episode": 62.0, "batch_reward": 0.7366447400450706, "critic_loss": 0.6265401938259602, "actor_loss": -91.72694323730468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.46284055709839, "step": 62000}
{"episode_reward": 969.6450813328171, "episode": 63.0, "batch_reward": 0.7390145653486252, "critic_loss": 0.6041158400177956, "actor_loss": -91.72753018188476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.391357421875, "step": 63000}
{"episode_reward": 934.3662737474158, "episode": 64.0, "batch_reward": 0.7435224706530571, "critic_loss": 0.6115265524685383, "actor_loss": -91.80656434631348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.678473949432373, "step": 64000}
{"episode_reward": 982.1308946022662, "episode": 65.0, "batch_reward": 0.748251837670803, "critic_loss": 0.5764225165247917, "actor_loss": -91.7983370513916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.893693447113037, "step": 65000}
{"episode_reward": 984.8692087175262, "episode": 66.0, "batch_reward": 0.75113841432333, "critic_loss": 0.5426998437196017, "actor_loss": -91.80074334716797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.984607696533203, "step": 66000}
{"episode_reward": 937.9204990119625, "episode": 67.0, "batch_reward": 0.7531509727239609, "critic_loss": 0.5418848288804292, "actor_loss": -91.82551606750488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.626166105270386, "step": 67000}
{"episode_reward": 936.4330549634959, "episode": 68.0, "batch_reward": 0.7570817418694497, "critic_loss": 0.5297753305137157, "actor_loss": -91.89625582885742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.638660192489624, "step": 68000}
{"episode_reward": 959.5232842868587, "episode": 69.0, "batch_reward": 0.7600782912373543, "critic_loss": 0.5129730777591467, "actor_loss": -91.86770500183106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.113504648208618, "step": 69000}
{"episode_reward": 985.6246262664679, "episode": 70.0, "batch_reward": 0.7610452637672425, "critic_loss": 0.5086265245229006, "actor_loss": -91.83211157226563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.369999170303345, "step": 70000}
{"episode_reward": 924.8230564015925, "episode": 71.0, "batch_reward": 0.7666653353571892, "critic_loss": 0.5118498569726944, "actor_loss": -91.92708500671387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.427858114242554, "step": 71000}
{"episode_reward": 952.0986440910465, "episode": 72.0, "batch_reward": 0.7679797681570053, "critic_loss": 0.4923422258794308, "actor_loss": -91.94610501098633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.028136014938354, "step": 72000}
{"episode_reward": 966.7557848168944, "episode": 73.0, "batch_reward": 0.7705480936765671, "critic_loss": 0.4959627753198147, "actor_loss": -91.956634765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.251465797424316, "step": 73000}
{"episode_reward": 946.5029812131901, "episode": 74.0, "batch_reward": 0.7749488754272461, "critic_loss": 0.5106563181430102, "actor_loss": -91.97013542175293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.837433099746704, "step": 74000}
{"episode_reward": 899.6384953399399, "episode": 75.0, "batch_reward": 0.7737680785059929, "critic_loss": 0.4729588085114956, "actor_loss": -91.92762428283692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.384963989257812, "step": 75000}
{"episode_reward": 962.8611468558323, "episode": 76.0, "batch_reward": 0.7765801700949669, "critic_loss": 0.48739745159447195, "actor_loss": -91.87553273010253, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.89873695373535, "step": 76000}
{"episode_reward": 948.4404888941036, "episode": 77.0, "batch_reward": 0.778158362030983, "critic_loss": 0.4795224173665047, "actor_loss": -91.8566441192627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.756980419158936, "step": 77000}
{"episode_reward": 961.6627864206463, "episode": 78.0, "batch_reward": 0.7818963151574135, "critic_loss": 0.4770455104708672, "actor_loss": -91.98165260314941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.23119330406189, "step": 78000}
{"episode_reward": 957.7053059303078, "episode": 79.0, "batch_reward": 0.7833114389181137, "critic_loss": 0.49508323313295843, "actor_loss": -91.92559542846679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.196077823638916, "step": 79000}
{"episode_reward": 893.2292592465602, "episode": 80.0, "batch_reward": 0.7849725813865661, "critic_loss": 0.4982796241641045, "actor_loss": -91.85294485473632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.45192241668701, "step": 80000}
{"episode_reward": 977.0235622675655, "episode": 81.0, "batch_reward": 0.7886391291022301, "critic_loss": 0.48882144278287887, "actor_loss": -92.00225834655761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.47454214096069, "step": 81000}
{"episode_reward": 911.4031510656913, "episode": 82.0, "batch_reward": 0.790489972949028, "critic_loss": 0.48550783717632295, "actor_loss": -92.00532852172852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.395201683044434, "step": 82000}
{"episode_reward": 949.3368719560359, "episode": 83.0, "batch_reward": 0.7905592541098595, "critic_loss": 0.48609551444649696, "actor_loss": -91.9218964691162, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.521010160446167, "step": 83000}
{"episode_reward": 919.4051188979881, "episode": 84.0, "batch_reward": 0.7948501139879227, "critic_loss": 0.49047651106119156, "actor_loss": -92.02057301330566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.545931577682495, "step": 84000}
{"episode_reward": 988.7646615908, "episode": 85.0, "batch_reward": 0.7941860159635544, "critic_loss": 0.5133165363669395, "actor_loss": -91.93738415527343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.184566020965576, "step": 85000}
{"episode_reward": 958.6544887132101, "episode": 86.0, "batch_reward": 0.7975327781438828, "critic_loss": 0.502327786296606, "actor_loss": -91.88741551208496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.93610978126526, "step": 86000}
{"episode_reward": 958.6100230054318, "episode": 87.0, "batch_reward": 0.7986021689772606, "critic_loss": 0.5119079103320837, "actor_loss": -91.9157763671875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.83686923980713, "step": 87000}
{"episode_reward": 928.7763834369741, "episode": 88.0, "batch_reward": 0.7989437413811684, "critic_loss": 0.5367188047617674, "actor_loss": -91.89310855102539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.85276436805725, "step": 88000}
{"episode_reward": 841.6622118645672, "episode": 89.0, "batch_reward": 0.7997214480042457, "critic_loss": 0.534377357929945, "actor_loss": -91.94724417114257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.045523166656494, "step": 89000}
{"episode_reward": 966.3443222632611, "episode": 90.0, "batch_reward": 0.8031182036995888, "critic_loss": 0.5239410247802735, "actor_loss": -92.06020512390137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.331635236740112, "step": 90000}
{"episode_reward": 962.5308519907776, "episode": 91.0, "batch_reward": 0.8038526349663735, "critic_loss": 0.4842024605721235, "actor_loss": -91.95801135253906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.32340216636658, "step": 91000}
{"episode_reward": 952.8329052715551, "episode": 92.0, "batch_reward": 0.8081968559026718, "critic_loss": 0.51944143897295, "actor_loss": -92.16772372436523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.38871669769287, "step": 92000}
{"episode_reward": 969.6939163993004, "episode": 93.0, "batch_reward": 0.8072991256117821, "critic_loss": 0.49198214097321036, "actor_loss": -92.06390693664551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.965421438217163, "step": 93000}
{"episode_reward": 987.5869743814424, "episode": 94.0, "batch_reward": 0.8100921092629433, "critic_loss": 0.4486828465759754, "actor_loss": -92.2019828491211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.11018085479736, "step": 94000}
{"episode_reward": 948.8866906014124, "episode": 95.0, "batch_reward": 0.8112245891690254, "critic_loss": 0.4907931329458952, "actor_loss": -92.15691609191894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.843411922454834, "step": 95000}
{"episode_reward": 875.2578200943391, "episode": 96.0, "batch_reward": 0.8112535938620568, "critic_loss": 0.4708009470105171, "actor_loss": -92.09609391784667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.525914907455444, "step": 96000}
{"episode_reward": 951.4000264773022, "episode": 97.0, "batch_reward": 0.810704745709896, "critic_loss": 0.49980793650448324, "actor_loss": -92.02992596435547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.45370078086853, "step": 97000}
{"episode_reward": 916.8437953856637, "episode": 98.0, "batch_reward": 0.8143074964284897, "critic_loss": 0.49748240180313585, "actor_loss": -92.09229837036133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.12451434135437, "step": 98000}
{"episode_reward": 954.6378393235212, "episode": 99.0, "batch_reward": 0.8161574370861053, "critic_loss": 0.4785979479700327, "actor_loss": -92.1151429901123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.044740200042725, "step": 99000}
{"episode_reward": 946.344909674134, "episode": 100.0, "batch_reward": 0.8188746119737625, "critic_loss": 0.5128714115023613, "actor_loss": -92.11550723266602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.1385760307312, "step": 100000}
{"episode_reward": 914.6240155382836, "episode": 101.0, "batch_reward": 0.8180856721401215, "critic_loss": 0.5132933074980974, "actor_loss": -92.23258232116699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.11603045463562, "step": 101000}
{"episode_reward": 990.4508308970026, "episode": 102.0, "batch_reward": 0.8179632241725922, "critic_loss": 0.5305279553681612, "actor_loss": -92.28524592590333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.99458885192871, "step": 102000}
{"episode_reward": 969.3665042924735, "episode": 103.0, "batch_reward": 0.8199318897128105, "critic_loss": 0.5169327797442674, "actor_loss": -92.26148315429687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.09624719619751, "step": 103000}
{"episode_reward": 919.1876223781818, "episode": 104.0, "batch_reward": 0.8227745562195777, "critic_loss": 0.5097712637931109, "actor_loss": -92.29645231628417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.036516427993774, "step": 104000}
{"episode_reward": 961.9459646979124, "episode": 105.0, "batch_reward": 0.8241296402215957, "critic_loss": 0.5399738945215941, "actor_loss": -92.30920385742188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.707778453826904, "step": 105000}
{"episode_reward": 875.9205398827546, "episode": 106.0, "batch_reward": 0.8237304586172104, "critic_loss": 0.5502911787778139, "actor_loss": -92.27483357238769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.570062160491943, "step": 106000}
{"episode_reward": 920.926657157564, "episode": 107.0, "batch_reward": 0.8242095767259597, "critic_loss": 0.5337493527978658, "actor_loss": -92.29851422119141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.244260549545288, "step": 107000}
{"episode_reward": 926.3729821636612, "episode": 108.0, "batch_reward": 0.8273565753102302, "critic_loss": 0.5188068009465933, "actor_loss": -92.48071572875976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.715142965316772, "step": 108000}
{"episode_reward": 947.9540623558228, "episode": 109.0, "batch_reward": 0.8265771954655647, "critic_loss": 0.5091081269979477, "actor_loss": -92.32710119628906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.955833435058594, "step": 109000}
{"episode_reward": 975.2581812460955, "episode": 110.0, "batch_reward": 0.8277965426445008, "critic_loss": 0.5211131682246923, "actor_loss": -92.3431538848877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.875327110290527, "step": 110000}
{"episode_reward": 929.6854085429923, "episode": 111.0, "batch_reward": 0.8297278416752816, "critic_loss": 0.5228935598284006, "actor_loss": -92.35102250671386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 57.05369281768799, "step": 111000}
{"episode_reward": 966.2797149484294, "episode": 112.0, "batch_reward": 0.8310488156676292, "critic_loss": 0.5612228231579065, "actor_loss": -92.45116873168945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.136157512664795, "step": 112000}
{"episode_reward": 927.501819605947, "episode": 113.0, "batch_reward": 0.8317442215085029, "critic_loss": 0.5798749375194311, "actor_loss": -92.46307350158692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.992010354995728, "step": 113000}
{"episode_reward": 888.1360709157818, "episode": 114.0, "batch_reward": 0.8312676082253456, "critic_loss": 0.5517837079316378, "actor_loss": -92.4901771850586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.572656393051147, "step": 114000}
{"episode_reward": 976.9131320505361, "episode": 115.0, "batch_reward": 0.8336929505467415, "critic_loss": 0.5526821947842836, "actor_loss": -92.5186554107666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.843838691711426, "step": 115000}
{"episode_reward": 922.3404009956241, "episode": 116.0, "batch_reward": 0.8347936841845512, "critic_loss": 0.5330324414670468, "actor_loss": -92.60241438293457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.70382809638977, "step": 116000}
{"episode_reward": 954.2106906472121, "episode": 117.0, "batch_reward": 0.8349956766366958, "critic_loss": 0.5584698669463396, "actor_loss": -92.57311351013183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.85551381111145, "step": 117000}
{"episode_reward": 949.3691421692671, "episode": 118.0, "batch_reward": 0.8360978775024414, "critic_loss": 0.5319813656359911, "actor_loss": -92.65995585632324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.284642219543457, "step": 118000}
{"episode_reward": 982.8015004586356, "episode": 119.0, "batch_reward": 0.8371151109933853, "critic_loss": 0.5365186814665794, "actor_loss": -92.62106562805175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.50471782684326, "step": 119000}
{"episode_reward": 947.9523945175708, "episode": 120.0, "batch_reward": 0.8361919648647308, "critic_loss": 0.5056113327592612, "actor_loss": -92.47072499084473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.150367259979248, "step": 120000}
{"episode_reward": 892.5915857348501, "episode": 121.0, "batch_reward": 0.8385750200748444, "critic_loss": 0.49179889404773713, "actor_loss": -92.62336547851562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.51866960525513, "step": 121000}
{"episode_reward": 979.1979792599316, "episode": 122.0, "batch_reward": 0.8402740572094918, "critic_loss": 0.49593861900269987, "actor_loss": -92.67162997436523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.596660375595093, "step": 122000}
{"episode_reward": 943.6281273483312, "episode": 123.0, "batch_reward": 0.8421029772162437, "critic_loss": 0.519710213676095, "actor_loss": -92.64005551147461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.78557062149048, "step": 123000}
{"episode_reward": 959.7893437525363, "episode": 124.0, "batch_reward": 0.8415116894245148, "critic_loss": 0.5328448993861675, "actor_loss": -92.74330500793457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.875489950180054, "step": 124000}
{"episode_reward": 985.8467722027332, "episode": 125.0, "batch_reward": 0.8437856496572494, "critic_loss": 0.4747890606373549, "actor_loss": -92.8623618774414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.67430853843689, "step": 125000}
{"episode_reward": 986.472319060894, "episode": 126.0, "batch_reward": 0.8431961832046508, "critic_loss": 0.4793432029783726, "actor_loss": -92.95119328308105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.919869422912598, "step": 126000}
{"episode_reward": 989.6316246936734, "episode": 127.0, "batch_reward": 0.8444171326160431, "critic_loss": 0.5019616699814796, "actor_loss": -92.9868981628418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.35244393348694, "step": 127000}
{"episode_reward": 928.7761874698541, "episode": 128.0, "batch_reward": 0.8451067191958428, "critic_loss": 0.5236931957900525, "actor_loss": -93.06545982360839, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.01795983314514, "step": 128000}
{"episode_reward": 976.4502335865072, "episode": 129.0, "batch_reward": 0.8476702834367752, "critic_loss": 0.4835629558712244, "actor_loss": -93.20606167602539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.173528909683228, "step": 129000}
{"episode_reward": 982.9123639165429, "episode": 130.0, "batch_reward": 0.8491445552706719, "critic_loss": 0.48092854319512846, "actor_loss": -93.19470901489258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.778504371643066, "step": 130000}
{"episode_reward": 988.6466718752527, "episode": 131.0, "batch_reward": 0.8488893640041352, "critic_loss": 0.4476713197231293, "actor_loss": -93.13910609436036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.125752449035645, "step": 131000}
{"episode_reward": 964.2552339920537, "episode": 132.0, "batch_reward": 0.8504016146063804, "critic_loss": 0.4592226316332817, "actor_loss": -93.1859962463379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.869537353515625, "step": 132000}
{"episode_reward": 985.4115007179482, "episode": 133.0, "batch_reward": 0.8489859527349473, "critic_loss": 0.47722852155566214, "actor_loss": -93.26115548706055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.874070405960083, "step": 133000}
{"episode_reward": 928.3500009497841, "episode": 134.0, "batch_reward": 0.8507009851336479, "critic_loss": 0.46080612514913083, "actor_loss": -93.365755859375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.825868368148804, "step": 134000}
{"episode_reward": 974.2424258028334, "episode": 135.0, "batch_reward": 0.8539442717432976, "critic_loss": 0.423362546145916, "actor_loss": -93.4468490600586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.778545379638672, "step": 135000}
{"episode_reward": 991.9731912844477, "episode": 136.0, "batch_reward": 0.8537184273004532, "critic_loss": 0.42557828421890737, "actor_loss": -93.40669122314453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.595535278320312, "step": 136000}
{"episode_reward": 989.2746194506517, "episode": 137.0, "batch_reward": 0.8527132542729378, "critic_loss": 0.42760903573036196, "actor_loss": -93.42556382751465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.0342583656311, "step": 137000}
{"episode_reward": 969.0071757654684, "episode": 138.0, "batch_reward": 0.8564657793045044, "critic_loss": 0.44497183941304685, "actor_loss": -93.50560243225098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.071950912475586, "step": 138000}
{"episode_reward": 960.1895555025521, "episode": 139.0, "batch_reward": 0.8554576644897461, "critic_loss": 0.4473797850161791, "actor_loss": -93.46412606811523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.92194628715515, "step": 139000}
{"episode_reward": 976.7270108297116, "episode": 140.0, "batch_reward": 0.8556448286175727, "critic_loss": 0.46956482669711114, "actor_loss": -93.47924816894532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.356109142303467, "step": 140000}
{"episode_reward": 954.5043042511371, "episode": 141.0, "batch_reward": 0.8583371933698655, "critic_loss": 0.4532385886311531, "actor_loss": -93.60388534545899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 56.53692436218262, "step": 141000}
{"episode_reward": 955.7235802433188, "episode": 142.0, "batch_reward": 0.8572403016090393, "critic_loss": 0.4540211301296949, "actor_loss": -93.563267578125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.95433521270752, "step": 142000}
{"episode_reward": 988.7631992105051, "episode": 143.0, "batch_reward": 0.858302754163742, "critic_loss": 0.42775365070998667, "actor_loss": -93.60944961547851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.71491575241089, "step": 143000}
{"episode_reward": 847.3015552172861, "episode": 144.0, "batch_reward": 0.859084411740303, "critic_loss": 0.4472543358653784, "actor_loss": -93.64694612121582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.41972517967224, "step": 144000}
{"episode_reward": 955.0866493373935, "episode": 145.0, "batch_reward": 0.8607150772213936, "critic_loss": 0.43681365928053856, "actor_loss": -93.72576057434082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.707784175872803, "step": 145000}
{"episode_reward": 987.9131634351567, "episode": 146.0, "batch_reward": 0.860745957672596, "critic_loss": 0.4448997381031513, "actor_loss": -93.77142597961426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.01298213005066, "step": 146000}
{"episode_reward": 971.5927170632591, "episode": 147.0, "batch_reward": 0.8596846908330917, "critic_loss": 0.4504445922970772, "actor_loss": -93.69666722106933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.599218130111694, "step": 147000}
{"episode_reward": 897.8484728370356, "episode": 148.0, "batch_reward": 0.8628873749375343, "critic_loss": 0.4190147587880492, "actor_loss": -93.76667944335938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.256335973739624, "step": 148000}
{"episode_reward": 984.7323177373202, "episode": 149.0, "batch_reward": 0.8618864566087723, "critic_loss": 0.4278593442440033, "actor_loss": -93.72765753173829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.41293740272522, "step": 149000}
{"episode_reward": 941.8255613597164, "episode": 150.0, "batch_reward": 0.8632876002788543, "critic_loss": 0.44544939844310283, "actor_loss": -93.84443740844726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
