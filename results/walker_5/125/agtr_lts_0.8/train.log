{"episode_reward": 0.0, "episode": 1.0, "duration": 27.635695219039917, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 2.369638442993164, "step": 2000}
{"episode_reward": 890.1817750618746, "episode": 3.0, "batch_reward": 0.48989460433710014, "critic_loss": 0.982372130193723, "actor_loss": -85.67152284803082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 94.07107138633728, "step": 3000}
{"episode_reward": 791.9626543134718, "episode": 4.0, "batch_reward": 0.6236507538557052, "critic_loss": 1.270120240867138, "actor_loss": -88.63624633789063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.49845814704895, "step": 4000}
{"episode_reward": 877.377951950293, "episode": 5.0, "batch_reward": 0.6832449291348457, "critic_loss": 1.7192030484676362, "actor_loss": -90.03302310180663, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.57340383529663, "step": 5000}
{"episode_reward": 952.8734918535397, "episode": 6.0, "batch_reward": 0.7331715461015701, "critic_loss": 1.9306221104860306, "actor_loss": -91.22314002990723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.022860527038574, "step": 6000}
{"episode_reward": 916.6914333691458, "episode": 7.0, "batch_reward": 0.7573720851540565, "critic_loss": 2.0097652349472046, "actor_loss": -91.99283978271484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.756715774536133, "step": 7000}
{"episode_reward": 930.478846769439, "episode": 8.0, "batch_reward": 0.7761115910410881, "critic_loss": 2.332417530834675, "actor_loss": -92.4746749420166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.925557136535645, "step": 8000}
{"episode_reward": 867.1504785763715, "episode": 9.0, "batch_reward": 0.7838836677074432, "critic_loss": 2.02268344193697, "actor_loss": -92.61411170959472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.30873942375183, "step": 9000}
{"episode_reward": 799.44022282301, "episode": 10.0, "batch_reward": 0.7904283602833748, "critic_loss": 1.6451056671142579, "actor_loss": -92.63365417480469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.6773624420166, "step": 10000}
{"episode_reward": 832.824827687057, "episode": 11.0, "batch_reward": 0.791050168633461, "critic_loss": 1.5732005524635315, "actor_loss": -92.45057048034668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.945173263549805, "step": 11000}
{"episode_reward": 810.7098666547829, "episode": 12.0, "batch_reward": 0.7827929161190986, "critic_loss": 1.7034323374032974, "actor_loss": -91.7684365234375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.008917570114136, "step": 12000}
{"episode_reward": 720.7703725731762, "episode": 13.0, "batch_reward": 0.7814133893847466, "critic_loss": 1.6550971502661704, "actor_loss": -91.57193521118164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.21539807319641, "step": 13000}
{"episode_reward": 702.5723987971991, "episode": 14.0, "batch_reward": 0.7875675743222237, "critic_loss": 1.4325487198233604, "actor_loss": -91.38040086364747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.023613214492798, "step": 14000}
{"episode_reward": 979.7479866002392, "episode": 15.0, "batch_reward": 0.7986742864847183, "critic_loss": 1.4447011833786965, "actor_loss": -91.80219146728516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.366846323013306, "step": 15000}
{"episode_reward": 894.0695319727517, "episode": 16.0, "batch_reward": 0.8052138890624047, "critic_loss": 1.5443061391711235, "actor_loss": -91.60008840942383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.544729232788086, "step": 16000}
{"episode_reward": 906.716756871911, "episode": 17.0, "batch_reward": 0.8044306212067605, "critic_loss": 1.5479622466564178, "actor_loss": -91.62446212768555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.560914993286133, "step": 17000}
{"episode_reward": 836.3083626879729, "episode": 18.0, "batch_reward": 0.8117853043675423, "critic_loss": 1.6813506348133087, "actor_loss": -91.61668968200684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.44358468055725, "step": 18000}
{"episode_reward": 869.7209386042944, "episode": 19.0, "batch_reward": 0.8143341661691665, "critic_loss": 1.8913801988363266, "actor_loss": -91.4391860961914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.22430396080017, "step": 19000}
{"episode_reward": 919.8300992709346, "episode": 20.0, "batch_reward": 0.8228934838175773, "critic_loss": 1.9102248062491416, "actor_loss": -91.8519698638916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.50349020957947, "step": 20000}
{"episode_reward": 964.4379537507881, "episode": 21.0, "batch_reward": 0.8244803918004036, "critic_loss": 1.96081953561306, "actor_loss": -91.79856329345704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.46587777137756, "step": 21000}
{"episode_reward": 813.7891907372376, "episode": 22.0, "batch_reward": 0.8292289546728134, "critic_loss": 1.8979478750228882, "actor_loss": -91.7947269744873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.54047083854675, "step": 22000}
{"episode_reward": 983.0105116498164, "episode": 23.0, "batch_reward": 0.8342492390871048, "critic_loss": 1.6956365936994553, "actor_loss": -92.11445405578613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.262783527374268, "step": 23000}
{"episode_reward": 952.0389999674696, "episode": 24.0, "batch_reward": 0.8403922860026359, "critic_loss": 1.5275029992461204, "actor_loss": -92.13782579040527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.771271228790283, "step": 24000}
{"episode_reward": 977.7922821902737, "episode": 25.0, "batch_reward": 0.8451249545812607, "critic_loss": 1.5016201862692833, "actor_loss": -92.14996978759766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.18840265274048, "step": 25000}
{"episode_reward": 956.1715462583867, "episode": 26.0, "batch_reward": 0.8483812856078148, "critic_loss": 1.3915428955554963, "actor_loss": -92.4557558746338, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.45571255683899, "step": 26000}
{"episode_reward": 984.8979229815933, "episode": 27.0, "batch_reward": 0.8574561078548432, "critic_loss": 1.3271020311117172, "actor_loss": -92.55236579895019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.59643530845642, "step": 27000}
{"episode_reward": 983.0682965576748, "episode": 28.0, "batch_reward": 0.8589611899852753, "critic_loss": 1.2927271865010261, "actor_loss": -92.55595402526855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.17284965515137, "step": 28000}
{"episode_reward": 956.0660967158526, "episode": 29.0, "batch_reward": 0.8632853603959083, "critic_loss": 1.0999968866109848, "actor_loss": -92.7857163696289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.463650941848755, "step": 29000}
{"episode_reward": 953.7842707461564, "episode": 30.0, "batch_reward": 0.8644393361210823, "critic_loss": 1.2194756476283073, "actor_loss": -92.7098196258545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.354432582855225, "step": 30000}
{"episode_reward": 864.5209961964557, "episode": 31.0, "batch_reward": 0.8646838465929031, "critic_loss": 1.3000385710597038, "actor_loss": -92.7544081878662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 58.92072868347168, "step": 31000}
{"episode_reward": 902.9780171956288, "episode": 32.0, "batch_reward": 0.8681172639131546, "critic_loss": 1.207207554101944, "actor_loss": -92.6761241607666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.268484354019165, "step": 32000}
{"episode_reward": 954.6987812915844, "episode": 33.0, "batch_reward": 0.8685220364928246, "critic_loss": 1.2323255534172057, "actor_loss": -92.91111488342285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.48264718055725, "step": 33000}
{"episode_reward": 928.9076721002375, "episode": 34.0, "batch_reward": 0.872370877802372, "critic_loss": 1.2346000799536705, "actor_loss": -92.78285345458984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.422889709472656, "step": 34000}
{"episode_reward": 981.6533010577401, "episode": 35.0, "batch_reward": 0.8734682618379593, "critic_loss": 1.2688324245214462, "actor_loss": -93.1264819946289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.801045894622803, "step": 35000}
{"episode_reward": 918.0528070708851, "episode": 36.0, "batch_reward": 0.874762665450573, "critic_loss": 1.253127782523632, "actor_loss": -92.84091130065919, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.726196765899658, "step": 36000}
{"episode_reward": 948.8173432544636, "episode": 37.0, "batch_reward": 0.8763265528082848, "critic_loss": 1.1808016729354858, "actor_loss": -93.14929872131347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.538997650146484, "step": 37000}
{"episode_reward": 950.8111245804974, "episode": 38.0, "batch_reward": 0.8803201729059219, "critic_loss": 1.2044982324838638, "actor_loss": -93.18298370361327, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.791847705841064, "step": 38000}
{"episode_reward": 983.1325316038672, "episode": 39.0, "batch_reward": 0.8804589874148369, "critic_loss": 1.3012385743260384, "actor_loss": -93.20177944946289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.74919152259827, "step": 39000}
{"episode_reward": 913.8129236793172, "episode": 40.0, "batch_reward": 0.8829105535149574, "critic_loss": 1.273023080945015, "actor_loss": -93.35708949279785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.80945920944214, "step": 40000}
{"episode_reward": 969.1335776665517, "episode": 41.0, "batch_reward": 0.8853255205154419, "critic_loss": 1.3322476089596749, "actor_loss": -93.43210612487793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 58.895071029663086, "step": 41000}
{"episode_reward": 916.1259146960974, "episode": 42.0, "batch_reward": 0.8865994302630424, "critic_loss": 1.352935751736164, "actor_loss": -93.12792654418945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.54391813278198, "step": 42000}
{"episode_reward": 906.563482900057, "episode": 43.0, "batch_reward": 0.8869931400418282, "critic_loss": 1.417047267794609, "actor_loss": -93.28107829284669, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.732727527618408, "step": 43000}
{"episode_reward": 914.8490118296448, "episode": 44.0, "batch_reward": 0.8875859714746476, "critic_loss": 1.3248283616900445, "actor_loss": -93.26730192565918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.79156804084778, "step": 44000}
{"episode_reward": 976.2381929628424, "episode": 45.0, "batch_reward": 0.8885052190423012, "critic_loss": 1.2303120177388192, "actor_loss": -93.35078018188477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.467167139053345, "step": 45000}
{"episode_reward": 943.7876435180178, "episode": 46.0, "batch_reward": 0.8898154579997063, "critic_loss": 1.2768824800848961, "actor_loss": -93.39523843383789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.207351207733154, "step": 46000}
{"episode_reward": 925.9980574334943, "episode": 47.0, "batch_reward": 0.8916641966104507, "critic_loss": 1.2138841971755028, "actor_loss": -93.54069526672363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.39057970046997, "step": 47000}
{"episode_reward": 961.0165171048565, "episode": 48.0, "batch_reward": 0.8913116011023522, "critic_loss": 1.3368895773887635, "actor_loss": -93.41895104980469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.71396517753601, "step": 48000}
{"episode_reward": 897.4380118844791, "episode": 49.0, "batch_reward": 0.8946376466155053, "critic_loss": 1.3100399350821972, "actor_loss": -93.682431640625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.39257836341858, "step": 49000}
{"episode_reward": 956.5247693220026, "episode": 50.0, "batch_reward": 0.8949580487012864, "critic_loss": 1.2420082968473434, "actor_loss": -93.51413487243653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.80768084526062, "step": 50000}
{"episode_reward": 973.1309111831499, "episode": 51.0, "batch_reward": 0.8960585986971855, "critic_loss": 1.2894977759718895, "actor_loss": -93.53995663452149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.77958965301514, "step": 51000}
{"episode_reward": 924.6719029607896, "episode": 52.0, "batch_reward": 0.8960618857741356, "critic_loss": 1.2278733151555061, "actor_loss": -93.5397229309082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.467745780944824, "step": 52000}
{"episode_reward": 956.4230295815269, "episode": 53.0, "batch_reward": 0.8982142505645752, "critic_loss": 1.20700401699543, "actor_loss": -93.73084370422363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.336936473846436, "step": 53000}
{"episode_reward": 957.1979386720507, "episode": 54.0, "batch_reward": 0.8966354238390922, "critic_loss": 1.284486108481884, "actor_loss": -93.64417254638671, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.62588357925415, "step": 54000}
{"episode_reward": 848.0018585768258, "episode": 55.0, "batch_reward": 0.8976217064857482, "critic_loss": 1.177685941874981, "actor_loss": -93.92602178955079, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.26970839500427, "step": 55000}
{"episode_reward": 957.2224540672339, "episode": 56.0, "batch_reward": 0.8993207027316094, "critic_loss": 1.2087332369089128, "actor_loss": -93.8960693206787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.808692932128906, "step": 56000}
{"episode_reward": 965.2348648764406, "episode": 57.0, "batch_reward": 0.8995673347115517, "critic_loss": 1.2698339884877206, "actor_loss": -93.69294039916993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.907238960266113, "step": 57000}
{"episode_reward": 897.3116422704428, "episode": 58.0, "batch_reward": 0.900207258105278, "critic_loss": 1.1976339700818062, "actor_loss": -93.76574090576172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.018415451049805, "step": 58000}
{"episode_reward": 975.6386408884042, "episode": 59.0, "batch_reward": 0.9024483550190926, "critic_loss": 1.2542568105459213, "actor_loss": -93.79213621520996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.626331090927124, "step": 59000}
{"episode_reward": 953.320628582521, "episode": 60.0, "batch_reward": 0.8995110441446305, "critic_loss": 1.3298540245592594, "actor_loss": -93.75866627502441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.690467596054077, "step": 60000}
{"episode_reward": 794.0144179460125, "episode": 61.0, "batch_reward": 0.899661276459694, "critic_loss": 1.281465894460678, "actor_loss": -93.65584904479981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.04265832901001, "step": 61000}
{"episode_reward": 945.9421408542365, "episode": 62.0, "batch_reward": 0.8998308569788933, "critic_loss": 1.3111415637135506, "actor_loss": -93.90494931030274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.096458196640015, "step": 62000}
{"episode_reward": 927.3323975991226, "episode": 63.0, "batch_reward": 0.8999632458686828, "critic_loss": 1.2874870489239694, "actor_loss": -93.75318675231934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.544538497924805, "step": 63000}
{"episode_reward": 924.7986838751225, "episode": 64.0, "batch_reward": 0.9014792205095291, "critic_loss": 1.353509942471981, "actor_loss": -93.85618907165528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.54296326637268, "step": 64000}
{"episode_reward": 956.0094315565328, "episode": 65.0, "batch_reward": 0.9034471681714058, "critic_loss": 1.340471383690834, "actor_loss": -93.7621709136963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.77556324005127, "step": 65000}
{"episode_reward": 979.2514067198337, "episode": 66.0, "batch_reward": 0.9032022107839585, "critic_loss": 1.2692778077125548, "actor_loss": -93.79991540527344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.77099108695984, "step": 66000}
{"episode_reward": 906.375846254346, "episode": 67.0, "batch_reward": 0.9013473495841027, "critic_loss": 1.2774128687381745, "actor_loss": -93.8269443359375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.95835041999817, "step": 67000}
{"episode_reward": 894.6609066928431, "episode": 68.0, "batch_reward": 0.902964539885521, "critic_loss": 1.2711197182536125, "actor_loss": -93.74875270080567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.21790957450867, "step": 68000}
{"episode_reward": 953.9064788139628, "episode": 69.0, "batch_reward": 0.9046537191271782, "critic_loss": 1.2131286201775073, "actor_loss": -93.88327378845214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.608113288879395, "step": 69000}
{"episode_reward": 983.9143708920325, "episode": 70.0, "batch_reward": 0.9058727920055389, "critic_loss": 1.2200499172508716, "actor_loss": -93.94952694702148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.759786367416382, "step": 70000}
{"episode_reward": 914.2511140686718, "episode": 71.0, "batch_reward": 0.9046291549801826, "critic_loss": 1.2290374480187893, "actor_loss": -94.0150147857666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.93962645530701, "step": 71000}
{"episode_reward": 946.2369176289816, "episode": 72.0, "batch_reward": 0.9068361986279487, "critic_loss": 1.2153147396743298, "actor_loss": -94.07355624389649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.55555295944214, "step": 72000}
{"episode_reward": 980.1967511042793, "episode": 73.0, "batch_reward": 0.9064510895013809, "critic_loss": 1.2715541708469391, "actor_loss": -93.95236378479004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.40726637840271, "step": 73000}
{"episode_reward": 951.3780088244431, "episode": 74.0, "batch_reward": 0.9087644900679588, "critic_loss": 1.3010172753334046, "actor_loss": -94.14733255004883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.32645344734192, "step": 74000}
{"episode_reward": 922.4199792171024, "episode": 75.0, "batch_reward": 0.908404968559742, "critic_loss": 1.2712938698232175, "actor_loss": -93.98183670043946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.73231816291809, "step": 75000}
{"episode_reward": 969.4168143236631, "episode": 76.0, "batch_reward": 0.9094125020503998, "critic_loss": 1.314875547528267, "actor_loss": -94.06344343566894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.233157873153687, "step": 76000}
{"episode_reward": 944.8875758606822, "episode": 77.0, "batch_reward": 0.9089958005547524, "critic_loss": 1.199593205690384, "actor_loss": -93.96259915161133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.528847217559814, "step": 77000}
{"episode_reward": 962.2586783508158, "episode": 78.0, "batch_reward": 0.9104723917245865, "critic_loss": 1.1782168970406055, "actor_loss": -94.19828727722168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.40687823295593, "step": 78000}
{"episode_reward": 961.3595165045347, "episode": 79.0, "batch_reward": 0.911205642938614, "critic_loss": 1.203150725156069, "actor_loss": -93.88779479980468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.291697025299072, "step": 79000}
{"episode_reward": 968.6823965459299, "episode": 80.0, "batch_reward": 0.9113669874072075, "critic_loss": 1.193774912893772, "actor_loss": -94.0973949432373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.920690298080444, "step": 80000}
{"episode_reward": 982.495474689024, "episode": 81.0, "batch_reward": 0.9115014602541923, "critic_loss": 1.2298253665864467, "actor_loss": -94.10219441223144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.766921281814575, "step": 81000}
{"episode_reward": 896.8999468703904, "episode": 82.0, "batch_reward": 0.912004168510437, "critic_loss": 1.183138394445181, "actor_loss": -94.33462432861329, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.238919973373413, "step": 82000}
{"episode_reward": 922.1551335166448, "episode": 83.0, "batch_reward": 0.9110313176512718, "critic_loss": 1.2053557920455933, "actor_loss": -94.11546258544922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.340106964111328, "step": 83000}
{"episode_reward": 863.702423411492, "episode": 84.0, "batch_reward": 0.912067657828331, "critic_loss": 1.1403824735879897, "actor_loss": -94.55052224731445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.601749420166016, "step": 84000}
{"episode_reward": 988.6399518348614, "episode": 85.0, "batch_reward": 0.9120082230567932, "critic_loss": 1.1378356189131738, "actor_loss": -94.2522029724121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.35575532913208, "step": 85000}
{"episode_reward": 959.8779154838521, "episode": 86.0, "batch_reward": 0.9126942569613457, "critic_loss": 1.1031835948824882, "actor_loss": -94.20315669250488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.31231117248535, "step": 86000}
{"episode_reward": 956.7690294733194, "episode": 87.0, "batch_reward": 0.9140178416371345, "critic_loss": 1.0955027511417865, "actor_loss": -94.29587532043458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.46571373939514, "step": 87000}
{"episode_reward": 952.4703833619187, "episode": 88.0, "batch_reward": 0.9135396033525467, "critic_loss": 1.1434501986801624, "actor_loss": -94.14841450500488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.70361304283142, "step": 88000}
{"episode_reward": 944.3777782727875, "episode": 89.0, "batch_reward": 0.9137349700331688, "critic_loss": 1.0890900854468346, "actor_loss": -94.33482318115234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.29400658607483, "step": 89000}
{"episode_reward": 963.559409922821, "episode": 90.0, "batch_reward": 0.9156403938531875, "critic_loss": 1.0288038899302483, "actor_loss": -94.46906002807617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.435953617095947, "step": 90000}
{"episode_reward": 960.1581973022335, "episode": 91.0, "batch_reward": 0.9153158230185509, "critic_loss": 1.0505531102716923, "actor_loss": -94.32239315795898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.02306866645813, "step": 91000}
{"episode_reward": 941.1531374641607, "episode": 92.0, "batch_reward": 0.9166869918704033, "critic_loss": 1.0016899811327458, "actor_loss": -94.44136888122559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.333626985549927, "step": 92000}
{"episode_reward": 967.7608880549396, "episode": 93.0, "batch_reward": 0.9158273163437843, "critic_loss": 1.0084708156585693, "actor_loss": -94.3071867980957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.31612420082092, "step": 93000}
{"episode_reward": 986.5393389591768, "episode": 94.0, "batch_reward": 0.9158380129337311, "critic_loss": 0.9828248019516468, "actor_loss": -94.48532524108887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.52963161468506, "step": 94000}
{"episode_reward": 940.7434518609491, "episode": 95.0, "batch_reward": 0.9167038233876228, "critic_loss": 0.9966215753853321, "actor_loss": -94.5138218536377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.312952041625977, "step": 95000}
{"episode_reward": 958.2139917728972, "episode": 96.0, "batch_reward": 0.9173524487614632, "critic_loss": 1.0024906494915486, "actor_loss": -94.5799769897461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.857479572296143, "step": 96000}
{"episode_reward": 959.5145208804315, "episode": 97.0, "batch_reward": 0.917278360068798, "critic_loss": 1.056175018966198, "actor_loss": -94.5963973236084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.8449649810791, "step": 97000}
{"episode_reward": 927.1117242199526, "episode": 98.0, "batch_reward": 0.9176971799731255, "critic_loss": 0.9906968691647052, "actor_loss": -94.55604638671875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.367700815200806, "step": 98000}
{"episode_reward": 916.2045767841815, "episode": 99.0, "batch_reward": 0.9172330406904221, "critic_loss": 1.006201406598091, "actor_loss": -94.39897978210449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.48545002937317, "step": 99000}
{"episode_reward": 923.7573479762752, "episode": 100.0, "batch_reward": 0.9192578701376914, "critic_loss": 0.9636133940517903, "actor_loss": -94.55605763244628, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.34962749481201, "step": 100000}
{"episode_reward": 917.8271476555609, "episode": 101.0, "batch_reward": 0.9196991674900055, "critic_loss": 0.9688949648737908, "actor_loss": -94.60564086914063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.68378472328186, "step": 101000}
{"episode_reward": 987.200817104407, "episode": 102.0, "batch_reward": 0.9191754355430602, "critic_loss": 0.9571970236003399, "actor_loss": -94.53480224609375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.312687873840332, "step": 102000}
{"episode_reward": 983.7315255338309, "episode": 103.0, "batch_reward": 0.9184524936079979, "critic_loss": 0.9436365807056427, "actor_loss": -94.63623796081544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.123465061187744, "step": 103000}
{"episode_reward": 907.724701616307, "episode": 104.0, "batch_reward": 0.9199457880854607, "critic_loss": 0.9395641828477382, "actor_loss": -94.70100636291504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.42303204536438, "step": 104000}
{"episode_reward": 958.4680515576872, "episode": 105.0, "batch_reward": 0.9207394105792046, "critic_loss": 0.9440252991616725, "actor_loss": -94.7401661682129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.679558753967285, "step": 105000}
{"episode_reward": 911.7105355391092, "episode": 106.0, "batch_reward": 0.9196714878082275, "critic_loss": 0.9775573078691959, "actor_loss": -94.65043670654296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.03249168395996, "step": 106000}
{"episode_reward": 905.3778483810308, "episode": 107.0, "batch_reward": 0.9188285682797432, "critic_loss": 1.0171533692479133, "actor_loss": -94.65489053344727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.58719229698181, "step": 107000}
{"episode_reward": 961.1672112132563, "episode": 108.0, "batch_reward": 0.9211904489398003, "critic_loss": 1.0308367325663566, "actor_loss": -94.6891573638916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.32042908668518, "step": 108000}
{"episode_reward": 953.1005742041962, "episode": 109.0, "batch_reward": 0.9206877877116203, "critic_loss": 0.9659865159988403, "actor_loss": -94.86631430053711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.01509380340576, "step": 109000}
{"episode_reward": 949.0723114294135, "episode": 110.0, "batch_reward": 0.9206954882144928, "critic_loss": 1.0064466656446458, "actor_loss": -94.808896774292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.57797574996948, "step": 110000}
{"episode_reward": 945.4276665106447, "episode": 111.0, "batch_reward": 0.9199414795041084, "critic_loss": 1.026168742209673, "actor_loss": -94.74156065368652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.82128405570984, "step": 111000}
{"episode_reward": 910.0148193476899, "episode": 112.0, "batch_reward": 0.920617617726326, "critic_loss": 1.009165657967329, "actor_loss": -94.59501672363281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.13877034187317, "step": 112000}
{"episode_reward": 956.407108391487, "episode": 113.0, "batch_reward": 0.921715048611164, "critic_loss": 0.9749159141182899, "actor_loss": -94.76652543640137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.85799241065979, "step": 113000}
{"episode_reward": 959.3462920332144, "episode": 114.0, "batch_reward": 0.9212353745698929, "critic_loss": 0.9989764749109745, "actor_loss": -94.86136224365234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.313300132751465, "step": 114000}
{"episode_reward": 978.611292382899, "episode": 115.0, "batch_reward": 0.9219114120602607, "critic_loss": 1.0123153214752674, "actor_loss": -94.72329405212402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.88572669029236, "step": 115000}
{"episode_reward": 913.366696550616, "episode": 116.0, "batch_reward": 0.9211243833303452, "critic_loss": 1.015477754831314, "actor_loss": -94.67874740600585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.575921058654785, "step": 116000}
{"episode_reward": 895.6925229503555, "episode": 117.0, "batch_reward": 0.9214361216425896, "critic_loss": 1.0168412282466888, "actor_loss": -94.62646099853515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.63636374473572, "step": 117000}
{"episode_reward": 941.8325146472454, "episode": 118.0, "batch_reward": 0.9220608004927635, "critic_loss": 1.0469688319563866, "actor_loss": -94.74576837158203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.150441646575928, "step": 118000}
{"episode_reward": 989.3511279371381, "episode": 119.0, "batch_reward": 0.9219325966238976, "critic_loss": 1.030310792207718, "actor_loss": -94.75408320617676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.386109352111816, "step": 119000}
{"episode_reward": 945.4119182316181, "episode": 120.0, "batch_reward": 0.9215283116698265, "critic_loss": 0.9992882993221283, "actor_loss": -94.65683290100098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.75200533866882, "step": 120000}
{"episode_reward": 926.1335691038247, "episode": 121.0, "batch_reward": 0.9228721632361412, "critic_loss": 0.9413963281512261, "actor_loss": -94.62162283325195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.30259656906128, "step": 121000}
{"episode_reward": 981.2512870659432, "episode": 122.0, "batch_reward": 0.9228224353194237, "critic_loss": 1.0110137427449226, "actor_loss": -94.67778419494628, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.212402820587158, "step": 122000}
{"episode_reward": 949.3052098424337, "episode": 123.0, "batch_reward": 0.9234608060717583, "critic_loss": 1.0305659881234168, "actor_loss": -94.55932389831543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.57825565338135, "step": 123000}
{"episode_reward": 949.0483345315746, "episode": 124.0, "batch_reward": 0.9222376052737236, "critic_loss": 0.999868123948574, "actor_loss": -94.69057409667968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.21566891670227, "step": 124000}
{"episode_reward": 919.100728419341, "episode": 125.0, "batch_reward": 0.9241414886116982, "critic_loss": 0.9508599643707275, "actor_loss": -94.72560832214356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.75357675552368, "step": 125000}
{"episode_reward": 985.1366580171169, "episode": 126.0, "batch_reward": 0.92508157736063, "critic_loss": 0.9658820413649082, "actor_loss": -94.72319393920898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.896939754486084, "step": 126000}
{"episode_reward": 987.6354765159517, "episode": 127.0, "batch_reward": 0.9237757772803307, "critic_loss": 0.9565615572929382, "actor_loss": -94.84180282592773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.44161677360535, "step": 127000}
{"episode_reward": 941.7145922209587, "episode": 128.0, "batch_reward": 0.9245164975523948, "critic_loss": 0.9451616821587085, "actor_loss": -95.00619033813477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.570162773132324, "step": 128000}
{"episode_reward": 968.4410757409976, "episode": 129.0, "batch_reward": 0.9248689228892326, "critic_loss": 0.8837340447306633, "actor_loss": -94.92428939819337, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.678699016571045, "step": 129000}
{"episode_reward": 984.7594340583618, "episode": 130.0, "batch_reward": 0.9265371409654617, "critic_loss": 0.8775842819958926, "actor_loss": -94.95161598205567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.59002494812012, "step": 130000}
{"episode_reward": 990.1635709981769, "episode": 131.0, "batch_reward": 0.9262886262536049, "critic_loss": 0.8678966790884733, "actor_loss": -94.97787384033204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.3299286365509, "step": 131000}
{"episode_reward": 956.8191879437651, "episode": 132.0, "batch_reward": 0.9256619603037834, "critic_loss": 0.9312142388671637, "actor_loss": -94.96833198547364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.255573749542236, "step": 132000}
{"episode_reward": 934.9791477377356, "episode": 133.0, "batch_reward": 0.9258656928539276, "critic_loss": 0.8975149433016777, "actor_loss": -94.97335832214355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.486709117889404, "step": 133000}
{"episode_reward": 960.4531312811877, "episode": 134.0, "batch_reward": 0.9264193956851959, "critic_loss": 0.8726451442092658, "actor_loss": -95.02549621582031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.428379774093628, "step": 134000}
{"episode_reward": 965.4210113897877, "episode": 135.0, "batch_reward": 0.9275860053896904, "critic_loss": 0.8704060814976692, "actor_loss": -95.01084310913086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.13801121711731, "step": 135000}
{"episode_reward": 987.6743802557297, "episode": 136.0, "batch_reward": 0.9267752155065536, "critic_loss": 0.8412771600782871, "actor_loss": -95.15214558410645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 33.04773831367493, "step": 136000}
{"episode_reward": 979.7691440632132, "episode": 137.0, "batch_reward": 0.9259012119174004, "critic_loss": 0.8601264670789242, "actor_loss": -95.0386904296875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.14414954185486, "step": 137000}
{"episode_reward": 974.7304303292138, "episode": 138.0, "batch_reward": 0.9290387875437737, "critic_loss": 0.8603703202456235, "actor_loss": -94.89400326538086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.695327281951904, "step": 138000}
{"episode_reward": 955.9090391934599, "episode": 139.0, "batch_reward": 0.9272151715755462, "critic_loss": 0.8638642021417617, "actor_loss": -94.9243606414795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.87958359718323, "step": 139000}
{"episode_reward": 985.3742047909006, "episode": 140.0, "batch_reward": 0.9284957552552223, "critic_loss": 0.8340974628925324, "actor_loss": -94.89093072509766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.53247117996216, "step": 140000}
{"episode_reward": 950.7465343619375, "episode": 141.0, "batch_reward": 0.9291428786516189, "critic_loss": 0.8271341781318188, "actor_loss": -95.01379902648925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.39554238319397, "step": 141000}
{"episode_reward": 967.5616030562143, "episode": 142.0, "batch_reward": 0.9291727861762047, "critic_loss": 0.8231684441864491, "actor_loss": -95.02018504333496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.486878871917725, "step": 142000}
{"episode_reward": 988.782099006648, "episode": 143.0, "batch_reward": 0.9291477086544037, "critic_loss": 0.8334725909084082, "actor_loss": -95.10800381469727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.20190715789795, "step": 143000}
{"episode_reward": 945.5906973094407, "episode": 144.0, "batch_reward": 0.929917236328125, "critic_loss": 0.8410722761750221, "actor_loss": -95.11806555175781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.275181770324707, "step": 144000}
{"episode_reward": 927.4382316312547, "episode": 145.0, "batch_reward": 0.929170895755291, "critic_loss": 0.848031685307622, "actor_loss": -95.06916200256347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.83431124687195, "step": 145000}
{"episode_reward": 988.6789065960423, "episode": 146.0, "batch_reward": 0.9303098621964455, "critic_loss": 0.8374257759153843, "actor_loss": -95.08393211364746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.04522180557251, "step": 146000}
{"episode_reward": 962.9606043195441, "episode": 147.0, "batch_reward": 0.9291047287583352, "critic_loss": 0.8583526544868946, "actor_loss": -95.15673300170899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.586114406585693, "step": 147000}
{"episode_reward": 930.2232747234342, "episode": 148.0, "batch_reward": 0.9307267679572105, "critic_loss": 0.8162039812505245, "actor_loss": -95.08448513793945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.80970525741577, "step": 148000}
{"episode_reward": 986.9239285619242, "episode": 149.0, "batch_reward": 0.929466978609562, "critic_loss": 0.8413447446227074, "actor_loss": -95.11424070739746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.50523018836975, "step": 149000}
{"episode_reward": 934.3108609345087, "episode": 150.0, "batch_reward": 0.9294685613512993, "critic_loss": 0.8579140099436044, "actor_loss": -95.02530081176758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
