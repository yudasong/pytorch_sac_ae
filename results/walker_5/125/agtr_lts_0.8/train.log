{"episode_reward": 0.0, "episode": 1.0, "duration": 20.688366413116455, "step": 1000}
{"episode_reward": 59.660092495208936, "episode": 2.0, "duration": 1.7998192310333252, "step": 2000}
{"episode_reward": 981.6628711771527, "episode": 3.0, "batch_reward": 0.5493410554835303, "critic_loss": 0.16900273676925637, "actor_loss": -87.32022185705337, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.67680644989014, "step": 3000}
{"episode_reward": 977.6768538707383, "episode": 4.0, "batch_reward": 0.7127410276532173, "critic_loss": 0.15507392137497664, "actor_loss": -91.70543286132812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.101208925247192, "step": 4000}
{"episode_reward": 981.6395160321273, "episode": 5.0, "batch_reward": 0.7746711892485618, "critic_loss": 0.13454633390903473, "actor_loss": -93.34100346374511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097769021987915, "step": 5000}
{"episode_reward": 988.6280159031037, "episode": 6.0, "batch_reward": 0.8105615352988244, "critic_loss": 0.13166761426627635, "actor_loss": -94.05305158996582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10102391242981, "step": 6000}
{"episode_reward": 977.6038378893907, "episode": 7.0, "batch_reward": 0.8288023863434791, "critic_loss": 0.18503662372380494, "actor_loss": -94.37014042663574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.088191270828247, "step": 7000}
{"episode_reward": 921.5283581816124, "episode": 8.0, "batch_reward": 0.845927670776844, "critic_loss": 0.1875851646363735, "actor_loss": -94.7117976989746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.089398622512817, "step": 8000}
{"episode_reward": 944.2953060756889, "episode": 9.0, "batch_reward": 0.8470830046534539, "critic_loss": 0.3110808808282018, "actor_loss": -94.49428649902343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08971929550171, "step": 9000}
{"episode_reward": 851.5335380637354, "episode": 10.0, "batch_reward": 0.8539423201084136, "critic_loss": 0.24436536832153796, "actor_loss": -94.4976662902832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08239769935608, "step": 10000}
{"episode_reward": 913.1672433134121, "episode": 11.0, "batch_reward": 0.8621063664555549, "critic_loss": 0.2510357245504856, "actor_loss": -94.60313877868653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.52758526802063, "step": 11000}
{"episode_reward": 957.7188128167819, "episode": 12.0, "batch_reward": 0.865145799279213, "critic_loss": 0.25774406323581933, "actor_loss": -94.6975905456543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.075198650360107, "step": 12000}
{"episode_reward": 914.2486107185819, "episode": 13.0, "batch_reward": 0.8718874713778496, "critic_loss": 0.239935669451952, "actor_loss": -94.83821551513672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.102558374404907, "step": 13000}
{"episode_reward": 931.3875860753169, "episode": 14.0, "batch_reward": 0.8792249962091446, "critic_loss": 0.24203404527157546, "actor_loss": -95.01252281188965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09819984436035, "step": 14000}
{"episode_reward": 959.9662358377351, "episode": 15.0, "batch_reward": 0.8851471162438392, "critic_loss": 0.24287534967064858, "actor_loss": -95.12543869018555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.101175546646118, "step": 15000}
{"episode_reward": 978.7136325684232, "episode": 16.0, "batch_reward": 0.8886654765605927, "critic_loss": 0.32669705975055696, "actor_loss": -95.18740496826172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097153425216675, "step": 16000}
{"episode_reward": 905.2674595988848, "episode": 17.0, "batch_reward": 0.8847836427092552, "critic_loss": 0.3102830089777708, "actor_loss": -95.02178507995606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087294101715088, "step": 17000}
{"episode_reward": 858.8326587942586, "episode": 18.0, "batch_reward": 0.883998465359211, "critic_loss": 0.4445604385733604, "actor_loss": -94.87924884033202, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09315037727356, "step": 18000}
{"episode_reward": 813.8782385188927, "episode": 19.0, "batch_reward": 0.8858650928735733, "critic_loss": 0.34571407426893713, "actor_loss": -94.89788438415528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.090436458587646, "step": 19000}
{"episode_reward": 967.5253588308615, "episode": 20.0, "batch_reward": 0.8909648472070694, "critic_loss": 0.29485148323327304, "actor_loss": -95.01800132751465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08966875076294, "step": 20000}
{"episode_reward": 981.8332997068285, "episode": 21.0, "batch_reward": 0.8935144230723381, "critic_loss": 0.37202708432078363, "actor_loss": -95.0769453125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.46804642677307, "step": 21000}
{"episode_reward": 928.691051535812, "episode": 22.0, "batch_reward": 0.8972778789997101, "critic_loss": 0.3590419340878725, "actor_loss": -95.08824641418457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08405637741089, "step": 22000}
{"episode_reward": 983.6081264900072, "episode": 23.0, "batch_reward": 0.8982440541386605, "critic_loss": 0.3553724015131593, "actor_loss": -95.12260552978516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098135709762573, "step": 23000}
{"episode_reward": 919.5057298876111, "episode": 24.0, "batch_reward": 0.900723720729351, "critic_loss": 0.3268521375134587, "actor_loss": -95.17737298583984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.102194786071777, "step": 24000}
{"episode_reward": 980.4995290925356, "episode": 25.0, "batch_reward": 0.9007914233207702, "critic_loss": 0.4148196443170309, "actor_loss": -95.16735668945313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093936920166016, "step": 25000}
{"episode_reward": 914.3525862291204, "episode": 26.0, "batch_reward": 0.9037811723947525, "critic_loss": 0.3275431423038244, "actor_loss": -95.23530479431152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08383083343506, "step": 26000}
{"episode_reward": 976.1881309579388, "episode": 27.0, "batch_reward": 0.9077608570456505, "critic_loss": 0.3636173011362553, "actor_loss": -95.33163162231445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092455625534058, "step": 27000}
{"episode_reward": 964.5969636831794, "episode": 28.0, "batch_reward": 0.9096945045590401, "critic_loss": 0.3528436267748475, "actor_loss": -95.40143556213378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077860116958618, "step": 28000}
{"episode_reward": 961.2826551627128, "episode": 29.0, "batch_reward": 0.9107316308617592, "critic_loss": 0.382134145796299, "actor_loss": -95.38727676391602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.076244592666626, "step": 29000}
{"episode_reward": 945.888441993362, "episode": 30.0, "batch_reward": 0.9111193370223045, "critic_loss": 0.3295015357285738, "actor_loss": -95.36317648315429, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077980756759644, "step": 30000}
{"episode_reward": 913.4430209914, "episode": 31.0, "batch_reward": 0.9113490061163902, "critic_loss": 0.3362632431015372, "actor_loss": -95.40199687194824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.50866937637329, "step": 31000}
{"episode_reward": 922.3253662124501, "episode": 32.0, "batch_reward": 0.9131568644046784, "critic_loss": 0.3891225699931383, "actor_loss": -95.37216395568848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093109130859375, "step": 32000}
{"episode_reward": 943.2688358059888, "episode": 33.0, "batch_reward": 0.9137824987769126, "critic_loss": 0.34111852319538594, "actor_loss": -95.45401567077637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09860634803772, "step": 33000}
{"episode_reward": 967.3754679498534, "episode": 34.0, "batch_reward": 0.9153970915675164, "critic_loss": 0.357900208286941, "actor_loss": -95.4602293395996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.089841842651367, "step": 34000}
{"episode_reward": 975.4803841136767, "episode": 35.0, "batch_reward": 0.9160374918580055, "critic_loss": 0.3495690396055579, "actor_loss": -95.56840464782715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097739934921265, "step": 35000}
{"episode_reward": 924.5639745981277, "episode": 36.0, "batch_reward": 0.9164881505966187, "critic_loss": 0.38808147491514683, "actor_loss": -95.49133041381836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.096325874328613, "step": 36000}
{"episode_reward": 957.9389903013706, "episode": 37.0, "batch_reward": 0.916686674952507, "critic_loss": 0.4019767909273505, "actor_loss": -95.55083752441406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.110669136047363, "step": 37000}
{"episode_reward": 958.1112486716233, "episode": 38.0, "batch_reward": 0.9194173777103424, "critic_loss": 0.3527627659589052, "actor_loss": -95.54234999084473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.103055953979492, "step": 38000}
{"episode_reward": 986.1923364491248, "episode": 39.0, "batch_reward": 0.920395240187645, "critic_loss": 0.45803196004778146, "actor_loss": -95.58874591064453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07996702194214, "step": 39000}
{"episode_reward": 901.896213724197, "episode": 40.0, "batch_reward": 0.9200398572683335, "critic_loss": 0.44281148601323367, "actor_loss": -95.58872633361817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10990285873413, "step": 40000}
{"episode_reward": 982.9870553224472, "episode": 41.0, "batch_reward": 0.921092894256115, "critic_loss": 0.5070079865902662, "actor_loss": -95.55880342102051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.52059555053711, "step": 41000}
{"episode_reward": 877.839532771727, "episode": 42.0, "batch_reward": 0.9217381681799889, "critic_loss": 0.4947177954316139, "actor_loss": -95.49073081970215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097063064575195, "step": 42000}
{"episode_reward": 981.0654331250435, "episode": 43.0, "batch_reward": 0.9204168621897697, "critic_loss": 0.48940804629027845, "actor_loss": -95.51072148132324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.086328268051147, "step": 43000}
{"episode_reward": 881.5976812385585, "episode": 44.0, "batch_reward": 0.9210379174947738, "critic_loss": 0.5009250843822957, "actor_loss": -95.49373150634766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085665464401245, "step": 44000}
{"episode_reward": 941.0612406196414, "episode": 45.0, "batch_reward": 0.9212567504048348, "critic_loss": 0.5941511086598039, "actor_loss": -95.49765606689454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.090177059173584, "step": 45000}
{"episode_reward": 929.2123866672205, "episode": 46.0, "batch_reward": 0.9215439260601997, "critic_loss": 0.5373413354605436, "actor_loss": -95.48929679870605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.076353073120117, "step": 46000}
{"episode_reward": 952.2739140415096, "episode": 47.0, "batch_reward": 0.9231705452799797, "critic_loss": 0.539175445869565, "actor_loss": -95.58058506774903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085325956344604, "step": 47000}
{"episode_reward": 978.4384182032588, "episode": 48.0, "batch_reward": 0.9229806452989578, "critic_loss": 0.5229429176747799, "actor_loss": -95.57992767333984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08996272087097, "step": 48000}
{"episode_reward": 904.6555430958839, "episode": 49.0, "batch_reward": 0.9241802471280098, "critic_loss": 0.5596335394233465, "actor_loss": -95.66284928894044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.083804845809937, "step": 49000}
{"episode_reward": 945.1363886398786, "episode": 50.0, "batch_reward": 0.9243636108040809, "critic_loss": 0.5270685183480383, "actor_loss": -95.57186860656738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10014295578003, "step": 50000}
{"episode_reward": 984.8289520923092, "episode": 51.0, "batch_reward": 0.9251691268086434, "critic_loss": 0.5219115641862154, "actor_loss": -95.62606558227539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.56771659851074, "step": 51000}
{"episode_reward": 974.1494215767859, "episode": 52.0, "batch_reward": 0.9259380048513413, "critic_loss": 0.5311947621405124, "actor_loss": -95.64014601135254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.088147163391113, "step": 52000}
{"episode_reward": 958.6885835169677, "episode": 53.0, "batch_reward": 0.9269512779116631, "critic_loss": 0.5013518297225237, "actor_loss": -95.70136093139648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08872151374817, "step": 53000}
{"episode_reward": 963.536023026396, "episode": 54.0, "batch_reward": 0.9260823824405671, "critic_loss": 0.5246297037601471, "actor_loss": -95.66082991027832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.084186792373657, "step": 54000}
{"episode_reward": 926.2008601183297, "episode": 55.0, "batch_reward": 0.9271964368224144, "critic_loss": 0.5342949833720922, "actor_loss": -95.7721118927002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085471630096436, "step": 55000}
{"episode_reward": 968.2586098845936, "episode": 56.0, "batch_reward": 0.9289945878386497, "critic_loss": 0.48254519218206404, "actor_loss": -95.79438279724121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100310802459717, "step": 56000}
{"episode_reward": 983.9207284195119, "episode": 57.0, "batch_reward": 0.9289215530157089, "critic_loss": 0.5052550282627344, "actor_loss": -95.73779508972169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09591507911682, "step": 57000}
{"episode_reward": 916.9009802895926, "episode": 58.0, "batch_reward": 0.929418698310852, "critic_loss": 0.5487527511566878, "actor_loss": -95.7570835723877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08466672897339, "step": 58000}
{"episode_reward": 982.5590263806666, "episode": 59.0, "batch_reward": 0.9308230372071267, "critic_loss": 0.4545125363022089, "actor_loss": -95.84315950012207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.102417707443237, "step": 59000}
{"episode_reward": 955.1953746952199, "episode": 60.0, "batch_reward": 0.9314326247572899, "critic_loss": 0.46538010918349026, "actor_loss": -95.89710861206055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.112394332885742, "step": 60000}
{"episode_reward": 966.0187408150871, "episode": 61.0, "batch_reward": 0.9297763386964798, "critic_loss": 0.48247973397374155, "actor_loss": -95.76784121704101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.591901540756226, "step": 61000}
{"episode_reward": 915.6551859077329, "episode": 62.0, "batch_reward": 0.9299935173392296, "critic_loss": 0.46376479452103375, "actor_loss": -95.84370126342773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.122368097305298, "step": 62000}
{"episode_reward": 970.0443365243763, "episode": 63.0, "batch_reward": 0.9292505725622177, "critic_loss": 0.48087387555092576, "actor_loss": -95.76105778503418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12343454360962, "step": 63000}
{"episode_reward": 889.3767567094542, "episode": 64.0, "batch_reward": 0.9303304867744446, "critic_loss": 0.4920534065067768, "actor_loss": -95.83771221923828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11678671836853, "step": 64000}
{"episode_reward": 987.8148786212193, "episode": 65.0, "batch_reward": 0.9326062475442887, "critic_loss": 0.4372399979233742, "actor_loss": -95.88556118774414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.115005254745483, "step": 65000}
{"episode_reward": 982.1164421249823, "episode": 66.0, "batch_reward": 0.9307748034000397, "critic_loss": 0.47052058272063735, "actor_loss": -95.82356303405761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.106237411499023, "step": 66000}
{"episode_reward": 907.1902654784425, "episode": 67.0, "batch_reward": 0.9296860795617103, "critic_loss": 0.4643744542747736, "actor_loss": -95.81028968811034, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092217206954956, "step": 67000}
{"episode_reward": 907.8679731327647, "episode": 68.0, "batch_reward": 0.9311764219403267, "critic_loss": 0.4121530934125185, "actor_loss": -95.82158155822754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12321162223816, "step": 68000}
{"episode_reward": 981.1348314398147, "episode": 69.0, "batch_reward": 0.932028805077076, "critic_loss": 0.4272194347307086, "actor_loss": -95.91385171508789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.119920253753662, "step": 69000}
{"episode_reward": 981.9014182217101, "episode": 70.0, "batch_reward": 0.9331750335097313, "critic_loss": 0.4172081781104207, "actor_loss": -95.91953742980957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108495235443115, "step": 70000}
{"episode_reward": 951.3375171715585, "episode": 71.0, "batch_reward": 0.932862967312336, "critic_loss": 0.46849074053019285, "actor_loss": -95.95713948059083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.569151639938354, "step": 71000}
{"episode_reward": 962.9897645792324, "episode": 72.0, "batch_reward": 0.9338726291060447, "critic_loss": 0.463833925999701, "actor_loss": -95.98189440917969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10891318321228, "step": 72000}
{"episode_reward": 981.6034410165151, "episode": 73.0, "batch_reward": 0.934013275206089, "critic_loss": 0.4362216527760029, "actor_loss": -95.96405458068848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11291813850403, "step": 73000}
{"episode_reward": 967.5228315735893, "episode": 74.0, "batch_reward": 0.9352879796624184, "critic_loss": 0.4145956516191363, "actor_loss": -96.06530946350098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10157585144043, "step": 74000}
{"episode_reward": 936.068538391373, "episode": 75.0, "batch_reward": 0.9346436275243759, "critic_loss": 0.4154237398803234, "actor_loss": -95.9881184387207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13657808303833, "step": 75000}
{"episode_reward": 969.9831653532254, "episode": 76.0, "batch_reward": 0.9346160512566567, "critic_loss": 0.43570227394998073, "actor_loss": -95.99371424865723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1161892414093, "step": 76000}
{"episode_reward": 957.6928471574907, "episode": 77.0, "batch_reward": 0.935274147450924, "critic_loss": 0.4363722194507718, "actor_loss": -95.98326181030274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.119239568710327, "step": 77000}
{"episode_reward": 981.002264998036, "episode": 78.0, "batch_reward": 0.9360858795642852, "critic_loss": 0.3950260936841369, "actor_loss": -96.0331406402588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09561586380005, "step": 78000}
{"episode_reward": 932.74219592166, "episode": 79.0, "batch_reward": 0.9353275873661041, "critic_loss": 0.41030282255262135, "actor_loss": -95.97136660766601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12579870223999, "step": 79000}
{"episode_reward": 935.355263446329, "episode": 80.0, "batch_reward": 0.9360327788591385, "critic_loss": 0.4051255304142833, "actor_loss": -96.00806895446777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.128887176513672, "step": 80000}
{"episode_reward": 976.3103974279716, "episode": 81.0, "batch_reward": 0.9361867921352387, "critic_loss": 0.4399663294479251, "actor_loss": -96.05561563110352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.5501594543457, "step": 81000}
{"episode_reward": 937.064216148098, "episode": 82.0, "batch_reward": 0.9365542896986008, "critic_loss": 0.438329917088151, "actor_loss": -96.05247337341308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097749710083008, "step": 82000}
{"episode_reward": 953.8627408030935, "episode": 83.0, "batch_reward": 0.936480809032917, "critic_loss": 0.46762563590705397, "actor_loss": -96.06746005249023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.105793237686157, "step": 83000}
{"episode_reward": 913.3254935943473, "episode": 84.0, "batch_reward": 0.9371848940253258, "critic_loss": 0.4656798775717616, "actor_loss": -96.15287045288086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100104570388794, "step": 84000}
{"episode_reward": 983.3954975062413, "episode": 85.0, "batch_reward": 0.9347442116737366, "critic_loss": 0.4661890599280596, "actor_loss": -96.02170565795899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092622756958008, "step": 85000}
{"episode_reward": 862.1251806573483, "episode": 86.0, "batch_reward": 0.9352627583742141, "critic_loss": 0.4108061746954918, "actor_loss": -95.9937843170166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.095335245132446, "step": 86000}
{"episode_reward": 931.6339481201229, "episode": 87.0, "batch_reward": 0.9355433708429337, "critic_loss": 0.4349600575119257, "actor_loss": -96.05393231201172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.088922262191772, "step": 87000}
{"episode_reward": 965.6540380152951, "episode": 88.0, "batch_reward": 0.9360497451424599, "critic_loss": 0.46657901909947397, "actor_loss": -96.03054988098144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11943769454956, "step": 88000}
{"episode_reward": 907.5350807817399, "episode": 89.0, "batch_reward": 0.9350655706524849, "critic_loss": 0.48557563401013615, "actor_loss": -96.03541441345214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.117652654647827, "step": 89000}
{"episode_reward": 976.6086559130666, "episode": 90.0, "batch_reward": 0.936191281735897, "critic_loss": 0.45789182420819996, "actor_loss": -96.09938162231445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.119105577468872, "step": 90000}
{"episode_reward": 901.630884374858, "episode": 91.0, "batch_reward": 0.9357044333815575, "critic_loss": 0.46362981521338226, "actor_loss": -96.01707173156738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.927680253982544, "step": 91000}
{"episode_reward": 969.1596334203664, "episode": 92.0, "batch_reward": 0.9368838163018227, "critic_loss": 0.4938401530459523, "actor_loss": -96.0902067565918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.38946771621704, "step": 92000}
{"episode_reward": 966.5294023087305, "episode": 93.0, "batch_reward": 0.9352913905382156, "critic_loss": 0.4816505149230361, "actor_loss": -96.03778535461426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.076375246047974, "step": 93000}
{"episode_reward": 974.9694269058317, "episode": 94.0, "batch_reward": 0.9350752282738686, "critic_loss": 0.5574844532310963, "actor_loss": -96.00116827392579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07797408103943, "step": 94000}
{"episode_reward": 742.3296974165463, "episode": 95.0, "batch_reward": 0.9339379552006721, "critic_loss": 0.5575944398567081, "actor_loss": -95.9740594177246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10357904434204, "step": 95000}
{"episode_reward": 948.0742419259068, "episode": 96.0, "batch_reward": 0.9349165949225425, "critic_loss": 0.5868069099485874, "actor_loss": -96.01021047973633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108136415481567, "step": 96000}
{"episode_reward": 878.069550725937, "episode": 97.0, "batch_reward": 0.9338898015022278, "critic_loss": 0.6444353167489171, "actor_loss": -95.97030996704102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097697019577026, "step": 97000}
{"episode_reward": 824.5376663530787, "episode": 98.0, "batch_reward": 0.9330151722431183, "critic_loss": 0.5908058906048537, "actor_loss": -95.91470834350586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.103418588638306, "step": 98000}
{"episode_reward": 876.0398612468413, "episode": 99.0, "batch_reward": 0.9317332907915116, "critic_loss": 0.6705304454416037, "actor_loss": -95.83870922851563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10469126701355, "step": 99000}
{"episode_reward": 963.1058699994543, "episode": 100.0, "batch_reward": 0.9344589375257492, "critic_loss": 0.6680756592154503, "actor_loss": -95.99708428955078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10003089904785, "step": 100000}
{"episode_reward": 967.589562408204, "episode": 101.0, "batch_reward": 0.9339749395251274, "critic_loss": 0.7152403855100274, "actor_loss": -95.9638624572754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.60508847236633, "step": 101000}
{"episode_reward": 957.6168847840643, "episode": 102.0, "batch_reward": 0.934174666762352, "critic_loss": 0.6357402428537607, "actor_loss": -95.93515719604493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.119811534881592, "step": 102000}
{"episode_reward": 979.3659564266685, "episode": 103.0, "batch_reward": 0.9333559875488281, "critic_loss": 0.7422758764773607, "actor_loss": -95.9036907043457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1285719871521, "step": 103000}
{"episode_reward": 890.3822064738492, "episode": 104.0, "batch_reward": 0.9342856935858727, "critic_loss": 0.6828238574489951, "actor_loss": -95.94961672973633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.110107421875, "step": 104000}
{"episode_reward": 935.2410954198048, "episode": 105.0, "batch_reward": 0.9343501608967781, "critic_loss": 0.7427797446399927, "actor_loss": -95.99713151550293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100561380386353, "step": 105000}
{"episode_reward": 967.3243262473238, "episode": 106.0, "batch_reward": 0.9341480041742325, "critic_loss": 0.8030424091517925, "actor_loss": -95.92724551391602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097548246383667, "step": 106000}
{"episode_reward": 818.8315762444977, "episode": 107.0, "batch_reward": 0.9324831573963165, "critic_loss": 0.7778734736591577, "actor_loss": -95.82898014831542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10717225074768, "step": 107000}
{"episode_reward": 934.6593687534647, "episode": 108.0, "batch_reward": 0.9339080567359924, "critic_loss": 0.7856968565881253, "actor_loss": -95.91128843688965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.107365608215332, "step": 108000}
{"episode_reward": 908.2866875564717, "episode": 109.0, "batch_reward": 0.9328379745483398, "critic_loss": 0.7763201254606247, "actor_loss": -95.9468816986084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094136238098145, "step": 109000}
{"episode_reward": 943.159806797557, "episode": 110.0, "batch_reward": 0.9316628450155258, "critic_loss": 0.7645509970039129, "actor_loss": -95.8831368713379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093132495880127, "step": 110000}
{"episode_reward": 841.7677572197044, "episode": 111.0, "batch_reward": 0.931650082886219, "critic_loss": 0.8201744295433163, "actor_loss": -95.8360403289795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.55445647239685, "step": 111000}
{"episode_reward": 912.5390613791241, "episode": 112.0, "batch_reward": 0.9314005224704742, "critic_loss": 0.7924046237915754, "actor_loss": -95.77825080871582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11255192756653, "step": 112000}
{"episode_reward": 962.122239085698, "episode": 113.0, "batch_reward": 0.9325448147058487, "critic_loss": 0.7805709717571735, "actor_loss": -95.85354588317871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11841082572937, "step": 113000}
{"episode_reward": 961.437363474123, "episode": 114.0, "batch_reward": 0.9323674564361573, "critic_loss": 0.8019951599687338, "actor_loss": -95.87301594543457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100411891937256, "step": 114000}
{"episode_reward": 959.0157370035955, "episode": 115.0, "batch_reward": 0.9330439001321793, "critic_loss": 0.8310297976583242, "actor_loss": -95.78312037658691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097139358520508, "step": 115000}
{"episode_reward": 920.6663366555308, "episode": 116.0, "batch_reward": 0.9328425028920173, "critic_loss": 0.8405611875057221, "actor_loss": -95.80866857910156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12225866317749, "step": 116000}
{"episode_reward": 959.3730581439796, "episode": 117.0, "batch_reward": 0.9323168467283249, "critic_loss": 0.909453916490078, "actor_loss": -95.77120422363281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.102787256240845, "step": 117000}
{"episode_reward": 860.3225425937912, "episode": 118.0, "batch_reward": 0.9320539490580558, "critic_loss": 0.8569148826897144, "actor_loss": -95.79683981323242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108126401901245, "step": 118000}
{"episode_reward": 981.5653433160953, "episode": 119.0, "batch_reward": 0.9327204401493072, "critic_loss": 0.8849214700907468, "actor_loss": -95.82869366455078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09868860244751, "step": 119000}
{"episode_reward": 945.2557176359576, "episode": 120.0, "batch_reward": 0.9321324276924133, "critic_loss": 0.8895196155905724, "actor_loss": -95.74691917419433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.102272987365723, "step": 120000}
{"episode_reward": 917.3990725589935, "episode": 121.0, "batch_reward": 0.9328052466511726, "critic_loss": 0.8684451815932989, "actor_loss": -95.74580187988282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.54637408256531, "step": 121000}
{"episode_reward": 956.2728621948592, "episode": 122.0, "batch_reward": 0.9314855064749717, "critic_loss": 0.9445292230546475, "actor_loss": -95.68807852172851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094077110290527, "step": 122000}
{"episode_reward": 916.2961214484242, "episode": 123.0, "batch_reward": 0.9330666958093643, "critic_loss": 0.963812090843916, "actor_loss": -95.68840594482423, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09333109855652, "step": 123000}
{"episode_reward": 973.4745725750574, "episode": 124.0, "batch_reward": 0.932247307896614, "critic_loss": 0.9051015665829182, "actor_loss": -95.67289559936523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.106409788131714, "step": 124000}
{"episode_reward": 969.8430276233065, "episode": 125.0, "batch_reward": 0.9334529662728309, "critic_loss": 0.8512681206911802, "actor_loss": -95.76693646240234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097059965133667, "step": 125000}
{"episode_reward": 968.7323246709349, "episode": 126.0, "batch_reward": 0.933443407356739, "critic_loss": 0.8955464717596769, "actor_loss": -95.74079995727539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10152792930603, "step": 126000}
{"episode_reward": 970.537357826963, "episode": 127.0, "batch_reward": 0.9336778021454811, "critic_loss": 0.8756112400740385, "actor_loss": -95.7909962463379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108105897903442, "step": 127000}
{"episode_reward": 965.6289711644553, "episode": 128.0, "batch_reward": 0.9330948561429977, "critic_loss": 0.8897724843025208, "actor_loss": -95.85833081054687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.123605251312256, "step": 128000}
{"episode_reward": 960.056593752828, "episode": 129.0, "batch_reward": 0.9340953685045242, "critic_loss": 0.8561530927121639, "actor_loss": -95.84761274719239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1155366897583, "step": 129000}
{"episode_reward": 971.4466630962183, "episode": 130.0, "batch_reward": 0.934440612256527, "critic_loss": 0.8735940817296505, "actor_loss": -95.86602803039551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.089502811431885, "step": 130000}
{"episode_reward": 981.7094452780697, "episode": 131.0, "batch_reward": 0.9355953746438026, "critic_loss": 0.8726624860614538, "actor_loss": -95.86891069030762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.537657737731934, "step": 131000}
{"episode_reward": 971.3017441963048, "episode": 132.0, "batch_reward": 0.9355572014451027, "critic_loss": 0.8317254623472691, "actor_loss": -95.87914233398438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100993394851685, "step": 132000}
{"episode_reward": 981.0350382308013, "episode": 133.0, "batch_reward": 0.9350389977693557, "critic_loss": 0.9089551985561848, "actor_loss": -95.85313693237305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093989372253418, "step": 133000}
{"episode_reward": 847.7355116872839, "episode": 134.0, "batch_reward": 0.9357855536937714, "critic_loss": 0.9270953103750944, "actor_loss": -95.91033638000488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.41098952293396, "step": 134000}
{"episode_reward": 982.1872112283556, "episode": 135.0, "batch_reward": 0.9366660577654838, "critic_loss": 0.8516245606690646, "actor_loss": -95.9225744934082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09589958190918, "step": 135000}
{"episode_reward": 989.3447708247896, "episode": 136.0, "batch_reward": 0.9361125787496567, "critic_loss": 0.8662836295217275, "actor_loss": -96.00589193725585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07407569885254, "step": 136000}
{"episode_reward": 984.9975140388317, "episode": 137.0, "batch_reward": 0.9347885788679123, "critic_loss": 0.9851904014497995, "actor_loss": -95.86657466125489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.076344966888428, "step": 137000}
{"episode_reward": 953.5203502215528, "episode": 138.0, "batch_reward": 0.9366611252427102, "critic_loss": 0.9369436533004045, "actor_loss": -95.84263108825684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.096275568008423, "step": 138000}
{"episode_reward": 954.7423034445776, "episode": 139.0, "batch_reward": 0.9353342007398605, "critic_loss": 0.9146698647588491, "actor_loss": -95.85388040161133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.105644702911377, "step": 139000}
{"episode_reward": 969.2227286437407, "episode": 140.0, "batch_reward": 0.9369961659908295, "critic_loss": 0.9014124675393105, "actor_loss": -95.86498951721191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10843062400818, "step": 140000}
{"episode_reward": 964.3406144033911, "episode": 141.0, "batch_reward": 0.9372020751833916, "critic_loss": 0.8833411112874746, "actor_loss": -95.91742544555665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.5939621925354, "step": 141000}
{"episode_reward": 977.4663640158208, "episode": 142.0, "batch_reward": 0.937277012526989, "critic_loss": 0.8796379169523716, "actor_loss": -95.91543133544921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109140634536743, "step": 142000}
{"episode_reward": 985.0810707064757, "episode": 143.0, "batch_reward": 0.937688248038292, "critic_loss": 0.9551452428847551, "actor_loss": -95.96424024963379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109903812408447, "step": 143000}
{"episode_reward": 962.4423559816942, "episode": 144.0, "batch_reward": 0.9381920573711395, "critic_loss": 0.9423472295701504, "actor_loss": -95.93329780578614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09863543510437, "step": 144000}
{"episode_reward": 932.2300412399317, "episode": 145.0, "batch_reward": 0.9378202495574951, "critic_loss": 0.9456163585931062, "actor_loss": -95.94813792419434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.113563537597656, "step": 145000}
{"episode_reward": 977.7231000014875, "episode": 146.0, "batch_reward": 0.9377626699805259, "critic_loss": 0.9187652525156736, "actor_loss": -95.94307073974609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09785771369934, "step": 146000}
{"episode_reward": 973.9326034870082, "episode": 147.0, "batch_reward": 0.9383666123747826, "critic_loss": 0.98346458157897, "actor_loss": -95.98200805664062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.105647325515747, "step": 147000}
{"episode_reward": 959.1324889767322, "episode": 148.0, "batch_reward": 0.9391129443049431, "critic_loss": 0.9872195254862308, "actor_loss": -95.95468794250488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.111570358276367, "step": 148000}
{"episode_reward": 979.4216524293623, "episode": 149.0, "batch_reward": 0.9382517632842063, "critic_loss": 0.9232094307541847, "actor_loss": -95.99780755615234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1003999710083, "step": 149000}
{"episode_reward": 932.7089792090097, "episode": 150.0, "batch_reward": 0.9376143009066582, "critic_loss": 0.9227349992394447, "actor_loss": -95.95476379394532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
