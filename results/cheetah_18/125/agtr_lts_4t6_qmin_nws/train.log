{"episode_reward": 0.0, "episode": 1.0, "duration": 13.929678678512573, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.2631492614746094, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.22218360091774175, "critic_loss": 0.0500114994088176, "actor_loss": -27.14740151692243, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 77.2681131362915, "step": 3000}
{"episode_reward": 98.71664356671889, "episode": 4.0, "batch_reward": 0.17135841113328934, "critic_loss": 0.06092537476122379, "actor_loss": -22.16943621945381, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.18173837661743, "step": 4000}
{"episode_reward": 65.64379470556658, "episode": 5.0, "batch_reward": 0.14117752783745527, "critic_loss": 0.05385555685684085, "actor_loss": -23.833330515399574, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.87808656692505, "step": 5000}
{"episode_reward": 35.02693662941661, "episode": 6.0, "batch_reward": 0.12434489620476961, "critic_loss": 0.07165126816555857, "actor_loss": -21.664644515275956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.176194667816162, "step": 6000}
{"episode_reward": 81.76639346249549, "episode": 7.0, "batch_reward": 0.12034719222038984, "critic_loss": 0.0906364248842001, "actor_loss": -20.51491234970093, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.358837366104126, "step": 7000}
{"episode_reward": 99.83072252775685, "episode": 8.0, "batch_reward": 0.1224744517505169, "critic_loss": 0.09876566153019667, "actor_loss": -20.857698814123868, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.003413200378418, "step": 8000}
{"episode_reward": 135.7295899173508, "episode": 9.0, "batch_reward": 0.12297792940586805, "critic_loss": 0.1011988129094243, "actor_loss": -18.699634634666143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.147221565246582, "step": 9000}
{"episode_reward": 98.47068121941464, "episode": 10.0, "batch_reward": 0.11757399233430624, "critic_loss": 0.10842858728021383, "actor_loss": -18.812262971043587, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.408713579177856, "step": 10000}
{"episode_reward": 49.82575569451144, "episode": 11.0, "batch_reward": 0.11111000190675259, "critic_loss": 0.13092134808376432, "actor_loss": -17.386040780514477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.98034620285034, "step": 11000}
{"episode_reward": 44.813418857538714, "episode": 12.0, "batch_reward": 0.1079341667816043, "critic_loss": 0.1530173475407064, "actor_loss": -16.88960791990906, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.65574288368225, "step": 12000}
{"episode_reward": 98.33173309161985, "episode": 13.0, "batch_reward": 0.10615524528175592, "critic_loss": 0.14810051466152072, "actor_loss": -16.42073394341767, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.765132665634155, "step": 13000}
{"episode_reward": 78.8983155077806, "episode": 14.0, "batch_reward": 0.10418572683632374, "critic_loss": 0.15133924486488104, "actor_loss": -17.588534482359886, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.277295112609863, "step": 14000}
{"episode_reward": 78.78066108646635, "episode": 15.0, "batch_reward": 0.10211506287008523, "critic_loss": 0.14942869405075906, "actor_loss": -15.103164021402597, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.989636659622192, "step": 15000}
{"episode_reward": 70.49384963831946, "episode": 16.0, "batch_reward": 0.09780998699739575, "critic_loss": 0.15007584390044212, "actor_loss": -14.363391990348697, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.006162881851196, "step": 16000}
{"episode_reward": 33.28103091236976, "episode": 17.0, "batch_reward": 0.09532358144968749, "critic_loss": 0.1643412053361535, "actor_loss": -14.943319971129299, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.234334707260132, "step": 17000}
{"episode_reward": 51.589774455560885, "episode": 18.0, "batch_reward": 0.09348768562823534, "critic_loss": 0.13351948368921876, "actor_loss": -14.99016645014286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.25279712677002, "step": 18000}
{"episode_reward": 120.01212657611633, "episode": 19.0, "batch_reward": 0.09285910292714834, "critic_loss": 0.15179645166546107, "actor_loss": -14.689522047579288, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.001035690307617, "step": 19000}
{"episode_reward": 22.134496556696178, "episode": 20.0, "batch_reward": 0.09138476773351431, "critic_loss": 0.1412714373022318, "actor_loss": -13.930542310357094, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.787777185440063, "step": 20000}
{"episode_reward": 92.12022857344365, "episode": 21.0, "batch_reward": 0.09151686137542128, "critic_loss": 0.16624451887607575, "actor_loss": -13.48283717417717, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.56255650520325, "step": 21000}
{"episode_reward": 59.52115640635393, "episode": 22.0, "batch_reward": 0.09070038050413132, "critic_loss": 0.19946217407286168, "actor_loss": -14.228856132745744, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.94779872894287, "step": 22000}
{"episode_reward": 114.63443192279746, "episode": 23.0, "batch_reward": 0.09077263682708145, "critic_loss": 0.19626395208388567, "actor_loss": -14.637992171645164, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.892151832580566, "step": 23000}
{"episode_reward": 56.85837888512587, "episode": 24.0, "batch_reward": 0.09234997241944075, "critic_loss": 0.22567331889271736, "actor_loss": -14.035041661024094, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.223819494247437, "step": 24000}
{"episode_reward": 191.8036348792332, "episode": 25.0, "batch_reward": 0.09541613498330116, "critic_loss": 0.2245294456332922, "actor_loss": -15.062975497722626, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.904340267181396, "step": 25000}
{"episode_reward": 135.08052166984473, "episode": 26.0, "batch_reward": 0.09679957658424973, "critic_loss": 0.22023845893144608, "actor_loss": -15.399242478847503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.113982915878296, "step": 26000}
{"episode_reward": 206.40520224128105, "episode": 27.0, "batch_reward": 0.1024555815756321, "critic_loss": 0.21752943185716866, "actor_loss": -15.948905615806579, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.398931980133057, "step": 27000}
{"episode_reward": 276.48842928122775, "episode": 28.0, "batch_reward": 0.1076981672719121, "critic_loss": 0.21174432725459338, "actor_loss": -16.64476023674011, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.757278442382812, "step": 28000}
{"episode_reward": 168.77303370975557, "episode": 29.0, "batch_reward": 0.1098211537078023, "critic_loss": 0.2113974539861083, "actor_loss": -15.859009427070617, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.14210605621338, "step": 29000}
{"episode_reward": 112.15160283081032, "episode": 30.0, "batch_reward": 0.10773006530851126, "critic_loss": 0.19756548193097115, "actor_loss": -15.888489327907562, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.68081521987915, "step": 30000}
{"episode_reward": 44.75986564678786, "episode": 31.0, "batch_reward": 0.10818834786117076, "critic_loss": 0.20238032036274672, "actor_loss": -15.42940990447998, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.50816774368286, "step": 31000}
{"episode_reward": 156.8653053127914, "episode": 32.0, "batch_reward": 0.1077989736199379, "critic_loss": 0.20472514476627113, "actor_loss": -15.60536778640747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.81279444694519, "step": 32000}
{"episode_reward": 60.09333726510669, "episode": 33.0, "batch_reward": 0.10893507158756256, "critic_loss": 0.21926901400834323, "actor_loss": -15.651573687553405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.08829092979431, "step": 33000}
{"episode_reward": 211.03242767037787, "episode": 34.0, "batch_reward": 0.11226420164108276, "critic_loss": 0.26330347445607183, "actor_loss": -16.789333107948302, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.98547887802124, "step": 34000}
{"episode_reward": 317.9072673393975, "episode": 35.0, "batch_reward": 0.11845902007818222, "critic_loss": 0.2768989985436201, "actor_loss": -16.596606657981873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.903886079788208, "step": 35000}
{"episode_reward": 248.20625021197316, "episode": 36.0, "batch_reward": 0.12151455692201853, "critic_loss": 0.2656642931252718, "actor_loss": -17.738034938812255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.27669334411621, "step": 36000}
{"episode_reward": 241.83011996788412, "episode": 37.0, "batch_reward": 0.12371205718815327, "critic_loss": 0.2758005097657442, "actor_loss": -17.692288018226623, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.49220585823059, "step": 37000}
{"episode_reward": 162.77595545239845, "episode": 38.0, "batch_reward": 0.12772812786698343, "critic_loss": 0.2805705660432577, "actor_loss": -17.682510442733765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.254088878631592, "step": 38000}
{"episode_reward": 413.6411881122266, "episode": 39.0, "batch_reward": 0.1335995663627982, "critic_loss": 0.283039138674736, "actor_loss": -17.631436542510986, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.399546146392822, "step": 39000}
{"episode_reward": 218.85676005852508, "episode": 40.0, "batch_reward": 0.1370362831503153, "critic_loss": 0.2756424283310771, "actor_loss": -18.25977645111084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.955475330352783, "step": 40000}
{"episode_reward": 311.1698659166092, "episode": 41.0, "batch_reward": 0.13909719236940146, "critic_loss": 0.27589586659520865, "actor_loss": -18.298725326538086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.64076256752014, "step": 41000}
{"episode_reward": 96.26496313585878, "episode": 42.0, "batch_reward": 0.1388566667288542, "critic_loss": 0.3161413748264313, "actor_loss": -18.60216321182251, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.29263210296631, "step": 42000}
{"episode_reward": 185.2898820298134, "episode": 43.0, "batch_reward": 0.1400827704593539, "critic_loss": 0.3164557569772005, "actor_loss": -18.68675422477722, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.318597555160522, "step": 43000}
{"episode_reward": 155.36782820736167, "episode": 44.0, "batch_reward": 0.13996033386141063, "critic_loss": 0.303156735688448, "actor_loss": -18.887056802749633, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.001224279403687, "step": 44000}
{"episode_reward": 145.55244586439116, "episode": 45.0, "batch_reward": 0.14175348251312972, "critic_loss": 0.33352087849378587, "actor_loss": -18.49828767967224, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.308212280273438, "step": 45000}
{"episode_reward": 297.51495171242476, "episode": 46.0, "batch_reward": 0.14395870223641397, "critic_loss": 0.3334672923758626, "actor_loss": -19.273652925491334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.10784912109375, "step": 46000}
{"episode_reward": 339.9527457863846, "episode": 47.0, "batch_reward": 0.1474929359331727, "critic_loss": 0.30140423564612867, "actor_loss": -19.381090509414673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.549513578414917, "step": 47000}
{"episode_reward": 114.11350283061026, "episode": 48.0, "batch_reward": 0.14844788235425949, "critic_loss": 0.32257338146865366, "actor_loss": -19.80419938659668, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.071868419647217, "step": 48000}
{"episode_reward": 336.7701377940636, "episode": 49.0, "batch_reward": 0.15048933819681407, "critic_loss": 0.32128008437901734, "actor_loss": -19.55957806587219, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.3139066696167, "step": 49000}
{"episode_reward": 264.33715372673333, "episode": 50.0, "batch_reward": 0.15254672031849623, "critic_loss": 0.33085442845523355, "actor_loss": -20.156328853607178, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.061465978622437, "step": 50000}
{"episode_reward": 251.0930696626171, "episode": 51.0, "batch_reward": 0.157109410636127, "critic_loss": 0.3513449914455414, "actor_loss": -20.843827733993532, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.22244477272034, "step": 51000}
{"episode_reward": 421.28880204367005, "episode": 52.0, "batch_reward": 0.16150934345275164, "critic_loss": 0.3553118963092566, "actor_loss": -20.63511491775513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.095781564712524, "step": 52000}
{"episode_reward": 284.114413473742, "episode": 53.0, "batch_reward": 0.1622581512928009, "critic_loss": 0.360786203853786, "actor_loss": -21.141765056610108, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.014775276184082, "step": 53000}
{"episode_reward": 130.1751332969168, "episode": 54.0, "batch_reward": 0.16126965402066706, "critic_loss": 0.3737269570231438, "actor_loss": -20.771231407165526, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.326228857040405, "step": 54000}
{"episode_reward": 141.06445796780898, "episode": 55.0, "batch_reward": 0.16161150250583886, "critic_loss": 0.3959727715700865, "actor_loss": -21.07252018547058, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.343600273132324, "step": 55000}
{"episode_reward": 125.27310790978532, "episode": 56.0, "batch_reward": 0.16006392707675696, "critic_loss": 0.38520206221938136, "actor_loss": -20.603425157546997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.695895433425903, "step": 56000}
{"episode_reward": 208.61096753853684, "episode": 57.0, "batch_reward": 0.16332678338885306, "critic_loss": 0.40391426625847815, "actor_loss": -21.275490947723387, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.036305904388428, "step": 57000}
{"episode_reward": 290.31078779995653, "episode": 58.0, "batch_reward": 0.16589357260614634, "critic_loss": 0.4147746054828167, "actor_loss": -21.65570373725891, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.445520877838135, "step": 58000}
{"episode_reward": 441.96416515573986, "episode": 59.0, "batch_reward": 0.17088727451860905, "critic_loss": 0.4481811770796776, "actor_loss": -22.107714698791504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.58388662338257, "step": 59000}
{"episode_reward": 459.58022838349757, "episode": 60.0, "batch_reward": 0.17428079932928087, "critic_loss": 0.4492217460423708, "actor_loss": -22.174805173873903, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.19316577911377, "step": 60000}
{"episode_reward": 232.41940840605216, "episode": 61.0, "batch_reward": 0.17653994864225386, "critic_loss": 0.5332041563540697, "actor_loss": -22.632736698150634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.690417528152466, "step": 61000}
{"episode_reward": 444.95840790344533, "episode": 62.0, "batch_reward": 0.17841024552285673, "critic_loss": 0.519940420627594, "actor_loss": -22.9854379196167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.397919416427612, "step": 62000}
{"episode_reward": 118.892463022236, "episode": 63.0, "batch_reward": 0.17902199034392835, "critic_loss": 0.49539175829291343, "actor_loss": -23.1623826713562, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.01915669441223, "step": 63000}
{"episode_reward": 396.5138067341065, "episode": 64.0, "batch_reward": 0.18371075968444348, "critic_loss": 0.5066032885909081, "actor_loss": -23.517575954437255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.100021839141846, "step": 64000}
{"episode_reward": 465.30745530388396, "episode": 65.0, "batch_reward": 0.18647890862822533, "critic_loss": 0.4688833228945732, "actor_loss": -23.963327919006346, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.363369703292847, "step": 65000}
{"episode_reward": 252.9818231761214, "episode": 66.0, "batch_reward": 0.18923289355635642, "critic_loss": 0.4419428177177906, "actor_loss": -23.911964365005492, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.31060242652893, "step": 66000}
{"episode_reward": 464.3895929264199, "episode": 67.0, "batch_reward": 0.19391950690746307, "critic_loss": 0.49520570869743824, "actor_loss": -24.096388889312745, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.443841218948364, "step": 67000}
{"episode_reward": 473.1203580358053, "episode": 68.0, "batch_reward": 0.19507073573768138, "critic_loss": 0.44459214216470716, "actor_loss": -25.0026328125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.17789602279663, "step": 68000}
{"episode_reward": 309.91559859207155, "episode": 69.0, "batch_reward": 0.19791177183389663, "critic_loss": 0.4326661043614149, "actor_loss": -25.00097444152832, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.174211025238037, "step": 69000}
{"episode_reward": 483.40888862276995, "episode": 70.0, "batch_reward": 0.2028959887176752, "critic_loss": 0.3988326714038849, "actor_loss": -25.37362152862549, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.366034269332886, "step": 70000}
{"episode_reward": 501.9166008494958, "episode": 71.0, "batch_reward": 0.20708821338415145, "critic_loss": 0.38545115484297277, "actor_loss": -26.350506290435792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.19243884086609, "step": 71000}
{"episode_reward": 465.0522907738249, "episode": 72.0, "batch_reward": 0.21024860917031765, "critic_loss": 0.3521710927113891, "actor_loss": -26.582332412719726, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.33009934425354, "step": 72000}
{"episode_reward": 505.58143794468174, "episode": 73.0, "batch_reward": 0.21219729164242745, "critic_loss": 0.34761675119400026, "actor_loss": -26.784237064361573, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.494452953338623, "step": 73000}
{"episode_reward": 132.36275918595683, "episode": 74.0, "batch_reward": 0.21305470018088818, "critic_loss": 0.3308372256234288, "actor_loss": -26.477816310882567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.857624053955078, "step": 74000}
{"episode_reward": 447.37783012964354, "episode": 75.0, "batch_reward": 0.2172282870709896, "critic_loss": 0.3585004202723503, "actor_loss": -26.837948848724366, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.07531762123108, "step": 75000}
{"episode_reward": 489.50857700461376, "episode": 76.0, "batch_reward": 0.219800605610013, "critic_loss": 0.33348928655683996, "actor_loss": -27.134443237304687, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.87431287765503, "step": 76000}
{"episode_reward": 477.205339649827, "episode": 77.0, "batch_reward": 0.22316969077289103, "critic_loss": 0.3841752418577671, "actor_loss": -27.45097473526001, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.032438278198242, "step": 77000}
{"episode_reward": 481.2260938200018, "episode": 78.0, "batch_reward": 0.22692964623868467, "critic_loss": 0.33181842166930436, "actor_loss": -27.685141376495363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.99088144302368, "step": 78000}
{"episode_reward": 456.1362962518519, "episode": 79.0, "batch_reward": 0.22703339239954948, "critic_loss": 0.36639088781923057, "actor_loss": -28.40693127822876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.523982286453247, "step": 79000}
{"episode_reward": 132.03329780280694, "episode": 80.0, "batch_reward": 0.22786946097016333, "critic_loss": 0.4460590578615665, "actor_loss": -27.89079780960083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.528136253356934, "step": 80000}
{"episode_reward": 268.30991379469043, "episode": 81.0, "batch_reward": 0.2289042734503746, "critic_loss": 0.4060671282708645, "actor_loss": -27.961765384674074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.56748390197754, "step": 81000}
{"episode_reward": 467.7332220929248, "episode": 82.0, "batch_reward": 0.23257529963552953, "critic_loss": 0.3529733517318964, "actor_loss": -27.927038108825684, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.182559967041016, "step": 82000}
{"episode_reward": 482.24964145815903, "episode": 83.0, "batch_reward": 0.2359493590891361, "critic_loss": 0.3558913249075413, "actor_loss": -28.591064750671386, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.266090869903564, "step": 83000}
{"episode_reward": 479.07360034695677, "episode": 84.0, "batch_reward": 0.23832278759777545, "critic_loss": 0.34997144144773484, "actor_loss": -28.41805916595459, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.242770195007324, "step": 84000}
{"episode_reward": 449.71869616562003, "episode": 85.0, "batch_reward": 0.23974163126945497, "critic_loss": 0.32163807496428487, "actor_loss": -28.65648094177246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.554807424545288, "step": 85000}
{"episode_reward": 460.03930229969615, "episode": 86.0, "batch_reward": 0.24348664554953575, "critic_loss": 0.3575542824938893, "actor_loss": -29.33932098007202, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.721287727355957, "step": 86000}
{"episode_reward": 435.60689647237825, "episode": 87.0, "batch_reward": 0.2453744043558836, "critic_loss": 0.35583573044091465, "actor_loss": -29.261688579559326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.215165853500366, "step": 87000}
{"episode_reward": 489.17278470368746, "episode": 88.0, "batch_reward": 0.24753394274413584, "critic_loss": 0.355570879727602, "actor_loss": -29.623922843933105, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.26736879348755, "step": 88000}
{"episode_reward": 205.2072171187263, "episode": 89.0, "batch_reward": 0.24560564912855626, "critic_loss": 0.3157729596570134, "actor_loss": -29.29199642562866, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.194931745529175, "step": 89000}
{"episode_reward": 133.88625571236017, "episode": 90.0, "batch_reward": 0.24634090478718282, "critic_loss": 0.3594840019568801, "actor_loss": -29.201732135772705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.443652868270874, "step": 90000}
{"episode_reward": 485.1550179980125, "episode": 91.0, "batch_reward": 0.2491372248083353, "critic_loss": 0.3636642167568207, "actor_loss": -29.72184004974365, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.79458665847778, "step": 91000}
{"episode_reward": 472.5813119593244, "episode": 92.0, "batch_reward": 0.2516087051331997, "critic_loss": 0.3771783297732472, "actor_loss": -29.880084548950194, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.778103590011597, "step": 92000}
{"episode_reward": 483.3962653417542, "episode": 93.0, "batch_reward": 0.2541981168240309, "critic_loss": 0.3468937889188528, "actor_loss": -30.14181558609009, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.742180109024048, "step": 93000}
{"episode_reward": 491.3976374976075, "episode": 94.0, "batch_reward": 0.2554205744117498, "critic_loss": 0.33436522956937553, "actor_loss": -30.38833393859863, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.680281400680542, "step": 94000}
{"episode_reward": 338.7821229515173, "episode": 95.0, "batch_reward": 0.2581617615520954, "critic_loss": 0.3395641287192702, "actor_loss": -30.33666632080078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.535345315933228, "step": 95000}
{"episode_reward": 487.0782323200117, "episode": 96.0, "batch_reward": 0.259775489538908, "critic_loss": 0.3659212188050151, "actor_loss": -30.60430615234375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.206928968429565, "step": 96000}
{"episode_reward": 480.0446594871626, "episode": 97.0, "batch_reward": 0.2619537102729082, "critic_loss": 0.34729781629890205, "actor_loss": -30.60561450576782, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.770546197891235, "step": 97000}
{"episode_reward": 469.4408039906984, "episode": 98.0, "batch_reward": 0.2644087689965963, "critic_loss": 0.36080558781325817, "actor_loss": -31.148533321380615, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.43305468559265, "step": 98000}
{"episode_reward": 479.37707268647944, "episode": 99.0, "batch_reward": 0.26652954168617726, "critic_loss": 0.2958155973628163, "actor_loss": -31.284818782806397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.457903623580933, "step": 99000}
{"episode_reward": 484.1298449173793, "episode": 100.0, "batch_reward": 0.2684257964640856, "critic_loss": 0.3120923399552703, "actor_loss": -31.50276322174072, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.313214540481567, "step": 100000}
{"episode_reward": 474.1680535139971, "episode": 101.0, "batch_reward": 0.2702932968437672, "critic_loss": 0.3458217807337642, "actor_loss": -31.48343993759155, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.919368743896484, "step": 101000}
{"episode_reward": 501.3032515265057, "episode": 102.0, "batch_reward": 0.2724237864911556, "critic_loss": 0.3249116033166647, "actor_loss": -31.871399765014647, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.072675228118896, "step": 102000}
{"episode_reward": 509.07615739432214, "episode": 103.0, "batch_reward": 0.27432594653964043, "critic_loss": 0.3153820323646069, "actor_loss": -32.17318727111817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.5021812915802, "step": 103000}
{"episode_reward": 488.12699146545316, "episode": 104.0, "batch_reward": 0.27806464476883413, "critic_loss": 0.32309687981009483, "actor_loss": -32.27991540908813, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.437535047531128, "step": 104000}
{"episode_reward": 493.71935675035957, "episode": 105.0, "batch_reward": 0.2790283856540918, "critic_loss": 0.3211349905729294, "actor_loss": -32.42330813980102, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.165631771087646, "step": 105000}
{"episode_reward": 470.97550256169035, "episode": 106.0, "batch_reward": 0.2804970612823963, "critic_loss": 0.34664904858917, "actor_loss": -32.75389456176758, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.996289491653442, "step": 106000}
{"episode_reward": 468.5647427739304, "episode": 107.0, "batch_reward": 0.28268847334384917, "critic_loss": 0.3310213256627321, "actor_loss": -33.01948226547241, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.457613229751587, "step": 107000}
{"episode_reward": 501.84564944652783, "episode": 108.0, "batch_reward": 0.28485353748500347, "critic_loss": 0.32924260799586774, "actor_loss": -33.08199440765381, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.138192415237427, "step": 108000}
{"episode_reward": 495.51046413078836, "episode": 109.0, "batch_reward": 0.28633516976237294, "critic_loss": 0.298281826980412, "actor_loss": -32.87938930892944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.27380061149597, "step": 109000}
{"episode_reward": 479.7126662600012, "episode": 110.0, "batch_reward": 0.2884103596806526, "critic_loss": 0.27972758951038124, "actor_loss": -33.31723271560669, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.86283230781555, "step": 110000}
{"episode_reward": 507.43290472842494, "episode": 111.0, "batch_reward": 0.2907052938491106, "critic_loss": 0.31823914907872675, "actor_loss": -33.31657404708862, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.11740517616272, "step": 111000}
{"episode_reward": 485.4417687869143, "episode": 112.0, "batch_reward": 0.2926301632523537, "critic_loss": 0.2717054117396474, "actor_loss": -33.75879628753662, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.04688549041748, "step": 112000}
{"episode_reward": 467.6975591893068, "episode": 113.0, "batch_reward": 0.29385547611117363, "critic_loss": 0.33859783481061456, "actor_loss": -33.97444049835205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.20684576034546, "step": 113000}
{"episode_reward": 483.47196053058195, "episode": 114.0, "batch_reward": 0.29579828733205793, "critic_loss": 0.28282307574898, "actor_loss": -33.64425828552246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.536685466766357, "step": 114000}
{"episode_reward": 522.8982149607775, "episode": 115.0, "batch_reward": 0.29746139676868916, "critic_loss": 0.3189556937888265, "actor_loss": -34.05861450958252, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.1999454498291, "step": 115000}
{"episode_reward": 470.16299007725775, "episode": 116.0, "batch_reward": 0.29959964503347875, "critic_loss": 0.2893580296784639, "actor_loss": -34.077615642547606, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.438642263412476, "step": 116000}
{"episode_reward": 488.26417536194265, "episode": 117.0, "batch_reward": 0.30169497007131574, "critic_loss": 0.2891139799207449, "actor_loss": -34.90487278747558, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.840779066085815, "step": 117000}
{"episode_reward": 466.3872534519975, "episode": 118.0, "batch_reward": 0.3013922307342291, "critic_loss": 0.28429651691764596, "actor_loss": -34.3083062286377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.5564181804657, "step": 118000}
{"episode_reward": 371.2726346069087, "episode": 119.0, "batch_reward": 0.30330540412664414, "critic_loss": 0.30657386922836305, "actor_loss": -34.48272396850586, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.101287126541138, "step": 119000}
{"episode_reward": 482.0975464101352, "episode": 120.0, "batch_reward": 0.3033396132588387, "critic_loss": 0.30913757455348967, "actor_loss": -34.68332189559936, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.297428131103516, "step": 120000}
{"episode_reward": 504.2618319974205, "episode": 121.0, "batch_reward": 0.30629481802880765, "critic_loss": 0.3203374143689871, "actor_loss": -34.914900341033935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.01841354370117, "step": 121000}
{"episode_reward": 477.42283213992386, "episode": 122.0, "batch_reward": 0.30687875482439997, "critic_loss": 0.30026348211616277, "actor_loss": -34.95541933441162, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.96108889579773, "step": 122000}
{"episode_reward": 450.69972810233946, "episode": 123.0, "batch_reward": 0.3096416730880737, "critic_loss": 0.3171597750633955, "actor_loss": -35.64921550750732, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.01711130142212, "step": 123000}
{"episode_reward": 483.16106007570136, "episode": 124.0, "batch_reward": 0.30941019213199616, "critic_loss": 0.3332602562457323, "actor_loss": -35.457443492889404, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.349765300750732, "step": 124000}
{"episode_reward": 474.85357944305713, "episode": 125.0, "batch_reward": 0.3121055777966976, "critic_loss": 0.3240423921644688, "actor_loss": -35.61012562942505, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.07105851173401, "step": 125000}
{"episode_reward": 500.04759650928816, "episode": 126.0, "batch_reward": 0.31183350060880183, "critic_loss": 0.31871226962655785, "actor_loss": -35.35863449859619, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.901690006256104, "step": 126000}
{"episode_reward": 501.2993626659706, "episode": 127.0, "batch_reward": 0.3141074483394623, "critic_loss": 0.33134078108519316, "actor_loss": -35.826931644439696, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.266533136367798, "step": 127000}
{"episode_reward": 506.04457326230175, "episode": 128.0, "batch_reward": 0.31555974268913267, "critic_loss": 0.2914181637167931, "actor_loss": -35.839576168060304, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.228451251983643, "step": 128000}
{"episode_reward": 515.0683722245356, "episode": 129.0, "batch_reward": 0.31775948029756546, "critic_loss": 0.30591985283792017, "actor_loss": -35.901008968353274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.284018754959106, "step": 129000}
{"episode_reward": 518.4816514183434, "episode": 130.0, "batch_reward": 0.3191224673986435, "critic_loss": 0.3645327112227678, "actor_loss": -35.920632152557374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.03355574607849, "step": 130000}
{"episode_reward": 486.3688412006426, "episode": 131.0, "batch_reward": 0.3208807501643896, "critic_loss": 0.31873328775167464, "actor_loss": -35.99072310638428, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.47297668457031, "step": 131000}
{"episode_reward": 500.1491292104315, "episode": 132.0, "batch_reward": 0.3223501825034618, "critic_loss": 0.2965348777845502, "actor_loss": -36.18346283721924, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.721401691436768, "step": 132000}
{"episode_reward": 517.8272308869697, "episode": 133.0, "batch_reward": 0.3224359190165997, "critic_loss": 0.28696322759240867, "actor_loss": -36.46039944458008, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.8850576877594, "step": 133000}
{"episode_reward": 496.5103967547088, "episode": 134.0, "batch_reward": 0.32362221029400823, "critic_loss": 0.29363573145866395, "actor_loss": -36.35935827255249, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.489197731018066, "step": 134000}
{"episode_reward": 354.47741426189503, "episode": 135.0, "batch_reward": 0.32393447670340536, "critic_loss": 0.29971208260953425, "actor_loss": -36.317421741485596, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.20924687385559, "step": 135000}
{"episode_reward": 517.4744956956223, "episode": 136.0, "batch_reward": 0.32621495085954666, "critic_loss": 0.2943320270180702, "actor_loss": -36.34649311828613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.41401171684265, "step": 136000}
{"episode_reward": 494.21685076430555, "episode": 137.0, "batch_reward": 0.32727267318964004, "critic_loss": 0.2842296689003706, "actor_loss": -36.773827728271485, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.343531847000122, "step": 137000}
{"episode_reward": 499.9836953239602, "episode": 138.0, "batch_reward": 0.3289065420031548, "critic_loss": 0.29165362691134217, "actor_loss": -37.234738632202145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.08192276954651, "step": 138000}
{"episode_reward": 418.9870868720426, "episode": 139.0, "batch_reward": 0.3291565520763397, "critic_loss": 0.3084761757105589, "actor_loss": -37.165341136932376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.307373523712158, "step": 139000}
{"episode_reward": 490.2229730885381, "episode": 140.0, "batch_reward": 0.3295839416384697, "critic_loss": 0.29375108444690706, "actor_loss": -37.13606673812866, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.10619592666626, "step": 140000}
{"episode_reward": 488.14513897244245, "episode": 141.0, "batch_reward": 0.3311366984844208, "critic_loss": 0.3071930514499545, "actor_loss": -37.41174766540527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.39328932762146, "step": 141000}
{"episode_reward": 511.6795866393768, "episode": 142.0, "batch_reward": 0.3318435574769974, "critic_loss": 0.3263449652194977, "actor_loss": -37.05038906478882, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.201945781707764, "step": 142000}
{"episode_reward": 274.1901971041154, "episode": 143.0, "batch_reward": 0.3325648390352726, "critic_loss": 0.3375887515768409, "actor_loss": -37.22498449707031, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.09699296951294, "step": 143000}
{"episode_reward": 491.6293753054449, "episode": 144.0, "batch_reward": 0.3331292997300625, "critic_loss": 0.2949161762446165, "actor_loss": -37.17845705795288, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.51867437362671, "step": 144000}
{"episode_reward": 482.46582076912176, "episode": 145.0, "batch_reward": 0.33454992255568505, "critic_loss": 0.2988714262098074, "actor_loss": -37.487933685302735, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.93774127960205, "step": 145000}
{"episode_reward": 482.8602108073441, "episode": 146.0, "batch_reward": 0.3354140966236591, "critic_loss": 0.2900680573731661, "actor_loss": -37.462698085784915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.313993215560913, "step": 146000}
{"episode_reward": 496.4077515083671, "episode": 147.0, "batch_reward": 0.33574425104260447, "critic_loss": 0.3023670480251312, "actor_loss": -37.229397174835206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.429572820663452, "step": 147000}
{"episode_reward": 501.0239337308308, "episode": 148.0, "batch_reward": 0.3379883005023003, "critic_loss": 0.3506481218487024, "actor_loss": -37.790229484558104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.106374740600586, "step": 148000}
{"episode_reward": 493.9460722929143, "episode": 149.0, "batch_reward": 0.33926770424842834, "critic_loss": 0.3061063546985388, "actor_loss": -37.73926699066162, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.296283960342407, "step": 149000}
{"episode_reward": 508.0152111213977, "episode": 150.0, "batch_reward": 0.34051994249224665, "critic_loss": 0.30741771711409094, "actor_loss": -37.67841669845581, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
