{"episode_reward": 0.0, "episode": 1.0, "duration": 17.957952976226807, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.4924261569976807, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.2334415279713898, "critic_loss": 0.17480355382050106, "actor_loss": -45.833674267131165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 63.947585582733154, "step": 3000}
{"episode_reward": 318.30525847084454, "episode": 4.0, "batch_reward": 0.2634132508188486, "critic_loss": 0.3439869259148836, "actor_loss": -47.2635740814209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.743547916412354, "step": 4000}
{"episode_reward": 200.11065173535238, "episode": 5.0, "batch_reward": 0.2580602553486824, "critic_loss": 0.36800883665680884, "actor_loss": -47.51626992797851, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.112351179122925, "step": 5000}
{"episode_reward": 401.6751031175498, "episode": 6.0, "batch_reward": 0.2533734327852726, "critic_loss": 0.4126649882644415, "actor_loss": -47.61100735473633, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.08508062362671, "step": 6000}
{"episode_reward": 21.52905909466092, "episode": 7.0, "batch_reward": 0.21519726042449475, "critic_loss": 0.34847672408819197, "actor_loss": -46.467926582336425, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.639288187026978, "step": 7000}
{"episode_reward": 6.470736638715308, "episode": 8.0, "batch_reward": 0.18978505344688892, "critic_loss": 0.32679002802073953, "actor_loss": -45.602737998962404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.051047563552856, "step": 8000}
{"episode_reward": 19.106774963072507, "episode": 9.0, "batch_reward": 0.17003635536879302, "critic_loss": 0.35148125775158406, "actor_loss": -45.050806381225584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.598254680633545, "step": 9000}
{"episode_reward": 90.0889938069744, "episode": 10.0, "batch_reward": 0.16047939973324538, "critic_loss": 0.32416467113792896, "actor_loss": -44.54988719940186, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.490100145339966, "step": 10000}
{"episode_reward": 6.324260836925984, "episode": 11.0, "batch_reward": 0.14550301691889764, "critic_loss": 0.24388033798336983, "actor_loss": -43.99905404663086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.45942687988281, "step": 11000}
{"episode_reward": 10.49708053785124, "episode": 12.0, "batch_reward": 0.13426268694549798, "critic_loss": 0.17868276608735323, "actor_loss": -43.11057960510254, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.6770761013031, "step": 12000}
{"episode_reward": 9.642896305096773, "episode": 13.0, "batch_reward": 0.12841052410006523, "critic_loss": 0.15650653226673603, "actor_loss": -41.9425286026001, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.62215828895569, "step": 13000}
{"episode_reward": 248.48746933945222, "episode": 14.0, "batch_reward": 0.14735109743475913, "critic_loss": 0.22485235702246428, "actor_loss": -41.62486724853515, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.522634506225586, "step": 14000}
{"episode_reward": 433.17658250853304, "episode": 15.0, "batch_reward": 0.1676861886754632, "critic_loss": 0.27081023320555686, "actor_loss": -42.45804387664795, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.440423011779785, "step": 15000}
{"episode_reward": 435.5410324289173, "episode": 16.0, "batch_reward": 0.17758841940015554, "critic_loss": 0.35557298235595225, "actor_loss": -42.4587425994873, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.750427961349487, "step": 16000}
{"episode_reward": 123.18189025025899, "episode": 17.0, "batch_reward": 0.17011175493896008, "critic_loss": 0.3086948963701725, "actor_loss": -41.93788240814209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.912269592285156, "step": 17000}
{"episode_reward": 8.86731441122489, "episode": 18.0, "batch_reward": 0.1599548908174038, "critic_loss": 0.26405028232932093, "actor_loss": -41.5870564956665, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.045076847076416, "step": 18000}
{"episode_reward": 5.892510365070366, "episode": 19.0, "batch_reward": 0.15145039635896682, "critic_loss": 0.25689418890327215, "actor_loss": -40.834319694519046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.953755378723145, "step": 19000}
{"episode_reward": 10.5889885895174, "episode": 20.0, "batch_reward": 0.14378982129693033, "critic_loss": 0.24797633551061155, "actor_loss": -40.04638168334961, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.061248064041138, "step": 20000}
{"episode_reward": 14.829784397143163, "episode": 21.0, "batch_reward": 0.14789000558108092, "critic_loss": 0.30066948383301495, "actor_loss": -39.63565407562256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.84194087982178, "step": 21000}
{"episode_reward": 266.3044193613846, "episode": 22.0, "batch_reward": 0.14839874244481324, "critic_loss": 0.35646274699270725, "actor_loss": -39.233643699645995, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.11049723625183, "step": 22000}
{"episode_reward": 125.34645773326201, "episode": 23.0, "batch_reward": 0.15411927828192712, "critic_loss": 0.28714782746881246, "actor_loss": -39.012937492370604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.93198275566101, "step": 23000}
{"episode_reward": 460.6816369635308, "episode": 24.0, "batch_reward": 0.16103198779374361, "critic_loss": 0.2617176183462143, "actor_loss": -38.769017303466796, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.269770860671997, "step": 24000}
{"episode_reward": 190.0818594909468, "episode": 25.0, "batch_reward": 0.1670958376303315, "critic_loss": 0.2405469716861844, "actor_loss": -38.65354960632324, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.857877492904663, "step": 25000}
{"episode_reward": 472.01211173443875, "episode": 26.0, "batch_reward": 0.1766301045268774, "critic_loss": 0.23546912163496017, "actor_loss": -38.527111877441406, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.794217586517334, "step": 26000}
{"episode_reward": 213.46664430268822, "episode": 27.0, "batch_reward": 0.1796040656864643, "critic_loss": 0.2244054214581847, "actor_loss": -38.218624137878415, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.826521158218384, "step": 27000}
{"episode_reward": 336.14518423518945, "episode": 28.0, "batch_reward": 0.18378697065263985, "critic_loss": 0.23535134068876504, "actor_loss": -38.14124343109131, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.75556492805481, "step": 28000}
{"episode_reward": 209.2616448495756, "episode": 29.0, "batch_reward": 0.18678294377028942, "critic_loss": 0.21196065533906222, "actor_loss": -37.969671279907224, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.714388370513916, "step": 29000}
{"episode_reward": 470.58013233519097, "episode": 30.0, "batch_reward": 0.19651525083184243, "critic_loss": 0.22269347222149372, "actor_loss": -38.20917747497558, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.649224519729614, "step": 30000}
{"episode_reward": 482.74245249756103, "episode": 31.0, "batch_reward": 0.20656036610901357, "critic_loss": 0.19746813468635083, "actor_loss": -38.41979931640625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.07165861129761, "step": 31000}
{"episode_reward": 513.8896145038093, "episode": 32.0, "batch_reward": 0.21666392262279988, "critic_loss": 0.18291061312705278, "actor_loss": -38.76327268218994, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.62035584449768, "step": 32000}
{"episode_reward": 421.3555653326305, "episode": 33.0, "batch_reward": 0.22346798431873321, "critic_loss": 0.17174991881102322, "actor_loss": -38.82804793548584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.926272869110107, "step": 33000}
{"episode_reward": 505.2193314378454, "episode": 34.0, "batch_reward": 0.23083543966710568, "critic_loss": 0.16511825296282767, "actor_loss": -39.27225912475586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.483527660369873, "step": 34000}
{"episode_reward": 493.2969383290345, "episode": 35.0, "batch_reward": 0.23845672391355038, "critic_loss": 0.15812184358388184, "actor_loss": -39.052943634033205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.574933290481567, "step": 35000}
{"episode_reward": 510.2676397978303, "episode": 36.0, "batch_reward": 0.2439644619524479, "critic_loss": 0.15716803376376628, "actor_loss": -39.28174703979492, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.905945777893066, "step": 36000}
{"episode_reward": 460.37766826898815, "episode": 37.0, "batch_reward": 0.25175955665111543, "critic_loss": 0.17009552194923164, "actor_loss": -39.53934610748291, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.195404767990112, "step": 37000}
{"episode_reward": 504.83604976710535, "episode": 38.0, "batch_reward": 0.25846596279740336, "critic_loss": 0.1799234932512045, "actor_loss": -39.42777806854248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.015785694122314, "step": 38000}
{"episode_reward": 470.59700008560475, "episode": 39.0, "batch_reward": 0.2642523339539766, "critic_loss": 0.16169399458169936, "actor_loss": -39.29857151794434, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.56040120124817, "step": 39000}
{"episode_reward": 522.5420348552144, "episode": 40.0, "batch_reward": 0.2704992279559374, "critic_loss": 0.15851594583690168, "actor_loss": -39.53819989013672, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.88717222213745, "step": 40000}
{"episode_reward": 472.07982254852493, "episode": 41.0, "batch_reward": 0.2756836092174053, "critic_loss": 0.1578649258390069, "actor_loss": -39.726151741027834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.79467439651489, "step": 41000}
{"episode_reward": 487.40406863091715, "episode": 42.0, "batch_reward": 0.28090450747311113, "critic_loss": 0.16707532837986946, "actor_loss": -40.03277516174317, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.987295866012573, "step": 42000}
{"episode_reward": 495.9544025368434, "episode": 43.0, "batch_reward": 0.28643831726908686, "critic_loss": 0.16665996215492487, "actor_loss": -40.18570578765869, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.68702483177185, "step": 43000}
{"episode_reward": 478.2842178333457, "episode": 44.0, "batch_reward": 0.28944754640758036, "critic_loss": 0.1773157656416297, "actor_loss": -40.2865793762207, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.66566753387451, "step": 44000}
{"episode_reward": 453.8072954341705, "episode": 45.0, "batch_reward": 0.2933977196663618, "critic_loss": 0.17593039794266224, "actor_loss": -40.0988263092041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.75001549720764, "step": 45000}
{"episode_reward": 510.43169635595285, "episode": 46.0, "batch_reward": 0.29777006620168683, "critic_loss": 0.17540045369416477, "actor_loss": -40.32194593048096, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.67378878593445, "step": 46000}
{"episode_reward": 488.94576508967873, "episode": 47.0, "batch_reward": 0.3040970373302698, "critic_loss": 0.16088766819238662, "actor_loss": -40.70237505340576, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.234413862228394, "step": 47000}
{"episode_reward": 508.6661654424566, "episode": 48.0, "batch_reward": 0.30718879841268065, "critic_loss": 0.1591336214467883, "actor_loss": -41.013714347839354, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.664650917053223, "step": 48000}
{"episode_reward": 519.668886875186, "episode": 49.0, "batch_reward": 0.3131546570062637, "critic_loss": 0.15887366379797457, "actor_loss": -41.048415000915526, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.516493558883667, "step": 49000}
{"episode_reward": 515.4400496623557, "episode": 50.0, "batch_reward": 0.3149729329198599, "critic_loss": 0.14787957183271647, "actor_loss": -41.103425468444826, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.684096813201904, "step": 50000}
{"episode_reward": 496.8866539221911, "episode": 51.0, "batch_reward": 0.31997939944267273, "critic_loss": 0.14830995362997054, "actor_loss": -41.64054927062988, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.47837996482849, "step": 51000}
{"episode_reward": 493.9777301962957, "episode": 52.0, "batch_reward": 0.3222358985543251, "critic_loss": 0.15625751300156115, "actor_loss": -41.112529067993165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.614682912826538, "step": 52000}
{"episode_reward": 498.1259483754669, "episode": 53.0, "batch_reward": 0.3272211945950985, "critic_loss": 0.15600895844399928, "actor_loss": -41.60242993164063, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.052202701568604, "step": 53000}
{"episode_reward": 513.9543524736018, "episode": 54.0, "batch_reward": 0.32956512945890426, "critic_loss": 0.14918306313455104, "actor_loss": -41.662812950134274, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.67547607421875, "step": 54000}
{"episode_reward": 483.4800253917037, "episode": 55.0, "batch_reward": 0.33258881440758703, "critic_loss": 0.14986043425649404, "actor_loss": -42.12277224731445, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.64153289794922, "step": 55000}
{"episode_reward": 509.6892898446608, "episode": 56.0, "batch_reward": 0.3361254818737507, "critic_loss": 0.14833577727526426, "actor_loss": -41.85284062194824, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.847546577453613, "step": 56000}
{"episode_reward": 466.1525429264817, "episode": 57.0, "batch_reward": 0.3386356702744961, "critic_loss": 0.15760782162100076, "actor_loss": -41.97791568756104, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.096827507019043, "step": 57000}
{"episode_reward": 498.5515985427616, "episode": 58.0, "batch_reward": 0.3413220461010933, "critic_loss": 0.1518113845810294, "actor_loss": -42.78415920257569, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.953286170959473, "step": 58000}
{"episode_reward": 498.82902060237626, "episode": 59.0, "batch_reward": 0.3435109687447548, "critic_loss": 0.15024934980645777, "actor_loss": -42.62780748748779, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.993144035339355, "step": 59000}
{"episode_reward": 495.9418565521879, "episode": 60.0, "batch_reward": 0.3460943016111851, "critic_loss": 0.1509168624728918, "actor_loss": -42.070695755004884, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.808820486068726, "step": 60000}
{"episode_reward": 512.7434546039656, "episode": 61.0, "batch_reward": 0.3483877046406269, "critic_loss": 0.16244137681275606, "actor_loss": -42.98671812438965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.43181395530701, "step": 61000}
{"episode_reward": 479.803033116949, "episode": 62.0, "batch_reward": 0.35114510330557824, "critic_loss": 0.16023631861805915, "actor_loss": -43.211574768066406, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.81376886367798, "step": 62000}
{"episode_reward": 493.8500574622752, "episode": 63.0, "batch_reward": 0.3519606201052666, "critic_loss": 0.15660576342791319, "actor_loss": -42.834473960876466, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.64955759048462, "step": 63000}
{"episode_reward": 496.7597472600477, "episode": 64.0, "batch_reward": 0.3551818895637989, "critic_loss": 0.16831605605781078, "actor_loss": -43.2300291595459, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.456515312194824, "step": 64000}
{"episode_reward": 522.8491189642272, "episode": 65.0, "batch_reward": 0.35678257393836976, "critic_loss": 0.1545974154509604, "actor_loss": -43.09340834808349, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.50357174873352, "step": 65000}
{"episode_reward": 526.7042729712833, "episode": 66.0, "batch_reward": 0.36134853357076646, "critic_loss": 0.15621004163473845, "actor_loss": -43.285966423034665, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.739877700805664, "step": 66000}
{"episode_reward": 518.5469546399805, "episode": 67.0, "batch_reward": 0.36240351903438567, "critic_loss": 0.16283398769050836, "actor_loss": -42.8542289352417, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.71166753768921, "step": 67000}
{"episode_reward": 514.4581135362027, "episode": 68.0, "batch_reward": 0.36459515333175657, "critic_loss": 0.14683979929611088, "actor_loss": -44.01976191711426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.511387825012207, "step": 68000}
{"episode_reward": 518.3310129194, "episode": 69.0, "batch_reward": 0.3670243714749813, "critic_loss": 0.16214809133857488, "actor_loss": -43.64503328704834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.32230854034424, "step": 69000}
{"episode_reward": 513.0385084076388, "episode": 70.0, "batch_reward": 0.36899724370241166, "critic_loss": 0.15775940502434968, "actor_loss": -43.692321952819825, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.75187659263611, "step": 70000}
{"episode_reward": 511.68279519504136, "episode": 71.0, "batch_reward": 0.371188438475132, "critic_loss": 0.1554470088109374, "actor_loss": -44.28851238250732, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.4282763004303, "step": 71000}
{"episode_reward": 440.918820639185, "episode": 72.0, "batch_reward": 0.3722313520908356, "critic_loss": 0.1714627556949854, "actor_loss": -44.105727813720705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.66678285598755, "step": 72000}
{"episode_reward": 514.6070717327248, "episode": 73.0, "batch_reward": 0.374248327344656, "critic_loss": 0.16519682240486144, "actor_loss": -44.26287001037598, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.642310619354248, "step": 73000}
{"episode_reward": 511.52273047961927, "episode": 74.0, "batch_reward": 0.37624925404787063, "critic_loss": 0.17609815449267627, "actor_loss": -44.02130982208252, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.879695177078247, "step": 74000}
{"episode_reward": 501.7506329270568, "episode": 75.0, "batch_reward": 0.3777873519361019, "critic_loss": 0.16970626882463694, "actor_loss": -44.33984407806396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.831223249435425, "step": 75000}
{"episode_reward": 511.6475854964886, "episode": 76.0, "batch_reward": 0.38018638134002686, "critic_loss": 0.1761221290528774, "actor_loss": -44.44156967163086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.649822473526, "step": 76000}
{"episode_reward": 517.3025319782737, "episode": 77.0, "batch_reward": 0.38152592453360556, "critic_loss": 0.1797626539543271, "actor_loss": -44.60054213714599, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.347806453704834, "step": 77000}
{"episode_reward": 507.8022609084371, "episode": 78.0, "batch_reward": 0.383486904412508, "critic_loss": 0.17296175374090672, "actor_loss": -44.43541840362549, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.593347787857056, "step": 78000}
{"episode_reward": 531.333159982342, "episode": 79.0, "batch_reward": 0.38494813233613967, "critic_loss": 0.17707056594640017, "actor_loss": -45.148045791625975, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.905292510986328, "step": 79000}
{"episode_reward": 528.6888378646396, "episode": 80.0, "batch_reward": 0.3873008881807327, "critic_loss": 0.16543573145568372, "actor_loss": -45.14198627471924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.736295700073242, "step": 80000}
{"episode_reward": 527.3487587685181, "episode": 81.0, "batch_reward": 0.389260184109211, "critic_loss": 0.1725921107158065, "actor_loss": -45.06402153778076, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.58368229866028, "step": 81000}
{"episode_reward": 507.5952585863318, "episode": 82.0, "batch_reward": 0.39040896728634833, "critic_loss": 0.1585813862681389, "actor_loss": -44.66341697692871, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.526543617248535, "step": 82000}
{"episode_reward": 520.4527452084355, "episode": 83.0, "batch_reward": 0.3919030236601829, "critic_loss": 0.14701811710000037, "actor_loss": -45.11000228118896, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.309844255447388, "step": 83000}
{"episode_reward": 531.5058661787444, "episode": 84.0, "batch_reward": 0.39362448641657827, "critic_loss": 0.16265310318768025, "actor_loss": -45.192596145629885, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.64417290687561, "step": 84000}
{"episode_reward": 502.52681140963585, "episode": 85.0, "batch_reward": 0.39408462396264077, "critic_loss": 0.1631130523607135, "actor_loss": -44.957682487487794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.600699424743652, "step": 85000}
{"episode_reward": 525.596121480984, "episode": 86.0, "batch_reward": 0.3957548052072525, "critic_loss": 0.16112310772016644, "actor_loss": -45.38386275482178, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.77865433692932, "step": 86000}
{"episode_reward": 525.960524346604, "episode": 87.0, "batch_reward": 0.3967260445356369, "critic_loss": 0.1579729556515813, "actor_loss": -45.45404271697998, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.837604761123657, "step": 87000}
{"episode_reward": 522.5696407586106, "episode": 88.0, "batch_reward": 0.3990293933749199, "critic_loss": 0.16301846059411765, "actor_loss": -46.00799383544922, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.977612018585205, "step": 88000}
{"episode_reward": 520.5395503939702, "episode": 89.0, "batch_reward": 0.3986827878057957, "critic_loss": 0.15943886156380177, "actor_loss": -45.69450314331055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.78190302848816, "step": 89000}
{"episode_reward": 522.3266096416943, "episode": 90.0, "batch_reward": 0.4019490394890308, "critic_loss": 0.16328056909143926, "actor_loss": -45.55633098602295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.686011791229248, "step": 90000}
{"episode_reward": 527.1692513576367, "episode": 91.0, "batch_reward": 0.4036772544682026, "critic_loss": 0.14729322670400144, "actor_loss": -45.91711946105957, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.43895721435547, "step": 91000}
{"episode_reward": 504.1894045683838, "episode": 92.0, "batch_reward": 0.40555984258651734, "critic_loss": 0.15081258934736252, "actor_loss": -46.0978570022583, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.700196027755737, "step": 92000}
{"episode_reward": 501.70374682077744, "episode": 93.0, "batch_reward": 0.40528256791830064, "critic_loss": 0.15240504781901837, "actor_loss": -46.12716756439209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.782220602035522, "step": 93000}
{"episode_reward": 524.10610630735, "episode": 94.0, "batch_reward": 0.4062567090392113, "critic_loss": 0.1474533098116517, "actor_loss": -46.42015811157226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.910541534423828, "step": 94000}
{"episode_reward": 296.3213325116414, "episode": 95.0, "batch_reward": 0.40519317373633384, "critic_loss": 0.15808436674624682, "actor_loss": -45.551043357849125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.773998260498047, "step": 95000}
{"episode_reward": 536.7043758577247, "episode": 96.0, "batch_reward": 0.40663780841231345, "critic_loss": 0.14874126897379755, "actor_loss": -46.0222392578125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.581519603729248, "step": 96000}
{"episode_reward": 526.447725627598, "episode": 97.0, "batch_reward": 0.40821778383851054, "critic_loss": 0.1599485213905573, "actor_loss": -46.01218049621582, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.55893087387085, "step": 97000}
{"episode_reward": 512.7998971230164, "episode": 98.0, "batch_reward": 0.4089058164358139, "critic_loss": 0.16140771163254977, "actor_loss": -46.215497024536134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.688581943511963, "step": 98000}
{"episode_reward": 515.8521242516082, "episode": 99.0, "batch_reward": 0.41078144043684006, "critic_loss": 0.152921261459589, "actor_loss": -46.22986353302002, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.66917872428894, "step": 99000}
{"episode_reward": 534.007740053202, "episode": 100.0, "batch_reward": 0.4113097177147865, "critic_loss": 0.15339757351577282, "actor_loss": -46.40948080444336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.226616621017456, "step": 100000}
{"episode_reward": 75.58332680948057, "episode": 101.0, "batch_reward": 0.40816019493341443, "critic_loss": 0.1496782222762704, "actor_loss": -45.696045585632326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 39.68078303337097, "step": 101000}
{"episode_reward": 531.8290639668543, "episode": 102.0, "batch_reward": 0.4087700778543949, "critic_loss": 0.15767895454913378, "actor_loss": -46.01285115814209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.541542053222656, "step": 102000}
{"episode_reward": 518.2555432758334, "episode": 103.0, "batch_reward": 0.409469164788723, "critic_loss": 0.15555425111576915, "actor_loss": -45.986566802978516, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.501976490020752, "step": 103000}
{"episode_reward": 511.3539323539076, "episode": 104.0, "batch_reward": 0.41203112906217576, "critic_loss": 0.15866434814035893, "actor_loss": -46.14925192260742, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.81401491165161, "step": 104000}
{"episode_reward": 496.43285429795003, "episode": 105.0, "batch_reward": 0.41250687488913534, "critic_loss": 0.1691939682662487, "actor_loss": -46.18694090270996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.65201210975647, "step": 105000}
{"episode_reward": 519.8226181572281, "episode": 106.0, "batch_reward": 0.4120717175900936, "critic_loss": 0.16341124477982522, "actor_loss": -46.45376739501953, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.7082462310791, "step": 106000}
{"episode_reward": 515.5887478394329, "episode": 107.0, "batch_reward": 0.4144644868671894, "critic_loss": 0.1701213082522154, "actor_loss": -46.33019225311279, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.721323490142822, "step": 107000}
{"episode_reward": 526.8154186177622, "episode": 108.0, "batch_reward": 0.4157761314511299, "critic_loss": 0.17020099574327469, "actor_loss": -46.37677571868897, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.766350507736206, "step": 108000}
{"episode_reward": 534.1923741213126, "episode": 109.0, "batch_reward": 0.41595243313908575, "critic_loss": 0.18680159451812506, "actor_loss": -46.3659298248291, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.8471782207489, "step": 109000}
{"episode_reward": 495.6744353885547, "episode": 110.0, "batch_reward": 0.41649747216701505, "critic_loss": 0.16861652936041355, "actor_loss": -46.15517664337158, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.926177978515625, "step": 110000}
{"episode_reward": 538.7911480038626, "episode": 111.0, "batch_reward": 0.4186635375022888, "critic_loss": 0.174883136741817, "actor_loss": -46.288631462097165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.636043071746826, "step": 111000}
{"episode_reward": 508.2719630740584, "episode": 112.0, "batch_reward": 0.4187324651777744, "critic_loss": 0.1731227826550603, "actor_loss": -46.6397813949585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.83121156692505, "step": 112000}
{"episode_reward": 493.37604796527467, "episode": 113.0, "batch_reward": 0.41995127165317536, "critic_loss": 0.16219692321121693, "actor_loss": -46.92455290985107, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.983489513397217, "step": 113000}
{"episode_reward": 525.1461554485445, "episode": 114.0, "batch_reward": 0.4199791426062584, "critic_loss": 0.16729420544207096, "actor_loss": -46.27297859191894, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.645354747772217, "step": 114000}
{"episode_reward": 525.5636130238464, "episode": 115.0, "batch_reward": 0.421180459022522, "critic_loss": 0.15602526174485684, "actor_loss": -46.76488639831543, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.94336199760437, "step": 115000}
{"episode_reward": 516.2330390722642, "episode": 116.0, "batch_reward": 0.42285209834575654, "critic_loss": 0.157232584413141, "actor_loss": -46.660016746520995, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.692404985427856, "step": 116000}
{"episode_reward": 527.8307733219948, "episode": 117.0, "batch_reward": 0.42396853312849997, "critic_loss": 0.14906463988125324, "actor_loss": -47.14139734649658, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.710503816604614, "step": 117000}
{"episode_reward": 512.827266303843, "episode": 118.0, "batch_reward": 0.4237459361851215, "critic_loss": 0.1538653086721897, "actor_loss": -46.8111017074585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.879554748535156, "step": 118000}
{"episode_reward": 508.8991158730418, "episode": 119.0, "batch_reward": 0.42527062422037126, "critic_loss": 0.15222304208576679, "actor_loss": -46.94346878814697, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.958946228027344, "step": 119000}
{"episode_reward": 529.336333431604, "episode": 120.0, "batch_reward": 0.4242526041269302, "critic_loss": 0.15200572149455546, "actor_loss": -47.3001241607666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.238258838653564, "step": 120000}
{"episode_reward": 498.5959682408543, "episode": 121.0, "batch_reward": 0.4267933113873005, "critic_loss": 0.16068468070030212, "actor_loss": -47.11944869995117, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.58419585227966, "step": 121000}
{"episode_reward": 525.3168229342344, "episode": 122.0, "batch_reward": 0.4274729262590408, "critic_loss": 0.14721635636687277, "actor_loss": -46.968922561645506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.720913887023926, "step": 122000}
{"episode_reward": 508.0397393856064, "episode": 123.0, "batch_reward": 0.4290838798284531, "critic_loss": 0.15561530447378755, "actor_loss": -47.58103694915771, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.555693864822388, "step": 123000}
{"episode_reward": 521.4392363866441, "episode": 124.0, "batch_reward": 0.4283469204008579, "critic_loss": 0.1557473917528987, "actor_loss": -47.11429490661621, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.787413358688354, "step": 124000}
{"episode_reward": 504.7570541205167, "episode": 125.0, "batch_reward": 0.42975066414475444, "critic_loss": 0.14198115344718099, "actor_loss": -47.6854366607666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.885490894317627, "step": 125000}
{"episode_reward": 511.45185488399096, "episode": 126.0, "batch_reward": 0.428607705950737, "critic_loss": 0.1492098539546132, "actor_loss": -47.104924728393556, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.902058124542236, "step": 126000}
{"episode_reward": 531.7241039343184, "episode": 127.0, "batch_reward": 0.43096859550476074, "critic_loss": 0.14972221976518632, "actor_loss": -47.23605613708496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.678377151489258, "step": 127000}
{"episode_reward": 492.9614626921835, "episode": 128.0, "batch_reward": 0.43117311865091323, "critic_loss": 0.1527436248138547, "actor_loss": -47.322731185913085, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.56979990005493, "step": 128000}
{"episode_reward": 526.5945163013788, "episode": 129.0, "batch_reward": 0.4314636480510235, "critic_loss": 0.14791256891191007, "actor_loss": -47.26687922668457, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.610549211502075, "step": 129000}
{"episode_reward": 504.7167567866879, "episode": 130.0, "batch_reward": 0.43304333251714705, "critic_loss": 0.15631208158656953, "actor_loss": -47.33736566162109, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.44220542907715, "step": 130000}
{"episode_reward": 511.770861002912, "episode": 131.0, "batch_reward": 0.43329807433485984, "critic_loss": 0.14177074213325977, "actor_loss": -47.27397034454346, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.57061171531677, "step": 131000}
{"episode_reward": 529.0355415195032, "episode": 132.0, "batch_reward": 0.4337317753136158, "critic_loss": 0.1439446501880884, "actor_loss": -47.60838550567627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.392591953277588, "step": 132000}
{"episode_reward": 508.1401423183991, "episode": 133.0, "batch_reward": 0.4346358539760113, "critic_loss": 0.14293123646080494, "actor_loss": -47.55360238647461, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.784913063049316, "step": 133000}
{"episode_reward": 525.6582387450338, "episode": 134.0, "batch_reward": 0.4347387251853943, "critic_loss": 0.1347964508831501, "actor_loss": -47.37557085418701, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.790768146514893, "step": 134000}
{"episode_reward": 506.89272228544604, "episode": 135.0, "batch_reward": 0.4357801513373852, "critic_loss": 0.13490479843318462, "actor_loss": -47.661297721862795, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.77454423904419, "step": 135000}
{"episode_reward": 532.7871692278474, "episode": 136.0, "batch_reward": 0.43585362312197684, "critic_loss": 0.13879972737655044, "actor_loss": -47.42349377441406, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.756701469421387, "step": 136000}
{"episode_reward": 522.695456751925, "episode": 137.0, "batch_reward": 0.436590623319149, "critic_loss": 0.13930827681720256, "actor_loss": -47.87953469848633, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.735483646392822, "step": 137000}
{"episode_reward": 523.8514873855091, "episode": 138.0, "batch_reward": 0.438353655487299, "critic_loss": 0.14231350714340807, "actor_loss": -48.30631726074219, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.781627893447876, "step": 138000}
{"episode_reward": 531.9221401079933, "episode": 139.0, "batch_reward": 0.4379039718210697, "critic_loss": 0.1359663487263024, "actor_loss": -48.19852474975586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.73641085624695, "step": 139000}
{"episode_reward": 519.8038593341066, "episode": 140.0, "batch_reward": 0.43805955904722216, "critic_loss": 0.1455084195919335, "actor_loss": -48.42091353607178, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.634585857391357, "step": 140000}
{"episode_reward": 492.6672385212634, "episode": 141.0, "batch_reward": 0.4397848300635815, "critic_loss": 0.14305975053459405, "actor_loss": -48.71068181610107, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.19225335121155, "step": 141000}
{"episode_reward": 525.4935242132327, "episode": 142.0, "batch_reward": 0.43955961737036703, "critic_loss": 0.14988899247720838, "actor_loss": -48.1152395401001, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.908902168273926, "step": 142000}
{"episode_reward": 525.3813076972838, "episode": 143.0, "batch_reward": 0.4408179846405983, "critic_loss": 0.14059478082507848, "actor_loss": -48.484517013549805, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.80480408668518, "step": 143000}
{"episode_reward": 525.2087483288057, "episode": 144.0, "batch_reward": 0.4408852584958077, "critic_loss": 0.14415575335919856, "actor_loss": -48.29010263061524, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.782727479934692, "step": 144000}
{"episode_reward": 495.23445229281526, "episode": 145.0, "batch_reward": 0.44193615412712095, "critic_loss": 0.15808980536460876, "actor_loss": -48.62130197143555, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.62058997154236, "step": 145000}
{"episode_reward": 515.0318038038267, "episode": 146.0, "batch_reward": 0.44117827630043027, "critic_loss": 0.15210749515891075, "actor_loss": -48.22379047393799, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.769150972366333, "step": 146000}
{"episode_reward": 508.7568886782632, "episode": 147.0, "batch_reward": 0.4417478923499584, "critic_loss": 0.14275226678326727, "actor_loss": -48.35710516357422, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.86991810798645, "step": 147000}
{"episode_reward": 523.7970488447139, "episode": 148.0, "batch_reward": 0.4431658844649792, "critic_loss": 0.150646937943995, "actor_loss": -48.48638463592529, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.087634801864624, "step": 148000}
{"episode_reward": 538.2889966854924, "episode": 149.0, "batch_reward": 0.44346402150392533, "critic_loss": 0.14364840801805256, "actor_loss": -48.48453365325928, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.88707208633423, "step": 149000}
{"episode_reward": 510.8985049318532, "episode": 150.0, "batch_reward": 0.44464395704865456, "critic_loss": 0.14977624718099833, "actor_loss": -48.44565586090088, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
