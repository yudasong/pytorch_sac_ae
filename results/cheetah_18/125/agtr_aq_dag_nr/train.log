{"episode": 1.0, "duration": 18.526768684387207, "episode_reward": 5.1931688606333894, "step": 1000}
{"episode": 2.0, "duration": 1.6327235698699951, "episode_reward": 454.7514538707513, "step": 2000}
{"episode": 3.0, "batch_reward": 0.22871871326875193, "critic_loss": 0.17703088434682007, "actor_loss": -45.282373812256836, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 80.13027620315552, "episode_reward": 207.4721187488193, "step": 3000}
{"episode": 4.0, "batch_reward": 0.23246998019516468, "critic_loss": 0.18868361831456423, "actor_loss": -44.498281440734864, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.84063482284546, "episode_reward": 298.56591919366963, "step": 4000}
{"episode": 5.0, "batch_reward": 0.25240444427728653, "critic_loss": 0.22432647375017403, "actor_loss": -45.22960929107666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.884201765060425, "episode_reward": 344.8381008727832, "step": 5000}
{"episode": 6.0, "batch_reward": 0.2637831871062517, "critic_loss": 0.23617580565810203, "actor_loss": -45.587086090087894, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.683629512786865, "episode_reward": 284.9741669099072, "step": 6000}
{"episode": 7.0, "batch_reward": 0.26696683779358865, "critic_loss": 0.2447438040971756, "actor_loss": -45.56641256713867, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.449100971221924, "episode_reward": 271.9483899020149, "step": 7000}
{"episode": 8.0, "batch_reward": 0.26305291263759134, "critic_loss": 0.33731116707623005, "actor_loss": -45.13725226593017, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.520197868347168, "episode_reward": 200.68915160015948, "step": 8000}
{"episode": 9.0, "batch_reward": 0.25546052715182305, "critic_loss": 0.4161646970808506, "actor_loss": -44.61099787139893, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.721120834350586, "episode_reward": 214.3932863810533, "step": 9000}
{"episode": 10.0, "batch_reward": 0.25711608001589775, "critic_loss": 0.49175022953748704, "actor_loss": -37.675567726135256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 4688.685278892517, "episode_reward": 356.39972872567427, "step": 10000}
{"episode": 11.0, "batch_reward": 0.25721536269783973, "critic_loss": 0.44237132382392885, "actor_loss": -37.18445903778076, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 43.002002477645874, "episode_reward": 68.82730647324892, "step": 11000}
{"episode": 12.0, "batch_reward": 0.2508836966902018, "critic_loss": 0.39113493318855763, "actor_loss": -33.14007054138184, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 544.7483615875244, "episode_reward": 360.5394797637642, "step": 12000}
{"episode": 13.0, "batch_reward": 0.2599734574109316, "critic_loss": 0.3782941762059927, "actor_loss": -33.949775566101074, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.019912004470825, "episode_reward": 383.05123838055397, "step": 13000}
{"episode": 14.0, "batch_reward": 0.27039928187429907, "critic_loss": 0.3730918528884649, "actor_loss": -33.468099361419675, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 577.498074054718, "episode_reward": 381.479414492997, "step": 14000}
{"episode": 15.0, "batch_reward": 0.2773952464610338, "critic_loss": 0.3803952387422323, "actor_loss": -34.04075967025757, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.780883073806763, "episode_reward": 400.05515625174917, "step": 15000}
{"episode": 16.0, "batch_reward": 0.2824129442721605, "critic_loss": 0.3967944379299879, "actor_loss": -33.17763203811646, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 542.1556768417358, "episode_reward": 310.7377463969728, "step": 16000}
{"episode": 17.0, "batch_reward": 0.2871838542073965, "critic_loss": 0.3818209917545319, "actor_loss": -33.455467903137205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.905818939208984, "episode_reward": 384.33235639760954, "step": 17000}
{"episode": 18.0, "batch_reward": 0.2923522152900696, "critic_loss": 0.39757552300393584, "actor_loss": -33.03120986175537, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 553.6167178153992, "episode_reward": 394.19273244862615, "step": 18000}
{"episode": 19.0, "batch_reward": 0.29805017110705373, "critic_loss": 0.435454644292593, "actor_loss": -33.35211304473877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.30022883415222, "episode_reward": 404.12039880236966, "step": 19000}
{"episode": 20.0, "batch_reward": 0.30376951694488524, "critic_loss": 0.4305114379227161, "actor_loss": -33.435743309021, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 532.5843877792358, "episode_reward": 400.5517499595388, "step": 20000}
{"episode": 21.0, "batch_reward": 0.308899331510067, "critic_loss": 0.36466426952183245, "actor_loss": -33.71199379730225, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 42.754600048065186, "episode_reward": 420.79464906918224, "step": 21000}
{"episode": 22.0, "batch_reward": 0.3134612908065319, "critic_loss": 0.3396769081056118, "actor_loss": -33.79799102020264, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 491.2685012817383, "episode_reward": 414.49318691337174, "step": 22000}
{"episode": 23.0, "batch_reward": 0.3190849989056587, "critic_loss": 0.3118168979585171, "actor_loss": -34.24583741760254, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.864707231521606, "episode_reward": 442.43261451844285, "step": 23000}
{"episode": 24.0, "batch_reward": 0.3241853883266449, "critic_loss": 0.2789947894662619, "actor_loss": -34.4044271697998, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 509.4348511695862, "episode_reward": 431.46853285450516, "step": 24000}
{"episode": 25.0, "batch_reward": 0.32810444667935373, "critic_loss": 0.2433997058197856, "actor_loss": -34.73678369522095, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.62023663520813, "episode_reward": 419.6762025697188, "step": 25000}
{"episode": 26.0, "batch_reward": 0.33192144200205803, "critic_loss": 0.21759032679349183, "actor_loss": -34.866973033905026, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 489.5955731868744, "episode_reward": 440.45215453962663, "step": 26000}
{"episode": 27.0, "batch_reward": 0.33621370419859886, "critic_loss": 0.20029490687698126, "actor_loss": -35.24241524505615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.220545530319214, "episode_reward": 449.49432077078336, "step": 27000}
{"episode": 28.0, "batch_reward": 0.33930528634786605, "critic_loss": 0.1783756730929017, "actor_loss": -35.42723757171631, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 483.74734807014465, "episode_reward": 423.30716371969334, "step": 28000}
{"episode": 29.0, "batch_reward": 0.34327468371391295, "critic_loss": 0.1629259861856699, "actor_loss": -35.74168430328369, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.132192611694336, "episode_reward": 427.2390648458122, "step": 29000}
{"episode": 30.0, "batch_reward": 0.3458836224973202, "critic_loss": 0.15513003511726856, "actor_loss": -36.24106649017334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 486.8493232727051, "episode_reward": 420.4090944345616, "step": 30000}
{"episode": 31.0, "batch_reward": 0.3483166740238667, "critic_loss": 0.1560562757924199, "actor_loss": -36.502250045776364, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.31808805465698, "episode_reward": 407.09460372735214, "step": 31000}
{"episode": 32.0, "batch_reward": 0.34959079745411875, "critic_loss": 0.16085175892710685, "actor_loss": -36.034813682556155, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 488.8703737258911, "episode_reward": 397.829551177116, "step": 32000}
{"episode": 33.0, "batch_reward": 0.351162773668766, "critic_loss": 0.14270359357073903, "actor_loss": -36.19219009399414, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.531655073165894, "episode_reward": 393.45821884754037, "step": 33000}
{"episode": 34.0, "batch_reward": 0.3526709023118019, "critic_loss": 0.143481886330992, "actor_loss": -36.67122528839111, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 525.8271560668945, "episode_reward": 401.0093720727116, "step": 34000}
{"episode": 35.0, "batch_reward": 0.3547000470459461, "critic_loss": 0.14368432755023242, "actor_loss": -36.84406059265137, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.914257764816284, "episode_reward": 410.1790971305347, "step": 35000}
{"episode": 36.0, "batch_reward": 0.35522745978832243, "critic_loss": 0.14695125071704387, "actor_loss": -36.38540012359619, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 495.4202516078949, "episode_reward": 406.8908110279544, "step": 36000}
{"episode": 37.0, "batch_reward": 0.3567574975192547, "critic_loss": 0.14419661298394204, "actor_loss": -36.57668445587158, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.36564588546753, "episode_reward": 390.0171365921125, "step": 37000}
{"episode": 38.0, "batch_reward": 0.3576698606908321, "critic_loss": 0.1601834538653493, "actor_loss": -36.51936044311523, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 525.8083946704865, "episode_reward": 406.2832694645649, "step": 38000}
{"episode": 39.0, "batch_reward": 0.3593626792728901, "critic_loss": 0.1835408394485712, "actor_loss": -36.64672077941894, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.95400094985962, "episode_reward": 413.11920947832584, "step": 39000}
{"episode": 40.0, "batch_reward": 0.36020512992143633, "critic_loss": 0.18412623899057506, "actor_loss": -36.801161315917966, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 513.8286349773407, "episode_reward": 412.95130595430896, "step": 40000}
{"episode": 41.0, "batch_reward": 0.3615900420844555, "critic_loss": 0.18001639783382417, "actor_loss": -36.94690676116944, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.03628659248352, "episode_reward": 393.75835784423197, "step": 41000}
{"episode": 42.0, "batch_reward": 0.36299481078982354, "critic_loss": 0.20874684965610504, "actor_loss": -36.623533973693846, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 481.52137875556946, "episode_reward": 404.92357623431707, "step": 42000}
{"episode": 43.0, "batch_reward": 0.363168633967638, "critic_loss": 0.1941088082008064, "actor_loss": -36.693210510253905, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.322686672210693, "episode_reward": 394.66693391143735, "step": 43000}
{"episode": 44.0, "batch_reward": 0.36419496732950213, "critic_loss": 0.22931245341151954, "actor_loss": -36.89558457946777, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 479.04244780540466, "episode_reward": 415.52907196947194, "step": 44000}
{"episode": 45.0, "batch_reward": 0.3648134814798832, "critic_loss": 0.24273256146907807, "actor_loss": -36.90159721374512, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.216546058654785, "episode_reward": 431.05698158067446, "step": 45000}
{"episode": 46.0, "batch_reward": 0.36667710047960284, "critic_loss": 0.28474468451738355, "actor_loss": -36.9610192489624, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 505.7696635723114, "episode_reward": 430.1449093664203, "step": 46000}
{"episode": 47.0, "batch_reward": 0.3679828887283802, "critic_loss": 0.25962252521514895, "actor_loss": -37.106089767456055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.740121364593506, "episode_reward": 421.9889071237703, "step": 47000}
{"episode": 48.0, "batch_reward": 0.3695513719022274, "critic_loss": 0.31095614581555125, "actor_loss": -37.020831283569336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 492.3721766471863, "episode_reward": 429.26562528873524, "step": 48000}
{"episode": 49.0, "batch_reward": 0.37021111997962, "critic_loss": 0.3817175084352493, "actor_loss": -37.12524164581299, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.155519485473633, "episode_reward": 401.8693303573542, "step": 49000}
{"episode": 50.0, "batch_reward": 0.371188523799181, "critic_loss": 0.432640462256968, "actor_loss": -37.46224227905273, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 497.98243737220764, "episode_reward": 411.30323681434703, "step": 50000}
{"episode": 51.0, "batch_reward": 0.37199837267398833, "critic_loss": 0.4792471826225519, "actor_loss": -37.513541732788084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 45.439208030700684, "episode_reward": 416.45219987356194, "step": 51000}
{"episode": 52.0, "batch_reward": 0.37263761985301974, "critic_loss": 0.47908886905759573, "actor_loss": -37.605833160400394, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 501.17894983291626, "episode_reward": 401.6410013256057, "step": 52000}
{"episode": 53.0, "batch_reward": 0.3729750527739525, "critic_loss": 0.544193753041327, "actor_loss": -37.64024110412598, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.962673902511597, "episode_reward": 404.5260193549689, "step": 53000}
{"episode": 54.0, "batch_reward": 0.37374379992485046, "critic_loss": 0.7464220529273152, "actor_loss": -37.871644577026366, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 516.300318479538, "episode_reward": 416.958278107289, "step": 54000}
{"episode": 55.0, "batch_reward": 0.37503486013412474, "critic_loss": 0.9686034038588405, "actor_loss": -38.028384315490726, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.66862440109253, "episode_reward": 418.52751928997543, "step": 55000}
{"episode": 56.0, "batch_reward": 0.3756880878806114, "critic_loss": 0.8594356352165341, "actor_loss": -37.72338535308838, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 485.3266353607178, "episode_reward": 428.48898449560363, "step": 56000}
{"episode": 57.0, "batch_reward": 0.3764735297560692, "critic_loss": 1.5964329836070537, "actor_loss": -37.852527984619144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.027947902679443, "episode_reward": 409.2636119520793, "step": 57000}
{"episode": 58.0, "batch_reward": 0.3776450693011284, "critic_loss": 1.3722540998309851, "actor_loss": -38.115759567260746, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 477.7323408126831, "episode_reward": 406.4368647763581, "step": 58000}
{"episode": 59.0, "batch_reward": 0.37789462342858315, "critic_loss": 1.9908384031355382, "actor_loss": -38.15606156921387, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.919245958328247, "episode_reward": 412.8969362222892, "step": 59000}
{"episode": 60.0, "batch_reward": 0.37836431789398195, "critic_loss": 1.9266044182628392, "actor_loss": -38.26713722229004, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 476.5081715583801, "episode_reward": 422.28252550603355, "step": 60000}
{"episode": 61.0, "batch_reward": 0.37899918577075004, "critic_loss": 2.0810176958441735, "actor_loss": -38.335064010620115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.59882164001465, "episode_reward": 419.6373628517096, "step": 61000}
{"episode": 62.0, "batch_reward": 0.37923768255114554, "critic_loss": 2.6720552339702843, "actor_loss": -38.159110038757326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 493.5256371498108, "episode_reward": 424.17849551046316, "step": 62000}
{"episode": 63.0, "batch_reward": 0.38035986298322677, "critic_loss": 2.5913418113291264, "actor_loss": -38.255814704895016, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07886576652527, "episode_reward": 429.96833767870345, "step": 63000}
{"episode": 64.0, "batch_reward": 0.38054732662439344, "critic_loss": 3.2846299289911984, "actor_loss": -38.177720359802244, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 481.432879447937, "episode_reward": 430.5199390152345, "step": 64000}
{"episode": 65.0, "batch_reward": 0.3818136376440525, "critic_loss": 4.947812075987458, "actor_loss": -38.35647030639648, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.605255603790283, "episode_reward": 399.88506250437865, "step": 65000}
{"episode": 66.0, "batch_reward": 0.38190529811382296, "critic_loss": 5.245804833292961, "actor_loss": -38.570787254333496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 513.2728655338287, "episode_reward": 413.90293449061005, "step": 66000}
{"episode": 67.0, "batch_reward": 0.3825638183951378, "critic_loss": 5.247986709445715, "actor_loss": -38.563738159179685, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.90489649772644, "episode_reward": 424.36511768682385, "step": 67000}
{"episode": 68.0, "batch_reward": 0.3815665903389454, "critic_loss": 13.252468954831361, "actor_loss": -38.39300382232666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 522.2641713619232, "episode_reward": 85.03106785459734, "step": 68000}
{"episode": 69.0, "batch_reward": 0.3772946255803108, "critic_loss": 27.93229796153307, "actor_loss": -37.76878717041016, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.536699771881104, "episode_reward": 115.85583635687121, "step": 69000}
{"episode": 70.0, "batch_reward": 0.37405288937687875, "critic_loss": 37.20057200169563, "actor_loss": -37.4166424407959, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 439.2679808139801, "episode_reward": 151.67195012796248, "step": 70000}
{"episode": 71.0, "batch_reward": 0.3717781434953213, "critic_loss": 31.087060648202897, "actor_loss": -37.136236778259274, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.29111337661743, "episode_reward": 372.1042855400739, "step": 71000}
{"episode": 72.0, "batch_reward": 0.3713501645922661, "critic_loss": 27.19711612403393, "actor_loss": -37.015962341308594, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 507.27934885025024, "episode_reward": 402.1627995876061, "step": 72000}
{"episode": 73.0, "batch_reward": 0.37183050191402434, "critic_loss": 26.055363584876062, "actor_loss": -37.00101865386963, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.10688304901123, "episode_reward": 404.104831441098, "step": 73000}
{"episode": 74.0, "batch_reward": 0.3724032678306103, "critic_loss": 30.451213083505632, "actor_loss": -37.2784066696167, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 478.27842926979065, "episode_reward": 426.84647365483664, "step": 74000}
{"episode": 75.0, "batch_reward": 0.3737174406647682, "critic_loss": 35.31572058224678, "actor_loss": -37.386617835998535, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.77168893814087, "episode_reward": 407.83626655020527, "step": 75000}
{"episode": 76.0, "batch_reward": 0.3740638756453991, "critic_loss": 36.53829180455208, "actor_loss": -37.483140380859375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 461.6528751850128, "episode_reward": 395.8380074441788, "step": 76000}
{"episode": 77.0, "batch_reward": 0.3747902378737927, "critic_loss": 27.363133439183237, "actor_loss": -37.543782501220704, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.478970289230347, "episode_reward": 405.9852635246002, "step": 77000}
{"episode": 78.0, "batch_reward": 0.37519588238000867, "critic_loss": 28.538253457784652, "actor_loss": -37.90132528686524, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 492.1680312156677, "episode_reward": 398.8950274599557, "step": 78000}
{"episode": 79.0, "batch_reward": 0.37556741905212404, "critic_loss": 22.079962940096856, "actor_loss": -37.9188649597168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.10342788696289, "episode_reward": 434.38084151973464, "step": 79000}
{"episode": 80.0, "batch_reward": 0.3758523095548153, "critic_loss": 15.060186627745628, "actor_loss": -38.094960594177245, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 490.64683055877686, "episode_reward": 431.0824183093081, "step": 80000}
{"episode": 81.0, "batch_reward": 0.3768109789192677, "critic_loss": 15.031055300831795, "actor_loss": -38.17711777496338, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 42.18053150177002, "episode_reward": 436.2670900662143, "step": 81000}
{"episode": 82.0, "batch_reward": 0.3774955971837044, "critic_loss": 14.07992807662487, "actor_loss": -38.03622387695312, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 466.5117473602295, "episode_reward": 423.71540937028686, "step": 82000}
{"episode": 83.0, "batch_reward": 0.37755779311060905, "critic_loss": 12.12835555768013, "actor_loss": -38.05568054199219, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.766659021377563, "episode_reward": 424.71720056326194, "step": 83000}
{"episode": 84.0, "batch_reward": 0.3780769464969635, "critic_loss": 13.515861316621304, "actor_loss": -38.16350705718994, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 473.1168632507324, "episode_reward": 288.26048303335284, "step": 84000}
{"episode": 85.0, "batch_reward": 0.3778519704043865, "critic_loss": 13.687267811059952, "actor_loss": -38.12429592895508, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.475358247756958, "episode_reward": 401.6981499863106, "step": 85000}
{"episode": 86.0, "batch_reward": 0.3777024211883545, "critic_loss": 12.594106074750423, "actor_loss": -37.979092887878416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 483.5711364746094, "episode_reward": 443.2901523794652, "step": 86000}
{"episode": 87.0, "batch_reward": 0.37812534457445146, "critic_loss": 8.240887136161327, "actor_loss": -37.959518951416015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.58449625968933, "episode_reward": 446.73903817807405, "step": 87000}
{"episode": 88.0, "batch_reward": 0.37926026672124863, "critic_loss": 7.510522877156735, "actor_loss": -38.45872937774658, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 475.853905916214, "episode_reward": 421.32030280758426, "step": 88000}
{"episode": 89.0, "batch_reward": 0.3793322244882584, "critic_loss": 4.887207110583782, "actor_loss": -38.52776644897461, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.11365532875061, "episode_reward": 427.7294536748923, "step": 89000}
{"episode": 90.0, "batch_reward": 0.38015393483638765, "critic_loss": 5.5768300554156305, "actor_loss": -38.63353067779541, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 468.4372365474701, "episode_reward": 449.769301231788, "step": 90000}
{"episode": 91.0, "batch_reward": 0.38058545944094657, "critic_loss": 4.286769577682018, "actor_loss": -38.79844452667236, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.49679756164551, "episode_reward": 441.2810284895714, "step": 91000}
{"episode": 92.0, "batch_reward": 0.3812647073566914, "critic_loss": 3.9578061541616916, "actor_loss": -38.99841326904297, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 481.3192608356476, "episode_reward": 417.9750923008776, "step": 92000}
{"episode": 93.0, "batch_reward": 0.3822807401418686, "critic_loss": 4.084452510297298, "actor_loss": -39.07264134216309, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.476428985595703, "episode_reward": 413.7240765128266, "step": 93000}
{"episode": 94.0, "batch_reward": 0.3819972103834152, "critic_loss": 3.2301774884164334, "actor_loss": -38.78217575836182, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 466.3189477920532, "episode_reward": 434.3234786984712, "step": 94000}
{"episode": 95.0, "batch_reward": 0.382462223470211, "critic_loss": 3.245912626057863, "actor_loss": -38.86160624694824, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.653185844421387, "episode_reward": 412.9234275464898, "step": 95000}
{"episode": 96.0, "batch_reward": 0.38260331881046294, "critic_loss": 3.204764928519726, "actor_loss": -39.32333618164063, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 488.98617124557495, "episode_reward": 240.1721412220231, "step": 96000}
{"episode": 97.0, "batch_reward": 0.3816570470035076, "critic_loss": 3.2271887218356134, "actor_loss": -39.14552185821533, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.43575668334961, "episode_reward": 427.91862887404346, "step": 97000}
{"episode": 98.0, "batch_reward": 0.38203462728857995, "critic_loss": 3.6722967491149903, "actor_loss": -39.166812629699706, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 461.8793103694916, "episode_reward": 417.4245258746598, "step": 98000}
{"episode": 99.0, "batch_reward": 0.3823762397170067, "critic_loss": 3.3679235104620457, "actor_loss": -39.122756538391116, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.01899480819702, "episode_reward": 427.3453318640373, "step": 99000}
{"episode": 100.0, "batch_reward": 0.3827758230268955, "critic_loss": 3.4182920157313346, "actor_loss": -39.39146131134033, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 438.0895380973816, "episode_reward": 424.98551480579056, "step": 100000}
{"episode": 101.0, "batch_reward": 0.3830113043189049, "critic_loss": 3.270050004422665, "actor_loss": -39.398767372131346, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.33028316497803, "episode_reward": 423.7040066906682, "step": 101000}
{"episode": 102.0, "batch_reward": 0.3837172476351261, "critic_loss": 3.2446949164867402, "actor_loss": -39.0834832611084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 467.0726981163025, "episode_reward": 438.70681009033103, "step": 102000}
{"episode": 103.0, "batch_reward": 0.3843357819318771, "critic_loss": 2.9119997486770153, "actor_loss": -39.197316856384276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.96732521057129, "episode_reward": 426.72938981897585, "step": 103000}
{"episode": 104.0, "batch_reward": 0.3845321775972843, "critic_loss": 2.8804522503614427, "actor_loss": -39.41961685943603, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 462.8730659484863, "episode_reward": 429.542350534971, "step": 104000}
{"episode": 105.0, "batch_reward": 0.38462776720523834, "critic_loss": 3.0988129977583885, "actor_loss": -39.438206817626956, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.09114146232605, "episode_reward": 444.56955537087595, "step": 105000}
{"episode": 106.0, "batch_reward": 0.3856501118838787, "critic_loss": 3.4752663949280977, "actor_loss": -40.130627853393555, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 495.70401191711426, "episode_reward": 414.14856708736113, "step": 106000}
{"episode": 107.0, "batch_reward": 0.3858960533440113, "critic_loss": 3.7389155943393706, "actor_loss": -40.15427568817139, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.577724933624268, "episode_reward": 422.0161821674306, "step": 107000}
{"episode": 108.0, "batch_reward": 0.38569235473871233, "critic_loss": 3.4832782334983348, "actor_loss": -39.84971186065674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 415.5375325679779, "episode_reward": 381.28070913915406, "step": 108000}
{"episode": 109.0, "batch_reward": 0.38567964726686477, "critic_loss": 3.7580134279727937, "actor_loss": -39.8393946762085, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.2584388256073, "episode_reward": 386.09573382726563, "step": 109000}
{"episode": 110.0, "batch_reward": 0.3856624800264835, "critic_loss": 3.9636060906648636, "actor_loss": -39.6353643951416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 461.5360412597656, "episode_reward": 359.33222658167256, "step": 110000}
{"episode": 111.0, "batch_reward": 0.3856360729932785, "critic_loss": 3.7904275220930574, "actor_loss": -39.779689178466796, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.457913875579834, "episode_reward": 360.53539515889844, "step": 111000}
{"episode": 112.0, "batch_reward": 0.38539714339375497, "critic_loss": 4.025007580637932, "actor_loss": -39.65374314880371, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 518.3596634864807, "episode_reward": 348.7218783563543, "step": 112000}
{"episode": 113.0, "batch_reward": 0.38449267187714575, "critic_loss": 3.822943908125162, "actor_loss": -39.62574270629883, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.782304048538208, "episode_reward": 374.60442418513395, "step": 113000}
{"episode": 114.0, "batch_reward": 0.38554190158843993, "critic_loss": 3.83844856479764, "actor_loss": -39.252600578308105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 539.4005227088928, "episode_reward": 407.2026062286895, "step": 114000}
{"episode": 115.0, "batch_reward": 0.3858716815114021, "critic_loss": 3.6163599333763123, "actor_loss": -39.26276973724365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.978711366653442, "episode_reward": 409.61372553212277, "step": 115000}
{"episode": 116.0, "batch_reward": 0.38544428697228433, "critic_loss": 3.470667278021574, "actor_loss": -39.928798683166505, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 488.7694568634033, "episode_reward": 418.2376166890645, "step": 116000}
{"episode": 117.0, "batch_reward": 0.38631746593117716, "critic_loss": 3.049741787582636, "actor_loss": -40.08213186645508, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.81515908241272, "episode_reward": 416.36190549763035, "step": 117000}
{"episode": 118.0, "batch_reward": 0.3863247624635696, "critic_loss": 2.677119857028127, "actor_loss": -39.39036995697022, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 488.15556740760803, "episode_reward": 432.0314944620966, "step": 118000}
{"episode": 119.0, "batch_reward": 0.38684195998311044, "critic_loss": 2.393682338923216, "actor_loss": -39.46334013366699, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.48793339729309, "episode_reward": 427.17935732343784, "step": 119000}
{"episode": 120.0, "batch_reward": 0.3871931563615799, "critic_loss": 2.500344096913934, "actor_loss": -39.434626647949216, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 484.1709690093994, "episode_reward": 434.1063603153726, "step": 120000}
{"episode": 121.0, "batch_reward": 0.3870673255622387, "critic_loss": 2.3784773368239405, "actor_loss": -39.43072717285156, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 41.28701901435852, "episode_reward": 405.70285762901165, "step": 121000}
{"episode": 122.0, "batch_reward": 0.38789438298344614, "critic_loss": 2.2907320423573254, "actor_loss": -39.73805505371094, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 463.85094356536865, "episode_reward": 432.6667499701245, "step": 122000}
{"episode": 123.0, "batch_reward": 0.38819326397776605, "critic_loss": 2.0572954559326173, "actor_loss": -39.69663474273682, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.111860036849976, "episode_reward": 436.46589689354306, "step": 123000}
{"episode": 124.0, "batch_reward": 0.3883028448820114, "critic_loss": 1.8259197166413068, "actor_loss": -39.51777305603027, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 476.92441296577454, "episode_reward": 445.18490558961435, "step": 124000}
{"episode": 125.0, "batch_reward": 0.38885775315761567, "critic_loss": 2.09314475466311, "actor_loss": -39.63098148345947, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.639591693878174, "episode_reward": 431.904625035415, "step": 125000}
{"episode": 126.0, "batch_reward": 0.388878327101469, "critic_loss": 2.296049485787749, "actor_loss": -39.18736045837402, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 493.8573055267334, "episode_reward": 418.7083692029561, "step": 126000}
{"episode": 127.0, "batch_reward": 0.3886664845645428, "critic_loss": 2.0024314695000647, "actor_loss": -39.28129400634766, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.72395944595337, "episode_reward": 396.6885124995497, "step": 127000}
{"episode": 128.0, "batch_reward": 0.3898205664157867, "critic_loss": 1.8752345739901066, "actor_loss": -39.61667247009277, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 511.9952518939972, "episode_reward": 426.16964643971863, "step": 128000}
{"episode": 129.0, "batch_reward": 0.38944249242544177, "critic_loss": 1.9988692248016595, "actor_loss": -39.442224365234374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.508012533187866, "episode_reward": 428.295325615176, "step": 129000}
{"episode": 130.0, "batch_reward": 0.39003694081306456, "critic_loss": 1.8825616641491651, "actor_loss": -39.18312615966797, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 470.0692057609558, "episode_reward": 432.87942220207503, "step": 130000}
{"episode": 131.0, "batch_reward": 0.39039845979213716, "critic_loss": 2.0759503267556427, "actor_loss": -39.33324939727783, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 42.49535417556763, "episode_reward": 437.6125437580012, "step": 131000}
{"episode": 132.0, "batch_reward": 0.39100105929374696, "critic_loss": 2.148932169660926, "actor_loss": -39.39946524810791, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 509.75354528427124, "episode_reward": 434.23049240061397, "step": 132000}
{"episode": 133.0, "batch_reward": 0.39062416344881057, "critic_loss": 2.699158834695816, "actor_loss": -39.32718632507324, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.7727210521698, "episode_reward": 411.47185459080026, "step": 133000}
{"episode": 134.0, "batch_reward": 0.3905356862843037, "critic_loss": 2.7023225715309382, "actor_loss": -39.27710060119629, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 469.8773567676544, "episode_reward": 397.73203414741994, "step": 134000}
{"episode": 135.0, "batch_reward": 0.39103985580801964, "critic_loss": 2.568387932986021, "actor_loss": -39.31715624237061, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.32356905937195, "episode_reward": 394.24685402104774, "step": 135000}
{"episode": 136.0, "batch_reward": 0.3910441641509533, "critic_loss": 2.504407787322998, "actor_loss": -39.464949127197265, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 472.699818611145, "episode_reward": 395.7821380156941, "step": 136000}
{"episode": 137.0, "batch_reward": 0.3917557037770748, "critic_loss": 3.1832862105369566, "actor_loss": -39.587573875427246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.08174443244934, "episode_reward": 414.72232809993636, "step": 137000}
{"episode": 138.0, "batch_reward": 0.3909509678483009, "critic_loss": 2.5012493281364443, "actor_loss": -39.37727934265137, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 507.5379877090454, "episode_reward": 409.8307926133669, "step": 138000}
{"episode": 139.0, "batch_reward": 0.3913129853606224, "critic_loss": 2.4761388260126114, "actor_loss": -39.379299110412596, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.750841856002808, "episode_reward": 422.0314815352209, "step": 139000}
{"episode": 140.0, "batch_reward": 0.39231787046790123, "critic_loss": 2.0871053887456656, "actor_loss": -39.44403343963623, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 449.7083833217621, "episode_reward": 407.36491905697153, "step": 140000}
{"episode": 141.0, "batch_reward": 0.3912220697402954, "critic_loss": 1.8823535826206208, "actor_loss": -39.328238441467285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 45.895265102386475, "episode_reward": 415.82354468080155, "step": 141000}
{"episode": 142.0, "batch_reward": 0.39142313712835314, "critic_loss": 1.76858489716053, "actor_loss": -38.74390308380127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 459.58826994895935, "episode_reward": 407.00915990706113, "step": 142000}
{"episode": 143.0, "batch_reward": 0.39242655727267267, "critic_loss": 1.528722280189395, "actor_loss": -38.89225550842285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.617990255355835, "episode_reward": 409.0167047624648, "step": 143000}
{"episode": 144.0, "batch_reward": 0.3917844149172306, "critic_loss": 1.6624302679896354, "actor_loss": -38.79734093475342, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 524.9051463603973, "episode_reward": 365.94639858207535, "step": 144000}
{"episode": 145.0, "batch_reward": 0.3911731245219707, "critic_loss": 1.5705334018021821, "actor_loss": -38.79444844055176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.222302436828613, "episode_reward": 401.2478877912729, "step": 145000}
{"episode": 146.0, "batch_reward": 0.3913184533715248, "critic_loss": 1.7690015020668506, "actor_loss": -38.91015660095215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 563.3394124507904, "episode_reward": 394.79213918567433, "step": 146000}
{"episode": 147.0, "batch_reward": 0.39220959636569025, "critic_loss": 2.1263839803040026, "actor_loss": -38.97016487121582, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.05491042137146, "episode_reward": 381.09440166970836, "step": 147000}
{"episode": 148.0, "batch_reward": 0.3919153805077076, "critic_loss": 2.0865536274164915, "actor_loss": -39.38093035125733, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 720.7602806091309, "episode_reward": 421.3446665829062, "step": 148000}
{"episode": 149.0, "batch_reward": 0.392357986330986, "critic_loss": 2.0584696728140117, "actor_loss": -39.49438025665283, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.428686380386353, "episode_reward": 408.6311978987115, "step": 149000}
{"episode": 150.0, "batch_reward": 0.3925779611468315, "critic_loss": 1.7993971778154374, "actor_loss": -39.58535734558105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
