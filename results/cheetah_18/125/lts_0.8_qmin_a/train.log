{"episode_reward": 0.0, "episode": 1.0, "duration": 17.917285919189453, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.5441203117370605, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.22299262689983657, "critic_loss": 0.05099694686344004, "actor_loss": -37.428053006051286, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 61.37685513496399, "step": 3000}
{"episode_reward": 105.68229780545491, "episode": 4.0, "batch_reward": 0.1757901503816247, "critic_loss": 0.06057532617263496, "actor_loss": -33.09886815389991, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.73777461051941, "step": 4000}
{"episode_reward": 56.87841513548816, "episode": 5.0, "batch_reward": 0.1417215878739953, "critic_loss": 0.052287170585244895, "actor_loss": -28.3827020233199, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.428967237472534, "step": 5000}
{"episode_reward": 21.289596647210583, "episode": 6.0, "batch_reward": 0.1172898310571909, "critic_loss": 0.04647788859717548, "actor_loss": -29.195597094468773, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.74635934829712, "step": 6000}
{"episode_reward": 19.08287041064856, "episode": 7.0, "batch_reward": 0.11094467359408736, "critic_loss": 0.0628639943189919, "actor_loss": -29.340536618366837, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.667847871780396, "step": 7000}
{"episode_reward": 145.66841293111526, "episode": 8.0, "batch_reward": 0.11356018324196339, "critic_loss": 0.08053395753726363, "actor_loss": -27.917627429559825, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.804115295410156, "step": 8000}
{"episode_reward": 52.279742606908584, "episode": 9.0, "batch_reward": 0.11233458569645882, "critic_loss": 0.09550806346908211, "actor_loss": -27.06804419337213, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.5470929145813, "step": 9000}
{"episode_reward": 150.3974881300227, "episode": 10.0, "batch_reward": 0.11424246970564127, "critic_loss": 0.10030069445446134, "actor_loss": -26.743353670597077, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.937864303588867, "step": 10000}
{"episode_reward": 92.1793503773418, "episode": 11.0, "batch_reward": 0.11526833905279636, "critic_loss": 0.10680401469394564, "actor_loss": -26.164634088486434, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.56370449066162, "step": 11000}
{"episode_reward": 142.279666054078, "episode": 12.0, "batch_reward": 0.1112141982614994, "critic_loss": 0.1043178932890296, "actor_loss": -24.68287287157774, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.79619002342224, "step": 12000}
{"episode_reward": 44.98991860586109, "episode": 13.0, "batch_reward": 0.10726370524615049, "critic_loss": 0.12065863179787993, "actor_loss": -24.178071862220765, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.20159339904785, "step": 13000}
{"episode_reward": 53.89470508291657, "episode": 14.0, "batch_reward": 0.1005292503759265, "critic_loss": 0.11615273072570563, "actor_loss": -22.46769014751911, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.10760474205017, "step": 14000}
{"episode_reward": 23.91995412824012, "episode": 15.0, "batch_reward": 0.1009522803798318, "critic_loss": 0.13126039374619722, "actor_loss": -24.487470726132393, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.429358959197998, "step": 15000}
{"episode_reward": 118.61505809237673, "episode": 16.0, "batch_reward": 0.10114051672071218, "critic_loss": 0.14040623135119676, "actor_loss": -23.068173986196516, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.532032251358032, "step": 16000}
{"episode_reward": 179.43364489621192, "episode": 17.0, "batch_reward": 0.10745561472326517, "critic_loss": 0.14939157409593462, "actor_loss": -24.098855591535568, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88064408302307, "step": 17000}
{"episode_reward": 145.5641342573951, "episode": 18.0, "batch_reward": 0.10628139930218458, "critic_loss": 0.15046096208691598, "actor_loss": -23.110809846878052, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.169920444488525, "step": 18000}
{"episode_reward": 58.22242672879923, "episode": 19.0, "batch_reward": 0.10204126270115375, "critic_loss": 0.15622105387598276, "actor_loss": -21.907608204841615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.062320947647095, "step": 19000}
{"episode_reward": 26.224695311485817, "episode": 20.0, "batch_reward": 0.10152952446043491, "critic_loss": 0.2211334481909871, "actor_loss": -22.652266452550887, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.148666858673096, "step": 20000}
{"episode_reward": 151.50182219507215, "episode": 21.0, "batch_reward": 0.10303703539073467, "critic_loss": 0.22378724060952662, "actor_loss": -22.727988278627397, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.30031752586365, "step": 21000}
{"episode_reward": 71.85686866189579, "episode": 22.0, "batch_reward": 0.09969026781618595, "critic_loss": 0.22821442517638207, "actor_loss": -22.01991790509224, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.068400144577026, "step": 22000}
{"episode_reward": 27.4649107186163, "episode": 23.0, "batch_reward": 0.09914445179328323, "critic_loss": 0.2621199154481292, "actor_loss": -22.50779534125328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.624439477920532, "step": 23000}
{"episode_reward": 102.00396347625434, "episode": 24.0, "batch_reward": 0.10173948772624135, "critic_loss": 0.33376117556542156, "actor_loss": -22.26819231557846, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.69994878768921, "step": 24000}
{"episode_reward": 208.2375099066621, "episode": 25.0, "batch_reward": 0.1032663556560874, "critic_loss": 0.3232024405747652, "actor_loss": -21.7780981361866, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.248545169830322, "step": 25000}
{"episode_reward": 80.46112025901341, "episode": 26.0, "batch_reward": 0.10033576822280883, "critic_loss": 0.26207620418816807, "actor_loss": -22.190486482143402, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.12506604194641, "step": 26000}
{"episode_reward": 28.495195867095816, "episode": 27.0, "batch_reward": 0.10181106316298247, "critic_loss": 0.2771587352603674, "actor_loss": -21.581595256328583, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.72243094444275, "step": 27000}
{"episode_reward": 245.99519537499964, "episode": 28.0, "batch_reward": 0.10312888212502003, "critic_loss": 0.4013561625927687, "actor_loss": -21.303678916692732, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.745789527893066, "step": 28000}
{"episode_reward": 33.563014355968754, "episode": 29.0, "batch_reward": 0.1006682676449418, "critic_loss": 0.38645296669006346, "actor_loss": -21.405044634103774, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.635313034057617, "step": 29000}
{"episode_reward": 35.01077512905745, "episode": 30.0, "batch_reward": 0.10220030516386032, "critic_loss": 0.4446206378787756, "actor_loss": -21.060282029390336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.6943838596344, "step": 30000}
{"episode_reward": 156.66963126650924, "episode": 31.0, "batch_reward": 0.102491339687258, "critic_loss": 0.41030295328795907, "actor_loss": -21.21032532262802, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.78021192550659, "step": 31000}
{"episode_reward": 209.37751370091257, "episode": 32.0, "batch_reward": 0.10568385598063469, "critic_loss": 0.44269440817832945, "actor_loss": -21.223530058860778, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.67459797859192, "step": 32000}
{"episode_reward": 116.50100195374164, "episode": 33.0, "batch_reward": 0.10707486173510551, "critic_loss": 0.4153573382049799, "actor_loss": -21.98731020593643, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.514671087265015, "step": 33000}
{"episode_reward": 230.93556138517874, "episode": 34.0, "batch_reward": 0.10851080194115639, "critic_loss": 0.40057362093031407, "actor_loss": -21.446851904869078, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.61416721343994, "step": 34000}
{"episode_reward": 48.558604137497916, "episode": 35.0, "batch_reward": 0.10733502635359764, "critic_loss": 0.4477362272441387, "actor_loss": -22.160742067813874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.677948474884033, "step": 35000}
{"episode_reward": 85.5063941575288, "episode": 36.0, "batch_reward": 0.10772016306966543, "critic_loss": 0.44847403982281686, "actor_loss": -21.016215053558348, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.789637327194214, "step": 36000}
{"episode_reward": 89.05797157914533, "episode": 37.0, "batch_reward": 0.1075109321847558, "critic_loss": 0.5480593332797289, "actor_loss": -21.8032481713295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.141603708267212, "step": 37000}
{"episode_reward": 311.98966992469684, "episode": 38.0, "batch_reward": 0.1116614297479391, "critic_loss": 0.578630042091012, "actor_loss": -22.10737520456314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.228232860565186, "step": 38000}
{"episode_reward": 62.96243190597663, "episode": 39.0, "batch_reward": 0.11227801528573036, "critic_loss": 0.5249124308377504, "actor_loss": -22.092944986343383, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.098777055740356, "step": 39000}
{"episode_reward": 138.86932079517013, "episode": 40.0, "batch_reward": 0.11138733794540166, "critic_loss": 0.4833984852582216, "actor_loss": -22.097800407886506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.456810235977173, "step": 40000}
{"episode_reward": 64.80218314650791, "episode": 41.0, "batch_reward": 0.10998343314230442, "critic_loss": 0.46526238721609114, "actor_loss": -21.974433572292327, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.33749055862427, "step": 41000}
{"episode_reward": 82.51447914572327, "episode": 42.0, "batch_reward": 0.11028986103087664, "critic_loss": 0.5118578659147024, "actor_loss": -21.119970616817476, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.356815814971924, "step": 42000}
{"episode_reward": 142.60613869892967, "episode": 43.0, "batch_reward": 0.1114575507491827, "critic_loss": 0.5151487618982792, "actor_loss": -21.367395534038543, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.744112730026245, "step": 43000}
{"episode_reward": 181.9981195978805, "episode": 44.0, "batch_reward": 0.11126691007614135, "critic_loss": 0.5239710344523192, "actor_loss": -21.193883548736572, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.16252040863037, "step": 44000}
{"episode_reward": 57.37686365042713, "episode": 45.0, "batch_reward": 0.11192496332526207, "critic_loss": 0.526367019161582, "actor_loss": -21.1407191696167, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.283989906311035, "step": 45000}
{"episode_reward": 97.13132035683323, "episode": 46.0, "batch_reward": 0.10934971307218075, "critic_loss": 0.5567143525630236, "actor_loss": -20.64081122303009, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.733747482299805, "step": 46000}
{"episode_reward": 56.9633906361619, "episode": 47.0, "batch_reward": 0.11080499773472548, "critic_loss": 0.6253436951041221, "actor_loss": -21.28485327386856, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.108402967453003, "step": 47000}
{"episode_reward": 164.2902426733225, "episode": 48.0, "batch_reward": 0.10984792374074459, "critic_loss": 0.7234684610664844, "actor_loss": -20.814250501632692, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.136190176010132, "step": 48000}
{"episode_reward": 31.236802348686837, "episode": 49.0, "batch_reward": 0.10970887699723243, "critic_loss": 0.767731952264905, "actor_loss": -21.294624612808228, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.19215226173401, "step": 49000}
{"episode_reward": 117.4623525542842, "episode": 50.0, "batch_reward": 0.11006849423050881, "critic_loss": 0.6511476345062256, "actor_loss": -20.965965865135193, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.051005363464355, "step": 50000}
{"episode_reward": 251.15011668651172, "episode": 51.0, "batch_reward": 0.11310402569919825, "critic_loss": 0.6656059580594301, "actor_loss": -21.274544846534727, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.45557641983032, "step": 51000}
{"episode_reward": 165.63658573719286, "episode": 52.0, "batch_reward": 0.11461612316966056, "critic_loss": 0.6124824978560209, "actor_loss": -21.312891978263856, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.07803988456726, "step": 52000}
{"episode_reward": 317.38644984233713, "episode": 53.0, "batch_reward": 0.11843236143141984, "critic_loss": 0.6325980098545552, "actor_loss": -21.885647212982178, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.82038187980652, "step": 53000}
{"episode_reward": 328.2745617050633, "episode": 54.0, "batch_reward": 0.12179092908650636, "critic_loss": 0.6003716985732317, "actor_loss": -21.960074699401854, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.54744815826416, "step": 54000}
{"episode_reward": 221.8888381833737, "episode": 55.0, "batch_reward": 0.12287251421064138, "critic_loss": 0.5823599373698235, "actor_loss": -22.641410183906554, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.611212253570557, "step": 55000}
{"episode_reward": 130.59300739901514, "episode": 56.0, "batch_reward": 0.12394202882051468, "critic_loss": 0.6879077784866094, "actor_loss": -22.559511085510255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.71325397491455, "step": 56000}
{"episode_reward": 224.92165487386234, "episode": 57.0, "batch_reward": 0.12670342740416526, "critic_loss": 0.8212926720380783, "actor_loss": -22.261173846244812, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.482202291488647, "step": 57000}
{"episode_reward": 373.35432500780735, "episode": 58.0, "batch_reward": 0.13090347959846257, "critic_loss": 0.7020422815829516, "actor_loss": -22.776064567565918, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.12300705909729, "step": 58000}
{"episode_reward": 397.01134227888207, "episode": 59.0, "batch_reward": 0.13571328404545785, "critic_loss": 0.6108793769329787, "actor_loss": -22.937862511634826, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.738312244415283, "step": 59000}
{"episode_reward": 397.684679902762, "episode": 60.0, "batch_reward": 0.14032750295102597, "critic_loss": 0.5981389574259519, "actor_loss": -23.590274602890016, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.219364404678345, "step": 60000}
{"episode_reward": 397.971797094684, "episode": 61.0, "batch_reward": 0.1450591952651739, "critic_loss": 0.5506717131733895, "actor_loss": -23.769524610519408, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.32934379577637, "step": 61000}
{"episode_reward": 406.74071857771406, "episode": 62.0, "batch_reward": 0.14862599722296, "critic_loss": 0.6350802106559277, "actor_loss": -24.852203442573547, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.08697271347046, "step": 62000}
{"episode_reward": 376.9949699236, "episode": 63.0, "batch_reward": 0.15205913756787776, "critic_loss": 0.589941108584404, "actor_loss": -24.800276469230653, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.124588012695312, "step": 63000}
{"episode_reward": 405.92006048257275, "episode": 64.0, "batch_reward": 0.15644278579205276, "critic_loss": 0.6081136940866709, "actor_loss": -25.156628898620607, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.755589485168457, "step": 64000}
{"episode_reward": 423.9493353388602, "episode": 65.0, "batch_reward": 0.1605236978009343, "critic_loss": 0.6106569119393825, "actor_loss": -25.33689453125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.784297943115234, "step": 65000}
{"episode_reward": 440.71441072168824, "episode": 66.0, "batch_reward": 0.16495848149061204, "critic_loss": 0.60235206399858, "actor_loss": -25.788623872756958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.991372108459473, "step": 66000}
{"episode_reward": 404.46701750087107, "episode": 67.0, "batch_reward": 0.16773477862030267, "critic_loss": 0.6226626171767712, "actor_loss": -26.251488258361817, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.24239993095398, "step": 67000}
{"episode_reward": 388.5191920898612, "episode": 68.0, "batch_reward": 0.1718887359648943, "critic_loss": 0.6140991249382496, "actor_loss": -26.524980262756348, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.903374433517456, "step": 68000}
{"episode_reward": 406.7049368581485, "episode": 69.0, "batch_reward": 0.17516685090959072, "critic_loss": 0.6550660921186209, "actor_loss": -26.93479204940796, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.200929641723633, "step": 69000}
{"episode_reward": 435.6083370190284, "episode": 70.0, "batch_reward": 0.1786289671510458, "critic_loss": 0.7154281943291426, "actor_loss": -27.334772340774535, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.929277181625366, "step": 70000}
{"episode_reward": 414.2075380291218, "episode": 71.0, "batch_reward": 0.18229408358037472, "critic_loss": 0.7715988246947527, "actor_loss": -27.829579164505006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.66789364814758, "step": 71000}
{"episode_reward": 404.0189034365189, "episode": 72.0, "batch_reward": 0.18530479414761067, "critic_loss": 0.8449371815621853, "actor_loss": -28.075110132217407, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.341344118118286, "step": 72000}
{"episode_reward": 420.90384825092974, "episode": 73.0, "batch_reward": 0.18876755917072296, "critic_loss": 1.011743106931448, "actor_loss": -28.210984895706176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.25920343399048, "step": 73000}
{"episode_reward": 404.50232538158247, "episode": 74.0, "batch_reward": 0.19085581171512603, "critic_loss": 0.9007346919476986, "actor_loss": -29.01468096923828, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.0441472530365, "step": 74000}
{"episode_reward": 394.9619712629067, "episode": 75.0, "batch_reward": 0.19505458000302314, "critic_loss": 0.7172050585150719, "actor_loss": -28.984692781448363, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.691559076309204, "step": 75000}
{"episode_reward": 425.73938963841675, "episode": 76.0, "batch_reward": 0.19638540679216385, "critic_loss": 0.6516761166453362, "actor_loss": -29.352927492141724, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.755292892456055, "step": 76000}
{"episode_reward": 239.52092976076293, "episode": 77.0, "batch_reward": 0.19724494808912277, "critic_loss": 0.6435969578325749, "actor_loss": -29.204457191467284, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.81700611114502, "step": 77000}
{"episode_reward": 413.0841311856574, "episode": 78.0, "batch_reward": 0.2011834474056959, "critic_loss": 0.6026124395728111, "actor_loss": -29.919814531326296, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.058613777160645, "step": 78000}
{"episode_reward": 422.8935544073616, "episode": 79.0, "batch_reward": 0.20275753985345363, "critic_loss": 0.573444420799613, "actor_loss": -29.06811323928833, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.819534301757812, "step": 79000}
{"episode_reward": 411.89653770675295, "episode": 80.0, "batch_reward": 0.20611235909163952, "critic_loss": 0.5394658968150615, "actor_loss": -29.965091871261595, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.938527822494507, "step": 80000}
{"episode_reward": 451.59781071594665, "episode": 81.0, "batch_reward": 0.20993334467709066, "critic_loss": 0.5726615049540996, "actor_loss": -30.22875393104553, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.64009404182434, "step": 81000}
{"episode_reward": 407.9880026306368, "episode": 82.0, "batch_reward": 0.21196405535936355, "critic_loss": 0.5309581431746483, "actor_loss": -31.24899427986145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.15990710258484, "step": 82000}
{"episode_reward": 390.59621290757576, "episode": 83.0, "batch_reward": 0.21462146370112897, "critic_loss": 0.5620100737512111, "actor_loss": -30.611072923660277, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89832043647766, "step": 83000}
{"episode_reward": 414.15741517252155, "episode": 84.0, "batch_reward": 0.21605779787898063, "critic_loss": 0.5352017303854227, "actor_loss": -31.76459828186035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.249504327774048, "step": 84000}
{"episode_reward": 373.82319970283726, "episode": 85.0, "batch_reward": 0.21842862474918365, "critic_loss": 0.5289218489825726, "actor_loss": -31.301074075698853, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.98381209373474, "step": 85000}
{"episode_reward": 428.66984360022184, "episode": 86.0, "batch_reward": 0.2190136723816395, "critic_loss": 0.5020992436110974, "actor_loss": -31.35213063621521, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.793263912200928, "step": 86000}
{"episode_reward": 112.00877125474899, "episode": 87.0, "batch_reward": 0.21890803590416907, "critic_loss": 0.5055496963858604, "actor_loss": -31.205297786712645, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.338611841201782, "step": 87000}
{"episode_reward": 381.4314025045303, "episode": 88.0, "batch_reward": 0.22039937089383602, "critic_loss": 0.5338642841279506, "actor_loss": -31.042688020706176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.788610219955444, "step": 88000}
{"episode_reward": 434.29346192711847, "episode": 89.0, "batch_reward": 0.22379269802570342, "critic_loss": 0.5065323153734207, "actor_loss": -31.775967866897584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.70663833618164, "step": 89000}
{"episode_reward": 370.0178316650159, "episode": 90.0, "batch_reward": 0.22518180420994757, "critic_loss": 0.5579303587526083, "actor_loss": -32.080945011138915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.517411947250366, "step": 90000}
{"episode_reward": 415.7246644585768, "episode": 91.0, "batch_reward": 0.22678387673199177, "critic_loss": 0.49219449070096016, "actor_loss": -31.973316230773925, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.69809889793396, "step": 91000}
{"episode_reward": 361.0149975203262, "episode": 92.0, "batch_reward": 0.22875856982171536, "critic_loss": 0.47695912742614743, "actor_loss": -32.04842945098877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.626772165298462, "step": 92000}
{"episode_reward": 402.235097524364, "episode": 93.0, "batch_reward": 0.23025314338505268, "critic_loss": 0.4985762482136488, "actor_loss": -32.03812993049622, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.668622255325317, "step": 93000}
{"episode_reward": 367.96860423931867, "episode": 94.0, "batch_reward": 0.23140492762625217, "critic_loss": 0.5487067291736603, "actor_loss": -32.40157010269165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93723464012146, "step": 94000}
{"episode_reward": 409.16261819068575, "episode": 95.0, "batch_reward": 0.2334272509366274, "critic_loss": 0.5673639257401228, "actor_loss": -32.737298986434936, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.022118091583252, "step": 95000}
{"episode_reward": 345.8391149175981, "episode": 96.0, "batch_reward": 0.23413490590453148, "critic_loss": 0.5959030151814222, "actor_loss": -32.85468857765198, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.838902711868286, "step": 96000}
{"episode_reward": 293.37346619017677, "episode": 97.0, "batch_reward": 0.23508067566156388, "critic_loss": 0.531954752445221, "actor_loss": -33.29734772872925, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97676110267639, "step": 97000}
{"episode_reward": 364.222971973708, "episode": 98.0, "batch_reward": 0.23738721466064452, "critic_loss": 0.5821070881485939, "actor_loss": -33.129427339553835, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.02319359779358, "step": 98000}
{"episode_reward": 386.08786633976655, "episode": 99.0, "batch_reward": 0.23846257504820823, "critic_loss": 0.5542903573811054, "actor_loss": -32.79801101875305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93526530265808, "step": 99000}
{"episode_reward": 160.8952619096602, "episode": 100.0, "batch_reward": 0.2375550139248371, "critic_loss": 0.5920174499899149, "actor_loss": -32.91728472328186, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.27207088470459, "step": 100000}
{"episode_reward": 387.36414046517865, "episode": 101.0, "batch_reward": 0.23880038414895535, "critic_loss": 0.6025377659499646, "actor_loss": -33.04047838783264, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.051960468292236, "step": 101000}
{"episode_reward": 390.1802721501761, "episode": 102.0, "batch_reward": 0.23940116593241692, "critic_loss": 0.6063681501299143, "actor_loss": -32.960677335739135, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.124433040618896, "step": 102000}
{"episode_reward": 412.48012586988335, "episode": 103.0, "batch_reward": 0.24197111089527606, "critic_loss": 0.5384332754313946, "actor_loss": -33.58412689590454, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.98393940925598, "step": 103000}
{"episode_reward": 413.6751286967551, "episode": 104.0, "batch_reward": 0.24451612433791162, "critic_loss": 0.5623026202917099, "actor_loss": -33.797303035736086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.248334407806396, "step": 104000}
{"episode_reward": 390.96906901747855, "episode": 105.0, "batch_reward": 0.24551004058122636, "critic_loss": 0.5261218997389078, "actor_loss": -33.75199654006958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.341814279556274, "step": 105000}
{"episode_reward": 451.0189450978032, "episode": 106.0, "batch_reward": 0.24762962007522582, "critic_loss": 0.5355354822427034, "actor_loss": -33.873556827545166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.061140775680542, "step": 106000}
{"episode_reward": 440.8649099519698, "episode": 107.0, "batch_reward": 0.24904092110693454, "critic_loss": 0.5899167136698962, "actor_loss": -34.243702590942384, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.839482307434082, "step": 107000}
{"episode_reward": 449.68656003442675, "episode": 108.0, "batch_reward": 0.25132520267367364, "critic_loss": 0.5953099484890699, "actor_loss": -34.152238475799564, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.663511514663696, "step": 108000}
{"episode_reward": 415.2462414893593, "episode": 109.0, "batch_reward": 0.25309902089834213, "critic_loss": 0.5933566877096892, "actor_loss": -35.023481002807614, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.66252875328064, "step": 109000}
{"episode_reward": 424.1126693269655, "episode": 110.0, "batch_reward": 0.25366863611340523, "critic_loss": 0.5687190880179405, "actor_loss": -34.801890224456784, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.81142520904541, "step": 110000}
{"episode_reward": 433.8107322810875, "episode": 111.0, "batch_reward": 0.255653195425868, "critic_loss": 0.5798036325573921, "actor_loss": -35.02801547431946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.10980463027954, "step": 111000}
{"episode_reward": 436.50747524746606, "episode": 112.0, "batch_reward": 0.25685802987217904, "critic_loss": 0.5582143061459065, "actor_loss": -34.42669444656372, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.270747661590576, "step": 112000}
{"episode_reward": 449.5796243236946, "episode": 113.0, "batch_reward": 0.25844273808598517, "critic_loss": 0.5904459458291531, "actor_loss": -34.974313610076905, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.28038001060486, "step": 113000}
{"episode_reward": 459.928257467119, "episode": 114.0, "batch_reward": 0.26098172208666803, "critic_loss": 0.5110003532320261, "actor_loss": -35.64029262161255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.954466104507446, "step": 114000}
{"episode_reward": 445.8280527565883, "episode": 115.0, "batch_reward": 0.2622675409168005, "critic_loss": 0.5815575303435325, "actor_loss": -35.31712812423706, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97797465324402, "step": 115000}
{"episode_reward": 319.6523136102666, "episode": 116.0, "batch_reward": 0.2635694649666548, "critic_loss": 0.6005723552703858, "actor_loss": -35.44809685516358, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.388049125671387, "step": 116000}
{"episode_reward": 404.26350824466147, "episode": 117.0, "batch_reward": 0.2648004324287176, "critic_loss": 0.5889279209524393, "actor_loss": -35.35234348297119, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.77916121482849, "step": 117000}
{"episode_reward": 440.08880181358774, "episode": 118.0, "batch_reward": 0.26427765014767646, "critic_loss": 0.6009711791872978, "actor_loss": -35.45039874649048, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.66709589958191, "step": 118000}
{"episode_reward": 116.27544870871522, "episode": 119.0, "batch_reward": 0.2641958201080561, "critic_loss": 0.5824857551306486, "actor_loss": -35.55313156890869, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.673243284225464, "step": 119000}
{"episode_reward": 403.9136876845122, "episode": 120.0, "batch_reward": 0.265155628323555, "critic_loss": 0.5816872243136167, "actor_loss": -35.4475920677185, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.892686128616333, "step": 120000}
{"episode_reward": 452.39290320793145, "episode": 121.0, "batch_reward": 0.26744355651736257, "critic_loss": 0.5411834361255169, "actor_loss": -35.346327537536624, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.85212707519531, "step": 121000}
{"episode_reward": 460.535522448317, "episode": 122.0, "batch_reward": 0.2691117239147425, "critic_loss": 0.5692977516800165, "actor_loss": -35.75297498321533, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.06542944908142, "step": 122000}
{"episode_reward": 459.9138975982589, "episode": 123.0, "batch_reward": 0.27091758935153487, "critic_loss": 0.5737318478226662, "actor_loss": -35.304194004058836, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.856854915618896, "step": 123000}
{"episode_reward": 420.21693287251867, "episode": 124.0, "batch_reward": 0.2721126269549131, "critic_loss": 0.5896253902465105, "actor_loss": -35.96251577758789, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.091400384902954, "step": 124000}
{"episode_reward": 429.9000245023324, "episode": 125.0, "batch_reward": 0.27307230769097807, "critic_loss": 0.5302502622455358, "actor_loss": -35.777101081848144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.114861726760864, "step": 125000}
{"episode_reward": 440.2549641086541, "episode": 126.0, "batch_reward": 0.27308918291330336, "critic_loss": 0.5187489754706621, "actor_loss": -35.585601928710936, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.022198915481567, "step": 126000}
{"episode_reward": 437.84605365245193, "episode": 127.0, "batch_reward": 0.27526303167641164, "critic_loss": 0.5154448731690645, "actor_loss": -36.38254459381103, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.806914806365967, "step": 127000}
{"episode_reward": 458.6536816699683, "episode": 128.0, "batch_reward": 0.2766446747034788, "critic_loss": 0.532120318889618, "actor_loss": -37.079976573944094, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.80371332168579, "step": 128000}
{"episode_reward": 438.2305541430201, "episode": 129.0, "batch_reward": 0.27738422636687754, "critic_loss": 0.5661962987631559, "actor_loss": -36.73773202133179, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.8686683177948, "step": 129000}
{"episode_reward": 413.71635533779335, "episode": 130.0, "batch_reward": 0.2794160556346178, "critic_loss": 0.5722083098143339, "actor_loss": -36.72449545669556, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.572829961776733, "step": 130000}
{"episode_reward": 466.42304966416157, "episode": 131.0, "batch_reward": 0.28162850145995616, "critic_loss": 0.5446033283472062, "actor_loss": -37.32839761352539, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.860066175460815, "step": 131000}
{"episode_reward": 460.72560757807855, "episode": 132.0, "batch_reward": 0.2820996435731649, "critic_loss": 0.5140010700672865, "actor_loss": -37.31933727264404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.139851570129395, "step": 132000}
{"episode_reward": 401.59469839060085, "episode": 133.0, "batch_reward": 0.28287134556472304, "critic_loss": 0.567278017282486, "actor_loss": -37.18893009948731, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.833810329437256, "step": 133000}
{"episode_reward": 474.10737743117926, "episode": 134.0, "batch_reward": 0.28409792421758173, "critic_loss": 0.5655043604373932, "actor_loss": -37.49143193435669, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.071916103363037, "step": 134000}
{"episode_reward": 426.7968300496146, "episode": 135.0, "batch_reward": 0.2854407810717821, "critic_loss": 0.5572683400809765, "actor_loss": -37.46733294677735, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.10909652709961, "step": 135000}
{"episode_reward": 441.6490978700736, "episode": 136.0, "batch_reward": 0.2860652530193329, "critic_loss": 0.5825809130221605, "actor_loss": -38.06692895126343, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.820688247680664, "step": 136000}
{"episode_reward": 448.0810867680502, "episode": 137.0, "batch_reward": 0.2870000786781311, "critic_loss": 0.5549945111423731, "actor_loss": -37.762840515136716, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.83358144760132, "step": 137000}
{"episode_reward": 435.2259843304716, "episode": 138.0, "batch_reward": 0.28835340701043605, "critic_loss": 0.5219564843922854, "actor_loss": -36.98242253112793, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.934031009674072, "step": 138000}
{"episode_reward": 495.8723250830453, "episode": 139.0, "batch_reward": 0.2904215028136969, "critic_loss": 0.5259279754310846, "actor_loss": -37.46967485046387, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.041465997695923, "step": 139000}
{"episode_reward": 457.87722386118907, "episode": 140.0, "batch_reward": 0.29048948401212693, "critic_loss": 0.5529495245814323, "actor_loss": -37.11941879653931, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.360891342163086, "step": 140000}
{"episode_reward": 453.1550693219641, "episode": 141.0, "batch_reward": 0.292372196033597, "critic_loss": 0.5166767999678851, "actor_loss": -37.59662079238892, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.65392279624939, "step": 141000}
{"episode_reward": 433.9686736998581, "episode": 142.0, "batch_reward": 0.29264494341611863, "critic_loss": 0.533848278194666, "actor_loss": -37.72278030014038, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.707510471343994, "step": 142000}
{"episode_reward": 437.84778020332794, "episode": 143.0, "batch_reward": 0.29510515730082987, "critic_loss": 0.48027864055335523, "actor_loss": -38.30003593063355, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.064676761627197, "step": 143000}
{"episode_reward": 441.5068085567443, "episode": 144.0, "batch_reward": 0.29631011551618575, "critic_loss": 0.5075321083813906, "actor_loss": -38.406537269592285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.717891216278076, "step": 144000}
{"episode_reward": 432.9310630309555, "episode": 145.0, "batch_reward": 0.2971510369181633, "critic_loss": 0.516390204384923, "actor_loss": -38.262885261535644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.850830793380737, "step": 145000}
{"episode_reward": 422.74810930821894, "episode": 146.0, "batch_reward": 0.29751891273260117, "critic_loss": 0.5339242022037506, "actor_loss": -38.28983309173584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.70622158050537, "step": 146000}
{"episode_reward": 443.57637210690353, "episode": 147.0, "batch_reward": 0.2982992233335972, "critic_loss": 0.4842331087142229, "actor_loss": -38.79073587036133, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.72139263153076, "step": 147000}
{"episode_reward": 421.18478927544726, "episode": 148.0, "batch_reward": 0.299577507391572, "critic_loss": 0.47795333158969877, "actor_loss": -38.48639504241943, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.841912508010864, "step": 148000}
{"episode_reward": 495.1488260662801, "episode": 149.0, "batch_reward": 0.30115067437291143, "critic_loss": 0.5113705497831106, "actor_loss": -38.84165900039673, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.839287519454956, "step": 149000}
{"episode_reward": 429.53456684892114, "episode": 150.0, "batch_reward": 0.3013068098127842, "critic_loss": 0.49287213099002836, "actor_loss": -38.39156848526001, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
