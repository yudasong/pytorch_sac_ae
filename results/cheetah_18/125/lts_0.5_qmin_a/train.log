{"episode_reward": 0.0, "episode": 1.0, "duration": 17.31017827987671, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.4835209846496582, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.21995729249729717, "critic_loss": 0.04245107800309416, "actor_loss": -23.950672325006323, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 60.41101598739624, "step": 3000}
{"episode_reward": 45.06965053620746, "episode": 4.0, "batch_reward": 0.1485379940420389, "critic_loss": 0.039024964672513304, "actor_loss": -22.907630630016328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97028923034668, "step": 4000}
{"episode_reward": 16.05384275576674, "episode": 5.0, "batch_reward": 0.11961116198450326, "critic_loss": 0.04449456663802266, "actor_loss": -19.338711770772935, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.99497938156128, "step": 5000}
{"episode_reward": 30.693753734066366, "episode": 6.0, "batch_reward": 0.108891760610044, "critic_loss": 0.05927204872108996, "actor_loss": -19.22275981235504, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95490074157715, "step": 6000}
{"episode_reward": 61.62712443494156, "episode": 7.0, "batch_reward": 0.11289588551968337, "critic_loss": 0.07203171537816525, "actor_loss": -19.849054122447967, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.959644317626953, "step": 7000}
{"episode_reward": 198.4511390981622, "episode": 8.0, "batch_reward": 0.121731301240623, "critic_loss": 0.089296143963933, "actor_loss": -20.08795139312744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.98409342765808, "step": 8000}
{"episode_reward": 185.71334285108924, "episode": 9.0, "batch_reward": 0.12860832469910383, "critic_loss": 0.11224137928709388, "actor_loss": -20.833148532390595, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93026089668274, "step": 9000}
{"episode_reward": 175.86263947907628, "episode": 10.0, "batch_reward": 0.12745455199480057, "critic_loss": 0.12471930115297437, "actor_loss": -19.973023223876954, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9593825340271, "step": 10000}
{"episode_reward": 37.46132334967483, "episode": 11.0, "batch_reward": 0.11953973864763975, "critic_loss": 0.12467618595808744, "actor_loss": -20.07529948234558, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.409088134765625, "step": 11000}
{"episode_reward": 48.735831596603184, "episode": 12.0, "batch_reward": 0.11344663969427347, "critic_loss": 0.12859364308416843, "actor_loss": -18.675646881103514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.982606887817383, "step": 12000}
{"episode_reward": 57.671164965129236, "episode": 13.0, "batch_reward": 0.10841794480383396, "critic_loss": 0.15896083319932222, "actor_loss": -17.577263287067414, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.151474475860596, "step": 13000}
{"episode_reward": 46.062919122767184, "episode": 14.0, "batch_reward": 0.10259880756214261, "critic_loss": 0.17741057220101356, "actor_loss": -16.485526272773743, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.130695343017578, "step": 14000}
{"episode_reward": 32.46145640285241, "episode": 15.0, "batch_reward": 0.09818081731349229, "critic_loss": 0.18868897543102503, "actor_loss": -17.786256066322327, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.919076681137085, "step": 15000}
{"episode_reward": 29.737162769480605, "episode": 16.0, "batch_reward": 0.09569363877177238, "critic_loss": 0.19864638133347035, "actor_loss": -17.504762793540955, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.943543434143066, "step": 16000}
{"episode_reward": 83.9955192206498, "episode": 17.0, "batch_reward": 0.09374090111628175, "critic_loss": 0.24871629606932402, "actor_loss": -16.445613191604615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.262342929840088, "step": 17000}
{"episode_reward": 36.30855354121622, "episode": 18.0, "batch_reward": 0.08989851919561624, "critic_loss": 0.2798099669069052, "actor_loss": -15.765910586357117, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.99134874343872, "step": 18000}
{"episode_reward": 18.446415433425955, "episode": 19.0, "batch_reward": 0.08800656236335636, "critic_loss": 0.267637822329998, "actor_loss": -16.060533421516418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95674729347229, "step": 19000}
{"episode_reward": 75.66340194046707, "episode": 20.0, "batch_reward": 0.08642055700719356, "critic_loss": 0.3188380289897323, "actor_loss": -16.150410655975342, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.930795669555664, "step": 20000}
{"episode_reward": 70.0695048934204, "episode": 21.0, "batch_reward": 0.08601000627875328, "critic_loss": 0.35421083725988867, "actor_loss": -16.522471648216246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.417893409729004, "step": 21000}
{"episode_reward": 62.18298731374396, "episode": 22.0, "batch_reward": 0.08755206970870495, "critic_loss": 0.43344860237836835, "actor_loss": -16.226753614425657, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.98925232887268, "step": 22000}
{"episode_reward": 159.83560137632114, "episode": 23.0, "batch_reward": 0.09180573557689786, "critic_loss": 0.4965007337033749, "actor_loss": -16.874184950828553, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.964688301086426, "step": 23000}
{"episode_reward": 260.7831679156767, "episode": 24.0, "batch_reward": 0.09803716224431992, "critic_loss": 0.49963095018267634, "actor_loss": -18.407911833763123, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.94088625907898, "step": 24000}
{"episode_reward": 235.8551170332548, "episode": 25.0, "batch_reward": 0.10530031601339579, "critic_loss": 0.4762918682396412, "actor_loss": -18.702024921417237, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.967764139175415, "step": 25000}
{"episode_reward": 299.3510728277602, "episode": 26.0, "batch_reward": 0.11005280729383231, "critic_loss": 0.530714086189866, "actor_loss": -19.095147840499877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96891188621521, "step": 26000}
{"episode_reward": 100.20461013418998, "episode": 27.0, "batch_reward": 0.10860706967115402, "critic_loss": 0.395104198589921, "actor_loss": -18.720748573303222, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91905164718628, "step": 27000}
{"episode_reward": 49.66469954562713, "episode": 28.0, "batch_reward": 0.1043019393235445, "critic_loss": 0.3112530886828899, "actor_loss": -18.507851068496706, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.961236238479614, "step": 28000}
{"episode_reward": 12.27231636420515, "episode": 29.0, "batch_reward": 0.10287026563286782, "critic_loss": 0.37282351340353487, "actor_loss": -19.0074765625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.974733591079712, "step": 29000}
{"episode_reward": 39.06397448218084, "episode": 30.0, "batch_reward": 0.10024072176590562, "critic_loss": 0.38294332212954757, "actor_loss": -18.514198377609254, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.94754719734192, "step": 30000}
{"episode_reward": 46.84047309077512, "episode": 31.0, "batch_reward": 0.10381233185529709, "critic_loss": 0.3792999638468027, "actor_loss": -18.952249935150146, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.3422155380249, "step": 31000}
{"episode_reward": 379.75118157233425, "episode": 32.0, "batch_reward": 0.10890312737971544, "critic_loss": 0.35211862581968306, "actor_loss": -19.380198621749877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.933878183364868, "step": 32000}
{"episode_reward": 79.75273278603538, "episode": 33.0, "batch_reward": 0.10952763556689024, "critic_loss": 0.3813002283722162, "actor_loss": -19.143129137039185, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.971853494644165, "step": 33000}
{"episode_reward": 338.6696826065176, "episode": 34.0, "batch_reward": 0.11730330138653516, "critic_loss": 0.4559839926958084, "actor_loss": -18.93416467666626, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.970988035202026, "step": 34000}
{"episode_reward": 230.56538578455007, "episode": 35.0, "batch_reward": 0.12093915682286024, "critic_loss": 0.39318084378540513, "actor_loss": -20.2030498752594, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.966853618621826, "step": 35000}
{"episode_reward": 235.82924965816096, "episode": 36.0, "batch_reward": 0.12254890552163124, "critic_loss": 0.45294275936484335, "actor_loss": -19.763681324005127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.942826509475708, "step": 36000}
{"episode_reward": 158.45391529076093, "episode": 37.0, "batch_reward": 0.12504274260252715, "critic_loss": 0.42481225508451465, "actor_loss": -19.978561651229857, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97783899307251, "step": 37000}
{"episode_reward": 417.8246414148524, "episode": 38.0, "batch_reward": 0.1340123674198985, "critic_loss": 0.45411429040133955, "actor_loss": -21.14874822616577, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.938541173934937, "step": 38000}
{"episode_reward": 442.2388057265424, "episode": 39.0, "batch_reward": 0.14231719198822976, "critic_loss": 0.4654561691582203, "actor_loss": -22.352651779174806, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.948615550994873, "step": 39000}
{"episode_reward": 444.65495719663886, "episode": 40.0, "batch_reward": 0.1483012490645051, "critic_loss": 0.43813025729358196, "actor_loss": -22.928974830627443, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9412944316864, "step": 40000}
{"episode_reward": 219.58444978852174, "episode": 41.0, "batch_reward": 0.15012177262455226, "critic_loss": 0.4258833222538233, "actor_loss": -22.860071928024293, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.332606077194214, "step": 41000}
{"episode_reward": 336.992973431948, "episode": 42.0, "batch_reward": 0.1557741803601384, "critic_loss": 0.44848321144282816, "actor_loss": -23.133251808166502, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.960176467895508, "step": 42000}
{"episode_reward": 438.5053167536457, "episode": 43.0, "batch_reward": 0.16271831095218658, "critic_loss": 0.39297865971922874, "actor_loss": -23.91122993659973, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.94795298576355, "step": 43000}
{"episode_reward": 412.839757033122, "episode": 44.0, "batch_reward": 0.1684274756014347, "critic_loss": 0.39567006966471674, "actor_loss": -24.2593713054657, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97799277305603, "step": 44000}
{"episode_reward": 423.8042106904229, "episode": 45.0, "batch_reward": 0.17468316850066185, "critic_loss": 0.3886363256275654, "actor_loss": -25.225536947250365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.952453136444092, "step": 45000}
{"episode_reward": 424.52333290765125, "episode": 46.0, "batch_reward": 0.1786182030439377, "critic_loss": 0.36599539390206337, "actor_loss": -25.664285720825195, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.983585357666016, "step": 46000}
{"episode_reward": 384.11429998471027, "episode": 47.0, "batch_reward": 0.18503579005599022, "critic_loss": 0.3680622854530811, "actor_loss": -25.816461877822874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.974021196365356, "step": 47000}
{"episode_reward": 408.7826534564004, "episode": 48.0, "batch_reward": 0.18933489702641965, "critic_loss": 0.39191963224112986, "actor_loss": -25.895213460922243, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.945769786834717, "step": 48000}
{"episode_reward": 458.1519539809509, "episode": 49.0, "batch_reward": 0.19438489687442778, "critic_loss": 0.3987383444309235, "actor_loss": -26.514999238967896, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.99773621559143, "step": 49000}
{"episode_reward": 414.09178243818155, "episode": 50.0, "batch_reward": 0.19689880026876927, "critic_loss": 0.40400043442845346, "actor_loss": -26.948201049804688, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.966721296310425, "step": 50000}
{"episode_reward": 264.8278361631781, "episode": 51.0, "batch_reward": 0.20002908365428448, "critic_loss": 0.4241470655798912, "actor_loss": -26.748149869918823, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.38823485374451, "step": 51000}
{"episode_reward": 404.0850604358747, "episode": 52.0, "batch_reward": 0.20374046857655048, "critic_loss": 0.40296037001907825, "actor_loss": -27.69205722808838, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.98801851272583, "step": 52000}
{"episode_reward": 416.4477467351311, "episode": 53.0, "batch_reward": 0.20698737449944019, "critic_loss": 0.43560896734893323, "actor_loss": -27.761613529205324, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96113085746765, "step": 53000}
{"episode_reward": 394.26040354531085, "episode": 54.0, "batch_reward": 0.21123284380137922, "critic_loss": 0.4764489504545927, "actor_loss": -28.1927081489563, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.964923858642578, "step": 54000}
{"episode_reward": 413.99568646111624, "episode": 55.0, "batch_reward": 0.21478685399889946, "critic_loss": 0.4753515546619892, "actor_loss": -28.119665603637696, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.976516246795654, "step": 55000}
{"episode_reward": 422.6697655447092, "episode": 56.0, "batch_reward": 0.21969118089973927, "critic_loss": 0.4806504483819008, "actor_loss": -29.109684658050536, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.950823068618774, "step": 56000}
{"episode_reward": 470.8605733068277, "episode": 57.0, "batch_reward": 0.22405562734603882, "critic_loss": 0.5027167351394892, "actor_loss": -29.727189643859862, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.949649572372437, "step": 57000}
{"episode_reward": 447.77893913188433, "episode": 58.0, "batch_reward": 0.22720769259333612, "critic_loss": 0.5772017056494951, "actor_loss": -29.57300661087036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95539402961731, "step": 58000}
{"episode_reward": 470.38902832918444, "episode": 59.0, "batch_reward": 0.23217042003571986, "critic_loss": 0.5653323602080346, "actor_loss": -30.53860926437378, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.949265241622925, "step": 59000}
{"episode_reward": 489.48151045234516, "episode": 60.0, "batch_reward": 0.2360432158112526, "critic_loss": 0.5425483399480582, "actor_loss": -31.901984859466552, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93102264404297, "step": 60000}
{"episode_reward": 465.447134140422, "episode": 61.0, "batch_reward": 0.2400348542034626, "critic_loss": 0.49947288577258586, "actor_loss": -31.56120972442627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.33356285095215, "step": 61000}
{"episode_reward": 450.80162148149356, "episode": 62.0, "batch_reward": 0.24395795941352844, "critic_loss": 0.5045464429557324, "actor_loss": -31.86595560836792, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97925591468811, "step": 62000}
{"episode_reward": 492.16713410226885, "episode": 63.0, "batch_reward": 0.24751376320421695, "critic_loss": 0.46621815468370914, "actor_loss": -32.70392386245727, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.939202785491943, "step": 63000}
{"episode_reward": 451.76227822424767, "episode": 64.0, "batch_reward": 0.2507694488465786, "critic_loss": 0.3906682152301073, "actor_loss": -32.82611178970337, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9244167804718, "step": 64000}
{"episode_reward": 467.9599520515985, "episode": 65.0, "batch_reward": 0.2534028458297253, "critic_loss": 0.3931148731261492, "actor_loss": -33.266061328887936, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97857165336609, "step": 65000}
{"episode_reward": 446.7384095327834, "episode": 66.0, "batch_reward": 0.25810751344263555, "critic_loss": 0.38697071066498756, "actor_loss": -33.56420475006104, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96151876449585, "step": 66000}
{"episode_reward": 435.84114568833877, "episode": 67.0, "batch_reward": 0.25925600653886793, "critic_loss": 0.36735577185451984, "actor_loss": -34.0926143989563, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.954782485961914, "step": 67000}
{"episode_reward": 438.5624324038183, "episode": 68.0, "batch_reward": 0.25860611350834367, "critic_loss": 0.3673772567510605, "actor_loss": -33.37410688018799, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.993523359298706, "step": 68000}
{"episode_reward": 111.18877119319225, "episode": 69.0, "batch_reward": 0.2590643658787012, "critic_loss": 0.3737079973369837, "actor_loss": -33.79462608718872, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.932084798812866, "step": 69000}
{"episode_reward": 427.10712321548385, "episode": 70.0, "batch_reward": 0.2623097032904625, "critic_loss": 0.386683902874589, "actor_loss": -34.174825084686276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96919822692871, "step": 70000}
{"episode_reward": 449.5885477546143, "episode": 71.0, "batch_reward": 0.2643948904424906, "critic_loss": 0.38689450223743915, "actor_loss": -33.78839934158325, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.32550048828125, "step": 71000}
{"episode_reward": 466.0974232219136, "episode": 72.0, "batch_reward": 0.2682670422047377, "critic_loss": 0.38819106404483317, "actor_loss": -34.21950897598266, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.973448276519775, "step": 72000}
{"episode_reward": 496.6038498460512, "episode": 73.0, "batch_reward": 0.27031661650538447, "critic_loss": 0.4043690078407526, "actor_loss": -34.35830160140991, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.961570978164673, "step": 73000}
{"episode_reward": 481.72621959843417, "episode": 74.0, "batch_reward": 0.27378052155673505, "critic_loss": 0.400173029884696, "actor_loss": -34.79439458847046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95994806289673, "step": 74000}
{"episode_reward": 473.57724156663244, "episode": 75.0, "batch_reward": 0.27710693402588366, "critic_loss": 0.3806939711421728, "actor_loss": -34.88106548309326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.954637050628662, "step": 75000}
{"episode_reward": 504.3781490264278, "episode": 76.0, "batch_reward": 0.2796641793102026, "critic_loss": 0.3702801149487495, "actor_loss": -34.93335671234131, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.936492919921875, "step": 76000}
{"episode_reward": 503.52650601936006, "episode": 77.0, "batch_reward": 0.2823734549731016, "critic_loss": 0.4033113363236189, "actor_loss": -35.179855804443356, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.965608835220337, "step": 77000}
{"episode_reward": 493.53517083379995, "episode": 78.0, "batch_reward": 0.2850880225747824, "critic_loss": 0.42844192099571227, "actor_loss": -35.752293529510496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.931405305862427, "step": 78000}
{"episode_reward": 446.9730138665908, "episode": 79.0, "batch_reward": 0.2866576779335737, "critic_loss": 0.4394901699721813, "actor_loss": -35.2461651763916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.920787811279297, "step": 79000}
{"episode_reward": 453.19199365143896, "episode": 80.0, "batch_reward": 0.28962377209961415, "critic_loss": 0.4909082469791174, "actor_loss": -35.46821588897705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.980892658233643, "step": 80000}
{"episode_reward": 497.7486367488208, "episode": 81.0, "batch_reward": 0.2929383243173361, "critic_loss": 0.4603526822626591, "actor_loss": -36.023848468780514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.36697959899902, "step": 81000}
{"episode_reward": 490.70748903228423, "episode": 82.0, "batch_reward": 0.2952857611179352, "critic_loss": 0.41991347233951093, "actor_loss": -36.63450117492676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.99190092086792, "step": 82000}
{"episode_reward": 349.2215383992939, "episode": 83.0, "batch_reward": 0.2955345110595226, "critic_loss": 0.41443909028172493, "actor_loss": -36.13034332275391, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.00727939605713, "step": 83000}
{"episode_reward": 473.9846536888438, "episode": 84.0, "batch_reward": 0.2973418668806553, "critic_loss": 0.4141232219785452, "actor_loss": -36.26476486587524, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.984524965286255, "step": 84000}
{"episode_reward": 408.15596723074935, "episode": 85.0, "batch_reward": 0.2978824400752783, "critic_loss": 0.4285224580466747, "actor_loss": -36.448692092895506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.978628158569336, "step": 85000}
{"episode_reward": 486.78883637563456, "episode": 86.0, "batch_reward": 0.3002449711412191, "critic_loss": 0.41968605799973013, "actor_loss": -36.29308355712891, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.992761850357056, "step": 86000}
{"episode_reward": 452.7673158032979, "episode": 87.0, "batch_reward": 0.30260722532868384, "critic_loss": 0.4065597501248121, "actor_loss": -36.49173252487183, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97356867790222, "step": 87000}
{"episode_reward": 471.97177342654817, "episode": 88.0, "batch_reward": 0.3040447286814451, "critic_loss": 0.3952854801863432, "actor_loss": -36.15443118667603, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.976954221725464, "step": 88000}
{"episode_reward": 479.43080203955566, "episode": 89.0, "batch_reward": 0.30635036490857603, "critic_loss": 0.3450378693714738, "actor_loss": -36.62255392837525, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.003393411636353, "step": 89000}
{"episode_reward": 505.88599640598227, "episode": 90.0, "batch_reward": 0.3075994580686092, "critic_loss": 0.3803864127248526, "actor_loss": -37.06734063720703, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.961216926574707, "step": 90000}
{"episode_reward": 199.05970674783546, "episode": 91.0, "batch_reward": 0.3074560258537531, "critic_loss": 0.3599549462646246, "actor_loss": -36.562663494110105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.431562662124634, "step": 91000}
{"episode_reward": 502.9372550235988, "episode": 92.0, "batch_reward": 0.31030731186270716, "critic_loss": 0.35941807755827904, "actor_loss": -36.821916828155516, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.004430532455444, "step": 92000}
{"episode_reward": 467.48300068302893, "episode": 93.0, "batch_reward": 0.31059041479229926, "critic_loss": 0.35926838356256485, "actor_loss": -36.75251461410522, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.007514476776123, "step": 93000}
{"episode_reward": 470.59089617734855, "episode": 94.0, "batch_reward": 0.31295119351148604, "critic_loss": 0.35638701483607294, "actor_loss": -36.83583720779419, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.010244131088257, "step": 94000}
{"episode_reward": 493.0580904245751, "episode": 95.0, "batch_reward": 0.31438044917583463, "critic_loss": 0.3685861506611109, "actor_loss": -37.544795455932615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.00537633895874, "step": 95000}
{"episode_reward": 503.05487364367724, "episode": 96.0, "batch_reward": 0.31569962306320665, "critic_loss": 0.35688976195454597, "actor_loss": -37.17192210769653, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.009181261062622, "step": 96000}
{"episode_reward": 482.99886633671275, "episode": 97.0, "batch_reward": 0.31778481248021123, "critic_loss": 0.3648929850310087, "actor_loss": -37.45987692260742, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.969022274017334, "step": 97000}
{"episode_reward": 457.88804460350025, "episode": 98.0, "batch_reward": 0.32030388414859773, "critic_loss": 0.33451455694437027, "actor_loss": -37.63238288497925, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.01583766937256, "step": 98000}
{"episode_reward": 498.6975147340845, "episode": 99.0, "batch_reward": 0.3220959520041943, "critic_loss": 0.3255417464822531, "actor_loss": -37.67331360244751, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.999826908111572, "step": 99000}
{"episode_reward": 496.2574069717496, "episode": 100.0, "batch_reward": 0.3230976955294609, "critic_loss": 0.3470262293666601, "actor_loss": -37.47060930252075, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.98101282119751, "step": 100000}
{"episode_reward": 466.2745547528514, "episode": 101.0, "batch_reward": 0.3250664640665054, "critic_loss": 0.35535669469833375, "actor_loss": -38.067808113098145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.359694480895996, "step": 101000}
{"episode_reward": 504.1099154213282, "episode": 102.0, "batch_reward": 0.32626097977161406, "critic_loss": 0.370318224683404, "actor_loss": -38.03213133621216, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.954978942871094, "step": 102000}
{"episode_reward": 468.4654915996276, "episode": 103.0, "batch_reward": 0.3272379004955292, "critic_loss": 0.3606819066107273, "actor_loss": -38.15518012237549, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.978276252746582, "step": 103000}
{"episode_reward": 487.7204195754063, "episode": 104.0, "batch_reward": 0.33050510302186015, "critic_loss": 0.3642605673223734, "actor_loss": -38.30991574859619, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.986709356307983, "step": 104000}
{"episode_reward": 496.32007219982773, "episode": 105.0, "batch_reward": 0.3309175108969212, "critic_loss": 0.4010931742489338, "actor_loss": -38.253130764007565, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.959401845932007, "step": 105000}
{"episode_reward": 133.18024840790704, "episode": 106.0, "batch_reward": 0.32866169479489327, "critic_loss": 0.39396394915878774, "actor_loss": -37.73078969192505, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.964786767959595, "step": 106000}
{"episode_reward": 498.2130786833833, "episode": 107.0, "batch_reward": 0.33151208513975144, "critic_loss": 0.40193045185506343, "actor_loss": -38.255857372283934, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96851921081543, "step": 107000}
{"episode_reward": 497.56451357682243, "episode": 108.0, "batch_reward": 0.33306459537148475, "critic_loss": 0.39698043605685235, "actor_loss": -38.49496726989746, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.98257303237915, "step": 108000}
{"episode_reward": 469.0840962892078, "episode": 109.0, "batch_reward": 0.33343640857934953, "critic_loss": 0.4014571226388216, "actor_loss": -38.51591711044311, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.965606212615967, "step": 109000}
{"episode_reward": 471.8363040639331, "episode": 110.0, "batch_reward": 0.33504496347904206, "critic_loss": 0.3794091487303376, "actor_loss": -38.88690315246582, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.974546194076538, "step": 110000}
{"episode_reward": 499.52843850271665, "episode": 111.0, "batch_reward": 0.33643869692087175, "critic_loss": 0.36872738571465014, "actor_loss": -39.17715977478027, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.328150510787964, "step": 111000}
{"episode_reward": 473.91911104133726, "episode": 112.0, "batch_reward": 0.33753108966350553, "critic_loss": 0.35758838295936585, "actor_loss": -38.87429305267334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92854952812195, "step": 112000}
{"episode_reward": 434.74483404898785, "episode": 113.0, "batch_reward": 0.3392311922907829, "critic_loss": 0.3943551086932421, "actor_loss": -38.76856363296509, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9707989692688, "step": 113000}
{"episode_reward": 493.9798569346881, "episode": 114.0, "batch_reward": 0.33946329537034037, "critic_loss": 0.39004103315621613, "actor_loss": -39.45359977722168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.959715366363525, "step": 114000}
{"episode_reward": 509.55640837414967, "episode": 115.0, "batch_reward": 0.3420413752794266, "critic_loss": 0.3780039394646883, "actor_loss": -39.376402828216555, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91669201850891, "step": 115000}
{"episode_reward": 497.59200244804174, "episode": 116.0, "batch_reward": 0.3433137868642807, "critic_loss": 0.3811711157858372, "actor_loss": -39.63027811050415, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.972615480422974, "step": 116000}
{"episode_reward": 422.5645383153836, "episode": 117.0, "batch_reward": 0.34515214490890506, "critic_loss": 0.3722333659529686, "actor_loss": -39.39040660095215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96409034729004, "step": 117000}
{"episode_reward": 499.0004550913721, "episode": 118.0, "batch_reward": 0.3446826463341713, "critic_loss": 0.3938277821987867, "actor_loss": -39.57586470794678, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.955877780914307, "step": 118000}
{"episode_reward": 485.4774203812073, "episode": 119.0, "batch_reward": 0.3460474593937397, "critic_loss": 0.3969516757130623, "actor_loss": -39.727453540802, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.98629069328308, "step": 119000}
{"episode_reward": 487.81724819516705, "episode": 120.0, "batch_reward": 0.34679998165369036, "critic_loss": 0.43432265585660934, "actor_loss": -39.41031013870239, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96664261817932, "step": 120000}
{"episode_reward": 489.1169130194495, "episode": 121.0, "batch_reward": 0.3494132762253285, "critic_loss": 0.4371250607818365, "actor_loss": -39.85125566101074, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.38997721672058, "step": 121000}
{"episode_reward": 480.91032599059093, "episode": 122.0, "batch_reward": 0.34936381250619886, "critic_loss": 0.38702019447088243, "actor_loss": -40.20421340942383, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.00850510597229, "step": 122000}
{"episode_reward": 503.1392273967564, "episode": 123.0, "batch_reward": 0.3522336881458759, "critic_loss": 0.37246482145786286, "actor_loss": -39.81846850204468, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.938807249069214, "step": 123000}
{"episode_reward": 500.3941635622551, "episode": 124.0, "batch_reward": 0.3523049306869507, "critic_loss": 0.40326308391988275, "actor_loss": -40.360247543334964, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.958515167236328, "step": 124000}
{"episode_reward": 505.450775645952, "episode": 125.0, "batch_reward": 0.35303824323415756, "critic_loss": 0.4076931458041072, "actor_loss": -39.886092384338376, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.009324073791504, "step": 125000}
{"episode_reward": 258.05363723758967, "episode": 126.0, "batch_reward": 0.3513634154200554, "critic_loss": 0.438898648917675, "actor_loss": -40.351716632843015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.938076972961426, "step": 126000}
{"episode_reward": 513.526734462329, "episode": 127.0, "batch_reward": 0.3534737241566181, "critic_loss": 0.4143679993450642, "actor_loss": -40.4838427734375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97020936012268, "step": 127000}
{"episode_reward": 465.88254820300546, "episode": 128.0, "batch_reward": 0.355044778585434, "critic_loss": 0.41941611920297145, "actor_loss": -40.49143383026123, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.99062967300415, "step": 128000}
{"episode_reward": 484.58406238751024, "episode": 129.0, "batch_reward": 0.3557910484075546, "critic_loss": 0.45539057612419126, "actor_loss": -40.670692470550534, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.963046073913574, "step": 129000}
{"episode_reward": 488.55685900445377, "episode": 130.0, "batch_reward": 0.356568879455328, "critic_loss": 0.44944633246958254, "actor_loss": -40.77572177505493, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.931880950927734, "step": 130000}
{"episode_reward": 494.13885895568166, "episode": 131.0, "batch_reward": 0.35888983991742135, "critic_loss": 0.64597914673388, "actor_loss": -40.95157497406006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.37629532814026, "step": 131000}
{"episode_reward": 533.4139438875768, "episode": 132.0, "batch_reward": 0.3592584541141987, "critic_loss": 0.7358330108225346, "actor_loss": -40.78128644943237, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.990865230560303, "step": 132000}
{"episode_reward": 447.07074303096374, "episode": 133.0, "batch_reward": 0.35900627878308294, "critic_loss": 0.7520278922319412, "actor_loss": -41.10993684768677, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.369474172592163, "step": 133000}
{"episode_reward": 474.30131888023067, "episode": 134.0, "batch_reward": 0.3597625496685505, "critic_loss": 0.805573192447424, "actor_loss": -41.520647373199466, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.28149962425232, "step": 134000}
{"episode_reward": 499.1069828522724, "episode": 135.0, "batch_reward": 0.36111135324835775, "critic_loss": 0.7048498846888542, "actor_loss": -41.611564868927005, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97384738922119, "step": 135000}
{"episode_reward": 453.4927012978907, "episode": 136.0, "batch_reward": 0.3631132018864155, "critic_loss": 0.5323493228256703, "actor_loss": -42.02254597854614, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.114664554595947, "step": 136000}
{"episode_reward": 492.07516439631866, "episode": 137.0, "batch_reward": 0.3631721470057964, "critic_loss": 0.4821365534067154, "actor_loss": -41.73466449737549, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.029547929763794, "step": 137000}
{"episode_reward": 438.3438157684184, "episode": 138.0, "batch_reward": 0.3634544638991356, "critic_loss": 0.5006655602008104, "actor_loss": -41.49104001617432, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.978848934173584, "step": 138000}
{"episode_reward": 467.8675510300476, "episode": 139.0, "batch_reward": 0.3642910764217377, "critic_loss": 0.440866103887558, "actor_loss": -41.660554481506345, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97702431678772, "step": 139000}
{"episode_reward": 505.6287773571466, "episode": 140.0, "batch_reward": 0.36426483166217805, "critic_loss": 0.4265287394523621, "actor_loss": -41.47179119873047, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.98257088661194, "step": 140000}
{"episode_reward": 459.4281234805068, "episode": 141.0, "batch_reward": 0.3652305430471897, "critic_loss": 0.4106000631451607, "actor_loss": -41.36832977294922, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.95788288116455, "step": 141000}
{"episode_reward": 515.2899462157413, "episode": 142.0, "batch_reward": 0.36690385594964026, "critic_loss": 0.3983518818616867, "actor_loss": -42.00987257385254, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.40599012374878, "step": 142000}
{"episode_reward": 493.5821944396626, "episode": 143.0, "batch_reward": 0.3689755406975746, "critic_loss": 0.4285054823309183, "actor_loss": -41.86423446655274, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.285418272018433, "step": 143000}
{"episode_reward": 513.5735196791136, "episode": 144.0, "batch_reward": 0.3690766831934452, "critic_loss": 0.4623972166031599, "actor_loss": -42.12737441253662, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.63139271736145, "step": 144000}
{"episode_reward": 484.08815213385304, "episode": 145.0, "batch_reward": 0.3712339209914207, "critic_loss": 0.4509775065779686, "actor_loss": -42.181029708862305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.036699295043945, "step": 145000}
{"episode_reward": 512.0200415887856, "episode": 146.0, "batch_reward": 0.37040302246809004, "critic_loss": 0.4559381384551525, "actor_loss": -42.493459663391114, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.14298105239868, "step": 146000}
{"episode_reward": 529.8907925719866, "episode": 147.0, "batch_reward": 0.3717878732979298, "critic_loss": 0.4309371911138296, "actor_loss": -42.551828407287594, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.480990171432495, "step": 147000}
{"episode_reward": 398.53254280657364, "episode": 148.0, "batch_reward": 0.3730114049613476, "critic_loss": 0.43991520038247106, "actor_loss": -42.734378051757815, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.171769857406616, "step": 148000}
{"episode_reward": 505.5942812326653, "episode": 149.0, "batch_reward": 0.3735764418840408, "critic_loss": 0.4433846329748631, "actor_loss": -42.832450973510745, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.375969171524048, "step": 149000}
{"episode_reward": 508.33892977260075, "episode": 150.0, "batch_reward": 0.3744676610827446, "critic_loss": 0.42494303406774997, "actor_loss": -43.031860206604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
