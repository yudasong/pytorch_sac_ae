{"episode_reward": 0.0, "episode": 1.0, "duration": 13.075579643249512, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.1202452182769775, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.22040507611770477, "critic_loss": 0.25710829306628635, "actor_loss": -44.72857826144374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 71.28792262077332, "step": 3000}
{"episode_reward": 67.43631710804476, "episode": 4.0, "batch_reward": 0.16776474168151617, "critic_loss": 0.2286950211971998, "actor_loss": -39.95010866928101, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.827093601226807, "step": 4000}
{"episode_reward": 147.42027669580267, "episode": 5.0, "batch_reward": 0.17182787706702948, "critic_loss": 0.25101155711710454, "actor_loss": -39.571033493041995, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.58706498146057, "step": 5000}
{"episode_reward": 228.1490575953651, "episode": 6.0, "batch_reward": 0.16885324553400277, "critic_loss": 0.2210016246587038, "actor_loss": -37.387608116149906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.447505950927734, "step": 6000}
{"episode_reward": 33.42769777772208, "episode": 7.0, "batch_reward": 0.15429298676550388, "critic_loss": 0.21739173419773578, "actor_loss": -34.15964046096802, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.4204204082489, "step": 7000}
{"episode_reward": 97.18976677569795, "episode": 8.0, "batch_reward": 0.15358621399104594, "critic_loss": 0.21432900629937648, "actor_loss": -33.39249291610718, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.92569136619568, "step": 8000}
{"episode_reward": 249.04465585536775, "episode": 9.0, "batch_reward": 0.1648475466966629, "critic_loss": 0.21822336453199387, "actor_loss": -33.35211085128784, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.959426164627075, "step": 9000}
{"episode_reward": 216.51925208122708, "episode": 10.0, "batch_reward": 0.16934007388353348, "critic_loss": 0.22628819452226162, "actor_loss": -33.92791698074341, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.633166790008545, "step": 10000}
{"episode_reward": 207.25086510239572, "episode": 11.0, "batch_reward": 0.1717523616105318, "critic_loss": 0.21219463750720025, "actor_loss": -33.01275095748901, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.892197132110596, "step": 11000}
{"episode_reward": 140.5306837955277, "episode": 12.0, "batch_reward": 0.16859741808474063, "critic_loss": 0.20172479060292245, "actor_loss": -31.909157779693604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.97103762626648, "step": 12000}
{"episode_reward": 120.49991752166315, "episode": 13.0, "batch_reward": 0.16759129859507083, "critic_loss": 0.20159479722380638, "actor_loss": -31.098444324493407, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.923490047454834, "step": 13000}
{"episode_reward": 256.66498446109796, "episode": 14.0, "batch_reward": 0.16975042946636676, "critic_loss": 0.21437745020538568, "actor_loss": -31.44632801437378, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.630035638809204, "step": 14000}
{"episode_reward": 89.39482746279269, "episode": 15.0, "batch_reward": 0.17057772473990918, "critic_loss": 0.1964386217817664, "actor_loss": -30.080816558837892, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.38038969039917, "step": 15000}
{"episode_reward": 299.35175254907443, "episode": 16.0, "batch_reward": 0.17757270208001136, "critic_loss": 0.19765531489998103, "actor_loss": -30.01008302307129, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.577110528945923, "step": 16000}
{"episode_reward": 319.5820070128761, "episode": 17.0, "batch_reward": 0.18234415316581726, "critic_loss": 0.19440959122031928, "actor_loss": -30.462538314819337, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.469929218292236, "step": 17000}
{"episode_reward": 79.1323373545456, "episode": 18.0, "batch_reward": 0.18016970594227313, "critic_loss": 0.1718198205381632, "actor_loss": -30.053666786193848, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.76013422012329, "step": 18000}
{"episode_reward": 299.1519105172363, "episode": 19.0, "batch_reward": 0.18594644840061664, "critic_loss": 0.16631333538144827, "actor_loss": -29.068056999206544, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.301788330078125, "step": 19000}
{"episode_reward": 306.7671751242635, "episode": 20.0, "batch_reward": 0.19068096189200878, "critic_loss": 0.18268340500444175, "actor_loss": -28.873576717376707, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.845036506652832, "step": 20000}
{"episode_reward": 134.73478096307394, "episode": 21.0, "batch_reward": 0.18902278862893582, "critic_loss": 0.1728692553266883, "actor_loss": -27.992880393981935, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.07934880256653, "step": 21000}
{"episode_reward": 152.73342243102257, "episode": 22.0, "batch_reward": 0.18935773342847825, "critic_loss": 0.1722670118138194, "actor_loss": -27.71016354370117, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.648544549942017, "step": 22000}
{"episode_reward": 221.72219385884057, "episode": 23.0, "batch_reward": 0.18872550575435162, "critic_loss": 0.18874735307693483, "actor_loss": -27.806385890960694, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.703145265579224, "step": 23000}
{"episode_reward": 140.71243210409958, "episode": 24.0, "batch_reward": 0.18841050401329995, "critic_loss": 0.21945760302990674, "actor_loss": -26.565119468688966, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.0021812915802, "step": 24000}
{"episode_reward": 257.8520137521738, "episode": 25.0, "batch_reward": 0.1917392194122076, "critic_loss": 0.21394118766486644, "actor_loss": -27.090868156433107, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.49643564224243, "step": 25000}
{"episode_reward": 336.708775500746, "episode": 26.0, "batch_reward": 0.19663021278381349, "critic_loss": 0.22591328164935112, "actor_loss": -27.130399063110353, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.67945098876953, "step": 26000}
{"episode_reward": 410.48361068180265, "episode": 27.0, "batch_reward": 0.20640319207310676, "critic_loss": 0.24621197810024023, "actor_loss": -27.330143100738525, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.891045808792114, "step": 27000}
{"episode_reward": 421.77631546429336, "episode": 28.0, "batch_reward": 0.21229501283168792, "critic_loss": 0.2362631378620863, "actor_loss": -27.494995571136474, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.174859046936035, "step": 28000}
{"episode_reward": 205.27427734445249, "episode": 29.0, "batch_reward": 0.2118946777433157, "critic_loss": 0.20960265558212995, "actor_loss": -26.45639364242554, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.800103425979614, "step": 29000}
{"episode_reward": 172.32595495093997, "episode": 30.0, "batch_reward": 0.21334046751260757, "critic_loss": 0.21554463147372008, "actor_loss": -26.427330291748046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.70827627182007, "step": 30000}
{"episode_reward": 470.13718236590404, "episode": 31.0, "batch_reward": 0.2213371611982584, "critic_loss": 0.20268227250874044, "actor_loss": -26.617079746246336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.13882040977478, "step": 31000}
{"episode_reward": 441.76724734917195, "episode": 32.0, "batch_reward": 0.22962150771915912, "critic_loss": 0.19926322604715824, "actor_loss": -26.920980949401855, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.10392165184021, "step": 32000}
{"episode_reward": 481.38295846492434, "episode": 33.0, "batch_reward": 0.23779574677348136, "critic_loss": 0.20904472348093986, "actor_loss": -27.01265717315674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.050170421600342, "step": 33000}
{"episode_reward": 473.0155162931053, "episode": 34.0, "batch_reward": 0.24427239590883254, "critic_loss": 0.2086425501257181, "actor_loss": -28.557429801940916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.925774574279785, "step": 34000}
{"episode_reward": 471.1034536367285, "episode": 35.0, "batch_reward": 0.25058756206929683, "critic_loss": 0.21426563710719346, "actor_loss": -27.894415187835694, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.277780055999756, "step": 35000}
{"episode_reward": 481.8421580448501, "episode": 36.0, "batch_reward": 0.25618389780819417, "critic_loss": 0.24299559170007706, "actor_loss": -28.962561332702638, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.132514715194702, "step": 36000}
{"episode_reward": 475.1371309698017, "episode": 37.0, "batch_reward": 0.2626722675561905, "critic_loss": 0.31713057155907154, "actor_loss": -29.178774101257325, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.447086572647095, "step": 37000}
{"episode_reward": 514.9658583444609, "episode": 38.0, "batch_reward": 0.2703809237778187, "critic_loss": 0.30118012899160385, "actor_loss": -29.40002625656128, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.894380569458008, "step": 38000}
{"episode_reward": 429.0624756345422, "episode": 39.0, "batch_reward": 0.2732574182897806, "critic_loss": 0.288530095115304, "actor_loss": -29.534746829986574, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.663273572921753, "step": 39000}
{"episode_reward": 412.58436913362516, "episode": 40.0, "batch_reward": 0.27781986306607726, "critic_loss": 0.259978865429759, "actor_loss": -30.34196646118164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.872515201568604, "step": 40000}
{"episode_reward": 378.88489823737115, "episode": 41.0, "batch_reward": 0.2801998837590218, "critic_loss": 0.2523721504583955, "actor_loss": -30.592872779846193, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.93078374862671, "step": 41000}
{"episode_reward": 506.8302763475997, "episode": 42.0, "batch_reward": 0.286206200838089, "critic_loss": 0.23690180010348558, "actor_loss": -31.82616240310669, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.223320245742798, "step": 42000}
{"episode_reward": 512.3800062345887, "episode": 43.0, "batch_reward": 0.2915159931778908, "critic_loss": 0.23316391807049514, "actor_loss": -32.094004707336424, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.811039209365845, "step": 43000}
{"episode_reward": 470.6820177363572, "episode": 44.0, "batch_reward": 0.2952697805464268, "critic_loss": 0.22418191209435462, "actor_loss": -32.676947261810305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.85149908065796, "step": 44000}
{"episode_reward": 505.3370618066799, "episode": 45.0, "batch_reward": 0.29943214951455593, "critic_loss": 0.2086252202615142, "actor_loss": -33.066732582092285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.946857213974, "step": 45000}
{"episode_reward": 527.1891599830975, "episode": 46.0, "batch_reward": 0.3032598929703236, "critic_loss": 0.20037726424634456, "actor_loss": -33.50175699234009, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.730608463287354, "step": 46000}
{"episode_reward": 522.2271630610448, "episode": 47.0, "batch_reward": 0.3097768269777298, "critic_loss": 0.19129681807011367, "actor_loss": -33.57857619094849, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.90234637260437, "step": 47000}
{"episode_reward": 523.6433569342979, "episode": 48.0, "batch_reward": 0.3123624728918076, "critic_loss": 0.1911693265810609, "actor_loss": -33.96045190048218, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.106966972351074, "step": 48000}
{"episode_reward": 249.2458221502019, "episode": 49.0, "batch_reward": 0.3134962308704853, "critic_loss": 0.1719564163312316, "actor_loss": -34.32393887710571, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.924817323684692, "step": 49000}
{"episode_reward": 524.6024032059867, "episode": 50.0, "batch_reward": 0.3160096482932568, "critic_loss": 0.16440920393913985, "actor_loss": -34.569315502166745, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.251056671142578, "step": 50000}
{"episode_reward": 536.2806680971579, "episode": 51.0, "batch_reward": 0.32178380304574966, "critic_loss": 0.1520031825825572, "actor_loss": -35.10366568756103, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.025702238082886, "step": 51000}
{"episode_reward": 534.9945230341618, "episode": 52.0, "batch_reward": 0.32493095117807386, "critic_loss": 0.15400449339300393, "actor_loss": -35.78445704650879, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.906699657440186, "step": 52000}
{"episode_reward": 528.8987843713741, "episode": 53.0, "batch_reward": 0.32544458577036856, "critic_loss": 0.17329541327804326, "actor_loss": -36.014716720581056, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.15738034248352, "step": 53000}
{"episode_reward": 149.19520110835813, "episode": 54.0, "batch_reward": 0.32226499903202055, "critic_loss": 0.17684273354709149, "actor_loss": -36.204536697387695, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.361659049987793, "step": 54000}
{"episode_reward": 51.0536535035384, "episode": 55.0, "batch_reward": 0.32142396530508993, "critic_loss": 0.16231415162980556, "actor_loss": -36.17425958251953, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.908405303955078, "step": 55000}
{"episode_reward": 291.6081573562354, "episode": 56.0, "batch_reward": 0.3156958924531937, "critic_loss": 0.15386692058295012, "actor_loss": -36.18364237976074, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.088684558868408, "step": 56000}
{"episode_reward": 22.375230912102136, "episode": 57.0, "batch_reward": 0.3135969356894493, "critic_loss": 0.12381674273312092, "actor_loss": -36.1673960647583, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.8602454662323, "step": 57000}
{"episode_reward": 203.8291179587772, "episode": 58.0, "batch_reward": 0.3090428461432457, "critic_loss": 0.10862172281742095, "actor_loss": -36.084979972839356, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.0798978805542, "step": 58000}
{"episode_reward": 63.64573964332802, "episode": 59.0, "batch_reward": 0.306324671253562, "critic_loss": 0.1068225943557918, "actor_loss": -35.890145431518555, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.07340359687805, "step": 59000}
{"episode_reward": 108.48707892403672, "episode": 60.0, "batch_reward": 0.30416476534307, "critic_loss": 0.11812853452190757, "actor_loss": -35.54037831878662, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.911723613739014, "step": 60000}
{"episode_reward": 220.33998234396356, "episode": 61.0, "batch_reward": 0.3035929865986109, "critic_loss": 0.138471634991467, "actor_loss": -35.62052156066895, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.177265882492065, "step": 61000}
{"episode_reward": 302.2967527101018, "episode": 62.0, "batch_reward": 0.30365228036046027, "critic_loss": 0.15385977844148874, "actor_loss": -35.28565718078613, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.894218921661377, "step": 62000}
{"episode_reward": 558.2426995483586, "episode": 63.0, "batch_reward": 0.30811541701853273, "critic_loss": 0.1638830085322261, "actor_loss": -35.53030292129517, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.637542247772217, "step": 63000}
{"episode_reward": 551.9319094972958, "episode": 64.0, "batch_reward": 0.31110391265153886, "critic_loss": 0.17518475368618966, "actor_loss": -35.76560132598877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.497720956802368, "step": 64000}
{"episode_reward": 539.9655335020767, "episode": 65.0, "batch_reward": 0.3150526931285858, "critic_loss": 0.1813389050886035, "actor_loss": -35.8446089553833, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.09220814704895, "step": 65000}
{"episode_reward": 560.9758646813686, "episode": 66.0, "batch_reward": 0.31943229714035987, "critic_loss": 0.172334524333477, "actor_loss": -36.37400296783447, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.15477418899536, "step": 66000}
{"episode_reward": 529.080773292035, "episode": 67.0, "batch_reward": 0.3227165975570679, "critic_loss": 0.17151125298440456, "actor_loss": -36.49120642852783, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.006346702575684, "step": 67000}
{"episode_reward": 549.9717490173012, "episode": 68.0, "batch_reward": 0.32581476095318795, "critic_loss": 0.17590131800621747, "actor_loss": -37.03052847290039, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.10118842124939, "step": 68000}
{"episode_reward": 574.5202331781554, "episode": 69.0, "batch_reward": 0.32923076447844507, "critic_loss": 0.16718171602487564, "actor_loss": -37.313572944641116, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.84301209449768, "step": 69000}
{"episode_reward": 562.5733283946789, "episode": 70.0, "batch_reward": 0.33189819592237474, "critic_loss": 0.1602642169073224, "actor_loss": -37.487249504089355, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.394285440444946, "step": 70000}
{"episode_reward": 538.067468117271, "episode": 71.0, "batch_reward": 0.335481760263443, "critic_loss": 0.15378389347344637, "actor_loss": -37.82126892089844, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.7933828830719, "step": 71000}
{"episode_reward": 567.768423294988, "episode": 72.0, "batch_reward": 0.3392119738459587, "critic_loss": 0.1504096708521247, "actor_loss": -38.261424346923825, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.261165142059326, "step": 72000}
{"episode_reward": 574.1682199249581, "episode": 73.0, "batch_reward": 0.341412473320961, "critic_loss": 0.15133156506717205, "actor_loss": -38.57187825012207, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.967792510986328, "step": 73000}
{"episode_reward": 572.7262419644752, "episode": 74.0, "batch_reward": 0.3471273619532585, "critic_loss": 0.14199706549197436, "actor_loss": -39.04372393798828, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.830795764923096, "step": 74000}
{"episode_reward": 583.0019775001033, "episode": 75.0, "batch_reward": 0.34830641305446625, "critic_loss": 0.1454395178258419, "actor_loss": -39.315130775451664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.675168991088867, "step": 75000}
{"episode_reward": 560.5916442366383, "episode": 76.0, "batch_reward": 0.35173840990662575, "critic_loss": 0.14326271650195121, "actor_loss": -39.635710639953615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.942885637283325, "step": 76000}
{"episode_reward": 589.8522342423495, "episode": 77.0, "batch_reward": 0.3543154604136944, "critic_loss": 0.13461008968949317, "actor_loss": -40.155114250183104, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.679117918014526, "step": 77000}
{"episode_reward": 573.3725908204316, "episode": 78.0, "batch_reward": 0.35820843699574473, "critic_loss": 0.16011850802600383, "actor_loss": -40.297729637146, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.07808208465576, "step": 78000}
{"episode_reward": 588.0484630978839, "episode": 79.0, "batch_reward": 0.35708895954489706, "critic_loss": 0.1988525505810976, "actor_loss": -40.856236236572265, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.004982709884644, "step": 79000}
{"episode_reward": 5.827076091136989, "episode": 80.0, "batch_reward": 0.3536184298694134, "critic_loss": 0.20111069647222757, "actor_loss": -40.98665134429932, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.836055040359497, "step": 80000}
{"episode_reward": 2.9154879206659396, "episode": 81.0, "batch_reward": 0.3486575621664524, "critic_loss": 0.19701250323653222, "actor_loss": -41.23493058776855, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.44425559043884, "step": 81000}
{"episode_reward": 15.162626139451568, "episode": 82.0, "batch_reward": 0.3435516290664673, "critic_loss": 0.18401087572425603, "actor_loss": -41.13666056060791, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.114245891571045, "step": 82000}
{"episode_reward": 2.4833131844705374, "episode": 83.0, "batch_reward": 0.34007127496600154, "critic_loss": 0.17104736932367087, "actor_loss": -41.4399280090332, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.492475271224976, "step": 83000}
{"episode_reward": 5.36032798474418, "episode": 84.0, "batch_reward": 0.33972989988327024, "critic_loss": 0.16041813696920873, "actor_loss": -41.660274047851566, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.69413685798645, "step": 84000}
{"episode_reward": 528.3159975848299, "episode": 85.0, "batch_reward": 0.33794551208615303, "critic_loss": 0.15535256050527096, "actor_loss": -41.646250984191894, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.061994791030884, "step": 85000}
{"episode_reward": 6.848687846622758, "episode": 86.0, "batch_reward": 0.3386852983832359, "critic_loss": 0.14597851479053497, "actor_loss": -41.736523582458496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.888656854629517, "step": 86000}
{"episode_reward": 556.9017241323635, "episode": 87.0, "batch_reward": 0.33772613444924354, "critic_loss": 0.1421498761549592, "actor_loss": -41.81936410522461, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.06245708465576, "step": 87000}
{"episode_reward": 106.49254055270659, "episode": 88.0, "batch_reward": 0.3371191792488098, "critic_loss": 0.1475115204975009, "actor_loss": -41.75869278717041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.459259271621704, "step": 88000}
{"episode_reward": 568.3297476300907, "episode": 89.0, "batch_reward": 0.3391209255158901, "critic_loss": 0.15255428113788366, "actor_loss": -41.76104277801514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.251370429992676, "step": 89000}
{"episode_reward": 541.412433936496, "episode": 90.0, "batch_reward": 0.3414221402108669, "critic_loss": 0.1398352655246854, "actor_loss": -41.864120712280275, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.89563226699829, "step": 90000}
{"episode_reward": 594.7965418978528, "episode": 91.0, "batch_reward": 0.34468800729513166, "critic_loss": 0.133292540602386, "actor_loss": -41.814680305480955, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.467148542404175, "step": 91000}
{"episode_reward": 580.2523555973165, "episode": 92.0, "batch_reward": 0.3491169003844261, "critic_loss": 0.15352462603896858, "actor_loss": -41.985093383789064, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.0495765209198, "step": 92000}
{"episode_reward": 581.1675721948078, "episode": 93.0, "batch_reward": 0.3496427487134933, "critic_loss": 0.14165370494127275, "actor_loss": -42.18366430664062, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.372501611709595, "step": 93000}
{"episode_reward": 558.8204238002223, "episode": 94.0, "batch_reward": 0.3520324659049511, "critic_loss": 0.1455815027654171, "actor_loss": -42.101215141296386, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.98475742340088, "step": 94000}
{"episode_reward": 556.4790644466568, "episode": 95.0, "batch_reward": 0.35397561490535734, "critic_loss": 0.15293785166740417, "actor_loss": -42.03858861541748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.275376558303833, "step": 95000}
{"episode_reward": 608.0419850543879, "episode": 96.0, "batch_reward": 0.3567345114350319, "critic_loss": 0.15936906281858682, "actor_loss": -42.02563645172119, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.950944185256958, "step": 96000}
{"episode_reward": 572.0916652397717, "episode": 97.0, "batch_reward": 0.3602894538342953, "critic_loss": 0.1550808536335826, "actor_loss": -42.33945800018311, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.38377094268799, "step": 97000}
{"episode_reward": 577.5731908476962, "episode": 98.0, "batch_reward": 0.361965729534626, "critic_loss": 0.16437565110623836, "actor_loss": -42.27677717590332, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.000917434692383, "step": 98000}
{"episode_reward": 611.7510236491976, "episode": 99.0, "batch_reward": 0.3633161858022213, "critic_loss": 0.13907040597498416, "actor_loss": -42.465958869934084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.00619602203369, "step": 99000}
{"episode_reward": 598.9671755246943, "episode": 100.0, "batch_reward": 0.36745649671554564, "critic_loss": 0.1485636171773076, "actor_loss": -42.7447152633667, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.440747022628784, "step": 100000}
{"episode_reward": 584.3329473504872, "episode": 101.0, "batch_reward": 0.369076607555151, "critic_loss": 0.15299692068248988, "actor_loss": -42.91956269836426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.14245128631592, "step": 101000}
{"episode_reward": 586.4877831506353, "episode": 102.0, "batch_reward": 0.36971331083774567, "critic_loss": 0.14864451956003905, "actor_loss": -42.870531051635744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.323259115219116, "step": 102000}
{"episode_reward": 328.67426085732836, "episode": 103.0, "batch_reward": 0.3688222853541374, "critic_loss": 0.16375903271138667, "actor_loss": -42.7721598815918, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.050268173217773, "step": 103000}
{"episode_reward": 586.4874952390779, "episode": 104.0, "batch_reward": 0.3731702679991722, "critic_loss": 0.14367744097858667, "actor_loss": -42.96091975402832, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.007267713546753, "step": 104000}
{"episode_reward": 556.6761366717814, "episode": 105.0, "batch_reward": 0.37452667048573496, "critic_loss": 0.16433274899423123, "actor_loss": -43.085119735717775, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.739250421524048, "step": 105000}
{"episode_reward": 599.1351361481712, "episode": 106.0, "batch_reward": 0.3764145429432392, "critic_loss": 0.15714874172210694, "actor_loss": -43.15984285736084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.939908027648926, "step": 106000}
{"episode_reward": 556.6282760361412, "episode": 107.0, "batch_reward": 0.37876108330488206, "critic_loss": 0.1462644337080419, "actor_loss": -43.31856982421875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.264225721359253, "step": 107000}
{"episode_reward": 612.1145541807907, "episode": 108.0, "batch_reward": 0.38157905504107476, "critic_loss": 0.14202233830094338, "actor_loss": -43.49509619903564, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.162516117095947, "step": 108000}
{"episode_reward": 579.9134644723588, "episode": 109.0, "batch_reward": 0.3821256896555424, "critic_loss": 0.1620759386494756, "actor_loss": -43.24310817718506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.345072269439697, "step": 109000}
{"episode_reward": 462.6223670274764, "episode": 110.0, "batch_reward": 0.3816037909090519, "critic_loss": 0.14100758365169166, "actor_loss": -43.344321563720705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.615564584732056, "step": 110000}
{"episode_reward": 137.2148051497081, "episode": 111.0, "batch_reward": 0.38132979917526244, "critic_loss": 0.16116165985167027, "actor_loss": -43.38986042785645, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.37879490852356, "step": 111000}
{"episode_reward": 609.7546518070147, "episode": 112.0, "batch_reward": 0.3840332828164101, "critic_loss": 0.16043741246685386, "actor_loss": -43.635083587646484, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.41001534461975, "step": 112000}
{"episode_reward": 618.6029227357498, "episode": 113.0, "batch_reward": 0.38548832792043686, "critic_loss": 0.18217593315988778, "actor_loss": -43.882485160827635, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.041722774505615, "step": 113000}
{"episode_reward": 606.5996600191387, "episode": 114.0, "batch_reward": 0.3874881425499916, "critic_loss": 0.16312464255839587, "actor_loss": -43.95473865509033, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.111332654953003, "step": 114000}
{"episode_reward": 580.8039184117499, "episode": 115.0, "batch_reward": 0.388856815546751, "critic_loss": 0.15246146580576897, "actor_loss": -44.18987372589111, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.1680326461792, "step": 115000}
{"episode_reward": 595.5884244912068, "episode": 116.0, "batch_reward": 0.3897688043117523, "critic_loss": 0.17821246991306544, "actor_loss": -44.37030915832519, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.039408922195435, "step": 116000}
{"episode_reward": 581.3108045062864, "episode": 117.0, "batch_reward": 0.3920894384980202, "critic_loss": 0.14608538623526693, "actor_loss": -44.63893923950195, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.639925241470337, "step": 117000}
{"episode_reward": 596.0472016813815, "episode": 118.0, "batch_reward": 0.3942328751385212, "critic_loss": 0.1551030530743301, "actor_loss": -44.64324346923828, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.181156873703003, "step": 118000}
{"episode_reward": 585.1999223205162, "episode": 119.0, "batch_reward": 0.39546348974108697, "critic_loss": 0.16174284578114748, "actor_loss": -44.814897415161134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.57260036468506, "step": 119000}
{"episode_reward": 555.907417828587, "episode": 120.0, "batch_reward": 0.3964576675593853, "critic_loss": 0.1936582679823041, "actor_loss": -44.72212200927734, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.494976043701172, "step": 120000}
{"episode_reward": 592.4847363192401, "episode": 121.0, "batch_reward": 0.398756716966629, "critic_loss": 0.16978463848680259, "actor_loss": -44.783845375061034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.17357587814331, "step": 121000}
{"episode_reward": 578.159834438974, "episode": 122.0, "batch_reward": 0.4009855039715767, "critic_loss": 0.1604315971210599, "actor_loss": -44.78397987365722, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.957425117492676, "step": 122000}
{"episode_reward": 603.6291083137137, "episode": 123.0, "batch_reward": 0.40148481249809265, "critic_loss": 0.19033171663433313, "actor_loss": -44.94384982299805, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.06435465812683, "step": 123000}
{"episode_reward": 557.2128712844112, "episode": 124.0, "batch_reward": 0.40237269642949103, "critic_loss": 0.16867660633474588, "actor_loss": -44.95684561920166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.048295736312866, "step": 124000}
{"episode_reward": 604.7029843008519, "episode": 125.0, "batch_reward": 0.4037639908492565, "critic_loss": 0.17567281952127814, "actor_loss": -44.944244468688964, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.066392421722412, "step": 125000}
{"episode_reward": 569.4777111901573, "episode": 126.0, "batch_reward": 0.4045791504085064, "critic_loss": 0.1805790620148182, "actor_loss": -45.2269084854126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.22882580757141, "step": 126000}
{"episode_reward": 606.7665517776878, "episode": 127.0, "batch_reward": 0.40626079922914504, "critic_loss": 0.19012554550915955, "actor_loss": -45.057553649902346, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.95371413230896, "step": 127000}
{"episode_reward": 599.1206711858507, "episode": 128.0, "batch_reward": 0.40877881947159767, "critic_loss": 0.1755733051598072, "actor_loss": -45.365677391052245, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.27583599090576, "step": 128000}
{"episode_reward": 628.5988962688068, "episode": 129.0, "batch_reward": 0.41015051051974294, "critic_loss": 0.16924775626510383, "actor_loss": -45.5220386428833, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.503325700759888, "step": 129000}
{"episode_reward": 609.1303101309231, "episode": 130.0, "batch_reward": 0.4124580326080322, "critic_loss": 0.15207511284947395, "actor_loss": -45.82015803527832, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.361753702163696, "step": 130000}
{"episode_reward": 552.8102707715078, "episode": 131.0, "batch_reward": 0.41319819080829623, "critic_loss": 0.19473132665455342, "actor_loss": -45.56158869171143, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.28156542778015, "step": 131000}
{"episode_reward": 589.1078044517426, "episode": 132.0, "batch_reward": 0.4148204028010368, "critic_loss": 0.17297844643890858, "actor_loss": -45.83014541625977, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.64072847366333, "step": 132000}
{"episode_reward": 355.87590686637304, "episode": 133.0, "batch_reward": 0.4132241944670677, "critic_loss": 0.16881289318576456, "actor_loss": -45.790287986755374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.69745945930481, "step": 133000}
{"episode_reward": 583.0329548872027, "episode": 134.0, "batch_reward": 0.414974837243557, "critic_loss": 0.15917591140791773, "actor_loss": -45.786865425109866, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.056506395339966, "step": 134000}
{"episode_reward": 591.9108515142702, "episode": 135.0, "batch_reward": 0.41657181322574616, "critic_loss": 0.17609377328678966, "actor_loss": -45.928274215698245, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.743958234786987, "step": 135000}
{"episode_reward": 606.2263095601514, "episode": 136.0, "batch_reward": 0.41786121478676796, "critic_loss": 0.160547348767519, "actor_loss": -45.932605018615725, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.848822355270386, "step": 136000}
{"episode_reward": 597.1375327176665, "episode": 137.0, "batch_reward": 0.418929941534996, "critic_loss": 0.1935642415471375, "actor_loss": -46.04485970306396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.94983983039856, "step": 137000}
{"episode_reward": 560.9148328232393, "episode": 138.0, "batch_reward": 0.4205163605213165, "critic_loss": 0.1853591824248433, "actor_loss": -46.2265637512207, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.84791135787964, "step": 138000}
{"episode_reward": 601.9586746392425, "episode": 139.0, "batch_reward": 0.4223684084713459, "critic_loss": 0.19055789468437434, "actor_loss": -46.51925437927246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.92942476272583, "step": 139000}
{"episode_reward": 608.038196313802, "episode": 140.0, "batch_reward": 0.4229410790205002, "critic_loss": 0.1828942644633353, "actor_loss": -46.4021921005249, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.168517351150513, "step": 140000}
{"episode_reward": 622.4226821164912, "episode": 141.0, "batch_reward": 0.425084719568491, "critic_loss": 0.17699976153299213, "actor_loss": -46.72424092102051, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.13855791091919, "step": 141000}
{"episode_reward": 593.6065352141712, "episode": 142.0, "batch_reward": 0.4252818537354469, "critic_loss": 0.19657485881075262, "actor_loss": -46.67533158874512, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.535120248794556, "step": 142000}
{"episode_reward": 613.4235838632707, "episode": 143.0, "batch_reward": 0.42742590108513834, "critic_loss": 0.17200807978212834, "actor_loss": -46.77288809967041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.750579595565796, "step": 143000}
{"episode_reward": 620.6407141474037, "episode": 144.0, "batch_reward": 0.42918146860599515, "critic_loss": 0.16124861264973878, "actor_loss": -46.84097177886963, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.834036350250244, "step": 144000}
{"episode_reward": 596.5583976181189, "episode": 145.0, "batch_reward": 0.42976996076107027, "critic_loss": 0.1705948454514146, "actor_loss": -46.81154707336426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.80494236946106, "step": 145000}
{"episode_reward": 610.4953421410294, "episode": 146.0, "batch_reward": 0.42951015433669093, "critic_loss": 0.1669480506181717, "actor_loss": -47.10291783905029, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.870421886444092, "step": 146000}
{"episode_reward": 605.6042890665442, "episode": 147.0, "batch_reward": 0.43117370522022247, "critic_loss": 0.1685035476014018, "actor_loss": -46.856275299072266, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.983332633972168, "step": 147000}
{"episode_reward": 588.2512294873079, "episode": 148.0, "batch_reward": 0.4335862590074539, "critic_loss": 0.17954624865204097, "actor_loss": -47.26254973602295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.76486849784851, "step": 148000}
{"episode_reward": 636.581879444972, "episode": 149.0, "batch_reward": 0.4351972290277481, "critic_loss": 0.18125562036037446, "actor_loss": -47.44486334228515, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.898428678512573, "step": 149000}
{"episode_reward": 575.4073406045626, "episode": 150.0, "batch_reward": 0.43612097018957136, "critic_loss": 0.1889893953129649, "actor_loss": -47.6495916519165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
