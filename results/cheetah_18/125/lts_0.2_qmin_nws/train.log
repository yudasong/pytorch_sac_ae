{"episode_reward": 0.0, "episode": 1.0, "duration": 18.896557569503784, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.5420849323272705, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.21791850341960325, "critic_loss": 0.03541544026894872, "actor_loss": -9.947786708985891, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 70.43133521080017, "step": 3000}
{"episode_reward": 24.325160679488363, "episode": 4.0, "batch_reward": 0.14325370439141988, "critic_loss": 0.047837389844469724, "actor_loss": -10.450451725006104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22183346748352, "step": 4000}
{"episode_reward": 39.16703334890835, "episode": 5.0, "batch_reward": 0.1227196775302291, "critic_loss": 0.042133577108383176, "actor_loss": -9.9335847864151, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.385139226913452, "step": 5000}
{"episode_reward": 100.93458332194704, "episode": 6.0, "batch_reward": 0.12209070343524217, "critic_loss": 0.059044533401727675, "actor_loss": -10.16414982032776, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.61767053604126, "step": 6000}
{"episode_reward": 66.2797429925226, "episode": 7.0, "batch_reward": 0.11890830444544553, "critic_loss": 0.06797691957652569, "actor_loss": -10.688028549671174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.88981032371521, "step": 7000}
{"episode_reward": 160.10442712176481, "episode": 8.0, "batch_reward": 0.11918445987254381, "critic_loss": 0.07265375182405114, "actor_loss": -10.288153909683228, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.516281127929688, "step": 8000}
{"episode_reward": 47.083103602125675, "episode": 9.0, "batch_reward": 0.11855641812831164, "critic_loss": 0.10180821469798684, "actor_loss": -11.205582847595215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.379812717437744, "step": 9000}
{"episode_reward": 229.8956610780887, "episode": 10.0, "batch_reward": 0.12383307356387377, "critic_loss": 0.10799208768084645, "actor_loss": -11.643468857765198, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.636742115020752, "step": 10000}
{"episode_reward": 58.3384138686357, "episode": 11.0, "batch_reward": 0.12226438569277524, "critic_loss": 0.1319742357581854, "actor_loss": -13.059961987495422, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.578431129455566, "step": 11000}
{"episode_reward": 168.99013606693958, "episode": 12.0, "batch_reward": 0.12025793017446995, "critic_loss": 0.13054630982130766, "actor_loss": -12.61942126941681, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.774067401885986, "step": 12000}
{"episode_reward": 33.030999929903075, "episode": 13.0, "batch_reward": 0.11670310113579035, "critic_loss": 0.13726054491847753, "actor_loss": -12.944941969871522, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.85230302810669, "step": 13000}
{"episode_reward": 128.76772995862396, "episode": 14.0, "batch_reward": 0.11385361230373382, "critic_loss": 0.20295003423839808, "actor_loss": -12.95959783935547, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.933155059814453, "step": 14000}
{"episode_reward": 28.704460642546067, "episode": 15.0, "batch_reward": 0.11278108382970095, "critic_loss": 0.21286296536773444, "actor_loss": -13.423781546592712, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.73863959312439, "step": 15000}
{"episode_reward": 120.86824923934, "episode": 16.0, "batch_reward": 0.11047109404206276, "critic_loss": 0.2172609294950962, "actor_loss": -13.867240983963013, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.997759342193604, "step": 16000}
{"episode_reward": 76.25377918275281, "episode": 17.0, "batch_reward": 0.10894845310598612, "critic_loss": 0.20719166090339422, "actor_loss": -13.562662567138672, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.62381148338318, "step": 17000}
{"episode_reward": 47.71507256455692, "episode": 18.0, "batch_reward": 0.10282976730167866, "critic_loss": 0.1946779709458351, "actor_loss": -13.8056273021698, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.271204710006714, "step": 18000}
{"episode_reward": 4.379862755449215, "episode": 19.0, "batch_reward": 0.09711235911026597, "critic_loss": 0.1800971525758505, "actor_loss": -15.448426860809326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.965171813964844, "step": 19000}
{"episode_reward": 6.735154017890876, "episode": 20.0, "batch_reward": 0.09215244687721133, "critic_loss": 0.18393327351659536, "actor_loss": -15.768819248199463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.56255078315735, "step": 20000}
{"episode_reward": 4.714352355728933, "episode": 21.0, "batch_reward": 0.0901130207143724, "critic_loss": 0.19910978820174932, "actor_loss": -16.61616039085388, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.32996940612793, "step": 21000}
{"episode_reward": 78.53598604721148, "episode": 22.0, "batch_reward": 0.08857159125804902, "critic_loss": 0.2052098022699356, "actor_loss": -16.34706010246277, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.86283302307129, "step": 22000}
{"episode_reward": 31.167457653889475, "episode": 23.0, "batch_reward": 0.08899554523453117, "critic_loss": 0.2345472754985094, "actor_loss": -15.849480173110962, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.94967293739319, "step": 23000}
{"episode_reward": 118.07348754946666, "episode": 24.0, "batch_reward": 0.08847641322389245, "critic_loss": 0.30027940556406973, "actor_loss": -16.123455404281618, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.157654523849487, "step": 24000}
{"episode_reward": 74.92692454192537, "episode": 25.0, "batch_reward": 0.08972437402233481, "critic_loss": 0.3023760951086879, "actor_loss": -16.56604253959656, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.191585540771484, "step": 25000}
{"episode_reward": 96.17191196506599, "episode": 26.0, "batch_reward": 0.09085167175903916, "critic_loss": 0.35322113665938376, "actor_loss": -16.882434167861938, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.64976143836975, "step": 26000}
{"episode_reward": 224.1196253754323, "episode": 27.0, "batch_reward": 0.09494345797598362, "critic_loss": 0.39878542777895926, "actor_loss": -17.292519721984863, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.161031007766724, "step": 27000}
{"episode_reward": 126.48174296345927, "episode": 28.0, "batch_reward": 0.09718130526319146, "critic_loss": 0.3982270416766405, "actor_loss": -17.58710899543762, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.04576086997986, "step": 28000}
{"episode_reward": 267.38646259884746, "episode": 29.0, "batch_reward": 0.10426013852655888, "critic_loss": 0.4143356542736292, "actor_loss": -18.456329736709595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.37749433517456, "step": 29000}
{"episode_reward": 272.8932371705925, "episode": 30.0, "batch_reward": 0.10805765934288501, "critic_loss": 0.376279992043972, "actor_loss": -18.928025039672853, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.52844500541687, "step": 30000}
{"episode_reward": 109.59212514635553, "episode": 31.0, "batch_reward": 0.10947367747873069, "critic_loss": 0.3940867181569338, "actor_loss": -19.06918955421448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.388458013534546, "step": 31000}
{"episode_reward": 308.02224615779045, "episode": 32.0, "batch_reward": 0.1159675155878067, "critic_loss": 0.40752792011201383, "actor_loss": -20.01919796180725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.612142086029053, "step": 32000}
{"episode_reward": 312.5608651573497, "episode": 33.0, "batch_reward": 0.12291736174374819, "critic_loss": 0.41014512567222117, "actor_loss": -20.686350330352784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.70499014854431, "step": 33000}
{"episode_reward": 327.0635861723299, "episode": 34.0, "batch_reward": 0.12634531208872796, "critic_loss": 0.4008939145803452, "actor_loss": -20.543446809768678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.38553285598755, "step": 34000}
{"episode_reward": 105.1001663088235, "episode": 35.0, "batch_reward": 0.12590703904628753, "critic_loss": 0.4271759932041168, "actor_loss": -20.717312158584594, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.451972723007202, "step": 35000}
{"episode_reward": 92.82723345135483, "episode": 36.0, "batch_reward": 0.12569372382760047, "critic_loss": 0.4191752346009016, "actor_loss": -20.92859854507446, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.466607332229614, "step": 36000}
{"episode_reward": 171.20801228662827, "episode": 37.0, "batch_reward": 0.12577046705037356, "critic_loss": 0.41991002184152604, "actor_loss": -20.814093664169313, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27303719520569, "step": 37000}
{"episode_reward": 73.39254544690507, "episode": 38.0, "batch_reward": 0.12419442596286535, "critic_loss": 0.42615207260847093, "actor_loss": -20.74447195625305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.208483695983887, "step": 38000}
{"episode_reward": 53.79716657985052, "episode": 39.0, "batch_reward": 0.12551852232962846, "critic_loss": 0.47186217790842055, "actor_loss": -21.192973196029662, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.570433855056763, "step": 39000}
{"episode_reward": 328.6002828433042, "episode": 40.0, "batch_reward": 0.13133159998059274, "critic_loss": 0.4579294343739748, "actor_loss": -21.52651486968994, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3794949054718, "step": 40000}
{"episode_reward": 440.7849705448781, "episode": 41.0, "batch_reward": 0.13788833124935626, "critic_loss": 0.4728694752305746, "actor_loss": -22.087527027130125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.10284447669983, "step": 41000}
{"episode_reward": 180.46929163299873, "episode": 42.0, "batch_reward": 0.139105495326221, "critic_loss": 0.442394978672266, "actor_loss": -21.850676052093505, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14256453514099, "step": 42000}
{"episode_reward": 445.0208450467402, "episode": 43.0, "batch_reward": 0.14728741105645896, "critic_loss": 0.43511059410870073, "actor_loss": -22.828905006408693, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.348017930984497, "step": 43000}
{"episode_reward": 419.12721416120417, "episode": 44.0, "batch_reward": 0.1535926461517811, "critic_loss": 0.42279582864046095, "actor_loss": -23.33640786743164, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.901489973068237, "step": 44000}
{"episode_reward": 441.5856929335159, "episode": 45.0, "batch_reward": 0.1581564245969057, "critic_loss": 0.38458702009916307, "actor_loss": -23.85878646469116, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.91500234603882, "step": 45000}
{"episode_reward": 123.09064871823345, "episode": 46.0, "batch_reward": 0.15881091875582934, "critic_loss": 0.37196476131677625, "actor_loss": -23.91924925994873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.976106882095337, "step": 46000}
{"episode_reward": 394.68929729248794, "episode": 47.0, "batch_reward": 0.16453002305328845, "critic_loss": 0.37804394809901715, "actor_loss": -24.201796447753907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.980666875839233, "step": 47000}
{"episode_reward": 422.26573048416066, "episode": 48.0, "batch_reward": 0.1683506184220314, "critic_loss": 0.36958522276580336, "actor_loss": -24.227055404663087, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.612452030181885, "step": 48000}
{"episode_reward": 267.4450490417818, "episode": 49.0, "batch_reward": 0.16957728539407252, "critic_loss": 0.41365435341000556, "actor_loss": -24.36958783721924, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.19862675666809, "step": 49000}
{"episode_reward": 121.29293433304902, "episode": 50.0, "batch_reward": 0.16984370231628418, "critic_loss": 0.41935318429768087, "actor_loss": -24.504885375976563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.089040756225586, "step": 50000}
{"episode_reward": 479.9702991460867, "episode": 51.0, "batch_reward": 0.177342674061656, "critic_loss": 0.38924255268275737, "actor_loss": -24.901959659576416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.60111212730408, "step": 51000}
{"episode_reward": 476.9020890589257, "episode": 52.0, "batch_reward": 0.18256887416541576, "critic_loss": 0.4075510032325983, "actor_loss": -25.812935176849365, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.905739068984985, "step": 52000}
{"episode_reward": 436.63514866104384, "episode": 53.0, "batch_reward": 0.18770116877555848, "critic_loss": 0.4368408882021904, "actor_loss": -26.02459325790405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.042044639587402, "step": 53000}
{"episode_reward": 474.647382987231, "episode": 54.0, "batch_reward": 0.19305892053246498, "critic_loss": 0.37181433075666426, "actor_loss": -26.21756536102295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.971880674362183, "step": 54000}
{"episode_reward": 474.590115568808, "episode": 55.0, "batch_reward": 0.19687953120470048, "critic_loss": 0.3371150082349777, "actor_loss": -26.682849533081054, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.887390851974487, "step": 55000}
{"episode_reward": 143.8139853186002, "episode": 56.0, "batch_reward": 0.19654764497280122, "critic_loss": 0.34575487099587915, "actor_loss": -26.63495840835571, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.183518409729004, "step": 56000}
{"episode_reward": 463.144113313855, "episode": 57.0, "batch_reward": 0.2024253536015749, "critic_loss": 0.3157653133869171, "actor_loss": -27.621784996032716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.244912147521973, "step": 57000}
{"episode_reward": 451.29142862899454, "episode": 58.0, "batch_reward": 0.2073316530585289, "critic_loss": 0.31273552199453114, "actor_loss": -27.799035251617433, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.814412593841553, "step": 58000}
{"episode_reward": 459.130505922038, "episode": 59.0, "batch_reward": 0.21090815915167332, "critic_loss": 0.3506135557293892, "actor_loss": -28.49806640625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.66209650039673, "step": 59000}
{"episode_reward": 478.93732394749225, "episode": 60.0, "batch_reward": 0.21557327581942082, "critic_loss": 0.29576831613481047, "actor_loss": -29.062606716156004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.74732208251953, "step": 60000}
{"episode_reward": 487.74954433577534, "episode": 61.0, "batch_reward": 0.22058330997824668, "critic_loss": 0.34000985450297594, "actor_loss": -29.124034065246583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.74316358566284, "step": 61000}
{"episode_reward": 483.6835433902707, "episode": 62.0, "batch_reward": 0.22347769631445408, "critic_loss": 0.33320035064220427, "actor_loss": -29.336239471435547, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.404712677001953, "step": 62000}
{"episode_reward": 417.0705807579988, "episode": 63.0, "batch_reward": 0.2266846215724945, "critic_loss": 0.34445422974228856, "actor_loss": -30.02522776412964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.44905185699463, "step": 63000}
{"episode_reward": 412.85414542645196, "episode": 64.0, "batch_reward": 0.2294758052378893, "critic_loss": 0.3717501521706581, "actor_loss": -29.93955345916748, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.918606758117676, "step": 64000}
{"episode_reward": 439.4503628993951, "episode": 65.0, "batch_reward": 0.23274514321982862, "critic_loss": 0.38863278956711295, "actor_loss": -30.14438423919678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.90795350074768, "step": 65000}
{"episode_reward": 261.9158444791764, "episode": 66.0, "batch_reward": 0.23453319407999515, "critic_loss": 0.3379454331845045, "actor_loss": -30.26346057891846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.315470695495605, "step": 66000}
{"episode_reward": 489.22347755330213, "episode": 67.0, "batch_reward": 0.23799115577340127, "critic_loss": 0.3500035958737135, "actor_loss": -30.52773784637451, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.461613655090332, "step": 67000}
{"episode_reward": 499.22936400988436, "episode": 68.0, "batch_reward": 0.24106524080038072, "critic_loss": 0.3690279359072447, "actor_loss": -30.663189704895018, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.861987352371216, "step": 68000}
{"episode_reward": 513.9723290117997, "episode": 69.0, "batch_reward": 0.2448647230565548, "critic_loss": 0.36629700429737566, "actor_loss": -31.03787201309204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.84944462776184, "step": 69000}
{"episode_reward": 481.2204145261797, "episode": 70.0, "batch_reward": 0.24899021223187445, "critic_loss": 0.3602805622816086, "actor_loss": -31.285304302215575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.05719518661499, "step": 70000}
{"episode_reward": 515.7806155623618, "episode": 71.0, "batch_reward": 0.2534176986068487, "critic_loss": 0.3602181706726551, "actor_loss": -31.600648635864257, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.71138620376587, "step": 71000}
{"episode_reward": 526.0181500764727, "episode": 72.0, "batch_reward": 0.25627833437919617, "critic_loss": 0.3316392711997032, "actor_loss": -32.014979625701905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.378726720809937, "step": 72000}
{"episode_reward": 551.9793417524644, "episode": 73.0, "batch_reward": 0.260467523291707, "critic_loss": 0.3448950216919184, "actor_loss": -32.42356404876709, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.243956804275513, "step": 73000}
{"episode_reward": 509.56804593375233, "episode": 74.0, "batch_reward": 0.26345001520216466, "critic_loss": 0.3352095284610987, "actor_loss": -32.70328726959229, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.973763465881348, "step": 74000}
{"episode_reward": 271.6744350851442, "episode": 75.0, "batch_reward": 0.26437048806250096, "critic_loss": 0.33103955852985384, "actor_loss": -32.66610985946655, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30337166786194, "step": 75000}
{"episode_reward": 535.9147643260287, "episode": 76.0, "batch_reward": 0.26706901580095294, "critic_loss": 0.31603084144741295, "actor_loss": -32.74140782546997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.754076957702637, "step": 76000}
{"episode_reward": 275.22807674249015, "episode": 77.0, "batch_reward": 0.2680964340120554, "critic_loss": 0.3386455965489149, "actor_loss": -33.016558864593506, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.226688861846924, "step": 77000}
{"episode_reward": 529.8880679886548, "episode": 78.0, "batch_reward": 0.27119157652556897, "critic_loss": 0.3395603254288435, "actor_loss": -33.26851558685303, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.101006746292114, "step": 78000}
{"episode_reward": 533.1285544252119, "episode": 79.0, "batch_reward": 0.2746287819892168, "critic_loss": 0.3153750344887376, "actor_loss": -33.412999465942384, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.68172025680542, "step": 79000}
{"episode_reward": 530.7969746769022, "episode": 80.0, "batch_reward": 0.2779713145047426, "critic_loss": 0.30563284213840963, "actor_loss": -33.4163317527771, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.811959981918335, "step": 80000}
{"episode_reward": 540.4536641791731, "episode": 81.0, "batch_reward": 0.28226970364153386, "critic_loss": 0.33780076090991495, "actor_loss": -34.03118725204468, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.702868938446045, "step": 81000}
{"episode_reward": 532.4513764170084, "episode": 82.0, "batch_reward": 0.285859876409173, "critic_loss": 0.3139160273075104, "actor_loss": -34.1879746055603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.334178686141968, "step": 82000}
{"episode_reward": 527.8419529196682, "episode": 83.0, "batch_reward": 0.2875710666775703, "critic_loss": 0.2992244697511196, "actor_loss": -34.318632610321046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.276347875595093, "step": 83000}
{"episode_reward": 532.1560642665576, "episode": 84.0, "batch_reward": 0.29034564226865767, "critic_loss": 0.2979645697250962, "actor_loss": -34.534769969940186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.127395629882812, "step": 84000}
{"episode_reward": 554.6965417516674, "episode": 85.0, "batch_reward": 0.29341127042472365, "critic_loss": 0.302477113597095, "actor_loss": -34.63177536392212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.80761694908142, "step": 85000}
{"episode_reward": 545.809941524575, "episode": 86.0, "batch_reward": 0.29638744284212587, "critic_loss": 0.2919691780358553, "actor_loss": -34.79510847854614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.402706623077393, "step": 86000}
{"episode_reward": 523.6707167544783, "episode": 87.0, "batch_reward": 0.2990631431937218, "critic_loss": 0.30089887586981057, "actor_loss": -34.90127159500122, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.875802993774414, "step": 87000}
{"episode_reward": 543.5341783476911, "episode": 88.0, "batch_reward": 0.30103878578543664, "critic_loss": 0.3125009638592601, "actor_loss": -35.04901515579223, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.314804553985596, "step": 88000}
{"episode_reward": 548.0581020972501, "episode": 89.0, "batch_reward": 0.3040445922464132, "critic_loss": 0.29353118839859965, "actor_loss": -35.401169158935545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.267833471298218, "step": 89000}
{"episode_reward": 543.8148244693366, "episode": 90.0, "batch_reward": 0.3072019974142313, "critic_loss": 0.2595584730356932, "actor_loss": -35.74330877685547, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.930772304534912, "step": 90000}
{"episode_reward": 488.4591941229727, "episode": 91.0, "batch_reward": 0.30901993465423583, "critic_loss": 0.27292856708168983, "actor_loss": -35.6586759147644, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.94579315185547, "step": 91000}
{"episode_reward": 560.9096332104176, "episode": 92.0, "batch_reward": 0.31166524009406565, "critic_loss": 0.28435529974848034, "actor_loss": -35.953786693573, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.622119426727295, "step": 92000}
{"episode_reward": 502.3963891636554, "episode": 93.0, "batch_reward": 0.3140241041779518, "critic_loss": 0.26397875068336724, "actor_loss": -36.094552684783935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.033398389816284, "step": 93000}
{"episode_reward": 545.6037743530845, "episode": 94.0, "batch_reward": 0.31608898991346357, "critic_loss": 0.28532100293785334, "actor_loss": -36.46984819793701, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.719634771347046, "step": 94000}
{"episode_reward": 528.4780268134012, "episode": 95.0, "batch_reward": 0.3189167663455009, "critic_loss": 0.2708090244308114, "actor_loss": -36.89473628234863, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.946917295455933, "step": 95000}
{"episode_reward": 535.8345770716248, "episode": 96.0, "batch_reward": 0.31966828283667564, "critic_loss": 0.275667863458395, "actor_loss": -36.87997655105591, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.31093668937683, "step": 96000}
{"episode_reward": 511.5379241296289, "episode": 97.0, "batch_reward": 0.3224626781642437, "critic_loss": 0.2670560003519058, "actor_loss": -37.190907279968265, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.802321672439575, "step": 97000}
{"episode_reward": 490.5993461179194, "episode": 98.0, "batch_reward": 0.3253209641575813, "critic_loss": 0.26318610229343176, "actor_loss": -37.457332237243655, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.254788875579834, "step": 98000}
{"episode_reward": 531.1566266316614, "episode": 99.0, "batch_reward": 0.3272098327577114, "critic_loss": 0.3047824197337031, "actor_loss": -37.592922790527346, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.784913778305054, "step": 99000}
{"episode_reward": 534.5672773452819, "episode": 100.0, "batch_reward": 0.3297248492538929, "critic_loss": 0.28398986654728653, "actor_loss": -37.67753656768799, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.221684455871582, "step": 100000}
{"episode_reward": 534.111779945055, "episode": 101.0, "batch_reward": 0.3308896130621433, "critic_loss": 0.28446343856304884, "actor_loss": -37.84804442596435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.30913996696472, "step": 101000}
{"episode_reward": 540.8177918975355, "episode": 102.0, "batch_reward": 0.3317809495329857, "critic_loss": 0.2841483596861362, "actor_loss": -37.999391098022464, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.80218505859375, "step": 102000}
{"episode_reward": 515.7302229093148, "episode": 103.0, "batch_reward": 0.33275194826722143, "critic_loss": 0.300879611261189, "actor_loss": -37.98774257659912, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.250911235809326, "step": 103000}
{"episode_reward": 500.94114197178, "episode": 104.0, "batch_reward": 0.3372889918684959, "critic_loss": 0.3246665092036128, "actor_loss": -38.06766076660156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.53876519203186, "step": 104000}
{"episode_reward": 361.52362970291637, "episode": 105.0, "batch_reward": 0.33686018776893617, "critic_loss": 0.3142382950484753, "actor_loss": -38.08030276107788, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.755101203918457, "step": 105000}
{"episode_reward": 550.5953614825734, "episode": 106.0, "batch_reward": 0.3381418982744217, "critic_loss": 0.33844155293703077, "actor_loss": -37.985056312561035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.062007188796997, "step": 106000}
{"episode_reward": 540.7577517549599, "episode": 107.0, "batch_reward": 0.34135620009899137, "critic_loss": 0.3297645765990019, "actor_loss": -38.54552243804932, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.308966398239136, "step": 107000}
{"episode_reward": 538.7949254147511, "episode": 108.0, "batch_reward": 0.34220272383093836, "critic_loss": 0.3301986031085253, "actor_loss": -38.91847801971436, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.769383192062378, "step": 108000}
{"episode_reward": 579.8297242000159, "episode": 109.0, "batch_reward": 0.34415962943434714, "critic_loss": 0.33246058028936387, "actor_loss": -38.97080670166016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.631804704666138, "step": 109000}
{"episode_reward": 513.7162772153139, "episode": 110.0, "batch_reward": 0.3461607221364975, "critic_loss": 0.3281489550024271, "actor_loss": -39.06872883605957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.63690185546875, "step": 110000}
{"episode_reward": 543.0414001393684, "episode": 111.0, "batch_reward": 0.34859622246026994, "critic_loss": 0.3296751765012741, "actor_loss": -39.52669610595703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.14303278923035, "step": 111000}
{"episode_reward": 561.5502667666904, "episode": 112.0, "batch_reward": 0.35008982476592065, "critic_loss": 0.34545125549286604, "actor_loss": -39.515142982482914, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.65038013458252, "step": 112000}
{"episode_reward": 550.5800941325296, "episode": 113.0, "batch_reward": 0.352149488478899, "critic_loss": 0.3092240437492728, "actor_loss": -39.469280380249025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.655054569244385, "step": 113000}
{"episode_reward": 576.9017936308403, "episode": 114.0, "batch_reward": 0.3530783919394016, "critic_loss": 0.30482857117801904, "actor_loss": -39.74783577728272, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.44407820701599, "step": 114000}
{"episode_reward": 526.5981764000427, "episode": 115.0, "batch_reward": 0.3557310512959957, "critic_loss": 0.31808275077492, "actor_loss": -39.92055267333984, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23846936225891, "step": 115000}
{"episode_reward": 581.4455083479269, "episode": 116.0, "batch_reward": 0.35736398243904116, "critic_loss": 0.3253409047499299, "actor_loss": -40.01154514312744, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.661667108535767, "step": 116000}
{"episode_reward": 570.1584939320278, "episode": 117.0, "batch_reward": 0.3596321136653423, "critic_loss": 0.3352732125595212, "actor_loss": -40.2066471786499, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.439490795135498, "step": 117000}
{"episode_reward": 549.3803311563586, "episode": 118.0, "batch_reward": 0.3606185116767883, "critic_loss": 0.30663695369660854, "actor_loss": -40.14503366851807, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.011382579803467, "step": 118000}
{"episode_reward": 544.0993444896374, "episode": 119.0, "batch_reward": 0.3625525872707367, "critic_loss": 0.3293921170309186, "actor_loss": -40.260208534240725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.501577615737915, "step": 119000}
{"episode_reward": 549.2713740121368, "episode": 120.0, "batch_reward": 0.3631939722597599, "critic_loss": 0.32251182656735183, "actor_loss": -40.244174102783205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.11077380180359, "step": 120000}
{"episode_reward": 591.8283324081266, "episode": 121.0, "batch_reward": 0.3661905271112919, "critic_loss": 0.3121304413601756, "actor_loss": -40.60242861175537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.16701793670654, "step": 121000}
{"episode_reward": 560.7928013408997, "episode": 122.0, "batch_reward": 0.3673184613287449, "critic_loss": 0.3291811307370663, "actor_loss": -40.773942413330076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.88887882232666, "step": 122000}
{"episode_reward": 369.8707095149102, "episode": 123.0, "batch_reward": 0.36785402619838714, "critic_loss": 0.32806428950279953, "actor_loss": -40.551569534301755, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.536126852035522, "step": 123000}
{"episode_reward": 327.6865778006067, "episode": 124.0, "batch_reward": 0.3671418792009354, "critic_loss": 0.33521650763601063, "actor_loss": -40.63970719146729, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.462583780288696, "step": 124000}
{"episode_reward": 573.6361010735386, "episode": 125.0, "batch_reward": 0.3688465886414051, "critic_loss": 0.32842147587239745, "actor_loss": -40.72173260498047, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.308568477630615, "step": 125000}
{"episode_reward": 558.2614295987066, "episode": 126.0, "batch_reward": 0.3693219987750053, "critic_loss": 0.33749502564966677, "actor_loss": -40.876038597106934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.718403339385986, "step": 126000}
{"episode_reward": 550.9292019269164, "episode": 127.0, "batch_reward": 0.3714092708826065, "critic_loss": 0.31400364427268507, "actor_loss": -41.05168408966065, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.027366399765015, "step": 127000}
{"episode_reward": 539.999609688384, "episode": 128.0, "batch_reward": 0.37229716050624845, "critic_loss": 0.3161225748360157, "actor_loss": -41.15310961151123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.340045928955078, "step": 128000}
{"episode_reward": 574.2032887117648, "episode": 129.0, "batch_reward": 0.373586925804615, "critic_loss": 0.31839313931763175, "actor_loss": -41.43026431274414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.18903636932373, "step": 129000}
{"episode_reward": 238.66392476894995, "episode": 130.0, "batch_reward": 0.3729505122601986, "critic_loss": 0.34645148491859434, "actor_loss": -41.125615341186524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14389657974243, "step": 130000}
{"episode_reward": 537.1346770236863, "episode": 131.0, "batch_reward": 0.3759249403774738, "critic_loss": 0.3273206623792648, "actor_loss": -41.287661849975585, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.636369705200195, "step": 131000}
{"episode_reward": 557.1222095159618, "episode": 132.0, "batch_reward": 0.37658464908599854, "critic_loss": 0.29763742635399104, "actor_loss": -41.29080731964111, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.530755043029785, "step": 132000}
{"episode_reward": 575.2468300606232, "episode": 133.0, "batch_reward": 0.37627962642908097, "critic_loss": 0.3421104402095079, "actor_loss": -41.45402996826172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.696208477020264, "step": 133000}
{"episode_reward": 494.66237287720134, "episode": 134.0, "batch_reward": 0.37761122059822083, "critic_loss": 0.2936709165200591, "actor_loss": -41.445632598876955, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.257046461105347, "step": 134000}
{"episode_reward": 348.94291146070964, "episode": 135.0, "batch_reward": 0.3780340675413609, "critic_loss": 0.34575133127719165, "actor_loss": -41.26945530700684, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.763248682022095, "step": 135000}
{"episode_reward": 576.9400569307003, "episode": 136.0, "batch_reward": 0.37974617442488673, "critic_loss": 0.36196937983483074, "actor_loss": -41.81278374481201, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.005055904388428, "step": 136000}
{"episode_reward": 564.8127900998603, "episode": 137.0, "batch_reward": 0.3806689208447933, "critic_loss": 0.3698989694714546, "actor_loss": -41.514439216613766, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.160872220993042, "step": 137000}
{"episode_reward": 567.0172104539638, "episode": 138.0, "batch_reward": 0.38232004863023755, "critic_loss": 0.33340714360028506, "actor_loss": -41.60916230773926, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.24307370185852, "step": 138000}
{"episode_reward": 563.9114118891953, "episode": 139.0, "batch_reward": 0.38394923335313796, "critic_loss": 0.32403804777562617, "actor_loss": -41.9810128326416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.45241355895996, "step": 139000}
{"episode_reward": 521.6727551933795, "episode": 140.0, "batch_reward": 0.38395192664861677, "critic_loss": 0.31650587534159424, "actor_loss": -41.99740093231201, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.999335050582886, "step": 140000}
{"episode_reward": 566.7823330657501, "episode": 141.0, "batch_reward": 0.3865095077753067, "critic_loss": 0.3541139750406146, "actor_loss": -42.04280229949951, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.86919283866882, "step": 141000}
{"episode_reward": 589.6338969696236, "episode": 142.0, "batch_reward": 0.38641473042964936, "critic_loss": 0.3526254014968872, "actor_loss": -41.774117393493654, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.83525824546814, "step": 142000}
{"episode_reward": 569.3294408735346, "episode": 143.0, "batch_reward": 0.3894265548884869, "critic_loss": 0.36589842130243777, "actor_loss": -42.34793884277344, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.653156518936157, "step": 143000}
{"episode_reward": 563.9137015622769, "episode": 144.0, "batch_reward": 0.39006005427241325, "critic_loss": 0.34928976302593945, "actor_loss": -42.46388101196289, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.649258375167847, "step": 144000}
{"episode_reward": 568.9373599849041, "episode": 145.0, "batch_reward": 0.392248908162117, "critic_loss": 0.33546883431077, "actor_loss": -42.48635451507568, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.395496368408203, "step": 145000}
{"episode_reward": 587.5894340032902, "episode": 146.0, "batch_reward": 0.3924079205393791, "critic_loss": 0.32928903925418856, "actor_loss": -42.57136376953125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.153361797332764, "step": 146000}
{"episode_reward": 576.9209557607792, "episode": 147.0, "batch_reward": 0.3938039786219597, "critic_loss": 0.3092435896322131, "actor_loss": -42.69642762756347, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.400855779647827, "step": 147000}
{"episode_reward": 552.3872019902419, "episode": 148.0, "batch_reward": 0.39472326907515526, "critic_loss": 0.32332653824985025, "actor_loss": -42.82934837341308, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.722529411315918, "step": 148000}
{"episode_reward": 563.8859146045348, "episode": 149.0, "batch_reward": 0.3970207605957985, "critic_loss": 0.3271791784837842, "actor_loss": -42.88652928924561, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.035012006759644, "step": 149000}
{"episode_reward": 537.6615944874711, "episode": 150.0, "batch_reward": 0.39737212264537813, "critic_loss": 0.33520738228410485, "actor_loss": -43.0031209640503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
