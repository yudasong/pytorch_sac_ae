{"episode_reward": 0.0, "episode": 1.0, "duration": 17.55413508415222, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.5192365646362305, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.21694713222777776, "critic_loss": 0.02698342662862688, "actor_loss": -28.99810369534283, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 68.34839344024658, "step": 3000}
{"episode_reward": 15.926243626513717, "episode": 4.0, "batch_reward": 0.13780598367005586, "critic_loss": 0.02956366119813174, "actor_loss": -26.924073548316954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.199349880218506, "step": 4000}
{"episode_reward": 2.2440730225162415, "episode": 5.0, "batch_reward": 0.10614987619221211, "critic_loss": 0.02709874798823148, "actor_loss": -23.655694665908815, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.787657737731934, "step": 5000}
{"episode_reward": 1.2664266424511932, "episode": 6.0, "batch_reward": 0.08671072160825133, "critic_loss": 0.03058938485290855, "actor_loss": -23.632868176460267, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.238890647888184, "step": 6000}
{"episode_reward": 1.0223557113144455, "episode": 7.0, "batch_reward": 0.0734895353987813, "critic_loss": 0.034367779864929615, "actor_loss": -25.075553741455078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.022456645965576, "step": 7000}
{"episode_reward": 1.1800878281539364, "episode": 8.0, "batch_reward": 0.0643719238974154, "critic_loss": 0.03968640564056113, "actor_loss": -23.664950825691225, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.63729166984558, "step": 8000}
{"episode_reward": 1.5438466883095066, "episode": 9.0, "batch_reward": 0.05665000811219215, "critic_loss": 0.046228254588320854, "actor_loss": -22.639719814300538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.429072856903076, "step": 9000}
{"episode_reward": 1.277187728184372, "episode": 10.0, "batch_reward": 0.051301166916266086, "critic_loss": 0.041739056458463895, "actor_loss": -23.00883946275711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.27505326271057, "step": 10000}
{"episode_reward": 1.6136331561399828, "episode": 11.0, "batch_reward": 0.04659854722209275, "critic_loss": 0.044370985021116215, "actor_loss": -23.348389533519743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.443251848220825, "step": 11000}
{"episode_reward": 0.9733075740073316, "episode": 12.0, "batch_reward": 0.04284302786923945, "critic_loss": 0.0447680107052438, "actor_loss": -21.7184562125206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.80632257461548, "step": 12000}
{"episode_reward": 1.2085085114408858, "episode": 13.0, "batch_reward": 0.03926374011579901, "critic_loss": 0.045309666311601174, "actor_loss": -21.93626380443573, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.30212140083313, "step": 13000}
{"episode_reward": 2.2020646462115345, "episode": 14.0, "batch_reward": 0.036020190177485346, "critic_loss": 0.03863658739789389, "actor_loss": -20.229596435546874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.808167219161987, "step": 14000}
{"episode_reward": 1.6531448155104251, "episode": 15.0, "batch_reward": 0.03413746214937419, "critic_loss": 0.04462257303600199, "actor_loss": -22.91239834499359, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.107741355895996, "step": 15000}
{"episode_reward": 1.694465377400967, "episode": 16.0, "batch_reward": 0.031660746127367016, "critic_loss": 0.04403215572214685, "actor_loss": -22.47029991197586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.40367031097412, "step": 16000}
{"episode_reward": 1.724522422207594, "episode": 17.0, "batch_reward": 0.029960884439293296, "critic_loss": 0.04458792189671658, "actor_loss": -21.121056269407273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.581854581832886, "step": 17000}
{"episode_reward": 1.832800474795393, "episode": 18.0, "batch_reward": 0.028542412678711115, "critic_loss": 0.037247102332417854, "actor_loss": -21.069671476125716, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.37055206298828, "step": 18000}
{"episode_reward": 1.7651027763017486, "episode": 19.0, "batch_reward": 0.027062020582612603, "critic_loss": 0.03287127959844656, "actor_loss": -20.379830672502518, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.851359844207764, "step": 19000}
{"episode_reward": 4.91231347143075, "episode": 20.0, "batch_reward": 0.02549421342823189, "critic_loss": 0.051830256239394655, "actor_loss": -22.093541464328766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.8370201587677, "step": 20000}
{"episode_reward": 1.9211072375070464, "episode": 21.0, "batch_reward": 0.02496520781214349, "critic_loss": 0.039371515095233914, "actor_loss": -22.093650866508483, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.494378089904785, "step": 21000}
{"episode_reward": 1.2101014715392249, "episode": 22.0, "batch_reward": 0.023542654348304496, "critic_loss": 0.0478910592768807, "actor_loss": -21.01963546061516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.10077738761902, "step": 22000}
{"episode_reward": 2.0553164407960254, "episode": 23.0, "batch_reward": 0.023062397194793447, "critic_loss": 0.03246261841920205, "actor_loss": -20.58410370516777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.484896421432495, "step": 23000}
{"episode_reward": 3.0276586352391543, "episode": 24.0, "batch_reward": 0.021801698953029698, "critic_loss": 0.04912245247582905, "actor_loss": -21.50037765097618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.963581323623657, "step": 24000}
{"episode_reward": 4.438906539991005, "episode": 25.0, "batch_reward": 0.021004318604478614, "critic_loss": 0.05178712315147277, "actor_loss": -20.622099701404572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.92109990119934, "step": 25000}
{"episode_reward": 2.276775844629313, "episode": 26.0, "batch_reward": 0.020334758151089774, "critic_loss": 0.03961528651247499, "actor_loss": -20.404014912843703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.57582449913025, "step": 26000}
{"episode_reward": 1.2175776660516617, "episode": 27.0, "batch_reward": 0.01979457687807735, "critic_loss": 0.031661515183281155, "actor_loss": -21.17731298291683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.679864406585693, "step": 27000}
{"episode_reward": 1.4883071191432875, "episode": 28.0, "batch_reward": 0.018999019809183663, "critic_loss": 0.03811938509216998, "actor_loss": -20.204906170606613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.734654188156128, "step": 28000}
{"episode_reward": 0.8234244354789584, "episode": 29.0, "batch_reward": 0.01900973107968457, "critic_loss": 0.03390035579085816, "actor_loss": -21.062912425756455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.595449209213257, "step": 29000}
{"episode_reward": 1.0210738433323436, "episode": 30.0, "batch_reward": 0.017648753776797095, "critic_loss": 0.04268722074135439, "actor_loss": -20.38428464281559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.448729276657104, "step": 30000}
{"episode_reward": 1.1710362479272214, "episode": 31.0, "batch_reward": 0.017218714291113428, "critic_loss": 0.049273709218017755, "actor_loss": -20.745930710196497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.712493658065796, "step": 31000}
{"episode_reward": 1.4392972295619055, "episode": 32.0, "batch_reward": 0.016441426311037503, "critic_loss": 0.03891350607515778, "actor_loss": -21.104035672068594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.12589693069458, "step": 32000}
{"episode_reward": 1.1362490228539368, "episode": 33.0, "batch_reward": 0.016249835424125194, "critic_loss": 0.03467180171830114, "actor_loss": -21.273896812081336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60689949989319, "step": 33000}
{"episode_reward": 2.62044520524484, "episode": 34.0, "batch_reward": 0.015785337882698515, "critic_loss": 0.03063916205186979, "actor_loss": -19.401333053827287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.24120020866394, "step": 34000}
{"episode_reward": 1.887895760277988, "episode": 35.0, "batch_reward": 0.015263886658649426, "critic_loss": 0.03232268236170057, "actor_loss": -21.116699880480766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.76956009864807, "step": 35000}
{"episode_reward": 2.2292358034984474, "episode": 36.0, "batch_reward": 0.01494098092848435, "critic_loss": 0.024007070450345055, "actor_loss": -19.22412056815624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.71017074584961, "step": 36000}
{"episode_reward": 2.8349182188353472, "episode": 37.0, "batch_reward": 0.014852497388492338, "critic_loss": 0.032990612795896594, "actor_loss": -19.815485369324684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.428117036819458, "step": 37000}
{"episode_reward": 4.372421941403675, "episode": 38.0, "batch_reward": 0.014523132356524002, "critic_loss": 0.025827447270261473, "actor_loss": -20.04212453830242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.930115938186646, "step": 38000}
{"episode_reward": 2.2767957853397327, "episode": 39.0, "batch_reward": 0.013945618308323901, "critic_loss": 0.024396906802023294, "actor_loss": -21.05051783454418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.55660581588745, "step": 39000}
{"episode_reward": 1.679572161495818, "episode": 40.0, "batch_reward": 0.01381987182085868, "critic_loss": 0.026191779915214285, "actor_loss": -20.75101575875282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20406222343445, "step": 40000}
{"episode_reward": 2.112044896868765, "episode": 41.0, "batch_reward": 0.013583969118772075, "critic_loss": 0.023251348714285996, "actor_loss": -20.773256590783596, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.94824290275574, "step": 41000}
{"episode_reward": 2.4989048488684324, "episode": 42.0, "batch_reward": 0.012921792773471679, "critic_loss": 0.02210220336524071, "actor_loss": -20.100917270541192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004214763641357, "step": 42000}
{"episode_reward": 1.1934969093940797, "episode": 43.0, "batch_reward": 0.01301729741221061, "critic_loss": 0.023850097162328894, "actor_loss": -20.221688303530215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.56361961364746, "step": 43000}
{"episode_reward": 1.9353294074692329, "episode": 44.0, "batch_reward": 0.012653758150176145, "critic_loss": 0.015593897291866598, "actor_loss": -19.351289840459824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.60124373435974, "step": 44000}
{"episode_reward": 2.2046201525625935, "episode": 45.0, "batch_reward": 0.012619581239123363, "critic_loss": 0.01592278975302179, "actor_loss": -20.9003917273283, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.47449517250061, "step": 45000}
{"episode_reward": 2.078042626074316, "episode": 46.0, "batch_reward": 0.012170248456997797, "critic_loss": 0.017988416565553052, "actor_loss": -19.9828257779479, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.95008373260498, "step": 46000}
{"episode_reward": 2.313544965039525, "episode": 47.0, "batch_reward": 0.012411885096575134, "critic_loss": 0.014460066492145415, "actor_loss": -19.903911952614784, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.568313598632812, "step": 47000}
{"episode_reward": 2.283433208804354, "episode": 48.0, "batch_reward": 0.01176914733927697, "critic_loss": 0.011906297581590479, "actor_loss": -19.170303247988222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.585176467895508, "step": 48000}
{"episode_reward": 2.004045294967132, "episode": 49.0, "batch_reward": 0.011747955406201072, "critic_loss": 0.02139476223193924, "actor_loss": -20.45222768086195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.509052753448486, "step": 49000}
{"episode_reward": 1.8266162479917, "episode": 50.0, "batch_reward": 0.011171404263703152, "critic_loss": 0.022952818425459553, "actor_loss": -19.957157164275646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.742297887802124, "step": 50000}
{"episode_reward": 1.3687810322504386, "episode": 51.0, "batch_reward": 0.01111253419140121, "critic_loss": 0.014309796580913825, "actor_loss": -19.33597920513153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.82456421852112, "step": 51000}
{"episode_reward": 1.009076527493841, "episode": 52.0, "batch_reward": 0.011068694124463945, "critic_loss": 0.020078820979601005, "actor_loss": -20.915548312962056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.457699060440063, "step": 52000}
{"episode_reward": 1.4138824089818427, "episode": 53.0, "batch_reward": 0.011033265951962676, "critic_loss": 0.015879957489538354, "actor_loss": -20.03489417976141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.21309733390808, "step": 53000}
{"episode_reward": 1.0455427609714094, "episode": 54.0, "batch_reward": 0.010359069185389671, "critic_loss": 0.01787001438366133, "actor_loss": -20.579187384068966, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.926957368850708, "step": 54000}
{"episode_reward": 1.4545731110568794, "episode": 55.0, "batch_reward": 0.01056820093258284, "critic_loss": 0.02776872897526482, "actor_loss": -19.8497805801034, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.793009757995605, "step": 55000}
{"episode_reward": 1.2735148115123907, "episode": 56.0, "batch_reward": 0.01033062859455822, "critic_loss": 0.025648742887264233, "actor_loss": -21.05979715487361, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.86711096763611, "step": 56000}
{"episode_reward": 1.3074336131382236, "episode": 57.0, "batch_reward": 0.00996562906500185, "critic_loss": 0.028500040018494474, "actor_loss": -20.2063901732564, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.586456775665283, "step": 57000}
{"episode_reward": 2.2621220212728232, "episode": 58.0, "batch_reward": 0.010103925680567045, "critic_loss": 0.017958496638297218, "actor_loss": -19.478493493825198, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.206527709960938, "step": 58000}
{"episode_reward": 1.4149065362737403, "episode": 59.0, "batch_reward": 0.009580396960722283, "critic_loss": 0.02469542465420818, "actor_loss": -19.447818557202815, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.988924741744995, "step": 59000}
{"episode_reward": 4.029970002904693, "episode": 60.0, "batch_reward": 0.009907395425310824, "critic_loss": 0.016685396552631574, "actor_loss": -20.582561477094888, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.78103804588318, "step": 60000}
{"episode_reward": 2.053275225271085, "episode": 61.0, "batch_reward": 0.009722838323796168, "critic_loss": 0.020315967677237496, "actor_loss": -20.122503648430108, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.6508629322052, "step": 61000}
{"episode_reward": 2.2764984139806694, "episode": 62.0, "batch_reward": 0.009693138017260934, "critic_loss": 0.016752660742142326, "actor_loss": -19.702132670015096, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.35308337211609, "step": 62000}
{"episode_reward": 1.2656378324064463, "episode": 63.0, "batch_reward": 0.009410267656028736, "critic_loss": 0.0290890005360925, "actor_loss": -19.48640318250656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.32916760444641, "step": 63000}
{"episode_reward": 1.6134484645220637, "episode": 64.0, "batch_reward": 0.00898686807701597, "critic_loss": 0.015788237589771596, "actor_loss": -19.821577915400265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.15594172477722, "step": 64000}
{"episode_reward": 1.614771331602222, "episode": 65.0, "batch_reward": 0.009006688493886032, "critic_loss": 0.026746791980825947, "actor_loss": -19.5702916367054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.162959337234497, "step": 65000}
{"episode_reward": 2.769798798918887, "episode": 66.0, "batch_reward": 0.009216908466885798, "critic_loss": 0.01796206039833487, "actor_loss": -20.167642677545548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19926428794861, "step": 66000}
{"episode_reward": 3.0866186076729565, "episode": 67.0, "batch_reward": 0.009013643383572344, "critic_loss": 0.020729390195800078, "actor_loss": -21.18090168106556, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.825223922729492, "step": 67000}
{"episode_reward": 1.8871126268336003, "episode": 68.0, "batch_reward": 0.008828288707649335, "critic_loss": 0.020176843984634617, "actor_loss": -19.337679086029528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.08630108833313, "step": 68000}
{"episode_reward": 0.9373706391704787, "episode": 69.0, "batch_reward": 0.008604247579234652, "critic_loss": 0.020197414237125486, "actor_loss": -20.055462185263632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19944143295288, "step": 69000}
{"episode_reward": 1.9407182315251057, "episode": 70.0, "batch_reward": 0.008833653745008633, "critic_loss": 0.01327256337912695, "actor_loss": -20.505567158579826, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.059181690216064, "step": 70000}
{"episode_reward": 2.1268811554913976, "episode": 71.0, "batch_reward": 0.008792352630349342, "critic_loss": 0.008621267206071934, "actor_loss": -19.33338049170375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.24566888809204, "step": 71000}
{"episode_reward": 2.0789812732625728, "episode": 72.0, "batch_reward": 0.008523748177860398, "critic_loss": 0.014299704166711308, "actor_loss": -19.5652774656713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.925384998321533, "step": 72000}
{"episode_reward": 1.5776719989308203, "episode": 73.0, "batch_reward": 0.008427629333746155, "critic_loss": 0.008157808205960465, "actor_loss": -19.348836772888898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.743337631225586, "step": 73000}
{"episode_reward": 1.1163771753891554, "episode": 74.0, "batch_reward": 0.00818187799968291, "critic_loss": 0.007642371159152389, "actor_loss": -20.38908117772639, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.44747304916382, "step": 74000}
{"episode_reward": 1.2810943120584097, "episode": 75.0, "batch_reward": 0.008099071172240655, "critic_loss": 0.006788376986878575, "actor_loss": -20.509099580168723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.836277723312378, "step": 75000}
{"episode_reward": 2.285344066923713, "episode": 76.0, "batch_reward": 0.008188115340773948, "critic_loss": 0.009821000092721079, "actor_loss": -20.125918551787734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.769511938095093, "step": 76000}
{"episode_reward": 3.013502302526872, "episode": 77.0, "batch_reward": 0.00796121248730924, "critic_loss": 0.010650101095077844, "actor_loss": -19.91698454929888, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.512077808380127, "step": 77000}
{"episode_reward": 1.1406104948758151, "episode": 78.0, "batch_reward": 0.008248025725886692, "critic_loss": 0.007844708256601734, "actor_loss": -20.37421072565019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.4000563621521, "step": 78000}
{"episode_reward": 1.0924440935934232, "episode": 79.0, "batch_reward": 0.00771128625352867, "critic_loss": 0.008353870244172867, "actor_loss": -18.079128105357288, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.18441367149353, "step": 79000}
{"episode_reward": 1.5128444174385947, "episode": 80.0, "batch_reward": 0.007708588467270601, "critic_loss": 0.007962575546898734, "actor_loss": -19.372462738469242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.375237703323364, "step": 80000}
{"episode_reward": 1.2071937171278773, "episode": 81.0, "batch_reward": 0.007541999017004855, "critic_loss": 0.008765735670192953, "actor_loss": -19.423558267489074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.04668211936951, "step": 81000}
{"episode_reward": 2.3231945317219798, "episode": 82.0, "batch_reward": 0.007717932569852565, "critic_loss": 0.010649414930063357, "actor_loss": -21.150542527511718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.415745735168457, "step": 82000}
{"episode_reward": 2.6919322160789805, "episode": 83.0, "batch_reward": 0.007435507258400321, "critic_loss": 0.007192848757862521, "actor_loss": -19.251068380266428, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.569678783416748, "step": 83000}
{"episode_reward": 3.075514675517802, "episode": 84.0, "batch_reward": 0.0072430202204850505, "critic_loss": 0.007082852374001959, "actor_loss": -20.67714419488609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.076476573944092, "step": 84000}
{"episode_reward": 2.0261115129897966, "episode": 85.0, "batch_reward": 0.007566455156251322, "critic_loss": 0.009236377409619308, "actor_loss": -20.428912082657217, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.259669542312622, "step": 85000}
{"episode_reward": 1.9778079860293964, "episode": 86.0, "batch_reward": 0.007386373209126759, "critic_loss": 0.00877753097137429, "actor_loss": -19.048651511013507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.224344968795776, "step": 86000}
{"episode_reward": 2.0719887527342196, "episode": 87.0, "batch_reward": 0.007344802492356394, "critic_loss": 0.007524247729394119, "actor_loss": -20.104578581482173, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97589874267578, "step": 87000}
{"episode_reward": 2.331800750529985, "episode": 88.0, "batch_reward": 0.007403873755654786, "critic_loss": 0.011471033017260197, "actor_loss": -19.451893629968165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.266862392425537, "step": 88000}
{"episode_reward": 3.1529428323932187, "episode": 89.0, "batch_reward": 0.007397627009777352, "critic_loss": 0.007923052064430522, "actor_loss": -19.7859932525754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.39573574066162, "step": 89000}
{"episode_reward": 2.4715451568418647, "episode": 90.0, "batch_reward": 0.007132375469896942, "critic_loss": 0.010968844488692411, "actor_loss": -20.429535885453223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.112401485443115, "step": 90000}
{"episode_reward": 0.8867522868184746, "episode": 91.0, "batch_reward": 0.007329225955880247, "critic_loss": 0.010252623917425808, "actor_loss": -19.244959190532565, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.40153789520264, "step": 91000}
{"episode_reward": 1.7963297253790658, "episode": 92.0, "batch_reward": 0.007222988568944856, "critic_loss": 0.01024415946812951, "actor_loss": -19.70365554677695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.147781133651733, "step": 92000}
{"episode_reward": 1.79389992380563, "episode": 93.0, "batch_reward": 0.006981456209265161, "critic_loss": 0.0089775507811064, "actor_loss": -19.6231204245165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.620315313339233, "step": 93000}
{"episode_reward": 1.6508744366093344, "episode": 94.0, "batch_reward": 0.0068817516186391, "critic_loss": 0.010444893623658573, "actor_loss": -19.688039615973832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88079309463501, "step": 94000}
{"episode_reward": 2.056168998717583, "episode": 95.0, "batch_reward": 0.006951125594438053, "critic_loss": 0.0083266906857898, "actor_loss": -20.61207821305096, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.99468755722046, "step": 95000}
{"episode_reward": 1.8290068443945828, "episode": 96.0, "batch_reward": 0.006858126775710844, "critic_loss": 0.009190215285358136, "actor_loss": -20.197929434128106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.509900331497192, "step": 96000}
{"episode_reward": 1.6861522885866678, "episode": 97.0, "batch_reward": 0.006839448395418004, "critic_loss": 0.006623908818837663, "actor_loss": -20.67553803229332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.810606479644775, "step": 97000}
{"episode_reward": 2.446823478451285, "episode": 98.0, "batch_reward": 0.006798989886534401, "critic_loss": 0.008812057715578704, "actor_loss": -19.684756684690715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.314274311065674, "step": 98000}
{"episode_reward": 1.698500527765523, "episode": 99.0, "batch_reward": 0.006541850195266307, "critic_loss": 0.006923936861719994, "actor_loss": -19.934898952968418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.596467971801758, "step": 99000}
{"episode_reward": 1.5054609544531337, "episode": 100.0, "batch_reward": 0.0066993739628815096, "critic_loss": 0.010192405588408292, "actor_loss": -19.349834115713836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03458595275879, "step": 100000}
{"episode_reward": 2.481917261204928, "episode": 101.0, "batch_reward": 0.006490126710035838, "critic_loss": 0.008572523344924775, "actor_loss": -20.124900181509556, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.183817863464355, "step": 101000}
{"episode_reward": 1.5508401947105854, "episode": 102.0, "batch_reward": 0.0066036367548513225, "critic_loss": 0.008012347941912594, "actor_loss": -19.729208820059895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.937679767608643, "step": 102000}
{"episode_reward": 2.0510210636708406, "episode": 103.0, "batch_reward": 0.006677945831674151, "critic_loss": 0.007715501514112475, "actor_loss": -19.479194011457263, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.6453595161438, "step": 103000}
{"episode_reward": 2.754655910957976, "episode": 104.0, "batch_reward": 0.006538891055097338, "critic_loss": 0.008146670877718861, "actor_loss": -19.73266150341928, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.314417362213135, "step": 104000}
{"episode_reward": 0.8677266206415379, "episode": 105.0, "batch_reward": 0.006556167519534938, "critic_loss": 0.009950303434223314, "actor_loss": -19.536640430934728, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.071069717407227, "step": 105000}
{"episode_reward": 1.7090879174130496, "episode": 106.0, "batch_reward": 0.006444462247658521, "critic_loss": 0.010009125189266343, "actor_loss": -19.153015502363445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.096614837646484, "step": 106000}
{"episode_reward": 2.637207236008689, "episode": 107.0, "batch_reward": 0.006469880907097832, "critic_loss": 0.012659896858935099, "actor_loss": -18.960596397250892, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.24228525161743, "step": 107000}
{"episode_reward": 2.271284246187427, "episode": 108.0, "batch_reward": 0.006275124373845756, "critic_loss": 0.016275992976450653, "actor_loss": -19.270858069248497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.291606903076172, "step": 108000}
{"episode_reward": 6.254687274117674, "episode": 109.0, "batch_reward": 0.006213896551518701, "critic_loss": 0.01330404190644549, "actor_loss": -20.24819590676576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.59164261817932, "step": 109000}
{"episode_reward": 2.9946155529389284, "episode": 110.0, "batch_reward": 0.006167681336053647, "critic_loss": 0.010761888272678334, "actor_loss": -19.593501740537583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.320039987564087, "step": 110000}
{"episode_reward": 4.632312026173197, "episode": 111.0, "batch_reward": 0.006215890961466357, "critic_loss": 0.0097719998682187, "actor_loss": -20.19399152312428, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.73027014732361, "step": 111000}
{"episode_reward": 1.9269803753625139, "episode": 112.0, "batch_reward": 0.006319054628023878, "critic_loss": 0.01325850139852264, "actor_loss": -19.385845365673305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.313063383102417, "step": 112000}
{"episode_reward": 2.9141305671748254, "episode": 113.0, "batch_reward": 0.00604242454803898, "critic_loss": 0.012042492459120695, "actor_loss": -18.92097601567209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.293131351470947, "step": 113000}
{"episode_reward": 2.8049816303954787, "episode": 114.0, "batch_reward": 0.006077159210515674, "critic_loss": 0.011286401213881619, "actor_loss": -20.877288221769035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.46335220336914, "step": 114000}
{"episode_reward": 2.94609416299809, "episode": 115.0, "batch_reward": 0.006151576669130009, "critic_loss": 0.014637550998415464, "actor_loss": -19.8897023961246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.72249174118042, "step": 115000}
{"episode_reward": 3.146920142535925, "episode": 116.0, "batch_reward": 0.006121710926061496, "critic_loss": 0.01791916161801055, "actor_loss": -20.61347819944471, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.463637590408325, "step": 116000}
{"episode_reward": 1.9656193471826486, "episode": 117.0, "batch_reward": 0.006281843416800257, "critic_loss": 0.017230764157189698, "actor_loss": -18.805654687874018, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.13379716873169, "step": 117000}
{"episode_reward": 1.2049278094220424, "episode": 118.0, "batch_reward": 0.006184190806758125, "critic_loss": 0.015267350574278681, "actor_loss": -20.15886779961735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.940638542175293, "step": 118000}
{"episode_reward": 1.1010809106190802, "episode": 119.0, "batch_reward": 0.006013516880804673, "critic_loss": 0.013190286986515275, "actor_loss": -20.34497386972606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.680824041366577, "step": 119000}
{"episode_reward": 1.3394560657415409, "episode": 120.0, "batch_reward": 0.005841726314916741, "critic_loss": 0.010217222746818152, "actor_loss": -19.488464586056768, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.492010354995728, "step": 120000}
{"episode_reward": 0.9959996618766572, "episode": 121.0, "batch_reward": 0.005941662232857197, "critic_loss": 0.011356162147247233, "actor_loss": -19.54566425200552, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.40959715843201, "step": 121000}
{"episode_reward": 1.628580482911747, "episode": 122.0, "batch_reward": 0.00595074574672617, "critic_loss": 0.008276548294030362, "actor_loss": -19.67634192571044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.85713768005371, "step": 122000}
{"episode_reward": 1.39578084721283, "episode": 123.0, "batch_reward": 0.005892856769729405, "critic_loss": 0.00913323394602412, "actor_loss": -17.986753831602634, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.064298391342163, "step": 123000}
{"episode_reward": 1.4311238802873982, "episode": 124.0, "batch_reward": 0.0058147924540680835, "critic_loss": 0.006116306980209629, "actor_loss": -19.491923822760583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.41570496559143, "step": 124000}
{"episode_reward": 1.2779974005837356, "episode": 125.0, "batch_reward": 0.005647169670904987, "critic_loss": 0.012517370338340697, "actor_loss": -19.100681774504483, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06829285621643, "step": 125000}
{"episode_reward": 1.087091559900618, "episode": 126.0, "batch_reward": 0.00560075886483537, "critic_loss": 0.012431195192231825, "actor_loss": -19.872934792801736, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.977431058883667, "step": 126000}
{"episode_reward": 1.0583827609766288, "episode": 127.0, "batch_reward": 0.005741940426698421, "critic_loss": 0.007707359349151375, "actor_loss": -19.407524925202132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.14808464050293, "step": 127000}
{"episode_reward": 1.125092845612949, "episode": 128.0, "batch_reward": 0.005615432668244466, "critic_loss": 0.0066770485757187996, "actor_loss": -19.466682751320302, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.514352083206177, "step": 128000}
{"episode_reward": 1.2134935675310978, "episode": 129.0, "batch_reward": 0.005614198681665584, "critic_loss": 0.007392000861775159, "actor_loss": -20.11460194619, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.888413906097412, "step": 129000}
{"episode_reward": 1.8527678885744936, "episode": 130.0, "batch_reward": 0.00559609632199863, "critic_loss": 0.006303656893203879, "actor_loss": -20.120879038892685, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.500215768814087, "step": 130000}
{"episode_reward": 1.0362906214457697, "episode": 131.0, "batch_reward": 0.005534171452978626, "critic_loss": 0.008977840728584851, "actor_loss": -20.38872023343295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.187766790390015, "step": 131000}
{"episode_reward": 1.4717833811127405, "episode": 132.0, "batch_reward": 0.005600740834488534, "critic_loss": 0.00696383089775918, "actor_loss": -20.1846152080819, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.961417198181152, "step": 132000}
{"episode_reward": 1.545802067763971, "episode": 133.0, "batch_reward": 0.005532420730451122, "critic_loss": 0.006070485164669662, "actor_loss": -19.531577599331737, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.65343928337097, "step": 133000}
{"episode_reward": 1.6210851630616792, "episode": 134.0, "batch_reward": 0.005692989534931257, "critic_loss": 0.00686594923391749, "actor_loss": -20.18181001713127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.824050664901733, "step": 134000}
{"episode_reward": 1.3762681103913348, "episode": 135.0, "batch_reward": 0.00545372244779719, "critic_loss": 0.004708389006416837, "actor_loss": -20.235608245000243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.05707287788391, "step": 135000}
{"episode_reward": 1.3315504097875734, "episode": 136.0, "batch_reward": 0.0052688556714565495, "critic_loss": 0.005380291198183841, "actor_loss": -20.756861483104526, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.89053463935852, "step": 136000}
{"episode_reward": 1.0053639165941615, "episode": 137.0, "batch_reward": 0.005436855519015808, "critic_loss": 0.00518781415781632, "actor_loss": -19.91603696282953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.66048765182495, "step": 137000}
{"episode_reward": 1.1681019796436063, "episode": 138.0, "batch_reward": 0.005518786768836435, "critic_loss": 0.0077234237577686144, "actor_loss": -18.686753147229552, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.179764986038208, "step": 138000}
{"episode_reward": 1.4487983433415548, "episode": 139.0, "batch_reward": 0.005439404707518406, "critic_loss": 0.0039032126993261045, "actor_loss": -18.943615739196538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.49239945411682, "step": 139000}
{"episode_reward": 1.3079925252903015, "episode": 140.0, "batch_reward": 0.005268806946056429, "critic_loss": 0.004566891650618345, "actor_loss": -18.743486168809234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.008824110031128, "step": 140000}
{"episode_reward": 1.0924880062406919, "episode": 141.0, "batch_reward": 0.005268397442763671, "critic_loss": 0.004855537881710916, "actor_loss": -18.281588333107532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.13736057281494, "step": 141000}
{"episode_reward": 1.1905581788343016, "episode": 142.0, "batch_reward": 0.005288320159947034, "critic_loss": 0.004540718367672525, "actor_loss": -19.26092203513533, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.162055253982544, "step": 142000}
{"episode_reward": 1.2398169188901935, "episode": 143.0, "batch_reward": 0.0052195427560363895, "critic_loss": 0.005375991802229692, "actor_loss": -18.931843589529397, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.24320936203003, "step": 143000}
{"episode_reward": 0.7160001744915708, "episode": 144.0, "batch_reward": 0.0053960727447993125, "critic_loss": 0.008375915600623557, "actor_loss": -19.720377195090055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.958338022232056, "step": 144000}
{"episode_reward": 1.2081820421415137, "episode": 145.0, "batch_reward": 0.005119489290111232, "critic_loss": 0.005164521599239379, "actor_loss": -18.736211028628052, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981587171554565, "step": 145000}
{"episode_reward": 1.1887480126898788, "episode": 146.0, "batch_reward": 0.005126270231441595, "critic_loss": 0.00791237473595902, "actor_loss": -19.070881933700292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.204848766326904, "step": 146000}
{"episode_reward": 1.2595768543447388, "episode": 147.0, "batch_reward": 0.005030231613724027, "critic_loss": 0.004831947700175078, "actor_loss": -19.765401602223516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.79346489906311, "step": 147000}
{"episode_reward": 1.511407803055846, "episode": 148.0, "batch_reward": 0.005349749736313242, "critic_loss": 0.006933932408264809, "actor_loss": -18.811335841756314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.148247480392456, "step": 148000}
{"episode_reward": 1.0270728455018654, "episode": 149.0, "batch_reward": 0.005053276416496374, "critic_loss": 0.0063522211197596335, "actor_loss": -18.7963739445433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.10941743850708, "step": 149000}
{"episode_reward": 1.5860875647337631, "episode": 150.0, "batch_reward": 0.004978247046237811, "critic_loss": 0.004984587082619328, "actor_loss": -19.38914316869527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
