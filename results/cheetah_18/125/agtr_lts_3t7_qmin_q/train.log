{"episode_reward": 0.0, "episode": 1.0, "duration": 13.238664388656616, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.0946581363677979, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.21945231539054727, "critic_loss": 0.23203957097237807, "actor_loss": -44.26287700291298, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 70.53340744972229, "step": 3000}
{"episode_reward": 73.86519554433052, "episode": 4.0, "batch_reward": 0.17502018110454082, "critic_loss": 0.2675023074746132, "actor_loss": -39.605506240844726, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.392000913619995, "step": 4000}
{"episode_reward": 184.57600860943646, "episode": 5.0, "batch_reward": 0.1811178089529276, "critic_loss": 0.25463231103122236, "actor_loss": -39.65710459899903, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.588496446609497, "step": 5000}
{"episode_reward": 196.68539730882185, "episode": 6.0, "batch_reward": 0.1750347563996911, "critic_loss": 0.2394968573153019, "actor_loss": -37.46789447402954, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.48682951927185, "step": 6000}
{"episode_reward": 62.22855907156045, "episode": 7.0, "batch_reward": 0.15992554588615895, "critic_loss": 0.22677063328772784, "actor_loss": -34.25544445037842, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.677303314208984, "step": 7000}
{"episode_reward": 95.16728669314865, "episode": 8.0, "batch_reward": 0.15262416231632234, "critic_loss": 0.2097745389044285, "actor_loss": -32.309256896972656, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.261481046676636, "step": 8000}
{"episode_reward": 91.67313329151412, "episode": 9.0, "batch_reward": 0.14797970609366895, "critic_loss": 0.21694972426444292, "actor_loss": -30.324117233276368, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.352030515670776, "step": 9000}
{"episode_reward": 203.68820810755358, "episode": 10.0, "batch_reward": 0.1534352051243186, "critic_loss": 0.23777587366104125, "actor_loss": -30.51133402633667, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.52819514274597, "step": 10000}
{"episode_reward": 99.90194461310577, "episode": 11.0, "batch_reward": 0.15564947707206012, "critic_loss": 0.26417741053551436, "actor_loss": -29.961437385559083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.795565605163574, "step": 11000}
{"episode_reward": 308.2116874679863, "episode": 12.0, "batch_reward": 0.15934134834259747, "critic_loss": 0.25647620102763174, "actor_loss": -29.456796669006348, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.67982244491577, "step": 12000}
{"episode_reward": 63.60379641464632, "episode": 13.0, "batch_reward": 0.15178485317528248, "critic_loss": 0.22057638262212276, "actor_loss": -28.11269184875488, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.663379907608032, "step": 13000}
{"episode_reward": 66.54373817322588, "episode": 14.0, "batch_reward": 0.1509156251549721, "critic_loss": 0.2365820838585496, "actor_loss": -28.077371379852295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.101062059402466, "step": 14000}
{"episode_reward": 292.69188881911157, "episode": 15.0, "batch_reward": 0.1629643363431096, "critic_loss": 0.26196816565096376, "actor_loss": -28.237896697998046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.598668575286865, "step": 15000}
{"episode_reward": 335.94627588378944, "episode": 16.0, "batch_reward": 0.17177237355709077, "critic_loss": 0.27986962028592827, "actor_loss": -28.450571617126464, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.561577558517456, "step": 16000}
{"episode_reward": 176.5712350016419, "episode": 17.0, "batch_reward": 0.17138598289340734, "critic_loss": 0.3330632286518812, "actor_loss": -28.62669857788086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.391168117523193, "step": 17000}
{"episode_reward": 166.03172521866364, "episode": 18.0, "batch_reward": 0.17377581018209456, "critic_loss": 0.40874732680618764, "actor_loss": -28.476478965759277, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.898391485214233, "step": 18000}
{"episode_reward": 224.02975588503145, "episode": 19.0, "batch_reward": 0.17476995907723902, "critic_loss": 0.41877020068466664, "actor_loss": -28.265794456481935, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.441492080688477, "step": 19000}
{"episode_reward": 180.70023526895702, "episode": 20.0, "batch_reward": 0.16826453278958797, "critic_loss": 0.37583942802250386, "actor_loss": -27.62582822418213, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.285438537597656, "step": 20000}
{"episode_reward": 9.879546047965784, "episode": 21.0, "batch_reward": 0.1606024942100048, "critic_loss": 0.3541086619645357, "actor_loss": -27.65305490875244, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.031917572021484, "step": 21000}
{"episode_reward": 9.54318068421878, "episode": 22.0, "batch_reward": 0.1536294632554054, "critic_loss": 0.33550402192771434, "actor_loss": -28.20744155883789, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.632422924041748, "step": 22000}
{"episode_reward": 6.641208621762666, "episode": 23.0, "batch_reward": 0.14757975742965937, "critic_loss": 0.31586304819583894, "actor_loss": -28.63224948120117, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.537123203277588, "step": 23000}
{"episode_reward": 8.497306087340109, "episode": 24.0, "batch_reward": 0.1409720635563135, "critic_loss": 0.30539732611179354, "actor_loss": -28.35744919204712, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.11512041091919, "step": 24000}
{"episode_reward": 8.332194232699491, "episode": 25.0, "batch_reward": 0.13522626551985742, "critic_loss": 0.32755697539448736, "actor_loss": -29.402566009521486, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.70193839073181, "step": 25000}
{"episode_reward": 8.368941599091595, "episode": 26.0, "batch_reward": 0.13080413158982993, "critic_loss": 0.30883338341116906, "actor_loss": -29.80099517059326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.491354942321777, "step": 26000}
{"episode_reward": 14.089840353974106, "episode": 27.0, "batch_reward": 0.1268999909684062, "critic_loss": 0.28265239973366263, "actor_loss": -29.773184356689452, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.62732219696045, "step": 27000}
{"episode_reward": 12.444738933472772, "episode": 28.0, "batch_reward": 0.12253689559549093, "critic_loss": 0.2586930905878544, "actor_loss": -29.704273418426514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.816174745559692, "step": 28000}
{"episode_reward": 13.301186873478574, "episode": 29.0, "batch_reward": 0.11882825331389904, "critic_loss": 0.26073059859126807, "actor_loss": -29.18913860321045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.65191626548767, "step": 29000}
{"episode_reward": 13.066500793236376, "episode": 30.0, "batch_reward": 0.11607077110558749, "critic_loss": 0.34561426086723807, "actor_loss": -29.82119314956665, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.612810373306274, "step": 30000}
{"episode_reward": 34.810300599204844, "episode": 31.0, "batch_reward": 0.11710351835936308, "critic_loss": 0.48867468890547755, "actor_loss": -31.111475914001463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.78473234176636, "step": 31000}
{"episode_reward": 203.1561038390492, "episode": 32.0, "batch_reward": 0.12078235069662333, "critic_loss": 0.5179851880222559, "actor_loss": -31.746009952545165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.41604781150818, "step": 32000}
{"episode_reward": 397.27362105796976, "episode": 33.0, "batch_reward": 0.12791366443783045, "critic_loss": 0.6429722278267145, "actor_loss": -32.39776650238037, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.634294033050537, "step": 33000}
{"episode_reward": 231.05868856832078, "episode": 34.0, "batch_reward": 0.1329162909835577, "critic_loss": 0.7662938362956047, "actor_loss": -33.31559482955932, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.642508029937744, "step": 34000}
{"episode_reward": 401.15820692686475, "episode": 35.0, "batch_reward": 0.13890096081793307, "critic_loss": 0.8261668097376823, "actor_loss": -34.047950744628906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.24515390396118, "step": 35000}
{"episode_reward": 365.65715622202157, "episode": 36.0, "batch_reward": 0.14266972672939301, "critic_loss": 0.9507006801962853, "actor_loss": -34.85815258407593, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.35267734527588, "step": 36000}
{"episode_reward": 97.24402250702495, "episode": 37.0, "batch_reward": 0.14626056306809188, "critic_loss": 1.1394429889321327, "actor_loss": -35.58905212020874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.001688480377197, "step": 37000}
{"episode_reward": 466.9056169473295, "episode": 38.0, "batch_reward": 0.15101787640154363, "critic_loss": 2.1221062640547754, "actor_loss": -37.136627300262454, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.38003182411194, "step": 38000}
{"episode_reward": 138.39451398254943, "episode": 39.0, "batch_reward": 0.14970557396113873, "critic_loss": 2.805069583296776, "actor_loss": -39.04011011123657, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.59872269630432, "step": 39000}
{"episode_reward": 75.41570158152089, "episode": 40.0, "batch_reward": 0.14738297255337238, "critic_loss": 3.501687286555767, "actor_loss": -40.184851978302, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.608740091323853, "step": 40000}
{"episode_reward": 82.73074168965388, "episode": 41.0, "batch_reward": 0.14447901880741118, "critic_loss": 4.3199612001180645, "actor_loss": -41.388505504608155, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.00197696685791, "step": 41000}
{"episode_reward": 18.16383171602227, "episode": 42.0, "batch_reward": 0.14289997688680886, "critic_loss": 5.2416720764637, "actor_loss": -42.84958225631714, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.367082834243774, "step": 42000}
{"episode_reward": 12.090450100928367, "episode": 43.0, "batch_reward": 0.13991433815658091, "critic_loss": 5.512431400537491, "actor_loss": -45.2158563041687, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.819218635559082, "step": 43000}
{"episode_reward": 15.86517219615152, "episode": 44.0, "batch_reward": 0.13632061643898488, "critic_loss": 5.213819904088974, "actor_loss": -46.36786332702637, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.592761278152466, "step": 44000}
{"episode_reward": 23.49443964732346, "episode": 45.0, "batch_reward": 0.1351490154787898, "critic_loss": 5.119572414636612, "actor_loss": -49.81595489120483, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.535468339920044, "step": 45000}
{"episode_reward": 19.16378851403445, "episode": 46.0, "batch_reward": 0.13074585463106633, "critic_loss": 4.966734887599945, "actor_loss": -51.35497616577148, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.86047077178955, "step": 46000}
{"episode_reward": 26.34107810292639, "episode": 47.0, "batch_reward": 0.1293601701334119, "critic_loss": 4.640742042779922, "actor_loss": -54.137319648742675, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.505563497543335, "step": 47000}
{"episode_reward": 37.327836046299765, "episode": 48.0, "batch_reward": 0.12842499893903733, "critic_loss": 4.146226336479187, "actor_loss": -55.151949348449705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.210742473602295, "step": 48000}
{"episode_reward": 56.19966145086663, "episode": 49.0, "batch_reward": 0.12557638665288687, "critic_loss": 3.892479310274124, "actor_loss": -58.31039579391479, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.754756212234497, "step": 49000}
{"episode_reward": 45.38920188361446, "episode": 50.0, "batch_reward": 0.12532809962332248, "critic_loss": 3.931036379098892, "actor_loss": -59.137521907806395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.471730709075928, "step": 50000}
{"episode_reward": 50.53065786046799, "episode": 51.0, "batch_reward": 0.12314799676835538, "critic_loss": 3.913505008339882, "actor_loss": -60.0570853805542, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.01935291290283, "step": 51000}
{"episode_reward": 78.99733161434308, "episode": 52.0, "batch_reward": 0.12232467561215163, "critic_loss": 4.265099519014359, "actor_loss": -61.82805400085449, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.52604579925537, "step": 52000}
{"episode_reward": 67.11505300736539, "episode": 53.0, "batch_reward": 0.12267623407393694, "critic_loss": 4.595179389834404, "actor_loss": -62.8997289276123, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.754326820373535, "step": 53000}
{"episode_reward": 134.2895321917411, "episode": 54.0, "batch_reward": 0.12081258664280176, "critic_loss": 4.179938924312592, "actor_loss": -64.06264319610595, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.321485996246338, "step": 54000}
{"episode_reward": 48.816239560597396, "episode": 55.0, "batch_reward": 0.12112394197285176, "critic_loss": 3.3909228912591933, "actor_loss": -64.03294365692139, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.804591178894043, "step": 55000}
{"episode_reward": 197.0649911486127, "episode": 56.0, "batch_reward": 0.12086785959452391, "critic_loss": 2.8044212124347685, "actor_loss": -63.630356300354, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.531020879745483, "step": 56000}
{"episode_reward": 35.128295641253885, "episode": 57.0, "batch_reward": 0.1227002960368991, "critic_loss": 2.3722745139598844, "actor_loss": -62.61232388305664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.19130516052246, "step": 57000}
{"episode_reward": 349.3533717556793, "episode": 58.0, "batch_reward": 0.126333046361804, "critic_loss": 2.0831522985696793, "actor_loss": -61.6422318611145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.623432636260986, "step": 58000}
{"episode_reward": 354.4633906416861, "episode": 59.0, "batch_reward": 0.1308724595606327, "critic_loss": 1.733636962532997, "actor_loss": -60.75400971984863, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.716240406036377, "step": 59000}
{"episode_reward": 369.18747828037266, "episode": 60.0, "batch_reward": 0.13390611033141614, "critic_loss": 1.4170245527029037, "actor_loss": -60.82749492263794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.53775906562805, "step": 60000}
{"episode_reward": 283.58290537965195, "episode": 61.0, "batch_reward": 0.13683740112185477, "critic_loss": 1.159855367064476, "actor_loss": -59.31226831817627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.88718795776367, "step": 61000}
{"episode_reward": 398.2209385981529, "episode": 62.0, "batch_reward": 0.14119777393341065, "critic_loss": 1.0136093188524247, "actor_loss": -59.48645349884033, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.646607875823975, "step": 62000}
{"episode_reward": 231.18182667578088, "episode": 63.0, "batch_reward": 0.1415457225292921, "critic_loss": 0.8827116893529892, "actor_loss": -57.095548683166506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.69008445739746, "step": 63000}
{"episode_reward": 118.51306666037803, "episode": 64.0, "batch_reward": 0.14210547136515378, "critic_loss": 0.7930160390436649, "actor_loss": -56.16610037612915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.817073345184326, "step": 64000}
{"episode_reward": 457.9495026282979, "episode": 65.0, "batch_reward": 0.1470048613399267, "critic_loss": 0.7358732370436192, "actor_loss": -54.98717570495605, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.508386611938477, "step": 65000}
{"episode_reward": 496.8427800799217, "episode": 66.0, "batch_reward": 0.15387093848735095, "critic_loss": 0.6857206501662731, "actor_loss": -54.080520542144775, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.589301109313965, "step": 66000}
{"episode_reward": 484.0800095616282, "episode": 67.0, "batch_reward": 0.15800841804593801, "critic_loss": 0.6063546520471573, "actor_loss": -53.36978765869141, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.97678256034851, "step": 67000}
{"episode_reward": 421.27684313195005, "episode": 68.0, "batch_reward": 0.1629094461351633, "critic_loss": 0.5390091812312603, "actor_loss": -51.16725924301147, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.9021258354187, "step": 68000}
{"episode_reward": 494.4144320677477, "episode": 69.0, "batch_reward": 0.16662150056660174, "critic_loss": 0.49602894711494444, "actor_loss": -50.118634021759036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.208509922027588, "step": 69000}
{"episode_reward": 474.5000214864041, "episode": 70.0, "batch_reward": 0.17073265680670738, "critic_loss": 0.484941604077816, "actor_loss": -50.08352967453003, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.83920979499817, "step": 70000}
{"episode_reward": 329.9415625189539, "episode": 71.0, "batch_reward": 0.173447183907032, "critic_loss": 0.43140719750523565, "actor_loss": -48.74630464172363, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.902058601379395, "step": 71000}
{"episode_reward": 479.41093167071995, "episode": 72.0, "batch_reward": 0.1773622102737427, "critic_loss": 0.4467343793809414, "actor_loss": -47.70913613510132, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.98128604888916, "step": 72000}
{"episode_reward": 461.58124436825796, "episode": 73.0, "batch_reward": 0.18252776443213226, "critic_loss": 0.42348522336781025, "actor_loss": -47.55685489654541, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.51942276954651, "step": 73000}
{"episode_reward": 490.76790966613333, "episode": 74.0, "batch_reward": 0.18497561475634575, "critic_loss": 0.40368008211255074, "actor_loss": -47.24069409942627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.665253400802612, "step": 74000}
{"episode_reward": 493.4803844053987, "episode": 75.0, "batch_reward": 0.1905320716649294, "critic_loss": 0.3641563940048218, "actor_loss": -46.35812477111816, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.556709051132202, "step": 75000}
{"episode_reward": 507.4095370072439, "episode": 76.0, "batch_reward": 0.19387963856756688, "critic_loss": 0.3327581088244915, "actor_loss": -45.796392246246334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.148533582687378, "step": 76000}
{"episode_reward": 505.224460669771, "episode": 77.0, "batch_reward": 0.1981742376834154, "critic_loss": 0.30441201135516166, "actor_loss": -44.6890698928833, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.72642183303833, "step": 77000}
{"episode_reward": 522.9007370940691, "episode": 78.0, "batch_reward": 0.20379564782977105, "critic_loss": 0.3074431576281786, "actor_loss": -44.227583854675295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.745824098587036, "step": 78000}
{"episode_reward": 505.75002598856787, "episode": 79.0, "batch_reward": 0.20564132079482078, "critic_loss": 0.29649377494305373, "actor_loss": -43.04288501739502, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.638277292251587, "step": 79000}
{"episode_reward": 512.8811608633179, "episode": 80.0, "batch_reward": 0.21144714438915252, "critic_loss": 0.30880636167526243, "actor_loss": -42.7592650680542, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.357712984085083, "step": 80000}
{"episode_reward": 498.27463717576376, "episode": 81.0, "batch_reward": 0.21408876465260981, "critic_loss": 0.31573746383190154, "actor_loss": -42.27246546936035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.83359360694885, "step": 81000}
{"episode_reward": 461.07091546095063, "episode": 82.0, "batch_reward": 0.217462415471673, "critic_loss": 0.2903431330770254, "actor_loss": -42.150864822387696, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.315889358520508, "step": 82000}
{"episode_reward": 515.8999016654732, "episode": 83.0, "batch_reward": 0.22086602832376956, "critic_loss": 0.3020713658183813, "actor_loss": -41.412591720581055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.54063630104065, "step": 83000}
{"episode_reward": 496.767404293289, "episode": 84.0, "batch_reward": 0.22511934827268124, "critic_loss": 0.2896696616411209, "actor_loss": -41.20730431365967, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.028995513916016, "step": 84000}
{"episode_reward": 538.9029186647294, "episode": 85.0, "batch_reward": 0.22858844418823718, "critic_loss": 0.2797094222456217, "actor_loss": -40.84184421539307, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.404475927352905, "step": 85000}
{"episode_reward": 514.8142123512714, "episode": 86.0, "batch_reward": 0.2315131830126047, "critic_loss": 0.2937903973758221, "actor_loss": -40.424804695129396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.57602047920227, "step": 86000}
{"episode_reward": 507.1956437589601, "episode": 87.0, "batch_reward": 0.2343039170652628, "critic_loss": 0.27847976425290105, "actor_loss": -40.173835414886476, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.714714765548706, "step": 87000}
{"episode_reward": 523.8617012088538, "episode": 88.0, "batch_reward": 0.23771013543009759, "critic_loss": 0.2711851924359798, "actor_loss": -39.95481694793701, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.28858995437622, "step": 88000}
{"episode_reward": 515.4774720356714, "episode": 89.0, "batch_reward": 0.2414334777444601, "critic_loss": 0.26014575668424367, "actor_loss": -39.887704849243164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.521404504776, "step": 89000}
{"episode_reward": 519.3494947343903, "episode": 90.0, "batch_reward": 0.24429249487817287, "critic_loss": 0.25403533295542, "actor_loss": -39.70009085083008, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.788493156433105, "step": 90000}
{"episode_reward": 519.8779513053843, "episode": 91.0, "batch_reward": 0.247270481929183, "critic_loss": 0.2540498782992363, "actor_loss": -39.409579933166505, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.305829763412476, "step": 91000}
{"episode_reward": 516.0259431572105, "episode": 92.0, "batch_reward": 0.24991525346040724, "critic_loss": 0.2374886839464307, "actor_loss": -39.26000172424317, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.986995697021484, "step": 92000}
{"episode_reward": 509.102678115765, "episode": 93.0, "batch_reward": 0.25315114922821524, "critic_loss": 0.24016636153310536, "actor_loss": -39.07024587249756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.73620319366455, "step": 93000}
{"episode_reward": 511.5607972685652, "episode": 94.0, "batch_reward": 0.2551728523671627, "critic_loss": 0.2468381908684969, "actor_loss": -38.92583275604248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.72401261329651, "step": 94000}
{"episode_reward": 266.13568234954755, "episode": 95.0, "batch_reward": 0.2550647611320019, "critic_loss": 0.23337732189148663, "actor_loss": -38.57425312042236, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.8398277759552, "step": 95000}
{"episode_reward": 546.1383448254002, "episode": 96.0, "batch_reward": 0.25807169152796267, "critic_loss": 0.22542316476255655, "actor_loss": -38.51255567169189, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.053305864334106, "step": 96000}
{"episode_reward": 532.9731469450945, "episode": 97.0, "batch_reward": 0.2609520442187786, "critic_loss": 0.22967906773090363, "actor_loss": -38.42739247894287, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.728546857833862, "step": 97000}
{"episode_reward": 510.43157786931505, "episode": 98.0, "batch_reward": 0.26402208566665647, "critic_loss": 0.2429019471257925, "actor_loss": -38.43757286834717, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.33989691734314, "step": 98000}
{"episode_reward": 525.0981147945738, "episode": 99.0, "batch_reward": 0.26708842954039574, "critic_loss": 0.22694442862272263, "actor_loss": -38.36544618225098, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.51000142097473, "step": 99000}
{"episode_reward": 520.2643362751121, "episode": 100.0, "batch_reward": 0.26966649405658244, "critic_loss": 0.23159860046207906, "actor_loss": -38.27308450317383, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.661888122558594, "step": 100000}
{"episode_reward": 537.9339542068423, "episode": 101.0, "batch_reward": 0.27166872018575666, "critic_loss": 0.22339793979376554, "actor_loss": -38.133924293518064, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.31070899963379, "step": 101000}
{"episode_reward": 556.219765267446, "episode": 102.0, "batch_reward": 0.27365457056462766, "critic_loss": 0.23766946079581977, "actor_loss": -38.11651300048828, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.85169768333435, "step": 102000}
{"episode_reward": 558.8577810764916, "episode": 103.0, "batch_reward": 0.2763884210586548, "critic_loss": 0.22790088097006084, "actor_loss": -38.07764176177979, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.437379360198975, "step": 103000}
{"episode_reward": 550.1790921308299, "episode": 104.0, "batch_reward": 0.28070436860620973, "critic_loss": 0.21635681708902121, "actor_loss": -38.11906958770752, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.63668727874756, "step": 104000}
{"episode_reward": 532.5261529663493, "episode": 105.0, "batch_reward": 0.28248278149962425, "critic_loss": 0.2284284079745412, "actor_loss": -38.03355417633057, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.618202686309814, "step": 105000}
{"episode_reward": 518.4219856054428, "episode": 106.0, "batch_reward": 0.283862300157547, "critic_loss": 0.22218112621456385, "actor_loss": -38.15542506408691, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.729801416397095, "step": 106000}
{"episode_reward": 518.6724007774565, "episode": 107.0, "batch_reward": 0.2873448925614357, "critic_loss": 0.21460316118597983, "actor_loss": -38.05062074661255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.505176544189453, "step": 107000}
{"episode_reward": 547.0458894843968, "episode": 108.0, "batch_reward": 0.28926369278132913, "critic_loss": 0.21981250002235175, "actor_loss": -37.955738204956056, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.720591068267822, "step": 108000}
{"episode_reward": 566.574269887061, "episode": 109.0, "batch_reward": 0.2927263650894165, "critic_loss": 0.19894101838767528, "actor_loss": -38.06602479934693, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.513586282730103, "step": 109000}
{"episode_reward": 551.5514363103888, "episode": 110.0, "batch_reward": 0.294196201980114, "critic_loss": 0.20367299672216177, "actor_loss": -38.132933471679685, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.619694471359253, "step": 110000}
{"episode_reward": 524.1157690539978, "episode": 111.0, "batch_reward": 0.2959515445977449, "critic_loss": 0.20963371046632528, "actor_loss": -37.95372930908203, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.55967044830322, "step": 111000}
{"episode_reward": 535.0391971773103, "episode": 112.0, "batch_reward": 0.29802995201945304, "critic_loss": 0.21908813667297364, "actor_loss": -38.28862783050537, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.726179838180542, "step": 112000}
{"episode_reward": 535.6188452656854, "episode": 113.0, "batch_reward": 0.3002050158083439, "critic_loss": 0.21122852619737387, "actor_loss": -38.1525082321167, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.517435312271118, "step": 113000}
{"episode_reward": 553.2271934651546, "episode": 114.0, "batch_reward": 0.3024019352197647, "critic_loss": 0.2372502109184861, "actor_loss": -38.15331803894043, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.479341745376587, "step": 114000}
{"episode_reward": 540.5119303501333, "episode": 115.0, "batch_reward": 0.30536584571003916, "critic_loss": 0.21135508055984975, "actor_loss": -38.394904197692874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.311996459960938, "step": 115000}
{"episode_reward": 541.8753877922278, "episode": 116.0, "batch_reward": 0.3083813721984625, "critic_loss": 0.21992641102522612, "actor_loss": -38.542468688964846, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.41792345046997, "step": 116000}
{"episode_reward": 547.1142561950695, "episode": 117.0, "batch_reward": 0.3102725715041161, "critic_loss": 0.19812133695930242, "actor_loss": -38.609885917663576, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.884040355682373, "step": 117000}
{"episode_reward": 555.2537843166439, "episode": 118.0, "batch_reward": 0.3105055031776428, "critic_loss": 0.21812850680947304, "actor_loss": -38.45578229522705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.03760313987732, "step": 118000}
{"episode_reward": 529.2742647346302, "episode": 119.0, "batch_reward": 0.31334499141573907, "critic_loss": 0.1982044379040599, "actor_loss": -38.531386486053464, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.781171321868896, "step": 119000}
{"episode_reward": 542.8888229067674, "episode": 120.0, "batch_reward": 0.314001270249486, "critic_loss": 0.22938500336557627, "actor_loss": -38.76637692260742, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.69542098045349, "step": 120000}
{"episode_reward": 514.6546111386509, "episode": 121.0, "batch_reward": 0.3160182745754719, "critic_loss": 0.23156360652297736, "actor_loss": -38.688122497558595, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.036534547805786, "step": 121000}
{"episode_reward": 176.77858091049865, "episode": 122.0, "batch_reward": 0.3147955948412418, "critic_loss": 0.25516601028293373, "actor_loss": -38.711957168579104, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.45929527282715, "step": 122000}
{"episode_reward": 472.7447027526713, "episode": 123.0, "batch_reward": 0.318283881098032, "critic_loss": 0.22641306472569703, "actor_loss": -39.19913327026367, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.45231318473816, "step": 123000}
{"episode_reward": 546.3062787732335, "episode": 124.0, "batch_reward": 0.3188299901485443, "critic_loss": 0.2506481210291386, "actor_loss": -38.930833786010744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.057175636291504, "step": 124000}
{"episode_reward": 514.118628296209, "episode": 125.0, "batch_reward": 0.31959163621068, "critic_loss": 0.2455419984832406, "actor_loss": -38.76871827697754, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.6605806350708, "step": 125000}
{"episode_reward": 523.3711959190682, "episode": 126.0, "batch_reward": 0.3208550603687763, "critic_loss": 0.2328898427784443, "actor_loss": -38.89660140609741, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.82914710044861, "step": 126000}
{"episode_reward": 540.3027550191408, "episode": 127.0, "batch_reward": 0.3226518955528736, "critic_loss": 0.2478909833803773, "actor_loss": -39.00890075302124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.454267501831055, "step": 127000}
{"episode_reward": 523.8971721984641, "episode": 128.0, "batch_reward": 0.32519928832352163, "critic_loss": 0.2503503588438034, "actor_loss": -38.79381289291382, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.34577178955078, "step": 128000}
{"episode_reward": 549.9079338306387, "episode": 129.0, "batch_reward": 0.3268660995960236, "critic_loss": 0.25266736767441034, "actor_loss": -38.96552325439453, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.441686391830444, "step": 129000}
{"episode_reward": 528.8964111796801, "episode": 130.0, "batch_reward": 0.32853517451882364, "critic_loss": 0.24768684431910515, "actor_loss": -39.27119789123535, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.780092000961304, "step": 130000}
{"episode_reward": 538.5910490395318, "episode": 131.0, "batch_reward": 0.33055184450745584, "critic_loss": 0.25514908868819475, "actor_loss": -38.96103006744385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.98897075653076, "step": 131000}
{"episode_reward": 559.0443085741184, "episode": 132.0, "batch_reward": 0.332097485601902, "critic_loss": 0.2523694226592779, "actor_loss": -39.486222419738766, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.495967626571655, "step": 132000}
{"episode_reward": 535.374768880984, "episode": 133.0, "batch_reward": 0.33282816046476366, "critic_loss": 0.28118305595219134, "actor_loss": -39.4626814956665, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.625810384750366, "step": 133000}
{"episode_reward": 558.7904491293137, "episode": 134.0, "batch_reward": 0.33405775794386866, "critic_loss": 0.30552424128353595, "actor_loss": -39.62110056304932, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.490305185317993, "step": 134000}
{"episode_reward": 528.4272057630843, "episode": 135.0, "batch_reward": 0.3369934205710888, "critic_loss": 0.2914339288547635, "actor_loss": -39.852664909362794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.04397201538086, "step": 135000}
{"episode_reward": 570.2195411183832, "episode": 136.0, "batch_reward": 0.3380309486091137, "critic_loss": 0.2850426978468895, "actor_loss": -39.69879807281494, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.091524362564087, "step": 136000}
{"episode_reward": 567.6051478447544, "episode": 137.0, "batch_reward": 0.3391200398504734, "critic_loss": 0.29883640150725843, "actor_loss": -40.44557852935791, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.400933980941772, "step": 137000}
{"episode_reward": 533.7717305584531, "episode": 138.0, "batch_reward": 0.3414163136780262, "critic_loss": 0.3043635635897517, "actor_loss": -40.73656063842773, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.024478912353516, "step": 138000}
{"episode_reward": 540.1202598772435, "episode": 139.0, "batch_reward": 0.34241199201345446, "critic_loss": 0.285767760373652, "actor_loss": -40.83534218597412, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.750287771224976, "step": 139000}
{"episode_reward": 553.481285285288, "episode": 140.0, "batch_reward": 0.34348087787628173, "critic_loss": 0.3075221485123038, "actor_loss": -41.0707370223999, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.96788239479065, "step": 140000}
{"episode_reward": 523.3221746552036, "episode": 141.0, "batch_reward": 0.3450445224940777, "critic_loss": 0.3165365119278431, "actor_loss": -41.23941432189942, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.63145971298218, "step": 141000}
{"episode_reward": 546.4453277775546, "episode": 142.0, "batch_reward": 0.34710778313875196, "critic_loss": 0.27970102860778573, "actor_loss": -41.05607839202881, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.540460109710693, "step": 142000}
{"episode_reward": 554.5382360031083, "episode": 143.0, "batch_reward": 0.34886686250567434, "critic_loss": 0.28546751648187635, "actor_loss": -41.23257662963867, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.67909288406372, "step": 143000}
{"episode_reward": 552.6865035582541, "episode": 144.0, "batch_reward": 0.35065887719392774, "critic_loss": 0.2880568322837353, "actor_loss": -41.327528175354004, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.42292547225952, "step": 144000}
{"episode_reward": 549.8659941840077, "episode": 145.0, "batch_reward": 0.35209514293074606, "critic_loss": 0.28078870917111637, "actor_loss": -41.60322061157227, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.446632623672485, "step": 145000}
{"episode_reward": 554.0526697312824, "episode": 146.0, "batch_reward": 0.35220862439274786, "critic_loss": 0.28437155490368604, "actor_loss": -41.75640486145019, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.050025463104248, "step": 146000}
{"episode_reward": 533.8181524437061, "episode": 147.0, "batch_reward": 0.35286797097325323, "critic_loss": 0.2903825766220689, "actor_loss": -41.68286027526855, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.589160680770874, "step": 147000}
{"episode_reward": 536.264047684797, "episode": 148.0, "batch_reward": 0.3554229029119015, "critic_loss": 0.2796849486380816, "actor_loss": -42.05990755462646, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.036593198776245, "step": 148000}
{"episode_reward": 538.2961831353133, "episode": 149.0, "batch_reward": 0.3562732126414776, "critic_loss": 0.2825691158846021, "actor_loss": -42.01224991607666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.469801664352417, "step": 149000}
{"episode_reward": 553.8979087654977, "episode": 150.0, "batch_reward": 0.3588265749514103, "critic_loss": 0.287781921505928, "actor_loss": -42.249156936645505, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
