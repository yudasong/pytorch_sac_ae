{"episode_reward": 0.0, "episode": 1.0, "duration": 17.8492431640625, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.6545045375823975, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.22195544090369176, "critic_loss": 0.04291636899309919, "actor_loss": -23.01628490859697, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 67.0233199596405, "step": 3000}
{"episode_reward": 109.90721332481826, "episode": 4.0, "batch_reward": 0.1719245315566659, "critic_loss": 0.03680122372321785, "actor_loss": -21.27733484930545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.973305463790894, "step": 4000}
{"episode_reward": 31.542334698278864, "episode": 5.0, "batch_reward": 0.1383160855099559, "critic_loss": 0.03432560623064637, "actor_loss": -16.89083496081084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.20678973197937, "step": 5000}
{"episode_reward": 79.6012674198776, "episode": 6.0, "batch_reward": 0.13305652118474245, "critic_loss": 0.056095660435035825, "actor_loss": -18.047318872369825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.304638862609863, "step": 6000}
{"episode_reward": 119.75565950393154, "episode": 7.0, "batch_reward": 0.12704911353439094, "critic_loss": 0.0659693703968078, "actor_loss": -18.795168557837606, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.158788442611694, "step": 7000}
{"episode_reward": 31.86543915434572, "episode": 8.0, "batch_reward": 0.12430244561284781, "critic_loss": 0.06714039331860841, "actor_loss": -17.92337977336347, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.23035168647766, "step": 8000}
{"episode_reward": 149.00480970341698, "episode": 9.0, "batch_reward": 0.12370256561040878, "critic_loss": 0.07661223626881838, "actor_loss": -17.638504134237767, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.93898034095764, "step": 9000}
{"episode_reward": 90.99215798446582, "episode": 10.0, "batch_reward": 0.1216819973140955, "critic_loss": 0.10826649732887744, "actor_loss": -16.69052163553238, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.24198341369629, "step": 10000}
{"episode_reward": 127.63705459177395, "episode": 11.0, "batch_reward": 0.11931870106607675, "critic_loss": 0.1383724827580154, "actor_loss": -17.127781271219252, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.430227518081665, "step": 11000}
{"episode_reward": 50.42779127790162, "episode": 12.0, "batch_reward": 0.11397615376859903, "critic_loss": 0.13751259096339344, "actor_loss": -15.72885503077507, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.39217472076416, "step": 12000}
{"episode_reward": 71.19291158838843, "episode": 13.0, "batch_reward": 0.10706612047553063, "critic_loss": 0.12106719843670725, "actor_loss": -15.047258838176727, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.955451011657715, "step": 13000}
{"episode_reward": 19.79621723580898, "episode": 14.0, "batch_reward": 0.10269767695665359, "critic_loss": 0.20323063353076576, "actor_loss": -14.269889992952347, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.772591829299927, "step": 14000}
{"episode_reward": 76.13843830977856, "episode": 15.0, "batch_reward": 0.10288929829001427, "critic_loss": 0.25412051667273045, "actor_loss": -16.109510885715483, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.25175905227661, "step": 15000}
{"episode_reward": 101.08334842755032, "episode": 16.0, "batch_reward": 0.09999253513664007, "critic_loss": 0.22490202779322863, "actor_loss": -15.842240915298461, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.094324588775635, "step": 16000}
{"episode_reward": 44.12415359325394, "episode": 17.0, "batch_reward": 0.09575430468097329, "critic_loss": 0.2611403161510825, "actor_loss": -14.631718832492828, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.47957181930542, "step": 17000}
{"episode_reward": 21.07885326572357, "episode": 18.0, "batch_reward": 0.09418977396935224, "critic_loss": 0.2808850165680051, "actor_loss": -14.252402945041656, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.68994951248169, "step": 18000}
{"episode_reward": 76.91519196106539, "episode": 19.0, "batch_reward": 0.09504605523869396, "critic_loss": 0.29475371189415456, "actor_loss": -15.049336839199066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.03352165222168, "step": 19000}
{"episode_reward": 197.81535587053122, "episode": 20.0, "batch_reward": 0.09574528571218252, "critic_loss": 0.27432328767329456, "actor_loss": -15.39215453672409, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.200828790664673, "step": 20000}
{"episode_reward": 32.30493682324455, "episode": 21.0, "batch_reward": 0.0945562703460455, "critic_loss": 0.24187476237118244, "actor_loss": -15.521617030620575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.421440839767456, "step": 21000}
{"episode_reward": 45.09454078601179, "episode": 22.0, "batch_reward": 0.09267663189396262, "critic_loss": 0.2833461299687624, "actor_loss": -14.590105850696563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30639362335205, "step": 22000}
{"episode_reward": 69.98865925792431, "episode": 23.0, "batch_reward": 0.09196891194581985, "critic_loss": 0.24084883537888527, "actor_loss": -14.069638007640838, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.696714401245117, "step": 23000}
{"episode_reward": 67.01111893985565, "episode": 24.0, "batch_reward": 0.09224844174459576, "critic_loss": 0.25554634898155926, "actor_loss": -14.869036600112915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.14661145210266, "step": 24000}
{"episode_reward": 142.11591634044655, "episode": 25.0, "batch_reward": 0.09333196495100855, "critic_loss": 0.28938323161751034, "actor_loss": -14.38198120880127, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.607619047164917, "step": 25000}
{"episode_reward": 83.97247648440036, "episode": 26.0, "batch_reward": 0.09198590998724103, "critic_loss": 0.23682515796273948, "actor_loss": -14.315155533790588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.606064558029175, "step": 26000}
{"episode_reward": 65.30503564061276, "episode": 27.0, "batch_reward": 0.09309263034164905, "critic_loss": 0.22599143105000258, "actor_loss": -14.294461936473846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.623804807662964, "step": 27000}
{"episode_reward": 154.7115336401966, "episode": 28.0, "batch_reward": 0.09271448995545506, "critic_loss": 0.24945796632021666, "actor_loss": -14.053814596176148, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.21807551383972, "step": 28000}
{"episode_reward": 60.443141847451216, "episode": 29.0, "batch_reward": 0.09412308175861836, "critic_loss": 0.2530518576130271, "actor_loss": -14.821738949775696, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.888670444488525, "step": 29000}
{"episode_reward": 129.1369198469804, "episode": 30.0, "batch_reward": 0.09305199852958322, "critic_loss": 0.26742771376669405, "actor_loss": -14.50260585308075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.774107694625854, "step": 30000}
{"episode_reward": 60.60434660617896, "episode": 31.0, "batch_reward": 0.09509384236857295, "critic_loss": 0.28663515858352184, "actor_loss": -14.948100356101989, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.22508764266968, "step": 31000}
{"episode_reward": 174.06665005296406, "episode": 32.0, "batch_reward": 0.09815679710358381, "critic_loss": 0.31391470800340177, "actor_loss": -15.18885886001587, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14002251625061, "step": 32000}
{"episode_reward": 261.55262266719836, "episode": 33.0, "batch_reward": 0.10291900955140591, "critic_loss": 0.2769656240940094, "actor_loss": -15.648609107017517, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.79559016227722, "step": 33000}
{"episode_reward": 240.80901966618504, "episode": 34.0, "batch_reward": 0.10566493681818247, "critic_loss": 0.3125413314849138, "actor_loss": -15.1028568983078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.758485794067383, "step": 34000}
{"episode_reward": 105.5117413178987, "episode": 35.0, "batch_reward": 0.10736047492921352, "critic_loss": 0.274936945296824, "actor_loss": -16.149028807640075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.15770435333252, "step": 35000}
{"episode_reward": 311.0965783899283, "episode": 36.0, "batch_reward": 0.11236993071436882, "critic_loss": 0.26679278291761876, "actor_loss": -16.152158353805543, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.655787706375122, "step": 36000}
{"episode_reward": 320.4224505875685, "episode": 37.0, "batch_reward": 0.11912771455943584, "critic_loss": 0.2963108931258321, "actor_loss": -16.8474447183609, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.086654901504517, "step": 37000}
{"episode_reward": 348.4739692649146, "episode": 38.0, "batch_reward": 0.12514297345280648, "critic_loss": 0.30098198173195123, "actor_loss": -17.861989755630493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.546910762786865, "step": 38000}
{"episode_reward": 287.8299568719596, "episode": 39.0, "batch_reward": 0.12834637246280908, "critic_loss": 0.27862435014545917, "actor_loss": -18.651251756668092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.04774308204651, "step": 39000}
{"episode_reward": 205.42415916889823, "episode": 40.0, "batch_reward": 0.13009340578317644, "critic_loss": 0.2790908159688115, "actor_loss": -18.665296239852907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.743948459625244, "step": 40000}
{"episode_reward": 99.12613630214751, "episode": 41.0, "batch_reward": 0.13038709328323603, "critic_loss": 0.30669829244166613, "actor_loss": -18.51126072692871, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.31401181221008, "step": 41000}
{"episode_reward": 235.9505006739388, "episode": 42.0, "batch_reward": 0.13106749350577593, "critic_loss": 0.2937259005308151, "actor_loss": -18.211313173294066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.842870950698853, "step": 42000}
{"episode_reward": 105.96406320785262, "episode": 43.0, "batch_reward": 0.13265662354975938, "critic_loss": 0.2785057312697172, "actor_loss": -18.608647737503052, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.569510459899902, "step": 43000}
{"episode_reward": 361.75235284089274, "episode": 44.0, "batch_reward": 0.1385846871510148, "critic_loss": 0.28045695113390684, "actor_loss": -18.924318113327026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.623732566833496, "step": 44000}
{"episode_reward": 410.1602140664488, "episode": 45.0, "batch_reward": 0.14490165031701327, "critic_loss": 0.2738600881174207, "actor_loss": -20.06243650817871, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.086086988449097, "step": 45000}
{"episode_reward": 313.1152289314344, "episode": 46.0, "batch_reward": 0.1477374214231968, "critic_loss": 0.2797991189062595, "actor_loss": -20.33858879852295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.847607851028442, "step": 46000}
{"episode_reward": 397.12903728860954, "episode": 47.0, "batch_reward": 0.1542711207792163, "critic_loss": 0.2705263593569398, "actor_loss": -20.57881015777588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.64890480041504, "step": 47000}
{"episode_reward": 382.3574088402474, "episode": 48.0, "batch_reward": 0.15666139869391918, "critic_loss": 0.2699116758480668, "actor_loss": -20.593662395477295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.90991187095642, "step": 48000}
{"episode_reward": 103.24385665893871, "episode": 49.0, "batch_reward": 0.15706510853022337, "critic_loss": 0.2710835918262601, "actor_loss": -20.85747448539734, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.97963237762451, "step": 49000}
{"episode_reward": 380.123345401775, "episode": 50.0, "batch_reward": 0.16163478081673383, "critic_loss": 0.25861540392041205, "actor_loss": -21.59089068031311, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.536344528198242, "step": 50000}
{"episode_reward": 414.4516316557043, "episode": 51.0, "batch_reward": 0.16694409966468812, "critic_loss": 0.268133032694459, "actor_loss": -21.582544317245482, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.80782890319824, "step": 51000}
{"episode_reward": 377.23675909266393, "episode": 52.0, "batch_reward": 0.17059520579874515, "critic_loss": 0.24409761253744364, "actor_loss": -22.66119348526001, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.363229036331177, "step": 52000}
{"episode_reward": 259.53737460434206, "episode": 53.0, "batch_reward": 0.17197822926938533, "critic_loss": 0.26004468674957754, "actor_loss": -22.613955337524413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.787891387939453, "step": 53000}
{"episode_reward": 356.05359869059635, "episode": 54.0, "batch_reward": 0.17627897733449935, "critic_loss": 0.2640088129043579, "actor_loss": -22.98957579421997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14582085609436, "step": 54000}
{"episode_reward": 392.3077597122345, "episode": 55.0, "batch_reward": 0.18023930376768113, "critic_loss": 0.29202591137588024, "actor_loss": -23.07601809310913, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.358946323394775, "step": 55000}
{"episode_reward": 418.6311883587507, "episode": 56.0, "batch_reward": 0.18236204281449317, "critic_loss": 0.27623327004909515, "actor_loss": -23.773787712097167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.27308464050293, "step": 56000}
{"episode_reward": 106.70117133246639, "episode": 57.0, "batch_reward": 0.18384169259667396, "critic_loss": 0.2692890610694885, "actor_loss": -24.058641759872437, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.4001145362854, "step": 57000}
{"episode_reward": 431.14440172716115, "episode": 58.0, "batch_reward": 0.18748612457513808, "critic_loss": 0.2905967390611768, "actor_loss": -23.603929899215697, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.163409948349, "step": 58000}
{"episode_reward": 419.17053976428946, "episode": 59.0, "batch_reward": 0.19134575894474984, "critic_loss": 0.28453324538469316, "actor_loss": -24.208903093338012, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.4332754611969, "step": 59000}
{"episode_reward": 327.26456439325716, "episode": 60.0, "batch_reward": 0.19404889369010925, "critic_loss": 0.2919396163970232, "actor_loss": -25.606499792098997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.832724809646606, "step": 60000}
{"episode_reward": 401.0441786963139, "episode": 61.0, "batch_reward": 0.19755934649705886, "critic_loss": 0.2774900870323181, "actor_loss": -25.021472034454344, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.553712368011475, "step": 61000}
{"episode_reward": 442.2726973431341, "episode": 62.0, "batch_reward": 0.20130439358949662, "critic_loss": 0.2708580926731229, "actor_loss": -25.259476325988768, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.228605031967163, "step": 62000}
{"episode_reward": 435.8654973908002, "episode": 63.0, "batch_reward": 0.20422505755722523, "critic_loss": 0.2777021838501096, "actor_loss": -26.156076595306395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.61920666694641, "step": 63000}
{"episode_reward": 409.68849727797186, "episode": 64.0, "batch_reward": 0.20700631281733514, "critic_loss": 0.29993433075398207, "actor_loss": -26.15975416946411, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.473268508911133, "step": 64000}
{"episode_reward": 270.2705280127476, "episode": 65.0, "batch_reward": 0.2077408421933651, "critic_loss": 0.3183478191867471, "actor_loss": -26.42172407722473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.143962383270264, "step": 65000}
{"episode_reward": 245.00873193298767, "episode": 66.0, "batch_reward": 0.21041534304618836, "critic_loss": 0.31317357025295495, "actor_loss": -26.74244736480713, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.0635085105896, "step": 66000}
{"episode_reward": 327.97794660522965, "episode": 67.0, "batch_reward": 0.21064671890437603, "critic_loss": 0.3493920803964138, "actor_loss": -27.26885720825195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.233282327651978, "step": 67000}
{"episode_reward": 288.4478494345812, "episode": 68.0, "batch_reward": 0.21155847644805909, "critic_loss": 0.36971444565057754, "actor_loss": -26.562886070251466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.072972536087036, "step": 68000}
{"episode_reward": 338.89634145191997, "episode": 69.0, "batch_reward": 0.21382127597928047, "critic_loss": 0.40593580310046673, "actor_loss": -27.24382104110718, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.467005014419556, "step": 69000}
{"episode_reward": 408.19692342398406, "episode": 70.0, "batch_reward": 0.21695747843384744, "critic_loss": 0.3970605274438858, "actor_loss": -27.68962503051758, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.993621826171875, "step": 70000}
{"episode_reward": 454.7034619761576, "episode": 71.0, "batch_reward": 0.2205901045948267, "critic_loss": 0.4163988532721996, "actor_loss": -27.4785326461792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.776522636413574, "step": 71000}
{"episode_reward": 440.8052898821549, "episode": 72.0, "batch_reward": 0.22344518035650254, "critic_loss": 0.3922269925177097, "actor_loss": -27.959955307006837, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.846603870391846, "step": 72000}
{"episode_reward": 440.0921699402484, "episode": 73.0, "batch_reward": 0.22653212061524391, "critic_loss": 0.4224557359516621, "actor_loss": -28.482308326721192, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.672112226486206, "step": 73000}
{"episode_reward": 466.5494981933524, "episode": 74.0, "batch_reward": 0.2301274090707302, "critic_loss": 0.43237597300112246, "actor_loss": -29.27142897415161, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.84886407852173, "step": 74000}
{"episode_reward": 460.80309356241236, "episode": 75.0, "batch_reward": 0.23253243942558766, "critic_loss": 0.4112141058743, "actor_loss": -29.445564430236818, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.520414113998413, "step": 75000}
{"episode_reward": 394.93903336853884, "episode": 76.0, "batch_reward": 0.23452156788110734, "critic_loss": 0.375327336743474, "actor_loss": -29.670227016448976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.344016551971436, "step": 76000}
{"episode_reward": 431.84170169364256, "episode": 77.0, "batch_reward": 0.23827012427151203, "critic_loss": 0.38056491082906724, "actor_loss": -30.14243123245239, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.41710138320923, "step": 77000}
{"episode_reward": 473.58435687119845, "episode": 78.0, "batch_reward": 0.2410444568246603, "critic_loss": 0.37028340114653113, "actor_loss": -30.750400985717775, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.2214515209198, "step": 78000}
{"episode_reward": 433.4870741369632, "episode": 79.0, "batch_reward": 0.2426529048681259, "critic_loss": 0.4101740584820509, "actor_loss": -30.38920322036743, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.06080198287964, "step": 79000}
{"episode_reward": 446.3007410322284, "episode": 80.0, "batch_reward": 0.24637873055040838, "critic_loss": 0.3750603838264942, "actor_loss": -30.84608425140381, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.850747108459473, "step": 80000}
{"episode_reward": 472.7169211078871, "episode": 81.0, "batch_reward": 0.24919514118134975, "critic_loss": 0.3778523437380791, "actor_loss": -31.25494518661499, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.52670693397522, "step": 81000}
{"episode_reward": 468.80958055860305, "episode": 82.0, "batch_reward": 0.2517118029594421, "critic_loss": 0.3583256702125073, "actor_loss": -31.934128650665283, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.357314825057983, "step": 82000}
{"episode_reward": 406.0175068688693, "episode": 83.0, "batch_reward": 0.25385360372066496, "critic_loss": 0.3650934427902102, "actor_loss": -31.677687255859375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.335227489471436, "step": 83000}
{"episode_reward": 465.8517105905882, "episode": 84.0, "batch_reward": 0.25659340173006057, "critic_loss": 0.3624486144706607, "actor_loss": -31.884348487854005, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.360520601272583, "step": 84000}
{"episode_reward": 468.6565342301603, "episode": 85.0, "batch_reward": 0.2574026055037975, "critic_loss": 0.37775446759164333, "actor_loss": -32.11740203857422, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.76925230026245, "step": 85000}
{"episode_reward": 171.8026798222051, "episode": 86.0, "batch_reward": 0.25777846720814707, "critic_loss": 0.3618575668036938, "actor_loss": -31.68053589630127, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.07201838493347, "step": 86000}
{"episode_reward": 439.6942015725964, "episode": 87.0, "batch_reward": 0.25880159850418566, "critic_loss": 0.3625396196842194, "actor_loss": -31.80362738418579, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.67255139350891, "step": 87000}
{"episode_reward": 453.3083711326023, "episode": 88.0, "batch_reward": 0.2614615785330534, "critic_loss": 0.36961095249652864, "actor_loss": -31.66548016357422, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.989368677139282, "step": 88000}
{"episode_reward": 477.49112007043425, "episode": 89.0, "batch_reward": 0.2635899212360382, "critic_loss": 0.36070645397901535, "actor_loss": -32.15013256072998, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.204203605651855, "step": 89000}
{"episode_reward": 463.2261993574976, "episode": 90.0, "batch_reward": 0.2662812352925539, "critic_loss": 0.32638368487358094, "actor_loss": -32.60825503158569, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.764753103256226, "step": 90000}
{"episode_reward": 474.20866304487004, "episode": 91.0, "batch_reward": 0.2686016843020916, "critic_loss": 0.3475493795126677, "actor_loss": -32.48583345031738, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.65207123756409, "step": 91000}
{"episode_reward": 433.661942918062, "episode": 92.0, "batch_reward": 0.2696094446629286, "critic_loss": 0.3260293328166008, "actor_loss": -32.57692404556274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.002779960632324, "step": 92000}
{"episode_reward": 451.98679430736627, "episode": 93.0, "batch_reward": 0.2715596204251051, "critic_loss": 0.32430073983222246, "actor_loss": -32.68460611343384, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.459460020065308, "step": 93000}
{"episode_reward": 481.2890002508314, "episode": 94.0, "batch_reward": 0.27457246463000773, "critic_loss": 0.3259625046700239, "actor_loss": -32.82825283432007, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.929736614227295, "step": 94000}
{"episode_reward": 486.7036955309552, "episode": 95.0, "batch_reward": 0.2770392952114344, "critic_loss": 0.3016099773794413, "actor_loss": -33.49675959777832, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.60529899597168, "step": 95000}
{"episode_reward": 339.4400381339816, "episode": 96.0, "batch_reward": 0.2767447664141655, "critic_loss": 0.32440477453172206, "actor_loss": -33.088153331756594, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.5430588722229, "step": 96000}
{"episode_reward": 421.08530674499207, "episode": 97.0, "batch_reward": 0.27707169361412526, "critic_loss": 0.34755163635313513, "actor_loss": -33.23881528472901, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23898434638977, "step": 97000}
{"episode_reward": 127.59098055120116, "episode": 98.0, "batch_reward": 0.27716009253263474, "critic_loss": 0.3276037035435438, "actor_loss": -33.11086925888061, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.67484402656555, "step": 98000}
{"episode_reward": 495.9123091761228, "episode": 99.0, "batch_reward": 0.2793077867925167, "critic_loss": 0.3374240630865097, "actor_loss": -33.28418221664429, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.67248034477234, "step": 99000}
{"episode_reward": 489.1255655493045, "episode": 100.0, "batch_reward": 0.28266717870533464, "critic_loss": 0.3481423726826906, "actor_loss": -33.1933861618042, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.9748854637146, "step": 100000}
{"episode_reward": 467.9565292295753, "episode": 101.0, "batch_reward": 0.28392381983995435, "critic_loss": 0.3414562534242868, "actor_loss": -33.7492438621521, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.00473213195801, "step": 101000}
{"episode_reward": 509.7488008322178, "episode": 102.0, "batch_reward": 0.28463973435759543, "critic_loss": 0.3432557831853628, "actor_loss": -33.739148094177246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.207528114318848, "step": 102000}
{"episode_reward": 455.1834321887364, "episode": 103.0, "batch_reward": 0.2850778818130493, "critic_loss": 0.374610743150115, "actor_loss": -33.72733168792725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.46340274810791, "step": 103000}
{"episode_reward": 148.96539765170476, "episode": 104.0, "batch_reward": 0.28620638579130175, "critic_loss": 0.3908684070259333, "actor_loss": -33.60459063720703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.033749103546143, "step": 104000}
{"episode_reward": 482.1479558950961, "episode": 105.0, "batch_reward": 0.28827744773030284, "critic_loss": 0.35811063706874846, "actor_loss": -33.8270326385498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.84160828590393, "step": 105000}
{"episode_reward": 475.51380220193727, "episode": 106.0, "batch_reward": 0.2893202676773071, "critic_loss": 0.35975439559668304, "actor_loss": -33.66284959411621, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.50468349456787, "step": 106000}
{"episode_reward": 481.83329747908414, "episode": 107.0, "batch_reward": 0.291809181317687, "critic_loss": 0.359826647400856, "actor_loss": -34.13494319534302, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.166416883468628, "step": 107000}
{"episode_reward": 488.7643133330664, "episode": 108.0, "batch_reward": 0.29351515844464304, "critic_loss": 0.34066110284626483, "actor_loss": -34.26382572555542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.26475739479065, "step": 108000}
{"episode_reward": 368.2900422208716, "episode": 109.0, "batch_reward": 0.2940683135390282, "critic_loss": 0.3526436126679182, "actor_loss": -34.42360866546631, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.13920307159424, "step": 109000}
{"episode_reward": 487.38683647929275, "episode": 110.0, "batch_reward": 0.2962076971679926, "critic_loss": 0.3659574174582958, "actor_loss": -34.66245121383667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.788554191589355, "step": 110000}
{"episode_reward": 485.2206116824109, "episode": 111.0, "batch_reward": 0.2980424758344889, "critic_loss": 0.3532448759973049, "actor_loss": -35.08980250549316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.35736346244812, "step": 111000}
{"episode_reward": 428.1948936998955, "episode": 112.0, "batch_reward": 0.2995688140690327, "critic_loss": 0.33771050116419793, "actor_loss": -34.77409115600586, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.7040958404541, "step": 112000}
{"episode_reward": 483.8996972856276, "episode": 113.0, "batch_reward": 0.30061321100592614, "critic_loss": 0.3305355293378234, "actor_loss": -34.61153336334228, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.821000814437866, "step": 113000}
{"episode_reward": 476.7282445140891, "episode": 114.0, "batch_reward": 0.30154924432933333, "critic_loss": 0.36898439279943707, "actor_loss": -35.25778884124756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.142526626586914, "step": 114000}
{"episode_reward": 496.0131844967089, "episode": 115.0, "batch_reward": 0.3042330166697502, "critic_loss": 0.33498882128298285, "actor_loss": -35.21509239578247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.231988430023193, "step": 115000}
{"episode_reward": 465.22812304343626, "episode": 116.0, "batch_reward": 0.3052879290878773, "critic_loss": 0.30909344451874493, "actor_loss": -35.49513659286499, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.697525024414062, "step": 116000}
{"episode_reward": 485.7180020896683, "episode": 117.0, "batch_reward": 0.30782341888546944, "critic_loss": 0.329079364515841, "actor_loss": -35.20223306655884, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.160930156707764, "step": 117000}
{"episode_reward": 493.2247059941329, "episode": 118.0, "batch_reward": 0.30792299982905386, "critic_loss": 0.3062337743937969, "actor_loss": -35.537455352783205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.532198190689087, "step": 118000}
{"episode_reward": 498.327797922212, "episode": 119.0, "batch_reward": 0.3098342796564102, "critic_loss": 0.2902822668775916, "actor_loss": -35.84016342163086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.834392547607422, "step": 119000}
{"episode_reward": 478.5066935177582, "episode": 120.0, "batch_reward": 0.31062926971912386, "critic_loss": 0.2930326234102249, "actor_loss": -35.378486087799075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.029916286468506, "step": 120000}
{"episode_reward": 497.0162038581337, "episode": 121.0, "batch_reward": 0.3135339700877666, "critic_loss": 0.32351440493017436, "actor_loss": -35.98598294067383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.91944646835327, "step": 121000}
{"episode_reward": 498.46829276875445, "episode": 122.0, "batch_reward": 0.31531488996744156, "critic_loss": 0.3031914488002658, "actor_loss": -36.28098445892334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.546204328536987, "step": 122000}
{"episode_reward": 485.4840745121839, "episode": 123.0, "batch_reward": 0.3171645720601082, "critic_loss": 0.3082915508598089, "actor_loss": -35.928554050445555, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.012605667114258, "step": 123000}
{"episode_reward": 472.2893825390678, "episode": 124.0, "batch_reward": 0.3166898087561131, "critic_loss": 0.28892364936321974, "actor_loss": -36.48270055389404, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.046300649642944, "step": 124000}
{"episode_reward": 455.68524547446714, "episode": 125.0, "batch_reward": 0.318394710958004, "critic_loss": 0.32150249564647676, "actor_loss": -36.062693794250485, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.09163212776184, "step": 125000}
{"episode_reward": 505.12957595178835, "episode": 126.0, "batch_reward": 0.3189714185297489, "critic_loss": 0.3043547119051218, "actor_loss": -36.618493152618406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.33933424949646, "step": 126000}
{"episode_reward": 499.00895858672897, "episode": 127.0, "batch_reward": 0.3215750607252121, "critic_loss": 0.286903391905129, "actor_loss": -36.87710697555542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.704286575317383, "step": 127000}
{"episode_reward": 507.5209662201076, "episode": 128.0, "batch_reward": 0.3229046857059002, "critic_loss": 0.31732120402902364, "actor_loss": -36.90799312210083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.575797080993652, "step": 128000}
{"episode_reward": 482.9476515048814, "episode": 129.0, "batch_reward": 0.3233622424900532, "critic_loss": 0.3253921288922429, "actor_loss": -37.079657920837406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.569138526916504, "step": 129000}
{"episode_reward": 513.6056150038046, "episode": 130.0, "batch_reward": 0.32489222210645674, "critic_loss": 0.2947083411067724, "actor_loss": -37.226454181671144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.55854368209839, "step": 130000}
{"episode_reward": 476.3672035962953, "episode": 131.0, "batch_reward": 0.32644931179285047, "critic_loss": 0.2921243868693709, "actor_loss": -37.30653415298462, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.17080330848694, "step": 131000}
{"episode_reward": 494.116455888332, "episode": 132.0, "batch_reward": 0.32779719176888467, "critic_loss": 0.2945306493788958, "actor_loss": -37.18256535339356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.338542461395264, "step": 132000}
{"episode_reward": 466.58253535393527, "episode": 133.0, "batch_reward": 0.3279911976456642, "critic_loss": 0.2719556481763721, "actor_loss": -37.416876609802245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.105842113494873, "step": 133000}
{"episode_reward": 469.70909485911676, "episode": 134.0, "batch_reward": 0.32929440796375276, "critic_loss": 0.270030218757689, "actor_loss": -37.631806549072266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.480912685394287, "step": 134000}
{"episode_reward": 458.43532545981014, "episode": 135.0, "batch_reward": 0.33059039497375486, "critic_loss": 0.2667237935513258, "actor_loss": -37.64585412979126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.436933994293213, "step": 135000}
{"episode_reward": 495.88222030695266, "episode": 136.0, "batch_reward": 0.33187962889671324, "critic_loss": 0.2553162083849311, "actor_loss": -37.92944004821777, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.930450677871704, "step": 136000}
{"episode_reward": 460.8197179373404, "episode": 137.0, "batch_reward": 0.3325527202785015, "critic_loss": 0.28252437587827445, "actor_loss": -37.66331462860107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.814382553100586, "step": 137000}
{"episode_reward": 511.8093217910304, "episode": 138.0, "batch_reward": 0.3353726330697536, "critic_loss": 0.2842598913088441, "actor_loss": -37.65145432662964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.713810205459595, "step": 138000}
{"episode_reward": 492.5840418994386, "episode": 139.0, "batch_reward": 0.33567760640382766, "critic_loss": 0.2610015216320753, "actor_loss": -37.73518450164795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.383455276489258, "step": 139000}
{"episode_reward": 508.5041826967871, "episode": 140.0, "batch_reward": 0.3359260696470737, "critic_loss": 0.2681249865218997, "actor_loss": -37.50983675765991, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.39942240715027, "step": 140000}
{"episode_reward": 408.9843087058093, "episode": 141.0, "batch_reward": 0.337058143556118, "critic_loss": 0.26003200326114895, "actor_loss": -37.45710758972168, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.092084646224976, "step": 141000}
{"episode_reward": 493.4113438280659, "episode": 142.0, "batch_reward": 0.33822408464550974, "critic_loss": 0.2847015537172556, "actor_loss": -38.201009765625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.439789295196533, "step": 142000}
{"episode_reward": 510.9163413755646, "episode": 143.0, "batch_reward": 0.34060809275507925, "critic_loss": 0.2662860270887613, "actor_loss": -38.01994465637207, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.099525928497314, "step": 143000}
{"episode_reward": 517.9235783929212, "episode": 144.0, "batch_reward": 0.3411069398522377, "critic_loss": 0.26815917518734933, "actor_loss": -38.33376182937622, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.762234449386597, "step": 144000}
{"episode_reward": 461.5778626386562, "episode": 145.0, "batch_reward": 0.3417164619266987, "critic_loss": 0.30887598791718485, "actor_loss": -38.13874073028565, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.06532645225525, "step": 145000}
{"episode_reward": 496.1365728398089, "episode": 146.0, "batch_reward": 0.34176799631118776, "critic_loss": 0.290495453864336, "actor_loss": -38.65608187866211, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.74405598640442, "step": 146000}
{"episode_reward": 451.1951914570046, "episode": 147.0, "batch_reward": 0.3428785477876663, "critic_loss": 0.2970047485753894, "actor_loss": -38.48079011154175, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.972193241119385, "step": 147000}
{"episode_reward": 436.3543865246491, "episode": 148.0, "batch_reward": 0.34411202189326284, "critic_loss": 0.2878981973901391, "actor_loss": -38.64987359237671, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.365710258483887, "step": 148000}
{"episode_reward": 517.9996918831931, "episode": 149.0, "batch_reward": 0.3457576813995838, "critic_loss": 0.29437482453137637, "actor_loss": -38.832786781311036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.710191011428833, "step": 149000}
{"episode_reward": 482.87110254082137, "episode": 150.0, "batch_reward": 0.34643060448765756, "critic_loss": 0.29443823313713074, "actor_loss": -38.97115568161011, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
