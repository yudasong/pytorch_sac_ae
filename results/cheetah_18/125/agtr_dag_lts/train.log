{"episode": 1.0, "duration": 17.486743211746216, "episode_reward": 5.1931688606333894, "step": 1000}
{"episode": 2.0, "duration": 1.4909088611602783, "episode_reward": 454.7514538707513, "step": 2000}
{"episode": 3.0, "batch_reward": 0.2334415279713898, "critic_loss": 0.17480355382050106, "actor_loss": -45.833674267131165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 66.1234757900238, "episode_reward": 318.30525847084454, "step": 3000}
{"episode": 4.0, "batch_reward": 0.2634132508188486, "critic_loss": 0.3439869259148836, "actor_loss": -47.2635740814209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.54000449180603, "episode_reward": 200.11065173535238, "step": 4000}
{"episode": 5.0, "batch_reward": 0.2580602553486824, "critic_loss": 0.36800883665680884, "actor_loss": -47.51626992797851, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.645906448364258, "episode_reward": 401.6751031175498, "step": 5000}
{"episode": 6.0, "batch_reward": 0.2533734327852726, "critic_loss": 0.4126649882644415, "actor_loss": -47.61100735473633, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.80372452735901, "episode_reward": 21.52905909466092, "step": 6000}
{"episode": 7.0, "batch_reward": 0.21519726042449475, "critic_loss": 0.34847672408819197, "actor_loss": -46.467926582336425, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.784508228302002, "episode_reward": 6.470736638715308, "step": 7000}
{"episode": 8.0, "batch_reward": 0.18978505344688892, "critic_loss": 0.32679002802073953, "actor_loss": -45.602737998962404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.812878608703613, "episode_reward": 19.106774963072507, "step": 8000}
{"episode": 9.0, "batch_reward": 0.17003635536879302, "critic_loss": 0.35148125775158406, "actor_loss": -45.050806381225584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.846107721328735, "episode_reward": 90.0889938069744, "step": 9000}
{"episode": 10.0, "batch_reward": 0.1601029405221343, "critic_loss": 0.29459697334468365, "actor_loss": -42.52406851196289, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 3512.7082993984222, "episode_reward": 2.183880246759572, "step": 10000}
{"episode": 11.0, "batch_reward": 0.14530562734603883, "critic_loss": 0.21283071283251048, "actor_loss": -41.669483901977536, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.67934989929199, "episode_reward": 10.328399492160212, "step": 11000}
{"episode": 12.0, "batch_reward": 0.13397481545060874, "critic_loss": 0.17792848224937916, "actor_loss": -39.56140237045288, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 394.39179372787476, "episode_reward": 6.046128371466677, "step": 12000}
{"episode": 13.0, "batch_reward": 0.12406067851930856, "critic_loss": 0.1803797118216753, "actor_loss": -38.71208562469482, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.975196838378906, "episode_reward": 31.85676375978163, "step": 13000}
{"episode": 14.0, "batch_reward": 0.11639558474719525, "critic_loss": 0.2614977318048477, "actor_loss": -37.518564945220945, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 394.42607069015503, "episode_reward": 9.530842040746078, "step": 14000}
{"episode": 15.0, "batch_reward": 0.10880692761391401, "critic_loss": 0.2295765607357025, "actor_loss": -36.265158557891844, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.664763689041138, "episode_reward": 7.843308878978302, "step": 15000}
{"episode": 16.0, "batch_reward": 0.114670100428164, "critic_loss": 0.2616485181823373, "actor_loss": -35.84344351577759, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 393.8470890522003, "episode_reward": 371.60542206787983, "step": 16000}
{"episode": 17.0, "batch_reward": 0.11780467561632395, "critic_loss": 0.2839762131050229, "actor_loss": -35.35003857421875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.6738543510437, "episode_reward": 5.467994706429134, "step": 17000}
{"episode": 18.0, "batch_reward": 0.1230489992275834, "critic_loss": 0.24488573968410493, "actor_loss": -34.81673365020752, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.8995740413666, "episode_reward": 411.1900051980868, "step": 18000}
{"episode": 19.0, "batch_reward": 0.12967750779539347, "critic_loss": 0.373924293898046, "actor_loss": -34.735727840423586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.64768695831299, "episode_reward": 12.006344286534416, "step": 19000}
{"episode": 20.0, "batch_reward": 0.1225777024179697, "critic_loss": 0.3810287364050746, "actor_loss": -33.465591667175296, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.25891852378845, "episode_reward": 11.079206792109966, "step": 20000}
{"episode": 21.0, "batch_reward": 0.11723865395784377, "critic_loss": 0.6640433698520064, "actor_loss": -32.67427265930176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.57230257987976, "episode_reward": 11.080102195776611, "step": 21000}
{"episode": 22.0, "batch_reward": 0.11234443929046392, "critic_loss": 2.540860332891345, "actor_loss": -32.06563759994507, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.70840668678284, "episode_reward": 8.84521908562042, "step": 22000}
{"episode": 23.0, "batch_reward": 0.10795284672826529, "critic_loss": 4.32538732200861, "actor_loss": -32.482061721801756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.023298978805542, "episode_reward": 17.754771650232644, "step": 23000}
{"episode": 24.0, "batch_reward": 0.10430585897341371, "critic_loss": 4.7573712297677995, "actor_loss": -32.99025131225586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.05652713775635, "episode_reward": 19.42139367465815, "step": 24000}
{"episode": 25.0, "batch_reward": 0.10091852541267872, "critic_loss": 7.742731091499329, "actor_loss": -37.4034156036377, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.995168685913086, "episode_reward": 22.668800723212403, "step": 25000}
{"episode": 26.0, "batch_reward": 0.09793604499474168, "critic_loss": 9.061088234901428, "actor_loss": -41.55615793609619, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.10235047340393, "episode_reward": 17.315205332112225, "step": 26000}
{"episode": 27.0, "batch_reward": 0.0941507026962936, "critic_loss": 8.853379264831544, "actor_loss": -47.37200524902344, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.001893997192383, "episode_reward": 22.23180785995016, "step": 27000}
{"episode": 28.0, "batch_reward": 0.09172594541683793, "critic_loss": 7.825653865814209, "actor_loss": -51.791985385894776, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.43084478378296, "episode_reward": 36.26461813194693, "step": 28000}
{"episode": 29.0, "batch_reward": 0.08955774245038628, "critic_loss": 6.821991705894471, "actor_loss": -52.84537574005127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.106308460235596, "episode_reward": 20.186085321835513, "step": 29000}
{"episode": 30.0, "batch_reward": 0.08833619740605354, "critic_loss": 6.337160860061646, "actor_loss": -58.855290325164795, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.53508138656616, "episode_reward": 43.04192214984768, "step": 30000}
{"episode": 31.0, "batch_reward": 0.08560416407883167, "critic_loss": 4.592003168582917, "actor_loss": -61.392210206985474, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.658305168151855, "episode_reward": 15.865841108326965, "step": 31000}
{"episode": 32.0, "batch_reward": 0.08437160918489099, "critic_loss": 3.8564578313827513, "actor_loss": -58.861631969451906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.22602462768555, "episode_reward": 88.96227996652617, "step": 32000}
{"episode": 33.0, "batch_reward": 0.08743911702558398, "critic_loss": 3.503725068092346, "actor_loss": -57.519712705612186, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.931440830230713, "episode_reward": 172.61148412766022, "step": 33000}
{"episode": 34.0, "batch_reward": 0.08744025763869286, "critic_loss": 2.891192586183548, "actor_loss": -58.609387098312375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.51968789100647, "episode_reward": 62.46710317744735, "step": 34000}
{"episode": 35.0, "batch_reward": 0.09131467558816075, "critic_loss": 2.473658715605736, "actor_loss": -57.091008838653565, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.694267749786377, "episode_reward": 363.0517168917201, "step": 35000}
{"episode": 36.0, "batch_reward": 0.09930670557171106, "critic_loss": 2.241126569747925, "actor_loss": -55.44879732322693, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.2674922943115, "episode_reward": 381.5657641042675, "step": 36000}
{"episode": 37.0, "batch_reward": 0.10669348488748073, "critic_loss": 2.178767842292786, "actor_loss": -57.22196339988709, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.110832691192627, "episode_reward": 414.33693945653977, "step": 37000}
{"episode": 38.0, "batch_reward": 0.1145520170852542, "critic_loss": 2.120901581645012, "actor_loss": -56.45059906387329, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.76599860191345, "episode_reward": 415.0583366507957, "step": 38000}
{"episode": 39.0, "batch_reward": 0.12172699761390686, "critic_loss": 2.0311675478219984, "actor_loss": -55.05197031402588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.984360218048096, "episode_reward": 421.23193627901736, "step": 39000}
{"episode": 40.0, "batch_reward": 0.12954939794540404, "critic_loss": 1.8647296826839448, "actor_loss": -55.21088156509399, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.54654479026794, "episode_reward": 432.99281791907697, "step": 40000}
{"episode": 41.0, "batch_reward": 0.13808201415091753, "critic_loss": 1.6217454261779785, "actor_loss": -55.93515618515015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.41589164733887, "episode_reward": 439.76024101165905, "step": 41000}
{"episode": 42.0, "batch_reward": 0.14533106373250484, "critic_loss": 1.4423663936853408, "actor_loss": -57.9631453666687, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 383.4014070034027, "episode_reward": 462.26253162632474, "step": 42000}
{"episode": 43.0, "batch_reward": 0.1537985339835286, "critic_loss": 1.380422956287861, "actor_loss": -56.68109787368775, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.926692485809326, "episode_reward": 474.93127861887257, "step": 43000}
{"episode": 44.0, "batch_reward": 0.15676676732301711, "critic_loss": 1.824634303867817, "actor_loss": -57.068697044372556, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.0144872665405, "episode_reward": 53.87363122023302, "step": 44000}
{"episode": 45.0, "batch_reward": 0.15349027764052153, "critic_loss": 2.3523181076049804, "actor_loss": -56.84820027542114, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.053558588027954, "episode_reward": 6.114664474847173, "step": 45000}
{"episode": 46.0, "batch_reward": 0.14972851041704416, "critic_loss": 2.4829043996334077, "actor_loss": -60.899936153411865, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.8521273136139, "episode_reward": 11.898322869901037, "step": 46000}
{"episode": 47.0, "batch_reward": 0.14685377146303655, "critic_loss": 2.5735845341682433, "actor_loss": -57.97938128280639, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.750811338424683, "episode_reward": 5.745566376838949, "step": 47000}
{"episode": 48.0, "batch_reward": 0.14378216502815486, "critic_loss": 2.5332206221818923, "actor_loss": -60.94033924102783, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.3350899219513, "episode_reward": 2.9786947339618624, "step": 48000}
{"episode": 49.0, "batch_reward": 0.14132621219754218, "critic_loss": 2.4332042846679687, "actor_loss": -61.30070530700684, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.972152709960938, "episode_reward": 3.707006319997319, "step": 49000}
{"episode": 50.0, "batch_reward": 0.138551020167768, "critic_loss": 2.1946059523820876, "actor_loss": -59.27618214035034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.4690647125244, "episode_reward": 2.320639625268038, "step": 50000}
{"episode": 51.0, "batch_reward": 0.13516152258217334, "critic_loss": 1.8942366145253182, "actor_loss": -63.10809260177612, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.65576219558716, "episode_reward": 1.9567185489178267, "step": 51000}
{"episode": 52.0, "batch_reward": 0.13238648391515018, "critic_loss": 1.5482645223736764, "actor_loss": -62.022063735961915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.65974140167236, "episode_reward": 8.472809435082722, "step": 52000}
{"episode": 53.0, "batch_reward": 0.1303632085546851, "critic_loss": 1.4858229765892028, "actor_loss": -57.842346035003665, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.01982831954956, "episode_reward": 9.137654031997466, "step": 53000}
{"episode": 54.0, "batch_reward": 0.12918246875703335, "critic_loss": 1.6936743718385696, "actor_loss": -61.497202632904056, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.4254701137543, "episode_reward": 18.50277999567778, "step": 54000}
{"episode": 55.0, "batch_reward": 0.12692888467758895, "critic_loss": 1.8566159707903862, "actor_loss": -59.12879635238647, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.957427978515625, "episode_reward": 10.142457947346617, "step": 55000}
{"episode": 56.0, "batch_reward": 0.12455144191533327, "critic_loss": 1.5541182872653008, "actor_loss": -60.95828694152832, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.56131958961487, "episode_reward": 1.8697997261862656, "step": 56000}
{"episode": 57.0, "batch_reward": 0.12266887775808573, "critic_loss": 1.1623387661576272, "actor_loss": -62.81822719955444, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.037126541137695, "episode_reward": 1.5395251619102361, "step": 57000}
{"episode": 58.0, "batch_reward": 0.11927111221849919, "critic_loss": 0.8416092812120914, "actor_loss": -58.336608406066894, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.39055371284485, "episode_reward": 11.945765171698998, "step": 58000}
{"episode": 59.0, "batch_reward": 0.11773099484294652, "critic_loss": 0.7314051298499107, "actor_loss": -55.10010509872436, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.04382586479187, "episode_reward": 10.846322760822108, "step": 59000}
{"episode": 60.0, "batch_reward": 0.11679869832098484, "critic_loss": 0.6585545853674412, "actor_loss": -56.95019773483276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.275465965271, "episode_reward": 7.792954111337619, "step": 60000}
{"episode": 61.0, "batch_reward": 0.11491332805156708, "critic_loss": 0.5671777255237103, "actor_loss": -56.67812072753906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.578354597091675, "episode_reward": 11.146203552678006, "step": 61000}
{"episode": 62.0, "batch_reward": 0.11346600730717182, "critic_loss": 0.49887372279167175, "actor_loss": -52.86647702026367, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.98209261894226, "episode_reward": 7.917537433545969, "step": 62000}
{"episode": 63.0, "batch_reward": 0.11117689462006092, "critic_loss": 0.39625070014595987, "actor_loss": -54.64365883636474, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.968313217163086, "episode_reward": 9.320366001466523, "step": 63000}
{"episode": 64.0, "batch_reward": 0.11038641312718392, "critic_loss": 0.32811868995428084, "actor_loss": -52.18834150314331, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.40287828445435, "episode_reward": 8.466021771539287, "step": 64000}
{"episode": 65.0, "batch_reward": 0.10707584332302213, "critic_loss": 0.26000371722877025, "actor_loss": -49.48006258773804, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.972140550613403, "episode_reward": 8.237445191231247, "step": 65000}
{"episode": 66.0, "batch_reward": 0.10554537016153336, "critic_loss": 0.22061163029819728, "actor_loss": -48.74118089675903, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.21826124191284, "episode_reward": 13.073725856641987, "step": 66000}
{"episode": 67.0, "batch_reward": 0.1063371456488967, "critic_loss": 0.1863073257431388, "actor_loss": -45.88453718566895, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.624669790267944, "episode_reward": 89.85514088727597, "step": 67000}
{"episode": 68.0, "batch_reward": 0.10772619941085577, "critic_loss": 0.15225733755528928, "actor_loss": -46.092051189422605, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.32394647598267, "episode_reward": 366.43388423787417, "step": 68000}
{"episode": 69.0, "batch_reward": 0.11109847676753998, "critic_loss": 0.13353957383334636, "actor_loss": -43.15966872406006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.014002084732056, "episode_reward": 341.02399511552653, "step": 69000}
{"episode": 70.0, "batch_reward": 0.1137901187799871, "critic_loss": 0.12197053341567517, "actor_loss": -42.38029513168335, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.20163440704346, "episode_reward": 283.8292094962237, "step": 70000}
{"episode": 71.0, "batch_reward": 0.1156689099892974, "critic_loss": 0.12174956093356014, "actor_loss": -40.71434545135498, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.61325144767761, "episode_reward": 78.88179101836944, "step": 71000}
{"episode": 72.0, "batch_reward": 0.11675780814141035, "critic_loss": 0.10667559853196144, "actor_loss": -40.61340701675415, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.39509773254395, "episode_reward": 417.4806391223176, "step": 72000}
{"episode": 73.0, "batch_reward": 0.12039473617076873, "critic_loss": 0.10909223106130958, "actor_loss": -38.12637029647827, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.964911937713623, "episode_reward": 254.4080475734191, "step": 73000}
{"episode": 74.0, "batch_reward": 0.12235422646254301, "critic_loss": 0.11198208328336477, "actor_loss": -38.65525150680542, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.6269464492798, "episode_reward": 421.0309133804531, "step": 74000}
{"episode": 75.0, "batch_reward": 0.12750188461691142, "critic_loss": 0.10571078399196267, "actor_loss": -37.06277017974853, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.969255685806274, "episode_reward": 429.3611309540581, "step": 75000}
{"episode": 76.0, "batch_reward": 0.12980771094560623, "critic_loss": 0.11434617897495628, "actor_loss": -36.37956734085083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.5537009239197, "episode_reward": 400.9102913641036, "step": 76000}
{"episode": 77.0, "batch_reward": 0.1344956829547882, "critic_loss": 0.1221298508644104, "actor_loss": -35.17280144882202, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.977999925613403, "episode_reward": 298.5145943519957, "step": 77000}
{"episode": 78.0, "batch_reward": 0.13802066537737848, "critic_loss": 0.12961064739897848, "actor_loss": -34.58285428619385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.4158766269684, "episode_reward": 477.0368415366745, "step": 78000}
{"episode": 79.0, "batch_reward": 0.1406966460570693, "critic_loss": 0.13844831437245012, "actor_loss": -33.6518330116272, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.69415283203125, "episode_reward": 478.7033631627646, "step": 79000}
{"episode": 80.0, "batch_reward": 0.1456807444691658, "critic_loss": 0.15331542411446572, "actor_loss": -33.80166064453125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.79190158843994, "episode_reward": 478.88138812095775, "step": 80000}
{"episode": 81.0, "batch_reward": 0.14849722841382026, "critic_loss": 0.16441168750077487, "actor_loss": -33.08956025695801, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.63871645927429, "episode_reward": 441.5363042901058, "step": 81000}
{"episode": 82.0, "batch_reward": 0.1527487890943885, "critic_loss": 0.17361155879497528, "actor_loss": -32.626834854125974, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.76132678985596, "episode_reward": 440.4545149174844, "step": 82000}
{"episode": 83.0, "batch_reward": 0.15641097040474414, "critic_loss": 0.19009099646657707, "actor_loss": -32.44268868255615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.94483757019043, "episode_reward": 430.4400530440689, "step": 83000}
{"episode": 84.0, "batch_reward": 0.15894413915276528, "critic_loss": 0.19891544030606748, "actor_loss": -31.82936172103882, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.8183877468109, "episode_reward": 469.22369402773217, "step": 84000}
{"episode": 85.0, "batch_reward": 0.16372022379934786, "critic_loss": 0.20427959978580476, "actor_loss": -31.859203575134277, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.750368356704712, "episode_reward": 492.2180956453237, "step": 85000}
{"episode": 86.0, "batch_reward": 0.16699304898828268, "critic_loss": 0.20622726218402385, "actor_loss": -31.47541131591797, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.66055059432983, "episode_reward": 436.404506179014, "step": 86000}
{"episode": 87.0, "batch_reward": 0.16954788179695607, "critic_loss": 0.20238302962481974, "actor_loss": -31.61141093444824, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.6612229347229, "episode_reward": 472.2488528208867, "step": 87000}
{"episode": 88.0, "batch_reward": 0.17383657785505055, "critic_loss": 0.19882069052755832, "actor_loss": -31.314357707977294, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.46773195266724, "episode_reward": 436.74138575565905, "step": 88000}
{"episode": 89.0, "batch_reward": 0.17591752753406764, "critic_loss": 0.1896997335553169, "actor_loss": -31.259663970947265, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.961809396743774, "episode_reward": 452.93990205597237, "step": 89000}
{"episode": 90.0, "batch_reward": 0.18124356964230537, "critic_loss": 0.19320509304106234, "actor_loss": -31.54215975189209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.6626899242401, "episode_reward": 463.12894894169204, "step": 90000}
{"episode": 91.0, "batch_reward": 0.18214339239895344, "critic_loss": 0.18438882411271335, "actor_loss": -31.250083255767823, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.354878425598145, "episode_reward": 462.87229992711866, "step": 91000}
{"episode": 92.0, "batch_reward": 0.18597867321968078, "critic_loss": 0.18473637091368436, "actor_loss": -31.389659217834474, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 383.8436563014984, "episode_reward": 459.7745888320418, "step": 92000}
{"episode": 93.0, "batch_reward": 0.18911324612796307, "critic_loss": 0.18269327014684678, "actor_loss": -31.444177398681642, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.970699310302734, "episode_reward": 470.84490716504655, "step": 93000}
{"episode": 94.0, "batch_reward": 0.19132881958782672, "critic_loss": 0.16958431094884874, "actor_loss": -31.3752984085083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.0021297931671, "episode_reward": 444.5155279027671, "step": 94000}
{"episode": 95.0, "batch_reward": 0.1954888231009245, "critic_loss": 0.16934844293445347, "actor_loss": -31.297614597320557, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.996715307235718, "episode_reward": 443.8864030601105, "step": 95000}
{"episode": 96.0, "batch_reward": 0.19779064084589482, "critic_loss": 0.17211669048666953, "actor_loss": -31.247898750305175, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 389.86343812942505, "episode_reward": 440.56825158317923, "step": 96000}
{"episode": 97.0, "batch_reward": 0.2005024119913578, "critic_loss": 0.16292449795454741, "actor_loss": -31.192586643218995, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.671222448349, "episode_reward": 422.980988144302, "step": 97000}
{"episode": 98.0, "batch_reward": 0.20177348966896533, "critic_loss": 0.15851048897206782, "actor_loss": -31.107399753570558, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.36604833602905, "episode_reward": 476.87323994879796, "step": 98000}
{"episode": 99.0, "batch_reward": 0.20375302033126355, "critic_loss": 0.16342488671839236, "actor_loss": -31.094719635009767, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.06299591064453, "episode_reward": 454.80415672539783, "step": 99000}
{"episode": 100.0, "batch_reward": 0.2067186362296343, "critic_loss": 0.15445215015858413, "actor_loss": -31.18894033432007, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.11822175979614, "episode_reward": 459.9219072862517, "step": 100000}
{"episode": 101.0, "batch_reward": 0.21038457922637463, "critic_loss": 0.14929860232025385, "actor_loss": -31.442254875183107, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.73320531845093, "episode_reward": 450.1450459256877, "step": 101000}
{"episode": 102.0, "batch_reward": 0.21229841324687004, "critic_loss": 0.1571610917299986, "actor_loss": -31.587285095214845, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.35733366012573, "episode_reward": 419.76318245681716, "step": 102000}
{"episode": 103.0, "batch_reward": 0.21512490266561507, "critic_loss": 0.15501555931568145, "actor_loss": -31.503445331573488, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.012067317962646, "episode_reward": 423.80132927728255, "step": 103000}
{"episode": 104.0, "batch_reward": 0.2164854625314474, "critic_loss": 0.15121745523065327, "actor_loss": -31.2644404296875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.56976532936096, "episode_reward": 456.6012827521331, "step": 104000}
{"episode": 105.0, "batch_reward": 0.2188231190741062, "critic_loss": 0.15149771810323, "actor_loss": -31.346047050476074, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.981121063232422, "episode_reward": 443.6430970156117, "step": 105000}
{"episode": 106.0, "batch_reward": 0.22070212644338608, "critic_loss": 0.14594833593815565, "actor_loss": -30.99816386413574, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.5497419834137, "episode_reward": 411.74471553813856, "step": 106000}
{"episode": 107.0, "batch_reward": 0.22284699459373952, "critic_loss": 0.14841333712637425, "actor_loss": -31.078845111846924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.980414867401123, "episode_reward": 426.34797714480425, "step": 107000}
{"episode": 108.0, "batch_reward": 0.22364678698778154, "critic_loss": 0.1493653085529804, "actor_loss": -31.114504905700684, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.6074221134186, "episode_reward": 437.61588249143676, "step": 108000}
{"episode": 109.0, "batch_reward": 0.2267145107239485, "critic_loss": 0.15473413365334274, "actor_loss": -31.167844184875488, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.912861585617065, "episode_reward": 440.0968900145984, "step": 109000}
{"episode": 110.0, "batch_reward": 0.2289734222739935, "critic_loss": 0.15264655914902686, "actor_loss": -31.39586696624756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.16704392433167, "episode_reward": 359.7726070828834, "step": 110000}
{"episode": 111.0, "batch_reward": 0.22955643272399903, "critic_loss": 0.14837078401446344, "actor_loss": -31.142948848724366, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.47472834587097, "episode_reward": 433.4822168389014, "step": 111000}
{"episode": 112.0, "batch_reward": 0.23085703633725643, "critic_loss": 0.156595503680408, "actor_loss": -31.148733814239502, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.8234989643097, "episode_reward": 433.1871979697819, "step": 112000}
{"episode": 113.0, "batch_reward": 0.2334352589249611, "critic_loss": 0.15497227378934622, "actor_loss": -31.133370723724365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.07033395767212, "episode_reward": 446.1708384173048, "step": 113000}
{"episode": 114.0, "batch_reward": 0.2360881596803665, "critic_loss": 0.1618213695064187, "actor_loss": -31.007370777130127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.8131031990051, "episode_reward": 461.1624692657848, "step": 114000}
{"episode": 115.0, "batch_reward": 0.23673701520264148, "critic_loss": 0.1579537242874503, "actor_loss": -31.063192462921144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.999477863311768, "episode_reward": 473.59474393376513, "step": 115000}
{"episode": 116.0, "batch_reward": 0.23979482388496398, "critic_loss": 0.1498443084396422, "actor_loss": -30.91471395111084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.86164808273315, "episode_reward": 484.4316471115439, "step": 116000}
{"episode": 117.0, "batch_reward": 0.24148874156177044, "critic_loss": 0.15210648399963975, "actor_loss": -30.921757759094238, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.75101900100708, "episode_reward": 496.07199974208584, "step": 117000}
{"episode": 118.0, "batch_reward": 0.24331177428364753, "critic_loss": 0.15643862003833056, "actor_loss": -30.95482427597046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.6695387363434, "episode_reward": 444.5796229004856, "step": 118000}
{"episode": 119.0, "batch_reward": 0.2445529562830925, "critic_loss": 0.15778977504372596, "actor_loss": -30.9286325340271, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.98616361618042, "episode_reward": 448.15948465567163, "step": 119000}
{"episode": 120.0, "batch_reward": 0.24711123959720135, "critic_loss": 0.15296777117997407, "actor_loss": -31.098382698059083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.0289785861969, "episode_reward": 460.97811665087954, "step": 120000}
{"episode": 121.0, "batch_reward": 0.24888957853615284, "critic_loss": 0.15725012896209956, "actor_loss": -31.2320594291687, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.32377314567566, "episode_reward": 416.81905330151324, "step": 121000}
{"episode": 122.0, "batch_reward": 0.24926641350984574, "critic_loss": 0.15584324078261852, "actor_loss": -31.113264820098877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.46302556991577, "episode_reward": 346.62518313549515, "step": 122000}
{"episode": 123.0, "batch_reward": 0.2515814025551081, "critic_loss": 0.16952879735827445, "actor_loss": -31.18584462738037, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.868085384368896, "episode_reward": 424.2885665559291, "step": 123000}
{"episode": 124.0, "batch_reward": 0.25206569373607635, "critic_loss": 0.16126052934676408, "actor_loss": -31.022973976135255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.3167939186096, "episode_reward": 429.38913724066816, "step": 124000}
{"episode": 125.0, "batch_reward": 0.2527111033499241, "critic_loss": 0.15987624277174473, "actor_loss": -30.890107666015624, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.050072193145752, "episode_reward": 462.60726736702617, "step": 125000}
{"episode": 126.0, "batch_reward": 0.2557778754234314, "critic_loss": 0.15467032719403506, "actor_loss": -31.097120864868163, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.51518273353577, "episode_reward": 458.18778973342455, "step": 126000}
{"episode": 127.0, "batch_reward": 0.256152565613389, "critic_loss": 0.15955223651230335, "actor_loss": -31.0987590675354, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.03369641304016, "episode_reward": 436.52718702703737, "step": 127000}
{"episode": 128.0, "batch_reward": 0.258624257594347, "critic_loss": 0.1623504444770515, "actor_loss": -30.910249965667724, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.7082953453064, "episode_reward": 450.0562630530157, "step": 128000}
{"episode": 129.0, "batch_reward": 0.2605500314384699, "critic_loss": 0.163123023070395, "actor_loss": -31.098788955688477, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.094476222991943, "episode_reward": 452.03765175020123, "step": 129000}
{"episode": 130.0, "batch_reward": 0.260135185316205, "critic_loss": 0.16293187448382376, "actor_loss": -31.053529933929443, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.70008850097656, "episode_reward": 420.3123058183757, "step": 130000}
{"episode": 131.0, "batch_reward": 0.26336261904239655, "critic_loss": 0.16225779363512993, "actor_loss": -31.335121871948243, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.58788990974426, "episode_reward": 253.34702158179982, "step": 131000}
{"episode": 132.0, "batch_reward": 0.26103620529174804, "critic_loss": 0.15966819848120212, "actor_loss": -30.936608612060546, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.21296548843384, "episode_reward": 407.0508742440132, "step": 132000}
{"episode": 133.0, "batch_reward": 0.26385165774822233, "critic_loss": 0.16723083128035068, "actor_loss": -31.190426929473876, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.749602794647217, "episode_reward": 424.7528915834831, "step": 133000}
{"episode": 134.0, "batch_reward": 0.2641202670931816, "critic_loss": 0.1872450131699443, "actor_loss": -30.829457664489745, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.7988107204437, "episode_reward": 441.1673844203517, "step": 134000}
{"episode": 135.0, "batch_reward": 0.26598085004091265, "critic_loss": 0.18685790344327688, "actor_loss": -30.97364507675171, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.80716848373413, "episode_reward": 423.15688230064956, "step": 135000}
{"episode": 136.0, "batch_reward": 0.2670727438777685, "critic_loss": 0.16384497495740652, "actor_loss": -31.13332568359375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.28219842910767, "episode_reward": 394.4464277088479, "step": 136000}
{"episode": 137.0, "batch_reward": 0.26737194545567033, "critic_loss": 0.15873071049898863, "actor_loss": -30.865006145477295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.007314205169678, "episode_reward": 400.2207862946606, "step": 137000}
{"episode": 138.0, "batch_reward": 0.2691170021742582, "critic_loss": 0.14796180633455516, "actor_loss": -31.056245811462404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 391.17053174972534, "episode_reward": 406.66096235917286, "step": 138000}
{"episode": 139.0, "batch_reward": 0.26930368566513063, "critic_loss": 0.1487485278919339, "actor_loss": -30.91677053451538, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.815061807632446, "episode_reward": 422.0095880651896, "step": 139000}
{"episode": 140.0, "batch_reward": 0.27202517250180247, "critic_loss": 0.1507571950890124, "actor_loss": -31.065972339630125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.9443988800049, "episode_reward": 440.10516786942077, "step": 140000}
{"episode": 141.0, "batch_reward": 0.2729369110763073, "critic_loss": 0.15344534801319243, "actor_loss": -31.076386947631836, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.30684208869934, "episode_reward": 473.43083651103126, "step": 141000}
{"episode": 142.0, "batch_reward": 0.2730810239613056, "critic_loss": 0.15296853560954332, "actor_loss": -30.921550380706787, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 383.4907567501068, "episode_reward": 432.70093680679304, "step": 142000}
{"episode": 143.0, "batch_reward": 0.2745409636646509, "critic_loss": 0.1386944528631866, "actor_loss": -31.329894775390624, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.084718704223633, "episode_reward": 444.2007575602643, "step": 143000}
{"episode": 144.0, "batch_reward": 0.27686186008155345, "critic_loss": 0.14767214303836226, "actor_loss": -31.459368766784667, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 389.2369680404663, "episode_reward": 468.4269935549653, "step": 144000}
{"episode": 145.0, "batch_reward": 0.277997696980834, "critic_loss": 0.13575205456465483, "actor_loss": -31.608403705596924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.082834482192993, "episode_reward": 484.1081698787407, "step": 145000}
{"episode": 146.0, "batch_reward": 0.2796828484982252, "critic_loss": 0.14280417672917248, "actor_loss": -31.80710302734375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.1248109340668, "episode_reward": 469.486313770368, "step": 146000}
{"episode": 147.0, "batch_reward": 0.2799465969204903, "critic_loss": 0.15154683636128902, "actor_loss": -31.712249481201173, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.936991691589355, "episode_reward": 485.94062651033073, "step": 147000}
{"episode": 148.0, "batch_reward": 0.281505008533597, "critic_loss": 0.1467087624594569, "actor_loss": -32.0538815574646, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 390.34267020225525, "episode_reward": 447.29697210609936, "step": 148000}
{"episode": 149.0, "batch_reward": 0.28085065641999246, "critic_loss": 0.14710020553693176, "actor_loss": -31.77649199295044, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.028518676757812, "episode_reward": 489.86763398671087, "step": 149000}
{"episode": 150.0, "batch_reward": 0.28310138058662415, "critic_loss": 0.14275166545808315, "actor_loss": -32.13548820114136, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
