{"episode_reward": 0.0, "episode": 1.0, "duration": 18.091205596923828, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.505763053894043, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.23005255902258703, "critic_loss": 0.23622467854781007, "actor_loss": -45.79922125710636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.30383539199829, "step": 3000}
{"episode_reward": 239.7431509658522, "episode": 4.0, "batch_reward": 0.23312821073830128, "critic_loss": 0.36315079128742217, "actor_loss": -44.52889412689209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.843088388442993, "step": 4000}
{"episode_reward": 250.8503259646263, "episode": 5.0, "batch_reward": 0.25079048457741737, "critic_loss": 0.4905653713196516, "actor_loss": -44.53918674468994, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.360047101974487, "step": 5000}
{"episode_reward": 391.75838177515976, "episode": 6.0, "batch_reward": 0.2692654440253973, "critic_loss": 0.5079418267011643, "actor_loss": -44.5823139038086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.064029216766357, "step": 6000}
{"episode_reward": 200.6043590021668, "episode": 7.0, "batch_reward": 0.26720999835431575, "critic_loss": 0.5459204067289829, "actor_loss": -42.72309706878662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.535332918167114, "step": 7000}
{"episode_reward": 405.69075957204484, "episode": 8.0, "batch_reward": 0.26889492774009705, "critic_loss": 0.6311402076780797, "actor_loss": -41.85522467041016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.172049045562744, "step": 8000}
{"episode_reward": 80.26848104621078, "episode": 9.0, "batch_reward": 0.2586517002284527, "critic_loss": 0.631585551917553, "actor_loss": -40.15135019683838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1088445186615, "step": 9000}
{"episode_reward": 386.1498981807198, "episode": 10.0, "batch_reward": 0.27558365112543104, "critic_loss": 0.663436761111021, "actor_loss": -41.17227349090576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.7333722114563, "step": 10000}
{"episode_reward": 407.1279585659455, "episode": 11.0, "batch_reward": 0.2757992399483919, "critic_loss": 0.6586972928345204, "actor_loss": -40.67905556488037, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.59774398803711, "step": 11000}
{"episode_reward": 82.70047883409474, "episode": 12.0, "batch_reward": 0.2684514827132225, "critic_loss": 0.6313904255628586, "actor_loss": -39.31632822036743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.78458571434021, "step": 12000}
{"episode_reward": 424.393431549994, "episode": 13.0, "batch_reward": 0.28458077266812326, "critic_loss": 0.6349439305067063, "actor_loss": -40.40456728744507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.64875030517578, "step": 13000}
{"episode_reward": 492.31328329249027, "episode": 14.0, "batch_reward": 0.29895669835805894, "critic_loss": 0.645191516250372, "actor_loss": -41.106132778167726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.923582553863525, "step": 14000}
{"episode_reward": 455.28257927211297, "episode": 15.0, "batch_reward": 0.3090166917145252, "critic_loss": 0.6345118913054466, "actor_loss": -42.48381055831909, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.278456449508667, "step": 15000}
{"episode_reward": 446.1053919436109, "episode": 16.0, "batch_reward": 0.3162304531931877, "critic_loss": 0.6317875580191612, "actor_loss": -42.46625882720947, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.408169746398926, "step": 16000}
{"episode_reward": 258.71346255927466, "episode": 17.0, "batch_reward": 0.31685760426521303, "critic_loss": 0.5661373763680458, "actor_loss": -41.95602055740356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.736634492874146, "step": 17000}
{"episode_reward": 503.11629781526324, "episode": 18.0, "batch_reward": 0.3274165545701981, "critic_loss": 0.55011413449049, "actor_loss": -42.66700872039795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24154543876648, "step": 18000}
{"episode_reward": 508.31289820572607, "episode": 19.0, "batch_reward": 0.337307425737381, "critic_loss": 0.500202661961317, "actor_loss": -43.25730972290039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.563913583755493, "step": 19000}
{"episode_reward": 516.7286872983076, "episode": 20.0, "batch_reward": 0.3452606045603752, "critic_loss": 0.4726255888491869, "actor_loss": -44.03863486480713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.350902318954468, "step": 20000}
{"episode_reward": 482.5833859987039, "episode": 21.0, "batch_reward": 0.3523543200492859, "critic_loss": 0.4449053309261799, "actor_loss": -44.560769958496095, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.17772555351257, "step": 21000}
{"episode_reward": 481.0028889129332, "episode": 22.0, "batch_reward": 0.35976909586787226, "critic_loss": 0.4115650532990694, "actor_loss": -44.83936367797852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.903482913970947, "step": 22000}
{"episode_reward": 521.1480341953297, "episode": 23.0, "batch_reward": 0.36571438428759573, "critic_loss": 0.383011878490448, "actor_loss": -45.488156951904294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.245375871658325, "step": 23000}
{"episode_reward": 471.8219752685456, "episode": 24.0, "batch_reward": 0.3698996766805649, "critic_loss": 0.3972675478309393, "actor_loss": -45.65787209320068, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.721747159957886, "step": 24000}
{"episode_reward": 500.3817855758553, "episode": 25.0, "batch_reward": 0.37537159338593484, "critic_loss": 0.4019166729301214, "actor_loss": -45.6394221572876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3790283203125, "step": 25000}
{"episode_reward": 485.358893789084, "episode": 26.0, "batch_reward": 0.37769155290722844, "critic_loss": 0.4257982040643692, "actor_loss": -45.87711932373047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.74502921104431, "step": 26000}
{"episode_reward": 444.9135824357132, "episode": 27.0, "batch_reward": 0.3817663843333721, "critic_loss": 0.43000457787513735, "actor_loss": -46.37961073303223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.9308500289917, "step": 27000}
{"episode_reward": 430.9789225276255, "episode": 28.0, "batch_reward": 0.38518399354815486, "critic_loss": 0.4548692902326584, "actor_loss": -46.21222164916992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.235846042633057, "step": 28000}
{"episode_reward": 481.90447307691653, "episode": 29.0, "batch_reward": 0.38685608887672424, "critic_loss": 0.47283393567800525, "actor_loss": -46.778713668823244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.6122088432312, "step": 29000}
{"episode_reward": 405.9368698018409, "episode": 30.0, "batch_reward": 0.38866419160366056, "critic_loss": 0.4638631257116795, "actor_loss": -46.52814801025391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27610969543457, "step": 30000}
{"episode_reward": 488.539927418492, "episode": 31.0, "batch_reward": 0.3923895827829838, "critic_loss": 0.4570694722235203, "actor_loss": -47.14667834472656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.80720281600952, "step": 31000}
{"episode_reward": 494.8699941996001, "episode": 32.0, "batch_reward": 0.39043804159760476, "critic_loss": 0.48729524844884875, "actor_loss": -46.648396034240726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.230058431625366, "step": 32000}
{"episode_reward": 95.75430583379158, "episode": 33.0, "batch_reward": 0.38691861417889595, "critic_loss": 0.4585156704187393, "actor_loss": -46.57799548339844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.057714223861694, "step": 33000}
{"episode_reward": 518.4295000157092, "episode": 34.0, "batch_reward": 0.389525474011898, "critic_loss": 0.4879757679402828, "actor_loss": -46.30793228149414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.387534141540527, "step": 34000}
{"episode_reward": 481.300636518717, "episode": 35.0, "batch_reward": 0.39254981392621996, "critic_loss": 0.49308372774720194, "actor_loss": -46.927261680603024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.63220238685608, "step": 35000}
{"episode_reward": 516.7459085648017, "episode": 36.0, "batch_reward": 0.39535976940393447, "critic_loss": 0.4651812770366669, "actor_loss": -46.43299136352539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.348328351974487, "step": 36000}
{"episode_reward": 522.2223820059742, "episode": 37.0, "batch_reward": 0.3932184894979, "critic_loss": 0.44075727804005144, "actor_loss": -46.73052584075928, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.559975147247314, "step": 37000}
{"episode_reward": 62.801714727602985, "episode": 38.0, "batch_reward": 0.38963115495443346, "critic_loss": 0.4327740625143051, "actor_loss": -46.431131843566895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.47292447090149, "step": 38000}
{"episode_reward": 487.6062465110195, "episode": 39.0, "batch_reward": 0.39298528915643693, "critic_loss": 0.4096443880200386, "actor_loss": -46.87571475219727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.162302017211914, "step": 39000}
{"episode_reward": 501.0447384510764, "episode": 40.0, "batch_reward": 0.39529075345396997, "critic_loss": 0.4218709598481655, "actor_loss": -47.11340139007569, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.74947714805603, "step": 40000}
{"episode_reward": 498.6287383576786, "episode": 41.0, "batch_reward": 0.39890386229753494, "critic_loss": 0.43312482331693175, "actor_loss": -47.18358703613281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.12817859649658, "step": 41000}
{"episode_reward": 494.7629807327313, "episode": 42.0, "batch_reward": 0.4010596354901791, "critic_loss": 0.41127959637343886, "actor_loss": -46.89981356048584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.481040954589844, "step": 42000}
{"episode_reward": 525.5523227032519, "episode": 43.0, "batch_reward": 0.40398283356428144, "critic_loss": 0.4101222267895937, "actor_loss": -47.23683561706543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.85680055618286, "step": 43000}
{"episode_reward": 517.8777471270466, "episode": 44.0, "batch_reward": 0.4038963268399239, "critic_loss": 0.43412682648003104, "actor_loss": -47.086151573181155, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2266845703125, "step": 44000}
{"episode_reward": 154.17667678870689, "episode": 45.0, "batch_reward": 0.3994079951345921, "critic_loss": 0.4096570979654789, "actor_loss": -46.86562403106689, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.753108739852905, "step": 45000}
{"episode_reward": 320.76370386839096, "episode": 46.0, "batch_reward": 0.3958763254284859, "critic_loss": 0.4331368548721075, "actor_loss": -46.3963162612915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.541173934936523, "step": 46000}
{"episode_reward": 162.31535561009107, "episode": 47.0, "batch_reward": 0.39396459427475927, "critic_loss": 0.4443136995136738, "actor_loss": -46.35638535308838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.37160634994507, "step": 47000}
{"episode_reward": 514.8878544518392, "episode": 48.0, "batch_reward": 0.3957279336154461, "critic_loss": 0.42772252014279366, "actor_loss": -45.928102981567385, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.103928804397583, "step": 48000}
{"episode_reward": 495.5473463931026, "episode": 49.0, "batch_reward": 0.39930025267601016, "critic_loss": 0.4725031497478485, "actor_loss": -46.897601737976075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.870835065841675, "step": 49000}
{"episode_reward": 530.537290175914, "episode": 50.0, "batch_reward": 0.40062118580937384, "critic_loss": 0.4270210017710924, "actor_loss": -46.948227035522464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.174307346343994, "step": 50000}
{"episode_reward": 518.2929564266508, "episode": 51.0, "batch_reward": 0.4032869966030121, "critic_loss": 0.426866542622447, "actor_loss": -47.154552856445314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.91535568237305, "step": 51000}
{"episode_reward": 492.4976598421062, "episode": 52.0, "batch_reward": 0.4046996618807316, "critic_loss": 0.4258311311006546, "actor_loss": -47.32359275817871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.22455334663391, "step": 52000}
{"episode_reward": 488.5125163362027, "episode": 53.0, "batch_reward": 0.4069529435634613, "critic_loss": 0.4421795596331358, "actor_loss": -47.371989418029784, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.534820556640625, "step": 53000}
{"episode_reward": 491.42155907509044, "episode": 54.0, "batch_reward": 0.4076689339876175, "critic_loss": 0.4260161115974188, "actor_loss": -47.520187057495114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.089534759521484, "step": 54000}
{"episode_reward": 494.6408737004212, "episode": 55.0, "batch_reward": 0.40924271976947785, "critic_loss": 0.41766850782930853, "actor_loss": -47.693409912109374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.909260511398315, "step": 55000}
{"episode_reward": 478.62733134776175, "episode": 56.0, "batch_reward": 0.410983309596777, "critic_loss": 0.40520431722700595, "actor_loss": -47.96115559387207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.2394700050354, "step": 56000}
{"episode_reward": 492.50136837678787, "episode": 57.0, "batch_reward": 0.4128298544883728, "critic_loss": 0.41302904130518436, "actor_loss": -47.974798622131345, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.780229330062866, "step": 57000}
{"episode_reward": 518.2785931353978, "episode": 58.0, "batch_reward": 0.4141938123703003, "critic_loss": 0.44367289984226227, "actor_loss": -47.798158210754394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.064175128936768, "step": 58000}
{"episode_reward": 367.40379638716524, "episode": 59.0, "batch_reward": 0.41342570784688, "critic_loss": 0.4628276698887348, "actor_loss": -47.73327749633789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.03909659385681, "step": 59000}
{"episode_reward": 520.7887306447099, "episode": 60.0, "batch_reward": 0.4148954389691353, "critic_loss": 0.4283217931985855, "actor_loss": -48.08001531982422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.8780357837677, "step": 60000}
{"episode_reward": 509.11768278080746, "episode": 61.0, "batch_reward": 0.4171749306023121, "critic_loss": 0.4101961015611887, "actor_loss": -48.175208267211914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.48820662498474, "step": 61000}
{"episode_reward": 526.1867414449671, "episode": 62.0, "batch_reward": 0.41838547638058665, "critic_loss": 0.41654878182709215, "actor_loss": -48.543474632263184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.589040279388428, "step": 62000}
{"episode_reward": 495.0484506223242, "episode": 63.0, "batch_reward": 0.4193929328918457, "critic_loss": 0.3876492564678192, "actor_loss": -48.30218416595459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.217009782791138, "step": 63000}
{"episode_reward": 518.879968063914, "episode": 64.0, "batch_reward": 0.42084933334589003, "critic_loss": 0.4214661200493574, "actor_loss": -48.64281072998047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.610650300979614, "step": 64000}
{"episode_reward": 515.2418361633779, "episode": 65.0, "batch_reward": 0.4236922035515308, "critic_loss": 0.40490613758564, "actor_loss": -48.8423380203247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.663652420043945, "step": 65000}
{"episode_reward": 495.9058189200143, "episode": 66.0, "batch_reward": 0.42415505355596544, "critic_loss": 0.41707097986340524, "actor_loss": -48.90164607238769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.625404596328735, "step": 66000}
{"episode_reward": 521.3598390847432, "episode": 67.0, "batch_reward": 0.4245864714682102, "critic_loss": 0.42339516089856627, "actor_loss": -49.04946295166015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.116822481155396, "step": 67000}
{"episode_reward": 485.17273699481393, "episode": 68.0, "batch_reward": 0.4262186773121357, "critic_loss": 0.3816149839758873, "actor_loss": -48.674819328308104, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.298415422439575, "step": 68000}
{"episode_reward": 544.7014982448312, "episode": 69.0, "batch_reward": 0.4282196342349052, "critic_loss": 0.3941210930198431, "actor_loss": -48.93523641204834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.463245153427124, "step": 69000}
{"episode_reward": 517.0666821015595, "episode": 70.0, "batch_reward": 0.4299679021537304, "critic_loss": 0.39565939800441263, "actor_loss": -49.531373359680174, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.252235174179077, "step": 70000}
{"episode_reward": 534.1283789611819, "episode": 71.0, "batch_reward": 0.4306484082043171, "critic_loss": 0.40613751009106636, "actor_loss": -49.425411987304685, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.56755805015564, "step": 71000}
{"episode_reward": 516.2556272448177, "episode": 72.0, "batch_reward": 0.432171981960535, "critic_loss": 0.40642963296175005, "actor_loss": -49.4386537399292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.6209614276886, "step": 72000}
{"episode_reward": 533.4762845527705, "episode": 73.0, "batch_reward": 0.4334514513909817, "critic_loss": 0.4048472173959017, "actor_loss": -49.605881813049315, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.99825358390808, "step": 73000}
{"episode_reward": 516.4406843399806, "episode": 74.0, "batch_reward": 0.4353183697462082, "critic_loss": 0.4183275662660599, "actor_loss": -49.87618141174316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.225154399871826, "step": 74000}
{"episode_reward": 492.13297256221836, "episode": 75.0, "batch_reward": 0.4357965303361416, "critic_loss": 0.4326383913308382, "actor_loss": -50.049355995178225, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.426501274108887, "step": 75000}
{"episode_reward": 521.6982780641897, "episode": 76.0, "batch_reward": 0.437225290030241, "critic_loss": 0.42454009534418585, "actor_loss": -50.2262717666626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.790668725967407, "step": 76000}
{"episode_reward": 524.3242319618721, "episode": 77.0, "batch_reward": 0.4367000458240509, "critic_loss": 0.41049137510359285, "actor_loss": -49.826319442749025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.331586122512817, "step": 77000}
{"episode_reward": 459.89617166173764, "episode": 78.0, "batch_reward": 0.43761831963062287, "critic_loss": 0.4103134193867445, "actor_loss": -50.04507332611084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.023605585098267, "step": 78000}
{"episode_reward": 493.3175138995335, "episode": 79.0, "batch_reward": 0.4390450402200222, "critic_loss": 0.39897033163905143, "actor_loss": -49.77781655883789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.68089199066162, "step": 79000}
{"episode_reward": 515.5250751068197, "episode": 80.0, "batch_reward": 0.4391923391222954, "critic_loss": 0.40985320645570755, "actor_loss": -50.03846364593506, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.55393147468567, "step": 80000}
{"episode_reward": 535.9068315171845, "episode": 81.0, "batch_reward": 0.440964476197958, "critic_loss": 0.4038049466907978, "actor_loss": -50.34570597839355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.045950412750244, "step": 81000}
{"episode_reward": 519.6321657152674, "episode": 82.0, "batch_reward": 0.44286307656764984, "critic_loss": 0.4147992446124554, "actor_loss": -50.79862226867676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.457974672317505, "step": 82000}
{"episode_reward": 530.9019351476336, "episode": 83.0, "batch_reward": 0.4425490471124649, "critic_loss": 0.3870512571334839, "actor_loss": -50.06536781311035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.77108645439148, "step": 83000}
{"episode_reward": 536.329052697335, "episode": 84.0, "batch_reward": 0.4440850502550602, "critic_loss": 0.3762225722372532, "actor_loss": -50.73405853271484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.2624773979187, "step": 84000}
{"episode_reward": 511.0103562562432, "episode": 85.0, "batch_reward": 0.4439698472619057, "critic_loss": 0.378244432464242, "actor_loss": -50.757609367370605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.069223165512085, "step": 85000}
{"episode_reward": 504.97159059280676, "episode": 86.0, "batch_reward": 0.44610564932227137, "critic_loss": 0.36718743345141414, "actor_loss": -50.62872353363037, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.90739870071411, "step": 86000}
{"episode_reward": 505.6277568965674, "episode": 87.0, "batch_reward": 0.4459073647558689, "critic_loss": 0.33765998494625094, "actor_loss": -50.667088455200194, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.894373416900635, "step": 87000}
{"episode_reward": 504.19467146267004, "episode": 88.0, "batch_reward": 0.4473253674507141, "critic_loss": 0.34825832507014276, "actor_loss": -50.569538307189944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.981486797332764, "step": 88000}
{"episode_reward": 523.4668827762615, "episode": 89.0, "batch_reward": 0.4468497278690338, "critic_loss": 0.35672059865295885, "actor_loss": -51.02824294281006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.85584783554077, "step": 89000}
{"episode_reward": 522.1022412367732, "episode": 90.0, "batch_reward": 0.44832191526889803, "critic_loss": 0.38289327861368655, "actor_loss": -51.38489514160156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.020427942276, "step": 90000}
{"episode_reward": 432.1287811128136, "episode": 91.0, "batch_reward": 0.448260453671217, "critic_loss": 0.373528981924057, "actor_loss": -51.03502497863769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.23383903503418, "step": 91000}
{"episode_reward": 492.9456416282037, "episode": 92.0, "batch_reward": 0.44907167997956277, "critic_loss": 0.40563536730408667, "actor_loss": -50.89762621307373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.73242473602295, "step": 92000}
{"episode_reward": 505.845321031825, "episode": 93.0, "batch_reward": 0.44884103786945345, "critic_loss": 0.3849461719989777, "actor_loss": -50.940100883483886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.341928243637085, "step": 93000}
{"episode_reward": 495.681306502215, "episode": 94.0, "batch_reward": 0.4495306845009327, "critic_loss": 0.4158871349543333, "actor_loss": -51.09030770111084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.749598026275635, "step": 94000}
{"episode_reward": 505.27144482184235, "episode": 95.0, "batch_reward": 0.4500934302210808, "critic_loss": 0.41799387845396996, "actor_loss": -51.577290885925294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.71191167831421, "step": 95000}
{"episode_reward": 535.1265336707125, "episode": 96.0, "batch_reward": 0.45102291271090506, "critic_loss": 0.42398499953746793, "actor_loss": -51.54117291259766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.17170214653015, "step": 96000}
{"episode_reward": 481.60311549760826, "episode": 97.0, "batch_reward": 0.4521584083139896, "critic_loss": 0.4300418854802847, "actor_loss": -51.826859954833985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.098005771636963, "step": 97000}
{"episode_reward": 480.70037613913814, "episode": 98.0, "batch_reward": 0.4514925594329834, "critic_loss": 0.4447074438780546, "actor_loss": -51.20144979858399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.970719814300537, "step": 98000}
{"episode_reward": 520.6098115042116, "episode": 99.0, "batch_reward": 0.45295437690615653, "critic_loss": 0.473155073210597, "actor_loss": -51.3965986251831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.911678791046143, "step": 99000}
{"episode_reward": 510.2874810963649, "episode": 100.0, "batch_reward": 0.453454685240984, "critic_loss": 0.41504818534851073, "actor_loss": -51.4723908996582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.03774905204773, "step": 100000}
{"episode_reward": 496.61403697370594, "episode": 101.0, "batch_reward": 0.4533323700428009, "critic_loss": 0.4295182869285345, "actor_loss": -51.595746932983396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.053643465042114, "step": 101000}
{"episode_reward": 513.012882766303, "episode": 102.0, "batch_reward": 0.4539411930441856, "critic_loss": 0.4448778913617134, "actor_loss": -51.578437057495115, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.16205859184265, "step": 102000}
{"episode_reward": 490.7576004357466, "episode": 103.0, "batch_reward": 0.4542317515313625, "critic_loss": 0.4580810371339321, "actor_loss": -51.64412018585205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21963882446289, "step": 103000}
{"episode_reward": 516.9343934390315, "episode": 104.0, "batch_reward": 0.45509761077165606, "critic_loss": 0.4717988743185997, "actor_loss": -51.66151572418213, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.633751153945923, "step": 104000}
{"episode_reward": 517.7181796715503, "episode": 105.0, "batch_reward": 0.45648436695337297, "critic_loss": 0.46192502850294115, "actor_loss": -51.781427436828615, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.42599368095398, "step": 105000}
{"episode_reward": 518.1668064492923, "episode": 106.0, "batch_reward": 0.45599505469202994, "critic_loss": 0.4539200404435396, "actor_loss": -51.449231758117676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.706811666488647, "step": 106000}
{"episode_reward": 518.7048561922464, "episode": 107.0, "batch_reward": 0.45686720141768455, "critic_loss": 0.4333285071998835, "actor_loss": -51.73985543060303, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.70720887184143, "step": 107000}
{"episode_reward": 530.2989596667414, "episode": 108.0, "batch_reward": 0.4579404997527599, "critic_loss": 0.4611006400883198, "actor_loss": -51.86835862731934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.302254915237427, "step": 108000}
{"episode_reward": 497.72290284721925, "episode": 109.0, "batch_reward": 0.45829621896147726, "critic_loss": 0.47411259135603906, "actor_loss": -52.1188445892334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.60997700691223, "step": 109000}
{"episode_reward": 493.43070490924185, "episode": 110.0, "batch_reward": 0.45857041916251184, "critic_loss": 0.4580057983249426, "actor_loss": -51.879789016723635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.423877954483032, "step": 110000}
{"episode_reward": 485.56620793933047, "episode": 111.0, "batch_reward": 0.4584259766638279, "critic_loss": 0.454118365123868, "actor_loss": -52.28462768554687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.951367139816284, "step": 111000}
{"episode_reward": 509.85229350884833, "episode": 112.0, "batch_reward": 0.4584743903577328, "critic_loss": 0.4558135739862919, "actor_loss": -51.997917282104495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.834275007247925, "step": 112000}
{"episode_reward": 524.5872089877568, "episode": 113.0, "batch_reward": 0.4595268889963627, "critic_loss": 0.44211839586496354, "actor_loss": -52.011428970336915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.84445858001709, "step": 113000}
{"episode_reward": 517.1800665804258, "episode": 114.0, "batch_reward": 0.46085757315158843, "critic_loss": 0.45323366521298886, "actor_loss": -52.38890135192871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.24431276321411, "step": 114000}
{"episode_reward": 523.208618414934, "episode": 115.0, "batch_reward": 0.4605674802958965, "critic_loss": 0.4239069046229124, "actor_loss": -52.17993547058106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.328613758087158, "step": 115000}
{"episode_reward": 518.7139910278634, "episode": 116.0, "batch_reward": 0.46156114795804026, "critic_loss": 0.43752655845880506, "actor_loss": -52.351793380737305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.782160997390747, "step": 116000}
{"episode_reward": 502.8708533626004, "episode": 117.0, "batch_reward": 0.4616894051730633, "critic_loss": 0.4111292627155781, "actor_loss": -52.26269596862793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.172662019729614, "step": 117000}
{"episode_reward": 500.61614196541694, "episode": 118.0, "batch_reward": 0.46169357231259345, "critic_loss": 0.4565351655036211, "actor_loss": -52.35521506500244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.060269832611084, "step": 118000}
{"episode_reward": 529.1927903188547, "episode": 119.0, "batch_reward": 0.4623366028368473, "critic_loss": 0.42036592100560666, "actor_loss": -52.52846143341065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14670968055725, "step": 119000}
{"episode_reward": 521.0052515654442, "episode": 120.0, "batch_reward": 0.4626984112560749, "critic_loss": 0.4039906750023365, "actor_loss": -52.18532904815674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.979495763778687, "step": 120000}
{"episode_reward": 505.60410954849476, "episode": 121.0, "batch_reward": 0.46361669328808786, "critic_loss": 0.40519058126211166, "actor_loss": -52.439631858825685, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.1010000705719, "step": 121000}
{"episode_reward": 510.1863479598518, "episode": 122.0, "batch_reward": 0.4630931511819363, "critic_loss": 0.3984696929752827, "actor_loss": -52.34707517242432, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.749835729599, "step": 122000}
{"episode_reward": 514.6524375490847, "episode": 123.0, "batch_reward": 0.4644196521639824, "critic_loss": 0.40879746527969835, "actor_loss": -52.09693929290771, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.9817533493042, "step": 123000}
{"episode_reward": 520.4256715928722, "episode": 124.0, "batch_reward": 0.46474445456266406, "critic_loss": 0.3984784026294947, "actor_loss": -52.58755949401856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.501904249191284, "step": 124000}
{"episode_reward": 488.65273778171644, "episode": 125.0, "batch_reward": 0.46493328419327734, "critic_loss": 0.3924757908731699, "actor_loss": -52.616388206481936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.091254711151123, "step": 125000}
{"episode_reward": 509.2470521082555, "episode": 126.0, "batch_reward": 0.465270265430212, "critic_loss": 0.41140997417271136, "actor_loss": -52.74134666442871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.37255334854126, "step": 126000}
{"episode_reward": 488.4681750269942, "episode": 127.0, "batch_reward": 0.4655509647130966, "critic_loss": 0.4001403155475855, "actor_loss": -52.63258693695068, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.876694917678833, "step": 127000}
{"episode_reward": 531.9976755047405, "episode": 128.0, "batch_reward": 0.4657120130360127, "critic_loss": 0.42436535336077214, "actor_loss": -52.97918606567383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.86262083053589, "step": 128000}
{"episode_reward": 499.39604125922864, "episode": 129.0, "batch_reward": 0.46574306875467303, "critic_loss": 0.4042284277677536, "actor_loss": -52.977362548828125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.019649505615234, "step": 129000}
{"episode_reward": 469.5911706804142, "episode": 130.0, "batch_reward": 0.46612411326169967, "critic_loss": 0.42193394953012464, "actor_loss": -52.78187905883789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.602574348449707, "step": 130000}
{"episode_reward": 514.3012452817302, "episode": 131.0, "batch_reward": 0.4668347571194172, "critic_loss": 0.4240110316127539, "actor_loss": -53.220992515563964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.43000626564026, "step": 131000}
{"episode_reward": 465.5230705646223, "episode": 132.0, "batch_reward": 0.46677920445799825, "critic_loss": 0.4088795080780983, "actor_loss": -52.94166641998291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.55963373184204, "step": 132000}
{"episode_reward": 511.1033395386733, "episode": 133.0, "batch_reward": 0.4664733772277832, "critic_loss": 0.40487301111221313, "actor_loss": -53.05993414306641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.6597843170166, "step": 133000}
{"episode_reward": 485.73199912050427, "episode": 134.0, "batch_reward": 0.4671671000123024, "critic_loss": 0.4022298475205898, "actor_loss": -53.13354959869385, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22381830215454, "step": 134000}
{"episode_reward": 482.61050652729267, "episode": 135.0, "batch_reward": 0.4670758196413517, "critic_loss": 0.42105508521199225, "actor_loss": -53.105925750732425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.507285833358765, "step": 135000}
{"episode_reward": 508.75280985967737, "episode": 136.0, "batch_reward": 0.46733993396162987, "critic_loss": 0.48421774169802667, "actor_loss": -53.38555107879639, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.006576776504517, "step": 136000}
{"episode_reward": 451.4721038254017, "episode": 137.0, "batch_reward": 0.4662850185632706, "critic_loss": 0.4763481105566025, "actor_loss": -52.85666380310059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.12556219100952, "step": 137000}
{"episode_reward": 513.0739283847836, "episode": 138.0, "batch_reward": 0.467993734061718, "critic_loss": 0.4485942996442318, "actor_loss": -52.88496083068848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.60042905807495, "step": 138000}
{"episode_reward": 499.53595675643055, "episode": 139.0, "batch_reward": 0.4679699783027172, "critic_loss": 0.4198277916908264, "actor_loss": -52.97175952148437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.423282623291016, "step": 139000}
{"episode_reward": 493.1709635033069, "episode": 140.0, "batch_reward": 0.46777526184916496, "critic_loss": 0.4011857142597437, "actor_loss": -52.820523612976075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.596465349197388, "step": 140000}
{"episode_reward": 524.72623574906, "episode": 141.0, "batch_reward": 0.4685896075963974, "critic_loss": 0.438021641805768, "actor_loss": -52.79855919647217, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.623331785202026, "step": 141000}
{"episode_reward": 519.4357134229703, "episode": 142.0, "batch_reward": 0.4690529573261738, "critic_loss": 0.4157624182924628, "actor_loss": -53.122503433227536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.247483491897583, "step": 142000}
{"episode_reward": 521.4862837267801, "episode": 143.0, "batch_reward": 0.46917839854955673, "critic_loss": 0.41630736708641053, "actor_loss": -53.15373201751709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.434388637542725, "step": 143000}
{"episode_reward": 512.0845656350828, "episode": 144.0, "batch_reward": 0.4693120259046555, "critic_loss": 0.3880711228847504, "actor_loss": -53.28161567687988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.970531702041626, "step": 144000}
{"episode_reward": 496.5251620983094, "episode": 145.0, "batch_reward": 0.4700418862700462, "critic_loss": 0.4164973052889109, "actor_loss": -53.20895947265625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.698646306991577, "step": 145000}
{"episode_reward": 513.7351846116838, "episode": 146.0, "batch_reward": 0.4696891309320927, "critic_loss": 0.39611275697499515, "actor_loss": -53.161669326782224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.602837562561035, "step": 146000}
{"episode_reward": 512.2148390621342, "episode": 147.0, "batch_reward": 0.4705975331068039, "critic_loss": 0.39666770258545875, "actor_loss": -53.300370407104495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.280951261520386, "step": 147000}
{"episode_reward": 522.56202118967, "episode": 148.0, "batch_reward": 0.4712551381289959, "critic_loss": 0.3602240850776434, "actor_loss": -53.07320819854736, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.083953619003296, "step": 148000}
{"episode_reward": 530.1249118394392, "episode": 149.0, "batch_reward": 0.47061446073651314, "critic_loss": 0.3960515943914652, "actor_loss": -53.24884473419189, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.252224445343018, "step": 149000}
{"episode_reward": 496.67812378446104, "episode": 150.0, "batch_reward": 0.4712550121843815, "critic_loss": 0.3985795018672943, "actor_loss": -53.34577098083496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
