{"episode_reward": 0.0, "episode": 1.0, "duration": 17.798250436782837, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.5702519416809082, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.21949730266448297, "critic_loss": 0.24212558183442676, "actor_loss": -44.538035343531945, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 61.98106074333191, "step": 3000}
{"episode_reward": 63.44234731229652, "episode": 4.0, "batch_reward": 0.16184148278832436, "critic_loss": 0.17979482596367596, "actor_loss": -40.02881499481201, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.273714303970337, "step": 4000}
{"episode_reward": 93.23270627579714, "episode": 5.0, "batch_reward": 0.15417317607998848, "critic_loss": 0.18998799042403697, "actor_loss": -38.64757859802246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.308056831359863, "step": 5000}
{"episode_reward": 155.09595437279597, "episode": 6.0, "batch_reward": 0.15702552116662263, "critic_loss": 0.17451480375230313, "actor_loss": -38.53014694595337, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.571281671524048, "step": 6000}
{"episode_reward": 196.455529176572, "episode": 7.0, "batch_reward": 0.16571650532633067, "critic_loss": 0.16139212780445814, "actor_loss": -38.725748874664305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.36855149269104, "step": 7000}
{"episode_reward": 237.56197089243878, "episode": 8.0, "batch_reward": 0.1764466703683138, "critic_loss": 0.14947350960224867, "actor_loss": -38.68352334213257, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.553571939468384, "step": 8000}
{"episode_reward": 237.61803787666838, "episode": 9.0, "batch_reward": 0.18471618773043155, "critic_loss": 0.1537364799976349, "actor_loss": -38.76424717712403, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.171008348464966, "step": 9000}
{"episode_reward": 222.96899640096876, "episode": 10.0, "batch_reward": 0.18939556351304054, "critic_loss": 0.17175968557596208, "actor_loss": -38.546147281646725, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.357603549957275, "step": 10000}
{"episode_reward": 269.9429861397187, "episode": 11.0, "batch_reward": 0.1966873836815357, "critic_loss": 0.17629519657045603, "actor_loss": -38.58772630310059, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.61158490180969, "step": 11000}
{"episode_reward": 265.631155661195, "episode": 12.0, "batch_reward": 0.2026879689246416, "critic_loss": 0.1631058525443077, "actor_loss": -38.408959194183346, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.607771396636963, "step": 12000}
{"episode_reward": 278.6601053474904, "episode": 13.0, "batch_reward": 0.2099621867388487, "critic_loss": 0.15354874106496572, "actor_loss": -38.80665720748901, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.268955945968628, "step": 13000}
{"episode_reward": 305.12655222051205, "episode": 14.0, "batch_reward": 0.21737610709667204, "critic_loss": 0.1586062987819314, "actor_loss": -38.43268257522583, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.153379678726196, "step": 14000}
{"episode_reward": 295.4596975292551, "episode": 15.0, "batch_reward": 0.22151805807650088, "critic_loss": 0.1615264559313655, "actor_loss": -40.20151383590698, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.1334810256958, "step": 15000}
{"episode_reward": 280.3887377853949, "episode": 16.0, "batch_reward": 0.22492065307497977, "critic_loss": 0.16617778573185205, "actor_loss": -39.155945728302, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.472694635391235, "step": 16000}
{"episode_reward": 252.20645522392635, "episode": 17.0, "batch_reward": 0.22659528808295726, "critic_loss": 0.18114896796643734, "actor_loss": -39.623413902282714, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.46415114402771, "step": 17000}
{"episode_reward": 287.8003499972309, "episode": 18.0, "batch_reward": 0.22713811461627484, "critic_loss": 0.20943516892939806, "actor_loss": -38.807721477508544, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.315571308135986, "step": 18000}
{"episode_reward": 79.41286860421518, "episode": 19.0, "batch_reward": 0.22315502326190473, "critic_loss": 0.2037915271669626, "actor_loss": -37.394733600616455, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.920209407806396, "step": 19000}
{"episode_reward": 302.69254120400086, "episode": 20.0, "batch_reward": 0.2263959832340479, "critic_loss": 0.1937438911497593, "actor_loss": -38.352389602661134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.38677668571472, "step": 20000}
{"episode_reward": 289.17521742670436, "episode": 21.0, "batch_reward": 0.2300244086384773, "critic_loss": 0.1887520498111844, "actor_loss": -38.47083110427857, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.207525968551636, "step": 21000}
{"episode_reward": 292.3450581728793, "episode": 22.0, "batch_reward": 0.2307515106201172, "critic_loss": 0.19154456958174707, "actor_loss": -38.13308877182007, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.292571306228638, "step": 22000}
{"episode_reward": 113.5498284898956, "episode": 23.0, "batch_reward": 0.22709240548312665, "critic_loss": 0.19156510566174983, "actor_loss": -38.149788902282715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.442805767059326, "step": 23000}
{"episode_reward": 177.1269216281846, "episode": 24.0, "batch_reward": 0.22587623307108878, "critic_loss": 0.19139690604805945, "actor_loss": -37.30152132415771, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.26049542427063, "step": 24000}
{"episode_reward": 319.17946098257477, "episode": 25.0, "batch_reward": 0.22998037070035934, "critic_loss": 0.18235327097028495, "actor_loss": -37.20507024002075, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.83699107170105, "step": 25000}
{"episode_reward": 313.71208273916795, "episode": 26.0, "batch_reward": 0.2317431487739086, "critic_loss": 0.18728657975047827, "actor_loss": -37.89010768508911, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.329230785369873, "step": 26000}
{"episode_reward": 292.7093532538977, "episode": 27.0, "batch_reward": 0.23520719575881957, "critic_loss": 0.18767178344726562, "actor_loss": -37.44669735717773, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.37866759300232, "step": 27000}
{"episode_reward": 324.44627391208815, "episode": 28.0, "batch_reward": 0.23724901375174523, "critic_loss": 0.1803219744414091, "actor_loss": -37.15011823654175, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.67649245262146, "step": 28000}
{"episode_reward": 140.6849799583642, "episode": 29.0, "batch_reward": 0.23494356313347817, "critic_loss": 0.17535354626178742, "actor_loss": -37.24689107131958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.213671684265137, "step": 29000}
{"episode_reward": 312.1693339509872, "episode": 30.0, "batch_reward": 0.23844313034415246, "critic_loss": 0.18190477687120438, "actor_loss": -37.06514025497437, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.34195828437805, "step": 30000}
{"episode_reward": 342.0827222242546, "episode": 31.0, "batch_reward": 0.2411135563403368, "critic_loss": 0.1749444976374507, "actor_loss": -37.22153837585449, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.010740518569946, "step": 31000}
{"episode_reward": 316.7472087303558, "episode": 32.0, "batch_reward": 0.24316072821617127, "critic_loss": 0.1671714132502675, "actor_loss": -36.85475820159912, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.370176076889038, "step": 32000}
{"episode_reward": 318.58710242276936, "episode": 33.0, "batch_reward": 0.24569952149689198, "critic_loss": 0.16663103813678026, "actor_loss": -37.84128232192993, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.331223964691162, "step": 33000}
{"episode_reward": 302.30941378940787, "episode": 34.0, "batch_reward": 0.24684480048716068, "critic_loss": 0.1710241872742772, "actor_loss": -37.163239017486575, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.96166706085205, "step": 34000}
{"episode_reward": 316.9554130083598, "episode": 35.0, "batch_reward": 0.24990336832404136, "critic_loss": 0.17363095036149026, "actor_loss": -38.4859483757019, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.861215114593506, "step": 35000}
{"episode_reward": 332.1035235208153, "episode": 36.0, "batch_reward": 0.25184166952967646, "critic_loss": 0.16982514829933643, "actor_loss": -37.299960849761966, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.355948209762573, "step": 36000}
{"episode_reward": 331.16664172002635, "episode": 37.0, "batch_reward": 0.25315219958126545, "critic_loss": 0.17017680528014897, "actor_loss": -38.53761334609985, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.718809366226196, "step": 37000}
{"episode_reward": 310.6675401874214, "episode": 38.0, "batch_reward": 0.2555421147495508, "critic_loss": 0.17503007804602386, "actor_loss": -38.53328889083862, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.222744464874268, "step": 38000}
{"episode_reward": 328.3048337778808, "episode": 39.0, "batch_reward": 0.2578111751824617, "critic_loss": 0.17142894028127192, "actor_loss": -38.67336646270752, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.727264404296875, "step": 39000}
{"episode_reward": 326.7822747580396, "episode": 40.0, "batch_reward": 0.2588223593831062, "critic_loss": 0.19216350769251586, "actor_loss": -38.95041022491455, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.281293869018555, "step": 40000}
{"episode_reward": 304.0631803236395, "episode": 41.0, "batch_reward": 0.26082589657604693, "critic_loss": 0.1958612997829914, "actor_loss": -39.191078662872314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.42096281051636, "step": 41000}
{"episode_reward": 326.0807298334778, "episode": 42.0, "batch_reward": 0.2622139294892549, "critic_loss": 0.1908656855970621, "actor_loss": -38.360392963409424, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.583333253860474, "step": 42000}
{"episode_reward": 327.4071574241686, "episode": 43.0, "batch_reward": 0.26337473960220814, "critic_loss": 0.1881474754884839, "actor_loss": -38.721396656036376, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.297876596450806, "step": 43000}
{"episode_reward": 316.37097110808617, "episode": 44.0, "batch_reward": 0.2648516322076321, "critic_loss": 0.19183444480597972, "actor_loss": -38.702067375183105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.80376887321472, "step": 44000}
{"episode_reward": 312.92401629652136, "episode": 45.0, "batch_reward": 0.26630693635344505, "critic_loss": 0.1893474838733673, "actor_loss": -38.905833030700684, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.728364944458008, "step": 45000}
{"episode_reward": 361.56890606416937, "episode": 46.0, "batch_reward": 0.2679523113965988, "critic_loss": 0.19200741298496724, "actor_loss": -38.931074821472166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.765785694122314, "step": 46000}
{"episode_reward": 363.5506676976771, "episode": 47.0, "batch_reward": 0.27058677427470684, "critic_loss": 0.20191362593322992, "actor_loss": -39.54669815063477, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.386763334274292, "step": 47000}
{"episode_reward": 373.17142767252057, "episode": 48.0, "batch_reward": 0.2729415112286806, "critic_loss": 0.21333755726367234, "actor_loss": -39.34531719970703, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.06419539451599, "step": 48000}
{"episode_reward": 404.25020967609925, "episode": 49.0, "batch_reward": 0.2754910491406918, "critic_loss": 0.2219804295822978, "actor_loss": -40.24653183746338, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.233787059783936, "step": 49000}
{"episode_reward": 345.81964041227394, "episode": 50.0, "batch_reward": 0.27588687047362326, "critic_loss": 0.2165472644045949, "actor_loss": -39.49329872512818, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.74561882019043, "step": 50000}
{"episode_reward": 378.6245262657506, "episode": 51.0, "batch_reward": 0.2792711254805326, "critic_loss": 0.22286141241341828, "actor_loss": -39.897243896484376, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.87801456451416, "step": 51000}
{"episode_reward": 358.44352736198107, "episode": 52.0, "batch_reward": 0.2807568795979023, "critic_loss": 0.22668691163510085, "actor_loss": -39.816030670166015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.15841817855835, "step": 52000}
{"episode_reward": 357.44663364759253, "episode": 53.0, "batch_reward": 0.28173295271396637, "critic_loss": 0.2299587165117264, "actor_loss": -40.17588447189331, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.426285982131958, "step": 53000}
{"episode_reward": 374.449443898727, "episode": 54.0, "batch_reward": 0.28122043481469156, "critic_loss": 0.24178439619392156, "actor_loss": -39.67545344543457, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.631855487823486, "step": 54000}
{"episode_reward": 88.66577412738074, "episode": 55.0, "batch_reward": 0.2802560678124428, "critic_loss": 0.24731514520198106, "actor_loss": -40.477632484436036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.62051010131836, "step": 55000}
{"episode_reward": 350.4117953881356, "episode": 56.0, "batch_reward": 0.2811664745360613, "critic_loss": 0.2586955142319202, "actor_loss": -40.25210059738159, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.587068557739258, "step": 56000}
{"episode_reward": 394.35190849943234, "episode": 57.0, "batch_reward": 0.28370161877572536, "critic_loss": 0.2732153813391924, "actor_loss": -39.63933638381958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.418608903884888, "step": 57000}
{"episode_reward": 389.06873533008934, "episode": 58.0, "batch_reward": 0.285219669342041, "critic_loss": 0.29446946586668493, "actor_loss": -39.99306312179566, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.857327222824097, "step": 58000}
{"episode_reward": 334.2466306832438, "episode": 59.0, "batch_reward": 0.2849225137233734, "critic_loss": 0.3034938712120056, "actor_loss": -39.55317811203003, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.469922304153442, "step": 59000}
{"episode_reward": 170.6820342139562, "episode": 60.0, "batch_reward": 0.2844053753912449, "critic_loss": 0.3106435208171606, "actor_loss": -39.608618419647215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.49632954597473, "step": 60000}
{"episode_reward": 419.6427785250193, "episode": 61.0, "batch_reward": 0.2862595292776823, "critic_loss": 0.31142299620807173, "actor_loss": -39.39713005447388, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.31010603904724, "step": 61000}
{"episode_reward": 380.6414275568166, "episode": 62.0, "batch_reward": 0.287744622156024, "critic_loss": 0.3108207754343748, "actor_loss": -40.55503701019287, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.64593768119812, "step": 62000}
{"episode_reward": 372.5198372483325, "episode": 63.0, "batch_reward": 0.2881046181023121, "critic_loss": 0.33324753607809543, "actor_loss": -39.88213701629639, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.280820846557617, "step": 63000}
{"episode_reward": 162.50477163113268, "episode": 64.0, "batch_reward": 0.2871906049102545, "critic_loss": 0.3513612525463104, "actor_loss": -39.770615474700925, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.804705381393433, "step": 64000}
{"episode_reward": 416.62575658871094, "episode": 65.0, "batch_reward": 0.28892096887528895, "critic_loss": 0.35281662817299364, "actor_loss": -39.54008388900757, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.03459596633911, "step": 65000}
{"episode_reward": 382.3319431497355, "episode": 66.0, "batch_reward": 0.29092347103357313, "critic_loss": 0.35250937677919864, "actor_loss": -39.87893572616577, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.28284478187561, "step": 66000}
{"episode_reward": 387.8648247841269, "episode": 67.0, "batch_reward": 0.292215870141983, "critic_loss": 0.3735186647325754, "actor_loss": -40.16840007019043, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.36688256263733, "step": 67000}
{"episode_reward": 422.510254986387, "episode": 68.0, "batch_reward": 0.29389390885829925, "critic_loss": 0.38115401957929135, "actor_loss": -39.969186084747314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.925947189331055, "step": 68000}
{"episode_reward": 407.38994864236446, "episode": 69.0, "batch_reward": 0.29580573135614396, "critic_loss": 0.3596397204548121, "actor_loss": -40.30522496032715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.404038906097412, "step": 69000}
{"episode_reward": 430.7236869112746, "episode": 70.0, "batch_reward": 0.29766607996821404, "critic_loss": 0.36934271605312824, "actor_loss": -40.6714676322937, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.924875259399414, "step": 70000}
{"episode_reward": 396.1891455904442, "episode": 71.0, "batch_reward": 0.29870689937472344, "critic_loss": 0.3515491829663515, "actor_loss": -40.94950411987305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.756328105926514, "step": 71000}
{"episode_reward": 429.1536944058805, "episode": 72.0, "batch_reward": 0.3007340221107006, "critic_loss": 0.34765716330707075, "actor_loss": -41.116115104675295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.201091289520264, "step": 72000}
{"episode_reward": 369.09358484954305, "episode": 73.0, "batch_reward": 0.3015387890636921, "critic_loss": 0.3537955258190632, "actor_loss": -40.80961606597901, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.386836051940918, "step": 73000}
{"episode_reward": 412.2888186718204, "episode": 74.0, "batch_reward": 0.30333441236615183, "critic_loss": 0.3492847189605236, "actor_loss": -41.40377195358276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.379446029663086, "step": 74000}
{"episode_reward": 391.26629218324337, "episode": 75.0, "batch_reward": 0.303799638569355, "critic_loss": 0.3560362261384726, "actor_loss": -40.88917086029053, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.362873554229736, "step": 75000}
{"episode_reward": 229.2607250070635, "episode": 76.0, "batch_reward": 0.30339731359481814, "critic_loss": 0.3725423554927111, "actor_loss": -41.049473598480226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.77108073234558, "step": 76000}
{"episode_reward": 376.9393291664612, "episode": 77.0, "batch_reward": 0.30415848806500434, "critic_loss": 0.3600651373565197, "actor_loss": -40.58576243972778, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.42474389076233, "step": 77000}
{"episode_reward": 398.56233928906056, "episode": 78.0, "batch_reward": 0.30565095084905625, "critic_loss": 0.3663350594341755, "actor_loss": -41.33209336853027, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.102954626083374, "step": 78000}
{"episode_reward": 372.03731033709994, "episode": 79.0, "batch_reward": 0.3054343924224377, "critic_loss": 0.351568610355258, "actor_loss": -39.953996643066404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.39594841003418, "step": 79000}
{"episode_reward": 132.69298393917663, "episode": 80.0, "batch_reward": 0.30250164565443993, "critic_loss": 0.3727043725848198, "actor_loss": -40.45769646835327, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.385535717010498, "step": 80000}
{"episode_reward": 94.1509906880407, "episode": 81.0, "batch_reward": 0.3014402646422386, "critic_loss": 0.3844620268046856, "actor_loss": -40.151347118377686, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.44687604904175, "step": 81000}
{"episode_reward": 379.98915766477705, "episode": 82.0, "batch_reward": 0.3027760047316551, "critic_loss": 0.37333349959552287, "actor_loss": -41.254689575195314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.34982419013977, "step": 82000}
{"episode_reward": 400.59448430933963, "episode": 83.0, "batch_reward": 0.30385930263996125, "critic_loss": 0.36190558977425097, "actor_loss": -40.37557865905762, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.635276317596436, "step": 83000}
{"episode_reward": 437.64342875005406, "episode": 84.0, "batch_reward": 0.3057898010909557, "critic_loss": 0.36971925745904444, "actor_loss": -41.92127285003662, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.34724736213684, "step": 84000}
{"episode_reward": 372.6340655274577, "episode": 85.0, "batch_reward": 0.30599614238739015, "critic_loss": 0.37153373059630396, "actor_loss": -40.98348576354981, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.88366723060608, "step": 85000}
{"episode_reward": 313.1961752841671, "episode": 86.0, "batch_reward": 0.3064879350066185, "critic_loss": 0.3630051817148924, "actor_loss": -40.94090702056885, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.101767778396606, "step": 86000}
{"episode_reward": 413.1236970299211, "episode": 87.0, "batch_reward": 0.30794717425107954, "critic_loss": 0.35154512271285054, "actor_loss": -40.85102312088013, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.48067021369934, "step": 87000}
{"episode_reward": 429.0948561189751, "episode": 88.0, "batch_reward": 0.30920994573831556, "critic_loss": 0.3522804856449366, "actor_loss": -40.525824405670164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.408586502075195, "step": 88000}
{"episode_reward": 349.38026411391644, "episode": 89.0, "batch_reward": 0.3093195063471794, "critic_loss": 0.3754488164484501, "actor_loss": -41.28113053894043, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.376951456069946, "step": 89000}
{"episode_reward": 423.3284307827661, "episode": 90.0, "batch_reward": 0.31003997701406477, "critic_loss": 0.3961695667207241, "actor_loss": -41.547660385131834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.93067479133606, "step": 90000}
{"episode_reward": 434.03467476372526, "episode": 91.0, "batch_reward": 0.31264262878894805, "critic_loss": 0.37677955023944376, "actor_loss": -41.39137591552734, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.076824426651, "step": 91000}
{"episode_reward": 402.26086049797954, "episode": 92.0, "batch_reward": 0.31338258424401283, "critic_loss": 0.36541135820746423, "actor_loss": -41.323398525238034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.258217811584473, "step": 92000}
{"episode_reward": 429.77109418306304, "episode": 93.0, "batch_reward": 0.31364946308732033, "critic_loss": 0.3635646073371172, "actor_loss": -41.02174137878418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.018831491470337, "step": 93000}
{"episode_reward": 148.68690770277635, "episode": 94.0, "batch_reward": 0.312253213852644, "critic_loss": 0.3430745524764061, "actor_loss": -41.276287998199464, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.461418628692627, "step": 94000}
{"episode_reward": 402.52764743330874, "episode": 95.0, "batch_reward": 0.3133001818060875, "critic_loss": 0.34393874387443063, "actor_loss": -41.557490211486815, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.177557945251465, "step": 95000}
{"episode_reward": 424.1502618692748, "episode": 96.0, "batch_reward": 0.31396760246157646, "critic_loss": 0.3746997647732496, "actor_loss": -41.76089705657959, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.257108688354492, "step": 96000}
{"episode_reward": 397.7422733820824, "episode": 97.0, "batch_reward": 0.31553488558530807, "critic_loss": 0.3862055284976959, "actor_loss": -42.13979162979126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.549277782440186, "step": 97000}
{"episode_reward": 313.65014065743696, "episode": 98.0, "batch_reward": 0.3155561649799347, "critic_loss": 0.37528319254517556, "actor_loss": -41.76642419815064, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.50472593307495, "step": 98000}
{"episode_reward": 427.6945583547402, "episode": 99.0, "batch_reward": 0.3163273065984249, "critic_loss": 0.39295714142918586, "actor_loss": -41.27594444656372, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.220635175704956, "step": 99000}
{"episode_reward": 423.61854270764434, "episode": 100.0, "batch_reward": 0.31777163019776344, "critic_loss": 0.38397305537760257, "actor_loss": -41.74489081573486, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.10301184654236, "step": 100000}
{"episode_reward": 423.6444878805155, "episode": 101.0, "batch_reward": 0.31905916467309, "critic_loss": 0.3776148673295975, "actor_loss": -41.91581202697754, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.94896173477173, "step": 101000}
{"episode_reward": 420.5663283282411, "episode": 102.0, "batch_reward": 0.31964473393559456, "critic_loss": 0.3699337187856436, "actor_loss": -41.590278064727784, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.491169452667236, "step": 102000}
{"episode_reward": 417.051214695059, "episode": 103.0, "batch_reward": 0.32042923545837404, "critic_loss": 0.3545938479751348, "actor_loss": -42.207869892120364, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.955875873565674, "step": 103000}
{"episode_reward": 419.393860146639, "episode": 104.0, "batch_reward": 0.3216902469098568, "critic_loss": 0.35197857816517353, "actor_loss": -42.31319018554687, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.426084280014038, "step": 104000}
{"episode_reward": 174.55327446788408, "episode": 105.0, "batch_reward": 0.3211895432472229, "critic_loss": 0.3542053056061268, "actor_loss": -42.184219764709475, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.932730674743652, "step": 105000}
{"episode_reward": 449.2241485958185, "episode": 106.0, "batch_reward": 0.321715323895216, "critic_loss": 0.35327642543613913, "actor_loss": -41.965709789276126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.19899320602417, "step": 106000}
{"episode_reward": 418.2185185202103, "episode": 107.0, "batch_reward": 0.3224817413687706, "critic_loss": 0.3671248521655798, "actor_loss": -42.43945289993286, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.520540714263916, "step": 107000}
{"episode_reward": 393.8354395879612, "episode": 108.0, "batch_reward": 0.32383938843011856, "critic_loss": 0.3698034352064133, "actor_loss": -42.183188091278076, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.637768268585205, "step": 108000}
{"episode_reward": 426.8030289652761, "episode": 109.0, "batch_reward": 0.3234356642961502, "critic_loss": 0.3455205573141575, "actor_loss": -43.02585440063476, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.75468397140503, "step": 109000}
{"episode_reward": 375.2077345041398, "episode": 110.0, "batch_reward": 0.32435932928323746, "critic_loss": 0.35983078652620315, "actor_loss": -42.790492095947265, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.515281677246094, "step": 110000}
{"episode_reward": 399.52290085837126, "episode": 111.0, "batch_reward": 0.32539662352204324, "critic_loss": 0.3604933300614357, "actor_loss": -42.851352725982665, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.102760791778564, "step": 111000}
{"episode_reward": 426.7215773792689, "episode": 112.0, "batch_reward": 0.32528925693035127, "critic_loss": 0.37445088095963003, "actor_loss": -42.0231430053711, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.200706005096436, "step": 112000}
{"episode_reward": 236.6068417822214, "episode": 113.0, "batch_reward": 0.32555111262202263, "critic_loss": 0.34122257941961287, "actor_loss": -42.578889541625976, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.64938998222351, "step": 113000}
{"episode_reward": 424.90807160647245, "episode": 114.0, "batch_reward": 0.3261830048561096, "critic_loss": 0.34569132755696774, "actor_loss": -43.030332862854, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.325867652893066, "step": 114000}
{"episode_reward": 433.81545549541295, "episode": 115.0, "batch_reward": 0.3271559709906578, "critic_loss": 0.3572026741653681, "actor_loss": -42.49838636398315, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.06989073753357, "step": 115000}
{"episode_reward": 419.20398958795676, "episode": 116.0, "batch_reward": 0.3282056812644005, "critic_loss": 0.3612835110127926, "actor_loss": -42.61369529724121, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.03180742263794, "step": 116000}
{"episode_reward": 414.11566406062684, "episode": 117.0, "batch_reward": 0.32927472999691965, "critic_loss": 0.37801006917655466, "actor_loss": -42.426195236206055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.346237421035767, "step": 117000}
{"episode_reward": 436.3036217813401, "episode": 118.0, "batch_reward": 0.32902749681472776, "critic_loss": 0.3747312244772911, "actor_loss": -42.71290142440796, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.30955481529236, "step": 118000}
{"episode_reward": 202.0561791871121, "episode": 119.0, "batch_reward": 0.3282859862744808, "critic_loss": 0.37635265597701073, "actor_loss": -42.79804492950439, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.219843864440918, "step": 119000}
{"episode_reward": 396.15961114128396, "episode": 120.0, "batch_reward": 0.32884863010048865, "critic_loss": 0.35081448253989217, "actor_loss": -42.57524380111694, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.095762968063354, "step": 120000}
{"episode_reward": 427.8597506105758, "episode": 121.0, "batch_reward": 0.32997374221682546, "critic_loss": 0.34790792274475096, "actor_loss": -42.19818246078491, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.79274272918701, "step": 121000}
{"episode_reward": 420.0847182622083, "episode": 122.0, "batch_reward": 0.33097123563289643, "critic_loss": 0.37116608807444573, "actor_loss": -42.57259240341187, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.346890449523926, "step": 122000}
{"episode_reward": 406.1596944501869, "episode": 123.0, "batch_reward": 0.3315893562734127, "critic_loss": 0.3667881353497505, "actor_loss": -41.95277600479126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.91177749633789, "step": 123000}
{"episode_reward": 417.0324300692022, "episode": 124.0, "batch_reward": 0.3320311880707741, "critic_loss": 0.35748663122951985, "actor_loss": -42.601637042999265, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.390337228775024, "step": 124000}
{"episode_reward": 415.12707095654616, "episode": 125.0, "batch_reward": 0.3321491847336292, "critic_loss": 0.37150733679533005, "actor_loss": -42.388107509613036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.65818500518799, "step": 125000}
{"episode_reward": 395.6099300704534, "episode": 126.0, "batch_reward": 0.33278166452050206, "critic_loss": 0.3790359530001879, "actor_loss": -42.1414991569519, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.486307621002197, "step": 126000}
{"episode_reward": 412.16663224561376, "episode": 127.0, "batch_reward": 0.3337925128936768, "critic_loss": 0.4056243198364973, "actor_loss": -43.10612049102783, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.324942111968994, "step": 127000}
{"episode_reward": 368.8760022194277, "episode": 128.0, "batch_reward": 0.3336563800573349, "critic_loss": 0.38613397972285746, "actor_loss": -43.605809463500975, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.17150378227234, "step": 128000}
{"episode_reward": 413.26757872513474, "episode": 129.0, "batch_reward": 0.3339448015987873, "critic_loss": 0.38839229552447796, "actor_loss": -43.193036849975584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.44035267829895, "step": 129000}
{"episode_reward": 371.14587445195383, "episode": 130.0, "batch_reward": 0.3347362388968468, "critic_loss": 0.44313017052412035, "actor_loss": -43.19575177383423, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.187198400497437, "step": 130000}
{"episode_reward": 406.86929418087453, "episode": 131.0, "batch_reward": 0.33658722466230395, "critic_loss": 0.4468571012765169, "actor_loss": -43.64347727203369, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.397298097610474, "step": 131000}
{"episode_reward": 373.0432462519539, "episode": 132.0, "batch_reward": 0.33651852774620056, "critic_loss": 0.46731888099014757, "actor_loss": -43.56380643844604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.061899662017822, "step": 132000}
{"episode_reward": 399.2810806003846, "episode": 133.0, "batch_reward": 0.3361129997968674, "critic_loss": 0.4559615321606398, "actor_loss": -43.36379228591919, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.240465879440308, "step": 133000}
{"episode_reward": 421.24308289079397, "episode": 134.0, "batch_reward": 0.33660470628738404, "critic_loss": 0.4574627300053835, "actor_loss": -43.69629936981201, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.4710054397583, "step": 134000}
{"episode_reward": 411.5171208505364, "episode": 135.0, "batch_reward": 0.3379685480892658, "critic_loss": 0.45406704318523405, "actor_loss": -43.561156929016114, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.285520315170288, "step": 135000}
{"episode_reward": 426.3656808432537, "episode": 136.0, "batch_reward": 0.33813751736283304, "critic_loss": 0.46035216867923734, "actor_loss": -44.180604763031006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.080889463424683, "step": 136000}
{"episode_reward": 460.693367227798, "episode": 137.0, "batch_reward": 0.3394325941205025, "critic_loss": 0.44011658896505834, "actor_loss": -43.8857142906189, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.088454008102417, "step": 137000}
{"episode_reward": 408.1209129252942, "episode": 138.0, "batch_reward": 0.3392102372050285, "critic_loss": 0.450317989885807, "actor_loss": -42.81230327987671, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.42139434814453, "step": 138000}
{"episode_reward": 302.5506715724571, "episode": 139.0, "batch_reward": 0.3401251579225063, "critic_loss": 0.4555212115496397, "actor_loss": -43.21683271026611, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.369841814041138, "step": 139000}
{"episode_reward": 431.80625188101527, "episode": 140.0, "batch_reward": 0.3400167317688465, "critic_loss": 0.45675884464383126, "actor_loss": -42.820086326599125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.14158010482788, "step": 140000}
{"episode_reward": 463.13533198799865, "episode": 141.0, "batch_reward": 0.34152187395095823, "critic_loss": 0.4707448922544718, "actor_loss": -43.272751991271974, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.266289710998535, "step": 141000}
{"episode_reward": 442.5671555222693, "episode": 142.0, "batch_reward": 0.3416384233832359, "critic_loss": 0.47091352760791777, "actor_loss": -43.4541893157959, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.9914128780365, "step": 142000}
{"episode_reward": 428.4634329125808, "episode": 143.0, "batch_reward": 0.3424922395646572, "critic_loss": 0.43582840709388254, "actor_loss": -43.83890382003784, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.573962688446045, "step": 143000}
{"episode_reward": 449.8526442320478, "episode": 144.0, "batch_reward": 0.34331782260537147, "critic_loss": 0.4282728378176689, "actor_loss": -43.84746677398682, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.398120403289795, "step": 144000}
{"episode_reward": 445.78289491546434, "episode": 145.0, "batch_reward": 0.34388323497772216, "critic_loss": 0.40966564665734767, "actor_loss": -43.658088840484616, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.343925714492798, "step": 145000}
{"episode_reward": 455.16912077055827, "episode": 146.0, "batch_reward": 0.34400931736826895, "critic_loss": 0.40641609942913054, "actor_loss": -43.569090141296385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.501381397247314, "step": 146000}
{"episode_reward": 432.7330379876665, "episode": 147.0, "batch_reward": 0.34401376071572304, "critic_loss": 0.41836327865719797, "actor_loss": -44.258491065979, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.891033411026, "step": 147000}
{"episode_reward": 447.3448367153365, "episode": 148.0, "batch_reward": 0.34623408755660057, "critic_loss": 0.4159570098668337, "actor_loss": -43.89267634963989, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.414284467697144, "step": 148000}
{"episode_reward": 464.9488990978433, "episode": 149.0, "batch_reward": 0.34685900977253914, "critic_loss": 0.44937030944228173, "actor_loss": -44.14572534942627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.535372734069824, "step": 149000}
{"episode_reward": 381.3963372762597, "episode": 150.0, "batch_reward": 0.347199566423893, "critic_loss": 0.5507390626370907, "actor_loss": -43.55742015838623, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
