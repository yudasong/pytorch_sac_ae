{"episode_reward": 0.0, "episode": 1.0, "duration": 17.57484245300293, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.5257923603057861, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.2176486472684608, "critic_loss": 0.24272978580834748, "actor_loss": -44.30566976851776, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 63.264867544174194, "step": 3000}
{"episode_reward": 21.258942691336394, "episode": 4.0, "batch_reward": 0.14351237861812113, "critic_loss": 0.1384406608790159, "actor_loss": -38.921594066619875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.58342409133911, "step": 4000}
{"episode_reward": 35.32742934337549, "episode": 5.0, "batch_reward": 0.12665011602640153, "critic_loss": 0.19185088315606116, "actor_loss": -36.89103181457519, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.634037733078003, "step": 5000}
{"episode_reward": 146.38906503310164, "episode": 6.0, "batch_reward": 0.13169222816824913, "critic_loss": 0.20797814466804265, "actor_loss": -36.33098192596436, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.122761011123657, "step": 6000}
{"episode_reward": 93.23913395160129, "episode": 7.0, "batch_reward": 0.1282981831356883, "critic_loss": 0.20347368118166922, "actor_loss": -34.69567356109619, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.530500411987305, "step": 7000}
{"episode_reward": 112.90867477182988, "episode": 8.0, "batch_reward": 0.12276616907119751, "critic_loss": 0.1946482291519642, "actor_loss": -32.283824390411375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.048675060272217, "step": 8000}
{"episode_reward": 61.98934333463755, "episode": 9.0, "batch_reward": 0.12135436740517616, "critic_loss": 0.19907520532608033, "actor_loss": -31.05790141296387, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.415828227996826, "step": 9000}
{"episode_reward": 167.47428363152073, "episode": 10.0, "batch_reward": 0.12669825579971075, "critic_loss": 0.2215469858944416, "actor_loss": -30.693130332946776, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.365308046340942, "step": 10000}
{"episode_reward": 143.88552048258714, "episode": 11.0, "batch_reward": 0.1304480913877487, "critic_loss": 0.2391041163355112, "actor_loss": -30.28226414489746, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.90578007698059, "step": 11000}
{"episode_reward": 196.82466027290326, "episode": 12.0, "batch_reward": 0.12928763422369957, "critic_loss": 0.2315118584856391, "actor_loss": -28.90527414703369, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.320812463760376, "step": 12000}
{"episode_reward": 55.17508989278168, "episode": 13.0, "batch_reward": 0.12267826922982931, "critic_loss": 0.22091511183977128, "actor_loss": -27.582868461608886, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.610353231430054, "step": 13000}
{"episode_reward": 41.91820216591334, "episode": 14.0, "batch_reward": 0.12296821770071983, "critic_loss": 0.22986082606017588, "actor_loss": -26.812516654968263, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.81443166732788, "step": 14000}
{"episode_reward": 279.5156106095364, "episode": 15.0, "batch_reward": 0.13532259365171195, "critic_loss": 0.24644115238636732, "actor_loss": -28.819270446777345, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.625608921051025, "step": 15000}
{"episode_reward": 285.7610573990297, "episode": 16.0, "batch_reward": 0.1384916074052453, "critic_loss": 0.24430320654064416, "actor_loss": -28.16523913192749, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.833872079849243, "step": 16000}
{"episode_reward": 68.00170451935561, "episode": 17.0, "batch_reward": 0.14179812981188297, "critic_loss": 0.2449309459477663, "actor_loss": -27.653057523727416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.730761528015137, "step": 17000}
{"episode_reward": 352.394729417575, "episode": 18.0, "batch_reward": 0.14863540779799223, "critic_loss": 0.2784801135659218, "actor_loss": -27.941735877990723, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.264170169830322, "step": 18000}
{"episode_reward": 87.94906142383583, "episode": 19.0, "batch_reward": 0.14943819430470467, "critic_loss": 0.363474200040102, "actor_loss": -27.611887981414796, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.44921112060547, "step": 19000}
{"episode_reward": 311.92417758674134, "episode": 20.0, "batch_reward": 0.1540157484859228, "critic_loss": 0.3965773815661669, "actor_loss": -28.135305906295777, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.789944171905518, "step": 20000}
{"episode_reward": 105.73542570103629, "episode": 21.0, "batch_reward": 0.15626014327257873, "critic_loss": 0.4415330520272255, "actor_loss": -28.233888961791994, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.969667196273804, "step": 21000}
{"episode_reward": 375.06694493108205, "episode": 22.0, "batch_reward": 0.16715656523406505, "critic_loss": 0.5279472577720881, "actor_loss": -28.62233848762512, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.99809980392456, "step": 22000}
{"episode_reward": 356.75750020243817, "episode": 23.0, "batch_reward": 0.17437179236114025, "critic_loss": 1.139070102483034, "actor_loss": -29.60769138145447, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.637781381607056, "step": 23000}
{"episode_reward": 241.28621282535545, "episode": 24.0, "batch_reward": 0.17417550756037234, "critic_loss": 3.882557889223099, "actor_loss": -30.02576811981201, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.608278512954712, "step": 24000}
{"episode_reward": 107.79839316776092, "episode": 25.0, "batch_reward": 0.16770091742277146, "critic_loss": 6.666255088686943, "actor_loss": -30.96618871688843, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.792956829071045, "step": 25000}
{"episode_reward": 12.597537991779456, "episode": 26.0, "batch_reward": 0.16089962869137525, "critic_loss": 8.532148810386659, "actor_loss": -34.01731114959717, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.66210126876831, "step": 26000}
{"episode_reward": 13.286529874265891, "episode": 27.0, "batch_reward": 0.15620413784682752, "critic_loss": 8.522680750846863, "actor_loss": -38.87869215011597, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.632957458496094, "step": 27000}
{"episode_reward": 11.573742342130302, "episode": 28.0, "batch_reward": 0.15132407622784377, "critic_loss": 7.175372045040131, "actor_loss": -43.19375160217285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.93632459640503, "step": 28000}
{"episode_reward": 12.727441492313181, "episode": 29.0, "batch_reward": 0.14709250024706125, "critic_loss": 5.556569095849991, "actor_loss": -43.67968313598633, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.546752214431763, "step": 29000}
{"episode_reward": 27.3038460892459, "episode": 30.0, "batch_reward": 0.1422355878278613, "critic_loss": 3.6382173626422882, "actor_loss": -44.828996822357176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.143610954284668, "step": 30000}
{"episode_reward": 14.784175517539804, "episode": 31.0, "batch_reward": 0.13803207243978977, "critic_loss": 2.591669830918312, "actor_loss": -43.51083823776245, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.687782526016235, "step": 31000}
{"episode_reward": 53.08338586990958, "episode": 32.0, "batch_reward": 0.13827394343912602, "critic_loss": 2.0601795162558556, "actor_loss": -44.317048458099364, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.085351705551147, "step": 32000}
{"episode_reward": 281.44226032834075, "episode": 33.0, "batch_reward": 0.14453923692554235, "critic_loss": 1.7674764439463615, "actor_loss": -42.99465235900879, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.856792211532593, "step": 33000}
{"episode_reward": 343.31323346106285, "episode": 34.0, "batch_reward": 0.15044446839392187, "critic_loss": 1.471781973361969, "actor_loss": -44.308599395751955, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.566097259521484, "step": 34000}
{"episode_reward": 354.5029729868431, "episode": 35.0, "batch_reward": 0.15631933284550906, "critic_loss": 1.2014028549194335, "actor_loss": -42.91797909545898, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.37296772003174, "step": 35000}
{"episode_reward": 352.905463516684, "episode": 36.0, "batch_reward": 0.16190714187175034, "critic_loss": 0.9942810707092286, "actor_loss": -44.12857480239868, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.274755716323853, "step": 36000}
{"episode_reward": 392.3305218466803, "episode": 37.0, "batch_reward": 0.16837914031744003, "critic_loss": 0.8334367617666721, "actor_loss": -43.05323136138916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.625741720199585, "step": 37000}
{"episode_reward": 390.34275644236186, "episode": 38.0, "batch_reward": 0.1735242903754115, "critic_loss": 0.8443971066474915, "actor_loss": -42.2617557182312, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.832570791244507, "step": 38000}
{"episode_reward": 331.8133473935222, "episode": 39.0, "batch_reward": 0.17890962839126587, "critic_loss": 0.8424203688204288, "actor_loss": -41.955152458190916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.428210020065308, "step": 39000}
{"episode_reward": 399.6216968810716, "episode": 40.0, "batch_reward": 0.18360693968832492, "critic_loss": 0.8593023551404476, "actor_loss": -41.57347580718994, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.029221773147583, "step": 40000}
{"episode_reward": 360.3750774161959, "episode": 41.0, "batch_reward": 0.18585641454160212, "critic_loss": 0.8505555594861507, "actor_loss": -41.20066534423828, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.15985298156738, "step": 41000}
{"episode_reward": 88.8946428055971, "episode": 42.0, "batch_reward": 0.18713028599321843, "critic_loss": 0.7995302758812904, "actor_loss": -41.09428034973145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.417563915252686, "step": 42000}
{"episode_reward": 409.2166826039934, "episode": 43.0, "batch_reward": 0.19227231991291047, "critic_loss": 0.8001521844863891, "actor_loss": -40.95892591094971, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.18319845199585, "step": 43000}
{"episode_reward": 406.3750643110741, "episode": 44.0, "batch_reward": 0.19636541764438153, "critic_loss": 0.7405686728358268, "actor_loss": -40.81653868865967, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.55362582206726, "step": 44000}
{"episode_reward": 377.90045769168376, "episode": 45.0, "batch_reward": 0.20019519382715226, "critic_loss": 0.7408891598880291, "actor_loss": -40.08601181793213, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.47191309928894, "step": 45000}
{"episode_reward": 182.05710383667954, "episode": 46.0, "batch_reward": 0.19962938798964022, "critic_loss": 0.7075502955019474, "actor_loss": -39.68241162109375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.53678846359253, "step": 46000}
{"episode_reward": 378.7649587628516, "episode": 47.0, "batch_reward": 0.2046969677954912, "critic_loss": 0.7072546498179436, "actor_loss": -39.43574736022949, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.542977571487427, "step": 47000}
{"episode_reward": 391.109511710303, "episode": 48.0, "batch_reward": 0.20693720646202565, "critic_loss": 0.6614767670333386, "actor_loss": -39.32599434661865, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.631914138793945, "step": 48000}
{"episode_reward": 154.7012249258766, "episode": 49.0, "batch_reward": 0.20519905215501785, "critic_loss": 0.6878809954822064, "actor_loss": -38.333155403137205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.83074975013733, "step": 49000}
{"episode_reward": 125.8376798208797, "episode": 50.0, "batch_reward": 0.20453467985987664, "critic_loss": 0.6803575550615788, "actor_loss": -37.887341911315914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.595640420913696, "step": 50000}
{"episode_reward": 236.50303895456744, "episode": 51.0, "batch_reward": 0.20626628293097019, "critic_loss": 0.7181283751428127, "actor_loss": -37.689809677124025, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.216819524765015, "step": 51000}
{"episode_reward": 399.1514011566997, "episode": 52.0, "batch_reward": 0.21032157166302204, "critic_loss": 0.6925449352860451, "actor_loss": -37.62974627685547, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.69156241416931, "step": 52000}
{"episode_reward": 384.506815063287, "episode": 53.0, "batch_reward": 0.21301750840246678, "critic_loss": 0.6805097111463547, "actor_loss": -37.49068511962891, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.151551961898804, "step": 53000}
{"episode_reward": 406.521012784554, "episode": 54.0, "batch_reward": 0.21597075389325618, "critic_loss": 0.6225211901962757, "actor_loss": -37.43405376434326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.626152276992798, "step": 54000}
{"episode_reward": 438.55408895670473, "episode": 55.0, "batch_reward": 0.2211904930472374, "critic_loss": 0.6059840544313192, "actor_loss": -37.703861377716066, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.709128856658936, "step": 55000}
{"episode_reward": 410.2663392587354, "episode": 56.0, "batch_reward": 0.22471167488396168, "critic_loss": 0.5630843137353658, "actor_loss": -37.551846710205076, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.768842458724976, "step": 56000}
{"episode_reward": 425.9161415098032, "episode": 57.0, "batch_reward": 0.22831946493685246, "critic_loss": 0.5185002355873585, "actor_loss": -37.46352502059936, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.09042739868164, "step": 57000}
{"episode_reward": 351.1871201574008, "episode": 58.0, "batch_reward": 0.2304098427593708, "critic_loss": 0.4821058360338211, "actor_loss": -37.30422719955445, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.628600120544434, "step": 58000}
{"episode_reward": 439.57018436048554, "episode": 59.0, "batch_reward": 0.23417729197442533, "critic_loss": 0.49441215746104716, "actor_loss": -37.310499404907226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.69855237007141, "step": 59000}
{"episode_reward": 427.6258701909866, "episode": 60.0, "batch_reward": 0.23723158916831016, "critic_loss": 0.488683235168457, "actor_loss": -37.521953205108645, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.99995708465576, "step": 60000}
{"episode_reward": 398.59132714457206, "episode": 61.0, "batch_reward": 0.24076062509417534, "critic_loss": 0.4438315177708864, "actor_loss": -37.40832865524292, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.05350208282471, "step": 61000}
{"episode_reward": 440.42053839014, "episode": 62.0, "batch_reward": 0.24220081336796284, "critic_loss": 0.4545697981566191, "actor_loss": -37.50077703857422, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.15702223777771, "step": 62000}
{"episode_reward": 402.29686727248645, "episode": 63.0, "batch_reward": 0.24498227787017823, "critic_loss": 0.45560602194070815, "actor_loss": -37.329966121673586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.57477068901062, "step": 63000}
{"episode_reward": 430.5954073644497, "episode": 64.0, "batch_reward": 0.247947524279356, "critic_loss": 0.4353931660503149, "actor_loss": -37.44895741653443, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.659403085708618, "step": 64000}
{"episode_reward": 430.8242453174937, "episode": 65.0, "batch_reward": 0.25095960299670694, "critic_loss": 0.4375955210626125, "actor_loss": -37.55435456085205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.819223880767822, "step": 65000}
{"episode_reward": 456.5745890605174, "episode": 66.0, "batch_reward": 0.2551441332101822, "critic_loss": 0.42491677464544775, "actor_loss": -37.718237396240234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.810004472732544, "step": 66000}
{"episode_reward": 460.1887286423346, "episode": 67.0, "batch_reward": 0.2572778511941433, "critic_loss": 0.4376336857676506, "actor_loss": -37.916695766448974, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.910183429718018, "step": 67000}
{"episode_reward": 438.3561835955024, "episode": 68.0, "batch_reward": 0.2599732894897461, "critic_loss": 0.47325019823014736, "actor_loss": -37.51029463195801, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.566187381744385, "step": 68000}
{"episode_reward": 421.36748825649073, "episode": 69.0, "batch_reward": 0.2620547346174717, "critic_loss": 0.4617866138219833, "actor_loss": -37.46008920669556, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.64975595474243, "step": 69000}
{"episode_reward": 458.1923847563299, "episode": 70.0, "batch_reward": 0.2655830193012953, "critic_loss": 0.45210747957229613, "actor_loss": -38.03501498413086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.243329763412476, "step": 70000}
{"episode_reward": 382.9616675158964, "episode": 71.0, "batch_reward": 0.2666658917069435, "critic_loss": 0.4461615634262562, "actor_loss": -37.9174635848999, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.48737859725952, "step": 71000}
{"episode_reward": 413.8385385097672, "episode": 72.0, "batch_reward": 0.26909549470245836, "critic_loss": 0.44014026491343977, "actor_loss": -37.76723471069336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.67696499824524, "step": 72000}
{"episode_reward": 413.5626108419104, "episode": 73.0, "batch_reward": 0.27072575733065607, "critic_loss": 0.4607965456843376, "actor_loss": -37.93599210739136, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.736157655715942, "step": 73000}
{"episode_reward": 445.98841194344345, "episode": 74.0, "batch_reward": 0.2727731525450945, "critic_loss": 0.45655936998128893, "actor_loss": -38.28036200332642, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.936132192611694, "step": 74000}
{"episode_reward": 260.8011871832688, "episode": 75.0, "batch_reward": 0.2732954153865576, "critic_loss": 0.45317230582237245, "actor_loss": -38.08862378692627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.59322762489319, "step": 75000}
{"episode_reward": 444.92129768530594, "episode": 76.0, "batch_reward": 0.27483222451806066, "critic_loss": 0.47258068834245204, "actor_loss": -38.29650242614746, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.87580370903015, "step": 76000}
{"episode_reward": 164.69366609642344, "episode": 77.0, "batch_reward": 0.27427587531507014, "critic_loss": 0.4300037281215191, "actor_loss": -37.65031953430176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.631865739822388, "step": 77000}
{"episode_reward": 449.59654805707873, "episode": 78.0, "batch_reward": 0.27634752905368803, "critic_loss": 0.43547280733287336, "actor_loss": -37.9688155670166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.878333806991577, "step": 78000}
{"episode_reward": 418.4970093533988, "episode": 79.0, "batch_reward": 0.2785269791483879, "critic_loss": 0.42187588252127173, "actor_loss": -37.40382908630371, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.47603440284729, "step": 79000}
{"episode_reward": 466.63662811015007, "episode": 80.0, "batch_reward": 0.28102423961460593, "critic_loss": 0.4666139061897993, "actor_loss": -37.97368669509888, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.798614501953125, "step": 80000}
{"episode_reward": 369.70220576279894, "episode": 81.0, "batch_reward": 0.28178718462586405, "critic_loss": 0.4239354147017002, "actor_loss": -38.05108023452759, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.50300741195679, "step": 81000}
{"episode_reward": 423.34264663323967, "episode": 82.0, "batch_reward": 0.28337358808517454, "critic_loss": 0.42427369095385076, "actor_loss": -38.704735996246335, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.640722274780273, "step": 82000}
{"episode_reward": 271.41685861676507, "episode": 83.0, "batch_reward": 0.2831889229863882, "critic_loss": 0.4674426395446062, "actor_loss": -37.5411849937439, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.701165199279785, "step": 83000}
{"episode_reward": 468.65484655055866, "episode": 84.0, "batch_reward": 0.28526100200414656, "critic_loss": 0.45910814534127714, "actor_loss": -38.41928602981567, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.490760803222656, "step": 84000}
{"episode_reward": 430.90006077043734, "episode": 85.0, "batch_reward": 0.28661727224290373, "critic_loss": 0.4334262861162424, "actor_loss": -38.29147319793701, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.333998918533325, "step": 85000}
{"episode_reward": 432.17620023360683, "episode": 86.0, "batch_reward": 0.28874394215643406, "critic_loss": 0.423230398863554, "actor_loss": -38.22464455413818, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.135859727859497, "step": 86000}
{"episode_reward": 467.1737766849789, "episode": 87.0, "batch_reward": 0.2902939817458391, "critic_loss": 0.40593755334615705, "actor_loss": -38.1591781539917, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.642558097839355, "step": 87000}
{"episode_reward": 254.93605620112734, "episode": 88.0, "batch_reward": 0.29016000929474833, "critic_loss": 0.4101975882053375, "actor_loss": -37.71388812255859, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.604758501052856, "step": 88000}
{"episode_reward": 471.4951179234907, "episode": 89.0, "batch_reward": 0.2922378616333008, "critic_loss": 0.39502735242247583, "actor_loss": -38.66087504196167, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.38960075378418, "step": 89000}
{"episode_reward": 474.2614963190936, "episode": 90.0, "batch_reward": 0.29368214567005635, "critic_loss": 0.4366486450433731, "actor_loss": -39.08970612335205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.1971538066864, "step": 90000}
{"episode_reward": 245.79520369059125, "episode": 91.0, "batch_reward": 0.29452902510762213, "critic_loss": 0.42510251329839227, "actor_loss": -38.420737663269044, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.09229135513306, "step": 91000}
{"episode_reward": 415.0018704362255, "episode": 92.0, "batch_reward": 0.2962524174451828, "critic_loss": 0.4179962234646082, "actor_loss": -38.23317505264282, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.874678134918213, "step": 92000}
{"episode_reward": 463.8503166642662, "episode": 93.0, "batch_reward": 0.2961954958438873, "critic_loss": 0.40271162846684455, "actor_loss": -38.25676790618896, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.50791883468628, "step": 93000}
{"episode_reward": 462.32115564799915, "episode": 94.0, "batch_reward": 0.2988690887093544, "critic_loss": 0.4188938050121069, "actor_loss": -38.51837735748291, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.693233251571655, "step": 94000}
{"episode_reward": 315.5902089476133, "episode": 95.0, "batch_reward": 0.29950343909859656, "critic_loss": 0.40050622357428073, "actor_loss": -39.23074578857422, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.156482458114624, "step": 95000}
{"episode_reward": 463.65998985552505, "episode": 96.0, "batch_reward": 0.3000344041287899, "critic_loss": 0.38045691211521626, "actor_loss": -39.26447398757934, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.669077396392822, "step": 96000}
{"episode_reward": 469.543266677595, "episode": 97.0, "batch_reward": 0.30235691787302493, "critic_loss": 0.4019129580259323, "actor_loss": -39.54483575820923, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.609419345855713, "step": 97000}
{"episode_reward": 471.9349007483045, "episode": 98.0, "batch_reward": 0.3045540083795786, "critic_loss": 0.399161735996604, "actor_loss": -38.74350260162353, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.626795530319214, "step": 98000}
{"episode_reward": 488.97638318310254, "episode": 99.0, "batch_reward": 0.30752838212251665, "critic_loss": 0.39142152161896226, "actor_loss": -39.19247556686401, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.619508028030396, "step": 99000}
{"episode_reward": 460.8575599110236, "episode": 100.0, "batch_reward": 0.3082243604063988, "critic_loss": 0.3961361504644155, "actor_loss": -39.24815431213379, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.956871509552002, "step": 100000}
{"episode_reward": 473.45240992852536, "episode": 101.0, "batch_reward": 0.3091236345022917, "critic_loss": 0.3983652604520321, "actor_loss": -39.572721210479735, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.16985774040222, "step": 101000}
{"episode_reward": 472.86386385196636, "episode": 102.0, "batch_reward": 0.3098384029865265, "critic_loss": 0.42345680394768714, "actor_loss": -39.47384314727783, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.652194261550903, "step": 102000}
{"episode_reward": 449.08071458621953, "episode": 103.0, "batch_reward": 0.31155535027384756, "critic_loss": 0.4095008453428745, "actor_loss": -39.56743109130859, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.58501148223877, "step": 103000}
{"episode_reward": 468.94018760698793, "episode": 104.0, "batch_reward": 0.31404562905430794, "critic_loss": 0.43035941061377525, "actor_loss": -39.707262275695804, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.62149691581726, "step": 104000}
{"episode_reward": 418.0905312516522, "episode": 105.0, "batch_reward": 0.3160665093064308, "critic_loss": 0.43153652766346934, "actor_loss": -39.85377098464966, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.678647756576538, "step": 105000}
{"episode_reward": 457.79066019380394, "episode": 106.0, "batch_reward": 0.31594459593296054, "critic_loss": 0.4196857999414206, "actor_loss": -39.44574332427978, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.051496028900146, "step": 106000}
{"episode_reward": 497.68564515442307, "episode": 107.0, "batch_reward": 0.31865471068024637, "critic_loss": 0.4098729932159185, "actor_loss": -40.00074491119385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.622803926467896, "step": 107000}
{"episode_reward": 481.51357556138686, "episode": 108.0, "batch_reward": 0.31989911663532256, "critic_loss": 0.3807536070495844, "actor_loss": -40.02235312652588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.784196376800537, "step": 108000}
{"episode_reward": 460.60904561306546, "episode": 109.0, "batch_reward": 0.3208248797059059, "critic_loss": 0.3862721397727728, "actor_loss": -40.54517124176025, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.747649669647217, "step": 109000}
{"episode_reward": 448.85463885186573, "episode": 110.0, "batch_reward": 0.3230083765089512, "critic_loss": 0.4078137575685978, "actor_loss": -40.18667470169068, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.716243743896484, "step": 110000}
{"episode_reward": 476.6371801706984, "episode": 111.0, "batch_reward": 0.32370221361517904, "critic_loss": 0.4246047617942095, "actor_loss": -40.998135177612305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.63902258872986, "step": 111000}
{"episode_reward": 457.38635327871367, "episode": 112.0, "batch_reward": 0.3242657835185528, "critic_loss": 0.3995557360649109, "actor_loss": -40.44309616470337, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.81264901161194, "step": 112000}
{"episode_reward": 475.5114526984472, "episode": 113.0, "batch_reward": 0.3265995535850525, "critic_loss": 0.4106046440154314, "actor_loss": -40.60107790374756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.851475477218628, "step": 113000}
{"episode_reward": 375.2592877021084, "episode": 114.0, "batch_reward": 0.3267010572254658, "critic_loss": 0.4033421377390623, "actor_loss": -41.014538654327396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.570801734924316, "step": 114000}
{"episode_reward": 477.3597064878107, "episode": 115.0, "batch_reward": 0.3281099967360496, "critic_loss": 0.4071193820238113, "actor_loss": -40.75420706558228, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.75758171081543, "step": 115000}
{"episode_reward": 468.5343390770396, "episode": 116.0, "batch_reward": 0.3294870933294296, "critic_loss": 0.4293151067644358, "actor_loss": -41.01475686264038, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.820499420166016, "step": 116000}
{"episode_reward": 464.9714304283638, "episode": 117.0, "batch_reward": 0.3305338817834854, "critic_loss": 0.39238234017789364, "actor_loss": -40.89004418563843, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.670716285705566, "step": 117000}
{"episode_reward": 472.68850826857187, "episode": 118.0, "batch_reward": 0.33083797770738604, "critic_loss": 0.4091164706349373, "actor_loss": -41.13646422195435, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.006078481674194, "step": 118000}
{"episode_reward": 454.8784528521186, "episode": 119.0, "batch_reward": 0.3323064360320568, "critic_loss": 0.40645591078698634, "actor_loss": -41.488718074798584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.68541979789734, "step": 119000}
{"episode_reward": 404.3446209251756, "episode": 120.0, "batch_reward": 0.3330808365345001, "critic_loss": 0.3833493823111057, "actor_loss": -40.78474208831787, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.941994667053223, "step": 120000}
{"episode_reward": 483.3188840423679, "episode": 121.0, "batch_reward": 0.3349640724658966, "critic_loss": 0.3867695074230432, "actor_loss": -41.15057025527954, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.809879541397095, "step": 121000}
{"episode_reward": 457.050707964147, "episode": 122.0, "batch_reward": 0.3349428505599499, "critic_loss": 0.3653354535996914, "actor_loss": -41.238074047088624, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.079222679138184, "step": 122000}
{"episode_reward": 464.71635467233875, "episode": 123.0, "batch_reward": 0.3366276916861534, "critic_loss": 0.3942151231914759, "actor_loss": -40.38056421661377, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.582321643829346, "step": 123000}
{"episode_reward": 376.8232246788383, "episode": 124.0, "batch_reward": 0.3368800976574421, "critic_loss": 0.3864212310016155, "actor_loss": -41.32843349456787, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.743258714675903, "step": 124000}
{"episode_reward": 433.7188554121874, "episode": 125.0, "batch_reward": 0.3367204093337059, "critic_loss": 0.3752723340243101, "actor_loss": -41.371458961486816, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.598977088928223, "step": 125000}
{"episode_reward": 472.7948815850723, "episode": 126.0, "batch_reward": 0.33810191351175306, "critic_loss": 0.3689402340650558, "actor_loss": -41.52328807449341, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.784478425979614, "step": 126000}
{"episode_reward": 472.0943041512566, "episode": 127.0, "batch_reward": 0.33907068058848383, "critic_loss": 0.3676274471282959, "actor_loss": -41.49070537567139, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.57084083557129, "step": 127000}
{"episode_reward": 463.910627286208, "episode": 128.0, "batch_reward": 0.3403504226207733, "critic_loss": 0.3985527402162552, "actor_loss": -42.11873006820679, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.16755223274231, "step": 128000}
{"episode_reward": 449.82976791997015, "episode": 129.0, "batch_reward": 0.3413698562681675, "critic_loss": 0.3947222493439913, "actor_loss": -42.3113657913208, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.49039912223816, "step": 129000}
{"episode_reward": 446.56659949228975, "episode": 130.0, "batch_reward": 0.3424357399046421, "critic_loss": 0.3835573313087225, "actor_loss": -41.93531885910034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.69915771484375, "step": 130000}
{"episode_reward": 444.3335321587415, "episode": 131.0, "batch_reward": 0.34375636020302774, "critic_loss": 0.3994987158477306, "actor_loss": -42.71843391799927, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.08324575424194, "step": 131000}
{"episode_reward": 416.4169651348907, "episode": 132.0, "batch_reward": 0.343755535274744, "critic_loss": 0.3947034637928009, "actor_loss": -42.13011133956909, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.174153804779053, "step": 132000}
{"episode_reward": 458.8136551507915, "episode": 133.0, "batch_reward": 0.3437502181529999, "critic_loss": 0.3980277267694473, "actor_loss": -42.28594769668579, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.441377639770508, "step": 133000}
{"episode_reward": 489.8867459567254, "episode": 134.0, "batch_reward": 0.344601739436388, "critic_loss": 0.39718247386813166, "actor_loss": -42.419161071777346, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.66140604019165, "step": 134000}
{"episode_reward": 425.4461290746837, "episode": 135.0, "batch_reward": 0.3455748043358326, "critic_loss": 0.35857416833937167, "actor_loss": -42.60464211654663, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.578956842422485, "step": 135000}
{"episode_reward": 448.2896062525936, "episode": 136.0, "batch_reward": 0.34691812193393706, "critic_loss": 0.3841805740594864, "actor_loss": -43.13078539276123, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.758244514465332, "step": 136000}
{"episode_reward": 455.29598777547227, "episode": 137.0, "batch_reward": 0.34761311510205267, "critic_loss": 0.39396687552332876, "actor_loss": -42.336906749725344, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.591220378875732, "step": 137000}
{"episode_reward": 484.1537050350112, "episode": 138.0, "batch_reward": 0.34871750709414484, "critic_loss": 0.36150652623176577, "actor_loss": -42.20132702255249, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.72647976875305, "step": 138000}
{"episode_reward": 460.10735056908305, "episode": 139.0, "batch_reward": 0.34943917047977446, "critic_loss": 0.36645578771829607, "actor_loss": -42.313485496521, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.36562705039978, "step": 139000}
{"episode_reward": 433.28224290879143, "episode": 140.0, "batch_reward": 0.3500058096945286, "critic_loss": 0.3745746677070856, "actor_loss": -42.3371944694519, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.830310583114624, "step": 140000}
{"episode_reward": 483.2699214674272, "episode": 141.0, "batch_reward": 0.3505432252585888, "critic_loss": 0.3544662752449512, "actor_loss": -42.09696238327027, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.295066595077515, "step": 141000}
{"episode_reward": 495.15802990890506, "episode": 142.0, "batch_reward": 0.3515858065783978, "critic_loss": 0.3707897105664015, "actor_loss": -42.761651161193846, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.722378253936768, "step": 142000}
{"episode_reward": 481.3532332151605, "episode": 143.0, "batch_reward": 0.35362597432732584, "critic_loss": 0.3950080896317959, "actor_loss": -42.88299221420288, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.088075399398804, "step": 143000}
{"episode_reward": 469.50601019179055, "episode": 144.0, "batch_reward": 0.3541619918048382, "critic_loss": 0.3782962607741356, "actor_loss": -43.167271350860595, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.59349751472473, "step": 144000}
{"episode_reward": 456.6323148733351, "episode": 145.0, "batch_reward": 0.35511633095145223, "critic_loss": 0.3865721031278372, "actor_loss": -43.06848959350586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.91007375717163, "step": 145000}
{"episode_reward": 462.58468944468154, "episode": 146.0, "batch_reward": 0.3541223021745682, "critic_loss": 0.36166141703724863, "actor_loss": -42.87826747131348, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.70369815826416, "step": 146000}
{"episode_reward": 463.7785345847903, "episode": 147.0, "batch_reward": 0.3558535547852516, "critic_loss": 0.3523271659910679, "actor_loss": -43.156408946990965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.90020251274109, "step": 147000}
{"episode_reward": 453.25855884767367, "episode": 148.0, "batch_reward": 0.3570083991587162, "critic_loss": 0.3246098600924015, "actor_loss": -42.65677111434937, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.6340274810791, "step": 148000}
{"episode_reward": 495.6631284275564, "episode": 149.0, "batch_reward": 0.35815457212924956, "critic_loss": 0.3752326101511717, "actor_loss": -43.144106132507325, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.70532202720642, "step": 149000}
{"episode_reward": 451.78095878434027, "episode": 150.0, "batch_reward": 0.35853626346588136, "critic_loss": 0.355162087649107, "actor_loss": -43.124148830413816, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
