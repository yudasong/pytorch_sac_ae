{"episode": 1.0, "duration": 18.43981170654297, "episode_reward": 5.1931688606333894, "step": 1000}
{"episode": 2.0, "duration": 1.5918140411376953, "episode_reward": 454.7514538707513, "step": 2000}
{"episode": 3.0, "batch_reward": 0.2284316493893274, "actor_loss": -45.66720158827691, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 54.10048508644104, "episode_reward": 198.609607944258, "step": 3000}
{"episode": 4.0, "batch_reward": 0.220894970536232, "actor_loss": -44.294112815856934, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.725260257720947, "episode_reward": 239.38839978366107, "step": 4000}
{"episode": 5.0, "batch_reward": 0.22834606172144414, "actor_loss": -44.40224684143067, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.2803156375885, "episode_reward": 257.885402601559, "step": 5000}
{"episode": 6.0, "batch_reward": 0.23009384535253047, "actor_loss": -44.2857622756958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.646525621414185, "episode_reward": 206.91642785266885, "step": 6000}
{"episode": 7.0, "batch_reward": 0.2260319149941206, "actor_loss": -43.9148178024292, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.93403172492981, "episode_reward": 198.52724315474475, "step": 7000}
{"episode": 8.0, "batch_reward": 0.22464667409658431, "actor_loss": -43.722155387878416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.653659343719482, "episode_reward": 251.65284370535105, "step": 8000}
{"episode": 9.0, "batch_reward": 0.2258210840076208, "actor_loss": -43.68454483795166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.310747861862183, "episode_reward": 225.7186953858871, "step": 9000}
{"episode": 10.0, "batch_reward": 0.2262134243249893, "actor_loss": -38.54976316833496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 4011.3426411151886, "episode_reward": 206.08590844078532, "step": 10000}
{"episode": 11.0, "batch_reward": 0.22361427780985832, "actor_loss": -38.37005485534668, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 33.93736720085144, "episode_reward": 221.86891945680296, "step": 11000}
{"episode": 12.0, "batch_reward": 0.22458031058311462, "actor_loss": -35.62697635650635, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 443.9085659980774, "episode_reward": 254.25766482103853, "step": 12000}
{"episode": 13.0, "batch_reward": 0.22686508022248744, "actor_loss": -35.779646675109866, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.073862314224243, "episode_reward": 235.72237189730987, "step": 13000}
{"episode": 14.0, "batch_reward": 0.2312962603867054, "actor_loss": -34.19304306793213, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 429.90328216552734, "episode_reward": 345.8128592199871, "step": 14000}
{"episode": 15.0, "batch_reward": 0.23976063348352908, "actor_loss": -34.79163628387451, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 16.279369592666626, "episode_reward": 359.2903832738211, "step": 15000}
{"episode": 16.0, "batch_reward": 0.24630122105777263, "actor_loss": -33.49524053573609, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 431.1145122051239, "episode_reward": 325.7112003051075, "step": 16000}
{"episode": 17.0, "batch_reward": 0.2481333472877741, "actor_loss": -33.65786750793457, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.573578119277954, "episode_reward": 261.0218408657234, "step": 17000}
{"episode": 18.0, "batch_reward": 0.2509338235259056, "actor_loss": -33.02697101211548, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 435.1258306503296, "episode_reward": 297.1013670796986, "step": 18000}
{"episode": 19.0, "batch_reward": 0.2515242784023285, "actor_loss": -33.07139596557617, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.497501850128174, "episode_reward": 233.9835543909016, "step": 19000}
{"episode": 20.0, "batch_reward": 0.2527991652786732, "actor_loss": -32.21338251876831, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 441.2816822528839, "episode_reward": 291.6000641739935, "step": 20000}
{"episode": 21.0, "batch_reward": 0.25119354289770124, "actor_loss": -32.103649326324465, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 32.77506184577942, "episode_reward": 220.46472366997426, "step": 21000}
{"episode": 22.0, "batch_reward": 0.2531651338934898, "actor_loss": -32.542790531158445, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 439.96895122528076, "episode_reward": 345.1634712024198, "step": 22000}
{"episode": 23.0, "batch_reward": 0.25706684225797655, "actor_loss": -32.77528951263428, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.055869340896606, "episode_reward": 353.81074387925685, "step": 23000}
{"episode": 24.0, "batch_reward": 0.2617003292888403, "actor_loss": -32.55990591049194, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 412.51355624198914, "episode_reward": 346.99932833411583, "step": 24000}
{"episode": 25.0, "batch_reward": 0.26468647722899913, "actor_loss": -32.78425135040283, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 16.74195647239685, "episode_reward": 344.1560320542134, "step": 25000}
{"episode": 26.0, "batch_reward": 0.2684934996217489, "actor_loss": -33.19022910308838, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 417.4497539997101, "episode_reward": 365.03334300062915, "step": 26000}
{"episode": 27.0, "batch_reward": 0.27240191140770914, "actor_loss": -33.43928393936157, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 16.604310750961304, "episode_reward": 343.52198185661786, "step": 27000}
{"episode": 28.0, "batch_reward": 0.27455455261468886, "actor_loss": -33.153185905456546, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 408.7540862560272, "episode_reward": 307.1007822527022, "step": 28000}
{"episode": 29.0, "batch_reward": 0.2740782027989626, "actor_loss": -33.05802587509155, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.017607927322388, "episode_reward": 260.5402234996461, "step": 29000}
{"episode": 30.0, "batch_reward": 0.2749095701277256, "actor_loss": -33.30968452072143, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 429.8236153125763, "episode_reward": 326.5658965616765, "step": 30000}
{"episode": 31.0, "batch_reward": 0.27691051813960077, "actor_loss": -33.44442663574219, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.23562717437744, "episode_reward": 335.6938355466349, "step": 31000}
{"episode": 32.0, "batch_reward": 0.2765967855602503, "actor_loss": -33.806077926635744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 440.4247691631317, "episode_reward": 147.41671689127878, "step": 32000}
{"episode": 33.0, "batch_reward": 0.27517232243716716, "actor_loss": -33.515054401397705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.902448654174805, "episode_reward": 405.11144487552633, "step": 33000}
{"episode": 34.0, "batch_reward": 0.27833759467303754, "actor_loss": -34.3212579498291, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 435.8163917064667, "episode_reward": 350.9557776650415, "step": 34000}
{"episode": 35.0, "batch_reward": 0.2811509400308132, "actor_loss": -34.48810903930664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.129817962646484, "episode_reward": 361.88452304931445, "step": 35000}
{"episode": 36.0, "batch_reward": 0.28230394315719604, "actor_loss": -34.4706622467041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 445.21143674850464, "episode_reward": 343.8555184869598, "step": 36000}
{"episode": 37.0, "batch_reward": 0.2849322420656681, "actor_loss": -34.6130364151001, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.653096437454224, "episode_reward": 355.49731556636107, "step": 37000}
{"episode": 38.0, "batch_reward": 0.28635925698280335, "actor_loss": -35.18046040344238, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 440.174293756485, "episode_reward": 310.20361328543424, "step": 38000}
{"episode": 39.0, "batch_reward": 0.2856181496083736, "actor_loss": -35.129535804748535, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.093188762664795, "episode_reward": 250.5783529160266, "step": 39000}
{"episode": 40.0, "batch_reward": 0.28529677097499373, "actor_loss": -34.908412017822265, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 438.4164922237396, "episode_reward": 216.15019795343304, "step": 40000}
{"episode": 41.0, "batch_reward": 0.2835960962772369, "actor_loss": -34.751301597595216, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.205384492874146, "episode_reward": 221.74574536612403, "step": 41000}
{"episode": 42.0, "batch_reward": 0.2831256316155195, "actor_loss": -34.570914077758786, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 435.737366437912, "episode_reward": 324.6111340733874, "step": 42000}
{"episode": 43.0, "batch_reward": 0.283785386711359, "actor_loss": -34.65043128967285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.771548986434937, "episode_reward": 308.2398015490912, "step": 43000}
{"episode": 44.0, "batch_reward": 0.2839666239619255, "actor_loss": -34.060200199127195, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 437.9862370491028, "episode_reward": 309.4444054593029, "step": 44000}
{"episode": 45.0, "batch_reward": 0.28505181458592416, "actor_loss": -34.17825088500977, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.771360635757446, "episode_reward": 323.38572073985534, "step": 45000}
{"episode": 46.0, "batch_reward": 0.28616993403434754, "actor_loss": -33.791714752197265, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 451.13121509552, "episode_reward": 342.92098788410755, "step": 46000}
{"episode": 47.0, "batch_reward": 0.2877076489329338, "actor_loss": -33.87537007141113, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 16.755510091781616, "episode_reward": 340.46160056437884, "step": 47000}
{"episode": 48.0, "batch_reward": 0.28861191260814667, "actor_loss": -34.095267333984374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 439.1952884197235, "episode_reward": 372.0492875504191, "step": 48000}
{"episode": 49.0, "batch_reward": 0.2906750369668007, "actor_loss": -34.22515134429931, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.070266723632812, "episode_reward": 400.77655576251635, "step": 49000}
{"episode": 50.0, "batch_reward": 0.2918948256969452, "actor_loss": -34.34945573425293, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 435.0208773612976, "episode_reward": 289.1647943871986, "step": 50000}
{"episode": 51.0, "batch_reward": 0.2919439959228039, "actor_loss": -34.39643033599854, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.516244888305664, "episode_reward": 321.5485062268379, "step": 51000}
{"episode": 52.0, "batch_reward": 0.2924396240115166, "actor_loss": -34.16565531158447, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 434.02219820022583, "episode_reward": 286.5681451383747, "step": 52000}
{"episode": 53.0, "batch_reward": 0.2928954662978649, "actor_loss": -34.164410820007326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.064337730407715, "episode_reward": 318.9728033558702, "step": 53000}
{"episode": 54.0, "batch_reward": 0.2924921372234821, "actor_loss": -34.10727835083008, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 433.74687337875366, "episode_reward": 292.9994078611575, "step": 54000}
{"episode": 55.0, "batch_reward": 0.29201702985167505, "actor_loss": -34.09535227966309, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.31982135772705, "episode_reward": 285.32598142053735, "step": 55000}
{"episode": 56.0, "batch_reward": 0.2930256572663784, "actor_loss": -33.624190731048586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 442.1151793003082, "episode_reward": 314.93255326691036, "step": 56000}
{"episode": 57.0, "batch_reward": 0.2936965513527393, "actor_loss": -33.60346399307251, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.791463136672974, "episode_reward": 383.01269595200864, "step": 57000}
{"episode": 58.0, "batch_reward": 0.295573156028986, "actor_loss": -33.826751834869384, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 441.1569902896881, "episode_reward": 387.9971534827793, "step": 58000}
{"episode": 59.0, "batch_reward": 0.2975331119894981, "actor_loss": -33.98874788665771, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.008925199508667, "episode_reward": 412.9169719951476, "step": 59000}
{"episode": 60.0, "batch_reward": 0.2996418754756451, "actor_loss": -34.194838977813724, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 442.6241171360016, "episode_reward": 417.001668910319, "step": 60000}
{"episode": 61.0, "batch_reward": 0.30099485829472544, "actor_loss": -34.28105535888672, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.52739119529724, "episode_reward": 393.18429583672713, "step": 61000}
{"episode": 62.0, "batch_reward": 0.30248159047961237, "actor_loss": -33.79004441833496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 440.39290714263916, "episode_reward": 347.72833709443523, "step": 62000}
{"episode": 63.0, "batch_reward": 0.30275820645689966, "actor_loss": -33.82820155334473, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.3004207611084, "episode_reward": 399.28927312680753, "step": 63000}
{"episode": 64.0, "batch_reward": 0.30447066646814347, "actor_loss": -34.1078184967041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 440.09595799446106, "episode_reward": 351.64301777280167, "step": 64000}
{"episode": 65.0, "batch_reward": 0.30470792391896245, "actor_loss": -34.16481533050537, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.661152839660645, "episode_reward": 329.16377006448715, "step": 65000}
{"episode": 66.0, "batch_reward": 0.3056524490714073, "actor_loss": -34.37537683105469, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 440.5867512226105, "episode_reward": 368.9469873085376, "step": 66000}
{"episode": 67.0, "batch_reward": 0.30675110578536985, "actor_loss": -34.52184523773193, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.192344188690186, "episode_reward": 401.6722583151797, "step": 67000}
{"episode": 68.0, "batch_reward": 0.30818385928869246, "actor_loss": -34.57856216430664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 448.4977447986603, "episode_reward": 312.55690911431196, "step": 68000}
{"episode": 69.0, "batch_reward": 0.30787196895480157, "actor_loss": -34.44723533630371, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.702234983444214, "episode_reward": 368.24127838831674, "step": 69000}
{"episode": 70.0, "batch_reward": 0.308344675630331, "actor_loss": -34.90969845581055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 444.6179881095886, "episode_reward": 352.56946850730606, "step": 70000}
{"episode": 71.0, "batch_reward": 0.30966975530982016, "actor_loss": -35.03442803955078, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.477479696273804, "episode_reward": 368.66848876795416, "step": 71000}
{"episode": 72.0, "batch_reward": 0.31057107082009316, "actor_loss": -35.28030559539795, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 443.8534390926361, "episode_reward": 336.36007563640027, "step": 72000}
{"episode": 73.0, "batch_reward": 0.31103908547759057, "actor_loss": -35.347228187561036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 16.02916932106018, "episode_reward": 392.85354923764754, "step": 73000}
{"episode": 74.0, "batch_reward": 0.31103246194124223, "actor_loss": -34.62483625793457, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 445.6777677536011, "episode_reward": 355.6573533219485, "step": 74000}
{"episode": 75.0, "batch_reward": 0.312314759016037, "actor_loss": -34.68208815002441, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.137261390686035, "episode_reward": 341.3140066339664, "step": 75000}
{"episode": 76.0, "batch_reward": 0.3127183262109757, "actor_loss": -34.9072112121582, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 436.2022702693939, "episode_reward": 392.6831386477157, "step": 76000}
{"episode": 77.0, "batch_reward": 0.31397568628191946, "actor_loss": -35.0119188079834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.767770528793335, "episode_reward": 394.30264074267905, "step": 77000}
{"episode": 78.0, "batch_reward": 0.3149188612997532, "actor_loss": -35.24258234405517, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 439.75554966926575, "episode_reward": 347.3283965679876, "step": 78000}
{"episode": 79.0, "batch_reward": 0.31491185995936394, "actor_loss": -35.26028383636475, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 16.953301429748535, "episode_reward": 332.4558663241186, "step": 79000}
{"episode": 80.0, "batch_reward": 0.31559821194410326, "actor_loss": -35.91584992218018, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 447.8865644931793, "episode_reward": 264.7008295779071, "step": 80000}
{"episode": 81.0, "batch_reward": 0.3145021786391735, "actor_loss": -35.850054550170896, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.84316658973694, "episode_reward": 303.36253176726603, "step": 81000}
{"episode": 82.0, "batch_reward": 0.31403791618347165, "actor_loss": -35.89658682250977, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 440.65965151786804, "episode_reward": 305.42096426009834, "step": 82000}
{"episode": 83.0, "batch_reward": 0.314185603171587, "actor_loss": -35.91203410339355, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.11443257331848, "episode_reward": 317.4268262094424, "step": 83000}
{"episode": 84.0, "batch_reward": 0.3141866380274296, "actor_loss": -36.662551445007324, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 437.07378029823303, "episode_reward": 329.2928261094531, "step": 84000}
{"episode": 85.0, "batch_reward": 0.3142782419025898, "actor_loss": -36.63044179534912, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.83828377723694, "episode_reward": 349.1906373807816, "step": 85000}
{"episode": 86.0, "batch_reward": 0.31557869747281075, "actor_loss": -36.98735075378418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 445.51478457450867, "episode_reward": 379.2680731541468, "step": 86000}
{"episode": 87.0, "batch_reward": 0.31623018833994865, "actor_loss": -37.043340133666995, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.33953046798706, "episode_reward": 401.9636987271935, "step": 87000}
{"episode": 88.0, "batch_reward": 0.316947922796011, "actor_loss": -37.58243340301514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 440.25880575180054, "episode_reward": 343.18626558173827, "step": 88000}
{"episode": 89.0, "batch_reward": 0.3167670726776123, "actor_loss": -37.58713347625732, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.34723973274231, "episode_reward": 336.65148839173185, "step": 89000}
{"episode": 90.0, "batch_reward": 0.31804769137501715, "actor_loss": -37.81049240112305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 446.80810809135437, "episode_reward": 337.90717933363885, "step": 90000}
{"episode": 91.0, "batch_reward": 0.3179107284247875, "actor_loss": -37.86922675323486, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 40.13955330848694, "episode_reward": 332.92215261568447, "step": 91000}
{"episode": 92.0, "batch_reward": 0.3175795480310917, "actor_loss": -38.18708003997803, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 437.88673758506775, "episode_reward": 351.4692824144769, "step": 92000}
{"episode": 93.0, "batch_reward": 0.31775591340661047, "actor_loss": -38.26297597503662, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.318140506744385, "episode_reward": 326.3331596458206, "step": 93000}
{"episode": 94.0, "batch_reward": 0.31811942809820176, "actor_loss": -38.69453311157226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 446.69995737075806, "episode_reward": 385.72107485262796, "step": 94000}
{"episode": 95.0, "batch_reward": 0.31917589509487154, "actor_loss": -38.81637065887451, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.4350848197937, "episode_reward": 383.85483047624405, "step": 95000}
{"episode": 96.0, "batch_reward": 0.3199368085861206, "actor_loss": -38.84229737854004, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 442.613920211792, "episode_reward": 416.35608367341734, "step": 96000}
{"episode": 97.0, "batch_reward": 0.32069231250882146, "actor_loss": -38.919802017211914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.368797540664673, "episode_reward": 369.9490665441762, "step": 97000}
{"episode": 98.0, "batch_reward": 0.320972465544939, "actor_loss": -39.348151222229006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 444.1909022331238, "episode_reward": 415.61554610574535, "step": 98000}
{"episode": 99.0, "batch_reward": 0.32194964334368703, "actor_loss": -39.381612937927244, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.715355396270752, "episode_reward": 413.90053464294726, "step": 99000}
{"episode": 100.0, "batch_reward": 0.32363747173547747, "actor_loss": -39.52648477172851, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 446.7584743499756, "episode_reward": 446.31689853506083, "step": 100000}
{"episode": 101.0, "batch_reward": 0.32425630250573156, "actor_loss": -39.66019906616211, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.92124319076538, "episode_reward": 427.54065456927225, "step": 101000}
{"episode": 102.0, "batch_reward": 0.32570045563578603, "actor_loss": -39.869117057800295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 443.8781464099884, "episode_reward": 420.453487889501, "step": 102000}
{"episode": 103.0, "batch_reward": 0.32624776661396027, "actor_loss": -39.94235262298584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.146179914474487, "episode_reward": 417.48130346751464, "step": 103000}
{"episode": 104.0, "batch_reward": 0.326937068849802, "actor_loss": -39.59099548339844, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 441.93899416923523, "episode_reward": 386.7387251086141, "step": 104000}
{"episode": 105.0, "batch_reward": 0.32758822283148764, "actor_loss": -39.594081520080564, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.686034440994263, "episode_reward": 409.93542232924926, "step": 105000}
{"episode": 106.0, "batch_reward": 0.3286325518786907, "actor_loss": -39.28811779022217, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 443.41931319236755, "episode_reward": 365.6813509289807, "step": 106000}
{"episode": 107.0, "batch_reward": 0.3285808490216732, "actor_loss": -39.21638261413574, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.01696252822876, "episode_reward": 375.5015330346481, "step": 107000}
{"episode": 108.0, "batch_reward": 0.3299399492740631, "actor_loss": -39.031421875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 440.2600917816162, "episode_reward": 373.042834800938, "step": 108000}
{"episode": 109.0, "batch_reward": 0.3300489258468151, "actor_loss": -39.06601098632812, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.240699291229248, "episode_reward": 361.3763334799979, "step": 109000}
{"episode": 110.0, "batch_reward": 0.32996169456839564, "actor_loss": -38.208602043151856, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 440.3008029460907, "episode_reward": 389.72555356515625, "step": 110000}
{"episode": 111.0, "batch_reward": 0.33028717252612116, "actor_loss": -38.182470252990726, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 33.206371784210205, "episode_reward": 389.6212084679652, "step": 111000}
{"episode": 112.0, "batch_reward": 0.3308080414235592, "actor_loss": -37.57694911956787, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 448.01516032218933, "episode_reward": 380.49902678674675, "step": 112000}
{"episode": 113.0, "batch_reward": 0.3315115181207657, "actor_loss": -37.648164962768554, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.518259286880493, "episode_reward": 372.2371977905741, "step": 113000}
{"episode": 114.0, "batch_reward": 0.3317867783606052, "actor_loss": -36.23259043884277, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 441.58877301216125, "episode_reward": 373.8712406045316, "step": 114000}
{"episode": 115.0, "batch_reward": 0.3329712173342705, "actor_loss": -36.33416301727295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.65263605117798, "episode_reward": 380.00219404499774, "step": 115000}
{"episode": 116.0, "batch_reward": 0.3322019675374031, "actor_loss": -36.11460620880127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 442.10952830314636, "episode_reward": 378.8400707893231, "step": 116000}
{"episode": 117.0, "batch_reward": 0.33308473059535026, "actor_loss": -36.12941436004639, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.147712469100952, "episode_reward": 366.24742071814524, "step": 117000}
{"episode": 118.0, "batch_reward": 0.33317827147245405, "actor_loss": -35.749300048828125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 436.36139154434204, "episode_reward": 399.37001110891106, "step": 118000}
{"episode": 119.0, "batch_reward": 0.3338110698759556, "actor_loss": -35.85316355133057, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.30258297920227, "episode_reward": 397.1693844795521, "step": 119000}
{"episode": 120.0, "batch_reward": 0.33431442332267763, "actor_loss": -34.89497401428223, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 444.306880235672, "episode_reward": 350.1931027464345, "step": 120000}
{"episode": 121.0, "batch_reward": 0.33442867279052735, "actor_loss": -34.89587116241455, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 32.899810552597046, "episode_reward": 341.1507336584904, "step": 121000}
{"episode": 122.0, "batch_reward": 0.3349456770122051, "actor_loss": -34.83447778320313, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 443.17179894447327, "episode_reward": 399.31426150863354, "step": 122000}
{"episode": 123.0, "batch_reward": 0.33481206840276717, "actor_loss": -34.8245313873291, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.146735191345215, "episode_reward": 418.84256954122753, "step": 123000}
{"episode": 124.0, "batch_reward": 0.3359474556148052, "actor_loss": -34.46545848083496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 441.4023208618164, "episode_reward": 396.22705434188276, "step": 124000}
{"episode": 125.0, "batch_reward": 0.33594099137187006, "actor_loss": -34.543523361206056, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.233043432235718, "episode_reward": 358.3331661962179, "step": 125000}
{"episode": 126.0, "batch_reward": 0.337211880594492, "actor_loss": -34.46735361862183, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 449.2811629772186, "episode_reward": 377.5728238430257, "step": 126000}
{"episode": 127.0, "batch_reward": 0.33721526992321016, "actor_loss": -34.48180917358398, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.658541202545166, "episode_reward": 370.02145462152095, "step": 127000}
{"episode": 128.0, "batch_reward": 0.33681433591246607, "actor_loss": -34.14943021011352, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 446.209557056427, "episode_reward": 395.8074361497084, "step": 128000}
{"episode": 129.0, "batch_reward": 0.33753764888644217, "actor_loss": -34.22539347076416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.69958233833313, "episode_reward": 384.3493715049135, "step": 129000}
{"episode": 130.0, "batch_reward": 0.3375778618454933, "actor_loss": -34.15180368804932, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 441.30011558532715, "episode_reward": 379.89493743576105, "step": 130000}
{"episode": 131.0, "batch_reward": 0.33809927222132685, "actor_loss": -34.16768790435791, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.995325326919556, "episode_reward": 397.0333615706159, "step": 131000}
{"episode": 132.0, "batch_reward": 0.33864208686351777, "actor_loss": -33.91844264602661, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 445.2367584705353, "episode_reward": 392.75376485911886, "step": 132000}
{"episode": 133.0, "batch_reward": 0.33869156157970426, "actor_loss": -33.9129006729126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.066505193710327, "episode_reward": 388.29368337569264, "step": 133000}
{"episode": 134.0, "batch_reward": 0.34026487785577775, "actor_loss": -33.93668140411377, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 456.6583878993988, "episode_reward": 408.84014277399274, "step": 134000}
{"episode": 135.0, "batch_reward": 0.339972784101963, "actor_loss": -33.8599728012085, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.493892192840576, "episode_reward": 382.3094016385715, "step": 135000}
{"episode": 136.0, "batch_reward": 0.34076807180047036, "actor_loss": -33.915316993713375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 453.1054768562317, "episode_reward": 398.80279301473354, "step": 136000}
{"episode": 137.0, "batch_reward": 0.3406773151755333, "actor_loss": -33.97268006896973, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.03519058227539, "episode_reward": 394.502114782431, "step": 137000}
{"episode": 138.0, "batch_reward": 0.340896398216486, "actor_loss": -33.80239511871338, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 443.63174962997437, "episode_reward": 404.90987102653537, "step": 138000}
{"episode": 139.0, "batch_reward": 0.3417280970811844, "actor_loss": -33.866394550323484, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.487657070159912, "episode_reward": 398.3492440981193, "step": 139000}
{"episode": 140.0, "batch_reward": 0.3423784526288509, "actor_loss": -33.94961361694336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 447.90090560913086, "episode_reward": 391.7759918913188, "step": 140000}
{"episode": 141.0, "batch_reward": 0.342401446133852, "actor_loss": -34.02835796356201, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.768309593200684, "episode_reward": 409.2557013207167, "step": 141000}
{"episode": 142.0, "batch_reward": 0.3423345616161823, "actor_loss": -34.13419986724853, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 442.44517040252686, "episode_reward": 410.0958102421811, "step": 142000}
{"episode": 143.0, "batch_reward": 0.3430235677957535, "actor_loss": -34.172974197387695, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 17.794719696044922, "episode_reward": 407.6095079258064, "step": 143000}
{"episode": 144.0, "batch_reward": 0.3437161002755165, "actor_loss": -34.714307548522946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 441.8092188835144, "episode_reward": 420.75805238924727, "step": 144000}
{"episode": 145.0, "batch_reward": 0.34443521428108215, "actor_loss": -34.77942366027832, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 18.227006673812866, "episode_reward": 433.9517904422196, "step": 145000}
{"episode": 146.0, "batch_reward": 0.3452453660964966, "actor_loss": -34.560628120422365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 443.9340760707855, "episode_reward": 405.3484004735697, "step": 146000}
{"episode": 147.0, "batch_reward": 0.34527940353751185, "actor_loss": -34.588360832214356, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 15.79810881614685, "episode_reward": 405.88220259294513, "step": 147000}
{"episode": 148.0, "batch_reward": 0.3460990023612976, "actor_loss": -34.74621516418457, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 415.10808181762695, "episode_reward": 407.9078585802348, "step": 148000}
{"episode": 149.0, "batch_reward": 0.3459701272845268, "actor_loss": -34.77143870544434, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 16.905745029449463, "episode_reward": 410.3901386384424, "step": 149000}
{"episode": 150.0, "batch_reward": 0.3461800330579281, "actor_loss": -34.645802261352536, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
