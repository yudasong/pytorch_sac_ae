{"episode_reward": 0.0, "episode": 1.0, "duration": 17.23096227645874, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.4636471271514893, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.2191261327258743, "critic_loss": 0.04486411704072215, "actor_loss": -19.41190675913342, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 60.179181814193726, "step": 3000}
{"episode_reward": 43.71405177255502, "episode": 4.0, "batch_reward": 0.15669879032671452, "critic_loss": 0.06009045364521444, "actor_loss": -20.240533015727998, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.882187128067017, "step": 4000}
{"episode_reward": 126.97152466759606, "episode": 5.0, "batch_reward": 0.16527919064462185, "critic_loss": 0.08348089541494846, "actor_loss": -17.230548100948333, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89737844467163, "step": 5000}
{"episode_reward": 192.287940272102, "episode": 6.0, "batch_reward": 0.15927993635088206, "critic_loss": 0.06796239129640162, "actor_loss": -18.246275616645814, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87172269821167, "step": 6000}
{"episode_reward": 64.77568929938688, "episode": 7.0, "batch_reward": 0.1412152708172798, "critic_loss": 0.06389313793368638, "actor_loss": -17.12441330242157, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.861689567565918, "step": 7000}
{"episode_reward": 38.67992891269975, "episode": 8.0, "batch_reward": 0.12644873493164777, "critic_loss": 0.08180916857719421, "actor_loss": -15.395667057037354, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.187893629074097, "step": 8000}
{"episode_reward": 25.231615596866526, "episode": 9.0, "batch_reward": 0.11688473093509674, "critic_loss": 0.09624482867494226, "actor_loss": -15.855074469566345, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.82670760154724, "step": 9000}
{"episode_reward": 46.517825054419674, "episode": 10.0, "batch_reward": 0.1125088630914688, "critic_loss": 0.0980152244567871, "actor_loss": -15.028104297161102, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.805092573165894, "step": 10000}
{"episode_reward": 86.8329202617531, "episode": 11.0, "batch_reward": 0.10519272183999419, "critic_loss": 0.10183500232174993, "actor_loss": -14.65881122303009, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.29797315597534, "step": 11000}
{"episode_reward": 22.401837256910945, "episode": 12.0, "batch_reward": 0.10437240014597773, "critic_loss": 0.10119075249135494, "actor_loss": -14.723272813796997, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.802024841308594, "step": 12000}
{"episode_reward": 111.77130550564615, "episode": 13.0, "batch_reward": 0.10455912332981825, "critic_loss": 0.12305314137414097, "actor_loss": -14.916749433517456, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.816014051437378, "step": 13000}
{"episode_reward": 191.1614978137793, "episode": 14.0, "batch_reward": 0.10677538807317614, "critic_loss": 0.1827210480645299, "actor_loss": -14.211733310699463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.884429693222046, "step": 14000}
{"episode_reward": 31.509537218709504, "episode": 15.0, "batch_reward": 0.10286276358738541, "critic_loss": 0.1707022603712976, "actor_loss": -15.221072790145874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.856287240982056, "step": 15000}
{"episode_reward": 39.75532837212492, "episode": 16.0, "batch_reward": 0.09793423973023892, "critic_loss": 0.17690297221392393, "actor_loss": -15.06599303817749, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.854868412017822, "step": 16000}
{"episode_reward": 50.606088115145376, "episode": 17.0, "batch_reward": 0.09417202823609114, "critic_loss": 0.15967442256957293, "actor_loss": -14.004486750602721, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.873238563537598, "step": 17000}
{"episode_reward": 19.98638350938474, "episode": 18.0, "batch_reward": 0.09359232054278255, "critic_loss": 0.17397189626097678, "actor_loss": -14.174463252067566, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.85471510887146, "step": 18000}
{"episode_reward": 110.01537971400708, "episode": 19.0, "batch_reward": 0.09107901630178093, "critic_loss": 0.1860416649952531, "actor_loss": -14.663087921142578, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87292242050171, "step": 19000}
{"episode_reward": 24.250337452727003, "episode": 20.0, "batch_reward": 0.08875186060741544, "critic_loss": 0.23018680967390537, "actor_loss": -14.627805752754211, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.876340627670288, "step": 20000}
{"episode_reward": 58.088404682225956, "episode": 21.0, "batch_reward": 0.09016863954067231, "critic_loss": 0.265433495298028, "actor_loss": -14.975210324287415, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.2038676738739, "step": 21000}
{"episode_reward": 122.4781111899376, "episode": 22.0, "batch_reward": 0.090930041231215, "critic_loss": 0.3315570066124201, "actor_loss": -14.877007486343384, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.859469175338745, "step": 22000}
{"episode_reward": 124.48010536459661, "episode": 23.0, "batch_reward": 0.09460999001190067, "critic_loss": 0.36229720485955474, "actor_loss": -14.827202164649963, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.879542589187622, "step": 23000}
{"episode_reward": 190.52685297335952, "episode": 24.0, "batch_reward": 0.09521903173997998, "critic_loss": 0.4158388966023922, "actor_loss": -15.663612753868103, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.84867548942566, "step": 24000}
{"episode_reward": 70.30581293437756, "episode": 25.0, "batch_reward": 0.09516526522114872, "critic_loss": 0.3951089098453522, "actor_loss": -15.203681746482848, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89889097213745, "step": 25000}
{"episode_reward": 86.11060318493521, "episode": 26.0, "batch_reward": 0.09692797376587987, "critic_loss": 0.4907084932476282, "actor_loss": -16.75098621749878, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.855772972106934, "step": 26000}
{"episode_reward": 243.26991352280993, "episode": 27.0, "batch_reward": 0.0998952151313424, "critic_loss": 0.557954942882061, "actor_loss": -19.129703720092774, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.84838342666626, "step": 27000}
{"episode_reward": 67.70417071162923, "episode": 28.0, "batch_reward": 0.09706021632254123, "critic_loss": 0.4493541138619184, "actor_loss": -19.826964794158936, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.855597257614136, "step": 28000}
{"episode_reward": 31.096584739500496, "episode": 29.0, "batch_reward": 0.09546274913102389, "critic_loss": 0.3871701856404543, "actor_loss": -21.124361614227293, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.882731676101685, "step": 29000}
{"episode_reward": 35.973664040293606, "episode": 30.0, "batch_reward": 0.09588848223537207, "critic_loss": 0.40035216246545313, "actor_loss": -21.830608753204345, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88077187538147, "step": 30000}
{"episode_reward": 143.4476231204569, "episode": 31.0, "batch_reward": 0.09626291280984879, "critic_loss": 0.4215928198993206, "actor_loss": -22.021450691223144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.22162699699402, "step": 31000}
{"episode_reward": 92.92327266405412, "episode": 32.0, "batch_reward": 0.09554630777984857, "critic_loss": 0.381228582367301, "actor_loss": -21.919438232421875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.879342555999756, "step": 32000}
{"episode_reward": 54.9527204671345, "episode": 33.0, "batch_reward": 0.09473629719763994, "critic_loss": 0.3861321148574352, "actor_loss": -21.578002208709716, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.870373010635376, "step": 33000}
{"episode_reward": 68.98606051312282, "episode": 34.0, "batch_reward": 0.09345020438730717, "critic_loss": 0.34833381362259386, "actor_loss": -21.287499210357666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.853065967559814, "step": 34000}
{"episode_reward": 30.266017944675266, "episode": 35.0, "batch_reward": 0.09137561028450727, "critic_loss": 0.339287463337183, "actor_loss": -20.967824634552002, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88363528251648, "step": 35000}
{"episode_reward": 48.141190819787155, "episode": 36.0, "batch_reward": 0.0921090310253203, "critic_loss": 0.35456741315126417, "actor_loss": -20.83349571609497, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.82576632499695, "step": 36000}
{"episode_reward": 180.4503539465841, "episode": 37.0, "batch_reward": 0.09209032167121768, "critic_loss": 0.3832594166994095, "actor_loss": -20.53753090286255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.856127500534058, "step": 37000}
{"episode_reward": 40.443540178260726, "episode": 38.0, "batch_reward": 0.09141793642938137, "critic_loss": 0.3921214289665222, "actor_loss": -20.24257186126709, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.83833622932434, "step": 38000}
{"episode_reward": 50.0194372397324, "episode": 39.0, "batch_reward": 0.09127111173421144, "critic_loss": 0.41880948626995085, "actor_loss": -20.006179599761964, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.865214586257935, "step": 39000}
{"episode_reward": 118.57693199451272, "episode": 40.0, "batch_reward": 0.09111926275491715, "critic_loss": 0.3760509191304445, "actor_loss": -19.752825092315675, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.865947008132935, "step": 40000}
{"episode_reward": 66.22981953802075, "episode": 41.0, "batch_reward": 0.0908226483426988, "critic_loss": 0.4259558204114437, "actor_loss": -19.410350685119628, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.25800967216492, "step": 41000}
{"episode_reward": 88.64039751719416, "episode": 42.0, "batch_reward": 0.09100944206118583, "critic_loss": 0.39184930801391604, "actor_loss": -19.311137044906616, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.869248390197754, "step": 42000}
{"episode_reward": 110.85279453681217, "episode": 43.0, "batch_reward": 0.09198742006346583, "critic_loss": 0.39039865538477897, "actor_loss": -19.213101654052736, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.880314588546753, "step": 43000}
{"episode_reward": 117.23219461995001, "episode": 44.0, "batch_reward": 0.09473961184173822, "critic_loss": 0.40765269750356675, "actor_loss": -19.24861532974243, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.878319263458252, "step": 44000}
{"episode_reward": 409.5356837293016, "episode": 45.0, "batch_reward": 0.10087511125952005, "critic_loss": 0.41056058076024055, "actor_loss": -19.700850704193115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.84813404083252, "step": 45000}
{"episode_reward": 314.9950874747015, "episode": 46.0, "batch_reward": 0.1060146841481328, "critic_loss": 0.40698584473133087, "actor_loss": -20.04277272796631, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.86982011795044, "step": 46000}
{"episode_reward": 306.96381969677145, "episode": 47.0, "batch_reward": 0.11145997060090304, "critic_loss": 0.40664348523318766, "actor_loss": -20.211023975372314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.835360527038574, "step": 47000}
{"episode_reward": 341.5377831275985, "episode": 48.0, "batch_reward": 0.11480350928008556, "critic_loss": 0.4000081132799387, "actor_loss": -20.258600419998167, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.86621856689453, "step": 48000}
{"episode_reward": 338.5617534992574, "episode": 49.0, "batch_reward": 0.12012197618931532, "critic_loss": 0.359807899273932, "actor_loss": -20.506157655715942, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.83877730369568, "step": 49000}
{"episode_reward": 264.7203466766674, "episode": 50.0, "batch_reward": 0.12322968921810389, "critic_loss": 0.36439926745742557, "actor_loss": -20.62699174118042, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.867263078689575, "step": 50000}
{"episode_reward": 381.78826488440893, "episode": 51.0, "batch_reward": 0.12907957096397876, "critic_loss": 0.3738075314462185, "actor_loss": -20.816950273513793, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.24819254875183, "step": 51000}
{"episode_reward": 441.8872973777092, "episode": 52.0, "batch_reward": 0.13576741014420987, "critic_loss": 0.3465336731672287, "actor_loss": -21.520957609176637, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.85963225364685, "step": 52000}
{"episode_reward": 458.7718113608333, "episode": 53.0, "batch_reward": 0.14053685856610537, "critic_loss": 0.32345757418870924, "actor_loss": -21.689766729354858, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90859842300415, "step": 53000}
{"episode_reward": 429.13036658171416, "episode": 54.0, "batch_reward": 0.14671354971826076, "critic_loss": 0.31762396249175073, "actor_loss": -22.088497165679932, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.908814907073975, "step": 54000}
{"episode_reward": 448.35370164172946, "episode": 55.0, "batch_reward": 0.15226140163093804, "critic_loss": 0.31274456085264685, "actor_loss": -22.100394845962523, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.905529022216797, "step": 55000}
{"episode_reward": 478.95938266936685, "episode": 56.0, "batch_reward": 0.15859188375622035, "critic_loss": 0.29539810034632685, "actor_loss": -22.77966786956787, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.875911474227905, "step": 56000}
{"episode_reward": 443.5667813111193, "episode": 57.0, "batch_reward": 0.16306367722153664, "critic_loss": 0.29926223248243333, "actor_loss": -23.19635892868042, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87015700340271, "step": 57000}
{"episode_reward": 467.28641364025185, "episode": 58.0, "batch_reward": 0.1688553708344698, "critic_loss": 0.2923098348528147, "actor_loss": -23.18955851364136, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.83569359779358, "step": 58000}
{"episode_reward": 438.2949246383274, "episode": 59.0, "batch_reward": 0.17205643710494042, "critic_loss": 0.29972772524505853, "actor_loss": -23.645729766845704, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.864081621170044, "step": 59000}
{"episode_reward": 445.26736202194314, "episode": 60.0, "batch_reward": 0.17806134857237338, "critic_loss": 0.2872803115546703, "actor_loss": -24.25995182418823, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.8660147190094, "step": 60000}
{"episode_reward": 466.6721334785564, "episode": 61.0, "batch_reward": 0.18294603810459376, "critic_loss": 0.28831027674674986, "actor_loss": -24.38879610443115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.15119409561157, "step": 61000}
{"episode_reward": 456.25849516631166, "episode": 62.0, "batch_reward": 0.1871197333484888, "critic_loss": 0.28607921064645053, "actor_loss": -24.50861716079712, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.83239483833313, "step": 62000}
{"episode_reward": 481.44044667843997, "episode": 63.0, "batch_reward": 0.19114245368540286, "critic_loss": 0.2916019734814763, "actor_loss": -24.873969787597655, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.823487520217896, "step": 63000}
{"episode_reward": 508.27152071082804, "episode": 64.0, "batch_reward": 0.19656885902583598, "critic_loss": 0.2830169442892075, "actor_loss": -25.31094358062744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.86072063446045, "step": 64000}
{"episode_reward": 472.05838462485826, "episode": 65.0, "batch_reward": 0.20105238768458367, "critic_loss": 0.30334454859793186, "actor_loss": -25.91813541793823, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.84010648727417, "step": 65000}
{"episode_reward": 473.5396247307671, "episode": 66.0, "batch_reward": 0.2061492068618536, "critic_loss": 0.2833916708678007, "actor_loss": -26.187699703216552, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.837289094924927, "step": 66000}
{"episode_reward": 485.978456731501, "episode": 67.0, "batch_reward": 0.20889992305636407, "critic_loss": 0.2845183252543211, "actor_loss": -26.792742797851563, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.85649037361145, "step": 67000}
{"episode_reward": 441.975052290101, "episode": 68.0, "batch_reward": 0.21239253535866737, "critic_loss": 0.3033240325152874, "actor_loss": -26.435193836212157, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.860699892044067, "step": 68000}
{"episode_reward": 488.7137226463019, "episode": 69.0, "batch_reward": 0.2156788905709982, "critic_loss": 0.28961911782622335, "actor_loss": -27.16185903930664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.881246328353882, "step": 69000}
{"episode_reward": 471.55334561905005, "episode": 70.0, "batch_reward": 0.22037314987182618, "critic_loss": 0.2962609907537699, "actor_loss": -27.54923731994629, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.85579228401184, "step": 70000}
{"episode_reward": 467.48077652256194, "episode": 71.0, "batch_reward": 0.22396883323788644, "critic_loss": 0.29469187556952237, "actor_loss": -27.534994995117188, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.20375204086304, "step": 71000}
{"episode_reward": 488.3843345836523, "episode": 72.0, "batch_reward": 0.227095289722085, "critic_loss": 0.29551435878127813, "actor_loss": -27.82202500152588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.894598484039307, "step": 72000}
{"episode_reward": 482.7396212060575, "episode": 73.0, "batch_reward": 0.23102783542871475, "critic_loss": 0.27007321831583975, "actor_loss": -28.24313228225708, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.845590353012085, "step": 73000}
{"episode_reward": 471.0006317996265, "episode": 74.0, "batch_reward": 0.2341364367157221, "critic_loss": 0.27897218297421933, "actor_loss": -28.723247505187988, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.851768493652344, "step": 74000}
{"episode_reward": 488.6213466022133, "episode": 75.0, "batch_reward": 0.2389331688284874, "critic_loss": 0.2741589326038957, "actor_loss": -28.925010162353516, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87622094154358, "step": 75000}
{"episode_reward": 503.69224045363507, "episode": 76.0, "batch_reward": 0.24071348808705806, "critic_loss": 0.2769273885115981, "actor_loss": -29.006356414794922, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.875189542770386, "step": 76000}
{"episode_reward": 466.2336792288389, "episode": 77.0, "batch_reward": 0.24203133495151996, "critic_loss": 0.2710727108716965, "actor_loss": -29.27435847854614, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.883062601089478, "step": 77000}
{"episode_reward": 237.14988172490519, "episode": 78.0, "batch_reward": 0.24466567254066468, "critic_loss": 0.2794735552817583, "actor_loss": -29.616960639953614, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87406849861145, "step": 78000}
{"episode_reward": 488.8539565273171, "episode": 79.0, "batch_reward": 0.24679681695997716, "critic_loss": 0.2863240093365312, "actor_loss": -29.591435039520263, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.85751748085022, "step": 79000}
{"episode_reward": 496.3455758742146, "episode": 80.0, "batch_reward": 0.250354075267911, "critic_loss": 0.2846450889259577, "actor_loss": -29.905689086914062, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.86908793449402, "step": 80000}
{"episode_reward": 495.5064913736062, "episode": 81.0, "batch_reward": 0.2547780166119337, "critic_loss": 0.290557481944561, "actor_loss": -30.841926265716552, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.160255670547485, "step": 81000}
{"episode_reward": 511.77502965978414, "episode": 82.0, "batch_reward": 0.2578141926974058, "critic_loss": 0.2739085482135415, "actor_loss": -31.149042278289794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.866555213928223, "step": 82000}
{"episode_reward": 480.00867141015874, "episode": 83.0, "batch_reward": 0.25981077829003335, "critic_loss": 0.2618137081414461, "actor_loss": -31.229258396148683, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.849808931350708, "step": 83000}
{"episode_reward": 479.3382350074264, "episode": 84.0, "batch_reward": 0.26187527371943, "critic_loss": 0.26363224439322946, "actor_loss": -31.484630001068115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.862253427505493, "step": 84000}
{"episode_reward": 460.74994372761864, "episode": 85.0, "batch_reward": 0.2641297908872366, "critic_loss": 0.25735981699079274, "actor_loss": -31.689338970184327, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.870656490325928, "step": 85000}
{"episode_reward": 472.32151171032984, "episode": 86.0, "batch_reward": 0.2666962243616581, "critic_loss": 0.27217396584153175, "actor_loss": -31.616990676879883, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.844839334487915, "step": 86000}
{"episode_reward": 500.0155925422003, "episode": 87.0, "batch_reward": 0.26744224317371845, "critic_loss": 0.29048412045836447, "actor_loss": -31.459556632995607, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88065242767334, "step": 87000}
{"episode_reward": 139.77547885991402, "episode": 88.0, "batch_reward": 0.2672854214608669, "critic_loss": 0.2678415692746639, "actor_loss": -31.31395309829712, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.892969369888306, "step": 88000}
{"episode_reward": 274.88297328859056, "episode": 89.0, "batch_reward": 0.2677431737035513, "critic_loss": 0.27129924804717304, "actor_loss": -31.656370872497558, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.816248416900635, "step": 89000}
{"episode_reward": 492.5099695270592, "episode": 90.0, "batch_reward": 0.2706402209252119, "critic_loss": 0.2833531927615404, "actor_loss": -31.938361614227293, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.858261346817017, "step": 90000}
{"episode_reward": 460.05423298044855, "episode": 91.0, "batch_reward": 0.2728145732283592, "critic_loss": 0.28753103175014255, "actor_loss": -31.831306858062746, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.19182562828064, "step": 91000}
{"episode_reward": 474.8431923779, "episode": 92.0, "batch_reward": 0.27522493128478526, "critic_loss": 0.2660993534848094, "actor_loss": -32.21166298675537, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.84973978996277, "step": 92000}
{"episode_reward": 510.15399803241206, "episode": 93.0, "batch_reward": 0.2765233208686113, "critic_loss": 0.27080685943365096, "actor_loss": -32.16940146636963, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.84515142440796, "step": 93000}
{"episode_reward": 498.8402699671262, "episode": 94.0, "batch_reward": 0.2790786412060261, "critic_loss": 0.2665883286520839, "actor_loss": -32.473085521697996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.859230756759644, "step": 94000}
{"episode_reward": 462.6875009550282, "episode": 95.0, "batch_reward": 0.28163230381906035, "critic_loss": 0.29427705594152215, "actor_loss": -32.894212814331055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.843005895614624, "step": 95000}
{"episode_reward": 482.11206797164806, "episode": 96.0, "batch_reward": 0.28341925103962423, "critic_loss": 0.26671126190572975, "actor_loss": -32.77665277862549, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.833816528320312, "step": 96000}
{"episode_reward": 479.46029852306845, "episode": 97.0, "batch_reward": 0.28588464473187924, "critic_loss": 0.29339596735686063, "actor_loss": -33.18415508270264, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89208173751831, "step": 97000}
{"episode_reward": 497.83204106583116, "episode": 98.0, "batch_reward": 0.28866370756924153, "critic_loss": 0.29024060698598625, "actor_loss": -33.303498161315915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.85948944091797, "step": 98000}
{"episode_reward": 477.5310022540294, "episode": 99.0, "batch_reward": 0.2903538263738155, "critic_loss": 0.27227401723712685, "actor_loss": -33.35338388061523, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.849555730819702, "step": 99000}
{"episode_reward": 509.1391722190046, "episode": 100.0, "batch_reward": 0.2926441800445318, "critic_loss": 0.2823388849273324, "actor_loss": -33.383078437805175, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.84152054786682, "step": 100000}
{"episode_reward": 509.66068485091887, "episode": 101.0, "batch_reward": 0.29391879014670846, "critic_loss": 0.2894496036469936, "actor_loss": -33.76041707229614, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.169249057769775, "step": 101000}
{"episode_reward": 527.2988467794282, "episode": 102.0, "batch_reward": 0.2960371364951134, "critic_loss": 0.2744643448144197, "actor_loss": -34.09487175750733, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.870023488998413, "step": 102000}
{"episode_reward": 491.2730259251959, "episode": 103.0, "batch_reward": 0.2980484973043203, "critic_loss": 0.30034494735300543, "actor_loss": -34.13138452911377, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87979793548584, "step": 103000}
{"episode_reward": 513.0088051901735, "episode": 104.0, "batch_reward": 0.3014332646429539, "critic_loss": 0.29162875570356844, "actor_loss": -34.2792548828125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.799642086029053, "step": 104000}
{"episode_reward": 516.5477553527368, "episode": 105.0, "batch_reward": 0.30335844615101815, "critic_loss": 0.26403697215765715, "actor_loss": -33.996678730010984, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.874759435653687, "step": 105000}
{"episode_reward": 499.7739754546454, "episode": 106.0, "batch_reward": 0.3036061471104622, "critic_loss": 0.2747996503636241, "actor_loss": -33.86629584121704, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.85010576248169, "step": 106000}
{"episode_reward": 522.0617181661878, "episode": 107.0, "batch_reward": 0.3069760335236788, "critic_loss": 0.27645693490654233, "actor_loss": -34.77376719665527, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.845031023025513, "step": 107000}
{"episode_reward": 532.5563758850953, "episode": 108.0, "batch_reward": 0.3096684155464172, "critic_loss": 0.25955973943322896, "actor_loss": -34.99653751754761, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.85195827484131, "step": 108000}
{"episode_reward": 515.0011277536679, "episode": 109.0, "batch_reward": 0.310665557205677, "critic_loss": 0.2516483025699854, "actor_loss": -34.86897253799439, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.868648767471313, "step": 109000}
{"episode_reward": 514.3627338331294, "episode": 110.0, "batch_reward": 0.3124199575781822, "critic_loss": 0.24089334753900765, "actor_loss": -35.167377933502195, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.85740828514099, "step": 110000}
{"episode_reward": 515.5380283145557, "episode": 111.0, "batch_reward": 0.3152047178000212, "critic_loss": 0.25924653535336256, "actor_loss": -35.377439029693605, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.152034521102905, "step": 111000}
{"episode_reward": 478.8381272657279, "episode": 112.0, "batch_reward": 0.3158718010932207, "critic_loss": 0.26229805961251257, "actor_loss": -35.318618419647215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.854315042495728, "step": 112000}
{"episode_reward": 497.78675814508904, "episode": 113.0, "batch_reward": 0.3175208982527256, "critic_loss": 0.2554137829393148, "actor_loss": -35.38792195129395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.906046628952026, "step": 113000}
{"episode_reward": 531.6783086892967, "episode": 114.0, "batch_reward": 0.31852252554893495, "critic_loss": 0.2601086854934692, "actor_loss": -35.855639850616456, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.873600244522095, "step": 114000}
{"episode_reward": 498.3233269948994, "episode": 115.0, "batch_reward": 0.32183230423927306, "critic_loss": 0.2866561875641346, "actor_loss": -35.88954528427124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.915894031524658, "step": 115000}
{"episode_reward": 505.24045960301066, "episode": 116.0, "batch_reward": 0.32332064092159274, "critic_loss": 0.2785233834013343, "actor_loss": -36.27636834716797, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.933805227279663, "step": 116000}
{"episode_reward": 503.00241780247126, "episode": 117.0, "batch_reward": 0.32506069356203077, "critic_loss": 0.25979543951153755, "actor_loss": -36.196322521209716, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.903654098510742, "step": 117000}
{"episode_reward": 531.0088084193984, "episode": 118.0, "batch_reward": 0.32572390618920327, "critic_loss": 0.25231715638935565, "actor_loss": -36.499752063751224, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.887105464935303, "step": 118000}
{"episode_reward": 523.7161454049331, "episode": 119.0, "batch_reward": 0.32698886159062385, "critic_loss": 0.2668813175782561, "actor_loss": -36.262867012023925, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89816975593567, "step": 119000}
{"episode_reward": 498.54373166426103, "episode": 120.0, "batch_reward": 0.3280107645690441, "critic_loss": 0.26258939097076656, "actor_loss": -35.97720627975464, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87175750732422, "step": 120000}
{"episode_reward": 484.26172989144936, "episode": 121.0, "batch_reward": 0.33094006225466727, "critic_loss": 0.2601799558699131, "actor_loss": -36.35974570083618, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.529367446899414, "step": 121000}
{"episode_reward": 530.5374719265911, "episode": 122.0, "batch_reward": 0.33174179992079733, "critic_loss": 0.2630062568485737, "actor_loss": -36.656574813842774, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88195776939392, "step": 122000}
{"episode_reward": 536.4492801187149, "episode": 123.0, "batch_reward": 0.3347321973145008, "critic_loss": 0.2547500087544322, "actor_loss": -36.60492392730713, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89353108406067, "step": 123000}
{"episode_reward": 503.0270449010867, "episode": 124.0, "batch_reward": 0.33515866643190384, "critic_loss": 0.26993366934359075, "actor_loss": -37.07588288879395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.892051935195923, "step": 124000}
{"episode_reward": 513.5244352868493, "episode": 125.0, "batch_reward": 0.33588931694626806, "critic_loss": 0.278178461804986, "actor_loss": -36.738197887420654, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.886255502700806, "step": 125000}
{"episode_reward": 489.24342827107444, "episode": 126.0, "batch_reward": 0.3366376736164093, "critic_loss": 0.2531847134307027, "actor_loss": -37.320082481384276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.921615839004517, "step": 126000}
{"episode_reward": 512.3150956193914, "episode": 127.0, "batch_reward": 0.3384385167360306, "critic_loss": 0.2523755726367235, "actor_loss": -37.46084007263184, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.909767627716064, "step": 127000}
{"episode_reward": 510.1186384930859, "episode": 128.0, "batch_reward": 0.3406213273704052, "critic_loss": 0.27134982094913723, "actor_loss": -37.796799365997316, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.909748554229736, "step": 128000}
{"episode_reward": 501.0848631872823, "episode": 129.0, "batch_reward": 0.34075319477915766, "critic_loss": 0.27087968473881485, "actor_loss": -37.93132219696045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.874111652374268, "step": 129000}
{"episode_reward": 527.2936724628761, "episode": 130.0, "batch_reward": 0.3424433295726776, "critic_loss": 0.25387409968674185, "actor_loss": -37.57825527572632, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.857840299606323, "step": 130000}
{"episode_reward": 501.38503345596445, "episode": 131.0, "batch_reward": 0.345013035774231, "critic_loss": 0.25038292320817707, "actor_loss": -37.95990642166138, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.52164340019226, "step": 131000}
{"episode_reward": 536.435191310363, "episode": 132.0, "batch_reward": 0.3460502505302429, "critic_loss": 0.2514628575220704, "actor_loss": -37.89092764282226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.893970727920532, "step": 132000}
{"episode_reward": 504.0958999559594, "episode": 133.0, "batch_reward": 0.34650918212533, "critic_loss": 0.25442388287186624, "actor_loss": -38.383850582122804, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89806604385376, "step": 133000}
{"episode_reward": 515.7224015891602, "episode": 134.0, "batch_reward": 0.34674352142214776, "critic_loss": 0.24560670211166144, "actor_loss": -38.57260603713989, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.84062433242798, "step": 134000}
{"episode_reward": 495.0648547948737, "episode": 135.0, "batch_reward": 0.3493843157589436, "critic_loss": 0.24794856228679418, "actor_loss": -38.26133044052124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.843236207962036, "step": 135000}
{"episode_reward": 532.7248814704103, "episode": 136.0, "batch_reward": 0.3505640335083008, "critic_loss": 0.2475597572699189, "actor_loss": -38.466428428649905, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.823598384857178, "step": 136000}
{"episode_reward": 513.2685271552737, "episode": 137.0, "batch_reward": 0.35201877638697626, "critic_loss": 0.2537324475571513, "actor_loss": -38.4778681678772, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.856778860092163, "step": 137000}
{"episode_reward": 530.9030707816896, "episode": 138.0, "batch_reward": 0.35325773045420644, "critic_loss": 0.2511034366339445, "actor_loss": -38.388414642333984, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.827738046646118, "step": 138000}
{"episode_reward": 533.5830302314258, "episode": 139.0, "batch_reward": 0.35411891934275624, "critic_loss": 0.2629088397398591, "actor_loss": -38.60359899520874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.840369701385498, "step": 139000}
{"episode_reward": 512.7301574344108, "episode": 140.0, "batch_reward": 0.35462422782182695, "critic_loss": 0.2642374994978309, "actor_loss": -38.557298816680905, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.857618808746338, "step": 140000}
{"episode_reward": 510.77250193147336, "episode": 141.0, "batch_reward": 0.3570047779083252, "critic_loss": 0.24994345758855344, "actor_loss": -38.71565033340454, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.23711848258972, "step": 141000}
{"episode_reward": 525.9245717718376, "episode": 142.0, "batch_reward": 0.35712373396754266, "critic_loss": 0.26662935196608306, "actor_loss": -38.919936447143556, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.84447741508484, "step": 142000}
{"episode_reward": 546.8579099969187, "episode": 143.0, "batch_reward": 0.3599852097928524, "critic_loss": 0.26976322588324547, "actor_loss": -39.17598065185547, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.877535343170166, "step": 143000}
{"episode_reward": 541.994838587395, "episode": 144.0, "batch_reward": 0.36048822435736655, "critic_loss": 0.25546053620427844, "actor_loss": -39.27074069976807, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87094521522522, "step": 144000}
{"episode_reward": 518.942470291352, "episode": 145.0, "batch_reward": 0.36255005037784577, "critic_loss": 0.2701447411328554, "actor_loss": -39.51559819412231, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.860203742980957, "step": 145000}
{"episode_reward": 524.0740317730678, "episode": 146.0, "batch_reward": 0.36215621641278267, "critic_loss": 0.23258741211146117, "actor_loss": -39.77997388458252, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87506413459778, "step": 146000}
{"episode_reward": 542.2579155968845, "episode": 147.0, "batch_reward": 0.3641045345067978, "critic_loss": 0.2587730317786336, "actor_loss": -39.70044826889038, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.862595796585083, "step": 147000}
{"episode_reward": 542.0938071327787, "episode": 148.0, "batch_reward": 0.36560368159413337, "critic_loss": 0.23490612748265266, "actor_loss": -39.691452175140384, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.830522775650024, "step": 148000}
{"episode_reward": 546.2129962788551, "episode": 149.0, "batch_reward": 0.3661038528084755, "critic_loss": 0.2706499802172184, "actor_loss": -39.90314854431152, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.819265604019165, "step": 149000}
{"episode_reward": 518.6590813127633, "episode": 150.0, "batch_reward": 0.36792414063215256, "critic_loss": 0.2630894374474883, "actor_loss": -40.11124297714233, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
