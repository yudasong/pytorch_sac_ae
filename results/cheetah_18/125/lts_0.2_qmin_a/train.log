{"episode_reward": 0.0, "episode": 1.0, "duration": 17.530746459960938, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.5123910903930664, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.22060613984831495, "critic_loss": 0.036162265575645856, "actor_loss": -10.833069870466826, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 61.803430795669556, "step": 3000}
{"episode_reward": 86.0045479749215, "episode": 4.0, "batch_reward": 0.18633440859615802, "critic_loss": 0.06207370579428971, "actor_loss": -13.94598930644989, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.363710641860962, "step": 4000}
{"episode_reward": 246.48113083909155, "episode": 5.0, "batch_reward": 0.20412695279717447, "critic_loss": 0.06969138497114181, "actor_loss": -14.323888894081115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.40155839920044, "step": 5000}
{"episode_reward": 211.2475147857101, "episode": 6.0, "batch_reward": 0.19206003700196744, "critic_loss": 0.07251474340260029, "actor_loss": -14.06289262676239, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.41229772567749, "step": 6000}
{"episode_reward": 73.5838683653793, "episode": 7.0, "batch_reward": 0.17966437117755413, "critic_loss": 0.08015135773643851, "actor_loss": -14.463222084999085, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.39025044441223, "step": 7000}
{"episode_reward": 119.54785951044869, "episode": 8.0, "batch_reward": 0.165732996404171, "critic_loss": 0.07290559659153223, "actor_loss": -13.797738966941834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.404470205307007, "step": 8000}
{"episode_reward": 52.4732216127012, "episode": 9.0, "batch_reward": 0.15565975735336543, "critic_loss": 0.08222169549390673, "actor_loss": -14.300420372009278, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.380226135253906, "step": 9000}
{"episode_reward": 83.40266538300321, "episode": 10.0, "batch_reward": 0.15209543397277595, "critic_loss": 0.11297044960036874, "actor_loss": -14.575364921569824, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.39911127090454, "step": 10000}
{"episode_reward": 163.31925492117284, "episode": 11.0, "batch_reward": 0.1471474719569087, "critic_loss": 0.1032042690590024, "actor_loss": -15.701450910568237, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.9843909740448, "step": 11000}
{"episode_reward": 56.24036822920421, "episode": 12.0, "batch_reward": 0.1443337637782097, "critic_loss": 0.1320367523469031, "actor_loss": -15.470159006118774, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.390440702438354, "step": 12000}
{"episode_reward": 137.5088825827041, "episode": 13.0, "batch_reward": 0.13876080844551325, "critic_loss": 0.15542503874003888, "actor_loss": -15.598885828018188, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.395731925964355, "step": 13000}
{"episode_reward": 65.73917193517472, "episode": 14.0, "batch_reward": 0.13914528057724238, "critic_loss": 0.17434340710937976, "actor_loss": -15.85540252494812, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.404242277145386, "step": 14000}
{"episode_reward": 228.1127630472355, "episode": 15.0, "batch_reward": 0.1432041131928563, "critic_loss": 0.21537489347159863, "actor_loss": -16.44447664451599, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.38406252861023, "step": 15000}
{"episode_reward": 104.37146597486519, "episode": 16.0, "batch_reward": 0.14376176553219558, "critic_loss": 0.2351635980606079, "actor_loss": -16.786417125701906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.38831114768982, "step": 16000}
{"episode_reward": 232.0308289791917, "episode": 17.0, "batch_reward": 0.14476763419806957, "critic_loss": 0.24106673286110164, "actor_loss": -16.66220122718811, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.392125606536865, "step": 17000}
{"episode_reward": 75.59202930252613, "episode": 18.0, "batch_reward": 0.14042236322909593, "critic_loss": 0.23609796998649835, "actor_loss": -16.462771030426026, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.399304389953613, "step": 18000}
{"episode_reward": 67.63416196750717, "episode": 19.0, "batch_reward": 0.1362972773760557, "critic_loss": 0.2488758851289749, "actor_loss": -17.055174823760986, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.37285804748535, "step": 19000}
{"episode_reward": 89.27122355642366, "episode": 20.0, "batch_reward": 0.1338136759698391, "critic_loss": 0.25363125698268413, "actor_loss": -16.898602695465087, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.39875817298889, "step": 20000}
{"episode_reward": 103.72158992068596, "episode": 21.0, "batch_reward": 0.13790066604316234, "critic_loss": 0.2847942612692714, "actor_loss": -17.649991647720338, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.9054479598999, "step": 21000}
{"episode_reward": 279.73901391040533, "episode": 22.0, "batch_reward": 0.13812981124967336, "critic_loss": 0.2762141813486815, "actor_loss": -17.61853026199341, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.373304843902588, "step": 22000}
{"episode_reward": 36.96460689863201, "episode": 23.0, "batch_reward": 0.13545701383054257, "critic_loss": 0.26479858058691025, "actor_loss": -17.268250022888182, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.38788104057312, "step": 23000}
{"episode_reward": 88.34095757534052, "episode": 24.0, "batch_reward": 0.13222144684940576, "critic_loss": 0.27452752918750045, "actor_loss": -17.285462890625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.41541361808777, "step": 24000}
{"episode_reward": 54.618928312433695, "episode": 25.0, "batch_reward": 0.1329653317555785, "critic_loss": 0.3014046482667327, "actor_loss": -17.657353704452515, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.379759788513184, "step": 25000}
{"episode_reward": 284.8844839423176, "episode": 26.0, "batch_reward": 0.13762895146012305, "critic_loss": 0.34947797380387785, "actor_loss": -18.192251483917236, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.385809898376465, "step": 26000}
{"episode_reward": 225.35906670724304, "episode": 27.0, "batch_reward": 0.14459337471425535, "critic_loss": 0.3888495938926935, "actor_loss": -18.943847665786745, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.397396326065063, "step": 27000}
{"episode_reward": 410.9266516889683, "episode": 28.0, "batch_reward": 0.15416147324442864, "critic_loss": 0.3781947237998247, "actor_loss": -19.710081037521363, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.3470618724823, "step": 28000}
{"episode_reward": 395.45332101114104, "episode": 29.0, "batch_reward": 0.15835913549363614, "critic_loss": 0.4114779231250286, "actor_loss": -20.296916736602782, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.39373517036438, "step": 29000}
{"episode_reward": 59.077683463287876, "episode": 30.0, "batch_reward": 0.15673536661267282, "critic_loss": 0.42749214740097524, "actor_loss": -20.367983839035034, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.396304845809937, "step": 30000}
{"episode_reward": 177.26130980858008, "episode": 31.0, "batch_reward": 0.15657446134090425, "critic_loss": 0.42121104657649994, "actor_loss": -20.490057344436647, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.90927314758301, "step": 31000}
{"episode_reward": 133.67639344220999, "episode": 32.0, "batch_reward": 0.15545963829010725, "critic_loss": 0.4081275787204504, "actor_loss": -20.611636825561522, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.399669647216797, "step": 32000}
{"episode_reward": 127.11298647838805, "episode": 33.0, "batch_reward": 0.15816181107610464, "critic_loss": 0.400000536441803, "actor_loss": -20.818864864349365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.369128227233887, "step": 33000}
{"episode_reward": 388.0210469039402, "episode": 34.0, "batch_reward": 0.16397871132940053, "critic_loss": 0.39950106489658355, "actor_loss": -21.282715717315675, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.401816844940186, "step": 34000}
{"episode_reward": 391.7662506285526, "episode": 35.0, "batch_reward": 0.17060139672458172, "critic_loss": 0.43507795710861685, "actor_loss": -22.003910427093505, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.405876874923706, "step": 35000}
{"episode_reward": 392.53518309715645, "episode": 36.0, "batch_reward": 0.17642875047028064, "critic_loss": 0.4372565459907055, "actor_loss": -22.651635665893554, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.368960857391357, "step": 36000}
{"episode_reward": 399.8854735167784, "episode": 37.0, "batch_reward": 0.183411116451025, "critic_loss": 0.4753484500348568, "actor_loss": -23.199990356445312, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.4237117767334, "step": 37000}
{"episode_reward": 425.97737748918723, "episode": 38.0, "batch_reward": 0.1905899660438299, "critic_loss": 0.4631728732734919, "actor_loss": -23.882552761077882, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.401125192642212, "step": 38000}
{"episode_reward": 403.65017003555045, "episode": 39.0, "batch_reward": 0.19650598557293414, "critic_loss": 0.4567444880306721, "actor_loss": -24.63424586105347, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.375977754592896, "step": 39000}
{"episode_reward": 470.8227011656523, "episode": 40.0, "batch_reward": 0.2036232637166977, "critic_loss": 0.47779054749011995, "actor_loss": -25.404734752655028, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.38520312309265, "step": 40000}
{"episode_reward": 430.55103504799763, "episode": 41.0, "batch_reward": 0.20943353256583214, "critic_loss": 0.4487136392891407, "actor_loss": -25.78708718109131, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.90381956100464, "step": 41000}
{"episode_reward": 462.4426665378721, "episode": 42.0, "batch_reward": 0.2128951430618763, "critic_loss": 0.44920270252227784, "actor_loss": -25.89684769439697, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.399065494537354, "step": 42000}
{"episode_reward": 166.5000188512203, "episode": 43.0, "batch_reward": 0.21368859416246413, "critic_loss": 0.45995340698957443, "actor_loss": -26.196195663452148, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.406283617019653, "step": 43000}
{"episode_reward": 433.4963564106147, "episode": 44.0, "batch_reward": 0.2191004341840744, "critic_loss": 0.4528714420646429, "actor_loss": -26.769474731445314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.351395845413208, "step": 44000}
{"episode_reward": 503.7703034064688, "episode": 45.0, "batch_reward": 0.22436858204007148, "critic_loss": 0.4375931224673986, "actor_loss": -27.213880081176757, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.381736040115356, "step": 45000}
{"episode_reward": 254.02474557608892, "episode": 46.0, "batch_reward": 0.22615215577185155, "critic_loss": 0.44614282983541487, "actor_loss": -27.597917720794676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.407012939453125, "step": 46000}
{"episode_reward": 510.87293139064604, "episode": 47.0, "batch_reward": 0.23343752317130564, "critic_loss": 0.4079044191539288, "actor_loss": -27.966348209381103, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.40042757987976, "step": 47000}
{"episode_reward": 485.85253231781047, "episode": 48.0, "batch_reward": 0.23781859849393366, "critic_loss": 0.3951426296830177, "actor_loss": -28.30627194595337, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.4256649017334, "step": 48000}
{"episode_reward": 507.4422595390571, "episode": 49.0, "batch_reward": 0.2427404482215643, "critic_loss": 0.3986227039992809, "actor_loss": -28.806431686401368, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.38783359527588, "step": 49000}
{"episode_reward": 485.6248353038696, "episode": 50.0, "batch_reward": 0.24807766212522983, "critic_loss": 0.3893200045526028, "actor_loss": -29.411056686401366, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.370808124542236, "step": 50000}
{"episode_reward": 538.0974393848558, "episode": 51.0, "batch_reward": 0.25519628612697126, "critic_loss": 0.3270996731221676, "actor_loss": -29.85030554962158, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.94462323188782, "step": 51000}
{"episode_reward": 548.6523771381156, "episode": 52.0, "batch_reward": 0.25963194885849955, "critic_loss": 0.32407607753574846, "actor_loss": -30.42636207962036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.376933813095093, "step": 52000}
{"episode_reward": 522.8227645132368, "episode": 53.0, "batch_reward": 0.2620135743021965, "critic_loss": 0.3416184166222811, "actor_loss": -30.597827194213867, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.3847918510437, "step": 53000}
{"episode_reward": 137.13980865456114, "episode": 54.0, "batch_reward": 0.26158705793321135, "critic_loss": 0.3134332552403212, "actor_loss": -30.139070262908934, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.383389711380005, "step": 54000}
{"episode_reward": 503.3034185713106, "episode": 55.0, "batch_reward": 0.2670547826141119, "critic_loss": 0.3493604787290096, "actor_loss": -30.625242847442628, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.385818243026733, "step": 55000}
{"episode_reward": 537.1408724999582, "episode": 56.0, "batch_reward": 0.2712002623081207, "critic_loss": 0.3317626933455467, "actor_loss": -31.098762310028075, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.371440887451172, "step": 56000}
{"episode_reward": 535.6657134679953, "episode": 57.0, "batch_reward": 0.2767052529603243, "critic_loss": 0.3481928057968616, "actor_loss": -31.705768951416015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.37963104248047, "step": 57000}
{"episode_reward": 535.5045410189023, "episode": 58.0, "batch_reward": 0.28087767735123637, "critic_loss": 0.32954301457107066, "actor_loss": -31.790441261291505, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.372092485427856, "step": 58000}
{"episode_reward": 500.77605724565814, "episode": 59.0, "batch_reward": 0.2841205342710018, "critic_loss": 0.344244437456131, "actor_loss": -32.385093936920164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.377386569976807, "step": 59000}
{"episode_reward": 516.0190738127668, "episode": 60.0, "batch_reward": 0.28848676934838297, "critic_loss": 0.35716470547020435, "actor_loss": -32.92988652038574, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.382031440734863, "step": 60000}
{"episode_reward": 537.9286131895923, "episode": 61.0, "batch_reward": 0.29350277335941793, "critic_loss": 0.3919823200106621, "actor_loss": -33.21125569534302, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.909135580062866, "step": 61000}
{"episode_reward": 553.0009464931449, "episode": 62.0, "batch_reward": 0.2967902790158987, "critic_loss": 0.3842791231274605, "actor_loss": -33.455716583251956, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.42585563659668, "step": 62000}
{"episode_reward": 527.6577600328981, "episode": 63.0, "batch_reward": 0.2993153861612082, "critic_loss": 0.3488395795375109, "actor_loss": -34.148466621398924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.353004217147827, "step": 63000}
{"episode_reward": 502.8843728346334, "episode": 64.0, "batch_reward": 0.3027164011746645, "critic_loss": 0.38348001378774643, "actor_loss": -34.21324740982055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.364731788635254, "step": 64000}
{"episode_reward": 481.5095209670715, "episode": 65.0, "batch_reward": 0.3028562626987696, "critic_loss": 0.3880944242328405, "actor_loss": -34.5939347114563, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.39767599105835, "step": 65000}
{"episode_reward": 6.451441460776923, "episode": 66.0, "batch_reward": 0.30097024773061276, "critic_loss": 0.40263042214512823, "actor_loss": -34.73202507781983, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.381104707717896, "step": 66000}
{"episode_reward": 406.19868139174446, "episode": 67.0, "batch_reward": 0.3014660039693117, "critic_loss": 0.41879074481129647, "actor_loss": -35.28656851577759, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.405137538909912, "step": 67000}
{"episode_reward": 283.9823116656742, "episode": 68.0, "batch_reward": 0.302483025893569, "critic_loss": 0.46791337840259073, "actor_loss": -35.62015265655518, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.412394046783447, "step": 68000}
{"episode_reward": 506.7361457084921, "episode": 69.0, "batch_reward": 0.30589220313727855, "critic_loss": 0.4610978516787291, "actor_loss": -36.23586939239502, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.334648847579956, "step": 69000}
{"episode_reward": 428.2393995054984, "episode": 70.0, "batch_reward": 0.30769054129719736, "critic_loss": 0.4855429622083902, "actor_loss": -36.65458706665039, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.359963178634644, "step": 70000}
{"episode_reward": 533.8230242068923, "episode": 71.0, "batch_reward": 0.3116329446285963, "critic_loss": 0.4739978339970112, "actor_loss": -37.20455345916748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.965853214263916, "step": 71000}
{"episode_reward": 558.4105507815658, "episode": 72.0, "batch_reward": 0.31460422664880755, "critic_loss": 0.4572894899100065, "actor_loss": -37.777350036621094, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.42319369316101, "step": 72000}
{"episode_reward": 558.178342699015, "episode": 73.0, "batch_reward": 0.31889133220911026, "critic_loss": 0.5091940303742886, "actor_loss": -38.45932111358643, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.389707565307617, "step": 73000}
{"episode_reward": 569.4062523689191, "episode": 74.0, "batch_reward": 0.3220408054292202, "critic_loss": 0.5400160741209984, "actor_loss": -38.938664924621584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.341272830963135, "step": 74000}
{"episode_reward": 529.4573277916126, "episode": 75.0, "batch_reward": 0.3246581121981144, "critic_loss": 0.5400877927690745, "actor_loss": -39.50606217956543, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.37471890449524, "step": 75000}
{"episode_reward": 510.57142471585496, "episode": 76.0, "batch_reward": 0.32671393421292305, "critic_loss": 0.5981917149424553, "actor_loss": -39.90697718048096, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.42120051383972, "step": 76000}
{"episode_reward": 524.2350447331213, "episode": 77.0, "batch_reward": 0.3279963833093643, "critic_loss": 0.7143791806846858, "actor_loss": -40.444083267211916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.373389720916748, "step": 77000}
{"episode_reward": 228.55790551478754, "episode": 78.0, "batch_reward": 0.326848154515028, "critic_loss": 0.707844524025917, "actor_loss": -40.64312628936768, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.38512659072876, "step": 78000}
{"episode_reward": 186.82832995609658, "episode": 79.0, "batch_reward": 0.3244400593340397, "critic_loss": 0.7362567989528179, "actor_loss": -40.9609260559082, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.436280012130737, "step": 79000}
{"episode_reward": 98.23544222078252, "episode": 80.0, "batch_reward": 0.32134648129343985, "critic_loss": 0.6872629111111164, "actor_loss": -41.42048062896728, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.364505529403687, "step": 80000}
{"episode_reward": 142.158715324496, "episode": 81.0, "batch_reward": 0.318306837439537, "critic_loss": 0.8503648253083229, "actor_loss": -42.01762072753906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.992448568344116, "step": 81000}
{"episode_reward": 3.6111359843784463, "episode": 82.0, "batch_reward": 0.3145883783996105, "critic_loss": 0.9919011659026146, "actor_loss": -43.032443313598634, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.426241159439087, "step": 82000}
{"episode_reward": 4.1864920583280245, "episode": 83.0, "batch_reward": 0.3109671775996685, "critic_loss": 1.101354562163353, "actor_loss": -43.777497367858885, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.42262363433838, "step": 83000}
{"episode_reward": 9.583769877934518, "episode": 84.0, "batch_reward": 0.3071447146087885, "critic_loss": 1.277513263463974, "actor_loss": -44.33038068389892, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.40252161026001, "step": 84000}
{"episode_reward": 11.003667242792549, "episode": 85.0, "batch_reward": 0.30306246389448643, "critic_loss": 1.6909301813840867, "actor_loss": -45.06363272094727, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.429845333099365, "step": 85000}
{"episode_reward": 10.081053967026609, "episode": 86.0, "batch_reward": 0.29970796656608584, "critic_loss": 2.3606432858109474, "actor_loss": -45.680360542297365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.410013675689697, "step": 86000}
{"episode_reward": 42.14131196917356, "episode": 87.0, "batch_reward": 0.2971241488158703, "critic_loss": 2.7693110733032227, "actor_loss": -46.39846395874024, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.397490978240967, "step": 87000}
{"episode_reward": 93.56480269274041, "episode": 88.0, "batch_reward": 0.29601116850972176, "critic_loss": 2.9328947917222976, "actor_loss": -47.85847284698486, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.3476779460907, "step": 88000}
{"episode_reward": 293.4303752432531, "episode": 89.0, "batch_reward": 0.2951589618176222, "critic_loss": 2.8192439367175104, "actor_loss": -49.460353843688964, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.38238000869751, "step": 89000}
{"episode_reward": 301.0680820076614, "episode": 90.0, "batch_reward": 0.29514246340095995, "critic_loss": 2.3020483110547065, "actor_loss": -50.67860626220703, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.415571212768555, "step": 90000}
{"episode_reward": 110.61265676117328, "episode": 91.0, "batch_reward": 0.2947969351708889, "critic_loss": 1.7798300787806511, "actor_loss": -51.79147334289551, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.90824222564697, "step": 91000}
{"episode_reward": 208.27824208209935, "episode": 92.0, "batch_reward": 0.291890265956521, "critic_loss": 1.3688412605524063, "actor_loss": -51.93199101257324, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.40539002418518, "step": 92000}
{"episode_reward": 79.78603405180665, "episode": 93.0, "batch_reward": 0.2889823657721281, "critic_loss": 1.0272952406704425, "actor_loss": -52.558031257629395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.42647910118103, "step": 93000}
{"episode_reward": 70.7964519235405, "episode": 94.0, "batch_reward": 0.2876883099973202, "critic_loss": 0.8634247387051582, "actor_loss": -51.87112435913086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.421714305877686, "step": 94000}
{"episode_reward": 230.07508840728147, "episode": 95.0, "batch_reward": 0.28617548795044423, "critic_loss": 0.6712582650184631, "actor_loss": -50.7045348815918, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.421567916870117, "step": 95000}
{"episode_reward": 20.87338187671501, "episode": 96.0, "batch_reward": 0.2828373810350895, "critic_loss": 0.5611173411309719, "actor_loss": -50.086543212890625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.44404935836792, "step": 96000}
{"episode_reward": 9.46139520751908, "episode": 97.0, "batch_reward": 0.28181013782322406, "critic_loss": 0.5237096716761589, "actor_loss": -49.301632957458494, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.406543493270874, "step": 97000}
{"episode_reward": 275.1499173483234, "episode": 98.0, "batch_reward": 0.28282751607894896, "critic_loss": 0.5286809277832508, "actor_loss": -48.569135688781735, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.378783226013184, "step": 98000}
{"episode_reward": 299.69222027187226, "episode": 99.0, "batch_reward": 0.2822665688842535, "critic_loss": 0.4994733090251684, "actor_loss": -47.757249618530274, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.44181251525879, "step": 99000}
{"episode_reward": 378.52281950188893, "episode": 100.0, "batch_reward": 0.28335474474728106, "critic_loss": 0.5325323204249144, "actor_loss": -47.13670357513428, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.412561178207397, "step": 100000}
{"episode_reward": 163.99781923334768, "episode": 101.0, "batch_reward": 0.28321817687153816, "critic_loss": 0.5536288694441318, "actor_loss": -46.026623474121095, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.92141652107239, "step": 101000}
{"episode_reward": 573.9846925840751, "episode": 102.0, "batch_reward": 0.28563461621105674, "critic_loss": 0.5501026868522167, "actor_loss": -45.78669745635986, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.41944193840027, "step": 102000}
{"episode_reward": 546.1262081405645, "episode": 103.0, "batch_reward": 0.2884937030524015, "critic_loss": 0.5633916372209787, "actor_loss": -45.37711703491211, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.37187886238098, "step": 103000}
{"episode_reward": 525.0724700903031, "episode": 104.0, "batch_reward": 0.2912553296536207, "critic_loss": 0.6016743172109127, "actor_loss": -45.17713965606689, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.407277822494507, "step": 104000}
{"episode_reward": 530.6056419526976, "episode": 105.0, "batch_reward": 0.2941495139300823, "critic_loss": 0.5743864351660013, "actor_loss": -44.98905545043945, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.407408714294434, "step": 105000}
{"episode_reward": 532.9100404324001, "episode": 106.0, "batch_reward": 0.29408969055116174, "critic_loss": 0.5569298586845398, "actor_loss": -44.52678624725342, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.356791734695435, "step": 106000}
{"episode_reward": 537.5186178237449, "episode": 107.0, "batch_reward": 0.2979572940319776, "critic_loss": 0.5432964663803578, "actor_loss": -44.36900144195557, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.399033069610596, "step": 107000}
{"episode_reward": 564.5423484924764, "episode": 108.0, "batch_reward": 0.3012905582934618, "critic_loss": 0.5290933773070574, "actor_loss": -44.07061898803711, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.37705159187317, "step": 108000}
{"episode_reward": 552.2837076857719, "episode": 109.0, "batch_reward": 0.30214078281819823, "critic_loss": 0.5012582354992628, "actor_loss": -43.714423080444334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.38130521774292, "step": 109000}
{"episode_reward": 524.2723506646543, "episode": 110.0, "batch_reward": 0.304703398257494, "critic_loss": 0.4752852054536343, "actor_loss": -43.608218818664554, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.412630081176758, "step": 110000}
{"episode_reward": 354.98306880702074, "episode": 111.0, "batch_reward": 0.30413991829752923, "critic_loss": 0.5493561872243882, "actor_loss": -43.258030647277835, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.89734435081482, "step": 111000}
{"episode_reward": 68.26881272356147, "episode": 112.0, "batch_reward": 0.30340327295660974, "critic_loss": 0.4945854069292545, "actor_loss": -42.94180144500732, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.375497817993164, "step": 112000}
{"episode_reward": 530.5171781554769, "episode": 113.0, "batch_reward": 0.30531173953413965, "critic_loss": 0.5084949320405722, "actor_loss": -42.71663631439209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.413904428482056, "step": 113000}
{"episode_reward": 545.2189496099153, "episode": 114.0, "batch_reward": 0.30638702036440374, "critic_loss": 0.504760686352849, "actor_loss": -42.35294788360596, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.36766743659973, "step": 114000}
{"episode_reward": 326.6200995642201, "episode": 115.0, "batch_reward": 0.30799039888381957, "critic_loss": 0.5262031465023757, "actor_loss": -42.268017272949216, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.424087285995483, "step": 115000}
{"episode_reward": 571.1209675923726, "episode": 116.0, "batch_reward": 0.3102298249900341, "critic_loss": 0.4868695627748966, "actor_loss": -42.30691068267822, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.34792184829712, "step": 116000}
{"episode_reward": 585.0744815624159, "episode": 117.0, "batch_reward": 0.31075233288109305, "critic_loss": 0.4847622724920511, "actor_loss": -42.096393119812014, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.364094257354736, "step": 117000}
{"episode_reward": 565.1427812800757, "episode": 118.0, "batch_reward": 0.3143998876810074, "critic_loss": 0.46773080149292945, "actor_loss": -42.02335186004639, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.399223566055298, "step": 118000}
{"episode_reward": 564.2417017482866, "episode": 119.0, "batch_reward": 0.31565936855971816, "critic_loss": 0.4563902302533388, "actor_loss": -42.140760620117184, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.393227338790894, "step": 119000}
{"episode_reward": 564.7484977340084, "episode": 120.0, "batch_reward": 0.3174196859896183, "critic_loss": 0.4536777432858944, "actor_loss": -41.80809020996094, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.37941265106201, "step": 120000}
{"episode_reward": 566.3747673886186, "episode": 121.0, "batch_reward": 0.32095108622312546, "critic_loss": 0.4575858754515648, "actor_loss": -41.886952163696286, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.9429452419281, "step": 121000}
{"episode_reward": 575.6881388279829, "episode": 122.0, "batch_reward": 0.32227851542830466, "critic_loss": 0.4155645166784525, "actor_loss": -41.848130348205565, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.38606834411621, "step": 122000}
{"episode_reward": 584.5365710918255, "episode": 123.0, "batch_reward": 0.32589874395728113, "critic_loss": 0.4288614944666624, "actor_loss": -41.77038798522949, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.402425289154053, "step": 123000}
{"episode_reward": 568.6304315089869, "episode": 124.0, "batch_reward": 0.3261223253309727, "critic_loss": 0.42350368279218675, "actor_loss": -41.81022236633301, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.374385595321655, "step": 124000}
{"episode_reward": 560.4951917100512, "episode": 125.0, "batch_reward": 0.3283225613832474, "critic_loss": 0.41984805251657964, "actor_loss": -41.731997230529785, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.3897225856781, "step": 125000}
{"episode_reward": 564.5432791170891, "episode": 126.0, "batch_reward": 0.32994850870966913, "critic_loss": 0.43840914392471314, "actor_loss": -41.75802306365967, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.406028509140015, "step": 126000}
{"episode_reward": 589.1679771928899, "episode": 127.0, "batch_reward": 0.33212374660372734, "critic_loss": 0.40768916653096676, "actor_loss": -41.747156204223636, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.36406397819519, "step": 127000}
{"episode_reward": 556.1447572882553, "episode": 128.0, "batch_reward": 0.33444904509186746, "critic_loss": 0.38656185552477834, "actor_loss": -41.70414727020264, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.375950574874878, "step": 128000}
{"episode_reward": 581.5103126260271, "episode": 129.0, "batch_reward": 0.3360936269760132, "critic_loss": 0.40620143893361094, "actor_loss": -41.688239776611326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.405581951141357, "step": 129000}
{"episode_reward": 580.3548639922743, "episode": 130.0, "batch_reward": 0.33886837804317477, "critic_loss": 0.3982990887016058, "actor_loss": -41.70829052734375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.385074853897095, "step": 130000}
{"episode_reward": 582.9837059193611, "episode": 131.0, "batch_reward": 0.33968277433514593, "critic_loss": 0.38626596964895726, "actor_loss": -41.650174613952636, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.901283979415894, "step": 131000}
{"episode_reward": 588.9436048215078, "episode": 132.0, "batch_reward": 0.34134126007556914, "critic_loss": 0.3873141475841403, "actor_loss": -41.55522248077393, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.406768321990967, "step": 132000}
{"episode_reward": 543.4134038413383, "episode": 133.0, "batch_reward": 0.3431009288430214, "critic_loss": 0.3607896474599838, "actor_loss": -41.63350904846192, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.359025955200195, "step": 133000}
{"episode_reward": 571.0468768227207, "episode": 134.0, "batch_reward": 0.3447136169075966, "critic_loss": 0.3450472739040852, "actor_loss": -41.71169287872314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.382375717163086, "step": 134000}
{"episode_reward": 538.4706219866393, "episode": 135.0, "batch_reward": 0.34632676526904105, "critic_loss": 0.3811500959396362, "actor_loss": -41.505855850219724, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.389708757400513, "step": 135000}
{"episode_reward": 594.6053499918344, "episode": 136.0, "batch_reward": 0.3479683496057987, "critic_loss": 0.38567336900532245, "actor_loss": -41.71248362731934, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.379889965057373, "step": 136000}
{"episode_reward": 566.4567875802232, "episode": 137.0, "batch_reward": 0.3496649579703808, "critic_loss": 0.39593597561120986, "actor_loss": -41.6102201461792, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.421849489212036, "step": 137000}
{"episode_reward": 577.5369794582049, "episode": 138.0, "batch_reward": 0.35281101036071777, "critic_loss": 0.37936753054708244, "actor_loss": -41.663689453125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.403120756149292, "step": 138000}
{"episode_reward": 545.0049209949163, "episode": 139.0, "batch_reward": 0.3515887611508369, "critic_loss": 0.371071869134903, "actor_loss": -41.61504914855957, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.388694047927856, "step": 139000}
{"episode_reward": 121.0731872841002, "episode": 140.0, "batch_reward": 0.35087389531731605, "critic_loss": 0.37074116775393484, "actor_loss": -41.40630093383789, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.372236013412476, "step": 140000}
{"episode_reward": 572.5709753686577, "episode": 141.0, "batch_reward": 0.3536472566127777, "critic_loss": 0.3810626499950886, "actor_loss": -41.42394107055664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.90456032752991, "step": 141000}
{"episode_reward": 579.1040549073816, "episode": 142.0, "batch_reward": 0.3528332370817661, "critic_loss": 0.392047211304307, "actor_loss": -41.32634279632568, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.44140076637268, "step": 142000}
{"episode_reward": 577.7427928963097, "episode": 143.0, "batch_reward": 0.35709214717149734, "critic_loss": 0.3668182720541954, "actor_loss": -41.66943251037598, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.437767267227173, "step": 143000}
{"episode_reward": 438.94443817596004, "episode": 144.0, "batch_reward": 0.3557316448688507, "critic_loss": 0.3962502790093422, "actor_loss": -41.59173574066162, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.380699396133423, "step": 144000}
{"episode_reward": 557.0350477701535, "episode": 145.0, "batch_reward": 0.35988933098316195, "critic_loss": 0.39195845849812033, "actor_loss": -41.66873597717285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.420235633850098, "step": 145000}
{"episode_reward": 590.3463459427782, "episode": 146.0, "batch_reward": 0.3589082354307175, "critic_loss": 0.39118584171682597, "actor_loss": -41.63863500976562, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.447142601013184, "step": 146000}
{"episode_reward": 577.3505750477316, "episode": 147.0, "batch_reward": 0.3607732708156109, "critic_loss": 0.3729370409399271, "actor_loss": -41.70045386505127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.41386365890503, "step": 147000}
{"episode_reward": 548.5090933391674, "episode": 148.0, "batch_reward": 0.3622429481744766, "critic_loss": 0.39594411532580853, "actor_loss": -41.854263381958006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.618659496307373, "step": 148000}
{"episode_reward": 585.2212883036595, "episode": 149.0, "batch_reward": 0.3651758190989494, "critic_loss": 0.39471545319259166, "actor_loss": -41.91105700683594, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.537039518356323, "step": 149000}
{"episode_reward": 602.6082745383349, "episode": 150.0, "batch_reward": 0.3663929552435875, "critic_loss": 0.4028222380653024, "actor_loss": -42.04380968475342, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
